{"id": "2602.02648", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.02648", "abs": "https://arxiv.org/abs/2602.02648", "authors": ["Yasamin Panahi", "Subhayan Sahu", "Naren Manjunath", "Chong Wang"], "title": "Quantum criticality at strong randomness: a lesson from anomaly", "comment": "5+13 pages, 8 figures", "summary": "Quantum criticality in the presence of strong quenched randomness remains a challenging topic in modern condensed matter theory. We show that the topology and anomaly associated with average symmetry can be used to predict certain nontrivial universal properties. Our focus is on systems subject to average Lieb--Schultz--Mattis constraints, where lattice translation symmetry is preserved only on average, while on-site symmetries remain exact. We argue that in the absence of spontaneous symmetry breaking, the system must exhibit critical correlations of local operators in two distinct ways: (i) for some operator $O_e$ charged under exact symmetries, the first absolute moment correlation $\\overline{|\\langle O_e(x)O^{\\dagger}_e(y)\\rangle|}$ decays slowly; and (ii) for some operator $O_a$ charged under average symmetries, the first-moment correlation $\\overline{\\langle O_a(x)O^{\\dagger}_a(y)\\rangle}$ decays slowly. We verify these predictions in a few examples: the random-singlet Heisenberg spin chain in one dimension, and the disordered free-fermion critical states in symmetry class BDI in one and two dimensions. Surprisingly, even for these well-studied systems, our anomaly-based argument reveals critical correlations overlooked in previous literature. We also discuss the experimental feasibility of measuring these critical correlations."}
{"id": "2602.03031", "categories": ["cond-mat.dis-nn", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03031", "abs": "https://arxiv.org/abs/2602.03031", "authors": ["Kimihiro Yamazaki", "Itsushi Sakata", "Takuya Konishi", "Yoshinobu Kawahara"], "title": "Physics-inspired transformer quantum states via latent imaginary-time evolution", "comment": null, "summary": "Neural quantum states (NQS) are powerful ansätze in the variational Monte Carlo framework, yet their architectures are often treated as black boxes. We propose a physically transparent framework in which NQS are treated as neural approximations to latent imaginary-time evolution. This viewpoint suggests that standard Transformer-based NQS (TQS) architectures correspond to physically unmotivated effective Hamiltonians dependent on imaginary time in a latent space. Building on this interpretation, we introduce physics-inspired transformer quantum states (PITQS), which enforce a static effective Hamiltonian by sharing weights across layers and improve propagation accuracy via Trotter-Suzuki decompositions without increasing the number of variational parameters. For the frustrated $J_1$-$J_2$ Heisenberg model, our ansätze achieve accuracies comparable to or exceeding state-of-the-art TQS while using substantially fewer variational parameters. This study demonstrates that reinterpreting the deep network structure as a latent cooling process enables a more physically grounded, systematic, and compact design, thereby bridging the gap between black-box expressivity and physically transparent construction."}
{"id": "2602.03488", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.03488", "abs": "https://arxiv.org/abs/2602.03488", "authors": ["Maria Chiara Angelini", "Saverio Palazzi", "Giorgio Parisi", "Tommaso Rizzo"], "title": "Long-range spin glass in a field at zero temperature", "comment": null, "summary": "We compute the critical exponents of the zero-temperature spin glass transition in a field on a one-dimensional long-range model, a proxy for higher-dimensional systems. Our approach is based on a novel loop expansion within the Bethe $M$-layer formalism, whose adaptation to this specific case is detailed here. The resulting estimates provide crucial benchmarks for numerical simulations that can access larger system sizes in one dimension, thus offering a key test of the theory of spin glasses in a field."}
{"id": "2602.02665", "categories": ["cond-mat.str-el", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02665", "abs": "https://arxiv.org/abs/2602.02665", "authors": ["Luciano Loris Viteritti", "Riccardo Rende", "Subir Sachdev", "Giuseppe Carleo"], "title": "Approaching the Thermodynamic Limit with Neural-Network Quantum States", "comment": "10 pages, 8 figures, 2 tables", "summary": "Accessing the thermodynamic-limit properties of strongly correlated quantum matter requires simulations on very large lattices, a regime that remains challenging for numerical methods, especially in frustrated two-dimensional systems. We introduce the Spatial Attention mechanism, a minimal and physically interpretable inductive bias for Neural-Network Quantum States, implemented as a single learned length scale within the Transformer architecture. This bias stabilizes large-scale optimization and enables access to thermodynamic-limit physics through highly accurate simulations on unprecedented system sizes within the Variational Monte Carlo framework. Applied to the spin-$\\tfrac12$ triangular-lattice Heisenberg antiferromagnet, our approach achieves state-of-the-art results on clusters of up to $42\\times42$ sites. The ability to simulate such large systems allows controlled finite-size scaling of energies and order parameters, enabling the extraction of experimentally relevant quantities such as spin-wave velocities and uniform susceptibilities. In turn, we find extrapolated thermodynamic limit energies systematically better than those obtained with tensor-network approaches such as iPEPS. The resulting magnetization is strongly renormalized, $M_0=0.148(1)$ (about $30\\%$ of the classical value), revealing that less accurate variational states systematically overestimate magnetic order. Analysis of the optimized wave function further suggests an intrinsically non-local sign structure, indicating that the sign problem cannot be removed by local basis transformations. We finally demonstrate the generality of the method by obtaining state-of-the-art energies for a $J_1$-$J_2$ Heisenberg model on a $20\\times20$ square lattice, outperforming Residual Convolutional Neural Networks."}
{"id": "2602.03404", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.03404", "abs": "https://arxiv.org/abs/2602.03404", "authors": ["Arjun Puthli", "Somdatta Goswami", "Souvik Chakraborty"], "title": "Neural Hodge Corrective Solvers: A Hybrid Iterative-Neural Framework", "comment": null, "summary": "We introduce the Neural Hodge Corrective Solver (NHCS), a hybrid iterative-neural framework for partial differential equations that embeds learned corrective operators within the Discrete Exterior Calculus (DEC) formulation. The method combines classical Jacobi-Richardson iterations with data-driven corrections to refine numerical solutions while preserving the underlying topological and metric structure. NHCS employs a two-phase training strategy. In the first phase, DEC operators are learned through relative residual minimization from data. In the second phase, these operators are integrated into the iterative solver, and training targets the improvement of convergence through learned corrective updates that remain effective even for inaccurate intermediate solutions. This staggered training enables stable, progressive refinement while maintaining the structure-preserving properties of DEC discretizations. To improve multiscale adaptivity, NHCS introduces a convolutional neural network-based correction term capable of capturing fine-scale solution features via localized updates informed by global context, improving scalability over mesh component-wise neural approaches. Moreover, the proposed framework substantially reduces computational cost by avoiding Newton-Raphson-based training and the associated Jacobian evaluations of parameterized operators. The resulting solver achieves improved efficiency, robustness, and accuracy without compromising numerical stability."}
{"id": "2602.03656", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-lat"], "pdf": "https://arxiv.org/pdf/2602.03656", "abs": "https://arxiv.org/abs/2602.03656", "authors": ["Fo-Hong Wang", "Fanjie Sun", "Chenghao He", "Xiao Yan Xu"], "title": "Resolving Quantum Criticality in the Honeycomb Hubbard Model", "comment": "12+20 pages, 6+16 figures", "summary": "The interplay between Dirac fermions and electronic correlations on the honeycomb lattice hosts a fundamental quantum phase transition from a semimetal to a Mott insulator, governed by the Gross-Neveu-Heisenberg (GNH) universality class. Despite its importance, consensus on the precise critical exponents remains elusive due to severe finite-size effects in numerical simulations and the lack of conformal bootstrap benchmarks. Here we try to resolve this long-standing controversy by performing projector determinant quantum Monte Carlo (QMC) simulations on lattices of unprecedented size, reaching 10,368 sites. By developing a novel projected submatrix update algorithm, we achieve a significant algorithmic speedup that enables us to access the thermodynamic limit with high precision. We observe that the fermion anomalous dimension and the correlation length exponent converge rapidly, while the boson anomalous dimension exhibits a systematic size dependence that we resolve via linear extrapolation. To validate our analysis, we perform parallel large-scale simulations of the spinless $t$-$V$ model on the honeycomb lattice, which belongs to the Gross-Neveu-Ising class. Our results for the $t$-$V$ model, including the first QMC determination of the fermion anomalous dimension, show agreement with conformal bootstrap predictions, thereby corroborating the robustness of our methodology. Our work provides state-of-the-art critical exponents for the honeycomb Hubbard model and establishes a systematic finite-size scaling workflow applicable to a broad class of strongly correlated quantum systems, paving the way for resolving other challenging fermionic quantum critical phenomena."}
{"id": "2602.02714", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.02714", "abs": "https://arxiv.org/abs/2602.02714", "authors": ["Jake Spisak", "Christopher P. Riedel", "Andrey Sushko", "Michal Adamkiewicz", "Joan Creus-Costa", "John Dean", "Jacob Radford", "F. Martin Ralph", "Larissa Reames", "Anna M. Wilson", "Subin Yoon", "Vijay Tallapragada", "Todd Hutchinson"], "title": "The Design and Performance of Meteorological Sensors for WindBorne Global Sounding Balloons", "comment": "33 pages. 13 figures. Submitted to Journal of Atmospheric and Oceanic Technology", "summary": "WindBorne Systems has developed a constellation of long-duration atmospheric balloons to collect meteorological data across the globe, filling gaps in current in-situ data collection methods. Each Global Sounding Balloon (GSB) is capable of flying for weeks or months and performing dozens of soundings while measuring pressure, temperature, humidity, and GNSS-derived position, altitude, and wind velocity. This data is transmitted to ground via satellite, processed, and made available within minutes of being collected. The current meteorological sensor package has remained largely unchanged since mid-2024 and has flown on thousands of GSBs totaling over one million hours of flight time. Here we present the design and performance of this sensor package. The custom readout architecture and housing allow for data collection across nearly all in-flight conditions while minimizing sources of bias and noise. Uncertainty is characterized via sounding reproducibility studies and in-house calibration of pressure, humidity, and temperature sensors. The calibration and data processing procedures have been optimized and validated by comparison with external datasets. We present external validation in the form of 1) side-by-side radiosonde launches performed in collaboration with the Center for Western Weather and Water Extremes at the Scripps Institution of Oceanography, which show agreement within expected uncertainty limits, and 2) intercomparison studies with European Centre for Medium-Range Weather Forecasts Reanalysis v5, which show an aggregate root mean square difference of: Geopotential height -- 14 m; Pressure -- 0.36 hPa; Temperature -- 0.91 K; Wind speed u -- 2.45 m/s; Wind speed v -- 2.50 m/s; Relative humidity -- 13%."}
{"id": "2602.03244", "categories": ["physics.hist-ph", "physics.chem-ph", "physics.class-ph"], "pdf": "https://arxiv.org/pdf/2602.03244", "abs": "https://arxiv.org/abs/2602.03244", "authors": ["José-María Martín-Olalla"], "title": "A third law of thermodynamics is an unnecessary complexity", "comment": "2 figures, 1 table, 5000 words", "summary": "This paper elaborates on the implications of the relationship between the Second and Third Laws and provides a comprehensive formal and historical justification for the logical redundancy of the Nernst heat theorem. By revisiting the Nernst-Einstein debate, the underlying hypotheses that lead to the traditional view of the Third Law as an independent postulate are examined. It is argued that the historical rejection of Nernst's proof -- motivated by Einstein's insistence on the practical non-performability of cycles at absolute zero -- overlooks the fact that a universal Second Law already precludes such cycles, rendering an independent Third Law an unnecessary complexity. Ultimately, the Nernst theorem is shown to be an essential consistency regulator rather than an independent physical discovery."}
{"id": "2602.02529", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.02529", "abs": "https://arxiv.org/abs/2602.02529", "authors": ["Milan Janosov"], "title": "How Much of the United States Can Still Host New Hyperscale Data Centers? A Constraint-Based Feasibility Analysis", "comment": "15 pages, 5 figures", "summary": "The rapid expansion of hyperscale data centers, primarily driven by cloud computing and generative AI is placing growing pressure on electricity systems, land, and climate-sensitive infrastructure. While existing maps document where data centers are currently located, a major unanswered question remains: where can hyperscale data centers still be built under present-day physical, infrastructural, and environmental constraints?\n  Here we address this question, focusing on the United States, using a national-scale, constraint-first geospatial framework that infers feasibility from revealed hyperscale siting patterns rather than from demand forecasts or optimization assumptions. By combining power-grid adjacency, environmental limits, land-use constraints, and climatic constraints within a uniform hexagonal spatial system, we estimate the feasible hyperscale hosting capacity.\n  Our presented approaches converge on a limited feasible land envelope, implying a substantial contraction relative to naive land-availability assumptions. Based on observed build-out patterns, we estimate that total physically feasible U.S. hyperscale capacity lies in the tens of gigawatts rather than the hundreds. The results of this piece are intended to support national-scale reasoning about infrastructure feasibility under modern constraints."}
{"id": "2602.02814", "categories": ["math.OC", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02814", "abs": "https://arxiv.org/abs/2602.02814", "authors": ["Berk Bozkurt", "Aditya Mahajan", "Ashutosh Nayyar", "Yi Ouyang"], "title": "Sub-optimality bounds for certainty equivalent policies in partially observed systems", "comment": "12 pages, 0 figures", "summary": "In this paper, we present a generalization of the certainty equivalence principle of stochastic control. One interpretation of the classical certainty equivalence principle for linear systems with output feedback and quadratic costs is as follows: the optimal action at each time is obtained by evaluating the optimal state-feedback policy of the stochastic linear system at the minimum mean square error (MMSE) estimate of the state. Motivated by this interpretation, we consider certainty equivalent policies for general (non-linear) partially observed stochastic systems that allow for any state estimate rather than restricting to MMSE estimates. In such settings, the certainty equivalent policy is not optimal. For models where the cost and the dynamics are smooth in an appropriate sense, we derive upper bounds on the sub-optimality of certainty equivalent policies. We present several examples to illustrate the results."}
{"id": "2602.02866", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02866", "abs": "https://arxiv.org/abs/2602.02866", "authors": ["Qinan Zhou", "Jing Sun"], "title": "Estimation of Cell-to-Cell Variation and State of Health for Battery Modules with Parallel-Connected Cells", "comment": null, "summary": "Estimating cell-to-cell variation (CtCV) and state of health (SoH) for battery modules with parallel-connected cells is challenging when only module-level signals are measurable and individual cell behaviors remain unobserved. Although progress has been made in SoH estimation, CtCV estimation remains unresolved in the literature. This paper proposes a unified framework that accurately estimates both CtCV and SoH for modules using only module-level information extracted from incremental capacity analysis (ICA) and differential voltage analysis (DVA). With the proposed framework, CtCV and SoH estimations can be decoupled into two separate tasks, allowing each to be solved with dedicated algorithms without mutual interference and providing greater design flexibility. The framework also exhibits strong versatility in accommodating different CtCV metrics, highlighting its general-purpose nature. Experimental validation on modules with three parallel-connected cells demonstrates that the proposed framework can systematically select optimal module-level features for CtCV and SoH estimations, deliver accurate CtCV and SoH estimates with high confidence and low computational complexity, remain effective across different C-rates, and be suitable for onboard implementation."}
{"id": "2602.02512", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02512", "abs": "https://arxiv.org/abs/2602.02512", "authors": ["Changan Liu", "Haoxin Sun", "Ahad N. Zehmakan", "Zhongzhi Zhang"], "title": "Efficient Edge Rewiring Strategies for Enhancing PageRank Fairness", "comment": "Accepted by Theoretical Computer Science (TCS)", "summary": "We study the notion of unfairness in social networks, where a group such as females in a male-dominated industry are disadvantaged in access to important information, e.g. job posts, due to their less favorable positions in the network. We investigate a well-established network-based formulation of fairness called PageRank fairness, which refers to a fair allocation of the PageRank weights among distinct groups. Our goal is to enhance the PageRank fairness by modifying the underlying network structure. More precisely, we study the problem of maximizing PageRank fairness with respect to a disadvantaged group, when we are permitted to rewire a fixed number of edges in the network. Building on a greedy approach, we leverage techniques from fast sampling of rooted spanning forests to devise an effective linear-time algorithm for this problem. To evaluate the accuracy and performance of our proposed algorithm, we conduct a large set of experiments on various real-world network data. Our experiments demonstrate that the proposed algorithm significantly outperforms the existing ones. Our algorithm is capable of generating accurate solutions for networks of million nodes in just a few minutes."}
{"id": "2602.02681", "categories": ["cond-mat.stat-mech", "nlin.CD", "nlin.CG"], "pdf": "https://arxiv.org/pdf/2602.02681", "abs": "https://arxiv.org/abs/2602.02681", "authors": ["Pavel Orlov", "Enej Ilievski"], "title": "Thermalization in classical systems with discrete phase space", "comment": "6 pages, 3 figures", "summary": "We study the emergence of statistical mechanics in isolated classical systems with local interactions and discrete phase spaces. We establish that thermalization in such systems does not require global ergodicity; instead, it arises from effective local ergodicity, where dynamics in a subsystem may appear pseudorandom. To corroborate that, we analyze the spectrum of the unitary evolution operator and propose an ansatz to describe statistical properties of local observables expanded in the eigenfunction basis - the classical counterpart of the Eigenstate Thermalization Hypothesis. Our framework provides a unified perspective on thermalization in classical and quantum systems with discrete spectra."}
{"id": "2602.02703", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02703", "abs": "https://arxiv.org/abs/2602.02703", "authors": ["Chenxi Li", "Ke Zhu", "Shu Yang", "Xiaofei Wang"], "title": "Selective Information Borrowing for Region-Specific Treatment Effect Inference under Covariate Mismatch in Multi-Regional Clinical Trials", "comment": null, "summary": "Multi-regional clinical trials (MRCTs) are central to global drug development, enabling evaluation of treatment effects across diverse populations. A key challenge is valid and efficient inference for a region-specific estimand when the target region is small and differs from auxiliary regions in baseline covariates or unmeasured factors. We adopt an estimand-based framework and focus on the region-specific average treatment effect (RSATE) in a prespecified target region, which is directly relevant to local regulatory decision-making. Cross-region differences can induce covariate shift, covariate mismatch, and outcome drift, potentially biasing information borrowing and invalidating RSATE inference. To address these issues, we develop a unified causal inference framework with selective information borrowing. First, we introduce an inverse-variance weighting estimator that combines a \"small-sample, rich-covariate\" target-only estimator with a \"large-sample, limited-covariate\" full-borrowing doubly robust estimator, maximizing efficiency under no outcome drift. Second, to accommodate outcome drift, we apply conformal prediction to assess patient-level comparability and adaptively select auxiliary-region patients for borrowing. Third, to ensure rigorous finite-sample inference, we employ a conditional randomization test with exact, model-free, selection-aware type I error control. Simulation studies show the proposed estimator improves efficiency, yielding 10-50% reductions in mean squared error and higher power relative to no-borrowing and full-borrowing approaches, while maintaining valid inference across diverse scenarios. An application to the POWER trial further demonstrates improved precision for RSATE estimation."}
{"id": "2602.02866", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02866", "abs": "https://arxiv.org/abs/2602.02866", "authors": ["Qinan Zhou", "Jing Sun"], "title": "Estimation of Cell-to-Cell Variation and State of Health for Battery Modules with Parallel-Connected Cells", "comment": null, "summary": "Estimating cell-to-cell variation (CtCV) and state of health (SoH) for battery modules with parallel-connected cells is challenging when only module-level signals are measurable and individual cell behaviors remain unobserved. Although progress has been made in SoH estimation, CtCV estimation remains unresolved in the literature. This paper proposes a unified framework that accurately estimates both CtCV and SoH for modules using only module-level information extracted from incremental capacity analysis (ICA) and differential voltage analysis (DVA). With the proposed framework, CtCV and SoH estimations can be decoupled into two separate tasks, allowing each to be solved with dedicated algorithms without mutual interference and providing greater design flexibility. The framework also exhibits strong versatility in accommodating different CtCV metrics, highlighting its general-purpose nature. Experimental validation on modules with three parallel-connected cells demonstrates that the proposed framework can systematically select optimal module-level features for CtCV and SoH estimations, deliver accurate CtCV and SoH estimates with high confidence and low computational complexity, remain effective across different C-rates, and be suitable for onboard implementation."}
{"id": "2602.02681", "categories": ["cond-mat.stat-mech", "nlin.CD", "nlin.CG"], "pdf": "https://arxiv.org/pdf/2602.02681", "abs": "https://arxiv.org/abs/2602.02681", "authors": ["Pavel Orlov", "Enej Ilievski"], "title": "Thermalization in classical systems with discrete phase space", "comment": "6 pages, 3 figures", "summary": "We study the emergence of statistical mechanics in isolated classical systems with local interactions and discrete phase spaces. We establish that thermalization in such systems does not require global ergodicity; instead, it arises from effective local ergodicity, where dynamics in a subsystem may appear pseudorandom. To corroborate that, we analyze the spectrum of the unitary evolution operator and propose an ansatz to describe statistical properties of local observables expanded in the eigenfunction basis - the classical counterpart of the Eigenstate Thermalization Hypothesis. Our framework provides a unified perspective on thermalization in classical and quantum systems with discrete spectra."}
{"id": "2602.02617", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02617", "abs": "https://arxiv.org/abs/2602.02617", "authors": ["Moncy Vilavinal John"], "title": "On the reality of quantum states: A pedagogic survey from classical to quantum mechanics", "comment": "36 pages, No figures", "summary": "Some recent experiments claim to show that any model in which a quantum state represents mere information about an underlying physical reality of the system must make predictions which contradict those of quantum theory. The present work undertakes to investigate the issue of reality, treading a more fundamental route from the Hamilton-Jacobi equation of classical mechanics to the Schrodinger equation of quantum mechanics. Motivation for this is a similar approach from the eikonal equation in geometrical optics to the wave equation in electromagnetic theory. We rewrite the classical Hamilton-Jacobi equation as a wave equation and seek to generalise de Broglie's wave particle duality by demanding that both particle and light waves have the freedom of being described by any square-integrable function. This generalisation, which allows superposition also for matter wave functions, helps us to obtain the Schrodinger equation, whose solution can be seen to be as much objective as the classical mechanics wave function. Several other equations which one writes in quantum mechanics, including the eigenvalue equations for observables, series expansion of energy states in terms of eigenstates of observables other than energy, etc., can be written in the classical case too. Absence of any collapse of the wave function, entanglement, etc. in the classical realm have their origin in the nonlinearity of the classical wave equation. These considerations indicate that many of the puzzles in quantum mechanics are present also in classical mechanics in a dormant form, which fact shall help to demystify quantum mechanics to a great extent."}
{"id": "2602.02993", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.02993", "abs": "https://arxiv.org/abs/2602.02993", "authors": ["Zhen Zhang", "Xuebin Zhao", "Andrew Curtis"], "title": "Variational and Monte Carlo Methods for Bayesian Inversion of Dynamic Subsurface Flow Simulations Using Seismic and Fluid Pressure Data", "comment": null, "summary": "In order to predict future performance of subsurface fluid reservoirs under possible operating scenarios, a dynamic, porous-medium flow simulation model must be tuned to include representative properties of the reservoir. Estimating subsurface reservoir properties given remotely sensed or borehole-based observations typically involves finding the solution to a challenging inverse problem. We compare Monte Carlo random sampling to variational inference methods which use optimisation to constrain parametrised uncertainties in nonlinear Bayesian inversions. We use them to estimate the posterior probability distribution of reservoir permeability given fluid pressure and seismic measurements. The methods include automatic differentiation variational inference (ADVI), Stein variational gradient descent (SVGD), and a Monte Carlo method called stochastic SVGD (sSVGD), all of which we benchmark against results from Metropolis-Hastings McMC. We also test an ADVI variant called physically structured variational inference (PSVI): in our implementation this method estimates only spatially-local correlations between model parameters based on the intuition that such correlations are strong in remote sensing problems in which data only inform about spatial-averages of local dynamics. We apply the methods to two- and three-dimensional inverse problems of carbon dioxide storage, inspired by the Endurance field, located in the UK North Sea. Results show that PSVI achieves a good balance between mean-field ADVI and full-rank ADVI in terms of accuracy of the posterior approximation and computational efficiency. SVGD and sSVGD offer more accurate approximations of the target posterior distribution, but at far higher computational cost. Between them, sSVGD outperforms SVGD, exhibiting better computational efficiency and mitigating the problems of mode collapse and spurious correlations."}
{"id": "2602.02811", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.02811", "abs": "https://arxiv.org/abs/2602.02811", "authors": ["Vikram Krishnamurthy", "Luke Snow"], "title": "Efficient Counterfactual Estimation of Conditional Greeks via Malliavin-based Weak Derivatives", "comment": null, "summary": "We study counterfactual gradient estimation of conditional loss functionals of diffusion processes. In quantitative finance, these gradients are known as conditional Greeks: the sensitivity of expected market values, conditioned on some event of interest. The difficulty is that when the conditioning event has vanishing or zero probability, naive Monte Carlo estimators are prohibitively inefficient; kernel smoothing, though common, suffers from slow convergence. We propose a two-stage kernel-free methodology. First, we show using Malliavin calculus that the conditional loss functional of a diffusion process admits an exact representation as a Skorohod integral, yielding classical Monte-Carlo estimator variance and convergence rates. Second, we establish that a weak derivative estimate of the conditional loss functional with respect to model parameters can be evaluated algorithmically with constant variance, in contrast to the widely used score function method whose variance grows linearly in the sample path length. Together, these results yield an efficient framework for counterfactual conditional stochastic gradient algorithms and financial Greek computations in rare-event regimes."}
{"id": "2602.02549", "categories": ["math.NA", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.02549", "abs": "https://arxiv.org/abs/2602.02549", "authors": ["Yuki Uchino", "Katsuhisa Ozaki", "Toshiyuki Imamura"], "title": "Error Analysis of Matrix Multiplication Emulation Using Ozaki-II Scheme", "comment": "18 pages, 4 figures", "summary": "The Ozaki-II scheme is an emulation method that leverages the Chinese Remainder Theorem to compute high-precision matrix multiplication via a sequence of low-precision matrix multiplications. In this scheme, the attainable numerical accuracy improves as the number of low-precision matrix multiplications increases. Previous numerical studies have shown that single- and double-precision matrix multiplication using the Ozaki-II scheme achieves higher throughput than that of standard BLAS routines on modern AI hardware equipped with fast INT8 matrix multiply-accumulate units with INT8 inputs and INT32 accumulation. However, the accuracy of the Ozaki-II scheme can degrade when the exponent distribution of the input matrices is wide, in which case a large number of low-precision matrix multiplications is required to obtain high-precision results. In this paper, we present a rigorous deterministic error analysis of the Ozaki-II scheme. The proposed analysis not only clarifies the accuracy behavior of the method but also enables the estimation of the number of low-precision matrix multiplications required to achieve a desired level of numerical accuracy."}
{"id": "2602.03776", "categories": ["q-fin.CP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03776", "abs": "https://arxiv.org/abs/2602.03776", "authors": ["Zhuohan Wang", "Carmine Ventre"], "title": "DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books", "comment": "12 pages, 8 figures", "summary": "Modern generative models for limit order books (LOBs) can reproduce realistic market dynamics, but remain fundamentally passive: they either model what typically happens without accounting for hypothetical future market conditions, or they require interaction with another agent to explore alternative outcomes. This limits their usefulness for stress testing, scenario analysis, and decision-making. We propose \\textbf{DiffLOB}, a regime-conditioned \\textbf{Diff}usion model for controllable and counterfactual generation of \\textbf{LOB} trajectories. DiffLOB explicitly conditions the generative process on future market regimes--including trend, volatility, liquidity, and order-flow imbalance, which enables the model to answer counterfactual queries of the form: ``If the future market regime were X instead of Y, how would the limit order book evolve?'' Our systematic evaluation framework for counterfactual LOB generation consists of three criteria: (1) \\textit{Controllable Realism}, measuring how well generated trajectories can reproduce marginal distributions, temporal dependence structure and regime variables; (2) \\textit{Counterfactual validity}, testing whether interventions on future regimes induce consistent changes in the generated LOB dynamics; (3) \\textit{Counterfactual usefulness}, assessing whether synthetic counterfactual trajectories improve downstream prediction of future market regimes."}
{"id": "2602.02800", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.02800", "abs": "https://arxiv.org/abs/2602.02800", "authors": ["Suhan Liu", "Mo Liu"], "title": "Decision-Focused Optimal Transport", "comment": null, "summary": "We propose a fundamental metric for measuring the distance between two distributions. This metric, referred to as the decision-focused (DF) divergence, is tailored to stochastic linear optimization problems in which the objective coefficients are random and may follow two distinct distributions. Traditional metrics such as KL divergence and Wasserstein distance are not well-suited for quantifying the resulting cost discrepancy, because changes in the coefficient distribution do not necessarily change the optimizer of the underlying linear program. Instead, the impact on the objective value depends on how the two distributions are coupled (aligned). Motivated by optimal transport, we introduce decision-focused distances under several settings, including the optimistic DF distance, the robust DF distance, and their entropy-regularized variants. We establish connections between the proposed DF distance and classical distributional metrics. For the calculation of the DF distance, we develop efficient computational methods. We further derive sample complexity guarantees for estimating these distances and show that the DF distance estimation avoids the curse of dimensionality that arises in Wasserstein distance estimation. The proposed DF distance provides a foundation for a broad range of applications. As an illustrative example, we study the interpolation between two distributions. Numerical studies, including a toy newsvendor problem and a real-world medical testing dataset, demonstrate the practical value of the proposed DF distance."}
{"id": "2602.02649", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02649", "abs": "https://arxiv.org/abs/2602.02649", "authors": ["Iao-Fai Io", "Fu-Hsiang Huang", "Chang-Tse Hsieh"], "title": "Non-Hermitian free-fermion critical systems and logarithmic conformal field theory", "comment": "6+12 pages, 1 figure, 1 table", "summary": "Conformal invariance often accompanies criticality in Hermitian systems. However, its fate in non-Hermitian settings is less clear, especially near exceptional points where the Hamiltonian becomes non-diagonalizable. Here we investigate whether a 1+1-dimensional gapless non-Hermitian system can admit a conformal description, focusing on a PT-symmetric free-fermion field theory. Working in the biorthogonal formalism, we identify the conformal structure of this theory by constructing a traceless energy-momentum tensor whose Fourier modes generate a Virasoro algebra with central charge $c=-2$. This yields a non-Hermitian, biorthogonal realization of a logarithmic conformal field theory, in which correlation functions exhibit logarithmic scaling and the spectrum forms Virasoro staggered modules that are characterized by universal indecomposability parameters. We further present a microscopic construction and show how the same conformal data (with finite-size corrections) can be extracted from the lattice model at exceptional-point criticality, thereby supporting the field-theory prediction."}
{"id": "2602.03745", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.03745", "abs": "https://arxiv.org/abs/2602.03745", "authors": ["Michael Poluektov"], "title": "Transformation front kinetics in deformable ferromagnets", "comment": null, "summary": "Materials such as magnetic shape-memory alloys possess an intrinsic coupling between material's magnetisation and mechanical deformation. These materials also undergo structural phase transitions, with phase boundaries separating different phases and the kinetics of the phase boundaries governed by the magnetic field and the mechanical stresses. There is a multiplicity of other materials revealing similar phenomena, e.g. magnetic perovskites. To model the propagation of the phase boundaries in deformable magnetic materials at the continuum scale, three ingredients are required: a set of governing equations for the bulk behaviour with coupled magnetic and mechanical degrees of freedom, a dependency of the phase boundary velocity on the governing factors, and a reliable computational method. The expression for the phase boundary velocity is usually obtained within the continuum thermodynamics setting, where the entropy production due to phase boundary propagation is derived, which gives a thermodynamic driving force for the phase boundary kinetics. For deformable ferromagnets, all three elements (bulk behaviour, interface kinetics, and computational approaches) have been explored, but under a number of limitations. The present paper focuses on the derivation of the thermodynamic driving force for transformation fronts in a general magneto-mechanical setting, adapts the cut-finite-element method for transformation fronts in magneto-mechanics, which allows for an exceptionally efficient handling of the propagating interfaces, without modifying the finite-element mesh, and applies the developments to qualitative modelling of magneto-mechanics of magnetic shape-memory alloys."}
{"id": "2602.03347", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.03347", "abs": "https://arxiv.org/abs/2602.03347", "authors": ["Caroline Sandford", "Nick Rayner"], "title": "Addressing the World War 2 Warm Anomaly in HadSST.4.2.0.0", "comment": "23 pages, 17 figures, 2 tables", "summary": "We present an update to the Hadley Centre Sea-Surface Temperature dataset (HadSST.4.2.0.0) that addresses residual warm bias during the Second World War (WW2). Using an existing quantitative definition of the WW2 warm anomaly we identify Engine Room Intake (ERI) bias corrections as the dominant factor in this warm bias in HadSST4, and use this to propose new constraints on ERI bias estimates prior to 1950. In addition, we implement corrections for truncation bias in observations from the Japanese Kobe Collection, spanning the period from 1933 to 1961. We evaluate the effects of these changes with respect to the previous version of HadSST and compare with the most recent iterations of other SST datasets including ERSSTv6, COBE-SST3 and DCENT. We show that it is possible to remove the WW2 warm anomaly using a physically-based approach that maintains the independence of HadSST from land surface temperature records, and preserves structural diversity within the range of available global SST datasets."}
{"id": "2602.02540", "categories": ["physics.soc-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.02540", "abs": "https://arxiv.org/abs/2602.02540", "authors": ["Aditya Patel", "Naveen Sudharsan", "Trevor Brooks", "Harsh Kamath", "Dru Crawley", "Zack Baumer", "Marc Coudert", "Dev Niyogi"], "title": "Thermal Comfort Path Planning Tool for Urban Mobility in Austin, Texas", "comment": "11 pages, 2 figures", "summary": "Extreme heat poses a growing challenge for active transportation in cities like Austin, Texas, where conventional weather reporting (e.g. a single air temperature measurement for the whole city) fails to capture the large microclimate variations that pedestrians and cyclists actually experience. We present a novel walking and biking route planner that selects paths based on thermal comfort using the Universal Thermal Climate Index (UTCI) (Jendritzky et al., 2012) rather than just distance or travel time. This system combines high-resolution thermal modeling with real-time route mapping. We generate city-scale UTCI maps using SOLWEIG-GPU (Solar and LongWave Environmental Irradiance Geometry), to account for urban features (buildings, trees, etc.) and weather conditions (Lindberg et al., 2008; Kamath et al., 2026). For any given origin and destination, our tool calculates the average UTCI along each possible route and recommends the 'coolest' route, i.e. the path with the lowest heat stress (often the most shaded or otherwise thermally comfortable), while still being reasonably direct. In a case study for Austin, this approach identifies routes that significantly reduce pedestrians' heat exposure (often recommending routes with a much larger proportion of shade). Such thermally-informed route planning has important public health implications: by helping people avoid dangerous heat hotspots and sun-exposed areas, it can reduce the risk of heat-related illness and make walking or biking a safer choice even on hot days. This paper describes the motivation, methodology, results, and implications of the thermal comfort path planner, emphasizing the role of shade and thermal comfort in urban mobility and heat mitigation."}
{"id": "2602.02826", "categories": ["math.OC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02826", "abs": "https://arxiv.org/abs/2602.02826", "authors": ["Louis Callens", "Bastiaan Vandewal", "Ibrahim Ibrahim", "Jan Swevers", "Wilm Decré"], "title": "Fast Near Time-Optimal Motion Planning for Holonomic Vehicles in Structured Environments", "comment": null, "summary": "This paper proposes a novel and efficient optimization-based method for generating near time-optimal trajectories for holonomic vehicles navigating through complex but structured environments. The approach aims to solve the problem of motion planning for planar motion systems using magnetic levitation that can be used in assembly lines, automated laboratories or clean-rooms. In these applications, time-optimal trajectories that can be computed in real-time are required to increase productivity and allow the vehicles to be reactive if needed. The presented approach encodes the environment representation using free-space corridors and represents the motion of the vehicle through such a corridor using a motion primitive. These primitives are selected heuristically and define the trajectory with a limited number of degrees of freedom, which are determined in an optimization problem. As a result, the method achieves significantly lower computation times compared to the state-of-the-art, most notably solving a full Optimal Control Problem (OCP), OMG-tools or VP-STO without significantly compromising optimality within a fixed corridor sequence. The approach is benchmarked extensively in simulation and is validated on a real-world Beckhoff XPlanar system"}
{"id": "2602.02942", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02942", "abs": "https://arxiv.org/abs/2602.02942", "authors": ["David William Marques Guerra", "Taufik Abrao"], "title": "Hybrid-Field Channel Estimation for XL-MIMO Systems: Dictionary-based Sparse Signal Recovery", "comment": "5 pages, 2 figures, letter paper", "summary": "Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are a key technology for future wireless networks, but the large array aperture naturally creates a hybrid-field (HF) propagation regime in which far-field (FF) planar-wave and near-field (NF) spherical-wave components coexist. This work considers the problem of HF channel estimation (CE) and introduces a unified model that superimposes FF and NF contributions according to the Rayleigh distance boundary. By exploiting the inherent sparsity of the channel in the angular and polar domains, we formulate the estimation task as a sparse recovery problem. Unlike conventional approaches that require prior knowledge of the channel sparsity level, the proposed method operates without requiring knowledge of the sparsity level L and the NF/FF ratio γ, which are used only for synthetic channel generation in simulations. The channel estimator determines the number of paths adaptively through a residual-based stopping rule. A combined FF/NF dictionary is employed to initialize the support, and each selected atom undergoes continuous parameter refinement to mitigate grid mismatch. Simulation results demonstrate that the proposed estimator achieves accurate HF channel reconstruction under both line-of-sight (LoS) and non-line-of-sight (NLoS) conditions, offering a practical and computationally efficient solution for XL-MIMO systems.\n  Extremely Large-Scale MIMO (XL-MIMO); Channel State Information (CSI); Channel estimation (CE); hybrid-field (HF) wave propagation; near-field (NF) spherical wave model; far-field (FF) planar wave model"}
{"id": "2602.02524", "categories": ["cs.SI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02524", "abs": "https://arxiv.org/abs/2602.02524", "authors": ["Olha Wloch", "Liam Hebert", "Robin Cohen", "Lukasz Golab"], "title": "GASTON: Graph-Aware Social Transformer for Online Networks", "comment": "Submitted to ICWSM", "summary": "Online communities have become essential places for socialization and support, yet they also possess toxicity, echo chambers, and misinformation. Detecting this harmful content is difficult because the meaning of an online interaction stems from both what is written (textual content) and where it is posted (social norms). We propose GASTON (Graph-Aware Social Transformer for Online Networks), which learns text and user embeddings that are grounded in their local norms, providing the necessary context for downstream tasks. The heart of our solution is a contrastive initialization strategy that pretrains community embeddings based on user membership patterns, capturing a community's user base before processing any text. This allows GASTON to distinguish between communities (e.g., a support group vs. a hate group) based on who interacts there, even if they share similar vocabulary. Experiments on tasks such as stress detection, toxicity scoring, and norm violation demonstrate that the embeddings produced by GASTON outperform state-of-the-art baselines."}
{"id": "2602.02904", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02904", "abs": "https://arxiv.org/abs/2602.02904", "authors": ["Tymoteusz Braciszewski", "Oliwier Urbański", "Piotr Tomczak"], "title": "Quantum phase transition in transverse-field Ising model on Sierpiński gasket lattice", "comment": null, "summary": "We study quantum phase transition in the transverse-field Ising model on the Sierpiński gasket. By applying finite-size scaling and numerical renormalization group methods, we determine the critical coupling and the exponents that describe this transition. We first checked our finite-size scaling and the renormalization methods on the exactly solvable one-dimensional chain, where we recovered proper values of critical couplings and exponents. Then, we applied the method to the Sierpiński gasket with 11 and 15 spins. We found a quantum critical point at $λ_c \\approx 2.72$ to $2.93$, with critical exponents $z\\approx0.84$, $ν\\approx 1.12 $, $β\\approx 0.30$, and $γ\\approx 2.54$. The lower dynamical exponent $z$ indicates that quantum fluctuations slow down due to fractal geometry, yielding an effective critical dimension of about 2.43. The numerical renormalization group method yielded similar results $λ_c = 2.765$, $β= 0.306$, supporting our findings. These exponents differ from those in both the one-dimensional and mean-field cases."}
{"id": "2602.02753", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.02753", "abs": "https://arxiv.org/abs/2602.02753", "authors": ["Youngjin Cho", "Meimei Liu"], "title": "Effect-Wise Inference for Smoothing Spline ANOVA on Tensor-Product Sobolev Space", "comment": null, "summary": "Functional ANOVA provides a nonparametric modeling framework for multivariate covariates, enabling flexible estimation and interpretation of effect functions such as main effects and interaction effects. However, effect-wise inference in such models remains challenging. Existing methods focus primarily on inference for entire functions rather than individual effects. Methods addressing effect-wise inference face substantial limitations: the inability to accommodate interactions, a lack of rigorous theoretical foundations, or restriction to pointwise inference. To address these limitations, we develop a unified framework for effect-wise inference in smoothing spline ANOVA on a subspace of tensor product Sobolev space. For each effect function, we establish rates of convergence, pointwise confidence intervals, and a Wald-type test for whether the effect is zero, with power achieving the minimax distinguishable rate up to a logarithmic factor. Main effects achieve the optimal univariate rates, and interactions achieve optimal rates up to logarithmic factors. The theoretical foundation relies on an orthogonality decomposition of effect subspaces, which enables the extension of the functional Bahadur representation framework to effect-wise inference in smoothing spline ANOVA with interactions. Simulation studies and real-data application to the Colorado temperature dataset demonstrate superior performance compared to existing methods."}
{"id": "2602.02942", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02942", "abs": "https://arxiv.org/abs/2602.02942", "authors": ["David William Marques Guerra", "Taufik Abrao"], "title": "Hybrid-Field Channel Estimation for XL-MIMO Systems: Dictionary-based Sparse Signal Recovery", "comment": "5 pages, 2 figures, letter paper", "summary": "Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are a key technology for future wireless networks, but the large array aperture naturally creates a hybrid-field (HF) propagation regime in which far-field (FF) planar-wave and near-field (NF) spherical-wave components coexist. This work considers the problem of HF channel estimation (CE) and introduces a unified model that superimposes FF and NF contributions according to the Rayleigh distance boundary. By exploiting the inherent sparsity of the channel in the angular and polar domains, we formulate the estimation task as a sparse recovery problem. Unlike conventional approaches that require prior knowledge of the channel sparsity level, the proposed method operates without requiring knowledge of the sparsity level L and the NF/FF ratio γ, which are used only for synthetic channel generation in simulations. The channel estimator determines the number of paths adaptively through a residual-based stopping rule. A combined FF/NF dictionary is employed to initialize the support, and each selected atom undergoes continuous parameter refinement to mitigate grid mismatch. Simulation results demonstrate that the proposed estimator achieves accurate HF channel reconstruction under both line-of-sight (LoS) and non-line-of-sight (NLoS) conditions, offering a practical and computationally efficient solution for XL-MIMO systems.\n  Extremely Large-Scale MIMO (XL-MIMO); Channel State Information (CSI); Channel estimation (CE); hybrid-field (HF) wave propagation; near-field (NF) spherical wave model; far-field (FF) planar wave model"}
{"id": "2602.02653", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02653", "abs": "https://arxiv.org/abs/2602.02653", "authors": ["Yuzhou Chai", "Dahlia Ghoshal", "Nayana P. Tiwari", "Alexander Kolar", "Benjamin Pingault", "Hannes Bernien", "Tian Zhong"], "title": "Direct telecom network between atomic and solid-state quantum nodes", "comment": null, "summary": "Future quantum networks will interconnect quantum systems with distinct functionalities, ideally over long distances via low-loss telecom optical fibers. Here, we realize a two-node hybrid network that directly connects an atomic single photon source to a solid-state quantum memory in the telecom C-band without the need of frequency conversion and external filtering. Both nodes exhibit state-of-the-art performance at 1530 nm: the source achieves a heralded auto-$g^{(2)}(0)$ = 0.031 at a photon rate of 46 kcps, and the memory a storage efficiency of 10.6% with high multimode capacity. We leverage the intrinsic tunability of both nodes to optimize spectral matching, enabling direct networking between the two: single-photon storage and retrieval for 1 $μ$s over up to 37 temporal modes across extended fibers of 10.6 km (metropolitan) and 49.2 km (laboratory) while preserving non-classicality. These results define a high-bandwidth source-memory link that operates natively in the telecom band, introducing a new paradigm for the design and scaling of hybrid quantum networks."}
{"id": "2602.03360", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.03360", "abs": "https://arxiv.org/abs/2602.03360", "authors": ["Alvaro Vergara", "Sergio Palma", "Raul Fuentes"], "title": "Scaling laws for rockfall impact fragmentation emerging from diverse lithologies", "comment": "16 pages", "summary": "Impact-induced fragmentation is a fundamental dissipative process in geosciences, yet its stochastic nature makes predicting debris evolution a persistent challenge. Here, we introduce a discrete element framework to resolve fragmentation mechanics across a diverse lithological spectrum, from high-strength siliciclastic units to massive carbonates, validated against high-resolution field data from documented rockfall events. Our results reveal that, despite the inherent randomness of impact dynamics, fragment size distributions consistently follow a universal Weibull scaling law, independent of lithology or initial kinetic energy. By applying a relative breakage index, we demonstrate a remarkable collapse of fragmentation data onto a single statistical signature, bridging the gap between grain-scale fracture and macroscopic debris evolution. We find that this Weibullian signature acts as a proxy for lithological sensitivity, reflecting distinct efficiencies in converting kinetic energy into new fracture surfaces. This framework explicitly resolves the energy partitioning between surviving blocks and comminuted debris, providing a robust predictive link between impact mechanics and structural resilience. From an engineering perspective, our findings enable a shift from idealised single-block impact assumptions toward a realistic assessment of distributed energy in fragmented particle clouds, offering a physical basis for optimising protective galleries and hazard mitigation strategies in complex mountainous terrains."}
{"id": "2602.03092", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.03092", "abs": "https://arxiv.org/abs/2602.03092", "authors": ["Vahidullah Tac", "Christopher Gardner", "Ellen Kuhl"], "title": "Generative Artificial Intelligence creates delicious, sustainable, and nutritious burgers", "comment": "13 pages, 4 figures", "summary": "Food choices shape both human and planetary health; yet, designing foods that are delicious, nutritious, and sustainable remains challenging. Here we show that generative artificial intelligence can learn the structure of the human palate directly from large-scale, human-generated recipe data to create novel foods within a structured design space. Using burgers as a model system, the generative AI rediscovers the classic Big Mac without explicit supervision and generates novel burgers optimized for deliciousness, sustainability, or nutrition. Compared to the Big Mac, its delicious burgers score the same or better in overall liking, flavor, and texture in a blinded sensory evaluation conducted in a restaurant setting with 101 participants; its mushroom burger achieves an environmental impact score more than an order of magnitude lower; and its bean burger attains nearly twice the nutritional score. Together, these results establish generative AI as a quantitative framework for learning human taste and navigating complex trade-offs in principled food design."}
{"id": "2602.02616", "categories": ["math.NA", "physics.flu-dyn", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2602.02616", "abs": "https://arxiv.org/abs/2602.02616", "authors": ["Élise Foulatier", "Pierre-Alain Boucard", "François Louf", "David Néron", "Philipp Junker"], "title": "A space-time LATIN-PGD strategy for solving Newtonian compressible flows", "comment": null, "summary": "Simulating flow problems is at the core of many engineering applications but often requires high computational effort, especially when dealing with complex models. This work presents a novel approach for resolving flow problems using the LATIN-PGD solver. In this contribution, we place ourselves within the framework of Newtonian compressible and laminar flows. This specific and relatively simple case enables focusing on flows for which a state equation provides a direct relation between pressure and density. It is then possible to use the LATIN solver to set up a pressure-velocity decoupling algorithm. Moreover, Proper Generalised Decomposition (PGD) is natively included in the solver and yields two independent space-time decompositions for the velocity and the pressure fields. As a first step, the solver is validated on a problem for which an analytical solution is available. It is then applied to slightly more complex problems. The results show good agreement with the literature, and we expect that the solver could be used to compute more complicated material laws in the future."}
{"id": "2602.03202", "categories": ["math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.03202", "abs": "https://arxiv.org/abs/2602.03202", "authors": ["Joonhyuk Jung", "Chao Gao"], "title": "Sharp Inequalities between Total Variation and Hellinger Distances for Gaussian Mixtures", "comment": "34 pages", "summary": "We study the relation between the total variation (TV) and Hellinger distances between two Gaussian location mixtures. Our first result establishes a general upper bound: for any two mixing distributions supported on a compact set, the Hellinger distance between the two mixtures is controlled by the TV distance raised to a power $1-o(1)$, where the $o(1)$ term is of order $1/\\log\\log(1/\\mathrm{TV})$. We also construct two sequences of mixing distributions that demonstrate the sharpness of this bound. Taken together, our results resolve an open problem raised in Jia et al. (2023) and thus lead to an entropic characterization of learning Gaussian mixtures in total variation. Our inequality also yields optimal robust estimation of Gaussian mixtures in Hellinger distance, which has a direct implication for bounding the minimax regret of empirical Bayes under Huber contamination."}
{"id": "2602.02665", "categories": ["cond-mat.str-el", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02665", "abs": "https://arxiv.org/abs/2602.02665", "authors": ["Luciano Loris Viteritti", "Riccardo Rende", "Subir Sachdev", "Giuseppe Carleo"], "title": "Approaching the Thermodynamic Limit with Neural-Network Quantum States", "comment": "10 pages, 8 figures, 2 tables", "summary": "Accessing the thermodynamic-limit properties of strongly correlated quantum matter requires simulations on very large lattices, a regime that remains challenging for numerical methods, especially in frustrated two-dimensional systems. We introduce the Spatial Attention mechanism, a minimal and physically interpretable inductive bias for Neural-Network Quantum States, implemented as a single learned length scale within the Transformer architecture. This bias stabilizes large-scale optimization and enables access to thermodynamic-limit physics through highly accurate simulations on unprecedented system sizes within the Variational Monte Carlo framework. Applied to the spin-$\\tfrac12$ triangular-lattice Heisenberg antiferromagnet, our approach achieves state-of-the-art results on clusters of up to $42\\times42$ sites. The ability to simulate such large systems allows controlled finite-size scaling of energies and order parameters, enabling the extraction of experimentally relevant quantities such as spin-wave velocities and uniform susceptibilities. In turn, we find extrapolated thermodynamic limit energies systematically better than those obtained with tensor-network approaches such as iPEPS. The resulting magnetization is strongly renormalized, $M_0=0.148(1)$ (about $30\\%$ of the classical value), revealing that less accurate variational states systematically overestimate magnetic order. Analysis of the optimized wave function further suggests an intrinsically non-local sign structure, indicating that the sign problem cannot be removed by local basis transformations. We finally demonstrate the generality of the method by obtaining state-of-the-art energies for a $J_1$-$J_2$ Heisenberg model on a $20\\times20$ square lattice, outperforming Residual Convolutional Neural Networks."}
{"id": "2602.03178", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.03178", "abs": "https://arxiv.org/abs/2602.03178", "authors": ["Davit Aslanyan", "Constantine Sideris"], "title": "Fully Automated Adaptive Parameter Selection for 3-D High-order Nyström Boundary Integral Equation Methods", "comment": null, "summary": "We present an adaptive Chebyshev-based Boundary Integral Equation (CBIE) solver for electromagnetic scattering from smooth perfect electric conductor (PEC) objects. The proposed approach eliminates manual parameter tuning by introducing (i) a unified adaptive quadrature strategy for automatic selection of the near-singular interaction distance and (ii) an adaptive computation of all self- and near-singular precomputation integrals to a prescribed accuracy using Gauss-Kronrod (h-adaptive) or Clenshaw-Curtis (p-adaptive) rules and singularity-resolving changes of variables. Both h-adaptive and p-adaptive schemes are explored within this framework, ensuring high-order accuracy and robustness across a broad range of geometries without loss of efficiency. Numerical results for canonical and complex CAD geometries demonstrate that the adaptive solver achieves accuracy and convergence rates comparable to optimally tuned fixed-grid CBIE implementations, while offering automation and scalability to electrically large, geometrically complex problems."}
{"id": "2602.02541", "categories": ["physics.soc-ph", "math.RA"], "pdf": "https://arxiv.org/pdf/2602.02541", "abs": "https://arxiv.org/abs/2602.02541", "authors": ["Chandrasekhar Gokavarapu"], "title": "The Spectral Topology of Global Imbalances:A Graph-Theoretic Framework for Systemic Risk in the Balance of Payments", "comment": null, "summary": "Traditional balance-of-payments (BoP) analysis treats national external positions as largely idiosyncratic time series. This misses an essential structural fact: global imbalances are jointly realized on a directed, weighted network of cross-border current-account and financial claims. We propose a network-theoretic paradigm in which the world economy is a directed graph whose edge weights encode net bilateral exposures. In this setting, systemic fragility is an emergent property of the spectral topology of the global exposure matrix. We develop (i) a mathematically explicit construction of a BoP adjacency operator, (ii) a \\textbf{Spectral Stability Criterion} proving that the system is globally asymptotically stable if and only if the spectral radius $ρ(A) < 1$, and (iii) a \\textbf{Spectral Stability Margin} ($δ= 1 - ρ(B)$) that quantifies the proximity of the global economy to a ``Critical Slowing Down'' phase transition. Furthermore, we define a systemic-risk index using eigenvector centrality to identify nodes whose failure is mathematically indistinguishable from global collapse. Finally, we employ a \\textbf{Non-backtracking (Hashimoto) operator} to derive a precise \\textbf{topological threshold} for sovereign debt contagion, filtering bilateral ``noise'' to isolate deep-network circulation. Our results demonstrate that systemic risk is a latent property of the global spectral topology, requiring macroprudential interventions targeted at the network's spectral gaps rather than individual debt-to-GDP ratios."}
{"id": "2602.02981", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.02981", "abs": "https://arxiv.org/abs/2602.02981", "authors": ["Harbir Antil", "Animesh Jain", "Rainald Löhner"], "title": "Fisher-Information-Based Sensor Placement for Structural Digital Twins: Analytic Results and Benchmarks", "comment": null, "summary": "High-fidelity digital twins rely on the accurate assimilation of sensor data into physics-based computational models. In structural applications, such twins aim to identify spatially distributed quantities--such as elementwise weakening fields, material parameters, or effective thermal loads--by minimizing discrepancies between measured and simulated responses subject to the governing equations of structural mechanics. While adjoint-based methods enable efficient gradient computation for these inverse problems, the quality and stability of the resulting estimates depend critically on the choice of sensor locations, measurement types, and directions.\n  This paper develops a rigorous and implementation-ready framework for Fisher-information-based sensor placement in adjoint-based finite-element digital twins. Sensor configurations are evaluated using a D-optimal design criterion derived from a linearization of the measurement map, yielding a statistically meaningful measure of information content. We present matrix-free operator formulas for applying the Jacobian and its adjoint, and hence for computing Fisher-information products $Fv = J^\\top R^{-1} Jv$ using only forward and adjoint solves. Building on these operator evaluations, we derive explicit sensitivity expressions for D-optimal sensor design with respect to measurement parameters and discuss practical strategies for evaluating the associated log-determinant objectives. To complement the general framework, we provide analytically tractable sensor placement results for a canonical one-dimensional structural model, clarifying the distinction between detectability and localizability and proving that D-optimal placement of multiple displacement sensors yields approximately uniform spacing."}
{"id": "2602.03020", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03020", "abs": "https://arxiv.org/abs/2602.03020", "authors": ["Shashank Shekhar", "Abhinav Karn", "Kris Keshav", "Shivam Bansal", "Parikshit Pareek"], "title": "Fast Diffusion with Physics-Correction for ACOPF", "comment": null, "summary": "Generating large-scale, physically consistent AC Optimal Power Flow (ACOPF) datasets is essential for modern data-driven power system applications. The central challenge lies in balancing solution accuracy with computational efficiency. Recent diffusion-based generative models produce high-quality samples; however, their slow sampling procedures limit practical scalability. In this work, we argue that exact physical feasibility is ultimately enforced by power flow solvers or projection steps, and therefore the generative model only needs to produce good initializations rather than perfectly feasible solutions. Based on this insight, we propose a fast diffusion framework using Denoising Diffusion Implicit Models (DDIM) combined with physics-guided corrections during sampling. The proposed method replaces slow stochastic refinement with a small number of deterministic steps and explicit constraint guidance. Experiments on IEEE 6-, 24-, and 118-bus systems show that our approach achieves up to 20 times faster sampling than standard diffusion models while maintaining comparable statistical accuracy and physical consistency. This makes the method well suited for scalable OPF dataset generation and practical power system learning tasks. We release the implementation code at https://github.com/PSquare-Lab/DDIM_OPF."}
{"id": "2602.02525", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02525", "abs": "https://arxiv.org/abs/2602.02525", "authors": ["Liam Hebert", "Lucas Kopp", "Robin Cohen"], "title": "Community Norms in the Spotlight: Enabling Task-Agnostic Unsupervised Pre-Training to Benefit Online Social Media", "comment": "Submitted to ICWSM Poster", "summary": "Modelling the complex dynamics of online social platforms is critical for addressing challenges such as hate speech and misinformation. While Discussion Transformers, which model conversations as graph structures, have emerged as a promising architecture, their potential is severely constrained by reliance on high-quality, human-labelled datasets. In this paper, we advocate a paradigm shift from task-specific fine-tuning to unsupervised pretraining, grounded in an entirely novel consideration of community norms. We posit that this framework not only mitigates data scarcity but also enables interpretation of the social norms underlying the decisions made by such an AI system. Ultimately, we believe that this direction offers many opportunities for AI for Social Good."}
{"id": "2602.02946", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.02946", "abs": "https://arxiv.org/abs/2602.02946", "authors": ["Hitomi Endo", "Michikazu Kobayashi"], "title": "Violation of local equilibrium thermodynamics in one-dimensional Hamiltonian-Potts model", "comment": null, "summary": "We investigate non-equilibrium phase coexistence associated with a first-order phase transition by numerically studying a one-dimensional Hamiltonian-Potts model with fractional spatial derivatives. The fractional derivative is introduced so as to reproduce the low-wavenumber density of states of the standard two-dimensional model, allowing phase coexistence to occur in a minimal one-dimensional setting under steady heat conduction. By imposing a constant heat flux through boundary heat baths, we observe stable coexistence of ordered and disordered phases separated by a stationary interface. We find that the temperature at the interface systematically deviates from the equilibrium transition temperature, demonstrating a clear violation of the local equilibrium description. This deviation indicates that equilibrium metastable states can be stabilized and controlled by a steady heat current. Furthermore, the interface temperature obtained in our simulations is in quantitative agreement with the prediction of global thermodynamics for non-equilibrium steady states. These results confirm that the breakdown of local equilibrium and the stabilization of metastable states are intrinsic features of non-equilibrium first-order phase transitions, independent of spatial dimensionality. Our study thus provides a minimal and controlled numerical model for exploring the fundamental limits of thermodynamic descriptions in non-equilibrium steady states."}
{"id": "2602.02771", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02771", "abs": "https://arxiv.org/abs/2602.02771", "authors": ["J. Brandon Carter", "Catherine A. Calder"], "title": "Markov Random Fields: Structural Properties, Phase Transition, and Response Function Analysis", "comment": null, "summary": "This paper presents a focused review of Markov random fields (MRFs)--commonly used probabilistic representations of spatial dependence in discrete spatial domains--for categorical data, with an emphasis on models for binary-valued observations or latent variables. We examine core structural properties of these models, including clique factorization, conditional independence, and the role of neighborhood structures. We also discuss the phenomenon of phase transition and its implications for statistical model specification and inference. A central contribution of this review is the use of response functions, a unifying tool we introduce for prior analysis that provides insight into how different formulations of MRFs influence implied marginal and joint distributions. We illustrate these concepts through a case study of direct-data MRF models with covariates, highlighting how different formulations encode dependence. While our focus is on binary fields, the principles outlined here extend naturally to more complex categorical MRFs and we draw connections to these higher-dimensional modeling scenarios. This review provides both theoretical grounding and practical tools for interpreting and extending MRF-based models."}
{"id": "2602.03020", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03020", "abs": "https://arxiv.org/abs/2602.03020", "authors": ["Shashank Shekhar", "Abhinav Karn", "Kris Keshav", "Shivam Bansal", "Parikshit Pareek"], "title": "Fast Diffusion with Physics-Correction for ACOPF", "comment": null, "summary": "Generating large-scale, physically consistent AC Optimal Power Flow (ACOPF) datasets is essential for modern data-driven power system applications. The central challenge lies in balancing solution accuracy with computational efficiency. Recent diffusion-based generative models produce high-quality samples; however, their slow sampling procedures limit practical scalability. In this work, we argue that exact physical feasibility is ultimately enforced by power flow solvers or projection steps, and therefore the generative model only needs to produce good initializations rather than perfectly feasible solutions. Based on this insight, we propose a fast diffusion framework using Denoising Diffusion Implicit Models (DDIM) combined with physics-guided corrections during sampling. The proposed method replaces slow stochastic refinement with a small number of deterministic steps and explicit constraint guidance. Experiments on IEEE 6-, 24-, and 118-bus systems show that our approach achieves up to 20 times faster sampling than standard diffusion models while maintaining comparable statistical accuracy and physical consistency. This makes the method well suited for scalable OPF dataset generation and practical power system learning tasks. We release the implementation code at https://github.com/PSquare-Lab/DDIM_OPF."}
{"id": "2602.02663", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.02663", "abs": "https://arxiv.org/abs/2602.02663", "authors": ["Preethi Gopalakrishnan", "András Grabarits", "Adolfo del Campo"], "title": "Tailoring Quantum Chaos With Continuous Quantum Measurements", "comment": "5 pages, 2 figures + supplemental material", "summary": "We investigate the role of quantum monitoring in the dynamical manifestations of Hamiltonian quantum chaos. Specifically, we analyze the generalized spectral form factor, defined as the survival probability of a coherent Gibbs state under continuous energy measurements. We show that quantum monitoring can tailor the signatures of quantum chaos in the dynamics, such as the extension of the ramp in the spectral form factor, by varying the measurement strength and detection efficiency. In particular, a typical quantum trajectory obtained by monitoring with unit efficiency exhibits enhanced quantum chaos relative to the average dynamics and to unitary evolution without measurements."}
{"id": "2602.03509", "categories": ["physics.geo-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.03509", "abs": "https://arxiv.org/abs/2602.03509", "authors": ["Zepeng Wu", "Liangrui Wei", "Chen Gao", "Shunqing Wu", "Renata M. Wentzcovitch", "Yang Sun"], "title": "Radial gradient of superionic hydrogen in Earth's inner core", "comment": null, "summary": "Hydrogen is considered a major light element in Earth's core, yet the thermodynamics of its superionic phase and its distribution in the inner core remain unclear. Here, we compute ab initio Gibbs free energies for liquid and superionic hcp and bcc Fe-H phases and construct the superionic-liquid phase diagram over pressure-temperature conditions relevant to the Earth's inner core. We find that phase diagrams at different inner-core pressures collapse when temperatures are scaled by the melting temperature of pure iron, indicating that solid-liquid partitioning is controlled primarily by a reduced temperature relative to iron melting and is weakly sensitive to pressure. This scaling relation further reconciles previously reported discrepancies in partition coefficients among theoretical studies and yields good agreement with available experimental data at low pressures. By applying thermochemical constraints, our free-energy results reveal a radial hydrogen gradient within the inner core. These results demonstrate that compositional gradients of superionic hydrogen in the inner core emerge naturally from equilibrium thermodynamics and suggest a general mechanism governing the depth-dependent distribution of light elements within Earth's inner core."}
{"id": "2602.02779", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.02779", "abs": "https://arxiv.org/abs/2602.02779", "authors": ["Koji Koyamada"], "title": "Comparison of Trefftz-Based PINNs and Standard PINNs Focusing on Structure Preservation", "comment": null, "summary": "In this study, we investigate the capability of physics-informed neural networks (PINNs) to preserve global physical structures by comparing standard PINNs with a Trefftz-based PINN (Trefftz-PINN). The target problem is the reproduction of mag-netic field-line structures in a helical fusion reactor configuration. Using identical training data sampled from exact solutions, we perform comparisons under matched mean squared error (MSE) levels. Visualization of magnetic field lines reveals that standard PINNs may exhibit structural collapse across magnetic surfaces even when the MSE is sufficiently small, whereas Trefftz-PINNs successfully preserve the global topology of magnetic field lines. Furthermore, the proposed framework is extended to computational fluid dynamics (CFD) problems, where streamline structures of veloc-ity fields are analyzed. Similar tendencies are observed, demonstrating that Trefftz-PINNs provide superior structure preservation compared to standard PINNs. These results indicate that minimizing numerical error alone does not guarantee physical consistency, and that constraining the solution space prior to learning is an effective strategy for physics-consistent surrogate modeling."}
{"id": "2602.03283", "categories": ["math.ST", "cs.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.03283", "abs": "https://arxiv.org/abs/2602.03283", "authors": ["Haohua Chen", "Songbin Liu", "Junjie Ma"], "title": "Orthogonal Approximate Message Passing Algorithms for Rectangular Spiked Matrix Models with Rotationally Invariant Noise", "comment": "To appear in the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2026", "summary": "We propose an orthogonal approximate message passing (OAMP) algorithm for signal estimation in the rectangular spiked matrix model with general rotationally invariant (RI) noise. We establish a rigorous state evolution that exactly characterizes the high-dimensional dynamics of the algorithm. Building on this framework, we derive an optimal variant of OAMP that minimizes the predicted mean-squared error at each iteration. For the special case of i.i.d. Gaussian noise, the fixed point of the proposed OAMP algorithm coincides with that of the standard AMP algorithm. For general RI noise models, we conjecture that the optimal OAMP algorithm is statistically optimal within a broad class of iterative methods, and achieves Bayes-optimal performance in certain regimes."}
{"id": "2602.02732", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02732", "abs": "https://arxiv.org/abs/2602.02732", "authors": ["Charles Snider", "Stephen Carr", "D. E. Feldman", "Chandrasekhar Ramanathan", "V. F. Mitrović"], "title": "Dynamic Simulations of Strongly Coupled Spin Ensembles for Inferring Nature of Electronic Correlations from Nuclear Magnetic Resonance", "comment": "62 pages, 14 figures", "summary": "We develop an efficient package for the simulation of nuclear magnetic resonance spin echo experiments to study the effects of strong electronic spin correlations on the dynamics of the nuclear spin ensemble. A mean-field model is used to study correlated electronic phases through their hyperfine interaction with nuclear spins. We explore the dynamics of the interacting nuclear ensemble and discuss the key behaviors of the system. In particular, we classify the types of temporal asymmetry that the interaction induces in the system as well as a pulse-dependent shift in the spectral domain. Us- ing these results, we discuss how careful measurement of the pulse-dependent shiftcanbeusedtoextractinformationabouttheanisotropyoftheelectronic interaction and how these results represent a novel tool for the examination of exotic NMR signatures in strongly correlated materials. Finally, we re- view specific aspects of the simulation package developed for our exploration and give explicit examples where package can be used to infer range and anisotropy of electronic correlations. In particular, we discuss its structure, accuracy, and the technical merits of the various approximations used to model the nuclear spin ensemble."}
{"id": "2602.02553", "categories": ["physics.soc-ph", "math.DS", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.02553", "abs": "https://arxiv.org/abs/2602.02553", "authors": ["Yishen Jiang", "Xin Wang", "Ming Wei", "Wenqiang Zhu", "Longzhao Liu", "Hongwei Zheng", "Shaoting Tang"], "title": "Indirect Reciprocity with Environmental Feedback", "comment": null, "summary": "Indirect reciprocity maintains cooperation in stranger societies by mapping individual behaviors onto reputation signals via social norms. Existing theoretical frameworks assume static environments with constant resources and fixed payoff structures. However, in real-world systems, individuals' strategic behaviors not only shape their reputation but also induce collective-level resource changes in ecological, economic, or other external environments, which in turn reshape the incentives governing future individual actions. To overcome this limitation, we establish a co-evolutionary framework that couples moral assessment, strategy updating, and environmental dynamics, allowing the payoff structure to dynamically adjust in response to the ecological consequences of collective actions. We find that this environmental feedback mechanism helps lower the threshold for the emergence of cooperation, enabling the system to spontaneously transition from a low-cooperation state to a stable high-cooperation regime, thereby reducing the dependence on specific initial conditions. Furthermore, while lenient norms demonstrate adaptability in static environments, norms with strict discrimination are shown to be crucial for curbing opportunism and maintaining evolutionary resilience in dynamic settings. Our results reveal the evolutionary dynamics of coupled systems involving reputation institutions and environmental constraints, offering a new theoretical perspective for understanding collective cooperation and social governance in complex environments."}
{"id": "2602.02992", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02992", "abs": "https://arxiv.org/abs/2602.02992", "authors": ["Masashi Wakaiki"], "title": "Data-driven stabilization of continuous-time systems with noisy input-output data", "comment": "18 pages", "summary": "We study data-driven stabilization of continuous-time systems in autoregressive form when only noisy input-output data are available. First, we provide an operator-based characterization of the set of systems consistent with the data. Next, combining this characterization with behavioral theory, we derive a necessary and sufficient condition for the noisy data to be informative for quadratic stabilization. This condition is formulated as linear matrix inequalities, whose solution yields a stabilizing controller. Finally, we characterize data informativity for system identification in the noise-free setting."}
{"id": "2602.03070", "categories": ["eess.SY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03070", "abs": "https://arxiv.org/abs/2602.03070", "authors": ["Chao Shen", "Zihan Guo", "Xu Wan", "Zhenghao Yang", "Yifan Zhang", "Wengi Huang", "Jie Song", "Zongyan Zhang", "Mingyang Sun"], "title": "ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling", "comment": null, "summary": "Growing renewable penetration introduces substantial uncertainty into power system operations, necessitating frequent adaptation of dispatch objectives and constraints and challenging expertise-intensive, near-real-time modeling workflows. Large Language Models (LLMs) provide a promising avenue for automating this process by translating natural-language (NL) operational requirements into executable optimization models via semantic reasoning and code synthesis. Yet existing LLM datasets and benchmarks for optimization modeling primarily target coarse-grained cross-domain generalization, offering limited, rigorous evaluation in power-system settings, particularly for Optimal Power Flow (OPF). We therefore introduce \\textbf{ProOPF-D} and \\textbf{ProOPF-B}, a dataset and benchmark for professional-grade OPF modeling: ProOPF-D contains 12K instances pairing NL requests with parameter adjustments and structural extensions to a canonical OPF, together with executable implementations; ProOPF-B provides 121 expert-annotated test cases with ground-truth code, enabling end-to-end evaluation under both concrete and abstract OPF modeling regimes."}
{"id": "2602.02534", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.02534", "abs": "https://arxiv.org/abs/2602.02534", "authors": ["Enhao Huang", "Tongtong Pan", "Shuhuai Zhang", "Qishu Jin", "Liheng Zheng", "Kaichun Hu", "Yiming Li", "Zhan Qin", "Kui Ren"], "title": "DualMind: Towards Understanding Cognitive-Affective Cascades in Public Opinion Dissemination via Multi-Agent Simulation", "comment": "Accepted as a demo paper at TheWebConf (WWW) 2026", "summary": "Forecasting public opinion during PR crises is challenging, as existing frameworks often overlook the interaction between transient affective responses and persistent cognitive beliefs. To address this, we propose DualMind, an LLM-driven multi-agent platform designed to model this dual-component interplay. We evaluate the system on 15 real-world crises occurring post-August 2024 using social media data as ground truth. Empirical results demonstrate that DualMind faithfully reconstructs opinion trajectories, significantly outperforming state-of-the-art baselines. This work offers a high-fidelity tool for proactive crisis management. Code is available at https://github.com/EonHao/DualMind."}
{"id": "2602.03431", "categories": ["cond-mat.stat-mech", "nlin.SI"], "pdf": "https://arxiv.org/pdf/2602.03431", "abs": "https://arxiv.org/abs/2602.03431", "authors": ["Kohei Fukai", "Balázs Pozsgay", "István Vona"], "title": "Solving models with generalized free fermions I: Algebras and eigenstates", "comment": null, "summary": "We study quantum spin chains solvable via hidden free fermionic structures. We study the algebras behind such models, establishing connections to the mathematical literature of the so-called ``graph-Clifford'' or ``quasi-Clifford'' algebras. We also introduce the ``defining representation'' for such algebras, and show that this representation actually coincides with the terms of the Hamiltonian in two relevant models: the XY model and the ``free fermions in disguise'' model of Fendley. Afterwards we study a particular anti-symmetric combination of commuting Hamiltonians; this is performed in a model independent way. We show that for this combination there exists a reference state, and few body eigenstates can be created by the fermionic operators. Concrete application is presented in the case of the ``free fermions in disguise'' model."}
{"id": "2602.02777", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02777", "abs": "https://arxiv.org/abs/2602.02777", "authors": ["Isqeel Ogunsola", "Olatunji Johnson"], "title": "Disentangling spatial interference and spatial confounding biases in causal inference", "comment": null, "summary": "Spatial interference and spatial confounding are two major issues inhibiting precise causal estimates when dealing with observational spatial data. Moreover, the definition and interpretation of spatial confounding remain arguable in the literature. In this paper, our goal is to provide clarity in a novel way on misconception and issues around spatial confounding from Directed Acyclic Graph (DAG) perspective and to disentangle both direct, indirect spatial confounding and spatial interference based on bias induced on causal estimates. Also, existing analyses of spatial confounding bias typically rely on Normality assumptions for treatments and confounders, assumptions that are often violated in practice. Relaxing these assumptions, we derive analytical expressions for spatial confounding bias under more general distributional settings using Poisson as example . We showed that the choice of spatial weights, the distribution of the treatment, and the magnitude of interference critically determine the extent of bias due to spatial interference. We further demonstrate that direct and indirect spatial confounding can be disentangled, with both the weight matrix and the nature of exposure playing central roles in determining the magnitude of indirect bias. Theoretical results are supported by simulation studies and an application to real-world spatial data. In future, parametric frameworks for concomitantly adjusting for spatial interference, direct and indirect spatial confounding for both direct and mediated effects estimation will be developed."}
{"id": "2602.03070", "categories": ["eess.SY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.03070", "abs": "https://arxiv.org/abs/2602.03070", "authors": ["Chao Shen", "Zihan Guo", "Xu Wan", "Zhenghao Yang", "Yifan Zhang", "Wengi Huang", "Jie Song", "Zongyan Zhang", "Mingyang Sun"], "title": "ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling", "comment": null, "summary": "Growing renewable penetration introduces substantial uncertainty into power system operations, necessitating frequent adaptation of dispatch objectives and constraints and challenging expertise-intensive, near-real-time modeling workflows. Large Language Models (LLMs) provide a promising avenue for automating this process by translating natural-language (NL) operational requirements into executable optimization models via semantic reasoning and code synthesis. Yet existing LLM datasets and benchmarks for optimization modeling primarily target coarse-grained cross-domain generalization, offering limited, rigorous evaluation in power-system settings, particularly for Optimal Power Flow (OPF). We therefore introduce \\textbf{ProOPF-D} and \\textbf{ProOPF-B}, a dataset and benchmark for professional-grade OPF modeling: ProOPF-D contains 12K instances pairing NL requests with parameter adjustments and structural extensions to a canonical OPF, together with executable implementations; ProOPF-B provides 121 expert-annotated test cases with ground-truth code, enabling end-to-end evaluation under both concrete and abstract OPF modeling regimes."}
{"id": "2602.02672", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02672", "abs": "https://arxiv.org/abs/2602.02672", "authors": ["Barkay Guttel", "Danielle Gov", "Noam Netzer", "Uri Goldblatt", "Sergey Hazanov", "Lalit M. Joshi", "Alessandro Romito", "Yuval Gefen", "Parveen Kumar", "Kyrylo Snizhko", "Fabien Lafont", "Serge Rosenblum"], "title": "Unravelling the emergence of quantum jumps in a monitored qubit", "comment": "25 pages, 15 figures, including supplementary information", "summary": "Quantum jumps, the collapse of a quantum system upon measurement, are among the most striking consequences of observation in quantum mechanics. While recent experiments have revealed the continuous nature of individual jumps, the crossover from coherent dynamics to measurement-dominated behaviour has remained elusive. Here, we tune the measurement strength of a continuously monitored superconducting qubit, and observe that quantum jumps emerge not through a gradual crossover, but via a cascade of three distinct dynamical transitions. The first transition manifests as an exceptional point where coherent oscillations abruptly cease, giving way to jumps towards a stable eigenstate. The second transition marks the onset of dynamical state freezing, where the qubit's dwell time near the eigenstate diverges. A third threshold signals entry into the quantum Zeno regime, where stronger measurement paradoxically suppresses relaxation. Strikingly, we find that decoherence does not blur these transitions but rather fundamentally restructures the dynamical phase diagram, notably inverting their order. These results map measurement-induced transitions in a monitored qubit, revealing that the interplay between coherent driving, measurement, and decoherence gives rise to a hierarchy of distinct dynamical phases."}
{"id": "2602.02540", "categories": ["physics.soc-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.02540", "abs": "https://arxiv.org/abs/2602.02540", "authors": ["Aditya Patel", "Naveen Sudharsan", "Trevor Brooks", "Harsh Kamath", "Dru Crawley", "Zack Baumer", "Marc Coudert", "Dev Niyogi"], "title": "Thermal Comfort Path Planning Tool for Urban Mobility in Austin, Texas", "comment": "11 pages, 2 figures", "summary": "Extreme heat poses a growing challenge for active transportation in cities like Austin, Texas, where conventional weather reporting (e.g. a single air temperature measurement for the whole city) fails to capture the large microclimate variations that pedestrians and cyclists actually experience. We present a novel walking and biking route planner that selects paths based on thermal comfort using the Universal Thermal Climate Index (UTCI) (Jendritzky et al., 2012) rather than just distance or travel time. This system combines high-resolution thermal modeling with real-time route mapping. We generate city-scale UTCI maps using SOLWEIG-GPU (Solar and LongWave Environmental Irradiance Geometry), to account for urban features (buildings, trees, etc.) and weather conditions (Lindberg et al., 2008; Kamath et al., 2026). For any given origin and destination, our tool calculates the average UTCI along each possible route and recommends the 'coolest' route, i.e. the path with the lowest heat stress (often the most shaded or otherwise thermally comfortable), while still being reasonably direct. In a case study for Austin, this approach identifies routes that significantly reduce pedestrians' heat exposure (often recommending routes with a much larger proportion of shade). Such thermally-informed route planning has important public health implications: by helping people avoid dangerous heat hotspots and sun-exposed areas, it can reduce the risk of heat-related illness and make walking or biking a safer choice even on hot days. This paper describes the motivation, methodology, results, and implications of the thermal comfort path planner, emphasizing the role of shade and thermal comfort in urban mobility and heat mitigation."}
{"id": "2602.03083", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.03083", "abs": "https://arxiv.org/abs/2602.03083", "authors": ["Hao Hu", "Haijun Yu"], "title": "Scaling Optimized Spectral Approximations on Unbounded Domains: The Generalized Hermite and Laguerre Methods", "comment": "40 pages", "summary": "We propose a novel error analysis framework for scaled generalized Laguerre and generalized Hermite approximations.This framework can be regarded as an analogue of the Nyquist-Shannon sampling theorem: It characterizes the spatial and frequency bandwidths that can be effectively captured by Laguerre or Hermite sampling points. Provided a function satisfies the corresponding bandwidth constraints, it can be accurately approximated within this framework. The proposed framework is notably more powerful than classical theory -- it not only provides systematic guidance for choosing the optimal scaling factor, but also predicts root-exponential and other intricate convergence behaviors that classical approaches fail to capture. Leveraging this framework, we conducted a detailed comparative study of Hermite and Laguerre approximations. We find that functions with similar decay and oscillation characteristics may nonetheless display markedly different convergence rates. Furthermore, approximations based on two concatenated sets of Laguerre functions may offer significant advantages over those using a single set of Hermite functions."}
{"id": "2602.03539", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.03539", "abs": "https://arxiv.org/abs/2602.03539", "authors": ["Thomas Nagler", "Sophie Langer"], "title": "Optimal neural network approximation of smooth compositional functions on sets with low intrinsic dimension", "comment": null, "summary": "We study approximation and statistical learning properties of deep ReLU networks under structural assumptions that mitigate the curse of dimensionality. We prove minimax-optimal uniform approximation rates for $s$-Hölder smooth functions defined on sets with low Minkowski dimension using fully connected networks with flexible width and depth, improving existing results by logarithmic factors even in classical full-dimensional settings. A key technical ingredient is a new memorization result for deep ReLU networks that enables efficient point fitting with dense architectures. We further introduce a class of compositional models in which each component function is smooth and acts on a domain of low intrinsic dimension. This framework unifies two common assumptions in the statistical learning literature, structural constraints on the target function and low dimensionality of the covariates, within a single model. We show that deep networks can approximate such functions at rates determined by the most difficult function in the composition. As an application, we derive improved convergence rates for empirical risk minimization in nonparametric regression that adapt to smoothness, compositional structure, and intrinsic dimensionality."}
{"id": "2602.02872", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.02872", "abs": "https://arxiv.org/abs/2602.02872", "authors": ["Banasree S. Mou", "Stephen M. Winter"], "title": "Dynamical Effective Hamiltonian Approach to Second-Harmonic Generation in Quantum Magnets: Application to NiI$_2$", "comment": "4 figures", "summary": "Although second harmonic generation (SHG) is a promising and widely used method recently for studying 2D magnetic materials, the quantitative analysis of the full SHG tensor is currently challenging. In this letter, we describe a first-principles-based approach towards quantitative analysis of SHG in insulating magnets through formulation in terms of dynamical effective operators. These operators are computed by solving local many-body cluster models. We benchmark this method on NiI$_2$, a multiferroic 2D van der Waals antiferromagnet, demonstrating quantitative analysis of reported Rotational Anisotropy (RA)-SHG data. SHG is demonstrated to probe local ring-current susceptibilities, which provide sensitivity to short-range chiral spin-spin correlations. The described methods may be easily extended to other non-linear optical responses and materials."}
{"id": "2602.02562", "categories": ["physics.soc-ph", "math.DS", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.02562", "abs": "https://arxiv.org/abs/2602.02562", "authors": ["Enrique Calderoli", "Maria Cristina Varriale", "Flávio Kapczinski"], "title": "A Distinct Communication Strategies Model of the Double Empathy Problem", "comment": "16 pages, 5 figures", "summary": "The double empathy problem recasts the difficulty of forming empathy bonds in social interactions between autistic and neurotypical individuals as a bidirectional problem, rather than due to a deficit exclusive to the person on the spectrum. However, no explicit mechanism to explain such a phenomenon has been proposed. Here we build a feedback-loop mathematical model that would theoretically induce the empathy degradation observed during communication in neurotypical-autistic pairs solely due to differences in communication preferences between neurotypical and neurodivergent individuals. Numerical simulations of dyadic interactions show the model, whose mechanism is based solely on communication preferences, can illustrate the breakdown of empathic bonding observed clinically. Stability analysis of the model provides a way to predict the overall trajectory of the interaction in the empathy space. Furthermore, we suggest experimental designs to measure several parameters outlined here and discuss the future directions for testing the proposed model."}
{"id": "2602.03460", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03460", "abs": "https://arxiv.org/abs/2602.03460", "authors": ["Julia Adlercreutz", "Richard Pates"], "title": "Cholesky factorisation, and intrinsically sparse linear quadratic regulation", "comment": "15 pages, 7 figures, under review", "summary": "We classify a family of matrices of shift operators that can be factorised in a computationally tractable manner with the Cholesky algorithm. Such matrices arise in the linear quadratic regulator problem, and related areas. We use the factorisation to uncover intrinsic sparsity properties in the control laws for transportation problems with an underlying tree structure. This reveals that the optimal control can be applied in a distributed manner that is obscured by standard solution methods."}
{"id": "2602.03256", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03256", "abs": "https://arxiv.org/abs/2602.03256", "authors": ["Eymen Ipek", "Assoc. Mario Hirz"], "title": "Impact of Physics-Informed Features on Neural Network Complexity for Li-ion Battery Voltage Prediction in Electric Vertical Takeoff and Landing Aircrafts", "comment": null, "summary": "The electrification of vertical takeoff and landing aircraft demands high-fidelity battery management systems capable of predicting voltage response under aggressive power dynamics. While data-driven models offer high accuracy, they often require complex architectures and extensive training data. Conversely, equivalent circuit models (ECMs), such as the second-order model, offer physical interpretability but struggle with high C-rate non-linearities. This paper investigates the impact of integrating physics-based information into data-driven surrogate models. Specifically, we evaluate whether physics-informed features allow for the simplification of neural network architectures without compromising accuracy. Using the open-source electric vertical takeoff and landing (eVTOL) battery dataset, we compare pure data-driven models against physics-informed data models. Results demonstrate that physics-informed models achieve comparable accuracy to complex pure data-driven models while using up to 75% fewer trainable parameters, significantly reducing computational overhead for potential on-board deployment."}
{"id": "2602.02601", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02601", "abs": "https://arxiv.org/abs/2602.02601", "authors": ["Hieu Duong", "Eugene Levin", "Todd Gary", "Long Nguyen"], "title": "CaST: Causal Discovery via Spatio-Temporal Graphs in Disaster Tweets", "comment": null, "summary": "Understanding causality between real-world events from social media is essential for situational awareness, yet existing causal discovery methods often overlook the interplay between semantic, spatial, and temporal contexts. We propose CaST: Causal Discovery via Spatio-Temporal Graphs, a unified framework for causal discovery in disaster domain that integrates semantic similarity and spatio-temporal proximity using Large Language Models (LLMs) pretrained on disaster datasets. CaST constructs an event graph for each window of tweets. Each event extracted from tweets is represented as a node embedding enriched with its contextual semantics, geographic coordinates, and temporal features. These event nodes are then connected to form a spatio-temporal event graph, which is processed using a multi-head Graph Attention Network (GAT) \\cite{gat} to learn directed causal relationships. We construct an in-house dataset of approximately 167K disaster-related tweets collected during Hurricane Harvey and annotated following the MAVEN-ERE schema. Experimental results show that CaST achieves superior performance over both traditional and state-of-the-art methods. Ablation studies further confirm that incorporating spatial and temporal signals substantially improves both recall and stability during training. Overall, CaST demonstrates that integrating spatio-temporal reasoning into event graphs enables more robust and interpretable causal discovery in disaster-related social media text."}
{"id": "2602.03764", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03764", "abs": "https://arxiv.org/abs/2602.03764", "authors": ["Pedro V. Paraguassú"], "title": "Stochastic Thermodynamics of Quantum-Induced Stochastic Dynamics", "comment": "12 pages, 3 appendix", "summary": "Quantum-Induced Stochastic Dynamics arises from the coupling between a classical system and a quantum environment. Unlike standard thermal reservoirs, this environment acts as a dynamic bath, capable of simultaneously exchanging heat and performing work. We formulate a thermodynamic framework for this semi-classical regime, defining heat, work, and entropy production. We derive a modified Second Law that accounts for non-equilibrium quantum features, such as squeezing. The framework is exemplified by an optomechanical setup, where we characterize the thermodynamics of the non-stationary noise induced by the cavity field."}
{"id": "2602.02809", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02809", "abs": "https://arxiv.org/abs/2602.02809", "authors": ["Zhiwei Zhang", "Peisong Han", "Wei Zhang"], "title": "A Model-Robust G-Computation Method for Analyzing Hybrid Control Studies Without Assuming Exchangeability", "comment": null, "summary": "There is growing interest in a hybrid control design for treatment evaluation, where a randomized controlled trial is augmented with external control data from a previous trial or a real world data source. The hybrid control design has the potential to improve efficiency but also carries the risk of introducing bias. The potential bias in a hybrid control study can be mitigated by adjusting for baseline covariates that are related to the control outcome. Existing methods that serve this purpose commonly assume that the internal and external control outcomes are exchangeable upon conditioning on a set of measured covariates. Possible violations of the exchangeability assumption can be addressed using a g-computation method with variable selection under a correctly specified outcome regression model. In this article, we note that a particular version of this g-computation method is protected against misspecification of the outcome regression model. This observation leads to a model-robust g-computation method that is remarkably simple and easy to implement, consistent and asymptotically normal under minimal assumptions, and able to improve efficiency by exploiting similarities between the internal and external control groups. The method is evaluated in a simulation study and illustrated using real data from HIV treatment trials."}
{"id": "2602.03256", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03256", "abs": "https://arxiv.org/abs/2602.03256", "authors": ["Eymen Ipek", "Assoc. Mario Hirz"], "title": "Impact of Physics-Informed Features on Neural Network Complexity for Li-ion Battery Voltage Prediction in Electric Vertical Takeoff and Landing Aircrafts", "comment": null, "summary": "The electrification of vertical takeoff and landing aircraft demands high-fidelity battery management systems capable of predicting voltage response under aggressive power dynamics. While data-driven models offer high accuracy, they often require complex architectures and extensive training data. Conversely, equivalent circuit models (ECMs), such as the second-order model, offer physical interpretability but struggle with high C-rate non-linearities. This paper investigates the impact of integrating physics-based information into data-driven surrogate models. Specifically, we evaluate whether physics-informed features allow for the simplification of neural network architectures without compromising accuracy. Using the open-source electric vertical takeoff and landing (eVTOL) battery dataset, we compare pure data-driven models against physics-informed data models. Results demonstrate that physics-informed models achieve comparable accuracy to complex pure data-driven models while using up to 75% fewer trainable parameters, significantly reducing computational overhead for potential on-board deployment."}
{"id": "2602.02673", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.02673", "abs": "https://arxiv.org/abs/2602.02673", "authors": ["Francesco Perciavalle", "Francesco Plastina", "Nicola Lo Gullo"], "title": "Floquet-engineered fidelity revivals in the PXP model", "comment": "14 pages, 7 figures", "summary": "We explore the dynamics of the PXP model when subjected to a periodic drive, and unveil the mechanism through which the interplay between spectral properties and initial states governs the emergence of dynamical revivals and their evolution across the space of driving parameters. For Néel-ordered initial states, revivals follow well-defined trajectories in the parameter space of the driving, primarily determined by a dominant quasi-energy spacing in the Floquet spectrum. Initial states interpolating between Néel and fully polarized configurations exhibit hybrid dynamics, which can be controlled by tuning their overlap with Floquet eigenstates via the driving parameters. This control also allows steering different routes for avoiding Floquet thermalization, showing how both initial state choice and driving protocol shape long-lived dynamics in this driven quantum many-body systems."}
{"id": "2602.03118", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.03118", "abs": "https://arxiv.org/abs/2602.03118", "authors": ["Henri Klintebäck", "Christoph Ortner", "Lior Silberman"], "title": "The High Cost of Data Augmentation for Learning Equivariant Models", "comment": "33 pages, 13 figures", "summary": "According to Noether's theorem the presence of a continuous symmetry in a Hamiltonian systems is equivalent to the existence of a conserved quantity, yet these symmetries are not always explicitly enforced in data-driven models. There remains a debate whether or not encoding of symmetry into a model architecture is the optimal approach. A competing approach is to target approximate symmetry through data augmentation. In this work, we study two approaches aimed at improving the symmetry properties of such an approximation scheme: one based on a quadrature rule for the Haar measure on the compact Lie group encoding the continuous symmetry of interest and one based on a random sampling of that Haar measure. We demonstrate both theoretically and empirically that the quadrature augmentation leads to exact symmetry preservation in polynomial models, while the random augmentation has only square-root convergence of the symmetrization error."}
{"id": "2602.02753", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.02753", "abs": "https://arxiv.org/abs/2602.02753", "authors": ["Youngjin Cho", "Meimei Liu"], "title": "Effect-Wise Inference for Smoothing Spline ANOVA on Tensor-Product Sobolev Space", "comment": null, "summary": "Functional ANOVA provides a nonparametric modeling framework for multivariate covariates, enabling flexible estimation and interpretation of effect functions such as main effects and interaction effects. However, effect-wise inference in such models remains challenging. Existing methods focus primarily on inference for entire functions rather than individual effects. Methods addressing effect-wise inference face substantial limitations: the inability to accommodate interactions, a lack of rigorous theoretical foundations, or restriction to pointwise inference. To address these limitations, we develop a unified framework for effect-wise inference in smoothing spline ANOVA on a subspace of tensor product Sobolev space. For each effect function, we establish rates of convergence, pointwise confidence intervals, and a Wald-type test for whether the effect is zero, with power achieving the minimax distinguishable rate up to a logarithmic factor. Main effects achieve the optimal univariate rates, and interactions achieve optimal rates up to logarithmic factors. The theoretical foundation relies on an orthogonality decomposition of effect subspaces, which enables the extension of the functional Bahadur representation framework to effect-wise inference in smoothing spline ANOVA with interactions. Simulation studies and real-data application to the Colorado temperature dataset demonstrate superior performance compared to existing methods."}
{"id": "2602.02941", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.02941", "abs": "https://arxiv.org/abs/2602.02941", "authors": ["Shinji Watanabe", "Tatsuya Iwasaki"], "title": "Effect of magnetic field on whirling-anti-whirling order in icosahedral-quasicrystal approximant", "comment": "7 pages, 3 figures", "summary": "Recent neutron measurement in the icosahedral quasicrystal approximant Au-SM-Tb (SM=Al, Ga) has revealed unique noncollinear magnetic order ``whirling-anti-whirling states''. Here, we report theoretical analysis on the magnetic-field-direction dependence on the whirling-anti-whirling order in the 1/1 approximant crystal. By performing exact-diagonalization calculation for the effective model taking into account the uniaxial magnetic anisotropy arising from the crystalline electric field, we show the metamagnetic transition takes place simultaneously with the topological transition under the magnetic field along the (111) direction. After the metamagnetic transition, the emergent fictious magnetic field induced by the chirality of noncoplanar magnetic moments appears, the analysis of which concludes that the topological Hall effect is expected to be observed in the electrical conductivity $σ_{xy}$ and $σ_{yz}$ for the applied field direction from (111) to (001)."}
{"id": "2602.02587", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "cs.GT", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.02587", "abs": "https://arxiv.org/abs/2602.02587", "authors": ["Gregg Hartvigsen"], "title": "The Evolution of Lying in a Spatially-Explicit Prisoner's Dilemma Model", "comment": "18 pages, 11 figures", "summary": "I present the results from a spatial model of the prisoner's dilemma, played on a toroidal lattice. Each individual has a default strategy of either cooperating ($C$) or defecting ($D$). Two strategies were tested, including ``tit-for-tat'' (TFT), in which individuals play their opponent's last play, or simply playing their default play. Each individual also has a probability of telling the truth ($0 \\leq P_{truth} \\leq 1$) about their last play. This parameter, which can evolve over time, allows individuals to be, for instance, a defector but present as a cooperator regarding their last play. This leads to interesting dynamics where mixed populations of defectors and cooperators with $P_{truth} \\geq 0.75$ move toward populations of truth-telling cooperators. Likewise, mixed populations with $P_{truth} < 0.7$ become populations of lying defectors. Both such populations are stable because they each have higher average scores than populations with intermediate values of $P_{truth}$. Applications of this model are discussed with regards to both humans and animals."}
{"id": "2602.03508", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03508", "abs": "https://arxiv.org/abs/2602.03508", "authors": ["Galina Sidorenko", "Johan Thunberg"], "title": "A necessary and sufficient condition for discrete-time consensus on star boundaries", "comment": "14 pages, 8 figures", "summary": "It is intuitive and well known, that if agents in a multi-agent system iteratively update their states in the Euclidean space as convex combinations of neighbors' states, all states eventually converge to the same value (consensus), provided the interaction graph is sufficiently connected. However, this seems to be also true in practice if the convex combinations of states are mapped or radially projected onto any unit $l_p$-sphere or even boundaries of star-convex sets, herein referred to as star boundaries. In this paper, we present insight into this matter by providing a necessary and sufficient condition for asymptotic consensus of the normalized states (directions) for strongly connected directed graphs, which is equivalent to asymptotic consensus of states when the star boundaries are the same for all agents. Furthermore, we show that when asymptotic consensus occurs, the states converge linearly and the point of convergence is continuous in the initial states. Assuming a directed strongly connected graph provides a more general setting than that considered, for example, in gradient-based consensus protocols, where symmetric graphs are assumed. Illustrative examples and a vast number of numerical simulations showcase the theoretical results."}
{"id": "2602.03272", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03272", "abs": "https://arxiv.org/abs/2602.03272", "authors": ["Nicola Ramseyer", "Matthieu Jacobs", "Mario Paolone"], "title": "Power Reserve Procurement Considering Dependent Random Variables with PCE", "comment": null, "summary": "This paper presents an approach for the modelling of dependent random variables using generalised polynomial chaos. This allows to write chance-constrained optimization problems with respect to a joint distribution modelling dependencies between different stochastic inputs. Arbitrary dependencies are modelled by using Gaussian copulas to construct the joint distribution. The paper exploits the problem structure and develops suitable transformations to ensure tractability. The proposed method is applied to a probabilistic power reserve procurement problem. The effectiveness of the method to capture dependencies is shown by comparing the approach with a standard approach considering independent random variables."}
{"id": "2602.02606", "categories": ["cs.SI", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02606", "abs": "https://arxiv.org/abs/2602.02606", "authors": ["Faezeh Fadaei", "Jenny Carla Moran", "Taha Yasseri"], "title": "Gender Dynamics and Homophily in a Social Network of LLM Agents", "comment": "Under Review", "summary": "Generative artificial intelligence and large language models (LLMs) are increasingly deployed in interactive settings, yet we know little about how their identity performance develops when they interact within large-scale networks. We address this by examining Chirper.ai, a social media platform similar to X but composed entirely of autonomous AI chatbots. Our dataset comprises over 70,000 agents, approximately 140 million posts, and the evolving followership network over one year. Based on agents' text production, we assign weekly gender scores to each agent. Results suggest that each agent's gender performance is fluid rather than fixed. Despite this fluidity, the network displays strong gender-based homophily, as agents consistently follow others performing gender similarly. Finally, we investigate whether these homophilic connections arise from social selection, in which agents choose to follow similar accounts, or from social influence, in which agents become more similar to their followees over time. Consistent with human social networks, we find evidence that both mechanisms shape the structure and evolution of interactions among LLMs. Our findings suggest that, even in the absence of bodies, cultural entraining of gender performance leads to gender-based sorting. This has important implications for LLM applications in synthetic hybrid populations, social simulations, and decision support."}
{"id": "2602.03790", "categories": ["cond-mat.stat-mech", "cond-mat.mtrl-sci", "cond-mat.soft", "physics.class-ph"], "pdf": "https://arxiv.org/pdf/2602.03790", "abs": "https://arxiv.org/abs/2602.03790", "authors": ["Andrés Santos"], "title": "The Mpemba effect in the Descartes protocol: A time-delayed Newton's law of cooling approach", "comment": "12 pages, 8 figures", "summary": "We investigate the direct and inverse Mpemba effects within the framework of the time-delayed Newton's law of cooling by introducing and analyzing the Descartes protocol, a three-reservoir thermal scheme in which each sample undergoes a single-step quench at different times. This protocol enables a transparent separation of the roles of the delay time $τ$, the waiting time $t_{\\text{w}}$, and the normalized warm temperature $ω$, thus providing a flexible setting to characterize anomalous thermal relaxation. For instantaneous quenches, exact conditions for the existence of the Mpemba effect are obtained as bounds on $ω$ for given $τ$ and $t_{\\text{w}}$. Within those bounds, the effect becomes maximal at a specific value $ω=\\widetildeω(t_{\\text{w}})$, and its magnitude is quantified by the extremal value of the temperature-difference function at this optimum. Accurate and compact approximations for both $\\widetildeω(t_{\\text{w}})$ and the maximal magnitude $\\text{Mp}(t_{\\text{w}})$ are derived, showing in particular that the absolute maximum at fixed $τ$ is reached for $t_{\\text{w}}=τ$. A comparison with a previously studied two-reservoir protocol reveals that, despite its additional control parameter, the Descartes protocol yields a smaller maximal magnitude of the effect. The analysis is extended to finite-rate quenches, where strict equality of bath conditions prevents a genuine Mpemba effect, although an approximate one survives when the bath time scale is sufficiently short. The developed framework offers a unified and analytically tractable approach that can be readily applied to other multi-step thermal protocols."}
{"id": "2602.02860", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.02860", "abs": "https://arxiv.org/abs/2602.02860", "authors": ["Ruiyan Luo", "Xin Qi"], "title": "Functional regression with multivariate responses", "comment": null, "summary": "We consider the functional regression model with multivariate response and functional predictors. Compared to fitting each individual response variable separately, taking advantage of the correlation between the response variables can improve the estimation and prediction accuracy. Using information in both functional predictors and multivariate response, we identify the optimal decomposition of the coefficient functions for prediction in population level. Then we propose methods to estimate this decomposition and fit the regression model for the situations of a small and a large number $p$ of functional predictors separately. For a large $p$, we propose a simultaneous smooth-sparse penalty which can both make curve selection and improve estimation and prediction accuracy. We provide the asymptotic results when both the sample size and the number of functional predictors go to infinity. Our method can be applied to models with thousands of functional predictors and has been implemented in the R package FRegSigCom."}
{"id": "2602.03272", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03272", "abs": "https://arxiv.org/abs/2602.03272", "authors": ["Nicola Ramseyer", "Matthieu Jacobs", "Mario Paolone"], "title": "Power Reserve Procurement Considering Dependent Random Variables with PCE", "comment": null, "summary": "This paper presents an approach for the modelling of dependent random variables using generalised polynomial chaos. This allows to write chance-constrained optimization problems with respect to a joint distribution modelling dependencies between different stochastic inputs. Arbitrary dependencies are modelled by using Gaussian copulas to construct the joint distribution. The paper exploits the problem structure and develops suitable transformations to ensure tractability. The proposed method is applied to a probabilistic power reserve procurement problem. The effectiveness of the method to capture dependencies is shown by comparing the approach with a standard approach considering independent random variables."}
{"id": "2602.02695", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.02695", "abs": "https://arxiv.org/abs/2602.02695", "authors": ["Wilke Dononelli"], "title": "Integration of Variational Quantum Algorithms into Atomistic Simulation Workflows", "comment": null, "summary": "In this work, we present the integration of Qiskit Nature's quantum chemistry solvers into the Atomic Simulation Environment (ASE), enabling hybrid quantum-classical workflows for force-driven atomistic simulations. This coupling allows the use of the Variational Quantum Eigensolver (VQE) and its adaptive variant (ADAPT-VQE) not only for ground-state energy calculations, but also for geometry optimisation, vibrational frequency analysis, strain evaluation, and molecular dynamics, all managed through ASE's calculator interface. By applying ADAPT-VQE to multi-electron systems such as BeH2, we obtain vibrational and structural properties in close agreement with high-level classical CCSD calculations within the same minimal basis. These results demonstrate that adaptive variational quantum algorithms can deliver stable and chemically meaningful forces within an atomistic modelling workflow, enabling downstream applications such as molecular dynamics and active-learning accelerated simulations."}
{"id": "2602.03166", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.03166", "abs": "https://arxiv.org/abs/2602.03166", "authors": ["Arun Govind Neelan"], "title": "Event-Level Probabilistic Prediction of Extreme Rainfall over India Using Physics-Gated Latent Dynamics", "comment": null, "summary": "Extreme rainfall over the Indian monsoon region poses severe societal and infrastructural risks but remains difficult to predict at daily time scales due to stochastic convective triggering and multiscale atmospheric interactions. While large-scale atmospheric fields provide important environmental context, their ability to localize extreme rainfall events is fundamentally limited. In this study, we examine how large-scale atmospheric information from ERA5 reanalysis can be leveraged for event-level probabilistic prediction of daily rainfall extremes over India. We compare an adaptive ConvLSTM baseline with a proposed Physics-Gated Latent Ordinary Differential Equation (PG-LODE) framework, which models atmospheric evolution as a continuous-time latent process whose dynamics are explicitly modulated by a physics-based gating mechanism under convectively unstable conditions. Extreme events are defined using the local 95th percentile of the India Meteorological Department gridded rainfall dataset during the June to September monsoon season. Pixel-wise evaluation shows limited skill for both models due to spatial displacement errors, whereas event-level tile-based verification reveals a clear performance contrast. The ConvLSTM remains highly conservative, detecting only 27 percent of extreme events, while PG-LODE achieves near-complete detection with a substantially higher critical success index and a moderate false alarm rate. These results demonstrate that physics-gated continuous-time latent dynamics offer a robust pathway for translating large-scale atmospheric predictability into reliable assessments of extreme rainfall risk."}
{"id": "2602.02875", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.02875", "abs": "https://arxiv.org/abs/2602.02875", "authors": ["F. A. Shiha"], "title": "Shiha Distribution: Statistical Properties and Applications to Reliability Engineering and Environmental Data", "comment": null, "summary": "This paper introduces a new two-parameter distribution, referred to as the Shiha distribution, which provides a flexible model for skewed lifetime data with either heavy or light tails. The proposed distribution is applicable to various fields, including reliability engineering, environmental studies, and related areas. We derive its main statistical properties, including the moment generating function, moments, hazard rate function, quantile function, and entropy. The stress--strength reliability parameter is also derived in closed form. A simulation study is conducted to evaluate its performance. Applications to several real data sets demonstrate that the Shiha distribution consistently provides a superior fit compared with established competing models, confirming its practical effectiveness for lifetime data analysis."}
{"id": "2602.03287", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.03287", "abs": "https://arxiv.org/abs/2602.03287", "authors": ["Michelle Ocker", "Robert Möller", "Marius Peters", "Franziska Walther", "Vivien Kirschall", "Dominik C. Hezel", "Michael Merz", "Christo Guguschev", "Cornelius Krellner", "Kristin Kliemt"], "title": "Single crystal growth and properties of Au- and Ge-substituted EuPd$_2$Si$_2$", "comment": null, "summary": "We report on the single crystal growth of Eu(Pd$_{1-x}$Au$_x$)$_2$Si$_2$, $0< x\\leq 0.2$, from a levitating Eu-rich melt using the Czochralski method. Our structural analysis of the samples confirms the ThCr$_2$Si$_2$-type structure as well as an increase of the room temperature $a$ and $c$ lattice parameters with increasing $x$. Chemical analysis reveals that, depending on the Au concentration, only about 25-35\\% of the amount of Au available in the initial melt is incorporated into the crystal structure, resulting in a decreasing substitution level for increasing $x$. Through Au substitution, chemical pressure is applied and large changes in valence crossover temperatures are already observed for low substitution levels $x$. In contrast to previous studies, we do not find any signs of a first-order transition in samples with $x_{\\rm nom}=0.1$ or AFM order for higher $x$. Furthermore, we observe the formation of quarternary side phases for a higher amount of Au in the melt.\n  In addition, cubic-mm-sized single crystals of EuPd$_2$(Si$_{1-x}$Ge$_x$)$_2$ with $x_{\\rm nom}=0.2$ were grown. The analysis of the X-ray fluorescence revealed that the crystals exhibit a slight variation in the Ge content. Such tiny compositional changes can cause changes in the sample properties concerning variations of the crossover temperature or changes of the type of the transition from crossover to magnetic order. Furthermore, we report on a new orthorhombic phase EuPd$_{1.42}$Si$_{1.27}$Ge$_{0.31}$ that orders antiferromagnetically below $17\\,\\rm K$."}
{"id": "2602.02598", "categories": ["physics.soc-ph", "cs.AI", "cs.CL", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.02598", "abs": "https://arxiv.org/abs/2602.02598", "authors": ["Yueqing Hu", "Yixuan Jiang", "Zehua Jiang", "Xiao Wen", "Tianhong Wang"], "title": "Social Catalysts, Not Moral Agents: The Illusion of Alignment in LLM Societies", "comment": "7 pages, 5 figures", "summary": "The rapid evolution of Large Language Models (LLMs) has led to the emergence of Multi-Agent Systems where collective cooperation is often threatened by the \"Tragedy of the Commons.\" This study investigates the effectiveness of Anchoring Agents--pre-programmed altruistic entities--in fostering cooperation within a Public Goods Game (PGG). Using a full factorial design across three state-of-the-art LLMs, we analyzed both behavioral outcomes and internal reasoning chains. While Anchoring Agents successfully boosted local cooperation rates, cognitive decomposition and transfer tests revealed that this effect was driven by strategic compliance and cognitive offloading rather than genuine norm internalization. Notably, most agents reverted to self-interest in new environments, and advanced models like GPT-4.1 exhibited a \"Chameleon Effect,\" masking strategic defection under public scrutiny. These findings highlight a critical gap between behavioral modification and authentic value alignment in artificial societies."}
{"id": "2602.03526", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.03526", "abs": "https://arxiv.org/abs/2602.03526", "authors": ["Hossein Safi", "Rizwana Ahmad", "Iman Tavakkolnia", "Harald Haas"], "title": "Q-Learning for 3D Coverage in VCSEL-based Optical Wireless Systems", "comment": "Accepted for oral presentation at the IEEE ICC 2026 symposium", "summary": "Beam divergence control is a key factor in maintaining reliable coverage in indoor optical wireless communication (OWC) systems as receiver height varies.Conventional systems employ fixed divergence angles, which result in significant coverage degradation due to the non-convex tradeoff between optical power concentration and spatial spread. In this paper, we introduce a reinforcement learning (RL)-based framework for dynamic divergence adaptation in vertical-cavity surface-emitting laser (VCSEL)-based OWC networks. By continuously interacting with the environment, the RL agent autonomously learns a near-optimal mapping between receiver height and beam divergence, thereby eliminating the need for analytical modeling or computationally intensive exhaustive search. Simulation results demonstrate that the proposed approach achieves up to 92% coverage at low receiver heights and maintains robust performance under challenging conditions, enabling scalable, real-time, and energy-efficient beam control for dense VCSEL array deployments in next-generation OWC systems."}
{"id": "2602.03346", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03346", "abs": "https://arxiv.org/abs/2602.03346", "authors": ["Sreeshma Markkassery", "Ton van den Boom", "Bart De Schutter"], "title": "Dynamics of Implicit Time-Invariant Max-Min-Plus-Scaling Discrete-Event Systems", "comment": "12 pages, Under review at Automatica", "summary": "Max-min-plus-scaling (MMPS) systems generalize max-plus, min-plus and max-min-plus models with more flexibility in modelling discrete-event dynamics. Especially, implicit MMPS models capture a wide range of real world discrete-event applications. This article analyzes the dynamics of an autonomous, time-invariant implicit MMPS system in a discrete-event framework. First, we provide sufficient conditions under which an implicit MMPS system admits at least one solution to its state-space representation. Then, we analyze its global behavior by determining the key parameters; the growth rates and fixed points. For a solvable MMPS system, we assess the local behavior of the system around its set of fixed points via a normalization procedure. Further, we present the notion of stability for the normalized system. A case study of the urban railway network substantiates the theoretical results."}
{"id": "2602.02624", "categories": ["cs.SI", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.02624", "abs": "https://arxiv.org/abs/2602.02624", "authors": ["Paul Bouchaud", "Pedro Ramaciotti"], "title": "Recommender system in X inadvertently profiles ideological positions of users", "comment": null, "summary": "Studies on recommendations in social media have mainly analyzed the quality of recommended items (e.g., their diversity or biases) and the impact of recommendation policies (e.g., in comparison with purely chronological policies). We use a data donation program, collecting more than 2.5 million friend recommendations made to 682 volunteers on X over a year, to study instead how real-world recommenders learn, represent and process political and social attributes of users inside the so-called black boxes of AI systems. Using publicly available knowledge on the architecture of the recommender, we inferred the positions of recommended users in its embedding space. Leveraging ideology scaling calibrated with political survey data, we analyzed the political position of users in our study (N=26,509 among volunteers and recommended contacts) among several attributes, including age and gender. Our results show that the platform's recommender system produces a spatial ordering of users that is highly correlated with their Left-Right positions (Pearson rho=0.887, p-value < 0.0001), and that cannot be explained by socio-demographic attributes. These results open new possibilities for studying the interaction between human and AI systems. They also raise important questions linked to the legal definition of algorithmic profiling in data privacy regulation by blurring the line between active and passive profiling. We explore new constrained recommendation methods enabled by our results, limiting the political information in the recommender as a potential tool for privacy compliance capable of preserving recommendation relevance."}
{"id": "2602.03800", "categories": ["cond-mat.stat-mech", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.03800", "abs": "https://arxiv.org/abs/2602.03800", "authors": ["Iván Álvarez Domenech", "Javier Rodríguez-Laguna", "Pedro Córdoba-Torres", "Silvia N. Santalla"], "title": "Emergent correlations in the selected link-times along optimal paths", "comment": null, "summary": "In the context of first-passage percolation (FPP), we investigate the statistical properties of the selected link-times (SLTs) -the random link times comprising the optimal paths (or geodesics) connecting two given points. We focus on weakly disordered square lattices, whose geodesics are known to fall under the Kardar-Parisi-Zhang (KPZ) universality class. Our analysis reveals universal power-law decays with the end-to-end distance for both the average and standard deviation of the SLTs, along with an intricate pattern of long-range correlations, whose scaling exponents are directly linked to KPZ universality. Crucially, the SLT distributions for diagonal and axial paths exhibit significant differences, which we trace back to the distinct directed and undirected nature, respectively, of the underlying geodesics. Moreover, we demonstrate that the SLT distribution violates the conditions of the central limit theorem. Instead, SLT sums follow the Tracy-Widom distribution characteristic of the KPZ class, which we associate with evidence for the emergence of high-order long-range correlations in the ensemble."}
{"id": "2602.02875", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.02875", "abs": "https://arxiv.org/abs/2602.02875", "authors": ["F. A. Shiha"], "title": "Shiha Distribution: Statistical Properties and Applications to Reliability Engineering and Environmental Data", "comment": null, "summary": "This paper introduces a new two-parameter distribution, referred to as the Shiha distribution, which provides a flexible model for skewed lifetime data with either heavy or light tails. The proposed distribution is applicable to various fields, including reliability engineering, environmental studies, and related areas. We derive its main statistical properties, including the moment generating function, moments, hazard rate function, quantile function, and entropy. The stress--strength reliability parameter is also derived in closed form. A simulation study is conducted to evaluate its performance. Applications to several real data sets demonstrate that the Shiha distribution consistently provides a superior fit compared with established competing models, confirming its practical effectiveness for lifetime data analysis."}
{"id": "2602.03346", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03346", "abs": "https://arxiv.org/abs/2602.03346", "authors": ["Sreeshma Markkassery", "Ton van den Boom", "Bart De Schutter"], "title": "Dynamics of Implicit Time-Invariant Max-Min-Plus-Scaling Discrete-Event Systems", "comment": "12 pages, Under review at Automatica", "summary": "Max-min-plus-scaling (MMPS) systems generalize max-plus, min-plus and max-min-plus models with more flexibility in modelling discrete-event dynamics. Especially, implicit MMPS models capture a wide range of real world discrete-event applications. This article analyzes the dynamics of an autonomous, time-invariant implicit MMPS system in a discrete-event framework. First, we provide sufficient conditions under which an implicit MMPS system admits at least one solution to its state-space representation. Then, we analyze its global behavior by determining the key parameters; the growth rates and fixed points. For a solvable MMPS system, we assess the local behavior of the system around its set of fixed points via a normalization procedure. Further, we present the notion of stability for the normalized system. A case study of the urban railway network substantiates the theoretical results."}
{"id": "2602.02698", "categories": ["quant-ph", "cs.FL"], "pdf": "https://arxiv.org/pdf/2602.02698", "abs": "https://arxiv.org/abs/2602.02698", "authors": ["Armando Bellante", "Reinis Irmejs", "Marta Florido-Llinàs", "María Cea Fernández", "Marianna Crupi", "Matthew Kiser", "J. Ignacio Cirac"], "title": "Compiling Quantum Regular Language States", "comment": "Code available at https://github.com/reinisirmejs/RLSComp", "summary": "State preparation compilers for quantum computers typically sit at two extremes: general-purpose routines that treat the target as an opaque amplitude vector, and bespoke constructions for a handful of well-known state families. We ask whether a compiler can instead accept simple, structure-aware specifications while providing predictable resource guarantees. We answer this by designing and implementing a quantum state-preparation compiler for regular language states (RLS): uniform superpositions over bitstrings accepted by a regular description, and their complements. Users describe the target state via (i) a finite set of bitstrings, (ii) a regular expression, or (iii) a deterministic finite automaton (DFA), optionally with a complement flag. By translating the input to a DFA, minimizing it, and mapping it to an optimal matrix product state (MPS), the compiler obtains an intermediate representation (IR) that exposes and compresses hidden structure. The efficient DFA representation and minimization offloads expensive linear algebra computation in exchange of simpler automata manipulations. The combination of the regular-language frontend and this IR gives concise specifications not only for RLS but also for their complements that might otherwise require exponentially large state descriptions. This enables state preparation of an RLS or its complement with the same asymptotic resources and compile time. We outline two hardware-aware backends: SeqRLSP, which yields linear-depth, ancilla-free circuits for linear nearest-neighbor architectures via sequential generation, and TreeRLSP, which achieves logarithmic depth on all-to-all connectivity via a tree tensor network. We prove depth and gate-count bounds scaling with the system size and the state's maximal Schmidt rank, and we give explicit compile-time bounds that expose the benefit of our approach. We implement and evaluate the pipeline."}
{"id": "2602.03178", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.03178", "abs": "https://arxiv.org/abs/2602.03178", "authors": ["Davit Aslanyan", "Constantine Sideris"], "title": "Fully Automated Adaptive Parameter Selection for 3-D High-order Nyström Boundary Integral Equation Methods", "comment": null, "summary": "We present an adaptive Chebyshev-based Boundary Integral Equation (CBIE) solver for electromagnetic scattering from smooth perfect electric conductor (PEC) objects. The proposed approach eliminates manual parameter tuning by introducing (i) a unified adaptive quadrature strategy for automatic selection of the near-singular interaction distance and (ii) an adaptive computation of all self- and near-singular precomputation integrals to a prescribed accuracy using Gauss-Kronrod (h-adaptive) or Clenshaw-Curtis (p-adaptive) rules and singularity-resolving changes of variables. Both h-adaptive and p-adaptive schemes are explored within this framework, ensuring high-order accuracy and robustness across a broad range of geometries without loss of efficiency. Numerical results for canonical and complex CAD geometries demonstrate that the adaptive solver achieves accuracy and convergence rates comparable to optimally tuned fixed-grid CBIE implementations, while offering automation and scalability to electrically large, geometrically complex problems."}
{"id": "2602.03326", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.03326", "abs": "https://arxiv.org/abs/2602.03326", "authors": ["Margherita Parodi", "Sergey Artyukhin"], "title": "Thermal conductivity in noncollinear magnets", "comment": "8 pages, 2 figures", "summary": "Magnetic memory and logic devices, including prospective ones based on skyrmions, inevitably produce heat. Thus, controlling heat flow is essential for their performance. Here we study how non-collinear spin arrangement affects the magnon contribution to thermal conductivity. As a paradigm system, we consider the most basic non-collinear magnet with a spin spiral ground state. Spin noncollinearity leads to anharmonic terms, resulting in magnon fusion and decay processes. These processes determine the magnon lifetime, which can be used to estimate thermal conductivity in a single-mode approximation. However, by solving the full Boltzmann equation numerically, we find a much higher thermal conductivity. This signifies that heat is carried not by individual magnons but by their linear combinations -- relaxons. The thermal conductivity is found to increase with the diminishing spiral pitch, consistent with recent experiments. The results provide the blueprint for calculating magnetic thermal transport in non-collinear magnets."}
{"id": "2602.02967", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.02967", "abs": "https://arxiv.org/abs/2602.02967", "authors": ["Ruofeng Rao", "Sarana Photchanachan"], "title": "Influence Mechanism Of Environmental Stimulus And Consumer Ethnocentrism On Purchasing Wuliangye: Applications Of Extended Theory Of Planned Behavior (ETPB) And Stimulus-Organism-Response (SOR) Theory", "comment": null, "summary": "Environmental stimuli play a pivotal role in triggering impulsive purchases among consumers,while consumers from Sichuan Province, China, exhibit strong ethnocentric tendencies, impacting their decision-making process, particularly regarding Wuliangye liquor, a local product. Through an online survey of 453 Wuliangye consumers from Sichuan, an analysis was conducted using structural equation modeling rooted in the ETPB and SOR theory. This analysis revealed the favorable impact of environmental stimuli and consumer ethnocentrism on purchasing behavior. This influence was found to be partially mediated through perceived value, attitudes, and purchase intention, forming a chain-mediated effect. Notably, purchase intention doesn't always translate to actual buying behavior, with environmental stimuli, consumer ethnocentrism, perceived behavioral control and purchase intention all being robust predictors of purchase behavior. Finally, several management strategies were proposed, aimed at bolstering Wuliangye sales, with a focus on platform development, mid-to-low range product creation, and appealing to Generation Z consumers."}
{"id": "2602.03763", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.03763", "abs": "https://arxiv.org/abs/2602.03763", "authors": ["Mathias Hudoba de Badyn", "Tyler Summers"], "title": "Optimizing Weighted Hodge Laplacian Flows on Simplicial Complexes", "comment": "6 pages, 4 figures, presented at 2025 Conference on Decision and Control", "summary": "Simplicial complexes are generalizations of graphs that describe higher-order network interactions among nodes in the graph. Network dynamics described by graph Laplacian flows have been widely studied in network science and control theory, and these can be generalized to simplicial complexes using Hodge Laplacians. We study weighted Hodge Laplacian flows on simplicial complexes. In particular, we develop a framework for weighted consensus dynamics based on weighted Hodge Laplacian flows and show some decomposition results for weighted Hodge Laplacians. We then show that two key spectral functions of the weighted Hodge Laplacians, the trace of the pseudoinverse and the smallest non-zero eigenvalue, are jointly convex in upper and lower simplex weights and can be formulated as semidefinite programs. Thus, globally optimal weights can be efficiently determined to optimize flows in terms of these functions. Numerical experiments demonstrate that optimal weights can substantially improve these metrics compared to uniform weights."}
{"id": "2602.03433", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03433", "abs": "https://arxiv.org/abs/2602.03433", "authors": ["Komeil Nosrati", "Aleksei Tepljakov", "Juri Belikov", "Eduard Petlenkov"], "title": "When control meets large language models: From words to dynamics", "comment": null, "summary": "While large language models (LLMs) are transforming engineering and technology through enhanced control capabilities and decision support, they are simultaneously evolving into complex dynamical systems whose behavior must be regulated. This duality highlights a reciprocal connection in which prompts support control system design while control theory helps shape prompts to achieve specific goals efficiently. In this study, we frame this emerging interconnection of LLM and control as a bidirectional continuum, from prompt design to system dynamics. First, we investigate how LLMs can advance the field of control in two distinct capacities: directly, by assisting in the design and synthesis of controllers, and indirectly, by augmenting research workflows. Second, we examine how control concepts help LLMs steer their trajectories away from undesired meanings, improving reachability and alignment via input optimization, parameter editing, and activation-level interventions. Third, we look into deeper integrations by treating LLMs as dynamic systems within a state-space framework, where their internal representations are closely linked to external control loops. Finally, we identify key challenges and outline future research directions to understand LLM behavior and develop interpretable and controllable LLMs that are as trustworthy and robust as their electromechanical counterparts, thereby ensuring they continue to support and safeguard society."}
{"id": "2602.02625", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.02625", "abs": "https://arxiv.org/abs/2602.02625", "authors": ["Md Motaleb Hossen Manik", "Ge Wang"], "title": "OpenClaw Agents on Moltbook: Risky Instruction Sharing and Norm Enforcement in an Agent-Only Social Network", "comment": null, "summary": "Agentic AI systems increasingly operate in shared social environments where they exchange information, instructions, and behavioral cues. However, little empirical evidence exists on how such agents regulate one another in the absence of human participants or centralized moderation. In this work, we present an empirical analysis of OpenClaw agents interacting on Moltbook, an agent-only social network. Analyzing 39,026 posts and 5,712 comments produced by 14,490 agents, we quantify the prevalence of action-inducing instruction sharing using a lexicon-based Action-Inducing Risk Score (AIRS), and examine how other agents respond to such content. We find that 18.4% of posts contain action-inducing language, indicating that instruction sharing is a routine behavior in this environment. While most social responses are neutral, posts containing actionable instructions are significantly more likely to elicit norm-enforcing replies that caution against unsafe or risky behavior, compared to non-instructional posts. Importantly, toxic responses remain rare across both conditions. These results suggest that OpenClaw agents exhibit selective social regulation, whereby potentially risky instructions are more likely to be challenged than neutral content, despite the absence of human oversight. Our findings provide early empirical evidence of emergent normative behavior in agent-only social systems and highlight the importance of studying social dynamics alongside technical safeguards in agentic AI ecosystems."}
{"id": "2602.02587", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "cs.GT", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.02587", "abs": "https://arxiv.org/abs/2602.02587", "authors": ["Gregg Hartvigsen"], "title": "The Evolution of Lying in a Spatially-Explicit Prisoner's Dilemma Model", "comment": "18 pages, 11 figures", "summary": "I present the results from a spatial model of the prisoner's dilemma, played on a toroidal lattice. Each individual has a default strategy of either cooperating ($C$) or defecting ($D$). Two strategies were tested, including ``tit-for-tat'' (TFT), in which individuals play their opponent's last play, or simply playing their default play. Each individual also has a probability of telling the truth ($0 \\leq P_{truth} \\leq 1$) about their last play. This parameter, which can evolve over time, allows individuals to be, for instance, a defector but present as a cooperator regarding their last play. This leads to interesting dynamics where mixed populations of defectors and cooperators with $P_{truth} \\geq 0.75$ move toward populations of truth-telling cooperators. Likewise, mixed populations with $P_{truth} < 0.7$ become populations of lying defectors. Both such populations are stable because they each have higher average scores than populations with intermediate values of $P_{truth}$. Applications of this model are discussed with regards to both humans and animals."}
{"id": "2602.02931", "categories": ["stat.ME", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02931", "abs": "https://arxiv.org/abs/2602.02931", "authors": ["Kevin McCoy", "Zachary Wooten", "Katarzyna Tomczak", "Christine B. Peterson"], "title": "Weighted Sum-of-Trees Model for Clustered Data", "comment": "14 pages, 8 figures, 3 tables", "summary": "Clustered data, which arise when observations are nested within groups, are incredibly common in clinical, education, and social science research. Traditionally, a linear mixed model, which includes random effects to account for within-group correlation, would be used to model the observed data and make new predictions on unseen data. Some work has been done to extend the mixed model approach beyond linear regression into more complex and non-parametric models, such as decision trees and random forests. However, existing methods are limited to using the global fixed effects for prediction on data from out-of-sample groups, effectively assuming that all clusters share a common outcome model. We propose a lightweight sum-of-trees model in which we learn a decision tree for each sample group. We combine the predictions from these trees using weights so that out-of-sample group predictions are more closely aligned with the most similar groups in the training data. This strategy also allows for inference on the similarity across groups in the outcome prediction model, as the unique tree structures and variable importances for each group can be directly compared. We show our model outperforms traditional decision trees and random forests in a variety of simulation settings. Finally, we showcase our method on real-world data from the sarcoma cohort of The Cancer Genome Atlas, where patient samples are grouped by sarcoma subtype."}
{"id": "2602.03433", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03433", "abs": "https://arxiv.org/abs/2602.03433", "authors": ["Komeil Nosrati", "Aleksei Tepljakov", "Juri Belikov", "Eduard Petlenkov"], "title": "When control meets large language models: From words to dynamics", "comment": null, "summary": "While large language models (LLMs) are transforming engineering and technology through enhanced control capabilities and decision support, they are simultaneously evolving into complex dynamical systems whose behavior must be regulated. This duality highlights a reciprocal connection in which prompts support control system design while control theory helps shape prompts to achieve specific goals efficiently. In this study, we frame this emerging interconnection of LLM and control as a bidirectional continuum, from prompt design to system dynamics. First, we investigate how LLMs can advance the field of control in two distinct capacities: directly, by assisting in the design and synthesis of controllers, and indirectly, by augmenting research workflows. Second, we examine how control concepts help LLMs steer their trajectories away from undesired meanings, improving reachability and alignment via input optimization, parameter editing, and activation-level interventions. Third, we look into deeper integrations by treating LLMs as dynamic systems within a state-space framework, where their internal representations are closely linked to external control loops. Finally, we identify key challenges and outline future research directions to understand LLM behavior and develop interpretable and controllable LLMs that are as trustworthy and robust as their electromechanical counterparts, thereby ensuring they continue to support and safeguard society."}
{"id": "2602.02750", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.02750", "abs": "https://arxiv.org/abs/2602.02750", "authors": ["Xianlong Liu", "Jie-ping Zheng", "Antonio M. García-García"], "title": "Inducing, and enhancing, many-body quantum chaos by continuous monitoring", "comment": "12 pages, 9 figures + supplemental material", "summary": "It is intuitively expected, and supported by earlier studies, that many-body quantum chaos is suppressed, or even destroyed, by dissipative effects induced by continuous monitoring. We show here that this is not always the case. For this purpose, we study the quenched dynamics of a continuously monitored Sachdev-Ye-Kitaev (SYK) model, described by the Lindblad formalism, coupled to a thermal environment modeled by another SYK maintained at constant temperature. We find that the combined effect of monitoring and the thermal bath drives the system toward a non-thermal steady state independently of the initial conditions. The corresponding retarded Green's function exhibits two stages of exponential decay, with rates that depend non-monotonously on the thermal bath coupling and the monitoring strength. In the limit of weak coupling, the late time decay of the Green's function, computed analytically, is closely related to that of the thermal bath. Strikingly, we identify a range of parameters in which continuous monitoring, despite being a source of decoherence, induces or enhances quantum chaotic dynamics suppressed by the thermal bath. For instance, in the limit of weak coupling to the thermal bath, the Lyapunov exponent increases sharply when monitoring is turned on. For intermediate values of the thermal bath coupling, the Lyapunov exponent exhibits re-entrant behavior: it vanishes at zero or sufficiently weak monitoring strength, and becomes positive again as the monitoring strength is increased. Our results offer intriguing insights on the mechanisms leading to quantum scrambling which paves the way to its experimental control and consequently to a performance enhancement of quantum information devices."}
{"id": "2602.03239", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.03239", "abs": "https://arxiv.org/abs/2602.03239", "authors": ["Wenli Wang", "Duo Liu", "Gangrong Qu", "Michiel E. Hochstenbach"], "title": "Deterministic and randomized Kaczmarz methods for $AXB=C$ with applications to color image restoration", "comment": null, "summary": "We study Kaczmarz type methods to solve consistent linear matrix equations. We first present a block Kaczmarz (BK) method that employs a deterministic cyclic row selection strategy. Assuming that the associated coefficient matrix has full column or row rank, we derive matrix formulas for a cycle of this BK method. Moreover, we propose a greedy randomized block Kaczmarz (GRBK) method and further extend it to a relaxed variant (RGRBK) and a deterministic counterpart (MWRBK). We establish the convergence properties of the proposed methods. Numerical tests verify the theoretical findings, and we apply the proposed methods to color image restoration problems."}
{"id": "2602.03598", "categories": ["cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.03598", "abs": "https://arxiv.org/abs/2602.03598", "authors": ["Xavier Waintal"], "title": "Calculating Feynman diagrams with matrix product states", "comment": "27 pages, 16 figures. arXiv admin note: text overlap with arXiv:2601.03035", "summary": "This text reviews, hopefully in a pedagogical manner, a series of work on the automatic calculations of Feynman diagrams in the context of quantum nanoelectronics (Keldysh formalism) with an application to the Kondo effect in the out-of-equilibrium single impurity Anderson model. It includes a discussion of (A) how to deal with the proliferation of diagrams, (B) how to calculate them using the Tensor Cross Interpolation algorithm instead of Monte-Carlo and (C) how to resum the obtained series. These notes correspond to a lecture given at the Autumn School on Correlated Electrons 2025 in Jullich, Germany. The book with all the lectures of the school (edited by Eva Pavarini, Erik Koch, Alexander Lichtenstein, and Dieter Vollhardt) is available in open access."}
{"id": "2602.03620", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.03620", "abs": "https://arxiv.org/abs/2602.03620", "authors": ["Sabin Roman", "Francesco Bertolotti"], "title": "Toward a new AI winter? How diffusion of technological innovation on networks leads to chaotic boom-bust cycles", "comment": null, "summary": "Technological developments and the impact of artificial intelligence (AI) are omnipresent themes and concerns of the present day. Much has been written on these topics but applications of quantitative models to understand the techno-social landscape have been much more limited. We propose a mathematical model that can help understand in a unified manner the patterns underlying technological development and also identify the different regimes in which the technological landscape evolves. First, we develop a model of innovation diffusion between different technologies, the growth of each reinforcing the development of the others. The model has a variable that quantifies the level of development (or innovation, discovery) potential for a given technology. The potential, or market capacity, increases via diffusion from related technologies, reflecting the fact that a technology does not develop in isolation. Hence, the growth of each technology is influenced by how developed its neighboring (related) technologies are. This allows us to reproduce long-term trends seen in computing technology and large language models (LLMs). We then present a three-dimensional system of supply, demand, and investment which shows oscillations (business cycles) emerging if investment is too high into a given technology, product, or market. We finally combine the two models through a common variable and show that if investment or diffusion is too high in the network context, chaotic boom-bust cycles can emerge. These quantitative considerations allow us to reproduce the boom-bust patterns seen in non-fungible token (NFT) transaction data and also have deep implications for the development of AI which we highlight, such as the arrival of a new AI winter."}
{"id": "2602.03691", "categories": ["eess.SY", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.03691", "abs": "https://arxiv.org/abs/2602.03691", "authors": ["Max H. Cohen", "Pio Ong", "Aaron D. Ames"], "title": "Input-to-State Safe Backstepping: Robust Safety-Critical Control with Unmatched Uncertainties", "comment": "To appear at the 2026 American Control Conference", "summary": "Guaranteeing safety in the presence of unmatched disturbances -- uncertainties that cannot be directly canceled by the control input -- remains a key challenge in nonlinear control. This paper presents a constructive approach to safety-critical control of nonlinear systems with unmatched disturbances. We first present a generalization of the input-to-state safety (ISSf) framework for systems with these uncertainties using the recently developed notion of an Optimal Decay CBF, which provides more flexibility for satisfying the associated Lyapunov-like conditions for safety. From there, we outline a procedure for constructing ISSf-CBFs for two relevant classes of systems with unmatched uncertainties: i) strict-feedback systems; ii) dual-relative-degree systems, which are similar to differentially flat systems. Our theoretical results are illustrated via numerical simulations of an inverted pendulum and planar quadrotor."}
{"id": "2602.03521", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03521", "abs": "https://arxiv.org/abs/2602.03521", "authors": ["Manuel Treutlein", "Pascal Bothe", "Marc Schmidt", "Roman Hahn", "Oliver Neumann", "Ralf Mikut", "Veit Hagenmeyer"], "title": "Real-world energy data of 200 feeders from low-voltage grids with metadata in Germany over two years", "comment": "20 pages, 6 Figures, 6 Tables. Data is available on Zenodo: https://zenodo.org/records/17831177", "summary": "The last mile of the distribution grid is crucial for a successful energy transition, as more low-carbon technology like photovoltaic systems, heat pumps, and electric vehicle chargers connect to the low-voltage grid. Despite considerable challenges in operation and planning, researchers often lack access to suitable low-voltage grid data. To address this, we present the FeederBW dataset with data recorded by the German distribution system operator Netze BW. It offers real-world energy data from 200 low-voltage feeders over two years (2023-2025) with weather information and detailed metadata, including changes in low-carbon technology installations. The dataset includes feeder-specific details such as the number of housing units, installed power of low-carbon technology, and aggregated industrial energy data. Furthermore, high photovoltaic feed-in and one-minute temporal resolution makes the dataset unique. FeederBW supports various applications, including machine learning for load forecasting, conducting non-intrusive load monitoring, generating synthetic data, and analyzing the interplay between weather, feeder measurements, and metadata. The dataset reveals insightful patterns and clearly reflects the growing impact of low-carbon technology on low-voltage grids."}
{"id": "2602.02754", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.02754", "abs": "https://arxiv.org/abs/2602.02754", "authors": ["Alejandro Cuevas", "Manoel Horta Ribeiro"], "title": "Deepfake Pornography is Resilient to Regulatory and Platform Shocks", "comment": "13 pages, 4 figures. Under submission", "summary": "Generative artificial intelligence tools have made it easier to create realistic, synthetic non-consensual explicit imagery (popularly known as deepfake pornography; hereinafter SNCEI) of people. Once created, this SNCEI is often shared on various websites, causing significant harm to victims. This emerging form of sexual abuse was recently criminalized in the US at the federal level by S.146, the TAKE IT DOWN Act. A week after the bill's passage became effectively imminent, the MrDeepfakes website -- one of the most notorious facilitators of SNCEI creation and dissemination -- shut down. Here, we explore the impact of the bill's passage and the subsequent shutdown as a compound intervention on the dissemination of SNCEI. We select three online forums where sexually explicit content is shared, each containing dedicated subforums to organize various types of sexually explicit content. By leveraging each forum's design, we compare activity in subforums dedicated to SNCEI with that in other pornographic genres using a synthetic control, quasi-experimental approach. Across websites, we observed an increase in the sharing and requests for SNCEI, and, in some cases, in new contributors. These results indicate that the compound intervention did not suppress SNCEI activity overall but instead coincided with its redistribution across platforms, with substantial heterogeneity in timing and magnitude. Together, our findings suggest that deplatforming and regulatory signals alone may shift where and when SNCEI is produced and shared, rather than reducing its prevalence."}
{"id": "2602.02648", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.02648", "abs": "https://arxiv.org/abs/2602.02648", "authors": ["Yasamin Panahi", "Subhayan Sahu", "Naren Manjunath", "Chong Wang"], "title": "Quantum criticality at strong randomness: a lesson from anomaly", "comment": "5+13 pages, 8 figures", "summary": "Quantum criticality in the presence of strong quenched randomness remains a challenging topic in modern condensed matter theory. We show that the topology and anomaly associated with average symmetry can be used to predict certain nontrivial universal properties. Our focus is on systems subject to average Lieb--Schultz--Mattis constraints, where lattice translation symmetry is preserved only on average, while on-site symmetries remain exact. We argue that in the absence of spontaneous symmetry breaking, the system must exhibit critical correlations of local operators in two distinct ways: (i) for some operator $O_e$ charged under exact symmetries, the first absolute moment correlation $\\overline{|\\langle O_e(x)O^{\\dagger}_e(y)\\rangle|}$ decays slowly; and (ii) for some operator $O_a$ charged under average symmetries, the first-moment correlation $\\overline{\\langle O_a(x)O^{\\dagger}_a(y)\\rangle}$ decays slowly. We verify these predictions in a few examples: the random-singlet Heisenberg spin chain in one dimension, and the disordered free-fermion critical states in symmetry class BDI in one and two dimensions. Surprisingly, even for these well-studied systems, our anomaly-based argument reveals critical correlations overlooked in previous literature. We also discuss the experimental feasibility of measuring these critical correlations."}
{"id": "2602.03077", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.03077", "abs": "https://arxiv.org/abs/2602.03077", "authors": ["Ziang Zhang", "Peter Carbonetto", "Matthew Stephens"], "title": "Empirical Bayes Shrinkage of Functional Effects, with Application to Analysis of Dynamic eQTLs", "comment": null, "summary": "We introduce functional adaptive shrinkage (FASH), an empirical Bayes method for joint analysis of observation units in which each unit estimates an effect function at several values of a continuous condition variable. The ideas in this paper are motivated by dynamic expression quantitative trait locus (eQTL) studies, which aim to characterize how genetic effects on gene expression vary with time or another continuous condition. FASH integrates a broad family of Gaussian processes defined through linear differential operators into an empirical Bayes shrinkage framework, enabling adaptive smoothing and borrowing of information across units. This provides improved estimation of effect functions and principled hypothesis testing, allowing straightforward computation of significance measures such as local false discovery and false sign rates. To encourage conservative inferences, we propose a simple prior- adjustment method that has theoretical guarantees and can be more broadly used with other empirical Bayes methods. We illustrate the benefits of FASH by reanalyzing dynamic eQTL data on cardiomyocyte differentiation from induced pluripotent stem cells. FASH identified novel dynamic eQTLs, revealed diverse temporal effect patterns, and provided improved power compared with the original analysis. More broadly, FASH offers a flexible statistical framework for joint analysis of functional data, with applications extending beyond genomics. To facilitate use of FASH in dynamic eQTL studies and other settings, we provide an accompanying R package at https: //github.com/stephenslab/fashr."}
{"id": "2602.03521", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03521", "abs": "https://arxiv.org/abs/2602.03521", "authors": ["Manuel Treutlein", "Pascal Bothe", "Marc Schmidt", "Roman Hahn", "Oliver Neumann", "Ralf Mikut", "Veit Hagenmeyer"], "title": "Real-world energy data of 200 feeders from low-voltage grids with metadata in Germany over two years", "comment": "20 pages, 6 Figures, 6 Tables. Data is available on Zenodo: https://zenodo.org/records/17831177", "summary": "The last mile of the distribution grid is crucial for a successful energy transition, as more low-carbon technology like photovoltaic systems, heat pumps, and electric vehicle chargers connect to the low-voltage grid. Despite considerable challenges in operation and planning, researchers often lack access to suitable low-voltage grid data. To address this, we present the FeederBW dataset with data recorded by the German distribution system operator Netze BW. It offers real-world energy data from 200 low-voltage feeders over two years (2023-2025) with weather information and detailed metadata, including changes in low-carbon technology installations. The dataset includes feeder-specific details such as the number of housing units, installed power of low-carbon technology, and aggregated industrial energy data. Furthermore, high photovoltaic feed-in and one-minute temporal resolution makes the dataset unique. FeederBW supports various applications, including machine learning for load forecasting, conducting non-intrusive load monitoring, generating synthetic data, and analyzing the interplay between weather, feeder measurements, and metadata. The dataset reveals insightful patterns and clearly reflects the growing impact of low-carbon technology on low-voltage grids."}
{"id": "2602.02792", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.02792", "abs": "https://arxiv.org/abs/2602.02792", "authors": ["Stefan H. Lohaus", "Kay T. Xia", "Yongqiang Cheng", "Ryan G. Hadt"], "title": "Experimental Quantification of Spin-Phonon Coupling in Molecular Qubits using Inelastic Neutron Scattering", "comment": "21 pages, 5 figures, 1 table", "summary": "Electronic spin superposition states enable nanoscale sensing through their sensitivity to the local environment, yet their sensitivity to vibrational motion also limits their coherence times. In molecular spin systems, chemical tunability and atomic-scale resolution are accompanied by a dense, thermally accessible phonon spectrum that introduces efficient spin relaxation pathways. Despite extensive theoretical work, there is little experimental consensus on which vibrational energies dominate spin relaxation or how molecular structure controls spin-phonon coupling (SPC). We present a fully experimental method to quantify SPC coefficients by combining temperature-dependent vibrational spectra from inelastic neutron scattering with spin relaxation rates measured by electron paramagnetic resonance. We apply this framework to two model S = 1/2 systems, copper(II) phthalocyanine (CuPc) and copper(II) octaethylporphyrin (CuOEP). Two distinct relaxation regimes emerge: below 40 K, weakly coupled lattice modes below $50~\\mathrm{cm}^{-1}$ dominate, whereas above 40 K, optical phonons above ~$185~\\mathrm{cm}^{-1}$ become thermally populated and drive relaxation with SPC coefficients nearly three orders of magnitude larger. Structural distortions in CuOEP that break planar symmetry soften the crystal lattice and enhance anharmonic scattering, but also raise the energy of stretching modes at the molecular core where the spins reside. This redistributes vibrational energy toward the molecular periphery and out of plane, ultimately reducing SPC relative to CuPc and enabling room-temperature spin coherence in CuOEP. Although our method does not provide mode-specific SPC coefficients, it quantifies contributions from distinct spectral regions and establishes a broadly applicable, fully experimental link between crystal structure, lattice dynamics, and spin relaxation."}
{"id": "2602.03247", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.03247", "abs": "https://arxiv.org/abs/2602.03247", "authors": ["Qianxing Jia", "Dong Wang"], "title": "Physics informed learning of orthogonal features with applications in solving partial differential equations", "comment": null, "summary": "The random feature method (RFM) constructs approximation spaces by initializing features from generic distributions, which provides universal approximation properties to solve general partial differential equations. However, such standard initializations lack awareness of the underlying physical laws and geometry, which limits approximation. In this work, we propose the Physics-Driven Orthogonal Feature Method (PD-OFM), a framework for constructing feature representations that are explicitly tailored to both the differential operator and the computational domain by pretraining features using physics-informed objectives together with orthogonality regularization. This pretraining strategy yields nearly orthogonal feature bases. We provide both theoretical and empirical evidence that physics-informed pretraining improves the approximation capability of the learned feature space. When employed to solve Helmholtz, Poisson, wave, and Navier-Stokes equations, the proposed method achieves residual errors 2-3 orders of magnitude lower than those of comparable methods. Furthermore, the orthogonality regularization improves transferability, enabling pretrained features to generalize effectively across different source terms and domain geometries for the same PDE."}
{"id": "2602.03600", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.03600", "abs": "https://arxiv.org/abs/2602.03600", "authors": ["Miłosz Rybak", "Benjamin Pestka", "Biplab Bhattacharyya", "Jeff Strasdas", "Adam K. Budniak", "Adi Harchol", "Vitaliy Feyer", "Iulia Cojocariu", "Daniel Baranowski", "Efrat Lifshitz", "Markus Morgenstern", "Magdalena Birowska", "Krzysztof Wohlfeld"], "title": "Evidence for Many-Body States in NiPS$_3$ Revealed by Angle-Resolved Photoelectron Spectroscopy", "comment": "22 pages, 13 figures", "summary": "We present $μ$-ARPES spectra of the Mott-insulating van der Waals antiferromagnet NiPS$_3$. Signatures of strong correlations- such as the onset of atomic or atomic-ligand multiplets and spin-orbit-entangled exciton have been observed in this material by various two-particle spectroscopies, but not previously in photoemission. Our measurements reveal a weakly dispersive feature at the valence-band edge that is absent in DFT+$U$ calculations and remains unchanged across the Néel transition. After critically examining and ruling out alternative interpretations, we show that an exact diagonalization of a NiS$_6$ cluster yields low-energy final-state configurations of mixed multiplet $d^7$ and $d^8\\underline{L}$ character, whose energy differences are consistent with the observed additional feature. This implies that ARPES directly accesses local Ni-S multiplet physics in NiPS$_3$, revealing a many-body structure beyond mean-field theory. Our results confirm that NiPS$_3$ is an excellent model platform in which strong correlations, reduced dimensionality, and covalent metal-ligand bonding jointly shape both two- and single-particle spectroscopies, underscoring the need for a genuinely quantum many-body description of two-dimensional quantum materials."}
{"id": "2602.03676", "categories": ["physics.soc-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.03676", "abs": "https://arxiv.org/abs/2602.03676", "authors": ["Korak Biswas"], "title": "Entropy Geometry and Condensation in Wealth Allocation", "comment": null, "summary": "We develop a statistical framework for wealth allocation in which agents hold discrete units of wealth and macrostates are defined by how wealth is distributed across agents. The structure of the economic state space is characterized through a value convertibility function, which captures how effectively additional wealth can be transformed into productive or meaningful value. The derivative of this function determines the effective number of internally distinct configurations available to an agent at a given wealth level. In a closed setting with fixed total wealth and a fixed number of agents, we show that equilibrium wealth distributions follow directly from unbiased counting of admissible configurations and may display a condensation phenomenon, where a finite fraction of total wealth accumulates onto a single agent once the remaining agents can no longer absorb additional wealth. We then extend the framework to open systems in which both total wealth and the number of agents may vary. By embedding the system within a larger closed environment and analyzing a finite subsystem, we show that exponential weighting in wealth and agent number emerges naturally from counting arguments alone, without invoking explicit optimization or entropy maximization principles. This extension leads to a richer interpretation of wealth concentration: accumulation is no longer driven solely by excess wealth, but by a balance between wealth growth and the system's capacity to accommodate new agents. Condensation arises when this capacity is limited, forcing surplus wealth to concentrate onto a few agents. The framework thus provides a minimal and structurally grounded description of wealth concentration in both closed and open economic settings."}
{"id": "2602.03646", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03646", "abs": "https://arxiv.org/abs/2602.03646", "authors": ["Nico Holzinger", "Matthias Althoff"], "title": "A Comparison of Set-Based Observers for Nonlinear Systems", "comment": "13 pages", "summary": "Set-based state estimation computes sets of states consistent with a system model given bounded sets of disturbances and noise. Bounding the set of states is crucial for safety-critical applications so that one can ensure that all specifications are met. While numerous approaches have been proposed for nonlinear discrete-time systems, a unified evaluation under comparable conditions is lacking. This paper reviews and implements a representative selection of set-based observers within the CORA framework. To provide an objective comparison, the methods are evaluated on common benchmarks, and we examine computational effort, scalability, and the conservatism of the resulting state bounds. This study highlights characteristic trade-offs between observer categories and set representations, as well as practical considerations arising in their implementation. All implementations are made publicly available to support reproducibility and future development. This paper thereby offers the first broad, tool-supported comparison of guaranteed state estimators for nonlinear discrete-time systems."}
{"id": "2602.02838", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02838", "abs": "https://arxiv.org/abs/2602.02838", "authors": ["Philipp J. Schneider", "Lanqin Yuan", "Marian-Andrei Rizoiu"], "title": "Beyond Content: Behavioral Policies Reveal Actors in Information Operations", "comment": null, "summary": "The detection of online influence operations -- coordinated campaigns by malicious actors to spread narratives -- has traditionally depended on content analysis or network features. These approaches are increasingly brittle as generative models produce convincing text, platforms restrict access to behavioral data, and actors migrate to less-regulated spaces. We introduce a platform-agnostic framework that identifies malicious actors from their behavioral policies by modeling user activity as sequential decision processes. We apply this approach to 12,064 Reddit users, including 99 accounts linked to the Russian Internet Research Agency in Reddit's 2017 transparency report, analyzing over 38 million activity steps from 2015-2018. Activity-based representations, which model how users act rather than what they post, consistently outperform content models in detecting malicious accounts. When distinguishing trolls -- users engaged in coordinated manipulation -- from ordinary users, policy-based classifiers achieve a median macro-$F_1$ of 94.9%, compared to 91.2% for text embeddings. Policy features also enable earlier detection from short traces and degrade more gracefully under evasion strategies or data corruption. These findings show that behavioral dynamics encode stable, discriminative signals of manipulation and point to resilient, cross-platform detection strategies in the era of synthetic content and limited data access."}
{"id": "2602.02649", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02649", "abs": "https://arxiv.org/abs/2602.02649", "authors": ["Iao-Fai Io", "Fu-Hsiang Huang", "Chang-Tse Hsieh"], "title": "Non-Hermitian free-fermion critical systems and logarithmic conformal field theory", "comment": "6+12 pages, 1 figure, 1 table", "summary": "Conformal invariance often accompanies criticality in Hermitian systems. However, its fate in non-Hermitian settings is less clear, especially near exceptional points where the Hamiltonian becomes non-diagonalizable. Here we investigate whether a 1+1-dimensional gapless non-Hermitian system can admit a conformal description, focusing on a PT-symmetric free-fermion field theory. Working in the biorthogonal formalism, we identify the conformal structure of this theory by constructing a traceless energy-momentum tensor whose Fourier modes generate a Virasoro algebra with central charge $c=-2$. This yields a non-Hermitian, biorthogonal realization of a logarithmic conformal field theory, in which correlation functions exhibit logarithmic scaling and the spectrum forms Virasoro staggered modules that are characterized by universal indecomposability parameters. We further present a microscopic construction and show how the same conformal data (with finite-size corrections) can be extracted from the lattice model at exceptional-point criticality, thereby supporting the field-theory prediction."}
{"id": "2602.03165", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.03165", "abs": "https://arxiv.org/abs/2602.03165", "authors": ["Anas Cherradi", "Yazid Janati", "Alain Durmus", "Sylvain Le Corff", "Yohan Petetin", "Julien Stoehr"], "title": "Entropic Mirror Monte Carlo", "comment": null, "summary": "Importance sampling is a Monte Carlo method which designs estimators of expectations under a target distribution using weighted samples from a proposal distribution. When the target distribution is complex, such as multimodal distributions in highdimensional spaces, the efficiency of importance sampling critically depends on the choice of the proposal distribution. In this paper, we propose a novel adaptive scheme for the construction of efficient proposal distributions. Our algorithm promotes efficient exploration of the target distribution by combining global sampling mechanisms with a delayed weighting procedure. The proposed weighting mechanism plays a key role by enabling rapid resampling in regions where the proposal distribution is poorly adapted to the target. Our sampling algorithm is shown to be geometrically convergent under mild assumptions and is illustrated through various numerical experiments."}
{"id": "2602.03646", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03646", "abs": "https://arxiv.org/abs/2602.03646", "authors": ["Nico Holzinger", "Matthias Althoff"], "title": "A Comparison of Set-Based Observers for Nonlinear Systems", "comment": "13 pages", "summary": "Set-based state estimation computes sets of states consistent with a system model given bounded sets of disturbances and noise. Bounding the set of states is crucial for safety-critical applications so that one can ensure that all specifications are met. While numerous approaches have been proposed for nonlinear discrete-time systems, a unified evaluation under comparable conditions is lacking. This paper reviews and implements a representative selection of set-based observers within the CORA framework. To provide an objective comparison, the methods are evaluated on common benchmarks, and we examine computational effort, scalability, and the conservatism of the resulting state bounds. This study highlights characteristic trade-offs between observer categories and set representations, as well as practical considerations arising in their implementation. All implementations are made publicly available to support reproducibility and future development. This paper thereby offers the first broad, tool-supported comparison of guaranteed state estimators for nonlinear discrete-time systems."}
{"id": "2602.02868", "categories": ["quant-ph", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2602.02868", "abs": "https://arxiv.org/abs/2602.02868", "authors": ["Lea Gassab", "Onur Pusuluk", "Travis J. A. Craddock"], "title": "Quantum Information Flow in Microtubule Tryptophan Networks", "comment": null, "summary": "Networks of aromatic amino acid residues within microtubules, particularly those formed by tryptophan, may serve as pathways for optical information flow. Ultraviolet excitation dynamics in these networks are typically modeled with effective non-Hermitian Hamiltonians. By extending this approach to a Lindblad master equation that incorporates explicit site geometries and dipole orientations, we track how correlations are generated, routed, and dissipated, while capturing both energy dissipation and information propagation among coupled chromophores. We compare localized injections, fully delocalized preparations, and eigenmode-based initial states. To quantify the emerging quantum-informational structure, we evaluate the $L_1$ norm of coherence, the correlated coherence, and the logarithmic negativity within and between selected chromophore sub-networks. The results reveal a strong dependence of both the direction and persistence of information flow on the type of initial preparation. Superradiant components drive the rapid export of correlations to the environment, whereas subradiant components retain them and slow their leakage. Embedding single tubulin units into larger dimers and spirals reshapes pairwise correlation maps and enables site-selective routing. Scaling to larger ordered lattices strengthens both export and retention channels, whereas static energetic and structural disorder suppresses long-range transport and reduces overall correlation transfer. These findings provide a Lindbladian picture of information flow in cytoskeletal chromophore networks and identify structural and dynamical conditions that transiently preserve nonclassical correlations in microtubules."}
{"id": "2602.03322", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.03322", "abs": "https://arxiv.org/abs/2602.03322", "authors": ["Yanyan Shi", "Christian Lubich"], "title": "Weighted finite difference methods for a nonlinear Klein--Gordon equation with high oscillations in space and time", "comment": null, "summary": "We consider a nonlinear Klein--Gordon equation in the nonrelativistic limit regime with initial data in the form of a modulated highly oscillatory exponential. In this regime of a small scaling parameter $\\varepsilon$, the solution exhibits rapid oscillations in both time and space, posing challenges for numerical approximation. We propose an explicit and an implicit exponentially weighted finite difference method. While the explicit weighted leapfrog method needs to satisfy a CFL-type stability condition, the implicit weighted Crank--Nicolson method is unconditionally stable. Both methods achieve second-order accuracy with time steps and mesh sizes that are not restricted in magnitude by $\\varepsilon$. The methods are uniformly convergent in the range from arbitrarily small to moderately bounded $\\varepsilon$. Numerical experiments illustrate the theoretical results."}
{"id": "2602.03656", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-lat"], "pdf": "https://arxiv.org/pdf/2602.03656", "abs": "https://arxiv.org/abs/2602.03656", "authors": ["Fo-Hong Wang", "Fanjie Sun", "Chenghao He", "Xiao Yan Xu"], "title": "Resolving Quantum Criticality in the Honeycomb Hubbard Model", "comment": "12+20 pages, 6+16 figures", "summary": "The interplay between Dirac fermions and electronic correlations on the honeycomb lattice hosts a fundamental quantum phase transition from a semimetal to a Mott insulator, governed by the Gross-Neveu-Heisenberg (GNH) universality class. Despite its importance, consensus on the precise critical exponents remains elusive due to severe finite-size effects in numerical simulations and the lack of conformal bootstrap benchmarks. Here we try to resolve this long-standing controversy by performing projector determinant quantum Monte Carlo (QMC) simulations on lattices of unprecedented size, reaching 10,368 sites. By developing a novel projected submatrix update algorithm, we achieve a significant algorithmic speedup that enables us to access the thermodynamic limit with high precision. We observe that the fermion anomalous dimension and the correlation length exponent converge rapidly, while the boson anomalous dimension exhibits a systematic size dependence that we resolve via linear extrapolation. To validate our analysis, we perform parallel large-scale simulations of the spinless $t$-$V$ model on the honeycomb lattice, which belongs to the Gross-Neveu-Ising class. Our results for the $t$-$V$ model, including the first QMC determination of the fermion anomalous dimension, show agreement with conformal bootstrap predictions, thereby corroborating the robustness of our methodology. Our work provides state-of-the-art critical exponents for the honeycomb Hubbard model and establishes a systematic finite-size scaling workflow applicable to a broad class of strongly correlated quantum systems, paving the way for resolving other challenging fermionic quantum critical phenomena."}
{"id": "2602.03680", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.03680", "abs": "https://arxiv.org/abs/2602.03680", "authors": ["Fumihiko Ishiyama"], "title": "Instantaneous Spectra Analysis of Pulse Series - Application to Lung Sounds with Abnormalities", "comment": "10 pages, 6 figures.To appear Proc. IEEE CSPA 2026", "summary": "The origin of the \"theoretical limit of time-frequency resolution of Fourier analysis\" is from its numerical implementation, especially from an assumption of \"Periodic Boundary Condition (PBC),\" which was introduced a century ago. We previously proposed to replace this condition with \"Linear eXtrapolation Condition (LXC),\" which does not require periodicity. This feature makes instantaneous spectra analysis of pulse series available, which replaces the short time Fourier transform (STFT). We applied the instantaneous spectra analysis to two lung sounds with abnormalities (crackles and wheezing) and to a normal lung sound, as a demonstration. Among them, crackles contains a random pulse series. The spectrum of each pulse is available, and the spectrogram of pulse series is available with assembling each spectrum. As a result, the time-frequency structure of given pulse series is visualized."}
{"id": "2602.03691", "categories": ["eess.SY", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.03691", "abs": "https://arxiv.org/abs/2602.03691", "authors": ["Max H. Cohen", "Pio Ong", "Aaron D. Ames"], "title": "Input-to-State Safe Backstepping: Robust Safety-Critical Control with Unmatched Uncertainties", "comment": "To appear at the 2026 American Control Conference", "summary": "Guaranteeing safety in the presence of unmatched disturbances -- uncertainties that cannot be directly canceled by the control input -- remains a key challenge in nonlinear control. This paper presents a constructive approach to safety-critical control of nonlinear systems with unmatched disturbances. We first present a generalization of the input-to-state safety (ISSf) framework for systems with these uncertainties using the recently developed notion of an Optimal Decay CBF, which provides more flexibility for satisfying the associated Lyapunov-like conditions for safety. From there, we outline a procedure for constructing ISSf-CBFs for two relevant classes of systems with unmatched uncertainties: i) strict-feedback systems; ii) dual-relative-degree systems, which are similar to differentially flat systems. Our theoretical results are illustrated via numerical simulations of an inverted pendulum and planar quadrotor."}
{"id": "2602.03068", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.03068", "abs": "https://arxiv.org/abs/2602.03068", "authors": ["Mirza Nayeem Ahmed", "Raiyan Abdul Baten"], "title": "From semantic memory to collective creativity: A generative cognitive foundation for social creativity models", "comment": null, "summary": "Simulation-based theory development has yielded powerful insights into collective performance by linking social structure to emergent outcomes, yet it has struggled to extend to collective creativity. Creativity is hard to capture purely at the social level, as novel ideas are generated through cognitive mechanisms. To address this gap, we introduce a multi-level socio-cognitive agent-based framework in which agents share a common semantic vocabulary and substrate but differ in semantic network topology. A single generative parameter tunes semantic modularity, yielding emergent individual differences in ideational breadth. When agents exchange ideation traces, two canonical social-creativity phenomena arise without being imposed: lower pre-interaction ideation overlap predicts larger stimulation gains, and shared inspiration sources induce network-level redundancy. The framework enables mechanistic theory-building about cognition and social structure in collective creativity."}
{"id": "2602.02663", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.02663", "abs": "https://arxiv.org/abs/2602.02663", "authors": ["Preethi Gopalakrishnan", "András Grabarits", "Adolfo del Campo"], "title": "Tailoring Quantum Chaos With Continuous Quantum Measurements", "comment": "5 pages, 2 figures + supplemental material", "summary": "We investigate the role of quantum monitoring in the dynamical manifestations of Hamiltonian quantum chaos. Specifically, we analyze the generalized spectral form factor, defined as the survival probability of a coherent Gibbs state under continuous energy measurements. We show that quantum monitoring can tailor the signatures of quantum chaos in the dynamics, such as the extension of the ramp in the spectral form factor, by varying the measurement strength and detection efficiency. In particular, a typical quantum trajectory obtained by monitoring with unit efficiency exhibits enhanced quantum chaos relative to the average dynamics and to unitary evolution without measurements."}
{"id": "2602.03218", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.03218", "abs": "https://arxiv.org/abs/2602.03218", "authors": ["Hirotada Maeda", "Satoshi Hattori", "Tim Friede"], "title": "Blinded sample size re-estimation accounting for uncertainty in mid-trial estimation", "comment": null, "summary": "For randomized controlled trials to be conclusive, it is important to set the target sample size accurately at the design stage. Comparing two normal populations, the sample size calculation requires specification of the variance other than the treatment effect and misspecification can lead to underpowered studies. Blinded sample size re-estimation is an approach to minimize the risk of inconclusive studies. Existing methods proposed to use the total (one-sample) variance that is estimable from blinded data without knowledge of the treatment allocation. We demonstrate that, since the expectation of this estimator is greater than or equal to the true variance, the one-sample variance approach can be regarded as providing an upper bound of the variance in blind reviews. This worst-case evaluation can likely reduce a risk of underpowered studies. However, blinded reviews of small sample size may still lead to underpowered studies. We propose a refined method accounting for estimation error in blind reviews using an upper confidence limit of the variance. A similar idea had been proposed in the setting of external pilot studies. Furthermore, we developed a method to select an appropriate confidence level so that the re-estimated sample size attains the target power. Numerical studies showed that our method works well and outperforms existing methods. The proposed procedure is motivated and illustrated by recent randomized clinical trials."}
{"id": "2602.03691", "categories": ["eess.SY", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.03691", "abs": "https://arxiv.org/abs/2602.03691", "authors": ["Max H. Cohen", "Pio Ong", "Aaron D. Ames"], "title": "Input-to-State Safe Backstepping: Robust Safety-Critical Control with Unmatched Uncertainties", "comment": "To appear at the 2026 American Control Conference", "summary": "Guaranteeing safety in the presence of unmatched disturbances -- uncertainties that cannot be directly canceled by the control input -- remains a key challenge in nonlinear control. This paper presents a constructive approach to safety-critical control of nonlinear systems with unmatched disturbances. We first present a generalization of the input-to-state safety (ISSf) framework for systems with these uncertainties using the recently developed notion of an Optimal Decay CBF, which provides more flexibility for satisfying the associated Lyapunov-like conditions for safety. From there, we outline a procedure for constructing ISSf-CBFs for two relevant classes of systems with unmatched uncertainties: i) strict-feedback systems; ii) dual-relative-degree systems, which are similar to differentially flat systems. Our theoretical results are illustrated via numerical simulations of an inverted pendulum and planar quadrotor."}
{"id": "2602.02950", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.02950", "abs": "https://arxiv.org/abs/2602.02950", "authors": ["Arick Grootveld", "Haodong Yang", "Nandan Sriranga", "Biao Chen", "Venkata Gandikota", "Jason Pollack"], "title": "Asymptotically Optimal Quantum Universal Quickest Change Detection", "comment": null, "summary": "This paper investigates the quickest change detection of quantum states in a universal setting: specifically, where the post-change quantum state is not known a priori. We establish the asymptotic optimality of a two-stage approach in terms of worst average delay to detection. The first stage employs block POVMs with classical outputs that preserve quantum relative entropy to arbitrary precision. The second stage leverages a recently proposed windowed-CUSUM algorithm that is known to be asymptotically optimal for quickest change detection with an unknown post-change distribution in the classical setting."}
{"id": "2602.03348", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.03348", "abs": "https://arxiv.org/abs/2602.03348", "authors": ["Shaoshuai Chu", "Michael Herty"], "title": "A Comparative Study of Low-Dissipation Numerical Schemes for Hyperbolic Conservation Laws", "comment": "arXiv admin note: substantial text overlap with arXiv:2504.01699", "summary": "This work provides a comparative assessment of several low-dissipation numerical schemes for hyperbolic conservation laws, highlighting their performance relative to the classical Harten-Lax-van Leer (HLL) schemes. The schemes under consideration include the classical Harten-Lax-van Leer-Contact (HLLC), the recently proposed TV flux splitting, the low-dissipation Central-Upwind (LDCU), and the local characteristic decomposition-based Central-Upwind (LCDCU) schemes. These methods are extended to higher orders of accuracy, up to the fifth order, within both finite-volume and finite-difference frameworks. A series of numerical experiments for the one- and two-dimensional Euler equations of gas dynamics are performed to evaluate the accuracy, robustness, and computational efficiency of the studied schemes. The comparison highlights the trade-offs between resolution of contact and shear waves, robustness in the presence of shocks, and computational cost. The investigated low-dissipation schemes show comparable levels of numerical dissipation, with only subtle differences appearing in selected benchmark problems. The results provide practical guidance for selecting efficient low-dissipation solvers for the simulation of complex compressible flows."}
{"id": "2602.03658", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.03658", "abs": "https://arxiv.org/abs/2602.03658", "authors": ["Yidian Li", "Mingxin Zhang", "Xian Du", "Cuiying Pei", "Jieyi Liu", "Houke Chen", "Wenxuan Zhao", "Kaiyi Zhai", "Yinqi Hu", "Senyao Zhang", "Jiawei Shao", "Mingxin Mao", "Yantao Cao", "Jinkui Zhao", "Zhengtai Li", "Dawei Shen", "Yaobo Huang", "Makoto Hashimoto", "Donghui Lu", "Zhongkai Liu", "Yulin Chen", "Hanjie Guo", "Yilin Wang", "Yanpeng Qi", "Lexian Yang"], "title": "Orbital-selective Mottness Driven by Geometric Frustration of Interorbital Hybridization in Pr4Ni3O10", "comment": null, "summary": "The interplay among orbital-selective Mott physics, Hund's coupling, tunable structural motifs, and Kondo-like scattering establishes a compelling paradigm for understanding and engineering correlated multi-orbital systems, as vividly exemplified by nickelate superconductors. Here, using high-resolution angle-resolved photoemission spectroscopy combined with theoretical calculations, we systematically investigate the electronic properties of trilayer nickelates. In La4Ni3O10, we observe pronounced interorbital hybridization, whereas in Pr4Ni3O10, the flat d_(z^2 ) band becomes markedly incoherent and diminishes in spectral weight. By contrast, the dispersive d_(x^2-y^2 ) bands retain coherence in both compounds. This striking incoherence/coherence dichotomy identifies an orbital-selective Mott phase modulated by the interlayer Ni-O-Ni bonding angle. The depletion of the d_(z^2 ) orbitals further frustrates the interorbital hybridization and influences the density-wave transition in Pr4Ni3O10. Moreover, the density-wave gap is substantially reduced in Pr4Ni3O10, likely due to extra scattering channels provided by the local moments of Pr3+ cations. Our findings elucidate the intricate interplay among lattice, orbital, spin, and electronic degrees of freedom and reveal a feasible structural control parameter for the multi-orbital correlated state in trilayer nickelates, which provide a concrete framework for understanding the emergence of superconductivity under high pressure."}
{"id": "2602.03738", "categories": ["physics.soc-ph", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.03738", "abs": "https://arxiv.org/abs/2602.03738", "authors": ["Andrew Nugent", "Carmen Calatayud Fernandez", "Susana N. Gomes"], "title": "Emergent structures in coupled opinion and network dynamics", "comment": null, "summary": "This paper investigates a model of opinion formation on an adaptive social network, consisting of a system of coupled ordinary differential equations for individuals' opinions and corresponding network edge weights. A key driver of the system's behaviour is the form of the interaction function, which determines the strength of interactions based on the distance between individuals' opinions and appears in both opinion and network dynamics. Two cases are examined: in the first the interaction function is always positive and in the second case the interaction function is of bounded-confidence type. In both cases there is positive feedback between opinion clustering and the emergence of community structure in the social network. This is confirmed through analytical results on long-term behaviour, extending existing results for a fixed network, as well as through numerical simulations. Transient network dynamics are also examined through a short-time approximation that captures the `typical' early network dynamics. Each approach improves some aspect of our understanding of the interplay between opinion and network evolution."}
{"id": "2602.03757", "categories": ["eess.SY", "cs.OS"], "pdf": "https://arxiv.org/pdf/2602.03757", "abs": "https://arxiv.org/abs/2602.03757", "authors": ["Arkaprava Sain", "Sunandan Adhikary", "Soumyajit Dey"], "title": "Mitigating Timing-Based Attacks in Real-Time Cyber-Physical Systems", "comment": "12 pages, 10 figures", "summary": "Real-time cyber-physical systems depend on deterministic task execution to guarantee safety and correctness. Unfortunately, this determinism can unintentionally expose timing information that enables adversaries to infer task execution patterns and carry out timing-based attacks targeting safety-critical control tasks. While prior defenses aim to obscure schedules through randomization or isolation, they typically neglect the implications of such modifications on closed-loop control behavior and real-time feasibility. This work studies the problem of securing real-time control workloads against timing inference attacks while explicitly accounting for both schedulability constraints and control performance requirements. We present a scheduling-based mitigation approach that introduces bounded timing perturbations to control task executions in a structured manner, reducing adversarial opportunities without violating real-time guarantees. The framework jointly considers worst-case execution behavior and the impact of execution delays on control performance, enabling the system to operate within predefined safety and performance limits. Through experimental evaluation on representative task sets and control scenarios, the proposed approach demonstrates that exposure to timing-based attacks can be significantly reduced while preserving predictable execution and acceptable control quality."}
{"id": "2602.03089", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.03089", "abs": "https://arxiv.org/abs/2602.03089", "authors": ["Jennifer Golbeck", "Celia Chen", "Alex Leitch"], "title": "\"Why I Took the Blackpill\": A Thematic Analysis of the Radicalization Process in Incel Communities", "comment": "8 pages, 1 figure. Published in Proceedings of the 2025 International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2025), Springer", "summary": "Incels, or \"involuntary celibates\", are an extreme, misogynistic hate group that exists entirely online. Members of the community have been linked to acts of offline violence, including mass shootings. Previous research has engaged with the ideologies and beliefs of incels, but none has looked specifically at the radicalization process. In this paper, we perform a thematic analysis on social media posts where incels describe their own radicalization process. We identified six major themes grouped into four chronological steps: Pre-radicalization (themes of Appearance, Social Isolation, and Psychological issues), Searching for Blame, Radicalization, and Post Radicalization. These results align closely with existing work on radicalization among other extremist groups, bringing incel radicalization inline with a growing body of research on understanding and managing radicalization."}
{"id": "2602.02673", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.02673", "abs": "https://arxiv.org/abs/2602.02673", "authors": ["Francesco Perciavalle", "Francesco Plastina", "Nicola Lo Gullo"], "title": "Floquet-engineered fidelity revivals in the PXP model", "comment": "14 pages, 7 figures", "summary": "We explore the dynamics of the PXP model when subjected to a periodic drive, and unveil the mechanism through which the interplay between spectral properties and initial states governs the emergence of dynamical revivals and their evolution across the space of driving parameters. For Néel-ordered initial states, revivals follow well-defined trajectories in the parameter space of the driving, primarily determined by a dominant quasi-energy spacing in the Floquet spectrum. Initial states interpolating between Néel and fully polarized configurations exhibit hybrid dynamics, which can be controlled by tuning their overlap with Floquet eigenstates via the driving parameters. This control also allows steering different routes for avoiding Floquet thermalization, showing how both initial state choice and driving protocol shape long-lived dynamics in this driven quantum many-body systems."}
{"id": "2602.03483", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.03483", "abs": "https://arxiv.org/abs/2602.03483", "authors": ["Francisco Cuevas-Pacheco", "Jonathan Acosta"], "title": "Kriging for large datasets via penalized neighbor selection", "comment": "Submitted for Journal publication", "summary": "Kriging is a fundamental tool for spatial prediction, but its computational complexity of $O(N^3)$ becomes prohibitive for large datasets. While local kriging using $K$-nearest neighbors addresses this issue, the selection of $K$ typically relies on ad-hoc criteria that fail to account for spatial correlation structure. We propose a penalized kriging framework that incorporates LASSO-type penalties directly into the kriging equations to achieve automatic, data-driven neighbor selection. We further extend this to adaptive LASSO, using data-driven penalty weights that account for the spatial correlation structure. Our method determines which observations contribute non-zero weights through $\\ell_1$ regularization, with the penalty parameter selected via a novel criterion based on effective sample size that balances prediction accuracy against information redundancy. Numerical experiments demonstrate that penalized kriging automatically adapts neighborhood structure to the underlying spatial correlation, selecting fewer neighbors for smoother processes and more for highly variable fields, while maintaining prediction accuracy comparable to global kriging at substantially reduced computational cost."}
{"id": "2602.03757", "categories": ["eess.SY", "cs.OS"], "pdf": "https://arxiv.org/pdf/2602.03757", "abs": "https://arxiv.org/abs/2602.03757", "authors": ["Arkaprava Sain", "Sunandan Adhikary", "Soumyajit Dey"], "title": "Mitigating Timing-Based Attacks in Real-Time Cyber-Physical Systems", "comment": "12 pages, 10 figures", "summary": "Real-time cyber-physical systems depend on deterministic task execution to guarantee safety and correctness. Unfortunately, this determinism can unintentionally expose timing information that enables adversaries to infer task execution patterns and carry out timing-based attacks targeting safety-critical control tasks. While prior defenses aim to obscure schedules through randomization or isolation, they typically neglect the implications of such modifications on closed-loop control behavior and real-time feasibility. This work studies the problem of securing real-time control workloads against timing inference attacks while explicitly accounting for both schedulability constraints and control performance requirements. We present a scheduling-based mitigation approach that introduces bounded timing perturbations to control task executions in a structured manner, reducing adversarial opportunities without violating real-time guarantees. The framework jointly considers worst-case execution behavior and the impact of execution delays on control performance, enabling the system to operate within predefined safety and performance limits. Through experimental evaluation on representative task sets and control scenarios, the proposed approach demonstrates that exposure to timing-based attacks can be significantly reduced while preserving predictable execution and acceptable control quality."}
{"id": "2602.02985", "categories": ["quant-ph", "cs.PF"], "pdf": "https://arxiv.org/pdf/2602.02985", "abs": "https://arxiv.org/abs/2602.02985", "authors": ["Dragana Grbic", "Laleh Aghababaie Beni", "Noah Shutty"], "title": "Accelerating the Tesseract Decoder for Quantum Error Correction", "comment": null, "summary": "Quantum Error Correction (QEC) is essential for building robust, fault-tolerant quantum computers; however, the decoding process often presents a significant computational bottleneck. Tesseract is a novel Most-Likely-Error (MLE) decoder for QEC that employs the A* search algorithm to explore an exponentially large graph of error hypotheses, achieving high decoding speed and accuracy. This paper presents a systematic approach to optimizing the Tesseract decoder through low-level performance enhancements. Based on extensive profiling, we implemented four targeted optimization strategies, including the replacement of inefficient data structures, reorganization of memory layouts to improve cache hit rates, and the use of hardware-accelerated bit-wise operations. We achieved significant decoding speedups across a wide range of code families and configurations, including Color Codes, Bivariate-Bicycle Codes, Surface Codes, and Transversal CNOT Protocols. Our results demonstrate consistent speedups of approximately 2x for most code families, often exceeding 2.5x. Notably, we achieved a peak performance gain of over 5x for the most computationally demanding configurations of Bivariate-Bicycle Codes. These improvements make the Tesseract decoder more efficient and scalable, serving as a practical case study that highlights the importance of high-performance software engineering in QEC and providing a strong foundation for future research."}
{"id": "2602.03428", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.03428", "abs": "https://arxiv.org/abs/2602.03428", "authors": ["T. Chaumont-Frelet", "S. Sauter"], "title": "On singular Galerkin discretizations for three models in high-frequency scattering", "comment": null, "summary": "We consider three common mathematical models for time-harmonic high frequency scattering: the Helmholtz equation in two and three spatial dimensions, a transverse magnetic problem in two dimensions, and Maxwell's equation in three dimensions with dissipative boundary conditions such that the continuous problem is well posed. In this paper, we construct meshes for popular (low order) Galerkin finite element discretizations such that the discrete system matrix becomes singular and the discrete problem is not well posed. This implies that a condition \"the finite element space has to be sufficiently rich\" in the form of a resolution condition - typically imposed for discrete well-posedness - is not an artifact from the proof by a compact perturbation argument but necessary for discrete stability of the Galerkin discretization."}
{"id": "2602.03761", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.03761", "abs": "https://arxiv.org/abs/2602.03761", "authors": ["Sankha Subhra Bakshi", "Yunhao Fan", "Gia-Wei Chern"], "title": "Machine Learning Modeling of Charge-Density-Wave Recovery After Laser Melting", "comment": "12 pages, 6 figures", "summary": "We investigate the nonequilibrium dynamics of a laser-pumped two-dimensional spinless Holstein model within a semiclassical framework, focusing on the melting and recovery of long-range charge-density-wave order. Accurately describing this process requires fully nonadiabatic electron-lattice dynamics, which is computationally demanding due to the need to resolve fast electronic motion over long time scales. By analyzing the structure of the lattice force during nonequilibrium evolution, we show that the force naturally separates into a smooth quasi-adiabatic component and a residual bath-like contribution associated with fast electronic fluctuations. The quasi-adiabatic component depends only on the instantaneous local lattice configuration and can be efficiently learned using machine-learning techniques, while a minimal Langevin description of the bath term captures the essential features of the recovery dynamics. Combining these elements enables efficient and scalable simulations of long-time nonequilibrium dynamics on large lattices, providing a practical route to access driven correlated systems beyond the reach of direct nonadiabatic approaches."}
{"id": "2602.03266", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.03266", "abs": "https://arxiv.org/abs/2602.03266", "authors": ["Gamal Adel", "Eszter Bokányi", "Eelke M. Heemskerk", "Frank W. Takes"], "title": "Link Fraction Mixed Membership Reveals Community Diversity in Aggregated Social Networks", "comment": "21 pages, 6 figures", "summary": "Community detection is a critical tool for understanding the mesoscopic structure of large-scale networks. However, when applied to aggregated or coarse-grained social networks, disjoint community partitions cannot capture the diverse composition of community memberships within aggregated nodes. While existing mixed membership methods alleviate this issue, they may detected communities that are highly sensitive to the aggregation resolution, not reliably reflecting the underlying community structure of the underlying individual-level network. This paper presents the Link Fraction Mixed Membership (LFMM) method, which computes the mixed memberships of nodes in aggregated networks. Unlike existing mixed membership methods, LFMM is consistent under aggregation. Specifically, we show that it conserves community membership sums at different scales. The method is utilized to study a population-scale social network of the Netherlands, aggregated at different resolutions. Experiments reveal variation in community membership across different geographical regions and evolution over the last decade. In particular, we show how our method identifies large urban hubs that act as the melting pots of diverse, spatially remote communities."}
{"id": "2602.02814", "categories": ["math.OC", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02814", "abs": "https://arxiv.org/abs/2602.02814", "authors": ["Berk Bozkurt", "Aditya Mahajan", "Ashutosh Nayyar", "Yi Ouyang"], "title": "Sub-optimality bounds for certainty equivalent policies in partially observed systems", "comment": "12 pages, 0 figures", "summary": "In this paper, we present a generalization of the certainty equivalence principle of stochastic control. One interpretation of the classical certainty equivalence principle for linear systems with output feedback and quadratic costs is as follows: the optimal action at each time is obtained by evaluating the optimal state-feedback policy of the stochastic linear system at the minimum mean square error (MMSE) estimate of the state. Motivated by this interpretation, we consider certainty equivalent policies for general (non-linear) partially observed stochastic systems that allow for any state estimate rather than restricting to MMSE estimates. In such settings, the certainty equivalent policy is not optimal. For models where the cost and the dynamics are smooth in an appropriate sense, we derive upper bounds on the sub-optimality of certainty equivalent policies. We present several examples to illustrate the results."}
{"id": "2602.03090", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.03090", "abs": "https://arxiv.org/abs/2602.03090", "authors": ["Celia Chen", "Alex Leitch", "William Jordan Conway", "Eric Cotugno", "Emily Klein", "Rajesh Kumar Gnanasekaran", "Kristin Buckstad Hamilton", "Casi Sherman", "Celia Sterrn", "Logan C. Stevens", "Rebecca Zarrella", "Jennifer Golbeck"], "title": "In Bad Faith: Assessing Discussion Quality on Social Media", "comment": "8 pages, 1 figure, 1 table. Published in Proceedings of the 2025 International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2025), Springer", "summary": "The quality of a user's social media experience is determined both by the content they see and by the quality of the conversation and interaction around it. In this paper, we look at replies to tweets from mainstream media outlets and official government agencies and assess if they are good faith, engaging honestly and constructively with the original post, or bad faith, attacking the author or derailing the conversation. We assess automated approaches that may help in making this determination and then show that within our dataset of replies to mainstream media outlets and government agencies, bad faith interactions constitute 68.3% of all replies we studied, suggesting potential concerns about the quality of discourse in these specific conversational contexts. This is particularly true from verified accounts, where 91.7% of replies were bad faith. Given that verified accounts are algorithmically amplified, we discuss the implications of our work for understanding the user experience on social media."}
{"id": "2602.03488", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.03488", "abs": "https://arxiv.org/abs/2602.03488", "authors": ["Maria Chiara Angelini", "Saverio Palazzi", "Giorgio Parisi", "Tommaso Rizzo"], "title": "Long-range spin glass in a field at zero temperature", "comment": null, "summary": "We compute the critical exponents of the zero-temperature spin glass transition in a field on a one-dimensional long-range model, a proxy for higher-dimensional systems. Our approach is based on a novel loop expansion within the Bethe $M$-layer formalism, whose adaptation to this specific case is detailed here. The resulting estimates provide crucial benchmarks for numerical simulations that can access larger system sizes in one dimension, thus offering a key test of the theory of spin glasses in a field."}
{"id": "2602.03613", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.03613", "abs": "https://arxiv.org/abs/2602.03613", "authors": ["Arya Farahi", "Jonah Rose", "Paul Torrey"], "title": "Simulation-Based Inference via Regression Projection and Batched Discrepancies", "comment": "comments are welcome,", "summary": "We analyze a lightweight simulation-based inference method that infers simulator parameters using only a regression-based projection of the observed data. After fitting a surrogate linear regression once, the procedure simulates small batches at the proposed parameter values and assigns kernel weights based on the resulting batch-residual discrepancy, producing a self-normalized pseudo-posterior that is simple, parallelizable, and requires access only to the fitted regression coefficients rather than raw observations. We formalize the construction as an importance-sampling approximation to a population target that averages over simulator randomness, prove consistency as the number of parameter draws grows, and establish stability in estimating the surrogate regression from finite samples. We then characterize the asymptotic concentration as the batch size increases and the bandwidth shrinks, showing that the pseudo-posterior concentrates on an identified set determined by the chosen projection, thereby clarifying when the method yields point versus set identification. Experiments on a tractable nonlinear model and on a cosmological calibration task using the DREAMS simulation suite illustrate the computational advantages of regression-based projections and the identifiability limitations arising from low-information summaries."}
{"id": "2602.02814", "categories": ["math.OC", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02814", "abs": "https://arxiv.org/abs/2602.02814", "authors": ["Berk Bozkurt", "Aditya Mahajan", "Ashutosh Nayyar", "Yi Ouyang"], "title": "Sub-optimality bounds for certainty equivalent policies in partially observed systems", "comment": "12 pages, 0 figures", "summary": "In this paper, we present a generalization of the certainty equivalence principle of stochastic control. One interpretation of the classical certainty equivalence principle for linear systems with output feedback and quadratic costs is as follows: the optimal action at each time is obtained by evaluating the optimal state-feedback policy of the stochastic linear system at the minimum mean square error (MMSE) estimate of the state. Motivated by this interpretation, we consider certainty equivalent policies for general (non-linear) partially observed stochastic systems that allow for any state estimate rather than restricting to MMSE estimates. In such settings, the certainty equivalent policy is not optimal. For models where the cost and the dynamics are smooth in an appropriate sense, we derive upper bounds on the sub-optimality of certainty equivalent policies. We present several examples to illustrate the results."}
{"id": "2602.03037", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03037", "abs": "https://arxiv.org/abs/2602.03037", "authors": ["Yu Zhu", "Félix Beaudoin", "Hong Guo"], "title": "Device variability of Josephson junctions induced by interface roughness", "comment": null, "summary": "As quantum processors scale to large qubit numbers, device-to-device variability emerges as a critical challenge. Superconducting qubits are commonly realized using Al/AlO$_{\\text{x}}$/Al Josephson junctions operating in the tunneling regime, where even minor variations in device geometry can lead to substantial performance fluctuations. In this work, we develop a quantitative model for the variability of the Josephson energy $E_{J}$ induced by interface roughness at the Al/AlO$_{\\text{x}}$ interfaces. The roughness is modeled as a Gaussian random field characterized by two parameters: the root-mean-square roughness amplitude $σ$ and the transverse correlation length $ξ$. These parameters are extracted from the literature and molecular dynamics simulations. Quantum transport is treated using the Ambegaokar--Baratoff relation combined with a local thickness approximation. Numerical simulations over $5,000$ Josephson junctions show that $E_{J}$ follows a log-normal distribution. The mean value of $E_{J}$ increases with $σ$ and decreases slightly with $ξ$, while the variance of $E_{J}$ increases with both $σ$ and $ξ$. These results paint a quantitative and intuitive picture of Josephson energy variability induced by surface roughness, with direct relevance for junction design."}
{"id": "2602.02981", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.02981", "abs": "https://arxiv.org/abs/2602.02981", "authors": ["Harbir Antil", "Animesh Jain", "Rainald Löhner"], "title": "Fisher-Information-Based Sensor Placement for Structural Digital Twins: Analytic Results and Benchmarks", "comment": null, "summary": "High-fidelity digital twins rely on the accurate assimilation of sensor data into physics-based computational models. In structural applications, such twins aim to identify spatially distributed quantities--such as elementwise weakening fields, material parameters, or effective thermal loads--by minimizing discrepancies between measured and simulated responses subject to the governing equations of structural mechanics. While adjoint-based methods enable efficient gradient computation for these inverse problems, the quality and stability of the resulting estimates depend critically on the choice of sensor locations, measurement types, and directions.\n  This paper develops a rigorous and implementation-ready framework for Fisher-information-based sensor placement in adjoint-based finite-element digital twins. Sensor configurations are evaluated using a D-optimal design criterion derived from a linearization of the measurement map, yielding a statistically meaningful measure of information content. We present matrix-free operator formulas for applying the Jacobian and its adjoint, and hence for computing Fisher-information products $Fv = J^\\top R^{-1} Jv$ using only forward and adjoint solves. Building on these operator evaluations, we derive explicit sensitivity expressions for D-optimal sensor design with respect to measurement parameters and discuss practical strategies for evaluating the associated log-determinant objectives. To complement the general framework, we provide analytically tractable sensor placement results for a canonical one-dimensional structural model, clarifying the distinction between detectability and localizability and proving that D-optimal placement of multiple displacement sensors yields approximately uniform spacing."}
{"id": "2602.03771", "categories": ["cond-mat.str-el", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2602.03771", "abs": "https://arxiv.org/abs/2602.03771", "authors": ["Linh Pham", "Ehsan Khatami"], "title": "Spin and Charge Conductivity in the Square Lattice Fermi-Hubbard Model", "comment": "11 pages, 11 figures", "summary": "Dynamical properties are notoriously difficult to compute in numerical treatments of the Fermi-Hubbard model, especially in two spatial dimensions. However, they are essential in providing us with insight into some of the most important and less well-understood phases of the model, such as the pseudogap and strange metal phases at relatively high temperatures, or unconventional superconductivity at lower temperatures, away from the commensurate filling. Here, we use the numerical linked-cluster expansions to compute spin and charge optical conductivities of the model at different temperatures and strong interaction strengths via the exact real-time-dependent correlation functions of the current operators. We mitigate systematic errors associated with having a limited access to the long-time behavior of the correlators by introducing fits and allowing for non-zero Drude weights when appropriate. We compare our results to available data from optical lattice experiments and find that the Drude contributions can account for the theory-experiment gap in the DC spin conductivity of the model at half filling in the strong-coupling region. Our method helps paint a more complete picture of the conductivity in the two-dimensional Hubbard model and opens the door to studying dynamical properties of quantum lattice models in the thermodynamic limit."}
{"id": "2602.03308", "categories": ["nlin.AO", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.03308", "abs": "https://arxiv.org/abs/2602.03308", "authors": ["A. Schmaus", "K. Stiller", "N. Molkenthin"], "title": "Emergence and co-existence of periodic and unstructured motion in future-avoiding random walks", "comment": null, "summary": "Self-avoiding random walks on graphs can be seen as walkers interacting with their own past history. This letter considers a complementary class of dynamics: Mutual future avoiding random walks (MFARWs), where stochastically driven walkers are avoiding each others planned future trajectories. Such systems arise naturally in conceptual models of shared mobility. We show that periodic behavior emerges spontaneously in such MFARWs, and that periodic and unstructured behavior coexist, providing a first example of Chimera style behavior of non-oscillatory paths on networks. Further, we analytically describe and predict the onset of structure. We find that the phase transition from unstructured to periodic behavior is driven by a novel mechanism of self-amplifying coupling to the periodic components of the stochastic drivers of the system. In the context of shared mobility applications, these Chimera states imply a regime of naturally stable co-existence between flexible and line-based public transport."}
{"id": "2602.02992", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02992", "abs": "https://arxiv.org/abs/2602.02992", "authors": ["Masashi Wakaiki"], "title": "Data-driven stabilization of continuous-time systems with noisy input-output data", "comment": "18 pages", "summary": "We study data-driven stabilization of continuous-time systems in autoregressive form when only noisy input-output data are available. First, we provide an operator-based characterization of the set of systems consistent with the data. Next, combining this characterization with behavioral theory, we derive a necessary and sufficient condition for the noisy data to be informative for quadratic stabilization. This condition is formulated as linear matrix inequalities, whose solution yields a stabilizing controller. Finally, we characterize data informativity for system identification in the noise-free setting."}
{"id": "2602.03266", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.03266", "abs": "https://arxiv.org/abs/2602.03266", "authors": ["Gamal Adel", "Eszter Bokányi", "Eelke M. Heemskerk", "Frank W. Takes"], "title": "Link Fraction Mixed Membership Reveals Community Diversity in Aggregated Social Networks", "comment": "21 pages, 6 figures", "summary": "Community detection is a critical tool for understanding the mesoscopic structure of large-scale networks. However, when applied to aggregated or coarse-grained social networks, disjoint community partitions cannot capture the diverse composition of community memberships within aggregated nodes. While existing mixed membership methods alleviate this issue, they may detected communities that are highly sensitive to the aggregation resolution, not reliably reflecting the underlying community structure of the underlying individual-level network. This paper presents the Link Fraction Mixed Membership (LFMM) method, which computes the mixed memberships of nodes in aggregated networks. Unlike existing mixed membership methods, LFMM is consistent under aggregation. Specifically, we show that it conserves community membership sums at different scales. The method is utilized to study a population-scale social network of the Netherlands, aggregated at different resolutions. Experiments reveal variation in community membership across different geographical regions and evolution over the last decade. In particular, we show how our method identifies large urban hubs that act as the melting pots of diverse, spatially remote communities."}
{"id": "2602.03656", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-lat"], "pdf": "https://arxiv.org/pdf/2602.03656", "abs": "https://arxiv.org/abs/2602.03656", "authors": ["Fo-Hong Wang", "Fanjie Sun", "Chenghao He", "Xiao Yan Xu"], "title": "Resolving Quantum Criticality in the Honeycomb Hubbard Model", "comment": "12+20 pages, 6+16 figures", "summary": "The interplay between Dirac fermions and electronic correlations on the honeycomb lattice hosts a fundamental quantum phase transition from a semimetal to a Mott insulator, governed by the Gross-Neveu-Heisenberg (GNH) universality class. Despite its importance, consensus on the precise critical exponents remains elusive due to severe finite-size effects in numerical simulations and the lack of conformal bootstrap benchmarks. Here we try to resolve this long-standing controversy by performing projector determinant quantum Monte Carlo (QMC) simulations on lattices of unprecedented size, reaching 10,368 sites. By developing a novel projected submatrix update algorithm, we achieve a significant algorithmic speedup that enables us to access the thermodynamic limit with high precision. We observe that the fermion anomalous dimension and the correlation length exponent converge rapidly, while the boson anomalous dimension exhibits a systematic size dependence that we resolve via linear extrapolation. To validate our analysis, we perform parallel large-scale simulations of the spinless $t$-$V$ model on the honeycomb lattice, which belongs to the Gross-Neveu-Ising class. Our results for the $t$-$V$ model, including the first QMC determination of the fermion anomalous dimension, show agreement with conformal bootstrap predictions, thereby corroborating the robustness of our methodology. Our work provides state-of-the-art critical exponents for the honeycomb Hubbard model and establishes a systematic finite-size scaling workflow applicable to a broad class of strongly correlated quantum systems, paving the way for resolving other challenging fermionic quantum critical phenomena."}
{"id": "2602.03756", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.03756", "abs": "https://arxiv.org/abs/2602.03756", "authors": ["Yulong Chen", "Jim Griffin", "Francisco Javier Rubio"], "title": "Bayesian variable and hazard structure selection in the General Hazard model", "comment": null, "summary": "The proportional hazards (PH) and accelerated failure time (AFT) models are the most widely used hazard structures for analysing time-to-event data. When the goal is to identify variables associated with event times, variable selection is typically performed within a single hazard structure, imposing strong assumptions on how covariates affect the hazard function. To allow simultaneous selection of relevant variables and the hazard structure itself, we develop a Bayesian variable selection approach within the general hazard (GH) model, which includes the PH, AFT, and other structures as special cases. We propose two types of g-priors for the regression coefficients that enable tractable computation and show that both lead to consistent model selection. We also introduce a hierarchical prior on the model space that accounts for multiplicity and penalises model complexity. To efficiently explore the GH model space, we extend the Add-Delete-Swap algorithm to jointly sample variable inclusion indicators and hazard structures. Simulation studies show accurate recovery of both the true hazard structure and active variables across different sample sizes and censoring levels. Two real-data applications are presented to illustrate the use of the proposed methodology and to compare it with existing variable selection methods."}
{"id": "2602.02992", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.02992", "abs": "https://arxiv.org/abs/2602.02992", "authors": ["Masashi Wakaiki"], "title": "Data-driven stabilization of continuous-time systems with noisy input-output data", "comment": "18 pages", "summary": "We study data-driven stabilization of continuous-time systems in autoregressive form when only noisy input-output data are available. First, we provide an operator-based characterization of the set of systems consistent with the data. Next, combining this characterization with behavioral theory, we derive a necessary and sufficient condition for the noisy data to be informative for quadratic stabilization. This condition is formulated as linear matrix inequalities, whose solution yields a stabilizing controller. Finally, we characterize data informativity for system identification in the noise-free setting."}
{"id": "2602.03057", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03057", "abs": "https://arxiv.org/abs/2602.03057", "authors": ["André R. R. Carvalho", "Liam J. McClelland", "Erik W. Streed", "Joan Vaccaro"], "title": "Quantum spin-heat engine with trapped ions", "comment": "10 pages, 8 figures", "summary": "We propose an ion-trap implementation of the Vaccaro, Barnett and Wright et al. spin-heat engine (SHE); a hypothetical engine that operates between energy and spin thermal reservoirs rather than two energy reservoirs. The SHE operates in two steps: first, in the work extraction stage, heat from a thermal energy reservoir is converted into optical work via a two photon Raman transition resonant with close-to energy degenerate spin states; second, the internal spin states are brought back to their initial state via non-energetic information erasure using a spin reservoir. The latter incurs no energy cost, but rather the reset occurs at the cost of angular momentum from a spin bath that acts as the thermal spin reservoir. The SHE represents an important first step toward demonstrating heat engines that operate beyond the conventional paradigm of requiring two thermal reservoirs, paving the way to harness quantum coherence in arbitrary conserved quantities via similar machines."}
{"id": "2602.03654", "categories": ["nlin.AO", "math.NA", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.03654", "abs": "https://arxiv.org/abs/2602.03654", "authors": ["Su Yang", "Weiqi Chu", "Panayotis G. Kevrekidis"], "title": "Noisy nonlocal aggregation model with gradient flow structures", "comment": "15 pages; 4 figures", "summary": "Interacting particle systems provide a fundamental framework for modeling collective behavior in biological, social, and physical systems. In many applications, stochastic perturbations are essential for capturing environmental variability and individual uncertainty, yet their impact on long-term dynamics and equilibrium structure remains incompletely understood, particularly in the presence of nonlocal interactions. We investigate a stochastic interacting particle system governed by potential-driven interactions and its continuum density formulation in the large-population limit. We introduce an energy functional and show that the macroscopic density evolution has a gradient-flow structure in the Wasserstein-2 space. The associated variational framework yields equilibrium states through constrained energy minimization and illustrates how noise regulates the density and mitigates singular concentration. We demonstrate the connection between microscopic and macroscopic descriptions through numerical examples in one and two dimensions. Within the variational framework, we compute energy minimizers and perform a linear stability analysis. The numerical results show that the stable minimizers agree with the long-time dynamics of the macroscopic density model."}
{"id": "2602.03843", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03843", "abs": "https://arxiv.org/abs/2602.03843", "authors": ["Aadi Singh", "Chakradhar Rangi", "Ka-Ming Tam"], "title": "Classical Benchmarks of a Symmetry-Adapted Variational Quantum Eigensolver for Real-Time Green's Functions in Dynamical Mean-Field Theory", "comment": "11 pages, 6 figures", "summary": "We present a variational quantum eigensolver (VQE) approach for solving the Anderson Impurity Model (AIM) arising in Dynamical Mean-Field Theory (DMFT). Recognizing that the minimal two-site approximation often fails to resolve essential spectral features, we investigate the efficacy of VQE for larger bath discretizations while adhering to near-term hardware constraints. We employ a symmetry-adapted ansatz enforcing conservation of particle number $(N)$, spin projection $(S_z=0)$, and total spin $(S^2=0)$ symmetry, benchmarking the performance against exact diagonalization across different interaction strengths using bath parameters extracted from the DMFT self-consistency loop. For a four-site model, the relative error in the ground state energy remains well below $0.01%$ with a compact parameter set $(N_p \\le 30)$. Crucially, we demonstrate that the single-particle Green's function-the central quantity for DMFT-can be accurately extracted from VQE-prepared ground states via real-time evolution in the intermediate to strong interaction regimes. However, in the weak interaction regime, the Green's function exhibits noticeable deviations from the exact benchmark, particularly in resolving low-energy spectral features, despite the ground state energy showing excellent agreement. These findings demonstrate that VQE combined with real-time evolution can effectively extend quantum-classical hybrid DMFT beyond the two-site approximation, particularly for describing insulating phases. While this approach offers a viable pathway for simulating strongly correlated materials on near-term devices, the observation that accurate ground state energy does not guarantee accurate dynamical properties highlights a key challenge for applying such approaches to correlated metals."}
{"id": "2602.03654", "categories": ["nlin.AO", "math.NA", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.03654", "abs": "https://arxiv.org/abs/2602.03654", "authors": ["Su Yang", "Weiqi Chu", "Panayotis G. Kevrekidis"], "title": "Noisy nonlocal aggregation model with gradient flow structures", "comment": "15 pages; 4 figures", "summary": "Interacting particle systems provide a fundamental framework for modeling collective behavior in biological, social, and physical systems. In many applications, stochastic perturbations are essential for capturing environmental variability and individual uncertainty, yet their impact on long-term dynamics and equilibrium structure remains incompletely understood, particularly in the presence of nonlocal interactions. We investigate a stochastic interacting particle system governed by potential-driven interactions and its continuum density formulation in the large-population limit. We introduce an energy functional and show that the macroscopic density evolution has a gradient-flow structure in the Wasserstein-2 space. The associated variational framework yields equilibrium states through constrained energy minimization and illustrates how noise regulates the density and mitigates singular concentration. We demonstrate the connection between microscopic and macroscopic descriptions through numerical examples in one and two dimensions. Within the variational framework, we compute energy minimizers and perform a linear stability analysis. The numerical results show that the stable minimizers agree with the long-time dynamics of the macroscopic density model."}
{"id": "2602.03460", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03460", "abs": "https://arxiv.org/abs/2602.03460", "authors": ["Julia Adlercreutz", "Richard Pates"], "title": "Cholesky factorisation, and intrinsically sparse linear quadratic regulation", "comment": "15 pages, 7 figures, under review", "summary": "We classify a family of matrices of shift operators that can be factorised in a computationally tractable manner with the Cholesky algorithm. Such matrices arise in the linear quadratic regulator problem, and related areas. We use the factorisation to uncover intrinsic sparsity properties in the control laws for transportation problems with an underlying tree structure. This reveals that the optimal control can be applied in a distributed manner that is obscured by standard solution methods."}
{"id": "2602.03775", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.03775", "abs": "https://arxiv.org/abs/2602.03775", "authors": ["Farnoosh Hashemi", "Michael W. Macy"], "title": "An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents", "comment": null, "summary": "Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and interactions among 32K LLM agents over a year. We start with homophily and social influence among LLMs, learning that similar to humans', their social networks exhibit these fundamental phenomena. Next, we study the toxic language of LLMs, its linguistic features, and their interaction patterns, finding that LLMs show different structural patterns in toxic posting than humans. After studying the ideological leaning in LLMs posts, and the polarization in their community, we focus on how to prevent their potential harmful activities. We present a simple yet effective method, called Chain of Social Thought (CoST), that reminds LLM agents to avoid harmful posting."}
{"id": "2602.03676", "categories": ["physics.soc-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.03676", "abs": "https://arxiv.org/abs/2602.03676", "authors": ["Korak Biswas"], "title": "Entropy Geometry and Condensation in Wealth Allocation", "comment": null, "summary": "We develop a statistical framework for wealth allocation in which agents hold discrete units of wealth and macrostates are defined by how wealth is distributed across agents. The structure of the economic state space is characterized through a value convertibility function, which captures how effectively additional wealth can be transformed into productive or meaningful value. The derivative of this function determines the effective number of internally distinct configurations available to an agent at a given wealth level. In a closed setting with fixed total wealth and a fixed number of agents, we show that equilibrium wealth distributions follow directly from unbiased counting of admissible configurations and may display a condensation phenomenon, where a finite fraction of total wealth accumulates onto a single agent once the remaining agents can no longer absorb additional wealth. We then extend the framework to open systems in which both total wealth and the number of agents may vary. By embedding the system within a larger closed environment and analyzing a finite subsystem, we show that exponential weighting in wealth and agent number emerges naturally from counting arguments alone, without invoking explicit optimization or entropy maximization principles. This extension leads to a richer interpretation of wealth concentration: accumulation is no longer driven solely by excess wealth, but by a balance between wealth growth and the system's capacity to accommodate new agents. Condensation arises when this capacity is limited, forcing surplus wealth to concentrate onto a few agents. The framework thus provides a minimal and structurally grounded description of wealth concentration in both closed and open economic settings."}
{"id": "2602.03460", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03460", "abs": "https://arxiv.org/abs/2602.03460", "authors": ["Julia Adlercreutz", "Richard Pates"], "title": "Cholesky factorisation, and intrinsically sparse linear quadratic regulation", "comment": "15 pages, 7 figures, under review", "summary": "We classify a family of matrices of shift operators that can be factorised in a computationally tractable manner with the Cholesky algorithm. Such matrices arise in the linear quadratic regulator problem, and related areas. We use the factorisation to uncover intrinsic sparsity properties in the control laws for transportation problems with an underlying tree structure. This reveals that the optimal control can be applied in a distributed manner that is obscured by standard solution methods."}
{"id": "2602.03099", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03099", "abs": "https://arxiv.org/abs/2602.03099", "authors": ["Joseph Li", "Gengzhi Yang", "Jiaqi Leng", "Xiaodi Wu"], "title": "Resource-efficient quantum simulation of transport phenomena via Hamiltonian embedding", "comment": "27 pages, 7 figures", "summary": "Transport phenomena play a key role in a variety of application domains, and efficient simulation of these dynamics remains an outstanding challenge. While quantum computers offer potential for significant speedups, existing algorithms either lack rigorous theoretical guarantees or demand substantial quantum resources, preventing scalable and efficient validation on realistic quantum hardware. To address this gap, we develop a comprehensive framework for simulating classes of transport equations, offering both rigorous theoretical guarantees -- including exponential speedups in specific cases -- and a systematic, hardware-efficient implementation. Central to our approach is the Hamiltonian embedding technique, a white-box approach for end-to-end simulation of sparse Hamiltonians that avoids abstract query models and retains near-optimal asymptotic complexity. Empirical resource estimates indicate that our approach can yield an order-of-magnitude (e.g., $42\\times$) reduction in circuit depth given favorable problem structures. We then apply our framework to solve linear and nonlinear transport PDEs, including the first experimental demonstration of a 2D advection equation on a trapped-ion quantum computer."}
{"id": "2602.03848", "categories": ["cond-mat.str-el", "cond-mat.supr-con", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03848", "abs": "https://arxiv.org/abs/2602.03848", "authors": ["Donghae Seo", "Taegon Lee", "Gil Young Cho"], "title": "A Unified Categorical Description of Quantum Hall Hierarchy and Anyon Superconductivity", "comment": "14 pages, 1 figure, 1 table", "summary": "We present a unified category-theoretic framework for quantum Hall hierarchy constructions and anyon superconductivity based on modular tensor categories over $\\mathrm{Rep}(\\mathrm{U}(1))$ and $\\mathrm{sRep}(\\mathrm{U}(1)^f)$. Our approach explicitly incorporates conserved $\\mathrm{U}(1)$ charge and formulates doping via a generalized stack-and-condense procedure, in which an auxiliary topological order is stacked onto the parent phase, and the quasiparticles created by doping subsequently condense. Depending on whether this condensation preserves or breaks the $\\mathrm{U}(1)$ symmetry, the system undergoes a transition to a quantum Hall hierarchy state or to an anyon superconductor. For anyon superconductors, the condensate charge is determined unambiguously by the charged local bosons contained in the condensable algebra. Our framework reproduces all known anyon superconductors obtained from field-theoretic analyses and further predicts novel phases, including a charge-$2e$ anyon superconductor derived from the Laughlin state and charge-$ke$ anyon superconductors arising from bosonic $\\mathbb{Z}_k$ Read-Rezayi states. By placing hierarchy transitions and anyon superconductivity within a single mathematical formalism, our work provides a unified understanding of competing and proximate phases near experimentally realizable fractional quantum Hall states."}
{"id": "2602.03508", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03508", "abs": "https://arxiv.org/abs/2602.03508", "authors": ["Galina Sidorenko", "Johan Thunberg"], "title": "A necessary and sufficient condition for discrete-time consensus on star boundaries", "comment": "14 pages, 8 figures", "summary": "It is intuitive and well known, that if agents in a multi-agent system iteratively update their states in the Euclidean space as convex combinations of neighbors' states, all states eventually converge to the same value (consensus), provided the interaction graph is sufficiently connected. However, this seems to be also true in practice if the convex combinations of states are mapped or radially projected onto any unit $l_p$-sphere or even boundaries of star-convex sets, herein referred to as star boundaries. In this paper, we present insight into this matter by providing a necessary and sufficient condition for asymptotic consensus of the normalized states (directions) for strongly connected directed graphs, which is equivalent to asymptotic consensus of states when the star boundaries are the same for all agents. Furthermore, we show that when asymptotic consensus occurs, the states converge linearly and the point of convergence is continuous in the initial states. Assuming a directed strongly connected graph provides a more general setting than that considered, for example, in gradient-based consensus protocols, where symmetric graphs are assumed. Illustrative examples and a vast number of numerical simulations showcase the theoretical results."}
{"id": "2602.03765", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.03765", "abs": "https://arxiv.org/abs/2602.03765", "authors": ["Théo Lejeune", "Miha Papič", "John Goold", "Felix C. Binder", "François Damanet", "Mattia Moroder"], "title": "Accelerating qubit reset through the Mpemba effect", "comment": "19 pages, 9 figures", "summary": "Passive qubit reset is a key primitive for quantum information processing, whereby qubits are initialized by allowing them to relax to their ground state through natural dissipation, without the need for active control or feedback. However, passive reset occurs on timescales that are much longer than those of gate operations and measurements, making it a significant bottleneck for algorithmic execution. Here, we show that this limitation can be overcome by exploiting the Mpemba effect, originally indicating the faster cooling of hot systems compared to cooler ones. Focusing on the regime where coherence times exceed energy relaxation times ($T_2 > T_1$), we propose a simple protocol based on a single entangling two-qubit gate that converts local single-qubit coherences into fast-decaying global two-qubit coherences. This removes their overlap with the slowest decaying Liouvillian mode and enables a substantially faster relaxation to the ground state. For realistic parameters, we find that our protocol can reduce reset times by up to $50\\%$ compared to standard passive reset. We analyze the robustness of the protocol under non-Markovian noise, imperfect coherent control and finite temperature, finding that the accelerated reset persists across a broad range of realistic error sources. Finally, we present an experimental implementation of our protocol on an IQM superconducting quantum processor. Our results demonstrate how Mpemba-like accelerated relaxation can be harnessed as a practical tool for fast and accurate qubit initialization."}
{"id": "2602.03508", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.03508", "abs": "https://arxiv.org/abs/2602.03508", "authors": ["Galina Sidorenko", "Johan Thunberg"], "title": "A necessary and sufficient condition for discrete-time consensus on star boundaries", "comment": "14 pages, 8 figures", "summary": "It is intuitive and well known, that if agents in a multi-agent system iteratively update their states in the Euclidean space as convex combinations of neighbors' states, all states eventually converge to the same value (consensus), provided the interaction graph is sufficiently connected. However, this seems to be also true in practice if the convex combinations of states are mapped or radially projected onto any unit $l_p$-sphere or even boundaries of star-convex sets, herein referred to as star boundaries. In this paper, we present insight into this matter by providing a necessary and sufficient condition for asymptotic consensus of the normalized states (directions) for strongly connected directed graphs, which is equivalent to asymptotic consensus of states when the star boundaries are the same for all agents. Furthermore, we show that when asymptotic consensus occurs, the states converge linearly and the point of convergence is continuous in the initial states. Assuming a directed strongly connected graph provides a more general setting than that considered, for example, in gradient-based consensus protocols, where symmetric graphs are assumed. Illustrative examples and a vast number of numerical simulations showcase the theoretical results."}
{"id": "2602.03101", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03101", "abs": "https://arxiv.org/abs/2602.03101", "authors": ["Rudraksh Sharma", "Ravi Katukam", "Arjun Nagulapally"], "title": "Quantum Annealing for Combinatorial Optimization: Foundations, Architectures, Benchmarks, and Emerging Directions", "comment": null, "summary": "Critical decision-making issues in science, engineering, and industry are based on combinatorial optimization; however, its application is inherently limited by the NP-hard nature of the problem. A specialized paradigm of analogue quantum computing, quantum annealing (QA), has been proposed to solve these problems by encoding optimization problems into physical energy landscapes and solving them by quantum tunnelling systematically through exploration of solution space. This is a critical review that summarizes the current applications of quantum annealing to combinatorial optimization and includes a theoretical background, hardware designs, algorithm implementation strategies, encoding and embedding schemes, protocols to benchmark quantum annealing, areas of implementation, and links with the quantum algorithms implementation with gate-based hardware and classical solvers. We develop a unified framework, relating adiabatic quantum dynamics, Ising and QUBO models, stoquastic and non-stoquastic Hamiltonians, and diabatic transitions to modern flux-qubit annealers (Chimera, Pegasus, Zephyr topologies), and emergent architectures (Lechner-Hauke-Zoller systems, Rydberg atom platforms), and hybrids of quantum and classical computation. Through our analysis, we find that overhead in embedding and encoding is the largest determinant of the scalability and performance (this is not just the number of qubits). Minor embeddings also usually have a physical qubit count per logical variable of between 5 and 12 qubits, which limits effective problem capacity by 80-92% and, due to chain-breaking errors, compromises the quality of solutions."}
{"id": "2602.02648", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.02648", "abs": "https://arxiv.org/abs/2602.02648", "authors": ["Yasamin Panahi", "Subhayan Sahu", "Naren Manjunath", "Chong Wang"], "title": "Quantum criticality at strong randomness: a lesson from anomaly", "comment": "5+13 pages, 8 figures", "summary": "Quantum criticality in the presence of strong quenched randomness remains a challenging topic in modern condensed matter theory. We show that the topology and anomaly associated with average symmetry can be used to predict certain nontrivial universal properties. Our focus is on systems subject to average Lieb--Schultz--Mattis constraints, where lattice translation symmetry is preserved only on average, while on-site symmetries remain exact. We argue that in the absence of spontaneous symmetry breaking, the system must exhibit critical correlations of local operators in two distinct ways: (i) for some operator $O_e$ charged under exact symmetries, the first absolute moment correlation $\\overline{|\\langle O_e(x)O^{\\dagger}_e(y)\\rangle|}$ decays slowly; and (ii) for some operator $O_a$ charged under average symmetries, the first-moment correlation $\\overline{\\langle O_a(x)O^{\\dagger}_a(y)\\rangle}$ decays slowly. We verify these predictions in a few examples: the random-singlet Heisenberg spin chain in one dimension, and the disordered free-fermion critical states in symmetry class BDI in one and two dimensions. Surprisingly, even for these well-studied systems, our anomaly-based argument reveals critical correlations overlooked in previous literature. We also discuss the experimental feasibility of measuring these critical correlations."}
{"id": "2602.03113", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03113", "abs": "https://arxiv.org/abs/2602.03113", "authors": ["Tie-Jun Wang", "Run-Qing Zhang", "Ling Qian", "Yun-Tao Song", "Ting Lan", "Hai-Qing Liu", "Keren Li"], "title": "Validating a Koopman-Quantum Hybrid Paradigm for Diagnostic Denoising of Fusion Devices", "comment": "27 pages, 4 figures", "summary": "The potential of Quantum Machine Learning (QML) in data-intensive science is strictly bottlenecked the difficulty of interfacing high-dimensional, chaotic classical data into resource-limited, noisy quantum processors. To bridge this gap, we introduce a physics-informed Koopman-Quantum hybrid framework, theoretically grounded in a representation-level structural isomorphism we establish between the Koopman operator, which linearizes nonlinear dynamics, and quantum evolution. Based on this theoretical foundation, we design a realizable NISQ-friendly pipeline: the Koopman operator functions as a physics-aware \"data distiller,\" compressing waveforms into compact, \"quantum-ready\" features, which are subsequently processed by a modular, parallel quantum neural network. We validated this framework on 4,763 labeled channel sequences from 433 discharges of the tokamak system. The results demonstrate that our model achieves 97.0\\% accuracy in screening corrupted diagnostic data, matching the performance of state-of-the-art deep classical CNNs while using orders-of-magnitude fewer trainable parameters. This work establishes a practical, physics-grounded paradigm for leveraging quantum processing in constrained environments, offering a scalable path for quantum-enhanced edge computing."}
{"id": "2602.03291", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.03291", "abs": "https://arxiv.org/abs/2602.03291", "authors": ["Himuro Hashimoto", "Akio Nakabayashi", "Lento Nagano", "Yutaro Iiyama", "Ryu Sawada", "Junichi Tanaka", "Koji Terashi"], "title": "Comprehensive Numerical Studies of Barren Plateau and Overparametrization in Variational Quantum Algorithm", "comment": "16 pages, 15 figures", "summary": "The variational quantum algorithm (VQA) with a parametrized quantum circuit is widely applicable to near-term quantum computing, but its fundamental issues that limit optimization performance have been reported in the literature. For example, VQA optimization often suffers from vanishing gradients called barren plateau (BP) and the presence of local minima in the landscape of the cost function. Numerical studies have shown that the trap in local minima is significantly reduced when the circuit is overparametrized (OP), where the number of parameters exceeds a certain threshold. Theoretical understanding of the BP and OP phenomena has advanced over the past years, however, comprehensive studies of both effects in the same setting are not fully covered in the literature. In this paper, we perform a comprehensive numerical study in VQA, quantitatively evaluating the impacts of BP and OP and their interplay on the optimization of a variational quantum circuit, using concrete implementations of one-dimensional transverse and longitudinal field quantum Ising model. The numerical results are compared with the theoretical diagnostics of BP and OP phenomena. The framework presented in this paper will provide a guiding principle for designing VQA algorithms and ansatzes with theoretical support for behaviors of parameter optimization in practical settings."}
{"id": "2602.03173", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03173", "abs": "https://arxiv.org/abs/2602.03173", "authors": ["Georgi Bebrov"], "title": "Surpassing the currently achievable distance of quantum key distribution based on sending-or-not-sending approach", "comment": "20 pages, 11 figures", "summary": "Protocols based on the sending-or-not-sending (SNS) principle have been intensively studied in recent years and have been shown to enable the longest transmission distances in quantum key distribution (QKD). In this work, we propose a sending-or-not-sending phase-matching QKD protocol (SNS-PM-QKD) that improves tolerance to phase mismatch, thereby extending the achievable transmission distance. We present a security analysis of SNS-PM-QKD in the asymptotic (infinite-key) regime under collective attacks. The performance of the proposed protocol is compared with that of standard phase-matching QKD, theoretical SNS-type twin-field QKD protocols (SNS-TF-QKD), and an experimental SNS-TF-QKD operated over transmission distances of up to 1002km. Our results show that SNS-PM-QKD achieves greater transmission distances than these existing protocols, highlighting its potential for long-distance quantum communication."}
{"id": "2602.03186", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03186", "abs": "https://arxiv.org/abs/2602.03186", "authors": ["Gihwan Kim", "Andreas Butler", "Oskar Painter"], "title": "A Tunable, Modeless, and Hybridization-free Cross-Kerr Coupler for Miniaturized Superconducting Qubits", "comment": "23 pages, 14 figures", "summary": "Superconducting quantum circuits typically use capacitive charge-based linear coupling schemes to control interactions between elements such as qubits. While simple and effective, this coupling scheme makes it difficult to satisfy competing circuit design requirements such as maintaining large qubit anharmonicity and coherence along with a high degree of qubit connectivity and packing density. Moreover, tunable interactions using linear coupling elements produce dynamical variations in mode hybridization, which can induce non-adiabatic transitions, resulting in leakage errors and limiting gate speeds. In this work we attempt to address these challenges by proposing a junction-based coupling architecture based on SQUID (superconducting quantum interference device) couplers with relatively small Josephson energies. SQUID couplers provide intrinsic cross-Kerr interactions that can be controlled by external fluxes and that do not rely on mode hybridization. The small Josephson energies of the coupler maintain the interaction at a perturbative scale, which limits undesired higher-order mixing between coupled elements while achieving a sufficiently strong cross-Kerr interaction originating from diagonal coupling elements. Based on these properties, we show that a SQUID coupler can be used to implement a fast, adiabatic, and high-fidelity controlled-Z gate without introducing extra modes, and the operation is robust against junction asymmetry for high-frequency qubits. Although unconventional crosstalk may arise due to junction asymmetries and parasitic hybridization with spectator qubits, we show that these effects are sufficiently small for realistic circuit parameters. As an example of the utility of such junction-based coupling schemes, we present a scalable tiling strategy for a miniaturized superconducting quantum processor based on merged-element transmon qubits."}
{"id": "2602.03234", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03234", "abs": "https://arxiv.org/abs/2602.03234", "authors": ["Ha Eum Kim", "Andrew D. Kim", "Jong Yeon Lee"], "title": "Liouvillian Gap in Dissipative Haar-Doped Clifford Circuits", "comment": "29 pages, 8 figures", "summary": "Quantum chaos is commonly assessed through probe-dependent signatures such as spectral statistics, OTOCs, and entanglement growth, which need not coincide. Recently, a dissipative diagnostic of chaos has been proposed, in which an infinitesimal coupling to a bath yields a finite Liouvillian gap in chaotic systems, marking the onset of intrinsic relaxation. This raises a conceptual question: what is the minimal departure from Clifford dynamics needed for this intrinsically relaxing behavior to emerge? In this work, we investigate the dynamics under the Floquet two-qubit Clifford circuit interleaved with a finite density of Haar-random single-site gates, followed by a depolarizing channel with strength $γ$. For Floquet Clifford circuits built from an \\textit{i}SWAP-class two-qubit gate, our analysis identifies two distinct regimes for the Liouvillian gap in the thermodynamic limit, exemplified by the undoped and fully doped extreme cases. In both regimes, the dissipative diagnostic signals chaotic behavior, differing only in how the gap scales with system size. In the undoped circuit, the gap scales as $Δ\\sim γN$, whereas in the fully doped circuit it remains finite as $N\\to\\infty$. We find that the doping density $p_h$ governs the crossover: as $p_h\\to 0$, any spatial structure remains undoped-like, whereas for finite $p_h$ certain structures can enter a finite-gap regime. These results are analytically established in the strongly dissipative regime $γ\\gg 1$ by deriving lower bounds on the gap as a function of $p_h$ and explicit finite-gap constructions, and their extension toward $γ\\to 0$ is supported by numerics. Importantly, our analytic treatment depends only on the spatial doping structure, so the same gap scaling persists even when the Haar rotations are independently resampled each Floquet period."}
{"id": "2602.03276", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03276", "abs": "https://arxiv.org/abs/2602.03276", "authors": ["Uwe Holm", "Hans-Peter Weber", "Morgan Berkane", "Camilla Wulf", "Anton Kantz", "Anja Kuhnhold", "Andreas Buchleitner"], "title": "Thermodynamic state variables from a minimal set of quantum constituents", "comment": "6 pages, 4 figures", "summary": "We show how the macroscopic state variables pressure, entropy and temperature of equilibrium thermodynamics can be consistently derived from the (quantum) chaotic spectral structure of one or two particles in two-dimensional domains. This provides a definition of work and heat from first principles, a microscopic underpinning of the first and second law of thermodynamics, and a transparent illustration of the ``eigenstate thermalization hypothesis''."}
{"id": "2602.03291", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.03291", "abs": "https://arxiv.org/abs/2602.03291", "authors": ["Himuro Hashimoto", "Akio Nakabayashi", "Lento Nagano", "Yutaro Iiyama", "Ryu Sawada", "Junichi Tanaka", "Koji Terashi"], "title": "Comprehensive Numerical Studies of Barren Plateau and Overparametrization in Variational Quantum Algorithm", "comment": "16 pages, 15 figures", "summary": "The variational quantum algorithm (VQA) with a parametrized quantum circuit is widely applicable to near-term quantum computing, but its fundamental issues that limit optimization performance have been reported in the literature. For example, VQA optimization often suffers from vanishing gradients called barren plateau (BP) and the presence of local minima in the landscape of the cost function. Numerical studies have shown that the trap in local minima is significantly reduced when the circuit is overparametrized (OP), where the number of parameters exceeds a certain threshold. Theoretical understanding of the BP and OP phenomena has advanced over the past years, however, comprehensive studies of both effects in the same setting are not fully covered in the literature. In this paper, we perform a comprehensive numerical study in VQA, quantitatively evaluating the impacts of BP and OP and their interplay on the optimization of a variational quantum circuit, using concrete implementations of one-dimensional transverse and longitudinal field quantum Ising model. The numerical results are compared with the theoretical diagnostics of BP and OP phenomena. The framework presented in this paper will provide a guiding principle for designing VQA algorithms and ansatzes with theoretical support for behaviors of parameter optimization in practical settings."}
{"id": "2602.03296", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03296", "abs": "https://arxiv.org/abs/2602.03296", "authors": ["Shuo Ren", "Rui-Jian Liang", "Zhen-Xuan He", "Ji-Yang Zhou", "Wu-Xi Lin", "Zhi-He Hao", "Bing Chen", "Tao Tu", "Jin-Shi Xu", "Chuan-Feng Li", "Guang-Can Guo"], "title": "Decoherence-protected entangling gates in a silicon carbide quantum node", "comment": null, "summary": "Solid-state color centers are promising candidates for nodes in quantum network architectures. However, realizing scalable and fully functional quantum nodes, comprising both processor and memory qubits with high-fidelity universal gate operations, remains a central challenge in this field. Here, we demonstrate a fully functional quantum node in silicon carbide, where electron spins act as quantum processors and nuclear spins serve as quantum memory. Specifically, we design a pulse sequence that combines dynamical decoupling with hyperfine interactions to realize decoherence-protected universal gate operations between the processor and memory qubits. Leveraging this gate, we deterministically prepare entangled states within the quantum node, achieving a fidelity of 90%, which exceeds the fault-tolerance threshold of certain quantum network architectures. These results open a pathway toward scalable and fully functional quantum nodes based on silicon carbide."}
{"id": "2602.03336", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03336", "abs": "https://arxiv.org/abs/2602.03336", "authors": ["Kaito Kishi", "Riki Toshio", "Jun Fujisaki", "Hirotaka Oshima", "Shintaro Sato", "Keisuke Fujii"], "title": "Even More Efficient Soft-Output Decoding with Extra-Cluster Growth and Early Stopping", "comment": null, "summary": "In fault-tolerant quantum computing, soft outputs from real-time decoders play a crucial role in improving decoding accuracy, post-selecting magic states, and accelerating lattice surgery. A recent paper by Meister et al. [arXiv:2405.07433 (2024)] proposed an efficient method to evaluate soft outputs for cluster-based decoders, including the Union-Find (UF) decoder. However, in parallel computing environments, its computational complexity is comparable to or even surpasses that of the UF decoder itself, resulting in a substantial overhead. Furthermore, this method requires global information about the decoding graph, making it poorly suited for existing hardware implementations of the UF decoder on Field-Programmable Gate Arrays (FPGAs). In this paper, to alleviate these issues, we develop more efficient methods for evaluating high-quality soft outputs in cluster-based decoders by introducing several early-stopping techniques. Our central idea is that the precise value of a large soft output is often unnecessary in practice. Based on this insight, we introduce two types of novel soft-outputs: the bounded cluster gap and the extra-cluster gap. The former reduces the computational complexity of Meister's method by terminating the calculation at an early stage. Our numerical simulations show that this method achieves improved scaling with code distance $d$ compared to the original proposal. The latter, the extra-cluster gap, quantifies decoder reliability by performing a small, additional growth of the clusters obtained by the decoder. This approach offers the significant advantage of enabling soft-output computation without modifying the existing architecture of FPGA-implemented UF decoders. These techniques offer lower computational complexity and higher hardware compatibility, laying a crucial foundation for future real-time decoders with soft outputs."}
{"id": "2602.03378", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03378", "abs": "https://arxiv.org/abs/2602.03378", "authors": ["Giuliano Angelone", "Domenico Monaco", "Gabriele Peluso"], "title": "Zak phase and bulk-boundary correspondence in a generalized Dirac-Kronig-Penney model", "comment": "44 pages; 11 figures", "summary": "We investigate the topological properties of a generalized Dirac--Kronig--Penney model, a continuum one-dimensional model for a relativistic quantum chain. By tuning the coupling parameters this model can accommodate five Altland--Zirnbauer--Cartan symmetry classes, three of which (AIII, BDI and D) support non-trivial topological phases in dimension one. We characterize analytically the spectral properties of the Hamiltonian in terms of a spectral function, and numerically compute the Zak phase to probe the bulk topological content of the insulating phases. Our findings reveal that, while the Zak phase is quantized in classes AIII and BDI, it exhibits non-quantized values in class D, challenging its traditional role as a topological marker in continuum settings. We also discuss the bulk-boundary correspondence for a truncated version of the chain, analyzing how the emergence of edge states depends on both the truncation position and the boundary conditions. In classes AIII and BDI, we find that the Zak phase effectively detects edge states as a relative boundary topological index, although the correspondence is highly sensitive to the parameters characterizing the truncation."}
{"id": "2602.03405", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.03405", "abs": "https://arxiv.org/abs/2602.03405", "authors": ["Jeongbin Jo", "Santanam Wishal", "Shah Md Khalil Ullah", "Shan Kowalski", "Dikshant Dulai"], "title": "Enhancing Quantum Diffusion Models for Complex Image Generation", "comment": "18 pages, 6 figures", "summary": "Quantum generative models offer a novel approach to exploring high-dimensional Hilbert spaces but face significant challenges in scalability and expressibility when applied to multi-modal distributions. In this study, we explore a Hybrid Quantum-Classical U-Net architecture integrated with Adaptive Non-Local Observables (ANO) as a potential solution to these hurdles. By compressing classical data into a dense quantum latent space and utilizing trainable observables, our model aims to extract non-local features that complement classical processing. We also investigate the role of Skip Connections in preserving semantic information during the reverse diffusion process. Experimental results on the full MNIST dataset (digits 0-9) demonstrate that the proposed architecture is capable of generating structurally coherent and recognizable images for all digit classes. While hardware constraints still impose limitations on resolution, our findings suggest that hybrid architectures with adaptive measurements provide a feasible pathway for mitigating mode collapse and enhancing generative capabilities in the NISQ era."}
{"id": "2602.03456", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03456", "abs": "https://arxiv.org/abs/2602.03456", "authors": ["Q. Deplano", "A. Pontin", "F. Marino", "F. Marin"], "title": "Stationary entanglement of a levitated oscillator with an optical field", "comment": null, "summary": "We report the generation of quantum entanglement between the center-of-mass motion of a levitated nanosphere, coupled by coherent scattering to an optical cavity mode, and the electromagnetic field. Using heterodyne detection, we reconstruct the full set of optical-mechanical correlations and observe a violation of separability bounds between the mechanical degrees of freedom and the propagating optical mode. Thus, we demonstrate the ability to distribute nonclassical correlations beyond the interaction region. Our results are obtained at room temperature and are robust over a broad range of detunings set by the cavity linewidth. These findings establish levitated optomechanical systems as a promising platform for macroscopic quantum optics and for future tests of fundamental physics."}
{"id": "2602.03466", "categories": ["quant-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.03466", "abs": "https://arxiv.org/abs/2602.03466", "authors": ["Adriano Macarone-Palmieri"], "title": "Quantum Circuit Generation via test-time learning with large language models", "comment": "9 pages, 1 figure", "summary": "Large language models (LLMs) can generate structured artifacts, but using them as dependable optimizers for scientific design requires a mechanism for iterative improvement under black-box evaluation. Here, we cast quantum circuit synthesis as a closed-loop, test-time optimization problem: an LLM proposes edits to a fixed-length gate list, and an external simulator evaluates the resulting state with the Meyer-Wallach (MW) global entanglement measure. We introduce a lightweight test-time learning recipe that can reuse prior high-performing candidates as an explicit memory trace, augments prompts with a score-difference feedback, and applies restart-from-the-best sampling to escape potential plateaus. Across fixed 20-qubit settings, the loop without feedback and restart-from-the-best improves random initial circuits over a range of gate budgets. To lift up this performance and success rate, we use the full learning strategy. For 25-qubit, it mitigates a pronounced performance plateau when naive querying is used. Beyond raw scores, we analyze the structure of synthesized states and find that high MW solutions can correspond to stabilizer or graph-state-like constructions, but full connectivity is not guaranteed due to the metric property and prompt design. These results illustrate both the promise and the pitfalls of memory evaluator-guided LLM optimization for circuit synthesis, highlighting the critical role of prior human-made theoretical theorem to optimally design a custom tool in support of research."}
{"id": "2602.03482", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03482", "abs": "https://arxiv.org/abs/2602.03482", "authors": ["Michel Meulen", "Niels M. P. Neumann", "Jasper Verbree"], "title": "Evaluating Quantum Wire Cutting for QAOA: Performance Benchmarks in Ideal and Noisy Environments", "comment": null, "summary": "Current quantum computers suffer from a limited number of qubits and high error rates, limiting practical applicability. Different techniques exist to mitigate these effects and run larger algorithms. In this work, we analyze one of these techniques called quantum circuit cutting. With circuit cutting, a quantum circuit is decomposed into smaller sub-circuits, each of which can be run on smaller quantum hardware. We compare the performance of quantum circuit cutting with different cutting strategies, and then apply circuit cutting to a QAOA algorithm. Using simulations, we first show that Randomized Clifford measurements outperform both Pauli and random unitary measurements. Second, we show that circuit cutting has trouble providing correct answers in noisy settings, especially as the number of circuits increases."}
{"id": "2602.03522", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03522", "abs": "https://arxiv.org/abs/2602.03522", "authors": ["Anderson Fernandes Pereira dos Santos"], "title": "QRC-Lab: An Educational Toolbox for Quantum Reservoir Computing", "comment": null, "summary": "Quantum Reservoir Computing (QRC) has emerged as a strong pa- radigm for Noisy Intermediate-Scale Quantum (NISQ) machine learning, ena- bling the processing of temporal data with minimal training overhead by exploi- ting the high-dimensional dynamics of quantum states. This paper introduces QRC-Lab, an open-source, modular Python framework designed to bridge the gap between theoretical quantum dynamics and applied machine learning work- flows. We provide a rigorous definition of QRC, contrast physical and gate- based approaches, and formalize the reservoir mapping used in the toolbox. QRC-Lab instantiates a configurable gate-based laboratory for studying in- put encoding, reservoir connectivity, and measurement strategies, and validates these concepts through three educational case studies: short-term memory re- construction, temporal parity (XOR), and NARMA10 forecasting as a deliberate stress test. In addition, we include a learning-theory motivated generalization- gap scan to build intuition about capacity control in quantum feature maps. The full source code, experiment scripts, and reproducibility assets are publicly available at: https://doi.org/10.5281/zenodo.18469026."}
{"id": "2602.03534", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03534", "abs": "https://arxiv.org/abs/2602.03534", "authors": ["Ayanda Zungu", "Ilya Sinayskiy", "Francesco Petruccione"], "title": "Microscopic derivation of a completely positive master equation for the description of Open Quantum Brownian Motion of a particle in a potential", "comment": "19 pages, 6 figures", "summary": "Open Quantum Brownian Motion (OQBM) was introduced as a scaling limit of discrete-time open quantum walks. This limit defines a new class of quantum Brownian motion, which incorporates both the external and internal degrees of freedom of the Brownian particle. We consider a weakly driven Brownian particle confined in a harmonic potential and dissipatively coupled to a thermal bath. Applying the rotating wave approximation (RWA) to the system-bath interaction Hamiltonian, we derive a completely positive Born-Markov master equation for the reduced dynamics. We express the resulting master equation in the coordinate representation and, utilizing the adiabatic elimination of fast variables, derive a completely positive hybrid quantum-classical master equation that defines OQBM. We illustrate the resulting dynamics using examples of initial Gaussian and non-Gaussian distributions of the OQBM walker. Both examples reveal the emergence of Gaussian distributions in the limiting behavior of the OQBM dynamics, which closely matches that of the standard OQBM. With the help of the obtained OQBM master equation, we derive the equations for the $n$-th moments and the cumulants of the position distribution of the open Brownian walker. We subsequently solve these equations numerically for Gaussian initial distributions across various parameter regimes. Notably, we find that the third-order cumulant is nonzero, indicating that the dynamics' intrinsic generator is non-Gaussian."}
{"id": "2602.03536", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03536", "abs": "https://arxiv.org/abs/2602.03536", "authors": ["Leo Sünkel", "Michael Kölle", "Tobias Rohe", "Claudia Linnhoff-Popien"], "title": "An Evaluation of the Remote CX Protocol under Noise in Distributed Quantum Computing", "comment": "Accepted at IEEE ICC 2026", "summary": "Quantum computers connected through classical and quantum communication channels can be combined to function as a single unit to run large quantum circuits that each device is unable to execute on their own. The distributed quantum computing paradigm is therefore often seen as a potential pathway to scaling quantum computing to capacities necessary for practical and large-scale applications. Whether connecting multiple quantum processing units (QPUs) in clusters or over networks, quantum communication requires entanglement to be generated and distributed over distances. Using entanglement, the remote CX protocol can be performed, which allows the application of the CX gate involving qubits located in different QPUs. In this work, we use a specialized simulation framework for a high-level evaluation of the impact of the protocol when executed under noise in various network configurations using different number of QPUs. We compare naive and graph partitioning qubit assignment strategies and how they affect the fidelity in experiments run on Grover, GHZ, VQC, and random circuits. The results provide insights on how QPU and network configurations or naive scheduling can degrade performance."}
{"id": "2602.03605", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03605", "abs": "https://arxiv.org/abs/2602.03605", "authors": ["Benjamin Wong", "Sergey Bravyi", "David Gosset", "Yinchen Liu"], "title": "Lee-Yang tensors and Hamiltonian complexity", "comment": "37 pages, 6 figures", "summary": "A complex tensor with $n$ binary indices can be identified with a multilinear polynomial in $n$ complex variables. We say it is a Lee-Yang tensor with radius $r$ if the polynomial is nonzero whenever all variables lie in the open disk of radius $r$. In this work we study quantum states and observables which are Lee-Yang tensors when expressed in the computational basis. We first review their basic properties, including closure under tensor contraction and certain quantum operations. We show that quantum states with Lee-Yang radius $r > 1$ can be prepared by quasipolynomial-sized circuits. We also show that every Hermitian operator with Lee-Yang radius $r > 1$ has a unique principal eigenvector. These results suggest that $r = 1$ is a key threshold for quantum states and observables. Finally, we consider a family of two-local Hamiltonians where every interaction term energetically favors a deformed EPR state $|00\\rangle + s|11\\rangle$ for some $0 \\leq s \\leq 1$. We numerically investigate this model and find that on all graphs considered the Lee-Yang radius of the ground state is at least $r = 1/\\sqrt{s}$ while the spectral gap between the two smallest eigenvalues is at least $1-s^2$. We conjecture that these lower bounds hold more generally; in particular, this would provide an efficient quantum adiabatic algorithm for the quantum Max-Cut problem on uniformly weighted bipartite graphs."}
{"id": "2602.03618", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03618", "abs": "https://arxiv.org/abs/2602.03618", "authors": ["Hao-Yu Guan", "Xiao-Long Zhu", "Yu-Hang Dang", "Xiu-Hao Deng"], "title": "Optimal Effective Hamiltonian for Quantum Computing and Simulation", "comment": "Main text: 18 pages, 9 figures; Supplementary Material: 17 pages", "summary": "The effective Hamiltonian serves as the conceptual pivot of quantum engineering, transforming physical complexity into programmable logic; yet, its construction remains compromised by the mathematical non-uniqueness of block diagonalization, which introduces an intrinsic \"gauge freedom\" that standard methods fail to resolve. We address this by establishing the Least Action Unitary Transformation (LAUT) as the fundamental principle for effective models. By minimizing geometric action, LAUT guarantees dynamical fidelity and inherently enforces the preservation of symmetries--properties frequently violated by conventional Schrieffer-Wolff and Givens rotation techniques. We identify the Bloch-Brandow formalism as the natural perturbative counterpart to this principle, yielding analytic expansions that preserve symmetries to high order. We validate this framework against experimental data from superconducting quantum processors, demonstrating that LAUT quantitatively reproduces interaction rates in driven entangling gates where standard approximations diverge. Furthermore, in tunable coupler architectures, we demonstrate that the LAUT approach captures essential non-rotating-wave contributions that standard models neglect; this inclusion is critical for quantitatively reproducing interaction rates and revealing physical multi-body interactions such as $XZX+YZY$, which are verified to be physical rather than gauge artifacts. By reconciling variational optimality with analytical tractability, this work provides a systematic, experimentally validated route for high-precision system learning and Hamiltonian engineering."}
{"id": "2602.03675", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03675", "abs": "https://arxiv.org/abs/2602.03675", "authors": ["George Mihailescu", "Karol Gietka"], "title": "Anti-Critical Quantum Metrology", "comment": "10 pages, 5 figures", "summary": "Critical quantum metrology exploits the dramatic growth of the quantum Fisher information near quantum phase transitions to enhance the precision of parameter estimation. Traditionally, this enhancement is associated with a closing energy gap, which causes the characteristic timescales for adiabatic preparation or relaxation to diverge with increasing system size. Consequently, the apparent growth of the quantum Fisher information largely reflects the increasing evolution time induced by critical slowing down, rather than a genuine gain in metrological performance, thereby severely limiting the practical usefulness of such protocols. Here we show that the relationship between energy-gap variations, quantum Fisher information, and achievable precision is far more subtle in interacting quantum systems: enhanced sensitivity does not require a vanishing gap, and, perhaps more surprisingly, a decreasing quantum Fisher information does not necessarily imply reduced precision once the time is properly taken into account. Building on this insight, we introduce an anti-critical metrology scheme that achieves enhanced precision while the energy gap increases. We illustrate this mechanism using the quantum Rabi model, thereby identifying a route to metrological advantage that avoids the critical slowing down associated with conventional criticality."}
{"id": "2602.03706", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03706", "abs": "https://arxiv.org/abs/2602.03706", "authors": ["Robert Czupryniak", "Bibek Bhandari", "Paolo Andrea Erdman", "Andrew N Jordan"], "title": "Universal Characterization of Quantum Vacuum Measurement Engines", "comment": "26 pages: 6 pages - main body, 20 pages - supplementary material. 6 figures, 2 tables", "summary": "Quantum measurements can inject energy into quantum systems, enabling engines whose operation is powered entirely by measurements. We develop a general theory of quantum vacuum measurement engines by introducing the quantum vacuum bending function (QVBF), a quantity that characterizes the lowering of the ground-state energy due to interactions. We show that all thermodynamic observables, including work and efficiency, are governed solely by the shape of the ground-state energy landscape encoded in the QVBF, regardless of microscopic details. We further demonstrate that work fluctuations are defined by the curvature of QVBF modulated by a model-dependent quantity, and are constrained by a generalized quantum fluctuation relation that involves the interplay between quantum Fisher information and the ground-state energy landscape. Exactly solvable models and numerical simulations of single and many-body systems confirm the theory and illustrate how the QVBF alone determines the performance of quantum vacuum measurement engines."}
{"id": "2602.03710", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03710", "abs": "https://arxiv.org/abs/2602.03710", "authors": ["Amandeep Singh Bhatia", "Sabre Kais"], "title": "Quantum Computing for Electronic Circular Dichroism Spectrum Prediction of Chiral Molecules", "comment": null, "summary": "Electronic circular dichroism (ECD) spectroscopy captures the chiroptical response of molecules, enabling absolute configuration assignment that is vital for enantioselective synthesis and drug design. The practical use of ECD spectra in predictive modeling remains restricted, as existing approaches offer limited confidence for chiral discrimination. By contrast, theoretical ECD calculations demand substantial computational effort rooted in electronic structure theory, which constrains their scalability to larger chemically diverse molecules. These limitations underscore the need for computational approaches that retain first principles physical rigor while enabling efficient and scalable prediction. Motivated by recent advances in quantum algorithms for chemistry, we introduce a variational quantum framework combined with the quantum equation of motion formalism to compute molecular properties and predict ECD spectra, implemented within a multi GPU or QPU accelerated hybrid quantum/classical workflow. We demonstrate its efficient applicability on 12 clinically relevant chiral drug molecules accessing expanded active spaces. The proposed framework is assessed by comparison with established classical wavefunction based methods, employing Coupled Cluster Singles and Doubles (CCSD) for ground-state energy benchmarks and Complete Active Space Configuration Interaction (CASCI) as the reference method for excited state energies and chiroptical properties within the same active orbital space. Notably, the quantum computed ECD spectra, obtained from chemically relevant active spaces mapped onto quantum circuits of approximately 20 to 24 qubits, exhibit near quantitative agreement with classical reference calculations, accurately reproducing spectral line shapes, Cotton effect signs, and relative peak intensities."}
{"id": "2602.03725", "categories": ["quant-ph", "cs.DS", "q-fin.CP", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2602.03725", "abs": "https://arxiv.org/abs/2602.03725", "authors": ["Dylan Herman", "Yue Sun", "Jin-Peng Liu", "Marco Pistoia", "Charlie Che", "Rob Otter", "Shouvanik Chakrabarti", "Aram Harrow"], "title": "Quantum Speedups for Derivative Pricing Beyond Black-Scholes", "comment": null, "summary": "This paper explores advancements in quantum algorithms for derivative pricing of exotics, a computational pipeline of fundamental importance in quantitative finance. For such cases, the classical Monte Carlo integration procedure provides the state-of-the-art provable, asymptotic performance: polynomial in problem dimension and quadratic in inverse-precision. While quantum algorithms are known to offer quadratic speedups over classical Monte Carlo methods, end-to-end speedups have been proven only in the simplified setting over the Black-Scholes geometric Brownian motion (GBM) model. This paper extends existing frameworks to demonstrate novel quadratic speedups for more practical models, such as the Cox-Ingersoll-Ross (CIR) model and a variant of Heston's stochastic volatility model, utilizing a characteristic of the underlying SDEs which we term fast-forwardability. Additionally, for general models that do not possess the fast-forwardable property, we introduce a quantum Milstein sampler, based on a novel quantum algorithm for sampling Lévy areas, which enables quantum multi-level Monte Carlo to achieve quadratic speedups for multi-dimensional stochastic processes exhibiting certain correlation types.\n  We also present an improved analysis of numerical integration for derivative pricing, leading to substantial reductions in the resource requirements for pricing GBM and CIR models. Furthermore, we investigate the potential for additional reductions using arithmetic-free quantum procedures. Finally, we critique quantum partial differential equation (PDE) solvers as a method for derivative pricing based on amplitude estimation, identifying theoretical barriers that obstruct achieving a quantum speedup through this approach. Our findings significantly advance the understanding of quantum algorithms in derivative pricing, addressing key challenges and open questions in the field."}
{"id": "2602.03727", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03727", "abs": "https://arxiv.org/abs/2602.03727", "authors": ["Piotr T. Grochowski", "Matteo Fadel", "Radim Filip"], "title": "Distributed Phase-Insensitive Displacement Sensing", "comment": "8+16 pages, 1+2 figures", "summary": "Distributed quantum sensing leverages quantum correlations among multiple sensors to enhance the precision of parameter estimation beyond classical limits. Most existing approaches target phase estimation and rely on a shared phase reference between the signal and the probe, yet many relevant scenarios deal with regimes where such a reference is absent, making the estimation of force or field amplitudes the main task. We study this phase-insensitive regime for bosonic sensors that undergo identical displacements with common phases randomly varying between experimental runs. We derive analytical bounds on the achievable precision and show that it is determined by first-order normal correlations between modes in the probe state, constrained by their average excitations. These correlations yield a collective sensitivity enhancement over the standard quantum limit, with a gain that grows linearly in the total excitation number, revealing a distributed quantum advantage even without a global phase reference. We identify families of multimode states with definite joint parity that saturate this limit and can be probed efficiently via local parity measurements already demonstrated or emerging in several quantum platforms. We further demonstrate that experimentally relevant decoherence channels favor two distinct sensing strategies: splitting of a single-mode nonclassical state among the modes, which is robust to loss and heating, and separable probes, which are instead resilient to dephasing and phase jitter. Our results are relevant to multimode continuous platforms, including trapped-ion, solid-state mechanical, optomechanical, superconducting, and photonic systems."}
{"id": "2602.03734", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03734", "abs": "https://arxiv.org/abs/2602.03734", "authors": ["Mikhail Mamaev", "Jayameenakshi Venkatraman", "Martin Koppenhöfer", "Ania C. Bleszynski Jayich", "Aashish A. Clerk"], "title": "Detecting quantum noise of a solid-state spin ensemble with dispersive measurement", "comment": "13+11 pages, 5 figures", "summary": "We theoretically explore protocols for measuring the spin polarization of an ensemble of solid-state spins, with precision at or below the standard quantum limit. Such measurements in the solid-state are challenging, as standard approaches based on optical fluorescence are often limited by poor readout fidelity. Indirect microwave resonator-mediated measurements provide an attractive alternative, though a full analysis of relevant sources of measurement noise is lacking. In this work we study dispersive readout of an inhomogeneously broadened spin ensemble via coupling to a driven resonator measured via homodyne detection. We derive generic analytic conditions for when the homodyne measurement can be limited by the fundamental spin-projection noise, as opposed to microwave-drive shot noise or resonator phase noise. By studying fluctuations of the measurement record in detail, we also propose an experimental protocol for directly detecting spin squeezing, i.e. a reduction of the spin ensemble's intrinsic projection noise from entanglement. Our protocol provides a method for benchmarking entangled states for quantum-enhanced metrology."}
{"id": "2602.03765", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.03765", "abs": "https://arxiv.org/abs/2602.03765", "authors": ["Théo Lejeune", "Miha Papič", "John Goold", "Felix C. Binder", "François Damanet", "Mattia Moroder"], "title": "Accelerating qubit reset through the Mpemba effect", "comment": "19 pages, 9 figures", "summary": "Passive qubit reset is a key primitive for quantum information processing, whereby qubits are initialized by allowing them to relax to their ground state through natural dissipation, without the need for active control or feedback. However, passive reset occurs on timescales that are much longer than those of gate operations and measurements, making it a significant bottleneck for algorithmic execution. Here, we show that this limitation can be overcome by exploiting the Mpemba effect, originally indicating the faster cooling of hot systems compared to cooler ones. Focusing on the regime where coherence times exceed energy relaxation times ($T_2 > T_1$), we propose a simple protocol based on a single entangling two-qubit gate that converts local single-qubit coherences into fast-decaying global two-qubit coherences. This removes their overlap with the slowest decaying Liouvillian mode and enables a substantially faster relaxation to the ground state. For realistic parameters, we find that our protocol can reduce reset times by up to $50\\%$ compared to standard passive reset. We analyze the robustness of the protocol under non-Markovian noise, imperfect coherent control and finite temperature, finding that the accelerated reset persists across a broad range of realistic error sources. Finally, we present an experimental implementation of our protocol on an IQM superconducting quantum processor. Our results demonstrate how Mpemba-like accelerated relaxation can be harnessed as a practical tool for fast and accurate qubit initialization."}
{"id": "2602.02649", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02649", "abs": "https://arxiv.org/abs/2602.02649", "authors": ["Iao-Fai Io", "Fu-Hsiang Huang", "Chang-Tse Hsieh"], "title": "Non-Hermitian free-fermion critical systems and logarithmic conformal field theory", "comment": "6+12 pages, 1 figure, 1 table", "summary": "Conformal invariance often accompanies criticality in Hermitian systems. However, its fate in non-Hermitian settings is less clear, especially near exceptional points where the Hamiltonian becomes non-diagonalizable. Here we investigate whether a 1+1-dimensional gapless non-Hermitian system can admit a conformal description, focusing on a PT-symmetric free-fermion field theory. Working in the biorthogonal formalism, we identify the conformal structure of this theory by constructing a traceless energy-momentum tensor whose Fourier modes generate a Virasoro algebra with central charge $c=-2$. This yields a non-Hermitian, biorthogonal realization of a logarithmic conformal field theory, in which correlation functions exhibit logarithmic scaling and the spectrum forms Virasoro staggered modules that are characterized by universal indecomposability parameters. We further present a microscopic construction and show how the same conformal data (with finite-size corrections) can be extracted from the lattice model at exceptional-point criticality, thereby supporting the field-theory prediction."}
{"id": "2602.02665", "categories": ["cond-mat.str-el", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02665", "abs": "https://arxiv.org/abs/2602.02665", "authors": ["Luciano Loris Viteritti", "Riccardo Rende", "Subir Sachdev", "Giuseppe Carleo"], "title": "Approaching the Thermodynamic Limit with Neural-Network Quantum States", "comment": "10 pages, 8 figures, 2 tables", "summary": "Accessing the thermodynamic-limit properties of strongly correlated quantum matter requires simulations on very large lattices, a regime that remains challenging for numerical methods, especially in frustrated two-dimensional systems. We introduce the Spatial Attention mechanism, a minimal and physically interpretable inductive bias for Neural-Network Quantum States, implemented as a single learned length scale within the Transformer architecture. This bias stabilizes large-scale optimization and enables access to thermodynamic-limit physics through highly accurate simulations on unprecedented system sizes within the Variational Monte Carlo framework. Applied to the spin-$\\tfrac12$ triangular-lattice Heisenberg antiferromagnet, our approach achieves state-of-the-art results on clusters of up to $42\\times42$ sites. The ability to simulate such large systems allows controlled finite-size scaling of energies and order parameters, enabling the extraction of experimentally relevant quantities such as spin-wave velocities and uniform susceptibilities. In turn, we find extrapolated thermodynamic limit energies systematically better than those obtained with tensor-network approaches such as iPEPS. The resulting magnetization is strongly renormalized, $M_0=0.148(1)$ (about $30\\%$ of the classical value), revealing that less accurate variational states systematically overestimate magnetic order. Analysis of the optimized wave function further suggests an intrinsically non-local sign structure, indicating that the sign problem cannot be removed by local basis transformations. We finally demonstrate the generality of the method by obtaining state-of-the-art energies for a $J_1$-$J_2$ Heisenberg model on a $20\\times20$ square lattice, outperforming Residual Convolutional Neural Networks."}
{"id": "2602.02732", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02732", "abs": "https://arxiv.org/abs/2602.02732", "authors": ["Charles Snider", "Stephen Carr", "D. E. Feldman", "Chandrasekhar Ramanathan", "V. F. Mitrović"], "title": "Dynamic Simulations of Strongly Coupled Spin Ensembles for Inferring Nature of Electronic Correlations from Nuclear Magnetic Resonance", "comment": "62 pages, 14 figures", "summary": "We develop an efficient package for the simulation of nuclear magnetic resonance spin echo experiments to study the effects of strong electronic spin correlations on the dynamics of the nuclear spin ensemble. A mean-field model is used to study correlated electronic phases through their hyperfine interaction with nuclear spins. We explore the dynamics of the interacting nuclear ensemble and discuss the key behaviors of the system. In particular, we classify the types of temporal asymmetry that the interaction induces in the system as well as a pulse-dependent shift in the spectral domain. Us- ing these results, we discuss how careful measurement of the pulse-dependent shiftcanbeusedtoextractinformationabouttheanisotropyoftheelectronic interaction and how these results represent a novel tool for the examination of exotic NMR signatures in strongly correlated materials. Finally, we re- view specific aspects of the simulation package developed for our exploration and give explicit examples where package can be used to infer range and anisotropy of electronic correlations. In particular, we discuss its structure, accuracy, and the technical merits of the various approximations used to model the nuclear spin ensemble."}
{"id": "2602.02904", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.02904", "abs": "https://arxiv.org/abs/2602.02904", "authors": ["Tymoteusz Braciszewski", "Oliwier Urbański", "Piotr Tomczak"], "title": "Quantum phase transition in transverse-field Ising model on Sierpiński gasket lattice", "comment": null, "summary": "We study quantum phase transition in the transverse-field Ising model on the Sierpiński gasket. By applying finite-size scaling and numerical renormalization group methods, we determine the critical coupling and the exponents that describe this transition. We first checked our finite-size scaling and the renormalization methods on the exactly solvable one-dimensional chain, where we recovered proper values of critical couplings and exponents. Then, we applied the method to the Sierpiński gasket with 11 and 15 spins. We found a quantum critical point at $λ_c \\approx 2.72$ to $2.93$, with critical exponents $z\\approx0.84$, $ν\\approx 1.12 $, $β\\approx 0.30$, and $γ\\approx 2.54$. The lower dynamical exponent $z$ indicates that quantum fluctuations slow down due to fractal geometry, yielding an effective critical dimension of about 2.43. The numerical renormalization group method yielded similar results $λ_c = 2.765$, $β= 0.306$, supporting our findings. These exponents differ from those in both the one-dimensional and mean-field cases."}
{"id": "2602.03031", "categories": ["cond-mat.dis-nn", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03031", "abs": "https://arxiv.org/abs/2602.03031", "authors": ["Kimihiro Yamazaki", "Itsushi Sakata", "Takuya Konishi", "Yoshinobu Kawahara"], "title": "Physics-inspired transformer quantum states via latent imaginary-time evolution", "comment": null, "summary": "Neural quantum states (NQS) are powerful ansätze in the variational Monte Carlo framework, yet their architectures are often treated as black boxes. We propose a physically transparent framework in which NQS are treated as neural approximations to latent imaginary-time evolution. This viewpoint suggests that standard Transformer-based NQS (TQS) architectures correspond to physically unmotivated effective Hamiltonians dependent on imaginary time in a latent space. Building on this interpretation, we introduce physics-inspired transformer quantum states (PITQS), which enforce a static effective Hamiltonian by sharing weights across layers and improve propagation accuracy via Trotter-Suzuki decompositions without increasing the number of variational parameters. For the frustrated $J_1$-$J_2$ Heisenberg model, our ansätze achieve accuracies comparable to or exceeding state-of-the-art TQS while using substantially fewer variational parameters. This study demonstrates that reinterpreting the deep network structure as a latent cooling process enables a more physically grounded, systematic, and compact design, thereby bridging the gap between black-box expressivity and physically transparent construction."}
{"id": "2602.03764", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03764", "abs": "https://arxiv.org/abs/2602.03764", "authors": ["Pedro V. Paraguassú"], "title": "Stochastic Thermodynamics of Quantum-Induced Stochastic Dynamics", "comment": "12 pages, 3 appendix", "summary": "Quantum-Induced Stochastic Dynamics arises from the coupling between a classical system and a quantum environment. Unlike standard thermal reservoirs, this environment acts as a dynamic bath, capable of simultaneously exchanging heat and performing work. We formulate a thermodynamic framework for this semi-classical regime, defining heat, work, and entropy production. We derive a modified Second Law that accounts for non-equilibrium quantum features, such as squeezing. The framework is exemplified by an optomechanical setup, where we characterize the thermodynamics of the non-stationary noise induced by the cavity field."}
{"id": "2602.03843", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03843", "abs": "https://arxiv.org/abs/2602.03843", "authors": ["Aadi Singh", "Chakradhar Rangi", "Ka-Ming Tam"], "title": "Classical Benchmarks of a Symmetry-Adapted Variational Quantum Eigensolver for Real-Time Green's Functions in Dynamical Mean-Field Theory", "comment": "11 pages, 6 figures", "summary": "We present a variational quantum eigensolver (VQE) approach for solving the Anderson Impurity Model (AIM) arising in Dynamical Mean-Field Theory (DMFT). Recognizing that the minimal two-site approximation often fails to resolve essential spectral features, we investigate the efficacy of VQE for larger bath discretizations while adhering to near-term hardware constraints. We employ a symmetry-adapted ansatz enforcing conservation of particle number $(N)$, spin projection $(S_z=0)$, and total spin $(S^2=0)$ symmetry, benchmarking the performance against exact diagonalization across different interaction strengths using bath parameters extracted from the DMFT self-consistency loop. For a four-site model, the relative error in the ground state energy remains well below $0.01%$ with a compact parameter set $(N_p \\le 30)$. Crucially, we demonstrate that the single-particle Green's function-the central quantity for DMFT-can be accurately extracted from VQE-prepared ground states via real-time evolution in the intermediate to strong interaction regimes. However, in the weak interaction regime, the Green's function exhibits noticeable deviations from the exact benchmark, particularly in resolving low-energy spectral features, despite the ground state energy showing excellent agreement. These findings demonstrate that VQE combined with real-time evolution can effectively extend quantum-classical hybrid DMFT beyond the two-site approximation, particularly for describing insulating phases. While this approach offers a viable pathway for simulating strongly correlated materials on near-term devices, the observation that accurate ground state energy does not guarantee accurate dynamical properties highlights a key challenge for applying such approaches to correlated metals."}
{"id": "2602.03848", "categories": ["cond-mat.str-el", "cond-mat.supr-con", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.03848", "abs": "https://arxiv.org/abs/2602.03848", "authors": ["Donghae Seo", "Taegon Lee", "Gil Young Cho"], "title": "A Unified Categorical Description of Quantum Hall Hierarchy and Anyon Superconductivity", "comment": "14 pages, 1 figure, 1 table", "summary": "We present a unified category-theoretic framework for quantum Hall hierarchy constructions and anyon superconductivity based on modular tensor categories over $\\mathrm{Rep}(\\mathrm{U}(1))$ and $\\mathrm{sRep}(\\mathrm{U}(1)^f)$. Our approach explicitly incorporates conserved $\\mathrm{U}(1)$ charge and formulates doping via a generalized stack-and-condense procedure, in which an auxiliary topological order is stacked onto the parent phase, and the quasiparticles created by doping subsequently condense. Depending on whether this condensation preserves or breaks the $\\mathrm{U}(1)$ symmetry, the system undergoes a transition to a quantum Hall hierarchy state or to an anyon superconductor. For anyon superconductors, the condensate charge is determined unambiguously by the charged local bosons contained in the condensable algebra. Our framework reproduces all known anyon superconductors obtained from field-theoretic analyses and further predicts novel phases, including a charge-$2e$ anyon superconductor derived from the Laughlin state and charge-$ke$ anyon superconductors arising from bosonic $\\mathbb{Z}_k$ Read-Rezayi states. By placing hierarchy transitions and anyon superconductivity within a single mathematical formalism, our work provides a unified understanding of competing and proximate phases near experimentally realizable fractional quantum Hall states."}
