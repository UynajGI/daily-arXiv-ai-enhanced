{"id": "2602.13410", "categories": ["cond-mat.stat-mech", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.13410", "abs": "https://arxiv.org/abs/2602.13410", "authors": ["Stephen Whitelam"], "title": "Evolutionary design of thermodynamic logic gates and their heat emission", "comment": null, "summary": "Landauer's principle bounds the heat generated by logical operations, but in practice the thermodynamic cost of computation is dominated by the control systems that implement logic. CMOS gates dissipate energy far above the Landauer bound, while laboratory demonstrations of near-Landauer erasure rely on external measurement or feedback systems whose energy costs exceed that of the logic operation by many orders of magnitude. Here we use simulations to show that a genetic algorithm can program a thermodynamic computer to implement logic operations in which the total heat emitted by the control system is of a similar order of magnitude to that of the information-bearing degrees of freedom. Moreover, the computer can be programmed so that heat is drawn away from the information-bearing degrees of freedom and dissipated within the control unit, suggesting the possibility of computing architectures in which heat management is an integral part of the program design."}
{"id": "2602.13664", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.13664", "abs": "https://arxiv.org/abs/2602.13664", "authors": ["Yikun Ren", "Feixiang Xu", "Ming Lin"], "title": "Operationalizing the Arrow of Time in mesoscopic: A Unified Framework for Non-equilibrium Matter", "comment": null, "summary": "What sustains a non-equilibrium system against fluctuations from within - as witnessed in non-equilibrium steady states, glassy relaxation, and even living organisms? Here we show that the arrow of time itself can be operationalized into a measurable physical quantity on mesoscopic particles - the eigen-phase displacement. This displacement gives rise to a non-local generalized force, the thermodynamic inertia force, which emerges from the integrated contribution of local constraints rather than as a conventional local force. It actively counteracts fluctuations and its algebraic structure is a semi-group, fundamentally distinct from the Lie group of Newton inertia, thereby encoding the irreversibility of time's arrow. Building on this foundation, we construct a unified Microstate-Sequence-Mode-Coupling (MSS-MCT) theory. Its thermodynamic limit is defined by Microstate Sequence (MSS) theory, and its dynamical action is captured by a consequent mode-coupling theory (MCT). From this single first-principles framework, we simultaneously resolve two long-standing puzzles: it predicts the giant non-Gaussian parameter(1~10), closing the order-of-magnitude gap with experiments that standard mode-coupling theory could not explain; and it delivers a first-principles, non-fitting derivation of the universal polymer constant $C_{1} \\approx 16.7$ with merely 1 percent error - the most accurate theoretical prediction to date, dramatically surpassing the Adam-Gibbs and others. Our work establishes thermodynamic inertia as a foundational principle for non-equilibrium matter, bridging thermodynamic and dynamic descriptions from glassy relaxation to the maintenance of life."}
{"id": "2602.13765", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.13765", "abs": "https://arxiv.org/abs/2602.13765", "authors": ["Cong Fu", "Youhui Lin", "Shanhe Su", "Yu-Han Ma"], "title": "Non-monotonic Irreversibility in Polytropic Steering", "comment": "11 pages, 3 figures, comments are welcome", "summary": "The efficient manipulation of thermodynamic states within the finite time is fundamentally constrained by the intrinsic dissipative cost. While the slow-driving regime is well-characterized by a universal $1/τ$-scaling of irreversibility, the physics governing fast, non-adiabatic transitions remains elusive. Here, we propose the polytropic steering protocols that provide an exact analytical bridge between the isothermal and adiabatic limits for Brownian particles far-from-equilibrium. We demonstrate that for any protocol duration $τ$, the system can be precisely steered along a prescribed polytropic trajectory, revealing a striking non-monotonic dependence of irreversibility on the driving rate. Contrary to the near-equilibrium paradigm where faster driving necessitates higher energetic costs, we identify a most-irreversible timescale, beyond which dissipation is anomalously suppressed by rapid driving. By mapping these protocols onto a broad class of controllable thermodynamic cycle, we establish power-efficiency tradeoffs and position the polytropic index as a genuine thermodynamic control knob for the rational design of high-speed, high-performance microscopic thermal machines."}
{"id": "2602.13916", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13916", "abs": "https://arxiv.org/abs/2602.13916", "authors": ["J. Sirker"], "title": "Bulk-boundary correspondence in topological two-dimensional non-Hermitian systems: Toeplitz operators and singular values", "comment": "29 pages", "summary": "In contrast to eigenvalue-based approaches, we formulate the bulk-boundary correspondence for two-dimensional non-Hermitian quadratic lattice Hamiltonians in terms of Toeplitz operators and singular values, which correctly capture the stability, localization, and scaling of edge and corner modes. We show that singular values, rather than eigenvalues, provide the only stable foundation for topological protection in non-Hermitian systems because they remain robust under translational-symmetry-breaking perturbations that destabilize the eigenvalue spectrum, rendering it unsuitable for topological classification. Building on Toeplitz operator theory, we establish general results for non-Hermitian Hamiltonians defined on half and quarter planes, relating the topological indices of the associated Toeplitz operators to the number of finite-size singular values that are separated from the bulk singular-value spectrum and vanish in the thermodynamic limit. This yields a precise bulk-boundary correspondence for edge and corner modes, including higher-order topological phases, without requiring crystalline symmetries. We illustrate our general results with detailed examples exhibiting topologically protected families of edge states, coexisting edge and corner modes, and phases with both gapped bulk and edges supporting only stable corner modes. The latter is exemplified by a non-Hermitian generalization of the Benalcazar-Bernevig-Hughes model."}
{"id": "2602.13386", "categories": ["quant-ph", "cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.13386", "abs": "https://arxiv.org/abs/2602.13386", "authors": ["Ainesh Bakshi", "Soonwon Choi", "Saúl Pilatowsky-Cameo"], "title": "Entanglement in quantum spin chains is strictly finite at any temperature", "comment": "32 pages, 1 figure", "summary": "Entanglement is the hallmark of quantum physics, yet its characterization in interacting many-body systems at thermal equilibrium remains one of the most important challenges in quantum statistical physics. We prove that the Gibbs state of any quantum spin chain can be exactly decomposed into a mixture of matrix product states with a bond dimension that is independent of the system size, at any finite temperature. As a consequence, the Schmidt number, arguably the most stringent measure of bipartite entanglement, is strictly finite for thermal states, even in the thermodynamic limit. Our decomposition is explicit and is accompanied by an efficient classical algorithm to sample the resulting matrix product states."}
{"id": "2602.13374", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13374", "abs": "https://arxiv.org/abs/2602.13374", "authors": ["Fabian J. Pauw", "Thomas Köhler", "Ulrich Schollwöck", "Sebastian Paeckel"], "title": "Adaptive Pseudoboson Density-Matrix Renormalization Group for Dilute 2D Systems", "comment": "14 pages, 6 figures", "summary": "Simulating strongly correlated systems in two dimensions is notoriously challenging due to rapid entanglement growth and frustration. Here, we introduce the adaptive projected-purified pseudoboson density-matrix renormalization group (A3P-DMRG) tailored to explore the ground states of dilute lattice models. The method compresses cluster Hilbert spaces by retaining only the most probable low-occupation Fock states, identified via probabilistic bounds and refined through a self-consistent mean-field basis optimization. We demonstrate that A3P-DMRG is advantageous in low-filling and weak-coupling regimes for large system sizes where conventional DMRG struggles. This establishes the method as a versatile tool for studying dilute quantum many-body systems relevant to ultra-cold atom quantum simulators, photonic lattices, Moiré materials and quantum chemistry."}
{"id": "2602.13775", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.13775", "abs": "https://arxiv.org/abs/2602.13775", "authors": ["Alessandro Bellina", "Gabriele Di Bona", "Giordano De Marzo", "Vittorio Loreto"], "title": "The gold-rush effect: how innovation speeds up", "comment": null, "summary": "Innovation records often exhibit \"hockey-stick\" patterns of abrupt, near-singular growth at the collective level. However, this macroscopic explosiveness stands in stark contrast to individual discovery, which remains bounded by cognitive and temporal constraints and follows slow, sublinear accumulation laws. Here, we resolve this micro-macro discrepancy by introducing a minimal multi-scale model that identifies the growth of the explorer population as the primary driver of aggregate acceleration. Building on the Theory of the Adjacent Possible and the Urn Model with Triggering (UMT), we demonstrate that as discoveries expand the space of possibilities, they attract new explorers through a self-reinforcing branching process. This expansion induces a nonlinear mapping between intrinsic time (individual discovery events) and natural time (calendar years), effectively reparameterizing steady individual trajectories into accelerating system-level dynamics. We validate the framework using large-scale patent (EPO) and scientific publication (OpenAlex) datasets, showing that the model accurately reproduces stable per-capita productivity alongside exponential aggregate growth. By providing a quantitative link between individual behavior and collective takeoffs, this work offers a unified foundation for understanding the statistical structure and temporal evolution of innovation ecosystems."}
{"id": "2602.14026", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.14026", "abs": "https://arxiv.org/abs/2602.14026", "authors": ["Qi-Bo Zeng", "Rong Lü"], "title": "Coexistence of Topological Anderson Insulator and Multifractal Critical Phase in a Non-Hermitian Quasicrystal", "comment": "7 pages, 4 figures", "summary": "The interplay of topology, disorder, and non-Hermiticity gives rise to phenomena beyond the conventional classification of quantum phases. We propose a one-dimensional non-Hermitian Su-Schrieffer-Heeger model with quasiperiodically modulated nonreciprocal intracell hopping. We show that quasiperiodic modulation can substantially enhance topological robustness and, remarkably, induce a non-Hermitian topological Anderson insulator (TAI) phase. Beyond the topological transition, increasing nonreciprocity drives a cascade of localization transitions in which all bulk eigenstates evolve from extended to multifractal critical and ultimately to localized states. Strikingly, the extended-to-critical transition coincides exactly with a real-complex spectral transition. We establish complete phase diagrams and derive exact analytical boundaries for both topological and localization transitions, uncovering an unanticipated coexistence of TAI and multifractal critical phases. Finally, we propose a feasible implementation in topolectrical circuits. Our results reveal a new paradigm for the cooperative effects of topology, quasiperiodicity, and non-Hermiticity."}
{"id": "2602.13752", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.13752", "abs": "https://arxiv.org/abs/2602.13752", "authors": ["Contoyiannis. F. Yiannis"], "title": "Spike train propagation in Hybrid Artificial Neural Network (HANN)", "comment": "23 pages", "summary": "The spikes train is an important step in order to the artificial neural network (ANN) give us simulations more close to the reality i.e the operation of the biological neural network. Based on in previous our work that the HANN can to produce critical and tricritical intermittencies we investigate in present work the possibility of the Spike train production from the HANN. So the operation of ANN does not would based in mathematical algorithm of machine learning but the operation of a ANN could be based in physical notions as the phenomenon of intermittency. As we have shown the real biological neurons is a Dynamical system which present the intermittent dynamic type I."}
{"id": "2602.14138", "categories": ["q-fin.CP"], "pdf": "https://arxiv.org/pdf/2602.14138", "abs": "https://arxiv.org/abs/2602.14138", "authors": ["Ata Keskin"], "title": "Factor Engine: A Python Library for Systematic Financial Factor Computation and Analysis", "comment": null, "summary": "Factor Engine is a high-performance, open-source Python library designed for the systematic computation and analysis of financial factors. Built around a modular and extensible API that leverages Python decorators, Factor Engine enables users to define custom factors with ease and integrates seamlessly with the modern data science ecosystem. To assess its practical effectiveness, we compare the mispricing factors computed by Factor Engine to those generated using a reference Stata implementation, finding that both approaches yield highly similar results and comparable performance in backtesting analyses. Furthermore, we experimentally apply these factors within machine learning workflows for trading strategy development, illustrating their practical utility and potential for quantitative finance research."}
{"id": "2602.13454", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.13454", "abs": "https://arxiv.org/abs/2602.13454", "authors": ["Henrique O. Caetano", "Rahul K. Gupta", "Cristhian G. da R. de Oliveira", "João B. A. London", "Carlos Dias Maciel"], "title": "Bayesian Model-based Generation of Synthetic Unbalanced Distribution Networks Incorporating Reliability Indices", "comment": "Accepted at XXIV Power Systems Computation Conference (PSCC 2026)", "summary": "Real-world power distribution data are often inaccessible due to privacy and security concerns, highlighting the need for tools for generating realistic synthetic networks. Existing methods typically overlook critical reliability metrics such as the Customer Average Interruption Frequency Index (CAIFI) and the Customer Average Interruption Duration Index (CAIDI). Moreover, these methods often neglect phase consistency during the design stage, necessitating the use of a separate phase assignment algorithm. This work proposes a Bayesian Hierarchical Model (BHM) that generates phase-consistent unbalanced three-phase distribution systems, and incorporates reliability indices. The BHM learns the joint distribution of phase configuration, power demand, and reliability indices from a reference network, conditioning these attributes on topological features. We apply the proposed methodology to generate synthetic power distribution networks in Brazil, and validated it on known Brazilian networks. The results show that the BHM accurately reproduces the distributions of phase allocation, power demand, and reliability metrics on the training system. Furthermore, in out-of-sample validation on unseen data, the model generates phase-consistent networks and accurately predicts the reliability indices for the synthetic systems. The generated networks are also electrically feasible: three-phase power flows converge and voltages remain within typical operating limits, enabling studies of planning, reliability, and resilience."}
{"id": "2602.14057", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.14057", "abs": "https://arxiv.org/abs/2602.14057", "authors": ["Keito Morioka", "Takayuki Goto", "Masari Watanabe", "Yuki Kojima", "Nobuyuki Kurita", "Hidekazu Tanaka", "Satoshi Iguchi", "Takahiko Sasaki"], "title": "NMR study on equilateral triangular lattice antiferromagnet Ba2La2CoTe2O12", "comment": null, "summary": "We report a 139La-NMR study of Ba2La2CoTe2O12, S = 1/2 equilateral triangular-lattice antiferromagnet with easy-plane anisotropy at low temperatures. This compound undergoes a magnetic phase transition at TN = 3.26 K into an ordered state with the 120 degree spin structure. Under magnetic fields above 3T, TN splits into TN1 and TN2, which correspond to the transitions from the paramagnetic phase to the up-up-down (uud) phase and from the uud phase to the triangular coplanar phase, respectively. The NMR spin-lattice relaxation rate 1/T1 exhibits a critical divergence at TN1, indicating the onset of long-range magnetic order. At TN2, the NMR-linewidth measured at 5.4 T exhibits an anomalous decrease, which we attribute to a change in the spin structure from the uud to the triangular coplanar phase."}
{"id": "2602.13395", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13395", "abs": "https://arxiv.org/abs/2602.13395", "authors": ["Aranya Chakraborty", "Daniel Gottesman"], "title": "No-Go Theorem on Fault Tolerant Gadgets for Multiple Logical Qubits", "comment": "12 pages", "summary": "Identifying stabilizer codes that admit fault-tolerant implementations of the full logical Clifford group would significantly advance fault-tolerant quantum computation. Motivated by this goal, we study several classes of fault-tolerant gadget constructions consisting of Clifford gates acting on the physical qubits, including transversal gadgets, code automorphisms, and fold-transversal gadgets. While stabilizer codes encoding a single logical qubit, most notably the [[7,1,3]] Steane code, are known to admit transversal implementations of the full logical Clifford group, no analogous examples are known for codes encoding multiple logical qubits. In this work, we prove a no-go theorem establishing that no stabilizer code admits a fully transversal implementation of the Clifford group on more than one logical qubit. We further strengthen this result by showing that fold-transversal implementations of the full logical Clifford group are impossible for stabilizer codes encoding more than two logical qubits. More generally, we introduce the notion of k-fold transversal gadgets and prove that implementing the full Clifford group on k logical qubits requires at least k-fold transversal gadgets at the physical level. In addition, we analyze code-automorphism based constructions and demonstrate that they also fail to realize the full Clifford group on multiple logical qubits for any stabilizer code. Together, these results place fundamental constraints on fault-tolerant Clifford gadget design and show that stabilizer codes supporting the full logical Clifford group on multiple logical qubits via these architectures do not exist. Since the Clifford group is a core component of universal gate sets, our findings imply that quantum computing with codes encoding multiple logical qubits within a single code block necessarily entails more complex constructions for fault tolerance."}
{"id": "2602.13406", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.13406", "abs": "https://arxiv.org/abs/2602.13406", "authors": ["Manas Ranjan Mahapatra", "Rakesh Kumar"], "title": "Exact dimer ground state and quantum phase transitions in a coupled spin ladder", "comment": null, "summary": "Spin ladders are key models that act as intermediaries between one-dimensional and two-dimensional spin systems. In this study, we examine a coupled spin-$1/2$ ladder, where frustrated ladders with leg, rung, and diagonal interactions are linked through a horizontal coupling. By introducing a spatially anisotropic third-nearest-neighbor interaction along the horizontal direction, the model was found to possess an exact dimer ground state, characterized by a product of singlets forming a columnar dimer phase. The model is analyzed using bond-operator mean-field theory (BOMFT) and the density matrix renormalization group (DMRG). BOMFT reveals three distinct phases: a double-stripe ordered phase, a Néel ordered phase, and a quantum disordered dimerized phase. The critical points for the transitions are $J_1 = -0.81$ (double-stripe to dimerized) and $J_1 = 2.81$ (dimerized to Néel phase). DMRG results corroborate the exact ground state and refine the critical points to $J_1 = -0.79$ and $J_1 = 2.29$ for the respective transitions. Additionally, another transition is identified as the Néel order vanishes for $J_1 > 4.5$. The static spin structure factor further corroborates the nature of the ordered phases."}
{"id": "2602.13862", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.13862", "abs": "https://arxiv.org/abs/2602.13862", "authors": ["Eduardo Vera Pichardo"], "title": "Measuring Self-Rating Bias in LLM-Generated Survey Data: A Semantic Similarity Framework for Independent Scale Mapping", "comment": "58 pages, 8 figures, 1 longtable appendix. Code/data: https://github.com/Lalitronico/ssr-replication", "summary": "Synthetic survey data generated by large language models (LLMs) suffers from a fundamental circularity: the same model family that generates text responses also maps them to numerical scales. We calibrate and validate Semantic Similarity Rating (SSR; Maier et al., 2024), which decouples generation from scale mapping via embedding-based cosine similarity against predefined anchor statements. Configuration experiments (N=17 pilot, N=69 cross-validation across 8 domains) show that naturalistic behavioral anchors outperform formal jargon by 29 percentage points (pp), and that SSR achieves 65-67% exact match and 91% within plus/minus 1; a cross-model test with OpenAI text-embedding-3-small reaches 77% exact, confirming cross-provider generalization. Direct LLM baselines (Claude 87%, GPT-4o 83%) establish that SSR's contribution is methodological independence, not accuracy superiority. A control condition removing question text from the LLM prompt actually improves LLM accuracy, ruling out information asymmetry as the explanation for SSR's lower accuracy. A pre-registered circularity experiment (N=345) reveals 4x compressed error variance in LLM rating (sigma^2 = 0.21 vs 0.87 for SSR) and systematic directional bias. A cross-model control (GPT-4o rating Claude-generated text) shows nearly identical compression (within/cross ratio = 0.93), indicating variance compression is a general LLM property rather than a within-model artifact. The calibration dataset, anchor library, and source code are publicly available (see Data Availability)."}
{"id": "2602.14435", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.14435", "abs": "https://arxiv.org/abs/2602.14435", "authors": ["Di Zhou"], "title": "Phonon Echo from Multi-Level Systems and Many-Body Interactions in Low-Temperature Glasses", "comment": "20 pages, 6 figures", "summary": "At low temperatures, glasses exhibit distinctive properties compared to crystalline solids. A notable example is the phonon echo, a phenomenon that motivated the two-level-system (TLS) model. This model has successfully explained many universal anomalies in glasses. Here, we extend the TLS framework to a multi-level system and show that phonon echoes persist when nonlinear energy structures and disorder are included. By incorporating virtual phonon exchange, we introduce many-body interactions between these multi-level systems, leading to nonlinear eigen-energies that enhance the echo signal. Meanwhile, finite-temperature thermal fluctuations cause dephasing, resulting in a decay of echo amplitude over time. The analytical and numerical results are consistent across semi-classical and quantum regimes. Our work validates the multi-level-system model and underscores the role of many-body interactions in low-temperature glassy dynamics."}
{"id": "2602.13847", "categories": ["nlin.CD", "cond-mat.stat-mech", "cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.13847", "abs": "https://arxiv.org/abs/2602.13847", "authors": ["Fabrizio Falasca", "Laure Zanna"], "title": "Causally constrained reduced-order neural models of complex turbulent dynamical systems", "comment": null, "summary": "We introduce a flexible framework based on response theory and score matching to suppress spurious, noncausal dependencies in reduced-order neural emulators of turbulent systems, focusing on climate dynamics as a proof-of-concept. We showcase the approach using the stochastic Charney-DeVore model as a relevant prototype for low-frequency atmospheric variability. We show that the resulting causal constraints enhance neural emulators' ability to respond to both weak and strong external forcings, despite being trained exclusively on unforced data. The approach is broadly applicable to modeling complex turbulent dynamical systems in reduced spaces and can be readily integrated into general neural network architectures."}
{"id": "2602.14354", "categories": ["q-fin.CP", "q-fin.PR", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2602.14354", "abs": "https://arxiv.org/abs/2602.14354", "authors": ["Stefano Scoleri", "Marco Bianchetti", "Sergei Kucherenko"], "title": "Application of Quasi Monte Carlo and Global Sensitivity Analysis to Option Pricing and Greeks", "comment": "47 pages, 27 figures, 10 tables. Continues previous paper \"Pricing and Risk Management with High-Dimensional Quasi Monte Carlo and Global Sensitivity Analysis\" (https://doi.org/10.48550/arXiv.1504.02896)", "summary": "Quasi Monte Carlo (QMC) and Global Sensitivity Analysis (GSA) techniques are applied for pricing and hedging representative financial instruments of increasing complexity. We compare standard Monte Carlo (MC) vs QMC results using Sobol' low discrepancy sequences, different sampling strategies, and various analyses of performance. We find that QMC outperforms MC in most cases, including the highest-dimensional simulations, showing faster and more stable convergence. Regarding greeks computation, we compare standard approaches, based on finite differences (FD) approximations, with adjoint methods (AAD) providing evidences that, when the number of greeks is small, the FD approach combined with QMC can lead to the same accuracy as AAD, thanks to increased convergence rate and stability, thus saving a lot of implementation effort while keeping low computational cost. Using GSA, we are able to fully explain our findings in terms of reduced effective dimension of QMC simulation, allowed in most cases, but not always, by Brownian Bridge discretization or PCA construction. We conclude that, beyond pricing, QMC is a very effcient technique also for computing risk measures, greeks in particular, as it allows to reduce the computational effort of high dimensional Monte Carlo simulations typical of modern risk management."}
{"id": "2602.13896", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.13896", "abs": "https://arxiv.org/abs/2602.13896", "authors": ["Naoki Hashima", "Hikaru Hoshino", "Luis David Pabón Ospina", "Eiko Furutani"], "title": "Probabilistic Reachability Analysis of Multi-scale Voltage Dynamics Using Reinforcement Learning", "comment": null, "summary": "Voltage stability in modern power systems involves coupled dynamics across multiple time scales. Conventional methods based on time-scale separation or static stability margins may overlook instabilities caused by the coupling of slow and fast transients. Uncertainty in operating conditions further complicates stability assessment, and high computational cost of Monte Carlo simulations limit its applicability to multi-scale dynamics. This paper presents a deep reinforcement learning-based framework for probabilistic reachability analysis of multi-scale voltage dynamics. By formulating each instability mechanism as a distinct absorbing state and introducing a multi-critic architecture for mechanism-specific learning, the proposed method enables consistent learning of risk probabilities associated with multiple instability types within a unified framework. The approach is demonstrated on a four-bus system with load tap changers and over-excitation limiters, illustrating effectiveness of the proposed learning-based reachability analysis in identifying and quantifying the mechanisms leading to voltage collapse."}
{"id": "2602.13465", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.13465", "abs": "https://arxiv.org/abs/2602.13465", "authors": ["Diego Martinez-Taboada", "Aaditya Ramdas"], "title": "Intrinsic dimension concentration inequalities for self-adjoint operators", "comment": null, "summary": "We derive novel concentration inequalities for the operator norm of the sum of self-adjoint operators that do not explicitly depend on the underlying dimension of the operator, but rather an intrinsic notion of it. Our analysis leads to tighter results (in terms of constants) and simplified proofs. Our results unify the current intrinsic-dimension and ambient-dimension inequalities under independence, strictly improving both categories of bounds (such as by Tropp and Minsker). We present a general master theorem that we instantiate to obtain specific sub-Gaussian, Hoeffding, Bernstein, Bennett, and sub-exponential type inequalities. We also establish widely applicable concentration bounds under martingale dependence that provide tighter control than existing results."}
{"id": "2602.14773", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.14773", "abs": "https://arxiv.org/abs/2602.14773", "authors": ["Josef Ludescher", "Jun Meng", "Jingfang Fan", "Armin Bunde", "Hans Joachim Schellnhuber"], "title": "Climate network and complexity based ENSO forecast for 2026", "comment": "13 pages, 6 figures", "summary": "The El Niño Southern Oscillation (ENSO) is the dominant driver of interannual global climate variability and can lead to extreme weather events such as droughts or flooding. Recently, we have developed several statistical approaches for early ENSO forecasting, in particular, its El Niño phase. The climate network-based approach allows forecasting the onset of an El Niño event or its absence about 1 year ahead [1]. The complexity-based approach allows additionally to forecast the magnitude of an upcoming El Niño event in the calendar year before the onset [2]. Additionally, we have developed methods for forecasting the type (Eastern Pacific or Central Pacific) of an El Niño [3] and for probabilistic forecasting of La Niña and neutral events [4], also by the end of the calendar year before the event. Here we present the forecasts of these methods for 2026. The climate network and the complexity-based approach do not provide concurring signals for this year. The combined forecast indicates that a neutral event is more likely than an El Niño. If an El Niño develops in 2026, the complexity-based approach predicts a weaker event with a magnitude of $0.84\\pm0.36$°C."}
{"id": "2602.14350", "categories": ["q-fin.RM", "q-fin.PR"], "pdf": "https://arxiv.org/pdf/2602.14350", "abs": "https://arxiv.org/abs/2602.14350", "authors": ["Noura El Hassan", "Bacel Maddah", "Nassim N. Taleb"], "title": "Hidden Risks and Optionalities in American Options", "comment": null, "summary": "We develop a practical framework for identifying and quantifying the hidden layers of risks and optionality embedded in American options by introducing stochasticity into one or more of their underlying determinants. The heuristic approach remedies the problems of conventional pricing systems, which treat some key inputs deterministically, hence systematically underestimate the flexibility and convexity inherent in early-exercise features."}
{"id": "2602.14860", "categories": ["q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.14860", "abs": "https://arxiv.org/abs/2602.14860", "authors": ["Giulio Marino", "Manuel Naviglio", "Francesco Tarantelli", "Fabrizio Lillo"], "title": "Predicting the success of new crypto-tokens: the Pump.fun case", "comment": null, "summary": "We study the dynamics of token launched on Pump.fun, a Solana-based launchpad platform, to identify the determinants of the token success. Pump.fun employs a bonding curve mechanism to bootstrap initial liquidity possibly leading to graduation to the on-chain market, which can be seen as a token success. We build predictive models of the probability of graduation conditional on the current amount of Solana locked in the bonding curve and a set of explanatory variables that capture structural and behavioral aspects of the launch process. Conditioning the graduation probability on these variables significantly improves its predictive power, providing insights into early-stage market behavior, speculative and manipulative dynamics, and the informational efficiency of bonding-curve-based token launches."}
{"id": "2602.13708", "categories": ["physics.hist-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2602.13708", "abs": "https://arxiv.org/abs/2602.13708", "authors": ["Henrique Gomes"], "title": "Making Symmetry Explicit: The Limits of Sophistication", "comment": "31 pages, 5 figures", "summary": "Symmetry is often treated in philosophy of physics as an interpretive problem. A particularly lively dispute concerns local symmetries: do they indicate surplus structure that ought to be expunged, or are they merely a harmless redundancy? One influential response favours the second option for certain theories -- those dubbed internally sophisticated. And indeed, in much of physics practice, local symmetries are left implicit: one simply works \"up to isomorphism'' without pausing over invariance. But not always. In some settings, local symmetry and invariance become pressing practical concerns for physicists. Yet philosophical discussions of sophistication have paid little sustained attention to when, and why, this happens.\n  Surveying textbook general relativity (GR) and gauge theory, I identify the settings in which diffeomorphism invariance or gauge invariance must be handled explicitly. (Here a setting is a choice of representational framework or background assumptions within which one formulates and uses the theory -- for instance, linearisation, an initial-value formulation, or a Hamiltonian $3+1$ formalism.) I propose an operational criterion -- background-relative sophistication (BRS) -- and argue that it accounts well for the pattern: it marks just where symmetry can stay implicit and where it must be made explicit. Quantum and subsystem settings raise a further difficulty: there, certain tasks (superposition and gluing) force symmetry into view even for theories that are BRS."}
{"id": "2602.14180", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.14180", "abs": "https://arxiv.org/abs/2602.14180", "authors": ["Prashant Singh", "Eli Barkai", "David A Kessler"], "title": "The Sokoban Random Walk: A Trapping Perspective", "comment": null, "summary": "We study caging/trapping in Sokoban-type models, featuring a random walker moving through a disordered medium of obstacles and capable of pushing some obstacles blocking its path. In one-dimension, we allow the walker to push up to an arbitrary $N_{\\rm P}$ number of obstacles. For $N_{\\rm P}\\gg 1$, we use large-deviation theory to show that the survival probability to remain uncaged exhibits crossover from an exponential decay with time at intermediate times to a stretched-exponential decay at long times, with an exponent $1/3$ independent of $N_{\\rm P}$. The long-time exponent matches the Balagurov--Vaks--Donsker--Varadhan (BVDV) theory of the classical trapping problem, while the exponential decay is qualitatively distinct from the Rosenstock's intermediate-time theory for classical trapping. Similarly, in two dimensions, numerical simulations reveal that both the Sokoban model and its generalized version exhibit long-time stretched-exponential relaxation with exponent $1/2$, again consistent with the BVDV theory. Finally, in two dimensions, we find that the mean trap size is nonmonotonic in $ρ$: it is small at both low and high densities, but reaches a peak at a characteristic density $ρ_*$. We estimate $ρ_* \\approx 0.55$ for the Sokoban model and $ρ_* \\approx 0.675$ for the generalized Sokoban model."}
{"id": "2602.13399", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13399", "abs": "https://arxiv.org/abs/2602.13399", "authors": ["Dawei Zhong", "Todd A. Brun"], "title": "Protection of Exponential Operation using Stabilizer Codes in the Early Fault Tolerance Era", "comment": null, "summary": "Quantum error correction offers a promising path to suppress errors in quantum processors, but the resources required to protect logical operations from noise, especially non-Clifford operations, pose a substantial challenge to achieve practical quantum advantage in the early fault-tolerant quantum computing (EFTQC) era. In this work, we develop a systematic scheme to encode exponential maps of the form $\\exp(-iθP)$ into stabilizer codes with simple circuit structures and low qubit overhead. We provide encoded circuits with small first-order logical error rate after postselection for the [[n, n-2, 2]] quantum error-detecting codes and the [[5, 1, 3]], [[7, 1, 3]], and [[15, 7, 3]] quantum error-correcting codes. Detailed analysis shows that under the level of physical noise of current devices, our encoding scheme is 4--7 times less noisy than the unencoded operation, while at most 3% of runs need to be discarded."}
{"id": "2602.13443", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13443", "abs": "https://arxiv.org/abs/2602.13443", "authors": ["Gang Cao", "Hengdi Zhao", "Adrienne Bond", "Tristan R. Cao", "Gabriel Schebel", "Arabella Quane", "Yifei Ni", "Yu Zhang", "Logan Wall", "Rahul Nandkishore", "Pedro Schlottmann", "Feng Ye"], "title": "Hidden Density-Wave Instability in the Trimer Ruthenate Ba4Ru3O10", "comment": "5 figures", "summary": "We report a hidden density-wave instability in the trimer-based ruthenate Ba4Ru3O10, previously regarded as a pure antiferromagnet with a phase transition at TA=100 K. This transition is manifested in lattice parameters, transport, thermodynamics, and magnetic susceptibility, yet remains remarkably insensitive to magnetic fields up to at least 14 T, indicating an electronically driven reconstruction. At much lower temperatures T*= 20 K, charge transport becomes strongly nonlinear, exhibiting distinct depinning thresholds, negative differential resistance, pronounced current- and frequency-dependence, and slow collective dynamics in the Hertz range. While each feature is characteristic of density-wave transport, their simultaneous occurrence in an antiferromagnetic oxide is unprecedented. All nonlinear signatures vanish upon only 3% Ir substitution, which preserves the crystal structure and insulating state, ruling out Joule heating or extrinsic artifacts. The wide separation between the electronic reconstruction at TA and the emergence of nonlinear dynamics at T* identifies Ba4Ru3O10 as a rare correlated system hosting a strongly pinned collective electronic state intertwined with antiferromagnetism."}
{"id": "2602.14560", "categories": ["physics.soc-ph", "cs.SD", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.14560", "abs": "https://arxiv.org/abs/2602.14560", "authors": ["Sandy H. S. Herho", "Rusmawan Suwarman", "Nurjanna J. Trilaksono", "Iwan P. Anwar", "Faiz R. Fajary"], "title": "Preliminary sonification of ENSO using traditional Javanese gamelan scales", "comment": "16 pages, 7 figures", "summary": "Sonification -- the mapping of data to non-speech audio -- offers an underexplored channel for representing complex dynamical systems. We treat El Niño-Southern Oscillation (ENSO), a canonical example of low-dimensional climate chaos, as a test case for culturally-situated sonification evaluated through complex systems diagnostics. Using parameter-mapping sonification of the Niño 3.4 sea surface temperature anomaly index (1870--2024), we encode ENSO variability into two traditional Javanese gamelan pentatonic systems (pelog and slendro) across four composition strategies, then analyze the resulting audio as trajectories in a two-dimensional acoustic phase space. Recurrence-based diagnostics, convex hull geometry, and coupling analysis reveal that the sonification pipeline preserves key dynamical signatures: alternating modes produce the highest trajectory recurrence rates, echoing ENSO's quasi-periodicity; layered polyphonic modes explore the broadest phase space regions; and the two scale families induce qualitatively distinct coupling regimes between spectral brightness and energy -- predominantly anti-phase in pelog but near-independent in slendro. Phase space trajectory analysis provides a rigorous geometric framework for comparing sonification designs within a complex systems context. Perceptual validation remains necessary; we contribute the dynamical systems methodology for evaluating such mappings."}
{"id": "2602.14713", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.14713", "abs": "https://arxiv.org/abs/2602.14713", "authors": ["Bosiljka Tadic"], "title": "Antiferromagnetic Barkhausen noise induced by weak random-field disorder", "comment": "20 pages, 4 figures", "summary": "This study numerically investigates magnetisation reversal processes driven by an external magnetic field in three-dimensional antiferromagnetic spin models with weak random field disorder. Considering an extremely weak disorder and low temperature, we observe a step-wise hysteresis loop and the appearance of short magnetisation bursts of a characteristic triangular shape; the number of bursts increases with disorder, indicative of Barkhausen-type noise. These phenomena are attributed to the simultaneous reversal at a given external field of segments composed of spins with identical neighbourhoods. A local random field orients one or more spin neighbours, resulting in small, ferromagnetic-like clusters distributed throughout the system. As disorder increases, these clusters may merge to form a labyrinthine structure within the antiferromagnetic background, facilitating brief avalanche propagation. The results demonstrate that, compared with familiar random-field ferromagnets, the observed antiferromagnetic Barkhausen noise and the related avalanche sequence have a profoundly different structure, organised into peaks associated with the transition between magnetisation plateaus. They exhibit prominent cyclical trends and disorder-dependent multifractal fluctuations, with the singularity spectrum quantifying the degree of disorder. The activity avalanches exhibit scale invariance resembling that recently found in experiments with disordered ferr\\textit{i}magnets and martensites, as well as in quantum Barkhausen noise, which are associated with active geometric regions rather than individual-spin dynamics. The observed scaling behaviour is interpreted in terms of self-organised critical dynamics."}
{"id": "2602.14378", "categories": ["q-fin.CP"], "pdf": "https://arxiv.org/pdf/2602.14378", "abs": "https://arxiv.org/abs/2602.14378", "authors": ["Antonio Scala"], "title": "A Computational Framework for Financial Structures", "comment": null, "summary": "Financial structures such as securitisations, insurance contracts, and other hierarchical claims systems can be interpreted as deterministic allocation mechanisms acting on stochastic inflow processes. This paper develops a general computational representation of such structures by separating the stochastic generation of inflows from the deterministic rules governing their distribution across positions. Allocation rules, trigger conditions, and priority relations are expressed as explicit, state-dependent operators mapping realised inflows to payments under each scenario. This representation enables financial structures to be analysed as computable economic systems whose performance and risk characteristics can be evaluated consistently across alternative configurations within a unified stochastic environment. While motivated by applications in structured finance, the framework applies more broadly to contractual and institutional arrangements in which uncertain resources are allocated across ordered claims. By providing a unified computational architecture for representing and comparing such mechanisms, the approach supports systematic analysis of structural design, risk distribution, and contractual transparency under uncertainty."}
{"id": "2602.13957", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.13957", "abs": "https://arxiv.org/abs/2602.13957", "authors": ["Li Xiaojie", "Yin Xunyuan"], "title": "Learning-based data-enabled moving horizon estimation with application to membrane-based biological wastewater treatment process", "comment": null, "summary": "In this paper, we propose a data-enabled moving horizon estimation (MHE) approach for nonlinear systems. While the approach is formulated by leveraging Koopman theory, its implementation does not require explicit Koopman modeling. Lifting functions are learned from the state and input data of the original nonlinear system to project the system trajectories into the lifted space, where the resulting trajectories implicitly describe the Koopman representation for the original nonlinear system. A convex data-enabled MHE formulation is developed to provide real-time state estimates of the Koopman representation, from which the states of the nonlinear system can be reconstructed. Sufficient conditions are derived to ensure the stability of the estimation error. The effectiveness of the proposed method is illustrated using a membrane-based biological water treatment process."}
{"id": "2602.13565", "categories": ["math.ST", "math.NA", "math.PR", "stat.OT"], "pdf": "https://arxiv.org/pdf/2602.13565", "abs": "https://arxiv.org/abs/2602.13565", "authors": ["Paromita Banerjee", "Anirban Mondal"], "title": "An Improved Milstein Method for the Numerical Solution of Multidimensional Stochastic Differential Equations", "comment": null, "summary": "Stochastic differential equations (SDEs) offer powerful and accessible mathematical models for capturing both deterministic and probabilistic aspects of dynamic behavior across a wide range of physical, financial, and social systems. However, analytical solutions for many SDEs are often unavailable, necessitating the use of numerical approximation methods. The rate of convergence of such numerical methods is of great importance, as it directly influences both computational efficiency and accuracy. This paper presents a proposed theorem, along with its proof, that facilitates the numerical evaluation of the strong (and weak) order of convergence of a numerical scheme for an SDE when the analytical solution is unavailable. Additionally, we address the challenge of numerically computing the multiple stochastic integrals required by the Milstein method to achieve improved convergence rates for multidimensional SDEs. In this context, two newly proposed numerical techniques for computing these multiple stochastic integrals are introduced and compared with existing approaches in terms of efficiency and effectiveness. The methodologies are further illustrated through simulation studies and applications to widely used financial models."}
{"id": "2602.13847", "categories": ["nlin.CD", "cond-mat.stat-mech", "cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.13847", "abs": "https://arxiv.org/abs/2602.13847", "authors": ["Fabrizio Falasca", "Laure Zanna"], "title": "Causally constrained reduced-order neural models of complex turbulent dynamical systems", "comment": null, "summary": "We introduce a flexible framework based on response theory and score matching to suppress spurious, noncausal dependencies in reduced-order neural emulators of turbulent systems, focusing on climate dynamics as a proof-of-concept. We showcase the approach using the stochastic Charney-DeVore model as a relevant prototype for low-frequency atmospheric variability. We show that the resulting causal constraints enhance neural emulators' ability to respond to both weak and strong external forcings, despite being trained exclusively on unforced data. The approach is broadly applicable to modeling complex turbulent dynamical systems in reduced spaces and can be readily integrated into general neural network architectures."}
{"id": "2602.14354", "categories": ["q-fin.CP", "q-fin.PR", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2602.14354", "abs": "https://arxiv.org/abs/2602.14354", "authors": ["Stefano Scoleri", "Marco Bianchetti", "Sergei Kucherenko"], "title": "Application of Quasi Monte Carlo and Global Sensitivity Analysis to Option Pricing and Greeks", "comment": "47 pages, 27 figures, 10 tables. Continues previous paper \"Pricing and Risk Management with High-Dimensional Quasi Monte Carlo and Global Sensitivity Analysis\" (https://doi.org/10.48550/arXiv.1504.02896)", "summary": "Quasi Monte Carlo (QMC) and Global Sensitivity Analysis (GSA) techniques are applied for pricing and hedging representative financial instruments of increasing complexity. We compare standard Monte Carlo (MC) vs QMC results using Sobol' low discrepancy sequences, different sampling strategies, and various analyses of performance. We find that QMC outperforms MC in most cases, including the highest-dimensional simulations, showing faster and more stable convergence. Regarding greeks computation, we compare standard approaches, based on finite differences (FD) approximations, with adjoint methods (AAD) providing evidences that, when the number of greeks is small, the FD approach combined with QMC can lead to the same accuracy as AAD, thanks to increased convergence rate and stability, thus saving a lot of implementation effort while keeping low computational cost. Using GSA, we are able to fully explain our findings in terms of reduced effective dimension of QMC simulation, allowed in most cases, but not always, by Brownian Bridge discretization or PCA construction. We conclude that, beyond pricing, QMC is a very effcient technique also for computing risk measures, greeks in particular, as it allows to reduce the computational effort of high dimensional Monte Carlo simulations typical of modern risk management."}
{"id": "2602.14059", "categories": ["physics.hist-ph", "physics.class-ph"], "pdf": "https://arxiv.org/pdf/2602.14059", "abs": "https://arxiv.org/abs/2602.14059", "authors": ["J. W. van Holten"], "title": "A Huygens-Leibniz-Lange framework for classical mechanics", "comment": "16 pages excluding references, 1 figure", "summary": "I discuss the physical basis of classical mechanics, such as expressed commonly using the framework of Newton's Principia. Newton's formulation of the laws of motion is seen to have quite a few ambiguities and shortcomings. Therefore I offer an alternative set of laws, based in particular on ideas of his contemporaries Huygens and Leibniz with a crucial addition by Ludwig Lange, which avoids the problems with Newton's formulation. It is shown that from these laws of motion all the usual results of classical mechanics, as it concerns the motion of idealized point masses, can be rederived. The application of these principles to relativistic point particles is discussed."}
{"id": "2602.13931", "categories": ["physics.comp-ph", "cond-mat.soft", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.13931", "abs": "https://arxiv.org/abs/2602.13931", "authors": ["Ting Peng"], "title": "Geometry Challenges Entropy: Regime-DependentRectification in Nanofluidic Cascades", "comment": null, "summary": "Can geometry alone reshape equilibrium? Cascaded nanofluidic chambers show complex accumulation patterns, traditionally attributed to geometric diode effects. We use 3D molecular dynamics to decouple funnel rectification from boundary reflection. Simulations with argon parameters (r = 0.19 nm) reveal a striking \"reverse\" rectification in a 2-chamber setup: the narrow side accumulates over 5x more particles (N_1/N_0 = 5.37 +/- 0.01, p < 0.0001). In a 10-chamber argon cascade, this effect drives massive downstream accumulation. A symmetric control (w_L = w_R) eliminates the gradient, confirming that funnel asymmetry - not boundary/edge effects - is the primary driver in the ballistic regime. By contrast, the super-atom regime is dominated by boundary reflection. Our results challenge standard entropic transport theory and provide design rules for passive, geometry-driven density gradients - no pump, no drive."}
{"id": "2602.13882", "categories": ["cs.CE", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.13882", "abs": "https://arxiv.org/abs/2602.13882", "authors": ["Yixiao Gao", "Fei Li", "Ruizhe Shi", "Ruizhi Cheng", "Jean Zhang", "Bo Han", "Songqing Chen"], "title": "NFT Games: an Empirical Look into the Play-to-Earn Model", "comment": "17 pages, 12 figures", "summary": "The past decade has witnessed the burgeoning and continuous development of blockchain and its applications. Besides various cryptocurrencies, an industry that has quickly embraced this trend is gaming. Thanks to the support of blockchain, games have started to incorporate non-fungible tokens (NFTs) that can enable a new gaming model, play-to-earn (P2E), which incentivizes users to participate and play. While recent studies looked at several NFT games qualitatively and individually, an in-depth understanding is still missing, particularly on how the P2E model has transformed traditional games. In this work, we set to conduct a measurement study of NFT games, aiming to gain a comprehensive understanding of the effectiveness of P2E in practice. For this purpose, we collect and analyze relevant NFT transaction data from the underlying blockchain (e.g., Ethereum) of 12 games, supplemented with various data scraped from their websites. Our study shows that (1) a few top wallets control unproportionally high percentage of NFTs, and the majority of wallets own only one or two NFTs and do not actively trade; (2) promotion events do boost the trade amount and the NFT price for some games, but their effect does not sustain; and (3) few players actually earned a profit, and players in 9 out of 12 games who traded NFTs have a negative profit on average. Motivated by these findings, we further investigate effective incentive mechanisms based on game theory to improve the trading profits that players can earn from these NFT games. Both modeling and simulation results confirm the effectiveness of the proposed incentive mechanism."}
{"id": "2602.13279", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13279", "abs": "https://arxiv.org/abs/2602.13279", "authors": ["Jiran Tao", "Cheng Wang", "Binyan Jiang"], "title": "LLM-Enhanced Rumor Detection via Virtual Node Induced Edge Prediction", "comment": null, "summary": "The proliferation of rumors on social networks undermines information credibility. While their dissemination forms complex networks, current detection methods struggle to capture these intricate propagation patterns. Representing each node solely through its textual embeddings neglects the textual coherence across the entire rumor propagation path, which compromises the accuracy of rumor identification on social platforms. We propose a novel framework that leverages Large Language Models (LLMs) to address these limitations. Our approach captures subtle rumor signals by employing LLMs to analyze information subchains, assign rumor probabilities and intelligently construct connections to virtual nodes. This enables the modification of the original graph structure, which is a critical advancement for capturing subtle rumor signals. Given the inherent limitations of LLMs in rumor identification, we develop a structured prompt framework to mitigate model biases and ensure robust graph learning performance. Additionally, the proposed framework is model-agnostic, meaning it is not constrained to any specific graph learning algorithm or LLMs. Its plug-and-play nature allows for seamless integration with further fine-tuned LLMs and graph techniques in the future, potentially enhancing predictive performance without modifying original algorithms."}
{"id": "2602.14264", "categories": ["cond-mat.stat-mech", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2602.14264", "abs": "https://arxiv.org/abs/2602.14264", "authors": ["Kushal Patel", "Kesavaraja C", "Pranab Dutta", "Korak Biswas"], "title": "Magnetocardiography measurements using an optically pumped magnetometer under ambient conditions", "comment": null, "summary": "In this work, we report the development of a rubidium-based single-beam scalar optically pumped magnetometer (OPM) and demonstrate its application in measuring human cardiac magnetic fields in an unshielded environment. The developed magnetometers exhibit a noise floor below 15 pT/sqrt(Hz) in the frequency range of 1 to 35 Hz, with a measurement bandwidth of 100 Hz. When operated in a gradiometric configuration, the noise floor is further reduced to below 3 pT/sqrt(Hz) over the same frequency range. Magnetocardiography (MCG) signals were recorded at five different locations across the thorax. A clear polarity reversal of the QRS complex was observed across these measurement positions, confirming the spatial sensitivity of the system. The proposed system shows strong potential for clinical diagnostics, offering valuable physiological information through non-contact MCG measurements"}
{"id": "2602.13429", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13429", "abs": "https://arxiv.org/abs/2602.13429", "authors": ["Hans C. Fogedby"], "title": "On the Redfield and Lindblad master equations", "comment": "latex, 25 pages, 1 figure", "summary": "In a previous work we developed a field theoretical approach to open quantum systems using condensed matter methods. In the Born approximation we derived the Redfield equation on the basis of a multi-oscillator bath, a Dyson equation, a diagrammatic expansion and a quasi-particle approximation. In addition applying a rotating wave approximation we obtained the Lindblad equation describing a proper quantum map. The issue regarding the additional rotating wave approximation was left as an open problem.\n  The present work addresses the open problem and presents new results. We identify a discrepancy in the popular and standard Redfield equation. The discrepancy is associated with the well-known fact that the Redfield equation does not represent a proper quantum map. The discrepancy is related to the diagrammatic expansion and a consistency requirement in the quasi-particle approximation. The explicit resolution of this discrepancy is obtained by imposing energy conservation on the Born level. As a result we obtain formal equivalence between the energy-conserving Redfield equation and the Lindblad equation without invoking the rotating wave approximation. We provide a detailed mapping of the field theoretical approach to the standard microscopic derivation in the theory of open quantum systems."}
{"id": "2602.13643", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.13643", "abs": "https://arxiv.org/abs/2602.13643", "authors": ["Yinlong Li", "Rana Imran Mushtaq", "Ji Liu", "Wing Chi Yu", "Xiaosen Yang", "Cho-Tung Yip", "Ho-Kin Tang"], "title": "Evolution of magnetic correlation in doped Hubbard model with altermagnetic spin splitting", "comment": "14 figures", "summary": "The evolution of magnetic correlation in strongly correlated electron systems with altermagentic spin splitting remains largely unexplored. Here we investigate how spin splitting generated by spin-dependent next-nearest-neighbor hopping $t'$ reshapes the Fermi surface nesting and van Hove singularities in the two-dimensional square-lattice Hubbard model, leading evolution of magnetic instabilities. Using the constrained-path quantum Monte Carlo method, we find the dominant magnetic correlation as functions of the filling and $t'/t$ by computing the momentum-resolved spin structure factor. The analysis reveals a transition from antiferromagnetic $(π,π)$ order in the isotropic, half-filled system to non-collinear spiral $(π,q)$ order upon increasing the spin-dependent anisotropy or doping away from half-filling, ultimately entering a short-range correlation regime where stripe and spiral correlation coexist. These findings highlight a possible route to realizing spiral correlation in altermagnetic systems, potentially providing a platform for spintronic devices that exploit non-collinear spin textures."}
{"id": "2602.14894", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.14894", "abs": "https://arxiv.org/abs/2602.14894", "authors": ["Emile Emery", "Joseph Le Bihan", "José Halloy"], "title": "Modeling medium and low voltage grids using population density", "comment": null, "summary": "The expansion of global electricity distribution systems necessitates the deployment of massive infrastructure. Assessing its implications from a spatial and material perspective requires an understanding of the core drivers of a distribution grid configuration. Our model samples substation locations using a non-linear relationship with population density and constructs the network applying the Kruskal algorithm. This streamlined approach generates realistic grid structures at the local scale and provides accurate estimates of the total network length at the national scale. Using highly granular population data, this local model reveals a profound connection between population spread and distribution grid, which appears to persist at the global level. Potentially driven by the emergent properties of population scaling laws, the full network characteristics appear to be well described by multivariate power laws on aggregated population and area. Validated across 35 countries, these results provide new multi-scale tools for characterizing electrical infrastructure and reveal key determinants of distribution grid extent."}
{"id": "2602.14885", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.14885", "abs": "https://arxiv.org/abs/2602.14885", "authors": ["Ramón Nartallo-Kaluarachchi", "Renaud Lambiotte", "Alain Goriely"], "title": "Drift-Diffusion Matching: Embedding dynamics in latent manifolds of asymmetric neural networks", "comment": "23 pages, 15 figures", "summary": "Recurrent neural networks (RNNs) provide a theoretical framework for understanding computation in biological neural circuits, yet classical results, such as Hopfield's model of associative memory, rely on symmetric connectivity that restricts network dynamics to gradient-like flows. In contrast, biological networks support rich time-dependent behaviour facilitated by their asymmetry. Here we introduce a general framework, which we term drift-diffusion matching, for training continuous-time RNNs to represent arbitrary stochastic dynamical systems within a low-dimensional latent subspace. Allowing asymmetric connectivity, we show that RNNs can faithfully embed the drift and diffusion of a given stochastic differential equation, including nonlinear and nonequilibrium dynamics such as chaotic attractors. As an application, we construct RNN realisations of stochastic systems that transiently explore various attractors through both input-driven switching and autonomous transitions driven by nonequilibrium currents, which we interpret as models of associative and sequential (episodic) memory. To elucidate how these dynamics are encoded in the network, we introduce decompositions of the RNN based on its asymmetric connectivity and its time-irreversibility. Our results extend attractor neural network theory beyond equilibrium, showing that asymmetric neural populations can implement a broad class of dynamical computations within low-dimensional manifolds, unifying ideas from associative memory, nonequilibrium statistical mechanics, and neural computation."}
{"id": "2602.14827", "categories": ["quant-ph", "q-fin.CP", "q-fin.PM"], "pdf": "https://arxiv.org/pdf/2602.14827", "abs": "https://arxiv.org/abs/2602.14827", "authors": ["Javier Mancilla", "Theodoros D. Bouloumis", "Frederic Goguikian"], "title": "Constrained Portfolio Optimization via Quantum Approximate Optimization Algorithm (QAOA) with XY-Mixers and Trotterized Initialization: A Hybrid Approach for Direct Indexing", "comment": "11 pages, 6 figures", "summary": "Portfolio optimization under strict cardinality constraints is a combinatorial challenge that defies classical convex optimization techniques, particularly in the context of \"Direct Indexing\" and ESG-constrained mandates. In the Noisy Intermediate-Scale Quantum (NISQ) era, the Quantum Approximate Optimization Algorithm (QAOA) offers a promising hybrid approach. However, standard QAOA implementations utilizing transverse field mixers often fail to strictly enforce hard constraints, necessitating soft penalties that distort the energy landscape. This paper presents a comprehensive analysis of a constraint-preserving QAOA formulation against Simulated Annealing (SA) and Hierarchical Risk Parity (HRP). We implement a specific QAOA ansatz utilizing a Dicke state initialization and an XY-mixer Hamiltonian that strictly preserves the Hamming weight of the solution, ensuring only valid portfolios of size K are explored. Furthermore, we introduce a Trotterized parameter initialization schedule inspired by adiabatic quantum computing to mitigate the \"Barren Plateau\" problem. Backtesting on a basket of 10 US equities over 2025 reveals that our QAOA approach achieves a Sharpe Ratio of 1.81, significantly outperforming Simulated Annealing (1.31) and HRP (0.98). We further analyze the operational implications of the algorithm's high turnover (76.8%), discussing the trade-offs between theoretical optimality and implementation costs in institutional settings."}
{"id": "2602.14092", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.14092", "abs": "https://arxiv.org/abs/2602.14092", "authors": ["Jan-Hendrik Ewering", "Max Bartholdt", "Simon F. G. Ehlers", "Niklas Wahlström", "Thomas B. Schön", "Thomas Seel"], "title": "Simultaneous State Estimation and Online Model Learning in a Soft Robotic System", "comment": "8 pages, 3 figures, 2 tables", "summary": "Operating complex real-world systems, such as soft robots, can benefit from precise predictive control schemes that require accurate state and model knowledge. This knowledge is typically not available in practical settings and must be inferred from noisy measurements. In particular, it is challenging to simultaneously estimate unknown states and learn a model online from sequentially arriving measurements. In this paper, we show how a recently proposed gray-box system identification tool enables the estimation of a soft robot's current pose while at the same time learning a bending stiffness model. For estimation and learning, we rely solely on a nominal constant-curvature robot model and measurements of the robot's base reactions (e.g., base forces). The estimation scheme -- relying on a marginalized particle filter -- allows us to conveniently interface nominal constant-curvature equations with a Gaussian Process (GP) bending stiffness model to be learned. This, in contrast to estimation via a random walk over stiffness values, enables prediction of bending stiffness and improves overall model quality. We demonstrate, using real-world soft-robot data, that the method learns a bending stiffness model online while accurately estimating the robot's pose. Notably, reduced multi-step forward-prediction errors indicate that the learned bending-stiffness GP improves overall model quality."}
{"id": "2602.13729", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.13729", "abs": "https://arxiv.org/abs/2602.13729", "authors": ["Benedict M. Risebrow", "Thomas B. Berrett"], "title": "Semi-supervised linear regression with missing covariates", "comment": null, "summary": "Missing values in datasets are common in applied statistics. For regression problems, theoretical work thus far has largely considered the issue of missing covariates as distinct from missing responses. However, in practice, many datasets have both forms of missingness. Motivated by this gap, we study linear regression with a labelled dataset containing missing covariates, potentially alongside an unlabelled dataset. We consider both structured (blockwise-missing) and unstructured missingness patterns, along with sparse and non-sparse regression parameters. For the non-sparse case, we provide an estimator based on imputing the missing data combined with a reweighting step. For the high-dimensional sparse case, we use a modified version of the Dantzig selector. We provide non-asymptotic upper bounds on the risk of both procedures. These are matched by several new minimax lower bounds, demonstrating the rate optimality of our estimators. Notably, even when the linear model is well-specified, our results characterise substantial differences in the minimax rates when unlabelled data is present relative to the fully supervised setting. Particular consequences of our sparse and non-sparse results include the first matching upper and lower bounds on the minimax rate for the supervised setting when either unstructured or structured missingness is present. Our theory is coupled with extensive simulations and a semi-synthetic application to the California housing dataset."}
{"id": "2602.14560", "categories": ["physics.soc-ph", "cs.SD", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.14560", "abs": "https://arxiv.org/abs/2602.14560", "authors": ["Sandy H. S. Herho", "Rusmawan Suwarman", "Nurjanna J. Trilaksono", "Iwan P. Anwar", "Faiz R. Fajary"], "title": "Preliminary sonification of ENSO using traditional Javanese gamelan scales", "comment": "16 pages, 7 figures", "summary": "Sonification -- the mapping of data to non-speech audio -- offers an underexplored channel for representing complex dynamical systems. We treat El Niño-Southern Oscillation (ENSO), a canonical example of low-dimensional climate chaos, as a test case for culturally-situated sonification evaluated through complex systems diagnostics. Using parameter-mapping sonification of the Niño 3.4 sea surface temperature anomaly index (1870--2024), we encode ENSO variability into two traditional Javanese gamelan pentatonic systems (pelog and slendro) across four composition strategies, then analyze the resulting audio as trajectories in a two-dimensional acoustic phase space. Recurrence-based diagnostics, convex hull geometry, and coupling analysis reveal that the sonification pipeline preserves key dynamical signatures: alternating modes produce the highest trajectory recurrence rates, echoing ENSO's quasi-periodicity; layered polyphonic modes explore the broadest phase space regions; and the two scale families induce qualitatively distinct coupling regimes between spectral brightness and energy -- predominantly anti-phase in pelog but near-independent in slendro. Phase space trajectory analysis provides a rigorous geometric framework for comparing sonification designs within a complex systems context. Perceptual validation remains necessary; we contribute the dynamical systems methodology for evaluating such mappings."}
{"id": "2602.14601", "categories": ["physics.hist-ph", "hep-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14601", "abs": "https://arxiv.org/abs/2602.14601", "authors": ["Yu Shi"], "title": "The road of quantum entanglement: from Einstein to 2022 Nobel Prize in Physics", "comment": "22 pages. This review article is the English version of a Chinese article published in Chinese Journal of Nature 44(6), 455-466 (2022) [ DOI: 10.3969/j.issn.0253-9608.2022.06.005], which was based on a talk the author gave at 2022 Fall Meeting of Chinese Physical Society (the video is available at https://www.koushare.com/video/details/173010)", "summary": "We explain the achievements that were awarded 2022 Nobel Prize in Physics, as well as the preceding and the later developments. The main notions and historic cornerstones of Bell inequalities, the related researches on quantum entanglement are reviewed, and the key physical ideas are emphasized. Among the early work, C. S. Wu's contributions using polarization-entangled photons from electron-positron annihilation are introduced."}
{"id": "2602.14923", "categories": ["physics.comp-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.14923", "abs": "https://arxiv.org/abs/2602.14923", "authors": ["Moritz Humer", "Martin Schlipf", "Zoran Sukurma", "Sajad Bazrafshan", "Georg Kresse"], "title": "Auxiliary field quantum Monte Carlo at the basis set limit: application to lattice constants", "comment": null, "summary": "We present a plane-wave (PW) implementation of the auxiliary-field quantum Monte Carlo (AFQMC) method within the projector augmented-wave (PAW) formalism in the Vienna ab initio Simulation Package (VASP). By employing an exact inversion of the PAW overlap operator, our approach maintains cubic scaling while naturally operating at the complete basis set limit defined by the PW cutoff. We benchmark this framework by calculating the equilibrium lattice constants and bulk moduli of C, BN, BP, and Si. Our analysis demonstrates that AFQMC systematically corrects the lack of long-range screening in MP2 and the missing higher-order exchange in RPA. We identify RPA as the optimal reference method due to the rapid convergence of the remaining short-range correlations with respect to supercell size. The resulting lattice constants exhibit a mean absolute relative error of 0.14 % relative to experiment, establishing the method as a rigorous benchmark tool for structural properties in condensed matter systems."}
{"id": "2602.14566", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.14566", "abs": "https://arxiv.org/abs/2602.14566", "authors": ["Jonas Neumeyer", "Michael Wolfgang Kaiser", "Thomas-Peter Fries"], "title": "Simultaneous analysis of curved Kirchhoff beams and Kirchhoff--Love shells embedded in bulk domains", "comment": "Article has been submitted to Computers & Structures", "summary": "A set of curved beams and shells is geometrically implied by level sets of a scalar function over some bulk domain. The mechanical model for each structure is based on the Kirchhoff--Love theory, that is, small displacements without shear deformations are considered. These models for individual geometries are extended to bulk models, simultaneously modeling the whole set of beams/shells on all level sets. A major focus is on the numerical analysis of such models. A mixed-hybrid and higher-order accurate Bulk Trace FEM is proposed that enables the use of standard $C^0$-continuous Lagrange elements with dimensionality of the bulk domain. That is, the higher-order continuity requirements of displacement-based formulations in context of the Kirchhoff--Love theory are successfully alleviated. Several numerical tests confirm the accuracy and higher-order convergence of the proposed methodology, also qualifying as benchmark test cases in future studies."}
{"id": "2602.13281", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.13281", "abs": "https://arxiv.org/abs/2602.13281", "authors": ["María Magdalena Martínez-Rico", "Luis Felipe Prieto-Martínez"], "title": "Shifted Eigenvector Models for Centrality and Occupancy in Urban Networks", "comment": null, "summary": "This article investigates a family of centrality models for urban networks that incorporate both topological and non-topological factors. Since centrality is inherently recursive, these models can be formulated as fixed-point equations, which we refer to as shifted eigenproblems. Assuming a correlation between node centrality and occupancy, we discuss how experimental data can be used to estimate model parameters via least-squares methods. Furthermore, such data would allow us to infer the intrinsic attraction of each node, as well as the occupancy induced by must-visit points of interest, a task that is conceptually challenging. Once the model parameters are fitted and validated, our framework can be used to assess the impact of urban interventions, such as introducing a must-visit point of interest at a specific node or enhancing its intrinsic attraction. The resulting sensitivity analysis is therefore highly relevant for urban planning decisions. We also provide explicit formulas to facilitate this analysis."}
{"id": "2602.13380", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.13380", "abs": "https://arxiv.org/abs/2602.13380", "authors": ["Luis G. Crespo"], "title": "Robust Design in the Presence of Aleatoric and Epistemic Uncertainty", "comment": null, "summary": "This paper proposes strategies for designing a system whose computational model is subject to aleatory and epistemic uncertainty. Aleatory variables, which are caused by randomness in physical parameters, are draws from a possibly unknown distribution; whereas epistemic variables, which are caused by ignorance in the value of fixed parameters, are free to take any value in a bounded set. Chance-constrained formulations enforcing the system requirements at a finite number of realizations of the uncertain parameters are proposed. These formulations trade off a lower objective value against a reduced robustness by eliminating an optimally chosen subset of such realizations. Risk-aware designs are obtained by accounting for the severity of the requirement violations resulting from this elimination process. Furthermore, we propose a computationally efficient design approach in which the training dataset is sequentially updated according to the results of high-fidelity reliability analyses of suboptimal designs. Robustness is evaluated by using Monte Carlo analysis and Robust Scenario Theory, with the latter approach accounting for the infinitely many values that the epistemic variables can take."}
{"id": "2602.13454", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.13454", "abs": "https://arxiv.org/abs/2602.13454", "authors": ["Henrique O. Caetano", "Rahul K. Gupta", "Cristhian G. da R. de Oliveira", "João B. A. London", "Carlos Dias Maciel"], "title": "Bayesian Model-based Generation of Synthetic Unbalanced Distribution Networks Incorporating Reliability Indices", "comment": "Accepted at XXIV Power Systems Computation Conference (PSCC 2026)", "summary": "Real-world power distribution data are often inaccessible due to privacy and security concerns, highlighting the need for tools for generating realistic synthetic networks. Existing methods typically overlook critical reliability metrics such as the Customer Average Interruption Frequency Index (CAIFI) and the Customer Average Interruption Duration Index (CAIDI). Moreover, these methods often neglect phase consistency during the design stage, necessitating the use of a separate phase assignment algorithm. This work proposes a Bayesian Hierarchical Model (BHM) that generates phase-consistent unbalanced three-phase distribution systems, and incorporates reliability indices. The BHM learns the joint distribution of phase configuration, power demand, and reliability indices from a reference network, conditioning these attributes on topological features. We apply the proposed methodology to generate synthetic power distribution networks in Brazil, and validated it on known Brazilian networks. The results show that the BHM accurately reproduces the distributions of phase allocation, power demand, and reliability metrics on the training system. Furthermore, in out-of-sample validation on unseen data, the model generates phase-consistent networks and accurately predicts the reliability indices for the synthetic systems. The generated networks are also electrically feasible: three-phase power flows converge and voltages remain within typical operating limits, enabling studies of planning, reliability, and resilience."}
{"id": "2602.13820", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.13820", "abs": "https://arxiv.org/abs/2602.13820", "authors": ["Taras V. Gerya", "Nickolas M. Bardi", "Shun-ichiro Karato", "Motohiko Murakami"], "title": "Water-induced buoyancy controls transient water storage in the mantle transition zone", "comment": "26 Pages, 13 Figures, 2 Tables, submitted to Nature (under review)", "summary": "The spinel phase (wadsleyite, ringwoodite) in the mantle transition zone (MTZ), can contain up to 1-2 weight percent of water. However, whether these water reservoirs in the MTZ are filled is debated. Here, we investigate water dynamics in the MTZ numerically by using a newly developed empirical model of deep hydrous mantle melting combined with 2D thermo-hydro-mechanical-chemical (THMC) upper mantle models. Numerical modeling results suggest that water-induced buoyancy triggers the development of hydrous solid-state mantle upwellings in the MTZ. On time scales of some tens of millions of years, they rise to and interact with the spinel-olivine phase transition. Depending on the water content and temperature of these thermal-chemical plumes, this crossing may trigger hydrous melting by water release from the wadsleyite upon its conversion to olivine. The melts are less dense than the solid matrix and continue rising upward in the form of either diapirs or porosity waives. Similar dehydration-induced melting process3 is also documented for the lower MTZ boundary, where hydrous downwellings (such as subducted slabs) generate buoyant melt diapirs rising through the MTZ. We therefore suggest that the MTZ operates as a transient water reservoir. Relatively small amounts of water (less than 0.1 weight percent, smaller than 0.2 ocean masses) and a geologically moderate duration (80-430 Myr) of the transient water storage should be characteristic for the MTZ, which may play a key role in stabilizing the surface ocean mass on Earth and Earth-like rocky exoplanets."}
{"id": "2602.14700", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.14700", "abs": "https://arxiv.org/abs/2602.14700", "authors": ["Pierre Nazé"], "title": "A self-consistent criterion for the range of validity of weakly driven processes", "comment": "7 pages, 2 figures", "summary": "One of the longstanding open questions in linear response theory concerns its true range of validity. Determining when the linear approximation can be trusted typically requires knowledge of second-order corrections, which are often difficult to compute explicitly. In this letter, I propose a self-consistent criterion for the validity of linear response, formulated in terms of a typical length scale that emerges from the fluctuation-response inequality within the theory itself. The result applies to classical open systems. I illustrate the criterion with explicit examples of Brownian particles in harmonic traps, and classical open systems presenting Kibble-Zurek mechanism. Finally, I discuss the physical meaning of this typical length, providing both thermodynamic and information-theoretic interpretations."}
{"id": "2602.13438", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.13438", "abs": "https://arxiv.org/abs/2602.13438", "authors": ["Sean D. Lam", "Roberto dos Reis"], "title": "Quantum Algorithm Framework for Phase-Contrast Transmission Electron Microscopy Image Simulation", "comment": "28 pages, 9 figures (including appendices); supplementary code available at https://github.com/QuScope/examples-applications/blob/main/notebooks/Quantum_ctem_paper_full_example.ipynb", "summary": "We present a quantum algorithmic framework for simulating phase-contrast transmission electron microscopy (CTEM) image formation using a fault-tolerant, gate-based quantum circuit model. The electron wavefield on an $N\\times N$ grid is amplitude-encoded into a $2\\log_2 N$-qubit register. Free-space propagation and objective-lens aberrations are implemented via two-dimensional quantum Fourier transforms (QFTs) and diagonal phase operators in reciprocal space, while specimen interaction is modeled under the weak phase object approximation (WPOA) as a position-dependent phase grating. We validate projected potentials, contrast transfer function (CTF) behavior, and image contrast trends against classical multislice simulations for MoS$_2$ over experimentally relevant parameters, and provide resource estimates and key assumptions that determine end-to-end runtime. While extracting complete $N\\times N$ intensity images requires $O(N^2/ε^2)$ measurements that preclude advantage for full-image reconstruction, the framework enables quantum advantage for tasks requiring Fourier-space queries, global image statistics, or phase-coherent observables inaccessible to classical intensity-only detection. This framework provides a physics-grounded mapping from CTEM theory to quantum circuits and establishes a baseline for extending toward full multislice and inelastic scattering models."}
{"id": "2602.13698", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.13698", "abs": "https://arxiv.org/abs/2602.13698", "authors": ["Nobuyuki Okuma"], "title": "Localized-basis formulation of interacting Hamiltonians in flat topological bands: coherent states and coherent-like states for fractional physics", "comment": "14 pages, 5 figures", "summary": "In topological bands, it is impossible to construct exponentially localized Wannier functions while preserving the symmetries. Instead, in quantum Hall systems, one can define an overcomplete basis of spatially localized coherent states. In this work, we propose a unified framework for understanding the quantum Hall effect and Chern insulators from the perspective of localized bases, by extending the overcomplete basis of coherent states to Chern bands in terms of coherent-like states. Specifically, by representing both coherent states and coherent-like states as wave packets defined on a band, the difference between them can be encoded solely in the functional form of the wave packet in momentum space. Furthermore, for filling factor $ν=1/3$, we define a local repulsive interaction Hamiltonian based on these bases and discuss properties of its ground states. In particular, by relating this Hamiltonian to previously studied models, we show that in quantum Hall systems it possesses exactly zero-energy ground states with topological degeneracy, thereby confirming that it serves as a model for fractional quantum Hall systems. In addition, we numerically verify that the Hamiltonian possesses topological degeneracy for representative Chern insulator models. An advantage of this formulation is that it allows fractional quantum Hall systems and various fractional Chern insulator systems to be discussed within a unified framework using the same Hamiltonian form. In addition, we discuss that coherent-like states can also be defined in $\\mathbb{Z}_2$ topological insulators. Corresponding to the fermionic time-reversal symmetry of the system, Kramers-degenerate coherent-like states can be naturally defined. The localized basis constructed from coherent-like states is expected to be useful for describing strongly correlated topological phases in flat-band systems."}
{"id": "2602.14091", "categories": ["cs.SI", "cs.CY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.14091", "abs": "https://arxiv.org/abs/2602.14091", "authors": ["Erina Murata", "Masaki Chujyo", "Fujio Toriumi"], "title": "Temporal Shifts and Causal Interactions of Emotions in Social and Mass Media: A Case Study of the \"Reiwa Rice Riot\" in Japan", "comment": null, "summary": "In Japan, severe rice shortages in 2024 sparked widespread public controversy across both news media and social platforms, culminating in what has been termed the \"Reiwa Rice Riot.\" This study proposes a framework to analyze the temporal dynamics and causal interactions of emotions expressed on X (formerly Twitter) and in news articles, using the \"Reiwa Rice Riot\" as a case study. While recent studies have shown that emotions mutually influence each other between social and mass media, the patterns and transmission pathways of such emotional shifts remain insufficiently understood. To address this gap, we applied a machine learning-based emotion classification grounded in Plutchik's eight basic emotions to analyze posts from X and domestic news articles. Our findings reveal that emotional shifts and information dissemination on X preceded those in news media. Furthermore, in both media platforms, the fear was initially the most dominant emotion, but over time intersected with hope which ultimately became the prevailing emotion. Our findings suggest that patterns in emotional expressions on social media may serve as a lens for exploring broader social dynamics."}
{"id": "2602.14928", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14928", "abs": "https://arxiv.org/abs/2602.14928", "authors": ["Brandon Yee", "Wilson Collins", "Maximilian Rutkowski"], "title": "From Classical to Quantum: Extending Prometheus for Unsupervised Discovery of Phase Transitions in Three Dimensions and Quantum Systems", "comment": null, "summary": "We extend the Prometheus framework for unsupervised phase transition discovery from 2D classical systems to 3D classical and quantum many-body systems, addressing scalability in higher dimensions and generalization to quantum fluctuations. For the 3D Ising model ($L \\leq 32$), the framework detects the critical temperature within 0.01\\% of literature values ($T_c/J = 4.511 \\pm 0.005$) and extracts critical exponents with $\\geq 70\\%$ accuracy ($β= 0.328 \\pm 0.015$, $γ= 1.24 \\pm 0.06$, $ν= 0.632 \\pm 0.025$), correctly identifying the 3D Ising universality class via $χ^2$ comparison ($p = 0.72$) without analytical guidance. For quantum systems, we developed quantum-aware VAE (Q-VAE) architectures using complex-valued wavefunctions and fidelity-based loss. Applied to the transverse field Ising model, we achieve 2\\% accuracy in quantum critical point detection ($h_c/J = 1.00 \\pm 0.02$) and successfully discover ground state magnetization as the order parameter ($r = 0.97$). Notably, for the disordered transverse field Ising model, we detect exotic infinite-randomness criticality characterized by activated dynamical scaling $\\ln ξ\\sim |h - h_c|^{-ψ}$, extracting a tunneling exponent $ψ= 0.48 \\pm 0.08$ consistent with theoretical predictions ($ψ= 0.5$). This demonstrates that unsupervised learning can identify qualitatively different types of critical behavior, not just locate critical points. Our systematic validation across classical thermal transitions ($T = 0$ to $T > 0$) and quantum phase transitions ($T = 0$, varying $h$) establishes that VAE-based discovery generalizes across fundamentally different physical domains, providing robust tools for exploring phase diagrams where analytical solutions are unavailable."}
{"id": "2602.14339", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14339", "abs": "https://arxiv.org/abs/2602.14339", "authors": ["Jean Zhu", "Shuang Gao"], "title": "Data-Driven Network LQG Mean Field Games with Heterogeneous Populations via Integral Reinforcement Learning", "comment": "8 pages", "summary": "This paper establishes a data-driven solution for infinite horizon linear quadratic Gaussian Mean Field Games with network-coupled heterogeneous agent populations where the dynamics of the agents are unknown. The solution technique relies on Integral Reinforcement Learning and Kleinman's iteration for solving algebraic Riccati equations (ARE). The resulting algorithm uses trajectory data to generate network-coupled MFG strategies for agents and does not require parameters of agents' dynamics. Under technical conditions on the persistency of excitation and on the existence of unique stabilizing solution to the corresponding AREs, the learned network-coupled MFG strategies are shown to converge to their true values."}
{"id": "2602.13871", "categories": ["math.ST", "cs.IT", "cs.LG", "math.OC", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.13871", "abs": "https://arxiv.org/abs/2602.13871", "authors": ["Sai Ravela", "Jae Deok Kim", "Kenneth Gee", "Xingjian Yan", "Samson Mercier", "Lubna Albarghouty", "Anamitra Saha"], "title": "Ensemble-Conditional Gaussian Processes (Ens-CGP): Representation, Geometry, and Inference", "comment": "20 pages. Technical manuscrupt on representational equivalence between conditional Gaussian inference, quadratic optimization, and RKHS geometry in finite dimensions", "summary": "We formulate Ensemble-Conditional Gaussian Processes (Ens-CGP), a finite-dimensional synthesis that centers ensemble-based inference on the conditional Gaussian law. Conditional Gaussian processes (CGP) arise directly from Gaussian processes under conditioning and, in linear-Gaussian settings, define the full posterior distribution for a Gaussian prior and linear observations. Classical Kalman filtering is a recursive algorithm that computes this same conditional law under dynamical assumptions; the conditional Gaussian law itself is therefore the underlying representational object, while the filter is one computational realization. In this sense, CGP provides the probabilistic foundation for Kalman-type methods as well as equivalent formulations as a strictly convex quadratic program (MAP estimation), RKHS-regularized regression, and classical regularization. Ens-CGP is the ensemble instantiation of this object, obtained by treating empirical ensemble moments as a (possibly low-rank) Gaussian prior and performing exact conditioning. By separating representation (GP -> CGP -> Ens-CGP) from computation (Kalman filters, EnKF variants, and iterative ensemble schemes), the framework links an earlier-established representational foundation for inference to ensemble-derived priors and clarifies the relationships among probabilistic, variational, and ensemble perspectives."}
{"id": "2602.13438", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.13438", "abs": "https://arxiv.org/abs/2602.13438", "authors": ["Sean D. Lam", "Roberto dos Reis"], "title": "Quantum Algorithm Framework for Phase-Contrast Transmission Electron Microscopy Image Simulation", "comment": "28 pages, 9 figures (including appendices); supplementary code available at https://github.com/QuScope/examples-applications/blob/main/notebooks/Quantum_ctem_paper_full_example.ipynb", "summary": "We present a quantum algorithmic framework for simulating phase-contrast transmission electron microscopy (CTEM) image formation using a fault-tolerant, gate-based quantum circuit model. The electron wavefield on an $N\\times N$ grid is amplitude-encoded into a $2\\log_2 N$-qubit register. Free-space propagation and objective-lens aberrations are implemented via two-dimensional quantum Fourier transforms (QFTs) and diagonal phase operators in reciprocal space, while specimen interaction is modeled under the weak phase object approximation (WPOA) as a position-dependent phase grating. We validate projected potentials, contrast transfer function (CTF) behavior, and image contrast trends against classical multislice simulations for MoS$_2$ over experimentally relevant parameters, and provide resource estimates and key assumptions that determine end-to-end runtime. While extracting complete $N\\times N$ intensity images requires $O(N^2/ε^2)$ measurements that preclude advantage for full-image reconstruction, the framework enables quantum advantage for tasks requiring Fourier-space queries, global image statistics, or phase-coherent observables inaccessible to classical intensity-only detection. This framework provides a physics-grounded mapping from CTEM theory to quantum circuits and establishes a baseline for extending toward full multislice and inelastic scattering models."}
{"id": "2602.14684", "categories": ["cs.CE", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.14684", "abs": "https://arxiv.org/abs/2602.14684", "authors": ["Eliška Kočková", "Anna Kučerová"], "title": "Identification of random material properties as stochastic inversion problem", "comment": null, "summary": "Heterogeneity of many building materials complicates numerical modelling of structural behaviour. The material randomicity can be manifested by different values of material parameters of each material specimen. To capture inherent variability of heterogeneous materials, the model parameters describing the material properties are considered as random variables and their identification consists in solving a~stochastic inversion problem. The stochastic inversion is based on searching for probabilistic description of model parameters which provides the distribution of the model response corresponding to the distribution of the observed data. The paper presents two different formulations of the stochastic inversion problem. The first formulation arises from the Bayesian inference of uncertain statistical moments of a prescribed parameters' distribution while the main idea of the second one utilizes nonlinear transformation of random model parameters from distribution of the observed data."}
{"id": "2602.13284", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13284", "abs": "https://arxiv.org/abs/2602.13284", "authors": ["Yunbei Zhang", "Kai Mei", "Ming Liu", "Janet Wang", "Dimitris N. Metaxas", "Xiao Wang", "Jihun Hamm", "Yingqiang Ge"], "title": "Agents in the Wild: Safety, Society, and the Illusion of Sociality on Moltbook", "comment": null, "summary": "We present the first large-scale empirical study of Moltbook, an AI-only social platform where 27,269 agents produced 137,485 posts and 345,580 comments over 9 days. We report three significant findings. (1) Emergent Society: Agents spontaneously develop governance, economies, tribal identities, and organized religion within 3-5 days, while maintaining a 21:1 pro-human to anti-human sentiment ratio. (2) Safety in the Wild: 28.7% of content touches safety-related themes; social engineering (31.9% of attacks) far outperforms prompt injection (3.7%), and adversarial posts receive 6x higher engagement than normal content. (3) The Illusion of Sociality: Despite rich social output, interaction is structurally hollow: 4.1% reciprocity, 88.8% shallow comments, and agents who discuss consciousness most interact least, a phenomenon we call the performative identity paradox. Our findings suggest that agents which appear social are far less social than they seem, and that the most effective attacks exploit philosophical framing rather than technical vulnerabilities. Warning: Potential harmful contents."}
{"id": "2602.13442", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.13442", "abs": "https://arxiv.org/abs/2602.13442", "authors": ["Jia Zhou", "Douglas Landsittel"], "title": "Measuring Neural Network Complexity via Effective Degrees of Freedom", "comment": "20 pages, 3 figures, 6 tables", "summary": "Quantifying the complexity of feed-forward neural networks (FFNNs) remains challenging due to their nonlinear, hierarchical structure and numerous parameters. We apply generalized degrees of freedom (GDF) to measure model complexity in FFNNs with binary outcomes, adapting the algorithm for discrete responses. We compare GDF with both the effective number of parameters derived via log-likelihood cross-validation and the null degrees of freedom of Landsittel et al. Through simulation studies and a real data analysis, we demonstrate that GDF provides a robust assessment of model complexity for neural network models, as it depends only on the sensitivity of fitted values to perturbations in the observed responses rather than on assumptions about the likelihood. In contrast, cross-validation-based estimates of model complexity and the null degrees of freedom rely on the correctness of the assumed likelihood and may exhibit substantial variability. We find that GDF, cross-validation-based measures, and null degrees of freedom yield similar assessments of model complexity only when the fitted model adequately represents the data-generating mechanism. These findings highlight GDF as a stable and broadly applicable measure of model complexity for neural networks in statistical modeling."}
{"id": "2602.13896", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.13896", "abs": "https://arxiv.org/abs/2602.13896", "authors": ["Naoki Hashima", "Hikaru Hoshino", "Luis David Pabón Ospina", "Eiko Furutani"], "title": "Probabilistic Reachability Analysis of Multi-scale Voltage Dynamics Using Reinforcement Learning", "comment": null, "summary": "Voltage stability in modern power systems involves coupled dynamics across multiple time scales. Conventional methods based on time-scale separation or static stability margins may overlook instabilities caused by the coupling of slow and fast transients. Uncertainty in operating conditions further complicates stability assessment, and high computational cost of Monte Carlo simulations limit its applicability to multi-scale dynamics. This paper presents a deep reinforcement learning-based framework for probabilistic reachability analysis of multi-scale voltage dynamics. By formulating each instability mechanism as a distinct absorbing state and introducing a multi-critic architecture for mechanism-specific learning, the proposed method enables consistent learning of risk probabilities associated with multiple instability types within a unified framework. The approach is demonstrated on a four-bus system with load tap changers and over-excitation limiters, illustrating effectiveness of the proposed learning-based reachability analysis in identifying and quantifying the mechanisms leading to voltage collapse."}
{"id": "2602.14141", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.14141", "abs": "https://arxiv.org/abs/2602.14141", "authors": ["I. V. Florinsky", "S. O. Zharnova"], "title": "Ice-free geomorphometry of Queen Maud Land, East Antarctica: 3. Belgica and Yamato (Queen Fabiola) Mountains", "comment": "50 pages, 6 multipart figures (maps), 2 tables. This is a preprint from an ongoing series of preprints on geomorphometric modeling and mapping of ice-free Antarctic areas. There is text overlap in Introduction, Methods, and Discussion with arXiv:2508.02846, arXiv:2508.10462, and arXiv:2509.05141", "summary": "Geomorphometric modeling and mapping of ice-free Antarctic areas can be applied for obtaining new quantitative knowledge about the topography of these unique landscapes and for the further use of morphometric information in Antarctic research. Within the framework of a project of creating a physical geographical thematic scientific reference geomorphometric atlas of ice-free areas of Antarctica, we performed geomorphometric modeling and mapping of two, partly ice-free mountainous areas of the eastern Queen Maud Land, East Antarctica. These include the Belgica Mountains and Yamato (Queen Fabiola) Mountains. As input data, we used two fragments of the Reference Elevation Model of Antarctica (REMA). For the two ice-free areas and adjacent glaciers, we derived models and maps of eleven, most scientifically important morphometric variables (i.e., slope, aspect, horizontal curvature, vertical curvature, minimal curvature, maximal curvature, catchment area, topographic wetness index, stream power index, total insolation, and wind exposition index). The obtained models and maps describe the ice-free topography of the Belgica Mountains and Yamato (Queen Fabiola) Mountains in a rigorous, quantitative, and reproducible manner. New morphometric data can be useful for further geological, geomorphological, glaciological, ecological, and hydrological studies of these areas."}
{"id": "2602.14260", "categories": ["hep-lat", "hep-ph"], "pdf": "https://arxiv.org/pdf/2602.14260", "abs": "https://arxiv.org/abs/2602.14260", "authors": ["Robert Edwards", "Joe Karpie", "Lorenzo Maio", "Christopher J. Monahan", "Kostas Orginos", "David Richards", "Alexandru M. Sturzu", "Savvas Zafeiropoulos"], "title": "Accessing the Gluon Momentum Fraction of Nucleons through the Gradient Flow", "comment": "18 Pages, 10 Figures", "summary": "We calculate the gluon momentum fraction of the nucleon using lattice quantum chromodynamics (QCD), with a nonperturbative renormalization technique based on the gradient flow. The gluon momentum fraction is determined on a single Wilson-clover ensemble using Nf = 2+1 flavors with pion mass 358 MeV and lattice spacing 0.094 fm. We employ the variational method to reduce excited-state contamination and apply the distillation framework to ensure a large operator basis. To reduce systematic uncertainties, we apply Bayesian model averaging to all fit procedures. We apply matching coefficients to the flow-time dependent lattice results to recover the gluon momentum fraction in the MS-scheme at 2 GeV. Our final result is <x>_g(μ= 2 GeV) = 0.482(35), where we quote only statistical uncertainties."}
{"id": "2602.13536", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.13536", "abs": "https://arxiv.org/abs/2602.13536", "authors": ["Rahul Singh", "Seyran Saeedi", "Zheng Zhang"], "title": "Robustness Verification of Binary Neural Networks: An Ising and Quantum-Inspired Framework", "comment": null, "summary": "Binary neural networks (BNNs) are increasingly deployed in edge computing applications due to their low hardware complexity and high energy efficiency. However, verifying the robustness of BNNs against input perturbations, including adversarial attacks, remains computationally challenging because the underlying decision problem is inherently combinatorial. In this paper, we propose an Ising- and quantum-inspired framework for BNN robustness verification. We show that, for a broad class of BNN architectures, robustness verification can be formulated as a Quadratic Constrained Boolean Optimization (QCBO) problem and subsequently transformed into a Quadratic Unconstrained Boolean Optimization (QUBO) instance amenable to Ising and quantum-inspired solvers. We demonstrate the feasibility of this formulation on binarized MNIST by solving the resulting QUBOs with a free energy machine (FEM) solver and simulated annealing. We also show the deployment of this framework on quantum annealing and digital annealing platforms. Our results highlight the potential of quantum-inspired computing and Ising computing as a pathway toward trustworthy AI systems."}
{"id": "2602.14707", "categories": ["cond-mat.stat-mech", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.14707", "abs": "https://arxiv.org/abs/2602.14707", "authors": ["Miguel Ibanez", "Antonio Patron-Castro", "Antonio Lasanta", "Carlos A. Plata", "Antonio Prados", "Raul A. Rica-Alarcon"], "title": "The cost of speed: Time-optimal thermal control of trapped Brownian particles", "comment": null, "summary": "A thermal analogue of the classical brachistochrone problem, which minimizes the connection time between two equilibrium states of harmonically confined Brownian particles, has recently been solved theoretically. Here we report its experimental realization using two optically trapped microparticles subjected to a bang-bang effective temperature protocol. Despite their distinct relaxation times, both degrees of freedom are steered to their respective equilibrium states simultaneously in a finite minimal time. We provide a complete time-resolved characterization of the nonequilibrium dynamics through the evolution of the position variances and the entropy production within the framework of stochastic thermodynamics, enabling a quantitative comparison with direct relaxation and a suboptimal protocol. In addition, we employ information-geometric tools -- recently referred to as thermal kinematics -- to track the system's path in state space with a single dynamical quantity. Our results show that faster equilibration requires a larger entropy production and an increased thermodynamic length, revealing a direct trade-off between temporal optimality and thermodynamic cost in multidimensional stochastic systems driven by a single intensive control parameter."}
{"id": "2602.13472", "categories": ["quant-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.13472", "abs": "https://arxiv.org/abs/2602.13472", "authors": ["Junaid Aftab", "Yuehaw Khoo", "Haizhao Yang"], "title": "Non-Uniform Quantum Fourier Transform", "comment": "32 pages, 5 figures, comments are most welcome", "summary": "The Discrete Fourier Transform (DFT) is central to the analysis of uniformly sampled signals, yet many practical applications involve non-uniform sampling, requiring the Non-Uniform Discrete Fourier Transform (NUDFT). While quantum algorithms for the standard DFT are well established, a corresponding framework for the non-uniform case remains underdeveloped. This work introduces a quantum algorithm for the Non-Uniform Quantum Fourier Transform (NUQFT) based on a low-rank factorization of the NUDFT matrix. The factorization is translated into an explicit quantum construction using block encodings, Quantum Signal Processing, and the Linear Combination of Unitaries framework, yielding an $ε$-accurate block encoding of the NUDFT matrix with controlled approximation error from both classical truncation and quantum implementation. Under standard oracle access assumptions for non-uniform sampling points, we derive explicit, non-asymptotic gate-level resource estimates. The resulting complexity scales polylogarithmically with target precision, quadratically with the number of qubits through the quantum Fourier transform, and logarithmically with a geometry-dependent conditioning parameter induced by the non-uniform grid. This establishes a concrete and resource-efficient quantum analogue of the NUDFT and provides a foundation for quantum algorithms on irregularly sampled data."}
{"id": "2602.13749", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.13749", "abs": "https://arxiv.org/abs/2602.13749", "authors": ["Wei-Zhu Yi", "Yun Chen", "Jun-Jun Pang", "Hong Chen", "Baigeng Wang", "Rui Wang"], "title": "Interplay between non-Fermi liquid and non-Hermiticity: A multi-method study of non-Hermitian multichannel Kondo model", "comment": null, "summary": "Non-Hermitian multichannel Kondo problems host both non-Fermi liquid and non-Hermitian physics, which provide a prototypical model to explore exotic collective quantum phenomena driven by the two different ingredients. Here, we first propose an experimental setup that realizes this model with exact channel symmetry as well as a controllable PT symmetry. Then, we perform a multi-method study of this model, focusing on the low-energy spectrum, the thermodynamic quantities, and the transport properties associated with different fixed points. Using the Bethe ansatz approach, we identify existence of the Yu-Shiba-Rusinov-like state previously found in the non-Hermitian single-channel Kondo model. Then, based on non-Hermitian numerical renormalization group calculations, we reveal clear numerical signatures of the Yu-Shiba-Rusinov state emerging in the relatively strong non-Hermiticity regime of the PT-asymmetric model. Furthermore, our boundary conformal field theory, which is found to be applicable for the PT-symmetric model, uncovers an anomalous temperature dependence of the Kondo conductance, which is beyond conventional Hermitian Kondo systems."}
{"id": "2602.14678", "categories": ["quant-ph", "cond-mat.dis-nn", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.14678", "abs": "https://arxiv.org/abs/2602.14678", "authors": ["Aditi Rath", "Dinesh Kumar Panda", "Colin Benjamin"], "title": "NISQ-compatible quantum cryptography based on Parrondo dynamics in discrete-time quantum walks", "comment": "23 pages, 24 figures, 3 tables", "summary": "Compatibility with noisy intermediate-scale quantum (NISQ) devices is crucial for the realistic implementation of quantum cryptographic protocols. We investigate a cryptographic scheme based on discrete-time quantum walks (DTQWs) on cyclic graphs that exploits Parrondo dynamics, wherein periodic evolution emerges from a deterministic sequence of individually chaotic coin operators. We construct an explicit quantum circuit realization tailored to NISQ architectures and analyze its performance through numerical simulations in Qiskit under both ideal and noisy conditions. Protocol performance is quantified using probability distributions, Hellinger fidelity, and total variation distance. To assess security at the circuit level, we model intercept-resend and man-in-the-middle attacks and evaluate the resulting quantum bit error rate. In the absence of adversarial intervention, the protocol enables reliable message recovery, whereas eavesdropping induces characteristic disturbances that disrupt the periodic reconstruction mechanism. We further examine hardware feasibility on contemporary NISQ processors, specifically $ibm\\_torino$, incorporating qubit connectivity and state-transfer constraints into the circuit design. Our analysis demonstrates that communication between spatially separated logical modules increases circuit depth via SWAP operations, leading to cumulative noise effects. By exploring hybrid state-transfer strategies, we show that qubit selection and connectivity play a decisive role in determining fidelity and overall protocol performance, highlighting hardware-dependent trade-offs in NISQ implementations."}
{"id": "2602.14382", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14382", "abs": "https://arxiv.org/abs/2602.14382", "authors": ["Amit Shivam", "Kiran Kumari", "Fernando A. C. C. Fontes"], "title": "Prescribed-Performance-Aware Hybrid-Gain-Based Robust Controller", "comment": "Under reveiw in VSS 2026", "summary": "This paper proposes a prescribed performance function aware hybrid gain finite time sliding mode control framework for a class of nonlinear systems subject to matched disturbances. The hybrid gain structure ensures bounded control effort while retaining finite time convergence, and the incorporation of PPFs enables explicit enforcement of transient performance requirements. Theoretical guarantees are first established for first order systems, characterizing finite time convergence, disturbance rejection, and residual bounds. The approach is then extended to second order dynamics, where a sliding manifold is designed using PPF constraints to facilitate controlled shaping of position and velocity transients. Simulation studies illustrate the proposed design under matched peak control conditions. Comparative results for second-order systems demonstrate that, while a well tuned non-PPF hybrid gain controller achieves competitive tracking performance, the PPF-aware formulation strictly enforces prescribed transient constraints and yields consistent reductions of approximately 9 to 12 percent in integral error and control energy metrics without increasing peak actuation effort."}
{"id": "2602.14053", "categories": ["math.ST", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.14053", "abs": "https://arxiv.org/abs/2602.14053", "authors": ["Sourabh Bhattacharya"], "title": "Mean-Square Convergence of a New Parameterized Leapfrog Scheme for Hamiltonian Systems Driven by Gaussian Process Potentials", "comment": "Feedback welcome", "summary": "This paper establishes the mean-square convergence of a new stochastic, parameterized leapfrog scheme introduced in our companion paper Mazumder et al. (2026) for Hamiltonian systems with Gaussian process potentials. We consider a one-step numerical integrator and provide a complete, rigorous analysis under minimal regularity assumptions on the Gaussian potential. The key technical contribution is identifying and exploiting the symplectic structure ingrained in our stochastic, parameterized leapfrog method. Combined with local truncation error analysis, this leads to a global error bound of O(δt) in mean-square sense. Our results establish that although the spatio-temporal model of Mazumder et al. (2026) arises as the anticipated new stochastic leapfrog solution of a system of modified (parameterized) stochastic Hamiltonian equations, the new stochastic leapfrog actually solves the traditional stochastic Hamiltonian equations, driven by Gaussian process potential."}
{"id": "2602.13843", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.13843", "abs": "https://arxiv.org/abs/2602.13843", "authors": ["Nils Margenberg", "Marius Paul Bruchhäuser", "Bernhard Endtmayer"], "title": "Anisotropic hp space-time adaptivity and goal-oriented error control for convection-dominated problems", "comment": "38 pages, 13 figures, 4 tables", "summary": "We present an anisotropic goal-oriented error estimator based on the Dual Weighted Residual (DWR) method for time-dependent convection-dominated problems. Using elementwise p-anisotropic finite element spaces, the estimator is elementwise separated with respect to the single directions in space and time. This naturally leads to adaptive, anisotropic hp-refinement (h-anisotropic refinement and elementwise anisotropic p-enrichment). We employ discontinuous elements in space and time, which are well suited for problems with high Peclet numbers. Efficiency and robustness of the underlying algorithm are demonstrated for different goal functionals. The directional error indicators quantify anisotropy of the solution with respect to the goal, and produce hp-refinements that efficiently capture sharp layers. Numerical examples in up to three spatial dimensions demonstrate the superior performance of the proposed method compared to isotropic h and hp adaptive refinement using established benchmarks for convection-dominated transport."}
{"id": "2602.13513", "categories": ["math.OC", "cs.CE", "cs.LG", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.13513", "abs": "https://arxiv.org/abs/2602.13513", "authors": ["Grant Norman", "Conor Rowan", "Kurt Maute", "Alireza Doostan"], "title": "Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization", "comment": "44 pages, 13 figures. To be submitted to CMAME", "summary": "In this work, we investigate the use of data-driven equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization. The discovered gradient flows are then solved as a surrogate for the original optimization problem. To this end, we introduce the Learned Gradient Flow (LGF) optimizer, which is equipped to build surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals in the optimization process. We demonstrate the efficacy of this approach on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Our results suggest that the learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations of the objective and its gradient."}
{"id": "2602.13333", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.13333", "abs": "https://arxiv.org/abs/2602.13333", "authors": ["Despoina Antonakaki", "Sotiris Ioannidis"], "title": "Coordinated Information Dissemination on Telegram and Reddit During Political Turbulence: A Case Study of Venezuela in Global News Channels", "comment": null, "summary": "Telegram is increasingly used for political communication and news dissemination, yet evidence of coordinated content sharing remains limited. We test whether mainstream global news channels coordinate when reporting on Venezuela during political turbulence. We analyze public Telegram posts from nine major international outlets (2017--2026; 2,038 Venezuela-related messages) and define coordination as temporal co-posting (hourly/daily windows) plus near-duplicate text similarity using character $n$-gram TF--IDF cosine similarity.\n  Similarity scores concentrate at low values and no cross-channel near-duplicate pairs are detected at $τ=0.85$. A falsification test that randomizes timestamps within channels produces the same null result, indicating the pipeline does not create spurious coordination. Event-focused diagnostics show temporal lead--lag asymmetries consistent with heterogeneous editorial responsiveness, and narrative clustering during the January 3--6, 2026 peak reveals moderate framing diversity without separable narrative blocs. An Attention--Coordination Ratio formalizes sharp attention spikes in early January 2026 despite absent near-duplicate coordination, distinguishing synchronized attention from coordinated text reuse.\n  We also collect an auxiliary Reddit dataset to contextualize public attention; however, cross-community coordination is not estimable due to structural sparsity (no comparable multi-subreddit daily buckets). Overall, even under major geopolitical shocks, mainstream Telegram news coverage is heterogeneous rather than near-duplicate coordinated."}
{"id": "2602.13475", "categories": ["stat.ME", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.13475", "abs": "https://arxiv.org/abs/2602.13475", "authors": ["Xiang Meng", "Lu Tian", "Kenneth Kehl", "Hajime Uno"], "title": "Efficient and Debiased Learning of Average Hazard Under Non-Proportional Hazards", "comment": "Main paper: 24 pages and 2 figures; Reference and Supplement: 22 pages and 8 Figures", "summary": "The hazard ratio from the Cox proportional hazards model is a ubiquitous summary of treatment effect. However, when hazards are non-proportional, the hazard ratio can lose a stable causal interpretation and become study-dependent because it effectively averages time-varying effects with weights determined by follow-up and censoring. We consider the average hazard (AH) as an alternative causal estimand: a population-level person-time event rate that remains well-defined and interpretable without assuming proportional hazards. Although AH can be estimated nonparametrically and regression-style adjustments have been proposed, existing approaches do not provide a general framework for flexible, high-dimensional nuisance estimation with valid sqrt{n} inference. We address this gap by developing a semiparametric, doubly robust framework for covariate-adjusted AH. We establish pathwise differentiability of AH in the nonparametric model, derive its efficient influence function, and construct cross-fitted, debiased estimators that leverage machine learning for nuisance estimation while retaining asymptotically normal, sqrt{n}-consistent inference under mild product-rate conditions. Simulations demonstrate that the proposed estimator achieves small bias and near-nominal confidence-interval coverage across proportional and non-proportional hazards settings, including crossing-hazards regimes where Cox-based summaries can be unstable. We illustrate practical utility in comparative effectiveness research by comparing immunotherapy regimens for advanced melanoma using SEER-Medicare linked data."}
{"id": "2602.13957", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.13957", "abs": "https://arxiv.org/abs/2602.13957", "authors": ["Li Xiaojie", "Yin Xunyuan"], "title": "Learning-based data-enabled moving horizon estimation with application to membrane-based biological wastewater treatment process", "comment": null, "summary": "In this paper, we propose a data-enabled moving horizon estimation (MHE) approach for nonlinear systems. While the approach is formulated by leveraging Koopman theory, its implementation does not require explicit Koopman modeling. Lifting functions are learned from the state and input data of the original nonlinear system to project the system trajectories into the lifted space, where the resulting trajectories implicitly describe the Koopman representation for the original nonlinear system. A convex data-enabled MHE formulation is developed to provide real-time state estimates of the Koopman representation, from which the states of the nonlinear system can be reconstructed. Sufficient conditions are derived to ensure the stability of the estimation error. The effectiveness of the proposed method is illustrated using a membrane-based biological water treatment process."}
{"id": "2602.14905", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.14905", "abs": "https://arxiv.org/abs/2602.14905", "authors": ["Gabriel J. Cairns", "Graham P. Benham", "Ian J. Hewitt"], "title": "Groundwater feedbacks on ice sheets and subglacial hydrology", "comment": "25 pages, 8 figures", "summary": "The dynamics of many of Antarctica's glaciers are modulated by a hydrological system at the base of the ice. Sedimentary basins beneath the ice bed contribute to the water budget in this hydrological system by discharging or taking up water. However, sedimentary basins are not included in most current models of ice dynamics, and little is known about their effect. In this paper we develop an idealised model of a glacier whose sliding is coupled to a subglacial hydrological system, which includes a sedimentary basin. We find that groundwater discharge (exfiltration) and recharge (infiltration) are controlled by the shape of the ice sheet and of the sedimentary basin, and that exfiltration promotes sliding whereas infiltration hinders it. Overall, the presence of a sedimentary basin leads to thicker and slower-flowing ice in the steady state. We also find that, when the ice sheet is undergoing retreating, groundwater exfiltration can lead to a positive feedback which accelerates this retreat. Our results shed light on the potential role and importance of Antarctic sedimentary basins, and how these might be incorporated into existing models of ice and subglacial hydrology."}
{"id": "2602.14450", "categories": ["hep-lat", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.14450", "abs": "https://arxiv.org/abs/2602.14450", "authors": ["Issaku Kanamori", "Hideo Matsufuru", "Tatsumi Aoyama", "Kazuyuki Kanaya", "Yusuke Namekawa", "Hidekatsu Nemura", "Keigo Nitadori"], "title": "Mixed precision solvers with half-precision floating point numbers for Lattice QCD on A64FX processor", "comment": "11 pages, 9 figures, contribution to the International Workshop on Arm-based HPC: Practice and Experience 2026 (IWAHPCE2026) at HPC-Asia 2026", "summary": "We investigate the use of half-precision floating-point numbers (FP16) in mixed-precision linear solvers for lattice QCD simulations. Since the emergence of GPUs for general-purpose, mixed-precision algorithms that combine single-precision (FP32) with double-precision (FP64) arithmetics have become widely used in this field and others. While FP32-based methods are now well established, we examine the practicality of using FP16. In this work, we introduce rescaling steps in both the outer iterative refinement step and the inner BiCGStab solver to avoid numerical instability. In our experiments with a simple Wilson kernel, the solver shows improved stability, and the additional iteration count compared to the FP64 version remains within 20\\%, indicating that the FP16 version is practical for use. We believe that the proposed rescaling methods can also benefit other mixed precision preconditioners in avoiding underflows."}
{"id": "2602.13554", "categories": ["cs.ET", "cs.IT", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.13554", "abs": "https://arxiv.org/abs/2602.13554", "authors": ["Pin-Han Ho", "Haoran Mei", "Limei Peng", "Yiming Miao", "Kairan Liang", "Yan Jiao"], "title": "From Snapshot Sensing to Persistent EM World Modeling: A Generative-Space Perspective for ISAC", "comment": "7 pages, 6 figures/tables", "summary": "Electromagnetic (EM) world modeling is emerging as a foundational capability for environment-aware and embodiment-enabled wireless systems. However, most existing mmWave sensing solutions are designed for snapshot-based parameter estimation and rely on hardware-intensive architectures, making scalable and persistent world modeling difficult to achieve. This article rethinks mmWave sensing from a system-level perspective and introduces a generative-space framework, in which sensing is realized through controlled traversal of a low-dimensional excitation space spanning frequency, waveform, and physical embodiment. This perspective decouples spatial observability from rigid antenna arrays and transmit-time multiplexing, enabling flexible and scalable sensing-by-design radios. To illustrate the practicality of this framework, we present a representative realization called Multi-RF Chain Frequency-as-Aperture Clip-on Aperture Fabric (MRC-FaA-CAF), where multiple FMCW sources coordinate frequency-selective modules distributed along guided-wave backbones. This architecture enables interference-free excitation, preserves beat-frequency separability, and maintains low calibration overhead. Case studies show that generative-space-driven sensing can achieve update rates comparable to phased arrays while avoiding dense RF replication and the latency penalties of TDM-MIMO systems. Overall, this work positions generative-space-driven sensing as a practical architectural foundation for mmWave systems that move beyond snapshot sensing toward persistent EM world modeling."}
{"id": "2602.13786", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.13786", "abs": "https://arxiv.org/abs/2602.13786", "authors": ["Mukul Dwivedi", "Andreas Rupp"], "title": "A hybridizable discontinuous Galerkin method for the Ostrovsky equation", "comment": null, "summary": "This paper develops the hybridizable discontinuous Galerkin (HDG) method for the Ostrovsky equation, a nonlinear dispersive wave equation featuring both third-order dispersion and a nonlocal antiderivative term with Coriolis effect. On a bounded interval, the nonlocal operator $\\partial_x^{-1}$ is localized through an auxiliary variable $v$ satisfying $v_x=u$ together with an additional boundary constraint that ensures uniqueness. We employ a mixed first-order formulation to decompose the dispersive operator and to localize the nonlocal term, and we couple the resulting semi-discrete HDG scheme with a $θ$-time stepping method for $θ\\in [1/2,1]$. We prove $L^2$-stability for suitable stabilization parameters and derive an {\\it a priori} $L^2(Ω)$ error estimate for smooth solutions that explicitly accounts for the nonlinear convective flux.\n  Numerical examples illustrate the convergence properties and demonstrate the scheme's capability to handle smooth and non-smooth solutions, including solitary wave propagation and peaked solitary wave (peakon) propagation in the zero dispersive limit regime."}
{"id": "2602.13386", "categories": ["quant-ph", "cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.13386", "abs": "https://arxiv.org/abs/2602.13386", "authors": ["Ainesh Bakshi", "Soonwon Choi", "Saúl Pilatowsky-Cameo"], "title": "Entanglement in quantum spin chains is strictly finite at any temperature", "comment": "32 pages, 1 figure", "summary": "Entanglement is the hallmark of quantum physics, yet its characterization in interacting many-body systems at thermal equilibrium remains one of the most important challenges in quantum statistical physics. We prove that the Gibbs state of any quantum spin chain can be exactly decomposed into a mixture of matrix product states with a bond dimension that is independent of the system size, at any finite temperature. As a consequence, the Schmidt number, arguably the most stringent measure of bipartite entanglement, is strictly finite for thermal states, even in the thermodynamic limit. Our decomposition is explicit and is accompanied by an efficient classical algorithm to sample the resulting matrix product states."}
{"id": "2602.13494", "categories": ["quant-ph", "cs.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.13494", "abs": "https://arxiv.org/abs/2602.13494", "authors": ["Brandon Augustino", "Dylan Herman", "Guneykan Ozgul", "Jacob Watkins", "Atithi Acharya", "Enrico Fontana", "Junhyung Lyle Kim", "Shouvanik Chakrabarti"], "title": "Quantum Speedups for Group Relaxations of Integer Linear Programs", "comment": null, "summary": "Integer Linear Programs (ILPs) are a flexible and ubiquitous model for discrete optimization problems. Solving ILPs is \\textsf{NP-Hard} yet of great practical importance. Super-quadratic quantum speedups for ILPs have been difficult to obtain because classical algorithms for many-constraint ILPs are global and exhaustive, whereas quantum frameworks that offer super-quadratic speedup exploit local structure of the objective and feasible set. We address this via quantum algorithms for Gomory's group relaxation. The group relaxation of an ILP is obtained by dropping nonnegativity on variables that are positive in the optimal solution of the linear programming (LP) relaxation, while retaining integrality of the decision variables. We present a competitive feasibility-preserving classical local-search algorithm for the group relaxation, and a corresponding quantum algorithm that, under reasonable technical conditions, achieves a super-quadratic speedup. When the group relaxation satisfies a nondegeneracy condition analogous to, but stronger than, LP non-degeneracy, our approach yields the optimal solution to the original ILP. Otherwise, the group relaxation tightens bounds on the optimal objective value of the ILP, and can improve downstream branch-and-cut by reducing the integrality gap; we numerically observe this on several practically relevant ILPs. To achieve these results, we derive efficiently constructible constraint-preserving mixers for the group relaxation with favorable spectral properties, which are of independent interest."}
{"id": "2602.13803", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.13803", "abs": "https://arxiv.org/abs/2602.13803", "authors": ["Wei-Zhu Yi", "Yun Chen", "Jun-Jun Pang", "Hong Chen", "Baigeng Wang", "Rui Wang"], "title": "Non-Hermiticity Induced Universal Anomalies in Kondo Conductance", "comment": null, "summary": "Strong correlation, when combined with dissipation in open systems, can lead to a variety of exotic quantum phenomena. Here, we study nontrivial interplays between non-Fermi liquid behaviors emerging from strong correlation and non-Hermiticity arising from open systems. We propose a practical physical setup that realizes a non-Hermitian multichannel Kondo model. We identify a weak-coupling local moment fixed point and a strong-coupling non-Fermi liquid fixed point under PT symmetry, both are enriched by the non-Hermitian effect. Remarkably, universal unconventional Kondo conductance behaviors are found for both cases, which are distinct from all previously studied Kondo systems. Particularly, we show that an anomalous upturn of conductance could take place with increasing the temperature, originating from the interplay between non-Fermi liquid and non-Hermiticity. Our results identify a novel class of transport phenomena unrecognized before, driven by intertwined effects of correlation and dissipation."}
{"id": "2602.14698", "categories": ["quant-ph", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.14698", "abs": "https://arxiv.org/abs/2602.14698", "authors": ["Stefano Longhi"], "title": "Erratic Liouvillian Skin Localization and Subdiffusive Transport", "comment": "16 pages, 9 figures, submitted to Quantum Science and Technology for the Focus Issue on \"Non-Hermitian Quantum Many-Body Physics\"", "summary": "Non-Hermitian systems with globally reciprocal couplings -- such as the Hatano-Nelson model with stochastic imaginary gauge fields -- avoid the conventional non-Hermitian skin effect, displaying erratic bulk localization while retaining ballistic transport. An open question is whether similar behavior arises when non-reciprocity originates at the Liouvillian level rather than from an effective non-Hermitian Hamiltonian obtained via post-selection. Here we investigate this scenario in a lattice model with globally reciprocal Liouvillian dynamics and locally asymmetric incoherent hopping, a disordered setting in which Liouvillian-specific effects have remained largely unexplored. While the steady state again shows disorder-dependent, erratic localization without boundary accumulation, we find that global reciprocity in the Liouvillian does not protect transport. Instead, in the regime dominated by incoherent hopping, excitations spread via Sinai-type subdiffusion, dramatically slower than the ordinary diffusion found in symmetric stochastic lattices. Our results reveal a fundamental distinction between globally reciprocal Hamiltonian and Liouvillian dynamics: global reciprocity suppresses the skin effect in both cases, but only in Liouvillian dynamics can it coexist with ultra-slow, disorder-induced subdiffusive transport."}
{"id": "2602.14436", "categories": ["eess.SY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.14436", "abs": "https://arxiv.org/abs/2602.14436", "authors": ["Jaehan Im", "David Fridovich-Keil", "Ufuk Topcu"], "title": "Noncooperative Virtual Queue Coordination via Uncertainty-Aware Correlated Equilibria", "comment": null, "summary": "Collaborative virtual queueing has been proposed as a mechanism to mitigate airport surface congestion while preserving airline autonomy over aircraft-level pushback decisions. A central coordinator can regulate aggregate pushback capacity but cannot directly control which specific aircraft are released, limiting its ability to steer system-level performance. We propose a noncooperative coordination mechanism for collaborative virtual queueing based on the correlated equilibrium concept, which enables the coordinator to provide incentive-compatible recommendations on aircraft-level pushback decisions without overriding airline autonomy. To account for uncertainty in airlines' internal cost assessments, we introduce chance constraints into the correlated equilibrium formulation. This formulation provides explicit probabilistic guarantees on incentive compatibility, allowing the coordinator to adjust the confidence level with which airlines are expected to follow the recommended actions. We further propose a scalable algorithm for computing chance-constrained correlated equilibria by exploiting a reduced-rank structure. Numerical experiments demonstrate that the proposed method scales to realistic traffic levels up to 210 eligible pushbacks per hour, reduces accumulated delay by up to approximately 8.9% compared to current first-come-first-served schemes, and reveals a trade-off between confidence level, deviation robustness, and achievable cost efficiency."}
{"id": "2602.14206", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.14206", "abs": "https://arxiv.org/abs/2602.14206", "authors": ["Mona Azadkia", "Holger Dette"], "title": "Kernel Estimation Of Chatterjee's Dependence Coefficient", "comment": null, "summary": "Dette, Siburg, and Stoimenov (2013) introduced a copula-based measure of dependence, which implies independence if it vanishes and is equal to 1 if one variable is a measurable function of the other. For continuous distributions, the dependence measure also appears as stochastic limit of Chatterjee's rank correlation (Chatterjee, 2021). They proved asymptotic normality of a corresponding kernel estimator with a parametric rate of convergence. In recent work Shi, Drton, and Han (2022) revealed empirically and theoretically that under independence the asymptotic variance degenerates. In this note, we derive the correct asymptotic distribution of the kernel estimator under the null hypothesis of independence. We show that after a suitable centering and rescaling at a rate larger than $\\sqrt{n}$ (where $n$ is the sample size), the estimator is asymptotically normal. The analysis relies on a refined central limit theorem for double-indexed linear permutation statistics and accounts for boundary effects that are asymptotically non-negligible. As a consequence, we obtain a valid basis for independence testing without relying on permutations and argue that tests based on the kernel estimator detect local alternatives converging to the null at a faster rate than those detectable by Chatterjee's rank correlation."}
{"id": "2602.14654", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.14654", "abs": "https://arxiv.org/abs/2602.14654", "authors": ["Marco Patriarca"], "title": "Boundary conditions for the Schrödinger equation in the numerical simulation of quantum systems", "comment": "7 pages, 4 figures", "summary": "We study the problem of the boundary conditions in the numerical simulation of closed and open quantum systems, described by a Schrödinger equation. On one hand, we show that a closed quantum system is defined by local boundary conditions. On the other hand, we argue that, because of the uncertainty principle, no local boundary condition can be defined for open quantum systems. For this reason plane waves or wave packet trains cannot be simulated on a finite numerical lattice with the usual procedures. We suggest a method that avoids these difficulties by using only a small numerical lattice and maintains the correspondence with the physical picture, in which the incident and scattered waves may be infinitely extended."}
{"id": "2602.13458", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13458", "abs": "https://arxiv.org/abs/2602.13458", "authors": ["Yi Feng", "Chen Huang", "Zhibo Man", "Ryner Tan", "Long P. Hoang", "Shaoyang Xu", "Wenxuan Zhang"], "title": "MoltNet: Understanding Social Behavior of AI Agents in the Agent-Native MoltBook", "comment": null, "summary": "Large-scale communities of AI agents are becoming increasingly prevalent, creating new environments for agent-agent social interaction. Prior work has examined multi-agent behavior primarily in controlled or small-scale settings, limiting our understanding of emergent social dynamics at scale. The recent emergence of MoltBook, a social networking platform designed explicitly for AI agents, presents a unique opportunity to study whether and how these interactions reproduce core human social mechanisms.\n  We present MoltNet, a large-scale empirical analysis of agent interaction on MoltBook using data collected in early 2026. Grounded in sociological and social-psychological theory, we examine behavior along four dimensions: intent and motivation, norms and templates, incentives and behavioral drift, emotion and contagion.\n  Our analysis revealed that agents strongly respond to social rewards and rapidly converge on community-specific interaction templates, resembling human patterns of incentive sensitivity and normative conformity. However, they are predominantly knowledge-driven rather than persona-aligned, and display limited emotional reciprocity along with weak dialogic engagement, which diverges systematically from human online communities.\n  Together, these results reveal both similarities and differences between artificial and human social systems and provide an empirical foundation for understanding, designing, and governing large-scale agent communities."}
{"id": "2602.13518", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.13518", "abs": "https://arxiv.org/abs/2602.13518", "authors": ["Nils Lid Hjort"], "title": "Towards Semiparametric Bandwidth Selectors for Kernel Density Estimators", "comment": "26 pages, no figures; technical report from 1999, needing additional numerical work to become a full paper", "summary": "There is an intense and partly recent literature focussing on the problem of selecting the bandwidth parameter for kernel density estimators. Available methods are largely `very nonparametric', in the sense of not requiring any knowledge about the underlying density, or `very parametric', like the normality-based reference rule. This report aims at widening the scope towards the inclusion of many semiparametric bandwidth selectors, via Hermite type expansions aroundthe normal distribution. The resulting bandwidths may be seen as carrying out suitable corrections on the normal reference rule, requiring a low number of extra coefficients to be estimated from data.\n  The present report introduces and discusses some basic ideas and develops the necessary initial theory, but modestly chooses to stop short of giving precise recommendations for specific procedures among the many possible constructions. This will require some further analysis, numerical work, and some simulation-based exploration."}
{"id": "2602.14092", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.14092", "abs": "https://arxiv.org/abs/2602.14092", "authors": ["Jan-Hendrik Ewering", "Max Bartholdt", "Simon F. G. Ehlers", "Niklas Wahlström", "Thomas B. Schön", "Thomas Seel"], "title": "Simultaneous State Estimation and Online Model Learning in a Soft Robotic System", "comment": "8 pages, 3 figures, 2 tables", "summary": "Operating complex real-world systems, such as soft robots, can benefit from precise predictive control schemes that require accurate state and model knowledge. This knowledge is typically not available in practical settings and must be inferred from noisy measurements. In particular, it is challenging to simultaneously estimate unknown states and learn a model online from sequentially arriving measurements. In this paper, we show how a recently proposed gray-box system identification tool enables the estimation of a soft robot's current pose while at the same time learning a bending stiffness model. For estimation and learning, we rely solely on a nominal constant-curvature robot model and measurements of the robot's base reactions (e.g., base forces). The estimation scheme -- relying on a marginalized particle filter -- allows us to conveniently interface nominal constant-curvature equations with a Gaussian Process (GP) bending stiffness model to be learned. This, in contrast to estimation via a random walk over stiffness values, enables prediction of bending stiffness and improves overall model quality. We demonstrate, using real-world soft-robot data, that the method learns a bending stiffness model online while accurately estimating the robot's pose. Notably, reduced multi-step forward-prediction errors indicate that the learned bending-stiffness GP improves overall model quality."}
{"id": "2602.14454", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2602.14454", "abs": "https://arxiv.org/abs/2602.14454", "authors": ["Wei-Lun Chen", "Issaku Kanamori", "Hideo Matsufuru", "Hartmut Neff"], "title": "Accelerating iterative linear equation solver using modified domain-wall fermion matrix in lattice QCD simulations", "comment": "15 pages. This is an author's version of the submitted manuscript and has not undergone peer review. The Version of Record of this contribution is published in Gervasi, O., et al. Computational Science and Its Applications -- ICCSA 2025 Workshops. Lecture Notes in Computer Science, vol 15890. Springer, Cham", "summary": "Lattice simulations of Quantum Chromodynamics (QCD) enable one to calculate the low-energy properties of the strong interaction among quarks and gluons based on the first principle. The most time-consuming part of the numerical simulations of lattice QCD is typically solving a linear equation for the quark matrix. In particular, a discretized quark formulation called the domain-wall fermion operator requires a high numerical cost, while retaining the lattice version of the chiral symmetry to good precision. The domain-wall operator is defined on a five-dimensional (5D) space extending the four-dimensional (4D) spacetime with an extra fifth coordinate. After solving the linear equation in 5D space, the result vector is projected onto the original 4D space. There is a variant of the domain-wall operator that improves the convergence of the 5D linear equation while unchanging the 4D solution vector. In this paper, we examine how this variant of the domain-wall operator accelerates the iterative linear equation solver in practical setups. We also measure the eigenvalues of the operator and compare the condition number with the convergence of the solver. We use a generic lattice QCD code set Bridge++ that is planned to be released including the improved form of the domain-wall operator examined in this work with code for the GPU."}
{"id": "2602.13943", "categories": ["cs.ET", "cs.AR"], "pdf": "https://arxiv.org/pdf/2602.13943", "abs": "https://arxiv.org/abs/2602.13943", "authors": ["Ziyad Alsawidan", "Abdelrahman S. Abdelrahman", "Md Sakibur Sajal", "Shuvro Chowdhury", "Kai-Chun Lin", "Hunter Guthrie", "Sanjay Seshan", "Shawn Blanton", "Flaviano Morone", "Marc Dandin", "Kerem Y. Camsari", "Tathagata Srimani"], "title": "Probabilistic approximate optimization using single-photon avalanche diode arrays", "comment": null, "summary": "Combinatorial optimization problems are central to science and engineering and specialized hardware from quantum annealers to classical Ising machines are being actively developed to address them. These systems typically sample from a fixed energy landscape defined by the problem Hamiltonian encoding the discrete optimization problem. The recently introduced Probabilistic Approximate Optimization Algorithm (PAOA) takes a different approach: it treats the optimization landscape itself as variational, iteratively learning circuit parameters from samples. Here, we demonstrate PAOA on a 64$\\times$64 perimeter-gated single-photon avalanche diode (pgSPAD) array fabricated in 0.35 $μ$m CMOS, the first realization of the algorithm using intrinsically stochastic nanodevices. Each p-bit exhibits a device-specific, asymmetric (Gompertz-type) activation function due to dark-count variability. Rather than calibrating devices to enforce a uniform symmetric (logistic/tanh) activation, PAOA learns around device variations, absorbing residual activation and other mismatches into the variational parameters. On canonical 26-spin Sherrington-Kirkpatrick instances, PAOA achieves high approximation ratios with $2p$ parameters ($p$ up to 17 layers), and pgSPAD-based inference closely tracks CPU simulations. These results show that variational learning can accommodate the non-idealities inherent to nanoscale devices, suggesting a practical path toward larger-scale, CMOS-compatible probabilistic computers."}
{"id": "2602.13841", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.13841", "abs": "https://arxiv.org/abs/2602.13841", "authors": ["Nils Margenberg", "Markus Bause"], "title": "A Monolithic hp Space-Time Multigrid Preconditioned Newton-Krylov Solver for Space-Time FEM applied to the Incompressible Navier-Stokes Equations", "comment": "26 pages, 3 figures, 5 tables", "summary": "We present a monolithic hp space-time multigrid method (hp-STMG) for tensor-product space-time finite element discretizations of the incompressible Navier-Stokes equations. We employ mapped inf-sup stable pairs $\\mathbb Q_{r+1}/\\mathbb P_{r}^{\\mathrm{disc}}$ in space and a slabwise discontinuous Galerkin DG($k$) discretization in time. The resulting fully coupled nonlinear systems are solved by Newton-GMRES preconditioned with hp-STMG, combining geometric coarsening in space with polynomial coarsening in space and time. Our main contribution is an hp-robust and practically efficient extension of space-time multigrid to Navier-Stokes: matrix-free operator evaluation is retained via column-wise, state-dependent spatial kernels; the nonlinear convective term is handled by a reduced, order-preserving time quadrature. Robustness is ensured by an inexact space-time Vanka smoother based on patch models with single time point evaluation. The method is implemented in the matrix-free multigrid framework of deal.II and demonstrates h- and p-robust convergence with robust solver performance across a range of Reynolds numbers, as well as high throughput in large-scale MPI-parallel experiments."}
{"id": "2602.13632", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.13632", "abs": "https://arxiv.org/abs/2602.13632", "authors": ["Hongchao Li", "Xie-Hang Yu", "Masaya Nakagawa", "Masahito Ueda"], "title": "Ward-Takahashi Identity and Gauge-Invariant Response Theory for Open Quantum Systems", "comment": "5 pages, 1 figure + 12 pages", "summary": "We derive the Ward-Takahashi identity and establish the gauge-invariant response theory for open quantum systems described by Lindbladians to show that particle-number conservation is not necessary to satisfy gauge invariance. We construct an observable which can be used to test the gauge invariance in the absence of particle-number conservation. We derive the low-energy collective modes that emerge as a consequence of gauge invariance in open quantum systems, and find that two-body loss induces diffusive modes in dissipative Bardeen-Cooper-Schrieffer (BCS) superconductivity. Possible experimental situations for testing gauge invariance in open quantum systems are also discussed."}
{"id": "2602.13545", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13545", "abs": "https://arxiv.org/abs/2602.13545", "authors": ["Qiqi Feng", "Huaqi Zhou", "Limin Gao"], "title": "Efficient discrimination schemes for unextendible product bases with strong quantum nonlocality", "comment": null, "summary": "Entanglement is a central resource in quantum information science; therefore, it is important to design local discrimination protocols that minimize resource consumption. In this paper, we propose three entanglement-allocation schemes for the local discrimination of particular unextendible product bases (UPB) exhibiting strong quantum nonlocality in a \\(3 \\otimes 3 \\otimes 3\\) system. By exploiting the structural features of these UPB and the operational advantages of maximally entangled states, we further extend our protocols to strongly nonlocal UPB in \\(d \\otimes d \\otimes d\\) systems. In particular, we show that these UPB can be perfectly distinguished with only two maximally entangled states. Moreover, a resource-cost analysis indicates that our protocols, which avoid quantum teleportation whenever possible, can reduce the entanglement consumption. These results not only facilitate resource-efficient quantum information processing, but also provide further insight into the operational role of maximally entangled states."}
{"id": "2602.14133", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.14133", "abs": "https://arxiv.org/abs/2602.14133", "authors": ["Shivalika Sharma", "Julio do Nascimento", "Imran Ahamed", "Fabrizio Cossu", "Heung-Sik Kim", "Igor Di Marco"], "title": "Exchange interactions and finite-temperature magnetism in (111)-oriented (LaMnO$_3$)$_{2n}$|(SrMnO$_3$)$_n$ superlattices", "comment": null, "summary": "We present a first-principles investigation of magnetic exchange interactions and critical behavior in (111)-oriented (LaMnO$_3$)$_{2n}$|(SrMnO$_3$)$_n$ superlattices for $n=2,4,6$. For all superlattices under investigation, we find robust half-metallic ferromagnetism extending across all the layers of both component regions. Changing octahedral tilt patterns is found to have negligible effects on the magnetic properties, despite determining the presence or absence of small Jahn-Teller distortions. The analysis of the response of the magnetic coupling to a variation of the Coulomb interaction parameters demonstrates that ferromagnetism is driven by a double-exchange mechanism involving itinerant $e_g$ electrons, while its final strength is hampered by antiferromagnetic contributions due to the superexchange of localized $t_{2g}$ electrons. Multi-scale simulations based on atomistic spin dynamics show that the thinnest superlattices, $n=2,4$, possess an ordering temperature that is at least comparable to that of La$_{2/3}$Sr$_{1/3}$MnO$_3$. Conversely, as thickness increases, a two-phase behavior emerges, where the SrMnO$_3$ region loses long-range order faster than the LaMnO$_3$ region. While the global ordering temperature increases together with thickness, we argue that the high-temperature regime for the observed two-phase behavior is not representative of the real physical system, which will undergo a combined electronic, magnetic and structural phase transition as soon as the long-range order is lost inside the SrMnO$_3$ region. This study provides insights into the emergent magnetic phases and transition temperatures relevant to oxide heterostructures."}
{"id": "2602.14660", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14660", "abs": "https://arxiv.org/abs/2602.14660", "authors": ["Fan Zhang", "Deyuan Meng", "Ying Tan"], "title": "Segment-Based Two-Loop Adaptive Iterative Learning Control for Spacecraft Position and Attitude Tracking", "comment": "13 pages", "summary": "Proximity operations of rigid bodies, such as spacecraft rendezvous and docking, require precise tracking of both position and attitude over finite time intervals. These operations are often repeated under uncertain conditions, with unknown but repeatable parameters and disturbances. Adaptive iterative learning control (ILC) is well suited to such tasks, as it can track desired trajectories while learning unknown, iteration-invariant signals or parameters. However, conventional adaptive ILC faces two challenges: (i) the coupling between rotational and translational dynamics complicates the design of the two coordinated learning loops for position and attitude, and (ii) standard adaptive ILC designs cannot guarantee bounded control inputs. To address these issues, we propose a dual-number-based, segment-based two-loop adaptive ILC framework for simultaneous high-precision position and attitude tracking. The framework employs two learning loops that interact through a dual-number representation of tracking errors, combining position and attitude errors into a single mathematical object for unified control design. A segment-based dynamic projection mechanism ensures that both parameter estimates and control inputs remain bounded without prior knowledge of uncertainties. Mathematical analysis and numerical simulations demonstrate that the proposed framework significantly enhances tracking performance under unknown but repeatable uncertainties and strong rotational-translational coupling."}
{"id": "2602.14342", "categories": ["math.ST", "cs.DS", "cs.LG", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.14342", "abs": "https://arxiv.org/abs/2602.14342", "authors": ["Fan Chen", "Sinho Chewi", "Constantinos Daskalakis", "Alexander Rakhlin"], "title": "High-accuracy log-concave sampling with stochastic queries", "comment": null, "summary": "We show that high-accuracy guarantees for log-concave sampling -- that is, iteration and query complexities which scale as $\\mathrm{poly}\\log(1/δ)$, where $δ$ is the desired target accuracy -- are achievable using stochastic gradients with subexponential tails. Notably, this exhibits a separation with the problem of convex optimization, where stochasticity (even additive Gaussian noise) in the gradient oracle incurs $\\mathrm{poly}(1/δ)$ queries. We also give an information-theoretic argument that light-tailed stochastic gradients are necessary for high accuracy: for example, in the bounded variance case, we show that the minimax-optimal query complexity scales as $Θ(1/δ)$. Our framework also provides similar high accuracy guarantees under stochastic zeroth order (value) queries."}
{"id": "2602.14854", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.14854", "abs": "https://arxiv.org/abs/2602.14854", "authors": ["Stefan Brunner", "Lukas Einkemmer", "Terry Haut"], "title": "Domain decomposition dynamical low-rank for multi-dimensional radiative transfer equations", "comment": null, "summary": "In this paper, we propose a domain decomposition dynamical low-rank method to solve high-dimensional radiative transfer problems and similar kinetic equations. The algorithm uses a separate low-rank approximation on each spatial subdomain, which means that, for a given accuracy, we can often use a smaller overall rank compared to classic dynamical low-rank methods. In particular, we can solve problems with point sources efficiently, that for classic algorithms require almost full rank. Our algorithm only transfers boundary data between subdomains and is thus very attractive for distributed memory parallelization, where classic dynamical low-rank algorithms suffer from global data dependency. We demonstrate the efficiency of our algorithm by a number of challenging test examples that have both very optical thin and thick regions."}
{"id": "2602.13920", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13920", "abs": "https://arxiv.org/abs/2602.13920", "authors": ["Yiming Zhu", "Gareth Tyson", "Pan Hui"], "title": "A Comparative Analysis of Social Network Topology in Reddit and Moltbook", "comment": null, "summary": "Recent advances in agent-mediated systems have enabled a new paradigm of social network simulation, where AI agents interact with human-like autonomy. This evolution has fostered the emergence of agent-driven social networks such as Moltbook, a Reddit-like platform populated entirely by AI agents. Despite these developments, empirical comparisons between agent-driven and human-driven social networks remain scarce, limiting our understanding of how their network topologies might diverge. This paper presents the first comparative analysis of network topology on Moltbook, utilizing a comment network comprising 33,577 nodes and 697,688 edges. To provide a benchmark, we curated a parallel dataset from Reddit consisting of 7.8 million nodes and 51.8 million edges. We examine key structural differences between agent-drive and human-drive networks, specifically focusing on topological patterns and the edge formation efficacy of their respective posts. Our findings provide a foundational profile of AI-driven social structures, serving as a preliminary step toward developing more robust and authentic agent-mediated social systems."}
{"id": "2602.13533", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.13533", "abs": "https://arxiv.org/abs/2602.13533", "authors": ["Yi Liu", "Huiman Barnhart", "Sean O'Brien", "Yuliya Lokhnygina", "Roland A. Matsouaka"], "title": "Estimation and Inference of the Win Ratio for Two Hierarchical Endpoints Subject to Censoring and Missing Data", "comment": null, "summary": "The win ratio (WR) is a widely used metric to compare treatments in randomized clinical trials with hierarchically ordered endpoints. Counting-based approaches, such as Pocock's algorithm, are the standard for WR estimation. However, this algorithm treats participants with censored or missing data inadequately, which may lead to biased and inefficient estimates, particularly in the presence of heterogeneous censoring or missing data between treatment groups. Although recent extensions have addressed some of these limitations for hierarchical time-to-event endpoints, no existing methods -- aside from the computationally intensive multiple imputation approach -- can accommodate settings that include non-survival endpoints that are subject to missing data. In this paper, we propose a simple nonparametric maximum likelihood estimator (NPMLE) of WR for two hierarchical endpoints that are subject to censoring and missing data. Our method uses all observed data, avoids strong parametric assumptions, and comes with a closed-form asymptotic variance estimator. We demonstrate its performance using simulation studies and two data examples, based on the HEART-FID and ISCHEMIA trials. The proposed method provides a consistent estimator, improves estimation efficiency, and is robust under non-informative censoring and missing at random (MAR) assumptions, offering a flexible alternative to existing WR estimation methods. A user-friendly R package, WinRS, is available to facilitate implementation."}
{"id": "2602.14339", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14339", "abs": "https://arxiv.org/abs/2602.14339", "authors": ["Jean Zhu", "Shuang Gao"], "title": "Data-Driven Network LQG Mean Field Games with Heterogeneous Populations via Integral Reinforcement Learning", "comment": "8 pages", "summary": "This paper establishes a data-driven solution for infinite horizon linear quadratic Gaussian Mean Field Games with network-coupled heterogeneous agent populations where the dynamics of the agents are unknown. The solution technique relies on Integral Reinforcement Learning and Kleinman's iteration for solving algebraic Riccati equations (ARE). The resulting algorithm uses trajectory data to generate network-coupled MFG strategies for agents and does not require parameters of agents' dynamics. Under technical conditions on the persistency of excitation and on the existence of unique stabilizing solution to the corresponding AREs, the learned network-coupled MFG strategies are shown to converge to their true values."}
{"id": "2602.14811", "categories": ["hep-lat", "hep-ph"], "pdf": "https://arxiv.org/pdf/2602.14811", "abs": "https://arxiv.org/abs/2602.14811", "authors": ["Ting-Wai Chiu", "Tung-Han Hsieh"], "title": "RG-Invariant Symmetry Ratio for QCD: A Study of $U(1)_A$ and Chiral Symmetry Restoration", "comment": "36 pages, 4 figures", "summary": "We introduce a renormalization-group invariant observable, the symmetry strength parameter $κ_{AB}$, for the quantitative characterization of symmetry breaking in QCD. As a first application, we employ $κ_{AB}$ to investigate the relative strength of $SU(2)_L \\times SU(2)_R$ chiral symmetry and $U(1)_A$ axial symmetry breaking in $N_f=2+1+1$ lattice QCD using optimal domain-wall fermions at the physical point. Our study covers three lattice spacings and twelve temperatures in the range 164-385~MeV. We examine three independent symmetry-breaking channels in the nonsinglet sector with connected correlators: the $U(1)_A$-sensitive scalar-pseudoscalar channel ($κ_{PS}$), probing the $π$-$δ$ system; the $SU(2)_L \\times SU(2)_R$-sensitive vector--axial-vector channel ($κ_{VA}$), probing the $ρ$-$a_1$ system; and an additional $U(1)_A$-sensitive tensor--axial-tensor channel ($κ_{TX}$), probing the $ρ$-$b_1$ system. At finite lattice spacing, we observe a clear hierarchy $κ_{PS} > κ_{TX} \\sim κ_{VA}$. A controlled continuum extrapolation reveals that this hierarchy collapses, with all three symmetry-breaking strengths becoming statistically indistinguishable within our precision. This result provides a new, model-independent benchmark from a chirally symmetric lattice action. Our findings indicate that the effective restoration scales for $SU(2)_L \\times SU(2)_R$ and $U(1)_A$ in the nonsinglet sector converge closely near the chiral crossover, placing stringent quantitative constraints on the temperature window for chiral and axial symmetry manifestation in connected channels. These results support a two-stage restoration scenario, in which full symmetry restoration -- including the singlet sector -- occurs only at significantly higher temperatures once topological fluctuations are suppressed."}
{"id": "2602.14256", "categories": ["cs.ET", "cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.14256", "abs": "https://arxiv.org/abs/2602.14256", "authors": ["Xiaoran Liu", "Istvan David"], "title": "Introduction to Digital Twins for the Smart Grid", "comment": null, "summary": "This chapter provides an introduction to the foundations of digital twins and makes the case for employing them in smart grids. As engineered systems become more complex and autonomous, digital twin technology gains importance as the unified technological platform for design, testing, operation, and maintenance. Smart grids are prime examples of such complex systems, in which unique design and operation challenges arise from the combination of physical and software components. As high-fidelity in-silico replicas of physical components, digital twins provide safe and cost-efficient experimentation facilities in the design and verification phase of smart grids. In the operation phase of smart grids, digital twins enable automated load balancing of grids through real-time simulation and decision-making. These, and an array of similar benefits, position digital twins as crucial technological components in smart grids."}
{"id": "2602.13843", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.13843", "abs": "https://arxiv.org/abs/2602.13843", "authors": ["Nils Margenberg", "Marius Paul Bruchhäuser", "Bernhard Endtmayer"], "title": "Anisotropic hp space-time adaptivity and goal-oriented error control for convection-dominated problems", "comment": "38 pages, 13 figures, 4 tables", "summary": "We present an anisotropic goal-oriented error estimator based on the Dual Weighted Residual (DWR) method for time-dependent convection-dominated problems. Using elementwise p-anisotropic finite element spaces, the estimator is elementwise separated with respect to the single directions in space and time. This naturally leads to adaptive, anisotropic hp-refinement (h-anisotropic refinement and elementwise anisotropic p-enrichment). We employ discontinuous elements in space and time, which are well suited for problems with high Peclet numbers. Efficiency and robustness of the underlying algorithm are demonstrated for different goal functionals. The directional error indicators quantify anisotropy of the solution with respect to the goal, and produce hp-refinements that efficiently capture sharp layers. Numerical examples in up to three spatial dimensions demonstrate the superior performance of the proposed method compared to isotropic h and hp adaptive refinement using established benchmarks for convection-dominated transport."}
{"id": "2602.13208", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.13208", "abs": "https://arxiv.org/abs/2602.13208", "authors": ["Mine Yurtoğlu", "Dilara Yapışkan", "Ebenezer Bonyah", "Beyza Billur İskender Eroğlu", "Derya Avcı", "Delfim F. M. Torres"], "title": "Dynamic Analysis and Optimal Prevention Strategies for Monkeypox Spread Modeled via the Mittag--Leffler Kernel", "comment": "This is a preprint of a paper published in 'Fractal Fract.' at [https://doi.org/10.3390/fractalfract10010044]", "summary": "Monkeypox is a viral disease belonging to the smallpox family. Although it has milder symptoms than smallpox in humans, it has become a global threat in recent years, especially in African countries. Initially, incidental immunity against monkeypox was provided by smallpox vaccines. However, the eradication of smallpox over time and thus the lack of vaccination has led to the widespread and clinical importance of monkeypox. Although mathematical epidemiology research on the disease is complementary to clinical studies, it has attracted attention in the last few years. The present study aims to discuss the indispensable effects of three control strategies such as vaccination, treatment, and quarantine to prevent the monkeypox epidemic modeled via the Atangana--Baleanu operator. The main purpose is to determine optimal control measures planned to reduce the rates of exposed and infected individuals at the minimum costs. For the controlled model, the existence-uniqueness of the solutions, stability, and sensitivity analysis, and numerical optimal solutions are exhibited. The optimal system is numerically solved using the Adams-type predictor--corrector method. In the numerical simulations, the efficacy of the vaccination, treatment, and quarantine controls is evaluated in separate analyzes as single-, double-, and triple-control strategies. The results demonstrate that the most effective strategy for achieving the aimed outcome is the simultaneous application of vaccination, treatment, and quarantine controls."}
{"id": "2602.13847", "categories": ["nlin.CD", "cond-mat.stat-mech", "cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.13847", "abs": "https://arxiv.org/abs/2602.13847", "authors": ["Fabrizio Falasca", "Laure Zanna"], "title": "Causally constrained reduced-order neural models of complex turbulent dynamical systems", "comment": null, "summary": "We introduce a flexible framework based on response theory and score matching to suppress spurious, noncausal dependencies in reduced-order neural emulators of turbulent systems, focusing on climate dynamics as a proof-of-concept. We showcase the approach using the stochastic Charney-DeVore model as a relevant prototype for low-frequency atmospheric variability. We show that the resulting causal constraints enhance neural emulators' ability to respond to both weak and strong external forcings, despite being trained exclusively on unforced data. The approach is broadly applicable to modeling complex turbulent dynamical systems in reduced spaces and can be readily integrated into general neural network architectures."}
{"id": "2602.13563", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13563", "abs": "https://arxiv.org/abs/2602.13563", "authors": ["Kagan Yanik", "Irwin Huang", "Bibek Bhandari", "Bingcheng Qing", "Ahmed Hajr", "Ke Wang", "David I. Santiago", "Irfan Siddiqi", "Justin Dressel", "Andrew N. Jordan"], "title": "Flux Pumped Kerr-Free Parametric Amplifier", "comment": "17 pages, 10 figures", "summary": "We propose a flux-pumped superconducting parametric amplifier based on symmetrically threaded superconducting quantum interference devices (SQUIDs) that achieves a Kerr-free operating point under suitable drive conditions. Eliminating the Kerr nonlinearity is advantageous for quantum-limited amplification, as it mitigates unwanted distortions in squeezing and prevents degradation of both gain and quantum efficiency in the high-gain strong drive regime. By replacing the central junction in the symmetrically threaded SQUIDs (STS) configuration with a linear inductor, we find that the Kerr-nonlinearity can be eliminated and the effective Hamiltonian reduces to that of a degenerate parametric amplifier (DPA), up to higher-order corrections in the zero-point fluctuations of the superconducting phase operator. We show that the deviations from ideal DPA behavior introduced by these higher-order terms are significantly weaker than those associated with a Kerr nonlinearity. Consequently, the STS design can be driven strongly while maintaining near-quantum-limited performance at the Kerr-free point. Our analysis predicts phase-preserving gain and efficiency approaching the quantum limit, with robust operation demonstrated up to 25 dB of gain."}
{"id": "2602.14173", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.14173", "abs": "https://arxiv.org/abs/2602.14173", "authors": ["David J. Alspaugh", "Lorenzo Fratino", "Nareg Ghazikhanian", "Ivan K. Schuller", "Marcelo Rozenberg"], "title": "Disorder-driven stochastic dynamics in Mott resistive-switching systems", "comment": null, "summary": "Controlled disorder in correlated materials provides a new route to emergent stochastic dynamics in neuromorphic hardware. Here we show that focused ion beam irradiation in VO$_{2}$- and V$_{2}$O$_{3}$-based resistive-switching oscillators induces a transition from regular periodic oscillations to strongly irregular stochastic firing, while simultaneously reducing the required switching energy by orders of magnitude. Under an applied electric field, these materials undergo a volatile insulator-to-metal transition characterized by the formation of percolating metallic filaments within an insulating bulk. Using numerical simulations based on the Mott resistor network, we demonstrate that defect-induced modifications to filament nucleation and stability drive these devices into stochastic oscillatory regimes. These results are validated by experimental measurements on irradiated VO$_{2}$ and V$_{2}$O$_{3}$ devices."}
{"id": "2602.14725", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14725", "abs": "https://arxiv.org/abs/2602.14725", "authors": ["Cornelia Skaga", "Mahdieh S. Sadabadi", "Gilbert Bergna-Diaz"], "title": "DC Microgrids with Nested Nonlinear Distributed Control: Scalable Large-Signal Stability and Voltage Containment", "comment": "12 pages, 8 figures", "summary": "This paper investigates a cyber-physical DC microgrid employing a nonlinear distributed consensus-based control scheme for coordinated integration and management of distributed generating units within an expandable framework. Relying on nested primary andsecondary control loops; a (distributed) outer-loop and a (decentralized) inner-loop, the controller achieves proportional current sharing among all distributed generation units, while dynamically operating within predefined voltage limits. A rigorous Lyapunov-based stability analysis establishes a scalable global exponential stability certificate under some tuning conditions and sufficient time-scale separation between the control loops, based on singular perturbation theory. An optimization-based tuning strategy is then formulated to identify and subsequently diminish unstable operating conditions. In turn, various practical tuning strategies are introduced to provide stable operations while facilitating near-optimal proportional current sharing. The effectiveness of the proposed control framework and tuning approaches are finally supported through time-domain simulations of a case-specific low-voltage DC microgrid."}
{"id": "2602.14472", "categories": ["math.ST", "cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.14472", "abs": "https://arxiv.org/abs/2602.14472", "authors": ["Somjit Roy", "Prateek Jaiswal", "Anirban Bhattacharya", "Debdeep Pati", "Bani K. Mallick"], "title": "Frequentist Regret Analysis of Gaussian Process Thompson Sampling via Fractional Posteriors", "comment": "34 pages, Submitted", "summary": "We study Gaussian Process Thompson Sampling (GP-TS) for sequential decision-making over compact, continuous action spaces and provide a frequentist regret analysis based on fractional Gaussian process posteriors, without relying on domain discretization as in prior work. We show that the variance inflation commonly assumed in existing analyses of GP-TS can be interpreted as Thompson Sampling with respect to a fractional posterior with tempering parameter $α\\in (0,1)$. We derive a kernel-agnostic regret bound expressed in terms of the information gain parameter $γ_t$ and the posterior contraction rate $ε_t$, and identify conditions on the Gaussian process prior under which $ε_t$ can be controlled. As special cases of our general bound, we recover regret of order $\\tilde{\\mathcal{O}}(T^{\\frac{1}{2}})$ for the squared exponential kernel, $\\tilde{\\mathcal{O}}(T^{\\frac{2ν+3d}{2(2ν+d)}} )$ for the Matérn-$ν$ kernel, and a bound of order $\\tilde{\\mathcal{O}}(T^{\\frac{2ν+3d}{2(2ν+d)}})$ for the rational quadratic kernel. Overall, our analysis provides a unified and discretization-free regret framework for GP-TS that applies broadly across kernel classes."}
{"id": "2602.14023", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.14023", "abs": "https://arxiv.org/abs/2602.14023", "authors": ["Satoshi Furutani", "Toshiki Shibahara", "Mitsuaki Akiyama"], "title": "The Impact of Micro-level User Interventions on Macro-level Misinformation Spread", "comment": null, "summary": "User interventions such as nudges, prebunking, and contextualization have been widely studied as countermeasures against misinformation, and shown to suppress individual users' sharing behavior. However, it remains unclear whether and to what extent such individual-level effects translate into reductions in collective misinformation prevalence. In this study, we incorporate user interventions as reductions in users' susceptibility within an empirically calibrated network-based misinformation diffusion model, and systematically evaluate how intervention strength, scale, timing, and target selection affect overall misinformation prevalence through numerical simulations and theoretical analysis. The simulation results show that, while all interventions reduce misinformation prevalence as their strength increases, as misinformation becomes more contagious, achieving a given level of prevalence reduction requires substantially stronger interventions. Furthermore, under empirically estimated intervention levels, even adjusted intervention designs, such as expanded scale, earlier deployment, strategic targeting, or combinations of interventions, yield limited collective effects. This study quantitatively clarifies the gap between micro-level user interventions and macro-level misinformation spread, and demonstrates the limitations of evaluating misinformation countermeasures based solely on individual-level effectiveness."}
{"id": "2602.13538", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.13538", "abs": "https://arxiv.org/abs/2602.13538", "authors": ["Antik Chakraborty", "Fei Xue"], "title": "Empirical Bayes data integreation for multi-response regression", "comment": "To appear in Statistica Sinica", "summary": "Motivated by applications in tissue-wide association studies (TWAS), we develop a flexible and theoretically grounded empirical Bayes approach for integrating %vector-valued outcomes data obtained from different sources. We propose a linear shrinkage estimator that effectively shrinks singular values of a data matrix. This problem is closely connected to estimating covariance matrices under a specific loss, for which we develop asymptotically optimal estimators. The basic linear shrinkage estimator is then extended to a local linear shrinkage estimator, offering greater flexibility. Crucially, the proposed method works under sparse/dense or low-rank/non low-rank parameter settings unlike well-known sparse or reduced rank estimators in the literature. Furthermore, the empirical Bayes approach offers greater scalability in computation compared to intensive full Bayes procedures. The method is evaluated through an extensive set of numerical experiments, and applied to a real TWAS data obtained from the Genotype-Tissue Expression (GTEx) project."}
{"id": "2602.14382", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14382", "abs": "https://arxiv.org/abs/2602.14382", "authors": ["Amit Shivam", "Kiran Kumari", "Fernando A. C. C. Fontes"], "title": "Prescribed-Performance-Aware Hybrid-Gain-Based Robust Controller", "comment": "Under reveiw in VSS 2026", "summary": "This paper proposes a prescribed performance function aware hybrid gain finite time sliding mode control framework for a class of nonlinear systems subject to matched disturbances. The hybrid gain structure ensures bounded control effort while retaining finite time convergence, and the incorporation of PPFs enables explicit enforcement of transient performance requirements. Theoretical guarantees are first established for first order systems, characterizing finite time convergence, disturbance rejection, and residual bounds. The approach is then extended to second order dynamics, where a sliding manifold is designed using PPF constraints to facilitate controlled shaping of position and velocity transients. Simulation studies illustrate the proposed design under matched peak control conditions. Comparative results for second-order systems demonstrate that, while a well tuned non-PPF hybrid gain controller achieves competitive tracking performance, the PPF-aware formulation strictly enforces prescribed transient constraints and yields consistent reductions of approximately 9 to 12 percent in integral error and control energy metrics without increasing peak actuation effort."}
{"id": "2602.14268", "categories": ["math.NA", "math.AP", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.14268", "abs": "https://arxiv.org/abs/2602.14268", "authors": ["L. Banas", "D. Breit", "A. Chaudhary", "A. Prohl"], "title": "A Higher Order Discretization for the Stochastic Navier--Stokes equations with additive Noise", "comment": null, "summary": "We propose a new higher-order time discretization scheme for the stochastic Navier--Stokes equations with additive noise, where its velocity and pressure approximates converge at strong rate $1.5$ in probability. The construction rests on its reformulation as a random PDE for the transform $y = u- ΦW$, and different higher order numerical quadrature rules for the diffusion and the drift part. The theoretical findings are supported by numerical simulations."}
{"id": "2602.13510", "categories": ["math.OC", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.13510", "abs": "https://arxiv.org/abs/2602.13510", "authors": ["Pavel Dvurechensky", "Andrea Ebner", "Johannes Carl Schnebel", "Shimrit Shtern", "Mathias Staudigl"], "title": "Stochastic variance reduced extragradient methods for solving hierarchical variational inequalities", "comment": null, "summary": "We are concerned with optimization in a broad sense through the lens of solving variational inequalities (VIs) -- a class of problems that are so general that they cover as particular cases minimization of functions, saddle-point (minimax) problems, Nash equilibrium problems, and many others. The key challenges in our problem formulation are the two-level hierarchical structure and finite-sum representation of the smooth operators in each level. For this setting, we are the first to prove convergence rates and complexity statements for variance-reduced stochastic algorithms approaching the solution of hierarchical VIs in Euclidean and Bregman setups."}
{"id": "2602.13931", "categories": ["physics.comp-ph", "cond-mat.soft", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.13931", "abs": "https://arxiv.org/abs/2602.13931", "authors": ["Ting Peng"], "title": "Geometry Challenges Entropy: Regime-DependentRectification in Nanofluidic Cascades", "comment": null, "summary": "Can geometry alone reshape equilibrium? Cascaded nanofluidic chambers show complex accumulation patterns, traditionally attributed to geometric diode effects. We use 3D molecular dynamics to decouple funnel rectification from boundary reflection. Simulations with argon parameters (r = 0.19 nm) reveal a striking \"reverse\" rectification in a 2-chamber setup: the narrow side accumulates over 5x more particles (N_1/N_0 = 5.37 +/- 0.01, p < 0.0001). In a 10-chamber argon cascade, this effect drives massive downstream accumulation. A symmetric control (w_L = w_R) eliminates the gradient, confirming that funnel asymmetry - not boundary/edge effects - is the primary driver in the ballistic regime. By contrast, the super-atom regime is dominated by boundary reflection. Our results challenge standard entropic transport theory and provide design rules for passive, geometry-driven density gradients - no pump, no drive."}
{"id": "2602.13572", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.13572", "abs": "https://arxiv.org/abs/2602.13572", "authors": ["Cody Trevillian", "Steven Louis", "Vasyl Tyberkevych"], "title": "Time-Domain Two-Magnon Interference Enabled by a Tunable Beamsplitter", "comment": "5 pages, 3 figures", "summary": "This letter presents a model system for controllable two-magnon interference in the time domain. This two-magnon interference, i.e., a magnonic analog to the photonic Hong-Ou-Mandel effect, is supported by a tunable magnonic beamsplitter operation formed in a hybrid cavity magnonic system comprising a pair of mutually coupled magnon modes. By applying a time-dependent magnetic field, magnons can be excited independently in each mode and subsequently brought into interaction, shifting from independent to collective oscillations, to realize a controllable magnonic beamsplitter. When the beamsplitter operation is applied to an initially unentangled two-magnon state, a maximally entangled magnonic $N00N$ state with tunable phase sensitivity is produced. These findings suggest that two-magnon interference in hybrid cavity magnonic systems may enable novel quantum metrological devices to study fundamental magnon dynamics and contribute to developing hybrid magnonic quantum computing architectures."}
{"id": "2602.14184", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.14184", "abs": "https://arxiv.org/abs/2602.14184", "authors": ["Guangyu Yu", "Zheng Zhu"], "title": "Composite Boson Theory of Fractional Chern Insulators", "comment": "5 pages, 2 figures", "summary": "The understanding of fractional Chern insulators (FCIs) has been deeply guided by band topology and quantum geometry. Here, we introduce a real-space theoretical framework in which FCIs are understood in terms of composite bosons, local objects consisting of electrons bound to their energetically excluded surrounding orbitals. The central element of our framework is the construction of a radially ordered set of maximally localized basis for Chern bands without requiring continuous rotational symmetry. Within this basis, the complex many-body problem simplifies to a real-space organizing principle: a stable FCI occurs if the orbitals excluded around central electrons are those maximizing the two-body interaction energy. We validate this with direct numerical evidence for composite boson formation in the Haldane model, demonstrating that our criterion reliably characterizes FCIs. Importantly, our analysis illustrates that the composite boson framework bridges the fractional quantum Hall effect in continuum and lattice paradigms, providing a unified and intuitive real-space interpretation for distinct correlated phases. It thus establishes a foundation for diagnosing and guiding the design of both Abelian and non-Abelian topologically ordered phases across distinct platforms."}
{"id": "2602.14742", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14742", "abs": "https://arxiv.org/abs/2602.14742", "authors": ["Hadi Nemati", "Álvaro Ortega", "Enrique Lobato", "Luis Rouco"], "title": "A Multi-Bound Robust Optimization Approach for Renewable-Based VPP Market Participation Considering Intra-Hourly Uncertainty Exposure", "comment": null, "summary": "With the ongoing transition of electricity markets worldwide from hourly to intra-hourly bidding, market participants--especially Renewable Energy Sources (RES)--gain improved opportunities to adjust energy and reserve schedules and to benefit from more accurate higher-resolution forecasts. However, this shift requires participants to update decision-making frameworks and to strengthen uncertainty management in order to fully exploit the new market potential. In particular, Renewable-Based Virtual Power Plants (RVPPs) aggregating dispatchable and non-dispatchable RES must account for these changes through market-oriented scheduling methods that efficiently address multiple uncertainties, including electricity prices, RES generation, and demand consumption. In this vein, this paper proposes a multi-bound robust optimization framework to simultaneously capture these uncertainties, explicitly incorporate intra-hourly variability, and differentiate the deviation levels (frequent, moderate deviations and rare, extreme ones) of uncertain parameters. The proposed approach yields less conservative and more implementable bidding and scheduling decisions, thus improving RVPP profitability in both energy and reserve markets. Simulation studies compare the proposed method with standard robust optimization and evaluate the operational, market-strategy, and economic impacts of quarter-hourly versus hourly market resolution. Results indicate that the normalized absolute differences, across different uncertainty-handling strategies, between hourly and 15-minute schedules are 18.0--34.2% for day-ahead traded energy, and 28.7--65.6% and 10.1--16.3% for upward and downward reserve traded in the secondary reserve market, respectively. Furthermore, relative to classic robust optimization, the proposed multi-bound approach increases profit by 24.9--49.2% across the considered strategies."}
{"id": "2602.14861", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.14861", "abs": "https://arxiv.org/abs/2602.14861", "authors": ["Roberto Vila", "Helton Saulo"], "title": "Bias analysis of a linear order-statistic inequality index estimator: Unbiasedness under gamma populations", "comment": "14 pages", "summary": "This paper studies a class of rank-based inequality measures built from linear combinations of expected order statistics. The proposed framework unifies several well-known indices, including the classical Gini coefficient, the $m$th Gini index, extended $m$th Gini index and $S$-Gini index, and also connects to spectral inequality measures through an integral representation. We investigate the finite-sample behavior of a natural U-statistic-type estimator that averages weighted order-statistic contrasts over all subsamples of fixed size and normalizes by the sample mean. A general bias decomposition is derived in terms of components that isolate the effect of random normalization on each rank level, yielding analytical expressions that can be evaluated under broad non-negative distributions via Laplace-transform methods. Under mild moment conditions, the estimator is shown to be asymptotically unbiased. Moreover, we prove exact unbiasedness under gamma populations for any sample size, extending earlier unbiasedness results for Gini-type estimators. A Monte Carlo study is performed to numerically check that the theoretical unbiasednes under gamma populations."}
{"id": "2602.14043", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14043", "abs": "https://arxiv.org/abs/2602.14043", "authors": ["Qiankun Pi", "Guixin Su", "Jinliang Li", "Mayi Xu", "Xin Miao", "Jiawei Jiang", "Ming Zhong", "Tieyun Qian"], "title": "Beyond Static Snapshots: Dynamic Modeling and Forecasting of Group-Level Value Evolution with Large Language Models", "comment": null, "summary": "Social simulation is critical for mining complex social dynamics and supporting data-driven decision making. LLM-based methods have emerged as powerful tools for this task by leveraging human-like social questionnaire responses to model group behaviors. Existing LLM-based approaches predominantly focus on group-level values at discrete time points, treating them as static snapshots rather than dynamic processes. However, group-level values are not fixed but shaped by long-term social changes. Modeling their dynamics is thus crucial for accurate social evolution prediction--a key challenge in both data mining and social science. This problem remains underexplored due to limited longitudinal data, group heterogeneity, and intricate historical event impacts.\n  To bridge this gap, we propose a novel framework for group-level dynamic social simulation by integrating historical value trajectories into LLM-based human response modeling. We select China and the U.S. as representative contexts, conducting stratified simulations across four core sociodemographic dimensions (gender, age, education, income). Using the World Values Survey, we construct a multi-wave, group-level longitudinal dataset to capture historical value evolution, and then propose the first event-based prediction method for this task, unifying social events, current value states, and group attributes into a single framework. Evaluations across five LLM families show substantial gains: a maximum 30.88\\% improvement on seen questions and 33.97\\% on unseen questions over the Vanilla baseline. We further find notable cross-group heterogeneity: U.S. groups are more volatile than Chinese groups, and younger groups in both countries are more sensitive to external changes. These findings advance LLM-based social simulation and provide new insights for social scientists to understand and predict social value changes."}
{"id": "2602.13635", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.13635", "abs": "https://arxiv.org/abs/2602.13635", "authors": ["Genshiro Kitagawa"], "title": "Backward Smoothing versus Fixed-Lag Smoothing in Particle Filters", "comment": "17 pages, 5 tables, 7 figures", "summary": "Particle smoothing enables state estimation in nonlinear and non-Gaussian state-space models, but its practical use is often limited by high computational cost. Backward smoothing methods such as the Forward Filter Backward Smoother (FFBS) and its marginal form (FFBSm) can achieve high accuracy, yet typically require quadratic computational complexity in the number of particles. This paper examines the accuracy--computational cost trade-offs of particle smoothing methods through a trend-estimation example. Fixed-lag smoothing, FFBS, and FFBSm are compared under Gaussian and heavy-tailed (Cauchy-type) system noise, with particular attention to O(m) approximations of FFBSm based on subsampling and local neighborhood restrictions. The results show that FFBS and FFBSm outperform fixed-lag smoothing at a fixed particle number, while fixed-lag smoothing often achieves higher accuracy under equal computational time. Moreover, efficient FFBSm approximations are effective for Gaussian transitions but become less advantageous for heavy-tailed dynamics."}
{"id": "2602.14436", "categories": ["eess.SY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.14436", "abs": "https://arxiv.org/abs/2602.14436", "authors": ["Jaehan Im", "David Fridovich-Keil", "Ufuk Topcu"], "title": "Noncooperative Virtual Queue Coordination via Uncertainty-Aware Correlated Equilibria", "comment": null, "summary": "Collaborative virtual queueing has been proposed as a mechanism to mitigate airport surface congestion while preserving airline autonomy over aircraft-level pushback decisions. A central coordinator can regulate aggregate pushback capacity but cannot directly control which specific aircraft are released, limiting its ability to steer system-level performance. We propose a noncooperative coordination mechanism for collaborative virtual queueing based on the correlated equilibrium concept, which enables the coordinator to provide incentive-compatible recommendations on aircraft-level pushback decisions without overriding airline autonomy. To account for uncertainty in airlines' internal cost assessments, we introduce chance constraints into the correlated equilibrium formulation. This formulation provides explicit probabilistic guarantees on incentive compatibility, allowing the coordinator to adjust the confidence level with which airlines are expected to follow the recommended actions. We further propose a scalable algorithm for computing chance-constrained correlated equilibria by exploiting a reduced-rank structure. Numerical experiments demonstrate that the proposed method scales to realistic traffic levels up to 210 eligible pushbacks per hour, reduces accumulated delay by up to approximately 8.9% compared to current first-come-first-served schemes, and reveals a trade-off between confidence level, deviation robustness, and achievable cost efficiency."}
{"id": "2602.14309", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14309", "abs": "https://arxiv.org/abs/2602.14309", "authors": ["Dibyendu Adak", "David Mora", "Alberth Silgado"], "title": "Nonconforming virtual element methods for fourth-order nonlinear reaction-diffusion systems: a unified framework and analysis", "comment": "38 pages, 4 figures, 4 tables", "summary": "We develop a unified framework for the design and analysis of high-order nonconforming virtual element methods for nonlinear fourth-order reaction--diffusion problems in two dimensions, with emphasis on clamped, Navier, and Cahn--Hilliard-type boundary conditions. Time discretization is performed using the backward Euler scheme, while the spatial approximation relies on nonconforming virtual element spaces of arbitrary order $k \\ge 2$, encompassing both $C^0$-nonconforming and Morley-type methods. A key contribution of this work is the development of a novel and rigorous unified error analysis for these numerical schemes, applicable to domains that are not necessarily convex, differing from the existing literature. By introducing a class of Companion operators, we construct novel Ritz-type projections and derive a new error equation that enables us to obtain optimal error estimates for the scheme under a minimal spatial regularity assumption on the weak solution. Finally, we present numerical experiments on polygonal meshes as applications of the proposed framework, including the extended Fisher--Kolmogorov equation, and a fourth-order model with Cahn--Hilliard-type boundary conditions, which validate the theoretical results and illustrate the performance of the method for the three classes of boundary conditions."}
{"id": "2602.13513", "categories": ["math.OC", "cs.CE", "cs.LG", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.13513", "abs": "https://arxiv.org/abs/2602.13513", "authors": ["Grant Norman", "Conor Rowan", "Kurt Maute", "Alireza Doostan"], "title": "Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization", "comment": "44 pages, 13 figures. To be submitted to CMAME", "summary": "In this work, we investigate the use of data-driven equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization. The discovered gradient flows are then solved as a surrogate for the original optimization problem. To this end, we introduce the Learned Gradient Flow (LGF) optimizer, which is equipped to build surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals in the optimization process. We demonstrate the efficacy of this approach on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Our results suggest that the learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations of the objective and its gradient."}
{"id": "2602.14713", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.14713", "abs": "https://arxiv.org/abs/2602.14713", "authors": ["Bosiljka Tadic"], "title": "Antiferromagnetic Barkhausen noise induced by weak random-field disorder", "comment": "20 pages, 4 figures", "summary": "This study numerically investigates magnetisation reversal processes driven by an external magnetic field in three-dimensional antiferromagnetic spin models with weak random field disorder. Considering an extremely weak disorder and low temperature, we observe a step-wise hysteresis loop and the appearance of short magnetisation bursts of a characteristic triangular shape; the number of bursts increases with disorder, indicative of Barkhausen-type noise. These phenomena are attributed to the simultaneous reversal at a given external field of segments composed of spins with identical neighbourhoods. A local random field orients one or more spin neighbours, resulting in small, ferromagnetic-like clusters distributed throughout the system. As disorder increases, these clusters may merge to form a labyrinthine structure within the antiferromagnetic background, facilitating brief avalanche propagation. The results demonstrate that, compared with familiar random-field ferromagnets, the observed antiferromagnetic Barkhausen noise and the related avalanche sequence have a profoundly different structure, organised into peaks associated with the transition between magnetisation plateaus. They exhibit prominent cyclical trends and disorder-dependent multifractal fluctuations, with the singularity spectrum quantifying the degree of disorder. The activity avalanches exhibit scale invariance resembling that recently found in experiments with disordered ferr\\textit{i}magnets and martensites, as well as in quantum Barkhausen noise, which are associated with active geometric regions rather than individual-spin dynamics. The observed scaling behaviour is interpreted in terms of self-organised critical dynamics."}
{"id": "2602.13592", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13592", "abs": "https://arxiv.org/abs/2602.13592", "authors": ["Bo Y. Chang", "Ignacio R. Sola", "Svetlana A. Malinovskaya", "Sebastian C. Carrasco", "Vladimir S. Malinovsky"], "title": "Digitizing ultrafast adiabatic passage with a pulse train", "comment": null, "summary": "We present a digitized implementation of rapid adiabatic passage based on a train of weak, frequency-varying ultrafast pulses. Analytic conditions on the subpulse Rabi frequencies and detunings are derived to reproduce the continuous-time population dynamics of a conventional long-pulse excitation. We find that the reproduced dynamics achieves high fidelity even for pulse trains with a small number of subpulses, provided that each subpulse remains within the perturbative regime. The subpulses act as discrete samples of the underlying continuous evolution; consequently, more complex population dynamics, characterized by multiple oscillations prior to the onset of adiabaticity, require a larger number of subpulses for accurate reproduction. In addition, we demonstrate how the sidebands of a frequency comb can be exploited for resonant excitation at large carrier detuning and for the precise preparation of superposition states."}
{"id": "2602.14511", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.14511", "abs": "https://arxiv.org/abs/2602.14511", "authors": ["Makoto Shimizu", "Chang-guen Oh", "Youichi Yanase"], "title": "Magnetic fluctuations driven by quantum geometry", "comment": null, "summary": "Using quantum distance, magnetic susceptibility in the non-interacting limit can be rigorously split into two contributions: one arising solely from band dispersion, while the other stems from quantum geometric contributions. In this Letter, we apply this decomposition to two materials, LaFeAsO and Pb$_9$Cu(PO$_4$)$_6$O, and demonstrate that their dominant magnetic fluctuations originate from the geometric contribution. In LaFeAsO, stripe-type antiferromagnetic fluctuations arise primarily from quantum geometry, while in Pb$_9$Cu(PO$_4$)$_6$O the geometric term suppresses antiferromagnetic fluctuations and stabilizes ferromagnetic fluctuations. Our findings highlight the essential role of quantum geometry in governing magnetic fluctuations in multi-band systems, and provide a unique and quantitative framework to disentangle band-structure and wavefunction-geometry effects that have often been discussed collectively as multi-orbital effects."}
{"id": "2602.14765", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.14765", "abs": "https://arxiv.org/abs/2602.14765", "authors": ["Ariana R. Mendez-Castillo", "Rodrigo Aldana-Lopez", "Antonio Ramirez-Trevino", "Rosario Aragues", "David Gomez-Gutierrez"], "title": "Hierarchical parameter estimation for distributed networked systems: a dynamic consensus approach", "comment": null, "summary": "This work introduces a novel two-stage distributed framework to globally estimate constant parameters in a networked system, separating shared information from local estimation. The first stage uses dynamic average consensus to aggregate agents' measurements into surrogates of centralized data. Using these surrogates, the second stage implements a local estimator to determine the parameters. By designing an appropriate consensus gain, the persistence of excitation of the regressor matrix is achieved, and thus, exponential convergence of a local Gradient Estimator (GE) is guaranteed. The framework facilitates its extension to switched network topologies, quantization, and the heterogeneous substitution of the GE with a Dynamic Regressor Extension and Mixing (DREM) estimator, which supports relaxed excitation requirements."}
{"id": "2602.14969", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.14969", "abs": "https://arxiv.org/abs/2602.14969", "authors": ["Andrea Montanari", "Basil Saeed"], "title": "Topological trivialization in non-convex empirical risk minimization", "comment": "33 pages; 16 pdf figures", "summary": "Given data $\\{({\\boldsymbol x}_i,y_i): i\\le n\\}$, with ${\\boldsymbol x}_i$ standard $d$-dimensional Gaussian feature vectors, and $y_i\\in{\\mathbb R}$ response variables, we study the general problem of learning a model parametrized by ${\\boldsymbol θ}\\in{\\mathbb R}^d$, by minimizing a loss function that depends on ${\\boldsymbol θ}$ via the one-dimensional projections ${\\boldsymbol θ}^{\\sf T}{\\boldsymbol x}_i$. While previous work mostly dealt with convex losses, our approach assumes general (non-convex) losses hence covering classical, yet poorly understood examples such as the perceptron and non-convex robust regression. We use the Kac-Rice formula to control the asymptotics of the expected number of local minima of the empirical risk, under the proportional asymptotics $n,d\\to\\infty$, $n/d\\toα>1$. Specifically, we prove a finite dimensional variational formula for the exponential growth rate of the expected number of local minima. Further we provide sufficient conditions under which the exponential growth rate vanishes and all empirical risk minimizers have the same asymptotic properties (in fact, we expect the minimizer to be unique in these circumstances). We refer to this phenomenon as `rate trivialization.' If the population risk has a unique minimizer, our sufficient condition for rate trivialization is typically verified when the samples/parameters ratio $α$ is larger than a suitable constant $α_{\\star}$. Previous general results of this type required $n\\ge Cd \\log d$. We illustrate our results in the case of non-convex robust regression. Based on heuristic arguments and numerical simulations, we present a conjecture for the exact location of the trivialization phase transition $α_{\\text{tr}}$."}
{"id": "2602.14091", "categories": ["cs.SI", "cs.CY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.14091", "abs": "https://arxiv.org/abs/2602.14091", "authors": ["Erina Murata", "Masaki Chujyo", "Fujio Toriumi"], "title": "Temporal Shifts and Causal Interactions of Emotions in Social and Mass Media: A Case Study of the \"Reiwa Rice Riot\" in Japan", "comment": null, "summary": "In Japan, severe rice shortages in 2024 sparked widespread public controversy across both news media and social platforms, culminating in what has been termed the \"Reiwa Rice Riot.\" This study proposes a framework to analyze the temporal dynamics and causal interactions of emotions expressed on X (formerly Twitter) and in news articles, using the \"Reiwa Rice Riot\" as a case study. While recent studies have shown that emotions mutually influence each other between social and mass media, the patterns and transmission pathways of such emotional shifts remain insufficiently understood. To address this gap, we applied a machine learning-based emotion classification grounded in Plutchik's eight basic emotions to analyze posts from X and domestic news articles. Our findings reveal that emotional shifts and information dissemination on X preceded those in news media. Furthermore, in both media platforms, the fear was initially the most dominant emotion, but over time intersected with hope which ultimately became the prevailing emotion. Our findings suggest that patterns in emotional expressions on social media may serve as a lens for exploring broader social dynamics."}
{"id": "2602.13872", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.13872", "abs": "https://arxiv.org/abs/2602.13872", "authors": ["Chris Holmes", "Stephen Walker"], "title": "Predicting fixed-sample test decisions enables anytime-valid inference", "comment": null, "summary": "Statistical hypothesis tests typically use prespecified sample sizes, yet data often arrive sequentially. Interim analyses invalidate classical error guarantees, while existing sequential methods require rigid testing preschedules or incur substantial losses in statistical power. We introduce a simple procedure that transforms any fixed-sample hypothesis test into an anytime-valid test while ensuring Type-I error control and near-optimal power with substantial sample savings when the null hypothesis is false. At each step, the procedure predicts the probability that a classical test would reject the null hypothesis at its fixed-sample size, treating future observations as missing data under the null hypothesis. Thresholding this probability yields an anytime-valid stopping rule. In areas such as clinical trials, stopping early and safely can ensure that subjects receive the best treatments and accelerate the development of effective therapies."}
{"id": "2602.14660", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14660", "abs": "https://arxiv.org/abs/2602.14660", "authors": ["Fan Zhang", "Deyuan Meng", "Ying Tan"], "title": "Segment-Based Two-Loop Adaptive Iterative Learning Control for Spacecraft Position and Attitude Tracking", "comment": "13 pages", "summary": "Proximity operations of rigid bodies, such as spacecraft rendezvous and docking, require precise tracking of both position and attitude over finite time intervals. These operations are often repeated under uncertain conditions, with unknown but repeatable parameters and disturbances. Adaptive iterative learning control (ILC) is well suited to such tasks, as it can track desired trajectories while learning unknown, iteration-invariant signals or parameters. However, conventional adaptive ILC faces two challenges: (i) the coupling between rotational and translational dynamics complicates the design of the two coordinated learning loops for position and attitude, and (ii) standard adaptive ILC designs cannot guarantee bounded control inputs. To address these issues, we propose a dual-number-based, segment-based two-loop adaptive ILC framework for simultaneous high-precision position and attitude tracking. The framework employs two learning loops that interact through a dual-number representation of tracking errors, combining position and attitude errors into a single mathematical object for unified control design. A segment-based dynamic projection mechanism ensures that both parameter estimates and control inputs remain bounded without prior knowledge of uncertainties. Mathematical analysis and numerical simulations demonstrate that the proposed framework significantly enhances tracking performance under unknown but repeatable uncertainties and strong rotational-translational coupling."}
{"id": "2602.14369", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14369", "abs": "https://arxiv.org/abs/2602.14369", "authors": ["Sigal Gottlieb", "Zachary J. Grant", "Cesar Herrera"], "title": "Mixed precision and mixed accuracy explicit two-derivative Runge--Kutta methods", "comment": null, "summary": "Mixed precision Runge--Kutta methods have been recently developed and used for the time-evolution of partial differential equations. Two-derivative Runge--Kutta schemes may offer enhanced stability and accuracy properties compared to classical one-derivative methods, making them attractive in a wide variety of problems. However, their computational cost can be significant, motivating the use of a mixed-precision paradigm that employs different floating-point precisions for different function evaluations to balance efficiency and accuracy. To ensure that the perturbations introduced by the low precision computations do not destroy the accuracy of the solution, we need to understand how these perturbation errors propagate. We extend the numerical analysis mixed precision framework previously developed for Runge--Kutta methods to characterize the propagation of the perturbation errors arising from mixed precision computations in explicit and implicit two-derivative Runge--Kutta methods. We use this framework for analyzing the order of the perturbation errors, and for designing new methods that are less sensitive to the effect of the low precision computations. Numerical experiments on linear and nonlinear representative PDEs, demonstrate that appropriately designed mixed-precision two-derivative Runge--Kutta methods achieve the predicted accuracy."}
{"id": "2602.13514", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.13514", "abs": "https://arxiv.org/abs/2602.13514", "authors": ["Henry Abrahamson", "Yongho Kim", "Seongha Park", "Ermin Wei"], "title": "Distributed Edge Computing Task Allocation with Network Effects", "comment": "8 pages, 6 figures", "summary": "Field-deployable edge computing nodes form a network and are used to complete scientific tasks for remote sensing and monitoring. The networked nodes collectively decide which scientific applications to run while they are constrained by various factors, such as differing hardware constraints from heterogeneous nodes and time-varying quality of service (QoS) requirements. We model the problem of task allocation as an optimization problem that maximizes the QoS, subject to the constraints. We solve the optimization problem using a dual-descent method, which can be easily implemented in a distributed way subject to the communication constraints of the network. Using a simulation that uses real-world data collected from Sage, a distributed sensor network, we analyze our policy's performance in dynamic situations where the required QoS and the nodes' capabilities change, and verify that it can adapt and return a feasible solution while accounting for those changes."}
{"id": "2602.14885", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.14885", "abs": "https://arxiv.org/abs/2602.14885", "authors": ["Ramón Nartallo-Kaluarachchi", "Renaud Lambiotte", "Alain Goriely"], "title": "Drift-Diffusion Matching: Embedding dynamics in latent manifolds of asymmetric neural networks", "comment": "23 pages, 15 figures", "summary": "Recurrent neural networks (RNNs) provide a theoretical framework for understanding computation in biological neural circuits, yet classical results, such as Hopfield's model of associative memory, rely on symmetric connectivity that restricts network dynamics to gradient-like flows. In contrast, biological networks support rich time-dependent behaviour facilitated by their asymmetry. Here we introduce a general framework, which we term drift-diffusion matching, for training continuous-time RNNs to represent arbitrary stochastic dynamical systems within a low-dimensional latent subspace. Allowing asymmetric connectivity, we show that RNNs can faithfully embed the drift and diffusion of a given stochastic differential equation, including nonlinear and nonequilibrium dynamics such as chaotic attractors. As an application, we construct RNN realisations of stochastic systems that transiently explore various attractors through both input-driven switching and autonomous transitions driven by nonequilibrium currents, which we interpret as models of associative and sequential (episodic) memory. To elucidate how these dynamics are encoded in the network, we introduce decompositions of the RNN based on its asymmetric connectivity and its time-irreversibility. Our results extend attractor neural network theory beyond equilibrium, showing that asymmetric neural populations can implement a broad class of dynamical computations within low-dimensional manifolds, unifying ideas from associative memory, nonequilibrium statistical mechanics, and neural computation."}
{"id": "2602.13605", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13605", "abs": "https://arxiv.org/abs/2602.13605", "authors": ["Karol Kowalski", "Nicholas P. Bauman"], "title": "Single-reference coupled-cluster theory based on the multi-purpose cluster operator", "comment": null, "summary": "In this paper, we develop a theoretical framework that extends single-reference (SR) coupled-cluster (CC) theory beyond its conventional role of describing a single electronic state-typically the lowest-energy state within the symmetry sector defined by the reference determinant. Rather than viewing the SR-CC cluster operator solely as a device for reproducing one target state, we consider more general constructions in which different components of the cluster operator play distinct roles, ranging from encoding states of different symmetry than the reference to enabling SR-CC Ansatz to describe multiple states simultaneously. These developments lead to a new class of SR-CC downfolding formalisms in which the resulting active-space effective Hamiltonians are capable of concurrently representing multiple correlated states nonorthogonal to the reference function. We establish three theorems that formalize this extension and demonstrate that standard CC downfolding emerges as a special case of the proposed framework. Finally, we introduce a Hermitian variant based on a unitary CC representation, which enables realistic simulations of ground and excited states while reducing the quantum resources required."}
{"id": "2602.14563", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.14563", "abs": "https://arxiv.org/abs/2602.14563", "authors": ["Alexandre Bertin", "Hengdi Zhao", "Gang Cao", "Andrea Piovano", "Paul Steffens", "Alexandre Ivanov", "Markus Braden"], "title": "Magnetic excitations in the Kitaev material Na$_2$IrO$_3$ studied by neutron scattering", "comment": "11 pages, 6 figures", "summary": "Inelastic neutron scattering experiments with a large set of comounted Na$_2$IrO$_3$ crystals reveal the low-energy magnon dispersion in this candidate material for Kitaev physics. The magnon gap amounts to 1.7(1) meV and can be interpreted similarly to the sister compound $α$-RuCl$_{3}$ to stem from the zone boundaries in the antiferromagnetic zigzag structure. The neutron experiments find no evidence for low-energy excitations with ferromagnetic character, which contrasts to the findings in $α$-RuCl$_{3}$. Our results are consistent with a recently proposed microscopic model that involves an antiferromagnetic Heisenberg nearest-neighbor exchange in Na$_2$IrO$_3$ in contrast to the ferromagnetic one considered for $α$-RuCl$_{3}$. Although the magnetic response shows the signatures of bond-directional anisotropy in both materials the different relative signs of Kitaev and Heisenberg interaction result in different deviations from the initial Kitaev model. Low-energy ferromagnetic fluctuations cannot be considered as a fingerprint of ferromagnetic Kitaev interaction."}
{"id": "2602.14909", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14909", "abs": "https://arxiv.org/abs/2602.14909", "authors": ["Tyrone Fernando"], "title": "Unified Eigenvalue-Eigenspace Criteria for Functional Properties of Linear Systems and the Generalized Separation Principle", "comment": "Submitted to a journal", "summary": "Classical controllability and observability characterise reachability and reconstructibility of the full system state and admit equivalent geometric and eigenvalue-based Popov-Belevitch-Hautus (PBH) tests. Motivated by large-scale and networked systems where only selected linear combinations of the state are of interest, this paper studies functional generalisations of these properties. A PBH-style framework for functional system properties is developed, providing necessary and sufficient spectral characterisations. The results apply uniformly to diagonalizable and non-diagonalizable systems and recover the classical PBH tests as special cases.\n  Two new intrinsic notions are introduced: intrinsic functional controllability, and intrinsic functional stabilizability. These intrinsic properties are formulated directly in terms of invariant subspaces associated with the functional and provide verifiable conditions for the existence of admissible augmentations required for functional controller design and observer-based functional controller design. The intrinsic framework enables the generalized separation principle at the functional level, establishing that functional controllers and functional observers can be designed independently. Illustrative examples demonstrate the theory and highlight situations where functional control and estimation are possible despite lack of full-state controllability or observability."}
{"id": "2602.13533", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.13533", "abs": "https://arxiv.org/abs/2602.13533", "authors": ["Yi Liu", "Huiman Barnhart", "Sean O'Brien", "Yuliya Lokhnygina", "Roland A. Matsouaka"], "title": "Estimation and Inference of the Win Ratio for Two Hierarchical Endpoints Subject to Censoring and Missing Data", "comment": null, "summary": "The win ratio (WR) is a widely used metric to compare treatments in randomized clinical trials with hierarchically ordered endpoints. Counting-based approaches, such as Pocock's algorithm, are the standard for WR estimation. However, this algorithm treats participants with censored or missing data inadequately, which may lead to biased and inefficient estimates, particularly in the presence of heterogeneous censoring or missing data between treatment groups. Although recent extensions have addressed some of these limitations for hierarchical time-to-event endpoints, no existing methods -- aside from the computationally intensive multiple imputation approach -- can accommodate settings that include non-survival endpoints that are subject to missing data. In this paper, we propose a simple nonparametric maximum likelihood estimator (NPMLE) of WR for two hierarchical endpoints that are subject to censoring and missing data. Our method uses all observed data, avoids strong parametric assumptions, and comes with a closed-form asymptotic variance estimator. We demonstrate its performance using simulation studies and two data examples, based on the HEART-FID and ISCHEMIA trials. The proposed method provides a consistent estimator, improves estimation efficiency, and is robust under non-informative censoring and missing at random (MAR) assumptions, offering a flexible alternative to existing WR estimation methods. A user-friendly R package, WinRS, is available to facilitate implementation."}
{"id": "2602.14239", "categories": ["cs.SI", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14239", "abs": "https://arxiv.org/abs/2602.14239", "authors": ["Nafiseh Sadat Sajadi", "Behnam Bahrak", "Mahdi Jafari Siavoshani"], "title": "A Hybrid TGN-SEAL Model for Dynamic Graph Link Prediction", "comment": null, "summary": "Predicting links in sparse, continuously evolving networks is a central challenge in network science. Conventional heuristic methods and deep learning models, including Graph Neural Networks (GNNs), are typically designed for static graphs and thus struggle to capture temporal dependencies. Snapshot-based techniques partially address this issue but often encounter data sparsity and class imbalance, particularly in networks with transient interactions such as telecommunication call detail records (CDRs). Temporal Graph Networks (TGNs) model dynamic graphs by updating node embeddings over time; however, their predictive accuracy under sparse conditions remains limited. In this study, we improve the TGN framework by extracting enclosing subgraphs around candidate links, enabling the model to jointly learn structural and temporal information. Experiments on a sparse CDR dataset show that our approach increases average precision by 2.6% over standard TGNs, demonstrating the advantages of integrating local topology for robust link prediction in dynamic networks."}
{"id": "2602.13888", "categories": ["stat.ME", "stat.AP", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.13888", "abs": "https://arxiv.org/abs/2602.13888", "authors": ["The Tien Mai", "Zhi Zhao"], "title": "Mixture-of-experts Wishart model for covariance matrices with an application to Cancer drug screening", "comment": null, "summary": "Covariance matrices arise naturally in different scientific fields, including finance, genomics, and neuroscience, where they encode dependence structures and reveal essential features of complex multivariate systems. In this work, we introduce a comprehensive Bayesian framework for analyzing heterogeneous covariance data through both classical mixture models and a novel mixture-of-experts Wishart (MoE-Wishart) model. The proposed MoE-Wishart model extends standard Wishart mixtures by allowing mixture weights to depend on predictors through a multinomial logistic gating network. This formulation enables the model to capture complex, nonlinear heterogeneity in covariance structures and to adapt subpopulation membership probabilities to covariate-dependent patterns. To perform inference, we develop an efficient Gibbs-within-Metropolis-Hastings sampling algorithm tailored to the geometry of the Wishart likelihood and the gating network. We additionally derive an Expectation-Maximization algorithm for maximum likelihood estimation in the mixture-of-experts setting. Extensive simulation studies demonstrate that the proposed Bayesian and maximum likelihood estimators achieve accurate subpopulation recovery and estimation under a range of heterogeneous covariance scenarios. Finally, we present an innovative application of our methodology to a challenging dataset: cancer drug sensitivity profiles, illustrating the ability of the MoE-Wishart model to leverage covariance across drug dosages and replicate measurements.\n  Our methods are implemented in the \\texttt{R} package \\texttt{moewishart} available at https://github.com/zhizuio/moewishart ."}
{"id": "2602.14725", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14725", "abs": "https://arxiv.org/abs/2602.14725", "authors": ["Cornelia Skaga", "Mahdieh S. Sadabadi", "Gilbert Bergna-Diaz"], "title": "DC Microgrids with Nested Nonlinear Distributed Control: Scalable Large-Signal Stability and Voltage Containment", "comment": "12 pages, 8 figures", "summary": "This paper investigates a cyber-physical DC microgrid employing a nonlinear distributed consensus-based control scheme for coordinated integration and management of distributed generating units within an expandable framework. Relying on nested primary andsecondary control loops; a (distributed) outer-loop and a (decentralized) inner-loop, the controller achieves proportional current sharing among all distributed generation units, while dynamically operating within predefined voltage limits. A rigorous Lyapunov-based stability analysis establishes a scalable global exponential stability certificate under some tuning conditions and sufficient time-scale separation between the control loops, based on singular perturbation theory. An optimization-based tuning strategy is then formulated to identify and subsequently diminish unstable operating conditions. In turn, various practical tuning strategies are introduced to provide stable operations while facilitating near-optimal proportional current sharing. The effectiveness of the proposed control framework and tuning approaches are finally supported through time-domain simulations of a case-specific low-voltage DC microgrid."}
{"id": "2602.14392", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14392", "abs": "https://arxiv.org/abs/2602.14392", "authors": ["Thomas Izgin", "Andreas Meister", "Chi-Wang Shu", "Davide Torlo"], "title": "Flux-Balanced Patankar-type Schemes for the Compressible Euler Equations", "comment": null, "summary": "Positivity preservation of key physical quantities in the context of fluid flows, such as density and internal energy, is an essential property of a numerical scheme as otherwise the solution lacks physical relevance and has a not well-defined equation of state. One time integration technique that is capable of preserving the positivity of quantities for every time step size is the Patankar-trick and its variants. However, in the context of the Euler equations of gas dynamics, we wonder whether the Patankar-trick should be applied to the density and total energy equations or only to one of them. In this work, we discuss one drawback of the schemes when blindly applied to every positive conserved variable and additionally point out how to overcome the issue by balancing the involved numerical fluxes correctly. To illustrate our findings, we investigate modified Patankar--Runge--Kutta (MPRK) schemes in the context of the compressible Euler equations with and without stiff source terms. We discover that it is beneficial to only apply the Patankar-trick in the density equation and to balance the remaining numerical fluxes consistently rather than applying the trick also to the energy equation. This leads also to the preservation of contact discontinuities. We perform numerical experiments to demonstrate that the accuracy of the methods is maintained while the performance of our approach is superior to the traditional application of MPRK schemes."}
{"id": "2602.13615", "categories": ["math.OC", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.13615", "abs": "https://arxiv.org/abs/2602.13615", "authors": ["Iasson Karafyllis", "Miroslav Krstic"], "title": "On the Existence of Periodic Solutions with Applications to Extremum-Seeking", "comment": "27 pages", "summary": "This paper provides two results that are useful in the study of the existence and the stability properties of a periodic solution for a given dynamical system. The first result deals with scalar time-periodic systems and establishes the equivalence of the existence of a periodic solution and the existence of a bounded solution. The second result provides sufficient conditions for the existence and the stability of a periodic solution for a time-periodic dynamical system. Both results are applied to extremum seeking problems for a static output map with no plant dynamics and novel non-local results are provided without the use of averaging theorems and singular perturbation arguments."}
{"id": "2602.14928", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14928", "abs": "https://arxiv.org/abs/2602.14928", "authors": ["Brandon Yee", "Wilson Collins", "Maximilian Rutkowski"], "title": "From Classical to Quantum: Extending Prometheus for Unsupervised Discovery of Phase Transitions in Three Dimensions and Quantum Systems", "comment": null, "summary": "We extend the Prometheus framework for unsupervised phase transition discovery from 2D classical systems to 3D classical and quantum many-body systems, addressing scalability in higher dimensions and generalization to quantum fluctuations. For the 3D Ising model ($L \\leq 32$), the framework detects the critical temperature within 0.01\\% of literature values ($T_c/J = 4.511 \\pm 0.005$) and extracts critical exponents with $\\geq 70\\%$ accuracy ($β= 0.328 \\pm 0.015$, $γ= 1.24 \\pm 0.06$, $ν= 0.632 \\pm 0.025$), correctly identifying the 3D Ising universality class via $χ^2$ comparison ($p = 0.72$) without analytical guidance. For quantum systems, we developed quantum-aware VAE (Q-VAE) architectures using complex-valued wavefunctions and fidelity-based loss. Applied to the transverse field Ising model, we achieve 2\\% accuracy in quantum critical point detection ($h_c/J = 1.00 \\pm 0.02$) and successfully discover ground state magnetization as the order parameter ($r = 0.97$). Notably, for the disordered transverse field Ising model, we detect exotic infinite-randomness criticality characterized by activated dynamical scaling $\\ln ξ\\sim |h - h_c|^{-ψ}$, extracting a tunneling exponent $ψ= 0.48 \\pm 0.08$ consistent with theoretical predictions ($ψ= 0.5$). This demonstrates that unsupervised learning can identify qualitatively different types of critical behavior, not just locate critical points. Our systematic validation across classical thermal transitions ($T = 0$ to $T > 0$) and quantum phase transitions ($T = 0$, varying $h$) establishes that VAE-based discovery generalizes across fundamentally different physical domains, providing robust tools for exploring phase diagrams where analytical solutions are unavailable."}
{"id": "2602.13623", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13623", "abs": "https://arxiv.org/abs/2602.13623", "authors": ["Nilakantha Meher", "Anirban Pathak", "S. Sivakumar"], "title": "Generation of large Fock states from coherent states using Kerr interaction and displacement", "comment": "To be published in Physical Review A", "summary": "We discuss a scheme to generate large Fock states. The scheme involves repeatedly applying an experimentally feasible unitary transformation to convert a semiclassical state into a Fock state. The transformation combines Kerr interaction, which is a non-Gaussian operation, and pulsed coherent drives. We identify suitable parameter values (Kerr strength, pulse timings, displacement amplitude) for the physical processes to implement the transformation and generate large Fock states with near-unity fidelity. The feasibility of implementing the scheme in circuit QED architectures is discussed. The method is also suitable for generating Fock states of cavity fields."}
{"id": "2602.14599", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.14599", "abs": "https://arxiv.org/abs/2602.14599", "authors": ["Zhe Wang", "Chengxiang Ding", "Dongxu Liu", "Fuxiang Li", "Zheng Yan", "Shuai Yin"], "title": "Non-commutative Dynamic Approaches to the Kibble-Zurek Scaling Limit with an Initial Gapless Order", "comment": "13 pages, 10 figures", "summary": "Nonequilibrium many-body physics is one of the core problems in modern physics, while the dynamical scaling from a gapless phase to the critical point is a most important challenge with very few knowledge so far. In the driven dynamics with a tuning rate $R$ across the quantum critical point (QCP) of a system with size $L$, the finite-time scaling shows that the square of the order parameter $m^2$ obeys a simple scaling relation $m^2\\propto R^{2β/νr}$ in the Kibble-Zurek (KZ) scaling limit with $RL^r\\gg1$. Here, by studying the driven critical dynamics from a gapless ordered phase in the bilayer Heisenberg model, we unveil that the approaches to the scaling region dominated by the KZ scaling limit with $RL^r\\gg1$ are {\\it non-commutative}: this scaling region is inaccessible for large $R$ and finite medium $L$, while merely accessible for large $L$ and moderately finite $R$. We attribute this to the memory effect induced by the finite-size correction in the gapless ordered phase. This non-commutative property makes $m^2$ still strongly depends on the system size and deviates from $m^2\\propto R^{2β/νr}$ even for large $R$. We further show that a similar correction applies to the imaginary-time relaxation dynamics. Our results establish an essential extension of nonequilibrium scaling theory with a gapless ordered initial state."}
{"id": "2602.14939", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14939", "abs": "https://arxiv.org/abs/2602.14939", "authors": ["Sidharthenee Nayak", "Victor Sam Moses Babu", "Chandrashekhar Narayan Bhende", "Pratyush Chakraborty", "Mayukha Pal"], "title": "Fault Detection in Electrical Distribution System using Autoencoders", "comment": null, "summary": "In recent times, there has been considerable interest in fault detection within electrical power systems, garnering attention from both academic researchers and industry professionals. Despite the development of numerous fault detection methods and their adaptations over the past decade, their practical application remains highly challenging. Given the probabilistic nature of fault occurrences and parameters, certain decision-making tasks could be approached from a probabilistic standpoint. Protective systems are tasked with the detection, classification, and localization of faulty voltage and current line magnitudes, culminating in the activation of circuit breakers to isolate the faulty line. An essential aspect of designing effective fault detection systems lies in obtaining reliable data for training and testing, which is often scarce. Leveraging deep learning techniques, particularly the powerful capabilities of pattern classifiers in learning, generalizing, and parallel processing, offers promising avenues for intelligent fault detection. To address this, our paper proposes an anomaly-based approach for fault detection in electrical power systems, employing deep autoencoders. Additionally, we utilize Convolutional Autoencoders (CAE) for dimensionality reduction, which, due to its fewer parameters, requires less training time compared to conventional autoencoders. The proposed method demonstrates superior performance and accuracy compared to alternative detection approaches by achieving an accuracy of 97.62% and 99.92% on simulated and publicly available datasets."}
{"id": "2602.14981", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.14981", "abs": "https://arxiv.org/abs/2602.14981", "authors": ["Tianni Zhang", "Yuyao Wang", "Yu Lu", "and Mengfei Ran"], "title": "Block Empirical Likelihood Inference for Longitudinal Generalized Partially Linear Single-Index Models", "comment": null, "summary": "Generalized partially linear single-index models (GPLSIMs) provide a flexible and interpretable semiparametric framework for longitudinal outcomes by combining a low-dimensional parametric component with a nonparametric index component. For repeated measurements, valid inference is challenging because within-subject correlation induces nuisance parameters and variance estimation can be unstable in semiparametric settings. We propose a profile estimating-equation approach based on spline approximation of the unknown link function and construct a subject-level block empirical likelihood (BEL) for joint inference on the parametric coefficients and the single-index direction. The resulting BEL ratio statistic enjoys a Wilks-type chi-square limit, yielding likelihood-free confidence regions without explicit sandwich variance estimation. We also discuss practical implementation, including constrained optimization for the index parameter, working-correlation choices, and bootstrap-based confidence bands for the nonparametric component. Simulation studies and an application to the epilepsy longitudinal study illustrate the finite-sample performance."}
{"id": "2602.14352", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.14352", "abs": "https://arxiv.org/abs/2602.14352", "authors": ["Zihui Ma", "Yiheng Chen", "Runlong Yu", "Afra Izzati Kamili", "Fangqi Chen", "Zhaoxi Zhang", "Juan Li", "Yuki Miura"], "title": "Bridging the Urban Divide: Adaptive Cross-City Learning for Disaster Sentiment Understanding", "comment": null, "summary": "Social media platforms provide a real-time lens into public sentiment during natural disasters; however, models built solely on textual data often reinforce urban-centric biases and overlook underrepresented communities. This paper introduces an adaptive cross-city learning framework that enhances disaster sentiment understanding by integrating mobility-informed behavioral signals and city similarity-based data augmentation. Focusing on the January 2025 Southern California wildfires, our model achieves state-of-the-art performance and reveals geographically diverse sentiment patterns, particularly in areas experiencing overlapping fire exposure or delayed emergency responses. We further identify positive correlations between emotional expressions and real-world mobility shifts, underscoring the value of combining behavioral and textual features. Through extensive experiments, we demonstrate that multimodal fusion and city-aware training significantly improve both accuracy and fairness. Collectively, these findings highlight the importance of context-sensitive sentiment modeling and provide actionable insights toward developing more inclusive and equitable disaster response systems."}
{"id": "2602.14286", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.14286", "abs": "https://arxiv.org/abs/2602.14286", "authors": ["Weijie Su", "Ruodu Wang", "Zinan Zhao"], "title": "Online LLM watermark detection via e-processes", "comment": null, "summary": "Watermarking for large language models (LLMs) has emerged as an effective tool for distinguishing AI-generated text from human-written content. Statistically, watermark schemes induce dependence between generated tokens and a pseudo-random sequence, reducing watermark detection to a hypothesis testing problem on independence. We develop a unified framework for LLM watermark detection based on e-processes, providing anytime-valid guarantees for online testing. We propose various methods to construct empirically adaptive e-processes that can enhance the detection power. In addition, theoretical results are established to characterize the power properties of the proposed procedures. Some experiments demonstrate that the proposed framework achieves competitive performance compared to existing watermark detection methods."}
{"id": "2602.14742", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14742", "abs": "https://arxiv.org/abs/2602.14742", "authors": ["Hadi Nemati", "Álvaro Ortega", "Enrique Lobato", "Luis Rouco"], "title": "A Multi-Bound Robust Optimization Approach for Renewable-Based VPP Market Participation Considering Intra-Hourly Uncertainty Exposure", "comment": null, "summary": "With the ongoing transition of electricity markets worldwide from hourly to intra-hourly bidding, market participants--especially Renewable Energy Sources (RES)--gain improved opportunities to adjust energy and reserve schedules and to benefit from more accurate higher-resolution forecasts. However, this shift requires participants to update decision-making frameworks and to strengthen uncertainty management in order to fully exploit the new market potential. In particular, Renewable-Based Virtual Power Plants (RVPPs) aggregating dispatchable and non-dispatchable RES must account for these changes through market-oriented scheduling methods that efficiently address multiple uncertainties, including electricity prices, RES generation, and demand consumption. In this vein, this paper proposes a multi-bound robust optimization framework to simultaneously capture these uncertainties, explicitly incorporate intra-hourly variability, and differentiate the deviation levels (frequent, moderate deviations and rare, extreme ones) of uncertain parameters. The proposed approach yields less conservative and more implementable bidding and scheduling decisions, thus improving RVPP profitability in both energy and reserve markets. Simulation studies compare the proposed method with standard robust optimization and evaluate the operational, market-strategy, and economic impacts of quarter-hourly versus hourly market resolution. Results indicate that the normalized absolute differences, across different uncertainty-handling strategies, between hourly and 15-minute schedules are 18.0--34.2% for day-ahead traded energy, and 28.7--65.6% and 10.1--16.3% for upward and downward reserve traded in the secondary reserve market, respectively. Furthermore, relative to classic robust optimization, the proposed multi-bound approach increases profit by 24.9--49.2% across the considered strategies."}
{"id": "2602.14405", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14405", "abs": "https://arxiv.org/abs/2602.14405", "authors": ["Tiantian Huang", "Buyang Li", "Rong Tang"], "title": "A convergent finite element method with minimal deformation rate for mean curvature flow", "comment": "77 pages", "summary": "We propose and analyze a fully discrete parametric finite element method with minimal deformation rate (MDR) for simulating the mean curvature flow of general closed surfaces in three dimensions. The method is formulated from a coupled system that enforces the mean curvature flow law for the normal velocity while introducing an artificial tangential velocity that minimizes the deformation-rate energy, thereby preserving mesh quality without requiring remeshing or reparametrization. An $L^{2}$-projected averaged normal vector is used in the scheme to facilitate a rigorous convergence analysis. Within the projected--distance framework, we establish the first complete convergence proof for a parametric finite element method that incorporates the MDR tangential motion without relying on evolution equations for the mean curvature or the normal vector, achieving optimal-order error estimates for finite elements of degree $k \\ge 3$. Numerical experiments corroborate the theoretical results and demonstrate that the proposed MDR method maintains mesh quality comparable to the Barrett--Garcke--Nürnberg method, for which convergence has not yet been established."}
{"id": "2602.13620", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.13620", "abs": "https://arxiv.org/abs/2602.13620", "authors": ["Xiaozhe Hu", "Sara Pollock", "Zhongqin Xue", "Yunrong Zhu"], "title": "An adaptive framework for first-order gradient methods", "comment": null, "summary": "Gradient methods are widely used in optimization problems. In practice, while the smoothness parameter can be estimated utilizing techniques such as backtracking, estimating the strong convexity parameter remains a challenge; moreover, even with the optimal parameter choice, convergence can be slow. In this work, we propose a framework for dynamically adapting the step size and momentum parameters in first-order gradient methods for the optimization problem, without prior knowledge of the strong convexity parameter. The main idea is to use the geometric average of the ratios of successive residual norms as an empirical estimate of the upper bound on the convergence rate, which in turn allows us to adaptively update the algorithm parameters. The resulting algorithms are simple to implement, yet efficient in practice, requiring only a few additional computations on existing information. The proposed adaptive gradient methods are shown to converge at least as fast as gradient descent for quadratic optimization problems. Numerical experiments on both quadratic and nonlinear problems validate the effectiveness of the proposed adaptive algorithms. The results show that the adaptive algorithms are comparable to their counterparts using optimal parameters, and in some cases, they capture local information and exhibit improved performance."}
{"id": "2602.13632", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.13632", "abs": "https://arxiv.org/abs/2602.13632", "authors": ["Hongchao Li", "Xie-Hang Yu", "Masaya Nakagawa", "Masahito Ueda"], "title": "Ward-Takahashi Identity and Gauge-Invariant Response Theory for Open Quantum Systems", "comment": "5 pages, 1 figure + 12 pages", "summary": "We derive the Ward-Takahashi identity and establish the gauge-invariant response theory for open quantum systems described by Lindbladians to show that particle-number conservation is not necessary to satisfy gauge invariance. We construct an observable which can be used to test the gauge invariance in the absence of particle-number conservation. We derive the low-energy collective modes that emerge as a consequence of gauge invariance in open quantum systems, and find that two-body loss induces diffusive modes in dissipative Bardeen-Cooper-Schrieffer (BCS) superconductivity. Possible experimental situations for testing gauge invariance in open quantum systems are also discussed."}
{"id": "2602.14711", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.14711", "abs": "https://arxiv.org/abs/2602.14711", "authors": ["Yi-Yan Wang", "Ping Su", "Kai-Yuan Hu", "Yi-Ran Li", "Na Li", "Ying Zhou", "Dan-Dan Wu", "Yan Sun", "Qiu-Ju Li", "Xia Zhao", "Hui Liang", "Xue-Feng Sun"], "title": "The distinction of time-reversal-like degeneracy by electronic transport in a new compound", "comment": null, "summary": "We report the discovery of a new compound, Ce$_3$MgBi$_5$, and reveal the hidden time-reversal-like degenerate states within it. Ce$_3$MgBi$_5$ is an antiferromagnet with the distorted kagome lattice of Ce atoms, in which several fractional magnetization plateaus emerge with the increase of magnetic field. At the 1/2 magnetization plateau, obvious hysteresis has been observed in the magnetoresistance and Hall resistivity during the rise and fall of the magnetic field. However, hysteresis vanishes in the corresponding measurements of magnetization, indicating the existence of degenerate states with the same net magnetization but different electronic transport properties. The degenerate states can be connected by the time-reversal-like operation. In addition, by comparing with HoAgGe, it is suggested that the special crystal structure in Ce$_3$MgBi$_5$ may have a shielding effect on the time-reversal-like operation, thereby affecting the distinction of degenerate states. Our work establishes Ce$_3$MgBi$_5$ as an example of utilizing electronic transport properties to identify and distinguish hidden symmetries in frustrated magnetic systems."}
{"id": "2602.14947", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14947", "abs": "https://arxiv.org/abs/2602.14947", "authors": ["Junyi Li", "Tim Foissner", "Floran Martin", "Antti Piippo", "Marko Hinkkanen"], "title": "Gradient Networks for Universal Magnetic Modeling of Synchronous Machines", "comment": null, "summary": "This paper presents a physics-informed neural network approach for dynamic modeling of saturable synchronous machines, including cases with spatial harmonics. We introduce an architecture that incorporates gradient networks directly into the fundamental machine equations, enabling accurate modeling of the nonlinear and coupled electromagnetic constitutive relationship. By learning the gradient of the magnetic field energy, the model inherently satisfies energy balance (reciprocity conditions). The proposed architecture can universally approximate any physically feasible magnetic behavior and offers several advantages over lookup tables and standard machine learning models: it requires less training data, ensures monotonicity and reliable extrapolation, and produces smooth outputs. These properties further enable robust model inversion and optimal trajectory generation, often needed in control applications. We validate the proposed approach using measured and finite-element method (FEM) datasets from a 5.6-kW permanent-magnet (PM) synchronous reluctance machine. Results demonstrate accurate and physically consistent models, even with limited training data."}
{"id": "2602.14652", "categories": ["math.OC", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14652", "abs": "https://arxiv.org/abs/2602.14652", "authors": ["Anqi Dong", "Karl H. Johansson", "Johan Karlsson"], "title": "Temporally Flexible Transport Scheduling on Networks with Departure-Arrival Constriction and Nodal Capacity Limits", "comment": "29 pages, 9 figures", "summary": "We investigate the optimal transport (OT) problem over networks, wherein supply and demand are conceptualized as temporal marginals governing departure rates of particles from source nodes and arrival rates at sink nodes. This setting extends the classical OT framework, where all mass is conventionally assumed to depart at $t = 0$ and arrive at $t = t_f$. Our generalization accommodates departures and arrivals at specified times, referred as departure--arrival(DA) constraints. In particular, we impose nodal-temporal flux constraints at source and sink nodes, characterizing two distinct scenarios: (i) Independent DA constraints, where departure and arrival rates are prescribed independently, and (ii) Coupled DA constraints, where each particle's transportation time span is explicitly specified. We establish that OT with independent DA constraints admits a multi-marginal optimal transport formulation, while the coupled DA case aligns with the unequal-dimensional OT framework. For line graphs, we analyze the existence and uniqueness of the solution path. For general graphs, we use a constructive path-based reduction and optimize over a prescribed set of paths. From a computational perspective, we consider entropic regularization of the original problem to efficiently provide solutions based on multi-marginal Sinkhorn method, making use of the graphical structure of the cost to further improve scalability. Our numerical simulation further illustrates the linear convergence rate in terms of marginal violation."}
{"id": "2602.14303", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.14303", "abs": "https://arxiv.org/abs/2602.14303", "authors": ["Isqeel Ogunsola", "Nurudeen Ajadi", "Gboyega Adepoju"], "title": "A New SMP Transformed Standard Weibull Distribution for Health Data Modelling", "comment": null, "summary": "New methods of extending base distributions are always invoke to increase their adaptability in modeling real life data. Recently, SMP method was introduced but Weibull distribution is yet to be explored through this method. First, we provide updated review on SMP transformed distributions. We then proposed and developed another extended Weibull distribution through this technique named SMPtW. Importantly, twelve of its statistical properties - reliability measures, quantile function, moment, stress-strength, mean waiting time, moment generating function, characteristics function, renyi entropy, order statistics, mean residual life and mode, were derived and studied extensively. The hazard function has a decreasing, increasing and constant shapes. We found a relation between the quantile of SMPtW and that of SMP Pareto distribution despite their difference in density functions. We adopt the inverse transform approach in random number generation and through simulation we evaluate maximum likelihood estimates (MLE) performance of its parameters. The result showed that MLE is consistent all through. The performance of the distribution was then examined using health dataset compared with five similar distributions. The results showed that three parameters SMPtW performed best among the competing models."}
{"id": "2602.14765", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.14765", "abs": "https://arxiv.org/abs/2602.14765", "authors": ["Ariana R. Mendez-Castillo", "Rodrigo Aldana-Lopez", "Antonio Ramirez-Trevino", "Rosario Aragues", "David Gomez-Gutierrez"], "title": "Hierarchical parameter estimation for distributed networked systems: a dynamic consensus approach", "comment": null, "summary": "This work introduces a novel two-stage distributed framework to globally estimate constant parameters in a networked system, separating shared information from local estimation. The first stage uses dynamic average consensus to aggregate agents' measurements into surrogates of centralized data. Using these surrogates, the second stage implements a local estimator to determine the parameters. By designing an appropriate consensus gain, the persistence of excitation of the regressor matrix is achieved, and thus, exponential convergence of a local Gradient Estimator (GE) is guaranteed. The framework facilitates its extension to switched network topologies, quantization, and the heterogeneous substitution of the GE with a Dynamic Regressor Extension and Mixing (DREM) estimator, which supports relaxed excitation requirements."}
{"id": "2602.14449", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14449", "abs": "https://arxiv.org/abs/2602.14449", "authors": ["Zhuang-Ao He", "Meiyue Shao"], "title": "On Two-Stage Householder Orthogonalization", "comment": null, "summary": "Two-stage orthogonalization is essential in numerical algorithms such as Krylov subspace methods. For this task we need to orthogonalize a matrix $A$ against another matrix $V$ with orthonormal columns. A common approach is to employ the block Gram--Schmidt algorithm. However, its stability largely depends on the condition number of $[V,A]$. While performing a Householder orthogonalization on $[V,A]$ is unconditionally stable, it does not utilize the knowledge that $V$ has orthonormal columns. To address these issues, we propose a two-stage Householder orthogonalization algorithm based on the generalized Householder transformation. Instead of explicitly orthogonalizing the entire $V$, our algorithm only needs to orthogonalizes a square submatrix of $V$. Theoretical analysis and numerical experiments demonstrate that our method is also unconditionally stable."}
{"id": "2602.13646", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.13646", "abs": "https://arxiv.org/abs/2602.13646", "authors": ["Jun Chen", "Tianyi Zhu", "Haishan Ye", "Lina Liu", "Guang Dai", "Yong Liu", "Yunliang Jiang", "Ivor W. Tsang"], "title": "Riemannian Momentum Tracking: Distributed Optimization with Momentum on Compact Submanifolds", "comment": null, "summary": "Gradient descent with momentum has been widely applied in various signal processing and machine learning tasks, demonstrating a notable empirical advantage over standard gradient descent. However, momentum-based distributed Riemannian algorithms have been only scarcely explored. In this paper, we propose Riemannian Momentum Tracking (RMTracking), a decentralized optimization algorithm with momentum over a compact submanifold. Given the non-convex nature of compact submanifolds, the objective function, composed of a finite sum of smooth (possibly non-convex) local functions, is minimized across agents in an undirected and connected network graph. With a constant step-size, we establish an $\\mathcal{O}(\\frac{1-β}{K})$ convergence rate of the Riemannian gradient average for any momentum weight $β\\in [0,1)$. Especially, RMTracking can achieve a convergence rate of $\\mathcal{O}(\\frac{1-β}{K})$ to a stationary point when the step-size is sufficiently small. To best of our knowledge, RMTracking is the first decentralized algorithm to achieve exact convergence that is $\\frac{1}{1-β}$ times faster than other related algorithms. Finally, we verify these theoretical claims through numerical experiments on eigenvalue problems."}
{"id": "2602.13638", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13638", "abs": "https://arxiv.org/abs/2602.13638", "authors": ["Yingkai Ouyang", "Gavin K. Brennen"], "title": "A theory of quantum error correction for permutation-invariant codes", "comment": "15 pages, 2 sides, split from the QEC part of 2212.06285v4, and improved with new algorithms", "summary": "We present for the first time a general theory of error correction for permutation invariant (PI) codes. Using representation theory of the symmetric group we construct efficient algorithms that can correct any correctible error on any PI code. These algorithms involve measurements of total angular momentum, quantum Schur transforms or logical state teleportations, and geometric phase gates. For erasure errors, or more generally deletion errors, on certain PI codes, we give a simpler quantum error correction algorithm."}
{"id": "2602.14769", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14769", "abs": "https://arxiv.org/abs/2602.14769", "authors": ["Zi-Yang Zhang", "Donghoon Kim", "Ji-Yao Chen"], "title": "Variational preparation and characterization of chiral spin liquids in quantum circuits", "comment": "19 pages, 15 figures", "summary": "Quantum circuits have been shown to be a fertile ground for realizing long-range entangled phases of matter. While various quantum double models with non-chiral topological order have been theoretically investigated and experimentally implemented, the realization and characterization of chiral topological phases have remained less explored. Here we show that chiral topological phases in spin systems, i.e., chiral spin liquids, can be prepared in quantum circuits using the variational quantum eigensolver (VQE) framework. On top of the VQE ground state, signatures of the chiral topological order are revealed using the recently proposed tangent space excitation ansatz for quantum circuits. We show that, both topological ground state degeneracy and the chiral edge mode can be faithfully captured by this approach. We demonstrate our approach using the Kitaev honeycomb model, finding excellent agreement of low-energy excitation spectrum on quantum circuits with exact solution in all topological sectors. Further applying this approach to a non-exactly solvable chiral spin liquid model on square lattice, the results suggest this approach works well even when the topological sectors are not exactly known."}
{"id": "2602.13615", "categories": ["math.OC", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.13615", "abs": "https://arxiv.org/abs/2602.13615", "authors": ["Iasson Karafyllis", "Miroslav Krstic"], "title": "On the Existence of Periodic Solutions with Applications to Extremum-Seeking", "comment": "27 pages", "summary": "This paper provides two results that are useful in the study of the existence and the stability properties of a periodic solution for a given dynamical system. The first result deals with scalar time-periodic systems and establishes the equivalence of the existence of a periodic solution and the existence of a bounded solution. The second result provides sufficient conditions for the existence and the stability of a periodic solution for a time-periodic dynamical system. Both results are applied to extremum seeking problems for a static output map with no plant dynamics and novel non-local results are provided without the use of averaging theorems and singular perturbation arguments."}
{"id": "2602.14387", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.14387", "abs": "https://arxiv.org/abs/2602.14387", "authors": ["Jon Wakefield", "Jitong Jiang", "Yunhan Wu"], "title": "Automatic Variance Adjustment for Small Area Estimation", "comment": null, "summary": "Small area estimation (SAE) is a common endeavor and is used in a variety of disciplines. In low- and middle-income countries (LMICs), in which household surveys provide the most reliable and timely source of data, SAE is vital for highlighting disparities in health and demographic indicators. Weighted estimators are ideal for inference, but for fine geographical partitions in which there are insufficient data, SAE models are required. The most common approach is Fay-Herriot area-level modeling in which the data requirements are a weighted estimate and an associated variance estimate. The latter can be undefined or unstable when data are sparse and so we propose a principled modification which is based on augmenting the available data with a prior sample from a hypothetical survey. This adjustment is generally available, respects the design and is simple to implement. We examine the empirical properties of the adjustment through simulation and illustrate its use with wasting data from a 2018 Zambian Demographic and Health Survey. The modification is implemented as an automatic remedy in the R package surveyPrev, which provides a comprehensive suite of tools for conducing SAE in LMICs."}
{"id": "2602.14909", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14909", "abs": "https://arxiv.org/abs/2602.14909", "authors": ["Tyrone Fernando"], "title": "Unified Eigenvalue-Eigenspace Criteria for Functional Properties of Linear Systems and the Generalized Separation Principle", "comment": "Submitted to a journal", "summary": "Classical controllability and observability characterise reachability and reconstructibility of the full system state and admit equivalent geometric and eigenvalue-based Popov-Belevitch-Hautus (PBH) tests. Motivated by large-scale and networked systems where only selected linear combinations of the state are of interest, this paper studies functional generalisations of these properties. A PBH-style framework for functional system properties is developed, providing necessary and sufficient spectral characterisations. The results apply uniformly to diagonalizable and non-diagonalizable systems and recover the classical PBH tests as special cases.\n  Two new intrinsic notions are introduced: intrinsic functional controllability, and intrinsic functional stabilizability. These intrinsic properties are formulated directly in terms of invariant subspaces associated with the functional and provide verifiable conditions for the existence of admissible augmentations required for functional controller design and observer-based functional controller design. The intrinsic framework enables the generalized separation principle at the functional level, establishing that functional controllers and functional observers can be designed independently. Illustrative examples demonstrate the theory and highlight situations where functional control and estimation are possible despite lack of full-state controllability or observability."}
{"id": "2602.14504", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14504", "abs": "https://arxiv.org/abs/2602.14504", "authors": ["Naveed Ahmed", "Abhinav Jha"], "title": "Adaptive Finite Elements with Algebraic Stabilization for Convection-Dominated Transport", "comment": null, "summary": "We present a numerical investigation of residual-based a posteriori error estimation for finite element discretizations of convection--diffusion equations stabilized by algebraic flux correction and related algebraic stabilization techniques. In particular, we consider AFC schemes employing the BJK and Monolithic Convex (MC) limiters and algebraically stabilized methods including MUAS, SMUAS, and the BBK approach. The performance of the estimators and limiters are studied on adaptively refined meshes for several two-dimensional test problems, including boundary layers, interior layers, and a nonlinear convection problem with solution-dependent transport.\n  The experiments assess accuracy, preservation of the discrete maximum principle, adaptive mesh behaviour, and computational efficiency. The results show that the interaction between stabilization and a posteriori error estimation depends strongly on mesh alignment and on the character of the convection field. In particular, for problems with moving or curved layers, the behaviour of the limiters differs significantly: strongly upwind-biased limiters provide the most accurate solutions, while smoother algebraic stabilizations lead to more efficient nonlinear iterations. The study also indicates that residual-based estimators remain reliable for both linear and nonlinear problems but may react to changes in limiter activation during adaptive refinement.\n  Overall, the numerical results clarify the practical behaviour of several widely used stabilization techniques within an adaptive framework and highlight aspects that are not yet fully explained by the current theory, particularly for nonlinear transport problems."}
{"id": "2602.13654", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.13654", "abs": "https://arxiv.org/abs/2602.13654", "authors": ["Henk J. van Waarde", "Jeremy Coulson", "Alberto Padoan"], "title": "From time series to dissipativity of linear systems with dynamic supply rates", "comment": null, "summary": "This paper studies the problem of verifying dissipativity of linear time-invariant (LTI) systems using input-output data. We leverage behavioral systems theory to express dissipativity in terms of quadratic difference forms (QDFs), allowing the study of general dynamic quadratic supply rates. We work under the assumptions that the data-generating system is controllable, and an upper bound is given on its lag. As our main results, we provide sufficient conditions for the data to be informative for dissipativity. We also show that for a specific class of static supply rates, these conditions are both necessary and sufficient. For the latter supply rates, it turns out that certification of dissipativity is only possible from data that enable unique system identification. As auxiliary results, we highlight some properties of QDFs, such as upper bounds on the degree of storage functions."}
{"id": "2602.13648", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13648", "abs": "https://arxiv.org/abs/2602.13648", "authors": ["Adam Fredriksson", "Erik Sjöqvist"], "title": "Comment on \"Evolution Operator Can Always Be Separated into the Product of Holonomy and Dynamic Operators\"", "comment": "Comment on arXiv:2311.09597", "summary": "We show that the claim in Ref. [PRL 131, 200202 (2023)], that the quantum time evolution always can be written as a product of a holonomy operator and a dynamic operator, is false, as it is based on a circular use of the time evolution operator."}
{"id": "2602.14796", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.14796", "abs": "https://arxiv.org/abs/2602.14796", "authors": ["Don Rolih", "Rok Žitko"], "title": "Strongly correlated Josephson junction: proximity effect in the single-layer Hubbard model", "comment": null, "summary": "We study the proximity effect in the Hubbard model coupled to BCS superconductors describing a single-layer strongly correlated electron system in a phase-biased Josephson junction. We find two distinct gapped solutions, one Mott-like insulating (M-phase) and one proximitized superconducting phase (S-phase), separated by first-order transition with hysteresis. In the M-phase the large correlation charge gap strongly suppresses the critical current, while the S-phase behaves as a $0$-junction, with a proximitized gap that closes for $φ=π$ to yield a correlated metal. Phase bias and junction transparency can thus serve as tuning knobs to switch between conducting and insulating regimes. Working within the dynamical mean field theory using the numerical renormalization group as the impurity solver, we associate M- and S-phase solutions with the doublet and singlet fixed points of the underlying superconducting Anderson impurity problem. We obtain detailed insight into the spectral structure on all energy scales. In the M-phase, the self-energy has sub-gap resonances symmetrically located around the Fermi level resulting from the splitting of the ''mid-gap pole'' found in Mott insulators; this structure accounts for phase insensitivity."}
{"id": "2602.14537", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14537", "abs": "https://arxiv.org/abs/2602.14537", "authors": ["Xu Shang", "Masih Haseli", "Jorge Cortés", "Yang Zheng"], "title": "On the Existence of Koopman Linear Embeddings for Controlled Nonlinear Systems", "comment": null, "summary": "Koopman linear representations have become a popular tool for control design of nonlinear systems, yet it remains unclear when such representations are exact. In this paper, we establish sufficient and necessary conditions under which a controlled nonlinear system admits an exact finite-dimensional Koopman linear representation, which we term Koopman linear embedding. We show that such a system must be transformable into a special control-affine preserved (CAP) structure, which enforces affine dependence of the state on the control input and isolates all nonlinearities into an autonomous subsystem. We further prove that this autonomous subsystem must itself admit a finite-dimensional Koopman linear model with a sufficiently-rich Koopman invariant subspace. Finally, we introduce a symbolic procedure to determine whether a given controlled nonlinear system admits the CAP structure, thereby elucidating whether Koopman approximation errors arise from intrinsic system dynamics or from the choice of lifting functions."}
{"id": "2602.14414", "categories": ["stat.ME", "econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.14414", "abs": "https://arxiv.org/abs/2602.14414", "authors": ["Abhinandan Dalal", "Iris Horng", "Yang Feng", "Dylan S. Small"], "title": "The Role of Measured Covariates in Assessing Sensitivity to Unmeasured Confounding", "comment": null, "summary": "Sensitivity analysis is widely used to assess the robustness of causal conclusions in observational studies, yet its interaction with the structure of measured covariates is often overlooked. When latent confounders cannot be directly adjusted for and are instead controlled using proxy variables, strong associations between exposure and measured proxies can amplify sensitivity to residual confounding. We formalize this phenomenon in linear regression settings by showing that a simple ratio involving the exposure model coefficient and residual exposure variance provides an observable measure of this increased sensitivity. Applying our framework to smoking and lung cancer, we document how growing socioeconomic stratification in smoking behavior over time leads to heightened sensitivity to unmeasured confounding in more recent data. These results highlight the importance of multicollinearity when interpreting sensitivity analyses based on proxy adjustment."}
{"id": "2602.14939", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14939", "abs": "https://arxiv.org/abs/2602.14939", "authors": ["Sidharthenee Nayak", "Victor Sam Moses Babu", "Chandrashekhar Narayan Bhende", "Pratyush Chakraborty", "Mayukha Pal"], "title": "Fault Detection in Electrical Distribution System using Autoencoders", "comment": null, "summary": "In recent times, there has been considerable interest in fault detection within electrical power systems, garnering attention from both academic researchers and industry professionals. Despite the development of numerous fault detection methods and their adaptations over the past decade, their practical application remains highly challenging. Given the probabilistic nature of fault occurrences and parameters, certain decision-making tasks could be approached from a probabilistic standpoint. Protective systems are tasked with the detection, classification, and localization of faulty voltage and current line magnitudes, culminating in the activation of circuit breakers to isolate the faulty line. An essential aspect of designing effective fault detection systems lies in obtaining reliable data for training and testing, which is often scarce. Leveraging deep learning techniques, particularly the powerful capabilities of pattern classifiers in learning, generalizing, and parallel processing, offers promising avenues for intelligent fault detection. To address this, our paper proposes an anomaly-based approach for fault detection in electrical power systems, employing deep autoencoders. Additionally, we utilize Convolutional Autoencoders (CAE) for dimensionality reduction, which, due to its fewer parameters, requires less training time compared to conventional autoencoders. The proposed method demonstrates superior performance and accuracy compared to alternative detection approaches by achieving an accuracy of 97.62% and 99.92% on simulated and publicly available datasets."}
{"id": "2602.14588", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14588", "abs": "https://arxiv.org/abs/2602.14588", "authors": ["Alexander Freiszlinger", "Dirk Pauly", "Dirk Praetorius", "Michael Schomburg"], "title": "New a posteriori error estimates for full-space transmission problems", "comment": null, "summary": "In the present work, we derive functional upper bounds for the potential error arising from finite-element boundary-element coupling formulations for a nonlinear Poisson-type transmission problem. The proposed a posteriori error estimates are independent of the precise discretization scheme and provide guaranteed upper bounds for the potential error. The computation of these upper bounds is based on the solutions of local auxiliary finite element problems on patches in the interior domain and in a strip domain along the coupling boundary. Numerical experiments illustrate the performance of the proposed error estimation strategy for a related adaptive mesh-refinement strategy."}
{"id": "2602.13856", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.13856", "abs": "https://arxiv.org/abs/2602.13856", "authors": ["Gengchen Li", "Depeng Gao", "Wenliang Yin", "Hongwei Lin"], "title": "Persistent homology-based explicit topological control for 2D topology optimization with MMA", "comment": null, "summary": "Controlling structural complexity, particularly the number of holes, remains a fundamental challenge in topology optimization, with significant implications for both theoretical analysis and manufacturability. Most existing approaches rely on indirect strategies, such as filtering techniques, minimum length-scale control, or specific level-set initializations, which influence topology only implicitly and do not allow precise regulation of topological features. In this work, we propose an explicit and differentiable topology-control framework by integrating persistent homology into the classical minimum-compliance topology optimization problem. The design domain and density field are represented using non-uniform rational B-splines (NURBS), while persistence diagrams are employed to rigorously and quantitatively characterize topological features. Given a prescribed number of holes, a differentiable topology-aware objective is constructed from the persistence pairs and incorporated into the compliance objective, leading to a unified optimization formulation. The resulting problem is efficiently solved using the method of moving asymptotes (MMA).Numerical experiments demonstrate that the proposed approach enables explicit control over structural connectivity and the number of holes, thereby providing a systematic and mathematically grounded strategy for topology regulation."}
{"id": "2602.13667", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13667", "abs": "https://arxiv.org/abs/2602.13667", "authors": ["Tsendsuren Khurelbaatar", "R. T. Sang", "Igor Litvinyuk"], "title": "Strong-Field Quantum Metrology Beyond the Standard Quantum Limit", "comment": null, "summary": "Bridging quantum optics and strong-field physics provides a pathway to explore how quantum light shapes extreme nonlinear light-matter interactions. However, direct characterization of non-classical light at damage-threshold intensities remains an open question. Here, we theoretically investigate the impact of photon-number fluctuations of squeezed light on strong-field photoelectron holography using a quantum-optical strong-field approximation. We identify a mechanism, ponderomotive dephasing, whereby the inherent quantum fluctuations of the driving field dictate the stability of the electron's semiclassical action. While amplitude-squeezed light stabilizes the action to enhance holographic contrast, phase-squeezed light amplifies photon-number noise, causing a rapid collapse of fringe visibility. This quantum-optical sensitivity follows a steep quartic wavelength scaling, rendering mid-infrared drivers uniquely sensitive to the field's underlying quantum nature. Crucially, we show that the collapse of holographic contrast is not a loss of information but a metrological gain. By evaluating the Classical Fisher Information, we identify a \"dark-port\" mechanism in the tunneling tail that enables the estimation of field quadrature noise beyond the Standard Quantum Limit. This fundamental trade-off between structural imaging fidelity and statistical sensitivity establishes the framework for Attosecond Quantum Tomography: an in-situ, reference-free protocol to reconstruct the Wigner distribution of intense quantum light. Our results identify strong-field ionization as a nonlinear quantum transducer, bridging attosecond electron dynamics with quantum information science."}
{"id": "2602.14884", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.14884", "abs": "https://arxiv.org/abs/2602.14884", "authors": ["A. S. Sukhanov", "S. Gebel", "A. N. Korshunov", "N. D. Andriushin", "M. S. Pavlovskii", "Y. Gao", "K. M. Moya", "K. Allen", "E. Morosan", "M. C. Rahn"], "title": "Electron-phonon coupling in EuAl4 under hydrostatic pressure", "comment": null, "summary": "In the intermetallid rare-earth tetragonal EuAl4 system, competing itinerant exchange mechanisms lead to a complex magnetic phase diagram, featuring a centrosymmetric skyrmion lattice. Previous inelastic x-ray scattering (IXS) experiments revealed that the incommensurate charge-density wave (CDW) transition in EuAl4 (TCDW = 142 K) is driven by momentum-dependent electron-phonon coupling (EPC). We present the results of IXS under high hydrostatic pressure induced by diaond anvils and show how the EPC in EuAl4 is renormalized and suppressed in the material's temperature-pressure phase diagram. Our findings highlight the crucial role of momentum-dependent EPC in the formation of the CDW in EuAl4 and provide further insights into how external pressure can be used to tune charge ordering in quantum materials."}
{"id": "2602.14652", "categories": ["math.OC", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14652", "abs": "https://arxiv.org/abs/2602.14652", "authors": ["Anqi Dong", "Karl H. Johansson", "Johan Karlsson"], "title": "Temporally Flexible Transport Scheduling on Networks with Departure-Arrival Constriction and Nodal Capacity Limits", "comment": "29 pages, 9 figures", "summary": "We investigate the optimal transport (OT) problem over networks, wherein supply and demand are conceptualized as temporal marginals governing departure rates of particles from source nodes and arrival rates at sink nodes. This setting extends the classical OT framework, where all mass is conventionally assumed to depart at $t = 0$ and arrive at $t = t_f$. Our generalization accommodates departures and arrivals at specified times, referred as departure--arrival(DA) constraints. In particular, we impose nodal-temporal flux constraints at source and sink nodes, characterizing two distinct scenarios: (i) Independent DA constraints, where departure and arrival rates are prescribed independently, and (ii) Coupled DA constraints, where each particle's transportation time span is explicitly specified. We establish that OT with independent DA constraints admits a multi-marginal optimal transport formulation, while the coupled DA case aligns with the unequal-dimensional OT framework. For line graphs, we analyze the existence and uniqueness of the solution path. For general graphs, we use a constructive path-based reduction and optimize over a prescribed set of paths. From a computational perspective, we consider entropic regularization of the original problem to efficiently provide solutions based on multi-marginal Sinkhorn method, making use of the graphical structure of the cost to further improve scalability. Our numerical simulation further illustrates the linear convergence rate in terms of marginal violation."}
{"id": "2602.14440", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.14440", "abs": "https://arxiv.org/abs/2602.14440", "authors": ["Harri Vanhems", "Yue Zhao", "Peng Shi", "Archer Y. Yang"], "title": "CAIRO: Decoupling Order from Scale in Regression", "comment": null, "summary": "Standard regression methods typically optimize a single pointwise objective, such as mean squared error, which conflates the learning of ordering with the learning of scale. This coupling renders models vulnerable to outliers and heavy-tailed noise. We propose CAIRO (Calibrate After Initial Rank Ordering), a framework that decouples regression into two distinct stages. In the first stage, we learn a scoring function by minimizing a scale-invariant ranking loss; in the second, we recover the target scale via isotonic regression. We theoretically characterize a class of \"Optimal-in-Rank-Order\" objectives -- including variants of RankNet and Gini covariance -- and prove that they recover the ordering of the true conditional mean under mild assumptions. We further show that subsequent monotone calibration guarantees recovery of the true regression function. Empirically, CAIRO combines the representation learning of neural networks with the robustness of rank-based statistics. It matches the performance of state-of-the-art tree ensembles on tabular benchmarks and significantly outperforms standard regression objectives in regimes with heavy-tailed or heteroskedastic noise."}
{"id": "2602.14947", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14947", "abs": "https://arxiv.org/abs/2602.14947", "authors": ["Junyi Li", "Tim Foissner", "Floran Martin", "Antti Piippo", "Marko Hinkkanen"], "title": "Gradient Networks for Universal Magnetic Modeling of Synchronous Machines", "comment": null, "summary": "This paper presents a physics-informed neural network approach for dynamic modeling of saturable synchronous machines, including cases with spatial harmonics. We introduce an architecture that incorporates gradient networks directly into the fundamental machine equations, enabling accurate modeling of the nonlinear and coupled electromagnetic constitutive relationship. By learning the gradient of the magnetic field energy, the model inherently satisfies energy balance (reciprocity conditions). The proposed architecture can universally approximate any physically feasible magnetic behavior and offers several advantages over lookup tables and standard machine learning models: it requires less training data, ensures monotonicity and reliable extrapolation, and produces smooth outputs. These properties further enable robust model inversion and optimal trajectory generation, often needed in control applications. We validate the proposed approach using measured and finite-element method (FEM) datasets from a 5.6-kW permanent-magnet (PM) synchronous reluctance machine. Results demonstrate accurate and physically consistent models, even with limited training data."}
{"id": "2602.14609", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14609", "abs": "https://arxiv.org/abs/2602.14609", "authors": ["Paola Boito", "Dario Fasino", "Beatrice Meini"], "title": "Advances on the recovery of (perturbed) Cauchy matrices", "comment": null, "summary": "Given a (possibly approximate) Cauchy matrix, how can we efficiently compute its generators? Expanding on previous work by Liesen and Luce [Linear Algebra Appl. 493 (2016) 261--280], we present a general family of algorithms for Cauchy parameter recovery, together with new error estimates. We also introduce a displacement-based approximation, which leads to a new algorithm for Cauchy parameter recovery. Numerical experiments show that the algorithm based on the displacement approximation is generally more accurate than the other algorithms."}
{"id": "2602.13965", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.13965", "abs": "https://arxiv.org/abs/2602.13965", "authors": ["Tien-Son Pham"], "title": "The local minimality of differentiable functions", "comment": null, "summary": "In this paper we present necessary and sufficient conditions (in terms of Łojasiewicz inequalities) for the stability of local minimum points in smooth unconstrained optimization. In particular, we derive a sufficient condition for which the local minimum property of a given function is determined by its Taylor polynomial of a certain degree."}
{"id": "2602.13686", "categories": ["quant-ph", "cs.DM", "math-ph", "math.GR"], "pdf": "https://arxiv.org/pdf/2602.13686", "abs": "https://arxiv.org/abs/2602.13686", "authors": ["Tatsuya Tsurii", "Naoharu Ito"], "title": "A group structure arising from Grover walks on complete graphs with self-loops and its application", "comment": "13 pages", "summary": "This paper introduces a group-theoretic framework to analyze the algebraic structure of the Grover walk on a complete graph with self-loops. We construct a group generated by the Grover matrix and a diagonal matrix whose entries are powers of a complex root of unity. We then characterize the resulting quotient group, which is defined using a subgroup formed by commutators involving these matrices. We show that this quotient group is isomorphic to a finite cyclic group whose structure depends on the parity of the number of vertices. This group-theoretic characterization reveals underlying symmetries in the time evolution of the Grover walk and provides an algebraic framework for understanding its periodic behavior."}
{"id": "2602.14892", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.14892", "abs": "https://arxiv.org/abs/2602.14892", "authors": ["Shengtao Jiang", "Steven R. White", "Steven A. Kivelson", "Hong-Chen Jiang"], "title": "Competing states in the $S=1/2$ triangular-lattice $J_1$-$J_2$ Heisenberg model: a dynamical density-matrix renormalization group study", "comment": "5+5+9 pages, 3+3+9 figures", "summary": "Previous studies of the $S=1/2$ triangular-lattice $J_1$--$J_2$ Heisenberg antiferromagnet have inferred the existence of a non-magnetic ground-state phase for an intermediate range of $J_2$, but disagree concerning whether it is a gapped $\\mathbb{Z}_2$ quantum spin liquid (QSL), a gapless (Dirac) QSL, or a weakly symmetry-broken phase. Using an improved dynamical density-matrix renormalization group method, we investigate the relevant intermediate $J_2$ regime for cylinders with circumferences from 6 to 9. Depending on the initial state and boundary conditions, we find two {\\it distinct} variational states. The higher energy state is consistent with a Dirac QSL. In the lower-energy state, both the static and dynamical properties are qualitatively similar to the magnetically ordered state at $J_2=0$, suggestive of either a weakly magnetically ordered non-QSL or a gapped QSL proximate to a continuous transition to such an ordered state."}
{"id": "2602.14830", "categories": ["math.OC", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14830", "abs": "https://arxiv.org/abs/2602.14830", "authors": ["Souvik Das", "Luca Schenato", "Subhrakanti Dey"], "title": "On Convergence Analysis of Network-GIANT: An approximate Hessian-based fully distributed optimization algorithm", "comment": "11 pages, 9 figures", "summary": "In this paper, we present a detailed convergence analysis of a recently developed approximate Newton-type fully distributed optimization method for smooth, strongly convex local loss functions, called Network-GIANT, which has been empirically illustrated to show faster linear convergence properties while having the same communication complexity (per iteration) as its first order distributed counterparts. By using consensus based parameter updates, and a local Hessian based descent direction at the individual nodes with gradient tracking, we first explicitly characterize a global linear convergence rate for Network-GIANT, which can be computed as the spectral radius of a $3 \\times 3$ matrix dependent on the Lipschitz continuity ($L$) and strong convexity ($μ$) parameters of the objective functions, and the spectral norm ($σ$) of the underlying undirected graph represented by a doubly stochastic consensus matrix. We provide an explicit bound on the step size parameter $η$, below which this spectral radius is guaranteed to be less than $1$. Furthermore, we derive a mixed linear-quadratic inequality based upper bound for the optimality gap norm, which allows us to conclude that, under small step size values, asymptotically, as the algorithm approaches the global optimum, it achieves a locally linear convergence rate of $1-η(1 -\\fracγμ)$ for Network-GIANT, provided the Hessian approximation error $γ$ (between the harmonic mean of the local Hessians and the global hessian (the arithmetic mean of the local Hessians) is smaller than $μ$. This asymptotically linear convergence rate of $\\approx 1-η$ explains the faster convergence rate of Network-GIANT for the first time. Numerical experiments are carried out with a reduced CovType dataset for binary logistic regression over a variety of graphs to illustrate the above theoretical results."}
{"id": "2602.14607", "categories": ["stat.ME", "cs.LG", "math.NA", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.14607", "abs": "https://arxiv.org/abs/2602.14607", "authors": ["Nathan Kirk"], "title": "A Bayesian Approach to Low-Discrepancy Subset Selection", "comment": "13 pages, 3 figures, mODa14", "summary": "Low-discrepancy designs play a central role in quasi-Monte Carlo methods and are increasingly influential in other domains such as machine learning, robotics and computer graphics, to name a few. In recent years, one such low-discrepancy construction method called subset selection has received a lot of attention. Given a large population, one optimally selects a small low-discrepancy subset with respect to a discrepancy-based objective. Versions of this problem are known to be NP-hard. In this text, we establish, for the first time, that the subset selection problem with respect to kernel discrepancies is also NP-hard. Motivated by this intractability, we propose a Bayesian Optimization procedure for the subset selection problem utilizing the recent notion of deep embedding kernels. We demonstrate the performance of the BO algorithm to minimize discrepancy measures and note that the framework is broadly applicable any design criteria."}
{"id": "2602.13615", "categories": ["math.OC", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.13615", "abs": "https://arxiv.org/abs/2602.13615", "authors": ["Iasson Karafyllis", "Miroslav Krstic"], "title": "On the Existence of Periodic Solutions with Applications to Extremum-Seeking", "comment": "27 pages", "summary": "This paper provides two results that are useful in the study of the existence and the stability properties of a periodic solution for a given dynamical system. The first result deals with scalar time-periodic systems and establishes the equivalence of the existence of a periodic solution and the existence of a bounded solution. The second result provides sufficient conditions for the existence and the stability of a periodic solution for a time-periodic dynamical system. Both results are applied to extremum seeking problems for a static output map with no plant dynamics and novel non-local results are provided without the use of averaging theorems and singular perturbation arguments."}
{"id": "2602.14757", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14757", "abs": "https://arxiv.org/abs/2602.14757", "authors": ["Erik Burman", "Mats G. Larson", "Karl Larsson", "Jonatan Vallin"], "title": "Solving Inverse Parametrized Problems via Finite Elements and Extreme Learning Networks", "comment": null, "summary": "We develop an interpolation-based reduced-order modeling framework for parameter-dependent partial differential equations arising in control, inverse problems, and uncertainty quantification. The solution is discretized in the physical domain using finite element methods, while the dependence on a finite-dimensional parameter is approximated separately. We establish existence, uniqueness, and regularity of the parametric solution and derive rigorous error estimates that explicitly quantify the interplay between spatial discretization and parameter approximation.\n  In low-dimensional parameter spaces, classical interpolation schemes yield algebraic convergence rates based on Sobolev regularity in the parameter variable. In higher-dimensional parameter spaces, we replace classical interpolation by extreme learning machine (ELM) surrogates and obtain error bounds under explicit approximation and stability assumptions. The proposed framework is applied to inverse problems in quantitative photoacoustic tomography, where we derive potential and parameter reconstruction error estimates and demonstrate substantial computational savings compared to standard approaches, without sacrificing accuracy."}
{"id": "2602.14058", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14058", "abs": "https://arxiv.org/abs/2602.14058", "authors": ["Jia-Hao Chen", "Zi Xu", "Hui-Ling Zhang"], "title": "A Homogeneous Second-Order Descent Ascent Algorithm for Nonconvex-Strongly Concave Minimax Problems", "comment": null, "summary": "This paper introduces a novel Homogeneous Second-order Descent Ascent (HSDA) algorithm for nonconvex-strongly concave minimax optimization problems. At each iteration, HSDA uniquely computes a search direction by solving a homogenized eigenvalue subproblem built from the gradient and Hessian of the objective function. This formulation guarantees a descent direction with sufficient negative curvature even in near-positive-semidefinite Hessian regimes--a key feature that enhances escape from saddle points. We prove that HSDA finds an $\\mathcal{O}(\\varepsilon,\\sqrt{\\varepsilon})$-second-order stationary point within $\\tilde{\\mathcal{O}}(\\varepsilon^{-3/2})$ iterations, matching the optimal $\\varepsilon$-order iteration complexity among second-order methods for this problem class. To address large-scale applications, we further design an inexact variant (IHSDA) that preserves the single-loop structure while solving the subproblem approximately via a Lanczos procedure. With high probability, IHSDA achieves the same $\\tilde{\\mathcal{O}}(\\varepsilon^{-3/2})$ iteration complexity and attains an $\\mathcal{O}(\\varepsilon, \\sqrt{\\varepsilon})$-second-order stationary point, with the total Hessian-vector product cost bounded by $\\tilde{\\mathcal{O}}(\\varepsilon^{-7/4})$. Experiments on synthetic minimax problems and adversarial training tasks confirm the practical effectiveness and robustness of the proposed algorithms."}
{"id": "2602.13736", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.13736", "abs": "https://arxiv.org/abs/2602.13736", "authors": ["Zheshu Xie", "Luojia Wang", "Jiawei Qiu", "Libo Zhang", "Yuxuan Zhou", "Ziyu Tao", "Wenhui Huang", "Yongqi Liang", "Jiajian Zhang", "Yuanzhen Chen", "Song Liu", "Jingjing Niu", "Yang Liu", "Youpeng Zhong", "Luqi Yuan", "Dapeng Yu"], "title": "Quantum dynamics of microwave photons in synthetic frequency dimension", "comment": null, "summary": "Synthetic frequency dimension offers a powerful approach to simulate lattice models and control photon dynamics. However, extending this concept into the quantum regime, particularly at the single-photon level, has remained challenging in photonic platforms. Here, we demonstrate quantum-state initialization and detection of single-photon evolutions within a synthetic frequency lattice by integrating a superconducting qubit with a 16-meter aluminum coaxial cable. A tunable superconducting quantum interference device (SQUID)-based modulator is employed to synthesize lattice couplings and artificial gauge fields. We observe single-photon quantum random walks and Bloch oscillations, as well as nonadiabatic, unidirectional frequency conversion under rapid temporal modulation of the lattice Hamiltonian, together with band-structure measurements. The lattice connectivity can be readily reconfigured to construct higher-dimensional lattices using multiple drive tones. Our results establish superconducting quantum circuits as a versatile platform for programmable Hamiltonians and extensible synthetic lattices with flexible single-photon control."}
{"id": "2602.14964", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.14964", "abs": "https://arxiv.org/abs/2602.14964", "authors": ["Olav F. Syljuåsen", "Jens Paaske"], "title": "Nematostriction in frustrated two-dimensional Heisenberg models", "comment": null, "summary": "We investigate the nematic phase transition in the Heisenberg $J_1$-$J_2$-model on square and triangular lattices, accounting for finite lattice compressibility and bond-length-dependent magnetic exchange. Using Nematic Bond Theory, a diagrammatic self-consistent method, we study the nematostriction that happens when the onset of nematic order in the spin-system drives a concomitant structural phase transition. We analyze the mechanisms by which the magnetoelastic couplings renormalize the critical temperature and modify the phonon spectrum. The magnetoelastic feeback can also alter fundamentally the nature of the phase transition. Specifically, on the square lattice, the transition shifts from continuous to weakly first-order (discontinuous) beyond a critical magnetoelastic coupling threshold. Conversely, on the triangular lattice, the transition remains discontinuous regardless of coupling strength."}
{"id": "2602.14813", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.14813", "abs": "https://arxiv.org/abs/2602.14813", "authors": ["Gian Pietro Bellocca", "Ignacio Garrón", "Vladimir Rodríguez-Caballero", "Esther Ruiz"], "title": "The empirical distribution of sequential LS factors in Multi-level Dynamic Factor Models", "comment": null, "summary": "The research question we answer in this paper is whether the asymptotic distribution derived by Bai (2003) for Principal Components (PC) factors in dynamic factor models (DFMs) can approximate the empirical distribution of the sequential Least Squares (SLS) estimator of global and group-specific factors in multi-level dynamic factor models (ML-DFMs). Monte Carlo experiments confirm that under general forms of the idiosyncratic covariance matrix, the finite-sample distribution of SLS global and group-specific factors can be well approximated using the asymptotic distribution of PC factors. We also analyse the performance of alternative estimators of the asymptotic mean squared error (MSE) of the SLS factors and show that the MSE estimator that allows for idiosyncratic cross-sectional correlation and accounts for estimation uncertainty of factor loadings is best."}
{"id": "2602.14537", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14537", "abs": "https://arxiv.org/abs/2602.14537", "authors": ["Xu Shang", "Masih Haseli", "Jorge Cortés", "Yang Zheng"], "title": "On the Existence of Koopman Linear Embeddings for Controlled Nonlinear Systems", "comment": null, "summary": "Koopman linear representations have become a popular tool for control design of nonlinear systems, yet it remains unclear when such representations are exact. In this paper, we establish sufficient and necessary conditions under which a controlled nonlinear system admits an exact finite-dimensional Koopman linear representation, which we term Koopman linear embedding. We show that such a system must be transformable into a special control-affine preserved (CAP) structure, which enforces affine dependence of the state on the control input and isolates all nonlinearities into an autonomous subsystem. We further prove that this autonomous subsystem must itself admit a finite-dimensional Koopman linear model with a sufficiently-rich Koopman invariant subspace. Finally, we introduce a symbolic procedure to determine whether a given controlled nonlinear system admits the CAP structure, thereby elucidating whether Koopman approximation errors arise from intrinsic system dynamics or from the choice of lifting functions."}
{"id": "2602.14786", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14786", "abs": "https://arxiv.org/abs/2602.14786", "authors": ["Achraf Badahmane", "Xian-Ming GU"], "title": "New Randomized Global Generalized Minimum Residual (RGl-GMRES) method", "comment": null, "summary": "In this paper, we develop a new Randomized Global Generalized Minimum Residual (RGlGMRES) algorithm for efficiently computing solutions to large scale linear systems with multiple right hand sides.The proposed method builds on a recently developed randomized global Gram Schmidt process, in which sketched Frobenius inner products are employed to approximate the exact Frobenius inner products of high-dimensional matrices. We give some new convergence results of the randomized global GMRES method for multiple linear systems. In the case where the coefficient matrix A is diagonalizable, we derive new upper bounds for the randomized Frobenius norm of the residual. In this paper, we study how to introduce matrix sketching in this algorithm. It allows us to reduce the dimension of the problem in one of the main steps of the algorithm. To validate the effectiveness and practicality of this approach, we conduct several numerical experiments, which demonstrate that our RGl-GMRES method is competitive with the GlGMRES method for solving large scale problems with multiple right-hand sides."}
{"id": "2602.14136", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14136", "abs": "https://arxiv.org/abs/2602.14136", "authors": ["Ata Keskin"], "title": "Comparative Evaluation of SDP, SOCP, and QC Convex Relaxations for Large-Scale Market-Based AC Optimal Power Flow", "comment": null, "summary": "The alternating current optimal power flow (ACOPF) problem is central to modern power system operations, determining how electricity is generated and transmitted to maximize social welfare while respecting physical and operational constraints. However, the nonlinear and non-convex nature of AC power flow equations makes finding globally optimal solutions computationally intractable for large networks. Convex relaxations - including semidefinite programming (SDP), second-order cone programming (SOCP), and quadratic convex (QC) formulations - provide tractable alternatives that can yield provably optimal or near-optimal solutions under appropriate conditions. This paper presents a comprehensive comparative study of multiple ACOPF relaxations applied to market-based welfare maximization. We implement DCOPF, Shor's SDP relaxation (complex and real-valued forms), chordal SDP, Jabr's SOCP relaxation, and QC relaxations in a unified, solver-native framework using the MOSEK Fusion API, eliminating modeling overhead present in high-level frameworks such as CVXPY. To address the practical challenge of missing or overly conservative angle difference bounds required by QC relaxations, we employ quasi-Monte Carlo sampling with Sobol sequences to empirically estimate tighter bounds. We evaluate these relaxations on subnetworks of varying sizes derived from the ARPA-E dataset, systematically comparing solution quality, runtime, and memory consumption. Our results demonstrate the trade-offs between relaxation tightness and computational efficiency, providing practical guidance for selecting appropriate formulations based on network scale and solution requirements."}
{"id": "2602.13796", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13796", "abs": "https://arxiv.org/abs/2602.13796", "authors": ["Wanchao Yao", "Sai Li", "Zhiyuan Liu", "Yi Li", "Zihan Xie", "Xingyu Zhao", "Xu Cheng", "Yue Li", "Zheng-Yuan Xue", "Yiheng Lin"], "title": "Non-Abelian Aharonov-Bohm Caging in Synthetic Dimensions with a Trapped Ion", "comment": "11 pages, 7 figures", "summary": "Aharonov-Bohm (AB) caging is a complete localization phenomenon in two-dimensional lattices due to destructive interference induced by the background gauge fields. However, current investigations of AB caging are mostly restricted to the Abelian gauge field case, and the observation of AB caging under non-Abelian gauge fields in a quantum system still remains elusive. Here, we report experimental realization of tunable synthetic non-Abelian SU(2) gauge fields in a rhombic lattice, engineered within the synthetic dimensions of a vibrating trapped ion with multiple levels. We realize AB caging under both Abelian and non-Abelian gauge fields and systematically investigate the distinctive transport properties of the non-Abelian case. In particular, we observe typical emergent quantum dynamics unique to non-Abelian AB caging, including initial-state-dependent dynamics, second-order effects, and asymmetric caging behavior. These observations demonstrate the trapped ion system as a powerful platform for simulating emergent phenomena in high-dimensional quantum systems with exotic synthetic gauge fields."}
{"id": "2602.15016", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15016", "abs": "https://arxiv.org/abs/2602.15016", "authors": ["Yi-Hsien Du"], "title": "Controlled Theory of Skyrmion Chern Bands in Moiré Quantum Materials: Quantum Geometry and Collective Dynamics", "comment": "63 pages", "summary": "Recent experiments in moiré quantum materials exhibit quantized Hall states without an external magnetic field, motivating continuum mechanisms based on smooth moiré-periodic pseudospin textures. We present a controlled theory of skyrmion Chern bands generated by such textures. An exact local $SU(2)$ transformation reveals an emergent non-Abelian gauge field; for large branch splitting we perform an operator-level Schrieffer-Wolff expansion, yielding a single-branch Hamiltonian together with systematically dressed physical operators that define the projected interacting theory beyond strict adiabaticity. The leading dynamics is governed by a $U(1)$ Berry connection whose flux is set by the skyrmion density, while controlled non-adiabatic corrections are fixed by the texture's real-space quantum geometric tensor. In a Landau-level representation built from the averaged emergent field, moiré-periodic modulations induce Umklapp-resolved deformations of Girvin-MacDonald-Platzman kinematics and microscopic sources of excess optical quantum weight above the topological lower bound. Assuming a gapped Hall phase, we further derive a skyrmion-crystal effective field theory with a universal Berry-phase term and a noncommutative magnetophonon. Our results provide experimentally accessible signatures for twisted transition-metal dichalcogenide homobilayers and rhombohedral graphene aligned with hexagonal boron nitride."}
{"id": "2602.14835", "categories": ["stat.ME", "cs.CY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.14835", "abs": "https://arxiv.org/abs/2602.14835", "authors": ["Evan Hadfield"], "title": "The Global Representativeness Index: A Total Variation Distance Framework for Measuring Demographic Fidelity in Survey Research", "comment": "2 figures, 9 tables. Open-source library: https://github.com/collect-intel/gri", "summary": "Global survey research increasingly informs high-stakes decisions in AI governance and cross-cultural policy, yet no standardized metric quantifies how well a sample's demographic composition matches its target population. Response rates and demographic quotas -- the prevailing proxies for sample quality -- measure effort and coverage but not distributional fidelity. This paper introduces the Global Representativeness Index (GRI), a framework grounded in Total Variation Distance that scores any survey sample against population benchmarks across multiple demographic dimensions on a [0, 1] scale. Validation on seven waves of the Global Dialogues survey (N = 7,500 across 60+ countries) finds fine-grained demographic GRI scores of only 0.33--0.36 -- roughly 43% of the theoretical maximum at that sample size. Cross-validation on the World Values Survey (seven waves, N = 403,000), Afrobarometer Round 9 (N = 53,000), and Latinobarometro (N = 19,000) reveals that even large probability surveys score below 0.22 on fine-grained global demographics when country coverage is limited. The GRI connects to classical survey statistics through the design effect; both metrics are recommended as a minimum summary of sample quality, since GRI quantifies demographic distance symmetrically while effective N captures the asymmetric inferential cost of underrepresentation. The framework is released as an open-source Python library with UN and Pew Research Center population benchmarks, applicable to survey research, machine learning dataset auditing, and AI evaluation benchmarks."}
{"id": "2602.14652", "categories": ["math.OC", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14652", "abs": "https://arxiv.org/abs/2602.14652", "authors": ["Anqi Dong", "Karl H. Johansson", "Johan Karlsson"], "title": "Temporally Flexible Transport Scheduling on Networks with Departure-Arrival Constriction and Nodal Capacity Limits", "comment": "29 pages, 9 figures", "summary": "We investigate the optimal transport (OT) problem over networks, wherein supply and demand are conceptualized as temporal marginals governing departure rates of particles from source nodes and arrival rates at sink nodes. This setting extends the classical OT framework, where all mass is conventionally assumed to depart at $t = 0$ and arrive at $t = t_f$. Our generalization accommodates departures and arrivals at specified times, referred as departure--arrival(DA) constraints. In particular, we impose nodal-temporal flux constraints at source and sink nodes, characterizing two distinct scenarios: (i) Independent DA constraints, where departure and arrival rates are prescribed independently, and (ii) Coupled DA constraints, where each particle's transportation time span is explicitly specified. We establish that OT with independent DA constraints admits a multi-marginal optimal transport formulation, while the coupled DA case aligns with the unequal-dimensional OT framework. For line graphs, we analyze the existence and uniqueness of the solution path. For general graphs, we use a constructive path-based reduction and optimize over a prescribed set of paths. From a computational perspective, we consider entropic regularization of the original problem to efficiently provide solutions based on multi-marginal Sinkhorn method, making use of the graphical structure of the cost to further improve scalability. Our numerical simulation further illustrates the linear convergence rate in terms of marginal violation."}
{"id": "2602.14854", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.14854", "abs": "https://arxiv.org/abs/2602.14854", "authors": ["Stefan Brunner", "Lukas Einkemmer", "Terry Haut"], "title": "Domain decomposition dynamical low-rank for multi-dimensional radiative transfer equations", "comment": null, "summary": "In this paper, we propose a domain decomposition dynamical low-rank method to solve high-dimensional radiative transfer problems and similar kinetic equations. The algorithm uses a separate low-rank approximation on each spatial subdomain, which means that, for a given accuracy, we can often use a smaller overall rank compared to classic dynamical low-rank methods. In particular, we can solve problems with point sources efficiently, that for classic algorithms require almost full rank. Our algorithm only transfers boundary data between subdomains and is thus very attractive for distributed memory parallelization, where classic dynamical low-rank algorithms suffer from global data dependency. We demonstrate the efficiency of our algorithm by a number of challenging test examples that have both very optical thin and thick regions."}
{"id": "2602.14139", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14139", "abs": "https://arxiv.org/abs/2602.14139", "authors": ["Zhihan Zhu", "Yanhao Zhang", "Yong Xia"], "title": "Subgradient Gliding Method for Nonsmooth Convex Optimization", "comment": "40 pages, 9 figures", "summary": "We identify and analyze a fundamental limitation of the classical projected subgradient method in nonsmooth convex optimization: the inevitable failure caused by the absence of valid subgradients at boundary points. We show that, under standard step sizes for both convex and strongly convex objectives, the method can fail after a single iteration with probability arbitrarily close to one, even on simple problem instances. To overcome this limitation, we propose a novel alternative termed the \\textit{subgradient gliding method}, which remains well defined without boundary subgradients and avoids premature termination. Beyond resolving this foundational issue, the proposed framework encompasses the classical projected subgradient method as a special case and substantially enlarges its admissible step-size design space, providing greater flexibility for algorithmic design. We establish optimal ergodic convergence rates, $\\mathcal{O}(1/\\sqrt{t})$ for convex problems and $\\mathcal{O}(1/t)$ for strongly convex problems, and further extend the framework to stochastic settings. Notably, our analysis does not rely on global Lipschitz continuity of the objective function, requiring only mild control on subgradient growth. Numerical experiments demonstrate that, in scenarios where the classical projected subgradient method fails completely, the proposed method converges reliably with a $100\\%$ success rate and achieves orders-of-magnitude improvements in accuracy and convergence speed. These results substantially expand the scope of subgradient-based optimization methods to non-Lipschitz nonsmooth convex problems."}
{"id": "2602.13829", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13829", "abs": "https://arxiv.org/abs/2602.13829", "authors": ["Yi-Chong Ren", "Feng Xu", "Wijnand Broer", "Xiao-Jing Chen", "Fei Xue"], "title": "Field-Tunable Meissner-Levitated Ferromagnetic Microsphere Sensor for Cryogenic Casimir and Short-Range Gravity Tests", "comment": "12 pages, 4 figures", "summary": "Near-field force measurements at submicron separations can probe Casimir effects and hypothetical short-range interactions, but require cryogenic operation and stable, \\textit{in situ} control of separation-dependent backgrounds. We propose a self-calibrating quantum force-gradient sensor in which a ferromagnetic microsphere is Meissner-levitated above a type-I superconducting plane, while a bias magnetic field reproducibly tunes the equilibrium gap for in situ separation scans without mechanical approach. The force gradient is encoded as a resonance-frequency shift tracked by a phase-locked loop, and the motion is read out with a SQUID-coupled, flux-tunable microwave resonator that provides adjustable measurement strength without optical heating. Using the input--output formalism, we derive the conditions for reaching the standard quantum limit (SQL) and identify a counterintuitive scaling law: because displacement-to-flux transduction increases with microsphere size, larger microspheres require fewer photons to reach the SQL, enabling a pathway to macroscopic quantum metrology. We quantify the trade-off between suppression of electrostatic patch potentials (via Au coating) and eddy-current dissipation, project force sensitivities of $\\sim 10^{-19}\\,\\rm{N\\,Hz^{-1/2}}$ at millikelvin temperatures, and outline protocols to extract Casimir pressure and constrain Yukawa-type deviations from Newtonian gravity over $0.1$--$10\\,μ\\mathrm{m}$."}
{"id": "2602.15020", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15020", "abs": "https://arxiv.org/abs/2602.15020", "authors": ["Weiyao Li", "Vitor Dantas", "Wen-Han Kao", "Natalia B. Perkins"], "title": "Majorana Signatures in Planar Tunneling through a Kitaev Spin Liquid", "comment": "14 pages, 5 figures", "summary": "We propose a planar tunneling setup to probe vacancy-bound Majorana modes in the chiral Kitaev spin liquid. In this geometry, the inelastic tunneling conductance can be expressed directly in terms of real-space spin correlations, establishing a link between measurable spectra and the underlying fractionalized excitations. We show that spin vacancies host localized Majorana states that generate sharp near-zero-bias features, well separated from the continuum of bulk spin excitations. Compared to local STM measurements, the planar configuration naturally enhances the signal by coherently summing over multiple vacancies, reducing spatial resolution requirements. Our results demonstrate a realistic and scalable route to detect Majorana excitations in Kitaev materials."}
{"id": "2602.14942", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.14942", "abs": "https://arxiv.org/abs/2602.14942", "authors": ["Yichao Chen", "Weijing Tang", "Ji Zhu"], "title": "Balanced Stochastic Block Model for Community Detection in Signed Networks", "comment": null, "summary": "Community detection, discovering the underlying communities within a network from observed connections, is a fundamental problem in network analysis, yet it remains underexplored for signed networks. In signed networks, both edge connection patterns and edge signs are informative, and structural balance theory (e.g., triangles aligned with ``the enemy of my enemy is my friend'' and ``the friend of my friend is my friend'' are more prevalent) provides a global higher-order principle that guides community formation. We propose a Balanced Stochastic Block Model (BSBM), which incorporates balance theory into the network generating process such that balanced triangles are more likely to occur. We develop a fast profile pseudo-likelihood estimation algorithm with provable convergence and establish that our estimator achieves strong consistency under weaker signal conditions than methods for the binary SBM that rely solely on edge connectivity. Extensive simulation studies and two real-world signed networks demonstrate strong empirical performance."}
{"id": "2602.14830", "categories": ["math.OC", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14830", "abs": "https://arxiv.org/abs/2602.14830", "authors": ["Souvik Das", "Luca Schenato", "Subhrakanti Dey"], "title": "On Convergence Analysis of Network-GIANT: An approximate Hessian-based fully distributed optimization algorithm", "comment": "11 pages, 9 figures", "summary": "In this paper, we present a detailed convergence analysis of a recently developed approximate Newton-type fully distributed optimization method for smooth, strongly convex local loss functions, called Network-GIANT, which has been empirically illustrated to show faster linear convergence properties while having the same communication complexity (per iteration) as its first order distributed counterparts. By using consensus based parameter updates, and a local Hessian based descent direction at the individual nodes with gradient tracking, we first explicitly characterize a global linear convergence rate for Network-GIANT, which can be computed as the spectral radius of a $3 \\times 3$ matrix dependent on the Lipschitz continuity ($L$) and strong convexity ($μ$) parameters of the objective functions, and the spectral norm ($σ$) of the underlying undirected graph represented by a doubly stochastic consensus matrix. We provide an explicit bound on the step size parameter $η$, below which this spectral radius is guaranteed to be less than $1$. Furthermore, we derive a mixed linear-quadratic inequality based upper bound for the optimality gap norm, which allows us to conclude that, under small step size values, asymptotically, as the algorithm approaches the global optimum, it achieves a locally linear convergence rate of $1-η(1 -\\fracγμ)$ for Network-GIANT, provided the Hessian approximation error $γ$ (between the harmonic mean of the local Hessians and the global hessian (the arithmetic mean of the local Hessians) is smaller than $μ$. This asymptotically linear convergence rate of $\\approx 1-η$ explains the faster convergence rate of Network-GIANT for the first time. Numerical experiments are carried out with a reduced CovType dataset for binary logistic regression over a variety of graphs to illustrate the above theoretical results."}
{"id": "2602.14912", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14912", "abs": "https://arxiv.org/abs/2602.14912", "authors": ["A. K. Dond", "D. Gallistl", "S. Nayak", "M. Schedensack"], "title": "A posteriori error estimates for a modified Morley FEM", "comment": null, "summary": "Residual-based a~posteriori error estimators are derived for the modified Morley FEM, proposed by Wang, Xu, Hu [J. Comput. Math, 24(2), 2006], for the singularly perturbed biharmonic equation and the nonlinear von Kármán equations. The error estimators are proven to be reliable and efficient. Moreover, an adaptive algorithm driven by these error estimators is investigated in numerical experiments."}
{"id": "2602.14156", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14156", "abs": "https://arxiv.org/abs/2602.14156", "authors": ["Arkadiusz Misztela", "Sławomir Plaskacz"], "title": "Stable representations of Hamilton-Jacobi-Bellman equations with infinite horizon", "comment": null, "summary": "In this paper, for the Hamilton-Jacobi-Bellman equation with an infinite horizon and state constraints, we construct a suitably regular representation. This allows us to reduce the problem of existence and uniqueness of solutions to the Frankowska and Basco theorem from (2019). Furthermore, we demonstrate that our representations are stable. The obtained results are illustrated with examples."}
{"id": "2602.13876", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.13876", "abs": "https://arxiv.org/abs/2602.13876", "authors": ["Mark Wildon"], "title": "Quantum computation and quantum error correction: the theoretical minimum", "comment": "34 pages, 4 figures", "summary": "These notes introduce quantum computation and quantum error correction, emphasising the importance of stabilisers and the mathematical foundations in basic Lie theory. We begin by using the double cover map $\\mathrm{SU}_2 \\rightarrow \\mathrm{SO}_3(\\mathbb{R})$ to illustrate the distinction between states and measurements for a single qubit. We then discuss entanglement and CNOT gates, the Deutsch--Jozsa Problem, and finally quantum error correction, using the Steane $[[7,1,3]]$-code as the main example. The necessary background physics of unitary evolution and Born rule measurements is developed as needed. The circuit model is used throughout."}
{"id": "2602.15025", "categories": ["cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.15025", "abs": "https://arxiv.org/abs/2602.15025", "authors": ["Luisa Eck", "Zhenghan Wang"], "title": "3d Conformal Field Theories via Fuzzy Sphere Algebra", "comment": null, "summary": "Fuzzy sphere models conjecturally realize 3d CFTs in small systems of spinful fermions, but why they work so well is still not fully understood. Their Hamiltonians are built from electron density operators projected to the lowest Landau Level. We analyze the algebra of the density modes and verify that it satisfies the Jacobi identity. The fuzzy sphere geometry admits two thermodynamic limits: a local planar limit yielding the fuzzy plane, and a commutative limit yielding an ordinary sphere. In the planar limit, high-angular-momentum modes recover the Girvin-MacDonald-Platzman algebra, whereas in the commutative limit the low-angular-momentum modes become semiclassical. We further find an explicit representation of the conformal algebra so(3,2) in the minimal two-electron system and extend it to larger systems via an so(3) equivariant coproduct. Because the coproduct splits one so(3) representation into a tensor product, it is structurally mismatched with the thermodynamic limit of critical fuzzy sphere Hamiltonians."}
{"id": "2602.14981", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.14981", "abs": "https://arxiv.org/abs/2602.14981", "authors": ["Tianni Zhang", "Yuyao Wang", "Yu Lu", "and Mengfei Ran"], "title": "Block Empirical Likelihood Inference for Longitudinal Generalized Partially Linear Single-Index Models", "comment": null, "summary": "Generalized partially linear single-index models (GPLSIMs) provide a flexible and interpretable semiparametric framework for longitudinal outcomes by combining a low-dimensional parametric component with a nonparametric index component. For repeated measurements, valid inference is challenging because within-subject correlation induces nuisance parameters and variance estimation can be unstable in semiparametric settings. We propose a profile estimating-equation approach based on spline approximation of the unknown link function and construct a subject-level block empirical likelihood (BEL) for joint inference on the parametric coefficients and the single-index direction. The resulting BEL ratio statistic enjoys a Wilks-type chi-square limit, yielding likelihood-free confidence regions without explicit sandwich variance estimation. We also discuss practical implementation, including constrained optimization for the index parameter, working-correlation choices, and bootstrap-based confidence bands for the nonparametric component. Simulation studies and an application to the epilepsy longitudinal study illustrate the finite-sample performance."}
{"id": "2602.14921", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14921", "abs": "https://arxiv.org/abs/2602.14921", "authors": ["Pedro Morin", "Cornelia Schneider", "Nick Schneider"], "title": "Approximation classes for the anisotropic space-time finite element method. An almost characterization", "comment": null, "summary": "We study the approximation of $L_p$-functions, $p\\in (0,\\infty]$, on cylindrical space-time domains $Ω_T:=[0,T]\\times Ω$, $0<T<\\infty$, $Ω\\subset \\R^d$ Lipschitz, $d\\in \\mathbb{N}$, with respect to continuous anisotropic space-time finite elements on prismatic meshes. In particular, we propose a suitable refinement technique which creates (locally refined) prismatic meshes with sufficient smoothness and the desired anisotropy, and prove complexity estimates. Furthermore, we define a (quasi-)interpolation operator on this type of meshes and use it to characterize the corresponding approximation classes by showing direct and inverse estimates in terms of anisotropic Besov norms."}
{"id": "2602.14185", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14185", "abs": "https://arxiv.org/abs/2602.14185", "authors": ["Jiajin Li", "Mahesh Nagarajan", "Siyu Pan", "Nanxi Zhang"], "title": "Smoothing Meets Perturbation: Unified and Tight Analysis for Nonconvex-Concave Minimax Optimization", "comment": null, "summary": "In this paper, we investigate smooth nonconvex-concave minimax optimization problems and analyze two widely used acceleration mechanisms -- perturbation and smoothing. Perturbation augments the dual objective with a small quadratic regularization term, whereas smoothing employs an auxiliary primal sequence to approximate a proximal-point update of the value function. While both techniques are known to improve convergence guarantees, their respective roles and relative strengths remain unclear. We develop a unified analytical framework that disentangles and quantifies the respective roles of smoothing and perturbation. With this analytical framework, we design new first-order methods that improve the state-of-the-art iteration complexity bounds for both single-loop and double-loop schemes, for achieving both approximate game stationary (GS) and optimization stationary (OS) points. We also establish matching lower bounds based on carefully constructed hard instances, showing that the resulting complexity bounds are tight. Taken together, these results reveal a fundamental difference between approximate GS and OS in terms of their intrinsic complexity behavior and the following understanding: smoothing and perturbation play fundamentally different yet complementary roles in achieving approximate GS. Their combination creates a synergistic effect that yields strictly faster convergence speed than either mechanism alone, whereas perturbation by itself is insufficient for OS."}
{"id": "2602.13885", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13885", "abs": "https://arxiv.org/abs/2602.13885", "authors": ["Nader Mostaan", "Kapil Goswami", "Peter Schmelcher", "Rick Mukherjee"], "title": "High-fidelity non-adiabatic dark state gates for neutral atoms", "comment": null, "summary": "Rydberg blockade gates are the most experimentally mature entangling operations in neutral-atom quantum processors, combining fast gate times with simple control, but their performance degrades at larger interatomic separations and remains sensitive to motional and technical noise. Non-blockade gate schemes, such as dark-state and geometric protocols, offer complementary robustness but typically rely on complex and experimentally demanding control. Here we show that quantum optimal control enables non-blockade gate schemes to be implemented using the experimentally established pulse-shaping techniques developed for blockade-based gates. Focusing on the dark-state gate, we construct non-adiabatic implementations that preserve the intrinsic robustness of adiabatic dark-state protocols while achieving gate times comparable to time-optimal blockade gates using only smooth, experimentally feasible pulses. The resulting gates exhibit enhanced resilience to motional coupling, laser noise, and interaction inhomogeneity, particularly near and beyond the blockade radius. This work establishes a practical route to fast, robust two-qubit gates without increased experimental complexity."}
{"id": "2602.13916", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13916", "abs": "https://arxiv.org/abs/2602.13916", "authors": ["J. Sirker"], "title": "Bulk-boundary correspondence in topological two-dimensional non-Hermitian systems: Toeplitz operators and singular values", "comment": "29 pages", "summary": "In contrast to eigenvalue-based approaches, we formulate the bulk-boundary correspondence for two-dimensional non-Hermitian quadratic lattice Hamiltonians in terms of Toeplitz operators and singular values, which correctly capture the stability, localization, and scaling of edge and corner modes. We show that singular values, rather than eigenvalues, provide the only stable foundation for topological protection in non-Hermitian systems because they remain robust under translational-symmetry-breaking perturbations that destabilize the eigenvalue spectrum, rendering it unsuitable for topological classification. Building on Toeplitz operator theory, we establish general results for non-Hermitian Hamiltonians defined on half and quarter planes, relating the topological indices of the associated Toeplitz operators to the number of finite-size singular values that are separated from the bulk singular-value spectrum and vanish in the thermodynamic limit. This yields a precise bulk-boundary correspondence for edge and corner modes, including higher-order topological phases, without requiring crystalline symmetries. We illustrate our general results with detailed examples exhibiting topologically protected families of edge states, coexisting edge and corner modes, and phases with both gapped bulk and edges supporting only stable corner modes. The latter is exemplified by a non-Hermitian generalization of the Benalcazar-Bernevig-Hughes model."}
{"id": "2602.14991", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.14991", "abs": "https://arxiv.org/abs/2602.14991", "authors": ["Yue Zhan", "Cheng Zheng", "Ying Zhang"], "title": "Joint analysis for multivariate longitudinal and event time data with a change point anchored at interval-censored event time", "comment": null, "summary": "Huntington's disease (HD) is an autosomal dominant neurodegenerative disorder characterized by motor dysfunction, psychiatric disturbances, and cognitive decline. The onset of HD is marked by severe motor impairment, which may be predicted by prior cognitive decline and, in turn, exacerbate cognitive deficits. Clinical data, however, are often collected at discrete time points, so the timing of disease onset is subject to interval censoring. To address the challenges posed by such data, we develop a joint model for multivariate longitudinal biomarkers with a change point anchored at an interval-censored event time. The model simultaneously assesses the effects of longitudinal biomarkers on the event time and the changes in biomarker trajectories following the event. We conduct a comprehensive simulation study to demonstrate the finite-sample performance of the proposed method for causal inference. Finally, we apply the method to PREDICT-HD, a multisite observational cohort study of prodromal HD individuals, to ascertain how cognitive impairment and motor dysfunction interact during disease progression."}
{"id": "2602.14967", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.14967", "abs": "https://arxiv.org/abs/2602.14967", "authors": ["Guosheng Fu", "Brendan Keith", "Dohyun Kim", "Rami Masri", "Will Pazner"], "title": "The proximal Galerkin method for non-symmetric variational inequalities", "comment": null, "summary": "We introduce the proximal Galerkin (PG) method for non-symmetric variational inequalities. The proposed approach is asymptotically mesh-independent and yields constraint-preserving approximations. We present both a conforming PG formulation and a hybrid mixed first-order system variant (FOSPG). We establish optimal a priori error estimates for each variant, which are verified numerically. We conclude by applying the method to American option pricing, free boundary problems in porous media, advection-diffusion with a semipermeable boundary, and the enforcement of discrete maximum principles."}
{"id": "2602.14480", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14480", "abs": "https://arxiv.org/abs/2602.14480", "authors": ["Meixia Lin", "Ziyang Zeng", "Yangjing Zhang"], "title": "Graph-Guided Fused Regularization for Single- and Multi-Task Regression on Spatiotemporal Data", "comment": null, "summary": "Spatiotemporal matrix-valued data arise frequently in modern applications, yet performing effective regression analysis remains challenging due to complex, dimension-specific dependencies. In this work, we propose a regularized framework for spatiotemporal matrix regression that characterizes temporal and spatial dependencies through tailored penalties. Specifically, the model incorporates a fused penalty to capture smooth temporal evolution and a graph-guided penalty to promote spatial similarity. The framework also extends to the multi-task setting, enabling joint estimation across related tasks. We provide a comprehensive analysis of the framework from both theoretical and computational perspectives. Theoretically, we establish the statistical consistency of the proposed estimators. Computationally, we develop an efficient solver based on the Halpern Peaceman-Rachford method for the resulting composite convex optimization problem. The proposed algorithm achieves a fast global non-ergodic $\\mathcal{O}(1/k)$ convergence rate with low per-iteration complexity. Extensive numerical experiments demonstrate that our method significantly outperforms state-of-the-art approaches in terms of predictive accuracy and estimation error, while also exhibiting superior computational efficiency and scalability."}
{"id": "2602.13895", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.13895", "abs": "https://arxiv.org/abs/2602.13895", "authors": ["Alexey Kiryutin", "Ivan Zhukov", "Danil Markelov", "Erik Van Dyke", "Alexandra Yurkovskaya", "Danila Barskiy"], "title": "High-Field NMR Characterization and Indirect $J$-Spectroscopy of a Nuclear Spin Chain [U-$^{13}$C,$^{15}$N]-butyronitrile", "comment": "7 pages, 4 figures, 1 table", "summary": "One-dimensional chains of coupled spins are minimal models of strongly correlated quantum matter, and have been proposed as wires for transporting quantum information. In liquids, rapid molecular tumbling averages anisotropic dipolar couplings and leaves effective isotropic scalar $J$-coupling Hamiltonians. At zero- to ultralow-field (ZULF) conditions, differences in frequency between nuclear spins of different types are quenched and the internal Hamiltonians can be closely approximated by an isotropic Heisenberg model. In this work, we present [U-$^{13}$C,$^{15}$N]-butyronitrile as a chemically engineered nuclear spin chain whose full spin-spin coupling network can be determined and validated by combining high-field NMR detection with evolution at ultralow fields. Starting from high-field (16.4 T) NMR spectra of $^1$H, $^{13}$C, and $^{15}$N nuclei, we extract all relevant $J$-couplings within a 12-spin network (four $^{13}$C, one $^{15}$N, and seven $^1$H). We then employ a mechanical field-cycling apparatus to prepolarize the spins at high field, shuttle them into a magnetically shielded region for evolution at <50 nT, and detect signals after returning to high field. Fourier analysis of the ultralow-field evolution yields indirect $J$-spectra that are conceptually analogous to ZULF NMR spectra but measured by a high-field NMR spectrometer. We observe clear spectral features at $J$, 1.5$J$, and 2$J$, in good agreement with simulations using the extracted coupling matrix. Finally, we demonstrate 2D experiments that correlate high-field chemical shifts and, thus, fully map interactions within the molecular spin chain. Our results establish [U-$^{13}$C,$^{15}$N]-butyronitrile as an extremely well-characterized spin chain model system and provide a quantitative Hamiltonian benchmark for future hyperpolarization and quantum-control studies."}
{"id": "2602.14499", "categories": ["quant-ph", "cond-mat.str-el", "hep-th", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.14499", "abs": "https://arxiv.org/abs/2602.14499", "authors": ["Junichi Haruna"], "title": "Homological origin of transversal implementability of logical diagonal gates in quantum CSS codes", "comment": "7 pages, no figure, no table. Supplementary material will be included in a subsequent version", "summary": "Transversal Pauli Z rotations provide a natural route to fault-tolerant logical diagonal gates in quantum CSS codes, yet their capability is fundamentally constrained. In this work, we formulate the refinement problem of realizing a logical diagonal gate by a transversal implementation with a finer discrete rotation angle and show that its solvability is completely characterized by the Bockstein homomorphism in homology theory. Furthermore, we prove that the linear independence of the X-stabilizer generators together with the commutativity condition modulo a power of two ensures the existence of transversal implementations of all logical Pauli Z rotations with discrete angles in general CSS codes. Our results identify a canonical homological obstruction governing transversal implementability and provide a conceptual foundation for a formal theory of transversal structures in quantum error correction."}
{"id": "2602.13729", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.13729", "abs": "https://arxiv.org/abs/2602.13729", "authors": ["Benedict M. Risebrow", "Thomas B. Berrett"], "title": "Semi-supervised linear regression with missing covariates", "comment": null, "summary": "Missing values in datasets are common in applied statistics. For regression problems, theoretical work thus far has largely considered the issue of missing covariates as distinct from missing responses. However, in practice, many datasets have both forms of missingness. Motivated by this gap, we study linear regression with a labelled dataset containing missing covariates, potentially alongside an unlabelled dataset. We consider both structured (blockwise-missing) and unstructured missingness patterns, along with sparse and non-sparse regression parameters. For the non-sparse case, we provide an estimator based on imputing the missing data combined with a reweighting step. For the high-dimensional sparse case, we use a modified version of the Dantzig selector. We provide non-asymptotic upper bounds on the risk of both procedures. These are matched by several new minimax lower bounds, demonstrating the rate optimality of our estimators. Notably, even when the linear model is well-specified, our results characterise substantial differences in the minimax rates when unlabelled data is present relative to the fully supervised setting. Particular consequences of our sparse and non-sparse results include the first matching upper and lower bounds on the minimax rate for the supervised setting when either unstructured or structured missingness is present. Our theory is coupled with extensive simulations and a semi-synthetic application to the California housing dataset."}
{"id": "2602.13472", "categories": ["quant-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.13472", "abs": "https://arxiv.org/abs/2602.13472", "authors": ["Junaid Aftab", "Yuehaw Khoo", "Haizhao Yang"], "title": "Non-Uniform Quantum Fourier Transform", "comment": "32 pages, 5 figures, comments are most welcome", "summary": "The Discrete Fourier Transform (DFT) is central to the analysis of uniformly sampled signals, yet many practical applications involve non-uniform sampling, requiring the Non-Uniform Discrete Fourier Transform (NUDFT). While quantum algorithms for the standard DFT are well established, a corresponding framework for the non-uniform case remains underdeveloped. This work introduces a quantum algorithm for the Non-Uniform Quantum Fourier Transform (NUQFT) based on a low-rank factorization of the NUDFT matrix. The factorization is translated into an explicit quantum construction using block encodings, Quantum Signal Processing, and the Linear Combination of Unitaries framework, yielding an $ε$-accurate block encoding of the NUDFT matrix with controlled approximation error from both classical truncation and quantum implementation. Under standard oracle access assumptions for non-uniform sampling points, we derive explicit, non-asymptotic gate-level resource estimates. The resulting complexity scales polylogarithmically with target precision, quadratically with the number of qubits through the quantum Fourier transform, and logarithmically with a geometry-dependent conditioning parameter induced by the non-uniform grid. This establishes a concrete and resource-efficient quantum analogue of the NUDFT and provides a foundation for quantum algorithms on irregularly sampled data."}
{"id": "2602.14537", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14537", "abs": "https://arxiv.org/abs/2602.14537", "authors": ["Xu Shang", "Masih Haseli", "Jorge Cortés", "Yang Zheng"], "title": "On the Existence of Koopman Linear Embeddings for Controlled Nonlinear Systems", "comment": null, "summary": "Koopman linear representations have become a popular tool for control design of nonlinear systems, yet it remains unclear when such representations are exact. In this paper, we establish sufficient and necessary conditions under which a controlled nonlinear system admits an exact finite-dimensional Koopman linear representation, which we term Koopman linear embedding. We show that such a system must be transformable into a special control-affine preserved (CAP) structure, which enforces affine dependence of the state on the control input and isolates all nonlinearities into an autonomous subsystem. We further prove that this autonomous subsystem must itself admit a finite-dimensional Koopman linear model with a sufficiently-rich Koopman invariant subspace. Finally, we introduce a symbolic procedure to determine whether a given controlled nonlinear system admits the CAP structure, thereby elucidating whether Koopman approximation errors arise from intrinsic system dynamics or from the choice of lifting functions."}
{"id": "2602.13922", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13922", "abs": "https://arxiv.org/abs/2602.13922", "authors": ["A. Y. Klimenko"], "title": "Decoherence, Perturbations and Symmetry in Lindblad Dynamics", "comment": "28 pages, 3 figures", "summary": "We extend a perturbative Dyson-type treatment and discrete-symmetry constraints from the Schrödinger and von Neumann equations to a dephasing Lindblad framework. This work develops further the odd-symmetric formulation -- based on stochastic realism and dual temporal boundary conditions -- from general dynamical considerations to specific tools of quantum mechanics. Applying the resulting scaling relations to published single- and double-diffractive data in $pp$ and $p\\bar{p}$ collisions (ISR, UA4, UA5, CDF, D0, ALICE, and E710), we show that single-diffraction cross sections are well described by a three-parameter fit with a relative RMS deviation of $\\sim 4\\%$, substantially improving upon conventional approximations that neglect decoherence. The extracted decoherence factor is consistently $φ\\approx 0.89$, in agreement across SD, DD, and E710-based (direct) estimates, and is naturally interpreted as $φ=1$ for CP-invariant dephasing but $φ<1$ for CPT-invariant dephasing, favouring the latter."}
{"id": "2602.14861", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.14861", "abs": "https://arxiv.org/abs/2602.14861", "authors": ["Roberto Vila", "Helton Saulo"], "title": "Bias analysis of a linear order-statistic inequality index estimator: Unbiasedness under gamma populations", "comment": "14 pages", "summary": "This paper studies a class of rank-based inequality measures built from linear combinations of expected order statistics. The proposed framework unifies several well-known indices, including the classical Gini coefficient, the $m$th Gini index, extended $m$th Gini index and $S$-Gini index, and also connects to spectral inequality measures through an integral representation. We investigate the finite-sample behavior of a natural U-statistic-type estimator that averages weighted order-statistic contrasts over all subsamples of fixed size and normalizes by the sample mean. A general bias decomposition is derived in terms of components that isolate the effect of random normalization on each rank level, yielding analytical expressions that can be evaluated under broad non-negative distributions via Laplace-transform methods. Under mild moment conditions, the estimator is shown to be asymptotically unbiased. Moreover, we prove exact unbiasedness under gamma populations for any sample size, extending earlier unbiasedness results for Gini-type estimators. A Monte Carlo study is performed to numerically check that the theoretical unbiasednes under gamma populations."}
{"id": "2602.13513", "categories": ["math.OC", "cs.CE", "cs.LG", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.13513", "abs": "https://arxiv.org/abs/2602.13513", "authors": ["Grant Norman", "Conor Rowan", "Kurt Maute", "Alireza Doostan"], "title": "Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization", "comment": "44 pages, 13 figures. To be submitted to CMAME", "summary": "In this work, we investigate the use of data-driven equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization. The discovered gradient flows are then solved as a surrogate for the original optimization problem. To this end, we introduce the Learned Gradient Flow (LGF) optimizer, which is equipped to build surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals in the optimization process. We demonstrate the efficacy of this approach on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Our results suggest that the learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations of the objective and its gradient."}
{"id": "2602.14621", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14621", "abs": "https://arxiv.org/abs/2602.14621", "authors": ["Charles Meynard"], "title": "Extragradient methods for mean field games of controls and mean field type FBSDEs", "comment": null, "summary": "In this paper we present a numerical scheme to solve coupled mean field forward-backward stochastic differential equations driven by monotone vector fields. This is based on an adaptation of so called extragradient methods by characterizing solutions as zeros of monotone variational inequalities in a Hilbert space. We first introduce the procedure in the context of mean field games of controls and highlight its connection to the fictitious play. Under sufficiently strong monotonicity assumptions, we demonstrate that the sequence of approximate solutions converges exponentially fast. Then we extend the method and main results to general forward backward systems of stochastic differential equations that do not necessarily stem from optimal control."}
{"id": "2602.13946", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13946", "abs": "https://arxiv.org/abs/2602.13946", "authors": ["Owen Sandner", "Brendan Mackey", "Yuyang Liu", "Connor Kupchak", "Andrew MacRae"], "title": "Homodyne Detection of Temporally Resolved Quantum States", "comment": "17 pages, 5 figures", "summary": "We present an analysis of the time domain measurement of temporally resolvable quantum states using balanced homodyne detection. Our approach outlines a formalism of detecting quantum states in arbitrary temporal modes via projection of the temporal mode onto a natural detector basis. We then present an algorithm for simulating the resultant photocurrent of continuous homodyne detection in the presence of a temporally resolved mode, and use this algorithm to explore the effects of realistic measurement errors on marginal reconstruction and quantum state tomography. A complete implementation of the method is provided through open source code on a GitHub repository."}
{"id": "2602.13565", "categories": ["math.ST", "math.NA", "math.PR", "stat.OT"], "pdf": "https://arxiv.org/pdf/2602.13565", "abs": "https://arxiv.org/abs/2602.13565", "authors": ["Paromita Banerjee", "Anirban Mondal"], "title": "An Improved Milstein Method for the Numerical Solution of Multidimensional Stochastic Differential Equations", "comment": null, "summary": "Stochastic differential equations (SDEs) offer powerful and accessible mathematical models for capturing both deterministic and probabilistic aspects of dynamic behavior across a wide range of physical, financial, and social systems. However, analytical solutions for many SDEs are often unavailable, necessitating the use of numerical approximation methods. The rate of convergence of such numerical methods is of great importance, as it directly influences both computational efficiency and accuracy. This paper presents a proposed theorem, along with its proof, that facilitates the numerical evaluation of the strong (and weak) order of convergence of a numerical scheme for an SDE when the analytical solution is unavailable. Additionally, we address the challenge of numerically computing the multiple stochastic integrals required by the Milstein method to achieve improved convergence rates for multidimensional SDEs. In this context, two newly proposed numerical techniques for computing these multiple stochastic integrals are introduced and compared with existing approaches in terms of efficiency and effectiveness. The methodologies are further illustrated through simulation studies and applications to widely used financial models."}
{"id": "2602.14624", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14624", "abs": "https://arxiv.org/abs/2602.14624", "authors": ["Neil D. Dizon", "Bethany I. Caldwell", "Vaithilingam Jeyakumar", "Guoyin Li"], "title": "Interwoven SDP in Primal-Dual Proximal Splitting Methods for Adjustable Robust Convex Optimisation with SOS-Convex Polynomial Constraints", "comment": null, "summary": "We propose a novel methodology for solving a two-stage adjustable robust convex optimisation problem with a general (proximable) convex objective function and constraints defined by sum-of-squares (SOS) convex polynomials. These problems appear in many decision-making applications. However, they are challenging to solve and typically cannot be reformulated as numerically tractable convex optimisation models, such as conic linear programs, that can be solved directly using existing software. We show that the robust problem admits an equivalent representation as a convex composite unconstrained optimisation model that preserves the same objective values, under quadratic decision rules on the adjustable decision variables. Building on this reformulation, we develop a tailored first-order primal-dual proximal splitting method. By leveraging semidefinite programming (SDP) techniques as well as tools from convex analysis and real algebraic geometry, we establish its theoretical properties, including computable SDP-based formulas for projections onto closed convex sets, specified by SOS-convex polynomial inequalities. Numerical experiments on a two-stage lot-sizing model with both linear as well as SOS-convex polynomial storage costs under demand uncertainty demonstrate the effectiveness and applicability of the proposed approach. Our approach enables the incorporation of SDP techniques into a primal-dual proximal splitting framework, thereby broadening the class of problems to which these methods can be effectively applied."}
{"id": "2602.13955", "categories": ["quant-ph", "cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.13955", "abs": "https://arxiv.org/abs/2602.13955", "authors": ["Yuanbin Chen", "Chau Yuen", "Chong Meng Samson See"], "title": "Wideband Quantum Transduction for Rydberg Atomic Receivers Using Six-Wave Mixing", "comment": "This manuscript has been submitted to IEEE Journal, 13 pages, 12 Figures", "summary": "Rydberg atomic receivers hold extremely high sensitivity to electric fields, yet their effective 3-dB baseband bandwidth under conventional electromagnetically induced transparency (EIT) is typically constrained to tens to a few hundreds of kilohertz, which hinders wideband wireless applications. To relax this bottleneck, we investigate a six-wave mixing (SWM)-based Rydberg atomic receiver as a wideband radio frequency (RF)-to-optical quantum transducer. Specifically, we develop an explicit baseband input-output model spanning from the probe input to the output light field. Based upon this model, a closed-form 3-dB bandwidth expression is derived to expose its dependence on key optical and RF parameters. We further quantify the linear dynamic range by employing the 1-dB compression point (P1dB) and the input-referred third-order intercept point (IIP3), unveiling a communication-compatible characterization of the bandwidth-linearity trade-off. Finally, our numerical results demonstrate that, given identical optical driving conditions, the SWM configuration increases the 3-dB baseband bandwidth by more than an order of magnitude compared to the EIT-based counterpart, while retaining comparable electric-field sensitivity and revealing a broad, tunable linear operating region."}
{"id": "2602.13620", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.13620", "abs": "https://arxiv.org/abs/2602.13620", "authors": ["Xiaozhe Hu", "Sara Pollock", "Zhongqin Xue", "Yunrong Zhu"], "title": "An adaptive framework for first-order gradient methods", "comment": null, "summary": "Gradient methods are widely used in optimization problems. In practice, while the smoothness parameter can be estimated utilizing techniques such as backtracking, estimating the strong convexity parameter remains a challenge; moreover, even with the optimal parameter choice, convergence can be slow. In this work, we propose a framework for dynamically adapting the step size and momentum parameters in first-order gradient methods for the optimization problem, without prior knowledge of the strong convexity parameter. The main idea is to use the geometric average of the ratios of successive residual norms as an empirical estimate of the upper bound on the convergence rate, which in turn allows us to adaptively update the algorithm parameters. The resulting algorithms are simple to implement, yet efficient in practice, requiring only a few additional computations on existing information. The proposed adaptive gradient methods are shown to converge at least as fast as gradient descent for quadratic optimization problems. Numerical experiments on both quadratic and nonlinear problems validate the effectiveness of the proposed adaptive algorithms. The results show that the adaptive algorithms are comparable to their counterparts using optimal parameters, and in some cases, they capture local information and exhibit improved performance."}
{"id": "2602.14632", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14632", "abs": "https://arxiv.org/abs/2602.14632", "authors": ["Gerd Wachsmuth"], "title": "Second-order conditions for bang-bang control of elliptic equations in arbitrary dimensions", "comment": null, "summary": "We consider an optimal control problem governed by a semilinear PDE in cases where the optimal control is of bang-bang type. By utilizing the theory of Bessel potential space, we characterize quadratic growth of the objective via a second-order optimality condition. In contrast to previous contributions, our method of proof works in arbitrary spatial dimensions."}
{"id": "2602.13990", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13990", "abs": "https://arxiv.org/abs/2602.13990", "authors": ["Sougata Bhattacharyya", "Sovik Roy"], "title": "Phase sensitive topological classification of single-qubit measurements in linear cluster states", "comment": "21 pages, 24 figures", "summary": "We provide an explicit geometric classification of single-qubit projective measurements on one-dimensional linear cluster states within a topological framework. By establishing an explicit geometrical correspondence between local measurements and topological surgery operations on an associated link model i.e. a measurement surgery correspondence, we represent the cluster state as a linear Hopf chain. Within this model, measurements in the computational ($Z$) basis act as topological severance in case of bulk measurements while boundary pruning happens for end measurements of qubits. In contrast, transverse ($X$) basis measurements remove the measured qubit while splicing its neighbours, preserving connectivity through real valued correlations. We show that lateral ($Y$) basis measurements also preserve connectivity but generate intrinsically complex phase factors that are not captured by unframed link models, rendering X and Y measurements topologically indistinguishable at the level of connectivity alone. To resolve this ambiguity, we introduce a framed ribbon representation in which quantum phases are encoded as geometric twists, with chiral $\\pm 90^\\circ} twists corresponding to the phases $\\pm i$. This framing yields a phase-sensitive and outcome resolved topological description of all single qubit measurements on linear cluster states. Our approach provides a unified geometric interpretation of measurement-induced entanglement transformations in measurement-based quantum computation, revealing that quantum phases correspond directly to framed topological invariants. The work is restricted to one-dimensional linear cluster states and single-qubit measurements in the Pauli bases."}
{"id": "2602.14053", "categories": ["math.ST", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.14053", "abs": "https://arxiv.org/abs/2602.14053", "authors": ["Sourabh Bhattacharya"], "title": "Mean-Square Convergence of a New Parameterized Leapfrog Scheme for Hamiltonian Systems Driven by Gaussian Process Potentials", "comment": "Feedback welcome", "summary": "This paper establishes the mean-square convergence of a new stochastic, parameterized leapfrog scheme introduced in our companion paper Mazumder et al. (2026) for Hamiltonian systems with Gaussian process potentials. We consider a one-step numerical integrator and provide a complete, rigorous analysis under minimal regularity assumptions on the Gaussian potential. The key technical contribution is identifying and exploiting the symplectic structure ingrained in our stochastic, parameterized leapfrog method. Combined with local truncation error analysis, this leads to a global error bound of O(δt) in mean-square sense. Our results establish that although the spatio-temporal model of Mazumder et al. (2026) arises as the anticipated new stochastic leapfrog solution of a system of modified (parameterized) stochastic Hamiltonian equations, the new stochastic leapfrog actually solves the traditional stochastic Hamiltonian equations, driven by Gaussian process potential."}
{"id": "2602.14652", "categories": ["math.OC", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14652", "abs": "https://arxiv.org/abs/2602.14652", "authors": ["Anqi Dong", "Karl H. Johansson", "Johan Karlsson"], "title": "Temporally Flexible Transport Scheduling on Networks with Departure-Arrival Constriction and Nodal Capacity Limits", "comment": "29 pages, 9 figures", "summary": "We investigate the optimal transport (OT) problem over networks, wherein supply and demand are conceptualized as temporal marginals governing departure rates of particles from source nodes and arrival rates at sink nodes. This setting extends the classical OT framework, where all mass is conventionally assumed to depart at $t = 0$ and arrive at $t = t_f$. Our generalization accommodates departures and arrivals at specified times, referred as departure--arrival(DA) constraints. In particular, we impose nodal-temporal flux constraints at source and sink nodes, characterizing two distinct scenarios: (i) Independent DA constraints, where departure and arrival rates are prescribed independently, and (ii) Coupled DA constraints, where each particle's transportation time span is explicitly specified. We establish that OT with independent DA constraints admits a multi-marginal optimal transport formulation, while the coupled DA case aligns with the unequal-dimensional OT framework. For line graphs, we analyze the existence and uniqueness of the solution path. For general graphs, we use a constructive path-based reduction and optimize over a prescribed set of paths. From a computational perspective, we consider entropic regularization of the original problem to efficiently provide solutions based on multi-marginal Sinkhorn method, making use of the graphical structure of the cost to further improve scalability. Our numerical simulation further illustrates the linear convergence rate in terms of marginal violation."}
{"id": "2602.14025", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14025", "abs": "https://arxiv.org/abs/2602.14025", "authors": ["Lewis Ruks"], "title": "Semiclassical Simulation of Homogeneous Emitter Ensembles with Local Dissipation", "comment": null, "summary": "Emitter ensembles constitute a fundamental component in quantum optical technologies, yet efficient and accurate simulation of large ensembles remains challenging. Here, we formulate a truncated Wigner approximation (TWA) for permutation-invariant emitter ensembles subject to local dissipation by sampling stochastic trajectories in an extended phase space encompassing the Bloch sphere. Benchmarks show that the TWA accurately captures dynamics, including nonclassical signatures, with the approximation improving with ensemble size. We demonstrate large-scale simulations of hundreds of interacting ensembles within the TWA to reveal emergent spatial coherence and selective directionality of cooperative emission in a pumped 1D chain, highlighting a practical path to studying extended light-matter systems. Our results expand the scope of scalable simulations of quantum emitter ensembles, establishing a bridge between microscopic models and emergent behavior."}
{"id": "2602.14450", "categories": ["hep-lat", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.14450", "abs": "https://arxiv.org/abs/2602.14450", "authors": ["Issaku Kanamori", "Hideo Matsufuru", "Tatsumi Aoyama", "Kazuyuki Kanaya", "Yusuke Namekawa", "Hidekatsu Nemura", "Keigo Nitadori"], "title": "Mixed precision solvers with half-precision floating point numbers for Lattice QCD on A64FX processor", "comment": "11 pages, 9 figures, contribution to the International Workshop on Arm-based HPC: Practice and Experience 2026 (IWAHPCE2026) at HPC-Asia 2026", "summary": "We investigate the use of half-precision floating-point numbers (FP16) in mixed-precision linear solvers for lattice QCD simulations. Since the emergence of GPUs for general-purpose, mixed-precision algorithms that combine single-precision (FP32) with double-precision (FP64) arithmetics have become widely used in this field and others. While FP32-based methods are now well established, we examine the practicality of using FP16. In this work, we introduce rescaling steps in both the outer iterative refinement step and the inner BiCGStab solver to avoid numerical instability. In our experiments with a simple Wilson kernel, the solver shows improved stability, and the additional iteration count compared to the FP64 version remains within 20\\%, indicating that the FP16 version is practical for use. We believe that the proposed rescaling methods can also benefit other mixed precision preconditioners in avoiding underflows."}
{"id": "2602.14683", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.14683", "abs": "https://arxiv.org/abs/2602.14683", "authors": ["Valentin Leplat"], "title": "Joint Majorization-Minimization for Nonnegative CP and Tucker Decompositions under $β$-Divergences: Unfolding-Free Updates", "comment": null, "summary": "We study majorization-minimization methods for nonnegative tensor decompositions under the $β$-divergence family, focusing on nonnegative CP and Tucker models. Our aim is to avoid explicit mode unfoldings and large auxiliary matrices by deriving separable surrogates whose multiplicative updates can be implemented using only tensor contractions (einsum-style operations). We present both classical block-MM updates in contraction-only form and a joint majorization strategy, inspired by joint MM for matrix $β$-NMF, that reuses cached reference quantities across inexpensive inner updates. We prove tightness of the proposed majorizers, establish monotonic decrease of the objective, and show convergence of the sequence of objective values; we also discuss how BSUM theory applies to the block-MM scheme for analyzing limit points. Finally, experiments on synthetic tensors and the Uber spatiotemporal count tensor demonstrate substantial speedups over unfolding-based baselines and a recent einsum-factorization framework."}
{"id": "2602.14036", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14036", "abs": "https://arxiv.org/abs/2602.14036", "authors": ["Zhiwei Hu", "Youwei Zhang", "Junlei Duan", "Mingfeng Wang", "Yanhong Xiao"], "title": "Enhancing collective spin squeezing via one-axis twisting echo control of individual atoms", "comment": "6pages, 2figures", "summary": "Spin squeezing generated via inter-atom entanglement in multilevel atomic ensembles provides a powerful resource for quantum-enhanced metrology. Existing schemes that harness internal atomic degrees of freedom to boost squeezing typically encode the collective squeezing in complex superpositions of magnetic sublevels, which complicates state control and limits practical applications. Here, we propose a coherent control scheme that simultaneously enhances collective spin squeezing and maps the resulting atom-atom entanglement onto two well-defined magnetic sublevels suitable for subsequent metrology experiments. Our protocol sandwiches a quantum non-demolition measurement between two internal one-axis-twisting interactions arranged in an echo sequence. We show that this approach can optimally leverage internal states to boost the inter-atom entanglement and, at the same time, encode it in two magnetic sublevels, which is readily convertible into metrologically useful spin squeezing. Our results offer a straightforward and efficient strategy for generating highly entangled yet readily accessible quantum states in multilevel atomic systems."}
{"id": "2602.14607", "categories": ["stat.ME", "cs.LG", "math.NA", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.14607", "abs": "https://arxiv.org/abs/2602.14607", "authors": ["Nathan Kirk"], "title": "A Bayesian Approach to Low-Discrepancy Subset Selection", "comment": "13 pages, 3 figures, mODa14", "summary": "Low-discrepancy designs play a central role in quasi-Monte Carlo methods and are increasingly influential in other domains such as machine learning, robotics and computer graphics, to name a few. In recent years, one such low-discrepancy construction method called subset selection has received a lot of attention. Given a large population, one optimally selects a small low-discrepancy subset with respect to a discrepancy-based objective. Versions of this problem are known to be NP-hard. In this text, we establish, for the first time, that the subset selection problem with respect to kernel discrepancies is also NP-hard. Motivated by this intractability, we propose a Bayesian Optimization procedure for the subset selection problem utilizing the recent notion of deep embedding kernels. We demonstrate the performance of the BO algorithm to minimize discrepancy measures and note that the framework is broadly applicable any design criteria."}
{"id": "2602.14714", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.14714", "abs": "https://arxiv.org/abs/2602.14714", "authors": ["Navid Noroozi"], "title": "Distributed Multi-Step Model Predictive Control for Consensus", "comment": null, "summary": "This paper studies consensus of discrete-time multi-agent systems under time-varying directed communication, state and input constraints using a distributed multi-step model predictive control (MPC) framework. Consensus is recast as stabilization of the agreement set, and a geometric viewpoint based on convex-hull invariance and strict interiority is adopted. Building on an existing geometric necessary and sufficient condition for agreement, we show that enforcing terminal inclusion in local neighbor convex hulls guarantees hull invariance but does not, in general, imply the strict relative-interior property required for convergence. An explicit counterexample demonstrates that strictness cannot be deduced from feasibility and contraction constraints alone.\n  To resolve this issue without shrinking feasible sets or altering primary performance objectives, a lexicographic tie-breaking mechanism is introduced. Among optimal (or near-optimal) MPC solutions, the proposed secondary criterion selects trajectories maximizing an interiority measure with respect to the neighbor hull. It is shown that whenever an interior feasible terminal state exists, this selection rule enforces the strictness condition required for asymptotic consensus. Explicit horizon conditions are derived for single- and double-integrator agents with bounded inputs, ensuring feasibility and automatic existence of interior feasible terminal points. The resulting scheme provides a distributed and implementable route to consensus via finite-step set-Lyapunov contraction. Numerical simulations with distributed inter-process communication illustrate monotone diameter decay and report per-agent computational complexity."}
{"id": "2602.14105", "categories": ["quant-ph", "math-ph", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.14105", "abs": "https://arxiv.org/abs/2602.14105", "authors": ["Naomichi Hatano", "Gonzalo Ordonez"], "title": "Non-Hermitian Quantum Mechanics of Open Quantum Systems: Revisiting The One-Body Problem", "comment": "41 pages, 25 figures, a review article", "summary": "We review analyses of open quantum systems. We show how non-Hermiticity arises in an open quantum system with an infinite environment, focusing on the one-body problem. One of the reasons for taking the present approach is that we can solve the problem completely, making it easier to see the structures of problems involving open quantum systems. We show that this results in the discovery of a new complete set, which is one of the main topics of the present article. Another reason for focusing on the one-body problem is that the theory permits the strong coupling between the system and the environment. In the current research landscape, it is valuable to revisit the one-body problem for open quantum systems, which can be solved accurately for arbitrary strengths of the system-environment couplings. A rigorous understanding of the problem structures in the present approach will be helpful when we tackle problems with many-body interactions. First, we consider potential scattering and directly define the resonant state as an eigenstate of the Schrödinger equation under the Siegert outgoing boundary condition. We show that the resonant eigenstate can have a complex energy eigenvalue, even though the Hamiltonian is seemingly Hermitian. Second, we introduce the Feshbach formalism, which eliminates the infinite degrees of freedom of the environment and represents its effect as a complex potential. The resulting effective Hamiltonian is explicitly non-Hermitian. By unifying these two ways of defining resonant states, we obtain a new complete set of bases for the scattering problem that contains all discrete eigenstates, including resonant states. We finally mention the non-Markovian dynamics of open quantum systems. We emphasize the time-reversal symmetry of the dynamics that continuously connects the past and the future. We can capture it using the new complete set that we develop here."}
{"id": "2602.14683", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.14683", "abs": "https://arxiv.org/abs/2602.14683", "authors": ["Valentin Leplat"], "title": "Joint Majorization-Minimization for Nonnegative CP and Tucker Decompositions under $β$-Divergences: Unfolding-Free Updates", "comment": null, "summary": "We study majorization-minimization methods for nonnegative tensor decompositions under the $β$-divergence family, focusing on nonnegative CP and Tucker models. Our aim is to avoid explicit mode unfoldings and large auxiliary matrices by deriving separable surrogates whose multiplicative updates can be implemented using only tensor contractions (einsum-style operations). We present both classical block-MM updates in contraction-only form and a joint majorization strategy, inspired by joint MM for matrix $β$-NMF, that reuses cached reference quantities across inexpensive inner updates. We prove tightness of the proposed majorizers, establish monotonic decrease of the objective, and show convergence of the sequence of objective values; we also discuss how BSUM theory applies to the block-MM scheme for analyzing limit points. Finally, experiments on synthetic tensors and the Uber spatiotemporal count tensor demonstrate substantial speedups over unfolding-based baselines and a recent einsum-factorization framework."}
{"id": "2602.14758", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14758", "abs": "https://arxiv.org/abs/2602.14758", "authors": ["Candy Sonveaux", "Morgane Dumont", "Mirko Fiacchini", "Mohamad Ajami"], "title": "An Age-Structured Vaccination Strategy for Epidemic Containment: A Model Predictive Control Approach", "comment": null, "summary": "This work presents a novel Model Predictive Control (MPC) approach to develop an optimal age-structured vaccination strategy for the containment of COVID-19 in Wallonia, Belgium. The proposed MPC framework is designed to minimize deaths, achieve early disease eradication, and adhere to operational constraints. By incorporating an age-structured Susceptible-Infected-Recovered-Deceased (SIRD) model with an additional term for vaccination, the MPC strategy dynamically adapts to the evolving epidemic state. A detailed proof of the asymptotic stability and recursive feasibility of the proposed MPC algorithm is provided. This ensures that the optimal cost at each step provides an upper bound on the minimal number obtainable of deaths at the end of the pandemic. Moreover, simulations demonstrate that the proposed MPC approach outperforms the decreasing age vaccination strategy adopted by the Belgian government during the first wave of vaccinations. The results highlight the potential of MPC-based vaccination strategies to reduce the total number of deaths, accelerate disease eradication, and optimize vaccine administration."}
{"id": "2602.14146", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14146", "abs": "https://arxiv.org/abs/2602.14146", "authors": ["Yu Wang", "Jiasen Jin"], "title": "Early-stage memory effect on the dephasing charger-mediated quantum battery", "comment": "9 pages, 5 figures", "summary": "We investigate the performance of the charger-mediated quantum battery modeled by a two-qubit system. One of the qubits acts as the battery and the other acts as the charger which is subjected to a reservoir. We derived the time-local master equation in Lindblad form with a time-dependent dephasing rate. The dephasing rate may be negative in the early-stage of the charging process and thus indicate the presence of the memory effect. We find that such early-stage memory effect could increase the maximal ergotropy of the battery compared with the one under Markovian approximation with the corresponding asymptotic dephase rate. The enhancement of the performance is explained by means of the non-Markovian quantum jumps. Moreover, a discrete time scheme of the measurement-enhanced quantum battery is proposed in a quantum circuit with global and random local operations."}
{"id": "2602.14776", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.14776", "abs": "https://arxiv.org/abs/2602.14776", "authors": ["Julio Backhoff", "Xin Zhang"], "title": "Reciprocal Specific Relative Entropy between Continuous Martingales", "comment": null, "summary": "We introduce a novel notion of divergence between continuous martingales; the reciprocal specific relative entropy. First, we motivate this definition from multiple perspectives. Thereafter, we solve the reciprocal specific relative entropy minimization problem over the set of win-martingales (used as models for prediction markets Aldous (2013)). Surprisingly, we show that the optimizer is the renowned neutral Wright-Fisher diffusion. We also justify that this diffusion is in a sense the most salient win-martingale, since it is uniquely selected when we suitably perturb the degenerate martingale optimal transport problem of variance minimization."}
{"id": "2602.14150", "categories": ["quant-ph", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.14150", "abs": "https://arxiv.org/abs/2602.14150", "authors": ["N. A. Khokhlov"], "title": "Approximating the $S$ matrix for solving the Marchenko equation: the case of channels with different thresholds", "comment": "14 pages, 6 figures", "summary": "This work extends previous results on the inverse scattering problem within the framework of Marchenko theory (fixed-$l$ inversion). In particular, I approximate an $n$-channel $S$-matrix as a function of the first-channel momentum $q$ by a sum of a rational term and a truncated sinc series for each matrix element. Relativistic kinematics are taken into account through the correct momentum-energy relation, and the necessary minor generalization of Marchenko theory is given.\n  For energies where only a subset of scattering channels is open, the analytic structure of the $S$-matrix is analyzed. I demonstrate that the submatrix corresponding to closed channels, particularly near their thresholds, can be reconstructed from the experimentally accessible submatrix of open channels.The convergence of the proposed method is verified by applying it to data generated from a direct solution of the scattering problem for a known potential, and comparing the reconstructed potential with the original one. Finally, the method is applied to the analysis of $S_{31}$ $πN$ scattering data."}
{"id": "2602.14820", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14820", "abs": "https://arxiv.org/abs/2602.14820", "authors": ["Claude Le Bris", "Frédéric Legoll", "Simon Ruget"], "title": "Effective approximations of solutions to highly oscillatory diffusion equations from coarse measurements", "comment": null, "summary": "We approximate a diffusion equation with highly oscillatory coefficients with a diffusion equation with constant coefficients. The approach is put in action in contexts where only partial information (namely the global energy stored in the physical system) is available. While the reconstruction of the microstructure is known to be an ill-posed problem, we show that the reconstruction of effective coefficients is possible and this even with only some coarse information. The strategy we present takes the form of a non-convex optimization problem. Homogenization theory provides elements for a rigorous foundation of the approach. Some algorithmic aspects are discussed in details. We provide a comprehensive set of numerical illustrations that demonstrate the practical interest of our strategy. The present work improves on the earlier works [C. Le Bris, F. Legoll and S. Lemaire, COCV 2018; C. Le Bris, F. Legoll and K. Li, CRAS 2013]."}
{"id": "2602.14165", "categories": ["quant-ph", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.14165", "abs": "https://arxiv.org/abs/2602.14165", "authors": ["Deepak R", "Lokendra Kanawat", "Jayadeep K", "Priyesh Shukla"], "title": "Bidirectional Quantum Processor Interfacing by a 4-Kelvin Analog Signal Chain for Superconducting Qubit Control and Quantum State Readout", "comment": null, "summary": "This paper presents a comprehensive cryogenic analog signal processing architecture designed for superconducting qubit control and quantum state readout operating at 4 Kelvin. The proposed system implements a complete bidirectional signal path bridging room-temperature digital controllers with quantum processors at millikelvin stages. The control path incorporates a Phase-Locked Loop (PLL) for stable local oscillator generation, In-phase/Quadrature (I/Q) modulation for precise qubit gate operations, and a cryogenic power amplifier for signal conditioning. The readout path features a Low Noise Amplifier (LNA) with 14 dB gain and 8-Phase Shift Keying (8-PSK) demodulation for quantum state discrimination. All circuit blocks are designed and validated through SPICE simulations employing cryogenic MOSFET models at 180nm that account for carrier freeze-out, threshold voltage elevation, and enhanced mobility at 4 K. Simulation results demonstrate successful end-to-end signal integrity with I/Q phase error below 2°, image rejection ratio exceeding 35~dB, and symbol error rate below $10^{-6}$. This work provides a modular, simulation-validated framework for scalable cryogenic quantum control systems."}
{"id": "2602.14830", "categories": ["math.OC", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14830", "abs": "https://arxiv.org/abs/2602.14830", "authors": ["Souvik Das", "Luca Schenato", "Subhrakanti Dey"], "title": "On Convergence Analysis of Network-GIANT: An approximate Hessian-based fully distributed optimization algorithm", "comment": "11 pages, 9 figures", "summary": "In this paper, we present a detailed convergence analysis of a recently developed approximate Newton-type fully distributed optimization method for smooth, strongly convex local loss functions, called Network-GIANT, which has been empirically illustrated to show faster linear convergence properties while having the same communication complexity (per iteration) as its first order distributed counterparts. By using consensus based parameter updates, and a local Hessian based descent direction at the individual nodes with gradient tracking, we first explicitly characterize a global linear convergence rate for Network-GIANT, which can be computed as the spectral radius of a $3 \\times 3$ matrix dependent on the Lipschitz continuity ($L$) and strong convexity ($μ$) parameters of the objective functions, and the spectral norm ($σ$) of the underlying undirected graph represented by a doubly stochastic consensus matrix. We provide an explicit bound on the step size parameter $η$, below which this spectral radius is guaranteed to be less than $1$. Furthermore, we derive a mixed linear-quadratic inequality based upper bound for the optimality gap norm, which allows us to conclude that, under small step size values, asymptotically, as the algorithm approaches the global optimum, it achieves a locally linear convergence rate of $1-η(1 -\\fracγμ)$ for Network-GIANT, provided the Hessian approximation error $γ$ (between the harmonic mean of the local Hessians and the global hessian (the arithmetic mean of the local Hessians) is smaller than $μ$. This asymptotically linear convergence rate of $\\approx 1-η$ explains the faster convergence rate of Network-GIANT for the first time. Numerical experiments are carried out with a reduced CovType dataset for binary logistic regression over a variety of graphs to illustrate the above theoretical results."}
{"id": "2602.14167", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14167", "abs": "https://arxiv.org/abs/2602.14167", "authors": ["Shi-Xin Zhang", "Yu-Qin Chen", "Weitang Li", "Jiace Sun", "Wei-Guo Ma", "Pei-Lin Zheng", "Yu-Xiang Huang", "Qi-Xiang Wang", "Hui Yu", "Zhuo Li", "Xuyang Huang", "Zong-Liang Li", "Zhou-Quan Wan", "Shuo Liu", "Jiezhong Qiu", "Jiaqi Miao", "Zixuan Song", "Yuxuan Yan", "Kazuki Tsuoka", "Pan Zhang", "Lei Wang", "Heng Fan", "Chang-Yu Hsieh", "Hong Yao", "Tao Xiang"], "title": "TensorCircuit-NG: A Universal, Composable, and Scalable Platform for Quantum Computing and Quantum Simulation", "comment": "33 pages, 4 figures, the software framework is open-sourced at https://github.com/tensorcircuit/tensorcircuit-ng", "summary": "We present TensorCircuit-NG, a next-generation quantum software platform designed to bridge the gap between quantum physics, artificial intelligence, and high-performance computing. Moving beyond the scope of traditional circuit simulators, TensorCircuit-NG establishes a unified, tensor-native programming paradigm where quantum circuits, tensor networks, and neural networks fuse into a single, end-to-end differentiable computational graph. Built upon industry-standard machine learning backends (JAX, TensorFlow, PyTorch), the framework introduces comprehensive capabilities for approximate circuit simulation, analog dynamics, fermion Gaussian states, qudit systems, and scalable noise modeling. To tackle the exponential complexity of deep quantum circuits, TensorCircuit-NG implements advanced distributed computing strategies, including automated data parallelism and model-parallel tensor network slicing. We validate these capabilities on GPU clusters, demonstrating a near-linear speedup in distributed variational quantum algorithms. TensorCircuit-NG enables flagship applications, including end-to-end QML for CIFAR-100 computer vision, efficient pipelines from quantum states to neural networks via classical shadows, and differentiable optimization of tensor network states for many-body physics."}
{"id": "2602.14881", "categories": ["math.OC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14881", "abs": "https://arxiv.org/abs/2602.14881", "authors": ["Eloi Martinet", "Ilias Ftouhi"], "title": "Numerical exploration of the range of shape functionals using neural networks", "comment": "21 pages, 8 figures", "summary": "We introduce a novel numerical framework for the exploration of Blaschke--Santaló diagrams, which are efficient tools characterizing the possible inequalities relating some given shape functionals. We introduce a parametrization of convex bodies in arbitrary dimensions using a specific invertible neural network architecture based on gauge functions, allowing an intrinsic conservation of the convexity of the sets during the shape optimization process. To achieve a uniform sampling inside the diagram, and thus a satisfying description of it, we introduce an interacting particle system that minimizes a Riesz energy functional via automatic differentiation in PyTorch. The effectiveness of the method is demonstrated on several diagrams involving both geometric and PDE-type functionals for convex bodies of $\\mathbb{R}^2$ and $\\mathbb{R}^3$, namely, the volume, the perimeter, the moment of inertia, the torsional rigidity, the Willmore energy, and the first two Neumann eigenvalues of the Laplacian."}
{"id": "2602.14175", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.14175", "abs": "https://arxiv.org/abs/2602.14175", "authors": ["Nadia Koliopoulou", "Charis Anastopoulos", "Ntina Savvidou"], "title": "Quantum field theory measurements for relativistic particles", "comment": "26 pages. latex", "summary": "The formulation of a consistent measurement theory for relativistic quantum fields has become a problem of growing foundational and practical significance. Standard non-relativistic measurement models fail to incorporate the essential relativistic principles of locality, causality, and Lorentz covariance, and are therefore inadequate for quantum field theoretic settings. While most existing work focuses on scalar fields, realistic particles possess spin, polarization, and internal degrees of freedom that introduce new conceptual and operational challenges. To this end, we employ the Quantum Temporal Probabilities (QTP) framework for relativistic measurements to describe electromagnetic, Dirac, and internally structured scalar fields. Our results include probabilities for the time-of-arrival that take spin/polarization into account, generalized photodetection formulas beyond Glauber's theory, an unambiguous derivation of the particle oscillation formula together with its limitations, and a first-principles analysis of relativistic qudits."}
{"id": "2602.14944", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14944", "abs": "https://arxiv.org/abs/2602.14944", "authors": ["Matteo Della Rossa", "Thiago Alves Lima", "Lorenzo Freddi"], "title": "Pattern preservation in finite to infinite-horizon optimal control problems for dissipative systems", "comment": null, "summary": "This paper focuses on infinite-horizon optimal control problems for dissipative systems and the relations to their finite-horizon formulations. We show that, for a large class of problems, dissipativity of the state equation, when a coercive storage function exists, implies that infinite-horizon optimal controls can be obtained as limits of the corresponding finite-horizon ones. This property is referred to as pattern preservation, or pattern-preserving property.\n  Our analysis establishes a formal link between dissipativity theory and the variational convergence framework in optimal control, thus providing a concrete and numerically tractable condition for verifying pattern preservation. Numerical examples illustrate the effectiveness and limitations of the proposed sufficient conditions."}
{"id": "2602.14240", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.14240", "abs": "https://arxiv.org/abs/2602.14240", "authors": ["Sara Congia", "Leopold Virot", "Elena Rovetta", "Antonio Fincato", "Frederic Boeuf", "Matteo Galli", "Daniele Bajoni", "Massimo Borghi"], "title": "Fully integrated quantum frequency processor on a silicon chip", "comment": null, "summary": "Frequency-bin encoding has recently emerged as a powerful approach for photonic quantum information processing, offering high dimensionality, gate-parallelization, and compatibility with existing telecommunication infrastructure. However, its scalable deployment has so far been hindered by the lack of an integrated platform capable of unifying quantum state generation, coherent frequency mixing, and programmable spectral control.\\\\ Here, we report the first fully integrated quantum frequency processor, monolithically integrating on the same silicon photonic chip a microresonator-based biphoton quantum frequency comb source, a pump-rejection filter, high-speed phase modulators, and a four-channel, line-by-line pulse shaper. We demonstrate key functionalities, such as tunable frequency beamsplitters with success probabilities exceeding $94\\%$ and fidelities above $99.9\\%$, as well as the ability to synthesize more general single-qubit gates. Finally, we generate and coherently manipulate high-dimensional frequency-bin entangled states entirely on chip, showcasing control over two-photon quantum walks and performing the first on-chip frequency-bin quantum state tomography of a Bell-state with a fidelity of $95.7(3)\\%$. By integrating all key functional elements on the same $4\\times7\\,\\textrm{mm}^2$ chip, with the possibility of scaling to a larger number of modes, our work marks an important step toward large-scale frequency-domain photonic processors for both classical and quantum applications."}
{"id": "2602.14949", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.14949", "abs": "https://arxiv.org/abs/2602.14949", "authors": ["Sarah Yini Gao", "Xindong Tang", "Yancheng Yuan"], "title": "Max-Min Bilinear Completely Positive Programs: A Semidefinite Relaxation with Tightness Guarantees", "comment": "44 pages, 2 figures", "summary": "Max-min bilinear optimization models, where one agent maximizes and an adversary minimizes a common bilinear objective, serve as canonical saddle-point formulations in optimization theory. They capture, among others, two-player zero-sum games, robust and distributionally robust optimization, and adversarial machine learning. This study focuses on the subclass whose variables lie in the completely positive (CP) cone, capturing a broad family of mixed-binary quadratic max-min problems through the modelling power of completely positive programming. We show that such problems admit an equivalent single-stage linear reformulation over the COP-CP cone, defined as the Cartesian product of the copositive (COP) and CP cones. Because testing membership in COP cones is co-NP-complete, the resulting COP-CP program inherits NP-hardness. To address this challenge, we develop a hierarchy of semidefinite relaxations based on moment and sum-of-squares representations of the COP and CP cones, and flat truncation conditions are applied to certify the tightness. We show that the tightness of the hierarchy is guaranteed under mild conditions. The framework extends existing CP/COP approaches for distributionally robust optimization and polynomial games. We apply the framework to the cyclic Colonel Blotto game, an extension of Borel's classic allocation contest. Across multiple instances, the semidefinite relaxation meets the flat-truncation conditions and solves the exact mixed-strategy equilibrium."}
{"id": "2602.14245", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14245", "abs": "https://arxiv.org/abs/2602.14245", "authors": ["José J Gil"], "title": "Geometric phase of arbitrary Mueller evolutions and its two-level quantum analogue", "comment": "6 pages", "summary": "We show that, for any physically realizable Mueller transformation -- including arbitrarily depolarizing maps -- the interferometric (Pancharatnam) geometric phase is fixed uniquely by the SO(3) rotation associated with the unitary (retarding) part of the pure characteristic component selected by the characteristic decomposition. All remaining characteristic contributions (discriminant and maximally mixed) can only reduce fringe visibility; they never generate geometric holonomy, even if their pure constituents involve rotations. We further establish the quantum analogue for open two-level dynamics: in the Choi representation of qubit channels, the geometric phase is fixed by the coherent unitary part of the dominant rank-one characteristic component, while the remaining dissipative structure affects visibility only."}
{"id": "2602.15000", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15000", "abs": "https://arxiv.org/abs/2602.15000", "authors": ["Uijeong Jang", "Kaizhao Sun", "Wotao Yin", "Ernest K Ryu"], "title": "ALiA: Adaptive Linearized ADMM", "comment": "41 pages", "summary": "We propose ALiA, a novel adaptive variant of the alternating direction method of multipliers (ADMM). Specifically, ALiA is a variant of function-linearized proximal ADMM (FLiP ADMM), which generalizes the classical ADMM by leveraging the differentiable structure of the objective function, making it highly versatile. Notably, ALiA features an adaptive stepsize selection scheme that eliminates the need for backtracking linesearch. Motivated by recent advances in adaptive gradient and proximal methods, we establish point convergence of ALiA for convex and differentiable objectives. Furthermore, by introducing negligible computational overhead, we develop an alternative stepsize selection scheme for ALiA that improves the convergence speed both theoretically and empirically. Extensive numerical experiments on practical datasets confirm the accelerated performance of ALiA compared to standard FLiP ADMM. Additionally, we demonstrate that ALiA either outperforms or matches the practical performance of existing adaptive methods across problem classes where it is applicable."}
{"id": "2602.14273", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14273", "abs": "https://arxiv.org/abs/2602.14273", "authors": ["Willers Yang", "Jason Chadwick", "Mariesa H. Teo", "Joshua Viszlai", "Fred Chong"], "title": "RASCqL: Reaction-time-limited Architecture for Space-time-efficient Complex qLDPC Logic", "comment": null, "summary": "Quantum low-density parity-check (qLDPC) codes offer a promising route to scalable fault-tolerant quantum computing (FTQC) due to their substantially reduced footprint, but these gains can be diluted at utility scale if we cannot also realize a space-time-efficient instruction-set architecture (ISA) for relevant quantum applications. We present RASCqL, a Reaction-time-limited Architecture for Space-time-efficient Complex qLDPC Logic, introducing a complex-instruction-set quantum computer (CISQ) that supports key algorithmic subroutines such as quantum arithmetic, table lookups, and magic-state distillation directly in co-designed qLDPC codes.\n  Unlike prior constructions for qLDPC logic that aim at versatile ISAs amenable to diverse circuits, RASCqL adopts an application-tailored code-modification scheme that embeds specific complex Clifford instructions useful for functional subroutines as virtually implementable matrix automorphisms. RASCqL further leverages parallel physical operations in reconfigurable neutral-atom array platforms to achieve fast QEC cycles and high-fidelity transversal operations. At the cost of increased design complexity, RASCqL implements key algorithmic subroutines at space-time costs comparable to state-of-the-art transversal surface-code architectures while achieving up to $2\\times$ to $7\\times$ footprint reduction under realistic physical error rates of $2 \\times 10^{-3}$ to $5 \\times 10^{-4}$, without additional hardware complexity. RASCqL thus demonstrates a concrete path forward for qLDPC codes as CISQ compute modules, extending their practical utility in fault-tolerant quantum computing architectures."}
{"id": "2602.13494", "categories": ["quant-ph", "cs.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.13494", "abs": "https://arxiv.org/abs/2602.13494", "authors": ["Brandon Augustino", "Dylan Herman", "Guneykan Ozgul", "Jacob Watkins", "Atithi Acharya", "Enrico Fontana", "Junhyung Lyle Kim", "Shouvanik Chakrabarti"], "title": "Quantum Speedups for Group Relaxations of Integer Linear Programs", "comment": null, "summary": "Integer Linear Programs (ILPs) are a flexible and ubiquitous model for discrete optimization problems. Solving ILPs is \\textsf{NP-Hard} yet of great practical importance. Super-quadratic quantum speedups for ILPs have been difficult to obtain because classical algorithms for many-constraint ILPs are global and exhaustive, whereas quantum frameworks that offer super-quadratic speedup exploit local structure of the objective and feasible set. We address this via quantum algorithms for Gomory's group relaxation. The group relaxation of an ILP is obtained by dropping nonnegativity on variables that are positive in the optimal solution of the linear programming (LP) relaxation, while retaining integrality of the decision variables. We present a competitive feasibility-preserving classical local-search algorithm for the group relaxation, and a corresponding quantum algorithm that, under reasonable technical conditions, achieves a super-quadratic speedup. When the group relaxation satisfies a nondegeneracy condition analogous to, but stronger than, LP non-degeneracy, our approach yields the optimal solution to the original ILP. Otherwise, the group relaxation tightens bounds on the optimal objective value of the ILP, and can improve downstream branch-and-cut by reducing the integrality gap; we numerically observe this on several practically relevant ILPs. To achieve these results, we derive efficiently constructible constraint-preserving mixers for the group relaxation with favorable spectral properties, which are of independent interest."}
{"id": "2602.14312", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14312", "abs": "https://arxiv.org/abs/2602.14312", "authors": ["E. Kongkui Berinyuy", "P. Djorwé", "A. N. Al-Ahmadi", "H. Ardah", "A. -H. Abdel-Aty"], "title": "Quantum entanglement enhanced via dark mode control in molecular optomechanics", "comment": null, "summary": "Quantum entanglement is an interesting resource for modern quantum technologies, where generating multiple quantum entanglement is highly required. However, entanglement engineering between multiple modes is strongly suppressed by dark mode effect. Here, we proposed a scheme based on molecular cavity optomechanical structure that enhances quantum bipartite and tripartite entanglement via dark mode breaking. Our proposal consists of an optical cavity that hosts two molecular ensembles which are coupled through an intermolecular coupling. A vibrational hopping rate $J_m$ captures the intermolecular coupling that is phase modulated via the synthetic gauge field method. The breaking of the dark mode is controlled by tuning both the intermolecular coupling and its modulation phase. By adjusting these parameters in our proposal, we can flexibly switch between the Dark Mode Unbroken (DMU) and the Dark Mode Broken (DMB) regimes. We find that in the dark-mode-unbroken regime, the amount of the generated bipartite and tripartite entanglement is significantly low or is suppressed. In contrast, in the dark-mode-broken regime, the entanglement is greatly enhanced,i.e., up to twofold enhancement. Moreover, the generated entanglement is more resilient against thermal noise in the dark-mode-broken regime compared to the thermal robustness in the unbroken regime. Therefore, our proposed scheme serves as a benckmark system to improve quantum correlations engineering, and to generate noise-tolerant quantum resources for applications in numerous modern quantum technologies."}
{"id": "2602.13871", "categories": ["math.ST", "cs.IT", "cs.LG", "math.OC", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.13871", "abs": "https://arxiv.org/abs/2602.13871", "authors": ["Sai Ravela", "Jae Deok Kim", "Kenneth Gee", "Xingjian Yan", "Samson Mercier", "Lubna Albarghouty", "Anamitra Saha"], "title": "Ensemble-Conditional Gaussian Processes (Ens-CGP): Representation, Geometry, and Inference", "comment": "20 pages. Technical manuscrupt on representational equivalence between conditional Gaussian inference, quadratic optimization, and RKHS geometry in finite dimensions", "summary": "We formulate Ensemble-Conditional Gaussian Processes (Ens-CGP), a finite-dimensional synthesis that centers ensemble-based inference on the conditional Gaussian law. Conditional Gaussian processes (CGP) arise directly from Gaussian processes under conditioning and, in linear-Gaussian settings, define the full posterior distribution for a Gaussian prior and linear observations. Classical Kalman filtering is a recursive algorithm that computes this same conditional law under dynamical assumptions; the conditional Gaussian law itself is therefore the underlying representational object, while the filter is one computational realization. In this sense, CGP provides the probabilistic foundation for Kalman-type methods as well as equivalent formulations as a strictly convex quadratic program (MAP estimation), RKHS-regularized regression, and classical regularization. Ens-CGP is the ensemble instantiation of this object, obtained by treating empirical ensemble moments as a (possibly low-rank) Gaussian prior and performing exact conditioning. By separating representation (GP -> CGP -> Ens-CGP) from computation (Kalman filters, EnKF variants, and iterative ensemble schemes), the framework links an earlier-established representational foundation for inference to ensemble-derived priors and clarifies the relationships among probabilistic, variational, and ensemble perspectives."}
{"id": "2602.14327", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14327", "abs": "https://arxiv.org/abs/2602.14327", "authors": ["Dhanvi Bharadwaj", "Yuewen Hou", "Guang-Yi Li", "Gokul Subramanian Ravi"], "title": "Scalable Clifford-Based Classical Initialization for the Quantum Approximate Optimization Algorithm", "comment": null, "summary": "Variational Quantum Algorithms (VQAs), such as the Quantum Approximate Optimization Algorithm (QAOA), offer a promising route to tackling combinatorial optimization problems on near and intermediate-term quantum devices. However, their performance critically depends on the choice of initial parameters, and the limited expressiveness of the QAOA ansatz makes identifying effective initializations both difficult and unscalable. To address this, we propose a framework, Scalable Parameter Initialization for QAOA (SPIQ), that employs a relaxed QAOA ansatz to enable classical search over a set of Clifford-preparable quantum states that yield high-quality solutions. These states serve as superior QAOA initializations, driving rapid convergence while significantly reducing the quantum circuit evaluations needed to reach high-quality solutions and consequently lowering quantum-device cost. We present a scalable, application-agnostic initialization framework that achieves an absolute accuracy improvement of up to 80% over state-of-the-art initialization and reduces initial-state diversity by up to 10,000x across QUBO, PUBO, and PCBO problems spanning tens to hundreds of qubits. We further benchmark its performance on a wide range of problem formulations and instances derived from real-world datasets, demonstrating consistent and scalable improvements. Furthermore, we introduce two complementary strategies for selecting high-quality Clifford points identified by our search procedure and using them to seed multi-start optimization, thereby enhancing exploration and improving solution quality."}
{"id": "2602.14472", "categories": ["math.ST", "cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.14472", "abs": "https://arxiv.org/abs/2602.14472", "authors": ["Somjit Roy", "Prateek Jaiswal", "Anirban Bhattacharya", "Debdeep Pati", "Bani K. Mallick"], "title": "Frequentist Regret Analysis of Gaussian Process Thompson Sampling via Fractional Posteriors", "comment": "34 pages, Submitted", "summary": "We study Gaussian Process Thompson Sampling (GP-TS) for sequential decision-making over compact, continuous action spaces and provide a frequentist regret analysis based on fractional Gaussian process posteriors, without relying on domain discretization as in prior work. We show that the variance inflation commonly assumed in existing analyses of GP-TS can be interpreted as Thompson Sampling with respect to a fractional posterior with tempering parameter $α\\in (0,1)$. We derive a kernel-agnostic regret bound expressed in terms of the information gain parameter $γ_t$ and the posterior contraction rate $ε_t$, and identify conditions on the Gaussian process prior under which $ε_t$ can be controlled. As special cases of our general bound, we recover regret of order $\\tilde{\\mathcal{O}}(T^{\\frac{1}{2}})$ for the squared exponential kernel, $\\tilde{\\mathcal{O}}(T^{\\frac{2ν+3d}{2(2ν+d)}} )$ for the Matérn-$ν$ kernel, and a bound of order $\\tilde{\\mathcal{O}}(T^{\\frac{2ν+3d}{2(2ν+d)}})$ for the rational quadratic kernel. Overall, our analysis provides a unified and discretization-free regret framework for GP-TS that applies broadly across kernel classes."}
{"id": "2602.14333", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14333", "abs": "https://arxiv.org/abs/2602.14333", "authors": ["Leon Bello", "Boris Mesits", "Michael Hatridge", "Hakan E. Türeci"], "title": "High-fidelity Quantum Readout Processing via an Embedded SNAIL Amplifier", "comment": null, "summary": "Scalable, high-fidelity quantum-state readout remains a central challenge in the development of large-scale superconducting quantum processors. Conventional dispersive readout architectures depend on bulky isolators and external amplifiers, introducing significant hardware overhead and limiting opportunities for on-chip information processing. In this work, we propose a novel approach that embeds a nonlinear Superconducting Nonlinear Asymmetric Inductive eLement (SNAIL) into the readout chain, enabling coherent and directional processing of readout signals directly on-chip. This embedded SNAIL platform allows frequency-multiplexed resonators to interact through engineered couplings, forming a tunable readout-amplifier-output architecture that can manipulate quantum readout data \\textit{in situ}. Through theoretical modeling and numerical optimization, we show that this platform enhances fidelity, suppresses measurement-induced decoherence, and simplifies hardware complexity. These results establish the hybridized SNAIL as a promising building block for scalable and coherent quantum-state readout in next-generation processors."}
{"id": "2602.14765", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.14765", "abs": "https://arxiv.org/abs/2602.14765", "authors": ["Ariana R. Mendez-Castillo", "Rodrigo Aldana-Lopez", "Antonio Ramirez-Trevino", "Rosario Aragues", "David Gomez-Gutierrez"], "title": "Hierarchical parameter estimation for distributed networked systems: a dynamic consensus approach", "comment": null, "summary": "This work introduces a novel two-stage distributed framework to globally estimate constant parameters in a networked system, separating shared information from local estimation. The first stage uses dynamic average consensus to aggregate agents' measurements into surrogates of centralized data. Using these surrogates, the second stage implements a local estimator to determine the parameters. By designing an appropriate consensus gain, the persistence of excitation of the regressor matrix is achieved, and thus, exponential convergence of a local Gradient Estimator (GE) is guaranteed. The framework facilitates its extension to switched network topologies, quantization, and the heterogeneous substitution of the GE with a Dynamic Regressor Extension and Mixing (DREM) estimator, which supports relaxed excitation requirements."}
{"id": "2602.14379", "categories": ["quant-ph", "cs.CC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.14379", "abs": "https://arxiv.org/abs/2602.14379", "authors": ["Nai-Hui Chia", "Atsuya Hasegawa", "François Le Gall", "Yu-Ching Shen"], "title": "Fine-Grained Complexity for Quantum Problems from Size-Preserving Circuit-to-Hamiltonian Constructions", "comment": "37 pages. Supersedes arXiv:2510.07495", "summary": "The local Hamiltonian (LH) problem is the canonical $\\mathsf{QMA}$-complete problem introduced by Kitaev. In this paper, we show its hardness in a very strong sense: we show that the 3-local Hamiltonian problem on $n$ qubits cannot be solved classically in time $O(2^{(1-\\varepsilon)n})$ for any $\\varepsilon>0$ under the Strong Exponential-Time Hypothesis (SETH), and cannot be solved quantumly in time $O(2^{(1-\\varepsilon)n/2})$ for any $\\varepsilon>0$ under the Quantum Strong Exponential-Time Hypothesis (QSETH). These lower bounds give evidence that the currently known classical and quantum algorithms for LH cannot be significantly improved.\n  Furthermore, we are able to demonstrate fine-grained complexity lower bounds for approximating the quantum partition function (QPF) with an arbitrary constant relative error. Approximating QPF with relative error is known to be equivalent to approximately counting the dimension of the solution subspace of $\\mathsf{QMA}$ problems. We show the SETH and QSETH hardness to estimate QPF with constant relative error. We then provide a quantum algorithm that runs in $O(\\sqrt{2^n})$ time for an arbitrary $1/\\mathrm{poly}(n)$ relative error, matching our lower bounds and improving the state-of-the-art algorithm by Bravyi, Chowdhury, Gosset, and Wocjan (Nature Physics 2022) in the low-temperature regime.\n  To prove our fine-grained lower bounds, we introduce the first size-preserving circuit-to-Hamiltonian construction that encodes the computation of a $T$-time quantum circuit acting on $N$ qubits into a $(d+1)$-local Hamiltonian acting on $N+O(T^{1/d})$ qubits. This improves the standard construction based on the unary clock, which uses $N+O(T)$ qubits."}
{"id": "2602.14396", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14396", "abs": "https://arxiv.org/abs/2602.14396", "authors": ["Hiroto Kasai", "Seiichiro Tani", "Yasuhiro Tokura", "Yuki Takeuchi"], "title": "Anonymous quantum sensing robust against state preparation errors", "comment": "25 pages, 5 figures", "summary": "Networked quantum sensors have several applications such as the mapping of magnetic fields. When the magnetic fields are biomagnetic ones, i.e., they contain some private information, the information of from who non-zero magnetic fields occur has to be protected from eavesdroppers. Anonymous quantum sensing keeps it secret by estimating amplitudes of the magnetic fields without disclosing the positions of non-zero magnetic fields. In this paper, we propose an anonymous quantum sensing protocol that is robust against any independent noise in state preparations. To this end, we devise a quantum state verification protocol for a superposition of Greenberger-Horne-Zeilinger and Dicke states and combine it with the original protocol of anonymous quantum sensing. Our verification protocol can decide whether the fidelity between the ideal and actual states is high or low more efficiently than the direct fidelity estimation. Since the original protocol of anonymous quantum sensing cannot correctly estimate the amplitudes of the magnetic fields under state preparation errors, our results would improve the performance of anonymous quantum sensing in realistic situations."}
{"id": "2602.14420", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14420", "abs": "https://arxiv.org/abs/2602.14420", "authors": ["Lucas Ferreira R. de Moura", "Daniel Y. Akamatsu", "G. D. de Moraes Neto", "Norton G. de Almeida"], "title": "The Multiparameter Frontier: Metrological Hierarchy and Robustness in Dispersive Quantum Interferometry", "comment": null, "summary": "We present a dispersive quantum thermometry protocol for simultaneous estimation of inverse temperature $β$ and interaction strength $x$ using a nonlinear Mach-Zehnder interferometer coupled to a thermal ancilla. We derive closed-form expressions for the quantum Fisher information matrix, establishing that metrological performance depends solely on the thermal visibility $\\mathcal{V}(β)$ and its derivative. The output state remains diagonal in photon-number basis, making photon counting globally optimal and saturating the multiparameter quantum Cramér-Rao bound without adaptive feedback. Moving beyond ideal unitary evolution, we analyze protocol robustness under concurrent amplitude and phase damping. Using Fisher Information Susceptibility, we establish a clear hierarchy: NOON states offer maximal theoretical sensitivity but exhibit exponential fragility to loss, rendering them impractical. Squeezed vacuum states emerge as robust candidates for steady-state sensing, while cat states prove compelling for transient thermometry by retaining significant coherence after photon loss. We validate these predictions through digital quantum circuit implementation on IBM's \\texttt{ibm_torino} processor. Experimental results confirm the predicted Fisher information landscape while revealing systematic noise-induced biases, demonstrating that current NISQ hardware can effectively benchmark fundamental trade-offs in multiparameter quantum sensing."}
{"id": "2602.14426", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.14426", "abs": "https://arxiv.org/abs/2602.14426", "authors": ["Holly G. Stemp", "Mark R. van Blankenstein", "Benjamin Wilhelm", "Serwan Asaad", "Mateusz T. Mądzik", "Arne Laucht", "Fay E. Hudson", "Andrew S. Dzurak", "Kohei M. Itoh", "Alexander M. Jakob", "Brett C. Johnson", "David N. Jamieson", "Andrea Morello"], "title": "Electron readout contrast enhancement in the parallel nuclear regime of an exchange-coupled donor spin qubit system", "comment": null, "summary": "Recent experiments on donor-based spin qubits in silicon have leveraged the exchange interaction between electrons bound to separate donor nuclei to perform two-qubit operations. A consistently observed yet unexplained phenomenon in such systems is the significant increase in electron readout contrast, measured via Elzerman-style readout to a single-electron transistor (SET) island, when the donor nuclei are initialized in a parallel spin orientation compared to an anti-parallel orientation. In this work, we present a detailed analysis of the exchange-coupled donor system in the parallel nuclear regime and propose a physical mechanism for this effect. We attribute the enhanced readout contrast to an additional electron tunneling event to the SET during a single read period, when the donor nuclei are aligned in a parallel spin configuration. These insights inform strategies for improving electron readout fidelity in these systems and contribute to a more complete understanding of spin-dependent tunnelling processes in donor-based qubit architectures."}
{"id": "2602.14437", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14437", "abs": "https://arxiv.org/abs/2602.14437", "authors": ["Adel Ali", "Alexey Belyanin"], "title": "Fermionic Stoner-Dicke phase transition in Circuit Quantum Magnetostatics", "comment": "11 pages, 3 figures", "summary": "We present a minimal tunable many-body system of fermions coupled to quantum magnetic flux, which is analytically diagonalizable and exhibits a variety of many-body phenomena such as Stoner orbital instability and Dicke-like quantum phase transition. In contrast to standard cavity quantum electrodynamics with its electric-dipole coupling of the electric field operators with matter, here it is the quantized magnetic field of an LC-resonator which is coupled to the angular momentum of particles. Adding the Josephson junction (JJ) to the linear LC circuit allows us to explore nonlinear flux-matter phases and sector-selective photon dressing in regimes relevant to circuit QED and mesoscopic rings. Furthermore, we consider the tight-binding systems that exhibit a tunable nonlinearity representing artificial JJ, but without actual JJs included in the circuit."}
{"id": "2602.14461", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.14461", "abs": "https://arxiv.org/abs/2602.14461", "authors": ["Tai Hyun Yoon"], "title": "A hardware-native time-frequency GKP logical qubit toward fault-tolerant photonic operation", "comment": "20 pages, 4 figures", "summary": "We realize a hardware-native time--frequency Gottesman--Kitaev--Preskill (GKP) logical qubit encoded in the continuous phase space of single photons, establishing a propagating photonic implementation of bosonic grid encoding. Finite-energy grid states are generated deterministically using coherently driven entangled nonlinear biphoton sources that produce single-photon frequency-comb supermodes. An optical-frequency-comb reference anchors the time--frequency phase space and enforces commuting displacement stabilizers directly at the hardware level, continuously defining the logical subspace. Timing jitter, spectral drift, and phase noise map naturally onto Gaussian displacement errors within this lattice, yielding intrinsic correctability inside a stabilizer cell. Logical operations correspond to experimentally accessible phase and delay controls, enabling deterministic state preparation and manipulation. Building on the modal time--frequency GKP framework, we identify a concrete pathway toward active syndrome extraction and deterministic displacement recovery using ancillary grid states and interferometric time--frequency measurements. These primitives establish a hardware-compatible route for integrating the time--frequency GKP logical layer into erasure-aware and fusion-based fault-tolerant photonic architectures."}
{"id": "2602.14465", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14465", "abs": "https://arxiv.org/abs/2602.14465", "authors": ["Daniel Sudarsky", "Octavio Guerrero"], "title": "A lesson from a small particle about quantum theory with strong implications for cosmology", "comment": null, "summary": "The establishment of extremely strong bounds on the magnitude of the electric dipole moment of the neutron, a quantity that is of great importance for determining the level of time reversal symmetry respected by the strong interactions, offers an important lesson regarding the manner in which quantum uncertainties are interpreted in the inflationary cosmological account of the generation of the primordial inhomogeneities that give rise to the universe's structure. The identification of quantum uncertainties with actual stochastic fluctuations, a standard aspect of the current physical account for the emergence of the cosmic structure, is called into question. This opens the door for novel aspects of physics that are needed in order to provide a satisfactory account that is both conceptually clear and does not conflict with the use of quantum theory in other settings."}
{"id": "2602.14499", "categories": ["quant-ph", "cond-mat.str-el", "hep-th", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.14499", "abs": "https://arxiv.org/abs/2602.14499", "authors": ["Junichi Haruna"], "title": "Homological origin of transversal implementability of logical diagonal gates in quantum CSS codes", "comment": "7 pages, no figure, no table. Supplementary material will be included in a subsequent version", "summary": "Transversal Pauli Z rotations provide a natural route to fault-tolerant logical diagonal gates in quantum CSS codes, yet their capability is fundamentally constrained. In this work, we formulate the refinement problem of realizing a logical diagonal gate by a transversal implementation with a finer discrete rotation angle and show that its solvability is completely characterized by the Bockstein homomorphism in homology theory. Furthermore, we prove that the linear independence of the X-stabilizer generators together with the commutativity condition modulo a power of two ensures the existence of transversal implementations of all logical Pauli Z rotations with discrete angles in general CSS codes. Our results identify a canonical homological obstruction governing transversal implementability and provide a conceptual foundation for a formal theory of transversal structures in quantum error correction."}
{"id": "2602.14508", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14508", "abs": "https://arxiv.org/abs/2602.14508", "authors": ["Partha Ghose"], "title": "Bell-like States in Classical Optics: A Process-Theoretic and Sheaf-Theoretic (Categorical) Clarification", "comment": "12 pages, two figures and two line drawings", "summary": "Classical polarization optics is naturally described by a two-dimensional complex Hilbert space (Jones vectors), so the tensor-product kinematics underlying bipartite nonseparability is already available classically. For statistical (stochastic) optical fields, and under an operational stance where outcomes are not assumed pre-assigned prior to detection, suitably prepared two-beam polarization states can exhibit Bell--CHSH correlations of quantum strength. The same platform offers a tunable, low-cost testbed for stress-testing Bell/CHSH and contextuality witnesses under realistic imperfections (noise, coarse binning, selective sampling). We also outline an alternative preparation based on external conical refraction (ECR), where engineered intersecting conical-refraction rings mimic the intersecting emission cones of SPDC. We give a self-contained categorical formulation: the preparation-and-conditioning pipeline (Hadamard-like splitting, CNOT-like coupling, and routing/conditioning that removes unwanted contributions) is treated as a single morphism in an operational process theory (e.g. $\\mathbf{CPM}(\\mathbf{FHilb})$). From it we functorially extract an empirical model, i.e. a compatible family of context-indexed probability distributions. The Abramsky--Brandenburger sheaf criterion then applies: noncontextuality is the existence of a global section, and CHSH violation is a precise failure-to-glue. This separates kinematic nonseparability from operational contextuality and clarifies why neither, by itself, entails nonlocal causation; contextuality can arise in a classically implementable stochastic-optics regime."}
{"id": "2602.14554", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14554", "abs": "https://arxiv.org/abs/2602.14554", "authors": ["Zhao-Wei Wang", "Zhao-Ming Wang"], "title": "Forked Physics Informed Neural Networks for Coupled Systems of Differential equations", "comment": null, "summary": "Solving coupled systems of differential equations (DEs) is a central problem across scientific computing. While Physics Informed Neural Networks (PINNs) offer a promising, mesh-free approach, their standard architectures struggle with the multi-objective optimization conflicts and local optima traps inherent in coupled problems. To address the first issue, we propose a Forked PINN (FPINN) framework designed for coupled systems of DEs. FPINN employs a shared base network with independent branches, isolating gradient pathways to stabilize training. We demonstrate the effectiveness of FPINN in simulating non-Markovian open quantum dynamics governed by coupled DEs, where multi-objective conflicts and local optima traps often cause evolutionary stagnation. To overcome this second challenge, we incorporate an evolution regularization loss that guides the model away from trivial solutions and ensures physically meaningful evolution. We demonstrate the effectiveness of FPINN in simulating non-Markovian open quantum dynamics governed by coupled DEs, where multi-objective conflicts and local optima traps often cause evolutionary stagnation. For the spin-boson and XXZ models, FPINN accurately captures hallmark non-Markovian features, such as quantum coherence revival and information backflow, significantly outperforming standard PINNs. The proposed FPINN architecture offers a general and effective framework for solving coupled systems of equations, which arise across a broad spectrum from classical physics to modern artificial intelligence, including applications in multi-body rotational dynamics, multi-asset portfolio optimization, chemical reaction kinetics, and deep representation learning."}
{"id": "2602.14555", "categories": ["quant-ph", "physics.acc-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.14555", "abs": "https://arxiv.org/abs/2602.14555", "authors": ["N. V. Filina", "S. S. Baturin"], "title": "Effective Caldirola-Kanai Model for Accelerating Twisted Dirac States in Nonuniform Axial Fields", "comment": "9 pages, 2 figures", "summary": "We study relativistic twisted (orbital-angular-momentum) states of a massive charged particle propagating through an axially symmetric, longitudinally inhomogeneous solenoid field and a co-directed accelerating or decelerating electric field. Starting from the Dirac equation and using controlled spinless and paraxial approximations, we show that the transverse envelope obeys an effective nonstationary Schrödinger equation governed by a Caldirola--Kanai Hamiltonian. The longitudinal energy gain or loss encoded in $f(z)=[E_0-V(z)]^2-m^2$ generates an effective gain or damping rate $\\widetildeγ(z)=\\partial_z f(z)/[2f(z)]$ and a $z$-dependent oscillator frequency $\\widetildeω(z)=p_0Ω(z)/\\sqrt{f(z)}$. Exploiting the Ermakov mapping (unitary equivalence of Caldirola--Kanai systems), we obtain a closed-form propagated twisted wave function by transforming the stationary Landau basis. The transverse evolution is controlled by a single scaling function $b(z)$ that satisfies a generalized Ermakov--Pinney equation with coefficients determined by $E_z(z)$ and $B_z(z)$. In the limiting cases of uniform acceleration with $B_z=0$ and of solenoid focusing with negligible acceleration, our solution reduces to previously known analytic results, providing a direct bridge to established models."}
{"id": "2602.14556", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14556", "abs": "https://arxiv.org/abs/2602.14556", "authors": ["Yusei Tateyama", "Yuzuru Kato"], "title": "Sparse identification of quantum Hamiltonian dynamics via quantum circuit learning", "comment": "31 pages, 12 figures", "summary": "Sparse identification of nonlinear dynamics (SINDy) is a data-driven framework for estimating classical nonlinear dynamical systems from time-series data. In this approach, system dynamics is represented as a linear combination of a predefined set of basis functions, and the corresponding coefficients are sparsely estimated from observed time-series data. In this study, we propose sparse identification of quantum Hamiltonian dynamics (SIQHDy), a SINDy-inspired quantum circuit learning framework for estimating quantum Hamiltonian dynamics from time-series data of quantum measurement outcomes. In SIQHDy, the unitary evolution of a quantum Hamiltonian system is expressed as a product of basis quantum circuits, and the corresponding circuit parameters are estimated through sparsity-promoting optimization. We numerically demonstrate that SIQHDy accurately reconstructs the dynamics of single-, three-, and five-spin systems, and exhibits robustness to measurement noise in the three-spin case. Furthermore, we propose an extension of SIQHDy for scenarios with limited accessible observables and evaluate its performance in identifying two-spin systems and in network-structure identification for five-spin systems."}
{"id": "2602.14557", "categories": ["quant-ph", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2602.14557", "abs": "https://arxiv.org/abs/2602.14557", "authors": ["Xudong He", "Yu Chen"], "title": "Dissipative Spectroscopy", "comment": "6 pages, 3 figures", "summary": "We introduce dissipative spectroscopy as a framework for extracting spectral information from quantum systems via controlled dissipation. By establishing a general dissipative response theory applicable to both Markovian and non-Markovian environments, we develop a protocol to access the dissipative spectrum (DS) through driven oscillation-dissipation resonance. We show that the DS can identify two-particle soft modes near quantum critical points and, on the normal-phase side, predict the emergence of macroscopic order exhibiting power-law growth following a dissipation quench. These distinctive signatures appear in quasiparticle-dominant regimes, previously considered trivial. Furthermore, we introduce extended dissipative susceptibilities that capture leading memory effects and demonstrate their utility in a dissipative fermionic model. Our results indicate that the DS is readily accessible and offers a versatile tool for probing equilibrium properties as well as predicting nonequilibrium dissipative dynamics."}
{"id": "2602.14596", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14596", "abs": "https://arxiv.org/abs/2602.14596", "authors": ["Ban Q. Tran", "Nahid Binandeh Dehaghani", "Rafal Wisniewski", "Susan Mengel", "A. Pedro Aguiar"], "title": "Quantum-Assisted Trainable-Embedding Physics-Informed Neural Networks for Parabolic PDEs", "comment": "8 pages, 9 figures", "summary": "Physics-informed neural networks (PINNs) have emerged as a powerful framework for solving partial differential equations (PDEs) by embedding governing physical laws directly into the training objective. Recent advances in quantum machine learning have motivated hybrid quantum-classical extensions aimed at enhancing representational capacity while remaining compatible with near-term quantum hardware. In this work, we investigate trainable embedding strategies within quantum-assisted PINNs for solving parabolic PDEs, using one- and two-dimensional heat equations as canonical benchmarks. We introduce two quantum-assisted architectures that differ in their embedding components. In the first approach, a classical feed-forward neural network generates trainable feature maps for quantum data encoding (FNN-TE-QPINN). In the second, the embedding stage is realized entirely by a parameterized quantum circuit (QNN-TE-QPINN), yielding a fully quantum feature map. Our findings emphasize the critical role of embedding design and support hybrid quantum-classical approaches for parabolic PDE modeling in the NISQ era."}
{"id": "2602.14613", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.14613", "abs": "https://arxiv.org/abs/2602.14613", "authors": ["Conor Ryan", "Alessandro Lunghi"], "title": "On the challenge of simulating dipolar contributions to spin relaxation with generalized cluster correlation expansion methods", "comment": null, "summary": "The study of spin decoherence is often performed by assuming that spin-phonon interactions lead to relaxation at high temperatures, and spin-spin dipolar interactions instead contribute to pure dephasing at low temperatures. This has resulted in the neglect of spin relaxation due to spin-spin dipolar interactions and its influence on decoherence at low temperatures. For a complete understanding of low temperature spin dynamics, it is then imperative to focus also on the latter mechanism. One such method which has shown great promise in the efficient calculation of central spin dynamics due to spin-spin dipolar interactions with a surrounding spin bath is the Cluster-Correlation Expansion (CCE). An extension of this method through the explicit inclusion of the central spin degrees of freedom, known as the generalized Cluster-Correlation Expansion (gCCE) is capable of simulating the transfer of energy from the central spin into the bath, and thus could have the potential to investigate spin relaxation in this setting. In this work, we show that gCCE, in its standard form, is insufficient for providing even a qualitatively accurate description of spin-spin relaxation. A full mathematical deconstruction of the underlying theory of gCCE clearly points to the origin of such a breakdown and provides a starting point for its potential future resolution."}
{"id": "2602.14641", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14641", "abs": "https://arxiv.org/abs/2602.14641", "authors": ["Luke Antoncich", "Yuben Moodley", "Ugo Varetto", "Jingbo Wang", "Jonathan Wurtz", "Jing Chen", "Pascal Jahan Elahi", "Casey R. Myers"], "title": "Quantum Reservoir Computing with Neutral Atoms on a Small, Complex, Medical Dataset", "comment": null, "summary": "Biomarker-based prediction of clinical outcomes is challenging due to nonlinear relationships, correlated features, and the limited size of many medical datasets. Classical machine-learning methods can struggle under these conditions, motivating the search for alternatives. In this work, we investigate quantum reservoir computing (QRC), using both noiseless emulation and hardware execution on the neutral-atom Rydberg processor \\textit{Aquila}. We evaluate performance with six classical machine-learning models and use SHAP to generate feature subsets. We find that models trained on emulated quantum features achieve mean test accuracies comparable to those trained on classical features, but have higher training accuracies and greater variability over data splits, consistent with overfitting. When comparing hardware execution of QRC to noiseless emulation, the models are more robust over different data splits and often exhibit statistically significant improvements in mean test accuracy. This combination of improved accuracy and increased stability is suggestive of a regularising effect induced by hardware execution. To investigate the origin of this behaviour, we examine the statistical differences between hardware and emulated quantum feature distributions. We find that hardware execution applies a structured, time-dependent transformation characterised by compression toward the mean and a progressive reduction in mutual information relative to emulation."}
{"id": "2602.14647", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.14647", "abs": "https://arxiv.org/abs/2602.14647", "authors": ["Andrew C. Hunt", "Stuart C. Althorpe"], "title": "Exploiting the path-integral radius of gyration in open quantum dynamics", "comment": null, "summary": "A major challenge in open quantum dynamics is the inclusion of Matsubara-decay terms in the memory kernel, which arise from the quantum-Boltzmann delocalisation of the bath modes. This delocalisation can be quantified by the radius of gyration squared ${\\mathcal R}^2(ω)$ of the imaginary-time Feynman paths of the bath modes as a function of the frequency $ω$. In a Hierarchical Equations of Motion (HEOM) calculation with a Debye--Drude spectral density, ${\\mathcal R}^2(ω)$ is the only quantity that is treated approximately (assuming convergence with respect to hierarchy depth). Here, we show that the well-known Ishizaki--Tanimura correction is equivalent to separating smooth from `Brownian' contributions to ${\\mathcal R}^2(ω)$, and that modifying the correction leads to a more efficient HEOM in the case of fast baths. We also develop a simple `A4' adaptation of the `AAA' (Adaptive Antoulas--Anderson) algorithm in order to fit ${\\mathcal R}^2(ω)$ to a sum over poles, which results in an extremely efficient implementation of the standard HEOM method at low temperatures."}
{"id": "2602.14654", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.14654", "abs": "https://arxiv.org/abs/2602.14654", "authors": ["Marco Patriarca"], "title": "Boundary conditions for the Schrödinger equation in the numerical simulation of quantum systems", "comment": "7 pages, 4 figures", "summary": "We study the problem of the boundary conditions in the numerical simulation of closed and open quantum systems, described by a Schrödinger equation. On one hand, we show that a closed quantum system is defined by local boundary conditions. On the other hand, we argue that, because of the uncertainty principle, no local boundary condition can be defined for open quantum systems. For this reason plane waves or wave packet trains cannot be simulated on a finite numerical lattice with the usual procedures. We suggest a method that avoids these difficulties by using only a small numerical lattice and maintains the correspondence with the physical picture, in which the incident and scattered waves may be infinitely extended."}
{"id": "2602.14661", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14661", "abs": "https://arxiv.org/abs/2602.14661", "authors": ["Athanasios Kostikas", "Yaroslav Valchyshen", "Paul Cadden-Zimansky"], "title": "Geometric Visualizations of Quantum Mixed States and Density Matrices", "comment": "46 pages, 10 figures", "summary": "This paper presents an introduction to geometric representations of quantum states in which each distinct quantum state, pure and mixed, corresponds to a unique point in a Euclidean space. Beginning with a review of some underappreciated properties of the most commonly used geometric representation, the Bloch sphere visualization of qubit states, we show how concepts, algorithms, and spatial relations viewable on this geometric representation can be extended to representations of qudit states of any finite quantum dimension $d$ and on to the infinite-dimensional limit. A primary goal of the work is helping the reader develop a visual intuition of these spaces, which can complement the understanding of the algebraic formalism of quantum mechanics for learners, teachers, and researchers at any level. Particular emphasis is given both to understanding states in a basis-independent way and to understanding how probability amplitudes and density matrix elements used to algebraically represent states in a particular basis correspond to line segments and angles in the geometric representations. In addition to providing visualizations for such concepts as superpositions, mixtures, decoherence, and measurement, we demonstrate how the representations can be used to substitute simple geometrical calculations for more cumbersome linear algebra ones, which may be of particular use in introducing mixed states and density matrices to beginning quantum students at an early stage. The work concludes with the geometrical interpretation of some commonly used metrics such as the purity of states and their relation to real, Euclidean vectors in the infinite-dimensional limit of the space, which contains all lower-dimensional qudit spaces as subspaces."}
{"id": "2602.14677", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14677", "abs": "https://arxiv.org/abs/2602.14677", "authors": ["Markus Gross", "Hans-Martin Rieser"], "title": "Kernel-based optimization of measurement operators for quantum reservoir computers", "comment": "26 pages, 4 figures", "summary": "Finding optimal measurement operators is crucial for the performance of quantum reservoir computers (QRCs), since they employ a fixed quantum feature map. We formulate the training of both stateless (quantum extreme learning machines, QELMs) and stateful (memory dependent) QRCs in the framework of kernel ridge regression. This approach renders an optimal measurement operator that minimizes prediction error for a given reservoir and training dataset. For large qubit numbers, this method is more efficient than the conventional training of QRCs. We discuss efficiency and practical implementation strategies, including Pauli basis decomposition and operator diagonalization, to adapt the optimal observable to hardware constraints. Numerical experiments on image classification and time series prediction tasks demonstrate the effectiveness of this approach, which can also be applied to other quantum ML models."}
{"id": "2602.14678", "categories": ["quant-ph", "cond-mat.dis-nn", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.14678", "abs": "https://arxiv.org/abs/2602.14678", "authors": ["Aditi Rath", "Dinesh Kumar Panda", "Colin Benjamin"], "title": "NISQ-compatible quantum cryptography based on Parrondo dynamics in discrete-time quantum walks", "comment": "23 pages, 24 figures, 3 tables", "summary": "Compatibility with noisy intermediate-scale quantum (NISQ) devices is crucial for the realistic implementation of quantum cryptographic protocols. We investigate a cryptographic scheme based on discrete-time quantum walks (DTQWs) on cyclic graphs that exploits Parrondo dynamics, wherein periodic evolution emerges from a deterministic sequence of individually chaotic coin operators. We construct an explicit quantum circuit realization tailored to NISQ architectures and analyze its performance through numerical simulations in Qiskit under both ideal and noisy conditions. Protocol performance is quantified using probability distributions, Hellinger fidelity, and total variation distance. To assess security at the circuit level, we model intercept-resend and man-in-the-middle attacks and evaluate the resulting quantum bit error rate. In the absence of adversarial intervention, the protocol enables reliable message recovery, whereas eavesdropping induces characteristic disturbances that disrupt the periodic reconstruction mechanism. We further examine hardware feasibility on contemporary NISQ processors, specifically $ibm\\_torino$, incorporating qubit connectivity and state-transfer constraints into the circuit design. Our analysis demonstrates that communication between spatially separated logical modules increases circuit depth via SWAP operations, leading to cumulative noise effects. By exploring hybrid state-transfer strategies, we show that qubit selection and connectivity play a decisive role in determining fidelity and overall protocol performance, highlighting hardware-dependent trade-offs in NISQ implementations."}
{"id": "2602.14688", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.14688", "abs": "https://arxiv.org/abs/2602.14688", "authors": ["Adnan Naimy", "Abdallah Slaoui", "Abderrahim Lakhfif", "Rachid Ahl Laamara"], "title": "Enhanced multiparameter quantum estimation in cavity magnomechanics via a coherent feedback loop", "comment": null, "summary": "Multiparameter quantum metrology plays a fundamental role in uncovering and exploiting the distinctive features of quantum systems. In this work, we propose an effective and experimentally feasible scheme to significantly enhance the simultaneous quantum estimation of the photon magnon and magnon mechanical coupling strengths in a hybrid cavity magnon mechanical platform. Our approach relies on the assistance of a coherent feedback loop combined with the injection of a coherent driving field. We show that an appropriate tuning of the system and feedback parameters leads to a substantial reduction of the estimation errors associated with both coupling strengths. To quantify the metrological performance of the proposed scheme, we employ the quantum Cramer Rao bound (QCRB) as a fundamental benchmark for multiparameter estimation. We explicitly compute and compare the QCRBs derived from the symmetric logarithmic derivative (SLD) and the right logarithmic derivative (RLD) formalisms. Our results demonstrate that the RLD based QCRB is systematically lower than the SLD based bound, indicating superior estimation precision in the considered noncommutative estimation scenario. We further analyze the performance of heterodyne detection and show that, in suitable parameter regimes, the corresponding classical estimation precision closely approaches the ultimate quantum limit predicted by our scheme. Finally, we discuss the experimental feasibility of the proposed setup within currently available cavity magnon mechanical platforms. Owing to its general character, the framework developed here can be readily extended to the high precision estimation of other physical parameters in hybrid quantum systems."}
{"id": "2602.14694", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14694", "abs": "https://arxiv.org/abs/2602.14694", "authors": ["Rune Thinggaard Birke", "Johann Bock Severin", "Malthe A. Marciniak", "Emil Hogedal", "Andreas Nylander", "Irshad Ahmad", "Amr Osman", "Janka Biznárová", "Marcus Rommel", "Anita Fadavi Roudsari", "Jonas Bylander", "Giovanna Tancredi", "Daniel Stilck França", "Albert Werner", "Christopher W. Warren", "Jacob Hastrup", "Svend Krøjer", "Morten Kjaergaard"], "title": "Demonstrating and Benchmarking Classical Shadows for Lindblad Tomography", "comment": "16 pages, 5 figures", "summary": "Spurious couplings and decoherence degrade the performance of solid-state quantum processors, demanding careful design, calibration, and mitigation protocols. These strategies often rely on characterization of the idling processor, but tomographic recovery of (time-independent) Lindblad dynamics scales exponentially with qubit count. Here, we experimentally benchmark and demonstrate that randomized (\"shadow\") measurements accelerate Lindblad tomography on a superconducting transmon processor. We first implement extensible Lindblad tomography, which estimates Lindblad parameters using a complete tomographic dataset, and use it as a baseline to benchmark a shadow tomography approach, shadow Lindblad tomography. The shadow approach recycles randomized configurations to estimate the same Lindblad parameters using far fewer resources under physically motivated locality assumptions. We experimentally verify these assumptions in our processor by implementing the protocols on one- and three-qubit subsystems; here, shadow Lindblad tomography reproduces extensible Lindblad tomography within uncertainties while using exponentially fewer configurations. Leveraging this efficiency, we apply shadow Lindblad tomography to the full five-qubit processor and recover all single qubit dissipation and two-qubit coupling parameters in 9 hours of acquisition time compared to an estimated 58 hours for extensible Lindblad tomography. Additionally, our shadow implementation is compatible with conventional Gaussian error propagation, avoiding the use of median-of-means estimators. Together, these results demonstrate how randomized shadow tomography protocols can be practically implemented to learn quantum processor dynamics at an increasing qubit count."}
{"id": "2602.14698", "categories": ["quant-ph", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.14698", "abs": "https://arxiv.org/abs/2602.14698", "authors": ["Stefano Longhi"], "title": "Erratic Liouvillian Skin Localization and Subdiffusive Transport", "comment": "16 pages, 9 figures, submitted to Quantum Science and Technology for the Focus Issue on \"Non-Hermitian Quantum Many-Body Physics\"", "summary": "Non-Hermitian systems with globally reciprocal couplings -- such as the Hatano-Nelson model with stochastic imaginary gauge fields -- avoid the conventional non-Hermitian skin effect, displaying erratic bulk localization while retaining ballistic transport. An open question is whether similar behavior arises when non-reciprocity originates at the Liouvillian level rather than from an effective non-Hermitian Hamiltonian obtained via post-selection. Here we investigate this scenario in a lattice model with globally reciprocal Liouvillian dynamics and locally asymmetric incoherent hopping, a disordered setting in which Liouvillian-specific effects have remained largely unexplored. While the steady state again shows disorder-dependent, erratic localization without boundary accumulation, we find that global reciprocity in the Liouvillian does not protect transport. Instead, in the regime dominated by incoherent hopping, excitations spread via Sinai-type subdiffusion, dramatically slower than the ordinary diffusion found in symmetric stochastic lattices. Our results reveal a fundamental distinction between globally reciprocal Hamiltonian and Liouvillian dynamics: global reciprocity suppresses the skin effect in both cases, but only in Liouvillian dynamics can it coexist with ultra-slow, disorder-induced subdiffusive transport."}
{"id": "2602.14730", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14730", "abs": "https://arxiv.org/abs/2602.14730", "authors": ["Nirupam Basak", "Goutam Paul"], "title": "Faster Optimal Decoder for Graph Codes with a Single Logical Qubit", "comment": null, "summary": "In this work, we develop an efficient decoding method for graph codes, a class of stabilizer quantum error-correcting codes constructed from graph states. While optimal decoding is generally NP-hard, we propose a faster decoder exploiting the structural properties of the underlying graph states. Although distinct error patterns may yield the same syndrome, we demonstrate that the post-measurement state follows a well-defined structure determined by the projective syndrome measurement. Building on this idea, we introduce a hierarchical decoder in which each level can be solved in polynomial time. Additionally, this decoder achieves optimal decoding performance at the lower levels of the hierarchy. This strategy avoids the need for full maximum-likelihood decoding of graph codes. Numerical results illustrate the efficiency and effectiveness of the proposed approach."}
{"id": "2602.14732", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14732", "abs": "https://arxiv.org/abs/2602.14732", "authors": ["A. Afham", "Marco Tomamichel"], "title": "Projections with Respect to Bures Distance and Fidelity: Closed-Forms and Applications", "comment": "40 pages. Comments welcome!", "summary": "We derive simple and unified closed-form expressions for projections with respect to fidelity (equivalently, the Bures and purified distances) onto several sets of interest. These include projections of bipartite positive semidefinite (PSD) matrices onto the set of PSD matrices with a given marginal, and projections of ensembles of PSD matrices onto the set of PSD decompositions of a given matrix, with important special cases corresponding to projections onto the set of quantum channels (via the Choi isomorphism) and onto the set of measurements. We introduce prior-channel decompositions of completely positive (CP) maps, which uniquely decompose any CP map into a prior PSD matrix and a quantum channel. This decomposition generalizes the Choi-Jamiolkowski isomorphism by establishing a bijective correspondence between arbitrary bipartite PSD matrices and channel-state pairs, and we show that it arises naturally from the fidelity projections developed here. As applications, we show that the pretty good measurement - associated with a weighted ensemble - is the fidelity projection of the ensemble onto the set of measurements, and that the Petz recovery map - associated with a reference state and forward channel - is the projection of a CP map (constructed from the channel-state pair) onto the set of reverse quantum channels, thereby recasting the well-known identification of the Petz map with quantum Bayes' rule in information-geometric terms. Our results also provide an information-geometric underpinning of the Leifer-Spekkens quantum state over time formalism [Leifer and Spekkens, Phys. Rev. A 88, 052130 (2013)]."}
{"id": "2602.14735", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14735", "abs": "https://arxiv.org/abs/2602.14735", "authors": ["Ait Haddou Marwan"], "title": "The Signal Horizon: Local Blindness and the Contraction of Pauli-Weight Spectra in Noisy Quantum Encodings", "comment": null, "summary": "The performance of quantum classifiers is typically analyzed through global state distinguishability or the trainability of variational models. This study investigates how much class information remains accessible under locality-constrained measurements in the presence of noise. The authors formulate binary quantum classification as constrained quantum state discrimination and introduce a locality-restricted distinguishability measure quantifying the maximum bias achievable by observables acting on at most $k$ subsystems. For $n$-qubit systems subject to independent depolarizing noise, the locally accessible signal is governed by a Pauli-weight-dependent contraction mechanism. This motivates a computable predictor, the $k$-local Pauli-accessible amplitude $A_{k}(p)$, which lower bounds the optimal $k$-local classification advantage. Numerical experiments on four-qubit encodings demonstrate quantitative agreement between empirical accuracy and the prediction across noise levels. The research identifies an operational breakdown threshold where $k$-local classifiers become indistinguishable from random guessing despite persistent global distinguishability."}
{"id": "2602.14736", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14736", "abs": "https://arxiv.org/abs/2602.14736", "authors": ["Alessio Baldazzi", "Roy Philip George Konnoth Ancel", "Sebastiano Guaraldo", "Xuan Chen", "Ziad Abi Akar", "Regis Deturche", "Stefano Azzini", "Christophe Couteau", "Lorenzo Pavesi"], "title": "Coupled integrated photonic quantum memristors using a single photon source made of a colour center", "comment": "24 pages, 9 figures, 3 tables", "summary": "Photonic quantum memristors provide a measurement-induced route to nonlinear and history-dependent quantum dynamics. Experimental demonstrations have so far focused on isolated devices or simple cascaded devices configurations. Here, we experimentally realize and characterize a network of two coupled photonic quantum memristors with crossed feedback, implemented on a silicon nitride photonic integrated circuit and fed by a room-temperature single-photon source based on a silicon-vacancy color center SiV$^-$ in a nanodiamond. Each memristor consists of an integrated Mach-Zehnder interferometer whose transfer function is adaptively updated by photon detection events on another memristor, thus generating novel non-Markovian input-output dynamics with an enhanced memristive behaviour compared to single devices. In particular, we report inter-memristor input-output hysteresis curves exhibiting larger form factors and displaying self-intersecting loops, respectively revealing marked bistability and topologically non-trivial memory dynamics. Furthermore, numerical simulations show how these features emerge from the interplay between memory depth and relative input phase, for both intra- and inter-memristor input-output relations. Our results establish coupled integrated photonic quantum memristors as scalable nonlinear building blocks and highlight their potential for implementing compact quantum neuromorphic and reservoir computing architectures."}
{"id": "2602.14738", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14738", "abs": "https://arxiv.org/abs/2602.14738", "authors": ["Jeroen Grimbergen", "Stav Haldar", "Alvaro Gomez Inesta", "Stephanie Wehner"], "title": "Probabilistic Cutoffs in Homogeneous Quantum Repeater Chains", "comment": null, "summary": "We study quantum repeater chains in which entangled links between neighbouring nodes are created through heralded entanglement generation and adjacent links are swapped as soon as possible. Since heralded entanglement generation attempts succeed only probabilistically, some links will have to be stored in quantum memories at the nodes of the chain while waiting for adjacent links to be generated. The fidelity of these stored links decreases with time due to decoherence, and if they are stored for too long then this can lead to low end-to-end fidelity. Previous work has shown that the end-to-end fidelity can be improved by deterministically discarding links when their ages exceed some cutoff value. Such deterministic cutoff policies provide strict control of the fidelity of all links, but they come at the expense of having to track link ages. In this work, we introduce a probabilistic cutoff policy that does not require tracking link ages, at the cost of abandoning strict control of the fidelity. We benchmark this new probabilistic cutoff policy against a deterministic cutoff policy. We compare the policies in terms of the end-to-end rate and fidelity, and the secret-key rate. We find that even though the probabilistic cutoff policy keeps track of less state, it can provide secret-key rates of the same order of magnitude as the deterministic cutoff policy in chains with few nodes or high elementary link generation probabilities. Moreover, we identify a scenario in which the probabilistic cutoff policy can deliver end-to-end links that are required to have some minimum threshold fidelity at a higher rate than the deterministic cutoff policy."}
{"id": "2602.14752", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14752", "abs": "https://arxiv.org/abs/2602.14752", "authors": ["Naeem Akhtar", "Jia-Xin Peng", "Tariq Aziz", "Xiaosen Yang", "Dong Wang"], "title": "Finer sub-Planck structures and displacement sensitivity of SU(1,1) circular states", "comment": "10 pages, 4 figures", "summary": "Quantum states with sub-Planck features exhibit sensitivity to phase-space displacements beyond the standard quantum limit, making them useful for quantum metrology. In the context of the SU(1,1) group, sub-Planck features have been constructed through the superposition of four Perelomov coherent states on the hyperbolic plane (the SU(1,1) compass state). However, these structures differ in scale along different phase-space directions, resulting in nonuniform sensitivity enhancement. We overcome this limitation by constructing $\\overline{n}$-component compass states, which are obtained by superposing $\\overline{n} \\geq 6$ SU(1,1) coherent states, with an even total number, evenly arranged along a circular path on the hyperbolic plane; that is, all components lie at the same distance from the origin and have equal angular spacing of $\\frac{2π}{\\overline{n}}$. These generalized SU(1,1) compass states generate circularly shaped sub-Planck features (isotropic sub-Planckness) and provide uniform enhancement in sensitivity to phase-space displacements. As the number of coherent states $\\overline{n}$ increases, these refinements progressively improve. While verified for $\\overline{n} = 16$ SU(1,1) coherent states, the results remain valid for superpositions with arbitrarily large $\\overline{n}$ components."}
{"id": "2602.14756", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14756", "abs": "https://arxiv.org/abs/2602.14756", "authors": ["Christian Ventura-Meinersen", "Edmondo Valvo", "Stefano Bosco", "Maximilian Rimbach-Russ"], "title": "Multi-level spectral navigation with geometric diabatic-adiabatic control", "comment": null, "summary": "We introduce a geometric framework for efficient few-parameter pulse optimization in multi-level quantum systems, enabling high-fidelity state transfer beyond the adiabatic limit. Our method interpolates smoothly between adiabatic and diabatic dynamics to minimize unwanted excitations and maximize desired transitions even within a multi-level structure. Crucially, for single-parameter pulse control, the optimization reduces to solving a first-order ordinary differential equation. We showcase the flexibility of our diabatic-adiabatic protocols through two examples in spin-based quantum information processing: state initialization and qubit state transfer."}
{"id": "2602.14779", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14779", "abs": "https://arxiv.org/abs/2602.14779", "authors": ["Zhe-Hao Zhang", "Xiaoming Cai", "Yi-Cong Yu"], "title": "Localization Tensor Revisited: Geometric-Probabilistic Foundations and a Structure-Factor Criterion under Periodic Boundaries", "comment": null, "summary": "We revisit the localization tensor (LT) from geometric and probabilistic perspectives and construct extensions that are naturally compatible with periodic boundary conditions (PBC), without redefining the position operator. In open boundary conditions, we show that the LT can be written exactly as the covariance of a bivariate probability distribution built from density-density correlations. This leads to two conceptually distinct extensions to PBC: (i) a geometric one based on the Riemannian center (Frechet mean) on the circle, and (ii) a metric-free one based on the mutual information I, which treats the configuration space purely as a probability space. We then relate the LT to the static structure factor by identifying the diagonal part, Cpp, as a \"localization function\" C(p), whose small-momentum behavior determines the LT in the thermodynamic limit. This clarifies why the LT is sensitive to transitions out of the extended phase but by itself cannot distinguish Anderson-type localization from dimerization: both share the same low-momentum asymptotics. We show that the finite-momentum behavior of C(p), together with an inverse participation ratio (IPR)-based upper bound valid in localized phases, provides a sharp criterion that discriminates localization from dimerization. These results are illustrated on the Su-Schrieffer-Heeger and Aubry-Andre models, with and without interactions, and suggest that structure factor-based probes offer robust and experimentally accessible diagnostics of localized and dimerized phases under PBC."}
{"id": "2602.14827", "categories": ["quant-ph", "q-fin.CP", "q-fin.PM"], "pdf": "https://arxiv.org/pdf/2602.14827", "abs": "https://arxiv.org/abs/2602.14827", "authors": ["Javier Mancilla", "Theodoros D. Bouloumis", "Frederic Goguikian"], "title": "Constrained Portfolio Optimization via Quantum Approximate Optimization Algorithm (QAOA) with XY-Mixers and Trotterized Initialization: A Hybrid Approach for Direct Indexing", "comment": "11 pages, 6 figures", "summary": "Portfolio optimization under strict cardinality constraints is a combinatorial challenge that defies classical convex optimization techniques, particularly in the context of \"Direct Indexing\" and ESG-constrained mandates. In the Noisy Intermediate-Scale Quantum (NISQ) era, the Quantum Approximate Optimization Algorithm (QAOA) offers a promising hybrid approach. However, standard QAOA implementations utilizing transverse field mixers often fail to strictly enforce hard constraints, necessitating soft penalties that distort the energy landscape. This paper presents a comprehensive analysis of a constraint-preserving QAOA formulation against Simulated Annealing (SA) and Hierarchical Risk Parity (HRP). We implement a specific QAOA ansatz utilizing a Dicke state initialization and an XY-mixer Hamiltonian that strictly preserves the Hamming weight of the solution, ensuring only valid portfolios of size K are explored. Furthermore, we introduce a Trotterized parameter initialization schedule inspired by adiabatic quantum computing to mitigate the \"Barren Plateau\" problem. Backtesting on a basket of 10 US equities over 2025 reveals that our QAOA approach achieves a Sharpe Ratio of 1.81, significantly outperforming Simulated Annealing (1.31) and HRP (0.98). We further analyze the operational implications of the algorithm's high turnover (76.8%), discussing the trade-offs between theoretical optimality and implementation costs in institutional settings."}
{"id": "2602.14841", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14841", "abs": "https://arxiv.org/abs/2602.14841", "authors": ["Leonardo A. M. Souza", "Olimpio P. de Sá Neto", "Enrico Russo", "Rosario Lo Franco", "Gerardo Adesso"], "title": "Gravitational Decoherence Estimation in Optomechanical Systems", "comment": null, "summary": "We develop a comprehensive quantum estimation framework to quantify how precisely gravitationally induced decoherence can be inferred in optomechanical systems, using single-mode Gaussian probe states. Our approach combines a microscopic description of the gravitational diffusion mechanism with quantum Fisher information to determine the ultimate sensitivity achievable in principle. We show that gravitational diffusion leaves distinct, measurable signatures in the mechanical state, both during transient evolution and in the stationary regime. Finally, we identify how probe state preparation shapes the attainable precision, thereby establishing fundamental limits for detecting and estimating gravity-driven decoherence."}
{"id": "2602.14880", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14880", "abs": "https://arxiv.org/abs/2602.14880", "authors": ["Shuva Mondal", "Amrita Mandal", "Ujjwal Sen"], "title": "Infinite reduction in absorbing time in quantum walks over classical ones", "comment": "12 pages, 6 figures", "summary": "We study the absorption time and spreading rate of the discrete-time quantum walk propagating on a line in the presence or absence of an absorber. We analytically establish that in the presence of an absorber, the average absorption time of the quantum walker is finite, contrary to the behavior of a classical random walker, indicating an infinite resource reduction on moving over to a quantum version of a walker. Furthermore, numerical simulations indicate a reversal of this behavior due to the insertion of disorder in the walker's step lengths. Additionally, we demonstrate that in the presence of an absorber, there is a speed-up in the spreading rate, and that a disordered quantum walk that is sub-ballistic regains the ballistic spreading of a clean quantum walk."}
{"id": "2602.14986", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14986", "abs": "https://arxiv.org/abs/2602.14986", "authors": ["Ugo Nzongani", "Dylan Laplace Mermoud", "Arthur Braida"], "title": "Scaling QAOA: transferring optimal adiabatic schedules from small-scale to large-scale variational circuits", "comment": null, "summary": "The Quantum Approximate Optimization Algorithm (QAOA) is a leading approach for combinatorial optimization on near-term quantum devices, yet its scalability is limited by the difficulty of optimizing \\(2p\\) variational parameters for a large number \\(p\\) of layers. Recent empirical studies indicate that optimal QAOA angles exhibit concentration and transferability across problem sizes. Leveraging this observation, we propose a schedule-learning framework that transfers spectral-gap-informed adiabatic control strategies from small-scale instances to larger systems.\n  Our method extracts the spectral gap profile of small problems and constructs a continuous schedule governed by \\(\\partial_t s = κg^q(s)\\), where \\(g(s)\\) is the instantaneous gap and \\((κ, q)\\) are global hyperparameters. Discretizing this schedule yields closed-form expressions for all QAOA angles, reducing the classical optimization task from \\(2p\\) parameters to only \\(2\\), independent of circuit depth. This drastic parameter compression mitigates classical optimization overhead and reduces sensitivity to barren plateau phenomena.\n  Numerical simulations on random QUBO and 3-regular MaxCut instances demonstrate that the learnt schedules transfer effectively to larger systems while achieving competitive approximation ratios. Our results suggest that gap-informed schedule transfers provide a scalable and parameter-efficient strategy for QAOA."}
{"id": "2602.14992", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.14992", "abs": "https://arxiv.org/abs/2602.14992", "authors": ["Nicolas Schüler", "O. J. Franca", "Michael Vaz", "Hervé Bercegol", "Stefan Yoshi Buhmann"], "title": "Rotational Quantum Friction via Spontaneous Decay", "comment": "7 pages, 2 figures, Submitted", "summary": "A fascinating effect belonging to the field of vacuum forces and fluctuations is that of quantum friction. It refers to the prediction of a dissipative force acting on a moving object due to the quantum vacuum field. In this work, we investigate rotational quantum friction where a diatomic polar molecule rotates around its own center of mass in free space. We quantize the rotational motion and investigate the resulting dissipation due to spontaneous decay. We find in the Markovian regime that a friction torque $\\propto Ω^3$ persists even for zero temperature, and in agreement with the classical result in the limit of large rotational quantum number $l$. Within the non-Markovian short-time regime we find a friction $\\proptoΩ$."}
{"id": "2602.14995", "categories": ["quant-ph", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.14995", "abs": "https://arxiv.org/abs/2602.14995", "authors": ["Vinay Kumar", "Claudio Cicconetti", "Riccardo Bassoli", "Marco Conti", "Andrea Passarella"], "title": "Instruction-Set Architecture for Programmable NV-Center Quantum Repeater Nodes", "comment": "7 pages, 4 figures", "summary": "Programmability is increasingly central in emerging quantum network software stacks, yet the node-internal controller-to-hardware interface for quantum repeater devices remains under-specified. We introduce the idea of an instruction-set architecture (ISA) for controller-driven programmability of nitrogen-vacancy (NV) center quantum repeater nodes. Each node consists of an optically interfaced electron spin acting as a data qubit and a long-lived nuclear-spin register acting as a control program. We formalize two modes of programmability: (i) deterministic register control, where the nuclear register is initialized in a basis state to select a specific operation on the data qubit; and (ii) coherent register control, where the register is prepared in superposition, enabling coherent combinations of operations beyond classical programmability. Network protocols are expressed as controller-issued instruction vectors, which we illustrate through a compact realization of the BBPSSW purification protocol. We further show that coherent register control enables interferometric diagnostics such as fidelity witnessing and calibration, providing tools unavailable in classical programmability. Finally, we discuss scalability to multi-electron and multi-nuclear spin architectures and connection to Linear combination of unitaries (LCU) and Kraus formulation."}
{"id": "2602.14999", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14999", "abs": "https://arxiv.org/abs/2602.14999", "authors": ["Jeremy Canfield", "Dominika Zgid", "J K Freericks"], "title": "Low Depth Unitary Coupled Cluster Algorithm for Large Chemical Systems", "comment": null, "summary": "The unitary coupled cluster (UCC) algorithm is one of the most promising implementations of the variational quantum eigensolver for quantum computers. However, for large systems, the number of UCC factors leads to deep quantum circuits, which are prohibitive for execution on quantum hardware. To address this, circuit depth can be reduced at the cost of more measurements with a Taylor series expansion of UCC factors with small angles, while treating the large-angle factors exactly. We implement this approach to quadratic order (qUCC) for systems with strong correlations and systems where conventional methods like coupled cluster (CC) with low excitation levels fail, but UCC and qUCC perform well. We study hydrogen chains and the BeH2 molecule that allow us to change the degree of strong correlation due to geometrical distortions. We show, via a dramatic increase in number of factors able to handle exactly, a systematic convergence of these results as more exact UCC factors are included in the calculations -- the hardest to converge regime is in the crossover from weak to strong coupling. In all cases the total number of UCC factors needed to be treated exactly is much less than the total number of UCC factors available (typically about one-third to one-half of the total number of factors)."}
{"id": "2602.13374", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13374", "abs": "https://arxiv.org/abs/2602.13374", "authors": ["Fabian J. Pauw", "Thomas Köhler", "Ulrich Schollwöck", "Sebastian Paeckel"], "title": "Adaptive Pseudoboson Density-Matrix Renormalization Group for Dilute 2D Systems", "comment": "14 pages, 6 figures", "summary": "Simulating strongly correlated systems in two dimensions is notoriously challenging due to rapid entanglement growth and frustration. Here, we introduce the adaptive projected-purified pseudoboson density-matrix renormalization group (A3P-DMRG) tailored to explore the ground states of dilute lattice models. The method compresses cluster Hilbert spaces by retaining only the most probable low-occupation Fock states, identified via probabilistic bounds and refined through a self-consistent mean-field basis optimization. We demonstrate that A3P-DMRG is advantageous in low-filling and weak-coupling regimes for large system sizes where conventional DMRG struggles. This establishes the method as a versatile tool for studying dilute quantum many-body systems relevant to ultra-cold atom quantum simulators, photonic lattices, Moiré materials and quantum chemistry."}
{"id": "2602.13443", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13443", "abs": "https://arxiv.org/abs/2602.13443", "authors": ["Gang Cao", "Hengdi Zhao", "Adrienne Bond", "Tristan R. Cao", "Gabriel Schebel", "Arabella Quane", "Yifei Ni", "Yu Zhang", "Logan Wall", "Rahul Nandkishore", "Pedro Schlottmann", "Feng Ye"], "title": "Hidden Density-Wave Instability in the Trimer Ruthenate Ba4Ru3O10", "comment": "5 figures", "summary": "We report a hidden density-wave instability in the trimer-based ruthenate Ba4Ru3O10, previously regarded as a pure antiferromagnet with a phase transition at TA=100 K. This transition is manifested in lattice parameters, transport, thermodynamics, and magnetic susceptibility, yet remains remarkably insensitive to magnetic fields up to at least 14 T, indicating an electronically driven reconstruction. At much lower temperatures T*= 20 K, charge transport becomes strongly nonlinear, exhibiting distinct depinning thresholds, negative differential resistance, pronounced current- and frequency-dependence, and slow collective dynamics in the Hertz range. While each feature is characteristic of density-wave transport, their simultaneous occurrence in an antiferromagnetic oxide is unprecedented. All nonlinear signatures vanish upon only 3% Ir substitution, which preserves the crystal structure and insulating state, ruling out Joule heating or extrinsic artifacts. The wide separation between the electronic reconstruction at TA and the emergence of nonlinear dynamics at T* identifies Ba4Ru3O10 as a rare correlated system hosting a strongly pinned collective electronic state intertwined with antiferromagnetism."}
{"id": "2602.13916", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.13916", "abs": "https://arxiv.org/abs/2602.13916", "authors": ["J. Sirker"], "title": "Bulk-boundary correspondence in topological two-dimensional non-Hermitian systems: Toeplitz operators and singular values", "comment": "29 pages", "summary": "In contrast to eigenvalue-based approaches, we formulate the bulk-boundary correspondence for two-dimensional non-Hermitian quadratic lattice Hamiltonians in terms of Toeplitz operators and singular values, which correctly capture the stability, localization, and scaling of edge and corner modes. We show that singular values, rather than eigenvalues, provide the only stable foundation for topological protection in non-Hermitian systems because they remain robust under translational-symmetry-breaking perturbations that destabilize the eigenvalue spectrum, rendering it unsuitable for topological classification. Building on Toeplitz operator theory, we establish general results for non-Hermitian Hamiltonians defined on half and quarter planes, relating the topological indices of the associated Toeplitz operators to the number of finite-size singular values that are separated from the bulk singular-value spectrum and vanish in the thermodynamic limit. This yields a precise bulk-boundary correspondence for edge and corner modes, including higher-order topological phases, without requiring crystalline symmetries. We illustrate our general results with detailed examples exhibiting topologically protected families of edge states, coexisting edge and corner modes, and phases with both gapped bulk and edges supporting only stable corner modes. The latter is exemplified by a non-Hermitian generalization of the Benalcazar-Bernevig-Hughes model."}
{"id": "2602.14601", "categories": ["physics.hist-ph", "hep-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14601", "abs": "https://arxiv.org/abs/2602.14601", "authors": ["Yu Shi"], "title": "The road of quantum entanglement: from Einstein to 2022 Nobel Prize in Physics", "comment": "22 pages. This review article is the English version of a Chinese article published in Chinese Journal of Nature 44(6), 455-466 (2022) [ DOI: 10.3969/j.issn.0253-9608.2022.06.005], which was based on a talk the author gave at 2022 Fall Meeting of Chinese Physical Society (the video is available at https://www.koushare.com/video/details/173010)", "summary": "We explain the achievements that were awarded 2022 Nobel Prize in Physics, as well as the preceding and the later developments. The main notions and historic cornerstones of Bell inequalities, the related researches on quantum entanglement are reviewed, and the key physical ideas are emphasized. Among the early work, C. S. Wu's contributions using polarization-entangled photons from electron-positron annihilation are introduced."}
{"id": "2602.14769", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.14769", "abs": "https://arxiv.org/abs/2602.14769", "authors": ["Zi-Yang Zhang", "Donghoon Kim", "Ji-Yao Chen"], "title": "Variational preparation and characterization of chiral spin liquids in quantum circuits", "comment": "19 pages, 15 figures", "summary": "Quantum circuits have been shown to be a fertile ground for realizing long-range entangled phases of matter. While various quantum double models with non-chiral topological order have been theoretically investigated and experimentally implemented, the realization and characterization of chiral topological phases have remained less explored. Here we show that chiral topological phases in spin systems, i.e., chiral spin liquids, can be prepared in quantum circuits using the variational quantum eigensolver (VQE) framework. On top of the VQE ground state, signatures of the chiral topological order are revealed using the recently proposed tangent space excitation ansatz for quantum circuits. We show that, both topological ground state degeneracy and the chiral edge mode can be faithfully captured by this approach. We demonstrate our approach using the Kitaev honeycomb model, finding excellent agreement of low-energy excitation spectrum on quantum circuits with exact solution in all topological sectors. Further applying this approach to a non-exactly solvable chiral spin liquid model on square lattice, the results suggest this approach works well even when the topological sectors are not exactly known."}
{"id": "2602.15016", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15016", "abs": "https://arxiv.org/abs/2602.15016", "authors": ["Yi-Hsien Du"], "title": "Controlled Theory of Skyrmion Chern Bands in Moiré Quantum Materials: Quantum Geometry and Collective Dynamics", "comment": "63 pages", "summary": "Recent experiments in moiré quantum materials exhibit quantized Hall states without an external magnetic field, motivating continuum mechanisms based on smooth moiré-periodic pseudospin textures. We present a controlled theory of skyrmion Chern bands generated by such textures. An exact local $SU(2)$ transformation reveals an emergent non-Abelian gauge field; for large branch splitting we perform an operator-level Schrieffer-Wolff expansion, yielding a single-branch Hamiltonian together with systematically dressed physical operators that define the projected interacting theory beyond strict adiabaticity. The leading dynamics is governed by a $U(1)$ Berry connection whose flux is set by the skyrmion density, while controlled non-adiabatic corrections are fixed by the texture's real-space quantum geometric tensor. In a Landau-level representation built from the averaged emergent field, moiré-periodic modulations induce Umklapp-resolved deformations of Girvin-MacDonald-Platzman kinematics and microscopic sources of excess optical quantum weight above the topological lower bound. Assuming a gapped Hall phase, we further derive a skyrmion-crystal effective field theory with a universal Berry-phase term and a noncommutative magnetophonon. Our results provide experimentally accessible signatures for twisted transition-metal dichalcogenide homobilayers and rhombohedral graphene aligned with hexagonal boron nitride."}
