<div id=toc></div>

# Table of Contents

- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 4]
- [stat.ME](#stat.ME) [Total: 30]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [cs.SI](#cs.SI) [Total: 2]
- [hep-lat](#hep-lat) [Total: 2]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [math.NA](#math.NA) [Total: 15]
- [cs.ET](#cs.ET) [Total: 3]
- [math.ST](#math.ST) [Total: 7]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 11]
- [physics.hist-ph](#physics.hist-ph) [Total: 3]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [nlin.CD](#nlin.CD) [Total: 1]
- [math.OC](#math.OC) [Total: 14]
- [nlin.AO](#nlin.AO) [Total: 1]
- [quant-ph](#quant-ph) [Total: 60]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 6]
- [eess.SY](#eess.SY) [Total: 20]
- [cs.CE](#cs.CE) [Total: 7]
- [q-fin.ST](#q-fin.ST) [Total: 2]


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [1] [Energy gap of quantum spin glasses: a projection quantum Monte Carlo study](https://arxiv.org/abs/2602.20108)
*L. Brodoloni,G. E. Astrakharchik,S. Giorgini,S. Pilati*

Main category: cond-mat.dis-nn

TL;DR: 研究了量子退火在两种典型量子自旋玻璃模型中的性能，发现二维Edwards-Anderson模型的能量隙分布具有重尾特性，导致退火效率受限，而Sherrington-Kirkpatrick模型的能量隙随系统尺寸呈较慢的幂律衰减，预示其在全连接优化问题中更具潜力。


<details>
  <summary>Details</summary>
Motivation: 理解量子退火在组合优化中性能受限的根本原因，特别是能量隙Δ在量子相变处随系统规模N的变化规律。

Method: 使用新提出的无偏能量隙估计器结合连续时间投影量子蒙特卡洛模拟，并辅以高性能稀疏特征值求解器，分析无序实现下的能隙分布。

Result: 二维Edwards-Anderson模型的逆能隙分布随N增大出现方差无限的重尾，表明超代数标度行为在高斯无序下依然存在；而Sherrington-Kirkpatrick模型的平均能隙遵循接近Δ∝N^(-1/3)的幂律，且方差有限。

Conclusion: 二维自旋玻璃的能隙重尾是普遍特征，限制量子退火效率；而全连接的SK模型虽有缓慢能隙衰减，但仍为量子退火应用于密集优化问题提供了积极前景。

Abstract: The performance of quantum annealing for combinatorial optimization is fundamentally limited by the minimum energy gap $Δ$ encountered at quantum phase transitions. We investigate the scaling of $Δ$ with system size $N$ for two paradigmatic quantum spin-glass models: the two-dimensional Edwards-Anderson (2D-EA) and the all-to-all Sherrington-Kirkpatrick (SK) models. Utilizing a newly proposed unbiased energy-gap estimator for continuous-time projection quantum Monte Carlo simulations, complemented by high-performance sparse eigenvalue solvers, we characterize the gap distributions across disorder realizations. It is found that, in the 2D-EA case, the inverse-gap distribution develops a fat tail with infinite variance as $N$ increases. This indicates that the unfavorable super-algebraic scaling of $Δ$, recently reported for binary couplings [Nature 631, 749 (2024)], persists for the Gaussian disorder considered here, pointing to a universal feature of 2D spin glasses. Conversely, the SK model retains a finite-variance distribution, with the disorder-averaged gap following a rather slow power law, close to $Δ\propto N^{-1/3}$. This finding provides a promising outlook for the potential efficiency of quantum annealers for optimization problems with dense connectivity.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [2] [AI-based Regional Emulation for Kilometer-Scale Dynamical Downscaling](https://arxiv.org/abs/2602.18646)
*Yingkai Sha,Tracy Hertneky,Ethan Gutmann,Seth McGinnis,Lulin Xue,David John Gagne,Kathryn Newman,Andrew Newman*

Main category: physics.ao-ph

TL;DR: 本文提出了一种基于人工智能的有限区域模型（AI-based LAM），用于美国南部大平原和东南部地区的动力降尺度，具备在不同边界条件下良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 旨在将AI天气预报模型扩展应用于区域气候模拟，提升传统降尺度方法的效率与稳定性。

Method: 使用ERA5数据作为强迫输入、CONUS404作为训练目标，在1980–2019年期间训练生成4公里每小时分辨率的降尺度输出，并结合后处理模型推导诊断变量；模型在多种强迫数据、时间段和气候状态下进行评估。

Result: 模型在当前气候模拟中表现稳定，无明显漂移，确定性评分与其他AI天气模型相当；能稳健泛化至非ERA5粗分辨率强迫数据；成功重建锋面气旋和飓风结构；在30年气候模拟和集合模拟中保持稳定，有效捕捉气候变化信号且不破坏集合离散度。

Conclusion: 该AI-LAM模型表现出优异的降尺度性能和跨气候条件的泛化能力，为将AI天气模型迁移至区域气候应用提供了实用且可推广的范例。

Abstract: An AI-based Limited-Area Model (LAM) is developed for dynamical downscaling over the Southern Great Plains and the southeastern United States, with strong generalization abilities under diverse boundary conditions. The model is trained using 0.25-degree, 3-hourly ERA5 as forcings and CONUS404 as targets in 1980--2019, producing 4-km, hourly dynamical downscaling outputs; it is also connected to a post-processing model to derive additional diagnostic variables. The model is evaluated across multiple forcing datasets, time periods, and climate regimes. For present-day downscaling in the 2021--2024 water years, the model produces stable multi-year simulations with no unrealistic drift; its deterministic verification scores are comparable to other weather-forecasting-oriented AI models. The model also generalizes robustly to a 1.0-degree, 6-hourly non-ERA5 forcing dataset, yielding only minor performance changes. Frontal cyclone and hurricane case studies further demonstrate that the model reconstructs realistic, interpretable weather-scale dynamical and thermodynamic structure from coarse boundary information. The AI-based LAM is further tested by downscaling 30-year global climate model runs in 1980--2010 and 2070--2100, and climate model ensembles in 2025-2027. In this application, the model remains stable at hourly downscaling frequencies for all 30 years and effectively captures future climate-change signals, indicating meaningful generalization across different climate regimes. When downscaling ensembles, the model produces well-posed ensemble distributions without collapsing the ensemble spread. Overall, the AI-based LAM of this study offers good downscaling performance and generalization abilities. It provides a practical and transferable example of adapting AI weather prediction models for regional climate applications.

</details>


### [3] [On Using Medium-Range Ensemble Forecasts for Storm Transposition of Synoptic-Scale Systems in Probable Maximum Precipitation Estimation](https://arxiv.org/abs/2602.19233)
*Mathieu Mure-Ravaud*

Main category: physics.ao-ph

TL;DR: 本研究使用内部变异性利用（IVL）方法对2021年10月影响美国西海岸的大气河事件进行风暴位移，结合ECMWF集合预报生成多种可能路径，评估威拉米特河和纳西河流域的最大可能降水量，得到24小时流域平均降水深度分别为119毫米和98毫米。


<details>
  <summary>Details</summary>
Motivation: 现有风暴位移方法在估计最大可能降水（PMP）时存在物理合理性不足的问题，需发展更可靠的物理一致的位移技术。

Method: 采用内部变异性利用（IVL）方法，结合ECMWF中程集合预报生成多种可能的风暴演变路径，将2021年10月的大气河事件位移到目标流域，并通过初始和边界条件调整进一步增强降水效果。

Result: 在威拉米特河和纳西河流域分别获得了24小时最大流域平均降水深度为119 mm和98 mm的结果。

Conclusion: IVL方法结合集合预报能够生成物理上更合理的风暴位移情景，为估计最大可能降水提供了更具物理一致性的新途径。

Abstract: Most methods for estimating probable maximum precipitation (PMP) -- the greatest depth of precipitation that is physically possible over a given area and duration -- rely on storm transposition (ST), the process of transporting a storm, either historically observed or simulated, from its original location to a target basin. Existing ST approaches, whether classical or physically based, involve assumptions and manipulations that can introduce inconsistencies, leaving the physical validity of the transposed storm uncertain. In this study, the internal variability leveraging (IVL) approach is used to transpose an atmospheric river cluster that affected the U.S. West Coast during 20-29 October 2021. Steering the storm toward the target basin and determining its transposition region are achieved by considering an ensemble of plausible storm evolutions and trajectories obtained from archived ECMWF medium-range forecasts. The Willamette River and Nass River watersheds, located approximately 6 deg N, 2 deg W and 16 deg N, 8 deg W, respectively, from the area most affected by the observed precipitation, were selected as target basins. For each basin, the IVL realization yielding the largest 24-h basin-average precipitation depth was identified, and the initial and boundary condition shifting method was subsequently applied to further enhance its impact, producing 24-h precipitation depths of 119 mm for the Willamette and 98 mm for the Nass.

</details>


### [4] [Koopman Analysis of Sea Surface Temperature with a Signature Kernel](https://arxiv.org/abs/2602.19494)
*Nozomi Sugiura*

Main category: physics.ao-ph

TL;DR: 提出了一种基于轨迹的Koopman方法，利用签名核对年际海表温度（SST）序列进行提升，并学习一年时间偏移算子，有效提升了多步预测性能并揭示了SST动力学中的相干谱模式。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉仅基于SST演化的记忆效应和有限时间历史依赖，需要一种能编码时间序列路径特征的动力学建模方法。

Method: 使用签名核（signature kernel）作为再生核希尔伯特空间（RKHS）中的核函数，对年际SST轨迹段进行编码，并结合核扩展动态模态分解（kernel EDMD）构建Koopman算子，学习SST的一年时间平移操作。

Result: 该方法在样本外多步预测中优于气候学基线，能够揭示具有物理意义的相干谱模式，并通过签名核Gram矩阵实现统一的预测与谱分析流程。

Conclusion: 基于轨迹的Koopman方法结合签名核能有效建模高维SST动力学，兼顾记忆效应与长期预测能力，为复杂气候变量的时间序列分析提供了新工具。

Abstract: We develop a trajectory-based Koopman method for sea surface temperature (SST) that lifts annual SST segments using a signature kernel -- a reproducing kernel Hilbert space (RKHS) kernel that compares paths via iterated-integral features -- and learns the one-year shift operator. By operating on annual trajectory segments rather than instantaneous fields, the method encodes finite-time history, which helps capture memory effects in SST-only evolution. The resulting operator improves out-of-sample multi-year forecast skill relative to a climatology baseline and reveals coherent spectral modes. We implement the approach via kernel extended dynamic mode decomposition (EDMD) on signature-kernel Gram matrices, yielding a single pipeline for forecasting and spectral diagnostics of high-dimensional SST dynamics.

</details>


### [5] [Deep Learning Based Monthly Temperature Prediction for Jilin Province: A Multi Model Comparative Study 2000 2026](https://arxiv.org/abs/2602.19564)
*Xingyue Deng,Xuechen Liang*

Main category: physics.ao-ph

TL;DR: 本研究基于2000–2024年吉林省市1 km × 1 km月均温栅格数据，构建多模型对比系统，评估深度学习与传统机器学习模型在中纬度寒冷地区温度预测中的性能，结果表明LSTM模型最优，并用于2025–2026年温度预测。


<details>
  <summary>Details</summary>
Motivation: 针对现有温度预测研究较少关注具有显著季节性和空间异质性的中纬度大陆性气候区（如吉林），且多数模型未充分融合时空特征与周期性，导致预测精度受限，亟需开展区域适配性建模研究。

Method: 采用高分辨率月均温栅格数据，分析吉林省气温的时空变化特征；构建包括LSTM、GRU、BiLSTM、Transformer四种深度学习模型及岭回归/Lasso、SVR、随机森林、梯度提升等五种传统机器学习模型的预测系统，通过RMSE、MAE和R²指标进行性能比较。

Result: 吉林省气温呈现明显的纬向分布、显著变暖趋势、强季节周期性和高时间自相关性；LSTM模型表现最优（测试集RMSE=2.26°C，MAE=1.83°C，R²=0.9655），优于传统模型和Transformer；预测2025–2026年气温将保持稳定季节波动，年均温约为4.9°C。

Conclusion: LSTM模型能有效捕捉吉林省月均温的长期依赖与周期特征，适用于中纬度寒冷地区的温度预测，研究成果为农业规划、霜冻预警和极端温度风险防控提供了科学依据和技术支持。

Abstract: Jilin Province, a core commercial grain production base in China with a mid-temperate continental monsoon climate and significant temperature fluctuations, relies heavily on temperature for agricultural production and ecological security. Existing temperature prediction studies focus mostly on national/southeastern coastal regions, with few targeting Jilin's specific climatic characteristics, and most models fail to integrate local temperature's spatiotemporal differentiation and seasonal periodicity, limiting prediction accuracy.
  Using 1 km $\times$ 1 km monthly mean temperature raster data (2000--2024) of Jilin Province, we analyzed regional temperature's spatiotemporal variation and constructed a multi-model comparison system including four deep learning models (LSTM, GRU, BiLSTM, Transformer) and five traditional machine learning models (Ridge/Lasso Regression, SVR, Random Forest, Gradient Boosting). Model performance was evaluated via RMSE, MAE, and $R^2$.
  Results show Jilin's temperature has obvious latitudinal zonal distribution, significant warming trend, strong seasonal periodicity, and high temporal autocorrelation. The LSTM model achieved optimal performance (test set RMSE=2.26 $^\circ$C, MAE=1.83 $^\circ$C, $R^2$=0.9655), outperforming traditional models and Transformer. Predictions for 2025--2026 indicate stable seasonal temperature fluctuations with an annual mean of ~4.9 $^\circ$C.
  This study enriches mid-latitude cold region temperature prediction research, verifies LSTM's applicability for Jilin's monthly temperature prediction, and provides scientific support for agricultural planning, frost disaster warning, and extreme temperature risk prevention.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [6] [Ostrom-Weighted Bootstrap: A Theoretically Optimal and Provably Complete Framework for Hierarchical Imputation in Multi-Agent Systems](https://arxiv.org/abs/2602.18442)
*Hirofumi Wakimoto*

Main category: stat.ME

TL;DR: 提出并分析了Ostrom加权自助法（OWB），一种用于多主体投票数据中缺失值填补和原型估计的分层、方差感知重采样方法，兼具最优线性无偏估计、贝叶斯后验均值解释、经验贝叶斯收缩及渐近有效推断等性质，并保证在极小数据假设下实现零NaN填充。


<details>
  <summary>Details</summary>
Motivation: 针对多主体投票数据中缺失值普遍且方差异质的问题，现有方法难以同时兼顾统计最优性、贝叶斯解释性和稳健的重采样推断，因此需要一种统一的、方差感知的分层重采样框架。

Method: 构建两级OWB框架：一级在已知个体方差下证明其为高斯-马尔可夫最佳线性无偏估计（BLUE）；二级在分层正态模型下建立其与条件贝叶斯后验均值的一致性；进而分析使用经验估计方差的可行OWB，将其解释为可行广义最小二乘（FGLS）与经验贝叶斯收缩估计，并建立渐近有效的加权自助置信区间。

Result: 理论证明理想OWB在不同设定下分别具有BLUE性质和贝叶斯后验均值解释；可行OWB具有FGLS和经验贝叶斯双重解释，并支持渐近有效的加权自助推断；提出‘零NaN保证’：只要每个维度至少有一个有限观测，OWB即可生成完全无NaN的填补结果。

Conclusion: OWB是首个同时实现BLUE最优性、贝叶斯解释、经验贝叶斯精度收缩、渐近有效FGLS推断、一致加权自助推断以及零NaN填补保证的重采样方法，在极小数据假设下展现出强理论保证与实用价值。

Abstract: We study the statistical properties of the \emph{Ostrom-Weighted Bootstrap} (OWB), a hierarchical, variance-aware resampling scheme for imputing missing values and estimating archetypes in multi-agent voting data. At Level~1, under mild linear model assumptions, the \emph{ideal} OWB estimator -- with known persona-level (agent-level) variances -- is shown to be the Gauss--Markov best linear unbiased estimator (BLUE) and to strictly dominate uniform weighting whenever persona variances differ. At Level~2, within a canonical hierarchical normal model, the ideal OWB coincides with the conditional Bayesian posterior mean of the archetype. We then analyze the \emph{feasible} OWB, which replaces unknown variances with hierarchically pooled empirical estimates, and show that it can be interpreted as both a feasible generalized least-squares (FGLS) and an empirical-Bayes shrinkage estimator with asymptotically valid weighted bootstrap confidence intervals under mild regularity conditions. Finally, we establish a Zero-NaN Guarantee: as long as each petal has at least one finite observation, the OWB imputation algorithm produces strictly NaN-free completed data using only explicit, non-uniform bootstrap weights and never resorting to uniform sampling or numerical zero-filling.
  To our knowledge, OWB is the first resampling-based method that simultaneously achieves exact BLUE optimality, conditional Bayesian posterior mean interpretation, empirical Bayes shrinkage of precision parameters, asymptotic efficiency via FGLS, consistent weighted bootstrap inference, and provable zero-NaN completion under minimal data assumptions.

</details>


### [7] [Spatiotemporal double machine learning to estimate the impact of Cambodian land concessions on deforestation](https://arxiv.org/abs/2602.18570)
*Anika Arifin,Duncan DeProfio,Layla Lammers,Benjamin Shapiro,Brian J Reich,Henry Uddyback,Joshua M Gray*

Main category: stat.ME

TL;DR: 本文提出了一种改进的双空间回归（DSR）方法，结合双重机器学习和时空分析，用于评估柬埔寨土地特许经营对森林砍伐的因果效应，并通过贝叶斯加性回归树模拟验证其优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 环境政策评估常需考虑时空因素，而传统方法难以处理影响处理与结果的未观测混杂因素，因此需要更有效的因果推断方法。

Method: 采用改进的双空间回归（DSR）方法，结合双重机器学习与时空建模，并使用带空间嵌入的贝叶斯加性回归树（BART）进行大规模模拟研究，以估计政策干预效果。

Result: 在特定条件下，所提出的DSR模型在应对未观测空间混杂方面优于标准方法；应用于柬埔寨案例时，能更准确地评估土地特许经营对森林砍伐的影响。

Conclusion: 引入时间维度的改进型DSR方法能更有效地控制时空混杂偏差，为具有空间效应的环境政策评估提供了更可靠的因果推断工具。

Abstract: Environmental policy evaluation frequently requires thoughtful consideration of space and time in causal inference. We use novel statistical methods to analyze the causal effect of land concessions on deforestation rates in Cambodia. Standard approaches, such as difference-in-differences regression, effectively address spatiotemporally-correlated treatments under some conditions, but they are limited in their ability to account for unobserved confounders affecting both treatment and outcome. Double Spatial Regression (DSR) is an approach that uses double machine learning to address these scenarios. DSR resolves the confounding variables for both treatment and outcome, comparing the residuals to estimate treatment effectiveness. We improve upon DSR by considering time in our analysis of policy interventions with spatial effects. We conduct a large-scale simulation study using Bayesian Additive Regression Trees (BART) with spatial embeddings and find that, under certain conditions, our DSR model outperforms standard approaches for addressing unobserved spatial confounding. We then apply our method to evaluate the policy impacts of land concessions on deforestation in Cambodia.

</details>


### [8] [Hybrid combinations of parametric and empirical likelihoods](https://arxiv.org/abs/2602.18651)
*Nils Lid Hjort,Ian W. McKeague,Ingrid Van Keilegom*

Main category: stat.ME

TL;DR: 本文提出了一种基于参数与非参数似然折衷的混合似然（HL）方法，用于在参数模型下对参数θ进行推断，结合经验似然以提高稳健性，并建立了HL估计量的渐近正态性和类似Wilks定理的结果。


<details>
  <summary>Details</summary>
Motivation: 为了在利用参数模型强度的同时增强对模型误设的稳健性，本文旨在结合参数似然与经验似然的优点，提出一种新的推断框架。

Method: 构造混合似然函数H_n(θ) = L_n(θ)^{1-a} R_n(μ(θ))^a，其中L_n为参数似然，R_n为经验似然，a为权衡参数；在此基础上研究估计量的渐近性质，并讨论模型误设下的扩展及参数a的选择方法。

Result: 建立了混合似然估计量的渐近正态性，证明了类似Wilks定理的结果，并在模型误设情形下验证了方法的稳健性，同时提出了a参数的选取策略。

Conclusion: 混合似然方法有效平衡了参数模型的效率与非参数方法的稳健性，为复杂设定下的统计推断提供了灵活且理论支持充分的新工具。

Abstract: This paper develops a hybrid likelihood (HL) method based on a compromise between parametric and nonparametric likelihoods. Consider the setting of a parametric model for the distribution of an observation $Y$ with parameter $θ$. Suppose there is also an estimating function $m(\cdot,μ)$ identifying another parameter $μ$ via $E\,m(Y,μ)=0$, at the outset defined independently of the parametric model. To borrow strength from the parametric model while obtaining a degree of robustness from the empirical likelihood method, we formulate inference about $θ$ in terms of the hybrid likelihood function $H_n(θ)=L_n(θ)^{1-a}R_n(μ(θ))^a$. Here $a\in[0,1)$ represents the extent of the compromise, $L_n$ is the ordinary parametric likelihood for $θ$, $R_n$ is the empirical likelihood function, and $μ$ is considered through the lens of the parametric model. We establish asymptotic normality of the corresponding HL estimator and a version of the Wilks theorem. We also examine extensions of these results under misspecification of the parametric model, and propose methods for selecting the balance parameter $a$.

</details>


### [9] [Minimally Discrete and Minimally Randomized p-Values](https://arxiv.org/abs/2602.18656)
*Joshua Habiger,Pratyaydipta Rudra*

Main category: stat.ME

TL;DR: 本文提出了“最小离散”自然p值、中间p值和“最小随机化”p值，这些新方法在保持有效性的同时减少了传统p值带来的保守性或额外变异性，为元分析和多重假设检验提供了更高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 由于离散分布数据导致的p值不完全服从均匀分布，传统的自然p值、中间p值和随机化p值存在保守性或引入额外变异的问题，本文旨在通过构建更优的p值形式来缓解这一“离散效应”。

Method: 提出并研究了“最小离散”（MD）自然p值、MD中间p值以及“最小随机化”（MR）p值，利用随机序和凸序理论分析其性质，并比较它们与传统p值在分布主导性和附加变异性方面的差异。

Result: MD p值在随机序和凸序下优于传统对应形式，使下游方法更高效且仍保持有效性；MR p值在保持零假设下均匀分布的同时，减少了由辅助变量引入的变异。

Conclusion: 所提出的MD和MR p值为处理离散数据中的p值问题提供了理论上更优的替代方案，有助于构建更高效的统计推断方法，并为现有和新方法的理论研究设立“黄金标准”。

Abstract: In meta analysis, multiple hypothesis testing and many other methods, p-values are utilized as inputs and assumed to be uniformly distributed over the unit interval under the null hypotheses. If data used to generate p-values have discrete distributions then either natural, mid- or randomized p-values are typically utilized. Natural and mid-p-values can allow for valid, albeit conservative, downstream methods since under the null hypothesis they are dominated by uniform distributions in the stochastic and convex order, respectively. Randomized p-values need not lead to conservative procedures since they permit a uniform distributions under the null hypotheses through the generation of independent auxiliary variates. However, the auxiliary variates necessarily add variation to procedures. This manuscript introduces and studies ``minimally discrete'' (MD) natural p-values, MD mid-p-values and ``minimally randomized'' (MR) p-values. It is shown that MD p-values dominate their non-MD counterparts in the stochastic and convex order, and hence lead to less conservative, yet still valid, downstream methods. Likewise, MR p-values dominate their non-MR counterparts in that they are still uniformly distributed under the null hypotheses, but the added variation attributable to the independently generated auxiliary variate is smaller. It is anticipated that results here will facilitate the construction of new meta-analysis and multiple testing methods via more efficient p-value construction, and facilitate theoretical study of existing and new methods by establishing gold standards for addressing the unavoidable detrimental ``discreteness effect''.

</details>


### [10] [Better Assumptions, Stronger Conclusions: The Case for Ordinal Regression in HCI](https://arxiv.org/abs/2602.18660)
*Brandon Victor Syiem,Eduardo Velloso*

Main category: stat.ME

TL;DR: 本文探讨了人机交互（HCI）领域中对有序数据（如李克特量表）的统计分析方法，指出现有方法的局限性和常见误区，并倡导使用累积链接模型（CLM/CLMM）进行更合适的分析，同时提供了基于R语言的实际案例。


<details>
  <summary>Details</summary>
Motivation: 由于在HCI研究中对有序数据的统计方法缺乏共识，且常忽视方法背后的假设，导致分析结果的解释力下降，因此需要系统评估现有实践并推荐更恰当的统计方法。

Method: 通过回顾近期发表的HCI研究中对有序数据的统计分析方法，总结常用方法及其问题，并引入累积链接模型（CLM/CLMM），结合R语言对开源数据集进行实例分析，展示其优势和应用方式。

Result: 发现HCI领域普遍混用参数与非参数方法，常忽略其前提假设；CLM/CLMM能更好地处理有序数据的特性，提供更准确的推断；并通过实际案例验证了其可行性与优越性。

Conclusion: 应优先采用符合有序数据性质的统计模型（如CLM/CLMM）替代传统方法，以提升HCI研究中数据分析的严谨性与有效性，推动该领域的统计实践规范化。

Abstract: Despite the widespread use of ordinal measures in HCI, such as Likert-items, there is little consensus among HCI researchers on the statistical methods used for analysing such data. Both parametric and non-parametric methods have been extensively used within the discipline, with limited reflection on their assumptions and appropriateness for such analyses. In this paper, we examine recent HCI works that report statistical analyses of ordinal measures. We highlight prevalent methods used, discuss their limitations and spotlight key assumptions and oversights that diminish the insights drawn from these methods. Finally, we champion and detail the use of cumulative link (mixed) models (CLM/CLMM) for analysing ordinal data. Further, we provide practical worked examples of applying CLM/CLMMs using R to published open-sourced datasets. This work contributes towards a better understanding of the statistical methods used to analyse ordinal data in HCI and helps to consolidate practices for future work.

</details>


### [11] [Bayesian calendar-time survival analysis with epidemic curve priors and variant-specific infection hazards](https://arxiv.org/abs/2602.18677)
*Angela M Dahl,Elizabeth R Brown*

Main category: stat.ME

TL;DR: 提出了一种贝叶斯日历时间生存模型，用于流行病期间传染病预防研究，能够结合疫情曲线估计来推断干预措施与感染风险的关系。


<details>
  <summary>Details</summary>
Motivation: 在疫情快速变化的背景下，传统模型难以准确评估干预措施（如疫苗）对感染风险的影响，因此需要一种能动态适应流行病曲线变化的新模型。

Method: 构建贝叶斯生存模型，将不同病毒变异株的感染视为竞争风险，并引入基于疫情曲线先验信息的基线风险函数；同时允许估计生物标志物的保护阈值。

Result: 模拟显示该方法能更准确地估计干预效果，尤其在随访数据稀少的时间段；应用于COVID-19疫苗观察性研究中成功识别了疫苗关联性。

Conclusion: 该模型有效整合了流行病动力学信息，提升了在复杂、动态疫情环境中评估干预措施保护效果的能力。

Abstract: In this paper, we develop a Bayesian calendar-time survival model motivated by infectious disease prevention studies occurring during an epidemic, when the risk of infection can change rapidly as the epidemic curve shifts. For studies in which a biomarker is the predictor of interest, we include the option to estimate a threshold of protection for the biomarker. If the intervention is hypothesized to have different associations with several circulating viral variants, or if the infectiousness of the dominant variant(s) changes over the course of the study, we treat infection from different variants as competing risks. We also introduce a novel method for incorporating existing epidemic curve estimates into an informative prior for the baseline hazard function, enabling estimation of the intervention's association with infection risk during periods of calendar time with minimal follow-up in one or more comparator groups. We demonstrate the strengths of this method via simulations, and we apply it to data from an observational COVID-19 vaccine study.

</details>


### [12] [Expected Shortfall Regression via Optimization](https://arxiv.org/abs/2602.18865)
*Yuanzhi Li,Shushu Zhang,Xuming He*

Main category: stat.ME

TL;DR: 提出了一种新的基于优化的线性预期短缺回归方法，无需对条件分位数模型附加假设，具有异质性自适应权重，提高了估计效率。


<details>
  <summary>Details</summary>
Motivation: 现有超分位数回归与预期短缺回归不一致，缺乏高效且无需额外假设的线性预期短缺回归方法。

Method: 提出一种隐式定义但基于优化的损失函数方法，结合分箱技术进行初始估计，并建立估计量的一致性和渐近正态性。

Result: 该方法实现了异质性自适应加权，在模拟研究中表现出比现有方法更高的估计效率。

Conclusion: 所提方法为线性预期短缺回归提供了有效且理论可靠的解决方案，优于现有方法。

Abstract: To provide a comprehensive summary of the tail distribution, the expected shortfall is defined as the average over the tail above (or below) a certain quantile of the distribution. The expected shortfall regression captures the heterogeneous covariate-response relationship and describes the covariate effects on the tail of the response distribution. Based on a critical observation that the superquantile regression from the operations research literature does not coincide with the expected shortfall regression, we propose and validate a novel optimization-based approach for the linear expected shortfall regression, without additional assumptions on the conditional quantile models. While the proposed loss function is implicitly defined, we provide a prototype implementation of the proposed approach with some initial expected shortfall estimators based on binning techniques. With practically feasible initial estimators, we establish the consistency and the asymptotic normality of the proposed estimator. The proposed approach achieves heterogeneity-adaptive weights and therefore often offers efficiency gain over existing linear expected shortfall regression approaches in the literature, as demonstrated through simulation studies.

</details>


### [13] [Optimal and Structure-Adaptive CATE Estimation with Kernel Ridge Regression](https://arxiv.org/abs/2602.18958)
*Seok-Jin Kim*

Main category: stat.ME

TL;DR: 提出了一种在再生核希尔伯特空间中估计条件平均处理效应的最优算法，通过两阶段核岭回归方法实现，并能适应未知的CATE正则性。


<details>
  <summary>Details</summary>
Motivation: 为了更高效地估计条件平均处理效应（CATEs），尤其是在对比函数比干扰函数结构更简单的情况下。

Method: 开发了一个统一的两阶段核岭回归（KRR）方法，该方法能够达到由对比函数复杂度决定的最小最大率。

Result: 所提出的方法在样本量和重叠方面都达到了由对比函数复杂度而非干扰类复杂度决定的最小最大率。此外，简单的模型选择步骤可以产生一个预言不等式，使方法能够适应未知的CATE正则性。

Conclusion: 提出的两阶段KRR方法为估计CATE提供了一个有效的解决方案，尤其适用于对比函数结构较为简单的情况。

Abstract: We propose an optimal algorithm for estimating conditional average treatment effects (CATEs) when response functions lie in a reproducing kernel Hilbert space (RKHS). We study settings in which the contrast function is structurally simpler than the nuisance functions: (i) it lies in a lower-complexity RKHS with faster eigenvalue decay, (ii) it satisfies a source condition relative to the nuisance kernel, or (iii) it depends on a known low-dimensional covariate representation. We develop a unified two-stage kernel ridge regression (KRR) method that attains minimax rates governed by the complexity of the contrast function rather than the nuisance class, in terms of both sample size and overlap. We also show that a simple model-selection step over candidate contrast spaces and regularization levels yields an oracle inequality, enabling adaptation to unknown CATE regularity.

</details>


### [14] [Distributional Discontinuity Design](https://arxiv.org/abs/2602.19290)
*Kyle Schindl,Larry Wasserman*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Regression discontinuity and kink designs are typically analyzed through mean effects, even when treatment changes the shape of the entire outcome distribution. To address this, we introduce distributional discontinuity designs, a framework for estimating causal effects for a scalar outcome at the boundary of a discontinuity in treatment assignment. Our estimand is the Wasserstein distance between limiting conditional outcome distributions; a single scale-interpretable measure of distribution shift. We show that this weakly bounds the average treatment effect, where equality holds if and only if the treatment effect is purely additive; thus, departure from equality measures effect heterogeneity. To further encode effect heterogeneity we show that the Wasserstein distance admits an orthogonal decomposition into squared differences in $L$-moments, thereby quantifying the contribution from location, scale, skewness, and higher-order shape components to the overall distributional distance. Next, we extend this framework to distributional kink designs by evaluating the Wasserstein derivative at a policy kink; this describes the flow of probability mass through the kink. In the case of fuzzy kink designs, we derive new identification results. Finally, we apply our methods on real data by re-analyzing two natural experiments to compare our distributional effects to traditional causal estimands.

</details>


### [15] [Latent Moment Models for Recurrent Binary Outcomes: A Bayesian and Quasi-Distributional Approach](https://arxiv.org/abs/2602.18988)
*Niloofar Ramezani,Lori P. Selby,Pascal Nitiema,Jeffrey R. Wilson*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recurrent binary outcomes within individuals, such as hospital readmissions, often reflect latent risk processes that evolve over time. Conventional methods like generalized linear mixed models and generalized estimating equations estimate average risk but fail to capture temporal changes in variability, asymmetry, and tail behavior. We introduce two statistical frameworks that model each binary event as the outcome of a thresholded value drawn from a time-varying latent distribution defined by its location, scale, skewness, and kurtosis. Rather than treating these four quantities as nonparametric moment estimators, we model them as interpretable latent moments within a flexible latent distributional family. The first, BLaS-Recurrent, is a Bayesian model using the sinh-arcsinh distribution (a parametric family that provides explicit control over asymmetry and tail weight) to estimate latent moment trajectories; the second, QuaD-Recurrent, is a quasi-distributional approach that maps simulated moment vectors to event probabilities using a flexible nonparametric surface. Both models support time-dependent covariates, serial correlation, and multiple membership structures. Simulation studies show improved calibration, interpretability, and robustness over standard models. Applied to ICU readmission data from the MIMIC-IV database, both approaches uncover clinically meaningful patterns in latent risk, such as right-skewed escalation and widening dispersion, that are missed by traditional methods. These models provide interpretable, distribution-sensitive tools for longitudinal binary outcomes in healthcare while explicitly acknowledging that latent "moments" summarize but do not uniquely determine the underlying distribution.

</details>


### [16] [Zero Variance Portfolio](https://arxiv.org/abs/2602.19462)
*Jinyuan Chang,Yi Ding,Zhentao Shi,Bo Zhang*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: When the number of assets is larger than the sample size, the minimum variance portfolio interpolates the training data, delivering pathological zero in-sample variance. We show that if the weights of the zero variance portfolio are learned by a novel ``Ridgelet'' estimator, in a new test data this portfolio enjoys out-of-sample generalizability. It exhibits the double descent phenomenon and can achieve optimal risk in the overparametrized regime when the number of assets dominates the sample size. In contrast, a ``Ridgeless'' estimator which invokes the pseudoinverse fails in-sample interpolation and diverges away from out-of-sample optimality. Extensive simulations and empirical studies demonstrate that the Ridgelet method performs competitively in high-dimensional portfolio optimization.

</details>


### [17] [Adaptive Weighting for Time-to-Event Continual Reassessment Method: Improving Safety in Phase I Dose-Finding Through Data-Driven Delay Distribution Estimation](https://arxiv.org/abs/2602.19012)
*Robert Amevor,Emmanuel Kubuafor,Dennis Baidoo*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Background: Phase I dose-finding trials increasingly encounter delayed-onset toxicities, especially with immunotherapies and targeted agents. The time-to-event continual reassessment method (TITE-CRM) handles incomplete follow-up using fixed linear weights, but this ad hoc approach doesn't reflect actual delay patterns and may expose patients to excessive risk during dose escalation.
  Methods: We replace TITE-CRM's fixed weights with adaptive weights, posterior predictive probabilities derived from the evolving toxicity delay distribution. Under a Weibull timing model, we get closed-form weight updates through maximum likelihood estimation, making real-time implementation straightforward. We tested our method (AW-TITE) against TITE-CRM and standard designs (3+3, mTPI, BOIN) across three dose-toxicity scenarios through simulation (N = 30 patients, 2,000 replications). We also examined robustness across varying accrual rates, sample sizes, shape parameters, observation windows, and priors.
  Results: Our AW-TITE reduced patient overdosing by 40.6% compared to TITE-CRM (mean fraction above MTD: 0.202 vs 0.340; 95% CI: -0.210 to -0.067, p < 0.001) while maintaining comparable MTD selection accuracy (mean difference: +0.023, p = 0.21). Against algorithm-based methods, AW-TITE achieved higher MTD identification: +32.6% vs mTPI, +19.8% vs 3+3, and +5.6% vs BOIN. Performance remained robust across all sensitivity analyses.
  Conclusions: Adaptive weighting offers a practical way to improve Phase I trial safety while preserving MTD selection accuracy. The method requires minimal computation and is ready for real-time use.

</details>


### [18] [The generalized underlap coefficient with an application in clustering](https://arxiv.org/abs/2602.19473)
*Zhaoxi Zhang,Vanda Inacio,Sara Wade*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantifying distributional separation across groups is fundamental in statistical learning and scientific discovery, yet most classical discrepancy measures are tailored to two-group comparisons. We generalize the underlap coefficient (UNL), a multi-group separation measure, to multivariate variables. We establish key properties of UNL and provide an explicit connection to the total variation. We further interpret the UNL as a dependence measure between a group label and variables of interest and compare it with mutual information. We propose an importance sampling estimator of the UNL that can be combined with flexible density estimators. The utility of the UNL for assessing partition-covariate dependence in clustering is highlighted in detail, where it is particularly useful for evaluating the single-weights assumption in covariate-dependent mixture models. Finally we illustrate the application of the UNL in clustering using two real world datasets.

</details>


### [19] [Estimation and Statistical Inference for Generalized Multilayer Latent Space Model](https://arxiv.org/abs/2602.19129)
*Zhaozhe Liu,Gongjun Xu,Haoran Zhang*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multilayer networks have become increasingly ubiquitous across diverse scientific fields, ranging from social sciences and biology to economics and international relations. Despite their broad applications, the inferential theory for multilayer networks remains underdeveloped. In this paper, we propose a flexible latent space model for multilayer directed networks with various edge types, where each node is assigned with two latent positions capturing sending and receiving behaviors, and each layer has a connection matrix governing the layer-specific structure. Through nonlinear link functions, the proposed model represents the structure of a multilayer network as a tensor, which admits a Tucker low-rank decomposition. This formulation poses significant challenges on the estimation and statistical inference for the latent positions and connection matrices, where existing techniques are inapplicable. To tackle this issue, a novel unfolding and fusion method is developed to facilitate estimation. We establish both consistency and asymptotic normality for the estimated latent positions and connection matrices, which paves the way for statistical inference tasks in multilayer network applications, such as constructing confidence regions for the latent positions and testing whether two network layers share the same structure. We validate the proposed method through extensive simulation studies and demonstrate its practical utility on real-world data.

</details>


### [20] [Optimality of the Half-Order Exponent in the Turing-Good Identities for Bayes Factors](https://arxiv.org/abs/2602.19838)
*Kensuke Okada*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Bayes factors are widely computed by Monte Carlo, yet heavy-tailed sampling distributions can make numerical validation unreliable. The Turing--Good identities provide exact moment equalities for powers of a Bayes factor (a density ratio). When these identities are used as Good-check diagnostics, the power choice becomes a statistical design parameter. We develop a nonasymptotic variance theory for Monte Carlo evaluation of the identities and show that the half-order (square-root) power is uniquely minimax-stable: it equalizes variability across the two model orientations and is the only choice that guarantees finite second moments in a distribution-free worst-case sense over all mutually absolutely continuous model pairs. This yields a balanced two-sample half-order diagnostic that is symmetric in model labeling and has a uniform variance bound at fixed computational budget; in small-overlap regimes it is guaranteed to be no less efficient than the standard one-sided Turing check. Simulations for binomial Bayes factor workflows illustrate stable finite-sample behavior and sensitivity to simulator--evaluator mismatches. We further connect the half-order overlap viewpoint to stable primitives for normalizing-constant ratios and importance-sampling degeneracy summaries.

</details>


### [21] [Generalized entropy calibration for inference with partially observed data: A unified framework](https://arxiv.org/abs/2602.19203)
*Mst Moushumi Pervin,Hengfang Wang,Jae Kwang Kim*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Missing data is an universal problem in statistics. We develop a unified framework for estimating parameters defined by general estimating equations under a missing-at-random (MAR) mechanism, based on generalized entropy calibration weighting. We construct weights by minimizing a convex entropy subject to (i) balancing constraints on a data-adaptive calibration function, estimated using flexible machine-learning predictors with cross-fitting, and (ii) a debiasing constraint involving the fitted propensity score (PS) model. The resulting estimator is doubly robust, remaining consistent if either the outcome regression (OR) or the PS model is correctly specified, and attains the semiparametric efficiency bound when both models are correctly specified. Our formulation encompasses classical inverse probability weighting (IPW) and augmented IPW (AIPW) as special cases and accommodates a broad class of entropy functions. We illustrate the versatility of the approach in three important settings: semi-supervised learning with unlabeled outcomes, regression analysis with missing covariates, and causal effect estimation in observational studies. Extensive simulation studies and real-data applications demonstrate that the proposed estimators achieve greater efficiency and numerical stability than existing methods. In particular, the proposed estimator outperforms the classical AIPW estimator under the OR model misspecification.

</details>


### [22] [Conformal Risk Control for Non-Monotonic Losses](https://arxiv.org/abs/2602.20151)
*Anastasios N. Angelopoulos*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Conformal risk control is an extension of conformal prediction for controlling risk functions beyond miscoverage. The original algorithm controls the expected value of a loss that is monotonic in a one-dimensional parameter. Here, we present risk control guarantees for generic algorithms applied to possibly non-monotonic losses with multidimensional parameters. The guarantees depend on the stability of the algorithm -- unstable algorithms have looser guarantees. We give applications of this technique to selective image classification, FDR and IOU control of tumor segmentations, and multigroup debiasing of recidivism predictions across overlapping race and sex groups using empirical risk minimization.

</details>


### [23] [Statistical Measures for Explainable Aspect-Based Sentiment Analysis: A Case Study on Environmental Discourse in Reddit](https://arxiv.org/abs/2602.19216)
*Luisa Stracqualursi,Patrizia Agati*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Aspect-Based Sentiment Analysis (ABSA) provides a fine-grained understanding of opinions by linking sentiment to specific aspects in text. While transformer-based models excel at this task, their black-box nature limits their interpretability, posing risks in real-world applications without labeled data. This paper introduces a statistical, model-agnostic framework to assess the behavioral transparency and trustworthiness of ABSA models. Our framework relies on several metrics, such as the entropy of polarity distributions, soft-count-based dominance scores, and sentiment divergence between sources, whose robustness is validated through bootstrap resampling and sensitivity analysis. A case study on environmentally focused Reddit communities illustrates how the proposed indicators provide interpretable diagnostics of model certainty, decisiveness, and cross-source variability. The results show that statistical indicators computed on soft outputs can complement traditional approaches, offering a computationally efficient methodology for validating, monitoring, and interpreting ABSA models in contexts where labeled data are unavailable.

</details>


### [24] [A likelihood approach to proper analysis of secondary outcomes in matched case-control studies](https://arxiv.org/abs/2602.19220)
*Shanshan Liu,Guoqing Diao*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Matched case-control studies are commonly employed in epidemiological research for their convenience and efficiency. Analysis of secondary outcomes can yield valuable insights into biological pathways and help identify genetic variants of importance. Naive analysis using standard statistical methods, such as least-squares regression for quantitative traits, can be misleading because they fail to account for unequal sampling induced by the case-control design and matching. In this paper, we propose novel statistical methods that appropriately reflect the study design and sampling scheme in the analysis of secondary outcome data. The new methods provide consistent estimation and accurate coverage probabilities for the confidence interval estimators. We demonstrate the advantages of the new methods through simulation studies and a real application with diabetes patients. R code implementing the proposed methods is publicly available.

</details>


### [25] [CoMET: A Compressed Bayesian Mixed-Effects Model for High-Dimensional Tensors](https://arxiv.org/abs/2602.19236)
*Sreya Sarkar,Kshitij Khare,Sanvesh Srivastava*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Mixed-effects models are fundamental tools for analyzing clustered and repeated-measures data, but existing high-dimensional methods largely focus on penalized estimation with vector-valued covariates. Bayesian alternatives in this regime are limited, with no sampling-based mixed-effects framework that supports tensor-valued fixed- and random-effects covariates while remaining computationally tractable. We propose the Compressed Mixed-Effects Tensor (CoMET) model for high-dimensional repeated-measures data with scalar responses and tensor-valued covariates. CoMET performs structured, mode-wise random projection of the random-effects covariance, yielding a low-dimensional covariance parameter that admits simple Gaussian prior specification and enables efficient imputation of compressed random-effects. For the mean structure, CoMET leverages a low-rank tensor decomposition and margin-structured Horseshoe priors to enable fixed-effects selection. These design choices lead to an efficient collapsed Gibbs sampler whose computational complexity grows approximately linearly with the tensor covariate dimensions. We establish high-dimensional theoretical guarantees by identifying regularity conditions under which CoMET's posterior predictive risk decays to zero. Empirically, CoMET outperforms penalized competitors across a range of simulation studies and two benchmark applications involving facial-expression prediction and music emotion modeling.

</details>


### [26] [Localized conformal model selection](https://arxiv.org/abs/2602.19284)
*Yuhao Wang,Tengyao Wang*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a localized conformal model selection framework that integrates local adaptivity with post-selection validity for distribution-free prediction. By performing model selection symmetrically across calibration points using upper and lower surrogate intervals, we construct a data-dependent safe index set that contains the oracle model and preserves exchangeability. The resulting ensemble procedure retains exact finite-sample marginal coverage while adapting to spatial heterogeneity and model complexity. Simulations demonstrate substantial reductions in interval length compared to the best fixed model, especially in heterogeneous and low-noise settings.

</details>


### [27] [Identification and estimation of the conditional average treatment effect with nonignorable missing covariates, treatment, and outcome](https://arxiv.org/abs/2602.19378)
*Shuozhi Zuo,Yixin Wang,Fan Yang*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Treatment effect heterogeneity is central to policy evaluation, social science, and precision medicine, where interventions can affect individuals differently. In observational studies, covariates, treatment, and outcomes are often only partially observed. When missingness depends on unobserved values (missing not at random; MNAR), standard methods can yield biased estimates of the conditional average treatment effect (CATE). This paper establishes nonparametric identification of the CATE under multivariate MNAR mechanisms that allow covariates, treatment, and outcomes to be MNAR. It also develops nonparametric and parametric estimators and proposes a sensitivity analysis framework for assessing robustness to violations of the missingness assumptions.

</details>


### [28] [Variable selection via knockoffs for clustered data](https://arxiv.org/abs/2602.19398)
*Silvia Bacci,Leonardo Grilli,Carla Rampichini*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We extend the knockoffs method for selecting predictors to clustered data (cross-sectional or repeated measures). In the setting of clustered data, variable selection is complex because some predictors are measured at the observation level (level 1), whereas others are measured at the cluster level (level 2), so their values are constant within clusters. The solution we propose is to conduct variable selection separately at the two levels. To this end, we suggest a two-step approach: (i) decompose each level 1 predictor into level 2 and level 1 components by replacing it with the cluster mean and the deviation from the cluster mean; (ii) perform variable selection separately at the two levels, where the level 1 data matrix includes the deviations from the cluster means and the level 2 data matrix includes the cluster means of level 1 predictors and the level 2 predictors. To evaluate the performance of the proposed approach, we conduct a simulation study comparing the sequential knockoff, the derandomized knockoff, and the Lasso. The study shows satisfactory results in terms of false discovery rate and power. All methods fail when applied to the complete data matrix, including both level 1 and level 2 predictors. In contrast, all methods perform better when applied to the level 1 and level 2 data matrices separately. Moreover, the sequential knockoffs method performs substantially better than the Lasso and the derandomized knockoffs. Our proposal to implement the knockoffs method in a clustered data framework is feasible, flexible, and effective.

</details>


### [29] [Local depth-based classification of directional data](https://arxiv.org/abs/2602.19648)
*Giuseppe Gismondi,Rebecca Rivieccio,Giuseppe Pandolfo*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Directional data arise in many applications where observations are naturally represented as unit vectors or as observations on the surface of a unit hypersphere. In this context, statistical depth functions provide a center--outward ordering of the data. This work aims at proposing the use of a local notion of data depth function to be applied in the DD-plot (Depth vs. Depth plot) to classify directional data. The proposed method is investigated through an extensive simulation study and two real-data examples.

</details>


### [30] [Individualized Causal Effects under Network Interference with Combinatorial Treatments](https://arxiv.org/abs/2602.19738)
*Yunping Lu,Haoang Chi,Qirui Hu,Zhiheng Zhang*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Modern causal decision-making increasingly demands individualized treatment-effect estimation in networks where interventions are high-dimensional, combinatorial vectors. While network interference, effect heterogeneity, and multi-dimensional treatments have been studied separately, their intersection yields an exponentially large intervention space that makes standard identification tools and low-dimensional exposure mappings untenable. We bridge this gap with a unified framework that constructs a \emph{global potential-outcome emulator} for unit-level inference. Our method combines (1) rooted network configurations to leverage local smoothness, (2) doubly robust orthogonalization to mitigate confounding from network position and covariates, and (3) sparse spectral learning to efficiently estimate response surfaces over the $2^p$-dimensional treatment space. We also decompose networked effects into own-treatment, structural, and interaction components, and provide finite-sample error bounds and asymptotic consistency guarantees. Overall, we show that individualized causal inference remains feasible in high-dimensional networked settings without collapsing the intervention space.

</details>


### [31] [Orthogonal Uplift Learning with Permutation-Invariant Representations for Combinatorial Treatments](https://arxiv.org/abs/2602.19851)
*Xinyan Su,Jiacan Gao,Mingyuan Ma,Xiao Xu,Xinrui Wan,Tianqi Gu,Enyun Yu,Jiecheng Guo,Zhiheng Zhang*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study uplift estimation for combinatorial treatments. Uplift measures the pure incremental causal effect of an intervention (e.g., sending a coupon or a marketing message) on user behavior, modeled as a conditional individual treatment effect. Many real-world interventions are combinatorial: a treatment is a policy that specifies context-dependent action distributions rather than a single atomic label. Although recent work considers structured treatments, most methods rely on categorical or opaque encodings, limiting robustness and generalization to rare or newly deployed policies. We propose an uplift estimation framework that aligns treatment representation with causal semantics. Each policy is represented by the mixture it induces over contextaction components and embedded via a permutation-invariant aggregation. This representation is integrated into an orthogonalized low-rank uplift model, extending Robinson-style decompositions to learned, vector-valued treatments. We show that the resulting estimator is expressive for policy-induced causal effects, orthogonally robust to nuisance estimation errors, and stable under small policy perturbations. Experiments on large-scale randomized platform data demonstrate improved uplift accuracy and stability in long-tailed policy regimes

</details>


### [32] [Transfer Learning with Network Embeddings under Structured Missingness](https://arxiv.org/abs/2602.19922)
*Mengyan Li,Xiaoou Li,Kenneth D Mandl,Tianxi Cai*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Modern data-driven applications increasingly rely on large, heterogeneous datasets collected across multiple sites. Differences in data availability, feature representation, and underlying populations often induce structured missingness, complicating efforts to transfer information from data-rich settings to those with limited data. Many transfer learning methods overlook this structure, limiting their ability to capture meaningful relationships across sites. We propose TransNEST (Transfer learning with Network Embeddings under STructured missingness), a framework that integrates graphical data from source and target sites with prior group structure to construct and refine network embeddings. TransNEST accommodates site-specific features, captures within-group heterogeneity and between-site differences adaptively, and improves embedding estimation under partial feature overlap. We establish the convergence rate for the TransNEST estimator and demonstrate strong finite-sample performance in simulations. We apply TransNEST to a multi-site electronic health record study, transferring feature embeddings from a general hospital system to a pediatric hospital system. Using a hierarchical ontology structure, TransNEST improves pediatric embeddings and supports more accurate pediatric knowledge extraction, achieving the best accuracy for identifying pediatric-specific relational feature pairs compared with benchmark methods.

</details>


### [33] [Change point analysis of high-dimensional data using random projections](https://arxiv.org/abs/2602.19988)
*Yi Xu,Yeonwoo Rho*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper develops a novel change point identification method for high-dimensional data using random projections. By projecting high-dimensional time series into a one-dimensional space, we are able to leverage the rich literature for univariate time series. We propose applying random projections multiple times and then combining the univariate test results using existing multiple comparison methods. Simulation results suggest that the proposed method tends to have better size and power, with more accurate location estimation. At the same time, random projections may introduce variability in the estimated locations. To enhance stability in practice, we recommend repeating the procedure, and using the mode of the estimated locations as a guide for the final change point estimate. An application to an Australian temperature dataset is presented. This study, though limited to the single change point setting, demonstrates the usefulness of random projections in change point analysis.

</details>


### [34] [Covariance estimation for derivatives of functional data using an additive penalty in P-splines](https://arxiv.org/abs/2602.20029)
*Yueyun Zhu,Steven Golovkine,Norma Bargary,Andrew J. Simpkin*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: P-splines provide a flexible and computationally efficient smoothing framework and are commonly used for derivative estimation in functional data. Including an additive penalty term in P-splines has been shown to improve estimates of derivatives. We propose a method which incorporates the fast covariance estimation (FACE) algorithm with an additive penalty in P-splines. The proposed method is used to estimate derivatives of covariance for functional data, which play an important role in derivative-based functional principal component analysis (FPCA). Following this, we provide an algorithm for estimating the eigenfunctions and their corresponding scores in derivative-based FPCA. For comparison, we evaluate our algorithm against an existing function \texttt{FPCAder()} in simulation. In addition, we extend the algorithm to multivariate cases, referred to as derivative multivariate functional principal component analysis (DMFPCA). DMFPCA is applied to joint angles in human movement data, where the derivative-based scores demonstrate strong performance in distinguishing locomotion tasks.

</details>


### [35] [Improving the Power of Bonferroni Adjustments under Joint Normality and Exchangeability](https://arxiv.org/abs/2602.20118)
*Caleb Hiltunen,Yeonwoo Rho*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Bonferroni's correction is a popular tool to address multiplicity but is notorious for its low power when tests are dependent. This paper proposes a practical modification of Bonferroni's correction when test statistics are jointly normal and exchangeable. This method is intuitive to practitioners and achieves higher power in sparse alternatives, as our simulations suggest. We also prove that this method successfully controls the family-wise error rate at any significance level.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [36] [Hearing the forest for the trees: machine learning and topological acoustics for remote sensing with seismic noise](https://arxiv.org/abs/2602.18485)
*Jiayang Wang,I-Tzu Huang,Bingxu Luo,Susan L. Beck,Falk Huettmann,Skyler DeVaughn,Benjamin Stilin,Keith Runge,Pierre Deymier,Marat I. Latypov*

Main category: physics.geo-ph

TL;DR: 本研究首次证明，通过被动地震感知技术可以从环境地震噪声中捕捉树木的特征信号，实现全天候、持续的森林监测。利用阿拉斯加的地震数据，结合机器学习和拓扑声学分析，实现了86%准确率的森林识别，关键频率在35至60 Hz之间。


<details>
  <summary>Details</summary>
Motivation: 传统卫星遥感在监测偏远森林时受限于天气、树冠密度和光照条件，亟需一种稳定、全天候的替代监测手段。

Method: 采用被动地震传感技术，利用台站间的地震噪声互相关近似介质的经验格林函数，并结合监督式机器学习模型进行森林分类；同时通过拓扑声学分析验证分类结果的物理来源。

Result: 机器学习模型在地震数据上实现了86%的森林分类准确率，识别出35至60 Hz为关键区分频段，拓扑相位分析证实了这些信号源于森林与地震波的相互作用。

Conclusion: 环境地震噪声中存在可检测的森林-波相互作用信号，被动地震感知可作为一种可扩展、鲁棒的技术手段，用于难以到达区域的连续植被监测，为应对气候变化和生物多样性保护提供新工具。

Abstract: Monitoring remote forests is a global challenge central to climate mitigation and biodiversity conservation, yet satellite observations are frequently limited by weather, dense canopies, and solar dependency. Here we show that passive seismic sensing offers a persistent, all-weather alternative for autonomous ecosystem monitoring by capturing characteristic learnable signatures of trees within the ambient wavefield. Using seismic data from Alaska, we demonstrate that cross-correlations between stations provide a physical basis for forest detection by approximating the empirical Green's function of the medium. Supervised machine learning models applied to these data achieve a classification accuracy of 86%, identifying key discriminating frequencies (35 to 60 Hz) consistent with known forest-wave interactions. A topological acoustics analysis of the geometric phase change independently confirms the physical origin of these data-driven classifications. Together, these results provide the first demonstration that subtle forest-wave interactions manifest in ambient seismic noise and can be harnessed as a scalable tool for continuous vegetation monitoring, offering a robust solution for tracking environmental change challenging regions.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [37] [UniRank: A Multi-Agent Calibration Pipeline for Estimating University Rankings from Anonymized Bibliometric Signals](https://arxiv.org/abs/2602.18824)
*Pedram Riyazimehr,Seyyed Ehsan Mahmoudi*

Main category: cs.SI

TL;DR: UniRank是一个基于多智能体大语言模型的系统，利用OpenAlex和Semantic Scholar的公开文献计量数据，通过三阶段架构匿名预测大学在全球排名中的位置，避免了模型记忆偏差，在THE排名中表现出良好相关性且无记忆化现象。


<details>
  <summary>Details</summary>
Motivation: 为了避免大语言模型在大学排名预测中依赖记忆而非分析推理，需要构建一个不暴露机构身份和真实排名的评估系统，以检验模型的真实推理能力。

Method: 采用三阶段多智能体LLM流水线：（a）基于匿名机构指标进行零样本估计，（b）针对各排名系统使用工具增强校准，（c）最终结果合成；所有机构信息如名称、国家、论文标题等均被脱敏处理，真实排名在校准过程中对工具不可见。

Result: 在THE世界大学排名（n=352）上，系统取得MAE=251.5，中位AE=131.5，PNMAE=12.03%，Spearman ρ=0.769，Kendall τ=0.591，前50命中率20.7%，前100命中率39.8%，记忆指数为0；误差呈系统性正偏（+190.1），且从顶尖到尾部院校性能单调下降，表明为真实分析而非记忆。

Conclusion: UniRank能够基于公开数据进行去匿名化的大学排名预测，其结果证明该系统依赖于实际分析推理而非记忆已有排名，为公平、透明的学术评估提供了可复现的新范式。

Abstract: We present UniRank, a multi-agent LLM pipeline that estimates university positions across global ranking systems using only publicly available bibliometric data from OpenAlex and Semantic Scholar. The system employs a three-stage architecture: (a) zero-shot estimation from anonymized institutional metrics, (b) per-system tool-augmented calibration against real ranked universities, and (c) final synthesis. Critically, institutions are anonymized -- names, countries, DOIs, paper titles, and collaboration countries are all redacted -- and their actual ranks are hidden from the calibration tools during evaluation, preventing LLM memorization from confounding results. On the Times Higher Education (THE) World University Rankings ($n=352$), the system achieves MAE = 251.5 rank positions, Median AE = 131.5, PNMAE = 12.03%, Spearman $ρ= 0.769$, Kendall $τ= 0.591$, hit rate @50 = 20.7%, hit rate @100 = 39.8%, and a Memorization Index of exactly zero (no exact-match zero-width predictions among all 352 universities). The systematic positive-signed error (+190.1 positions, indicating the system consistently predicts worse ranks than actual) and monotonic performance degradation from elite tier (MAE = 60.5, hit@100 = 90.5%) to tail tier (MAE = 328.2, hit@100 = 20.8%) provide strong evidence that the pipeline performs genuine analytical reasoning rather than recalling memorized rankings. A live demo is available at https://unirank.scinito.ai .

</details>


### [38] [Constrained graph generation: Preserving diameter and clustering coefficient simultaneously](https://arxiv.org/abs/2602.19595)
*Dávid Ferenczi,Alexander Grigoriev*

Main category: cs.SI

TL;DR: 提出了一种结合蚁群优化（ACO）和马尔可夫链蒙特卡洛（MCMC）的两步混合框架，用于生成满足直径和聚类系数等严格结构约束的图，显著提升了图的多样性和搜索效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法在生成满足多重结构性约束（如直径和聚类系数）的图时面临搜索空间不可达或遍历性破坏的问题，难以找到可行解并保证多样性。

Method: 首先设计分层的ACO启发式算法进行引导性全局搜索，找到满足约束的有效图；然后将这些图作为种子状态输入MCMC重连算法，实现结构多样化的采样。

Result: 实验表明，相比标准MCMC方法局限于初始种子附近的孤立图集，该混合框架能跨越不连通的构型空间，生成更丰富、结构更多样的有效图。

Conclusion: ACO-MCMC混合框架有效解决了强约束下图生成的遍历性难题，显著提升了结构多样性和采样能力。

Abstract: Generating graphs subject to strict structural constraints is a fundamental computational challenge in network science. Simultaneously preserving interacting properties-such as the diameter and the clustering coefficient- is particularly demanding. Simple constructive algorithms often fail to locate vanishingly small sets of feasible graphs, while traditional Markov-chain Monte Carlo (MCMC) samplers suffer from severe ergodicity breaking. In this paper, we propose a two-step hybrid framework combining Ant Colony Optimization (ACO) and MCMC sampling. First, we design a layered ACO heuristic to perform a guided global search, effectively locating valid graphs with prescribed diameter and clustering coefficient. Second, we use these ACO-designed graphs as structurally distinct seed states for an MCMC rewiring algorithm. We evaluate this framework across a wide range of graph edge densities and varying diameter-clustering-coefficient constraint regimes. Using the spectral distance of the normalized Laplacian to quantify structural diversity of the resulting graphs, our experiments reveal a sharp contrast between the methods. Standard MCMC samplers remain rigidly trapped in an isolated subset of feasible graphs around their initial seeds. Conversely, our hybrid ACO-MCMC approach successfully bridges disconnected configuration landscapes, generating a vastly richer and structurally diverse set of valid graphs.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [39] [Index theorem with Minimally Doubled Fermions in four space-time dimensions](https://arxiv.org/abs/2602.19767)
*Abhijeet Kishore,Subhasish Basak,Dipankar Chakrabarti*

Main category: hep-lat

TL;DR: 本文研究了在Karsten-Wilczek和Borici-Creutz两种形式下，四维时空格点上最小倍增费米子（MDF）的零本征模谱，并利用具有整数拓扑荷的背景规范场验证了Atiyah-Singer指标定理。


<details>
  <summary>Details</summary>
Motivation: 为了理解最小倍增费米子在格点QCD中如何正确再现拓扑性质，特别是零模与拓扑荷之间的关系。

Method: 采用具有整数拓扑荷的背景规范场（Smit-Vink和冷却后的MILC asqtad系综），结合带味质量项和修正的手性算符，分析零本征模的谱流和手性。

Result: 验证了Atiyah-Singer指标定理在两种背景场下的成立；谱流能够反映背景场的拓扑结构；通过修正手性算符得到了零模的手性和费米拓扑荷。

Conclusion: 最小倍增费米子能够在格点上正确描述拓扑效应，且其零模结构与理论预期一致。

Abstract: We determine the zero eigenmode spectrum of Minimally Doubled Fermions (MDF), namely in Karsten-Wilczek (KW) and Borici-Creutz (BC) formulations on the 4-dimensional space-time lattice. We employ background gauge fields with integer valued topological charges. The Atiyah-Singer index theorem is verified in the presence of two different background gauge fields, namely Smit-Vink [1] and cooled down MILC asqtad ensembles with $N_f=2+1$ dynamical flavors of quarks [2]. Using flavored mass terms [3,4], we find that the spectral flow of the eigenvalues detects the topology of the background gauge field. With the use of the modified chirality operator, we obtain chiralities of the zero eigenmodes and the fermionic topological charge.

</details>


### [40] [The Lambda 1405 at the $SU(3)$ point in lattice QCD](https://arxiv.org/abs/2602.19928)
*Javier Suarez Sucunza,Thomas Luu,Carsten Urbach*

Main category: hep-lat

TL;DR: 本研究通过在SU(3)对称点上的格点QCD模拟，研究Λ(1405)的极点结构，利用手征微扰理论和介子-重子相互作用探讨其双极点起源。


<details>
  <summary>Details</summary>
Motivation: Λ(1405)的极点结构长期存在争议，希望通过SU(3)对称性下的格点QCD计算揭示其内在结构。

Method: 在SU(3)对称的格点QCD系综上，使用弥散技术计算相关关联函数，并构建属于SU(3)不可约表示的插值算符。

Result: 提取了与单态及两个八重态量子数对应的能级，可用于手征微扰理论中的极点分析。

Conclusion: 该方法为理解Λ(1405)的双极点结构提供了基于第一性原理的理论支持。

Abstract: The pole structure of the $Λ(1405)$ has been a topic of debate for a long time. Chiral perturbation theory predicts that its experimental spectrum may be explained by a two pole structure originating in the $SU(3)$ chiral dynamics of the baryon-meson interaction. The $SU(3)$-symmetric flavor point is readily accessible in lattice QCD, in this work we study the baryon-meson states directly at this point. We construct interpolation operators that belong to the irreducible representations of $SU(3)$ that are attractive in the channel with the quantum numbers of the (singlet and two octets). The extracted energy levels can be used as input for chiral perturbation theory to find the poles associated with each representation. The relevant correlation functions are computed on $SU(3)$-symmetric ensembles with $M_π\approx 714$ MeV using the distillation technique.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [41] [Extension of the fusion power plant costing standard](https://arxiv.org/abs/2602.19389)
*Simon Woodruff,Alicia Durham,Alex Higginbottom,Chris Raastad*

Main category: physics.soc-ph

TL;DR: 本文介绍了清洁空气任务组（CATF）国际工作组在2024-2025年对核聚变成本分析的研究，扩展了pyFECONs成本估算框架，引入了基于磁约束、惯性约束和磁惯性约束聚变的三类架构成本驱动模型，并增强了从物理参数到经济评估的可追溯性。


<details>
  <summary>Details</summary>
Motivation: 为了提升核聚变电站成本估算的透明度与准确性，支持对不同聚变技术路径的公平比较和政策决策。

Method: 基于ARPA-E的标准会计科目表和物理到经济的工作流，重构并深化了pyFECONs框架，针对MFE、IFE和MIFE三大聚变路径建立驱动器中心化的成本账户体系；引入概率性成本层，结合材料价格、技术成熟度和学习曲线的不确定性；发展安全信息成本模型，将安全措施映射至标准账户，并加入监管与财务附加项；扩展宏观经济与融资参数化模块及价值指标计算。

Result: 构建了一个可扩展、透明且集成了不确定性传播、安全与金融耦合分析的成本分析环境，能够支持聚变示范电厂和NOAK场景下的敏感性研究与综合评估。

Conclusion: 该框架将确定性成本核算升级为支持多维度分析的综合平台，有助于推动聚变能源的商业化决策和技术路线评估。

Abstract: This paper documents the work of the Clean Air Task Force (CATF) International Working Group (IWG) on Fusion Cost Analysis in 2024-2025, and the methodological extensions implemented in the CATF-supported branch of the pyFECONs fusion power-plant costing framework. Using the standards-aligned chart-of-accounts and physics-to-economics workflow established by ARPA-E. The IWG development reorganizes and deepens the framework around three architecture-defining cost-driver tracks for Magnetic Fusion Energy (MFE), Inertial Fusion Energy (IFE), and Magneto-Inertial Fusion Energy (MIFE). In particular, the generic driver placeholder in Account 22.1.3 is treated as a controlled swap-point and replaced by a full cost-account development for the dominant driver in each class, enabling auditable traceability from requirements and geometry to rolled-up plant costs. On top of this driver-centric foundation, we introduce a probabilistic costing layer that compounds materials price uncertainty, TRL-based maturity uncertainty, and learning-curve uncertainty into cost distributions. We then describe safety-informed costing that enumerates fusion-relevant hazards and maps mitigating systems, structures, and provisions into standardized accounts, together with scenario-parameterized regulatory and financial adders. Finally, we document expanded macroeconomic and finance parameterization and a value-metrics module that complements LCOE with investment and planning measures (NPV, IRR MIRR, revenue requirements, WACC-based annualization, and residual and follow-on value), all computed from the same COA-mapped outputs. Collectively, these additions convert a deterministic, standards-aligned costing backbone into an extensible analysis environment suitable for transparent sensitivity studies, uncertainty propagation, and safety- and finance-coupled interpretation of fusion pilot-plant and NOAK scenarios.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [42] [Sparse Dictionary-Based Solution of Dynamic Inverse Problems](https://arxiv.org/abs/2602.18593)
*Aidan Mason-Mackay,Daniela Calvetti,Erkki Somersalo,Antti Aarnio,Mikko Kettunen,Ekaterina Paasonen Olli Gröhn,Ville Kolehmainen*

Main category: math.NA

TL;DR: 提出了一种基于随机分层稀疏先验的字典编码方法，用于求解病态动态反问题，通过最大后验估计和IAS算法实现，在动态CT和MRI数据上表现出对超参数较低敏感性的竞争优势。


<details>
  <summary>Details</summary>
Motivation: 利用空间特征和时间相关性改善数据有限、未知量高维情况下的动态反问题求解质量。

Method: 将时空特征编码入字典原子，采用随机分层稀疏先验建模，通过IAS算法求解最大后验估计。

Result: 在真实动态CT和MRI数据上的实验表明，该方法在压缩感知任务中与ADMM相当，且对超参数选择的敏感性显著更低。

Conclusion: 所提方法在处理动态反问题时具有竞争力，并具备更稳健的超参数鲁棒性。

Abstract: In ill-posed dynamic inverse problems expected spatial features and temporal correlation between frames can be leveraged to improve the quality of the computed solution, in particular when the available data are limited and the dimensionality of the unknown is large. One way to take advantage of the spatial and temporal traits believed to characterize the solution is to encode them into the entries of a dictionary, and to seek the solution as a sparse linear combination of the dictionary atoms. To promote a vector of coefficients with mostly vanishing entries, we consider a stochastic extension of the dictionary coding problem model with a random hierarchical sparsity promoting prior. We compute the Maximum A Posteriori (MAP) estimate of the coefficient vector using the Iterative Alternating Sequential Algorithm (IAS), which has been demonstrated to efficiently solve inverse problems with minimal need for parameter tuning. The proposed methodology is tested on real-world dynamic Computed Tomography and MRI datasets, where it is compared to the popular Alternating Direction Method of Minimizers (ADMM). The computed examples show the that proposed methodology is competitive with the ADMM for compressed sensing, with a significantly lower sensitivity to hyper-parameter selection.

</details>


### [43] [From an Elementary Proof of Error Representation for Hermite Quadrature to a Rediscovery of Legendre Polynomials and Rodrigues Formula](https://arxiv.org/abs/2602.18634)
*Tan Bui-Thanh,Giancarlo Villatoro,C. G. Krishnanunni*

Main category: math.NA

TL;DR: 本文推广了两点插值Hermite求积公式，利用反向分部积分法给出了该求积规则的精确误差表达式，其推导仅需分部积分，且对函数正则性要求更低，适用于更广泛的函数类。同时揭示了Legendre多项式与Hermite插值之间的深刻联系，并重新发现了Legendre多项式的Rodrigues公式。


<details>
  <summary>Details</summary>
Motivation: 传统Hermite求积公式的误差分析通常要求较高阶导数的存在性，限制了其适用范围。本文旨在通过更初等的方法推导误差公式，并降低对函数正则性的要求，从而扩展其应用范围，同时探索其与Legendre多项式之间的内在联系。

Method: 采用反向形式的分部积分法进行误差分析，并结合Peano核定理提供另一种证明途径；构造复合插值Hermite求积公式以增强实用性。

Result: 得到了仅需函数n阶导数存在的精确误差表达式，放宽了经典方法中对(2n)阶导数的要求；发现Legendre多项式恰好是Hermite求积误差的核函数，并重新导出了Rodrigues公式；提出了可用于实际计算的复合Hermite求积规则。

Conclusion: 所提出的方法不仅简化了Hermite求积误差的推导过程，还显著降低了正则性条件，拓展了其适用范围，同时建立了Hermite插值与Legendre多项式之间的自然联系，具有理论和应用价值。

Abstract: We generalize two-point interpolatory Hermite quadrature to functions with available values and the first (n-1) derivatives at both end points. Armed with integration by parts in the reverse form we provide an elementary derivation of an exact error represenation of Hermite quadrature rule. This approach possesses several advantages over the classical approaches: i) Only integration by parts is needed for the derivation; ii) the error representation requires much milder regularity, namely the existence of nth-order derivative rather than a (2n)th-order derivative of the function under consideration. As a result, our error formula is valid for less regular functions for which the classical ones are not valid; iii) our approach rediscovers Legendre polynomials and more interestingly it provides a surprisingly elegant relation between Legendre polynomial and Hermite interpolation. In particular, Legendre polynomials are precisely the error kernels for interpolatory Hermite quadrature rules; and iv) We also rediscover the Rodrigues formula for Legendre polynomials as part of our findings. For those who are interested in a different proof of the exact error representation for Hermite quadrature rule, we provide an alternative proof using the Peano kernel theorem. We also provide a composite interpolatory Hermite quadrature rule for practical applications.

</details>


### [44] [Constructive discretization and approximation in reproducing kernel Hilbert spaces](https://arxiv.org/abs/2602.18719)
*Abdellah Chkifa,Matthieu Dolbeault,David Krieg,Mario Ullrich*

Main category: math.NA

TL;DR: 本文推广了Batson、Spielman和Srivastava的稀疏化算法，使其部分结果与维度无关，得到了L2范数和上确界范数下的离散化不等式，并改进了现有近似误差界的构造性和常数因子。


<details>
  <summary>Details</summary>
Motivation: 为了在有限维和无限维空间中更构造性地建立离散化不等式，并改进基于采样的最小二乘逼近误差分析，作者希望摆脱对非构造性强但不够实用的Marcus-Spielman-Srivastava结果的依赖。

Method: 通过推广Batson-Spielman-Srivastava的稀疏化技术，引入与维度无关的分析方法，结合采样策略和矩阵分析工具，在一般有限维子空间上推导出L2和上确界范数下的离散化不等式，并将其扩展到合适的无限维情形。

Result: 获得了与维度无关的离散化不等式；建立了适用于最小二乘逼近误差分析的新结果；改进了已有近似界中的常数和过采样因子；提供了比Marcus-Spielman-Srivastava方法更具构造性的替代方案。

Conclusion: 所提出的广义稀疏化方法为函数逼近和基于采样的最小二乘法提供了更强且更实用的理论支持，同时在多个关键指标上优于先前工作。

Abstract: We generalize the sparsification algorithm of Batson, Spielman and Srivastava, making one part of the result dimension-independent. In particular, we recover discretization inequalities in $L_2$- and sup-norms on general finite-dimensional subspaces, prove a suitable infinite-dimensional variant, and discuss the implications for the error of least-squares approximation based on samples. This gives a more constructive version of several recently established approximation bounds, some of which relied on the stronger and less constructive result of Marcus, Spielman and Srivastava. We also improve the constants and oversampling factors in these results.

</details>


### [45] [Finite element methods for isometric embedding of Riemannian manifolds](https://arxiv.org/abs/2602.18722)
*Guangwei Gao,Kaibo Hu,Buyang Li,Ganghui Zhang*

Main category: math.NA

TL;DR: 本文研究了二维正高斯曲率黎曼流形等距嵌入到三维欧氏空间的数值逼近问题，提出了新的弱形式并建立了适于高阶有限元离散的数值格式，证明了其适定性、解的存在唯一性及收敛性，并推广至里奇流的等距嵌入，提供了几何演化的可视化方法，数值实验验证了理论分析。


<details>
  <summary>Details</summary>
Motivation: 等距嵌入问题是微分几何中的核心问题，但由于其非线性和退化特性，严格的数值分析进展有限。本文旨在填补这一空白，为计算黎曼流形的等距嵌入建立坚实的数值基础。

Method: 提出了一种新的弱形式，适用于高阶有限元离散，并进行系统分析以证明其适定性、数值解的存在唯一性以及具有误差估计的收敛性。

Result: 建立了Weyl问题的数值逼近框架，证明了弱形式的适定性和数值解的收敛性，扩展至里奇流的等距嵌入并给出严格误差估计，数值实验验证了方法的有效性和收敛性。

Conclusion: 本文为黎曼流形向欧氏空间的等距嵌入提供了首个系统的数值分析框架，奠定了计算基础，并有望推广至更广泛的情形和应用。

Abstract: The isometric embedding problem for Riemannian manifolds, which connects intrinsic and extrinsic geometry, is a central question in differential geometry with deep theoretical significance and wide-ranging applications. Despite extensive analytical progress, the nonlinear and degenerate nature of this problem has hindered the development of rigorous numerical analysis in this area. As the first step toward addressing this gap, we study the numerical approximation of Weyl's problem, i.e., the isometric embedding of two-dimensional Riemannian manifolds with positive Gaussian curvature into $\mathbb{R}^3$, by establishing a new weak formulation that naturally leads to a numerical scheme well suited for high-order finite element discretization, and conducting a systematic analysis to prove the well-posedness of this weak formulation, the existence and uniqueness of its numerical solution, as well as its convergence with error estimates. This provides a foundational framework for computing isometric embeddings of Riemannian manifolds into Euclidean space, with the goal of extending it to a broader range of cases and applications in the future. Our framework also extends naturally to the isometric embedding of the Ricci flow, with rigorous error estimates, enabling the visualization of geometric evolutions in intrinsic curvature flows. Numerical experiments support the theoretical analysis by demonstrating the convergence of the method and its effectiveness in simulating isometric embeddings of given Riemannian manifolds as well as Ricci flows.

</details>


### [46] [Structure-preserving Krylov Subspace Approximations for the Matrix Exponential of Hamiltonian Matrices: A Comparative Study](https://arxiv.org/abs/2602.18937)
*Peter Benner,Heike Faßbender,Michel-Niklas Senn*

Main category: math.NA

TL;DR: 研究了保持结构的Krylov子空间方法，用于近似大Hamiltonian矩阵的函数-向量乘积，在指数积分器中保持Hamiltonian结构。


<details>
  <summary>Details</summary>
Motivation: 标准Krylov方法在投影过程中破坏Hamiltonian结构，因此需要保持结构的方法以确保数值解的物理一致性。

Method: 采用具有J-正交列的Krylov基，使得投影后的矩阵保持Hamiltonian结构，并实现辛约化指数映射。

Result: 在代表性Hamiltonian问题上比较了多种结构保持方法，验证了其在精度、效率和结构保持方面的优势。

Conclusion: 结构保持的Krylov方法能有效维持Hamiltonian系统的几何特性，适合用于指数积分器。

Abstract: We study structure-preserving Krylov subspace methods for approximating the matrix-vector products f(H)b, where H is a large Hamiltonian matrix and f denotes either the matrix exponential or the related phi-function. Such computations are central to exponential integrators for Hamiltonian systems. Standard Krylov methods generally destroy the Hamiltonian structure under projection, motivating the use of Krylov bases with J-orthogonal columns that yield Hamiltonian projected matrices and symplectic reduced exponentials. We compare several such structure-preserving Krylov methods on representative Hamiltonian test problems, focusing on accuracy, efficiency, and structure preservation, and briefly discuss adaptive strategies for selecting the Krylov subspace dimension.

</details>


### [47] [Computing the SVD efficiently with photonic chips](https://arxiv.org/abs/2602.18950)
*Johannes Maly,Korbinian Neuner,Samarth Vadia*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In light of today's massive data processing, digital computers are reaching fundamental performance limits due to physical limitations and energy consumption. For specific applications, tailored analog systems offer promising alternatives to digital processors. In this work, we investigate the potential of linear photonic chips for accelerating the computation of the singular value decomposition (SVD) of a matrix. The SVD is a key primitive in linear algebra and forms a crucial component of various modern data processing algorithms. Our main insights are twofold: first, hybrid systems of digital controller and photonic chip asymptotically perform on par with large-scale CPU/GPU systems in terms of runtime. Second, such hybrid systems clearly outperform digital systems in terms of energy consumption.

</details>


### [48] [On the convergence of explicit formulas for $L^2$ solutions to the Benjamin-Ono and continuum Calogero-Moser equations](https://arxiv.org/abs/2602.19046)
*Yvonne Alama Bronsard,Thierry Laurens*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: By developing discrete counterparts to recent advances in nonlinear integrability, and in particular to the discovery of explicit formulas, we design and analyze fully-discrete approximations to the Benjamin-Ono (BO) and continuum Calogero-Moser (CCM) equations on the torus. We build on the key observation that discretizing such explicit formulas yields schemes that are exact in time (requiring only spatial discretization) and have a computational cost independent of the final time $T$. In this work, we first generalize the fully-discrete schemes of arXiv:2412.13480 to include numerical approximations with better structure preservation properties, including the conservation of mass and momentum in the case of the (BO) equation. Secondly, building on recent analyses of the corresponding Lax operators, we extend the convergence results to this class of schemes for rough solutions $u(t)$ merely belonging to $L^2(\mathbb{T})$ for (BO) and $L^2_{+}(\mathbb{T})$ for (CCM), the latter of which is precisely the scaling-critical regularity. Our main theorem states that the $L^2(\mathbb{T})$-norm of the error goes to zero as the truncation parameters go to infinity, uniformly on any bounded time interval $[-T,T]$. As an example, we apply our scheme to the (BO) equation with a square-wave initial profile, and obtain the first numerical evidence of the Talbot effect for (BO) supported by a rigorous convergence result.

</details>


### [49] [Forward Error-Oriented Iterative Refinement for Eigenvectors of a Real Symmetric Matrix](https://arxiv.org/abs/2602.19090)
*Takeshi Terao,Katsuhisa Ozaki*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we discuss numerical methods for the eigenvalue decomposition of real symmetric matrices. While many existing methods can compute approximate eigenpairs with sufficiently small backward errors, the magnitude of the resulting forward errors is often unknown. Consequently, when high-precision numerical solutions are required, the computational cost tends to increase significantly because backward errors must be reduced to an excessive degree. To address this issue, we propose an efficient approximation algorithm that aims to achieve a prescribed forward error, together with a high-accuracy numerical algorithm based on the Ozaki scheme -- an emulation technique for matrix multiplication -- adapted to this problem. Since the proposed method is not primarily focused on reducing backward errors, the computational cost can be significantly reduced. Finally, we present numerical experiments to evaluate the efficiency of the proposed method.

</details>


### [50] [A median-filter-based framework for interface optimal design problems](https://arxiv.org/abs/2602.19155)
*Sihao Cheng,Ziming Shao,Dong Wang*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a robust and efficient numerical framework based on a median filter scheme for solving a broad class of interface-related optimization problems, from image segmentation to topology optimization. A key innovation of our work is the extension of the binary scheme into a continuous level-set scheme via a weighted quantile interpretation. Unlike traditional binary iterative convolution-thresholding method (ICTM), this continuous median filter scheme effectively overcomes the pinning effect caused by spatial discretization, achieving accurate interface evolution even with small time steps. We also provide a rigorous theoretical analysis, proving the unconditional energy stability of the iterative scheme. Furthermore, we prove that for a wide class of data fidelity terms, the convex relaxation inherently enforces a binary solution, justifying the effectiveness of the method without explicit penalization. Numerical experiments on the Chan--Vese model, the local intensity fitting (LIF) model, and topology optimization in Stokes flow demonstrate that the proposed efficient continuous framework effectively eliminates the pinning effect, guarantees unconditional energy stability, and accurately converges to binary solutions.

</details>


### [51] [Parametric charge-conservative mixed finite element method for 3D incompressible inductionless MHD equations on curved domains](https://arxiv.org/abs/2602.19375)
*Xue Jiang,Lei Li,Lingxiao Li*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper develops a charge-conservative mixed finite element method with optimal convergence rates for the stationary incompressible inductionless MHD equations on three-dimensional curved domains. The discretization employs the isoparametric Taylor-Hood elements with grad-div stabilization for the velocity-pressure pair, and parametric Brezzi-Douglas-Marini elements for the current density. Utilizing the Piola's transformation, the discrete current density is exactly divergence-free. By employing suitable extensions and projections, optimal a priori error estimates are derived in both the energy norm and the $L^2$-norm. Numerical experiments are presented to confirm the theoretical results.

</details>


### [52] [Dekker's floating point number system and compensated summation algorithms](https://arxiv.org/abs/2602.19452)
*Longfei Gao,Frimpong Baidoo*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The recent hardware trend towards reduced precision computing has reignited the interest in numerical techniques that can be used to enhance the accuracy of floating point operations beyond what is natively supported for basic arithmetic operations on the hardware. In this work, we study the behavior of various compensated summation techniques, which can be used to enhance the accuracy for the summation operation, particularly in situations when the addends are not known a priori. Complete descriptions of the error behavior are provided for these techniques. In particular, the relationship between the intermediate results at two consecutive summing steps is provided, which is used to identify the operation that limits accuracy and guide the design of more nuanced techniques. The analysis relies on the work of Dekker [Numerische Mathematik, 1971], which uses a special floating point number system that does not require uniqueness in the number representation. Despite this seemingly strange attribute, Dekker's system is very convenient for the analysis here and allows general statements to be expressed succinctly compared to a number system that requires uniqueness. To prepare the foundation for discussion, we start by giving a thorough exhibition of Dekker's number system and supply the details that were omitted in Dekker [Numerische Mathematik, 1971]. Numerical examples are designed to explain the inner workings of these compensated summation techniques, illustrate their efficacy, and empirically verify the analytical results derived. Discussions are also given on application scenarios where these techniques can be beneficial.

</details>


### [53] [Optimal Error Estimates of a new Multiphysic Finite Element Method for Nonlinear Poroelasticity model with Hencky-Mises Stress Tensor](https://arxiv.org/abs/2602.19457)
*Yanan He,Zhihao Ge*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we develop a new multiphysics finite element method for a nonlinear poroelastic model with Hencky-Mises stress tensor. By introducing some new notations, we reformulate the original model into a fluid-fluid coupling problem, which is viewed as a generalized nonlinear Stokes sub-problem combined with a reaction-diffusion sub-problem. Then, we establish the existence and uniqueness of the weak solution for the reformulated problem, and propose a stable, fully discrete multiphysics finite element method which employs Lagrangian finite element pairs for spatial discretization and a backward Euler scheme for temporal discretization. By ensuring the parameters $κ_1$ and $κ_3$ remain bounded and non-zero even as $λ$ tends to infinity, the proposed method maintains stability for a wide range of Lagrangian element pairs. Based on the continuity and monotonicity of the nonlinear term $\mathcal{N}(\varepsilon(\mathbf{u}_h^{n}))$, we give the stability analysis and derive optimal error estimates for the displacement vector $\mathbf{u}$ and the pressure $p$ in both $L^2$-norm and $H^1$-norm. In particular, the $L^2$-norm error estimate for the displacement $\mathbf{u}$, which was not present in previous literature, is established here through an auxiliary problem and a Poincar$\acute{e}$ inequality. Also, we present numerical tests to verify the theoretical analysis, and the results confirm the optimal convergence rates. Finally, we draw conclusions to summarize the work.

</details>


### [54] [Extreme $L_p$ discrepancy, numerical integration and the curse of dimensionality](https://arxiv.org/abs/2602.19760)
*Erich Novak,Friedrich Pillichshammer*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The classical notion of extreme $L_p$ discrepancy is a quantitative measure for the irregularity of distribution of finite point sets in the $d$-dimensinal unit cube. In this paper we find a dual integration problem whose worst-case error is exactly the extreme $L_p$ discrepancy of the underlying integration nodes. Studying this integration problem we show that the extreme $L_p$ discrepancy suffers from the curse of dimensionality for all $p \in (1,\infty)$. It is known that the problem is tractable for $p=\infty$; the case $p=1$ stays open.

</details>


### [55] [Optimal $L^2$-norm error estimate of multiphysics finite element method for poroelasticity model and simulating brain edema](https://arxiv.org/abs/2602.19854)
*Zhihao Ge,Yanan He,Yajie Yang*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we derive an optimal $L^2$-norm error estimate of the multiphysics finite element method for the poroelasticity model by introducing an auxiliary problem. We show some numerical tests to verify the theoretical result and apply the multiphysics finite element method to simulate the brain edema which caused by abnormal accumulation of cerebrospinal fluid in injured areas. And we investigate the effects of the key physical parameters on brain edema and observed that the permeability $K$ has the biggest influence on intracranial pressure and tissue deformation, Young's modulus $E$ and Poisson ratio $ν$ have little effect on the maximum value of intracranial pressure, but have great effect on the tissue deformation and the developing speed of brain edema.

</details>


### [56] [An new polar factor retraction on the Stiefel manifold with closed-form inverse](https://arxiv.org/abs/2602.19923)
*Rasmus Jensen,Ralf Zimmermann*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Retractions are the workhorse in Riemannian computing applications, where computational efficiency is of the essence. This work introduces a new retraction on the compact Stiefel manifold of orthogonal frames. The retraction is second-order accurate under the Euclidean metric and features a closed-form inverse that can be efficiently computed. To the best of our knowledge, this is the first Stiefel retraction with both these properties. A variety of retractions is known on the Stiefel manifold, including the Riemannian exponential map, the polar factor retraction, the QR-retraction and the Cayley retraction, but none of them features a closed-form inverse. The only Stiefel retraction with closed-form inverse that we are aware of is based on quasi-geodesics, but this one is of first order.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [57] [SKYLIGHT: A Scalable Hundred-Channel 3D Photonic In-Memory Tensor Core Architecture for Real-time AI Inference](https://arxiv.org/abs/2602.19031)
*Meng Zhang,Ziang Yin,Nicholas Gangi,Alexander Chen,Brett Bamfo,Tianle Xu,Jiaqi Gu,Zhaoran Rena Huang*

Main category: cs.ET

TL;DR: SKYLIGHT是一种可扩展的3D光子存内张量核心架构，用于实时AI推理，兼具高能效与支持片上学习能力，展现出在大规模光子AI加速器中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统电子计算难以满足AI日益增长的算力需求，现有光子计算架构在可扩展性和可靠性方面存在瓶颈，亟需一种高效、可扩展且支持学习的光子AI加速方案。

Method: 提出SKYLIGHT架构，通过3D堆叠实现光子存内计算，采用低损耗Si/SiN交叉开关拓扑、非微环谐振器的波分复用技术、多端口光电探测器的层次化信号累加，以及基于相变材料的光学编程权重，并支持原位权重更新与局部学习；利用SimPhony进行系统级建模与评估。

Result: 单个144×256 SKYLIGHT核心可在单个光刻区域内实现，提供342.1 TOPS算力和23.7 TOPS/W能效，ResNet-50推理达1212 FPS，每图耗能27 mJ，端到端能效为84.17 FPS/W，较NVIDIA RTX PRO 6000 Blackwell GPU提升1.61倍；在四种典型机器学习任务中表现出对硬件非理想因素的鲁棒性。

Conclusion: SKYLIGHT通过协同设计光子架构与3D集成，实现了高性能、高能效、可扩展且支持片上学习的光子AI推理，结合噪声感知训练可保持高精度，是迈向大规模实用化光子AI加速器的可行方案。

Abstract: The growing computational demands of artificial intelligence (AI) are challenging conventional electronics, making photonic computing a promising alternative. However, existing photonic architectures face fundamental scalability and reliability barriers. This paper introduces SKYLIGHT, a scalable 3D photonic in-memory tensor core architecture designed for real-time AI inference. By co-designing its topology, wavelength routing, accumulation, and programming in a 3D stack, SKYLIGHT overcomes key limitations. Its innovations include a low-loss 3D Si/SiN crossbar topology, a thermally robust non-micro-ring resonator (MRR)-based wavelength-division multiplexing (WDM) component, a hierarchical signal accumulation using a multi-port photodetector (PD), and optically programmed non-volatile phase-change material (PCM) weights. Importantly, SKYLIGHT enables in-situ weight updates that support label-free, layer-local learning (e.g., forward-forward local updates) in addition to inference. Using SimPhony for system-level modeling, we show that a single 144 x 256 SKYLIGHT core is feasible within a single reticle and delivers 342.1 TOPS at 23.7 TOPS/W, enabling ResNet-50 inference at 1212 FPS with 27 mJ per image, and achieves 84.17 FPS/W end-to-end (1.61 x higher than an NVIDIA RTX PRO 6000 Blackwell GPU) under the same workload in real-time measurements. System-level evaluations on four representative machine learning tasks, including unsupervised local self-learning, demonstrate SKYLIGHT's robustness to realistic hardware non-idealities (low-bit quantization and signal-proportional analog noise capturing modulation, PCM programming, and readout variations). With noise-aware training, SKYLIGHT maintains high task accuracy, validating its potential as a comprehensive solution for energy-efficient, large-scale photonic AI accelerators.

</details>


### [58] [All Cities are Equal: A Unified Human Mobility Generation Model Enabled by LLMs](https://arxiv.org/abs/2602.19694)
*Bo Liu,Tong Li,Zhu Xiao,Ruihui Li,Geyong Min,Zhuo Tang,Kenli Li*

Main category: cs.ET

TL;DR: 本文提出了一种名为UniMob的统一人类移动性生成模型，能够在数据稀缺的城市中有效生成高质量的人类移动数据，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在数据丰富的城市表现良好，但在数据资源有限的城市效果显著下降，因此需要一种不依赖城市规模和数据资源的通用解决方案。

Method: UniMob包含三个主要组件：基于大语言模型（LLM）的旅行规划器、统一的空间嵌入模块和基于扩散机制的移动性生成器，分别用于生成语义丰富的出行计划、将不同城市的空间区域映射到共享表示空间，并建模时空移动特征。

Result: 在涵盖五个城市的两个真实数据集上进行实验，UniMob在多个指标上超越现有最先进方法超过30%，并在零样本和少样本场景下表现出强鲁棒性，同时具备隐私保护能力和下游任务适用性。

Conclusion: UniMob实现了跨城市的统一人类移动性建模，解决了数据稀缺城市中的生成难题，推动了智能城市系统在不同发展水平城市中的公平应用。

Abstract: Synthetic human mobility generation is gaining traction as an ethical and practical approach to supporting the data needs of intelligent urban systems. Existing methods perform well primarily in data-rich cities, while their effectiveness declines significantly in cities with limited data resources. However, the ability to generate reliable human mobility data should not depend on a city's size or available resources, all cities deserve equal consideration. To address this open issue, we propose UniMob, a unified human mobility generation model across cities. UniMob is composed of three main components: an LLM-powered travel planner that derives high-level, temporally-aware, and semantically meaningful travel plans; a unified spatial embedding module that projects the spatial regions of various cities into a shared representation space; and a diffusion-based mobility generator that captures the joint spatiotemporal characteristics of human movement, guided by the derived travel plans. We evaluate UniMob extensively using two real-world datasets covering five cities. Comprehensive experiments show that UniMob significantly outperforms state-of-the-art baselines, achieving improvements of over 30\% across multiple evaluation metrics. Further analysis demonstrates UniMob's robustness in both zero- and few-shot scenarios, underlines the importance of LLM guidance, verifies its privacy-preserving nature, and showcases its applicability for downstream tasks.

</details>


### [59] [CQ-CiM: Hardware-Aware Embedding Shaping for Robust CiM-Based Retrieval](https://arxiv.org/abs/2602.20083)
*Xinzhao Li,Alptekin Vardar,Franz Müller,Navya Goli,Umamaheswara Tida,Kai Ni,X. Sharon Hu,Thomas Kämpfe,Ruiyang Qin*

Main category: cs.ET

TL;DR: 本文提出了CQ-CiM，一种统一的、硬件感知的数据整形框架，通过联合学习压缩与量化，生成适用于多种存内计算（CiM）设计的低比特嵌入表示，以解决检索增强生成（RAG）在边缘设备部署中的精度与维度不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 由于高精度、高维嵌入与CiM低精度、低维度阵列之间的“表示差距”，以及不同CiM实现的多样性，导致RAG难以有效利用CiM架构，现有方法单独处理维度和精度转换，损害数据保真度，限制了CiM的应用。

Method: 提出CQ-CiM框架，联合优化压缩与量化过程，针对不同的CiM硬件设计（如SRAM、ReRAM、FeFET）生成兼容的低比特嵌入，并在训练中考虑硬件约束以提升实际适配性。

Result: CQ-CiM首次实现了面向多种CiM架构的统一数据整形，显著提升了数据保真度和系统效率，明确了硬件失效来源，增强了CiM在RAG应用中的可行性。

Conclusion: CQ-CiM有效弥合了RAG与CiM之间的表示差距，为在边缘设备上高效部署RAG提供了可行路径，并推动了CiM技术在实际AI应用中的落地。

Abstract: Deploying Retrieval-Augmented Generation (RAG) on edge devices is in high demand, but is hindered by the latency of massive data movement and computation on traditional architectures. Compute-in-Memory (CiM) architectures address this bottleneck by performing vector search directly within their crossbar structure. However, CiM's adoption for RAG is limited by a fundamental ``representation gap,'' as high-precision, high-dimension embeddings are incompatible with CiM's low-precision, low-dimension array constraints. This gap is compounded by the diversity of CiM implementations (e.g., SRAM, ReRAM, FeFET), each with unique designs (e.g., 2-bit cells, 512x512 arrays). Consequently, RAG data must be naively reshaped to fit each target implementation. Current data shaping methods handle dimension and precision disjointly, which degrades data fidelity. This not only negates the advantages of CiM for RAG but also confuses hardware designers, making it unclear if a failure is due to the circuit design or the degraded input data. As a result, CiM adoption remains limited. In this paper, we introduce CQ-CiM, a unified, hardware-aware data shaping framework that jointly learns Compression and Quantization to produce CiM-compatible low-bit embeddings for diverse CiM designs. To the best of our knowledge, this is the first work to shape data for comprehensive CiM usage on RAG.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [60] [A Selection Premium Decomposition for the Expected Maximum of Random Walks](https://arxiv.org/abs/2602.19481)
*Victor H. de la Pena,Fangyuan Lin,Victor K. de la Pena*

Main category: math.ST

TL;DR: 本文研究了在相同验证集上评估K个模型时，由于选择导致的赢家表现高估问题，并提出了一个分解公式来分析这种偏差的来源和性质。


<details>
  <summary>Details</summary>
Motivation: 当多个模型在同一验证集上进行比较时，选出的最佳模型的表现往往会因选择而产生向上偏倚，本文旨在揭示并量化这一偏差的机制。

Method: 通过引入选择溢价函数φ_K(u)，利用条件期望和望远镜和的方法推导出最大期望得分的分解公式，并从五个方向展开理论分析。

Result: 得到了选择偏差的精确数学表达式，扩展到停时情形，给出了非同质均值下的诅咒分解，并发现了一个普适的偏差集中规律：前α比例的观测会产生√α比例的总偏差。

Conclusion: 选择偏差本质上源于模型间的比较与筛选过程，即使所有模型真实性能相同也会出现高估，且偏差具有可量化的结构特征。

Abstract: When $K$ models are evaluated on the same validation set of size $n$, the selected winner's apparent performance is biased upward. Suppose $K$ models are evaluated on a shared sequence of i.i.d. observations $X_1,\dots, X_n$, where model $k$ achieves response $f_k(X_i)$ with mean $μ_k = \mathbb E[f_k(X)]$. Writing $Y_{i,k} = f_k(X_i)-μ_k$ for the centered increment and $S_{n,k} = \sum_{i=1}^n Y_{i,k}$ for the centered cumulative score, the expected maximum satisfies $0\le\mathbb E\bigl[\max_k S_{n,k}\bigr] = \sum_{i=1}^n \mathbb E\bigl[\varphi_K(S_{i-1})\bigr]$ where $\varphi_K(u) = \mathbb{E}\bigl[\max_k(u_k + Y_k)\bigr] - \max_k u_k$, $u\in \mathbb R^K$, is the selection premium function. This formula corresponds to the null hypothesis case (all models are equal in the sense that they have the same mean), which clarifies that the bias arises from selection. While this decomposition follows from elementary conditioning and telescoping, we develop the analytical consequences in five directions. (i) structural properties of $\varphi_K$; (ii) extension to stopping times, recovering Wald's equation at $K=1$; (iii) a winner's curse decomposition for heterogeneous means; (iv) a universal bias concentration law showing that the first $α$-fraction of observations generates a $\sqrtα$-fraction of total bias.

</details>


### [61] [On Expectation Propagation and the Probabilistic Editor in some simple mixture problems](https://arxiv.org/abs/2602.19709)
*Nils Lid Hjort,Mike Titterington*

Main category: math.ST

TL;DR: 本文探讨了在混合模型中使用期望传播及其变体方法，能够产生渐近具有正确方差的近似后验分布，从而提供可靠的参数区间估计。


<details>
  <summary>Details</summary>
Motivation: 由于精确贝叶斯分析在混合问题中通常不可行，因此需要发展近似方法来获得可靠的参数估计。

Method: 采用期望传播（Expectation Propagation）及其变体方法对混合模型进行近似贝叶斯分析，并研究其渐近性质。

Result: 在某些混合问题中，期望传播方法产生的近似后验分布在渐近意义下具有正确的方差。

Conclusion: 期望传播及其变体方法在特定混合问题中能提供比变分贝叶斯更可靠的区间估计结果。

Abstract: As for other latent-variable problems, exact Bayesian analysis is typically not practicable for mixture problems and approximate methods have been developed. Variational Bayes tends to produce approximate posterior distributions for parameters that are too tightly concentrated in having variances that are too small. The paper identifies a few mixture problems in which Expectation Propagation and variations thereof lead to approximate posterior distributions that asymptotically exhibit `correct' variances and therefore stand to provide reliable interval estimates for the unknown parameter or parameters.

</details>


### [62] [From Asymptotic to Finite-Sample Minimax Robust Hypothesis Testing](https://arxiv.org/abs/2602.19803)
*Gökhan Gül*

Main category: math.ST

TL;DR: 本文建立了有限样本与渐近最小最大稳健假设检验在分布不确定性下的形式联系，证明了当存在有限样本最小最大稳健检验时，其与相应渐近最小最大问题的解一致。


<details>
  <summary>Details</summary>
Motivation: 为了在分布不确定的情况下实现稳健的假设检验，并避免依赖启发式方法构造检验统计量。

Method: 通过分析总变差距离和带状模型作为不确定性类的代表，推导出最不利分布及相应的稳健似然比函数的参数形式。

Result: 得出在总变差情形下允许不等鲁棒参数的新推导结果，并解释和系统化了先前启发式设计；通过模拟验证理论结果。

Conclusion: 该理论使得可以通过渐近理论解析地推导有限样本最小最大稳健检验，而无需依赖启发式构造。

Abstract: This paper establishes a formal connection between finite-sample and asymptotically minimax robust hypothesis testing under distributional uncertainty. It is shown that, whenever a finite-sample minimax robust test exists, it coincides with the solution of the corresponding asymptotic minimax problem. This result enables the analytical derivation of finite-sample minimax robust tests using asymptotic theory, bypassing the need for heuristic constructions. The total variation distance and band model are examined as representative uncertainty classes. For each, the least favorable distributions and corresponding robust likelihood ratio functions are derived in parametric form. In the total variation case, the new derivation generalizes earlier results by allowing unequal robustness parameters. The theory also explains and systematizes previously heuristic designs. Simulations are provided to illustrate the theoretical results.

</details>


### [63] [Addressing parity blindness of data-driven Sobolev tests on the hypersphere](https://arxiv.org/abs/2602.19839)
*Marcio Reverbel*

Main category: math.ST

TL;DR: 本文研究了在（超）球面上用于检验均匀性的数据驱动Sobolev检验的渐近行为，发现其对某些相邻备择假设不敏感，并提出对检验统计量的简单修改。改进后的检验在固定备择假设下保持一致性，并在原检验失效的相邻备择下具有非平凡的渐近功效，模拟结果支持了理论发现。


<details>
  <summary>Details</summary>
Motivation: 原始的数据驱动Sobolev检验在检测某些相邻备择假设时可能失效，缺乏足够的检验功效，因此需要改进以提升其在复杂情况下的性能。

Method: 通过分析检验统计量的渐近行为，识别其在特定相邻备择下的盲区，并提出一个简单的修正形式，使其在保持原有优良性质的同时增强对这些备择的敏感性。

Result: 修正后的检验在固定备择下仍保持一致性，并在原检验失败的某些相邻备择下实现了非平凡的渐近功效。模拟实验验证了理论结果的有效性。

Conclusion: 所提出的修改显著提升了Sobolev检验在复杂情形下的适用性和稳健性，是原方法的一个有效改进。

Abstract: We study the asymptotic behavior of the data-driven Sobolev test for testing uniformity on the (hyper)sphere. We show that it can be blind to certain contiguous alternatives and propose a simple modification of the test statistic. This adapted test retains consistency under fixed alternatives and achieves non-trivial asymptotic power against contiguous alternatives for which the original test fails. Simulation results support our theoretical findings.

</details>


### [64] [Order Dependence in the Moving-Range Sigma Estimator: A Total-Variance Decomposition](https://arxiv.org/abs/2602.20007)
*Andrew T. Karl*

Main category: math.ST

TL;DR: 本文研究了个体与移动极差（I-MR）图中过程标准差的估计方法，提出通过随机排列建模来显式分析观测顺序对平均移动极差估计量的影响，并利用全方差公式分解其方差来源，提出了一个顺序不变的基线估计量。


<details>
  <summary>Details</summary>
Motivation: 由于I-MR图中常用的span-2平均移动极差估计量依赖于观测顺序，而这种顺序依赖性可能影响估计稳定性，因此需要明确建模顺序的影响并提供更稳健的基准。

Method: 将观测顺序建模为独立的均匀随机排列，应用全方差定律分解估计量的方差为顺序和数值两部分，并以所有排列的均值作为顺序不变的基准，得到基于样本Gini均差除以常数d₂的估计量。

Result: 推导出顺序不变的基准估计量为样本Gini均差除以d₂；模拟结果显示在正态独立同分布下，顺序引起的方差占比显著；两个NIST实例展示了典型顺序和强序列结构顺序相对于随机排列的行为差异。

Conclusion: 观测顺序对平均移动极差估计量有显著影响，提出的方法能有效分离顺序与数值对方差的贡献，所提出的Gini均差基准为评估实际数据顺序效应提供了有力工具。

Abstract: In Individuals and Moving Range (I-MR) charts, the process standard deviation is often estimated by the span-2 average moving range, scaled by the usual constant $d_2$. Unlike the sample standard deviation, this estimator depends on the observation order: permuting the values can change the average moving range. We make this dependence explicit by modeling the order as an independent uniformly random permutation. A direct application of the law of total variance then decomposes its variance into a component due to ordering and a component due to the realized values. Averaging over all permutations yields a simple order-invariant baseline for the moving-range estimator: the sample Gini mean difference divided by $d_2$. Simulations quantify the resulting fraction of variance attributable to ordering under i.i.d. Normal sampling, and two NIST examples illustrate a typical ordering and an ordering with strong serial structure relative to random permutations of the same values.

</details>


### [65] [Estimators of different delta coefficients based on the unbiased estimator of the expected proportions of agreements](https://arxiv.org/abs/2602.20071)
*A. Martín Andrés,M. Álvarez Hernández*

Main category: math.ST

TL;DR: 本文提出了一种新的无偏估计方法来改进Δ、α_i和S_i等参数的估计，特别是在样本量或类别数较小时表现更优，并讨论了当一个评分者为金标准时的新参数：一致性与预测性。


<details>
  <summary>Details</summary>
Motivation: 由于Cohen's kappa在边缘分布高度不平衡时表现不佳，且经典估计量存在偏差，因此需要开发更准确的估计方法以提高分类一致性的测量精度。

Method: 基于delta响应模型，推导出新的无偏估计量Δ_U、α_iU和S_iU，并计算其方差，通过模拟分析比较新旧估计量的表现。

Result: 新提出的估计量在小样本（n≤50）或少量类别（K≤3）情况下显著减少偏差，表现优于传统估计量。同时提出了在金标准存在下的新参数：conformity与predictivity。

Conclusion: 应优先使用新提出的无偏估计量Δ_U、α_iU和S_iU，尤其在n或K较小时；此外，在有金标准的情况下，可利用新参数更好地评估评分者的一致性与可靠性。

Abstract: To measure the degree of agreement between two observers that independently classify $n$ subjects within $K$ categories, it is common to use different kappa type coefficients, the most common of which is the $κ_C$ coefficient (Cohen's kappa). As $κ_C$ has some weaknesses -such as its poor performance with highly unbalanced marginal distributions-, the $Δ$ coefficient is sometimes used, based on the $delta$ response model. This model allows us to obtain other parameters like: (a) the $α_i$ contribution of each $i$ category to the value of the global agreement $Δ=\sum α_i$; and (b) the consistency $\mathcal{S}_i$ in the category $i$ (degree of agreement in the category $i$), a more appropriate parameter than the kappa value obtained by collapsing the data into the category $i$. It has recently been shown that the classic estimator $\hatκ_C$ underestimates $κ_C$, having obtained a new estimator $\hatκ_{CU}$ which is less biased. This article demonstrates that something similar happens to the known estimators $\hatΔ$, $\hatα_i$, and $\hat{\mathcal{S}}_i$ of $Δ$, $α_i$ and $\mathcal{S}_i$ (respectively), proposes new and less biased estimators $\hatΔ_U$, $\hatα_{iU}$, and $\hat{\mathcal{S}}_{iU}$, determines their variances, analyses the behaviour of all estimators, and concludes that the new estimators should be used when $n$ or $K$ are small (at least when $n\leq 50$ or $K\leq 3$). Additionally, the case where one of the raters is a gold standard is contemplated, in which situation two new parameters arise: the $conformity$ (the rater's capability to recognize a subject in the category $i$) and the $predictivity$ (the reliability of a response $i$ by the rater).

</details>


### [66] [Compound decisions and empirical Bayes via Bayesian nonparametrics](https://arxiv.org/abs/2602.20115)
*Nikolaos Ignatiadis,Sid Kankanala*

Main category: math.ST

TL;DR: 研究高斯序列复合决策问题，提出基于狄利克雷过程的贝叶斯非参数方法，在经验贝叶斯框架下实现了近最优的遗憾界，并证明其优于经典的NPMLE方法。


<details>
  <summary>Details</summary>
Motivation: 受经典非参数最大似然估计（NPMLE）精确结果的启发，探讨是否可以使用标准贝叶斯非参数先验获得类似保证。

Method: 采用基于狄利克雷过程的贝叶斯非参数方法，在经验贝叶斯和分层模型两种设定下分析其遗憾性能。

Result: 证明该贝叶斯程序可达到近最优的遗憾界；在复合决策框架和层次模型中均提供理论保证；后验均值规则是可容许的，而NPMLE插件规则是不可容许的。

Conclusion: 基于狄利克雷过程的贝叶斯非参数方法在复合决策问题中具有良好的理论性质和优越性，优于传统的NPMLE方法。

Abstract: We study the Gaussian sequence compound decision problem and analyze a Bayesian nonparametric estimator from an empirical Bayes, regret-based perspective. Motivated by sharp results for the classical nonparametric maximum likelihood estimator (NPMLE), we ask whether an analogous guarantee can be obtained using a standard Bayesian nonparametric prior. We show that a Dirichlet-process-based Bayesian procedure achieves near-optimal regret bounds. Our main results are stated in the compound decision framework, where the mean vector is treated as fixed, while we also provide parallel guarantees under a hierarchical model in which the means are drawn from a true unknown prior distribution. The posterior mean Bayes rule is, a fortiori, admissible, whereas we show that the NPMLE plug-in rule is inadmissible.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [67] [Is altermagnetism in vanadium oxychalcogenides a lost cause?](https://arxiv.org/abs/2602.18672)
*Bishal Thapa,Po-Hao Chang,Kirill Belashchenko,Igor I. Mazin*

Main category: cond-mat.str-el

TL;DR: 钒基含氧硫族化合物虽被提议为反铁磁候选材料，但研究表明除CsV2Te2O外，多数材料因弱层间耦合而呈现反铁磁序，且化学计量偏差不影响其磁基态。


<details>
  <summary>Details</summary>
Motivation: 探究钒基含氧硫族化合物是否具备保持体相反铁磁态所需的层间耦合特性。

Method: 系统研究AV2Q2O家族（A = K, Rb, Cs；Q = S, Se, Te）的磁序和层间耦合关系，并通过空穴掺杂模拟碱金属空位的影响。

Result: 发现除CsV2Te2O外，其余化合物均因较弱的层间耦合趋向于形成具有双倍磁单胞的反铁磁基态，且非化学计量比不会改变该磁基态。

Conclusion: 大多数AV2Q2O化合物并非反铁磁材料，仅CsV2Te2O例外，表明其作为反铁磁候选材料的局限性。

Abstract: Vanadium-based oxychalcogenide compounds with the inverse Lieb-lattice (ILL) structural pattern have recently been proposed as candidate altermagnets (AM). However, early studies postulated ferromagnetic interlayer coupling, a critical requirement for preserving the bulk AM state. Here we present a systematic survey of the complete AV2Q2O family (A = K, Rb, Cs; Q = S, Se, Te) in terms of their magnetic ordering and interlayer coupling. While intralayer exchange interaction favors AM ordering in a single ILL layer across the entire family, the relatively weak interlayer coupling in most cases favors Kramers-degenerate antiferromagnetic order with a doubled magnetic unit cell. This means that most stoichiometric bulk materials, including the previously proposed candidate KV2Se2O, are not altermagnetic, with CsV2Te2O being the only exception. Using hole doping to simulate alkali vacancies, we show that realistic deviations from stoichiometry do not change the magnetic ground state in these compounds.

</details>


### [68] [Precompression engineering of metal-insulator transition and magnetism in designed breathing kagome systems](https://arxiv.org/abs/2602.19147)
*Qingzhuo Duan,Hongdao Zhuge,Ying Liang,Tianxing Ma*

Main category: cond-mat.str-el

TL;DR: 本研究通过化学预压缩在Nb3XCl7（X = F, Cl, Br, I）中引入呼吸效应，诱导金属-绝缘体转变和磁性变化，结合DFT和输运理论揭示了呼吸效应对电子结构和磁基态的调控机制，并提出了可行的合成路径。


<details>
  <summary>Details</summary>
Motivation: 寻找具有可调电导率的Kagome材料以推动其在器件中的应用，但目前此类材料稀缺，限制了实际使用。

Method: 基于密度泛函理论（DFT）和玻尔兹曼输运理论，研究引入呼吸效应后的能带结构、光学吸收谱和磁性基态，并分析不同Ueff和tin/tout下的电子与磁性质。

Result: 发现增强的呼吸效应促进金属-绝缘体转变，单层Nb3Cl8和Nb3XCl7分别在Ueff=1 eV和tout/tin=0.6674时转变为莫特绝缘体；计算结果与实验在Ueff=2 eV下吻合良好。

Conclusion: 该工作建立了研究关联Kagome体系中呼吸效应的有效框架，为理解真实呼吸Kagome材料中的金属-绝缘体转变和磁性提供了重要见解，并提出多种材料的可行合成路线。

Abstract: Kagome materials featuring dispersive Dirac cones and topological flat bands exhibit unique electronic and magnetic properties. However, kagome compounds with tunable electrical conductivity remain scarce, which severely impedes their device applications. Here, based on density functional theory (DFT) and Boltzmann transport theory, we introduce the breathing effect into kagome materials $\mathrm{Nb_3XCl_7}$ (X = F, Cl, Br, I) via chemical precompression, thereby inducing a metal-insulator transition and magnetic variation. We determine that the band structures, optical absorption spectra and magnetic ground states agree well with experimental results at the effective correlation strength $U_{\text{eff}} = 2$ eV. The calculated conductivity and magnetic properties reveal that the monolayer $\mathrm{Nb_3Cl_8}$ and $\mathrm{Nb_3XCl_7}$ undergoes transitions from paramagnetic metals to Mott insulators at $U_{\text{eff}} = 1$ eV and $t_{\text{out}}/t_{\text{in}} = 0.6674$, respectively. Our detailed analysis establishes that the stronger breathing effect corresponds to enhanced chemical precompression, which reduces the region of free electron gas between intercell Nb atoms and facilitates the metal-insulator transition. Finally, we propose several viable synthesis routes for $\mathrm{Nb_3FCl_7}$, $\mathrm{Nb_3BrCl_7}$, and $\mathrm{Nb_3ICl_7}$, providing predictive guidance for experimental studies. Our study establishes a practical framework for investigating the breathing effect in correlated kagome systems and yields valuable insights into the mechanisms underlying metal-insulator transition and magnetic properties in real breathing kagome materials.

</details>


### [69] [Microscopic origin of hard-plane antiferromagnetism in the Kondo lattice Ce2Rh3Ge5](https://arxiv.org/abs/2602.19221)
*Rajesh Tripathi,Ewan Scott,D. T. Adroja,D. Das,C. Ritter,Huanzhi Hu,Michal P. Kwasigroch,Nicholas Corkill,Gheorghe Lucian Pascut,T. Masuda,S. Asai,T. Takabatake,T. Onimaru,T. Shiroka,Francis Pratt,A. M. Strydom,S. Langridge,A. Sundaresan,S. Patil*

Main category: cond-mat.str-el

TL;DR: Ce₂Rh₃Ge₅ 实现了一种罕见的平面反铁磁有序，其中部分4f磁矩离域导致RKKY相互作用压倒单离子各向异性，实现了单离子与有序态各向异性的反转。


<details>
  <summary>Details</summary>
Motivation: 探索在Ce基近藤晶格中罕见的平面反铁磁有序机制，特别是当磁矩垂直于单离子晶体电场易轴时的成因。

Method: 结合中子衍射、非弹性中子散射和磁化率测量，建立统一的微观模型，分析4f磁矩的部分离域和RKKY交换作用。

Result: 发现Ce₂Rh₃Ge₅中磁矩位于ab面内，而顺磁态下易轴沿c轴，表明单离子各向异性与有序态各向异性发生反转。

Conclusion: Ce₂Rh₃Ge₅为研究单离子各向异性、近藤屏蔽和RKKY相互作用竞争提供了基准体系，揭示了强杂化近藤晶格中实现硬平面反铁磁序的合作机制。

Abstract: Hard plane antiferromagnetic order where ordered moments lie perpendicular to the single-ion crystal electric field easy axis is rare in Ce-based Kondo lattices and is a subject of active interest. Here we show that Ce$_2$Rh$_3$Ge$_5$ realizes a hard-plane antiferromagnetic state in which partial delocalization of the local moment gives rise to an RKKY exchange that overturns the single-ion easy-axis preference. Neutron diffraction reveals moments in the $ab$ plane, while inelastic neutron scattering and susceptibility establish a magnetic easy axis along $c$ in the paramagnetic regime, highlighting a clear inversion between single-ion and ordered-state anisotropies. In this work, we establish a unified microscopic framework to consistently account for partial $4f$-moment delocalization, enhanced in-plane RKKY exchange, and the resulting hard-plane antiferromagnetic order. Ce$_2$Rh$_3$Ge$_5$ thus provides a benchmark system in which single-ion anisotropy, Kondo screening, and RKKY exchange compete on comparable energy scales, revealing a cooperative route to hard-axis ordering in strongly hybridized Kondo lattices.

</details>


### [70] [Toward the Thermodynamic Limit: Neural Operators for Non-equilibrium Dynamics of Mott Insulators](https://arxiv.org/abs/2602.19484)
*Miles Waugh,Chuwei Wang,Radu Andrei,Nusair Islam,Taylor Lee Patti,Eugene Demler,Anima Anandkumar*

Main category: cond-mat.str-el

TL;DR: 本研究利用傅里叶神经算子（FNOs）学习强关联材料在光激发下的动量分布演化，仅在小尺度系统上训练即可零样本推广至上千规模的晶格系统，显著超越传统数值模拟的限制，为研究热力学极限下的非平衡动力学提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 莫特绝缘体在强光驱动下的载流子倍增效应具有突破Shockley-Queisser极限的潜力，但研究其非平衡动力学需进入热力学极限，而传统数值方法因希尔伯特空间指数增长受限于小系统。

Method: 采用原本用于求解偏微分方程的傅里叶神经算子（FNOs），学习从噪声扰动下的基态动量分布到脉冲激发后动量分布的映射，训练基于小尺度晶格数据，实现对大尺度系统的零样本预测。

Result: 模型能在几秒内预测1024x1024晶格系统的动量分布，结果符合关键观测量的理论行为，远超当前数值模拟仅能处理约30×30晶格的限制。

Conclusion: 神经算子能够有效捕捉非局域效应并推广至极大系统，展示了其在强关联材料非平衡动力学研究中通向热力学极限的巨大潜力。

Abstract: Mott insulators exhibit complex photoexcitation dynamics under intense optical driving, with potential implications for carrier multiplication beyond the Shockley-Queisser limit. Probing these nonequilibrium processes requires access to the thermodynamic limit, where the number of lattice sites becomes arbitrarily large, but conventional solvers are constrained to small systems due to the exponential growth of the Hilbert space. Fourier Neural Operators (FNOs), originally developed for solving partial differential equations, naturally accommodate inputs of varying resolution and are capable of capturing nonlocal effects. Here, we employ FNOs to learn the mapping from noise-perturbed ground-state momentum distributions to their post-pulse counterparts across a range of interaction strengths and driving parameters. Trained only on small lattices, the model generalizes zero-shot to much larger systems, producing physically reasonable momentum distributions well beyond the reach of numerical solvers. Specifically, the model can predict momentum distribution for a 1024x1024 system within a few seconds that matches the theoretical behavior of key observables, whereas direct numerical simulations have so far been restricted to edge sizes of ~30. These results demonstrate the potential of neural operators to directly access large-scale nonequilibrium dynamics, providing a new pathway toward the thermodynamic limit in strongly correlated materials.

</details>


### [71] [Electron-electron and electron-phonon collision cross sections in CsV3Sb5](https://arxiv.org/abs/2602.19499)
*Charles Menil,Andrea Capa Salinas,Stephen D. Wilson,Benoît Fauqué,Kamran Behnia*

Main category: cond-mat.str-el

TL;DR: CsV3Sb5被确定为具有中等电子关联和强电子-声子散射的费米液体，电输运和热输运行为符合Bloch-Grüneisen模型，且低温下满足魏德曼-弗朗兹定律。


<details>
  <summary>Details</summary>
Motivation: 探索CsV3Sb5作为kagome金属中的费米液体行为及其电子关联和电子-声子相互作用特性。

Method: 通过系统研究CsV3Sb5的电输运和热输运性质，在零场和有限磁场下测量热导率，分离电子和晶格对热导的贡献，并分析电阻率的温度依赖性。

Result: 发现电阻率的T²项符合Kadowaki-Woods标度；魏德曼-弗朗兹定律在零温极限下成立，但在有限温度出现偏离；电子-声子散射的Bloch-Grüneisen模型能同时解释电导和热导行为，表明存在显著的电子-声子碰撞截面。

Conclusion: CsV3Sb5是一种具有中等电子关联和强电子-声子相互作用的费米液体，其输运性质可通过传统理论框架描述，但表现出异常大的电子-声子散射强度。

Abstract: AV3Sb5 (A=K, Rb, Cs) are kagome metals and superconductors, attracting much recent attention as nexus of multiple quantum states. Here, through a systematic study of electric and thermal transport of CsV3Sb5, we identify iy as a metallic Fermi liquid with moderate electronic correlations ans strong electron-phonon (e-ph) collision cross section. We observe contributions to the inelastic electrical resistivity, each dominating within a distinct temperature window. The prefactor of the T2 is consistent with the Kadowaki-Woods scaling for a Fermi liquid with moderate correlation. By performing thermal conductivity measurements at zero and finite magnetic field, we separate the electronic and the lattice contributions to the thermal conductivity. The Wiedemann-Franz law is is satisfied in the zero-temperature limit, while a downward deviation emerges at finite temperature due to the mismatch between the prefactors of the electrical and thermal quadratic resistivities, as reported in other metals. The Bloch-Grüneisen description of electron-phonon scattering successfully accounts for both electronic thermal and electrical transport, indicating a remarkably large e-ph collision cross section in CsV3Sb5.

</details>


### [72] [Data-Driven Bath Fitting for Hamiltonian-Diagonalization Dynamical Mean-Field Theory](https://arxiv.org/abs/2602.19637)
*Taeung Kim,Jeongmoo Lee,Ara Go*

Main category: cond-mat.str-el

TL;DR: 提出一种基于机器学习的初始化方法，用于改善哈密顿对角化DMFT中的非线性浴场拟合问题，通过核岭回归模型直接从目标杂化函数预测近最优离散浴参数，显著提升收敛速度与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在HD-DMFT中，随着浴站点数增加，传统优化方法对初值敏感且易陷入局部极小，导致自洽循环变慢或不稳定，亟需更可靠的初始化策略。

Method: 将浴场拟合重构为监督回归问题，利用核岭回归模型预测浴参数；训练数据来自层状钙钛矿类钌氧化物模型在结构形变下的紧束缚哈密顿量，并结合时间反演对称性设计特征与目标表示以保证物理一致性。

Result: 在非相互作用极限下测试表明，该方法显著降低初始拟合误差、减少共轭梯度迭代次数并增强对局部极小的鲁棒性；在Sr2RuO4的相互作用DMFT计算中也展现出更快的收敛速度，且结果与传统方法一致。

Conclusion: 所提机器学习初始化方法有效克服了HD-DMFT中浴场拟合的非凸优化难题，提升了计算效率与稳定性，并具备向复杂材料体系迁移的潜力。

Abstract: We propose a machine-learning-based initialization method to overcome the nonlinear bath-fitting bottleneck in Hamiltonian-diagonalization-based dynamical mean-field theory (HD-DMFT). In HD-DMFT, the continuous hybridization function is approximated by a finite set of bath-site energies and hybridization amplitudes, determined by minimizing a highly non-convex multivariable cost function. As the number of bath sites increases, the optimization becomes more sensitive to the initial guess and more prone to suboptimal local minima, which can slow or destabilize the DMFT self-consistency loop. We reformulate bath fitting as a supervised regression problem and train a kernel ridge regression model to predict near-optimal discrete bath parameters directly from the target hybridization function on the Matsubara axis. To ensure physical relevance and data diversity, we construct the training dataset from tight-binding Hamiltonians of layered-perovskite-like ruthenate models across systematically deformed structures, instead of relying on naive random parameter sampling, and obtain high-quality labels through fully converged conventional bath fitting. Time-reversal symmetry is explicitly incorporated in both feature and target representations to reduce effective dimensionality and enforce physical consistency. Benchmarks in the non-interacting limit show that the learned initialization systematically reduces the initial fitting error, decreases the number of conjugate-gradient iterations, and improves robustness against local minima over a wide range of bath sizes. We further demonstrate transferability to interacting DMFT calculations for $\mathrm{Sr_{2}RuO_{4}}$ solved with an adaptive-truncation impurity solver, where the ML initialization yields consistently faster convergence than a symmetry-preserving heuristic baseline while preserving the final fitted solution.

</details>


### [73] [From Quantum Chaos to a Reversed Quantum Disentangled Liquid in a Disorder-Free Spin Ladder](https://arxiv.org/abs/2602.19586)
*Hanieh Najafzadeh,Abdollah Langari*

Main category: cond-mat.str-el

TL;DR: 本文研究了一个具有非对称XY腿耦合和可调Ising横撑相互作用的自旋-1/2梯子系统，发现其在强耦合下展现出一种无序无关的非热化机制——反向量子解缠液体（reversed-QDL），其中轻粒子热化而重粒子保持局域化，并揭示了准多体局域化的微观起源。


<details>
  <summary>Details</summary>
Motivation: 探索除无序导致的多体局域化外，相互作用驱动的量子系统如何避免热化，寻找新的非遍历动力学相及其微观机制。

Method: 采用纠缠动力学、保真度 susceptiblity、绝热规范势范数、能级间距统计和本征态熵等多种诊断工具，系统分析不同横撑耦合强度Jz下的动力学行为。

Result: 发现了随Jz变化的重入型动力学相变：Jz=0时为可积行为，中等Jz时出现量子混沌，强Jz下进入稳健的非热化 regime；在强耦合极限下观察到反向QDL现象，并识别出由固定点结构支撑的局域守恒量，解释了准MBL动力学的微观基础。

Conclusion: 反向量子解缠液体是一种无需无序即可实现非遍历性的新途径，拓展了量子物质中动力学相的分类。

Abstract: The mechanisms by which isolated interacting quantum systems evade thermalization extend beyond disorder-induced many-body localization, encompassing a growing class of interaction-driven phenomena. We investigate a spin-1/2 ladder with asymmetric XY leg couplings and tunable Ising interactions on the rungs, and identify the microscopic origin of many-body localization (MBL) in this setting. Through a suite of diagnostics -including entanglement dynamics, fidelity susceptibility, adiabatic gauge potential norms, level-spacing statistics and entropy of eigenstates- we uncover a reentrant progression of dynamical regimes as the rung coupling Jz is varied: integrable behavior at Jz=0, quantum chaos at intermediate Jz, and a robust nonthermal regime at strong coupling. In the latter regime, we demonstrate the emergence of a reversed quantum disentangled liquid (reversed-QDL), where the light species thermalizes while the heavy species remains localized. The strong-coupling limit further yields emergent local integrals of motion anchored in a fixed-point structure, providing a microscopic origin of the observed quasi-MBL dynamics. These results establish reversed-QDL as a distinct, disorder-free route to nonergodicity and broaden the classification of dynamical phases in quantum matter.

</details>


### [74] [Floquet product mode and eigenphase order](https://arxiv.org/abs/2602.19795)
*Felix Möckel,Harald Schmid,Felix von Oppen*

Main category: cond-mat.str-el

TL;DR: 研究Floquet量子伊辛模型在破坏可积性扰动下的鲁棒性，发现复合边缘模式比单个马约拉纳边缘模式更稳定，并通过有限链中的本征相位序和四重态谱统计解释其稳定性机制。


<details>
  <summary>Details</summary>
Motivation: 探讨在破坏可积性的扰动下，Floquet量子伊辛模型中Majorana零模和π模所构成的复合边缘模式为何表现出更强的鲁棒性。

Method: 基于开放边界条件下有限链的本征相位序，分析Floquet本征态形成的四重态结构，并研究破坏可积性扰动对这些四重态及边界自旋关联函数的影响。

Result: 发现在可积极限下所有Floquet本征态形成四重态；复合边缘模式的强鲁棒性及其边界自旋关联函数的行为可通过四重态的谱统计来理解。

Conclusion: Floquet产品模式的高鲁棒性源于其与本征相位序相关的四重态结构，该结构在破坏可积性扰动下仍能保持较好稳定性。

Abstract: We study the robustness of the Floquet quantum Ising model against integrability-breaking perturbations, focusing on the phase hosting both Majorana zero and $π$ modes. A recent work [Phys. Rev. B 110, 075117, (2024)] observed that the Floquet product mode, a composite edge mode constructed from both Majorana operators, is considerably more robust than the individual Majorana edge modes. We analyze these strong modes from the point of view of the eigenphase order present in finite chains with open boundary conditions. As a result of the Majorana modes, all Floquet eigenstates come in quadruplets in the integrable limit. We show that the robustness of the various modes as well as the behavior of the boundary spin correlation functions can be understood in terms of the spectral statistics of these quadruplets in the presence of integrability-breaking perturbations.

</details>


### [75] [Anisotropic magnons in a layered honeycomb ferromagnet](https://arxiv.org/abs/2602.19935)
*Travis J. Williams,Douglas L. Abernathy,Mark D. Lumsden,Jiaqiang Yan,Andrew D. Christianson*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent experimental and theoretical studies have suggested a possible Dirac magnon gap in the two-dimensional ferromagnetic semiconductor CrSiTe$_3$. Detailed neutron scattering measurements were performed to shed light on the existence of the magnon gap, and suggest that the gap is very small or non-existent, with previous measurements being complicated by experimental factors. During these measurements, it was found that the out-of-plane couplings could explain the usual property of the increase in the magnetic transition temperature when CrSiTe$_3$ is exfoliated to monolayers. Furthermore, the material was shown to have anisotropic magnons along the out-of-plane direction, through the proposed Dirac point. We speculate that this is due to an exchange anisotropy, though Kitaev-like interactions alone cannot explain the spectra.

</details>


### [76] [Non Fermi liquid signatures across strain engineered metal-insulator transition in line-graph lattices](https://arxiv.org/abs/2602.19972)
*Shashikant Singh Kunwar,Madhuparna Karmakar*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Controlling the properties and thus the functionalities of correlated electron systems via externally tunable perturbations has always remained a cherished goal in quantum condensed matter physics. Recently, straintronics has proved to be one such external control which can dictate the quantum phases and transitions in materials via the reconstruction of their electronic band structure. A particularly intriguing scenario arises in the context of flat band line-graph lattices wherein straintronics is found to bring forth non trivial phase transitions. This paper reports the phase transitions and thermal scales across the Lieb/Kagome interconversion in the electronic interaction-strain-temperature space. Based on the thermodynamic, spectroscopic and transport signatures across the strain tuned interconversion of these line-graph lattices we have mapped out the low temperature phases and thermal transition scales, numerically determined using non perturbative calculations. While at the low temperatures, interaction-strain plane is spanned by magnetically correlated insulators, flat band induced weak transiently localized insulators and non Fermi liquid metallic phases, thermal fluctuations aid in to stabilize coexistent magnetic correlations. Apart from quantifying the magnetic transition scales in this system our results on the spectroscopic and transport signatures distill the strain tuned metal-insulator transition and crossover scales which exhibit variable transport scaling exponents.

</details>


### [77] [Coexisting magnetic, charge, and superconducting orders in the two-dimensional Hubbard model](https://arxiv.org/abs/2602.20073)
*Robin Scholle,Pietro M. Bonetti,Walter Metzner,Demetrio Vilardi*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We perform a renormalized mean-field study of the two-dimensional repulsive Hubbard model, focusing on the intricate interplay and possible coexistence of magnetic, charge, and superconducting orders. We improve on conventional mean-field theory by utilizing a renormalization group framework that captures high-energy fluctuations. This method generates effective magnetic and $d$-wave pairing interactions, and allows for an unbiased exploration of coexisting phases at weak and moderate interaction strengths. Unrestricted mean-field calculations of the effective Hamiltonian on large finite lattices are combined with analyses in the thermodynamic limit, revealing a rich phase diagram with extensive regions of coexisting orders. We find that $d$-wave superconductivity coexists with Néel order on the electron-doped side. On the hole-doped side, superconductivity is found to coexist with spiral or stripe magnetic orders. Within the stripe ordered region, the superconducting order parameter is spatially modulated, with a period that follows the charge modulation of the stripes. Below van Hove filling, pairing provides the primary energy gain, while the stripe order yields only a small, and hence fragile, additional energy lowering.

</details>


<div id='physics.hist-ph'></div>

# physics.hist-ph [[Back]](#toc)

### [78] [Dark Matter in Zwicky's Cosmology: Towards an Epistemological Reconstruction](https://arxiv.org/abs/2602.18475)
*Simon Beyne,Christian Marinoni*

Main category: physics.hist-ph

TL;DR: 本文重新解读了Fritz Zwicky 1933年关于星系团速度弥散的维里分析论文，指出暗物质并非源于简单的天文观测，而是受到宇宙学动机驱动，并在当时科学讨论中已有潜在基础。作者认为Zwicky的结果并非意外，其质量差异恰与其预期相符，因此暗物质不应被视为拯救牛顿理论的特设假设，而可能是支持广义相对论的早期宇宙学证据之一。


<details>
  <summary>Details</summary>
Motivation: 挑战传统叙事，即暗物质是为挽救牛顿引力理论而提出的特设假设，并澄清Zwicky原始工作中被误解的科学动机与背景。

Method: 通过对Zwicky 1933年论文进行语境化重读，结合科学史与哲学分析，考察其理论动机、观测结果及其所处的科学争论背景。

Result: 发现Zwicky对暗物质的预测与其宇宙学预期一致，质量差异并不令人惊讶；暗物质在其研究中具有隐含的核心地位，而非事后补充。

Conclusion: 暗物质可能不是为了挽救牛顿力学而提出的特设假设，而是广义相对论框架下早期宇宙学思考的产物，这一观点对科学哲学中关于特设假设的认识论讨论具有重要意义。

Abstract: A new contextualised reading of Fritz Zwicky's 1933 article ''The redshift of extragalactic nebulae'' about the virial analysis of the velocity dispersion of galaxies in the Coma cluster leads to a reconsideration of the traditional discourse on the introduction of dark matter. We argue that this component of matter was not only already on the stage of the scientific debates of the time, but also, in a more concealed form, played a central role in Zwicky's epistemic context. We thus reject the narration that dark matter is the result of a ``na{ï}ve'' astrophysical observation and emphasise the cosmological motivations that prompted Zwicky to presciently search for it. Moreover, with regard to its abundance, we argue that the discrepancy between the observed amount of luminous matter in the Coma Cluster and Zwicky's higher mass estimate derived from virial analysis was not, in fact, astonishing. What Zwicky described as a surprising excess of dark matter was of precisely the order of magnitude he had set out to identify. Consequently, we challenge the widespread view that dark matter was merely an ad hoc hypothesis introduced to rescue Newtonian theory. Instead, we suggest it may represent one of the earliest cosmological indications supporting a new emerging theory of gravitation: General Relativity. This reinterpretation contributes to ongoing debates in the philosophy of science concerning the epistemic status of ad hoc hypotheses.

</details>


### [79] [Marking Noon: The Time Balls and Time Flaps of the Netherlands](https://arxiv.org/abs/2602.19364)
*Richard de Grijs*

Main category: physics.hist-ph

TL;DR: 荷兰在19世纪迅速采用并改进了英国的时间球技术，用于航海计时校准，得益于本土传统和制度支持，并成为科学现代化的象征，后因电报和无线电的兴起而衰落。


<details>
  <summary>Details</summary>
Motivation: 探讨荷兰为何能迅速采纳并发展时间球系统，以及该系统在航海、社会和科技现代化中的作用。

Method: 通过历史分析，结合荷兰本土的时间信号传统、海军与科研机构的支持，以及天文学家弗雷德里克·凯泽的技术改进，研究时间球系统的引入与发展。

Result: 揭示了荷兰时间球系统的成功源于本土实践与制度支持的结合，特别是凯泽推动的旋转挡板技术提升了信号的精确性，同时时间信号也成为国家现代性和帝国影响力的象征。

Conclusion: 荷兰对时间球的采纳不仅是技术引进，更是本土传统与科学制度协同发展的结果，反映了19世纪荷兰在航海计时领域的现代化进程。

Abstract: In the nineteenth century, the Netherlands quickly adopted the time ball -- a British innovation for maritime chronometer calibration -- in its main naval ports (Nieuwediep/Den Helder, Vlissingen, Hellevoetsluis) and commercial centres (Amsterdam, Rotterdam). A large sphere dropped from a mast at a fixed time, the device enabled ships to verify their chronometers against a standard, essential for accurate longitude determination and safe navigation. Its ready acceptance was eased by indigenous Dutch traditions. Rural communities had long used visual time signals like the sjouw on Terschelling island, a wicker ball raised on a mast to mark the lunch hour and milking time for farmers, and the lawei, a basket or sack used in the peat bogs of Friesland to regulate labourers' hours. The Dutch time-signal system was distinguished by its strong institutional backing from the country's Royal Navy, its Hydrographic Service and by professional astronomers. Among the latter, Frederik Kaiser was a pivotal figure, vehemently defending the system's accuracy and pioneering technical improvements. He successfully advocated for replacing the traditional falling ball with a system of rotating flaps, which provided a more instantaneous and reliable visual signal. Beyond their practical role, time signals became civic spectacles and symbols of Dutch scientific modernity and imperial reach. Their decline began with the electric telegraph and was finalised by wireless radio, which allowed ships to calibrate chronometers at sea.

</details>


### [80] [Dutch Colonial Time: Time Signals in Paramaribo and the Dutch Caribbean](https://arxiv.org/abs/2602.19365)
*Richard de Grijs*

Main category: physics.hist-ph

TL;DR: 19世纪荷兰在其大西洋殖民地建立了时间信号系统，以将航海与欧洲标准同步，这些系统在不同地区根据环境、财政和政治条件进行了本地化适应，最终因预算压力和新技术而衰落。


<details>
  <summary>Details</summary>
Motivation: 探讨荷兰在19世纪如何通过时间信号系统将其大西洋殖民地纳入全球航海体系，并分析这些技术基础设施在殖民地的本地化适应过程。

Method: 通过历史分析方法，研究不同殖民地（如苏里南的帕拉马里博、库拉索、阿鲁巴和圣尤斯特歇斯）使用的时间信号装置及其运作方式，比较其技术和行政差异。

Result: 揭示了殖民地时间信号系统不仅是技术设施，也是城市生活的一部分，并且是海军指挥官与殖民总督之间政治谈判的焦点；不同岛屿采用不同的系统反映了去中心化的殖民管理策略。

Conclusion: 这些时间信号系统的演变显示了殖民科学基础设施的脆弱性和协商性质，它们并非简单复制欧洲模式，而是经历了混合适应的过程。

Abstract: In the nineteenth century, the Dutch established time signals in their Atlantic colonies to synchronise maritime navigation with European standards. In Paramaribo (Suriname), a sophisticated sequence of apparatus -- including time balls, noon guns, discs and flags -- operated from 1851 until World War I. Naval officers aboard guard ships used sextants equipped with artificial horizons to determine local noon, thus integrating the colony into the global Greenwich-based cartographic system. This infrastructure was not merely technical; it became a civic ritual, with the daily noon gun structuring urban life and becoming a point of political negotiation between naval commanders and the colonial governor. In contrast, the Dutch Caribbean islands employed simpler, pragmatic systems. Curaçao used a daily time flag, a cost-effective solution suited to its climate and harbour scale, while smaller islands like Aruba and St. Eustatius relied on occasional noon guns. This diversity reflected a decentralised colonial administration that adapted technologies to local conditions and budgets. The history of these time signals reveals a process of hybrid adaptation, not simply replication of European models. They were shaped by environmental challenges, fiscal constraints and local politics, functioning simultaneously as navigational aids and civic landmarks. Their eventual decline, owing to budgetary pressures and new technologies like wireless telegraphy, underscores the fragile and negotiated nature of colonial scientific infrastructures.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [81] [Boltzmann Generators for Condensed Matter via Riemannian Flow Matching](https://arxiv.org/abs/2602.18482)
*Emil Hoffmann,Maximilian Schebek,Leon Klein,Frank Noé,Jutta Rogal*

Main category: physics.comp-ph

TL;DR: 提出了一种结合流匹配与黎曼几何的连续归一化流方法，用于凝聚态系统中的平衡分布采样，并通过Hutchinson迹估计和偏差校正实现高效准确的自由能计算。


<details>
  <summary>Details</summary>
Motivation: 传统方法在凝聚态系统中进行平衡采样和自由能估计时存在计算成本高、依赖多阶段估计等问题，而现有流匹配方法未充分考虑系统的周期性结构，限制了其在该类系统中的应用。

Method: 将系统的周期性嵌入到连续归一化流中，采用黎曼流匹配框架；利用Hutchinson迹估计降低密度估计的计算开销，并基于累积量展开引入偏差校正步骤，使随机估计适用于严格的热力学重加权。

Result: 在单原子冰系统上验证了方法的有效性，能够训练前所未有的大规模系统，并获得高精度的自由能估计，无需传统多阶段估计器。

Conclusion: 所提方法为凝聚态系统的平衡采样提供了可扩展且精确的新途径，显著提升了生成模型在物理建模中的实用性。

Abstract: Sampling equilibrium distributions is fundamental to statistical mechanics. While flow matching has emerged as scalable state-of-the-art paradigm for generative modeling, its potential for equilibrium sampling in condensed-phase systems remains largely unexplored. We address this by incorporating the periodicity inherent to these systems into continuous normalizing flows using Riemannian flow matching. The high computational cost of exact density estimation intrinsic to continuous normalizing flows is mitigated by using Hutchinson's trace estimator, utilizing a crucial bias-correction step based on cumulant expansion to render the stochastic estimates suitable for rigorous thermodynamic reweighting. Our approach is validated on monatomic ice, demonstrating the ability to train on systems of unprecedented size and obtain highly accurate free energy estimates without the need for traditional multistage estimators.

</details>


### [82] [Multiphysics Modelling of the Molten Salt Fast Reactor using NekRS and the Fission Matrix Method](https://arxiv.org/abs/2602.18626)
*Maximiliano Dalinger,Elia Merzari,Saya Lee*

Main category: physics.comp-ph

TL;DR: 本文提出了一种用于分析熔盐快堆（MSFR）的中子学-热工水力耦合计算模型，采用基于Fission Matrix方法的降阶模型以实现快速且精确的中子学模拟，并依托Cardinal平台集成NekRS与OpenMC工具进行高保真多物理场计算。


<details>
  <summary>Details</summary>
Motivation: 由于MSFR的冷却剂即为燃料，导致中子学与热工水力之间强耦合，传统独立求解难以准确分析，因此需要发展高效的多物理场耦合计算模型。

Method: 采用基于Fission Matrix（FM）方法的降阶模型求解中子学方程，利用预先通过蒙特卡洛模拟生成的数据库；结合高保真代码Cardinal（集成NekRS与OpenMC于MOOSE框架下）实现中子学与热工水力的耦合仿真。

Result: 成功构建了基于FM方法的MSFR中子学-热工水力耦合模型，能够在保持较高计算精度的同时显著提升计算效率。

Conclusion: FM方法结合预计算数据库是实现MSFR快速、准确中子学模拟的有效途径，所提出的多物理场模型为MSFR的设计与安全分析提供了高效计算工具。

Abstract: The Molten Salt Fast Reactor (MSFR) has the particularity that the coolant is also the fuel, which tightens the coupling between neutronics and thermal hydraulics as the fuel circulates through the primary system. Therefore, developing computational models to analyze the MSFR requires a multiphysics approach. In this paper, we propose developing a neutronic thermal-hydraulic computational model of the MSFR that uses a reduced-order model to solve the neutronics equations. The principal computational tool chosen for this purpose is the high-fidelity code Cardinal, a wrapping within the MOOSE framework that integrates the Computational Fluid Dynamics code NekRS and the Monte Carlo particle transport code OpenMC. However, we use the Fission Matrix (FM) Method to solve the neutronics equations instead of OpenMC. The FM method can perform fast and still accurate neutronics simulations. It relies on precalculated databases obtained through a Monte Carlo simulation.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [83] [A Criterion for Safe Overshoot in Coupled Tipping Systems](https://arxiv.org/abs/2602.19696)
*Sacha Sinet,Nathalie A. M. Delmeire,Paul D. L. Ritchie,Henk A. Dijkstra,Anna S. von der Heydt*

Main category: nlin.CD

TL;DR: 研究了在相互作用的慢快系统中，超越临界点的安全性问题，提出了适用于交互环境的类反平方律准则，并通过大西洋经向翻转环流与亚马逊雨林或格陵兰冰盖相互作用的概念模型进行了说明。


<details>
  <summary>Details</summary>
Motivation: 探讨在子系统相互作用下，有限时间内的阈值超调是否安全，扩展对气候和生态突变的理解。

Method: 推导出适用于非线性相互作用和时间导数耦合的慢快系统的安全超调判据，该判据以时间尺度分离和耦合强度显式表达。

Result: 得到了一个类似于孤立系统反平方律的安全超调准则，但适用于子系统交互情形，并在两个概念模型中得到验证。

Conclusion: 在耦合系统中，即使出现阈值超调，也可能存在安全路径，这取决于时间尺度分离和耦合强度。

Abstract: Abrupt transitions are a central concern in climate and ecological research, and may arise when critical thresholds known as tipping points are crossed. However, previous work has shown that finite-time overshoots of tipping points can be safe, and that such behavior is captured by an inverse-square-law criterion when overshoots are sufficiently small and slow. So far studied in isolated systems with external drivers, (un)safe overshoots may also emerge from interactions between subsystems. Here, we investigate safe-overshoot phenomena in unidirectionally coupled slow-fast systems featuring both nonlinear interactions and coupling through time-derivatives. Specifically, we derive a criterion for the occurrence of safe overshoots analogous to the inverse-square law for isolated systems, but adapted to interactive settings, and expressed explicitly in terms of the timescale separation and coupling strength between subsystems. We illustrate these results using two conceptual models in which the Atlantic Meridional Overturning Circulation interacts with either the Amazon rainforest or the Greenland Ice Sheet.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [84] [Synchronization of Unbalanced Dynamical Optimal Transport across Multiple Spaces](https://arxiv.org/abs/2602.18725)
*Zixuan Cang,Jingfeng Wang,Xiaoqi Wei,Yanxiang Zhao*

Main category: math.OC

TL;DR: 提出了一种新的非平衡同步最优传输框架UnSyncOT，用于在不同空间之间同步传输-反应流，适用于多模态生物系统分析。


<details>
  <summary>Details</summary>
Motivation: 许多生物系统通过异质模态被观测，需要能够在空间间耦合动力学并允许质量变化的传输模型。现有方法难以处理这种跨空间的动态同步问题。

Method: 提出了UnSyncOT框架，包括Monge型（基于几何嵌入）和Kantorovich型（基于马尔可夫核）两种形式，并证明其可约化为单空间问题；引入Hellinger-Kantorovich时间离散化和 staggered-grid 离散化方法，结合原始-对偶求解器进行高效计算。

Result: 理论分析表明UnSyncOT可归约为具有修正动能的Benamou-Brenier问题或由同步算子诱导的非局部作用；数值实验验证了该方法的收敛性、稳定性和效率，并实现了跨空间的相干动力学重建。

Conclusion: UnSyncOT为异质模态下的跨空间动力学建模提供了统一且高效的框架，兼具理论深度与计算可行性，适用于复杂生物系统的分析。

Abstract: Many biological systems are observed through heterogeneous modalities, requiring transport models that couple dynamics across spaces while allowing mass variation. To address this challenge, we introduce Unbalanced Synchronized Optimal Transport (UnSyncOT), a novel dynamical framework that synchronizes transport-reaction flows between spaces via either geometric embeddings (Monge type) or Markov kernels (Kantorovich type). For both cases we prove that UnSyncOT can be reduced to a single-space problem: the Monge model becomes a Benamou-Brenier problem with a metric-modified kinetic energy, and the Kantorovich model yields a nonlocal action induced by the synchronization operator, both of which fit within a dissipation-distance formulation. We also analyze the pure transport (Wasserstein) and pure reaction (Fisher-Rao) limits and derive structural properties. For the Kantorovich case we propose an approximate UnSyncOT by introducing a Hellinger-Kantorovich based trapezoidal time discretization of the secondary action for efficient computation. Finally we present staggered-grid discretizations and primal-dual solvers, validate the convergence, stability, and efficiency, and demonstrate coherent dynamics reconstructions across spaces.

</details>


### [85] [Multiunit I.I.D. Prophet Inequalities via Extreme Value Asymptotics](https://arxiv.org/abs/2602.18756)
*Jieming Kong,Karthyek Murthy*

Main category: math.OC

TL;DR: 研究了独立同分布的k-选择先知不等式问题，分析了在奖励分布极值指数和k下的最优福利比率，并探讨了确定性等价启发式算法的性能表现及其对流体缩放假设的敏感性。


<details>
  <summary>Details</summary>
Motivation: 旨在理解在线资源分配中可达到的性能极限，并改进现有静态阈值算法的保证，以更好地指导在线市场中的定价机制设计。

Method: 通过渐近分析方法，在n趋于无穷时刻画最优动态规划的性能比，同时分析确定性等价（CE）启发式算法在不同条件下的表现，尤其是其相对于最优解的遗憾增长情况。

Result: 得到了最优性能比至少为1−logk/(8k)[1+ε]，优于静态阈值算法的1−1/√(2πk)；CE启发式在k增大时能匹配最优动态规划的主项，但在n/k→∞时遗憾可能发散。

Conclusion: 揭示了CE启发式算法性能对流体缩放假设的敏感性，强调在评估在线算法时需谨慎对待该假设，同时提供了更优的理论性能界限。

Abstract: We study the i.i.d. $k$-selection prophet inequality problem, where a decision-maker sequentially observes $n$ independent nonnegative rewards and may accept at most $k$ of them without knowledge of future realizations. The objective is to maximize the expected total reward relative to that of a prophet who observes all rewards in advance. This problem captures the performance limits achievable in online resource allocation and underlies posted-price mechanisms in online marketplaces. We characterize the optimal welfare achievable relative to the prophet in terms of $k$ and the extreme value index of the reward distribution, in the asymptotic regime where the number of offers $n$ grows large. This optimal performance ratio turns out to be at least $1-\frac{\log k}{8k}[1+ε]$ for any $ε> 0$ and sufficiently large $k$, improving upon the respective, tight $1 - \frac{1}{\sqrt{2πk}}$ guarantee of static-threshold algorithms. We additionally analyze the certainty-equivalent (CE) heuristic, a widely used online allocation algorithm known to yield optimal regret growth in $n$ when evaluated under the fluid scaling assumption. Even in the absence of the fluid scaling, the CE heuristics's performance improves with $k$ to eventually match the leading order terms of the optimal dynamic program's performance ratio. A finer analysis nevertheless reveals that regret can be divergent and large relative to the optimal dynamic program when $n/k \to \infty$. This highlights the sensitivity in viewing the CE heuristic's performance under the commonly adopted, though subjective, fluid scaling assumption.

</details>


### [86] [Variational Sufficiency and Solution Stability in Optimization](https://arxiv.org/abs/2602.18796)
*Matúš Benko,R. Tyrrell Rockafellar*

Main category: math.OC

TL;DR: 本文探讨了变分稳定性与强变分充分性之间的关系，后者是局部最优的一个新近提出的充分条件。


<details>
  <summary>Details</summary>
Motivation: 研究变分稳定性对于验证实际应用中模型的鲁棒性以及算法设计中的结果可信度具有重要意义。

Method: 通过理论分析，建立了变分稳定性与强变分充分性之间的联系。

Result: 提出了关于变分稳定性如何与强变分充分性相关的基础性结果。

Conclusion: 强变分充分性为理解优化问题在参数变化下的局部良好行为提供了新的视角。

Abstract: Variational stability, in the sense of local good behavior of optimal values and solutions in problems of optimization under shifts in parameters, is important not only for validating model robustness in practical applications but also for confidence of outcomes in the design of solution algorithms. Fundamental results are presented here about how such stability relates to a recently developed sufficient condition for local optimality called strong variational sufficiency.

</details>


### [87] [Limits of Convergence-Rate Control for Open-Weight Safety](https://arxiv.org/abs/2602.18868)
*Domenic Rosati,Xijie Zeng,Hong Huang,Sebastian Dionicio,Subhabrata Majumdar,Frank Rudzicz,Hassan Sajjad*

Main category: math.OC

TL;DR: 提出了一种通过谱重参数化控制收敛速度的新方法SpecDef，用于防止开源基础模型被恶意微调，但在对抗性设置中存在理论局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的训练抵抗方法无法为防止开源基础模型被恶意微调提供理论保证，因此需要一种具有理论支持的新方法。

Method: 将优化干预视为收敛速率控制问题，利用模型权重的谱结构设计了SpecDef算法，以减缓一阶和二阶梯度优化的收敛速度。

Result: SpecDef在非对抗环境下能有效且可证明地减缓优化收敛；但在对抗环境下，拥有足够知识的攻击者可通过线性增加模型大小恢复快速收敛，揭示了此类方法的根本限制。

Conclusion: 仅控制收敛速率的方法存在固有局限，未来需探索不等价于收敛控制的新防御机制。

Abstract: Open-weight foundation models can be fine-tuned for harmful purposes after release, yet no existing training resistance methods provide theoretical guarantees. Treating these interventions as convergence-rate control problems allows us to connect optimization speed to the spectral structure of model weights. We leverage this insight to develop a novel understanding of convergence rate control through spectral reparameterization and derive an algorithm, SpecDef, that can both provably and empirically slow first- and second-order optimization in non-adversarial settings. In adversarial settings, we establish a fundamental limit on a broad class of convergence rate control methods including our own: an attacker with sufficient knowledge can restore fast convergence at a linear increase in model size. In order to overcome this limitation, future works will need to investigate methods that are not equivalent to controlling convergence rate.

</details>


### [88] [Effective Second-Harmonic Generation Coefficient and C-eigenvalue of Nonlinear Susceptibility Tensors](https://arxiv.org/abs/2602.18995)
*Die Xiao,Yisheng Song*

Main category: math.OC

TL;DR: 本文讨论了单轴晶体中有效二次谐波产生（SHG）系数的计算方法，通过非线性光学 susceptibilit 轴对称性将其转化为带几何约束的优化模型，并将变量减半以简化计算，同时比较了SHG系数与C-特征值的关系，最后通过典型晶体类别的实例验证了理论结果的正确性和广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地计算单轴晶体中的有效SHG系数，并理解其与材料对称性之间的关系。

Method: 利用基频光特性和非线性光学susceptibility张量的对称性，将SHG系数的计算转化为带有几何约束的优化问题，并将变量减少到2个以便于计算。

Result: 成功简化了有效SHG系数的计算模型，实现了变量减半，并给出了SHG系数与C-特征值之间的比较结果。

Conclusion: 提出的方法能够有效简化SHG系数的计算，并具有广泛的适用性，通过典型晶体的例子验证了理论结果的正确性。

Abstract: The effective second-harmonic generation (SHG) coefficient is a crucial data that quantifies the efficiency of transforming fundamental frequency light into its second harmonic. With the help of the symmetry of nonlinear optical susceptibility tensors, we mainly discuss the computability of such a effective SHG coefficient in uniaxial crystals. For one thing, the calculation of effective SHG coefficient is converted into the optimization models with some geometric constraints by means of the peculiarity of fundamental frequency light. Secondly, the number of variables of such maximum models are cutted in half to $2$ to calculate it easier, and a comparison between the effective SHG coefficient and C-eigenvalue of susceptibility tensor is given also. Finally, some examples of typical crystal classes are presented to verify the correctness and broader applicabilities of the theoretical results.

</details>


### [89] [New reformulations for 0-1 quadratic programming problem using quadratic nonconvex reformulation techniques and valid inequalities](https://arxiv.org/abs/2602.19051)
*Cheng Lu,Yu Fei,Jing Zhou,Zhibin Deng,Guangtai Qu*

Main category: math.OC

TL;DR: 本文提出了一种基于二次非凸重构（QNR）技术的新型0-1二次规划问题重构方法，通过引入非凸约束并结合有效不等式（如三角不等式）来增强问题的下界，并优化McCormick松弛界，数值实验表明其相较于传统凸重构方法更有效。


<details>
  <summary>Details</summary>
Motivation: 为了提升求解0-1二次规划问题的效率，探索比现有二次凸重构（QCR）更具灵活性的重构方法，利用非凸重构（QNR）技术以更好地紧致下界。

Method: 采用二次非凸重构（QNR）技术对0-1二次规划问题进行重构，引入非凸二次约束并融合三角不等式等有效不等式，同时设计方法最大化McCormick松弛界。

Result: 所提出的重构方法能够显著提升求解器中的下界，数值实验显示其在0-1二次规划问题上优于现有的二次凸重构方法。

Conclusion: QNR技术为加速求解器提供了新途径，所提出的重构方法通过灵活引入非凸约束和有效不等式，在理论和实验上均展现出优越性。

Abstract: It is well-known that the quadratic convex reformulation (QCR) technique can speed up some general-purpose solvers such as CPLEX and Gurobi. Recently, the method of quadratic nonconvex reformulation (QNR) was proposed, which provides an alternative way for accelerating a solver via reformulation technique. This paper proposes several new reformulations for 0-1 quadratic programming problems using the QNR technique. Such a technique provides more flexibility in adding nonconvex quadratic constraints into the problem formulation, so that some valid inequalities, such as the triangle inequalities, can be incorporated into the formulation to tighten the lower bound of the problem. We analyze the effects of the proposed reformulations on the lower bounds implemented in the solver, and propose some methods to maximize the McCormick relaxation bounds of the reformulations. Our numerical experiments compare the proposed reformulations with the existing quadratic convex reformulations, showing the effectiveness of the proposed reformulations on 0-1 quadratic programming problems.

</details>


### [90] [CBO algorithm with average drift and applications to portfolio optimization](https://arxiv.org/abs/2602.19204)
*Hyeong-Ohk Bae,Seung-Yeal Ha,Chanho Min,Jane Yoo,Jaeyoung Yoon*

Main category: math.OC

TL;DR: 提出了一种基于共识的优化算法Ad-CBO，并证明其粒子解收敛于全局最优解，在静态和动态目标函数优化中表现优异，尤其在金融市场的多资产投资组合优化中展现出更高的搜索速度和更低的跟踪误差与遗憾界。


<details>
  <summary>Details</summary>
Motivation: 为了改进现有共识优化算法在动态环境中的性能，特别是在金融等实时应用中更高效地寻找全局最优解。

Method: 提出带有平均漂移的共识优化算法（Ad-CBO），并通过理论分析证明粒子解向全局最小值的收敛性，结合数值模拟验证其在静态和动态目标函数中的表现。

Result: Ad-CBO在优化静态和动态目标函数时表现出更高的搜索速度、更低的跟踪误差和遗憾界，优于无随机扩散的CBO算法。

Conclusion: Ad-CBO是一种有效的全局优化方法，尤其适用于动态变化环境下的实际应用，如金融市场中的实时投资组合优化。

Abstract: We propose a consensus based optimization algorithm with average drift (in short Ad-CBO) and provide a theoretical framework for it. In the theoretical analysis, we show that particle solutions to Ad-CBO converge to a global minimizer. In numerical simulations, we examine Ad-CBO's performance in optimizing static and dynamic objective functions. As a real-time application, we test the efficiency of Ad-CBO to find the optimal portfolio given stochastically evolving multi-asset prices in a financial market. The proposed Ad-CBO exhibits higher searching speed, lower tracking errors and regret bound than the CBO without stochastic diffusion

</details>


### [91] [Time-iteration methods for controllability](https://arxiv.org/abs/2602.19272)
*Frédéric Marbach*

Main category: math.OC

TL;DR: 本文综述了控制理论中的三种时间迭代方法：针对线性偏微分方程的Lebeau-Robbiano方法、非线性偏微分方程的Liu-Takahashi-Tucsnak方法以及非线性常微分方程的切向量方法。


<details>
  <summary>Details</summary>
Motivation: 旨在系统介绍适用于不同类型动力系统的控制策略，特别是通过时间迭代实现状态趋近目标的方法，推动对可控性问题的理解与应用。

Method: 对线性PDE采用谱不等式与耗散估计结合的Lebeau-Robbiano方法；对非线性PDE提出可直接应用的黑箱式Liu-Takahashi-Tucsnak方法；对非线性ODE使用基于近似可达方向的切向量方法。

Result: 总结了三类重要控制策略的有效框架，并为非线性系统提供了简化的应用途径。

Conclusion: 这些方法统一了不同系统下的可控性分析思路，具有良好的理论价值和教学意义。

Abstract: These notes are based on a short course delivered at the Summer School EUR MINT 2025 "Control, Inverse Problems and Spectral Theory", held in June 2025 in Toulouse, France. The course presents three important strategies in control theory, formulated as time-iteration methods, where each time step brings the state of the system closer to the desired target.
  For linear PDEs, we survey the classical Lebeau-Robbiano method and its more recent developments. This method combines spectral inequalities and dissipation estimates to prove null controllability of a dissipative linear system.
  For nonlinear PDEs, we reinterpret the Liu-Takahashi-Tucsnak method, which establishes local controllability of a nonlinear system by analyzing the control cost of its linearization. We provide an easily applicable black-box formulation of their method.
  Finally, for nonlinear ODEs, we present the tangent vectors method, which establishes local exact controllability starting from approximately reachable directions.

</details>


### [92] [Smoothing-Enabled Randomized Stochastic Gradient Schemes for Solving Nonconvex Nonsmooth Potential Games under Uncertainty](https://arxiv.org/abs/2602.19325)
*Zhuoyu Xiao*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The state of the art in solving nonconvex nonsmooth games under uncertainty remains in its infancy. Existing studies primarily rely on stringent growth conditions or local convexity-like properties, making the development of alternative algorithms desirable. In this work, we study a class of stochastic $N$-player noncooperative games characterized by a potential function. We first consider the nonconvex smooth setting and develop a randomized stochastic gradient (RSG) scheme. The RSG scheme achieves the optimal sample complexity of $\mathcal{O}(N^{2}ε^{-4})$ for reaching a point whose expected residual has norm at most $ε$. Building on this result, we introduce a randomized smoothed RSG (RS-RSG) scheme for solving stochastic potential games afflicted by nonconvexity and nonsmoothness. We show that RS-RSG asymptotically converges to an equilibrium of the smoothed game with sample complexity $\mathcal{O}(L^{4}_{\max}n^{3/2}_{\max}N^{3}η^{-1}ε^{-4})$, where $η>0$ is the smoothing parameter. Under Lipschitz continuity of the Clarke subdifferentials, we show that the expected residual evaluated at the smoothed equilibrium is $\mathcal{O}(η^{2})$. In addition, we discuss the biased RSG and RS-RSG variants and demonstrate the effectiveness of the biased RS-RSG scheme on a class of stochastic potential hierarchical games where the exact lower-level solution is unavailable in finite time. Collectively, our results provide a new pathway that goes beyond classical conditions for solving stochastic nonconvex nonsmooth games. Some preliminary numerics are also provided.

</details>


### [93] [Implementation of Time-Varying Controllers for a Nonholonomic Mobile Robot: Experimental Studies](https://arxiv.org/abs/2602.19334)
*Alexander Zuyev,Victoria Grushkovskaya,Sebastian Eisner*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider a kinematic model of a wheeled mobile robot controlled by translational and angular velocities. For this class of nonholonomic systems, a family of time-varying feedback controllers was proposed in our previous works using gradient flow approximation techniques. In the present study, these controllers are implemented on a TurtleBot3 Burger (TB3) mobile robot to provide experimental validation of the stabilization problem with oscillating input signals. In addition, the admissibility problem of a gradient flow is investigated to justify the construction of a Lyapunov function candidate. The presented experimental results demonstrate the possibility of stabilizing the reference position of the robot using feedback controls with practically acceptable parameters.

</details>


### [94] [Enhancing network resilience through topological switching](https://arxiv.org/abs/2602.19420)
*Fei Chen,Jorge Cortés,Sonia Martínez*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work studies how to preemptively increase the resilience of a network by means of time-varying topological actuation. To do this, we focus on linear dynamical systems that are compatible with a given network, and consider policies that switch periodically between the given one and an alternative, topologically-compatible dynamics. In particular, we seek to solve design problems aimed at finding a) the optimal switching schedule between two preselected topologies, and b) an optimal topology and optimal switching schedule. By imposing periodicity, we first provide a metric of resilience in terms of the spectral abscissa of the averaged linear time-invariant dynamics. By restricting our policies to commutative networks, we then show how the optimal scheduling problem reduces to a convex optimization, providing a bound on the net resilience that can be achieved. After this, we find that the optimal, sparse commutative network to switch with is fully disconnected and allocates the spectral sum among the nodes of the network equally. We then impose additional restrictions on topology edge selection, which leads to a biconvex optimization for which certain matrix rank conditions guide the choice of weighting parameters to obtain desirable solutions. Finally, we provide two methods to solve this problem efficiently (based on a McCormick relaxation, and alternating minimization), and illustrate the results in simulations.

</details>


### [95] [Optimal design with uncertainties: a risk-averse approach](https://arxiv.org/abs/2602.19869)
*Amal Alphonse,Petar Kunštek,Marko Vrdoljak*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study a class of stochastic optimal design problems for elliptic partial differential equations in divergence form, where the coefficients represent mixtures of two conducting materials. The objective is to minimize a generalized risk measure of the system response, incorporating uncertainty in the loading through probability distributions. We establish existence of relaxed optimal designs via homogenization theory and derive first-order stationarity conditions satisfied by the optima. Based on these conditions, we develop an optimality criteria algorithm for numerical computations. The stochastic component is treated using a truncated Karhunen--Loève expansion, allowing evaluation of the value-at-risk (VaR) and conditional value-at-risk (CVaR) contributions arising from the sensitivity analysis and featured in the algorithm. The method is illustrated for an example involving CVaR-based compliance minimization.

</details>


### [96] [Local Second-Order Limit Dynamics of the Alternating Direction Method of Multipliers for Semidefinite Programming](https://arxiv.org/abs/2602.20103)
*Shucheng Kang,Heng Yang*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The alternating direction method of multipliers (ADMM) is widely used for solving large-scale semidefinite programs (SDPs), yet on instances with multiple primal--dual optimal solution pairs, it often enters prolonged slow-convergence regions where the Karush--Kuhn--Tucker (KKT) residuals nearly stall. To explain and predict the fine-grained dynamical behavior inside these regions, we develop a local second-order limit dynamics framework for ADMM near an arbitrary KKT point -- not necessarily the eventual limit point of the iterates. Assuming the existence of a strictly complementary primal--dual solution pair, we derive a second-order local expansion of the ADMM dynamics by leveraging a refined and simplified variational characterization of the (parabolic) second-order directional derivative of the PSD projection operator. This expansion reveals a closed convex cone of directions along which the local first-order update vanishes, and it induces a second-order limit map that governs the persistent drift after transient effects are filtered out. We characterize fundamental properties of this mapping, including its kernel, range, and continuity. A primal--dual decoupling further yields a clean scaling law for the effect of the penalty parameter in ADMM. We connect these properties to second-order dynamical features of ADMM, including fixed points, almost-invariant sets, and microscopic phases. Three empirical phenomena in slow-convergence regions are then explained or predicted: (i) angles between consecutive iterate differences are small yet nonzero, except for sparse spikes; (ii) primal and dual infeasibilities are insensitive to penalty-parameter updates; and (iii) iterates can be transiently trapped in a low-dimensional subspace for an extended period. Extensive numerical experiments on the Mittelmann dataset corroborate our theoretical predictions.

</details>


### [97] [On a discrete max-plus transportation problem](https://arxiv.org/abs/2602.20136)
*Sergio Mayorga,Eugene Stepanov,Pedro Barrios*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We provide an explicit algorithm to solve the idempotent analogue of the discrete Monge-Kantorovich optimal mass transportation problem with the usual real number field replaced by the tropical (max-plus) semiring, in which addition is defined as the maximum and product is defined as usual addition, with minus infinity and zero playing the roles of additive and multiplicative identities. Such a problem may be naturally called tropical or "max-plus" optimal transportation problem. We show that the solutions to the latter, called the optimal tropical plans, may not correspond to perfect matchings even if the data (max-plus probability measures) have all weights equal to zero, in contrast with the classical discrete optimal transportation analogue, where perfect matching optimal plans in similar situations always exist. Nevertheless, in some randomized situation the existence of perfect matching optimal tropical plans may occur rather frequently. At last, we prove that the uniqueness of solutions of the optimal tropical transportation problem is quite rare.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [98] [Analytical characterization of self sustained nonlinear oscillators modelling human walking and bouncing](https://arxiv.org/abs/2602.19029)
*Varun Nevash,Prakash Kumar,Chinika Dangi*

Main category: nlin.AO

TL;DR: 本文应用了新的数学工具来改进现有的混合Van der Pol-Rayleigh-Duffing振荡器模型，提出了一种系统性的方法来估计模型参数。


<details>
  <summary>Details</summary>
Motivation: 现有模型主要依赖于Lindstedt-Poincare摄动法、能量平衡和谐波平衡技术，缺乏对极限环稳定性的解析证明及非线性效应的高阶逼近方法。

Method: 采用Krylov-Bogolyubov摄动法证明极限环的稳定性，改进多尺度法以迭代确定近似阶数，并利用描述函数法推导另一种振幅表达式。

Result: 揭示了摄动分析与描述函数法在特定条件下的一致性，并利用该条件提出了用于模型参数估计的附加约束。

Conclusion: 所提出的方法为建模人体诱导力提供了更系统的参数估计途径，减少了对纯优化方法的依赖。

Abstract: Researchers have developed hybrid Van der Pol Rayleigh Duffing type oscillators to model human induced forces; however, their analytical framework has largely relied on the Lindstedt Poincare perturbation method, energy balance approaches, and harmonic balance techniques. This paper aims to apply new mathematical tools to these existing models and address potential research gaps. An analytical proof for the stability of the limit cycle has been formulated by using the Krylov Bogolyubov perturbation method. The multiple scales method has been modified to highlight an iterative algorithm for determining the order of approximation required to capture nonlinear effects. The describing function method is utilised to formulate an alternate amplitude. Comparisons between first order amplitudes obtained from perturbation analysis and the describing function formulations reveal conditions under which the two approaches converge. These conditions are exploited to formulate additional constraints for the estimation of model parameters, offering a systematic alternative to purely optimisation based approaches.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [99] [Trotter Error and Orbital Transformations in Quantum Phase Estimation](https://arxiv.org/abs/2602.18913)
*Marvin Kronenberger,Mihael Erakovic,Markus Reiher*

Main category: quant-ph

TL;DR: 本文研究了轨道变换对Trotter误差的影响，探讨了三种通过轨道变换降低Trotter误差的策略，发现尽管局域轨道基在分子计算中不会产生大的Trotter误差，但可靠地减少Trotter误差仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 由于局域轨道基虽能降低电路深度，但文献指出其可能带来较大的Trotter误差，因此需要系统研究轨道变换对Trotter误差的影响。

Method: 提出了三种降低Trotter误差的轨道变换策略：(i) 预先选择低Trotter误差的轨道基；(ii) 构造使基态能量无Trotter误差的轨道基；(iii) 在Trotter步间变换计算基。利用Givens旋转参数分析误差连续性，并进行数值验证。

Result: 数值结果表明，尽管存在理论指导，可靠降低Trotter误差仍困难；但发现局域轨道基在分子计算中并不导致大的Trotter误差。

Conclusion: 局域轨道基可用于高效的量子相位估计（QPE）设置，因其在保持低电路深度的同时并未引入显著Trotter误差，这对量子化学模拟具有重要意义。

Abstract: Quantum computation with Trotter product formulae is straightforward and requires little overhead in terms of logical qubits. The choice of the orbital basis significantly affects circuit depth, with localised orbitals yielding lowest circuit depths. However, literature results point to large Trotter errors incurred by localised orbitals. Here, we therefore investigate the effect of orbital transformations on Trotter error. We consider three strategies to reduce Trotter error by orbital transformation: (i) The a priori selection of an orbital basis that produces low Trotter error. (ii) The derivation of an orbital basis that produces a ground state energy free of Trotter error (as we observed that the Trotter error is a continuous function in the Givens-rotation parameter, from which continuity of this error upon orbital transformation can be deduced). (iii) Application of propagators that change the computational basis between Trotter steps. Our numerical results show that reliably reducing Trotter error by orbital transformations is challenging. General recipes to produce low Trotter errors cannot be easily derived, despite analytical expressions which suggest ways to decrease Trotter error. Importantly, we found that localised orbital bases do not produce large Trotter errors in molecular calculations, which is an important result for efficient QPE set-ups.

</details>


### [100] [Detecting Initial System-Environment Correlations from a Single Observable](https://arxiv.org/abs/2602.18516)
*Ali Abu-Nada,Russell Ceballos,Lian-Ao Wu*

Main category: quant-ph

TL;DR: 提出了一种仅通过监测单个可观测量的时间演化来检测系统与环境初始关联的方法，避免了完全态层析和多次制备初态的实验负担。


<details>
  <summary>Details</summary>
Motivation: 现有检测初始系统-环境关联的方法通常需要全态层析或多轮系统准备，实验上代价高；而实际中环境往往不可访问，因此需要更简洁有效的方法。

Method: 针对已知相互作用（如各向同性Heisenberg交换或纯退相位自旋-玻色模型），推导出因子化初态下系统单个观测量（如⟨σ_z^S⟩）时间演化的精确边界（即‘因子化包络’）；若实际轨迹突破该边界，则可认证初始关联的存在。

Result: 在多种关联初态下观察到明显的包络突破现象，包括系统约化态为最大混合态的情况；方法同样适用于无限环境的纯退相位模型，且只需一次校准和单个可观测量即可实现认证。

Conclusion: 单轴测量结合初态的一次校准，足以在无需环境访问或态层析的情况下，有效认证系统与环境之间的初始关联。

Abstract: We address the problem of detecting initial system--environment correlations when the environment is not directly accessible. Most existing approaches rely on full state tomography or multiple system preparations, which can be experimentally demanding.
  We show that, for a known interaction, it can be sufficient to monitor a single expectation value of the system. Focusing on a qubit interacting with an environment via isotropic Heisenberg exchange, we derive exact bounds on the signal $z(t)=\langleσ_z^S\rangle(t)$ that hold for all factorized initial states. These bounds define a \emph{factorized envelope}: if an observed trajectory exits this envelope at any time, initial system--environment correlations are certified.
  From a reduced-dynamics perspective, the envelope admits a clear operational interpretation as the admissible region generated by the standard product assignment (embedding) map, which serves as a null model for uncorrelated preparations. Envelope violations therefore rule out the entire product-assignment class using only a single calibrated observable.
  We illustrate the method using three families of correlated initial states and observe clear envelope violations, including cases in which the reduced system state is maximally mixed. We further show that the same single-observable logic extends to an exactly solvable pure-dephasing spin--boson model with an infinite environment, where factorized initial states generate a simple coherence envelope whose violation certifies initial correlations. Overall, our results demonstrate that single-axis measurements, combined with a one-time calibration of $ρ_S(0)$, can certify initial system--environment correlations without tomography or environment access.

</details>


### [101] [Time uncertainty and fundamental sensitivity limits in quantum sensing: application to optomechanical gravimetry](https://arxiv.org/abs/2602.18524)
*Salman Sajad Wani,Saif Al-Kuwari,Arshid Shabir,Paolo Vezio,Francesco Marino,Mir Faizal*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: High-sensitivity accelerometers and gravimeters, achieving the ultimate limits of measurement sensitivity are key tools for advancing both fundamental and applied physics. While numerous platforms have been proposed to achieve this goal, from atom interferometers to optomechanical systems, all of these studies neglect the effects of intrinsic quantum uncertainty in time estimation. Starting from the Hamiltonian of a generic linear quantum sensor, we derive the two-parameter quantum Fisher information matrix and establish the corresponding Cram'er-Rao bound, treating time as an uncertain (nuisance) parameter. Our analysis reveals a fundamental coupling between time and signal estimation that inherently degrades measurement sensitivity, with the standard single-parameter quantum limit recovered only at specific interrogation times or under special decoupling conditions. We then apply these results to an optomechanical gravimeter and explicitly derive an optimal decoupling condition under which the effects of time uncertainty are averaged out in a continuous measurement scheme. Our approach is general and can be readily extended to a broad class of quantum sensors.

</details>


### [102] [Entanglement dynamics of many-body quantum states: sensitivity to system conditions and a hidden universality](https://arxiv.org/abs/2602.19280)
*Devanshu Shekhar,Pragya Shukla*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider physical Hamiltonians that can be represented by the multiparametric Gaussian ensembles, theoretically derive the state ensembles for its eigenstates and analyze the effect of varying system conditions on its bipartite entanglement entropy. Our approach leads to a single parametric based common mathematical formulation for the evolution of the entanglement statistics of different states of a given Hamiltonian or different Hamiltonians subjected to same symmetry constraints. The parameter turns out to be a single functional of the system parameters and thereby reveals a deep web of connection hidden underneath different quantum states.

</details>


### [103] [Engineering quantum criticality and dynamics on an analog-digital simulator](https://arxiv.org/abs/2602.18555)
*Alexandra A. Geim,Nazli Ugur Koyluoglu,Simon J. Evered,Rahul Sahay,Sophie H. Li,Muqing Xu,Dolev Bluvstein,Nik O. Gjonbalaj,Nishad Maskara,Marcin Kalinowski,Tom Manovitz,Ruben Verresen,Susanne F. Yelin,Johannes Feldmeier,Markus Greiner,Vladan Vuletic,Mikhail D. Lukin*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Understanding emergent phenomena in out-of-equilibrium interacting many-body systems is an exciting frontier in physical science. While quantum simulators represent a promising approach to this long-standing problem, in practice it can be challenging to directly realize the required interactions, measure arbitrary observables, and mitigate errors. Here we use coherent mapping between the Rydberg and hyperfine qubits in a neutral atom array simulator to engineer and probe complex quantum dynamics. We combine efficient analog dynamics with fully programmable state preparation and measurement, leverage non-destructive readout for loss information and atomic qubit reuse, and use an atom reservoir for replacing lost atoms. With this analog-digital approach, we first demonstrate dynamical engineering of ring-exchange and particle hopping dynamics via Floquet driving and measure the spectral function of single excitations by evolving initial superposition states. Extending these techniques to a 271-site kagome lattice, we employ closed-loop optimization to target an out-of-equilibrium critical quantum spin liquid of the Rokhsar-Kivelson type. We observe the key features of such a state, including the absence of local order, many-body coherences between nearly equal-amplitude dimer configurations over up to 18 sites, and universal correlations consistent with predictions from field theory. Together, these results pave the way for using dynamical control in analog-digital quantum simulators to study complex quantum many-body systems.

</details>


### [104] [Self-correction phase transition in the dissipative toric code](https://arxiv.org/abs/2602.19288)
*Sanjeev Kumar,Hendrik Weimer*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze a time-continuous version of a cellular automaton decoder for the toric code in the form of a Lindblad master equation. In this setting, a self-correcting quantum memory becomes a thermodynamical phase of the steady state, which manifests itself through the steady state being topologically ordered. We compute the steady state phase diagram, finding a competition between the error correction rate and the update rate for the classical field of the cellular automaton. Strikingly, we find that self-correction of errors is possible even in situations where conventional quantum error correction does not have a finite threshold.

</details>


### [105] [Controlling emergent dynamical behavior via phase-engineered strong symmetries](https://arxiv.org/abs/2602.18563)
*Marc Nairn,Beatriz Olmos,Parvinder Solanki*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Symmetry constraints provide a powerful means to control the dynamics of open quantum systems. However, the set of accessible control parameters is often limited. Here, we show that a tunable phase in the collective light-matter coupling of a cavity QED system induces a phase-dependent strong symmetry of the Liouvillian, enabling dynamical control of the open quantum system evolution. We demonstrate that tuning this phase substantially reduces the critical driving strength for dissipative phase transitions between stationary and non-stationary phases. We illustrate this mechanism in two experimentally relevant cavity QED settings: a two-species ensemble of two-level atoms and a single-species ensemble of three-level atoms. Our results establish phase control as a versatile tool for engineering dissipative phase transitions, with implications for quantum state preparation.

</details>


### [106] [Predicting Magic from Very Few Measurements](https://arxiv.org/abs/2602.18939)
*J. M. Varela,L. L. Keller,A. de Oliveira Junior,D. A. Moreira,R. Chaves,R. A. Macêdo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The nonstabilizerness of quantum states is a necessary resource for universal quantum computation, yet its characterization is notoriously demanding. Quantifying nonstabilizerness typically requires an exponential number of measurements and a doubly exponential classical post-processing cost to evaluate its standard monotones. In this work, we show that nonstabilizerness is, to a large extent, in the eyes of the beholder: it can be witnessed and quantified using any set of $m$ $n$-qubit Pauli measurements, provided the set contains anti-commuting pairs. We introduce a general framework that projects the stabilizer polytope onto the subspace defined by these observables and provide an algorithm that estimates magic from Pauli expectation values with runtime exponential in the number of measurements $m$ and polynomial in the number of qubits $n$. By relating the problem to a stabilizer-restricted variant of the quantum marginal problem, we also prove that deciding membership in the corresponding reduced stabilizer polytope is NP-hard. In particular, unless $\mathrm{P} = \mathrm{NP}$, no algorithm polynomial in $m$ can solve the problem in full generality, thus establishing fundamental complexity-theoretic limitations. Finally, we employ our framework to compute nonstabilizerness in different Hamiltonian ground states, demonstrating the practical performance of our method in regimes beyond the reach of existing techniques.

</details>


### [107] [Four- and six-photon stimulated Raman transitions for coherent qubit and qudit operations](https://arxiv.org/abs/2602.18567)
*Gabriel J. Gregory,Evan R. Ritchie,Alex Quinn,Sean Brudney,David J. Wineland,David T. C. Allcock,Jameson O'Reilly*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We experimentally demonstrate transitions between electronic angular momentum states with a difference in magnetic quantum numbers $Δ\mathrm{m_J} = $ 3, 4, and 5 via resonant four- and six-photon stimulated Raman transitions in a single trapped atom. Derivation of the corresponding Rabi frequencies, which are verified experimentally, follows the standard treatment of two-photon transitions including the adiabatic elimination of intermediate states. Finally, we discuss pathways to increase the observed multi-photon transition fidelities to $>99.99\%$, providing a tool for efficient, high-fidelity control of qu\textit{d}its and single-atom logical qubits.

</details>


### [108] [Auto Quantum Machine Learning for Multisource Classification](https://arxiv.org/abs/2602.18642)
*Tomasz Rybotycki,Sebastian Dziura,Piotr Gawron*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: With fault-tolerant quantum computing on the horizon, there is growing interest in applying quantum computational methods to data-intensive scientific fields like remote sensing. Quantum machine learning (QML) has already demonstrated potential for such demanding tasks. One area of particular focus is quantum data fusion -- a complex data analysis problem that has attracted significant recent attention. In this work, we introduce an automated QML (AQML) approach for addressing data fusion challenges. We evaluate how AQML-generated quantum circuits perform compared to classical multilayer perceptrons (MLPs) and manually designed QML models when processing multisource inputs. Furthermore, we apply our method to change detection using the multispectral ONERA dataset, achieving improved accuracy over previously reported QML-based change detection results.

</details>


### [109] [Calderbank-Shor-Steane codes on group-valued qudits](https://arxiv.org/abs/2602.19558)
*Ben T. McDonough,Jian-Hao Zhang,Victor V. Albert,Andrew Lucas*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Calderbank-Shor-Steane (CSS) codes are a versatile quantum error-correcting family built out of commuting $X$- and $Z$-type checks. We introduce CSS-like codes on $G$-valued qudits for any finite group $G$ that reduce to qubit CSS codes for $G = \mathbb{Z}_2$ yet generalize the Kitaev quantum double model for general groups. The $X$-checks of our group-CSS codes correspond to left and/or right multiplication by group elements, while $Z$-checks project onto solutions to group word equations. We describe quantum-double models on oriented two-dimensional CW complexes (which need not cellulate a manifold) and prove that, when $G$ is non-Abelian and simple, every $G$-covariant group-CSS code with suitably upper-bounded $Z$-check weight and lower-bounded $Z$-distance reduces to a CW quantum double. We describe the codespace and logical operators of CW quantum doubles via the same intuition used to obtain logical structure of surface codes. We obtain distance bounds for codes on non-Abelian simple groups from the graph underlying the CW complex, and construct intrinsically non-Abelian code families with asymptotically optimal rate and distances. Adding "ghost vertices" to the CW complex generalizes quantum double models with defects and rough boundary conditions whose logical structure can be understood without reference to non-Abelian anyons or defects. Several non-invertible symmetry-protected topological states, both with ordinary and higher-form symmetries, are the unique codewords of simply-connected CW quantum doubles with a single ghost vertex.

</details>


### [110] [Differentiable Maximum Likelihood Noise Estimation for Quantum Error Correction](https://arxiv.org/abs/2602.19722)
*Hanyan Cao,Dongyang Feng,Cheng Ye,Feng Pan*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate noise estimation is essential for fault-tolerant quantum computing, as decoding performance depends critically on the fidelity of the circuit-level noise parameters. In this work, we introduce a differentiable Maximum Likelihood Estimation (dMLE) framework that enables exact, efficient, and fully differentiable computation of syndrome log-likelihoods, allowing circuit-level noise parameters to be optimized directly via gradient descent. Leveraging the exact Planar solver for repetition codes and a novel, simplified Tensor Network (TN) architecture combined with optimized contraction path finding for surface codes, our method achieves tractable and fully differentiable likelihood evaluation even for distance 5 surface codes with up to 25 rounds. Our method recovers the underlying error probabilities with near-exact precision in simulations and reduces logical error rates by up to 30.6(3)% for repetition codes and 8.1(2)% for surface codes on experimental data from Google's processor compared to previous state-of-the-art methods: correlation analysis and Reinforcement Learning (RL) methods. Our approach yields provably optimal, decoder-independent error priors by directly maximizing the syndrome likelihood, offering a powerful noise estimation and control tool for unlocking the full potential of current and future error-corrected quantum processors.

</details>


### [111] [Higher-order circuits](https://arxiv.org/abs/2602.18701)
*Matt Wilson*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We write down a series of basic laws for (strict) higher-order circuit diagrams. More precisely, we define higher-order circuit theories in terms of: (a) nesting, (b) temporal and spatial composition, and (c) equivalence between lower-order bipartite processes and higher-order bipartite states. In category-theoretic terms, these laws are expressed using enrichment and cotensors in symmetric polycategories, along with a frobenius-like coherence between them. We describe how these laws capture the salient features of higher-order quantum theory, and discover an upper bound for higher-order circuits: any higher-order circuit theory embeds into the theory of strong profunctors.

</details>


### [112] [Krylov Distribution and Universal Convergence of Quantum Fisher Information](https://arxiv.org/abs/2602.19750)
*Mohsen Alishahiha,Fatemeh Tarighi Tabesh,Mohammad Javad Vasli*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We develop a spectral-resolvent framework for computing the quantum Fisher information (QFI) using Krylov subspace methods, extending the notion of the Krylov distribution. By expressing the QFI as a resolvent moment of the superoperator $\mathcal{K}_ρ$ associated with a density matrix, the Krylov distribution quantifies how the QFI weight is distributed across Krylov levels in operator space and provides a natural measure for controlling the truncation error in Krylov approximations. Leveraging orthogonal polynomial theory, we identify two universal convergence regimes: exponential decay when the Liouville-space spectrum is gapped away from zero, and algebraic decay governed by hard-edge (Bessel) universality when small eigenvalues accumulate near zero. This framework establishes a direct connection between quantum metrology, spectral geometry, and Krylov dynamics, offering both conceptual insight and practical tools for efficient QFI computation in high-dimensional and many-body systems.

</details>


### [113] [Hierarchies of Gaussian multimode entanglement from thermodynamic quantifiers](https://arxiv.org/abs/2602.18816)
*Mrinmoy Samanta,Sudipta Mondal,Ayan Patra,Saptarshi Roy,Aditi Sen De*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We develop a thermodynamic characterization of multimode entanglement in pure continuous-variable systems by quantifying the gap between globally and locally extractable work (ergotropy). For arbitrary pure multimode Gaussian states, we prove that the $2$-local ergotropic gap is a faithful entanglement monotone across any bipartition and constitutes a functionally independent upper bound to the Renyi-2 entanglement entropy. We further introduce the $k$-ergotropic score, the minimum $k$-local ergotropic gap, and show that it faithfully quantifies multimode entanglement across $k$ partitions. For pure three-mode Gaussian states, we derive its closed-form relation with the geometric measure for genuine multimode entanglement $(k=2)$, and total Gaussian multimode entanglement $(k=3)$. For systems with more than three modes, the $k$-ergotropic score becomes a functionally independent measure of multimode entanglement to the standard geometric measures. Our results reveal a direct operational hierarchy linking Gaussian multimode entanglement to work extraction under locality constraints, and provide a computable and experimentally accessible thermodynamic framework for characterizing quantum correlations.

</details>


### [114] [Entanglement formation in two-dimensional materials within microcavity](https://arxiv.org/abs/2602.20077)
*Fabricio Danel Matias,Facundo Arreyes,Juan Sebastián Ardenghi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, the entanglement generation between two hexagonal-lattice layers embedded in a microcavity is studied, accounting for both electromagnetic coupling and intrinsic spin-orbit interaction (SOI). Utilizing a short-time dynamical approach, we perform a perturbative Taylor expansion of the reduced density matrix to characterize the bipartite quantum correlations between the hexagonal layers. We demonstrate that the system undergoes a rapid transition from a localized product state in the conduction bands at t = 0 to a coherent superposition of valence and conduction band states. Our results indicate that the degree of entanglement is highly sensitive to the interlayer photon propagator, which contains the geometric ratios of the layer positions and the height cavity, and the specific Fermi energy and SOI signatures of the respective layers. We show the emergence of spacelike-separated quantum correlations in the ultra-short evolution regime, suggesting that heterostructures in cavities may be suitable to develop experiments for a deep understanding of spacelike-separated quantum effects.

</details>


### [115] [Frozen and Growing Quantum Work under Noise: Coherence and Correlations as Key Resources](https://arxiv.org/abs/2602.18860)
*Mohammad B. Arjmandi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the decomposition of ergotropy into incoherent and coherent contributions for quantum systems subject to typical Markovian noise channels. The incoherent part originates from population inversion in the energy eigenbasis after dephasing, while the coherent part captures the role of quantum coherence in work extraction. For single-qubit systems, we derive explicit conditions for freezing and enhancement of coherent ergotropy and obtain an analytical upper bound, showing that it cannot exceed one half of the state's quantum coherence. We then study two classes of separable two-qubit states under local noise. For Bell-diagonal states, which are locally completely passive and possess no local coherence, we prove that the total extractable work equals the average of geometric quantum and classical correlations. In this case, coherent ergotropy cannot be enhanced, although freezing occurs under specific noise conditions. By contrast, for separable states with local coherence, coherent ergotropy can increase under all considered noise channels, including phase-flip and depolarizing noise. Extending the analysis to multipartite systems, we show that both the magnitude and range of noise-induced enhancement grow with the number of qubits, indicating collective reinforcement. Finally, we demonstrate through an explicit example that entanglement does not prevent this enhancement: coherent ergotropy may increase under noise even for entangled states. Our results reveal that noise can assist energy storage, challenging the conventional view of noise as purely detrimental and suggesting compatibility between noise-assisted enhancement and fast entanglement-based charging mechanisms in quantum batteries.

</details>


### [116] [Generalized $\mathbb{Z}_p$ toric codes as qudit low-density parity-check codes](https://arxiv.org/abs/2602.20158)
*Zijian Liang,Yu-An Chen*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study two-dimensional translation-invariant CSS stabilizer codes over prime-dimensional qudits on the square lattice under twisted boundary conditions, generalizing the Kitaev $\mathbb{Z}_p$ toric code by augmenting each stabilizer with two additional qudits. Using the Laurent-polynomial formalism, we adapt the Gröbner basis to compute the logical dimension $k$ efficiently, without explicitly constructing large parity-check matrices. We then perform a systematic search over various stabilizer realizations and lattice geometries for $p\in\{3,5,7,11\}$, identifying qudit low-density parity-check codes with the optimal finite-size performance. Representative examples include $[[242,10,22]]_3$ and $[[120,6,20]]_{11}$, both achieving $k d^{2}/n=20$. Across the searched regime, the best observed $k d^{2}$ at fixed $n$ increases with $p$, with an empirical relation $k d^{2} = 0.0541 \, n^{2}\ln p + 3.84 \, n$, compatible with a Bravyi--Poulin--Terhal-type tradeoff when the interaction range grows with system size.

</details>


### [117] [Why measurements are made of effects](https://arxiv.org/abs/2602.18898)
*Tobias Fritz*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Both in quantum theory and in general probabilistic theories, measurements with $n$ outcomes are modelled as $n$-tuples of \emph{effects} summing up to the unit effect. Why is this the case, and can this assumption be meaningfully relaxed? Here we develop \emph{generalized measurement theories (GMTs)} as a mathematical framework for physical theories that is complementary to general probabilistic theories, and where this kind of question can be made precise and answered. We then give a definition of \emph{probabilistic state} on a GMT, prove that measurements are made of effects in every GMT in which the probabilistic states separate the measurements, and also argue that this separation condition is physically well-motivated. Finally, we also discuss when a GMT should be considered classical and characterize GMTs corresponding to Boolean algebras as those that are strongly classical and projective.

</details>


### [118] [Integrable cascaded frequency conversion using the time rescaling shortcut to adiabaticity](https://arxiv.org/abs/2602.18930)
*J. L. Montenegro Ferreira*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this letter we explore how full frequency conversion can be performed in shorter, integrable devices by using a STIRAP-like protocol modified by the time rescaling shortcut to adiabaticity. We show how the coupled equations for two simultaneous three-wave mixing processes can be written in terms of a STIRAP-like system, which creates robust conversion, albeit requiring long propagation distances inside a bulk crystal or waveguide. We then discuss how the time rescaling (TR) method can be modified to be applied in optical systems, then apply it in the conversion process to create a TR-STIRAP protocol, showing that full conversion is also obtained, but at a fraction of the propagation distance. We also show how the original shaping of the coupling coefficients required by the TR-STIRAP can be approximated by gaussian functions with high conversion fidelity, thus simplifying the experimental implementation. This protocol has the potential to be used in several areas, including the integration of photon sources and efficient detectors for quantum key distribution.

</details>


### [119] [Co-Propagation of Quantum Time Synchronization and Optical Frequency Transfer over a 122 km Hollow-Core Fiber](https://arxiv.org/abs/2602.19013)
*Huibo Hong,Xiao Xiang,Runai Quan,Rongduo Lu,Qian Zhou,Dawei Ge,Liuyan Han,Bo Liu,Ru Yuan,Dechao Zhang,Yuting Liu,Bingke Shi,ZhiGuang Xia,Xinghua Li,Mingtao Cao,Tao Liu,Ruifang Dong,Shougang Zhang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The co-propagation of quantum and classical signals through shared optical fibers is crucial for scalable quantum networks. However, this coexistence is fundamentally limited by spontaneous Raman scattering (SpRS) from the bright classical light, which generates overwhelming noise that disrupts the single-photon-level quantum signals. Here, we overcome this long-standing challenge by leveraging the inherently ultralow nonlinearity of hollow-core fiber (HCF) to suppress SpRS noise. By operating both the quantum time synchronization (QTS) and classical optical frequency transfer (OFT) signals within the telecom C-band, separated by only ~10 nm, we successfully demonstrate their simultaneous transmission over a 122-km HCF link. With a classical OFT power of 1 mW, the QTS performance shows negligible degradation, maintaining sub-picosecond time stability at 2000 s, while the OFT achieves a fractional frequency instability of 10^-20. Near-sub-picosecond QTS stability is preserved even when the classical power is increased to 3 mW. Furthermore, simulations based on our experimental data indicate that with next-generation low-loss HCF, the platform can tolerate classical powers beyond 10 mW and extend the QTS range to over 500 km. By realizing a unified quantum-classical time-frequency distribution framework, this work establishes HCF as a highly capable and practical platform for future scalable quantum networks.

</details>


### [120] [Exceptional Point Superradiant Lasing with Ultranarrow Linewidth](https://arxiv.org/abs/2602.19030)
*Min Du,Qian Bin,Qing-Yang Qiu,Franco Nori,Xin-You Lü*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Achieving superradiant lasing with an ultranarrow linewidth is crucial for enhancing atomic clock stability in quantum precision measurement. By employing the exceptional point (EP) property of the system, we demonstrate theoretically superradiant lasing with linewidths in the $μ$Hz range, sustained at the high-power level. This is achieved by incoherently pumping optical lattice clock transitions with ultracold alkaline-earth strontium-87 atoms in the EP of a $\mathcal{PT}$-symmetric system. Physically, the atomic coherence reaches a maximum in the EP, significantly amplifying the superradiance effect and resulting in superradiant lasing with an ultranarrow linewidth. This linewidth is even three orders of magnitude smaller than that of superradiant lasing in the systems without EP. Our work extends the realm of superradiant lasing by introducing the EP property, and offers promising applications for developing atomic clocks with exceptional stability and accuracy.

</details>


### [121] [Quantum Error Correction and Dynamical Decoupling: Better Together or Apart?](https://arxiv.org/abs/2602.19042)
*Victor Kasatkin,Mario Morford-Oberst,Arian Vezvaee,Daniel A. Lidar*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum error correction (QEC) and dynamical decoupling (DD) are tools for protecting quantum information. A natural goal is to combine them to outperform either approach alone. Such a benefit is not automatic: physical DD can conflict with an encoded subspace, and QEC performance is governed by the errors that survive decoding, not necessarily those DD suppresses. We analyze a hybrid memory cycle where DD is implemented logically (LDD) using normalizer elements of an $[[n,k,d]]$ stabilizer code, followed by a round of syndrome measurement and recovery (or, in the detection setting, postselection on a trivial syndrome). In an effective Pauli model with physical error probability $p$, LDD suppression factor $p_{DD}$, and recovery imperfection rate $p_{QEC}$ (or $p_{QED}$), we derive closed-form entanglement-fidelity expressions for QEC-only, LDD-only, physical DD, and the hybrid LDD+QEC protocol. The formulas are expressed via a small set of code-dependent weight enumerator polynomials, making the role of the decoder and the LDD group explicit. For ideal recovery LDD+QEC outperforms QEC-only iff the conditional fraction of uncorrectable Pauli errors is larger in the LDD-suppressed sector than in the unsuppressed sector. In the low-noise regime, a sufficient design rule guaranteeing hybrid advantage is that LDD suppresses at least one minimum-weight uncorrectable Pauli error for the chosen recovery map. We show how stabilizer-equivalent choices of LDD generators can be used to enforce this condition. We supplement our analysis with numerical results for the $[[7,1,3]]$ Steane code and a $[[13,1,3]]$ code, mapping regions of hybrid-protocol advantage in parameter space beyond the small-$p$ regime. Our work illustrates the need for co-design of the code, decoder, and logical decoupling group, and clarifies the conditions under which the hybrid LDD+QEC protocol is advantageous.

</details>


### [122] [Structural Analysis of Directional qLDPC Codes](https://arxiv.org/abs/2602.19057)
*Mohammad Rowshan*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Directional codes, recently introduced by Gehér--Byfield--Ruban \cite{Geher2025Directional}, constitute a hardware-motivated family of quantum low-density parity-check (qLDPC) codes. These codes are defined by stabilizers measured by ancilla qubits executing a fixed \emph{direction word} (route) on square- or hex-grid connectivity. In this work, we develop a comprehensive \emph{word-first} analysis framework for route-generated, translation-invariant CSS codes on rectangular tori. Under this framework, a direction word $W$ deterministically induces a finite support pattern $P(W)$, from which we analytically derive: (i)~a closed-form route-to-support map; (ii)~the odd-multiplicity difference lattice $L(W)$ that classifies commutation-compatible $X/Z$ layouts; and (iii)~conservative finite-torus admissibility criteria. Furthermore, we provide: (iv)~a rigorous word equivalence and canonicalization theory (incorporating dihedral lattice symmetries, reversal/inversion, and cyclic shifts) to enable symmetry-quotiented searches; (v)~an ``inverse problem'' criterion to determine when a translation-invariant support pattern is realizable by a single route, including reconstruction and non-realizability certificates; and (vi)~a quasi-cyclic (group-algebra) reduction for row-periodic layouts that explains the sensitivity of code dimension $k$ to boundary conditions. As a case study, we analyze the word $W=\texttt{NE$^2$NE$^2$N}$ end-to-end. We provide explicit stabilizer dependencies, commuting-operator motifs, and an exact criterion for dimension collapse on thin rectangles: for $(L_x, L_y) = (2d, d)$ with row alternation, we find $k=4$ if $6 \mid d$, and $k=0$ otherwise.

</details>


### [123] [Near-perfect Noisy Quantum State Teleportation](https://arxiv.org/abs/2602.19103)
*Md Manirul Ali,Sovik Roy,Dipankar Home*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Achieving high fidelity of quantum teleportation (QT) in a noisy environment is an essential requirement for its real-world applications. To this end, we devise a distinctive protocol for ensuring teleportation fidelity {\it close to unity}, hinging essentially on the timing of Alice's Bell-basis measurement (BM) dependent on the choice of Bob's local noise parameters, but is independent of Alice's local noise. Our scheme is enabled by Alice communicating to Bob only two of the BM outcomes corresponding to the states that are decoherence-free under common dephasing at Alice's wing. On the other hand, Bob is asked to discard the states of his qubit for the other two BM outcomes in order to maximize fidelity of the teleported state. This ensures the teleportation fidelity's independence of noise parameters in Alice's wing. We formulate the protocol in terms of a generic two-level quantum system, subjected to non-Markovian dephasing noise, applicable for any pure maximally/non-maximally entangled state as well as a Werner-type mixed state as resource. Notably, we show that high fidelity is achievable even using resource states with small values of the entanglement measure. Remarkably, even within the local regime of Werner states, where Bell-CHSH inequalities are not violated, the teleportation fidelity remains significantly high. Finally, we discuss the empirical feasibility of our scheme using photonic qubits.

</details>


### [124] [Kaiwu-PyTorch-Plugin: Bridging Deep Learning and Photonic Quantum Computing for Energy-Based Models and Active Sample Selection](https://arxiv.org/abs/2602.19114)
*Hongdong Zhu,Qi Gao,Yin Ma,Shaobo Chen,Haixu Liu,Fengao Wang,Tinglan Wang,Chang Wu,Kai Wen*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper introduces the Kaiwu-PyTorch-Plugin (KPP) to bridge Deep Learning and Photonic Quantum Computing across multiple dimensions. KPP integrates the Coherent Ising Machine into the PyTorch ecosystem, addressing classical inefficiencies in Energy-Based Models. The framework facilitates quantum integration in three key aspects: accelerating Boltzmann sampling, optimizing training data via Active Sampling, and constructing hybrid architectures like QBM-VAE and Q-Diffusion. Empirical results on single-cell and OpenWebText datasets demonstrate KPPs ability to achieve SOTA performance, validating a comprehensive quantum-classical paradigm.

</details>


### [125] [Ion-atom two-qubit quantum gate based on phonon blockade](https://arxiv.org/abs/2602.19222)
*Subhra Mudli,Bimalendu Deb*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In a previous paper [S. Mudli {\it et al.} Phys. Rev. A 110, 062618 (2024)], it was shown that a trapped ion can mediate interaction between two largely separated Rydberg atoms, and this mediated interaction can be leveraged to perform a universal two-qubit gate operation between neutral atom qubits in optical tweezers. In this paper, we demonstrate the universal two-qubit CNOT gate with high fidelity between an ionic and an atomic qubit relying on Rydberg excitation of the atom and the resulting phonon blockade in the motional states of the harmonically trapped ion. The phonon blockade arises due to strong ion-atom interaction when the atom is excited to a Rydberg state. These demonstrations suggest that an ion-atom hybrid system can serve as a resourceful platform or module for quantum computing and quantum networking as it can utilize the best features of charged as well as neutral atom qubits.

</details>


### [126] [Eigenstate-assisted realization of general quantum controlled unitaries with a fixed cost](https://arxiv.org/abs/2602.19250)
*Carlos Navas-Merlo,Juan Carlos García-Escartín*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Controlled unitary gates are a basic element in many quantum algorithms. Converting a general unitary $U$ with a known decomposition into its controlled version, controlled-$U$, can introduce a large overhead in terms of the depth of the circuit. We present a general method to take any unitary $U$ into controlled-$U$ using a fixed circuit with 4 CNOT gates and 2 Toffoli gates per qubit. For $n$-qubit unitaries and one control qubit, we require $2n+1$ qubits and a circuit that can generate an eigenstate of $U$, for which there are many cost-effective known algorithms. The method also works for any black block implementation of $U$, achieving a constant-depth realization independent of its decomposition. We illustrate its use in the Hadamard test and discuss applications to variational and quantum machine-learning algorithms.

</details>


### [127] [Quantum Sketches, Hashing, and Approximate Nearest Neighbors](https://arxiv.org/abs/2602.19259)
*Sajjad Hashemian*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Motivated by Johnson--Lindenstrauss dimension reduction, amplitude encoding, and the view of measurements as hash-like primitives, one might hope to compress an $n$-point approximate nearest neighbor (ANN) data structure into $O(\log n)$ qubits. We rule out this possibility in a broad quantum sketch model, the dataset $P$ is encoded as an $m$-qubit state $ρ_P$, and each query is answered by an arbitrary query-dependent measurement on a fresh copy of $ρ_P$. For every approximation factor $c\ge 1$ and constant success probability $p>1/2$, we exhibit $n$-point instances in Hamming space $\{0,1\}^d$ with $d=Θ(\log n)$ for which any such sketch requires $m=Ω(n)$ qubits, via a reduction to quantum random access codes and Nayak's lower bound. These memory lower bounds coexist with potential quantum query-time gains and in candidate-scanning abstractions of hashing-based ANN, amplitude amplification yields a quadratic reduction in candidate checks, which is essentially optimal by Grover/BBBV-type bounds.

</details>


### [128] [Mass-Independent Gravitationally Induced Entanglement](https://arxiv.org/abs/2602.19306)
*Lorenzo Braccini,Alessio Serafini,Sougato Bose*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analytically solve the entangling quantum dynamics of two interacting Stern-Gerlach Interferometers~(SGI). Each SGI exploits an operator-valued force applied by a qubit to create and recombine a non-Gaussian state of matter. The entangling phase between the two qubits generated by the leading-order gravitational interaction of the massive degrees of freedom is found to be mass-independent, both for unitary and open dynamics, irrespective of the temperature and squeezing of the initial states. Further, we show that the solution of the four interferometric paths reveals that the mere presence of the interaction does not allow for a perfect recombination of the centre of mass. This second-order effect, alongside higher-order interaction terms, can be used to bound the mass from above and below, thus restricting the experiment's regime to mesoscopic masses. By solving the open dynamics which includes diffusion and dephasing with initial squeezed thermal states, the bounds are tightened by the inclusion of realistic experimental noise. We discuss diamagnetic levitated masses with embedded NV-centres as a specific physical implementation.

</details>


### [129] [Learning partial transpose signatures in qubit ququart states from a few measurements](https://arxiv.org/abs/2602.19307)
*Christian Candeago,Paolo Da Rold,Michele Grossi,Pawel Horodecki,Antonio Mandarino*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Higher-dimensional quantum systems are attracting interest for improving quantum protocol performance by increasing memory space. Characterizing quantum resources of such systems is fundamental but experimentally costly. We tackle the first non-trivial example: a qubit-ququart system, focusing on partial-transpose spectral classification. Entanglement distillation extracts maximally entangled states from noisy resources, but determining distillability typically requires full state tomography, experimentally prohibitive for high-dimensional systems. We explore a machine learning framework to classify distillable bipartite quantum states using fewer measurements than complete tomography. Our approach employs the PPT criterion, categorizing states by negative eigenvalues in the partial transpose. We use various ML algorithms, including Support Vector Machines, Random Forest, and Artificial Neural Networks, with features from fixed measurements and learnable observables. Results show learnable observables consistently outperform Collective Measurement Witnesses methods. While all models distinguish between non-distillable (PPT) and distillable (NPT) states, differentiating NPT subclasses remains challenging, underscoring the intricate Hilbert space geometry. This work provides an experimentally friendly tool for distillability verification in high-dimensional quantum systems without full state reconstruction

</details>


### [130] [Gravitational Poissonian Spontaneous Localization Model of Hybrid Quantum-Classical Newtonian Gravity: Energy Increase and Experimental Bounds](https://arxiv.org/abs/2602.19377)
*Nicolò Piccione*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Gravitational Poissonian Spontaneous Localization (GPSL) model is a hybrid classical-quantum framework in which Newtonian gravity emerges from stochastic collapses of a smeared mass-density operator. Consistency of the hybrid dynamics entails momentum diffusion and, hence, spontaneous heating. Without smearing, which enters both the collapse (measurement) and gravitational-feedback components of the dynamics, the heating rate would be divergent. Previous work assumed identical smearings for both components. Here, we treat the general case of distinct spatial smearings $g_{r_C} (\mathbf{x})$ and $g_{r_G} (\mathbf{x})$, characterized, respectively, by length scales $r_C$ and $r_G$. We characterize the spontaneous heating rate for arbitrary $g_{r_C} (\mathbf{x})$ and $g_{r_G} (\mathbf{x})$, and then discuss which smearing profiles minimize the spontaneous heating rate in relevant physical situations. Remarkably, there are situations in which, while the measurement noise remains the same, allowing $g_{r_G} (\mathbf{x}) \neq g_{r_C} (\mathbf{x})$ may reduce the feedback-induced spontaneous heating by more than 60 orders of magnitude already for $r_G = 10 r_C$. Finally, we use our results to estimate the spontaneous heating rate of neutron stars and to set new lower bounds on the model's parameters by comparing the theoretical predictions with astronomical data on temperature, radius, and mass of neutron stars.

</details>


### [131] [Contextuality-enhanced quantum state discrimination under fixed failure probability](https://arxiv.org/abs/2602.19397)
*Min Namkung,Hyang-Tag Lim*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum state discrimination enables the accurate identification of quantum states, which are generally nonorthogonal. Among various strategies, minimum-error discrimination and unambiguous state discrimination exhibit contextuality-enhanced success probabilities that surpass classical bounds, offering significant advantages for quantum sensing and communication. However, in practice, both error and failure outcomes can occur, suggesting the need for a unified strategy that incorporates both aspects while exploring the potential for contextuality enhancement. In this work, we theoretically demonstrate contextuality enhancement in quantum state discrimination under a fixed failure probability. We show that this enhancement disappears within a certain intermediate range of failure probabilities--a phenomenon absent in conventional strategies, where both minimum-error and unambiguous discrimination consistently outperform the noncontextual bound for equal priors. Moreover, we analyze how the existence of this non-enhancement region depends on the confusability of the quantum states, which corresponds to their fidelity in a quantum model. We further extend the discussion to the noisy state discrimination, which even encompasses the maximal-confidence discrimination. In this extended discussion, we observe that the non-enhancement region tends to disappear with increasing noise strength.

</details>


### [132] [Robust GHZ State Preparation via Majority-Voted Boundary Measurements](https://arxiv.org/abs/2602.19405)
*Jean-Baptiste Waring,Sébastien Le Beux,Christophe Pere*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Preparing high-fidelity Greenberger-Horne-Zeilinger (GHZ) states on noisy quantum hardware remains challenging due to cumulative gate errors and decoherence. We introduce Group-Majority-Voting (Group-MV), a dynamic-circuit protocol that partitions arbitrary coupling graphs, prepares local GHZ states in parallel, and fuses them via majority-voted mid-circuit measurements. The majority vote over redundant boundary links mitigates measurement errors that would otherwise propagate through classical feedforward. We evaluate Group-MV on simulated Heavy-hex and Grid topologies for 30 through 60 qubits under a realistic noise regime. Group-MV generalizes to arbitrary GHZ sizes on arbitrary coupling topologies, achieving 2.4x higher fidelity than the Line Dynamic method while tracking the unitary baseline within 3%.

</details>


### [133] [Subsystem Statistics and Conditional Self-Similarity of Random Quantum States](https://arxiv.org/abs/2602.19448)
*Sangchul Oh*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analytically derive the bit-string probability distributions of subsystems of random pure states and depolarized random states using the Dirichlet distribution. We identify the exact Beta distribution as the universal statistical law of random quantum states, providing a unified finite-size description of full-system, subsystem, and conditional statistics. In the presence of depolarizing noise, these distributions are scaled and shifted by the noise strength, producing a noise-induced gap in their support. Remarkably, we prove that random states exhibit exact conditional self-similarity: the distribution of subsystem bit-string probabilities conditioned on specific outcomes of the complementary subsystem is identical to that of the full system. This hidden scale invariance enables the exact restoration of the full-system statistics from the marginalized Beta distribution via post-selection, and persists under depolarizing noise. Our results uncover a fundamental symmetry of Hilbert space and provide a scalable, rigorous framework for validating random circuit sampling via subsystem or conditional cross-entropy benchmarking.

</details>


### [134] [Quantum Hamiltonian Learning using Time-Resolved Measurement Data and its Application to Gene Regulatory Network Inference](https://arxiv.org/abs/2602.19496)
*Mohammad Aamir Sohail,Ranga R. Sudharshan,S. Sandeep Pradhan,Arvind Rao*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a new Hamiltonian-learning framework based on time-resolved measurement data from a fixed local IC-POVM and its application to inferring gene regulatory networks. We introduce the quantum Hamiltonian-based gene-expression model (QHGM), in which gene interactions are encoded as a parameterized Hamiltonian that governs gene expression evolution over pseudotime. We derive finite-sample recovery guarantees and establish upper bounds on the number of time and measurement samples required for accurate parameter estimation with high probability, scaling polynomially with system size. To recover the QHGM parameters, we develop a scalable variational learning algorithm based on empirical risk minimization. Our method recovers network structure efficiently on synthetic benchmarks and reveals novel, biologically plausible regulatory connections in Glioblastoma single-cell RNA sequencing data, highlighting its potential in cancer research. This framework opens new directions for applying quantum-like modeling to biological systems beyond the limits of classical inference.

</details>


### [135] [Deterministic Ground State Preparation via Power-Cosine Filtering of Time Evolution Operators](https://arxiv.org/abs/2602.19556)
*Jeongbin Jo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The deterministic preparation of quantum many-body ground states is essential for advanced quantum simulation, yet optimal algorithms often require prohibitive hardware resources. Here, we propose a highly efficient, non-variational protocol for ground state preparation using a Power-Cosine quantum signal processing (QSP) filter. By eschewing complex block-encoding techniques, our method directly utilizes coherent time-evolution operators controlled by a single ancillary qubit. The integration of mid-circuit measurement and reset (MCMR) drastically minimizes spatial overhead, translating iterative non-unitary filtering into deep temporal coherence. We analytically demonstrate that this approach achieves exponential suppression of excited states with a circuit depth scaling of $\mathcal{O}(Δ^{-2}\log(1/ε))$, prioritizing implementational simplicity over optimal asymptotic complexity. Numerical simulations on the 1D Heisenberg XYZ model validate the theoretical soundness and shot-noise resilience of our method. Furthermore, an advantage analysis reveals that our protocol exponentially outperforms standard Trotterized Adiabatic State Preparation (TASP) at equivalent circuit depths. This single-ancilla framework provides a highly practical and deterministic pathway for many-body ground state preparation on Early Fault-Tolerant (EFT) quantum architectures.

</details>


### [136] [A Relation Between the Chrestenson Operator, Weyl Operator Basis, and Kronecker-Pauli Operator Basis](https://arxiv.org/abs/2602.19573)
*Mickaya A. Razanaparany,Christian Rakotonirina*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Within the framework of quantum theory, we review the Chrestenson operator, the Weyl operator basis, and the Kronecker-Pauli operator basis in $d$-dimensional Hilbert spaces using Dirac notation, where $d$ is a prime integer strictly greater than 2. We establish a new algebraic relation connecting these operators and present the cases $d=3$ and $d=5$ as illustrative examples.

</details>


### [137] [Characterization and active cancellation of power-line-induced motional-mode frequency noise in a trapped-ion system](https://arxiv.org/abs/2602.19588)
*Jaehun You,Jiyong Kang,Kyunghye Kim,Wonhyeong Choi,Taehyun Kim*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The stability of motional-mode frequency is essential for realizing high-fidelity quantum gates in trapped-ion quantum computing. While broadband Gaussian noise has been extensively studied and mitigated using pulse shaping techniques, the impact of coherent periodic noise has remained largely unexplored. Here we report a systematic investigation of 60-Hz power-line noise and its effect on the secular frequencies of a single ${}^{171}\mathrm{Yb}^{+}$ ion. Using spin-echo Ramsey spectroscopy, we characterize the amplitude and phase of the resulting secular-frequency modulation and validate this characterization via passive phase correction of the Ramsey sequence. Building on this, we implement active cancellation by injecting a compensation tone into the set-point of a PI controller that stabilizes the trap RF drive amplitude. A phasor-fitting procedure optimizes the amplitude and phase of the compensation signal, enabling near-complete suppression of the 60-Hz component. With active cancellation engaged, the coherence time of a radial motional mode is extended from approximately 10 ms to 35 ms, consistent with the limit set by motional heating. Our results provide both a clear characterization of periodic motional-mode noise and a practical framework for its suppression in trapped-ion quantum computing platforms.

</details>


### [138] [Magnon squeezing in the quantum regime](https://arxiv.org/abs/2602.19671)
*Yuan-Chao Weng,Da Xu,Zhen Chen,Li-Zhou Tan,Xu-Ke Gu,Jie Li,Hai-Feng Yu,Shi-Yao Zhu,Xuedong Hu,Franco Nori,J. Q. You*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Squeezed states, crucial for quantum metrology and emerging quantum technologies, have been demonstrated in various platforms, but quantum squeezing of magnons in macroscopic spin systems remains elusive. Here we report the experimental observation of quantum-level magnon squeezing in a millimeter-scale yttrium iron garnet (YIG) sphere. By engineering a strong dispersive magnon-superconducting qubit coupling via a microwave cavity, we implement a significant self-Kerr nonlinearity to generate squeezed magnon states with their mean magnon number less than one. Harnessing a magnon-assisted Raman process, we perform Wigner tomography, revealing quadrature variances of $\sim\!0.8$ ($\sim\!1.0$~dB squeezing) relative to the vacuum. These results lay the groundwork for quantum nonlinear magnonics and promise potential applications in quantum metrology.

</details>


### [139] [Reversible Information Transformation via Quantum Reservoir Computing: Conditions, Protocol, and Noise Resilience](https://arxiv.org/abs/2602.19700)
*Hikaru Wakaura,Taiki Tanimae*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum reservoir computing (QRC) exploits fixed quantum dynamics and a trainable linear readout to process temporal data, yet reversing the transformation -- reconstructing the input from the reservoir output -- has been considered intractable owing to the recursive nonlinearity of sequential quantum state evolution. Here we propose a four-equation encode-decode protocol with cross-key pairing and constructively show that quantum reservoir and key combinations satisfying all four equations exist. Using a full XYZ Hamiltonian reservoir with 10 data qubits, we expand the feature dimension to 76 without increasing qubit count and achieve machine-precision reconstruction (mean-squared error $\mathrm{MSE} \sim 10^{-17}$) for data lengths up to 30 under ideal conditions; the rank condition $\mathrm{dim}(V) \geq N_c$ is identified as a necessary criterion. A comprehensive noise analysis across seven conditions and four baseline methods reveals a clear hierarchy: shot noise dominates, depolarizing noise adds a moderate factor, and asymmetric resource allocation -- 10 shots for encoding, $10^5$ for decoding -- yields approximately two orders of magnitude MSE improvement by exploiting the asymmetric noise roles of the encryption and decryption feature matrices. Under realistic noise the MSE degrades to $10^{-3}$-$10^{-1}$, indicating that error mitigation is needed before practical deployment, but our results establish the feasibility of bidirectional reversible information transformation within QRC.

</details>


### [140] [Direct access to the initial polarization of ${}^{13}C$ nuclei by measuring coherence evolution of an nitrogen-vacancy center spin qubit](https://arxiv.org/abs/2602.19701)
*Mateusz Kuniej,Katarzyna Roszak*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce a method for the measurement of the lower bound on the initial polarization of spinful nuclei in a diamond by following the coherence evolution of an NV center spin qubit after a simple scheme is operated on the qubit to facilitate the transfer of information from the environment into the qubit state. Current polarization measurement techniques are challenging to implement due to the need for direct access to the environment. In our method, information is obtained by measuring the difference of the evolution of the qubit coherence resulting from preparation phase when the environment evolution is conditional on the qubit pointer state. We find that the method does not depend strongly on the applied magnetic field, but rather on the number of spinfull nuclei that lead to decoherence, and gives a reasonable estimate if the environment is polarized. The key advantage of this approach is its simplicity and minimal experimental requirements, allowing the inference of initial nuclear polarizations without direct access to the environment. We demonstrate the efficacy of this method using a simulated environment of up to fifteen randomly placed nuclear spins.

</details>


### [141] [Symmetry and Exact Solutions of General Spin-Boson Models](https://arxiv.org/abs/2602.19747)
*Yifan Sun,Lian-Ao Wu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Spin-boson models are the canonical benchmark for quantum dissipation. We show the symmetry structure of general spin-boson Hamiltonians and obtain their spectra explicitly by exploiting the symmetry. As an illustration of the general case, we numerically demonstrate the exact solution for the two-mode case.

</details>


### [142] [Improving Generalization and Trainability of Quantum Eigensolvers via Graph Neural Encoding](https://arxiv.org/abs/2602.19752)
*Jungyun Lee,Daniel K. Park*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Determining the ground state of a many-body Hamiltonian is a central problem across physics, chemistry, and combinatorial optimization, yet it is often classically intractable due to the exponential growth of Hilbert space with system size. Even on fault-tolerant quantum computers, quantum algorithms with convergence guarantees -- such as quantum phase estimation and quantum subspace methods -- require an initial state with sufficiently large overlap with the true ground state to be effective. Variational quantum eigensolvers (VQEs) are natural candidates for preparing such states; however, standard VQEs typically exhibit poor generalization, requiring retraining for each Hamiltonian instance, and often suffer from barren plateaus, where gradients can vanish exponentially with circuit depth and system size. To address these limitations, we propose an end-to-end representation learning framework that combines a graph autoencoder with a classical neural network to generate VQE parameters that generalize across Hamiltonian instances. By encoding interaction topology and coupling structure, the proposed model produces high-overlap initial states without instance-specific optimization. Through extensive numerical experiments on families of one- and two-local Hamiltonians, we demonstrate improved generalization and trainability, manifested as reduced test error and a significantly milder decay of gradient variance. We further show that our method substantially accelerates convergence in quantum subspace-based eigensolvers, highlighting its practical impact for downstream quantum algorithms.

</details>


### [143] [Multiphoton Hong-Ou-Mandel Interference Enables Superresolution of Bright Thermal Sources](https://arxiv.org/abs/2602.19772)
*Aiman Khan,Danilo Triggiani,Vincenzo Tamma*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a quantum optical scheme for imaging transversely displaced thermal sources of arbitrary intensities by employing multiphoton interference with a reference single-photon Fock state at a beamsplitter. Obtaining an analytical form for transverse momenta-resolved $L$-photon probabilities in either output, we show via Fisher information analysis that separation estimators built using interference sampling of multiphoton events exhibit significantly enhanced precision vis-à-vis existing imaging schemes over a wide range of separations and brightness. Even-photon-number coincidences exhibit constant precision in the sub-Rayleigh regime, demonstrating quantum superresolution of our scheme beyond the diffraction limit. For sources emitting on average $N_s\sim1$ photon per frame (such as in IR emission of thermal sources), precision bounds for our scheme scale linearly in $N_s$, exemplifying an enhanced precision of estimators in relation to weak sources $N_s\ll1$, and matching the ultimate quantum scaling. Finally, transverse momenta resolution in the Fourier plane produces finite imaging precisions for intermediate and large source separations using coarse pixel sizes of order $δy\sim100\,μ\mathrm{m}$ for exemplary image spot sizes $σ_x \sim 0.1\, μ\mathrm{m}$, in contrast with existing schemes of diffraction-limited direct imaging and superresolved inversion interferometric imaging that are severely degraded by coarse pixel sizes and have limited use. Combining the relatively straightforward sensing operation of Hong-Ou-Mandel interferometers with multiphoton coincidence detection of arbitrarily bright thermal sources and inner variable resolution of transverse photonic momenta, our scheme offers a robust alternative to non-invasive single-particle tracking and imaging of bright sources in nanoscopic chemical and biological systems.

</details>


### [144] [Unlocking photodetection for quantum sensing with Bayesian likelihood-free methods and deep learning](https://arxiv.org/abs/2602.19792)
*Mateusz Molenda,Lewis A. Clark,Marcin Płodzień,Jan Kolodynski*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: To operate quantum sensors at their quantum limit in real time, it is crucial to identify efficient data inference tools for rapid parameter estimation. In photodetection, the key challenge is the fast interpretation of click-patterns that exhibit non-classical statistics -- the very features responsible for the quantum enhancement of precision. We achieve this goal by comparing Bayesian likelihood-free methods with ones based on deep learning (DL). While the former are more conceptually intuitive, the latter, once trained, provide significantly faster estimates with comparable precision and yield similar predictions of the associated errors, challenging a common misconception that DL lacks such capabilities. We first verify both approaches for an analytically tractable, yet multiparameter, scenario of a two-level system emitting uncorrelated photons. Our main result, however, is the application to a driven nonlinear optomechanical device emitting non-classical light with complex multiclick correlations; in this case, our methods are essential for fast inference and, hence, unlock the possibility of distinguishing different photon statistics in real time. Our results pave the way for dynamical control of quantum sensors that leverage non-classical effects in photodetection.

</details>


### [145] [Rapid state-resolved single-atom imaging of alkaline-earth fermions](https://arxiv.org/abs/2602.19876)
*Thies Plassmann,Leon Schaefer,Meny Menashes,Guillaume Salomon*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Local Hilbert spaces with large dimension are of key interest for quantum information with applications in quantum computing and memories, quantum simulations and metrology. Thanks to its weak coupling to external perturbations, the large ground-state nuclear spin manifold of fermionic alkaline-earth atoms is an exciting resource to explore for quantum information. Simultaneous single atom and state-resolved detection however remains an outstanding challenge limiting the development of novel quantum computing and simulation schemes beyond qubits. Here, we report on a new imaging technique enabling the simultaneous detection of up to four quantum states encoded in the nuclear spin manifold of a single fermionic strontium atom within 100 microseconds, with state-resolved detection fidelities ranging from 0.936 to 0.997. This technique is further used to track the highly coherent nuclear spin dynamics after a quench highlighting the potential of this system for quantum information. These results offer fascinating perspectives for quantum science with multi-electron atoms ranging from qudit-based quantum computing to quantum simulations of the SU(N) Fermi-Hubbard model.

</details>


### [146] [Heat flow through the quantum heat valve coupled to ohmic baths via a master equation approach](https://arxiv.org/abs/2602.19908)
*Antti Vaaranta,Marco Cattaneo,Paolo Muratore-Ginanneschi,Jukka Pekola*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We provide a theoretical model for the non-equilibrium steady state heat flow through a quantum heat valve. The model is based on a master equation approach, where the partial secular approximation has been carefully performed in order to obtain accurate results. Our study assumes an ohmic spectral density for the two thermal baths of the model. This is in contrast with previous treatments of the quantum heat valve, where the baths have been assumed as being structured with a peaked spectral density near the resonance frequency of the resonator. These studies have also taken the resonator to be a part of the open quantum system of interest, which results in double counting of the resonator, as the latter appears both in the spectral density of the bath and as a part of the open system. Although this model accounts for the observations in a satisfactory way, it raises issues regarding its physical interpretation. Our method solves this conceptual problem. We apply it to describe an experiment on a quantum heat valve, showing that it successfully captures the experimental results and improves upon the previous theoretical model, which suffered from the resonator double-counting issue. Our findings confirm that the careful application of the master equation approach, in particular when it comes to the secular approximation, is a useful tool for explaining realistic experimental setups.

</details>


### [147] [Two components relativistic quantum wave equation for scalar bosons](https://arxiv.org/abs/2602.19971)
*Roland Combescot*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We show that, in the relativistic regime, scalar bosons satisfy a quantum wave equation which is quite analogous to the Dirac equation. In contrast with the Klein-Gordon equation it is first order with respect to time derivation. It leads in a regular way to the standard Schrödinger equation in the non-relativistic limit. There are two components for the wave function in this representation for the scalar boson, in a way completely analogous to the four components for the spin $1/2$ fermion in the Dirac equation.

</details>


### [148] [GAP Measures and Wave Function Collapse](https://arxiv.org/abs/2602.19993)
*Roderich Tumulka*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: GAP measures (also known as Scrooge measures) are a natural class of probability distributions on the unit sphere of a Hilbert space that come up in quantum statistical mechanics; for each density matrix $ρ$ there is a unique measure GAP$_ρ$. We describe and prove a property of these measures that was not recognized so far: If a wave function $Ψ$ is GAP$_ρ$ distributed and a collapse occurs, then the collapsed wave function $Ψ'$ is again GAP distributed (relative to the appropriate $ρ'$). This fact applies to collapses due to a quantum measurement carried out by an observer, as well as to spontaneous collapse theories such as CSL or GRW. More precisely, it is the conditional distribution of $Ψ'$, given the measurement outcome (respectively, the noise in CSL or the collapse history in GRW), that is GAP$_{ρ'}$.

</details>


### [149] [A Quantum Internet Protocol Suite Beyond Layering](https://arxiv.org/abs/2602.19998)
*Angela Sara Cacciapuoti,Marcello Caleffi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Layering, the protocol organization principle underpinning the classical Internet, is ill-suited to the Quantum Internet, built around entanglement, which is non-local and stateful. This paper proposes a quantum-native organizational principle based on dynamic composition, which replaces static layering with a distributed orchestration fabric driven by the node local state and in-band control. Each node runs a Dynamic Kernel that i) constructs a local PoA of candidate steps to advance a service intent, and ii) executes the PoA by composing atomic micro-protocols into context-aware procedures (the meta-protocols). Quantum packets carry an in-band control-field (the meta-header) containing the service intent and an append-only list of action-commit records, termed as stamps. Successive nodes exploit this minimal, authoritative history to construct their local PoAs. As quantum packets progress, these local commits collectively induce a network-wide, direct acyclic graph that certifies end-to-end service fulfillment, without requiring global synchronization. In contrast to classical encapsulation, the proposed suite enforces order by certification: dependency-aware local scheduling decides what may run at a certain node, stamps certify what did run and constrain subsequent planning. By embedding procedural control within the quantum packet, the design ensures coherence and consistency between entanglement-state evolution and control-flow, preventing divergence between resource state ad protocol logic, while remaining MP-agnostic and implementation-decoupled. The resulting suite is modular, adaptable to entanglement dynamics, and scalable. It operates correctly with or without optional control-plane hints. Indeed, when present, hints can steer QoS policies, without changing semantics. We argue that dynamic composition is the organizing principle required for a truly quantum-native Internet.

</details>


### [150] [Electrical post-fabrication tuning of aluminum Josephson junctions at room temperature](https://arxiv.org/abs/2602.20002)
*Christian Križan,Maurizio Toselli,Irshad Ahmad,Hadi Khaksaran,Marcus Rommel,Nermin Trnjanin,Janka Biznárová,Mamta Dahiya,Emil Hogedal,Halldór Jakobsson,Andreas Nylander,Jonas Bylander,Per Delsing,Giovanna Tancredi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Josephson junctions are a key element of superconducting quantum technology, serving as the core building blocks of superconducting qubits. We present an experimental study on room-temperature electrical tuning of aluminum junctions, showing that voltage pulses can controllably increase their resistance and adjust the Josephson energy while maintaining qubit quality factors above 1 million. We find that the rate of resistance increase scales exponentially with pulse amplitude during manipulation, after which the spontaneous resistance increase scales proportionally to the amount of manipulation. We show that this spontaneous increase halts at cryogenic temperatures, and resumes again at room temperature. Using our stepwise protocol, we achieve up to a 270% increase in junction resistance, corresponding to a reduction of nearly 2 GHz of the qubit transition frequency. These results establish the achievable range, relaxation behavior, and practical limits of electrical tuning, enabling post-fabrication mitigation of frequency crowding in quantum processors.

</details>


### [151] [Quantum correlation and coherence in a mononuclear nickel-based molecular Magnet](https://arxiv.org/abs/2602.20013)
*S. Bhuvaneswari,R. Muthuganesan,R. Radha*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the behaviors of thermal entanglement, quantum correlation beyond entanglement namely, measurement-induced nonlocality (MIN) and coherence in a nickel radical molecular magnet (Et3NH)[Ni(hfac)2L], whose spin-spin interactions are well described by the Heisenberg model. Using experimentally estimated coupling parameters, we compute the thermal state of the system and analyze the dependence of quantum resources on temperature and magnetic field. The results indicate that the quantum resources of the nickel-radical molecular magnet persist even at room temperature. We show that while negativity (the entanglement measure) rapidly vanishes with increasing temperature and magnetic field, measurement-induced nonlocality and quantum coherence remain comparatively more stable and persist in regions where entanglement is absent. These results highlight the significance of nonclassical correlations beyond entanglement in thermally activated spin systems and suggest that such molecular magnets could serve as viable platforms for quantum information processing in realistic conditions.

</details>


### [152] [Spectroscopy of the Dirac oscillator perturbed by a surface delta potential](https://arxiv.org/abs/2602.20030)
*J. Munárriz,F. Domínguez-Adame,R. P. A. Lima*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study theoretically the level shift of the Dirac oscillator perturbed by any sharply peaked potential approaching a surface delta potential. A Green function method is used to obtain closed expressions for all partial waves and parities.

</details>


### [153] [Nonlinear quantum optomechanics in a Fano-mirror microcavity system](https://arxiv.org/abs/2602.20085)
*Lei Du,Juliette Monsel,Witlef Wieczorek,Janine Splettstoesser*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study a Fano-mirror optomechanical system in the quantum nonlinear regime. In this system, two strongly lossy optical modes hybridize through both coherent and dissipative couplings to form an effective optical mode with a drastically reduced linewidth. This linewidth reduction enables the system to access the single-photon strong-coupling and sideband-resolved regimes simultaneously. We formulate the system dynamics using an effective master-equation approach and benchmark it against quantum Langevin and dressed-state master-equation descriptions. With experimentally realistic parameters, we predict clear quantum signatures, including photon blockade and the generation of mechanical cat states. Our work establishes the Fano-mirror architecture as a promising platform for harnessing single-photon optomechanical nonlinearities for quantum state engineering under achievable experimental conditions.

</details>


### [154] [The quantum superluminality in the tunnel-ionization process of H-like atoms](https://arxiv.org/abs/2602.20106)
*Ossama Kullie,Igor A. Ivanov*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The quantum tunneling time remains the subject of heated debate,
  and one of its most curious features is faster-than-light or
  superluminal tunneling.
  Our tunnel-ionization model of the time-delay, presented in previous work, shows good agreement with the attoclock measurement in the adiabatic and nonadiabatic field calibrations, which also enables the determination of the barrier time-delay.
  In the present work, we show that the tunnel-ionization for H-like atoms with large nuclear charge can be superluminal (quantum superluminality), which in principle can be investigated experimentally using the attoclock scheme.
  We discuss the quantum superluminality in detail for the different regimes of the tunnel-ionization. Our result shows that quantum tunneling faster-than-light is indeed possible, albeit only under somewhat extreme conditions.

</details>


### [155] [CQM: Cyclic Qubit Mappings](https://arxiv.org/abs/2602.20123)
*Maxwell Poster,Sayam Sethi,Jonathan Baker*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum computers show promise to solve select problems otherwise intractable on classical computers. However, noisy intermediate-scale quantum (NISQ) era devices are currently prone to various sources of error. Quantum error correction (QEC) shows promise as a path towards fault tolerant quantum computing. Surface codes, in particular, have become ubiquitous throughout literature for their efficacy as a quantum error correcting code, and can execute quantum circuits via lattice surgery operations. Lattice surgery also allows for logical qubits to maneuver around the architecture, if there is space for it. Hardware used for near-term demonstrations have both spatially and temporally varying error results in logical qubits. By maneuvering logical qubits around the topology, an average logical error rate (LER) can be enforced. We propose cyclic qubit mappings (CQM), a dynamic remapping technique implemented during compilation to mitigate hardware heterogeneity by expanding and contracting logical qubits. In addition to LER averaging, CQM shows initial promise given it's minimal execution time overhead and effective resource utilization.

</details>


### [156] [Experimental characterization of coherent and non-Markovian errors using tangent space decomposition](https://arxiv.org/abs/2602.20128)
*Elia Perego,Andrea Rodriguez-Blanco,K. Birgitta Whaley,Bharath Hebbe Madhusudhana*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate characterization of coherent and non-Markovian errors remains a central challenge in quantum information processing, as conventional benchmarking techniques typically rely on Markovian and time-independent noise assumptions. In practice, however, quantum devices exhibit both systematic coherent miscalibrations and temporally correlated fluctuations, which complicate error diagnosis and mitigation. Here, we apply a technique based on tangent-space decomposition to characterize such error in single-qubit quantum gates implemented on a trapped ion platform. Small imperfections in a quantum operation are treated as perturbations of the target quantum map, represented as tangent vectors in the space of quantum channels. This formulations enables a natural decomposition of the deviation into three components corresponding to coherent, Markovian and non-Markovian processes.The relative weights of these components provide a quantitative measure of the contribution from each type of error mechanism, directly from a single tomographic snapshot. We experimentally validate this method on a single-qubit gates implemented on a trapped $^{40}$Ca$^+$ ion, where control is achieved through laser-driven optical transitions. By analyzing experimentally reconstructed process matrices, expressed in the Pauli Transfer Matrix and Choi representations, we identify and quantify non-Markovian effects arising from controlled injection of slow fluctuations in the experimental environment. We also characterize deterministic coherent miscalibrations using the same technique. This approach provides a physically transparent and experimentally accessible tool for diagnosing complex error sources in quantum control systems.

</details>


### [157] [Quantum Information Approach to Bosonization of Supersymmetric Yang-Mills Fields](https://arxiv.org/abs/2602.20149)
*Radhakrishnan Balu,S. James Gates*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider bosonization of supersymmetry in the context of Wess-Zumino quantum mechanics. Our motivation for this investigation is the flexibility the bosonic fock space affords as any classical probability distribution can be realized on it making it a versatile framework to work with for quantum processes. We proceed by constructing a minimal bosonization of a system with one bosonic and two fermionic degrees of freedom. We iterate this process to construct a tower of SUSY systems that is akin to unfolded Adinkras. We then identify an osp(2|2) symmetry of the system constructed. To build an irreducible representation of the system we induce representations across the sectors, a first to our knowledge, as the previous work have focused on induction only within the bosonic sector. First, we start with a fermionic representation using Clifford algebras and then induce a representation to gl(2|2) and restrict it to osp(2|2). In the second method, we induce a representation from that of the bosonic sector. In both cases, our representations are in terms of qubit operators that provide a way to solve SUSY problems using quantum information based approaches. Depending upon the direction of induction the representations are suitable for implementation on a hybrid qubit and fermionic or bosonic quantum computers.

</details>


### [158] [Quantum simulation in the Heisenberg picture via vectorization](https://arxiv.org/abs/2602.20154)
*Shao-Hen Chiew,Armando Angrisani,Zoë Holmes,Giuseppe Carleo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a general framework for simulating quantum systems in the Heisenberg picture on quantum hardware. Based on the vectorization map, our framework fully exploits the mapping between operators and quantum states, allowing any task defined on Heisenberg operators to be mapped to standard Schrödinger-picture tasks that are naturally accessible via quantum computers and simulators. This yields new or improved protocols for tasks such as operator sampling, the computation of OTOCs/superoperator expectation values and their higher order moments, two-point correlators, and operator stabilizer and entanglement entropies. Our approach is also amenable to implementation, as it inherits the structure and resource requirements of the (forward and time-reversed) Schrödinger-picture quantum simulation problem. We demonstrate this by proposing implementations of our framework for a 2D problem on digital and analog quantum simulators, taking into account device connectivity constraints.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [159] [Thermodynamic and Kinetic Bounds for Finite-frequency Fluctuation-Response](https://arxiv.org/abs/2602.18631)
*Jiming Zheng,Zhiyue Lu*

Main category: cond-mat.stat-mech

TL;DR: 提出了适用于稳态马尔可夫过程在时变扰动下的频域涨落-响应不等式，揭示了谱信噪比受动态活性和熵产生率的普遍约束，并通过F1-ATPase模型展示了如何从功率谱推断耗散。


<details>
  <summary>Details</summary>
Motivation: 探索非平衡系统中时变扰动下的有限频率涨落-响应关系，弥补时间域静态响应理论在频域扩展上的空白。

Method: 基于稳态马尔可夫过程理论，推导出针对屏障扰动、熵扰动以及时变扰动下状态-电流观测量的频域涨落-响应不等式。

Result: 发现谱信噪比（SNR）被动态活性所限制；对于状态-电流观测量，SNR受限于熵产生率（EPR），并在F1-ATPase模型中验证了该结果。

Conclusion: 这些有限频率的不等式为通过功率谱测量推断系统耗散提供了实用途径。

Abstract: Fluctuation-response relations encode fundamental constraints on nonequilibrium systems. While time-domain static response is bounded by activity and entropy production, finite-frequency extensions for time-dependent perturbations remain largely unexplored. Here, we derive frequency-domain fluctuation-response inequalities for steady-state Markov processes with time-dependent perturbations. For barrier and entropic perturbations, the spectral signal-to-noise ratio (SNR) is universally bounded by dynamical activity. Furthermore, for state-current observables, the SNR is bounded by the entropy production rate (EPR). We illustrate our results using the F1-ATPase model to infer EPR. These finite-frequency inequalities provide a practical route to infer dissipation from power spectra measurements.

</details>


### [160] [peapods: A Rust-Accelerated Monte Carlo Package for Ising Spin Systems](https://arxiv.org/abs/2602.19045)
*Yan Ru Pei*

Main category: cond-mat.stat-mech

TL;DR: peapods是一个开源Python包，用于在任意维度超立方格点上进行伊辛自旋系统的蒙特卡洛模拟，结合Rust核心以实现高性能计算。


<details>
  <summary>Details</summary>
Motivation: 为了高效且灵活地模拟具有任意耦合常数的伊辛模型，同时兼顾易用性与计算性能。

Method: 使用Rust编写计算核心并通过PyO3集成到Python中，实现了Metropolis、Gibbs、Swendsen-Wang、Wolff算法以及并行回火方法，并采用Rayon实现并行计算。

Result: 成功实现了多种蒙特卡洛更新算法和并行化支持，并通过二维伊辛模型的Binder累积量有限尺寸标度验证了程序的正确性。

Conclusion: peapods提供了一个高性能、易扩展的框架，适用于研究广泛伊辛自旋系统。

Abstract: We present peapods (github.com/PeaBrane/peapods), an open-source Python package for Monte Carlo simulation of Ising spin systems with arbitrary coupling constants on arbitrary-dimensional hypercubic lattices with periodic boundary conditions. The computational core is written in Rust and exposed to Python via PyO3, combining the ergonomic interface of Python with the performance of compiled, memory-safe code. The package implements Metropolis and Gibbs single-spin-flip algorithms, Swendsen--Wang and Wolff cluster updates, and parallel tempering. Replica-level parallelism is achieved through the Rayon work-stealing scheduler. We validate the implementation against the exact critical temperature of the two-dimensional Ising model via finite-size scaling of the Binder cumulant.

</details>


### [161] [Critical Scaling and Metabolic Regulation in a Ginzburg--Landau Theory of Cognitive Dynamics](https://arxiv.org/abs/2602.19023)
*Gunn Kim*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种现象学有效场论，将生物智能视为由持续代谢流维持的宏观序参量，通过变分自由能原理推导出信息容量和结构 susceptibility 的闭式表达式，并预测了在临界点附近结构 susceptibility 的普适代数发散行为，解释了皮层雪崩中观测到的标度律。


<details>
  <summary>Details</summary>
Motivation: 试图从宏观物理视角解释生物智能的涌现机制，尤其是认知功能如何在非平衡稳态下接近临界性而实现高效信息处理，并为神经动力学中的标度现象提供无需微观细节的理论基础。

Method: 将认知建模为受变分自由能支配的粗粒化神经活动场，采用高斯最大熵近似构建有效场论，推导出信息容量与结构 susceptibility 的解析表达式，并结合非平衡稳态与临界性分析来刻画正常与病理认知状态。

Result: 发现结构 susceptibility 在结构刚度 K 趋近失稳阈值时呈现普适的代数发散 χ∼K^(-3/2)，指数 γ=3/2 与均场分支过程普适类一致，解释了皮层雪崩大小指数 τ≈3/2 的实验观测；提出成年认知是代谢钉扎在 Γ≡K/α≈1 附近的非平衡稳态，病理衰退则对应于结构稳定性破坏引发的去局域化转变。

Conclusion: 该理论为大脑认知功能的临界性提供了宏观物理解释框架，无需依赖微观等价假设，同时对注意力标度、意识状态改变和经颅磁刺激响应等现象给出了可检验的预测，有望统一理解健康与疾病状态下的脑动力学。

Abstract: We formulate a phenomenological effective field theory in which biological intelligence emerges as a macroscopic order parameter sustained by continuous metabolic flux. By modeling cognition as a coarse-grained neural activity field governed by a variational free energy, we derive closed-form expressions for information capacity and structural susceptibility using a Gaussian maximum entropy approximation. The theory predicts a universal algebraic divergence of the susceptibility, $χ\sim K^{-3/2}$, as the structural stiffness $K$ approaches the instability threshold. The exponent $γ= 3/2$ is consistent with the mean-field branching process universality class, thereby providing a theoretical rationale for the observed avalanche size exponent $τ\approx 3/2$ in cortical dynamics without invoking microscopic equivalence. We identify adult cognition as a metabolically pinned non-equilibrium steady state maintained near the critical regime $Γ\equiv K/α\approx 1$ by continuous metabolic regulation, while pathological decline corresponds to a delocalization transition triggered by the violation of structural stability conditions. The framework generates concrete, falsifiable predictions for attention scaling, altered states of consciousness, and transcranial magnetic stimulation responses, each of which can be tested against existing neuroimaging and electrophysiological datasets.

</details>


### [162] [Two-parameter families of MPO integrals of motion in Heisenberg spin chains](https://arxiv.org/abs/2602.19741)
*Vsevolod I. Yashin*

Main category: cond-mat.stat-mech

TL;DR: 本文发现了XXX、XXZ和XYZ海森堡自旋链哈密顿量的两参数矩阵乘积算符（MPO）守恒量族，并提出了一种寻找此类守恒量的符号代数方法。


<details>
  <summary>Details</summary>
Motivation: 受Fendley等人关于XYZ模型可积性研究的启发，试图扩展其单参数MPO守恒量至更一般的多参数情形，以深化对海森堡模型可积结构的理解。

Method: 采用符号代数方法构造与海森堡哈密顿量对易的两参数MPO家族，并验证其在XXX、XXZ和XYZ情况下的普适性。

Result: 成功构造出两参数的MPO守恒量族，涵盖XXX、XXZ和XYZ三种情形，推广了此前的单参数结果。

Conclusion: 该结果揭示了海森堡模型中更丰富的可积结构，所提出的符号方法可能有助于发现新的可积系统或应用于非平衡态物理等领域。

Abstract: Recently, Fendley et al. (2025) [arXiv:2511.04674] revealed a new way to demonstrate the integrability of XYZ Heisenberg model by constructing a one-parameter family of integrals of motion in the matrix product operator (MPO) form. In this short note, I report on the discovery of two-parameter families of MPOs that commute with with the Heisenberg spin chain Hamiltonian in the XXX, XXZ, and XYZ cases. I describe a symbolic algebra approach for finding such integrals of motion and speculate about possible applications.

</details>


### [163] [Thermodynamic Geometry of Classical and Quantum Statistics in the Relativistic Regime](https://arxiv.org/abs/2602.19759)
*Hosein Mohammadzadeh,Zahra Ebadi,Omid Yahyayi Monem,Mohammad Hossein Naghizadeh Ardabili*

Main category: cond-mat.stat-mech

TL;DR: 研究了相对论性经典和量子理想气体的热力学几何，分析了粒子质量与空间维度的影响，发现热力学曲率符号在玻色子和费米子中分别保持正负，且曲率奇点随质量变化发生位移。


<details>
  <summary>Details</summary>
Motivation: 探讨相对论效应对理想气体热力学几何的影响，特别是粒子质量和空间维度的作用。

Method: 基于配分函数导出的Fisher-Rao信息度量，结合相对论能量-动量关系和密度态函数，对麦克斯韦-玻尔兹曼、玻色-爱因斯坦和费米-狄拉克统计进行分析。二维情况获得解析解，三维通过数值方法研究。

Result: 热力学曲率符号在相对论区域仍保持统计特性：玻色子为正，费米子为负；曲率奇点从非相对论临界点移动到μ=mc²的质量依赖阈值；计算了相对论性玻色-爱因斯坦凝聚温度，得到质量修正项。

Conclusion: 热力学几何能统一描述相对论性统计系统，揭示量子统计、相对论运动学与临界行为之间的相互作用。

Abstract: We investigate the thermodynamic geometry of classical and quantum ideal gases in the relativistic regime, with particular emphasis on the effects of particle mass and spatial dimensionality. Relativistic kinematics is incorporated through the full energy-momentum dispersion relation and the corresponding relativistic density of states. Using the Fisher-Rao information metric derived from the partition function, we analyze the thermodynamic curvature for Maxwell-Boltzmann, Bose-Einstein, and Fermi-Dirac statistics. Exact analytical expressions are obtained in two spatial dimensions, while the three-dimensional case is studied numerically. We show that the thermodynamic curvature preserves its characteristic sign-positive for bosons and negative for fermions; even in the relativistic regime, reflecting effective attractive and repulsive statistical interactions, respectively. A distinctive relativistic effect is the shift of curvature singularities from the non-relativistic critical point to a mass-dependent threshold at $μ=mc^{2}$. In addition, the relativistic Bose-Einstein condensation temperature is evaluated, revealing explicit mass-dependent corrections to the non-relativistic result. These findings provide a unified geometric perspective on relativistic statistical systems and clarify the interplay between quantum statistics, relativistic kinematics, and critical behavior.

</details>


### [164] [Separation of the Kibble-Zurek Mechanism from Quantum Criticality](https://arxiv.org/abs/2602.19865)
*R. Jafari,Alireza Akbari*

Main category: cond-mat.stat-mech

TL;DR: 该研究挑战了Kibble-Zurek机制与量子临界性之间普遍关联的传统观点，发现在某些情况下缺陷密度的抑制可快于Kibble-Zurek预测，而通过非临界点的淬火仍可能表现出类Kibble-Zurek标度行为。


<details>
  <summary>Details</summary>
Motivation: 探究Kibble-Zurek机制是否普遍适用于所有量子临界点淬火过程，并澄清缺陷生成与平衡态临界性之间的关系。

Method: 基于代表广泛一类准一维费米系统的模型，分析不同淬火路径下拓扑缺陷产生的动力学行为。

Result: 发现缺陷密度可在穿越临界点时比Kibble-Zurek预测更快地被抑制；同时，在穿越非临界点时仍可能出现类似Kibble-Zurek的标度行为。

Conclusion: Kibble-Zurek标度行为并不总是依赖于是否穿过量子临界点，其普适性取决于具体的动力学条件而非仅由平衡态临界指数决定。

Abstract: When a system is swept through a quantum critical point (QCP), the Kibble-Zurek mechanism predicts that the average number of topological defects follows a universal power-law scaling with the ramp time scale. This scaling behavior is determined by the equilibrium critical exponents of the underlying phase transition. We show that the correspondence between Kibble-Zurek scaling and quantum criticality does not hold generally. In particular, the defect density can exhibit a suppression faster than the Kibble-Zurek prediction even when the quench crosses a critical point, while conventional Kibble-Zurek scaling may persist for quenches through a non-critical point. Our results, based on models representative of a broad class of quasi-one-dimensional Fermi systems, identify the dynamical conditions under which universal defect scaling emerges and clarify the relation between defect generation and equilibrium criticality.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [165] [An Electricity Market with Reactive Power Trading: Incorporating Dynamic Operating Envelopes](https://arxiv.org/abs/2602.18668)
*Zeinab Salehi,Elizabeth L. Ratnam,Yijun Chen,Ian R. Petersen,Guodong Shi,Duncan S. Callaway*

Main category: eess.SY

TL;DR: 本文提出了一种考虑配电网约束的电力市场设计，支持用户通过点对点（P2P）交易共享屋顶太阳能发电和无功功率，利用动态运行包络线管理电压和热限制，并在IEEE 13节点测试馈线上进行验证。


<details>
  <summary>Details</summary>
Motivation: 为了提升分布式能源资源（DERs）在配电网中的集成能力，需要一种能够管理电网约束（如电压和热限制）并激励用户参与能源共享的电力市场机制。

Method: 将电力市场建模为基于优化的问题，引入客户特定的动态操作包络线（DOEs）来管理馈线上的电压和热限制，并设计包含有功和无功功率P2P交易的竞争性均衡机制。

Result: 所提出的市场设计能够在满足电网安全约束的同时，实现用户间的有效能源共享与利润分配，改善馈线电压分布。

Conclusion: 该方法通过动态操作包络线实现了对配电网约束的有效管理，支持了DER的高效集成和P2P能源交易的经济激励，具备实际应用潜力。

Abstract: Electricity market design that accounts for grid constraints such as voltage and thermal limits at the distribution level can increase opportunities for the grid integration of Distributed Energy Resources (DERs). In this paper, we consider rooftop solar backed by battery storage connected to a distribution grid. We design an electricity market to support customers sharing rooftop generation in excess of their energy demand, where customers earn a profit through peer-to-peer (P2P) energy trading. Our proposed electricity market also incorporates P2P reactive power trading to improve the voltage profile across a distribution feeder. We formulate the electricity market as an optimization-based problem, where voltage and thermal limits across a feeder are managed through the assignment of customer-specific dynamic operating envelopes (DOEs). The electricity market equilibrium is referred to as a competitive equilibrium, which is equivalent to a Nash equilibrium in a standard game. Our proposed market design is benchmarked using the IEEE 13-node test feeder.

</details>


### [166] [Seeking Nash Equilibrium in Non-cooperative Quadratic Games Under Delayed Information Exchange](https://arxiv.org/abs/2602.18751)
*Kaichen Jiang,Yuyue Yan,Mingda Yue,Yuhu Wu*

Main category: eess.SY

TL;DR: 本文研究了在非合作二次博弈中，当所有智能体交换其延迟策略信息时，如何寻求纳什均衡（NE）。通过设计估计机制和基于Lyapunov-Krasovskii方法分析，证明了多步延迟下渐近收敛到NE，单步延迟下在学习率限制下可指数收敛。


<details>
  <summary>Details</summary>
Motivation: 在非合作博弈中，由于信息交换存在延迟，传统的最佳响应算法难以直接应用，因此需要设计新的机制来处理延迟信息并确保收敛到纳什均衡。

Method: 设计了一种估计机制，使每个智能体能够估计当前的策略组合，并基于该估计进行最佳响应；利用Lyapunov-Krasovskii泛函方法分析系统动态的收敛性。

Result: 在多步延迟信息交换下，策略动态可渐近收敛到纳什均衡；在单步延迟下，若学习率小于某一上界，则可实现指数收敛，同时提出了导致NE不稳定的学习率下界。

Conclusion: 所提出的估计机制与策略更新规则能有效处理延迟信息，在合理条件下保证系统收敛到纳什均衡，为延迟环境下的分布式博弈学习提供了理论支持。

Abstract: In this paper, we investigate the seeking of Nash equilibrium (NE) in a non-cooperative quadratic game where all agents exchange their delayed strategy information with their neighbors. To extend best-response algorithms to the delayed information setting, an estimation mechanism for each agent to estimate the current strategy profile is designed. Based on the best-response strategy to the estimations, the strategy profile dynamics of all agents is established, which is revealed to converge asymptotically to the NE when agents exchange multi-step-delay information via the Lyapunov-Krasovskii functional approach. In the scenario where agents exchange one-step-delay information, the exponential convergence of the strategy profile dynamics to the NE can be guaranteed by restricting the learning rate to less than an upper bound. Moreover, a lower bound on the learning rate for instability of the NE is proposed. Numerical simulations are provided for verifying the developed results.

</details>


### [167] [A Stochastic Gradient Descent Approach to Design Policy Gradient Methods for LQR](https://arxiv.org/abs/2602.18933)
*Bowen Song,Simon Weissmann,Mathias Staudigl,Andrea Iannelli*

Main category: eess.SY

TL;DR: 提出了一种基于随机梯度下降（SGD）框架的数据驱动策略梯度算法，用于线性二次调节器问题，通过两种方案估计策略梯度，并分析其收敛性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在线性二次调节器问题中缺乏精确模型时的策略优化难题，设计能够直接从随机轨迹数据中学习的策略梯度方法。

Method: 采用间接在线辨识方法和直接零阶方法来估计策略梯度，将梯度估计建模为有偏的随机梯度 oracle，并利用SGD理论分析收敛性。

Result: 推导出SGD在有偏梯度oracle下渐近收敛到最优策略的充分条件，并据此设计梯度估计参数；数值实验验证了方法的有效性。

Conclusion: 所提出的两种数据驱动梯度估计方法均能有效逼近最优策略，且各有优劣，适用于不同场景。

Abstract: In this work, we propose a stochastic gradient descent (SGD) framework to design data-driven policy gradient descent algorithms for the linear quadratic regulator problem. Two alternative schemes are considered to estimate the policy gradient from stochastic trajectory data: (i) an indirect online identification based approach, in which the system matrices are first estimated and subsequently used to construct the gradient, and (ii) a direct zeroth-order approach, which approximates the gradient using empirical cost evaluations. In both cases, the resulting gradient estimates are random due to stochasticity in the data, allowing us to use SGD theory to analyze the convergence of the associated policy gradient methods. A key technical step consists of modeling the gradient estimates as suitable stochastic gradient oracles, which, because of the way they are computed, are inherently based. We derive sufficient conditions under which SGD with a biased gradient oracle converges asymptotically to the optimal policy, and leverage these conditions to design the parameters of the gradient estimation schemes. Moreover, we compare the advantages and limitations of the two data-driven gradient estimators. Numerical experiments validate the effectiveness of the proposed methods.

</details>


### [168] [Cooperative Transportation Without Prior Object Knowledge via Adaptive Self-Allocation and Coordination](https://arxiv.org/abs/2602.19070)
*Jie Song,Yang Bai,Naoki Wakamiya*

Main category: eess.SY

TL;DR: 提出了一种无需先验信息的多智能体协同运输框架，通过局部感知、吸引场和CBF机制实现自主组队与均衡分布。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在未知环境中对不同大小货物进行协同运输时缺乏先验知识、易发生碰撞和分配不均的问题。

Method: 利用局部感知构建基于密度函数的吸引场，结合自适应加权Centroidal Voronoi Tessellation（CVT）实现智能体自组织，并引入控制屏障函数（CBF）保证安全距离与均匀分布。

Result: 仿真结果表明该框架能同时、协调且无碰撞地运输多个不同尺寸的货物。

Conclusion: 所提方法实现了无需全局信息的自主团队形成与负载均衡，提升了多智能体协同运输的鲁棒性与安全性。

Abstract: This work proposes a novel cooperative transportation framework for multi-agent systems that does not require any prior knowledge of cargo locations or sizes. Each agent relies on local sensing to detect cargos, recruit nearby agents, and autonomously form a transportation team with an appropriate size. The core idea is that once an agent detects a cargo within its sensing range, it generates an attraction field represented by a density function, which pulls neighboring agents toward the cargo. When multiple cargos are present, the attraction fields generated by different agents are adaptively weighted and combined with Centroidal Voronoi Tessellation (CVT), enabling agents to self-organize into balanced formations while automatically allocating more agents to larger cargos. To prevent agents from clustering on one side of a large cargo, a Control Barrier Function (CBF)-based mechanism is introduced to enforce safe inter-agent distances and promote a uniform, symmetric distribution of agents around each cargo, which is essential for stable transportation. Simulation results demonstrate that the proposed framework can simultaneously transport multiple cargos of different sizes in a coordinated and collision-free manner.

</details>


### [169] [On the Stability of Spatially Distributed Cavity Laser and Boundary of Resonant Beam SLIPT](https://arxiv.org/abs/2602.19238)
*Mingliang Xiong,Zeqian Guo,Qingqing Zhang,Qingwen Liu,Gang Wang,Gang Li,Bin He*

Main category: eess.SY

TL;DR: 本文研究了空间分布式腔体（SDC）激光器在长距离共振光束生成中的基本限制，提出了两种算法来量化稳定运行的最大可接受公差，并通过实验验证了使用精密可调元件实现长距离光束传输的可行性。


<details>
  <summary>Details</summary>
Motivation: 为了克服在米级工作距离下由于腔体稳定性约束、制造/装配公差和衍射损耗带来的挑战，推动SLIPT技术在物联网设备中的应用。

Method: 进行了理论分析，研究了腔体稳定性和光束特性，提出了一种基于二分搜索的蒙特卡洛模拟算法和一种线性近似算法来量化最大可接受公差。

Result: 数值结果表明，随着距离增加，稳定区域急剧收缩；固定组件系统中0.01毫米的可接受公差将传输距离限制在2米以内。实验验证显示，通过装配时调整稳定区域，传输距离可扩展至2.8米。

Conclusion: 该研究为实现稳定的长距离SDC系统提供了重要的理论见解和实用设计指南。

Abstract: Spatially distributed cavity (SDC) lasers are a promising technology for simultaneous light information and power transfer (SLIPT), offering benefits such as increased mobility and intrinsic safety, which are advantageous for various Internet of Things (IoT) devices. \mll However, achieving beam transmission over meter-level long working distances presents significant challenges from cavity stability constraints, manufacturing/assembly tolerances, and diffraction losses\mrr. This paper conducts a theoretical investigation of the fundamental restrictions limiting long-range resonant beam generation. We investigate cavity stability and beam characteristics, and propose a binary-search-based Monte Carlo simulation algorithm as well as a linear approximation algorithm to quantify the maximum acceptable tolerances for stable operation. \mll Numerical results indicate that the stable region contracts sharply as distance increases. For fixed-component systems, an acceptable tolerance of 0.01 mm restricts the achievable transmission distance to less than 2 m. \mrr To address this limitation, we also prove the feasibility of long-range beam formation using precision adjustable elements, paving the way for advanced engineering applications. \mll Experimental results verified this assumption, demonstrating that by tuning the stable region during assembly, the transmission distance could be extended to 2.8 m. \mrr This work provides essential theoretical insights and practical design guidelines for realizing stable, long-range SDC systems.

</details>


### [170] [A Power Market Model with Hypersaclers and Modular Datacenters](https://arxiv.org/abs/2602.19310)
*Yihsu Chen,Abel Souza,Fargol Nematkhah,Andrew L. Liu*

Main category: eess.SY

TL;DR: 该研究提出了一种电力市场模型，允许超大规模企业将大语言模型推理任务迁移到与可再生能源共址的分布式模块化数据中心（MDC），以利用被弃用的绿色能源。模型通过互补性问题形式化，并证明了解的存在性和唯一性。案例分析显示，单纯要求MDC披露碳排放未必带来显著减排，但结合购电协议可缓解此问题并降低电网拥塞。


<details>
  <summary>Details</summary>
Motivation: 应对AI算力需求激增与可再生能源弃电并存的问题，探索如何通过工作负载迁移实现低碳计算。

Method: 构建了一个包含超大规模企业、MDC、消费者、发电方和电网运营商的电力市场模型，将其表述为互补性问题，并在IEEE RTS-24节点系统上进行案例分析。

Result: 发现即使要求MDC披露碳排放，由于合约重分配（contract-reshuffling）现象，选择低排放MDC难以实现显著减排；而引入购电协议可缓解该问题，并在超大规模企业更关注成本时减少系统拥塞。

Conclusion: 单纯依赖MDC的碳信息披露不足以有效降低碳排放，需结合电力市场机制设计（如购电协议）来引导真正的绿色计算行为。

Abstract: The rapid adoption of AI has led the growth of computational demand, with large language models (LLMs) at the forefront since ChatGPT's debut in 2022. Meanwhile, large amounts of renewable energy have been deployed but, ultimately, curtailed due to transmission congestion and inadequate demand. This work develops a power market model that allows hyperscalers to spatially migrate LLM inference workloads to geo-distributed modular datacenters (MDCs), which are co-located with near renewable sources of energy at the edge of the network. We introduce the optimization problems faced by the hyperscaler and MDCs in addition to consumers, producers, and the electric grid operator, where the hyerscaler enters an agreement to lease MDCs while ensuring that the required service level objectives (SLOs) are met. The overall market model is formulated as a complementarity problem, where the proof is provided showing the existence and uniqueness of the solutions. When applying the model to an IEEE RTS-24 bus case study, we show that even with a provision that requires MDCs to disclose the CO$_2$ emissions associated with their energy supply sources, renting less polluting MDCs is unlikely to yield meaningful emission reductions due to so-called contract-reshuffling. The situation can be mitigated when conventional loads are supplied by forward contracts through power purchase agreements. This also leads to a decline in system congestion when the hyperscaler becomes increasingly cost-aware.

</details>


### [171] [Decentralized Attack-Resilient CLF-Based Control of Nonlinear DC Microgrids under FDI Attacks](https://arxiv.org/abs/2602.19386)
*Mohamadamin Rajabinezhad,Muratkhan Abdirash,Xiaofan Cui,Shan Zuo*

Main category: eess.SY

TL;DR: 提出了一种基于控制李雅普诺夫函数的分布式抗攻击控制框架，用于非线性直流微电网，能够在无需全局信息的情况下抵御无界虚假数据注入攻击，具有良好的稳定性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有控制方法在面对非线性运行区域和各类虚假数据注入攻击时缺乏鲁棒性与可扩展性，难以满足未来直流微电网的安全需求。

Method: 基于端口-哈密顿系统模型，设计了一种去中心化的AR-CLF-QP控制框架，引入自适应韧性项以动态补偿包括无界控制输入扰动在内的多种攻击。

Result: 仿真结果表明，所提控制器在遭受无界攻击时仍能保持大信号稳定性，表现出优于传统方法的抗攻击能力与动态性能。

Conclusion: 该方法实现了完全去中心化、强韧性、可扩展且物理一致的直流微电网控制，为下一代微电网提供了可行的解决方案。

Abstract: The growing deployment of nonlinear, converter interfaced distributed energy resources (DERs) in DC microgrids demands decentralized controllers that remain stable and resilient under a wide range of cyber-physical attacks and disturbances. Traditional droop or linearized control methods lack resilience and scalability, especially when the system operates in its nonlinear region or faces diverse false-data-injection (FDI) attacks on control inputs. In this work, we develop a Decentralized Attack-Resilient Control Lyapunov Function (AR-CLF) based Quadratic Program (QP) control framework for nonlinear DC microgrids that ensures large-signal stability in a fully decentralized manner. Built upon the port-Hamiltonian representation, the proposed controller dynamically compensates diverse attacks including exponentially unbounded control-input perturbations beyond the bounded-attack regime commonly assumed in existing methods, through an adaptive resilience term, without requiring global information. Simulations validate that the AR-CLF based QP controller achieves superior stability and resilience against unbounded attacks, paving the way for scalable, attack-resilient, and physically consistent control of next-generation DC microgrids.

</details>


### [172] [A Reinforcement Learning-based Transmission Expansion Framework Considering Strategic Bidding in Electricity Markets](https://arxiv.org/abs/2602.19421)
*Tomonari Kanazawa,Hikaru Hoshino,Eiko Furutani*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Transmission expansion planning in electricity markets is tightly coupled with the strategic bidding behaviors of generation companies. This paper proposes a Reinforcement Learning (RL)-based co-optimization framework that simultaneously learns transmission investment decisions and generator bidding strategies within a unified training process. Based on a multiagent RL framework for market simulation, the proposed method newly introduces a design policy layer that jointly optimizes continuous/discrete transmission expansion decisions together with strategic bidding policies. Through iterative interaction between market clearing and investment design, the framework effectively captures their mutual influence and achieves consistent co-optimization of expansion and bidding decisions. Case studies on the IEEE 30-bus system are provided for proof-of-concept validation of the proposed co-optimization framework.

</details>


### [173] [Sizing of Battery Considering Renewable Energy Bidding Strategy with Reinforcement Learning](https://arxiv.org/abs/2602.19428)
*Taiyo Mantani,Hikaru Hoshino,Tomonari Kanazawa,Eiko Furutani*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes a novel computationally efficient algorithm for optimal sizing of Battery Energy Storage Systems (BESS) considering renewable energy bidding strategies. Unlike existing two-stage methods, our algorithm enables the cooptimization of both by updating the BESS size during the training of the bidding policy, leveraging an extended reinforcement learning (RL) framework inspired by advancements in embodied cognition. By integrating the Deep Recurrent Q-Network (DRQN) with a distributed RL framework, the proposed algorithm effectively manages uncertainties in renewable generation and market prices while enabling parallel computation for efficiently handling long-term data.

</details>


### [174] [A mixed Hinfty-Passivity approach for Leveraging District Heating Systems as Frequency Ancillary Service in Electric Power Systems](https://arxiv.org/abs/2602.19486)
*Xinyi Yi,Ioannis Lestas*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper introduces a mixed H-infinity-passivity framework that enables district heating systems (DHSs) with heat pumps to support electric-grid frequency regulation. The analysis illustrates how the DHS regulator influences coupled electro-thermal frequency dynamics and provides LMI conditions for efficient controller design. We also present a disturbance-independent temperature regulator that ensures stability and robustness against heat-demand uncertainty. Simulations demonstrate improved frequency-control dynamics in the electrical power grid while maintaining good thermal performance in the DHS.

</details>


### [175] [Co-Optimization of Network Topology and Variable Impedance Devices under Dynamic Line Ratings in Power Transmission Systems](https://arxiv.org/abs/2602.19587)
*Junseon Park,Hyeongon Park,Rahul K. Gupta*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Power system operators are increasingly deploying Grid Enhancing Technologies (GETs) to mitigate operational challenges such as line and transformer congestion, and voltage violations. These technologies, including Network Topology Optimization (NTO), Variable Impedance Devices (VIDs), and Dynamic Line Rating (DLR), enhance system flexibility and enable better utilization of existing network assets. However, as the deployment of multiple GETs grows, effective coordination among them becomes essential to fully realize their potential benefits. This paper presents a co-optimization framework that models and coordinates NTO, VID, and DLR within a unified optimization scheme to alleviate network congestion and minimize operational costs. The NTO formulation is developed using a node-breaker model, offering finer switching granularity and improved operational flexibility. The inclusion of VIDs introduces nonlinear and non-convex relationships in the optimization problem. DLR takes into account of weather conditions, primarily wind speed and ambient temperature, enabling adaptive utilization of transmission capacity. The proposed framework is validated on standard IEEE benchmark test systems, demonstrating its effectiveness under varying numbers and placements of impedance controllers.

</details>


### [176] [Multicellular Feedback Control Strategies in Synthetic Microbial Consortia: From Embedded to Distributed Control](https://arxiv.org/abs/2602.19666)
*Mario di Bernardo*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Living organisms rely on endogenous feedback mechanisms to maintain homeostasis in the presence of uncertainty and environmental fluctuations. An emerging challenge at the interface of control systems engineering and synthetic biology is the design of reliable feedback strategies to regulate cellular behavior and collective biological functions. In this article, we review recent advances in multicellular feedback control, where sensing, computation, and actuation are distributed across different cell populations within synthetic microbial consortia, giving rise to biological multiagent control systems governed by molecular communication. From a control-theoretic perspective, these consortia can be interpreted as distributed biomolecular control systems, where coordination among populations replace embedded regulation. We survey theoretical frameworks, control architectures, and modeling approaches, ranging from aggregate population-level dynamics to spatially aware agent-based simulations, and discuss experimental demonstrations in engineered \textit{Escherichia coli} consortia. We highlight how distributing control functions across populations can reduce metabolic burden, mitigate retroactivity, improve robustness to uncertainty, and enable modular reuse of control components. Beyond regulation of gene expression, we discuss the emerging problem of population composition control, where coordination among growing and competing cell populations becomes an integral part of the control objective. Finally, we outline key open challenges that must be addressed before multicellular control strategies can be deployed in real-world applications such as biomanufacturing, environmental remediation, and therapeutic systems. These challenges span modeling and simulation, experimental platform development, coordination and composition control, and long-term evolutionary stability.

</details>


### [177] [Impact of Training Dataset Size for ML Load Flow Surrogates](https://arxiv.org/abs/2602.19667)
*Timon Conrad,Changhun Kim,Johann Jäger,Andreas Maier,Siming Bayer*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Efficient and accurate load flow calculations are a bedrock of modern power system operation. Classical numerical methods such as the Newton-Raphson algorithm provide highly precise results but are computationally demanding, which limits their applicability in large-scale scenario studies and optimization in time-critical contexts. Research has shown that machine learning approaches can approximate load flow results with high accuracy while substantially reducing computation time.
  Sample efficiency, i.e., the ability to achieve high accuracy with limited training dataset size, is still insufficiently researched, especially in grids with a fixed topology. This paper presents a systematic investigation of the sample efficiency of a Multilayer Perceptron and two Graph Neural Network variants on a dataset based on a modified IEEE 5-bus system. The results for this grid size show that Graph Neural Networks achieve the lowest losses. However, the availability of large training datasets remains the dominant factor influencing performance compared to architecture choice.

</details>


### [178] [High-Altitude Platforms in the Low-Altitude Economy: Bridging Communication, Computing, and Regulation](https://arxiv.org/abs/2602.19784)
*Bang Huang,Eddine Youcef Belmekki,Mohamed-Slim Alouini*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Low-Altitude Economy (LAE) is rapidly emerging as a new technological and industrial frontier, with unmanned aerial vehicles (UAVs), electric vertical takeoff and landing (eVTOL) aircraft, and aerial swarms increasingly deployed in logistics, infrastructure inspection, security, and emergency response. However, the large-scale development of the LAE demands a reliable aerial foundation that ensures not only real-time connectivity and computational support, but also navigation integrity and safe airspace management for safety-critical operations. High-Altitude Platforms (HAPs), positioned at around 20 km, provide a unique balance between wide-area coverage and low-latency responsiveness. Compared with low earth orbit (LEO) satellites, HAPs are closer to end users and thus capable of delivering millisecond-level connectivity, fine-grained regulatory oversight, and powerful onboard computing and caching resources. Beyond connectivity and computation, HAPs-assisted sensing and regulation further enable navigation integrity and airspace trust, which are essential for safety-critical UAV and eVTOL operations in the LAE. This article proposes a five-stage evolutionary roadmap for HAPs in the LAE: from serving as aerial infrastructure bases, to becoming super back-ends for UAV, to acting as frontline support for ground users, further enabling swarm-scale UAV coordination, and ultimately advancing toward edge-air-cloud closed-loop autonomy. In parallel, HAPs complement LEO satellites and cloud infrastructures to form a global-regional-local three-tier architecture. Looking forward, HAPs are expected to evolve from simple platforms into intelligent hubs, emerging as pivotal nodes for air traffic management, intelligent logistics, and emergency response. By doing so, they will accelerate the transition of the LAE toward large-scale deployment, autonomy, and sustainable growth.

</details>


### [179] [Rendezvous and Docking of Mobile Ground Robots for Efficient Transportation Systems](https://arxiv.org/abs/2602.19862)
*Lars Fischer,Daniel Flögel,Sören Hohmann*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In-Motion physical coupling of multiple mobile ground robots has the potential to enable new applications like in-motion transfer that improves efficiency in handling and transferring goods, which tackles current challenges in logistics. A key challenge lies in achieving reliable autonomous in-motion physical coupling of two mobile ground robots starting at any initial position. Existing approaches neglect the modeling of the docking interface and the strategy for approaching it, resulting in uncontrolled collisions that make in-motion physical coupling either impossible or inefficient. To address this challenge, we propose a central mpc approach that explicitly models the dynamics and states of two omnidirectional wheeled robots, incorporates constraints related to their docking interface, and implements an approaching strategy for rendezvous and docking. This novel approach enables omnidirectional wheeled robots with a docking interface to physically couple in motion regardless of their initial position. In addition, it makes in-motion transfer possible, which is 19.75% more time- and 21.04% energy-efficient compared to a non-coupling approach in a logistic scenario.

</details>


### [180] [A Stochastic Tube-Based MPC Framework with Hard Input Constraints](https://arxiv.org/abs/2602.19867)
*Carlo Karam,Matteo Tacchi,Mirko Fiacchini*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work presents a stochastic tube-based model predictive control framework that guarantees hard input constraint satisfaction for linear systems subject to unbounded additive disturbances. The approach relies on a structured design of probabilistic reachable sets that explicitly incorporates actuator saturation into the error dynamics and bounds the resulting nonlinearity within a convex embedding. The proposed controller retains the computational efficiency and structural advantages of stochastic tube-based approaches while ensuring state chance constraint satisfaction alongside hard input limits. Recursive feasibility and mean-square stability are established for our scheme, and a numerical example illustrates its effectiveness.

</details>


### [181] [Edge-based Synchronization over Signed Digraphs with Multiple Leaders](https://arxiv.org/abs/2602.19933)
*Pelin Sekercioglu,Angela Fontan,Dimos V. Dimarogonas*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We address the edge-based synchronization problem in first-order multi-agent systems containing both cooperative and antagonistic interactions with one or multiple leader groups. The presence of multiple leaders and antagonistic interactions means that the multi-agent typically does not achieve consensus, unless specific conditions (on the number of leaders and on the signed graph) are met, in which case the agents reach a trivial form of consensus. In general, we show that the multi-agent system exhibits a more general form of synchronization, including bipartite consensus and containment. Our approach uses the signed edge-based agreement protocol for signed networks described by signed edge-Laplacian matrices. In particular, in this work, we present new spectral properties of signed edge-Laplacian matrices containing multiple zero eigenvalues and establish global exponential stability of the synchronization errors. Moreover, we compute the equilibrium to which all edge states converge. Numerical simulations validate our theoretical results.

</details>


### [182] [Robust Taylor-Lagrange Control for Safety-Critical Systems](https://arxiv.org/abs/2602.20076)
*Wei Xiao,Christos Cassandras,Anni Li*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Solving safety-critical control problem has widely adopted the Control Barrier Function (CBF) method. However, the existence of a CBF is only a sufficient condition for system safety. The recently proposed Taylor-Lagrange Control (TLC) method addresses this limitation, but is vulnerable to the feasibility preservation problem (e.g., inter-sampling effect). In this paper, we propose a robust TLC (rTLC) method to address the feasibility preservation problem. Specifically, the rTLC method expands the safety function at an order higher than the relative degree of the function using Taylor's expansion with Lagrange remainder, which allows the control to explicitly show up at the current time instead of the future time in the TLC method. The rTLC method naturally addresses the feasibility preservation problem with only one hyper-parameter (the discretization time interval size during implementation), which is much less than its counterparts. Finally, we illustrate the effectiveness of the proposed rTLC method through an adaptive cruise control problem, and compare it with existing safety-critical control methods.

</details>


### [183] [Informativity and Identifiability for Identification of Networks of Dynamical Systems](https://arxiv.org/abs/2602.20107)
*Anders Hansson,João Victor Galvão da Mata,Martin S. Andersen*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we show how informativity and identifiability for networks of dynamical systems can be investigated using Gröbner bases. We provide a sufficient condition for informativity in terms of positive definiteness of the spectrum of external signals and full generic rank of the transfer function relating the external signals to the inputs of the predictor. Moreover, we show how generic local network identifiability can be investigated by computing the dimension of the fiber associated with the closed loop transfer function from external measurable signals to the measured outputs.

</details>


### [184] [Agentic AI for Scalable and Robust Optical Systems Control](https://arxiv.org/abs/2602.20144)
*Zehao Wang,Mingzhe Han,Wei Cheng,Yue-Kai Huang,Philip Ji,Denton Wu,Mahdi Safari,Flemming Holtorf,Kenaish AlQubaisi,Norbert M. Linke,Danyang Zhuo,Yiran Chen,Ting Wang,Dirk Englund,Tingjun Chen*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present AgentOptics, an agentic AI framework for high-fidelity, autonomous optical system control built on the Model Context Protocol (MCP). AgentOptics interprets natural language tasks and executes protocol-compliant actions on heterogeneous optical devices through a structured tool abstraction layer. We implement 64 standardized MCP tools across 8 representative optical devices and construct a 410-task benchmark to evaluate request understanding, role-aware responses, multi-step coordination, robustness to linguistic variation, and error handling. We assess two deployment configurations--commercial online LLMs and locally hosted open-source LLMs--and compare them with LLM-based code generation baselines. AgentOptics achieves 87.7%--99.0% average task success rates, significantly outperforming code-generation approaches, which reach up to 50% success. We further demonstrate broader applicability through five case studies extending beyond device-level control to system orchestration, monitoring, and closed-loop optimization. These include DWDM link provisioning and coordinated monitoring of coherent 400 GbE and analog radio-over-fiber (ARoF) channels; autonomous characterization and bias optimization of a wideband ARoF link carrying 5G fronthaul traffic; multi-span channel provisioning with launch power optimization; closed-loop fiber polarization stabilization; and distributed acoustic sensing (DAS)-based fiber monitoring with LLM-assisted event detection. These results establish AgentOptics as a scalable, robust paradigm for autonomous control and orchestration of heterogeneous optical systems.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [185] [Learning Adaptive Perturbation-Conditioned Contexts for Robust Transcriptional Response Prediction](https://arxiv.org/abs/2602.18885)
*Yinhua Piao,Hyomin Kim,Seonghwan Kim,Yunhak Oh,Junhyeok Jeon,Sang-Yeon Hwang,Jaechang Lim,Woo Youn Kim,Chanyoung Park,Sungsoo Ahn*

Main category: cs.CE

TL;DR: AdaPert是一种针对基因扰动转录响应预测的新框架，通过学习扰动特异性子图和自适应学习来缓解均值坍塌问题，显著提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预测高维转录响应时易出现均值坍塌，且静态知识图可能传播噪声，导致假阳性多、可解释性差。

Method: AdaPert利用扰动条件化框架，从生物知识图中学习扰动特异的稀疏子图，并采用自适应学习分离信号与噪声。

Result: 在多个基因扰动基准上，AdaPert优于现有方法，在DEG感知指标上表现更优，更准确地恢复扰动特异性转录变化。

Conclusion: AdaPert能有效建模稀疏性和生物学结构，提升扰动响应预测的准确性与可解释性。

Abstract: Predicting high-dimensional transcriptional responses to genetic perturbations is challenging due to severe experimental noise and sparse gene-level effects. Existing methods often suffer from mean collapse, where high correlation is achieved by predicting global average expression rather than perturbation-specific responses, leading to many false positives and limited biological interpretability. Recent approaches incorporate biological knowledge graphs into perturbation models, but these graphs are typically treated as dense and static, which can propagate noise and obscure true perturbation signals. We propose AdaPert, a perturbation-conditioned framework that addresses mean collapse by explicitly modeling sparsity and biological structure. AdaPert learns perturbation-specific subgraphs from biological knowledge graphs and applies adaptive learning to separate true signals from noise. Across multiple genetic perturbation benchmarks, AdaPert consistently outperforms existing baselines and achieves substantial improvements on DEG-aware evaluation metrics, indicating more accurate recovery of perturbation-specific transcriptional changes.

</details>


### [186] [Dual-Kernel Adapter: Expanding Spatial Horizons for Data-Constrained Medical Image Analysis](https://arxiv.org/abs/2602.18888)
*Ziquan Zhu,Hanruo Zhu,Siyuan Lu,Xiang Li,Yanda Meng,Gaojie Jin,Lu Yin,Lijie Hu,Di Wang,Lu Liu,Tianjin Huang*

Main category: cs.CE

TL;DR: 本文研究了在极端数据稀缺的医疗成像场景中，传统适配器（adapter）在微调大型预训练模型时性能下降的问题，并提出了一种新的双核适配器（DKA），通过大核和小核卷积扩展空间上下文并保留局部细节，显著提升了低数据条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 由于标注成本高、隐私法规和数据分散，医学图像领域常面临极端数据稀缺问题，而现有适配器在此类条件下性能不佳，亟需更鲁棒的微调方法。

Method: 提出双核适配器（DKA），结合大核卷积以扩大有效感受野，同时使用小核卷积保留局部细节，从而增强模型在低数据环境下的表示能力。

Result: 在多个分类与分割任务上实验表明，DKA在极低数据（<1%训练数据）和充足数据下均显著优于现有适配器方法，取得了新的最优结果。

Conclusion: DKA通过改进空间上下文建模，有效缓解了适配器在低数据医疗图像任务中的性能退化问题，为高效微调提供了更具鲁棒性的解决方案。

Abstract: Adapters have become a widely adopted strategy for efficient fine-tuning of large pretrained models, particularly in resource-constrained settings. However, their performance under extreme data scarcity, common in medical imaging due to high annotation costs, privacy regulations, and fragmented datasets, remains underexplored. In this work, we present the first comprehensive study of adapter-based fine-tuning for large pretrained models in low-data medical imaging scenarios. We find that, contrary to their promise, conventional adapters can degrade performance under severe data constraints, performing even worse than simple linear probing when trained on less than 1% of the corresponding training data. Through systematic analysis, we identify a sharp reduction in Effective Receptive Field (ERF) as a key factor behind this degradation. Motivated by these findings, we propose the Dual-Kernel Adapter (DKA), a lightweight module that expands spatial context via large-kernel convolutions while preserving local detail with small-kernel counterparts. Extensive experiments across diverse classification and segmentation benchmarks show that DKA significantly outperforms existing adapter methods, establishing new leading results in both data-constrained and data-rich regimes.

</details>


### [187] [Evaluation and Benchmarking Suite for Financial Large Language Models and Agents](https://arxiv.org/abs/2602.19073)
*Shengyuan Lin,Kaiwen He,Jaisal Patel,Qinchuan Zhang,Chris Ding,James Tang,Keyi Wang,Yupeng Cao,Yan Wang,Kairong Xiao,Vincent Caldeira,Matt White,Xiao-Yang Liu Yanglet*

Main category: cs.CE

TL;DR: 本文提出了一套针对金融大语言模型（FinLLMs）和金融智能体（FinAgents）的评估与基准测试工具，涵盖其全生命周期，旨在推动更稳健、可靠的金融人工智能生态系统建设。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在处理复杂金融推理任务时表现不足，缺乏金融领域专业知识，因此需要专门针对金融场景的评估体系来提升模型的可靠性与实用性。

Method: 构建了一个包含评估流水线、治理框架、排行榜（与HuggingFace合作）、AgentOps框架（与Red Hat合作）和文档网站在内的综合评估与基准测试套件，并通过SecureFinAI实验室主导，联合多个开源组织共同开发。

Result: 该套件支持对不同FinLLMs和FinAgents进行定量与定性分析，已形成三个发展阶段：2023年探索阶段、2024年准备阶段、2025年治理阶段，并建立了开放平台促进协作创新。

Conclusion: 所提出的评估与基准测试套件为金融AI的发展提供了标准化、可扩展的基础设施，有助于推动FinLLMs和FinAgents从研究走向实际应用与治理。

Abstract: Over the past three years, the financial services industry has witnessed Large Language Models (LLMs) and agents transitioning from the exploration stage to readiness and governance stages. Financial large language models (FinLLMs), such as open FinGPT and proprietary BloombergGPT , have great potential in financial applications, including retrieving real-time data, tutoring, analyzing sentiment of social media, analyzing SEC filings, and agentic trading. However, general-purpose LLMs and agents lack financial expertise and often struggle to handle complex financial reasoning. This paper presents an evaluation and benchmarking suite that covers the lifecycle of FinLLMs and FinAgents. This suite led by SecureFinAI Lab includes an evaluation pipeline and a governance framework collaborating with Linux Foundation and PyTorch Foundation, a FinLLM Leaderboard with HuggingFace, an AgentOps framework with Red Hat, and a documentation website with Rensselear Center of Open Source. Our collaborative development evolves through three stages: FinLLM Exploration (2023), FinLLM Readiness (2024), and FinAI Governance (2025). The proposed suite serves as an open platform that enables researchers and practitioners to perform both quantitative and qualitative analysis of different FinLLMs and FinAgents, fostering a more robust and reliable FinAI ecosystem.

</details>


### [188] [Pixel2Phys: Distilling Governing Laws from Visual Dynamics](https://arxiv.org/abs/2602.19516)
*Ruikun Li,Jun Yao,Yingfan Hua,Shixiang Tang,Biqing Qi,Bin Liu,Wanli Ouyang,Yan Lu*

Main category: cs.CE

TL;DR: 提出Pixel2Phys，一种基于多智能体框架的多模态大语言模型方法，能从高维视觉数据中自动发现简洁、可解释的物理规律。


<details>
  <summary>Details</summary>
Motivation: 从高维、冗余的视觉数据中提取低维、结构化的物理规律是科学智能的核心挑战，现有方法难以有效识别与物理相关的变量并生成可解释方程。

Method: 提出Pixel2Phys，一种协作式多智能体框架，结合多模态大语言模型，通过迭代的假设生成、验证与优化流程，从原始视频中提取形式化物理知识，并寻找最简明且能准确描述系统演化的物理方程。

Result: 在多种模拟和真实物理视频上验证了方法的有效性，Pixel2Phys能够发现准确且可解释的控制方程，并实现稳定的长期外推，优于基线方法。

Conclusion: Pixel2Phys实现了从原始视觉数据中自动化发现物理规律的突破，模仿人类科学家的迭代推理过程，为科学智能提供了新的路径。

Abstract: Discovering physical laws directly from high-dimensional visual data is a long-standing human pursuit but remains a formidable challenge for machines, representing a fundamental goal of scientific intelligence. This task is inherently difficult because physical knowledge is low-dimensional and structured, whereas raw video observations are high-dimensional and redundant, with most pixels carrying little or no physical meaning. Extracting concise, physically relevant variables from such noisy data remains a key obstacle. To address this, we propose Pixel2Phys, a collaborative multi-agent framework adaptable to any Multimodal Large Language Model (MLLM). It emulates human scientific reasoning by employing a structured workflow to extract formalized physical knowledge through iterative hypothesis generation, validation, and refinement. By repeatedly formulating, and refining candidate equations on high-dimensional data, it identifies the most concise representations that best capture the underlying physical evolution. This automated exploration mimics the iterative workflow of human scientists, enabling AI to reveal interpretable governing equations directly from raw observations. Across diverse simulated and real-world physics videos, Pixel2Phys discovers accurate, interpretable governing equations and maintaining stable long-term extrapolation where baselines rapidly diverge.

</details>


### [189] [Neural Markov chain Monte Carlo: Bayesian inversion via normalizing flows and variational autoencoders](https://arxiv.org/abs/2602.19597)
*Giacomo Bottacini,Matteo Torzoni,Andrea Manzoni*

Main category: cs.CE

TL;DR: 提出了一种结合MCMC采样、降维和神经密度估计的贝叶斯框架，用于高效求解多次出现且似然函数难以处理的反问题。


<details>
  <summary>Details</summary>
Motivation: 针对需多次求解且似然函数不可用或难以计算的反问题，现有方法效率低或无法准确量化不确定性，因此需要一种更高效的贝叶斯推断框架。

Method: 采用变分自编码器进行观测数据的概率特征提取，利用基于正规化流的神经似然估计器建模任意观测似然，并在MCMC随机游走中联合采样参数与数据引导的潜在变量。

Result: 在铁路桥梁结构健康监测和达西地下水流动导电场估计两个案例中验证了方法的有效性，结果显示推理策略高效且能避免因模型与现实差异导致的过度自信错误估计。

Conclusion: 该框架能有效处理多任务、似然函数不明确的反问题，在保持推断准确性的同时合理量化不确定性，具有良好的应用前景。

Abstract: This paper introduces a Bayesian framework that combines Markov chain Monte Carlo (MCMC) sampling, dimensionality reduction, and neural density estimation to efficiently handle inverse problems that (i) must be solved multiple times, and (ii) are characterized by intractable or unavailable likelihood functions. The posterior probability distribution over quantities of interest is estimated via differential evolution Metropolis sampling, empowered by learnable mappings. First, a variational autoencoder performs probabilistic feature extraction from observational data. The resulting latent structure inherently quantifies uncertainty, capturing deviations between the actual data-generating process and the training data distribution. At each step of the MCMC random walk, the algorithm jointly samples from the data-informed latent distribution and the space of parameters to be inferred. These samples are fed into a neural likelihood estimator based on normalizing flows, specifically real-valued non-volume preserving transformations. The scaling and translation functions of the affine coupling layers are modeled by neural networks conditioned on the unknown parameters, allowing the representation of arbitrary observation likelihoods. The proposed methodology is validated on two case studies: (i) structural health monitoring of a railway bridge for damage detection, localization, and quantification, and (ii) estimation of the conductivity field in a steady-state Darcy's groundwater flow problem. The results demonstrate the efficiency of the inference strategy, while ensuring that model-reality mismatches do not yield overconfident, yet inaccurate, estimates.

</details>


### [190] [Stress-constrained Topology Optimization for Metamaterial Microstructure Design](https://arxiv.org/abs/2602.19662)
*Yanda Chen,Sebastian Rodriguez,Beatriz Moya,Francisco Chinesta*

Main category: cs.CE

TL;DR: 本研究将局部应力约束引入超材料微结构设计的拓扑优化框架中，以避免应力集中，并通过扩展增广拉格朗日方法高效处理多约束问题，同时研究了循环载荷下的设计，验证了方法在二维和三维基准问题中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有拓扑优化框架在超材料设计中难以有效引入局部应力约束的问题，避免优化后微结构出现应力集中，提升其机械性能。

Method: 采用扩展的增广拉格朗日公式来处理包含局部和全局约束的拓扑优化问题，并将该方法应用于静态和循环载荷条件下的超材料微结构设计。

Result: 成功实现了在二维和三维情况下满足局部应力约束的超材料微结构优化设计，有效避免了应力集中，并在多种基准测试中验证了方法的有效性。

Conclusion: 所提出的结合局部应力约束的拓扑优化框架能够有效提升超材料微结构的力学性能，适用于复杂载荷条件，为高性能超材料的设计提供了可行方案。

Abstract: Although stress-constrained topology optimization has been extensively studied in structural design, the development of optimization frameworks to enable the creation of metamaterials with optimal mechanical performance is still an open problem. This study incorporates local stress constraints into the topology optimization framework for metamaterial microstructure design, aiming to avoid the stress concentration in the optimized microstructure. For the efficient solution of multi-constraint topology optimization problems, the Augmented Lagrangian formulation is extended to address local minimization problems subjected to the combined action of local and global constraints. Additionally, as an extension of static load conditions, this study further investigates the design of metamaterial microstructures under cyclic loading. Finally, the effectiveness of the proposed approach is demonstrated through a series of two-dimensional and three-dimensional benchmark problems.

</details>


### [191] [GPU-Native Compressed Neighbor Lists with a Space-Filling-Curve Data Layout](https://arxiv.org/abs/2602.19873)
*Felix Thaler,Sebastian Keller*

Main category: cs.CE

TL;DR: 提出基于空间填充曲线和粒子簇的压缩邻居列表，适用于GPU高效构建，内存占用低，支持可变作用半径，适用于高密度对比系统，并与八叉树方法兼容，成功应用于Evrard坍缩模拟。


<details>
  <summary>Details</summary>
Motivation: 为解决短程粒子相互作用中邻居列表在高密度对比系统中的效率和内存占用问题，尤其是天体物理和宇宙学应用中的需求。

Method: 采用空间填充曲线（SFC）内存布局和粒子簇构建压缩邻居列表，支持NVIDIA和AMD GPU，每粒子仅用4字节存储约200个邻居，并兼容八叉树和多极子方法。

Result: 与GROMACS优化实现性能相当，内存占用更低，在高达1024个GPU上成功模拟Evrard坍缩，结果与解析解吻合。

Conclusion: 该方法在性能、内存效率和可扩展性方面表现优异，特别适合处理具有复杂密度分布的大规模粒子系统，且能有效耦合长短程相互作用。

Abstract: We have developed a compressed neighbor list for short-range particle-particle interaction based on a space- filling curve (SFC) memory layout and particle clusters. The neighbor list can be constructed efficiently on GPUs, supporting NVIDIA and AMD hardware, and has a memory footprint of only 4 bytes per particle to store approximately 200 neighbors. Compared to the highly-optimized domain-specific neighbor list implementation of GROMACS, a molecular dynamics code, it has a comparable cluster overhead and delivers similar performance in a neighborhood pass. Thanks to the SFC-based data layout and the support for varying interaction radii per particle, our neighbor list performs well for systems with high density contrasts, such as those encountered in many astrophysical and cosmological applications. Due to the close relation between SFCs and octrees, our neighbor list seamlessly integrates with octree-based domain decomposition and multipole-based methods for long-range gravitational or electrostatic interactions. To demonstrate the coupling between long- and short-range forces, we simulate an Evrard collapse, a standard test case for the coupling between hydrodynamical and gravitational forces, on up to 1024 GPUs, and compare our results to the analytical solution.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [192] [VOLatility Archive for Realized Estimates (VOLARE)](https://arxiv.org/abs/2602.19732)
*Fabrizio Cipollini,Giulia Cruciani,Giampiero M. Gallo,Alessandra Insana,Edoardo Otranto,Fabio Spagnolo*

Main category: q-fin.ST

TL;DR: VOLARE是一个开放的研究基础设施，提供基于超高频金融数据的标准实现波动率和协方差度量，支持多种资产类别的数据处理与可视化分析。


<details>
  <summary>Details</summary>
Motivation: 为解决不同资产类别在交易日历、微观结构噪声和时间戳精度方面的异质性问题，提供一致且可比的实现波动率估计。

Method: 采用资产特定的处理流程，对逐笔数据进行清洗、规则采样，并应用多种已建立的实现波动率估计方法（如HAR、MEM模型）。

Result: 构建了包括实现方差、双幂变差、半方差、实现四次幂等在内的全面估计量集合，并支持跨资产比较与实时建模。

Conclusion: VOLARE平台实现了方法论一致性与跨资产可比性，促进了高频金融数据分析的标准化和开放研究。

Abstract: VOLARE (VOLatility Archive for Realized Estimates - https://volare.unime.it) is an open research infrastructure providing standardized realized volatility and covariance measures constructed from ultra-high-frequency financial data. The platform processes tick-level observations across equities, exchange rates, and futures using an asset-specific pipeline that addresses heterogeneous trading calendars, microstructure noise, and timestamp precision. For equities, price series are cleaned using a documented outlier detection procedure and sampled at regular intervals.
  VOLARE delivers a comprehensive set of realized estimators, including realized variance, range-based measures, bipower variation, semivariances, realized quarticity, realized kernels, and multivariate covariance measures, ensuring methodological consistency and cross-asset comparability. In addition to bulk dataset download, the platform supports interactive visualization and real-time estimation of established volatility models such as HAR and MEM specifications.

</details>


### [193] [Detecting and Explaining Unlawful Insider Trading: A Shapley Value and Causal Forest Approach to Identifying Key Drivers and Causal Relationships](https://arxiv.org/abs/2602.19841)
*Krishna Neupane,Igor Griva,Robert Axtell,William Kennedy,Jason Kinser*

Main category: q-fin.ST

TL;DR: 本研究结合SHAP值与因果森林模型，提出一种高精度检测非法内幕交易（UIT）并识别关键驱动因素的框架，强调因果关系在解释UIT中的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于企业内部人交易动机复杂且常涉及未公开重大信息（MNPI），准确识别非法内幕交易及其成因具有挑战性，需更有效的检测与解释方法。

Method: 采用Shapley值（SHAP）进行特征重要性解释，结合因果森林（Causal Forest）模型评估因果效应，在高维特征空间中实现UIT的分类与归因分析。

Result: 发现董事身份、市净率、收益率和市场贝塔等特征与UIT存在显著统计关联，揭示了信息不对称、估值风险、市场波动等因素对内幕交易的影响；模型具备良好分类性能与因果解释能力。

Conclusion: 引入因果推理有助于深入理解非法内幕交易的驱动机制，决策树类模型通过整合异质性可有效挖掘金融行为中的潜在结构，为监管提供可解释的分析工具。

Abstract: Corporate insiders trade for diverse reasons, often possessing Material Non-Public Information (MNPI). Determining whether specific trades leverage MNPI is a significant challenge due to inherent complexity. This study focuses on two critical objectives: accurately detecting Unlawful Insider Trading (UIT) and identifying key features explaining classification. The analysis demonstrates how combining Shapley Values (SHAP) and Causal Forest (CF) reveals these explanatory drivers.
  The findings underscore the necessity of causality in identifying and interpreting UIT, requiring the consideration of alternative scenarios and potential outcomes. Within a high-dimensional feature space, the proposed architecture integrates state-of-the-art techniques to achieve high classification accuracy. The framework provides robust feature rankings via SHAP and causal significance assessments through CF, facilitating the discovery of unique causal relationships.
  Statistically significant relationships are documented between the outcome and several key features, including director status, price-to-book ratio, return, and market beta. These features significantly influence the likelihood of UIT, suggesting potential links between insider behavior and factors such as information asymmetry, valuation risk, market volatility, and stock performance. The analysis draws attention to the complexities of financial causality, noting that while initial descriptors offer intuitive insights, deeper examination is required to understand nuanced impacts. These findings reaffirm the architectural flexibility of decision tree models. By incorporating heterogeneity during tree construction, these models effectively uncover latent structures within trade, finance, and governance data, characterizing fraudulent behavior while maintaining reliable results.

</details>
