<div id=toc></div>

# Table of Contents

- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 4]
- [q-fin.RM](#q-fin.RM) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 7]
- [quant-ph](#quant-ph) [Total: 32]
- [math.OC](#math.OC) [Total: 13]
- [cs.CE](#cs.CE) [Total: 2]
- [eess.SY](#eess.SY) [Total: 3]
- [cs.ET](#cs.ET) [Total: 2]
- [nlin.AO](#nlin.AO) [Total: 1]
- [math.ST](#math.ST) [Total: 8]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [math.NA](#math.NA) [Total: 10]
- [stat.ME](#stat.ME) [Total: 9]
- [hep-lat](#hep-lat) [Total: 1]


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [1] [Steering Dynamical Regimes of Diffusion Models by Breaking Detailed Balance](https://arxiv.org/abs/2602.15914)
*Haiqi Lu,Ying Tang*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了在生成扩散过程中故意打破细致平衡如何加速逆向过程而不改变稳态分布，提出了一种非可逆扰动方法以优化长期松弛速率，并分析了其对相变动力学的影响。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过引入非可逆性来加速生成扩散模型中的反向采样过程，同时保持目标稳态分布不变。

Method: 基于Ornstein--Uhlenbeck过程，将动力学分解为对称部分和非可逆的反对称部分，构建指数最优的非可逆扰动，并推导出调控宏观动力学相变的准则。

Result: 发现适当的非可逆扰动能加速‘物种形成’时间，但对由对称部分决定的‘坍缩’过程无影响；数值实验验证了该理论。

Conclusion: 非可逆控制可通过引入旋转概率流来加速特定动力学过程，为提升生成扩散模型效率提供了新途径。

Abstract: We show that deliberately breaking detailed balance in generative diffusion processes can accelerate the reverse process without changing the stationary distribution. Considering the Ornstein--Uhlenbeck process, we decompose the dynamics into a symmetric component and a non-reversible anti-symmetric component that generates rotational probability currents. We then construct an exponentially optimal non-reversible perturbation that improves the long-time relaxation rate while preserving the stationary target. We analyze how such non-reversible control reshapes the macroscopic dynamical regimes of the phase transitions recently identified in generative diffusion models. We derive a general criterion for the speciation time and show that suitable non-reversible perturbations can accelerate speciation. In contrast, the collapse transition is governed by a trace-controlled phase-space contraction mechanism that is fixed by the symmetric component, and the corresponding collapse time remains unchanged under anti-symmetric perturbations. Numerical experiments on Gaussian mixture models support these findings.

</details>


### [2] [Breaking of clustering and macroscopic coherence under the lens of asymmetry measures](https://arxiv.org/abs/2602.15969)
*Florent Ferro*

Main category: cond-mat.stat-mech

TL;DR: 研究了一维系统中相互作用对自发对称性破缺现象的影响，发现局域淬火会增强量子干涉并产生宏观磁化分布，通过纠缠不对称性和量子费舍尔信息揭示了扰动区域内宏观量子相干性的出现。


<details>
  <summary>Details</summary>
Motivation: 探索一维系统中由于非零能量密度注入导致对称性恢复的情况下，相互作用如何影响自发对称性破缺的不稳定性及其引发的宏观量子现象。

Method: 采用具有守恒畴壁数的相互作用模型，结合局域淬火方法，并利用纠缠不对称性（EA）和量子费舍尔信息（QFI）作为不对称性度量来表征磁化涨落相关的量子相干性。

Result: 局域淬火放大了量子干涉，产生了反映模型散射相位的宏观磁化分布；在与扰动光锥尺度相当的子系统中，确认了整个扰动区域内宏观量子相干性的出现；提出了纯态方差/EA不等式可推广为混合态的QFI/EA不等式。

Conclusion: 在一维Z2对称破缺的相互作用系统中，局域扰动可诱导全区域的宏观量子相干，且EA与QFI的关系可扩展至混合态，深化了对低维系统中量子退相干机制的理解。

Abstract: In one-dimensional systems, spontaneous symmetry breaking (SSB) states are fragile by nature, as the injection of a non-zero energy density above the ground state is expected to restore the symmetry. This instability implies that local perturbations can lead to macroscopic correlation profiles, a breaking of clustering properties and even macroscopic quantum superpositions. In this work, we investigate the effect of interaction on this phenomenology by considering an interacting model with conserved domain wall number, that possesses a ferromagnetic ground state breaking the Z2 symmetry of the Hamiltonian. We first show that a local quench in this system amplifies quantum interferences, producing a macroscopic magnetisation profile that directly reflects the scattering phase of the model. Then, we use two asymmetry measures, namely the Entanglement Asymmetry (EA) and Quantum Fisher Information (QFI), to characterise the quantum coherence associated with the fluctuations of the magnetisation. By focusing on subsystems comparable in size to the light-cone of the perturbation, we confirm the emergence of macroscopic quantum coherence throughout the whole perturbed region. Finally, we discuss the link between EA and QFI and show that the variance/EA inequality for pure state can be generalised to a QFI/EA inequality for mixed states.

</details>


### [3] [Computation of thermal conductivity based on Path Integral Monte Carlo methods](https://arxiv.org/abs/2602.16405)
*Vladislav Efremkin,Stefano Mossa,Jean-Louis Barrat,Markus Holzmann*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种基于路径积分蒙特卡洛（PIMC）与格林-久保理论相结合的全量子方法，用于计算低温下绝缘体固体的热导率，揭示了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 在低于德拜温度时，经典和半经典方法在计算绝缘体固体热导率方面失效，需发展全量子方法以准确描述量子效应主导的输运行为。

Method: 结合路径积分蒙特卡洛（PIMC）模拟与格林-久保线性响应理论，通过能量流的虚时间关联函数提取热输运系数，并采用物理启发的先验模型进行分析。

Result: 在晶态氩系统中发现，仅依靠声子寿命的准谐近似或Peierls-Boltzmann框架无法解释低温热导率上升现象，而从热流关联中提取出一个独特的输运寿命。

Conclusion: 量子蒙特卡洛方法为研究绝缘体中的热输运提供了超越经典分子动力学和准谐近似的非微扰、稳健框架。

Abstract: The calculation of thermal conductivity in insulating solids at temperatures below the Debye temperature is problematic, due to the breakdown of classical and semi-classical approaches. In this work, we present a fully quantum methodology to compute thermal conductivity based on Path Integral Monte Carlo (PIMC) simulations combined with the Green-Kubo linear response theory. The method is applied to crystalline argon modeled by a Lennard-Jones potential, a paradigmatic system where quantum effects strongly affect both thermodynamic and transport properties. From PIMC simulations, we obtain the temperature-dependent phonon frequencies, lifetimes, and specific heat. From the imaginary time correlations of the energy current, we extract the thermal transport coefficients based on a physically motivated prior. We show that the experimentally observed increase of the thermal conductivity at low temperatures cannot be explained within a standard Peierls-Boltzmann framework or quasi-harmonic approximation using phonon lifetimes alone. Instead, a distinct transport lifetime emerges from the analysis of heat-current correlations. Our results demonstrate that quantum Monte Carlo methods provide a robust, non-perturbative framework to investigate heat transport in insulating solids, beyond the limits of classical molecular dynamics and quasi-harmonic approximations.

</details>


### [4] [Quantum-classical correspondence for spins at finite temperatures with application to Monte Carlo simulations](https://arxiv.org/abs/2602.16501)
*A. El Mendili,M. E. Zhitomirsky*

Main category: cond-mat.stat-mech

TL;DR: 该论文提出了一种将任意相互作用自旋系统在有限温度下的量子模型映射到经典模型的方法，在大S极限下，量子系统的分区函数渐近等价于自旋长度为 $ S_C=\sqrt{S(S+1)} $ 的经典模型，并通过 $ 1/[S(S+1)] $ 的幂级数修正项描述量子涨落。该方法为真实磁性哈密顿量的经典模拟提供了严格基础，并应用于多种材料的相变温度计算，蒙特卡洛模拟结果与实验数据吻合良好。


<details>
  <summary>Details</summary>
Motivation: 为了建立一个严格的量子到经典映射框架，以便在有限温度下对实际磁性材料进行高效且准确的经典模拟，特别是解决传统方法中缺乏系统性处理量子涨落的问题。

Method: 在大自旋极限（large-S）下推导出量子系统分区函数的渐近形式，将其映射为有效经典模型，并以 $ 1/[S(S+1)] $ 展开得到量子修正项；随后使用经典蒙特卡洛方法计算多个二维磁性材料的相变温度。

Result: 得到了适用于任意相互作用自旋系统的量子-经典映射的解析表达式，确认了经典自旋长度应取 $ S_C=\sqrt{S(S+1)} $；对包括 MnF$_2$、CrI$_3$ 等多种材料的相变温度模拟结果与实验值高度一致。

Conclusion: 该研究为基于真实参数的磁性系统提供了可靠的经典模拟理论基础，证明在大S极限下经典模型可以高精度逼近量子系统行为，拓展了经典方法在量子材料预测中的应用范围。

Abstract: We consider quantum-to-classical mapping for an arbitrary system of interacting spins at finite temperatures. We prove that, in the large-$S$ limit, the asymptotic form of the partition function coincides with that of a classical model for spins of length $S_C=\sqrt{S(S+1)}$. Quantum corrections to the leading term form a series in powers of $1/[S(S+1)]$. This representation provides a rigorous basis for classical modeling of realistic magnetic Hamiltonians. As an application, the classical Monte Carlo simulations are performed to compute transition temperatures for several topical materials with known interaction parameters, including MnF$_2$, MnTe, Rb$_2$MnF$_4$, MnPSe$_3$, FePS$_3$, FePSe$_3$, CoPS$_3$, CrSBr, and CrI$_3$. The resulting transition temperatures show good agreement with experimental data.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [5] [Stackelberg Equilibria in Monopoly Insurance Markets with Probability Weighting](https://arxiv.org/abs/2602.16401)
*Maria Andraos,Mario Ghossoub,Bin Li,Benxuan Shi*

Main category: q-fin.RM

TL;DR: 本文研究了在垄断性集中顺序保险市场中的Stackelberg均衡，其中保险公司采用扭曲保费原则定价，投保人则试图最小化扭曲风险度量。研究发现均衡下的最优赔偿函数具有分层结构，并且保险覆盖范围和保险公司利润随投保人风险厌恶程度增加而增加。


<details>
  <summary>Details</summary>
Motivation: 探讨在顺序决策保险市场中，保险公司与投保人之间的策略互动及其对均衡结果的影响。

Method: 通过构建一个包含扭曲保费原则和扭曲风险度量的理论模型，分析Stackelberg均衡的存在性和特性。

Result: 1. 最优赔偿函数呈现分层结构；2. 保险覆盖和 insurer 利润随投保人风险厌恶程度上升而增加；3. 均衡合同是帕累托有效的，但不带来投保人福利增益；4. 所有无福利增益的帕累托最优合同均可作为均衡合同实现。

Conclusion: 该研究表明，在所考虑的市场结构下，均衡合同既有效又反映了双方的风险态度，同时揭示了风险厌恶程度对市场结果的重要影响。

Abstract: We study Stackelberg Equilibria (Bowley optima) in a monopolistic centralized sequential-move insurance market, with a profit-maximizing insurer who sets premia using a distortion premium principle, and a single policyholder who seeks to minimize a distortion risk measure. We show that equilibria are characterized as follows: In equilibrium, the optimal indemnity function exhibits a layer-type structure, providing full insurance over any loss layer on which the policyholder is more pessimistic than the insurer's pricing functional about tail losses; and no insurance coverage over loss layers on which the policyholder is less pessimistic than the insurer's pricing functional about tail losses. In equilibrium, the optimal pricing distortion function is determined by the policyholder's degree of risk aversion, whereby prices never exceed the policyholder's marginal willingness to insure tail losses. Moreover, we show that both the insurance coverage and the insurer's expected profit increase with the policyholder's degree of risk aversion. Additionally, and echoing recent work in the literature, we show that equilibrium contracts are Pareto efficient, but they do not induce a welfare gain to the policyholder. Conversely, any Pareto-optimal contract that leaves no welfare gain to the policyholder can be obtained as an equilibrium contract. Finally, we consider a few examples of interest that recover some existing results in the literature as special cases of our analysis.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [6] [Zero Indirect Band Gap and Flat Bands in a Niobium Oxyiodide Cluster Material](https://arxiv.org/abs/2602.16011)
*Jan Beitlberger,Mario Martin,Marcus Scheele,Marek Matas,Carl P. Romao,Markus Ströbele,H. -Jürgen Meyer*

Main category: cond-mat.str-el

TL;DR: 在NbI4、Li2(CN2)和Li2O反应体系中发现了两种新的铌氧碘簇化合物Nb6O3I15和Nb11O6I24，其结构基于[Nb4O]簇核扩展而成，其中Nb11O6I24表现出独特的弦状结构和强关联电子态特征。


<details>
  <summary>Details</summary>
Motivation: 探索由NbI4、Li2(CN2)和Li2O组成的反应体系中的新型铌氧碘簇化合物，并研究其结构多样性与电子特性。

Method: 通过单晶X射线衍射对新发现的铌氧碘簇化合物进行结构表征，并利用DFT计算分析其电子结构和性质。

Result: 发现了两种新化合物Nb6O3I15和Nb11O6I24，均基于[Nb4O]簇核；Nb6O3I15形成三维框架结构，而Nb11O6I24具有手性单元和弦状排列；DFT计算显示其具有零间接带隙和三维平带，表明存在强关联的簇间单重态电子态。

Conclusion: 该反应体系可生成结构多样的铌氧碘簇化合物，Nb11O6I24的独特结构导致其具备潜在的强电子关联特性，为功能材料的设计提供了新思路。

Abstract: Explorative chemistry in a reaction system composed of NbI4, Li2(CN2), and Li2O has led to the discovery of a number of niobium oxyiodide cluster compounds. During this reaction, the formation of solid phases was detected alongside with gaseous phases, resulting in a range of products with cluster cores of varying shapes. After several niobium oxyiodide cluster compounds have already been identified within this reaction system, two additional compounds, Nb6O3I15 and Nb11O6I24, are discovered and structurally characterized by single-crystal X-ray diffraction. Both structures are based on the butterfly-shaped, oxygen-capped niobium cluster [Nb4O], which is extended to larger cluster fragments. The [Nb4O] cluster core in Nb6O3I15 is extended by two [NbO] units to form a three-dimensional framework, and Nb11O6I24 contains two connected [Nb4O] units, which form chiral units within an antiferrochiral hexagonal packing of strings. The striking string-like character of Nb11O6I24 was investigated in terms of its electronic structure and properties. DFT calculations showed Nb11O6I24 to possess a zero indirect band gap, with a pair of 3-dimensional flat bands surrounding the Fermi level. These unusual features of the electronic band structure suggest the presence of strongly correlated inter-cluster singlet electron states, arising from the helical shape of the clusters, the hexagonal packing of the strings, and the delocalized nature of cluster electron wavefunctions.

</details>


### [7] [Stripe antiferromagnetism in van der Waals metal HoTe3 decoupled from charge density wave order](https://arxiv.org/abs/2602.16261)
*Weiyi Yun,Ryota Nakano,Ryo Misawa,Rinsuke Yamada,Shun Akatsuka,Yoshichika Onuki,Priya Ranjan Baral,Hiraku Saitoh,Ryoji Kiyanagi,Takashi Ohhara,Taro Nakajima,Taka-hisa Arima,Max Hirschberger*

Main category: cond-mat.str-el

TL;DR: 本研究通过中子衍射在单晶HoTe3中发现两种不同的反铁磁相，分别具有垂直条纹和倾斜条纹的层间堆叠方式，但未观察到磁性与电荷密度波之间的耦合。


<details>
  <summary>Details</summary>
Motivation: 探索RTe3体系中磁性与电荷密度波（CDW）自由度之间的相互作用机制。

Method: 结合极化与非极化中子衍射技术对单晶HoTe3进行结构与磁结构分析。

Result: 识别出两个独立的反铁磁相（AFM-II和AFM-I），各自具有不同的层间堆叠方式和传播矢量，且未发现磁性与CDW之间的耦合现象。

Conclusion: 磁性与CDW的耦合可能依赖于反铁磁与CDW传播矢量的相对取向以及单离子各向异性，这在层状范德瓦尔斯系统中起关键作用。

Abstract: The $R\mathrm{Te}_3$ ($R = \text{rare earth}$) family of layered van der Waals (vdW) compounds hosts coexisting magnetic and charge density wave (CDW) orders, yet the interplay between these degrees of freedom remains little explored. Combining polarized and unpolarized neutron diffraction on single-crystal $\mathrm{HoTe}_3$, we identify two distinct antiferromagnetic (AFM) phases, both exhibiting a collinear $\uparrow\uparrow\downarrow\downarrow$ motif within individual vdW layers. The two phases are distinguished by the vdW stacking of magnetic layers: ferromagnetic (FM) stacking in the higher-temperature AFM-II phase, here termed ``vertical-stripe'', and AFM stacking in the AFM-I ground state, here termed ``tilted-stripe''; the two phases have propagation vectors $\boldsymbol{q}_{\mathrm{m2}} = (0.48, 0, 0)$ and $\boldsymbol{q}_{\mathrm{m1}} = (0.5, 0.5, 0)$, respectively. In contrast to the CDW-driven exotic magnetism in $\mathrm{DyTe}_3$, $\mathrm{TbTe}_3$, and $\mathrm{GdTe}_3$, we find no evidence for coupling between magnetism and CDW in $\mathrm{HoTe}_3$. The relative alignment between AFM and CDW propagation vectors, as well as single-ion anisotropy, are likely essential for generating coupled spin/charge orders in layered vdW systems.

</details>


### [8] [Monte Carlo study of the classical antiferromagnetic $J_1$-$J_2$-$J_3$ Heisenberg model on a simple cubic lattice](https://arxiv.org/abs/2602.16471)
*A. N. Ignatenko,S. V. Streltsov,V. Yu. Irkhin*

Main category: cond-mat.str-el

TL;DR: 通过蒙特卡洛方法研究了具有第一、第二和第三近邻交换相互作用的简立方晶格上经典海森堡模型的相变特性，计算了奈尔温度和挫败参数，并探讨了其在反铁磁钙钛矿材料中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究多近邻反铁磁交换作用下经典海森堡模型的相变行为及挫败效应，为理解复杂磁性系统提供理论依据。

Method: 采用广泛的蒙特卡洛模拟，结合Binder累积量法分析相变特征，并与Tyablikov近似进行比较。

Result: 计算得到了不同J2/J1、J3/J1比值和温度范围内的奈尔温度TN和挫败参数f = |θ|/TN，揭示了挫败效应的强度及其对相变的影响。

Conclusion: 该模型能有效描述强挫败反铁磁系统，结果对理解CaMnO3和HgMnO3等反铁磁钙钛矿的磁性具有参考价值。

Abstract: An extensive Monte Carlo study of the classical Heisenberg model on a simple cubic lattice with antiferromagnetic exchange interactions $J_n$ between the first, second, and third neighbors is performed in a broad region of $J_2 / J_1$, $J_3 / J_1$ ratios, and temperature. The character of the phase transitions is analyzed via the Binder cumulant method. The Neel temperature $T_{\mathrm{N}}$ and the frustration parameter (the ratio $f= |θ|/T_{\mathrm{N}}$, $θ$ being the Curie-Weiss temperature) are calculated. A comparison with the Tyablikov approximation is carried out. The strength of the frustration effects is explored. Possible applications to antiferromagnetic perovskites, such as CaMnO$_3$ and HgMnO$_3$, are discussed.

</details>


### [9] [Anisotropic magnetism at the surface of a non-magnetic bulk insulator](https://arxiv.org/abs/2602.16557)
*Jarryd A. Horn,Keenan E. Avers,Nicholas Crombie,Shanta R. Saha,Johnpierre Paglione*

Main category: cond-mat.str-el

TL;DR: 本论文研究了FeSb2表面态的磁性特性，利用磁化率的表面面积依赖性分离表面与体相贡献，发现表面磁各向异性与磁输运各向异性具有良好一致性，并观察到低温下表面输运中的反常霍尔效应。


<details>
  <summary>Details</summary>
Motivation: 探索d电子体系中拓扑Kondo绝缘体行为的潜力，特别是FeSb2表面态的磁性尚未被充分研究。

Method: 通过测量薄单晶FeSb2的磁化率随表面面积的变化，分离表面和体相的磁响应，并提取表面磁各向异性，与磁输运各向异性进行比较。

Result: 发现了表面磁化与磁输运各向异性之间的一致性，并观察到低温下表面输运存在反常霍尔效应。

Conclusion: FeSb2表面具有显著的磁各向异性和非平凡的输运行为，支持其作为拓扑相关绝缘体候选材料的潜力。

Abstract: The potential for topological Kondo insulating behavior in d-electron systems has attracted interest in studying the surface states of the correlated insulators FeSb2 and FeSi. While detailed studies and theoretical description of a spin-orbit coupled ferromagnetic surface state have been applied to FeSi, the magnetic properties of the surface states of FeSb2 have not been addressed. Here, we report on the surface magnetic properties of FeSb2, utilizing the surface area dependence of magnetic susceptibility to separate the surface Curie-Weiss temperature dependence from the bulk spin-gap susceptibility. We use these results to further extract the surface magnetic anisotropy of a thin, rough-surfaced single-crystal FeSb2 to compare with the observed magnetotransport anisotropy, and find good agreement between the anisotropy in the surface magnetization and surface magnetotransport. We conclude with evidence of an anomalous Hall contribution to the low-temperature surface transport.

</details>


### [10] [Entanglement negativity in decohered topological states](https://arxiv.org/abs/2602.16597)
*Kang-Le Cai,Meng Cheng*

Main category: cond-mat.str-el

TL;DR: 研究了在纯态拓扑序退相干后得到的混合态相的普遍纠缠特征，提出了拓扑纠缠负性（TEN）和拓扑互信息（TMI）的概念，并通过复本场论框架和双态构造给出了其在强退相干 regime 下的一般表达式。


<details>
  <summary>Details</summary>
Motivation: 探索混合态拓扑序中的普适纠缠特性，特别是在退相干影响下原有拓扑序如何体现于纠缠度量中。

Method: 发展了一种基于双态构造的复本场论框架，用于分析阿贝尔拓扑序在退相干下的TEN和TMI；并精确计算了G分级弦网态在退相干后的TEN与TMI。

Result: 发现TMI反映的是涌现前模任何子理论的总量子维度，而TEN仅探测其模部分；该结果可通过一形式对称性框架解释。

Conclusion: TEN和TMI可作为识别混合态拓扑相的有效纠缠判据，且二者分别对应不同类型的任何子结构，揭示了退相干下拓扑序的残余特征。

Abstract: We investigate universal entanglement signatures of mixed-state phases obtained by decohering pure-state topological order (TO), focusing on topological corrections to logarithmic entanglement negativity and mutual information: topological entanglement negativity (TEN) and topological mutual information (TMI). For Abelian TOs under decoherence, we develop a replica field-theory framework based on a doubled-state construction that relates TEN and TMI to the quantum dimensions of domain-wall defects between decoherence-induced topological boundary conditions, yielding general expressions in the strong-decoherence regime. We further compute TEN and TMI exactly for decohered $G$-graded string-net states, including cases with non-Abelian anyons. We interpret the results within the strong one-form-symmetry framework for mixed-state TOs: TMI probes the total quantum dimension of the emergent premodular anyon theory, whereas TEN detects only its modular part.

</details>


### [11] [A Tale of Two Plateaus: Competing Orders in Spin-1 and Spin-$\tfrac{3}{2}$ Pyrochlore Magnets](https://arxiv.org/abs/2602.16661)
*Imre Hagymási*

Main category: cond-mat.str-el

TL;DR: 通过大规模密度矩阵重正化群模拟，研究了自旋-1和自旋-3/2烧绿石海森堡反铁磁体的磁化曲线，发现两者在半磁化平台均稳定形成16个格点的四倍原胞态，与量子二聚体模型预测不同，表明微扰机制在海森堡点失效。


<details>
  <summary>Details</summary>
Motivation: 探究自旋-1和自旋-3/2烧绿石海森堡反铁磁体在磁场下的平台态结构，检验有效量子二聚体模型的适用性。

Method: 采用最大达20000的键维数的大规模密度矩阵重正化群（DMRG）模拟，研究包含64个格点的立方簇上的磁化行为。

Result: 自旋-1和自旋-3/2系统均展现出稳健的半磁化平台，并选择相同的16个格点四倍原胞态；该结果与量子二聚体模型预测的“R”态不符。

Conclusion: 在海森堡点处，传统的微扰机制失效，非微扰方法揭示了新的场致有序态，为相关材料的实验提供了理论指导。

Abstract: We use large-scale density-matrix renormalization group simulations with bond dimensions up to $20\ 000$ to determine the magnetization curves of spin-1 and spin-$\tfrac{3}{2}$ pyrochlore Heisenberg antiferromagnets. Both models exhibit a robust half-magnetization plateau, and we find that the same 16-site state (quadrupled unit cell) is selected in both cases on the largest 64-site cubic cluster we consider for the plateau state. This contrasts sharply with the effective quantum dimer model prediction which favors the ``R'' state, and demonstrates the breakdown of the perturbative mechanism at the Heisenberg point. These results provide a nonperturbative characterization of field-induced phases in pyrochlore magnets and predictive guidance for spin-1 and spin-$\tfrac{3}{2}$ materials.

</details>


### [12] [Ab Initio Auxiliary-Field Quantum Monte Carlo in the Thermodynamic Limit](https://arxiv.org/abs/2602.16679)
*Jinghong Zhang,Meng-Fu Chen,Adam Rettig,Tong Jiang,Paul J. Robinson,Hieu Q. Dinh,Anton Z. Ni,Joonho Lee*

Main category: cond-mat.str-el

TL;DR: 提出了一种结合张量超压缩和k点对称性的新方法，显著降低了从头算辅助场量子蒙特卡罗（AFQMC）在固体计算中的计算和内存开销，使其达到与扩散蒙特卡罗相当的O(N^3)和O(N^2)复杂度，从而实现了直接且同时趋近热力学极限和完备基组极限的高效计算。


<details>
  <summary>Details</summary>
Motivation: AFQMC方法在扩展固体中的应用受限于高昂的计算成本和内存需求，难以实现热力学极限和完备基组极限下的精确计算，因此需要一种更高效的算法改进方案。

Method: 通过引入基于插值可分密度拟合的张量超压缩技术，并结合k点空间群对称性，优化了AFQMC的标度行为，降低了计算和内存复杂度。

Result: 实现了O(N^3)计算复杂度和O(N^2)内存复杂度，能够在不依赖嵌入、局域近似或经验修正的情况下，对绝缘体、金属和强关联固体进行精确的能量和磁性观测量计算。

Conclusion: 该方法使AFQMC成为一种通用、系统可改进的从头算方法，适用于固体的高精度预测模拟，为替代扩散蒙特卡罗和耦合簇方法提供了统一框架。

Abstract: Ab initio auxiliary-field quantum Monte Carlo (AFQMC) is a systematically improvable many-body method, but its application to extended solids has been severely limited by unfavorable computational scaling and memory requirements that obstruct direct access to the thermodynamic and complete-basis-set limits. By combining tensor hypercontraction via interpolative separable density fitting with $\mathbf{k}$-point symmetry, we reduce the computational and memory scaling of ab initio AFQMC for solids to $O(N^3)$ and $O(N^2)$ with arbitrary basis, respectively, comparable to diffusion Monte Carlo. This enables direct and simultaneous thermodynamic-limit and complete-basis-set AFQMC calculations across insulating, metallic, and strongly correlated solids, without embedding, local approximations, empirical finite-size corrections, or composite schemes. Our results establish AFQMC as a general-purpose, systematically improvable alternative to diffusion Monte Carlo and coupled-cluster methods for predictive ab initio simulations of solids, enabling accurate energies and magnetic observables within a unified framework.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [13] [On the possibility of differential algebraic elimination of the spinor field from the Maxwell-Dirac electrodynamics](https://arxiv.org/abs/2602.15907)
*Andrey Akhmeteli*

Main category: quant-ph

TL;DR: 研究了是否可以通过微分代数方法从麦克斯韦-狄拉克方程中消除旋量场。


<details>
  <summary>Details</summary>
Motivation: 探索旋量场在麦克斯韦-狄拉克方程中是否可被消除，以简化理论模型。

Method: 构建通用截断幂级数解，线性化麦克斯韦-狄拉克电动力学的延拓系统，并计算相关系数矩阵的秩。

Result: 结果表明，旋量分量通常由电磁场及其导数唯一确定。

Conclusion: 这强烈表明通过微分代数方法消除旋量场是可能的。

Abstract: We investigate whether the spinor field can be eliminated from the Maxwell-Dirac equations by differential algebraic methods. A generic truncated power series solution is constructed, the prolonged system of the Maxwell-Dirac electrodynamics is linearized about the solution, and the ranks of the associated coefficient matrices are computed. The results indicate that, generically, the spinor components are uniquely determined by the electromagnetic field and its derivatives. This strongly suggests that differential-algebraic elimination of the spinor field is possible.

</details>


### [14] [Enhanced Superconducting Nanowire Single Photon Detector Performances using Silicon Capping](https://arxiv.org/abs/2602.15948)
*C. Klein,S. Cohen,T. Descamps,A. Iovan,P. Zolotov,P. Vennéguès,I. Florea,F. Semond,V. Zwiller*

Main category: quant-ph

TL;DR: 本研究通过引入硅保护层，有效抑制了NbTiN超导纳米线单光子探测器薄膜的氧化，提升了超导转变温度，实现了3 nm超薄薄膜在3 K下的超导性，并显著扩展了饱和检测平台至2050 nm，同时保持低于50 ps的时间抖动，降低了纳米加工难度并拓宽了工作温度范围。


<details>
  <summary>Details</summary>
Motivation: 解决NbTiN基超导纳米线单光子探测器在薄膜厚度小于5 nm时因表面氧化和不均匀性导致的制备困难和性能退化问题。

Method: 在NbTiN薄膜上引入硅（Si）保护层，系统研究其对薄膜物性及探测器性能的影响，包括超导转变温度、临界电流、时间抖动和光谱响应范围。

Result: 硅保护层有效抑制氧化，使3 nm厚的薄膜在3 K下实现超导；提高了临界电流，将饱和检测平台扩展至2050 nm；器件在250 nm线宽和20×20 μm²探测面积下仍保持低于50 ps的时间抖动。

Conclusion: 使用硅保护层的超薄NbTiN薄膜可实现高性能单光子探测，降低纳米加工难度，拓展工作温度和光谱范围，为高集成度、宽光谱单光子探测器的制备提供了可行方案。

Abstract: Niobium Titanium nitride (NbTiN) based superconducting nanowire single photon detectors (SNSPDs) are known for their high performance across a wide spectral range, from the X-ray to the mid-infrared. Nonetheless, fabrication challenges and performance degradation attributable to surface oxidation and lack of uniformity in films thinner than 5 nm remain a significant barrier for achieving high-quality detectors. In this work, we study the influence of a Silicon capping layer on film properties and on the performance of SNSPDs. A Silicon capping layer effectively suppresses oxidation and increases the superconducting transition temperature. This enables superconductivity in films as thin as 3 nm at 3 K, increases critical current in patterned nanowires and significantly extends the saturation plateau from the visible to the near infrared (up to 2050 nm): These detectors maintain sub-50 ps timing jitter, even for nanowires as wide as 250 nm and with detection areas of 20x20μm2. Our results establish that thinner films protected by a capping layer allow for the fabrication of wider wires, decreasing nanofabrication challenges and extending the operating temperature range for efficient single photon detection.

</details>


### [15] [Hardware-Agnostic Modeling of Quantum Side-Channel Leakage via Conditional Dynamics and Learning from Full Correlation Data](https://arxiv.org/abs/2602.15966)
*Brennan Bell,Andreas Trügler,Konstantin Beyer,Paul Erker*

Main category: quant-ph

TL;DR: 本文研究了在隐藏门序列期间，探针量子比特与目标量子比特相互作用的顺序相干侧信道模型，提出了一种机器学习解码器用于从实验相关记录中恢复门序列，并预测了随深度变化的最佳耦合带。


<details>
  <summary>Details</summary>
Motivation: 为了理解并量化在量子计算中由于侧信道攻击导致的信息泄露，特别是在连续操作过程中通过探针量子比特获取目标系统信息的可能性。

Method: 采用一种与耦合和测量方式无关的框架描述顺序探针模型，并在一个具体的实例（控制旋转耦合、固定投影读出和交换Rx门集）中推导出依赖于电路深度的信息泄露包络线，同时设计了一个基于机器学习的操作性解码器。

Result: 发现存在一个随电路深度变化的‘金发姑娘’耦合带，在此范围内可以最大化信息提取；提出的机器学习解码器能够在不同耦合强度和噪声条件下泛化，实现对门序列的高精度恢复；实验表明序列恢复性能在预测的耦合带附近集中，并随着退相干和有限采样误差而可预测地下降。

Conclusion: 该工作揭示了量子侧信道攻击中信息泄露的深度依赖特性，提出了有效的分析框架和解码方法，为评估和防范此类安全威胁提供了理论基础和实用工具。

Abstract: We study a sequential coherent side-channel model in which an adversarial probe qubit interacts with a target qubit during a hidden gate sequence. Repeating the same hidden sequence for $N$ shots yields an empirical full-correlation record: the joint histogram $\widehat{P}_g(b)$ over probe bit-strings $b\in\{0,1\}^k$, which is a sufficient statistic for classical post-processing under identically and independently distributed (i.i.d.) shots but grows exponentially with circuit depth. We first describe this sequential probe framework in a coupling- and measurement-agnostic form, emphasizing the scaling of the observation space and why exact analytic distinguishability becomes intractable with circuit depth.
  We then specialize to a representative instantiation (a controlled-rotation probe coupling with fixed projective readout and a commuting $R_x$ gate alphabet) where we (i) derive a depth-dependent leakage envelope whose maximizer predicts a "Goldilocks" coupling band as a function of depth, and (ii) provide an operational decoder, via machine learning, a single parameter-conditioned map from $\widehat{P}_g$ to Alice's per-step gate labels, generalizing across coupling and noise settings without retraining. Experiments over broad coupling and noise grids show that strict sequence recovery concentrates near the predicted coupling band and degrades predictably under decoherence and finite-shot estimation.

</details>


### [16] [Strong-to-Weak Symmetry Breaking in Open Quantum Systems: From Discrete Particles to Continuum Hydrodynamics](https://arxiv.org/abs/2602.16045)
*Jacob Hauser,Kaixiang Su,Hyunsoo Ha,Jerome Lloyd,Thomas G. Kiely,Romain Vasseur,Sarang Gopalakrishnan,Cenke Xu,Matthew P. A. Fisher*

Main category: quant-ph

TL;DR: 研究了在U(1)对称开放系统动力学下强到弱对称性自发破缺（SW-SSB）的出现，发现在一维中有限时间内不发生强对称性破缺，但相关函数在随时间线性增长的长度尺度上形成序；二维中存在类似BKT的有限时间相变，而连续流体力学中则在无穷小时间即发生SW-SSB，标志着连续流体力学描述的 emergence。


<details>
  <summary>Details</summary>
Motivation: 探索在电荷守恒的开放量子系统中，强对称性如何向弱对称性自发破缺，以及这一现象在不同维度下的时空演化特征和物理含义。

Method: 结合场论分析、数值模拟和解码协议构造，在三种互补模型中研究SW-SSB现象，包括具有短时量子相干性的非平庸模型，并通过子区域电荷推断问题解释其物理起源。

Result: 一维中无有限时间强对称破缺，但SW-SSB关联长度随时间线性增长；二维支持有限时间BKT类相变；连续流体力学预测在高维瞬时发生SW-SSB，表明该转变时间对应于非流体自由度丢失的时标。

Conclusion: SW-SSB的出现时间可视为连续流体力学描述开始有效的标志，反映了从微观量子动力学到宏观经典随机流体行为的过渡。

Abstract: We explore the onset of spontaneous strong-to-weak symmetry breaking (SW-SSB) under U(1)-symmetric (i.e., charge-conserving) open-system dynamics. We define this phenomenon for quantum states and classical probability distributions, and explore it in three complementary models, one of which exhibits nontrivial quantum coherence at short times. Our main conclusions are as follows. In one dimension, the strong symmetry is not spontaneously broken at any finite time; however, correlators probing strong-to-weak symmetry breaking develop order on length scales that grow linearly in time, parametrically faster than charge diffusion. We provide numerical evidence for this scaling in multiple distinct probes of SW-SSB, and derive it from a field-theory analysis. Moreover, we relate this scaling to the problem of inferring the charge inside a subregion by measuring its surroundings, and construct explicit decoding protocols that illustrate its origin. In two dimensions, field theory and numerical simulations support a finite-time Berezinskii-Kosterlitz-Thouless-like SW-SSB transition. Within continuum hydrodynamics, by contrast, SW-SSB happens at infinitesimal time in two or more dimensions. The SW-SSB transition time can thus be interpreted as marking the emergence of a continuum hydrodynamic description, or (more precisely) the timescale beyond which non-hydrodynamic information such as discrete particle worldlines can no longer be inferred. We support this picture by analyzing a model in which we exploit SW-SSB to derive a classical stochastic hydrodynamic description from the underlying quantum dynamics.

</details>


### [17] [Reinforcement learning for path integrals in quantum statistical physics](https://arxiv.org/abs/2602.16176)
*Timour Ichmoukhamedov,Dries Sels*

Main category: quant-ph

TL;DR: 本文提出了一种利用强化学习计算欧几里得路径积分的方法，用于获得量子系统的热密度矩阵，并通过两步法先变分近似后精确计算自由能等热力学量。


<details>
  <summary>Details</summary>
Motivation: 探索在路径积分框架下应用机器学习的新途径，弥补当前研究中对此方法关注不足的问题。

Method: 采用强化学习方法，设计两步策略：第一步得到目标量的变分近似，第二步利用该近似高效计算精确结果。

Result: 在多个简单系统上验证了该方法的有效性，并成功应用于量子转子链系统。

Conclusion: 强化学习可用于计算量子系统的热性质，所提出的两步法兼具近似效率与精确计算能力，拓展了机器学习在计算量子物理中的应用路径。

Abstract: Machine learning is rapidly finding its way into the field of computational quantum physics. One of the most popular and widely studied approaches in this direction is to use neural networks to model quantum states (NQS) in the Hamiltonian formulation of quantum mechanics. However, an alternative angle of attack to leverage machine learning in physics is through the path integral formulation, which has so far received far more limited attention. In this paper, we explore how reinforcement learning can be used to compute a class of Euclidean path integrals that yield the thermal density matrix of a quantum system, thereby enabling the computation of the free energy or other thermal expectation values. In particular, we propose a two-step approach with the unique feature that after a variational approximation for a quantity is obtained in a first step, it can then be used to efficiently compute the exact result in a second step. We benchmark this method on several simple systems and then apply it to the quantum rotor chain.

</details>


### [18] [Benchmarking the Lights Out Problem on Real Quantum Hardware](https://arxiv.org/abs/2602.16014)
*Maksims Dimitrijevs,Maria Palchiha,Abuzer Yakaryilmaz*

Main category: quant-ph

TL;DR: 本文研究了在2D网格和莫比乌斯梯形图上实现“熄灯”问题，并在真实量子硬件上评估Grover搜索算法的性能，使用了IBM和IQM提供的9和16量子比特实例。实验表明，IBM的Heron r2相比r1有所改进，而IQM设备上的输出分布接近均匀。通过小规模Grover SAT基准测试发现，IQM Garnet表现更稳定，且相同制造版本的量子处理单元性能差异显著，校准质量对性能影响重大。


<details>
  <summary>Details</summary>
Motivation: 探索Grover算法在真实量子硬件上的可行性与性能限制，特别是在不同拓扑结构（如2D网格和莫比乌斯梯）中的应用，并评估当前NISQ设备的实际计算能力。

Method: 在IBM和IQM的公开量子硬件上实现Lights Out问题的Grover搜索算法，使用9和16量子比特电路，并运行Grover SAT基准测试以分析设备性能差异与校准影响。

Result: IBM Heron r2相比r1有性能提升；IQM设备上Lights Out电路输出接近均匀分布；IQM Garnet在基准测试中表现最可靠；相同制造批次的设备性能存在显著差异；设备校准对结果影响显著。

Conclusion: 当前量子硬件在执行复杂算法时仍受限于校准质量和设备间差异，选择合适的设备需综合考虑校准状态而非仅依赖型号或发布顺序。

Abstract: We implement the Lights Out problem on a 2D grid and on Mobius ladder graphs and evaluate the performance of Grover's search on real quantum hardware. We use two instances using 9 and 16 qubits, and implement them on publicly available quantum hardware by IBM and IQM. Our experiments show improvements in IBM hardware between the Heron r1 and Heron r2 generations, highlighting progress in IBM hardware during the 2023-2024 period. The Lights Out circuits produced output distributions close to uniform on IQM devices. To diagnose device limitations, we additionally ran a small Grover SAT baseline, finding that IQM Garnet performs more reliably than other tested IQM devices. We also observed that QPUs of the same manufacturing revision can differ significantly in performance (a newer device is not guaranteed to be better), and that calibration has a significant impact on the performance of quantum devices, so the choice of device strongly depends on calibration quality.

</details>


### [19] [Device for MHz-rate rastering of arbitrary 2D optical potentials](https://arxiv.org/abs/2602.16025)
*Edita Bytyqi,Josiah Sinclair,Joshua Ramette,Vladan Vuletić*

Main category: quant-ph

TL;DR: 提出一种可在任意二维图案上以1 MHz刷新率运行的光学扫描装置，用于增强中性原子阵列中的量子比特操控能力。


<details>
  <summary>Details</summary>
Motivation: 现有中性原子阵列架构受限于声光偏转器（AODs）的速度和几何约束，难以实现高速、灵活的多方向量子比特操控。

Method: 设计并演示了一种新型光学栅格装置，支持任意二维模式的快速生成，分辨率达40x40，并可扩展至100x100。

Result: 该装置实现了1 MHz的刷新率，突破了传统行/列式移动限制，支持任意方向的原子量子比特并行传输。

Conclusion: 该技术提升了中性原子量子系统的连接性和电路效率，具有在量子计算、LiDAR和荧光显微镜等领域的广泛应用潜力。

Abstract: Current architectures for neutral-atom arrays utilize devices such as acousto-optic deflectors (AODs) and spatial light modulators (SLMs) to multiplex a single classical control line into N qubit control lines. Dynamic control is speed-limited by the response time of AODs, and geometrically constrained to respect a product structure, limiting motion to row-by-row or column-by-column moves. We propose an optical rastering device that can produce any 2D pattern, not limited to grids, at 1 MHz refresh rates. We demonstrate a design with a resolution of 40 x 40 that can be further scaled up to 100 x 100 to match existing and future neutral atom devices. The ability to simultaneously transport atomic qubits in arbitrary directions will enhance qubit connectivity, enable more efficient circuits, and may have broader applications ranging from LiDAR to fluorescence microscopy.

</details>


### [20] [Multi-emitter oscillating bound states in Waveguide QED](https://arxiv.org/abs/2602.16032)
*Sergi Terradas-Briansó,Carlos A. González-Gutiérrez,Iván Huarte,David Zueco,Luis Martin-Moreno*

Main category: quant-ph

TL;DR: 本文研究了在腔阵列波导中与两个空间分离的量子发射器耦合下束缚态叠加的形成与动力学，发现通过调节系统参数可实现非局域平衡态，并支持光子密度在发射器间的振荡呼吸模式。


<details>
  <summary>Details</summary>
Motivation: 探索和实现非马尔可夫量子现象是当前量子电动力学的重要课题，特别是在波导系统中如何通过自发辐射形成稳定的非局域量子态仍需深入研究。

Method: 通过解析推导束缚态出现的条件，并结合数值模拟方法，研究在自发辐射过程中束缚态叠加的形成及其长时演化行为。

Result: 发现了嵌入和位于能带外的束缚态共存导致的混合振荡模式，实现了无需外部驱动的发射器间相互作用及光子密度的持续振荡。

Conclusion: 该工作表明，在可调参数条件下，腔阵列波导系统可用于生成具有持久振荡特性的非局域量子态，为非马尔可夫动力学和量子信息处理提供了新途径。

Abstract: Waveguide quantum electrodynamics platforms have emerged as promising candidates for exploring and implementing non-Markovian quantum phenomena. In this work, we investigate the formation and dynamics of superpositions of bound states in a cavity array waveguide coupled to two spatially separated quantum emitters. By tuning the system parameters, we show that spontaneous emission can drive the system into non-local equilibrium states in which both photonic and emitter populations exhibit persistent oscillations. These states arise from the coexistence of bound states embedded in the energy continuum and bound states outside it, leading to hybrid oscillatory modes. We analytically derive the conditions required for the emergence of these states, numerically simulate their formation through spontaneous emission, and predict their long-time behaviour. Our results demonstrate that such bound-state superpositions enable the generation of emitter-emitter interaction through free evolution, while supporting oscillatory breathing modes of the photon density between the emitters.

</details>


### [21] [Contractivity of time-dependent driven-dissipative systems](https://arxiv.org/abs/2602.16067)
*Lasse H. Wolff,Daniel Malz,Rahul Trivedi*

Main category: quant-ph

TL;DR: 本文研究了具有固定耗散器但时间依赖哈密顿驱动的Lindblad主方程的动力学压缩性，提出了在小或慢驱动下指数压缩的条件，并给出了与哈密顿无关的压缩性的充分条件。


<details>
  <summary>Details</summary>
Motivation: 理解在时间依赖控制下量子系统是否仍会因环境退相干而失去初始信息，特别是在动力学是否指数压缩方面的行为。

Method: 分析具有固定耗散器和时变哈密顿量的Lindblad方程，研究其在不同驱动强度和速度下的压缩性，并推导出与哈密顿无关的压缩性条件。

Result: 证明在足够小或足够慢的驱动下系统呈现指数压缩；给出反例显示强或快的哈密顿可能导致非压缩行为；并提出若干保证压缩性的耗散器条件。

Conclusion: 建立了时变Lindbladian系统指数压缩的判据，完全刻画了无条件压缩性在单比特系统和幺正耗散器中的情形。

Abstract: In a number of physically relevant contexts, a quantum system interacting with a decohering environment is simultaneously subjected to time-dependent controls and its dynamics is thus described by a time-dependent Lindblad master equation. Of particular interest in such systems is to understand the circumstances in which, despite the ability to apply time-dependent controls, they lose information about their initial state exponentially with time i.e., their dynamics are exponentially contractive. While there exists an extensive framework to study contractivity for time-independent Lindbladians, their time-dependent counterparts are far less well understood. In this paper, we study the contractivity of Lindbladians, which have a fixed dissipator (describing the interaction with an environment), but with a time-dependent driving Hamiltonian. We establish exponential contractivity in the limit of sufficiently small or sufficiently slow drives together with explicit examples showing that, even when the fixed dissipator is exponentially contractive by itself, a sufficiently large or a sufficiently fast Hamiltonian can result in non-contractive dynamics. Furthermore, we provide a number of sufficient conditions on the fixed dissipator that imply exponential contractivity independently of the Hamiltonian. These sufficient conditions allow us to completely characterize Hamiltonian-independent contractivity for unital dissipators and for two-level systems.

</details>


### [22] [Lie-Algebraic Analysis of Generators: Approximation-Error Bounds and Barren-Plateau Heuristics](https://arxiv.org/abs/2602.16094)
*Hiroshi Ohno*

Main category: quant-ph

TL;DR: 本文从函数逼近的角度，利用李代数框架分析参数化量子电路的傅里叶模式，提出了在Sobolev空间下量子电路逼近误差的上下界、基于非对易生成元的生成元选择规则，以及表征 barren plateau 现象的启发式度量，并通过实验验证了频谱视角的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和优化混合量子-经典学习中的参数化量子电路，需要从函数逼近的角度分析其表达能力，并解决训练中如barren plateau等问题。

Method: 利用李代数和生成元的谱性质建模量子电路的可访问傅里叶频率；推导在Sobolev球上的L²逼近误差的minimax下界和Jackson型上界；提出通过非对易生成元扩展有效频率集的选择准则；设计基于生成元迹成分的启发式指标以反映训练行为。

Result: 得到了逼近误差随有效带宽变化的标度律Ω(K^{d/2−r})；提出了提升表达能力的生成元选择方法；给出了与barren plateau相关的简单启发式度量；仿真验证了理论分析和启发式策略的有效性。

Conclusion: 李代数框架为分析量子机器学习中的逼近能力和训练动态提供了有力工具，通过控制生成元的谱结构可有效提升量子电路的性能并缓解训练困难。

Abstract: Lie algebras provide a useful framework for theoretical analysis in quantum machine learning, particularly in hybrid quantum-classical learning. From the viewpoint of function approximation, expectation values of parameterized quantum circuits can be viewed as trigonometric polynomials whose accessible Fourier modes are determined by the spectra of the generators. In this study, we describe: (1) a minimax lower bound on the $ L^{2} $-approximation error over a Sobolev ball when the circuit's effective frequency set is contained in a radius-$K$ ball, which yields a scaling law of the form $ Ω(K^{\frac{d}{2} - r}) $ for $ r > \frac{d}{2} $ (assuming the target function belongs to the Sobolev space $ W_2^{r}(\mathbb{T}^{d}) $), and we also derive a Jackson-type upper bound on the approximation error of quantum circuits under Sobolev regularity of the target function, expressed in terms of an effective bandwidth determined by generator spectral gaps; (2) a generator-selection rule motivated by enlarging the effective frequency set via non-commuting generators; and (3) a simple heuristic metric based on the trace component of generators, aimed at characterizing training behaviors related to barren plateaus. Simulation experiments on toy problems illustrate the practical implications of the frequency-spectrum perspective and the proposed heuristics.

</details>


### [23] [Local and Multi-Scale Strategies to Mitigate Exponential Concentration in Quantum Kernels](https://arxiv.org/abs/2602.16097)
*Claudia Zendejas-Morales,Debashis Saikia,Utkarsh Singh*

Main category: quant-ph

TL;DR: 研究了基于保真度的量子核在高维或高表达性电路下的指数集中问题，提出并评估了局部和多尺度核作为缓解策略。


<details>
  <summary>Details</summary>
Motivation: 解决保真度量子核随系统规模增大或电路表达能力增强时出现的指数集中问题，导致相似性结构丧失。

Method: 在Qiskit中实现两种缓解策略：局部（分块）核和多尺度核，并在多个表格数据集上对基线、局部和多尺度核进行基准测试，控制相同预处理、数据划分和SVM协议，扫描特征维度范围d∈{4,6,…,20}。

Result: 局部和多尺度核在抑制核矩阵集中、提升谱丰富性方面表现一致优于全局保真度核；核与标签的中心对齐度更高；但分类准确率的提升因数据集和维度而异。

Conclusion: 局部和多尺度量子核能有效缓解指数集中问题，增强核的表达能力，是改进量子核方法的可行方向，但其对最终分类性能的影响需结合具体任务评估。

Abstract: Fidelity-based quantum kernels provide a direct interface between quantum feature maps and classical kernel methods, but they can exhibit exponential concentration: with increasing system size or circuit expressivity, the Gram matrix approaches the identity and suppresses informative similarity structure. We present an empirical study of two mitigation strategies implemented in Qiskit: (i) local (patch-wise) kernels that aggregate subsystem similarities, and (ii) multi-scale kernels that mix local and global similarity across patch granularities.
  We benchmark baseline, local, and multi-scale kernels under matched preprocessing, splits, and SVM protocols on several tabular datasets, sweeping the feature dimension $d\in\{4,6,\dots,20\}$. We report concentration diagnostics based on off-diagonal kernel statistics, spectral richness via effective rank, and centered alignment with labels. Across datasets, local and multi-scale constructions consistently mitigate concentration and yield richer kernel spectra relative to the global fidelity baseline, while the impact on classification accuracy depends on the dataset and dimension.

</details>


### [24] [Reductions of QAOA Induced by Classical Symmetries: Theoretical Insights and Practical Implications](https://arxiv.org/abs/2602.16141)
*Boris Tsvelikhovskiy,Bao Bach,Jose Falla,Ilya Safro*

Main category: quant-ph

TL;DR: 本研究探讨了如何利用经典对称性作为量子近似优化算法（QAOA）的设计原则，特别针对MaxCut问题中的全局比特翻转对称性。通过固定单个变量来研究简化后的QAOA实例及其动力学李代数（DLA）结构的变化，发现不同变量的固定会导致DLA维度显著变化，甚至从指数级降至二次方。数值实验表明，在非对称图上这种简化通常会产生维度更小的DLA，从而可能提高可训练性。此外，证明了任何图都可以嵌入到稍大的图中（仅需二次开销），使得标准简化DLA与自由简化DLA一致，大多数情况下意味着简化QAOA实例在希尔伯特空间上的指数维度和不可约性。这些结果确立了基于对称性感知简化的QAOA电路设计方法。


<details>
  <summary>Details</summary>
Motivation: 量子近似优化算法（QAOA）的表现与其哈密顿量生成的动力学李代数（DLA）结构密切相关，而DLA决定了算法的表达能力和可训练性。然而，现有QAOA设计缺乏系统性的结构指导原则，尤其是在利用经典对称性方面尚未充分探索。因此，本文旨在通过引入对称性感知的简化策略，揭示其对DLA结构的影响，并为构建更具表达性和可训练性的QAOA电路提供理论依据。

Method: 聚焦于具有全局比特翻转对称性的MaxCut问题，分析通过固定单一变量得到的简化QAOA实例，并研究该选择如何影响相应的动力学李代数（DLA）结构。采用数学构造方法展示特定例子中DLA维度从指数级坍缩至二次方的现象。同时，进行数值实验以评估在非对称图上简化后DLA维度的变化趋势。进一步地，提出一种图嵌入方案，将任意图扩展为稍大的图，使得标准简化DLA与自由简化DLA相一致，进而推导出其在多数情况下的指数维度和不可约性。

Result: 1. 发现固定不同变量会显著改变QAOA的动力学李代数（DLA）结构，某些情况下DLA维度可从指数级降至二次方；2. 数值实验证明在非对称图中，简化后的QAOA通常产生更低维度的DLA，暗示更好的可训练性；3. 提出并证明了一种图嵌入方法，可在仅需二次开销的情况下使标准简化DLA与自由简化DLA一致，大多数情况下保证DLA具有指数维度和希尔伯特空间上的不可约性。

Conclusion: 通过对称性感知的变量固定策略，可以系统性地设计更具表达性和潜在可训练性的QAOA电路。该方法不仅揭示了DLA结构对QAOA性能的关键影响，还为未来量子算法设计提供了新的理论工具和优化路径。

Abstract: The performance of the Quantum Approximate Optimization Algorithm (QAOA) is closely tied to the structure of the dynamical Lie algebra (DLA) generated by its Hamiltonians, which determines both its expressivity and trainability. In this work, we show that classical symmetries can be systematically exploited as a design principle for QAOA. Focusing on the MaxCut problem with global bit-flip symmetry, we analyze reduced QAOA instances obtained by fixing a single variable and study how this choice affects the associated DLAs. We show that the structure of the DLAs can change dramatically depending on which variable is held fixed. In particular, we construct explicit examples where the dimension collapses from exponential to quadratic, uncovering phenomena that do not appear in the original formulation.
  Numerical experiments on asymmetric graphs indicate that such reductions often produce DLAs of much smaller dimension, suggesting improved trainability. We also prove that any graph can be embedded into a slightly larger one (requiring only quadratic overhead) such that the standard reduced DLA coincides with the free reduced DLA, in most cases implying exponential dimension and irreducibility on the Hilbert space for reduced QAOA instances. These results establish symmetry-aware reduction as a principled tool for designing expressive and potentially trainable QAOA circuits.

</details>


### [25] [Squeezed superradiant lasing of a quantum many-body emitter](https://arxiv.org/abs/2602.16215)
*Da-Wu Xiao,Chong Chen,Ren-Bao Liu*

Main category: quant-ph

TL;DR: 提出了量子多体激光器的概念，利用相干相互作用的发射体实现集体辐射，并将自旋压缩传递给光子，生成具有超越传统光学相干性的量子关联光。


<details>
  <summary>Details</summary>
Motivation: 探索超越传统激光和超辐射激光的新型光源，实现具有量子关联的明亮量子光，推动量子技术和量子非线性光学研究。

Method: 研究一个耦合到多个泵浦自旋-1/2发射体（具有全对全相互作用）的光学腔系统，理论分析其在相干多体相互作用下的激光行为。

Result: 发现相干多体相互作用引起的自旋压缩可以通过超辐射激光传递给光子，产生具有量子关联的光场。

Conclusion: 量子多体激光器能够生成具有非经典量子相关性的亮光源，为量子光学和量子技术提供了新平台。

Abstract: In conventional lasers, the emitters are typically incoherent, radiating photons independently; in superradiant lasers, many coherent emitters radiate photons collectively, but they essentially do not interact with each other. Here, we present the concept of quantum many-body lasers, in which the emitters interact coherently and radiate collectively. In this proof-of-concept study, we consider a cavity coupled to many pumped spin-1/2 emitters with all-to-all interaction. We find that the squeezing induced by the coherent many-body interaction can be transferred from the spins to photons through superradiant lasing. This work illustrates the concept of using a pumped quantum many-body system to generate bright quantum light with quantum correlations beyond conventional optical coherence, which can facilitate quantum technologies and the study of nonlinear optics in the quantum realm.

</details>


### [26] [Tomographically-nonlocal entanglement](https://arxiv.org/abs/2602.16280)
*Roberto D. Baldijão,Marco Erba,David Schmid,John H. Selby,Ana Belén Sainz*

Main category: quant-ph

TL;DR: 本文研究了在广义概率理论框架下，当系统不具备层析局域性时出现的两种不同类型的纠缠：层析局域纠缠和层析非局域纠缠，并揭示了它们在贝尔非定域性、导引、量子隐形传态、密集编码和数据隐藏等任务中的不同操作意义。


<details>
  <summary>Details</summary>
Motivation: 探讨在存在对称性或超选择规则等物理约束下，量子纠缠行为的改变，尤其是当层析局域性失效时（如在实量子理论、twirled世界或费米子量子理论中），纠缠表现出的反直觉现象的根源。

Method: 采用广义概率理论框架，分析在不具备层析局域性的理论中纠缠的结构，区分出层析局域与非局域纠缠，并研究其在各类量子信息任务中的操作后果。

Result: 发现层析非局域纠缠无法用于贝尔非定域性、导引和量子隐形传态，但可用于密集编码和完美安全的数据隐藏；而层析局域纠缠则支持前者。

Conclusion: 层析局域性的缺失导致纠缠分为两种本质不同的类型，该框架解释了此前在费米子或超选择规则下量子纠缠中一些令人困惑的现象。

Abstract: Entanglement is a central and subtle feature of quantum theory, whose structure and operational behavior can change dramatically when additional physical constraints, such as symmetries or superselection rules, are imposed. Such constraints can give rise to striking and counter-intuitive phenomena, including local broadcasting of entangled states and failures of entanglement monogamy. These effects naturally arise in tomographically nonlocal theories (like real quantum theory, twirled worlds, or fermionic quantum theory), where composite systems possess holistic degrees of freedom that are inaccessible to local measurements. In this work, we study entanglement in such theories within the framework of generalized probabilistic theories. We show that the failure of tomographic locality leads to two qualitatively distinct forms of entanglement, which we term $\textit{tomographically-local}$ entanglement and $\textit{tomographically-nonlocal}$ entanglement. We analyze the operational consequences of this distinction, proving that tomographically-nonlocal entanglement is useless for Bell nonlocality, steering, and teleportation, but sufficient for dense coding and perfectly secure data hiding. This framework clarifies the origin of several previously puzzling features of entanglement that arise when tomographic locality fails, as can happen even in quantum theory when one considers fermions or fundamental superselection rules.

</details>


### [27] [What Kind of World Supports Darwinian Evolution? Quantum Foundational Options](https://arxiv.org/abs/2602.16286)
*Partha Ghose*

Main category: quant-ph

TL;DR: 该论文探讨了量子力学中的经典数据产生与达尔文进化论所需的记录、复制和不可逆性之间的联系，强调在完全相干的量子体系中由于不可克隆定理和线性特性导致主体性失效，并通过退相干和随机力学为量子到经典的过渡提供原则性解释。


<details>
  <summary>Details</summary>
Motivation: 理解量子力学如何支持需要稳定记录和复制的达尔文式进化过程，以及在无经典结构的纯量子世界中主体性和事实性的基础问题。

Method: 运用范畴量子力学（CQM）分析‘复制’与‘删除’操作仅在存在经典数据部门时才可能实现，并结合退相干理论与扩展的维格纳朋友场景进行概念分析，同时引入具有可变扩散的随机力学模型作为桥梁。

Result: 表明经典数据的出现是实现稳定记录和主体性的关键；退相干不足以确定唯一历史，需引入额外本体假设；在纯量子区域最小主体性因不可克隆和线性而失败；随机力学提供了从量子到经典的连续过渡路径，并为测量更新提供时间对称的最小改变规则。

Conclusion: 经典结构的出现对于实现可遗传记录和主体性至关重要，而从量子到经典的转变需要包括退相干、选择机制或随机动力学在内的补充原理来完成。

Abstract: Darwinian evolution requires (i) heritable records, (ii) repeatable copying with variation, and (iii) routine irreversibility. Categorical quantum mechanics (CQM) makes precise why ``copy'' and ``delete'' are not generic quantum operations: they exist only for a realized \emph{classical data} sector (a preferred basis/observable; a commutative structure). Decoherence explains how a pointer basis can be selected dynamically, but it does not by itself select a unique outcome. This motivates a neutral presentation of the main ontological options (unique-history, decohered multiplicity, agent-relative facticity, and a stochastic foundation with variable diffusion). We also note the relevance of the ``agency constraint'' argued by Adlam-McQueen-Waegell: in a strictly coherent, basis-unselected ``purely quantum'' regime, minimal agency fails due to no-cloning and linearity, which sharpens the role of classical resources for record-based processes. Extended Wigner's Friend scenarios then serve as a stress test, since they treat ``friends'' simultaneously as coherent quantum systems and as agents possessing stable records. Finally, a stochastic-mechanics foundation (with variable diffusion) offers a continuous bridge between quantum and classical regimes, and suggests a principled way to implement measurement update as conditioning plus a time-symmetric minimal-change rule.

</details>


### [28] [A resolution of the Ito-Stratonovich debate in quantum stochastic processes](https://arxiv.org/abs/2602.16314)
*Aritro Mukherjee*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum stochastic processes are widely used in describing open quantum systems and in the context of quantum foundations. Physically relevant quantum stochastic processes driven by multiplicative colored noise are generically non-Markovian and analytically intractable. Further, their Markovian limits are generically inequivalent when using either the Ito or Stratonovich conventions for the same quantum stochastic processes. We introduce a quantum noise homogenization scheme that temporally coarse-grains non-Markovian, colored-noise driven quantum stochastic processes and connects them to their effective white-noise (Markovian) limits. Our approach uses a novel phase-space augmentation that maps the non-Markovian dynamics into a higher dimensional Markovian system and then applies a controlled perturbative coarse-graining scheme in the characteristic time scales of the noise. This allows an explicit analytical algorithm to derive effective Markovian generators with renormalized coefficients and enables imposing various physical constraints on them. We thus resolve the Ito-Stratonovich ambiguity for multiplicative colored noise driven quantum stochastic processes, wherein we show that their consistent Markovian limit corresponds to the Stratonovich convention with renormalized coefficients as well as Ito correction terms. By assuming their Markovian limit unravels completely positive, trace-preserving maps, we further characterize a physically relevant family of non-Markovian quantum stochastic processes driven by multiplicative colored noise.

</details>


### [29] [Quantum-enhanced sensing via spectral noise reduction](https://arxiv.org/abs/2602.16350)
*Romain Dalidet,Sébastien Tanzilli,Audrey Dot,Inès Ghorbel,Loïc Morvan,Laurent Labonté,Anthony Martin*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We report a direct demonstration of quantum-enhanced sensing in the Fourier domain by comparing single- and two-photon interference in a fiber-based interferometer under strictly identical noise conditions. The simultaneous acquisition of both signals provides a common-mode reference that enables a fair and unambiguous benchmark of quantum advantage. Spectral analysis of the interferometric outputs reveals that quantum correlations do not increase the amplitude of the modulation peak, but instead lower the associated noise floor, resulting in the expected 3 dB improvement in signal-to-noise ratio. This enhancement persists in the sub-shot-noise regime, where the classical signal becomes buried in the spectral background while the two-photon contribution remains resolvable. These observations establish Fourier-domain quantum super-sensitivity as an operational and broadly applicable resource for precision interferometric sensing.

</details>


### [30] [A Formal Theory for Finite-Dimensional Possibilistic Quantum Mechanics](https://arxiv.org/abs/2602.16368)
*Olivier Brunet*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, we present a logical formalism for reasoning about quantum systems in finite dimension. Contrary to the usual approach in quantum logic, our formalism is based classical first-order logic, which allows us to use the tools of model theory in our study. In particular, we show that our formal theory is complete, meaning that it entirely determines the behaviour of quantum systems. Moreover, we provide a characterization of the models of our formal theory, thus providing new insights in the study of hidden variable models of quantum theory.

</details>


### [31] [Why the Casimir Force for Magnetic Metals Computed by the Lifshitz Theory Using the Drude Model Disagrees with the Measurement Data](https://arxiv.org/abs/2602.16370)
*G. L. Klimchitskaya,C. C. Korikov,V. M. Mostepanenko*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider the Casimir force in configurations with magnetic metal plates and analyze the reasons why the predictions of the Lifshitz theory using the dielectric permittivity of the Drude model are inconsistent with the measurement data. For this purpose, the contributions of the electromagnetic waves with the transverse magnetic and transverse electric polarizations to the Casimir force are computed using the Lifshitz theory expressed in terms of the pure imaginary Matsubara frequencies. Furthermore, the fractions of the evanescent and propagating waves in these contributions are found using an equivalent formulation of the Lifshitz theory along the real frequency axis. All computations are performed for Au-Ni and Ni-Ni plates using the Drude model and the experimentally consistent plasma model over the separation region from 0.5 to 6~mum, where the total force value is determined by conduction electrons. It is shown that the transverse magnetic contribution to the Casimir force does not depend on the used model of the dielectric permittivity, so that the total difference between the predictions of the Lifshitz theory using the Drude model and the measurement data is determined by the transverse electric contribution. In doing so, as opposed to the case of nonmagnetic metals, both fractions of the evanescent and propagating waves in this contribution depend on the model of the dielectric permittivity used in computations, whereas the magnetic properties of the plate metal influence the Casimir force solely through the fraction of propagating waves in the transverse electric contribution. The issue of a more adequate theoretical description of the electromagnetic response of magnetic metals is discussed.

</details>


### [32] [Solving the Mysteries of Quantum Mechanics: Why Nature Abhors a Continuum](https://arxiv.org/abs/2602.16382)
*Tim Palmer*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Feynman famously asserted that interference is the only real mystery in quantum mechanics (QM). It is concluded that the reason for this mystery, and thereby the related mysteries of complementarity, non-commutativity of observables, the uncertainty principle and violation of Bell's equality, is that the axioms of QM depend vitally on the continuum nature of Hilbert Space, deemed unphysical. We develop a theory of quantum physics - Rational Quantum Mechanics (RaQM) - in which Hilbert Space is gravitationally discretised. The key to solving the mysteries of QM in RaQM is a number-theoretic property of the cosine function, concealed in QM when angles range over the continuum. This number-theoretic property describes mathematically the utter indivisibility of the quantum world and implies that the laws of physics are profoundly holistic. We contrast holism with nonlocality. In theories which embrace the continuum, the violation of Bell's inequality requires the laws of physics to be either nonlocal or not realistic; both incomprehensible concepts. By contrast, holism, as embodied in Mach's Principle or in the fractal geometry of a chaotic attractor, is neither incomprehensible nor unphysical. As part of this, we solve the deepest mystery of all; why nature makes use of complex numbers.

</details>


### [33] [Enhancing delocalization and entanglement in asymmetric discrete-time quantum walks](https://arxiv.org/abs/2602.16391)
*Hao Zhao,Qiyan He,Fengzhi Yang,Cui Kong,Huiyun Cao,Tianqi Yan,Bingrui Zhong,Kaikun Tian,Jiguo Wang,Chuanjia Shan,Jibing Liu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we investigate the enhancement of delocalization and coin-position entanglement in asymmetric discrete-time quantum walks (DTQWs). The asymmetry results from asymmetric coin operations, asymmetric initial states, and asymmetric polarization-dependent losses. By varying these asymmetry factors, the inverse participation ratio and entanglement entropy of the walker are numerically calculated for different coin and loss parameters, both for symmetric and asymmetric initial states. We then experimentally implement a 16-step asymmetric DTQW using a time-multiplexing fiber loop structure. By choosing an asymmetric initial state, both coin-position entanglement and delocalization are simultaneously enhanced under specific coin parameters. Moreover, we observe that with finite asymmetric polarization-dependent loss, the photon probability on the left side decreases significantly, while that on the right side increases and becomes more localized. Interestingly, under specific coin parameters, the entanglement and delocalization exhibit improved robustness against polarization-dependent loss. These results demonstrate that the DTQWs constitute an ideal platform for investigating photonic delocalization and hybrid entanglement.

</details>


### [34] [Measurement Induced Subradiance](https://arxiv.org/abs/2602.16413)
*Ipsita Bar,Aditi Thakar,B. Prasanna Venkatesh*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Preparing subradiant steady states of collectively emitting quantum two-level emitters (TLEs) is hindered by their dark, weakly interacting nature. Existing approaches rely on patterned driving, local control, or structured environments. We propose a platform-independent protocol based on projective measurements on a single TLE. For permutation-symmetric ensembles, a single measurement yields appreciable occupation of single-excitation subradiant steady states. For generic arrays, repeated measurements on one emitter drive the unmeasured TLEs into a nearly pure state with large overlap with the subradiant Dicke subspace.

</details>


### [35] [Nonlocal prediction of quantum measurement outcomes](https://arxiv.org/abs/2602.16426)
*Chirag Srivastava,Aparajita Bhattacharyya,Ujjwal Sen*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We define nonlocal predictability as how well one observer can predict another's measurement outcomes without classical communication, given full knowledge of the shared quantum state and measurement settings. The local bound on nonlocal predictability is defined as the maximum probability with which one observer can correctly predict the other's measurement outcome prior to measurement. We show that product states always meet this bound, while all pure entangled states and some classically correlated states can exceed it. This demonstrates a nonlocal phenomenon since the predictability of measurement outcomes increases after the measurement. Perfect nonlocal predictability for arbitrary projective measurements occurs only for maximally entangled states among all pure states, underscoring their special role. Comparing pure entangled states with their dephased versions, we find that dephasing on one subsystem can enhance nonlocal predictability for a broad class of states and measurements - a counterintuitive, noise-induced advantage that vanishes for maximally entangled states under any projective measurement.

</details>


### [36] [Edge states and quantum optical high-harmonic generation from topological insulators](https://arxiv.org/abs/2602.16454)
*Christian Saugbjerg Lange,Lars Bojer Madsen*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The strong-field process of high-harmonic generation (HHG) has, in recent years, been treated from a quantum optical perspective in the emerging research area of strong-field quantum optics. These investigations show that HHG radiation is, in general, in a nonclassical state of light. However, the quantum optical treatment of HHG from topological nontrivial materials is missing. Here, we aim to address this gap in current knowledge and consider the quantum optical HHG response from the Su-Schrieffer-Heeger model, a finite chain of atoms with both a topologically trivial and nontrivial insulating phase, the latter supporting edge states. We find that HHG from both topological phases is squeezed at the band-gap frequency. Interestingly, while the harmonic spectrum discriminates the two topological phases of the system, the degree of squeezing only discriminates the phases for smaller chain lengths. We attribute this difference to a relative increase in overlap between bulk and edge states in the topological nontrivial phase for smaller systems. Our findings reveal how the strength of dipole couplings governs the nonclassical HHG response and define new research questions on topologically protected generation of quantum light in strong-field physics.

</details>


### [37] [Quantitative study of Silicon Waveguides for the Generation of Quantum Correlated Photon Pairs Bridging Mid-Infrared and Telecom Bands](https://arxiv.org/abs/2602.16464)
*Abhishek Kumar Pandey,Deepak Jain,Catherine Baskiotis*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sources of quantum correlated photons pairs bridging the 3um-4um Mid-infrared (MIR) band and Telecom/Near-Infrared/Visible band are of high importance for quantum technologies. Spontaneous Parametric Down Conversion is generally used for realizing such sources, but requires costly implementation platforms with reduced versatility. Here, we explore the potentialities of Spontaneous Four-Wave Mixing (SFWM) in all-solid Silicon On Insulator (SOI) waveguides thanks to an experimentally validated model and propose designs ensuring the production of correlated photon pairs bridging the 3um-4um Mid-infrared band and Telecom C-band. Choosing a pump with a wavelength in the range 2100nm-2210nm and a pulse duration of 5ps, we quantitatively performed simulations targeting a probability of photon pair generation per pulse of 0.05, and we found realistic conditions of utilization (2cm-length straight waveguides, intra-modal Four Wave Mixing with the fundamental TE00 mode) with a pump peak power in between 9.2mW and 32mW. A first design (wCOM) reaches a signal wavelength as high as 3.905um, which is situated in an atmospheric transparency window, while maintaining an idler in the Telecom C-band, making it of high interest for atmospheric Quantum Key Distribution. Two other designs wCH4 and wNO2 aim precise CH4 and NO2 gas sensing with a signal wavelength of 3265nm and 3461nm respectively. In terms of signal/idler wavelength separation, wCOM attains the value of 2364nm which is well above the current record of ~1125nm obtained in quantum regime with SFWM in all-solid SOI waveguides.

</details>


### [38] [Nonequilibrium Casimir-Polder Force: Motion-induced Thermal-like Effect](https://arxiv.org/abs/2602.16483)
*D. Reiche,B. Beverungen,K. Busch,F. Intravaia*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Casimir-Polder force is analyzed when an atom is moving at a constant velocity relative to a collection of translationally invariant macroscopic bodies with generic shapes and compositions. The interaction is described within an approach that accurately treats the atom-field coupling and accounts for the backaction from the environment onto the moving particle. Previously overlooked aspects are uncovered and linked to the nonequilibrium and nonconservative nature of the interaction. Specifically, we examine a behavior that can be understood by characterizing the underlying physical processes in terms of a motional-induced effective temperature. This phenomenon shares similarities with the Fulling-Davies-Unruh effect, opening new perspectives for the understanding of nonequilibrium physics at work in the system.

</details>


### [39] [Port-based teleportation under pure-dephasing decoherence](https://arxiv.org/abs/2602.16513)
*Rajendra S. Bhati,Michał Studziński,Jarosław K. Korbicz*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study deterministic port based teleportation in the presence of noise affecting both the entangled resource state and the measurement process. We focus on a physically motivated model in which each Bell pair constituting the resource interacts with an identical local environment, corresponding to independently distributed entangled links. Two noisy scenarios are analyzed: one with decoherence acting solely on the resource state and ideal measurements, and another with noisy, noise adapted measurements optimised for the given noise model. In the first case, we derive an analytical lower bound and later a closed-form expression for the entanglement fidelity of the teleportation channel and analyze its asymptotic behaviour. In the second, we combine semi analytical and numerical methods. Surprisingly, we find that noise-adapted measurements perform worse than the noiseless ones. To connect the abstract noise description with microscopic physics, we embed the protocol in a spin boson model and investigate the influence of bath memory and temperature on the teleportation fidelity, highlighting qualitative differences between different environments.

</details>


### [40] [Bichromatic Quantum Teleportation of Weak Coherent Polarization States on a Metropolitan Fiber](https://arxiv.org/abs/2602.16613)
*Zofia A. Borowska,Shane Andrewski,Giorgio De Pascalis,Olivia Brasher,Mael Flament,Alexander N. Craddock,Niccolò Bigagli,Ronny Döring,Michaela Ritter,Ralf-Peter Braun,Klaus Jons,Marc Geitz,Oliver Holschke,Matheus Sena,Mehdi Namazi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As quantum technologies mature, telecommunication operators have a clear opportunity to unlock and scale new services by providing the connectivity layer that links quantum computers, sensors, clocks, and other quantum devices. Realizing this opportunity requires demonstrating quantum networking protocols, including quantum teleportation, under real-world conditions on existing telecom infrastructure. In this work, we demonstrate quantum teleportation over Deutsche Telekom's metropolitan fiber testbed in Berlin using commercial components deployed at the telecom datacenter. A local Bell-state measurement between 795 nm photons from a weak coherent source and from a bichromatic warm-atom entangled photon source enables conditional state transfer onto an O-band photon, which is transmitted through a 30-km field-deployed fiber loop under real-world environmental conditions. The teleported state is reconstructed after propagation via state tomography, achieving an average teleportation fidelity of 90\% on the deployed link. System performance is evaluated in both the absence and the presence of co-propagating C-band classical traffic within the same fiber, demonstrating compatibility with wavelength-division multiplexed telecom infrastructure carrying live data channels.

</details>


### [41] [Beyond the Classical Ceiling: Multi-Layer Fully-Connected Variational Quantum Circuits](https://arxiv.org/abs/2602.16623)
*Howard Su,Chen-Yu Liu,Samuel Yen-Chi Chen,Kuan-Cheng Chen,Huan-Hsin Tseng*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Standard Variational Quantum Circuits (VQCs) struggle to scale to high-dimensional data due to the ``curse of dimensionality,'' which manifests as exponential simulation costs ($\mathcal{O}(2^d)$) and untrainable Barren Plateaus. Existing solutions often bypass this by relying on classical neural networks for feature compression, obscuring the true quantum capability. In this work, we propose the \textbf{Multi-Layer Fully-Connected VQC (FC-VQC)}, a modular architecture that performs \textbf{end-to-end quantum learning} without trainable classical encoders. By restricting local Hilbert space dimensions while enabling global feature interaction via structured block mixing, our framework achieves \textbf{linear scalability $\mathcal{O}(d)$}. We empirically validate this approach on standard benchmarks and a high-dimensional industrial task: \textbf{300-asset Option Portfolio Pricing}. In this regime, the FC-VQC breaks the ``Classical Ceiling,'' outperforming state-of-the-art Gradient Boosting baselines (XGBoost/CatBoost) while exhibiting \textbf{$\approx 17\times$ greater parameter efficiency} than Deep Neural Networks. These results provide concrete evidence that pure, modular quantum architectures can effectively learn industrial-scale feature spaces that are intractable for monolithic ansatzes.

</details>


### [42] [Amplification of bosonic interactions through squeezing in the presence of decoherence](https://arxiv.org/abs/2602.16655)
*Ankit Tiwari,Cecilia Cormick,Christian Arenz*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider the amplification of bosonic interactions through parametric control that implements squeezing along orthogonal quadratures. We show that bosonic interactions described by certain classes of quadratic and quartic Hamiltonians can be enhanced in this way while simultaneously overcoming noise and decoherence. In general, the amplification method enhances both desired and undesired interactions present in the system. Depending on the case, however, detrimental processes can be less amplified than the desired couplings. We leverage this observation to improve the fidelity for preparing Bell-type entangled states between two bosonic modes in the presence of noise and losses. We also investigate noise models for which the protocol either fails or partially achieves a loss-tolerant state preparation speedup. Our work facilitates faster preparation of complex quantum states and implementation of entangling gates in the presence of decoherence mechanisms.

</details>


### [43] [Intermodal quantum key distribution over an 18 km free-space channel with adaptive optics and room-temperature detectors](https://arxiv.org/abs/2602.16680)
*Edoardo Rossi,Ilektra Karakosta-Amarantidou,Matteo Padovan,Marco Nardi,Marco Avesani,Francesco Bruno Leonardo Santagiustina,Marco Taffarello,Antonio Vanzo,Stefano Bonora,Giuseppe Vallone,Paolo Villoresi,Francesco Vedovato*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Intermodal quantum key distribution at telecom wavelengths provides a hybrid interface between fiber connections and free-space links, both essential for the realization of scalable and interoperable quantum networks. Although demonstrated over short-range free-space links, long-distance implementations of intermodal quantum key distribution remain challenging, due to turbulence-induced wavefront aberrations which limit efficient single-mode fiber coupling at the optical receiver. Here, we demonstrate a real-time intermodal quantum key distribution field trial over an 18 km free-space link, connecting a remote terminal to an urban optical ground station equipped with a 40 cm-class telescope. An adaptive optics system, implementing direct wavefront sensing and high-order aberration correction, enables efficient single-mode fiber coupling and allows secure key generation of 200 bit/s using a compact state analyzer equipped with room-temperature detectors. We further validate through experimental data a turbulence-based model for predicting fiber coupling efficiency, providing practical design guidelines for future intermodal quantum networks.

</details>


### [44] [Numerical study of non-relativistic quantum systems and small oscillations induced in a helically twisted geometry](https://arxiv.org/abs/2602.16693)
*C. F. S. Pereira,R. L. L. Vitória,A. R. Soares,B. B. Silva,H. Belich,Edilberto O. Silva*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate bound states of a non-relativistic scalar particle in a three-dimensional helically twisted (torsional) geometry, considering both the free case and the presence of external radial interactions. The dynamics is described by the Schrödinger equation on a curved spatial background and, when included, by minimal coupling to a magnetic vector potential incorporating an Aharonov--Bohm flux. After separation of variables, the problem reduces to a one-dimensional radial eigenvalue equation governed by an effective potential that combines torsion-induced Coulomb-like and centrifugal-like structures with magnetic/flux-dependent terms and optional model interactions. Because closed-form analytic solutions are not reliable over the parameter ranges required for systematic scans, we compute spectra and eigenfunctions numerically by formulating the radial equation as a self-adjoint Sturm--Liouville problem and solving it with a finite-difference discretization on a truncated radial domain, with explicit convergence control. We analyze four representative scenarios: (i) no external potential, (ii) Cornell-type confinement, (iii) Kratzer-type interaction, and (iv) the small-oscillation regime around the minimum of a Morse potential. We present systematic trends of the low-lying levels as functions of the torsion parameter, magnetic field, and azimuthal sector, and we show that geometric couplings alone can produce effective confinement even in the absence of an external interaction.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [45] [Exploring New Frontiers in Vertical Federated Learning: the Role of Saddle Point Reformulation](https://arxiv.org/abs/2602.15996)
*Aleksandr Beznosikov,Georgiy Kormakov,Alexander Grigorievskiy,Mikhail Rudakov,Ruslan Nazykov,Alexander Rogozin,Anton Vakhrushev,Andrey Savchenko,Martin Takáč,Alexander Gasnikov*

Main category: math.OC

TL;DR: 本文研究了垂直联邦学习（VFL）中基于经典拉格朗日函数的鞍点重构方法，提出并分析了多种随机优化策略以适应实际应用需求。


<details>
  <summary>Details</summary>
Motivation: 为了解决VFL中因设备间特征分布不同但用户重叠所带来的协同训练难题，并克服传统最小化模型在扩展性上的局限。

Method: 采用拉格朗日函数对VFL问题进行鞍点重构，设计了结合压缩传输、异步部分参与和坐标选择的随机算法，并提供收敛性分析。

Result: 所提出的框架支持多种实用扩展，在理论和实验上均验证了其有效性与性能提升。

Conclusion: 鞍点重构为VFL提供了更灵活的优化视角，使原本难以实现的技术扩展成为可能，增强了实际部署能力。

Abstract: The objective of Vertical Federated Learning (VFL) is to collectively train a model using features available on different devices while sharing the same users. This paper focuses on the saddle point reformulation of the VFL problem via the classical Lagrangian function. We first demonstrate how this formulation can be solved using deterministic methods. More importantly, we explore various stochastic modifications to adapt to practical scenarios, such as employing compression techniques for efficient information transmission, enabling partial participation for asynchronous communication, and utilizing coordinate selection for faster local computation. We show that the saddle point reformulation plays a key role and opens up possibilities to use mentioned extension that seem to be impossible in the standard minimization formulation. Convergence estimates are provided for each algorithm, demonstrating their effectiveness in addressing the VFL problem. Additionally, alternative reformulations are investigated, and numerical experiments are conducted to validate performance and effectiveness of the proposed approach.

</details>


### [46] [Exponential Conic Optimization for Multi-Regime Service System Design under Congestion and Tail-Risk Control](https://arxiv.org/abs/2602.16021)
*Víctor Blanco,Miguel Martínez-Antón,Justo Puerto*

Main category: math.OC

TL;DR: 提出了一种混合整数指数锥优化框架，用于多模式单设施服务系统的设计，兼顾成本、拥塞、公平性和可靠性，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在多模式环境下，传统的服务系统设计难以同时满足响应时间约束、公平性和尾部风险控制的需求，因此需要新的优化框架来应对这些挑战。

Method: 提出了一个混合整数指数锥优化模型，集成了SLA机会约束、冲突图设计限制和基于CVaR的尾部风险控制，并开发了高效的分解算法求解该问题。

Result: 计算实验和大规模城市案例研究表明，新框架相比现有系统显著提升了效率、拥塞控制、公平性和鲁棒性之间的权衡表现。

Conclusion: 该框架为具有拥塞感知和尾部风险控制的服务系统设计提供了实用工具，适用于实际复杂环境中的设施规划。

Abstract: We study the design of single-facility service systems operating under multiple recurring regimes with service-level constraints on response times. Regime-dependent arrival and service rates induce hyperexponential response-time distributions, and the design problem selects regime-specific capacities to balance cost, congestion, fairness, and reliability. We propose a mixed-integer exponential conic optimization framework integrating SLA chance constraints, conflict-graph design restrictions, and CVaR-based tail-risk control. Although NP-hard, the problem admits an efficient decomposition scheme and tractable special cases. Computational experiments and a large-scale urban case study show substantial improvements over the current system, quantifying explicit trade-offs between efficiency, congestion control, fairness, and robustness. The framework provides a practical tool for congestion-aware and tail-control service system design.

</details>


### [47] [Null controllability of one-dimensional quasilinear parabolic equations via multiplicative controls](https://arxiv.org/abs/2602.16150)
*Jilei Huang,Peidong Lei,Yansheng Ma,Jingxue Yin*

Main category: math.OC

TL;DR: 本文研究了一类具有空间局部支撑的乘性控制拟线性抛物方程的零可控性问题。通过建立无控制时系统的解的衰减性质，结合最大模估计和加性控制下的局部零可控性，证明了乘性控制下的零可控性，并进一步得到大时间下加性控制的全局零可控性以及时间最优控制的存在性。


<details>
  <summary>Details</summary>
Motivation: 研究拟线性抛物方程在乘性控制下的零可控性，拓展对非线性系统控制理论的理解，特别是在缺乏小初值假设下解的行为分析。

Method: 首先建立齐次拟线性抛物方程解的L∞范数和H¹范数的衰减估计；利用最大模估计与加性控制下的局部零可控性结果，推导出乘性控制下的零可控性；进一步分析长时间行为以研究时间最优控制的存在性。

Result: 获得了无需初值小性条件的L∞范数衰减估计；在L∞范数保持较小时得到了H¹范数的衰减；证明了乘性控制下系统的零可控性；作为副产品，得到了加性控制下的全局零可控性；并证明了时间最优控制的存在性。

Conclusion: 拟线性抛物方程可通过局部乘性控制实现零可控性，且在大时间下存在时间最优控制，拓展了非线性系统的可控性理论。

Abstract: This paper is concerned with the null controllability problem for a class of quasilinear parabolic equations under multiplicative control, locally supported in space. For the purpose of proving the existence of a multiplicative control forcing the solution rest at a time $T>0$, we need to establish the decay property of solutions for the system without control first. We have obtained decay estimates for the $L^\infty$-norm and the $H^1$-norm of solutions to the homogenous quasilinear parabolic equations. Notably, the decay of the $L^\infty$-norm requires no smallness condition on the initial data, whereas the decay of the $H^1$-norm requires that the $L^\infty$-norm remains small. Based on the decay estimates and maximum modulus estimate of solutions to quasilinear parabolic equations, together with the local null controllability of quasilinear parabolic equations under additive controls, we prove the null controllability of the quasilinear parabolic equations via multiplicative controls. As a byproduct, we also obtain the global null controllability for large time to the quasilinear parabolic equations via additive controls. Given that the controllability under multiplicative control is achieved over a long time horizon, we finally investigate the existence of time optimal control.

</details>


### [48] [Metaheuristic algorithms for the induced P-median problem with upgrades](https://arxiv.org/abs/2602.16170)
*Sergio Salazar,Abraham Duarte,Mauricio G. C. Resende,J. Manuel Colmenar*

Main category: math.OC

TL;DR: 本文提出了一种基于GRASP的元启发式算法，用于求解带升级的诱导p-中位问题（IpMU），在更大规模实例上实现了比现有数学规划方法更快的求解速度和更优的结果。


<details>
  <summary>Details</summary>
Motivation: 由于传统p-中位问题无法充分建模现实中的多维成本与时间因素，且现有数学规划方法计算代价高，因此需要更高效的算法来解决更具现实意义的IpMU问题。

Method: 采用两阶段的GRASP元启发式算法，分别独立求解中位点选择问题和边成本优化（升级）问题，并在大规模标准测试实例上进行验证。

Result: 相比现有基于数学规划的方法，平均求解时间提升了两个数量级，在超过99%的测试实例上获得了已知最优解。

Conclusion: 所提出的GRASP两阶段方法在求解IpMU问题上具有显著优势，尤其在计算效率和解的质量方面优于现有方法，适用于更大规模的实际问题求解。

Abstract: Facility location problems (FLPs) are a family of optimisation problems with significant social impact. This class of problems has been the subject of study since the 1960s, with classical approaches including the Weber problem and the p-Median problem. Currently, more complex variations of these problems are being investigated. In particular, the Induced p-Median Problem with Upgrades (IpMU) represents a variation of the classical p-Median problem, where the concepts of transport cost and time are separated as distinct metrics in the input graph of the problem. Furthermore, the problem includes a budget which allows one to relax the graph costs, reducing the cost of the edges, thus improving the associated routes between the designated medians and the customers. In this study, a metaheuristic algorithm, based on the Greedy Randomized Adaptive Search Procedure (GRASP), is proposed. A two-phase resolution scheme is defined, studying the median problem and the upgrading problem independently. In this approach, a larger set of state-of-the-art instances was analysed to ensure a fair comparison with previous proposals. In addition, the characteristics of the instances were studied to assess their complexity. The results obtained are promising when compared to the state-of-the-art, which is based entirely on mathematical programming models. The execution time was improved on average by two orders of magnitude for the harder instances, and the best known result was obtained in more than 99% of the tested instances.

</details>


### [49] [Optimal driving strategies for a fleet of trains](https://arxiv.org/abs/2602.16205)
*Phil Howlett,Maria Kapsis,Peter Pudney*

Main category: math.OC

TL;DR: 本文研究了在电力传输和分配管理中，铁路运营商如何通过优化列车驾驶策略，在不改变行程时间的前提下减少高峰时段的能耗，从而降低运营成本。


<details>
  <summary>Details</summary>
Motivation: 由于系统运营商在高峰需求期间提供经济激励以鼓励大型消费者减少能源使用，铁路运营商需要探索在不影响行程时间的情况下调整能耗模式的可能性。

Method: 采用经典约束优化方法，寻找在特定时间段内受总能耗限制的列车车队最优驾驶策略。

Result: 提出了可在不改变各个行程出发和到达时间的情况下，有效减少高峰时段能耗的驾驶策略。

Conclusion: 该策略有助于大型铁路组织在最小干扰现有调度的情况下降低整体运营成本。

Abstract: In order to manage electricity transmission and distribution it is now common practice for system operators to offer financial incentives that encourage large consumers to reduce energy usage during designated peak demand periods. For train operators on large rail networks it may be profitable -- with selected individual journeys -- to reduce energy usage during peak times and increase energy usage at other times rather than simply minimizing overall energy consumption. We will use classical methods of constrained optimization to find optimal driving strategies for a fleet of trains subject to limits on total energy consumption during specified intermediate time intervals but with no change to individual journey times. The proposed strategies can be used by a large rail organisation to reduce overall operating costs with only minimal disruption to existing schedules and with no changes to important departure and arrival times.

</details>


### [50] [Partially observed controlled Markov chains and optimal control of the Wonham filter](https://arxiv.org/abs/2602.16392)
*Fulvia Confortola,Marco Fuhrman*

Main category: math.OC

TL;DR: 研究一类连续时间马尔可夫链的最优控制问题，其中控制影响转移速率且过程不可观测，通过Girsanov测度变换转化为分离型控制问题，并利用Wonham滤波方程分析其值函数与最优性条件。


<details>
  <summary>Details</summary>
Motivation: 解决在部分可观测情况下对受控马尔可夫链进行最优控制的问题，克服因状态不可直接观测带来的挑战。

Method: 采用Girsanov型测度变换将原问题转化为基于条件分布的分离型最优控制问题，并结合Wonham滤波方程和动态规划方法进行分析。

Result: 证明了原问题与分离问题的等价性，给出了值函数作为动态规划方程唯一粘性解的刻画，并建立了验证定理和随机最大值原理形式的必要最优条件。

Conclusion: 该方法有效处理了不可观测控制过程下的最优控制问题，为有限状态马尔可夫链在部分信息下的优化提供了理论基础和分析工具。

Abstract: We consider a class of optimal control problems, with finite or infinite horizon, for a continuous-time Markov chain with finite state space. In this case, the control process affects the transition rates. We suppose that the controlled process can not be observed, and at any time the control actions are chosen based on the observation of a related stochastic process perturbed by an exogenous Brownian motion. We describe a construction of the controlled Markov chain, having stochastic transition rates adapted to the observation filtration. By a change of probability measure of Girsanov type, we introduce the so-called separated optimal control problem, where the state is the conditional (unnormalized) distribution of the controlled Markov chain and the observation process becomes a driving Brownian motion, and we prove the equivalence with the original control problem. The controlled equations for the separated problem are an instance of the Wonham filtering equations. Next we present an analysis of the separated problem: we characterize the value function as the unique viscosity solution to the dynamic programming equations (both in the parabolic and the elliptic case) we prove verifications theorems and a version of the stochastic maximum principle in the form of a necessary conditions for optimality.

</details>


### [51] [Primal-dual dynamical systems with closed-loop control for convex optimization in continuous and discrete time](https://arxiv.org/abs/2602.16402)
*Huan Zhang,Xiangkai Sun,Shengjie Li,Kok Lay Teo*

Main category: math.OC

TL;DR: 本文提出了一种闭环设计系数的原始-对偶动力系统，用于求解带线性等式约束的凸优化问题，并通过反馈控制实现快速收敛。


<details>
  <summary>Details</summary>
Motivation: 为了提高求解带线性等式约束凸优化问题的效率和收敛速度，设计一种具有自适应机制的动力系统。

Method: 引入一种“二阶原始+一阶对偶”的连续时间动力系统，利用拉格朗日函数梯度的反馈控制来调节时间缩放和Hessian驱动阻尼；随后通过对该系统进行时间离散化，开发出具有梯度定义自适应步长的加速原始-对偶算法。

Result: 所提出的系统和算法在原始-对偶间隙、可行性违反程度和目标残差方面均实现了快速收敛率，并通过数值实验验证了其有效性和优越性能。

Conclusion: 该方法通过闭环反馈机制有效提升了原始-对偶算法的收敛速度与实际表现，适用于求解带线性等式约束的凸优化问题。

Abstract: This paper develops a primal-dual dynamical system where the coefficients are designed in closed-loop way for solving a convex optimization problem with linear equality constraints. We first introduce a ``second-order primal" + ``first-order dual'' continuous-time dynamical system, in which both the time scaling and Hessian-driven damping are governed by a feedback control of the gradient for the Lagrangian function. This system achieves the fast convergence rates for the primal-dual gap, the feasibility violation, and the objective residual along its trajectory. Subsequently, by time discretization of this system, we develop an accelerated primal-dual algorithm with a gradient-defined adaptive step size. We also obtain convergence rates for the primal-dual gap, the feasibility violation, and the objective residual. Furthermore, we provide numerical results to demonstrate the practical efficacy and superior performance of the proposed algorithm.

</details>


### [52] [The Complexity Landscape of Two-Stage Robust Selection Problems with Budgeted Uncertainty](https://arxiv.org/abs/2602.16465)
*Marc Goerigk,Dorothee Henke,Lasse Wulf*

Main category: math.OC

TL;DR: 本文研究了在预算不确定性下的两阶段选择问题的复杂性，揭示了连续预算不确定性下两阶段选择问题是NP难的，而相应的两阶段代表选择问题可在多项式时间内求解。


<details>
  <summary>Details</summary>
Motivation: 预算不确定性是鲁棒优化中常见的一种不确定性集合，但其在两阶段设置下的复杂性，尤其是在基础名义优化问题较简单（如选择问题）时，仍缺乏系统研究。本文旨在回答长期未解决的复杂性问题。

Method: 通过分析三种类型的选择问题和三种类型的预算不确定性集合，系统地研究了其计算复杂性，特别是针对离散和连续预算不确定性进行了区分处理。

Result: 证明了在连续预算不确定性下的两阶段选择问题是NP难的，而对应的两阶段代表选择问题可在多项式时间内求解；此外，该结果还意味着两阶段分配问题在连续预算不确定性下也是NP难的。

Conclusion: 本文全面回答了多种选择问题在不同类型预算不确定性下的复杂性问题，揭示了连续与离散预算不确定性之间的本质差异，并为相关问题的算法设计提供了理论依据。

Abstract: A standard type of uncertainty set in robust optimization is budgeted uncertainty, where an interval of possible values for each parameter is given and the total deviation from their lower bounds is bounded. In the two-stage setting, discrete and continuous budgeted uncertainty have to be distinguished. The complexity of such problems is largely unexplored, in particular if the underlying nominal optimization problem is simple, such as for selection problems. In this paper, we give a comprehensive answer to long-standing open complexity questions for three types of selection problems and three types of budgeted uncertainty sets. In particular, we demonstrate that the two-stage selection problem with continuous budgeted uncertainty is NP-hard, while the corresponding two-stage representative selection problem is solvable in polynomial time. Our hardness result implies that also the two-stage assignment problem with continuous budgeted uncertainty is NP-hard.

</details>


### [53] [PL conditions do not guarantee convergence of gradient descent-ascent dynamics](https://arxiv.org/abs/2602.16517)
*Jean-Christophe Mourrat*

Main category: math.OC

TL;DR: 本文提供了一个满足双侧Polyak-Lojasiewicz条件的函数示例，但梯度下降-上升流线未能收敛到鞍点，而是围绕其旋转。


<details>
  <summary>Details</summary>
Motivation: 研究在满足特定优化条件下梯度方法的收敛性问题。

Method: 构造一个满足双侧Polyak-Lojasiewicz条件的函数，并分析其梯度下降-上升流线的行为。

Result: 发现即使满足双侧Polyak-Lojasiewicz条件，梯度下降-上升流线仍可能不收敛到鞍点，而是围绕其循环。

Conclusion: 双侧Polyak-Lojasiewicz条件不足以保证梯度下降-上升方法的收敛性。

Abstract: We give an example of a function satisfying a two-sided Polyak-Lojasiewicz condition but for which a gradient descent-ascent flow line fails to converge to the saddle point, circling around it instead.

</details>


### [54] [Learning Distributed Equilibria in Linear-Quadratic Stochastic Differential Games: An $α$-Potential Approach](https://arxiv.org/abs/2602.16555)
*Philipp Plank,Yufei Zhang*

Main category: math.OC

TL;DR: 本文研究了在N人线性二次随机微分博弈中独立策略梯度学习的收敛性，发现当交互对称时算法全局线性收敛到均衡，不对称时收敛到近似均衡，且数值实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 分析多玩家在仅依赖自身状态信息的情况下，独立采用策略梯度方法是否能收敛到博弈均衡，特别是在存在对称与非对称交互作用时的表现。

Method: 通过揭示LQ博弈具有α-势结构，构建分布式策略更新机制，并利用势函数优化来分析独立策略梯度算法的收敛性。

Result: 证明了在对称交互下独立PG方法可全局线性收敛到一个仿射分布式均衡，复杂度随群体规模线性增长；在非对称情况下，投影PG算法线性收敛到一个与不对称程度成比例的近似均衡。数值实验验证了理论分析。

Conclusion: 独立策略梯度方法在LQ随机微分博弈中具有良好的收敛性质，尤其在对称交互时能高效收敛到精确均衡，为多智能体分布式学习提供了理论支持。

Abstract: We analyze independent policy-gradient (PG) learning in $N$-player linear-quadratic (LQ) stochastic differential games. Each player employs a distributed policy that depends only on its own state and updates the policy independently using the gradient of its own objective. We establish global linear convergence of these methods to an equilibrium by showing that the LQ game admits an $α$-potential structure, with $α$ determined by the degree of pairwise interaction asymmetry. For pairwise-symmetric interactions, we construct an affine distributed equilibrium by minimizing the potential function and show that independent PG methods converge globally to this equilibrium, with complexity scaling linearly in the population size and logarithmically in the desired accuracy. For asymmetric interactions, we prove that independent projected PG algorithms converge linearly to an approximate equilibrium, with suboptimality proportional to the degree of asymmetry. Numerical experiments confirm the theoretical results across both symmetric and asymmetric interaction networks.

</details>


### [55] [Nonparametric Kernel Regression for Coordinated Energy Storage Peak Shaving with Stacked Services](https://arxiv.org/abs/2602.16586)
*Emily Logan,Ning Qi,Bolun Xu*

Main category: math.OC

TL;DR: 提出了一种两阶段框架，用于协调商业建筑中电表后储能的削峰和能源套利，无需依赖预测即可实现成本节约和有效峰值管理。


<details>
  <summary>Details</summary>
Motivation: 为了降低商业建筑的电力成本并延长电池寿命，需要开发有效的控制策略来协调削峰和叠加服务。

Method: 第一阶段使用非参数核回归模型从历史数据构建满足削峰需求的充电状态轨迹边界；第二阶段利用迁移学习方法将剩余容量用于能源套利。

Result: 基于纽约市商业建筑负荷数据的案例研究表明，该方法性能比最先进的基于预测的方法提高了1.3倍，实现了成本节约和有效的峰值管理。

Conclusion: 所提出的端到端两阶段框架在不依赖预测的情况下，能有效协调削峰和能源套利，提升储能系统经济效益和运行效率。

Abstract: Developing effective control strategies for behind-the-meter energy storage to coordinate peak shaving and stacked services is essential for reducing electricity costs and extending battery lifetime in commercial buildings. This work proposes an end-to-end, two-stage framework for coordinating peak shaving and energy arbitrage with a theoretical decomposition guarantee. In the first stage, a non-parametric kernel regression model constructs state-of-charge trajectory bounds from historical data that satisfy peak-shaving requirements. The second stage utilizes the remaining capacity for energy arbitrage via a transfer learning method. Case studies using New York City commercial building demand data show that our method achieves a 1.3 times improvement in performance over the state-of-the-art forecast-based method, achieving cost savings and effective peak management without relying on predictions.

</details>


### [56] [Optimal bounds for numerical approximations of finite horizon problems based on dynamic programming approach](https://arxiv.org/abs/2602.16574)
*Javier de Frutos,Julia Novo*

Main category: math.OC

TL;DR: 本文研究了有限时域问题的全离散动态规划逼近的最优误差界，通过使用分段常数控制，在较弱的正则性假设下实现了时间和空间上的一阶收敛率。


<details>
  <summary>Details</summary>
Motivation: 改进无限时域误差分析方法在有限时域问题中的应用，避免对控制函数提出过强的正则性要求，并提升时间收敛速率。

Method: 将文献[nos]中的误差分析方法适配到有限时域情形，采用分段常数控制进行全离散逼近，并推导先验误差估计。

Result: 证明了大小为O(h+k)的先验误差界，其中h为时间步长，k为空间网格尺寸，并在标准正则性假设下实现了一阶收敛。

Conclusion: 在有限时域问题中，使用分段常数控制可避免无限时域方法中时间收敛率下降的问题，且无需强正则性假设即可获得最优收敛速度。

Abstract: In this paper we provide optimal bounds for fully discrete approximations to finite horizon problems via dynamic programming. We adapt the error analysis in \cite{nos} for the infinite horizon case to the
  finite horizon case. We prove an a priori bound of size $O(h+k)$ for the method, $h$ being the time discretization step and $k$ the spatial mesh size. Arguing with piecewise constants controls we are able to obtain first order of convergence in time and space under standard regularity assumptions, avoiding the more restrictive regularity assumptions on the controls required in \cite{nos}.
  We show that the loss in the rate of convergence in time of the
  infinite case (obtained arguing with piece-wise controls)
  can be avoided in the finite horizon case

</details>


### [57] [Hybrid Optimization Techniques for Multi-State Optimal Design Problems](https://arxiv.org/abs/2602.16592)
*Marko Erceg,Petar Kunštek,Marko Vrdoljak*

Main category: math.OC

TL;DR: 本文研究了由多状态稳态扩散方程控制的最优设计问题，提出了一种结合均匀化和形状优化的数值方法，通过水平集方法和最优性准则算法同时优化区域形状和材料分布。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在给定比例下同时优化区域形状和各向同性材料分布的最优设计问题。

Method: 采用结合内部均匀化松弛和对可接受区域施加限制的混合方法，并利用水平集方法演化边界，通过最优性准则算法更新内部材料分布。

Result: 建立了广义解的存在性，并在一个代表性例子中验证了该方法的有效性。

Conclusion: 所提出的数值方法能够有效处理多状态扩散方程控制下的形状与材料联合优化问题。

Abstract: This paper addresses optimal design problems governed by multi-state stationary diffusion equations, aiming at the simultaneous optimization of the domain shape and the distribution of two isotropic materials in prescribed proportions. Existence of generalized solutions is established via a hybrid approach combining homogenization-based relaxation in the interior with suitable restrictions on admissible domains.
  Based on this framework, we propose a numerical method that integrates homogenization and shape optimization. The domain boundary is evolved using a level set method driven by the shape derivative, while the interior material distribution is updated via an optimality criteria algorithm. The approach is demonstrated on a representative example.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [58] [Experimental and Numerical Study of the Transient Response of a Cantilever Beam with a Piezoelectric Disc Sensor](https://arxiv.org/abs/2602.16374)
*Radek Kolman,Robert Cimrman,Ladislav Musil,Moritz Frey,Jaromir Kylar,Sebastian Brandstaeter,Vojtech Kotek,Alexander Popp,Jan Kober*

Main category: cs.CE

TL;DR: 本研究结合实验与建模方法，分析了带压电传感器的悬臂梁结构的动力响应，提出了一种包含浮动电势边界条件的弹性动力学模型，并通过有限元法进行离散化，模型结果与实验数据吻合良好，同时基于实验数据识别了瑞利阻尼参数。


<details>
  <summary>Details</summary>
Motivation: 为了实现对复杂结构（如飞机和电站关键部件）健康状态的在线实时监测，需要高精度的动态响应传感技术。压电材料因其能将机械变形转化为电信号而被广泛用于动态监测，但其与结构耦合后的动力学行为需精确建模以提高监测可靠性。

Method: 采用实验与数值建模相结合的方法：通过激光测振仪记录悬臂梁表面某点在瞬态振动下的法向速度时间历程，同时测量压电传感器的输出电压；建立耦合压电传感器的悬臂梁弹性动力学模型，并采用有限元法进行离散化，模型中引入额外项以实现保持电极电荷恒定的浮动电势边界条件，且模型形式适用于敏感性分析或参数识别。

Result: 数值模拟结果与实验数据具有良好的一致性，验证了模型的有效性；基于实验测量数据成功识别出瑞利阻尼参数。

Conclusion: 所提出的弹性动力学模型能够准确描述带压电传感器的悬臂梁动力响应，为结构健康监测中的传感器集成与参数识别提供了可靠的建模基础。

Abstract: Online and real-time sensing and monitoring of the health state of complex structures, such as aircraft and critical components of power stations, are essential aspects of research in dynamics. Several types of sensors are used to capture dynamic responses and monitor changes during the operation of critical parts of complex systems. Piezoelectric (PZ) materials belong to a class of electroactive materials that convert mechanical deformation into an electrical response. For example, PZ ceramics or PVDF foils are employed for online sensing of the time history of mechanical deformation. This paper focuses on the dynamical response of a cantilever beam structure equipped with a glued PZ sensor and combines experimental and modelling approaches to achieve accurate and reliable results. The time history of the normal velocity at a point on the beam surface was recorded with a laser vibrometer during transient vibrations of the beam, triggered by the sudden removal of a mass load at the beam's free end. Simultaneously, the output voltage of the PZ sensor was measured with an electronic device. An elastodynamic model of a cantilever beam coupled with a piezoelectric sensor is introduced, along with its discretization using the finite element method. The mathematical model includes additional terms that enforce a floating-potential boundary condition to maintain a constant charge on one of the sensor's electrodes and is presented in an extended form suitable for sensitivity analysis or parameter identification. The model implementation is validated using a numerical example corresponding to the experimental setup. The computed results show good agreement with the experimental data. Furthermore, values of the Rayleigh damping parameters were identified based on the experimental measurements.

</details>


### [59] [Retrieval Augmented Generation of Literature-derived Polymer Knowledge: The Example of a Biodegradable Polymer Expert System](https://arxiv.org/abs/2602.16650)
*Sonakshi Gupta,Akhlak Mahmood,Wei Xiong,Rampi Ramprasad*

Main category: cs.CE

TL;DR: 本文提出并比较了两种用于聚合物文献分析的检索增强生成（RAG）系统——基于向量的VectorRAG和基于图的GraphRAG，利用1000多篇PHA论文构建知识表示，结果表明GraphRAG在精确性和可解释性上更优，而VectorRAG具有更高的召回率，二者互补，为材料科学领域提供了可信赖、可溯源的文献分析框架。


<details>
  <summary>Details</summary>
Motivation: 聚合物文献中蕴含大量实验知识，但这些知识多以非结构化文本和不一致术语形式存在，现有工具难以系统化检索和跨研究推理，限制了科学研究的整体进展。

Method: 构建了两种检索管道：基于密集语义向量的VectorRAG和基于结构化知识图谱的GraphRAG；使用超过1000篇聚羟基烷酸酯（PHA）论文生成上下文保持的段落嵌入，并构建标准化的知识图谱以支持实体消歧和多跳推理；通过标准检索指标、与GPT和Gemini等通用系统的对比以及领域化学家的定性验证进行评估。

Result: GraphRAG在检索精度和可解释性方面表现更优，能够支持多跳推理和实体识别；VectorRAG则具备更广的召回能力；专家验证表明，特别是GraphRAG能生成有据可依、引用可靠且领域相关性强的回答。

Conclusion: 该工作建立了基于定制化语料库和检索设计的材料科学助手实用框架，能够在减少对专有模型依赖的同时，实现可信赖的大规模文献分析，推动科研人员高效导航文献、跨研究比较发现并挖掘手动难以提取的模式。

Abstract: Polymer literature contains a large and growing body of experimental knowledge, yet much of it is buried in unstructured text and inconsistent terminology, making systematic retrieval and reasoning difficult. Existing tools typically extract narrow, study-specific facts in isolation, failing to preserve the cross-study context required to answer broader scientific questions. Retrieval-augmented generation (RAG) offers a promising way to overcome this limitation by combining large language models (LLMs) with external retrieval, but its effectiveness depends strongly on how domain knowledge is represented. In this work, we develop two retrieval pipelines: a dense semantic vector-based approach (VectorRAG) and a graph-based approach (GraphRAG). Using over 1,000 polyhydroxyalkanoate (PHA) papers, we construct context-preserving paragraph embeddings and a canonicalized structured knowledge graph supporting entity disambiguation and multi-hop reasoning. We evaluate these pipelines through standard retrieval metrics, comparisons with general state-of-the-art systems such as GPT and Gemini, and qualitative validation by a domain chemist. The results show that GraphRAG achieves higher precision and interpretability, while VectorRAG provides broader recall, highlighting complementary trade-offs. Expert validation further confirms that the tailored pipelines, particularly GraphRAG, produce well-grounded, citation-reliable responses with strong domain relevance. By grounding every statement in evidence, these systems enable researchers to navigate the literature, compare findings across studies, and uncover patterns that are difficult to extract manually. More broadly, this work establishes a practical framework for building materials science assistants using curated corpora and retrieval design, reducing reliance on proprietary models while enabling trustworthy literature analysis at scale.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [60] [Close-enough general routing problem for multiple unmanned aerial vehicles in monitoring missions](https://arxiv.org/abs/2602.15841)
*Huan Liu,Michel Gendreau,Binjie Xu,Guohua Wu,Yi Gu*

Main category: eess.SY

TL;DR: 本文提出了一种用于多无人机监控任务的近似多无人机通用路径规划问题（CEMUAVGRP），通过两阶段迭代方法结合变邻域下降启发式和二阶锥规划，在自适应迭代局部搜索框架下优化路径，有效降低了总飞行距离。


<details>
  <summary>Details</summary>
Motivation: 为了提高多无人机在包含节点及其邻域范围和边的监控任务中的路径规划效率，减少总飞行距离，解决传统路径规划未充分考虑节点覆盖范围的问题。

Method: 提出一种两阶段迭代方法：第一阶段使用变邻域下降（VND）启发式算法进行通用路径规划；第二阶段利用二阶锥规划（SOCP）优化每个节点的代表点；两阶段在自适应迭代局部搜索（AILS）框架下交替执行直至满足终止条件。

Result: 实验结果表明所提出的AILS-VND-SOCP算法在求解CEMUAVGRP上具有高效性，且引入节点的磁盘邻域显著优于传统点覆盖模型。

Conclusion: 该方法能有效处理考虑覆盖邻域的多无人机路径规划问题，通过两阶段协同优化显著提升路径质量，适用于实际监控应用。

Abstract: In this paper, we introduce a close-enough multi-UAV general routing problem (CEMUAVGRP) where a fleet of homogeneous UAVs conduct monitoring tasks containing nodes, each of which has its disk neighborhood, and edges, aiming to minimize the total distance. A two-phase iterative method is proposed, partitioning the CEMUAVGRP into a general routing phase where a satisfactory route including required nodes and edges for each UAV is obtained without considering the disk neighborhoods of required nodes, and a close-enough routing phase where representative points are optimized for each required node in the determined route. To be specific, a variable neighborhood descent (VND) heuristic is proposed for the general routing phase, while a second-order cone programming (SOCP) procedure is applied in the close-enough routing phase. These two phases are performed in an iterative fashion under the framework of an adaptive iterated local search (AILS) algorithm until the predefined termination criteria are satisfied. Extensive experiments and comparative studies are conducted, demonstrating the efficiency of the proposed AILS-VND-SOCP algorithm and the superiority of disk neighborhoods.

</details>


### [61] [MARLEM: A Multi-Agent Reinforcement Learning Simulation Framework for Implicit Cooperation in Decentralized Local Energy Markets](https://arxiv.org/abs/2602.16063)
*Nelson Salazar-Pena,Alejandra Tabares,Andres Gonzalez-Mancera*

Main category: eess.SY

TL;DR: 本文提出了一种新颖的开源多智能体强化学习（MARL）仿真框架，用于研究去中心化局部可观测马尔可夫决策过程建模的本地能源市场（LEM）中的隐式协作。


<details>
  <summary>Details</summary>
Motivation: 为了促进未来智能、去中心化能源系统中无需显式通信的隐式协作，并提升市场效率与电网稳定性。

Method: 将LEM建模为去中心化部分可观测马尔可夫决策过程，构建模块化市场平台，增强智能体观测与奖励以包含系统级关键性能指标，从而实现自主学习集体有益策略。

Result: 通过案例研究表明该框架能够分析不同市场配置对系统性能的影响，支持新兴协调行为，提高市场效率和电网稳定性。

Conclusion: 所提出的框架是一个灵活、可扩展且可复现的工具，有助于研究人员设计、测试和验证去中心化能源系统的协作策略。

Abstract: This paper introduces a novel, open-source MARL simulation framework for studying implicit cooperation in LEMs, modeled as a decentralized partially observable Markov decision process and implemented as a Gymnasium environment for MARL. Our framework features a modular market platform with plug-and-play clearing mechanisms, physically constrained agent models (including battery storage), a realistic grid network, and a comprehensive analytics suite to evaluate emergent coordination. The main contribution is a novel method to foster implicit cooperation, where agents' observations and rewards are enhanced with system-level key performance indicators to enable them to independently learn strategies that benefit the entire system and aim for collectively beneficial outcomes without explicit communication. Through representative case studies (available in a dedicated GitHub repository in https://github.com/salazarna/marlem, we show the framework's ability to analyze how different market configurations (such as varying storage deployment) impact system performance. This illustrates its potential to facilitate emergent coordination, improve market efficiency, and strengthen grid stability. The proposed simulation framework is a flexible, extensible, and reproducible tool for researchers and practitioners to design, test, and validate strategies for future intelligent, decentralized energy systems.

</details>


### [62] [Autonomous and non-autonomous fixed-time leader-follower consensus for second-order multi-agent systems](https://arxiv.org/abs/2602.16260)
*Miguel A. Trujillo,Rodrigo Aldana-López,David Gomez Gutierrez,Michael Defoort,Javier Ruiz Leon,Hector M. Becerra*

Main category: eess.SY

TL;DR: 本文研究了具有双积分器动力学的领导-跟随多智能体系统的固定时间一致性跟踪问题，提出两种分布式控制策略，分别通过自主和非自主协议实现对领导者状态的估计与跟踪，并保证收敛时间上界可预先设定且增益有界，数值仿真验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中仅部分跟随者可获取领导者状态时的固定时间一致性跟踪问题，实现快速且收敛时间可控的协同控制。

Method: 采用两步控制方案：首先设计分布式固定时间观测器估计领导者状态；然后基于估计值设计固定时间控制器。提出自主协议（预设收敛时间上界）和基于时变增益的非自主协议（降低保守性）。

Result: 所提两种策略均能实现固定时间一致性跟踪，非自主协议在保证增益有界的前提下提供了更小的收敛时间上界估计，降低了保守性。

Conclusion: 本文提出的两种分布式控制策略有效解决了双积分器多智能体系统的固定时间一致性跟踪问题，尤其非自主协议在性能和实用性之间取得了更好平衡。

Abstract: This paper addresses the problem of consensus tracking with fixed-time convergence, for leader-follower multi-agent systems with double-integrator dynamics, where only a subset of followers has access to the state of the leader. The control scheme is divided into two steps. The first one is dedicated to the estimation of the leader state by each follower in a distributed way and in a fixed-time. Then, based on the estimate of the leader state, each follower computes its control law to track the leader in a fixed-time. In this paper, two control strategies are investigated and compared to solve the two mentioned steps. The first one is an autonomous protocol which ensures a fixed-time convergence for the observer and for the controller parts where the Upper Bound of the Settling-Time (UBST) is set a priory by the user. Then, the previous strategy is redesigned using time-varying gains to obtain a non-autonomous protocol. This enables to obtain less conservative estimates of the UBST while guaranteeing that the time-varying gains remain bounded. Some numerical examples show the effectiveness of the proposed consensus protocols.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [63] [Decomposing Large-Scale Ising Problems on FPGAs: A Hybrid Hardware Approach](https://arxiv.org/abs/2602.15985)
*Ruihong Yin,Yue Zheng,Chaohui Li,Ahmet Efe,Abhimanyu Kumar,Ziqing Zeng,Ulya R. Karpuzcu,Sachin S. Sapatnekar,Chris H. Kim*

Main category: cs.ET

TL;DR: 本文提出了一种异构系统，通过将分解任务卸载到FPGA上，与28nm伊辛求解器紧密集成，显著减少了数字预处理与模拟求解之间的速度差距，相比CPU上的软件基线实现了近2倍的速度提升和两个数量级以上的能效改进。


<details>
  <summary>Details</summary>
Motivation: 现有的基于振荡器的伊辛机在解决组合优化问题时收敛速度快，但受限于物理实现难以扩展到大规模问题，且在CPU上进行问题分解会引入显著延迟，限制了高速求解器的性能发挥。

Method: 设计了一种异构计算系统，将问题分解逻辑迁移至FPGA，利用其并行处理能力和可重构特性，实现与定制28nm伊辛求解器的紧密集成，减少主机与设备间的通信延迟。

Result: 该系统在评估中表现出接近2倍的速度提升，并在能效上比现代CPU上的优化软件基线提高了两个数量级以上。

Conclusion: 通过FPGA加速问题分解的异构架构有效弥合了数字预处理与模拟求解之间的性能鸿沟，为大规模组合优化问题提供了高效、低功耗的解决方案。

Abstract: Emerging analog computing substrates, such as oscillator-based Ising machines, offer rapid convergence times for combinatorial optimization but often suffer from limited scalability due to physical implementation constraints. To tackle real-world problems involving thousands of variables, problem decomposition is required; however, performing this step on standard CPUs introduces significant latency, preventing the high-speed solver from operating at full capacity. This work presents a heterogeneous system that offloads the decomposition workload to an FPGA, tightly integrated with a custom 28nm Ising solver. By migrating the decomposition logic to reconfigurable hardware and utilizing parallel processing elements, the system minimizes the communication latency typically associated with host-device interactions. Our evaluation demonstrates that this co-design approach effectively bridges the speed gap between digital preprocessing and analog solving, achieving nearly 2$\times$ speedup and an energy efficiency improvement of over two orders of magnitude compared to optimized software baselines running on modern CPUs.

</details>


### [64] [Bibby AI -- AI Latex Editor writing assistant for researchers vs Overleaf Alternative vs OpenAI Prism. (Bibby AI Latex Editor)](https://arxiv.org/abs/2602.16432)
*Nilesh jain,Rohit Yadav,Andrej Karpathy*

Main category: cs.ET

TL;DR: Bibby AI是一个原生的、以AI为核心的LaTeX编辑器，集成了AI写作助手、智能引文搜索、公式与表格生成、论文评审等功能，显著提升了学术写作效率。


<details>
  <summary>Details</summary>
Motivation: 现有的LaTeX编辑器缺乏原生AI支持，导致研究人员需在不同工具间切换，破坏写作连贯性。

Method: 开发了Bibby AI，集成多种AI功能于单一界面，并构建LaTeXBench-500基准测试其错误检测与修复能力。

Result: Bibby在错误检测准确率达91.4%，一键修复准确率达83.7%，优于Overleaf和OpenAI Prism。

Conclusion: 一个隐私保护、面向研究的AI编辑器能有效加速学术写作全流程，Bibby AI是比Overleaf和OpenAI Prism更优的选择。

Abstract: Large language models are increasingly integrated into academic writing workflows; however, the most widely used \LaTeX\ editors remain AI-peripheral -- offering compilation and collaboration, but no native intelligence. This separation forces researchers to leave their editing environment for AI assistance, fragmenting document context and interrupting writing flow. We present Bibby AI (trybibby.com), a native, AI-first \LaTeX\ editor that unifies the complete research writing lifecycle within a single interface. Bibby embeds an AI writing assistant, smart citation search, AI table and equation generation, an AI paper reviewer, abstract generator, literature review drafting, a deep research assistant, and real-time \LaTeX\ error detection and auto-fix -- all natively, without plugins or copy-paste workflows. We introduce LaTeXBench-500, a benchmark of 500 real-world compilation errors across six categories. Bibby achieves 91.4\% detection accuracy and 83.7\% one-click fix accuracy, outperforming Overleaf's native diagnostics (61.2\%) and OpenAI Prism (78.3 / 64.1\%) by large margins. Bibby demonstrates that a privacy-preserving, research-first AI editor can meaningfully accelerate every stage of academic manuscript preparation. We found that Bibby AI is a far superior alternative to overleaf latex and better than OpenAI Prism functionalities and AI.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [65] [Lyapunov Spectral Analysis of Speech Embedding Trajectories in Psychosis](https://arxiv.org/abs/2602.16273)
*Jelena Vasic,Branislav Andjelic,Ana Mancic,Dusica Filipovic Djurdjevic,Ljiljana Mihic,Aleksandar Kovacevic,Nadja P. Maric,Aleksandra Maluckov*

Main category: nlin.AO

TL;DR: 通过分析精神病患者和健康对照者的言语嵌入，利用李雅普诺夫指数谱评估其语言生成的高维动力学特性，发现非线性动力学不变量可稳定区分精神病与健康言语，且结论在不同嵌入模型间具有一致性。


<details>
  <summary>Details</summary>
Motivation: 探索精神病患者语言表达的动力学特征，以物理启发的方法揭示认知紊乱的潜在机制，并验证不同语言模型嵌入表示下的结论稳定性。

Method: 使用两种不同的大语言模型生成词级别和回答级别的言语嵌入，计算李雅普诺夫指数（LE）谱，分析其动力学稳定性及吸引子维度。

Result: 词级别嵌入显示完全收缩动力学，无正李雅普诺夫指数；回答级别嵌入虽整体收缩，但存在多个正李雅普诺夫指数和更高维吸引子，能稳健区分精神病与健康言语，但在精神病组内差异不显著。

Conclusion: 言语嵌入的非线性动力学不变量可作为探测认知障碍的可靠工具，且结果在不同嵌入模型下保持稳定。

Abstract: We analyze speech embeddings from structured clinical interviews of psychotic patients and healthy controls by treating language production as a high-dimensional dynamical process. Lyapunov exponent (LE) spectra are computed from word-level and answer-level embeddings generated by two distinct large language models, allowing us to assess the stability of the conclusions with respect to different embedding presentations. Word-level embeddings exhibit uniformly contracting dynamics with no positive LE, while answer-level embeddings, in spite of the overall contraction, display a number of positive LEs and higher-dimensional attractors. The resulting LE spectra robustly separate psychotic from healthy speech, while differentiation within the psychotic group is not statistically significant overall, despite a tendency of the most severe cases to occupy distinct dynamical regimes. These findings indicate that nonlinear dynamical invariants of speech embeddings provide a physics-inspired probe of disordered cognition whose conclusions remain stable across embedding models.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [66] [Ratio Covers of Convex Sets and Optimal Mixture Density Estimation](https://arxiv.org/abs/2602.16142)
*Spencer Compton,Gábor Lugosi,Jaouad Mourtada,Jian Qian,Nikita Zhivotovskiy*

Main category: math.ST

TL;DR: 本文研究了在Kullback-Leibler散度下的密度估计问题，考虑模型聚合与凸聚合两种情形，提出了在无界密度比和不同支撑集假设下的最优高概率收敛速率，并通过新的覆盖定理支持混合密度估计的理论分析。


<details>
  <summary>Details</summary>
Motivation: 在不假设基密度具有有界密度比或相同支撑集的情况下，研究密度估计在KL散度下的高概率性能极限，填补现有理论在复杂密度结构下的空白。

Method: 利用局部Hellinger熵的精细上界和针对凸集的最优比率覆盖定理，结合高维几何工具分析混合密度类的覆盖数，从而推导出模型聚合与凸聚合的最优误差界。

Result: 得到了两种聚合设置下KL散度意义下的最优高概率收敛速率；证明了这些速率高于传统有界密度比假设下的结果，并在离散分布特例下匹配已知下界；提出了两个新的覆盖引理，其一为混合类的局部Hellinger熵提供了分布无关的上界，其二为凸集建立了最优的坐标支配覆盖。

Conclusion: 本文确立了在无强正则性假设下密度估计的最优性能界限，所提出的覆盖技术具有独立意义，可应用于多目标优化等领域。

Abstract: We study density estimation in Kullback-Leibler divergence: given an i.i.d. sample from an unknown density $p$, the goal is to construct an estimator $\widehat p$ such that $\mathrm{KL}(p,\widehat p)$ is small with high probability. We consider two settings involving a finite dictionary of $M$ densities: (i) model aggregation, where $p$ belongs to the dictionary, and (ii) convex aggregation (mixture density estimation), where $p$ is a mixture of densities from the dictionary. Crucially, we make no assumption on the base densities: their ratios may be unbounded and their supports may differ. For both problems, we identify the best possible high-probability guarantees in terms of the dictionary size, sample size, and confidence level. These optimal rates are higher than those achievable when density ratios are bounded by absolute constants; for mixture density estimation, they match existing lower bounds in the special case of discrete distributions.
  Our analysis of the mixture case hinges on two new covering results. First, we provide a sharp, distribution-free upper bound on the local Hellinger entropy of the class of mixtures of $M$ distributions. Second, we prove an optimal ratio covering theorem for convex sets: for every convex compact set $K\subset \mathbb{R}_+^d$, there exists a subset $A\subset K$ with at most $2^{8d}$ elements such that each element of $K$ is coordinate-wise dominated by an element of $A$ up to a universal constant factor. This geometric result is of independent interest; notably, it yields new cardinality estimates for $\varepsilon$-approximate Pareto sets in multi-objective optimization when the attainable set of objective vectors is convex.

</details>


### [67] [Nonparametric estimation of linear multiplier for processes driven by a Hermite process](https://arxiv.org/abs/2602.16223)
*B. L. S. Prakasa Rao*

Main category: math.ST

TL;DR: 研究了满足特定随机微分方程的过程中的线性乘子函数θ(t)的非参数估计问题，并探讨了当ε趋近于0时未知函数θ(t)估计量的渐近行为。


<details>
  <summary>Details</summary>
Motivation: 为了理解和估计在含有小噪声的随机微分方程中线性乘子函数θ(t)的行为，特别是在Hermite过程驱动下的情况。

Method: 采用非参数估计方法来估计线性乘子函数θ(t)，并分析当噪声强度ε趋于零时估计量的渐近性质。

Result: 得到了估计量在ε→0时的渐近行为结果。

Conclusion: 该研究提供了对于由已知阶数和自相似参数的Hermite过程驱动的随机微分方程中线性乘子函数θ(t)的有效非参数估计及其渐近特性的理解。

Abstract: We study the problem of nonparametric estimation of the linear multiplier function $θ(t)$ for processes satisfying stochastic differential equations of the type $$dX_t=θ(t) X_tdt+ εdZ^{q,H}_t, X_0=x_0, 0\leq t \leq T$$ where $\{Z^{q,H}_t, t \geq 0\}$ is a Hermite process with known order $q$ and known self-similarity parameter $H \in (\frac{1}{2},1).$ We investigate the asymptotic behaviour of the estimator of the unknown function $θ(t)$ as $ε\rightarrow 0.$

</details>


### [68] [HAL-MLE Log-Splines Density Estimation (Part I: Univariate)](https://arxiv.org/abs/2602.16259)
*Yilong Hou,Zhengpu Zhao,Yi Li,Mark van der Laan*

Main category: math.ST

TL;DR: 本文研究了在总变差（TV）型惩罚下的非参数最大似然密度估计，利用高适应性Lasso（HAL）框架提出了基于对数样条链接函数的HAL-MLE方法。在单变量情形下，证明了有界截面变差范数假设与经典有界TV假设等价，从而将HAL-MLE与现有的TV惩罚方法（如局部自适应样条）联系起来。文章建立了三个新理论结果：HAL-MLE具有渐近线性性、点态渐近正态性，并在光滑阶k≥1时以n^{-(k+1)/(2k+3)}速率一致收敛（至多对数因子）。这些结果推广了前人工作，提供了TV惩罚密度估计的统一框架。


<details>
  <summary>Details</summary>
Motivation: 总变差（TV）正则化在回归和密度估计中已有广泛应用，但现有方法在收敛速度和理论性质方面仍存在局限。本文旨在通过HAL框架重新审视TV惩罚下的密度估计问题，建立与现有TV方法的联系，并提升理论保证，特别是在收敛速率和渐近性质方面。

Method: 采用基于对数样条链接函数的高适应性Lasso（HAL）框架构建最大似然估计量（HAL-MLE），利用HAL的有界截面变差范数结构，在单变量情况下将其与经典的有界TV假设建立等价关系，并进行理论分析。

Result: 1. 证明了单变量HAL-MLE的渐近线性性；2. 建立了点态渐近正态性；3. 对光滑阶k≥1，获得了一致收敛速率n^{-(k+1)/(2k+3)}（至多对数因子），改进了此前仅对k=0保证一致性的结果。同时揭示了HAL-MLE与局部自适应样条等TV惩罚方法的内在联系。

Conclusion: 本文为TV惩罚密度估计提供了一个统一框架，通过HAL-MLE将现代非参数方法与经典TV方法相连接。理论结果不仅深化了对HAL-MLE的理解，也为未来多维情形的研究奠定了基础。

Abstract: We study nonparametric maximum likelihood estimation of probability densities under a total variation (TV) type penalty, sectional variation norm (also named as Hardy-Krause variation). TV regularization has a long history in regression and density estimation, including results on $L^2$ and KL divergence convergence rates. Here, we revisit this task using the Highly Adaptive Lasso (HAL) framework. We formulate a HAL-based maximum likelihood estimator (HAL-MLE) using the log-spline link function from \citet{kooperberg1992logspline}, and show that in the univariate setting the bounded sectional variation norm assumption underlying HAL coincides with the classical bounded TV assumption. This equivalence directly connects HAL-MLE to existing TV-penalized approaches such as local adaptive splines \citep{mammen1997locally}. We establish three new theoretical results: (i) the univariate HAL-MLE is asymptotically linear, (ii) it admits pointwise asymptotic normality, and (iii) it achieves uniform convergence at rate $n^{-(k+1)/(2k+3)}$ up to logarithmic factors for the smoothness order $k \geq 1$. These results extend existing results from \citet{van2017uniform}, which previously guaranteed only uniform consistency without rates when $k=0$. We will include the uniform convergence for general dimension $d$ in the follow-up work of this paper. The intention of this paper is to provide a unified framework for the TV-penalized density estimation methods, and to connect the HAL-MLE to the existing TV-penalized methods in the univariate case, despite that the general HAL-MLE is defined for multivariate cases.

</details>


### [69] [Orthogonal parametrisations of Extreme-Value distributions](https://arxiv.org/abs/2602.16283)
*Nathan Huet,Ilaria Prosdocimi*

Main category: math.ST

TL;DR: 本文提出了主要极值分布的几种正交重新参数化方法，以改善小样本下极值分布拟合的稳定性，并增强了参数的可解释性。


<details>
  <summary>Details</summary>
Motivation: 由于极值分布常用于小样本数据且其参数通常难以解释，导致推断不稳定，因此需要更稳健和可解释的参数化方法。

Method: 应用Cox和Reid（1987）提出的理论，对广义极值分布、广义帕累托分布和Gumbel分布进行正交重新参数化，并通过模拟研究验证其优势。

Result: 重新参数化后的模型在模拟中表现出更好的推断稳定性，同时提高了参数的可解释性。

Conclusion: 正交重新参数化能有效提升极值分布的估计效果，尤其适用于小样本场景下的极端事件风险评估。

Abstract: Extreme value distributions are routinely employed to assess risks connected to extreme events in a large number of applications. They typically are two- or three- parameter distributions: the inference can be unstable, which is particularly problematic given the fact that often times these distributions are fitted to small samples. Furthermore, the distribution's parameters are generally not directly interpretable and not the key aim of the estimation. We present several orthogonal reparametrisations of the main extreme-value distributions, key in the modelling of rare events. In particular, we apply the theory developed in Cox and Reid (1987) to the Generalised Extreme-Value, Generalised Pareto, and Gumbel distributions. We illustrate the principal advantage of these reparametrisations in a simulation study.

</details>


### [70] [Estimation of Conformal Metrics](https://arxiv.org/abs/2602.16466)
*Jérôme Taupin*

Main category: math.ST

TL;DR: 本文研究了由共形因子诱导的RN中域的测地距离变形，在正reach假设和对共形因子的温和假设下，证明了共形度量下的测地线具有良好正则性，并给出了基于随机点云估计共形度量的误差界和收敛速率，同时建立了球图与最近邻图在Ahlfors正则性条件下的等价性。


<details>
  <summary>Details</summary>
Motivation: 为了在非子流形的广义域上理解共形度量对几何结构的影响，并实现从离散点云高效、稳定地估计共形度量。

Method: 利用正reach条件保证域的几何正则性，结合共形因子的光滑性分析测地线的正则性；通过Hausdorff距离控制点云逼近误差，并构造可在O(n^2)时间内计算的估计量；借助Ahlfors正则性建立球图与最近邻图之间的等价关系。

Result: 证明了共形度量下测地线具有下界正则性（有界reach）；给出了估计误差与Hausdorff距离成正比的界；获得了接近最优的收敛速率n^(-1/d)；建立了在Ahlfors正则测度下球图与最近邻图的等价性。

Conclusion: 在合理假设下，共形度量的几何性质具有良好稳定性，可从点云高效估计，并为基于图的几何学习方法提供了理论支持。

Abstract: We study deformations of the geodesic distances on a domain of R N induced by a function called conformal factor. We show that under a positive reach assumption on the domain (not necessarily a submanifold) and mild assumptions on the conformal factor, geodesics for the conformal metric have good regularity properties in the form of a lower bounded reach. This regularity allows for efficient estimation of the conformal metric from a random point cloud with a relative error proportional to the Hausdorff distance between the point cloud and the original domain. We then establish convergence rates of order n^(-1/d) that are close to sharp when the intrinsic dimension d of the domain is large, for an estimator that can be computed in O(n^2 ) time. Finally, this paper includes a useful equivalence result between ball graphs and nearest-neighbors graphs when assuming Ahlfors regularity of the sampling measure, allowing to transpose results from one setting to another.

</details>


### [71] [Optimal training-conditional regret for online conformal prediction](https://arxiv.org/abs/2602.16537)
*Jiadong Liang,Zhimei Ren,Yuxin Chen*

Main category: math.ST

TL;DR: 本文研究了在未知分布漂移的非平稳数据流中进行在线共形预测的问题，提出了一种基于漂移检测的自适应算法，并在不同设置下实现了最优的累积后悔界。


<details>
  <summary>Details</summary>
Motivation: 现有工作多集中于对抗性设置或时间平均边际覆盖性能评估，而本文旨在通过训练条件下的累积后悔来更准确地评估非平稳环境中的预测性能。

Method: 针对预训练的非一致性评分函数，提出一种基于划分共形方法并结合漂移检测的算法；对于在线训练的评分函数，则设计一种全共形风格的算法，利用模型拟合算法的稳定性应对分布漂移。

Result: 所提算法在突变和渐变两种分布漂移下均实现了最小最大最优的后悔界，理论分析得到非渐近后悔保证，实验结果验证了理论发现。

Conclusion: 结合漂移检测与共形预测的方法能有效应对非平稳数据流中的分布变化，在理论和实践中均表现出优越性能。

Abstract: We study online conformal prediction for non-stationary data streams subject to unknown distribution drift. While most prior work studied this problem under adversarial settings and/or assessed performance in terms of gaps of time-averaged marginal coverage, we instead evaluate performance through training-conditional cumulative regret. We specifically focus on independently generated data with two types of distribution shift: abrupt change points and smooth drift.
  When non-conformity score functions are pretrained on an independent dataset, we propose a split-conformal style algorithm that leverages drift detection to adaptively update calibration sets, which provably achieves minimax-optimal regret. When non-conformity scores are instead trained online, we develop a full-conformal style algorithm that again incorporates drift detection to handle non-stationarity; this approach relies on stability - rather than permutation symmetry - of the model-fitting algorithm, which is often better suited to online learning under evolving environments. We establish non-asymptotic regret guarantees for our online full conformal algorithm, which match the minimax lower bound under appropriate restrictions on the prediction sets. Numerical experiments corroborate our theoretical findings.

</details>


### [72] [Separating Oblivious and Adaptive Models of Variable Selection](https://arxiv.org/abs/2602.16568)
*Ziyun Chen,Jerry Li,Kevin Tian,Yusong Zhu*

Main category: math.ST

TL;DR: 本文研究了具有ℓ∞误差保证的稀疏恢复问题，揭示了在“无感知”和“自适应”模型之间存在显著的样本复杂度差异：无感知模型下可在近线性时间内以约k log d个样本达到最优ℓ∞误差，而自适应模型则需要至少k²个样本。这与标准ℓ₂情形形成鲜明对比，并初步探讨了部分自适应模型下的变量选择。


<details>
  <summary>Details</summary>
Motivation: 受变量选择任务驱动，旨在估计高维空间中稀疏信号的支持集，关注ℓ∞误差下的恢复性能。

Method: 通过理论分析比较无感知（for each）与自适应（for all）两种模型下的ℓ∞稀疏恢复能力，利用信息论下界和算法上界证明样本复杂度的分离现象，并初步研究部分自适应模型。

Result: 证明在无感知模型下，仅需约k log d个样本即可在近线性时间内实现最优ℓ∞误差；而在自适应模型下，任何算法要达到相同误差都需要至少k²个样本，显示出与ℓ₂情形的根本不同。

Conclusion: ℓ∞稀疏恢复在自适应设定下面临更高的样本复杂度，揭示了模型适应性对恢复效率的关键影响，为变量选择提供了新的理论理解。

Abstract: Sparse recovery is among the most well-studied problems in learning theory and high-dimensional statistics. In this work, we investigate the statistical and computational landscapes of sparse recovery with $\ell_\infty$ error guarantees. This variant of the problem is motivated by \emph{variable selection} tasks, where the goal is to estimate the support of a $k$-sparse signal in $\mathbb{R}^d$. Our main contribution is a provable separation between the \emph{oblivious} (``for each'') and \emph{adaptive} (``for all'') models of $\ell_\infty$ sparse recovery. We show that under an oblivious model, the optimal $\ell_\infty$ error is attainable in near-linear time with $\approx k\log d$ samples, whereas in an adaptive model, $\gtrsim k^2$ samples are necessary for any algorithm to achieve this bound. This establishes a surprising contrast with the standard $\ell_2$ setting, where $\approx k \log d$ samples suffice even for adaptive sparse recovery. We conclude with a preliminary examination of a \emph{partially-adaptive} model, where we show nontrivial variable selection guarantees are possible with $\approx k\log d$ measurements.

</details>


### [73] [On Sharpened Convergence Rate of Generalized Sliced Inverse Regression for Nonlinear Sufficient Dimension Reduction](https://arxiv.org/abs/2602.16606)
*Chak Fung Choi,Yin Tang,Bing Li*

Main category: math.ST

TL;DR: 本文改进了广义切片逆回归（GSIR）的收敛速度，在温和的特征值衰减和光滑性条件下，其收敛速度可接近n^{-1/3}，优于Li和Song（2017）的n^{-1/4}，对半参数估计等问题具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 提升GSIR方法的收敛速度，以满足半参数估计中对无限维干扰参数估计速度高于n^{-1/4}的要求，从而实现渐近有效性等理想性质。

Method: 在额外的温和特征值衰减率和光滑性条件下，建立改进的GSIR收敛速度理论，并推广到更一般的情形如函数型充分降维。

Result: 得到了比原有结果更快的收敛速度，可在适当条件下使收敛速度任意接近n^{-1/3}，显著优于之前的n^{-1/4}。

Conclusion: 改进后的GSIR收敛速度能够满足更多统计推断需求，尤其在半参数模型中具有重要应用价值，且该结果可推广至更广泛的场景。

Abstract: Generalized Sliced Inverse Regression (GSIR) is one of the most important methods for nonlinear sufficient dimension reduction. As shown in Li and Song (2017), it enjoys a convergence rate that is independent of the dimension of the predictor, thus avoiding the curse of dimensionality. In this paper we establish an improved convergence rate of GSIR under additional mild eigenvalue decay rate and smoothness conditions. Our convergence rate can be made arbitrarily close to $n^{-1/3}$ under appropriate decay rate and smoothness parameters. As a comparison, the rate of Li and Song (2017) is $n^{-1/4}$ under the best conditions. This improvement is significant because, for example, in a semiparametric estimation problem involving an infinite-dimensional nuisance parameter, the convergence rate of the estimator of the nuisance parameter is often required to be faster than $n^{-1/4}$ to guarantee desired semiparametric properties such as asymptotic efficiency. This can be achieved by the improved convergence rate, but not by the original rate. The sharpened convergence rate can also be established for GSIR in more general settings, such as functional sufficient dimension reduction.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [74] [Development of a single-parameter spring-dashpot rolling friction model for coarse-grained DEM](https://arxiv.org/abs/2602.15887)
*Putri Mustika Widartiningsih,Yoshiharu Tsugeno,Toshiki Imatani,Yuki Tsunazawa,Mikio Sakai*

Main category: physics.comp-ph

TL;DR: 提出一种新的弹簧-阻尼型滚动摩擦模型，仅需一个物理意义明确的参数——临界滚动角，简化了非球形颗粒在离散元模拟中的建模与标定过程。


<details>
  <summary>Details</summary>
Motivation: 现有滚动摩擦模型需要多个相互依赖的经验参数，导致标定困难、参数模糊和应用不确定性，限制了非球形颗粒的大规模离散元模拟。

Method: 基于理论推导引入单一参数——临界滚动角，构建新型弹簧-阻尼型滚动摩擦模型，并结合稳定性分析验证其物理一致性，进一步集成到粗粒化DEM框架中用于大规模模拟。

Result: 新模型避免了传统模型中的旋转振荡问题，能稳定达到物理平衡状态；通过DEM-CFD耦合模拟焚烧系统验证，可准确再现原始系统的宏观行为。

Conclusion: 该研究通过简化参数体系提升了离散元方法在工业尺度非球形颗粒系统模拟中的适用性和可靠性。

Abstract: Simulating granular materials composed of non-spherical particles remains a major challenge in discrete element method (DEM) simulations due to the complexity of contact detection and rotational dynamics, rendering large-scale simulations computationally prohibitive. To address this limitation, rolling friction is commonly introduced as an approximation to account for particle shape effects by applying a resistive torque to spherical particles. Among existing rolling friction formulations, the spring-dashpot (S-D) type model is widely recognized for its numerical stability and realistic representation of rolling resistance. However, conventional S-D models require multiple empirical parameters that must be calibrated in an interdependent manner, leading to increased experimental effort, parameter ambiguity, and uncertainty in practical applications. To overcome these issues, this study proposes a new S-D type rolling friction model that reduces the parameter set to a single physically meaningful quantity: the critical rolling angle. Derived from theoretical considerations, this parameter characterizes the transition from static to rolling motion at particle contacts. The use of a single parameter simplifies implementation and eliminates the need for extensive calibration. Stability analysis demonstrates that the proposed model allows particles to reach a physically consistent equilibrium state without spurious rotational oscillations. For large-scale applications, the model is further integrated into a coarse-grained DEM framework. Validation using DEM-CFD simulations of an incinerator system confirms that the proposed approach successfully reproduces the macroscopic behavior of the original particle system. Overall, this study enhances the applicability of DEM for industrial-scale simulations involving non-spherical particles.

</details>


### [75] [Surrogate Modeling for Neutron Transport: A Neural Operator Approach](https://arxiv.org/abs/2602.15890)
*Md Hossain Sahadath,Qiyun Cheng,Shaowu Pan,Wei Ji*

Main category: physics.comp-ph

TL;DR: 本研究提出了一种基于神经算子的替代模型框架，用于中子输运计算，采用DeepONet和FNO两种架构学习从各向异性源到角通量的映射，并在不同散射比下表现出高精度与高效性，显著加速求解过程，具备实现实时数字孪生和设计优化的潜力。


<details>
  <summary>Details</summary>
Motivation: 为加速传统中子输运求解器的计算，克服其在重复评估（如设计优化）中的高成本问题，探索神经算子作为高效、可推广的替代模型。

Method: 采用DeepONet和FNO两种神经算子架构，在一维平板几何中训练模型以学习从各向异性中子源Q(x,μ)到角通量ψ(x,μ)的映射；针对不同散射比（c=0.1, 0.5, 1.0）分别训练模型，并将其嵌入S_N k-特征值求解器中替代输运扫描循环。

Result: FNO通常具有更高的预测精度，而DeepONet更具计算效率；两者相比传统S_N求解器运行时间均低于0.3%；在k-特征值求解中，运行时间降至传统方法的0.1%以下，特征值偏差分别为DeepONet 135 pcm和FNO 112 pcm。

Conclusion: 神经算子框架在中子输运问题中展现出高精度、高效率和良好泛化能力，有望支持实时数字孪生和高频次仿真任务，如反应堆设计优化。

Abstract: This work introduces a neural operator based surrogate modeling framework for neutron transport computation. Two architectures, the Deep Operator Network (DeepONet) and the Fourier Neural Operator (FNO), were trained for fixed source problems to learn the mapping from anisotropic neutron sources, Q(x,μ), to the corresponding angular fluxes, ψ(x,μ), in a one-dimensional slab geometry. Three distinct models were trained for each neural operator, corresponding to different scattering ratios (c = 0.1, 0.5, & 1.0), providing insight into their performance across distinct transport regimes (absorption-dominated, moderate, and scattering-dominated). The models were subsequently evaluated on a wide range of previously unseen source configurations, demonstrating that FNO generally achieves higher predictive accuracy, while DeepONet offers greater computational efficiency. Both models offered significant speedups that become increasingly pronounced as the scattering ratio increases, requiring <0.3% of the runtime of a conventional S_N solver. The surrogate models were further incorporated into the S_N k-eigenvalue solver, replacing the computationally intensive transport sweep loop with a single forward pass. Across varying fission cross sections and spatial-angular grids, both neural operator solvers reproduced reference eigenvalues with deviations up to 135 pcm for DeepONet and 112 pcm for FNO, while reducing runtime to <0.1% of that of the S_N solver on relatively fine grids. These results demonstrate the strong potential of neural operator frameworks as accurate, efficient, and generalizable surrogates for neutron transport, paving the way for real-time digital twin applications and repeated evaluations, such as in design optimization.

</details>


### [76] [The Beauty of Mathematics in Helfrich's Biomembrane Theory](https://arxiv.org/abs/2602.16002)
*Tao Xu,Zhong-Can Ou-Yang*

Main category: physics.comp-ph

TL;DR: 本文综述了生物膜形状问题，以纪念液晶膜模型创始人Wolfgang Helfrich教授。通过软物质物理、液晶理论和连续弹性模型，系统阐述了红细胞双凹形等生物膜形态的形成机制，并指出在特定力学条件下，柱状、球状、环状、双凹圆盘及Delaunay曲面等形状具有内在几何统一性。


<details>
  <summary>Details</summary>
Motivation: 为纪念Wolfgang Helfrich教授对膜物理和液晶显示技术的杰出贡献，同时系统总结生物膜形状形成的物理机制，揭示其背后的统一几何与力学原理。

Method: 采用材料科学与液晶理论相结合的方法，基于Helfrich弹性模型和连续介质弹性理论，分析生物膜的形状演化，并类比晶体、肥皂泡、层状液晶及碳纳米结构等系统进行讨论。

Result: 发现柱状、球状、环状、双凹圆盘及Delaunay曲面等生物膜形状构成一个具有内在几何统一性的形状族；该特性独立于具体的膜方程，仅在压力、表面张力和弯曲模量满足特定条件时显现。

Conclusion: 连续弹性理论具有强大的统一描述能力，可广泛应用于解释从生物到合成系统中多种膜形态的形成机制，体现了软物质物理在生物膜研究中的核心作用。

Abstract: It is with great regret that Prof. Wolfgang Helfrich passed away on 28 September 2025 in Berlin. As the founder of the membrane liquid crystal model, Prof. Helfrich made outstanding contributions to membrane physics and liquid crystal display technology. This review article is written in his memory. Biomembranes, primarily composed of lipid bilayers, are not merely passive barriers but dynamic and complex materials whose shapes are governed by the principles of soft matter physics. This review explores the shape problem in biomembranes through the lens of material science and liquid crystal theory. Beginning with classical analogies to crystals and soap bubbles, it details the application of the Helfrich elastic model to explain the biconcave shape of red blood cells. The discussion extends to multi-layer systems, drawing parallels between the focal conic structures of smectic liquid crystals, the geometries of fullerenes and carbon nanotubes, and the reversible transitions in peptide assemblies. Furthermore, it examines icosahedral self-assemblies and shape formation in two-dimensional lipid monolayers at air/water interfaces. At the end of the paper, we find that the shapes such as cylinders, spheres, tori, bicocave discoids and Delaunay surfaces form a group. This result is merely an intrinsic geometric feature of these shapes and is independent of the biomembrane equation. When the pressure on the membrane, surface tension, and bending modules meet certain conditions, the biomembrane will take on these shapes. The review concludes by highlighting the unifying power of continuum elastic theories in describing a vast array of membrane morphologies across biological and synthetic systems.

</details>


### [77] [Inverse Engineering of Optical Constants in Photochromic Micron-Scale Hybrid Films](https://arxiv.org/abs/2602.16180)
*Bahrem Serhat Danis,Amin Tabatabaei Mohseni,Smagul Karazhanov,Esra Zayim*

Main category: physics.comp-ph

TL;DR: 提出了一种数据驱动框架，通过实验透射率测量提取微米级光致变色杂化薄膜的有效光学常数，实现对其光学调制的准确预测。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏明确定义的光学常数，微米级光致变色杂化薄膜的理性设计受到限制，传统电磁模拟方法计算成本高且与实验分布存在差异。

Method: 建立双态有效模型，将非均匀光致变色层近似为具有伪折射率和伪消光系数的均质介质，并通过实验数据系统优化确定波长相关的伪光学常数和压缩比。

Result: 利用钨氧化物-聚乙烯吡咯烷酮杂化薄膜的实验数据验证了该方法，能够准确预测特定厚度范围内的光学调制性能。

Conclusion: 该数据驱动建模方法为设计杂化光致变色系统提供了有效框架，并展示了其在复杂纳米结构材料表征中的优势。

Abstract: Photochromic materials enable dynamic optical modulation through reversible transitions between distinct absorption states, with broad potential for smart windows, adaptive optics, and reconfigurable photonic devices. Micron-scale photochromic hybrid films present a particularly attractive platform for these applications, combining straightforward preparation with substantial optical modulation and scalability for high-volume fabrication. However, rational design of such films remains fundamentally constrained by the absence of well-defined optical constants. Unlike homogeneous thin films, micron-scale hybrid photochromic materials comprise active particles dispersed non-uniformly within polymer matrices. Conventional first-principles electromagnetic simulations face substantial computational costs and discrepancies between simulated and experimental particle distributions. Here, we introduce a data-driven framework that extracts effective optical constants directly from minimal experimental transmittance measurements. Our dual-state effective model approximates the complex inhomogeneous photochromic layer as a compressed homogeneous medium characterized by pseudo-refractive indices and pseudo-extinction coefficients for both pristine and UV-irradiated states. Through systematic optimization against experimental data from tungsten oxide-polyvinylpyrrolidone hybrid films, we determine wavelength-dependent pseudo-optical constants and compression ratios that enable accurate prediction of optical modulation within the tested thickness range. Our methodology establishes a framework for engineering hybrid photochromic systems and demonstrates how data-driven modeling can overcome limitations in characterizing complex nanostructured materials.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [78] [Mapping tuberculosis fatalities by region and age group in South Korea: A dataset for targeted health policy optimization](https://arxiv.org/abs/2602.16437)
*Yongsung Kwon,Deok-Sun Lee,Mi Jin Lee,Seung-Woo Son*

Main category: physics.soc-ph

TL;DR: 本研究通过重建方法生成了韩国2014至2022年区级结核病死亡与医疗可及性高分辨率数据集，结合年龄结构优化医院资源配置，揭示了效率与人口 targeting 之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 由于隐私限制，韩国缺乏区级年龄分层的结核病数据，限制了对医疗可及性的精细分析。本研究旨在构建高分辨率数据集以支持更精准的流行病学与资源配置研究。

Method: 整合省级年龄特异性统计与区级空间人口数据，采用重构方法推断区级年龄分层的结核病病例与死亡数；扩展医院分配框架为目标函数加入年龄权重，优化不同加权方案下的医院配置。

Result: 成功构建覆盖228个区、多年度的结核病死亡与医疗可及性数据集；发现引入年龄结构会导致不同的最优医院配置模式，尽管总死亡最小化结果相近，但暴露了效率与人口公平间的权衡；数据集支持时间趋势与空间异质性分析。

Conclusion: 年龄结构在医疗资源优化中具有重要影响，忽略该因素可能掩盖关键的人口健康不平等；本数据集为高分辨率空间流行病学和卫生政策制定提供了有力工具。

Abstract: In South Korea, age-disaggregated tuberculosis (TB) data at the district level are not publicly available due to privacy constraints, limiting fine-scale analyses of healthcare accessibility. To address this limitation, we present a high-resolution, district-level dataset on tuberculosis (TB) fatalities and hospital accessibility in South Korea, covering the years 2014 to 2022 across 228 districts. The dataset is constructed using a reconstruction method that infers age-disaggregated TB cases and fatalities at the district level by integrating province-level age-specific statistics with district-level spatial and demographic data, enabling analyses that account for both spatial heterogeneity and age structure. Building on an existing hospital allocation framework, we extend the objective function to an age-weighted formulation and apply it to the reconstructed dataset to minimize TB fatalities under different age-weighting schemes. We demonstrate that incorporating age structure can give rise to distinct optimized hospital allocation patterns, even when the total number of minimized fatalities is similar, revealing trade-offs between efficiency and demographic targeting. In addition, the dataset supports temporal analyses of TB burden, hospital availability, and demographic variation over time, and provides a testbed for spatial epidemiology and optimization studies that require high-resolution demographic and healthcare data.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [79] [Projection-based approximations for eigenvalue problems of Fredholm integral operators with Green's kernels](https://arxiv.org/abs/2602.16191)
*Shashank K. Shukla,Gobinda Rakshit,Akshay S. Rane*

Main category: math.NA

TL;DR: 研究了具有格林核的紧线性积分算子K的特征值和谱子空间逼近的收敛速度，通过在2r+1个配置点上使用分段偶次多项式空间的正交和插值投影，实现了迭代下特征函数的超收敛，并通过数值例子验证了改进投影方法比经典方法具有更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 提高特征值和特征函数逼近的收敛速度，改进经典投影方法在处理具有格林核的紧积分算子时的精度和效率。

Method: 采用在2r+1个非必需为高斯点的配置点上的正交和插值投影，将问题投影到分段偶次多项式空间，并分析其迭代下的收敛性。

Result: 证明了改进的投影方法能实现特征函数的超收敛，获得了比经典方法更快的收敛速率，并通过数值实验验证了理论结果。

Conclusion: 改进的投影方法在处理具有格林核的紧积分算子特征值问题时，显著提升了收敛速度，是一种有效的数值逼近策略。

Abstract: We consider the eigenvalue problem $K x = λx$. Our analysis focuses on the convergence rates of eigenvalue and spectral subspace approximations for compact linear integral operator $K$ with Green's kernels. By employing orthogonal and interpolatory projections at $2r+1$ collocation points (which are not necessarily Gauss points) onto an approximating space of piecewise even degree polynomials, we establish the superconvergence of eigenfunctions under iteration. The modified projection methods achieve a faster convergence rates compared to classical projection methods. The enhancement in convergence rate is verified by numerical examples.

</details>


### [80] [Numerical Construction of Quasi-Periodic Solutions Beyond Symplectic Integrators](https://arxiv.org/abs/2602.16275)
*Mingwei Fu,Bin Shi*

Main category: math.NA

TL;DR: 提出一种基于Nash-Moser迭代的数值算法，通过频率更新和增维牛顿法直接求解拟周期轨道，消除传统辛积分器中的相位漂移问题，克服了KAM理论在数值计算中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统辛积分器在长时间模拟中存在累积相位误差的问题，且KAM理论因全局无理条件难以直接用于数值计算，需发展可执行的构造性方法。

Method: 受CWB方案启发，引入包含频率更新的数值算子，结合增维牛顿迭代，采用交替数值流程直接求解瞬时位置与相位角，将Nash-Moser迭代转化为实用数值框架。

Result: 实现了相位误差不随总积分时间增长的拟周期解计算，可在足够资源下任意减小相位误差，并局部处理无理数条件，避免全局Diophantine条件的限制。

Conclusion: 该算法突破了传统KAM方法的数值不可达性，为近可积哈密顿系统的长期模拟提供了无需时间步进、无相位滞后的新型数值途径。

Abstract: Symplectic integrators are the established standard for long-term simulations of nearly-integrable Hamiltonian systems due to their preservation of geometric structures. However, they suffer from an inherent limitation: secular phase-shift errors. While the qualitative ''shape'' of invariant tori is preserved, the numerical solution gradually drifts along the torus, leading to a phase-lag accumulation that degrades long-term positional accuracy. Inspired by the Craig-Wayne-Bourgain (CWB) scheme, originally developed as an analytical tool for infinite-dimensional systems, we introduce a numerical operator that incorporates frequency updates into a dimension-enlarged Newton iteration to compute quasi-periodic solutions. Unlike conventional time-stepping integrators, our alternating numerical procedure eliminates phase-lag accumulation by directly solving for instantaneous positions and phase angles. Theoretically, provided sufficient computational resources, the phase error can be reduced arbitrarily, remaining independent of the total integration time. Our algorithm translates the Nash-Moser iteration into a practical numerical framework, marking a significant departure from traditional Kolmogorov-Arnold-Moser (KAM) theory. While KAM provides rigorous existence proofs, its requirement for global Diophantine conditions and the total exclusion of resonant sets render it numerically inaccessible. By employing a ''step-by-step'' exclusion process and incrementally enlarging the dimension, our algorithm resolves irrationality conditions locally. This approach demonstrates that the ''numerical irrationality problem'' is not an intrinsic barrier to computation, offering a constructive, executable alternative to the non-executable nature of global KAM-based methods.

</details>


### [81] [Finite elements for the space approximation of a differential model for salts crystallization](https://arxiv.org/abs/2602.16303)
*Alessandra Aimi,Gabriella Bretti,Giulia Di Credico,Francesco Freddi,Chiara Guardasoni,Mario Pezzella*

Main category: math.NA

TL;DR: 本文研究了与石质文物因暴露于空气和大气因素导致盐晶积累而退化相关的时空微分模型，提出了一种基于有限元空间离散化和隐式-显式时间推进的数值方法，并在二维和三维空间中进行了高效模拟与分析。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地模拟石质文物在复杂环境下的盐分积累和退化过程，需要发展适用于高维空间的数值模型。

Method: 采用有限元法进行空间离散化，结合隐式-显式时间步进方法，并在原有的一维有限差分框架基础上进行扩展，同时进行稳定性分析和实验收敛性分析。

Result: 实现了高效的代码实现，并在二维和三维空间中得到了数值结果，验证了所提方法的有效性和性能。

Conclusion: 所提出的有限元方法能够有效处理高维情况下的石质文物退化建模，具有良好的稳定性和收敛性，适用于实际应用中的复杂几何结构模拟。

Abstract: This article investigates a space-time differential model related to the degradation of stone artifacts caused by exposure to air and atmospheric agents, which specifically lead to the accumulation of salt crystals in the material. A numerical method based on finite-element space discretization and implicit-explicit time marching is proposed as an extension of a one-dimensional finite-difference framework introduced in the literature. Within the same one-dimensional setting, a sensitivity analysis is performed, based on the techniques developed therein. They are also used as a comparison tool for the finite-element formulation, here introduced for more realistic simulations in higher space dimensions. Considerations about stability will be provided, together with an experimental convergence analysis highlighting the performance of the proposed approach. Numerical results in two and three space dimensions, obtained by an efficient code implementation, will be presented and discussed.

</details>


### [82] [An agglomeration-based multigrid solver for the discontinuous Galerkin discretization of cardiac electrophysiology](https://arxiv.org/abs/2602.16312)
*Marco Feder,Pasquale Claudio Africa*

Main category: math.NA

TL;DR: 提出了一种基于聚集的多级预处理器，用于加速心脏电生理学单域模型间断Galerkin离散化所得线性系统的求解。


<details>
  <summary>Details</summary>
Motivation: 为了提高求解心脏电生理学中大规模线性系统的效率和可扩展性，特别是基于不连续Galerkin方法的离散化系统。

Method: 采用基于元素聚集的策略构建多级网格层次结构，在粗层级上使用广义多面体网格，并结合多级预处理器框架加速迭代求解器的收敛。

Result: 数值实验表明该方法在二维和三维复杂几何下具有良好的求解效率和强可扩展性，且对多项式次数和多级层数变化均表现稳健。

Conclusion: 所提出的基于聚集的多级预处理器能有效加速间断Galerkin法求解单域模型的收敛过程，具备良好的可扩展性和应用前景。

Abstract: This work presents a novel agglomeration-based multilevel preconditioner designed to accelerate the convergence of iterative solvers for linear systems arising from the discontinuous Galerkin discretization of the monodomain model in cardiac electrophysiology. The proposed approach exploits general polytopic grids at coarser levels, obtained through the agglomeration of elements from an initial, potentially fine, mesh. By leveraging a robust and efficient agglomeration strategy, we construct a nested hierarchy of grids suitable for multilevel solver frameworks. The effectiveness and performance of the methodology are assessed through a series of numerical experiments on two- and three-dimensional domains, involving different ionic models and realistic unstructured geometries. The results demonstrate strong solver effectiveness and favorable scalability with respect to both the polynomial degree of the discretization and the number of levels selected in the multigrid preconditioner.

</details>


### [83] [A Fully Discrete Nonnegativity-Preserving FEM for a Stochastic Heat Equation](https://arxiv.org/abs/2602.16508)
*Owen Hearder,Claude Le Bris,Ana Djurdjevac*

Main category: math.NA

TL;DR: 提出了一种结合质量集中有限元与Lie-Trotter分裂策略的全离散数值方法，用于求解具有非线性乘性有限维噪声的随机热方程，在保持非负性的同时实现了收敛。


<details>
  <summary>Details</summary>
Motivation: 为了在数值求解具有非负初值的随机热方程时保持解的非负性，并提高计算效率与稳定性。

Method: 结合质量集中的有限元方法与Lie-Trotter算子分裂策略，分别处理确定性和随机动力学部分。

Result: 该方法在离散层面保持了非负性，并在适当正则性条件下证明了收敛性；数值实验验证了收敛速率和非负性保持能力。

Conclusion: 所提方法有效保持了解的非负性并实现了收敛，数值实验表明其在理论范围外也具有良好的适用性与潜力。

Abstract: We consider a stochastic heat equation with nonlinear multiplicative finite-dimensional noise that admits a unique nonnegative solution when given nonnegative initial data. Inspired by existing results for fully discrete finite difference schemes and building on the convergence analysis of semi-discrete mass-lumped finite element approximations, a fully discrete numerical method is introduced that combines mass-lumped finite elements with a Lie-Trotter splitting strategy. This discretization preserves nonnegativity at the discrete level and is shown to be convergent under suitable regularity conditions. A rigorous convergence analysis is provided, highlighting the role of mass lumping in ensuring nonnegativity and of operator splitting in decoupling the deterministic and stochastic dynamics. Numerical experiments are presented to confirm the convergence rates and the preservation of nonnegativity. In addition, we examine several numerical examples outside the scope of the established theory, aiming to explore the range of applicability and potential limitations of the proposed method.

</details>


### [84] [A higher order pressure-stabilized virtual element formulation for the Stokes-Poisson-Boltzmann equations](https://arxiv.org/abs/2602.16538)
*Sudheer Mishra,Sundararajan Natarajan,E. Natarajan,Gianmarco Manzini*

Main category: math.NA

TL;DR: 提出了一种基于等阶虚拟元方法的Stokes-Poisson-Boltzmann方程数值模拟框架，适用于复杂几何域下的电渗流问题，具有最优收敛性且支持任意多边形网格。


<details>
  <summary>Details</summary>
Motivation: 为在复杂几何域中准确模拟纳米孔传感器和微流控器件中的流体-静电耦合现象，需发展能处理不规则边界和自适应网格细化的稳健数值方法。

Method: 采用等阶虚拟元方法求解Stokes-Poisson-Boltzmann方程组，引入基于残差的压力稳定化策略，将动量方程中的拉普拉斯阻力项转化为非线性Poisson-Boltzmann方程相关的加权对流项，从而避免高阶导数项并保持理论严谨性。

Result: 在多种多边形网格（含畸变单元、非凸多边形、Voronoi图及悬挂节点）上验证了方法的最优收敛阶，数值结果与理论预测一致，并成功应用于复杂障碍物构型下的纳米孔电渗流模拟。

Conclusion: 该方法简化了实现过程，统一处理各物理场的多项式逼近，原生支持任意多边形网格，相较Taylor-Hood有限元更具工程实用性。

Abstract: Electrokinetic phenomena in nanopore sensors and microfluidic devices require accurate simulation of coupled fluid-electrostatic interactions in geometrically complex domains with irregular boundaries and adaptive mesh refinement. We develop an equal-order virtual element method for the Stokes--Poisson--Boltzmann equations that naturally handles general polygonal meshes, including meshes with hanging nodes, without requiring special treatment or remeshing. The key innovation is a residual-based pressure stabilization scheme derived by reformulating the Laplacian drag force in the momentum equation as a weighted advection term involving the nonlinear Poisson--Boltzmann equation, thereby eliminating second-order derivative terms while maintaining theoretical rigor. Well-posedness of the coupled stabilized problem is established using the Banach and Brouwer fixed-point theorems under sufficiently small data assumptions, and optimal a priori error estimates are derived in the energy norm with convergence rates of order $\mathcal{O}(h^k)$ for approximation degree $k \geq 1$. Numerical experiments on diverse polygonal meshes -- including distorted elements, non-convex polygons, Voronoi tessellations, and configurations with hanging nodes -- confirm optimal convergence rates, validating theoretical predictions. Applications to electro-osmotic flows in nanopore sensors with complex obstacle geometries illustrate the method's practical utility for engineering simulations. Compared to Taylor--Hood finite element formulations, the equal-order approach simplifies implementation through uniform polynomial treatment of all fields and offers native support for general polygonal elements.

</details>


### [85] [Whittle-Matérn Fields with Variable Smoothness](https://arxiv.org/abs/2602.16581)
*Hamza Ruzayqat,Wenyu Lei,David Bolin,George Turkiyyah,Omar Knio*

Main category: math.NA

TL;DR: 提出并分析了一种非局部Whittle-Matérn高斯场的推广模型，其光滑性参数通过分数阶s=s(x)在空间中变化。基于修正贝塞尔函数构造核，并研究了变阶非局部形式下的存在唯一性和正则性，同时提出了有限元采样方法与数值实验。


<details>
  <summary>Details</summary>
Motivation: 传统Whittle-Matérn场采用常数阶光滑性参数，难以刻画空间异质性；本文旨在通过引入空间可变的分数阶参数s(x)，构建更灵活的非局部随机场模型以适应复杂的空间不均匀结构。

Method: 通过修正第二类贝塞尔函数构造积分型算子核，其奇异性由对称指数β(x,y)=(s(x)+s(y))/2控制；建立适配该核的新变分框架，证明截断有界域上弱解的存在唯一性，并分析高斯谱解的Sobolev正则性；设计有限元采样方法并推导误差估计。

Result: 证明了解的存在唯一性，得到样本路径属于H^r(G)（对所有r<2\underline{s}-d/2），当\underline{s}>d/4时属于L_2(G)；数值实验展示了空间变化光滑性对样本协方差的影响；提出了可行的有限元实现方案。

Conclusion: 该变阶非局部Whittle-Matérn模型能有效刻画空间依赖性的局部变化，理论分析和数值方法为处理空间异质随机场提供了新工具，具有进一步扩展至大规模应用的潜力。

Abstract: We introduce and analyze a nonlocal generalization of Whittle--Matérn Gaussian fields in which the smoothness parameter varies in space through the fractional order, $s=s(x)\in[\underline{s}\,,\bar{s}]\subset(0,1)$. The model is defined via an integral-form operator whose kernel is constructed from the modified Bessel function of the second kind and whose local singularity is governed by the symmetric exponent $β(x,y)=(s(x)+s(y))/2$. This variable-order nonlocal formulation departs from the classical constant-order pseudodifferential setting and raises new analytic and numerical challenges. We develop a novel variational framework adapted to the kernel, prove existence and uniqueness of weak solutions on truncated bounded domains, and derive Sobolev regularity of the Gaussian (spectral) solution controlled by the minimal local order: realizations lie in $H^r(G)$ for every $r<2\underline{s}-\tfrac{d}{2}$ (here $H^r(G)$ denotes the Sobolev space on the bounded domain $G$), hence in $L_2(G)$ when $\underline s>d/4$. We also present a finite-element sampling method for the integral model, derive error estimates, and provide numerical experiments in one dimension that illustrate the impact of spatially varying smoothness on samples covariances. Computational aspects and directions for scalable implementations are discussed.

</details>


### [86] [Discrete reliability for high-order Crouzeix--Raviart finite elements](https://arxiv.org/abs/2602.16588)
*Nis-Erik Bohne,Stefan A. Sauter*

Main category: math.NA

TL;DR: 本文研究了任意奇数次Crouzeix-Raviart有限元（CR_k FEM）在二维Poisson模型问题中的自适应数值解，基于‘自适应公理’框架，提出了残差型后验误差估计器，并证明了离散可靠性（Axiom 3），推广了低阶CR_1方法的已有结果。文中还引入了新的局部拟插值算子以支持理论证明，并通过数值实验验证了各奇数次k下的最优收敛率。


<details>
  <summary>Details</summary>
Motivation: 为了将自适应有限元方法的理论框架扩展到高阶Crouzeix-Raviart元，特别是针对任意奇数次k≥1的情形，弥补现有研究主要集中在最低阶（k=1）的不足。

Method: 采用‘自适应公理’理论框架，构造适用于CR_k FEM的后验误差估计器，重点证明离散可靠性；引入并分析新的局部拟插值算子以支持理论推导。

Result: 成功证明了Axiom 3（离散可靠性），建立了高阶CR_k FEM的最优收敛性理论；数值实验表明，对于多个低阶和高阶奇数k值，自适应算法均达到最优收敛率。

Conclusion: 本文将自适应有限元的最优性理论推广至任意奇数次Crouzeix-Raviart元，所提出的拟插值算子和误差分析方法为高阶非协调元的自适应分析提供了新工具，数值结果验证了理论预测。

Abstract: In this paper, the adaptive numerical solution of a 2D Poisson model problem by Crouzeix-Raviart elements ($\operatorname*{CR}_{k}$ $\operatorname*{FEM}$) of arbitrary odd degree $k\geq1$ is investigated. The analysis is based on an established, abstract theoretical framework: the \textit{axioms of adaptivity} imply optimal convergence rates for the adaptive algorithm induced by a residual-type a posteriori error estimator. Here, we introduce the error estimator for the $\operatorname*{CR}_{k}$ $\operatorname*{FEM}$ discretization and our main theoretical result is the proof ot Axiom 3: \textit{discrete reliability}. This generalizes results for adaptive lowest order $\operatorname*{CR}_{1}$ $\operatorname*{FEM}$ in the literature. For this analysis, we introduce and analyze new local quasi-interpolation operators for $\operatorname*{CR}_{k}$ $\operatorname*{FEM}$ which are key for our proof of discrete reliability. We present the results of numerical experiments for the adaptive version of $\operatorname*{CR}_{k}$ $\operatorname*{FEM}$ for some low and higher (odd) degrees $k\geq1$ which illustrate the optimal convergence rates for all considered values of $k$.

</details>


### [87] [Fast Ewald Summation using Prolate Spheroidal Wave Functions](https://arxiv.org/abs/2602.16591)
*Erik Boström,Anna-Karin Tornberg,Ludvig af Klinteberg*

Main category: math.NA

TL;DR: 提出基于第一类扁球面波函数（PSWF）的快速Ewald求和方法，通过优化实空间和傅里叶空间的集中性，显著减少傅里叶模式和窗口支持，实现比高斯和B样条方法更高的计算效率与精度。


<details>
  <summary>Details</summary>
Motivation: 传统Ewald求和方法在分子动力学模拟中依赖于分裂方式和窗函数选择，影响精度与计算成本；为提升效率与误差控制，需寻找在实空间和傅里叶空间均具有最优集中性的函数作为基础。

Method: 利用第一类扁球面波函数（PSWF）构造Ewald分裂中的磨光函数（mollifier）和插值中的窗函数，并推导傅里叶截断与混叠误差的闭式近似表达式，给出满足预设误差容限的显式参数选择方案。

Result: 理论分析提供了严格的误差估计，数值实验表明PSWF方法在相同精度下所需傅里叶模数和窗函数支撑更小，优于现有基于高斯和B样条的方法。

Conclusion: PSWF-based Ewald求和是一种更优的库仑相互作用计算方法，在保证精度的同时显著降低计算开销，适用于粒子模拟中的高效计算。

Abstract: Fast Ewald summation efficiently evaluates Coulomb interactions and is widely used in molecular dynamics simulations. It is based on a split into a short-range and a long-range part, where evaluation of the latter is accelerated using the fast Fourier transform (FFT). The accuracy and computational cost depend critically on the mollifier in the Ewald split and the window function used in the spreading and interpolation steps that enable the use of the FFT. The first prolate spheroidal wavefunction (PSWF) has optimal concentration in real and Fourier space simultaneously, and is used when defining both a mollifier and a window function. We provide a complete description of the method and derive rigorous error estimates. In addition, we obtain closed-form approximations of the Fourier truncation and aliasing errors, yielding explicit parameter choices for the achieved error to closely match the prescribed tolerance. Numerical experiments confirm the analysis: PSWF-based Ewald summation achieves a given accuracy with significantly fewer Fourier modes and smaller window supports than Gaussian- and B-spline-based approaches, providing a superior alternative to existing Ewald methods for particle simulations.

</details>


### [88] [Quantum-Inspired Tensor Networks for Approximating PDE Flow Maps](https://arxiv.org/abs/2602.15906)
*Nahid Binandeh Dehaghani,Ban Q. Tran,Rafal Wisniewski,Susan Mengel,A. Pedro Aguiar*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate quantum-inspired tensor networks (QTNs) for approximating flow maps of hydrodynamic partial differential equations (PDEs). Motivated by the effective low-rank structure that emerges after tensorization of discretized transport and diffusion dynamics, we encode PDE states as matrix product states (MPS) and represent the evolution operator as a structured low-rank matrix product operator (MPO) in tensor-train form (e.g., arising from finite-difference discretizations assembled in MPO form). The MPO is applied directly in MPS form, and rank growth is controlled via canonicalization and SVD-based truncation after each step. We provide theoretical context through standard matrix product properties, including exact MPS representability bounds, local optimality of SVD truncation, and a Lipschitz-type multi-step error propagation estimate. Experiments on one- and two-dimensional linear advection-diffusion and nonlinear viscous Burgers equations demonstrate accurate short-horizon prediction, favorable scaling in smooth diffusive regimes, and error growth in nonlinear multi-step predictions.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [89] [Nonparametric Identification and Inference for Counterfactual Distributions with Confounding](https://arxiv.org/abs/2602.15916)
*Jianle Sun,Kun Zhang*

Main category: stat.ME

TL;DR: 本文提出了在存在观测和未观测混杂因素的情况下，联合潜在结果分布的非参数识别与半参数估计方法。通过条件copula和因果表示学习，结合工具变量与三重机器学习，实现了对个体层面效应的有效推断。


<details>
  <summary>Details</summary>
Motivation: 在复杂因果系统中，传统的因果推断方法难以有效处理混杂因素对联合潜在结果分布的影响，尤其是当存在未观测混杂时。本文旨在提供更紧致的识别界和可操作的估计方法，以支持分布层面和反事实推断。

Method: 1) 利用条件copula构建协变量相关的 tighter bounds，并采用多项式边界条件或log-sum-exp平滑近似解决不可导问题；2) 提出基于工具变量的因果表示学习框架，证明潜混杂子空间的非参数可识别性；3) 设计三重机器学习估计器，结合交叉拟合处理表示学习、辅助参数与目标函数；4) 开发基于VAE的实用算法进行混杂表示学习。

Result: 建立了所提估计量的渐近分布，量化了表示学习误差带来的方差膨胀，并给出了半参数效率条件。模拟和实证分析验证了方法在边界收紧、推断有效性及表示学习准确性方面的优势。

Conclusion: 本文通过融合经典半参数理论与现代表示学习，为复杂系统中的分布式因果推断提供了稳健的统计基础，拓展了个体层面因果效应的可推断性。

Abstract: We propose nonparametric identification and semiparametric estimation of joint potential outcome distributions in the presence of confounding. First, in settings with observed confounding, we derive tighter, covariate-informed bounds on the joint distribution by leveraging conditional copulas. To overcome the non-differentiability of bounding min/max operators, we establish the asymptotic properties for both a direct estimator with polynomial margin condition and a smooth approximation with log-sum-exp operator, facilitating valid inference for individual-level effects under the canonical rank-preserving assumption. Second, we tackle the challenge of unmeasured confounding by introducing a causal representation learning framework. By utilizing instrumental variables, we prove the nonparametric identifiability of the latent confounding subspace under injectivity and completeness conditions. We develop a ``triple machine learning" estimator that employs cross-fitting scheme to sequentially handle the learned representation, nuisance parameters, and target functional. We characterize the asymptotic distribution with variance inflation induced by representation learning error, and provide conditions for semiparametric efficiency. We also propose a practical VAE-based algorithm for confounding representation learning. Simulations and real-world analysis validate the effectiveness of proposed methods. By bridging classical semiparametric theory with modern representation learning, this work provides a robust statistical foundation for distributional and counterfactual inference in complex causal systems.

</details>


### [90] [Competing Risk Analysis in Cardiovascular Outcome Trials: A Simulation Comparison of Cox and Fine-Gray Models](https://arxiv.org/abs/2602.16031)
*Tuo Wang,Yu Du*

Main category: stat.ME

TL;DR: 在典型的心血管结局试验中，当竞争事件发生率较低时，Cox模型与Fine-Gray模型的估计结果几乎一致；Cox模型因可解释性强仍适合作为主要分析方法，而Fine-Gray模型不应用作Cox的敏感性分析，因其目标估计量不同。


<details>
  <summary>Details</summary>
Motivation: 心血管结局试验常面临非心血管死亡等竞争风险，影响主要不良心血管事件（MACE）的观察。如何正确处理竞争风险、选择合适的统计模型成为关键问题。现有研究对Cox模型与Fine-Gray模型在不同情境下的表现缺乏系统比较。

Method: 通过使用双变量copula模型的模拟研究，系统地改变竞争事件发生率（每年0.5%-5%）、治疗对竞争事件的影响（减少50%至增加50%）以及相关结构，比较Cox比例风险模型与Fine-Gray子分布风险模型的表现。

Result: 在年竞争事件率约为1%的典型心血管试验中，无论相关性强度或治疗效应方向如何，Cox与Fine-Gray模型得到的风险比估计几乎相同。仅在高竞争事件率且治疗效应方向不一致时出现显著差异，但此时两种方法均无法无偏估计真实的边际风险比。

Conclusion: 在低竞争事件率的典型心血管试验中，Cox模型因其良好的可解释性仍适合作为主要分析方法，不应被竞争风险方法取代；Fine-Gray模型不满足ICH E9(R1)对敏感性分析的要求，不能作为Cox模型的合理补充分析；建议将Aalen-Johansen法估计的累积发生率作为补充以增强透明度；在高竞争风险场景下，可考虑逆概率删失加权、多重插补或包含全因死亡率的复合终点等替代方法。

Abstract: Cardiovascular outcome trials commonly face competing risks when non-CV death prevents observation of major adverse cardiovascular events (MACE). While Cox proportional hazards models treat competing events as independent censoring, Fine-Gray subdistribution hazard models explicitly handle competing risks, targeting different estimands. This simulation study using bivariate copula models systematically varies competing event rates (0.5%-5% annually), treatment effects on competing events (50% reduction to 50% increase), and correlation structures to compare these approaches. At competing event rates typical of CV outcome trials (~1% annually), Cox and Fine-Gray produce nearly identical hazard ratio estimates regardless of correlation strength or treatment effect direction. Substantial divergence occurs only with high competing rates and directionally discordant treatment effects, though neither estimator provides unbiased estimates of true marginal hazard ratios under these conditions. In typical CV trial settings with low competing event rates, Cox models remain appropriate for primary analysis due to superior interpretability. Pre-specified Cox models should not be abandoned for competing risk methods. Importantly, Fine-Gray models do not constitute proper sensitivity analyses to Cox models per ICH E9(R1), as they target different estimands rather than testing assumptions. As supplementary analysis, cumulative incidence using Aalen-Johansen estimator can provide transparency about competing risk impact. Under high competing-risk scenarios, alternative approaches such as inverse probability of censoring weighting, multiple imputation, or inclusion of all-cause mortality in primary endpoints warrant consideration.

</details>


### [91] [Covariate Adjustment for Wilcoxon Two Sample Statistic and Test](https://arxiv.org/abs/2602.16040)
*Zhilan Lou,Jun Shao,Ting Ye,Tuo Wang,Yanyao Yi,Yu Du*

Main category: stat.ME

TL;DR: 本文提出通过对Wilcoxon两样本统计量和Wilcoxon-Mann-Whitney检验进行协变量调整，提升估计效率并扩展其在协变量自适应随机化设计中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了提高Wilcoxon方法在存在协变量情况下的估计效率，并使其适用于协变量自适应随机化设计的情形。

Method: 采用基于校准的协变量调整方法，推导调整后统计量的渐近分布，并量化效率增益。

Result: 建立了调整后Wilcoxon统计量的渐近分布，证明其在多种协变量自适应随机化方案下具有不变性，并给出了保证的效率提升。

Conclusion: 协变量调整不仅提高了效率，还实现了在不同随机化方案下统一推断公式，增强了方法的适用性和稳健性。

Abstract: We apply covariate adjustment to the Wincoxon two sample statistic and Wincoxon-Mann-Whitney test in comparing two treatments. The covariate adjustment through calibration not only improves efficiency in estimation/inference but also widens the application scope of the Wilcoxon two sample statistic and Wincoxon-Mann-Whitney test to situations where covariate-adaptive randomization is used. We motivate how to adjust covariates to reduce variance, establish the asymptotic distribution of adjusted Wincoxon two sample statistic, and provide explicitly the guaranteed efficiency gain. The asymptotic distribution of adjusted Wincoxon two sample statistic is invariant to all commonly used covariate-adaptive randomization schemes so that a unified formula can be used in inference regardless of which covariate-adaptive randomization is applied.

</details>


### [92] [Experimental Assortments for Choice Estimation and Nest Identification](https://arxiv.org/abs/2602.16137)
*Xintong Yu,Will Ma,Michael Zhao*

Main category: stat.ME

TL;DR: 提出了一种结构化的非自适应实验设计，仅需O(log n)个不同的商品组合，用于估计包含n个商品的选择模型，优于随机和其他启发式设计，并在Dream11平台上成功应用，实现了对商品簇的准确识别和预测。


<details>
  <summary>Details</summary>
Motivation: 为了高效估计大规模商品集合下的选择模型，尤其是存在复杂替代关系的情形，需要设计一种数据收集效率高且估计准确的实验方法。

Method: 提出一种仅需O(log n)个不同商品组合的非自适应实验设计，并结合新算法从数据中自动识别Nested Logit模型中的商品簇（nests），无需预先设定。

Result: 该设计在数值实验中显著优于随机和其他启发式设计；在Dream11平台7000万用户数据上验证，能准确识别商品簇，提升样本外预测性能，且结果可解释、易被管理层接受。

Conclusion: 结构化实验设计与数据驱动的簇识别相结合，能够高效、准确地估计Nested Logit等选择模型，适用于具有复杂替代模式的大规模实际场景。

Abstract: What assortments (subsets of items) should be offered, to collect data for estimating a choice model over $n$ total items? We propose a structured, non-adaptive experiment design requiring only $O(\log n)$ distinct assortments, each offered repeatedly, that consistently outperforms randomized and other heuristic designs across an extensive numerical benchmark that estimates multiple different choice models under a variety of (possibly mis-specified) ground truths.
  We then focus on Nested Logit choice models, which cluster items into "nests" of close substitutes. Whereas existing Nested Logit estimation procedures assume the nests to be known and fixed, we present a new algorithm to identify nests based on collected data, which when used in conjunction with our experiment design, guarantees correct identification of nests under any Nested Logit ground truth.
  Our experiment design was deployed to collect data from over 70 million users at Dream11, an Indian fantasy sports platform that offers different types of betting contests, with rich substitution patterns between them. We identify nests based on the collected data, which lead to better out-of-sample choice prediction than ex-ante clustering from contest features. Our identified nests are ex-post justifiable to Dream11 management.

</details>


### [93] [Introducing the b-value: combining unbiased and biased estimators from a sensitivity analysis perspective](https://arxiv.org/abs/2602.16310)
*Zhexiao Lin,Peter J. Bickel,Peng Ding*

Main category: stat.ME

TL;DR: 本文研究了在存在未知偏差的情况下，如何结合无偏但精度较低的估计量与有偏但精度较高的估计量进行有效统计推断的问题。提出了一种基于敏感性分析的方法，通过构建随偏差程度变化的置信区间序列，并引入“b值”概念，用于判断结论何时因偏差而改变。推荐使用软阈值估计量的b值及其置信区间，因其对未知偏差更具鲁棒性且最坏情况下的风险最低。


<details>
  <summary>Details</summary>
Motivation: 在实证研究中，当存在多个估计量时，如何在兼顾精度与偏差的前提下进行有效推断仍是一个未充分研究的问题，特别是当偏差未知时，传统方法可能误导结论。因此需要一种能够量化偏差影响并保持推断有效性的新方法。

Method: 从敏感性分析视角出发，构建一系列依赖于最大相对偏差程度的置信区间；引入b值——即导致合并估计不再显著的关键偏差阈值；并对三种典型组合估计量（精度加权、预检验、软阈值）分别推导其置信区间序列与偏差转折点。

Result: 得到了三种组合估计量对应的置信区间序列和偏差阈值表达式；发现软阈值估计量在应对未知偏差时表现最优，其b值和对应置信区间具有更强的鲁棒性，并在最坏情况下风险最低。

Conclusion: 推荐报告基于软阈值估计量的b值及其置信区间，作为在存在未知偏差时进行稳健统计推断的标准做法，有助于提高研究结论的可信度与透明度。

Abstract: In empirical research, when we have multiple estimators for the same parameter of interest, a central question arises: how do we combine unbiased but less precise estimators with biased but more precise ones to improve the inference? Under this setting, the point estimation problem has attracted considerable attention. In this paper, we focus on a less studied inference question: how can we conduct valid statistical inference in such settings with unknown bias? We propose a strategy to combine unbiased and biased estimators from a sensitivity analysis perspective. We derive a sequence of confidence intervals indexed by the magnitude of the bias, which enable researchers to assess how conclusions vary with the bias levels. Importantly, we introduce the notion of the b-value, a critical value of the unknown maximum relative bias at which combining estimators does not yield a significant result. We apply this strategy to three canonical combined estimators: the precision-weighted estimator, the pretest estimator, and the soft-thresholding estimator. For each estimator, we characterize the sequence of confidence intervals and determine the bias threshold at which the conclusion changes. Based on the theory, we recommend reporting the b-value based on the soft-thresholding estimator and its associated confidence intervals, which are robust to unknown bias and achieve the lowest worst-case risk among the alternatives.

</details>


### [94] [Focused Relative Risk Information Criterion for Variable Selection in Linear Regression](https://arxiv.org/abs/2602.16463)
*Nils Lid Hjort*

Main category: stat.ME

TL;DR: 本文提出了一种新的变量选择方法，通过聚焦相对风险信息准则（FRIC）和置信分布理论，评估线性回归模型中不同子模型的相对均方误差风险，实现了对变量选择的精确判断，并将其扩展到多焦点参数情形，同时与Mallows准则建立了联系。


<details>
  <summary>Details</summary>
Motivation: 在回归分析中，如何在众多候选模型中选择最优子模型以准确估计回归均值是一个关键问题。传统的变量选择方法可能无法充分反映数据对各个子模型的支持程度，因此需要一种更精确、更具针对性的方法来评估模型风险。

Method: 利用置信分布理论，推导出各子模型相对于全模型的相对均方误差风险的精确表达式，并构建聚焦相对风险信息准则（FRIC）及其可视化工具（如FRIC图和置信图），进一步扩展至多个焦点参数情形，提出平均FRIC（AFRIC）准则。

Result: 提出了FRIC和AFRIC准则，能够有效平衡模型复杂度与拟合优度；特别地，当所有协变量同等重要时，导出了一个新的整体变量选择标准，并揭示了其与Mallows准则之间的联系，提出了相应的改进版本。

Conclusion: 该方法为线性回归中的变量选择提供了更加精细和灵活的框架，具有良好的理论基础和实际应用价值，尤其适用于需要关注特定预测目标的情形。

Abstract: This paper motivates and develops a novel and focused approach to variable selection in linear regression models. For estimating the regression mean $μ=\E\,(Y\midd x_0)$, for the covariate vector of a given individual, there is a list of competing estimators, say $\hattμ_S$ for each submodel $S$. Exact expressions are found for the relative mean squared error risks, when compared to the widest model available, say $\mse_S/\mse_\wide$. The theory of confidence distributions is used for accurate assessments of these relative risks. This leads to certain Focused Relative Risk Information Criterion scores, and associated FRIC plots and FRIC tables, as well as to Confidence plots to exhibit the confidence the data give in the submodels. The machinery is extended to handle many focus parameters at the same time, with appropriate averaged FRIC scores. The particular case where all available covariate vectors have equal importance yields a new overall criterion for variable selection, balancing complexity and fit in a natural fashion. A connection to the Mallows criterion is demonstrated, leading also to natural modifications of the latter. The FRIC and AFRIC strategies are illustrated for real data.

</details>


### [95] [Factor-Adjusted Multiple Testing for High-Dimensional Individual Mediation Effects](https://arxiv.org/abs/2602.16497)
*Chen Shi,Zhao Chen,Christina Dan Wang*

Main category: stat.ME

TL;DR: 提出了一种新的高维中介分析方法FADMT，可在复杂依赖结构下实现个体中介效应的大规模推断，并有效控制错误发现率。


<details>
  <summary>Details</summary>
Motivation: 传统的去偏推断方法在中介变量存在广泛依赖时会导致错误发现率膨胀，难以准确识别个体中介变量，因此需要一种能处理复杂依赖结构的新方法。

Method: 提出Factor-Adjusted Debiased Mediation Testing (FADMT) 框架，假设中介模型误差具有近似因子结构，提取潜在因子并构建去相关伪中介变量，用于后续推断；理论证明去偏估计量的渐近正态性，并设计多重检验方法以实现错误发现率控制。

Result: FADMT在模拟数据中表现出优越的小样本性能，适用于多种相关结构；在TCGA-BRCA多组学数据和中国沪深港通股票研究中的应用验证了其实际有效性。

Conclusion: FADMT能够有效校正由潜在因子引起的依赖性，提升观测研究中对虚假关联的鲁棒性，是高维中介分析中实现个体效应推断与FDR控制的有效工具。

Abstract: Identifying individual mediators is a central goal of high-dimensional mediation analysis, yet pervasive dependence among mediators can invalidate standard debiased inference and lead to substantial false discovery rate (FDR) inflation. We propose a Factor-Adjusted Debiased Mediation Testing (FADMT) framework that enables large-scale inference for individual mediation effects with FDR control under complex dependence structures. Our approach posits an approximate factor structure on the unobserved errors of the mediator model, extracts common latent factors, and constructs decorrelated pseudo-mediators for the subsequent inferential procedure. We establish the asymptotic normality of the debiased estimator and develop a multiple testing procedure with theoretical FDR control under mild high-dimensional conditions. By adjusting for latent factor induced dependence, FADMT also improves robustness to spurious associations driven by shared latent variation in observational studies. Extensive simulations demonstrate the superior finite-sample performance across a wide range of correlation structures. Applications to TCGA-BRCA multi-omics data and to China's stock connect study further illustrate the practical utility of the proposed method.

</details>


### [96] [Generalised Linear Models Driven by Latent Processes: Asymptotic Theory and Applications](https://arxiv.org/abs/2602.16540)
*Wagner Barreto-Souza,Ngai Hang Chan*

Main category: stat.ME

TL;DR: 提出了一类基于潜过程的广义线性模型（GLM），适用于计数、实值、二元和正连续时间序列，扩展了传统模型的分布假设，允许条件分布属于双参数指数族，并通过乘法方式引入潜过程到条件均值中，提升了模型灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有潜过程回归框架多基于泊松或单参数指数族假设，限制了模型适用范围，尤其在处理正连续数据和估计未知离散参数时存在不足，因此需要更灵活的建模方法。

Method: 将响应变量的条件分布扩展为双参数指数族，潜过程以乘法形式进入条件均值；忽略潜过程影响下使用GLM似然估计参数，并推导正确的信息矩阵以保证统计推断有效性；提出系统的预测与预报方法。

Result: 建立了忽略潜过程时GLM估计量的渐近正态性，给出了正确的信息矩阵；在麻疹感染和古气候冰川纹层数据上的应用显示新模型具有更好的适应性和实用优势。

Conclusion: 所提出的模型显著拓宽了潜过程GLM的应用范围，自然支持伽马响应等情形，可有效估计离散参数，避免了传统链接函数的严格限制，且提供了可验证的统计推断和预测框架。

Abstract: This paper introduces a class of generalised linear models (GLMs) driven by latent processes for modelling count, real-valued, binary, and positive continuous time series. Extending earlier latent-process regression frameworks based on Poisson or one-parameter exponential family assumptions, we allow the conditional distribution of the response to belong to a bi-parameter exponential family, with the latent process entering the conditional mean multiplicatively. This formulation substantially broadens the scope of latent-process GLMs, for instance, it naturally accommodates gamma responses for positive continuous data, enables estimation of an unknown dispersion parameter via method of moments, and avoids restrictive conditions on link functions that arise under existing formulations. We establish the asymptotic normality of the GLM estimators obtained from the GLM likelihood that ignores the latent process, and we derive the correct information matrix for valid inference. In addition, we provide a principled approach to prediction and forecasting in GLMs driven by latent processes, a topic not previously addressed in the literature. We present two real data applications on measles infections in North Rhine-Westphalia (Germany) and paleoclimatic glacial varves, which highlight the practical advantages and enhanced flexibility of the proposed modelling framework.

</details>


### [97] [Synthetic-Powered Multiple Testing with FDR Control](https://arxiv.org/abs/2602.16690)
*Yonghoon Lee,Meshi Bashari,Edgar Dobriban,Yaniv Romano*

Main category: stat.ME

TL;DR: 本文提出了一种名为SynthBH的新型多重检验方法，可在未知合成数据质量的情况下安全利用合成数据，在保证错误发现率（FDR）控制的同时提升检验效能。


<details>
  <summary>Details</summary>
Motivation: 在多重假设检验中，如何有效利用辅助或合成数据以提高检验功效是一个重要问题，尤其是在真实数据有限的情况下。现有方法通常要求合成数据可靠或p值有效，限制了其应用范围。

Method: 提出SynthBH方法，通过整合真实与合成数据构造测试权重，自适应地利用合成数据的质量；在温和的正相关依赖条件（PRDS-type）下，无需假设合成数据生成的p值在原假设下有效，即可实现有限样本、分布无关的FDR控制。

Result: 在表格异常检测、基因组药物-癌症敏感性分析及模拟实验中，SynthBH在合成数据质量高时显著提升功效，而在合成数据质量差时仍能维持FDR控制，表现出良好的鲁棒性和适应性。

Conclusion: SynthBH是一种安全、灵活且高效的多重检验框架，能够充分利用外部合成信息，在广泛的应用场景中实现可靠的FDR控制与更高的统计功效。

Abstract: Multiple hypothesis testing with false discovery rate (FDR) control is a fundamental problem in statistical inference, with broad applications in genomics, drug screening, and outlier detection. In many such settings, researchers may have access not only to real experimental observations but also to auxiliary or synthetic data -- from past, related experiments or generated by generative models -- that can provide additional evidence about the hypotheses of interest. We introduce SynthBH, a synthetic-powered multiple testing procedure that safely leverages such synthetic data. We prove that SynthBH guarantees finite-sample, distribution-free FDR control under a mild PRDS-type positive dependence condition, without requiring the pooled-data p-values to be valid under the null. The proposed method adapts to the (unknown) quality of the synthetic data: it enhances the sample efficiency and may boost the power when synthetic data are of high quality, while controlling the FDR at a user-specified level regardless of their quality. We demonstrate the empirical performance of SynthBH on tabular outlier detection benchmarks and on genomic analyses of drug-cancer sensitivity associations, and further study its properties through controlled experiments on simulated data.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [98] [Recent results on the $Λ\rightarrow p\ell \barν_\ell$ semileptonic decay](https://arxiv.org/abs/2602.16560)
*Simone Bacchio,Andreas Konstantinou*

Main category: hep-lat

TL;DR: 本文通过格点QCD计算了$\Lambda \to p$的矢量和轴矢量形状因子，为半轻子衰变$\Lambda \to p\ell\barν_\ell$提供了理论输入，并用于精确测定跃迁形状因子。利用这些结果，计算了电子和μ子通道的衰变率及其比值，可用于检验轻子味普适性和可能的非标准标量或张量相互作用。此外，该衰变模式为从重子部门提取CKM矩阵元$|V_{us}|$提供了可靠的理论途径，并结合BESIII和LHCb的实验数据给出了$|V_{us}|$的估计值。


<details>
  <summary>Details</summary>
Motivation: 提供精确的理论输入以研究半轻子衰变$\Lambda \to p\ell\barν_\ell$，并支持对轻子味普适性及新物理效应的检验，同时从重子衰变中可靠地提取CKM矩阵元$|V_{us}|$。

Method: 采用具有物理质量的轻夸克、奇异夸克和粲夸克的单个规范系综进行格点QCD计算，确定完整的跃迁形状因子集合，包括第二类贡献。

Result: 精确确定了$\Lambda \to p$的矢量和轴矢量形状因子；计算了电子和μ子衰变通道的衰变率及其比值；结合实验数据给出了$|V_{us}|$的估计值。

Conclusion: $\Lambda \to p\ell\barν_\ell$衰变为检验标准模型和探索新物理提供了高精度的理论工具，且是提取$|V_{us}|$的有效途径。

Abstract: We present a lattice-QCD determination of the $Λ\to p$ vector and axial-vector form factors, providing theoretical input for studies of the semileptonic decay $Λ\to p\ell\barν_\ell$. The calculation is carried out on a single gauge ensemble with physical light, strange, and charm quark masses and delivers a precise determination of the complete set of transition form factors, including second-class contributions.
  Using these form factors, we compute decay rates for both the electronic and muonic channels, as well as their ratio, which offers a sensitive test of lepton-flavor universality and possible non-standard scalar or tensor interactions.
  This decay mode provides a theoretically well-controlled avenue for extracting the CKM matrix element $|V_{us}|$ from the baryon sector.
  Our estimate of $|V_{us}|$ is obtained by combining our recent lattice-QCD results with recent measurements of the relevant branching fraction reported by BESIII and LHCb.

</details>
