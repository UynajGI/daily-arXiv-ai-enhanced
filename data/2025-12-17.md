<div id=toc></div>

# Table of Contents

- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [stat.ME](#stat.ME) [Total: 14]
- [math.ST](#math.ST) [Total: 5]
- [physics.hist-ph](#physics.hist-ph) [Total: 1]
- [math.NA](#math.NA) [Total: 13]
- [hep-lat](#hep-lat) [Total: 2]
- [eess.SY](#eess.SY) [Total: 15]
- [quant-ph](#quant-ph) [Total: 43]
- [nlin.CD](#nlin.CD) [Total: 1]
- [physics.geo-ph](#physics.geo-ph) [Total: 3]
- [physics.ao-ph](#physics.ao-ph) [Total: 2]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 10]
- [cs.CE](#cs.CE) [Total: 3]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 8]
- [cs.SI](#cs.SI) [Total: 2]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [math.OC](#math.OC) [Total: 10]


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [1] [Not all Chess960 positions are equally complex](https://arxiv.org/abs/2512.14319)
*Marc Barthelemy*

Main category: physics.soc-ph

TL;DR: 该论文分析了Chess960的960种起始局面，发现执白方普遍存在先手优势，并提出一种基于信息论的复杂度度量方法 $S(n)$，用于衡量开局阶段决策难度。研究发现不同起始位置在总体复杂性和黑白双方决策负担上差异显著，经典国际象棋起始位置并非最平衡的选择。


<details>
  <summary>Details</summary>
Motivation: 探究Chess960中不同起始位置对战略复杂性和公平性的影响，评估经典国际象棋起始位置是否经过文化演化达到了最优或最平衡状态。

Method: 使用Stockfish引擎评估所有960种起始位置的胜势，定义基于信息熵的度量指标 $S(n)$ 来量化前n步最优走法所需的信息总量，并分解为白方($S_W$)和黑方($S_B$)的贡献，进而计算总复杂度 $S_{\mathrm{tot}}$ 和决策不对称性 $A=S_B-S_W$。

Result: 几乎所有起始位置都显示白方有先手优势（平均胜势+0.30兵）；$S_{\mathrm{tot}}$ 在不同位置间相差三倍，$A$ 的取值范围为-2.5到+1.8比特，表明某些开局更难对白方或黑方而言；标准国际象棋起始位置具有较高的不对称性（91百分位），但总复杂度普通（47百分位）；位置#226最复杂，#198最平衡。

Conclusion: Chess960的起始位置在战略深度和公平性方面高度异质，微小的初始变化可显著影响游戏复杂性；经典国际象棋起始位置虽经长期文化选择，却远非最平衡配置。

Abstract: We analyze strategic complexity across all 960 Chess960 (Fischer Random Chess) starting positions. Stockfish evaluations show a near-universal first-move advantage for White ($\langle E \rangle = +0.30 \pm 0.14$ pawns), indicating that the advantage conferred by moving first is a robust structural feature of the game. To quantify decision difficulty, we introduce an information-based measure $S(n)$ describing the cumulative information required to identify optimal moves over the first $n$ plies. This measure decomposes into contributions from White and Black, $S_W$ and $S_B$, yielding a total opening complexity $S_{\mathrm{tot}} = S_W + S_B$ and a decision asymmetry $A=S_B-S_W$. Across the ensemble, $S_{\mathrm{tot}}$ varies by a factor of three, while $A$ spans from $-2.5$ to $+1.8$ bits, showing that some openings burden White and others Black. The mean $\langle A \rangle = -0.25$ bits indicates a slight tendency for White to face harder opening decisions. Standard chess (position \#518, \texttt{RNBQKBNR}) exhibits above-average asymmetry (91st percentile) but typical overall complexity (47th percentile). The most complex opening is \#226 (\texttt{BNRQKBNR}), whereas \#198 (\texttt{QNBRKBNR})is the most balanced, with both evaluation and asymmetry near zero. These results reveal a highly heterogeneous Chess960 landscape in which small rearrangements of the back-rank pieces can significantly alter strategic depth and competitive fairness. Remarkably, the classical starting position-despite centuries of cultural selection-lies far from the most balanced configuration.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [2] [Parameter Estimation for Partially Observed Stable Continuous-State Branching Processes](https://arxiv.org/abs/2512.13841)
*Eduardo Gutiérrez-Peña,Carlos Octavio Pérez-Mendoza,Alan Riva Palacio,Arno Siri-Jégousse*

Main category: stat.ME

TL;DR: 提出了一种基于次级过程表示的连续状态分支过程参数推断新框架，通过拉普拉斯逆变换实现似然函数的高效数值恢复，并提供了相应的动态模拟方法。


<details>
  <summary>Details</summary>
Motivation: 针对连续状态分支过程（CSBPs）在缺乏闭式转移密度时参数估计困难的问题，需要一种不依赖额外假设的灵活且高效的估计方法。

Method: 利用CSBPs的次级过程表示，将随机动力学转移到关联的次级过程上，通过参数化估计结合拉普拉斯变换逆变换来重构似然函数，并提出基于该结构的离散时间轨迹动态模拟框架。

Result: 实现了对CSBPs参数的有效估计，即使在无闭式解的情况下也能高效计算似然，同时能够生成精确的离散时间路径。

Conclusion: 该方法为CSBPs提供了一个灵活、高效的参数推断与模拟框架，拓展了其在实际问题中的应用潜力。

Abstract: In this article, we present a novel inference framework for estimating the parameters of Continuous-State Branching Processes (CSBPs). We do so by leveraging their subordinator representation. Our method reformulates the estimation problem by shifting the stochastic dynamics to the associated subordinator, enabling a parametric estimation procedure without requiring additional assumptions. This reformulation allows for efficient numerical recovery of the likelihood function via Laplace transform inversion, even in models where closed-form transition densities are unavailable. In addition to offering a flexible approach to parameter estimation, we propose a dynamic simulation framework that generates discrete-time trajectories of CSBPs using the same subordinator-based structure.

</details>


### [3] [Bond strength uncertainty quantification via confidence intervals for nondestructive evaluation of bonded composites](https://arxiv.org/abs/2512.13875)
*Michael C. Stanley,Peter W. Spaeth,James E. Warner,Matthew R. Webster*

Main category: stat.ME

TL;DR: 提出了一种基于优化的非破坏性评估方法，用于计算粘接复合材料强度估计的有限样本置信区间，并通过统计逆模型和刚度回归传播区间，实现了在高噪声和边界参数情况下更优的覆盖性和精度。


<details>
  <summary>Details</summary>
Motivation: 需要对航空航天用粘接复合材料的物理特性（如强度）进行认证，非破坏性评估（NDE）中的不确定性量化（UQ）对于理解风险至关重要，尤其是对粘接强度的估计。

Method: 采用基于优化的方法计算有限样本置信区间，利用扫频超声相位观测数据建立统计逆模型以估计界面刚度置信区间，并通过已知的界面刚度回归关系将该区间传播至粘接强度；同时发展了处理非线性前向模型和未知方差的优化方法，并引入校准机制确保置信覆盖水平。

Result: 在模拟数据上验证了该方法，在不同噪声水平和两种典型参数设置下，相比基线方法在高噪声环境和干扰参数接近约束边界时表现出更高的覆盖概率和更小的置信区间。

Conclusion: 所提出的优化-统计联合方法能有效实现粘接强度估计的不确定性量化，在实际NDE应用中具有更高的可靠性与精度，尤其适用于复杂噪声条件和边界情况。

Abstract: As bonded composite materials are used more frequently for aerospace applications, it is necessary to certify that parts achieve desired levels of certain physical characteristics (e.g., strength) for safety and performance. Nondestructive evaluation (NDE) of adhesively bonded structures enables verification of bond physical characteristics, but uncertainty quantification (UQ) of NDE estimates is crucial for understanding risks, especially for NDE estimates like bond strength. To address the critical need for NDE UQ for adhesive bond strength estimates, we propose an optimization--based approach to computing finite--sample confidence intervals showing the range of bond strengths that could feasibly be produced by the observed data. A statistical inverse model approach is used to compute a confidence interval of specimen interfacial stiffness from swept--frequency ultrasonic phase observations and a method for propagating the interval to bond strength via a known interfacial stiffness regression is proposed. This approach requires innovating the optimization--based confidence interval to handle both a nonlinear forward model and unknown variance and developing a calibration approach to ensure that the final bond strength interval achieves at least the desired coverage level. Using model assumptions in line with current literature, we demonstrate our approach on simulated measurement data using a variety of low to high noise settings under two prototypical parameter settings. Relative to a baseline approach, we show that our method achieves better coverage and smaller intervals in high--noise settings and when a nuisance parameter is near the constraint boundary.

</details>


### [4] [A latent variable model for identifying and characterizing food adulteration](https://arxiv.org/abs/2512.13939)
*Alessandro Casa,Thomas Brendan Murphy,Michael Fop*

Main category: stat.ME

TL;DR: 提出了一种针对食品掺假检测的潜变量模型，能够识别掺假样本、估计掺假程度并定位受影响的光谱区域。


<details>
  <summary>Details</summary>
Motivation: 由于消费者对食品质量和可持续性的关注增加，需要更有效的食品真实性验证方法；现有光谱数据分析面临统计学挑战。

Method: 设计一种专门针对光谱数据特征的潜变量模型，用于检测食品掺假，并估计掺假水平及识别关键光谱区域。

Result: 在合成和真实的蜂蜜中红外光谱数据上验证了该方法，能精确估计掺假程度并准确识别受掺假影响的光谱区域。

Conclusion: 该方法比现有方法更具细粒度，提供了更深入的分析洞察，有助于开发便携快速的食品真实性检测设备。

Abstract: Recently, growing consumer awareness of food quality and sustainability has led to a rising demand for effective food authentication methods. Vibrational spectroscopy techniques have emerged as a promising tool for collecting large volumes of data to detect food adulteration. However, spectroscopic data pose significant challenges from a statistical viewpoint, highlighting the need for more sophisticated modeling strategies. To address these challenges, in this work we propose a latent variable model specifically tailored for food adulterant detection, while accommodating the features of spectral data. Our proposal offers greater granularity with respect to existing approaches, since it does not only identify adulterated samples but also estimates the level of adulteration, and detects the spectral regions most affected by the adulterant. Consequently, the methodology offers deeper insights, and could facilitate the development of portable and faster instruments for efficient data collection in food authenticity studies. The method is applied to both synthetic and real honey mid-infrared spectroscopy data, delivering precise estimates of the adulteration level and accurately identifying which portions of the spectra are most impacted by the adulterant.

</details>


### [5] [Low-rank Covariate Balancing Estimators under Interference](https://arxiv.org/abs/2512.13944)
*Souhardya Sengupta,Kosuke Imai,Georgia Papadogeorgou*

Main category: stat.ME

TL;DR: 本文提出了一种用于处理存在干扰的观察性研究中因果效应估计的通用统计框架，通过引入潜在结果的低秩结构，在无需知晓真实倾向得分的情况下构建稳健的加权估计量。


<details>
  <summary>Details</summary>
Motivation: 在存在单元间干扰的观察性研究中，传统方法难以应对结果对多个处理分配的依赖以及处理分配间的复杂依赖关系，因此需要发展更鲁棒的因果推断方法。

Method: 提出基于潜在结果低秩结构的加权估计方法，该框架包含匿名、近邻和加性干扰等常见假设，并允许灵活设定特定研究的干扰模式；进一步构造无需已知倾向得分的无偏加权估计量，并在已知时提升效率。

Result: 证明在未知倾向得分时不存在一致无偏估计量，但在低秩假设下可构造无需已知倾向得分的无偏加权估计量；新估计量比标准IPW更高效，并具有良好的有限样本与渐近性质；并通过模拟和实证研究验证了方法有效性。

Conclusion: 所提出的低秩结构框架为处理复杂干扰下的因果推断提供了统一且稳健的方法，能够在不依赖精确倾向得分的情况下实现无偏估计，并提升估计效率。

Abstract: A key methodological challenge in observational studies with interference between units is twofold: (1) each unit's outcome may depend on many others' treatments, and (2) treatment assignments may exhibit complex dependencies across units. We develop a general statistical framework for constructing robust causal effect estimators to address these challenges. We first show that, without restricting the patterns of interference, the standard inverse probability weighting (IPW) estimator is the only uniformly unbiased estimator when the propensity score is known. In contrast, no estimator has such a property if the propensity score is unknown. We then introduce a \emph{low-rank structure} of potential outcomes as a broad class of structural assumptions about interference. This framework encompasses common assumptions such as anonymous, nearest-neighbor, and additive interference, while flexibly allowing for more complex study-specific interference assumptions. Under this low-rank assumption, we show how to construct an unbiased weighting estimator for a large class of causal estimands. The proposed weighting estimator does not require knowledge of true propensity scores and is therefore robust to unknown treatment assignment dependencies that often exist in observational studies. If the true propensity score is known, we can obtain an unbiased estimator that is more efficient than the IPW estimator by leveraging a low-rank structure. We establish the finite sample and asymptotic properties of the proposed weighting estimator, develop a data-driven procedure to select among candidate low-rank structures, and validate our approach through simulation and empirical studies.

</details>


### [6] [Joint Models with Multiple Markers and Multiple Time-to-event Outcomes Using Variational Approximations](https://arxiv.org/abs/2512.13962)
*Benjamin Christoffersen,Keith Humphreys,Alessandro Gasparini,Birzhan Akynkozhayev,Hedvig Kjellström,Mark Clements*

Main category: stat.ME

TL;DR: 提出了一种基于高斯变分近似的全似然联合模型方法，可处理多标记、多生存结局、延迟进入等问题，并具有良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有联合模型在处理多标记、多生存结局（包括终末事件、竞争事件和复发事件）、延迟进入及可扩展性方面存在不足。

Method: 基于高斯变分近似提出一种全似然联合建模方法，并开发开源实现，支持纵向标记和生存结局的灵活建模。

Result: 模拟结果显示该方法的变分近似下界接近全似然，且计算快速、可扩展；实际应用中用于建模乳腺组织密度与首次乳腺癌诊断时间的关系。

Conclusion: 变分近似为扩展当前联合模型提供了有前景的方法。

Abstract: Joint models are well suited to modelling linked data from laboratories and health registers. However, there are few examples of joint models that allow for (a) multiple markers, (b) multiple survival outcomes (including terminal events, competing events, and recurrent events), (c) delayed entry and (d) scalability. We propose a full likelihood approach for joint models based on a Gaussian variational approximation to satisfy criteria (a)-(d). We provide an open-source implementation for this approach, allowing for flexible sets of models for the longitudinal markers and survival outcomes. Through simulations, we find that the lower bound for the variational approximation is close to the full likelihood. We also find that our approach and implementation are fast and scalable. We provide an application with a joint model for longitudinal measurements of dense and fatty breast tissue and time to first breast cancer diagnosis. The use of variational approximations provides a promising approach for extending current joint models.

</details>


### [7] [Bayesian Global-Local Regularization](https://arxiv.org/abs/2512.13992)
*Jyotishka Datta,Nick Polson,Vadim Sokolov*

Main category: stat.ME

TL;DR: 提出了一种统一的全局-局部正则化框架，通过在序约束下利用边缘似然估计局部正则化强度，实现了高维稀疏模型下的近最小最大风险，连接了经典方法与贝叶斯分层建模。


<details>
  <summary>Details</summary>
Motivation: 旨在弥合传统正则化方法（如岭回归、非负garotte）与现代贝叶斯分层模型之间的差距，提供一种原理性更强的自适应收缩方法，适用于高维统计推断。

Method: 通过在序约束下使用边缘似然估计局部正则化参数，推广了Stein的正部估计量，提出了各向同性经验贝叶斯估计量，并结合形状约束估计与自由度调整进行建模。

Result: 该估计量在稀疏有序模型类上可达到近最小最大风险（至多对数因子），并在正交多项式回归中验证了方法的灵活性和有效性。

Conclusion: 所提出的框架统一了多种经典与现代正则化思想，为高维自适应收缩提供了理论支持和实用工具，深化了对经验贝叶斯与形状约束之间关系的理解。

Abstract: We propose a unified framework for global-local regularization that bridges the gap between classical techniques -- such as ridge regression and the nonnegative garotte -- and modern Bayesian hierarchical modeling. By estimating local regularization strengths via marginal likelihood under order constraints, our approach generalizes Stein's positive-part estimator and provides a principled mechanism for adaptive shrinkage in high-dimensional settings. We establish that this isotonic empirical Bayes estimator achieves near-minimax risk (up to logarithmic factors) over sparse ordered model classes, constituting a significant advance in high-dimensional statistical inference. Applications to orthogonal polynomial regression demonstrate the methodology's flexibility, while our theoretical results clarify the connections between empirical Bayes, shape-constrained estimation, and degrees-of-freedom adjustments.

</details>


### [8] [Most Powerful Test with Exact Family-Wise Error Rate Control: Necessary Conditions and a Path to Fast Computing](https://arxiv.org/abs/2512.14131)
*Prasanjit Dubey,Xiaoming Huo*

Main category: stat.ME

TL;DR: 本文提出了一种新的坐标下降算法，用于求解在强族系误差（FWER）控制下多重假设检验中最具统计功效的检验问题，填补了对偶优化问题缺乏有效构造方法的空白，并证明了算法的线性收敛性。


<details>
  <summary>Details</summary>
Motivation: 在多重假设检验中，如何在严格控制家族-wise误差率（FWER）的同时最大化检验功效是一个核心难题。现有方法虽建立了原问题与对偶问题之间的强对偶关系，但缺乏有效的构造性算法来求解对偶问题，导致计算上存在显著瓶颈。

Method: 通过推导对偶优化问题的新颖且必要的最优性条件，提出一种高效的坐标式算法来计算对偶最优解，并利用强对偶性获得原始问题的最优检验策略。同时证明该算法具有线性收敛性。

Result: 所提算法能够高效求解最具统计功效的FWER控制检验方法，计算复杂度与目标误差倒数的对数成正比；模拟研究表明其在统计功效上优于现有方法，并在临床和金融数据中成功识别出新的显著结果。

Conclusion: 本文首次提出了一个快速且计算高效的算法来构造在FWER控制下最具功效的多重假设检验方法，解决了长期存在的计算难题，具有重要的理论意义和实际应用价值。

Abstract: Identifying the most powerful test in multiple hypothesis testing under strong family-wise error rate (FWER) control is a fundamental problem in statistical methodology. State-of-the-art approaches formulate this as a constrained optimisation problem, for which a dual problem with strong duality has been established in a general sense. However, a constructive method for solving the dual problem is lacking, leaving a significant computational gap. This paper fills this gap by deriving novel, necessary optimality conditions for the dual optimisation. We show that these conditions motivate an efficient coordinate-wise algorithm for computing the optimal dual solution, which, in turn, provides the most powerful test for the primal problem. We prove the linear convergence of our algorithm, i.e., the computational complexity of our proposed algorithm is proportional to the logarithm of the reciprocal of the target error. To the best of our knowledge, this is the first time such a fast and computationally efficient algorithm has been proposed for finding the most powerful test with family-wise error rate control. The method's superior power is demonstrated through simulation studies, and its practical utility is shown by identifying new, significant findings in both clinical and financial data applications.

</details>


### [9] [Signature-Informed Selection Detection: A Novel Method for Multi-Locus Temporal Population Genetic Model with Recombination](https://arxiv.org/abs/2512.14353)
*Ritabrata Dutta,Yuehao Xu,Sherman Khoo,Francesca Basini,Andreas Futschik*

Main category: stat.ME

TL;DR: 提出了一种基于签名核评分规则的广义贝叶斯框架，用于多基因座时间序列群体遗传数据中选择系数的推断，并通过模拟和实际数据验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在多基因座连锁选择情况下，传统方法难以准确推断选择系数，因此需要一种适用于高维时间序列数据的新方法。

Method: 构建了一个广义贝叶斯框架，使用基于路径积分（签名）的核评分规则处理等位基因频率时间轨迹数据，并通过模拟估计得分，结合伪边缘MCMC算法从评分后验分布中采样。

Result: 在双基因座和三基因座的Wright-Fisher模型下，该方法优于现有基准方法；同时适用于负频率依赖选择模型及单/双基因座的实际数据（酵母和果蝇E&R实验）。

Conclusion: 所提出的签名核评分方法能有效实现多基因座选择系数的联合推断，具有良好的推断性能和实际应用潜力。

Abstract: In population genetics, there is often interest in inferring selection coefficients. This task becomes more challenging if multiple linked selected loci are considered simultaneously. For such a situation, we propose a novel generalized Bayesian framework where we compute a scoring rule posterior for the selection coefficients in multi-locus temporal population genetics models. As we consider trajectories of allele frequencies over time as our data, we choose to use a signature kernel scoring rule - a kernel scoring rule defined for high-dimensional time-series data using iterated path integrals of a path (called signatures). We can compute an unbiased estimate of the signature kernel score using model simulations. This enables us to sample asymptotically from the signature kernel scoring rule posterior of the selection coefficients using pseudo-marginal MCMC-type algorithms. Through a simulation study, we were able to show the inferential efficacy of our method compared to existing benchmark methods for two and three selected locus scenarios under the standard Wright-Fisher model with recombination and selection. We also consider a negative frequency-dependent selection model for one and two locus scenarios, and also joint inference of selection coefficients and initial haplotype frequencies under the standard Wright-Fisher model. Finally, we illustrate the application of our inferential method for two real-life dataset. More specifically, we consider a data set on Yeast, as well as data from an Evolve and Resequence (E\&R) experiment on {\em Drosophila simulans}.

</details>


### [10] [On the E(s^2)-optimality of two-level supersaturated designs constructed using Wu's method of partially aliased interactions on certain two-level orthogonal arrays](https://arxiv.org/abs/2512.14378)
*E. Androulakis,K. Chatterjee,H. Evangelaras*

Main category: stat.ME

TL;DR: 本文扩展了Wu的方法，证明了当起始设计为具有n次运行和n-1、n-2或n-3列的任意正交阵列时，所构造的超饱和设计在主效应和两列交互作用与两列交互作用部分混杂的情况下是E(s²)最优的。


<details>
  <summary>Details</summary>
Motivation: 为了扩展Wu方法的适用范围，使其不仅限于Hadamard设计作为起始设计，而是能够应用于更广泛的正交阵列，并保持生成的超饱和设计的E(s²)最优性。

Method: 通过使用具有n次运行和n-1、n-2或n-3列的任意正交阵列作为起始设计，并补充部分混杂的两列交互作用来构建超饱和设计，然后分析这些设计的E(s²)值以证明其最优性。

Result: 证明了当起始设计满足特定条件时，采用Wu方法构建的超饱和设计是E(s²)-最优的。

Conclusion: 该研究成功地将Wu方法的应用范围从仅限于Hadamard设计扩展到了更一般的正交阵列，同时保持了生成设计的E(s²)最优性质。

Abstract: Wu [10] proposed a method for constructing two-level supersaturated designs by using a Hadamard design with n runs and n-1 columns as a staring design and by supplementing it with two-column interactions, as long as they are partially aliased. Bulutoglu and Cheng [2] proved that this method results in E(s^2)-optimal supersaturated designs when certain interaction columns are selected. In this paper, we extend these results and prove E(s^2)-optimality for supersaturated designs that are constructed using Wu's method when the starting design is any orthogonal array with n runs and n-1, n-2 or n-3 columns, as long as its main effects and two-column interactions are partially aliased with two-column interactions.

</details>


### [11] [Trunc-Opt vine building algorithms](https://arxiv.org/abs/2512.14399)
*Dániel Pfeifer,Edith Alice Kovács*

Main category: stat.ME

TL;DR: 本文提出了一种新的截断藤结构构建方法，通过引入“截断藤权重”评分来更好地拟合数据，并利用条件独立性提升建模效率，在实际数据上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于藤结构模型参数空间高维，截断藤被提出以降低复杂度，但已有算法未充分利用条件独立性，因此需要更高效的构建方法。

Method: 基于截断后首棵树决定整个截断藤的观察，提出新的评分标准“截断藤权重”，并设计利用条件独立性的新算法来构建和编码截断藤结构。

Result: 新方法在真实数据集上的实验表明其性能优于R语言中已有的主流方法。

Conclusion: 所提出的基于条件独立性和新评分函数的截断藤构建方法在准确性和效率上均优于传统方法，为多变量依赖建模提供了更优工具。

Abstract: Vine copula models have become highly popular and practical tools for modelling multivariate probability distributions due to their flexibility in modelling different kinds of dependences between the random variables involved. However, their flexibility comes with the drawback of a high-dimensional parameter space. To tackle this problem, truncated vine copulas were introduced by Kurowicka (2010) (Gaussian case) and Brechmann and Czado (2013) (general case). Truncated vine copulas contain conditionally independent pair copulas after the truncation level. So far, in the general case, truncated vine constructing algorithms started from the lowest tree in order to encode the largest dependences in the lower trees. The novelty of this paper starts from the observation that a truncated vine is determined by the first tree after the truncation level (see Kovács and Szántai (2017)). This paper introduces a new score for fitting truncated vines to given data, called the Weight of the truncated vine. Then we propose a completely new methodology for constructing truncated vines. We prove theorems which motivate this new approach. While earlier algorithms did not use conditional independences, we give algorithms for constructing and encoding truncated vines which do exploit them. Finally, we illustrate the algorithms on real datasets and compare the results with well-known methods included in R packages. Our method generally compare favorably to previously known methods.

</details>


### [12] [Univariate-Guided Interaction Modeling](https://arxiv.org/abs/2512.14413)
*Aymen Echarghaoui,Robert Tibshirani*

Main category: stat.ME

TL;DR: 提出了一种基于单变量相互作用的稀疏回归方法，通过扩展UniLasso框架设计了uniPairs和uniPairs-2stage算法，在模型稀疏性和交互可解释性上优于现有方法，并在适当条件下证明了支持恢复性质。


<details>
  <summary>Details</summary>
Motivation: 为了构建更稀疏且具有更好可解释交互项的回归模型，现有方法在高维数据中常产生过多交互项，缺乏可解释性。

Method: 推广UniLasso方法，引入“单变量（边际）相互作用”概念，提出uniPairs和uniPairs-2stage两种算法，利用边际信息筛选重要主效应和交互项。

Result: 在模拟和真实数据上，所提方法相比Glinternet和Sprinter能生成更稀疏、更具可解释性的模型，并在合适条件下实现了交互结构的支持恢复。

Conclusion: 所提出的基于边际相互作用的稀疏回归框架有效提升了模型的稀疏性和可解释性，具备理论保证，适用于高维交互回归问题。

Abstract: We propose a procedure for sparse regression with pairwise interactions, by generalizing the Univariate Guided Sparse Regression (UniLasso) methodology. A central contribution is our introduction of a concept of univariate (or marginal) interactions. Using this concept, we propose two algorithms -- uniPairs and uniPairs-2stage -- , and evaluate their performance against established methods, including Glinternet and Sprinter. We show that our framework yields sparser models with more interpretable interactions. We also prove support recovery results for our proposal under suitable conditions.

</details>


### [13] [Causal Secondary Analysis of Linked Data in the Presence of Mismatch Error](https://arxiv.org/abs/2512.14492)
*Martin Slawski*

Main category: stat.ME

TL;DR: 本文研究了在数据链接存在不确定性的情况下，如何在因果推断框架中估计平均处理效应，并提出了一种基于估计方程和EM算法的方法来减少因链接错误导致的偏差。


<details>
  <summary>Details</summary>
Motivation: 由于观测数据日益增多且需要整合多源信息，而记录链接常因缺乏唯一标识符而产生错误，尤其在二次分析中分析者对链接质量了解有限，因此需解决链接不确定性对因果推断的影响。

Method: 将未知的匹配状态视为缺失数据，采用基于两组件混合模型的期望最大化（EM）算法进行估计，并利用估计方程方法进行参数推断。

Result: 模拟研究和案例研究表明，所提方法能有效校正链接误差带来的偏倚，且适用于渐近推断。

Conclusion: 在存在链接不确定性的场景下，所提出的估计方法能够显著提高平均处理效应估计的准确性，优于忽略链接误差的朴素分析方法。

Abstract: The increased prevalence of observational data and the need to integrate information from multiple sources are critical challenges in contemporary data analysis. Record linkage is a widely used tool for combining datasets in the absence of unique identifiers. The presence of linkage errors such as mismatched records, however, often hampers the analysis of data sets obtained in this way. This issue is more difficult to address in secondary analysis settings, where linkage and subsequent analysis are performed separately, and analysts have limited information about linkage quality. In this paper, we investigate the estimation of average treatment effects in the conventional potential outcome-based causal inference framework under linkage uncertainty. To mitigate the bias that would be incurred with naive analyses, we propose an approach based on estimating equations that treats the unknown match status indicators as missing data. Leveraging a variant of the Expectation-Maximization algorithm, these indicators are imputed based on a corresponding two-component mixture model. The approach is amenable to asymptotic inference. Simulation studies and a case study highlight the importance of accounting for linkage uncertainty and demonstrate the effectiveness of the proposed approach.

</details>


### [14] [A flexible class of latent variable models for the analysis of antibody response data](https://arxiv.org/abs/2512.14504)
*Emanuele Giorgi,Jonas Wallin*

Main category: stat.ME

TL;DR: 提出一种基于潜变量的连续免疫状态建模框架，克服传统血清学数据二分类模型的局限性，提升对年龄相关抗体分布变化的捕捉能力，并适用于多种模型形式及跨年龄联合分析。


<details>
  <summary>Details</summary>
Motivation: 挑战传统将个体划分为血清阴性/阳性两类的假设，旨在更真实地反映免疫状态的连续性，充分利用定量抗体测量数据的信息。

Method: 构建一个潜变量建模框架，将个体免疫状态表示为从弱到强的连续潜变量，并整合机制模型与回归模型，兼容有限混合模型作为特例。

Result: 在疟疾血清学数据中验证该模型能更好描述抗体分布随年龄的变化，支持跨全年龄段的联合分析，并可反映传播模式变迁。

Conclusion: 该连续潜变量建模框架更具灵活性和信息保留性，可推广至其他组学（omics）应用领域。

Abstract: Existing approaches to modelling antibody concentration data are mostly based on finite mixture models that rely on the assumption that individuals can be divided into two distinct groups: seronegative and seropositive. Here, we challenge this dichotomous modelling assumption and propose a latent variable modelling framework in which the immune status of each individual is represented along a continuum of latent seroreactivity, ranging from minimal to strong immune activation. This formulation provides greater flexibility in capturing age-related changes in antibody distributions while preserving the full information content of quantitative measurements. We show that the proposed class of models can accommodate a great variety of model formulations, both mechanistic and regression-based, and also includes finite mixture models as a special case. We demonstrate the advantages of this approach using malaria serology data and its ability to develop joint analyses across all ages that account for changes in transmission patterns. We conclude by outlining extensions of the proposed modelling framework and its relevance to other omics applications.

</details>


### [15] [Asymptotic Inference for Rank Correlations](https://arxiv.org/abs/2512.14609)
*Marc-Oliver Pohle,Jan-Lukas Wermuth,Christian H. Weiß*

Main category: stat.ME

TL;DR: 本文系统研究了Kendall's tau、Spearman's rho等秩相关系数在独立同分布和时间序列数据下的渐近推断问题，提出了适用于离散变量和时间序列的一致性方差估计方法，建立了置信区间和检验，并通过模拟和案例验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有对秩相关系数的渐近推断方法在离散变量和时间序列情形下尚不完善，缺乏有效的方差估计和置信区间构造方法，限制了实际应用。

Method: 基于U-统计量的渐近理论，推导了多种秩相关系数（如Kendall's tau、Spearman's rho、Goodman-Kruskal's gamma等）在iid和时间序列数据下的渐近分布，并提出了一致性方差估计方法。

Result: 得到了秩相关系数在更广泛条件下的渐近分布结果，提出了可计算的方差估计量，实现了置信区间构建和独立性检验，修正了传统检验方法，并在模拟和实际案例中验证了有限样本下的良好表现。

Conclusion: 本文完善了秩相关系数的渐近推断理论，扩展了经典结果至离散变量和时间序列场景，提供了实用的统计推断工具，提升了实际数据分析的准确性。

Abstract: Kendall's tau and Spearman's rho are widely used tools for measuring dependence. Surprisingly, when it comes to asymptotic inference for these rank correlations, some fundamental results and methods have not yet been developed, in particular for discrete random variables and in the time series case, and concerning variance estimation in general. Consequently, asymptotic confidence intervals are not available. We provide a comprehensive treatment of asymptotic inference for classical rank correlations, including Kendall's tau, Spearman's rho, Goodman-Kruskal's gamma, Kendall's tau-b, and grade correlation. We derive asymptotic distributions for both iid and time series data, resorting to asymptotic results for U-statistics, and introduce consistent variance estimators. This enables the construction of confidence intervals and tests, generalizes classical results for continuous random variables and leads to corrected versions of widely used tests of independence. We analyze the finite-sample performance of our variance estimators, confidence intervals, and tests in simulations and illustrate their use in case studies.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [16] [Codifference as a measure of dispersion and dependence for mixture models](https://arxiv.org/abs/2512.13928)
*Jakub Ślęzak*

Main category: math.ST

TL;DR: 本文探讨了codifference作为一种依赖性度量在重尾分布和其他非高斯分布中的应用，提出了其自然定义域和三种变体，并表明其能捕捉协方差无法检测的非线性记忆特性。


<details>
  <summary>Details</summary>
Motivation: Codifference常用于稳定向量和过程的依赖性度量，但作者认为它也可用于其他重尾及非高斯分布，因此希望在尽可能少的模型假设下深入分析其性质与应用。

Method: 通过使用变量尺度混合分布这一广泛分布类别，分析codifference的特性，提出其自然定义域及三种自然变体，并推导其估计量的渐近分布。

Result: Codifference可被解释为衡量分布主体特征的指标，对尾部信息的敏感度远低于协方差；同时能够检测协方差无法识别的非线性记忆结构；并获得了其估计量的渐近分布。

Conclusion: Codifference是一种比协方差更具普适性和洞察力的依赖性度量工具，尤其适用于重尾和非高斯场景，能揭示传统方法无法捕捉的统计特性。

Abstract: Codifference is a commonly used measure of dependence for stable vectors and processes for which covariance is infinite. However, we argue that it can also be used for other heavy-tail distributions and it provides useful information for other non-Gaussian distributions as well, no matter the tails. Motivated by this, we analyse codifference using as little assumptions as possible about the studied model. It leads us to propose its natural domain and three natural variants of it. Using the wide class of variable scale mixture distributions we argue that the codifference can be interpreted as the measure of bulk properties which ignores the tails much more than the covariance. It can also detect forms of non-linear memory which covariance cannot. Finally, we show the asymptotic distribution of its estimator.

</details>


### [17] [Extreme Mass Distributions For K-Increasing Quasi-Copulas](https://arxiv.org/abs/2512.14062)
*Matjaž Omladič,Martin Vuk,Aljaž Zalar*

Main category: math.ST

TL;DR: 本文研究了多变量拟相依函数中最大体积问题，通过简化原始和对偶线性规划，得出了精确的最大负质量和正质量及其对应的极值盒子。


<details>
  <summary>Details</summary>
Motivation: 尽管拟相依函数缺乏概率解释，但其在依赖性建模中的重要性日益增加。本文旨在解决此前文献中提出的关于多变量拟相依函数质量分布极值问题后的进一步挑战——即各子类中的最大体积问题。

Method: 通过构建并求解适当简化的原始和对偶线性规划模型，分析具有k-递增性质的d元拟相依函数的结构特性，从而确定其质量分布的极端情况。

Result: 成功推导出每个子类中最大负质量和正质量的精确值，并识别出对应的极值盒子，解决了Open Problem 5后续的关键优化问题。

Conclusion: 该研究填补了从拟相依函数到相依函数路径上的关键空白，为高维依赖结构的建模提供了理论支持，并推动了对k-递增性质的理解。

Abstract: The rating of quasi-copula problems in the dependence modeling community has recently risen in spite of the lack of probability interpretation of quasi-copulas. The trendsetting paper J.J. Arias-Garcia, R. Mesiar, and B. De Baets, The unwalked path between quasi-copulas and copulas: Stepping stones in higher dimensions, Internat. J. of Approx. Reasoning, 80 (2017) 89--99, proposes the k-increasing property for some k {\le} d as a property of d-variate quasi-copulas that would shed some light on what is in-between. This hierarchy of classes extends the bivariate notion of supermodularity property. The same authors propose a number of open problems in the continuation of this paper (Fuzzy Sets and Systems 393 (2020), 1--28). Their Open problem 5 asks for the extreme values of the mass distributions associated with multivariate quasi-copulas and was recently solved by the authors of this paper (Fuzzy Sets and Systems 527 (2026) 109698). The main goal of the present paper is to solve the maximal-volume problem (in absolute value) within each of the previously mentioned subclasses. By formulating and solving suitably simplified primal and dual linear programs, we derive the exact maximal negative and positive masses together with the corresponding extremal boxes.

</details>


### [18] [The Cost of Adaptation under Differential Privacy: Optimal Adaptive Federated Density Estimation](https://arxiv.org/abs/2512.14337)
*T. Tony Cai,Abhinav Chakraborty,Lasse Vuursteen*

Main category: math.ST

TL;DR: 本文研究了在联邦差分隐私（FDP）下密度估计中的自适应性问题，揭示了隐私与自适应性之间的根本冲突。与非隐私情形不同，FDP下全局估计存在不可避免的自适应代价，而点态估计则额外增加一个对数因子。作者提出了一个新的噪声机制和自适应FDP估计器，并建立了新的下界技术，首次严格刻画了自适应性的隐私-精度权衡。


<details>
  <summary>Details</summary>
Motivation: 在现代统计中，隐私保护数据分析日益重要，而自适应方法能在未知数据复杂性的情况下实现高效估计。然而，在隐私约束下自适应是否仍可行尚不明确，尤其是FDP框架下的适应代价尚未被系统刻画。

Method: 研究聚焦于联邦差分隐私（FDP）下的密度估计问题，提出了一种新的噪声机制和可一次性后处理实现的自适应FDP估计器，并发展了新的下界分析技术以刻画自适应推断在隐私限制下的根本极限。

Result: 1) 在FDP下，全局密度估计存在内在的自适应代价，不同于非隐私情形；2) 点态估计中，FDP引入额外的对数因子，叠加原有代价；3) 所提自适应估计器具有显式性能保证，优于现有方法；4) 提出了可用于其他问题的新下界技术。

Conclusion: 隐私约束从根本上改变了自适应性的代价：在FDP下，无论是全局还是点态密度估计，自适应均需付出额外代价，无法“免费”实现；本文首次严格刻画了这一隐私-精度-自适应三者的权衡关系。

Abstract: Privacy-preserving data analysis has become a central challenge in modern statistics. At the same time, a long-standing goal in statistics is the development of adaptive procedures -- methods that achieve near-optimal performance across diverse function classes without prior knowledge of underlying smoothness or complexity. While adaptation is often achievable at no extra cost in the classical non-private setting, this naturally raises a fundamental question: to what extent is adaptation still possible under privacy constraints?
  We address this question in the context of density estimation under federated differential privacy (FDP), a framework that encompasses both central and local DP models. We establish sharp results that characterize the cost of adaptation under FDP for both global and pointwise estimation, revealing fundamental differences from the non-private case. We then propose an adaptive FDP estimator that achieves explicit performance guarantees by introducing a new noise mechanism, enabling one-shot adaptation via post-processing. This approach strictly improves upon existing adaptive DP methods. Finally, we develop new lower bound techniques that capture the limits of adaptive inference under privacy and may be of independent interest beyond this problem.
  Our findings reveal a sharp contrast between private and non-private settings. For global estimation, where adaptation can be achieved for free in the classical non-private setting, we prove that under FDP an intrinsic adaptation cost is unavoidable. For pointwise estimation, where a logarithmic penalty is already known to arise in the non-private setting, we show that FDP introduces an additional logarithmic factor, thereby compounding the cost of adaptation. Taken together, these results provide the first rigorous characterization of the adaptive privacy-accuracy trade-off.

</details>


### [19] [Sharp convergence rates for Spectral methods via the feature space decomposition method](https://arxiv.org/abs/2512.14473)
*Guillaume Lecué,Zhifan Li,Zong Shang*

Main category: math.ST

TL;DR: 本文应用特征空间分解方法，在相当普遍的条件下，为线性回归中谱方法的人口过量风险提供了匹配的上下界估计。这使得可以对给定问题下的谱方法进行排序，并分析其收敛速率优劣，同时推广了逆问题中的饱和效应，并揭示了谱算法在特征学习上的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了在更广泛的条件下理解谱方法在线性回归中的性能表现，尤其是其人口过量风险的界限，并比较不同谱方法的优劣。

Method: 采用文献[LS24, GLS25, ALSS26]中发展的特征空间分解（FSD）方法，分析谱方法在平方损失下的线性回归中的表现，推导出匹配的上下界。

Result: 得到了任意协方差和信号下谱方法人口过量风险的匹配上下界；定义了基于收敛速率的谱方法偏序关系；推广了逆问题中的饱和效应并给出其发生当且仅当条件；证明了大多数谱方法不具备特征学习能力。

Conclusion: 谱方法在多数情况下无法突破信息指数所设限，缺乏特征学习能力，因此在如单指标学习等问题中存在根本性局限。

Abstract: In this paper, we apply the Feature Space Decomposition (FSD) method developed in [LS24, GLS25, ALSS26] to obtain, under fairly general conditions, matching upper and lower bounds for the population excess risk of spectral methods in linear regression under the squared loss, for every covariance and every signal. This result enables us, for a given linear regression problem, to define a partial order on the set of spectral methods according to their convergence rates, thereby characterizing which spectral algorithm is superior for that specific problem. Furthermore, this allows us to generalize the saturation effect proposed in inverse problems and to provide necessary and sufficient conditions for its occurrence. Our method also shows that, under broad conditions, any spectral algorithm lacks a feature learning property, and therefore cannot overcome the barrier of the information exponent in problems such as single-index learning.

</details>


### [20] [Learning the score under shape constraints](https://arxiv.org/abs/2512.14624)
*Rebecca M. Lewis,Oliver Y. Feng,Henry W. J. Reeve,Min Xu,Richard J. Samworth*

Main category: math.ST

TL;DR: 本文研究了在对数凹分布下分数估计的极小极大风险，提出了两类子类来刻画估计问题的本质特征，并建立了考虑尾部行为和光滑性的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 由于分数估计在扩散模型生成建模和基于凸M估计的线性回归中的关键作用，研究其在对数凹分布下的极小极大风险具有重要意义。

Method: 通过定义具有控制尾部增长和满足(β,L)-Hölder条件的对数凹密度子类，结合局部自适应多尺度估计方法，构建基于均匀置信带的估计量。

Result: 得到了考虑尾部行为和光滑性时的极小极大速率L^{2/(2β+1)}n^{-β/(2β+1)}（至多差一个对数因子），且当β<2时该速率优于仅依赖形状约束或光滑性假设的结果。

Conclusion: 分数估计在对数凹类中表现出与密度估计不同的特性，尾部行为和光滑性的联合约束能显著提升收敛速率。

Abstract: Score estimation has recently emerged as a key modern statistical challenge, due to its pivotal role in generative modelling via diffusion models. Moreover, it is an essential ingredient in a new approach to linear regression via convex $M$-estimation, where the corresponding error densities are projected onto the log-concave class. Motivated by these applications, we study the minimax risk of score estimation with respect to squared $L^2(P_0)$-loss, where $P_0$ denotes an underlying log-concave distribution on $\mathbb{R}$. Such distributions have decreasing score functions, but on its own, this shape constraint is insufficient to guarantee a finite minimax risk. We therefore define subclasses of log-concave densities that capture two fundamental aspects of the estimation problem. First, we establish the crucial impact of tail behaviour on score estimation by determining the minimax rate over a class of log-concave densities whose score function exhibits controlled growth relative to the quantile levels. Second, we explore the interplay between smoothness and log-concavity by considering the class of log-concave densities with a scale restriction and a $(β,L)$-Hölder assumption on the log-density for some $β\in [1,2]$. We show that the minimax risk over this latter class is of order $L^{2/(2β+1)}n^{-β/(2β+1)}$ up to poly-logarithmic factors, where $n$ denotes the sample size. When $β< 2$, this rate is faster than could be obtained under either the shape constraint or the smoothness assumption alone. Our upper bounds are attained by a locally adaptive, multiscale estimator constructed from a uniform confidence band for the score function. This study highlights intriguing differences between the score estimation and density estimation problems over this shape-constrained class.

</details>


<div id='physics.hist-ph'></div>

# physics.hist-ph [[Back]](#toc)

### [21] [Another 100 Years of Quantum Interpretation?](https://arxiv.org/abs/2512.14315)
*Karen Crowther*

Main category: physics.hist-ph

TL;DR: 本文探讨了量子力学解释的局限性，提出通过更基础的理论（如量子引力理论）来还原性地解释量子力学的可能性，并提出了评估量子力学不同解释的新标准，即其在启发性和统一性方面对寻找更基础理论的帮助。


<details>
  <summary>Details</summary>
Motivation: 质疑为何通常认为需要通过解释而非更基础的理论来理解量子力学的成功与特征，挑战现有范式。

Method: 分析量子力学和广义相对论之间的关系，讨论量子引力作为更基础理论的潜力，并提出基于启发性和统一性的新评估框架。

Result: 提出了一种新的评估量子力学解释的方法，强调这些解释在指导构建更基础理论方面的价值。

Conclusion: 解释并非唯一途径，还原性说明同样重要；应重视量子力学解释在推动理论统一和发现更基础理论中的作用。

Abstract: Interpretation is not the only way to explain a theory's success, form and features, and nor is it the only way to solve problems we see with a theory. This can also be done by giving a reductive explanation of the theory, by reference to a newer, more accurate, and/or more fundamental theory. We are seeking a theory of quantum gravity, a more fundamental theory than both quantum mechanics and general relativity, yet, while this theory is supposed to explain general relativity, it's not typically been thought to be necessary, or able, to explain quantum mechanics -- a task instead assigned to interpretation. Here, I question why this is. I also present a new way of assessing the various interpretations of quantum mechanics, in terms of their heuristic and unificatory potential in helping us find a more fundamental theory.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [22] [Offline Maximizing Minimally Invasive Proper Orthogonal Decomposition for Reduced Order Modeling of $S_n$ Radiation Transport](https://arxiv.org/abs/2512.13963)
*Quincy Huhn,Jean Ragusa,Youngsoo Choi*

Main category: math.NA

TL;DR: 提出了一种名为OMMI-POD的新方法，用于加速Sn辐射输运方程的降阶建模，通过离线构建简化系统库并在在线阶段插值，实现了1600倍加速且误差低。


<details>
  <summary>Details</summary>
Motivation: 为降低Sn输运方程全阶模型计算成本高的问题，探索高效的降阶建模方法。

Method: 基于快照数据使用POD构建降阶基，利用最小侵入式POD结合确定性求解器的扫描结构，并在离线阶段执行输运扫描以构建简化系统库，在线阶段进行插值求解。

Result: 在多群二维测试问题中验证了模型性能，显示出低误差和相比全阶模型1600倍的计算速度提升。

Conclusion: OMMI-POD能高效近似Sn输运方程的解，显著提升计算效率，适用于需要快速求解的场景。

Abstract: Deterministic solutions to the Sn transport equation can be computationally expensive to calculate. Reduced Order Models (ROMs) provide an efficient means of approximating the Full Order Model (FOM) solution. We propose a novel approach for constructing ROMs of the Sn radiation transport equation, Offline Maximizing Minimally Invasive (OMMI) Proper Orthogonal Decomposition (POD). POD uses snapshot data to build a reduced basis, which is then used to project the FOM. Minimally Invasive POD leverages the sweep infrastructure within deterministic Sn transport solvers to construct the reduced linear system, even though the FOM linear system is never directly assembled. OMMI-POD extends Minimally Invasive POD by performing transport sweeps offline, thereby maximizing the potential speedup. It achieves this by generating a library of reduced systems from a training set, which is then interpolated in the online stage to provide a rapid approximate solution to the Sn transport equation. The model's performance is evaluated on a multigroup 2-D test problem, demonstrating low error and a 1600-fold speedup over the full order model.

</details>


### [23] [An inverse problem for the one-phase Stefan problem with varying melting temperature](https://arxiv.org/abs/2512.13975)
*Marc Dambrine,Helmut Harbrecht*

Main category: math.NA

TL;DR: 本文研究了瞬态单相Stefan问题的正向和反向求解，提出基于移动网格有限元方法的数值算法，并通过模拟验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于实际应用中熔化温度可能随时间变化（如外部压力变化），需要对这类非定常Stefan问题进行建模与求解。

Method: 采用移动网格有限元方法，分别求解正向问题（计算区域演化）和反向问题（由几何演化重构时间依赖的熔化温度）。

Result: 开发了相应的数值算法并实现了数值模拟，能够有效处理熔化温度随时间变化的Stefan问题。

Conclusion: 所提出的移动网格有限元方法适用于求解具有时变熔化温度的瞬态Stefan问题，在正向和反向问题中均表现出良好的可行性。

Abstract: The present article is dedicated to the forward and backward solution of a transient one-phase Stefan problem. In the forward problem, we compute the evolution of the initial domain for a Stefan problem where the melting temperature varies over time. This occurs in practice, for example, when the pressure in the external space changes in time. In the corresponding backward problem, we then reconstruct the time-dependent melting temperature from the knowledge of the evolving geometry. We develop respective numerical algorithms using a moving mesh finite element method and provide numerical simulations.

</details>


### [24] [Multiple Scale Methods For Optimization Of Discretized Continuous Functions](https://arxiv.org/abs/2512.13993)
*Nicholas J. E. Richardson,Noah Marusenko,Michael P. Friedlander*

Main category: math.NA

TL;DR: 提出了一种用于Lipschitz连续函数空间问题的多尺度优化框架，通过在逐级细化网格上进行优化，显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 为解决高维或复杂空间中优化问题计算成本高的挑战，设计一种能在多尺度下高效收敛的优化方法。

Method: 先求解粗网格离散化问题，再通过线性插值将结果作为细网格上投影梯度下降的初值，逐步精细化；引入贪婪与懒惰变体，并结合约束修改技术保证跨尺度可行性。

Result: 理论分析表明该多尺度方法相比单尺度优化具有更紧的误差界和更低的计算成本；在概率密度估计等数值实验中实现了超过一个数量级的加速。

Conclusion: 所提出的多尺度优化框架能有效降低计算代价并提升精度，适用于广泛的一类具有迭代收敛性质的基算法。

Abstract: A multiscale optimization framework for problems over a space of Lipschitz continuous functions is developed. The method solves a coarse-grid discretization followed by linear interpolation to warm-start project gradient descent on progressively finer grids. Greedy and lazy variants are analyzed and convergence guarantees are derived that show the multiscale approach achieves provably tighter error bounds at lower computational cost than single-scale optimization. The analysis extends to any base algorithm with iterate convergence at a fixed rate. Constraint modification techniques preserve feasibility across scales. Numerical experiments on probability density estimation problems, including geological data, demonstrate speedups of an order of magnitude or better.

</details>


### [25] [Adaptive Wavelet-Galerkin Modelling of Heat Conduction in Heterogeneous Composite Materials](https://arxiv.org/abs/2512.14089)
*Taylan Demir,Atakan Koçyiğit*

Main category: math.NA

TL;DR: 提出了一种基于自适应小波Galerkin方法的非稳态热传导数值模拟技术，用于异质复合材料，具有高效性和高精度。


<details>
  <summary>Details</summary>
Motivation: 为了有效解决异质复合材料中由于材料界面和边界层导致的陡峭温度梯度问题，传统方法计算成本高且效率低。

Method: 结合多分辨小波基与隐式时间离散，利用小波系数驱动自适应细化，实现对关键区域的高效捕捉。

Result: 数值实验表明，该方法能准确解析层状、夹杂型和功能梯度复合材料中的热传导行为，显著减少自由度数量，提升计算效率。

Conclusion: 所提出的自适应小波Galerkin方法在保持高精度的同时大幅降低计算成本，适用于复杂复合材料的瞬态热传导模拟。

Abstract: We present an adaptive wavelet Galerkin method for transient heat conduction in heterogeneous composite materials. The approach combines multiresolution wavelet bases with an implicit time discretization to efficiently resolve sharp temperature gradients near material interfaces and boundary layers. Adaptive refinement is driven by wavelet coefficients, significantly reducing the number of degrees of freedom compared to uniform discretizations. Numerical examples demonstrate accurate resolution of layered, inclusion-based, and functionally graded composites with improved computational efficiency.

</details>


### [26] [Weighted Group Lasso for a static EEG problem](https://arxiv.org/abs/2512.14163)
*Ole Løseth Elvetun,Bjørn Fredrik Nielsen,Niranjana Sudheer*

Main category: math.NA

TL;DR: 本文研究了加权组Lasso在静态脑电图（EEG）逆问题中的应用，通过将每个位置的三个正交偶极子分量建模为一个整体组，有效缓解了深度和方向偏差，并提供了理论恢复保证和数值实验验证。


<details>
  <summary>Details</summary>
Motivation: 旨在提高EEG逆问题中神经源重建的空间准确性和生理合理性，克服传统方法中存在的深度和方向偏差。

Method: 采用加权组Lasso正则化框架，将每个位置的三个正交偶极子分量视为一个相干组；使用截断的Moore-Penrose伪逆定义权重矩阵。

Result: 理论分析给出了单组和多组源的恢复保证；数值实验表明该方法显著降低偶极定位误差（DLE），提升重建质量。

Conclusion: 所提方法为EEG逆问题提供了一种鲁棒的解决方案，能够实现更精确和生理上更合理的神经活动重建。

Abstract: We investigate the weighted Group Lasso formulation for the static inverse electroencephalography (EEG) problem, aiming at reconstructing the unknown underlying neuronal sources from voltage measurements on the scalp. By modelling the three orthogonal dipole components at each location as a single coherent group, we demonstrate that depth bias and orientation bias can be effectively mitigated through the proposed regularization framework. On the theoretical front, we provide concise recovery guarantees for both single and multiple group sources. Our numerical experiments highlight that while theoretical bounds hold for a broad range of weight definitions, the practical reconstruction quality, for cases not covered by the theory, depends significantly on the specific weighting strategy employed. Specifically, employing a truncated Moore-Penrose pseudoinverse for the involved weighting matrix gives a small Dipole Localization Error (DLE). The proposed method offers a robust approach for inverse EEG problems, enabling improved spatial accuracy and a more physiologically realistic reconstruction of neural activity.

</details>


### [27] [Analysis of a finite element method for second order uniformly elliptic PDEs in non-divergence form](https://arxiv.org/abs/2512.14219)
*Weifeng Qiu*

Main category: math.NA

TL;DR: 提出了一种有限元方法，用于求解非散度形式的二阶线性一致椭圆PDE和椭圆Hamilton-Jacobi-Bellman（HJB）方程，并在不同条件下证明了数值解在离散W^{2,p}范数下的最优收敛性及强解的良好适定性。


<details>
  <summary>Details</summary>
Motivation: 针对非散度形式的一致椭圆PDE和HJB方程，现有方法在系数不连续或区域非凸时存在理论局限，本文旨在发展一种能处理更广泛系数条件（如不连续或加权控制）和区域形状（包括非凸多边形）的有限元方法，并建立其最优收敛性和解的存在唯一性理论。

Method: 采用有限元方法构造数值格式，结合对偶论证和先验估计技术，在不同正则性假设下（如系数的均匀连续性或加权控制条件）分析离散解的收敛性；通过建立W^{2,p}框架下的稳定性与误差估计，证明最优收敛率并讨论强解的适定性。

Result: 证明了在凸多面体区域上，对于1<p≤2，数值解在离散W^{2,p}范数下具有最优收敛性；在二维非凸多边形区域上，p可在4/3附近的一个邻域内成立；同时证明了在相同区域上强解在W^{2,p}(Ω)中的良好适定性，并放宽了HJB方程中对系数连续性的传统假设。

Conclusion: 所提出的有限元方法能够有效处理非散度型椭圆PDE和HJB方程，即使在系数不连续或区域非凸的情况下仍保持最优收敛性和理论可靠性，扩展了现有理论的适用范围。

Abstract: We propose one finite element method for both second order linear uniformly elliptic PDE in non-divergence form and the elliptic Hamilton-Jacobi-Bellman (HJB) equation. For the linear elliptic PDE in non-divergence form, we consider two scenarios of the matrix coefficient matrix $A$. One is $A$ is uniformly continuous. The other is $A$ is discontinuous but $γA$ is dominated by $I_{d}$ where $γ$ is a positive weight function.
  We prove that optimal convergence in discrete $W^{2,p}$-norm of the numerical approximation to the strong solution for $1<p\leq 2$ on convex polyhedra in $\mathbb{R}^{d}$ ($d=2,3$). If the domain is a two dimensional non-convex polygon, $p$ is valid in a neighbourhood of $\frac{4}{3}$. We also prove the well-posedness of strong solution in $W^{2,p}(Ω)$ for both linear elliptic PDE in non-divergence form and the HJB equation for $1< p \leq 2$ on convex polyhedra in $\mathbb{R}^{d}$ ($d=2,3$) and for $p$ in an open interval starting from $1$ and including $\frac{4}{3}$ on two dimensional non-convex polygon. Furthermore, we relax the assumptions on the continuity of coefficients of the HJB equation, which have been widely used in literature.

</details>


### [28] [Structure-preserving Variational Multiscale Stabilization of the Incompressible Navier-Stokes Equations](https://arxiv.org/abs/2512.14231)
*Kevin Dijkstra,Deepesh Toshniwal*

Main category: math.NA

TL;DR: 本文提出了一种基于有限元外微积分（FEEC）框架的变分多尺度稳定化（VMS）方法，用于求解不可压缩Navier-Stokes方程，保持了连续问题的几何与拓扑结构，实现了残差型、能量稳定且最优收敛的离散格式，并适用于多种正则性水平的离散化。


<details>
  <summary>Details</summary>
Motivation: 为了在保持Navier-Stokes方程内在几何与拓扑结构的同时实现稳定的数值模拟，特别是在多尺度效应显著的情况下，需发展一种兼容FEEC框架的稳定化方法。

Method: 采用vorticity-velocity-pressure形式，在FEEC框架下进行离散；引入细尺度控制方程并同样用FEEC方法离散，通过将细尺度问题在单元间解耦以实现并行计算，并在矩阵组装过程中消去细尺度项，最终得到仅依赖粗尺度自由度的VMS格式。

Result: 所提方法具有残差驱动特性、能量稳定性及最优收敛性；细尺度模型可高效计算，且随着网格加密，稳定化效应渐近消失；该方法适用于低正则性和高正则性（如等几何）离散。

Conclusion: 基于FEEC的VMS方法能有效保持物理与数学结构，提供稳定、精确且可扩展的数值解，适用于广泛的流动问题，包括稳态、非稳态、粘性与无粘流。

Abstract: This paper introduces a Variational Multiscale Stabilization (VMS) formulation of the incompressible Navier--Stokes equations that utilizes the Finite Element Exterior Calculus (FEEC) framework. The FEEC framework preserves the geometric and topological structure of continuous spaces and PDEs in the discrete spaces and model, and helps build stable and convergent discretizations. For the Navier-Stokes equations, this structure is encoded in the de Rham complex. In this work, we consider the vorticity-velocity-pressure formulation discretized within the FEEC framework. We model the effect of the unresolved scales on the finite-dimensional solution by introducing appropriate fine-scale governing equations, which we also discretize using the FEEC approach. This preserves the structure of the continuous problem in both the coarse- and fine-scale solutions; for instance, both the coarse- and fine-scale velocities are pointwise incompressible. We demonstrate that the resulting formulation is residual-based, energetically stable, and optimally convergent. Moreover, our fine-scale model provides an efficient computational approach: by decoupling fine-scale problems across elements, they can be solved in parallel. In fact, the fine-scale equations can be eliminated during matrix assembly, leading to a VMS formulation in which the problem size is governed solely by the coarse-scale discretization. Finally, the proposed formulation applies to both the lowest regularity discretizations of the de Rham complex and high-regularity isogeometric discretizations. We validate our theoretical results through numerical experiments, simulating both steady-, unsteady-, viscous-, and inviscid-flow problems. These tests show that the stabilized solutions are qualitatively better than the unstabilized ones, converge at optimal rates, and, as the mesh is refined, the stabilization is asymptotically turned off.

</details>


### [29] [Separation-free exponential fitting with structured noise, with applications to inverse problems in parabolic PDEs](https://arxiv.org/abs/2512.14301)
*Rami Katz,Dmitry Batenkov,Giulia Giordano*

Main category: math.NA

TL;DR: 本论文研究了在结构化噪声下，从带有噪声的有限测量数据中恢复Sturm-Liouville算子前N₁个特征值对应的指数和幅值的问题，证明了Prony方法可实现超指数精度的恢复，并将其应用于线性反应扩散方程中未知势函数的重构。


<details>
  <summary>Details</summary>
Motivation: 传统上，指数和参数恢复问题在任意噪声下极度病态，难以精确求解。本文旨在探究当噪声具有特定结构（即由后续特征值构成的指数和）时，是否能显著改善恢复的稳定性与精度。

Method: 利用Sturm-Liouville算子的谱结构，将结构化噪声建模为后续特征值生成的指数和；结合超分辨率数学理论，分析并应用经典的Prony方法，在分离自由（separation-free）条件下实现参数的高精度恢复。

Result: 理论上证明了在结构化噪声下，指数和幅值可被超指数精度恢复；数值上验证了Prony方法能达到最优误差衰减速率，即使在特征值趋于无穷的分离自由情形也成立；并将该方法成功应用于线性反应-扩散方程中未知势函数的重构。

Conclusion: 结构化噪声的引入极大缓解了指数和恢复问题的病态性，使得经典Prony方法在更广泛设置下仍具高精度性能，拓展了其应用范围至偏微分方程参数识别等新领域。

Abstract: We investigate the recovery of exponents and amplitudes of an exponential sum, where the exponents $\left\{λ_n \right\}_{n=1}^{N_1}$ are the first $N_1$ eigenvalues of a Sturm-Liouville operator, from finitely many measurements subject to measurement noise. This inverse problem is extremely ill-conditioned when the noise is arbitrary and unstructured. Surprisingly, however, the extreme ill-conditioning exhibited by this problem disappears when considering a \emph{structured} noise term, taken as an exponential sum with exponents given by the subsequent eigenvalues $\left\{λ_n \right\}_{n=N_1+1}^{N_1+N_2}$ of the Sturm-Liouville operator, multiplied by a noise magnitude parameter $\varepsilon>0$. In this case, we rigorously show that the exponents and amplitudes can be recovered with super-exponential accuracy: we both prove the theoretical result and show that it can be achieved numerically by a specific algorithm. By leveraging recent results on the mathematical theory of super-resolution, we show in this paper that the classical Prony's method attains the analytic optimal error decay also in the ``separation-free'' regime where $λ_n \to \infty$ as $n \to \infty$, thereby extending the applicability of Prony's method to new settings. As an application of our theoretical analysis, we show that the approximated eigenvalues obtained by our method can be used to recover an unknown potential in a linear reaction-diffusion equation from discrete solution traces.

</details>


### [30] [Reducing Training Complexity in Empirical Quadrature-Based Model Reduction via Structured Compression](https://arxiv.org/abs/2512.14416)
*Björn Liljegren-Sailer*

Main category: math.NA

TL;DR: 提出一种基于结构化压缩的预处理方法，显著降低非线性系统复杂度约简的离线计算成本，同时保持精度。


<details>
  <summary>Details</summary>
Motivation: 现有复杂度约简方法的离线训练因依赖全量快照数据而计算昂贵，限制了其在大规模问题中的应用。

Method: 引入一种针对训练数据的结构化压缩预处理方法，使计算复杂度仅与快照数量相关，而不随降维模型维度增长。

Result: 实现了约一个数量级的离线计算成本和内存需求降低，且数值实验表明精度得以保持。

Conclusion: 该方法有效提升了经验求积和单元经验积分等复杂度约简技术的可扩展性，适用于更大规模的非线性系统降阶问题。

Abstract: Model order reduction seeks to approximate large-scale dynamical systems by lower-dimensional reduced models. For linear systems, a small reduced dimension directly translates into low computational cost, ensuring online efficiency. This property does not generally hold for nonlinear systems, where an additional approximation of nonlinear terms -- known as complexity reduction -- is required. To achieve online efficiency, empirical quadrature and cell-based empirical cubature are among the most effective complexity reduction techniques. However, existing offline training algorithms can be prohibitively expensive because they operate on raw snapshot data of all nonlinear integrands associated with the reduced model. In this paper, we introduce a preprocessing approach based on a specific structured compression of the training data. Its key feature is that it scales only with the number of collected snapshots, rather than additionally with the reduced model dimension. Overall, this yields roughly an order-of-magnitude reduction in offline computational cost and memory requirements, thereby enabling the application of the complexity reduction methods to larger-scale problems. Accuracy is preserved, as indicated by our error analysis and demonstrated through numerical examples.

</details>


### [31] [Semi-robust equal-order hybridized discontinuous methods](https://arxiv.org/abs/2512.14419)
*Xiaoqi Ma,Jin Zhang*

Main category: math.NA

TL;DR: 本文提出了一个统一的等阶混合间断有限元（HDG）方法分析框架，涵盖标准HDG、嵌入式间断有限元和嵌入-混合间断有限元方法。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个统一的框架来分析不同类型的等阶HDG方法，促进这些方法的理论理解和应用。

Method: 提出了一种统一的分析框架，适用于多种HDG方法，包括标准HDG、嵌入式和嵌入-混合式方法。

Result: 成功构建了一个能够涵盖多种HDG方法的统一分析框架。

Conclusion: 该框架有助于更好地理解与比较不同的HDG方法，并为未来的研究提供了理论基础。

Abstract: This paper introduces a unified analysis framework of equal-order hybridized discontinuous finite element (HDG) methods. The general framework covers standard HDG, embedded discontinuous finite element, and embedded-hybridized discontinuous finite element methods.

</details>


### [32] [Ensemble Parameter Estimation for the LPLSP Framework: A Rapid Approach to Reduced-Order Modeling for Transient Thermal Systems](https://arxiv.org/abs/2512.14467)
*Neelakantan Padmanabhan*

Main category: math.NA

TL;DR: 提出了一种集成参数估计框架，使LPLSP方法能从单一瞬态数据集生成降阶热模型，显著减少计算成本和模型开发时间。


<details>
  <summary>Details</summary>
Motivation: 早期的LPLSP方法依赖多次独立热源激励的参数模拟，限制了效率和可扩展性，因此需要一种更高效的方法来生成降阶热模型。

Method: 引入集成参数估计框架，采用全瞬态激励同时识别所有模型系数，并提出两种策略（秩缩减和两阶段分解）以降低计算成本并提高可扩展性。

Result: 所提方法生成的降阶模型在温度预测误差低于5%的情况下，将模型开发时间缩短至O(10^0 s)-O(10^1 s)，且新工况下的求解时间仅为O(10^0 s)。

Conclusion: 该框架显著提升了LPLSP方法的效率与实用性，支持快速热分析及数字孪生系统的自动化构建。

Abstract: This work introduces an ensemble parameter estimation framework that enables the Lumped Parameter Linear Superposition (LPLSP) method to generate reduced order thermal models from a single transient dataset. Unlike earlier implementations that relied on multiple parametric simulations to excite each heat source independently, the proposed approach simultaneously identifies all model coefficients using fully transient excitations. Two estimation strategies namely rank-reduction and two-stage decomposition are developed to further reduce computational cost and improve scalability for larger systems. The proposed strategies yield ROMs with mean temperature-prediction errors within 5% of CFD simulations while reducing model-development times to O(10^0 s)-O(10^1 s). Once constructed, the ROM evaluates new transient operating conditions in O(10^0 s), enabling rapid thermal analysis and enabling automated generation of digital twins for both simulated and physical systems.

</details>


### [33] [On the constants in inverse trace inequalities for polynomials orthogonal to lower-order subspaces](https://arxiv.org/abs/2512.14570)
*Zhaonan Dong,Tanvi Wadhawan*

Main category: math.NA

TL;DR: 推导了多项式函数在d维单形上正交于低阶子空间时的逆迹不等式的显式精确常数，结果对hp型混合Galerkin方法分析具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 为高精度有限元方法（如混合间断Galerkin方法）的hp分析提供关键的数学工具，需要明确且最优的逆迹不等式常数。

Method: 利用参考单形上的正交多项式展开，并仔细分析面质量矩阵相关块的特征值，沿用文献[9]的论证思路。

Result: 得到了关于多项式空间\(\mathbb{P}_p(T)\)中正交于低阶子空间\(\mathbb{P}_n(T)\)的函数的逆迹不等式的精确、显式常数。

Conclusion: 所得到的显式常数对于涉及高阶多项式逼近的混合Galerkin类数值方法的理论分析非常有用。

Abstract: We derive sharp, explicit constants in inverse trace inequalities for polynomial functions belonging to $\mathbb{P}_p(T)$ (polynomial space with total degree $p$) that are orthogonal to the lower-order subspace $\mathbb{P}_n(T)$, $n\leq p$, where $T$ denotes a $d$-dimensional simplex. The proofs rely on orthogonal polynomial expansions on reference simplices and on a careful analysis of the eigenvalues of the relevant blocks of the face mass matrices, following the arguments developed in [9]. These results are very useful in the $hp$-analysis of the hybrid Galerkin methods, e.g. hybridizable discontinuous Galerkin methods, hybrid high-order methods, etc.

</details>


### [34] [Inverse obstacle scattering regularized by the tangent-point energy](https://arxiv.org/abs/2512.14590)
*Henrik Schumacher,Jannik Rönsch,Thorsten Hohage,Max Wardetzky*

Main category: math.NA

TL;DR: 本文提出使用切点能量作为三维逆散射问题的Tikhonov正则化方法，具有抑制表面粗糙和自避免特性，理论证明了问题的良好适定性和解的收敛性，并设计了迭代正则化高斯-牛顿算法，数值实验显示该方法可行且能产生高质量重建结果。


<details>
  <summary>Details</summary>
Motivation: 针对三维逆散射问题不适定性，寻找兼具几何正则性和数学良好性质的正则化方法，以提升重建质量与稳定性。

Method: 采用切点能量作为Tikhonov正则项，利用其对嵌入曲面的自避免性和光滑性惩罚；结合连续性和紧性理论，分析正则化问题的适定性与收敛性；提出基于高斯-牛顿法的迭代正则化算法。

Result: 证明了在噪声趋于零时正则化解收敛于真实解；数值实验验证了方法的可行性，并实现了前所未有的高质量重建效果。

Conclusion: 切点能量是一种有效的正则化工具，适用于三维逆散射问题，兼具理论严谨性与实际重建优势。

Abstract: We employ the so-called tangent-point energy as Tikhonov regularizer for ill-conditioned inverse scattering problems in 3D. The tangent-point energy is a self-avoiding functional on the space of embedded surfaces that also penalizes surface roughness. Moreover, it features nice compactness and continuity properties. These allow us to show the well-posedness of the regularized problems and the convergence of the regularized solutions to the true solution in the limit of vanishing noise level. We also provide a reconstruction algorithm of iteratively regularized Gauss-Newton type. Our numerical experiments demonstrate that our method is numerically feasible and effective in producing reconstructions of unprecedented quality.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [35] [Algorithmic aspects of gauged Gaussian fermionic projected entangled pair states](https://arxiv.org/abs/2512.13812)
*Itay Gomelski,Jonathan Elyovich,Ariel Kelman,Erez Zohar,Patrick Emonts*

Main category: hep-lat

TL;DR: 本研究探讨了基于Gaugged Gaussian fermionic PEPS（GGFPEPS）的变分蒙特卡洛方法在Z2规范理论中的算法特性，发现了最优更新步长，并分析了规范固定和翻译不变性对收敛速度的影响。


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡洛方法在处理实时间演化和符号问题时存在局限，因此需要发展无符号问题的变分方法（如GGFPEPS）来研究格点规范理论。然而，GGFPEPS框架内的非基于作用量的蒙特卡洛算法性能尚不清楚，亟需系统分析其数值行为以推动更大更复杂系统的模拟。

Method: 采用GGFPEPS作为变分基态试探波函数，结合变分蒙特卡洛技术，在2+1维Z2格点规范理论中系统研究不同更新步长、是否进行规范固定以及是否利用平移不变性等策略对收敛行为和计算效率的影响。

Result: 确定了GGFPEPS-MC模拟中的最优更新步长；发现规范固定通常会减慢收敛速度；表明在某些情况下不利用平移不变性反而可以改善误差收敛的计算时间标度。

Conclusion: 这些算法上的洞察有助于优化GGFPEPS方法的实现，提升其在大型和复杂格点规范系统中的可扩展性和计算效率，为未来量子多体模拟提供重要支持。

Abstract: Lattice gauge theories (LGTs) provide a powerful framework for studying non-perturbative phenomena in gauge theories. However, conventional approaches such as Monte Carlo (MC) simulations in imaginary time are limited, as they do not allow real time evolution and suffer from a sign problem in many important cases. Using Gauged Gaussian fermionic projected entangled pair states (GGFPEPS) as a variational ground state ansatz offers an alternative for studying LGTs through a sign-problem-free variational MC. As this method is extended to larger and more complex systems, understanding its numerical behavior becomes essential. While conventional action based MC has been extensively studied, the performance and characteristics of non-action-based MC within the GGFPEPS framework are far less explored. In this work, we investigate these algorithmic aspects, identifying an optimal update size for GGFPEPS-based MC simulations for $\mathbb{Z}_2$ in $2+1$ dimensions. We show that gauge fixing generally slows convergence, and demonstrate that not exploiting the translation-invariance can, in some cases, improve the computational time scaling of error convergence. We expect that these improvements will allow advancing the simulation to larger and more complex systems.

</details>


### [36] [Complex Langevin simulations with a kernel](https://arxiv.org/abs/2512.14153)
*Michael Mandl,Erhard Seiler,Dénes Sexty*

Main category: hep-lat

TL;DR: 本文讨论了核函数在复数朗之万模拟中的最新应用，提出了一种解决简单玩具模型中错误收敛问题的方法，并推导出一个充分且必要的正确性判据，同时介绍了利用机器学习在格点规范理论中寻找合适核函数的初步成果。


<details>
  <summary>Details</summary>
Motivation: 复数朗之万方法在处理复作用量系统时面临错误收敛的问题，而传统的收敛判据仅为必要非充分条件，难以确保结果正确，因此需要更可靠的评估手段和改进方法。

Method: 引入核函数来修正复数朗之万演化路径，并提出一个新的、既必要又充分的正确性条件；结合机器学习方法，在格点规范理论中自动搜索有效的核函数，应用于QCD的重密度极限进行测试。

Result: 在简单模型中验证了核函数能有效解决错误收敛问题；新提出的正确性条件可更可靠地判断模拟是否正确收敛；机器学习方法在QCD重密度极限中初步显示出寻找合适核的潜力。

Conclusion: 核函数是改善复数朗之万模拟收敛行为的有效工具，配合新的严格正确性判据和机器学习优化策略，有望提升该方法在强关联量子场论计算中的可靠性与适用性。

Abstract: We discuss recent developments regarding the use of kernels in complex Langevin simulations. In particular, we outline how a kernel can be used to solve the problem of wrong convergence in a simple toy model. Since conventional correctness criteria for complex Langevin results are only necessary but not sufficient, the correct convergence of complex Langevin simulations is not always straightforward to assess. Hence, we furthermore discuss a condition for correctness that we have recently derived, which is both necessary and sufficient. Finally, we outline a machine-learning approach for finding suitable kernels in lattice gauge theories and present preliminary results of its application to the heavy-dense limit of QCD.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [37] [Delay Optimization in a Simple Offloading System: Extended Version](https://arxiv.org/abs/2512.13810)
*Darin Jeff,Eytan Modiano*

Main category: eess.SY

TL;DR: 本文研究了计算卸载系统中任务分配与资源划分的最优策略，旨在最小化延迟。系统包含本地服务器和高容量云服务器，提供两种服务模式。通过分析稳定性区域和吞吐量最大化原则，推导出给定任务分配下的最优资源划分及延迟闭式表达，并证明延迟最优策略具有分岔结构：在低负载时所有任务使用单一模式，超过临界阈值后需在两种模式间分配。数值实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 为了在顺序处理的计算卸载系统中实现最小延迟，需要联合优化任务的服务模式分配与服务器资源划分，现有方法缺乏对这种联合优化及其结构性质的研究。

Method: 首先刻画系统的稳定性区域并设计最大化吞吐量的服务模式；然后针对固定的任务分配策略，推导最优资源划分方案并给出延迟的闭式表达式；最后分析延迟最优任务分配策略的结构特性，并通过数值仿真验证理论结论。

Result: 1) 确定了系统的稳定性区域和服务模式的设计原则；2) 得到了任意任务分配策略下的最优资源划分及对应的延迟闭式解；3) 证明了延迟最优策略具有‘分岔结构’——低负载时全部任务使用一种服务模式，超过临界负载后必须使用两种模式；4) 数值结果验证了理论分析的正确性。

Conclusion: 在计算卸载系统中，延迟最优的任务分配策略具有结构性特征：低于临界负载时应统一使用单一服务模式，而高于该阈值时必须启用双模式分配；结合最优资源划分可显著降低系统延迟。

Abstract: We consider a computation offloading system where jobs are processed sequentially at a local server followed by a higher-capacity cloud server. The system offers two service modes, differing in how the processing is split between the servers. Our goal is to design an optimal policy for assigning jobs to service modes and partitioning server resources in order to minimize delay. We begin by characterizing the system's stability region and establishing design principles for service modes that maximize throughput. For any given job assignment strategy, we derive the optimal resource partitioning and present a closed-form expression for the resulting delay. Moreover, we establish that the delay-optimal assignment policy exhibits a distinct breakaway structure: at low system loads, it is optimal to route all jobs through a single service mode, whereas beyond a critical load threshold, jobs must be assigned across both modes. We conclude by validating these theoretical insights through numerical evaluation.

</details>


### [38] [A Convex Obstacle Avoidance Formulation](https://arxiv.org/abs/2512.13836)
*Ricardo Tapia,Iman Soltani*

Main category: eess.SY

TL;DR: 提出了一种新的凸优化障碍物避让方法，适用于非线性模型预测控制，提高计算效率并支持短视界实时应用。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中实现可靠的碰撞避免是自动驾驶的关键需求，但现有非线性模型预测控制方法在高频需求下计算负担重，难以应对紧急情况。

Method: 通过引入逻辑集成的新方法，构建首个通用的凸形障碍物避让公式，并将其融入凸MPC框架中，允许使用更短的预测时域。

Result: 该方法在自动驾驶车辆应用中进行了评估，表现出比传统非凸方法更高的计算效率，且在障碍物超出预测范围时仍能有效避障。

Conclusion: 所提出的凸优化方法在保证避障性能的同时显著提升了计算速度，适合实时部署，尤其在非凸问题中也达到或超过了现有方法的表现。

Abstract: Autonomous driving requires reliable collision avoidance in dynamic environments. Nonlinear Model Predictive Controllers (NMPCs) are suitable for this task, but struggle in time-critical scenarios requiring high frequency. To meet this demand, optimization problems are often simplified via linearization, narrowing the horizon window, or reduced temporal nodes, each compromising accuracy or reliability. This work presents the first general convex obstacle avoidance formulation, enabled by a novel approach to integrating logic. This facilitates the incorporation of an obstacle avoidance formulation into convex MPC schemes, enabling a convex optimization framework with substantially improved computational efficiency relative to conventional nonconvex methods. A key property of the formulation is that obstacle avoidance remains effective even when obstacles lie outside the prediction horizon, allowing shorter horizons for real-time deployment. In scenarios where nonconvex formulations are unavoidable, the proposed method meets or exceeds the performance of representative nonconvex alternatives. The method is evaluated in autonomous vehicle applications, where system dynamics are highly nonlinear.

</details>


### [39] [Safe Online Control-Informed Learning](https://arxiv.org/abs/2512.13868)
*Tianyu Zhou,Zihao Liang,Zehui Lu,Shaoshuai Mou*

Main category: eess.SY

TL;DR: 提出了一种安全在线控制感知学习框架，用于安全关键的自主系统，结合最优控制、参数估计和安全约束，在线更新参数并保证安全性。


<details>
  <summary>Details</summary>
Motivation: 为了在不确定环境下实现安全关键系统的鲁棒、高效数据适应，并解决对高质量初始猜测的依赖问题。

Method: 采用扩展卡尔曼滤波器实时更新系统参数，结合软加屏障函数来强制满足约束条件，实现在线学习与控制。

Result: 理论分析证明了收敛性和安全性，实验在倒立摆和机械臂系统上验证了该框架的有效性。

Conclusion: 该框架能够有效实现安全关键系统的在线学习与控制，具备良好的安全保证和适应能力。

Abstract: This paper proposes a Safe Online Control-Informed Learning framework for safety-critical autonomous systems. The framework unifies optimal control, parameter estimation, and safety constraints into an online learning process. It employs an extended Kalman filter to incrementally update system parameters in real time, enabling robust and data-efficient adaptation under uncertainty. A softplus barrier function enforces constraint satisfaction during learning and control while eliminating the dependence on high-quality initial guesses. Theoretical analysis establishes convergence and safety guarantees, and the framework's effectiveness is demonstrated on cart-pole and robot-arm systems.

</details>


### [40] [A Fair, Flexible, Zero-Waste Digital Electricity Market: A First-Principles Approach Combining Automatic Market Making, Holarchic Architectures and Shapley Theory](https://arxiv.org/abs/2512.13871)
*Shaun Sweeney,Robert Shorten,Mark O'Malley*

Main category: eess.SY

TL;DR: 本文重新构想了电力市场在批发和平衡层面的设计，提出了一种基于电网物理特性的动态、事件驱动的双侧市场机制——分层自动做市商（AMM），通过统一的稀缺性传播规则实现节点与分区定价，并确保价格有界、成本合理分摊和系统稳定。


<details>
  <summary>Details</summary>
Motivation: 现有电力市场设计在不确定性下缺乏抗冲击的纳什均衡，依赖价格上限和监管干预维持运行，难以保障安全与公平；因此需要一种内生稳定、符合物理约束且能应对现实不确定性的新型市场架构。

Method: 提出一种分层自动做市商（AMM）框架，将市场价格视为由物理紧张程度决定的外生控制信号，而非均衡结果；通过嵌套的稀缺层级（从节点到系统）实现价格形成与稀缺性传播，支持公平接入与短缺下的比例分配，并结合支付即投标的能源出清与基于贡献度的成本分摊机制。

Result: 大规模仿真表明该AMM架构具有有界输入有界输出稳定性、可控采购成本、零结构性浪费以及更优的分配效果；节点和分区定价成为该统一框架的特例，且能够回收燃料与非燃料成本。

Conclusion: 该研究为电力市场提供了气候适应性强、政策可配置的新范式，但其实施需配套新的操作工具和有序过渡路径，标志着从静态市场出清向动态物理耦合控制系统的根本转变。

Abstract: This thesis presents a fundamental rethink of electricity market design at the wholesale and balancing layers. Rather than treating markets as static spot clearing mechanisms, it reframes them as a continuously online, event driven dynamical control system: a two sided marketplace operating directly on grid physics.
  Existing energy only, capacity augmented, and zonal market designs are shown to admit no shock robust Nash equilibrium under realistic uncertainty, instead relying on price caps, uplift, and regulatory intervention to preserve solvency and security. In response, the thesis develops a holarchic Automatic Market Maker (AMM) in which prices are bounded, exogenous control signals derived from physical tightness rather than emergent equilibrium outcomes.
  The AMM generalises nodal and zonal pricing through nested scarcity layers, from node to cluster to zone to region to system, such that participant facing prices inherit from the tightest binding constraint. Nodal and zonal pricing therefore emerge as special cases of a unified scarcity propagation rule.
  Beyond pricing, the AMM functions as a scarcity aware control system and a digitally enforceable rulebook for fair access and proportional allocation under shortage. Fuel costs are recovered through pay as bid energy dispatch consistent with merit order, while non fuel operating and capital costs are allocated according to adequacy, flexibility, and locational contribution.
  Large scale simulations demonstrate bounded input bounded output stability, controllable procurement costs, zero structural waste, and improved distributional outcomes. The architecture is climate aligned and policy configurable, but requires a managed transition and new operational tools for system operators and market participants.

</details>


### [41] [Data-Driven Control via Conditional Mean Embeddings: Formal Guarantees via Uncertain MDP Abstraction](https://arxiv.org/abs/2512.13940)
*Ibon Gracia,Morteza Lahijanian*

Main category: eess.SY

TL;DR: 提出一种基于条件均值嵌入和不确定马尔可夫决策过程的数据驱动策略合成框架，为未知动态的随机系统提供形式化性能保证。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景中，控制具有未知动态且需满足复杂规范的随机系统极具挑战性，需要确保性能保证。

Method: 从轨迹数据中学习系统的转移核作为条件均值嵌入，构建捕获学习和离散化误差的有限状态不确定马尔可夫决策过程抽象，并通过鲁棒动态规划生成具有形式化性能界限的策略。

Result: 在温度调节基准上验证了方法的有效性，实现了对系统的形式化性能保证。

Conclusion: 所提框架能够有效处理未知动态系统的控制问题，并为复杂规范下的安全关键应用提供可靠策略。

Abstract: Controlling stochastic systems with unknown dynamics and under complex specifications is specially challenging in safety-critical settings, where performance guarantees are essential. We propose a data-driven policy synthesis framework that yields formal performance guarantees for such systems using conditional mean embeddings (CMEs) and uncertain Markov decision processes (UMDPs). From trajectory data, we learn the system's transition kernel as a CME, then construct a finite-state UMDP abstraction whose transition uncertainties capture learning and discretization errors. Next, we generate a policy with formal performance bounds through robust dynamic programming. We demonstrate and empirically validate our method through a temperature regulation benchmark.

</details>


### [42] [Fast Frequency Response Potential of Data Centers through Workload Modulation and UPS Coordination](https://arxiv.org/abs/2512.14128)
*Xiaojie Tao,Rajit Gadh*

Main category: eess.SY

TL;DR: 本文探讨了利用数据中心通过实时工作负载调节和UPS协调提供快速频率响应（FFR）的可行性，提出了一种结合数据中心功耗与电网频率动态的控制策略，并在IEEE 39节点系统上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源的快速增长，电力系统惯性降低，对快速频率响应的需求增加。数据中心作为大型灵活负荷，具备参与频率调节的潜力，但如何有效整合其资源仍需研究。

Method: 建立了一个融合数据中心IT服务器、冷却系统和储能设备的动态模型，设计基于频率偏差的控制策略，通过调节服务器功率和调度UPS电池放电实现快速频率响应。

Result: 在修改后的IEEE 39节点系统上的案例研究表明，该策略能有效提高频率最低点并缩短恢复时间，同时不影响服务质量。

Conclusion: 数据中心有望成为未来低惯性电力系统中重要的电网支撑资源，通过合理的控制策略可兼顾电网稳定与运行性能。

Abstract: The rapid growth of renewable energy sources has significantly reduced system inertia and increased the need for fast frequency response (FFR) in modern power systems. Data centers, as large and flexible electrical consumers, hold great potential to contribute to frequency stabilization due to their controllable IT workloads and on-site uninterruptible power supply (UPS) systems. This paper investigates the feasibility of leveraging data centers for providing fast frequency response through real-time workload modulation and UPS coordination. A dynamic model combining data center power consumption and grid frequency dynamics is developed, capturing the interactions between IT servers, cooling systems, and energy storage. Control strategies based on frequency deviation are implemented to adjust server power and discharge UPS batteries during frequency events. Case studies on a modified IEEE 39-bus system demonstrate that the proposed strategy can effectively reduce frequency nadir and shorten recovery time without compromising service quality. The results highlight the promising role of data centers as grid-supporting resources in future low-inertia systems.

</details>


### [43] [Coordinated Fast Frequency Response from Electric Vehicles, Data Centers, and Battery Energy Storage Systems](https://arxiv.org/abs/2512.14136)
*Xiaojie Tao,Rajit Gadh*

Main category: eess.SY

TL;DR: 本文提出了一种协调控制框架，整合电动汽车、数据中心和电池储能系统，提供快速频率响应，提升低惯量电力系统的频率稳定性。


<details>
  <summary>Details</summary>
Motivation: 高比例可再生能源接入降低了电网系统惯性，传统资源难以满足快速频率响应需求，亟需挖掘分布式非传统资源的协同潜力。

Method: 建立EV、数据中心UPS与负荷调节、BESS的动态模型，设计基于响应速度和容量的分层控制架构，实现多资源协调响应。

Result: 在IEEE 39节点系统中验证表明，相比单一资源，该框架可将频率最低点提升0.2 Hz，降低变化率并加快恢复速度。

Conclusion: 异构资源协同可显著增强电网频率稳定性，为高比例可再生能源电网的频率调节市场提供了有效技术路径。

Abstract: High renewable penetration has significantly reduced system inertia in modern power grids, increasing the need for fast frequency response (FFR) from distributed and non-traditional resources. While electric vehicles (EVs), data centers, and battery energy storage systems (BESS) have each demonstrated the capability to provide sub-second active power support, their combined frequency response potential has not been systematically evaluated. This paper proposes a coordinated control framework that aggregates these heterogeneous resources to provide fast, stable, and reliable FFR. Dynamic models for EV fleets, data center UPS and workload modulation, and BESS are developed, explicitly capturing their response times, power limits, and operational constraints. A hierarchical control architecture is introduced, where an upper-level coordinator dynamically allocates FFR among resources based on response speed and available capacity, and lower-level controllers implement the actual power response. Case studies based on the IEEE 39-bus test system demonstrate that the coordinated EV-DC-BESS framework improves frequency nadir by up to 0.2 Hz, reduces RoCoF, and accelerates frequency recovery compared with single-resource FFR. Results confirm that synergistic coordination significantly enhances grid stability, especially in low-inertia scenarios. This work highlights the value of multi-resource aggregation for future frequency regulation markets in renewable-dominated grids.

</details>


### [44] [KalMRACO: Unifying Kalman Filter and Model Reference Adaptive Control for Robust Control and Estimation of Uncertain Systems](https://arxiv.org/abs/2512.14175)
*Lauritz Rismark Fosso,Christian Holden,Sveinung Johan Ohrem*

Main category: eess.SY

TL;DR: 提出KalMRACO方法，结合卡尔曼滤波与模型参考自适应控制，减少对系统参数先验知识的依赖，并通过水下航行器实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 卡尔曼滤波通常需要已知系统参数，但在实际应用中这些参数往往未知，限制了其应用。因此，需要一种不依赖精确系统参数的滤波方法。

Method: 将模型参考自适应控制（MRAC）中的参考模型作为卡尔曼滤波的系统模型，提出KalMRACO框架；同时引入状态估计与测量值的混合反馈机制，以改善初始瞬态期间的稳定性。

Result: 在水下航行器上的仿真和实验表明，KalMRACO能有效实现参考模型状态的跟踪、观测器状态收敛，并具有良好的噪声抑制能力。

Conclusion: KalMRACO成功融合卡尔曼滤波与MRAC，显著降低了对系统参数先验知识的依赖，在实际工程应用中具有潜力。

Abstract: A common assumption when applying the Kalman filter is a priori knowledge of the system parameters. These parameters are not necessarily known, and this may limit real-world applications of the Kalman filter. The well-established Model Reference Adaptive Controller (MRAC) utilizes a known reference model and ensures that the input-output behavior of a potentially unknown system converges to that of the reference model. We present KalMRACO, a unification of the Kalman filter and MRAC leveraging the reference model of MRAC as the Kalman filter system model, thus eliminating, to a large degree, the need for knowledge of the underlying system parameters in the application of the Kalman filter. We also introduce the concept of blending estimated states and measurements in the feedback law to handle stability issues during the initial transient. KalMRACO is validated through simulations and lab trials on an underwater vehicle. Results show superior tracking of the reference model state, observer state convergence, and noise mitigation properties.

</details>


### [45] [A Data-Driven Approach for Electric Vehicle Powertrain Modeling](https://arxiv.org/abs/2512.14344)
*Eymen Ipek,Mario Hirz*

Main category: eess.SY

TL;DR: 提出了一种模块化框架，用于开发动力总成仿真，通过定义电池、逆变器和电动机的标准接口，实现不同类型模型的集成，以缩短开发周期。


<details>
  <summary>Details</summary>
Motivation: 汽车工业电气化和动力系统复杂性的增加要求加快开发周期并降低成本，现有研究在组件级别上探索数据驱动模型，但缺乏系统级仿真的整合方法。

Method: 通过为关键部件（电池、逆变器、电动机）定义标准化接口，构建一个模块化框架，支持数据驱动、基于物理或经验模型的独立开发与集成。

Result: 实现了可扩展的系统级建模，能够灵活集成不同类型的模型，提升虚拟验证效率。

Conclusion: 该框架有助于缩短汽车动力总成的开发时间，满足现代汽车工业对敏捷开发的需求。

Abstract: Electrification in the automotive industry and increasing powertrain complexity demand accelerated, cost-effective development cycles. While data-driven models are recently investigated at component level, a gap exists in systematically integrating them into cohesive, system-level simulations for virtual validation. This paper addresses this gap by presenting a modular framework for developing powertrain simulations. By defining standardized interfaces for key components-the battery, inverter, and electric motor-our methodology enables independently developed models, whether data-driven, physics-based, or empirical, to be easily integrated. This approach facilitates scalable system-level modeling, aims to shorten development timelines and to meet the agile demands of the modern automotive industry.

</details>


### [46] [A Geometric Task-Space Port-Hamiltonian Formulation for Redundant Manipulators](https://arxiv.org/abs/2512.14349)
*Federico Califano,Camilla Rota,Riccardo Zanella,Antonio Franchi*

Main category: eess.SY

TL;DR: 提出了一种新的几何端口-哈密顿模型，用于描述执行微分运动学任务的冗余机械臂，并通过坐标变换将标准哈密顿动量分解为任务空间和零空间动量，结合IDA-PBC控制方法实现了对7自由度机械臂的阻抗控制与稳定。


<details>
  <summary>Details</summary>
Motivation: 为解决冗余机械臂在任务空间中建模与控制的挑战，需建立能清晰区分任务空间与零空间动力学的统一几何框架。

Method: 基于几何端口-哈密顿系统理论，通过坐标变换从标准哈密顿动力学导出新模型，分离任务空间与零空间动量，并结合IDA-PBC方法设计控制器。

Result: 成功建立了冗余机械臂的几何端口-哈密顿模型，揭示了其与现有拉格朗日模型的关系，并在7-DOF Emika Panda机器人仿真中实现了阻抗调节与稳定控制。

Conclusion: 所提模型为冗余机械臂提供了结构保持的动力学描述，适用于基于能量的控制设计，验证了其在复杂任务中的有效性与潜力。

Abstract: We present a novel geometric port-Hamiltonian formulation of redundant manipulators performing a differential kinematic task $η=J(q)\dot{q}$, where $q$ is a point on the configuration manifold, $η$ is a velocity-like task space variable, and $J(q)$ is a linear map representing the task, for example the classical analytic or geometric manipulator Jacobian matrix. The proposed model emerges from a change of coordinates from canonical Hamiltonian dynamics, and splits the standard Hamiltonian momentum variable into a task-space momentum variable and a null-space momentum variable. Properties of this model and relation to Lagrangian formulations present in the literature are highlighted. Finally, we apply the proposed model in an \textit{Interconnection and Damping Assignment Passivity-Based Control} (IDA-PBC) design to stabilize and shape the impedance of a 7-DOF Emika Panda robot in simulation.

</details>


### [47] [Equivariant Filter Cascade for Relative Attitude, Target's Angular Velocity, and Gyroscope Bias Estimation](https://arxiv.org/abs/2512.14412)
*Gil Serrano,Pedro Lourenço,Bruno J. Guerreiro,Rita Cunha*

Main category: eess.SY

TL;DR: 提出了一种基于等变滤波器级联的航天器相对姿态与角速度估计方法，用于追踪非合作目标的交会对接任务。


<details>
  <summary>Details</summary>
Motivation: 在追踪失效卫星等非合作目标时，需要精确估计相对姿态和角速度，同时克服陀螺仪偏差的影响。

Method: 采用级联的等变滤波器（EqF），第一级利用星跟踪器估计追逐航天器的姿态和偏差，第二级利用目标固连的两个非共线矢量观测来估计相对姿态和目标角速度。

Result: 理论上分析了滤波器级联的稳定性，并通过仿真验证了其性能。

Conclusion: 所提出的EqF级联方法能有效估计相对姿态和角速度，具有良好的稳定性和估计精度。

Abstract: Rendezvous and docking between a chaser spacecraft and an uncooperative target, such as an inoperative satellite, require synchronization between the chaser spacecraft and the target. In these scenarios, the chaser must estimate the relative attitude and angular velocity of the target using onboard sensors, in the presence of gyroscope bias. In this work, we propose a cascade of Equivariant Filters (EqF) to address this problem. The first stage of the cascade estimates the chaser's attitude and the bias, using measurements from a star tracker, while the second stage of the cascade estimates the relative attitude and the target's angular velocity, using observations of two known, non-collinear vectors fixed in the target frame. The stability of the EqF cascade is theoretically analyzed and simulation results demonstrate the filter cascade's performance.

</details>


### [48] [Nonlinear System Identification Nano-drone Benchmark](https://arxiv.org/abs/2512.14450)
*Riccardo Busetto,Elia Cereda,Marco Forgione,Gabriele Maroni,Dario Piga,Daniele Palossi*

Main category: eess.SY

TL;DR: 本文提出了一个基于75,000个真实世界样本的纳米四旋翼飞行器系统辨识基准，提供了多输入多输出、开环不稳定和非线性动力学下的挑战性测试平台，并公开了数据集、脚本和基线模型以促进微型敏捷飞行机器人研究。


<details>
  <summary>Details</summary>
Motivation: 为了推动微型空中机器人在复杂真实环境中的系统辨识研究，需要一个包含真实噪声和执行非线性的标准化基准测试平台。

Method: 使用Crazyflie 2.1纳米四旋翼的真实飞行数据构建包含四个激进轨迹的数据集，包含4维电机输入和13维输出测量，并设计多 horizon 预测指标用于评估不同方法的一致性和误差传播特性。

Result: 发布了包含75k样本的大规模真实系统辨识数据集，配套实验设置说明、评估工具和基线模型，并通过开源方式促进算法透明比较。

Conclusion: 该基准为微型、敏捷飞行器的系统辨识提供了具有挑战性的现实测试平台，有助于推动高精度建模与控制方法的发展。

Abstract: We introduce a benchmark for system identification based on 75k real-world samples from the Crazyflie 2.1 Brushless nano-quadrotor, a sub-50g aerial vehicle widely adopted in robotics research. The platform presents a challenging testbed due to its multi-input, multi-output nature, open-loop instability, and nonlinear dynamics under agile maneuvers. The dataset comprises four aggressive trajectories with synchronized 4-dimensional motor inputs and 13-dimensional output measurements. To enable fair comparison of identification methods, the benchmark includes a suite of multi-horizon prediction metrics for evaluating both one-step and multi-step error propagation. In addition to the data, we provide a detailed description of the platform and experimental setup, as well as baseline models highlighting the challenge of accurate prediction under real-world noise and actuation nonlinearities. All data, scripts, and reference implementations are released as open-source at https://github.com/idsia-robotics/nanodrone-sysid-benchmark to facilitate transparent comparison of algorithms and support research on agile, miniaturized aerial robotics.

</details>


### [49] [Equivariant Observer for Bearing Estimation with Linear and Angular Velocity Inputs](https://arxiv.org/abs/2512.14451)
*Gil Serrano,Marcelo Jacinto,Bruno J. Guerreiro,Rita Cunha*

Main category: eess.SY

TL;DR: 提出了一种在单位球面上具有线性速度输入的等变观测器设计方法，适用于需要稳定方位估计的图像视觉伺服场景。


<details>
  <summary>Details</summary>
Motivation: 为了解决单位球面上一阶动力系统的等变观测器设计问题，特别是在图像视觉伺服中需要考虑载体与目标特征之间相对速度的情况。

Method: 基于角速度输入的单位视线向量动力学，引入投影到单位球面切空间的额外线性速度输入，并利用特殊正交群上的提升运动学设计观测器。

Result: 设计了针对视线向量的等变观测器，证明了其几乎全局渐近稳定性，并展示了如何在原始状态流形上表达该观测器，数值仿真验证了算法的有效性。

Conclusion: 所提出的等变观测器能够有效处理带有线性速度输入的单位球面动力系统，在图像视觉伺服应用中具有良好的稳定性和实用性。

Abstract: This work addresses the problem of designing an equivariant observer for a first order dynamical system on the unit-sphere. Building upon the established case of unit bearing vector dynamics with angular velocity inputs, we introduce an additional linear velocity input projected onto the unit-sphere tangent space. This extended formulation is particularly useful in image-based visual servoing scenarios where stable bearing estimates are required and the relative velocity between the vehicle and target features must be accounted for. Leveraging lifted kinematics to the Special Orthogonal group, we design an observer for the bearing vector and prove its almost global asymptotic stability. Additionally, we demonstrate how the equivariant observer can be expressed in the original state manifold. Numerical simulation results validate the effectiveness of the proposed algorithm.

</details>


### [50] [Closed-Loop Consistent, Causal Data-Driven Predictive Control via SSARX](https://arxiv.org/abs/2512.14510)
*Aihui Liu,Magnus Jansson*

Main category: eess.SY

TL;DR: 提出了一种不依赖Willems基本引理的、基于SSARX预测器的数据驱动预测控制（DDPC）方法，具有因果性和闭环保一致性，在噪声环境下表现良好。


<details>
  <summary>Details</summary>
Motivation: 避免现有数据驱动预测控制方法对Willems基本引理和堆叠Hankel矩阵的依赖，提升方法在实际闭环控制中的适用性与鲁棒性。

Method: 基于多步预测器Subspace-ARX（SSARX），首先通过高阶ARX模型估计预测/观测Markov参数以解耦噪声，再通过回归学习过去到未来的映射，可选加入低秩约束。

Result: 所提方法是严格因果且闭环保一致的，能自然嵌入MPC框架；实验结果表明其在含测量和过程噪声的闭环数据下性能与其他方法相当。

Conclusion: 该DDPC方案无需基本引理和Hankel结构，提供了一种更简洁、实用的数据驱动MPC实现方式，适用于存在噪声的实际系统。

Abstract: We propose a fundamental-lemma-free data-driven predictive control (DDPC) scheme for synthesizing model predictive control (MPC)-like policies directly from input-output data. Unlike the well-known DeePC approach and other DDPC methods that rely on Willems' fundamental lemma, our method avoids stacked Hankel representations and the DeePC decision variable g. Instead, we develop a closed-loop consistent, causal DDPC scheme based on the multi-step predictor Subspace-ARX (SSARX). The method first (i) estimates predictor/observer Markov parameters via a high-order ARX model to decouple the noise, then (ii) learns a multi-step past-to-future map by regression, optionally with a reduced-rank constraint. The SSARX predictor is strictly causal, which allows it to be integrated naturally into an MPC formulation. Our experimental results show that SSARX performs competitively with other methods when applied to closed-loop data affected by measurement and process noise.

</details>


### [51] [Scalable Nonlinear DeePC: Bridging Direct and Indirect Methods and Basis Reduction](https://arxiv.org/abs/2512.14535)
*Thomas O. de Jong,Mircea Lazar,Siep Weiland,Florian Dörfler*

Main category: eess.SY

TL;DR: 本文研究了非线性框架下的正则化数据驱动预测控制（DeePC）及其与子空间预测控制（SPC）的关系，扩展了Π-正则化并提出了提升数据的稀疏基选择方法，在无噪声和有噪声情况下通过仿真验证了DeePC的性能优于或等效于SPC。


<details>
  <summary>Details</summary>
Motivation: 旨在理解DeePC在非线性系统中的表现，并探索其与SPC的理论联系，同时提升算法的可扩展性和抗噪能力。

Method: 将Π-正则化推广到一般基函数，提出基于SVD的降维方法和LASSO稀疏基选择方法，保持与SPC的等价性并提高计算效率。

Result: 在无噪声条件下，适当强的正则化下DeePC与SPC具有相同的跟踪误差；在有噪声时，合理调节正则化可使DeePC的平均绝对误差更低。

Conclusion: DeePC在合适正则化下是SPC的有效推广，在噪声环境下更具优势，结合降维与稀疏基选择可提升其可扩展性。

Abstract: This paper studies regularized data-enabled predictive control (DeePC) within a nonlinear framework and its relationship to subspace predictive control (SPC). The $Π$-regularization is extended to general basis functions and it is shown that, under suitable conditions, the resulting basis functions DeePC formulation constitutes a relaxation of basis functions SPC. To improve scalability, we introduce an SVD-based dimensionality reduction that preserves the equivalence with SPC, and we derive a reduced Π-regularization. A LASSO based sparse basis selection method is proposed to obtain a reduced basis from lifted data. Simulations on a nonlinear van der Pol oscillator model indicate that, in the absence of noise, DeePC and SPC yield equivalent absolute mean tracking errors (AMEs) when large penalties are applied. In contrast, under noisy measurements, careful tuning of the DeePC regularization results in a reduced AME, outperforming SPC.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [52] [Electron-positron pair creation induced by multi-pulse train of electric fields: effect of randomness in time-delay](https://arxiv.org/abs/2512.13722)
*Deepak Sah,Manoranjan P. Singh*

Main category: quant-ph

TL;DR: 研究了在具有随机时间延迟的Sauter-like电场脉冲序列中电子-正电子对（EPP）的产生，发现增加时间延迟的波动性可显著增强中心动量区域的产率，为优化多脉冲场配置和实验设计提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 探索在非均匀、随时间变化的电场脉冲序列中电子-正电子对产生的机制，并理解随机时间延迟对量子干涉效应的影响。

Method: 通过求解量子Vlasov方程，模拟了具有高斯分布随机时间延迟的Sauter-like脉冲序列中的EPP产生过程，并分析了不同延迟波动强度下的纵向动量谱。

Result: 随着时间延迟标准差σ_T的增加，动量谱从类似多缝干涉的条纹转变为具有残余振荡的高斯型包络；在N=20脉冲下，σ_T≈31 [m⁻¹]时中心峰值增强约十倍，σ_T≈50 [m⁻¹]时增强达10³倍。

Conclusion: 随机时间延迟能显著增强电子-正电子对在中心动量区域的产率，表明可通过调控脉冲时序优化EPP产率，为未来实验提供指导。

Abstract: We investigate the creation of electron-positron pairs (EPPs) in a sequence of alternating-sign, time-dependent electric field pulse trains by solving the quantum Vlasov equations. Specifically, we focus on Sauter-like pulse trains with random time delays between successive pulses, drawn from a Gaussian distribution wherein the extent of fluctuations is controlled by the standard deviation $σ_T$ of the distribution. We find that increasing $σ_T$ leads to a dramatic transformation in the longitudinal momentum spectrum. The well-known fringe pattern, akin to that in the multi-slit interference, gets significantly modified. The averaged spectra exhibit a robust Gaussian-like envelope with residual oscillations, which are much more prominent in the central momentum region. Notably, we find that in certain cases, stochastic time delays lead to a pronounced enhancement in the central peak of the distribution function for pulse train containing $N$ pulses. For example, for $N=20$ pulses, $σ_T \approx 31$ $[m^{-1}]$(about $17\%$ of the mean time delay) yields nearly a tenfold increase in the central peak, which for $σ_T \approx 50$ $[m^{-1}]$ (about $27\%$ of the mean time delay), scales up to $10^3.$ This may open up new possibilities for optimizing multi-pulse field configurations and guide future experimental designs aimed at maximizing EPPs creation.

</details>


### [53] [Search Smarter, Not Harder: A Scalable, High-Quality Zoned Neutral Atom Compiler](https://arxiv.org/abs/2512.13790)
*Yannick Stade,Lukas Burgholzer,Robert Wille*

Main category: quant-ph

TL;DR: 提出了一种可扩展的编译策略Iterative Diving Search (IDS)和松弛路由优化，用于千量子比特规模的中性原子量子计算，有效降低内存需求并减少28.1%的原子重排开销。


<details>
  <summary>Details</summary>
Motivation: 现有编译器在扩展到数千量子比特时面临巨大内存需求，难以支持大规模中性原子量子计算系统的发展。

Method: 提出了Iterative Diving Search（IDS）——一种目标导向的搜索算法，避免传统方法的高内存消耗；引入松弛路由优化以减少原子重排开销。

Result: 该方法成功编译了包含数千量子比特的电路，并平均减少了28.1%的重排开销。

Conclusion: 所提出的编译策略具备良好的可扩展性，为大规模中性原子量子计算提供了高效、自动化的解决方案。

Abstract: Zoned neutral atom architectures are emerging as a promising platform for large-scale quantum computing. Their growing scale, however, creates a critical need for efficient and automated compilation solutions. Yet, existing methods fail to scale to the thousands of qubits these devices promise. State-of-the-art compilers, in particular, suffer from immense memory requirements that limit them to small-scale problems. This work proposes a scalable compilation strategy that "searches smarter, not harder". We introduce Iterative Diving Search (IDS), a goal-directed search algorithm that avoids the memory issues of previous methods, and relaxed routing, an optimization to mitigate atom rearrangement overhead. Our evaluation confirms that this approach compiles circuits with thousands of qubits and, in addition, even reduces rearrangement overhead by 28.1% on average. The complete code is publicly available in open-source as part of the Munich Quantum Toolkit (MQT) at https://github.com/munich-quantum-toolkit/qmap.

</details>


### [54] [Quantum simulation using Trotterized disorder Hamiltonians in a single-mode optical cavity](https://arxiv.org/abs/2512.13774)
*Rahel Lea Baumgartner,Pietro Pelliconi,Soumik Bandyopadhyay,Francesca Orsi,Philipp Hauke,Jean-Philippe Brantut,Julian Sonner*

Main category: quant-ph

TL;DR: 提出了一种利用Trotter化方案增强无序密度的方法，并通过单模腔QED平台实现了复杂的Sachdev-Ye-Kitaev模型，分析了有效模型的性质及其对耗散的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决全连接无序多体系统在量子模拟中因辅助自由度导致无序减弱和引入不期望关联的问题。

Method: 采用Trotter化方案来增强模型中的无序密度，并研究由此产生的模型的统计特性及Trotter化误差对时间演化和动力学观测量的影响。

Result: 成功实现复杂Sachdev-Ye-Kitaev模型的有效模拟，揭示了有效耦合分布、相互作用位点数量、态制备以及量子混沌探针行为等特征，并验证了结果对耗散的鲁棒性。

Conclusion: Trotter化方案能有效提升无序密度并减少模拟误差，为在量子平台上模拟全连接无序系统提供了可行路径。

Abstract: All-to-all interacting and disordered many-body systems are notoriously hard to simulate on quantum platforms, as interactions are commonly mediated by auxiliary degrees of freedom that lower the amount of disorder, introducing undesired correlations. In this work, we show how a Trotterization scheme can be effectively utilized to densify the disorder of the model. In particular, we study the statistical properties of the resulting model, as well as Trotterization errors in the simulation that affect the time evolution and dynamical observables. As a concrete example, we propose an implementation via a single-mode cavity QED platform of the complex Sachdev-Ye-Kitaev model. We analyze several features of the effective model, such as the distribution of the effective couplings, the number of interacting sites, state preparation, and the behavior of quantum chaos probes. We conclude this work with a detailed investigation of the robustness of our findings against dissipation, both analytically and numerically.

</details>


### [55] [Transversal Clifford-Hierarchy Gates via Non-Abelian Surface Codes](https://arxiv.org/abs/2512.13777)
*Alison Warman,Sakura Schafer-Nameki*

Main category: quant-ph

TL;DR: 提出了一种基于非阿贝尔表面码的纯二维横向实现任意层级Clifford层次相位门的方法，通过在非阿贝尔群G的量子双D(G)上编码逻辑量子比特，并利用对称保护拓扑相实现横向逻辑门，绕过了Bravyi-König定理的限制。


<details>
  <summary>Details</summary>
Motivation: 克服Bravyi-König定理对在D维Pauli稳定子码上由恒定深度量子电路可实现的酉门局限于Clifford层次第D层的限制，实现在2D中任意层级的横向酉门操作。

Method: 在三角形空间区域上的非阿贝尔群G的量子双D(G)中编码一个逻辑量子比特，通过堆叠由群2-上循环指定的对称保护拓扑(SPT)相来横向实现逻辑门。使用G = D_{4N}（阶为8N的二面体群）时，可在逻辑Z基下实现相位门T^{1/N}。当8N=2^n时，该门位于Clifford层次的第n层，并可通过n个物理量子比特每条晶格边的Clifford层次稳定子构造。

Result: 实现了在2D中无需牺牲局域性或容错性即可横向执行任意层级Clifford层次的酉门；具体实现了T^{1/N}相位门并展示了其在qubit-only系统中的实现方式；讨论了切换到Z_2×Z_2和Z_2环面码的可能性以用于量子纠错。

Conclusion: 通过使用非阿贝尔群的量子双和SPT相，成功绕开Bravyi-König定理的限制，在2D中实现了任意层级的横向相位门，同时保持了局域性和容错性，为容错量子计算提供了新路径。

Abstract: We present a purely 2D transversal realization of phase gates at any level of the Clifford hierarchy, and beyond, using non-Abelian surface codes. Our construction encodes a logical qubit in the quantum double $D(G)$ of a non-Abelian group $G$ on a triangular spatial patch. The logical gate is implemented transversally by stacking on the spatial region a symmetry-protected topological (SPT) phase specified by a group 2-cocycle. The Bravyi--König theorem limits the unitary gates implementable by constant-depth quantum circuits on Pauli stabilizer codes in $D$ dimensions to the $D$-th level of the Clifford hierarchy. We bypass this, by constructing transversal unitary gates at arbitrary levels of the Clifford hierarchy purely in 2D, without sacrificing locality or fault tolerance, however at the cost of using the quantum double of a non-Abelian group $G$. Specifically, for $G = D_{4N}$, the dihedral group of order $8N$, we realize the phase gate $T^{1/N} = \mathrm{diag}(1, e^{iπ/(4N)})$ in the logical $\overline{Z}$ basis. For $8N = 2^n$, this gate lies at the $n$-th level of the Clifford hierarchy and, importantly, has a qubit-only realization: we show that it can be constructed in terms of Clifford-hierarchy stabilizers for a code with $n$ physical qubits on each edge of the lattice. We also discuss code-switching to the $\mathbb{Z}_2 \times \mathbb{Z}_2$ and $\mathbb{Z}_2$ toric codes, which can be utilized for the quantum error correction in this setup.

</details>


### [56] [Freeness Reined in by a Single Qubit](https://arxiv.org/abs/2512.13803)
*Alexander Altland,Francisco Divi,Tobias Micklitz,Maedeh Rezaei*

Main category: quant-ph

TL;DR: 研究了在最小偏离自由性的情况下，即单个辅助量子比特与高维Haar分布量子电路耦合时，自由概率理论框架的鲁棒性。发现即使在这种情况下，自由概率理论预测的相关函数仍存在O(1)量级的修正，并且这些修正在系统动力学已变为遍历时仍然持续。


<details>
  <summary>Details</summary>
Motivation: 探讨复杂量子系统中非对易可观测量之间的相关性在偏离自由性条件下的行为，特别是当引入一个辅助量子比特时自由概率理论的有效性和局限性。

Method: 通过分析单个辅助量子比特与高维Haar分布量子电路耦合的情况，结合解析推导和数值模拟，研究相关函数的变化及其来源。

Result: 发现相关函数的预测存在O(1)量级的修正，这些修正源于非均匀分布的定态量子态，并在长时间尺度上依然存在。

Conclusion: 即使在接近自由性的条件下，自由概率理论也需要考虑显著的修正项，这表明其在实际复杂量子系统中的应用需要更加谨慎。

Abstract: Free probability provides a framework for describing correlations between non-commuting observables in complex quantum systems whose Hilbert-space states follow maximum-entropy distributions. We examine the robustness of this framework under a minimal deviation from freeness: the coupling of a single ancilla qubit to a Haar-distributed quantum circuit of dimension $D0 \gg 1$. We find that, even in this setting, the correlation functions predicted by free probability theory receive corrections of order $O(1)$. These modifications persist at long times, when the dynamics of the coupled system is already ergodic. We trace their origin to non-uniformly distributed stationary quantum states, which we characterize analytically and confirm numerically.

</details>


### [57] [Discrete time crystals enabled by Floquet strong Hilbert space fragmentation](https://arxiv.org/abs/2512.14182)
*Ling-Zhi Tang,Xiao Li,Z. D. Wang,Dan-Wei Zhang*

Main category: quant-ph

TL;DR: 本研究在无序自由的周期性驱动XXZ自旋链中探索了离散时间晶体（DTC），揭示了由于Floquet强希尔伯特空间碎片化导致的周期倍增和多周期响应，并通过数值和解析方法证实了DTC的稳定性机制。


<details>
  <summary>Details</summary>
Motivation: 探索无序自由系统中离散时间晶体的稳定机制，理解Floquet强希尔伯特空间碎片化对非平衡物相的影响。

Method: 采用数值模拟和解析分析相结合的方法，研究周期性驱动的XXZ自旋链中的DTC行为，利用Floquet理论分析谱结构和对称性子空间维度比。

Result: 发现了常规DTC的周期倍增响应以及由多个π对相干相互作用引起的多周期拍频动力学；DTC寿命与驱动频率无关，且随ZZ相互作用强度呈幂律依赖，随系统尺寸指数增长；揭示了磁化强度和畴壁数在Floquet算符下的近似守恒。

Conclusion: Floquet希尔伯特空间碎片化是一种无需无序即可维持非平凡时间序的有效机制，为非平衡量子多体系统中的时序物相提供了新见解。

Abstract: Discrete time crystals (DTCs) are non-equilibrium phases of matter that break the discrete time-translation symmetry and is characterized by a robust subharmonic response in periodically driven quantum systems. Here, we explore the DTC in a disorder-free, periodically kicked XXZ spin chain, which is stabilized by the Floquet strong Hilbert space fragmentation. We numerically show the period-doubling response of the conventional DTC order, and uncover a multiple-period response with beating dynamics due to the coherent interplay of multiple $π$-pairs in the Floquet spectrum of small-size systems. The lifetime of the DTC order exhibits independence of the driving frequency and a power-law dependence on the ZZ interaction strength. It also grows exponentially with the system size, as a hallmark of the strong fragmentation inherent to the Floquet model. We analytically reveal the approximate conservation of the magnetization and domain-wall number in the Floquet operator for the emergent strong fragmentation, which is consistent with numerical results of the dimensionality ratio of symmetry subspaces. The rigidity and phase regime of the DTC order are identified through finite-size scaling of the Floquet-spectrum-averaged mutual information, as well as via dynamical probes. Our work establishes the Floquet Hilbert space fragmentation as a disorder-free mechanism for sustaining nontrivial temporal orders in out-of-equilibrium quantum many-body systems.

</details>


### [58] [Universal Statistics of Measurement-Induced Entanglement in Tomonaga-Luttinger liquids](https://arxiv.org/abs/2512.13809)
*Kabir Khanna,Romain Vasseur*

Main category: quant-ph

TL;DR: 研究了一维量子临界态中测量诱导纠缠的统计特性，利用复制技巧和共形场论工具推导出纠缠矩的闭式表达式，并发现低能下测量结果的平均等价于共形边界条件的加权平均，预言了临界行为和后测量纠缠熵分布的双峰及厚尾特征，理论预测与数值计算结果吻合良好。


<details>
  <summary>Details</summary>
Motivation: 探索在Tomonaga-Luttinger液体描述的一维量子临界态中，部分测量如何诱导纠缠，并理解其统计行为特别是在低能极限下的普适性质。

Method: 采用复制技巧对电荷基中的测量结果进行平均，并结合共形场论（CFT）工具推导纠缠各阶矩的闭式表达式，将微观测量结果的Born平均映射为共形边界条件的加权平均。

Result: 得到了MIE各阶矩的闭式表达式，发现在未测量部分极大分离时所有矩均呈现独特的临界行为；获得了后测量纠缠熵的完整分布，显示其通常为双峰且具有厚尾特征；数值计算验证了理论预测。

Conclusion: 测量诱导纠缠的统计特性在低能下可由共形场论有效描述，测量平均等价于对共形边界条件的加权平均，揭示了量子测量下纠缠分布的普适临界行为。

Abstract: We study the statistics of measurement-induced entanglement (MIE) after partial measurement on a class of one-dimensional quantum critical states described by Tomonaga-Luttinger liquids at low energies. Using a replica trick to average over measurement outcomes in the charge basis and tools from conformal field theory (CFT), we derive closed-form expressions for the cumulants of MIE. We show that exact Born-averaging over microscopic measurement outcomes becomes equivalent at low energy to averaging over conformal boundary conditions weighted by their corresponding partition functions. Our results yield distinctive critical behavior across all cumulants in the regime where the unmeasured parts of the system are maximally separated. We also obtain the full distribution of the post-measurement entanglement entropy, finding that it is generically bimodal and exhibits fat-tails. We corroborate our analytical predictions by numerical calculations and find good agreement between them.

</details>


### [59] [Fractional decay in the spontaneous emission of a two-level system](https://arxiv.org/abs/2512.13817)
*Hiroki Nakabayashi,Hayato Kinkawa,Takano Taira,Naomichi Hatano*

Main category: quant-ph

TL;DR: 研究发现，在具有能量谱下界但无上界的环境中，双能级系统的自发辐射存活概率在短时间和长时间范围内分别按 $1-αt^{2-D/n}$ 和 $αt^{D/n-2}$ 的形式随空间维度 $D$ 和能量色散指数 $n$ 变化，导致具有不同时间尺度的量子芝诺效应。


<details>
  <summary>Details</summary>
Motivation: 探索环境能量谱特性对双能级系统动力学行为的影响，特别是存活概率的时间演化规律。

Method: 理论分析双能级系统与具有特定能量色散关系的无上界环境之间的相互作用，并推导存活概率在短时间和长时间极限下的标度行为。

Result: 存活概率在短时间为 $1-αt^{2-D/n}$，长时间为 $αt^{D/n-2}$，揭示了依赖于 $D$ 和 $n$ 的分数标度律，并表明量子芝诺时间呈现新的标度关系。

Conclusion: 环境的能量谱结构显著影响双能级系统的演化动力学，导致非传统的量子芝诺效应标度行为。

Abstract: We find that when the environment of a two-level system has an energy spectrum with a lower bound but without an upper one, the survival probability of the spontaneous emission of the two-level system scales with the spatial dimension $D$ and the exponent $n$ of the energy dispersion $|\vec{k}|^n$ of the environment in the form $1-αt^{2-D/n}$ in the short-time and in the form $αt^{D/n-2}$ in the long-time regime. The former fractional scaling of the survival probability leads to a quantum Zeno effect with a different scaling of the Zeno time.

</details>


### [60] [Impact of Information on Quantum Heat Engines](https://arxiv.org/abs/2512.13371)
*Lindsay Bassman Oftelie,Michele Campisi*

Main category: quant-ph

TL;DR: 本文提出了一种通用的两冲程量子热机框架，其中麦克斯韦妖通过投影测量和经典记忆实现反馈控制，将机器与记忆视为混合系统，从而统一处理信息与热力学过程。研究发现，并非总是信息越多性能越好，有时“知之较少”反而更优。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对反馈控制量子热机的统一理论框架，且信息作为资源在量子热力学中的作用尚需深入理解，特别是麦克斯韦妖悖论在量子体系中的解决仍不完善。

Method: 构建一个包含N个热库和麦克斯韦妖的通用两冲程量子热机模型；妖通过对工作物质进行投影测量并将结果存储于嵌入热库的经典记忆中，实施基于测量结果的条件性幺正操作以实现反馈控制；将机器-记忆复合系统视为与N+1个热库相互作用的混合（经典-量子）标准热机。

Result: 提出了适用于反馈控制量子热机的通用框架，为麦克斯韦悖论提供了清晰的解释；通过双量子比特引擎示例验证了该框架的有效性；发现更多信息并不总能提升热力学性能，存在‘知之较少反而更好’的现象。

Conclusion: 信息在量子热机中是一种关键资源，但其利用需权衡热力学代价；本文框架将工作物质与记忆统一处理，为量子反馈控制热机提供了普适描述，并揭示了信息与热力学性能之间的非单调关系。

Abstract: The emerging field of quantum thermodynamics is beginning to reveal the intriguing role that information can play in quantum thermal engines. Information enters as a resource when considering feedback-controlled thermal machines. While both a general theory of quantum feedback control as well as specific examples of quantum feedback-controlled engines have been presented, still lacking is a general framework for such machines. Here, we present a framework for a generic, two-stroke quantum heat engine interacting with $N$ thermal baths and Maxwell's demon. The demon performs projective measurements on the engine working substance, the outcome of which is recorded in a classical memory, embedded in its own thermal bath. To perform feedback control, the demon enacts unitary operations on the working substance, conditioned on the recorded outcome. By considering the compound machine-memory as a hybrid (classical-quantum) standard thermal machine interacting with $N+1$ thermal baths, our framework puts the working substance and memory on equal footing, thereby enabling a comprehensible resolution to Maxwell's paradox. We illustrate the application of our framework with a two-qubit engine. A remarkable observation is that more information does not necessarily result in better thermodynamic performance: sometimes knowing less is better.

</details>


### [61] [Microwave-free vector magnetometry and crystal orientation determination with Nitrogen-Vacancy centers using Bayesian inference](https://arxiv.org/abs/2512.13835)
*Hilario Espinós,Omkar Dhungel,Arne Wickenbrock,Dmitry Budker,Ricardo Puebla,Erik Torrontegui*

Main category: quant-ph

TL;DR: 提出了一种无需微波、在近零场条件下实现矢量磁力测量的通用框架，利用贝叶斯推断从光致发光图中直接提取磁场矢量和NV中心取向，结合交叉弛豫共振的解析模型，实现了鲁棒的方向确定和矢量场重建，为紧凑型、免对准的NV磁力计提供了可行路径。


<details>
  <summary>Details</summary>
Motivation: 克服传统NV中心量子传感中依赖微波导致的加热和电磁干扰问题，并解决光学方法中需严格对准晶轴限制实用性的问题。

Method: 基于不同取向NV中心之间的交叉弛豫现象，构建解析的共振模型，并结合贝叶斯推断方法，从光致发光图中直接反演出磁场矢量和NV中心的取向信息，适用于任意外场和取向配置。

Result: 实验上成功实现了无需微波的矢量磁场测量，能够鲁棒地确定NV中心取向并重建外部磁场矢量，且不受晶体取向严格对准的限制。

Conclusion: 该研究建立了一种通用、紧凑且无需对准的NV磁力测量方案，为实际应用中的无扰动量子传感提供了新途径。

Abstract: Nitrogen-vacancy (NV) centers in diamond provide a solid-state platform for quantum sensing. While optically detected magnetic resonance techniques offer high sensitivity, their reliance on microwaves introduces heating and stray electromagnetic fields that can perturb nearby samples. Optical approaches based on cross-relaxation between differently oriented NV centers remove this constraint but have so far required stringent alignment of the external field with crystallographic axes, restricting their practicality. Here we introduce a general framework for microwave-free vector magnetometry at near-zero field that leverages Bayesian inference to extract both the magnetic field vector and the NV orientation directly from photoluminescence maps. An analytical model of cross-relaxation resonances enables efficient inference under arbitrary field and orientation configurations, while naturally incorporating the discrete degeneracies of the NV symmetry. We experimentally demonstrate robust orientation determination and vector-field reconstruction, establishing a general route toward compact and alignment-free NV magnetometers for practical sensing applications.

</details>


### [62] [Achieving $10^{-5}$ level relative intensity crosstalk in optical holographic qubit addressing via a double-pass digital micromirror device](https://arxiv.org/abs/2512.13882)
*Shilpa Mahato,Rajibul Islam*

Main category: quant-ph

TL;DR: 提出了一种基于数字微镜器件（DMD）双通配置的全光束整形方案，通过傅里叶平面全息与图像平面空间滤波结合，有效抑制了邻近位点的强度串扰和远场背景光，实现串扰≤10⁻⁵、远场背景≈10⁻⁶，适用于离子阱等量子系统。


<details>
  <summary>Details</summary>
Motivation: 传统全息光束整形在原子量子比特控制中存在邻近位点串扰和远场背景光问题，导致多量子比特误差累积，限制了其应用精度和可扩展性。

Method: 采用单个DMD在双通配置下工作：第一通在傅里叶平面使用二值振幅全息图实现独立寻址；第二通在中间像平面利用不同区域作为可编程孔径进行空间滤波。通过复用傅里叶平面全息图生成辅助弱场，与非目标区域的杂散光相消干涉，同时像平面滤波抑制远距离残余光尾。

Result: 在整个相关视场内将相对强度串扰控制在10⁻⁵（-50 dB）或以下，远场背景进一步降低至约10⁻⁶，接近探测极限。

Conclusion: 该方法提供了一种紧凑、低串扰的DMD基全息光学寻址解决方案，可直接应用于离子阱及其他空间有序量子系统。

Abstract: Holographic beam shaping is a powerful approach for generating individually addressable optical spots for controlling atomic qubits, such as those in trapped-ion quantum processors. However, its application in qubit control is limited by residual intensity crosstalk at neighboring sites and by a nonzero background floor in the far wings of the addressing beam, leading to accumulated errors from many exposed qubits. Here, we present an all-optical scheme that mitigates both effects using a single digital micromirror device (DMD) operated in a double-pass configuration, in which light interacts with two separate regions of the same device. In the first pass, one region of the DMD is placed in a Fourier plane and implements a binary-amplitude hologram for individual addressing, while in the second pass a different region serves as a programmable intermediate image-plane aperture for spatial filtering. By multiplexing the Fourier-plane hologram to include secondary holograms, we generate weak auxiliary fields that interfere destructively with unwanted light at selected sites, while image-plane filtering suppresses the residual tail at larger distances. Together, these techniques maintain relative intensity crosstalk at or below $10^{-5}$ ($-50\,\mathrm{dB}$) across the full field of view relevant for qubit addressing, and further reduce the far-wing background to approximately $10^{-6}$ at large distances from the addressed qubit, approaching the detection limit. These results provide a compact, DMD-based solution for low-crosstalk optical holographic qubit addressing that is directly applicable to trapped ions and other spatially ordered quantum systems.

</details>


### [63] [Reading Qubits with Sequential Weak Measurements: Limits of Information Extraction](https://arxiv.org/abs/2512.14583)
*Cesar Lema,Aleix Bou-Comas,Atithi Acharya,Vadim Oganesyan,Anirvan Sengupta*

Main category: quant-ph

TL;DR: 该论文研究了基于弱测量的量子轨迹中的信息物理，旨在优化单量子比特读出的性能，分析了两种实际模型下的信息提取极限和最佳测量时长。


<details>
  <summary>Details</summary>
Motivation: 为了在存在弱测量和内在动力学的情况下实现高精度的量子比特配置读出，需要理解初始状态信息如何被编码在测量记录中，并确定可达到的最佳性能。

Method: 使用互信息来量化测量记录中包含的关于初始状态的信息量，结合离散时间步长方法和连续极限下的随机主方程，发展了测量效率参数的渐近展开方法进行计算。

Result: 发现信息提取存在互信息平台现象，获得了信息提取的上限以及达到该上限所需的最佳测量时长，且结果适用于不同测量强度、记录时长和内在动力学强度的情况。

Conclusion: 研究成果有助于提升当前NISQ设备中量子比特读出的性能，对量子器件优化及机器学习辅助读出方法具有应用价值。

Abstract: Quantum information processing and computation requires high accuracy qubit configuration readout. In many practical schemes, the initial qubit configuration has to be inferred from readout that is a time-dependent weak measurement record. However, a combination of the measurement scheme and intrinsic dynamics can end up scrambling the initial state and lose information irretrievably. Here, we study the information physics of quantum trajectories based on weak measurements in order to address the optimal achievable performance in qubit configuration readout for two realistic models of single qubit readout: (i) Model I is informationally complete, but without intrinsic dynamics; (ii) Model II is informationally incomplete weak measurements with intrinsic dynamics. We first use mutual information to characterize how much intrinsic information about the initial state is encoded in the measurement record. Using a fixed discrete time-step formulation, we compute the mutual information while varying the measurement strength, duration of measurement record, and the relative strength of intrinsic dynamics in our measurement schemes. We also exploit the emergence of continuum scaling and the Stochastic Master Equation in the weak measurement limit. We develop an asymptotic expansion in the measurement efficiency parameter to calculate mutual information, which captures qualitative and quantitative features of the numerical data. The bounds on information extraction are manifested as plateaux in mutual information, our analysis obtains these bounds and also optimal duration of measurement required to saturate them. Our results should be useful both for quantum device operation and optimization and also, possibly, for improving the performance of recent machine learning approaches for qubit and multiqubit configuration readout in current Noisy Intermediate-Scale Quantum (NISQ) experiment regimes.

</details>


### [64] [Group-Theoretic Reinforcement Learning of Dynamical Decoupling Sequences](https://arxiv.org/abs/2512.13890)
*Charles Marrder,Shuo Sun,Murray J. Holland*

Main category: quant-ph

TL;DR: 提出了一种基于强化学习的脉冲序列设计方法，用于在未知噪声谱的情况下最小化量子比特的去相位。


<details>
  <summary>Details</summary>
Motivation: 在实际噪声谱下，寻找最优脉冲时序仍具挑战性，传统解析方法受限于对噪声模型的依赖。

Method: 利用源自Thompson群F的新型动作集，结合强化学习算法，使智能体能在非凸优化空间中高效搜索最优脉冲序列。

Result: 强化学习智能体能够在无需先验噪声信息的情况下学习到有效抑制去相位的脉冲序列，并在存在脉冲误差或非高斯噪声等未建模效应时仍保持潜力。

Conclusion: 该方法为实现实时、自适应的量子比特动力学解耦控制提供了可行路径，具有模型无关性和实际应用前景。

Abstract: Dynamical decoupling seeks to mitigate phase decoherence in qubits by applying a carefully designed sequence of effectively instantaneous electromagnetic pulses. Although analytic solutions exist for pulse timings that are optimal under specific noise regimes, identifying the optimal timings for a realistic noise spectrum remains challenging. We propose a reinforcement learning (RL)-based method for designing pulse sequences on qubits. Our novel action set enables the RL agent to efficiently navigate this inherently non-convex optimization landscape. The action set, derived from Thompson's group $F$, is applicable to a broad class of sequential decision problems whose states can be represented as bounded sequences. We demonstrate that our RL agent can learn pulse sequences that minimize dephasing without requiring explicit knowledge of the underlying noise spectrum. This work opens the possibility for real-time learning of optimal dynamical decoupling sequences on qubits which are dephasing-limited. The model-free nature of our algorithm suggests that the agent may ultimately learn optimal pulse sequences even in the presence of unmodeled physical effects, such as pulse errors or non-Gaussian noise.

</details>


### [65] [Implementing the Koopman-von Neumann approach on continuous-variable photonic quantum computers](https://arxiv.org/abs/2512.13887)
*Xinfeng Gao,Olivier Pfister,Stefan Bekiranov*

Main category: quant-ph

TL;DR: 本文探讨了Koopman-von Neumann (KvN) 方法在连续变量光量子计算架构上的实现，利用量子模拟高效求解非线性动力学问题，并通过谐振子和一维非线性偏微分方程验证其可行性。


<details>
  <summary>Details</summary>
Motivation: 将经典力学的KvN形式映射到量子计算平台，以利用量子算法的优势模拟复杂经典动力系统，特别是难以解析处理的非线性动力学问题。

Method: 采用KvN希尔伯特空间框架，使用类薛定谔方程描述经典波函数演化，并在连续变量光量子计算架构中实现该方法，利用量子线路模拟谐振子和非线性偏微分方程的动力学。

Result: 成功实现了KvN方法在两个典型问题上的量子模拟：谐振子和1D非线性动力学PDE，验证了该方法在光量子平台上的可行性和正确性。

Conclusion: KvN方法结合连续变量量子计算为经典系统模拟提供了有效路径，尤其适用于采样和求解传统方法难以处理的非线性动力学问题，展示了经典-量子混合计算的潜力。

Abstract: The Koopman-von Neumann (KvN) formalism recasts classical mechanics in a Hilbert space framework using complex wavefunctions and linear operators, akin to quantum mechanics. Instead of evolving probability densities in phase space (as in Liouville's equation), KvN uses a Schrödinger-like equation for a classical wavefunction, with commuting position and momentum operators. Mapped to quantum computing, KvN offers a promising route to simulate classical dynamical systems using quantum algorithms by leveraging unitary evolution and quantum linear algebra tools, potentially enabling efficient classical-to-quantum mappings without invoking full quantum uncertainty. In this work, we specifically explore the implementation of the KvN approach on continuous-variable photonic quantum computing architectures, with the goals of leveraging quantum simulation for both sampling and computing intractable nonlinear dynamics. We will demonstrate its implementation and feasibility with two problems: the harmonic oscillator and a 1D partial differential equation governing nonlinear dynamics.

</details>


### [66] [Quantum Anticodes](https://arxiv.org/abs/2512.13891)
*ChunJun Cao,Giuseppe Cotardo,Brad Lackey*

Main category: quant-ph

TL;DR: 本文提出了一种用于量子纠错码的辛框架，通过反码视角分析局部结构，涵盖了稳定子码和子系统码等多种量子码家族，扩展了广义距离的概念，并引入了新的不变量来捕捉局部代数和组合特征。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和分析量子纠错码的局部结构，本文旨在建立一个统一的辛框架，将反码概念引入量子领域。

Method: 将量子码视为辛空间，利用反码作为最大辛子空间来研究其在特定分量上的消失性质，从而定义新的操作如穿孔和缩短，并推导出相应的代数解释。

Result: 该框架不仅涵盖多种已知量子码类型，还提供了对清洗引理和互补恢复等现象的代数解释，并给出了权重枚举子的新描述。

Conclusion: 所提出的辛框架为量子纠错码提供了新的结构性视角，揭示了局部代数与组合特性之间的联系，并促进了对关键量子纠错现象的理解。

Abstract: This work introduces a symplectic framework for quantum error correcting codes in which local structure is analyzed through an anticode perspective. In this setting, a code is treated as a symplectic space, and anticodes arise as maximal symplectic subspaces whose elements vanish on a prescribed set of components, providing a natural quantum analogue of their classical counterparts. This framework encompasses several families of quantum codes, including stabilizer and subsystem codes, provides a natural extension of generalized distances in quantum codes, and yields new invariants that capture local algebraic and combinatorial features. The notion of anticodes also naturally leads to operations such as puncturing and shortening for symplectic codes, which in turn provide algebraic interpretations of key phenomena in quantum error correction, such as the cleaning lemma and complementary recovery and yield new descriptions of weight enumerators.

</details>


### [67] [Regulated reconstruction of long-time spin--boson dynamics and emergent zero-bias transverse measurement primitive](https://arxiv.org/abs/2512.13900)
*Dragomir Davidovic*

Main category: quant-ph

TL;DR: 提出了一种基于Davies参考半群的调控与部分重求和方法，通过非马尔可夫密度矩阵关联函数重构动力学映射，解决了TCL主方程在长时间下的发散问题，并在无偏自旋-玻色模型中发现了一种由干涉效应引起的横向测量基元。


<details>
  <summary>Details</summary>
Motivation: TCL主方程在长时间和强关联 regime 下会出现发散问题，传统微扰方法失效，需发展新的非马尔可夫动力学重构方法。

Method: 围绕Davies参考半群，构建一个受调控且部分重求和的动力学映射，引入保持有界的非马尔可夫密度矩阵关联函数C(t)，并在旋转波近似下进行精确求解验证。

Result: 该方法有效抑制了生成元的长期增长，在无偏自旋-玻色模型中揭示了一种由浴记忆和逆旋转项诱导的相位锁定现象，导致σ_x本征空间间的相对相位在有限时间t_P内被不可逆擦除，形成有效的横向测量通道。

Conclusion: 发现的横向测量基元源于非马尔可夫干涉效应，不依赖先验假设的基底，且在旋转波近似和Davies弱耦合极限下消失，证明其本质是非马尔可夫性的结果。

Abstract: Time--convolutionless (TCL) master equations can break down at long times: time-local perturbative generators develop secular growth in correlation-dominated regimes. We mitigate this by a regulated, partially resummed reconstruction of the dynamical map around a Davies reference semigroup, expressed through a non--Markovian density-matrix correlator C(t) that remains bounded at late times. An exactly solvable rotating-wave benchmark links generator growth to interference-induced near-zeros of the coherence and shows how the reconstruction regulates the map. Applying the method to the unbiased spin--boson model reveals an emergent transverse measurement primitive: bath memory and counter--rotating terms induce phase lock-in that irreversibly erases the relative phase between $σ_x$ eigenspaces on a finite timescale $t_P$, yielding an effective zero-bias transverse ($σ_x$) measurement channel. The selected transverse basis is not assumed a priori; it follows from the reconstructed reduced dynamics. The effect disappears in the rotating-wave approximation and in the Davies weak-coupling limit, demonstrating its non--Markovian interference origin.

</details>


### [68] [Magic state cultivation on a superconducting quantum processor](https://arxiv.org/abs/2512.13908)
*Emma Rosenfeld,Craig Gidney,Gabrielle Roberts,Alexis Morvan,Nathan Lacroix,Dvir Kafri,Jeffrey Marshall,Ming Li,Volodymyr Sivak,Dmitry Abanin,Amira Abbas,Rajeev Acharya,Laleh Aghababaie Beni,Georg Aigeldinger,Ross Alcaraz,Sayra Alcaraz,Trond I. Andersen,Markus Ansmann,Frank Arute,Kunal Arya,Walt Askew,Nikita Astrakhantsev,Juan Atalaya,Ryan Babbush,Brian Ballard,Joseph C. Bardin,Hector Bates,Andreas Bengtsson,Majid Bigdeli Karimi,Alexander Bilmes,Simon Bilodeau,Felix Borjans,Jenna Bovaird,Dylan Bowers,Leon Brill,Peter Brooks,Michael Broughton,David A. Browne,Brett Buchea,Bob B. Buckley,Tim Burger,Brian Burkett,Nicholas Bushnell,Jamal Busnaina,Anthony Cabrera,Juan Campero,Hung-Shen Chang,Silas Chen,Zijun Chen,Ben Chiaro,Liang-Ying Chih,Agnetta Y. Cleland,Bryan Cochrane,Matt Cockrell,Josh Cogan,Paul Conner,Harold Cook,Rodrigo G. Cortiñas,William Courtney,Alexander L. Crook,Ben Curtin,Martin Damyanov,Sayan Das,Dripto M. Debroy,Sean Demura,Paul Donohoe,Ilya Drozdov,Andrew Dunsworth,Valerie Ehimhen,Alec Eickbusch,Aviv Moshe Elbag,Lior Ella,Mahmoud Elzouka,David Enriquez,Catherine Erickson,Lara Faoro,Vinicius S. Ferreira,Marcos Flores,Leslie Flores Burgos,Sam Fontes,Ebrahim Forati,Jeremiah Ford,Brooks Foxen,Masaya Fukami,Alan Wing Lun Fung,Lenny Fuste,Suhas Ganjam,Gonzalo Garcia,Christopher Garrick,Robert Gasca,Helge Gehring,Robert Geiger,Élie Genois,William Giang,Dar Gilboa,James E. Goeders,Edward C. Gonzales,Raja Gosula,Stijn J. de Graaf,Alejandro Grajales Dau,Dietrich Graumann,Joel Grebel,Alex Greene,Jonathan A. Gross,Jose Guerrero,Loïck Le Guevel,Tan Ha,Steve Habegger,Tanner Hadick,Ali Hadjikhani,Michael C. Hamilton,Monica Hansen,Matthew P. Harrigan,Sean D. Harrington,Jeanne Hartshorn,Stephen Heslin,Paula Heu,Oscar Higgott,Reno Hiltermann,Jeremy Hilton,Hsin-Yuan Huang,Mike Hucka,Christopher Hudspeth,Ashley Huff,William J. Huggins,Lev B. Ioffe,Evan Jeffrey,Shaun Jevons,Zhang Jiang,Xiaoxuan Jin,Chaitali Joshi,Pavol Juhas,Andreas Kabel,Hui Kang,Kiseo Kang,Amir H. Karamlou,Ryan Kaufman,Kostyantyn Kechedzhi,Tanuj Khattar,Mostafa Khezri,Seon Kim,Paul V. Klimov,Can M. Knaut,Bryce Kobrin,Alexander N. Korotkov,Fedor Kostritsa,John Mark Kreikebaum,Ryuho Kudo,Ben Kueffler,Arun Kumar,Vladislav D. Kurilovich,Vitali Kutsko,Tiano Lange-Dei,Brandon W. Langley,Pavel Laptev,Kim-Ming Lau,Emma Leavell,Justin Ledford,Joy Lee,Kenny Lee,Brian J. Lester,Wendy Leung,Lily Li,Wing Yan Li,Alexander T. Lill,William P. Livingston,Matthew T. Lloyd,Aditya Locharla,Laura De Lorenzo,Erik Lucero,Daniel Lundahl,Aaron Lunt,Sid Madhuk,Aniket Maiti,Ashley Maloney,Salvatore Mandrà,Leigh S. Martin,Orion Martin,Eric Mascot,Paul Masih Das,Dmitri Maslov,Melvin Mathews,Cameron Maxfield,Jarrod R. McClean,Matt McEwen,Seneca Meeks,Anthony Megrant,Kevin C. Miao,Zlatko K. Minev,Reza Molavi,Sebastian Molina,Shirin Montazeri,Charles Neill,Michael Newman,Anthony Nguyen,Murray Nguyen,Chia-Hung Ni,Murphy Yuezhen Niu,Nicholas Noll,Logan Oas,William D. Oliver,Raymond Orosco,Kristoffer Ottosson,Alice Pagano,Agustin Di Paolo,Sherman Peek,David Peterson,Alex Pizzuto,Elias Portoles,Rebecca Potter,Orion Pritchard,Michael Qian,Chris Quintana,Ganesh Ramachandran,Arpit Ranadive,Matthew J. Reagor,Rachel Resnick,David M. Rhodes,Daniel Riley,Roberto Rodriguez,Emma Ropes,Lucia B. De Rose,Eliott Rosenberg,Dario Rosenstock,Elizabeth Rossi,Pedram Roushan,David A. Rower,Robert Salazar,Kannan Sankaragomathi,Murat Can Sarihan,Max Schaefer,Sebastian Schroeder,Henry F. Schurkus,Aria Shahingohar,Michael J. Shearn,Aaron Shorter,Noah Shutty,Vladimir Shvarts,Spencer Small,W. Clarke Smith,David A. Sobel,Barrett Spells,Sofia Springer,George Sterling,Jordan Suchard,Aaron Szasz,Alexander Sztein,Madeline Taylor,Jothi Priyanka Thiruraman,Douglas Thor,Dogan Timucin,Eifu Tomita,Alfredo Torres,M. Mert Torunbalci,Hao Tran,Abeer Vaishnav,Justin Vargas,Sergey Vdovichev,Guifre Vidal,Benjamin Villalonga,Catherine Vollgraff Heidweiller,Meghan Voorhees,Steven Waltman,Jonathan Waltz,Shannon X. Wang,Danni Wang,Brayden Ware,James D. Watson,Yonghua Wei,Travis Weidel,Theodore White,Kristi Wong,Bryan W. K. Woo,Christopher J. Wood,Maddy Woodson,Cheng Xing,Z. Jamie Yao,Ping Yeh,Bicheng Ying,Juhwan Yoo,Noureldin Yosri,Elliot Young,Grayson Young,Adam Zalcman,Ran Zhang,Yaxing Zhang,Ningfeng Zhu,Nicholas Zobrist,Zhenjie Zou,Hartmut Neven,Sergio Boixo,Cody Jones,Julian Kelly,Alexandre Bourassa,Kevin J. Satzinger*

Main category: quant-ph

TL;DR: 本研究在超导量子处理器上实验验证了魔态培育技术，通过容错测量协议实现了高达0.9999的魔态保真度，错误率降低40倍，证明其是解决非Clifford门资源开销问题的有效途径。


<details>
  <summary>Details</summary>
Motivation: 非Clifford门在容错量子计算中资源开销大，传统蒸馏协议成本高，亟需高效替代方案。

Method: 在超导量子处理器上实现魔态培育，结合码切换至表面码，并设计容错测量协议以限制魔态保真度。

Result: 错误率降低40倍，魔态保真度达到0.9999(1)，但仅保留8%的尝试成功率。

Conclusion: 实验结果验证了魔态培育作为解决量子计算中非Clifford门资源瓶颈的可行方案。

Abstract: Fault-tolerant quantum computing requires a universal gate set, but the necessary non-Clifford gates represent a significant resource cost for most quantum error correction architectures. Magic state cultivation offers an efficient alternative to resource-intensive distillation protocols; however, testing the proposal's assumptions represents a challenging departure from quantum memory experiments. We present an experimental study of magic state cultivation on a superconducting quantum processor. We implement cultivation, including code-switching into a surface code, and develop a fault-tolerant measurement protocol to bound the magic state fidelity. Cultivation reduces the error by a factor of 40, with a state fidelity of 0.9999(1) (retaining 8% of attempts). Our results experimentally establish magic state cultivation as a viable solution to one of quantum computing's most significant challenges.

</details>


### [69] [Q-IRIS: The Evolution of the IRIS Task-Based Runtime to Enable Classical-Quantum Workflows](https://arxiv.org/abs/2512.13931)
*Narasinga Rao Miniskar,Mohammad Alaul Haque Monil,Elaine Wong,Vicente Leyton-Ortega,Jeffrey S. Vetter,Seth R. Johnson,Travis S. Humble*

Main category: quant-ph

TL;DR: 本文提出了一种集成IRIS异步任务运行时与XACC量子编程框架的混合执行框架，通过QIR-EE实现对经典与量子任务的协同调度，验证了多量子工作负载的异步执行，并利用量子电路切割降低模拟负载，展示了提升模拟吞吐量的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着HPC系统中引入量子加速器，需要能够协调经典与量子工作负载的运行时系统，以应对极端异构性带来的挑战。

Method: 将IRIS异步任务运行时与XACC量子编程框架通过量子中间表示执行引擎（QIR-EE）集成，使用QIR编写的程序在多种异构后端（包括多个量子模拟器）上进行并发执行，并采用量子电路切割技术将四量子比特电路分解为更小的子电路以减少模拟负担。

Result: 成功实现了多个量子工作负载的异步调度与执行；通过电路切割降低了单个任务的量子模拟负载，改善了模拟器吞吐量并减少了排队现象。

Conclusion: 混合运行时在协调经典与量子任务方面具有潜力，但仍面临扩展性挑战，包括协同调度、经典-量子交互管理以及对多样化后端资源的支持。

Abstract: Extreme heterogeneity in emerging HPC systems are starting to include quantum accelerators, motivating runtimes that can coordinate between classical and quantum workloads. We present a proof-of-concept hybrid execution framework integrating the IRIS asynchronous task-based runtime with the XACC quantum programming framework via the Quantum Intermediate Representation Execution Engine (QIR-EE). IRIS orchestrates multiple programs written in the quantum intermediate representation (QIR) across heterogeneous backends (including multiple quantum simulators), enabling concurrent execution of classical and quantum tasks. Although not a performance study, we report measurable outcomes through the successful asynchronous scheduling and execution of multiple quantum workloads. To illustrate practical runtime implications, we decompose a four-qubit circuit into smaller subcircuits through a process known as quantum circuit cutting, reducing per-task quantum simulation load and demonstrating how task granularity can improve simulator throughput and reduce queueing behavior -- effects directly relevant to early quantum hardware environments. We conclude by outlining key challenges for scaling hybrid runtimes, including coordinated scheduling, classical-quantum interaction management, and support for diverse backend resources in heterogeneous systems.

</details>


### [70] [Integrability Breaking and Coherent Dynamics in Hermitian and Non-Hermitian Spin Chains with Long-Range Coupling](https://arxiv.org/abs/2512.14065)
*Y. S. Liu,X. Z. Zhang*

Main category: quant-ph

TL;DR: 该研究通过引入可调的长程跃迁项 $H_n$，系统分析了一维自旋模型中从可积性到量子混沌的转变，并揭示了非厄米效应和长程相互作用对量子遍历性的普遍影响机制。


<details>
  <summary>Details</summary>
Motivation: 探索复杂量子系统中遍历性破缺的机制是非平衡物理的核心问题，特别是如何在全局混沌中保持量子相干性。

Method: 通过能级间距统计、Krylov复杂度和纠缠熵的系统分析，研究含有可调长程跃迁项 $H_n$ 的一维自旋模型。

Result: 发现 $H_n$ 可作为驱动从可积到混沌转变的通用参数，在厄米和非厄米情况下均诱导混沌行为；同时识别出一组精确的非热本征态，表现为低纠缠和相干动力学的量子多体疤痕。

Conclusion: 长程和非厄米效应提供了一种普遍机制来重塑量子遍历性，为在复杂多体系统中保护量子相干性开辟了新途径。

Abstract: Unraveling the mechanisms of ergodicity breaking in complex quantum systems is a central pursuit in nonequilibrium physics. In this work, we investigate a one-dimensional spin model featuring a tunable long-range hopping term, $H_{n}$, which introduces nonlocal interactions and bridges the gap between Hermitian and non-Hermitian regimes. Through a systematic analysis of level-spacing statistics, Krylov complexity, and entanglement entropy, we demonstrate that $H_{n}$ acts as a universal control parameter driving the transition from integrability to quantum chaos. Specifically, increasing the strength of $H_{n}$ induces a crossover from Poissonian to Gaussian Orthogonal Ensemble statistics in the Hermitian limit, and similarly triggers chaotic dynamics in the non-Hermitian case. Most remarkably, despite the onset of global chaos, we identify a tower of exact nonthermal eigenstates that evade thermalization. These states survive as robust quantum many-body scars, retaining low entanglement and coherent dynamics even under strong non-Hermitian perturbations. Our findings reveal a universal mechanism by which long-range and non-Hermitian effects reshape quantum ergodicity, offering new pathways for preserving quantum coherence in complex many-body systems.

</details>


### [71] [Frozen Gaussian sampling algorithms for simulating Markovian open quantum systems in the semiclassical regime](https://arxiv.org/abs/2512.14015)
*Limin Xu,Zhen Huang,Zhennan Zhou*

Main category: quant-ph

TL;DR: 提出了一种基于Wigner-Fokker-Planck相空间表述的冻结高斯采样（FGS）算法，用于高效模拟半经典区域的马尔可夫开放量子系统。该方法在计算物理可观测量时采样误差不依赖于半经典参数，并且避免了网格边界引起的不稳定性，适用于强非谐势中稳态存在的数值研究。


<details>
  <summary>Details</summary>
Motivation: 传统网格方法在模拟半经典区间的马尔可夫开放量子系统时因高度振荡的动力学而面临计算分辨率要求过高的挑战，亟需一种高效且稳定的数值方法。

Method: 基于Wigner-Fokker-Planck相空间公式，发展了一种无网格的冻结高斯采样（FGS）算法，利用Frozen Gaussian初始分布进行随机采样以演化系统密度矩阵并计算物理可观测量。

Result: FGS算法在计算物理可观测量时采样误差与半经典参数ε无关，克服了传统网格方法在半经典极限下的计算瓶颈；同时其无网格特性消除了边界诱导的不稳定性，实现了长时间稳定模拟，并在强非谐势中提供了存在稳态的数值证据。

Conclusion: FGS算法为研究半经典区域开放量子系统的长时行为提供了一个高效、稳定且可扩展的工具，尤其在缺乏严格解析结果的强非谐势体系中展现出重要应用潜力。

Abstract: Simulating Markovian open quantum systems in the semiclassical regime poses a grand challenge for computational physics, as the highly oscillatory nature of the dynamics imposes prohibitive resolution requirements on traditional grid-based methods. To overcome this barrier, this paper introduces an efficient Frozen Gaussian Sampling (FGS) algorithm based on the Wigner-Fokker-Planck phase-space formulation. The proposed algorithm exhibits two transformative advantages. First, for the computation of physical observables, its sampling error is independent of the semiclassical parameter $\varepsilon$, thus fundamentally breaking the prohibitive computational scaling faced by grid methods in the semiclassical limit. Second, its mesh-free nature entirely eliminates the boundary-induced instabilities that constrain long-time grid-based simulations. Leveraging these capabilities, the FGS algorithm serves as a powerful investigatory tool for exploring the long-time behavior of open quantum systems. Specifically, we provide compelling numerical evidence for the existence of steady states in strongly non-harmonic potentials-a regime where rigorous analytical results are currently lacking.

</details>


### [72] [Coherence-Sensitive Readout Models for Quantum Devices: Beyond the Classical Assignment Matrix](https://arxiv.org/abs/2512.13949)
*Zachariah Malik,Zain Saleem*

Main category: quant-ph

TL;DR: 本文提出了一种新的测量读出误差模型，超越了传统假设中的经典噪声描述，引入了一个相干响应矩阵C来捕捉量子设备中由于非对角POVM元素引起的相干性影响，从而提供了对当前和未来量子器件上读出建模的通用框架。


<details>
  <summary>Details</summary>
Motivation: 传统的读出误差模型假设测量噪声是经典的，忽略了量子相干性的影响，这限制了对真实量子系统行为的准确描述。本文旨在建立一个更全面的模型以包含这些被忽略的相干效应。

Method: 通过放松经典噪声假设，推导出在任意完全正定迹保持（CPTP）噪声下的观测测量概率的一般表达式，并引入由有效POVM非对角元素构成的相干响应矩阵C。

Result: 得到了观测概率向量z的一般形式z = Ax + Cy，其中A为经典的分配矩阵，C则量化了与相干读出失真及计算基态间干涉相关的信息。当且仅当所有POVM元素为对角时，才恢复经典模型z = Ax。

Conclusion: 该工作提供了一个自然且完全通用的框架，用于在现有和未来的量子设备上进行考虑相干性的读出建模，揭示了仅使用经典模型无法获取的额外信息。

Abstract: Readout error models for noisy quantum devices almost universally assume that measurement noise is classical: the measurement statistics are obtained from the ideal computational-basis populations by a column-stochastic assignment matrix $A$. This description is equivalent to assuming that the effective positive-operator-valued measurement (POVM) is diagonal in the measurement basis, and therefore completely insensitive to quantum coherences. We relax this assumption and derive a fully general expression for the observed measurement probabilities under arbitrary completely positive trace-preserving (CPTP) noise preceding a computational-basis measurement. Writing the ideal post-circuit stat $\tildeρ$ in terms of its populations $x$ and coherences $y$, we show that the observed probability vector $z$ satisfies $z = A x + C y$, where $A$ is the familiar classical assignment matrix and $C$ is a coherence-response matrix constructed from the off-diagonal matrix elements of the effective POVM in the computational basis. The classical model $z = A x$ arises if and only if all POVM elements are diagonal; in this sense $C$ quantifies accessible information about coherent readout distortions and interference between computational-basis states, all of which are invisible to models that retain only $A$. This work therefore provides a natural, fully general framework for coherence-sensitive readout modeling on current and future quantum devices.

</details>


### [73] [Quantifying electron-nuclear spin entanglement dynamics in central-spin systems using one-tangles](https://arxiv.org/abs/2512.14004)
*Isabela Gnasso,Khadija Sarguroh,Dorian Gangloff,Sophia E. Economou,Edwin Barnes*

Main category: quant-ph

TL;DR: 本文研究了电子-核自旋中心系统中的纠缠动力学，推广了一缠结能力度量方法，并以(In)GaAs量子点为例，提出实现电子与核间最大纠缠的参数条件，同时利用该度量精确计算电子自旋退相干时间，识别保持相干性的系统条件。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和控制固态量子系统中电子与核自旋之间的纠缠动力学，尤其是在含有高自旋核的系统中，需要将已有的一缠结能力方法进行推广，以适用于更广泛的系统类型。

Method: 通过推广一缠结能力度量至包含自旋大于1/2的核系统，结合(In)GaAs量子点实例，分析物理参数对纠缠的影响，并利用自然存在的简并性和系统可调性，在动力学解耦条件下生成目标自旋子集间的最大纠缠。同时使用一缠结能力直接计算电子自旋退相干时间。

Result: 提出了在(In)GaAs量子点中实现电子与核自旋最大纠缠的可行参数区域；能够在施加动力学解耦时调控特定核自旋子集间的纠缠；能够准确快速地计算有无自旋回波情况下的电子自旋退相干时间，并识别出维持系统相干性的条件。

Conclusion: 一缠结能力是一种有效且通用的工具，可用于分析和优化多种中心自旋系统中的纠缠特性与相干性，为量子信息处理提供了理论支持。

Abstract: Optically-active solid-state systems such as self-assembled quantum dots, rare-earth ions, and color centers in diamond and SiC are promising candidates for quantum network, computing, and sensing applications. Although the nuclei in these systems naturally lead to electron spin decoherence, they can be repurposed, if they are controllable, as long-lived quantum memories. Prior work showed that a metric known as the one-tangling power can be used to quantify the entanglement dynamics of sparse systems of spin-1/2 nuclei coupled to color centers in diamond and SiC. Here, we generalize these findings to a wide range of electron-nuclear central-spin systems, including those with spin > 1/2 nuclei, such as in III-V quantum dots (QDs), rare-earth ions, and some color centers. Focusing on the example of an (In)GaAs QD, we offer a procedure for pinpointing physically realistic parameter regimes that yield maximal entanglement between the central electron and surrounding nuclei. We further harness knowledge of naturally-occurring degeneracies and the tunability of the system to generate maximal entanglement between target subsets of spins when the QD electron is subject to dynamical decoupling. We also leverage the one-tangling power as an exact and immediate method for computing QD electron spin dephasing times with and without the application of spin echo sequences, and use our analysis to identify coherence-sustaining conditions within the system.

</details>


### [74] [Quantum Fisher Information Measure in a Strongly Confined Harmonic Paul Trap Lattice System](https://arxiv.org/abs/2512.14155)
*Precious Ogbonda Amadi,Paphon Pewkhom,Pruet Kalasuwan,Norshamsuri Ali,Syed Alwee Aljunid,Rosdisham Endut*

Main category: quant-ph

TL;DR: 研究了在保罗陷阱中通过光学晶格调控有效势时，单个离子的信息和结构特性如何响应变化，发现费舍尔信息、香农熵等能追踪有效势的曲率，且系统行为由曲率决定而非控制参数选择。


<details>
  <summary>Details</summary>
Motivation: 探索在可调有效势下，离子囚禁系统中的信息与结构特性如何变化，以实现对量子系统的精确控制。

Method: 将陷阱频率ω和晶格κ作为独立调节参数，分析费舍尔信息、香农熵和费舍尔-香农复杂度随有效势曲率的变化。

Result: 费舍尔信息、香农熵和费舍尔-香农复杂度能够准确反映有效势的曲率变化；ω和κ的扫描表明系统行为由曲率决定，而非具体控制参数的选择。

Conclusion: 有效势的曲率决定了系统的物理行为，且可在不改变系统谐波特性的前提下进行工程调控，为精密量子控制和信息流研究提供了新途径。

Abstract: In this work, we examine how the informational and structural properties of a single ion respond to controlled changes of the effective potential in a Paul trap modified by an optical lattice. We consider the ground state of the system where confinement is strongest. And by treating the trap frequency $ω$ and lattice $κ$ as independent tunning parameters, we show that Fisher information, Shannon entropy, and Fisher-Shannon complexity track the curvature of the effective potential $ω_{\mathrm{eff}}=ω^2\,\sqrt{1-κ}$. The $ω$ and $κ$ sweeps confirm that curvature and not the choice of control parameter determines the behaviour of the system. This gives the trapped-ion platform a clear advantage that the curvature can be engineered without altering the harmonic characteristics of the system. The interplay between $ω$ and $κ$ thus provides a practical route for precision quantum control and offers Information-theoretic framework for experiments that probe confinement, quantization scale, and information flow in engineered ion traps.

</details>


### [75] [High-Order Harmonic Generation with Beyond-Semiclassical Emitter Dynamics: A Strong-Field Quantum Optical Heisenberg Picture Approach](https://arxiv.org/abs/2512.14174)
*Christian Saugbjerg Lange,Ella Elisabeth Lassen,Rasmus Vesterager Gothelf,Lars Bojer Madsen*

Main category: quant-ph

TL;DR: 本文在海森堡绘景中发展了一种精确控制的微扰展开方法，用于描述强场过程中的高次谐波产生（HHG），揭示了量子涨落对发射光非经典特性的影响，并提供了多发射子体系下的可扩展关系。


<details>
  <summary>Details</summary>
Motivation: 传统上强场过程多采用薛定谔绘景进行近似建模，而海森堡绘景尚未被充分探索；本文旨在建立一个更清晰、可控且适用于现实实验的量子光学理论框架。

Method: 在海森堡绘景中对时间演化算符进行准确控制的微扰展开，推导出发射体动力学的超越半经典修正，获得关键可观测量的闭式表达式，并分析多发射子情况下的缩放关系。

Result: 该方法简化了数值计算，明确关联了辐射光的非经典特征与介质动力学之间的关系；发现随着发射子数量增加，压缩程度增强，但光子统计趋于经典的泊松分布；同时发现超越半经典的动力学显著增强光场的压缩特性。

Conclusion: 本文推进了对量子光学HHG的理论理解，提出了一种可处理实际实验条件的清晰、可控且易于实现的理论框架。

Abstract: Quantum-optical descriptions of strong-field processes have attracted significant attention in recent years. Typically, the theoretical modeling has been conducted in the Schrödinger picture, where results are only obtainable under certain approximations, while, in contrast, the Heisenberg picture has remained relatively unexplored. In this work, we develop an accurately controlled perturbative expansion of the time-evolution operator in the Heisenberg picture and derive beyond-semiclassical corrections to the emitter dynamics due to the coupling to the quantized electromagnetic field, capturing effects of the quantum fluctuations present in the latter. We focus on high-order harmonic generation (HHG), where the approach is accurate in parameter regimes of current interest and it gives closed-form expressions for key observables. This formulation not only simplifies numerical calculations compared to the Schrödinger-picture approach but also provides a clear correspondence between nonclassical features of the emitted light and the underlying induced dynamics of the generating medium including quantum fluctuations. Moreover, the Heisenberg framework naturally yields scaling relations with the number of independent emitters, enabling us to assess whether nonclassical behavior should persist under typical experimental conditions involving large emitter ensembles. Interestingly, we find that the degree of squeezing increases with the number of emitters, whereas the photon statistics approaches a classical Poissonian distribution in the many-emitter limit. We also find that the beyond-semiclassical emitter dynamics significantly enhances the degree of squeezing of the emitted light. Our work advances the theoretical understanding of quantum-optical HHG and introduces an accessible and well-controlled framework to describe realistic experiments.

</details>


### [76] [Information-efficient decoding of surface codes](https://arxiv.org/abs/2512.14255)
*Long D. H. My,Shao-Hen Chiew,Jing Hao Chai,Hui Khoon Ng*

Main category: quant-ph

TL;DR: 本文提出两种新的解码器，通过减少表面码错误校正中所需的综合征信息量，使通信需求显著降低，从而缓解实时解码中的指数级 backlog 问题。


<details>
  <summary>Details</summary>
Motivation: 解决在表面码中执行逻辑T门时出现的指数级backlog问题，该问题要求实时解码综合征信息，导致量子处理单元与经典处理器之间的通信速率要求过高，难以维持量子处理器的质量。

Method: 设计了两种依赖于较少综合征信息的解码器，其使用的综合征比特数仅随表面码块的宽度缩放，而非传统的面积缩放。

Result: 新解码器显著降低了实时解码所需的通信带宽，缓解了通信压力，同时保持了解码有效性。

Conclusion: 所提出的解码器为实现高效的容错量子计算提供了更可行的通信方案，特别适用于需要频繁执行逻辑T门的应用场景。

Abstract: Surface codes are a popular error-correction route to fault-tolerant quantum computation. The so-called exponential backlog problem that can arise when one has to do logical $T$-gates within the surface code demands real-time decoding of the syndrome information to diagnose the appropriate Pauli frame in which to do the gate. This in turn puts a minimum requirement on the communication rate between the quantum processing unit, where the syndrome information is collected, and the classical processor, where the decoding algorithm is run. This minimum communication rate can be difficult to achieve while preserving the quality of the quantum processor. Here, we present two decoders that make use of a reduced syndrome information volume, relying on a number of syndrome bits that scale only as the width -- and not the usual area -- of the surface-code patch. This eases the communication requirements necessary for real-time decoding.

</details>


### [77] [Engineering Anisotropic Rabi Model in Circuit QED](https://arxiv.org/abs/2512.14276)
*S. Mojtaba Tabatabaei,Babak Zare Rameshti,Mohsen Akbari*

Main category: quant-ph

TL;DR: 提出了一种基于电路量子电动力学的各向异性Rabi模型实现方案，通过几何调控实现Jaynes-Cummings和反Jaynes-Cummings相互作用的连续调节。


<details>
  <summary>Details</summary>
Motivation: 各向异性Rabi模型（ARM）在全参数范围内实现具有挑战性，尤其是可调的JC和AJC相互作用难以同时控制。

Method: 通过将量子比特同时耦合到谐振腔的电压和电流波腹处，利用几何方式调节相互作用强度，实现从纯JC到纯AJC的连续调控。

Result: 实现了对ARM参数的静态控制，展示了消散射位移和Purcell抑制读出等新型量子测量能力。

Conclusion: 该工作为探索ARM的完整参数空间及其在量子信息处理中的应用提供了直接平台。

Abstract: The anisotropic Rabi model (ARM), which features tunable Jaynes-Cummings (JC) and anti-Jaynes-Cummings (AJC) interactions, has remained challenging to realize fully. We present a circuit QED implementation that provides static control over the ARM parameters. By simultaneously coupling a qubit to a resonator's voltage and current antinodes, we geometrically tune the interaction from pure JC to pure AJC. This control enables novel quantum measurement capabilities, including dispersive shift cancellation and Purcell-suppressed readout. Our work establishes a direct platform for exploring the ARM's full parameter space and its applications in quantum information processing.

</details>


### [78] [Universal Structure of Nonlocal Operators for Deterministic Navigation and Geometric Locking](https://arxiv.org/abs/2512.14302)
*Jia Bao,Bin Guo,Shu Qu,Fanqin Xu,Zhaoyu Sun*

Main category: quant-ph

TL;DR: 提出了一种普适几何框架，将最优非局域算符的搜索转化为确定性预测-验证过程，揭示了量子临界性中的几何临界与几何锁定两种本质不同的相变类型。


<details>
  <summary>Details</summary>
Motivation: 寻找描述非局域性的最优算符通常是一个复杂的组合问题，缺乏直观的物理图像；希望通过建立几何框架来实现系统性、可预测的求解方式。

Method: 通过发现主特征值由仅含两个角度变量θ和φ的低维流形决定，并利用其对称性简化问题，建立了外部控制参数到最优测量构型的精确映射。

Result: 揭示了量子相变中存在两种不同机制：涉及对称性旋转的转变表现为几何临界（算符剧烈重定向），而强各向异性主导的转变则呈现几何锁定（最优基稳定）。

Conclusion: 该几何框架为贝尔实验提供了精确导航图，并为量子相变提供了新的结构化分类方法。

Abstract: We establish a universal geometric framework that transforms the search for optimal nonlocal operators from a combinatorial black box into a deterministic predict-verify operation. We discover that the principal eigenvalue governing nonlocality is rigorously dictated by a low-dimensional manifold parameterized by merely two fundamental angular variables, $θ$ and $φ$, whose symmetry leads to further simplification. This geometric distillation establishes a precise mapping connecting external control parameters directly to optimal measurement configurations. Crucially, a comparative analysis of the geometric angles against the principal eigenvalue spectrum, including its magnitude, susceptibility, and nonlocal gap, reveals a fundamental dichotomy in quantum criticality. While transitions involving symmetry sector rotation manifest as geometric criticality with drastic operator reorientation, transitions dominated by strong anisotropy exhibit geometric locking, where the optimal basis remains robust despite clear signatures of phase transitions in the spectral indicators. This distinction offers a novel structural classification of quantum phase transitions and provides a precision navigation chart for Bell experiments.

</details>


### [79] [Steering Alternative Realities through Local Quantum Memory Operations](https://arxiv.org/abs/2512.14377)
*Xiongfeng Ma*

Main category: quant-ph

TL;DR: 本文提出了“现实引导”协议，允许观察者通过局部擦除记忆中的‘结果信息’，概率性地进入初始量子态中已存在的不同现实，而无需逆转环境的退相干。该过程无法被内部验证，但在非线性操作下可能实现可验证的现实导航。


<details>
  <summary>Details</summary>
Motivation: 探索量子测量后多重现实的存在性，并试图构建一种无需逆转环境退相干即可切换观察者现实的机制。

Method: 基于量子信息理论，提出‘现实引导’协议，通过仅作用于观察者记忆的局部操作来擦除测量记录，利用初始量子态中已有的叠加分支实现现实切换。

Result: 发现现实切换在标准量子力学框架内虽理论上可行，但无法被观察者内部确认；切换后的记忆与新现实完全一致，无痕迹表明发生过切换；引入非线性操作可能实现可验证的导航。

Conclusion: 多现实探索可被纳入受限的量子信息框架，但其验证依赖于超越标准量子理论的操作，为意识与量子现实的关系提供了新的讨论基础。

Abstract: Quantum measurement resolves a superposition into a definite outcome by correlating it with an observer's memory -- a reality register. While the global quantum state remains coherent, the observer's local reality becomes singular and definite. This work introduces reality steering, a protocol that allows an observer to probabilistically access a different reality already supported by the initial quantum state, without reversing decoherence on the environment. The mechanism relies on locally erasing the 'which-outcome' information stored in the observer's brain. Here, 'local' means operations confined to the observer's memory, excluding the environment, which may be cosmically large. Reality steering nevertheless faces intrinsic constraints: successful navigation requires coherent participation from the observer's counterparts across the relevant branches, and any transition is operationally indistinguishable from non-transition. After arriving in a new reality, all memory records are perfectly consistent with that reality, leaving no internal evidence that a switch occurred. This makes conscious confirmation impossible within standard quantum mechanics. We show that nonlinear operations beyond the standard theory could, in principle, enable verifiable and deliberate navigation. Our results shift multi-reality exploration from philosophical speculation toward a concrete -- though fundamentally constrained -- quantum-informational framework.

</details>


### [80] [Geometric quantum thermodynamics: A fibre bundle approach](https://arxiv.org/abs/2512.14383)
*T. Pernambuco,L. C. Céleri*

Main category: quant-ph

TL;DR: 本文探讨了量子热力学的几何结构，通过构建相关的主纤维丛，揭示了与量子热力学规范理论相关的两种不同但相关的几何结构，并尝试用几何和拓扑性质解释热力学的基本特性。


<details>
  <summary>Details</summary>
Motivation: 由于在量子力学中信息论在描述系统热性质方面起着重要作用，而传统热力学基于粗粒化丢弃微观信息，因此需要一种新的框架来统一描述量子系统的热力学行为。

Method: 通过显式构造相关主纤维丛，探索量子热力学规范理论中的几何结构，并分析其几何与拓扑特性。

Result: 发现了与量子热力学规范理论相关的两种不同的几何结构，并建立了与基本物理理论相同数学语言的热力学表达形式。

Conclusion: 几何和拓扑结构有助于深入理解热力学的基本性质，为量子热力学提供了新的数学框架。

Abstract: Classical thermodynamics is a theory based on coarse-graining, meaning that the thermodynamic variables arise from discarding information related to the microscopic features of the system at hand. In quantum mechanics, however, where one has a high degree of control over microscopic systems, information theory plays an important role in describing the thermal properties of quantum systems. Recently, a new approach has been proposed in the form of a quantum thermodynamic gauge theory, where the notion of redundant information arises from a group of physically motivated gauge transformations called the thermodynamic group. In this work, we explore the geometrical structure of quantum thermodynamics. Particularly, we do so by explicitly constructing the relevant principal fibre bundle. We then show that there are two distinct (albeit related) geometric structures associated with the gauge theory of quantum thermodynamics. In this way, we express thermodynamics in the same mathematical (geometric) language as the fundamental theories of physics. Finally, we discuss how the geometric and topological properties of these structures may help explain fundamental properties of thermodynamics.

</details>


### [81] [Capacity and SKR tradeoff in coexisting classical and CV-QKD metropolitan-reach optical links](https://arxiv.org/abs/2512.14408)
*Cagla Ozkan,Lucas Alves Zischler,Kadir Gumus,Joao dos Reis Frazao,Cristian Antonelli,Chigo Okonkwo*

Main category: quant-ph

TL;DR: 通过优化量子-经典共存的保护带，实现了城域DWDM中不同功率 regime 下的性能提升，边缘频带配置在保持较低容量损失的同时显著提高了密钥生成率。


<details>
  <summary>Details</summary>
Motivation: 在城域密集波分复用（DWDM）系统中实现量子通信与经典通信的高效共存，同时最大化量子密钥分发（QKD）性能并最小化对经典信道容量的影响。

Method: 采用功率依赖的保护带优化策略，比较量子信道位于频带边缘和频带中心时的性能，使用100-150 GHz的保护带宽，并评估不同输入功率条件下的密钥生成率（SKR）和容量损失。

Result: 在-1.5 dBm/ch输入功率下，频带边缘配置相比频带中心配置将密钥生成率（SKR）提升了108%，且仅引入3.4%的容量损失，而频带中心配置的损失为6.8%。

Conclusion: 频带边缘配合适中保护带宽的方案在量子-经典共存DWDM系统中更具优势，能够在较小容量代价下显著提升量子通信性能。

Abstract: We demonstrate power-regime-dependent guardband optimization for quantum-classical coexistence in metropolitan DWDM. Quantum channel at band-edge with 100-150 GHz guardbands achieves 108% SKR improvement at -1.5 dBm/ch, incurring 3.4% capacity loss versus 6.8% for band-center.

</details>


### [82] [Ground State Energy via Adiabatic Evolution and Phase Measurement for a Molecular Hamiltonian on an Ion-Trap Quantum Computer](https://arxiv.org/abs/2512.14415)
*Ludwig Nützel,Michael J. Hartmann,Henrik Dreyer,Etienne Granet*

Main category: quant-ph

TL;DR: 本文研究了在离子阱量子计算机上实现分子基态能量估计时硬件噪声的影响，发现泄漏错误是达到化学精度的主要障碍。


<details>
  <summary>Details</summary>
Motivation: 理解硬件噪声对量子计算中分子基态能量估计实验的影响，以区分不同类型的误差并指导硬件和算法的发展。

Method: 采用绝热态制备方法制备H3+分子的六量子比特编码基态，并使用抗噪的迭代量子相位估计算法提取其能量。

Result: 实验结果优于经典Hartree-Fock能量；分析表明相干和非相干噪声影响较小，而泄漏错误是主要问题；模拟显示若无泄漏错误，可接近化学精度。

Conclusion: 抑制泄漏错误对未来量子算法和硬件发展至关重要。

Abstract: Estimating molecular ground-state energies is a central application of quantum computing, requiring both the preparation of accurate quantum states and efficient energy readout. Understanding the effect of hardware noise on these experiments is crucial to distinguish errors that have low impact, errors that can be mitigated, and errors that must be reduced at the hardware level. We ran a state preparation and energy measurement protocol on an ion-trap quantum computer, without any non-scalable off-loading of computational tasks to classical computers, and show that leakage errors are the main obstacle to chemical accuracy. More specifically, we apply adiabatic state preparation to prepare the ground state of a six-qubit encoding of the H3+ molecule and extract its energy using a noise-resilient variant of iterative quantum phase estimation. Our results improve upon the classical Hartree-Fock energy. Analyzing the effect of hardware noise on the result, we find that while coherent and incoherent noise have little influence, the hardware results are mainly impacted by leakage errors. Absent leakage errors, noisy numerical simulations show that with our experimental settings we would have achieved close to chemical accuracy, even shot noise included. These insights highlight the importance of targeting leakage suppression in future algorithm and hardware development.

</details>


### [83] [Adiabatic-Inspired Hybrid Quantum-Classical Methods for Molecular Ground State Preparation](https://arxiv.org/abs/2512.14449)
*Sean Thrasher,Ioannis Kolotouros,Julien Michel,Petros Wallden*

Main category: quant-ph

TL;DR: 本文提出了一种新的混合量子算法G-AQC-PQC，用于解决量子化学中的基态问题，相较于传统VQE方法在精度和量子计算成本上更具优势，并通过BeH₂分子验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 为克服VQE的收敛困难和AQC对深度电路的需求，填补现有近似绝热量子算法之间的差距，提升当前量子设备在量子化学问题上的求解能力。

Method: 提出了一个统一的绝热启发算法框架，引入新型混合算法G-AQC-PQC，结合绝热初始化与低内存BFGS优化器，并在不同参数设置下对多种算法进行基准测试。

Result: G-AQC-PQC在BeH₂分子的电子结构计算中表现优于传统VQE，降低了量子计算成本，且在特定条件下展现出明显优势。

Conclusion: G-AQC-PQC是一种有前景的近似绝热方法，在当前量子硬件条件下为量子化学问题提供了更高效、准确的解决方案，尤其适用于高度关联材料的电子结构求解。

Abstract: Quantum computing promises to efficiently and accurately solve many important problems in quantum chemistry which elude classical solvers, such as the electronic structure problem of highly correlated materials. Two leading methods in solving the ground state problem are the Variational Quantum Eigensolver (VQE) and Adiabatic Quantum Computing (AQC) algorithms. VQE often struggles with convergence due to the energy landscape being highly non-convex and the existence of barren plateaux, and implementing AQC is beyond the capabilities of current quantum devices as it requires deep circuits. Adiabatically-inspired algorithms aim to fill this gap. In this paper, we first present a unifying framework for these algorithms and then benchmark the following methods: the Adiabatically Assisted VQE (AAVQE) (Garcia-Saez and Latorre (2018)), the Variational Adiabatic Quantum Computing (VAQC) (Harwood et al (2022)), and the Adiabatic Quantum Computing with Parametrized Quantum Circuits (AQC-PQC) (Kolotouros et al (2025)) algorithms. Second, we introduce a novel hybrid approach termed G-AQC-PQC, which generalizes the AQC-PQC method, and combines adiabatic-inspired initialization with the low-memory BFGS optimizer, reducing the quantum computational cost of the method. Third, we compare the accuracy of the methods for chemistry applications using the beryllium hydride molecule (BeH$_2$). We compare the approaches across a number of different choices (ansätze types, depth, discretization steps, initial Hamiltonian, adiabatic schedules and method used). Our results show that the G-AQC-PQC outperforms conventional VQE. We further discuss limitations such as the zero-gradient problem and identify regimes where adiabatically-inspired methods offer a tangible advantage for near-term quantum chemistry applications.

</details>


### [84] [Super-Heisenberg-limited Sensing via Collective Subradiance in Waveguide QED](https://arxiv.org/abs/2512.14463)
*Xin Wang,Zeyang Liao*

Main category: quant-ph

TL;DR: 该研究探讨了亚波长间距发射器阵列在纳米光子波导中的量子计量潜力，发现强偶极-偶极相互作用可产生超窄亚辐射共振，其最亚辐射态的衰减速率遵循N^{-3}标度律，并表现出奇偶振荡行为。单光子散射谱中可观测到这一标度，使原子间距微小变化的检测灵敏度达到N^3量级，量子费舍尔信息（QFI）更可达N^6量级，且在实际位置无序下仍保持鲁棒性，为集成纳米光子平台上的可扩展量子传感提供了新路径。


<details>
  <summary>Details</summary>
Motivation: 探索强偶极-偶极相互作用下亚波长发射器阵列的集体光学响应，以挖掘其在高精度量子传感中的潜力。

Method: 通过有效非厄米哈密顿量的本征模式分析，推导出最亚辐射态衰减速率的普适标度律，并结合单光子散射谱和量子费舍尔信息评估其在量子计量中的性能。

Result: 发现了衰减速率的N^{-3}标度律及奇偶振荡现象，散射谱中可实现N^3量级的检测灵敏度，量子费舍尔信息达N^6量级，且结果在存在位置无序时依然稳健。

Conclusion: 偶极-偶极工程诱导的亚辐射是实现高灵敏度、可扩展量子传感器的有效资源，连接了多体波导量子电动力学与精密测量技术。

Abstract: We explore the quantum-metrological potential of subwavelength-spaced emitter arrays coupled to a one-dimensional nanophotonic waveguide. In this system, strong dipole--dipole interactions profoundly modify the collective optical response, leading to the emergence of ultranarrow subradiant resonances. Through an eigenmode analysis of the effective non-Hermitian Hamiltonian, we derive a universal scaling law for the decay rate of the most subradiant state, which exhibits an $ N^{-3} $ scaling with even-odd oscillatory behavior in the deep-subwavelength regime. This scaling is directly observable in the single-photon scattering spectrum, enabling the detection of minute changes in atomic separation with a figure of merit that scales as $ N^3 $. The quantum Fisher information (QFI) scales as $N^6$ and can be closely approached by measuring spectral shifts near the steepest slope of the most subradiant resonance. These enhancements remain robust under realistic positional disorder, confirming that dipole--dipole-engineered subradiance provides a viable resource for quantum metrology. Our work bridges many-body waveguide quantum electrodynamics and high-precision sensing, opening a route toward scalable quantum sensors on integrated nanophotonic platforms.

</details>


### [85] [Nonlocal contributions to ergotropy: A thermodynamic perspective](https://arxiv.org/abs/2512.14497)
*B. Vigneshwar,R. Sankaranarayanan*

Main category: quant-ph

TL;DR: 提出了一种量化双体系统中非局域性对可提取功贡献的新方法，揭示了在无相互作用哈密顿量下非局域资源始终增强可提取功，而在有相互作用时则取决于态和哈密顿量的结构。


<details>
  <summary>Details</summary>
Motivation: 识别非局域性对可提取功的贡献是量子热力学中的核心问题，旨在明确非局域量子资源在热力学过程中的作用。

Method: 引入了一个量化非局域性对可提取功贡献的度量，并通过施密特系数推导出其闭式表达式，分析了在非相互作用和相互作用哈密顿量下的不同表现。

Result: 在严格无相互作用哈密顿量下建立了ergotropy与关联之间的直接关系；非局域性在无相互作用时始终提升可提取功，在有相互作用时可能增强或削弱可提取功。

Conclusion: 非局域量子资源在量子热力学中具有重要作用，其对可提取功的影响依赖于系统哈密顿量的结构。

Abstract: Nonlocality is a defining feature of quantum mechanics and has long served as a key indicator of quantum resources since the formulation of Bell's inequalities. Identifying the contribution of nonlocality to extractable work remains a central problem in quantum thermodynamics. We address this by introducing a quantifier of nonlocal contributions to extractable work in bipartite systems. It is shown that closed form expressions can be calculated for our quantity in terms of the Schmidt coefficients. Further for strictly non-interacting Hamiltonian, the direct relationship between ergotropy and correlations is established. Our results reveal that nonlocal resources invariably enhance extractable work under non-interacting Hamiltonians, while in the presence of interactions, their contribution can either increase or diminish depending on the structure of the state and the Hamiltonian.

</details>


### [86] [Large circuit execution for NMR spectroscopy simulation on NISQ quantum hardware](https://arxiv.org/abs/2512.14513)
*Artemiy Burov,Julien Baglio,Clément Javerzac-Galy*

Main category: quant-ph

TL;DR: 本研究利用量子计算技术，结合先进的错误缓解和抑制方法，在超导和离子阱量子计算机上实现了多达34个自旋的一维核磁共振谱的量子哈密顿模拟，突破了经典模拟的极限，展示了近期量子实用性的潜力。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代向量子实用性过渡的背景下，传统方法难以模拟大规模核磁共振谱，亟需利用量子计算突破经典计算在模拟复杂自旋系统时的局限性。

Method: 采用Q-CTRL的先进误差缓解与抑制技术，结合IBM的超导量子计算机和IonQ的离子阱量子计算机，实现高场条件下液态一维NMR谱的量子哈密顿模拟，并构建可执行深度量子电路的处理流程。

Result: 成功模拟了最多达34个自旋的系统，其中16、22和34自旋系统的1D NMR谱关键特征得以再现；噪声显著降低，均方误差改善了22倍；34自旋系统已超出经典Liouville空间模拟的实际可行范围（32自旋为极限）。

Conclusion: 该工作标志着在核磁共振波谱学中实现近期量子实用性的关键一步，展示了量子计算在化学和材料科学中解决实际问题的潜力。

Abstract: With the latest advances in quantum computing technology, we are gradually moving from the noisy intermediate-scale quantum (NISQ) era characterized by hardware limited in the number of qubits and plagued with quantum noise, to the age of quantum utility where both the newest hardware and software methods allow for tackling problems which have been deemed difficult or intractable with conventional classical methods. One of these difficult problems is the simulation of one-dimensional (1D) nuclear magnetic resonance (NMR) spectra, a major tool to learn about the structure of molecules, helping the design of new materials or drugs. Using advanced error mitigation and error suppression techniques from Q-CTRL together with the latest commercially available superconducting-qubit quantum computer from IBM and trapped-ion quantum computer from IonQ, we present the quantum Hamiltonian simulation of liquid-state 1D NMR spectra in the high-field regime for spin systems up to 34 spins. Our pipeline has a major impact on the ability to execute deep quantum circuits with the reduction of quantum noise, improving mean square error by a factor of 22. It allows for the execution of deep quantum circuits and obtaining salient features of the 1D NMR spectra for both 16-spin and 22-spin systems, as well as a 34-spin system, which lies beyond the regime where unrestricted full Liouvillespace simulations are practical (32 spins, the Liouville limit). Our work is a step toward near-term quantum utility in NMR spectroscopy.

</details>


### [87] [Finite-Time Protocols Stabilize Charging in Noisy Ising Quantum Batteries](https://arxiv.org/abs/2512.14521)
*Riccardo Grazi,Henrik Johannesson,Dario Ferraro,Niccolò Traverso Ziani*

Main category: quant-ph

TL;DR: 研究了横向场伊辛链作为量子电池，在有限充电时间下，比特间相互作用与充电协议的结合可实现更平滑、可控的充电过程，且噪声对不同激发程度的协议影响不同，可能抑制或增强电池性能。


<details>
  <summary>Details</summary>
Motivation: 为了推动量子电池向实际应用发展，需要可靠的充电协议。本文旨在研究在有限充电时间内，qubit相互作用和充电动力学对量子电池性能的影响。

Method: 采用横向场伊辛链作为量子电池模型，分析其在有限时间充电过程中的行为，并引入随机噪声以研究不同充电轨迹下的能量存储与可提取功的变化。

Result: 发现qubit相互作用与有限时间充电结合可实现更平滑、可控的充电；弱激发协议在噪声下获得能量但损失可提取功，而强激发多模式的协议则在噪声下储存能量减少但效率提升。

Conclusion: 有限时间充电能稳定量子电池的充电过程，且噪声的影响取决于具体协议，可能抑制或增强电池性能，为设计鲁棒性量子充电协议提供了新视角。

Abstract: Reliable charging protocols are crucial for advancing quantum batteries toward practical use. We investigate a transverse-field Ising chain as a quantum battery, focusing on the combined role of qubit interactions in the battery model and finite charging time. This interplay yields smoother and more controllable charging compared to sudden protocols or non-interacting batteries. Introducing stochastic noise reveals a strong dependence on the charging trajectory. Protocols that weakly excite the system gain energy under noise but lose extractable work. In contrast, protocols that strongly excite many modes show the opposite trend: noise reduces stored energy yet improves efficiency, defined as the ratio of ergotropy to stored energy. These findings demonstrate that finite-time ramps stabilize charging and highlight that noise can either hinder or enhance quantum-battery performance depending on the protocol.

</details>


### [88] [Continuous Accumulation of Cold Atoms in an Optical Cavity](https://arxiv.org/abs/2512.14528)
*Edward Gheorghita,Sebastian Wald,Andrea Pupić,Onur Hosten*

Main category: quant-ph

TL;DR: 该研究实现了在腔内偶极子阱中连续捕获和累积亚多普勒冷却的原子，通过光频移调控实现空间变化的冷却参数，使原子在稳态下保持低于10微开尔文，为连续运行的腔量子电动力学系统和长时量子传感器提供了新路径。


<details>
  <summary>Details</summary>
Motivation: 为了实现稳态量子传感和高效量子处理，需要持续运行的原子-光界面，而传统的时间序列操作限制了系统的连续性。

Method: 利用光频移操控产生空间变化的冷却参数，结合浅腔内偶极子阱与磁光阱，将来自源池的铷原子连续导入腔模式并进行冷却和囚禁。

Result: 实现了数百万个原子在腔内的连续稳定维持，温度低于10微开尔文，并表征了原子系综与腔场的集体耦合特性。

Conclusion: 该工作建立了连续运行的腔-QED系统和长时原子及混合量子传感器的技术基础。

Abstract: Continuously operating atom-light interfaces represent a key prerequisite for steady-state quantum sensors and efficient quantum processors. Here, we demonstrate continuous accumulation of sub-Doppler-cooled atoms in a shallow intracavity dipole trap, realizing this regime. The key ingredient is a light-shift manipulation that creates spatially varying cooling parameters, enabling efficient capture and accumulation of atoms within a cavity mode. Demonstrated with rubidium atoms, a continuous flux from a source cell is funneled through the magneto-optical trap into the cavity mode, where the atoms are cooled and maintained below $10~μ\text{K}$ in steady state without time-sequenced operation. We characterize the resulting continuously maintained ensemble of millions of atoms and its collective coupling to the cavity field, establishing a route toward continuously operated cavity-QED systems and long-duration atomic and hybrid quantum sensors.

</details>


### [89] [Fair sampling of ground-state configurations using hybrid quantum-classical MCMC algorithms](https://arxiv.org/abs/2512.14552)
*Yuichiro Nakano,Keisuke Fujii*

Main category: quant-ph

TL;DR: 该论文研究了混合量子-经典马尔可夫链蒙特卡洛（MCMC）算法在组合优化问题中的公平采样特性，表明该方法能有效纠正量子动力学引起的采样偏差，实现对简并基态的近均匀采样，并在随机k-SAT问题中展现出良好的公平性和解计数效率。


<details>
  <summary>Details</summary>
Motivation: 由于量子优化启发算法（如量子退火和QAOA）在处理具有简并基态的组合优化问题时存在采样偏差，本文旨在探索一种能够实现公平采样的混合量子-经典MCMC方法。

Method: 采用混合量子-经典MCMC算法，将量子动力学作为提议转移机制，并通过经典的接受步骤强制满足细致平衡条件；在小规模伊辛模型和接近可满足性阈值的随机k-SAT问题上进行验证。

Result: MCMC后处理能够纠正量子动力学的采样偏差，实现对简并基态的近均匀采样；在随机2-SAT中，该方法达到与PT-ICM相当的公平性；在随机3-SAT中仍能实现近似均匀采样，且解计数所需的转移次数与WalkSAT相当。

Conclusion: 混合量子-经典MCMC为公平采样和解的枚举提供了一个可行的框架，兼具量子提议的优势和经典MCMC的采样公平性。

Abstract: We study the fair sampling properties of hybrid quantum-classical Markov chain Monte Carlo (MCMC) algorithms for combinatorial optimization problems with degenerate ground states. While quantum optimization heuristics such as quantum annealing and the quantum approximate optimization algorithm (QAOA) are known to induce biased sampling, hybrid quantum-classical MCMC incorporates quantum dynamics only as a proposal transition and enforces detailed balance through classical acceptance steps. Using small Ising models, we show that MCMC post-processing corrects the sampling bias of quantum dynamics and restores near-uniform sampling over degenerate ground states. We then apply the method to random $k$-SAT problems near the satisfiability threshold. For random 2-SAT, a hybrid MCMC combining QAOA-assisted neural proposals with single spin-flip updates achieves fairness comparable to that of PT-ICM. For random 3-SAT, where such classical methods are no longer applicable, the hybrid MCMC still attains approximately uniform sampling. We also examine solution counting and find that the required number of transitions is comparable to that of WalkSAT. These results indicate that hybrid quantum-classical MCMC provides a viable framework for fair sampling and solution enumeration.

</details>


### [90] [Entanglement measure for the W-class states](https://arxiv.org/abs/2512.14566)
*Reza Hamzehofi*

Main category: quant-ph

TL;DR: 本文研究了W类态在混合态动力学下的纠缠结构与量化，提出两两纠缠的缺失足以保证系统全局可分离，并引入两纠缠之和作为有效的纠缠度量，解决了传统π-纠缠在多粒子极限下失效的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统纠缠度量（如π-纠缠）在大尺寸W态中失效的问题，并建立更合理的纠缠量化方法。

Method: 通过物理动机驱动的变换分析混合态动力学，建立全局可分离性与两两纠缠之间的严格条件，并提出新的纠缠度量——两纠缠之和与π-纠缠之和。

Result: 证明了在保持希尔伯特空间基的前提下，两两纠缠的缺失可保证全局可分离；提出了两纠缠之和作为W类态的有效纠缠度量；发现π-纠缠在n趋于无穷时消失，而π-纠缠之和仍有效；提出新的纠缠度量判据。

Conclusion: 两纠缠之和是描述W类态纠缠的自然且有效的度量方式，新提出的度量标准有助于构建物理意义明确、行为良好的纠缠测度。

Abstract: The structure and quantification of entanglement in the W-class states are investigated under physically motivated transformations that induce mixed-state dynamics. A rigorous condition is established linking global separability to the behavior of pairwise entanglement, showing that the absence of pairwise entanglement is sufficient to guarantee complete separability of the system, provided the Hilbert-space basis is preserved. This result motivates the identification of the sum of two-tangles as a natural and effective entanglement quantifier for the W-class states. Furthermore, the commonly used $π$-tangle becomes ineffective for the maximally entangled $n$-qubit W state as the system size increases, vanishing in the large-$n$ limit. To address this limitation, the sum of $π$-tangles is introduced, which, like the sum of two-tangles, successfully quantifies the entanglement of the maximally entangled $n$-qubit W state in the large-$n$ limit. In addition, a new condition for entanglement measures is introduced, which facilitates the formulation of a well-behaved and physically meaningful entanglement measure.

</details>


### [91] [Exploiting Reset Operations in Cloud-based Quantum Computers to Run Quantum Circuits for Free](https://arxiv.org/abs/2512.14582)
*Jakub Szefer*

Main category: quant-ph

TL;DR: 本文首次系统探讨了如何利用云量子计算机中的重置操作来免费运行量子电路，揭示了一种针对云量子计算经济模式的新攻击方式。通过滥用中程测量与重置操作，用户可在单次shot内串行执行多个电路，从而大幅降低实际成本（最高可达900%的费用减少），并对现有按shot计费模式构成严重财务风险。作者提出新的计费方案以应对该问题，同时保留重置功能的实用性。


<details>
  <summary>Details</summary>
Motivation: 随着主流量子计算公司提供基于云的硬件访问服务，其收费模式多基于量子电路执行的shot数量。然而，近年来引入的中程测量与重置功能可能被滥用，导致安全与经济漏洞。本文旨在揭示这一潜在威胁，并推动更公平合理的计费机制设计。

Method: 研究通过在真实云量子计算机上进行实验，展示如何将多个量子电路通过重置操作串联成一个更大的电路，在单个shot中连续执行多个独立任务。利用IBM等平台的实际设备验证该方法的有效性，并量化其对计费的影响。

Result: 实验证明，通过在单个shot内集成多个电路并使用重置操作分隔，可使用户的实际单位电路成本显著下降，某些情况下总成本降幅高达900%。这表明当前按shot计费的商业模式存在严重漏洞，可能导致量子计算服务商重大收入损失。

Conclusion: 本文揭示了云量子计算中按shot计费模式的安全与经济隐患，指出必须改进计费策略以防止滥用重置操作带来的免费计算问题。建议根据电路中使用的物理资源（如有效门操作、测量次数或重置次数）进行精细化计费，在保障用户体验的同时维护平台经济可持续性。

Abstract: This work presents the first thorough exploration of how reset operations in cloud-based quantum computers could be exploited to run quantum circuits for free. This forms a new type of attack on the economics of cloud-based quantum computers. All major quantum computing companies today offer access to their hardware through some type of cloud-based service. Due to the noisy nature of quantum computers, a quantum circuit is run many times to collect the output statistics, and each run is called a shot. The fees users pay for access to the machines typically depend on the number of these shots of a quantum circuit that are executed. Per-shot pricing is a clean and straightforward approach as users are charged a small fee for each shot of their circuit. This work demonstrates that per-shot pricing can be exploited to get circuits to run for free when users abuse recently implemented mid-circuit qubit measurement and reset operations. Through evaluation on real, cloud-based quantum computers this work shows how multiple circuits can be executed together within a shot, by separating each user circuit by set of reset operations and submitting all the circuits, and reset operations, as one larger circuit. As a result, the user is charged per-shot pricing, even though inside each shot are multiple circuits. Total per-shot cost to run certain circuits could be reduced by up to $900$\% using methods proposed in this work, leading to significant financial losses to quantum computing companies. To address this novel finding, this work proposes a clear approach for how users should be charged for their execution, while maintaining the flexibility and usability of the mid-circuit measurement and reset~operations.

</details>


### [92] [Sequential realization of Quantum Instruments](https://arxiv.org/abs/2512.14588)
*Soham Sau,Michal Sedlák*

Main category: quant-ph

TL;DR: 本文提出了一种自适应仪器序列（ASI）的数学描述方法，证明了任何量子仪器都可以分解为ASI，并研究了实现过程中测量步数N与辅助量子比特数n_A之间的权衡关系，发现对于将n个量子比特转换为m(>n)个量子比特的量子仪器，仅需(m-n)个可重复测量的辅助量子比特即可实现。


<details>
  <summary>Details</summary>
Motivation: 为了更高效地实现量子仪器，减少所需量子资源（如量子比特数量），特别是在自适应量子电路中通过中间测量结果动态调整后续操作的需求驱动下，需要对这类过程进行系统的数学建模和资源分析。

Method: 引入自适应仪器序列（ASI）的概念，利用量子信息理论工具对一般量子仪器进行分解，分析实现所需的最小测量步数N和辅助量子比特数n_A，并推导出二者乘积的下界及其最优性条件。

Result: 建立了任意量子仪器可分解为ASI的数学框架；给出了N×n_A的可实现下界；发现对于输出多于输入的量子仪器，存在仅使用(m-n)个辅助量子比特并通过重复测量实现的方案。

Conclusion: 该工作揭示了在自适应量子电路中实现量子仪器时资源使用的潜在优化路径，挑战了传统直觉，表明通过合理设计测量策略可以显著减少所需物理资源，尤其适用于扩展量子态的场景。

Abstract: In adaptive quantum circuits classical results of mid-circuit measurements determine the upcoming gates. This allows POVMs, quantum channels or more generally quantum instruments to be implemented sequentially, so that fewer qubits need to be used at each of the $N$ measurement steps. In this paper, we mathematically describe these problems via adaptive sequence of instruments (ASI) and show how any instrument can be decomposed into it. Number of steps $N$ and number of ancillary qubits $n_A$ needed for actual implementation are crucial parameters of any such ASI. We show an achievable lower bound on the product $N.n_A$ and we determine in which situations this tradeoff is likely to be optimal. Contrary to common intuition we show that for quantum instruments which transform $n$ to $m(>n)$ qubits, there exist $N$-step ASI implementing them just with $(m-n)$ ancillary qubits, which are remeasured $(N-1)$ times and finally used as output qubits.

</details>


### [93] [Improved Lower Bounds for QAC0](https://arxiv.org/abs/2512.14643)
*Malvika Raj Joshi,Avishay Tal,Francisca Vasconcelos,John Wright*

Main category: quant-ph

TL;DR: 本文建立了关于允许多项式数量辅助比特和门的QAC$^0$电路的最强下界，证明了深度3的QAC$^0$电路无法计算奇偶性函数且需要指数级门数来计算多数函数，深度2的电路无法有效逼近高影响力布尔函数，并揭示了常数深度量子电路在经典决策问题上未必优于经典电路。


<details>
  <summary>Details</summary>
Motivation: 探索QAC$^0$电路在充分资源下的计算极限，特别是在处理PARITY和MAJORITY等基本布尔函数时的能力边界，以理解量子电路相对于经典电路的真正优势。

Method: 通过发展新的技术将某些QAC$^0$电路在AC$^0$中进行经典模拟，结合对输出位的放松要求（仅需单比特输出），从而获得深度3的下界；同时分析深度2电路在逼近高影响力函数和合成特定量子态方面的局限性。

Result: 1. 深度3 QAC$^0$电路不能计算PARITY，且计算MAJORITY需要Ω(exp(√n))个门；2. 深度2 QAC$^0$电路无法以非可忽略优势逼近高影响力函数（如PARITY）；3. 深度2 QAC$^0$电路无法精确合成n-target nekomata态。

Conclusion: 对于本质上的经典决策问题，常数深度量子电路并不一定比经典电路更具优势，本文结果强化了对QAC$^0$能力的理解，并指出其在关键任务上的根本限制。

Abstract: In this work, we establish the strongest known lower bounds against QAC$^0$, while allowing its full power of polynomially many ancillae and gates. Our two main results show that:
  (1) Depth 3 QAC$^0$ circuits cannot compute PARITY regardless of size, and require at least $Ω(\exp(\sqrt{n}))$ many gates to compute MAJORITY.
  (2) Depth 2 circuits cannot approximate high-influence Boolean functions (e.g., PARITY) with non-negligible advantage in depth $2$, regardless of size.
  We present new techniques for simulating certain QAC$^0$ circuits classically in AC$^0$ to obtain our depth $3$ lower bounds. In these results, we relax the output requirement of the quantum circuit to a single bit (i.e., no restrictions on input preservation/reversible computation), making our depth $2$ approximation bound stronger than the previous best bound of Rosenthal (2021). This also enables us to draw natural comparisons with classical AC$^0$ circuits, which can compute PARITY exactly in depth $2$ using exponential size. Our proof techniques further suggest that, for inherently classical decision problems, constant-depth quantum circuits do not necessarily provide more power than their classical counterparts. Our third result shows that depth $2$ QAC$^0$ circuits, regardless of size, cannot exactly synthesize an $n$-target nekomata state (a state whose synthesis is directly related to the computation of PARITY). This complements the depth $2$ exponential size upper bound of Rosenthal (2021) for approximating nekomatas (which is used as a sub-circuit in the only known constant depth PARITY upper bound).

</details>


### [94] [Testing electron-photon exchange-correlation functional performance for many-electron systems under weak and strong light-matter coupling](https://arxiv.org/abs/2512.14655)
*Iman Ahmadabadi,I-Te Lu,Leonardo A. Cunha,Michael Ruggenthaler,Johannes Flick,Angel Rubio*

Main category: quant-ph

TL;DR: 提出了一种光子自由的交换-相关泛函（pxcLDA），适用于从弱到强光-物质耦合范围内的多电子系统，能够在原子和分子中准确再现腔调制电子密度，为实际电子系统中的量子电动力学密度泛函理论应用提供了可行路径。


<details>
  <summary>Details</summary>
Motivation: 为了在量子电动力学密度泛函理论（QEDFT）框架下更高效地描述从弱到强光-物质耦合下的多电子系统电子密度，并克服现有方法在处理电子-光子关联和非均匀性时的局限性。

Method: 基于非相对论Pauli-Fierz哈密顿量推导出交换-相关泛函，采用简单的重整化因子计算方法，在弱耦合 regime 中通过与量子电动力学耦合簇及已有QEDFT优化有效势方法对比，确定该因子。

Result: 在多种原子和分子体系中，pxcLDA泛函能够高度准确地再现腔调制的电子密度；随着系统尺寸或集体耦合强度增加，重整化因子趋近于1，表明电子-光子交换主导行为且精度提高。

Conclusion: pxcLDA为基于电子密度的QEDFT泛函在真实多电子系统中的应用提供了一个实用且高效的途径，尤其适用于强耦合和大尺度系统。

Abstract: We present results of a photon-free exchange-correlation functional within the local density approximation (pxcLDA) for quantum electrodynamics density functional theory (QEDFT) that efficiently describes the electron density of many-electron systems across weak to strong light-matter coupling. Building on previous work [I-Te. Lu et al., Phys. Rev. A 109, 052823 (2024)] that captured electron-photon correlations via an exchange-correlation functional derived from the nonrelativistic Pauli-Fierz Hamiltonian and tested on one-electron systems, we use a simple procedure to compute a renormalization factor describing electron-photon correlations and inhomogeneity in the weak-coupling regime by comparing it with quantum electrodynamics coupled-cluster, and previous QEDFT optimized effective potential methods. Across various atoms and molecules, pxcLDA reproduces cavity-modified densities in close agreement with these references. The renormalization factor approaches unity as the system size or collective coupling increases, reflecting an electron-photon exchange-dominated behavior and improved accuracy for larger systems. This approach now offers a practical route to applying QEDFT functionals based on electron density to realistic electron systems.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [95] [Quantum-Inspired Approach to Analyzing Complex System Dynamics](https://arxiv.org/abs/2512.14169)
*Parsa Kafashi,Mozhgan Orujlu*

Main category: nlin.CD

TL;DR: 提出了一种受量子信息启发的框架，用于通过多元时间序列分析复杂系统，利用密度矩阵和量子保真度量化高阶关联、系统间影响及恢复时间尺度，并在合成与真实气候数据上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉多元时间序列中的高阶相关性和动态响应，需要一种无需降维即可全面刻画复杂系统（如气候系统）弹性和相似性的新方法。

Method: 将系统状态编码为密度矩阵，借助量子信息中的保真度等工具，量化时间序列间的相对影响、对外部扰动的响应及恢复时间，捕捉超越两两统计的高阶共波动。

Result: 在9维改进Lorenz-96模型的合成数据和九区域全球气温异常的真实气候数据上成功应用，能够量化每个288个月时间窗相对于1850-1874年基准期的差异性，直至2025年7月。

Conclusion: 该框架提供了一种无需降维即可全面表征高维动力系统中弹性与相似性的有效方法，适用于复杂系统的动态分析，尤其在气候科学等领域具有应用潜力。

Abstract: We present a quantum information-inspired framework for analyzing complex systems through multivariate time series. In this approach the system's state is encoded into a density matrix, providing a compact representation of higher-order correlations and dependencies. This formulation enables precise quantification of the relative influence among time series, tracking of their response to external perturbations and also the definition of a recovery timescale without need for dimensional reduction. By leveraging tools such as fidelity from quantum information theory, our method naturally captures higher-order co-fluctuations beyond pairwise statistics, offering a holistic characterization of resilience and similarity in high-dimensional dynamics. We validate this approach on synthetic data generated by a 9-dimensional modified Lorenz-96 model and demonstrate its utility on real-world climate data, analyzing global temperature anomalies across nine regions, quantifying the dissimilarity of each 288-month time window up to July 2025 relative to the 1850-1874 baseline period.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [96] [Seismic wave propagation in viscoelastic media under Atangana-Baleanu fractional dynamics: Model formulation and numerical simulations](https://arxiv.org/abs/2512.13897)
*Taylan Demir,Atakan Koçyiğit*

Main category: physics.geo-ph

TL;DR: 提出了一种基于Atangana-Baleanu-Caputo分数阶导数的黏弹性地震波模型，采用有限差分和Adams-Bashforth-Moulton方法进行数值求解，结果表明分数阶记忆效应改变了衰减和频散特性，导致能量非指数衰减。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地描述地震波在黏弹性介质中的传播特性，尤其是非指数的能量衰减行为，引入具有非奇异核的分数阶导数模型。

Method: 采用空间上的有限差分离散和时间上的Adams-Bashforth-Moulton预估-校正格式，对基于Atangana-Baleanu-Caputo分数阶导数的地震波方程进行数值求解。

Result: 模拟结果显示，不同分数阶次下，波场的衰减和频散显著变化，表现出非指数的能量衰减特征，区别于传统的整数阶模型。

Conclusion: 分数阶黏弹性模型能够更好地刻画地震波传播中的记忆效应和复杂耗散机制，为地球物理勘探提供了新的数值模拟工具。

Abstract: We propose a one-dimensional viscoelastic seismic-wave model driven by the Atangana-BaleanuCaputo fractional derivative with a non-singular Mittag-Leffler kernel. A finite-difference discretization in space and an Adams-Bashforth-Moulton predictor-corrector scheme in time are used to compute solutions for several fractional orders. Simulations indicate that fractional memory alters both attenuation and dispersion, leading to non-exponential energy decay compared with the classical integer-order case.

</details>


### [97] [A Generalized Formulation for Accurate and Robust Determination of Soil Shear Strength from Triaxial Tests](https://arxiv.org/abs/2512.13985)
*Altamirano-Muñiz Emilio Fernando*

Main category: physics.geo-ph

TL;DR: 本文提出了一种扩展的基于虚拟位移最小二乘法（LSVD）来估计多种土样在不同抗力条件下的剪切强度参数，能够适应多种破坏包络线形状，并在存在测量误差的情况下仍保持稳健性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理具有测量误差和复杂破坏包络线的土体数据时存在局限，因此需要一种更灵活、鲁棒的方法来准确估计剪切强度参数。

Method: 在原有线性LSVD基础上，提出了对数、抛物线、多项式、幂律及广义形式的LSVD变体，并通过合成噪声环境与p-q法和CTPAC等传统方法进行对比分析。

Result: LSVD方法在模拟噪声下表现出更强的鲁棒性和灵活性，能更好地拟合复杂土体力学行为，且对Mohr圆上代表点的选择不敏感。

Conclusion: LSVD及其广义形式是一种可靠且适应性强的工具，适用于多类型土壤的剪切强度参数估计，具有在岩土工程分析中广泛应用的潜力。

Abstract: This work presents an extended formulation of the Least Squares with Virtual Displacements (LSVD) method for estimating shear strength parameters from multiple soil samples under varying resistance conditions including cohesionless, frictional, and mixed types. LSVD is designed to identify a common tangent across n Mohr circles, even in the presence of measurement errors that render an exact solution infeasible. Beyond its original linear formulation, we introduce generalized LSVD variants like logarithmic, parabolic, polynomial, power law and generalized forms allowing the method to adapt to diverse failure envelope shapes observed in geotechnical materials. We benchmark these variants against established approaches such as the p-q method and CTPAC, analyzing performance under synthetic noise to simulate measurement uncertainty. This provides a comparative framework to assess each method's robustness, especially considering their differing selections of representative points on the Mohr circles. The results highlight LSVD's flexibility and reliability in modeling complex soil behavior and suggest its potential as a versatile tool for geomechanical analysis.

</details>


### [98] [Seesaw of Saltwater and Inundation Drives Methane Emissions in Coastal Tidal Wetlands](https://arxiv.org/abs/2512.14076)
*Xun Cai,Xiucheng Yang,Peter A. Raymond*

Main category: physics.geo-ph

TL;DR: 本研究通过整合海洋模型、遥感数据和元数据分析了美国东海岸潮汐沼泽的甲烷排放，发现盐度与淹没的相互作用是控制甲烷排放的关键因素，海平面上升初期会增加排放，但超过0.75米后盐水入侵将抑制其增长。


<details>
  <summary>Details</summary>
Motivation: 沿海潮汐湿地的甲烷排放受海洋驱动因素（如盐度和潮汐淹没）显著影响，但这些因素在区域评估中 representation 不足，亟需更准确的估算方法。

Method: 结合海洋模型、遥感数据集和来自元数据的经验关系，估算2001至2020年美国东海岸潮汐沼泽的甲烷排放，并分析其时空变化及气候驱动因素。

Result: 2001–2020年间甲烷排放量为0.019–0.038 Tg yr⁻¹，局部通量范围为0–20 g m⁻² day⁻¹；自2007年起排放以每年约802吨的速度持续上升，主要由变暖、淡水化和淹没增强驱动；预测显示海平面上升将增加甲烷排放，但在接近0.75米时因盐水入侵而趋于抑制。

Conclusion: 盐度与淹没的相互作用在沿海甲烷动态中起关键作用，未来气候情景下甲烷排放的变化取决于海平面上升与盐水入侵之间的平衡。

Abstract: Wetlands are significant carbon sinks, yet methane emissions partially offset this function due to its high global warming potential. Coastal tidal wetlands, unlike non-tidal wetlands, are regulated by oceanic drivers like salinity gradients and tidal inundation, which strongly influence methane production and release but remain poorly represented in regional assessments. Here, we estimate methane emissions from U.S. East Coast tidal marshes, by integrating ocean model, remote sensing datasets, empirical relationships from metadata. Spatially, emissions reflect the combined effects of marsh extent and per-unit-area flux rates, with hotspots occurring under lower salinity, higher inundation, and lower latitudes. Temporally, temperature and salinity dominate decadal-scale interannual variability. Between 2001 to 2020, total methane emissions are estimated at 0.019 - 0.038 Tg yr-1, with local fluxes rate ranging from 0 to 20 g m-2 day-1. Following pronounced hydrological variability in the early 2000s, emissions have increased steadily since 2007 at approximately 802 t yr-1, driven by warming, freshening, and enhanced inundation. Projections under IPCC climate scenarios indicate that increasing inundation will amplify methane emissions with sea-level rise, until a threshold near 0.75 m SLR, beyond which saltwater intrusion increasingly suppresses further growth, highlighting the critical role of salinity-inundation interactions in coastal methane dynamics.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [99] [Climatological variability of a thunderstorm environment dataset in tropical and temperate regions](https://arxiv.org/abs/2512.14304)
*Andrew Dowdy,Andrew Brown,Todd Lane,Mateusz Taszarek*

Main category: physics.ao-ph

TL;DR: 本研究利用1979-2023年ERA5再分析数据，分析全球雷暴环境的年际变化及其与气候模态的关系，发现厄尔尼诺-南方涛动等对雷暴环境有显著影响，长期趋势显示雷暴环境总体增加，但变化幅度小于自然变率，不确定性较大。


<details>
  <summary>Details</summary>
Motivation: 了解雷暴发生频率的时空变化及其与气候变率的关系，有助于评估气候变化对极端天气的影响，并为未来风险预测提供科学依据。

Method: 基于ERA5再分析数据构建雷暴环境指数，分析1979-2023年间全球雷暴环境的年际变率、长期趋势，并探讨其与主要气候模态（如ENSO、印度洋偶极子、北极和南极振荡）的关系。

Result: 雷暴环境的年际变率具有显著空间差异；ENSO对其影响最为明显，尤其在热带和海洋地区；长期趋势显示多数地区雷暴环境呈增加趋势，但变化量相对标准差较小，不确定性较高。

Conclusion: 尽管变暖背景下雷暴环境可能更有利于发展，但在1979-2023年间观测到的变化较弱，自然变率主导了雷暴环境的年际波动，需结合多源信息综合评估气候变化对雷暴的影响。

Abstract: Spatiotemporal variations in thunderstorm occurrence frequency are considered here using an environmental dataset derived from ERA5 reanalysis data. Interannual variability in the thunderstorm environments is examined for the period 1979-2023, with the standard deviation and coefficient of variation showing considerable spatial differences through the world. Atmospheric and oceanic modes of climate variability account for some of this interannual variability, particularly for the El Nino-Southern Oscillation through tropical and maritime regions, as well as to a lesser degree for the Indian Ocean Dipole, Arctic Oscillation and Antarctic Oscillation. Long-term trends can also contribute to interannual variability, with results showing increases are more common than decreases in the thunderstorm environments through the study region over the period 1979-2023. However, considerable uncertainties in those trends are noted as is also suggested from some additional analysis of global climate models, indicating that although more favorable thunderstorm environments might occur in a warming world, the estimated change over the period 1979-2023 is relatively small compared to the standard deviation in most locations. The study findings are intended to be complementary to other studies and contribute as part of a broader range of information available on thunderstorms and climate variability.

</details>


### [100] [WaveSim: A Wavelet-based Multi-scale Similarity Metric for Weather and Climate Fields](https://arxiv.org/abs/2512.14656)
*Gabriele Accarino,Viviana Acquaviva,Sara Shamekh,Duncan Watson-Parris,David Lawrence*

Main category: physics.ao-ph

TL;DR: WaveSim是一种用于评估天气和气候应用中空间场的多尺度相似性度量方法，基于小波变换分解场并从幅度、位移和结构三个正交分量计算相似性。


<details>
  <summary>Details</summary>
Motivation: 传统逐点度量无法按物理尺度或差异模式归因误差，缺乏对复杂场相似性的可解释评估手段。

Method: 利用小波变换将输入场分解为尺度特定的小波系数，并从中构建三个正交的相似性分量：幅度（能量分布）、位移（空间偏移）和结构（模式组织），各分量在多尺度上聚合得到总体相似性度量。

Result: 在合成测试和气候变率案例中验证了WaveSim对空间和时间扰动的敏感性和合理性，能够提供可解释且诊断性强的相似性评估。

Conclusion: WaveSim克服了传统指标的局限，提供了可解读、多尺度、可定制的场相似性评估框架，适用于模型比较、评估及预测系统校准。

Abstract: We introduce WaveSim, a multi-scale similarity metric for the evaluation of spatial fields in weather and climate applications. WaveSim exploits wavelet transforms to decompose input fields into scale-specific wavelet coefficients. The metric is built by multiplying three orthogonal components derived from these coefficients: Magnitude, which quantifies similarities in the energy distribution of the coefficients, i.e., the intensity of the field; Displacement, which captures spatial shift by comparing the centers of mass of normalized energy distributions; and Structure, which assesses pattern organization independent of location and amplitude. Each component yields a scale-specific similarity score ranging from 0 (no similarity) to 1 (perfect similarity), which are then combined across scales to produce an overall similarity measure. We first evaluate WaveSim using synthetic test cases, applying controlled spatial and temporal perturbations to systematically assess its sensitivity and expected behavior. We then demonstrate its applicability to physically relevant case studies of key modes of climate variability in Earth System Models. Traditional point-wise metrics lack a mechanism for attributing errors to physical scales or modes of dissimilarity. By operating in the wavelet domain and decomposing the signal along independent axes, WaveSim bypasses these limitations and provides an interpretable and diagnostically rich framework for assessing similarity in complex fields. Additionally, the WaveSim framework allows users to place emphasis on a specific scale or component, and lends itself to user-specific model intercomparison, model evaluation, and calibration and training of forecasting systems. We provide a PyTorch-ready implementation of WaveSim, along with all evaluation scripts, at: https://github.com/gabrieleaccarino/wavesim.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [101] [False Vacuum Decay in Flat-Band Ferromagnets: Role of Quantum Geometry and Chiral Edge States](https://arxiv.org/abs/2512.13786)
*Fabian Pichler,Clemens Kuhlenkamp,Michael Knap*

Main category: cond-mat.str-el

TL;DR: 提出了一种用于探测平带铁磁体中磁化动力学的协议，研究了在虚假真空上制备的磁泡的成核与动态生长，并强调了量子几何在其中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 受近期在转角MoTe2中实现光学控制磁化的实验启发，探索量子物质的动力学控制以研究强关联态。

Method: 通过理论分析和模型计算，研究了巡游铁磁体和自旋极化陈绝缘体中的磁泡动力学，并探讨了非平庸量子几何的影响。

Result: 发现在铁磁金属中量子几何对磁化动力学起关键作用，并可作为量子度量的探针；在量子霍尔铁磁体中，可动态探测局域于畴壁边界的手性边缘模式特性。

Conclusion: 非平衡协议在控制和探测强关联相方面具有潜力，尤其适用于转角MoTe2和基于石墨烯的平带铁磁体系统。

Abstract: Dynamical control of quantum matter is a challenging, yet promising direction for probing strongly correlated states. Motivated by recent experiments in twisted MoTe$_2$ that demonstrated optical control of magnetization, we propose a protocol for probing magnetization dynamics in flat-band ferromagnets. We investigate the nucleation and dynamical growth of magnetic bubbles prepared on top of a false vaccum in both itinerant ferromagnets and spin-polarized Chern insulators. For ferromagnetic metals, we emphasize the crucial role of a non-trivial quantum geometry in the magnetization dynamics, which in turn also provides a probe for the quantum metric. Furthermore, for quantum Hall ferromagnets, we show how properties of chiral edge modes localized at domain-wall boundaries can be dynamically accessed. Our work demonstrates the potential for nonequilibrium protocols to control and probe strongly correlated phases, with particular relevance for twisted MoTe$_2$ and graphene-based flat-band ferromagnets.

</details>


### [102] [Magnetism and superconductivity in bilayer nickelate](https://arxiv.org/abs/2512.13793)
*Hui Yang,Ya-Hui Zhang*

Main category: cond-mat.str-el

TL;DR: 提出了一个包含强Hund耦合的双层type-II t-J模型，用于统一描述双层镍酸盐La₃Ni₂O₇中的高温超导与自旋密度波相，并通过iDMRG计算揭示了条纹状磁序和层间s波超导的竞争机制。


<details>
  <summary>Details</summary>
Motivation: 需要一个最小理论模型来统一解释双层镍酸盐La₃Ni₂O₇中高温超导相与自旋密度波相的共存，而不依赖外部压力或应变。

Method: 构建了一个包含局域dz²轨道磁矩与巡游dx²-y²电子通过强Hund耦合相互作用的模型，在大JH极限下约化为双层type-II t-J模型，并在Ly=4、Lz=2的圆柱几何上进行iDMRG计算。

Result: 发现双交换铁磁性与面内超交换的竞争导致周期为4的条纹状SDW有序，该特征在单轨道t-J模型中不存在；增强层间交换耦合可抑制磁序并稳定层间s波超导。

Conclusion: type-II t-J模型是描述双层镍酸盐中磁性与超导竞争与共存的最小理论框架。

Abstract: The discovery of high-temperature superconductivity in bilayer nickelate La$_{3}$Ni$_{2}$O$_{7}$ necessitates a minimal theoretical model that unifies the superconducting phase with the spin-density-wave (SDW) phase without external pressure or strain. We propose a model where half-filled $d_{z^{2}}$ local moments interact with itinerant $d_{x^{2}-y^{2}}$ electrons via strong Hund's coupling $J_H$, which reduces to a bilayer type-II t-J model in the large $J_H$ limit. Using iDMRG calculations on an $L_y=4, L_z=2$ cylinder, we demonstrate that the competition between double-exchange ferromagnetism and in-plane superexchange generates period-4 stripe-like SDW order-a feature absent in one-orbital t-J model with only $d_{x^2-y^2}$ orbital. Furthermore, increasing the interlayer exchange coupling suppresses magnetic order and stabilizes interlayer s-wave superconductivity. These results identify the type-II t-J model as a minimal framework for capturing the interplay of magnetism and superconductivity in bilayer nickelates.

</details>


### [103] [Correlation functions at the topological quantum phase transition in the S=1 XXZ chain with single-ion anisotropy](https://arxiv.org/abs/2512.14075)
*Toshiya Hikihara,Akira Furusaki*

Main category: cond-mat.str-el

TL;DR: 研究了一维S=1 XXZ自旋模型在单离子各向异性下的相变行为，利用玻色化方法分析了临界点处的关联函数，并通过数值计算验证了理论预测。


<details>
  <summary>Details</summary>
Motivation: 探讨一维S=1 XXZ模型在Haldane相与大D相之间相变点的量子临界行为及其关联函数特性。

Method: 采用玻色化方法推导关联函数的渐近形式，并结合密度矩阵重正化群进行数值验证。

Result: 发现纵向（横向）自旋关联函数仅在均匀（交错）区域呈现代数衰减；弱键交替会诱导出缺失的幂律成分。

Conclusion: 该模型在相变点处的临界行为由中心电荷c=1的高斯共形场理论描述，且键交替显著影响关联函数结构。

Abstract: We study the one-dimensional S=1 XXZ spin model with single-ion anisotropy. It is known that at the transition points between the Haldane and large-D phases, the model exhibits a quantum criticality described by the Gaussian theory, i.e., a conformal field theory with the central charge c=1. Using the bosonization approach, we investigate various correlation functions at the phase transition and derive their asymptotic forms. This allows us to clarify their peculiar behavior: the longitudinal (transverse) two-point spin correlation function has components that decay algebraically only in the uniform (staggered) sector. These theoretical predictions are verified by the numerical calculations using the density-matrix renormalization group method. The effect of weak bond alternation on the critical ground state at the phase transition is also discussed. It is shown that the bond alternation induces the missing power-law components in the correlation functions.

</details>


### [104] [A sine-square deformation approach to quantum critical points in one-dimensional systems](https://arxiv.org/abs/2512.14149)
*Yuki Miyazaki,Shiori Tanigawa,Giacomo Marmorini,Nobuo Furukawa,Daisuke Yamamoto*

Main category: cond-mat.str-el

TL;DR: 提出一种基于正弦平方变形（SSD）的方法，通过局域观测量在热力学极限下是否呈现平移对称性来确定一维系统的量子相变边界，并结合数值计算与有限尺寸标度分析验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在精确确定一维无能隙系统中的量子临界点，克服传统方法对大系统尺寸的依赖，提供一种适用于小尺度系统的高效判定手段。

Method: 利用正弦平方变形（SSD）作用于哈密顿量，假设无能隙系统在SSD下基态的局域观测量在热力学极限中具有平移不变性，通过密度矩阵重正化群（DMRG）算法计算基态并分析局域横向磁化强度的空间依赖性，结合有限尺寸标度外推临界点。

Result: 在近邻和长程相互作用的反铁磁Ising链中成功识别量子临界点；近邻模型结果与文献一致；长程模型显示反铁磁相区域缩小；并提出了在里德堡原子阵列中实现该方案的可行实验路径。

Conclusion: 该方法能从小规模系统中精确提取量子相变边界，具备高精度和实验可实现性，为研究临界现象及提取临界指数提供了新途径。

Abstract: We propose a method to determine the quantum phase boundaries of one-dimensional systems using sine-square deformation (SSD). Based on the proposition, supported by several exactly solved cases though not proven in full generality, that ``if a one-dimensional system is gapless, then the expectation value of any local observable in the ground state of the Hamiltonian with SSD exhibits translational symmetry in the thermodynamic limit," we determine the quantum critical point as the location where a local observable becomes site-independent, identified through finite-size scaling analysis. As case studies, we consider two models: the antiferromagnetic Ising chain in mixed transverse and longitudinal magnetic fields with nearest-neighbor and long-range interactions. We calculate the ground state of these Hamiltonians with SSD using the density-matrix renormalization-group algorithm and evaluate the local transverse magnetization. For the nearest-neighbor model, we show that the quantum critical point can be accurately estimated by our procedure with systems of up to 84 sites, or even smaller, in good agreement with results from the literature. For the long-range model, we find that the phase boundary between the antiferromagnetic and paramagnetic phases is slightly shifted relative to the nearest-neighbor case, leading to a reduced region of antiferromagnetic order. Moreover, we propose an experimental procedure to implement the antiferromagnetic $J_1$-$J_2$ Ising couplings with SSD using Rydberg atom arrays in optical tweezers, which can be achieved within a very good approximation. Because multiple independent scaling conditions naturally emerge, our approach enables precise determination of quantum critical points and possibly even the extraction of additional critical phenomena, such as critical exponents, from relatively small system sizes.

</details>


### [105] [Simplex Crystal Ground State and Magnetization Plateaus in the Spin-$1/2$ Heisenberg Model on the Ruby Lattice](https://arxiv.org/abs/2512.14173)
*Pratyay Ghosh,Frédéric Mila*

Main category: cond-mat.str-el

TL;DR: 研究了自旋1/2海森堡反铁磁体在ruby晶格上的基态性质，发现其具有能隙且三重简并的simplex晶体基态，并在外加塞曼场下表现出多个磁化平台和超固相。


<details>
  <summary>Details</summary>
Motivation: 探索ruby晶格上自旋系统的基态及其在外场下的响应，理解几何阻挫和多体效应如何导致新颖量子态的形成。

Method: 采用无限投影纠缠对态（iPEPS）方法研究系统基态，并分析不同磁场下的磁化行为。

Result: 发现系统在零场下呈现有能隙且三重简并的simplex单重态晶体基态；施加塞曼场后出现m/ms = 0, 1/3, 1/2, 2/3处的磁化平台，其间为打破六重旋转对称性的超固相；这些平台不能用局域磁子描述。

Conclusion: ruby晶格上的自旋系统由于弱三角间耦合和有效手性哈密顿量的广泛简并，形成了独特的simplex单重态基态，并在外场下展现出丰富且对称性破缺的量子相结构。

Abstract: We investigate the spin-$1/2$ Heisenberg antiferromagnet on the ruby lattice with uniform first- and second-neighbor interactions, which forms a two-dimensional network of corner-sharing tetrahedra. Using infinite projected entangled pair states (iPEPS), we study the ground state of the system to find that it assumes a gapped threefold-degenerate simplex crystal ground state, with strong singlets formed on pairs of neighboring triangles. We argue that the formation of the simplex singlet ground state at the isotropic point relates to the weak inter-triangle coupling limit where an effective spin-chirality Hamiltonian on the honeycomb lattice exhibits an extensively degenerate ground state manifold of singlet coverings at the mean-field level. Under an applied Zeeman field, the iPEPS simulations uncover magnetization plateaus at $m/m_s = 0, 1/3, 1/2,$ and $2/3$, separated by intermediate supersolid phases, all breaking the sixfold rotational symmetry of the lattice. Unlike the checkerboard lattice, these plateaus cannot be described by strongly localized magnons.

</details>


### [106] [Acoustic phonon softening and lattice instability driven by on-site $f$-$d$ hybridization in CeCoSi](https://arxiv.org/abs/2512.14216)
*Takeshi Matsumura,Takumi Hasegawa,Ryuma Nakajima,Kenshin Kurauchi,Satoshi Tsutsui,Daisuke Ishikawa,Alfred Q. R. Baron,Hiroshi Tanida*

Main category: cond-mat.str-el

TL;DR: 在四角结构的CeCoSi中，通过高分辨非弹性X射线散射研究发现软声子模式，表现出与(yz+zx)型单斜畸变相关的横波声学模软化，并持续至布里渊区边界，表明晶格不稳定性具有短程关联。这种不稳定性源于缺乏反演对称性的Ce位点上的4f-5d轨道杂化。


<details>
  <summary>Details</summary>
Motivation: 探究CeCoSi在结构相变和反铁磁有序背后的晶格动力学机制，特别是软声子模式的起源及其与电子结构的关系。

Method: 采用高分辨率非弹性X射线散射技术研究CeCoSi中的软声子模式，并分析声学支色散关系及晶格畸变特性。

Result: 观测到与(yz+zx)型单斜畸变相关的横波声学模显著软化，且软化延伸至(0,0,q)方向的布里渊区边界，显示晶格不稳定的短程特性；该不稳定性表现为Curie型应变 susceptibilit  y，归因于Ce位点上4f-5d轨道的局域杂化。

Conclusion: CeCoSi中的晶格不稳定性由缺乏反演对称性导致的4f-5d轨道杂化驱动，是理解其结构相变和潜在电子关联效应的关键因素。

Abstract: Soft phonon modes in tetragonal CeCoSi, which undergoes a structural transition at $T_0=12$ K followed by antiferromagnetic order at $T_{\text{N}}=9.5$ K, have been investigated using high-resolution inelastic x-ray scattering. Pronounced softening was detected in the transverse acoustic modes corresponding to the $(yz+zx)$-type monoclinic distortion, consistent with the experimentally determined triclinic structure. Remarkably, the softening persists up to the zone boundary along (0, 0, $q$), indicating a short correlation length of the lattice instability. This instability, characterized by a Curie-type strain susceptibility, is interpreted as a consequence of the on-site $4f$-$5d$ hybridization, which is intrinsic to this crystal structure due to the lack of inversion symmetry at the two Ce sites.

</details>


### [107] [Pressure-induced hole delocalization in the strongly correlated quasicubic charge-transfer perovskite $LaBa_2Fe_3O_{8+δ}$d](https://arxiv.org/abs/2512.14314)
*M. ElMassalami,S. Favre,M. B. Silva Neto*

Main category: cond-mat.str-el

TL;DR: 通过分析LaBa2Fe3O8+δ的热压电阻演化，构建了其压力-温度相图，揭示了在无结构相变的情况下由局域态向空穴型扩展态转变的临界边界，表明该体系接近量子临界点。


<details>
  <summary>Details</summary>
Motivation: 研究LaBa2Fe3O8+δ在压力和温度下的电子态转变机制，探索其金属-绝缘体转变的本质及是否伴随结构变化。

Method: 通过测量电阻随压力和温度的变化构建P-T相图，并结合室温下高压X射线衍射分析结构稳定性。

Result: 发现较低临界压力下（约3–8 GPa）出现金属化转变，但无结构相变，体系保持准立方钙钛矿结构；同时观察到空穴离域、金属导电性和反铁磁性抑制。

Conclusion: LaBa2Fe3O8+δ中的金属-绝缘体转变是纯粹的电子型转变，源于增强的杂化强度和电荷转移特性，体系在接近临界压力时表现出量子临界行为。

Abstract: Analysis of the thermal and baric evolution of resistance in $LaBa_2Fe_3O_{8+δ}$ enabled the construction of its pressure-temperature (P-T) phase diagram, which prominently displays a critical boundary, $P^{MIT}_c(T)$, marking the transition from localized to hole-type extended states. The relatively low critical pressures [$P^{MIT}_c(T) \approx 3$-8 GPa] suggest that, as $P \rightarrow P_c$ in this narrow-gap, strongly correlated charge-transfer system, both the hybridization strength and the charge-transfer character are progressively enhanced - ultimately leading to the emergence of metallicity. Emphasizing the electronic nature of this transition, pressure-dependent structural analyses at room temperature reveal no associated structural phase transition at $P^{MIT}_c(T)$; the system retains a (weakly tetragonally distorted) quasicubic perovskite structure with Murnaghan-type compressibility up to 30\,GPa. The emergence of hole delocalization and metallic conduction, coupled with suppressed antiferromagnetism, suggests proximity to quantum criticality.

</details>


### [108] [Impact of nonlocal spatial correlations for different lattice geometries](https://arxiv.org/abs/2512.14396)
*Marvin Leusch,Alessandro Toschi,Andreas Hausoel,Giorgio Sangiovanni,Georg Rohringer*

Main category: cond-mat.str-el

TL;DR: 研究了不同布拉维格子几何结构对强关联电子系统中磁有序相变的影响，结合DMFT和DΓA方法分析了局域与非局域关联效应，发现非局域涨落显著降低或消除某些晶格（如fcc）的磁有序转变温度，体现了几何阻挫的重要作用。


<details>
  <summary>Details</summary>
Motivation: 探讨晶格几何结构如何影响强关联电子系统的磁有序相变，并评估DMFT在不同晶格中对转变温度的高估程度。

Method: 采用动力学平均场理论（DMFT）计算多种三维和四维布拉维晶格上的 Hubbard 模型磁化率，并结合动力学顶点近似（DΓA）引入非局域关联效应以改进结果。

Result: 在3d-sc、4d-sc和bcc晶格中，非局域涨落显著降低了DMFT预测的相变温度；随着配位数增加，DMFT与DΓA结果差异减小；而在fcc晶格中，DΓA下DMFT预测的有序相完全消失，表明存在强几何阻挫。

Conclusion: 非局域关联效应在磁相变中起关键作用，DMFT对有序相稳定性的预测存在明显高估，尤其在具有几何阻挫的晶格（如fcc）中需谨慎使用。

Abstract: We analyze the impact of the lattice geometry on the thermodynamic transition to magnetically ordered phases in strongly interacting electron systems for various Bravais lattices in three and four dimensions, including both local and nonlocal correlation effects. In a first step we use the dynamical mean field theory (DMFT), which takes into account purely local correlations, to calculate the magnetic susceptibilities of the Hubbard model on three (3d-sc) and four dimensional (4d-sc) simple cubic/hypercubic, as well as on three dimensional body- (bcc) and face-centered (fcc) cubic lattices, and determine the transition temperature to the corresponding magnetically-ordered state. In a second step, we exploit the dynamical vertex approximation (D$Γ$A), a diagrammatic extension of DMFT, to include the effect of nonlocal correlations which are particularly important in the vicinity of the corresponding phase transition. For the bipartite 3d-sc, 4d-sc and bcc lattices nonlocal fluctuations lead to a substantial reduction of the DMFT transition temperature consistent to the overall tendency of mean-field approaches to overestimate the stability of ordered phases. As expected, the magnitude of the difference between the DMFT, being exact in the limit of large connectivity/dimensions, and D$Γ$A transition temperatures decreases with increasing coordination number. On a more practical perspective, these results also provide a reasonable guidance to evaluate the expected overestimation of the DMFT ordering temperature for different material geometries. For the fcc lattice, on the other hand, the ordered phase observed in DMFT vanishes completely within D$Γ$A which is consistent with the existence of strong geometric frustration in this lattice.

</details>


### [109] [Long-range ferroelectric order in two dimensional excitonic insulators](https://arxiv.org/abs/2512.14558)
*Mikhail M. Glazov,Atac Imamoglu*

Main category: cond-mat.str-el

TL;DR: 在双层半导体中，通过外加电场和磁场调控，可实现层间激子的玻色-爱因斯坦凝聚，突破二维系统中传统认为无法形成长程有序的Mermin-Wagner定理限制。


<details>
  <summary>Details</summary>
Motivation: 探索在二维玻色系统中实现长程有序和玻色-爱因斯坦凝聚的可能性，挑战Mermin-Wagner定理在特定条件下的适用性。

Method: 利用外加电场调节层间带隙，使激子在基态自发产生；结合具有长程电子-空穴交换相互作用的能带结构，并施加有限磁场，理论分析双层半导体中的激子凝聚行为。

Result: 发现在满足特定条件下，二维双层半导体可实现真正的激子玻色-爱因斯坦凝聚，并同时表现出超流性和铁电序。

Conclusion: Mermin-Wagner定理在特定调控条件下可在二维激子系统中被规避，为实现二维系统的长程有序提供了新途径。

Abstract: It is generally argued that Mermin-Wagner theorem excludes the possibility of long-range order in two dimensional bosonic systems at non-zero temperatures. In contrast, we show here that generic bilayer semiconductors could demonstrate true Bose-Einstein condensation of interlayer excitons. We show that the key requirements include (i) reduction of the interlayer band gap using an applied electric field so that excitons spontaneously appear in the ground state, (ii) band structure that allows for long-range electron-hole exchange interaction, and (iii) a finite magnetic field. Our results indicate that superfluidity and ferroelectric order can co-exist in two dimensional excitonic insulators.

</details>


### [110] [Detection of Image Potential States above the vacuum level in GeTe](https://arxiv.org/abs/2512.14597)
*Frédéric Chassot,Aki Pulkkinen,Ján Minár,Gunther Springholz,Matthias Hengsberger,Claude Monney*

Main category: cond-mat.str-el

TL;DR: 在α-GeTe(111)铁电半导体中首次观测到延伸至真空能级以上0.8 eV的三个像势态（IPS），并通过时间与角度分辨光电子能谱结合理论计算揭示其源于强偶极跃迁和材料中的大电子库。


<details>
  <summary>Details</summary>
Motivation: 探索α-GeTe(111)中未被充分研究的导带附近未占据态，特别是高于真空能级的电子态特性。

Method: 采用时间与角度分辨光电子能谱（tr-ARPES）实验手段，并结合布洛赫谱函数计算进行分析。

Result: 观测到三个延伸至真空能级以上0.8 eV的像势态（IPS），解析出其完整的抛物线色散关系并确定结合能；理论表明IPS的存在源于强偶极跃迁和GeTe中丰富的电子库。

Conclusion: α-GeTe(111)中存在异常稳定的高于真空能级的像势态，这归因于材料内在的强偶极响应和大电子密度，为理解铁电半导体表面电子行为提供了新视角。

Abstract: The ferroelectric semiconductor α-GeTe(111) has attracted significant attention in the last decade due to its unique properties, with extensive studies focusing on its occupied electronic bandstructure. In contrast, its unoccupied states - particularly those near the conduction band minimum - remain largely unexplored. In an effort to characterize those states, we surprisingly observe three image potential states (IPS) in α-GeTe(111) extending up to 0.8 eV above the vacuum level. Using time and angle-resolved photoemission spectroscopy, we resolve the full parabolic dispersions of the first three IPS and determine their binding energies. Our analysis, combined with Bloch spectral function calculations, reveals that the unexpected persistence of IPS above the vacuum level originates from strong dipole transitions and the presence of large electron reservoirs in GeTe.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [111] [Co-simulation errors due to step size changes](https://arxiv.org/abs/2512.13845)
*Lars T. Kyllingstad*

Main category: cs.CE

TL;DR: 在连续时间协同仿真中，当两个仿真单元通过变量 $q$ 连接且各自具有表示 $q$ 时间积分的内部状态时，由于外推误差，这些状态之间通常存在差异。本文指出，在某些情况下，即使减小宏观时间步长，步长变化仍可能导致这种差异增大。


<details>
  <summary>Details</summary>
Motivation: 研究在连续时间协同仿真中因外推误差导致的状态不一致问题，特别是在步长减小时误差反而增大的异常现象。

Method: 分析连接仿真单元之间的变量与内部状态关系，探讨不同步长变化对积分状态差异的影响机制。

Result: 发现并证明了在特定条件下，即使减小时间步长，积分状态间的差异也可能因步长变化而增大。

Conclusion: 步长减小并不总能抑制外推误差引起的积分状态差异，需谨慎处理协同仿真中的步长调整策略。

Abstract: When two simulation units in a continuous-time co-simulation are connected via some variable $q$, and both simulation units have an internal state which represents the time integral of $q$, there will generally be a discrepancy between those states due to extrapolation errors. Normally, such extrapolation errors diminish if the macro time step size is reduced. Here we show that, under certain circumstances, step size changes can cause such discrepancies to increase even when the change is towards smaller steps.

</details>


### [112] [A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data](https://arxiv.org/abs/2512.14329)
*Yanning Dai,Chenyu Tang,Ruizhi Zhang,Wenyu Yang,Yilan Zhang,Yuhui Wang,Junliang Chen,Xuhang Chen,Ruimou Xie,Yangyue Cao,Qiaoying Li,Jin Cao,Tao Li,Hubin Zhao,Yu Pan,Arokia Nathan,Xin Gao,Peter Smielewski,Shuo Gao*

Main category: cs.CE

TL;DR: 提出一种数据-物理混合生成框架，通过单次20米平地行走数据重建中风患者神经肌肉控制，预测其在坡道和楼梯等任务中的步态表现，并指导临床康复决策，显著提升康复效果。


<details>
  <summary>Details</summary>
Motivation: 现有的中风后运动能力评估仅提供静态损伤评分，无法动态预测患者能否安全完成如爬坡、爬楼等具体任务，限制了个性化康复方案的制定。

Method: 结合可穿戴传感器运动学数据、比例-微分物理控制器、健康人群运动图谱以及基于目标条件的深度强化学习（结合行为克隆与生成对抗模仿学习），构建个性化的神经肌肉控制模型，从一次平地行走推断并生成患者在不同任务场景下的步态模拟。

Result: 在11名中风患者中，该方法相比纯物理模型将关节角度和端点精度分别提高4.73%和12.10%，训练时间减少至25.56%；在21名住院患者的多中心试验中，使用该预测系统指导康复的临床医生使患者28天内Fugl-Meyer下肢评分平均提升6.0分，优于对照组的3.7分。

Conclusion: 该生成式、任务预测框架能够有效增强中风后步态康复中的临床决策，为动态个性化的运动恢复策略提供了可行模板。

Abstract: Dynamic prediction of locomotor capacity after stroke is crucial for tailoring rehabilitation, yet current assessments provide only static impairment scores and do not indicate whether patients can safely perform specific tasks such as slope walking or stair climbing. Here, we develop a data-physics hybrid generative framework that reconstructs an individual stroke survivor's neuromuscular control from a single 20 m level-ground walking trial and predicts task-conditioned locomotion across rehabilitation scenarios. The system combines wearable-sensor kinematics, a proportional-derivative physics controller, a population Healthy Motion Atlas, and goal-conditioned deep reinforcement learning with behaviour cloning and generative adversarial imitation learning to generate physically plausible, patient-specific gait simulations for slopes and stairs. In 11 stroke survivors, the personalized controllers preserved idiosyncratic gait patterns while improving joint-angle and endpoint fidelity by 4.73% and 12.10%, respectively, and reducing training time to 25.56% relative to a physics-only baseline. In a multicentre pilot involving 21 inpatients, clinicians who used our locomotion predictions to guide task selection and difficulty obtained larger gains in Fugl-Meyer lower-extremity scores over 28 days of standard rehabilitation than control clinicians (mean change 6.0 versus 3.7 points). These findings indicate that our generative, task-predictive framework can augment clinical decision-making in post-stroke gait rehabilitation and provide a template for dynamically personalized motor recovery strategies.

</details>


### [113] [BridgeNet: A Dataset of Graph-based Bridge Structural Models for Machine Learning Applications](https://arxiv.org/abs/2512.14496)
*Lazlo Bleker,Mustafa Cem Güneş,Pierluigi D'Acunto*

Main category: cs.CE

TL;DR: BridgeNet是一个公开的、基于图的包含20,000个形态生成桥梁结构的数据集，旨在推动图机器学习和多模态学习在概念性结构设计中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有结构工程与设计中机器学习的应用受限于缺乏公开可用的结构系统数据集。

Method: 采用组合式平衡建模（CEM）方法生成铰接平衡线框模型，并通过受力引导的材料化方法生成三维体素网格，同时提供两个标准视角的渲染图像，构建多模态图数据集。

Result: 发布了BridgeNet数据集，包含20,000个桥梁结构的图模型、3D网格和图像，支持边分类、参数推断、跨模态重建和生成式设计等多种任务。

Conclusion: BridgeNet解决了结构工程中数据驱动方法面临的关键瓶颈，为基于机器学习的平衡桥梁结构设计提供了有力支持。

Abstract: Machine learning (ML) is increasingly used in structural engineering and design, yet its broader adoption is hampered by the lack of openly accessible datasets of structural systems. We introduce BridgeNet, a publicly available graph-based dataset of 20,000 form-found bridge structures aimed at enabling Graph ML and multi-modal learning in the context of conceptual structural design. Each datapoint consists of (i) a pin-jointed equilibrium wireframe model generated with the Combinatorial Equilibrium Modeling (CEM) form-finding method, (ii) a volumetric 3D mesh obtained through force-informed materialization, and (iii) rendered images from two canonical camera angles. The resulting dataset is modality-rich and application-agnostic, supporting tasks such as CEM-specific edge classification and parameter inference, surrogate modeling of form-finding, cross-modal reconstruction between graphs, meshes and images, and generative structural design. BridgeNet addresses a key bottleneck in data-driven applications for structural engineering and design by providing a dataset that facilitates the development of new ML-based approaches for equilibrium bridge structures.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [114] [Monte Carlo study of phase transitions in model orthonickelate](https://arxiv.org/abs/2512.13761)
*V. S. Ryumshin*

Main category: cond-mat.stat-mech

TL;DR: 本文通过经典蒙特卡洛方法对正交镍酸盐的伪自旋模型进行数值模拟，研究其相变类型。


<details>
  <summary>Details</summary>
Motivation: 探究正交镍酸盐伪自旋模型的相变行为。

Method: 采用经典蒙特卡洛方法并结合玻色子浓度的运动学记录进行数值模拟。

Result: 获得了正交镍酸盐模型的相变类型。

Conclusion: 该模型可用于分析正交镍酸盐中的相变特性。

Abstract: The results of numerical simulation using a classical Monte Carlo method with a kinematic accounting of the bosons concentration for a pseudospin model of orthonickelates are presented. Type of the phase transitions of the model orthonickelates is investigated.

</details>


### [115] [Conservation laws and chaos propagation in a non-reciprocal classical magnet](https://arxiv.org/abs/2512.13873)
*Nisarg Bhatt,Purnendu Das,Subroto Mukerjee,Sriram Ramaswamy*

Main category: cond-mat.stat-mech

TL;DR: 研究了一种非互易性推广的Heisenberg自旋链模型，发现其具有混沌的弹道扩散特性，并在不同耦合情况下表现出不同的动力学行为。


<details>
  <summary>Details</summary>
Motivation: 探索非对称交换耦合下经典Heisenberg自旋链的非互易性动力学及其对混沌传播和守恒量的影响。

Method: 通过分析变换后的变量中的相互作用关系，识别守恒量（如磁化强度和能量），并研究其泊松括号代数与哈密顿动力学；结合水动力理论分析长尺度极限下的行为。

Result: 在纯反对称耦合下，守恒量扩散且装饰因子对称传播，呈现简单水动力行为；一般情况（含对称与反对称部分）在大尺度下更复杂，但混沌的弹道传播依然存在；引入次近邻相互作用后，守恒律通常不再成立。

Conclusion: 非互易性Heisenberg模型展现出丰富的动力学现象，弹道混沌传播具有鲁棒性，而守恒律则对相互作用形式敏感。

Abstract: We study a nonreciprocal generalization [EPL 60, 418 (2002)] of the classical Heisenberg spin chain, in which the exchange coupling is nonsymmetric, and show that it displays a ballistic spreading of chaos as measured by the decorrelator. We show that the interactions are reciprocal in terms of transformed variables, with conserved quantities that can be identified as magnetization and energy, with a Poisson-bracket algebra and Hamiltonian dynamics. For strictly antisymmetric couplings in the original model the conserved quantities diffuse, the decorrelator spreads symmetrically, and a simple hydrodynamic theory emerges. The general case in which the interaction has symmetric and antisymmetric parts presents complexities in the limit of large scales. Ballistic propagation of chaos survives the inclusion of interactions beyond nearest neighbours, but the conservation laws in general do not.

</details>


### [116] [Renormalization group for spectral collapse in random matrices with power-law variance profiles](https://arxiv.org/abs/2512.13883)
*Philipp Fleig*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种基于重整化群（RG）的方法，通过调整自然谱尺度，实现不同系统尺寸下复杂系统随机矩阵模型特征值密度的比较与坍缩。


<details>
  <summary>Details</summary>
Motivation: 为了在不同系统尺寸下有效比较复杂系统的特征值密度，克服传统方法中因尺度差异导致的不可比性。

Method: 通过让模型归一化随系统尺寸变化，定义基于矩阵减除的RG方案，并推导出关于方差分布幂律指数的Beta函数以控制RG流；利用随机矩阵理论推导自洽的固定点方程来计算特征值密度。

Result: 实现了特征值密度曲线的谱坍缩，仿真和固定点方程解均验证了该方法的有效性。

Conclusion: 该RG方法可推广至其他系综，为广泛复杂系统的数据分析提供新工具。

Abstract: We propose a renormalization group (RG) approach to compare and collapse eigenvalue densities of random matrix models of complex systems across different system sizes. The approach is to fix a natural spectral scale by letting the model normalization run with size, turning raw spectra into comparable, collapsed density curves. We demonstrate this approach on generalizations of two classic random matrix ensembles--Wigner and Wishart--modified to have power-law variance profiles. We use random matrix theory methods to derive self-consistent fixed-point equations for the resolvent to compute their eigenvalue densities, we define an RG scheme based on matrix decimation, and compute the Beta function controlling the RG flow as a function of the variance profile power-law exponent. The running normalization leads to spectral collapse which we confirm in simulations and solutions of the fixed-point equations. We expect this RG approach to carry over to other ensembles, providing a method for data analysis of a broad range of complex systems.

</details>


### [117] [Hysteresis, Laning, and Negative Drag in Binary Systems with Opposite and Perpendicular Driving](https://arxiv.org/abs/2512.13925)
*C. Reichhardt,C. J. O. Reichhardt*

Main category: cond-mat.stat-mech

TL;DR: 研究了在外部驱动力下，具有排斥相互作用的二元粒子系统在相反或垂直方向驱动下的相分离、滞后效应及负拖拽现象。


<details>
  <summary>Details</summary>
Motivation: 探索非平衡条件下二元粒子系统在不同驱动方式下的集体行为和相变特性。

Method: 通过数值模拟分析粒子在相反或垂直方向驱动下的运动行为，研究速度-力曲线和拓扑缺陷的变化。

Result: 发现高驱动力下形成具有强滞后的相分离车道态；垂直驱动下出现堵塞态到无序态或倾斜车道态的转变，并观察到负拖拽效应和速度的跳跃行为。

Conclusion: 外部驱动方向和强度显著影响系统的相行为和动态响应，揭示了复杂滞后现象和新型有序结构的形成机制。

Abstract: We consider a binary system of particles with repulsive interactions that move in opposite or perpendicular directions to each other under an applied external drive. For opposite driving, at higher drives a phase-separated laned state forms that has strong hysteresis in the velocity-force curve and the fraction of topological defects as the drive is cycled up and down from zero. The amount of hysteresis depends on the drive value at which the drive changes from increasing to decreasing. For perpendicular driving, we find a jammed state that transitions into a disordered state or a tilted lane state, both of which also show strong hysteresis effects. Additionally, a negative drag effect can appear in which one species moves in the direction opposite to the other species due to a tilting of the lanes by the perpendicular drive. When a constant drive is applied along one direction while the drive in the perpendicular direction is increased, we observe a series of drops and jumps in the velocity as the system forms locked and tilted laned states. For weakly interacting particles, the jammed system can show co-tilted stripe-forming states.

</details>


### [118] [Decomposing Non-Markovian History Dependence](https://arxiv.org/abs/2512.13933)
*Matthew P. Leighton,Christopher W. Lynn*

Main category: cond-mat.stat-mech

TL;DR: 提出一种信息论方法分解非马尔可夫系统中的历史依赖性，并在果蝇行为记录中发现跨时间尺度的历史依赖强度存在非单调性。


<details>
  <summary>Details</summary>
Motivation: 缺乏量化生物学中普遍存在的非马尔可夫过程历史依赖性的通用框架。

Method: 采用信息论方法，分解并量化各阶依赖关系中的历史信息。

Result: 在最小非马尔可夫模型中验证了该方法的有效性；在果蝇行为数据中发现非马尔可夫依赖的标度在多个时间尺度上保持不变，但总体非马尔可夫信息量呈非单调变化。

Conclusion: 该框架能有效捕捉非马尔可夫系统的多阶历史依赖，揭示了生物行为中存在最强历史依赖的独特时间尺度。

Abstract: Non-Markovian stochastic processes are ubiquitous in biology. Nevertheless, we lack a general framework for quantifying historical dependencies. In this Letter, we propose an information-theoretic approach to decompose history dependence in systems with non-Markovian dynamics, quantifying the information encoded in dependencies of each order. In minimal models of non-Markovian dynamics, we show that this framework correctly captures the underlying historical dependencies, even when autocorrelations do not. In prolonged recordings of fly behavior, we find that the scaling of non-Markovian dependencies is invariant across timescales from fractions of a second to minutes. Despite this invariance, the overall amount of non-Markovian information is non-monotonic, suggesting a unique timescale on which historical dependencies are strongest.

</details>


### [119] [Tractable Model for Tunable Non-Markovian Dynamics](https://arxiv.org/abs/2512.13936)
*Matthew P. Leighton,Christopher W. Lynn*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种最小的非马尔可夫动力学模型，能够解析研究历史依赖性、自相关和信息论指标之间的关系，揭示了自相关可能无法准确反映潜在依赖性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏可处理的模型，对非马尔可夫过程的理解远落后于马尔可夫过程，因此需要构建一个简洁且可分析的模型来推动该领域研究。

Method: 构建了一个基于过去状态复制的非马尔可夫动力学模型，具有任意的历史依赖性，并通过解析方法研究其统计特性。

Result: 发现许多性质可以解析求解，但自相关函数可能在定性上也无法捕捉真实的依赖关系。

Conclusion: 该模型为研究非马尔可夫动力学提供了一个可处理的理论框架，有助于深入理解历史依赖与信息动态的关系。

Abstract: Non-Markovian dynamics are ubiquitous across physics, biology, and engineering. Yet our understanding of non-Markovian processes significantly lags that of simpler Markovian processes, due largely to a lack of tractable models. In this article, we present a minimal model of non-Markovian dynamics in which the current state copies past states with arbitrary history dependence. We show that many properties of this process can be studied analytically, providing insight into the relationships between history dependence, autocorrelations, and information-theoretic metrics like entropy and dynamical information. Strikingly, we find that autocorrelations can fail, even qualitatively, to capture the underlying dependencies. Ultimately, this model serves as a tractable sandbox for exploring non-Markovian dynamics.

</details>


### [120] [Age-structured hydrodynamics of ensembles of anomalously diffusing particles with renewal resetting](https://arxiv.org/abs/2512.14345)
*Baruch Meerson,Ohad Vilk*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一种年龄结构化的流体力学理论，用于描述大量异常扩散粒子在随机更新重置下的集体行为，并研究了三种不同的重置协议对非平衡稳态密度的影响。


<details>
  <summary>Details</summary>
Motivation: 为了理解具有全局粒子关联的更新重置规则下，大量异常扩散粒子的集体行为和稳态特性。

Method: 基于尺度布朗运动（sBm）建立年龄结构化流体力学（HD）理论，将粒子年龄作为动态变量，并应用于三种重置协议：独立重置到原点、最远粒子重置到原点以及扩展的“布朗蜜蜂”模型。

Result: 三种模型均达到非平衡稳态；模型A的稳态密度与单粒子情况一致；模型B和布朗蜜蜂模型的稳态密度具有紧支撑特性，且对所有H>0均成立。

Conclusion: 该年龄结构化HD理论可有效描述具有全局关联的异常扩散系统，并能推广至其他具有更新重置机制的复杂扩散过程。

Abstract: We develop an age-structured hydrodynamic (HD) theory which describes the collective behavior of $N\gg 1$ anomalously diffusing particles under stochastic renewal resetting. The theory treats the age of a particle -- the time since its last reset -- as an explicit dynamical variable and allows for resetting rules which introduce global inter-particle correlations. The anomalous diffusion is modeled by the scaled Brownian motion (sBm): a Gaussian process with independent increments, characterized by a power-law time dependence of the diffusion coefficient, $D(t)\sim t^{2H-1}$, where $H>0$. We apply this theory to three different resetting protocols: independent resetting to the origin (model~A), resetting to the origin of the particle farthest from it (model~B), and a scaled-diffusion extension of the ``Brownian bees" model of Berestycki et al, Ann. Probab. \textbf{50}, 2133 (2022). In all these models non-equilibrium steady states are reached at long times, and we determine the steady-state densities. For model A the (normalized to unity) steady-state density coincides with the steady-state probability density of a single particle undergoing sBM with resetting to the origin. For model B, and for the scaled Brownian bees, the HD steady-state densities are markedly different: in particular, they have compact supports for all $H>0$. The age-structured HD formalism can be extended to other anomalous diffusion processes with renewal resetting protocols which introduce global inter-particle correlations.

</details>


### [121] [50 years of Yukhnovskii's critical point theory: its place in the constant flow of theoretical physics](https://arxiv.org/abs/2512.14487)
*Yu. Kozitsky*

Main category: cond-mat.stat-mech

TL;DR: 本文回顾了Ihor Yukhnovskii在三维伊辛模型临界点研究中的层叠积分方法，指出其作为ε展开法的替代方案提供了更深入的物理洞察，并将其置于20世纪后半叶量子场论与统计物理发展的宏观背景下进行评述。


<details>
  <summary>Details</summary>
Motivation: 旨在从现代视角重新评估Yukhnovskii理论的核心思想及其在统计物理和量子场论发展中的历史地位与影响。

Method: 通过回顾Yukhnovskii在集体变量空间中采用的层叠积分方法，并与Wilson的ε展开法进行比较，结合历史发展脉络进行分析。

Result: 表明Yukhnovskii的方法不仅取得了与ε展开相当的结果，且对临界现象的本质提供了更深刻的见解。

Conclusion: Yukhnovskii的理论是统计物理发展中的重要贡献，应被更广泛地认识和重视。

Abstract: Half a century ago, Ihor Yukhnovskii elaborated a method of studying the critical point of the three-dimensional Ising model based on a layer-by-layer integration in the space of collective variables. His method was an alternative to that based on the $\varepsilon$-expansion for which K. G. Wilson was awarded the Nobel Prize in Physics in 1982. However, Yukhnovskii's technique, which yielded similar results, provided even deeper insight into the nature of this phenomenon. At that time, we, professor's students, saw only this aspect of his theory. Later, I realized that the mentioned Yukhnovskii's work naturally fits into a more general context of the turbulent development of quantum field theory and statistical physics in the last quarter of the twentieth century. The aim of the present article is to look at the main aspects and the impact of Yukhnovskii's theory from this perspective.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [122] [Deepfakes in the 2025 Canadian Election: Prevalence, Partisanship, and Platform Dynamics](https://arxiv.org/abs/2512.13915)
*Victor Livernoche,Andreea Musulan,Zachary Yang,Jean-François Godbout,Reihaneh Rabbany*

Main category: cs.SI

TL;DR: 本研究分析了2025年加拿大联邦选举期间X、Bluesky和Reddit平台上18.7万条帖子，发现5.86%的涉选图片为AI生成的深度伪造图像，右倾账户分享频率更高，但大多数深伪内容无害且传播有限，有害内容仅占浏览量的0.12%，整体影响尚属温和但潜在风险值得关注。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成政治内容的担忧加剧，缺乏关于深度伪造媒体在民主国家重大事件中实际出现和传播方式的实证证据，因此需要深入分析其对政治舆论环境的影响。

Method: 通过构建高精度检测框架，训练涵盖多种现代生成模型的数据集，对X、Bluesky和Reddit三个社交平台在2025年加拿大联邦选举期间发布的187,778条帖子中的图像进行深度伪造识别与内容分析，并按政治倾向分类统计传播特征。

Result: 研究发现5.86%的选举相关图片为深度伪造，右倾用户发布比例（8.66%）高于左倾用户（4.42%），多具诽谤或阴谋意图；但绝大多数深伪内容为良性或非政治性，真正造成危害的内容仅获得0.12%的浏览量，总体传播范围有限，而更逼真的伪造图像虽较少见却引发更高互动。

Conclusion: 尽管深度伪造已出现在加拿大选举讨论中，但其实际传播规模和影响力目前仍较有限，然而高仿真图像更高的用户参与度揭示了未来滥用的潜在风险，需加强监测与应对策略。

Abstract: Concerns about AI-generated political content are growing, yet there is limited empirical evidence on how deepfakes actually appear and circulate across social platforms during major events in democratic countries. In this study, we present one of the first in-depth analyses of how these realistic synthetic media shape the political landscape online, focusing specifically on the 2025 Canadian federal election. By analyzing 187,778 posts from X, Bluesky, and Reddit with a high-accuracy detection framework trained on a diverse set of modern generative models, we find that 5.86% of election-related images were deepfakes. Right-leaning accounts shared them more frequently, with 8.66% of their posted images flagged compared to 4.42% for left-leaning users, often with defamatory or conspiratorial intent. Yet, most detected deepfakes were benign or non-political, and harmful ones drew little attention, accounting for only 0.12% of all views on X. Overall, deepfakes were present in the election conversation, but their reach was modest, and realistic fabricated images, although less common, drew higher engagement, highlighting growing concerns about their potential misuse.

</details>


### [123] ["Talking past each other": Issue ownership and microtargeting in Swiss online political ads](https://arxiv.org/abs/2512.14564)
*Arthur Capozzi*

Main category: cs.SI

TL;DR: 本研究分析了2021至2025年间瑞士在Facebook和Instagram上发布的4万条政治广告，揭示了在线政治广告在直接民主制度下的广泛使用及其对公投结果的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨在非选举周期中，社交媒体政治广告如何影响公众决策，特别是在频繁举行公投的直接民主国家如瑞士。

Method: 收集并分析了2021至2025年期间在瑞士发布的40,000条Facebook和Instagram政治广告的数据，结合支出、展示量、受众定位和内容主题进行大规模数据驱动分析。

Result: 发现支持“赞成”立场的广告曝光与公投通过结果显著相关；不同政党采用差异化的微目标定位策略，且存在明显的地域性人口统计差异；内容上呈现“各说各话”模式，政党倾向于推广自己专属议题而非参与共同议题辩论；仅凭受众特征和话题可利用机器学习模型准确预测广告发布者。

Conclusion: 政治广告在直接民主体制下被广泛用于影响公投，其微目标定位和议题分化策略可能导致公共领域的碎片化，削弱传统民主协商过程。

Abstract: Switzerland's unique system of direct democracy, characterized by frequent popular referenda, provides a critical context for studying the impact of online political advertising beyond standard electoral cycles. This paper presents a large-scale, data-driven analysis of 40k political ads published on Facebook and Instagram in Switzerland between 2021 and 2025. Despite a voting population of only 5.6 million, the ad campaigns were significant in scale, costing CHF 4.5 million and achieving 560 million impressions. This study shows that political ads are used not only for federal elections, but also to influence referenda, where greater exposure to ``pro-Yes'' advertising correlates significantly with approval outcomes. The analysis of microtargeting reveals distinct partisan strategies: centrist and right-wing parties predominantly target older men, whereas left-wing parties focus on young women. Furthermore, significant region-specific demographic variations are observed even within the same party, reflecting Switzerland's strong territorial divisions. Regarding content, a clear pattern of ``talking past each other'' is identified: in line with issue ownership theory, parties avoid direct debate on shared issues, preferring to promote exclusively owned topics. Finally, it is demonstrated that these strategies are so distinct that an ad's author can be predicted using a machine learning model trained exclusively on its audience and topic features. This study sheds light on how microtargeting and issue divergence on social platforms may fragment the public sphere and bypass traditional democratic deliberation.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [124] [Unreasonable effectiveness of unsupervised learning in identifying Majorana topology](https://arxiv.org/abs/2512.13825)
*Jacob Taylor,Haining Pan,Sankar Das Sarma*

Main category: cond-mat.dis-nn

TL;DR: 结合无监督与有监督学习，利用自编码器分析无标签数据，识别马约拉纳纳米线中的拓扑序及其参数空间中的交叉区域。


<details>
  <summary>Details</summary>
Motivation: 拓扑序在物理上不总是显而易见（如拓扑超导），需要有效方法进行识别；传统无监督学习资源消耗大且效果不确定。

Method: 采用结合无监督与有监督学习的自编码器方法，对短且无序的马约拉纳纳米线中的无标签数据进行训练和分析。

Result: 该方法能够区分‘拓扑’与‘平凡’态，并确定其在参数空间中的交叉区域。

Conclusion: 所提出的方法可能成为识别马约拉纳纳米线中拓扑序的有效工具。

Abstract: In unsupervised learning, the training data for deep learning does not come with any labels, thus forcing the algorithm to discover hidden patterns in the data for discerning useful information. This, in principle, could be a powerful tool in identifying topological order since topology does not always manifest in obvious physical ways (e.g., topological superconductivity) for its decisive confirmation. The problem, however, is that unsupervised learning is a difficult challenge, necessitating huge computing resources, which may not always work. In the current work, we combine unsupervised and supervised learning using an autoencoder to establish that unlabeled data in the Majorana splitting in realistic short disordered nanowires may enable not only a distinction between `topological' and `trivial', but also where their crossover happens in the relevant parameter space. This may be a useful tool in identifying topology in Majorana nanowires.

</details>


### [125] [On the Boroxol Ring Fraction in Melt-Quenched B$_2$O$_3$ Glass](https://arxiv.org/abs/2512.14526)
*Debendra Meher,Nikhil V. S. Avula,Sundaram Balasubramanian*

Main category: cond-mat.dis-nn

TL;DR: 本研究开发了一种DFT精度的机器学习势，用于模拟熔融淬火B₂O₃玻璃，成功获得了高含量的硼氧六元环（boroxol ring），并通过低淬火速率和长程描述符实现了与实验接近的结构特征。


<details>
  <summary>Details</summary>
Motivation: B₂O₃玻璃中硼氧六元环的中间程有序结构难以在分子动力学模拟中重现，传统方法无法准确捕捉实验观测到的结构特征，因此需要更精确的势能模型和模拟策略。

Method: 采用基于深度势能的机器学习势（DPMD），结合DFT数据训练，并使用低至10^9 K/s的淬火速率进行熔融淬火模拟；系统研究了几何描述符截断半径对压力和硼氧环含量的影响。

Result: 获得的B₂O₃玻璃中超过30%的硼原子处于硼氧环中；需至少9 Å的描述符范围才能正确再现压力和结构；硼氧环比例随淬火速率降低而增加；非晶结构的能量最小值出现在约75%硼氧环时，接近实验估计值。

Conclusion: 该DFT精度的机器学习势能够有效模拟B₂O₃玻璃的原子结构，揭示了淬火速率和描述符范围对中间程有序结构形成的关键作用，为理解玻璃形成机制提供了新途径。

Abstract: An atomistic structural model for melt-quenched B$_2$O$_3$ glass has eluded the simulation community so far. The difficulty lies in the abundance of the six-membered boroxol rings - an intermediate-range order motif suggested through Raman and NMR spectroscopy - which is challenging to obtain in atomistic molecular dynamics simulations. Here, we report the development of a DFT-accurate machine-learned potential for B$_2$O$_3$ and employ quench rates as low as 10$^{9}$ K/s to obtain B$_2$O$_3$ glasses with more than 30% of boron atoms in boroxol rings. Also, we show that the pressure, and consequently the boroxol fraction, in the deep potential molecular dynamics (DPMD) simulations critically depends on the range of the geometry descriptor used in the embedding neural network, and at least a 9 $\unicode{x212B}$ range is required. The boroxol ring fraction increases with decreasing quench rate. Finally, amorphous B$_2$O$_3$ configurations display a minimum in energy at a boroxol fraction of 75%, intriguingly close to the experimental estimate in B$_2$O$_3$ glass.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [126] [Optimal Subgradient Methods for Lipschitz Convex Optimization with Error Bounds](https://arxiv.org/abs/2512.13863)
*Alex L. Wang*

Main category: math.OC

TL;DR: 本文研究了满足一般误差界的Lipschitz凸优化问题的迭代复杂度，证明了次梯度下降法在Polyak步长或衰减步长下可达到最优的收敛性保证。


<details>
  <summary>Details</summary>
Motivation: 为了理解在满足误差界条件下凸优化问题的收敛速度，并填补现有方法在距离最优性减少方面的理论空白。

Method: 采用带有Polyak步长或衰减步长的次梯度下降法，并构造同时满足零链条件和全局误差界的困难函数作为下界分析工具。

Result: 证明了次梯度下降法在此类问题上实现了关于距离最优性减少的最小-最大最优收敛保证。

Conclusion: 对于满足一般误差界的Lipschitz凸优化问题，次梯度下降结合合适步长策略具有最优迭代复杂度。

Abstract: We study the iteration complexity of Lipschitz convex optimization problems satisfying a general error bound. We show that for this class of problems, subgradient descent with either Polyak stepsizes or decaying stepsizes achieves minimax optimal convergence guarantees for decreasing distance-to-optimality. The main contribution is a novel lower-bounding argument that produces hard functions simultaneously satisfying zero-chain conditions and global error bounds.

</details>


### [127] [Volume Formulae for the Convex Hull of the Graph of a Trilinear Monomial: A Complete Characterization for General Box Domains](https://arxiv.org/abs/2512.13964)
*Lillian Makhoul,Emily Speakman*

Main category: math.OC

TL;DR: 本文研究了三线性单项式在混合整数非线性规划中的凸包体积公式，扩展了先前仅限于非负域的结果，提出了适用于一般情况（包含混合符号域）的六种不同体积公式。


<details>
  <summary>Details</summary>
Motivation: 由于实际应用中变量常具有混合符号的定义域，而现有研究仅针对非负边界情况，存在理论空白，因此需要将凸包体积公式推广到更一般的场景。

Method: 通过 exhaustive case analysis（详尽的案例分析），对三线性单项式在一般盒状域上的凸包结构进行分类，结合混合体积技术推导出不同参数配置下的体积公式。

Result: 发现了去除非负假设后凸包多面体结构发生改变，得到了六种不同的体积公式，完整刻画了所有可能的参数情形。

Conclusion: 本文填补了三线性单项式凸包体积研究中的空白，为混合符号域情况提供了精确的凸松弛基准，有助于提升空间分支定界法在复杂问题上的求解效率。

Abstract: Solving difficult mixed-integer nonlinear programs via spatial branch-and-bound requires effective convex outer-approximations of nonconvex sets. In this framework, complex problem formulations are decomposed into simpler library functions, whose relaxations are then composed to build relaxations of the overall problem. The trilinear monomial serves as one such fundamental library function, appearing frequently as a building block across diverse applications. By definition, its convex hull provides the tightest possible relaxation and thus serves as a benchmark for evaluating alternatives. Mixed volume techniques have yielded a parameterized volume formula for the convex hull of the graph of a trilinear monomial; however, existing results only address the case where all six bounds of the box domain are nonnegative. This restriction represents a notable gap in the literature, as variables with mixed-sign domains arise naturally in practice. In this work, we close the gap by extending to the general case via an exhaustive case analysis. We demonstrate that removing the nonnegative domain assumption alters the underlying structure of the convex hull polytope, leading to six distinct volume formulae that together characterize all possible parameter configurations.

</details>


### [128] [Complete Characterizations of Well-Posedness in Parametric Composite Optimization](https://arxiv.org/abs/2512.14124)
*Boris S. Mordukhovich,Peipei Tang,Chengjing Wang*

Main category: math.OC

TL;DR: 本文研究了扰动复合优化问题的KKT系统的适定性，利用抛物正则性建立了二阶次导数与新型二阶变分函数的关系，提出了强二阶充分条件，并给出了二阶资格条件与约束非退化性的等价性，进而获得了KKT系统具有Lipschitz-like性质的多种等价刻画。


<details>
  <summary>Details</summary>
Motivation: 为了对一般复合优化问题的KKT系统进行完整的适定性分析，特别是在扰动下的稳定性与灵敏度研究，需要建立更深入的二阶分析工具和等价条件。

Method: 利用复合模型的抛物正则性，引入新的二阶变分函数，结合C²-锥可约性假设，分析二阶次导数性质，并建立二阶充分条件、二阶资格条件与约束非退化性之间的联系。

Result: 得到了KKT系统具有Lipschitz-like/Aubin性质的多个等价条件；证明了在C²-锥可约性下该性质等价于强正则性；并在一定条件下将其归结为广义雅可比矩阵的非奇异性的验证。

Conclusion: 本文为复合优化问题的KKT系统提供了统一且严格的稳定性与灵敏度分析框架，同时为数值算法的设计与理论支持奠定了基础。

Abstract: This paper provides complete characterization of well-posedness for Karush-Kuhn-Tucker (KKT) systems associated with general problems of perturbed composite optimization. Leveraging the property of parabolic regularity for composite models, we show that the second-order subderivative of the cost function reduces to the novel second-order variational function playing a crucial role in the subsequent analysis. This foundational result implies that the strong second-order sufficient condition (SSOSC) introduced in this work for the general class of composite optimization problems naturally extends the classical second-order sufficient condition in nonlinear programming. Then we obtain several equivalent characterizations of the second-order qualification condition (SOQC) and highlight its equivalence to the constraint nondegeneracy condition under the $\mathcal{C}^{2}$-cone reducibility assumption. These insights lead us to multiple equivalent conditions for the major Lipschitz-like/Aubin property of KKT systems, including the SOQC combined with the new second-order subdifferential condition and the SOQC combined with tilt stability of local minimizers. Furthermore, under $\mathcal{C}^{2}$-cone reducibility, we prove that the Lipschitz-like property of the reference KKT system is equivalent to its strong regularity. Finally, we demonstrate that the Lipschitz-like property is equivalent to the nonsingularity of the generalized Jacobian associated with the KKT system under a certain verifiable assumption. These results provide a unified and rigorous framework for analyzing stability and sensitivity of solutions to composite optimization problems, as well as for the design and justification of numerical algorithms.

</details>


### [129] [Shape design with phase field methods for structural hemivariational inequalities in contact problems](https://arxiv.org/abs/2512.14226)
*Yixin Tan,Fang Feng,Shengfeng Zhu*

Main category: math.OC

TL;DR: 本文研究了在弹性体与刚性体摩擦接触问题中的形状设计和拓扑优化的数学模型，提出基于半变分不等式的灵敏度分析方法，并开发了新的边界变分法和相场算法，数值实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于摩擦接触问题具有非光滑、非凸和非线性的特点，传统变分不等式难以准确描述，因此需要建立更通用且现实的数学模型以实现有效的形状与拓扑优化。

Method: 通过严格的形状灵敏度分析推导半变分不等式的欧拉导数，采用正则化方法处理非光滑性，并提出一种数值边界变分方法用于形状优化；在拓扑优化方面发展了三种相场算法：梯度流相场法、带二阶正则化的相场法以及结合拓扑导数的相场法。

Result: 成功推导出能量型形状泛函的欧拉导数，验证了正则化方法的合理性，并提出了适用于半变分不等式的新颖形状与拓扑优化算法，数值实验表明所提方法具有良好的精度和有效性。

Conclusion: 本文提出的基于半变分不等式的形状和拓扑优化方法为摩擦接触问题提供了新的理论框架和高效数值工具，拓展了结构优化在复杂力学环境下的应用范围。

Abstract: We develop mathematical models for shape design and topology optimization in structural contact problems involving friction between elastic and rigid bodies. The governing mechanical constraint is a nonlinear, non-smooth, and non-convex hemivariational inequality, which provides a more general and realistic description of frictional contact forces than standard variational inequalities, but is also more challenging due to its non-convexity. For energy-type shape functionals, the Eulerian derivative of the hemivariational inequality is derived through rigorous shape sensitivity analysis. The rationality of a regularization approach is justified by asymptotic analysis, and this method is further applied to handle the non-smoothness of general shape functionals in the sensitivity framework. Based on these theoretical results, a numerical boundary variational method is proposed for shape optimization. For topology optimization, three phase-field algorithms are developed: a gradient-flow phase-field method, a phase-field method with second-order regularization of the cost functional, and a phase-field method coupled with topological derivatives. To the best of our knowledge, these approaches are new for shape design in hemivariational inequalities. Various numerical experiments confirm the accuracy and effectiveness of the proposed shape and topology optimization algorithms.

</details>


### [130] [Randomized multi-class classification under system constraints: a unified approach via post-processing](https://arxiv.org/abs/2512.14246)
*Evgenii Chzhen,Mohamed Hebiri,Gayane Taturyan*

Main category: math.OC

TL;DR: 提出了一种无需重新训练的后处理方法，用于在满足线性约束的同时实现多分类。


<details>
  <summary>Details</summary>
Motivation: 在系统级约束下进行多分类时，传统方法难以灵活满足各类实际需求，如公平性、拒绝预测和切换限制等。

Method: 将问题建模为随机分类器上的线性约束随机规划问题，采用熵正则化和对偶优化技术构造可行解。

Result: 提供了最终算法输出在风险和约束满足方面的有限样本保证。

Conclusion: 该框架能有效处理多种系统级约束，且无需重新训练模型即可调整现有分类器。

Abstract: We study the problem of multi-class classification under system-level constraints expressible as linear functionals over randomized classifiers. We propose a post-processing approach that adjusts a given base classifier to satisfy general constraints without retraining. Our method formulates the problem as a linearly constrained stochastic program over randomized classifiers, and leverages entropic regularization and dual optimization techniques to construct a feasible solution. We provide finite-sample guarantees for the risk and constraint satisfaction for the final output of our algorithm under minimal assumptions. The framework accommodates a broad class of constraints, including fairness, abstention, and churn requirements.

</details>


### [131] [Towards Real Time Control of Water Engineering with Nonlinear Hyperbolic Partial Differential Equations](https://arxiv.org/abs/2512.14387)
*Fabio DiFonzo,Michael Holst,Morteza Kimiaei,Vyacheslav Kungurtsev,Songqiang Qiu*

Main category: math.OC

TL;DR: 本文以受浅水方程约束的混合整数优化问题为案例，探讨了实现相关软件所需的关键数学、算法和计算组件，并指出了当前理论与技术上的开放性挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 由于水电级联中的河流流量管理等实际应用需求，需要处理非线性甚至非光滑的偏微分方程动态、控制到状态映射的存在性和正则性缺乏理论保证、以及操作决策所需的计算性能等问题，同时还要考虑来自需求、流入量和环境条件预测的不确定性。

Method: 本文采用案例研究的方法，系统地识别并组织了解决该问题所需的数学建模、数值优化方法和大规模科学计算工具，提出了一个综合框架来梳理关键组成要素。

Result: 提出了一种用于分析和指导复杂混合整数PDE约束优化问题的研究框架，明确了当前在理论基础、算法设计和计算实现方面的差距与挑战。

Conclusion: 目前尚无统一且可行的方法完全解决此类问题，但通过本案例研究可为后续更具体的相关问题提供指导，并有助于推动未来大规模协作研究的设计与发展。

Abstract: This paper examines aspirational requirements for software addressing mixed-integer optimization problems constrained by the nonlinear Shallow Water partial differential equations (PDEs), motivated by applications such as river-flow management in hydropower cascades. Realistic deployment of such software would require the simultaneous treatment of nonlinear and potentially non-smooth PDE dynamics, limited theoretical guarantees on the existence and regularity of control-to-state mappings under varying boundary conditions, and computational performance compatible with operational decision-making. In addition, practical settings motivate consideration of uncertainty arising from forecasts of demand, inflows, and environmental conditions. At present, the theoretical foundations, numerical optimization methods, and large-scale scientific computing tools required to address these challenges in a unified and tractable manner remain the subject of ongoing research across the associated research communities. Rather than proposing a complete solution, this work uses the problem as a case study to identify and organize the mathematical, algorithmic, and computational components that would be necessary for its realization. The resulting framework highlights open challenges and intermediate research directions, and may inform both more circumscribed related problems and the design of future large-scale collaborative efforts aimed at addressing such objectives.

</details>


### [132] [A preconditioned second-order convex splitting algorithm with extrapolation](https://arxiv.org/abs/2512.14468)
*Xinhua Shen,Hongpeng Sun*

Main category: math.OC

TL;DR: 提出了一种结合外推法的预条件二阶凸分裂算法，用于高效求解非凸优化问题，在理论和实验上均表现出良好的收敛性和效率。


<details>
  <summary>Details</summary>
Motivation: 非凸优化问题在机器学习和数据科学中广泛存在，现有方法在效率或收敛性方面存在局限，因此需要更高效的算法。

Method: 将二阶向后微分公式（BDF2）与外推法结合，并采用隐式-显式格式和预条件技术来简化子问题，提升求解效率。

Result: 理论分析证明了算法具有全局收敛性，数值实验在SCAD正则化最小二乘和图像分割等问题上显示了更快的求解速度和竞争力。

Conclusion: 所提算法能高效求解非凸优化问题，兼顾收敛性与计算效率，适用于多种实际应用。

Abstract: Nonconvex optimization problems are widespread in modern machine learning and data science. We introduce an extrapolation strategy into a class of preconditioned second-order convex splitting algorithms for nonconvex optimization problems. The proposed algorithms combine second-order backward differentiation formulas (BDF2) with an extrapolation method. Meanwhile, the implicit-explicit scheme simplifies the subproblem through a preconditioned process. As a result, our approach solves nonconvex problems efficiently without significant computational overhead. Theoretical analysis establishes global convergence of the algorithms using Kurdyka-Łojasiewicz properties. Numerical experiments include a benchmark problem, the least squares problem with SCAD regularization, and an image segmentation problem. These results demonstrate that our algorithms are highly efficient, as they achieve reduced solution times and competitive performance.

</details>


### [133] [An Inexact Modified Quasi-Newton Method for Nonsmooth Regularized Optimization](https://arxiv.org/abs/2512.14507)
*Nathan Allaire,Sébastien Le Digabel,Dominique Orban*

Main category: math.OC

TL;DR: 提出了一种名为iR2N的改进近端拟牛顿方法，用于最小化光滑函数和下半连续近端有界函数之和，允许对函数及其梯度和近端算子进行不精确计算，并在非凸情况下实现全局收敛。


<details>
  <summary>Details</summary>
Motivation: 针对包含非凸项且需要高效计算的优化问题，现有方法难以有效处理不精确计算场景，因此需要一种能利用可控精度和早期终止策略的新算法以节省计算成本。

Method: 采用修改的近端拟牛顿框架，在每次迭代中近似最小化由f的二次模型、h的模型和自适应二次正则项组成的函数，支持f、∇f及近端算子的不精确评估，并通过标准精度假设保证收敛性。

Result: 证明了该方法在标准精度假设下具有全局收敛性，一阶平稳性度量趋于零，最坏情况下的评估复杂度为O(ε⁻²)，并在ℓ_p范数、ℓ_p全变差和非凸伪p-范数球指示函数等实例上验证了其有效性。

Conclusion: iR2N方法能够灵活有效地处理非凸复合优化问题，通过控制不精确性显著降低计算开销，适用于可通过迭代程序近似求解近端算子或控制函数精度的应用场景。

Abstract: We introduce iR2N, a modified proximal quasi-Newton method for minimizing the sum of a smooth function $f$ and a lower semi-continuous prox-bounded function $h$, allowing inexact evaluations of $f$, its gradient, and the associated proximal operators. Both $f$ and $h$ may be nonconvex. iR2N is particularly suited to settings where proximal operators are computed via iterative procedures that can be stopped early, or where the accuracy of $f$ and $\nabla f$ can be controlled, leading to significant computational savings. At each iteration, the method approximately minimizes the sum of a quadratic model of $f$, a model of $h$, and an adaptive quadratic regularization term ensuring global convergence. Under standard accuracy assumptions, we prove global convergence in the sense that a first-order stationarity measure converges to zero, with worst-case evaluation complexity $O(ε^{-2})$. Numerical experiments with $\ell_p$ norms, $\ell_p$ total variation, and the indicator of the nonconvex pseudo $p$-norm ball illustrate the effectiveness and flexibility of the approach, and show how controlled inexactness can substantially reduce computational effort.

</details>


### [134] [The Innovation Null Space of the Kalman Predictor: A Stochastic Perspective for DeePC](https://arxiv.org/abs/2512.14520)
*Aihui Liu,Magnus Jansson*

Main category: math.OC

TL;DR: 本文提出了一种基于Willems引理的改进方法——Kalman滤波基本引理（KFFL），用于在噪声环境下优化数据驱动系统预测。通过将决策变量g限制在创新Hankel矩阵的零空间中，可使预测结果逼近Kalman滤波器。


<details>
  <summary>Details</summary>
Motivation: 在存在噪声的情况下，传统Willems引理中的决策变量g的选择会影响系统预测性能，因此需要一种更优的g选择策略以提升数据驱动方法的鲁棒性与准确性。

Method: 引入Kalman滤波基本引理（KFFL），将Willems引理应用于Kalman预测器，并指出最优的g应位于创新Hankel矩阵的零空间内；分析了多种现有方法（如正则化DeePC、工具变量法和ARX）与此零空间约束的关系。

Result: 证明了当g位于创新Hankel矩阵的零空间时，所得预测器趋近于Kalman预测器；揭示了多种现有数据驱动方法本质上是对该零空间约束的不同实现方式。

Conclusion: 通过引入KFFL，本文为噪声环境下的数据驱动控制提供了理论解释与改进方向，统一理解了多种方法的设计原理，并指出了零空间约束在提升预测性能中的关键作用。

Abstract: Willems' fundamental lemma uses a key decision variable $g$ to combine measured input-output data and describe trajectories of a linear time-invariant system. In this paper, we ask: what is a good choice for this vector $g$ when the system is affected by noise? For a linear system with Gaussian noise, we show that there exists an optimal subspace for this decision variable $g$, which is the null space of the innovation Hankel matrix. If the decision vector lies in this null space, the resulting predictor gets closer to the Kalman predictor. To show this, we use a result that we refer to as the Kalman Filter Fundamental Lemma (KFFL), which applies Willems' lemma to the Kalman predictor. This viewpoint also explains several existing data-driven predictive control methods: regularized DeePC schemes act as soft versions of the innovation null-space constraint, instrumental-variable methods enforce it by construction, and ARX-based approaches explicitly estimate this innovation null space.

</details>


### [135] [Enhancing Orbital Debris Remediation with Reconfigurable Space-Based Laser Constellations](https://arxiv.org/abs/2512.14682)
*David O. Williams Rogers,Hang Woon Lee*

Main category: math.OC

TL;DR: 本文提出了一种基于星座重构的激光清除空间碎片优化框架（R-L2D-ESP），通过动态调整激光卫星位置提升对快速变化碎片环境的响应能力和清理效率。实验表明，可重构星座显著优于静态星座，具有更强的碎片清理能力。


<details>
  <summary>Details</summary>
Motivation: 随着轨道碎片数量迅速增长，传统静态激光清除系统在可扩展性和响应速度方面面临瓶颈，亟需具备动态适应能力的系统级解决方案。

Method: 提出了可重构激光-碎片调度问题（R-L2D-ESP），采用滑动时域优化框架联合优化星座重构序列与激光照射任务分配，以最大化碎片清理容量。

Result: 仿真实验显示，可重构星座比静态星座能清理更多碎片对象，显著提升了清理能力；敏感性分析识别出影响性能的关键参数。

Conclusion: 星座重构是激光基碎片清除系统的重要进步，赋予系统必要的适应性与可扩展性，有助于实现可持续的轨道环境治理。

Abstract: Orbital debris poses an escalating threat to space missions and the long-term sustainability of Earth's orbital environment. The literature proposes various approaches for orbital debris remediation, including the use of multiple space-based lasers that collaboratively engage debris targets. While the proof of concept for this laser-based approach has been demonstrated, critical questions remain about its scalability and responsiveness as the debris population continues to expand rapidly. This paper introduces constellation reconfiguration as a system-level strategy to address these limitations. Through coordinated orbital maneuvers, laser-equipped satellites can dynamically adapt their positions to respond to evolving debris distributions and time-critical events. We formalize this concept as the Reconfigurable Laser-to-Debris Engagement Scheduling Problem (R-L2D-ESP), an optimization framework that determines the optimal sequence of constellation reconfigurations and laser engagements to maximize debris remediation capacity, which quantifies the constellation's ability to nudge, deorbit, or perform just-in-time collision avoidance maneuvers on debris objects. To manage the complexity of this combinatorial optimization problem, we employ a receding horizon approach. Our experiments reveal that reconfigurable constellations significantly outperform static ones, achieving greater debris remediation capacity and successfully deorbiting substantially more debris objects. Additionally, our sensitivity analyses identify the key parameters that influence remediation performance the most, providing essential insights for future system design. These findings demonstrate that constellation reconfiguration represents a promising advancement for laser-based debris removal systems, offering the adaptability and scalability necessary to enhance this particular approach to orbital debris remediation.

</details>
