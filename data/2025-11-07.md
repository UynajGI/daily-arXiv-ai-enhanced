<div id=toc></div>

# Table of Contents

- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 3]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [hep-lat](#hep-lat) [Total: 1]
- [cs.ET](#cs.ET) [Total: 2]
- [physics.soc-ph](#physics.soc-ph) [Total: 3]
- [math.OC](#math.OC) [Total: 13]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [nlin.AO](#nlin.AO) [Total: 1]
- [math.ST](#math.ST) [Total: 7]
- [stat.ME](#stat.ME) [Total: 11]
- [math.NA](#math.NA) [Total: 9]
- [physics.comp-ph](#physics.comp-ph) [Total: 6]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.CE](#cs.CE) [Total: 2]
- [physics.geo-ph](#physics.geo-ph) [Total: 3]
- [eess.SY](#eess.SY) [Total: 18]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 10]
- [nlin.CD](#nlin.CD) [Total: 1]


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [1] [Krylov Complexity Meets Confinement](https://arxiv.org/abs/2511.03783)
*Xuhao Jiang,Jad C. Halimeh,N. S. Srivatsa*

Main category: cond-mat.stat-mech

TL;DR: 本研究利用横场和纵场伊辛模型，通过Krylov态复杂度揭示了量子系统中类夸克禁闭行为的动力学特征，发现禁闭区域中复杂度增长受抑制且振荡频率对应介子质量。


<details>
  <summary>Details</summary>
Motivation: 探索凝聚态系统中类似高能物理禁闭现象的可测量指标，寻求能敏感反映量子信息扩展与束缚态动力学的新探针。

Method: 基于含横场和纵场的伊辛模型，计算淬火后Krylov态复杂度的演化，分析其在不同相（铁磁/顺磁）及跨临界点情况下的增长行为与频谱特征。

Result: 在铁磁相纵场导致的禁闭区，Krylov复杂度增长显著被抑制且出现与介子质量对应的振荡；顺磁相复杂度随纵场增强而上升，跨临界点淬火则呈现弱禁闭特征与极大复杂度；频谱峰值与半经典理论预测吻合。

Conclusion: Krylov态复杂度可作为探测量子系统中禁闭现象的敏感且定量的工具，其演化行为能有效反映束缚态形成与相关动力学过程。

Abstract: In high-energy physics, confinement denotes the tendency of fundamental
particles to remain bound together, preventing their observation as free,
isolated entities. Interestingly, analogous confinement behavior emerges in
certain condensed matter systems, for instance, in the Ising model with both
transverse and longitudinal fields, where domain walls become confined into
meson-like bound states as a result of a longitudinal field-induced linear
potential. In this work, we employ the Ising model to demonstrate that Krylov
state complexity--a measure quantifying the spread of quantum information under
the repeated action of the Hamiltonian on a quantum state--serves as a
sensitive and quantitative probe of confinement. We show that confinement
manifests as a pronounced suppression of Krylov complexity growth following
quenches within the ferromagnetic phase in the presence of a longitudinal
field, reflecting slow correlation dynamics. In contrast, while quenches within
the paramagnetic phase exhibit enhanced complexity with increasing longitudinal
field, reflecting the absence of confinement, those crossing the critical point
to the ferromagnetic phase reveal a distinct regime characterized by
orders-of-magnitude larger complexity and display trends of weak confinement.
Notably, in the confining regime, the complexity oscillates at frequencies
corresponding to the meson masses, with its power-spectrum peaks closely
matching the semiclassical predictions.

</details>


### [2] [Universality Classes with Strong Coupling in Conserved Surface Roughening: Explicit vs Emergent Symmetries](https://arxiv.org/abs/2511.04640)
*Pedro Gatón-Pérez,Enrique Rodriguez-Fernandez,Rodolfo Cuerno*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了一类具有参数n的保守随机演化方程，推广了随机Burgers方程，并通过动力学重正化群分析和数值模拟探讨了其强耦合行为和标度指数对n的依赖性。


<details>
  <summary>Details</summary>
Motivation: 理解非变分但守恒动力学界面的强耦合或非线性标度行为仍不充分，因此需要研究更广泛的守恒随机界面模型。

Method: 提出并研究一类依赖参数n的一维界面保守随机演化方程，采用一阶动力学重正化群分析，并对n=1,2,3的情况进行数值模拟，同时推广了Sasamoto和Spohn的数值格式以处理奇数n的稳定性问题。

Result: 分析表明标度指数依赖于n，奇数n（n=1,3）情况下数值结果提示存在顶点重正化，类似于守恒KPZ方程；而n=0和2时顶点未重正化；高度涨落分布的偏度为零，但峰度非高斯，支持强耦合行为结论。

Conclusion: 奇数n对应的模型在强耦合下表现出顶点重正化行为，且系统在长时间和饱和状态下具有零偏度的非高斯涨落，暗示存在空间对称性或强耦合不动点的涌现对称性。

Abstract: The occurrence of strong coupling or nonlinear scaling behavior for
kinetically rough interfaces whose dynamics are conserved, but not necessarily
variational, remains to be fully understood. Here we formulate and study a
family of conserved stochastic evolution equations for one-dimensional
interfaces, whose nonlinearity depends on a parameter n, thus generalizing that
of the stochastic Burgers equation, whose behavior is retrieved for n=0. This
family of equations includes as particular instances a stochastic porous medium
equation and other continuum models relevant to various hard and soft condensed
matter systems. We perform a one-loop dynamical renormalization group analysis
of the equations, which contemplates strong coupling scaling exponents that
depend on the value of $n$ and may or may not imply vertex renormalization.
These analytical expectations are contrasted with explicit numerical
simulations of the equations with n=1,2, and 3. For odd n, numerical stability
issues have required us to generalize the scheme originally proposed for n=0 by
T. Sasamoto and H. Spohn. Precisely for n=1 and 3, and at variance with the n=0
and 2 cases (whose numerical exponents are consistent with non-renormalization
of the vertex), numerical strong coupling exponent values are obtained which
suggest vertex renormalization, akin to that reported for the celebrated
conserved KPZ equation. We also study numerically the statistics of height
fluctuations, whose probability distribution function turns out (at variance
with cKPZ) to have zero skewness for long times and at saturation, irrespective
of the value of n. However, the kurtosis is non-Gaussian, further supporting
the conclusion on strong coupling asymptotic behavior. The zero skewness seems
related with space symmetries of the n=0 and 2 equations, and with an emergent
symmetry at the strong coupling fixed point for odd values of n.

</details>


### [3] [XYZ integrability the easy way](https://arxiv.org/abs/2511.04674)
*Paul Fendley,Sascha Gehrmann,Eric Vernier,Frank Verstraete*

Main category: cond-mat.stat-mech

TL;DR: 本文通过构造矩阵积算符显式地生成了一系列守恒量，简化了XYZ量子自旋链的可积性证明，并推广到包含杂质相互作用的情形，建立了与传统八顶点模型方法的联系。


<details>
  <summary>Details</summary>
Motivation: 简化XYZ量子自旋链可积性的证明，并推广其到包含边界磁场和杂质的情况。

Method: 通过构造矩阵积算符显式生成守恒量，并验证其与哈密顿量的对易性。

Result: 证明了在周期边界条件或任意边界磁场下，守恒量与XYZ哈密顿量对易；推广得到保持可积性的杂质相互作用，并提出了可积的Kondo问题推广形式。

Conclusion: 提出了一种更简洁的方法证明XYZ链的可积性，并通过引入杂质拓展了可积模型的应用范围，同时与八顶点模型的传统方法建立了联系。

Abstract: Sutherland showed that the XYZ quantum spin-chain Hamiltonian commutes with
the eight-vertex model transfer matrix, so that Baxter's subsequent tour de
force proves the integrability of both. The proof requires parametrising the
Boltzmann weights using elliptic theta functions and showing they satisfy the
Yang-Baxter equation. We here give a simpler derivation of the integrability of
the XYZ chain by explicitly constructing an extensive sequence of conserved
charges from a matrix-product operator. We show that they commute with the XYZ
Hamiltonian with periodic boundary conditions or an arbitrary boundary magnetic
field. A straightforward generalisation yields impurity interactions that
preserve the integrability. Placing such an impurity at the edge gives an
integrable generalisation of the Kondo problem with a gapped bulk. We make
contact with the traditional approach by relating our matrix-product operator
to products of the eight-vertex model transfer matrix.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [4] [Emergent Dynamical Translational Symmetry Breaking as a Dynamical Order Principle for Localization and Topological Transitions](https://arxiv.org/abs/2511.04360)
*Yucheng Wang*

Main category: cond-mat.dis-nn

TL;DR: 本文提出了一种新的动力学平移对称性（DTS）概念，通过长时间动力学定义，利用时间平均的局域平移对比度（TLTC）作为序参量，统一描述安德森局域化、多体局域化和拓扑相变等不同现象，揭示了这些相变背后共有的DTS破缺机制。


<details>
  <summary>Details</summary>
Motivation: 局域化相变是一类重要的连续相变，但不伴随传统对称性破缺，传统框架难以统一描述。因此，需要引入新的对称性概念来解释这类非平衡相变的本质。

Method: 引入动力学平移对称性（DTS）的概念，并定义其序参量——时间平均局域平移对比度（TLTC），通过分析局域观测量的长时间演化行为，判断平移对称性是否被恢复或破坏。

Result: TLTC能够普适地刻画安德森局域化、多体局域化以及拓扑相变，表明这些看似不同的现象均源于DTS的自发破缺。

Conclusion: 该工作建立了超越平衡态范式的统一动力学对称性框架，为理解无对称性破缺的相变提供了新视角。

Abstract: Localization transitions represent a fundamental class of continuous phase
transitions, yet they occur without any accompanying symmetry breaking. We
resolve this by introducing the concept of dynamical translational symmetry
(DTS), which is defined not by the Hamiltonian but by the long-time dynamics of
local observables. Its order parameter, the time-averaged local translational
contrast (TLTC), quantitatively diagnoses whether evolution restores or breaks
translational equivalence. We demonstrate that the TLTC universally captures
the Anderson localization transition, the many-body localization transition,
and topological phase transitions, revealing that these disparate phenomena are
unified by the emergent breaking of DTS. This work establishes a unified
dynamical-symmetry framework for phases transitions beyond the equilibrium
paradigm.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [5] [Classification of four-quark operators with $ΔF\le 2$ under flavor symmetry and their renormalization in a gauge-invariant scheme](https://arxiv.org/abs/2511.04305)
*Gregoris Spanoudes,Marios Costa,Kyproulla Mitsidi,Haralambos Panagopoulos*

Main category: hep-lat

TL;DR: 本文研究了一组完整的标量和赝标量四夸克算符，重点分析了在规范不变重整化方案（GIRS）中的重整化特性，提供了四夸克算符的详细分类，并给出了从GIRS到$\overline{\\text{MS}}$方案在下一级主导阶的转换矩阵。


<details>
  <summary>Details</summary>
Motivation: 为了在强相互作用理论中准确处理四夸克算符的重整化问题，避免与低维算符混合，本文旨在建立一个系统、规范不变的重整化框架。

Method: 通过分析算符在味对称群下的变换性质，识别不与低维算符混合的四夸克算符类别，研究其Fierz恒等式、对称性及混合模式，并探索多种GIRS变体，计算其到$\overline{\\text{MS}}$方案的转换矩阵。

Result: 完成了对ΔF = 2、ΔF = 1和ΔF = 0四夸克算符的系统分类，提出了民主型GIRS等变体，并为混合效应较小的方案计算了下一领头阶的GIRS到$\overline{\\text{MS}}$转换矩阵。

Conclusion: 该研究为四夸克算符的高精度重整化提供了可靠工具，有助于弱相互作用过程的精确理论计算。

Abstract: In this paper we study a complete set of scalar and pseudoscalar four-quark
operators, with a particular emphasis on their renormalization within a
Gauge-Invariant Renormalization Scheme (GIRS). We focus on operators that do
not mix with lower-dimensional operators by virtue of their transformation
properties under the flavor-symmetry group. This class includes all $\Delta F =
2$ operators, as well as their partners that transform under the same
irreducible representations of the flavor group. These encompass a substantial
subset of $\Delta F = 1$ and $\Delta F = 0$ operators. The present analysis
provides a detailed classification of all four-quark operators, exploring their
Fierz identities, symmetry properties, and mixing patterns. Different variants
of GIRS are explored, including a democratic version that treats all mixing
operators uniformly. For selected variants, which exhibit smaller mixing
effects, we present the conversion matrices from GIRS to the
$\overline{\text{MS}}$ scheme at next-to-leading order.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [6] [OpenMENA: An Open-Source Memristor Interfacing and Compute Board for Neuromorphic Edge-AI Applications](https://arxiv.org/abs/2511.03747)
*Ali Safa,Farida Mohsen,Zainab Ali,Bo Wang,Amine Bermak*

Main category: cs.ET

TL;DR: Open-MENA是首个完全开源的忆阻器存内计算加速系统，集成了硬件接口、固件软件栈和高效的权重编程方法，支持边缘AI的高效推理与在线学习，并已开源以推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 为了实现高效能、低功耗的边缘人工智能，亟需支持存内计算和本地学习的开源忆阻器系统，以促进研究和应用发展。

Method: 提出Open-MENA系统，包含可复现的混合信号读-写-验证硬件接口、支持高层API的固件与软件栈，以及VIPI权重编程方法结合芯片闭环微调技术。

Result: 在手写数字识别和真实机器人避障任务中验证了系统有效性，实现了从权重加载到设备上自适应学习的完整流程。

Conclusion: Open-MENA为忆阻器存内计算提供了完整、可复现的开源解决方案，显著推动了边缘AI的研究与实用化。

Abstract: Memristive crossbars enable in-memory multiply-accumulate and local
plasticity learning, offering a path to energy-efficient edge AI. To this end,
we present Open-MENA (Open Memristor-in-Memory Accelerator), which, to our
knowledge, is the first fully open memristor interfacing system integrating (i)
a reproducible hardware interface for memristor crossbars with mixed-signal
read-program-verify loops; (ii) a firmware-software stack with high-level APIs
for inference and on-device learning; and (iii) a Voltage-Incremental
Proportional-Integral (VIPI) method to program pre-trained weights into analog
conductances, followed by chip-in-the-loop fine-tuning to mitigate device
non-idealities. OpenMENA is validated on digit recognition, demonstrating the
flow from weight transfer to on-device adaptation, and on a real-world robot
obstacle-avoidance task, where the memristor-based model learns to map
localization inputs to motor commands. OpenMENA is released as open source to
democratize memristor-enabled edge-AI research.

</details>


### [7] [Implementation of transformer-based LLMs with large-scale optoelectronic neurons on a CMOS image sensor platform](https://arxiv.org/abs/2511.04136)
*Neil Na,Chih-Hao Cheng,Shou-Chen Hsu,Che-Fu Liang,Chung-Chih Lin,Nathaniel Y. Na,Andrew I. Shieh,Erik Chen,Haisheng Rong,Richard A. Soref*

Main category: cs.ET

TL;DR: 本文提出并分析了基于商用CMOS图像传感器平台的大规模光电神经元（OEN）实现Transformer模型的方法，展示了在小尺寸芯片上实现GPT-3级别大模型推理的高能效和高速度，为模拟神经处理单元提供了新的实用路径。


<details>
  <summary>Details</summary>
Motivation: 应对数据中心因大规模语言模型和AI应用部署导致的能源消耗急剧增长问题，探索更高效能的硬件实现方案。

Method: 利用商用CMOS图像传感器平台构建大规模光电神经元（OEN），将所需光电设备与电路集成于约2 cm × 3 cm的芯片上，实现Transformer模型的高效推理。

Result: 在40 nm CMOS工艺下，实现1750亿参数模型（如GPT-3）的推理，达到12.6 POPS的处理速度，功耗效率达74 TOPS/W，面积效率达19 TOPS/mm²，性能超越传统数字电子器件约两个数量级；量化格式与硬件误差影响较小。

Conclusion: 该研究为模拟神经处理单元（NPU）提供了一条兼具高性能与实用性的新路径，有望显著提升AI计算的能效与速度。

Abstract: The recent rapid deployment of datacenter infrastructures for performing
large language models (LLMs) and related artificial intelligence (AI)
applications in the clouds is predicted to incur an exponentially growing
energy consumption in the near-term future. In this paper, we propose and
analyze the implementation of the transformer model, which is the cornerstone
of the modern LLMs, with novel large-scale optoelectronic neurons (OENs)
constructed over the commercially available complementary
metal-oxide-semiconductor (CMOS) image sensor (CIS) platform. With all of the
required optoelectronic devices and electronic circuits integrated in a chiplet
only about 2 cm by 3 cm in size, 175 billon parameters in the case of GPT-3 are
shown to perform inference at an unprecedented speed of 12.6 POPS using only a
40 nm CMOS process node, along with a high power efficiency of 74 TOPS/W and a
high area efficiency of 19 TOPS/mm2, both surpassing the related digital
electronics by roughly two orders of magnitude. The influence of the
quantization formats and the hardware induced errors are numerically
investigated, and are shown to have a minimal impact. Our study presents a new
yet practical path toward analog neural processing units (NPUs) to complement
existing digital processing units.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [8] [Assessing Climate Vulnerability Risk for Substations in Massachusetts Via Sensitivity Analysis](https://arxiv.org/abs/2511.03748)
*Hritik Gopal Shah,Elli Ntakou*

Main category: physics.soc-ph

TL;DR: 本研究提出了一种针对马萨诸塞州配电变电站的气候脆弱性评估模型，整合多源数据和敏感性分析，以支持高效、公平的电网韧性投资决策。


<details>
  <summary>Details</summary>
Motivation: 随着社会对电力系统的依赖日益增加，提升电网应对气候变化的韧性变得至关重要。传统的单变量分析方法存在局限，难以全面评估复杂气候风险，因此需要一种更精确、可复制的评估框架。

Method: 研究结合地理空间分析、气候数据、电力资产信息和电力工程原理，对风暴潮、海平面上升、降水和极端温度等特定灾害进行独立评估，并通过敏感性分析确定气候风险的可操作阈值。

Result: 研究发现某些气候风险的阈值具有高度敏感性，可能导致需采取缓解措施的变电站数量显著增加，强调高精度长期气候预测在适应规划中的关键作用。

Conclusion: 该研究提供了一个实用且可复制的框架，支持以数据为驱动的、公平的气候适应规划，有助于指导电网韧性投资的优先级设定。

Abstract: The electric grid is increasingly vital, supporting essential services such
as healthcare, heating and cooling transportation, telecommunications, and
water systems. This growing dependence on reliable power underscores the need
for enhanced grid resilience. This study presents Eversource's Climate
Vulnerability Assessment (CVA) for bulk distribution substations in
Massachusetts, evaluating risks from storm surge, sea level rise,
precipitation, and extreme temperatures. The focus is on developing a
cost-efficient model to guide targeted resilience investments. This is achieved
by overcoming the limitations of single-variable analyses through
hazard-specific assessments that integrate spatial, climate, electrical asset,
and other relevant data; and applying sensitivity analysis to establish
data-driven thresholds for actionable climate risks. By integrating geospatial
analysis and data modeling with power engineering principles, this study
provides a practical and replicable framework for equitable, data-informed
climate adaptation planning. The results indicate that thresholds for certain
climate hazards can be highly sensitive and result in significantly larger sets
of stations requiring mitigation measures to adequately adapt to climate
change, indicating that high-fidelity long-term climate projections are
critical.

</details>


### [9] [Legal Entanglement](https://arxiv.org/abs/2511.03982)
*Nicholas Godfrey,Ted Sichelman*

Main category: physics.soc-ph

TL;DR: 本文扩展了法律概念纠缠的量化研究，将其应用于法律制定和司法裁判，并联系法律熵与信息含量，探讨法律模块化的边界及其对信息成本的影响，同时提出该模型对法律人工智能理论的改进作用，并反向思考法律理论对量子物理纠缠的启示。


<details>
  <summary>Details</summary>
Motivation: 受量子纠缠及贝尔定理的启发，已有学者用‘纠缠’比喻法律概念间的强关联。Godfrey（2024）首次对法律解释中的纠缠进行数学建模，本文旨在将其扩展至立法与裁判领域，并结合法律熵理论深化对法律系统信息结构的理解。

Method: 基于Godfrey（2024）的数学模型，本文将法律纠缠的量化方法应用于法律制定与司法裁判过程，结合Sichelman（2022）关于法律熵、复杂性与信息含量的研究，分析法律模块化与边界设置在降低信息成本中的作用，并探讨其对法律人工智能建模的意义。

Result: 成功扩展了法律纠缠的量化框架至立法与裁判领域；揭示了法律边界在控制信息传播与成本中的功能；为法律人工智能提供了更精确的理论模型；并提出若将法律纠缠类比物理纠缠，则需重新审视非定域性与经典实在论的放弃方式。

Conclusion: 法律纠缠不仅是一种有效的隐喻，还可作为量化工具用于分析法律系统的结构与动态，其与信息理论的结合有助于优化法律设计与人工智能应用，同时也为物理学中的纠缠理解提供了反向哲学启示。

Abstract: Quantum entanglement is a phenomenon in which two physical systems are
correlated in such a way that they appear to instantaneously affect one
another, regardless of the distance between them. As commonly understood,
Bell's Theorem famously demonstrates that any causal explanation of
entanglement must discard either locality (the principle that nothing,
including information, travels faster than light) or classical notions of
realism (or both). Drawing on this concept, several legal scholars have
metaphorically described 'entangled' legal concepts. For instance, if a state's
highest court redefines the concept of 'foreseeability' in negligence law, this
redefinition alters the concept of 'reasonable care' immediately in the eyes of
the law. Godfrey (2024) is the first work to mathematically model entangled
legal concepts, particularly in the context of legal interpretation. Here, we
extend the quantification to the formulation and delineation of law (lawmaking)
and the adjudication of law (judgment). In so doing, we connect legal
entanglement to Sichelman's (2022) work on legal entropy, complexity, and the
informational content of law. In addition to quantifying entanglement across
various legal contexts, our approach provides broader insights. For example, it
offers a more comprehensive analysis of the uses and limits of 'modularity' in
law--specifically, the role legal boundaries (spatial or intangible) play in
reducing information costs within legal systems. Moreover, we discuss how our
model can improve theories of legal artificial intelligence. Finally, we
explore the application of legal theory back to physics. If quantum physical
entanglement operates analogously to legal entanglement, it requires discarding
both locality and classical realism, though not in the manner commonly
imagined.

</details>


### [10] [The Normal, the Natural, and the Harmonic](https://arxiv.org/abs/2511.03759)
*Theodore Modis*

Main category: physics.soc-ph

TL;DR: 本文通过严格定义“正常”、“自然”和“和谐”等术语，揭示了它们的一些不为人知的方面，指出高斯分布不足以判断“正常”，自然增长曲线的波动未必是“自然”的，并提出实现和谐持续自然增长的条件。


<details>
  <summary>Details</summary>
Motivation: 澄清‘正常’、‘自然’和‘和谐’等常用术语的严格定义，以更准确地理解自然增长过程中的波动与规律。

Method: 采用严格的数学和概念定义，分析高斯分布的局限性，并提出在替代过程中重叠必须受限，以实现和谐的自然增长。

Result: 发现高斯分布不能充分界定‘正常’；自然增长中的波动不一定属于‘自然’；实现和谐自然增长需要控制替代过程中的重叠，并经历好坏交替的‘季节’。

Conclusion: 真正的自然增长需满足特定条件，不能仅依赖统计分布判断；和谐增长是一个包含周期性波动的动态过程。

Abstract: Use is made of rigorous definitions for the terms normal, natural, and
harmonic to reveal a number of unfamiliar aspects about them. The Gaussian
distribution is not sufficient to determine who is normal, and fluctuations
above or below a natural-growth curve may or may not be natural. A recipe for
harmonically sustained natural growth requires that the overlap during the
substitution process must be limited. As a consequence the overall growth
process must experience good as well as bad 'seasons'.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [11] [Hidden Convexity in Queueing Models](https://arxiv.org/abs/2511.03955)
*Xin Chen,Linwei Xin,Minda Zhao*

Main category: math.OC

TL;DR: 该论文研究了在排队系统中联合控制到达率和服务率的问题，目标是最小化长期期望成本减去收益。尽管目标函数是非凸的，但一阶方法在实践中被观察到能收敛到全局最优解。本文通过揭示优化问题的隐式凸性，为这一现象提供了理论基础：经过适当的变量变换后，原问题可以转化为凸优化问题。利用这种隐式凸性，作者证明了原始控制问题满足Polyak-Lojasiewicz-Kurdyka（PLK）条件，从而排除了伪局部极小值，并保证了一阶方法的全局收敛性。分析适用于广泛的GI/GI/1排队模型，包括具有伽马分布到达和服务时间的模型。证明中的一个关键步骤是发现交通强度的平方根变换下，期望队列长度具有新的凸性性质。


<details>
  <summary>Details</summary>
Motivation: 尽管非凸优化问题通常存在多个局部极小值，导致一阶方法难以保证全局收敛，但在实际中，对排队系统的联合控制问题使用一阶方法却能稳定收敛到全局最优。这种经验现象缺乏理论解释，因此需要揭示其背后的优化结构。

Method: 通过变量变换揭示原非凸优化问题中的隐式凸性，并将问题重新表述为凸优化形式。在此基础上，证明其满足Polyak-Lojasiewicz-Kurdyka（PLK）条件，从而保证梯度类算法的全局收敛性。同时，建立交通强度平方根变换下期望队列长度的新型凸性性质，作为理论证明的关键环节。

Result: 1. 揭示了排队系统联合控制问题中的隐式凸性，可通过变量变换实现凸化；2. 证明了该问题满足PLK条件，说明不存在伪局部极小值；3. 为一阶优化方法在该类非凸问题上实现全局收敛提供了理论依据；4. 所得结论适用于包括Gamma分布在内的广泛GI/GI/1模型。

Conclusion: 尽管排队系统中的联合控制问题目标函数非凸，但由于其存在隐式凸结构和PLK性质，一阶优化方法仍可实现全局收敛。这一工作为相关经验观察提供了坚实的理论基础，并拓展了对随机系统优化景观的理解。

Abstract: We study the joint control of arrival and service rates in queueing systems
with the objective of minimizing long-run expected cost minus revenue. Although
the objective function is non-convex, first-order methods have been empirically
observed to converge to globally optimal solutions. This paper provides a
theoretical foundation for this empirical phenomenon by characterizing the
optimization landscape and identifying a hidden convexity: the problem admits a
convex reformulation after an appropriate change of variables. Leveraging this
hidden convexity, we establish the Polyak-Lojasiewicz-Kurdyka (PLK) condition
for the original control problem, which excludes spurious local minima and
ensures global convergence for first-order methods. Our analysis applies to a
broad class of $GI/GI/1$ queueing models, including those with
Gamma-distributed interarrival and service times. As a key ingredient in the
proof, we establish a new convexity property of the expected queue length under
a square-root transformation of the traffic intensity.

</details>


### [12] [Towards optimal control of ensembles of discrete-time systems](https://arxiv.org/abs/2511.04230)
*Christian Fiedler,Alessandro Scagliotti*

Main category: math.OC

TL;DR: 本文研究了离散时间系统集合的最优控制问题，旨在最小化集合的平均有限时域成本。作者在较弱假设下证明了最优解的存在性，并通过Γ-收敛结果为集合最优控制问题提供了可实现的一致逼近方法，为后续研究奠定了理论基础。


<details>
  <summary>Details</summary>
Motivation: 集合控制在量子控制等领域具有重要应用，但其离散时间情形下的最优控制问题尚缺乏系统研究，因此需要建立相应的理论框架。

Method: 采用非线性控制系统的通用模型，结合广义的阶段成本和终端成本，在较弱假设下证明最优控制解的存在性，并利用Γ-收敛理论实现对集合最优控制问题的一致逼近。

Result: 建立了离散时间集合最优控制问题中最优解的存在性；给出了Γ-收敛结果，可用于通过经验概率测度等方法对原问题进行有效逼近。

Conclusion: 该研究为离散时间集合系统的最优控制提供了坚实的理论基础，并为后续的数值逼近和扩展研究开辟了方向。

Abstract: The control of ensembles of dynamical systems is an intriguing and
challenging problem, arising for example in quantum control. We initiate the
investigation of optimal control of ensembles of discrete-time systems,
focusing on minimising the average finite horizon cost over the ensemble. For
very general nonlinear control systems and stage and terminal costs, we
establish existence of minimisers under mild assumptions. Furthermore, we
provide a $\Gamma$-convergence result which enables consistent approximation of
the challenging ensemble optimal control problem, for example, by using
empirical probability measures over the ensemble. Our results form a solid
foundation for discrete-time optimal control of ensembles, with many
interesting avenues for future research.

</details>


### [13] [Some obstacle problems for partially hinged plates and related optimization issues](https://arxiv.org/abs/2511.04287)
*Elvise Berchio,Filomena Feo,Antonio Giuseppe Grimaldi*

Main category: math.OC

TL;DR: 研究了部分铰接矩形板在真实和人工障碍下的优化问题，分别通过最小化振动幅度和最大间隙函数来提升结构稳定性和抗扭性能，并给出了最优密度分布和障碍物的定性性质。


<details>
  <summary>Details</summary>
Motivation: 针对桥梁路面等部分铰接板结构，在存在实际障碍（如防碰撞）和人为引入障碍（增强稳定性）的情况下，优化其动态性能和稳定性。

Method: 建立两种最坏情况下的优化模型：针对真实障碍，以密度分布为变量最小化振动幅度；针对人工障碍，以障碍物为变量最小化板长边间位移的间隙函数最大值。

Result: 证明了两种优化问题解的存在性，并讨论了最优密度分布与最优障碍物的定性特征。

Conclusion: 所提优化方法能有效提升部分铰接板在复杂约束下的稳定性与抗扭能力，且最优解在理论上有良好性质。

Abstract: We study optimization problems for partially hinged rectangular plates,
modeling bridge roadways, in the presence of real and artificial obstacles.
Real obstacles represent structural constraints to avoid, while artificial ones
are introduced to enhance stability. For the former, aiming to prevent
collisions, we set up a worst-case optimization problem in which we minimize
the amplitude of oscillations with respect to the density distribution; for the
latter, aiming to improve the torsional stability, we minimize, with respect to
the obstacles, the maximum of a gap function quantifying the displacement
between the long edges of the plate. For both problems, existence results are
provided, along with a discussion about qualitative properties of optimal
density distributions and obstacles.

</details>


### [14] [On the relationship between MESP and 0/1 D-Opt and their upper bounds](https://arxiv.org/abs/2511.04350)
*Gabriel Ponte,Marcia Fampa,Jon Lee*

Main category: math.OC

TL;DR: 本文建立了最大熵采样与0/1 D-最优性两种非线性0/1优化问题之间的强关联，通过实例映射分析其性质，并在两者间迁移上界方法，获得新的支配结果和不等式关系，同时比较了基于映射的分支定界策略，发现某些原本不具优势的边界方法在转换后变得有效。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示最大熵采样与0/1 D-最优性问题之间的深层联系，以便共享优化方法并提升求解效率。

Method: 通过构建问题实例间的映射关系，分析映射行为，并在两个问题之间迁移上界方法和分支定界策略。

Result: 成功建立了两类问题间的等价映射，迁移了上界技术，获得了新的不等式和支配结果，并发现某些边界方法在转换后显著提升性能。

Conclusion: 最大熵采样与0/1 D-最优性问题之间存在紧密联系，利用映射可有效迁移优化技术，提升算法表现，尤其在实际数据转换后的应用中展现出意外优势。

Abstract: We establish strong connections between two fundamental nonlinear 0/1
optimization problems coming from the area of experimental design, namely
maximum entropy sampling and 0/1 D-Optimality. The connections are based on
maps between instances, and we analyze the behavior of these maps. Using these
maps, we transport basic upper-bounding methods between these two problems, and
we are able to establish new domination results and other inequalities relating
various basic upper bounds. Further, we establish results relating how
different branch-and-bound schemes based on these maps compare. Additionally,
we observe some surprising numerical results, where bounding methods that did
not seem promising in their direct application to real-data MESP instances, are
now useful for MESP instances that come from 0/1 D-Optimality.

</details>


### [15] [Signature-Based Universal Bilinear Approximations for Nonlinear Systems and Model Order Reduction](https://arxiv.org/abs/2511.04303)
*Martin Redmann,Justus Werner*

Main category: math.OC

TL;DR: 本文提出了一种基于签名（signature）的通用双线性系统方法，用于逼近非Lipschitz非线性系统，结合模型降阶技术实现高效建模与非线性系统的降阶，并通过数值实验验证了其在非线性系统模型降阶中的有效性。


<details>
  <summary>Details</summary>
Motivation: 非Lipschitz非线性系统难以直接分析和建模，现有线性化或双线性化方法在大规模系统中可行性低，因此需要一种可扩展且仅依赖数据的方法来有效逼近和简化此类系统。

Method: 利用粗糙路径理论中的签名（作为控制过程的迭代积分集合）将非线性系统近似为一个通用双线性系统，并提出针对含非零初态的不稳定双线性系统的模型降阶方法，结合数据驱动的学习策略实现降维。

Result: 成功构建了可任意逼近原非线性系统行为的高维双线性签名模型，并通过所提降阶方法得到低维近似模型，数值实验表明该方法在非线性系统模型降阶中具有有效性。

Conclusion: 签名方法为非Lipschitz非线性系统提供了一种可行且可扩展的双线性逼近框架，结合专用模型降阶技术，可在无需显式系统知识的情况下实现高效建模与降阶，具有数据驱动和模型导向的双重优势。

Abstract: This paper deals with non-Lipschitz nonlinear systems. Such systems can be
approximated by a linear map of so-called signatures, which play a crucial role
in the theory of rough paths and can be interpreted as collections of iterated
integrals involving the control process. As a consequence, we identify a
universal bilinear system, solved by the signature, that can approximate the
state or output of the original nonlinear dynamics arbitrarily well. In
contrast to other (bi)linearization techniques, the signature approach remains
feasible in large-scale settings, as the dimension of the associated bilinear
system grows only with the number of inputs. However, the signature model is
typically of high order, requiring an optimization process based on model order
reduction (MOR). We derive an MOR method for unstable bilinear systems with
non-zero initial states and apply it to the signature, yielding a potentially
low-dimensional bilinear model. An advantage of our method is that the original
nonlinear system need not be known explicitly, since only data are required to
learn the linear map of the signature. The subsequent MOR procedure is
model-oriented and specifically designed for the signature process.
Consequently, this work has two main applications: (1) efficient modeling/data
fitting using small-scale bilinear systems, and (2) MOR for nonlinear systems.
We illustrate the effectiveness of our approach in the second application
through numerical experiments.

</details>


### [16] [Lower and Upper Bounds for Small Canonical and Ordered Ramsey Numbers](https://arxiv.org/abs/2511.04364)
*Daniel Brosch,Bernard Lidický,Sydney Miyasaki,Diane Puges*

Main category: math.OC

TL;DR: 本文研究了Ramsey数在有序图、规范着色和无序规范着色三种组合环境下的扩展，利用禁忌搜索、整数规划和旗代数方法确定了多个小图的相应Ramsey数。


<details>
  <summary>Details</summary>
Motivation: 将经典Ramsey理论推广到有序结构和不同着色模式下，探索其在组合数学中的新性质与边界行为。

Method: 结合禁忌搜索、整数规划求下界，使用旗代数或整数规划求上界，对小规模图进行系统计算分析。

Result: 确定了所有顶点数不超过四的图G的有序Ramsey数R⃗(G)（除K₄⁻外），所有P₄排序下的ER(P₄)，以及CR(6,3)=26和CR(3,5)=13的精确值。

Conclusion: 通过算法与代数方法的结合，有效推进了有序与规范Ramsey数的研究，为小图情形提供了完整的数值结果与理论支持。

Abstract: In this paper, we investigate three extensions of Ramsey numbers to other
combinatorial settings.
  We first consider ordered Ramsey numbers. Here, we ask for a monochromatic
copy of a linearly ordered graph $G$ in every $2$-edge-coloring of a linearly
ordered complete graph $K_n$. The smallest such $n$ is denoted by $\vec{R}(G)$.
  Next, we study canonical Ramsey numbers. A canonical coloring of a linearly
ordered graph $G$ is an edge-coloring in which $G$ is monochromatic, rainbow,
or min/max-lexicographic. In the latter case, each pair of edges receives the
same color if and only if they share the same first (respectively, second)
vertex. Erd\H{o}s and Rado showed that for every $p$ there exists $n$ such that
every edge-coloring of a linearly ordered $K_n$ contains a canonical copy of
$K_p$; the smallest such $n$ is denoted by $ER(G)$.
  Finally, we examine unordered canonical Ramsey numbers, introduced by Richer.
An edge-coloring of $G$ is orderable if there exists a linear ordering of its
vertices such that the color of each edge is determined by its first vertex.
Unlike lexicographic colorings, this notion also includes monochromatic
colorings. Richer proved that for all $s$ and $t$, there exists $n$ such that
every edge-coloring of $K_n$ contains an orderable copy of $K_s$ or a rainbow
$K_t$. The smallest such $n$ is denoted by $CR(s,t)$.
  In all three settings, we focus on determining the corresponding Ramsey
numbers for small graphs $G$. We use tabu search and integer programming to
obtain lower bounds, and flag algebras or integer programming to establish
upper bounds. Among other results, we determine $\vec{R}(G)$ for all graphs $G$
on up to four vertices except $K_4^-$, $ER(P_4)$ for all orderings of $P_4$,
and the exact values $CR(6,3)=26$ and $CR(3,5)=13$.

</details>


### [17] [Computational Modeling and Learning-Based Adaptive Control of Solid-Fuel Ramjets](https://arxiv.org/abs/2511.04580)
*Gohar T. Khokhar,Kyle Hanquist,Parham Oveissi,Alex Dorsey,Ankit Goel*

Main category: math.OC

TL;DR: 本文提出了一种结合计算流体力学模型与基于学习的自适应控制方法的框架，用于固体燃料冲压发动机（SFRJ）的推力调节，验证了该方法在复杂非线性条件下的有效性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 固体燃料冲压发动机虽具有高能量密度和紧凑结构的优势，但因其强非线性、执行机构能力有限以及多物理场耦合复杂，推力调节面临巨大挑战，亟需一种无需精确降阶模型的鲁棒控制方法。

Method: 开发了一个包含热添加的CFD模型以表征推力响应、确定工作范围并识别进气道失启动点；在此基础上，采用基于回顾性成本自适应控制（RCAC）算法在线更新的自适应比例-积分控制器进行推力调节。

Result: 闭环仿真结果表明，该RCAC控制器在静态和动态工况下均能实现精确的推力调节，并对指令变化、超参数及进气状态变化具有较强鲁棒性。

Conclusion: RCAC方法适用于难以建立精确降阶模型的SFRJ控制系统，展示了基于学习的自适应控制在未来吸气式推进系统中的应用潜力。

Abstract: Solid-fuel ramjets offer a compact, energy-dense propulsion option for
long-range, high-speed flight but pose significant challenges for thrust
regulation due to strong nonlinearities, limited actuation authority, and
complex multi-physics coupling between fuel regression, combustion, and
compressible flow. This paper presents a computational and control framework
that combines a computational fluid dynamics model of an SFRJ with a
learning-based adaptive control approach. A CFD model incorporating heat
addition was developed to characterize thrust response, establish the
operational envelope, and identify the onset of inlet unstart. An adaptive
proportional-integral controller, updated online using the retrospective cost
adaptive control (RCAC) algorithm, was then applied to regulate thrust.
Closed-loop simulations demonstrate that the RCAC-based controller achieves
accurate thrust regulation under both static and dynamic operating conditions,
while remaining robust to variations in commands, hyperparameters, and inlet
states. The results highlight the suitability of RCAC for SFRJ control, where
accurate reduced-order models are challenging to obtain, and underscore the
potential of learning-based adaptive control to enable robust and reliable
operation of SFRJs in future air-breathing propulsion applications.

</details>


### [18] [Robust mean-field control under common noise uncertainty](https://arxiv.org/abs/2511.04515)
*Mathieu Laurière,Ariel Neufeld,Kyunghyun Park*

Main category: math.OC

TL;DR: 本文提出并分析了一个离散时间下受共同噪声不确定性影响的鲁棒均场控制框架，证明了其作为多智能体鲁棒优化问题渐近极限的存在性，并通过数值实验展示了考虑共同噪声不确定性的优势。


<details>
  <summary>Details</summary>
Motivation: 为了在存在共同噪声不确定性的情况下，优化无限多个合作智能体的集体行为，最大化代表性智能体在最坏情况下的期望奖励。

Method: 将鲁棒均场控制问题转化为概率测度空间上的提升型鲁棒马尔可夫决策问题，建立动态规划原理和Bellman-Isaac不动点定理，证明最优开环控制的存在性。

Result: 证明了该鲁棒均场控制问题是N智能体鲁棒优化问题的渐近极限（混沌传播），并建立了动态规划原理和最优控制的存在性。

Conclusion: 所提出的框架有效处理了共同噪声不确定性下的均场控制问题，理论结果通过数值实验在配电规划和金融系统性风险中得到验证。

Abstract: We propose and analyze a framework for discrete-time robust mean-field
control problems under common noise uncertainty. In this framework, the
mean-field interaction describes the collective behavior of infinitely many
cooperative agents' state and action, while the common noise -- a random
disturbance affecting all agents' state dynamics -- is uncertain. A social
planner optimizes over open-loop controls on an infinite horizon to maximize
the representative agent's worst-case expected reward, where worst-case
corresponds to the most adverse probability measure among all candidates
inducing the unknown true law of the common noise process. We refer to this
optimization as a robust mean-field control problem under common noise
uncertainty. We first show that this problem arises as the asymptotic limit of
a cooperative $N$-agent robust optimization problem, commonly known as
propagation of chaos. We then prove the existence of an optimal open-loop
control by linking the robust mean field control problem to a lifted robust
Markov decision problem on the space of probability measures and by
establishing the dynamic programming principle and Bellman--Isaac fixed point
theorem for the lifted robust Markov decision problem. Finally, we complement
our theoretical results with numerical experiments motivated by distribution
planning and systemic risk in finance, highlighting the advantages of
accounting for common noise uncertainty.

</details>


### [19] [On the feasibility of generalized inverse linear programs](https://arxiv.org/abs/2511.04549)
*Christoph Buchheim,Lowig T. Duer*

Main category: math.OC

TL;DR: 研究广义逆线性规划中的可行性问题，分析在不同条件下判断参数是否可使最优解属于目标集Y的复杂性。


<details>
  <summary>Details</summary>
Motivation: 探讨在参数可调的情况下，线性规划最优解是否能落入指定目标集的可行性判定问题及其计算复杂性。

Method: 通过分析目标集Y的结构、LP的形式、可调参数和场景类型（乐观/悲观），研究不同设定下的问题复杂性，并利用固定参数可追踪性等方法进行理论证明。

Result: 对于单点目标集，标准型LP可解，自然型NP难；给定目标基时，标准型在乐观情况下NP完全，悲观情况下仍可解；部分固定解时几乎立即NP难，但对非固定变量数具固定参数可追踪性；任意多面体目标集问题属于NP。

Conclusion: 逆线性规划的可行性问题复杂性高度依赖于问题结构，不同设定下复杂性差异显著，部分情形下可通过固定参数或结构限制实现高效求解。

Abstract: We investigate the feasibility problem for generalized inverse linear
programs. Given an LP with affinely parametrized objective function and
right-hand side as well as a target set Y, the goal is to decide whether the
parameters can be chosen such that there exists an optimal solution that
belongs to Y (optimistic scenario) or such that all optimal solutions belong to
Y (pessimistic scenario). We study the complexity of this decision problem and
show how it depends on the structure of the set Y, the form of the LP, the
adjustable parameters, and the underlying scenario. For a target singleton Y =
{y}, we show that the problem is tractable if the given LP is in standard form,
but NP-hard if the LP is given in natural form. If instead we are given a
target basis B, the problem in standard form becomes NP-complete in the
optimistic case, while remaining tractable in the pessimistic case. For
partially fixed target solutions, the problem gets almost immediately NP-hard,
but we prove fixed-parameter tractability in the number of non-fixed variables.
Moreover, we give a rigorous proof of membership in NP for any polyhedral
target set, and discuss how this property can be extended to more general
target sets using an oracle-based approach.

</details>


### [20] [Unified Theory of Adaptive Variance Reduction](https://arxiv.org/abs/2511.04569)
*Aleksandr Shestakov,Valery Parfenov,Aleksandr Beznosikov*

Main category: math.OC

TL;DR: 本文提出了一种新的方差缩减方法，引入了自适应步长机制，无需超参数调优，并将分析扩展到有偏估计器，适用于有限和问题、分布式优化和坐标方法。


<details>
  <summary>Details</summary>
Motivation: 现有的方差缩减方法多基于无偏估计器，且需要手动调节步长等超参数，限制了其在实际应用中的灵活性和效率。本文旨在突破无偏性假设，并消除对超参数调优的依赖。

Method: 通过推广已有框架，纳入有偏估计器，并设计一种在迭代过程中自适应调整步长的新机制，使得算法能自动适应不同问题结构。该方法覆盖有限和优化、分布式优化及坐标下降法。

Result: 理论分析表明无偏性假设是多余的，所提方法在多种任务上的数值实验验证了其有效性，在收敛速度和稳定性方面表现优越。

Conclusion: 本文提出的自适应步长方差缩减方法不仅扩展了现有理论框架，还提升了实际应用中的便捷性和性能，为随机优化提供了更通用的解决方案。

Abstract: Variance reduction is a family of powerful mechanisms for stochastic
optimization that appears to be helpful in many machine learning tasks. It is
based on estimating the exact gradient with some recursive sequences.
Previously, many papers demonstrated that methods with unbiased
variance-reduction estimators can be described in a single framework. We
generalize this approach and show that the unbiasedness assumption is
excessive; hence, we include biased estimators in this analysis. But the main
contribution of our work is the proposition of new variance reduction methods
with adaptive step sizes that are adjusted throughout the algorithm iterations
and, moreover, do not need hyperparameter tuning. Our analysis covers finite-
sum problems, distributed optimization, and coordinate methods. Numerical
experiments in various tasks validate the effectiveness of our methods.

</details>


### [21] [Knothe-Rosenblatt maps via soft-constrained optimal transport](https://arxiv.org/abs/2511.04579)
*Ricardo Baptista,Franca Hoffmann,Minh Van Hoang Nguyen,Benjamin Zhang*

Main category: math.OC

TL;DR: 本文扩展了Knothe-Rosenblatt（KR）映射的研究，证明其可通过带软约束的加权代价最优传输问题的松弛解序列来获得，并可应用于动态最优传输中的三角速度场构造，为估计KR映射提供了新的变分方法和静态/动态估计器。


<details>
  <summary>Details</summary>
Motivation: KR映射在数学与统计学中具有广泛应用，但其构造依赖于极限过程；作者旨在扩展已有理论，探索通过松弛优化问题和软约束条件构建KR映射的新路径，并连接动态最优传输框架。

Method: 利用带有软约束的加权代价最优传输问题的松弛形式，分析其解序列的极限行为，并将其与KR映射关联；同时结合动态最优传输方法构造三角速度场。

Result: 证明了KR映射可作为带软约束的松弛最优传输问题解序列的极限；该方法同样适用于构造最优速度场，为KR映射的估计提供了理论支持。

Conclusion: 该研究拓展了KR映射的生成方式，不仅加强了其与最优传输理论的联系，还为实际中基于散度最小化的变分估计方法提供了理论依据，并启发了新的静态与动态OT估计方法。

Abstract: In the theory of optimal transport, the Knothe-Rosenblatt (KR) rearrangement
provides an explicit construction to map between two probability measures by
building one-dimensional transformations from the marginal conditionals of one
measure to the other. The KR map has shown to be useful in different realms of
mathematics and statistics, from proving functional inequalities to designing
methodologies for sampling conditional distributions. It is known that the KR
rearrangement can be obtained as the limit of a sequence of optimal transport
maps with a weighted quadratic cost. We extend these results in this work by
showing that one can obtain the KR map as a limit of maps that solve a
relaxation of the weighted-cost optimal transport problem with a
soft-constraint for the target distribution. In addition, we show that this
procedure also applies to the construction of triangular velocity fields via
dynamic optimal transport yielding optimal velocity fields. This justifies
various variational methodologies for estimating KR maps in practice by
minimizing a divergence between the target and pushforward measure through an
approximate map. Moreover, it opens the possibilities for novel static and
dynamic OT estimators for KR maps.

</details>


### [22] [Closing the Gap: Efficient Algorithms for Discrete Wasserstein Barycenters](https://arxiv.org/abs/2511.04607)
*Jiaqi Wang,Weijun Xie*

Main category: math.OC

TL;DR: 本文研究了离散Wasserstein重心问题，提出了一种多项式时间近似方案（PTAS），改进了现有的2-近似算法，并在等权重情况下获得了更紧的近似保证，实验表明算法高效且接近最优。


<details>
  <summary>Details</summary>
Motivation: 离散Wasserstein重心问题是NP难的，现有最好算法仅达到2-近似，因此需要设计具有更好近似保证的高效算法。

Method: 提出了一种新的多项式时间近似方案（PTAS），通过优化加权Wasserstein距离的平均值来求解离散概率测度的重心问题，并针对等权重情况设计了改进算法。

Result: 实现了对离散Wasserstein重心问题的PTAS，打破了2-近似的瓶颈，在等权重情形下获得了更优的近似比，实验验证了算法的有效性和计算效率。

Conclusion: 本文成功解决了离散Wasserstein重心问题的近似算法瓶颈，提出了首个PTAS并取得了优于已有方法的理论与实践结果。

Abstract: The Wasserstein barycenter problem seeks a probability measure that minimizes
the weighted average of the Wasserstein distances to a given collection of
probability measures. We study the discrete setting, where each measure has
finite support-- a regime that frequently arises in machine learning and
operations research. The discrete Wasserstein barycenter problem is known to be
NP-hard, which motivates us to study approximation algorithms with provable
guarantees. The best-known algorithm to date achieves an approximation ratio of
two. We close this gap by developing a polynomial-time approximation scheme
(PTAS) for the discrete Wasserstein barycenter problem that generalizes and
improves upon the 2-approximation method. In addition, for the special case of
equally weighted measures, we obtain a strictly tighter approximation
guarantee. Numerical experiments show that the proposed algorithms are
computationally efficient and produce near-optimal barycenter solutions.

</details>


### [23] [ODE approximation for the Adam algorithm: General and overparametrized setting](https://arxiv.org/abs/2511.04622)
*Steffen Dereich,Arnulf Jentzen,Sebastian Kassing*

Main category: math.OC

TL;DR: 本文提出了一种基于ODE的方法来研究Adam优化器在快慢尺度下的行为，证明了Adam算法是特定向量场流的渐近伪轨迹，并建立了其收敛性结果，指出其极限为Adam向量场的零点而非目标函数的局部极小值或临界点；在过参数化的经验风险最小化设定下，Adam算法能在局部找到全局最小值集合。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解Adam优化器在深度学习中的动态行为，特别是在不同尺度下的收敛特性，本文引入常微分方程（ODE）方法进行分析。

Method: 采用基于常微分方程的分析方法，在固定动量参数和步长趋于零的条件下，将Adam算法视为某一特定向量场流的渐近伪轨迹，并利用其性质研究收敛性。

Result: 证明了Adam算法的极限必须是Adam向量场的零点；在过参数化设定下，若算法无限次进入全局最小值邻域，则会收敛至全局最小值集合。

Conclusion: Adam算法的收敛点不一定是目标函数的临界点，而是由其自身动力系统决定的Adam向量场的零点，但在过参数化情况下仍能有效收敛到全局最小值集。

Abstract: The Adam optimizer is currently presumably the most popular optimization
method in deep learning. In this article we develop an ODE based method to
study the Adam optimizer in a fast-slow scaling regime. For fixed momentum
parameters and vanishing step-sizes, we show that the Adam algorithm is an
asymptotic pseudo-trajectory of the flow of a particular vector field, which is
referred to as the Adam vector field. Leveraging properties of asymptotic
pseudo-trajectories, we establish convergence results for the Adam algorithm.
In particular, in a very general setting we show that if the Adam algorithm
converges, then the limit must be a zero of the Adam vector field, rather than
a local minimizer or critical point of the objective function.
  In contrast, in the overparametrized empirical risk minimization setting, the
Adam algorithm is able to locally find the set of minima. Specifically, we show
that in a neighborhood of the global minima, the objective function serves as a
Lyapunov function for the flow induced by the Adam vector field. As a
consequence, if the Adam algorithm enters a neighborhood of the global minima
infinitely often, it converges to the set of global minima.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [24] [Annual net community production and carbon exports in the central Sargasso Sea from autonomous underwater glider observations](https://arxiv.org/abs/2511.04544)
*Ruth G. Curry,Michael W. Lomas,Megan R. Sullivan,Damian Grundle*

Main category: physics.ao-ph

TL;DR: 利用自主水下滑翔机的高分辨率观测，研究揭示了百慕大时间序列研究站区域碳循环的季节性动态，改进了净群落生产和碳输出的估算一致性。


<details>
  <summary>Details</summary>
Motivation: 解决长期存在的对百慕大时间序列研究站区域年度碳循环理解不一致的问题，尤其是地球化学估算与直接观测之间的差异。

Method: 使用装备有生物地球化学传感器的自主水下滑翔机，基于氧气和硝酸盐的质量平衡，在全年周期内量化净群落生产（ANCP）。

Result: 发现氧气生产和消耗、硝酸盐通量的时空分布具有显著季节性，支持非红菲尔德比碳循环机制的存在，并指出春季樽海鞘垂直迁移可能对碳输出有重要贡献。同时，改进的数据分辨率使ANCP与碳输出（EP）估算更一致。

Conclusion: 高分辨率观测结合精确的光合层深度定义，显著提升了对海洋碳循环过程的理解，并缩小了不同估算方法之间的差距。

Abstract: Despite decades of ship-based observations at the Bermuda Atlantic Timeseries
Study (BATS) site, ambiguities linger in our understanding of the region's
annual carbon cycle. Difficulties reconciling geochemical estimates of annual
net community production (ANCP) with direct measurements of nutrient delivery
and carbon exports (EP) have implied either an insufficient understanding of
these processes, and/or that they are playing out on shorter time and spatial
scales than resolved by monthly sampling. We address the latter concern using
autonomous underwater gliders equipped with biogeochemical sensors to quantify
ANCP from mass balances of oxygen (O2) and nitrate (NO3) over a full annual
cycle. The timing, amplitude and distribution of O2 production, consumption,
and NO3 fluxes reaffirm ideas about strong seasonality in physical forcing and
trophic structure creating a dual system: i.e. production fueled by NO3
supplied to the photic zone from deeper layers in the first half of the year,
versus being recycled within the upper ocean during the second half. The
evidence also supports recently proposed hypotheses regarding the production
and recycling of carbon with non-Redfield characteristics, deplete in nitrogen
and phosphorus, to explain observed patterns of high NCP in the absence of
significant NO3 supply. It further identifies significant contributions to ANCP
and EP potentially linked to vertically migrating communities of salps in
spring after all convective activity has ceased. The improved resolution of the
datasets, combined with more precise definitions of photic and subphotic
integration depths, brings the estimates of ANCP and EP into better alignment
with each other.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [25] [Complex dynamics and route to quasiperiodic synchronization in non-isochronous directed Stuart-Landau triads](https://arxiv.org/abs/2511.04621)
*Ankan Pandey,Sandip Saha,Dibakar Ghosh*

Main category: nlin.AO

TL;DR: 研究了单向耦合非等频Stuart-Landau振子的复杂动力学行为，揭示了周期吸引子在弱强迫或弱耦合下的不稳定性，并发现系统趋向于环面拟周期振荡，结果有助于设计可控的复杂动力系统架构。


<details>
  <summary>Details</summary>
Motivation: 深入理解耦合拓扑、相互作用强度和频率失谐对系统动力学的影响，弥合理论预测与实验观察之间的差距。

Method: 通过计算稳态并进行稳定性分析，结合参数扫描对吸引子类型进行分类。

Result: 发现了周期、拟周期、部分同步和混沌区域，并揭示了弱耦合下周期吸引子的不稳定性导致系统进入拟周期状态。

Conclusion: 该结果为构建复杂且可控的动力学系统提供了理论基础和设计依据。

Abstract: The coupled Stuart-Landau equation serves as a fundamental model for
exploring synchronization and emergent behavior in complex dynamical systems.
However, understanding its dynamics from a comprehensive nonlinear perspective
remains challenging due to the multifaceted influence of coupling topology,
interaction strength, and oscillator frequency detuning. Despite extensive
theoretical investigations over the decades, numerous aspects remain
unexplored, particularly those that bridge theoretical predictions with
experimental observations-an essential step toward deepening our understanding
of real-world dynamical phenomena. This work investigates the complex dynamics
of unidirectionally coupled non-isochronous Stuart-Landau oscillators.
Calculations of steady-states and their stability analysis further reveal that
periodic attractors corresponding to weak forcing or coupling regimes are
dynamically unstable, which pushes the system towards quasiperiodic oscillation
on the torus attractor. The mapping of parameter values with the kind of
attractor of the oscillatory system is presented and classified into periodic,
quasiperiodic, partially synchronized, and chaotic regions. The results of this
study can be leveraged to design complex yet controllable dynamical
architectures.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [26] [The Behrens--Fisher problem revisited](https://arxiv.org/abs/2511.03951)
*Nagananda K G,Jong Sung Kim*

Main category: math.ST

TL;DR: 本文重新研究了双样本Behrens-Fisher问题，推导出经典检验统计量在零假设下的分布的紧凑表达式，通过Mellin-Barnes分解和超几何函数方法，实现了数值稳定的密度与累积分布函数表达，并提供了精确的尾部展开，用于分析Welch近似在不同参数下的保守性与偏差。


<details>
  <summary>Details</summary>
Motivation: Behrens-Fisher问题在方差不等且未知时缺乏精确的检验分布表达式，现有近似方法（如Welch法）在某些参数下存在显著偏差，因此需要精确的分布推导以支持可靠的统计推断。

Method: 采用Mellin-Barnes积分分解技术，将复杂的二维积分简化为单轮廓积分；利用残差级数和Euler-Beta约简，将密度函数表示为高斯超几何函数；结合Ramanujan母定理获得精确的尾部系数。

Result: 得到了检验统计量的精确密度和累积分布函数表达式；推导出代数特例下的截断残差级数；提供了数值稳定的计算形式，并揭示了Welch近似在不同样本量和方差比下从保守到宽松的转变过程及其最大显著性水平偏差。

Conclusion: 本文结果统一并扩展了前人工作，提供了Behrens-Fisher检验的精确分布表达，支持更可靠的尾部推断，并为Welch近似误差提供了量化依据。

Abstract: We revisit the two-sample Behrens--Fisher problem -- testing equality of
means when two normal populations have unequal, unknown variances -- and derive
a compact expression for the null distribution of the classical test statistic.
The key step is a Mellin--Barnes factorization that decouples the square root
of a weighted sum of independent chi-square variates, thereby collapsing a
challenging two-dimensional integral to a tractable single-contour integral.
Closing the contour yields a residue series that terminates whenever either
sample's degrees of freedom is odd. A complementary Euler--Beta reduction
identifies the density as a Gauss hypergeometric function with explicit
parameters, yielding a numerically stable form that recovers Student's $t$
under equal variances. Ramanujan's master theorem supplies exact inverse-power
tail coefficients, which bound Lugannani--Rice saddle-point approximation
errors and support reliable tail analyses. Our result subsumes the
hypergeometric density derived by Nel {\etal}, and extends it with a concise
cdf and analytic tail expansions; their algebraic special cases coincide with
our truncated residue series. Using our derived expressions, we tabulate exact
two-sided critical values over a broad grid of sample sizes and variance ratios
that reveal the parameter surface on which the well-known Welch's approximation
switches from conservative to liberal, quantifying its maximum size distortion.

</details>


### [27] [Finding Planted Cycles in a Random Graph](https://arxiv.org/abs/2511.04058)
*Julia Gaudio,Colin Sandon,Jiaming Xu,Dana Yang*

Main category: math.ST

TL;DR: 本文研究了在ER随机图中寻找植入环的问题，提出了信息论上可实现几乎精确恢复的条件，并设计了一种多项式时间算法，在特定条件下实现了高效恢复，与著名的植入团问题形成鲜明对比。


<details>
  <summary>Details</summary>
Motivation: 受著名植入团问题的启发，研究在随机图中植入环的可恢复性及其计算复杂性，探索是否存在计算-统计间隙。

Method: 通过分析ER随机图中随机子集上的植入环，结合信息论界限和多项式时间算法设计，研究几乎精确恢复的可行性。

Result: 证明了当λ小于某个阈值时，几乎精确恢复在信息论上是可行的，并提出了一个多项式时间算法实现该恢复；当λ大于该阈值时则不可行。

Conclusion: 与植入团问题不同，植入环问题在特定条件下不存在显著的计算-统计间隙，且可通过高效算法实现几乎精确恢复。

Abstract: In this paper, we study the problem of finding a collection of planted cycles
in an \ER random graph $G \sim \mathcal{G}(n, \lambda/n)$, in analogy to the
famous Planted Clique Problem. When the cycles are planted on a uniformly
random subset of $\delta n$ vertices, we show that almost-exact recovery (that
is, recovering all but a vanishing fraction of planted-cycle edges as $n \to
\infty$) is information-theoretically possible if $\lambda < \frac{1}{(\sqrt{2
\delta} + \sqrt{1-\delta})^2}$ and impossible if $\lambda > \frac{1}{(\sqrt{2
\delta} + \sqrt{1-\delta})^2}$. Moreover, despite the worst-case computational
hardness of finding long cycles, we design a polynomial-time algorithm that
attains almost exact recovery when $\lambda < \frac{1}{(\sqrt{2 \delta} +
\sqrt{1-\delta})^2}$. This stands in stark contrast to the Planted Clique
Problem, where a significant computational-statistical gap is widely
conjectured.

</details>


### [28] [A Generalized Back-Door Criterion for Linear Regression](https://arxiv.org/abs/2511.04060)
*Masato Shimokawa*

Main category: math.ST

TL;DR: 本文推广了Pearl的单门和后门准则，提出了一种新准则，用于识别总或部分因果效应，并揭示了后处理偏差的机制，指出节点的重复序列可能是该偏差的来源。


<details>
  <summary>Details</summary>
Motivation: 为了明确在何种数据生成过程中可以对回归系数进行因果解释，需要扩展现有的因果识别准则。

Method: 通过推广Pearl的单门和后门准则，提出一个新的识别准则，并分析线性数据生成过程中后处理偏差的来源。

Result: 提出了一个新的因果效应识别准则，阐明了后处理偏差的机制，发现节点的重复序列可能引发该偏差。

Conclusion: 该新准则适用于具有无分布假设误差项的有向无环图表示的线性数据生成过程，可有效识别因果效应并避免后处理偏差。

Abstract: What assumptions about the data-generating process are required to permit a
causal interpretation of partial regression coefficients? To answer this
question, this paper generalizes Pearl's single-door and back-door criteria and
proposes a new criterion, which enables the identification of total or partial
causal effects. In addition, this paper elucidates the mechanism of
post-treatment bias, showing that a repeated sequence of nodes can be a
potential source of this bias. The results apply to linear data-generating
processes represented by directed acyclic graphs with distribution-free error
terms.

</details>


### [29] [Goodness-of-fit testing of the distribution of posterior classification probabilities for validating model-based clustering](https://arxiv.org/abs/2511.04206)
*Salima El Kolei,Matthieu Marbac*

Main category: math.ST

TL;DR: 提出了一种评估模型聚类结果相关性的新方法，适用于参数和非参数框架，基于经验似然法和条件概率拟合度检验。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对模型聚类结果相关性的统一评估手段，尤其在不同数据类型和模型下难以适用。

Method: 利用混合模型定义的聚类成员条件概率，结合经验似然法和越来越多的矩条件，在数据分块基础上计算经验对数似然比，检验模型拟合优度。

Result: 该方法无需额外估计量，仅需参数的一致估计和每个观测的分类后验概率，能够获得精确的渐近显著性水平。

Conclusion: 所提方法通用性强，适用于任意数据类型和混合模型，为模型聚类结果提供了可靠的拟合优度检验工具。

Abstract: We present the first method for assessing the relevance of a model-based
clustering result in both parametric and non-parametric frameworks. The method
directly aligns with the clustering objective by assessing how well the
conditional probabilities of cluster memberships, as defined by the mixture
model, fit the data. By focusing on these conditional probabilities, the
procedure applies to any type and dimension of data and any mixture model. The
testing procedure requires only a consistent estimator of the parameters and
the associated conditional probabilities of classification for each
observation. Its implementation is straightforward, as no additional estimator
is needed. Under the null hypothesis, the method relies on the fact that any
functional transformation of the posterior probabilities of classification has
the same expectation under both the model being tested and the true model. This
goodness-of-fit procedure is based on a empirical likelihood method with an
increasing number of moment conditions to asymptotically detect any
alternative. Data are split into blocks to account for the use of a parameter
estimator, and the empirical log-likelihood ratio is computed for each block.
By analyzing the deviation of the maximum empirical log-likelihood ratios, the
exact asymptotic significance level of the goodnessof-fit procedure is
obtained.

</details>


### [30] [Rates of Convergence of Maximum Smoothed Log-Likelihood Estimators for Semi-Parametric Multivariate Mixtures](https://arxiv.org/abs/2511.04226)
*Marie Du Roy de Chaumaray,Michael Levine,Matthieu Marbac*

Main category: math.ST

TL;DR: 本文为半参数有限混合模型中的标准估计器建立了理论保证，提出了一种基于平滑对数似然函数的最大化估计方法，并证明了其一致性及收敛速率，填补了实际算法与统计理论之间的空白。


<details>
  <summary>Details</summary>
Motivation: 在半参数混合模型中，尽管已有许多实用的估计方法，但缺乏严格的理论支持。本文旨在为基于平滑似然的估计方法提供首个严谨的理论保证。

Method: 采用最大化平滑对数似然函数的估计方法，利用核卷积定义非线性正则化算子，并通过majorization-minimization算法高效计算；结合M-估计框架和对剖面平滑似然的分析，推导估计量的一致性和收敛速率。

Result: 证明了估计量在温和正则条件下的一致性，并得到了有限维和无限维参数的收敛速率。

Conclusion: 本文为条件独立假设下的半参数混合模型提供了首个严格的理论分析，建立了平滑似然方法的理论基础，弥合了算法实践与统计理论之间的差距。

Abstract: Theoretical guarantees are established for a standard estimator in a
semi-parametric finite mixture model, where each component density is modeled
as a product of univariate densities under a conditional independence
assumption. The focus is on the estimator that maximizes a smoothed
log-likelihood function, which can be efficiently computed using a
majorization-minimization algorithm. This smoothed likelihood applies a
nonlinear regularization operator defined as the exponential of a kernel
convolution on the logarithm of each component density. Consistency of the
estimators is demonstrated by leveraging classical M-estimation frameworks
under mild regularity conditions. Subsequently, convergence rates for both
finite- and infinite-dimensional parameters are derived by exploiting
structural properties of the smoothed likelihood, the behavior of the iterative
optimization algorithm, and a thorough study of the profile smoothed
likelihood. This work provides the first rigorous theoretical guarantees for
this estimation approach, bridging the gap between practical algorithms and
statistical theory in semi-parametric mixture modeling.

</details>


### [31] [An Approximate Bayesian Approach to Optimal Input Signal Design for System Identification](https://arxiv.org/abs/2511.04425)
*Piotr Bania,Anna Wójcik*

Main category: math.ST

TL;DR: 本文提出了一种基于贝叶斯框架的输入信号设计方法，利用观测与参数之间的互信息（MI）作为效用函数，并通过最大化一个可计算的MI下界来解决传统Fisher信息方法在模型不确定性和非线性情况下的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于Fisher信息的方法在存在显著模型不确定性和非线性时表现不佳，且具有局部性，因此需要一种更鲁棒、全局性的输入信号设计方法。

Method: 采用贝叶斯方法，以互信息为准则，通过优化一个可计算的互信息下界进行输入信号设计；提出一种降维算法，将需求逆的协方差矩阵维度减少N倍，提升计算效率。

Result: 所提方法在四类例子中（包括原子传感器模型）均优于平均D最优设计等现有方法，生成的输入信号能显著提高互信息，降低参数估计误差。

Conclusion: 该贝叶斯互信息最大化方法在处理非线性与不确定性系统识别时更有效，且通过降维算法实现了对长序列实验的可扩展性，具有实际应用价值。

Abstract: The design of informatively rich input signals is essential for accurate
system identification, yet classical Fisher-information-based methods are
inherently local and often inadequate in the presence of significant model
uncertainty and nonlinearity. This paper develops a Bayesian approach that uses
the mutual information (MI) between observations and parameters as the utility
function. To address the computational intractability of the MI, we maximize a
tractable MI lower bound. The method is then applied to the design of an input
signals for the identification of quasi-linear stochastic dynamical systems.
Evaluating the MI lower bound requires inversion of large covariance matrices
whose dimensions scale with the number of data points $N$. To overcome this
problem, an algorithm that reduces the dimension of the matrices to be inverted
by a factor of $N$ is developed, making the approach feasible for long
experiments. The proposed Bayesian method is compared with the average
D-optimal design method, a semi-Bayesian approach, and its advantages are
demonstrated. The effectiveness of the proposed method is further illustrated
through four examples, including atomic sensor models, where the input signals
that generates large MI are especially important for reducing the estimation
error.

</details>


### [32] [Asymptotics of constrained $M$-estimation under convexity](https://arxiv.org/abs/2511.04612)
*Victor-Emmanuel Brunel*

Main category: math.ST

TL;DR: 本文研究了凸损失函数下的M估计（无需可微）及其在凸约束下的渐近理论，揭示了估计量的渐近分布依赖于损失函数与约束集边界结构之间的相互作用，并将结果推广到U估计，适用于鲁棒位置/协差阵估计、Oja深度等最深点估计等问题。


<details>
  <summary>Details</summary>
Motivation: 传统M估计的渐近理论依赖于损失函数的光滑性假设，这些条件往往技术性强、限制过多或难以验证。本文旨在建立在更宽松条件下（如凸但不可微损失函数）的M估计渐近理论，以拓展其适用范围。

Method: 通过分析凸损失函数与凸约束集合边界结构之间的关系，建立M估计的渐近分布理论，并利用U统计量的渐近理论将其推广到U估计情形。

Result: 得到了凸损失下M估计量的渐近分布形式，发现其依赖于损失函数与约束集边界的相互作用；并将该理论成功应用于鲁棒位置/散射估计、基于深度函数（如Oja深度）的最深点估计等实际问题。

Conclusion: 本文为非光滑凸损失下的M估计提供了统一的渐近理论框架，放宽了传统光滑性要求，增强了理论的普适性和实用性，特别是在有约束和高维统计推断中具有重要意义。

Abstract: M-estimation, aka empirical risk minimization, is at the heart of statistics
and machine learning: Classification, regression, location estimation, etc.
Asymptotic theory is well understood when the loss satisfies some smoothness
assumptions and its derivatives are dominated locally. However, these
conditions are typically technical and can be too restrictive or heavy to
check. Here, we consider the case of a convex loss function, which may not even
be differentiable: We establish an asymptotic theory for M-estimation with
convex loss (which needs not be differentiable) under convex constraints. We
show that the asymptotic distributions of the corresponding M-estimators depend
on an interplay between the loss function and the boundary structure of the set
of constraints. We extend our results to U-estimators, building on the
asymptotic theory of U-statistics. Applications of our work include, among
other, robust location/scatter estimation, estimation of deepest points
relative to depth functions such as Oja's depth, etc.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [33] [Adaptive Geometric Regression for High-Dimensional Structured Data](https://arxiv.org/abs/2511.03817)
*Pawel Gajer,Jacques Ravel*

Main category: stat.ME

TL;DR: 提出一种基于几何框架的回归方法，通过将分析从高维空间转移到数据内在结构的几何对象上，解决高维低内在维度数据的回归问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以捕捉高维但低内在维度数据（如微生物组组成）的潜在几何结构，因此需要一种能尊重数据内在几何和响应结构的回归方法。

Method: 从特征空间的k近邻覆盖出发，通过热扩散和响应一致性调制迭代演化几何结构，在响应变化平滑的区域集中质量，在响应快速变化处形成扩散屏障。

Result: 实现了对条件期望的估计，同时尊重特征空间的内在几何和响应结构，提升了对复杂结构数据的建模能力。

Conclusion: 该几何框架为高维结构化数据的回归提供了有效工具，尤其适用于内在维度较低但传统方法表现不佳的数据集。

Abstract: We present a geometric framework for regression on structured
high-dimensional
  data that shifts the analysis from the ambient space to a geometric object
  capturing the data's intrinsic structure. The method addresses a fundamental
  challenge in analyzing datasets with high ambient dimension but low intrinsic
  dimension, such as microbiome compositions, where traditional approaches fail
  to capture the underlying geometric structure. Starting from a k-nearest
  neighbor covering of the feature space, the geometry evolves iteratively
  through heat diffusion and response-coherence modulation, concentrating mass
  within regions where the response varies smoothly while creating diffusion
  barriers where the response changes rapidly. This iterative refinement
  produces conditional expectation estimates that respect both the intrinsic
  geometry of the feature space and the structure of the response.

</details>


### [34] [A Pragmatic Framework for Bayesian Utility Magnitude-Based Decisions](https://arxiv.org/abs/2511.03932)
*Will G. Hopkins*

Main category: stat.ME

TL;DR: 本文提出了一种基于贝叶斯后验概率和实用价值评分的效用决策框架，通过统一的1-9分有形效应尺度，结合损失厌恶、副作用和实施成本等因素，生成期望效用得分，辅助实际决策。


<details>
  <summary>Details</summary>
Motivation: 传统统计推断难以直接支持实用决策，缺乏将统计结果与实际价值相结合的系统方法。本文旨在建立一个直观、原则性强的决策框架，使统计证据能更有效地服务于实践选择。

Method: 采用贝叶斯后验概率估计不同效应大小的可能性，结合一个统一的1-9分有形效应尺度（反映实际意义），计算干预措施的期望效用得分；引入个体反应差异的标准差以评估个体或场景间的效益分布；并通过敏感性分析检验系统偏差和主观输入的影响。

Result: 框架可生成单一的期望效用得分，用于与用户定义的最小重要净效益进行直观比较，从而做出初步决策；同时提供临床意义概率、可信区间及个体受益/无益/受害比例等信息，辅助全面评估证据强度和实施情境。

Conclusion: 该框架为从统计证据到实际决策提供了结构化、透明且直观的工具，虽尚未经验验证，但有助于整合证据与价值判断，支持个体化和情境化的决策制定。

Abstract: This article presents a pragmatic framework for making formal, utility-based
decisions from statistical inferences. The method calculates an expected
utility score for an intervention by combining Bayesian posterior probabilities
of different effect magnitudes with points representing their practical value.
A key innovation is a unified, non-arbitrary points scale (1-9 for small to
extremely large) derived from a principle linking tangible outcomes across
different effect types. This tangible scale enables a principled "trade-off"
method for including values for loss aversion, side effects, and implementation
cost. The framework produces a single, definitive expected utility score, and
the initial decision is made by comparing the magnitude of this single score to
a user-defined smallest important net benefit, a direct and intuitive
comparison made possible by the scale's tangible nature. This expected utility
decision is interpreted alongside clinical magnitude-based decision
probabilities or credible interval coverage to assess evidence strength.
Inclusion of a standard deviation representing individual responses to an
intervention (or differences between settings with meta-analytic data) allows
characterization of differences between individuals (or settings) in the
utility score expressed as proportions expected to experience benefit, a
negligible effect, and harm. These proportions provide context for the final
decision about implementation. Users must perform sensitivity analyses to
investigate the effects of systematic bias and of the subjective inputs on the
final decision. This framework, implemented in an accessible spreadsheet, has
not been empirically validated. It represents a tool in development, designed
for practical decision-making from available statistical evidence and
structured thinking about values of outcomes.

</details>


### [35] [Nonparametric Modeling of Continuous-Time Markov Chains](https://arxiv.org/abs/2511.03954)
*Filippo Monti,Xiang Ji,Marc A. Suchard*

Main category: stat.ME

TL;DR: 提出了一种基于高斯过程和可扩展HMC采样的贝叶斯框架，用于推断连续时间马尔可夫链的转移速率，能够捕捉协变量的非线性影响，并将计算复杂度从O(K^5)降至O(K^2)，在合成和真实数据上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 连续时间马尔可夫链（CTMC）转移速率的推断面临状态空间扩大导致速率数量二次增长、速率间强依赖性和转移信息不完整三大挑战，现有方法受限于线性协变量假设，难以充分刻画外部驱动因素的影响。

Method: 引入一种新的贝叶斯框架，利用高斯过程（GP）建模CTMC转移速率与协变量之间的非线性关系，并结合可扩展的哈密尔顿蒙特卡洛（HMC）采样器进行推断，通过将HMC轨迹与可扩展梯度近似结合，显著降低计算复杂度。

Result: 该方法将精确似然梯度计算的复杂度从O(K^5)降低到O(K^2)，其中K为CTMC状态数，在合成数据和真实数据（贝叶斯系统地理推断）上的实验表明，该方法能更准确地捕捉协变量对转移速率的影响。

Conclusion: 所提方法通过引入高斯过程和高效采样策略，提升了CTMC速率推断的准确性与可扩展性，有助于揭示潜在外部驱动因素，推动了CTMC在复杂实际场景中的应用。

Abstract: Inferring the infinitesimal rates of continuous-time Markov chains (CTMCs) is
a central challenge in many scientific domains. This task is hindered by three
factors: quadratic growth in the number of rates as the CTMC state space
expands, strong dependencies among rates, and incomplete information for many
transitions. We introduce a new Bayesian framework that flexibly models the
CTMC rates by incorporating covariates through Gaussian processes (GPs). This
approach improves inference by integrating new information and contributes to
the understanding of the CTMC stochastic behavior by shedding light on
potential external drivers. Unlike previous approaches limited to linear
covariate effects, our method captures complex non-linear relationships,
enabling fuller use of covariate information and more accurate characterization
of their influence. To perform efficient inference, we employ a scalable
Hamiltonian Monte Carlo (HMC) sampler. We address the prohibitive cost of
computing the exact likelihood gradient by integrating the HMC trajectories
with a scalable gradient approximation, reducing the computational complexity
from $O(K^5)$ to $O(K^2)$, where $K$ is the number of CTMC states. Finally, we
demonstrate our method on Bayesian phylogeography inference -- a domain where
CTMCs are central -- showing effectiveness on both synthetic and real datasets.

</details>


### [36] [Assessing Replicability Across Dependent Studies: A Framework for Testing Partial Conjunction Hypotheses with Application to GWAS](https://arxiv.org/abs/2511.04130)
*Monitirtha Dey,Trambak Banerjee,Prajamitra Bhuyan,Arunabha Majumdar*

Main category: stat.ME

TL;DR: 本文提出了一种基于e值理论的新方法e-Filter，用于在存在研究间依赖性的情况下进行可重复性分析，尤其适用于基因组关联研究（GWAS）中存在样本重叠的情形。该方法通过过滤和选择两步流程，在控制FWER和FDR的前提下有效识别部分联合（PC）假设中的显著发现，并在模拟和实际应用中展现出优于现有方法的统计功效。


<details>
  <summary>Details</summary>
Motivation: 现有的部分联合（PC）假设检验方法通常假定各研究之间相互独立，但在许多现代应用场景（如具有样本重叠的GWAS）中，这一假设被违反，导致汇总统计量之间存在依赖性。忽略这种依赖性会严重增加I类错误率，因此需要一种能在未知依赖结构下保持有效性且具备高统计功效的新方法。

Method: 提出e-Filter方法，基于e值理论，包含两个步骤：过滤步骤保留最有前景的PC假设，选择步骤则根据e值是否超过阈值来标记发现。该方法在未知研究依赖结构下仍能保证对家族-wise错误率（FWER）和错误发现率（FDR）的控制。

Result: 在全面的模拟研究中，e-Filter相比竞争方法展现出更高的统计功效；在低密度脂蛋白胆固醇（LDL-C）的GWAS可重复性分析中成功识别出一致的遗传信号，且通路富集分析显示其结果在生物学相关通路上具有更强的统计富集。

Conclusion: e-Filter是一种在研究间存在依赖时仍能有效控制错误率并提升检测功效的可重复性分析方法，特别适用于存在样本重叠的多研究整合场景，为跨研究一致性推断提供了可靠工具。

Abstract: Replicability is central to scientific progress, and the partial conjunction
(PC) hypothesis testing framework provides an objective tool to quantify it
across disciplines. Existing PC methods assume independent studies. Yet many
modern applications, such as genome-wide association studies (GWAS) with sample
overlap, violate this assumption, leading to dependence among study-specific
summary statistics. Failure to account for this dependence can drastically
inflate type I errors when combining inferences. We propose e-Filter, a
powerful procedure grounded on the theory of e-values. It involves a filtering
step that retains a set of the most promising PC hypotheses, and a selection
step where PC hypotheses from the filtering step are marked as discoveries
whenever their e-values exceed a selection threshold. We establish the validity
of e-Filter for FWER and FDR control under unknown study dependence. A
comprehensive simulation study demonstrates its excellent power gains over
competing methods. We apply e-Filter to a GWAS replicability study to identify
consistent genetic signals for low-density lipoprotein cholesterol (LDL-C).
Here, the participating studies exhibit varying levels of sample overlap,
rendering existing methods unsuitable for combining inferences. A subsequent
pathway enrichment analysis shows that e-Filter replicated signals achieve
stronger statistical enrichment on biologically relevant LDL-C pathways than
competing approaches.

</details>


### [37] [Estimation of Independent Component Analysis Systems](https://arxiv.org/abs/2511.04273)
*Vincent Starck*

Main category: stat.ME

TL;DR: 提出了一种基于特征函数和连续广义矩方法的独立成分分析（ICA）最优估计方法，避免了传统方法中的数值积分和调参问题，具有计算可行性和渐近有效性，并可应用于结构向量自回归模型估计。


<details>
  <summary>Details</summary>
Motivation: 传统基于特征函数的ICA方法在实现上存在数值积分和调参等困难，需要一种既保持理论优势又具备计算可行性的新方法。

Method: 扩展已有目标函数，结合连续广义矩方法（GMM）理论，构建可解析处理的最优估计器，并适应存在估计传感器的前置步骤。

Result: 新方法在模拟中优于高效GMM、JADE和FastICA；同时衍生出一个有用的模型设定检验，并成功应用于结构向量自回归（SVAR）模型估计。

Conclusion: 该方法结合了特征函数法的理论优势与实际可计算性，在无需高阶矩存在或参数假设的前提下实现了高效、稳健的ICA估计，具有广泛的应用潜力。

Abstract: Although approaches to Independent Component Analysis (ICA) based on
characteristic function seem theoretically elegant, they may suffer from
implementational challenges because of numerical integration steps or selection
of tuning parameters. Extending previously considered objective functions and
leveraging results from the continuum Generalized Method of Moments of Carrasco
and Florens (2000), I derive an optimal estimator that can take a tractable
form and thus bypass these concerns. The method shares advantages with
characteristic function approaches -- it does not require the existence of
higher-order moments or parametric restrictions -- while retaining
computational feasibility and asymptotic efficiency. The results are adapted to
handle a possible first step that delivers estimated sensors. Finally, a
by-product of the approach is a specification test that is valuable in many ICA
applications. The method's effectiveness is illustrated through simulations,
where the estimator outperforms efficient GMM, JADE, or FastICA, and an
application to the estimation of Structural Vector Autoregressions (SVAR), a
workhorse of the macroeconometric time series literature.

</details>


### [38] [Matrix-Variate Regression Model for Multivariate Spatio-Temporal Data](https://arxiv.org/abs/2511.04331)
*Carlos A. Ribeiro Diniz,Victor E. Lachos Olivares,Victor H. Lachos Davila*

Main category: stat.ME

TL;DR: 本文提出了一种用于分析时空多变量数据的矩阵回归模型，结合协变量与响应矩阵的均值结构及基于Kronecker积的可分协方差结构，有效捕捉时空依赖性，并通过模拟和实际农业数据验证了模型的有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地分析在空间位置和时间上观测到的多变量数据，特别是捕捉复杂的时空依赖结构，同时提升参数估计的效率和解释能力。

Method: 提出一种具有均值结构和可分协方差结构（基于Kronecker积）的矩阵变回归模型，推导所有参数的最大似然估计，并通过模拟研究评估参数恢复效果。

Result: 模拟研究表明模型能有效恢复不同空间分辨率下的参数；对巴西市政农业和畜牧业数据的应用揭示了明显的时空变化模式和协变量效应。

Conclusion: 该矩阵回归模型能够高效建模复杂时空数据，具有良好的参数估计性能和实际应用价值，适用于分析具有空间和时间依赖性的多变量数据。

Abstract: This paper introduces a matrix-variate regression model for analyzing
multivariate data observed across spatial locations and over time. The model's
design incorporates a mean structure that links covariates to the response
matrix and a separable covariance structure, based on a Kronecker product, to
capture spatial and temporal dependencies efficiently. We derive maximum
likelihood estimators for all model parameters. A simulation study validates
the model, showing its effectiveness in parameter recovery across different
spatial resolutions. Finally, an application to real-world data on agricultural
and livestock production from Brazilian municipalities showcases the model's
practical utility in revealing structured spatio-temporal patterns of variation
and covariate effects.

</details>


### [39] [Nonparametric Robust Comparison of Solutions under Input Uncertainty](https://arxiv.org/abs/2511.04457)
*Jaime Gonzalez-Hodar,Johannes Milz,Eunhye Song*

Main category: stat.ME

TL;DR: 提出了一种名为NIOU-C的方法，用于在无法获取额外数据的情况下处理输入不确定性中的排序与选择问题，通过构建包含最优解的置信集，并在温和条件下保证渐近有效性，其扩展版本NIOU-C:E可减小保守性并缩小置信集。数值实验表明该方法优于参数化方法。


<details>
  <summary>Details</summary>
Motivation: 在输入不确定性存在且无法获取更多数据的情况下，传统方法难以准确识别最优解，因此需要一种能够在有限数据下有效构建包含最优解的置信集的方法。

Method: 使用经验似然构建输入分布的模糊集，利用线性泛函表示近似每个解的均值性能，并通过在模糊集内求解最坏情况下的成对均值差异优化问题，构建与最优解无法区分的解的置信集。同时提出NIOU-C:E以减少保守性。

Result: NIOU-C在数值实验中相比利用参数分布族的参数化方法，提供了更小且更频繁包含最优解的置信集；理论分析表明该方法在温和条件下具有渐近有效性。

Conclusion: NIOU-C及其扩展NIOU-C:E能有效应对输入不确定性下的排序与选择问题，在无法获取额外数据时仍可构造高覆盖率的较小置信集，且优于传统参数方法。

Abstract: We study ranking and selection under input uncertainty in settings where
additional data cannot be collected. We propose the Nonparametric Input-Output
Uncertainty Comparisons (NIOU-C) procedure to construct a confidence set that
includes the optimal solution with a user-specified probability. We construct
an ambiguity set of input distributions using empirical likelihood and
approximate the mean performance of each solution using a linear functional
representation of the input distributions. By solving optimization problems
evaluating worst-case pairwise mean differences within the ambiguity set, we
build a confidence set of solutions indistinguishable from the optimum. We
characterize sample size requirements for NIOU-C to achieve the asymptotic
validity under mild conditions. Moreover, we propose an extension to NIOU-C,
NIOU-C:E, that mitigates conservatism and yields a smaller confidence set. In
numerical experiments, NIOU-C provides a smaller confidence set that includes
the optimum more frequently than a parametric procedure that takes advantage of
the parametric distribution families.

</details>


### [40] [Conditional Selective Inference for the Selected Groups in Panel Data](https://arxiv.org/abs/2511.04466)
*Chuang Wan,Jiajun Sun,Xingbai Xu*

Main category: stat.ME

TL;DR: 本文提出了一种针对面板数据中k均值聚类后组间斜率差异的可选择性推断方法，有效校正了传统Wald检验因数据重用导致的I类错误膨胀问题，并提供了R软件包TestHomoPanel实现该方法。


<details>
  <summary>Details</summary>
Motivation: 由于在聚类和推断中使用同一数据集，传统Wald检验在k均值聚类后的面板数据中会导致严重的I类错误膨胀，因此需要一种能控制选择偏差的统计推断方法。

Method: 提出一种基于选择事件条件下的可选择性推断方法，通过精确刻画聚类选择带来的偏差，构建正确的p值计算方式，并将该方法扩展至单个协变量系数差异检验和GMM估计框架中。

Result: 模拟研究表明该方法在有限样本下表现良好；应用于研究各国经济增长与二氧化碳排放关系时，发现了新的异质性结果。

Conclusion: 所提出的可选择性推断方法能有效控制面板数据中聚类后推断的I类错误，具有良好的实际应用价值，并为聚类后假设检验提供了可靠工具。

Abstract: We consider the problem of testing for differences in group-specific slopes
between the selected groups in panel data identified via k-means clustering. In
this setting, the classical Wald-type test statistic is problematic because it
produces an extremely inflated type I error probability. The underlying reason
is that the same dataset is used to identify the group structure and construct
the test statistic, simultaneously. This creates dependence between the
selection and inference stages. To address this issue, we propose a valid
selective inference approach conditional on the selection event to account for
the selection effect. We formally define the selective type I error and
describe how to efficiently compute the correct p-values for clusters obtained
using k-means clustering. Furthermore, the same idea can be extended to test
for differences in coefficients due to a single covariate and can be
incorporated into the GMM estimation framework. Simulation studies show that
our method has satisfactory finite sample performance. We apply this method to
explore the heterogeneous relationships between economic growth and the $CO_2$
emission across countries for which some new findings are discovered. An R
package TestHomoPanel is provided to implement the proposed selective inference
framework for panel data.

</details>


### [41] [A General Approach for Calibration Weighting under Missing at Random](https://arxiv.org/abs/2511.04496)
*Yonghyun Kwon,Jae Kwang Kim,Yumou Qiu*

Main category: stat.ME

TL;DR: 提出了一类基于加权广义熵的校准加权方法（GEC），用于处理缺失随机（MAR）数据，具有更高的稳定性和效率。该方法通过凸优化统一了熵方法和广义回归加权，并实现了双重稳健性。


<details>
  <summary>Details</summary>
Motivation: 为了解决缺失随机数据下的估计问题，提升现有校准加权方法的稳定性与效率，同时保证双重稳健性和对干扰参数估计的鲁棒性。

Method: 将权重构造建模为凸优化问题，引入基于广义熵的校准框架，结合协变量平衡、倾向得分模型去偏约束和Neyman正交约束；提出Bregman投影几何解释及高维扩展的软校准方法。

Result: GEC方法在模拟研究中表现出优于现有方法的性能，具有良好的几何性质（如广义毕达哥拉斯恒等式），并支持双重稳健推断，尤其在高维设置下通过投影校准保持统计有效性。

Conclusion: 所提出的GEC框架统一了多种校准方法，提供了理论支持和几何解释，提升了权重估计的稳定性与效率，适用于高维和复杂缺失数据场景。

Abstract: We propose a unified class of calibration weighting methods based on weighted
generalized entropy to handle missing at random (MAR) data with improved
stability and efficiency. The proposed generalized entropy calibration (GEC)
formulates weight construction as a convex optimization program that unifies
entropy-based approaches and generalized regression weighting. Double
robustness is achieved by augmenting standard covariate balancing with a
debiasing constraint tied to the propensity score model and a Neyman-orthogonal
constraint that removes first-order sensitivity to nuisance estimation.
Selection of the weights on the entropy function can lead to the optimal
calibration estimator under a correctly specified outcome regression model. The
proposed GEC weighting ha a nice geometric characterization: the GEC solution
is the Bregman projection of the initial weights onto a constraint set, which
yields a generalized Pythagorean identity and a nested decomposition that
quantifies the incremental distance paid for additional constraints. We also
develop a high-dimensional extension with soft calibration and a projection
calibration constraint that preserves doubly robust inference. Two simulation
studies are presented to compare the performance of the proposed method with
the existing methods.

</details>


### [42] [Geometric Decomposition of Statistical Inference through Gradient Flow and Co-Monotonicity Measures](https://arxiv.org/abs/2511.04599)
*Pawel Gajer,Jacques Ravel*

Main category: stat.ME

TL;DR: 提出了一种基于几何分解的框架，用于在高维数据中发现子群体依赖的特征-结果关联，通过梯度流和共单调性分解方法提升统计功效与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设全局关联，难以捕捉依赖上下文的模式，导致统计功效和可解释性下降。

Method: 构建基于数据驱动的黎曼图的区域分析框架，采用梯度流分解（基于离散Morse理论）和共单调性分解（基于顶点级系数与双聚类）两种策略，并结合贝叶斯后验采样。

Result: 实现了对高维数据中局部关联模式的有效识别，支持子群体特异性分析和多模态数据整合。

Conclusion: 该框架能更精细地揭示特征与结果之间的局部依赖关系，优于传统全局关联分析方法。

Abstract: Understanding feature-outcome associations in high-dimensional data remains
  challenging when relationships vary across subpopulations, yet standard
  methods assuming global associations miss context-dependent patterns,
reducing
  statistical power and interpretability. We develop a geometric decomposition
  framework offering two strategies for partitioning inference problems into
  regional analyses on data-derived Riemannian graphs. Gradient flow
  decomposition uses path-monotonicity-validated discrete Morse theory to
  partition samples into basins where outcomes exhibit monotonic behavior.
  Co-monotonicity decomposition leverages association structure: vertex-level
  coefficients measuring directional concordance between outcome and features,
  or between feature pairs, define embeddings of samples into association
space.
  These embeddings induce Riemannian k-NN graphs on which biclustering
  identifies co-monotonicity cells (coherent regions) and feature modules. This
  extends naturally to multi-modal integration across multiple feature sets.
  Both strategies apply independently or jointly, with Bayesian posterior
  sampling providing credible intervals.

</details>


### [43] [Where to Experiment? Site Selection Under Distribution Shift via Optimal Transport and Wasserstein DRO](https://arxiv.org/abs/2511.04658)
*Adam Bouyamourn*

Main category: stat.ME

TL;DR: 本文将实验地点选择问题建模为最优传输问题，通过最小化总体与样本协变量分布之间的Wasserstein距离来减少下游估计误差，并提出基于Wasserstein分布鲁棒优化的选址方法，以应对协变量分布偏移，且在模拟和实际微额信贷实验中验证了其优于随机和分层抽样等方法。


<details>
  <summary>Details</summary>
Motivation: 当部署总体与观测数据不同时，如何选择实验地点以提高估计准确性是一个关键问题。现有方法可能在分布偏移下表现不佳，因此需要更鲁棒的选址策略。

Method: 将实验地点选择建模为最优传输问题，使用Wasserstein距离衡量协变量分布差异；提出基于Wasserstein分布鲁棒优化（DRO）的选址方法，并设计数据驱动的方式选择不确定性半径。

Result: 推导了PATE和CATE估计误差的新上界，表明不同目标导致不同选址策略；在模拟和摩洛哥微额信贷实验中，新方法在协变量具有较高预后R平方、中等信息量及分布偏移情况下优于随机抽样、分层抽样和其他优化方法。

Conclusion: 基于Wasserstein距离和分布鲁棒优化的实验地点选择方法能有效降低估计误差，提升外部有效性，尤其在存在分布偏移或协变量信息较强时表现更优。

Abstract: How should researchers select experimental sites when the deployment
population differs from observed data? I formulate the problem of experimental
site selection as an optimal transport problem, developing methods to minimize
downstream estimation error by choosing sites that minimize the Wasserstein
distance between population and sample covariate distributions. I develop new
theoretical upper bounds on PATE and CATE estimation errors, and show that
these different objectives lead to different site selection strategies. I
extend this approach by using Wasserstein Distributionally Robust Optimization
to develop a site selection procedure robust to adversarial perturbations of
covariate information: a specific model of distribution shift. I also propose a
novel data-driven procedure for selecting the uncertainty radius the
Wasserstein DRO problem, which allows the user to benchmark robustness levels
against observed variation in their data. Simulation evidence, and a reanalysis
of a randomized microcredit experiment in Morocco (Cr\'epon et al.), show that
these methods outperform random and stratified sampling of sites when
covariates have prognostic R-squared > .5, and alternative optimization methods
i) for moderate-to-large size problem instances ii) when covariates are
moderately informative about treatment effects, and iii) under induced
distribution shift.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [44] [Relative entropy estimate and geometric ergodicity for implicit Langevin Monte Carlo](https://arxiv.org/abs/2511.04041)
*Lei Li,Jian-Guo Liu,Yuliang Wang*

Main category: math.NA

TL;DR: 本文研究了隐式Langevin Monte Carlo (iLMC) 方法，通过隐式迭代规则模拟过阻尼Langevin方程，并在相对熵和Wasserstein-1距离下证明了其时间离散化误差界和几何遍历性，方法具有普适性，可推广至其他隐式或分裂格式。


<details>
  <summary>Details</summary>
Motivation: 由于显式Langevin Monte Carlo (LMC) 在漂移场非全局Lipschitz时可能出现发散，而iLMC在单侧Lipschitz条件下仍具收敛性，因此研究iLMC的理论性质以提升其在复杂应用中的稳定性与可靠性。

Method: 采用适应的连续时间插值方法，结合PDE技巧（如Bernstein方法）估计对数数值密度的梯度，建立相对熵下的时间离散误差界；利用反射型连续-离散耦合方法证明iLMC在Wasserstein-1距离下的几何遍历性，并结合两者结果推导一致误差界。

Result: 证明了iLMC在相对熵下的时间离散化误差界和Wasserstein-1距离下的几何遍历性，进一步得到统一的时间一致误差估计。

Conclusion: iLMC在处理非Lipschitz漂移的随机微分方程时具有良好的收敛性和稳定性，所提出的分析方法具有普遍适用性，可用于其他隐式或分裂算法的理论分析。

Abstract: We study the implicit Langevin Monte Carlo (iLMC) method, which simulates the
overdamped Langevin equation via an implicit iteration rule. In many
applications, iLMC is favored over other explicit schemes such as the
(explicit) Langevin Monte Carlo (LMC). LMC may blow up when the drift field
$\nabla U$ is not globally Lipschitz, while iLMC has convergence guarantee when
the drift is only one-sided Lipschitz. Starting from an adapted continuous-time
interpolation, we prove a time-discretization error bound under the relative
entropy (or the Kullback-Leibler divergence), where a crucial gradient estimate
for the logarithm numerical density is obtained via a sequence of PDE
techniques, including Bernstein method. Based on a reflection-type
continuous-discrete coupling method, we prove the geometric ergodicity of iLMC
under the Wasserstein-1 distance. Moreover, we extend the error bound to a
uniform-in-time one by combining the relative entropy error bound and the
ergodicity. Our proof technique is universal and can be applied to other
implicit or splitting schemes for simulating stochastic differential equations
with non-Lipschitz drifts.

</details>


### [45] [Numerical boundary flux functions that give provable bounds for nonlinear initial boundary value problems with open boundaries](https://arxiv.org/abs/2511.04197)
*Andrew R. Winters,David A. Kopriva,Jan Nordström*

Main category: math.NA

TL;DR: 提出了一种将非线性特征型惩罚项解释为数值边界通量函数的策略，能够为具有开放边界的非线性双曲初边值问题提供可证明的解的界。


<details>
  <summary>Details</summary>
Motivation: 为了解决非线性双曲型方程在开放边界条件下解的稳定性与有界性问题，特别是标准线性分析方法失效的情况。

Method: 利用最近关于熵通量可表示为对称边界矩阵定义的二次型的研究成果，通过矩阵分解定义适当的特征型变量，系统设计弱施加边界条件的特征型惩罚项。

Result: 推导了Burgers方程和二维浅水方程的流入-流出边界通量，新方法与高阶精度间断Galerkin方法兼容，保证解的熵稳定性和仅依赖外部数据的有界性，数值实验显示新非线性通量在标准方法失效时仍有效。

Conclusion: 该方法为非线性双曲型问题提供了稳定、高阶兼容的边界处理策略，显著优于基于线性分析的标准边界处理方法。

Abstract: We present a strategy for interpreting nonlinear, characteristic-type penalty
terms as numerical boundary flux functions that provide provable bounds for
solutions to nonlinear hyperbolic initial boundary value problems with open
boundaries. This approach is enabled by recent work that found how to express
the entropy flux as a quadratic form defined by a symmetric boundary matrix.
The matrix formulation provides additional information for how to
systematically design characteristic-based penalty terms for the weak
enforcement of boundary conditions. A special decomposition of the boundary
matrix is required to define an appropriate set of characteristic-type
variables. The new boundary fluxes are directly compatible with high-order
accurate split form discontinuous Galerkin spectral element and similar methods
and guarantee that the solution is entropy stable and bounded solely by
external data. We derive inflow-outflow boundary fluxes specifically for the
Burgers equation and the two-dimensional shallow water equations, which are
also energy stable. Numerical experiments demonstrate that the new nonlinear
fluxes do not fail in situations where standard boundary treatments based on
linear analysis do.

</details>


### [46] [A space-time adaptive boundary element method for the wave equation](https://arxiv.org/abs/2511.04265)
*Alessandra Aimi,Giulia Di Credico,Heiko Gimperlein,Chiara Guardasoni*

Main category: math.NA

TL;DR: 本文首次研究了用于波动方程时间依赖边界元公式的时空自适应网格细化方法，提出了一种基于残差型误差指示器的自适应边界元算法，并通过数值实验验证了其在处理空间、时间或传播奇异性的声学散射问题中的高效性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地处理波动方程在时空域中的奇异性和不连续性，提高边界元方法的计算效率和精度，本文引入了时空自适应网格细化策略。

Method: 基于残差型误差指示器，采用局部张量积方式对时空网格进行自适应细化，提出了针对声学软散射问题的自适应边界元方法，并讨论了算法实现中的关键问题。

Result: 数值实验表明，该方法在能量范数下表现出良好的收敛性和计算效率，尤其在处理空间、时间或行进奇异解时性能优越；同时比较了严格与启发式后验误差指示器的有效性。

Conclusion: 所提出的时空自适应边界元方法能够有效捕捉解的局部特征，显著提升计算效率和精度，为时间依赖边界积分方程的数值求解提供了可行的自适应策略。

Abstract: This article initiates the study of space-time adaptive mesh refinements for
time-dependent boundary element formulations of wave equations. Based on error
indicators of residual type, we formulate an adaptive boundary element
procedure for acoustic soft-scattering problems with local tensor-product
refinements of the space-time mesh. We discuss the algorithmic challenges and
investigate the proposed method in numerical experiments. In particular, we
study the performance and improved convergence rates with respect to the energy
norm for problems dominated by spatial, temporal or traveling singularities of
the solution. The efficiency of the considered rigorous and heuristic a
posteriori error indicators is discussed.

</details>


### [47] [Normalized tensor train decomposition](https://arxiv.org/abs/2511.04369)
*Renfeng Peng,Chengkai Zhu,Bin Gao,Xin Wang,Ya-xiang Yuan*

Main category: math.NA

TL;DR: 本文提出了归一化张量列（NTT）分解方法，用于在保持单位范数约束的同时实现张量的低秩近似，并基于其流形结构设计了几何算法，应用于张量恢复、高维特征值问题和量子信息等任务，实验表明该方法高效且可扩展。


<details>
  <summary>Details</summary>
Motivation: 张量的单位Frobenius范数在科学计算和量子物理中至关重要，但传统的张量列分解无法自然保持该约束，因此需要一种能同时保持低秩结构和单位范数的新分解方法。

Method: 提出归一化张量列（NTT）分解，将张量近似为具有单位范数的张量列车格式；证明固定秩NTT张量构成光滑流形，并推导其黎曼几何结构，进而发展基于流形优化的几何算法。

Result: NTT分解成功应用于低秩张量恢复、高维特征值求解、稳定子秩估计和量子信道最小输出Rényi 2-熵计算；数值实验显示所提方法在效率和可扩展性方面优于现有方法。

Conclusion: NTT分解有效结合了低秩结构与单位范数约束，其流形几何框架为相关应用提供了理论基础和高效算法，具有广泛的应用前景。

Abstract: Tensors with unit Frobenius norm are fundamental objects in many fields,
including scientific computing and quantum physics, which are able to represent
normalized eigenvectors and pure quantum states. While the tensor train
decomposition provides a powerful low-rank format for tackling high-dimensional
problems, it does not intrinsically enforce the unit-norm constraint. To
address this, we introduce the normalized tensor train (NTT) decomposition,
which aims to approximate a tensor by unit-norm tensors in tensor train format.
The low-rank structure of NTT decomposition not only saves storage and
computational cost but also preserves the underlying unit-norm structure. We
prove that the set of fixed-rank NTT tensors forms a smooth manifold, and the
corresponding Riemannian geometry is derived, paving the way for geometric
methods. We propose NTT-based methods for low-rank tensor recovery,
high-dimensional eigenvalue problem, estimation of stabilizer rank, and
calculation of the minimum output R\'enyi 2-entropy of quantum channels.
Numerical experiments demonstrate the superior efficiency and scalability of
the proposed NTT-based methods.

</details>


### [48] [The Loewner framework applied to Zolotarev sign and ratio problems](https://arxiv.org/abs/2511.04404)
*Athanasios C. Antoulas,Ion Victor Gosea,Charles Poussot-Vassal*

Main category: math.NA

TL;DR: 本文研究了与第三和第四Zolotarev问题相关的函数逼近方法，比较了Loewner框架、标准AAA算法及其扩展变体（如符号和Lawson变体），结果表明Loewner框架速度快、可靠性高，且在高次逼近中精度优于AAA-Lawson，运行时间更短且不随逼近次数增加而显著增长。


<details>
  <summary>Details</summary>
Motivation: 为了找到高效且高精度的函数逼近方法，特别是在处理第三和第四Zolotarev问题时，需要对现有方法进行系统比较和评估。

Method: 采用数值研究方法，比较了Loewner框架、标准AAA算法以及AAA的符号和Lawson变体在函数逼近中的性能。

Result: Loewner框架在速度和精度上均表现优异，尤其在高次逼近中比AAA-Lawson更准确，且其运行时间基本恒定，而AAA-Lawson的运行时间随逼近次数增加而显著上升。

Conclusion: Loewner框架是一种快速、可靠且高精度的函数逼近方法，尤其适用于高次逼近问题，优于当前流行的迭代方法如AAA-Lawson。

Abstract: In this work, we propose a numerical study concerning the approximation of
functions associated with the 3rd and 4th Zolotarev problems. We compare
various methods, in particular the Loewner framework, the standard AAA
algorithm, and recently-proposed extensions of AAA (namely, the sign and Lawson
variants). We show that the Loewner framework is fast and reliable, and
provides approximants with a high level of accuracy. When the approximants are
of a higher degree, Loewner approximants are often more accurate than
near-optimal ones computed with AAA-Lawson. Last but not least, the Loewner
framework is a direct method for which the running time is typically lower than
that of the iterative AAA-Lawson variants. Moreover, for the latter, the
running time increases substantially with the degree of the approximant,
whereas for the Loewner method, it remains constant. These claims are supported
by an extensive numerical treatment.

</details>


### [49] [Mean square error analysis of stochastic gradient and variance-reduced sampling algorithms](https://arxiv.org/abs/2511.04413)
*Jianfeng Lu,Xuda Ye,Zhennan Zhou*

Main category: math.NA

TL;DR: 本文研究了在全局凸性假设下，应用于欠阻尼朗之万动力学的随机梯度采样算法的均方误差（MSE）分析，提出了新的离散泊松方程框架来界定时间平均采样误差，并推导了SG-UBU采样器的显式MSE界，发现其数值偏差对步长具有一阶收敛性，且误差系数与随机梯度方差成正比；进一步将分析扩展到有限和势能的方差缩减算法（SVRG-UBU和SAGA-UBU），发现了当步长低于临界阈值时，数值偏差的收敛速率从一阶跃变为二阶的相变现象，理论结果通过数值实验得到验证，并提供了在mini-batch SG-UBU和SVRG-UBU采样器之间选择以实现最优计算效率的经验准则。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地理解随机梯度采样算法在欠阻尼朗之万动力学中的表现，尤其是在全局凸性条件下，需要对采样误差进行系统分析，从而提升算法效率与理论理解。

Method: 提出了一种新的离散泊松方程框架，用于分析时间平均的采样误差，并基于此推导SG-UBU、SVRG-UBU和SAGA-UBU等算法的均方误差界，分析其收敛行为，特别是数值偏差随步长的变化规律。

Result: 1. 推导出SG-UBU的显式MSE界，数值偏差对步长h具有一阶收敛性，误差主项与随机梯度方差成正比；2. 对SVRG-UBU和SAGA-UBU，发现当步长低于某一阈值时，数值偏差的收敛阶从一阶跃升为二阶，表现出相变现象；3. 通过数值实验验证了理论分析；4. 提出了在SG-UBU与SVRG-UBU之间选择以实现最优计算效率的经验准则。

Conclusion: 本文建立了一个有效的分析框架，揭示了不同随机梯度采样算法在欠阻尼朗之万动力学下的误差结构与收敛特性，特别发现了方差缩减算法中的收敛阶相变现象，为算法选择与参数调优提供了理论依据和实用准则。

Abstract: This paper considers mean square error (MSE) analysis for stochastic gradient
sampling algorithms applied to underdamped Langevin dynamics under a global
convexity assumption. A novel discrete Poisson equation framework is developed
to bound the time-averaged sampling error. For the Stochastic Gradient UBU
(SG-UBU) sampler, we derive an explicit MSE bound and establish that the
numerical bias exhibits first-order convergence with respect to the step size
$h$, with the leading error coefficient proportional to the variance of the
stochastic gradient. The analysis is further extended to variance-reduced
algorithms for finite-sum potentials, specifically the SVRG-UBU and SAGA-UBU
methods. For these algorithms, we identify a phase transition phenomenon
whereby the convergence rate of the numerical bias shifts from first to second
order as the step size decreases below a critical threshold. Theoretical
findings are validated by numerical experiments. In addition, the analysis
provides a practical empirical criterion for selecting between the mini-batch
SG-UBU and SVRG-UBU samplers to achieve optimal computational efficiency.

</details>


### [50] [An efficient boundary integral equation solution technique for solving aperiodic scattering problems from two-dimensional, periodic boundaries](https://arxiv.org/abs/2511.04424)
*Riley Fisher,Fruzsina Agocs,Adrianna Gillman*

Main category: math.NA

TL;DR: 本文提出了一种高效的边界积分方程方法，用于求解二维半平面内的Helmholtz问题，该问题由无限周期曲线和Neumann边界条件及非周期点源定义。通过Floquet-Bloch变换将问题转化为计算包含拟周期边值问题解的积分，并采用Cho和Barnett的周期化方案变体，避免了拟周期格林函数的计算，同时支持大量预计算的重用。结合低秩线性代数加速，数值结果表明该方法比使用拟周期格林函数的传统方法快20-30倍。


<details>
  <summary>Details</summary>
Motivation: 为高效求解具有Neumann边界条件和非周期点源的二维半平面Helmholtz问题，尤其是在周期边界条件下避免计算复杂的拟周期格林函数，提升计算效率。

Method: 采用Floquet-Bloch变换将原问题转化为拟周期边值问题的积分求解；使用Cho和Barnett周期化方案的改进版本，避免直接计算拟周期格林函数；结合边界积分方程方法与低秩线性代数技术加速求解过程，并实现预计算的重复利用。

Result: 所提出的方法在楼梯状几何结构上比传统使用拟周期格林函数的技术快20-30倍，且在较少离散点下仍保持高精度。

Conclusion: 该方法显著提升了周期性Helmholtz问题的求解效率，适用于边界周期性明显且离散点不多的场景，具有良好的加速性能和可重用性。

Abstract: This manuscript presents an efficient boundary integral equation technique
for solving two-dimensional Helmholtz problems defined in the half-plane
bounded by an infinite, periodic curve with Neumann boundary conditions and an
aperiodic point source. The technique is designed for boundaries where one
period does not require a large number of discretization points to achieve high
accuracy. The Floquet--Bloch transform turns the problem into evaluating a
contour integral where the integrand is the solution of quasiperiodic boundary
value problems. To approximate the integral, one must solve a collection of
these problems. This manuscript uses a variant of the periodizing scheme by Cho
and Barnett which alleviates the need for evaluating the quasiperiodic Green's
function and is amenable to a large amount of precomputation that can be reused
for all of the necessary solves. The solution technique is accelerated by the
use of low rank linear algebra. The numerical results illustrate that the
presented method is 20-30 faster than the technique utilizing the quasiperiodic
Green's function for a stair-like geometry.

</details>


### [51] [Preconditioning of GMRES for Helmholtz problems with quasimodes](https://arxiv.org/abs/2511.04512)
*Victorita Dolean,Pierre Marchand,Axel Modave,Timothée Raynaud*

Main category: math.NA

TL;DR: 本文研究了有限元方法在复杂几何和非均匀介质中Helmholtz问题的应用，针对高波数或近共振条件下迭代求解器面临的挑战，提出了一种结合非线性相对残差行为的GMRES收敛性界，并通过调和Ritz值分析了拟模态小特征值对收敛的影响。此外，结合区域分解法与针对共振区域的（近似）特征向量进行去充技术，评估了其对GMRES性能的改进效果。


<details>
  <summary>Details</summary>
Motivation: Helmholtz问题在高波数或共振条件下，传统迭代求解器难以有效收敛，尤其是由拟模态引起的小特征值会显著影响求解效率，因此需要更深入理解收敛机制并提升求解性能。

Method: 推导包含非线性相对残差行为的GMRES收敛界，结合调和Ritz值分析收敛性；采用区域分解法，并结合基于近似特征向量的去充技术以改善收敛性能。

Result: 揭示了小特征值在何种情况下影响或不再影响GMRES收敛；数值实验验证了区域分解与去充技术在共振区域对GMRES性能的有效提升。

Conclusion: 通过调和Ritz值视角可更好理解GMRES在Helmholtz问题中的收敛行为，结合区域分解与针对性的去充技术能显著提升高波数或共振问题的求解效率。

Abstract: Finite element methods are effective for Helmholtz problems involving complex
geometries and heterogeneous media. However, the resulting linear systems are
often large, indefinite, and challenging for iterative solvers, particularly at
high wave numbers or near resonant conditions. We derive a GMRES convergence
bound that incorporates the nonlinear behavior of the relative residual and
relates convergence to harmonic Ritz values. This perspective reveals how small
eigenvalues associated with quasimodes can hinder convergence, and when they
cease to have an effect. These phenomena occur in domain decomposition, and we
illustrate them through numerical experiments. We also combine domain
decomposition methods with deflation techniques using (approximate)
eigenvectors tailored to resonant regimes. Their impact on GMRES performance is
evaluated.

</details>


### [52] [Mixed precision multigrid with smoothing based on incomplete Cholesky factorization](https://arxiv.org/abs/2511.04566)
*Petr Vacek,Hartwig Anzt,Erin Carson,Nils Kohl,Ulrich Rüde,Yu-Hsiang Tsai*

Main category: math.NA

TL;DR: 提出了一种混合精度的多网格V循环方法，分析了有限精度误差的影响，并表明在某些情况下，IC平滑步骤可以使用较低精度，从而实现显著的速度提升和能耗节约。


<details>
  <summary>Details</summary>
Motivation: 为了提高大规模稀疏线性方程组求解的效率，探索多网格方法中不同组件使用混合精度的可能性，以减少计算开销和能耗。

Method: 基于不完全Cholesky分解的平滑策略，推导出V循环中相对有限精度误差的上界，分析各组件误差对整体误差的影响。

Result: 理论结果表明，在特定设置下，IC平滑可使用远低于残差、限制、延拓和校正步骤的精度；实验验证了该结论，并实现了最高1.43倍的加速和最多29%的能耗降低。

Conclusion: 混合精度V循环在保证精度的同时能有效提升性能和能效，尤其适用于IC平滑等操作可降精度执行的场景。

Abstract: Multigrid methods are popular iterative methods for solving large-scale
sparse systems of linear equations. We present a mixed precision formulation of
the multigrid V-cycle with general assumptions on the finite precision errors
coming from the application of coarsest-level solver and smoothing. Inspired by
existing analysis, we derive a bound on the relative finite precision error of
the V-cycle which gives insight into how the finite precision errors from the
individual components of the method may affect the overall finite precision
error. We use the result to study V-cycle methods with smoothing based on
incomplete Cholesky factorization. The results imply that in certain settings
the precisions used for applying the IC smoothing can be significantly lower
than the precision used for computing the residual, restriction, prolongation
and correction on the concrete level. We perform numerical experiments using
simulated floating point arithmetic with the MATLAB Advanpix toolbox as well as
experiments computed on GPUs using the Ginkgo library. The experiments
illustrate the theoretical findings and show that in the considered settings
the IC smoothing can be applied in relatively low precisions, resulting in
significant speedups (up to 1.43x) and energy savings (down to 71%) in
comparison with the uniform double precision variant.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [53] [Robust Subgroup Method Using DE Algorithm for Resonance Self-Shielding Calculation](https://arxiv.org/abs/2511.04062)
*Beichen Zheng,Ying Chen,Lili Wen,Xiaofei Wu*

Main category: physics.comp-ph

TL;DR: 本文提出了一种结合鲁棒估计与差分进化算法的改进子群方法，有效消除了传统子群拟合中由U-238敏感基准反应性偏低引起的系统性吸收偏差，提升了输运模拟的预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统子群方法在处理共振自屏蔽时存在系统性吸收偏差，尤其在U-238敏感的基准中表现明显，影响反应性预测的准确性，因此需要一种更鲁棒的方法来克服模型误设和数据污染问题。

Method: 将鲁棒估计（RE）与差分进化（DE）算法结合，构建鲁棒子群方法，在RE框架下利用DE算法求解约束优化问题，抑制异常影响并保证参数可行性。

Result: 数值验证表明，新方法消除了传统子群拟合中的系统性吸收偏差，尤其改善了对U-238相关基准的预测能力，且能更准确地反映强自屏蔽下的物理行为。

Conclusion: 所提出的鲁棒子群方法通过限制影响并强制参数可行性，使子群参数更忠实地追踪真实物理机制，显著提升了反应性预测的保真度和稳定性。

Abstract: This paper presents an enhanced version of the subgroup method for resonance
self-shielding treatment, termed the robust subgroup method, which integrates
Robust Estimation (RE) with a Differential Evolution (DE) algorithm. The RE
approach is employed to handle model misspecification and data contamination,
while the DE algorithm serves as an optimization tool within the RE framework
to obtain constrained solutions. Numerical validation against experimental
benchmarks shows that the proposed method removes a systematic absorption bias
in conventional subgroup fits that would otherwise depress reactivity. This
bias appears only in benchmarks sensitive to U-238. Mechanistically, it
reflects a threshold-like conditioning failure: strong self-shielding leverage
dominates the loss and is magnified by dilution-induced multicollinearity. This
adverse conditioning appears to be seeded by a narrow, sparse resonance
structure at low energies in fertile even-even nuclides, thereby causing rapid
self-shielding response saturation and a weak Doppler broadening. By bounding
influence and enforcing feasibility within an RE-DE framework, the inferred
subgroup parameters track the underlying physics more faithfully, improving the
predictive fidelity of subsequent transport simulations.

</details>


### [54] [Novel Numerical Methods for Accurate Space Thermal Analysis: Enforcing View Factors and Modeling Diffuse Reflectivity](https://arxiv.org/abs/2511.04277)
*Bernat Frangi*

Main category: physics.comp-ph

TL;DR: 本研究提出并验证了两种新的辐射换热因子修正方法，结合多节点表面模型关系，提高了空间热分析中漫反射模拟的精度与效率。


<details>
  <summary>Details</summary>
Motivation: 现有辐射换热修正方法无法同时满足开放系统的封闭性和互易性，且缺乏多尺度模型间的一致性，限制了空间热分析的准确性。

Method: 采用Gebhart方法结合蒙特卡洛光线追踪计算辐射换热因子，并提出基于最小二乘优化（含非负修正和小正值避免）和迭代算法的两种新修正方法，同时引入多节点表面模型关系以统一不同离散化层级的视场因子与辐射换热因子。

Result: 在案例研究中，最小二乘法使平均绝对误差降低81%，迭代法降低56%且计算效率更优；考虑漫反射后，平板稳态温度降低4°C，表明反射辐射减少了净吸收。

Conclusion: 所提方法显著提升了空间热分析中辐射换热建模的准确性与一致性，为航天器系统提供了更可靠、高效的热预测工具。

Abstract: Accurate thermal analysis is crucial for modern spacecraft, driving demand
for reliable modeling tools. This research advances space thermal modeling by
improving the simulation accuracy and efficiency of radiative heat transfer,
the dominant mode of heat exchange in space. To this end, we incorporate
diffuse reflectivity using the Gebhart method, which computes radiative
exchange factors (REFs) from geometric view factors. The view factors, obtained
via Monte Carlo ray tracing (MCRT), require post-processing to mitigate
statistical errors. Critically, existing correction schemes cannot
simultaneously enforce closure and reciprocity for open systems. This research
addresses this gap by proposing two novel enforcement methods: (i) a
least-squares optimization with non-negativity rectification (NNR) and small
positive value avoidance (SPVA), and (ii) an iterative enforcement algorithm.
To ensure consistency across different discretization levels, this work also
introduces the multi-node surface model relations to formalize the connection
between sub-face, face, and node representations of view factors and REFs. A
simple case study demonstrates a substantial reduction in mean absolute error
(MAE): the least-squares method achieves an 81% MAE reduction, while the
iterative method offers the best balance of accuracy (56% MAE reduction) and
computational efficiency. A second case study shows that including diffuse
reflections decreases the steady-state temperature of a plate by $4^{\circ}C$,
reinforcing that reflected radiation reduces net absorption. This work
introduces and validates computationally efficient methods for integrating
diffuse reflectivity into space thermal analyses and for consistently coupling
multi-node surface radiative models. The results enable more accurate and
robust thermal predictions for spacecraft systems.

</details>


### [55] [Unveiling the Adsorption and Electronic Interactions of Drugs on 2D Graphsene: Insights from DFT and Machine Learning Approach](https://arxiv.org/abs/2511.04483)
*Chaithanya Purushottam Bhat,Pranav Suryawanshi,Aditya Guneja,Debashis Bandyopadhyay*

Main category: physics.comp-ph

TL;DR: 提出了一种结合密度泛函理论（DFT）和机器学习（ML）的协同框架，用于研究药物分子在新型二维石墨烯同素异形体Graphsene上的吸附行为和电子相互作用，实现了高效、低成本的药物-纳米材料相互作用筛选。


<details>
  <summary>Details</summary>
Motivation: 为了高效识别适用于纳米材料递送系统的潜在药物候选物，推动下一代药物递送系统的发展。

Method: 结合密度泛函理论（DFT）与机器学习（ML），利用包含67种药物在二维基底上吸附的数据集训练ML模型，并用DFT计算吸附能、投影态密度（PDOS）和Bader电荷等参数验证和分析药物与Graphsene的相互作用。

Result: ML模型在DFT验证下平均绝对误差为0.075 eV，表现出良好的预测精度；DFT分析显示药物分子与Graphsene之间存在显著的电荷转移和电子耦合。

Conclusion: DFT-ML联合策略可实现快速、低成本的药物-纳米材料相互作用筛选与机理理解，为数据驱动的先进纳米药物递送系统设计提供了新途径。

Abstract: Efficient identification of promising drug candidates for nanomaterial-based
delivery systems is essential for advancing next-generation therapeutics. In
this work, we present a synergistic framework combining density functional
theory (DFT) and machine learning (ML) to explore the adsorption behavior and
electronic interactions of drugs on a novel 2D graphene allotrope, termed
Graphsene (GrS). Graphsene, characterized by its porous ring topology and large
surface area, offers an excellent platform for efficient adsorption and strong
electronic coupling with drug molecules. A dataset comprising 67 drugs adsorbed
on various 2D substrates was employed to train the ML model, which was
subsequently applied to predict suitable drug candidates for GrS based on
molecular size and adsorption energy criteria (database link provided in a
later section). The ML model exhibited robust predictive accuracy, achieving a
mean absolute error of 0.075 eV upon DFT validation, though its sensitivity to
initialization highlighted the need for larger and more diverse datasets.
DFT-based analyses, including adsorption energetics, projected density of
states (PDOS), and Bader charge calculations, revealed pronounced charge
transfer and electronic coupling between the drug molecules and the GrS
surface, elucidating the fundamental nature of drug-substrate interactions. The
study reveals that the integrated DFT-ML strategy offers a rapid,
cost-efficient approach for screening and understanding drug-nanomaterial
interactions, paving the way for data-driven design of advanced
nanomaterial-enabled drug delivery systems.

</details>


### [56] [Scalable Domain-decomposed Monte Carlo Neutral Transport for Nuclear Fusion](https://arxiv.org/abs/2511.04489)
*Oskar Lappi,Huw Leggate,Yannick Marandet,Jan Åström,Keijo Heljanko,Dmitriy V. Borodin*

Main category: physics.comp-ph

TL;DR: 本文介绍了一种新的开源蒙特卡洛代码Eiron，实现了域分解蒙特卡洛（DDMC）算法，并在强扩展和弱扩展测试中表现出优于现有算法的性能，表明在EIRENE中实现该算法可提升性能并支持目前因内存限制无法进行的模拟。


<details>
  <summary>Details</summary>
Motivation: 由于EIRENE不支持域分解，无法处理网格数据超出单个计算节点内存的情况，因此需要开发支持域分解的新算法以扩展其应用范围。

Method: 在新开发的开源蒙特卡洛代码Eiron中实现了域分解蒙特卡洛（DDMC）算法，并复现了EIRENE中现有的两种并行算法，通过在Mahti超级计算机上进行强扩展和弱扩展测试对比三者的性能。

Result: DDMC在大多数情况下性能优于其他两种算法；在网格超出L3缓存时表现出超线性扩展；弱扩展测试中最多扩展到16384核，高碰撞情况下弱扩展效率为45%，低碰撞情况下为26%。

Conclusion: 在EIRENE中引入DDMC算法将显著提升其性能，并使当前因内存限制无法完成的大规模模拟成为可能。

Abstract: EIRENE [1] is a Monte Carlo neutral transport solver heavily used in the
fusion community. EIRENE does not implement domain decomposition, making it
impossible to use for simulations where the grid data does not fit on one
compute node (see e.g. [2]). This paper presents a domain-decomposed Monte
Carlo (DDMC) algorithm implemented in a new open source Monte Carlo code,
Eiron. Two parallel algorithms currently used in EIRENE are also implemented in
Eiron, and the three algorithms are compared by running strong scaling tests,
with DDMC performing better than the other two algorithms in nearly all cases.
On the supercomputer Mahti [3], DDMC strong scaling is superlinear for grids
that do not fit into an L3 cache slice (4 MiB). The DDMC algorithm is also
scaled up to 16384 cores in weak scaling tests, with a weak scaling efficiency
of 45% in a high-collisional (heavier compute load) case, and 26% in a
low-collisional (lighter compute load) case. We conclude that implementing this
domain decomposition algorithm in EIRENE would improve performance and enable
simulations that are currently impossible due to memory constraints.

</details>


### [57] [Uncertainties in Physics-informed Inverse Problems: The Hidden Risk in Scientific AI](https://arxiv.org/abs/2511.04564)
*Yoh-ichi Mototake,Makoto Sasaki*

Main category: physics.comp-ph

TL;DR: 本文提出了一种量化物理信息机器学习（PIML）中系数函数估计不确定性的框架，并通过引入几何约束实现了对磁流体动力学简化模型的唯一估计。


<details>
  <summary>Details</summary>
Motivation: 物理模型的评价不应仅依赖预测准确性，还应考虑其物理意义和不确定性。现有PIML方法缺乏对系数函数估计不确定性的系统分析。

Method: 提出一个用于量化和分析PIML中系数函数估计不确定性的框架，并在磁流体动力学简化模型中引入几何约束以实现唯一识别。

Result: 应用该框架发现存在估计不确定性，但通过引入几何约束可实现唯一识别，并成功估计出简化模型。

Conclusion: 该框架有助于在PIML中选择具有物理意义的解，提升模型的科学可信度。

Abstract: Physics-informed machine learning (PIML) integrates partial differential
equations (PDEs) into machine learning models to solve inverse problems, such
as estimating coefficient functions (e.g., the Hamiltonian function) that
characterize physical systems. This framework enables data-driven understanding
and prediction of complex physical phenomena. While coefficient functions in
PIML are typically estimated on the basis of predictive performance, physics as
a discipline does not rely solely on prediction accuracy to evaluate models.
For example, Kepler's heliocentric model was favored owing to small
discrepancies in planetary motion, despite its similar predictive accuracy to
the geocentric model. This highlights the inherent uncertainties in data-driven
model inference and the scientific importance of selecting physically
meaningful solutions. In this paper, we propose a framework to quantify and
analyze such uncertainties in the estimation of coefficient functions in PIML.
We apply our framework to reduced model of magnetohydrodynamics and our
framework shows that there are uncertainties, and unique identification is
possible with geometric constraints. Finally, we confirm that we can estimate
the reduced model uniquely by incorporating these constraints.

</details>


### [58] [Combining Harmonic Sampling with the Worm Algorithm to Improve the Efficiency of Path Integral Monte Carlo](https://arxiv.org/abs/2511.04597)
*Sourav Karmakar,Sutirtha Paul,Adrian Del Maestro,Barak Hirshberg*

Main category: physics.comp-ph

TL;DR: 提出了一种改进的路径积分蒙特卡洛算法H-PIMC及其推广M-PIMC，通过分离势能的谐波与非谐波部分，显著提高了在固体和密闭液体系统中的采样效率和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 传统PIMC方法在处理固体和密集受限液体时接受率低，效率差，因此需要开发更高效的采样算法。

Method: 将势能分为谐波和非谐波部分，在H-PIMC中精确生成谐波部分的虚时间路径，并基于非谐波部分进行接受或拒绝；在M-PIMC中限制谐波采样在局部极小值附近，其余部分使用标准PIMC。结合蠕虫算法推广至不可区分粒子系统。

Result: H-PIMC在弱到中等非谐性系统中将接受率提高6-16倍，自相关时间减少7-30倍，并减少所需虚时间切片数，带来额外2-4倍加速；M-PIMC在强非谐系统中优化自相关时间，且可推广至周期性系统。

Conclusion: H-PIMC和M-PIMC显著提升了量子凝聚相模拟的效率，尤其适用于不同非谐程度的系统，结合蠕虫算法后还可高效处理全同粒子系统。

Abstract: We propose an improved Path Integral Monte Carlo (PIMC) algorithm called
Harmonic PIMC (H-PIMC) and its generalization, Mixed PIMC (M-PIMC). PIMC is a
powerful tool for studying quantum condensed phases. However, it often suffers
from a low acceptance ratio for solids and dense confined liquids. We develop
two sampling schemes especially suited for such problems by dividing the
potential into its harmonic and anharmonic contributions. In H-PIMC, we
generate the imaginary time paths for the harmonic part of the potential
exactly and accept or reject it based on the anharmonic part. In M-PIMC, we
restrict the harmonic sampling to the vicinity of local minimum and use
standard PIMC otherwise, to optimize efficiency. We benchmark H-PIMC on systems
with increasing anharmonicity, improving the acceptance ratio and lowering the
auto-correlation time. For weakly to moderately anharmonic systems, at $\beta
\hbar \omega=16$, H-PIMC improves the acceptance ratio by a factor of 6-16 and
reduces the autocorrelation time by a factor of 7-30. We also find that the
method requires a smaller number of imaginary time slices for convergence,
which leads to another two- to four-fold acceleration. For strongly anharmonic
systems, M-PIMC converges with a similar number of imaginary time slices as
standard PIMC, but allows the optimization of the auto-correlation time. We
extend M-PIMC to periodic systems and apply it to a sinusoidal potential.
Finally, we combine H- and M-PIMC with the worm algorithm, allowing us to
obtain similar efficiency gains for systems of indistinguishable particles.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [59] [Causal Regime Detection in Energy Markets With Augmented Time Series Structural Causal Models](https://arxiv.org/abs/2511.04361)
*Dennis Thumm*

Main category: q-fin.CP

TL;DR: 提出了一种用于能源市场的增强型时间序列因果模型（ATSCM），能够对电力价格进行可解释建模并支持反事实推理。


<details>
  <summary>Details</summary>
Motivation: 现有电力价格模型缺乏明确的因果解释和反事实推理能力，且难以捕捉能源市场中连续发生的机制变化。

Method: 结合神经因果发现方法，学习时变因果图结构，构建包含天气、发电结构、需求模式等可解释因子的多变量时间序列因果模型。

Result: 在真实电力价格数据上验证了模型有效性，支持如‘不同可再生能源情景下的电价会如何’等反事实查询。

Conclusion: ATSCM为能源市场提供了具备因果解释和动态反事实推理能力的新建模框架，提升了对复杂电力系统的理解和决策支持能力。

Abstract: Energy markets exhibit complex causal relationships between weather patterns,
generation technologies, and price formation, with regime changes occurring
continuously rather than at discrete break points. Current approaches model
electricity prices without explicit causal interpretation or counterfactual
reasoning capabilities. We introduce Augmented Time Series Causal Models
(ATSCM) for energy markets, extending counterfactual reasoning frameworks to
multivariate temporal data with learned causal structure. Our approach models
energy systems through interpretable factors (weather, generation mix, demand
patterns), rich grid dynamics, and observable market variables. We integrate
neural causal discovery to learn time-varying causal graphs without requiring
ground truth DAGs. Applied to real-world electricity price data, ATSCM enables
novel counterfactual queries such as "What would prices be under different
renewable generation scenarios?".

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [60] [Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for Latin American Contexts](https://arxiv.org/abs/2511.04090)
*Brigitte A. Mora-Reyes,Jennifer A. Drewyor,Abel A. Reyes-Angulo*

Main category: cs.SI

TL;DR: 本文探讨了人工智能系统中因数据不平衡而导致的拉丁美洲等发展中地区边缘化问题，提出了一种基于拉丁美洲历史和文化背景的新型文化感知数据集，并通过文化表达力指标评估多个语言模型的表现。实验表明，使用该数据集微调Mistral-7B模型的文化表达力提升了42.9%，有助于推动公平的人工智能发展。


<details>
  <summary>Details</summary>
Motivation: 人工智能系统常反映经济发达地区的偏见，因训练数据不平衡而忽视拉丁美洲等发展中地区的文化背景。本文旨在揭示语言模型在处理西班牙语、葡萄牙语及土著语言（如克丘亚语和纳瓦特尔语）时的文化偏差，并挑战以西方为中心的AI模型。

Method: 构建了一个根植于拉丁美洲历史和社会政治背景的文化感知数据集；设计了六个语言模型在文化语境理解方面的测试问题；引入“文化表达力”新指标，结合统计检验和语言学分析进行评估；并对Mistral-7B模型使用该数据集进行微调以验证效果。

Result: 研究发现部分模型能较好捕捉拉丁美洲视角，而其他模型存在显著情感错位（p < 0.001）；使用新数据集微调Mistral-7B后，其文化表达力提升了42.9%。

Conclusion: 为实现公平的人工智能，应优先采用反映拉丁美洲历史、土著知识和多元语言的数据集，并倡导以社区为中心的方法，增强边缘化群体的声音。

Abstract: Artificial intelligence (AI) systems often reflect biases from economically
advanced regions, marginalizing contexts in economically developing regions
like Latin America due to imbalanced datasets. This paper examines AI
representations of diverse Latin American contexts, revealing disparities
between data from economically advanced and developing regions. We highlight
how the dominance of English over Spanish, Portuguese, and indigenous languages
such as Quechua and Nahuatl perpetuates biases, framing Latin American
perspectives through a Western lens. To address this, we introduce a culturally
aware dataset rooted in Latin American history and socio-political contexts,
challenging Eurocentric models. We evaluate six language models on questions
testing cultural context awareness, using a novel Cultural Expressiveness
metric, statistical tests, and linguistic analyses. Our findings show that some
models better capture Latin American perspectives, while others exhibit
significant sentiment misalignment (p < 0.001). Fine-tuning Mistral-7B with our
dataset improves its cultural expressiveness by 42.9%, advancing equitable AI
development. We advocate for equitable AI by prioritizing datasets that reflect
Latin American history, indigenous knowledge, and diverse languages, while
emphasizing community-centered approaches to amplify marginalized voices.

</details>


### [61] [Launch-Day Diffusion: Tracking Hacker News Impact on GitHub Stars for AI Tools](https://arxiv.org/abs/2511.04453)
*Obada Kraishan*

Main category: cs.SI

TL;DR: 本文提出一个可复现的系统，用于分析Hacker News（HN）曝光对GitHub上AI和LLM工具项目star增长的影响，发现HN曝光在24小时、48小时和一周内显著提升star数量，并通过机器学习模型识别出发布时间是影响传播的关键因素。


<details>
  <summary>Details</summary>
Motivation: 量化Hacker News等社交新闻平台对开源项目发布的即时影响具有挑战性，本文旨在通过可复现的方法揭示其实际效果。

Method: 利用公开API构建自动化分析流水线，收集2024-2025年间138个GitHub项目的发布数据，结合Elastic Net和梯度提升等机器学习模型，分析HN曝光后的star增长模式及关键影响因素。

Result: 项目在HN曝光后24小时内平均获得121个star，48小时内189个，一周内289个；发布时间是影响star增长的关键因素，而'Show HN'标签在控制其他变量后无显著优势。

Conclusion: 该系统可在五分钟内完成数据采集、建模与可视化，具备良好的可复现性和可扩展性，为研究者和开发者提供关于项目发布策略的实际指导。

Abstract: Social news platforms have become key launch outlets for open-source
projects, especially Hacker News (HN), though quantifying their immediate
impact remains challenging. This paper presents a reproducible demonstration
system that tracks how HN exposure translates into GitHub star growth for AI
and LLM tools. Built entirely on public APIs, our pipeline analyzes 138
repository launches from 2024-2025 and reveals substantial launch effects:
repositories gain an average of 121 stars within 24 hours, 189 stars within 48
hours, and 289 stars within a week of HN exposure. Through machine learning
models (Elastic Net) and non-linear approaches (Gradient Boosting), we identify
key predictors of viral growth. Posting timing appears as key factor--launching
at optimal hours can mean hundreds of additional stars--while the "Show HN" tag
shows no statistical advantage after controlling for other factors. The
demonstration completes in under five minutes on standard hardware,
automatically collecting data, training models, and generating visualizations
through single-file scripts. This makes our findings immediately reproducible
and the framework easily be extended to other platforms, providing both
researchers and developers with actionable insights into launch dynamics.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [62] [Cross-Modal Alignment between Visual Stimuli and Neural Responses in the Visual Cortex](https://arxiv.org/abs/2511.04096)
*Xing Gao,Dazhong Rong,Qinming He*

Main category: cs.CE

TL;DR: 本文提出了一种名为视觉-神经对齐（VNA）的跨模态对齐方法，用于更准确地刻画视觉刺激与神经响应之间的映射关系，相较于传统的直接编码和解码方法，在多个侵入式视觉皮层数据集上表现出更优的性能。


<details>
  <summary>Details</summary>
Motivation: 由于神经响应的变异性及记录技术的限制，现有直接编码和解码方法易过拟合且泛化能力差，因此需要一种更合理的判别性编码与解码框架。

Method: 提出视觉-神经对齐（VNA）方法，采用判别性编码与解码任务，通过跨模态对齐学习视觉刺激与神经响应之间的映射关系。

Result: 在三个侵入式视觉皮层数据集（涉及小鼠和猕猴）上的实验表明，VNA在判别性任务中普遍优于直接编码和直接解码方法。

Conclusion: VNA能更精确地刻画视觉刺激与神经响应之间的映射关系，为理解生物视觉处理机制提供了更可靠的方法。

Abstract: Investigating the mapping between visual stimuli and neural responses in the
visual cortex contributes to a deeper understanding of biological visual
processing mechanisms. Most existing studies characterize this mapping by
training models to directly encode visual stimuli into neural responses or
decode neural responses into visual stimuli. However, due to neural response
variability and limited neural recording techniques, these studies suffer from
overfitting and lack generalizability. Motivated by this challenge, in this
paper we shift the tasks from conventional direct encoding and decoding to
discriminative encoding and decoding, which are more reasonable. And on top of
this we propose a cross-modal alignment approach, named Visual-Neural Alignment
(VNA). To thoroughly test the performance of the three methods (direct
encoding, direct decoding, and our proposed VNA) on discriminative encoding and
decoding tasks, we conduct extensive experiments on three invasive visual
cortex datasets, involving two types of subject mammals (mice and macaques).
The results demonstrate that our VNA generally outperforms direct encoding and
direct decoding, indicating our VNA can most precisely characterize the above
visual-neural mapping among the three methods.

</details>


### [63] [Fitting Reinforcement Learning Model to Behavioral Data under Bandits](https://arxiv.org/abs/2511.04454)
*Hao Zhu,Jasper Hoffmann,Baohe Zhang,Joschka Boedecker*

Main category: cs.CE

TL;DR: 提出了一种基于凸松弛和优化的强化学习模型拟合新方法，在多臂赌博机环境下具有高效性和可及性。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地拟合多臂赌博机环境下的行为数据，刻画人类和动物的决策行为，需要改进现有强化学习模型的拟合方法。

Method: 通过建立通用的数学优化模型，分析其凸性，并基于凸松弛和优化理论提出新的求解方法。

Result: 在多个模拟环境中验证了该方法的有效性，性能与现有最先进方法相当，但显著减少了计算时间。

Conclusion: 所提出的方法在保持高性能的同时大幅降低计算开销，并通过开源Python包提升了可应用性。

Abstract: We consider the problem of fitting a reinforcement learning (RL) model to
some given behavioral data under a multi-armed bandit environment. These models
have received much attention in recent years for characterizing human and
animal decision making behavior. We provide a generic mathematical optimization
problem formulation for the fitting problem of a wide range of RL models that
appear frequently in scientific research applications, followed by a detailed
theoretical analysis of its convexity properties. Based on the theoretical
results, we introduce a novel solution method for the fitting problem of RL
models based on convex relaxation and optimization. Our method is then
evaluated in several simulated bandit environments to compare with some
benchmark methods that appear in the literature. Numerical results indicate
that our method achieves comparable performance to the state-of-the-art, while
significantly reducing computation time. We also provide an open-source Python
package for our proposed method to empower researchers to apply it in the
analysis of their datasets directly, without prior knowledge of convex
optimization.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [64] [Quantifying Compound Flood Risk and Transition Zones via an Extended Joint Probability Method](https://arxiv.org/abs/2511.03871)
*Mark S. Bartlett,Nathan Geldner,Zach Cobell,Luis Partida,Ovel Diaz,David R. Johnson,Hanbeen Kim,Brett McMann,Gabriele Villarini,Shubra Misra,Hugh J. Roberts,Muthukumar Narayanaswamy*

Main category: physics.geo-ph

TL;DR: 本文扩展了联合概率法（JPM）以量化热带和非热带风暴下的复合洪水深度可能性，结合降雨、前期土壤湿度、基流和海岸风暴潮，提供了复合洪水风险的统一概率基础。


<details>
  <summary>Details</summary>
Motivation: 现有方法在量化复合洪水风险时缺乏统一的概率基础，无法充分描述洪水响应的可能性及复合洪水过渡区的统计结构。

Method: 将联合概率法（JPM）扩展至水文过程，整合降雨场、前期土壤湿度、基流与海岸风暴潮，建立洪水深度对多种驱动因素联合分布的响应模型，并基于超越概率划定复合洪水过渡区（CFTZ），系统识别特定重现期的设计风暴。

Result: 在路易斯安那州马雷帕斯湖区域的应用显示，复合洪水过渡区面积是以往事件特异性划定结果的两倍以上，复合相互作用使洪水深度增加高达2.25英尺。

Conclusion: 扩展的JPM为复合洪水风险评估和规划提供了坚实的概率基础，弥补了传统方法仅基于驱动因素 likelihood 设计的不足。

Abstract: Compound flooding from the combined effects of extreme storm surge, rainfall,
and river flows poses significant risks to infrastructure and communities -- as
demonstrated by hurricanes Isaac and Harvey. Yet, existing methods to quantify
compound flood risk lack a unified probabilistic basis. Copula-based models
capture the co-occurrence of flood drivers but not the likelihood of the flood
response, while coupled hydrodynamic models simulate interactions but lack a
probabilistic characterization of compound flood extremes. The Joint
Probability Method (JPM), the foundation of coastal surge risk analysis, has
never been formally extended to incorporate hydrologic drivers -- leaving a
critical gap in quantifying compound flood risk and the statistical structure
of compound flood transition zones (CFTZs). Here, we extend the JPM theory to
hydrologic processes for quantifying the likelihood of compound flood depths
across both tropical and non-tropical storms. This extended methodology
incorporates rainfall fields, antecedent soil moisture, and baseflow alongside
coastal storm surge, enabling: (1) a statistical description of the flood depth
as the response to the joint distribution of hydrologic and coastal drivers,
(2) a statistical delineation of the CFTZ based on exceedance probabilities,
and (3) a systematic identification of design storms for specified return
period flood depths, moving beyond design based solely on driver likelihoods.
We demonstrate this method around Lake Maurepas, Louisiana. Results show a CFTZ
more than double the area of prior event-specific delineations, with compound
interactions increasing flood depths by up to 2.25 feet. This extended JPM
provides a probabilistic foundation for compound flood risk assessment and
planning.

</details>


### [65] [Insights on Numerical Damping Formulations Gained from Calibrating Two-Dimensional Ground Response Analyses at Downhole Array Sites](https://arxiv.org/abs/2511.04074)
*Nishkarsha Dawadi,Kami Mohammadi,Mohamad M. Hallal,Brady R. Cox*

Main category: physics.geo-ph

TL;DR: 本研究通过在四个井下阵列站点使用二维地面响应分析（2D GRAs），探讨了不同数值阻尼模型对地震波衰减的模拟效果，发现Rayleigh Mass阻尼在匹配实测传递函数方面表现最佳，且计算效率高。


<details>
  <summary>Details</summary>
Motivation: 准确模拟地震波衰减对地面响应分析至关重要，但一维分析中常通过放大最小阻尼比（D_min）来补偿无法捕捉的衰减机制，导致高频模态过度阻尼。因此，研究旨在通过二维模型更直接地模拟表观阻尼。

Method: 在Delaney Park、I-15、Treasure Island和Garner Valley四个站点进行二维地面响应分析，采用三种阻尼模型（Full Rayleigh、Maxwell和Rayleigh Mass），并结合常规和校准后放大的D_min进行对比。

Result: 结果表明，D_min的放大系数与场地速度对比度相关；使用放大D_min时，Full Rayleigh和Maxwell阻尼会过度抑制高阶模态，Maxwell还导致模态峰偏移，而Rayleigh Mass阻尼在四个站点中的三个表现最优，且计算更快。

Conclusion: 放大D_min可在二维分析中有效表征未建模的衰减，尤其适用于低速度对比场地；频率相关阻尼模型（如Rayleigh Mass）比传统频率无关模型能更准确预测场地响应。

Abstract: Accurately modeling seismic wave attenuation is critical for ground response
analyses (GRAs), which aim to replicate local site effects in ground motions.
However, theoretical transfer functions (TTFs) from GRAs often overestimate
empirical transfer functions (ETFs) when the small-strain damping ratio
($D_{\text{min}}$) is set equal to laboratory measurements. Prior studies
addressed this by inflating $D_{\text{min}}$ in one-dimensional (1D) GRAs to
account for apparent damping mechanisms such as diffraction and mode
conversions that cannot be captured in 1D. Although this approach improved
fundamental-mode predictions, it often overdamped higher modes. This study
explores more direct modeling of apparent damping using two-dimensional (2D)
GRAs at four downhole array sites: Delaney Park (DPDA), I-15 (I15DA), Treasure
Island (TIDA), and Garner Valley (GVDA). At each site, three numerical damping
formulations, Full Rayleigh, Maxwell, and Rayleigh Mass, were implemented using
both conventional $D_{\text{min}}$ and an inflated $D_{\text{min}}$ ($m \times
D_{\text{min}}$) obtained from site-specific calibration. Results show that the
appropriate $D_{\text{min}}$ multiplier ($m$) correlates with the site's
velocity contrast. Using inflated $D_{\text{min}}$, Full Rayleigh and Maxwell
damping systematically overdamped higher modes, with Maxwell damping also
shifting modal peaks. In contrast, Rayleigh Mass damping consistently achieved
the closest match to ETFs at three of the four sites while offering faster
computational performance. These findings demonstrate that inflated
$D_{\text{min}}$ can represent unmodeled attenuation in 2D GRAs, particularly
at sites with low velocity contrast, and that frequency-dependent formulations
such as Rayleigh Mass damping can more accurately predict site response than
traditional frequency-independent approaches.

</details>


### [66] [SeismoStats: A Python Package for Statistical Seismology](https://arxiv.org/abs/2511.04521)
*Aron Mirwald,Nicolas Schmid,Leila Mizrahi,Marta Han,Alicia Rohnacher,Vanille A. Ritz,Stefan Wiemer*

Main category: physics.geo-ph

TL;DR: SeismoStats是一个专注于成熟方法的Python包，用于实现基本的统计地震学分析，提供用户友好的工具来下载和操作地震目录，以及可视化和分析功能，如估计Gutenberg-Richter定律的a值和b值，或任何地震目录的完整性震级。


<details>
  <summary>Details</summary>
Motivation: 开发一个经过良好测试、文档齐全且公开可访问的Python包，以促进统计地震学研究，并作为长期社区努力的核心。

Method: 提供一个包含下载、操作、可视化地震目录及执行关键统计分析功能的综合Python包。

Result: 首个集成了多种地震学分析功能且开放共享的Python工具包，支持社区持续贡献和发展。

Conclusion: SeismoStats有望成为统计地震学领域的核心工具，推动该领域的方法标准化和协作研究。

Abstract: We introduce SeismoStats, a Python package that enables essential statistical
seismology analyses, with a focus on well-established methods. The package
provides user-friendly tools to download and manipulate earthquake catalogs,
but also plotting functionalities to visualize them, as well as means to
perform analyses such as estimating the a- and b-value of the Gutenberg-Richter
law, or estimating the magnitude of completeness of any earthquake catalog.
This is the first well-tested, well-documented, and openly accessible Python
package with all these features. It is intended to serve as the nucleus of a
long-term community effort, continually expanding in functionality through
shared contributions. We invite seismologists and developers to contribute
ideas and code to support and shape its future development.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [67] [On excitation of control-affine systems and its use for data-driven Koopman approximants](https://arxiv.org/abs/2511.03734)
*Philipp Schmitz,Lea Bold,Friedrich M. Philipp,Mario Rosenfelder,Peter Eberhard,Henrik Ebel,Karl Worthmann*

Main category: eess.SY

TL;DR: 本文提出了一种用于增强控制仿射映射数据拟合的框架，以提高系统辨识的鲁棒性，并改进双线性EDMD方法在非完整机器人控制中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的基于EDMD的双线性模型对数据要求高，限制了其在控制仿射系统中的应用，本文旨在提升数据效率和模型鲁棒性。

Method: 通过子空间角度指导输入选择，确保最小奇异值达到设定阈值，并推导出最大化最小奇异值的最优性条件，从而提升系统辨识的可靠性。

Result: 所提方法有效提高了双线性EDMD在控制仿射系统中的鲁棒性和可靠性，并在非完整机器人控制中验证了其有效性。

Conclusion: 该框架通过优化输入选择显著增强了双线性EDMD的性能，为复杂动力系统的建模与控制提供了更可靠的数据驱动方案。

Abstract: The Koopman operator and extended dynamic mode decomposition (EDMD) as a
data-driven technique for its approximation have attracted considerable
attention as a key tool for modeling, analysis, and control of complex
dynamical systems. However, extensions towards control-affine systems resulting
in bilinear surrogate models are prone to demanding data requirements rendering
their applicability intricate. In this paper, we propose a framework for
data-fitting of control-affine mappings to increase the robustness margin in
the associated system identification problem and, thus, to provide more
reliable bilinear EDMD schemes. In particular, guidelines for input selection
based on subspace angles are deduced such that a desired threshold with respect
to the minimal singular value is ensured. Moreover, we derive necessary and
sufficient conditions of optimality for maximizing the minimal singular value.
Further, we demonstrate the usefulness of the proposed approach using bilinear
EDMD with control for non-holonomic robots.

</details>


### [68] [Hybrid ILM-NILM Smart Plug System](https://arxiv.org/abs/2511.03737)
*Dániel István Németh,Kálmán Tornai*

Main category: eess.SY

TL;DR: 本文提出了一种混合负载分类解决方案，通过扩展智能插座以支持多个负载，降低系统安装成本，同时处理家庭中常见的通过延长线连接多个设备的情况。


<details>
  <summary>Details</summary>
Motivation: 现有的非侵入式和侵入式电力负载分类方法各有优缺点，但结合二者的研究较少。本文旨在通过混合方法在控制粒度和成本之间取得平衡。

Method: 提出一种混合负载分类方法，扩展智能插座以支持多个负载，并通过延长线连接多个电器，实现低成本的系统安装。

Result: 该方案能够在降低安装成本的同时，有效处理多个负载连接到同一智能插座的常见家庭场景。

Conclusion: 扩展智能插座以支持多负载是一种可行的混合方法，能够在牺牲部分控制粒度的前提下显著降低系统成本，适用于实际家庭环境。

Abstract: Electrical load classification is generally divided into intrusive and
non-intrusive approaches, both having their limitations and advantages. With
the non-intrusive approach, controlling appliances is not possible, but the
installation cost of a single measurement device is cheap. In comparison,
intrusive, smart plug-based solutions offer individual appliance control, but
the installation cost is much higher. There have been very few approaches
aiming to combine these methods. In this paper we show that extending a smart
plug-based solution to multiple loads per plug can reduce control granularity
in favor of lowering the system's installation costs. Connecting various loads
to a Smart Plug through an extension cord is seldom considered in the
literature, even though it is common in households. This scenario is also
handled by the hybrid load classification solution presented in this paper.

</details>


### [69] [InvSim algorithm for pre-computing airplane flight controls in limited-range autonomous missions, and demonstration via double-roll maneuver of Mirage III fighters](https://arxiv.org/abs/2511.03745)
*Osama A. Marzouk*

Main category: eess.SY

TL;DR: 本文提出了一种适用于非对称固定翼飞机的六自由度飞行动力学逆仿真数学框架，通过符号计算、RK4积分和有限差分法，实现了对目标飞行轨迹所需控制输入的预测。


<details>
  <summary>Details</summary>
Motivation: 为了实现对复杂飞行轨迹的精确控制，需要建立一个通用且灵活的逆仿真框架，以预测实现特定飞行路径所需的飞行控制输入。

Method: 基于六自由度运动方程，结合体轴、惯性轴、风轴及球面飞行角，构建逆仿真系统；采用符号数学、四阶龙格-库塔法和有限差分法进行时间积分，求解推力、副翼、升降舵和方向舵的控制量。

Result: 开发了一套数值方法，能够计算出实现指定轨迹（包括三维位置和滚转角）所需的四个控制变量的离散时间序列，并成功演示了该逆仿真系统的有效性。

Conclusion: 所提出的逆仿真方法可有效预测非对称飞机实现给定飞行轨迹所需的控制输入，具有良好的应用前景于飞行控制设计与任务规划。

Abstract: In this work, we start with a generic mathematical framework for the
equations of motion (EOM) in flight mechanics with six degrees of freedom
(6-DOF) for a general (not necessarily symmetric) fixed-wing aircraft. This
mathematical framework incorporates (1) body axes (fixed in the airplane at its
center of gravity), (2) inertial axes (fixed in the earth/ground at the
take-off point), wind axes (aligned with the flight path/course), (3) spherical
flight path angles (azimuth angle measured clockwise from the geographic north,
and elevation angle measured above the horizon plane), and (4) spherical flight
angles (angle of attack and sideslip angle). We then manipulate these equations
of motion to derive a customized version suitable for inverse simulation flight
mechanics, where a target flight trajectory is specified while a set of
corresponding necessary flight controls to achieve that maneuver are predicted.
We then present a numerical procedure for integrating the developed inverse
simulation (InvSim) system in time; utilizing (1) symbolic mathematics, (2)
explicit fourth-order Runge-Kutta (RK4) numerical integration technique, and
(3) expressions based on the finite difference method (FDM); such that the four
necessary control variables (engine thrust force, ailerons' deflection angle,
elevators' deflection angle, and rudder's deflection angle) are computed as
discrete values over the entire maneuver time, and these calculated control
values enable the airplane to achieve the desired flight trajectory, which is
specified by three inertial Cartesian coordinates of the airplane, in addition
to the Euler's roll angle. We finally demonstrate the proposed numerical
procedure of flight mechanics inverse simulation (InvSim).

</details>


### [70] [Electric Vehicle Charging Load Modeling: A Survey, Trends, Challenges and Opportunities](https://arxiv.org/abs/2511.03741)
*Xiachong Lin,Arian Prabowo,Imran Razzak,Hao Xue,Matthew Amos,Sam Behrens,Flora D. Salim*

Main category: eess.SY

TL;DR: 本文综述了近五年电动汽车充电负荷模型，将其分为统计、模拟和数据驱动三类方法，并分析了现有模型中信息融合的三层自下而上操作，讨论了该领域的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 准确预测电动汽车充电行为对基础设施规划至关重要，但充电负荷受不确定性和随机性影响较大，且现有文献缺乏对信息融合建模方法的系统分析。

Method: 对过去五年的电动汽车充电负荷模型进行分类综述，分为统计、模拟和数据驱动方法，并分析各类方法的优缺点，同时探讨信息融合在现有模型中的应用。

Result: 系统梳理了三类建模方法的特点与局限性，明确了信息融合在充电负荷预测中的关键作用。

Conclusion: 总结了当前研究的挑战与未来方向，为提升电动汽车充电行为建模提供了研究指导。

Abstract: The evolution of electric vehicles (EVs) is reshaping the automotive
industry, advocating for more sustainable transportation practices. Accurately
predicting EV charging behavior is essential for effective infrastructure
planning and optimization. However, the charging load of EVs is significantly
influenced by uncertainties and randomness, posing challenges for accurate
estimation. Furthermore, existing literature reviews lack a systematic analysis
of modeling approaches focused on information fusion. This paper
comprehensively reviews EV charging load models from the past five years. We
categorize state-of-the-art modeling methods into statistical, simulated, and
data-driven approaches, examining the advantages and drawbacks of each.
Additionally, we analyze the three bottom-up level operations of information
fusion in existing models. We conclude by discussing the challenges and
opportunities in the field, offering guidance for future research endeavors to
advance our understanding and explore practical research directions.

</details>


### [71] [Data-driven uncertainty-aware seakeeping prediction of the Delft 372 catamaran using ensemble Hankel dynamic mode decomposition](https://arxiv.org/abs/2511.04461)
*Giorgio Palma,Andrea Serani,Matteo Diez*

Main category: eess.SY

TL;DR: 本研究提出并验证了一种基于集成的Hankel动态模态分解含控制（HDMDc）方法，用于高航速双体船（Delft 372模型）在不确定条件下的耐波性预测。通过不规则波浪水池试验获取多变量时间序列数据，并采用FHDMDc和BHDMDc两种集成策略进行建模与不确定性量化。结果表明，FHDMDc在预测精度和不确定性估计方面优于确定性模型，且其概率密度函数与实验和URANS结果吻合良好，具备高效可靠的工程应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了提升高航速船舶在复杂海况下耐波性预测的准确性与可靠性，特别是在存在非线性与记忆效应的情况下，需要发展能够进行不确定性量化的数据驱动建模方法。

Method: 采用Hankel动态模态分解含控制（HDMDc）方法构建无方程的线性降阶模型，通过引入状态和输入的时间滞后副本捕捉系统非线性和记忆效应；并比较两种集成策略：贝叶斯HDMDc（BHDMDc）和频率学派HDMDc（FHDMDc），分别基于超参数采样和数据子集聚合进行不确定性量化。

Result: FHDMDc相比确定性模型显著提高了预测精度，并提供了稳健的不确定性估计；其预测的概率密度函数与实验数据及URANS模拟结果高度一致；而BHDMDc在本案例中未表现出优于确定性模型的效果。

Conclusion: FHDMDc是一种高效、可靠的数据驱动方法，适用于高航速双体船的耐波性预测与不确定性量化，具备在船舶设计与运行支持中应用的潜力。

Abstract: In this study, we present and validate an ensemble-based Hankel Dynamic Mode
Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions
of a high-speed catamaran, namely the Delft 372 model. Experimental
measurements (time histories) of wave elevation at the longitudinal center of
gravity, heave, pitch, notional flight-deck velocity, notional bridge
acceleration, and total resistance were collected from irregular wave basin
tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5
conditions at Fr = 0.425, and organized into training, validation, and test
sets. The HDMDc algorithm constructs an equation-free linear reduced-order
model of the seakeeping vessel by augmenting states and inputs with their
time-lagged copies to capture nonlinear and memory effects. Two ensembling
strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters
considered stochastic variables with prior distribution to produce posterior
mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which
aggregates multiple model obtained over data subsets, are compared in providing
seakeeping prediction and uncertainty quantification. The FHDMDc approach is
found to improve the accuracy of the predictions compared to the deterministic
counterpart, also providing robust uncertainty estimation; whereas the
application of BHDMDc to the present test case is not found beneficial in
comparison to the deterministic model. FHDMDc-derived probability density
functions for the motions closely match both experimental data and URANS
results, demonstrating reliable and computationally efficient seakeeping
prediction for design and operational support.

</details>


### [72] [A Model-Based Approach to Automated Digital Twin Generation in Manufacturing](https://arxiv.org/abs/2511.03742)
*Angelos Alexopoulos,Agorakis Bompotas,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Athanasios P. Kalogeras,Christos Alexakos*

Main category: eess.SY

TL;DR: 本文提出了一种基于AutomationML工厂规划的数字孪生自动生成与部署平台，结合GAI驱动的仿真场景生成和物理产线自动重构，提升了制造系统的效率与适应性。


<details>
  <summary>Details</summary>
Motivation: 为了应对现代制造对高灵活性和可重构性的需求，传统模型驱动工程在产线设计后仍需大量仿真与验证工作，亟需更高效的闭环解决方案。

Method: 提出一个自动化数字孪生生成与部署平台，利用AutomationML描述工厂规划，并集成GAI驱动的仿真场景生成和自动物理产线重构功能，实现从设计到执行的闭环。

Result: 该平台能够实现数字孪生的快速生成与部署，支持实时监控、仿真与动态重构，显著提升制造系统的响应速度与适应能力。

Conclusion: 所提出的平台有效整合了模型驱动工程与数字孪生技术，通过GAI增强仿真与自动重构，为未来智能制造提供了高效、灵活的解决方案。

Abstract: Modern manufacturing demands high flexibility and reconfigurability to adapt
to dynamic production needs. Model-based Engineering (MBE) supports rapid
production line design, but final reconfiguration requires simulations and
validation. Digital Twins (DTs) streamline this process by enabling real-time
monitoring, simulation, and reconfiguration. This paper presents a novel
platform that automates DT generation and deployment using AutomationML-based
factory plans. The platform closes the loop with a GAI-powered simulation
scenario generator and automatic physical line reconfiguration, enhancing
efficiency and adaptability in manufacturing.

</details>


### [73] [Predictive Compensation in Finite-Horizon LQ Games under Gauss-Markov Deviations](https://arxiv.org/abs/2511.03744)
*Navid Mojahed,Mahdis Rabbani,Shima Nazari*

Main category: eess.SY

TL;DR: 提出了一种用于有限时域离散时间线性二次动态博弈的预测补偿框架，以应对反馈纳什策略中的高斯-马尔可夫偏差。


<details>
  <summary>Details</summary>
Motivation: 为了解决动态博弈中因策略偏差导致的性能下降问题，特别是在存在相关随机扰动的情况下。

Method: 建立了一个预测补偿策略，通过一阶自回归过程建模偏差，并推导出均值和协方差传播的闭式递推公式。

Result: 分析了预测策略对性能的影响，结果表明通过预期未来相关性可有效改善期望成本的敏感性。

Conclusion: 所提出的预测补偿框架能有效提升存在相关随机偏差时动态博弈的控制性能。

Abstract: This paper presents a predictive compensation framework for finite-horizon
discrete-time linear quadratic dynamic games in the presence of Gauss-Markov
deviations from feedback Nash strategies. One player experiences correlated
stochastic deviations, modeled via a first-order autoregressive process, while
the other compensates using a predictive strategy that anticipates the effect
of future correlation. Closed-form recursions for mean and covariance
propagation are derived, and the resulting performance improvement is analyzed
through the sensitivity of expected cost.

</details>


### [74] [Analytical modelling of a stop-less modular bus service with an application to charging strategies comparison](https://arxiv.org/abs/2511.03754)
*Haoran Zhao,Neema Nassir,Andres Fielbaum*

Main category: eess.SY

TL;DR: 本文提出了一种集成车对车充电技术的无站停靠自主模块化（SLAM）公交服务优化模型，通过比较不同充电策略下的运营设计，揭示了随客流增长的多个运营阶段，并指出移动充电策略在高需求下可能导致服务不可行。


<details>
  <summary>Details</summary>
Motivation: 传统公交服务存在停站时间长、效率低等问题，同时电动公交的普及带来充电运营约束，因此需要研究结合V2V充电技术的新型公交系统以提升效率和可持续性。

Method: 构建了解析优化模型，比较无充电、固定充电和车对车移动充电策略下的SLAM公交系统最优设计，分析不同客流水平下的运营阶段变化。

Result: 识别出随客流增长的五个运营阶段：低需求下的空闲容量、小型车满载、大型车满载、频次受限扩容阶段，以及移动充电下的能量受限阶段直至高需求时的系统不可行性。

Conclusion: SLAM公交系统在集成V2V充电技术后可在中低需求下提升效率，但移动充电策略在高客流时可能因能量限制导致服务不可行，建议运营商根据需求阶段调整策略。

Abstract: Buses are a vital component of metropolitan public transport, yet
conventional bus services often struggle with inefficiencies including extended
dwelling time, which increases in-vehicle travel time for non-alighting
passengers. A stop-less autonomous modular (SLAM) bus service has emerged as a
solution, enabling dynamic capacity to reduce dwelling time. Meanwhile, the
electrification of buses is advancing as a strategy to mitigate greenhouse gas
emissions and reduces operators' costs, but introduces new operational
constraints due to charging requirements. This study develops analytical
optimization models for SLAM bus service that integrates vehicle-to-vehicle
(V2V) charging technology. By comparing the optimal designs and their
feasibility across non-charging case and charging strategies, we identify a
sequence of operational stages as ridership grows: from idle capacity under low
demand, to full small buses, full large buses, and a proposed frequency-capped
regime where only bus capacity expands. Under the mobile charging strategy,
this progression further includes an energy-limited regime, in which frequency
declines, and ultimately infeasibility under high demand. These findings enable
operators to deliver more efficient services.

</details>


### [75] [Removing Time-Scale Separation in Feedback-Based Optimization via Estimators](https://arxiv.org/abs/2511.03903)
*Niloufar Yousefi,John W. Simpson-Porco*

Main category: eess.SY

TL;DR: 提出了一种基于估计器的反馈优化方法，利用动态系统模型信息消除传统反馈优化中的时间尺度分离要求，提升了闭环系统的收敛速度，并在基于逆变器资源的快速电力系统频率控制中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统反馈优化方法因需在远慢于系统动态的时间尺度上运行，限制了闭环性能，本文旨在通过引入估计器机制克服这一时间尺度分离的限制。

Method: 提出一种基于估计器的反馈优化框架，利用系统的动态模型信息来设计控制器，从而取消时间尺度分离要求；并扩展至仅具有近似模型且系统存在奇异摄动的情况。

Result: 所提方法使闭环系统的收敛速度仅受限于开环系统的主导特征值，显著提升了响应速度，并在电力系统频率控制应用中得到验证。

Conclusion: 该估计器增强的反馈优化方法有效突破了传统方法的性能瓶颈，能够在不依赖精确系统模型的情况下实现快速闭环响应，适用于如快速频率调节等高性能控制场景。

Abstract: Feedback-based optimization (FBO) provides a simple control framework for
regulating a stable dynamical system to the solution of a constrained
optimization problem in the presence of exogenous disturbances, and does so
without full knowledge of the plant dynamics. However, closed-loop stability
requires the controller to operate on a sufficiently slower timescale than the
plant, significantly constraining achievable closed-loop performance. Motivated
by this trade-off, we propose an estimator-based modification of FBO which
leverages dynamic plant model information to eliminate the time-scale
separation requirement of traditional FBO. Under this design, the convergence
rate of the closed-loop system is limited only by the dominant eigenvalue of
the open-loop system. We extend the approach to the case of design based on
only an approximate plant model when the original system is singularly
perturbed. The results are illustrated via an application to fast power system
frequency control using inverter-based resources.

</details>


### [76] [A Co-simulation Framework for Quadrotor Control System Design using ROS 2 and MATLAB/Simulink](https://arxiv.org/abs/2511.03969)
*Hangyu Teng*

Main category: eess.SY

TL;DR: 本文提出了一种集成ROS 2与MATLAB/Simulink的协同仿真框架，用于四旋翼无人机控制系统的快速原型设计与软件在环验证。


<details>
  <summary>Details</summary>
Motivation: 为提高复杂信息物理系统的设计效率并降低成本，需要一个高效、标准化的协同仿真平台。

Method: 基于牛顿-欧拉方程建立四旋翼六自由度非线性动力学模型；设计并实现分层控制架构，其中姿态控制采用LQR控制器，位置控制采用PID控制器；构建ROS 2与MATLAB/Simulink之间的跨平台数据交换机制。

Result: 仿真结果表明该框架能有效支持无人机控制算法的快速原型开发和软件在环验证，具备良好的实用性与标准化能力。

Conclusion: 所提出的协同仿真框架为无人机控制系统的设计与验证提供了一个高效、可靠的解决方案，具有较强的工程应用价值。

Abstract: Co-simulation is a critical approach for the design and analysis of complex
cyber-physical systems. It will enhance development efficiency and reduce
costs. This paper presents a co-simulation framework integrating ROS 2 and
MATLAB/Simulink for quadrotor unmanned aerial vehicle (UAV) control system
design and verification. First, a six-degree-of-freedom nonlinear dynamic model
of the quadrotor is derived accurately that based on Newton-Euler equations.
Second, within the proposed framework, a hierarchical control architecture was
designed and implemented: LQR controller for attitude control to achieve
optimal regulation performance, and PID controller for position control to
ensure robustness and practical applicability. Third, elaborated the
architecture of the framework, including the implementation details of the
cross-platform data exchange mechanism. Simulation results demonstrate the
effectiveness of the framework, highlighting its capability to provide an
efficient and standardized solution for rapid prototyping and
Software-in-the-Loop (SIL) validation of UAV control algorithms.

</details>


### [77] [Necessary and Sufficient Conditions for the Optimization-Based Concurrent Execution of Learned Robotic Tasks](https://arxiv.org/abs/2511.04054)
*Sheikh A. Tahmid,Gennaro Notomista*

Main category: eess.SY

TL;DR: 本文提出定理，给出了在子状态空间中使用最小范数控制器并发执行基于值函数的多个强化学习任务的充要条件，并扩展了优化框架以兼容带折扣因子的值函数。


<details>
  <summary>Details</summary>
Motivation: 解决先前工作中未回答的问题：何时可以并发执行通过强化学习学到的值函数任务。

Method: 基于优化的框架，结合最小范数控制器，推导并发执行多个值函数任务的必要和充分条件，并扩展框架以支持带折扣因子的值函数。

Result: 提出了可并发执行任务的理论条件，识别出任务是否本就可并发、能否被调整为可并发，或根本不可行；同时改进了框架对标准RL训练方式的兼容性。

Conclusion: 该理论为多任务值函数的并发执行提供了明确判据，增强了优化框架在实际强化学习应用中的适用性。

Abstract: In this work, we consider the problem of executing multiple tasks encoded by
value functions, each learned through Reinforcement Learning, using an
optimization-based framework. Prior works develop such a framework, but left
unanswered a fundamental question of when learned value functions can be
concurrently executed. The main contribution of this work is to present
theorems which provide necessary and sufficient conditions to concurrently
execute sets of learned tasks within subsets of the state space, using a
previously proposed min-norm controller. These theorems provide insight into
when learned control tasks are possible to be made concurrently executable,
when they might already inherently be concurrently executable and when it is
not possible at all to make a set of learned tasks concurrently executable
using the previously proposed methods. Additional contributions of this work
include extending the optimization-based framework to execute multiple tasks
encoded by value functions to also account for value functions trained with a
discount factor, making the overall framework more compatible with standard RL
practices.

</details>


### [78] [Differential Flatness of Quasi-Static Slider-Pusher Models with Applications in Control](https://arxiv.org/abs/2511.04246)
*Sander De Witte,Tom Lefebvre,Thomas Neve,Andras Retzler,Guillaume Crevecoeur*

Main category: eess.SY

TL;DR: 本文研究了平面滑块-推杆系统的动态特性，提出了一种基于极限面方法的微分运动学模型，并分析了系统的微分平坦性，发现具有多边形滑块和圆形推杆的系统以质心为平坦输出具有平坦性。基于此，提出了两种轨迹跟踪控制策略，并通过仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在操作任务中更好地理解和利用滑块-推杆系统的运动特性，研究其动态行为并建立适用于不同滑块形状的通用模型。

Method: 基于准静态假设和忽略接触摩擦的条件下，采用极限面方法构建微分运动学模型，并分析系统的微分平坦性；提出级联准静态反馈和动态反馈线性化两种控制策略。

Result: 发现多边形滑块与圆形推杆系统具有微分平坦性，质心可作为平坦输出；两种控制策略在含扰动和噪声的仿真及实际实验中均表现出良好轨迹跟踪性能。

Conclusion: 所提出的模型和控制方法有效且具有实际应用潜力，实验结果验证了仿真参数的适用性，展示了该方法在实际操作任务中的可行性。

Abstract: This paper investigates the dynamic properties of planar slider-pusher
systems as a motion primitive in manipulation tasks. To that end, we construct
a differential kinematic model deriving from the limit surface approach under
the quasi-static assumption and with negligible contact friction. The
quasi-static model applies to generic slider shapes and circular pusher
geometries, enabling a differential kinematic representation of the system.
From this model, we analyze differential flatness - a property advantageous for
control synthesis and planning - and find that slider-pusher systems with
polygon sliders and circular pushers exhibit flatness with the centre of mass
as a flat output. Leveraging this property, we propose two control strategies
for trajectory tracking: a cascaded quasi-static feedback strategy and a
dynamic feedback linearization approach. We validate these strategies through
closed-loop simulations incorporating perturbed models and input noise, as well
as experimental results using a physical setup with a finger-like pusher and
vision-based state detection. The real-world experiments confirm the
applicability of the simulation gains, highlighting the potential of the
proposed methods for

</details>


### [79] [ComEMS4Build: Comfort-Oriented Energy Management System for Residential Buildings using Hydrogen for Seasonal Storage](https://arxiv.org/abs/2511.04293)
*Jovana Kovačević,Felix Langner,Erfan Tajalli-Ardekani,Marvin Dorn,Simon Waczowicz,Ralf Mikut,Jörg Matthes,Hüseyin K. Çakmak,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: 本研究提出了一种面向住宅建筑的舒适导向能源管理系统（ComEMS4Build），结合光伏、电池和氢储能系统，并利用燃料电池与热泵的协同优化系统性能。系统采用模糊逻辑控制，在德国冬季12周的仿真中表现出接近模型预测控制（MPC）的舒适性和经济性，优于基于规则的控制（RBC），显著降低了用电成本并提升了混合储能系统的利用率。


<details>
  <summary>Details</summary>
Motivation: 为应对可再生能源发电的波动性，提升住宅部门对可再生能源的消纳能力，同时解决氢储能系统初期成本高的问题，研究探索将燃料电池与热泵耦合，并通过智能能源管理提升系统经济性与舒适性。

Method: 提出基于模糊逻辑的ComEMS4Build能源管理系统，集成光伏、电池和氢储能，并将燃料电池与热泵作为互补技术。采用半合成建模方法，在德国典型家庭住宅中进行为期12周冬季的仿真验证，对比规则控制（RBC）和模型预测控制（MPC）两种基准策略。

Result: ComEMS4Build在12周中有10周未违反热舒适性，表现接近MPC，优于RBC（后者中位不适感高0.68 Kh）；相比MPC每周电费增加12.06欧元，远低于RBC的30.14欧元增幅；相比RBC，提升了混合储能系统利用率和电网能量交互效率，但在燃料电池启停次数和运行时长上略逊于RBC。

Conclusion: 基于模糊逻辑的ComEMS4Build系统在保障居住舒适度的同时，显著降低了能源成本并提高了储能系统效率，是一种在经济性、舒适性和系统性能之间具有良好平衡的住宅能源管理方案，具备实际应用潜力。

Abstract: Integrating flexible loads and storage systems into the residential sector
contributes to the alignment of volatile renewable generation with demand.
Besides batteries serving as a short-term storage solution, residential
buildings can benefit from a Hydrogen (H2) storage system, allowing seasonal
shifting of renewable energy. However, as the initial costs of H2 systems are
high, coupling a Fuel Cell (FC) with a Heat Pump (HP) can contribute to the
size reduction of the H2 system. The present study develops a Comfort-Oriented
Energy Management System for Residential Buildings (ComEMS4Build) comprising
Photovoltaics (PV), Battery Energy Storage System (BESS), and H2 storage, where
FC and HP are envisioned as complementary technologies. The fuzzy-logic-based
ComEMS4Build is designed and evaluated over a period of 12 weeks in winter for
a family household building in Germany using a semi-synthetic modeling
approach. The Rule-Based Control (RBC), which serves as a lower benchmark, is a
scheduler designed to require minimal inputs for operation. The Model
Predictive Control (MPC) is intended as a cost-optimal benchmark with an ideal
forecast. The results show that ComEMS4Build, similar to MPC, does not violate
the thermal comfort of occupants in 10 out of 12 weeks, while RBC has a
slightly higher median discomfort of 0.68 Kh. The ComEMS4Build increases the
weekly electricity costs by 12.06 EUR compared to MPC, while RBC increases the
weekly costs by 30.14 EUR. The ComEMS4Build improves the Hybrid Energy Storage
System (HESS) utilization and energy exchange with the main grid compared to
the RBC. However, when it comes to the FC operation, the RBC has an advantage,
as it reduces the toggling counts by 3.48% and working hours by 7.59% compared
to MPC...

</details>


### [80] [Data-Driven Modeling of Photosynthesis Regulation Under Oscillating Light Condition - Part I: In-Silico Exploration](https://arxiv.org/abs/2511.04330)
*Christian Portilla,Arviandy G Aribowo,Ramachandran Anantharaman,César A Gómez-Pérez,Leyla Özkan*

Main category: eess.SY

TL;DR: 本文利用数据驱动的频域系统辨识方法，基于模拟数据建立光合作用调控的简化控制模型，通过BLA方法估计LTI模型，并构建以光强DC值为调度参数的LPV模型。


<details>
  <summary>Details</summary>
Motivation: 为了在波动光照条件下实现对光合作用的有效控制，需要建立简洁且面向控制的模型，而物理模型复杂度高，难以直接用于控制设计。

Method: 采用频域系统辨识方法，利用BDM模型生成的模拟数据，输入为包含直流和交流成分的光强信号，输出为叶绿素荧光信号；使用最佳线性逼近（BLA）方法估计不同工作条件下的二阶线性时不变（LTI）传递函数模型，并进一步构建线性参数变化（LPV）模型。

Result: 成功估计了多个局部LTI模型，并基于DC光强构建了紧凑的状态空间形式的LPV模型，能够有效表征系统在不同工作条件下的动态特性。

Conclusion: 所提出的方法能够从复杂物理模型生成的数据中提取简化的控制导向模型，为光合作用系统的动态分析与控制设计提供了有效工具。

Abstract: This paper explores the application of data-driven system identification
techniques in the frequency domain to obtain simplified, control-oriented
models of photosynthesis regulation under oscillating light conditions.
In-silico datasets are generated using simulations of the physics-based Basic
DREAM Model (BDM) Funete et al.[2024], with light intensity signals --
comprising DC (static) and AC (modulated) components as input and chlorophyll
fluorescence (ChlF) as output. Using these data, the Best Linear Approximation
(BLA) method is employed to estimate second-order linear time-invariant (LTI)
transfer function models across different operating conditions defined by DC
levels and modulation frequencies of light intensity. Building on these local
models, a Linear Parameter-Varying (LPV) representation is constructed, in
which the scheduling parameter is defined by the DC values of the light
intensity, providing a compact state-space representation of the system
dynamics.

</details>


### [81] [Overview and Performance Evaluation of Supervisory Controller Synthesis with Eclipse ESCET v4.0](https://arxiv.org/abs/2511.04370)
*Dennis Hendriks,Michel Reniers,Wan Fokkink,Wytse Oortwijn*

Main category: eess.SY

TL;DR: 本文介绍了CIF建模语言的符号化监督控制器综合算法、基准模型集、ESCET工具在v0.8到v4.0版本间的合成性能改进，并评估了多级综合方法的性能增益。


<details>
  <summary>Details</summary>
Motivation: 为了提升监督控制器设计的自动化水平，解决实际应用中常被忽略的问题（如运行时错误预防、多类型需求处理和外部输入支持），并评估现有工具的综合性能。

Method: 采用基于模型的工程与计算机辅助设计相结合的合成化工程（SBE）方法，通过CIF语言实现符号化综合算法，并构建包含23个工业与学术模型的基准集进行性能评估，同时分析多级综合方法的效果。

Result: 描述了CIF的综合算法关键实践细节，发布了23个公开基准模型，评估了ESCET v0.8至v4.0的性能提升，验证了多级综合对性能的改进作用，但复杂模型的综合仍需进一步优化。

Conclusion: CIF和ESCET有效支持了监督控制器的自动化综合，性能持续提升，但面对复杂系统仍需进一步研究以提高综合效率。

Abstract: Supervisory controllers control cyber-physical systems to ensure their
correct and safe operation. Synthesis-based engineering (SBE) is an approach to
largely automate their design and implementation. SBE combines model-based
engineering with computer-aided design, allowing engineers to focus on 'what'
the system should do (the requirements) rather than 'how' it should do it
(design and implementation). In the Eclipse Supervisory Control Engineering
Toolkit (ESCET) open-source project, a community of users, researchers, and
tool vendors jointly develop a toolkit to support the entire SBE process,
particularly through the CIF modeling language and tools. In this paper, we
first provide a description of CIF's symbolic supervisory controller synthesis
algorithm, and thereby include aspects that are often omitted in the
literature, but are of great practical relevance, such as the prevention of
runtime errors, handling different types of requirements, and supporting input
variables (to connect to external inputs). Secondly, we introduce and describe
CIF's benchmark models, a collection of 23 freely available industrial and
academic models of various sizes and complexities. Thirdly, we describe recent
improvements between ESCET versions v0.8 (December 2022) and v4.0 (June 2024)
that affect synthesis performance, evaluate them on our benchmark models, and
show the current practical synthesis performance of CIF. Fourthly, we briefly
look at multi-level synthesis, a non-monolithic synthesis approach, evaluate
its gains, and show that while it can help to further improve synthesis
performance, further performance improvements are still needed to synthesize
complex models.

</details>


### [82] [Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear System with Input Delay](https://arxiv.org/abs/2511.04451)
*Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo*

Main category: eess.SY

TL;DR: 提出一种基于LSTM增强的深度Koopman模型，用于近似具有输入延迟的非线性系统的Koopman算子，相比传统方法在未知动态情况下显著提升预测精度。


<details>
  <summary>Details</summary>
Motivation: 非线性时滞系统在预测、估计和控制中面临挑战，传统线性方法效果有限，且现有Koopman方法依赖预定义字典，难以应对未知动态。

Method: 引入LSTM增强的深度Koopman模型，利用LSTM捕捉历史依赖关系，将时滞系统动态编码至潜空间，实现无需预定义字典的线性化表示。

Result: 在模拟系统上与扩展eDMD对比，新模型在真实非线性动态未知时显著提高预测精度，并在已知动态下表现相当。

Conclusion: 该方法为处理未知非线性时滞系统提供了一种高效、无需先验知识的建模范式，具有较强的实用潜力。

Abstract: Nonlinear dynamical systems with input delays pose significant challenges for
prediction, estimation, and control due to their inherent complexity and the
impact of delays on system behavior. Traditional linear control techniques
often fail in these contexts, necessitating innovative approaches. This paper
introduces a novel approach to approximate the Koopman operator using an
LSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear
systems with time delays. By incorporating Long Short-Term Memory (LSTM)
layers, the proposed framework captures historical dependencies and efficiently
encodes time-delayed system dynamics into a latent space. Unlike traditional
extended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined
dictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which
mitigates the problems with the underlying dynamics being known and
incorporated into the dictionary. Quantitative comparisons with extended eDMD
on a simulated system demonstrate highly significant performance gains in
prediction accuracy in cases where the true nonlinear dynamics are unknown and
achieve comparable results to eDMD with known dynamics of a system.

</details>


### [83] [Synchronous Observer Design for Landmark-Inertial SLAM with Almost-Global Convergence](https://arxiv.org/abs/2511.04531)
*Arkadeep Saha,Pieter van Goor,Antonio Franchi,Ravi Banavar*

Main category: eess.SY

TL;DR: 本文提出了一种连续时间下的非线性观测器用于Landmark Inertial SLAM问题，并在基空间中分析其可观测状态，证明了误差动态的局部指数稳定性和几乎全局渐近稳定性，并通过仿真验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决LI-SLAM中状态估计的稳定性和可观测性问题，提出一种在连续时间下具有良好稳定性保证的非线性观测器。

Method: 在连续时间框架下构建非线性观测器，并将其分析置于包含所有可观测状态的基空间中，通过理论证明和仿真验证其性能。

Result: 证明了所提观测器在基空间中的误差动态具有局部指数稳定性和几乎全局渐近稳定性，并通过仿真验证了理论结果的有效性。

Conclusion: 所提出的非线性观测器在理论和仿真中均表现出良好的稳定性，适用于LI-SLAM中的位姿与地标估计。

Abstract: Landmark Inertial Simultaneous Localisation and Mapping (LI-SLAM) is the
problem of estimating the locations of landmarks in the environment and the
robot's pose relative to those landmarks using landmark position measurements
and measurements from Inertial Measurement Unit (IMU). This paper proposes a
nonlinear observer for LI-SLAM posed in continuous time and analyses the
observer in a base space that encodes all the observable states of LI-SLAM. The
local exponential stability and almost-global asymptotic stability of the error
dynamics in base space is established in the proof section and validated using
simulations.

</details>


### [84] [Control Affine Hybrid Power Plant Subsystem Modeling for Supervisory Control Design](https://arxiv.org/abs/2511.04644)
*Stephen Ampleman,Himanshu Sharma,Sayak Mukherjee,Sonja Glavaski*

Main category: eess.SY

TL;DR: 本文提出了一种用于风能、太阳能和电池储能混合发电厂的建模与控制设计框架，采用非线性控制与控制屏障函数技术实现安全稳定的功率跟踪。


<details>
  <summary>Details</summary>
Motivation: 为了提高混合发电厂对电网需求的响应能力，并解决可再生能源出力不确定性问题，需要建立统一且适用于控制设计的模型框架。

Method: 将风力发电场、太阳能电站和电池储能的现有模型转化为适合上级控制设计的控制仿射形式，并利用非线性控制和控制屏障函数技术设计发电机转矩与电池单元电流的控制律。

Result: 通过使用实际负荷需求信号、时变风速和辐照度数据的测试案例，验证了该框架在规则基础上级控制下的有效性和实用性。

Conclusion: 所提出的建模与控制框架能够有效支持混合发电厂的安全、稳定运行，并实现对电网需求的良好跟踪性能。

Abstract: Hybrid power plants (HPPs) combine multiple power generators
(conventional/variable) and energy storage capabilities to support generation
inadequacy and grid demands. This paper introduces a modeling and control
design framework for hybrid power plants (HPPs) consisting of a wind farm,
solar plant, and battery storage. Specifically, this work adapts established
modeling paradigms for wind farms, solar plants and battery models into a
control affine form suitable for control design at the supervisory level. In
the case of wind and battery models, generator torque and cell current control
laws are developed using nonlinear control and control barrier function
techniques to track a command from a supervisory control law while maintaining
safe and stable operation. The utility of this modeling and control framework
is illustrated through a test case using a utility demand signal for tracking,
time varying wind and irradiance data, and a rule-based supervisory control
law.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [85] [Fermionic spinon theory of the hourglass spin excitation spectrum of the cuprates](https://arxiv.org/abs/2511.03792)
*Alexander Nikolaenko,Pietro M. Bonetti,Subir Sachdev*

Main category: cond-mat.str-el

TL;DR: 本文提出了一种关于空穴掺杂铜酸盐在周期为4的单向电荷密度波（“条纹”）有序基态下的自旋涨落谱理论。基于最近实验支持中间温度下赝能隙金属的分数化费米液体（FL*）描述，作者采用了一种费米型自旋子理论，并指出在低温下条纹序出现时自旋子被禁闭。该理论成功再现了中子散射实验中在条纹序波矢附近观察到的“沙漏”谱结构，同时预测在更高能量和布里渊区其他位置存在来自自旋子连续谱和束缚态的额外散射信号，可通过中子或X射线散射观测。


<details>
  <summary>Details</summary>
Motivation: 基于实验上对中间温度赝能隙金属中分数化费米液体（FL*）行为的证据，试图构建一个能解释空穴掺杂铜酸盐中自旋涨落和条纹序关系的微观理论。

Method: 采用费米型自旋子理论，考虑在条纹序形成时自旋子被禁闭的物理图像，计算自旋涨落谱。

Result: 理论成功再现了中子散射中观察到的‘沙漏’形自旋涨落谱，并预测了高能区和布里渊区其他区域存在来自自旋子连续态和束缚态的额外散射特征。

Conclusion: 该理论为理解空穴掺杂铜酸盐中条纹序与自旋动力学之间的关系提供了新的框架，支持FL*描述在赝能隙态中的适用性，并提出了可实验验证的高能激发特征。

Abstract: We present a theory for the spin fluctuation spectrum of the hole-doped
cuprates in a ground state with period 4 unidirectional charge density wave
(`stripe') order. Motivated by recent experimental evidence for a
fractionalized Fermi liquid (FL*) description of the intermediate temperature
pseudogap metal, we employ a theory of fermionic spinons which are confined
with the onset of stripe order at low temperatures. The theory produces the
`hourglass' spectrum near stripe-ordering wavevector observed by neutron
scattering. Additional scattering from spinon continua and bound states appears
at higher energies and elsewhere in the Brillouin zone, and could be observed
by neutron or X-ray scattering.

</details>


### [86] [Competitive Orders in Altermagnetic Chiral Magnons](https://arxiv.org/abs/2511.03922)
*Congzhe Yan,Jinyang Ni*

Main category: cond-mat.str-el

TL;DR: 本研究揭示了在有限温度下，长程各向异性自旋交换（ASE）与交替的各向同性自旋交换（ISE）之间存在竞争，导致反铁磁体中磁振子手性分裂的显著温度依赖性调制，并发现该竞争可逆转由能带分裂驱动的自旋流。


<details>
  <summary>Details</summary>
Motivation: 理解反铁磁体中磁振子在有限温度下的动态行为，特别是在缺乏自旋轨道耦合和外磁场的情况下手性分裂的物理机制。

Method: 通过引入磁振子-磁振子相互作用，理论分析长程各向异性自旋交换（ASE）对磁振子手性分裂的影响，并探讨其与交替各向同性自旋交换（ISE）的竞争效应。

Result: 发现ASE可在有限温度下诱导磁振子手性分裂，且ASE与ISE的竞争导致手性分裂随温度显著变化；该竞争与自旋涨落密切相关，并可在温度升高时逆转自旋流方向。

Conclusion: 反铁磁体中的集体自旋激发受ISE与ASE内在竞争的支配，这项工作为理解其有限温度下的动力学行为提供了新视角。

Abstract: In altermagnets, magnons-the quanta of collective spin excitations-exhibit
chiral splitting even in the absence of spin-orbit coupling and external
magnetic fields. Typically, this chiral splitting behavior can be well
described by alternating isotropic spin exchanges (ISE) in the low-temperature
regime; however, its dynamic behavior at a finite temperature remains unclear.
In this study, we reveal that, when including magnon-magnon interactions, long
range anisotropic spin exchange (ASE) can also induce chiral splitting of
magnons at a finite temperature. Crucially, the chiral splitting induced by ASE
competes with that arising from ISE, leading to a pronounced temperature
dependent modulation of the altermagnetic chiral splitting. Moreover, this
competition is intimately connected to spin fluctuations, and can reverse the
spin current driven by the band splitting as temperature increases. Our work
uncovers the intrinsic competition governing collective spin excitations in
altermagnets, providing new insights into their finite-temperature dynamical
behavior.

</details>


### [87] [Experimental confirmation of the magnetic ordering transition induced by an electronic structure change in the metallic triangular antiferromagnet Co$_{1/3}$TaS$_2$](https://arxiv.org/abs/2511.03999)
*Han-Jin Noh,En-Jin Cho,Byeong-Gyu Park,Hyowon Park,Ivar Martin,Cristian D. Batista,Pyeongjae Park,Woonghee Cho,Je-Guen Park*

Main category: cond-mat.str-el

TL;DR: 通过ARPES实验和DFT+DMFT计算，研究发现Co$_{1/3\pm\epsilon}$TaS$_2$中磁有序波矢从(1/2,0,0)到(1/3,0,0)的转变是由体系电子结构变化引起的，且与Co 3d和Ta 5d轨道间的嵌套向量及关联效应密切相关。


<details>
  <summary>Details</summary>
Motivation: 探究Co$_x$TaS$_2$体系中在x≈1/3附近磁有序波矢转变的微观机制，明确电子结构变化在其中的作用。

Method: 结合角分辨光电子能谱（ARPES）测量和DFT+DMFT理论计算，分析不同Co掺杂浓度下的费米面结构和磁化率响应。

Result: 在Co$_{0.325}$TaS$_2$中观察到符合三Q态的费米面结构；在Co$_{0.340}$TaS$_2$中出现新的电子口袋，费米面几何发生变化；DFT+DMFT计算表明磁有序最稳定波矢由(1/2,0,0)变为(1/3,0,0)，与实验观测一致。

Conclusion: Co$_{1/3\pm\epsilon}$TaS$_2$中磁有序波矢的转变源于电子结构的变化，特别是Co 3d与Ta 5d轨道间的嵌套效应以及Co$_4$S$_{18}$三脚架结构引起的关联效应。

Abstract: We report ARPES studies combined with DFT+DMFT calculations to confirm that
the magnetic ordering vector transition from \textbf{Q}=(1/2,0,0) to
\textbf{Q}=(1/3,0,0) in the metallic triangular antiferromagnets
Co$_{1/3\pm\epsilon}$TaS$_2$ ($\epsilon\approx$0.007) is induced by the
electronic structure change in the system. The ARPES-measured Fermi surface
(FS) maps of Co$_{0.325}$TaS$_2$ show two hexagonal and one circular hole-like
FSs around $\Gamma$, which matches well with the triple-\textbf{Q} state by
taking into account the contribution of nesting vectors occurring between Co
3$d$ and Ta 5$d$ orbitals. In the case of Co$_{0.340}$TaS$_2$, a new electron
pocket around K appears and the FS geometry changes as a result of the
correlation effect of Co$_4$S$_{18}$ tripods forming in the system. The
magnetic susceptibility calculations based on the DFT+DMFT band structure
indicate that the most stable magnetic ordering vector changes to (1/3,0,0)
from (1/2,0,0), which is very consistent with the magnetic phase transition
around $x$=1/3 in Co$_{x}$TaS$_2$.

</details>


### [88] [Phase diagrams of S=1/2 bilayer Models of SU(2) symmetric antiferromagnets](https://arxiv.org/abs/2511.04101)
*Fan Zhang,Nisheeta Desai,Wenan Guo,Ribhu K. Kaul*

Main category: cond-mat.str-el

TL;DR: 研究了S=1/2双层方格反铁磁模型在T=0时的相图，考虑了具有不同内部对称性的两类双层模型，揭示了丰富的相变行为，包括Néel、价键固体和二聚体相，并发现Néel与VBS之间的相变为一级相变。


<details>
  <summary>Details</summary>
Motivation: 探索具有多种自旋交换的双层量子磁体在零温下的相图结构，比较不同耦合机制（自旋-自旋与能量-能量）对相变行为的影响。

Method: 通过理论分析两类具有SU(2)海森堡对称性的双层模型：一类允许层间自旋和能量交换，另一类仅允许能量交换；研究其相图拓扑及相变性质。

Result: 发现传统双层模型中存在Néel、价键固体和简单二聚体相，以及一阶和连续相变，符合朗道序参量理论；而在仅能量耦合的模型中，无法形成简单二聚态，且Néel到VBS的相变均为一级，但有限尺寸标度行为显著不同，VBS到二聚体的转变偏离XY模型预期。

Conclusion: 两类模型虽均显示一级Néel-VBS相变，但其标度行为和相图结构差异显著，表明耦合类型对量子相变特性有重要影响。

Abstract: We study the $T=0$ phase diagrams of models of bilayers of $S=1/2$ square
lattices antiferromagnets with SU(2) Heisenberg symmetry that have 2, 4, and 6
spin exchanges. We study two families of bilayer models with distinct internal
symmetries and, hence, different phase diagram topologies. A traditional
bilayer model in which the interlayer interaction is Heisenberg so that the two
layers can exchange spin (and energy) with each other, making it possible to
achieve a simple dimerized valence bond liquid-like state. The resulting phase
diagram is rich with N\'eel, valence bond solid and simple dimer phases, and
both first-order and continuous transitions, which we demonstrate are
consistent with the conventional Landau theory of order parameters. In the
second family of models in which the layers can exchange only energy but no
spin (reminiscent of the Ashkin-Teller coupling), the simple dimer state cannot
occur. The phase diagrams reveal a number of phase transitions that are
accessed for the first time. We find that the phase transition between N\'eel
and VBS is first order in both the spin-spin and energy-energy coupled models,
although they have strikingly distinct finite-size scaling behavior and that
the transition from VBS to dimer in the spin-spin coupling model deviates from
the expected scenario of an XY model with dangerously irrelevant four-fold
anisotropy.

</details>


### [89] [Dynamical spin susceptibility of $d$-wave Hatsugai-Kohmoto altermagnet](https://arxiv.org/abs/2511.04141)
*Ádám Bácsi,Balázs Dóra*

Main category: cond-mat.str-el

TL;DR: 研究了在$d_{x^2-y^2}$ altermagnetic Hatsugai-Kohmoto模型中，随着相互作用增强发生多体Lifshitz转变，费米面双占据区域消失，动量态完全自旋极化；动态自旋 susceptibility出现与相互作用强度成正比的能隙，并在频率增加时出现尖锐峰，该峰在Lifshitz转变后移至能隙低端并呈对数发散，信号强度在转变前随相互作用增强而后饱和，静态 susceptibility不受关联影响，altermagnetism抑制静态横向响应。


<details>
  <summary>Details</summary>
Motivation: 探索altermagnetic能带结构与电子关联之间的相互作用机制，特别是在强关联条件下新型磁性态的形成及其对自旋响应的影响。

Method: 基于$d_{x^2-y^2}$ altermagnetic推广的Hatsugai-Kohmoto模型，采用Kubo公式直接计算多体占据概率下的自旋磁化率，并分析动态和静态自旋响应函数的行为。

Result: 发现随相互作用增强发生多体Lifshitz转变，导致费米面完全自旋极化；动态自旋 susceptibility出现交互作用依赖的能隙和频率相关的尖峰，且在转变后呈现对数发散；信号强度在转变点前增强后饱和，静态 susceptibility不受电子关联影响，但altermagnetism抑制横向静态响应。

Conclusion: altermagnetism与强电子关联共同驱动非平凡的多体相变和独特的自旋动力学行为，揭示了新型磁性材料中自旋响应的调控机制。

Abstract: We investigate the interplay between altermagnetic band structures and
electronic correlations by focusing on the $d_{x^2-y^2}$ altermagnetic
generalization of the Hatsugai-Kohmoto model. We find that with increasing
interaction, a many-body Lifshitz transition takes place when doubly occupied
regions disappear from the Fermi surface and each momentum state becomes fully
spin polarized. The spin susceptibility is directly evaluated from the Kubo
formula in terms of many-body occupation probabilities. We find that the
dynamical susceptibility, which possesses only transverse non-zero components
for small wavevectors, develops a gap proportional to the interaction strength,
and displays a sharp peak at a frequency increasing with the interaction. %with
increasing frequency. Above the Lifshitz transition, this peak moves to the
lower gap edge and becomes log-divergent. The signal intensity increases with
the interaction up until the Lifshitz transition and saturates afterwards. The
static susceptibility remains unaffected by the correlations and altermagnetism
reduces the static transverse response.

</details>


### [90] [Spin responses of a disordered helical superconducting edge under Zeeman field](https://arxiv.org/abs/2511.04263)
*Zeinab Bakhshipour,Mir Vahid Hosseini*

Main category: cond-mat.str-el

TL;DR: 研究了无序、塞曼场和超导对二维拓扑绝缘体螺旋边缘态的影响，发现塞曼场调控相互作用竞争，无序抑制横向密度波但增强超导配对，影响自旋电导的标度行为。


<details>
  <summary>Details</summary>
Motivation: 探索无序在存在塞曼场和超导条件下对拓扑绝缘体边缘态的影响机制。

Method: 采用玻色化方法和重正化群分析，研究杂质势对电荷、自旋密度波及超导配对关联的影响。

Result: 塞曼场在吸引区增强超导能隙，在排斥区稳定无序效应；无序抑制横向密度波关联，但通过正对数修正增强超导配对关联。

Conclusion: 无序与超导的相互作用显著改变螺旋边缘态的自旋电导标度行为，提供了可实验观测的物理特征。

Abstract: We investigate analytically and numerically the effects of disorder on the
helical edge of the 2D topological insulator in the presence of the Zeeman
field and superconductivity. Employing bosonization and a renormalization-group
analysis, we study how impurity potentials modify charge- and spin-density wave
correlations as well as superconducting pair correlations. Our results reveal
that the Zeeman field controls the competition: in the attractive regime, it
amplifies the superconducting gap, while in the repulsive regime, it stabilizes
impurity effects by keeping the system longer in the relevant regime for
disorder. We also find that disorder induces logarithmic suppression of
transverse density-wave correlations, while at the same time introducing
positive logarithmic corrections that enhance superconducting pair correlations
and contribute to their stability. These effects directly modify the scaling of
spin conductance, providing experimentally accessible signatures of the
interplay between disorder and superconductivity in topological edge channels.

</details>


### [91] [T-square electric resistivity and its thermal counterpart in RuO$_2$](https://arxiv.org/abs/2511.04278)
*Yu Ling,Florent Pawula,Ramzy Daou,Benoît Fauqué,Kamran Behnia*

Main category: cond-mat.str-el

TL;DR: 本研究发现RuO₂在低温下表现出二次温度依赖的电阻率，符合Kadowaki-Woods标度关系，并通过热导率测量验证了电子组分遵循Wiedemann-Franz定律，表明RuO₂为弱关联费米液体。


<details>
  <summary>Details</summary>
Motivation: 探究RuO₂中电子-电子散射行为及其在低温下的电热输运特性，为理解金属氧化物中的强关联效应提供实验依据。

Method: 通过精确测量低温下的电电阻率和热导率（零场与12 T磁场），分离电子和声子对输运的贡献，并分析其温度依赖性。

Result: 发现低于~20 K时电阻率呈T²依赖，其系数符合Kadowaki-Woods标度；观察到T⁵声子散射贡献；电子热导率在零温下满足Wiedemann-Franz定律，但在有限温度下出现向下偏离，两种T²电阻率前因子存在三倍差异。

Conclusion: RuO₂是一种弱关联费米液体，电子-电子散射主导低温输运，研究结果为从头计算金属氧化物中电子散射提供了新的实验基准。

Abstract: We present a study of low-temperature electric and thermal transport in
RuO$_2$, a metallic oxide which has attracted much recent attention. Careful
scrutiny of electric resistivity reveals a quadratic temperature dependence
below $\sim$ 20 K undetected in previous studies of electronic transport in
this material. The prefactor of this T$^2$ resistivity, given the electronic
specific heat, corresponds to what is expected by the Kadowaki-Woods scaling.
The variation of its amplitude across 4 different samples is negligible despite
an eightfold variation of residual resistivity. There is also a T$^5$
resistivity due to scattering by phonons. By measuring thermal conductivity,
$\kappa$, at zero field and at 12 T, we separated its electronic and the
phononic components and found that the electronic component respects the
Wiedemann-Franz law at zero temperature and deviates downward at finite
temperature. The latter corresponds to a threefold discrepancy between the
prefactors of the two (thermal and electric) T-square resistivities. Our
results, establishing RuO$_2$ as a weakly correlated Fermi liquid, provide new
input for the ongoing theoretical attempt to give a quantitative account of
electron-electron scattering in metallic oxides starting from first principles.

</details>


### [92] [Symmetry-enriched topological order and quasi-fractonic behavior in $\mathbb{Z}_N$ stabilizer codes](https://arxiv.org/abs/2511.04430)
*Siyu He,Hao Song*

Main category: cond-mat.str-el

TL;DR: 本文研究了一类称为Z_N双变量自行车码的广义量子稳定子码，发现其拓扑性质可由N的素因子对应的Z_p码决定，从而简化了高维量子码的分析，并推广了几何代数方法以确定任意子融合规则，同时揭示了其对称性增强拓扑序中的准分形行为。


<details>
  <summary>Details</summary>
Motivation: 为了理解广义量子稳定子码（尤其是高维情形）的拓扑性质，并解决其中任意子迁移性的问题，作者引入并研究Z_N双变量自行车码。

Method: 基于多项式表示方法，将Z_N码分解为其素因子p对应的Z_p码进行分析，并利用格罗布纳基在整数环上的计算代数方法研究拓扑序及其对称性增强性质。

Result: 发现Z_N码的拓扑性质由其素因子对应的Z_p码决定；成功推广代数几何方法（如BKK定理）到一般情形；揭示了模型具有准分形行为的对称性增强拓扑序；提供了高效计算拓扑序的代数方法。

Conclusion: Z_N双变量自行车码的拓扑结构可通过素因子分解简化为素数维情形分析，这为高维稳定子码的研究提供了统一而高效的框架，并深化了对其中任意子行为和对称性作用的理解。

Abstract: We study a broad class of qudit stabilizer codes, termed $\mathbb{Z}_N$
bivariate-bicycle (BB) codes, arising either as two-dimensional realizations of
modulated gauge theories or as $\mathbb{Z}_N$ generalizations of binary BB
codes. Our central finding, derived from the polynomial representation, is that
the essential topological properties of these $\mathbb{Z}_N$ codes can be
determined by the properties of their $\mathbb{Z}_p$ counterparts, where $p$
are the prime factors of $N$, even when $N$ contains prime powers ($N = \prod_i
p_i^{k_i}$). This result yields a significant simplification by leveraging the
well-studied framework of codes with prime qudit dimensions. In particular,
this insight directly enables the generalization of the algebraic-geometric
methods (e.g., the Bernstein-Khovanskii-Kushnirenko theorem) to determine anyon
fusion rules in the general qudit situation. Moreover, we analyze the model's
symmetry-enriched topological order (SET) to reveal a quasi-fractonic behavior,
resolving the anyon mobility puzzle in this class of models. We also present a
computational algebraic method using Gr\"{o}bner bases over the ring of
integers to efficiently calculate the topological order and its SET properties.

</details>


### [93] [Correlated electronic structure and local spin in lead-copper-vanadium-bromine apatite: a DMFT study](https://arxiv.org/abs/2511.04475)
*Ihor Sukhenko,Volodymyr Karbivskyy*

Main category: cond-mat.str-el

TL;DR: 本研究通过DFT+DMFT方法研究了铜取代的铅钒溴磷灰石Pb₉Cu(VO₄)₆Br₂的电子结构与局域自旋行为，发现其在化学计量比附近保持金属性，而在轻微空穴掺杂侧存在增强的自旋涨落，表现出类似多轨道Hund金属的自旋冻结交叉行为，表明该材料在铜取代磷灰石家族中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 探索铜取代磷灰石材料中的强关联电子行为和局域自旋动力学，理解其在低温下的非费米液体行为和可能的量子临界现象。

Method: 采用DFT+DMFT结合双轨道铜中心低能模型，对不同温度（20、60、100 K）和载流子填充范围（2.46 ≤ n ≤ 3.54）进行模拟，分析自能指数和局域自旋磁化率的动力学特性。

Result: 材料在化学计量比（n≈3）附近保持金属性；偏离该填充时，空穴和电子掺杂均导致非费米液体行为；在轻微空穴掺杂（n≈2.94）时出现显著的自旋涨落增强，呈现自旋冻结交叉特征。

Conclusion: Pb₉Cu(VO₄)₆Br₂是铜取代磷灰石家族中具有强关联特性和潜在量子临界行为的候选材料，尤其在轻微空穴掺杂下表现出类似Hund金属的自旋自由度冻结现象。

Abstract: We study the correlated electronic structure and local spin behaviour of the
copper-substituted lead-vanadium bromine apatite Pb$_9$Cu(VO$_4$)$_6$Br$_2$
using DFT+DMFT with a two-orbital Cu-centred low-energy model. Simulations are
done for several temperatures (20, 60, 100 K) and a broad range of band
fillings 2.46 $\leq$ n $\leq$ 3.54. We find that the present compound stays
metallic even once correlations are treated dynamically around the
stoichiometric filling (n $\simeq$ 3). Away from n $\simeq$ 3, both hole and
electron doping drive the system toward non-Fermi-liquid behaviour, and
spectral weight is transferred from the low-energy peak into upper and lower
Hubbard-like features. By analysing the low-frequency self-energy exponent and
the dynamical part of the local spin susceptibility, we identify a narrow
window of enhanced spin fluctuations on the slightly hole-doped side (n
$\simeq$ 2.94), i.e. a spin-freezing-crossover regime of the kind reported in
the literature for multiorbital Hund metals. This places
Pb$_9$Cu(VO$_4$)$_6$Br$_2$ among the promising members of the Cu-substituted
apatite family.

</details>


### [94] [High-Temperature Quantum Anomalous Hall Effect in Buckled Honeycomb Antiferromagnets](https://arxiv.org/abs/2511.04551)
*Mohsen Hafez-Torbati,Götz S. Uhrig*

Main category: cond-mat.str-el

TL;DR: 提出具有扭曲蜂窝结构的Néel反铁磁莫特绝缘体作为高温反铁磁陈绝缘体的候选材料，通过外加电场诱导实现拓扑相变，并预测该相可在室温下稳定存在。


<details>
  <summary>Details</summary>
Motivation: 寻找能在高温下实现量子反常霍尔效应的新型拓扑材料，突破传统铁磁陈绝缘体的温度限制。

Method: 基于广义Kondo晶格模型，研究垂直电场诱导的交错势对反铁磁莫特绝缘体拓扑性质的影响，并分析霍尔电导与手性边缘态的温度演化行为。

Result: 发现霍尔电导的量子化温度主要取决于自旋轨道耦合强度和跃迁参数；高于该温度时，手性边缘态出现谱展宽，表明其寿命有限；采用重过渡金属元素参数时，反铁磁陈绝缘体可稳定至室温。

Conclusion: Sr₃CaOs₂O₉等具有扭曲蜂窝结构的反铁磁莫特绝缘体是实现高温乃至室温反铁磁陈绝缘体的理想候选材料。

Abstract: We propose N\'eel antiferromagnetic (AF) Mott insulators with a buckled
honeycomb structure as potential candidates to host a high-temperature AF Chern
insulator (AFCI). Using a generalized Kondo lattice model we show that the
staggered potential induced by a perpendicular electric field due to the
buckling can drive the AF Mott insulator to an AFCI phase. We address the
temperature evolution of the Hall conductance and the chiral edge states. The
quantization temperature $T_q$, below which the Hall conductance is quantized,
depends essentially on the strength of the spin-orbit coupling and the hopping
parameter, independent of the specific details of the model. The deviation of
the Hall conductance from the quantized value $e^2/h$ above $T_q$ is found to
be accompanied by a spectral broadening of the chiral edge states, reflecting a
finite life-time, i.e., a decay. Using parameters typical for heavy
transition-metal elements we predict that the AFCI can survive up to room
temperature. We suggest Sr$_3$CaOs$_2$O$_9$ as a potential compound to realize
a high-$T$ AFCI phase.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [95] [Experimental Observation of Hidden Multistability in Nonlinear Systems](https://arxiv.org/abs/2511.04150)
*Kun Zhang,Qicheng Zhang,Shuaishuai Tong,Wenquan Wu,Xiling Feng,Chunyin Qiu*

Main category: nlin.CD

TL;DR: 首次实验观测到声学耦合腔系统中的隐藏多稳态，通过脉冲激发揭示并控制隐藏稳定态。


<details>
  <summary>Details</summary>
Motivation: 研究非线性动力学系统中难以探测的隐藏多稳态现象，拓展其在信息存储与加密等领域的应用潜力。

Method: 利用可编程声学耦合腔平台，集成自聚焦和自散焦克尔非线性，通过精确调控系统参数和脉冲激发实现对隐藏稳定态的探测与控制。

Result: 实验上实现了半隐藏和全隐藏的三稳态，并成功通过脉冲激励揭示了传统方法无法探测到的隐藏稳定态。

Conclusion: 该工作为理解隐藏多稳态的基本物理机制提供了新视角，并为多态动力学在信息技术和安全防护中的应用开辟了新途径。

Abstract: Multistability, the coexistence of multiple stable states, is a cornerstone
of nonlinear dynamical systems, governing their equilibrium, tunability, and
emergent complexity. Recently, the concept of hidden multistability, where
certain stable states evade detection via conventional continuous parameter
sweeping, has garnered increasing attention due to its elusive nature and
promising applications. In this Letter, we present the first experimental
observation of hidden multistability using a programmable acoustic
coupled-cavity platform that integrates competing self-focusing and
self-defocusing Kerr nonlinearities. Beyond established bistability, we
demonstrate semi- and fully-hidden tristabilities by precisely programming
system parameters. Crucially, the hidden stable states, typically inaccessible
via the traditional protocol, are unambiguously revealed and dynamically
controlled through pulsed excitation, enabling flexible transitions between
distinct types of stable states. These experimental findings not only offer new
insights into the fundamental physics of emerging hidden multistability, but
also unlock new avenues for applications in information storage, information
encryption, and safety precaution, where multi-state dynamics could enable
advanced control techniques.

</details>
