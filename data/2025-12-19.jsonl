{"id": "2512.16716", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.16716", "abs": "https://arxiv.org/abs/2512.16716", "authors": ["Sanjeeb Poudel", "Sanghyun Lee", "Lin Mu"], "title": "Pressure-robust enriched Galerkin finite element methods for coupled Navier-Stokes and heat equations", "comment": null, "summary": "We propose a pressure-robust enriched Galerkin (EG) finite element method for the incompressible Navier-Stokes and heat equations in the Boussinesq regime. For the Navier-Stokes equations, the EG formulation combines continuous Lagrange elements with a discontinuous enrichment vector per element in the velocity space and a piecewise constant pressure space, and it can be implemented efficiently within standard finite element frameworks. To enforce pressure robustness, we construct velocity reconstruction operators that map the discrete EG velocity field into exactly divergence-free, H(div)-conforming fields. In particular, we develop reconstructions based on Arbogast-Correa (AC) mixed finite element spaces on quadrilateral meshes and demonstrate that the resulting schemes remain stable and accurate even on highly distorted grids. The nonlinearity of the coupled Navier-Stokes-Boussinesq system is treated with several iterative strategies, including Picard iterations and Anderson-accelerated iterations; our numerical study shows that Anderson acceleration yields robust and efficient convergence for high Rayleigh number flows within the proposed framework. The performance of the method is assessed on a set of benchmark problems and application-driven test cases. These numerical experiments highlight the potential of pressure-robust EG methods as flexible and accurate tools for coupled flow and heat transport in complex geometries."}
{"id": "2512.15829", "categories": ["cs.ET", "cs.AI", "cs.CV", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.15829", "abs": "https://arxiv.org/abs/2512.15829", "authors": ["Jingli Liu", "Huannan Zheng", "Bohao Zou", "Kezhou Yang"], "title": "Human-like Working Memory from Artificial Intrinsic Plasticity Neurons", "comment": null, "summary": "Working memory enables the brain to integrate transient information for rapid decision-making. Artificial networks typically replicate this via recurrent or parallel architectures, yet incur high energy costs and noise sensitivity. Here we report IPNet, a hardware-software co-designed neuromorphic architecture realizing human-like working memory via neuronal intrinsic plasticity. Exploiting Joule-heating dynamics of Magnetic Tunnel Junctions (MTJs), IPNet physically emulates biological memory volatility. The memory behavior of the proposed architecture shows similar trends in n-back, free recall and memory interference tasks to that of reported human subjects. Implemented exclusively with MTJ neurons, the architecture with human-like working memory achieves 99.65% accuracy on 11-class DVS gesture datasets and maintains 99.48% on a novel 22-class time-reversed benchmark, outperforming RNN, LSTM, and 2+1D CNN baselines sharing identical backbones. For autonomous driving (DDD-20), IPNet reduces steering prediction error by 14.4% compared to ResNet-LSTM. Architecturally, we identify a 'Memory-at-the-Frontier' effect where performance is maximized at the sensing interface, validating a bio-plausible near-sensor processing paradigm. Crucially, all results rely on raw parameters from fabricated devices without optimization. Hardware-in-the-loop validation confirms the system's physical realizability. Separately, energy analysis reveals a reduction in memory power of 2,874x compared to LSTMs and 90,920x versus parallel 3D-CNNs. This capacitor-free design enables a compact ~1.5um2 footprint (28 nm CMOS): a >20-fold reduction over standard LIF neurons. Ultimately, we demonstrate that instantiating human-like working memory via intrinsic neuronal plasticity endows neural networks with the dual biological advantages of superior dynamic vision processing and minimal metabolic cost."}
{"id": "2512.15929", "categories": ["math.NA", "cs.DS", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.15929", "abs": "https://arxiv.org/abs/2512.15929", "authors": ["Ethan N. Epperly"], "title": "Make the most of what you have: Resource-efficient randomized algorithms for matrix computations", "comment": "460 pages, 44 figures; lightly edited version of officially submitted PhD thesis", "summary": "In recent years, randomized algorithms have established themselves as fundamental tools in computational linear algebra, with applications in scientific computing, machine learning, and quantum information science. Many randomized matrix algorithms proceed by first collecting information about a matrix and then processing that data to perform some computational task. This thesis addresses the following question: How can one design algorithms that use this information as efficiently as possible, reliably achieving the greatest possible speed and accuracy for a limited data budget?\n  The first part of this thesis focuses on low-rank approximation for positive-semidefinite matrices. Here, the goal is to compute an accurate approximation to a matrix after accessing as few entries of the matrix as possible. This part of the thesis explores the randomly pivoted Cholesky (RPCholesky) algorithm for this task, which achieves a level of speed and reliability greater than other methods for the same problem.\n  The second part of this thesis considers the task of estimating attributes of an implicit matrix accessible only by matrix-vector products. This thesis describes the leave-one-out approach to developing matrix attribute estimation algorithms and develops optimized trace, diagonal, and row-norm estimation algorithms.\n  The third part of this thesis considers randomized algorithms for overdetermined linear least squares problems. Randomized algorithms for linear-least squares problems are asymptotically faster than any known deterministic algorithm, but recent work has raised questions about the accuracy of these methods in floating point arithmetic. This thesis shows these issues are resolvable by developing fast randomized least-squares problem achieving backward stability, the gold-standard stability guarantee for a numerical algorithm."}
{"id": "2512.16487", "categories": ["cs.SI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2512.16487", "abs": "https://arxiv.org/abs/2512.16487", "authors": ["Philipp Plamper", "Hanna Köpcke", "Anika Groß"], "title": "A Survey on Spatio-Temporal Knowledge Graph Models", "comment": null, "summary": "Many complex real-world systems exhibit inherently intertwined temporal and spatial characteristics. Spatio-temporal knowledge graphs (STKGs) have therefore emerged as a powerful representation paradigm, as they integrate entities, relationships, time and space within a unified graph structure. They are increasingly applied across diverse domains, including environmental systems and urban, transportation, social and human mobility networks. However, modeling STKGs remains challenging: their foundations span classical graph theory as well as temporal and spatial graph models, which have evolved independently across different research communities and follow heterogeneous modeling assumptions and terminologies. As a result, existing approaches often lack conceptual alignment, generalizability and reusability. This survey provides a systematic review of spatio-temporal knowledge graph models, tracing their origins in static, temporal and spatial graph modeling. We analyze existing approaches along key modeling dimensions, including edge semantics, temporal and spatial annotation strategies, temporal and spatial semantics and relate these choices to their respective application domains. Our analysis reveals that unified modeling frameworks are largely absent and that most current models are tailored to specific use cases rather than designed for reuse or long-term knowledge preservation. Based on these findings, we derive modeling guidelines and identify open challenges to guide future research."}
{"id": "2512.15802", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.15802", "abs": "https://arxiv.org/abs/2512.15802", "authors": ["Bingxue An", "Tiffany M. Tang"], "title": "Consensus dimension reduction via multi-view learning", "comment": null, "summary": "A plethora of dimension reduction methods have been developed to visualize high-dimensional data in low dimensions. However, different dimension reduction methods often output different and possibly conflicting visualizations of the same data. This problem is further exacerbated by the choice of hyperparameters, which may substantially impact the resulting visualization. To obtain a more robust and trustworthy dimension reduction output, we advocate for a consensus approach, which summarizes multiple visualizations into a single consensus dimension reduction visualization. Here, we leverage ideas from multi-view learning in order to identify the patterns that are most stable or shared across the many different dimension reduction visualizations, or views, and subsequently visualize this shared structure in a single low-dimensional plot. We demonstrate that this consensus visualization effectively identifies and preserves the shared low-dimensional data structure through both simulated and real-world case studies. We further highlight our method's robustness to the choice of dimension reduction method and hyperparameters -- a highly-desirable property when working towards trustworthy and reproducible data science."}
{"id": "2512.15810", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.15810", "abs": "https://arxiv.org/abs/2512.15810", "authors": ["Yury A Kutoyants"], "title": "Adaptive Kalman Filter for Systems with Unknown Initial Values", "comment": null, "summary": "The models of partially observed linear stochastic differential equations with unknown initial values of the non-observed component are considered in two situations. In the first problem, the initial value is deterministic, and in the second problem, it is assumed to be a Gaussian random variable. The main problem is the computation of adaptive Kalman filters and the discussion of their asymptotic optimality. The realization of this program for both models is done in several steps. First, a preliminary estimator of the unknown parameter is constructed by observations on some learning interval. Then, this estimator is used for the calculation of recurrent one-step MLE estimators, which are subsequently substituted in the equations of Kalman filtration."}
{"id": "2512.15859", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.15859", "abs": "https://arxiv.org/abs/2512.15859", "authors": ["Kristoffer Leraand", "Kristian Mæland", "Asle Sudbø"], "title": "Spin-dependent quasiparticle lifetimes in altermagnets", "comment": "17 pages, 7 figures", "summary": "We investigate many-body effects on the spin-split electron bands in altermagnets by computing the electron self-energy arising from interactions with magnons, phonons, and hybridized magnon-phonon modes. These interactions lead to band broadening, which can obscure the intrinsic spin-splitting in spectroscopic measurements. We consider a $d$-wave Lieb lattice altermagnet as a representative example. Our results reveal that the spin-splitting remains spectroscopically resolvable and provide theoretical estimates of lifetime effects relevant for experimental detection. For electron-magnon coupling, we find a distinct difference between spectral function broadening for up and down spins close to the Fermi surface, which is not present in the case of electron-phonon coupling. We relate it to the spin splitting of the magnon modes in altermagnets. The results, including magneto-elastic coupling, are very similar to the pure magnon case. This provides insights into quasiparticle dynamics in altermagnets and contributes to the broader understanding of many-body interactions in spin-split systems. By including the temperature dependence of the self-energies, we also quantify how thermal fluctuations influence the broadening of the electronic states."}
{"id": "2512.15789", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.15789", "abs": "https://arxiv.org/abs/2512.15789", "authors": ["Amir Hossein Ghasemi"], "title": "Relational Emergent Time for Quantum System: A Multi-Observer, Gravitational, and Cosmological Framework", "comment": "10 pages, 3 figures, 1 figure (LaTeX-generated), All references and figures are included in the main LaTeX source", "summary": "We present a relational framework in which temporal structure is not fundamental but emerges from correlations within a globally stationary quantum state. Each subsystem includes an internal clock, and conditional states evolve effectively with respect to these internal readings. The construction naturally extends to relativistic motion, gravitational redshift, and cosmological expansion, leading to a unified emergent-time functional valid across diverse physical regimes. The theory reproduces classical time dilation, predicts correlation-dependent deviations from standard evolution, and suggests that non-interacting or massless particles exhibit negligible internal time. These consequences open directions for conceptual and experimental investigations in the foundations of temporal physics, from multi-clock quantum systems to precision metrology and cosmological settings. In particular, the framework suggests measurable deviation from standard quantum evolution for highly entangled systems and predicts negligible internal time for massless particles."}
{"id": "2512.15726", "categories": ["math.OC", "math.PR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.15726", "abs": "https://arxiv.org/abs/2512.15726", "authors": ["Can Er", "Mo Liu"], "title": "Decision-Focused Bias Correction for Fluid Approximation", "comment": null, "summary": "Fluid approximation is a widely used approach for solving two-stage stochastic optimization problems, with broad applications in service system design such as call centers and healthcare operations. However, replacing the underlying random distribution (e.g., demand distribution) with its mean (e.g., the time-varying average arrival rate) introduces bias in performance estimation and can lead to suboptimal decisions. In this paper, we investigate how to identify an alternative point statistic, which is not necessarily the mean, such that substituting this statistic into the two-stage optimization problem yields the optimal decision. We refer to this statistic as the decision-corrected point estimate (time-varying arrival rate). For a general service network with customer abandonment costs, we establish necessary and sufficient conditions for the existence of such a corrected point estimate and propose an algorithm for its computation. Under a decomposable network structure, we further show that the resulting decision-corrected point estimate is closely related to the classical newsvendor solution. Numerical experiments demonstrate the superiority of our decision-focused correction method compared to the traditional fluid approximation."}
{"id": "2512.15725", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15725", "abs": "https://arxiv.org/abs/2512.15725", "authors": ["Matteo Cercola", "Donatello Materassi", "Simone Formentin"], "title": "Generative design of stabilizing controllers with diffusion models: the Youla approach", "comment": null, "summary": "Designing controllers that simultaneously achieve strong performance and provable closed-loop stability remains a central challenge in control engineering. This work introduces a diffusion-based generative framework for linear controller synthesis grounded in the Youla-Kucera parameterization, enabling the construction of stabilizing controllers by design. The diffusion model learns a conditional mapping from plant dynamics and desired performance metrics to feasible Youla parameters, guaranteeing internal stability while flexibly accommodating user-specified targets. Trained on synthetically generated stable SISO plants with fixed-order Youla parameters, the proposed approach reliably synthesizes controllers that meet prescribed sensitivity and settling-time specifications on previously unseen systems. To the best of our knowledge, this work provides the first demonstration that diffusion models can generate stabilizing controllers, combining rigorous control-theoretic guarantees with the versatility of modern generative modeling."}
{"id": "2512.15725", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15725", "abs": "https://arxiv.org/abs/2512.15725", "authors": ["Matteo Cercola", "Donatello Materassi", "Simone Formentin"], "title": "Generative design of stabilizing controllers with diffusion models: the Youla approach", "comment": null, "summary": "Designing controllers that simultaneously achieve strong performance and provable closed-loop stability remains a central challenge in control engineering. This work introduces a diffusion-based generative framework for linear controller synthesis grounded in the Youla-Kucera parameterization, enabling the construction of stabilizing controllers by design. The diffusion model learns a conditional mapping from plant dynamics and desired performance metrics to feasible Youla parameters, guaranteeing internal stability while flexibly accommodating user-specified targets. Trained on synthetically generated stable SISO plants with fixed-order Youla parameters, the proposed approach reliably synthesizes controllers that meet prescribed sensitivity and settling-time specifications on previously unseen systems. To the best of our knowledge, this work provides the first demonstration that diffusion models can generate stabilizing controllers, combining rigorous control-theoretic guarantees with the versatility of modern generative modeling."}
{"id": "2512.16026", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.16026", "abs": "https://arxiv.org/abs/2512.16026", "authors": ["L. C. González-Morales", "I. Pérez Castillo", "J. I. Jiménez-Aquino"], "title": "Entropy-production fluctuation theorem for a generalized Langevin particle in crossed electric and magnetic fields", "comment": null, "summary": "We study fluctuations of entropy production for a charged Brownian particle confined in a harmonic trap and driven out of equilibrium by crossed electric and magnetic fields. The magnetic field is constant and perpendicular to the plane of motion, while the electric field is time dependent and provides the driving. The non-Markovian dynamics is modeled by a generalized Langevin equation with memory and Gaussian noise. Using the exact solution of this linear dynamics, we obtain the time-dependent Gaussian phase-space probability density and from it compute the trajectory-dependent total entropy production. For two solvable driving protocols, we prove analytically that the entropy production obeys a detailed fluctuation theorem."}
{"id": "2512.16004", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.16004", "abs": "https://arxiv.org/abs/2512.16004", "authors": ["Furkan Şık", "F. L. Teixeira", "B. Shanker"], "title": "Sparse Operator-Adapted Wavelet Decomposition Using Polygonal Elements for Multiscale FEM Problems", "comment": "11 pages, 11 figures", "summary": "We develop a sparse multiscale operator-adapted wavelet decomposition-based finite element method (FEM) on unstructured polygonal mesh hierarchies obtained via a coarsening procedure. Our approach decouples different resolution levels, allowing each scale to be solved independently and added to the entire solution without the need to recompute coarser levels. At the finest level, the meshes consist of triangular elements which are geometrically coarsened at each step to form convex polygonal elements. Smooth field regions of the domain are solved with fewer, larger, polygonal elements, whereas high-gradient regions are represented by smaller elements, thereby improving memory efficiency through adaptivity. The proposed algorithm computes solutions via sequences of hierarchical sparse linear-algebra operations with nearly linear computational complexity."}
{"id": "2512.16071", "categories": ["cs.ET", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.16071", "abs": "https://arxiv.org/abs/2512.16071", "authors": ["Yixuan Gao", "Tanvir Ahmed", "Mikhail Mohammed", "Zhongqi Cheng", "Rajalakshmi Nandakumar"], "title": "Feasibility of Radio Frequency Based Wireless Sensing of Lead Contamination in Soil", "comment": "12 pages, 12 Figures, International Conference on Embedded Wireless Systems and Networks, https://ewsn.org/file-repository/ewsn2024/ewsn24-final99.pdf, Best Paper Award of EWSN2024", "summary": "Widespread Pb (lead) contamination of urban soil significantly impacts food safety and public health and hinders city greening efforts. However, most existing technologies for measuring Pb are labor-intensive and costly. In this study, we propose SoilScanner, a radio frequency-based wireless system that can detect Pb in soils. This is based on our discovery that the propagation of different frequency band radio signals is affected differently by different salts such as NaCl and Pb(NO3)2 in the soil. In a controlled experiment, manually adding NaCl and Pb(NO3)2 in clean soil, we demonstrated that different salts reflected signals at different frequencies in distinct patterns. In addition, we confirmed the finding using uncontrolled field samples with a machine learning model. Our experiment results show that SoilScanner can classify soil samples into low-Pb and high-Pb categories (threshold at 200 ppm) with an accuracy of 72%, with no sample with > 500 ppm of Pb being misclassified. The results of this study show that it is feasible to build portable and affordable Pb detection and screening devices based on wireless technology."}
{"id": "2512.15992", "categories": ["math.NA", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15992", "abs": "https://arxiv.org/abs/2512.15992", "authors": ["Ahmed Abdeljawad", "Elena Cordero"], "title": "Time-Frequency Analysis for Neural Networks", "comment": null, "summary": "We develop a quantitative approximation theory for shallow neural networks using tools from time-frequency analysis. Working in weighted modulation spaces $M^{p,q}_m(\\mathbf{R}^{d})$, we prove dimension-independent approximation rates in Sobolev norms $W^{n,r}(Ω)$ for networks whose units combine standard activations with localized time-frequency windows. Our main result shows that for $f \\in M^{p,q}_m(\\mathbf{R}^{d})$ one can achieve \\[ \\|f - f_N\\|_{W^{n,r}(Ω)} \\lesssim N^{-1/2}\\,\\|f\\|_{M^{p,q}_m(\\mathbf{R}^{d})}, \\] on bounded domains, with explicit control of all constants. We further obtain global approximation theorems on $\\mathbf{R}^{d}$ using weighted modulation dictionaries, and derive consequences for Feichtinger's algebra, Fourier-Lebesgue spaces, and Barron spaces. Numerical experiments in one and two dimensions confirm that modulation-based networks achieve substantially better Sobolev approximation than standard ReLU networks, consistent with the theoretical estimates."}
{"id": "2512.15950", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.15950", "abs": "https://arxiv.org/abs/2512.15950", "authors": ["Gregory Camilli"], "title": "Modeling Issues with Eye Tracking Data", "comment": null, "summary": "I describe and compare procedures for binary eye-tracking (ET) data. These procedures are applied to both raw and compressed data. The basic GLMM model is a logistic mixed model combined with random effects for persons and items. Additional models address autocorrelation eye-tracking serial observations. In particular, two novel approaches are illustrated that address serial without the use of an observed lag-1 predictor: a first-order autoregressive model obtained with generalized estimating equations, and a recurrent two-state survival model. Altogether, the results of four different analyses point to unresolved issues in the analysis of eye-tracking data and new directions for analytic development."}
{"id": "2512.16759", "categories": ["math.ST", "math.PR", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16759", "abs": "https://arxiv.org/abs/2512.16759", "authors": ["Dante de Roos", "Ben Chugg", "Peter Grünwald", "Aaditya Ramdas"], "title": "Rao-Blackwellized e-variables", "comment": "19 pages", "summary": "We show that for any concave utility, the expected utility of an e-variable can only increase after conditioning on a sufficient statistic. The simplest form of the result has an extremely straightforward proof, which follows from a single application of Jensen's inequality. Similar statements hold for compound e-variables, asymptotic e-variables, and e-processes. These results echo the Rao-Blackwell theorem, which states that the expected squared error of an estimator can only decrease after conditioning on a sufficient statistic. We provide several applications of this insight, including a simplified derivation of the log-optimal e-variable for linear regression with known variance."}
{"id": "2512.15863", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.15863", "abs": "https://arxiv.org/abs/2512.15863", "authors": ["Zihan Yan", "Qingchen Li", "Tomohiro Soejima", "Eslam Khalaf"], "title": "Anyon Dispersion in Aharonov-Casher Bands and Implications for Twisted MoTe${}_2$", "comment": "18+9 pages, 4+7 figures", "summary": "The discovery of fractional quantum anomalous Hall (FQAH) states in two-dimensional heterostructures has opened the door to realizing phases of dispersing anyons. Here, we develop an analytically controlled theory of anyon dispersion in FQAH states realized in ideal or Aharonov-Casher (AC) bands by projecting interactions onto the space of Laughlin quasiholes. Constructing quasihole momentum eigenstates allows efficient evaluation of the single quasihole dispersion using Monte Carlo. We find that the quasihole bandwidth grows with increasing quantum-geometry inhomogeneity of the AC band and with increasing interaction screening length. For realistic parameters relevant to the bands of twisted MoTe${}_2$, the quasihole bandwidth is of order 1 meV, suggesting that itinerant-anyon physics may play an important role in sufficiently clean samples. Furthermore, we develop a microscopic Lagrangian framework in terms of a quasihole guiding-center coordinate, which reproduces the momentum-space formula for the dispersion. This approach reveals that quasihole dispersion originates from the combined effects of an interaction-generated periodic potential, arising from non-uniform quantum geometry of the single particle bands, and the quasihole many-body Berry phase arising from the background magnetic field. The latter endows the guiding-center coordinate with a noncommutative structure, converting the periodic potential into a finite dispersion. Finally, we outline how this framework generalizes to multiple quasiholes, enabling a microscopic theory of charged excitations in FQAH systems that retains only the anyon degrees of freedom."}
{"id": "2512.15801", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.15801", "abs": "https://arxiv.org/abs/2512.15801", "authors": ["S. M. Yousuf Iqbal Tomal", "Abdullah Al Shafin"], "title": "Geometric Latent Space Tomography with Metric-Preserving Autoencoders", "comment": "9 pages, 4 figures, 5 tables", "summary": "Quantum state tomography faces exponential scaling with system size, while recent neural network approaches achieve polynomial scaling at the cost of losing the geometric structure of quantum state space. We introduce geometric latent space tomography, combining classical neural encoders with parameterized quantum circuit decoders trained via a metric-preservation loss that enforces proportionality between latent Euclidean distances and quantum Bures geodesics. On two-qubit mixed states with purity 0.85--0.95 representing NISQ-era decoherence, we achieve high-fidelity reconstruction (mean fidelity $F = 0.942 \\pm 0.03$) with an interpretable 20-dimensional latent structure. Critically, latent geodesics exhibit strong linear correlation with Bures distances (Pearson $r = 0.88$, $R^2 = 0.78$), preserving 78\\% of quantum metric structure. Geometric analysis reveals intrinsic manifold dimension 6.35 versus 20 ambient dimensions and measurable local curvature ($κ= 0.011 \\pm 0.006$), confirming non-trivial Riemannian geometry with $O(d^2)$ computational advantage over $O(4^n)$ density matrix operations. Unlike prior neural tomography, our geometry-aware latent space enables direct state discrimination, fidelity estimation from Euclidean distances, and interpretable error manifolds for quantum error mitigation without repeated full tomography, providing critical capabilities for NISQ devices with limited coherence times."}
{"id": "2512.15733", "categories": ["math.OC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15733", "abs": "https://arxiv.org/abs/2512.15733", "authors": ["Soufian Ben Amor", "Alain Bui", "Guillaume Guerard"], "title": "A Context-Free Smart Grid Model Using Complex System Approach", "comment": null, "summary": "Energy and pollution are urging problems of the 21th century. By gradually changing the actual power grid system, smart grid may evolve into different systems by means of size, elements and strategies, but its fundamental requirements and objectives will not change such as optimizing production, transmission, and consumption. Studying the smart grid through modeling and simulation provides us with valuable results which cannot be obtained in real world due to time and cost related constraints. Moreover, due to the complexity of the smart grid, achieving global optimization is not an easy task. In this paper, we propose a complex system based approach to the smart grid modeling, accentuating on the optimization by combining game theoretical and classical methods in different levels. Thanks to this combination, the optimization can be achieved with flexibility and scalability, while keeping its generality."}
{"id": "2512.15734", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15734", "abs": "https://arxiv.org/abs/2512.15734", "authors": ["Eloy Serrano-Seco", "Edgar Ramirez-Laboreo", "Eduardo Moya-Lasheras"], "title": "Run-to-Run Indirect Trajectory Tracking Control of Electromechanical Systems Based on Identifiable and Flat Models", "comment": "6 pages, 4 figures. Version submitted to the 23rd IFAC World Congress", "summary": "Differentially flat models are frequently used to design feedforward controllers for electromechanical systems. However, control performance depends on model accuracy, which makes feedback imperative. This paper presents a control scheme for electromechanical systems in which measuring or estimating the output to be controlled -- typically the position -- is not feasible. It employs an identifiable-model-based controller and predictor, coupled with an iterative loop that updates model parameters using the error between a measurable output and its prediction. Simulations on electromechanical switching devices show effective tracking of the desired position trajectory using only coil current measurements."}
{"id": "2512.15734", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15734", "abs": "https://arxiv.org/abs/2512.15734", "authors": ["Eloy Serrano-Seco", "Edgar Ramirez-Laboreo", "Eduardo Moya-Lasheras"], "title": "Run-to-Run Indirect Trajectory Tracking Control of Electromechanical Systems Based on Identifiable and Flat Models", "comment": "6 pages, 4 figures. Version submitted to the 23rd IFAC World Congress", "summary": "Differentially flat models are frequently used to design feedforward controllers for electromechanical systems. However, control performance depends on model accuracy, which makes feedback imperative. This paper presents a control scheme for electromechanical systems in which measuring or estimating the output to be controlled -- typically the position -- is not feasible. It employs an identifiable-model-based controller and predictor, coupled with an iterative loop that updates model parameters using the error between a measurable output and its prediction. Simulations on electromechanical switching devices show effective tracking of the desired position trajectory using only coil current measurements."}
{"id": "2512.16073", "categories": ["cond-mat.stat-mech", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2512.16073", "abs": "https://arxiv.org/abs/2512.16073", "authors": ["Abhijit Bera", "Kevin E. Bassler"], "title": "Complete Decomposition of Anomalous Diffusion in Variable Speed Generalized Lévy Walks", "comment": "22 pages, 12 figures", "summary": "Variable Speed Generalized Lévy Walks (VGLWs) are a class of spatio-temporally coupled stochastic processes that unify a broad range of previously studied models within a single parametrized framework. Their dynamics consist of discrete random steps, or flights, during which the walker's speed varies deterministically with both the elapsed time and the total duration of the flight. We investigate the anomalous diffusive behavior of VGLWs and analyze it through decomposition into the three fundamental constitutive effects that capture violations of the Central Limit Theorem (CLT): the Joseph effect, reflecting long-range increment correlations, the Noah effect, arising from heavy-tailed step-size distributions with infinite variance, and the Moses effect, associated with statistical aging and non-stationarity. Our results show that anomalous diffusion in VGLWs is typically generated by a nontrivial combination of all three effects, rather than being attributable to a single mechanism. Strikingly, we find that within the VGLW framework the Noah exponent $L$, which quantifies the strength of the Noah effect, is unbounded from above, revealing a richer and more extreme landscape of anomalous diffusion than in previously studied Lévy-walk-type models."}
{"id": "2512.16110", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.16110", "abs": "https://arxiv.org/abs/2512.16110", "authors": ["Elyar Tourani", "Brian J. Edwards", "Bamin Khomami"], "title": "ClusTEK: A grid clustering algorithm augmented with diffusion imputation and origin-constrained connected-component analysis: Application to polymer crystallization", "comment": "30 pages, 10 figures", "summary": "Grid clustering algorithms are valued for their efficiency in large-scale data analysis but face persistent limitations: parameter sensitivity, loss of structural detail at coarse resolutions, and misclassifications of edge or bridge cells at fine resolutions. Previous studies have addressed these challenges through adaptive grids, parameter tuning, or hybrid integration with other clustering methods, each of which offers limited robustness. This paper introduces a grid clustering framework that integrates Laplacian-kernel diffusion imputation and origin-constrained connected-component analysis (OC-CCA) on a uniform grid to reconstruct the cluster topology with high accuracy and computational efficiency. During grid construction, an automated preprocessing stage provides data-driven estimates of cell size and density thresholds. The diffusion step then mitigates sparsity and reconstructs missing edge cells without over-smoothing physical gradients, while OC-CCA constrains component growth to physically consistent origins, reducing false merges across narrow gaps. Operating on a fixed-resolution grid with spatial indexing ensures the scaling of O(nlog n). Experiments on synthetic benchmarks and polymer simulation datasets demonstrate that the method correctly manages edges, preserves cluster topology, and avoids spurious connections. Benchmarking on polymer systems across scales (9k, 180k, and 989k atoms) shows that optimal preprocessing, combined with diffusion-based clustering, reproduces atomic-level accuracy and captures physically meaningful morphologies while delivering accelerated computation."}
{"id": "2512.16216", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.16216", "abs": "https://arxiv.org/abs/2512.16216", "authors": ["Lingxiao Li", "Haiyan Su", "He Zhang", "Weiying Zheng"], "title": "A divergence-free parametric finite element method for 3D Stokes equations on curved domains", "comment": null, "summary": "The Stokes equations play an important role in the incompressible flow simulation. In this paper, a novel divergence-free parametric mixed finite element method is proposed for solving three-dimensional Stokes equations on domains with piecewise smooth boundaries. The flow velocity and pressure are discretized with high-order parametric Brezzi-Douglas-Marini elements and volume elements, respectively, on curved tetrahedral meshes. Utilizing the interior-penalty discontinuous Galerkin (IPDG) technique, we prove the inf-sup condition for the mixed finite element pair, and high-order optimal error estimates in the energy norm, with the help of the extension and transformation of the true solution to computational domain. Moreover, the discrete velocity is exactly divergence-free, meaning that div uh = 0 holds in the curved computational domain. Numerical experiments are conducted to support the theoretical analyses."}
{"id": "2512.16012", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.16012", "abs": "https://arxiv.org/abs/2512.16012", "authors": ["JoonHo Lee"], "title": "Reliability-Targeted Simulation of Item Response Data: Solving the Inverse Design Problem", "comment": null, "summary": "Monte Carlo simulations are the primary methodology for evaluating Item Response Theory (IRT) methods, yet marginal reliability - the fundamental metric of data informativeness - is rarely treated as an explicit design factor. Unlike in multilevel modeling where the intraclass correlation (ICC) is routinely manipulated, IRT studies typically treat reliability as an incidental outcome, creating a \"reliability omission\" that obscures the signal-to-noise ratio of generated data. To address this gap, we introduce a principled framework for reliability-targeted simulation, transforming reliability from an implicit by-product into a precise input parameter. We formalize the inverse design problem, solving for a global discrimination scaling factor that uniquely achieves a pre-specified target reliability. Two complementary algorithms are proposed: Empirical Quadrature Calibration (EQC) for rapid, deterministic precision, and Stochastic Approximation Calibration (SAC) for rigorous stochastic estimation. A comprehensive validation study across 960 conditions demonstrates that EQC achieves essentially exact calibration, while SAC remains unbiased across non-normal latent distributions and empirical item pools. Furthermore, we clarify the theoretical distinction between average-information and error-variance-based reliability metrics, showing they require different calibration scales due to Jensen's inequality. An accompanying open-source R package, IRTsimrel, enables researchers to standardize reliability as a controlled experimental input."}
{"id": "2512.16363", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.16363", "abs": "https://arxiv.org/abs/2512.16363", "authors": ["Guanghui Wang", "Mengtao Wen", "Changliang Zou"], "title": "Empirical Likelihood Meets Prediction-Powered Inference", "comment": null, "summary": "We study inference with a small labeled sample, a large unlabeled sample, and high-quality predictions from an external model. We link prediction-powered inference with empirical likelihood by stacking supervised estimating equations based on labeled outcomes with auxiliary moment conditions built from predictions, and then optimizing empirical likelihood under these joint constraints. The resulting empirical likelihood-based prediction-powered inference (EPI) estimator is asymptotically normal, has asymptotic variance no larger than the fully supervised estimator, and attains the semiparametric efficiency bound when the auxiliary functions span the predictable component of the supervised score. For hypothesis testing and confidence sets, empirical likelihood ratio statistics admit chi-squared-type limiting distributions. As a by-product, the empirical likelihood weights induce a calibrated empirical distribution that integrates supervised and prediction-based information, enabling estimation and uncertainty quantification for general functionals beyond parameters defined by estimating equations. We present two practical implementations: one based on basis expansions in the predictions and covariates, and one that learns an approximately optimal auxiliary function by cross-fitting. In simulations and applications, EPI reduces mean squared error and shortens confidence intervals while maintaining nominal coverage."}
{"id": "2512.15868", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.15868", "abs": "https://arxiv.org/abs/2512.15868", "authors": ["Campbell McLauchlan", "Vedant Motamarri", "Benjamin Béri"], "title": "Classifying one-dimensional Floquet phases through two-dimensional topological order", "comment": "32 pages, 5 figures", "summary": "Floquet systems display rich phenomena, such as time crystals, with many-body localisation (MBL) protecting the phases from heating. While several types of Floquet phases have been classified, a unified picture of Floquet MBL is still emerging. Static phases have been fruitfully studied via \"symmetry topological field theory\" (SymTFT), wherein the universal features of $G$-symmetric systems are elucidated by placing them on the boundary of a topological order of one dimension higher. In this work, we provide a SymTFT approach to classifying $G$-symmetric Floquet MBL phases in 1D, for $G$ a finite Abelian group with on-site unitary action. In the SymTFT, these 1D systems correspond to the boundaries of the quantum double associated to $G$, and the classification naturally arises from considering the Lagrangian subgroups and boundary excitations of the quantum double. The classification covers all known Floquet phases while uncovering others previously unexplored, along with bulk features of phases thought to have only boundary signatures. We refer to the latter phases as \"dual\" time crystals. For static phases, we show how anyons of the quantum double and (string) order parameters provide a natural and simple interpretation of known classification schemes. By extending our framework to the boundaries of twisted quantum doubles, we uncover a new time-crystalline phase with non-onsite symmetry, which cannot be obtained through local, symmetric Hamiltonian drives. We numerically demonstrate evidence for the absolute stability of this phase, and observe that for open boundary conditions it has greater stability to symmetric perturbations. We finally discuss perspectives on using programmable quantum devices to realise and probe the phases we discuss. Our results show that SymTFT provides a powerful approach to unifying phases and features of Floquet systems."}
{"id": "2512.15831", "categories": ["quant-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.15831", "abs": "https://arxiv.org/abs/2512.15831", "authors": ["Benjamin Desef"], "title": "Optimization Techniques in Quantum Information", "comment": "PhD Thesis", "summary": "This thesis focuses on the intersection of mathematical and computational optimization and quantum information. Main contributions are open-source software code: A hybrid approach mixing \"traditional\" nonconvex and convex methods can make difficult problems more accessible. A demonstration of how to efficiently implement such an algorithm, avoiding interfacial bottlenecks, is provided, finding optimal protocols to establish entanglement through a lossy channel. The central software package developed addresses polynomial optimization problems. Many problems naturally involve only a polynomial objective and constraint polynomials. Such problems can automatically be cast into semidefinite programs that provide a hierarchy of outer approximations. The resulting problems are often so large and scale so unfavorably with respect to the variable number and degree involved that the boundary of the doable is reached quickly. However, technical progress both in hardware and algorithms has pushed this boundary - but software frameworks for polynomial optimization have not followed in the same manner, often now making them the bottleneck that before was the solver. The package PolynomialOptimization.jl developed during this thesis aims to fill the gap and provide a very resource-efficient intermediate layer together with a wide number of algorithms to reduce the problem size, and naturally supporting complex numbers and semidefinite constraints ubiquitous in quantum information problems. Its application on an entanglement distribution problem is demonstrated, showing that even relaxations with semidefinite matrices of three- and four-digit size can be solved conveniently. Finally, a new way to calculate interior-point barriers for the cone of sums-of-squares matrices in a nearly time-optimal way is developed, whose efficient implementation has the potential of further reducing resource consumption."}
{"id": "2512.15735", "categories": ["math.OC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15735", "abs": "https://arxiv.org/abs/2512.15735", "authors": ["Ningwei Bai", "Chi Pui Chan", "Qichen Yin", "Tengyang Gong", "Yunda Yan", "Zezhi Tang"], "title": "Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming", "comment": "9 pages, 9 figures, 2 numerical examples. This version presents a unified event-triggered ESO-ADP control framework, including stability analysis, algorithm description, and simulation studies. A journal extension with full hybrid-system stability proofs will follow", "summary": "This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes."}
{"id": "2512.15916", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15916", "abs": "https://arxiv.org/abs/2512.15916", "authors": ["Enrique Rodríguez-Miranda", "Pablo Otálora", "José González-Hernández", "José Luis Guzmán", "Manuel Berenguel"], "title": "A Comprehensive Benchmark Platform for Process Control Research of Outdoor Microalgae Raceway Reactors", "comment": null, "summary": "This paper presents a benchmarking framework to evaluate process control strategies in outdoor microalgae raceway reactors, integrating four key control regulation tasks: pH, dissolved oxygen (DO), culture volume through coordinated harvest-dilution actions, and temperature via a sump-mounted spiral heat exchanger. The benchmark is built upon a high-fidelity, experimentally calibrated dynamic model that captures the strongly coupled thermal, physicochemical, and biological processes governing industrial-scale open raceway ponds. A closed-loop simulation environment is provided, featuring realistic actuator constraints, gas transport delays, stiff integration, and a fully specified scenario based on multi-day outdoor disturbances (irradiance, temperature, wind, and humidity). Four user-replaceable controllers define the manipulation of CO2 injection, air bubbling, harvest/dilution sequencing, and heat-exchanger operation. The platform computes a unified global performance index, in addition to individual metrics for each control problem, combining tracking error, gas and energy usage, and biomass productivity, enabling consistent and quantitative comparison of alternative control strategies. Baseline regulatory architectures (On/Off, PI/PID, and Economic Model Predictive Control (EMPC)) are included to illustrate the benchmark use for classical and advanced control methods. By providing an openly specified, reproducible, and computationally tractable benchmark with well-defined function interfaces, this work aims to bridge control methodology and outdoor algal bioprocess engineering, and to support the development of multivariable control strategies for disturbance-rich environmental systems."}
{"id": "2512.15916", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15916", "abs": "https://arxiv.org/abs/2512.15916", "authors": ["Enrique Rodríguez-Miranda", "Pablo Otálora", "José González-Hernández", "José Luis Guzmán", "Manuel Berenguel"], "title": "A Comprehensive Benchmark Platform for Process Control Research of Outdoor Microalgae Raceway Reactors", "comment": null, "summary": "This paper presents a benchmarking framework to evaluate process control strategies in outdoor microalgae raceway reactors, integrating four key control regulation tasks: pH, dissolved oxygen (DO), culture volume through coordinated harvest-dilution actions, and temperature via a sump-mounted spiral heat exchanger. The benchmark is built upon a high-fidelity, experimentally calibrated dynamic model that captures the strongly coupled thermal, physicochemical, and biological processes governing industrial-scale open raceway ponds. A closed-loop simulation environment is provided, featuring realistic actuator constraints, gas transport delays, stiff integration, and a fully specified scenario based on multi-day outdoor disturbances (irradiance, temperature, wind, and humidity). Four user-replaceable controllers define the manipulation of CO2 injection, air bubbling, harvest/dilution sequencing, and heat-exchanger operation. The platform computes a unified global performance index, in addition to individual metrics for each control problem, combining tracking error, gas and energy usage, and biomass productivity, enabling consistent and quantitative comparison of alternative control strategies. Baseline regulatory architectures (On/Off, PI/PID, and Economic Model Predictive Control (EMPC)) are included to illustrate the benchmark use for classical and advanced control methods. By providing an openly specified, reproducible, and computationally tractable benchmark with well-defined function interfaces, this work aims to bridge control methodology and outdoor algal bioprocess engineering, and to support the development of multivariable control strategies for disturbance-rich environmental systems."}
{"id": "2512.16747", "categories": ["cond-mat.stat-mech", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2512.16747", "abs": "https://arxiv.org/abs/2512.16747", "authors": ["Yilin Ye", "Denis S. Grebenkov"], "title": "Correlation between the first-reaction time and the acquired boundary local time", "comment": null, "summary": "We investigate the statistical correlation between the first-reaction time of a diffusing particle and its boundary local time accumulated until the reaction event. Since the reaction event occurs after multiple encounters of the particle with a partially reactive boundary, the boundary local time as a proxy for the number of such encounters is not independent of, but intrinsically linked to, the first-reaction time. We propose a universal theoretical framework to derive their joint probability density and, in particular, the correlation coefficient. To illustrate the dependence of these correlations on the boundary reactivity and shape, we obtain explicit analytical solutions for several basic domains. The analytical results are complemented by Monte Carlo simulations, which we employ to examine the role of interior obstacles on correlations in disordered media. Applications of these statistical results in chemical physics are discussed"}
{"id": "2512.16812", "categories": ["cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.16812", "abs": "https://arxiv.org/abs/2512.16812", "authors": ["Christoph Schönle", "Davide Carbone", "Marylou Gabrié", "Tony Lelièvre", "Gabriel Stoltz"], "title": "Efficient Monte-Carlo sampling of metastable systems using non-local collective variable updates", "comment": null, "summary": "Monte-Carlo simulations are widely used to simulate complex molecular systems, but standard approaches suffer from metastability. Lately, the use of non-local proposal updates in a collective-variable (CV) space has been proposed in several works. Here, we generalize these approaches and explicitly spell out an algorithm for non-linear CVs and underdamped Langevin dynamics. We prove reversibility of the resulting scheme and demonstrate its performance on several numerical examples, observing a substantial performance increase compared to methods based on overdamped Langevin dynamics as considered previously. Advances in generative machine-learning-based proposal samplers now enable efficient sampling in CV spaces of intermediate dimensionality (tens to hundreds of variables), and our results extend their applicability toward more realistic molecular systems."}
{"id": "2512.16269", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.16269", "abs": "https://arxiv.org/abs/2512.16269", "authors": ["Khaoula El Maddah", "Matti Lassas", "Teemu Tyni"], "title": "Numerical reconstruction of Schrödinger equations with quadratic nonlinearities", "comment": "23 pages, 6 figures", "summary": "We introduce a numerical framework for reconstructing the potential in two dimensional semilinear elliptic PDEs with power type nonlinearities from the nonlinear Dirichlet to Neumann map. By applying higher order linearization method, we compute the Fourier data of the unknown potential and then invert it to recover $q$. Numerical experiments show accurate reconstructions for both smooth and discontinuous test cases."}
{"id": "2512.16061", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.16061", "abs": "https://arxiv.org/abs/2512.16061", "authors": ["Fernando Baltazar-Larios", "Alejandra Quintos"], "title": "Maximum Likelihood Estimation for Scaled Inhomogeneous Phase-Type Distributions from Discrete Observations", "comment": null, "summary": "Inhomogeneous phase-type (IPH) distributions extend classical phase-type models by allowing transition intensities to vary over time, offering greater flexibility for modeling heavy-tailed or time-dependent absorption phenomena. We focus on the subclass of IPH distributions with time-scaled sub-intensity matrices of the form $Λ(t) = h_β(t)Λ$, which admits a time transformation to a homogeneous Markov jump process. For this class, we develop a statistical inference framework for discretely observed trajectories that combines Markov-bridge reconstruction with a stochastic EM algorithm and a gradient-based up- date. The resulting method yields joint maximum-likelihood estimates of both the baseline sub-intensity matrix $Λ$ and the time-scaling parameter $β$. Through simulation studies for the matrix-Gompertz and matrix-Weibull families, and a real-data application to coronary allograft vasculopathy progression, we demonstrate that the proposed approach provides an accurate and computationally tractable tool for fitting time-scaled IPH models to irregular multi-state data."}
{"id": "2512.16411", "categories": ["stat.ME", "math.ST", "q-fin.ST", "q-fin.TR", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.16411", "abs": "https://arxiv.org/abs/2512.16411", "authors": ["Matthieu Garcin", "Louis Perot"], "title": "Asymptotic and finite-sample distributions of one- and two-sample empirical relative entropy, with application to change-point detection", "comment": null, "summary": "Relative entropy, as a divergence metric between two distributions, can be used for offline change-point detection and extends classical methods that mainly rely on moment-based discrepancies. To build a statistical test suitable for this context, we study the distribution of empirical relative entropy and derive several types of approximations: concentration inequalities for finite samples, asymptotic distributions, and Berry-Esseen bounds in a pre-asymptotic regime. For the latter, we introduce a new approach to obtain Berry-Esseen inequalities for nonlinear functions of sum statistics under some convexity assumptions. Our theoretical contributions cover both one- and two-sample empirical relative entropies. We then detail a change-point detection procedure built on relative entropy and compare it, through extensive simulations, with classical methods based on moments or on information criteria. Finally, we illustrate its practical relevance on two real datasets involving temperature series and volatility of stock indices."}
{"id": "2512.15872", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.15872", "abs": "https://arxiv.org/abs/2512.15872", "authors": ["Andres Perez Fadon", "David Pfau", "James S. Spencer", "Wan Tong Lou", "Titus Neupert", "W. M. C. Foulkes"], "title": "Extracting Anyon Statistics from Neural Network Fractional Quantum Hall States", "comment": null, "summary": "Fractional quantum Hall states host emergent anyons with exotic exchange statistics, but obtaining direct access to their topological properties in real systems remains a challenge. Neural-network wavefunctions provide a flexible computational approach, as they can represent highly correlated states without requiring a tailored basis. Here we use the neural-network variational Monte Carlo method to study the fractional quantum Hall effect on the torus and find the three degenerate ground states at filling factor nu=1/3. From these, we extract the modular S matrix via entanglement interferometry, a technique previously only applied to lattice models. The resulting S matrix encodes the quantum dimensions, fusion rules, and exchange statistics of the emergent anyons, providing a direct numerical demonstration of the topological order. The calculated anyon properties match the well-known theoretical and experimental results. Our work establishes neural-network wavefunctions as a powerful new tool for investigating anyonic properties."}
{"id": "2512.15838", "categories": ["quant-ph", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.15838", "abs": "https://arxiv.org/abs/2512.15838", "authors": ["Binglei Lou", "Gautham Duddi Krishnaswaroop", "Filip Wojcicki", "Ruilin Wu", "Richard Rademacher", "Zhiqiang Que", "Wayne Luk", "Philip H. W. Leong"], "title": "Low-Latency FPGA Control System for Real-Time Neural Network Processing in CCD-Based Trapped-Ion Qubit Measurement", "comment": null, "summary": "Accurate and low-latency qubit state measurement is critical for trapped-ion quantum computing. While deep neural networks (DNNs) have been integrated to enhance detection fidelity, their latency performance on specific hardware platforms remains underexplored. This work benchmarks the latency of DNN-based qubit detection on field-programmable gate arrays (FPGAs) and graphics processing units (GPUs). The FPGA solution directly interfaces an electron-multiplying charge-coupled device (EMCCD) with the subsequent data processing logic, eliminating buffering and interface overheads. As a baseline, the GPU-based system employs a high-speed PCIe image grabber for image input and I/O card for state output. We deploy Multilayer Perceptron (MLP) and Vision Transformer (ViT) models on hardware to evaluate measurement performance. Compared to conventional thresholding, DNNs reduce the mean measurement fidelity (MMF) error by factors of 1.8-2.5x (one-qubit case) and 4.2-7.6x (three-qubit case). FPGA-based MLP and ViT achieve nanosecond- and microsecond-scale inference latencies, while the complete single-shot measurement process achieves over 100x speedup compared to the GPU implementation. Additionally, clock-cycle-level signal analysis reveals inefficiencies in EMCCD data transmission via Cameralink, suggesting that optimizing this interface could further leverage the advantages of ultra-low-latency DNN inference, guiding the development of next-generation qubit detection systems."}
{"id": "2512.16006", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.16006", "abs": "https://arxiv.org/abs/2512.16006", "authors": ["Agnieszka Wiszniewska-Matyszkiel", "Maciej Wrona"], "title": "A cartel-fringe model in a nonrenewable resource economy with many fringe firms extracting from a common deposit", "comment": "46 pages, 8 figures, 1 table", "summary": "We study a model of a nonrenewable resource market, e.g. crude oil market. This market consists of a cartel with market power and a fringe consisting of many small firms, whose deposits are interrelated. In addition, the firms face constraints on extraction. Besides the nonrenewable resource, there is also its sustainable substitute, which constrains the price. We fully characterize the resulting Stackelberg equilibrium. Besides typical solution, in which initially the cartel and fringe extract simultaneously, we find that for some model parameters and initial capacities, the cartel may also deter the fringe from extraction, or it may refrain from extraction until the fringe depletes their deposit. We conduct sensitivity analysis and study the conditions when one of those counterintuitive solutions is optimal."}
{"id": "2512.15996", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15996", "abs": "https://arxiv.org/abs/2512.15996", "authors": ["Saiedeh Akbari", "Xuehui Shen", "Wenqian Xue", "Jordan C. Insinger", "Warren E. Dixon"], "title": "Lyapunov-based Adaptive Transformer (LyAT) for Control of Stochastic Nonlinear Systems", "comment": null, "summary": "This paper presents a novel Lyapunov-based Adaptive Transformer (LyAT) controller for stochastic nonlinear systems. While transformers have shown promise in various control applications due to sequential modeling through self-attention mechanisms, they have not been used within adaptive control architectures that provide stability guarantees. Existing transformer-based approaches for control rely on offline training with fixed weights, resulting in open-loop implementations that lack real-time adaptation capabilities and stability assurances. To address these limitations, a continuous LyAT controller is developed that adaptively estimates drift and diffusion uncertainties in stochastic dynamical systems without requiring offline pre-training. A key innovation is the analytically derived adaptation law constructed from a Lyapunov-based stability analysis, which enables real-time weight updates while guaranteeing probabilistic uniform ultimate boundedness of tracking and parameter estimation errors. Experimental validation on a quadrotor demonstrates the performance of the developed controller."}
{"id": "2512.15996", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15996", "abs": "https://arxiv.org/abs/2512.15996", "authors": ["Saiedeh Akbari", "Xuehui Shen", "Wenqian Xue", "Jordan C. Insinger", "Warren E. Dixon"], "title": "Lyapunov-based Adaptive Transformer (LyAT) for Control of Stochastic Nonlinear Systems", "comment": null, "summary": "This paper presents a novel Lyapunov-based Adaptive Transformer (LyAT) controller for stochastic nonlinear systems. While transformers have shown promise in various control applications due to sequential modeling through self-attention mechanisms, they have not been used within adaptive control architectures that provide stability guarantees. Existing transformer-based approaches for control rely on offline training with fixed weights, resulting in open-loop implementations that lack real-time adaptation capabilities and stability assurances. To address these limitations, a continuous LyAT controller is developed that adaptively estimates drift and diffusion uncertainties in stochastic dynamical systems without requiring offline pre-training. A key innovation is the analytically derived adaptation law constructed from a Lyapunov-based stability analysis, which enables real-time weight updates while guaranteeing probabilistic uniform ultimate boundedness of tracking and parameter estimation errors. Experimental validation on a quadrotor demonstrates the performance of the developed controller."}
{"id": "2512.16812", "categories": ["cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.16812", "abs": "https://arxiv.org/abs/2512.16812", "authors": ["Christoph Schönle", "Davide Carbone", "Marylou Gabrié", "Tony Lelièvre", "Gabriel Stoltz"], "title": "Efficient Monte-Carlo sampling of metastable systems using non-local collective variable updates", "comment": null, "summary": "Monte-Carlo simulations are widely used to simulate complex molecular systems, but standard approaches suffer from metastability. Lately, the use of non-local proposal updates in a collective-variable (CV) space has been proposed in several works. Here, we generalize these approaches and explicitly spell out an algorithm for non-linear CVs and underdamped Langevin dynamics. We prove reversibility of the resulting scheme and demonstrate its performance on several numerical examples, observing a substantial performance increase compared to methods based on overdamped Langevin dynamics as considered previously. Advances in generative machine-learning-based proposal samplers now enable efficient sampling in CV spaces of intermediate dimensionality (tens to hundreds of variables), and our results extend their applicability toward more realistic molecular systems."}
{"id": "2512.16887", "categories": ["physics.soc-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.16887", "abs": "https://arxiv.org/abs/2512.16887", "authors": ["Julián López", "Virginia Mazzone", "M. Leticia Rubio Puzzo", "Juan Cruz Moreno"], "title": "An evacuation simulator for pedestrian dynamics based on the Social Force Model", "comment": null, "summary": "The evacuation of pedestrians from enclosed spaces represents a key problem in safety engineering and infrastructure design. Analyzing the collective dynamics that emerge during evacuation processes requires simulation tools capable of capturing individual interactions and spatial constraints realistically.\n  In this work, we present \\textit{SiCoBioNa}, an open-source evacuation simulator based on the Social Force Model (SFM). The software provides an intuitive graphical interface that allows users to configure pedestrian properties, spatial geometries, and initial conditions without requiring prior expertise in numerical modeling techniques. The SFM framework enables the representation of goal-oriented motion, interpersonal interactions, and interactions with fixed obstacles.\n  The simulator generates both quantitative data and visual outputs, facilitating the analysis of evacuation dynamics and the evaluation of different spatial configurations. Due to its modular and extensible design, \\textit{SiCoBioNa} serves as a reproducible research tool for studies on pedestrian dynamics providing practical support for evacuation planning."}
{"id": "2512.15739", "categories": ["q-fin.RM", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15739", "abs": "https://arxiv.org/abs/2512.15739", "authors": ["Sharif Al Mamun", "Rakib Hossain", "Md. Jobayer Rahman", "Malay Kumar Devnath", "Farhana Afroz", "Lisan Al Amin"], "title": "Bayesian Modeling for Uncertainty Management in Financial Risk Forecasting and Compliance", "comment": null, "summary": "A Bayesian analytics framework that precisely quantifies uncertainty offers a significant advance for financial risk management. We develop an integrated approach that consistently enhances the handling of risk in market volatility forecasting, fraud detection, and compliance monitoring. Our probabilistic, interpretable models deliver reliable results: We evaluate the performance of one-day-ahead 95% Value-at-Risk (VaR) forecasts on daily S&P 500 returns, with a training period from 2000 to 2019 and an out-of-sample test period spanning 2020 to 2024. Formal tests of unconditional (Kupiec) and conditional (Christoffersen) coverage reveal that an LSTM baseline achieves near-nominal calibration. In contrast, a GARCH(1,1) model with Student-t innovations underestimates tail risk. Our proposed discount-factor DLM model produces a slightly liberal VaR estimate, with evidence of clustered violations. Bayesian logistic regression improves recall and AUC-ROC for fraud detection, and a hierarchical Beta state-space model provides transparent and adaptive compliance risk assessment. The pipeline is distinguished by precise uncertainty quantification, interpretability, and GPU-accelerated analysis, delivering up to 50x speedup. Remaining challenges include sparse fraud data and proxy compliance labels, but the framework enables actionable risk insights. Future expansion will extend feature sets, explore regime-switching priors, and enhance scalable inference."}
{"id": "2512.16179", "categories": ["nlin.CD", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.16179", "abs": "https://arxiv.org/abs/2512.16179", "authors": ["Yazhini Muruganantham", "Andrei Velichko", "Samidurai Rajendran"], "title": "Local Lyapunov Analysis via Micro-Ensembles: finite-time Lyapunov exponent Estimation and KNN-Based Predictive Comparison in Complex-Valued BAM Neural Networks", "comment": "22 pages, 7 figures, 4 Tables", "summary": "Finite-time Lyapunov exponents (FTLEs) quantify short-horizon trajectory divergence and provide a local, spatially resolved view of transient instabilities and synchronization behavior in nonlinear dynamics. This work studies a class of fractional-order complex-valued bidirectional associative memory (BAM) neural networks and proposes a unified analytical and data-driven framework for synchronization and local stability assessment. Using fractional Lyapunov stability theory together with Mittag-Leffler functions, sufficient conditions are derived to guarantee global Mittag-Leffler synchronization of the drive-response systems under a linear error-feedback controller. In addition, an explicit conservative time-to-tolerance estimate is obtained via a standard upper bound on the Mittag-Leffler function. Numerical simulations corroborate the theory and demonstrate rapid decay of synchronization errors in both real and imaginary state components. To complement the model-based guarantees, two trajectory-driven Lyapunov proxies are introduced: (i) micro-ensemble FTLE estimation based on the geometric-mean growth of small perturbations, and (ii) a k-nearest neighbors (kNN) prediction-error index that quantifies local instability through short-term forecast errors. Both proxies reveal oscillatory transient divergence patterns and consistently reflect the stabilizing effect of the designed controller. The proposed integration of fractional calculus, synchronization control, and data-driven Lyapunov diagnostics provides a robust methodology for complex-valued fractional-order neural networks, with potential applications in secure communications and nonlinear signal processing."}
{"id": "2512.16193", "categories": ["nlin.AO", "cond-mat.stat-mech", "math-ph", "math.DS", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2512.16193", "abs": "https://arxiv.org/abs/2512.16193", "authors": ["Narumi Fujii", "Keisuke Taga", "Riccardo Muolo", "Bob Rink", "Hiroya Nakao"], "title": "Emergence of higher-order interactions in systems of coupled Kuramoto oscillators with time delay", "comment": null, "summary": "Understanding the mechanisms that govern collective synchronization is a paramount task in nonlinear dynamics. While higher-order (many-body) interactions have recently emerged as a powerful framework for capturing collective behaviors, real-world examples regarding dynamics remain scarce. Here, we show that higher-order interactions naturally emerge from time-delayed pairwise coupling in Kuramoto oscillators. By expanding the delay term up to second order in the coupling strength, we derive an effective Kuramoto model featuring both two-body and three-body interactions, but without delay, hence, easier to be analyzed. Numerical simulations show that this reduced model can reproduce the bistability and synchronization transitions of the original time-delayed system. Furthermore, applying the Ott-Antonsen ansatz, we obtain a stability diagram for incoherent and synchronized states that closely matches the results of the original model. Our findings reveal that time delays can be effectively recast in the form of higher-order interactions, offering a new perspective on how delayed interactions shape the dynamics."}
{"id": "2512.16399", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.16399", "abs": "https://arxiv.org/abs/2512.16399", "authors": ["Miguel A. González-Casado", "Angel Sánchez", "Santo Fortunato"], "title": "What defines a group of friends? Rethinking community structure in signed, directed networks", "comment": null, "summary": "We study the structure of personal relationships among 1068 high school students using a dataset that contains the network of self-reported friendly and conflictive relationships, with information on their directionality and intensity. We analyse the resulting weighted, directed, and signed network using a Bayesian stochastic block model framework, which enables the inference of group structure without imposing prior assumptions on the role of negative or asymmetric ties. While a full model incorporating all edge attributes yields statistically coherent clusters, these do not align with socially meaningful communities. To address this, we focus first on the network backbone of mutual affinities, and we characterize its group organization. Many communities display an assortative structure, often embedded within larger cohesive configurations, but we also observe more diverse patterns such as core-periphery structure and isolated nodes. We then examine how relationship intensity, directionality, and conflict shape group structure. Asymmetric ties, though often occurring between communities, are frequently present within them, revealing the stabilizing effect of group membership on non-mutual relationships. Furthermore, the presence of asymmetric ties does not inherently imply a hierarchical structure, given that all groups both receive and report significant levels of non-reciprocal ties. More intense ties play a disproportionate role in shaping community structure. Finally, negative ties tend to bridge communities, but we find that groups feature a significant level of internal conflict. Our research offers a new perspective on the study of group organization when rich information about the directionality, the intensity and the sign of ties is considered, with implications for identifying social vulnerability and designing targeted interventions."}
{"id": "2512.16021", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.16021", "abs": "https://arxiv.org/abs/2512.16021", "authors": ["Marek Jankola", "Freya Behrens", "Cédric Koller", "Lenka Zdeborová"], "title": "Minority Takeover in Majority Dynamics: Searching for Rare Initializations via the History Passing Algorithm", "comment": null, "summary": "We investigate how much bias in the initial configuration is required to drive global agreement in synchronous, deterministic majority dynamics on large random $d$-regular graphs. Nodes take values $\\pm 1$ and update their states at each discrete time step to align with the majority of their neighbors. Using the backtracking dynamical cavity method (BDCM), we estimate the minimal fraction of initial $+1$ nodes required to achieve a $+1$ consensus in $p$ time steps. Our analysis predicts that for $d\\geq4$ an initial global minority of $+1$ nodes is sufficient to quickly steer the entire system toward consensus on $+1$.\n  We then investigate whether such initial conditions can be determined explicitly for a given large random regular graph. To this end, we introduce a new algorithm, which we name history-passing reinforcement (HPR), designed to find such initial configurations with a minority of $+1$ nodes. We find, as a main result, that the HPR algorithm finds initial configurations where the minority takes over the majority for $d$-regular random graphs with $d\\geq4$.\n  The HPR algorithm outperforms standard simulated annealing-based methods, but does not reach the lowest densities predicted by the BDCM. Rather, the lowest density achievable by the algorithm is near the onset of a dynamical one-step replica symmetry breaking (d1RSB) phase, which we estimate using a one-step replica symmetry breaking (1RSB) formulation of the BDCM. While we focus on the majority dynamics and random $d$-regular graphs, the algorithm can be extended to other dynamical rules and classes of sparse graphs."}
{"id": "2512.15718", "categories": ["q-fin.CP"], "pdf": "https://arxiv.org/pdf/2512.15718", "abs": "https://arxiv.org/abs/2512.15718", "authors": ["Marco Airoldi"], "title": "A High-Level Framework for Practically Model-Independent Pricing", "comment": "28 pages 10 figures", "summary": "We present a high-level framework that explains why, in practice, different pricing models calibrated to the same vanilla surface tend to produce similar valuations for exotic derivatives. Our approach acts as an overlay on the Monte Carlo infrastructure already used in banks, combining path reweighting with a conic optimisation layer without requiring any changes to existing code. This construction delivers narrow, practically model-independent price bands for exotics, reconciling front-office practice with the robust, model-independent ideas developed in the academic literature."}
{"id": "2512.16346", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.16346", "abs": "https://arxiv.org/abs/2512.16346", "authors": ["Shaoshuai Chu", "Alexander Kurganov", "Maria Lukacova-Medvidova", "Mingye Na"], "title": "A Locally Divergence-Free Local Characteristic Decomposition Based Path-Conservative Central-Upwind Scheme for Ideal Magnetohydrodynamics", "comment": null, "summary": "We introduce a locally divergence-free local characteristic decomposition based path-conservative central-upwind (LCD-PCCU) scheme for ideal magnetohydrodynamics (MHD) equations. The proposed method is a low-dissipation extension of the recently proposed locally divergence-free PCCU scheme. To reduce the numerical dissipation, we incorporate the LCD into the PCCU framework. The resulting LCD-PCCU method enhances the resolution of numerical solutions as demonstrated through a series of benchmark tests."}
{"id": "2512.16231", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16231", "abs": "https://arxiv.org/abs/2512.16231", "authors": ["Luke Hagar", "Andrew J. Martin"], "title": "An Efficient Framework for Robust Sample Size Determination", "comment": null, "summary": "In many settings, robust data analysis involves computational methods for uncertainty quantification and statistical inference. To design frequentist studies that leverage robust analysis methods, suitable sample sizes to achieve desired power are often found by estimating sampling distributions of p-values via intensive simulation. Moreover, most sample size recommendations rely heavily on assumptions about a single data-generating process. Consequently, robustness in data analysis does not by itself imply robustness in study design, as examining sample size sensitivity to data-generating assumptions typically requires further simulations. We propose an economical alternative for determining sample sizes that are robust to multiple data-generating mechanisms. Applying our theoretical results that model p-values as a function of the sample size, we assess power across the sample size space using simulations conducted at only two sample sizes for each data-generating mechanism. We demonstrate the broad applicability of our methodology to study design based on M-estimators in both experimental and observational settings through a varied set of clinical examples."}
{"id": "2512.16050", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16050", "abs": "https://arxiv.org/abs/2512.16050", "authors": ["Emma Berger", "Michael Arumainayagam", "Zhihuan Dong", "Lucas Schneider", "Tianle Wang", "Greyson Nichols", "Salman Kahn", "Rwik Dutta", "Gaoqiang Wang", "Takashi Taniguchi", "Kenji Watanabe", "Mit H. Naik", "Michael P. Zaletel", "Feng Wang", "Michael F. Crommie"], "title": "Imaging Electron-Hole Asymmetry in the Quantum Melting of Generalized Wigner Crystals", "comment": "49 pages (Main Text - 22 pages, 5 figures + SI - 27 pages, 12 Figures)", "summary": "Two-dimensional moiré materials provide a versatile platform to explore phase transitions in strongly correlated systems. Using scanning tunneling microscopy (STM) we have imaged the density-driven melting of generalized Wigner crystals (GWCs) and Mott insulators (MIs) in electron-doped, near-60° twisted MoSe2 bilayers featuring a triangular moiré superlattice. We observe striking electron-hole asymmetry in GWC melting: hole-doped GWCs yield interaction-driven disordered states whereas electron-doped GWCs melt into delocalized liquid-like states. This asymmetry arises from the broken particle-hole symmetry of the moiré superlattice, which produces electron and hole Fermi pockets with different momentum geometries upon GWC condensation. MI states melt without such asymmetry, consistent with the absence of a symmetry-breaking density modulation. This work provides direct visualization of the novel emergent phases that appear as GWCs undergo quantum melting transitions."}
{"id": "2512.15843", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.15843", "abs": "https://arxiv.org/abs/2512.15843", "authors": ["Reinis Irmejs", "J. Ignacio Cirac"], "title": "Efficient Simulation of Sparse, Non-Local Fermion Models", "comment": "15 pages, 2 figures", "summary": "Efficient simulation of interacting fermionic systems is a key application of near-term quantum computers, but is hindered by the overhead required to encode fermionic operators on qubit hardware. Here, we consider models with $N$ fermionic modes in which each participates in at most a constant number $d$ of interactions and study the circuit depth required to implement the Trotterized time evolution on qubit hardware with all-to-all connectivity. We introduce an encoding that augments each physical fermionic mode with a small number of auxiliary fermions, enabling the removal of Jordan--Wigner strings. Although the preparation of the auxiliary fermion state incurs an initial overhead, this state remains invariant under time evolution. As a result, long-time evolution can be implemented with asymptotically optimal circuit depth, reducing a previously multiplicative $O(\\log N)$ overhead to an additive overhead. Our results thus establish that the simulation of sparse fermionic models on qubit hardware matches the performance achievable on ideal fermionic hardware up to constant factors and $O(dN)$ ancillary qubits."}
{"id": "2512.16141", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.16141", "abs": "https://arxiv.org/abs/2512.16141", "authors": ["Sina Arefizadeh", "Angelia Nedić"], "title": "Existence of Solutions for Non-monotone VIs and Implications for Games", "comment": null, "summary": "In this paper, we study the existence of solutions in non-monotone variational inequalities (VIs) through the normal mapping properties. In particular, we show that when the normal mapping $F_K^{\\rm nor}(\\cdot)$ is norm coercive over a set $K$, and the generalized Jacobian of the normal mapping has a full rank at points $x$ where $F_K^{\\rm nor}(x)\\ne0$, then the VI$(K,F)$ has a solution. We then investigate conditions on the mapping $F(\\cdot)$ and its Jacobian that imply the full rank condition for the generalized Jacobian, such as the uniform P-function and the uniform P-matrix condition. Subsequently, we focus on VIs arising from games and interpret our main result in a game setting. Based on the P$_Υ$-matrix condition, we provide a sufficient condition for a game to have a Nash equilibrium. Additionally, through examples we show that our sufficient conditions can be used to assert the existence of a solution to a VI, or a quasi-Nash in a game, while the existing results relying on the uniform P-function property or the P$_Υ$-matrix condition cannot be employed."}
{"id": "2512.16102", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16102", "abs": "https://arxiv.org/abs/2512.16102", "authors": ["Fanghua Li", "Xiaolin Zhou", "Yongkang Chen", "Wei Ni", "Xin Wang", "Dusit Niyato", "Ekram Hossain"], "title": "Synchronization, Identification, and Signal Detection for Underwater Photon-Counting Communications With Input-Dependent Shot Noise", "comment": null, "summary": "Photon counting (PhC) is an effective detection technology for underwater optical wireless communication (OWC) systems. The presence of signal-dependent Poisson shot noise and asynchronous multi-user interference (MUI) complicates the processing of received data signals, hindering the effective signal detection of PhC OWC systems. This paper proposes a novel iterative signal detection method in grant-free, multi-user, underwater PhC OWC systems with signal-dependent Poisson shot noise. We first introduce a new synchronization algorithm with a unique frame structure design.The algorithm performs active user identification and transmission delay estimation. Specifically, the estimation is performed first on a user group basis and then at the individual user level with reduced complexity and latency.We also develop a nonlinear iterative multi-user detection (MUD) algorithm that utilizes a detection window for each user to identify interfering symbols and estimate MUI on a slot-by-slot basis, followed by maximum \\textit{a-posteriori} probability detection of user signals.Simulations demonstrate that our scheme achieves bit error rates comparable to scenarios with transmission delays known and signal detection perfectly synchronized."}
{"id": "2512.16102", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16102", "abs": "https://arxiv.org/abs/2512.16102", "authors": ["Fanghua Li", "Xiaolin Zhou", "Yongkang Chen", "Wei Ni", "Xin Wang", "Dusit Niyato", "Ekram Hossain"], "title": "Synchronization, Identification, and Signal Detection for Underwater Photon-Counting Communications With Input-Dependent Shot Noise", "comment": null, "summary": "Photon counting (PhC) is an effective detection technology for underwater optical wireless communication (OWC) systems. The presence of signal-dependent Poisson shot noise and asynchronous multi-user interference (MUI) complicates the processing of received data signals, hindering the effective signal detection of PhC OWC systems. This paper proposes a novel iterative signal detection method in grant-free, multi-user, underwater PhC OWC systems with signal-dependent Poisson shot noise. We first introduce a new synchronization algorithm with a unique frame structure design.The algorithm performs active user identification and transmission delay estimation. Specifically, the estimation is performed first on a user group basis and then at the individual user level with reduced complexity and latency.We also develop a nonlinear iterative multi-user detection (MUD) algorithm that utilizes a detection window for each user to identify interfering symbols and estimate MUI on a slot-by-slot basis, followed by maximum \\textit{a-posteriori} probability detection of user signals.Simulations demonstrate that our scheme achieves bit error rates comparable to scenarios with transmission delays known and signal detection perfectly synchronized."}
{"id": "2512.16858", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.16858", "abs": "https://arxiv.org/abs/2512.16858", "authors": ["Julian Talbot"], "title": "Random planting with harvest: A statistical-mechanical analysis", "comment": "16 pages, 10 figures", "summary": "We formulate a statistical-mechanical description of a recently introduced random planting model in which plants are represented by growing hard disks. Seedlings of negligible size are introduced at random positions in a field, grow at a prescribed rate, and are harvested upon reaching a fixed maturity diameter. Planting attempts that would lead to an overlap at any time during growth are rejected. Starting from an empty field, this simple dynamical rule drives the system to a nonequilibrium steady state in which the mean planting and harvesting rates coincide. We show that the steady state can be mapped onto a nonadditive polydisperse hard-disk fluid and exploit this mapping to develop analytical predictions based on a low-density virial expansion and on scaled particle theory. The resulting description yields an effective adsorption isotherm for the steady-state plant density as a function of the planting rate and compares favorably with numerical simulations over a wide range of parameters. At large planting rates, the density approaches the optimal value achieved by desynchronized regular planting, and the data are consistent with an algebraic approach to this limit with an exponent close to 1/3. Beyond density and yield, we show that the spatial organization of the field at high planting rates exhibits clear signatures of the same underlying geometric constraints that characterize optimal desynchronized planting. This connection is revealed through both the conventional radial distribution function and a radius-resolved pair correlation g(z,r) which highlights strong size correlations associated with parent-child seeding events and whose structure can be interpreted as a dynamically broadened precursor of the corresponding ideal mixe--size lattice. Finally, we extend the theory to sigmoidal growth laws and compute the associated virial coefficient."}
{"id": "2512.16186", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2512.16186", "abs": "https://arxiv.org/abs/2512.16186", "authors": ["Leonid Bunimovich", "Kirill Kovalenko"], "title": "For how long time evolution of chaotic or random systems can be predicted", "comment": null, "summary": "Traditionally, Probability theory was dealing with limit theorems where 'limit\" means that time tends to infinity. Questions about finite time dynamics (evolution) were always considered as, although important for practical applications, but untreatable rigorously (mathematically). The same attitude was in the theory of strongly chaotic dynamical systems, which evolve similarly to stochastic processes. However, a natural question on dependence of the process of escape on a position of a \"hole\" in the state (phase) space, which was never asked in mathematical theory of open dynamical systems, opened up a new direction of research, which was dealing with finite time predictions of evolutions of such systems. It turned out, that transport of orbits in the phase space of the \"most strongly chaotic\" dynamical systems has three different stages. In the first stage there is a hierarchy of the first hitting probabilities, that shows which parts of the phase space the orbits of a system, which is an equilibrium state, will be more likely to visit the first. A principal (and the most important for applications) question was how the length of this interval changes with more refinement observations of the positions of the orbits in the phase space. Surprisingly, it turned out that the length of the time interval, where finite time predictions are possible, increases (rather to be shrinking), which, at the first sight, seems to be natural. However, this increase of the length of the time interval, where finite time predictions are possible, was rather slow (just linear) with respect to the growth of precision (partition of the phase space) of observations. In the present paper it is proved (by totally different technique) that this growth is actually exponential."}
{"id": "2512.16515", "categories": ["nlin.AO", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16515", "abs": "https://arxiv.org/abs/2512.16515", "authors": ["Pradeep Singh", "Mudasani Rushikesh", "Bezawada Sri Sai Anurag", "Balasubramanian Raman"], "title": "The Universe Learning Itself: On the Evolution of Dynamics from the Big Bang to Machine Intelligence", "comment": "38 pages, 3 figures", "summary": "We develop a unified, dynamical-systems narrative of the universe that traces a continuous chain of structure formation from the Big Bang to contemporary human societies and their artificial learning systems. Rather than treating cosmology, astrophysics, geophysics, biology, cognition, and machine intelligence as disjoint domains, we view each as successive regimes of dynamics on ever-richer state spaces, stitched together by phase transitions, symmetry-breaking events, and emergent attractors. Starting from inflationary field dynamics and the growth of primordial perturbations, we describe how gravitational instability sculpts the cosmic web, how dissipative collapse in baryonic matter yields stars and planets, and how planetary-scale geochemical cycles define long-lived nonequilibrium attractors. Within these attractors, we frame the origin of life as the emergence of self-maintaining reaction networks, evolutionary biology as flow on high-dimensional genotype-phenotype-environment manifolds, and brains as adaptive dynamical systems operating near critical surfaces. Human culture and technology-including modern machine learning and artificial intelligence-are then interpreted as symbolic and institutional dynamics that implement and refine engineered learning flows which recursively reshape their own phase space. Throughout, we emphasize recurring mathematical motifs-instability, bifurcation, multiscale coupling, and constrained flows on measure-zero subsets of the accessible state space. Our aim is not to present any new cosmological or biological model, but a cross-scale, theoretical perspective: a way of reading the universe's history as the evolution of dynamics itself, culminating (so far) in biological and artificial systems capable of modeling, predicting, and deliberately perturbing their own future trajectories."}
{"id": "2512.16608", "categories": ["physics.soc-ph", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16608", "abs": "https://arxiv.org/abs/2512.16608", "authors": ["Jannie Coenen", "Vítor Vasconcelos", "Heiman Wertheim", "Marcel Olde Rikkert", "Sophie Hadjisotiriou", "Vittorio Nespeca", "Tom Oreel", "Rick Quax", "Etiënne Rouwette", "Vincent Marchau", "Hubert Korzilius"], "title": "Resilience of coupled systems under deep uncertainty and dynamic complexity: An integrative literature review", "comment": null, "summary": "Resilience in coupled systems is increasingly critical in addressing global challenges such as climate change and pandemics. These systems show unpredictable behaviour due to dynamic complexity and deep uncertainty across spatiotemporal scales. Despite growing interest, few studies systematically integrate both concepts when assessing resilience. This paper conducts an integrative review of 102 English-language publications to identify gaps in current approaches. Findings reveal that most papers address lower levels of uncertainty and rarely consider dynamic complexity and deep uncertainty simultaneously, which limits the effectiveness of resilience strategies. To advance systems research, we propose a conceptual framework and practical tools to support researchers and decision-makers in evaluating and improving resilience. The paper also outlines future research directions for more robust, adaptive, and integrative resilience assessments."}
{"id": "2512.16556", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.16556", "abs": "https://arxiv.org/abs/2512.16556", "authors": ["Assem Afanah", "Bernd Rosenow"], "title": "Unified Description of Learning Dynamics in the Soft Committee Machine from Finite to Ultra-Wide Regimes", "comment": null, "summary": "We study the learning dynamics of the soft committee machine (SCM) with Rectified Linear Unit (ReLU) activation using a statistical-mechanics approach within the annealed approximation. The SCM consists of a student network with $N$ input units and $K$ hidden units trained to reproduce the output of a teacher network with $M$ hidden units. We introduce a reduced set of macroscopic order parameters that yields a unified description valid from the conventional regime $K \\ll N$ to the ultra-wide limit $K \\ge N$. The control parameter $α$, proportional to the ratio of training samples to adjustable weights, serves as an effective measure of dataset size.\n  For small $γ= M/N$, we recover a continuous phase transition at $α_{c} \\approx 2π$ from an unspecialized, permutation-symmetric state to a specialized state in which student units align with the teacher. For finite $γ$, the transition disappears and the generalization error decreases smoothly with dataset size, reaching a low plateau when $γ=1$. In the asymptotic limit $α\\to \\infty$, the error scales as $\\varepsilon_{g} \\propto 1/α$, independent of $γ$ and $K$. The results highlight the central role of network dimensions in SCM learning and provide a framework extendable to other activations and quenched analyses."}
{"id": "2512.16115", "categories": ["q-fin.CP"], "pdf": "https://arxiv.org/pdf/2512.16115", "abs": "https://arxiv.org/abs/2512.16115", "authors": ["Liying Zhang", "Ying Gao"], "title": "An Efficient Machine Learning Framework for Option Pricing via Fourier Transform", "comment": null, "summary": "The increasing need for rapid recalibration of option pricing models in dynamic markets places stringent computational demands on data generation and valuation algorithms. In this work, we propose a hybrid algorithmic framework that integrates the smooth offset algorithm (SOA) with supervised machine learning models for the fast pricing of multiple path-independent options under exponential Lévy dynamics. Building upon the SOA-generated dataset, we train neural networks, random forests, and gradient boosted decision trees to construct surrogate pricing operators. Extensive numerical experiments demonstrate that, once trained, these surrogates achieve order-of-magnitude acceleration over direct SOA evaluation. Importantly, the proposed framework overcomes key numerical limitations inherent to fast Fourier transform-based methods, including the consistency of input data and the instability in deep out-of-the-money option pricing."}
{"id": "2512.16536", "categories": ["hep-lat", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.16536", "abs": "https://arxiv.org/abs/2512.16536", "authors": ["Stephan Durr", "Tolga S. H. Kiel"], "title": "Critical coupling in $φ_2^4$ theory", "comment": "13 pages, 6 tables, 6 figures", "summary": "We consider $φ^4$ theory with $φ(x)\\in\\mathbb{R}$ in two Euclidean dimensions. We determine for a variety of self-couplings $\\hatλ$ the (negative) critical bare mass $\\hatμ_{0\\mathrm{c}}^2(\\hatλ)$ where the lattice-regularized system changes from the symmetric to the broken phase. Based on these data, the transition to infinite volume and a universal scheme with the renormalized parameter $\\hatμ_\\mathrm{c}^2(\\hatλ)$ is made. Finally, $f_\\mathrm{c}=\\lim_{\\hatλ\\to0}\\hatλ/\\hatμ_\\mathrm{c}^2(\\hatλ)$ is determined, with a judicious choice of the parameterizations considered. Our final result reads $f_\\mathrm{c}=11.1097(20)_\\mathrm{stat}(09)_\\mathrm{sys}=11.1097(22)_\\mathrm{tot}$."}
{"id": "2512.16411", "categories": ["stat.ME", "math.ST", "q-fin.ST", "q-fin.TR", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.16411", "abs": "https://arxiv.org/abs/2512.16411", "authors": ["Matthieu Garcin", "Louis Perot"], "title": "Asymptotic and finite-sample distributions of one- and two-sample empirical relative entropy, with application to change-point detection", "comment": null, "summary": "Relative entropy, as a divergence metric between two distributions, can be used for offline change-point detection and extends classical methods that mainly rely on moment-based discrepancies. To build a statistical test suitable for this context, we study the distribution of empirical relative entropy and derive several types of approximations: concentration inequalities for finite samples, asymptotic distributions, and Berry-Esseen bounds in a pre-asymptotic regime. For the latter, we introduce a new approach to obtain Berry-Esseen inequalities for nonlinear functions of sum statistics under some convexity assumptions. Our theoretical contributions cover both one- and two-sample empirical relative entropies. We then detail a change-point detection procedure built on relative entropy and compare it, through extensive simulations, with classical methods based on moments or on information criteria. Finally, we illustrate its practical relevance on two real datasets involving temperature series and volatility of stock indices."}
{"id": "2512.16352", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.16352", "abs": "https://arxiv.org/abs/2512.16352", "authors": ["Hendrik Ranocha", "David I. Ketcheson"], "title": "Conserving mass, momentum, and energy for the Benjamin-Bona-Mahony, Korteweg-de Vries, and nonlinear Schrödinger equations", "comment": "The reproducibility repository is available at https://github.com/ranocha/2025_BBM_KdV_NLS", "summary": "We propose and study a class of arbitrarily high order numerical discretizations that preserve multiple invariants and are essentially explicit (they do not require the solution of any large systems of algebraic equations). In space, we use Fourier Galerkin methods, while in time we use a combination of orthogonal projection and relaxation. We prove and numerically demonstrate the conservation properties of the method by applying it to the Benjamin-Bona-Mahoney, Korteweg-de Vries, and nonlinear Schrödinger (NLS) PDEs as well as a hyperbolic approximation of NLS. For each of these equations, the proposed schemes conserve mass, momentum, and energy up to numerical precision. We show that this conservation leads to reduced growth of numerical errors for long-term simulations."}
{"id": "2512.16239", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16239", "abs": "https://arxiv.org/abs/2512.16239", "authors": ["Bohan Wu", "Eli N. Weinstein", "David M. Blei"], "title": "Bayesian Empirical Bayes: Simultaneous Inference from Probabilistic Symmetries", "comment": null, "summary": "Empirical Bayes (EB) improves the accuracy of simultaneous inference \"by learning from the experience of others\" (Efron, 2012). Classical EB theory focuses on latent variables that are iid draws from a fitted prior (Efron, 2019). Modern applications, however, feature complex structure, like arrays, spatial processes, or covariates. How can we apply EB ideas to these settings? We propose a generalized approach to empirical Bayes based on the notion of probabilistic symmetry. Our method pairs a simultaneous inference problem-with an unknown prior-to a symmetry assumption on the joint distribution of the latent variables. Each symmetry implies an ergodic decomposition, which we use to derive a corresponding empirical Bayes method. We call this methodBayesian empirical Bayes (BEB). We show how BEB recovers the classical methods of empirical Bayes, which implicitly assume exchangeability. We then use it to extend EB to other probabilistic symmetries: (i) EB matrix recovery for arrays and graphs; (ii) covariate-assisted EB for conditional data; (iii) EB spatial regression under shift invariance. We develop scalable algorithms based on variational inference and neural networks. In simulations, BEB outperforms existing approaches to denoising arrays and spatial data. On real data, we demonstrate BEB by denoising a cancer gene-expression matrix and analyzing spatial air-quality data from New York City."}
{"id": "2512.16131", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16131", "abs": "https://arxiv.org/abs/2512.16131", "authors": ["Li-Wei He", "Shun-Li Yu", "Jian-Xin Li"], "title": "Recent progress in quantum spin liquids, fractional magnetization plateaus, and unconventional superconductivity in kagome lattices", "comment": "published", "summary": "The kagome lattice, with its unique geometric structure, has emerged as a leading platform for exploring quantum many-body physics, particularly in the study of quantum spin liquids (QSLs) and unconventional superconductivity. This review highlights recent advancements in the investigations of QSLs, fractional magnetization plateau phases in kagome antiferromagnets, and unconventional superconductivity in vanadium-based kagome superconductors. We begin by examining the classical ground-state properties of the nearest-neighbor kagome antiferromagnetic Heisenberg model and introducing recent experimental progress in the study of QSLs and fractional magnetization plateau phases. Next, we discuss the fermionic description of the QSL states, along with related gauge theory and the variational Monte Carlo (VMC) method. We then focus on discussing the VMC studies of QSLs and magnetization plateau phases in kagome antiferromagnets. For superconductivity in kagome systems, we first analyze the characteristics of the electronic structure and the possible associated electronic instabilities. Finally, we review recent experimental advances in unconventional superconductivity in AV$_3$Sb$_5$ (A = K, Rb, Cs), with a particular focus on chiral superconductivity and pairing density waves."}
{"id": "2512.15871", "categories": ["quant-ph", "cond-mat.stat-mech", "nlin.SI"], "pdf": "https://arxiv.org/pdf/2512.15871", "abs": "https://arxiv.org/abs/2512.15871", "authors": ["Michael A. Rampp", "Suhail A. Rather", "Pieter W. Claeys"], "title": "Solvable Quantum Circuits from Spacetime Lattices", "comment": "22+12 pages, 6+2 figures", "summary": "In recent years dual-unitary circuits and their multi-unitary generalizations have emerged as exactly solvable yet chaotic models of quantum many-body dynamics. However, a systematic picture for the solvability of multi-unitary dynamics remains missing. We present a framework encompassing a large class of such non-integrable models with exactly solvable dynamics, which we term \\emph{completely reducible} circuits. In these circuits, the entanglement membrane determining operator growth and entanglement dynamics can be characterized analytically. Completely reducible circuits extend the notion of space-time symmetry to more general lattice geometries, breaking dual-unitarity globally but not locally, and allow for a rich phenomenology going beyond dual-unitarity. As example, we introduce circuits that support four and five directions of information flow. We derive a general expression for the entanglement line tension in terms of the pattern of information flow in spacetime. The solvability is shown to be related to the absence of knots of this information flow, connecting entanglement dynamics to the Kauffman bracket as knot invariant. Building on these results, we propose that in general non-integrable dynamics the curvature of the entanglement line tension can be interpreted as a density of information transport. Our results provide a new and unified framework for exactly solvable models of many-body quantum chaos, encompassing and extending known constructions."}
{"id": "2512.16241", "categories": ["math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16241", "abs": "https://arxiv.org/abs/2512.16241", "authors": ["Yingjie Zhou", "Xiaoqian Wang", "Tao Li"], "title": "Distributed Online Economic Dispatch With Time-Varying Coupled Inequality Constraints", "comment": null, "summary": "We investigate the distributed online economic dispatch problem for power systems with time-varying coupled inequality constraints. The problem is formulated as a distributed online optimization problem in a multi-agent system. At each time step, each agent only observes its own instantaneous objective function and local inequality constraints; agents make decisions online and cooperate to minimize the sum of the time-varying objectives while satisfying the global coupled constraints. To solve the problem, we propose an algorithm based on the primal-dual approach combined with constraint-tracking. Under appropriate assumptions that the objective and constraint functions are convex, their gradients are uniformly bounded, and the path length of the optimal solution sequence grows sublinearly, we analyze theoretical properties of the proposed algorithm and prove that both the dynamic regret and the constraint violation are sublinear with time horizon T. Finally, we evaluate the proposed algorithm on a time-varying economic dispatch problem in power systems using both synthetic data and Australian Energy Market data. The results demonstrate that the proposed algorithm performs effectively in terms of tracking performance, constraint satisfaction, and adaptation to time-varying disturbances, thereby providing a practical and theoretically well-supported solution for real-time distributed economic dispatch."}
{"id": "2512.16139", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16139", "abs": "https://arxiv.org/abs/2512.16139", "authors": ["Mengqi Xue", "Yuchao Xiong", "Yue Song"], "title": "Consensus tracking of perturbed open multi-agent systems with repelling antagonistic interactions", "comment": null, "summary": "An open multi-agent system (OMAS) comprises migrating agents which produce a flexible network structure that is naturally switching and size-varying. Meanwhile, agent migrations also make an OMAS more prone to environmental adversities. In this work, we deal with the consensus tracking problem of OMASs suffering these migration-induced adversities, including non-vanishing perturbations in the agent dynamics/state and the repelling antagonistic interactions among agents, over an intermittently disconnected signed digraph. The OMAS is interpreted into a perturbed $M^3D$ system in which unstable subsystems are created when repelling interactions dominate the normal cooperative ones in the OMAS network regardless of its connectivity. To handle the destabilizing effects brought by the repelling interaction as well as the non-vanishing perturbations, we extend the stability theory for $M^3D$ systems and apply it to the OMAS to show that practical consensus tracking can be achieved if the migration-induced switching satisfies the piecewise average dwell time and activation time ratio constraints. Particularly, we indicate that for vanishing perturbations and repelling interactions, asymptotic tracking can be expected under weaker switching constraints."}
{"id": "2512.16139", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16139", "abs": "https://arxiv.org/abs/2512.16139", "authors": ["Mengqi Xue", "Yuchao Xiong", "Yue Song"], "title": "Consensus tracking of perturbed open multi-agent systems with repelling antagonistic interactions", "comment": null, "summary": "An open multi-agent system (OMAS) comprises migrating agents which produce a flexible network structure that is naturally switching and size-varying. Meanwhile, agent migrations also make an OMAS more prone to environmental adversities. In this work, we deal with the consensus tracking problem of OMASs suffering these migration-induced adversities, including non-vanishing perturbations in the agent dynamics/state and the repelling antagonistic interactions among agents, over an intermittently disconnected signed digraph. The OMAS is interpreted into a perturbed $M^3D$ system in which unstable subsystems are created when repelling interactions dominate the normal cooperative ones in the OMAS network regardless of its connectivity. To handle the destabilizing effects brought by the repelling interaction as well as the non-vanishing perturbations, we extend the stability theory for $M^3D$ systems and apply it to the OMAS to show that practical consensus tracking can be achieved if the migration-induced switching satisfies the piecewise average dwell time and activation time ratio constraints. Particularly, we indicate that for vanishing perturbations and repelling interactions, asymptotic tracking can be expected under weaker switching constraints."}
{"id": "2512.15871", "categories": ["quant-ph", "cond-mat.stat-mech", "nlin.SI"], "pdf": "https://arxiv.org/pdf/2512.15871", "abs": "https://arxiv.org/abs/2512.15871", "authors": ["Michael A. Rampp", "Suhail A. Rather", "Pieter W. Claeys"], "title": "Solvable Quantum Circuits from Spacetime Lattices", "comment": "22+12 pages, 6+2 figures", "summary": "In recent years dual-unitary circuits and their multi-unitary generalizations have emerged as exactly solvable yet chaotic models of quantum many-body dynamics. However, a systematic picture for the solvability of multi-unitary dynamics remains missing. We present a framework encompassing a large class of such non-integrable models with exactly solvable dynamics, which we term \\emph{completely reducible} circuits. In these circuits, the entanglement membrane determining operator growth and entanglement dynamics can be characterized analytically. Completely reducible circuits extend the notion of space-time symmetry to more general lattice geometries, breaking dual-unitarity globally but not locally, and allow for a rich phenomenology going beyond dual-unitarity. As example, we introduce circuits that support four and five directions of information flow. We derive a general expression for the entanglement line tension in terms of the pattern of information flow in spacetime. The solvability is shown to be related to the absence of knots of this information flow, connecting entanglement dynamics to the Kauffman bracket as knot invariant. Building on these results, we propose that in general non-integrable dynamics the curvature of the entanglement line tension can be interpreted as a density of information transport. Our results provide a new and unified framework for exactly solvable models of many-body quantum chaos, encompassing and extending known constructions."}
{"id": "2512.16640", "categories": ["nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.16640", "abs": "https://arxiv.org/abs/2512.16640", "authors": ["Esmaeil Mahdavi", "Mina Zarei", "Philipp Hövel", "Farhad Shahbazi"], "title": "Time-Delayed Dynamics in Regular Kuramoto Networks with Inertia: Multistability, Traveling Waves, Chimera States, and Transitions to Seizure-Like Activity", "comment": "12 pages, 9 figures", "summary": "This study examines the complex interplay between inertia and time delay in regular rotor networks within the framework of the second-order Kuramoto model. By combining analytical and numerical methods, we demonstrate that intrinsic time delays -- arising from finite information transmission speeds - induce multistability among fully synchronized phase-locked states. Unlike systems without inertia, the presence of inertia destabilizes these phase-locked states, reduces their basin of attraction, and gives rise to nonlinear phase-locked dynamics over specific inertia ranges. In addition, we show that time delays promote the emergence of turbulent chimera states, while inertia enhances their spatial extent. Notably, the combined influence of inertia and time delay produces dynamic patterns reminiscent of partial epileptic seizures. These findings provide new insights into synchronization phenomena by revealing how inertia and time delay fundamentally reshape the stability and dynamics of regular rotor networks, with broader implications for neuronal modeling and other complex systems."}
{"id": "2512.16703", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.16703", "abs": "https://arxiv.org/abs/2512.16703", "authors": ["Juan C. Rocha", "Maike Hamann", "Jiangxiao Qiu", "Tong Wu", "Tomas Chaigneau", "Emilie Lindkvist", "Caroline Schill", "Alon Shepon", "Andrew R. Tilman", "Geraldine D. Verkleij", "Anne-Sophie Crépin", "Carl Folke"], "title": "Inequality traps detected in sustainable development goals data", "comment": "4 figures, 9 pages, 11 SM figures, 23 pages total", "summary": "The relationship between inequality and the biosphere has been hypothesized to mutual dependecies and feedbacks. If that is true, such feedbacks may give rise to inequality regimes and potential tipping points between them. Here we explore synergies and trade-offs between inequality and biosphere-related sustainable development goals. We used the openly available SDG datasets by the World Bank (WB) and United Nations (UN) and applied ordination methods to distill interactions between economic inequality and the environmental impact across countries. Our results confirm the existence of inequality regimes, and we find preliminary evidence that corruption may be a candidate driver of tipping between regimes."}
{"id": "2512.16726", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.16726", "abs": "https://arxiv.org/abs/2512.16726", "authors": ["Alexandru Ciobanu", "David Dahmen", "John Paul Strachan", "Moritz Helias"], "title": "Reduction of interaction order in hard combinatorial optimization via conditionally independent degrees of freedom", "comment": null, "summary": "Combinatorial optimization problems have a broad range of applications and map to physical systems with complex dynamics. Among them, the 3-SAT problem is prominent due to its NP-complete nature. In physics terms, its solution corresponds to finding the ground state of a disordered Ising spin Hamiltonian with third-order, or tensor, interactions. The large growth of the number of third-order interactions with number of variables poses technical difficulties for the physical implementation of minimizers. Therefore, researchers have proposed quadratization techniques which reduce the order of the system, however, at the cost of including additional degrees of freedom. Their inclusion induces a drastic slow down in the minimization, which makes such procedures technically infeasible for large problems. In this work, we take a physics approach by employing the renormalization group to create a pairwise interacting system from the original third-order system while preserving the free energy. Our procedure utilizes additional degrees of freedom that exhibit an independent dynamics provided the original degrees of freedom are fixed. A step-wise trace of the extra variables while running the minimization is therefore theoretically manageable, yielding a state-dependent effective interaction. We use the effective interaction to reconstruct the original third-order energy spectrum, as this yields equal scaling of computations-to-ground-state compared to the original tensor formulation. Here, the original degrees of freedom interact with a subsystem that appears to be in a superposition of an exponentially large number of states. In the zero-temperature limit, the superposition concentrates on one state. Our spectrum-engineering techniques reveal new routes toward the ground state of disordered Ising systems, through Markov chains, and allow for efficient technological implementations."}
{"id": "2512.16863", "categories": ["hep-lat", "hep-ph"], "pdf": "https://arxiv.org/pdf/2512.16863", "abs": "https://arxiv.org/abs/2512.16863", "authors": ["Thomas Appelquist", "James Ingoldby", "Maurizio Piai"], "title": "Dilaton Effective Field Theory across the Conformal Edge", "comment": "8 pages, 6 figures", "summary": "Dilaton effective field theory (dEFT) can be employed to analyze lattice data in gauge theories that lie in close proximity of the lower edge of the conformal window. Under special conditions, we show that it can be used as a diagnostic tool to distinguish near-conformal, yet confining, theories from infrared conformal ones. We demonstrate this efficacy by analyzing two sets of lattice measurements taken from the literature. For the $SU(3)$ theory coupled to $N_f=8$ Dirac fermions transforming in the fundamental representation, our analysis favors confinement. For the $SU(2)$ theory with $N_f=1$ adjoint fermion, our fits favor infrared conformal behavior. We discuss future lattice measurements, and analysis refinements, that can further test this framework."}
{"id": "2512.16359", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.16359", "abs": "https://arxiv.org/abs/2512.16359", "authors": ["Amelie Porfetye", "Zhuyan Tang", "Shaoshuai Chu", "Christiane Helzel", "Maria Lukacova-Medvidova"], "title": "New Fully Discrete Active Flux Methods with Truly Multi-Dimensional Evolution Operators and WENO Reconstruction", "comment": null, "summary": "We propose new fully discrete third-order accurate Active Flux and WENO methods based on truly multidimensional evolution operators for the two-dimensional acoustic equations. Building on the method of bicharacteristics, several approximate evolution operators are derived that yield an improved stability of the resulting schemes. A linear stability analysis is applied to determine the maximal CFL number. The schemes are tested extensively on both continuous and discontinuous problems, confirming their robustness and accurate approximation even on coarse grids."}
{"id": "2512.16276", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16276", "abs": "https://arxiv.org/abs/2512.16276", "authors": ["Yuta Hayashida", "Shonosuke Sugasawa"], "title": "Repulsive g-Priors for Regression Mixtures", "comment": "23 pages (main) + 27 pages (supplement)", "summary": "Mixture regression models are powerful tools for capturing heterogeneous covariate-response relationships, yet classical finite mixtures and Bayesian nonparametric alternatives often suffer from instability or overestimation of clusters when component separability is weak. Recent repulsive priors improve parsimony in density mixtures by discouraging nearby components, but their direct extension to regression is nontrivial since separation must respect the predictive geometry induced by covariates. We propose a repulsive g-prior for regression mixtures that enforces separation in the Mahalanobis metric, penalizing components indistinguishable in the predictive mean space. This construction preserves conjugacy-like updates while introducing geometry-aware interactions, enabling efficient blocked-collapsed Gibbs sampling. Theoretically, we establish tractable normalizing bounds, posterior contraction rates, and shrinkage of tail mass on the number of components. Simulations under correlated and overlapping designs demonstrate improved clustering and prediction relative to independent, Euclidean-repulsive, and sparsity-inducing baselines."}
{"id": "2512.16137", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16137", "abs": "https://arxiv.org/abs/2512.16137", "authors": ["S. Fujiyama", "K. Ueda", "Y. Otsuka"], "title": "Power-Law Suppression of Phonon Thermal Transport by Magnetic Excitations in a Molecular Quantum Spin Liquid", "comment": null, "summary": "We present large-scale ab initio phonon calculations for the molecular quantum spin liquid X[Pd(dmit)2]2. An unusually low average phonon velocity ( 700 {m/s}) and optical modes below 10 cm^{-1} confine the Debye T^{3} regime to T < 2 K. As the transfer-integral anisotropy approaches the maximally frustrated regime (t'/t \\to 1), the lattice stiffens, ruling out lattice softening as the origin of the spin-liquid state. By quantifying the additional suppression of the thermal conductivity from experimental data, we observe a power-law behavior consistent with two-dimensional magnetic excitations with a nodal, approximately linear (Dirac-like) spectrum."}
{"id": "2512.15876", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.15876", "abs": "https://arxiv.org/abs/2512.15876", "authors": ["Paul Aigner", "Wolfgang Dür"], "title": "On the power of moving quantum sensors: fully flexible and noise-resilient sensing", "comment": null, "summary": "We show that a single moving quantum sensor provides complete access to spatially correlated scalar fields. We demonstrate that with either trajectory or internal state control, one can selectively measure any linear functional, e.g. a gradient or a spatial Fourier series coefficient, while successfully eliminating {\\it all} noise signals with orthogonal spatial correlation. This even exceeds the capabilities of a sensor network consisting of multiple entangled, yet spatially fixed, quantum sensors, where the number of suppressed noise signals is limited by the number of sensor positions. We show that one can achieve an improved scaling of the quantum Fisher information for moving sensors beyond the static fundamental limit of $T^2$."}
{"id": "2512.16291", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.16291", "abs": "https://arxiv.org/abs/2512.16291", "authors": ["Jinghua Li", "Zhiyong Yu"], "title": "Classical solution to second-order Hamilton-Jacobi-Bellman equation and optimal feedback control for linear-convex problem", "comment": null, "summary": "In this paper, we are concerned with the classical solvability of a class of second-order Hamilton-Jacobi-Bellman equations (HJB equations) arising from stochastic optimal control problems with linear dynamics and uniformly convex cost functionals. By introducing the Hamiltonian system and extending the gradient descent method to a Hilbert space, we prove the existence and uniqueness of the optimal control under the uniform convexity condition. The regularity of the solution to the Hamiltonian system is obtained, including the derivatives with respect to the initial state and the Malliavin derivatives. The connection between the Hamiltonian system and the value function is subsequently proven, enabling us to derive regularity properties of the value function via probabilistic techniques. Finally, by the dynamic programming principle, the value function is verified to be the unique classical solution to the HJB equation and the optimal feedback control is provided. These results generalize the classical linear-quadratic theory and provide a new insight into the regularity of the value function."}
{"id": "2512.16263", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16263", "abs": "https://arxiv.org/abs/2512.16263", "authors": ["Bosen Yang", "Kang Ma", "Jin Lin", "Yonghua Song"], "title": "Black-Start Power Capacity Sizing and Control Strategy for an Islanded DFIG Wind-to-Hydrogen System", "comment": null, "summary": "This paper proposes a black-start method for an off-grid wind-to-hydrogen (W2H) system comprising a wind farm based on Doubly-Fed Induction Generators (DFIGs), proton exchange membrane fuel cells (PEMFCs) serving as the black-start power source, and a hydrogen production industry. The PEMFC is installed within the hydrogen industry to facilitate direct access to hydrogen fuel. Based on the microgrid topology and black-start scheme, this study innovatively sizes the rated capacity of the PEMFC through power flow analysis. The capacity must be sufficient to charge passive components such as transmission lines and transformers, provide rotor excitation, and supply wind turbine (WT) and electrolyzer (ELZ) auxiliaries during startup. The proposed system integrates wind-hydrogen coordinated control (WHCC) and hydrogen-storage coordinated control (HSCC). Under maximum power point tracking (MPPT) of the WTs, the ELZ follows power fluctuations to absorb wind output, ensuring stable voltage and frequency. Fixed-frequency control applied to either the DFIG or PEMFC converters enables DFIGs to retain conventional grid-following (GFL) operation, reducing converter development costs. For both control modes, this paper establishes the black-start sequence and formulates a comprehensive coordinated control strategy for the entire system. The entire control system is validated through simulations in MATLAB/Simulink. Results confirm that the calculated PEMFC capacity supports reliable black-start, while the black-start control strategy ensures smooth system self-startup. Furthermore, the coordinated control strategy maintains stable frequency and voltage under fluctuating wind power, demonstrating the practicality and robustness of the proposed approach."}
{"id": "2512.16263", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16263", "abs": "https://arxiv.org/abs/2512.16263", "authors": ["Bosen Yang", "Kang Ma", "Jin Lin", "Yonghua Song"], "title": "Black-Start Power Capacity Sizing and Control Strategy for an Islanded DFIG Wind-to-Hydrogen System", "comment": null, "summary": "This paper proposes a black-start method for an off-grid wind-to-hydrogen (W2H) system comprising a wind farm based on Doubly-Fed Induction Generators (DFIGs), proton exchange membrane fuel cells (PEMFCs) serving as the black-start power source, and a hydrogen production industry. The PEMFC is installed within the hydrogen industry to facilitate direct access to hydrogen fuel. Based on the microgrid topology and black-start scheme, this study innovatively sizes the rated capacity of the PEMFC through power flow analysis. The capacity must be sufficient to charge passive components such as transmission lines and transformers, provide rotor excitation, and supply wind turbine (WT) and electrolyzer (ELZ) auxiliaries during startup. The proposed system integrates wind-hydrogen coordinated control (WHCC) and hydrogen-storage coordinated control (HSCC). Under maximum power point tracking (MPPT) of the WTs, the ELZ follows power fluctuations to absorb wind output, ensuring stable voltage and frequency. Fixed-frequency control applied to either the DFIG or PEMFC converters enables DFIGs to retain conventional grid-following (GFL) operation, reducing converter development costs. For both control modes, this paper establishes the black-start sequence and formulates a comprehensive coordinated control strategy for the entire system. The entire control system is validated through simulations in MATLAB/Simulink. Results confirm that the calculated PEMFC capacity supports reliable black-start, while the black-start control strategy ensures smooth system self-startup. Furthermore, the coordinated control strategy maintains stable frequency and voltage under fluctuating wind power, demonstrating the practicality and robustness of the proposed approach."}
{"id": "2512.15880", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.15880", "abs": "https://arxiv.org/abs/2512.15880", "authors": ["Beatrice Magni", "Markus Heinrich", "Lorenzo Leone", "Xhek Turkeshi"], "title": "Anticoncentration and State Design of Doped Real Clifford Circuits and Tensor Networks", "comment": "5 pages, 1 figure. Comments are welcome", "summary": "We investigate the statistical properties of orthogonal, or real, Clifford circuits doped with magic and imaginary resources. By developing the Weingarten calculus for the real Clifford group, we derive the exact overlap distribution of real stabilizer states, identifying a new universality class: the orthogonal Clifford Porter-Thomas distribution. We prove that local real architectures recover this global statistic in logarithmic depth. Furthermore, we uncover a sharp hierarchy in resource requirements: while retrieving Haar statistics necessitates a polylogarithmic amount of magic states, recovering the full unitary Clifford statistics requires only a single phase gate."}
{"id": "2512.16659", "categories": ["physics.geo-ph", "cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.16659", "abs": "https://arxiv.org/abs/2512.16659", "authors": ["Matthew Oline", "Jeremy Hoskins", "David Seekell", "Mary Silber", "B. B. Cael"], "title": "Self-Affine Scaling of Earth's Islands", "comment": "11 pages, 3 figures", "summary": "Earth's relief is approximately self-affine, meaning a zoom-in on a small region looks statistically similar to a large region upon a suitable rescaling. Fractional Brownian surfaces give an idealized self-affine model of Earth's relief with one parameter, the Hurst exponent $H$, characterizing the roughness of the surface. To quantitatively assess agreement with Earth elevation data, we compile a large dataset of topographic profiles of islands (N=131,063 with the range of areas covering 8+ orders of magnitude) and obtain four estimates for the Hurst exponent of Earth's surface by fitting four statistical laws from the theory of self-affine surfaces concerning islands: (i) distribution of areas, (ii) volume-area relationship, (iii) perimeter-area relationship, and (iv) maximum height-area relationship. The estimated Hurst exponents differ greatly, indicating different fractal scaling behavior for different geometric features, but are sorted in order of increasing expected influence of erosion at the shorelines."}
{"id": "2512.16779", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.16779", "abs": "https://arxiv.org/abs/2512.16779", "authors": ["Qinwen Tang", "Ran Yan", "Nan Zhou", "Minda Ma"], "title": "Unraveling persistent urban-rural gaps: A long-term provincial analysis of residential heating and cooling loads", "comment": null, "summary": "With global climate change and rising demand for thermal comfort, space heating and cooling have become increasingly critical to achieving carbon neutrality in the building sector. This study presents a first attempt to develop a bottom-up regional building energy model based on prototype buildings simulated in EnergyPlus, to assess space heating and cooling loads of urban and rural residential buildings across 30 Chinese provinces from 1980 to 2024. The results indicate that: (1) Guangdong recorded the highest cooling loads in 2020, reaching 76.5 TWh/a in urban areas and 63.0 TWh/a in rural areas; Henan exhibited the highest rural heating load at 174.6 TWh/a, while urban heating loads were highest in provinces such as Liaoning and Shandong. (2) From 1980 to 2024, average cooling loads increased from 12.4 to 15.1 kWh/m2/a in urban areas but declined from 22.63 to 19.87 kWh/m2/a in rural areas. Over the same period, average heating loads decreased from 44.08 to 39.92 kWh/m2/a in urban areas and from 100.15 to 72.42 kWh/m2/a in rural areas. (3) Urban residential building stock has surpassed rural stock in 22 provinces in recent years, compared with only 4 provinces in 2000, and the presence of 12 urban energy-efficiency standards versus only one rural standard further highlights substantial envelope performance gaps. Collectively, these dynamics have led to pronounced and persistent urban-rural disparities in residential heating and cooling loads. These findings underscore the need for differentiated standards and region-specific clean heating strategies, while providing a transferable modeling framework to inform targeted energy-saving policies and support the building sector's transition toward carbon neutrality."}
{"id": "2507.12539", "categories": ["quant-ph", "cond-mat.dis-nn", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2507.12539", "abs": "https://arxiv.org/abs/2507.12539", "authors": ["Yanxuan Shao", "Saikat Guha", "Adilson E. Motter"], "title": "Hybrid satellite-fiber quantum network", "comment": "13 pages, 13 figures", "summary": "Quantum networks hold promise for key distribution, private and distributed computing, and quantum sensing, among other applications. The scale of such networks for ground users is currently limited by one's ability to distribute entanglement between distant locations. This can in principle be carried out by transmitting entangled photons through optical fibers or satellites. The former is limited by fiber-optic attenuation while the latter is limited by atmospheric extinction and diffraction. Here, we propose a hybrid network and protocol that outperform both ground- and satellite-based designs and lead to high-fidelity entanglement at a continental or even global scale."}
{"id": "2512.16418", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.16418", "abs": "https://arxiv.org/abs/2512.16418", "authors": ["Pere Díaz Lozano", "Giulia Di Nunno"], "title": "An Euler scheme for BSDEs via the Wiener chaos decomposition", "comment": "36 pages, 10 figures", "summary": "The Euler scheme is a standard time discretization for BSDEs, but its implementation hinges on approximating conditional expectations and the associated martingale terms at each time step. We propose an implementation based on the Wiener chaos decomposition to approximate these quantities. In contrast to many numerical schemes that rely on a forward-backward (Markovian) structure, our approach accommodates arbitrary $\\mathcal{F}_T$-measurable square-integrable terminal conditions. We provide a comprehensive convergence analysis and illustrate the method on several numerical examples."}
{"id": "2512.16336", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.16336", "abs": "https://arxiv.org/abs/2512.16336", "authors": ["J. A. Christen", "F. J. Rubio"], "title": "Hazard-based distributional regression via ordinary differential equations", "comment": "To appear in Statistical Methods in Medical Research", "summary": "The hazard function is central to the formulation of commonly used survival regression models such as the proportional hazards and accelerated failure time models. However, these models rely on a shared baseline hazard, which, when specified parametrically, can only capture limited shapes. To overcome this limitation, we propose a general class of parametric survival regression models obtained by modelling the hazard function using autonomous systems of ordinary differential equations (ODEs). Covariate information is incorporated via transformed linear predictors on the parameters of the ODE system. Our framework capitalises on the interpretability of parameters in common ODE systems, enabling the identification of covariate values that produce qualitatively distinct hazard shapes associated with different attractors of the system of ODEs. This provides deeper insights into how covariates influence survival dynamics. We develop efficient Bayesian computational tools, including parallelised evaluation of the log-posterior, which facilitates integration with general-purpose Markov Chain Monte Carlo samplers. We also derive conditions for posterior asymptotic normality, enabling fast approximations of the posterior. A central contribution of our work lies in the case studies. We demonstrate the methodology using clinical trial data with crossing survival curves, and a study of cancer recurrence times where our approach reveals how the efficacy of interventions (treatments) on hazard and survival are influenced by patient characteristics."}
{"id": "2512.16173", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.16173", "abs": "https://arxiv.org/abs/2512.16173", "authors": ["Khalid N. Anindya", "Hong Guo"], "title": "Tunable Topological Phases in an Organic One-Dimensional Mott Chain: Odd-Haldane (S = 1/2) and Haldane (S = 1)", "comment": null, "summary": "Establishing symmetry-protected topological (SPT) phases with interactions in chemically realistic systems remains an open challenge. We show that a single, synthetically plausible organic one-dimensional chain, tunable via chemical modification of its radical sites, hosts two such phases: an odd-Haldane phase of a dimerized $S=\\tfrac{1}{2}$ Heisenberg chain and a Haldane phase of an $S=1$ chain realized when Hund coupling locks two $S=\\tfrac{1}{2}$ spins per monomer into $S=1$. Density-functional theory places the active manifold deep in the Mott regime ($U/t\\!\\approx\\!126$), justifying a spin-only Heisenberg description; a compact $(t,U)\\!\\to\\!J$ mapping then fixes exchange couplings. Exact diagonalization and DMRG reveal a consistent SPT fingerprint across both phases, including a quantized many-body Zak phase, even-degenerate entanglement spectrum, protected edge spins, and characteristic triplon/Haldane features in $S^{+-}(q,ω)$. Our results identify a chemically programmable molecular platform for interacting SPT physics in one dimension and suggest concrete spectroscopic routes to organic Haldane spin chains for nanoscale quantum devices."}
{"id": "2512.15880", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.15880", "abs": "https://arxiv.org/abs/2512.15880", "authors": ["Beatrice Magni", "Markus Heinrich", "Lorenzo Leone", "Xhek Turkeshi"], "title": "Anticoncentration and State Design of Doped Real Clifford Circuits and Tensor Networks", "comment": "5 pages, 1 figure. Comments are welcome", "summary": "We investigate the statistical properties of orthogonal, or real, Clifford circuits doped with magic and imaginary resources. By developing the Weingarten calculus for the real Clifford group, we derive the exact overlap distribution of real stabilizer states, identifying a new universality class: the orthogonal Clifford Porter-Thomas distribution. We prove that local real architectures recover this global statistic in logarithmic depth. Furthermore, we uncover a sharp hierarchy in resource requirements: while retrieving Haar statistics necessitates a polylogarithmic amount of magic states, recovering the full unitary Clifford statistics requires only a single phase gate."}
{"id": "2512.16533", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.16533", "abs": "https://arxiv.org/abs/2512.16533", "authors": ["Julien Hermant", "Jean-François Aujol", "Charles Dossal", "Lorick Huang", "Aude Rondepierre"], "title": "Continuized Nesterov Acceleration for Non-Convex Optimization", "comment": null, "summary": "In convex optimization, continuous-time counterparts have been a fruitful tool for analyzing momentum algorithms. Fewer such examples are available when the function to minimize is non-convex. In several cases, discrepancies arise between the existing discrete-time results, namely those obtained for momentum algorithms, and their continuous-time counterparts, with the latter typically yielding stronger guarantees. We argue that the continuized framework (Even et al., 2021), mixing continuous and discrete components, can tighten the gap between known continuous and discrete results. This framework relies on computations akin to standard Lyapunov analyses, from which are deduced convergence bounds for an algorithm that can be written as a Nesterov momentum algorithm with stochastic parameters. In this work, we extend the range of applicability of the continuized framework, e.g. by allowing it to handle non-smooth Lyapunov functions. We then strengthen its trajectory-wise guarantees for linear convergence rate, deriving finite time bounds with high probability and asymptotic almost sure bounds. We apply this framework to the non-convex class of strongly quasar convex functions. Adapting continuous-time results that have weaker discrete equivalents to the continuized method, we improve by a constant factor the known convergence rate, and relax the existing assumptions on the set of minimizers."}
{"id": "2512.16333", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16333", "abs": "https://arxiv.org/abs/2512.16333", "authors": ["Rawan Hoteit", "Andrea Balestra", "Nathan Mingard", "Efe C. Balta", "John Lygeros"], "title": "Closed Loop Reference Optimization for Extrusion Additive Manufacturing", "comment": null, "summary": "Various defects occur during material extrusion additive manufacturing processes that degrade the quality of the 3D printed parts and lead to significant material waste. This motivates feedback control of the extrusion process to mitigate defects and prevent print failure. We propose a linear quadratic regulator (LQR) for closed-loop control with force feedback to provide accurate width tracking of the extruded filament. Furthermore, we propose preemptive optimization of the reference force given to the LQR that accounts for the performance of the LQR and generates the optimal reference for the closed loop extrusion dynamics and machine constraints. Simulation results demonstrate the improved tracking performance and response time. Experiments on a Fused Filament Fabrication 3D printer showcase a root mean square error improvement of 39.57% compared to tracking the unmodified reference as well as an 83.7% shorter settling time."}
{"id": "2512.16333", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16333", "abs": "https://arxiv.org/abs/2512.16333", "authors": ["Rawan Hoteit", "Andrea Balestra", "Nathan Mingard", "Efe C. Balta", "John Lygeros"], "title": "Closed Loop Reference Optimization for Extrusion Additive Manufacturing", "comment": null, "summary": "Various defects occur during material extrusion additive manufacturing processes that degrade the quality of the 3D printed parts and lead to significant material waste. This motivates feedback control of the extrusion process to mitigate defects and prevent print failure. We propose a linear quadratic regulator (LQR) for closed-loop control with force feedback to provide accurate width tracking of the extruded filament. Furthermore, we propose preemptive optimization of the reference force given to the LQR that accounts for the performance of the LQR and generates the optimal reference for the closed loop extrusion dynamics and machine constraints. Simulation results demonstrate the improved tracking performance and response time. Experiments on a Fused Filament Fabrication 3D printer showcase a root mean square error improvement of 39.57% compared to tracking the unmodified reference as well as an 83.7% shorter settling time."}
{"id": "2512.15890", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.15890", "abs": "https://arxiv.org/abs/2512.15890", "authors": ["Jiyuan Fang", "Qicheng Tang", "Xueda Wen"], "title": "Universal and Maximal Entanglement Swapping in General Fermionic Gaussian States", "comment": "22 pages, 5 figures", "summary": "Exploring universal entanglement structure in many-body systems is both fundamental and challenging, particularly when the system undergoes non-unitary operations. In this work, we uncover a universal mechanism for realizing maximal entanglement swapping in fermionic Gaussian states subjected to projective Bell measurements. We consider two initially decoupled, half-filled copies of a free-fermion system in arbitrary dimensions and perform post-selective Bell measurements on half of the corresponding sites across the two copies. Remarkably, the post-measurement state factorizes into a product of Bell pairs, establishing maximal interlayer entanglement entirely independent of the initial Gaussian state. We derive this post-measurement state exactly for general particle-number-conserving fermionic Gaussian states, establishing both the validity and universality of the mechanism, with numerical simulations serving as consistency checks. This phenomenon arises from a robust interplay between fermionic statistics and Gaussianity, revealing a distinct fermionic route to measurement-induced maximal entanglement."}
{"id": "2512.16827", "categories": ["physics.soc-ph", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16827", "abs": "https://arxiv.org/abs/2512.16827", "authors": ["Juan Sosa", "Brayan Riveros", "Emma J. Camargo-Díaz"], "title": "The Colombian legislative process, 2014-2025: networks, topics, and polarization", "comment": "48 pages, in Spanish language, 23 figures, 13 tables", "summary": "The legislative output of Colombia's House of Representatives between 2014 and 2025 is analyzed using 4,083 bills. Bipartite networks are constructed between parties and bills, and between representatives and bills, along with their projections, to characterize co-sponsorship patterns, centrality, and influence, and to assess whether political polarization is reflected in legislative collaboration. In parallel, the content of the initiatives is studied through semantic networks based on co-occurrences extracted from short descriptions, and topics by party and period are identified using a stochastic block model for weighted networks, with additional comparison using Latent Dirichlet Allocation. In addition, a Bayesian sociability model is applied to detect terms with robust connectivity and to summarize discursive cores. Overall, the approach integrates relational and semantic structure to describe thematic shifts across administrations, identify influential actors and collectives, and provide a reproducible synthesis that promotes transparency and citizen oversight of the legislative process."}
{"id": "2512.15884", "categories": ["quant-ph", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.15884", "abs": "https://arxiv.org/abs/2512.15884", "authors": ["Yanxuan Shao", "Jannik L. Wyss", "Don Towsley", "Adilson E. Motter"], "title": "Noncooperative Quantum Networks", "comment": null, "summary": "Existing protocols for quantum communication networks usually assume an initial allocation of quantum entanglement resources, which are then manipulated through local operations and classical communication (LOCC) to establish high-fidelity entanglement between distant parties. It is generally held that the resulting fidelity would increase monotonically with the entanglement budget. Here, we show that for noncooperative LOCC protocols, the resulting fidelity may decrease as more entanglement is added to a network with non-pure states. This effect results from a quantum analog of selfish routing and constitutes a potential obstacle to the optimal use of resources in large quantum networks."}
{"id": "2512.16525", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.16525", "abs": "https://arxiv.org/abs/2512.16525", "authors": ["Panasun Manorost", "Peter Bastian"], "title": "A non-negativity-preserving cut-cell discontinuous Galerkin method for the diffusive wave equation", "comment": null, "summary": "A non-negativity-preserving cut-cell discontinuous Galerkin method for the degenerate parabolic diffusive wave approximation of the shallow water equation is presented. The method can handle continuous and discontinuous bathymmetry as well as general triangular meshes. It is complemented by a finite volume method on Delauney triangulations which is also shown to be non-negativity preserving. Both methods feature an upwind flux and can handle Manning's and Chezy's friction law. By numerical experiment we demonstrate the discontinuous Galerkin method to be fully second-order accurate for the Barenblatt analytical solution on an inclined plane. In constrast, the finite volume method is only first-order accurate. Further numerical experiments show that three to four mesh refinements are needed for the finite volume method to match the solution of the discontinuous Galerkin method."}
{"id": "2512.16340", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16340", "abs": "https://arxiv.org/abs/2512.16340", "authors": ["Louise Linsell", "Noman Paracha", "Jamie Grossman", "Carsten Bokemeyer", "Jesus Garcia-Foncillas", "Antoine Italiano", "Gilles Vassal", "Yuxian Chen", "Barbara Torlinska", "Keith R Abrams"], "title": "Bayesian joint modelling of longitudinal biomarkers to enable extrapolation of overall survival: an application using larotrectinib trial clinical data", "comment": "24 pages, 3 figures, 4 tables", "summary": "Objectives To investigate the use of a Bayesian joint modelling approach to predict overall survival (OS) from immature clinical trial data using an intermediate biomarker. To compare the results with a typical parametric approach of extrapolation and observed survival from a later datacut.\n  Methods Data were pooled from three phase I/II open-label trials evaluating larotrectinib in 196 patients with neurotrophic tyrosine receptor kinase fusion-positive (NTRK+) solid tumours followed up until July 2021. Bayesian joint modelling was used to obtain patient-specific predictions of OS using individual-level sum of diameter of target lesions (SLD) profiles up to the time at which the patient died or was censored. Overall and tumour site-specific estimates were produced, assuming a common, exchangeable, or independent association structure across tumour sites.\n  Results The overall risk of mortality was 9% higher per 10mm increase in SLD (HR 1.09, 95% CrI 1.05 to 1.14) for all tumour sites combined. Tumour-specific point estimates of restricted mean , median and landmark survival were more similar across models for larger tumour groups, compared to smaller tumour groups. In general, parameters were estimated with more certainty compared to a standard Weibull model and were aligned with the more recent datacut.\n  Conclusions Joint modelling using intermediate outcomes such as tumour burden can offer an alternative approach to traditional survival modelling and may improve survival predictions from limited follow-up data. This approach allows complex hierarchical data structures, such as patients nested within tumour types, and can also incorporate multiple longitudinal biomarkers in a multivariate modelling framework."}
{"id": "2512.16194", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16194", "abs": "https://arxiv.org/abs/2512.16194", "authors": ["Benjamin Lowe", "Bernard Field", "Dhaneesh Kumar", "Daniel Moreno Cerrada", "Oleksandr Stetsovych", "Julian Ceddia", "Andrés Pinar Solé", "Amelia Domínguez-Celorrio", "Jack Hellerstedt", "Sinéad M. Griffin", "Pavel Jelínek", "Agustin Schiffrin"], "title": "Atomic-scale control of substrate-spin coupling via vertical manipulation of a 2D metal-organic framework", "comment": "16 pages, 6 figures, and SI 3 pages, 1 figure", "summary": "Two-dimensional (2D) materials with frustrated crystal geometries can host strongly correlated electrons, potentially leading to a range of exotic many-body quantum phases such as Mott insulators, quantum spin-liquids, and Kondo lattices. The ability to control exchange-coupling within these systems is therefore highly desirable. Here, we use an atomically sharp scanning tunneling microscope probe to vertically manipulate a 2D Mott insulating kagome metal-organic framework (MOF) featuring Kondo-screened local magnetic moments on Ag(111). We show that by controlling the adsorption height of the MOF, we can also controllably and reversibly change the strength of Kondo coupling between the MOF's local spins and the substrate's conduction electrons. This mechanical control of Kondo coupling could be extended to other forms of interlayer exchange coupling, potentially allowing for atomic-scale design or control of spintronics technologies."}
{"id": "2512.15884", "categories": ["quant-ph", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.15884", "abs": "https://arxiv.org/abs/2512.15884", "authors": ["Yanxuan Shao", "Jannik L. Wyss", "Don Towsley", "Adilson E. Motter"], "title": "Noncooperative Quantum Networks", "comment": null, "summary": "Existing protocols for quantum communication networks usually assume an initial allocation of quantum entanglement resources, which are then manipulated through local operations and classical communication (LOCC) to establish high-fidelity entanglement between distant parties. It is generally held that the resulting fidelity would increase monotonically with the entanglement budget. Here, we show that for noncooperative LOCC protocols, the resulting fidelity may decrease as more entanglement is added to a network with non-pure states. This effect results from a quantum analog of selfish routing and constitutes a potential obstacle to the optimal use of resources in large quantum networks."}
{"id": "2512.16565", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16565", "abs": "https://arxiv.org/abs/2512.16565", "authors": ["Yin Liu", "Qiming Dai", "Junyu Zhang", "Zaiwen Wen"], "title": "Non-Asymptotic Global Convergence of PPO-Clip", "comment": null, "summary": "Reinforcement learning (RL) has gained attention for aligning large language models (LLMs) via reinforcement learning from human feedback (RLHF). The actor-only variants of Proximal Policy Optimization (PPO) are widely applied for their efficiency. These algorithms incorporate a clipping mechanism to improve stability. Besides, a regularization term, such as the reverse KL-divergence or a more general \\(f\\)-divergence, is introduced to prevent policy drift. Despite their empirical success, a rigorous theoretical understanding of the problem and the algorithm's properties is limited. This paper advances the theoretical foundations of the PPO-Clip algorithm by analyzing a deterministic actor-only PPO algorithm within the general RL setting with \\(f\\)-divergence regularization under the softmax policy parameterization. We derive a non-uniform Lipschitz smoothness condition and a Łojasiewicz inequality for the considered problem. Based on these, a non-asymptotic linear convergence rate to the globally optimal policy is established for the forward KL-regularizer. Furthermore, stationary convergence and local linear convergence are derived for the reverse KL-regularizer."}
{"id": "2512.16338", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16338", "abs": "https://arxiv.org/abs/2512.16338", "authors": ["Edwin Baum", "Zonglin Liu", "Yuzhen Qin", "Olaf Stursberg"], "title": "Using Seminorms To Analyze Contraction of Switched Systems With Only Non-Contracting Modes", "comment": null, "summary": "This paper investigates contraction properties of switched dynamical systems for the case that all modes are non-contracting, thereby extending existing results that require at least one mode to be contracting. Leveraging the property that unstable systems may still exhibit stable behavior within certain subspaces, conditions are provided which ensure contracting evolution within a given subspace of the state space of the switched system. These conditions are derived using the concepts of seminorms and semi-contracting systems. Then, by selecting a set of subspaces whose corresponding seminorms form a separating family of the state space, and by verifying whether a given mode is contracting in each subspace, conditions on the activation time of each mode are provided by which contraction on the complete state space is guaranteed. Numerical examples are presented for illustration."}
{"id": "2512.16338", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16338", "abs": "https://arxiv.org/abs/2512.16338", "authors": ["Edwin Baum", "Zonglin Liu", "Yuzhen Qin", "Olaf Stursberg"], "title": "Using Seminorms To Analyze Contraction of Switched Systems With Only Non-Contracting Modes", "comment": null, "summary": "This paper investigates contraction properties of switched dynamical systems for the case that all modes are non-contracting, thereby extending existing results that require at least one mode to be contracting. Leveraging the property that unstable systems may still exhibit stable behavior within certain subspaces, conditions are provided which ensure contracting evolution within a given subspace of the state space of the switched system. These conditions are derived using the concepts of seminorms and semi-contracting systems. Then, by selecting a set of subspaces whose corresponding seminorms form a separating family of the state space, and by verifying whether a given mode is contracting in each subspace, conditions on the activation time of each mode are provided by which contraction on the complete state space is guaranteed. Numerical examples are presented for illustration."}
{"id": "2512.15928", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.15928", "abs": "https://arxiv.org/abs/2512.15928", "authors": ["Sukrut Mondkar", "Sayan Mondal", "Ujjwal Sen"], "title": "Resource-resolved quantum fluctuation theorems in end-point measurement scheme", "comment": "22 pages, 3 figures", "summary": "Fluctuation theorems provide universal constraints on nonequilibrium energy and entropy fluctuations, making them a natural framework to assess how and to what extent quantum resources become thermodynamically relevant. We develop a unified framework for incorporating a generic quantum resource, including athermality, quantum coherence, and entanglement, into fluctuation theorems. We work within the end point measurement scheme, which avoids an initial energy measurement and allows quantum resources in the initial state to affect nonequilibrium energy statistics. We derive a family of quantum fluctuation theorems, including generalized Jarzynski equalities and Crooks type fluctuation relations, in which corrections decompose into resource resolved contributions. For single systems, we introduce the concept of weight of athermality, and combine it with the weight of coherence to isolate distinct thermodynamic effects of these quantum resources. For bipartite systems, we furthermore obtain two families of entanglement-resolved fluctuation theorems using an appended correlation operator and the best separable approximation, respectively. Finally, we introduce the concepts of coherence and entanglement fluctuation distances, as Kullback Leibler divergences, which quantify the thermodynamic relevance of quantum resources in a process-dependent and operational manner."}
{"id": "2512.16887", "categories": ["physics.soc-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.16887", "abs": "https://arxiv.org/abs/2512.16887", "authors": ["Julián López", "Virginia Mazzone", "M. Leticia Rubio Puzzo", "Juan Cruz Moreno"], "title": "An evacuation simulator for pedestrian dynamics based on the Social Force Model", "comment": null, "summary": "The evacuation of pedestrians from enclosed spaces represents a key problem in safety engineering and infrastructure design. Analyzing the collective dynamics that emerge during evacuation processes requires simulation tools capable of capturing individual interactions and spatial constraints realistically.\n  In this work, we present \\textit{SiCoBioNa}, an open-source evacuation simulator based on the Social Force Model (SFM). The software provides an intuitive graphical interface that allows users to configure pedestrian properties, spatial geometries, and initial conditions without requiring prior expertise in numerical modeling techniques. The SFM framework enables the representation of goal-oriented motion, interpersonal interactions, and interactions with fixed obstacles.\n  The simulator generates both quantitative data and visual outputs, facilitating the analysis of evacuation dynamics and the evaluation of different spatial configurations. Due to its modular and extensible design, \\textit{SiCoBioNa} serves as a reproducible research tool for studies on pedestrian dynamics providing practical support for evacuation planning."}
{"id": "2512.16097", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2512.16097", "abs": "https://arxiv.org/abs/2512.16097", "authors": ["Jian-Jia Wang", "Ling-Zhi Tang", "Yan-Xiong Du", "Dan-Wei Zhang"], "title": "Discrete time crystals enhanced by Stark potentials in Rydberg atom arrays", "comment": "5 pages, 5 figures", "summary": "Discrete time crystals (DTCs) are non-equilibrium phases in periodically driven systems that exhibit spontaneous breaking of discrete time-translation symmetry. The stabilization of most DTC phases is achieved via the disorder-induced many-body localization. In this work, we propose an experimental scheme to realize disorder-free DTCs in a periodically driven Rydberg atom array. Our scheme utilizes a linear potential in the atomic detuning to enhance the DTC order, without being tired to (Stark) many-body localization. We numerically demonstrate that the Stark potential enhances the robustness of the DTC against the flip imperfections and extends its lifetime, which are independent of initial states. Thus, our scheme provides a promising way to explore DTCs in Rydberg atom arrays without disorder averaging and special state preparation."}
{"id": "2512.16539", "categories": ["math.NA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16539", "abs": "https://arxiv.org/abs/2512.16539", "authors": ["Hengzhun Chen", "Yingzhou Li", "Bichen Lu", "Jianfeng Lu"], "title": "Landscape Analysis of Excited States Calculation over Quantum Computers", "comment": null, "summary": "The variational quantum eigensolver (VQE) is one of the most promising algorithms for low-lying eigenstates calculation on Noisy Intermediate-Scale Quantum (NISQ) computers. Specifically, VQE has achieved great success for ground state calculations of a Hamiltonian. However, excited state calculations arising in quantum chemistry and condensed matter often requires solving more challenging problems than the ground state as these states are generally further away from a mean-field description, and involve less straightforward optimization to avoid the variational collapse to the ground state. Maintaining orthogonality between low-lying eigenstates is a key algorithmic hurdle. In this work, we analyze three VQE models that embed orthogonality constraints through specially designed cost functions, avoiding the need for external enforcement of orthogonality between states. Notably, these formulations possess the desirable property that any local minimum is also a global minimum, helping address optimization difficulties. We conduct rigorous landscape analyses of the models' stationary points and local minimizers, theoretically guaranteeing their favorable properties and providing analytical tools applicable to broader VQE methods. A comprehensive comparison between the three models is also provided, considering their quantum resource requirements and classical optimization complexity."}
{"id": "2512.16363", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.16363", "abs": "https://arxiv.org/abs/2512.16363", "authors": ["Guanghui Wang", "Mengtao Wen", "Changliang Zou"], "title": "Empirical Likelihood Meets Prediction-Powered Inference", "comment": null, "summary": "We study inference with a small labeled sample, a large unlabeled sample, and high-quality predictions from an external model. We link prediction-powered inference with empirical likelihood by stacking supervised estimating equations based on labeled outcomes with auxiliary moment conditions built from predictions, and then optimizing empirical likelihood under these joint constraints. The resulting empirical likelihood-based prediction-powered inference (EPI) estimator is asymptotically normal, has asymptotic variance no larger than the fully supervised estimator, and attains the semiparametric efficiency bound when the auxiliary functions span the predictable component of the supervised score. For hypothesis testing and confidence sets, empirical likelihood ratio statistics admit chi-squared-type limiting distributions. As a by-product, the empirical likelihood weights induce a calibrated empirical distribution that integrates supervised and prediction-based information, enabling estimation and uncertainty quantification for general functionals beyond parameters defined by estimating equations. We present two practical implementations: one based on basis expansions in the predictions and covariates, and one that learns an approximately optimal auxiliary function by cross-fitting. In simulations and applications, EPI reduces mean squared error and shortens confidence intervals while maintaining nominal coverage."}
{"id": "2512.16252", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.16252", "abs": "https://arxiv.org/abs/2512.16252", "authors": ["Kazuto Akiba", "Yuzuki Sega", "Yuichi Akahama", "Yuta Seo", "Tomoki Machida", "Masashi Tokunaga"], "title": "Magnetic-field-induced insulating behavior in black phosphorus under pressure", "comment": "6 pages, 3 figures, proceedings of 1000-Tesla Science Workshop", "summary": "We investigated the out-of-plane magnetoresistance of pressurized black phosphorus (BP) with a longitudinal field configuration. Despite the absence of the Lorentz force in the present configuration, we observed a significant enhancement of magnetoresistance marked with a clear onset field in both the semiconducting (1.1 GPa) and semimetallic (1.3 GPa) phases. The insulating behavior observed near the semiconductor-semimetal transitio pressure is possibly associated with emergence of an excitonic phase, which has been suggested in a recent theoretical study. BP under finely tuned pressure can be a candidate to realize the field-induced electronic phase transition in a moderate magnetic field below 9 T."}
{"id": "2512.15887", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.15887", "abs": "https://arxiv.org/abs/2512.15887", "authors": ["Jaron Skovsted Gundersen", "Rene Bødker Christensen", "Petar Popovski", "Rafał Wisniewski"], "title": "Deflating quantum error-correcting codes", "comment": "Submitted to IEEE transactions on information theory November 21, 2025", "summary": "In this work, we introduce a technique for reducing the length of a quantum stabilizer code, and we call this deflation of the code. Deflation can be seen as a generalization of the well-known puncturing and shortening techniques in cases where more than a single qudit is removed. We show that the parameters of the deflated quantum code can be controlled, and argue that a similar approach is not as beneficial when applied to classical linear codes. Furthermore, it is shown that deflation introduces additional freedom compared to applying just puncturing and shortening consecutively. We exemplify that it is possible to obtain better parameters by deflating a code rather than consecutively using puncturing and shortening."}
{"id": "2512.16598", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16598", "abs": "https://arxiv.org/abs/2512.16598", "authors": ["Xun Qian", "Hussein Rammal", "Dmitry Kovalev", "Peter Richtárik"], "title": "Muon is Provably Faster with Momentum Variance Reduction", "comment": "31 pages, 4 figures", "summary": "Recent empirical research has demonstrated that deep learning optimizers based on the linear minimization oracle (LMO) over specifically chosen Non-Euclidean norm balls, such as Muon and Scion, outperform Adam-type methods in the training of large language models. In this work, we show that such optimizers can be provably improved by replacing their vanilla momentum by momentum variance reduction (MVR). Instead of proposing and analyzing MVR variants of Muon and Scion separately, we incorporate MVR into the recently proposed Gluon framework, which captures Muon, Scion and other specific Non-Euclidean LMO-based methods as special cases, and at the same time works with a more general smoothness assumption which better captures the layer-wise structure of neural networks. In the non-convex case, we incorporate MVR into Gluon in three different ways. All of them improve the convergence rate from ${\\cal O} (\\frac{1}{K^{1/4}})$ to ${\\cal O} (\\frac{1}{K^{1/3}})$. Additionally, we provide improved rates in the star-convex case. Finally, we conduct several numerical experiments that verify the superior performance of our proposed algorithms in terms of iteration complexity."}
{"id": "2512.16345", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16345", "abs": "https://arxiv.org/abs/2512.16345", "authors": ["Zonglin Liu", "Kyra Borchhardt", "Olaf Stursberg"], "title": "Contraction Analysis of Filippov Solutions in Multi-Modal Piecewise Smooth Systems", "comment": null, "summary": "This paper provides conditions to ensure contractive behavior of Filippov solutions generated by multi-modal piecewise smooth (PWS) systems. These conditions are instrumental in analyzing the asymptotic behavior of PWS systems, such as convergence towards an equilibrium point or a limit cycle. The work is motivated by a known principle for contraction analysis of bimodal PWS systems which ensures that the flow dynamics of each mode and the sliding dynamics on the switching manifold are contracting. This approach is extended first to PWS systems with multiple non-intersecting switching manifolds in Rn, and then to two intersecting switching manifolds in R2. Numerical examples are provided to validate the theoretical findings, along with a discussion on extensions to more general intersecting switching manifolds in Rn."}
{"id": "2512.16345", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16345", "abs": "https://arxiv.org/abs/2512.16345", "authors": ["Zonglin Liu", "Kyra Borchhardt", "Olaf Stursberg"], "title": "Contraction Analysis of Filippov Solutions in Multi-Modal Piecewise Smooth Systems", "comment": null, "summary": "This paper provides conditions to ensure contractive behavior of Filippov solutions generated by multi-modal piecewise smooth (PWS) systems. These conditions are instrumental in analyzing the asymptotic behavior of PWS systems, such as convergence towards an equilibrium point or a limit cycle. The work is motivated by a known principle for contraction analysis of bimodal PWS systems which ensures that the flow dynamics of each mode and the sliding dynamics on the switching manifold are contracting. This approach is extended first to PWS systems with multiple non-intersecting switching manifolds in Rn, and then to two intersecting switching manifolds in R2. Numerical examples are provided to validate the theoretical findings, along with a discussion on extensions to more general intersecting switching manifolds in Rn."}
{"id": "2512.16193", "categories": ["nlin.AO", "cond-mat.stat-mech", "math-ph", "math.DS", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2512.16193", "abs": "https://arxiv.org/abs/2512.16193", "authors": ["Narumi Fujii", "Keisuke Taga", "Riccardo Muolo", "Bob Rink", "Hiroya Nakao"], "title": "Emergence of higher-order interactions in systems of coupled Kuramoto oscillators with time delay", "comment": null, "summary": "Understanding the mechanisms that govern collective synchronization is a paramount task in nonlinear dynamics. While higher-order (many-body) interactions have recently emerged as a powerful framework for capturing collective behaviors, real-world examples regarding dynamics remain scarce. Here, we show that higher-order interactions naturally emerge from time-delayed pairwise coupling in Kuramoto oscillators. By expanding the delay term up to second order in the coupling strength, we derive an effective Kuramoto model featuring both two-body and three-body interactions, but without delay, hence, easier to be analyzed. Numerical simulations show that this reduced model can reproduce the bistability and synchronization transitions of the original time-delayed system. Furthermore, applying the Ott-Antonsen ansatz, we obtain a stability diagram for incoherent and synchronized states that closely matches the results of the original model. Our findings reveal that time delays can be effectively recast in the form of higher-order interactions, offering a new perspective on how delayed interactions shape the dynamics."}
{"id": "2512.16668", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.16668", "abs": "https://arxiv.org/abs/2512.16668", "authors": ["Fabius Krämer", "Tim Laux"], "title": "Obstacle Mean Curvature Flow: Efficient Approximation and Convergence Analysis", "comment": "17 pages, 4 figures", "summary": "We introduce a simple and efficient numerical method to compute mean curvature flow with obstacles. The method augments the Merrimam-Bence-Osher scheme with a pointwise update that enforces the constraint and therefore retains the computational complexity of the original scheme. Remarkably, this naive scheme inherits both crucial structural properties of obstacle mean curvature flow: a geometric comparison principle and a minimizing movements interpretation. The latter immediately implies the unconditional stability of the scheme. Based on the comparison principle we prove the convergence of the scheme to the viscosity solution of obstacle mean curvature flow. Moreover, using the minimizing movements interpretation, we show convergence of a spatially discrete model. Finally, we present numerical experiments for a physical model that inspired this work."}
{"id": "2512.16411", "categories": ["stat.ME", "math.ST", "q-fin.ST", "q-fin.TR", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.16411", "abs": "https://arxiv.org/abs/2512.16411", "authors": ["Matthieu Garcin", "Louis Perot"], "title": "Asymptotic and finite-sample distributions of one- and two-sample empirical relative entropy, with application to change-point detection", "comment": null, "summary": "Relative entropy, as a divergence metric between two distributions, can be used for offline change-point detection and extends classical methods that mainly rely on moment-based discrepancies. To build a statistical test suitable for this context, we study the distribution of empirical relative entropy and derive several types of approximations: concentration inequalities for finite samples, asymptotic distributions, and Berry-Esseen bounds in a pre-asymptotic regime. For the latter, we introduce a new approach to obtain Berry-Esseen inequalities for nonlinear functions of sum statistics under some convexity assumptions. Our theoretical contributions cover both one- and two-sample empirical relative entropies. We then detail a change-point detection procedure built on relative entropy and compare it, through extensive simulations, with classical methods based on moments or on information criteria. Finally, we illustrate its practical relevance on two real datasets involving temperature series and volatility of stock indices."}
{"id": "2512.16417", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.16417", "abs": "https://arxiv.org/abs/2512.16417", "authors": ["Xiongfang Liu", "Shengwei Zeng", "Xun Liu", "Kun Han", "Difan Zhou", "Chi Sin Tang", "Ping Yang", "Mark B. H. Breese", "Chuanbing Cai", "Ariando Ariando", "Mi Jiang", "Xinmao Yin"], "title": "Interfacial Strain Modulated Correlated Plasmons in La1.85Sr0.15CuO4 and Their Role in High-temperature Superconductivity", "comment": null, "summary": "High-temperature superconductivity in cuprate materials remains a major challenge in physics due to the complexity of their strongly correlated electronic states. Interfacial strain is a powerful lever for tuning electronic correlations in complex oxides, offering new pathways to control emergent quantum phases. Here, we report the discovery of interfacial strain modulated correlated plasmons observed exclusively in superconducting La1.85Sr0.15CuO4 (LSCO) through spectroscopic ellipsometry. This form of plasmons is absent in the non-superconducting LSCO counterparts. Detailed analysis reveals that these correlated plasmons, arising from the collective excitations within Mott-correlated bands, are driven by long-range electronic correlations in the Cu-O planes. Furthermore, long-range electronic correlations, intricately modulated by interfacial strain, may play a crucial role in the emergence of superconductivity and in tuning the transition temperature. Dynamical cluster approximation (DCA) with quantum Monte Carlo (QMC) calculations of the extended Hubbard model suggest that long-range Coulomb interactions play an important role in LSCO, showing good agreement with our experimental findings. The collective evidence from both the experimental results and theoretical findings provides new insights into the nature of collective excitations and their pivotal role in the emergence of high-temperature superconductivity."}
{"id": "2512.15889", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.15889", "abs": "https://arxiv.org/abs/2512.15889", "authors": ["Yanbing Zhou", "Pablo A. M. Casares", "Diksha Dhawan", "Ignacio Loaiza", "Soran Jahangiri", "Robert A. Lang", "Juan Miguel Arrazola", "Stepan Fomichev"], "title": "Quantum Algorithms for Photoreactivity in Cancer-Targeted Photosensitizers", "comment": null, "summary": "Photodynamic therapy (PDT) is a targeted cancer treatment that uses light-activated photosensitizers to generate reactive oxygen species that selectively destroy tumor cells, generally causing less collateral damage than conventional treatments. However, its clinical success hinges on the availability of photosensitizers with strong optical sensitivity and high efficiency in generating reactive oxygen species. While classical computational methods have provided useful insights into photosensitizer design, they struggle to scale and often lack the accuracy needed for these simulations. In this work, we show how fault-tolerant quantum algorithms can be used to identify promising photosensitizer candidates for PDT. To predict photosensitizer performance, we assess two computational properties. First, we quantify light sensitivity by calculating the cumulative absorption in the therapeutic window with a threshold projection algorithm. Second, we determine the efficiency of reactive oxygen generation by estimating intersystem crossing (ISC) rates using the evolution-proxy approach, complemented by a vibronic dynamic treatment where appropriate. We apply these algorithms to a clinically relevant and actively pursued class of photosensitizers, BODIPY derivatives, including heavy-atom and transition-metal-substituted systems that are challenging for classical methods. Our resource estimates, obtained with PennyLane, suggest that systems with active spaces ranging from 11 to 45 spatial orbitals can be simulated using $180$-$350$ logical qubits and Toffoli gate depths between $10^7$ and $10^9$, placing our algorithms within reach of realistic fault-tolerant quantum devices. This paves the way to an efficient quantum-based workflow for designing photosensitizers that can accelerate the discovery of new PDT agents."}
{"id": "2512.16605", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.16605", "abs": "https://arxiv.org/abs/2512.16605", "authors": ["Yue Su", "Sophie N. Parragh", "Nicolas Dupin", "Jakob Puchinger"], "title": "The Bi-objective Electric Autonomous Dial-a-Ride Problem", "comment": null, "summary": "The electric autonomous dial-a-ride problem (E-ADARP) introduces electric, autonomously driving vehicles and their unique requirements into the classic dial-a-ride problem, where people are transported between pickup and drop-off locations. Next to an electric autonomous vehicle fleet, in the literature, a weighted-sum objective function, which combines the classic routing cost-oriented objective with a user-oriented objective function, has usually been considered. The user-oriented objective function minimizes the total excess user ride time. In this work, we treat them as two separate objective functions, which are optimized concurrently. In order to address the resulting bi-objective E-ADARP, we develop a novel exact framework (called fragment-based checker), whose core part is a smart ``select-and-check\" algorithm that iteratively constructs feasible solutions using fragments. Several enhancements are proposed to enforce the computational efficiency of the proposed method. In the computational experiments, we evaluate several variants of our checker algorithm by leveraging a previously developed branch-and-price algorithm. We benchmark the checker-based framework against state-of-the-art criterion space frameworks as well as a generalized branch-and-price algorithm. Numerical results on both bi-objective DARP and E-ADARP instances demonstrate the effectiveness of the proposed framework. With our proposed approaches, 21 out of 38 instances are solved optimally, where small-to-medium-sized instances are solved within seconds. On larger-scale instances, especially those requiring high battery end levels are computationally challenging to solve, our approaches provide high-quality approximations of the Pareto frontiers. Efficient solutions with varying energy restrictions are compared and we obtain valuable managerial insights for different kinds of service providers."}
{"id": "2512.16356", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16356", "abs": "https://arxiv.org/abs/2512.16356", "authors": ["Manuel R. Arahal", "Manuel G. Satué", "Manuel G. Ortega"], "title": "Optimal chiller loading including transients", "comment": null, "summary": "Scheduling and loading of chillers in a multi-chiller plant is considered. A new framework is introduced considering an extended set of independent variables for the optimization problem of energy consumption. In this way the number of decision variables is increased, providing extra degrees of freedom to optimize cooling plant operation. The dynamic effects due to transients arising from switching on and off of units are usually not considered in the literature dealing with Optimal Chiller Loading/Sequencing which is restricted to the static case. In this paper, these effects are treated in a way that results in a manageable optimization problem. A Simultaneous Perturbation Stochastic Approximation solution is deployed for the problem and the proposed method is compared with a similar but static approach showing the benefits in terms of reduced energy consumption."}
{"id": "2512.16356", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16356", "abs": "https://arxiv.org/abs/2512.16356", "authors": ["Manuel R. Arahal", "Manuel G. Satué", "Manuel G. Ortega"], "title": "Optimal chiller loading including transients", "comment": null, "summary": "Scheduling and loading of chillers in a multi-chiller plant is considered. A new framework is introduced considering an extended set of independent variables for the optimization problem of energy consumption. In this way the number of decision variables is increased, providing extra degrees of freedom to optimize cooling plant operation. The dynamic effects due to transients arising from switching on and off of units are usually not considered in the literature dealing with Optimal Chiller Loading/Sequencing which is restricted to the static case. In this paper, these effects are treated in a way that results in a manageable optimization problem. A Simultaneous Perturbation Stochastic Approximation solution is deployed for the problem and the proposed method is compared with a similar but static approach showing the benefits in terms of reduced energy consumption."}
{"id": "2512.16520", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.16520", "abs": "https://arxiv.org/abs/2512.16520", "authors": ["Felix Kloiber-Tollinger", "Lukas M. Sieberer"], "title": "Replica Keldysh field theory of quantum-jump processes: General formalism and application to imbalanced and inefficient fermion counting", "comment": "32 pages, 5 figures", "summary": "Measurement-induced phase transitions have largely been explored for projective or continuous measurements of Hermitian observables, assuming perfect detection without information loss. Yet such transitions also arise in more general settings, including quantum-jump processes with non-Hermitian jump operators, and under inefficient detection. A theoretical framework for treating these broader scenarios has been missing. Here we develop a comprehensive replica Keldysh field theory for general quantum-jump processes in both bosonic and fermionic systems. Our formalism provides a unified description of pure-state quantum trajectories under efficient detection and mixed-state dynamics emerging from inefficient monitoring, with deterministic Lindbladian evolution appearing as a limiting case. It thus establishes a direct connection between phase transitions in nonequilibrium steady states of driven open quantum matter and in measurement-induced dynamics. As an application, we study imbalanced and inefficient fermion counting in a one-dimensional lattice system: monitored gain and loss of fermions occurring at different rates, with a fraction of gain and loss jumps undetected. For imbalanced but efficient counting, we recover the qualitative picture of the balanced case: entanglement obeys an area law for any nonzero jump rate, with an extended quantum-critical regime emerging between two parametrically separated length scales. Inefficient detection introduces a finite correlation length beyond which entanglement, as quantified by the fermionic logarithmic negativity, obeys an area law, while the subsystem entropy shows volume-law scaling. Numerical simulations support our analytical findings. Our results offer a general and versatile theoretical foundation for studying measurement-induced phenomena across a wide class of monitored and open quantum systems."}
{"id": "2512.16004", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.16004", "abs": "https://arxiv.org/abs/2512.16004", "authors": ["Furkan Şık", "F. L. Teixeira", "B. Shanker"], "title": "Sparse Operator-Adapted Wavelet Decomposition Using Polygonal Elements for Multiscale FEM Problems", "comment": "11 pages, 11 figures", "summary": "We develop a sparse multiscale operator-adapted wavelet decomposition-based finite element method (FEM) on unstructured polygonal mesh hierarchies obtained via a coarsening procedure. Our approach decouples different resolution levels, allowing each scale to be solved independently and added to the entire solution without the need to recompute coarser levels. At the finest level, the meshes consist of triangular elements which are geometrically coarsened at each step to form convex polygonal elements. Smooth field regions of the domain are solved with fewer, larger, polygonal elements, whereas high-gradient regions are represented by smaller elements, thereby improving memory efficiency through adaptivity. The proposed algorithm computes solutions via sequences of hierarchical sparse linear-algebra operations with nearly linear computational complexity."}
{"id": "2512.16481", "categories": ["stat.ME", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.16481", "abs": "https://arxiv.org/abs/2512.16481", "authors": ["Nora M. Villanueva", "Marta Sestelo", "Luis Meira-Machado"], "title": "Efficient and scalable clustering of survival curves", "comment": null, "summary": "Survival analysis encompasses a broad range of methods for analyzing time-to-event data, with one key objective being the comparison of survival curves across groups. Traditional approaches for identifying clusters of survival curves often rely on computationally intensive bootstrap techniques to approximate the null hypothesis distribution. While effective, these methods impose significant computational burdens. In this work, we propose a novel approach that leverages the k-means and log-rank test to efficiently identify and cluster survival curves. Our method eliminates the need for computationally expensive resampling, significantly reducing processing time while maintaining statistical reliability. By systematically evaluating survival curves and determining optimal clusters, the proposed method ensures a practical and scalable alternative for large-scale survival data analysis. Through simulation studies, we demonstrate that our approach achieves results comparable to existing bootstrap-based clustering methods while dramatically improving computational efficiency. These findings suggest that the log-rank-based clustering procedure offers a viable and time-efficient solution for researchers working with multiple survival curves in medical and epidemiological studies."}
{"id": "2512.16431", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16431", "abs": "https://arxiv.org/abs/2512.16431", "authors": ["Wanying Chen", "Hongyun Zhang", "Jinxi Lu", "Yu Gu", "Qiyun Xu", "Fei Wang", "Xuanxi Cai", "Jiansong Li", "Jiayong Xiao", "Rui Chen", "Kenji Watanabe", "Takashi Taniguchi", "Jose Avila", "Pavel Dudin", "Matthew D. Watson", "Pu Yu", "Shengwei Jiang", "Wenhui Duan", "Tingxin Li", "Chong Wang", "Shuyun Zhou"], "title": "Moiré-modulated $Γ$ valley in twisted bilayer and twisted double-bilayer MoTe$_2$", "comment": "7 pages, 5 figures", "summary": "Twisted MoTe$_2$ hosts intriguing correlated quantum phenomena including the fractional quantum anomalous Hall effect in twisted bilayer (t-BL) MoTe$_2$ near 3.7$^\\circ$, which is sensitive to the twist angle and moiré superlattices. Here, we directly visualize the twist-angle-modulated electronic structure of t-BL and twisted double-bilayer (t-DBL) near this critical angle. We find that the moiré superlattice not only modifies the relative energy between $Γ$ and K valleys in t-BL MoTe$_2$, but also strongly reconstructs the $Γ$ valley for both t-BL and t-DBL. Specifically, the deep $p_z$-derived band at $Γ$ exhibits a distinct splitting that systematically varies with increasing twist angle. Theoretical analysis suggests that this modulation arises from the twist-angle-dependent lattice relaxation, especially interfacial corrugations. Our work directly visualizes the moiré-modulated electronic structure and provides key spectroscopic information of lattice relaxation and interlayer interactions underlying the physics of twisted MoTe$_2$."}
{"id": "2512.15890", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.15890", "abs": "https://arxiv.org/abs/2512.15890", "authors": ["Jiyuan Fang", "Qicheng Tang", "Xueda Wen"], "title": "Universal and Maximal Entanglement Swapping in General Fermionic Gaussian States", "comment": "22 pages, 5 figures", "summary": "Exploring universal entanglement structure in many-body systems is both fundamental and challenging, particularly when the system undergoes non-unitary operations. In this work, we uncover a universal mechanism for realizing maximal entanglement swapping in fermionic Gaussian states subjected to projective Bell measurements. We consider two initially decoupled, half-filled copies of a free-fermion system in arbitrary dimensions and perform post-selective Bell measurements on half of the corresponding sites across the two copies. Remarkably, the post-measurement state factorizes into a product of Bell pairs, establishing maximal interlayer entanglement entirely independent of the initial Gaussian state. We derive this post-measurement state exactly for general particle-number-conserving fermionic Gaussian states, establishing both the validity and universality of the mechanism, with numerical simulations serving as consistency checks. This phenomenon arises from a robust interplay between fermionic statistics and Gaussianity, revealing a distinct fermionic route to measurement-induced maximal entanglement."}
{"id": "2512.16684", "categories": ["math.OC", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.16684", "abs": "https://arxiv.org/abs/2512.16684", "authors": ["Yann Disser", "Georg Loho", "Matthew Maat", "Nils Mosis"], "title": "Lower bounds for ranking-based pivot rules", "comment": null, "summary": "The existence of a polynomial pivot rule for the simplex method for linear programming, policy iteration for Markov decision processes, and strategy improvement for parity games each are prominent open problems in their respective fields. While numerous natural candidates for efficient rules have been eliminated, all existing lower bound constructions are tailored to individual or small sets of pivot rules. We introduce a unified framework for formalizing classes of rules according to the information about the input that they rely on. Within this framework, we show lower bounds for \\emph{ranking-based} classes of rules that base their decisions on orderings of the improving pivot steps induced by the underlying data. Our first result is a superpolynomial lower bound for strategy improvement, obtained via a family of sink parity games, which applies to memory-based generalizations of Bland's rule that only access the input by comparing the ranks of improving edges in some global order. Our second result is a subexponential lower bound for policy iteration, obtained via a family of Markov decision processes, which applies to memoryless rules that only access the input by comparing improving actions according to their ranks in a global order, their reduced costs, and the associated improvements in objective value. Both results carry over to the simplex method for linear programming."}
{"id": "2512.16379", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16379", "abs": "https://arxiv.org/abs/2512.16379", "authors": ["Manuel G. Satué", "Manuel R. Arahal", "Luis F. Acedo", "Manuel G. Ortega"], "title": "Economic versus energetic model predictive control of a cold production plant with thermal energy storage", "comment": "14 pages", "summary": "Economic model predictive control has been proposed as a means for solving the unit loading and unit allocation problem in multi-chiller cooling plants. The adjective economic stems from the use of financial cost due to electricity consumption in a time horizon, such is the loss function minimized at each sampling period. The energetic approach is rarely encountered. This article presents for the first time a comparison between the energetic optimization objective and the economic one. The comparison is made on a cooling plant using air-cooled water chillers and a cold storage system. Models developed have been integrated into Simscape, and non-convex mixed optimization methods used to achieve optimal control trajectories for both energetic and economic goals considered separately. The results over several scenarios, and in different seasons, support the consideration of the energetic approach despite the current prevalence of the economic one. The results are dependent on the electric season and the available tariffs. In particular, for the high electric season and considering a representative tariff, the results show that an increment of about 2.15% in energy consumption takes place when using the economic approach instead of the energetic one. On the other hand, a reduction in cost of 2.94% is achieved."}
{"id": "2512.16379", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16379", "abs": "https://arxiv.org/abs/2512.16379", "authors": ["Manuel G. Satué", "Manuel R. Arahal", "Luis F. Acedo", "Manuel G. Ortega"], "title": "Economic versus energetic model predictive control of a cold production plant with thermal energy storage", "comment": "14 pages", "summary": "Economic model predictive control has been proposed as a means for solving the unit loading and unit allocation problem in multi-chiller cooling plants. The adjective economic stems from the use of financial cost due to electricity consumption in a time horizon, such is the loss function minimized at each sampling period. The energetic approach is rarely encountered. This article presents for the first time a comparison between the energetic optimization objective and the economic one. The comparison is made on a cooling plant using air-cooled water chillers and a cold storage system. Models developed have been integrated into Simscape, and non-convex mixed optimization methods used to achieve optimal control trajectories for both energetic and economic goals considered separately. The results over several scenarios, and in different seasons, support the consideration of the energetic approach despite the current prevalence of the economic one. The results are dependent on the electric season and the available tariffs. In particular, for the high electric season and considering a representative tariff, the results show that an increment of about 2.15% in energy consumption takes place when using the economic approach instead of the energetic one. On the other hand, a reduction in cost of 2.94% is achieved."}
{"id": "2512.16536", "categories": ["hep-lat", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.16536", "abs": "https://arxiv.org/abs/2512.16536", "authors": ["Stephan Durr", "Tolga S. H. Kiel"], "title": "Critical coupling in $φ_2^4$ theory", "comment": "13 pages, 6 tables, 6 figures", "summary": "We consider $φ^4$ theory with $φ(x)\\in\\mathbb{R}$ in two Euclidean dimensions. We determine for a variety of self-couplings $\\hatλ$ the (negative) critical bare mass $\\hatμ_{0\\mathrm{c}}^2(\\hatλ)$ where the lattice-regularized system changes from the symmetric to the broken phase. Based on these data, the transition to infinite volume and a universal scheme with the renormalized parameter $\\hatμ_\\mathrm{c}^2(\\hatλ)$ is made. Finally, $f_\\mathrm{c}=\\lim_{\\hatλ\\to0}\\hatλ/\\hatμ_\\mathrm{c}^2(\\hatλ)$ is determined, with a judicious choice of the parameterizations considered. Our final result reads $f_\\mathrm{c}=11.1097(20)_\\mathrm{stat}(09)_\\mathrm{sys}=11.1097(22)_\\mathrm{tot}$."}
{"id": "2512.16547", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16547", "abs": "https://arxiv.org/abs/2512.16547", "authors": ["William R. Nugent"], "title": "Extending a Matrix Lie Group Model of Measurement Symmetries", "comment": "28 pages; 1 figure", "summary": "Symmetry principles underlie and guide scientific theory and research, from Curie's invariance formulation to modern applications across physics, chemistry, and mathematics. Building on a recent matrix Lie group measurement model, this paper extends the framework to identify additional measurement symmetries implied by Lie group theory. Lie groups provide the mathematics of continuous symmetries, while Lie algebras serve as their infinitesimal generators. Within applied measurement theory, the preservation of symmetries in transformation groups acting on score frequency distributions ensure invariance in transformed distributions, with implications for validity, comparability, and conservation of information. A simulation study demonstrates how breaks in measurement symmetry affect score distribution symmetry and break effect size comparability. Practical applications are considered, particularly in meta analysis, where the standardized mean difference (SMD) is shown to remain invariant across measures only under specific symmetry conditions derived from the Lie group model. These results underscore symmetry as a unifying principle in measurement theory and its role in evidence based research."}
{"id": "2512.16459", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16459", "abs": "https://arxiv.org/abs/2512.16459", "authors": ["Ying-Xing Ding", "Wen-Tong Li", "Li-Min Zhang", "Yu-Biao Wu", "Duanlu Zhou", "Lin Zhuang", "Wu-Ming Liu"], "title": "Fractional Chern insulator with higher Chern number in optical lattice", "comment": null, "summary": "Fractional Chern insulators arise in topologically nontrivial flat bands, characterized by an integer Chern number C that corresponds to the number of dissipationless edge states in the non-interacting regime. Higher Chern numbers can replicate the physics of higher Landau levels and often confer enhanced topological robustness. However, realizing correlated fractional phases with higher Chern numbers in such flat band systems remains challenging. Here, we propose an interlayer coupling scheme to generate higher Chern numbers in a flat-band system, where the interlayer coupling transforms two C = 1 bands in a bilayer checkerboard lattice into a single flat band with C = 2 by lifting their degeneracy and merging their topological indices. Exact diagonalization calculation reveals that this engineered band hosts two fractional Chern insulator states with C = 2/3 and 2/5, respectively. An experimental setup is proposed to simulate these states using cold alkaline-earth-like atoms in an effective bilayer optical lattice. Our work provides a general and widely applicable strategy for constructing higher Chern number flat bands, opening a pathway to explore exotic fractional quantum phases"}
{"id": "2512.15901", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.15901", "abs": "https://arxiv.org/abs/2512.15901", "authors": ["Leonardo Bohac"], "title": "Closed-Form Optimal Quantum Circuits for Single-Query Identification of Boolean Functions", "comment": "7 pages, 1 figure, 2 tables. Includes explicit circuit decomposition", "summary": "We study minimum-error identification of an unknown single-bit Boolean function given black-box (oracle) access with one allowed query. Rather than stopping at an abstract optimal measurement, we give a fully constructive solution: an explicit state preparation and an explicit measurement unitary whose computational-basis readout achieves the Helstrom-optimal success probability 3/4 for distinguishing the four possible functions. The resulting circuit is low depth, uses a fixed gate set, and (in this smallest setting) requires no entanglement in the input state. Beyond the specific example, the main message is operational. It highlights a regime in which optimal oracle discrimination is not only well-defined but implementably explicit: the optimal POVM collapses to a compact gate-level primitive that can be compiled, verified, and composed inside larger routines. Motivated by this, we discuss a \"what if\" question that is open in spirit: for fixed (n,m,k), could optimal k-query identification (possibly for large hypothesis classes) admit deterministic, closed-form descriptions of the inter-query unitaries and the final measurement unitary acting on the natural n+m-qubit input--output registers (and, if needed, small work registers)? Even when such descriptions are not compact and do not evade known circuit-complexity barriers for generic Boolean functions, making the optimum constructive at the circuit level would be valuable for theory-to-hardware translation and for clarifying which forms of \"oracle access\" are physically meaningful."}
{"id": "2512.16865", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.16865", "abs": "https://arxiv.org/abs/2512.16865", "authors": ["Songhao Shen", "Yufeng Zhou", "Qin Lei", "Zhibin Wu"], "title": "A survey of the orienteering problem: model evolution, algorithmic advances, and future directions", "comment": null, "summary": "The orienteering problem (OP) is a combinatorial optimization problem that seeks a path visiting a subset of locations to maximize collected rewards under a limited resource budget. This article presents a systematic PRISMA-based review of OP research published between 2017 and 2025, with a focus on models and methods that have shaped subsequent developments in the field. We introduce a component-based taxonomy that decomposes OP variants into time-, path-, node-, structure-, and information-based extensions. This framework unifies classical and emerging variants -- including stochastic, time-dependent, Dubins, Set, and multi-period OPs -- within a single structural perspective. We further categorize solution approaches into exact algorithms, heuristics and metaheuristics, and learning-based methods, with particular emphasis on matheuristics and recent advances in artificial intelligence, especially reinforcement learning and neural networks, which enhance scalability in large-scale and information-rich settings. Building on this unified view, we discuss how different components affect computational complexity and polyhedral properties and identify open challenges related to robustness, sustainability, and AI integration. The survey thus provides both a consolidated reference for existing OP research and a structured agenda for future theoretical and applied work."}
{"id": "2512.16497", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16497", "abs": "https://arxiv.org/abs/2512.16497", "authors": ["Mohamed Shamseldein"], "title": "From Liability to Asset: A Three-Mode Grid-Forming Control Framework for Centralized Data Center UPS Systems", "comment": null, "summary": "AI workloads are turning large data centers into highly dynamic power-electronic loads; fault-time behavior and workload pulsing can stress weak-grid points of interconnection. This paper proposes a centralized medium-voltage (MV) uninterruptible power supply (UPS) control architecture implemented as three operating modes: Mode 1 regulates a DC stiff bus and shapes normal-operation grid draw, Mode 2 enforces current-limited fault-mode P--Q priority with UPS battery energy storage system (UPS-BESS) buffering and a rate-limited post-fault \"soft return,\" and Mode 3 optionally provides droop-based fast frequency response via grid-draw modulation. Fundamental-frequency averaged dq simulations (50 MW block, short-circuit ratio (SCR) = 1.5, 0.5 p.u. three-phase dip for 150~ms) show zero unserved information-technology (IT) energy (0.00000 MWh vs.0.00208 MWh for a momentary-cessation benchmark), a 0.57 p.u. peak inverter current (vs. 1.02 p.u. for a synchronous-reference-frame phase-locked loop (SRF-PLL) low-voltage ride-through (LVRT) baseline), a nonzero mean fault-window grid draw of 0.20~p.u. (vs.approx 0 for momentary cessation), and an improved settled point-of-common-coupling (PCC) voltage minimum of 0.79 p.u. after one cycle (vs. 0.66 p.u.). A forced-oscillation case study applies a 1 Hz pulsed load (+/- 0.25 p.u.) and shows that the normal-operation shaping filters the oscillation seen by the grid while the UPS-BESS buffers the pulsing component."}
{"id": "2512.16497", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16497", "abs": "https://arxiv.org/abs/2512.16497", "authors": ["Mohamed Shamseldein"], "title": "From Liability to Asset: A Three-Mode Grid-Forming Control Framework for Centralized Data Center UPS Systems", "comment": null, "summary": "AI workloads are turning large data centers into highly dynamic power-electronic loads; fault-time behavior and workload pulsing can stress weak-grid points of interconnection. This paper proposes a centralized medium-voltage (MV) uninterruptible power supply (UPS) control architecture implemented as three operating modes: Mode 1 regulates a DC stiff bus and shapes normal-operation grid draw, Mode 2 enforces current-limited fault-mode P--Q priority with UPS battery energy storage system (UPS-BESS) buffering and a rate-limited post-fault \"soft return,\" and Mode 3 optionally provides droop-based fast frequency response via grid-draw modulation. Fundamental-frequency averaged dq simulations (50 MW block, short-circuit ratio (SCR) = 1.5, 0.5 p.u. three-phase dip for 150~ms) show zero unserved information-technology (IT) energy (0.00000 MWh vs.0.00208 MWh for a momentary-cessation benchmark), a 0.57 p.u. peak inverter current (vs. 1.02 p.u. for a synchronous-reference-frame phase-locked loop (SRF-PLL) low-voltage ride-through (LVRT) baseline), a nonzero mean fault-window grid draw of 0.20~p.u. (vs.approx 0 for momentary cessation), and an improved settled point-of-common-coupling (PCC) voltage minimum of 0.79 p.u. after one cycle (vs. 0.66 p.u.). A forced-oscillation case study applies a 1 Hz pulsed load (+/- 0.25 p.u.) and shows that the normal-operation shaping filters the oscillation seen by the grid while the UPS-BESS buffers the pulsing component."}
{"id": "2512.16654", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16654", "abs": "https://arxiv.org/abs/2512.16654", "authors": ["Wanbing Zhao", "H. W. Shawn Liew", "Wen Wei Ho", "Chunxiao Liu", "Vir B. Bulchandani"], "title": "Scalable tests of quantum contextuality from stabilizer-testing nonlocal games", "comment": "27+4 pages, 4 figures", "summary": "Soon after the dawn of quantum error correction, DiVincenzo and Peres observed that stabilizer codewords could give rise to simple proofs of quantumness via contextuality. This discovery can be recast in the language of nonlocal games: every $n$-qubit stabilizer state defines a specific \"stabilizer-testing\" $n$-player nonlocal game, which quantum players can win with probability one. If quantum players can moreover outperform all possible classical players, then the state is contextual. However, the classical values of stabilizer-testing games are largely unknown for scalable examples beyond the $n$-qubit GHZ state. We introduce several new methods for upper-bounding the classical values of these games. We first prove a general coding-theory bound for all stabilizer-testing games: if the classical value $p_{\\mathrm{cl}}^* < 1$, then $p_{\\mathrm{cl}}^* \\leq 7/8$, i.e., there is no classical strategy that can perform as well as the optimal quantum strategy even in an asymptotic sense. We then show how to tighten this bound for the most common scalable examples, namely GHZ, toric-code and cyclic cluster states. In particular, we establish an asymptotically tight upper bound for cyclic cluster states using transfer-matrix methods. This leads to the striking conclusion that measuring an exponentially small fidelity to the cyclic cluster state will suffice to witness its contextuality."}
{"id": "2512.16745", "categories": ["stat.ME", "econ.EM"], "pdf": "https://arxiv.org/pdf/2512.16745", "abs": "https://arxiv.org/abs/2512.16745", "authors": ["Simon Donker van Heel", "Neil Shephard"], "title": "Exponentially weighted estimands and the exponential family: filtering, prediction and smoothing", "comment": null, "summary": "We propose using a discounted version of a convex combination of the log-likelihood with the corresponding expected log-likelihood such that when they are maximized they yield a filter, predictor and smoother for time series. This paper then focuses on working out the implications of this in the case of the canonical exponential family. The results are simple exact filters, predictors and smoothers with linear recursions. A theory for these models is developed and the models are illustrated on simulated and real data."}
{"id": "2512.16464", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16464", "abs": "https://arxiv.org/abs/2512.16464", "authors": ["Peter Thalmeier"], "title": "Hyperfine coupling in singlet ground state magnets", "comment": "12 pages, 12 figures", "summary": "The influence of hyperfine coupling to nuclear spins and of their quadrupolar splitting on the induced moment order in singlet ground state magnets is investigated. The latter are found among non-Kramers f electron compounds. Without coupling to the nuclear spins these magnets have a quantum critical point (QCP) separating paramagnetic and induced moment regime. The hyperfine interaction suppresses the QCP and leads to a gradual crossover between induced electronic and nuclear hyperfine coupling dominated magnetic order. It is shown how the critical temperature depends on the electronic and nuclear control parameters including the nuclear spin size and its possible nuclear quadrupole splitting. In particular the dependence of the specific heat on the control parameters and applied field is investigated for ferro- and antiferromagnetic order. It is shown that the three peak structure in the electronic induced moment regime gradually changes to a two-peak structure in the hyperfine coupling dominated nuclear moment order regime or for increasing field strength. Most importantly the possibility of a reentrance behaviour of magnetic order or likewise nonmonotonic critical fields due to hyperfine coupling influence is demonstrated. Finally the systematic evolution of the phase diagram under the influence of nuclear quadrupole coupling is clarified."}
{"id": "2512.15928", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.15928", "abs": "https://arxiv.org/abs/2512.15928", "authors": ["Sukrut Mondkar", "Sayan Mondal", "Ujjwal Sen"], "title": "Resource-resolved quantum fluctuation theorems in end-point measurement scheme", "comment": "22 pages, 3 figures", "summary": "Fluctuation theorems provide universal constraints on nonequilibrium energy and entropy fluctuations, making them a natural framework to assess how and to what extent quantum resources become thermodynamically relevant. We develop a unified framework for incorporating a generic quantum resource, including athermality, quantum coherence, and entanglement, into fluctuation theorems. We work within the end point measurement scheme, which avoids an initial energy measurement and allows quantum resources in the initial state to affect nonequilibrium energy statistics. We derive a family of quantum fluctuation theorems, including generalized Jarzynski equalities and Crooks type fluctuation relations, in which corrections decompose into resource resolved contributions. For single systems, we introduce the concept of weight of athermality, and combine it with the weight of coherence to isolate distinct thermodynamic effects of these quantum resources. For bipartite systems, we furthermore obtain two families of entanglement-resolved fluctuation theorems using an appended correlation operator and the best separable approximation, respectively. Finally, we introduce the concepts of coherence and entanglement fluctuation distances, as Kullback Leibler divergences, which quantify the thermodynamic relevance of quantum resources in a process-dependent and operational manner."}
{"id": "2512.15831", "categories": ["quant-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.15831", "abs": "https://arxiv.org/abs/2512.15831", "authors": ["Benjamin Desef"], "title": "Optimization Techniques in Quantum Information", "comment": "PhD Thesis", "summary": "This thesis focuses on the intersection of mathematical and computational optimization and quantum information. Main contributions are open-source software code: A hybrid approach mixing \"traditional\" nonconvex and convex methods can make difficult problems more accessible. A demonstration of how to efficiently implement such an algorithm, avoiding interfacial bottlenecks, is provided, finding optimal protocols to establish entanglement through a lossy channel. The central software package developed addresses polynomial optimization problems. Many problems naturally involve only a polynomial objective and constraint polynomials. Such problems can automatically be cast into semidefinite programs that provide a hierarchy of outer approximations. The resulting problems are often so large and scale so unfavorably with respect to the variable number and degree involved that the boundary of the doable is reached quickly. However, technical progress both in hardware and algorithms has pushed this boundary - but software frameworks for polynomial optimization have not followed in the same manner, often now making them the bottleneck that before was the solver. The package PolynomialOptimization.jl developed during this thesis aims to fill the gap and provide a very resource-efficient intermediate layer together with a wide number of algorithms to reduce the problem size, and naturally supporting complex numbers and semidefinite constraints ubiquitous in quantum information problems. Its application on an entanglement distribution problem is demonstrated, showing that even relaxations with semidefinite matrices of three- and four-digit size can be solved conveniently. Finally, a new way to calculate interior-point barriers for the cone of sums-of-squares matrices in a nearly time-optimal way is developed, whose efficient implementation has the potential of further reducing resource consumption."}
{"id": "2512.16624", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16624", "abs": "https://arxiv.org/abs/2512.16624", "authors": ["Mark Benazet", "Francesco Ricca", "Dario Bralla", "Melanie N. Zeilinger", "Andrea Carron"], "title": "Learning-based Approximate Model Predictive Control for an Impact Wrench Tool", "comment": null, "summary": "Learning-based model predictive control has emerged as a powerful approach for handling complex dynamics in mechatronic systems, enabling data-driven performance improvements while respecting safety constraints. However, when computational resources are severely limited, as in battery-powered tools with embedded processors, existing approaches struggle to meet real-time requirements. In this paper, we address the problem of real-time torque control for impact wrenches, where high-frequency control updates are necessary to accurately track the fast transients occurring during periodic impact events, while maintaining high-performance safety-critical control that mitigates harmful vibrations and component wear. The key novelty of the approach is that we combine data-driven model augmentation through Gaussian process regression with neural network approximation of the resulting control policy. This insight allows us to deploy predictive control on resource-constrained embedded platforms while maintaining both constraint satisfaction and microsecond-level inference times. The proposed framework is evaluated through numerical simulations and hardware experiments on a custom impact wrench testbed. The results show that our approach successfully achieves real-time control suitable for high-frequency operation while maintaining constraint satisfaction and improving tracking accuracy compared to baseline PID control."}
{"id": "2512.16624", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16624", "abs": "https://arxiv.org/abs/2512.16624", "authors": ["Mark Benazet", "Francesco Ricca", "Dario Bralla", "Melanie N. Zeilinger", "Andrea Carron"], "title": "Learning-based Approximate Model Predictive Control for an Impact Wrench Tool", "comment": null, "summary": "Learning-based model predictive control has emerged as a powerful approach for handling complex dynamics in mechatronic systems, enabling data-driven performance improvements while respecting safety constraints. However, when computational resources are severely limited, as in battery-powered tools with embedded processors, existing approaches struggle to meet real-time requirements. In this paper, we address the problem of real-time torque control for impact wrenches, where high-frequency control updates are necessary to accurately track the fast transients occurring during periodic impact events, while maintaining high-performance safety-critical control that mitigates harmful vibrations and component wear. The key novelty of the approach is that we combine data-driven model augmentation through Gaussian process regression with neural network approximation of the resulting control policy. This insight allows us to deploy predictive control on resource-constrained embedded platforms while maintaining both constraint satisfaction and microsecond-level inference times. The proposed framework is evaluated through numerical simulations and hardware experiments on a custom impact wrench testbed. The results show that our approach successfully achieves real-time control suitable for high-frequency operation while maintaining constraint satisfaction and improving tracking accuracy compared to baseline PID control."}
{"id": "2512.16659", "categories": ["physics.geo-ph", "cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.16659", "abs": "https://arxiv.org/abs/2512.16659", "authors": ["Matthew Oline", "Jeremy Hoskins", "David Seekell", "Mary Silber", "B. B. Cael"], "title": "Self-Affine Scaling of Earth's Islands", "comment": "11 pages, 3 figures", "summary": "Earth's relief is approximately self-affine, meaning a zoom-in on a small region looks statistically similar to a large region upon a suitable rescaling. Fractional Brownian surfaces give an idealized self-affine model of Earth's relief with one parameter, the Hurst exponent $H$, characterizing the roughness of the surface. To quantitatively assess agreement with Earth elevation data, we compile a large dataset of topographic profiles of islands (N=131,063 with the range of areas covering 8+ orders of magnitude) and obtain four estimates for the Hurst exponent of Earth's surface by fitting four statistical laws from the theory of self-affine surfaces concerning islands: (i) distribution of areas, (ii) volume-area relationship, (iii) perimeter-area relationship, and (iv) maximum height-area relationship. The estimated Hurst exponents differ greatly, indicating different fractal scaling behavior for different geometric features, but are sorted in order of increasing expected influence of erosion at the shorelines."}
{"id": "2512.16748", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16748", "abs": "https://arxiv.org/abs/2512.16748", "authors": ["Derek Long"], "title": "Shift-Aware Gaussian-Supremum Validation for Wasserstein-DRO CVaR Portfolios", "comment": "NeurIPS 2025 Workshop: Generative AI in Finance", "summary": "We study portfolio selection with a Conditional Value-at-Risk (CVaR) constraint under distribution shift and serial dependence. While Wasserstein distributionally robust optimization (DRO) offers tractable protection via an ambiguity ball around empirical data, choosing the ball radius is delicate: large radii are conservative, small radii risk violation under regime change. We propose a shift-aware Gaussian-supremum (GS) validation framework for Wasserstein-DRO CVaR portfolios, building on the work by Lam and Qian (2019). Phase I of the framework generates a candidate path by solving the exact reformulation of the robust CVaR constraint over a grid of Wasserstein radii. Phase II of the framework learns a target deployment law $Q$ by density-ratio reweighting of a time-ordered validation fold, computes weighted CVaR estimates, and calibrates a simultaneous upper confidence band via a block multiplier bootstrap to account for dependence. We select the least conservative feasible portfolio (or abstain if the effective sample size collapses). Theoretically, we extend the normalized GS validator to non-i.i.d. financial data: under weak dependence and regularity of the weighted scores, any portfolio passing our validator satisfies the CVaR limit under $Q$ with probability at least $1-β$; the Wasserstein term contributes a deterministic margin $(δ/α)\\|x\\|_*$. Empirical results indicate improved return-risk trade-offs versus the naive baseline."}
{"id": "2512.16651", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16651", "abs": "https://arxiv.org/abs/2512.16651", "authors": ["Haydn S. Adlong", "Eugen Dizer", "Richard Schmidt", "Atac Imamoglu", "Arthur Christianen"], "title": "Theory of exciton polarons in 2D Wigner crystals", "comment": "9 pages, 8 figures", "summary": "Monolayer transition-metal dichalcogenides (TMDs) provide a platform for realizing Wigner crystals and enable their detection via exciton spectroscopy. We develop a microscopic theoretical model for excitons interacting with the localized electrons of the Wigner crystal, including their vibrational motion. In addition to the previously observed exciton-Umklapp feature, the theory reproduces and explains the higher-band attractive-polaron resonances recently reported experimentally. Our model further uncovers that the appearance of two equal-strength and parallel attractive polarons, as commonly observed in WSe$_2$ and WS$_2$, is a signature of strong correlations in the electronic system. Altogether, our results demonstrate that accounting for electronic interactions is essential to reproduce and interpret the exciton-polaron spectra of TMDs."}
{"id": "2512.15932", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.15932", "abs": "https://arxiv.org/abs/2512.15932", "authors": ["Ping-Rui Tsai", "Tzay-Ming Hong"], "title": "A Dough-Like Model for Understanding Double-Slit Phenomena", "comment": null, "summary": "The probabilistic interference fringes observed in the double slit experiment vividly demonstrate the quantum superposition principle, yet they also highlight a fundamental conceptual challenge: the relationship between a system before and after the measurement. According to Copenhagen interpretation, an unobserved quantum system evolves continuously based on the Schrodinger equation, whereas observation induces an instantaneous collapse of the wave function to an eigenstate. This contrast between continuous evolution and sudden collapse renders the single particle behavior particularly enigmatic, especially given that quantum mechanics itself is constructed upon the statistical behavior of ensembles rather than individual entities. In this study, we introduce a Double Slit Diffraction Surrogate Model DSM based on deep learning, designed to capture the mapping between wave functions and probability distributions. The DSM explores multiple potential propagation paths and adaptively selects optimal transmission channels using gradient descent, forming a backbone for the information through the network. By comparing the interpretability of paths and interference, we propose an intuitive physical analogy: the particle behaves like a stretchable dough, extending across both slits, reconnecting after transmission, allowing detachment before the barrier. Monte Carlo simulations confirm that this framework can naturally reproduce the characteristic interference and diffraction probability patterns. Our approach offers a novel, physically interpretable perspective on quantum superposition and measurement induced collapse. The dough analogy is expected to extend to other quantum phenomena. Finally, we provide a dough based picture, attempting to unify interference, entanglement, and tunneling as manifestations of the same underlying phenomenon."}
{"id": "2512.16736", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16736", "abs": "https://arxiv.org/abs/2512.16736", "authors": ["Xiaofeng Zong", "Ming-Yu Wang", "Jimin Wang", "Ji-Feng Zhang"], "title": "Observer-based Differentially Private Consensus for Linear Multi-agent Systems", "comment": null, "summary": "This paper investigates the differentially private consensus problem for general linear multi-agent systems (MASs) based on output feedback protocols. To protect the output information, which is considered private data and may be at high risk of exposure, Laplace noise is added to the information exchange. The conditions for achieving mean square and almost sure consensus in observer-based MASs are established using the backstepping method and the convergence theory for nonnegative almost supermartingales. It is shown that the separation principle remains valid for the consensus problem of linear MASs with decaying Laplace noise. Furthermore, the convergence rate is provided. Then, a joint design framework is developed for state estimation gain, feedback control gain, and noise to ensure the preservation of ε-differential privacy. The output information of each agent is shown to be protected at every time step. Finally, sufficient conditions are established for simultaneously achieving consensus and preserving differential privacy for linear MASs utilizing both full-order and reduced-order observers. Meanwhile, an ε*-differentially private consensus is achieved to meet the desired privacy level. Two simulation examples are provided to validate the theoretical results."}
{"id": "2512.16736", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16736", "abs": "https://arxiv.org/abs/2512.16736", "authors": ["Xiaofeng Zong", "Ming-Yu Wang", "Jimin Wang", "Ji-Feng Zhang"], "title": "Observer-based Differentially Private Consensus for Linear Multi-agent Systems", "comment": null, "summary": "This paper investigates the differentially private consensus problem for general linear multi-agent systems (MASs) based on output feedback protocols. To protect the output information, which is considered private data and may be at high risk of exposure, Laplace noise is added to the information exchange. The conditions for achieving mean square and almost sure consensus in observer-based MASs are established using the backstepping method and the convergence theory for nonnegative almost supermartingales. It is shown that the separation principle remains valid for the consensus problem of linear MASs with decaying Laplace noise. Furthermore, the convergence rate is provided. Then, a joint design framework is developed for state estimation gain, feedback control gain, and noise to ensure the preservation of ε-differential privacy. The output information of each agent is shown to be protected at every time step. Finally, sufficient conditions are established for simultaneously achieving consensus and preserving differential privacy for linear MASs utilizing both full-order and reduced-order observers. Meanwhile, an ε*-differentially private consensus is achieved to meet the desired privacy level. Two simulation examples are provided to validate the theoretical results."}
{"id": "2512.16823", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.16823", "abs": "https://arxiv.org/abs/2512.16823", "authors": ["Mike Shubrook", "Moritz Cygorek", "Erik Gauger", "Jake Iles-Smith", "Ahsan Nazir"], "title": "Numerically exact open quantum system work statistics with process tensors", "comment": "10 pages, 5 figures, comments welcome", "summary": "Accurately quantifying the thermodynamic work costs of quantum operations is essential for the continued development and optimisation of emerging quantum technologies. This present a significant challenge in regimes of rapid control within complex, non-equilibrium environments - conditions under which many contemporary quantum devices operate and conventional approximations break down. Here, we introduce a process tensor framework that enables the computation of the full numerically exact quantum work statistics of driven open quantum systems. We demonstrate the utility of our approach by applying it to a Landauer erasure protocol operating beyond the weak-coupling, Markovian, and slow-driving limits. The resulting work probability distributions reveal distinct quantum signatures that are missed by low-order moments yet significantly impact the erasure fidelity of the protocol. Our framework delivers non-perturbative accuracy and detail in characterising energy-exchange fluctuations in driven open quantum systems, establishing a powerful and versatile tool for exploring thermodynamics and control in the operating regimes of both near-term and future quantum devices."}
{"id": "2512.16833", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16833", "abs": "https://arxiv.org/abs/2512.16833", "authors": ["Xiaokang Liu", "Rui Duan", "Raymond J. Carroll", "Yang Ning", "Yong Chen"], "title": "Distributed inference for heterogeneous mixture models using multi-site data", "comment": "70 pages, 5 figures", "summary": "Mixture models postulate the overall population as a mixture of finite subpopulations with unobserved membership. Fitting mixture models usually requires large sample sizes and combining data from multiple sites can be beneficial. However, sharing individual participant data across sites is often less feasible due to various types of practical constraints, such as data privacy concerns. Moreover, substantial heterogeneity may exist across sites, and locally identified latent classes may not be comparable across sites. We propose a unified modeling framework where a common definition of the latent classes is shared across sites and heterogeneous mixing proportions of latent classes are allowed to account for between-site heterogeneity. To fit the heterogeneous mixture model on multi-site data, we propose a novel distributed Expectation-Maximization (EM) algorithm where at each iteration a density ratio tilted surrogate Q function is constructed to approximate the standard Q function of the EM algorithm as if the data from multiple sites could be pooled together. Theoretical analysis shows that our estimator achieves the same contraction property as the estimators derived from the EM algorithm based on the pooled data."}
{"id": "2512.16765", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16765", "abs": "https://arxiv.org/abs/2512.16765", "authors": ["Sudip Mandal", "Mihir Ranjan Sahoo", "Kalpataru Pradhan"], "title": "Strain-Controlled Magnetic Phase Transitions through Anisotropic Exchange Interactions: A Combined DFT and Monte Carlo Study", "comment": "18 Pages, 12 Figures", "summary": "Epitaxial strain provides a powerful, non-chemical route to tune the properties of functional materials by manipulating the coupling between spin, charge, and lattice degrees of freedom. Using density functional theory (DFT) calculations and $\\rm BiFeO_3$ as a model system, we first demonstrate how epitaxial strain exactly leads to anisotropic magnetic interactions where the exchange coupling along the $c$-axis differs from that in the $ab$-plane. We show that subtle structural modifications, specifically the distortion from a cubic to a tetragonal lattice, drive a magnetic phase transition from a G-type to a C-type antiferromagnetic (AF) phase. The anisotropy in magnetic interactions, which becomes prominent in the lower symmetry tetragonal phase, provides a direct link between the structural distortion and the potential change in magnetic ordering. For a more comprehensive study, we next investigate the role of strain in driving magnetic phase transitions within a half-filled one-band Hubbard model in three dimensions. In this framework, strain is introduced through anisotropic hopping processes between nearest- and next-nearest-neighbor sites, inspired by the DFT calculations. Using a semiclassical Monte Carlo (s-MC) approach, we construct ground state phase diagrams in the nonperturbative regime, which show how uniaxial strain stabilizes distinct magnetic ground states: Compressive strain drives a transition from a G-type to a C-type AF insulator, whereas tensile strain suppresses the C-type AF order, favoring an A-type AF phase. Overall, our combined DFT and s-MC calculations highlight that strain is a powerful tuning parameter for controlling competing magnetic phases by governing exchange coupling mechanisms in correlated systems, offering valuable insights for the design of strain-controlled materials."}
{"id": "2512.15935", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.15935", "abs": "https://arxiv.org/abs/2512.15935", "authors": ["Patrick Hinrichs", "Douglas Singleton", "Nader Inan"], "title": "AC Stark effect or time-dependent Aharonov-Bohm effect for particle on a ring", "comment": "18 pages, 5 figures, revtex4, accepted for publication in Physics Letters A", "summary": "We study the effect of a time-varying solenoidal vector potential for a quantum particle confined to a ring. The setup appears to be a time-varying version of the Aharonov-Bohm effect, but since the particle moves in the presence of fields, it is not strictly an Aharonov-Bohm effect. The results are similar to the ac Stark effect, but with a time-varying electric field coming from the vector potential, rather than the scalar potential. We compare and contrast the present effect with the standard ac Stark effect. The signature of this setup is the generation of quasi-energy sidebands which are observable via spectroscopy."}
{"id": "2512.15733", "categories": ["math.OC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15733", "abs": "https://arxiv.org/abs/2512.15733", "authors": ["Soufian Ben Amor", "Alain Bui", "Guillaume Guerard"], "title": "A Context-Free Smart Grid Model Using Complex System Approach", "comment": null, "summary": "Energy and pollution are urging problems of the 21th century. By gradually changing the actual power grid system, smart grid may evolve into different systems by means of size, elements and strategies, but its fundamental requirements and objectives will not change such as optimizing production, transmission, and consumption. Studying the smart grid through modeling and simulation provides us with valuable results which cannot be obtained in real world due to time and cost related constraints. Moreover, due to the complexity of the smart grid, achieving global optimization is not an easy task. In this paper, we propose a complex system based approach to the smart grid modeling, accentuating on the optimization by combining game theoretical and classical methods in different levels. Thanks to this combination, the optimization can be achieved with flexibility and scalability, while keeping its generality."}
{"id": "2512.15733", "categories": ["math.OC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15733", "abs": "https://arxiv.org/abs/2512.15733", "authors": ["Soufian Ben Amor", "Alain Bui", "Guillaume Guerard"], "title": "A Context-Free Smart Grid Model Using Complex System Approach", "comment": null, "summary": "Energy and pollution are urging problems of the 21th century. By gradually changing the actual power grid system, smart grid may evolve into different systems by means of size, elements and strategies, but its fundamental requirements and objectives will not change such as optimizing production, transmission, and consumption. Studying the smart grid through modeling and simulation provides us with valuable results which cannot be obtained in real world due to time and cost related constraints. Moreover, due to the complexity of the smart grid, achieving global optimization is not an easy task. In this paper, we propose a complex system based approach to the smart grid modeling, accentuating on the optimization by combining game theoretical and classical methods in different levels. Thanks to this combination, the optimization can be achieved with flexibility and scalability, while keeping its generality."}
{"id": "2512.16886", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16886", "abs": "https://arxiv.org/abs/2512.16886", "authors": ["Oliver Hart", "David T. Stephen", "Evan Wickenden", "Rahul Nandkishore"], "title": "Many-body contextuality and self-testing quantum matter via nonlocal games", "comment": "21 pages, 6 figures", "summary": "Contextuality is arguably the fundamental property that makes quantum mechanics different from classical physics. It is responsible for quantum computational speedups in both magic-state-injection-based and measurement-based models of computation, and can be directly probed in a many-body setting by multiplayer nonlocal quantum games. Here, we discuss a family of games that can be won with certainty when performing single-site Pauli measurements on a state that is a codeword of a Calderbank-Shor-Steane (CSS) error-correcting quantum code. We show that these games require deterministic computation of a code-dependent Boolean function, and that the classical probability of success is upper bounded by a generalized notion of nonlinearity/nonquadraticity. This success probability quantifies the state's contextuality, and is computed via the function's (generalized) Walsh-Hadamard spectrum. To calculate this, we introduce an efficient, many-body-physics-inspired method that involves identifying the symmetries of an auxiliary hypergraph state. We compute the classical probability of success for several paradigmatic CSS codes and relate it to both classical statistical mechanics models and to strange correlators of symmetry-protected topological states. We also consider CSS submeasurement games, which can only be won with certainty by sharing the appropriate codeword up to local isometries. These games therefore enable self-testing, which we illustrate explicitly for the 2D toric code. We also discuss how submeasurement games enable an extensive notion of contextuality in many-body states."}
{"id": "2512.16857", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16857", "abs": "https://arxiv.org/abs/2512.16857", "authors": ["Chao Cheng", "Georgia Papadogeorgou", "Fan Li"], "title": "Identification and efficient estimation of compliance and network causal effects in cluster-randomized trials", "comment": null, "summary": "Treatment noncompliance is pervasive in infectious disease cluster-randomized trials. Although all individuals within a cluster are assigned the same treatment condition, the treatment uptake status may vary across individuals due to noncompliance. We propose a semiparametric framework to evaluate the individual compliance effect and network assignment effect within principal stratum exhibiting different patterns of noncompliance. The individual compliance effect captures the portion of the treatment effect attributable to changes in treatment receipt, while the network assignment effect reflects the pure impact of treatment assignment and spillover among individuals within the same cluster. Unlike prior efforts which either empirically identify or interval identify these estimands, we characterize new structural assumptions for nonparametric point identification. We then develop semiparametrically efficient estimators that combine data-adaptive machine learning methods with efficient influence functions to enable more robust inference. Additionally, we introduce sensitivity analysis methods to study the impact under assumption violations, and apply the proposed methods to reanalyze a cluster-randomized trial in Kenya that evaluated the impact of school-based mass deworming on disease transmission."}
{"id": "2512.16829", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16829", "abs": "https://arxiv.org/abs/2512.16829", "authors": ["Yoshito Watanabe", "Simon Trebst", "Ciarán Hickey"], "title": "Two-dimensional coherent spectroscopy of CoNb$_2$O$_6$", "comment": "17 pages, 13 figures", "summary": "With recent advances in terahertz (THz) sources and detection, two-dimensional coherent spectroscopy (2DCS), which allows to probe nonlinear responses in a two-frequency plane, now reaches the meV regime relevant for quasiparticle excitations in magnetic materials. This opens a promising route to reveal many-body phenomena that evade linear-response probes. To date most experimental applications have focused on classical magnets, and a solid demonstration in a quantum magnet has yet to be established. Here we present a theoretical study of 2DCS in CoNb$_2$O$_6$, a quasi-one-dimensional Ising magnet that is believed to host fractionalized spinons which at low temperatures are confined by weak interchain coupling. Our analysis, which builds on an effective $S=1/2$ Hamiltonian is found to reveal unambiguous 2DCS signatures of spinon deconfinement above the low-temperature ordered phase. Using a four-spinon approximation, we track these 2DCS signatures by sequentially building a faithful microscopic model for CoNb$_2$O$_6$, starting from the exactly solvable one-dimensional transverse-field Ising model (1$d$ TFIM) and successively adding interactions to capture its key low-energy physics. In particular, adding a bond-dependent staggered YZ interaction to the 1$d$-TFIM already reproduces many key spectral features of the full material Hamiltonian. Within this TFIM+YZ model, we find a series of bound states, including a four-spinon bound state that is distinct from the familiar two-spinon bound states. We further find that introducing a confinement potential suppresses sharp spinon-echo features in the two-frequency space, which are thought to reflect an underlying continuum of fractionalized excitations. Our results provide concrete predictions and clear targets for future THz 2DCS experiments on CoNb$_2$O$_6$ and related quasi-one-dimensional quantum magnets."}
{"id": "2512.15990", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.15990", "abs": "https://arxiv.org/abs/2512.15990", "authors": ["Arpan Akash Ray", "Boris Skoric"], "title": "Random coding for long-range continuous-variable QKD", "comment": null, "summary": "Quantum Key Distribution (QKD) schemes are key exchange protocols based on the physical properties of quantum channels. They avoid the computational-hardness assumptions that underlie the security of classical key exchange. Continuous-Variable QKD (CVQKD), in contrast to qubit-based discrete-variable (DV) schemes, makes use of quadrature measurements of the electromagnetic field. CVQKD has the advantage of being compatible with standard telecom equipment, but at long distances has to deal with very low signal to noise ratios, which necessitates labour-intensive error correction. It is challenging to implement the error correction decoding in realtime.\n  In this paper we introduce a random-codebook error correction method that is suitable for long range Gaussian-modulated CVQKD. We use likelihood ratio scoring with block rejection based on thresholding. For proof-technical reasons, the accept/reject decisions are communicated in encrypted form; in this way we avoid having to deal with non-Gaussian states in the analysis of the leakage. The error correction method is highly parallelisable, which is advantageous for realtime implementation. Under conservative assumptions on the computational resources, we predict a realtime key ratio of at least 8% of the Devetak-Winter value, which outperforms existing reconciliation schemes."}
{"id": "2512.15735", "categories": ["math.OC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15735", "abs": "https://arxiv.org/abs/2512.15735", "authors": ["Ningwei Bai", "Chi Pui Chan", "Qichen Yin", "Tengyang Gong", "Yunda Yan", "Zezhi Tang"], "title": "Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming", "comment": "9 pages, 9 figures, 2 numerical examples. This version presents a unified event-triggered ESO-ADP control framework, including stability analysis, algorithm description, and simulation studies. A journal extension with full hybrid-system stability proofs will follow", "summary": "This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes."}
{"id": "2512.15735", "categories": ["math.OC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.15735", "abs": "https://arxiv.org/abs/2512.15735", "authors": ["Ningwei Bai", "Chi Pui Chan", "Qichen Yin", "Tengyang Gong", "Yunda Yan", "Zezhi Tang"], "title": "Deep Reinforcement Learning Optimization for Uncertain Nonlinear Systems via Event-Triggered Robust Adaptive Dynamic Programming", "comment": "9 pages, 9 figures, 2 numerical examples. This version presents a unified event-triggered ESO-ADP control framework, including stability analysis, algorithm description, and simulation studies. A journal extension with full hybrid-system stability proofs will follow", "summary": "This work proposes a unified control architecture that couples a Reinforcement Learning (RL)-driven controller with a disturbance-rejection Extended State Observer (ESO), complemented by an Event-Triggered Mechanism (ETM) to limit unnecessary computations. The ESO is utilized to estimate the system states and the lumped disturbance in real time, forming the foundation for effective disturbance compensation. To obtain near-optimal behavior without an accurate system description, a value-iteration-based Adaptive Dynamic Programming (ADP) method is adopted for policy approximation. The inclusion of the ETM ensures that parameter updates of the learning module are executed only when the state deviation surpasses a predefined bound, thereby preventing excessive learning activity and substantially reducing computational load. A Lyapunov-oriented analysis is used to characterize the stability properties of the resulting closed-loop system. Numerical experiments further confirm that the developed approach maintains strong control performance and disturbance tolerance, while achieving a significant reduction in sampling and processing effort compared with standard time-triggered ADP schemes."}
{"id": "2512.15726", "categories": ["math.OC", "math.PR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.15726", "abs": "https://arxiv.org/abs/2512.15726", "authors": ["Can Er", "Mo Liu"], "title": "Decision-Focused Bias Correction for Fluid Approximation", "comment": null, "summary": "Fluid approximation is a widely used approach for solving two-stage stochastic optimization problems, with broad applications in service system design such as call centers and healthcare operations. However, replacing the underlying random distribution (e.g., demand distribution) with its mean (e.g., the time-varying average arrival rate) introduces bias in performance estimation and can lead to suboptimal decisions. In this paper, we investigate how to identify an alternative point statistic, which is not necessarily the mean, such that substituting this statistic into the two-stage optimization problem yields the optimal decision. We refer to this statistic as the decision-corrected point estimate (time-varying arrival rate). For a general service network with customer abandonment costs, we establish necessary and sufficient conditions for the existence of such a corrected point estimate and propose an algorithm for its computation. Under a decomposable network structure, we further show that the resulting decision-corrected point estimate is closely related to the classical newsvendor solution. Numerical experiments demonstrate the superiority of our decision-focused correction method compared to the traditional fluid approximation."}
{"id": "2512.16834", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16834", "abs": "https://arxiv.org/abs/2512.16834", "authors": ["N. Hernandez-Cepeda", "Sergio E. Ulloa"], "title": "Optimal array geometries for kinetic magnetism and Nagaoka polarons", "comment": null, "summary": "Quantum dot (QD) platforms have enabled the direct observation of Nagaoka ferromagnetism (NFM) in small arrays and non-infinite interaction strength. However, optimizing the cluster connectivity characteristics that yield a ground state with maximal spin and their robustness against magnetic fields remains unexplored. Employing exact diagonalization of the Hubbard Hamiltonian, we find a connection between the existence of kinetic ferromagnetism and graph theory descriptions. Algebraic connectivity ($λ_2$) and Katz centrality (KC) are shown to be related to the spin-correlation over the system. In square arrays, the onset of NFM is found to be $t_c/U\\simeq λ_2^2$. In optimal cluster geometries, large $λ_2$ and low KC fluctuation per site are found to enhance $t_c/U$, extending the NFM phase while diminishing the strength of spin correlation clouds. A perpendicular magnetic field introduces Aharonov-Bohm phases, and a critical flux for which NFM is destroyed. We further find that tuning the flux phase to $π$ results in a ground state that exhibits antiferromagnetic correlations (counter-Nagaoka state). Our results illustrate how NFM and polaron formation can be predicted from the array's connectivity ($λ_2$ and KC), and how the introduction of flux results in the counterintuitive destruction of kinetic ferromagnetism in the system."}
{"id": "2512.16016", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16016", "abs": "https://arxiv.org/abs/2512.16016", "authors": ["Luke C. Ugwuoke", "Tjaart P. J. Krüger", "Mark S. Tame"], "title": "Stationary two-qubit entanglement mediated by one-dimensional plasmonic nanoarrays", "comment": "12 pages, 8 figures", "summary": "Entanglement is one of the key measures of quantum correlations present in nanophotonic systems, with promising applications in quantum optics and beyond. Previous studies have shown that the degree of entanglement between two quantum dot qubits is preserved when a metal nanoparticle is used to mediate the interactions between the qubits. In this work, we investigate long-range plasmonic mediation of qubit--qubit entanglement by studying the impact of the number of mediating metal nanoparticles on stationary concurrence. Collinear and periodically spaced metal nanoparticles that satisfy the weak-coupling approximation are considered. An effective model that enables the derivation of the mediated interactions within the framework of cavity quantum electrodynamics is employed. Under weak driving at the single particle resonance frequency, the model shows that odd-number arrays are more robust to entanglement decay. We attribute this to strong inter-qubit dissipative coupling as a result of a hybridized dipole plasmon resonating with the driving frequency in odd-number arrays. These arrays can sustain non-vanishing stationary entanglement beyond an inter-qubit spacing of one micron, opening up the possibility of independent spatial optical probing of each quantum dot."}
{"id": "2512.16608", "categories": ["physics.soc-ph", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16608", "abs": "https://arxiv.org/abs/2512.16608", "authors": ["Jannie Coenen", "Vítor Vasconcelos", "Heiman Wertheim", "Marcel Olde Rikkert", "Sophie Hadjisotiriou", "Vittorio Nespeca", "Tom Oreel", "Rick Quax", "Etiënne Rouwette", "Vincent Marchau", "Hubert Korzilius"], "title": "Resilience of coupled systems under deep uncertainty and dynamic complexity: An integrative literature review", "comment": null, "summary": "Resilience in coupled systems is increasingly critical in addressing global challenges such as climate change and pandemics. These systems show unpredictable behaviour due to dynamic complexity and deep uncertainty across spatiotemporal scales. Despite growing interest, few studies systematically integrate both concepts when assessing resilience. This paper conducts an integrative review of 102 English-language publications to identify gaps in current approaches. Findings reveal that most papers address lower levels of uncertainty and rarely consider dynamic complexity and deep uncertainty simultaneously, which limits the effectiveness of resilience strategies. To advance systems research, we propose a conceptual framework and practical tools to support researchers and decision-makers in evaluating and improving resilience. The paper also outlines future research directions for more robust, adaptive, and integrative resilience assessments."}
{"id": "2512.16608", "categories": ["physics.soc-ph", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.16608", "abs": "https://arxiv.org/abs/2512.16608", "authors": ["Jannie Coenen", "Vítor Vasconcelos", "Heiman Wertheim", "Marcel Olde Rikkert", "Sophie Hadjisotiriou", "Vittorio Nespeca", "Tom Oreel", "Rick Quax", "Etiënne Rouwette", "Vincent Marchau", "Hubert Korzilius"], "title": "Resilience of coupled systems under deep uncertainty and dynamic complexity: An integrative literature review", "comment": null, "summary": "Resilience in coupled systems is increasingly critical in addressing global challenges such as climate change and pandemics. These systems show unpredictable behaviour due to dynamic complexity and deep uncertainty across spatiotemporal scales. Despite growing interest, few studies systematically integrate both concepts when assessing resilience. This paper conducts an integrative review of 102 English-language publications to identify gaps in current approaches. Findings reveal that most papers address lower levels of uncertainty and rarely consider dynamic complexity and deep uncertainty simultaneously, which limits the effectiveness of resilience strategies. To advance systems research, we propose a conceptual framework and practical tools to support researchers and decision-makers in evaluating and improving resilience. The paper also outlines future research directions for more robust, adaptive, and integrative resilience assessments."}
{"id": "2512.16241", "categories": ["math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16241", "abs": "https://arxiv.org/abs/2512.16241", "authors": ["Yingjie Zhou", "Xiaoqian Wang", "Tao Li"], "title": "Distributed Online Economic Dispatch With Time-Varying Coupled Inequality Constraints", "comment": null, "summary": "We investigate the distributed online economic dispatch problem for power systems with time-varying coupled inequality constraints. The problem is formulated as a distributed online optimization problem in a multi-agent system. At each time step, each agent only observes its own instantaneous objective function and local inequality constraints; agents make decisions online and cooperate to minimize the sum of the time-varying objectives while satisfying the global coupled constraints. To solve the problem, we propose an algorithm based on the primal-dual approach combined with constraint-tracking. Under appropriate assumptions that the objective and constraint functions are convex, their gradients are uniformly bounded, and the path length of the optimal solution sequence grows sublinearly, we analyze theoretical properties of the proposed algorithm and prove that both the dynamic regret and the constraint violation are sublinear with time horizon T. Finally, we evaluate the proposed algorithm on a time-varying economic dispatch problem in power systems using both synthetic data and Australian Energy Market data. The results demonstrate that the proposed algorithm performs effectively in terms of tracking performance, constraint satisfaction, and adaptation to time-varying disturbances, thereby providing a practical and theoretically well-supported solution for real-time distributed economic dispatch."}
{"id": "2512.16836", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16836", "abs": "https://arxiv.org/abs/2512.16836", "authors": ["Debarghya Chakraborty", "Dario Rosa"], "title": "Revival Dynamics from Equilibrium States: Scars from Chords in SYK", "comment": "33 pages, 8 figures", "summary": "We develop a novel framework to build quantum many-body scar states in bipartite systems characterized by perfect correlation between the Hamiltonians governing the two sides. By means of a Krylov construction, we build an interaction term which supports a tower of equally-spaced energy eigenstates. This gives rise to finite-time revivals whenever the system is initialized in a purification of a generic equilibrium state. The dynamics is universally characterized, and is largely independent of the specific details of the Hamiltonians defining the individual partitions. By considering the two-sided chord states of the double-scaled SYK model, we find an approximate realization of this framework. We analytically study the revival dynamics, finding rigid motion for wavepackets localized on the spectrum of a single SYK copy. These findings are tested numerically for systems of finite size, showing excellent agreement with the analytical predictions."}
{"id": "2512.16047", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16047", "abs": "https://arxiv.org/abs/2512.16047", "authors": ["Nicholas Brunelle", "Joshua Kanaganayagam", "Mehdi Keshavarz", "Chloe Clear", "Oney Soykal", "Myles Ruether", "Adam DeAbreu", "Amirhossein AlizadehKhaledi", "Yihuang Xiong", "Nikolay V. Abrosimov", "Geoffroy Hautier", "Michael Thewalt", "Stephanie Simmons", "Daniel Higginbottom"], "title": "Silicon T centre hyperfine structure and memory protection schemes", "comment": "8 pages, 5 figures", "summary": "Combining the long-coherence of spin qubits and the capability to transmit information and entanglement through photons, spin-photon interfaces (SPIs) are a promising platform for networked quantum computation and long-distance quantum communication. SPIs that possess local `memory' qubits in addition to the optically coupled `communication' qubit can improve remote entanglement fidelities through brokered entanglement schemes and entanglement purification. In these schemes, it is critical to protect the memory qubit from decoherence during entanglement operations on the communications qubit. Silicon, a platform with mature microelectronic and nanophotonic fabrication, is host to the T centre, an SPI with emission in the telecommunications O-band that directly integrates with silicon nanophotonics. Cavity-coupled T centres are a platform for brokered entanglement distribution in silicon photonic circuits and over long-distance optical fibre links. The T centre's electron and nuclear spin qubits are an intrinsic register of communication and memory qubits respectively, with anisotropic hyperfine coupling. In this work we determine the T centre's hydrogen hyperfine coupling tensor. We also introduce schemes to protect against dephasing or eliminate relaxation of the T centre's hydrogen memory qubit during optical excitation. These results address a key challenge for practical T centre quantum networks."}
{"id": "2512.16759", "categories": ["math.ST", "math.PR", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16759", "abs": "https://arxiv.org/abs/2512.16759", "authors": ["Dante de Roos", "Ben Chugg", "Peter Grünwald", "Aaditya Ramdas"], "title": "Rao-Blackwellized e-variables", "comment": "19 pages", "summary": "We show that for any concave utility, the expected utility of an e-variable can only increase after conditioning on a sufficient statistic. The simplest form of the result has an extremely straightforward proof, which follows from a single application of Jensen's inequality. Similar statements hold for compound e-variables, asymptotic e-variables, and e-processes. These results echo the Rao-Blackwell theorem, which states that the expected squared error of an estimator can only decrease after conditioning on a sufficient statistic. We provide several applications of this insight, including a simplified derivation of the log-optimal e-variable for linear regression with known variance."}
{"id": "2512.16868", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16868", "abs": "https://arxiv.org/abs/2512.16868", "authors": ["Jhinkyu Choi", "Mohan B. Neupane", "L. H. Vilela-Leão", "Bishnu P. Belbase", "Arjun Unnikrishnan", "Syeda Neha Zaidi", "Jukka I. Väyrynen", "Arnab Banerjee"], "title": "Wiedemann-Franz violation and thermal Hall effect in kagome metal TbCr6Ge6", "comment": null, "summary": "The thermal Hall effect has emerged as a powerful probe of exotic excitations in correlated quantum materials, providing access to charge-neutral heat carriers that remain invisible to electrical transport. To directly examine how heat and charge respond in relation within a kagome metal, we investigate the ferrimagnetic rare-earth 1-6-6 compound TbCr6Ge6 using the Wiedemann-Franz (WF) framework. We observe a dramatic breakdown of the WF law across the ferrimagnetic transition, where both longitudinal and transverse Lorenz ratios, L_{xx,xy} = κ_{xx,xy} / (T σ_{xx,xy}), deviate strongly from the Sommerfeld value L_0. After a partial recovery toward L_0 near 5-7 K, the Lorenz ratios are sharply suppressed well below L_0 despite a metallic charge response. We further find a pronounced low-temperature suppression of both L_{xx} and L_{xy} and a sign-changing transverse Lorenz ratio, indicating a clear decoupling between heat and charge transport and signaling substantial contributions from charge-neutral excitations whose Berry-curvature-driven transverse response evolves with temperature and magnetic field. TbCr6Ge6 thus provides a tunable metallic platform in which exchange-driven ferrimagnetism governs both longitudinal and transverse thermal responses, enabling controlled departures from Wiedemann-Franz behavior over an experimentally accessible temperature and field range."}
{"id": "2512.16097", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2512.16097", "abs": "https://arxiv.org/abs/2512.16097", "authors": ["Jian-Jia Wang", "Ling-Zhi Tang", "Yan-Xiong Du", "Dan-Wei Zhang"], "title": "Discrete time crystals enhanced by Stark potentials in Rydberg atom arrays", "comment": "5 pages, 5 figures", "summary": "Discrete time crystals (DTCs) are non-equilibrium phases in periodically driven systems that exhibit spontaneous breaking of discrete time-translation symmetry. The stabilization of most DTC phases is achieved via the disorder-induced many-body localization. In this work, we propose an experimental scheme to realize disorder-free DTCs in a periodically driven Rydberg atom array. Our scheme utilizes a linear potential in the atomic detuning to enhance the DTC order, without being tired to (Stark) many-body localization. We numerically demonstrate that the Stark potential enhances the robustness of the DTC against the flip imperfections and extends its lifetime, which are independent of initial states. Thus, our scheme provides a promising way to explore DTCs in Rydberg atom arrays without disorder averaging and special state preparation."}
{"id": "2512.16827", "categories": ["physics.soc-ph", "stat.CO", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.16827", "abs": "https://arxiv.org/abs/2512.16827", "authors": ["Juan Sosa", "Brayan Riveros", "Emma J. Camargo-Díaz"], "title": "The Colombian legislative process, 2014-2025: networks, topics, and polarization", "comment": "48 pages, in Spanish language, 23 figures, 13 tables", "summary": "The legislative output of Colombia's House of Representatives between 2014 and 2025 is analyzed using 4,083 bills. Bipartite networks are constructed between parties and bills, and between representatives and bills, along with their projections, to characterize co-sponsorship patterns, centrality, and influence, and to assess whether political polarization is reflected in legislative collaboration. In parallel, the content of the initiatives is studied through semantic networks based on co-occurrences extracted from short descriptions, and topics by party and period are identified using a stochastic block model for weighted networks, with additional comparison using Latent Dirichlet Allocation. In addition, a Bayesian sociability model is applied to detect terms with robust connectivity and to summarize discursive cores. Overall, the approach integrates relational and semantic structure to describe thematic shifts across administrations, identify influential actors and collectives, and provide a reproducible synthesis that promotes transparency and citizen oversight of the legislative process."}
{"id": "2512.16888", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16888", "abs": "https://arxiv.org/abs/2512.16888", "authors": ["Jens Havgaard Nyhegn", "Esben Rohan Christensen", "Georg M. Bruun"], "title": "An exciton interacting with the phonons of an electronic Wigner crystal", "comment": null, "summary": "With the advent of atomically thin and tunable van der Waals materials, a two-dimensional electronic Wigner crystal has recently been observed. The smoking gun signal was the appearance of an umklapp branch in optical exciton spectroscopy coming from the periodic potential generated by the Wigner crystal assumed to be static. Vibrations of the Wigner crystal however leads to a gapless phonon spectrum, which may affect the exciton spectrum. To explore this, we develop a field theoretical description of an exciton interacting with electrons forming a Wigner crystal including the coupling to the phonons. We show that importance of the exciton-phonon coupling scales with the exciton-electron interaction strength relative to the typical phonon energy squared. The motion of the exciton leads to two kinds of scattering processes, where the exciton emits a phonon either staying within the same Bloch band (intraband scattering) or changing its band (interband scattering). Using a non-perturbative self-consistent Born approximation, we demonstrate that these scattering processes lead to the formation of quasiparticles (polarons) consisting of the exciton in Bloch states dressed by Wigner crystal phonons. The energy shift and damping of these polarons depend on the electron density in a non-trivial way since it affects both the exciton-phonon interaction strength, as well as the phonon and exciton spectra. In particular, the damping is strongly affected by whether the polaron energy is inside the gapless phonon scattering continuum or not. Using these results, we finally analyse their effects on the observed spectral properties of the exciton."}
{"id": "2512.16114", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16114", "abs": "https://arxiv.org/abs/2512.16114", "authors": ["Yanhao Sun", "Ziyang Chen", "Xiangyu Wang", "Song Yu", "Hong Guo"], "title": "Analyzing the performance of CV-MDI QKD under continuous-mode scenarios", "comment": "12 pages, 6 figures", "summary": "Continuous-variable measurement-device-independent quantum key distribution (CV-MDI QKD) can address vulnerabilities on the detection side of a QKD system. The core of this protocol involves continuous-variable Bell measurements performed by an untrusted third party. However, in high-speed systems, spectrum broadening causes Bell measurements to deviate from the ideal single-mode scenario, resulting in mode mismatches, reduced performance, and compromised security. Here, we introduce temporal modes (TMs) to analyze the performance of CV-MDI QKD under continuous-mode scenarios. The mismatch between Bob's transmitting mode and Bell measurement mode has a more significant effect on system performance compared to that on Alice's side. When the Bell receiver is close to Bob and the mismatch is set to just 5%, the transmission distance drastically decreases from 87.96 km to 18.50 km. In comparison, the same mismatch for Alice reduces the distance to 86.83 km. This greater degradation on Bob's side can be attributed to the asymmetry in the data modification step. Furthermore, the mismatch in TM characteristics leads to a significant reduction in the secret key rate by 83% when the transmission distance is set to 15 km, which severely limits the practical usability of the protocol over specific distances. These results indicate that in scenarios involving continuous-mode interference, such as large-scale MDI network setups, careful consideration of each user's TM characteristics is crucial. Rigorous pre-calibration of these modes is essential to ensure the system's reliability and efficiency."}
{"id": "2512.16654", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16654", "abs": "https://arxiv.org/abs/2512.16654", "authors": ["Wanbing Zhao", "H. W. Shawn Liew", "Wen Wei Ho", "Chunxiao Liu", "Vir B. Bulchandani"], "title": "Scalable tests of quantum contextuality from stabilizer-testing nonlocal games", "comment": "27+4 pages, 4 figures", "summary": "Soon after the dawn of quantum error correction, DiVincenzo and Peres observed that stabilizer codewords could give rise to simple proofs of quantumness via contextuality. This discovery can be recast in the language of nonlocal games: every $n$-qubit stabilizer state defines a specific \"stabilizer-testing\" $n$-player nonlocal game, which quantum players can win with probability one. If quantum players can moreover outperform all possible classical players, then the state is contextual. However, the classical values of stabilizer-testing games are largely unknown for scalable examples beyond the $n$-qubit GHZ state. We introduce several new methods for upper-bounding the classical values of these games. We first prove a general coding-theory bound for all stabilizer-testing games: if the classical value $p_{\\mathrm{cl}}^* < 1$, then $p_{\\mathrm{cl}}^* \\leq 7/8$, i.e., there is no classical strategy that can perform as well as the optimal quantum strategy even in an asymptotic sense. We then show how to tighten this bound for the most common scalable examples, namely GHZ, toric-code and cyclic cluster states. In particular, we establish an asymptotically tight upper bound for cyclic cluster states using transfer-matrix methods. This leads to the striking conclusion that measuring an exponentially small fidelity to the cyclic cluster state will suffice to witness its contextuality."}
{"id": "2512.16138", "categories": ["quant-ph", "nucl-th"], "pdf": "https://arxiv.org/pdf/2512.16138", "abs": "https://arxiv.org/abs/2512.16138", "authors": ["Ionel Stetcu"], "title": "Antisymmetrization of composite fermionic states for quantum simulations of nuclear reactions in first-quantization mapping", "comment": "6 pages, 2 figures; 2 pages of supplemental material included", "summary": "I present a first-quantization deterministic algorithm for antisymmetrizing a spatially separated target-projectile system containing $N_T$ and $N_p$ identical fermions, respectively. The method constructs a fully antisymmetric wavefunction from the product of two independently antisymmetrized many-body states, each of which may be a superposition of Slater determinants. The algorithm uses a Dicke-state ancilla register that coherently encodes all one-particle exchange channels between the two subsystems, and, crucially, requires only single-particle swaps to generate the full antisymmetric structure. A total of $O(N_T N_p)$ single-particle exchanges are needed, with up to $N_p$ of them implemented in parallel, if an additional $N_p$ ancillae are used. The correct fermionic phase is incorporated through application of $Z$ gates on $N_T$ ancillae, after which the ancilla register is efficiently uncomputed using a compact sequence of controlled operations. This construction provides a nontrivial and scalable protocol for preparing fully antisymmetric states in reaction and scattering simulations, significantly expanding the range of systems that can be addressed with first-quantized quantum algorithms."}
{"id": "2512.16886", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16886", "abs": "https://arxiv.org/abs/2512.16886", "authors": ["Oliver Hart", "David T. Stephen", "Evan Wickenden", "Rahul Nandkishore"], "title": "Many-body contextuality and self-testing quantum matter via nonlocal games", "comment": "21 pages, 6 figures", "summary": "Contextuality is arguably the fundamental property that makes quantum mechanics different from classical physics. It is responsible for quantum computational speedups in both magic-state-injection-based and measurement-based models of computation, and can be directly probed in a many-body setting by multiplayer nonlocal quantum games. Here, we discuss a family of games that can be won with certainty when performing single-site Pauli measurements on a state that is a codeword of a Calderbank-Shor-Steane (CSS) error-correcting quantum code. We show that these games require deterministic computation of a code-dependent Boolean function, and that the classical probability of success is upper bounded by a generalized notion of nonlinearity/nonquadraticity. This success probability quantifies the state's contextuality, and is computed via the function's (generalized) Walsh-Hadamard spectrum. To calculate this, we introduce an efficient, many-body-physics-inspired method that involves identifying the symmetries of an auxiliary hypergraph state. We compute the classical probability of success for several paradigmatic CSS codes and relate it to both classical statistical mechanics models and to strange correlators of symmetry-protected topological states. We also consider CSS submeasurement games, which can only be won with certainty by sharing the appropriate codeword up to local isometries. These games therefore enable self-testing, which we illustrate explicitly for the 2D toric code. We also discuss how submeasurement games enable an extensive notion of contextuality in many-body states."}
{"id": "2512.16168", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16168", "abs": "https://arxiv.org/abs/2512.16168", "authors": ["Danilo F. Schafaschek", "Giovani L. Vasconcelos", "Antônio M. S. Macêdo"], "title": "Tunneling in double-well potentials within stochastic quantization: Application to ammonia inversion", "comment": "16 pages, 10 figures", "summary": "Stochastic quantization - introduced by Nelson in 1966 - describes quantum behavior as a conservative diffusion process in which a particle undergoes Brownian-like motion with a fluctuation amplitude set by Planck's constant. While it fully reproduces conventional quantum mechanics, this approach provides an alternative framework that enables the study of dynamical quantities not easily defined within the standard formulation. In the present work, stochastic quantization is employed to investigate tunneling-time statistics for bound states in double-well potentials. Using first-passage time theory within the stochastic quantization framework, both the mean tunneling time, $\\barτ$, and the full probability distribution, $p(τ)$, are computed, and the theoretical predictions are validated through extensive numerical simulations of stochastic trajectories for the two potentials considered as representative cases. For the square double-well potential, analytical expressions for $\\barτ$ are derived and show excellent agreement with simulations. In the high-barrier limit, the results reveal a direct relation between the stochastic-mechanical and quantum-mechanical tunneling times, expressed as $τ_{\\mathrm{QM}} = (π/2)\\barτ$, where $τ_{\\mathrm{QM}}$ corresponds to half the oscillation period of the probability of finding the particle in either well. This relation is further confirmed for generic double-well systems through a WKB analysis. As a concrete application, the inversion dynamics of the ammonia molecule is analyzed, yielding an inversion frequency of approximately $24$ GHz, in close agreement with experimental observations. These results highlight the potential of stochastic quantization as a powerful and physically insightful framework for analyzing tunneling phenomena in quantum systems."}
{"id": "2512.16177", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16177", "abs": "https://arxiv.org/abs/2512.16177", "authors": ["Junggu Choi", "Tak Hur", "Seokhoon Jeong", "Kyle L. Jung", "Jun Bae Park", "Junho Lee", "Jae U. Jung", "Daniel K. Park"], "title": "Optimizing Quantum Data Embeddings for Ligand-Based Virtual Screening", "comment": "16 pages, 5 figures", "summary": "Effective molecular representations are essential for ligand-based virtual screening. We investigate how quantum data embedding strategies can improve this task by developing and evaluating a family of quantum-classical hybrid embedding approaches. These approaches combine classical neural networks with parameterized quantum circuits in different ways to generate expressive molecular representations and are assessed across two benchmark datasets of different sizes: the LIT-PCBA and COVID-19 collections. Across multiple biological targets and class-imbalance settings, several quantum and hybrid embedding variants consistently outperform classical baselines, especially in limited-data regimes. These results highlight the potential of optimized quantum data embeddings as data-efficient tools for ligand-based virtual screening."}
{"id": "2512.16192", "categories": ["quant-ph", "math.FA"], "pdf": "https://arxiv.org/pdf/2512.16192", "abs": "https://arxiv.org/abs/2512.16192", "authors": ["Hassan Nasreddine"], "title": "Entropy Stability and Spectral Concentration under Convex Block Constraints", "comment": "23 pages", "summary": "We investigate entropy minimization problems for quantum states subject to convex block-diagonal constraints. Our principal result is a quantitative stability theorem: if a state has entropy within epsilon of the minimum possible value under a fixed block constraint, then it must lie within O(epsilon^{1/2}) in trace norm of the manifold of entropy minimizers. We show that this rate is optimal. The analysis is entirely finite-dimensional and relies on a precise decomposition of entropy into classical and internal components, together with sharp relative entropy inequalities. As an application, we study finite additive operators whose spectral decomposition induces natural block constraints. In this setting, the stability theorem yields quantitative non-concentration bounds for induced spectral measures. The framework is abstract and independent of arithmetic input. It provides a general stability principle for entropy minimizers under linear spectral constraints."}
{"id": "2512.16197", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.16197", "abs": "https://arxiv.org/abs/2512.16197", "authors": ["Sean Doan", "Sahil D. Patel", "Yilin Chen", "Jordan A. Gusdorff. Mark E. Turiansky", "Luis Villagomez", "Luka Jevremovic", "Nicholas Lewis", "Kenji Watanabe", "Takashi Taniguchi", "Lee C. Bassett", "Chris Van de Walle", "Galan Moody"], "title": "Near-Infrared Quantum Emission from Oxygen-Related Defects in hBN", "comment": null, "summary": "Color centers hosted in hexagonal boron nitride (hBN) have emerged as a promising platform for single-photon emission and coherent spin-photon interfaces that underpin quantum communication and quantum networking technologies. As a wide-bandgap van der Waals material, hBN can host individual optically active quantum defects emitting across the ultraviolet to visible spectrum, but existing color centers often show broad phonon sidebands (PSBs), unstable emission, or inconvenient wavelengths. Here, we show a simple, scalable oxygen-plasma process that reproducibly creates oxygen-related single quantum emitters in hBN with blinking-free zero-phonon lines spanning the near-infrared (NIR) spectrum from 700-960 nanometers. These emitters demonstrate room-temperature operation, high brightness, and ultra-sharp cryogenic linewidths in the few-gigahertz range under non-resonant excitation. Analysis of the PSBs shows weak electron-phonon coupling and predominant zero-phonon-line emission, while first-principles calculations identify plausible oxygen-related defect configurations. These emitters provide a promising platform for indistinguishable NIR single photons towards free-space quantum networking."}
{"id": "2512.16232", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16232", "abs": "https://arxiv.org/abs/2512.16232", "authors": ["Xin Wang", "Zhao-Min Gao"], "title": "Amplifying Decoherence-Free Many-Body Interactions with Giant Atoms Coupled to Parametric Waveguide", "comment": "11 pages, 8 figures", "summary": "Parametric amplification offers a powerful means to enhance quantum interactions through field squeezing, yet it typically introduces additional noise which accelerates quantum decoherence, a major obstacle for scalable quantum information processing. The squeezing field is implemented in cavities rather than continuous waveguides, thereby limiting its scalability for applications in quantum simulation. Giant atoms, which couple to waveguides at multiple points, provide a promising route to mitigate dissipation via engineered interference, enabling decoherence-free interactions. We extend the squeezing-amplified interaction to a novel quantum platform combining giant atoms with traveling-wave parametric waveguides based on $χ^{(2)}$ nonlinearity. By exploiting destructive interference between different coupling points, the interaction between giant atoms is not only significantly enhanced but also becomes immune to squeezed noise. Unlike conventional waveguide quantum electrodynamics without a squeezing pump, the giant emitters exhibit both exchange and pairing interactions, making this platform particularly suitable for simulating many-body quantum physics. More intriguingly, the strengths of these interactions can be smoothly tuned by adjusting the squeezing and coupling parameters. Our architecture thus provides a versatile and scalable platform for quantum simulation of strongly correlated physics and paves the way toward robust quantum control in many-body regimes."}
{"id": "2512.16242", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16242", "abs": "https://arxiv.org/abs/2512.16242", "authors": ["Smritikana Patra", "Soumyajit Pal", "Ranendu Adhikary"], "title": "Self-testing GHZ state via a Hardy-type paradox", "comment": "13 pages, 2 figures, comments are welcome", "summary": "Self-testing is a correlation-based framework that enables the certification of both the underlying quantum state and the implemented measurements without imposing any assumptions on the internal structure of the devices. In this work, we introduce a self-testing protocol for the Greenberger-Horne-Zeilinger (GHZ) state based on a natural generalization of Hardy's nonlocality argument. Within this framework, we prove that the correlation achieving the maximal Hardy success probability constitutes an extremal point of the quantum correlation set and, moreover, that this point is \\emph{exposed}. To address experimentally relevant imperfections, we further develop a robust self-testing analysis tailored to the Hardy construction. Additionally, we show that, in this scenario, the quantum correlation that attains the maximal violation of the Hardy-type paradox coincides with the correlation that yields the maximal violation of the Mermin inequality. This establishes a unified perspective in which the same multipartite correlation admits both a logical-paradox interpretation and a Bell-inequality-based characterization. Collectively, our results pave the way for investigating whether the correlations that maximally violate the generalized $N$-party Hardy paradox remain exposed in higher-party regimes."}
{"id": "2512.16309", "categories": ["quant-ph", "cs.DS"], "pdf": "https://arxiv.org/pdf/2512.16309", "abs": "https://arxiv.org/abs/2512.16309", "authors": ["Aleksandros Sobczyk", "Anastasios Zouzias"], "title": "Prefix Sums via Kronecker Products", "comment": null, "summary": "In this work, we revisit prefix sums through the lens of linear algebra. We describe an identity that decomposes triangular all-ones matrices as a sum of two Kronecker products, and apply it to design recursive prefix sum algorithms and circuits. Notably, the proposed family of circuits is the first one that achieves the following three properties simultaneously: (i) zero-deficiency, (ii) constant fan-out per-level, and (iii) depth that is asymptotically strictly smaller than $2\\log(n)$ for input length n. As an application, we show how to use these circuits to design quantum adders with $1.893\\log(n) + O(1)$ Toffoli depth, $O(n)$ Toffoli gates, and $O(n)$ additional qubits, improving the Toffoli depth and/or Toffoli size of existing constructions."}
{"id": "2512.16368", "categories": ["quant-ph", "physics.atom-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.16368", "abs": "https://arxiv.org/abs/2512.16368", "authors": ["Hans Dang", "Sebastian Luff", "Martin Fischer", "Markus Sondermann", "Gerd Leuchs"], "title": "Feedback Cooling and Thermometry of a Single Trapped Ion Using a Knife Edge", "comment": null, "summary": "We report on the first feedback cooling of a single trapped ion below the Doppler limit of $\\hbarΓ/2 k_\\mathrm{B}$. The motion of a single ion is monitored in real-time and cooled up to 9-times below the Doppler cooling temperature by applying electronic feedback. Real-time motion detection is implemented by imaging the fluorescence photons emitted by the ion onto a knife edge and detecting the transmitted light, a method used so far to cool trapped nanoparticles. The intensity modulation of the fluorescence resulting from the ion motion is used to generate and apply the feedback signal and also to determine the ion temperature. The method benefits from a high rate of detected scattered photons, which can be a challenge, and which we address by using a parabolic mirror for collecting the fluorescence."}
{"id": "2512.16385", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.16385", "abs": "https://arxiv.org/abs/2512.16385", "authors": ["Xiao-Wen Shang", "Jian-Peng Dou", "Feng Lu", "Sen Lin", "Hao Tang", "Xian-Min Jin"], "title": "Instantaneous velocity during quantum tunnelling", "comment": "9 pages, 5 figures", "summary": "Quantum tunnelling, a hallmark phenomenon of quantum mechanics, allows particles to pass through the classically forbidden region. It underpins fundamental processes ranging from nuclear fusion and photosynthesis to the operation of superconducting qubits. Yet the underlying dynamics of particle motion during tunnelling remain subtle and are still the subject of active debate. Here, by analyzing the temporal evolution of the tunnelling process, we show that the particle velocity inside the barrier continuously relaxes from a large initial value toward a smaller one, and may even approach zero in the evanescent regime. Meanwhile, the probability density within the barrier gradually builds up before reaching its stationary profile, in contrast to existing inherently. In addition, starting from the steady-state equations, we derive an explicit relation between the particle velocity and the barrier width, and show that the velocity in evanescent states approaches zero when the barrier is sufficiently wide. These findings resolve the apparent paradox of a vanishing steady-state velocity coexisting with a finite particle density. We point out that defining an effective speed from the probability density, rather than from the probability current, can lead to spuriously nonzero \"stationary speed,\" as appears to be the case in Ref. [Nature 643, 67 (2025)]. Our work establishes a clear dynamical picture for the formation of tunnelling flow and provides a theoretical foundation for testing time-resolved tunnelling phenomena."}
{"id": "2512.16400", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16400", "abs": "https://arxiv.org/abs/2512.16400", "authors": ["Rei Sato"], "title": "Coined Quantum Walks on Complex Networks for Quantum Computers", "comment": "6 figures, 11 pages", "summary": "We propose a quantum circuit design for implementing coined quantum walks on complex networks. In complex networks, the coin and shift operators depend on the varying degrees of the nodes, which makes circuit construction more challenging than for regular graphs. To address this issue, we use a dual-register encoding. This approach enables a simplified shift operator and reduces the resource overhead compared to previous methods. We implement the circuit using Qmod, a high-level quantum programming language, and evaluated the performance through numerical simulations on Erdős-Rényi, Watts-Strogatz, and Barabási-Albert models. The results show that the circuit depth scales as approximately $N^{1.9}$ regardless of the network topology. Furthermore, we execute the proposed circuits on the ibm\\_torino superconducting quantum processor for Watts-Strogatz models with $N=4$ and $N=8$. The experiments show that hardware-aware optimization slightly improved the $L_1$ distance for the larger graph, whereas connectivity constraints imposed overhead for the smaller one. These results indicate that while current NISQ devices are limited to small-scale validations, the polynomial scaling of our framework makes it suitable for larger-scale implementations in the early fault-tolerant quantum computing era."}
{"id": "2512.16435", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16435", "abs": "https://arxiv.org/abs/2512.16435", "authors": ["Mahmood Hasani", "Hadis Salasi", "Negar Ashari Astani"], "title": "Quantum-Inspired Ising Machines for Quantum Chemistry Calculations", "comment": "31 pages, 5 figures, 3 tables", "summary": "Four decades after Richard Feynman's famous remark, we have reached a stage at which nature can be simulated quantum mechanically. Quantum simulation is among the most promising applications of quantum computing. However, like many quantum algorithms, it is severely constrained by noise in near-term hardware. Quantum-inspired algorithms provide an attractive alternative by avoiding the need for error-prone quantum devices. In this study, we demonstrate that the coherent Ising machine and simulated bifurcation algorithms can accurately reproduce the electronic energy profiles of H_2 and H_2O, capturing their essential energetic features. Notably, we obtain computational times of 1.2 s and 2.4 s for the H_2 and H_2O profiles, respectively, representing a substantial speed-up compared to gate-based quantum computing approaches, which typically require at least 6 s to compute a single molecular geometry with comparable accuracy. These results highlight the potential of quantum-inspired approaches for scaling to larger molecular systems and for future applications in chemistry and materials science."}
{"id": "2512.16495", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.16495", "abs": "https://arxiv.org/abs/2512.16495", "authors": ["Denis Kopylov", "Manfred Hammer"], "title": "Classical and quantum electromagnetic momentum in anisotropic optical waveguides", "comment": null, "summary": "The guided modes supported by dielectric channel waveguides act as individual carriers of momentum. We show this by proving that the modes satisfy an orthogonality condition which relates to the momentum of the optical electromagnetic field, with a link to the more familiar power (energy) orthogonality. This result forms the basis for a rigorous, self-consistent procedure for the quantization of broadband guided electromagnetic fields in the typical channels used in integrated photonic circuits. Our work removes the existing theoretical gap between the classical solution of the Maxwell equations for guided fields and the intuitive understanding of photons in waveguides. The presented approach is valid for straight, lossless, and potentially anisotropic, dielectric waveguides of general shape, in the linear regime, and including material dispersion. Examples for the hybrid modes of a thin film lithium niobate strip waveguide are briefly discussed."}
{"id": "2512.16520", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.16520", "abs": "https://arxiv.org/abs/2512.16520", "authors": ["Felix Kloiber-Tollinger", "Lukas M. Sieberer"], "title": "Replica Keldysh field theory of quantum-jump processes: General formalism and application to imbalanced and inefficient fermion counting", "comment": "32 pages, 5 figures", "summary": "Measurement-induced phase transitions have largely been explored for projective or continuous measurements of Hermitian observables, assuming perfect detection without information loss. Yet such transitions also arise in more general settings, including quantum-jump processes with non-Hermitian jump operators, and under inefficient detection. A theoretical framework for treating these broader scenarios has been missing. Here we develop a comprehensive replica Keldysh field theory for general quantum-jump processes in both bosonic and fermionic systems. Our formalism provides a unified description of pure-state quantum trajectories under efficient detection and mixed-state dynamics emerging from inefficient monitoring, with deterministic Lindbladian evolution appearing as a limiting case. It thus establishes a direct connection between phase transitions in nonequilibrium steady states of driven open quantum matter and in measurement-induced dynamics. As an application, we study imbalanced and inefficient fermion counting in a one-dimensional lattice system: monitored gain and loss of fermions occurring at different rates, with a fraction of gain and loss jumps undetected. For imbalanced but efficient counting, we recover the qualitative picture of the balanced case: entanglement obeys an area law for any nonzero jump rate, with an extended quantum-critical regime emerging between two parametrically separated length scales. Inefficient detection introduces a finite correlation length beyond which entanglement, as quantified by the fermionic logarithmic negativity, obeys an area law, while the subsystem entropy shows volume-law scaling. Numerical simulations support our analytical findings. Our results offer a general and versatile theoretical foundation for studying measurement-induced phenomena across a wide class of monitored and open quantum systems."}
{"id": "2512.16569", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16569", "abs": "https://arxiv.org/abs/2512.16569", "authors": ["Ryan Benazzouk", "Maen Salman", "Trond Saue"], "title": "Wichmann-Kroll vacuum polarization density in a finite Gaussian basis set", "comment": "20 pages, 16 figures", "summary": "This work further develops the calculation of QED effects in a finite Gaussian basis. We focus on the non-linear $α(Zα)^{n\\ge 3}$ contribution to the vacuum polarization density, computing the energy shift of 1s$_{1/2}$ states of hydrogen-like ions. Our goal is to improve the numerical computations to achieve a precision comparable to that of Green's function methods reported in the literature. To do so, an analytic expression for the linear contribution to the vacuum polarization density is derived using Riesz projectors. Alternative formulations of the vacuum polarization density and their relation is discussed. The convergence of the finite Gaussian basis scheme is investigated, and the numerical difficulties that arise are characterized. In particular, an error analysis is performed to assess the method's robustness to numerical noise. We then report a strategy for computing the energy shift with sufficient precision to enable a sensible extrapolation of the partial-wave expansion. A key feature of the procedure is the use of even-tempered basis sets, allowing for an extrapolation towards the complete basis set limit."}
{"id": "2512.16580", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16580", "abs": "https://arxiv.org/abs/2512.16580", "authors": ["Weixiang Ye"], "title": "The measured speed in the evanescent regime reflects the spatial decay of the wavefunction, not particle motion", "comment": null, "summary": "The recent paper by Sharoglazova et al. reports an energy-dependent parameter $ν$ extracted from the spatial distribution of photons in a coupled-waveguide experiment. The authors interpret $ν$ as the speed of quantum particles, even in the classically forbidden regime, and claim that its finite value contradicts the Bohmian mechanics prediction of zero particle velocity. This challenge arises from a fundamental misunderstanding of the operational meaning of v within the Bohmian ontological framework. We demonstrate that v quantifies the spatial gradient of the wavefunctions amplitude, a geometric property of the guiding field, not the kinematical velocity of point-like particles. The experiment therefore does not challenge but rather illustrates the clean ontological separation between the wave and particle aspects inherent to Bohmian mechanics."}
{"id": "2512.16582", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16582", "abs": "https://arxiv.org/abs/2512.16582", "authors": ["Lintao Xiao", "Bo Zhang", "Yu Zeng", "Xiaoxuan Pan", "Jia-Qi Wang", "Ziyue Hua", "Hongwei Huang", "Yifang Xu", "Guangming Xue", "Haifeng Yu", "Xin-Biao Xu", "Weiting Wang", "Chang-Ling Zou", "Luyan Sun"], "title": "Giant-atom quantum acoustodynamics in hybrid superconducting-phononic integrated circuits", "comment": "7 pages, 4 figures", "summary": "We demonstrate a giant atom by coupling a superconducting transmon qubit to a lithium niobate phononic waveguide at two points separated by about 600 acoustic wavelengths, with a propagation delay of 125 ns. The giant atom yields non-Markovian relaxation dynamics characterized by phonon backflow and a frequency-dependent effective decay rate varying four-fold over merely 4 MHz, corresponding to a Purcell factor exceeding 40. Exploiting this frequency-dependent dissipation, we prepare quantum superposition states with high purity. Our results establish phononic integrated circuits as a versatile platform for giant-atom physics, providing highly tunable quantum devices for advanced quantum information processing."}
{"id": "2512.16617", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16617", "abs": "https://arxiv.org/abs/2512.16617", "authors": ["Timon L. Baltisberger", "Francesco Salusti", "Mark R. Hogg", "Malwina A. Marczak", "Nils Heinisch", "Sascha R. Valentin", "Stefan Schumacher", "Arne Ludwig", "Klaus D. Jöns", "Richard J. Warburton"], "title": "Indistinguishable photons from a two-photon cascade", "comment": "10 pages, 4 figures in main paper, 5 figures in supplementary information", "summary": "Decay of a four-level diamond scheme via a cascade is a potential source of entangled photon pairs. A solid-state implementation is the biexciton cascade in a semiconductor quantum dot. While high entanglement fidelities have been demonstrated, the two photons, XX and X, are temporally correlated, typically resulting in poor photon coherence. Here, we demonstrate a high two-photon interference visibility (a measure of the photon coherence) for both XX (V=94$\\pm$2%) and X (V=82$\\pm$6%) photons. This is achieved by Purcell-enhancing the biexciton transition in a low-noise device. We find that the photon coherence follows the well-known quantum optics result upon tuning the XX:X lifetime ratio over two orders of magnitude."}
{"id": "2512.16641", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16641", "abs": "https://arxiv.org/abs/2512.16641", "authors": ["Katrin Bolsmann", "Thiago L. M. Guedes", "Weibin Li", "Joseph W. P. Wilkinson", "Igor Lesanovsky", "Markus Müller"], "title": "Fast Native Three-Qubit Gates and Fault-Tolerant Quantum Error Correction with Trapped Rydberg Ions", "comment": "9 pages, 4 figures", "summary": "Trapped ions as one of the most promising quantum-information-processing platforms, yet conventional entangling gates mediated by collective motion remain slow and difficult to scale. Exciting trapped ions to high-lying electronic Rydberg states provides a promising route to overcome these limitations by enabling strong, long-range dipole-dipole interactions that support much faster multi-qubit operations. Here, we introduce the first scheme for implementing a native controlled-controlled-Z gate with microwave-dressed Rydberg ions by optimizing a single-pulse protocol that accounts for the finite Rydberg-state lifetime. The resulting gate outperforms standard decompositions into one- and two-qubit gates by achieving fidelities above 97% under realistic conditions, with execution times of about 2 microseconds at cryogenic temperatures. To explore the potential of trapped Rydberg ions for fault-tolerant quantum error correction, and to illustrate the utility of three-qubit Rydberg-ion gates in this context, we develop and analyze a proposal for fault-tolerant, measurement-free quantum error correction using the nine-qubit Bacon-Shor code. Our simulations confirm that quantum error correction can be performed in a fully fault-tolerant manner on a linear Rydberg-ion chain despite its limited qubit connectivity. These results establish native multiqubit Rydberg-ion gates as a valuable resource for fast, high-fidelity quantum computing and highlight their potential for fault-tolerant quantum error correction."}
{"id": "2512.16654", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16654", "abs": "https://arxiv.org/abs/2512.16654", "authors": ["Wanbing Zhao", "H. W. Shawn Liew", "Wen Wei Ho", "Chunxiao Liu", "Vir B. Bulchandani"], "title": "Scalable tests of quantum contextuality from stabilizer-testing nonlocal games", "comment": "27+4 pages, 4 figures", "summary": "Soon after the dawn of quantum error correction, DiVincenzo and Peres observed that stabilizer codewords could give rise to simple proofs of quantumness via contextuality. This discovery can be recast in the language of nonlocal games: every $n$-qubit stabilizer state defines a specific \"stabilizer-testing\" $n$-player nonlocal game, which quantum players can win with probability one. If quantum players can moreover outperform all possible classical players, then the state is contextual. However, the classical values of stabilizer-testing games are largely unknown for scalable examples beyond the $n$-qubit GHZ state. We introduce several new methods for upper-bounding the classical values of these games. We first prove a general coding-theory bound for all stabilizer-testing games: if the classical value $p_{\\mathrm{cl}}^* < 1$, then $p_{\\mathrm{cl}}^* \\leq 7/8$, i.e., there is no classical strategy that can perform as well as the optimal quantum strategy even in an asymptotic sense. We then show how to tighten this bound for the most common scalable examples, namely GHZ, toric-code and cyclic cluster states. In particular, we establish an asymptotically tight upper bound for cyclic cluster states using transfer-matrix methods. This leads to the striking conclusion that measuring an exponentially small fidelity to the cyclic cluster state will suffice to witness its contextuality."}
{"id": "2512.16657", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.16657", "abs": "https://arxiv.org/abs/2512.16657", "authors": ["J. R. Silva", "C. Antunis B. S. Santos"], "title": "Shaping Dynamics Through Memory: A Study of Reservoir Profiles in Open Quantum Systems", "comment": null, "summary": "In this work, we investigate how different reservoir memory profiles influence the dynamical evolution of a single waveguide coupled to an external environment. We compare three representative memory kernels: Lorentzian, Gaussian and Uniform, highlighting their distinct spatial correlations and their impact on system behavior. We compute the transmission amplitude, transparency properties, as well as long-time behavior of the system under each memory model. To quantify deviations from Markovian dynamics, we employ a non-Markovianity measure based on information backflow, allowing a direct comparison between the structured reservoirs and the Markovian limit. Our results reveal clear signatures of memoryless-induced modifications in the transmission spectrum and demonstrate how specific reservoir profiles enhance or suppress non-Markovian effects."}
{"id": "2512.16673", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16673", "abs": "https://arxiv.org/abs/2512.16673", "authors": ["Ritu Nehra", "Poetri Sonya Tarabunga", "Martina Frau", "Mario Collura", "Emanuele Tirrito", "Marcello Dalmonte"], "title": "Topological magic response in quantum spin chains", "comment": "19 pages, 12 figures", "summary": "Topological matter provides natural platforms for robust, non-local information storage, central to quantum error correction. Yet, while the relation between entanglement and topology is well established, little is known about the role of nonstabilizerness (or magic), a pivotal concept in fault-tolerant quantum computation, in topological phases. We introduce the concept of topological magic response, the ability of a state to spread over stabilizer space when perturbed by finite-depth non-Clifford circuits. Unlike a topological invariant or order parameter, this response function probes how a phase reacts to non-Clifford perturbations, revealing the presence of non-local quantum correlations. In Ising-type spin chains, we show that symmetry-broken and paramagnetic phases lack such a response, whereas symmetry-protected topological (SPT) phases always display it. To capture this, we utilize a combination of stabilizer Rényi entropies that, in analogy with topological entanglement entropy, isolates non-locally stored information. Using exact analytic computations and matrix product states simulations based on an algorithmic technique we introduce, we show that SPT phases doped with $T$ gates support robust topological magic response, while trivial phases remain featureless."}
{"id": "2512.16674", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16674", "abs": "https://arxiv.org/abs/2512.16674", "authors": ["Saverio Monaco", "Jamal Slim", "Florian Rehm", "Dirk Krücker", "Kerstin Borras"], "title": "Symbolic Pauli Propagation for Gradient-Enabled Pre-Training of Quantum Circuits", "comment": null, "summary": "Quantum Machine Learning models typically require expensive on-chip training procedures and often lack efficient gradient estimation methods. By employing Pauli propagation, it is possible to derive a symbolic representation of observables as analytic functions of a circuit's parameters. Although the number of terms in such functional representations grows rapidly with circuit depth, suitable choices of ansatz and controlled truncations on Pauli weights and frequency components yield accurate yet tractable estimators of the target observables. With the right ansatz design, this approach can be extended to system sizes beyond the reach of classical simulation, enabling scalable training for larger quantum systems. This also enables a form of classical pre-training through gradient-based optimization prior to deployment on quantum hardware. The proposed approach is demonstrated on the Variational Quantum Eigensolver for obtaining the ground state of a spin model, showing that accurate results can be achieved with a scalable and computationally efficient procedure."}
{"id": "2512.16682", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16682", "abs": "https://arxiv.org/abs/2512.16682", "authors": ["Nick von Selzam", "Florian Marquardt"], "title": "On the Dynamics of Local Hidden-Variable Models", "comment": "11+4 pages, 4 figures, comments welcome", "summary": "Bell nonlocality is an intriguing property of quantum mechanics with far reaching consequences for information processing, philosophy and our fundamental understanding of nature. However, nonlocality is a statement about static correlations only. It does not take into account dynamics, i.e. time evolution of those correlations. Consider a dynamic situation where the correlations remain local for all times. Then at each moment in time there exists a local hidden-variable (LHV) model reproducing the momentary correlations. Can the time evolution of the correlations then be captured by evolving the hidden variables? In this light, we define dynamical LHV models and motivate and discuss potential additional physical and mathematical assumptions. Based on a simple counter example we conjecture that such LHV dynamics does not always exist. This is further substantiated by a rigorous no-go theorem. Our results suggest a new type of nonlocality that can be deduced from the observed time evolution of measurement statistics and which generically occurs in interacting quantum systems."}
{"id": "2512.16695", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.16695", "abs": "https://arxiv.org/abs/2512.16695", "authors": ["Andrey M. Pupasov-Maksimov", "Marcelo Silva Oliveira"], "title": "Propagators of singular anharmonic oscillators with quasi-equidistant spectra", "comment": "20 pages, 5 figures", "summary": "Darboux transformations of the singular harmonic oscillator are considered. Analytical expressions for the propagators are obtained, using the image method applied to formal singular propagators. Two-well and three-well families of potentials and the corresponding propagators are presented. Axially symmetric magnetic field configurations corresponding to these potentials have been identified."}
{"id": "2512.16752", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16752", "abs": "https://arxiv.org/abs/2512.16752", "authors": ["Hana KimLee", "Leonardo Bacciottini", "Abhishek Bhatt", "Andrew Kille", "Stefan Krastanov"], "title": "QuantumSavory: Write Symbolically, Run on Any Backend -- A Unified Simulation Toolkit for Quantum Computing and Networking", "comment": "QuantumSavory Repository at: https://github.com/QuantumSavory/QuantumSavory.jl 17 pages, 9 figures", "summary": "Progress in quantum computing and networking depends on codesign across abstraction layers: device-level noise and heterogeneous hardware, algorithmic structure, and distributed classical control. We present QuantumSavory, an open-source toolkit built to make such end-to-end studies practical by cleanly separating a symbolic computer-algebra frontend from interchangeable numerical simulation backends. States, operations, measurements, and protocol logic are expressed in a backend-agnostic symbolic language; the same model can be executed across multiple backends (e.g., stabilizer, wavefunction, phase-space), enabling rapid exploration of accuracy-performance tradeoffs without rewriting the model. Furthermore, new custom backends can be added via a small, well-defined interface that immediately reuses existing models and protocols.\n  QuantumSavory also addresses the classical-quantum interaction inherent to LOCC protocols via discrete-event execution and a tag/query system for coordination. Tags attach structured classical metadata to quantum registers and message buffers, and queries retrieve, filter, or wait on matching metadata by wildcards or arbitrary predicates. This yields a data-driven control plane where protocol components coordinate by publishing and consuming semantic facts (e.g., resource availability, pairing relationships, protocol outcomes) rather than by maintaining rigid object graphs or bespoke message plumbing, improving composability and reuse as models grow. Our toolkit is also not limited to qubits and Bell pairs; rather, any networking dynamics of any quantum system under any type of multipartite entanglement can be tackled. Lastly, QuantumSavory ships reusable libraries of standard states, circuits, and protocol building blocks with consistent interfaces, enabling full-stack examples to be assembled, modified, and compared with minimal glue code."}
{"id": "2512.16775", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.16775", "abs": "https://arxiv.org/abs/2512.16775", "authors": ["Nicolás Medina Sánchez", "Borivoje Dakić"], "title": "Reconstruction of Quantum Fields", "comment": "16 pages", "summary": "One of the traditional ways of introducing bosons and fermions is through creation and annihilation algebras. Historically, these have been associated with emission and absorption processes at the quantum level and are characteristic of the language of second quantization. In this work, we formulate the transition from first to second quantization by taking quotients of the state spaces of distinguishable particles, so that the resulting equivalence classes identify states that contain no information capable of distinguishing between particles, thereby generalising the usual symmetrisation procedure. Assuming that the resulting indistinguishable-particle space (i) admits an ordered basis compatible with how an observer may label the accessible modes, (ii) is invariant under unitary transformations of those modes, and (iii) supports particle counting as a mode-wise local operation, we derive a new class of creation-annihilation algebras. These algebras reproduce the partition functions of transtatistics-maximal generalisations of bosons and fermions consistent with these operational principles."}
{"id": "2512.16777", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16777", "abs": "https://arxiv.org/abs/2512.16777", "authors": ["Zhenhuan Liu", "Tobias Haug", "Qi Ye", "Zi-Wen Liu", "Ingo Roth"], "title": "A magic criterion (almost) as nice as PPT, with applications in distillation and detection", "comment": "13 pages, 2 figures", "summary": "We introduce a mixed-state magic criterion, the Triangle Criterion, which plays a role for magic analogous to the Positive Partial Transposition (PPT) criterion for entanglement: it combines strong detection capability, a clear geometric interpretation, and an operational link to magic distillation. Using this criterion, we uncover several new features of multi-qubit magic distillation and detection. We prove that genuinely multi-qubit magic distillation protocols are strictly more powerful than all single-qubit schemes by showing that the Triangle Criterion is not stable under tensor products, in sharp contrast to the PPT criterion. Moreover, we show that, with overwhelming probability, multi-qubit magic states with relatively low rank cannot be distilled by any single-qubit distillation protocol. We derive an upper bound on the minimal purity of magic states, which is conjectured to be tight with both numerical and constructive evidences. Using this minimal-purity result, we predict the existence of unfaithful magic states, namely states that cannot be detected by any fidelity-based magic witness, and reveal fundamental limitations of mixed-state magic detection in any single-copy scheme."}
{"id": "2512.16778", "categories": ["quant-ph", "cs.CR", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16778", "abs": "https://arxiv.org/abs/2512.16778", "authors": ["Theshani Nuradha", "Ian George", "Christoph Hirche"], "title": "Non-Linear Strong Data-Processing for Quantum Hockey-Stick Divergences", "comment": null, "summary": "Data-processing is a desired property of classical and quantum divergences and information measures. In information theory, the contraction coefficient measures how much the distinguishability of quantum states decreases when they are transmitted through a quantum channel, establishing linear strong data-processing inequalities (SDPI). However, these linear SDPI are not always tight and can be improved in most of the cases. In this work, we establish non-linear SDPI for quantum hockey-stick divergence for noisy channels that satisfy a certain noise criterion. We also note that our results improve upon existing linear SDPI for quantum hockey-stick divergences and also non-linear SDPI for classical hockey-stick divergence. We define $F_γ$ curves generalizing Dobrushin curves for the quantum setting while characterizing SDPI for the sequential composition of heterogeneous channels. In addition, we derive reverse-Pinsker type inequalities for $f$-divergences with additional constraints on hockey-stick divergences. We show that these non-linear SDPI can establish tighter finite mixing times that cannot be achieved through linear SDPI. Furthermore, we find applications of these in establishing stronger privacy guarantees for the composition of sequential private quantum channels when privacy is quantified by quantum local differential privacy."}
{"id": "2512.16823", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.16823", "abs": "https://arxiv.org/abs/2512.16823", "authors": ["Mike Shubrook", "Moritz Cygorek", "Erik Gauger", "Jake Iles-Smith", "Ahsan Nazir"], "title": "Numerically exact open quantum system work statistics with process tensors", "comment": "10 pages, 5 figures, comments welcome", "summary": "Accurately quantifying the thermodynamic work costs of quantum operations is essential for the continued development and optimisation of emerging quantum technologies. This present a significant challenge in regimes of rapid control within complex, non-equilibrium environments - conditions under which many contemporary quantum devices operate and conventional approximations break down. Here, we introduce a process tensor framework that enables the computation of the full numerically exact quantum work statistics of driven open quantum systems. We demonstrate the utility of our approach by applying it to a Landauer erasure protocol operating beyond the weak-coupling, Markovian, and slow-driving limits. The resulting work probability distributions reveal distinct quantum signatures that are missed by low-order moments yet significantly impact the erasure fidelity of the protocol. Our framework delivers non-perturbative accuracy and detail in characterising energy-exchange fluctuations in driven open quantum systems, establishing a powerful and versatile tool for exploring thermodynamics and control in the operating regimes of both near-term and future quantum devices."}
{"id": "2512.16859", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16859", "abs": "https://arxiv.org/abs/2512.16859", "authors": ["Han-Ze Li", "Yi-Rui Zhang", "Yu-Jun Zhao", "Xuyang Huang", "Jian-Xin Zhong"], "title": "Nonstabilizerness in Stark many-body localization", "comment": null, "summary": "Quantum many-body disorder-free localization can suppress transport while still allowing the buildup of computationally costly non-Clifford resources. In a transverse-field Ising chain realizing disorder-free Stark many-body localization, we show that the stabilizer Rényi entropy remains nonzero and grows slowly to a finite plateau deep in the strong Stark-field regime, with strong initial-state selectivity. As the Stark field strength increases, long-time magic and entanglement consistently signal a crossover from ergodic to constrained localized dynamics. These results establish nonstabilizerness (``magic'') as a practical complexity probe for disorder-free ergodicity breaking and constrained localization, with direct relevance to benchmarking and designing near-term quantum simulators, and fill a gap in the understanding of nonstabilizerness in disorder-free many-body localization."}
{"id": "2512.16878", "categories": ["quant-ph", "cond-mat.other", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.16878", "abs": "https://arxiv.org/abs/2512.16878", "authors": ["Francesco Anna Mele", "Filippo Girardi", "Senrui Chen", "Marco Fanizza", "Ludovico Lami"], "title": "Random purification channel for passive Gaussian bosons", "comment": "13 pages. See independent work [arXiv:2512.15690] by Walter and Witteveen", "summary": "The random purification channel, which, given $n$ copies of an unknown mixed state $ρ$, prepares $n$ copies of an associated random purification, has proved to be an extremely valuable tool in quantum information theory. In this work, we construct a Gaussian version of this channel that, given $n$ copies of a bosonic passive Gaussian state, prepares $n$ copies of one of its randomly chosen Gaussian purifications. The construction has the additional advantage that each purification has a mean photon number which is exactly twice that of the initial state. Our construction relies on the characterisation of the commutant of passive Gaussian unitaries via the representation theory of dual reductive pairs of unitary groups."}
{"id": "2512.16879", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16879", "abs": "https://arxiv.org/abs/2512.16879", "authors": ["Arnab Adhikary", "S. E. Skelton", "Alberto Nocera", "Mona Berciu"], "title": "Advantage of Warm Starts for Electron-Phonon Systems on Quantum Computers", "comment": "16 pages, 11 figures", "summary": "Simulating electron-phonon interactions on quantum computers remains challenging, with most algorithmic effort focused on Hamiltonian simulation and circuit optimization. In this work, we study the single-electron Holstein model and propose an initial-state ansatz that substantially enhances ground state overlap in the strong coupling regime, thereby reducing the number of iterations required in standard quantum phase estimation. We further show that this ansatz can be implemented efficiently and yields an exponential reduction in overall circuit costs relative to conventional initial guesses. Our results highlight the practical value of incorporating physical intuition into initial state preparation for electron-phonon coupled systems."}
{"id": "2512.16886", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.16886", "abs": "https://arxiv.org/abs/2512.16886", "authors": ["Oliver Hart", "David T. Stephen", "Evan Wickenden", "Rahul Nandkishore"], "title": "Many-body contextuality and self-testing quantum matter via nonlocal games", "comment": "21 pages, 6 figures", "summary": "Contextuality is arguably the fundamental property that makes quantum mechanics different from classical physics. It is responsible for quantum computational speedups in both magic-state-injection-based and measurement-based models of computation, and can be directly probed in a many-body setting by multiplayer nonlocal quantum games. Here, we discuss a family of games that can be won with certainty when performing single-site Pauli measurements on a state that is a codeword of a Calderbank-Shor-Steane (CSS) error-correcting quantum code. We show that these games require deterministic computation of a code-dependent Boolean function, and that the classical probability of success is upper bounded by a generalized notion of nonlinearity/nonquadraticity. This success probability quantifies the state's contextuality, and is computed via the function's (generalized) Walsh-Hadamard spectrum. To calculate this, we introduce an efficient, many-body-physics-inspired method that involves identifying the symmetries of an auxiliary hypergraph state. We compute the classical probability of success for several paradigmatic CSS codes and relate it to both classical statistical mechanics models and to strange correlators of symmetry-protected topological states. We also consider CSS submeasurement games, which can only be won with certainty by sharing the appropriate codeword up to local isometries. These games therefore enable self-testing, which we illustrate explicitly for the 2D toric code. We also discuss how submeasurement games enable an extensive notion of contextuality in many-body states."}
{"id": "2512.15868", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.15868", "abs": "https://arxiv.org/abs/2512.15868", "authors": ["Campbell McLauchlan", "Vedant Motamarri", "Benjamin Béri"], "title": "Classifying one-dimensional Floquet phases through two-dimensional topological order", "comment": "32 pages, 5 figures", "summary": "Floquet systems display rich phenomena, such as time crystals, with many-body localisation (MBL) protecting the phases from heating. While several types of Floquet phases have been classified, a unified picture of Floquet MBL is still emerging. Static phases have been fruitfully studied via \"symmetry topological field theory\" (SymTFT), wherein the universal features of $G$-symmetric systems are elucidated by placing them on the boundary of a topological order of one dimension higher. In this work, we provide a SymTFT approach to classifying $G$-symmetric Floquet MBL phases in 1D, for $G$ a finite Abelian group with on-site unitary action. In the SymTFT, these 1D systems correspond to the boundaries of the quantum double associated to $G$, and the classification naturally arises from considering the Lagrangian subgroups and boundary excitations of the quantum double. The classification covers all known Floquet phases while uncovering others previously unexplored, along with bulk features of phases thought to have only boundary signatures. We refer to the latter phases as \"dual\" time crystals. For static phases, we show how anyons of the quantum double and (string) order parameters provide a natural and simple interpretation of known classification schemes. By extending our framework to the boundaries of twisted quantum doubles, we uncover a new time-crystalline phase with non-onsite symmetry, which cannot be obtained through local, symmetric Hamiltonian drives. We numerically demonstrate evidence for the absolute stability of this phase, and observe that for open boundary conditions it has greater stability to symmetric perturbations. We finally discuss perspectives on using programmable quantum devices to realise and probe the phases we discuss. Our results show that SymTFT provides a powerful approach to unifying phases and features of Floquet systems."}
{"id": "2512.16539", "categories": ["math.NA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16539", "abs": "https://arxiv.org/abs/2512.16539", "authors": ["Hengzhun Chen", "Yingzhou Li", "Bichen Lu", "Jianfeng Lu"], "title": "Landscape Analysis of Excited States Calculation over Quantum Computers", "comment": null, "summary": "The variational quantum eigensolver (VQE) is one of the most promising algorithms for low-lying eigenstates calculation on Noisy Intermediate-Scale Quantum (NISQ) computers. Specifically, VQE has achieved great success for ground state calculations of a Hamiltonian. However, excited state calculations arising in quantum chemistry and condensed matter often requires solving more challenging problems than the ground state as these states are generally further away from a mean-field description, and involve less straightforward optimization to avoid the variational collapse to the ground state. Maintaining orthogonality between low-lying eigenstates is a key algorithmic hurdle. In this work, we analyze three VQE models that embed orthogonality constraints through specially designed cost functions, avoiding the need for external enforcement of orthogonality between states. Notably, these formulations possess the desirable property that any local minimum is also a global minimum, helping address optimization difficulties. We conduct rigorous landscape analyses of the models' stationary points and local minimizers, theoretically guaranteeing their favorable properties and providing analytical tools applicable to broader VQE methods. A comprehensive comparison between the three models is also provided, considering their quantum resource requirements and classical optimization complexity."}
{"id": "2512.16836", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.16836", "abs": "https://arxiv.org/abs/2512.16836", "authors": ["Debarghya Chakraborty", "Dario Rosa"], "title": "Revival Dynamics from Equilibrium States: Scars from Chords in SYK", "comment": "33 pages, 8 figures", "summary": "We develop a novel framework to build quantum many-body scar states in bipartite systems characterized by perfect correlation between the Hamiltonians governing the two sides. By means of a Krylov construction, we build an interaction term which supports a tower of equally-spaced energy eigenstates. This gives rise to finite-time revivals whenever the system is initialized in a purification of a generic equilibrium state. The dynamics is universally characterized, and is largely independent of the specific details of the Hamiltonians defining the individual partitions. By considering the two-sided chord states of the double-scaled SYK model, we find an approximate realization of this framework. We analytically study the revival dynamics, finding rigid motion for wavepackets localized on the spectrum of a single SYK copy. These findings are tested numerically for systems of finite size, showing excellent agreement with the analytical predictions."}
