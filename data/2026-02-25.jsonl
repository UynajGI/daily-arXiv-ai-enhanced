{"id": "2602.20359", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.20359", "abs": "https://arxiv.org/abs/2602.20359", "authors": ["Rayan Mazouz", "Frederik Baymler Mathiesen", "Luca Laurenti", "Morteza Lahijanian"], "title": "StochasticBarrier.jl: A Toolbox for Stochastic Barrier Function Synthesis", "comment": null, "summary": "We present StochasticBarrier.jl, an open-source Julia-based toolbox for generating Stochastic Barrier Functions (SBFs) for safety verification of discrete-time stochastic systems with additive Gaussian noise. StochasticBarrier.jl certifies linear, polynomial, and piecewise affine (PWA) systems. The latter enables verification for a wide range of system dynamics, including general nonlinear types. The toolbox implements a Sum-of-Squares (SOS) optimization approach, as well as methods based on piecewise constant (PWC) functions. For SOS-based SBFs, StochasticBarrier.jl leverages semi-definite programming solvers, while for PWC SBFs, it offers three engines: two using linear programming (LP) and one based on gradient descent (GD). Benchmarking StochasticBarrier.jl against the state-of-the-art shows that the tool outperforms existing tools in computation time, safety probability bounds, and scalability across over 30 case studies. Compared to its closest competitor, StochasticBarrier.jl is up to four orders of magnitude faster, achieves significant safety probability improvements, and supports higher-dimensional systems."}
{"id": "2602.20453", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.20453", "abs": "https://arxiv.org/abs/2602.20453", "authors": ["Haizum Hanim Ab Halim", "Dalila Alias", "Akmal Zaini Arsad", "Lewis Tee Jen Looi", "Rosdiadee Nordin", "Denny Ng Kok Sum"], "title": "IoT-Driven Building Energy Management Systems (BEMS) for Net Zero Energy Buildings: Concept, Integration and Future Directions", "comment": null, "summary": "Construction and operating of buildings is one of the major contributors to global greenhouse emissions. With the inefficient usage of energy due to human behavior and manual operation, the energy consumption of buildings is further increased. These challenges highlight the need for improved Building Energy Management Systems (BEMS) integrated with Internet of Things (IoT) and data driven intelligence to enhance energy-efficiency in a building and contribute to Net-Zero Energy Buildings (NZEB) targets. This paper offers four keys contributions: i) a systematic review of IoT enabled BEMS including components, network architecture and functional capabilities, ii) an evaluation of real-world BEMS datasets to support Artificial Intelligence (AI) based predictive control, iii) an analysis of integration challenges related to interoperability, smart grids and net-zero energy strategies, and iv) a case study highlighting global best practices, performances outcomes, and lesson learned for scaling advanced BEMS solutions."}
{"id": "2602.20683", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.20683", "abs": "https://arxiv.org/abs/2602.20683", "authors": ["Mohamed Shamseldein"], "title": "Grid-Mind: An LLM-Orchestrated Multi-Fidelity Agent for Automated Connection Impact Assessment", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable tool-use capabilities, yet their application to power system operations remains largely unexplored. This paper presents Grid-Mind, a domain-specific LLM agent that interprets natural-language interconnection requests and autonomously orchestrates multi-fidelity power system simulations. The LLM-first architecture positions the language model as the central decision-making entity, employing an eleven-tool registry to execute Connection Impact Assessment (CIA) studies spanning steadystate power flow, N-1 contingency analysis, transient stability, and electromagnetic transient screening. A violation inspector grounds every decision in quantitative simulation outputs, while a three-layer anti-hallucination defence mitigates numerical fabrication risk through forced capacity-tool routing and post-response grounding validation. A prompt-level self-correction mechanism extracts distilled lessons from agent failures, yielding progressive accuracy improvements without model retraining. End-to-end evaluation on 50 IEEE 118-bus scenarios (DeepSeek-V3, 2026-02-23) achieved 84.0% tool-selection accuracy and 100% parsing accuracy. A separate 56-scenario self-correction suite passed 49 of 56 cases (87.5%) with a mean score of 89.3. These results establish a reproducible baseline for continued refinement while maintaining auditable, simulation-grounded decision support."}
{"id": "2602.20842", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.20842", "abs": "https://arxiv.org/abs/2602.20842", "authors": ["Marvin Dorn", "Julian Hoffmann", "André Weber", "Veit Hagenmeyer"], "title": "Fast-Response Balancing Capacity of Alkaline Electrolyzers", "comment": null, "summary": "The energy transition requires flexible technologies to maintain grid stability, and electrolyzers are playing an increasingly important role in meeting this need. While previous studies often question the dynamic capabilities of large-scale alkaline electrolyzer systems, we assess their potential to provide balancing services using real manufacturer data. Unlike common approaches, we propose the decoupling between the total electrolyzer power and a smaller fractions of power actually offered on balancing markets. Adapting an existing methodology, we analyze alkaline electrolyzer systems and extend the assessment to Germany and Europe. Our results show that large-scale electrolyzers are technically capable of delivering fast-response balancing services, with significantly lower dynamic requirements than previously assumed. The planned electrolyzers in Germany could cover the entire balancing capacity market, potentially saving around 13 % of their electricity costs, excluding energy balancing revenues. The decoupling also resolves part of the trade-off for electrolyzer manufacturers, enabling the design of less dynamic but more stable systems."}
{"id": "2602.20738", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.20738", "abs": "https://arxiv.org/abs/2602.20738", "authors": ["Karel L. K. De Witte", "Tom Braeckevelt", "Massimo Bocus", "Sander Vandenhaute", "Veronique Van Speybroeck"], "title": "A Novel NPT Thermodynamic Integration Scheme to Derive Rigorous Gibbs Free Energies for Crystalline Solids", "comment": null, "summary": "Thermodynamic Integration (TI) is the state-of-the-art computational technique for accurate Gibbs free energy predictions of solids. Conventional TI schemes start from an NVT harmonic reference and require three successive corrections to recover the Gibbs free energy of the real crystal in the NPT ensemble. However, the NVT-to-NPT correction neglects full cell flexibility. Here, we present a rigorous (and only) two-step TI scheme that operates entirely in the NPT ensemble, eliminating the need for the approximate NVT-to-NPT step. The key methodological advancement is the novel NPT reference that explicitly accounts for full cell fluctuations. The new approach is compared with the conventional one via two complementary case studies. For ice polymorphs, having simple cell-shape distributions, the new approach reproduces conventional TI results with excellent agreement. For CsPbI3, whose black phase exhibits complex cell-shape behavior, we demonstrate that our novel method provides more accurate Gibbs free energy differences than the conventional one. Moreover, the proposed framework maintains comparable computational cost while offering a simplified workflow. Overall, the new NPT TI scheme provides rigorous and direct Gibbs free energy calculations for solids."}
{"id": "2602.20489", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.20489", "abs": "https://arxiv.org/abs/2602.20489", "authors": ["Minseop Kim", "Jaeeun Kwon", "Hanbyeol Park", "Kikun Park", "Taekhyun Park", "Hyerim Bae"], "title": "Application of Large Language Models for Container Throughput Forecasting: Incorporating Contextual Information in Port Logistics", "comment": null, "summary": "Recent advancements in generative artificial intelligence (AI) have demonstrated its substantial potential in various fields. However, its application in port logistics remains underexplored. Ports are complex operational environments where diverse types of contextual information coexist, making them a promising domain for the implementation of generative AI and highlighting the urgency of related research. In this study, we applied a large language model (LLM)-a leading generative AI technique-to forecast container throughput, which is a critical challenge in port logistics. To this end, we adopted a state-of-the-art LLM approach and proposed a novel prompt structure designed to incorporate the contextual characteristics of port operations. Extensive experiments confirm the superiority of our method, showing that the proposed approach outperforms competitive benchmark models. Furthermore, additional experiments revealed that LLMs can effectively learn and utilize multiple layers of contextual information for inference in port logistics. Based on these findings, we explore the key constraints affecting LLM adoption in this domain and outline future research directions aimed at addressing them. Accordingly, we offer both technical and practical insights to support the effective deployment of generative AI in port logistics."}
{"id": "2602.20310", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.20310", "abs": "https://arxiv.org/abs/2602.20310", "authors": ["Ke Xu", "John Gunnar Carlsson"], "title": "A unified solution framework for truck-and-drone routing problems", "comment": null, "summary": "Coordinated truck-and-drone routing integrates the high capacity and range of ground vehicles with the flexible routing and speed of drones, enabling simultaneous service. Increasingly applied in last-mile delivery, this synchronization helps reduce completion time and operational costs. To improve its efficiency, various coordination modes between trucks and drones have been proposed. Each mode accommodates diverse operational constraints tailored to particular delivery requirements. In existing work, a slight change in the structural framework or operational characteristics could generate a totally different problem variant, which often requires the design of specialized algorithms. Consequently, under the requirement of maintaining structural validation and adapting to multiple operational features, this paper presents a unified three-phase solution framework based on the Lin-Kernighan-Helsgaun algorithm to solve a wide family of truck-and-drone routing problems. To validate its flexibility and effectiveness, we carry out numerical experiments on three problem variants: the Flying Sidekick Traveling Salesman Problem (FSTSP), the Traveling Salesman Problem with Multiple Drones (TSP-mD), and the Vehicle Routing Problem with Drones (VRP-D), benchmarking each against an effective algorithm. Computational results show that the framework can closely match optimal solutions on small-size instances and even improve the best-known solutions for several medium-size instances. Moreover, additional extensions are discussed to further highlight its versatility."}
{"id": "2602.20171", "categories": ["quant-ph", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.20171", "abs": "https://arxiv.org/abs/2602.20171", "authors": ["Shangzhou Xia", "Haitao Fu", "Jianjun Zhao"], "title": "QSolver: A Quantum Constraint Solver", "comment": null, "summary": "With the growing interest in quantum programs, ensuring their correctness is a fundamental challenge. Although constraint-solving techniques can overcome some limitations of traditional testing and verification, they have not yet been sufficiently explored in the context of quantum programs. To address this gap, we present QSolver, the first quantum constraint solver. QSolver provides a structured framework for handling five types of quantum constraints and incorporates an automated assertion generation module to verify quantum states. QSolver transforms quantum programs and multi-moment constraints into symbolic representations, and utilizes an SMT solver to obtain quantum states that satisfy these constraints. To validate the correctness of the generated input states, QSolver automatically generates assertion programs corresponding to each constraint. Experimental results show that QSolver efficiently processes commonly used quantum gates and demonstrates good scalability across quantum programs of different sizes."}
{"id": "2602.20984", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.20984", "abs": "https://arxiv.org/abs/2602.20984", "authors": ["Andrew Curtis", "Karen Lythgoe", "Stephen P. Hicks", "Lidong Bie", "Dominik Strutz", "Emma Chambers", "Brian Baptie", "Dave Cornwell", "Juliane Huebert", "Jessica Irving", "Glenn Jones", "Sergei Lebedev", "Walid Ben Mansour", "Aideliz Montiel Álvarez", "Stuart Nippress", "Koen Van Noten", "Tim Pharaoh", "Romesh Palamakumbura", "Nick Rawlinson", "Pablo Rodriguez Salgado", "James Verdon", "Chuanbin Zhu", "Wen Zhou", "Jelle Assink", "Ian Bastow", "Dino Bindi", "Tom Blenkinsop", "Raffaele Bonadio", "Michael Braim", "Tim Craig", "Elizabeth Day", "Giovanni Diaferia", "Stuart Dunning", "Ben Edwards", "Ake Fagereng", "Stewart Fishwick", "Amy Gilligan", "David Green", "David Healy", "Anna Horleston", "Mark Ireland", "Jenny Jenkins", "Jessica Johnson", "Mike Kendall", "Tom Kettlety", "Duygu Kiyan", "Paula Koelemeijer", "Rita Kounoudis", "Victoria Lane", "Chuanchuan Lu", "Alan MacDonald", "Fabrizio Magrini", "Auggie Marignier", "Carl Martin", "Martin Möllhoff", "Iain Neill", "Andy Nowacki", "Bob Paap", "Simone Pilia", "Sjoerd de Ridder", "Elmer Ruigrok", "Peidong Shi", "Anna Stork", "Alice Turner", "Jim Whiteley", "Anton Ziolkowski"], "title": "The UK and Ireland Geophysical Array -- Concept and Design", "comment": null, "summary": "Scientific exploration of the UK and Ireland's subsurface has made important contributions to scholarship and prosperity for people and the planet, including economic growth, sustainable use of natural resources, storage of greenhouse gases, and inspiring curiosity about the Earth beneath our feet. This article outlines a vision for an array of seismological instruments spanning the UK and Ireland, UKI Array, augmented by other types of geophysical sensors, to maximise the value offered by existing equipment pools. The mission is to research natural phenomena and structure in the deep and shallow Earth, to solve problems concerning hazards and resources, to connect scientists to schools and the broader public, and thus to inspire a new generation to learn about geophysics. The vision was created through a community driven process of engagement and participation. This paper describes the concept and design of the UKI-Array; a companion paper discusses related opportunities and potential applications."}
{"id": "2602.20282", "categories": ["math.NA", "cs.DM"], "pdf": "https://arxiv.org/pdf/2602.20282", "abs": "https://arxiv.org/abs/2602.20282", "authors": ["Egor P. Berezin", "Robert T. Zaks", "German Z. Alekhin", "Stanislav V. Morozov", "Sergey A. Matveev"], "title": "Two approaches to low-parametric SimRank computation", "comment": "13 pages, 3 figures, 1 table, 3 algorithms, 24 references", "summary": "In this work, we discuss low-parametric approaches for approximating SimRank matrices, which estimate the similarity between pairs of nodes in a graph. Although SimRank matrices and their computation require a significant amount of memory, common approaches mostly address the problem of algorithmic complexity. We propose two major formats for the economical embedding of target data. The first approach adopts a non-symmetric form that can be computed using a specialized alternating optimization algorithm. The second is based on a symmetric representation and Newton-type iterations. We propose numerical implementations for both methodologies that avoid working with dense matrices and maintain low memory consumption. Furthermore, we study both types of embeddings numerically using real data from publicly available datasets. The results show that our algorithms yield a good approximation of the SimRank matrices, both in terms of the error norm (particularly the Chebyshev norm) and in preserving the average number of the most similar elements for each given node."}
{"id": "2602.20174", "categories": ["cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.20174", "abs": "https://arxiv.org/abs/2602.20174", "authors": ["C. A. Lütken"], "title": "Elliptic mirror of the quantum Hall effect", "comment": "31 pages, 12 figures", "summary": "Toroidal sigma models of magneto-transport are analyzed, in which integer and fractional quantum Hall effects automatically are unified by a {holomorphic modular symmetry}. By exploiting a quantum equivalence called \\emph{mirror symmetry}, these models are mapped to tractable mirror models (also elliptic), in which topological protection is provided by more familiar winding numbers. Phase diagrams and scaling properties of elliptic models are compared to some of the experimental and numerical data accumulated over the past three decades. The geometry of scaling flows extracted from quantum Hall experiments is in good agreement with modular predictions, including the location of many quantum critical points. One conspicuous model %(arguably the simplest and most natural one) has a critical delocalization exponent $ν_{\\rm tor} = 18 \\ln 2 /(π^2 G^4) = 2.6051\\dots$ ($G$ is Gauss' constant) that is in excellent agreement with the value $ν_{\\rm num} = 2.607\\pm\\,.004$ calculated in the numerical Chalker-Coddington model, suggesting that these models are in the same universality class. The real delocalization exponent may be disentangled from other scaling exponents in finite size scaling experiments, giving an experimental value $ν_{\\rm exp} = 2.3\\pm 0.2$. The modular model suggests how these theoretical and experimental results may be reconciled, but in order to determine if these theoretical models really are in the quantum Hall universality class, improved finite size scaling experiments are urgently needed."}
{"id": "2602.20713", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.20713", "abs": "https://arxiv.org/abs/2602.20713", "authors": ["Carolina E. Mattsson", "Claudio Cellerini", "Jaume Ojer", "Michele Starnini"], "title": "Modeling financial transactions via random walks on temporal networks", "comment": "7 pages, see Supplementary Material as ancillary file", "summary": "We model financial transactions as random walks on activity-driven temporal networks. By enforcing fund conservation, our framework analytically derives heavy-tailed distributions for the stationary balances and transaction sizes. Crucially, the latter is driven by variance in the spending propensity of individuals. Calibrated with empirical data from a closed, digital currency community, the model also reproduces observed correlations between inflows and outflows. Our findings provide a path for understanding emergent properties of the circulation of money."}
{"id": "2602.20359", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.20359", "abs": "https://arxiv.org/abs/2602.20359", "authors": ["Rayan Mazouz", "Frederik Baymler Mathiesen", "Luca Laurenti", "Morteza Lahijanian"], "title": "StochasticBarrier.jl: A Toolbox for Stochastic Barrier Function Synthesis", "comment": null, "summary": "We present StochasticBarrier.jl, an open-source Julia-based toolbox for generating Stochastic Barrier Functions (SBFs) for safety verification of discrete-time stochastic systems with additive Gaussian noise. StochasticBarrier.jl certifies linear, polynomial, and piecewise affine (PWA) systems. The latter enables verification for a wide range of system dynamics, including general nonlinear types. The toolbox implements a Sum-of-Squares (SOS) optimization approach, as well as methods based on piecewise constant (PWC) functions. For SOS-based SBFs, StochasticBarrier.jl leverages semi-definite programming solvers, while for PWC SBFs, it offers three engines: two using linear programming (LP) and one based on gradient descent (GD). Benchmarking StochasticBarrier.jl against the state-of-the-art shows that the tool outperforms existing tools in computation time, safety probability bounds, and scalability across over 30 case studies. Compared to its closest competitor, StochasticBarrier.jl is up to four orders of magnitude faster, achieves significant safety probability improvements, and supports higher-dimensional systems."}
{"id": "2602.20383", "categories": ["stat.ME", "cs.LG", "econ.EM"], "pdf": "https://arxiv.org/pdf/2602.20383", "abs": "https://arxiv.org/abs/2602.20383", "authors": ["Joel Persson", "Jurriën Bakker", "Dennis Bohle", "Stefan Feuerriegel", "Florian von Wangenheim"], "title": "Detecting and Mitigating Group Bias in Heterogeneous Treatment Effects", "comment": null, "summary": "Heterogeneous treatment effects (HTEs) are increasingly estimated using machine learning models that produce highly personalized predictions of treatment effects. In practice, however, predicted treatment effects are rarely interpreted, reported, or audited at the individual level but, instead, are often aggregated to broader subgroups, such as demographic segments, risk strata, or markets. We show that such aggregation can induce systematic bias of the group-level causal effect: even when models for predicting the individual-level conditional average treatment effect (CATE) are correctly specified and trained on data from randomized experiments, aggregating the predicted CATEs up to the group level does not, in general, recover the corresponding group average treatment effect (GATE). We develop a unified statistical framework to detect and mitigate this form of group bias in randomized experiments. We first define group bias as the discrepancy between the model-implied and experimentally identified GATEs, derive an asymptotically normal estimator, and then provide a simple-to-implement statistical test. For mitigation, we propose a shrinkage-based bias-correction, and show that the theoretically optimal and empirically feasible solutions have closed-form expressions. The framework is fully general, imposes minimal assumptions, and only requires computing sample moments. We analyze the economic implications of mitigating detected group bias for profit-maximizing personalized targeting, thereby characterizing when bias correction alters targeting decisions and profits, and the trade-offs involved. Applications to large-scale experimental data at major digital platforms validate our theoretical results and demonstrate empirical performance."}
{"id": "2602.20620", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.20620", "abs": "https://arxiv.org/abs/2602.20620", "authors": ["Munetaka Sasaki"], "title": "Construction of a Neural Network with Temperature-Dependent Recall Patterns", "comment": "6 pages, 10 figures", "summary": "We present a simple model that recalls two different patterns depending on the temperature. To realize a change in recall pattern due to temperature change, we embed two patterns to different graphs: the first pattern into a fully connected graph and the second pattern into a sparse graph. Because a fully connected graph is more resistant to thermal fluctuations than a sparse graph, we can realize a change in recall pattern by tuning relative weights of the two patterns properly. We demonstrate by equilibrium Monte-Carlo simulations that such a temperature-dependent change in recall patterns does occur in our model. Simulation results strongly indicate that the system undergoes a first-order phase transition when the change in recall patterns occurs. It is also demonstrated by annealing simulations that the system fails to recall the pattern embedded in the sparse graph at low temperatures if the free-energy barrier is too high to overcome within the given simulation timescale."}
{"id": "2602.20856", "categories": ["q-fin.CP", "econ.EM", "q-fin.PM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20856", "abs": "https://arxiv.org/abs/2602.20856", "authors": ["Doron Avramov", "Xin He"], "title": "Stochastic Discount Factors with Cross-Asset Spillovers", "comment": null, "summary": "This paper develops a unified framework that links firm-level predictive signals, cross-asset spillovers, and the stochastic discount factor (SDF). Signals and spillovers are jointly estimated by maximizing the Sharpe ratio, yielding an interpretable SDF that both ranks characteristic relevance and uncovers the direction of predictive influence across assets. Out-of-sample, the SDF consistently outperforms self-predictive and expected-return benchmarks across investment universes and market states. The inferred information network highlights large, low-turnover firms as net transmitters. The framework offers a clear, economically grounded view of the informational architecture underlying cross-sectional return dynamics."}
{"id": "2602.20256", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20256", "abs": "https://arxiv.org/abs/2602.20256", "authors": ["Feng He", "Arthur Hutsalyuk", "Giuseppe Mussardo", "Andrea Stampiggi"], "title": "Spectral Decimation of Quantum Many-Body Hamiltonians", "comment": "16+6 pages; 5+3 figures", "summary": "We develop a systematic theory of spectral decimation for quantum many-body Hamiltonians and show that it provides a quantitative probe of emergent symmetries in statistically mixed spectra. Building on an analytical description of statistical mixtures, we derive an explicit expression for the size of a characteristic symmetry sector (CSS), defined as the largest subsequence of levels exhibiting non-Poissonian correlations. The CSS dimension is shown to be the size-biased average of the underlying symmetry sectors, establishing a direct link between spectral statistics and Hilbert-space structure. We apply this framework to two paradigmatic settings: Hilbert-space fragmentation and disorder-induced many-body localization (MBL). In fragmented systems, the CSS reproduces the mixture prediction and isolates correlated subsectors even when the full spectrum appears nearly Poissonian. In the disordered Heisenberg chain, spectral decimation reveals the gradual emergence of integrability through a shrinking CSS, whose statistics exhibit signatures consistent with local integrals of motion. We introduce a characteristic symmetry entropy (CSE) as a finite-size scaling observable and extract, within accessible system sizes, the crossover exponents. Our results establish spectral decimation as a controlled, unbiased and computationally inexpensive diagnostic of hidden structure in many-body spectra, capable of distinguishing between chaotic dynamics, statistical mixtures, and emergent integrability."}
{"id": "2602.20682", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.20682", "abs": "https://arxiv.org/abs/2602.20682", "authors": ["L. Salasnich", "F. Sattin"], "title": "Geometric investigation of chaos unfolding in Hamiltonian systems", "comment": null, "summary": "In this work we revisit the geometric approach to chaos in Hamiltonian dynamics, by means of the Jacobi-Levi-Civita equation (JLCE). We inspect numerically two low-dimensional dynamical systems; show that, along chaotic orbits, the exponential divergence between nearby trajectories quantified by the JLCE does not unfold in a continuous manner, rather is closer to a multiplicative discrete process: in correspondence of each turning point, where the trajectory bounces away from the boundary of the energetically allowed region, the relative separation increases sharply and abruptly. We highlight through analytical and numerical arguments that the chaotic rather than regular nature of the trajectory is determined by the details of the scattering with the boundary, and interpret these results in terms of parametric resonance theory, and specifically the Mathieu equation."}
{"id": "2602.21000", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.21000", "abs": "https://arxiv.org/abs/2602.21000", "authors": ["Rumana Lakdawala", "Roger Leenders", "Peter Ejbye-Ernst", "Joris Mulder"], "title": "Modelling Interaction Duration in Relational Event Models", "comment": "This paper is adapted from the dissertation of Rumana Lakdawala https://doi.org/10.26116/tsb.32104538", "summary": "The study of relational events, which are interactions occurring between actors over time, has gained significant traction recently. Traditional relational event models typically focus on modelling the occurrence and sequence of events without considering their duration even though duration information is frequently available in empirical relational event data. We introduce a novel Duration Relational Event Model (DuREM) that incorporates the temporal duration of events into the analysis. The proposed model extends the existing framework by (i) allowing the inclusion of past event durations in the endogenous statistics to account for how the duration of past events affects the rate of future interactions, and (ii) extending the traditional relational event model by also modelling when events will end based on past event history and covariates. This is achieved by extending the risk set to include both ongoing events at risk of ending and idle dyads at risk of starting new events. The methodology is implemented in a new R package `durem'. Two case studies concerning team dynamics and inter-personal violence are presented to illustrate the applicability of the model."}
{"id": "2602.20505", "categories": ["nlin.AO"], "pdf": "https://arxiv.org/pdf/2602.20505", "abs": "https://arxiv.org/abs/2602.20505", "authors": ["Yoshiki Kuramoto"], "title": "Half a century of the theory of synchronization", "comment": "10 pages, no figure, article submitted to the Statphys 19", "summary": "This review offers a retrospective of the development of the theory of coupled oscillators and synchronization over the past half century. Among the various works made by myself during this period, the following three specific works will be focused on, serving as some key points to illustrate the field's evolution. They are the derivation of (1) a simple partial differential equation exhibiting spatio-tempoeral chaos (Kuramoto-Sivashinsky equaiton), (2) a solvable mathematical model describing synchronization phase transition (Kuramoto model), and the discovery of (3) coexistence of coherence and incoherence in nonlocally coupled oscillators (chimera states). It is emphasized that all these works resulted fron the phase reduction of the complex Ginzburg-Landau equation (or its variants), the equation which was derived with a coworker in 1974 from a certain reaction-diffusion model. A quick overview will also be made on how the above three works influenced the subsequent development of the field of coupled oscillators and synchronization. Finally, a few comments will be made on how the methods of dynamical reduction, such as the center-manifold reduction and phase reduction, are crucial for exploring this field in depth. This article is a largely faithful reproduction of the content presented in my award lecture."}
{"id": "2602.20371", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.20371", "abs": "https://arxiv.org/abs/2602.20371", "authors": ["Magid Sabbagh", "David A. Stephens"], "title": "Semi-parametric Bayesian inference under Neyman orthogonality", "comment": "18 pages", "summary": "The validity of two-step or plug-in inference methods is questioned in the Bayesian framework. We study semi-parametric models where the plug-in of a non-parametrically modelled nuisance component is used. We show that when the nuisance and targeted parameters satisfy a Neyman orthogonal score property, the approach of cutting feedback through a two-step procedure is a valid way of conducting Bayesian inference. Our method relies on a non-parametric Bayesian formulation based on the Dirichlet process and the Bayesian bootstrap. We show that the marginal posterior of the targeted parameter exhibits good frequentist properties despite not accounting for the inferential uncertainty of the nuisance parameter. We adopt this approach in Bayesian causal inference problems where the nuisance propensity score model is estimated to obtain marginal inference for the treatment effect parameter, and demonstrate that a plug-in of the propensity score has a negligible effect on marginal posterior inference for the causal contrast. We investigate the absence of Neyman orthogonality and exploit our findings to show that in conventional two-step procedures, the posterior distribution converges under weaker restrictions than those needed in the frequentist sequel. For a simple family of useful scores, we demonstrate that even in the absence of Neyman orthogonality, the posterior distribution is asymptotically unchanged by the estimation of the nuisance parameter, merely provided the latter estimator is consistent."}
{"id": "2602.20373", "categories": ["hep-lat", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.20373", "abs": "https://arxiv.org/abs/2602.20373", "authors": ["Joseph Moscoso", "Felipe G. Ortega-Gama", "Raúl A. Briceño", "Andrew W. Jackura", "Charles Kacir", "Amy N. Nicholson"], "title": "Resolving the structure of bound states using lattice quantum field theories", "comment": null, "summary": "This work presents the first lattice calculation of a two-to-two particle matrix element of a local current. This exploratory calculation is performed using a leading-order pionless effective field theory of two nucleons in a finite 3D spatial volume, where the Hamiltonian can be diagonalized exactly for moderate volumes. By considering a range of couplings where the theory supports a deuteron-like bound state, we determine the finite-volume spectra and matrix elements of the conserved local vector current. Using the Lüscher formalism, we constrain the infinite-volume, purely hadronic amplitude for this theory. Using previously derived formalism, we then map the finite-volume matrix elements to scattering amplitudes describing a reaction coupling two-particle states via a current insertion, $\\2+\\Jc \\to \\2$. We then use a recently derived relation between this class of amplitudes and the bound-state elastic form factor to directly constrain the infinite-volume form factor. By varying over a range of values of the coupling of the theory, we explore the effects of this analysis for deep-bound states and shallow-bound states. We reproduce the expected result that for deep bound states, the finite-volume formalism is largely unnecessary, while for shallow bound states, it is absolutely critical to obtain a sensible result. We present a detailed outline of the analysis of this class of matrix elements, including the determination of the charge radius of the bound state. In the shallow bound state limit, we find good agreement with the prediction stemming from the anomalous threshold."}
{"id": "2602.21113", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21113", "abs": "https://arxiv.org/abs/2602.21113", "authors": ["Huy Trinh"], "title": "A Survey of Recent Developments in SYCL Compiler Implementations", "comment": null, "summary": "This survey discusses recent advancements in SYCL compiler implementations, one of the crucial aspects of compiler construction for heterogeneous computing systems. We explore the transition from traditional compiler construction, from Single-Source Multiple Compiler Passes (SMCP) to a more advanced approach to Single-Source Single Compiler Pass (SSCP). The survey analyzes multiple papers that researched the different developments of SYCL implementation based on SSCP and their approach to enhancing performance and addressing separate challenges."}
{"id": "2602.20299", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.20299", "abs": "https://arxiv.org/abs/2602.20299", "authors": ["Tim Pokart", "Frank Pollmann", "Jan Carl Budich"], "title": "Entanglement Barriers from Computational Complexity: Matrix-Product-State Approach to Satisfiability", "comment": "17 pages, 12 figures", "summary": "We approach the 3-SAT satisfiability problem with the quantum-inspired method of imaginary time propagation (ITP) applied to matrix product states (MPS) on a classical computer. This ansatz is fundamentally limited by a quantum entanglement barrier that emerges in imaginary time, reflecting the exponential hardness expected for this NP-complete problem. Strikingly, we argue based on careful analysis of the structure imprinted onto the MPS by the 3-SAT instances that this barrier arises from classical computational complexity. To reveal this connection, we elucidate with stochastic models the specific relationship between the classical hardness of the $\\sharp$P $\\supseteq$ NP-complete counting problem $\\sharp$3-SAT and the entanglement properties of the quantum state. Our findings illuminate the limitations of this quantum-inspired approach and demonstrate how purely classical computational complexity can manifest in quantum entanglement. Furthermore, we present estimates of the non-stabilizerness required by the protocol, finding a similar resource barrier. Specifically, the necessary amount of non-Clifford operations scales superlinearly in system size, thus implying extensive resource requirements of ITP on different architectures such as Clifford circuits or gate-based quantum computers."}
{"id": "2602.20540", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.20540", "abs": "https://arxiv.org/abs/2602.20540", "authors": ["Minseop Kim", "Takhyeong Kim", "Taekhyun Park", "Hanbyeol Park", "Hyerim Bae"], "title": "Generative AI and Machine Learning Collaboration for Container Dwell Time Prediction via Data Standardization", "comment": null, "summary": "Import container dwell time (ICDT) prediction is a key task for improving productivity in container terminals, as accurate predictions enable the reduction of container re-handling operations by yard cranes. Achieving this objective requires accurately predicting the dwell time of individual containers. However, the primary determinants of dwell time-owner information and cargo information-are recorded as unstructured text, which limits their effective use in machine learning models. This study addresses this limitation by proposing a collaborative framework that integrates generative artificial intelligence (Gen AI) with machine learning. The proposed framework employs Gen AI to standardize unstructured information into standard international codes, with dynamic re-prediction triggered by electronic data interchange state updates, enabling the machine learning model to predict ICDT accurately. Extensive experiments conducted on real container terminal data demonstrate that the proposed methodology achieves a 13.88% improvement in mean absolute error compared to conventional models that do not utilize standardized information. Furthermore, applying the improved predictions to container stacking strategies achieves up to 14.68% reduction in the number of relocations, thereby empirically validating the potential of Gen AI to enhance productivity in container terminal operations. Overall, this study provides both technical and methodological insights into the adoption of Gen AI in port logistics and its effectiveness."}
{"id": "2602.20326", "categories": ["math.OC", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.20326", "abs": "https://arxiv.org/abs/2602.20326", "authors": ["Ghorbanali Haghighatdoost"], "title": "Poisson Hamiltonian Pontryagin Dynamics and Optimal Control of Mechanical Systems on Lie Groupoids", "comment": null, "summary": "We develop a Poisson Hamiltonian formulation of Pontryagin dynamics for optimal control of mechanical systems on Lie groupoids. The reduced dynamics is formulated intrinsically on the dual Lie algebroid endowed with its canonical linear Poisson structure and evolves on its symplectic leaves. The main result of this work shows that symplectic leaves, rather than coadjoint orbits, provide the natural reduced phase spaces for Pontryagin dynamics on Lie groupoids. Under suitable regularity assumptions, we prove the equivalence between the variational formulation of the optimal control problem and the associated Poisson Hamiltonian Pontryagin system, and we show that groupoid invariant Lagrangians lead to reduced optimality conditions of Euler Poincare type. Several mechanical examples, including systems with configuration dependent inertia and local symmetries, are presented to illustrate the theory."}
{"id": "2602.20186", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.20186", "abs": "https://arxiv.org/abs/2602.20186", "authors": ["Frederick Dehmel", "Shilun Li"], "title": "A Symplectic Proof of the Quantum Singleton Bound", "comment": "6 pages", "summary": "We present a symplectic linear-algebraic proof of the Quantum Singleton Bound for stabiliser quantum error-correcting codes together with a Lean4 formalisation of the linear-algebraic argument. The proof is formulated in the language of finite-dimensional symplectic vector spaces modelling Pauli operators and relies on distance-based erasure correctability and the cleaning lemma. Using a dimension-counting argument within the symplectic stabiliser framework, we derive the bound \\( k + 2(d - 1) \\le n \\) for any [[n, k, d]] stabiliser code. This approach isolates the algebraic structure underlying the bound and avoids the heavier analytic machinery that appears in entropy-based proofs, while remaining well-suited to formal verification."}
{"id": "2602.20390", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.20390", "abs": "https://arxiv.org/abs/2602.20390", "authors": ["James Chen", "Alan Edelman", "John Urschel"], "title": "The largest 5th pivot may be the root of a 61st degree polynomial", "comment": null, "summary": "This paper introduces a number of new techniques in the study of the famous question from numerical linear algebra: what is the largest possible growth factor when performing Gaussian elimination with complete pivoting? This question is highly complex, due to a complicated set of polynomial inequalities that need to be simultaneously satisfied. This paper introduces the JuMP + Groebner basis + discriminant polynomial approach as well as the use of interval arithmetic computations. Thus, we are introducing a marriage of numerical and exact mathematical computations.\n  In 1988, Day and Peterson performed numerical optimization on $n=5$ with NPSOL and obtained a largest seen value of $4.1325...$. This same best value was reproduced by Gould with LANCELOT in 1991. We ran extensive comparable experiments with the modern software tool JuMP and also saw the same value $4.1325...$. While the combinatorial explosion of possibilities prevents us from knowing there may not be a larger maximum, we succeed in obtaining the exact mathematical value: the number $4.1325...$ is exactly the root of a 61st degree polynomial provided in this work, and is a maximum given the equality constraints seen by JuMP. In light of the numerics, we pose the conjecture that this lower bound is indeed the maximum. We also apply this technique to $n = 6$, $7$, and $8$.\n  Furthermore, in 1969, an upper bound of $4\\frac{17}{18}\\approx 4.94$ was produced for the maximum possible growth for $n = 5$. We slightly lower this upper bound to $4.84$."}
{"id": "2602.20560", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.20560", "abs": "https://arxiv.org/abs/2602.20560", "authors": ["Yi-Ming Liu", "Wei-Qiang Chen", "Zheng-Cheng Gu"], "title": "Real-space construction and classification for time-reversal symmetric crystalline superconductors in 2D interacting fermionic systems", "comment": null, "summary": "Crystalline symmetry and time-reversal symmetry are commonly present in real superconducting materials. However, the topological classification of systems respecting these symmetries, particularly for interacting fermions, remains incomplete. In this work, we systematically classify time-reversal symmetry-protected crystalline topological superconductors in two-dimensional interacting fermionic systems using an explicit real-space construction. Among the resulting phases, we identify intrinsically interacting fermionic topological superconductors, i.e., phases that cannot be realized in either free-fermion or interacting bosonic systems. For spinless fermions with protecting symmetry group $C_4 \\times Z_2^T$ or $D_4 \\times Z_2^T$ (plus fermion parity), the intrinsic sector has a $Z_4$ classification. The corresponding root phases generating this $Z_4$ classification admit a transparent real-space construction in terms of decorated 1D blocks. These blocks are 1D fermionic symmetry-protected topological (FSPT) phases, realizable as double Majorana chains. We further find the corresponding $Z_4$ spinless intrinsic phases for wallpaper groups $p4$, $p4m$, and $p4g$. We also find an additional $Z_2$ intrinsically interacting phase for spinless fermions with wallpaper group $pm$, which is absent with the corresponding point-group symmetry alone. Moreover, these intrinsic phases naturally give rise to higher-order FSPT phases that support corner zero modes. Finally, we verify the crystalline equivalence principle for generic 2D interacting FSPT systems with both crystalline and internal symmetries."}
{"id": "2602.20821", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.20821", "abs": "https://arxiv.org/abs/2602.20821", "authors": ["Julia Atienza-Barthelemy", "Samuel Martin-Gutierrez", "Juan C. Losada", "Rosa M. Benito"], "title": "Relationship between ideology and language in the Catalan independence context", "comment": null, "summary": "Political polarization generates strong effects on society, driving controversial debates and influencing the institutions. Territorial disputes are one of the most important polarized scenarios and have been consistently related to the use of language. In this work, we analyzed the opinion and language distributions through Twitter data of a particular territorial dispute around the independence of Catalonia. We infer a continuous opinion distribution by applying a model based on retweet interactions, previously detecting elite users with fixed and antagonist opinions. The resulting distribution presents a mainly bimodal behavior with an intermediate third pole that shows a less polarized society with the presence of not only antagonist opinions. We find that the more active, engaged and influential users hold more extreme positions. Also we prove that there is a clear relationship between political positions and the use of language, showing that against independence users speak mainly Spanish while pro-independence users speak Catalan and Spanish almost indistinctly. However, the third pole, closer in political opinion to the pro-independence pole, behaves similarly to the against-independence one concerning the use of language."}
{"id": "2602.20453", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.20453", "abs": "https://arxiv.org/abs/2602.20453", "authors": ["Haizum Hanim Ab Halim", "Dalila Alias", "Akmal Zaini Arsad", "Lewis Tee Jen Looi", "Rosdiadee Nordin", "Denny Ng Kok Sum"], "title": "IoT-Driven Building Energy Management Systems (BEMS) for Net Zero Energy Buildings: Concept, Integration and Future Directions", "comment": null, "summary": "Construction and operating of buildings is one of the major contributors to global greenhouse emissions. With the inefficient usage of energy due to human behavior and manual operation, the energy consumption of buildings is further increased. These challenges highlight the need for improved Building Energy Management Systems (BEMS) integrated with Internet of Things (IoT) and data driven intelligence to enhance energy-efficiency in a building and contribute to Net-Zero Energy Buildings (NZEB) targets. This paper offers four keys contributions: i) a systematic review of IoT enabled BEMS including components, network architecture and functional capabilities, ii) an evaluation of real-world BEMS datasets to support Artificial Intelligence (AI) based predictive control, iii) an analysis of integration challenges related to interoperability, smart grids and net-zero energy strategies, and iv) a case study highlighting global best practices, performances outcomes, and lesson learned for scaling advanced BEMS solutions."}
{"id": "2602.20448", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.20448", "abs": "https://arxiv.org/abs/2602.20448", "authors": ["Shamriddha De", "Joyee Ghosh"], "title": "Posterior Mode Guided Dimension Reduction for Bayesian Model Averaging in Heavy-Tailed Linear Regression", "comment": "35 pages, 6 figures", "summary": "For large model spaces, the potential entrapment of Markov chain Monte Carlo (MCMC) based methods with spike-and-slab priors poses significant challenges in posterior computation in regression models. On the other hand, maximum a posteriori (MAP) estimation, which is a more computationally viable alternative, fails to provide uncertainty quantification. To address these problems simultaneously and efficiently, this paper proposes a hybrid method that blends MAP estimation with MCMC-based stochastic search algorithms within a heavy-tailed error framework. Under hyperbolic errors, the current work develops a two-step expectation conditional maximization (ECM) guided MCMC algorithm. In the first step, we conduct an ECM-based posterior maximization and perform variable selection, thereby identifying a reduced model space in a high posterior probability region. In the second step, we execute a Gibbs sampler on the reduced model space for posterior computation. Such a method is expected to improve the efficiency of posterior computation and enhance its inferential richness. Through simulation studies and benchmark real life examples, our proposed method is shown to exhibit several advantages in variable selection and uncertainty quantification over various state-of-the-art methods."}
{"id": "2602.20256", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20256", "abs": "https://arxiv.org/abs/2602.20256", "authors": ["Feng He", "Arthur Hutsalyuk", "Giuseppe Mussardo", "Andrea Stampiggi"], "title": "Spectral Decimation of Quantum Many-Body Hamiltonians", "comment": "16+6 pages; 5+3 figures", "summary": "We develop a systematic theory of spectral decimation for quantum many-body Hamiltonians and show that it provides a quantitative probe of emergent symmetries in statistically mixed spectra. Building on an analytical description of statistical mixtures, we derive an explicit expression for the size of a characteristic symmetry sector (CSS), defined as the largest subsequence of levels exhibiting non-Poissonian correlations. The CSS dimension is shown to be the size-biased average of the underlying symmetry sectors, establishing a direct link between spectral statistics and Hilbert-space structure. We apply this framework to two paradigmatic settings: Hilbert-space fragmentation and disorder-induced many-body localization (MBL). In fragmented systems, the CSS reproduces the mixture prediction and isolates correlated subsectors even when the full spectrum appears nearly Poissonian. In the disordered Heisenberg chain, spectral decimation reveals the gradual emergence of integrability through a shrinking CSS, whose statistics exhibit signatures consistent with local integrals of motion. We introduce a characteristic symmetry entropy (CSE) as a finite-size scaling observable and extract, within accessible system sizes, the crossover exponents. Our results establish spectral decimation as a controlled, unbiased and computationally inexpensive diagnostic of hidden structure in many-body spectra, capable of distinguishing between chaotic dynamics, statistical mixtures, and emergent integrability."}
{"id": "2602.20308", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2602.20308", "abs": "https://arxiv.org/abs/2602.20308", "authors": ["Raphaël Maire"], "title": "Hyperuniformity in active fluids reshape nucleation and capillary-wave dynamics", "comment": "15 pages, 2 figures", "summary": "While nucleation in typical active and driven fluids often appears equilibrium-like, striking departures emerge when large-scale fluctuations are strongly suppressed. Here, we investigate nucleation in nonequilibrium hyperuniform fluids by projecting the full density-field dynamics onto relevant collective variables. We demonstrate that nucleation is governed by a nonequilibrium quasi-potential rather than the reversible work of formation. Surprisingly, because of the reduced hyperuniform fluctuations, the nucleation probability no longer separates into the usual surface and volume contributions. Furthermore, accounting for capillary waves reveals a clear breakdown of detailed balance driven by nonreciprocal dynamics. More broadly, our framework can be readily extended to identify nonequilibrium signatures in conventional active fluids."}
{"id": "2602.21123", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.21123", "abs": "https://arxiv.org/abs/2602.21123", "authors": ["Wojciech Szumiński", "Tomasz Kapitaniak"], "title": "Dynamics and non-integrability of the variable-length double pendulum: exploring chaos and periodicity via the Lyapunov refined maps", "comment": null, "summary": "This paper extends our previous work~(Szumiński and Maciejewski, 2024), where we explored the dynamics and integrability of the double-spring pendulum. Here, we investigate the variable-length double pendulum, a three-degree-of-freedom Hamiltonian system combining features of the classic double pendulum and the swinging Atwood machine. With its intricate dynamics, this system is crucial for studying nonlinear phenomena such as high-order resonances, chaos, and bifurcations. We address the challenges posed by high-dimensional phase spaces using a novel tool, the \\textit{Lyapunov refined maps}, which integrates Poincaré sections, phase-parametric diagrams, and Lyapunov exponents. This framework comprehensively analyzes periodic, quasi-periodic, and chaotic behaviors. By measuring the strength of chaos, it also offers insights into the system's dynamical structure. Additionally, we apply Morales-Ramis theory to examine integrability, leveraging the differential Galois group of variational equations to establish non-integrability conditions. The Kovacic algorithm is used to analyze the solvability of higher-dimensional differential equations, complemented by Lyapunov exponent diagrams to exclude integrable dynamics under certain parameters. Our findings advance the fundamental understanding of variable-length pendulum dynamics, offering new insights and methodologies for further research with potential applications in adaptive robotics, energy harvesting, and biomechanics. Additionally, this work represents a significant step toward proving the long-sought non-integrability of the classical double pendulum."}
{"id": "2602.20936", "categories": ["physics.soc-ph", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2602.20936", "abs": "https://arxiv.org/abs/2602.20936", "authors": ["Albarracin Mahault", "Mikeda Anna", "Jimenez Rodriguez Alejandro", "Namjoshi Sanjeev", "Sakthivadivel Dalton", "Pae Hongju", "Shah Harshil", "Wilson Philip"], "title": "Empathy Modeling in Active Inference Agents for Perspective-Taking and Alignment", "comment": null, "summary": "Artificial agents capable of understanding and aligning with others' intentions are essential for safe and socially robust artificial intelligence. We introduce a computational framework for empathy in active inference agents, grounded in explicit perspective-taking via self-other model transformation.\n  We instantiate this framework in a multi-agent Iterated Prisoner's Dilemma and show that empathic perspective-taking induces robust cooperation without explicit communication or reward shaping. Cooperation emerges only when empathy is reciprocated, while asymmetric empathy leads to systematic exploitation. Beyond equilibrium outcomes, empathic agents exhibit synchronized behavior, rapid recovery from stochastic defections, and joint intentional dynamics resembling apology-forgiveness cycles. Near empathy symmetry, interactions display long transients and elevated variance, consistent with critical dynamics near regime boundaries.\n  We further examine a learning-enabled variant in which agents infer opponent type via Bayesian updating. While opponent models converge rapidly, long-run cooperation remains primarily determined by the empathy parameter, indicating that cooperation is driven by empathic structure rather than learned reciprocity. Empathy functions as a structural prior over social interaction, shaping coordination stability, robustness, and temporal dynamics. The proposed framework highlights active inference as a principled foundation for socially aligned artificial agents that coordinate through internal simulation rather than behavioral mimicry."}
{"id": "2602.20640", "categories": ["math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20640", "abs": "https://arxiv.org/abs/2602.20640", "authors": ["Razak Christophe Sabi Gninkou", "Andrés F. López-Lopera", "Franck Massa", "Rodolphe Le Riche"], "title": "Scalable multitask Gaussian processes for complex mechanical systems with functional covariates", "comment": null, "summary": "Functional covariates arise in many scientific and engineering applications when model inputs take the form of time-dependent or spatially distributed profiles, such as varying boundary conditions or changing material behaviours. In addition, new practices in digital simulation require predictions accompanied by confidence intervals. Models based on Gaussian processes (GPs) provide principled uncertainty quantification. However, GPs capable of jointly handling functional covariates and multiple correlated functional tasks remain largely under-explored. In this work, we extend the framework of GPs with functional covariates to multitask problems by introducing a fully separable kernel structure that captures dependencies across tasks and functional inputs. By taking advantage of the Kronecker structure of the covariance matrix, the model is made scalable. The proposed model is validated on a synthetic benchmark and applied to a realistic structure, a riveted assembly with functional descriptions of the material behaviour and response forces. The proposed functional multitask GP significantly improves over single task GPs. For the riveted assembly, it requires less than 100 samples to produce an accurate mean and confidence interval prediction. Despite its larger number of parameters, the multitask GP is computationally easier to learn than its single task pendant."}
{"id": "2602.20516", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2602.20516", "abs": "https://arxiv.org/abs/2602.20516", "authors": ["Yuki Nagai", "Akio Tomiya", "Hiroshi Ohno"], "title": "Lattice Gauge Theory via LLVM-Level Automatic Differentiation", "comment": "7 pages, 3 figures, 1 table + Supplemental Material", "summary": "We enable the automatic construction of Hybrid Monte Carlo (HMC) forces in lattice gauge theory by performing reverse-mode automatic differentiation at the level of optimized LLVM intermediate representation, making the approach applicable to any language that lowers lattice action code to LLVM. In practice, this means that once the action evaluation routine is implemented, the corresponding HMC force can be generated automatically from the same code path, without deriving or maintaining a separate force routine. The method preserves conventional imperative, in-place implementations and enables a single-source workflow in which forces are generated directly from the action code while inheriting compiler optimizations. We perform end-to-end reverse-mode differentiation of both gauge and Wilson fermion actions. For the Wilson fermion case, we find that the force generated by automatic differentiation achieves performance comparable to a conventional hand-written fermion force implementation. The same differentiation pipeline targets both CPU and GPU backends, providing a practical route to performance-portable force construction for compositional lattice actions."}
{"id": "2602.21155", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21155", "abs": "https://arxiv.org/abs/2602.21155", "authors": ["Sanchita Ghosh", "Tanushree Roy"], "title": "KAN-Koopman Based Rapid Detection Of Battery Thermal Anomalies With Diagnostics Guarantees", "comment": "10 pages, 2 figures, Accepted to The 2026 American Control Conference", "summary": "Early diagnosis of battery thermal anomalies is crucial to ensure safe and reliable battery operation by preventing catastrophic thermal failures. Battery diagnostics primarily rely on battery surface temperature measurements and/or estimation of core temperatures. However, aging-induced changes in the battery model and limited training data remain major challenges for model-based and machine-learning based battery state estimation and diagnostics. To address these issues, we propose a Kolomogorov-Arnold network (KAN) in conjunction with a Koopman-based detection algorithm that leverages the unique advantages of both methods. Firstly, the lightweight KAN provides a model-free estimation of the core temperature to ensure rapid detection of battery thermal anomalies. Secondly, the Koopman operator is learned in real time using the estimated core temperature from KAN and the measured surface temperature of the battery to provide a prediction for diagnostic residual generation. This online learning approach overcomes the challenges of model changes, while the integrated structure reduces the dependence on large datasets. Furthermore, we derive analytical conditions that provide diagnostic guarantees on our KAN-Koopman detection scheme. Our simulation results illustrate a significant reduction in detection time with the proposed algorithm compared to the baseline Koopman-only algorithm."}
{"id": "2602.20609", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.20609", "abs": "https://arxiv.org/abs/2602.20609", "authors": ["Zhenhua Zheng", "Lu Zhang", "Junhong Zou", "Shitong Liu", "Zhen Lei", "Xiangyu Zhu", "Zhiyong Liu"], "title": "GA-Field: Geometry-Aware Vehicle Aerodynamic Field Prediction", "comment": null, "summary": "Accurate aerodynamic field prediction is crucial for vehicle drag evaluation, but the computational cost of high-fidelity CFD hinders its use in iterative design workflows. While learning-based methods enable fast and scalable inference, accurately aerodynamic fields modeling remains challenging, as it demands capturing both long-range geometric effects and fine-scale flow structures. Existing approaches typically encode geometry only once at the input and formulate prediction as a one-shot mapping, which often leads to diluted global shape awareness and insufficient resolution of sharp local flow variations. To address these issues, we propose GA-Field, a Geometry-Aware Field prediction network that introduces two complementary design components: (i) a global geometry injection mechanism that repeatedly conditions the network on a compact 3D geometry embedding at multiple stages to preserve long-range geometric consistency, and (ii) a coarse-to-fine field refinement strategy to recover sharp local aerodynamic details. GA-Field achieves new state-of-the-art performance on ShapeNet-Car and the large-scale DrivAerNet++ benchmark for surface pressure, wall shear stress, and 3D velocity prediction tasks, while exhibiting strong out-of-distribution generalization across different vehicle categories."}
{"id": "2602.20357", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.20357", "abs": "https://arxiv.org/abs/2602.20357", "authors": ["Muhammad Khan", "Yangyang Xu"], "title": "A variance reduced framework for (non)smooth nonconvex-nonconcave stochastic minimax problems with extended Kurdyka-Lojasiewicz property", "comment": null, "summary": "In this paper, we study stochastic constrained minimax optimization problems with nonconvex-nonconcave structure, a central problem in modern machine learning, for which reliable and efficient algorithms remain largely unexplored due to its inherent challenges. Prior approaches for nonconvex minimax optimization often require (strong) concavity on the maximization part, or certain restrictive geometric assumptions on the joint objective to have guaranteed convergence. In contrast, our method only assumes weak convexity in the primal variable and the extended Kurdyka-Lojasiewicz (KL) property, with exponent $θ\\in [0,1]$, in the dual variable, significantly broadening the class of tractable problems. To this end, we propose a variance reduced algorithm that provably handles this general setting and achieves an $\\varepsilon$-stationary solution with state-of-the-art sample complexity: in the smooth finite-sum setting, the sample complexity is $\\mathcal{O}\\left(\\sqrt{N}\\,\\varepsilon^{-\\max\\{4θ,2\\}}\\right)$, where $N$ is the number of total samples, and in the online smooth setting, it is $\\mathcal{O}\\Big(\\varepsilon^{-\\max\\{6θ,3\\}}\\Big)$. For the structured nonsmooth problem, the sample complexity is $\\mathcal{O}\\left(\\sqrt{N}\\,\\max\\Big\\{\\varepsilon^{-3}, \\varepsilon^{-5θ}, \\varepsilon^{-\\frac{11θ-3}{2θ}}\\Big\\}\\right)$ and $\\mathcal{O}\\left(\\max\\left\\{\\varepsilon^{-4}, \\varepsilon^{-\\frac{15θ-1}{2}}, \\varepsilon^{-\\frac{31θ-9}{4θ}}\\right\\}\\right)$ respectively for the two settings. To the best of our knowledge, this is the first unified framework that jointly accommodates weak convexity, the extended KL property, and variance-reduced stochastic updates, making it highly suitable for large-scale applications."}
{"id": "2602.20234", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20234", "abs": "https://arxiv.org/abs/2602.20234", "authors": ["Tyler D. Kharazi", "Stepan Fomichev", "Shu Kanno", "Takao Kobayashi", "Juan Miguel Arrazola", "Qi Gao", "Torin F. Stetina"], "title": "Quantum Simulations for Extreme Ultraviolet Photolithography", "comment": null, "summary": "Extreme Ultraviolet (EUV) lithography is the state-of-the-art process in semiconductor fabrication, yet its spatial resolution is fundamentally limited by the ``blur'' originating from absorption of photons at 92 eV, which induce physical and chemical changes in the photoresist via excited state processes and electron cascades. Accurate modeling of these phenomena requires precise ab initio data for high-energy decay channels, specifically photoabsorption and photoelectron emission. These are computationally difficult for classical methods due to prohibitive scaling in simulating electron dynamics, or due to the inability to resolve the ionization continuum in an efficient manner. In this work, we present quantum simulation algorithms to compute these key observables. First, we introduce a coherent time-domain spectroscopy algorithm optimized to resolve the photoabsorption cross-section at the 92 eV operating frequency. Second, we develop a first-quantized plane-wave simulation to compute the photoelectron kinetic energy spectrum, utilizing real-time dynamics and energy windowing to treat bound and delocalized scattering states on equal footing. Additionally, we provide logical resource estimation for a model photoresist monomer, 4-iodo-2-methylphenol (IMePh), and demonstrate that 92 eV absorption sensitivity can be resolved using roughly $200$ logical qubits and $10^{9}$ total non-Clifford gates per circuit with approximately $10^3$ shots for the smallest instance. The more sophisticated photoemission algorithm that models the continuum explicitly, incurs gate costs of $\\geq 10^{13}$ total non-Clifford gates per circuit, $10^4$ shots, and requires a few thousand logical qubits. These results establish high-fidelity quantum simulations as a key component to parameterize the multi-scale macroscopic models required to overcome the electron blur bottleneck in semiconductor miniaturization."}
{"id": "2602.20395", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.20395", "abs": "https://arxiv.org/abs/2602.20395", "authors": ["Tristan Goodwill", "Jeremy Hoskins", "Zydrunas Gimbutas", "Bowei Wu"], "title": "A parametrix for the surface Stokes equation", "comment": null, "summary": "We introduce an integral equation formulation of the surface Stokes equations, constructed using two-dimensional Stokeslets. The resulting integral equations are Fredholm integral equations of the second kind and can be discretized to high order using standard tools. Since the resulting discrete linear systems are dense, we describe and analyze a proxy shell method to construct fast direct solvers for these systems. The properties of our integral equation, and the performance of the resulting numerical scheme, are illustrated with several representative numerical examples."}
{"id": "2602.20600", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20600", "abs": "https://arxiv.org/abs/2602.20600", "authors": ["Debraj Debata", "Abhirup Mukherjee", "Siddhartha Lal"], "title": "Kondo breakdown as an entanglement transition driven by continuous measurement", "comment": "28 pages, 19 Figures", "summary": "We study the breakdown of Kondo screening by a local magnetic field from the perspective of a measurement-driven entanglement transition in a monitored quantum system. Here, the Kondo coupling leads to the growth in entanglement of an impurity spin with it's fermionic environment, while the local field plays the role of a continuous observer. Using a non-perturbative Unitary Renormalization Group (URG) approach, we derive coupled renormalization-group flow equations for the Kondo exchange and the local field, and obtain a field-dependent RG phase diagram. The RG flows separate a low-energy Kondo-screened phase, where the impurity is absorbed into the Fermi sea and forms an entangled singlet with the conduction bath, from a polarized local-moment phase in which screening is frustrated and impurity-bath entanglement is suppressed. We identify the fixed-point Hamiltonians governing the two phases and the critical regime, and relate the transition to the emergence of a novel non-Fermi liquid. Various impurity signatures such as the spectral function and thermalisation of impurity observables are used to characterise this entanglement transition. These results offer insight into the interplay of decoherence and measurement in governing the dynamics of a prototypical quantum system."}
{"id": "2602.20837", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.20837", "abs": "https://arxiv.org/abs/2602.20837", "authors": ["Samuel Martin-Gutierrez", "Juan C. Losada", "Rosa M. Benito"], "title": "Recurrent patterns of user behavior in different electoral campaigns: A Twitter analysis of the Spanish general elections of 2015 and 2016", "comment": null, "summary": "We have retrieved and analyzed several millions of Twitter messages corresponding to the Spanish General elections held on the 20th of December 2015 and repeated on the 26th of June 2016. The availability of data from two electoral campaigns that are very close in time allows us to compare collective behaviors of two analogous social systems with a similar context. By computing and analyzing the time series of daily activity, we have found a significant linear correlation between both elections. Additionally, we have revealed that the daily number of tweets, retweets and mentions follow a power law with respect to the number of unique users that take part in the conversation. Furthermore, we have verified that the topologies of the networks of mentions and retweets do not change from one election to the other, indicating that their underlying dynamics are robust in the face of a change in social context. Hence, in the light of our results, there are several recurrent collective behavioral patterns that exhibit similar and consistent properties in different electoral campaigns."}
{"id": "2602.20683", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.20683", "abs": "https://arxiv.org/abs/2602.20683", "authors": ["Mohamed Shamseldein"], "title": "Grid-Mind: An LLM-Orchestrated Multi-Fidelity Agent for Automated Connection Impact Assessment", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable tool-use capabilities, yet their application to power system operations remains largely unexplored. This paper presents Grid-Mind, a domain-specific LLM agent that interprets natural-language interconnection requests and autonomously orchestrates multi-fidelity power system simulations. The LLM-first architecture positions the language model as the central decision-making entity, employing an eleven-tool registry to execute Connection Impact Assessment (CIA) studies spanning steadystate power flow, N-1 contingency analysis, transient stability, and electromagnetic transient screening. A violation inspector grounds every decision in quantitative simulation outputs, while a three-layer anti-hallucination defence mitigates numerical fabrication risk through forced capacity-tool routing and post-response grounding validation. A prompt-level self-correction mechanism extracts distilled lessons from agent failures, yielding progressive accuracy improvements without model retraining. End-to-end evaluation on 50 IEEE 118-bus scenarios (DeepSeek-V3, 2026-02-23) achieved 84.0% tool-selection accuracy and 100% parsing accuracy. A separate 56-scenario self-correction suite passed 49 of 56 cases (87.5%) with a mean score of 89.3. These results establish a reproducible baseline for continued refinement while maintaining auditable, simulation-grounded decision support."}
{"id": "2602.20498", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.20498", "abs": "https://arxiv.org/abs/2602.20498", "authors": ["Peng Zhang"], "title": "Fast Algorithms for Exact Confidence Intervals in Randomized Experiments with Binary Outcomes", "comment": null, "summary": "We construct exact confidence intervals for the average treatment effect in randomized experiments with binary outcomes using sequences of randomization tests. Our approach does not rely on large-sample approximations and is valid for all sample sizes. Under a balanced Bernoulli design or a matched-pairs design, we show that exact confidence intervals can be computed using only $O(\\log n)$ randomization tests, yielding an exponential reduction in the number of tests compared to brute-force. We further prove an information-theoretic lower bound showing that this rate is optimal. In contrast, under balanced complete randomization, the most efficient known procedures require $O(n\\log n)$ randomization tests (Aronow et al., 2023), establishing a sharp separation between these designs. In addition, we extend our algorithm to general Bernoulli designs using $O(n^2)$ randomization tests."}
{"id": "2602.20321", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.20321", "abs": "https://arxiv.org/abs/2602.20321", "authors": ["Robin Bebon", "Thomas Speck"], "title": "Mutual Linearity is a Generic Property of Steady-State Markov Networks", "comment": "To appear in Phys. Rev. Lett", "summary": "Understanding and predicting how complex systems respond to external perturbations is a central challenge in nonequilibrium statistical physics. Here we consider continuous-time Markov networks, which we subject to perturbations along a single edge. We find that in steady state the probabilities of any two states are linearly related to one another. We show that this mutual linearity of probabilities extends to a broad class of observables, including currents but also generic counting and state-dependent observables. Moreover, we derive an exact relation between the relative response of any state's probability and the ratio of two steady-state probabilities. Leveraging the Markov chain tree theorem, we further show that probabilities and the considered observables are constrained by the topological and kinetic properties of the network and provide analytical expressions in terms of spanning tree polynomials. Our results are general, holding for arbitrary rate parameterizations and extending far from equilibrium."}
{"id": "2602.21149", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.21149", "abs": "https://arxiv.org/abs/2602.21149", "authors": ["Swetamber Das"], "title": "Geometry- and inertia-limited chaotic growth in classical many-body systems", "comment": "13 pages (including supplemental material), 1 figure; comments are welcome", "summary": "Chaotic instability in many-body systems is commonly quantified by the largest Lyapunov exponent, yet general constraints on its magnitude in classical interacting systems remain poorly understood. Here we establish explicit, Hamiltonian-specific upper bounds on the largest Lyapunov exponent for classical many-body systems with local interactions. These bounds arise from instantaneous stability constraints on the Hamiltonian flow and are expressed in terms of inertial scales and the curvature of the interaction potential. We show that they naturally separate into two qualitatively distinct classes: non-violable bounds, controlled by worst-case local curvature scales and inertia and insensitive to spatial structure, and ergodic ceilings, which retain spectral information and encode collective modes and finite-size effects under generic dynamical evolution. For a paradigmatic one-dimensional coupled-rotor chain (Josephson junction array), the ergodic ceiling admits a closed analytic form and produces a dynamically inaccessible region for sustained chaotic growth in the Lyapunov exponent-energy plane, which we confirm numerically. In contrast to non-violable estimates, the ergodic ceiling yields a sharper constraint on chaotic growth by capturing collective suppression mechanisms absent at the level of local curvature alone. Remarkably, in the thermodynamic limit the ergodic ceiling asymptotically approaches an inertial ceiling that limits sustained Lyapunov growth, becoming independent of temperature and interaction strength. While classical systems do not admit universal chaos bounds, our results identify a broad class of natural Hamiltonian systems in which chaotic growth is inherently limited by inertia and interaction geometry, thereby setting a minimal microscopic timescale for long-time loss of memory of initial conditions."}
{"id": "2602.20681", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.20681", "abs": "https://arxiv.org/abs/2602.20681", "authors": ["Sirui Lin", "Zijun Gao", "Jose Blanchet", "Peter Glynn"], "title": "Statistical Inference in Causal Partial Identification with Smooth Densities", "comment": null, "summary": "Many causal quantities are only partially identifiable due to the inherent missingness of potential outcomes, and the associated partial identification (PI) sets can be obtained by solving an optimal transport (OT) problem. Covariates often provide additional information about the potential outcomes and thus yield tighter PI sets, which can be obtained via conditional optimal transport (COT). However, COT-based PI set estimators are susceptible to the curse of dimensionality in the covariates and outcomes, which precludes the asymptotic normality and hinders statistical inference. In this paper, we exploit smoothness in the marginal densities of covariates and potential outcomes and develop a wavelet-based primal method for COT with multivariate outcomes and covariates. Moreover, for quadratic cost functions, we establish a stability result for COT and prove asymptotic normality of the proposed estimator. This characterization of the asymptotic distribution enables valid statistical inference for the partial identification set. Empirically, we validate the estimation and inference performance of our approach through numerical experiments in comparison with existing benchmarks."}
{"id": "2602.20848", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2602.20848", "abs": "https://arxiv.org/abs/2602.20848", "authors": ["Andres Stump", "Jeremy R. Green"], "title": "Importance of local tetraquark operators for $T_{cc}(3875)^+$", "comment": "10 pages, 3 figures, talk presented at the 42nd International Symposium on Lattice Field Theory (LATTICE2025), 2-8 November 2025, Tata Institute of Fundamental Research, Mumbai, India", "summary": "The doubly charmed tetraquark $T_{cc}(3875)^+$ observed at LHCb has attracted considerable interest in recent years. To accurately determine its finite-volume spectrum, a variational analysis using a large basis of operators, including bilocal scattering operators, but also local tetraquark operators, should be employed. Using Wilson-clover fermions at the $SU(3)$-flavour-symmetric point, we investigated the importance of local tetraquark operators for the $T_{cc}$ spectrum by adding them to a large basis of bilocal $DD^*$ and $D^*D^*$ scattering operators. We performed this calculation using the distillation framework combined with a position-space sampling method that we recently developed. This method makes local tetraquark operators affordable in distillation. Upon including local tetraquark operators, we observe significant shifts in the estimates of several energy levels. Finally, we show the effect of these shifts on the $DD^*$ scattering phase shifts obtained from a single-channel $s$-wave Lüscher analysis."}
{"id": "2602.20795", "categories": ["stat.ME", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.20795", "abs": "https://arxiv.org/abs/2602.20795", "authors": ["Xinhui Rong", "Girish N. Nair"], "title": "Hawkes Identification with a Prescribed Causal Basis: Closed-Form Estimators and Asymptotics", "comment": "21 pages, 4 figures", "summary": "Driven by the recent surge in neural-inspired modeling, point processes have gained significant traction in systems and control. While the Hawkes process is the standard model for characterizing random event sequences with memory, identifying its unknown kernels is often hindered by nonlinearity. Approaches using prescribed basis kernels have emerged to enable linear parameterization, yet they typically rely on iterative likelihood methods and lack rigorous analysis under model misspecification. This paper justifies a closed-form Least Squares identification framework for Hawkes processes with prescribed kernels. We guarantee estimator existence via the almost-sure positive definiteness of the empirical Gram matrix and prove convergence to the true parameters under correct specification, or to well-defined pseudo-true parameters under misspecification. Furthermore, we derive explicit Central Limit Theorems for both regimes, providing a complete and interpretable asymptotic theory. We demonstrate these theoretical findings through comparative numerical simulations."}
{"id": "2602.20928", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.20928", "abs": "https://arxiv.org/abs/2602.20928", "authors": ["Odysseas Vlachopoulos", "Niklas Luther", "Andrej Ceglar", "Andrea Toreti", "Elena Xoplaki"], "title": "Surrogate impact modelling for crop yield assessment", "comment": null, "summary": "This study presents the Surrogate Engine for Crop Simulations (SECS) a group of deep-learning models that emulate the process-based ECroPS model using only daily maximum and minimum temperature and precipitation. In this study we emulate grain maize and spring barley. Trained on ERA5-forced ECroPS simulations, SECS reproduces crop growth dynamics and harvest timing with high fidelity. Critically, SECS extremely reduces computational costs enabling ensemble-scale inference suitable for operational pipelines. When driven by seasonal data, SECS captures the interannual and spatial patterns of crop stress across Europe and aligns with independent monitoring, supporting its use as a probabilistic Areas of Concern indicator for early warning. Under CMIP6 SSP3-7.0 and SSP5-8.5 scenarios, SECS consistently identifies the Mediterranean basin as a persistent hotspot of yield risk through mid-century, with central-northern Europe showing mixed signals. These results demonstrate that a streamlined, data-efficient emulator can provide robust seasonal-to-climate risk assessments at continental scale."}
{"id": "2602.20552", "categories": ["math.OC", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2602.20552", "abs": "https://arxiv.org/abs/2602.20552", "authors": ["Xinman Cheng", "Guanxing Fu", "Xiaonyu Xia"], "title": "Stochastic Control Problems with Infinite Horizon and Regime Switching Arising in Optimal Liquidation with Semimartingale Strategies", "comment": null, "summary": "We study an optimal control problem on infinite time horizon with semimartingale strategies, random coefficients and regime switching. The value function and the optimal strategy can be characterized in terms of three systems of backward stochastic differential equations (BSDEs) with infinite horizon. One of them is a system of linear BSDEs with unbounded coefficients and infinite horizon, which seems to be new in literature. We establish the existence of the solutions to these BSDEs by BMO analysis and comparison theorem for multi-dimensional BSDEs. Next, we establish that the optimal control problem is well posed, in the sense that the value function is finite and the optimal strategy-when it exists-is unique. This is achieved by reformulating the cost functional as the sum of a quadratic functional and the candidate value function. The reformulation crucially relies on the well-established well-posedness results for systems of BSDEs. Finally, under additional assumptions, we obtain the unique optimal strategy."}
{"id": "2602.20238", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20238", "abs": "https://arxiv.org/abs/2602.20238", "authors": ["Satoshi Yoshida", "Ethan Lake", "Hayata Yamasaki"], "title": "Proof of a finite threshold for the union-find decoder", "comment": "20 pages, 6 figures", "summary": "Fast decoders that achieve strong error suppression are essential for fault-tolerant quantum computation (FTQC) from both practical and theoretical perspectives. The union-find (UF) decoder for the surface code is widely regarded as a promising candidate, offering almost-linear time complexity and favorable empirical error suppression supported by numerical evidence. However, the lack of a rigorous threshold theorem has left open whether the UF decoder can achieve fault tolerance beyond the error models and parameter regimes tested in numerical simulations. Here, we provide a rigorous proof of a finite threshold for the UF decoder on the surface code under the circuit-level local stochastic error model. To this end, we develop a refined error-clustering framework that extends techniques previously used to analyze cellular-automaton and renormalization-group decoders, by showing that error clusters can be separated by substantially larger buffers, thereby enabling analytical control over the behavior of the UF decoder. Using this guarantee, we further prove a quasi-polylogarithmic upper bound on the average runtime of a parallel UF decoder in terms of the code size. We also show that this framework yields a finite threshold for the greedy decoder, a simpler decoder with lower complexity but weaker empirical error suppression. These results provide a solid theoretical foundation for the practical use of UF-based decoders in the development of fault-tolerant quantum computers, while offering a unified framework for studying fault tolerance across these practical decoders."}
{"id": "2602.20679", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.20679", "abs": "https://arxiv.org/abs/2602.20679", "authors": ["Andreu Martorell", "Pep Mulet", "Dionisio F. Yáñez"], "title": "Implicit-explicit all-speed schemes for compressible Cahn-Hilliard-Navier-Stokes equations", "comment": null, "summary": "We propose a second-order implicit-explicit (IMEX) time-stepping scheme for the isentropic, compressible Cahn-Hilliard-Navier-Stokes equations in the low Mach number regime.\n  The method is based on finite differences on staggered grids and is specifically designed to handle the challenges posed by the low Mach number limit, where the system approaches to an incompressible behavior.\n  In this regime, standard explicit schemes suffer from severe time-step restrictions due to fourth-order diffusion terms and the stiffness induced by fast acoustic waves.\n  To overcome this, we employ an IMEX strategy which splits the governing equations into stiff and non-stiff components.\n  The stiff terms, arising from pressure, viscous forces and fourth-order Cahn-Hilliard contributions, are treated implicitly, while the remaining are dealt explicitly."}
{"id": "2602.20814", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.20814", "abs": "https://arxiv.org/abs/2602.20814", "authors": ["Dmitry M. Korotin", "Anna A. Anisimova", "Vladimir I. Anisimov"], "title": "Parameterizing DFT+U+V from Hybrid Functionals: A Wannier-Function-Based Approach for Strongly Correlated Materials", "comment": null, "summary": "We present an approach to parameterize DFT+$U$+$V$ from hybrid-functional calculations using Wannier-function projections. The method constructs a common localized Wannier basis for both semilocal DFT and hybrid-functional calculations, then determines effective on-site ($U$) and intersite ($V$) Hubbard parameters by minimizing the Hamiltonian mismatch within the correlated subspace. This procedure yields interaction parameters that reproduce the hybrid-functional electronic structure at a fraction of the computational cost and allow efficient structural relaxations and further many-body calculations. We validate the workflow on three oxide systems with different electronic characters: MgO (wide-gap insulator), NiO (antiferromagnetic charge-transfer insulator), and V$_2$O$_5$ (d$^0$ transition-metal oxide). In all cases, the mapped DFT+$U$+$V$ parameters reproduce hybrid-functional band gaps, densities of states, and magnetic moments and improve upon semilocal DFT while maintaining computational efficiency."}
{"id": "2602.20897", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.20897", "abs": "https://arxiv.org/abs/2602.20897", "authors": ["Samuel Martin-Gutierrez", "Juan C. Losada", "Rosa M. Benito"], "title": "Impact of individual actions on the collective response of social systems", "comment": null, "summary": "In a social system individual actions have the potential to trigger spontaneous collective reactions. The way and extent to which the activity (number of actions$-A$) of an individual causes or is connected to the response (number of reactions$-R$) of the system is still an open question. We measure the relationship between activity and response with the distribution of efficiency, a metric defined as $η=R/A$. Generalizing previous results, we show that the efficiency distribution presents a universal structure in three systems of different nature: Twitter, Wikipedia and the scientific citations network. To understand this phenomenon, we develop a theoretical framework composed of three minimal statistical models that contemplate different levels of dependence between $A$ and $R$. The models not only are able to reproduce the empirical activity-response data but also can serve as baselines or null models for more elaborated and domain-specific approaches."}
{"id": "2602.20842", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.20842", "abs": "https://arxiv.org/abs/2602.20842", "authors": ["Marvin Dorn", "Julian Hoffmann", "André Weber", "Veit Hagenmeyer"], "title": "Fast-Response Balancing Capacity of Alkaline Electrolyzers", "comment": null, "summary": "The energy transition requires flexible technologies to maintain grid stability, and electrolyzers are playing an increasingly important role in meeting this need. While previous studies often question the dynamic capabilities of large-scale alkaline electrolyzer systems, we assess their potential to provide balancing services using real manufacturer data. Unlike common approaches, we propose the decoupling between the total electrolyzer power and a smaller fractions of power actually offered on balancing markets. Adapting an existing methodology, we analyze alkaline electrolyzer systems and extend the assessment to Germany and Europe. Our results show that large-scale electrolyzers are technically capable of delivering fast-response balancing services, with significantly lower dynamic requirements than previously assumed. The planned electrolyzers in Germany could cover the entire balancing capacity market, potentially saving around 13 % of their electricity costs, excluding energy balancing revenues. The decoupling also resolves part of the trade-off for electrolyzer manufacturers, enabling the design of less dynamic but more stable systems."}
{"id": "2602.20503", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.20503", "abs": "https://arxiv.org/abs/2602.20503", "authors": ["Yui Kimura", "Shu Tamano"], "title": "Error-Controlled Borrowing from External Data Using Wasserstein Ambiguity Sets", "comment": null, "summary": "Incorporating external data can improve the efficiency of clinical trials, but distributional mismatches between current and external populations threaten the validity of inference. While numerous dynamic borrowing methods exist, the calibration of their borrowing parameters relies mainly on ad hoc, simulation-based tuning. To overcome this, we propose BOND (Borrowing under Optimal Nonparametric Distributional robustness), a framework that formalizes data noncommensurability through Wasserstein ambiguity sets centered at the current-trial distribution. By deriving sharp, closed-form bounds on the worst-case mean drift for both continuous and binary outcomes, we construct a distributionally robust, bias-corrected Wald statistic that ensures asymptotic type I error control uniformly over the ambiguity set. Importantly, BOND determines the optimal borrowing strength by maximizing a worst-case power proxy, converting heuristic parameter tuning into a transparent, analytically tractable optimization problem. Furthermore, we demonstrate that many prominent borrowing methods can be reparameterized via an effective borrowing weight, rendering our calibration framework broadly applicable. Simulation studies and a real-world clinical trial application confirm that BOND preserves the nominal size under unmeasured heterogeneity while achieving efficiency gains over standard borrowing methods."}
{"id": "2602.20579", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.20579", "abs": "https://arxiv.org/abs/2602.20579", "authors": ["A. Saravanan", "I. Iyyappan"], "title": "Fluctuation theorems for a non-Gaussian system", "comment": "Comments are welcome", "summary": "In this work, we numerically verify the Jarzynski equality and Crook fluctuation theorem for a Brownian particle diffusing in a heterogeneous thermal bath and hence having a non-Gaussian position distribution. We use the diffusing-diffusivity model to take the account of heterogeneity of the thermal bath where the mobility is considered as a fluctuating quantity. The Brownian particle is confined by a time-dependent harmonic potential. By changing the stiffness coefficient, we perform an isothermal process. We use the stochastic thermodynamics framework to calculate the work. We find that the Jarzynski equality and the Crook fluctuation theorem are convincingly satisfied for a non-Gaussion system. We also find that the work distribution is non-Gaussian for diffusing-diffusivity system even at a larger process time."}
{"id": "2602.20815", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.20815", "abs": "https://arxiv.org/abs/2602.20815", "authors": ["Nils Lid Hjort", "Nikolai G. Ushakov"], "title": "Upper Bounds for the I-MSE and max-MSE of Kernel Density Estimators", "comment": "21 pages, 0 figures. Statistical Research Report, Department of Mathematics, University of Oslo, from December 1999, but arXiv'd in February 2026", "summary": "The performance of kernel density estimators is usually studied via Taylor expansions and asymptotic approximation arguments, in which the bandwidth parameter tends to zero with increasing sample size. In contrast, this paper focusses directly on the finite-sample situation. Informative upper bounds are derived both for the integrated and the maximal mean squared error function. Results are reached for the traditional case, where the kernel is a probability density function, under various sets of assumptions on the underlying density to be estimated. Results are also derived for the important non-conventional case of the sinc kernel, which is not integrable and also takes negative values. We pin-point ways in which the sinc-based estimator performs better than the conventional kernel estimators. When proving our results we rely on methods related to characteristic and empirical characteristic functions."}
{"id": "2602.20970", "categories": ["hep-lat", "gr-qc", "hep-ph", "hep-th", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.20970", "abs": "https://arxiv.org/abs/2602.20970", "authors": ["Viktor Braguta", "Vladimir Goy", "Jayanta Dey", "Artem Roenko"], "title": "Spatial confinement-deconfinement transition in accelerated gluodynamics within lattice simulation", "comment": "24 pages, 16 figures", "summary": "In this work we investigate the influence of weak acceleration on the confinement-deconfinement phase transition in gluodynamics. Our study is carried out within lattice simulation in the comoving reference frame of accelerated observer which is parameterized by the Rindler coordinates. We find that finite temperature confinement-deconfinement phase transition turns into spatial crossover in the Rindler spacetime. In other words, spatially separated confinement and deconfinement phases can coexist in the Rindler spacetime within certain intervals of temperature and acceleration. We determine the position of the boundary between the phases as a function of temperature for several accelerations and find that it can be described by the Tolman-Ehrenfest law with rather good accuracy although a minor deviation takes place. Moreover, the critical temperature of the system in the weak acceleration regime is found to remain unchanged as that of the standard homogeneous gluodynamics. Our results imply that the spatial confinement-deconfinement transition might take place in the vicinity of the Schwarzschild black hole horizon."}
{"id": "2602.21090", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21090", "abs": "https://arxiv.org/abs/2602.21090", "authors": ["Alexander J Gallo", "Massimiliano Zoggia", "Alessandro Falsone", "Maria Prandini", "Simone Garatti"], "title": "Robustness certificates in data-driven non-convex optimization with additively-uncertain constraints", "comment": "11 pages, 8 figures. The manuscript has been submitted to the IEEE Transactions on Automatic Control for possible publication", "summary": "We consider decision-making problems that are formulated as non-convex optimization programs where uncertainty enters the constraints through an additive term, independent of the decision variables, and robustness is imposed using a finite data-set, according to the scenario robust optimization paradigm. By exploiting the structure of the constraints, we show that both a priori and a posteriori distribution-free probabilistic robustness certificates for a possibly sub-optimal solution to the resulting data-driven optimization problem can be obtained with minimal computational effort. Building on these results, we also discuss a one-shot and an incremental procedure to determine the size of the data-set so as to guarantee a user-chosen robustness level. Notably, both the a posteriori robustness assessment and incremental data-set sizing do not require to solve the non-convex scenario program. A comparative analysis performed on the unit commitment problem using real data reveals a limited increase in conservativeness with a significant computational saving with respect to the application of scenario theory results for general, non necessarily structured, non-convex problems."}
{"id": "2602.20646", "categories": ["math.OC", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20646", "abs": "https://arxiv.org/abs/2602.20646", "authors": ["Boao Kong", "Hengrui Zhang", "Kun Yuan"], "title": "On the Convergence of Stochastic Gradient Descent with Perturbed Forward-Backward Passes", "comment": "34 pages", "summary": "We study stochastic gradient descent (SGD) for composite optimization problems with $N$ sequential operators subject to perturbations in both the forward and backward passes. Unlike classical analyses that treat gradient noise as additive and localized, perturbations to intermediate outputs and gradients cascade through the computational graph, compounding geometrically with the number of operators. We present the first comprehensive theoretical analysis of this setting. Specifically, we characterize how forward and backward perturbations propagate and amplify within a single gradient step, derive convergence guarantees for both general non-convex objectives and functions satisfying the Polyak--Łojasiewicz condition, and identify conditions under which perturbations do not deteriorate the asymptotic convergence order. As a byproduct, our analysis furnishes a theoretical explanation for the gradient spiking phenomenon widely observed in deep learning, precisely characterizing the conditions under which training recovers from spikes or diverges. Experiments on logistic regression with convex and non-convex regularization validate our theories, illustrating the predicted spike behavior and the asymmetric sensitivity to forward versus backward perturbations."}
{"id": "2602.20269", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20269", "abs": "https://arxiv.org/abs/2602.20269", "authors": ["Mert Esencan", "A. I. Lvovsky", "Berislav Buča"], "title": "Time Crystals as Passively Protected Oscillating Qubits", "comment": "5 pages, 5 figures. Supplemental material included", "summary": "Protecting information against decoherence in open quantum systems remains a central challenge for quantum computing. In particular, passive error correction schemes have so far been limited to static memories rather than dynamical qubits. We demonstrate that a driven-dissipative bosonic system can encode a persistently oscillating qubit within a noiseless subsystem, realized explicitly in the Bose-Hubbard dimer (BHD). The strong parity symmetry of the model leads to degenerate stationary states. This symmetry is further broken into non-stationary states in the thermodynamic limit, which exhibit persistent oscillations. As the driving force increases, the Liouvillian spectrum of these states features a phase transition. Above the transition point, the non-stationary state encodes quantum information, preserving it in a noiseless subsystem. In addition to global loss that affects both bosonic modes identically, we further add global dephasing and show that the oscillating qubit is preserved. Finally, in order to gain additional physical insight, we study the effect of phase perturbation to both modes and observe that likewise they are passively protected, returning approximately to their initial configurations. These results establish dissipative time-crystalline dynamics as a mechanism for passive protection of dynamical quantum information, enabling autonomously stabilized oscillating qubits."}
{"id": "2602.20697", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.20697", "abs": "https://arxiv.org/abs/2602.20697", "authors": ["Vladimír Lukeš", "Eduard Rohan"], "title": "Reduced-order computational homogenization for hyperelastic media using gradient based sensitivity analysis of microstructures", "comment": null, "summary": "We propose an algorithm for the computational homogenization of locally periodic hyperelastic structures undergoing large deformations due to external quasi-static loading. The algorithm performs clustering of macroscopic deformations into subsets called \"centroids\", and, as a new ingredient, approximates the homogenized coefficients using sensitivity analysis of micro-configurations with respect to the macroscopic deformation. The novel \"model-order reduction\" approach significantly reduces the number of microscopic problems that must be solved in nonlinear simulations, thereby accelerating the overall computational process. The degree of reduction can be controlled by a user-defined error tolerance parameter. The algorithm is implemented in the finite element framework SfePy, and its performance effectiveness is demonstrated using two-dimensional test examples, when compared with solutions obtained by the proper orthogonal decomposition method, and by the full \"FE-square\" simulations. Extensions beyond the present implementations and the scope of tractable problems are discussed."}
{"id": "2602.20990", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.20990", "abs": "https://arxiv.org/abs/2602.20990", "authors": ["Min-Chul Cha", "Hoon Beom Kwon", "Ji-Woo Lee", "Myung-Hoon Chung"], "title": "Entanglement Properties of the One-Dimensional Dimerized Fermi-Hubbard Model", "comment": "6 pages and 5 figures", "summary": "We study the entanglement properties of the one-dimensional dimerized Fermi-Hubbard model. Using a matrix-product-state approach, we compute the ground state and identify two insulating phases at 1/2- and 3/4-filling, along with a metallic phase, whose mechanisms can be characterized by their entanglement spectra. Our findings indicate that the two insulating phases are distinct, implying that the phase at 1/2-filling has a charge gap arising from the band gap, which is enhanced by repulsive interactions, while the phase at 3/4-filling exhibits a Mott gap resulting from particle interactions. This difference between the two insulating phases is reflected in the scaling properties of the half-chain entanglement entropy and the distribution of the entanglement spectrum."}
{"id": "2602.20936", "categories": ["physics.soc-ph", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2602.20936", "abs": "https://arxiv.org/abs/2602.20936", "authors": ["Albarracin Mahault", "Mikeda Anna", "Jimenez Rodriguez Alejandro", "Namjoshi Sanjeev", "Sakthivadivel Dalton", "Pae Hongju", "Shah Harshil", "Wilson Philip"], "title": "Empathy Modeling in Active Inference Agents for Perspective-Taking and Alignment", "comment": null, "summary": "Artificial agents capable of understanding and aligning with others' intentions are essential for safe and socially robust artificial intelligence. We introduce a computational framework for empathy in active inference agents, grounded in explicit perspective-taking via self-other model transformation.\n  We instantiate this framework in a multi-agent Iterated Prisoner's Dilemma and show that empathic perspective-taking induces robust cooperation without explicit communication or reward shaping. Cooperation emerges only when empathy is reciprocated, while asymmetric empathy leads to systematic exploitation. Beyond equilibrium outcomes, empathic agents exhibit synchronized behavior, rapid recovery from stochastic defections, and joint intentional dynamics resembling apology-forgiveness cycles. Near empathy symmetry, interactions display long transients and elevated variance, consistent with critical dynamics near regime boundaries.\n  We further examine a learning-enabled variant in which agents infer opponent type via Bayesian updating. While opponent models converge rapidly, long-run cooperation remains primarily determined by the empathy parameter, indicating that cooperation is driven by empathic structure rather than learned reciprocity. Empathy functions as a structural prior over social interaction, shaping coordination stability, robustness, and temporal dynamics. The proposed framework highlights active inference as a principled foundation for socially aligned artificial agents that coordinate through internal simulation rather than behavioral mimicry."}
{"id": "2602.21113", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21113", "abs": "https://arxiv.org/abs/2602.21113", "authors": ["Huy Trinh"], "title": "A Survey of Recent Developments in SYCL Compiler Implementations", "comment": null, "summary": "This survey discusses recent advancements in SYCL compiler implementations, one of the crucial aspects of compiler construction for heterogeneous computing systems. We explore the transition from traditional compiler construction, from Single-Source Multiple Compiler Passes (SMCP) to a more advanced approach to Single-Source Single Compiler Pass (SSCP). The survey analyzes multiple papers that researched the different developments of SYCL implementation based on SSCP and their approach to enhancing performance and addressing separate challenges."}
{"id": "2602.20572", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.20572", "abs": "https://arxiv.org/abs/2602.20572", "authors": ["Chang Jun Im", "Jeong Min Jeon"], "title": "Local Fréchet regression with toroidal predictors", "comment": "52 pages, 1 figure. Submitted to Scandinavian Journal of Statistics", "summary": "We provide the first regression framework that simultaneously accommodates responses taking values in a general metric space and predictors lying on a general torus. We propose intrinsic local constant and local linear estimators that respect the underlying geometries of both the response and predictor spaces. Our local linear estimator is novel even in the case of scalar responses. We further establish their asymptotic properties, including consistency and convergence rates. Simulation studies, together with an application to real data, illustrate the superior performance of the proposed methodology."}
{"id": "2602.21003", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.21003", "abs": "https://arxiv.org/abs/2602.21003", "authors": ["Loris Di Cairano"], "title": "Criticality Beyond Nonanalyticity: Intrinsic Microcanonical Signatures of Phase Transitions", "comment": null, "summary": "Phase transitions are conventionally defined by nonanalyticities of thermodynamic potentials in the thermodynamic limit. In this Letter, we show that the singularity is not the definition of criticality but its asymptotic outcome: criticality is already written in the microcanonical entropy derivatives at any finite size as intrinsic morphological structures -- inflection points and extrema. The singularity is then the endpoint of a sharpening process that evolves with increasing system size. Combining microcanonical inflection-point analysis (MIPA) with the Berlin-Kac spherical model -- for which the microcanonical density of states is known in closed form at every finite $N$ -- we systematically identify these structures in the energy profiles of entropy derivatives that encode the transition. An inflection point in the inverse temperature $β_N(ε)=\\partial_εS_N$ and a pronounced peak in its derivative $γ_N(ε)=\\partial^2_εS_N$ define a well-controlled pseudocritical trajectory whose controlled sharpening and drift culminate in the macroscopic cusp at the critical energy $ε_c$ in the thermodynamic limit. This establishes an intrinsic, order-parameter-free notion of criticality that precedes its singular asymptotic representation."}
{"id": "2602.20844", "categories": ["math.ST", "cs.IT", "math.PR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20844", "abs": "https://arxiv.org/abs/2602.20844", "authors": ["Subhrosekhar Ghosh", "Rathindra Nath Karmakar", "Samriddha Lahiry"], "title": "Maximum entropy based testing in network models: ERGMs and constrained optimization", "comment": null, "summary": "Stochastic network models play a central role across a wide range of scientific disciplines, and questions of statistical inference arise naturally in this context. In this paper we investigate goodness-of-fit and two-sample testing procedures for statistical networks based on the principle of maximum entropy (MaxEnt). Our approach formulates a constrained entropy-maximization problem on the space of networks, subject to prescribed structural constraints. The resulting test statistics are defined through the Lagrange multipliers associated with the constrained optimization problem, which, to our knowledge, is novel in the statistical networks literature.\n  We establish consistency in the classical regime where the number of vertices is fixed. We then consider asymptotic regimes in which the graph size grows with the sample size, developing tests for both dense and sparse settings. In the dense case, we analyze exponential random graph models (ERGM) (including the Erdös-Rènyi models), while in the sparse regime our theory applies to Erd{ö}s-R{è}nyi graphs.\n  Our analysis leverages recent advances in nonlinear large deviation theory for random graphs. We further show that the proposed Lagrange-multiplier framework connects naturally to classical score tests for constrained maximum likelihood estimation. The results provide a unified entropy-based framework for network model assessment across diverse growth regimes."}
{"id": "2602.21145", "categories": ["hep-lat", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21145", "abs": "https://arxiv.org/abs/2602.21145", "authors": ["Marko Maležič", "Johann Ostmeyer"], "title": "Reducing the Gate Count with Efficient Trotter-Suzuki Schemes", "comment": "10 pages, 3 figures, 3 tables and 1 algorithm - Proceedings of the 42nd International Symposium on Lattice Field Theory (Lattice 2025), TIFR Mumbai, India, 2025", "summary": "Hamiltonian formulations of lattice field theories provide access to real-time dynamics, but their simulation is difficult to implement efficiently. Trotter-Suzuki decompositions are at the center of time evolution computation, either on quantum hardware or classically, for instance with the use of tensor networks. While low-order Trotterizations remain the standard choice due to their simplicity, higher-order schemes offer the potential for improved efficiency. In this work we outline a short guide to Trotter-Suzuki schemes and their implementations in general. To help with this, we highlight new efficient schemes found by our optimization framework, and demonstrate their performance on the Heisenberg model."}
{"id": "2602.20660", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.20660", "abs": "https://arxiv.org/abs/2602.20660", "authors": ["N. D. Dizon", "Q. Y. Huang", "T. D. Chuong", "G. Li", "V. Jeyakumar"], "title": "Convergent Lifted Lasserre Hierarchy of SDPs for Minimizing Expectation of Piecewise Polynomial Loss over Wasserstein Balls", "comment": null, "summary": "This paper investigates the minimization of the expectation of piecewise polynomial loss functions over Wasserstein balls. This optimization problem often appears as a key sub-problem of distributionally robust optimization problems. We establish the asymptotic convergence of a hierarchy of semi-definite programming (SDP) relaxations, providing a framework for approximating the optimal values of these inherently infinite-dimensional optimization problems. A central foundational contribution is the development of a new lifted positivity certificate: we demonstrate that piecewise polynomials positive over Archimedean basic semi-algebraic sets admit a structured system of sum-of-squares (SOS) representations. Furthermore, we prove that the proposed hierarchy achieves finite convergence under suitable conditions when the defining polynomials are convex. The practical utility and versatility of this approach are demonstrated via numerical experiments in revenue estimation and portfolio optimization."}
{"id": "2602.20270", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20270", "abs": "https://arxiv.org/abs/2602.20270", "authors": ["Ignacio Loaiza", "Alexander Kunitsa", "Stepan Fomichev", "Danial Motlagh", "Diksha Dhawan", "Soran Jahangiri", "Juliane Holst Fuglsbjerg", "Artur Izmaylov", "Nathan Wiebe", "Yaser Abu-Lebdeh", "Juan Miguel Arrazola", "Alain Delgado"], "title": "Quantum algorithm for simulating resonant inelastic X-ray scattering in battery materials", "comment": "18 pages, 12 figures, 2 tables", "summary": "Resonant inelastic X-ray scattering (RIXS) is the workhorse experimental technique for probing the structural degradation of higher-capacity cathode materials. However, the interpretation of experimental spectra is challenging due to the lack of accurate simulations. In this work, we propose a quantum algorithm for simulating the RIXS spectrum of molecular clusters hypothesized to form in Li-excess cathodes. The algorithm uses quantum phase estimation to sample the spectrum from a state encoding the scattering transition amplitudes of the cluster valence excitations. We prepare this state in the quantum computer using a block-encoding of the dipole operator and quantum signal processing to implement the Green's function propagator over intermediate core-excited states. To showcase the algorithm, we use a model cluster proposed in recent experimental works consisting of an oxygen dimer bonded to a manganese atom. Using the PennyLane software platform, we report resource estimation for simulating RIXS spectra for chemically motivated active spaces of increasing sizes. For a classically challenging active space with 20 orbitals, the algorithm requires $2.0 \\times 10^{10}$ Toffoli gates and $414$ logical qubits."}
{"id": "2602.20719", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.20719", "abs": "https://arxiv.org/abs/2602.20719", "authors": ["Peiyao Zhao", "Rui Wang", "Tingting Wu", "Yuesheng Xu"], "title": "The Adaptive Solution of High-Frequency Helmholtz Equations via Multi-Grade Deep Learning", "comment": null, "summary": "The Helmholtz equation is fundamental to wave modeling in acoustics, electromagnetics, and seismic imaging, yet high-frequency regimes remain challenging due to the ``pollution effect''. We propose FD-MGDL, an adaptive framework integrating finite difference schemes with Multi-Grade Deep Learning to efficiently resolve high-frequency solutions. While traditional PINNs struggle with spectral bias and automatic differentiation overhead, FD-MGDL employs a progressive training strategy, incrementally adding hidden layers to refine the solution and maintain stability. Crucially, when using ReLU activation, our algorithm recasts the highly non-convex training problem into a sequence of convex subproblems. Numerical experiments in 2D and 3D with wavenumbers up to $κ=200$ show that FD-MGDL significantly outperforms single-grade and conventional neural solvers in accuracy and speed. Applied to an inhomogeneous concave velocity model, the framework accurately resolves wave focusing and caustics, surpassing the 5-point finite difference method in capturing sharp phase transitions and amplitude spikes. These results establish FD-MGDL as a robust, scalable solver for high-frequency wave equations in complex domains."}
{"id": "2602.21086", "categories": ["cond-mat.str-el", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.21086", "abs": "https://arxiv.org/abs/2602.21086", "authors": ["Maksymilian Kliczkowski", "Jakub Grabowski", "Maciej M. Maśka"], "title": "Probing frustrated spin systems with impurities", "comment": null, "summary": "We investigate the effective interaction between two localized spin impurities embedded in a frustrated spin-1/2 $J_1\\!-\\!J_2$ Heisenberg chain. Treating the impurity spins as classical moments coupled locally to the host, we combine second--order perturbation theory with large--scale density matrix renormalization group (DMRG) calculations to determine the impurity--impurity interaction as a function of separation, coupling strength, and magnetic frustration. In the weak--coupling regime, we show that the interaction is governed by the the static spin susceptibility of the host and exhibits oscillatory power--law decay in the gapless phase, modified by universal logarithmic corrections at the SU(2)--symmetric critical point. In the gapped dimerized phase, the interaction decays exponentially with distance. For intermediate and strong impurity--host coupling, we observe a crossover to a boundary--dominated regime characterized by pronounced parity effects associated with the length of the chain segment between impurities, signaling a breakdown of the simple RKKY--like description. Our results establish impurity--impurity interactions as a sensitive probe of frustrated quantum spin liquids and provide a controlled framework for distinguishing gapless and gapped phases through local perturbations."}
{"id": "2602.21155", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21155", "abs": "https://arxiv.org/abs/2602.21155", "authors": ["Sanchita Ghosh", "Tanushree Roy"], "title": "KAN-Koopman Based Rapid Detection Of Battery Thermal Anomalies With Diagnostics Guarantees", "comment": "10 pages, 2 figures, Accepted to The 2026 American Control Conference", "summary": "Early diagnosis of battery thermal anomalies is crucial to ensure safe and reliable battery operation by preventing catastrophic thermal failures. Battery diagnostics primarily rely on battery surface temperature measurements and/or estimation of core temperatures. However, aging-induced changes in the battery model and limited training data remain major challenges for model-based and machine-learning based battery state estimation and diagnostics. To address these issues, we propose a Kolomogorov-Arnold network (KAN) in conjunction with a Koopman-based detection algorithm that leverages the unique advantages of both methods. Firstly, the lightweight KAN provides a model-free estimation of the core temperature to ensure rapid detection of battery thermal anomalies. Secondly, the Koopman operator is learned in real time using the estimated core temperature from KAN and the measured surface temperature of the battery to provide a prediction for diagnostic residual generation. This online learning approach overcomes the challenges of model changes, while the integrated structure reduces the dependence on large datasets. Furthermore, we derive analytical conditions that provide diagnostic guarantees on our KAN-Koopman detection scheme. Our simulation results illustrate a significant reduction in detection time with the proposed algorithm compared to the baseline Koopman-only algorithm."}
{"id": "2602.20795", "categories": ["stat.ME", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.20795", "abs": "https://arxiv.org/abs/2602.20795", "authors": ["Xinhui Rong", "Girish N. Nair"], "title": "Hawkes Identification with a Prescribed Causal Basis: Closed-Form Estimators and Asymptotics", "comment": "21 pages, 4 figures", "summary": "Driven by the recent surge in neural-inspired modeling, point processes have gained significant traction in systems and control. While the Hawkes process is the standard model for characterizing random event sequences with memory, identifying its unknown kernels is often hindered by nonlinearity. Approaches using prescribed basis kernels have emerged to enable linear parameterization, yet they typically rely on iterative likelihood methods and lack rigorous analysis under model misspecification. This paper justifies a closed-form Least Squares identification framework for Hawkes processes with prescribed kernels. We guarantee estimator existence via the almost-sure positive definiteness of the empirical Gram matrix and prove convergence to the true parameters under correct specification, or to well-defined pseudo-true parameters under misspecification. Furthermore, we derive explicit Central Limit Theorems for both regimes, providing a complete and interpretable asymptotic theory. We demonstrate these theoretical findings through comparative numerical simulations."}
{"id": "2602.20299", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.20299", "abs": "https://arxiv.org/abs/2602.20299", "authors": ["Tim Pokart", "Frank Pollmann", "Jan Carl Budich"], "title": "Entanglement Barriers from Computational Complexity: Matrix-Product-State Approach to Satisfiability", "comment": "17 pages, 12 figures", "summary": "We approach the 3-SAT satisfiability problem with the quantum-inspired method of imaginary time propagation (ITP) applied to matrix product states (MPS) on a classical computer. This ansatz is fundamentally limited by a quantum entanglement barrier that emerges in imaginary time, reflecting the exponential hardness expected for this NP-complete problem. Strikingly, we argue based on careful analysis of the structure imprinted onto the MPS by the 3-SAT instances that this barrier arises from classical computational complexity. To reveal this connection, we elucidate with stochastic models the specific relationship between the classical hardness of the $\\sharp$P $\\supseteq$ NP-complete counting problem $\\sharp$3-SAT and the entanglement properties of the quantum state. Our findings illuminate the limitations of this quantum-inspired approach and demonstrate how purely classical computational complexity can manifest in quantum entanglement. Furthermore, we present estimates of the non-stabilizerness required by the protocol, finding a similar resource barrier. Specifically, the necessary amount of non-Clifford operations scales superlinearly in system size, thus implying extensive resource requirements of ITP on different architectures such as Clifford circuits or gate-based quantum computers."}
{"id": "2602.20875", "categories": ["math.ST", "math.OC", "math.PR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20875", "abs": "https://arxiv.org/abs/2602.20875", "authors": ["Louis Sharrock", "Nikolas Kantas", "Grigorios A. Pavliotis"], "title": "Efficient Online Learning in Interacting Particle Systems", "comment": null, "summary": "We introduce a new method for online parameter estimation in stochastic interacting particle systems, based on continuous observation of a small number of particles from the system. Our method recursively updates the model parameters using a stochastic approximation of the gradient of the asymptotic log likelihood, which is computed using the continuous stream of observations. Under suitable assumptions, we rigorously establish convergence of our method to the stationary points of the asymptotic log-likelihood of the interacting particle system. We consider asymptotics both in the limit as the time horizon $t\\rightarrow\\infty$, for a fixed and finite number of particles, and in the joint limit as the number of particles $N\\rightarrow\\infty$ and the time horizon $t\\rightarrow\\infty$. Under additional assumptions on the asymptotic log-likelihood, we also establish an $\\mathrm{L}^2$ convergence rate and a central limit theorem. Finally, we present several numerical examples of practical interest, including a model for systemic risk, a model of interacting FitzHugh--Nagumo neurons, and a Cucker--Smale flocking model. Our numerical results corroborate our theoretical results, and also suggest that our estimator is effective even in cases where the assumptions required for our theoretical analysis do not hold."}
{"id": "2602.20793", "categories": ["math.OC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.20793", "abs": "https://arxiv.org/abs/2602.20793", "authors": ["Isaac Rudich", "Louis-Martin Rousseau"], "title": "Implicit Decision Diagrams", "comment": "27 pages, 9 figures, 7 algorithms", "summary": "Decision Diagrams (DDs) have emerged as a powerful tool for discrete optimization, with rapidly growing adoption. DDs are directed acyclic layered graphs; restricted DDs are a generalized greedy heuristic for finding feasible solutions, and relaxed DDs compute combinatorial relaxed bounds. There is substantial theory that leverages DD-based bounding, yet the complexity of constructing the DDs themselves has received little attention. Standard restricted DD construction requires $O(w \\log(w))$ per layer; standard relaxed DD construction requires $O(w^2)$, where $w$ is the width of the DD. Increasing $w$ improves bound quality at the cost of more time and memory.\n  We introduce implicit Decision Diagrams, storing arcs implicitly rather than explicitly, and reducing per-layer complexity to $O(w)$ for restricted and relaxed DDs. We prove this is optimal: any framework treating state-update and merge operations as black boxes cannot do better.\n  Optimal complexity shifts the challenge from algorithmic overhead to low-level engineering. We show how implicit DDs can drive a MIP solver, and release ImplicitDDs.jl, an open-source Julia solver exploiting the implementation refinements our theory enables. Experiments demonstrate the solver outperforms Gurobi on Subset Sum."}
{"id": "2602.20275", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20275", "abs": "https://arxiv.org/abs/2602.20275", "authors": ["K. De La Ossa Doria", "T. Merlo Vergara", "D. Goyeneche"], "title": "Pulse-level control for quantum resource preparation", "comment": "12 pages, 21 figures", "summary": "Minimizing the time required for quantum state preparation is crucial to mitigate decoherence and enable practical quantum algorithms on near-term hardware. In this work, we introduce a technique for quantum state preparation in transmon-qubit systems using optimized electromagnetic pulse sequences rather than discrete quantum gates. By directly targeting quantum correlations instead of specific target states, we identify minimal-time pulse protocols that optimize relevant entanglement resources, such as concurrence and the three-tangle for two and three qubit systems, respectively. For the figures of merit considered, this approach successfully achieves maximal entanglement in each case: Bell, GHZ and W like states. Beyond state preparation, the resource-oriented nature of the approach leads to a reduced effective expressivity of the control scheme, a feature that represents an advantage in algorithmic settings where excessive control freedom is known to hinder performance."}
{"id": "2602.20820", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.20820", "abs": "https://arxiv.org/abs/2602.20820", "authors": ["Wei Liu", "Tingfeng Wang", "Xiaofei Zhao"], "title": "Convergence analysis of $L^{p+1}$-normalized gradient flow for action ground state of nonlinear Schrödinger equation", "comment": "22 pages", "summary": "This paper presents a rigorous convergence analysis of the $L^{p+1}$-normalized gradient flow with asymptotic Lagrange multiplier (GFALM) method for computing the action ground state of the nonlinear Schrödinger equation in the focusing case. First, a general global convergence theory is established for the semi-discrete GFALM scheme, guaranteeing the existence of an accumulation point and a convergent subsequence. Then, under additional non-degeneracy assumptions, a local exponential convergence rate is rigorously proven. This result is further extended to the fully discrete case using a Fourier pseudo-spectral discretization. The analysis is achieved by characterizing the local geometry of the $L^{p+1}$-constrained manifold near the ground state, establishing a quadratic growth property of the energy functional, and deriving a Łojasiewicz-type gradient inequality. Finally, the paper also investigates the exponential convergence of the associated continuous-time gradient flow, providing a theoretical foundation for future numerical discretizations. This work extends existing convergence analyses for energy ground states, addressing the challenges posed by the $L^{p+1}$ constraint, especially the absence of an inner-product structure."}
{"id": "2602.21206", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.21206", "abs": "https://arxiv.org/abs/2602.21206", "authors": ["Can Cui", "Jing-Yu Zhao", "Zheng-Yu Weng"], "title": "Minimal loop currents in doped Mott insulators", "comment": "24 pages, 20 figures", "summary": "For the $t$-$J$ model, variational wave functions can generally be constructed based on an accurate description of antiferromagnetism (AFM) at half-filling and an exact phase-string sign structure under doping. The single-hole-doped and two-hole-doped states, as determined by variational Monte Carlo (VMC) simulations, display sharply contrasting behaviors. The single-hole state constitutes a ``cat state'' that resonates strongly between a quasiparticle component and a local loop-current component, with approximately equal weights. In the ground state, the quasiparticle spectral weight $Z_{\\mathbf{k}}$ peaks at momenta $\\mathbf{k}_0 \\equiv (\\pm\\fracπ{2},\\pm\\fracπ{2})$. The total-energy dispersion versus $\\mathbf{k}$ agrees remarkably well with the Green function Monte Carlo results. However, Landau's one-to-one correspondence hypothesis for quasiparticles breaks down here with the incoherent component exhibiting intrinsic magnetization originating from a minimal $2\\times2$ loop current that forms a $4\\times4$ pattern on the square lattice--a finding in excellent agreement with density matrix renormalization group (DMRG) calculations. In the two-hole ground state, a new pairing mechanism is revealed: the two holes are automatically fused into a tightly bound object consisting of an incoherent $d_{xy}$ pairing along the diagonal direction by compensating the local loop currents. This hole pair is again a ``cat state'' that resonates strongly between the incoherent $d_{xy}$ and a coherent $d_{x^2-y^2}$ Cooper channel to gain substantial hopping energy. Its size extends over an area of about $4\\times 4$ lattice spacings, much smaller than the divergent AFM correlation length, implying that it should survive as a minimal superconducting building block even in the dilute doping regime. Experimental implications and the generalization to the finite-doping case are briefly addressed."}
{"id": "2602.20795", "categories": ["stat.ME", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.20795", "abs": "https://arxiv.org/abs/2602.20795", "authors": ["Xinhui Rong", "Girish N. Nair"], "title": "Hawkes Identification with a Prescribed Causal Basis: Closed-Form Estimators and Asymptotics", "comment": "21 pages, 4 figures", "summary": "Driven by the recent surge in neural-inspired modeling, point processes have gained significant traction in systems and control. While the Hawkes process is the standard model for characterizing random event sequences with memory, identifying its unknown kernels is often hindered by nonlinearity. Approaches using prescribed basis kernels have emerged to enable linear parameterization, yet they typically rely on iterative likelihood methods and lack rigorous analysis under model misspecification. This paper justifies a closed-form Least Squares identification framework for Hawkes processes with prescribed kernels. We guarantee estimator existence via the almost-sure positive definiteness of the empirical Gram matrix and prove convergence to the true parameters under correct specification, or to well-defined pseudo-true parameters under misspecification. Furthermore, we derive explicit Central Limit Theorems for both regimes, providing a complete and interpretable asymptotic theory. We demonstrate these theoretical findings through comparative numerical simulations."}
{"id": "2602.20834", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.20834", "abs": "https://arxiv.org/abs/2602.20834", "authors": ["Nils Lid Hjort", "Tore Schweder"], "title": "Confidence Distributions and Related Themes", "comment": "26 pages, 5 figures. Invited introduction for a theme issue on Confidence Distributions and Related Themes, for the Journal of Statistical Planning and Inference, by the two guest editors. JSPI 2018, vol. 195, pages 1-13; journal version i is here: www.sciencedirect.com/science/article/abs/pii/S037837581730174X", "summary": "This is the guest editors' general introduction to a Special Issue of the Journal of Statistical Planning and Inference, dedicated to confidence distributions and related themes. Confidence distributions (CDs) are distributions for parameters of interest, constructed via a statistical model after analysing the data. As such they serve the same purpose for the frequentist statisticians as the posterior distributions for the Bayesians. There have been several attempts in the literature to put up a clear theory for such confidence distributions, from Fisher's fiducial inference and onwards. There are certain obstacles and difficulties involved in these attempts, both conceptually and operationally, which have contributed to the CDs being slow in entering statistical mainstream. Recently there is a renewed surge of interest in CDs and various related themes, however, reflected in both series of new methodological research, advanced applications to substantive sciences, and dissemination and communication via workshops and conferences. The present special issue of the JSPI is a collection of papers emanating from the {\\it Inference With Confidence} workshop in Oslo, May 2015. Several of the papers appearing here were first presented at that workshop. The present collection includes however also new research papers from other scholars in the field."}
{"id": "2602.20620", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.20620", "abs": "https://arxiv.org/abs/2602.20620", "authors": ["Munetaka Sasaki"], "title": "Construction of a Neural Network with Temperature-Dependent Recall Patterns", "comment": "6 pages, 10 figures", "summary": "We present a simple model that recalls two different patterns depending on the temperature. To realize a change in recall pattern due to temperature change, we embed two patterns to different graphs: the first pattern into a fully connected graph and the second pattern into a sparse graph. Because a fully connected graph is more resistant to thermal fluctuations than a sparse graph, we can realize a change in recall pattern by tuning relative weights of the two patterns properly. We demonstrate by equilibrium Monte-Carlo simulations that such a temperature-dependent change in recall patterns does occur in our model. Simulation results strongly indicate that the system undergoes a first-order phase transition when the change in recall patterns occurs. It is also demonstrated by annealing simulations that the system fails to recall the pattern embedded in the sparse graph at low temperatures if the free-energy barrier is too high to overcome within the given simulation timescale."}
{"id": "2602.20896", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.20896", "abs": "https://arxiv.org/abs/2602.20896", "authors": ["Paul Axmann", "Bruno Ebner", "Eduardo García-Portugués"], "title": "On Stein's test of uniformity on the hypersphere", "comment": "31 pages, 5 figures, 4 tables", "summary": "We propose a new test of uniformity on the hypersphere based on a Stein characterization associated with the Laplace--Beltrami operator. We identify a sufficient class of test functions for this characterization, linked to the moment generating function. Exploiting the operator's eigenfunctions to obtain a harmonic decomposition in terms of Gegenbauer polynomials, we show that the proposed procedure belongs to the class of Sobolev tests. We derive closed-form expressions for the distribution of the test statistic under the null hypothesis and under fixed alternatives. To enhance power against a range of alternatives, we introduce a tuning parameter into the characterization and study its impact on rejection probabilities. We discuss data-driven strategies for selecting this parameter to maximize rejection rates for a given alternative and compare the resulting performance with that of related parametric tests. Additional numerical experiments compare the proposed test with competing Sobolev-class procedures, highlighting settings in which it offers clear advantages."}
{"id": "2602.20931", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.20931", "abs": "https://arxiv.org/abs/2602.20931", "authors": ["O. P. Ferreira", "D. S. Gonçalves", "M. S. Louzeiro", "S. Z. Németh", "J. Zhu"], "title": "A subdifferential characterization via Busemann functions and applications to DC optimization on Hadamard manifolds", "comment": null, "summary": "This paper investigates the properties of Busemann functions on Hadamard manifolds and their use in optimization algorithms in Riemannian settings. We present a new Busemann-based characterization of the subdifferential, which is particularly well suited to Riemannian optimization. In the classical Hadamard manifold framework, a subgradient provides a global lower model of a convex function expressed through the inverse exponential map. However, this model may fail to exhibit a useful convexity or concavity structure. By contrast, our characterization yields a concave bounding function by exploiting key properties of Busemann functions. We use this concavity to design and analyze difference-of-convex (DC) optimization methods on Hadamard manifolds. In particular, we reformulate the classical DC algorithm (DCA) for Riemannian contexts and study its convergence properties. We also report preliminary numerical experiments comparing the proposed Busemann DCA, which leads to geodesically convex subproblems, with the classical Riemannian DCA."}
{"id": "2602.20299", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.20299", "abs": "https://arxiv.org/abs/2602.20299", "authors": ["Tim Pokart", "Frank Pollmann", "Jan Carl Budich"], "title": "Entanglement Barriers from Computational Complexity: Matrix-Product-State Approach to Satisfiability", "comment": "17 pages, 12 figures", "summary": "We approach the 3-SAT satisfiability problem with the quantum-inspired method of imaginary time propagation (ITP) applied to matrix product states (MPS) on a classical computer. This ansatz is fundamentally limited by a quantum entanglement barrier that emerges in imaginary time, reflecting the exponential hardness expected for this NP-complete problem. Strikingly, we argue based on careful analysis of the structure imprinted onto the MPS by the 3-SAT instances that this barrier arises from classical computational complexity. To reveal this connection, we elucidate with stochastic models the specific relationship between the classical hardness of the $\\sharp$P $\\supseteq$ NP-complete counting problem $\\sharp$3-SAT and the entanglement properties of the quantum state. Our findings illuminate the limitations of this quantum-inspired approach and demonstrate how purely classical computational complexity can manifest in quantum entanglement. Furthermore, we present estimates of the non-stabilizerness required by the protocol, finding a similar resource barrier. Specifically, the necessary amount of non-Clifford operations scales superlinearly in system size, thus implying extensive resource requirements of ITP on different architectures such as Clifford circuits or gate-based quantum computers."}
{"id": "2602.20822", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.20822", "abs": "https://arxiv.org/abs/2602.20822", "authors": ["Philipp Mickan", "Thorsten Hohage"], "title": "Hölder-Logarithmic Stability and Convergence Rates for an Inverse Random Source Problem", "comment": null, "summary": "In this paper, we investigate an inverse random source problem concerned with recovering the strength of a random, uncorrelated acoustic source from correlation measurements of emitted time-harmonic acoustic waves. Such problems arise in applications including aeroacoustics and seismic imaging. Unlike their deterministic counterparts, inverse random source problems are known to be uniquely solvable in the absence of noise. Nevertheless, due to their inherent ill-posedness, regularization is required to stably reconstruct the source strength.\n  We derive conditional Hölder-logarithmic stability estimates under Sobolev smoothness assumptions by employing complex geometrical optics solutions. Moreover, by establishing a variational source condition, we obtain Hölder-logarithmic convergence rates for spectral regularization methods. At fixed frequency, the exponents in the logarithmic stability and convergence estimates grow unboundedly as the Sobolev regularity of the source increases. Finally, we present numerical experiments supporting our theoretical findings."}
{"id": "2602.20299", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.20299", "abs": "https://arxiv.org/abs/2602.20299", "authors": ["Tim Pokart", "Frank Pollmann", "Jan Carl Budich"], "title": "Entanglement Barriers from Computational Complexity: Matrix-Product-State Approach to Satisfiability", "comment": "17 pages, 12 figures", "summary": "We approach the 3-SAT satisfiability problem with the quantum-inspired method of imaginary time propagation (ITP) applied to matrix product states (MPS) on a classical computer. This ansatz is fundamentally limited by a quantum entanglement barrier that emerges in imaginary time, reflecting the exponential hardness expected for this NP-complete problem. Strikingly, we argue based on careful analysis of the structure imprinted onto the MPS by the 3-SAT instances that this barrier arises from classical computational complexity. To reveal this connection, we elucidate with stochastic models the specific relationship between the classical hardness of the $\\sharp$P $\\supseteq$ NP-complete counting problem $\\sharp$3-SAT and the entanglement properties of the quantum state. Our findings illuminate the limitations of this quantum-inspired approach and demonstrate how purely classical computational complexity can manifest in quantum entanglement. Furthermore, we present estimates of the non-stabilizerness required by the protocol, finding a similar resource barrier. Specifically, the necessary amount of non-Clifford operations scales superlinearly in system size, thus implying extensive resource requirements of ITP on different architectures such as Clifford circuits or gate-based quantum computers."}
{"id": "2602.21090", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21090", "abs": "https://arxiv.org/abs/2602.21090", "authors": ["Alexander J Gallo", "Massimiliano Zoggia", "Alessandro Falsone", "Maria Prandini", "Simone Garatti"], "title": "Robustness certificates in data-driven non-convex optimization with additively-uncertain constraints", "comment": "11 pages, 8 figures. The manuscript has been submitted to the IEEE Transactions on Automatic Control for possible publication", "summary": "We consider decision-making problems that are formulated as non-convex optimization programs where uncertainty enters the constraints through an additive term, independent of the decision variables, and robustness is imposed using a finite data-set, according to the scenario robust optimization paradigm. By exploiting the structure of the constraints, we show that both a priori and a posteriori distribution-free probabilistic robustness certificates for a possibly sub-optimal solution to the resulting data-driven optimization problem can be obtained with minimal computational effort. Building on these results, we also discuss a one-shot and an incremental procedure to determine the size of the data-set so as to guarantee a user-chosen robustness level. Notably, both the a posteriori robustness assessment and incremental data-set sizing do not require to solve the non-convex scenario program. A comparative analysis performed on the unit commitment problem using real data reveals a limited increase in conservativeness with a significant computational saving with respect to the application of scenario theory results for general, non necessarily structured, non-convex problems."}
{"id": "2602.20885", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.20885", "abs": "https://arxiv.org/abs/2602.20885", "authors": ["Céline Cunen", "Nils Lid Hjort"], "title": "Combining Information Across Diverse Sources: The II-CC-FF Paradigm", "comment": "44 pages, 14 figures. This is the authors' version, with Supplementing Material, July 2020 (and arXiv'd February 2026), published in essentially this form in Scandinavian Journal of Statistics, 2022, vol. 49, pages 625-256, at this url: onlinelibrary.wiley.com/doi/pdf/10.1111/sjos.12530", "summary": "We introduce and develop a general paradigm for combining information across diverse data sources. In broad terms, suppose $φ$ is a parameter of interest, built up via components $ψ_1,\\ldots,ψ_k$ from data sources $1,\\ldots,k$. The proposed scheme has three steps. First, the Independent Inspection (II) step amounts to investigating each separate data source, translating statistical information to a confidence distribution $C_j(ψ_j)$ for the relevant focus parameter $ψ_j$ associated with data source $j$. Second, Confidence Conversion (CC) techniques are used to translate the confidence distributions to confidence log-likelihood functions, say $\\ell_{{\\rm con},j}(ψ_j)$. Finally, the Focused Fusion (FF) step uses relevant and context-driven techniques to construct a confidence distribution for the primary focus parameter $φ=φ(ψ_1,\\ldots,ψ_k)$, acting on the combined confidence log-likelihood. In traditional setups, the II-CC-FF strategy amounts to versions of meta-analysis, and turns out to be competitive against state-of-the-art methods. Its potential lies in applications to harder problems, however. Illustrations are presented, related to actual applications."}
{"id": "2602.20694", "categories": ["quant-ph", "cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.20694", "abs": "https://arxiv.org/abs/2602.20694", "authors": ["Samuel O. Scalet"], "title": "Spatial Entanglement Sudden Death in Spin Chains at All Temperatures", "comment": "19 pages, 2 figures", "summary": "We prove a finite entanglement length for the Gibbs state of any local Hamiltonian on a spin chain at any finite temperature: After removing an interval of size at least equal to the entanglement length, the remaining left and right half-chains are in a separable state."}
{"id": "2602.21055", "categories": ["math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.21055", "abs": "https://arxiv.org/abs/2602.21055", "authors": ["Keith Levin"], "title": "Adjacency Spectral Embeddings of Correlation Networks", "comment": null, "summary": "In many applications, weighted networks are constructed based on time series data: each time series is associated to a vertex and edge weights are given by pairwise correlations. The result is a network whose edge dependency structure violates the assumptions of most common network models. Nonetheless, it is common to analyze these \"correlation networks\" using embedding methods derived from edge-independent network models, based on a belief that the edges are approximately independent. In this work, we put this modeling choice on firm theoretical ground. We show that when the time series are expressible in terms of a small number of Fourier basis elements (or in some other suitably-chosen basis), correlation networks correspond to latent space networks with dependent edge noise in which the vertex-level latent variables encode the basis coefficients. Further, we show that when time series are observed subject to noise, spectral embedding of the resulting noisy correlation network still recovers these true vertex-level latent representations under suitable assumptions. This characterization of embeddings as learning Fourier coefficients appears to be folklore in the signal processing community in the context of principal component analysis, but is, to the best of our knowledge, new to the statistical network analysis literature."}
{"id": "2602.20991", "categories": ["math.OC", "cs.DS", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.20991", "abs": "https://arxiv.org/abs/2602.20991", "authors": ["Robin A. Heinonen"], "title": "Asymptotics of solutions to the linear search problem", "comment": null, "summary": "The exact leading asymptotics of solutions to the symmetric linear search problem are obtained for any positive probability density on the real line with a monotonic, sufficiently regular tail. A similar result holds for densities on a compact interval."}
{"id": "2602.20301", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20301", "abs": "https://arxiv.org/abs/2602.20301", "authors": ["Luiz Couto Correa Pinto Filho", "Jesper B. Christensen", "Anders Brusch", "Mikael Lassen"], "title": "Quantifying Effective Heterodyne Detection Efficiency with SI-Traceable Standards", "comment": "11 pages, 4 figures", "summary": "Accurate calibration of coherent optical receivers is essential for reliable performance assessment in coherent communications, precision and quantum sensing, and continuous-variable quantum key distribution (CV-QKD), where the effective detection efficiency directly impacts channel parameter estimation. We present a methodology traceable to the International System of Units (SI) to determine the effective heterodyne detection efficiency of balanced receivers using shot-noise-referenced measurements. The protocol relies on two observables acquired with an electrical spectrum analyzer: the heterodyne beat-note power and the local oscillator shot-noise variance, with explicit treatment of the analyzer's equivalent noise bandwidth (ENBW). The photon flux in the signal path is referenced to SI units via calibrated radiometric standards. We first validate the protocol on a free-space receiver, demonstrating consistency with an independently constructed optical loss chain across a wide range of signal powers and under controlled, calibrated attenuation. Extending the same estimator to a fiber-coupled, polarization-maintaining balanced receiver confirms that the protocol is robust for practical coherent-receiver architectures and intermediate frequencies in the MHz range. These results establish a traceable, uncertainty-bounded framework for real-time receiver calibration, providing a practical route for CV-QKD and other coherent optical systems."}
{"id": "2602.20948", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.20948", "abs": "https://arxiv.org/abs/2602.20948", "authors": ["Angelo A. Casulli", "Daniel Kressner", "Nian Shao"], "title": "Lanczos with compression for symmetric eigenvalue problems", "comment": null, "summary": "The Lanczos method with implicit restarting is one of the most popular methods for finding a few exterior eigenpairs of a large symmetric matrix $A$. Usually based on polynomial filtering, restarting is crucial to limit memory and the cost of orthogonalization. In this work, we propose a novel strategy for the same purpose, called Lanczos with compression. Unlike polynomial filtering, our approach compresses the Krylov subspace using rational approximation and, in doing so, it sacrifices the structure of the associated Krylov decomposition. Nevertheless, it remains compatible with subsequent Lanczos steps and the overall algorithm is still solely based on matrix-vector products with $A$. On the theoretical side, we show that compression introduces only a small error compared to standard (unrestarted) Lanczos and therefore has only a negligible impact on convergence. Comparable guarantees are not available for commonly used implicit restarting strategies, including the Krylov--Schur method. On the practical side, our numerical experiments demonstrate that compression often outperforms the Krylov--Schur method in terms of matrix-vector products."}
{"id": "2602.20612", "categories": ["quant-ph", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.20612", "abs": "https://arxiv.org/abs/2602.20612", "authors": ["Motohiko Ezawa"], "title": "Non-Clifford symmetry protected topological higher-order cluster states in multi-qubit measurement-based quantum computation", "comment": "19 pages, 11 figures", "summary": "A cluster state is a strongly entangled state, which is a source of measurement-based quantum computation. It is generated by applying controlled-Z (CZ) gates to the state $\\left\\vert ++\\cdots +\\right\\rangle $. It is protected by the $\\mathbb{Z}_{2}^{\\text{even}}\\times \\mathbb{Z}_{2}^{ \\text{odd}}$ symmetry. By applying general quantum gates to the state $ \\left\\vert ++\\cdots +\\right\\rangle $, we systematically obtain a general short-range entangled cluster state. If we use a non-Clifford gate such as the controlled phase-shift gate, we obtain a non-Clifford cluster state. Furthermore, if we use the controlled-controlled Z (CCZ) gate instead of the CZ gate, we obtain non-Clifford cluster states with five-body entanglement. We generalize it to the C$^{N}$Z gate, where $(2N+1)$-body entangled states are generated. The $\\mathbb{Z}_{2}^{\\text{even}}\\times \\mathbb{Z}_{2}^{\\text{odd}}$ symmetry is non-Clifford for $N\\geq 3$. We demonstrate that there emerge $2^{2N}$ fold degenerate ground states for an open chain, indicating the emergence of $N$ free spins at each edge. They can be used as an $N$-qubit input and an $N$-qubit output in measurement-based quantum computation. We also study the non-invertible symmetry, the Kennedy-Tasaki transformation and the string-order parameter in addition to the $\\mathbb{Z}_{2}^{\\text{even}}\\times \\mathbb{Z}_{2}^{\\text{odd}}$ symmetry in these models."}
{"id": "2602.20939", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.20939", "abs": "https://arxiv.org/abs/2602.20939", "authors": ["Cynthia Medeiros", "John Quigley", "Matthew Revie"], "title": "A Statistical Framework for Detecting Emergent Narratives in Longitudinal Text Corpora", "comment": null, "summary": "Narratives about economic events and policies are widely recognised as influential drivers of economic and business behaviour. Yet the statistical identification of narrative emergence remains underdeveloped. Narratives evolve gradually, exhibit subtle shifts in content, and may exert influence disproportionate to their observable frequency, making it difficult to determine when observed changes reflect genuine structural shifts rather than routine variation in language use. We propose a statistical framework for detecting narrative emergence in longitudinal text corpora using Latent Dirichlet Allocation (LDA). We define emergence as a sustained increase in a topic's relative prominence over time and articulate a statistical framework for interpreting such trajectories, recognising that topic proportions are latent, model-estimated quantities. We illustrate the approach using a corpus of academic publications in economics spanning 1970-2018, where Nobel Prize-recognised contributions serve as externally observable signals of influential narratives. Topics associated with these contributions display sustained increases in estimated prevalence that coincide with periods of heightened citation activity and broader disciplinary recognition. These findings indicate that model-based topic trajectories can reflect identifiable shifts in economic discourse and provide a statistically grounded basis for analysing thematic change in longitudinal textual data."}
{"id": "2602.21086", "categories": ["cond-mat.str-el", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.21086", "abs": "https://arxiv.org/abs/2602.21086", "authors": ["Maksymilian Kliczkowski", "Jakub Grabowski", "Maciej M. Maśka"], "title": "Probing frustrated spin systems with impurities", "comment": null, "summary": "We investigate the effective interaction between two localized spin impurities embedded in a frustrated spin-1/2 $J_1\\!-\\!J_2$ Heisenberg chain. Treating the impurity spins as classical moments coupled locally to the host, we combine second--order perturbation theory with large--scale density matrix renormalization group (DMRG) calculations to determine the impurity--impurity interaction as a function of separation, coupling strength, and magnetic frustration. In the weak--coupling regime, we show that the interaction is governed by the the static spin susceptibility of the host and exhibits oscillatory power--law decay in the gapless phase, modified by universal logarithmic corrections at the SU(2)--symmetric critical point. In the gapped dimerized phase, the interaction decays exponentially with distance. For intermediate and strong impurity--host coupling, we observe a crossover to a boundary--dominated regime characterized by pronounced parity effects associated with the length of the chain segment between impurities, signaling a breakdown of the simple RKKY--like description. Our results establish impurity--impurity interactions as a sensitive probe of frustrated quantum spin liquids and provide a controlled framework for distinguishing gapless and gapped phases through local perturbations."}
{"id": "2602.20572", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.20572", "abs": "https://arxiv.org/abs/2602.20572", "authors": ["Chang Jun Im", "Jeong Min Jeon"], "title": "Local Fréchet regression with toroidal predictors", "comment": "52 pages, 1 figure. Submitted to Scandinavian Journal of Statistics", "summary": "We provide the first regression framework that simultaneously accommodates responses taking values in a general metric space and predictors lying on a general torus. We propose intrinsic local constant and local linear estimators that respect the underlying geometries of both the response and predictor spaces. Our local linear estimator is novel even in the case of scalar responses. We further establish their asymptotic properties, including consistency and convergence rates. Simulation studies, together with an application to real data, illustrate the superior performance of the proposed methodology."}
{"id": "2602.21090", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21090", "abs": "https://arxiv.org/abs/2602.21090", "authors": ["Alexander J Gallo", "Massimiliano Zoggia", "Alessandro Falsone", "Maria Prandini", "Simone Garatti"], "title": "Robustness certificates in data-driven non-convex optimization with additively-uncertain constraints", "comment": "11 pages, 8 figures. The manuscript has been submitted to the IEEE Transactions on Automatic Control for possible publication", "summary": "We consider decision-making problems that are formulated as non-convex optimization programs where uncertainty enters the constraints through an additive term, independent of the decision variables, and robustness is imposed using a finite data-set, according to the scenario robust optimization paradigm. By exploiting the structure of the constraints, we show that both a priori and a posteriori distribution-free probabilistic robustness certificates for a possibly sub-optimal solution to the resulting data-driven optimization problem can be obtained with minimal computational effort. Building on these results, we also discuss a one-shot and an incremental procedure to determine the size of the data-set so as to guarantee a user-chosen robustness level. Notably, both the a posteriori robustness assessment and incremental data-set sizing do not require to solve the non-convex scenario program. A comparative analysis performed on the unit commitment problem using real data reveals a limited increase in conservativeness with a significant computational saving with respect to the application of scenario theory results for general, non necessarily structured, non-convex problems."}
{"id": "2602.20331", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2602.20331", "abs": "https://arxiv.org/abs/2602.20331", "authors": ["Ovidiu Cristinel Stoica"], "title": "No change in Hilbert space fundamentalism", "comment": "3 pages", "summary": "Hilbert space fundamentalism (HSF) states that everything about the physical world is encoded in the Hamiltonian operator and the state vector (as a unit vector, not a wavefunction, which requires additional specification of a configuration space, a position basis, or the position observables). That all structures needed to describe reality, including subsystems, space, fields, emerge from these.\n  I show that HSF can't account for our observations that the physical world changes in time."}
{"id": "2602.20955", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.20955", "abs": "https://arxiv.org/abs/2602.20955", "authors": ["Woula Themistoclakis", "Marc Van Barel"], "title": "Orthonormal polynomial wavelets associated with de la Vallée Poussin-type interpolation on $[-1,1]$", "comment": "33 pages", "summary": "Starting from de la Vallée Poussin type (VP) interpolation, the authors have recently introduced a family of interpolating polynomial scaling and wavelet bases generating the approximation and detail spaces of a non-standard multiresolution analysis. Motivated by the fact that, in many applications, orthonormal rather than interpolating bases are preferable, the present study develops a new family of scaling and wavelet polynomials that provide well-localized and orthonormal bases for the same approximation and detail spaces.\n  We show that the proposed new bases have a behavior very similar to the interpolating bases already introduced, presenting similar features although they are not interpolating but orthonormal. In particular, we study the Fourier projection corresponding to the proposed orthonormal scaling basis, and introduce a discrete version of it by approximating the Fourier--like coefficients. For both continuous and discrete orthogonal projections, we prove the uniform boundedness of the Lebesgue constants and the uniform convergence with an asymptotic rate comparable with the best uniform polynomial approximation.\n  Numerical experiments confirm the theoretical results and compare the new orthonormal VP scaling and wavelet bases with the interpolating case previously treated by the authors."}
{"id": "2602.20965", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.20965", "abs": "https://arxiv.org/abs/2602.20965", "authors": ["María José Llop", "Andrea Bergesio", "Anne-Françoise Yao"], "title": "Estimating the Partially Linear Zero-Inflated Poisson Regression Model: a Robust Approach Using a EM-like Algorithm", "comment": null, "summary": "Count data with an excessive number of zeros frequently arise in fields such as economics, medicine, and public health. Traditional count models often fail to adequately handle such data, especially when the relationship between the response and some predictors is nonlinear. To overcome these limitations, the partially linear zero-inflated Poisson (PLZIP) model has been proposed as a flexible alternative. However, all existing estimation approaches for this model are based on likelihood, which is known to be highly sensitive to outliers and slight deviations from the model assumptions. This article presents the first robust estimation method specifically developed for the PLZIP model. An Expectation-Maximization-like algorithm is used to take advantage of the mixture nature of the model and to address extreme observations in both the response and the covariates. Results of the algorithm convergence and the consistency of the estimators are proved. A simulation study under various contamination schemes showed the robustness and efficiency of the proposed estimators in finite samples, compared to classical estimators. Finally, the application of the methodology is illustrated through an example using real data."}
{"id": "2602.21190", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.21190", "abs": "https://arxiv.org/abs/2602.21190", "authors": ["Guglielmo Pellitteri", "Vittorio Giovannetti", "Vasco Cavina"], "title": "Exact quantum transport in non-Markovian open Gaussian systems", "comment": "10 pages + 15 pages of appendices, 5 figures", "summary": "We build an exact framework to evaluate heat, energy, and particle transport between Gaussian reservoirs mediated by a quadratic quantum system. By combining full counting statistics with newly developed non-Markovian master equation approaches, we introduce an effective master equation whose solution can be used to generate arbitrary moments of the heat statistics for any number of reservoirs. This theory applies equally to fermionic and bosonic systems, holds at arbitrarily strong coupling, and resolves out-of-equilibrium transient dynamics determined by the system's initial state. In the steady-state, weak-coupling limit, we recover results analogous to those of the well-known Landauer-Büttiker formalism. We conclude our discussion by demonstrating an application of the method to a prototypical fermionic system. Our results uncover a regime of transient negative heat conductance contingent upon the initial system preparation, providing a clear signature of non-trivial out-of-equilibrium dynamics."}
{"id": "2602.20965", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.20965", "abs": "https://arxiv.org/abs/2602.20965", "authors": ["María José Llop", "Andrea Bergesio", "Anne-Françoise Yao"], "title": "Estimating the Partially Linear Zero-Inflated Poisson Regression Model: a Robust Approach Using a EM-like Algorithm", "comment": null, "summary": "Count data with an excessive number of zeros frequently arise in fields such as economics, medicine, and public health. Traditional count models often fail to adequately handle such data, especially when the relationship between the response and some predictors is nonlinear. To overcome these limitations, the partially linear zero-inflated Poisson (PLZIP) model has been proposed as a flexible alternative. However, all existing estimation approaches for this model are based on likelihood, which is known to be highly sensitive to outliers and slight deviations from the model assumptions. This article presents the first robust estimation method specifically developed for the PLZIP model. An Expectation-Maximization-like algorithm is used to take advantage of the mixture nature of the model and to address extreme observations in both the response and the covariates. Results of the algorithm convergence and the consistency of the estimators are proved. A simulation study under various contamination schemes showed the robustness and efficiency of the proposed estimators in finite samples, compared to classical estimators. Finally, the application of the methodology is illustrated through an example using real data."}
{"id": "2602.21138", "categories": ["math.OC", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21138", "abs": "https://arxiv.org/abs/2602.21138", "authors": ["Kimon Fountoulakis", "David Martínez-Rubio"], "title": "Complexity of Classical Acceleration for $\\ell_1$-Regularized PageRank", "comment": "23 pages, 8 Figures", "summary": "We study the degree-weighted work required to compute $\\ell_1$-regularized PageRank using the standard one-gradient-per-iteration accelerated proximal-gradient method (FISTA). For non-accelerated local methods, the best known worst-case work scales as $\\widetilde{O} ((αρ)^{-1})$, where $α$ is the teleportation parameter and $ρ$ is the $\\ell_1$-regularization parameter. A natural question is whether FISTA can improve the dependence on $α$ from $1/α$ to $1/\\sqrtα$ while preserving the $1/ρ$ locality scaling. The challenge is that acceleration can break locality by transiently activating nodes that are zero at optimality, thereby increasing the cost of gradient evaluations. We analyze FISTA on a slightly over-regularized objective and show that, under a checkable confinement condition, all spurious activations remain inside a boundary set $\\mathcal{B}$. This yields a bound consisting of an accelerated $(ρ\\sqrtα)^{-1}\\log(α/\\varepsilon)$ term plus a boundary overhead $\\sqrt{vol(\\mathcal{B})}/(ρα^{3/2})$. We provide graph-structural conditions that imply such confinement. Experiments on synthetic and real graphs show the resulting speedup and slowdown regimes under the degree-weighted work model."}
{"id": "2602.20352", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20352", "abs": "https://arxiv.org/abs/2602.20352", "authors": ["Vinit Singh", "Amandeep Singh Bhatia", "Mandeep Kaur Saggi", "Manas Sajjan", "Sabre Kais"], "title": "Quantum Machine Learning for Complex Systems", "comment": null, "summary": "Quantum machine learning (QML) is rapidly transitioning from theoretical promise to practical relevance across data-intensive scientific domains. In this Review, we provide a structured overview of recent advances that bridge foundational quantum learning principles with real-world applications. We survey foundational QML paradigms, including variational quantum algorithms, quantum kernel methods, and neural-network quantum states, with emphasis on their applicability to complex quantum systems. We examine neural-network quantum states as expressive variational models for correlated matter, non-equilibrium dynamics, and open quantum systems, and discuss fundamental challenges associated with training and sampling. Recent advances in quantum-enhanced sampling and diagnostics of learning dynamics, including information-theoretic tools, are reviewed as mechanisms for improving scalability and trainability. The Review further highlights application-driven QML frameworks in drug discovery, cancer biology, and agro-climate modeling, where data complexity and constraints motivate hybrid quantum-classical approaches. We conclude with a discussion of federated quantum machine learning as a route to distributed, privacy-preserving quantum intelligence. Overall, this Review presents a unified perspective on the opportunities and limitations of QML for complex systems."}
{"id": "2602.21197", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.21197", "abs": "https://arxiv.org/abs/2602.21197", "authors": ["Vittoriano Ruas"], "title": "Variants of Raviart-Thomas mixed elements for curved domains using straight-edged tetrahedra", "comment": "This pre-publication is the same as the initial version of the manuscript submitted to (Springer) Journal of Scientific Computing, except for its abridged title and the dedication. It was accepted for publication by this journal in revised and improved form on February 21, 2026", "summary": "A numerical study of tetrahedral Raviart-Thomas mixed finite element methods is presented in the solution of model second order boundary value problems posed in a curved spatial domain. An emphasis is given to the case where normal fluxes are prescribed on a boundary portion. In this case the question on the best way to enforce known boundary degrees of freedom is raised. It seems intuitive that the normal component of the flux variable should preferably not take up corresponding prescribed values at nodes shifted to the boundary of the approximating polyhedron in the underlying normal direction. This is because an accuracy downgrade is to be expected, as shown in https://doi.org/10.1137/15M1045442 and https://doi.org/10.1051/m2an/2025028. In the former work accuracy improvement is achieved by means of a standard Galerkin formulation with parametric elements. The latter one in turn advocates the use of straight-edged triangles combined with a Petrov-Galerkin formulation, in which the aforementioned shift applies only to the test-flux space, while the shape-flux space consists of fields whose fluxes satisfy the prescribed conditions on the true boundary. The first purpose of this article is to show that the method studied in https://doi.org/10.1051/m2an/2025028 for two-dimensional problems can be extended quite naturally to the three-dimensional case. More particularly we illustrate this by carrying out numerical experimentation with such a version for the two lowest order methods of this family, as compared to the corresponding do-nothing strategy. In the case of the lowest order method this comparative study is enriched by assessing as well the performance of its Hermite analog introduced in https://doi.org/10.1016/j.cam.2012.08.027."}
{"id": "2602.21031", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.21031", "abs": "https://arxiv.org/abs/2602.21031", "authors": ["Hayk Gevorgyan", "Konstantinos Kalogeropoulos", "Angelos Alexopoulos"], "title": "Exchangeable Gaussian Processes for Staggered-Adoption Policy Evaluation", "comment": null, "summary": "We study the use of exchangeable multi-task Gaussian processes (GPs) for causal inference in panel data, applying the framework to two settings: one with a single treated unit subject to a once-and-for-all treatment and another with multiple treated units and staggered treatment adoption. Our approach models the joint evolution of outcomes for treated and control units through a GP prior that ensures exchangeability across units while allowing for flexible nonlinear trends over time. The resulting posterior predictive distribution for the untreated potential outcomes of the treated unit provides a counterfactual path, from which we derive pointwise and cumulative treatment effects, along with credible intervals to quantify uncertainty. We implement several variations of the exchangeable GP model using different kernel functions. To assess prediction accuracy, we conduct a placebo-style validation within the pre-intervention window by selecting a ``fake'' intervention date. Ultimately, this study illustrates how exchangeable GPs serve as a flexible tool for policy evaluation in panel data settings and proposes a novel approach to staggered-adoption designs with a large number of treated and control units."}
{"id": "2602.21068", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.21068", "abs": "https://arxiv.org/abs/2602.21068", "authors": ["Jake Bowers", "David Kim", "Nuole Chen"], "title": "Detecting Where Effects Occur by Testing Hypotheses in Order", "comment": null, "summary": "Experimental evaluations of public policies often randomize a new intervention within many sites or blocks. After a report of an overall result -- statistically significant or not -- the natural question from a policy maker is: \\emph{where} did any effects occur? Standard adjustments for multiple testing provide little power to answer this question. In simulations modeled after a 44-block education trial, the Hommel adjustment -- among the most powerful procedures controlling the family-wise error rate (FWER) -- detects effects in only 11\\% of truly non-null blocks. We develop a procedure that tests hypotheses top-down through a tree: test the overall null at the root, then groups of blocks, then individual blocks, stopping any branch where the null is not rejected. In the same 44-block design, this approach detects effects in 44\\% of non-null blocks -- roughly four times the detection rate. A stopping rule and valid tests at each node suffice for weak FWER control. We show that the strong-sense FWER depends on how rejection probabilities accumulate along paths through the tree. This yields a diagnostic: when power decays fast enough relative to branching, no adjustment is needed; otherwise, an adaptive $α$-adjustment restores control. We apply the method to 25 MDRC education trials and provide an R package, \\texttt{manytestsr}."}
{"id": "2602.20359", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.20359", "abs": "https://arxiv.org/abs/2602.20359", "authors": ["Rayan Mazouz", "Frederik Baymler Mathiesen", "Luca Laurenti", "Morteza Lahijanian"], "title": "StochasticBarrier.jl: A Toolbox for Stochastic Barrier Function Synthesis", "comment": null, "summary": "We present StochasticBarrier.jl, an open-source Julia-based toolbox for generating Stochastic Barrier Functions (SBFs) for safety verification of discrete-time stochastic systems with additive Gaussian noise. StochasticBarrier.jl certifies linear, polynomial, and piecewise affine (PWA) systems. The latter enables verification for a wide range of system dynamics, including general nonlinear types. The toolbox implements a Sum-of-Squares (SOS) optimization approach, as well as methods based on piecewise constant (PWC) functions. For SOS-based SBFs, StochasticBarrier.jl leverages semi-definite programming solvers, while for PWC SBFs, it offers three engines: two using linear programming (LP) and one based on gradient descent (GD). Benchmarking StochasticBarrier.jl against the state-of-the-art shows that the tool outperforms existing tools in computation time, safety probability bounds, and scalability across over 30 case studies. Compared to its closest competitor, StochasticBarrier.jl is up to four orders of magnitude faster, achieves significant safety probability improvements, and supports higher-dimensional systems."}
{"id": "2602.20407", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20407", "abs": "https://arxiv.org/abs/2602.20407", "authors": ["Lucas A. M. Rattighieri", "Pedro M. Prado", "Marcos C. de Oliveira", "Felipe F. Fanchini"], "title": "Measurement-Guided State Refinement for Shallow Feedback-Based Quantum Optimization Algorithm", "comment": "12 pages, 6 figures", "summary": "Limited circuit depth remains a central constraint for quantum optimization in the noisy intermediate-scale quantum (NISQ) regime, where shallow unitary dynamics may fail to sufficiently concentrate probability on low-energy configurations. We introduce Measurement-Guided Initialization (MGI), an iterative strategy that uses measurement outcomes from previous executions to update the initialization of subsequent runs. The method extracts single-qubit marginal probabilities from dominant measurement outcomes and prepares a biased product-state initialization, allowing information obtained during optimization to be reused without introducing classical parameter optimization. We implement this approach in the context of the Feedback-Based Algorithm for Quantum Optimization (FALQON) and evaluate its performance on weighted MaxCut instances. Numerical results show that measurement-guided initialization improves the performance of shallow-depth circuits and enables iterative refinement toward high-quality solutions while preserving the non-variational structure of the algorithm. These results indicate that measurement statistics can be exploited to improve shallow quantum optimization protocols compatible with NISQ devices."}
{"id": "2602.21036", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.21036", "abs": "https://arxiv.org/abs/2602.21036", "authors": ["Milleno Pan", "Antoine de Mathelin", "Wesley Tansey"], "title": "Empirically Calibrated Conditional Independence Tests", "comment": null, "summary": "Conditional independence tests (CIT) are widely used for causal discovery and feature selection. Even with false discovery rate (FDR) control procedures, they often fail to provide frequentist guarantees in practice. We highlight two common failure modes: (i) in small samples, asymptotic guarantees for many CITs can be inaccurate and even correctly specified models fail to estimate the noise levels and control the error, and (ii) when sample sizes are large but models are misspecified, unaccounted dependencies skew the test's behavior and fail to return uniform p-values under the null. We propose Empirically Calibrated Conditional Independence Tests (ECCIT), a method that measures and corrects for miscalibration. For a chosen base CIT (e.g., GCM, HRT), ECCIT optimizes an adversary that selects features and response functions to maximize a miscalibration metric. ECCIT then fits a monotone calibration map that adjusts the base-test p-values in proportion to the observed miscalibration. Across empirical benchmarks on synthetic and real data, ECCIT achieves valid FDR with higher power than existing calibration strategies while remaining test agnostic."}
{"id": "2602.20605", "categories": ["quant-ph", "math-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.20605", "abs": "https://arxiv.org/abs/2602.20605", "authors": ["Zhijian Lai", "Hantao Nie", "Jiayuan Wu", "Dong An"], "title": "Quantum circuit design from a retraction-based Riemannian optimization framework", "comment": "28 pages", "summary": "Designing quantum circuits for ground state preparation is a fundamental task in quantum information science. However, standard Variational Quantum Algorithms (VQAs) are often constrained by limited ansatz expressivity and difficult optimization landscapes. To address these issues, we adopt a geometric perspective, formulating the problem as the minimization of an energy cost function directly over the unitary group. We establish a retraction-based Riemannian optimization framework for this setting, ensuring that all algorithmic procedures are implementable on quantum hardware. Within this framework, we unify existing randomized gradient approaches under a Riemannian Random Subspace Gradient Projection (RRSGP) method. While recent geometric approaches have predominantly focused on such first-order gradient descent techniques, efficient second-order methods remain unexplored. To bridge this gap, we derive explicit expressions for the Riemannian Hessian and show that it can be estimated directly on quantum hardware via parameter-shift rules. Building on this, we propose the Riemannian Random Subspace Newton (RRSN) method, a scalable second-order algorithm that constructs a Newton system from measurement data. Numerical simulations indicate that RRSN achieves quadratic convergence, yielding high-precision ground states in significantly fewer iterations compared to both existing first-order approaches and standard VQA baselines. Ultimately, this work provides a systematic foundation for applying a broader class of efficient Riemannian algorithms to quantum circuit design."}
{"id": "2602.20410", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20410", "abs": "https://arxiv.org/abs/2602.20410", "authors": ["B. S. Ham"], "title": "A quantum mechanical analysis of the coherence de Broglie wavelength for superresolution and enhanced sensitivity in a coupled interferometer scheme", "comment": "8 pages, 3 figures", "summary": "Quantum sensing has drawn considerable attention as a means to overcome the fundamental limitations in classical sensing. In practice, however, quantum sensing has been strongly constrained by the photon loss, the achievable photon number N in N00N states, and by a finite squeezing level in squeezed states. These limitations are particularly critical to photon-loss-sensitive applications such as LiDAR as well as to general sensing platforms that require large effective N, such as ring-laser gyroscopes. Recently, fundamentally different sensing platforms have been reported to overcome both classical and quantum constraints in a practical regime. One such approach exploits the coherence de Broglie wavelength (CBW) realized in an anti-symmetrically coupled Mach-Zehnder interferometer (MZI) architecture. Here, a pure quantum mechanical analysis of the CBW is presented for a loss-free sensing mechanism of superresolution with enhanced sensitivity. A proof-of-principle demonstration of CBW is also presented."}
{"id": "2602.21068", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.21068", "abs": "https://arxiv.org/abs/2602.21068", "authors": ["Jake Bowers", "David Kim", "Nuole Chen"], "title": "Detecting Where Effects Occur by Testing Hypotheses in Order", "comment": null, "summary": "Experimental evaluations of public policies often randomize a new intervention within many sites or blocks. After a report of an overall result -- statistically significant or not -- the natural question from a policy maker is: \\emph{where} did any effects occur? Standard adjustments for multiple testing provide little power to answer this question. In simulations modeled after a 44-block education trial, the Hommel adjustment -- among the most powerful procedures controlling the family-wise error rate (FWER) -- detects effects in only 11\\% of truly non-null blocks. We develop a procedure that tests hypotheses top-down through a tree: test the overall null at the root, then groups of blocks, then individual blocks, stopping any branch where the null is not rejected. In the same 44-block design, this approach detects effects in 44\\% of non-null blocks -- roughly four times the detection rate. A stopping rule and valid tests at each node suffice for weak FWER control. We show that the strong-sense FWER depends on how rejection probabilities accumulate along paths through the tree. This yields a diagnostic: when power decays fast enough relative to branching, no adjustment is needed; otherwise, an adaptive $α$-adjustment restores control. We apply the method to 25 MDRC education trials and provide an R package, \\texttt{manytestsr}."}
{"id": "2602.20875", "categories": ["math.ST", "math.OC", "math.PR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20875", "abs": "https://arxiv.org/abs/2602.20875", "authors": ["Louis Sharrock", "Nikolas Kantas", "Grigorios A. Pavliotis"], "title": "Efficient Online Learning in Interacting Particle Systems", "comment": null, "summary": "We introduce a new method for online parameter estimation in stochastic interacting particle systems, based on continuous observation of a small number of particles from the system. Our method recursively updates the model parameters using a stochastic approximation of the gradient of the asymptotic log likelihood, which is computed using the continuous stream of observations. Under suitable assumptions, we rigorously establish convergence of our method to the stationary points of the asymptotic log-likelihood of the interacting particle system. We consider asymptotics both in the limit as the time horizon $t\\rightarrow\\infty$, for a fixed and finite number of particles, and in the joint limit as the number of particles $N\\rightarrow\\infty$ and the time horizon $t\\rightarrow\\infty$. Under additional assumptions on the asymptotic log-likelihood, we also establish an $\\mathrm{L}^2$ convergence rate and a central limit theorem. Finally, we present several numerical examples of practical interest, including a model for systemic risk, a model of interacting FitzHugh--Nagumo neurons, and a Cucker--Smale flocking model. Our numerical results corroborate our theoretical results, and also suggest that our estimator is effective even in cases where the assumptions required for our theoretical analysis do not hold."}
{"id": "2602.20452", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20452", "abs": "https://arxiv.org/abs/2602.20452", "authors": ["S. L. Wu", "Lian-Ao Wu"], "title": "A Unified Error Correction Code for Universal Quantum Computing with Identical Particles", "comment": "The manuscript was submitted to Physical Review Letters on June 13, 2025 (Manuscript ID: LF20042). One of the referee reports stated: In summary, ..., it lacks the broad impact and immediate relevance necessary for Physical Review Letters. I recommend that the manuscript be transferred to a more specialized journal, such as Physical Review A", "summary": "We present a universal fault-tolerant quantum computing architecture based on identical particle qubits (IPQs), where we find that the first-order IPQ - bath interaction fundamentally differs from the conventional first-order qubit-bath interaction. This key distinction necessitates a redesign of existing strategies to fight decoherence. We propose that the simplest quantum error correction code can be realized directly within the physical qubit, provided that conventional correction and restoration are generalized beyond unitary operations to employ physically implementable reversal operations -- naturally placing logical and physical qubits on equal footing. We further demonstrate that dynamical decoupling (DD) remains effective within this unified framework, and that a decoherence-free subspace (DFS) -- like structure emerges. Unlike previous approximate treatments, our analytically solvable IPQ-Bath model enables rigorous testing of these strategies, with numerical simulations validating their effectiveness."}
{"id": "2602.21132", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21132", "abs": "https://arxiv.org/abs/2602.21132", "authors": ["Xiaoning Kang", "Lulu Kang"], "title": "Robust and Sparse Generalized Linear Models for High-Dimensional Data via Maximum Mean Discrepancy", "comment": "22 pages, 5 tables, 2 figures", "summary": "High-dimensional datasets are frequently subject to contamination by outliers and heavy-tailed noise, which can severely bias standard regularized estimators like the Lasso. While Maximum Mean Discrepancy (MMD) has recently been introduced as a \"universal\" framework for robust regression, its application to high-dimensional Generalized Linear Models (GLMs) remains largely unexplored, particularly regarding variable selection. In this paper, we propose a penalized MMD framework for robust estimation and feature selection in GLMs. We introduce an $\\ell_1$-penalized MMD objective and develop two versions of the estimator: a full $O(n^2)$ version and a computationally efficient $O(n)$ approximation. To solve the resulting non-convex optimization problem, we employ an algorithm based on the Alternating Direction Method of Multipliers (ADMM) combined with AdaGrad. Through extensive simulation studies involving Gaussian linear regression and binary logistic regression, we demonstrate that our proposed methods significantly outperform classical penalized GLMs and existing robust benchmarks. Our approach shows particular strength in handling high-leverage points and heavy-tailed error distributions, where traditional methods often fail."}
{"id": "2602.20499", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20499", "abs": "https://arxiv.org/abs/2602.20499", "authors": ["Lirandë Pira", "Patrick Rebentrost"], "title": "Fundamentals of Quantum Machine Learning and Robustness", "comment": "This book chapter has been accepted for Springer Nature Quantum Robustness in Artificial Intelligence and will appear in the book: https://link.springer.com/book/9783032111524#accessibility-information", "summary": "Quantum machine learning (QML) sits at the intersection of quantum computing and classical machine learning, offering the prospect of new computational paradigms and advantages for processing complex data. This chapter introduces the fundamentals of QML for readers from both communities, establishing a shared conceptual foundation. We connect the worst-case, adversarial perspective from theoretical computer science with the physical principles of quantum systems, highlighting how superposition, entanglement, and measurement collapse influence learning and robustness. Special attention is given to adversarial robustness, understood as the ability of QML models to resist inputs designed to cause failure. We motivate the study of QML in adversarial settings, outlining distinctions between classical and quantum data and computations when the adversary is a core element. This chapter serves as a starting point to adversarial and robust quantum machine learning in subsequent chapters."}
{"id": "2602.21200", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21200", "abs": "https://arxiv.org/abs/2602.21200", "authors": ["Qingzhi Liu", "Gen Li", "Anastasia K. Yocum", "Melvin McInnis", "Brian D. Athey", "Veerabhadran Baladandayuthapani"], "title": "A Time-Varying and Covariate-Dependent Correlation Model for Multivariate Longitudinal Studies", "comment": "23 pages, 5 figures, 1 table", "summary": "In multivariate longitudinal studies, associations between outcomes often exhibit time-varying and individual level heterogeneity, motivating the modeling of correlations as an explicit function of time and covariates. However, most existing methods for correlation analysis fail to simultaneously capture the time-varying and covariate-dependent effects. We propose a Time-Varying and Covariate-Dependent (TiVAC) correlation model that jointly allows covariate effects on correlation to change flexibly and smoothly across time. TiVAC employs a bivariate Gaussian model where the covariate-dependent correlations are modeled semiparametrically using penalized splines. We develop a penalized maximum likelihood-based Newton-Raphson algorithm, and inference on time-varying effects is provided through simultaneous confidence bands. Simulation studies show that TiVAC consistently outperforms existing methods in accurately estimating correlations across a wide range of settings, including binary and continuous covariates, sparse to dense observation schedules, and across diverse correlation trajectory patterns. We apply TiVAC to a psychiatric case study of 291 bipolar I patients, modeling the time-varying correlation between depression and anxiety scores as a function of their clinical variables. Our analyses reveal significant heterogeneity associated with gender and nervous-system medication use, which varies with age, revealing the complex dynamic relationship between depression and anxiety in bipolar disorders."}
{"id": "2602.20508", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20508", "abs": "https://arxiv.org/abs/2602.20508", "authors": ["Elvira Bilokon", "Valeriia Bilokon", "Frank Großmann", "Jason R. Williams", "Denys I. Bondar"], "title": "Hilbert Space Black Hole Analog: Unidirectional Transport without Driving", "comment": "7 pages, 5 figures", "summary": "Black holes permit matter to cross their event horizon in only one direction. We show that interacting bosons in optical lattices with asymmetric barrier exhibit an analogous phenomenon, creating unidirectional quantum transport without external driving or dissipation. This directionality emerges purely from many-body interactions, which cause asymmetric projection of the initial state onto transport-enabled or transport-forbidden sectors. The resulting dynamics create an effective one-way boundary in Hilbert space, forming a quantum analog of a black-hole event horizon. Our results establish interactions as a fundamentally new route to directional transport, enabling coherent rectification in atomtronic circuits by the use of intrinsic properties of the system only."}
{"id": "2109.13124", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2109.13124", "abs": "https://arxiv.org/abs/2109.13124", "authors": ["Oliver J. Hines", "Karla Diaz-Ordaz", "Stijn Vansteelandt"], "title": "Parameterising the effect of a continuous treatment using average derivative effects", "comment": "Replication code is available from https://github.com/ohines/alse", "summary": "The average treatment effect (ATE) is commonly used to quantify the main effect of a binary treatment on an outcome. Extensions to continuous treatments are usually based on the dose-response curve or shift interventions, but both require strong overlap conditions and the resulting curves may be difficult to summarise. We focus instead on average derivative effects (ADEs) that are scalar estimands related to infinitesimal shift interventions requiring only local overlap assumptions. ADEs, however, are rarely used in practice because their estimation usually requires estimating conditional density functions. By characterising the Riesz representers of weighted ADEs, we propose a new class of estimands that provides a unified view of weighted ADEs/ATEs when the treatment is continuous/binary. We derive the estimand in our class that minimises the nonparametric efficiency bound, thereby extending optimal weighting results from the binary treatment literature to the continuous setting. We develop efficient estimators for two weighted ADEs that avoid density estimation and are amenable to modern machine learning methods, which we evaluate in simulations and an applied analysis of Warfarin dosage effects."}
{"id": "2602.20534", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20534", "abs": "https://arxiv.org/abs/2602.20534", "authors": ["Huining Zhang", "Dianzhen Cui", "W. Wang", "X. X. Yi"], "title": "Aging of coupled qubits", "comment": "10 pages, 8 figures", "summary": "The aging transition refers to the shift from an oscillatory state to a globally ceased state due to some forms of deterioration in classical physics. Similar behavior has also been observed in quantum oscillators. Although it has received extensive attention in coupled oscillator systems, it has not yet been studied in coupled qubits. In this manuscript, we explore the aging transition in a network of coupled qubits. Our model describes {numerous} qubits driven by a laser, with both dissipative and coherent qubit-qubit couplings. The ratio of inactive qubits to total qubits and the population in the excited state of the qubits are employed to characterize the aging transition. We find a transition where the population in the excited states suddenly drops when the ratio exceeds a threshold. This behavior is intriguing and contrasts with coupled oscillators, where no sudden drop is observed. Additionally, we demonstrate how the couplings and driving laser influence the threshold. The underlying physics of the sudden drop is elucidated. The region where the aging transition occurs is determined based on stability analysis theory."}
{"id": "2602.20371", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.20371", "abs": "https://arxiv.org/abs/2602.20371", "authors": ["Magid Sabbagh", "David A. Stephens"], "title": "Semi-parametric Bayesian inference under Neyman orthogonality", "comment": "18 pages", "summary": "The validity of two-step or plug-in inference methods is questioned in the Bayesian framework. We study semi-parametric models where the plug-in of a non-parametrically modelled nuisance component is used. We show that when the nuisance and targeted parameters satisfy a Neyman orthogonal score property, the approach of cutting feedback through a two-step procedure is a valid way of conducting Bayesian inference. Our method relies on a non-parametric Bayesian formulation based on the Dirichlet process and the Bayesian bootstrap. We show that the marginal posterior of the targeted parameter exhibits good frequentist properties despite not accounting for the inferential uncertainty of the nuisance parameter. We adopt this approach in Bayesian causal inference problems where the nuisance propensity score model is estimated to obtain marginal inference for the treatment effect parameter, and demonstrate that a plug-in of the propensity score has a negligible effect on marginal posterior inference for the causal contrast. We investigate the absence of Neyman orthogonality and exploit our findings to show that in conventional two-step procedures, the posterior distribution converges under weaker restrictions than those needed in the frequentist sequel. For a simple family of useful scores, we demonstrate that even in the absence of Neyman orthogonality, the posterior distribution is asymptotically unchanged by the estimation of the nuisance parameter, merely provided the latter estimator is consistent."}
{"id": "2602.20546", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20546", "abs": "https://arxiv.org/abs/2602.20546", "authors": ["Shifan Xu", "Kun Liu", "Patrick Rall", "Zhiyang He", "Yongshan Ding"], "title": "Distilling Magic States in the Bicycle Architecture", "comment": null, "summary": "Magic State Distillation is considered to be one of the promising methods for supplying the non-Clifford resources required to achieve universal fault tolerance. Conventional MSD protocols implemented in surface codes often require multiple code blocks and lattice surgery rounds, resulting in substantial qubit overhead, especially at low target error rates.\n  In this work, we present practical magic state distillation factories on Bivariate Bicycle (BB) codes that execute Pauli-measurement-based Clifford circuits inside a single BB code block. We formulate distillation circuit design as a joint optimization of logical qubit mapping, gate scheduling, measurement nativization, and protocol compression via qubit recycling. Based on detailed resource analysis and simulations, our BB factories have space-time volume comparable to that of leading distillation factories while delivering lower target error at a smaller qubit footprint, and are particularly compelling as second-round distillers following magic state cultivations."}
{"id": "2602.20844", "categories": ["math.ST", "cs.IT", "math.PR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20844", "abs": "https://arxiv.org/abs/2602.20844", "authors": ["Subhrosekhar Ghosh", "Rathindra Nath Karmakar", "Samriddha Lahiry"], "title": "Maximum entropy based testing in network models: ERGMs and constrained optimization", "comment": null, "summary": "Stochastic network models play a central role across a wide range of scientific disciplines, and questions of statistical inference arise naturally in this context. In this paper we investigate goodness-of-fit and two-sample testing procedures for statistical networks based on the principle of maximum entropy (MaxEnt). Our approach formulates a constrained entropy-maximization problem on the space of networks, subject to prescribed structural constraints. The resulting test statistics are defined through the Lagrange multipliers associated with the constrained optimization problem, which, to our knowledge, is novel in the statistical networks literature.\n  We establish consistency in the classical regime where the number of vertices is fixed. We then consider asymptotic regimes in which the graph size grows with the sample size, developing tests for both dense and sparse settings. In the dense case, we analyze exponential random graph models (ERGM) (including the Erdös-Rènyi models), while in the sparse regime our theory applies to Erd{ö}s-R{è}nyi graphs.\n  Our analysis leverages recent advances in nonlinear large deviation theory for random graphs. We further show that the proposed Lagrange-multiplier framework connects naturally to classical score tests for constrained maximum likelihood estimation. The results provide a unified entropy-based framework for network model assessment across diverse growth regimes."}
{"id": "2602.20553", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20553", "abs": "https://arxiv.org/abs/2602.20553", "authors": ["Edward Parker", "Nicholas A. O'Donoughue", "Alvin Moon", "Nicolas M. Robles"], "title": "Assessing the Practical Feasibility of the Clader-Jacobs-Sprouse Quantum Algorithm for Calculating Radar Cross Sections", "comment": "44 pages, 6 figures", "summary": "In 2013, Clader, Jacobs, and Sprouse developed a quantum computing algorithm that solves electromagnetic scattering problems exponentially faster than the best known classical algorithm for that problem. We examine this quantum algorithm's potential practical feasibility for modeling a target's radar cross section. Doing so could be important for modeling and predicting radar behavior against emerging targets."}
{"id": "2602.20875", "categories": ["math.ST", "math.OC", "math.PR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.20875", "abs": "https://arxiv.org/abs/2602.20875", "authors": ["Louis Sharrock", "Nikolas Kantas", "Grigorios A. Pavliotis"], "title": "Efficient Online Learning in Interacting Particle Systems", "comment": null, "summary": "We introduce a new method for online parameter estimation in stochastic interacting particle systems, based on continuous observation of a small number of particles from the system. Our method recursively updates the model parameters using a stochastic approximation of the gradient of the asymptotic log likelihood, which is computed using the continuous stream of observations. Under suitable assumptions, we rigorously establish convergence of our method to the stationary points of the asymptotic log-likelihood of the interacting particle system. We consider asymptotics both in the limit as the time horizon $t\\rightarrow\\infty$, for a fixed and finite number of particles, and in the joint limit as the number of particles $N\\rightarrow\\infty$ and the time horizon $t\\rightarrow\\infty$. Under additional assumptions on the asymptotic log-likelihood, we also establish an $\\mathrm{L}^2$ convergence rate and a central limit theorem. Finally, we present several numerical examples of practical interest, including a model for systemic risk, a model of interacting FitzHugh--Nagumo neurons, and a Cucker--Smale flocking model. Our numerical results corroborate our theoretical results, and also suggest that our estimator is effective even in cases where the assumptions required for our theoretical analysis do not hold."}
{"id": "2602.20568", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20568", "abs": "https://arxiv.org/abs/2602.20568", "authors": ["Huining Zhang", "X. Z. Hao", "X. X. Yi"], "title": "Effect of atom-oscillator interaction on the aging transition in coupled oscillators", "comment": "11 pages, 8 figures", "summary": "Oscillators are often employed as a model of radiation fields, which may couple to an atom and play an important role for creating and manipulating nonclassical states in quantum metrology, quantum simulation, and quantum information. Aging transitions in coupled oscillators have been studied extensively in both the classical and quantum contexts. It is well known that the onset of aging transitions can be modulated by the dissipative coupling between oscillators. In this study, we propose an alternative way to modulate the aging transition through coherent couplings between a two-level atom and the oscillators. Our findings reveal that, compared to atom-free systems in both classical and quantum regimes, the atom-oscillator coherent interaction reduces the inactive-to-total oscillator ratio required for aging transitions. Analytical results of the transition for both the classical oscillators and quantum oscillators suggest that the decay rate of the atom and the atom-oscillator coupling strength jointly change the aging transition point. The physics behind the observation is also elucidated in this article. Our research introduces a readily implementable strategy for manipulating aging transitions in more intricate systems, thereby advancing the control and understanding of these critical transitions in quantum technologies."}
{"id": "2602.20896", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.20896", "abs": "https://arxiv.org/abs/2602.20896", "authors": ["Paul Axmann", "Bruno Ebner", "Eduardo García-Portugués"], "title": "On Stein's test of uniformity on the hypersphere", "comment": "31 pages, 5 figures, 4 tables", "summary": "We propose a new test of uniformity on the hypersphere based on a Stein characterization associated with the Laplace--Beltrami operator. We identify a sufficient class of test functions for this characterization, linked to the moment generating function. Exploiting the operator's eigenfunctions to obtain a harmonic decomposition in terms of Gegenbauer polynomials, we show that the proposed procedure belongs to the class of Sobolev tests. We derive closed-form expressions for the distribution of the test statistic under the null hypothesis and under fixed alternatives. To enhance power against a range of alternatives, we introduce a tuning parameter into the characterization and study its impact on rejection probabilities. We discuss data-driven strategies for selecting this parameter to maximize rejection rates for a given alternative and compare the resulting performance with that of related parametric tests. Additional numerical experiments compare the proposed test with competing Sobolev-class procedures, highlighting settings in which it offers clear advantages."}
{"id": "2602.20605", "categories": ["quant-ph", "math-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.20605", "abs": "https://arxiv.org/abs/2602.20605", "authors": ["Zhijian Lai", "Hantao Nie", "Jiayuan Wu", "Dong An"], "title": "Quantum circuit design from a retraction-based Riemannian optimization framework", "comment": "28 pages", "summary": "Designing quantum circuits for ground state preparation is a fundamental task in quantum information science. However, standard Variational Quantum Algorithms (VQAs) are often constrained by limited ansatz expressivity and difficult optimization landscapes. To address these issues, we adopt a geometric perspective, formulating the problem as the minimization of an energy cost function directly over the unitary group. We establish a retraction-based Riemannian optimization framework for this setting, ensuring that all algorithmic procedures are implementable on quantum hardware. Within this framework, we unify existing randomized gradient approaches under a Riemannian Random Subspace Gradient Projection (RRSGP) method. While recent geometric approaches have predominantly focused on such first-order gradient descent techniques, efficient second-order methods remain unexplored. To bridge this gap, we derive explicit expressions for the Riemannian Hessian and show that it can be estimated directly on quantum hardware via parameter-shift rules. Building on this, we propose the Riemannian Random Subspace Newton (RRSN) method, a scalable second-order algorithm that constructs a Newton system from measurement data. Numerical simulations indicate that RRSN achieves quadratic convergence, yielding high-precision ground states in significantly fewer iterations compared to both existing first-order approaches and standard VQA baselines. Ultimately, this work provides a systematic foundation for applying a broader class of efficient Riemannian algorithms to quantum circuit design."}
{"id": "2602.20612", "categories": ["quant-ph", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.20612", "abs": "https://arxiv.org/abs/2602.20612", "authors": ["Motohiko Ezawa"], "title": "Non-Clifford symmetry protected topological higher-order cluster states in multi-qubit measurement-based quantum computation", "comment": "19 pages, 11 figures", "summary": "A cluster state is a strongly entangled state, which is a source of measurement-based quantum computation. It is generated by applying controlled-Z (CZ) gates to the state $\\left\\vert ++\\cdots +\\right\\rangle $. It is protected by the $\\mathbb{Z}_{2}^{\\text{even}}\\times \\mathbb{Z}_{2}^{ \\text{odd}}$ symmetry. By applying general quantum gates to the state $ \\left\\vert ++\\cdots +\\right\\rangle $, we systematically obtain a general short-range entangled cluster state. If we use a non-Clifford gate such as the controlled phase-shift gate, we obtain a non-Clifford cluster state. Furthermore, if we use the controlled-controlled Z (CCZ) gate instead of the CZ gate, we obtain non-Clifford cluster states with five-body entanglement. We generalize it to the C$^{N}$Z gate, where $(2N+1)$-body entangled states are generated. The $\\mathbb{Z}_{2}^{\\text{even}}\\times \\mathbb{Z}_{2}^{\\text{odd}}$ symmetry is non-Clifford for $N\\geq 3$. We demonstrate that there emerge $2^{2N}$ fold degenerate ground states for an open chain, indicating the emergence of $N$ free spins at each edge. They can be used as an $N$-qubit input and an $N$-qubit output in measurement-based quantum computation. We also study the non-invertible symmetry, the Kennedy-Tasaki transformation and the string-order parameter in addition to the $\\mathbb{Z}_{2}^{\\text{even}}\\times \\mathbb{Z}_{2}^{\\text{odd}}$ symmetry in these models."}
{"id": "2602.20614", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20614", "abs": "https://arxiv.org/abs/2602.20614", "authors": ["J. Thirunirai Selvam", "S. Saravana Veni", "Ria Rushin Joseph"], "title": "First- and Second-Order Digital Quantum Simulation of Three-Level Jaynes-Cummings Dynamics on Superconducting Quantum Processors", "comment": null, "summary": "This work presents a digital quantum simulation of a three-level atomic system interacting with a single-mode electromagnetic field based on the Jaynes-Cummings model, implemented on IBM Quantum superconducting processors. A qutrit is encoded using two physical qubits to represent the atomic states, while an additional qubit encodes the truncated field mode, enabling the realization of effective $Λ$-type atomic dynamics.The continuous-time light-matter interaction is implemented in a digital form by discretizing the evolution using Suzuki-Trotter decomposition. In contrast to an analog realization, the digital simulation replaces the continuous evolution with a sequence of quantum gates whose parameters are explicitly controlled. Phase evolution arising from the interaction Hamiltonian is digitally encoded using calibrated $R_Z$ gates, whose rotation angles are fixed by the physically relevant coupling scale and the chosen Trotter time step.State preparation is achieved using Hadamard and parametrized rotation gates, while the interaction dynamics are implemented through controlled operations. A comparative analysis between first- and second-order Trotter implementations reveals a trade-off between digital accuracy and hardware-induced noise. Overall, the results demonstrate that calibrated gate operations and noise-aware circuit design enable reliable digital simulation of multi-level light-matter interactions on noisy intermediate-scale quantum platforms."}
{"id": "2602.20661", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20661", "abs": "https://arxiv.org/abs/2602.20661", "authors": ["Luca Spagnoli", "Alessandro Roggero", "Nathan Wiebe"], "title": "Qudit stabiliser codes for $\\mathbb{Z}_N$ lattice gauge theories with matter", "comment": null, "summary": "In this work we extend the connection between Quantum Error Correction (QEC) and Lattice Gauge Theories (LGTs) by showing that a $\\mathbb{Z}_N$ gauge theory with prime dimension $N$ coupled to dynamical matter can be expressed as a qudit stabilizer code. Using the stabilizer formalism we show how to formulate an exact mapping of the encoded $\\mathbb{Z}_N$ gauge theory onto two different bosonic models, uncovering a logical duality generated by error correction itself. From this perspective, quantum error correction provides a unifying language to expose dual descriptions of lattice gauge theories. In addition, we generalize earlier $\\mathbb{Z}_2$ constructions on qubits to $\\mathbb{Z}_N$ on $N$-level qudits and demonstrate how universal fault-tolerant gates can be implemented via state injection between compatible qudit codes."}
{"id": "2602.20674", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20674", "abs": "https://arxiv.org/abs/2602.20674", "authors": ["Jakob Kaltoft Søndergaard", "René Bødker Christensen", "Petar Popovski"], "title": "Task Concurrency and Compatibility in Measurement-Based Quantum Networks", "comment": "To be published in 2026 International Conference on Quantum Communications, Networking, and Computing (QCNC)", "summary": "Measurement-Based Quantum Networks (MBQNs) rely on multipartite pre-shared entanglement resources to satisfy entanglement requests. Traditional designs optimize these resources for individual tasks, neglecting that multiple tasks may arrive concurrently and compete for the same entanglement. We introduce compatibility as a design-level metric, capturing whether concurrent tasks can be satisfied by the same entanglement resources. We define a worst-case notion of compatibility where nodes are prevented from coordinating after task arrival and illustrate why tasks may be incompatible. Furthermore, we explore compatibility extensions that account for stochastic arrivals and the capability to supplement the pre-shared entanglement with additional entanglement on-demand, and show that incompatibility differs structurally dependent on the set of concurrent tasks. We argue that compatibility should be used for resource state design, building the foundation for determining which task pairs the network should support with pre-shared entanglement and which require execution-time coordination. Numerical simulations demonstrate this potential, with $(G,1)$-compatibility achieving a 40%-55% gain in simultaneously supported tasks relative to the single-task baseline. By incorporating compatibility as a fundamental design objective, quantum networks can move beyond single-task optimization towards scalable, robust architectures that effectively balance proactive entanglement distribution and supplemental reactive coordination."}
{"id": "2602.20694", "categories": ["quant-ph", "cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.20694", "abs": "https://arxiv.org/abs/2602.20694", "authors": ["Samuel O. Scalet"], "title": "Spatial Entanglement Sudden Death in Spin Chains at All Temperatures", "comment": "19 pages, 2 figures", "summary": "We prove a finite entanglement length for the Gibbs state of any local Hamiltonian on a spin chain at any finite temperature: After removing an interval of size at least equal to the entanglement length, the remaining left and right half-chains are in a separable state."}
{"id": "2602.20763", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20763", "abs": "https://arxiv.org/abs/2602.20763", "authors": ["Xiaofen Huang", "Xishun Zhu", "Bin Chen", "Naihuan Jing", "Shao-Ming Fei"], "title": "A note on entanglement detection via the generalized realignment moments", "comment": null, "summary": "The experimental detection of quantum entanglement is of great importance in quantum information processing. We present two separability criteria based on the generalized realignment moments. By incorporating additional parameters, these criteria prove to be more flexible and stronger than some of existing ones. Detailed examples are given to demonstrate their availability and feasibility for entanglement detection."}
{"id": "2602.20772", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2602.20772", "abs": "https://arxiv.org/abs/2602.20772", "authors": ["Yanyang Wang", "Feng Gao", "Kui Tuo", "Wei Li"], "title": "Generative Deep Learning for the Two-Dimensional Quantum Rotor Model", "comment": null, "summary": "The advancement of diverse generative deep learning models and their variants has furnished substantial insights for investigating quantum many-body problems. In this work, we design two models based on the foundational architecture of generative adversarial networks (GANs) to investigate the ground-state properties and phase transition characteristics of the two-dimensional quantum rotor model (QRM). Within a semi-supervised learning framework, we incorporate multiple layers of transposed convolutions in the generator, enabling the conditional GAN to more efficiently extract low-dimensional encoded information. Analysis of one-dimensional latent variables associated with ground-state samples for different system sizes allows us to pinpoint the location of the critical point. In addition, we introduce dynamically adaptive weighting factors related to the distributional characteristics into the loss function of the deep convolutional GAN, and utilize upsampling techniques to enlarge the generated sample sizes. Comparisons of the optimization processes for mean magnetization and potential energy density across different magnetization regimes of QRM demonstrate that our model can efficiently generate valid ground-state samples, significantly reducing computational time. Our results highlight the promising potential of generative deep learning in quantum phase transition research, especially in critical point identification and the auxiliary generation of simulation data for quantum many-body models."}
{"id": "2602.20781", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20781", "abs": "https://arxiv.org/abs/2602.20781", "authors": ["Nhat A. Nghiem"], "title": "Toward speedup without quantum coherent access", "comment": "arXiv admin note: substantial text overlap with arXiv:2504.00833", "summary": "Along with the development of quantum technology, finding useful applications of quantum computers has been a central pursuit. Despite various quantum algorithms have been developed, many of them often require strong input assumptions, which is hardware demanding. In particular, recent advances on dequantization have revealed that the quantum advantage is more of a mere artifact of strong input assumptions. In this work, we propose a variant of these algorithms, leveraging both classical and quantum resources. Provided the classical knowledge (the entries) of the matrix/vector of interest, a classical procedure is used to pre-process this information. Then they are fed into a quantum circuit which is shown to be a block encoding of the matrix of interest. From this block-encoding, we show how to use it to tackle a wide range of problems, including principal component analysis, linear equation solving, Hamiltonian simulation, preparing ground state, and data fitting. We also analyze our protocol, showing that both the classical and quantum procedure can achieve logarithmic complexity in the input dimension, thus implying its potential for near term realization. We then discuss several implications and corollaries of our result. First,, our results suggest there are certain matrices/Hamiltonians where our method can provide exponential improvement compared to the existing ones with respect to the sparsity. Regarding dense linear systems, our method achieves exponential speed-up with respect to the inverse of error tolerance, compared to the best previously known quantum algorithm for dense systems. Last, and most importantly, regarding quantum data fitting, we show how the output of our quantum algorithms can be leveraged to predict unseen data. Thus, it provides an end-to-end application, which has been an open aspect of the previous quantum data fitting algorithm."}
{"id": "2602.20785", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20785", "abs": "https://arxiv.org/abs/2602.20785", "authors": ["Tangrui Liao", "Junhao Yang", "Tinggui Zhang", "Xiaofen Huang"], "title": "Quantum coherence of mixed states under noisy channels in noninertial frames", "comment": null, "summary": "We focus our attention on tripartite mixed states as initial states, and apply coherence concurrence to investigate quantum coherence properties in the background of a Schwarzschild black hole under phase damping, phase flip and bit flip channels, respectively. Several analytic complementary relationships based on coherence concurrence for tripartite subsystems are proposed. In the case of the bit flip channel, the behavior of the coherence concurrence is similar to the one of the phase damping channel, the accessible coherence concurrence always degrades as the Hawking acceleration rising, but sudden death never occurs, while the inaccessible coherence increases from zero monotonically. Interestingly, the coherence concurrence is decreasing at first and then increasing as the decay probability rising under phase flip channel. Unlike the case of tripartite pure states, the coherence concurrence of mixed state with X shape is equal to $l_1$ -norm of coherence."}
{"id": "2602.20819", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20819", "abs": "https://arxiv.org/abs/2602.20819", "authors": ["Yuxuan Xiong", "Zhiling Pi", "Tinggui Zhang", "Xiaofen Huang"], "title": "Quantum discord of mixed states under noisy channels in the curved spacetime", "comment": null, "summary": "We focus our attention on two-qubit mixed states as initial states, and apply the geometric measure of quantum discord to investigate quantum discord properties in the background of a Schwarzschild black hole under phase damping, phase flip and bit flip channels, respectively. Several analytical complementary relationships based on quantum discords for bipartite subsystems are proposed. For the three channel noises, the behaviors of discords are similar, the accessible discords always degrade as the Hawking acceleration rising, but sudden death never occurs, while the inaccessible discords increase from zero monotonically. Interestingly, in the case of the bit flip channel and phase flip channel, the discords perform symmetrically with the decay probability rising."}
{"id": "2602.20824", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20824", "abs": "https://arxiv.org/abs/2602.20824", "authors": ["Alexander Wolf", "Maxim A. Efremov"], "title": "Mach-Zehnder interferometer for in-situ characterization of atom traps", "comment": null, "summary": "Manipulating cold atoms in traps is a key tool for numerous realizations of quantum simulators and quantum sensors. They require accurate modeling and characterization of the underlying trapping potentials. We introduce a technique based on the Mach-Zehnder interferometer for in-situ characterization of weakly anharmonic potentials. By simulating the interferometer in an optical dipole trap, we can accurately determine its trap frequency and upper bounds onto anharmonicity magnitudes."}
{"id": "2602.20852", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20852", "abs": "https://arxiv.org/abs/2602.20852", "authors": ["Santiago Beltrán-Romero", "Stefan Löffler", "Dennis Rätzel", "Philipp Haslinger"], "title": "Simulating Microwave-Controlled Spin Imaging with Free-Space Electrons", "comment": "12 pages, 3 figures", "summary": "Coherent spin resonance techniques, such as nuclear and electron spin resonance spectroscopy, have revolutionized non-invasive imaging by providing spectrally resolved information about spin dynamics. Motivated by the recent emergence of electron microscopy methods capable of sensing microwave-excitations, we establish a theoretical framework for Spin Resonance Spectroscopy (SRS) in transmission electron microscopy (TEM). This technique combines microwave pump fields with focused electron probe beams to enable state-selective spin imaging at the atomic scale. Using scattering theory, we model the interaction between free-space electrons and electron spin systems, capturing both elastic and inelastic processes. The strongest effect of the spin system on the free electron is a magnetic phase shift. Our simulations demonstrate that phase shifts from individual electron spins are detectable in both image mode and diffraction mode. In principle, differential measurements under microwave control allow the extraction of local resonance frequencies that are influenced by the surrounding spin environment. By evaluating the Classical Fisher Information (CFI), we identify imaging conditions that maximize the signal-to-noise ratio (SNR), showing how defocus and beam width affect the measurement sensitivity. These findings establish a foundation for integrating SRS with high-resolution TEM, bridging spin spectroscopy and atomic-scale imaging, and enabling new capabilities in quantum spin research and nanoscale materials characterization."}
{"id": "2602.20881", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20881", "abs": "https://arxiv.org/abs/2602.20881", "authors": ["Eoin Carolan", "Nathan Keenan", "Gabriele Cenedese", "Giuliano Benenti"], "title": "$σ$-VQE: Excited-state preparation of quantum many-body scars with shallow circuits", "comment": "15 pages, 8 figures", "summary": "We present and benchmark a type of variational quantum eigensolver (VQE), which we denote the $σ$-VQE. It is designed to target mid-spectrum eigenstates and prepare quantum many-body scar states. The approach leverages the fact that noisy intermediate-scale quantum devices are limited in their ability to generate generic highly-entangled states. This modified VQE pairs a low-depth circuit with an energy-selective objective that explicitly penalizes energy variance around a chosen target energy. The cost function exploits the limited expressibility of the shallow circuit as atypical low-entanglement eigenstates such as scar states are preferentially selected. We validate this mechanism across two complementary families of models that contain many-body scar states: the Shiraishi-Mori embedding approach, and the matrix-product state parent Hamiltonian construction. We define an unbiased estimation scheme for the nonlinear cost function that is compatible with qubit-wise commuting grouping and bitstring reuse. A proof-of-principle demonstration using a small-system instance was carried out on IBM Fez (Heron r2 QPU). These results motivate its use both as a practical \"scar detector\" and as a state-preparation primitive for initializing nonthermal eigenstate-supported dynamics."}
{"id": "2602.20900", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20900", "abs": "https://arxiv.org/abs/2602.20900", "authors": ["Twan Kroll", "Jonas Helsen"], "title": "Error correction with brickwork Clifford circuits", "comment": "24 pages, see also the related work of Liu et al. (specifically the journal version [PRX Quantum 7, 010331 (2026)])", "summary": "We prove that random 1D Clifford brickwork circuits form (in expectation) good approximate quantum error correction codes in logarithmic depth. Our proof makes use of the statistical mechanics techniques for random circuits developed by Dalzell et al. [PRX Quantum 3, 010333], adapted extensively to our own purpose. We also consider exact error correction, where we give matching upper and lower bounds for the required depth in which random 1D Clifford brickwork circuits become error correcting."}
{"id": "2602.20905", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20905", "abs": "https://arxiv.org/abs/2602.20905", "authors": ["Asghar Ullah", "Özgür E. Müstecaplıoğlu"], "title": "Enhancing low-temperature quantum thermometry and magnetometry via quadratic interactions in optomechanical-like systems", "comment": "14 pages, 9 figures; comments are welcome", "summary": "Standard optomechanical sensors operating in the low-temperature regime often face fundamental precision limits imposed by vacuum fluctuations. Here, we demonstrate that moving beyond conventional radiation-pressure interactions and exploiting quadratic coupling can surpass these limits, generating intrinsic squeezing and non-Gaussian features in the probe state. We study quantum thermometry and magnetometry in a coupled two-resonator system, focusing on the estimation of a thermal bath temperature and an external magnetic field. The resonators are assumed to be in thermal equilibrium with a common bath, while a weak magnetic field acts on one of the resonators. We perform measurements on a single resonator, which serves as the probe for estimating both parameters. We compute the quantum Fisher information of the probe for two different interaction models between the resonators. Our results show that the counter-rotating terms in the quadratic interaction naturally induce squeezing at intermediate coupling and strong non-Gaussian correlations as the coupling increases further. These effects yield orders-of-magnitude enhancement in sensitivity in the low-temperature and weak-field regimes compared to standard radiation-pressure couplings. Finally, we investigate multiparameter estimation and find that, although the optimal measurements remain compatible, statistical correlations between parameters prevent the simultaneous estimation of temperature and magnetic field from attaining single-parameter precision."}
{"id": "2602.20927", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.20927", "abs": "https://arxiv.org/abs/2602.20927", "authors": ["Yifeng Du", "Yang Hu", "Yufeng Liu", "Wenhan Yan", "Jinghao Zhang", "Shining Zhu", "Xiao-Song Ma"], "title": "Experimental Asynchronous Measurement-Device-Independent Quantum Cryptographic Conferencing", "comment": null, "summary": "The quantum cryptographic conferencing (QCC) protocol, which distributes identical secure keys to user groups, is a crucial component of the quantum network. Previous experimental works have implemented the measurement-device-independent (MDI) QCC, of which the key rate in an $N$-user network scales down as $R\\sim O(η^N)$, respectively. Building on the MDI QCC protocol, the asynchronous MDI (AMDI) QCC protocol theoretically integrates the mode pairing scheme into QCC, significantly boosting the key rate to $R\\sim O(η)$, which is independent of the number of users, and thus demonstrating greater application potential. Experimentally, in this work, we implement the three-user AMDI QCC network without global phase tracking by adopting the fast Fourier transform-based frequency difference estimation and the phase drift compensation technique. Finally, we achieve a key rate of about $4.470\\times10^{-9}$ bits per pulse under a maximum overall loss of about 59.6 dB. This work provides a scalable solution for the development of large-scale quantum communication networks in the future."}
{"id": "2602.20941", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20941", "abs": "https://arxiv.org/abs/2602.20941", "authors": ["Andrés Muñoz-Moller", "Leevi Leppäjärvi", "Teiko Heinosaari"], "title": "Adversarial Information Gain in Non-ideal Quantum Measurements", "comment": null, "summary": "Performing a quantum measurement yields two different results: a classical outcome drawn from a probability distribution, according to Born's rule, and a quantum outcome corresponding to the post-measurement state. Quantum devices that provide both outcomes can be described through quantum instruments. In a realistic scenario, one can expect that the observer's obtained classical and quantum outcomes are non-ideal: this can be due to experimental limitations, but could also be explained by adversarial interference, that is, a second party that disturbs the device through a concealed measurement to obtain information. The second scenario can be interpreted through quantum compatibility, as it implies that both the observer's instrument and the adversary's measurement can be performed simultaneously. In this work, we show how the noise of the observer's device relates to the amount of information that the adversary can obtain. We study scenarios in which the adversary aims to acquire information on the same basis as the observer's measurement, or on a mutually unbiased basis with respect to the observer's basis. In both cases, we derive necessary and sufficient conditions for the compatibility of a single qubit non-ideal quantum instrument and a noisy meter, from which we obtain the maximum amount of information that the adversary can extract in terms of the noise parameters of the observer's instrument. Finally, we provide the device implementation from the adversary's point of view for the same basis scenario."}
{"id": "2602.20962", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20962", "abs": "https://arxiv.org/abs/2602.20962", "authors": ["Patrick Folge", "Laura Serino", "Ladislav Mišta", "Benjamin Brecht", "Christine Silberhorn", "Jaroslav Řeháček", "Zdeněk Hradil"], "title": "Quantum-limited detection of arrival time and carrier frequency of time-dependent signals", "comment": "11 pages, 7 figures", "summary": "Precise measurements of both the arrival time and carrier frequency of light pulses are essential for time-frequency-encoded quantum technologies. Quantum mechanics, however, imposes fundamental limits on the simultaneous determination of these quantities. In this work, we derive and experimentally verify the quantum uncertainty bounds governing joint time-frequency measurements. We show that when detection is restricted to finite time windows, the problem is naturally described by a quantum rotor, rendering the commonly used Heisenberg uncertainty relation inapplicable. We further propose an optimal detection scheme that saturates these fundamental limits. By sampling the Q-function, we demonstrate the reconstruction of the Wigner function beyond the harmonic oscillator. Using an experimental implementation based on a quantum pulse gate, we confirm that the proposed scheme approaches the ultimate quantum limit for simultaneous time-frequency measurements. These results provide a new framework for joint time-frequency detection with direct implications for precision measurements and quantum information processing."}
{"id": "2602.20987", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20987", "abs": "https://arxiv.org/abs/2602.20987", "authors": ["Tianfeng Feng", "Yue Cao", "Wenjun Yu", "Junkai Zeng", "Xiaopeng Li", "Xiu-Hao Deng", "Qi Zhao"], "title": "Entanglement-Induced Resilience of Quantum Dynamics", "comment": "29 pages, 11 figures, 1 tatble", "summary": "Quantum many-body devices suffer from imperfections that destabilize dynamics and limit scalability. We show that the dynamical growth of entanglement can intrinsically protect generic quantum dynamics against coherent and perturbative noise. Through rigorous theoretical analysis of general quantum dynamics and numerical simulations of spin chains and fermionic lattices, we prove that entanglement-entropy growth confines the influence of local Hamiltonian perturbations, thereby suppressing errors in dynamical errors. The degree of protection correlates quantitatively with the entanglement entropy of subsystems on which the perturbations act, and applies broadly to both analog quantum simulators and real-time control protocols. This entanglement-induced resilience is conceptually distinct from quantum error correction or dynamical decoupling: it passively leverages native many-body correlations without additional qubits, measurements, or control overhead. Our results reveal a generic mechanism linking entanglement growth to dynamical stability and provide practical guidelines for designing noise-resilient quantum devices."}
{"id": "2602.20997", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20997", "abs": "https://arxiv.org/abs/2602.20997", "authors": ["Masahito Hayashi", "Longyang Cao", "Baichu Yu", "Yuan-Yuan Zhao"], "title": "Characterization-free classification and identification of the environment between two quantum players", "comment": "17 pages, 4 figures", "summary": "Classifying the causal structure of quantum channels is essential for verifying quantum networks and certifying quantum resources. We introduce a characterization-free protocol enabling two isolated players, Alice and Bob, to classify and identify the definite-order strategy adopted by an unknown environment mediating their channels. Without assuming knowledge of their devices or the environment, the players infer the causal order solely from input-output statistics by testing Markovian conditions that we prove are necessary and sufficient for each strategy class. Remarkably, we prove that even with a minimal random channel consisting of two-outcome POVMs and two-state preparations, the protocol retains full performance with probability one. We experimentally demonstrate the protocol on an optical platform, reliably distinguishing between several strategies. Our results provide a strong and robust tool for causal inference in quantum networks."}
{"id": "2602.21007", "categories": ["quant-ph", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.21007", "abs": "https://arxiv.org/abs/2602.21007", "authors": ["Masaki Nagai", "Hideaki Kawaguchi", "Shin Nishio", "Takahiko Satoh"], "title": "Telemetry-Based Server Selection in the Quantum Internet via Cross-Layer Runtime Estimation", "comment": "13 pages, 10 figures", "summary": "The Quantum Internet will allow clients to delegate quantum workloads to remote servers over heterogeneous networks, but choosing the server that minimizes end-to-end execution time is difficult because server processing, feedforward classical communication, and entanglement distribution can overlap in protocol-dependent ways and shift the runtime bottleneck. We propose $T_{\\max}$, a lightweight runtime score that sums coarse telemetry from multiple layers to obtain a conservative ranking for online server selection without calibrating weights for each deployment. Using NetSquid discrete-event simulations of a modified parameter-blind VQE (PB-VQE) workload, we evaluate $T_{\\max}$ on pools of 10,000 heterogeneous candidates (selecting among up to 100 per decision) across crossover and bottleneck-dominated regimes, including temporal jitter scenarios and jobs with multiple shots. $T_{\\max}$ achieves single-digit mean regret normalized by the oracle (below 10%) in both regimes and remains in the single-digit range under classical communication latency jitter for multi-shot jobs, while performance degrades for single-shot jobs under severe jitter. To connect performance to deployment planning, we derive an operating map based on requirements relating distance and entanglement rate requirements to protocol level counts, quantify how simple multiuser contention shifts the crossover, and use Sobol global sensitivity analysis to identify regime-dependent bottlenecks. These findings suggest that simple cross-layer telemetry can enable practical server selection while providing actionable provisioning guidance for emerging Quantum Internet services."}
{"id": "2602.21016", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21016", "abs": "https://arxiv.org/abs/2602.21016", "authors": ["C. Fajardo", "M. Paraschiv"], "title": "Restriction-Based Certificate of Bipartite Schmidt Rank in Hypergraph States", "comment": "10 pages", "summary": "We investigate bipartite entanglement in qubit hypergraph states across an arbitrary fixed bipartition. Using the real equally weighted (REW) representation, the Schmidt rank across the cut can be computed as the real rank of a phase-cleaned cross-cut sign matrix. Whereas graph states admit an exact cut-rank rule, because the cross-cut phase is purely bilinear, hypergraph states typically contain higher-degree cross-cut interactions, for which the cut-rank rule fails. Our approach certifies entanglement by fixing a single computational-basis assignment on a subset of qubits, thereby selecting a submatrix on an active slice. When this restriction removes all higher-degree cross-cut residues, the remaining cross-cut phase becomes bilinear up to cut-local terms. We call the resulting submatrices residual-free bilinear cores and show that they yield an exponential Schmidt-rank lower bound in terms of the $\\mathbb{F}_2$-rank of an exposed core matrix. We further give a combinatorial sufficient condition, phrased as a disjoint bridge matching, that guarantees the existence of large full-rank cores for broad families of CCZ-type bridge patterns, and we present a search-and-verify procedure that constructs and certifies such cores directly from the hyperedge description."}
{"id": "2602.21050", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21050", "abs": "https://arxiv.org/abs/2602.21050", "authors": ["Baghdasar Baghdasaryan", "Karen Lozano-Méndez", "Markus Leipe", "Meritxell Cabrejo-Ponce", "Sabine Häussler", "Kaushik Joarder", "Tim Gühring", "Stephan Fritzsche", "Thorsten A. Goebel", "Ria G. Krämer", "Stefan Nolte", "Carlos Andres Melo Luna", "Yoshiaki Tsujimoto", "Fabian Steinlechner"], "title": "Asynchronous Multi-photon Interference for Quantum Networks", "comment": "13 pages, 13figures", "summary": "Advanced quantum communication protocols require high-visibility quantum interference between photons generated at distant nodes, which places stringent demands on optical synchronization. Conventionally, synchronization of optical wave packets relies on pulsed sources and precise optical path stabilization. An alternative approach employs continuous-wave (CW) photon-pair sources, where temporal indistinguishability is enforced by post-selecting detection events within a coincidence window $τ_w$ shorter than the photon coherence time $T_c$. Despite its conceptual simplicity, the quantitative relation between relevant time scales, achievable interference visibility, and usable multi-photon rates has remained unclear. Here, we develop in detail and experimentally validate a theoretical framework that quantitatively describes time-resolved multi-photon interference in the CW regime. We explicitly incorporate detector timing jitter, photon coherence time, and temporal post-selection. The model is verified using four-photon Hong-Ou-Mandel interference measurements. Based on this validated framework, we determine the coincidence window that maximizes usable four-photon rates for a target visibility. Finally, we compare CW and pulsed SPDC sources under equivalent indistinguishability constraints and show that CW operation can achieve comparable rates while relaxing optical synchronization requirements."}
{"id": "2602.21076", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21076", "abs": "https://arxiv.org/abs/2602.21076", "authors": ["Wayne M. Witzel", "Anand Ganti", "Tzvetan S. Metodi"], "title": "Correcting coherent quantum errors by going with the flow", "comment": "11 pages, 5 figures", "summary": "The performance of a given quantum error correction (QEC) code depends upon the noise model that is assumed. Independent Pauli noise, applied after each quantum operation, is a simplistic noise model that is easy to simulate and understand in the context of stabilizer codes. Although such a noise model is artificial, it is equivalent to independent, random, unbiased qubit rotations. What about spatially or temporally correlated qubit rotations? Such a noise model is applicable to global operations (e.g., NMR or ESR), common control sources (e.g., lasers), or slow drift (e.g., charge or magnetic noise) in various qubit technologies. In the worst case, such errors can combine constructively and result in a post-correction failure rate that increases with the number of error correction cycles. However, we show that this worst case does not generally arise unless taking active corrective actions while performing QEC. That is, by employing virtual Pauli frame updates (\"passive\" error correction) rather than physical corrections (\"active\" error correction), coherent errors do not compound appreciably. Starting in a random Pauli frame is also advantageous. In fact, through perturbation theory arguments and supporting numerical simulations, we show that the logical qubit performance beyond distance 3 for correlated single-qubit Hamiltonian noise models (i.e., global errant qubit rotations), when employing these \"lazy\" strategies, essentially matches the performance of Pauli noise model with the same process fidelity (fidelity after one application). In a more general circuit model of noise, correlations may add constructively within syndrome extraction rounds but Pauli frame randomization from passive error correction mitigates this effect across multiple rounds."}
{"id": "2602.21080", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21080", "abs": "https://arxiv.org/abs/2602.21080", "authors": ["Pedro M. Prado", "Lucas A. M. Rattighieri", "Rafael Simões do Carmo", "Giovanni S. Franco", "Guilherme E. L. Pexe", "Alexandre Drinko", "Erick G. Dorlass", "Tatiana F. de Almeida", "Felipe F. Fanchini"], "title": "Quantum feedback algorithms for DNA assembly using FALQON variants", "comment": "10 pages, 2 figures", "summary": "Reconstructing DNA sequences without a reference, known as de novo assembly, is a complex computational task involving the alignment of overlapping fragments. To address this problem, a usual strategy is to map the assembly to a Quadratic Unconstrained Binary Optimization (QUBO) formulation, which can be solved by different quantum algorithms. In this work, we focus on three versions of the Feedback-based Algorithm, a protocol that eliminates classical optimization loops via measurement feedback. We analyze long-read DNA fragments from SARS-CoV-2 and human mitochondrial DNA using standard FALQON, second-order FALQON (SO-FALQON), and time-rescaled FALQON (TR-FALQON). Numerical results show that both variants improve convergence to the ground state and increase success probabilities at reduced circuit depths. These findings indicate that enhanced feedback-driven dynamics are effective for solving combinatorial problems on near-term quantum hardware."}
{"id": "2602.21106", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21106", "abs": "https://arxiv.org/abs/2602.21106", "authors": ["Aric Hackebill", "Bill Poirier"], "title": "On Hydrodynamic Formulations of Quantum Mechanics and the Problem of Sparse Ontology", "comment": null, "summary": "Hydrodynamic reformulations of the Schrödinger equation suggest an interpretation of quantum mechanics in terms of a fluid flowing on configuration space. In the discrete hydrodynamic view, this fluid is not fundamental but emerges from many underlying microscopic fluid components whose collective behavior reproduces quantum phenomena. The most developed realization of this idea is the discrete many interacting worlds (MIW) framework, in which discrete particle-like worlds interact via inter-world forces and quantum probabilities are grounded in direct world counting. But there is also an older, continuous version of MIW. After reviewing the hydrodynamic and MIW formalisms, and emphasizing some of their interpretational advantages over the Everettian Many Worlds and Bohmian approaches, we argue that all discrete hydrodynamic models face a generic structural difficulty, which we call the problem of sparse ontology. Because wavefunctions typically branch under decoherence, the discrete components of the fluid are repeatedly partitioned into sub-ensembles, thereby thinning their density in configuration space and driving the dynamics away from the quantum regime once the components become sufficiently sparse. We conclude that successful hydrodynamic completions of quantum mechanics plausibly require an essentially continuous ontology."}
{"id": "2602.21124", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21124", "abs": "https://arxiv.org/abs/2602.21124", "authors": ["Krishnakanta Barik", "Goutam Paul"], "title": "Quantum Approximate Optimization for Decoding of Low-Density Parity-Check Codes", "comment": null, "summary": "Decoding Low-Density Parity-Check (LDPC) codes is a fundamental problem in coding theory, and Belief Propagation (BP) is one of the most popular methods for LDPC code decoding. However, BP may encounter convergence issues and suboptimal performance, especially for short-length codes and in high-noise channels. The Quantum Approximate Optimization Algorithm (QAOA) is a type of Variational Quantum Algorithm (VQA) designed to solve combinatorial optimization problems by minimizing a problem-specific cost function. In this paper, we present a QAOA-based decoding framework for LDPC codes by formulating a decoding cost function that incorporates both parity-check constraints and soft channel reliability information. The resulting optimization problem is solved using QAOA to search for low-energy configurations corresponding to valid codewords. We test the proposed method through extensive numerical experiments and compare its performance with BP decoding. The experimental results demonstrate that the QAOA-based decoder achieves a higher probability of correctly recovering the transmitted codeword than BP across multiple experimental settings."}
{"id": "2602.21190", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.21190", "abs": "https://arxiv.org/abs/2602.21190", "authors": ["Guglielmo Pellitteri", "Vittorio Giovannetti", "Vasco Cavina"], "title": "Exact quantum transport in non-Markovian open Gaussian systems", "comment": "10 pages + 15 pages of appendices, 5 figures", "summary": "We build an exact framework to evaluate heat, energy, and particle transport between Gaussian reservoirs mediated by a quadratic quantum system. By combining full counting statistics with newly developed non-Markovian master equation approaches, we introduce an effective master equation whose solution can be used to generate arbitrary moments of the heat statistics for any number of reservoirs. This theory applies equally to fermionic and bosonic systems, holds at arbitrarily strong coupling, and resolves out-of-equilibrium transient dynamics determined by the system's initial state. In the steady-state, weak-coupling limit, we recover results analogous to those of the well-known Landauer-Büttiker formalism. We conclude our discussion by demonstrating an application of the method to a prototypical fermionic system. Our results uncover a regime of transient negative heat conductance contingent upon the initial system preparation, providing a clear signature of non-trivial out-of-equilibrium dynamics."}
{"id": "2602.20256", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20256", "abs": "https://arxiv.org/abs/2602.20256", "authors": ["Feng He", "Arthur Hutsalyuk", "Giuseppe Mussardo", "Andrea Stampiggi"], "title": "Spectral Decimation of Quantum Many-Body Hamiltonians", "comment": "16+6 pages; 5+3 figures", "summary": "We develop a systematic theory of spectral decimation for quantum many-body Hamiltonians and show that it provides a quantitative probe of emergent symmetries in statistically mixed spectra. Building on an analytical description of statistical mixtures, we derive an explicit expression for the size of a characteristic symmetry sector (CSS), defined as the largest subsequence of levels exhibiting non-Poissonian correlations. The CSS dimension is shown to be the size-biased average of the underlying symmetry sectors, establishing a direct link between spectral statistics and Hilbert-space structure. We apply this framework to two paradigmatic settings: Hilbert-space fragmentation and disorder-induced many-body localization (MBL). In fragmented systems, the CSS reproduces the mixture prediction and isolates correlated subsectors even when the full spectrum appears nearly Poissonian. In the disordered Heisenberg chain, spectral decimation reveals the gradual emergence of integrability through a shrinking CSS, whose statistics exhibit signatures consistent with local integrals of motion. We introduce a characteristic symmetry entropy (CSE) as a finite-size scaling observable and extract, within accessible system sizes, the crossover exponents. Our results establish spectral decimation as a controlled, unbiased and computationally inexpensive diagnostic of hidden structure in many-body spectra, capable of distinguishing between chaotic dynamics, statistical mixtures, and emergent integrability."}
{"id": "2602.20600", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.20600", "abs": "https://arxiv.org/abs/2602.20600", "authors": ["Debraj Debata", "Abhirup Mukherjee", "Siddhartha Lal"], "title": "Kondo breakdown as an entanglement transition driven by continuous measurement", "comment": "28 pages, 19 Figures", "summary": "We study the breakdown of Kondo screening by a local magnetic field from the perspective of a measurement-driven entanglement transition in a monitored quantum system. Here, the Kondo coupling leads to the growth in entanglement of an impurity spin with it's fermionic environment, while the local field plays the role of a continuous observer. Using a non-perturbative Unitary Renormalization Group (URG) approach, we derive coupled renormalization-group flow equations for the Kondo exchange and the local field, and obtain a field-dependent RG phase diagram. The RG flows separate a low-energy Kondo-screened phase, where the impurity is absorbed into the Fermi sea and forms an entangled singlet with the conduction bath, from a polarized local-moment phase in which screening is frustrated and impurity-bath entanglement is suppressed. We identify the fixed-point Hamiltonians governing the two phases and the critical regime, and relate the transition to the emergence of a novel non-Fermi liquid. Various impurity signatures such as the spectral function and thermalisation of impurity observables are used to characterise this entanglement transition. These results offer insight into the interplay of decoherence and measurement in governing the dynamics of a prototypical quantum system."}
{"id": "2602.21145", "categories": ["hep-lat", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21145", "abs": "https://arxiv.org/abs/2602.21145", "authors": ["Marko Maležič", "Johann Ostmeyer"], "title": "Reducing the Gate Count with Efficient Trotter-Suzuki Schemes", "comment": "10 pages, 3 figures, 3 tables and 1 algorithm - Proceedings of the 42nd International Symposium on Lattice Field Theory (Lattice 2025), TIFR Mumbai, India, 2025", "summary": "Hamiltonian formulations of lattice field theories provide access to real-time dynamics, but their simulation is difficult to implement efficiently. Trotter-Suzuki decompositions are at the center of time evolution computation, either on quantum hardware or classically, for instance with the use of tensor networks. While low-order Trotterizations remain the standard choice due to their simplicity, higher-order schemes offer the potential for improved efficiency. In this work we outline a short guide to Trotter-Suzuki schemes and their implementations in general. To help with this, we highlight new efficient schemes found by our optimization framework, and demonstrate their performance on the Heisenberg model."}
