{"id": "2510.12810", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12810", "abs": "https://arxiv.org/abs/2510.12810", "authors": ["Lucas Böttcher"], "title": "Control of dynamical systems with neural networks", "comment": "23 pages, 14 figures, 1 table", "summary": "Control problems frequently arise in scientific and industrial applications,\nwhere the objective is to steer a dynamical system from an initial state to a\ndesired target state. Recent advances in deep learning and automatic\ndifferentiation have made applying these methods to control problems\nincreasingly practical. In this paper, we examine the use of neural networks\nand modern machine-learning libraries to parameterize control inputs across\ndiscrete-time and continuous-time systems, as well as deterministic and\nstochastic dynamics. We highlight applications in multiple domains, including\nbiology, engineering, physics, and medicine. For continuous-time dynamical\nsystems, neural ordinary differential equations (neural ODEs) offer a useful\napproach to parameterizing control inputs. For discrete-time systems, we show\nhow custom control-input parameterizations can be implemented and optimized\nusing automatic-differentiation methods. Overall, the methods presented provide\npractical solutions for control tasks that are computationally demanding or\nanalytically intractable, making them valuable for complex real-world\napplications."}
{"id": "2510.12832", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12832", "abs": "https://arxiv.org/abs/2510.12832", "authors": ["Alistair Brash", "Junyi Lu", "Bruce Stephen", "Blair Brown", "Robert Atkinson", "Craig Michie", "Fraser MacIntyre", "Christos Tachtatzis"], "title": "Coherent Load Profile Synthesis with Conditional Diffusion for LV Distribution Network Scenario Generation", "comment": null, "summary": "Limited visibility of power distribution network power flows at the low\nvoltage level presents challenges to both distribution network operators from a\nplanning perspective and distribution system operators from a congestion\nmanagement perspective. Forestalling these challenges through scenario analysis\nis confounded by the lack of realistic and coherent load data across\nrepresentative distribution feeders. Load profiling approaches often rely on\nsummarising demand through typical profiles, which oversimplifies the\ncomplexity of substation-level operations and limits their applicability in\nspecific power system studies. Sampling methods, and more recently generative\nmodels, have attempted to address this through synthesising representative\nloads from historical exemplars; however, while these approaches can\napproximate load shapes to a convincing degree of fidelity, the co-behaviour\nbetween substations, which ultimately impacts higher voltage level network\noperation, is often overlooked. This limitation will become even more\npronounced with the increasing integration of low-carbon technologies, as\nestimates of base loads fail to capture load diversity. To address this gap, a\nConditional Diffusion model for synthesising daily active and reactive power\nprofiles at the low voltage distribution substation level is proposed. The\nevaluation of fidelity is demonstrated through conventional metrics capturing\ntemporal and statistical realism, as well as power flow modelling. The results\nshow synthesised load profiles are plausible both independently and as a cohort\nin a wider power systems context. The Conditional Diffusion model is\nbenchmarked against both naive and state-of-the-art models to demonstrate its\neffectiveness in producing realistic scenarios on which to base sub-regional\npower distribution network planning and operations."}
{"id": "2510.12897", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12897", "abs": "https://arxiv.org/abs/2510.12897", "authors": ["Sanjay Johnson", "Dirk Lauinger", "Sungho Shin", "François Pacaud"], "title": "ExaModelsPower.jl: A GPU-Compatible Modeling Library for Nonlinear Power System Optimization", "comment": null, "summary": "As GPU-accelerated mathematical programming techniques mature, there is\ngrowing interest in utilizing them to address the computational challenges of\npower system optimization. This paper introduces ExaModelsPower.jl, an\nopen-source modeling library for creating GPU-compatible nonlinear AC optimal\npower flow models. Built on ExaModels.jl, ExaModelsPower.jl provides a\nhigh-level interface that automatically generates all necessary callback\nfunctions for GPU solvers. The library is designed for large-scale problem\ninstances, which may include multiple time periods and security constraints.\nUsing ExaModelsPower.jl, we benchmark GPU and CPU solvers on open-source test\ncases. Our results show that GPU solvers can deliver up to two orders of\nmagnitude speedups compared to alternative tools on CPU for problems with more\nthan 20,000 variables and a solution precision of up to $10^{-4}$, while\nperformance for smaller instances or tighter tolerances may vary."}
{"id": "2510.12914", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12914", "abs": "https://arxiv.org/abs/2510.12914", "authors": ["Zhi Liu", "Chengxi Liu", "Jiangbei Han", "Rui Qiu", "Mingyuan Liu"], "title": "A Wideband Composite Sequence Impedance Model for Evaluation of Interactions in Unbalanced Power-Electronic-Based Power Systems", "comment": "This work will be submitted to the IEEE for possible publication", "summary": "This paper proposes a wideband composite sequence impedance model\n(WCSIM)-based analysis method to evaluate the interactions in\npower-electronic-based power systems subjected to unbalanced grid faults or\nwith unbalanced loads. The WCSIM-based method intuitively assesses the impact\nof the small-signal interconnection among the positive-, negative-, and\nzero-sequence circuits on the interaction stability of unbalanced power\nsystems. The effectiveness of this method is demonstrated using a permanent\nmagnet synchronous generator-based weak grid system under a\nsingle-line-to-ground fault (SLGF). Frequency scanning results and controller\nhardware-in-loop tests validate both the correctness of the WCSIM and the\neffectiveness of the WCSIM-based analysis method."}
{"id": "2510.13785", "categories": ["q-fin.ST", "cs.CE", "physics.data-an", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13785", "abs": "https://arxiv.org/abs/2510.13785", "authors": ["Stanisław Drożdż", "Robert Kluszczyński", "Jarosław Kwapień", "Marcin Wątorek"], "title": "Multifractality and its sources in the digital currency market", "comment": null, "summary": "Multifractality in time series analysis characterizes the presence of\nmultiple scaling exponents, indicating heterogeneous temporal structures and\ncomplex dynamical behaviors beyond simple monofractal models. In the context of\ndigital currency markets, multifractal properties arise due to the interplay of\nlong-range temporal correlations and heavy-tailed distributions of returns,\nreflecting intricate market microstructure and trader interactions.\nIncorporating multifractal analysis into the modeling of cryptocurrency price\ndynamics enhances the understanding of market inefficiencies, may improve\nvolatility forecasting and facilitate the detection of critical transitions or\nregime shifts. Based on the multifractal cross-correlation analysis (MFCCA)\nwhose spacial case is the multifractal detrended fluctuation analysis (MFDFA),\nas the most commonly used practical tools for quantifying multifractality, in\nthe present contribution a recently proposed method of disentangling sources of\nmultifractality in time series was applied to the most representative\ninstruments from the digital market. They include Bitcoin (BTC), Ethereum\n(ETH), decentralized exchanges (DEX) and non-fungible tokens (NFT). The results\nindicate the significant role of heavy tails in generating a broad multifractal\nspectrum. However, they also clearly demonstrate that the primary source of\nmultifractality are temporal correlations in the series, and without them,\nmultifractality fades out. It appears characteristic that these temporal\ncorrelations, to a large extent, do not depend on the thickness of the tails of\nthe fluctuation distribution. These observations, made here in the context of\nthe digital currency market, provide a further strong argument for the validity\nof the proposed methodology of disentangling sources of multifractality in time\nseries."}
{"id": "2510.12928", "categories": ["math.ST", "math.PR", "stat.TH", "60F05, 62E20 (Primary) 62G20, 62H10 (Secondary)"], "pdf": "https://arxiv.org/pdf/2510.12928", "abs": "https://arxiv.org/abs/2510.12928", "authors": ["Armine Bagyan", "Donald Richards"], "title": "Random Modulation with Spherical Symmetry", "comment": "44 pages", "summary": "We consider the modulation of data given by random vectors $X_n \\in\n\\mathbb{R}^{d_n}$, $n \\in \\mathbb{N}$. For each $X_n$, one chooses an\nindependent modulating random vector $\\Xi_n \\in \\mathbb{R}^{d_n}$ and forms the\nprojection $Y_n = \\Xi_n'X_n$. It is shown, under regularity conditions on $X_n$\nand $\\Xi_n$, that $Y_n|\\Xi_n$ converges weakly in probability to a normal\ndistribution. More broadly, the conditional joint distribution of a family of\nprojections constructed from random samples from $X_n$ and $\\Xi_n$ is shown to\nconverge weakly to a matrix normal distribution. We derive, \\textit{via} G.\nP\\'olya's characterization of the normal distribution, a necessary and\nsufficient condition on $Y_n$ for $\\Xi_n$ to be normally distributed. When\n$\\Xi_n$ has a spherically symmetric distribution we deduce, through I. J.\nSchoenberg's characterization of the spherically symmetric characteristic\nfunctions on Hilbert spaces, that the probability density function of\n$Y_n|\\Xi_n$ converges pointwise in certain $p$th means to a mixture of normal\ndensities and the rate of convergence is quantified, resulting in uniform\nconvergence. The cumulative distribution function of $Y_n|\\Xi_n$ is shown to\nconverge uniformly in those $p$th means to the distribution function of the\nsame mixture, and a Lipschitz property is obtained. Examples of distributions\nsatisfying our results are provided; these include Bingham distributions on\nhyperspheres of random radii, uniform distributions on hyperspheres and\nhypercubes of random volumes, and multivariate normal distributions; and\nexamples of such $\\Xi_n$ include the multivariate $t$-, multivariate Laplace,\nand spherically symmetric stable distributions."}
{"id": "2510.13053", "categories": ["cond-mat.stat-mech", "gr-qc"], "pdf": "https://arxiv.org/pdf/2510.13053", "abs": "https://arxiv.org/abs/2510.13053", "authors": ["Tao Wang", "Yu Shi"], "title": "Adiabatic Elimination in Relativistic Stochastic Mechanics", "comment": "24 pages, 6 figures", "summary": "We investigate the adiabatic elimination of fast variables in relativistic\nstochastic mechanics, which is analyzed in the equation of motion and in the\ndistribution function, with relativistic corrections explicitly derived. A new\ndimensionless parameter is introduced to characterize the timescale. The\nadiabatic elimination is also compared with the path integral coarse graining,\nwhich is more general yet computationally demanding."}
{"id": "2510.13157", "categories": ["cs.CE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.13157", "abs": "https://arxiv.org/abs/2510.13157", "authors": ["Subhendu Khatuya", "Shashwat Naidu", "Pawan Goyal", "Niloy Ganguly"], "title": "Program of Thoughts for Financial Reasoning: Leveraging Dynamic In-Context Examples and Generative Retrieval", "comment": "This work has been accepted for publication in the Main Conference of\n  the Empirical Methods in Natural Language Processing (EMNLP) 2025", "summary": "Despite continuous advancements in the capabilities of large language models\n(LLMs), numerical reasoning remains a challenging area. Techniques like\nchain-of-thought prompting, tree-of-thought prompting, and program-of-thought\nprompting guide LLMs through intermediate reasoning steps. Although in-context\nlearning with few-shot prompting has improved performance, LLMs still lag\nbehind state-of-the-art models on financial numerical reasoning datasets such\nas FinQA and ConvFinQA. In this work, we introduce FINDER, a novel two-step\nframework, to enhance LLMs' capabilities in financial numerical reasoning. The\nfirst step utilizes a generative retriever to extract relevant facts from\nunstructured data, including both text and tables. This is followed by\ncontext-aware Program of Thought prompting with dynamic selection of in-context\nexamples. Our model FINDER achieves a new state-of-the-art performance on both\nthe FinQA and ConvFinQA datasets, surpassing previous benchmarks with execution\naccuracy improvements of 5.98% and 4.05%, respectively."}
{"id": "2510.13273", "categories": ["cs.SI", "cs.DL"], "pdf": "https://arxiv.org/pdf/2510.13273", "abs": "https://arxiv.org/abs/2510.13273", "authors": ["Xinyi Zhao", "Anna I. Thoma", "Ralph Hertwig", "Dirk U. Wulff"], "title": "Mapping the gender attrition gap in academic psychology", "comment": null, "summary": "Although more women than men enter social science disciplines, they are\nunderrepresented at senior levels. To investigate this leaky pipeline, this\nstudy analyzed the career trajectories of 78,216 psychology researchers using\nlarge-scale bibliometric data. Despite overall constituting over 60\\% of these\nresearchers, women experienced consistently higher attrition rates than men,\nparticularly in the early years following their first publication. Academic\nperformance, particularly first-authored publications, was strongly associated\nwith early-career retention -- more so than collaboration networks or\ninstitutional environment. After controlling for gender differences in\npublication-, collaboration-, and institution-level factors, women remained\nmore likely to leave academia, especially in early-career stages, pointing to\npersistent barriers that hinder women's academic careers. These findings\nsuggest that in psychology and potentially other social science disciplines,\nthe core challenge lies in retention rather than recruitment, underscoring the\nneed for targeted, early-career interventions to promote long-term gender\nequity."}
{"id": "2510.13012", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "65M60, 76S05"], "pdf": "https://arxiv.org/pdf/2510.13012", "abs": "https://arxiv.org/abs/2510.13012", "authors": ["Abderrahmane Benfanich", "Yves Bourgault", "Abdelaziz Beljadid"], "title": "A finite element method using a bounded auxiliary variable for solving the Richards equation", "comment": "Preprint submitted to the Journal of Computational Physics (Elsevier)", "summary": "The Richards equation, a nonlinear elliptic parabolic equation, is widely\nused to model infiltration in porous media. We develop a finite element method\nfor solving the Richards equation by introducing a new bounded auxiliary\nvariable to eliminate unbounded terms in the weak formulation of the method.\nThis formulation is discretized using a semi-implicit scheme and the resulting\nnonlinear system is solved using Newton's method. Our approach eliminates the\nneed of regularization techniques and offers advantages in handling both dry\nand fully saturated zones. In the proposed techniques, a non-overlapping\nSchwarz domain decomposition method is used for modeling infiltration in\nlayered soils. We apply the proposed method to solve the Richards equation\nusing the Havercamp and van Genuchten models for the capillary pressure.\nNumerical experiments are performed to validate the proposed approach,\nincluding tests such as modeling flows in fibrous sheets where the initial\nmedium is totally dry, two cases with fully saturated and dry regions, and an\ninfiltration problem in layered soils. The numerical results demonstrate the\nstability and accuracy of the proposed numerical method. The numerical\nsolutions remain positive in the presence of totally dry zones. The numerical\ninvestigations clearly demonstrated the capability of the proposed method to\neffectively predict the dynamics of flows in unsaturated soils."}
{"id": "2510.12880", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.12880", "abs": "https://arxiv.org/abs/2510.12880", "authors": ["Alwyn Jose Raja", "R. Ganesh"], "title": "The Kitaev-AKLT model", "comment": "4 pages + supplement, 5 + 4 figures", "summary": "Inspired by the Affleck-Kennedy-Lieb-Tasaki (AKLT) model, we present exact\nsolutions for a spin-1 chain with Kitaev-like couplings. We consider an\nexpanded Kitaev model with bilinear and biquadratic terms. At an exactly\nsolvable point, the Hamiltonian can be reexpressed as a sum of projection\noperators. Unlike the AKLT model where projectors act on total spin, we project\nonto components of spin along the bond direction. This leads to exponential\nground state degeneracy, expressed in terms of fractionalized\nspin-$\\frac{1}{2}$ objects. Each ground state can be expressed concisely as a\nmatrix product state. We construct a phase diagram by varying the relative\nstrength of bilinear and biquadratic terms. The fractionalized states provide a\nqualitative picture for the spin-1 Kitaev model, yielding approximate forms for\nthe ground state and low-lying excitations."}
{"id": "2510.13280", "categories": ["physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2510.13280", "abs": "https://arxiv.org/abs/2510.13280", "authors": ["D Huilier"], "title": "Math{é}matiques et M{é}canique {à} Strasbourg entre 1871 et 1939", "comment": "in French language", "summary": "The University of Strasbourg, fundamentally humanistic since its creation,\nhas a complicated history, being sometimes German, sometimes French through the\nages. If one focus, from 1871, on the area of mathematics, we can identify two\nperiods. Political goals led to send high-level scientists, sometimes rather\nyoung, to develop theoretical, later applied mathematics, leading to a novel\narea, mechanics. The first period, under Prussian influence until 1918, will\nsee the emergence of an Institute of mathematics such it was existing in\nG{\\\"o}ttingen; the second, dominated by the French influence, will make\nStrasbourg an anteroom to positions at the prestigious Faculty of Sciences in\nParis, the Sorbonne, the Academy of Sciences or the ENS. Present communication\nwill give an inside, through its history, of the development of Mathematics in\nStrasbourg, prelude to emerging Mechanics and the creation of what will become\nthe Institut de M{\\'e}canique des Fluides et des Solides en 2000."}
{"id": "2510.13189", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.13189", "abs": "https://arxiv.org/abs/2510.13189", "authors": ["Ajinkya Desai", "Antonio Quim Cervantes", "Tirtha Banerjee"], "title": "Scaling analysis for buoyant plumes over wildland fires", "comment": null, "summary": "Tracking the structure and geometric properties of a buoyant plume in\ncross-wind is critical for managing smoke hazards and improving disaster\nmitigation efforts. Plume features, such as the tilt angle, centerline\ntrajectory, plume height, and curvature changes with height, are impacted by a\nrange of forcing parameters, with the altered turbulence patterns induced by a\nvegetative canopy introducing an added layer of complexity. This study examines\nthe effects of these parameters, reduced to a set of fewer dimensionless\ngroups, on the plume centerline slope both, near the surface and in the\nfar-field (bent-over phase). Results from a suite of large-eddy simulations in\nboth canopy and no-canopy environments explore power-law dependencies between\nthe slopes and key dimensionless groups describing (1) the relative strength of\nthe buoyancy source to the ambient wind forcing and (2) the turbulence\nintensity within the plume relative to upstream. Near-surface slopes are an\norder of magnitude higher in the canopy cases owing to canopy drag. In the\ncanopy cases, the near-surface plume slope increases markedly with increase in\nthe dimensionless plume turbulence intensity, exhibiting a one-fourth power-law\ndependence. This effect is absent in the no-canopy case, reflecting spatial\ndifferences in the momentum-flux structure near the plume source between the\ntwo environments. Moreover, the canopy aerodynamic effects delay the transition\nof the plume from the rise phase into the far-field compared to the no-canopy\ncases. The transition height follows a one-fourth and one-third power-law\ndependence on group (1) in the canopy and no-canopy environments, respectively,\nwith canopy effects becoming less prominent at higher buoyancy source strength.\nOur findings support the development of scaling laws for plume structures\nacross varied environments and inform improved predictive modeling."}
{"id": "2510.12946", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12946", "abs": "https://arxiv.org/abs/2510.12946", "authors": ["Daniel C. Qi", "Kenshiro Oguri", "Puneet Singla", "Maruthi R. Akella"], "title": "Non-Gaussian Distribution Steering in Nonlinear Dynamics with Conjugate Unscented Transformation", "comment": null, "summary": "In highly nonlinear systems such as the ones commonly found in astrodynamics,\nGaussian distributions generally evolve into non-Gaussian distributions. This\npaper introduces a method for effectively controlling non-Gaussian\ndistributions in nonlinear environments using optimized linear feedback\ncontrol. This paper utilizes Conjugate Unscented Transformation to quantify the\nhigher-order statistical moments of non-Gaussian distributions. The formulation\nfocuses on controlling and constraining the sigma points associated with the\nuncertainty quantification, which would thereby reflect the control of the\nentire distribution and constraints on the moments themselves. This paper\ndevelops an algorithm to solve this problem with sequential convex programming,\nand it is demonstrated through a two-body and three-body example. The examples\nshow that individual moments can be directly controlled, and the moments are\naccurately approximated for non-Gaussian distributions throughout the\ncontroller's time horizon in nonlinear dynamics."}
{"id": "2510.13174", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.13174", "abs": "https://arxiv.org/abs/2510.13174", "authors": ["Himanshi Singh", "Tanmay Sahoo", "Nil Kamal Hazra"], "title": "A Generalized Notion of Completeness and Its Application", "comment": null, "summary": "From the perspective of data reduction, the notions of minimal sufficient and\ncomplete statistics together play an important role in determining optimal\nstatistics (estimators). The classical notion of sufficiency and completeness\nare not adequate in many robust estimations that are based on different\ndivergences. Recently, the notion of generalized sufficiency based on a\ngeneralized likelihood function was introduced in the literature. It is\nimportant to note that the concept of sufficiency alone does not necessarily\nproduce optimal statistics (estimators). Thus, in line with the generalized\nsufficiency, we introduce a generalized notion of completeness with respect to\na generalized likelihood function. We then characterize the family of\nprobability distributions that possesses completeness with respect to the\ngeneralized likelihood function associated with the density power divergence\n(DPD). Moreover, we show that the family of distributions associated with the\nlogarithmic density power divergence (LDPD) is not complete. Further, we extend\nthe Lehmann-Scheff\\'e theorem and the Basu's theorem for the generalized\nlikelihood estimation. Subsequently, we obtain the generalized uniformly\nminimum variance unbiased estimator (UMVUE) for the\n$\\mathcal{B^{(\\alpha)}}$-family. Further, we derive an formula of the\nasymptotic expected deficiency (AED) that is used to compare the performance\nbetween the minimum density power divergence estimator (MDPDE) and the\ngeneralized UMVUE for $\\mathcal{B^{(\\alpha)}}$-family. Finally, we provide an\napplication of the developed results in stress-strength reliability model."}
{"id": "2510.13453", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.13453", "abs": "https://arxiv.org/abs/2510.13453", "authors": ["Jetin E Thomas", "Ramandeep S. Johal"], "title": "Nonequilibrium steady states in bead-spring models: Entropy production and probability distributions", "comment": "10 pages, 12 figures", "summary": "We study non-equilibrium models comprising of beads connected by springs. The\nsystem is coupled to two thermal baths kept at different temperatures. We\nderive the steady state probability distributions of positions of the bead for\nthe one-bead system in the underdamped case. We employ the recently proposed\ntechnique of an effective temperature, along with numerical simulations to\nsolve the Langevin equations and obtain their corresponding probability\ndistributions. It is observed that the marginal probability distributions in\nthe position are independent of mass. We also obtain theoretically and\nnumerically the rate of entropy production for the one-bead system. The\nprobability distribution of the positions in the two-beads system are obtained\ntheoretically and numerically, both in the underdamped and overdamped case.\nLastly, we discuss the notion of ergodicity and have tested the convergence of\nthe time-averaging and the ensemble-averaging protocols."}
{"id": "2510.13559", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2510.13559", "abs": "https://arxiv.org/abs/2510.13559", "authors": ["Vahab Knauf Narouie", "Jorge-Humberto Urrea-Quintero", "Fehmi Cirak", "Henning Wessels"], "title": "Unsupervised Constitutive Model Discovery from Sparse and Noisy Data", "comment": "27 pages, 12 figures", "summary": "Recently, unsupervised constitutive model discovery has gained attention\nthrough frameworks based on the Virtual Fields Method (VFM), most prominently\nthe EUCLID approach. However, the performance of VFM-based approaches,\nincluding EUCLID, is affected by measurement noise and data sparsity, which are\nunavoidable in practice. The statistical finite element method (statFEM) offers\na complementary perspective by providing a Bayesian framework for assimilating\nnoisy and sparse measurements to reconstruct the full-field displacement\nresponse, together with quantified uncertainty. While statFEM recovers\ndisplacement fields under uncertainty, it does not strictly enforce consistency\nwith constitutive relations or aim to yield interpretable constitutive models.\nIn this work, we couple statFEM with unsupervised constitutive model discovery\nin the EUCLID framework, yielding statFEM--EUCLID. The framework is\ndemonstrated for isotropic hyperelastic materials. The results show that this\nintegration reduces sensitivity to noise and data sparsity, while ensuring that\nthe reconstructed fields remain consistent with both equilibrium and\nconstitutive laws."}
{"id": "2510.13392", "categories": ["physics.soc-ph", "cs.SI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13392", "abs": "https://arxiv.org/abs/2510.13392", "authors": ["Łukasz Brzozowski", "Marek Gagolewski", "Grzegorz Siudem", "Barbara Żogała-Siudem"], "title": "The Price-Pareto growth model of networks with community structure", "comment": null, "summary": "We introduce a new analytical framework for modelling degree sequences in\nindividual communities of real-world networks, e.g., citations to papers in\ndifferent fields. Our work is inspired by Price's model and its recent\ngeneralisation called 3DSI (three dimensions of scientific impact), which\nassumes that citations are gained partly accidentally, and to some extent\npreferentially. Our generalisation is motivated by existing research indicating\nsignificant differences between how various scientific disciplines grow,\nnamely, minding different growth ratios, average reference list lengths, and\npreferential citing tendencies. Extending the 3DSI model to heterogeneous\nnetworks with a community structure allows us to devise new analytical formulas\nfor, e.g., citation number inequality and preferentiality measures. We show\nthat the distribution of citations in a community tends to a Pareto type II\ndistribution. We also present analytical formulas for estimating its parameters\nand Gini's index. The new model is validated on real citation networks."}
{"id": "2510.13021", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.13021", "abs": "https://arxiv.org/abs/2510.13021", "authors": ["Frédéric Marazzato", "Shankar Venkataramani"], "title": "Computation of stresses in jammed packings modeled with Tresca friction", "comment": null, "summary": "This paper is interested in the computation of stresses within jammed\npackings of rigid polygonal cells. The cells are considered to follow a Tresca\nfriction law. First, a constrained minimization problem is introduced where the\nfriction energy is minimized while enforcing the non-interpenetration of\nneighboring cells as inequality constraint. The corresponding dual maximization\nproblem is then deduced and its solution provides normal stresses at the\ninterface between cells. Finally, lowest order Raviart-Thomas finite elements\nare used to reconstruct a consistent stress field by solving local problems.\nNumerical results are presented to showcase the consistency and robustness of\nthe proposed methodology."}
{"id": "2510.12884", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.12884", "abs": "https://arxiv.org/abs/2510.12884", "authors": ["Arthur Bril", "Nai Chao Hu", "Nick Bultinck"], "title": "Multi-Q spin-valley order in twisted WSe2", "comment": "14 pages, 8 figures", "summary": "We report on a study of the interacting phase diagram of $3.65^\\circ$-twisted\nWSe$_2$ at moir\\'e hole filling $\\nu=1$, in which we find previously-overlooked\ntypes of magnetism. Specifically, in part of the phase diagram we obtain a\nmagnetic order parameter which modulates in space with four different non-zero\nwave vectors, corresponding to the three $M$-points and one $K$-point of the\nmoir\\'e Brillouin zone. These multi-Q orders, which can be coplanar or\nnon-coplanar, are continuous deformations of the $120^\\circ$ spin-valley\nanti-ferromagnet (AFM), where the unit cell has expanded by a factor of four.\nInterestingly, we find that the multi-Q states are stabilized for\nexperimentally relevant values of interaction strength and displacement field,\nand are accompanied by a softening of the spin fluctuations near the $M$-points\nof the moir\\'e"}
{"id": "2510.13196", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.13196", "abs": "https://arxiv.org/abs/2510.13196", "authors": ["Ajinkya Desai", "Antonio Quim Cervantes", "Tirtha Banerjee"], "title": "Investigating Buoyant Plume Dynamics Induced by Localized Fire-Simulated Heating over Plant Canopies Using LES", "comment": null, "summary": "The interaction of a buoyant plume with a plant canopy results in turbulent\nflow features distinct from those in a grassland environment. In this work, we\nmodel the turbulence dynamics of a buoyant plume in a homogeneous plant canopy\nwith a crosswind using large-eddy simulations. As the plume interacts with the\ncrosswind, we observe increased vorticity at the windward edge and tilted\nhair-pin-like vortical structures on the leeward side. Strong rotational cores,\nrepresenting counter-rotating vortex pairs (CVPs), form as the flow twists and\nspirals into the leeward side of the buoyancy source from either side. Flow\npatterns aloft exhibit helical motions as the CVPs aloft propagate downstream,\ntrailing the plume. We also simulate a no-canopy environment to facilitate\ncomparison. The plume tilts less steeply near the source in the canopy case due\nto the canopy drag and its leeward side is marked by flow recirculation near\nthe canopy top, which obstructs the upstream flow as it approaches. Moreover,\nthe plume transition from the rise phase to the bent-over phase is delayed due\nto the canopy's aerodynamic effects and the oscillatory behavior of the\nfar-field mean plume centerline is more damped. Additionally, in the canopy\nenvironment, there is downward momentum transfer primarily via ejections above\nthe canopy and sweeps within the canopy space, upstream of the plume\ncenterline. On the leeward side, counter-gradient motions play a significant\nrole in transferring momentum away from the buoyancy source, with outward\ninteractions being most dominant. Contrarily, in the no-canopy environment,\ncounter-gradient motions near the surface are flanked upstream by an\nejection-dominated region and downstream by a sweep-dominated region. Insights\ninto the distinct plume behavior in canopy vs. no-canopy environments are vital\nfor comparing with experiments and refining fire behavior or plume rise models."}
{"id": "2510.13321", "categories": ["nlin.AO"], "pdf": "https://arxiv.org/pdf/2510.13321", "abs": "https://arxiv.org/abs/2510.13321", "authors": ["Zheng Wang", "Jinjie Zhu", "Xianbin Liu"], "title": "Moderate Higher-Order Interactions Enhance Stability While Preserving Basin Structure", "comment": null, "summary": "Synchronization is a ubiquitous phenomenon in complex systems. The Kuramoto\nmodel serves as a paradigmatic framework for understanding how coupled\noscillators achieve collective rhythm. Conventional approaches focus on\npairwise interactions, but real-world systems frequently involve higher-order\ncouplings among multiple elements. Previous studies have shown that\nhigher-order interactions enrich dynamics but generally shrink the attraction\nbasin of synchronized states, making synchronization harder to achieve. Here,\nwe demonstrate this picture is incomplete. Through systematic analysis of\ntwisted states on ring networks, we identify a moderate coupling regime where\nhigher-order interactions enhance stability without altering basin structure.\nThe relative distribution among twisted states remains constant, yet\nquasipotential barriers deepen as coupling strengths increase. By measuring\nmean first passage times, we show both pairwise and higher-order couplings\ncontribute synergistically to enhance stability, consistent with large\ndeviation theory. These findings provide new insights into the role of\nhigher-order interactions in synchronization."}
{"id": "2510.13246", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2510.13246", "abs": "https://arxiv.org/abs/2510.13246", "authors": ["Dishant Sisodia", "Sarika Jalan"], "title": "Dynamics of reservoir computing for crises prediction", "comment": null, "summary": "Reservoir computing has emerged as a powerful framework for time series\nmodelling and forecasting including the prediction of discontinuous\ntransitions. However, the mechanism behind its success is not yet fully\nunderstood. This letter elucidates the functioning of reservoir computing by\nexamining its successful prediction of boundary and attractor merging crises.\nWe investigate in detail how reservoirs's internal dynamics mimic the actual\nsystem, that enables it to accurately reproduce the scaling exponent near\nboundary crisis. We establish this across distinct systems, exemplified by the\nlogistic and Gauss maps. The study contributes to the broader understanding of\nthe internal dynamics that enable learning algorithms to anticipate critical\ntransitions."}
{"id": "2510.13392", "categories": ["physics.soc-ph", "cs.SI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13392", "abs": "https://arxiv.org/abs/2510.13392", "authors": ["Łukasz Brzozowski", "Marek Gagolewski", "Grzegorz Siudem", "Barbara Żogała-Siudem"], "title": "The Price-Pareto growth model of networks with community structure", "comment": null, "summary": "We introduce a new analytical framework for modelling degree sequences in\nindividual communities of real-world networks, e.g., citations to papers in\ndifferent fields. Our work is inspired by Price's model and its recent\ngeneralisation called 3DSI (three dimensions of scientific impact), which\nassumes that citations are gained partly accidentally, and to some extent\npreferentially. Our generalisation is motivated by existing research indicating\nsignificant differences between how various scientific disciplines grow,\nnamely, minding different growth ratios, average reference list lengths, and\npreferential citing tendencies. Extending the 3DSI model to heterogeneous\nnetworks with a community structure allows us to devise new analytical formulas\nfor, e.g., citation number inequality and preferentiality measures. We show\nthat the distribution of citations in a community tends to a Pareto type II\ndistribution. We also present analytical formulas for estimating its parameters\nand Gini's index. The new model is validated on real citation networks."}
{"id": "2510.12949", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12949", "abs": "https://arxiv.org/abs/2510.12949", "authors": ["Zhiyuan Fan", "Elizabeth Dentzer", "James Glynn", "David S. Goldberg", "Julio Friedmann", "Bolun Xu"], "title": "Enhancing Profit and CO2 Mitigation: Commercial Direct Air Capture Design and Operation with Power Market Volatility", "comment": "16 pages, 8 figure, Submitted and under review for Engineering", "summary": "Current decarbonization efforts are falling short of meeting the net-zero\ngreenhouse gas (GHG) emission target, highlighting the need for substantial\ncarbon dioxide removal methods such as direct air capture (DAC). However,\nintegrating DACs poses challenges due to their enormous power consumption. This\nstudy assesses the commercial operation of various DAC technologies that earn\nrevenue using monetized carbon incentives while purchasing electricity from\nwholesale power markets. We model four commercial DAC technologies and examine\ntheir operation in three representative locations including California, Texas,\nand New York. Our findings reveal that commercial DAC operations can take\nfinancial advantage of the volatile power market to operate only during\nlow-price periods strategically, offering a pathway to facilitate a\ncost-efficient decarbonization transition. The ambient operational environment\nsuch as temperature and relative humidity has non-trivial impact on abatement\ncapacity. Profit-driven decisions introduce climate-economic trade-offs that\nmight decrease the capacity factor of DAC and reduce total CO2 removal. These\nimplications extend throughout the entire lifecycle of DAC developments and\ninfluence power systems and policies related to full-scale DAC implementation.\nOur study shows that DAC technologies with shorter cycle spans and higher\nflexibility can better exploit the electricity price volatility, while power\nmarkets demonstrate persistent low-price windows that often synergize with low\ngrid emission periods, like during the solar \"duck curve\" in California. An\noptimal incentive design exists for profit-driven operations while carbon-tax\npolicy in electricity pricing is counterproductive for DAC systems."}
{"id": "2510.13179", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.13179", "abs": "https://arxiv.org/abs/2510.13179", "authors": ["Himanshi Singh", "Abhik Ghosh", "Nil Kamal Hazra"], "title": "On Generalized Likelihood Estimation Based on the Logarithmic Norm Relative Entropy", "comment": null, "summary": "Traditional likelihood based methods for parameter estimation get highly\naffected when the given data is contaminated by outliers even in a small\nproportion. In this paper, we consider a robust parameter estimation method,\nnamely the minimum logarithmic norm relative entropy (LNRE) estimation\nprocedure, and study different (generalized) sufficiency principles associated\nwith it. We introduce a new two-parameter power-law family of distributions\n(namely, $\\mathcal{M}^{(\\alpha,\\beta)}$-family), which is shown to have a fixed\nnumber of sufficient statistics, independent of the sample size, with respect\nto the generalized likelihood function associated with the LNRE. Then, we\nobtain the generalized minimal sufficient statistic for this family and derive\nthe generalized Rao-Blackwell theorem and the generalized Cram\\'{e}r-Rao lower\nbound for the minimum LNRE estimation. We also study the minimum LNRE\nestimators (MLNREEs) for the family of Student's distributions particularly in\ndetail. Our general results reduces to the classical likelihood based results\nunder the exponential family of distributions at specific choices of the tuning\nparameter $\\alpha$ and $\\beta$. Finally, we present simulation studies followed\nby a real data analysis, which highlight the practical utility of the MLNREEs\nfor data contaminated by possible outliers. Along the way we also correct a\nmistake found in a recent paper on related theory of generalized likelihoods."}
{"id": "2510.13555", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.13555", "abs": "https://arxiv.org/abs/2510.13555", "authors": ["Tatsuhiko Shirai"], "title": "Quasi-adiabatic thermal ensemble preparation in the thermodynamic limit", "comment": "8 pages, 4 figures", "summary": "We investigate a quasi-adiabatic thermal process for preparing\nfinite-temperature ensembles in the thermodynamic limit. The process gradually\ntransforms a thermal ensemble of a noninteracting system into that of an\ninteracting system of interest over a finite operation time, with the\ntemperature controlled by parameters associated with the entropy of the initial\nstate. We analyze this process in both nonintegrable and integrable spin chains\nwith translational invariance. For the nonintegrable case, numerical\nsimulations show that the thermal properties of local observables are\naccurately reproduced with a single parameter in the high temperature regime,\nalthough the operation time increases exponentially with precision. In\ncontrast, for the integrable transverse-field Ising model, we analytically show\nthat an extensive number of parameters tied to local conserved quantities is\ngenerally necessary, and that the operation time increases linearly with system\nsize, diverging in the thermodynamic limit. These results clarify the potential\nand limitations of the quasi-adiabatic thermal process for an ensemble\npreparation and highlight the role of integrability in determining its\nefficiency."}
{"id": "2510.13448", "categories": ["physics.comp-ph", "cond-mat.dis-nn", "cond-mat.mtrl-sci", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.13448", "abs": "https://arxiv.org/abs/2510.13448", "authors": ["Nikolaj Rønne", "Tejs Vegge", "Arghya Bhowmik"], "title": "GO-Diff: Data-free and amortized global structure optimization", "comment": null, "summary": "We introduce GO-Diff, a diffusion-based method for global structure\noptimization that learns to directly sample low-energy atomic configurations\nwithout requiring prior data or explicit relaxation. GO-Diff is trained from\nscratch using a Boltzmann-weighted score-matching loss, leveraging only the\nknown energy function to guide generation toward thermodynamically favorable\nregions. The method operates in a two-stage loop of self-sampling and model\nrefinement, progressively improving its ability to target low-energy\nstructures. Compared to traditional optimization pipelines, GO-Diff achieves\ncompetitive results with significantly fewer energy evaluations. Moreover, by\nreusing pretrained models across related systems, GO-Diff supports amortized\noptimization - enabling faster convergence on new tasks without retraining from\nscratch."}
{"id": "2510.13636", "categories": ["stat.ME", "cs.SI", "math.ST", "stat.TH", "62R01,"], "pdf": "https://arxiv.org/pdf/2510.13636", "abs": "https://arxiv.org/abs/2510.13636", "authors": ["Félix Almendra-Hernández", "Miles Bakenhus", "Vishesh Karwa", "Mitsunori Ogawa", "Sonja Petrović"], "title": "Non-asymptotic goodness-of-fit tests and model selection in valued stochastic blockmodels", "comment": null, "summary": "A valued stochastic blockmodel (SBM) is a general way to view networked data\nin which nodes are grouped into blocks and links between them are measured by\ncounts or labels. This family allows for varying dyad sampling schemes, thereby\nincluding the classical, Poisson, and labeled SBMs, as well as those in which\nsome edge observations are censored. This paper addresses the question of\ntesting goodness-of-fit of such non-Bernoulli SBMs, focusing in particular on\nfinite-sample tests. We derive explicit Markov bases moves necessary to\ngenerate samples from reference distributions and define goodness-of-fit\nstatistics for determining model fit, comparable to those in the literature for\nrelated model families.\n  For the labeled SBM, which includes in particular the censored-edge model, we\nstudy the asymptotic behavior of said statistics. One of the main purposes of\ntesting goodness-of-fit of an SBM is to determine whether block membership of\nthe nodes influences network formation. Power and Type 1 error rates are\nverified on simulated data. Additionally, we discuss the use of asymptotic\nresults in selecting the number of blocks under the latent-block modeling\nassumption. The method derived for Poisson SBM is applied to ecological\nnetworks of host-parasite interactions. Our data analysis conclusions differ in\nselecting the number of blocks for the species from previous results in the\nliterature."}
{"id": "2510.13034", "categories": ["math.NA", "cs.NA", "65N55, 65N80, 68T07, 65F08, 65F10"], "pdf": "https://arxiv.org/pdf/2510.13034", "abs": "https://arxiv.org/abs/2510.13034", "authors": ["Tianshi Xu", "Rui Peng Li", "Yuanzhe Xi"], "title": "Neural Approximate Inverse Preconditioners", "comment": "25 pages, 14 figures", "summary": "In this paper, we propose a data-driven framework for constructing efficient\napproximate inverse preconditioners for elliptic partial differential equations\n(PDEs) by learning the Green's function of the underlying operator with neural\nnetworks (NNs). The training process integrates four key components: an\nadaptive multiscale neural architecture ($\\alpha$MSNN) that captures\nhierarchical features across near-, middle-, and far-field regimes; the use of\ncoarse-grid anchor data to ensure physical identifiability; a\nmulti-$\\varepsilon$ staged training protocol that progressively refines the\nGreen's function representation across spatial scales; and an overlapping\ndomain decomposition that enables local adaptation while maintaining global\nconsistency. Once trained, the NN-approximated Green's function is directly\ncompressed into either a hierarchical ($\\mathcal{H}$-) matrix or a sparse\nmatrix-using only the mesh geometry and the network output. This geometric\nconstruction achieves nearly linear complexity in both setup and application\nwhile preserving the spectral properties essential for effective\npreconditioning. Numerical experiments on challenging elliptic PDEs demonstrate\nthat the resulting preconditioners consistently yield fast convergence and\nsmall iteration counts."}
{"id": "2510.12888", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2510.12888", "abs": "https://arxiv.org/abs/2510.12888", "authors": ["Yunxing Li", "Peigen Li", "Taimin Miao", "Rui Xu", "Yongqing Cai", "Neng Cai", "Bo Liang", "Han Gao", "Hanbo Xiao", "Yongzhen Jiang", "Jiefeng Cao", "Fangyuan Zhu", "Hongkun Wang", "Jincheng Xie", "Jingcheng Li", "Zhongkai Liu", "Chaoyu Chen", "Yunwei Zhang", "X. J. Zhou", "Dingyong Zhong", "Huichao Wang", "Jianwei Huang", "Donghui Guo"], "title": "Exotic Surface Stripe Orders in Correlated Kagome Metal CsCr3Sb5", "comment": "21 pages, 5 figures", "summary": "The newly discovered kagome superconductor CsCr3Sb5 exhibits distinct\nfeatures with flat bands and unique magnetism, providing a compelling platform\nfor exploring novel quantum states of correlated electron systems. Emergent\ncharge order in this material is a key for understanding unconventional\nsuperconductivity, but it remains unexplored at the atomic scale and the\nunderlying physics is elusive. Here, we identify and unreported stripe orders\non the surface which are distinct from the bulk and investigate the underlying\nbulk electronic properties using a combination of scanning tunneling microscopy\n(STM), angle-resolved photoemission spectroscopy (ARPES) and density functional\ntheory (DFT) calculations. Specifically, a mixture of 2a0 * a0 and 3a0 * a0\nstripe order is found on Cs-terminated surface while 4a0 * root3a0 stripe order\nis found on the Sb-terminated surface. The electronic spectra exhibit strongly\ncorrelated features resembling that of high temperature superconductors, with\nkagome flat bands lying about 330 meV above EF, suggesting that the electron\ncorrelations arise from Coulomb interactions and Hund's coupling. Moreover, a\ndistinct electron-boson coupling mode is observed at approximately 100 meV.\nThese findings provide new insights into the interplay between surface and bulk\ncharge orders in this strongly correlated kagome system."}
{"id": "2510.13104", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.13104", "abs": "https://arxiv.org/abs/2510.13104", "authors": ["Shrunal Pothagoni", "Dylan Miley", "Tyrus Berry", "Jeremy K. Mason", "Benjamin Schweinhart"], "title": "Dependence of Microstructure Classification Accuracy on Crystallographic Data Representation", "comment": null, "summary": "Convolutional neural networks are increasingly being used to analyze and\nclassify material microstructures, motivated by the possibility that they will\nbe able to identify relevant microstructural features more efficiently and\nimpartially than human experts. While up to now convolutional neural networks\nhave mostly been applied to light optimal microscopy and scanning electron\nmicroscope micrographs, application to EBSD micrographs will be increasingly\ncommon as rational design generates materials with unknown textures and phase\ncompositions. This raises the question of how crystallographic orientation\nshould be represented in such a convolutional neural network, and whether this\nchoice has a significant effect on the network's analysis and classification\naccuracy. Four representations of orientation information are examined and are\nused with convolutional neural networks to classify five synthetic\nmicrostructures with varying textures and grain geometries. Of these, a\nspectral embedding of crystallographic orientations in a space that respects\nthe crystallographic symmetries performs by far the best, even when the network\nis trained on small volumes of data such as could be accessible by practical\nexperiments."}
{"id": "2510.12917", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2510.12917", "abs": "https://arxiv.org/abs/2510.12917", "authors": ["Aiden Gundersen", "Neil J. Cornish"], "title": "Escaping Neal's Funnel: a multi-stage sampling method for hierarchical models", "comment": "8 pages, 4 figures", "summary": "Neal's funnel refers to an exponential tapering in probability densities\ncommon to Bayesian hierarchical models. Usual sampling methods, such as Markov\nChain Monte Carlo, struggle to efficiently sample the funnel. Reparameterizing\nthe model or analytically marginalizing local parameters are common techniques\nto remedy sampling pathologies in distributions exhibiting Neal's funnel. In\nthis paper, we show that the challenges of Neal's funnel can be avoided by\nperforming the hierarchical analysis, well, hierarchically. That is, instead of\nsampling all parameters of the hierarchical model jointly, we break the\nsampling into multiple stages. The first stage samples a generalized\n(higher-dimensional) hierarchical model which is parameterized to lessen the\nsharpness of the funnel. The next stage samples from the estimated density of\nthe first stage, but under a constraint which restricts the sampling to recover\nthe marginal distributions on the hyper-parameters of the original\n(lower-dimensional) hierarchical model. A normalizing flow can be used to\nrepresent the distribution from the first stage, such that it can easily be\nsampled from for the second stage of the analysis. This technique is useful\nwhen effective reparameterizations are computationally expensive to calculate,\nor a generalized hierarchical model already exists from which it is easy to\nsample."}
{"id": "2510.13083", "categories": ["math.OC", "cs.NA", "math.NA", "math.PR", "52A38, 60D05, 90C05, 90C31, 90C46"], "pdf": "https://arxiv.org/pdf/2510.13083", "abs": "https://arxiv.org/abs/2510.13083", "authors": ["Michael P. Friedlander", "Sharvaj Kubal", "Yaniv Plan", "Matthew S. Scott"], "title": "Average-case thresholds for exact regularization of linear programs", "comment": "25 pages, 4 figures", "summary": "Small regularizers can preserve linear programming solutions exactly. This\npaper provides the first average-case analysis of exact regularization: with a\nstandard Gaussian cost vector and fixed constraint set, bounds are established\nfor the probability that exact regularization succeeds as a function of\nregularization strength. Failure is characterized via the Gaussian measure of\ninner cones, controlled by novel two-sided bounds on the measure of shifted\ncones. Results reveal dimension-dependent scaling laws and connect exact\nregularization of linear programs to their polyhedral geometry via the normal\nfan and the Gaussian (solid-angle) measure of its cones. Computable bounds are\nobtained in several canonical settings, including regularized optimal\ntransport. Numerical experiments corroborate the predicted scalings and\nthresholds."}
{"id": "2510.12955", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12955", "abs": "https://arxiv.org/abs/2510.12955", "authors": ["Levi D. Reyes Premer", "Elias N. Pergantis", "Leo Semmelmann", "Davide Ziviani", "Kevin J. Kircher"], "title": "Model predictive control lowers barriers to adoption of heat-pump water heaters: A field study", "comment": null, "summary": "Electric heat-pump water heaters (HPWHs) could reduce the energy costs,\nemissions, and power grid impacts associated with water heating, the\nsecond-largest energy use in United States housing. However, most HPWHs today\nrequire 240 V circuits to power the backup resistance heating elements they use\nto maintain comfort during large water draws. Installing a 240 V circuit can\nincrease the up-front cost of a HPWH by half or more. This paper develops and\nfield-tests the first control system that enables a 120 V HPWH to efficiently\nmaintain comfort without resistance heating elements. The novel model\npredictive control (MPC) system enables pre-heating in anticipation of large\nwater draws, which it forecasts using an ensemble of machine learning\npredictors. By shifting electrical load over time, MPC also reduces energy\ncosts on average by 23% and 28% under time-of-use pricing and hourly pricing,\nrespectively, relative to a 240 V HPWH with standard controls. Compared to the\nincreasingly common practice in 120 V HPWHs of storing water at a constant,\nhigh temperature (60 {\\deg}C) to ensure comfort, MPC saves 37% energy on\naverage. In addition to demonstrating MPC's benefits in a real, occupied house,\nthis paper discusses implementation challenges and costs. A simple payback\nanalysis suggests that a 120 V HPWH, operated by the MPC system developed here,\nwould be economically attractive in most installation scenarios."}
{"id": "2510.13504", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.13504", "abs": "https://arxiv.org/abs/2510.13504", "authors": ["Louison Bocquet-Nouaille", "Jérôme Morio", "Benjamin Bobbia"], "title": "Control variates for variance-reduced ratio of means estimators", "comment": null, "summary": "The control variates method is a classical variance reduction technique for\nMonte Carlo estimators that exploits correlated auxiliary variables without\nintroducing bias. In many applications, the quantity of interest can be\nexpressed as a ratio of expectations. We propose a variance-reduced estimator\nfor such ratios, which applies control variates to both the numerator and the\ndenominator. The control variate coefficients are optimized jointly to minimize\nthe variance of the resulting estimator. This approach theoretically guarantees\nvariance reduction and naturally extends to approximate control variates.\nSimulation studies show significant variance reduction, particularly when\ncorrelations between variables and control variates are strong. The practical\nvalue of the method is illustrated with a multi-fidelity aircraft design use\ncase."}
{"id": "2510.13589", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.13589", "abs": "https://arxiv.org/abs/2510.13589", "authors": ["Timothée Herbeau", "Leonid Pastur", "Pascal Viot", "Gleb Oshanin"], "title": "Stochastic gyration driven by dichotomous noises", "comment": "45 pages, 18 figures", "summary": "We consider stochastic dynamics of a particle on a plane in presence of two\nnoises and\n  a confining parabolic potential - an analog of the experimentally-relevant\nBrownian Gyrator (BG) model. In contrast to the standard BG model, we suppose\nhere that the time-evolution of the position components is driven not by\nGaussian white-noises, but by two statistically-independent dichotomous noises.\nWe calculate analytically the position variances and cross-correlations, as\nwell as the mean angular momentum, which permits us to establish the conditions\nin which a spontaneous rotational motion of the particle around the origin\ntakes place. We also present a numerical analysis of the mean angular velocity.\n  Lastly, we\n  calculate analytically some marginal position probability density functions\nrevealing a remarkably rich behavior that emerges in such a system of two\ncoupled linear stochastic differential equations. We show that depending on the\nvalues of parameters characterizing noises these distributions approach the\nsteady-state forms defined on a finite support, having very unusual shapes,\npossessing multiple maxima and minima, plateaus and exhibiting a discontinuous\nbehavior."}
{"id": "2510.13785", "categories": ["q-fin.ST", "cs.CE", "physics.data-an", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.13785", "abs": "https://arxiv.org/abs/2510.13785", "authors": ["Stanisław Drożdż", "Robert Kluszczyński", "Jarosław Kwapień", "Marcin Wątorek"], "title": "Multifractality and its sources in the digital currency market", "comment": null, "summary": "Multifractality in time series analysis characterizes the presence of\nmultiple scaling exponents, indicating heterogeneous temporal structures and\ncomplex dynamical behaviors beyond simple monofractal models. In the context of\ndigital currency markets, multifractal properties arise due to the interplay of\nlong-range temporal correlations and heavy-tailed distributions of returns,\nreflecting intricate market microstructure and trader interactions.\nIncorporating multifractal analysis into the modeling of cryptocurrency price\ndynamics enhances the understanding of market inefficiencies, may improve\nvolatility forecasting and facilitate the detection of critical transitions or\nregime shifts. Based on the multifractal cross-correlation analysis (MFCCA)\nwhose spacial case is the multifractal detrended fluctuation analysis (MFDFA),\nas the most commonly used practical tools for quantifying multifractality, in\nthe present contribution a recently proposed method of disentangling sources of\nmultifractality in time series was applied to the most representative\ninstruments from the digital market. They include Bitcoin (BTC), Ethereum\n(ETH), decentralized exchanges (DEX) and non-fungible tokens (NFT). The results\nindicate the significant role of heavy tails in generating a broad multifractal\nspectrum. However, they also clearly demonstrate that the primary source of\nmultifractality are temporal correlations in the series, and without them,\nmultifractality fades out. It appears characteristic that these temporal\ncorrelations, to a large extent, do not depend on the thickness of the tails of\nthe fluctuation distribution. These observations, made here in the context of\nthe digital currency market, provide a further strong argument for the validity\nof the proposed methodology of disentangling sources of multifractality in time\nseries."}
{"id": "2510.13047", "categories": ["math.NA", "cs.NA", "35Q20, 65M70, 68T07"], "pdf": "https://arxiv.org/pdf/2510.13047", "abs": "https://arxiv.org/abs/2510.13047", "authors": ["Boyun Hu", "Kunlun Qi"], "title": "Solving the BGK Model and Boltzmann equation by Fourier Neural Operator with conservative constraints", "comment": null, "summary": "The numerical approximation of the Boltzmann collision operator presents\nsignificant challenges arising from its high dimensionality, nonlinear\nstructure, and nonlocal integral form. In this work, we propose a Fourier\nNeural Operator (FNO) based framework to learn the Boltzmann collision operator\nand its simplified BGK model across different dimensions. The proposed operator\nlearning approach efficiently captures the mapping between the distribution\nfunctions in either sequence-to-sequence or point to point manner, without\nrelying on fine grained discretization and large amount of data. To enhance\nphysical consistency, conservation constraints are embedded into the loss\nfunctional to enforce improved adherence to the fundamental conservation laws\nof mass, momentum, and energy compared with the original FNO framework. Several\nnumerical experiments are presented to demonstrate that the modified FNO can\nefficiently achieve the accurate and physically consistent results,\nhighlighting its potential as a promising framework for physics constrained\noperator learning in kinetic theory and other nonlinear integro-differential\nequations."}
{"id": "2510.12891", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.12891", "abs": "https://arxiv.org/abs/2510.12891", "authors": ["Michelangelo Tagliavini", "Fabian Wenzel", "Maurits W. Haverkort"], "title": "Polarization dependency in Resonant Inelastic X-Ray Scattering", "comment": null, "summary": "Resonant Inelastic X-Ray Scattering (RIXS) is a well-established tool for\nprobing excitations in a wide range of materials. The measured spectra strongly\ndepend on the scattering geometry, via its influence on the polarization of the\nincoming and outgoing light. By employing a tensor representation of the\n4-point response function that governs the RIXS intensity, we disentangle the\nexperimental geometry from the intrinsic material properties. In dipole-dipole\nRIXS processes and low-symmetry crystals, up to 81 linearly independent\nfundamental spectra can be measured as a function of light polarization.\nHowever, for crystals or molecules with symmetry, the number of independent\nfundamental spectra that define the RIXS tensor is significantly reduced.\n  This work presents a systematic framework for determining the number of\nfundamental spectra and expressing the RIXS tensor in terms of these\nfundamental components. Given a specific experimental geometry, the measured\nspectrum can be represented as a linear combination of these fundamental\nspectra. To validate our approach, we performed calculations for different\npoint group symmetries, both with and without an applied magnetic field. Within\nthe same framework, we derived expressions for powder spectra in\nmomentum-independent processes and spectra obtained using Bragg spectrometers.\nThis formalism provides a valuable toolkit for optimizing experiment planning,\ndata interpretation, and RIXS simulation."}
{"id": "2510.13120", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.13120", "abs": "https://arxiv.org/abs/2510.13120", "authors": ["Yizhi Li", "Yanyan Lu", "Jianxin Zhong", "Lijun Meng"], "title": "Long-Range Chiral Pairing enables Topological Superconductivity in Triangular Lattices without Spin-Orbit Coupling and Magnetic Field", "comment": "13 pages, 6 figures", "summary": "This paper demonstrates a pathway to topological superconductivity in\nmonolayer triangular lattices through long-range pairing without requiring\nspin-orbit coupling and magnetic field, contrasting conventional frameworks\nreliant on superconductivity and spin-orbit coupling and time-reversal symmetry\n(TRS) breaking. Berry curvature analysis reveals spontaneous\nTRS-breaking-induced peaks or valleys under long-range pairing, signaling\nnontrivial topology superconducting state. Notably, the increase in the\nlong-range pairing strength only changes the size of the energy band-gap,\nwithout triggering a topological phase transition. This characteristic is\nverified by calculating Berry curvature and topological edge states. In zigzag\nand armchair-edge ribbons of finite width, the topological edge states are\nregulated by the ribbon boundary symmetry and the interact range of long-range\npairing. Under nearest-neighbor pairing, the topological edge states maintain\nparticle-hole symmetry and matches the corresponding Chern number. However,\nnext-nearest-neighbor and third-nearest-neighbor pairings break the\nparticle-hole symmetry of the topological edge states in armchair-edge ribbon.\nThis work proposes a mechanism for realizing topological superconductivity\nwithout relying on spin-orbit coupling and magnetic field, offering a\ntheoretical foundation for simplifying the design of topological quantum\ndevices."}
{"id": "2510.13010", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.13010", "abs": "https://arxiv.org/abs/2510.13010", "authors": ["Chi Zhang", "Peijun Sang", "Yingli Qin"], "title": "Learning Shared and Source-specific Subspaces across Multiple Data Sources for Functional Data", "comment": null, "summary": "In the era of big data, integrating multi-source functional data to extract a\nsubspace that captures the shared subspace across sources has attracted\nconsiderable attention. In practice, data collection procedures often follow\nsource-specific protocols. Directly averaging sample covariance operators\nacross sources implicitly assumes homogeneity, which may bias the recovery of\nboth shared and source-specific variation patterns. To address this issue, we\npropose a projection-based data integration method that explicitly separates\nthe shared and source-specific subspaces. The method first estimates\nsource-specific projection operators via smoothing to accommodate the\nnonparametric nature of functional data. The shared subspace is then isolated\nby examining the eigenvalues of the averaged projection operator across all\nsources. If a source-specific subspace is of interest, we re-project the\nassociated source-specific covariance estimator onto the subspace orthogonal to\nthe estimated shared subspace, and estimate the source-specific subspace from\nthe resulting projection. We further establish the asymptotic properties of\nboth the shared and source-specific subspace estimators. Extensive simulation\nstudies demonstrate the effectiveness of the proposed method across a wide\nrange of settings. Finally, we illustrate its practical utility with an example\nof air pollutant data."}
{"id": "2510.13265", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.13265", "abs": "https://arxiv.org/abs/2510.13265", "authors": ["Cyril Letrouit"], "title": "Unstable optimal transport maps", "comment": null, "summary": "The stability of optimal transport maps with respect to perturbations of the\nmarginals is a question of interest for several reasons, ranging from the\njustification of the linearized optimal transport framework to numerical\nanalysis and statistics. Under various assumptions on the source measure, it is\nknown that optimal transport maps are stable with respect to variations of the\ntarget measure. In this note, we focus on the mechanisms that can, on the\ncontrary, lead to instability. We identify two of them, which we illustrate\nthrough examples of absolutely continuous source measures $\\rho$ in\n$\\mathbb{R}^d$ for which optimal transport maps are less stable, or even very\nunstable. We first show that instability may arise from the unboundedness of\nthe density: we exhibit a source density on the unit ball of $\\mathbb{R}^d$\nwhich blows up superpolynomially at two points of the boundary and for which\noptimal transport maps are highly unstable. Then we prove that even for uniform\ndensities on bounded open sets, optimal transport maps can be rather unstable\nclose enough to configurations where uniqueness of optimal plans is lost."}
{"id": "2510.12810", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12810", "abs": "https://arxiv.org/abs/2510.12810", "authors": ["Lucas Böttcher"], "title": "Control of dynamical systems with neural networks", "comment": "23 pages, 14 figures, 1 table", "summary": "Control problems frequently arise in scientific and industrial applications,\nwhere the objective is to steer a dynamical system from an initial state to a\ndesired target state. Recent advances in deep learning and automatic\ndifferentiation have made applying these methods to control problems\nincreasingly practical. In this paper, we examine the use of neural networks\nand modern machine-learning libraries to parameterize control inputs across\ndiscrete-time and continuous-time systems, as well as deterministic and\nstochastic dynamics. We highlight applications in multiple domains, including\nbiology, engineering, physics, and medicine. For continuous-time dynamical\nsystems, neural ordinary differential equations (neural ODEs) offer a useful\napproach to parameterizing control inputs. For discrete-time systems, we show\nhow custom control-input parameterizations can be implemented and optimized\nusing automatic-differentiation methods. Overall, the methods presented provide\npractical solutions for control tasks that are computationally demanding or\nanalytically intractable, making them valuable for complex real-world\napplications."}
{"id": "2510.12926", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.12926", "abs": "https://arxiv.org/abs/2510.12926", "authors": ["Jaron Kent-Dobias"], "title": "Structure of solutions to continuous constraint satisfaction problems through the statistics of wedged and inscribed spheres", "comment": null, "summary": "The study of random landscapes has long relied on counting stationary points:\nmetastable states and the barriers between them. However, this method is\nuseless for describing flat regions, common in constraint satisfaction\nproblems. We introduce a characterization of flat regions by counting the\nnumber of spheres that can be uniquely inserted into them, either by wedging\nspheres of fixed radius or by inscribing spheres of variable radius. The ratio\nof these counts constrains the topology of the solution space. We apply this\ncharacterization to the spherical perceptron and show the existence of at least\ntwo topological regimes."}
{"id": "2510.12961", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12961", "abs": "https://arxiv.org/abs/2510.12961", "authors": ["The Minh Nguyen", "Nagisa Sugishita", "Margarida Carvalho", "Amira Dems"], "title": "Competitive EV charging station location with queues", "comment": null, "summary": "Electric vehicle (EV) public charging infrastructure planning faces\nsignificant challenges in competitive markets, where multiple service providers\naffect congestion and user behavior. This work extends existing modeling\nframeworks by incorporating the presence of competitors' stations and more\nrealistic queueing systems.\n  First, we analyze three finite queueing systems, M/M/1/K, M/M/s/K, and\nM/Er/s/K, with varying numbers of servers (charging outlets) and service time\ndistributions, deriving analytic expressions for user behavior metrics. Second,\nwe embed the queueing-based user behavior model into a bilevel program, where\nthe upper level locates new charging stations to maximize accessibility\n(throughput), and the lower level captures users' station choices via a user\nequilibrium. Third, we apply a reformulation from competitive congested\nuser-choice facility location models to approximately solve the bilevel problem\nand introduce a surrogate-based heuristic to enhance scalability. Fourth, we\nshowcase our methodology on a real-world case study of an urban area in\nMontreal (Canada), offering managerial insights into how user-choice behavior\nassumptions and competition affect throughput and location decisions. The\nresults demonstrate that our model yields (re)location strategies that\noutperform the existing network. More broadly, this approach provides a tool\nfor incorporating charging service quality-through queueing metrics-and\nexisting competition into station planning."}
{"id": "2510.13605", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.13605", "abs": "https://arxiv.org/abs/2510.13605", "authors": ["Alexsandro A. Ferreira", "Gauss M. Cordeiro"], "title": "The generalized Marshall-Olkin Lomax distribution with applications to AIDS and COVID-19 data", "comment": null, "summary": "The generalized Marshall-Olkin Lomax distribution is introduced, and its\nproperties are easily obtained from those of the Lomax distribution. A\nregression model for censored data is proposed. The parameters are estimated\nthrough maximum likelihood, and consistency is verified by simulations. Three\nreal datasets are selected to illustrate the superiority of the new models\ncompared to those from two well-known classes."}
{"id": "2510.12926", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.12926", "abs": "https://arxiv.org/abs/2510.12926", "authors": ["Jaron Kent-Dobias"], "title": "Structure of solutions to continuous constraint satisfaction problems through the statistics of wedged and inscribed spheres", "comment": null, "summary": "The study of random landscapes has long relied on counting stationary points:\nmetastable states and the barriers between them. However, this method is\nuseless for describing flat regions, common in constraint satisfaction\nproblems. We introduce a characterization of flat regions by counting the\nnumber of spheres that can be uniquely inserted into them, either by wedging\nspheres of fixed radius or by inscribing spheres of variable radius. The ratio\nof these counts constrains the topology of the solution space. We apply this\ncharacterization to the spherical perceptron and show the existence of at least\ntwo topological regimes."}
{"id": "2510.13096", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.13096", "abs": "https://arxiv.org/abs/2510.13096", "authors": ["Shihan Guo", "Ping Lin", "Yifan Wang", "Xiaohe Yue", "Haibiao Zheng"], "title": "An Unconditionally Stable Explicit Robin-Robin Partitioned Scheme for Fluid-Structure Interaction", "comment": null, "summary": "We propose an explicit partitioned (loosely coupled) scheme for fluid\nstructure interaction (FSI) problems, specifically designed to achieve high\ncomputational efficiency in modern engineering simulations. The FSI problem\nunder consideration involves an incompressible viscous fluid, governed by the\nNavier-Stokes equations, with a thick linear elastic structure. The scheme\nadopts a Robin-Robin coupling condition, evaluating the right-hand side of the\nRobin boundary terms at each time step solely from the previous-step solutions.\nThis explicit scheme allows the fluid and structure subproblems to be solved\nentirely independently within each time step, eliminating the need for\nstaggered coupling or costly sub-iterations, which makes the method highly\nefficient and scalable for parallel computation. %More importantly, the\nproposed explicit scheme is inherently free from the added-mass effect\nguarantees unconditional stability. Various of numerical experiments\ndemonstrate the stability, accuracy, and superior computational efficiency of\nthe proposed approach, highlighting its strong potential for large scale\nparallel FSI computations in engineering applications."}
{"id": "2510.12918", "categories": ["cond-mat.str-el", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.12918", "abs": "https://arxiv.org/abs/2510.12918", "authors": ["Ian Jauslin", "Vieri Mastropietro"], "title": "Incommensurate Twisted Bilayer Graphene: emerging quasi-periodicity and stability", "comment": null, "summary": "We consider a lattice model of Twisted Bilayer Graphene (TBG). The presence\nof incommensurate angles produces an emerging quasi-periodicity manifesting\nitself in large momenta Umklapp interactions that almost connect the Dirac\npoints. We rigorously establish the stability of the semimetallic phase via a\nRenormalization Group analysis combined with number theoretical properties of\nirrationals, similar to the ones used in Kolmogorov-Arnold-Moser (KAM) theory\nfor the stability of invariant tori. The interlayer hopping is weak and short\nranged and the angles are chosen in a large measure set. The result provides a\njustification, in the above regime, to the effective continuum description of\nTBG in which large momenta interlayer interactions are neglected."}
{"id": "2510.13448", "categories": ["physics.comp-ph", "cond-mat.dis-nn", "cond-mat.mtrl-sci", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.13448", "abs": "https://arxiv.org/abs/2510.13448", "authors": ["Nikolaj Rønne", "Tejs Vegge", "Arghya Bhowmik"], "title": "GO-Diff: Data-free and amortized global structure optimization", "comment": null, "summary": "We introduce GO-Diff, a diffusion-based method for global structure\noptimization that learns to directly sample low-energy atomic configurations\nwithout requiring prior data or explicit relaxation. GO-Diff is trained from\nscratch using a Boltzmann-weighted score-matching loss, leveraging only the\nknown energy function to guide generation toward thermodynamically favorable\nregions. The method operates in a two-stage loop of self-sampling and model\nrefinement, progressively improving its ability to target low-energy\nstructures. Compared to traditional optimization pipelines, GO-Diff achieves\ncompetitive results with significantly fewer energy evaluations. Moreover, by\nreusing pretrained models across related systems, GO-Diff supports amortized\noptimization - enabling faster convergence on new tasks without retraining from\nscratch."}
{"id": "2510.13159", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.13159", "abs": "https://arxiv.org/abs/2510.13159", "authors": ["Hung Hung", "Zhi-Yu Jou", "Su-Yun Huang", "Shinto Eguchi"], "title": "The $φ$-PCA Framework: A Unified and Efficiency-Preserving Approach with Robust Variants", "comment": "27 pages, 4 figures", "summary": "Principal component analysis (PCA) is a fundamental tool in multivariate\nstatistics, yet its sensitivity to outliers and limitations in distributed\nenvironments restrict its effectiveness in modern large-scale applications. To\naddress these challenges, we introduce the $\\phi$-PCA framework which provides\na unified formulation of robust and distributed PCA. The class of $\\phi$-PCA\nmethods retains the asymptotic efficiency of standard PCA, while aggregating\nmultiple local estimates using a proper $\\phi$ function enhances\nordering-robustness, leading to more accurate eigensubspace estimation under\ncontamination. Notably, the harmonic mean PCA (HM-PCA), corresponding to the\nchoice $\\phi(u)=u^{-1}$, achieves optimal ordering-robustness and is\nrecommended for practical use. Theoretical results further show that robustness\nincreases with the number of partitions, a phenomenon seldom explored in the\nliterature on robust or distributed PCA. Altogether, the partition-aggregation\nprinciple underlying $\\phi$-PCA offers a general strategy for developing robust\nand efficiency-preserving methodologies applicable to both robust and\ndistributed data analysis."}
{"id": "2510.13333", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.13333", "abs": "https://arxiv.org/abs/2510.13333", "authors": ["François Pacaud", "Armin Nurkanović", "Anton Pozharskiy", "Alexis Montoison", "Sungho Shin"], "title": "An Augmented Lagrangian Method on GPU for Security-Constrained AC Optimal Power Flow", "comment": null, "summary": "We present a new algorithm for solving large-scale security-constrained\noptimal power flow in polar form (AC-SCOPF). The method builds on Nonlinearly\nConstrained augmented Lagrangian (NCL), an augmented Lagrangian method in which\nthe subproblems are solved using an interior-point method. NCL has two key\nadvantages for large-scale SC-OPF. First, NCL handles difficult problems such\nas infeasible ones or models with complementarity constraints. Second, the\naugmented Lagrangian term naturally regularizes the Newton linear systems\nwithin the interior-point method, enabling to solve the Newton systems with a\npivoting-free factorization that can be efficiently parallelized on GPUs. We\nassess the performance of our implementation, called MadNCL, on large-scale\ncorrective AC-SCOPFs, with complementarity constraints modeling the corrective\nactions. Numerical results show that MadNCL can solve AC-SCOPF with 500 buses\nand 256 contingencies fully on the GPU in less than 3 minutes, whereas Knitro\ntakes more than 3 hours to find an equivalent solution."}
{"id": "2510.12832", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12832", "abs": "https://arxiv.org/abs/2510.12832", "authors": ["Alistair Brash", "Junyi Lu", "Bruce Stephen", "Blair Brown", "Robert Atkinson", "Craig Michie", "Fraser MacIntyre", "Christos Tachtatzis"], "title": "Coherent Load Profile Synthesis with Conditional Diffusion for LV Distribution Network Scenario Generation", "comment": null, "summary": "Limited visibility of power distribution network power flows at the low\nvoltage level presents challenges to both distribution network operators from a\nplanning perspective and distribution system operators from a congestion\nmanagement perspective. Forestalling these challenges through scenario analysis\nis confounded by the lack of realistic and coherent load data across\nrepresentative distribution feeders. Load profiling approaches often rely on\nsummarising demand through typical profiles, which oversimplifies the\ncomplexity of substation-level operations and limits their applicability in\nspecific power system studies. Sampling methods, and more recently generative\nmodels, have attempted to address this through synthesising representative\nloads from historical exemplars; however, while these approaches can\napproximate load shapes to a convincing degree of fidelity, the co-behaviour\nbetween substations, which ultimately impacts higher voltage level network\noperation, is often overlooked. This limitation will become even more\npronounced with the increasing integration of low-carbon technologies, as\nestimates of base loads fail to capture load diversity. To address this gap, a\nConditional Diffusion model for synthesising daily active and reactive power\nprofiles at the low voltage distribution substation level is proposed. The\nevaluation of fidelity is demonstrated through conventional metrics capturing\ntemporal and statistical realism, as well as power flow modelling. The results\nshow synthesised load profiles are plausible both independently and as a cohort\nin a wider power systems context. The Conditional Diffusion model is\nbenchmarked against both naive and state-of-the-art models to demonstrate its\neffectiveness in producing realistic scenarios on which to base sub-regional\npower distribution network planning and operations."}
{"id": "2510.13090", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2510.13090", "abs": "https://arxiv.org/abs/2510.13090", "authors": ["Ruoxia Chen", "Kai Yang", "Morten M. Smedskjaer", "N. M. Anoop Krishnan", "Jaime Marian", "Fabian Rosner"], "title": "Optimization of Transferable Interatomic Potentials for Glasses toward Experimental Properties", "comment": null, "summary": "The accuracy of molecular simulations is fundamentally limited by the\ninteratomic potentials that govern atomic interactions. Traditional potential\ndevelopment, which relies heavily on ab initio calculations, frequently\nstruggles to reproduce the experimentally observed properties that govern real\nmaterial behavior. To address this challenge, we present a machine\nlearning-driven, active-learning optimization framework for optimizing\nclassical interatomic potentials to reproduce experimental properties. Our\nmethod, here showcased on soda-lime borosilicate glasses, targets both global\n(density) and local (boron coordination) structural features across a wide\nrange of compositions. By combining a surrogate model with iterative active\nlearning, the framework efficiently explores a five-dimensional parameter space\nusing only 400 molecular dynamics simulations over 17 iterations, making it\nhighly data-efficient and eliminating the need for extensive simulation\ncampaigns. Two transferable parameter sets are identified, each demonstrating\ngood agreement with experimental measurements, including glass density,\nfraction of four-fold boron, and X-ray structure factor. The framework\neffectively captures and manages inherent trade-offs between structural\nobjectives and compositional regimes, providing insights into the coordination\nbehavior of boron in complex glass networks. The resulting classical force\nfields are generalizable and do not require reparameterization for individual\ncompositions. Altogether, this work offers a scalable and experimentally\ngrounded approach for developing transferable interatomic potentials suitable\nfor a broad range of materials, including multi-component glass systems, and\nbeyond."}
{"id": "2510.13000", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13000", "abs": "https://arxiv.org/abs/2510.13000", "authors": ["Giacomo Bastianel", "Dirk Van Hertem", "Hakan Ergun", "Line Roald"], "title": "Identifying Best Candidates for Busbar Splitting", "comment": null, "summary": "Rising electricity demand and the growing integration of renewables are\nintensifying congestion in transmission grids. Grid topology optimization\nthrough busbar splitting (BuS) and optimal transmission switching can alleviate\ngrid congestion and reduce the generation costs in a power system. However, BuS\noptimization requires a large number of binary variables, and analyzing all the\nsubstations for potential new topological actions is computationally\nintractable, particularly in large grids. To tackle this issue, we propose a\nset of metrics to identify and rank promising candidates for BuS, focusing on\nfinding buses where topology optimization can reduce generation costs. To\nassess the effect of BuS on the identified buses, we use a combined\nmixed-integer convex-quadratic BuS model to compute the optimal topology and\ntest it with the non-linear non-convex AC optimal power flow (OPF) simulation\nto show its AC feasibility. By testing and validating the proposed metrics on\ntest cases of different sizes, we show that they are able to identify busbars\nthat reduce the total generation costs when their topology is optimized. Thus,\nthe metrics enable effective selection of busbars for BuS, with no need to test\nevery busbar in the grid, one at a time."}
{"id": "2510.13703", "categories": ["math.ST", "stat.ML", "stat.TH", "62E20, 62R30"], "pdf": "https://arxiv.org/pdf/2510.13703", "abs": "https://arxiv.org/abs/2510.13703", "authors": ["Lvfang Sun", "Zhenhua Lin", "Lin Liu"], "title": "Towards an Asymptotic Efficiency Theory on Regular Parameter Manifolds", "comment": "Comments are welcome!", "summary": "Asymptotic efficiency theory is one of the pillars in the foundations of\nmodern mathematical statistics. Not only does it serve as a rigorous\ntheoretical benchmark for evaluating statistical methods, but it also sheds\nlight on how to develop and unify novel statistical procedures. For example,\nthe calculus of influence functions has led to many important statistical\nbreakthroughs in the past decades. Responding to the pressing challenge of\nanalyzing increasingly complex datasets, particularly those with\nnon-Euclidean/nonlinear structures, many novel statistical models and methods\nhave been proposed in recent years. However, the existing efficiency theory is\nnot always readily applicable to these cases, as the theory was developed, for\nthe most part, under the often neglected premise that both the sample space and\nthe parameter space are normed linear spaces. As a consequence, efficiency\nresults outside normed linear spaces are quite rare and isolated, obtained on a\ncase-by-case basis. This paper aims to develop a more unified asymptotic\nefficiency theory, allowing the sample space, the parameter space, or both to\nbe Riemannian manifolds satisfying certain regularity conditions. We build a\nvocabulary that helps translate essential concepts in efficiency theory from\nnormed linear spaces to Riemannian manifolds, such as (locally) regular\nestimators, differentiable functionals, etc. Efficiency bounds are established\nunder conditions parallel to those for normed linear spaces. We also\ndemonstrate the conceptual advantage of the new framework by applying it to two\nconcrete examples in statistics: the population Frechet mean and the regression\ncoefficient vector of Single-Index Models."}
{"id": "2510.13199", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.13199", "abs": "https://arxiv.org/abs/2510.13199", "authors": ["Jongwon David Kim", "Jack Xin"], "title": "A Particle-Field Algorithm with Neural Interpolation for a Parabolic-Hyperbolic Chemotaxis System in 3D", "comment": null, "summary": "Tumor angiogenesis involves a collection of tumor cells moving towards blood\nvessels for nutrients to grow. Angiogenesis, and in general chemo- taxis,\nsystems have been modeled using partial differential equations (PDEs) and as\nsuch require numerical methods to approximate their solutions. Here we study a\nParabolic-Hyperbolic Keller-Segel (PHKS) system in three space dimensions. The\nmodel arises in the angiogenesis literature. To compute solutions to the PHKS\nsystem, we develop a neural stochastic interacting particle-field (NSIPF)\nmethod where the density variable is represented as empirical measures of\nparticles and the field variable (concentration of chemoattractant)\napproximated by a convolutional neural network (CNN). We discuss the\nperformance of NSIPF in computing multi-bump solutions to the system."}
{"id": "2510.13045", "categories": ["cond-mat.str-el", "cond-mat.supr-con", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.13045", "abs": "https://arxiv.org/abs/2510.13045", "authors": ["Archi Banerjee", "Meng Zeng"], "title": "Entanglement spectrum of gapless topological phases: a case study with topological superconductors", "comment": "6 pages + reference, 5 figures", "summary": "Using bulk gapless topological superconductors in both 1d and 2d as free\nfermion model examples, we demonstrate the power of subsystem correlation\nspectrum (the spectrum of correlation matrix), or equivalently the entanglement\nspectrum for the case of free fermions, in characterizing the topology of the\nnon-trivial ground state. For the systems considered, we show that signatures\nof the lowenergy spectrum, including both the edge modes and the bulk modes,\nappear in the correlation spectrum, albeit with different behaviors. This work\ngeneralizes the 2d Li-Haldane entanglement spectrum characterization of\ntopological edge states to 2d topological systems with gapless bulk."}
{"id": "2510.13568", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.13568", "abs": "https://arxiv.org/abs/2510.13568", "authors": ["Di Fan", "Changming Ke", "Shi Liu"], "title": "Rippled Moire Superlattices for Decoupled Ferroelectric Bits", "comment": null, "summary": "Symmetry considerations suggest that moire superlattices formed by twisted\ntwo-dimensional materials should preserve overall inversion symmetry. However,\nexperiments consistently report robust ferroelectricity in systems such as\ntwisted bilayer h-BN, posing a fundamental discrepancy between theory and\nexperiment regarding its microscopic origin. Here, using large-scale\nfinite-field molecular dynamics simulations, we challenge the prevailing\ndefect-pinning hypothesis and instead identify an out-of-plane bending field,\ninduced by in-plane compressive strain, as the key symmetry-breaking mechanism.\nThis strain-induced rippling drives spatially heterogeneous interlayer sliding\nand distorts the moire domain wall network, resulting in a four-state\nferroelectric system. Remarkably, we show this mechanism can be harnessed at\nthe nanoscale, where localized nanobubbles designate the moire lattice's\nfundamental hexagonal domain clusters as the smallest individually addressable\nferroelectric bits, thereby imposing local control on an otherwise globally\ndefined structure. Our findings establish a geometry-driven framework for\nunderstanding and engineering moire ferroelectrics, offering not only a route\ntoward ultra-high-density, rewritable memory, but also a strategy for locally\ntuning the moire potential itself, a critical step for manipulating emergent\ncorrelated and topological quantum phases."}
{"id": "2510.13216", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.13216", "abs": "https://arxiv.org/abs/2510.13216", "authors": ["David Kronthaler", "Leonhard Held"], "title": "Edgington's Method for Random-Effects Meta-Analysis Part II: Prediction", "comment": null, "summary": "Statistical inference about the average effect in random-effects\nmeta-analysis has been considered insufficient in the presence of substantial\nbetween-study heterogeneity. Predictive distributions are well-suited for\nquantifying heterogeneity since they are interpretable on the effect scale and\nprovide clinically relevant information about future events. We construct\npredictive distributions accounting for uncertainty through confidence\ndistributions from Edgington's $p$-value combination method and the generalized\nheterogeneity statistic. Simulation results suggest that 95% prediction\nintervals typically achieve nominal coverage when more than three studies are\navailable and effectively reflect skewness in effect estimates in scenarios\nwith 20 or less studies. Formulations that ignore uncertainty in heterogeneity\nestimation typically fail to achieve correct coverage, underscoring the need\nfor this adjustment in random-effects meta-analysis."}
{"id": "2510.13354", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.13354", "abs": "https://arxiv.org/abs/2510.13354", "authors": ["Kazuhiro Sato"], "title": "Target Controllability Score", "comment": null, "summary": "We introduce the target controllability score (TCS), a concept for evaluating\nnode importance under actuator constraints and designated target objectives,\nformulated within a virtual system setting. The TCS consists of the target\nvolumetric controllability score (VCS) and the target average energy\ncontrollability score (AECS), each defined as an optimal solution to a convex\noptimization problem associated with the output controllability Gramian. We\nestablish the existence and uniqueness (for almost all time horizons) and\ndevelop a projected gradient method for their computation. To enable\nscalability, we construct a target-only reduced virtual system and derive\nnon-asymptotic bounds showing that weak cross-coupling and a low or negative\nlogarithmic norm of the system matrix yield accurate approximations of target\nVCS/AECS, particularly over short or moderate time horizons. Experiments on\nhuman brain networks reveal a clear trade-off: at short horizons, both target\nVCS and target AECS are well approximated by their reduced formulations, while\nat long horizons, target AECS remains robust but target VCS deteriorates."}
{"id": "2510.12897", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12897", "abs": "https://arxiv.org/abs/2510.12897", "authors": ["Sanjay Johnson", "Dirk Lauinger", "Sungho Shin", "François Pacaud"], "title": "ExaModelsPower.jl: A GPU-Compatible Modeling Library for Nonlinear Power System Optimization", "comment": null, "summary": "As GPU-accelerated mathematical programming techniques mature, there is\ngrowing interest in utilizing them to address the computational challenges of\npower system optimization. This paper introduces ExaModelsPower.jl, an\nopen-source modeling library for creating GPU-compatible nonlinear AC optimal\npower flow models. Built on ExaModels.jl, ExaModelsPower.jl provides a\nhigh-level interface that automatically generates all necessary callback\nfunctions for GPU solvers. The library is designed for large-scale problem\ninstances, which may include multiple time periods and security constraints.\nUsing ExaModelsPower.jl, we benchmark GPU and CPU solvers on open-source test\ncases. Our results show that GPU solvers can deliver up to two orders of\nmagnitude speedups compared to alternative tools on CPU for problems with more\nthan 20,000 variables and a solution precision of up to $10^{-4}$, while\nperformance for smaller instances or tighter tolerances may vary."}
{"id": "2510.13178", "categories": ["cond-mat.dis-nn", "cond-mat.mtrl-sci", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2510.13178", "abs": "https://arxiv.org/abs/2510.13178", "authors": ["Zhen Zhang", "Zhencheng Xie", "Walter Kob"], "title": "Symmetry Transitions Beyond the Nanoscale in Pressurized Silica Glass", "comment": null, "summary": "Silica is the paradigmatic network glass-former and understanding its\nresponse to pressure is essential for comprehending the mechanical properties\nof silica-based materials and the behavior of silicate melts in the Earth's\ninterior. While pressure-induced changes in the short-range structure -\nparticularly the breakdown of tetrahedral symmetry - have been well documented,\nstructural transformations on larger length scales, important for many material\nproperties, remain poorly understood. Here, we numerically investigate the\nthree-dimensional structure of silica glass as a function of compression up to\n$P \\approx 100$~GPa. Using a novel many-body correlation function, we reveal a\ncomplex medium-range order: While for $P \\lesssim 10$~GPa, one finds\ntetrahedral, octahedral, and cubic symmetries, the structure at higher $P$s\nexhibits alternating cubic and octahedral particle arrangements. The\n$P$-dependence of the corresponding structural correlation length displays two\ndistinct maxima, which permits to rationalize the anomalous compressibility of\nsilica. The identified complex structural organization on intermediate range\nscales is the result of a pressure-and scale-dependent interplay between\ndirectional bonding, packing efficiency, and network stiffness. Since these\ncompeting effects are common in network glass-formers, the identified\nthree-dimensional medium-range order, and hence the physical properties of the\nglass, are expected to be universal features of such materials under extreme\nconditions."}
{"id": "2510.13004", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13004", "abs": "https://arxiv.org/abs/2510.13004", "authors": ["Robert Muldrow", "Channing Ludden", "Christopher Petersen"], "title": "Comparison of Forced and Unforced Rendezvous, Proximity Operations, and Docking Under Model Mismatch", "comment": "12 pages, 4 figures, AAS/AIAA Space Flight Mechanics", "summary": "This paper compares the required fuel usage for forced and unforced motion of\na chaser satellite engaged in Rendezvous, Proximity Operations, and Docking\n(RPOD) maneuvers. Improved RPOD models are vital, particularly as the space\nindustry expands and demands for improved fuel efficiency, cost effectiveness,\nand mission life span increase. This paper specifically examines the Clohessy-\nWiltshire (CW) Equations and the extent of model mismatch by comparing pre-\ndicted trajectories from this model with a more computationally complex, higher\nfidelity RPOD model. This paper assesses several test cases of similar mission\nparameters, in each case comparing natural motion circumnavigation (NMC) with\ncomparable forced motion circumnavigation. The Guidance, Navigation, and Con-\ntrol (GNC) impulse maneuvers required to maintain the supposedly zero fuel CW\ntrajectories is representative of the extent of CW model mismatch. This paper\ndemonstrates that unforced motions are not inherently more fuel efficient than\nforced motions, thus permitting extended orbital operations given the higher\nfuel efficiency."}
{"id": "2510.13751", "categories": ["math.ST", "cs.LG", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.13751", "abs": "https://arxiv.org/abs/2510.13751", "authors": ["Lap Chi Lau", "Akshay Ramachandran"], "title": "Optimal Bounds for Tyler's M-Estimator for Elliptical Distributions", "comment": "13 pages + proofs in Appendix", "summary": "A fundamental problem in statistics is estimating the shape matrix of an\nElliptical distribution. This generalizes the familiar problem of Gaussian\ncovariance estimation, for which the sample covariance achieves optimal\nestimation error. For Elliptical distributions, Tyler proposed a natural\nM-estimator and showed strong statistical properties in the asymptotic regime,\nindependent of the underlying distribution. Numerical experiments show that\nthis estimator performs very well, and that Tyler's iterative procedure\nconverges quickly to the estimator. Franks and Moitra recently provided the\nfirst distribution-free error bounds in the finite sample setting, as well as\nthe first rigorous convergence analysis of Tyler's iterative procedure.\nHowever, their results exceed the sample complexity of the Gaussian setting by\na $\\log^{2} d$ factor. We close this gap by proving optimal sample threshold\nand error bounds for Tyler's M-estimator for all Elliptical distributions,\nfully matching the Gaussian result. Moreover, we recover the algorithmic\nconvergence even at this lower sample threshold. Our approach builds on the\noperator scaling connection of Franks and Moitra by introducing a novel\npseudorandom condition, which we call $\\infty$-expansion. We show that\nElliptical distributions satisfy $\\infty$-expansion at the optimal sample\nthreshold, and then prove a novel scaling result for inputs satisfying this\ncondition."}
{"id": "2510.13204", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.13204", "abs": "https://arxiv.org/abs/2510.13204", "authors": ["Maolin Che", "Congpei An", "Yimin Wei", "Hong Yan"], "title": "How many integrals should be evaluated at least in two-dimensional hyperinterpolation?", "comment": "37 pages, 41 figures", "summary": "This paper introduces a novel approach to approximating continuous functions\nover high-dimensional hypercubes by integrating matrix CUR decomposition with\nhyperinterpolation techniques. Traditional Fourier-based hyperinterpolation\nmethods suffer from the curse of dimensionality, as the number of coefficients\ngrows exponentially with the dimension. To address this challenge, we propose\ntwo efficient strategies for constructing low-rank matrix CUR decompositions of\nthe coefficient matrix, significantly reducing computational complexity while\npreserving accuracy.\n  The first method employs structured index selection to form a compressed\nrepresentation of the tensor, while the second utilizes adaptive sampling to\nfurther optimize storage and computation. Theoretical error bounds are derived\nfor both approaches, ensuring rigorous control over approximation quality.\nAdditionally, practical algorithms -- including randomized and adaptive\ndecomposition techniques -- are developed to efficiently compute the CUR\ndecomposition. Numerical experiments demonstrate the effectiveness of our\nmethods in drastically reducing the number of required coefficients without\ncompromising precision.\n  Our results bridge matrix/tensor decomposition and function approximation,\noffering a scalable solution for high-dimensional problems. This work advances\nthe field of numerical analysis by providing a computationally efficient\nframework for hyperinterpolation, with potential applications in scientific\ncomputing, machine learning, and data-driven modeling."}
{"id": "2510.13530", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.13530", "abs": "https://arxiv.org/abs/2510.13530", "authors": ["Zixuan Jia", "Lufeng Zhang", "Qingzhuo Duan", "Zenghui Fan", "Jingyao Wang", "Bing Huang", "Tianxing Ma"], "title": "Interplay of magnetic and thermodynamic responses in the kagome-triangular system", "comment": "8 pages, 6 figures", "summary": "Inspired by the recent experimental progress in pyrochlore derivative\n\\ce{RE3Sb3A2O14 (A=Mg, Zn)}, we investigate the Hubbard model on the kagome\nlattice with an additional hopping $t'/t$, which enables continuous\ninterpolation between the kagome and triangular lattices by using determinant\nquantum Monte Carlo simulations. We analyze the evolution of magnetic\ncorrelations and thermodynamic responses across different values of $t'/t$ and\non-site interaction $U$. It is found that increasing $t'/t$ suppresses\nshort-range antiferromagnetic correlations, while the next-nearest-neighbor\ncorrelations exhibit a sign change near $t'/t \\approx 0.3 \\text{--} 0.4$.\nWithin this regime, the specific heat shows a pronounced low-temperature peak,\nindicating an emergent spin-related energy scale. Increasing $U$ enhances\nmagnetic correlations and shifts the associated $t'/t$ crossover points to\nlarger values. We also discuss the sign problem to clarify which parameter\nregion of our numerical simulations is accessible and reliable. Our results\nuncover the competition between frustration and correlations and the interplay\nof magnetic and thermodynamic responses in the kagome lattice, providing\ninsights into correlated states in frustrated materials."}
{"id": "2510.13597", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.13597", "abs": "https://arxiv.org/abs/2510.13597", "authors": ["Fabrizio Aguzzi", "Martín Armoa", "Santiago M. Rabazzi", "César Pairetti", "Alejandro Albanesi"], "title": "Multiphysics Finite Element Modeling of Irradiation and Thermal Behavior Demonstrated on a Fuel-Assembly Problem", "comment": "preprint on review", "summary": "This work presents a modeling framework to represent the thermomechanical\nbehavior of complex materials based on micromechanical dynamics. The framework\nis applied to nuclear fuel rod elements composed of Zircaloy-2 cladding tubes\nand spacer grids under typical Pressurized Water Reactor (PWR) conditions.\nThermal expansion and thermal creep are incorporated through a VPSC-FEM\ncoupling with the finite element solver Code_Aster, enabling analysis of\nin-reactor behavior under combined thermal, mechanical, and irradiation\nloading. The model captures anisotropic deformation driven by crystallographic\ntexture and prismatic slip activity under radial loading. Thermal creep, being\nstress-sensitive, contributes to early-stage stress relaxation and strain\naccumulation, leading to higher strain compared to the irradiation-only case.\nThe interaction of thermal creep with irradiation mechanisms modifies the\nstress distribution and clearance evolution, with relaxation governed by\nprismatic slip. For fuel rod components, irradiation-induced mechanisms\ndominate the long-term clearance behavior, whereas thermal effects remain\nrelevant in contact dynamics during thermal preloading. The stress-strain\nresponse is found to be more sensitive to micromechanical processes than to\nelastic constants. This high-resolution formulation enables predictive modeling\nof spacer-cladding interaction and provides a foundation for developing\nreduced-order models."}
{"id": "2510.13233", "categories": ["stat.ME", "stat.CO", "62M30"], "pdf": "https://arxiv.org/pdf/2510.13233", "abs": "https://arxiv.org/abs/2510.13233", "authors": ["Arghya Mukherjee", "Arnab Hazra", "Dootika Vats"], "title": "Scalable Bayesian inference for high-dimensional mixed-type multivariate spatial data", "comment": "38 pages, 3 figures, 8 tables", "summary": "Spatial generalized linear mixed-effects methods are popularly used to model\nspatially indexed univariate responses. However, with modern technology, it is\ncommon to observe vector-valued mixed-type responses, e.g., a combination of\nbinary, count, or continuous types, at each location. Methods that allow joint\nmodeling of such mixed-type multivariate spatial responses are rare. Using\nlatent multivariate Gaussian processes (GPs), we present a class of Bayesian\nspatial methods that can be employed for any combination of exponential family\nresponses. Since multivariate GP-based methods can suffer from computational\nbottlenecks when the number of spatial locations is high, we further employ a\ncomputationally efficient Vecchia approximation for fast posterior inference\nand prediction. Key theoretical properties of the proposed model, such as\nidentifiability and the structure of the induced covariance, are established.\nOur approach employs a Markov chain Monte Carlo-based inference method that\nutilizes elliptical slice sampling in a blocked Metropolis-within-Gibbs\nsampling framework. We illustrate the efficacy of the proposed method through\nsimulation studies and a real-data application on joint modeling of wildfire\ncounts and burnt areas across the United States."}
{"id": "2510.13458", "categories": ["math.OC", "34H05, 49J15, 49J45, 49N90"], "pdf": "https://arxiv.org/pdf/2510.13458", "abs": "https://arxiv.org/abs/2510.13458", "authors": ["Matteo Della Rossa", "Lorenzo Freddi", "Mattia Pinatto"], "title": "A non-parametric Zermelo navigation equation for strictly convex control sets", "comment": null, "summary": "We study a generalized version of Zermelo's navigation problem in which the\nadmissible set of control velocities is a strictly convex compact set, rather\nthan the classical spherical or ball-shaped one. After establishing existence\nresults under the natural assumption of weak currents, we derive necessary\noptimality conditions via Pontryagin's maximum principle and convex analysis.\nIn particular, we prove that strictly convex control sets ensure smoothness of\noptimal controls. In dimension two, this regularity allows us to eliminate the\nadjoint variables and obtain a second-order differential equation for the\noptimal control, which extends the classical Zermelo navigation equation to\nstrictly convex control sets in a non-parametric setting. We also develop the\ncase of an affine current, with a particular emphasis on the constant one where\noptimal trajectories reduce to straight lines. The results are illustrated with\nexamples relevant to ship routing with asymmetric or sail-assisted propulsion."}
{"id": "2510.12914", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12914", "abs": "https://arxiv.org/abs/2510.12914", "authors": ["Zhi Liu", "Chengxi Liu", "Jiangbei Han", "Rui Qiu", "Mingyuan Liu"], "title": "A Wideband Composite Sequence Impedance Model for Evaluation of Interactions in Unbalanced Power-Electronic-Based Power Systems", "comment": "This work will be submitted to the IEEE for possible publication", "summary": "This paper proposes a wideband composite sequence impedance model\n(WCSIM)-based analysis method to evaluate the interactions in\npower-electronic-based power systems subjected to unbalanced grid faults or\nwith unbalanced loads. The WCSIM-based method intuitively assesses the impact\nof the small-signal interconnection among the positive-, negative-, and\nzero-sequence circuits on the interaction stability of unbalanced power\nsystems. The effectiveness of this method is demonstrated using a permanent\nmagnet synchronous generator-based weak grid system under a\nsingle-line-to-ground fault (SLGF). Frequency scanning results and controller\nhardware-in-loop tests validate both the correctness of the WCSIM and the\neffectiveness of the WCSIM-based analysis method."}
{"id": "2510.13645", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2510.13645", "abs": "https://arxiv.org/abs/2510.13645", "authors": ["Mengyang Cui", "Hongxing Qi", "Chengduo Hu", "Qing Li"], "title": "Analysis and Prediction of Dark Current Mechanisms in Si:P Blocked Impurity Band (BIB) Infrared Detectors", "comment": null, "summary": "We investigated the nonlinear phenomena observed in the dark current of BIB\n(blocked-impurity-band) infrared detectors, including negative differential\nresistance (NDR) and current oscillations. Our analysis systematically\nelucidated the intrinsic transport mechanisms in optimized devices, revealing\nthat these anomalies arise from current path clustering induced by structural\ndisorder and impurity band conduction dynamics. Notably, the simulated\ncurrent-voltage (I-V) characteristics demonstrated strong agreement with\nexperimental measurements across a wide bias range, confirming the validity of\nour proposed physical model.Furthermore, we developed a transformer-based\npredictive model using experimental dark current datasets. The model achieved\nrobust performance metrics and this framework enables rapid prediction of dark\ncurrent trends under varying operational conditions, providing actionable\ninsights for detector optimization."}
{"id": "2510.13024", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13024", "abs": "https://arxiv.org/abs/2510.13024", "authors": ["Shahab Ataei", "Dipankar Maity", "Debdipta Goswami"], "title": "Data to Certificate: Guaranteed Cost Control with Quantization-Aware System Identification", "comment": "8 pages, 3 figures", "summary": "Cloud-assisted system identification and control have emerged as practical\nsolutions for low-power, resource-constrained control systems such as\nmicro-UAVs. In a typical cloud-assisted setting, state and input data are\ntransmitted from local agents to a central computer over low-bandwidth wireless\nlinks, leading to quantization. This paper investigates the impact of state and\ninput data quantization on a linear time invariant (LTI) system identification,\nderives a worst-case bound on the identification error, and develops a robust\ncontroller for guaranteed cost control. We establish a fundamental bound on the\nmodel error that depends only on the quantized data and quantization\nresolution, and develop a linear matrix inequality (LMI) based guaranteed cost\nrobust controller under this error bound."}
{"id": "2510.13159", "categories": ["stat.ME", "math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.13159", "abs": "https://arxiv.org/abs/2510.13159", "authors": ["Hung Hung", "Zhi-Yu Jou", "Su-Yun Huang", "Shinto Eguchi"], "title": "The $φ$-PCA Framework: A Unified and Efficiency-Preserving Approach with Robust Variants", "comment": "27 pages, 4 figures", "summary": "Principal component analysis (PCA) is a fundamental tool in multivariate\nstatistics, yet its sensitivity to outliers and limitations in distributed\nenvironments restrict its effectiveness in modern large-scale applications. To\naddress these challenges, we introduce the $\\phi$-PCA framework which provides\na unified formulation of robust and distributed PCA. The class of $\\phi$-PCA\nmethods retains the asymptotic efficiency of standard PCA, while aggregating\nmultiple local estimates using a proper $\\phi$ function enhances\nordering-robustness, leading to more accurate eigensubspace estimation under\ncontamination. Notably, the harmonic mean PCA (HM-PCA), corresponding to the\nchoice $\\phi(u)=u^{-1}$, achieves optimal ordering-robustness and is\nrecommended for practical use. Theoretical results further show that robustness\nincreases with the number of partitions, a phenomenon seldom explored in the\nliterature on robust or distributed PCA. Altogether, the partition-aggregation\nprinciple underlying $\\phi$-PCA offers a general strategy for developing robust\nand efficiency-preserving methodologies applicable to both robust and\ndistributed data analysis."}
{"id": "2510.13228", "categories": ["math.NA", "cs.NA", "41A25, 68W40"], "pdf": "https://arxiv.org/pdf/2510.13228", "abs": "https://arxiv.org/abs/2510.13228", "authors": ["Yan Tan", "Chenhao Ye", "Qinghai Zhang", "Shubo Zhao"], "title": "On Convergence of the Secant Method", "comment": null, "summary": "The secant method, as an important approach for solving nonlinear equations,\nis introduced in nearly all numerical analysis textbooks. However, most\ntextbooks only briefly address the Q-order of convergence of this method, with\nfew providing rigorous mathematical proofs. This paper establishes a rigorous\nproof for the Q-order of convergence of the secant method and theoretically\ncompares its computational efficiency with that of Newton's method."}
{"id": "2510.13603", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2510.13603", "abs": "https://arxiv.org/abs/2510.13603", "authors": ["S. K. Mahatha", "A. Kar", "J. Corral-Sertal", "Josu Diego", "A. Korshunov", "C. -Y. Lim", "F. K. Diekmann", "D. Subires", "J. Phillips", "T. Kim", "D. Ishikawa", "G. Marini", "I. Vobornik", "Ion Errea", "S. Rohlf", "M. Kalläne", "V. Bellini", "A. Q. R. Baron", "Adolfo O. Fumega", "A. Bosak", "V. Pardo", "K. Rossnagel", "S. Blanco-Canosa"], "title": "First-order phase transition driven by competing charge-order fluctuations in 1T'-TaTe$_{2}$", "comment": null, "summary": "First-order phase transitions, characterized by a discontinuous change in the\norder parameter, are intriguing phenomena in condensed matter physics. However,\nthe underlying, material-specific, microscopic mechanisms often remain unclear.\nHere, we unveil a high-temperature incommensurate charge-order precursor with\nthe wave vector $\\mathbf{q}^* = (0, \\frac{1}{4}+\\delta, \\frac{1}{2})$ in the\n1T' phase of TaTe$_2$, which competes with fluctuating high-temperature Ta\ntrimer bonding states at $\\mathbf{q}_\\mathrm{CO} =(0, \\frac{1}{3}, 0)$. The\nprecursor state follows the temperature dependence of the hidden\nincommensurability of the $\\textit{quasi}$-1D nested Fermi surface. In\ncontrast, the low-temperature commensurate charge order at\n$\\mathbf{q}_\\mathrm{CO}$, characterized by a charge disproportionation of the\ninequivalent Ta sites, appears to be driven by local chemical bonding.\nDynamical lattice calculations identify an imaginary optical mode at\n$\\mathbf{q}^*$, involving an in-plane vibration of the Ta atoms forming a\nchain-like structure that renormalizes below $T_\\mathrm{CO}$. Our experimental\nand theoretical observations suggest that the controversial first-order phase\ntransition, as captured by phenomenological Ginzburg-Landau theory, results\nfrom the competition between two order parameters: one involving Fermi surface\nnesting and the other involving local chemical bonding."}
{"id": "2510.13012", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "65M60, 76S05"], "pdf": "https://arxiv.org/pdf/2510.13012", "abs": "https://arxiv.org/abs/2510.13012", "authors": ["Abderrahmane Benfanich", "Yves Bourgault", "Abdelaziz Beljadid"], "title": "A finite element method using a bounded auxiliary variable for solving the Richards equation", "comment": "Preprint submitted to the Journal of Computational Physics (Elsevier)", "summary": "The Richards equation, a nonlinear elliptic parabolic equation, is widely\nused to model infiltration in porous media. We develop a finite element method\nfor solving the Richards equation by introducing a new bounded auxiliary\nvariable to eliminate unbounded terms in the weak formulation of the method.\nThis formulation is discretized using a semi-implicit scheme and the resulting\nnonlinear system is solved using Newton's method. Our approach eliminates the\nneed of regularization techniques and offers advantages in handling both dry\nand fully saturated zones. In the proposed techniques, a non-overlapping\nSchwarz domain decomposition method is used for modeling infiltration in\nlayered soils. We apply the proposed method to solve the Richards equation\nusing the Havercamp and van Genuchten models for the capillary pressure.\nNumerical experiments are performed to validate the proposed approach,\nincluding tests such as modeling flows in fibrous sheets where the initial\nmedium is totally dry, two cases with fully saturated and dry regions, and an\ninfiltration problem in layered soils. The numerical results demonstrate the\nstability and accuracy of the proposed numerical method. The numerical\nsolutions remain positive in the presence of totally dry zones. The numerical\ninvestigations clearly demonstrated the capability of the proposed method to\neffectively predict the dynamics of flows in unsaturated soils."}
{"id": "2510.13347", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.13347", "abs": "https://arxiv.org/abs/2510.13347", "authors": ["Mathias Lerbech Jeppesen", "Emilie Højbjerre-Frandsen"], "title": "postcard: An R Package for Marginal Effect Estimation with or without Prognostic Score Adjustment", "comment": "21 pages, 2 figures", "summary": "Covariate adjustment is a widely used technique in randomized clinical trials\n(RCTs) for improving the efficiency of treatment effect estimators. By\nadjusting for predictive baseline covariates, variance can be reduced,\nenhancing statistical precision and study power. Rosenblum and van der Laan\n[2010] use the framework of generalized linear models (GLMs) in a plug-in\nanalysis to show efficiency gains using covariate adjustment for marginal\neffect estimation. Recently the use of prognostic scores as adjustment\ncovariates has gained popularity. Schuler et al. [2022] introduce and validate\nthe method for continuous endpoints using linear models. Building on this work\nH{\\o}jbjerre-Frandsen et al. [2025] extends the method proposed by Schuler et\nal. [2022] to be used in combination with the GLM plug-in procedure [Rosenblum\nand van der Laan, 2010]. This method achieves semi-parametric efficiency under\nassumptions of additive treatment effects on the link scale. Additionally,\nH{\\o}jbjerre-Frandsen et al. [2025] provide a formula for power approximation\nwhich is valid even under model misspecification, enabling realistic sample\nsize estimation. This article introduces an R package, which implements the GLM\nplug-in method with or without PrOgnoSTic CovARiate aDjustment, postcard. The\npackage has two core features: (1) estimating marginal effects and the variance\nhereof (with or without prognostic adjustment) and (2) approximating\nstatistical power. Functionalities also include integration of the Discrete\nSuper Learner for constructing prognostic scores and simulation capabilities\nfor exploring the methods in practice. Through examples and simulations, we\ndemonstrate postcard as a practical toolkit for statisticians."}
{"id": "2510.13522", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "49N35, 93B51, 93B52, 90C34, 62M45, 41A05"], "pdf": "https://arxiv.org/pdf/2510.13522", "abs": "https://arxiv.org/abs/2510.13522", "authors": ["Siddhartha Ganguly", "Shubham Gupta", "Debasish Chatterjee"], "title": "Data-driven learning of feedback maps for explicit robust predictive control: an approximation theoretic view", "comment": "27 pages; submitted", "summary": "We establish an algorithm to learn feedback maps from data for a class of\nrobust model predictive control (MPC) problems. The algorithm accounts for the\napproximation errors due to the learning directly at the synthesis stage,\nensuring recursive feasibility by construction. The optimal control problem\nconsists of a linear noisy dynamical system, a quadratic stage and quadratic\nterminal costs as the objective, and convex constraints on the state, control,\nand disturbance sequences; the control minimizes and the disturbance maximizes\nthe objective. We proceed via two steps -- (a) Data generation: First, we\nreformulate the given minmax problem into a convex semi-infinite program and\nemploy recently developed tools to solve it in an exact fashion on grid points\nof the state space to generate (state, action) data. (b) Learning approximate\nfeedback maps: We employ a couple of approximation schemes that furnish tight\napproximations within preassigned uniform error bounds on the admissible state\nspace to learn the unknown feedback policy. The stability of the closed-loop\nsystem under the approximate feedback policies is also guaranteed under a\nstandard set of hypotheses. Two benchmark numerical examples are provided to\nillustrate the results."}
{"id": "2510.12946", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12946", "abs": "https://arxiv.org/abs/2510.12946", "authors": ["Daniel C. Qi", "Kenshiro Oguri", "Puneet Singla", "Maruthi R. Akella"], "title": "Non-Gaussian Distribution Steering in Nonlinear Dynamics with Conjugate Unscented Transformation", "comment": null, "summary": "In highly nonlinear systems such as the ones commonly found in astrodynamics,\nGaussian distributions generally evolve into non-Gaussian distributions. This\npaper introduces a method for effectively controlling non-Gaussian\ndistributions in nonlinear environments using optimized linear feedback\ncontrol. This paper utilizes Conjugate Unscented Transformation to quantify the\nhigher-order statistical moments of non-Gaussian distributions. The formulation\nfocuses on controlling and constraining the sigma points associated with the\nuncertainty quantification, which would thereby reflect the control of the\nentire distribution and constraints on the moments themselves. This paper\ndevelops an algorithm to solve this problem with sequential convex programming,\nand it is demonstrated through a two-body and three-body example. The examples\nshow that individual moments can be directly controlled, and the moments are\naccurately approximated for non-Gaussian distributions throughout the\ncontroller's time horizon in nonlinear dynamics."}
{"id": "2510.13448", "categories": ["physics.comp-ph", "cond-mat.dis-nn", "cond-mat.mtrl-sci", "cs.CE"], "pdf": "https://arxiv.org/pdf/2510.13448", "abs": "https://arxiv.org/abs/2510.13448", "authors": ["Nikolaj Rønne", "Tejs Vegge", "Arghya Bhowmik"], "title": "GO-Diff: Data-free and amortized global structure optimization", "comment": null, "summary": "We introduce GO-Diff, a diffusion-based method for global structure\noptimization that learns to directly sample low-energy atomic configurations\nwithout requiring prior data or explicit relaxation. GO-Diff is trained from\nscratch using a Boltzmann-weighted score-matching loss, leveraging only the\nknown energy function to guide generation toward thermodynamically favorable\nregions. The method operates in a two-stage loop of self-sampling and model\nrefinement, progressively improving its ability to target low-energy\nstructures. Compared to traditional optimization pipelines, GO-Diff achieves\ncompetitive results with significantly fewer energy evaluations. Moreover, by\nreusing pretrained models across related systems, GO-Diff supports amortized\noptimization - enabling faster convergence on new tasks without retraining from\nscratch."}
{"id": "2510.13100", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13100", "abs": "https://arxiv.org/abs/2510.13100", "authors": ["Yifu Ding", "Ruicheng Ao", "Pablo Duenas-Martinez", "Thomas Magnanti"], "title": "Decision-dependent Robust Charging Infrastructure Planning for Light-duty Truck Electrification at Industrial Sites: Scheduling and Abandonment", "comment": null, "summary": "Many industrial sites rely on diesel-powered light-duty trucks to transport\nworkers and small-scale facilities, which has resulted in a significant amount\nof greenhouse emissions (GHGs). To address this, we developed a two-stage\nrobust charging infrastructure planning model for electrifying light-duty\ntrucks at industrial sites. The model is formulated as a mixed-integer linear\nprogramming (MILP) that optimizes the charging infrastructure, selected from\nmultiple charger types and potential locations, and determines opportunity\ncharging schedules for each truck based on the chosen infrastructure. Given the\nstrict stopping points and schedules at industrial sites, we introduced a\nscheduling problem with abandonment, where trucks forgo charging if their\nwaiting times exceed a maximum threshold. We also further incorporated the\nimpacts of overnight charging and range anxiety on waiting and abandonment\nbehaviors. To represent the stochastic and heterogeneous parking durations of\ntrucks, we constructed a decision-dependent robust uncertainty set in which\nparking time variability flexibly depends on charging choices. We applied the\nmodel in a case study of an open-pit mining site, which plans charger\ninstallations in eight zones and schedules a fleet of around 200 trucks. By\ndecomposing the problem into monthly subproblems and using heuristic\napproaches, for the whole-year dataset, the model achieves an optimality gap of\nless than 0.1 % within a reasonable computation time under diverse uncertainty\nscenarios."}
{"id": "2510.13636", "categories": ["stat.ME", "cs.SI", "math.ST", "stat.TH", "62R01,"], "pdf": "https://arxiv.org/pdf/2510.13636", "abs": "https://arxiv.org/abs/2510.13636", "authors": ["Félix Almendra-Hernández", "Miles Bakenhus", "Vishesh Karwa", "Mitsunori Ogawa", "Sonja Petrović"], "title": "Non-asymptotic goodness-of-fit tests and model selection in valued stochastic blockmodels", "comment": null, "summary": "A valued stochastic blockmodel (SBM) is a general way to view networked data\nin which nodes are grouped into blocks and links between them are measured by\ncounts or labels. This family allows for varying dyad sampling schemes, thereby\nincluding the classical, Poisson, and labeled SBMs, as well as those in which\nsome edge observations are censored. This paper addresses the question of\ntesting goodness-of-fit of such non-Bernoulli SBMs, focusing in particular on\nfinite-sample tests. We derive explicit Markov bases moves necessary to\ngenerate samples from reference distributions and define goodness-of-fit\nstatistics for determining model fit, comparable to those in the literature for\nrelated model families.\n  For the labeled SBM, which includes in particular the censored-edge model, we\nstudy the asymptotic behavior of said statistics. One of the main purposes of\ntesting goodness-of-fit of an SBM is to determine whether block membership of\nthe nodes influences network formation. Power and Type 1 error rates are\nverified on simulated data. Additionally, we discuss the use of asymptotic\nresults in selecting the number of blocks under the latent-block modeling\nassumption. The method derived for Poisson SBM is applied to ecological\nnetworks of host-parasite interactions. Our data analysis conclusions differ in\nselecting the number of blocks for the species from previous results in the\nliterature."}
{"id": "2510.13386", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.13386", "abs": "https://arxiv.org/abs/2510.13386", "authors": ["Yani Feng", "Michael K. Ng", "Kejun Tang", "Zhiwen Zhang"], "title": "Functional tensor train neural network for solving high-dimensional PDEs", "comment": null, "summary": "Discrete tensor train decomposition is widely employed to mitigate the curse\nof dimensionality in solving high-dimensional PDEs through traditional methods.\nHowever, the direct application of the tensor train method typically requires\nuniform grids of regular domains, which limits its application on non-uniform\ngrids or irregular domains. To address the limitation, we develop a functional\ntensor train neural network (FTTNN) for solving high-dimensional PDEs, which\ncan represent PDE solutions on non-uniform grids or irregular domains. An\nessential ingredient of our approach is to represent the PDE solutions by the\nfunctional tensor train format whose TT-core functions are approximated by\nneural networks. To give the functional tensor train representation, we propose\nand study functional tensor train rank and employ it into a physics-informed\nloss function for training. Because of tensor train representation, the\nresulting high-dimensional integral in the loss function can be computed via\none-dimensional integrals by Gauss quadrature rules. Numerical examples\nincluding high-dimensional PDEs on regular or irregular domains are presented\nto demonstrate that the performance of the proposed FTTNN is better than that\nof Physics Informed Neural Networks (PINN)."}
{"id": "2510.13635", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2510.13635", "abs": "https://arxiv.org/abs/2510.13635", "authors": ["M. M. Piva", "T. Helm", "J. C. Souza", "K. R. Pakuszewski", "C. Adriano", "P. G. Pagliuso", "M. Nicklas"], "title": "Evidence for a field-induced Lifshitz transition in the Weyl semimetal CeAlSi", "comment": "10 pages", "summary": "The Weyl semimetal CeAlSi crystallises in the noncentrosymmetric tetragonal\nspace group $I4_1md$ and exhibits ferromagnetic order below 8 K, thereby\nbreaking both spatial inversion and time-reversal symmetries. This unique\ncombination of properties establishes CeAlSi as a model system for studying the\ninterplay between non-trivial topological states and strong electron\ncorrelations. In this work, we report observations of Shubnikov-de Haas\noscillations in the electrical resistivity under magnetic fields up to 68 T\napplied parallel to the [001] crystallographic axis. Our measurements reveal an\nabrupt change in the oscillation frequencies near 14 T, which is indicative of\na field-induced Lifshitz transition. Additionally, our results are consistent\nwith the ferromagnetic order bringing the Weyl nodes closer to the Fermi level\nin CeAlSi. Furthermore, they suggest that the RKKY interaction plays an\nimportant role."}
{"id": "2510.13377", "categories": ["stat.ME", "62P10"], "pdf": "https://arxiv.org/pdf/2510.13377", "abs": "https://arxiv.org/abs/2510.13377", "authors": ["Na Lei", "Mark A. Wolters", "Wenqing He"], "title": "A Flexible Partially Linear Single Index Proportional Hazards Regression Model for Multivariate Survival Data", "comment": "19 pages, 4 figures", "summary": "We address the problem of survival regression modelling with multivariate\nresponses and nonlinear covariate effects. Our model extends the proportional\nhazards model by introducing several weakly-parametric elements: the marginal\nbaseline hazard functions are expressed as piecewise constants, association is\nmodelled with copulas, and nonlinear covariate effects are handled by a\nsingle-index structure using a spline. The model permits a full likelihood\napproach to inference, making it possible to obtain individual-level survival\nor hazard function estimates. Performance of the new model is evaluated through\nsimulation studies and application to the Busselton health study data. The\nresults suggest that the proposed method can capture nonlinear covariate\neffects well, and that there is benefit to modeling the association between the\ncorrelated responses."}
{"id": "2510.12946", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12946", "abs": "https://arxiv.org/abs/2510.12946", "authors": ["Daniel C. Qi", "Kenshiro Oguri", "Puneet Singla", "Maruthi R. Akella"], "title": "Non-Gaussian Distribution Steering in Nonlinear Dynamics with Conjugate Unscented Transformation", "comment": null, "summary": "In highly nonlinear systems such as the ones commonly found in astrodynamics,\nGaussian distributions generally evolve into non-Gaussian distributions. This\npaper introduces a method for effectively controlling non-Gaussian\ndistributions in nonlinear environments using optimized linear feedback\ncontrol. This paper utilizes Conjugate Unscented Transformation to quantify the\nhigher-order statistical moments of non-Gaussian distributions. The formulation\nfocuses on controlling and constraining the sigma points associated with the\nuncertainty quantification, which would thereby reflect the control of the\nentire distribution and constraints on the moments themselves. This paper\ndevelops an algorithm to solve this problem with sequential convex programming,\nand it is demonstrated through a two-body and three-body example. The examples\nshow that individual moments can be directly controlled, and the moments are\naccurately approximated for non-Gaussian distributions throughout the\ncontroller's time horizon in nonlinear dynamics."}
{"id": "2510.12949", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12949", "abs": "https://arxiv.org/abs/2510.12949", "authors": ["Zhiyuan Fan", "Elizabeth Dentzer", "James Glynn", "David S. Goldberg", "Julio Friedmann", "Bolun Xu"], "title": "Enhancing Profit and CO2 Mitigation: Commercial Direct Air Capture Design and Operation with Power Market Volatility", "comment": "16 pages, 8 figure, Submitted and under review for Engineering", "summary": "Current decarbonization efforts are falling short of meeting the net-zero\ngreenhouse gas (GHG) emission target, highlighting the need for substantial\ncarbon dioxide removal methods such as direct air capture (DAC). However,\nintegrating DACs poses challenges due to their enormous power consumption. This\nstudy assesses the commercial operation of various DAC technologies that earn\nrevenue using monetized carbon incentives while purchasing electricity from\nwholesale power markets. We model four commercial DAC technologies and examine\ntheir operation in three representative locations including California, Texas,\nand New York. Our findings reveal that commercial DAC operations can take\nfinancial advantage of the volatile power market to operate only during\nlow-price periods strategically, offering a pathway to facilitate a\ncost-efficient decarbonization transition. The ambient operational environment\nsuch as temperature and relative humidity has non-trivial impact on abatement\ncapacity. Profit-driven decisions introduce climate-economic trade-offs that\nmight decrease the capacity factor of DAC and reduce total CO2 removal. These\nimplications extend throughout the entire lifecycle of DAC developments and\ninfluence power systems and policies related to full-scale DAC implementation.\nOur study shows that DAC technologies with shorter cycle spans and higher\nflexibility can better exploit the electricity price volatility, while power\nmarkets demonstrate persistent low-price windows that often synergize with low\ngrid emission periods, like during the solar \"duck curve\" in California. An\noptimal incentive design exists for profit-driven operations while carbon-tax\npolicy in electricity pricing is counterproductive for DAC systems."}
{"id": "2510.13114", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13114", "abs": "https://arxiv.org/abs/2510.13114", "authors": ["Zhuoyuan Wang", "Tongyao Jia", "Pharuj Rajborirug", "Neeraj Ramesh", "Hiroyuki Okuda", "Tatsuya Suzuki", "Soummya Kar", "Yorie Nakahira"], "title": "Safe Driving in Occluded Environments", "comment": null, "summary": "Ensuring safe autonomous driving in the presence of occlusions poses a\nsignificant challenge in its policy design. While existing model-driven control\ntechniques based on set invariance can handle visible risks, occlusions create\nlatent risks in which safety-critical states are not observable. Data-driven\ntechniques also struggle to handle latent risks because direct mappings from\nrisk-critical objects in sensor inputs to safe actions cannot be learned\nwithout visible risk-critical objects. Motivated by these challenges, in this\npaper, we propose a probabilistic safety certificate for latent risk. Our key\ntechnical enabler is the application of probabilistic invariance: It relaxes\nthe strict observability requirements imposed by set-invariance methods that\ndemand the knowledge of risk-critical states. The proposed techniques provide\nlinear action constraints that confine the latent risk probability within\ntolerance. Such constraints can be integrated into model predictive controllers\nor embedded in data-driven policies to mitigate latent risks. The proposed\nmethod is tested using the CARLA simulator and compared with a few existing\ntechniques. The theoretical and empirical analysis jointly demonstrate that the\nproposed methods assure long-term safety in real-time control in occluded\nenvironments without being overly conservative and with transparency to exposed\nrisks."}
{"id": "2510.13409", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.13409", "abs": "https://arxiv.org/abs/2510.13409", "authors": ["Chahat Ahuja", "Partha Chowdhury", "Subhashree Mohapatra"], "title": "An Enhanced Shifted QR Algorithm for Efficient Eigenvalue Computation of Square Non-Hermitian Matrices", "comment": "8 PAGES 3 FIGURES", "summary": "This work presents a novel approach to compute the eigenvalues of\nnon-Hermitian matrices using an enhanced shifted QR algorithm. The existing QR\nalgorithms fail to converge early in the case of non-hermitian matrices, and\nour approach shows significant improvement in convergence rate while\nmaintaining accuracy for all test cases. In this work, though our prior focus\nwill be to address the results for a class mid- large sized non-Hermitian\nmatrices, our algorithm has also produced significant improvements in the case\nof comparatively larger matrices such as 50 x 50 non-Hermitian matrices"}
{"id": "2510.13667", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.13667", "abs": "https://arxiv.org/abs/2510.13667", "authors": ["Jiawei Yan", "Jonas B. Profe", "Yuta Murakami", "Philipp Werner"], "title": "Excitonic correlations in the equilibrium and voltage-biased bilayer Hubbard model: multi-orbital two-particle self-consistent approach", "comment": "14 pages, 5 figures", "summary": "We develop a nonequilibrium multi-orbital extension of the two-particle\nself-consistent theory and apply it to the bilayer Hubbard model as a minimal\nplatform to investigate correlation effects in the presence of interlayer\ninteractions and tunneling. The method determines vertex corrections in the\nspin and charge channels self-consistently at the two-particle level, thereby\navoiding the spurious finite-temperature phase transitions that limit dynamical\nmean-field theory in two dimensions. We derive the spectral self-energy and\nimplement the framework directly on the real-frequency axis within the Keldysh\nnonequilibrium Green's function formalism, enabling the treatment of both\nequilibrium and non-equilibrium steady states without relying on numerical\nanalytic continuation. As an application, we demonstrate that a pseudogap can\nemerge in the bilayer Hubbard model when spin, charge, or excitonic\nfluctuations become sufficiently strong. Instabilities in different channels\nare also evaluated in an unbiased manner across the parameter space.\nRemarkably, we find that the excitonic susceptibility grows with increasing\ninterlayer bias, before it gets suppressed at large biases by the charge\nimbalance between the layers. This work establishes a versatile and\ncomputationally efficient framework for investigating correlated multi-orbital\nsystems under nonequilibrium conditions."}
{"id": "2510.13389", "categories": ["stat.ME", "stat.OT"], "pdf": "https://arxiv.org/pdf/2510.13389", "abs": "https://arxiv.org/abs/2510.13389", "authors": ["Tien-En Chang", "Argon Chen"], "title": "Understanding and Using the Relative Importance Measures Based on Orthonormality Transformation", "comment": "20 pages, 10 figures", "summary": "A class of relative importance measures based on orthonormality\ntransformation (OTMs), has been found to effectively approximate the General\nDominance index (GD). In particular, Johnson's Relative Weight (RW) has been\ndeemed the most successful OTM in the literature. Nevertheless, the theoretical\nfoundation of the OTMs remains unclear. To further understand the OTMs, we\nprovide a generalized framework that breaks down the OTM into two functional\nsteps: orthogonalization and reallocation. To assess the impact of each step on\nthe performance of OTMs, we conduct extensive Monte Carlo simulations under\nvarious predictors' correlation structures and response variable distributions.\nOur findings reveal that Johnson's minimal transformation consistently\noutperforms other common orthogonalization methods. We also summarize the\nperformance of reallocation methods under four scenarios of predictors'\ncorrelation structures in terms of the first principal component and the\nvariance inflation factor (VIF). This analysis provides guidelines for\nselecting appropriate reallocation methods in different scenarios, illustrated\nwith real-world dataset examples. Our research offers a deeper understanding of\nOTMs and provides valuable insights for practitioners seeking to accurately\nmeasure variable importance in various modeling contexts."}
{"id": "2510.12961", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12961", "abs": "https://arxiv.org/abs/2510.12961", "authors": ["The Minh Nguyen", "Nagisa Sugishita", "Margarida Carvalho", "Amira Dems"], "title": "Competitive EV charging station location with queues", "comment": null, "summary": "Electric vehicle (EV) public charging infrastructure planning faces\nsignificant challenges in competitive markets, where multiple service providers\naffect congestion and user behavior. This work extends existing modeling\nframeworks by incorporating the presence of competitors' stations and more\nrealistic queueing systems.\n  First, we analyze three finite queueing systems, M/M/1/K, M/M/s/K, and\nM/Er/s/K, with varying numbers of servers (charging outlets) and service time\ndistributions, deriving analytic expressions for user behavior metrics. Second,\nwe embed the queueing-based user behavior model into a bilevel program, where\nthe upper level locates new charging stations to maximize accessibility\n(throughput), and the lower level captures users' station choices via a user\nequilibrium. Third, we apply a reformulation from competitive congested\nuser-choice facility location models to approximately solve the bilevel problem\nand introduce a surrogate-based heuristic to enhance scalability. Fourth, we\nshowcase our methodology on a real-world case study of an urban area in\nMontreal (Canada), offering managerial insights into how user-choice behavior\nassumptions and competition affect throughput and location decisions. The\nresults demonstrate that our model yields (re)location strategies that\noutperform the existing network. More broadly, this approach provides a tool\nfor incorporating charging service quality-through queueing metrics-and\nexisting competition into station planning."}
{"id": "2510.12955", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12955", "abs": "https://arxiv.org/abs/2510.12955", "authors": ["Levi D. Reyes Premer", "Elias N. Pergantis", "Leo Semmelmann", "Davide Ziviani", "Kevin J. Kircher"], "title": "Model predictive control lowers barriers to adoption of heat-pump water heaters: A field study", "comment": null, "summary": "Electric heat-pump water heaters (HPWHs) could reduce the energy costs,\nemissions, and power grid impacts associated with water heating, the\nsecond-largest energy use in United States housing. However, most HPWHs today\nrequire 240 V circuits to power the backup resistance heating elements they use\nto maintain comfort during large water draws. Installing a 240 V circuit can\nincrease the up-front cost of a HPWH by half or more. This paper develops and\nfield-tests the first control system that enables a 120 V HPWH to efficiently\nmaintain comfort without resistance heating elements. The novel model\npredictive control (MPC) system enables pre-heating in anticipation of large\nwater draws, which it forecasts using an ensemble of machine learning\npredictors. By shifting electrical load over time, MPC also reduces energy\ncosts on average by 23% and 28% under time-of-use pricing and hourly pricing,\nrespectively, relative to a 240 V HPWH with standard controls. Compared to the\nincreasingly common practice in 120 V HPWHs of storing water at a constant,\nhigh temperature (60 {\\deg}C) to ensure comfort, MPC saves 37% energy on\naverage. In addition to demonstrating MPC's benefits in a real, occupied house,\nthis paper discusses implementation challenges and costs. A simple payback\nanalysis suggests that a 120 V HPWH, operated by the MPC system developed here,\nwould be economically attractive in most installation scenarios."}
{"id": "2510.13279", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13279", "abs": "https://arxiv.org/abs/2510.13279", "authors": ["Fuma Omori", "Atsushi Yano", "Takuya Azumi"], "title": "Partitioned Scheduling for DAG Tasks Considering Probabilistic Execution Time", "comment": null, "summary": "Autonomous driving systems, critical for safety, require real-time guarantees\nand can be modeled as DAGs. Their acceleration features, such as caches and\npipelining, often result in execution times below the worst-case. Thus, a\nprobabilistic approach ensuring constraint satisfaction within a probability\nthreshold is more suitable than worst-case guarantees for these systems. This\npaper considers probabilistic guarantees for DAG tasks by utilizing the results\nof probabilistic guarantees for single processors, which have been relatively\nmore advanced than those for multi-core processors. This paper proposes a task\nset partitioning method that guarantees schedulability under the partitioned\nscheduling. The evaluation on randomly generated DAG task sets demonstrates\nthat the proposed method schedules more task sets with a smaller mean analysis\ntime compared to existing probabilistic schedulability analysis for DAGs. The\nevaluation also compares four bin-packing heuristics, revealing Item-Centric\nWorst-Fit-Decreasing schedules the most task sets."}
{"id": "2510.13412", "categories": ["math.NA", "cs.LO", "cs.NA", "F.3.1; F.2.2; G.1.3"], "pdf": "https://arxiv.org/pdf/2510.13412", "abs": "https://arxiv.org/abs/2510.13412", "authors": ["Andrew W. Appel"], "title": "Formal Verification of COO to CSR Sparse Matrix Conversion (Invited Paper)", "comment": "In Proceedings VSS 2025, arXiv:2510.12314. This paper accompanies my\n  keynote lecture \"Foundational end-to-end verification of numerical programs\"\n  at VSS 2025, the International Workshop on Verification of Scientific\n  Software; and covers one of the results described in that talk", "summary": "We describe a machine-checked correctness proof of a C program that converts\na coordinate-form (COO) sparse matrix to a compressed-sparse-row (CSR) matrix.\nThe classic algorithm (sort the COO entries in lexicographic order by\nrow,column; fill in the CSR arrays left to right) is concise but has rather\nintricate invariants. We illustrate a bottom-up methodology for deriving the\ninvariants from the program."}
{"id": "2510.13767", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.13767", "abs": "https://arxiv.org/abs/2510.13767", "authors": ["Connor A Occhialini", "Christie Nelson", "Alessandro Bombardi", "Shiyu Fan", "Raul Acevedo-Esteves", "Riccardo Comin", "Dmitri N Basov", "Maki Musashi", "Masashi Kawasaki", "Masaki Uchida", "Hoydoo You", "John Mitchell", "Valentina Bisogni", "Claudio Mazzoli", "Jonathan Pelliciari"], "title": "Structural origin of resonant diffraction in RuO$_2$", "comment": null, "summary": "We report Ru L$_3$-edge resonant X-ray diffraction studies on single crystal\nand (001) epitaxial films of RuO$_2$. We investigate the distinct $\\mathbf{Q} =\n(100)$ and $(001)$ reflections as a function of incident energy, azimuthal\nangle, and temperature. The results show that the observed resonant diffraction\nin RuO$_2$ is fully consistent with a resonant charge anisotropy signal of\nstructural origin permitted by the parent (non-magnetic) rutile $P4_2/mnm$\nspace group. These results significantly constrain the magnetic contribution to\nthe resonant diffraction signal and indicate the unlikely existence of\n$\\mathbf{k} = 0$ antiferromagnetic order in RuO$_2$."}
{"id": "2510.13636", "categories": ["stat.ME", "cs.SI", "math.ST", "stat.TH", "62R01,"], "pdf": "https://arxiv.org/pdf/2510.13636", "abs": "https://arxiv.org/abs/2510.13636", "authors": ["Félix Almendra-Hernández", "Miles Bakenhus", "Vishesh Karwa", "Mitsunori Ogawa", "Sonja Petrović"], "title": "Non-asymptotic goodness-of-fit tests and model selection in valued stochastic blockmodels", "comment": null, "summary": "A valued stochastic blockmodel (SBM) is a general way to view networked data\nin which nodes are grouped into blocks and links between them are measured by\ncounts or labels. This family allows for varying dyad sampling schemes, thereby\nincluding the classical, Poisson, and labeled SBMs, as well as those in which\nsome edge observations are censored. This paper addresses the question of\ntesting goodness-of-fit of such non-Bernoulli SBMs, focusing in particular on\nfinite-sample tests. We derive explicit Markov bases moves necessary to\ngenerate samples from reference distributions and define goodness-of-fit\nstatistics for determining model fit, comparable to those in the literature for\nrelated model families.\n  For the labeled SBM, which includes in particular the censored-edge model, we\nstudy the asymptotic behavior of said statistics. One of the main purposes of\ntesting goodness-of-fit of an SBM is to determine whether block membership of\nthe nodes influences network formation. Power and Type 1 error rates are\nverified on simulated data. Additionally, we discuss the use of asymptotic\nresults in selecting the number of blocks under the latent-block modeling\nassumption. The method derived for Poisson SBM is applied to ecological\nnetworks of host-parasite interactions. Our data analysis conclusions differ in\nselecting the number of blocks for the species from previous results in the\nliterature."}
{"id": "2510.12961", "categories": ["eess.SY", "cs.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.12961", "abs": "https://arxiv.org/abs/2510.12961", "authors": ["The Minh Nguyen", "Nagisa Sugishita", "Margarida Carvalho", "Amira Dems"], "title": "Competitive EV charging station location with queues", "comment": null, "summary": "Electric vehicle (EV) public charging infrastructure planning faces\nsignificant challenges in competitive markets, where multiple service providers\naffect congestion and user behavior. This work extends existing modeling\nframeworks by incorporating the presence of competitors' stations and more\nrealistic queueing systems.\n  First, we analyze three finite queueing systems, M/M/1/K, M/M/s/K, and\nM/Er/s/K, with varying numbers of servers (charging outlets) and service time\ndistributions, deriving analytic expressions for user behavior metrics. Second,\nwe embed the queueing-based user behavior model into a bilevel program, where\nthe upper level locates new charging stations to maximize accessibility\n(throughput), and the lower level captures users' station choices via a user\nequilibrium. Third, we apply a reformulation from competitive congested\nuser-choice facility location models to approximately solve the bilevel problem\nand introduce a surrogate-based heuristic to enhance scalability. Fourth, we\nshowcase our methodology on a real-world case study of an urban area in\nMontreal (Canada), offering managerial insights into how user-choice behavior\nassumptions and competition affect throughput and location decisions. The\nresults demonstrate that our model yields (re)location strategies that\noutperform the existing network. More broadly, this approach provides a tool\nfor incorporating charging service quality-through queueing metrics-and\nexisting competition into station planning."}
{"id": "2510.13396", "categories": ["eess.SY", "cs.SY", "93-10"], "pdf": "https://arxiv.org/pdf/2510.13396", "abs": "https://arxiv.org/abs/2510.13396", "authors": ["Luka Baković", "David Ohlin", "Emma Tegling"], "title": "Multipolar dynamics of social segregation: Data validation on Swedish vaccination statistics", "comment": "Presented at CoDIT 2025", "summary": "We perform a validation analysis on the multipolar model of opinion dynamics.\nA general methodology for using the model on datasets of two correlated\nvariables is proposed and tested using data on the relationship between\nCOVID-19 vaccination rates and political participation in Sweden. The model is\nshown to successfully capture the opinion segregation demonstrated by the data\nand spatial correlation of biases is demonstrated as necessary for the result.\nA mixing of the biases on the other hand leads to a more homogeneous opinion\ndistribution, and greater penetration of the majority opinion, which here\ncorresponds to a decision to vote or vaccinate."}
{"id": "2510.13414", "categories": ["math.NA", "cs.NA", "D.2.4; G.1.0"], "pdf": "https://arxiv.org/pdf/2510.13414", "abs": "https://arxiv.org/abs/2510.13414", "authors": ["Max Fan", "Ariel E. Kellison", "Samuel D. Pollard"], "title": "Mechanizing Olver's Error Arithmetic", "comment": "In Proceedings VSS 2025, arXiv:2510.12314", "summary": "We mechanize the fundamental properties of a rounding error model for\nfloating-point arithmetic based on relative precision, a measure of error\nproposed as a substitute for relative error in rounding error analysis. A key\nproperty of relative precision is that it forms a true metric, providing a\nwell-defined measure of distance between exact results and their floating-point\napproximations while offering a structured approach to propagating error bounds\nthrough sequences of computations. Our mechanization formalizes this property,\nestablishes rules for converting between relative precision and relative error,\nand shows that the rounding error model based on relative precision slightly\noverapproximates the standard rounding error model. Finally, we demonstrate,\nwith a simple example of the inner product of two vectors, that this\nalternative model facilitates a tractable approach to developing certified\nrounding error bounds."}
{"id": "2510.13715", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.13715", "abs": "https://arxiv.org/abs/2510.13715", "authors": ["Younghoon Kim", "Po-Ling Loh", "Sumanta Basu"], "title": "Exact Coordinate Descent for High-Dimensional Regularized Huber Regression", "comment": null, "summary": "We develop an exact coordinate descent algorithm for high-dimensional\nregularized Huber regression. In contrast to composite gradient descent\nmethods, our algorithm fully exploits the advantages of coordinate descent when\nthe underlying model is sparse. Moreover, unlike existing second-order\napproximation methods previously introduced in the literature, it remains\neffective even when the Hessian becomes ill-conditioned due to high\ncorrelations among covariates drawn from heavy-tailed distributions. The key\nidea is that, for each coordinate, marginal increments arise only from inlier\nobservations, while the derivatives remain monotonically increasing over a grid\nconstructed from the partial residuals. Building on conventional coordinate\ndescent strategies, we further propose variable screening rules that\nselectively determine which variables to update at each iteration, thereby\naccelerating convergence. To the best of our knowledge, this is the first work\nto develop a first-order coordinate descent algorithm for penalized Huber loss\nminimization. We bound the nonasymptotic convergence rate of the proposed\nalgorithm by extending arguments developed for the Lasso and formally\ncharacterize the operation of the proposed screening rule. Extensive simulation\nstudies under heavy-tailed and highly-correlated predictors, together with a\nreal data application, demonstrate both the practical efficiency of the method\nand the benefits of the computational enhancements."}
{"id": "2510.13000", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13000", "abs": "https://arxiv.org/abs/2510.13000", "authors": ["Giacomo Bastianel", "Dirk Van Hertem", "Hakan Ergun", "Line Roald"], "title": "Identifying Best Candidates for Busbar Splitting", "comment": null, "summary": "Rising electricity demand and the growing integration of renewables are\nintensifying congestion in transmission grids. Grid topology optimization\nthrough busbar splitting (BuS) and optimal transmission switching can alleviate\ngrid congestion and reduce the generation costs in a power system. However, BuS\noptimization requires a large number of binary variables, and analyzing all the\nsubstations for potential new topological actions is computationally\nintractable, particularly in large grids. To tackle this issue, we propose a\nset of metrics to identify and rank promising candidates for BuS, focusing on\nfinding buses where topology optimization can reduce generation costs. To\nassess the effect of BuS on the identified buses, we use a combined\nmixed-integer convex-quadratic BuS model to compute the optimal topology and\ntest it with the non-linear non-convex AC optimal power flow (OPF) simulation\nto show its AC feasibility. By testing and validating the proposed metrics on\ntest cases of different sizes, we show that they are able to identify busbars\nthat reduce the total generation costs when their topology is optimized. Thus,\nthe metrics enable effective selection of busbars for BuS, with no need to test\nevery busbar in the grid, one at a time."}
{"id": "2510.13449", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13449", "abs": "https://arxiv.org/abs/2510.13449", "authors": ["Jan Brändle", "Julie Rousseau", "Pulkit Nahata", "Gabriela Hug"], "title": "On the Flexibility Potential of a Swiss Distribution Grid: Opportunities and Limitations", "comment": null, "summary": "The growing integration of distributed renewable generation and the\nelectrification of heating and transportation are rapidly increasing the number\nof flexible devices within modern distribution grids. Leveraging the aggregated\nflexibility of these small-scale distributed resources is essential to\nmaintaining future grid-wide stability. This work uses the Swiss distribution\ngrid of Walenstadt as a case study to provide insights into the aggregated\nflexibility potential of distribution grids. It demonstrates that incorporating\ndevices such as heat pumps and photovoltaic systems significantly enhances\ndistribution grid flexibility. It investigates the time-varying nature of\naggregated flexibility and highlights how it can vary seasonally. Furthermore,\nsimulations of future scenarios reveal that aggregated flexibility does not\nincrease linearly or monotonically with higher levels of flexible device\npenetration. This is primarily due to the overloading of individual feeders,\nwhich underscores the impact of grid topology and network constraints on the\naggregated flexibility potential."}
{"id": "2510.13429", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.13429", "abs": "https://arxiv.org/abs/2510.13429", "authors": ["Zhangchengrui Wang", "Lei Zhang", "Shuyu Sun", "Jijing Zhao"], "title": "A domain decomposition approach to pore-network modeling of porous media flow", "comment": null, "summary": "We propose a domain-decomposition pore-network method (DD-PNM) for modeling\nsingle-phase Stokes flow in porous media. The method combines the accuracy of\nfinite-element discretizations on body-fitted meshes within pore subdomains\nwith a sparse global coupling enforced through interface unknowns. Local\nDirichlet-to-Neumann operators are precomputed from finite-element solutions\nfor each pore subdomain, enabling a global Schur-complement system defined\nsolely on internal interfaces. Rigorous mathematical analysis establishes\nsolvability and discrete mass conservation of the global system. Moreover, we\nconstructively recover classical pore-network models by fitting half-throat\nconductivities to local Dirichlet-to-Neumann maps, providing a principled\nbridge between mesh-based and network-based frameworks. Numerical results are\npresented to demonstrate the validity and effectiveness of the overall\nmethodology."}
{"id": "2510.13004", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13004", "abs": "https://arxiv.org/abs/2510.13004", "authors": ["Robert Muldrow", "Channing Ludden", "Christopher Petersen"], "title": "Comparison of Forced and Unforced Rendezvous, Proximity Operations, and Docking Under Model Mismatch", "comment": "12 pages, 4 figures, AAS/AIAA Space Flight Mechanics", "summary": "This paper compares the required fuel usage for forced and unforced motion of\na chaser satellite engaged in Rendezvous, Proximity Operations, and Docking\n(RPOD) maneuvers. Improved RPOD models are vital, particularly as the space\nindustry expands and demands for improved fuel efficiency, cost effectiveness,\nand mission life span increase. This paper specifically examines the Clohessy-\nWiltshire (CW) Equations and the extent of model mismatch by comparing pre-\ndicted trajectories from this model with a more computationally complex, higher\nfidelity RPOD model. This paper assesses several test cases of similar mission\nparameters, in each case comparing natural motion circumnavigation (NMC) with\ncomparable forced motion circumnavigation. The Guidance, Navigation, and Con-\ntrol (GNC) impulse maneuvers required to maintain the supposedly zero fuel CW\ntrajectories is representative of the extent of CW model mismatch. This paper\ndemonstrates that unforced motions are not inherently more fuel efficient than\nforced motions, thus permitting extended orbital operations given the higher\nfuel efficiency."}
{"id": "2510.13461", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13461", "abs": "https://arxiv.org/abs/2510.13461", "authors": ["Yangye Jiang", "Jiachen Wang", "Daofei Li"], "title": "Physics-Informed Neural Network Modeling of Vehicle Collision Dynamics in Precision Immobilization Technique Maneuvers", "comment": null, "summary": "Accurate prediction of vehicle collision dynamics is crucial for advanced\nsafety systems and post-impact control applications, yet existing methods face\ninherent trade-offs among computational efficiency, prediction accuracy, and\ndata requirements. This paper proposes a dual Physics-Informed Neural Network\nframework addressing these challenges through two complementary networks. The\nfirst network integrates Gaussian Mixture Models with PINN architecture to\nlearn impact force distributions from finite element analysis data while\nenforcing momentum conservation and energy consistency constraints. The second\nnetwork employs an adaptive PINN with dynamic constraint weighting to predict\npost-collision vehicle dynamics, featuring an adaptive physics guard layer that\nprevents unrealistic predictions whil e preserving data-driven learning\ncapabilities. The framework incorporates uncertainty quantification through\ntime-varying parameters and enables rapid adaptation via fine-tuning\nstrategies. Validation demonstrates significant improvements: the impact force\nmodel achieves relative errors below 15.0% for force prediction on finite\nelement analysis (FEA) datasets, while the vehicle dynamics model reduces\naverage trajectory prediction error by 63.6% compared to traditional\nfour-degree-of-freedom models in scaled vehicle experiments. The integrated\nsystem maintains millisecond-level computational efficiency suitable for\nreal-time applications while providing probabilistic confidence bounds\nessential for safety-critical control. Comprehensive validation through FEA\nsimulation, dynamic modeling, and scaled vehicle experiments confirms the\nframework's effectiveness for Precision Immobilization Technique scenarios and\ngeneral collision dynamics prediction."}
{"id": "2510.13496", "categories": ["math.NA", "cs.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.13496", "abs": "https://arxiv.org/abs/2510.13496", "authors": ["Jürgen Dölz", "Michael Multerer"], "title": "Data-intrinsic approximation in metric spaces", "comment": null, "summary": "Analysis and processing of data is a vital part of our modern society and\nrequires vast amounts of computational resources. To reduce the computational\nburden, compressing and approximating data has become a central topic. We\nconsider the approximation of labeled data samples, mathematically described as\nsite-to-value maps between finite metric spaces. Within this setting, we\nidentify the discrete modulus of continuity as an effective data-intrinsic\nquantity to measure regularity of site-to-value maps without imposing further\nstructural assumptions. We investigate the consistency of the discrete modulus\nof continuity in the infinite data limit and propose an algorithm for its\nefficient computation. Building on these results, we present a sample based\napproximation theory for labeled data. For data subject to statistical\nuncertainty we consider multilevel approximation spaces and a variant of the\nmultilevel Monte Carlo method to compute statistical quantities of interest.\nOur considerations connect approximation theory for labeled data in metric\nspaces to the covering problem for (random) balls on the one hand and the\nefficient evaluation of the discrete modulus of continuity to combinatorial\noptimization on the other hand. We provide extensive numerical studies to\nillustrate the feasibility of the approach and to validate our theoretical\nresults."}
{"id": "2510.13024", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13024", "abs": "https://arxiv.org/abs/2510.13024", "authors": ["Shahab Ataei", "Dipankar Maity", "Debdipta Goswami"], "title": "Data to Certificate: Guaranteed Cost Control with Quantization-Aware System Identification", "comment": "8 pages, 3 figures", "summary": "Cloud-assisted system identification and control have emerged as practical\nsolutions for low-power, resource-constrained control systems such as\nmicro-UAVs. In a typical cloud-assisted setting, state and input data are\ntransmitted from local agents to a central computer over low-bandwidth wireless\nlinks, leading to quantization. This paper investigates the impact of state and\ninput data quantization on a linear time invariant (LTI) system identification,\nderives a worst-case bound on the identification error, and develops a robust\ncontroller for guaranteed cost control. We establish a fundamental bound on the\nmodel error that depends only on the quantized data and quantization\nresolution, and develop a linear matrix inequality (LMI) based guaranteed cost\nrobust controller under this error bound."}
{"id": "2510.13514", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13514", "abs": "https://arxiv.org/abs/2510.13514", "authors": ["Andreas C. Makrides", "Adam Suski", "Elina Spyrou"], "title": "Quantifying the Impact of Missing Risk Markets for Decarbonized Power Systems with Long Duration Energy Storage", "comment": null, "summary": "The transition to a fully decarbonised electricity system depends on\nintegrating new technologies that ensure reliability alongside sustainability.\nHowever, missing risk markets hinder investment in reliability-enhancing\ntechnologies by exposing investors to revenue uncertainty. This study provides\nthe first quantitative assessment of how missing risk markets affect investment\ndecisions in power systems that depend on long-duration energy storage (LDES)\nfor reliability. We develop a two-stage stochastic equilibrium model with\nrisk-averse market participants, which independently sizes power and energy\ncapacity. We apply the method to a case study of a deeply decarbonised power\nsystem in Great Britain. The results show that incomplete risk markets reduce\nsocial welfare, harm reliability, and discourage investment in LDES and other\ntechnologies with volatile revenue streams. Revenue volatility leads to\nsubstantial risk premiums and higher financing costs for LDES, creating a\nbarrier to its large-scale deployment. These findings demonstrate the\nimportance of policy mechanisms that hedge revenue risk to lower the cost of\ncapital and accelerate investment in reliability-enhancing, zero-carbon\ntechnologies"}
{"id": "2510.13510", "categories": ["math.NA", "cs.NA", "65M12, 65M22, 65M60"], "pdf": "https://arxiv.org/pdf/2510.13510", "abs": "https://arxiv.org/abs/2510.13510", "authors": ["Yannis Voet", "Espen Sande"], "title": "On the prospects of interpolatory spline bases for accurate mass lumping strategies in isogeometric analysis", "comment": "32 pages, 29 figures", "summary": "While interpolatory bases such as the Lagrange basis form the cornerstone of\nclassical finite element methods, they have been replaced in the more general\nfinite element setting of isogeometric analysis in favor of other desirable\nproperties. Yet, interpolation is a key property for devising accurate mass\nlumping strategies that are ubiquitous in explicit dynamic analyses of\nstructures. In this article, we explore the possibility of restoring\ninterpolation for spline bases within isogeometric analysis for the purpose of\nmass lumping. Although reminiscent of the spectral element method, this\ntechnique comes with its lot of surprises and challenges, which are critically\nassessed."}
{"id": "2510.13100", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13100", "abs": "https://arxiv.org/abs/2510.13100", "authors": ["Yifu Ding", "Ruicheng Ao", "Pablo Duenas-Martinez", "Thomas Magnanti"], "title": "Decision-dependent Robust Charging Infrastructure Planning for Light-duty Truck Electrification at Industrial Sites: Scheduling and Abandonment", "comment": null, "summary": "Many industrial sites rely on diesel-powered light-duty trucks to transport\nworkers and small-scale facilities, which has resulted in a significant amount\nof greenhouse emissions (GHGs). To address this, we developed a two-stage\nrobust charging infrastructure planning model for electrifying light-duty\ntrucks at industrial sites. The model is formulated as a mixed-integer linear\nprogramming (MILP) that optimizes the charging infrastructure, selected from\nmultiple charger types and potential locations, and determines opportunity\ncharging schedules for each truck based on the chosen infrastructure. Given the\nstrict stopping points and schedules at industrial sites, we introduced a\nscheduling problem with abandonment, where trucks forgo charging if their\nwaiting times exceed a maximum threshold. We also further incorporated the\nimpacts of overnight charging and range anxiety on waiting and abandonment\nbehaviors. To represent the stochastic and heterogeneous parking durations of\ntrucks, we constructed a decision-dependent robust uncertainty set in which\nparking time variability flexibly depends on charging choices. We applied the\nmodel in a case study of an open-pit mining site, which plans charger\ninstallations in eight zones and schedules a fleet of around 200 trucks. By\ndecomposing the problem into monthly subproblems and using heuristic\napproaches, for the whole-year dataset, the model achieves an optimality gap of\nless than 0.1 % within a reasonable computation time under diverse uncertainty\nscenarios."}
{"id": "2510.13563", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13563", "abs": "https://arxiv.org/abs/2510.13563", "authors": ["Ayten Gürbüz", "Giuseppe Caire"], "title": "Channel Estimation under Large Doppler Shifts in NOMA-Based Air-Ground Communications", "comment": "Submitted to IEEE Conference, 6 pages, 2 Figures", "summary": "This paper investigates a multiple antenna system with non-orthogonal\nmultiple access (NOMA) for the exchange of air traffic management data between\ncommercial aircraft pilots and ground-based air traffic controllers. While NOMA\ntechniques enhance spectral efficiency, their application to aircraft\ncommunications is challenged by the high speed of the aircraft (up to 214 m/s)\nand the long communication ranges (up to 250 km), resulting in significant\nDoppler shifts and low signal-to-noise ratios, respectively. To accurately\nassess these challenges, we employ a realistic geometry-based stochastic\nair-ground channel model, derived from dedicated flight measurement campaigns.\nIn this paper, multiple aircraft simultaneously transmit data to the ground\nstation. We focus on the channel estimation problem at the ground station under\nhigh carrier frequency offsets and the effects of channel aging due to\nchannel's time-varying nature. For the channel estimation problem, we compare\nthe Zadoff-Chu sequences with time-division approach under varying carrier\nfrequency offset pre-compensation accuracies at the aircraft transmitter. For\nthe channel aging problem and performance evaluation of channel estimators, we\ncompute the outage probability for both the zero-forcing detector and the\nminimum mean squared error detector with successive interference cancellation.\nThe results show that the favorable channel estimator-detector combinations\ndiffer between the takeoff & landing phase and the enroute cruise phase of the\nflight, due to the distinct channel propagation characteristics of each phase."}
{"id": "2510.13516", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.13516", "abs": "https://arxiv.org/abs/2510.13516", "authors": ["Zixu Feng", "Qinglin Tang"], "title": "On preconditioned Riemannian gradient methods for minimizing the Gross-Pitaevskii energy functional: algorithms, global convergence and optimal local convergence rate", "comment": null, "summary": "In this article, we propose a unified framework for preconditioned Riemannian\ngradient (P-RG) methods to minimize Gross-Pitaevskii (GP) energy functionals\nwith rotation on a Riemannian manifold. This framework enables comprehensive\nanalysis of existing projected Sobolev gradient methods and facilitates the\nconstruction of highly efficient P-RG algorithms. Under mild assumptions on the\npreconditioner, we prove energy dissipation and global convergence. Local\nconvergence is more challenging due to phase and rotational invariances.\nAssuming the GP functional is Morse-Bott, we derive a sharp Polyak-\\L\nojasiewicz (PL) inequality near minimizers. This allows precise\ncharacterization of the local convergence rate via the condition number\n$\\mu/L$, where $\\mu$ and $L$ are the lower and upper bounds of the spectrum of\na combined operator (preconditioner and Hessian) on a closed subspace. By\ncombining spectral analysis with the PL inequality, we identify an optimal\npreconditioner achieving the best possible local convergence rate:\n$(L-\\mu)/(L+\\mu)+\\varepsilon$ ($\\varepsilon>0$ small). To our knowledge, this\nis the first rigorous derivation of the local convergence rate for P-RG methods\napplied to GP functionals with two symmetry structures. Numerical experiments\non rapidly rotating Bose-Einstein condensates validate the theoretical results\nand compare the performance of different preconditioners."}
{"id": "2510.13114", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13114", "abs": "https://arxiv.org/abs/2510.13114", "authors": ["Zhuoyuan Wang", "Tongyao Jia", "Pharuj Rajborirug", "Neeraj Ramesh", "Hiroyuki Okuda", "Tatsuya Suzuki", "Soummya Kar", "Yorie Nakahira"], "title": "Safe Driving in Occluded Environments", "comment": null, "summary": "Ensuring safe autonomous driving in the presence of occlusions poses a\nsignificant challenge in its policy design. While existing model-driven control\ntechniques based on set invariance can handle visible risks, occlusions create\nlatent risks in which safety-critical states are not observable. Data-driven\ntechniques also struggle to handle latent risks because direct mappings from\nrisk-critical objects in sensor inputs to safe actions cannot be learned\nwithout visible risk-critical objects. Motivated by these challenges, in this\npaper, we propose a probabilistic safety certificate for latent risk. Our key\ntechnical enabler is the application of probabilistic invariance: It relaxes\nthe strict observability requirements imposed by set-invariance methods that\ndemand the knowledge of risk-critical states. The proposed techniques provide\nlinear action constraints that confine the latent risk probability within\ntolerance. Such constraints can be integrated into model predictive controllers\nor embedded in data-driven policies to mitigate latent risks. The proposed\nmethod is tested using the CARLA simulator and compared with a few existing\ntechniques. The theoretical and empirical analysis jointly demonstrate that the\nproposed methods assure long-term safety in real-time control in occluded\nenvironments without being overly conservative and with transparency to exposed\nrisks."}
{"id": "2510.13682", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13682", "abs": "https://arxiv.org/abs/2510.13682", "authors": ["Jiayang Li", "Qingyu Zhang", "Sohmyung Ha", "Dai Jiang", "Andreas Demosthenous", "Yu Wu"], "title": "A 0.62 μW/sensor 82 fps Time-to-Digital Impedance Measurement IC with Unified Excitation/Readout Front-end for Large-Scale Piezo-Resistive Sensor Array", "comment": null, "summary": "This paper presents a fast impedance measurement IC for large-scale\npiezo-resistive sensor array. It features a unified differential\ntime-to-digital demodulation architecture that readout impedance directly\nthrough the excitation circuit. The proposed pre-saturation adaptive bias\ntechnique further improves power efficiency. The chip scans 253 sensors in 12.2\nms (82 fps) at 125 kHz, consuming 158 {\\mu}W (7.5 nJ/sensor). With loads from\n20 {\\Omega} to 500 k{\\Omega}, it achieves 0.5% error and up to 71.1 dB SNR."}
{"id": "2510.13639", "categories": ["math.NA", "cs.NA", "65R20, 65D30, 31B10, 76D07"], "pdf": "https://arxiv.org/pdf/2510.13639", "abs": "https://arxiv.org/abs/2510.13639", "authors": ["J. Thomas Beale", "Svetlana Tlupova"], "title": "High order regularization of nearly singular surface integrals", "comment": null, "summary": "Solutions of partial differential equations can often be written as surface\nintegrals having a kernel related to a singular fundamental solution. Special\nmethods are needed to evaluate the integral accurately at points on or near the\nsurface. Here we derive formulas to regularize the integrals with high\naccuracy, using analysis from Beale and Tlupova (Adv. Comput. Math., 2024), so\nthat a standard quadrature can be used without special care near the\nsingularity. We treat single or double layer integrals for harmonic functions\nor for Stokes flow. The nearly singular case, evaluation at points close to the\nsurface, can be needed when surfaces are close to each other, or to find values\nat grid points near a surface. We derive formulas for regularized kernels with\nerror $O(\\delta^p)$ where $\\delta$ is the smoothing radius and $p = 3$, $5$,\n$7$. With spacing $h$ in the quadrature, we choose $\\delta = \\kappa h^q$ with\n$q<1$ so that the discretization error is controlled as $h \\to 0$. We see the\npredicted order of convergence $O(h^{pq})$ in various examples. Values at all\ngrid points can be obtained from those near the surface in an efficient manner\nsuggested in A. Mayo (SIAM J. Statist. Comput., 1985). With this technique we\nobtain high order accurate grid values for a harmonic function determined by\ninterfacial conditions and for the pressure and velocity in Stokes flow around\na translating spheroid."}
{"id": "2510.13279", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13279", "abs": "https://arxiv.org/abs/2510.13279", "authors": ["Fuma Omori", "Atsushi Yano", "Takuya Azumi"], "title": "Partitioned Scheduling for DAG Tasks Considering Probabilistic Execution Time", "comment": null, "summary": "Autonomous driving systems, critical for safety, require real-time guarantees\nand can be modeled as DAGs. Their acceleration features, such as caches and\npipelining, often result in execution times below the worst-case. Thus, a\nprobabilistic approach ensuring constraint satisfaction within a probability\nthreshold is more suitable than worst-case guarantees for these systems. This\npaper considers probabilistic guarantees for DAG tasks by utilizing the results\nof probabilistic guarantees for single processors, which have been relatively\nmore advanced than those for multi-core processors. This paper proposes a task\nset partitioning method that guarantees schedulability under the partitioned\nscheduling. The evaluation on randomly generated DAG task sets demonstrates\nthat the proposed method schedules more task sets with a smaller mean analysis\ntime compared to existing probabilistic schedulability analysis for DAGs. The\nevaluation also compares four bin-packing heuristics, revealing Item-Centric\nWorst-Fit-Decreasing schedules the most task sets."}
{"id": "2510.13522", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "49N35, 93B51, 93B52, 90C34, 62M45, 41A05"], "pdf": "https://arxiv.org/pdf/2510.13522", "abs": "https://arxiv.org/abs/2510.13522", "authors": ["Siddhartha Ganguly", "Shubham Gupta", "Debasish Chatterjee"], "title": "Data-driven learning of feedback maps for explicit robust predictive control: an approximation theoretic view", "comment": "27 pages; submitted", "summary": "We establish an algorithm to learn feedback maps from data for a class of\nrobust model predictive control (MPC) problems. The algorithm accounts for the\napproximation errors due to the learning directly at the synthesis stage,\nensuring recursive feasibility by construction. The optimal control problem\nconsists of a linear noisy dynamical system, a quadratic stage and quadratic\nterminal costs as the objective, and convex constraints on the state, control,\nand disturbance sequences; the control minimizes and the disturbance maximizes\nthe objective. We proceed via two steps -- (a) Data generation: First, we\nreformulate the given minmax problem into a convex semi-infinite program and\nemploy recently developed tools to solve it in an exact fashion on grid points\nof the state space to generate (state, action) data. (b) Learning approximate\nfeedback maps: We employ a couple of approximation schemes that furnish tight\napproximations within preassigned uniform error bounds on the admissible state\nspace to learn the unknown feedback policy. The stability of the closed-loop\nsystem under the approximate feedback policies is also guaranteed under a\nstandard set of hypotheses. Two benchmark numerical examples are provided to\nillustrate the results."}
{"id": "2510.13083", "categories": ["math.OC", "cs.NA", "math.NA", "math.PR", "52A38, 60D05, 90C05, 90C31, 90C46"], "pdf": "https://arxiv.org/pdf/2510.13083", "abs": "https://arxiv.org/abs/2510.13083", "authors": ["Michael P. Friedlander", "Sharvaj Kubal", "Yaniv Plan", "Matthew S. Scott"], "title": "Average-case thresholds for exact regularization of linear programs", "comment": "25 pages, 4 figures", "summary": "Small regularizers can preserve linear programming solutions exactly. This\npaper provides the first average-case analysis of exact regularization: with a\nstandard Gaussian cost vector and fixed constraint set, bounds are established\nfor the probability that exact regularization succeeds as a function of\nregularization strength. Failure is characterized via the Gaussian measure of\ninner cones, controlled by novel two-sided bounds on the measure of shifted\ncones. Results reveal dimension-dependent scaling laws and connect exact\nregularization of linear programs to their polyhedral geometry via the normal\nfan and the Gaussian (solid-angle) measure of its cones. Computable bounds are\nobtained in several canonical settings, including regularized optimal\ntransport. Numerical experiments corroborate the predicted scalings and\nthresholds."}
{"id": "2510.13396", "categories": ["eess.SY", "cs.SY", "93-10"], "pdf": "https://arxiv.org/pdf/2510.13396", "abs": "https://arxiv.org/abs/2510.13396", "authors": ["Luka Baković", "David Ohlin", "Emma Tegling"], "title": "Multipolar dynamics of social segregation: Data validation on Swedish vaccination statistics", "comment": "Presented at CoDIT 2025", "summary": "We perform a validation analysis on the multipolar model of opinion dynamics.\nA general methodology for using the model on datasets of two correlated\nvariables is proposed and tested using data on the relationship between\nCOVID-19 vaccination rates and political participation in Sweden. The model is\nshown to successfully capture the opinion segregation demonstrated by the data\nand spatial correlation of biases is demonstrated as necessary for the result.\nA mixing of the biases on the other hand leads to a more homogeneous opinion\ndistribution, and greater penetration of the majority opinion, which here\ncorresponds to a decision to vote or vaccinate."}
{"id": "2510.13449", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13449", "abs": "https://arxiv.org/abs/2510.13449", "authors": ["Jan Brändle", "Julie Rousseau", "Pulkit Nahata", "Gabriela Hug"], "title": "On the Flexibility Potential of a Swiss Distribution Grid: Opportunities and Limitations", "comment": null, "summary": "The growing integration of distributed renewable generation and the\nelectrification of heating and transportation are rapidly increasing the number\nof flexible devices within modern distribution grids. Leveraging the aggregated\nflexibility of these small-scale distributed resources is essential to\nmaintaining future grid-wide stability. This work uses the Swiss distribution\ngrid of Walenstadt as a case study to provide insights into the aggregated\nflexibility potential of distribution grids. It demonstrates that incorporating\ndevices such as heat pumps and photovoltaic systems significantly enhances\ndistribution grid flexibility. It investigates the time-varying nature of\naggregated flexibility and highlights how it can vary seasonally. Furthermore,\nsimulations of future scenarios reveal that aggregated flexibility does not\nincrease linearly or monotonically with higher levels of flexible device\npenetration. This is primarily due to the overloading of individual feeders,\nwhich underscores the impact of grid topology and network constraints on the\naggregated flexibility potential."}
{"id": "2510.13461", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13461", "abs": "https://arxiv.org/abs/2510.13461", "authors": ["Yangye Jiang", "Jiachen Wang", "Daofei Li"], "title": "Physics-Informed Neural Network Modeling of Vehicle Collision Dynamics in Precision Immobilization Technique Maneuvers", "comment": null, "summary": "Accurate prediction of vehicle collision dynamics is crucial for advanced\nsafety systems and post-impact control applications, yet existing methods face\ninherent trade-offs among computational efficiency, prediction accuracy, and\ndata requirements. This paper proposes a dual Physics-Informed Neural Network\nframework addressing these challenges through two complementary networks. The\nfirst network integrates Gaussian Mixture Models with PINN architecture to\nlearn impact force distributions from finite element analysis data while\nenforcing momentum conservation and energy consistency constraints. The second\nnetwork employs an adaptive PINN with dynamic constraint weighting to predict\npost-collision vehicle dynamics, featuring an adaptive physics guard layer that\nprevents unrealistic predictions whil e preserving data-driven learning\ncapabilities. The framework incorporates uncertainty quantification through\ntime-varying parameters and enables rapid adaptation via fine-tuning\nstrategies. Validation demonstrates significant improvements: the impact force\nmodel achieves relative errors below 15.0% for force prediction on finite\nelement analysis (FEA) datasets, while the vehicle dynamics model reduces\naverage trajectory prediction error by 63.6% compared to traditional\nfour-degree-of-freedom models in scaled vehicle experiments. The integrated\nsystem maintains millisecond-level computational efficiency suitable for\nreal-time applications while providing probabilistic confidence bounds\nessential for safety-critical control. Comprehensive validation through FEA\nsimulation, dynamic modeling, and scaled vehicle experiments confirms the\nframework's effectiveness for Precision Immobilization Technique scenarios and\ngeneral collision dynamics prediction."}
{"id": "2510.13514", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13514", "abs": "https://arxiv.org/abs/2510.13514", "authors": ["Andreas C. Makrides", "Adam Suski", "Elina Spyrou"], "title": "Quantifying the Impact of Missing Risk Markets for Decarbonized Power Systems with Long Duration Energy Storage", "comment": null, "summary": "The transition to a fully decarbonised electricity system depends on\nintegrating new technologies that ensure reliability alongside sustainability.\nHowever, missing risk markets hinder investment in reliability-enhancing\ntechnologies by exposing investors to revenue uncertainty. This study provides\nthe first quantitative assessment of how missing risk markets affect investment\ndecisions in power systems that depend on long-duration energy storage (LDES)\nfor reliability. We develop a two-stage stochastic equilibrium model with\nrisk-averse market participants, which independently sizes power and energy\ncapacity. We apply the method to a case study of a deeply decarbonised power\nsystem in Great Britain. The results show that incomplete risk markets reduce\nsocial welfare, harm reliability, and discourage investment in LDES and other\ntechnologies with volatile revenue streams. Revenue volatility leads to\nsubstantial risk premiums and higher financing costs for LDES, creating a\nbarrier to its large-scale deployment. These findings demonstrate the\nimportance of policy mechanisms that hedge revenue risk to lower the cost of\ncapital and accelerate investment in reliability-enhancing, zero-carbon\ntechnologies"}
{"id": "2510.13563", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13563", "abs": "https://arxiv.org/abs/2510.13563", "authors": ["Ayten Gürbüz", "Giuseppe Caire"], "title": "Channel Estimation under Large Doppler Shifts in NOMA-Based Air-Ground Communications", "comment": "Submitted to IEEE Conference, 6 pages, 2 Figures", "summary": "This paper investigates a multiple antenna system with non-orthogonal\nmultiple access (NOMA) for the exchange of air traffic management data between\ncommercial aircraft pilots and ground-based air traffic controllers. While NOMA\ntechniques enhance spectral efficiency, their application to aircraft\ncommunications is challenged by the high speed of the aircraft (up to 214 m/s)\nand the long communication ranges (up to 250 km), resulting in significant\nDoppler shifts and low signal-to-noise ratios, respectively. To accurately\nassess these challenges, we employ a realistic geometry-based stochastic\nair-ground channel model, derived from dedicated flight measurement campaigns.\nIn this paper, multiple aircraft simultaneously transmit data to the ground\nstation. We focus on the channel estimation problem at the ground station under\nhigh carrier frequency offsets and the effects of channel aging due to\nchannel's time-varying nature. For the channel estimation problem, we compare\nthe Zadoff-Chu sequences with time-division approach under varying carrier\nfrequency offset pre-compensation accuracies at the aircraft transmitter. For\nthe channel aging problem and performance evaluation of channel estimators, we\ncompute the outage probability for both the zero-forcing detector and the\nminimum mean squared error detector with successive interference cancellation.\nThe results show that the favorable channel estimator-detector combinations\ndiffer between the takeoff & landing phase and the enroute cruise phase of the\nflight, due to the distinct channel propagation characteristics of each phase."}
{"id": "2510.13682", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.13682", "abs": "https://arxiv.org/abs/2510.13682", "authors": ["Jiayang Li", "Qingyu Zhang", "Sohmyung Ha", "Dai Jiang", "Andreas Demosthenous", "Yu Wu"], "title": "A 0.62 μW/sensor 82 fps Time-to-Digital Impedance Measurement IC with Unified Excitation/Readout Front-end for Large-Scale Piezo-Resistive Sensor Array", "comment": null, "summary": "This paper presents a fast impedance measurement IC for large-scale\npiezo-resistive sensor array. It features a unified differential\ntime-to-digital demodulation architecture that readout impedance directly\nthrough the excitation circuit. The proposed pre-saturation adaptive bias\ntechnique further improves power efficiency. The chip scans 253 sensors in 12.2\nms (82 fps) at 125 kHz, consuming 158 {\\mu}W (7.5 nJ/sensor). With loads from\n20 {\\Omega} to 500 k{\\Omega}, it achieves 0.5% error and up to 71.1 dB SNR."}
{"id": "2510.13522", "categories": ["math.OC", "cs.LG", "cs.SY", "eess.SY", "49N35, 93B51, 93B52, 90C34, 62M45, 41A05"], "pdf": "https://arxiv.org/pdf/2510.13522", "abs": "https://arxiv.org/abs/2510.13522", "authors": ["Siddhartha Ganguly", "Shubham Gupta", "Debasish Chatterjee"], "title": "Data-driven learning of feedback maps for explicit robust predictive control: an approximation theoretic view", "comment": "27 pages; submitted", "summary": "We establish an algorithm to learn feedback maps from data for a class of\nrobust model predictive control (MPC) problems. The algorithm accounts for the\napproximation errors due to the learning directly at the synthesis stage,\nensuring recursive feasibility by construction. The optimal control problem\nconsists of a linear noisy dynamical system, a quadratic stage and quadratic\nterminal costs as the objective, and convex constraints on the state, control,\nand disturbance sequences; the control minimizes and the disturbance maximizes\nthe objective. We proceed via two steps -- (a) Data generation: First, we\nreformulate the given minmax problem into a convex semi-infinite program and\nemploy recently developed tools to solve it in an exact fashion on grid points\nof the state space to generate (state, action) data. (b) Learning approximate\nfeedback maps: We employ a couple of approximation schemes that furnish tight\napproximations within preassigned uniform error bounds on the admissible state\nspace to learn the unknown feedback policy. The stability of the closed-loop\nsystem under the approximate feedback policies is also guaranteed under a\nstandard set of hypotheses. Two benchmark numerical examples are provided to\nillustrate the results."}
