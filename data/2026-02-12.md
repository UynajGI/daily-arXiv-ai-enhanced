<div id=toc></div>

# Table of Contents

- [hep-lat](#hep-lat) [Total: 1]
- [nlin.AO](#nlin.AO) [Total: 1]
- [quant-ph](#quant-ph) [Total: 4]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 5]
- [nlin.CD](#nlin.CD) [Total: 3]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 10]
- [math.OC](#math.OC) [Total: 10]
- [physics.geo-ph](#physics.geo-ph) [Total: 2]
- [math.NA](#math.NA) [Total: 16]
- [physics.soc-ph](#physics.soc-ph) [Total: 6]
- [stat.ME](#stat.ME) [Total: 12]
- [math.ST](#math.ST) [Total: 8]
- [physics.hist-ph](#physics.hist-ph) [Total: 1]
- [cs.CE](#cs.CE) [Total: 2]
- [eess.SY](#eess.SY) [Total: 10]


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [1] [Dirac mode localization in QCD near the crossover temperature](https://arxiv.org/abs/2602.10921)
*Matteo Giordano,Tamas G. Kovacs,Ferenc Pittler*

Main category: hep-lat

TL;DR: 研究了QCD在接近交叉温度时低能狄拉克本征模的局域化特性，发现局域化低能模在特定温度范围内出现，与拟临界交叉温度高度一致。


<details>
  <summary>Details</summary>
Motivation: 探索QCD在高温下低能狄拉克本征模的局域化行为及其与相变温度的关系。

Method: 使用格点上的 staggered 费米子研究狄拉克算符的低能本征模。

Result: 在155 MeV到158 MeV的温度范围内观察到局域化的低能模，与通过手征凝聚和轻夸克敏感度确定的拟临界温度一致。

Conclusion: 局域化低能模的出现温度与QCD的伪临界温度高度吻合，表明其可作为相变的信号。

Abstract: We study the localization properties of the low-lying Dirac eigenmodes in QCD near the crossover temperature, using staggered fermions on the lattice. We find that localized low modes, absent at low temperature, appear at a temperature $T_{\mathrm{loc}}$ in the range $155\,\mathrm{MeV}\le T_{\mathrm{loc}}\le 158\,\mathrm{MeV}$, in excellent agreement with the pseudocritical crossover temperature as determined from the chiral condensate and from the light-quark susceptibility.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [2] [Defect states as a precursor of the chimera states in a ring of non-locally coupled oscillators](https://arxiv.org/abs/2602.10533)
*Tianjing Zhou,Nariya Uchida*

Main category: nlin.AO

TL;DR: 研究了非局域耦合相位振子环中从同步态到chimera态的转变，重点分析中间缺陷态及其作为chimera簇成核前兆的作用。


<details>
  <summary>Details</summary>
Motivation: 探索chimera态在受挫耦合振子系统中的产生机制，理解同步态向复杂异质态转变的动力学过程。

Method: 通过数值模拟和动力学分析，研究相位延迟α对缺陷态特性（如传播速度、数量、宽度）的影响，并分析其与chimera态出现的关系。

Result: 发现旅行缺陷态是chimera簇形成的前兆；缺陷态出现比例随α增加并在αc处达到峰值；缺陷的传播速度、数量和宽度随α增大，但总空间范围与系统大小N无关。

Conclusion: 旅行缺陷态在chimera态的形成中起关键作用，揭示了受挫耦合振子系统中chimera态涌现的新机制。

Abstract: We investigate the transition from synchronized to chimera states in a ring of non-locally coupled phase oscillators. Our focus is on the intermediate defect states, where solitary waves in the phase gradient profile travel at a constant speed. These traveling defects serve as a dynamical precursor for the nucleation of chimera clusters. The fraction of samples exhibiting defect states increases with the phase delay $α$ and peaks at $α_{c}$, where the system crosses over to asynchronous states filled with chimera clusters. While the traveling speed, number, and width of these defects increase with $α$, the total spatial extent of the defects remains robust against the system size $N$. These results shed new light on the emergence of chimera states in frustrated coupled oscillators.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [3] [Emulation of large-scale qubit registers with a phase space approach](https://arxiv.org/abs/2602.10830)
*Christian de Correc,Denis Lacroix,Corentin Bertrand*

Main category: quant-ph

TL;DR: 提出了一种基于相空间的统计系综方法，用于模拟大规模量子比特寄存器的连续时间演化，具有二次计算成本，可模拟多达数千个量子比特。


<details>
  <summary>Details</summary>
Motivation: 为克服传统方法在模拟大规模量子系统时的计算资源限制，发展一种高效且可扩展的近似模拟方法。

Method: 采用基于相空间的方法，通过独立平均场轨迹的统计系综进行模拟，将量子涨落/关联替换为经典涨落。

Result: 该方法在单量子比特可观测量演化上提供定性准确的结果，适用于从局域到全连接、弱耦合到强耦合的各种k-局部横向场伊辛模型，最大模拟规模达2000量子比特，并扩展至2D和3D伊辛模型。

Conclusion: 该方法在计算效率与系统规模之间实现了良好平衡，适合大尺度系统的定性研究，但在多量子比特关联量的预测能力上仍有局限。

Abstract: A phase-space approach is used and benchmarked for the simulation of the continuous-time evolution of large registers of qubits. It is based on a statistical ensemble of independent mean-field trajectories, where mean-field is introduced at the level of the qubits, substituting quantum fluctuations/correlations with classical ones. The approach only involves at worse a quadratic cost in the system size, allowing to simulate up to several thousands of qubits on a classical computer. It provides qualitatively accurate description of one-qubit observables evolutions, making it a useful reference in comparison to techniques limited to small qubit numbers. The predictive power is however less robust for multi-qubits observables. We benchmark the method on the $k$-local transverse-field Ising model (TFIM), considering a large variety of systems ranging from local to all-to-all interactions, and from weak to strong coupling regimes, with up to 2000 qubits. To showcase the versatility of the approach, simulations on 2D and 3D Ising models are also made.

</details>


### [4] [Quantum Brownian motion with non-Gaussian noises: Fluctuation-Dissipation Relation and nonlinear Langevin equation](https://arxiv.org/abs/2602.10421)
*Hing-Tong Cho,Bei-Lok Hu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Building upon the work of Hu, Paz, and Zhang [1,2] on open quantum systems we consider the quantum Brownian motion (QBM) model with one oscillator (position variable $x$) as the system, {\it nonlinearly} coupled to an environment of $N$ harmonic oscillators (with mass $m_n$, natural frequency $ω_n$, position $q_n$ and momentum $p_n$ variables) in the form $\sum_{n}\left(v_{n1}(x)q_{n}^{k}+v_{n2}(x)p_{n}^{l}\right)$ where $k, l$ are integers (the present work only considers the $k=l=2$ cases). The vertex functions $v_{n1}, v_{n2} $ are of the form $v_{n1}=λC_{n1} f(x), v_{n2}(x)=-λ\,C_{n2}m_{n}^{-2}ω_{n}^{-2}f(x)$ where $C_{n1,2}$ are the coupling constants with the $n$th oscillator, $f(x)$ is any arbitrary function of $x$, and $λ$ is a dimensionless constant. Employing the closed-time-path formalism the influence action $S_{IF}$ is calculated using a perturbative expansion in $λ$. It is possible to identify the terms in $S_{IF}$ quadratic or higher in $Δ(s)\equiv f(x_{+}(s))-f(x_{-}(s))$ to constitute the noise kernel, while terms linear in $Δ$ to that of the dissipation kernel. The non-Gaussian noise kernel gives rise to non-zero three-point correlation function of the corresponding stochastic force. The pathway presented here should be useful for the exploration of \textit{non-Gaussian properties of systems nonlinearly coupled with their environments}; examples in early universe cosmology and in quantum optomechanics (QOM) are mentioned. A modified fluctuation-dissipation relation (FDR) is also established, which ensures the consistency of the model and the accuracy of results even at higher perturbative orders. Another result of significance is the derivation of a nonlinear Langevin equation which is expected to be useful for many open quantum system applications.

</details>


### [5] [Ergotropic Mpemba crossings in finite-dimensional quantum batteries](https://arxiv.org/abs/2602.11056)
*Triyas Sapui,Tanoy Kanti Konar,Aditi Sen De*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The quantum Mpemba effect is a counterintuitive phenomenon in which a state initially farther from equilibrium relaxes more rapidly than one that starts nearer to equilibrium. In the context of finite-dimensional quantum batteries interacting with an environment, we introduce the notion of an ergotropic Mpemba crossing (EMC), defined by the intersection of ergotropy trajectories during the dynamics. For qubit batteries subjected to amplitude damping noise, we derive a condition for the occurrence of EMC in terms of the relative coherence of the initial states and fully characterize the region of state space that exhibits EMC with respect to a fixed reference state. Interestingly, our analysis reveals that under anisotropic Pauli noise, the emergence of EMC is jointly governed by the coherence and the energy of the initial states. To elucidate the physical origin of EMC, we decompose ergotropy into coherent and incoherent contributions and show that, in qubit systems, the coherent component plays a crucial role for EMC, an observation that strikingly does not extend to three-level batteries. Further, by extending our analysis to non-Markovian environments, we demonstrate that, unlike the Markovian case, non-Markovian dynamics can give rise to multiple Mpemba crossings, with the total number of crossings always being odd. Moreover, analyzing the connection between the EMC and the conventional state Mpemba effect reveals that, for qubits, an EMC necessarily entails a state Mpemba crossing while this correspondence breaks down for qutrits, where EMCs may arise without any state Mpemba crossing.

</details>


### [6] [Block encoding of sparse matrices with a periodic diagonal structure](https://arxiv.org/abs/2602.10589)
*Alessandro Andrea Zecchi,Claudio Sanavio,Luca Cappelli,Simona Perotto,Alessandro Roggero,Sauro Succi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Block encoding is a successful technique used in several powerful quantum algorithms. In this work we provide an explicit quantum circuit for block encoding a sparse matrix with a periodic diagonal structure. The proposed methodology is based on the linear combination of unitaries (LCU) framework and on an efficient unitary operator used to project the complex exponential at a frequency $ω$ multiplied by the computational basis into its real and imaginary components. We demonstrate a distinct computational advantage with a $\mathcal{O}(\text{poly}(n))$ gate complexity, where $n$ is the number of qubits, in the worst-case scenario used for banded matrices, and $\mathcal{O}(n)$ when dealing with a simple diagonal matrix, compared to the exponential scaling of general-purpose methods for dense matrices. Various applications for the presented methodology are discussed in the context of solving differential problems such as the advection-diffusion-reaction (ADR) dynamics, using quantum algorithms with optimal scaling, e.g., quantum singular value transformation (QSVT). Numerical results are used to validate the analytical formulation.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [7] [Generalized Kramers-Wannier Self-Duality in Hopf-Ising Models](https://arxiv.org/abs/2602.10183)
*Da-Chuan Lu,Arkya Chatterjee,Nathanan Tantivasadakarn*

Main category: cond-mat.str-el

TL;DR: 本文构建了一个基于有限维半单Hopf代数的广义1+1d Ising模型，实现了无反常的非可逆对称性，并通过推广Kramers-Wannier变换揭示了其在自对偶点的非可逆对称性，结合数值与代数方法研究了相图并统一了非可逆对称性与张量积晶格模型的实现框架。


<details>
  <summary>Details</summary>
Motivation: 扩展超越阿贝尔群规范对称的自对偶结构，探索非可逆对称性在非交换、非余交换代数背景下的实现方式，并建立更广泛的对称性与对偶性理论框架。

Method: 利用Hopf代数数据构建广义Ising模型，发展基于非(余)交换ZX-演算的图示化方法定义哈密顿量和对称算子；构造广义Kramers-Wannier对偶算子，并结合H-余模代数形式实现所有对称gapped相。

Result: 建立了具有Rep(H)非可逆对称性的模型；当H自对偶时，构造出在临界点成为非可逆对称的对偶操作；发现该对称性与平移对称混合，红外下流向Z2扩展的弱积分融合范畴；以H8为例，数值识别出四个gapped相，六个相均被代数实现，符合模范畴分类。

Conclusion: 本文提供了一个基于Hopf代数的统一框架，用于描述非可逆对称性、对偶性及其在张量积晶格模型中的实现，拓展了传统对称性与相变理论的理解。

Abstract: The Kramers-Wannier transformation of the 1+1d transverse-field Ising model exchanges the paramagnetic and ferromagnetic phases and, at criticality, manifests as a non-invertible symmetry. Extending such self-duality symmetries beyond gauging of abelian groups in tensor-product Hilbert spaces has, however, remained challenging. In this work, we construct a generalized 1+1d Ising model based on a finite-dimensional semisimple Hopf algebra $H$ that enjoys an anomaly-free non-invertible symmetry $\mathrm{Rep}(H)$. We provide an intuitive diagrammatic formulation of both the Hamiltonian and the symmetry operators using a non-(co)commutative generalization of ZX-calculus built from Hopf-algebraic data. When $H$ is self-dual, we further construct a generalized Kramers-Wannier duality operator that exchanges the paramagnetic and ferromagnetic phases and becomes a non-invertible symmetry at the self-dual point. This enlarged symmetry mixes with lattice translation and, in the infrared, flows to a weakly integral fusion category given by a $\mathbb{Z}_2$ extension of $\mathrm{Rep}(H)$. Specializing to the Kac-Paljutkin algebra $H_8$, the smallest self-dual Hopf algebra beyond abelian group algebras, we numerically study the phase diagram and identify four of the six $\mathrm{Rep}(H_8)$-symmetric gapped phases, separated by Ising critical lines and meeting at a multicritical point. We also realize all six $\mathrm{Rep}(H_8)$-symmetric gapped phases on the lattice via the $H$-comodule algebra formalism, in agreement with the module-category classification of $\mathrm{Rep}(H_8)$. Our results provide a unified Hopf-algebraic framework for non-invertible symmetries, dualities, and the tensor product lattice models that realize them.

</details>


### [8] [A web of exact mappings from RK models to spin chains](https://arxiv.org/abs/2602.10205)
*Gurkirat Singh,Inti Sodemann*

Main category: cond-mat.str-el

TL;DR: 研究了在准一维设置下的Rokhsar-Kivelson二聚体和自旋冰模型，发现了这些模型与三种量子链之间的大量映射关系，并通过数值方法确定了相图，揭示了异常的动力学、奇异的临界性和低能物理特性。


<details>
  <summary>Details</summary>
Motivation: 探索在准一维系统中U(1)晶格规范理论的低能物理和量子弦相互作用行为。

Method: 利用量子链映射方法，结合密度矩阵重整化群（DMRG）模拟和玻色化分析，研究模型的相图与动力学特性。

Result: 发现了模型与XXZ链、自旋-1链和动力学约束费米子链之间的映射；发现自旋-1链在RK点具有类布洛赫球的简并基态；发现一个远离RK点的稳定无能隙临界点及希尔伯特空间碎片化现象。

Conclusion: 量子链映射是研究晶格规范理论中非常规动力学和奇异临界行为的有效工具。

Abstract: We study Rokhsar-Kivelson (RK) dimer and spin ice models realizing $U(1)$-lattice gauge theories in a wide class of quasi-one-dimensional settings, which define a setup for the study of few quantum strings (closed electric field lines) interacting with themselves and each other. We discover a large collection of mappings of these models onto three quantum chains: the spin-1/2 XXZ chain, a spin-1 chain, and a kinetically constrained fermion chain whose configurations are best described in terms of tilings of a rectangular strip. We show that the twist of boundary conditions in the chains maps onto the transverse momentum of the electric field string, and their Drude weight to the inverse of the string mass per unit length. We numerically determine the phase diagrams for these spin chains, employing DMRG simulations and find global similarities but also many interesting new features in comparison to the full 2D problems. For example, the spin-1 chain we obtain features a continuous family of degenerate ground states at its RK point analogous to a Bloch sphere, but without an underlying microscopic global $SU(2)$ symmetry. We also argue for the existence of a (stable) Landau-forbidden gapless critical point away from the RK point in one of the models we study using bosonization and numerics. This is surprising given that the full 2D problem is generically gapped away from the RK point. The same model also displays extensively many local conserved quantities which fragment the Hilbert space, arising as a consequence of destructive resonances between the electric field lines. Our findings highlight spin-chain mappings as a potent technique for the exploration of unusual dynamics, exotic criticality, and low-energy physics in lattice gauge theories.

</details>


### [9] [Superconductivity in strongly correlated systems for local repulsive interactions](https://arxiv.org/abs/2602.10351)
*Humberto M. Silva,Francisco Dinola Neto,Griffith M. A. R.,Minos A. Neto,Octavio D. R. Salmon,Mucio A. Continentino,Amos Troper*

Main category: cond-mat.str-el

TL;DR: 本文研究了强关联体系中由库仑相互作用驱动的超导机制，采用二维Hubbard模型结合Green函数方法和Hubbard-I平均场近似，发现在排斥相互作用下存在由动能驱动的超导态，并需最小排斥强度U_min才能形成配对，强耦合下临界温度Tc呈现类似玻色-爱因斯坦凝聚的饱和行为。


<details>
  <summary>Details</summary>
Motivation: 理解强关联体系中超导机制的本质，探索排斥相互作用如何诱导超导态。

Method: 采用带有局域排斥相互作用的Hubbard模型，利用Green函数方法在Hubbard-I平均场近似下求解方程，适用于强相互作用极限。

Result: 在排斥相互作用情况下发现存在由电子动能介导的超导基态，具有非局域序参量；需最小排斥强度U_min才能形成配对态；在有限温度下，强相互作用时临界温度Tc出现饱和现象，类似于强吸引作用下的玻色-爱因斯坦凝聚。

Conclusion: 排斥相互作用可在强关联二维系统中诱导出非传统的超导态，其机制源于动能驱动和非局域序参量，为高温超导提供了新的理论视角。

Abstract: The understanding of the mechanisms responsible for superconductivity in strongly correlated systems is an interesting and important subject in condensed matter physics. Several theoretical proposals were considered for these systems. The Coulomb interaction between electrons allow a new approach to study this problem. In this paper, we use a usual Hubbard model with a local repulsive interaction to describe a 2D system. The system of equations are solved using the Green's functions method, within a Hubbard-I mean field approximation, which allows to treat the strong interaction limit. We consider both cases of attractive and repulsive interactions and obtain the zero temperature phase diagram of the model. Our results show, in the repulsive case, the existence of a superconducting ground state mediated by the kinetic electronic energy and described by a non-local order parameter. A minimum value of the repulsive interaction $U_{min}$ is required to create a pairing state. At finite temperatures, for strong interactions, the critical temperature $T_c$ shows a saturation similar to the Bose-Einstein condensation observed for strong attractive interactions.

</details>


### [10] [Quantum critical behavior of cuprate superconductors observed by inelastic X-ray scattering](https://arxiv.org/abs/2602.11011)
*H. Y. Huang,C. Y. Mou,A. Singh,J. S. Su,J. Okamoto,S. Komiya,C. T. Chen,T. K. Lee,A. Fujimor,D. J. Huang*

Main category: cond-mat.str-el

TL;DR: 通过高分辨共振非弹性X射线散射，研究发现La$_{2-x}$Sr$_x$CuO$_4$中存在量子临界点（QCP），其临界指数ν为0.74±0.08，且属于O(4)对称性普适类，表明电荷密度波与其他序共同作用，且QCP具有强耗散性和短准粒子寿命。


<details>
  <summary>Details</summary>
Motivation: 探索铜氧化物超导体复杂相图背后的量子临界点（QCP），因其被超导态掩盖而难以确认。

Method: 使用高分辨率共振非弹性X射线散射技术研究La$_{2-x}$Sr$_x$CuO$_4$中的动力学电荷关联，并分析关联长度的普适标度行为。

Result: 观测到不同掺杂和温度下的逆关联长度坍缩到一条普适标度曲线，得到临界指数ν = 0.74 ± 0.08；该值支持QCP的存在且暗示其属于O(4)对称性普适类，同时发现QCP具有强耗散性和短准粒子寿命。

Conclusion: 在超导覆盖下存在一个具有O(4)对称性特征的量子临界点，表明多种序参量共同参与，揭示了铜氧化物中量子涨落的纠缠本质。

Abstract: Progress toward a complete understanding of cuprate superconductors has been hindered by their intricate phase diagram, potentially linked to a quantum critical point (QCP). However, conclusive evidence for the QCP is lacking, as the presumed QCP is buried under the superconducting dome, disguising its presence. Here, we use high-resolution resonant inelastic X-ray scattering to examine the dynamical charge-charge correlation in La$_{2-x}$Sr$_x$CuO$_4$ and uncover the quantum critical scaling, a key feature required for a QCP. Specifically, \djh{we observed that the inverse correlation lengths for various dopings and temperatures collapsed onto a universal scaling curve, yielding a critical exponent $ν$ of $0.74 \pm 0.08$. The non-negativity of this exponent confirms the presence of a QCP. Remarkably, the value of $ν$ suggests that while the QCP is manifested through the charge-density wave, other orders also participate, such that the QCP appears to belong to the universality class characterized by the O(4) symmetry, reminiscent of the microscopic SO(4) symmetry in the Hubbard model at half-filling. Further analysis indicates that the QCP is highly dissipative with a short quasi-particle lifetime, reflecting the intertwined quantum fluctuations due to its being buried inside the superconducting state.

</details>


### [11] [Mapping reservoir-enhanced superconductivity to near-long-range magnetic order in the undoped 1D Anderson- and Kondo-lattices](https://arxiv.org/abs/2602.11153)
*J. E. Ebot,Lorenzo Pizzino,Sam Mardazad,Johannes S. Hofmann,Thierry Giamarchi,Adrian Kantian*

Main category: cond-mat.str-el

TL;DR: 本研究通过准精确数值方法首次大规模研究了一维安德森晶格模型及其对应的Kondo项链有效模型，揭示了在绝缘态出现的长度尺度以下，超导和密度-密度关联会退化并接近有序态，这种效应源于金属层在配对层中诱导的有效长程耦合。研究还将结果推广到Kondo系统中的近长程磁序现象，并解释了RKKY耦合的强重整化机制。


<details>
  <summary>Details</summary>
Motivation: 理解一维Kondo绝缘体中隐藏的超导与磁性关联的本质，以及安德森晶格模型与Kondo项链模型之间的深层联系，并探索金属层对超导配对的增强作用。

Method: 采用准精确数值方法对一维安德森晶格模型进行大规模计算，并通过将其精确映射到具有超导配对层与金属库耦合的系统中，分析其在任意空间维度下的行为，同时比较其与微扰导出的Kondo项链模型的结果。

Result: 发现低于绝缘态形成的特征长度尺度时，超导与密度-密度关联表现出退化并趋近于几乎有序的状态，且远超孤立一维配对层的表现；该效应归因于金属层介导的扩展范围耦合；同时发现Kondo系统在中间尺度可能出现近长程序，并观察到RKKY相互作用的显著重整化，源于配对层对金属层的反作用。

Conclusion: 安德森晶格模型在一维下展现出超越传统Kondo项链描述的丰富物理，揭示了金属库对超导相关性的显著增强作用，建立了周期性Kondo系统与储层增强超导之间的理论联系，为实验探测（如重费米子材料、原子链或冷原子系统）提供了新视角。

Abstract: The undoped Kondo necklace in 1D is a paradigmatic and well understood model of a Kondo insulator. This work performs the first large-scale study of the 1D Anderson-lattice underlying the Kondo necklace with quasi-exact numerical methods, comparing this with the perturbative effective 1D Kondo-necklace model derived from the former. This study is based on an exact mapping of the Anderson model to one of a superconducting pairing layer connected to a metallic reservoir which is valid in arbitrary spatial dimensions, thereby linking the previously disparate areas of reservoir-enhanced superconductivity, following Kivelson's pioneering proposals, and that of periodic Kondo-systems. Our work reveals that below the length-scales on which the insulating state sets in, which can be very large, superconducting and density-density correlations are degenerate and may both appear to approach an almost ordered state, to a degree that far exceeds that of any isolated 1D pairing layer with short-range interactions. We trace these effects to the effective extended-range coupling that the metallic layer mediates within the pairing layer. These results translate directly to the appearance of near-long-range magnetic order at intermediate scales in the Kondo-systems, and explain the strong renormalization of the RKKY-coupling that we effectively observe, in terms of the back-action of the pairing layer onto the metallic layer. The effects we predict could be tested either by local probes of quasi-1D heavy fermion compounds such as CeCo$_2$Ga$_8$, in engineered chains of ad-atoms or in ultracold atomic gases.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [12] [On the dynamical and statistical properties of a quartic mean-field Hamiltonian model](https://arxiv.org/abs/2602.10297)
*Matheus Rolim Sales,Edson Denis Leonel,Chris G. Antonopoulos*

Main category: nlin.CD

TL;DR: 该论文研究了四次平均场哈密顿模型在热力学极限和有限尺寸下的动力学与统计特性，发现随着系统自由度增加，混沌被抑制且系统趋于可积；有限N时最大李雅普诺夫指数代数衰减，熵指数q最终趋于1，表明渐近强混沌行为。


<details>
  <summary>Details</summary>
Motivation: 探讨大而有限系统中可积性如何出现以及混沌的本质，理解平均场系统中集体效应与混沌动力学随尺寸变化的关系。

Method: 在Vlasov无碰撞框架下分析热力学极限，推导自洽单粒子描述，并数值计算不同N下的最大李雅普诺夫指数；结合非广延统计力学工具分析熵指数q的时间演化。

Result: 发现平均场动力学在热力学极限下趋于自主并呈现代数收敛的积分量涨落消失；最大李雅普诺夫指数随N代数衰减；熵指数q在长时间下趋近于1，说明有限N系统最终处于强混沌状态。

Conclusion: 平均场哈密顿系统在热力学极限下趋向可积并抑制混沌；此前报道的q>1现象源于有限时间效应，而非持久弱混沌相，真正渐近行为表现为强混沌。

Abstract: Mean-field systems provide a natural framework in which collective effects persist as the number of degrees of freedom N increases, raising fundamental questions about the emergence of integrability and the nature of chaos in large but finite systems. We investigate the dynamical and statistical properties of a quartic mean-field Hamiltonian model, with particular emphasis on the relation between the thermodynamic limit and finite-size chaotic dynamics. We first analyze the thermodynamic limit of the model within the Vlasov collisionless framework and derive the corresponding self-consistent single-particle description. We identify the conditions under which the mean-field dynamics becomes effectively autonomous and show numerically that fluctuations of the relevant intensive quantities vanish algebraically with N, supporting the emergence of integrability as N goes to infinity. We then study the finite-N dynamics by computing the largest Lyapunov exponent over an exceptionally wide range of N, spanning several orders of magnitude. We find that the largest Lyapunov exponent decays algebraically with N, consistently with the suppression of chaos in the thermodynamic limit for mean-field Hamiltonian models. Using tools from non-extensive statistical mechanics, we further analyze the time evolution of the entropic index q and demonstrate that, although transient values q > 1 may appear at intermediate times, q systematically converges to unity as the observation time increases. This behavior indicates that the finite-N dynamics is strongly chaotic in the asymptotic regime and that previously reported q > 1 values for the present models originate from finite-time effects rather than from a persistent weakly chaotic phase.

</details>


### [13] [Stabilizing chaotic dynamical system reproduction in reservoir computing](https://arxiv.org/abs/2602.11069)
*Satoshi Oishi,Hiroshi Yamashita,Hideyuki Suzuki,Sho Shirasaka*

Main category: nlin.CD

TL;DR: 提出了一种确定性的输入层设计原则，有效抑制了储层计算中虚假不稳定模式的产生，显著提升了其在自主运行下的鲁棒性和预测能力。


<details>
  <summary>Details</summary>
Motivation: 解决储层计算在闭环运行中因随机初始化导致的不稳定性及对噪声敏感的问题，提高其可靠性和对目标动力系统的忠实模拟能力。

Method: 通过分析发现虚假的不稳定或中性模式是导致储层计算不可靠的主要原因，并提出一种新的确定性输入层设计方法，在训练前结构性地抑制这些模式的出现。

Result: 新方法显著增强了对初始化敏感性和内部噪声的鲁棒性，预测 horizon 提高了一倍；在混沌动力系统上实现了100%成功率的完整李雅普诺夫谱估计（50次不同随机种子）。

Conclusion: 该研究为储层计算的常见失效模式提供了系统性解释，并提出了可提升其稳定性的具体设计准则，推动其从依赖试错调参向可靠建模工具发展。

Abstract: Reservoir Computing (RC), a type of recurrent random neural network, is a powerful framework for modeling complex and chaotic dynamics. However, its autonomous (closed-loop) operation is often plagued by inherent instability. Moreover, performance is highly sensitive to the reservoir's random initialization, leading to vulnerability to noise and/or behaviour that bears no resemblance whatsoever to the target dynamical system. Here we identify a primary cause of this unreliability: the emergence of excessive, spurious unstable or neutral modes in the closed-loop dynamics. We introduce a simple deterministic input layer design principle that directly addresses this vulnerability by structurally suppressing the emergence of these spurious modes a priori (before training). Our approach dramatically improves robustness to both initialization sensitivity and internal noise, doubling the prediction horizon. Furthermore, we demonstrate on chaotic dynamical systems that this design enables robust estimation of the full Lyapunov spectrum (100\% success rate across 50 seeds), signifying that the autonomous RC faithfully emulates the essential properties of the target dynamical system. This work provides a systematic explanation for a common RC failure mode and offers a concrete design guideline, advancing RCs from heuristic trial-and-error tuning toward a reliable tool for modeling complex systems.

</details>


### [14] [Chaos, the Critical Phenomenon in Phase Space: Feigenbaum Constants and Critical Exponents](https://arxiv.org/abs/2602.08895)
*Yonghui Xia,Hongtao Feng*

Main category: nlin.CD

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Chaos in both dissipative systems and conservative systems is investigated on the approach of renormalization group. It is found that the chaos is regarded as the critical phenomenon of equilibrium statistics in phase space. The two Feigenbaum constants in the period-doubling bifurcation systems correspond to two independent critical exponents, which are universal and can be adopted to distinguish the classes of chaos. For the conservative systems, due to the critical nature of the chaos, the isolated systems with different parameters are correlated in the phase space, and therefore the isolated system is no longer isolated in the phase space. The information of conservative systems is irreversibly lost over time, which leads to the increase entropy in an isolated system, and the contradiction between the second law of thermodynamics and the reversibility of isolated systems can be resolved.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [15] [A non-perturbative framework for N-point functions of locally non-Gaussian fields](https://arxiv.org/abs/2602.10151)
*Hardi Veermäe*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种非微扰方法来研究局部非高斯场的关联函数和多谱，并发展了一个不依赖局域展开的半微扰框架，在强非高斯极限下推导出一些精确解析结果。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地描述局部非高斯场的统计特性，避免传统局域展开方法的局限性。

Method: 采用非微扰方法并发展半微扰框架，应用于具有指数尾部的局部非高斯场。

Result: 在强非高斯极限下得到了关联函数和多谱的一些精确解析结果。

Conclusion: 该方法为研究非高斯场提供了新的有效工具，尤其适用于强非高斯情形。

Abstract: We present a non-perturbative approach to correlation functions and polyspectra of locally non-Gaussian fields and develop a simple semi-perturbative framework that does not rely on the local expansion. As an example, we apply it to locally non-Gaussian fields possessing exponential tails and derive some exact analytic results in the strongly non-Gaussian limit.

</details>


### [16] [Scaling and Universality at Noise-Affected Non-Equilibrium Spin Correlation Functions](https://arxiv.org/abs/2602.10805)
*R. Jafari,Alireza Akbari*

Main category: cond-mat.stat-mech

TL;DR: 研究了在非平衡态自旋关联函数中噪声影响下的标度与普适性，发现噪声强度与扫速共同作用下会出现最大混合模式及高度振荡区域，并找到了普适的标度函数。


<details>
  <summary>Details</summary>
Motivation: 探索在随机驱动场和噪声存在下自旋系统动力学行为的普适规律，特别是关联函数的振荡转变和激发行为。

Method: 通过理论分析和数值模拟，研究含噪声情况下自旋关联函数随扫速变化的动力学相图，提取临界扫速与噪声强度的关系并寻找普适标度律。

Result: 发现临界扫速随噪声强度平方线性减小；当噪声与扫速相当，出现动量窗口内激发概率锁定为1/2的现象，对应噪声诱导的最大混合模；同时识别出一个具有二次标度关系的高振荡区域边界；所有边界曲线可通过普适标度函数坍缩为单一曲线。

Conclusion: 噪声显著改变非平衡自旋系统的动力学行为，诱导出新的普适类和最大混合态，揭示了噪声与驱动竞争下的丰富相结构和标度规律。

Abstract: We investigate scaling and universality in nonequilibrium spin correlation functions in the presence of uncorrelated noise. In the absence of noise, spin correlation functions exhibit a crossover from monotonic decay at fast sweep velocities to oscillatory behavior at slow sweeps. We show that, under a stochastically driven field, the critical sweep velocity at which the spin correlation functions undergo an abrupt change decreases with increasing noise strength and scales linearly with the square of the noise intensity. Remarkably, when the noise intensity and sweep velocity are comparable, the excitation probability becomes locked to pk = 1/2 over a finite momentum window, signaling the emergence of noise-induced maximally mixed modes. This gives rise to a highly oscillatory region in the dynamical phase diagram, whose threshold sweep velocity increases with noise and likewise exhibits quadratic scaling with the noise strength. Finally, we identify a universal scaling function under which all boundary sweep-velocity curves collapse onto a single universal curve.

</details>


### [17] [Whodunnit? The case of midge swarms](https://arxiv.org/abs/2602.10242)
*L. L. Bonilla,R. González-Albaladejo*

Main category: cond-mat.stat-mech

TL;DR: 本文综述并讨论了文献中提出的几种模型，扩展了谐波限制Vicsek模型至各向异性限制，数值模拟结果表明该模型能更好地解释自然群集中的静态临界指数。


<details>
  <summary>Details</summary>
Motivation: 解释实验室和野外研究中观察到的摇蚊群集的相关性和尺度自由行为之间的差异。

Method: 回顾和讨论文献中提出的几种模型，并扩展谐波限制Vicsek模型至各向异性限制，进行数值模拟。

Result: 数值模拟产生了拉长的群集形状，静态临界指数介于二维和各向同性三维模型之间，新值与自然群集中测量的值更一致。

Conclusion: 扩展的谐波限制Vicsek模型能更好地解释自然群集中的观察结果。

Abstract: As collective states of animal groups go, swarms of midge insects pose a number of puzzling questions. Their ordering polarization parameter is quite small and the insects are weakly coupled among themselves but strongly coupled to the swarm. In laboratory studies (free of external perturbations), the correlation length is small, whereas midge swarms exhibit strong correlations, scale free behavior and power laws for correlation length, susceptibility and correlation time in field studies. Data for the dynamic correlation function versus time collapse to a single curve only for small values of time scaled with the correlation time. Is there a theory that explains these disparate observations? Among the existing theories, whodunnit? Here we review and discuss several models proposed in the literature and extend our own one, the harmonically confined Vicsek model, to anisotropic confinement. Numerical simulations of the latter produce elongated swarm shapes and values of the static critical exponents between those of the two dimensional and isotropic three dimensional models. The new values agree better with those measured in natural swarms.

</details>


### [18] [Cyclic active refrigerators](https://arxiv.org/abs/2602.10276)
*S. Liu,A. Datta,A. C. Barato*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了循环活性制冷机的概念，揭示了在活性系统中制冷系数可超越传统热力学第二定律限制的现象，并展示了这类系统可表现出类似麦克斯韦妖的行为，甚至同时作为热机和制冷机运行。


<details>
  <summary>Details</summary>
Motivation: 研究循环活性系统中的热力学行为，特别是活性粒子对制冷性能的影响，探索传统热力学界限在活性物质中的适用性。

Method: 基于已推导的循环活性系统的第二定律，采用两个主动布朗粒子模型进行分析：一个用于解析求解的简化模型和一个通过数值模拟研究的更真实模型。

Result: 发现循环活性制冷机的表观制冷系数可超过传统被动制冷机的理论上限；系统可表现为麦克斯韦妖（无需做功实现热量逆温差流动）；并可进入兼具热机与制冷机功能的混合相。

Conclusion: 活性粒子能显著改变热力学循环的性能，挑战传统热力学界限的理解，为微型能量转换器件的设计提供了新思路。

Abstract: Thermodynamic cycles are idealized processes that can convert heat into work or produce heat flow against a temperature gradient with the input of work. They remain an active area of research in modern stochastic thermodynamics. In particular, cyclic active heat engines have been shown to display a rich phenomenology, such as ``violations'' of the Carnot bound on efficiency and an improved performance in comparison to their passive counterparts. We introduce the concept of cyclic active refrigerators using a previously derived second law for cyclic active systems. We show that for cyclic active refrigerators, a naive definition of the coefficient of performance can exceed the bound set by the standard second law for passive refrigerators. We also show that cyclic active systems can behave like a Maxwell's demon, with heat flowing from the cold to the hot reservoir without any work input. Beyond this phase, cyclic active systems can enter a hybrid phase, functioning as both a heat engine and a refrigerator simultaneously. Our results are obtained with two models that involve active Brownian particles, a simpler one that allows for analytical results and a more realistic one that is analyzed through numerical simulations.

</details>


### [19] [Thermodynamic Optimization of Sensory Adaptation via Game-Theoretic Path Integrals](https://arxiv.org/abs/2602.10571)
*Gunn Kim*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种基于变分自由能原理的场论框架，解释了生物感知系统在噪声环境中实现可靠适应的机制，揭示了感知响应中的相位超调源于记忆-耗散耦合产生的有效惯性，并发现适应性感知处理运行在热力学最优区间内。


<details>
  <summary>Details</summary>
Motivation: 理解生物感知系统如何在强噪声和过阻尼环境下实现跨宽动态范围的可靠适应。

Method: 采用Onsager-Machlup路径积分形式，构建了一个由生物体与环境之间的随机微分博弈描述的变分自由能原理框架，并将其与模型参考自适应控制方案进行数学等价分析。

Result: 感知响应中的相位超调可归因于记忆-耗散耦合产生的有效惯性（m* ≈ τγ），而非传统认为的生化精细调节；跨物种实验数据拟合结果R² > 0.88，表明适应过程处于由信噪比和稳定性约束限定的狭窄热力学最优区间。

Conclusion: 感官适应可通过场论和变分自由能原则统一解释，其核心机制源于动力学层面的有效惯性和动态格林函数重整化，支持生物系统在热力学限制下实现高效稳健的信息处理。

Abstract: Biological sensory systems, from \textit{E.~coli} chemotaxis to sensory neurons in \textit{C.~elegans}, achieve reliable adaptation over wide dynamic ranges despite operating in strongly noisy and overdamped regimes. Here, we present a field-theoretic framework in which sensory adaptation emerges from a variational free-energy principle, formulated as a stochastic differential game between an organism and its environment. Using an Onsager--Machlup path-integral formalism, we show that the resulting adaptive dynamics are mathematically equivalent to a class of model reference adaptive control schemes and can be interpreted as a dynamic renormalization of the system's Green's function. Within this framework, the phasic overshoot commonly observed in sensory responses arises naturally from an effective inertia ($m^* \approx τγ$) generated by memory-dissipation coupling, rather than from biochemical fine-tuning. Quantitative fits to experimental data across species yield $R^2 > 0.88$, and indicate that adaptive sensory processing operates within a narrow thermodynamically optimal regime bounded by signal-to-noise and stability constraints.

</details>


### [20] [Interplay of ion availability and mobility in the loss of cation selectivity for CaCl\textsubscript{2} in negatively charged nanopores: molecular dynamics using scaled-charge models](https://arxiv.org/abs/2602.10600)
*Salman Shabbir,Dezső Boda,Zoltán Ható*

Main category: cond-mat.stat-mech

TL;DR: 研究了NaCl和CaCl₂在带负电的二氧化硅纳米孔中的传输行为，发现多价电解质中由于Ca²⁺在表面附近的固定化及Cl⁻在孔内的主导传导，导致反常的阴离子优先传输。


<details>
  <summary>Details</summary>
Motivation: 探讨传统双电层理论在多价电解质中失效的原因，理解离子-表面强关联和电荷反转对纳米孔离子传输的影响。

Method: 采用基于缩放电荷离子模型的原子级分子动力学模拟，分析径向粒子电流密度中的浓度和速度贡献，关联静态吸附与动态选择性传输。

Result: NaCl表现出常规的阳离子选择性，而CaCl₂由于Ca²⁺在表面附近被固定以及发生电荷反转后Cl⁻在孔内主导传导，表现出接近体相甚至阴离子优先的传输行为。结果对力场中离子-表面和离子-水相互作用的平衡高度敏感。

Conclusion: 在多价电解质中，传统的基于双电层的离子选择性图像不再适用，离子-表面强相关效应和电荷反转显著改变传输特性，需谨慎考虑力场参数的影响。

Abstract: Ion transport through charged nanopores is commonly interpreted in terms of electrical double layer structure, leading to the expectation of cation-selective conduction in negatively charged pores. This picture can break down for multivalent electrolytes, where strong ion-urface correlations and charge inversion modify transport behavior. Here, we study NaCl and CaCl$_2$ conduction through negatively charged silica nanopores using atomistic molecular dynamics simulations with scaled-charge ion models. By separating concentration and velocity contributions to the radial particle current density, we connect static adsorption to dynamic perm-selectivity. While NaCl exhibits conventional cation selectivity, CaCl$_2$ shows nearly bulk-like or even anion-favored transport due to Ca$^{2+}$ immobilization near the surface and dominant Cl$^-$ conduction in the pore interior following charge inversion. Although this qualitative mechanism is robust, its detailed manifestation depends sensitively on the balance of ion-surface and ion-water interactions encoded in the force field.

</details>


### [21] [Analytic Nonlinear Theory of Shear Banding in Amorphous Solids](https://arxiv.org/abs/2602.10677)
*Avanish Kumar,Itamar Procaccia*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一种非晶固体在无热准静态剪切下的剪切带不稳定性解析理论，通过推导包含塑性变形影响的位移场非线性方程，揭示了剪切带形成的机制，并给出了位移场的解析表达式和临界应力的预测。


<details>
  <summary>Details</summary>
Motivation: 旨在建立一个能够解释非晶固体在剪切作用下出现剪切带不稳定的解析理论，弥补传统弹性理论在描述此类现象时的不足。

Method: 推导了包含塑性变形影响的非线性位移场方程，考虑了塑性事件引起的分布偶极子及其屏蔽效应，并通过求解弱非线性振幅方程分析剪切带的形成；构建了能量泛函并分析其Hessian矩阵的特征值行为。

Result: 发现了导致剪切带形成的非线性不稳定性，得到了与剪切带相关的位移场解析表达式，揭示了弹性模量对剪切带宽度及材料脆韧性的影响，并预测了失稳发生的临界应力值。

Conclusion: 所提出的非线性弹性理论能够有效解释非晶固体中剪切带的形成机制，为理解剪切带宽和材料力学响应提供了理论基础。

Abstract: The aim of this paper is to offer an analytic theory of the shear banding instability in amorphous solids that are subjected to athermal quasi-static shear. To this aim we derive nonlinear equations for the displacement field, including the consequences of plastic deformation on the mechanical response of amorphous solids. The plastic events collectively induce distributed dipoles that are responsible for screening effects and the creation of typical length-scales that are absent in classical elasticity theory. The nonlinear theory exposes an instability that results in the creation of shear bands. By solving the weakly nonlinear amplitude equation we present analytic expressions for the displacement fields that is associated with shear bands, explaining the role of the elastic moduli that determine the width of a shear band from ductile to brittle characteristics. We derive an energy functional whose Hessian possesses an eigenvalue that goes to zero at the shear-banding instability, providing a prediction for the critical value of the accumulated stress that results in an instability.

</details>


### [22] [A statistical theory of structure in many-particle systems with local interactions](https://arxiv.org/abs/2602.10779)
*John Çamkıran,Fabian Parsch,Glenn D. Hibbard*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种针对多粒子系统的结构理论，通过局部描述的随机场精确确定其在热力学平衡下的结构，并引入角冗余度作为局部有序性的量化指标。


<details>
  <summary>Details</summary>
Motivation: 为了理解具有稳定局部相互作用的经典粒子系统在热力学平衡状态下的结构形成机制，特别是局部有序性如何影响整体结构特性。

Method: 利用细粒度和粗粒度的局部描述随机场来建模系统结构，通过构型熵的微观表达分析局部团簇的有序程度，并定义一个基于邻近粒子位置角冗余的局部有序度量。

Result: 发现角冗余度可作为有效的局部有序量化指标，并建立了其与对称性的精确关系；给出了高配位粒子在键角分布广泛情况下的该量的闭式边缘分布。

Conclusion: 局部有序性是决定多粒子系统宏观结构的关键因素，所提出的局部序参数能有效刻画从气体、晶体到液体等不同相态的结构特征。

Abstract: A theory of structure is formulated for systems of many structureless classical particles with stable local interactions in Euclidean space. Such systems are shown to have their structure in thermodynamic equilibrium determined exactly by a random field of fine local descriptions and approximately by coarsenings thereof. The degree of order in the local cluster consisting of a particle and its neighbors is identified as a universal source of coarse local descriptions and characterized by expressing the behavior of configurational entropy in local microscopic terms. A local measure of the angular redundancy in neighboring particle positions is found to satisfy this characterization and thereby established as a valid local order quantifier. A precise relationship between order and symmetry is obtained by bounding this quantifier sharply from below by a simple function of the local point group and the largest stabilizer under its action on the set of bond pairs. The marginal distribution of the quantifier is given in closed form for highly coordinated particles with broadly distributed bond angles. Applications are made to the ideal gas, perfect crystal, and simple liquid.

</details>


### [23] [Stochastic synthesis-degradation processes: first-passage properties and connections with resetting](https://arxiv.org/abs/2602.11095)
*Gabriel Mercado-Vásquez,Denis Boyer*

Main category: cond-mat.stat-mech

TL;DR: 该论文研究了在合成与降解速率恒定的随机合成-降解（SSD）过程中，粒子在空间中任意扩散情况下的首次通过性质，利用重置过程理论揭示了在等速率下可最小化平均反应时间，并推导出CV判据和考虑合成成本时的最优合成率。


<details>
  <summary>Details</summary>
Motivation: 理解生物系统中广泛存在的随机合成与降解过程的动力学机制，尤其是在搜索目标位点时的时间优化问题。

Method: 采用来自重置过程理论的方法，分析具有恒定合成与降解速率的独立粒子在任意扩散过程中的首达时间统计特性。

Result: 在合成与降解速率相等时，平均反应时间可被最小化，并得出一个CV判据；当固定降解率并考虑合成代价时，存在最优合成率；在有界域中，若合成率超过临界值，SSD能改善平均搜索时间，且该临界值满足普适关系。

Conclusion: 随机合成与降解过程可通过调节合成率实现搜索效率的优化，且存在普适的优化准则，为理解生物分子搜索机制提供了新视角。

Abstract: Processes controlled by stochastic synthesis and degradation (SSD) are widespread in biology but their reaction kinetics are not well understood. Using methods borrowed from the theory of resetting processes, we determine the first-passage properties of a collection of independent particles that are synthesized and degraded at constant rates, and follow an arbitrary diffusive process in space. At equal synthesis and degradation rates, the mean reaction time with a target site can be minimized as in stochastic resetting, and a $CV$-criterion is derived. When the degradation rate is held fixed and the synthesis costs are taken into account, an optimal synthesis rate is obtained. In bounded domains, despite particle degradation, SSD improves the mean search time compared to a single non-degrading particle if the synthesis rate exceeds a critical value. The latter obeys a universal relation. We illustrate these findings with Brownian diffusion on the infinite line and in an interval.

</details>


### [24] [Data-Efficient Multidimensional Free Energy Estimation via Physics-Informed Score Learning](https://arxiv.org/abs/2602.11098)
*Daniel Nagel,Tristan Bereau*

Main category: cond-mat.stat-mech

TL;DR: 本文扩展了Fokker-Planck Score Learning (FPSL) 方法，用于从非平衡分子动力学模拟中高效重构二维自由能景观，并展示了其在多尺度系统中的有效性与数据效率。


<details>
  <summary>Details</summary>
Motivation: 许多生物过程涉及多个耦合的自由度，但自由能估计常受限于一维轮廓以降低计算成本。因此需要一种高效且可扩展的多维自由能估算方法。

Method: 扩展Fokker-Planck Score Learning (FPSL)，利用不同类型的集体变量，通过学习平滑的得分函数而非基于直方图的密度来重建二维自由能面，并引入对称性利用和正则化技术提升精度与数值稳定性。

Result: 在丙氨酸二肽构象动力学及粗粒化/全原子脂质双层渗透模型上验证了该方法的有效性；结果显示FPSL能揭示一维投影中隐藏的动力学特征，克服网格方法的指数缩放问题，在稀疏采样区域仍保持鲁棒性。

Conclusion: FPSL是一种数据高效、可扩展的工具，适用于多维自由能估计，在处理复杂生物系统时具有显著优势。

Abstract: Many biological processes involve numerous coupled degrees of freedom, yet free-energy estimation is often restricted to one-dimensional profiles to mitigate the high computational cost of multidimensional sampling. In this work, we extend Fokker--Planck Score Learning (FPSL) to efficiently reconstruct two-dimensional free-energy landscapes from non-equilibrium molecular dynamics simulations using different types of collective variables. We show that explicitly modeling orthogonal degrees of freedom reveals insights hidden in one-dimensional projections at negligible computational overhead. Additionally, exploiting symmetries in the underlying landscape enhances reconstruction accuracy, while regularization techniques ensure numerical robustness in sparsely sampled regions. We validate our approach on three distinct systems: the conformational dynamics of alanine dipeptide, as well as coarse-grained and all-atom models of solute permeation through lipid bilayers. We demonstrate that, because FPSL learns a smooth score function rather than histogram-based densities, it overcomes the exponential scaling of grid-based methods, establishing it as a data-efficient and scalable tool for multidimensional free-energy estimation.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [25] [Normal cones to sublevel sets of convex and quasi-convex supremum functions](https://arxiv.org/abs/2602.10342)
*Stephanie Caro,Rafael Correa,Abderrahim Hantoute*

Main category: math.OC

TL;DR: 本文研究了任意函数上确界次水平集的法锥的精确表征，并将其应用于无穷维凸与拟凸优化问题的最优性条件推导。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解并处理涉及上确界函数的优化问题，需要对次水平集的法锥进行精确描述。

Method: 利用数据函数的次微分（在凸情形下为近似次微分，在拟凸情形下为Fréchet次微分）来表达法锥。

Result: 得到了仅用数据函数次微分表示的法锥显式公式，并成功应用于无穷维优化问题的最优性条件推导。

Conclusion: 所提出的方法能够有效刻画上确界函数次水平集的法锥，为无限维优化问题提供了新的理论工具。

Abstract: We provide sharp and explicit characterizations of the normal cone to sublevel sets of suprema of arbitrary functions, expressed exclusively in terms of subdifferentials of the data functions. In the convex case, the resulting formulas involve the approximate subdifferential of the individual data functions at the nominal point. In contrast, the quasi-convex framework requires the use of the Fréchet subdifferential of these data functions but evaluated at nearby points. These results are applied to derive optimality conditions for infinite convex and quasi-convex optimization problems.

</details>


### [26] [Relationships between full-space and subspace quadratic interpolation models and simplex derivatives](https://arxiv.org/abs/2602.10374)
*Yiwen Chen*

Main category: math.OC

TL;DR: 本文研究了全空间与子空间中二次插值模型和单纯形导数之间的关系，推导出多种模型在不同空间下的转换公式，表明这些模型在特定子空间及其正交补方向上具有一致性，为无导数优化中的子空间近似技术提供了理论框架。


<details>
  <summary>Details</summary>
Motivation: 为了理解高维无导数优化中子空间方法的有效性，需要建立全空间与子空间模型之间的理论联系，以支持更高效的算法设计。

Method: 通过在适当选择的仿射子空间中构建模型，推导全空间与子空间之间关于最小范数、最小Frobenius范数、最小二乘更新以及基于广义单纯形梯度和Hessian的模型的显式转换公式。

Result: 建立了多种二次插值模型和单纯形导数在全空间与子空间之间的等价关系，证明了它们在仿射子空间及正交补方向上的一致性。

Conclusion: 结果为子空间近似方法提供了统一的理论基础，有助于理解和改进高维无导数优化算法的设计与分析。

Abstract: Quadratic interpolation models and simplex derivatives are fundamental tools in numerical optimization, particularly in derivative-free optimization. When constructed in suitably chosen affine subspaces, these tools have been shown to be especially effective for high-dimensional derivative-free optimization problems, where full-space model construction is often impractical. In this paper, we analyze the relationships between full-space and subspace formulations of these tools. In particular, we derive explicit conversion formulas between full-space and subspace models, including minimum-norm models, minimum Frobenius norm models, least Frobenius norm updating models, as well as models constructed via generalized simplex gradients and Hessians. We show that the full-space and subspace models coincide on the affine subspace and, in general, along directions in the orthogonal complement. Overall, our results provide a theoretical framework for understanding subspace approximation techniques and offer insight into the design and analysis of derivative-free optimization methods.

</details>


### [27] [Active set identification and rapid convergence for degenerate primal-dual problems](https://arxiv.org/abs/2602.10436)
*Mateo Díaz,Pedro Izquierdo Lehmann,Haihao Lu,Jinwen Yang*

Main category: math.OC

TL;DR: 本文研究了求解带函数约束的凸优化问题的原始-对偶方法中的两阶段行为，提出了在不依赖严格互补性条件下可证明的非渐近性主动集识别理论，并适用于多种常用算法。


<details>
  <summary>Details</summary>
Motivation: 现有理论大多依赖于严格互补性等非退化条件，但在实际中这些条件往往不成立，因此需要更温和的条件来保证主动集的识别。

Method: 通过分析问题几何结构和算法特性，提出了一套不依赖严格互补性的非渐近分析框架，用于刻画原始-对偶方法中主动集的识别过程。

Result: 证明了在较温和的条件下，多种常用算法（如近端点法、原始-对偶混合梯度法、交替方向乘子法和外梯度法）均可实现主动集的非渐近识别。

Conclusion: 所提出的方法为理解原始-对偶算法的两阶段收敛行为提供了新的理论支持，且适用范围更广，不依赖于严格的非退化假设。

Abstract: Primal-dual methods for solving convex optimization problems with functional constraints often exhibit a distinct two-stage behavior. Initially, they converge towards a solution at a sublinear rate. Then, after a certain point, the method identifies the set of active constraints and the convergence enters a faster local linear regime. Theory characterizing this phenomenon spans over three decades. However, most existing work only guarantees eventual identification of the active set and relies heavily on nondegeneracy conditions, such as strict complementarity, which often fail to hold in practice. We characterize mild conditions on the problem geometry and the algorithm under which this phenomenon provably occurs. Our guarantees are entirely nonasymptotic and, importantly, do not rely on strict complementarity. Our framework encompasses several widely-used algorithms, including the proximal point method, the primal-dual hybrid gradient method, the alternating direction method of multipliers, and the extragradient method.

</details>


### [28] [Revisiting Superlinear Convergence of Proximal Newton-Like Methods to Degenerate Solutions](https://arxiv.org/abs/2602.10470)
*Ching-pei Lee,Stephen J. Wright*

Main category: math.OC

TL;DR: 本文提出了一种不精确的近似牛顿类方法，用于求解退化的正则化优化问题及更广泛的广义方程零点问题，在满足Hölder型误差界条件下可实现超线性收敛，即使雅可比矩阵在解处奇异且非Lipschitz连续。对于凸正则化优化问题，还引入了一种新的全局化策略，确保目标函数严格递减并避免Maratos效应，无需先验参数即可达到局部Q-超线性收敛。


<details>
  <summary>Details</summary>
Motivation: 传统牛顿法通常要求雅可比矩阵满足Lipschitz连续性等较强假设，难以应用于雅可比奇异或非光滑的问题。本文旨在放宽这些限制，扩展牛顿类方法的适用范围，特别是在退化和非Lipschitz情形下仍能保证超线性收敛。

Method: 采用不精确的近似牛顿框架，结合Hölder型误差界条件分析收敛性；针对凸正则化问题设计新的全局化策略，通过线搜索确保单位步长接受和目标函数严格下降，同时避免Maratos效应。

Result: 在较弱的假设下（如雅可比仅需一致连续）实现了到解集距离和一阶最优性度量的超线性收敛；提出的全局化策略无需先验参数即可达到局部Q-超线性收敛，并兼容多种可能产生超线性收敛更新的候选方法。

Conclusion: 所提方法显著放宽了传统牛顿法对导数正则性的要求，扩展了其在退化、非Lipschitz甚至Hessian不存在情况下的适用性，为求解复杂正则化优化问题提供了更强健高效的算法框架。

Abstract: We describe inexact proximal Newton-like methods for solving degenerate regularized optimization problems and for the broader problem of
  finding a zero of a generalized equation that is the sum of a continuous map and a maximal monotone operator. Superlinear convergence for both the distance to the solution set and a certain measure of first-order optimality can be achieved under a Hölderian error bound condition, including for problems in which the continuous map is nonmonotone, with Jacobian singular at the solution and not Lipschitz. Superlinear convergence is attainable even when the Jacobian is merely uniformly continuous, relaxing the standard Lipschitz assumption to its theoretical limit. For convex regularized optimization problems, we introduce a novel globalization strategy that ensures strict objective decrease and avoids the Maratos effect, attaining local $Q$-superlinear convergence without prior knowledge of problem parameters. Unit step size acceptance in our line search strategy does not rely on continuity or even existence of the Hessian of the smooth term in the objective, making the framework compatible with other potential candidates for superlinearly convergent updates.

</details>


### [29] [Almost Sure Convergence of Nonlinear Stochastic Approximation: An Interplay of Noise and Step Size](https://arxiv.org/abs/2602.10580)
*Quang Dinh Thien Nguyen,Duc Anh Nguyen,Hoang Huy Nguyen,Siva Theja Maguluri*

Main category: math.OC

TL;DR: 本文研究了在具有有限p阶矩（p>1）的一般噪声序列下，随机逼近算法几乎必然收敛于非线性算子不动点的问题。通过引入通用的Lyapunov漂移分析方法，证明了任何非可和但p次方可和的步长序列足以保证几乎必然收敛，推广了经典结果。


<details>
  <summary>Details</summary>
Motivation: 经典随机逼近的几乎必然收敛结果主要针对平方可积噪声情形，限制了在重尾噪声（如机器学习和运筹学中常见）下的应用。本文旨在消除这一局限，建立更一般的收敛理论。

Method: 采用基于Lyapunov函数的方法：当p∈(1,2)时，使用||x−x⋆||^p作为Lyapunov函数并结合类泰勒展开估计；当p>2时，引入新的迭代投影技术以控制高阶矩和乘性噪声带来的非线性项。

Result: 证明了在p阶矩有界噪声下，只要步长序列非可和但p次方可和，即可保证几乎必然收敛。填补了现有理论在一般噪声条件下的空白。

Conclusion: 本文扩展了随机逼近算法的收敛性理论，适用于更广泛的噪声环境，尤其为重尾噪声场景提供了理论支持，并提出了可用于未来有限时间分析的新技术路径。

Abstract: We study the almost sure convergence of the Stochastic Approximation algorithm to the fixed point $x^\star$ of a nonlinear operator under a negative drift condition and a general noise sequence with finite $p$-th moment for some $p > 1$. Classical almost sure convergence results of Stochastic Approximation are mostly analyzed for the square-integrable noise setting, and it is shown that any non-summable but square-summable step size sequence is sufficient to obtain almost sure convergence. However, such a limitation prevents wider algorithmic application. In particular, many applications in Machine Learning and Operations Research admit heavy-tailed noise with infinite variance, rendering such guarantees inapplicable. On the other hand, when a stronger condition on the noise is available, such guarantees on the step size would be too conservative, as practitioners would like to pick a larger step size for a more preferable convergence behavior. To this end, we show that any non-summable but $p$-th power summable step size sequence is sufficient to guarantee almost sure convergence, covering the gap in the literature.
  Our guarantees are obtained using a universal Lyapunov drift argument. For the regime $p \in (1, 2)$, we show that using the Lyapunov function $\norm{x-x^\star}^p$ and applying a Taylor-like bound suffice. For $p > 2$, such an approach is no longer applicable, and therefore, we introduce a novel iterate projection technique to control the nonlinear terms produced by high-moment bounds and multiplicative noise. We believe our proof techniques and their implications could be of independent interest and pave the way for finite-time analysis of Stochastic Approximation under a general noise condition.

</details>


### [30] [Fast and Large-Scale Unbalanced Optimal Transport via its Semi-Dual and Adaptive Gradient Methods](https://arxiv.org/abs/2602.10697)
*Ferdinand Genans*

Main category: math.OC

TL;DR: 本文研究了非平衡最优传输（UOT）的半对偶形式，揭示其局部条件数优于传统分析结果，并基于此提出适用于随机和全批量场景的高效梯度算法，提升了大规模UOT问题的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 尽管非平衡最优传输（UOT）在处理异常值和质量变化方面表现出色，但基于梯度下降的大规模算法仍缺乏深入研究，尤其是半对偶形式在非平衡情形下的几何性质被普遍认为病态严重，限制了高效算法的设计。

Method: 通过分析熵正则化UOT的半对偶公式，揭示其局部条件数实际为O(1/ε)，远优于传统O(n/ε)的估计；在此基础上，证明随机梯度下降（SGD）能自适应局部曲率，并针对全批量情形设计基于局部光滑性的自适应Nesterov加速梯度（ANAG）方法。

Result: SGD在随机和在线设定下达到O(n/εT)的收敛速率；提出的ANAG方法在全批量离散情形下实现O(n²√(1/ε) ln(1/δ))的局部复杂度，接近紧上界。

Conclusion: UOT半对偶问题的实际几何结构比传统分析更优，利用局部条件数可设计出高效、可扩展的梯度类算法，显著提升大规模UOT求解性能。

Abstract: Unbalanced Optimal Transport (UOT) has emerged as a robust relaxation of standard Optimal Transport, particularly effective for handling outliers and mass variations. However, scalable algorithms for UOT, specifically those based on Gradient Descent (SGD), remain largely underexplored. In this work, we address this gap by analyzing the semi-dual formulation of Entropic UOT and demonstrating its suitability for adaptive gradient methods. While the semi-dual is a standard tool for large-scale balanced OT, its geometry in the unbalanced setting appears ill-conditioned under standard analysis. Specifically, worst-case bounds on the marginal penalties using $χ^2$ divergence suggest a condition number scaling with $n/\varepsilon$, implying poor scalability. In contrast, we show that the local condition number actually scales as $\mathcal{O}(1/\varepsilon)$, effectively removing the ill-conditioned dependence on $n$. Exploiting this property, we prove that SGD methods adapt to this local curvature, achieving a convergence rate of $\mathcal{O}(n/\varepsilon T)$ in the stochastic and online regimes, making it suitable for large-scale and semi-discrete applications. Finally, for the full batch discrete setting, we derive a nearly tight upper bound on local smoothness depending solely on the gradient. Using it to adapt step sizes, we propose a modified Adaptive Nesterov Accelerated Gradient (ANAG) method on the semi-dual functional and prove that it achieves a local complexity of $\mathcal{O}(n^2\sqrt{1/\varepsilon}\ln(1/δ))$.

</details>


### [31] [Mirror descent actor-critic methods for entropy regularised MDPs in general spaces: stability and convergence](https://arxiv.org/abs/2602.10838)
*Denis Zorba,David Šiška,Lukasz Szpruch*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We provide theoretical guarantees for convergence of discrete-time policy mirror descent with inexact advantage functions updated using temporal difference (TD) learning for entropy regularised MDPs in Polish state and action spaces. We rigorously derive sufficient conditions under which the single-loop actor-critic scheme is stable and convergent. To weaken these conditions, we introduce a variant that performs multiple TD steps per policy update and derive an explicit lower bound on the number of TD steps required to ensure stability. Finally, we establish sub-linear convergence when the number of TD steps grows logarithmically with the number of policy updates, and linear convergence when it grows linearly under a concentrability assumption.

</details>


### [32] [Managing delay in tail assignment: from minimum turn time to stochastic routing at Air France](https://arxiv.org/abs/2602.10866)
*Léo Baty,Axel Parmentier*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: On-time performance is a critical challenge in the airline industry, leading to large operational and customer dissatisfaction costs. The tail assignment problem builds the sequences of flights or routes followed by individual airplanes. While airlines cannot avoid some sources of delay, choosing routes wisely limits propagation along these. This paper addresses the stochastic tail assignment problem at Air France. We propose a column generation approach for this problem. The key ingredient is the pricing algorithm, which is a stochastic shortest path problem. We use dedicated bounds to discard paths in an enumeration algorithm, and introduce new bounds based on a lattice ordering of the set of piecewise linear convex functions to strike a balance between bounds quality and computational cost. A diving heuristic enables us to retrieve integer solutions. Numerical experiments on real-world Air France instances demonstrate that our algorithms lead to an average 0.28% optimality gap on instances with up to 600 flight legs in a few hours of computing time. The resulting solutions effectively balance operational costs and delay resilience, outperforming previous approaches based on minimum turn time.

</details>


### [33] [Data assimilation via model reference adaptation for linear and nonlinear dynamical systems](https://arxiv.org/abs/2602.10920)
*Benedikt Kaltenbach,Christian Aarset,Tram Thi Ngoc Nguyen*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We address data assimilation for linear and nonlinear dynamical systems via the so-called \emph{model reference adaptive system}. Continuing our theoretical developments in \cite{Tram_Kaltenbacher_2021}, we deliver the first practical implementation of this approach for online parameter identification with time series data. Our semi-implicit scheme couples a modified state equation with a parameter evolution law that is driven by model-data residuals. We demonstrate four benchmark problems of increasing complexity: the Darcy flow, the Fisher-KPP equation, a nonlinear potential equation and finally, an Allen-Cahn type equation. Across all cases, explicit model reference adaptive system construction, verified assumptions and numerically stable reconstructions underline our proposed method as a reliable, versatile tool for data assimilation and real-time inversion.

</details>


### [34] [Adversarial Graph Traversal](https://arxiv.org/abs/2602.11048)
*David Banks,Elvan Ceyhan,Leah Johnson,Li Zhou*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Suppose a Bayesian agent seeks to traverse a graph. Each time she crosses an edge, she pays a price. The first time she reaches a node, there is a payoff. She has an opponent who can reduce the payoffs. This paper uses adversarial risk analysis to find a solution to her route selection problem. It shows how the traveler is advantaged by having an accurate subjective distribution over the costs/payoffs and by having a Bayesian prior for her opponent's strategic choices. The results are relevant to military convoy routing, corporate competition, and certain games.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [35] [Investigation on the inclination angle of undrained shear slip surface in saturated soils based on mixture theory](https://arxiv.org/abs/2602.10128)
*Hu Yayuan,Zhou Jian*

Main category: physics.geo-ph

TL;DR: 本文基于混合物理论分析饱和土中不排水剪切滑动面的倾角，揭示了有效应力原理的力学机制，并结合莫尔-库仑强度理论探讨了饱和土中滑动面倾角在不同渗透性条件下的变化规律。


<details>
  <summary>Details</summary>
Motivation: 明确饱和土中不排水剪切滑动面倾角的确定方法及其与渗透性的关系，揭示有效应力原理在非平衡热力学框架下的物理本质。

Method: 基于混合物理论和能量守恒方程，结合非平衡热力学与状态变量分析，研究饱和土中固-液相互作用及固体组分的平衡方程，并在两种极端渗透条件下（渗透系数为零和无穷大）结合莫尔-库仑强度理论进行分析。

Result: 当渗透系数为无穷大时建议采用非耦合水力-力学分析，滑动面倾角为某特定值；当渗透系数为零时应采用完全耦合分析，滑动面倾角为另一特定值；实际饱和土需根据具体情况分析。

Conclusion: 饱和土中滑动面的倾角取决于渗透性条件，其分析方法应在耦合与非耦合水力-力学模型之间根据实际情况选择。

Abstract: The inclination angle of the undrained shear slip surface in saturated soils is analyzed based on mixture theory. First, starting from the property that the bulk strain of soil skeleton is equal to the flow ratio of water discharged from soil skeleton, the energy conservation equation of saturated soil is obtained. According to state variables of energy equation and non-equilibrium thermodynamics, the mechanical mechanism underlying effective stress principle is revealed that Gibbs free energy of saturated soil is only expressed as a function of effective stress under isothermal process. Consequently, the deformation and strength of saturated soil are uniquely determined by the effective stress and not directly related to Newton's equilibrium equations, which governs the movements of solid-fluid two-phase components. The instability of soil skeleton is related to the applied forces and requires analysis based on the Newtonian equilibrium condition. The interaction between the solid-water components and the equilibrium equation of solid component are investigated under two working conditions: when permeability tensor equals zero and when it equals infinity. Combined with the Mohr-Coulomb strength theory, the inclination angle of the undrained shear slip surface is explored under Rankine's passive earth pressure in saturated soil. The results indicate that, when the permeability equals infinity, the uncoupled hydro-mechanical analysis is recommended, and the inclination angle of slip surface is ; when the permeability equals zero, the fully coupled hydro-mechanical analysis is recommended, and the inclination angle of slip surface is . The permeability of actual saturated soil falls between the two extremes, the inclination angle of slip surface must be analyzed on a case-by-case basis.

</details>


### [36] [Field-Deployable Hybrid Gravimetry: Projecting Absolute Accuracy Across a Remote 24km$^2$ Survey via Daily Quantum Calibration](https://arxiv.org/abs/2602.10557)
*Nathan Shettell,Kai Sheng Lee,Fong En Oon,Elizaveta Maksimova,Hong Hui Chen,Rainer Dumke*

Main category: physics.geo-ph

TL;DR: 提出了一种量子增强的混合重力测量方法，利用原子重力仪对移动弹簧重力仪进行现场校准，实现了高精度、低漂移的区域重力梯度测量。


<details>
  <summary>Details</summary>
Motivation: 解决传统绝对重力仪体积大、部署困难，而相对重力仪存在时间漂移的问题，提升野外复杂环境下重力测量的精度和实用性。

Method: 在24平方公里的热带密林地区开展实地测量，使用现场原子重力仪定期对两个移动弹簧重力仪进行微伽级校准，并实现异步数据交叉比对。

Result: 有效抑制了仪器漂移，实现了高保真度的区域重力梯度观测，验证了量子传感器在野外环境下的实用性和可扩展性。

Conclusion: 场用型量子传感器可作为大范围、高精度地球物理勘测的可扩展校准骨干，推动量子级重力测量从实验室走向实际应用。

Abstract: Absolute gravimeters deliver drift-free, high-precision measurements but are typically bulky and difficult to deploy, whereas relative gravimeters are lightweight and mobile but intrinsically limited by time-dependent drift. We demonstrate a hybrid quantum-enabled gravimetry approach in which an on-site atomic gravimeter provides routine, $μ$Gal-level calibration of two mobile spring gravimeters during a field survey spanning 24 km$^2$ of dense tropical terrain. The atomic reference enables high-precision, asynchronous cross-comparison of relative measurements acquired over seven days, effectively suppressing instrumental drift to a level required for demanding geophysical applications. This deployment captures regional gravity gradients with high fidelity under challenging environmental conditions, illustrating how field-operable quantum sensors can extend quantum-grade gravimetry beyond laboratory settings and serve as scalable calibration backbones for large-area, high-precision geophysical surveys in remote or logistically constrained environments.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [37] [Discretization-free Bayesian inverse problems in distribution spaces](https://arxiv.org/abs/2602.10247)
*Daniela Calvetti,Erkki Somersalo*

Main category: math.NA

TL;DR: 本文旨在弥合线性逆问题在分布空间中的无限维理论与相关计算逆问题之间的差距，提出无需对未知量进行离散化即可进行数值处理的方法，仅需独立于未知量离散表示的数值积分近似。


<details>
  <summary>Details</summary>
Motivation: 由于贝叶斯方法具有测度论基础，在无限维函数空间中已有较完整的理论描述，但如何将其与实际计算问题有效结合仍具挑战，因此需要一种不依赖于前向模型离散逼近的方法。

Method: 通过假设条件下的分析，证明对未知量的离散化并非必要，仅需使用与未知量离散表示无关的数值积分方法来实现问题的数值求解，并探讨了该方法与基于离散化方法之间的联系。

Result: 表明在特定假设下，可以不对未知量进行离散化，仅依靠数值积分即可实现逆问题的数值处理，且提供了与传统离散化方法的比较分析。

Conclusion: 所提方法为贝叶斯逆问题提供了一种避免未知量离散化的有效数值途径，有助于连接无限维理论与实际计算应用。

Abstract: The Bayesian approach to inverse problems provides a practical way to solve ill-posed problems by augmenting the observation model with prior information. Due to the measure-theoretic underpinnings, the approach has raised theoretical interest, leading to a rather comprehensive description in infinite-dimensional function spaces. The goal of this article is to bridge the infinite-dimensional theory for linear inverse problems in distribution spaces and associated computational inverse problems without resorting to a discrete approximation of the forward model. We will shown that under certain assumptions, discretization of the unknown of interest is not necessary for the numerical treatment of the problem, the only approximations required being numerical quadratures that are independent of any discrete representation of the unknown. An analysis of the connection between the proposed approach and discretization-based ones is also provided.

</details>


### [38] [Unconditionally Long-Time Stable Variable-Step Second-Order Exponential Time-Differencing Schemes for the Incompressible NSE](https://arxiv.org/abs/2602.10268)
*Haifeng Wang,Xiaoming Wang,Min Zhang*

Main category: math.NA

TL;DR: 提出了一种高效、无条件稳定的变步长二阶指数时间差分格式，用于求解周期边界条件下不可压缩Navier-Stokes方程，并设计了嵌入式自适应时间步长策略，具有二阶时间精度和长时间稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如经典Runge-Kutta缺乏可证明的长时间稳定性，IMEX和基于SAV的BDF方法在变步长情况下通常无法保证无条件稳定，因此需要一种兼具高精度与稳定性的新方法。

Method: 采用指数时间差分框架，结合动态二阶标量辅助变量校正和均值回归型多步SAV公式，每步求解两个含周期边界的时变Stokes问题（可通过傅里叶法显式计算）和一个标量三次代数方程。

Result: 数值实验验证了二阶时间精度、均匀的长时间稳定性和自适应策略的有效误差控制；该方法在任意雷诺数和时间步长选择下均保持无条件时间一致稳定。

Conclusion: 所提方法克服了现有Navier-Stokes求解器在变步长下的稳定性与精度局限，为长时间模拟提供了可靠且高效的数值工具。

Abstract: We develop an efficient, unconditionally stable, variable step second order exponential time differencing scheme for the incompressible Navier Stokes equations in two and three spatial dimensions under periodic boundary conditions, together with an embedded adaptive time stepping variant. The scheme is unconditionally uniform in time stable in the sense that the numerical solution admits a time uniform bound in Linfinity over time with values in L2 to the power d whenever the external forcing term is uniformly bounded in time in L2, for all Reynolds numbers and for arbitrary choices of time step sizes.
  At each time step, the method requires the solution of two time dependent Stokes problems, which can be evaluated explicitly in the periodic setting using Fourier techniques, along with the solution of a single scalar cubic algebraic equation. Beyond the standard exponential time differencing framework, the proposed scheme incorporates two recently developed ingredients. The first is a dynamic second order scalar auxiliary variable correction, which is essential for achieving second order temporal accuracy. The second is a mean reverting scalar auxiliary variable multistep formulation, which plays a central role in ensuring long time stability.
  The proposed methods overcome key limitations of existing approaches for the Navier Stokes equations. Classical Runge Kutta schemes generally lack provable long time stability, while IMEX and scalar auxiliary variable based BDF methods typically do not admit unconditional stability guarantees in the variable step setting. Numerical experiments in two spatial dimensions confirm second order temporal accuracy, uniform long time stability, and effective error control provided by the adaptive strategy. Rigorous convergence analysis and a systematic investigation of long time statistical properties will be pursued in future work.

</details>


### [39] [Blind source separation for imaging](https://arxiv.org/abs/2602.10277)
*Randy Bartels,Olivier Pinaud*

Main category: math.NA

TL;DR: 本文研究了盲源分离问题及其在成像中的应用，推广了现有可分性准则至任意相关的复值信号，并在两种成像传播条件下验证了该理论，提出了一种优于传统时间反演算子分解方法的新成像方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决扩散环境中的成像问题，需要扩展现有的盲源分离准则以适应更广泛的信号类型，包括任意相关的复值信号和加性噪声。

Method: 通过理论推导将已有可分性准则推广到更一般的情形，并在散斑和随机几何光学两种典型成像传播机制下验证这些条件，进而提出基于盲源分离的新成像方法。

Result: 成功建立了适用于任意相关复值源的可分性准则，在两种典型成像环境下验证了其有效性，并开发出一种性能优于传统时间反演算子分解法的新型成像技术。

Conclusion: 所提出的盲源分离框架能够有效提升复杂环境下的成像质量，为扩散介质中的高分辨率成像提供了新的理论与方法支持。

Abstract: This work is concerned with the problem of blind source separation and its applications to imaging. We first establish a theoretical result that we stated in our previous article on imaging in diffusive environments. This result is a generalization of separability criteria found in the literature to arbitrary correlated complex-valued sources with additive noise. In a second step, we verify these separability conditions in two propagation regimes frequently encountered in imaging: the speckle regime and the random geometrical optics regime. Finally, we propose a new imaging method based on the blind source separation problem that improves on images obtained with the classical decomposition of the time reversal operator method.

</details>


### [40] [Impact of Separation Distance on the Performance and Annual Energy Production of a Dual-Flap Oscillating Surge Wave Energy Converter](https://arxiv.org/abs/2602.10301)
*Alaa Ahmed*

Main category: math.NA

TL;DR: 研究了双襟翼振荡涌浪波能转换器之间间距对其性能的影响，发现间距对年发电量影响不大。


<details>
  <summary>Details</summary>
Motivation: 探究双襟翼振荡涌浪波能转换器在不同间距下的相互作用及其对能量捕获效率的影响。

Method: 采用无粘数值模拟预测波能转换器的响应，并通过1:10缩尺模型的实验测量验证模拟结果。

Result: 短间距时，波频依赖的破坏性和建设性效应相互抵消；长间距时始终为建设性效应；总体上间距对年发电量影响不显著。

Conclusion: 分离距离对双襟翼振荡涌浪波能转换器的年度能源生产影响较小，设计时无需过度优化间距。

Abstract: Among the different concepts for wave energy conversion, oscillating surge wave energy converters have been shown to have a high capture width ratio. The primary wave capture structure consists of a flap hinged at the seabed or to a floating platform. Different flap configurations, including single and dual-flap, have been investigated. The separation distance between the oscillating surge wave energy converters can have an impact on their response when deployed in arrays. We consider the case of a dual-flap oscillating surge wave energy converter and investigate the impact of the separation distance between them on the performance of each flap. We estimate the absorbed wave energy and the annual energy production by the two flaps when deployed at the PacWave South site. Inviscid numerical simulations were conducted to predict the response of the oscillating surge wave energy converters. The simulations are validated with experimental measurements of a 1:10 scaled model in a wave tank. The results show that for a short separation distance, the interaction between the oscillating surge wave energy converters has a destructive and constructive effect depending on the wave frequency. However, these effects tend to balance each other out when considering the broad range of wave excitations. For longer separation distances, the interaction always results in a constructive effect. The results reveal that the separation distance has an insignificant impact on annual energy production when considering all wave frequencies and amplitudes.

</details>


### [41] [A Numerical Analysis of Sketched Linear Squares Problems and Stopping Criteria for Iterative Solvers](https://arxiv.org/abs/2602.10424)
*Zhongxiao Jia,Xinyuan Wan*

Main category: math.NA

TL;DR: 本文研究了随机子空间嵌入方法在求解线性最小二乘问题中的应用，提出了新的理论性质和高效的迭代求解停止准则。


<details>
  <summary>Details</summary>
Motivation: 通过降低最小二乘问题的行维度，利用随机化或草图最小二乘（sLS）问题来近似原问题，提高计算效率。

Method: 建立残差差异范数的紧凑边界，从后向误差角度分析sLS解的性质，并量化嵌入质量对残差、解误差及法方程相对残差范数的影响。

Result: 证明了sLS问题的解是某个扰动最小二乘问题中具有最小后向误差的解，并提出了动态监控迭代求解稳定性的新型停止准则。

Conclusion: 新提出的停止准则可靠且显著减少了计算成本，同时不牺牲可达到的精度。

Abstract: Randomized subspace embedding methods have had a great impact on the solution of a linear least squares (LS) problem by reducing its row dimension, leading to a randomized or sketched LS (sLS) problem, and use the solution of the sLS problem as an approximate solution of the LS problem. This work makes a numerical analysis on the sLS problem, establishes its numerous theoretical properties, and show their crucial roles on the most effective and efficient use of iterative solvers. We first establish a compact bound on the norm of the residual difference between the solutions of the LS and sLS problems, which is the first key result towards understanding the rationale of the sLS problem. Then from the perspective of backward errors, we prove that the solution of the sLS problem is the one of a certain perturbed LS problem with minimal backward error, and quantify how the embedded quality affects the residuals, solution errors, and the relative residual norms of normal equations of the LS and sLS problems. These theoretical results enable us to propose new novel and reliable general-purpose stopping criteria for iterative solvers for the sLS problem, which dynamically monitor stabilization patterns of iterative solvers for the LS problem itself and terminate them at the earliest iteration. Numerical experiments justify the theoretical bounds and demonstrate that the new stopping criteria work reliably and result in a tremendous reduction in computational cost without sacrificing attainable accuracy.

</details>


### [42] [Identifying the source term in a viscoelastic membrane with a Riemann-Liouville time derivative by the partial interior observation](https://arxiv.org/abs/2602.10440)
*Zhiwei Yang,Yikan Liu*

Main category: math.NA

TL;DR: 研究了一种基于黎曼-刘维尔分数阶导数的粘弹性膜反源问题，提出了一种最优控制框架来从有限内部观测数据中恢复未知源项。


<details>
  <summary>Details</summary>
Motivation: 解决具有材料记忆效应的粘弹性膜中的反源问题，这类问题是不适定的且难以直接求解。

Method: 采用最优控制框架，通过一阶最优性条件导出耦合的前向和后向分数阶偏微分方程系统，并结合有限元方法与共轭梯度迭代算法进行数值求解。

Result: 开发了有效的数值算法，多个数值例子验证了该方法在源项重建中的有效性和鲁棒性。

Conclusion: 所提方法能够高效稳定地求解分数阶粘弹性膜的反源问题，适用于有限内观测数据下的实际应用场景。

Abstract: This paper studies an inverse source problem for a viscoelastic membrane, where the material's memory effect is characterized by the Riemann-Liouville fractional derivative. The problem is to recover the unknown source term from the limited interior observation data. We propose an optimal control framework to address this ill-posed inverse problem. The first-order optimality condition leads to a coupled system of forward and backward fractional partial differential equations. A numerical algorithm combining the finite element method and a conjugate gradient iterative scheme is then developed for the reconstruction of the source term. Several numerical examples are provided to demonstrate the effectiveness and robustness of the proposed method.

</details>


### [43] [Solving PDEs in One Shot via Fourier Features with Exact Analytical Derivatives](https://arxiv.org/abs/2602.10541)
*Antonin Sulc*

Main category: math.NA

TL;DR: FastLSQ是一种基于随机傅里叶特征和解析算子组装的高效求解线性和非线性PDE的方法，利用正弦函数的循环导数结构，显著提升精度与速度。


<details>
  <summary>Details</summary>
Motivation: 现有随机特征方法仍依赖迭代优化或高成本导数计算，而如tanh等激活函数的高阶导数复杂度高，限制了效率。希望找到一种可解析高效计算导数的结构以降低计算成本。

Method: 采用冻结的随机傅里叶特征（sinusoidal RFF），利用其任意阶导数仍为单个正弦函数的性质，实现O(1)导数计算；对线性PDE通过一次最小二乘求解（FastLSQ），对非线性PDE结合牛顿-拉夫森迭代，在每步线性化中调用FastLSQ。

Result: 在17个涵盖1至6维的PDE基准测试中，FastLSQ在线性问题上达到10^{-7}量级相对L2误差，仅用0.07秒，比当前PINN方法快且精度高三个数量级；在非线性问题上通过牛顿迭代在9秒内达到10^{-8}至10^{-9}误差。

Conclusion: FastLSQ通过利用正弦特征的解析导数结构，实现了快速、高精度的一次性求解线性和非线性PDE的新方法，显著优于现有PINN和PIELM类方法。

Abstract: Recent random feature methods for solving partial differential equations (PDEs) reduce computational cost compared to physics-informed neural networks (PINNs) but still rely on iterative optimization or expensive derivative computation. We observe that sinusoidal random Fourier features possess a cyclic derivative structure: the derivative of any order of $\sin(\mathbf{W}\cdot\mathbf{x}+b)$ is a single sinusoid with a monomial prefactor, computable in $O(1)$ operations. Alternative activations such as $\tanh$, used in prior one-shot methods like PIELM, lack this property: their higher-order derivatives grow as $O(2^n)$ terms, requiring automatic differentiation for operator assembly. We propose FastLSQ, which combines frozen random Fourier features with analytical operator assembly to solve linear PDEs via a single least-squares call, and extend it to nonlinear PDEs via Newton--Raphson iteration where each linearized step is a FastLSQ solve. On a benchmark of 17 PDEs spanning 1 to 6 dimensions, FastLSQ achieves relative $L^2$ errors of $10^{-7}$ in 0.07\,s on linear problems, three orders of magnitude more accurate and significantly faster than state-of-the-art iterative PINN solvers, and $10^{-8}$ to $10^{-9}$ on nonlinear problems via Newton iteration in under 9s.

</details>


### [44] [An Energy-Stable, Bound-Preserving and Locally Conservative Numerical Framework for Multicomponent Gas Flow in Poroelastic Media](https://arxiv.org/abs/2602.10550)
*Huangxin Chen,Yuxiang Chen,Jisheng Kou,Shuyu Sun*

Main category: math.NA

TL;DR: 提出了一种稳健高效的数值框架，用于模拟多组分气体在孔隙弹性介质中的流动，保持热力学基本原理并确保计算可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决多组分气体在孔隙弹性介质中流动模拟中的质量守恒、能量稳定性和摩尔密度有界性等关键数值挑战。

Method: 开发了稳定的离散化方法，结合自适应时间步长策略，采用混合有限元与迎风格式处理流动和输运方程，使用间断Galerkin方法离散动量方程。

Result: 数值实验表明该方法在不同场景下具有良好的性能、鲁棒性和适用性，能有效保持能量耗散律和各组分摩尔密度的有界性。

Conclusion: 所提方法能够高效、稳定地模拟多组分气体在孔隙弹性介质中的复杂非线性耦合行为。

Abstract: In this paper, we propose a robust and efficient numerical framework for simulating multicomponent gas flow in poroelastic media, with a focus on preserving fundamental thermodynamic principles and ensuring computational reliability. The model captures the complex nonlinear coupling between multicomponent transport and solid deformation, while addressing critical numerical challenges such as mass conservation, energy stability, and molar density boundedness. To achieve this, we develop a stabilized discretization approach that guarantees the preservation of the original energy dissipation law and ensures the boundedness of each gas component's molar density. Furthermore, the proposed method incorporates an adaptive time-stepping strategy that dynamically adjusts the time step size based on the system's dynamics, significantly enhancing computational efficiency without compromising stability or accuracy. For spatial discretization, a mixed finite element method combined with an upwind scheme is employed for the flow and transport equations to ensure local mass conservation, while a discontinuous Galerkin (DG) method is utilized for discretizing the momentum equation of poroelasticity to effectively overcome numerical locking phenomena. Numerical experiments are presented to demonstrate the performance, robustness, and applicability of the method in simulating multicomponent gas flow under various scenarios.

</details>


### [45] [Convergence of a scheme for a two dimensional nonlocal system of transport equations](https://arxiv.org/abs/2602.10590)
*Diana Al Zareef,Ahmad El Hajj,Antoine Zurek*

Main category: math.NA

TL;DR: 本文提出了一种半显式有限差分（IMEX）数值格式，用于求解二维位错密度动力学系统，并通过正则化奇异速度实现了离散解的熵估计和收敛性证明。


<details>
  <summary>Details</summary>
Motivation: 由于该系统的双曲性不严格、速度和初值正则性弱且含有非局部项，现有方法难以处理，因此需要设计新的数值格式以实现稳定求解和理论分析。

Method: 采用Fejér核对奇异速度进行正则化，构造半显式有限差分（IMEX）格式，在离散层面保持梯度的熵估计，并证明了数值解的收敛性。

Result: 所提格式在离散层面上保持了重要的熵估计性质，并首次证明了此类系统数值解的收敛性，数值实验验证了方法的有效性和性能。

Conclusion: 本文提出的IMEX格式结合正则化策略成功解决了非严格双曲、非局部且低正则性位错动力学系统的数值求解难题，提供了首个收敛性结果，具有理论与应用价值。

Abstract: In this paper, we numerically study a two-dimensional system modeling the dynamics of dislocation densities. This system is hyperbolic, but not strictly hyperbolic, and couples two non-local transport equations. It is characterized by weak regularity in both the velocity and the initial data. We propose a semi-explicit finite difference (IMEX) numerical scheme for the discretization of this system, after regularizing the singular velocity using a Fejér kernel. We show that this scheme preserves, at the discrete level, an entropy estimate on the gradient, which then allows us to establish the convergence of the discrete solution to the continuous solution. To our knowledge, this is the first convergence result obtained for this type of system. We conclude with some numerical illustrations highlighting the performance of the proposed scheme.

</details>


### [46] [Evaluating Numerical Accuracy in Mixed-Precision Computing by Dual-Delta Testing](https://arxiv.org/abs/2602.10605)
*Peichen Xie*

Main category: math.NA

TL;DR: 本文提出了一种名为“双增量测试”（Dual-Delta Testing）的系统性方法，用于评估混合精度计算中自定义实现的数值准确性，通过与高精度参考值比较两个误差分布，能够更深入地区分误差来源。


<details>
  <summary>Details</summary>
Motivation: 传统单误差度量方法难以判断混合精度函数中的误差是源于精度限制还是实现缺陷，因此需要一种更系统的评估方法来区分这两者。

Method: 提出双增量测试方法，同时计算自定义实现和基准实现相对于高精度Oracle的两个误差分布，并通过统计分析进行比较；建立了数学框架和算法流程。

Result: 通过多个实际案例验证了该方法的有效性，能够清晰识别出误差是否由特定实现引入，而不仅仅是精度降低所致。

Conclusion: 双增量测试为混合精度函数的数值验证提供了一种更严谨、可解释的评估手段，适用于融合算子、GPU内核优化和量化推理等场景。

Abstract: Mixed-precision computing has become increasingly important in modern high-performance computing and machine learning applications. When implementing custom mixed-precision functions -- such as fused operators, optimized GPU kernels, or quantized inference paths -- it is critical to verify their numerical accuracy. Traditional approaches typically compare the custom implementation against a reference using a single error metric. However, this single-delta approach provides limited insight into whether the observed errors are inherent to the precision level or specific to the implementation. This paper introduces \textit{Dual-Delta Testing}, a systematic methodology that evaluates two error distributions against a high-precision oracle, enabling rigorous comparison between a custom implementation and a baseline reference. We present the mathematical framework, algorithmic formulation, statistical analysis techniques, and practical examples demonstrating the methodology's effectiveness in evaluating numerical accuracy.

</details>


### [47] [An Efficient Energy Stable Structure Preserving Method for The Landau-Lifshitz Equation](https://arxiv.org/abs/2602.10689)
*Changjian Xie,Yingxi Miao,Haocheng Yang*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: One of the main difficulties in micromagnetics simulation is the norm preserving constraints $\|\mathbf{m}\|=1$ at the continuous or the discrete level. Another difficulty is the stability with the time step constraint. Using standard explicit integrators leads to a physical time step of sub-pico seconds, which is often two orders of magnitude smaller than the fastest physical time scales. Direct implicit integrators require solving complicated, coupled systems. Another major difficulty with the projection method in this field is the lack of rigorous theoretical guarantees regarding its stability of the projection step. In this paper, we introduce a first order method. Such a method is structure preserving based on a combination of a Gauss-Seidel iteration, a double diffusion iteration and a Crank-Nicolson iteration to preserve the norm constraints.

</details>


### [48] [The Stochastic TR-BDF2 Scheme of Order 2](https://arxiv.org/abs/2602.10773)
*Tomás Caraballo,Macarena Gómez-Mármol,Ignacio Roldán*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Our main objective in this paper is to develop a second-order stochastic numerical method which generalizes the well-known deterministic TR-BDF2 scheme. Since most stochastic techniques used for approximating the solution of a stochastic differential equation may have lower order compared to the deterministic case, we have elaborated a scheme which not only preserves the second-order accuracy of the original scheme in the stochastic framework, but also its $A$-stability. Once we obtain the scheme and prove its second-order accuracy and $A$-stability, which is not a trivial task, we also state a result concerning its $MS$-stability. This concept is also analyzed for different parameter ranges in our scheme and the It{ô}--Taylor approximation of order 2, revealing scenarios where, for certain time step sizes, the developed method is $MS$-stable while the It{ô}--Taylor one is not. This concept is really useful to tackle slow-fast problems such as stiff ones, which we aim to explore further in future work. Finally, we validate the theoretical results with some academic test cases.

</details>


### [49] [Why summation by parts is not enough](https://arxiv.org/abs/2602.10786)
*Jan Glaubitz,Armin Iske,Joshua Lampert,Philipp Öffner*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the construction and performance of summation-by-parts (SBP) operators, which offer a powerful framework for the systematic development of structure-preserving numerical discretizations of partial differential equations. Previous approaches for the construction of SBP operators have usually relied on either local methods or sparse differentiation matrices, as commonly used in finite difference schemes. However, these methods often impose implicit requirements that are not part of the formal SBP definition. We demonstrate that adherence to the SBP definition alone does not guarantee the desired accuracy, and we identify conditions for SBP operators to achieve both accuracy and stability. Specifically, we analyze the error minimization for an augmented basis, discuss the role of sparsity, and examine the importance of nullspace consistency in the construction of SBP operators. Furthermore, we show how these design criteria can be integrated into a recently proposed optimization-based construction procedure for function space SBP (FSBP) operators on arbitrary grids. Our findings are supported by numerical experiments that illustrate the improved accuracy for the numerical solution using the proposed SBP operators.

</details>


### [50] [bound-preserving Adaptive Time-Stepping Method with Energy Stability for Simulating Compressible Gas Flow in Poroelastic Media](https://arxiv.org/abs/2602.10803)
*Huangxin Chen,Yuxiang Chen,Jisheng Kou,Shuyu Sun*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we present an efficient numerical method to address a thermodynamically consistent gas flow model in porous media involving compressible gas and deformable rock. The accurate modeling of gas flow in porous media often poses significant challenges due to their inherent nonlinearity, the coupling between gas and rock dynamics, and the need to preserve physical principles such as mass conservation, energy dissipation and molar density boundedness. The system is further complicated by the need to balance computational efficiency with the accuracy and stability of the numerical scheme. To tackle these challenges, we adopt a stabilization approach that is able to preserve the original energy dissipation while achieving linear energy-stable numerical schemes. We also prove the convergence of the adopted linear iterative method. At each time step, the stabilization parameter is adaptively updated using a simple and explicit formula to ensure compliance with the original energy dissipation law. The proposed method uses adaptive time stepping to improve computational efficiency while maintaining solution accuracy and boundedness. The adaptive time step size is calculated explicitly at each iteration, ensuring stability and allowing for efficient handling of highly dynamic scenarios. A mixed finite element method combined with an upwind scheme is employed as spatial discretization to ensure mass conservation and stability. Finally, we conduct a series of numerical experiments to validate the performance and robustness of the proposed numerical method.

</details>


### [51] [Hybrid Methods for Friedrichs Systems with Application to Scalar and Vector Diffusion-Advection Problems](https://arxiv.org/abs/2602.10890)
*Daniele Di Pietro,Aurelio Spadotto*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work we study arbitrary-order hybrid discretizations of Friedrichs systems. Friedrichs systems provide a framework that goes beyond the standard classification of partial differential equations into hyperbolic or elliptic, and are thus particularly suited for problems that include both diffusive and advective terms. The family of numerical schemes proposed in this work hinge on hybrid spaces with unknowns located at elements and faces. They support general meshes, are locally conservative and, compared with traditional Discontinuous Galerkin discretizations, lead to smaller algebraic systems once static condensation has been applied. We carry out a complete stability and convergence analysis, which appears to be the first of its kind. The performance of the method is illustrated on scalar and vector three-dimensional diffusion-advection-reaction problems.

</details>


### [52] [Drift-Randomized Milstein-Galerkin Finite Element Method for Semilinear Stochastic Evolution Equations](https://arxiv.org/abs/2602.11109)
*Xiao Qi,Yue Wu,Yubin Yan*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Kruse and Wu [Math. Comp. 88 (2019) 2793--2825] proposed a fully discrete randomized Galerkin finite element method for semilinear stochastic evolution equations (SEEs) driven by additive noise and showed that this method attains a temporal strong convergence rate exceeding order $\frac{1}{2}$ without imposing any differentiability assumptions on the drift nonlinearity. They further discussed a potential extension of the randomized method to SEEs with multiplicative noise and introduced the so-called drift-randomized Milstein-Galerkin finite element fully discrete scheme, but without providing a corresponding strong convergence analysis.
  This paper aims to fill this gap by rigorously analyzing the strong convergence behavior of the drift-randomized Milstein-Galerkin finite element scheme. By avoiding the use of differentiability assumptions on the nonlinear drift term, we establish strong convergence rates in both space and time for the proposed method. The obtained temporal convergence rate is $O(Δt^{1-\varepsilon_0})$, where $Δt$ denotes the time step size and $\varepsilon_0$ is an arbitrarily small positive number. Numerical experiments are reported to validate the theoretical findings.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [53] [Fiscal Dynamics in Japan under Demographic Pressure](https://arxiv.org/abs/2602.10130)
*Goshi Aoki*

Main category: physics.soc-ph

TL;DR: 该研究构建了一个系统动力学模型，分析日本人口老龄化对公共财政的影响，发现提高生产力和控制成本是短期内最有效的财政稳定措施，而提高生育率在中期内反而会恶化财政状况。


<details>
  <summary>Details</summary>
Motivation: 理解人口结构变化如何通过反馈机制影响财政结果，并评估不同政策工具在稳定财政指标方面的效果及时效性。

Method: 基于官方统计数据构建并校准一个整合了人口、劳动力、经济产出与公共财政的系统动力学模型，进行多项政策情景模拟。

Result: 提高生产力和控制人均支出能快速改善财政状况；提高生育率需数十年才能见效，在中期内加重财政负担；适度提升生产力加适度成本控制的组合方案可在2050年前基本消除财政赤字。

Conclusion: 在老龄化、高债务经济体中制定财政政策时，应优先选择能直接、快速影响预算的政策工具，而非依赖缓慢的人口调节机制。

Abstract: Japan's population is shrinking, the share of working-age people is falling, and the number of elderly is growing fast. These trends squeeze public finances from both sides--fewer people paying taxes and more people drawing on pensions and healthcare. Policy discussions often focus on one fix at a time, such as raising taxes, reforming pensions, or boosting productivity. However, these levers interact with each other through feedback loops and time delays that are not yet well understood. This study builds and calibrates an integrated system dynamics model that connects demographics, labor supply, economic output, and public finance to explore two questions: (RQ1) What feedback structure links demographic change to fiscal outcomes, and how do different policy levers work through that structure? (RQ2) Which combinations of policies can stabilize key fiscal indicators within a meaningful timeframe? The model, grounded in official statistics, tracks historical trends reasonably well. Policy experiments show that productivity improvements and controlling per-person costs offer the most effective near-term relief, because they act quickly through revenue and spending channels. In contrast, raising fertility actually worsens the fiscal picture in the medium term, since it takes decades for newborns to grow up and join the workforce. A combined scenario pairing moderate productivity gains with moderate cost control nearly eliminates the deficit by 2050. These findings underscore the importance of timing when evaluating demographic policy. Stabilizing finances within a practical timeframe requires levers that improve the budget directly, rather than those that work through slow demographic channels. The model serves as a transparent testing ground for designing time-aware fiscal policy packages in aging, high-debt economies.

</details>


### [54] [Silence Routing: When Not Speaking Improves Collective Judgment](https://arxiv.org/abs/2602.10145)
*Itsuki Fujisaki,Kunhao Yang*

Main category: physics.soc-ph

TL;DR: 本文提出了一种针对品味领域的集体智能路由框架，通过模拟聚合发现，在允许沉默的条件下，该框架能在特定项目上提升预测准确性，表明品味判断中的集体智慧依赖于有原则的信号路由而非简单平均。


<details>
  <summary>Details</summary>
Motivation: 研究不同类型的社交信号如何在品味领域中被有效利用，以提升群体判断的准确性。

Method: 基于音乐偏好数据集，构建一个包含个人评价（Own）和群体偏好估计（Estimated）的路由框架，并通过模拟聚合方法评估其性能。

Result: 在允许沉默的条件下，该框架在参数空间的广泛区域内优于全个人评价基线，且仅在允许沉默时才能实现增益。

Conclusion: 品味领域的集体智慧依赖于有原则的信号路由机制，而不是简单的意见平均，沉默在第二阶信号发挥作用中至关重要。

Abstract: The wisdom of crowds has been shown to operate not only for factual judgments but also in matters of taste, where accuracy is defined relative to an individual's preferences. However, it remains unclear how different types of social signals should be selectively used in such domains. Focusing on a music preference dataset in which contributors provide both personal evaluations (Own) and estimates of population-level preferences (Estimated), we propose a routing framework for collective intelligence in taste. The framework specifies when contributors should speak, what they should report, and when silence is preferable. Using simulation-based aggregation, we show that prediction accuracy improves over an all-own baseline across a broad region of the parameter space, conditional on items where routing applies. Importantly, these gains arise only when silence is allowed, enabling second-order signals to function effectively. The results demonstrate that collective intelligence in matters of taste depends on principled signal routing rather than simple averaging.

</details>


### [55] [Transforming Policy-Car Swerving for Mitigating Stop-and-Go Traffic Waves: A Practice-Oriented Jam-Absorption Driving Strategy](https://arxiv.org/abs/2602.10234)
*Zhengbing He*

Main category: physics.soc-ph

TL;DR: 本文提出了一种基于单辆车和两个检测器的阻塞吸收驾驶（SVDD-JAD）策略，通过“慢进快出”操作抑制高速公路中走走停停交通波的传播，并利用SUMO仿真验证了该策略在实际检测条件下的可行性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有阻塞吸收驾驶（JAD）策略因缺乏对实施车辆和运行条件的讨论而难以实用化，本文旨在提出一种更贴近现实、可实施的JAD策略。

Method: 受警车变道行为启发，构建SVDD-JAD问题模型，识别影响策略效果的五个关键参数，并基于SUMO仿真结合两个固定路侧检测器数据验证参数测量与控制效果。

Result: 仿真结果表明，所提JAD策略能有效抑制孤立交通波的传播，且不会引发二次波动，同时展示了如何利用双检测器在实践中测量关键参数。

Conclusion: 该研究推动了JAD从理论概念向可实施策略的转变，为实现实际交通管理中的主动波抑制提供了可行方案，并通过开源代码促进交通领域的可重复研究。

Abstract: Stop-and-go waves, as a major form of freeway traffic congestion, cause severe and long-lasting adverse effects, including reduced traffic efficiency, increased driving risks, and higher vehicle emissions. Amongst the highway traffic management strategies, jam-absorption driving (JAD), in which a dedicated vehicle performs "slow-in" and "fast-out" maneuvers before being captured by a stop-and-go wave, has been proposed as a potential method for preventing the propagation of such waves. However, most existing JAD strategies remain impractical mainly due to the lack of discussion regarding implementation vehicles and operational conditions. Inspired by real-world observations of police-car swerving behavior, this paper first introduces a Single-Vehicle Two-Detector Jam-Absorption Driving (SVDD-JAD) problem, and then proposes a practical JAD strategy that transforms such behavior into a maneuver capable of suppressing the propagation of an isolated stop-and-go wave. Five key parameters that significantly affect the proposed strategy, namely, JAD speed, inflow traffic speed, wave width, wave speed, and in-wave speed, are identified and systematically analyzed. Using a SUMO-based simulation as an illustrative example, we further demonstrate how these parameters can be measured in practice with two stationary roadside traffic detectors. The results show that the proposed JAD strategy successfully suppresses the propagation of a stop-and-go wave, without triggering a secondary wave. This paper is expected to take a significant step toward making JAD practical, advancing it from a theoretical concept to a feasible and implementable strategy. To promote reproducibility in the transportation domain, we have also open-sourced all the code on our GitHub repository https://github.com/gotrafficgo.

</details>


### [56] [Pivoting as an Adaptive Strategy to Geopolitical Tensions in U.S. Science](https://arxiv.org/abs/2602.10405)
*Moxin Li,Yifang Ma,Yang Wang,Dashun Wang*

Main category: physics.soc-ph

TL;DR: 美国对华地缘政治紧张显著影响在美科学家的科研资助，尤其对亚裔、早期职业科学家及高风险领域研究者不利，尽管部分科学家通过调整研究方向缓解影响，但适应效果不均。


<details>
  <summary>Details</summary>
Motivation: 探讨地缘政治紧张如何影响科学家的科研活动，特别是中美关系紧张背景下美国科学家与中方合作所面临的挑战及其应对策略。

Method: 利用过去十年的数百万条科研资助和发表数据，分析中美地缘政治紧张对在美科学家个体科研行为的影响。

Result: 发现地缘政治紧张显著减少科研资助机会；许多科学家通过转向其他研究主题来应对，这种调整可在一定程度上缓解资金损失，但效果不均：高风险领域、亚裔身份和早期职业科学家从中获益较少。

Conclusion: 地缘政治紧张通过改变科学家的研究战略决策重塑科学研究，这种不平等的适应性调整凸显了制定增强科学体系韧性与包容性的政策的重要性。

Abstract: Geopolitical tensions increasingly reshape the structure and openness of global science, yet we still lack a clear understanding of how successfully scientists adapt their work under such pressures. Using millions of funding and publication datasets across the past ten years, we investigate how U.S. China geopolitical tensions reshaped individual research activities of U.S. based scientists, particularly those collaborating with Chinese peers. We find that although U.S. China geopolitical tensions significantly reduce funding opportunities, many scientists actively respond by pivoting their research portfolios toward alternative topics, and this adaptive reorientation partially mitigates funding losses. Crucially, the effectiveness of this adaptive strategy is highly unequal: for scientists in high risk domains, those of Asian descent, and early-career scientists, pivoting offers only limited protection against funding loss. Our results demonstrate that geopolitical tensions reshape science through shifts in scientists' strategic decisions about their research focus. Understanding this adaptive but uneven reconfiguration is essential for science policies to strengthen the resilience and inclusiveness of the scientific enterprise.

</details>


### [57] [Detecting and forecasting tipping points from sample variance alone](https://arxiv.org/abs/2602.10817)
*Naoki Masuda*

Main category: physics.soc-ph

TL;DR: 提出了一种名为TIPMOC的新方法，通过拟合方差的幂律发散特性来检测复杂系统中即将发生的临界点，并准确预测其位置，具有低误报率和强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统基于临界慢化的早期预警信号在可靠预测分岔时间和避免误报方面存在局限，需要更有效的统计方法来提升预测能力。

Method: 利用方差在单参数分岔附近呈幂律发散的特性，通过逐步比较线性与幂律模型对样本方差的拟合优度，判断是否进入临界区域并预测 tipping point 的位置。

Result: 在多种动力学系统和分岔类型中验证了TIPMOC的有效性，表现出高准确性、低误报率，并能应对不均匀采样和有色噪声。

Conclusion: TIPMOC增强了经典早期预警信号的可解释性和实用性，可作为透明附加模块或独立工具用于预测复杂系统的 regime shifts。

Abstract: Anticipating tipping points in complex systems is a fundamental challenge across domains. Traditional early warning signals (EWSs) based on critical slowing down, such as increasing sample variance, are widely used, but their ability to reliably indicate imminent bifurcations and forecast their timing remains limited. Here, we introduce TIPMOC (TIpping via Power-law fits and MOdel Comparison), a parametric framework designed to statistically detect the approach of a bifurcation and estimate its future location using only the sample variance. TIPMOC exploits the mathematical property that variance diverges with a characteristic power-law form near codimension-one bifurcations. By sequentially monitoring system variance as a control parameter changes, TIPMOC statistically adjudicates between linear and power-law divergence at each step. When evidence favors power-law divergence, TIPMOC forecasts the impending tipping point and estimates its position; otherwise, it avoids false positives. Through numerical simulations, we demonstrate TIPMOC's robustness and accuracy in both detection and timing prediction across different types of dynamics and bifurcation. TIPMOC shows low false positive rates and performs well even with uneven sampling and colored noise. This method thus enhances the interpretability and practical utility of classical EWSs, serving as both a transparent add-on and a stand-alone statistical tool for forecasting regime shifts in diverse complex systems.

</details>


### [58] [Formalization and inevitability of the Pareto principle](https://arxiv.org/abs/2602.11131)
*Antti Hippeläinen*

Main category: physics.soc-ph

TL;DR: 本文形式化并研究了帕累托原则（“20/80法则”）在有界累积过程中的广义形式，通过增益密度函数的递减排列定义其唯一非平凡特征，并分析多种分布下的表现及其启示。


<details>
  <summary>Details</summary>
Motivation: 试图对广泛存在的帕累托现象进行数学上的统一刻画，明确其在不同分布中的普适性与限制条件。

Method: 利用非负增益密度建模累积过程，引入增益密度函数的递减排列来定义广义帕累托原则，并分析构造示例及常见分布族（如幂律、指数、正态分布）。

Result: 证明任意此类过程均满足“p比例输入产生1-p比例输出”的广义帕累托关系，且通过递减排列可获得非平凡且唯一的表征；预测了实际中常见的广义帕累托参数范围。

Conclusion: 广义帕累托原则可作为一类结构性规律被形式化，在多种分布下成立，将其从描述性特征提升为规范性指导具有理论和实践意义。

Abstract: We formalize and study a generalized form of the Pareto principle or "20/80-rule" as a property of bounded cumulative processes. Modeling such processes by non-negative gain densities, we first show that any such process satisfies a generalized Pareto principle of the form "fraction $p$ of inputs yields fraction $1-p$ of outputs". To obtain a non-trivial and unique characterization, we define the generalized Pareto principle via the decreasing rearrangement of the gain density function. Within this framework, we analyze both constructed gain densities that exemplify the framework and its imposed restrictions, as well as distribution families commonly encountered in datasets, including power-law, exponential, and normal distributions. Finally, we predict commonly encountered ranges for the generalized Pareto principle and discuss the implications of elevating a structural property into a prescriptive role.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [59] [Geographically Weighted Canonical Correlation Analysis: Local Spatial Associations Between Two Sets of Variables](https://arxiv.org/abs/2602.10241)
*Zhenzhi Jiao,Angela Yao,Ran Tao,Jean-Claude Thill*

Main category: stat.ME

TL;DR: 提出了一种新的地理加权典型相关分析方法（GWCCA），用于探索两组变量之间的局部空间关联，通过合成数据和美国县-level健康与社会决定因素的案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 经典典型相关分析（CCA）难以捕捉地理空间中变化的复杂多变量关系，因此需要一种能够揭示局部空间关联的新方法。

Method: 通过引入地理加权机制，对标准CCA进行局部化处理，即根据每个观测点与目标位置的空间距离进行加权，从而估计位置特定的典型相关系数。

Result: 在合成数据上验证了GWCCA能有效恢复空间结构并捕捉空间效应；在美国健康数据的案例中成功揭示了局部尺度上的多变量空间关联。

Conclusion: GWCCA具有广泛的应用潜力，适用于城市规划、环境科学、公共卫生和交通等依赖空间数据分析的领域。

Abstract: This article critically assesses the utility of the classical statistical technique of Canonical Correlation Analysis (CCA) for studying spatial associations and proposes a new approach to enhance it. Unlike bivariate correlation analysis, which focuses on the relationship between two individual variables, CCA investigates associations between two sets of variables by identifying pairs of linear combinations that are maximally correlated. CCA has strong potential for uncovering complex multivariate relationships that vary across geographic space. We propose Geographically Weighted Canonical Correlation Analysis (GWCCA) as a new technique for exploring local spatial associations between two sets of variables. GWCCA localizes standard CCA by weighting each observation according to its spatial distance from a target location, thereby estimating location-specific canonical correlations. The effectiveness of GWCCA in recovering spatial structure and capturing spatial effects is evaluated using synthetic data. A case study of US county-level health outcomes and social determinants of health further demonstrates the empirical capabilities of the proposed method. The results indicate that GWCCA has broad potential applications in spatial data-intensive fields such as urban planning, environmental science, public health, and transportation, where understanding local multivariate spatial associations is critical.

</details>


### [60] [Generalized Prediction-Powered Inference, with Application to Binary Classifier Evaluation](https://arxiv.org/abs/2602.10332)
*Runjia Zou,Daniela Witten,Brian Williamson*

Main category: stat.ME

TL;DR: 本文将预测驱动推断（PPI）推广到任意正则渐近线性估计量，并通过与缺失数据和半参数效率理论的联系，提出可处理协变量分布偏移的改进PPI估计量。


<details>
  <summary>Details</summary>
Motivation: 现有的PPI方法局限于M估计，且未充分利用缺失数据和半参数效率理论的成果，限制了其在实际场景中的效率和适用性。

Method: 将PPI框架推广至一般的正则渐近线性估计，并结合半参数效率理论分析其效率界限，提出能应对三种协变量分布偏移的改进PPI估计方法。

Result: 发现标准PPI无法在一般情况下达到半参数效率下界，但可作为计算简便的替代方案；新提出的PPI变体在数值实验中能有效估计真阳性率、假阳性率和曲线下面积。

Conclusion: PPI虽不具最优效率，但通过理论整合可扩展并改进，适用于更广泛的参数估计和分布偏移场景。

Abstract: In the partially-observed outcome setting, a recent set of proposals known as "prediction-powered inference" (PPI) involve (i) applying a pre-trained machine learning model to predict the response, and then (ii) using these predictions to obtain an estimator of the parameter of interest with asymptotic variance no greater than that which would be obtained using only the labeled observations. While existing PPI proposals consider estimators arising from M-estimation, in this paper we generalize PPI to any regular asymptotically linear estimator. Furthermore, by situating PPI within the context of an existing rich literature on missing data and semi-parametric efficiency theory, we show that while PPI does not achieve the semi-parametric efficiency lower bound outside of very restrictive and unrealistic scenarios, it can be viewed as a computationally-simple alternative to proposals in that literature. We exploit connections to that literature to propose modified PPI estimators that can handle three distinct forms of covariate distribution shift. Finally, we illustrate these developments by constructing PPI estimators of true positive rate, false positive rate, and area under the curve via numerical studies.

</details>


### [61] [Optimizing precision in stepped-wedge designs via machine learning and quadratic inference functions](https://arxiv.org/abs/2602.10348)
*Liangbo Lyu,Bingkai Wang*

Main category: stat.ME

TL;DR: 提出了一类新的阶梯楔形设计中因果平均处理效应的估计方法，通过灵活的机器学习协变量调整和自适应学习相关结构来优化精度。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法依赖于具有线性协变量调整和预设相关结构的参数模型，可能在实践中限制了可实现的精度。

Method: 使用基于机器学习的灵活协变量调整和二次推断函数来自适应学习相关结构，以提高估计精度。

Result: 所提方法在温和条件下具有一致性和渐近正态性，并且即使在模型误设的情况下也能达到最小渐近方差；此外，该方法不会降低相对于独立工作相关的效率。

Conclusion: 所提出的估计器能够有效提升阶梯楔形设计中的估计精度，并适用于不同研究领域和关键设计参数的研究。

Abstract: Stepped-wedge designs are increasingly used in randomized experiments to accommodate logistical and ethical constraints by staggering treatment roll-out over time. Despite their popularity, existing analytical methods largely rely on parametric models with linear covariate adjustment and prespecified correlation structures, which may limit achievable precision in practice. We propose a new class of estimators for the causal average treatment effect in stepped-wedge designs that optimizes precision through flexible, machine-learning-based covariate adjustment to capture complex outcome-covariate relationships, together with quadratic inference functions to adaptively learn the correlation structure. We establish consistency and asymptotic normality under mild conditions requiring only $L_2$ convergence of nuisance estimators, even under model misspecification, and characterize when the estimator attains the minimal asymptotic variance. Moreover, we prove that the proposed estimator never reduces efficiency relative to an independence working correlation. The proposed method further accommodates treatment-effect heterogeneity across both exposure duration and calendar time. Finally, we demonstrate our methods through simulation studies and reanalyses of two empirical studies that differ substantially in research area and key design parameters.

</details>


### [62] [CoVaR under Asymptotic Independence](https://arxiv.org/abs/2602.10484)
*Zhaowen Wang,Yutao Liu,Deyuan Li*

Main category: stat.ME

TL;DR: 本文提出了一种半参数方法来估计渐近独立变量对的条件风险价值（CoVaR），基于二元极值理论框架，通过参数建模解决联合尾部区域数据稀疏问题，并证明了估计量的一致性和渐近正态性，模拟研究和实际股票数据应用显示其具有稳健性能。


<details>
  <summary>Details</summary>
Motivation: 由于CoVaR是衡量系统性风险的重要指标，但在渐近独立情况下传统方法难以有效估计，尤其是在联合尾部数据稀疏时，因此需要发展新的估计方法。

Method: 在二元极值理论框架下，采用半参数方法结合参数建模来刻画极端变量之间的依赖结构，并构建CoVaR估计量，推导其统计性质。

Result: 所提估计量具有一致性和渐近正态性，在模拟研究中表现出稳健性，并能对美国股票收益数据提供有洞察力的动态CoVaR预测。

Conclusion: 该方法为渐近独立情形下的CoVaR估计提供了有效的解决方案，适用于金融系统性风险的动态评估。

Abstract: Conditional value-at-risk (CoVaR) is one of the most important measures of systemic risk. It is defined as the high quantile conditional on a related variable being extreme, widely used in the field of quantitative risk management. In this work, we develop a semi-parametric methodology to estimate CoVaR for asymptotically independent pairs within the framework of bivariate extreme value theory. We use parametric modelling of the bivariate extremal structure to address data sparsity in the joint tail regions and prove consistency and asymptotic normality of the proposed estimator. The robust performance of the estimator is illustrated via simulation studies. Its application to the US stock returns data produces insightful dynamic CoVaR forecasts.

</details>


### [63] [Inferring the presence and abundance of rare waterbirds species from scarce data](https://arxiv.org/abs/2602.10673)
*Barbara Bricout,Laura Dami,Pierre Defos du Rau,Sophie Donnet,Thomas Galewski,Stephane Robin*

Main category: stat.ME

TL;DR: 提出一种基于对数正态泊松模型的统计方法，用于处理生态学中具有大量缺失数据、高方差和过多零值的物种丰度数据，实现缺失值填补、协变量效应估计及趋势检测。


<details>
  <summary>Details</summary>
Motivation: 生态学中的物种丰度数据常存在大量缺失、高比例零值和高方差，尤其在稀有物种监测中更为显著，传统模型难以有效处理这些问题。

Method: 采用低秩潜变量结构的对数正态泊松模型，引入潜变量解释零膨胀，并通过变分EM算法进行参数推断，同时估计渐近方差和预测区间。

Result: 模型能有效填补缺失数据并提供可靠的预测区间，在人工退化数据和水鸟监测数据上验证了方法的准确性与实用性。

Conclusion: 该方法为生态丰度数据提供了统一的建模框架，兼具缺失数据填补、协变量分析和趋势检测能力，适用于复杂生态监测数据的分析。

Abstract: Abundance data are used in ecology for species monitoring and conservation. These count data often display several specific characteristics like numerous missing data, high variance, and a high proportion of zeros, particularly when monitoring rare species. We present a model that aims to impute missing data and estimate the effect of covariates on species presence and abundance. It is based on the log-normal Poisson model, which offers more flexibility in the variance of counts than a Poisson model. A latent variable is added for the overrepresentation of zeros in the data. The imputation of missing data is made possible by assuming that the latent variance matrix has low rank and the inclusion of covariates. \\ We demonstrate the identifiability in the presence of missing data. Since maximum likelihood inference is intractable, we use a variational expectation-maximization algorithm to infer the parameters. We provide an estimate of the asymptotic variance of the estimators and derive prediction intervals for the imputations, an estimate of the temporal trend, and a procedure for detecting a potential change in this trend. \\ We evaluate our imputations and associated prediction intervals using artificially degraded monitoring data set. We conclude with an illustration on a monitoring waterbirds data set.

</details>


### [64] [A closed form solution for Bayesian analysis of a simple linear mixed model](https://arxiv.org/abs/2602.10730)
*Hilde Vinje,Lars Erik Gangsei*

Main category: stat.ME

TL;DR: 本研究提出使用四参数广义贝塔分布作为简单线性混合模型的共轭先验，实现了平衡设计下线性混合模型的闭式贝叶斯解，方法性能与传统频率法相当且均方误差略低。


<details>
  <summary>Details</summary>
Motivation: 现有线性混合效应模型的推断多依赖于基于似然的近似方法，在小样本情况下可能不可靠，缺乏精确的贝叶斯解析解。

Method: 采用四参数广义贝塔分布作为共轭先验，推导出平衡设计下简单线性混合模型的闭式贝叶斯解，并通过与标准基于似然的频率方法进行比较评估性能。

Result: 贝叶斯方法在性能上与频率方法相当，且均方误差略有降低；提出了超参数的经验贝叶斯设定策略。

Conclusion: 该方法为线性混合模型提供了新的贝叶斯推断路径，虽目前限于平衡设计，但为更复杂模型的解析推断提供了可能性。

Abstract: Linear mixed-effects models are a central analytical tool for modeling hierarchical and longitudinal data, as they allow simultaneous representation of fixed and random sources of variation. In practice, inference for such models is most often based on likelihood-based approximations, which are computationally efficient, but rely on numerical integration and may be unreliable example wise in small-sample settings. In this study, the somewhat obscure four-parameter generalized beta density is shown to be usable as a conjugate prior distribution for a simple linear mixed model. This leads to a closed-form Bayesian solution for a balanced mixed-model design, representing a methodological development beyond standard approximate or simulation-based Bayesian approaches. Although the derivation is restricted to a balanced setting, the proposed framework suggests a pathway toward analytically tractable Bayesian inference for more complex mixed-model structures. The method is evaluated through comparison with a standard frequentist solution based on likelihood estimation for linear mixed-effects models. Results indicate that the Bayesian approach performs just as well as the frequentist alternative, while yielding slightly reduced mean squared error. The study further discusses the use of empirical Bayes strategies for hyperparameter specification and outlines potential directions for extending the approach beyond the balanced case.

</details>


### [65] [Non-centred Bayesian inference for discrete-valued state-transition models: the Rippler algorithm](https://arxiv.org/abs/2602.10924)
*James Neill,Lloyd A. C. Chapman,Chris Jewell*

Main category: stat.ME

TL;DR: 提出了一种名为Rippler的新型贝叶斯算法，用于估计个体层面传染病模型的参数和未观测疾病状态，且在疾病状态增多时表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为解决个体层面传染病数据中未观测疾病状态推断困难、状态空间高维且高度相关的问题，需要更高效的统计推断方法。

Method: 开发了一种非中心化的贝叶斯数据增强马尔可夫链蒙特卡洛算法（Rippler），可联合估计模型参数与个体未观测的疾病状态，并适用于任何基于个体的状态转移模型。

Result: Rippler算法在疾病状态数量增加时，性能优于当前最先进的个体化随机传染病模型推断方法。

Conclusion: Rippler算法为复杂传染病模型提供了更高效、更具扩展性的推断工具，尤其适用于高维状态空间的情形。

Abstract: Stochastic state-transition models of infectious disease transmission can be used to deduce relevant drivers of transmission when fitted to data using statistically principled methods. Fitting this individual-level data requires inference on individuals' unobserved disease statuses over time, which form a high-dimensional and highly correlated state space. We introduce a novel Bayesian (data-augmentation Markov chain Monte Carlo) algorithm for jointly estimating the model parameters and unobserved disease statuses, which we call the Rippler algorithm. This is a non-centred method that can be applied to any individual-based state-transition model. We compare the Rippler algorithm to the state-of-the-art inference methods for individual-based stochastic epidemic models and find that it performs better than these methods as the number of disease states in the model increases.

</details>


### [66] [Prior Smoothing for Multivariate Disease Mapping Models](https://arxiv.org/abs/2602.10955)
*Garazi Retegui,María Dolores Ugarte,Jaione Etxeberria,Alan E. Gelfand*

Main category: stat.ME

TL;DR: 本文研究了多变量疾病映射中的平滑效应，提出了理论和实证指标来评估不同多变量先验选择下的空间平滑效果。


<details>
  <summary>Details</summary>
Motivation: 扩展单变量区域数据模型中平滑效应的研究，探讨多变量疾病映射中不同先验设定对风险估计的影响。

Method: 采用分层模型结构，结合泊松模型与空间随机效应，比较三种不同多变量先验在区域内和平滑超参数上的表现。

Result: 提出了可量化平滑程度的理论与实证指标，并通过模拟和真实数据验证了不同先验下平滑效应的表现差异。

Conclusion: 不同多变量先验会带来不同程度的平滑效应，研究结果有助于用户理解模型偏离完美拟合的预期性质，从而更好地选择合适先验。

Abstract: To date, we have seen the emergence of a large literature on multivariate disease mapping. That is, incidence of (or mortality from) multiple diseases is recorded at the scale of areal units where incidence (mortality) across the diseases is expected to manifest dependence. The modeling involves a hierarchical structure: a Poisson model for disease counts (conditioning on the rates) at the first stage, and a specification of a function of the rates using spatial random effects at the second stage. These random effects are specified as a prior and introduce spatial smoothing to the rate (or risk) estimates. What we see in the literature is the amount of smoothing induced under a given prior across areal units compared with the observed/empirical risks. Our contribution here extends previous research on smoothing in univariate areal data models. Specifically, for three different choices of multivariate prior, we investigate both within prior smoothing according to hyperparameters and across prior smoothing. Its benefit to the user is to illuminate the expected nature of departure from perfect fit associated with these priors since model performance is not a question of goodness of fit. We propose both theoretical and empirical metrics for our investigation and illustrate with both simulated and real data.

</details>


### [67] [Weighting-Based Identification and Estimation in Graphical Models of Missing Data](https://arxiv.org/abs/2602.10969)
*Anna Guo,Razieh Nabi*

Main category: stat.ME

TL;DR: 提出了一种基于树的识别算法，用于在图模型中识别缺失数据的完整数据分布，通过干预视角处理缺失指示符，并开发了递归逆概率加权方法。


<details>
  <summary>Details</summary>
Motivation: 在缺失数据的图模型中，传统的识别方法可能因选择偏倚的传播而失败，需要一种能够追踪并避免该问题的新方法。

Method: 采用干预主义视角，将缺失指示符视为可干预变量，设计树形识别算法以跟踪选择偏倚的产生与传播，并提出递归逆概率加权估计方法。

Result: 实现了对完整数据分布和缺失机制的功能量的正确识别与估计，模拟研究和实际数据分析验证了方法的有效性。

Conclusion: 所提方法为缺失数据下的识别与估计提供了系统性解决方案，配套R包flexMissing支持实际应用。

Abstract: We propose a constructive algorithm for identifying complete data distributions in graphical models of missing data. The complete data distribution is unrestricted, while the missingness mechanism is assumed to factorize according to a conditional directed acyclic graph. Our approach follows an interventionist perspective in which missingness indicators are treated as variables that can be intervened on. A central challenge in this setting is that sequences of interventions on missingness indicators may induce and propagate selection bias, so that identification can fail even when a propensity score is invariant to available interventions. To address this challenge, we introduce a tree-based identification algorithm that explicitly tracks the creation and propagation of selection bias and determines whether it can be avoided through admissible intervention strategies. The resulting tree provides both a diagnostic and a constructive characterization of identifiability under a given missingness mechanism. Building on these results, we develop recursive inverse probability weighting procedures that mirror the intervention logic of the identification algorithm, yielding valid estimating equations for both the missingness mechanism and functionals of the complete data distribution. Simulation studies and a real-data application illustrate the practical performance of the proposed methods. An accompanying R package, flexMissing, implements all proposed procedures.

</details>


### [68] [Constrained Fiducial Inference for Gaussian Models](https://arxiv.org/abs/2602.11080)
*Hank Flury,Jan Hannig,Richard Smith*

Main category: stat.ME

TL;DR: 提出了一种基于Cayley变换和约束广义似然推断的新型MCMC方法，用于拟合参数化高斯模型，无需先验假设且适用于非独立同分布数据。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统贝叶斯方法需要设定先验分布以及对数据独立同分布的依赖问题，提出一种更灵活、易实现的统计推断方法。

Method: 利用Cayley变换分解参数化协方差矩阵，结合约束广义似然推断构建MCMC算法，并设计适用于多种参数化高斯模型的数据生成机制。

Result: 理论证明所提MCMC算法能准确靶向目标似然分布；在MA(1)和Matérn模型上的模拟表现良好，适用于时间序列与空间数据。

Conclusion: 该方法具有广泛适用性、易于实现，并避免了先验选择问题，为高斯模型提供了一种有效的无先验后验类推断工具。

Abstract: We propose a new fiducial Markov Chain Monte Carlo (MCMC) method for fitting parametric Gaussian models. We utilize the Cayley transform to decompose the parametric covariance matrix, which in turn allows us to formulate a general data generating algorithm for Gaussian data. Leveraging constrained generalized fiducial inference, we are able to create the basis of an MCMC algorithm, which can be specified to parametric models with minimal effort. The appeal of this novel approach is the wide class of models which it permits, ease of implementation and the posterior-like fiducial distribution without the need for a prior. We provide background information for the derivation of the relevant fiducial quantities, and a proof that the proposed MCMC algorithm targets the correct fiducial distribution. We need not assume independence nor identical distribution of the data, which makes the method attractive for application to time series and spatial data. Well-performing simulation results of the MA(1) and Matérn models are presented.

</details>


### [69] [Renet: Principled and Efficient Relaxation for the Elastic Net via Dynamic Objective Selection](https://arxiv.org/abs/2602.11107)
*Albert Dorador*

Main category: stat.ME

TL;DR: 本文提出了Renet，一种将Relaxed Lasso推广到Elastic Net系列估计器的新框架，通过自适应松弛策略解决标准Elastic Net的收缩偏差问题，在高维、低信噪比和多重共线性场景下显著提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 标准Elastic Net存在收缩偏差，导致预测精度下降，尤其是在高维和低信噪比情况下，需要一种更稳健且去偏的方法来提升性能。

Method: 提出Renet框架，采用自适应松弛策略，在保持符号一致性的同时动态切换凸组合与子路径重拟合，并结合‘一标准误规则’实现鲁棒去偏。

Result: 在20个合成和真实数据集上的实验表明，Renet在预测准确性和稳定性上优于标准Elastic Net和自适应Elastic Net，同时计算效率与最先进的坐标下降法相当。

Conclusion: Renet为Elastic Net家族提供了一个原则性强、统计效率高且计算可行的扩展，在高维复杂数据中具有优越的实用价值。

Abstract: We introduce Renet, a principled generalization of the Relaxed Lasso to the Elastic Net family of estimators. While, on the one hand, $\ell_1$-regularization is a standard tool for variable selection in high-dimensional regimes and, on the other hand, the $\ell_2$ penalty provides stability and solution uniqueness through strict convexity, the standard Elastic Net nevertheless suffers from shrinkage bias that frequently yields suboptimal prediction accuracy. We propose to address this limitation through a framework called \textit{relaxation}. Existing relaxation implementations rely on naive linear interpolations of penalized and unpenalized solutions, which ignore the non-linear geometry that characterizes the entire regularization path and risk violating the Karush-Kuhn-Tucker conditions. Renet addresses these limitations by enforcing sign consistency through an adaptive relaxation procedure that dynamically dispatches between convex blending and efficient sub-path refitting. Furthermore, we identify and formalize a unique synergy between relaxation and the ``One-Standard-Error'' rule: relaxation serves as a robust debiasing mechanism, allowing practitioners to leverage the parsimony of the 1-SE rule without the traditional loss in predictive fidelity. Our theoretical framework incorporates automated stability safeguards for ultra-high dimensional regimes and is supported by a comprehensive benchmarking suite across 20 synthetic and real-world datasets, demonstrating that Renet consistently outperforms the standard Elastic Net and provides a more robust alternative to the Adaptive Elastic Net in high-dimensional, low signal-to-noise ratio and high-multicollinearity regimes. By leveraging an adaptive solver backend, Renet delivers these statistical gains while offering a computational profile that remains competitive with state-of-the-art coordinate descent implementations.

</details>


### [70] [A Doubly Robust Machine Learning Approach for Disentangling Treatment Effect Heterogeneity with Functional Outcomes](https://arxiv.org/abs/2602.11118)
*Filippo Salmaso,Lorenzo Testa,Francesca Chiaromonte*

Main category: stat.ME

TL;DR: 本文提出了FOCaL（Functional Outcome Causal Learning）方法，一种用于估计函数型异质性处理效应（F-CATE）的新型双重稳健元学习器，能够有效利用时间或空间等连续域上的功能数据进行个性化因果推断。


<details>
  <summary>Details</summary>
Motivation: 现有的异质性处理效应（CATE）估计方法主要局限于标量输出，难以充分利用科学应用中常见的函数型（如随时间或空间变化）结果变量所包含的丰富信息，因此需要发展适用于函数型结果的因果学习框架。

Method: 提出FOCaL方法，结合函数回归技术与双重稳健机制，通过建模结果变量和重构函数型伪结果来直接估计F-CATE，并提供理论推导与算法实现。

Result: 在模拟实验中，FOCaL表现出优于现有非稳健方法的性能和鲁棒性；在多个真实世界的功能数据集上验证了其实际应用价值。

Conclusion: FOCaL拓展了机器学习在复杂数据下进行个性化因果推断的能力，为精准医疗、自适应政策设计和科学发现提供了更可靠的人工智能工具。

Abstract: Causal inference is paramount for understanding the effects of interventions, yet extracting personalized insights from increasingly complex data remains a significant challenge for modern machine learning. This is the case, in particular, when considering functional outcomes observed over a continuous domain (e.g., time, or space). Estimation of heterogeneous treatment effects, known as CATE, has emerged as a crucial tool for personalized decision-making, but existing meta-learning frameworks are largely limited to scalar outcomes, failing to provide satisfying results in scientific applications that leverage the rich, continuous information encoded in functional data. Here, we introduce FOCaL (Functional Outcome Causal Learning), a novel, doubly robust meta-learner specifically engineered to estimate a functional heterogeneous treatment effect (F-CATE). FOCaL integrates advanced functional regression techniques for both outcome modeling and functional pseudo-outcome reconstruction, thereby enabling the direct and robust estimation of F-CATE. We provide a rigorous theoretical derivation of FOCaL, demonstrate its performance and robustness compared to existing non-robust functional methods through comprehensive simulation studies, and illustrate its practical utility on diverse real-world functional datasets. FOCaL advances the capabilities of machine intelligence to infer nuanced, individualized causal effects from complex data, paving the way for more precise and trustworthy AI systems in personalized medicine, adaptive policy design, and fundamental scientific discovery.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [71] [Bernstein-von Mises theorem for log-concave posteriors](https://arxiv.org/abs/2602.10256)
*Victor-Emmanuel Brunel*

Main category: math.ST

TL;DR: 提出了适用于模型正确设定和误设情况下的新版本Bernstein-von Mises定理，仅依赖凸分析，无需技术性光滑假设。


<details>
  <summary>Details</summary>
Motivation: 为了在不需要传统光滑性假设的情况下，证明更广泛适用的Bernstein-von Mises定理。

Method: 利用对数似然函数在参数上的凹性和先验分布的对数凹性，基于凸分析方法进行理论推导。

Result: 成功证明了在模型正确设定和误设情况下新的Bernstein-von Mises定理版本。

Conclusion: 所提出的方法仅依赖于凸分析，摆脱了经典版本中对光滑性条件的依赖，扩展了定理的适用范围。

Abstract: We prove new, general versions of Bernstein-von Mises theorem for both well-specified and misspecified models when the log-likelihood is concave in the parameter and the prior distribution is log-concave. Unlike classical versions of Bernstein-von Mises theorem, our versions do not require technical smoothness assumptions, and they solely rely on convex analysis.

</details>


### [72] [Asymptotic equivalence for nonparametric additive regression](https://arxiv.org/abs/2602.10274)
*Moritz Jirak,Alexander Meister,Angelika Rohde*

Main category: math.ST

TL;DR: 本文证明了非参数可加回归模型与适当的高斯白噪声实验在渐近意义下的等价性，其中观测到一个维度等于可加成分数量的多维位移维纳过程。


<details>
  <summary>Details</summary>
Motivation: 研究非参数可加回归模型与高斯白噪声模型之间的渐近等价性，以便更好地理解其统计结构并简化分析。

Method: 通过一个显式指定的有界但非紧线性算子Γ，建立回归函数的可加成分与多维位移维纳过程之间的联系，并考虑协变量的一维和二维边际分布。

Result: 证明了在样本量趋于无穷时，两种模型的渐近等价性；当协变量成分两两独立时，白噪声模型可分解为d个独立的单变量过程；并在半参数设定下研究了算子Γ的分解性质。

Conclusion: 非参数可加回归与特定高斯白噪声模型在渐近意义上等价，该结果适用于可加成分数量随样本量适度增长的情形。

Abstract: We prove asymptotic equivalence of nonparametric additive regression and an appropriate Gaussian white noise experiment in which a multidimensional shifted Wiener process is observed, whose dimension equals the number of additive components. The shift depends on the additive components of the regression function and solely the one- and two-dimensional marginal distributions of the covariates via an explicitly specified bounded but non-compact linear operator~$Γ$. The number of additive components $d$ is allowed to increase moderately with respect to the sample size. In the special case of pairwise independent components of the covariates, the white noise model decomposes into $d$ independent univariate processes. Moreover, we study approximation in some semiparametric setting where $Γ$ splits into a multiplication operator and an asymptotically negligible Hilbert-Schmidt operator.

</details>


### [73] [Do More Predictions Improve Statistical Inference? Filtered Prediction-Powered Inference](https://arxiv.org/abs/2602.10464)
*Shirong Xu,Will Wei Sun*

Main category: math.ST

TL;DR: 本文提出了Filtered Prediction-Powered Inference (FPPI) 框架，通过自适应筛选预测质量高的区域来提升统计推断效率，解决了现有方法在预测质量异质时性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成预测的成本降低，数据可靠性取代数据稀缺成为统计推断的主要挑战；现有方法盲目使用所有未标注数据可能导致推断精度下降，尤其在预测质量不均一时。

Method: 提出FPPI框架，通过一个数据自适应的过滤区域选择性地纳入预测，在满足边界条件下一致估计该区域，并将预测驱动的修正限制在该区域内以减轻偏差或噪声影响。

Result: FPPI在渐近效率上优于现有的预测驱动推断方法，数值实验和大语言模型评估的实际应用表明其能显著减少对昂贵标签的依赖，同时在预测质量异质情况下仍保持准确推断。

Conclusion: FPPI通过自适应过滤机制有效提升了在有限标注数据下的推断效率与鲁棒性，为处理异质预测质量提供了新的解决方案。

Abstract: Recent advances in artificial intelligence have enabled the generation of large-scale, low-cost predictions with increasingly high fidelity. As a result, the primary challenge in statistical inference has shifted from data scarcity to data reliability. Prediction-powered inference methods seek to exploit such predictions to improve efficiency when labeled data are limited. However, existing approaches implicitly adopt a use-all philosophy, under which incorporating more predictions is presumed to improve inference. When prediction quality is heterogeneous, this assumption can fail, and indiscriminate use of unlabeled data may dilute informative signals and degrade inferential accuracy. In this paper, we propose Filtered Prediction-Powered Inference (FPPI), a framework that selectively incorporates predictions by identifying a data-adaptive filtered region in which predictions are informative for inference. We show that this region can be consistently estimated under a margin condition, achieving fast rates of convergence. By restricting the prediction-powered correction to the estimated filtered region, FPPI adaptively mitigates the impact of biased or noisy predictions. We establish that FPPI attains strictly improved asymptotic efficiency compared with existing prediction-powered inference methods. Numerical studies and a real-data application to large language model evaluation demonstrate that FPPI substantially reduces reliance on expensive labels by selectively leveraging reliable predictions, yielding accurate inference even in the presence of heterogeneous prediction quality.

</details>


### [74] [Finite-sample confidence regions for spectral clustering and graph centrality](https://arxiv.org/abs/2602.10566)
*Chandrasekhar Gokavarapu,Sekhar Babu Gosala,Vamis Pasalapudi,Tarakarama Kapakayala*

Main category: math.ST

TL;DR: 本文提出了针对图谱方法的有限样本推断框架，构建了图算子潜在特征空间的显式置信区域，并给出了谱聚类和图中心性功能的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 谱方法广泛应用于图数据分析，但其结果常被视为确定性输出，缺乏对有限样本下不确定性的合理刻画。本文旨在建立严格的有限样本推断理论。

Method: 在明确的采样模型下，利用非渐近分析技术构造图算子特征空间的置信区域，并结合谱间隙、噪声水平和样本量进行误差传播分析。

Result: 得到了谱聚类分配和光滑图中心性泛函的置信区域；揭示了常见渐近扰动论证在缺乏有限样本谱间隙时的失效问题；提供了具有覆盖保证和稳定性认证的推断框架。

Conclusion: 本文为谱图方法提供了可验证的不确定性量化工具，强调了谱间隙条件的重要性，支持公平约束后处理与拓扑摘要的统计推断。

Abstract: Let a graph be observed through a finite random sampling mechanism. Spectral methods are routinely applied to such graphs, yet their outputs are treated as deterministic objects. This paper develops finite-sample inference for spectral graph procedures.
  The primary result constructs explicit confidence regions for latent eigenspaces of graph operators under an explicit sampling model. These regions propagate to confidence regions for spectral clustering assignments and for smooth graph centrality functionals. All bounds are nonasymptotic and depend explicitly on the sample size, noise level, and spectral gap.
  The analysis isolates a failure of common practice: asymptotic perturbation arguments are often invoked without a finite-sample spectral gap, leading to invalid uncertainty claims. Under verifiable gap and concentration conditions, the present framework yields coverage guarantees and certified stability regions. Several corollaries address fairness-constrained post-processing and topological summaries derived from spectral embeddings.

</details>


### [75] [Covariate-Adaptive Randomization in Clinical Trials Without Inflated Variances](https://arxiv.org/abs/2602.10760)
*Zhang Li-Xin*

Main category: math.ST

TL;DR: 提出了一种新的协变量自适应随机化（CAR）方法，可在保持指定协变量平衡的同时，不增加未指定协变量的不平衡方差，优于简单随机化，且避免了“shift problem”。


<details>
  <summary>Details</summary>
Motivation: 现有CAR方法可能加剧未指定协变量的不平衡，导致治疗效应检验无效，调整困难。因此需要一种既能平衡关键协变量又不扩大其他协变量方差的新方法。

Method: 设计了一类新的CAR程序，用于在ρ:(1-ρ)比例下平衡两种治疗间的协变量，确保指定协变量的不平衡收敛速率为o(n^{1/2})，同时未指定协变量的渐近方差不超过简单随机化水平。

Result: 新CAR方法在理论上保证了指定协变量的良好平衡，且未指定协变量的不平衡方差不会膨胀，维持与简单随机化相当或更优水平，并避免了Liu, Hu, and Ma (2025)提出的“shift problem”。

Conclusion: 该新CAR方法在保持协变量平衡优势的同时，解决了未指定协变量方差膨胀的问题，使治疗效应的统计推断更为可靠，适用于更广泛的临床试验场景。

Abstract: Covariate adaptive randomization (CAR) procedures are extensively used to reduce the likelihood of covariate imbalances occurring in clinical trials. In literatures, a lot of CAR procedures have been proposed so that the specified covariates are balanced well between treatments. However, the variance of the imbalance of the unspecified covariates may be inflated comparing to the one under the simple randomization. The inflation of the variance causes the usual test of treatment effects being not valid and adjusting the test being not an easy work. In this paper, we propose a new kind covariate adaptive randomization procedures to balance covariates between two treatments with a ratio $ρ:(1-ρ)$. Under this kind of CAR procedures, the convergence rate of the imbalance of the specified covariates is $o(n^{1/2})$, and at the same time the asymptotic variance of the imbalance of any unspecified (observed or unobserved) covariates does not exceed the one under the simple randomization. The ``shift problem'' found by Liu, Hu, and Ma (2025) will not appear under the new CAR procedures.

</details>


### [76] [Nonparametric two sample test of spectral densities](https://arxiv.org/abs/2602.10774)
*Ilaria Nadin,Tatyana Krivobokova,Farida Enikeeva*

Main category: math.ST

TL;DR: 提出了一种新的非参数检验方法，用于检验两个高斯平稳过程协方差矩阵的相等性，并在模拟研究和真实脑电图数据分析中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了能够有效地检验可能长度不同的两个高斯平稳过程的协方差矩阵是否相等，提出了新的非参数检验方法。

Method: 将协方差矩阵相等性的检验转化为两个谱密度相等性的检验。

Result: 该检验方法被证明是最小最大速率最优的，在模拟研究中验证了检验性能，并通过分析真实的脑电图数据展示了其实用性。

Conclusion: 所提出的非参数检验方法在理论和实际应用中均表现出色，适用于不同长度的高斯平稳过程的协方差矩阵相等性检验。

Abstract: A novel nonparametric test for the equality of the covariance matrices of two Gaussian stationary processes, possibly of different lengths, is proposed. The test translates to testing the equality of two spectral densities and is shown to be minimax rate-optimal. Test performance is validated in a simulation study, and the practical utility is demonstrated in the analysis of real electroencephalography data. The test is implemented in the R-package sdf.test.

</details>


### [77] [Variational Optimality of Föllmer Processes in Generative Diffusions](https://arxiv.org/abs/2602.10989)
*Yifan Chen,Eric Vanden-Eijnden*

Main category: math.ST

TL;DR: 提出了一种基于随机插值框架的生成扩散模型，通过调节扩散系数在不改变时间边缘分布的情况下优化路径空间KL散度，证明了最优选择对应于Föllmer过程，并给出了其新的变分刻画。


<details>
  <summary>Details</summary>
Motivation: 旨在构建能将点质量输运到目标分布的生成扩散过程，并探索如何在有限时间内通过样本估计漂移项而不依赖复杂模拟。

Method: 利用随机插值框架表达漂移为条件期望，可从独立样本中估计；并研究扩散系数的事后调优对路径空间KL散度的影响。

Result: 证明在所有保持时间边缘分布不变的扩散系数中，最小化估计误差影响的选择对应一个Föllmer过程；且此时路径空间KL散度与插值调度无关。

Conclusion: 提供了Föllmer过程的新变分特征，补充了传统的Schrödinger桥和随机控制表述，并表明不同插值调度在最优扩散下具有统计等价性。

Abstract: We construct and analyze generative diffusions that transport a point mass to a prescribed target distribution over a finite time horizon using the stochastic interpolant framework. The drift is expressed as a conditional expectation that can be estimated from independent samples without simulating stochastic processes. We show that the diffusion coefficient can be tuned \emph{a~posteriori} without changing the time-marginal distributions. Among all such tunings, we prove that minimizing the impact of estimation error on the path-space Kullback--Leibler divergence selects, in closed form, a Föllmer process -- a diffusion whose path measure minimizes relative entropy with respect to a reference process determined by the interpolation schedules alone. This yields a new variational characterization of Föllmer processes, complementing classical formulations via Schrödinger bridges and stochastic control. We further establish that, under this optimal diffusion coefficient, the path-space Kullback--Leibler divergence becomes independent of the interpolation schedule, rendering different schedules statistically equivalent in this variational sense.

</details>


### [78] [A New Look at Bayesian Testing](https://arxiv.org/abs/2602.11132)
*Jyotishka Datta,Nicholas G. Polson,Vadim Sokolov,Daniel Zantedeschi*

Main category: math.ST

TL;DR: 本文通过中等偏差理论构建了贝叶斯假设检验的统一框架，揭示了贝叶斯检验在渐近风险和最优统计量方面的优势，并解释了Lindley悖论。


<details>
  <summary>Details</summary>
Motivation: 旨在统一贝叶斯假设检验的理论基础，解释经典检验与贝叶斯检验之间的根本差异，特别是Lindley悖论的成因。

Method: 利用中等偏差理论对贝叶斯风险进行渐近分析，推导出贝叶斯风险和最优检验统计量的显式展开式。

Result: 发现贝叶斯检验的阈值位于√(log n/n)的中等偏差尺度上，自然导出了Jeffreys阈值、BIC惩罚项和Chernoff-Stein指数等经典结果。

Conclusion: 贝叶斯方法在风险理论上优于经典的固定α检验，为自适应显著性水平提供了理论基础，并将贝叶斯检验与信息论联系起来。

Abstract: We develop a unified framework for Bayesian hypothesis testing through the theory of moderate deviations, providing explicit asymptotic expansions for Bayes risk and optimal test statistics. Our analysis reveals that Bayesian test cutoffs operate on the moderate deviation scale $\sqrt{\log n/n}$, in sharp contrast to the sample-size-invariant calibrations of classical testing. This fundamental difference explains the Lindley paradox and establishes the risk-theoretic superiority of Bayesian procedures over fixed-$α$ Neyman-Pearson tests. We extend the seminal Rubin (1965) program to contemporary settings including high-dimensional sparse inference, goodness-of-fit testing, and model selection. The framework unifies several classical results: Jeffreys' $\sqrt{\log n}$ threshold, the BIC penalty $(d/2)\log n$, and the Chernoff-Stein error exponents all emerge naturally from moderate deviation analysis of Bayes risk. Our results provide theoretical foundations for adaptive significance levels and connect Bayesian testing to information theory through gambling-based interpretations.

</details>


<div id='physics.hist-ph'></div>

# physics.hist-ph [[Back]](#toc)

### [79] [Between equilibrium and fluctuation: Einstein's heuristic argument and Boltzmann's principle](https://arxiv.org/abs/2602.10738)
*Enric Pérez,Antonio Gil*

Main category: physics.hist-ph

TL;DR: 重新审视爱因斯坦1905年关于光量子的启发式论证，揭示其内在逻辑的模糊性及其适用范围的局限性。


<details>
  <summary>Details</summary>
Motivation: 探讨爱因斯坦光量子理论的原始论证是否自洽，并分析其在电磁波谱中的推广限制。

Method: 通过历史与概念分析，结合玻尔兹曼原理的使用，评估爱因斯坦对辐射本质和概率角色的理解演变。

Result: 发现爱因斯坦的推理存在歧义，可被理解为涨落现象或平衡态之间的比较；推广光量子概念的关键参数是占据数而非频率。

Conclusion: 爱因斯坦的光量子论证虽具原创性，但其适用性受限于具体物理条件，需谨慎推广至整个电磁波谱。

Abstract: We critically revisit Einstein's 1905 heuristic argument for lightquanta, considering its internal coherence and the scope of its applicability. We argue that Einstein's reasoning, often celebrated for its originality, is ambiguous because it can be understood as a fluctuation or as a comparison between equilibrium states. A historical and conceptual analysis of Einstein's use of Boltzmann's principle in those years reveals his evolving stance on its meaning and the role of probability, as well as his persistent doubts about the nature of radiation. We use our analysis to examine the limitations of extending the notion of Einstein's lightquanta across the electromagnetic spectrum: the relevant parameter is not the frequency, but the occupancy number.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [80] [Multiconfiguration Pair-Density Functional Theory Calculations of Ground and Excited States of Complex Chemical Systems with Quantum Computers](https://arxiv.org/abs/2602.10435)
*Zhanou Liu,Yuhao Chen,Yingjin Ma,Xiao He,Yuxin Deng*

Main category: cs.CE

TL;DR: 提出了一种结合变分量子本征求解器与多组态对密度泛函理论的混合策略，有效分离静态和动态电子关联效应，在减少量子资源消耗的同时实现了化学精度。


<details>
  <summary>Details</summary>
Motivation: 准确描述复杂体系中的强电子关联是计算化学中的主要挑战，传统近似方法在处理总关联时往往需要过深的量子电路，难以在近期量子硬件上实现。

Method: 将变分量子本征求解器（VQE）与多组态对密度泛函理论（MC-PDFT）相结合，通过量子计算处理静态关联，利用经典密度泛函从约化密度矩阵中回收动态关联，并实现自洽轨道优化以降低量子资源开销。

Result: 在C₂平衡键长和苯激发能等标准测试中分别达到0.006 Å和0.048 eV的平均绝对误差；对于需大活性空间（48e, 42o）的Cr₂二聚体，即便存在硬件噪声，仍能获得合理的势能曲线并再现解离行为。

Conclusion: 分离静态与动态关联效应为在近期量子设备上实现可靠化学预测提供了一条切实可行的路径。

Abstract: Accurately describing strong electron correlation in complex systems remains a prominent challenge in computational chemistry as near-term quantum algorithms treating total correlation often require prohibitively deep circuits. Here we present a hybrid strategy combining the Variational Quantum Eigensolver with Multiconfiguration Pair-Density Functional Theory to efficiently decouple correlation effects. This approach confines static correlation to a compact multireference quantum state while recovering dynamic correlation through a classical on-top density functional using reduced-density information. By enabling self-consistent orbital optimization, the method significantly reduces quantum resource overheads without sacrificing physical rigor. We demonstrate chemical accuracy on standard benchmarks by reproducing C$_2$ equilibrium bond lengths and benzene excitation energies with mean absolute errors of 0.006 Å and 0.048 eV respectively. Most notably, for the strongly correlated Cr$_2$ dimer requiring a large complete active space (48e, 42o), the framework yields a bound potential-energy curve and recovers qualitative dissociation behavior despite realistic hardware noise. These results establish that separating correlation types provides a practical route to reliable predictions on near-term quantum hardware.

</details>


### [81] [Cross-Sectional Asset Retrieval via Future-Aligned Soft Contrastive Learning](https://arxiv.org/abs/2602.10711)
*Hyeongmin Lee,Chanyeol Choi,Jihoon Kwon,Yoon Kim,Alejandro Lopez-Lira,Wonbin Ahn,Yongjae Lee*

Main category: cs.CE

TL;DR: 提出了一种未来对齐的软对比学习框架FASCL，用于资产检索，通过利用未来收益相关性作为监督信号，在4229只美股中验证了其优于13种基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有资产检索方法依赖历史价格或行业分类，无法保证对未来行为的预测能力，因此需要一种与未来表现对齐的相似性度量方法。

Method: 提出Future-Aligned Soft Contrastive Learning (FASCL)，采用软对比损失函数，以资产对之间的未来回报相关性作为连续监督目标进行表示学习，并设计了评估协议来衡量检索结果是否具有相似的未来走势。

Result: 在4,229只美国股票上的实验表明，FASCL在所有未来行为指标上均一致优于13种基线方法。

Conclusion: FASCL能够更有效地识别在未来可能表现出相似回报的资产，提升了资产检索的前瞻性与实用性。

Abstract: Asset retrieval--finding similar assets in a financial universe--is central to quantitative investment decision-making. Existing approaches define similarity through historical price patterns or sector classifications, but such backward-looking criteria provide no guarantee about future behavior. We argue that effective asset retrieval should be future-aligned: the retrieved assets should be those most likely to exhibit correlated future returns. To this end, we propose Future-Aligned Soft Contrastive Learning (FASCL), a representation learning framework whose soft contrastive loss uses pairwise future return correlations as continuous supervision targets. We further introduce an evaluation protocol designed to directly assess whether retrieved assets share similar future trajectories. Experiments on 4,229 US equities demonstrate that FASCL consistently outperforms 13 baselines across all future-behavior metrics. The source code will be available soon.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [82] [Resilient Voltage Estimation for Battery Packs Using Self-Learning Koopman Operator](https://arxiv.org/abs/2602.10397)
*Sanchita Ghosh,Tanushree Roy*

Main category: eess.SY

TL;DR: 提出了一种基于Koopman算子的两阶段误差校正电压估计方案，用于在传感器攻击下实现电动汽车电池组的安全、高精度电压估计。


<details>
  <summary>Details</summary>
Motivation: 为应对云基电池管理系统中电压测量数据在传输过程中可能被篡改的问题，确保电动车双向充电的可靠性。

Method: 采用自学习Koopman算子框架，分两个阶段进行误差校正：第一阶段补偿Koopman近似误差，第二阶段通过经验策略或高斯过程回归方法恢复因缺乏高阶电池动态信息导致的误差。

Result: 在多种电池拓扑、充电设置、老化程度和攻击策略下，所提方法均实现了高精度的实时电压估计。

Conclusion: 该算法具有可扩展性和适应性，适用于不同电池配置和工况，无需大量数据或传感器冗余即可保障感知受损情况下的最优充电。

Abstract: Cloud-based battery management systems (BMSs) rely on real-time voltage measurement data to ensure coordinated bi-directional charging of electric vehicles (EVs) with vehicle-to-grid technology. Unfortunately, an adversary can corrupt the measurement data during transmission from the local-BMS to the cloud-BMS, leading to disrupted EV charging. Therefore, to ensure reliable voltage data under such sensor attacks, this paper proposes a two-stage error-corrected self-learning Koopman operator-based secure voltage estimation scheme for large-format battery packs. The first stage of correction compensates for the Koopman approximation error. The second stage aims to recover the error amassing from the lack of higher-order battery dynamics information in the self-learning feedback, using two alternative methods: an adaptable empirical strategy that uses cell-level knowledge of open circuit voltage to state-of-charge mapping for pack-level estimation, and a Gaussian process regression-based data-driven method that leverages minimal data-training. During our comprehensive case studies using the high-fidelity battery simulation package 'PyBaMM-liionpack', our proposed secure estimator reliably generated real-time voltage estimation with high accuracy under varying pack topologies, charging settings, battery age-levels, and attack policies. Thus, the scalable and adaptable algorithm can be easily employed to diverse battery configurations and operating conditions, without requiring significant modifications, excessive data or sensor redundancy, to ensure optimum charging of EVs under compromised sensing.

</details>


### [83] [Rapid Boundary Stabilization of Two-Dimensional Elastic Plates with In-Domain Aeroelastic Instabilities](https://arxiv.org/abs/2602.10567)
*Xingzhi Huang,Ji Wang*

Main category: eess.SY

TL;DR: 本文提出了一种针对二维偏微分方程建模的弹性板在域内不稳定情况下的快速边界稳定策略，应用于高马赫数飞行中的主动翼颤振抑制。通过PDE反步变换设计全状态反馈控制器，并结合状态观测器实现输出反馈，实现了可任意指定衰减速率的指数稳定性。


<details>
  <summary>Details</summary>
Motivation: 为解决高马赫数飞行中由于气动弹性效应引发的翼面颤振问题，需要对具有内部反阻尼特性的二维弹性板系统进行快速稳定控制。

Method: 采用活塞理论和哈密顿原理建立二维耦合波动偏微分方程模型；利用傅里叶级数展开将二维问题分解为一系列一维系统；基于PDE反步法设计全状态边界反馈控制器，并设计状态观测器以实现输出反馈控制；通过李雅普诺夫分析证明闭环系统的指数稳定性。

Result: 所提出的边界控制策略能够有效抑制流动诱导振动，数值模拟验证了该方法在不同模式下的控制性能，系统可实现用户指定的任意衰减速率。

Conclusion: 该研究成功实现了对具有域内不稳定的二维弹性板PDE系统的边界镇定，具备可调节的收敛速度，为高马赫数飞行器的主动颤振抑制提供了有效的控制方案。

Abstract: Motivated by active wing flutter suppression in high-Mach-number flight, this paper presents a rapid boundary stabilization strategy for a two-dimensional PDE-modeled elastic plate with in-domain instabilities, where the exponential stability is achieved with a decay rate that can be arbitrarily assigned by the users. First, the aeroelastic system is modeled as two-dimensional coupled wave PDEs with internal anti-damping terms, derived by Piston theory and Hamilton's principle. Using Fourier series expansion, the 2-D problem is decomposed into a parameterized family of 1-D systems. For each mode, a full-state boundary feedback controller is designed via PDE backstepping transformation. To enable output-feedback implementation, a state observer is further designed to estimate the distributed states over the two-dimensional spatial domain. Through Lyapunov analysis, the exponential stability of the 2-D elastic plate PDE under the proposed boundary control is established with a designer-tunable decay rate. Numerical simulations verify the effectiveness of the control strategy in suppressing flow-induced vibrations.

</details>


### [84] [Integrating Active Damping with Shaping-Filtered Reset Tracking Control for Piezo-Actuated Nanopositioning](https://arxiv.org/abs/2602.10724)
*Aditya Natu,Xiaozhe Hu,Hassan HosseinNia*

Main category: eess.SY

TL;DR: 本文提出了一种双环控制架构，结合内环的非最小相位谐振控制器和外环带复位机制的CgLp元件，用于提升压电纳米定位系统的带宽和跟踪性能，并通过滤波器抑制谐波影响，实验验证了性能提升。


<details>
  <summary>Details</summary>
Motivation: 为克服压电纳米定位系统中结构谐振和线性反馈增益-相位限制导致的带宽与跟踪性能不足问题。

Method: 采用双环架构：内环使用非最小相位谐振控制器（NRC）实现主动阻尼；外环采用带有常增益、相位超前（CgLp）复位元件的跟踪控制器，并在复位触发路径中引入整形滤波器以抑制高次谐波和多重复位行为。

Result: 在工业级压电纳米定位器上实现实时控制，相比优化的线性基线，开环 crossover 频率提高约55 Hz，闭环带宽提升约34 Hz。

Conclusion: 所提方法有效提升了系统带宽和跟踪精度，整形滤波器能有效抑制谐波干扰并维持相位恢复性能，适用于高性能纳米定位应用。

Abstract: Piezoelectric nanopositioning systems are often limited by lightly damped structural resonances and the gain--phase constraints of linear feedback, which restrict achievable bandwidth and tracking performance. This paper presents a dual-loop architecture that combines an inner-loop non-minimum-phase resonant controller (NRC) for active damping with an outer-loop tracking controller augmented by a constant-gain, lead-in-phase (CgLp) reset element to provide phase lead at the targeted crossover without increasing loop gain. We show that aggressively tuned CgLp designs with larger phase lead can introduce pronounced higher-order harmonics, degrading error sensitivity in specific frequency bands and causing multiple-reset behavior. To address this, a shaping filter is introduced in the reset-trigger path to regulate the reset action and suppress harmonic-induced effects while preserving the desired crossover-phase recovery. The proposed controllers are implemented in real time on an industrial piezo nanopositioner, demonstrating an experimental open-loop crossover increase of approximately 55~Hz and a closed-loop bandwidth improvement of about 34~Hz relative to a well-tuned linear baseline.

</details>


### [85] [Improving CACC Robustness to Parametric Uncertainty via Plant Equivalent Controller Realizations](https://arxiv.org/abs/2602.10752)
*Mischa Huisman,Thomas Arnold,Erjen Lefeber,Nathan van de Wouw,Carlos Murguia*

Main category: eess.SY

TL;DR: 本文提出了一种增强Cooperative Adaptive Cruise Control (CACC)鲁棒性的方法，通过显式建模参数不确定性下的系统失配，并利用L2轨迹匹配优化控制实现，在保持名义闭环性能的同时提升车队在非线性动态和参数不确定性下的稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 传统CACC依赖反馈线性化并假设车辆参数精确已知，但在实际中纵向动力学具有非线性和参数不确定性，导致模型失配和性能下降。因此需要提高CACC在参数不确定性下的鲁棒性。

Method: 将鲁棒性问题建模为L2轨迹匹配问题，最小化理想闭环动态与实际动态之间的失配能量；通过优化plant equivalent controller (PEC) 实现方式，在保持名义闭环行为的同时抑制参数不确定性的影响，并使用线性矩阵不等式（LMI）保证稳定性和性能，形成一个适用于异构车队的凸优化问题。

Result: 实验结果表明，所提方法在参数不确定性下显著提升了系统的鲁棒性和控制性能，同时保持了原有的CACC设计特性。

Conclusion: 该方法无需重新设计CACC控制律，即可有效应对参数不确定性带来的模型失配问题，增强了实际应用中车辆队列的稳定性与性能，具有良好的实用前景。

Abstract: Cooperative Adaptive Cruise Control (CACC) enables vehicle platooning through inter-vehicle communication, improving traffic efficiency and safety. Conventional CACC relies on feedback linearization, assuming exact vehicle parameters; however, longitudinal vehicle dynamics are nonlinear and subject to parametric uncertainty. Applying feedback linearization with a nominal model yields imperfect cancellation, leading to model mismatch and degraded performance with off-the-shelf CACC controllers. To improve robustness without redesigning the CACC law, we explicitly model the mismatch between the ideal closed-loop dynamics assumed by the CACC design and the actual dynamics under parametric uncertainties. Robustness is formulated as an $\mathcal{L}_2$ trajectory-matching problem, minimizing the energy of this mismatch to make the uncertain system behave as closely as possible to the ideal model. This objective is addressed by optimizing over plant equivalent controller (PEC) realizations that preserve the nominal closed-loop behavior while mitigating the effects of parametric uncertainty. Stability and performance are enforced via linear matrix inequalities, yielding a convex optimization problem applicable to heterogeneous platoons. Experimental results demonstrate improved robustness and performance under parametric uncertainty while preserving nominal CACC behavior.

</details>


### [86] [Singular Port-Hamiltonian Systems Beyond Passivity](https://arxiv.org/abs/2602.10855)
*Henrik Sandberg,Kamil Hassan,Heng Wu*

Main category: eess.SY

TL;DR: 研究一类具有奇异向量场的端口-哈密顿系统，揭示其在特定条件下如何通过不连续性提供能量以维持非平衡稳态，并分析其被动性特征。


<details>
  <summary>Details</summary>
Motivation: 探讨具有奇异性的端口-哈密顿系统在电力电子中的应用及其非平衡稳态行为背后的机理。

Method: 通过理论分析和系统互联方法，研究系统在不连续向量场下的收敛性和能量供给机制。

Result: 证明在一定条件下系统可收敛到预设的非平衡稳态，且不连续性提供了维持该状态所需的能量；用连续近似替代不连续性后系统呈现循环耗散特性但仍能供能。

Conclusion: 此类端口-哈密顿系统并非全局无源，其内在不连续性是实现非平衡运行的关键机制。

Abstract: In this paper, we study a class of port-Hamiltonian systems whose vector fields exhibit singularities. A representative example of this class has recently been employed in the power electronics literature to implement a grid-forming controller. We show that, under certain conditions, these port-Hamiltonian systems, when interconnected with passive systems, converge to a prescribed non-equilibrium steady state. At first glance, the apparently passive nature of the port-Hamiltonian system seems incompatible with the active power injection required to sustain this non-equilibrium condition. However, we demonstrate that the discontinuity inherent in the vector field provides the additional energy needed to maintain this operating point, indicating that the system is not globally passive. Moreover, when the discontinuity is replaced by a continuous approximation, the resulting system becomes cyclo-dissipative while still capable of supplying the required power.

</details>


### [87] [Backstepping Control of PDEs on Domains with Graph-Monotone Boundaries](https://arxiv.org/abs/2602.10876)
*Mohamed Camil Belhadjoudja*

Main category: eess.SY

TL;DR: 本文讨论了在非平行六面体区域上对高维PDE进行反步控制的问题，提出了一种无需域扩展方法的新策略，适用于具有图单调边界的区域。


<details>
  <summary>Details</summary>
Motivation: 现有的反步控制方法在处理非平行六面体或无对称性假设的高维PDE时存在局限，特别是域扩展方法计算复杂且难以拓展到输出反馈或自适应控制。因此需要一种能保留一维反步法优势的新方法。

Method: 通过一个简单计算表明，在钢琴形状区域上的热方程控制问题中，无需使用域扩展方法，可采用类似于平行六面体域的控制策略，并推广为适用于图单调边界区域的一般框架。

Result: 首次证明在非平行六面体、无对称性假设的区域上可以不依赖域扩展实现反步控制，提出并初步验证了适用于图单调边界区域的更广泛控制框架。

Conclusion: 该结果为高维PDE的反步控制提供了一个更具潜力和实用性的新方向，有望克服现有域扩展方法的多个缺陷。

Abstract: Despite the extensive body of work on backstepping for one-dimensional PDEs, results in higher dimensions remain comparatively limited. Most available methods either exploit particular symmetries of the PDE or address problems posed on parallelepiped domains. To the best of our knowledge, the only approach that enables the design of backstepping controllers on non-parallelepiped regions without symmetry assumptions is the domain extension technique. This method, however, presents several drawbacks. In particular, the control input at each time instant is obtained by simulating a PDE on an extended domain, from which the actual input on the original domain is approximated. By contrast, in the one-dimensional setting, once the time-independent backstepping gain kernel is known, the control input can be computed in closed form as a feedback depending solely on the state at that same instant. Moreover, problems such as output-feedback design or adaptive and robust control do not appear straightforward to address with the domain extension method, at least to the best of our knowledge. These considerations motivate the search, whenever possible, for alternatives that preserve the main advantages of one-dimensional backstepping. A motivating example for the domain extension method is the control of the heat equation on a piano-shaped domain, with actuation applied at the tail of the piano. In this extended abstract, we show through a simple calculation that the domain extension method is not required in this setting. Instead, a strategy akin to that used for parallelepiped domains can be adopted. This result constitutes a first instance of a broader framework for backstepping control of asymmetric PDEs posed on non-parallelepiped regions, which we refer to as domains with graph-monotone boundaries. The general framework is developed in a forthcoming paper.

</details>


### [88] [Trajectory-based data-driven predictive control and the state-space predictor](https://arxiv.org/abs/2602.10936)
*Levi D. Reyes Premer,Arash J. Khabbazi,Kevin J. Kircher*

Main category: eess.SY

TL;DR: 本文提出了轨迹预测控制（TPC），将其定义为一类基于输出反馈的间接数据驱动预测控制方法，并表明TPC涵盖多种现有DDPC方法；通过引入一种基于状态空间模型的轨迹预测器，TPC成为线性模型预测控制的特例，具有更少参数，在小训练数据集下表现更优，数值实验显示其性能接近理想H2最优控制。


<details>
  <summary>Details</summary>
Motivation: 旨在统一和扩展现有的数据驱动预测控制方法，提出更具通用性和理论基础的框架。

Method: 将系统输出轨迹表示为近期输入/输出历史和规划输入轨迹的线性函数，引入基于状态空间模型的轨迹预测器，使TPC成为线性MPC的特例。

Result: TPC涵盖了SPC、γ-DDPC等多种DDPC方法；在数值实验中，其性能接近已知系统模型的H2最优控制；在小数据集下由于参数更少而表现更优。

Conclusion: TPC提供了一个统一的数据驱动预测控制框架，结合状态空间预测器后具备良好理论基础和实际性能，尤其适用于数据有限的场景。

Abstract: We define trajectory predictive control (TPC) as a family of output-feedback indirect data-driven predictive control (DDPC) methods that represent the output trajectory of a discrete-time system as a linear function of the recent input/output history and the planned input trajectory. This paper shows that for different choices of the trajectory predictor, TPC encompasses a wide variety of DDPC methods, including subspace predictive control (SPC), closed-loop SPC, $γ$-DDPC, causal-$γ$-DDPC, transient predictive control, and others. This paper introduces a trajectory predictor that corresponds to a linear state-space model with the recent input/output history as the state. With this state-space predictor, TPC is a special case of linear model predictive control and therefore inherits its mature theory. In numerical experiments, TPC performance approaches the limit of oracle $H_2$-optimal control with perfect knowledge of the underlying system model. For TPC with small training datasets, the state-space predictor outperforms other predictors because it has fewer parameters.

</details>


### [89] [Lie Group Variational Integrator for the Geometrically Exact Rod with Circular Cross-Section Incorporating Cross-Sectional Deformation](https://arxiv.org/abs/2602.10963)
*Srishti Siddharth,Vivek Natarajan,Ravi N. Banavar*

Main category: eess.SY

TL;DR: 本文推导了包含平面截面变形的三维几何精确杆（Cosserat杆）的连续时空运动方程，并采用李群变分积分器技术建立了离散模型，该模型能保持体积守恒、旋转构型和能量守恒误差有界。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地模拟三维几何精确杆的动力学行为，特别是考虑截面变形的影响，从而提升建模的物理真实性与数值稳定性。

Method: 基于Cosserat杆理论推导连续运动方程，并采用李群变分积分器方法构建离散模型，引入局部膨胀因子以描述截面变形。

Result: 所提出的离散模型能够保持离散单元的体积守恒，具有良好的能量守恒性和旋转配置保持能力，在多种初始条件下均表现出优异的物理再现能力。

Conclusion: 该模型有效结合了截面变形与整体运动，具备变分积分器的优点，适用于高保真动力学仿真。

Abstract: In this paper, we derive the continuous space-time equations of motion of a three-dimensional geometrically exact rod, or the Cosserat rod, incorporating planar cross-sectional deformation. We then adopt the Lie group variational integrator technique to obtain a discrete model of the rod incorporating both rotational motion and cross-sectional deformation as well. The resulting discrete model possesses several desirable features: it ensures volume conservation of the discrete elements by considering cross-sectional deformation through a local dilatation factor, it demonstrates the beneficial properties associated with the variational integrator technique, such as the preservation of the rotational configuration, and energy conservation with a bounded error. An exhaustive set of numerical results under various initial conditions of the rod demonstrates the efficacy of the model in replicating the physics of the system.

</details>


### [90] [Credit-Based vs. Discount-Based Congestion Pricing: A Comparison Study](https://arxiv.org/abs/2602.11077)
*Chih-Yuan Chiu,Devansh Jalota,Marco Pavone*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Credit-based congestion pricing (CBCP) and discount-based congestion pricing (DBCP), which respectively allot travel credits and toll discounts to subsidize low-income users' access to tolled roads, have emerged as promising policies for alleviating the societal inequity concerns of congestion pricing. However, since real-world implementations of CBCP and DBCP are nascent, their relative merits remain unclear. In this work, we compare the efficacy of deploying CBCP and DBCP in reducing user costs and increasing toll revenues. We first formulate a non-atomic congestion game in which low-income users receive a travel credit or toll discount for accessing tolled lanes. We establish that, in our formulation, Nash equilibrium flows always exist and can be computed or well approximated via convex programming. Our main result establishes a set of practically relevant conditions under which DBCP provably outperforms CBCP in inducing equilibrium outcomes that minimize a given societal cost, which encodes user cost reduction and toll revenue maximization. Finally, we validate our theoretical contributions via a case study of the 101 Express Lanes Project, a CBCP program implemented in the San Francisco Bay Area.

</details>


### [91] [Multi-UAV Trajectory Optimization for Bearing-Only Localization in GPS Denied Environments](https://arxiv.org/abs/2602.11116)
*Alfonso Sciacchitano,Liraz Mudrik,Sean Kragelund,Isaac Kaminer*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate localization of maritime targets by unmanned aerial vehicles (UAVs) remains challenging in GPS-denied environments. UAVs equipped with gimballed electro-optical sensors are typically used to localize targets, however, reliance on these sensors increases mechanical complexity, cost, and susceptibility to single-point failures, limiting scalability and robustness in multi-UAV operations. This work presents a new trajectory optimization framework that enables cooperative target localization using UAVs with fixed, non-gimballed cameras operating in coordination with a surface vessel. This estimation-aware optimization generates dynamically feasible trajectories that explicitly account for mission constraints, platform dynamics, and out-of-frame events. Estimation-aware trajectories outperform heuristic paths by reducing localization error by more than a factor of two, motivating their use in cooperative operations. Results further demonstrate that coordinated UAVs with fixed, non-gimballed cameras achieve localization accuracy that meets or exceeds that of single gimballed systems, while substantially lowering system complexity and cost, enabling scalability, and enhancing mission resilience.

</details>
