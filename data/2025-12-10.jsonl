{"id": "2512.08099", "categories": ["math.NA", "cs.CV", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.08099", "abs": "https://arxiv.org/abs/2512.08099", "authors": ["Matthias Beckmann", "Robert Beinert", "Jonas Bresch"], "title": "Generalizations of the Normalized Radon Cumulative Distribution Transform for Limited Data Recognition", "comment": null, "summary": "The Radon cumulative distribution transform (R-CDT) exploits one-dimensional Wasserstein transport and the Radon transform to represent prominent features in images. It is closely related to the sliced Wasserstein distance and facilitates classification tasks, especially in the small data regime, like the recognition of watermarks in filigranology. Here, a typical issue is that the given data may be subject to affine transformations caused by the measuring process. To make the R-CDT invariant under arbitrary affine transformations, a two-step normalization of the R-CDT has been proposed in our earlier works. The aim of this paper is twofold. First, we propose a family of generalized normalizations to enhance flexibility for applications. Second, we study multi-dimensional and non-Euclidean settings by making use of generalized Radon transforms. We prove that our novel feature representations are invariant under certain transformations and allow for linear separation in feature space. Our theoretical results are supported by numerical experiments based on 2d images, 3d shapes and 3d rotation matrices, showing near perfect classification accuracies and clustering results."}
{"id": "2512.08142", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.08142", "abs": "https://arxiv.org/abs/2512.08142", "authors": ["Amy de Castro", "Hyesuk Lee"], "title": "Well-posedness of a novel Lagrange multiplier formulation for fluid-poroelastic interaction", "comment": null, "summary": "We introduce a novel monolithic formulation that employs Lagrange multipliers (LMs) to couple a fluid flow governed by the time-dependent Stokes equations with a poroelastic structure described by the Biot equations. The formulation is developed in detail, and we establish the well-posedness of both the semi-discrete and fully discrete saddle point problems. We further prove the stability of the fully discrete system. This saddle point formulation, which utilizes three LMs, is designed to enable a partitioned approach that completely decouples the Stokes and Biot subdomains, and this approach will be explored in a subsequent work."}
{"id": "2512.08178", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.08178", "abs": "https://arxiv.org/abs/2512.08178", "authors": ["Haonan Gu"], "title": "The Instability of Painlevé Equations in Recovering Largest Eigenvalue Distributions of GUE, LUE, JUE and an Attempt of Solution to It", "comment": null, "summary": "The distribution of the largest eigenvalue for the three classical unitary ensembles -- GUE, LUE, and JUE -- admits two complementary exact descriptions: (i) as Fredholm determinants of their orthogonal--polynomial correlation kernels and (ii) as isomonodromic $τ$--functions governed by Painlevé equations. For finite $n$, the associated Jimbo--Miwa--Okamoto $σ$--forms are $\\PIV$ (GUE), $\\mathrm{PV}$ (LUE), and $\\PVI$ (JUE); under soft- or hard-edge scalings these degenerate to $\\PII$ or $\\PIIIp$ descriptions of the Tracy--Widom and hard-edge laws \\cite{tracy1994level,forrester2003painleve,deift1999orthogonal}.\n  It is well known among random matrix theorists (for example Folkmar Bornemann) that the Fredholm determinant is a more numerically stable and accurate way to compute the CDF of the largest eigenvalue for GUE, LUE, JUE than direct Painlevé integration. The aim of this paper is not to improve on Fredholm methods, but to see to what extent one can numerically recover the \\emph{correct} Painlevé solution from finite-$n$ data and how unstable this reconstruction is. Numerically, we verify the equality between the Fredholm- and Painlevé-based CDFs by combining (a) high-accuracy Nyström discretizations of the finite-$n$ Fredholm determinants \\cite{bornemann2010numerical} with (b) an anchored, branch-locked integration of the $σ$--form ODEs, where anchors are extracted from local least-squares fits to $\\log\\det(I-\\mathsf K)$. Our results confirm agreement across GUE/LUE/JUE with precision of $O(10^{-3})$ to $O(10^{-5})$ (occasionally $O(10^{-2})$) and illustrate the finite-$n$ to scaling-limit transition. The theoretical connections to $τ$--functions and Virasoro constraints follow the framework of \\cite{adler2000random,forrester2003painleve}"}
{"id": "2512.08207", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.08207", "abs": "https://arxiv.org/abs/2512.08207", "authors": ["Jeremías Garay", "David Nolte", "Cristóbal Bertoglio"], "title": "Duct boundary conditions for incompressible fluid flows: finite element discretizations and parameter estimation in coronary blood flow", "comment": null, "summary": "3D-0D coupled flow models are widely used across many application fields but remain challenging to solve. Implicit coupling introduces non-local terms, whereas explicit coupling results in only conditionally stable schemes. Furthermore, incorporating inertial effects alongside viscous resistance enlarges the parameter space, making calibration more difficult.\n  In this work, we propose a new type of boundary condition based on the method of asymptotic partial decomposition of a domain (MAPDD), which we denote as the Duct Boundary Condition (DuBC). This approach enables the incorporation of geometrically reduced domains as a boundary term with only local coupling in the implicit case. Moreover, the DuBC accounts for both viscous and inertial effects simultaneously using a single physical parameter. Additionally, we derive a fractional-step time-marching scheme including the DuBC. We demonstrate the features of the DuBC in coronary artery blood flow simulations, including sequential parameter estimation from noisy velocity data."}
{"id": "2512.08103", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.08103", "abs": "https://arxiv.org/abs/2512.08103", "authors": ["Hamidreza Moradi", "Melika Filvantorkaman"], "title": "Broadband Thermoelectric Energy Harvesting for Wearable Biosensors Using Plasmonic Field-Enhancement and Machine-Learning-Guided Device Optimization", "comment": "7 Figure, 35 pages", "summary": "Wearable biosensors increasingly require continuous and battery-free power sources, but conventional skin-mounted thermoelectric generators are limited by the small temperature differences available in real environments. This work introduces a hybrid thermoplasmonic and thermoelectric energy harvester that combines multiband plasmonic absorption with machine-learning-guided optimization to improve on-body energy conversion. A broadband metasurface made of cross-bowtie nanoantennas is designed to absorb infrared radiation across the 2 to 12 micron range, capturing human body emission, ambient infrared radiation, and near-infrared sunlight. Electromagnetic simulations show strong field enhancement in nanoscale antenna gaps, producing localized thermoplasmonic heating directly above flexible Bi2Te3 thermoelectric junctions. Coupled optical, thermal, and electrical modeling indicates that this localized heating increases the effective temperature difference from the typical 3 to 4 degrees C of standard wearable thermoelectric generators to approximately 13 degrees C. This results in a power density of about 0.15 mW per cm^2 under indoor-relevant infrared flux, representing a four- to six-fold improvement over existing flexible devices. A machine-learning surrogate model trained on multiphysics data predicts temperature rise and electrical output with high accuracy (R2 greater than 0.92) and identifies optimal device geometries through Pareto-front analysis. The proposed hybrid thermoplasmonic, thermoelectric, and machine-learning framework provides a scalable route toward more efficient, compact, and flexible energy harvesters for autonomous and long-term wearable physiological monitoring."}
{"id": "2512.07973", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.07973", "abs": "https://arxiv.org/abs/2512.07973", "authors": ["Mithun Kumar Acharjee", "AKM Fazlur Rahman"], "title": "Bayesian Semiparametric Joint Dynamic Model for Multitype Recurrent Events and a Terminal Event", "comment": "30 pages, 4 tables, 4 figures, prepared for Statistics in Medicine", "summary": "In many biomedical research, recurrent events such as myocardial infraction, stroke, and heart failure often result in a terminal outcome such as death. Understanding the relationship among the multi-type recurrent events and terminal event is essential for developing interventions to prolong the terminal event such as death. This study introduces a Bayesian semiparametric joint dynamic model for type-specific hazards that quantifies how the type-specific event history dynamically changes the intensities of each recurrent event type and the terminal event over calendar time. The framework jointly captures unmeasured heterogeneity through a shared frailty term, cumulative effects of past recurrent events on themselves and terminal events, and the effects of covariates. Gamma process priors (GPP) are used as a nonparametric prior for the baseline cumulative hazard function (CHF) and parametric priors for covariates and frailty. For a more accurate risk assessment, this model provides an analytical closed-form estimator of cumulative hazard functions (CHF) and frailties. The Breslow-Aalen-type estimators of CHFs are special cases of our estimators when the precision parameters are set to zero. We evaluate the performance of the model through extensive simulations and apply the method to the Antihypertensive and Lipid-Lowering Treatment to Prevent Heart Attack Trial (ALLHAT). The analysis offers a practical past event effect based risk assessment for acute and chronic cardiovascular recurrent events with a terminal end point death and provides new information to support the prevention and treatment of cardiovascular disease to clinicians."}
{"id": "2512.08167", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08167", "abs": "https://arxiv.org/abs/2512.08167", "authors": ["Alexander Rogozin", "Nhat Trung Nguyen", "Hamed Azami Zenuzagh", "Alexander Gasnikov"], "title": "Dual Smoothing for Decentralized Optimization", "comment": null, "summary": "Decentralized optimization is widely used in different fields of study such as distributed learning, signal processing, and various distributed control problems. In these types of problems, nodes of the network are connected to each other and seek to optimize some objective function. In this article, we present a method for smoothing the non-smooth and non-strongly convex problems. This is done using the dual smoothing technique. We study two types of problems: consensus optimization of linear models and coupled constraints optimization. It is shown that these two problem classes are dual to each other."}
{"id": "2512.07870", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.07870", "abs": "https://arxiv.org/abs/2512.07870", "authors": ["Yurii Volkov", "Oleksandr Volkov"], "title": "Mixed Exponential Statistical Structures and Their Approximation Operators", "comment": "12 pages", "summary": "The paper examines the construction and analysis of a new class of mixed exponential statistical structures that combine the properties of stochastic models and linear positive operators.The relevance of the topic is driven by the growing need to develop a unified theoretical framework capable of describing both continuous and discrete random structures that possess approximation properties. The aim of the study is to introduce and analyze a generalized family of mixed exponential statistical structures and their corresponding linear positive operators, which include known operators as particular cases. We define auxiliary statistical structures B and H through differential relations between their elements, and construct the main Phillips-type structure. Recurrent relations for the central moments are obtained, their properties are established, and the convergence and approximation accuracy of the constructed operators are investigated. The proposed approach allows mixed exponential structures to be viewed as a generalization of known statistical systems, providing a unified analytical and stochastic description. The results demonstrate that mixed exponential statistical structures can be used to develop new classes of positive operators with controllable preservation and approximation properties. The proposed methodology forms a basis for further research in constructing multidimensional statistical structures, analyzing operators in weighted spaces, and studying their asymptotic characteristics."}
{"id": "2512.07899", "categories": ["cs.SI", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.07899", "abs": "https://arxiv.org/abs/2512.07899", "authors": ["Juan Zhao", "Jicheng Ma", "Yunyan Yang", "Liang Zhao"], "title": "Finding core subgraphs of directed graphs via discrete Ricci curvature flow", "comment": "21 pages", "summary": "Ricci curvature and its associated flow offer powerful geometric methods for analyzing complex networks. While existing research heavily focuses on applications for undirected graphs such as community detection and core extraction, there have been relatively less attention on directed graphs.\n  In this paper, we introduce a definition of Ricci curvature and an accompanying curvature flow for directed graphs. Crucially, for strongly connected directed graphs, this flow admits a unique global solution. We then apply this flow to detect strongly connected subgraphs from weakly connected directed graphs. (A weakly connected graph is connected overall but not necessarily strongly connected). Unlike prior work requiring graphs to be strongly connected, our method loosens this requirement. We transform a weakly connected graph into a strongly connected one by adding edges with very large artificial weights. This modification does not compromise our core subgraph detection. Due to their extreme weight, these added edges are automatically discarded during the final iteration of the Ricci curvature flow.\n  For core evaluation, our approach consistently surpasses traditional methods, achieving better results on at least two out of three key metrics. The implementation code is publicly available at https://github.com/12tangze12/Finding-core-subgraphs-on-directed-graphs."}
{"id": "2512.07871", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07871", "abs": "https://arxiv.org/abs/2512.07871", "authors": ["Andrew Kiruluta"], "title": "Quantum Circuit Reasoning Models: A Variational Framework for Differentiable Logical Inference", "comment": null, "summary": "This report introduces a novel class of reasoning architectures, termed Quantum Circuit Reasoning Models (QCRM), which extend the concept of Variational Quantum Circuits (VQC) from energy minimization and classification tasks to structured logical inference and reasoning. We posit that fundamental quantum mechanical operations, superposition, entanglement, interference, and measurement, naturally map to essential reasoning primitives such as hypothesis branching, constraint propagation, consistency enforcement, and decision making. The resulting framework combines quantum-inspired computation with differentiable optimization, enabling reasoning to emerge as a process of amplitude evolution and interference-driven selection of self-consistent states. We develop the mathematical foundation of QCRM, define its parameterized circuit architecture, and show how logical rules can be encoded as unitary transformations over proposition-qubit states. We further formalize a training objective grounded in classical gradient descent over circuit parameters and discuss simulation-based implementations on classical hardware. Finally, we propose the Quantum Reasoning Layer (QRL) as a differentiable hybrid component for composable reasoning models applicable to scientific, biomedical, and chemical inference domains."}
{"id": "2512.07980", "categories": ["cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.07980", "abs": "https://arxiv.org/abs/2512.07980", "authors": ["Xiaoyang Huang", "Zohar Komargodski", "Andrew Lucas", "Fedor K. Popov", "Tin Sulejmanpasic"], "title": "Minimal Models of Entropic Order", "comment": "11 pages, 5 figures", "summary": "Due to entropic effects, it is possible that generic high-energy states of a quantum or classical system are ordered. This leads to spontaneous symmetry breaking at arbitrarily high temperatures. We present minimal models of entropic order that arise from very simple interactions. Our main examples are the Arithmetic Ising Model (AIM) and its quantum analogue, where usual Ising spins are replaced by non-negative integers. Using a large-flavor expansion together with numerical simulations, we find that the high-temperature phase is ordered in the classical and quantum models. We also introduce classical gas models whose interactions drive the system to a crystal at high temperatures."}
{"id": "2512.08010", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08010", "abs": "https://arxiv.org/abs/2512.08010", "authors": ["Yeongjun Jang", "Sangwon Lee", "Junsoo Kim"], "title": "Sensor Attack Detection Method for Encrypted State Observers", "comment": "Submitted to IFAC World Congress 2026", "summary": "This paper proposes an encrypted state observer that is capable of detecting sensor attacks without decryption. We first design a state observer that operates over a finite field of integers with the modular arithmetic. The observer generates a residue signal that indicates the presence of attacks under sparse attack and sensing redundancy conditions. Then, we develop a homomorphic encryption scheme that enables the observer to operate over encrypted data while automatically disclosing the residue signal. Unlike our previous work restricted to single-input single-output systems, the proposed scheme is applicable to general multi-input multi-output systems. Given that the disclosed residue signal remains below a prescribed threshold, the full state can be recovered as an encrypted message."}
{"id": "2512.07916", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.07916", "abs": "https://arxiv.org/abs/2512.07916", "authors": ["E. V. Vasinovich", "V. A. Ulitko", "A. S. Moskvin"], "title": "Monte Carlo simulation of spin-reorientation transition in weak ferrimagnets YFeCrO3", "comment": null, "summary": "This work presents the modeling of the magnetic 3d sublattice in mixed orthoferrites-orthochromites YFe1-xCrxO3 using classical Monte Carlo methods. It is shown that, when taking into account the competition of the Dzyaloshinskii vectors in the mixed compositions, magnetic moment compensations are observed, as well as angular magnetic configurations corresponding to the spin reorientation."}
{"id": "2512.08044", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.08044", "abs": "https://arxiv.org/abs/2512.08044", "authors": ["A. V. Levin", "P. M. Ostrovsky"], "title": "Effect of superconductivity on non-uniform magnetization in dirty SF junctions", "comment": "12 pages, 6 figures", "summary": "We study proximity effect in a tunnel junction between a bulk superconductor and a thin disordered ferromagnetic layer on its surface. Cooper pairs penetrating from the superconductor into the ferromagnet tend to destabilize its uniform magnetic order. The competition of this effect and the intrinsic magnetic stiffness of the ferromagnet leads to a second order phase transition between uniform and non-uniform magnetic states. Using the quasiclassical Usadel equation, we derive the Landau functional for this transition and construct the complete phase diagram of the effect. We identify a special point of \"resonance\" at which the characteristic energy scale of the proximity effect equals the exchange field of the ferromagnet. At this point, the uniform magnetic state is unstable even in the limit of large stiffness. We further explore the parameter regime far beyond the transition and determine the properties of the resulting strongly non-uniform magnetic state."}
{"id": "2512.07860", "categories": ["q-fin.ST", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07860", "abs": "https://arxiv.org/abs/2512.07860", "authors": ["Mohammed Alruqimi", "Luca Di Persio"], "title": "Integrating LSTM Networks with Neural Levy Processes for Financial Forecasting", "comment": null, "summary": "This paper investigates an optimal integration of deep learning with financial models for robust asset price forecasting. Specifically, we developed a hybrid framework combining a Long Short-Term Memory (LSTM) network with the Merton-Lévy jump-diffusion model. To optimise this framework, we employed the Grey Wolf Optimizer (GWO) for the LSTM hyperparameter tuning, and we explored three calibration methods for the Merton-Levy model parameters: Artificial Neural Networks (ANNs), the Marine Predators Algorithm (MPA), and the PyTorch-based TorchSDE library. To evaluate the predictive performance of our hybrid model, we compared it against several benchmark models, including a standard LSTM and an LSTM combined with the Fractional Heston model. This evaluation used three real-world financial datasets: Brent oil prices, the STOXX 600 index, and the IT40 index. Performance was assessed using standard metrics, including Mean Squared Error (MSE), Mean Absolute Error(MAE), Mean Squared Percentage Error (MSPE), and the coefficient of determination (R2). Our experimental results demonstrate that the hybrid model, combining a GWO-optimized LSTM network with the Levy-Merton Jump-Diffusion model calibrated using an ANN, outperformed the base LSTM model and all other models developed in this study."}
{"id": "2512.08009", "categories": ["cs.ET", "cs.HC", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.08009", "abs": "https://arxiv.org/abs/2512.08009", "authors": ["Ava Hays", "Nolan Kosnic", "Ryan Miller", "Kunal Siddhawar"], "title": "Resonant and Stochastic Vibration in Neurorehabilitation", "comment": "8 pages, 6 figures", "summary": "Neurological injuries and age-related decline can impair sensory processing and disrupt motor coordination, gait, and balance. As mechanisms of neuroplasticity have become better understood, vibration-based interventions have gained attention as potential tools to stimulate sensory pathways and motor circuits to support functional recovery. This survey reviews stochastic and resonant vibration modalities, describing their mechanisms, therapeutic rationales, and clinical applications. We synthesize evidence on whole-body vibration for improving balance, mobility, and fine motor function in aging adults, stroke survivors, and individuals with Parkinson's disease, with attention to challenges in parameter optimization, generalizability, and safety. We also assess recent developments in focused muscle vibration and wearable stochastic resonance devices for upper-limb rehabilitation, evaluating their clinical promise along with limitations in scalability, ecological validity, and standardization. Across these modalities, we identify key variables that shape therapeutic outcomes and highlight ongoing efforts to refine protocols, improve usability, and integrate vibration techniques into broader neurorehabilitation frameworks. We conclude by outlining the most important research needs for translating vibration-based interventions into reliable and deployable clinical tools."}
{"id": "2512.08010", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08010", "abs": "https://arxiv.org/abs/2512.08010", "authors": ["Yeongjun Jang", "Sangwon Lee", "Junsoo Kim"], "title": "Sensor Attack Detection Method for Encrypted State Observers", "comment": "Submitted to IFAC World Congress 2026", "summary": "This paper proposes an encrypted state observer that is capable of detecting sensor attacks without decryption. We first design a state observer that operates over a finite field of integers with the modular arithmetic. The observer generates a residue signal that indicates the presence of attacks under sparse attack and sensing redundancy conditions. Then, we develop a homomorphic encryption scheme that enables the observer to operate over encrypted data while automatically disclosing the residue signal. Unlike our previous work restricted to single-input single-output systems, the proposed scheme is applicable to general multi-input multi-output systems. Given that the disclosed residue signal remains below a prescribed threshold, the full state can be recovered as an encrypted message."}
{"id": "2512.08158", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.08158", "abs": "https://arxiv.org/abs/2512.08158", "authors": ["Ziyan Zhao", "Ting Peng", "Peng Wu", "Chaojun Hu", "Qilin Yi", "Chuangrui Huang", "Junjie Niu", "Xiaoxue Xu", "Tao Li", "Yuan Li"], "title": "Seasonal thermal stress analysis of defective mass concrete sidewalls based on the average forming temperature method", "comment": null, "summary": "Thermal cracking in urban underground sidewalls is frequently observed when structures are cast in summer and enter service in winter, as seasonal temperature gradients act under structural restraint. To quantify the local stress field associated with pre-existing cracks, an orthogonal finite-element simulation matrix of 16 combinations is constructed. Distributions of maximum principal stress () at the surface crack tip and along the upper half of the crack bottom are evaluated using steady-state thermal loading and a linear-elastic constitutive model. Across all cases, pronounced tensile stress concentration occurs at both locations: the maximum ranges from 19.2 to 34.1 MPa at the crack surface end and from 17.2 to 29.4 MPa at the crack bottom. These concentrated values are consistently higher than the stress level at the same locations in an otherwise identical uncracked wall, clarifying how seasonal temperature gradients under restraint amplify local stresses around existing defects. The quantitative ranges reported here provide a basis for risk screening and for formulating practical mitigation measures (e.g., joint spacing and insulation strategies) in the design and operation of urban underground enclosure walls. In addition, three-dimensional simulations of randomly distributed internal voids show that adopting average forming temperature increases the peak tensile stress on void surfaces from 3.42 to 4.40 MPa at 10 deg C and from 5.98 to 6.96 MPa at -5 deg C, further highlighting the risk amplification effect of AFT under cold service conditions."}
{"id": "2512.08353", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08353", "abs": "https://arxiv.org/abs/2512.08353", "authors": ["Ruo Li", "Haoyang Liu", "Jun Yin"], "title": "A reconstructed discontinuous approximation for distributed elliptic control problems", "comment": "21 pages, 26 figures", "summary": "In this paper, we present and analyze an internal penalty discontinuous Galerkin method for the distributed elliptic optimal control problems. It is based on a reconstructed discontinuous approximation which admits arbitrarily high-order approximation space with only one unknown per element. Applying this method, we develop a proper discretization scheme that approximates the state and adjoint variables in the approximation space. Our main contributions are twofold: (1) the derivation of both a priori and a posteriori error estimates of the $L^2$-norm and the energy norms, and (2) the implementation of an efficiently solvable discrete system, which is solved via a linearly convergent projected gradient descent method. Numerical experiments are provided to verify the convergence order in a priori estimate and the efficiency of a posteriori error estimate."}
{"id": "2512.08336", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.08336", "abs": "https://arxiv.org/abs/2512.08336", "authors": ["Aobo Yang", "Zhen Wei", "Rhea Liem", "Pascal Fua"], "title": "Dflow-SUR: Enhancing Generative Aerodynamic Inverse Design using Differentiation Throughout Flow Matching", "comment": null, "summary": "Generative inverse design requires incorporating physical constraints to ensure that generated designs are both reliable and accurate. However, we observe that current state-of-the-art energy-based methods suffer from an asynchronous phenomenon, where the optimization of the physical loss is constrained by the flow matching inference process. To overcome this limitation, we introduce Dflow-SUR, a differentiation strategy that separates the optimization of the physical loss from the flow matching inference.\n  Compared to the most advanced energy-based baseline, Dflow-SUR achieves a reduction in physical loss by four orders of magnitude, while also cutting wall-clock time by 74% on the airfoil case. Additionally, it increases the mean lift-to-drag ratio by 11.8% over traditional Latin-hypercube sampling in wing design. Beyond improvements in accuracy and efficiency, Dflow-SUR offers three additional practical advantages: (i) enhanced control over guidance, (ii) lower surrogate uncertainty, and (iii) greater robustness to hyper-parameter tuning.\n  Together, these results demonstrate that Dflow-SUR is a highly promising framework, providing both scalability and high fidelity for generative aerodynamic design."}
{"id": "2512.08118", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08118", "abs": "https://arxiv.org/abs/2512.08118", "authors": ["Wookyeong Song", "Hans-Georg Müller"], "title": "ADOPT: Additive Optimal Transport Regression", "comment": "19 pages, 2 figures", "summary": "Regression analysis for responses taking values in general metric spaces has received increasing attention, particularly for settings with Euclidean predictors $X \\in \\mathbb{R}^p$ and non-Euclidean responses $Y \\in ( \\mathcal{M}, d)$. While additive regression is a powerful tool for enhancing interpretability and mitigating the curse of dimensionality in the presence of multivariate predictors, its direct extension is hindered by the absence of vector space operations in general metric spaces. We propose a novel framework for additive optimal transport regression, which incorporates additive structure through optimal geodesic transports. A key idea is to extend the notion of optimal transports in Wasserstein spaces to general geodesic metric spaces. This unified approach accommodates a wide range of responses, including probability distributions, symmetric positive definite (SPD) matrices with various metrics and spherical data. The practical utility of the method is illustrated with correlation matrices derived from resting state fMRI brain imaging data."}
{"id": "2512.08205", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08205", "abs": "https://arxiv.org/abs/2512.08205", "authors": ["Xiushan Jiang", "Dong Wang", "Weihai Zhang", "Daniel W. C. Ho", "Yuanqing Wu"], "title": "Primal-dual policy learning for mean-field stochastic LQR problem", "comment": null, "summary": "Integrating data-driven techniques with mechanism-driven insights has recently gained popularity as a powerful learning approach to solving traditional LQR problems for designing intelligent controllers in complex dynamic systems. However, the theoretical understanding of various reinforcement learning algorithms needs further exploration to enhance their efficiency and safety. In this article, by means of primal-dual optimization tools, we study the partially model-free design of the mean-field stochastic LQR (MF-SLQR) controller using a policy learning approach. Firstly, by designing appropriate optimizing variables, the considered MF-SLQR problem is transformed into a new static nonconvex constrained optimization problem with equivalence preserved in certain senses. After that, the equivalent formulation of the duality results is constructed via finding the solution of the generalized Lyapunov equation. Then, the strong duality is analyzed, based on which we establish a primal-dual algorithm by Karush-Kuhn-Tucker conditions. More importantly, a partially model-free implementation is also presented, which has a direct connection with the classical policy iteration algorithm. Finally, we use a high-dimensional example to validate our methods."}
{"id": "2512.08002", "categories": ["math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.08002", "abs": "https://arxiv.org/abs/2512.08002", "authors": ["M. P. Savelov"], "title": "The limit joint distributions of some statistics used in testing the quality of random number generators", "comment": null, "summary": "The limit joint distribution of statistics that are generalizations of some statistics from the NIST STS, TestU01, and other packages is found under the following hypotheses $H_0$ and $H_1$. Hypothesis $H_0$ states that the tested sequence is a sequence of independent random vectors with a known distribution, and the simple alternative hypothesis $H_1$ converges in some sense to $H_0$ with increasing sample size. In addition, an analogue of the Berry-Esseen inequality is obtained for the statistics under consideration, and conditions for their asymptotic independence are found."}
{"id": "2512.08045", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.08045", "abs": "https://arxiv.org/abs/2512.08045", "authors": ["Kester Wong", "Feng Shihui", "Sahan Bulathwela", "Mutlu Cukurova"], "title": "Scaffolding Reshapes Dialogic Engagement in Collaborative Problem Solving: Comparative Analysis of Two Approaches", "comment": "Accepted for 16th International Conference on Learning Analytics & Knowledge 2026 (LAK 2026), 27 April - 1 May 2026, Bergen, Norway. 22 pages, 7 figures, 1 table", "summary": "Supporting learners during Collaborative Problem Solving (CPS) is a necessity. Existing studies have compared scaffolds with maximal and minimal instructional support by studying their effects on learning and behaviour. However, our understanding of how such scaffolds could differently shape the distribution of individual dialogic engagement and behaviours across different CPS phases remains limited. This study applied Heterogeneous Interaction Network Analysis (HINA) and Sequential Pattern Mining (SPM) to uncover the structural effects of scaffolding on different phases of the CPS process among K-12 students in authentic educational settings. Students with a maximal scaffold demonstrated higher dialogic engagement across more phases than those with a minimal scaffold. However, they were extensively demonstrating scripting behaviours across the phases, evidencing the presence of overscripting. Although students with the minimal scaffold demonstrated more problem solving behaviours and fewer scripting behaviours across the phases, they repeated particular behaviours in multiple phases and progressed more to socialising behaviours. In both scaffold conditions, problem solving behaviours rarely progressed to other problem solving behaviours. The paper discusses the implications of these findings for scaffold design and teaching practice of CPS, and highlights the distinct yet complementary value of HINA and SPM approaches to investigate students' learning processes during CPS."}
{"id": "2512.07902", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07902", "abs": "https://arxiv.org/abs/2512.07902", "authors": ["Kagwe A. Muchane"], "title": "The State-Operator Clifford Compatibility: A Real Algebraic Framework for Quantum Information", "comment": "3 pages, 1 figure. Short expository note; expanded version in preparation", "summary": "We revisit the Pauli-Clifford connection to introduce a real, grade-preserving algebraic framework for $N$-qubit quantum computation based on the tensor product structure $C\\ell_{2,0}(\\mathbb{R})^{\\otimes N}$. In this setting the bivector $J = e_{12}$ satisfies $J^{2} = -1$ and supplies the complex structure on a minimal left ideal via right-multiplication, while Pauli operations arise as left actions of suitable Clifford elements. Adopting a canonical stabilizer mapping, the $N$-qubit computational basis state $|0\\cdots 0\\rangle$ is represented natively by a tensor product of real algebraic idempotents. This structural choice leads to a State-Operator Clifford Compatibility law that is stable under the geometric product for $N$ qubits and aligns symbolic Clifford multiplication with unitary evolution on the Hilbert space."}
{"id": "2512.08011", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08011", "abs": "https://arxiv.org/abs/2512.08011", "authors": ["Francisco C. Alcaraz"], "title": "Free fermionic and parafermionic multispin quantum chains with non-homogeneous interacting ranges", "comment": "12 pages, 15 figures", "summary": "A large family of multispin interacting one-dimensional quantum spin models with $Z(N)$ symmetry and a free-particle eigenspectra are known in the literature. They are free-fermionic ($N=2$) and free-parafermionic ($N\\geq 2$) quantum chains. The essential ingredient that implies the free-particle spectra is the fact that these Hamiltonians are expressed in terms of generators of a $Z(N)$ exchange algebra. In all these known quantum chains the number of spins in all the multispin interactions (range of interactions) is the same and therefore, the models have homogeneous interacting range. In this paper we extend the $Z(N)$ exchange algebra, by introducing new models with a free-particle spectra, where the interaction ranges of the multispin interactions are not uniform anymore and depends on the lattice sites (non-homogeneous interacting range). We obtain the general conditions that the site-dependent ranges of the multispin interactions have to satisfy to ensure a free-particle spectra. Several simple examples are introduced. We study in detail the critical properties in the case where the range of interactions of the even (odd) sites are constant. The dynamical critical exponent is evaluated in several cases."}
{"id": "2512.08013", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08013", "abs": "https://arxiv.org/abs/2512.08013", "authors": ["Robert Lefringhausen", "Theodor Springer", "Sandra Hirche"], "title": "Learning Dynamics from Infrequent Output Measurements for Uncertainty-Aware Optimal Control", "comment": "Submitted to the 2026 IFAC World Congress", "summary": "Reliable optimal control is challenging when the dynamics of a nonlinear system are unknown and only infrequent, noisy output measurements are available. This work addresses this setting of limited sensing by formulating a Bayesian prior over the continuous-time dynamics and latent state trajectory in state-space form and updating it through a targeted marginal Metropolis-Hastings sampler equipped with a numerical ODE integrator. The resulting posterior samples are used to formulate a scenario-based optimal control problem that accounts for both model and measurement uncertainty and is solved using standard nonlinear programming methods. The approach is validated in a numerical case study on glucose regulation using a Type 1 diabetes model."}
{"id": "2512.07923", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.07923", "abs": "https://arxiv.org/abs/2512.07923", "authors": ["Souta Shimozono", "Chisa Hotta"], "title": "Environment-matrix-product operator for boundary-free large-scale quantum many-body simulations", "comment": "7pages, 4figures", "summary": "We propose an alternative to the infinite density-matrix renormalization approach for accessing quantum many-body states within a finite-size calculation that faithfully mimics the thermodynamic limit. Our method constructs environment matrix product operators (MPOs) representing the Hamiltonian of semi-infinite regions surrounding the target system. Starting from the finite-size ground-state MPS, we contract its Hamiltonian representation to generate effective environment MPOs, which are then attached to a renewed finite system in a recursive manner. This iterative embedding drives the system toward a bulk-like state with negligible finite-size effects. The scheme requires no assumption of homogeneity and achieves unprecedentedly long real-time dynamics free from boundary reflections."}
{"id": "2512.08396", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.08396", "abs": "https://arxiv.org/abs/2512.08396", "authors": ["Barbara Baldoni", "Mickaël Delcey", "Yoann Cheny", "Adrien Gans", "Mathieu Jenny", "Sébastien Kiesgen de Richter"], "title": "Rheological Parameter Identification in Granular Materials Using Physics-Informed Neural Networks", "comment": "10 pages, 7 figures", "summary": "Physics-Informed Neural Networks (PINNs) have recently emerged as a promising tool for fluid dynamics, particularly for flow reconstruction and parameter identification. In the context of granular media, accurately estimating rheological parameters remains a major challenge, as it typically requires complex and costly experimental setups. In this work, we propose a PINN-based approach to identify key rheological parameters of granular materials using a simple experiment: the granular column collapse. A proof of concept is presented using synthetic data, where the PINN is trained to infer the flow fields while simultaneously recovering the rheological parameters. Beyond parameter identification, the method also enables reconstruction of the pressure field, which is difficult to access experimentally. The results highlight the potential of PINNs for data-driven rheometry of granular materials and open perspectives for future applications with real experimental data."}
{"id": "2512.07886", "categories": ["q-fin.ST", "q-fin.GN", "q-fin.PR"], "pdf": "https://arxiv.org/pdf/2512.07886", "abs": "https://arxiv.org/abs/2512.07886", "authors": ["Hamoon Soleimani"], "title": "The Endogenous Constraint: Hysteresis, Stagflation, and the Structural Inhibition of Monetary Velocity in the Bitcoin Network (2016-2025)", "comment": "42 pages, 13 figures. JEL Classification: E41, E51, G15, C24", "summary": "Bitcoin operates as a macroeconomic paradox: it combines a strictly predetermined, inelastic monetary issuance schedule with a stochastic, highly elastic demand for scarce block space. This paper empirically validates the Endogenous Constraint Hypothesis, positing that protocol-level throughput limits generate a non-linear negative feedback loop between network friction and base-layer monetary velocity. Using a verified Transaction Cost Index (TCI) derived from Blockchain.com on-chain data and Hansen's (2000) threshold regression, we identify a definitive structural break at the 90th percentile of friction (TCI ~ 1.63). The analysis reveals a bifurcation in network utility: while the network exhibits robust velocity growth of +15.44% during normal regimes, this collapses to +6.06% during shock regimes, yielding a statistically significant Net Utility Contraction of -9.39% (p = 0.012). Crucially, Instrumental Variable (IV) tests utilizing Hashrate Variation as a supply-side instrument fail to detect a significant relationship in a linear specification (p=0.196), confirming that the velocity constraint is strictly a regime-switching phenomenon rather than a continuous linear function. Furthermore, we document a \"Crypto Multiplier\" inversion: high friction correlates with a +8.03% increase in capital concentration per entity, suggesting that congestion forces a substitution from active velocity to speculative hoarding."}
{"id": "2512.08013", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08013", "abs": "https://arxiv.org/abs/2512.08013", "authors": ["Robert Lefringhausen", "Theodor Springer", "Sandra Hirche"], "title": "Learning Dynamics from Infrequent Output Measurements for Uncertainty-Aware Optimal Control", "comment": "Submitted to the 2026 IFAC World Congress", "summary": "Reliable optimal control is challenging when the dynamics of a nonlinear system are unknown and only infrequent, noisy output measurements are available. This work addresses this setting of limited sensing by formulating a Bayesian prior over the continuous-time dynamics and latent state trajectory in state-space form and updating it through a targeted marginal Metropolis-Hastings sampler equipped with a numerical ODE integrator. The resulting posterior samples are used to formulate a scenario-based optimal control problem that accounts for both model and measurement uncertainty and is solved using standard nonlinear programming methods. The approach is validated in a numerical case study on glucose regulation using a Type 1 diabetes model."}
{"id": "2512.08571", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.08571", "abs": "https://arxiv.org/abs/2512.08571", "authors": ["Phani Motamarri", "Gourab Panigrahi"], "title": "Matrix-free algorithms for fast ab initio calculations on distributed CPU architectures using finite-element discretization", "comment": null, "summary": "Finite-element (FE) discretisations have emerged as a powerful real-space alternative to large-scale Kohn-Sham density functional theory (DFT) calculations, offering systematic convergence, excellent parallel scalability, while accommodating generic boundary conditions. However, the dominant computational bottleneck in FE-based DFT arises from the repeated application of the discretised sparse Hamiltonian to large blocks of trial vectors during iterations in an iterative eigensolver. Traditional sparse matrix-vector multiplications and FE cell-matrix approaches encounter memory limitations and high data-movement overheads, particularly at higher polynomial orders, typically used in DFT calculations. To overcome these challenges, this work develops matrix-free algorithms for FE-discretised DFT that substantially accelerate these products by doing on-the-fly operations that utilize structured tensor contractions over 1D basis functions and quadrature data. A unified multilevel batched data layout that handles both real and complex-valued operators is introduced to maximise cache reuse and SIMD utilisation on Frontier (AVX2), Param Pravega (AVX512) and Fugaku (SVE). We also combine terms for optimal cache reuse, even-odd decomposition to reduce FLOP, and mixed-precision intrinsics. Extensive benchmarks show that for large multivector pseudopotential DFT calculations, the matrix-free kernels deliver 1.5-4x speedups over the state-of-the-art cell-matrix approach baselines. For all-electron DFT calculations, the matrix-free operator achieves gains of up to 5.8x due to its efficient implementation and superior arithmetic intensity. When integrated with an error-tolerant Chebyshev-filtered subspace iteration eigensolver, the matrix-free formalism yields substantial reductions in end-to-end time-to-solution using FE meshes that deliver desired accuracies in ground-state properties."}
{"id": "2512.08284", "categories": ["physics.geo-ph", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.08284", "abs": "https://arxiv.org/abs/2512.08284", "authors": ["Guangyuan Zou", "Junlun Li", "Feng Liu", "Xuejing Zheng", "Jianjian Xie", "Guoyi Chen"], "title": "Self-Reinforced Deep Priors for Reparameterized Full Waveform Inversion", "comment": "Submitted to GEOPHYSICS", "summary": "Full waveform inversion (FWI) has become a widely adopted technique for high-resolution subsurface imaging. However, its inherent strong nonlinearity often results in convergence toward local minima. Recently, deep image prior-based reparameterized FWI (DIP-FWI) has been proposed to alleviate the dependence on massive training data. By exploiting the spectral bias and implicit regularization in the neural network architecture, DIP-FWI can effectively avoid local minima and reconstruct more geologically plausible velocity models. Nevertheless, existing DIP-FWI typically use a fixed random input throughout the inversion process, which fails to utilize the mapping and correlation between the input and output of the network. Moreover, under complex geological conditions, the lack of informative prior in the input can exacerbate the ill-posedness of the inverse problem, leading to artifacts and unstable reconstructions. To address these limitations, we propose a self-reinforced DIP-FWI (SRDIP-FWI) framework, in which a steering algorithm alternately updates both the network parameters and the input at each iteration using feedback from the current network output. This design allows adaptive structural enhancement and improved regularization, thereby effectively mitigating the ill-posedness in FWI. Additionally, we analyze the spectral bias of the network in SRDIP-FWI and quantify its role in multiscale velocity model building. Synthetic tests and field land data application demonstrate that SRDIP-FWI achieves superior resolution, improved accuracy and greater depth penetration compared to multiscale FWI. More importantly, SRDIP-FWI eliminates the need for manual frequency-band selection and time-window picking, substantially simplifying the inversion workflow. Overall, the proposed method provides a novel, adaptive and robust framework for accurate subsurface velocity model reconstruction."}
{"id": "2512.08570", "categories": ["nlin.CD", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2512.08570", "abs": "https://arxiv.org/abs/2512.08570", "authors": ["Manuel Adams", "José M. Amigó", "Klaus Lehnertz"], "title": "Transcript-based estimators for characterizing interactions", "comment": "11 pages, 8 figures", "summary": "The concept of transcripts was introduced in 2009 as a means to characterize various aspects of the functional relationship between time series of interacting systems. Based on this concept that utilizes algebraic relations between ordinal patterns derived from time series, estimators for the strength, direction, and complexity of interactions have been introduced. These estimators, however, have not yet found widespread application in studies of interactions between real-world systems. Here, we revisit the concept of transcripts and showcase the usage of transcript-based estimators for a time-series-based investigation of interactions between coupled paradigmatic dynamical systems of varying complexity. At the example of a time-resolved analysis of multichannel and multiday recordings of ongoing human brain dynamics, we demonstrate the potential of the methods to provide novel insights into the intricate spatial-temporal interactions in the human brain underlying different vigilance states."}
{"id": "2512.07897", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.07897", "abs": "https://arxiv.org/abs/2512.07897", "authors": ["Lucas Isenmann"], "title": "Analysis of the Sybil defense of Duniter-based cryptocurrencies", "comment": null, "summary": "Duniter-based cryptocurrencies, which are providing a kind of universal basic income, are using a system called \"Web of Trust\" based on a social network whose evolution is subject to graph theoretical rules, time constraints and a licence in order to avoid large Sybil attacks. We investigate in this article the largest size of a Sybil attack that a simplified version of the graph theoretical rules of a Web of Trust can undergo depending on the number of attackers and on the parameters of the system. We show that even if in theory, without considering social and time constraints, this system cannot in general prevent huge attacks, in the real-world case of a Duniter-based cryptocurrency (with thousands of users), the system can prevent attacks of large size with only graph theoretical rules."}
{"id": "2512.08364", "categories": ["math.NA", "math.NT", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.08364", "abs": "https://arxiv.org/abs/2512.08364", "authors": ["Erich Novak", "Friedrich Pillichshammer"], "title": "Generalized Discrepancy of Random Points", "comment": null, "summary": "We study the $L_p$-discrepancy of random point sets in high dimensions, with emphasis on small values of $p$. Although the classical $L_p$-discrepancy suffers from the curse of dimensionality for all $p \\in (1,\\infty)$, the gap between known upper and lower bounds remains substantial, in particular for small $p \\ge 1$. To clarify this picture, we review the existing results for i.i.d.\\ uniformly distributed points and derive new upper bounds for \\emph{generalized} $L_p$-discrepancies, obtained by allowing non-uniform sampling densities and corresponding non-negative quadrature weights.\n  Using the probabilistic method, we show that random points drawn from optimally chosen product densities lead to significantly improved upper bounds. For $p=2$ these bounds are explicit and optimal; for general $p \\in [1,\\infty)$ we obtain sharp asymptotic estimates. The improvement can be interpreted as a form of importance sampling for the underlying Sobolev space $F_{d,q}$.\n  Our results also reveal that, even with optimal densities, the curse of dimensionality persists for random points when $p\\ge 1$, and it becomes most pronounced for small $p$. This suggests that the curse should also hold for the classical $L_1$-discrepancy for deterministic point sets."}
{"id": "2512.08425", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.08425", "abs": "https://arxiv.org/abs/2512.08425", "authors": ["Sajjad Arzemanzadeh", "Karol Miller", "Tim Rosenow", "Sjoerd B. Vos", "Adam Wittek"], "title": "Mechanical behaviour of brain-skull interface (meninges) under shear loading through experiment and finite element modelling: Preliminary results", "comment": "Computational Biomechanics for Medicine (CBM) XX - accepted", "summary": "The brain-skull interface (meninges) plays a critical role in governing brain motion during head impacts, yet computational models often simplify this interface using idealized contact conditions due to limited experimental data. This study presents an improved protocol combining experimental testing and computational modelling to determine the mechanical properties of the brain-skull interface under shear loading. Brain tissue and brain-skull complex samples were extracted from sheep cadaver heads and subjected to shear loading. Magnetic resonance imaging (MRI) was used to obtain accurate 3D geometries of the samples, which were then used to create computational grids (meshes) for simulation of the experiments using finite element (FE) models to determine subject-specific properties of the brain tissue and brain-skull interface. A second-order Ogden hyperelastic model was used for the brain tissue, and a cohesive layer was employed to model the brain-skull interface. Our results indicate that a cohesive layer captures the force-displacement and damage initiation of the brain-skull interface. The calibrated cohesive properties showed consistent patterns across samples, with maximum normal tractions ranging from 2.8-3.4 kPa and maximum tangential tractions from 1.8-2.1 kPa. This framework provides a foundation for improving the biofidelity of computational head models used in injury prediction and neurosurgical planning by replacing arbitrary boundary conditions with formulations derived from experimental data on brain-skull interface (meninges) biomechanical behaviour."}
{"id": "2512.08140", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08140", "abs": "https://arxiv.org/abs/2512.08140", "authors": ["Mohsen Sadatsafavi", "Jeroen Hoogland", "Thomas P. A. Debray", "John Petkau"], "title": "Non-parametric assessment of the calibration of individualized treatment effects", "comment": "24 pages, 9 figures, 2 tables, 2 appendices", "summary": "An important aspect of the performance of algorithms that predict individualized treatment effects (ITE) is moderate calibration, i.e., the average treatment effect among individuals with predicted treatment effect of z being equal to z. The assessment of moderate calibration is a challenging task on two fronts: counterfactual responses are unobserved, and quantifying the conditional response function for models that generate continuous predicted values requires regularization or parametric modeling. Perhaps because of these challenges, there is currently no inferential method for the null hypothesis that an ITE model is moderately calibrated in a population. In this work, we propose non-parametric methods for the assessment of moderate calibration of ITE models for binary outcomes using data from a randomized trial. These methods simultaneously resolve both challenges, resulting in novel numerical, graphical, and inferential methods for the assessment of moderate calibration. The key idea is to formulate a stochastic process for the cumulative prediction errors that obeys a functional central limit theorem, enabling the use of the properties of Brownian motion for asymptotic inference. We propose two approaches to construct this process from a sample: a conditional approach that relies on predicted risks (often an output of ITE models), and a marginal approach based on replacing the cumulative conditional expected value and variance terms with their marginal counterparts. Numerical simulations confirm the desirable properties of both approaches and their ability to detect miscalibration of different forms. We use a case study to provide practical suggestions on graphical presentation and the interpretation of results. Moderate calibration of predicted ITEs can be assessed without requiring regularization techniques or making assumptions about the functional form of treatment response."}
{"id": "2512.08235", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08235", "abs": "https://arxiv.org/abs/2512.08235", "authors": ["George Dunn", "Elizabeth Stojanovski", "Bishnu Lamichhane", "Hadi Charkhgard", "Ali Eshragh"], "title": "Strict Elimination of Double Traversals in Outer Subaisles and Two-Block Rectangular Warehouses", "comment": null, "summary": "The order picking problem seeks the shortest warehouse route that visits all required item locations. Strict conditions are known for single-block rectangular layouts under which optimal routes never require double traversals, while broader results show they are avoidable only when cross-aisle connectivity is present. We strengthen these findings by proving that no double traversals are needed in the upper or lower subaisles of warehouses with at least two aisles, establishing strict conditions for both single and two-block layouts."}
{"id": "2512.08200", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.08200", "abs": "https://arxiv.org/abs/2512.08200", "authors": ["Andrew T. A. Wood"], "title": "A multivariate generalization of Hall's theorem for Edgeworth expansions of bootstrap distributions", "comment": "24 pages", "summary": "Theorem 5.1 in the monograph by Hall (1992) provides rigorous in-probability justification of Edgeworth expansions of bootstrap distributions. Proving this result was rather challenging because bootstrap distributions do not satisfy the classical Cramér condition and therefore classical methods for justifying Edgeworth expansions, e.g. Bhattacharya and Rao (1976) and Bhattacharya and Ghosh (1978), are not available. Hall's (1992) theorem is for a univariate statistic which can be expressed as a smooth function of means, though the underlying population can be multivariate. However, there are a number of applications where a multivariate version of Hall's theorem is needed, and generalizing the proof from the univariate case to the multivariate case is not immediate. Our primary purpose in this article is to fill this gap by stating a multivariate version of the theorem and sketching the modifications to the proof of Hall's (1992) Theorem 5.1 that are needed."}
{"id": "2512.08055", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08055", "abs": "https://arxiv.org/abs/2512.08055", "authors": ["Honglian Wang", "Haoyun Chen", "Aristides Gionis"], "title": "Fairness-aware PageRank via Edge Reweighting", "comment": null, "summary": "Link-analysis algorithms, such as PageRank, are instrumental in understanding the structural dynamics of networks by evaluating the importance of individual vertices based on their connectivity. Recently, with the rising importance of responsible AI, the question of fairness in link-analysis algorithms has gained traction. In this paper, we present a new approach for incorporating group fairness into the PageRank algorithm by reweighting the transition probabilities in the underlying transition matrix. We formulate the problem of achieving fair PageRank by seeking to minimize the fairness loss, which is the difference between the original group-wise PageRank distribution and a target PageRank distribution. We further define a group-adapted fairness notion, which accounts for group homophily by considering random walks with group-biased restart for each group. Since the fairness loss is non-convex, we propose an efficient projected gradient-descent method for computing locally-optimal edge weights. Unlike earlier approaches, we do not recommend adding new edges to the network, nor do we adjust the restart vector. Instead, we keep the topology of the underlying network unchanged and only modify the relative importance of existing edges. We empirically compare our approach with state-of-the-art baselines and demonstrate the efficacy of our method, where very small changes in the transition matrix lead to significant improvement in the fairness of the PageRank algorithm."}
{"id": "2512.07906", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07906", "abs": "https://arxiv.org/abs/2512.07906", "authors": ["Shun-Cai Zhao"], "title": "Quantum catalysis-enhanced extract energy in qubit quantum battery", "comment": "5 pages, 3 figures", "summary": "What physical mechanism enables quantum catalysis to boost quantum battery (QB) performance in open systems? We investigate an external-field-driven qubit QB coupled to a harmonic oscillator catalyst, revealing a key thermodynamic mechanism: the catalyst induces transient negative heat flow ($J(t)<0$, or energy backflow) into the battery. This backflow actively counters dephasing losses, rapidly pushing the qubit into non-passive states, and results in a drastic enhancement of extractable work (Ergotropy). Leveraging the quantum first law, we precisely quantify this causal link between negative heat flux and QB performance enhancement. Our work uncovers the fundamental role of transient thermodynamic backflow in quantum catalysis, offering a crucial blueprint for high-performance quantum energy storage devices."}
{"id": "2512.08058", "categories": ["cond-mat.stat-mech", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2512.08058", "abs": "https://arxiv.org/abs/2512.08058", "authors": ["Marc Besse", "Raphaël Voituriez"], "title": "Emergent memory in cell-like active systems", "comment": "Main: 23 pages, 5 figures. SM: 39 pages, 4 figures", "summary": "Active systems across scales, ranging from molecular machines to human crowds, are usually modeled as assemblies of self-propelled particles driven by internally generated forces. However, these models often assume memoryless dynamics and no coupling of internal active forces to the environment. Here, guided by the example of living cells, which have recently been shown to display multi-timescale memory effects, we introduce a general theoretical framework that goes beyond this paradigm by incorporating internal state dynamics and environmental sensing into active particle models. We show that when the self-propulsion of an agent depends on internal variables with their own complex dynamics - modulated by local environmental cues - environmental memory spontaneously emerges and gives rise to new classes of behaviours. These include memory-induced responses, adaptable localization in complex landscapes, suppression of motility-induced phase separation, and enhanced jamming transitions. Our results demonstrate how minimal information processing capabilities, intrinsic to non-equilibrium agents with internal states like living cells, can profoundly influence both individual and collective behaviours. This framework bridges cell-scale activity and large-scale intelligent motion in cell assemblies, and opens the way to the quantitative analysis and design of systems ranging from synthetic colloids to biological collectives and robotic swarms."}
{"id": "2512.08066", "categories": ["eess.SY", "econ.GN", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.08066", "abs": "https://arxiv.org/abs/2512.08066", "authors": ["Alessandro V. M. Oliveira", "Moises D. Vassallo"], "title": "Cabin Layout, Seat Density, and Passenger Segmentation in Air Transport: Implications for Prices, Ancillary Revenues, and Efficiency", "comment": null, "summary": "This study investigates how the layout and density of seats in aircraft cabins influence the pricing of airline tickets on domestic flights. The analysis is based on microdata from boarding passes linked to face-to-face interviews with passengers, allowing us to relate the price paid to the location on the aircraft seat map, as well as market characteristics and flight operations. Econometric models were estimated using the Post-Double-Selection LASSO (PDS-LASSO) procedure, which selects numerous controls for unobservable factors linked to commercial and operational aspects, thus enabling better identification of the effect of variables such as advance purchase, reason for travel, fuel price, market structure, and load factor, among others. The results suggest that a higher density of seat rows is associated with lower prices, reflecting economies of scale with the increase in aircraft size and gains in operational efficiency. An unexpected result was also obtained: in situations where there was no seat selection fee, passengers with more expensive tickets were often allocated middle seats due to purchasing at short notice, when the side alternatives were no longer available. This behavior helps explain the economic logic behind one of the main ancillary revenues of airlines. In addition to quantitative analysis, the study incorporates an exploratory approach to innovative cabin concepts and their possible effects on density and comfort on board."}
{"id": "2512.07932", "categories": ["cond-mat.str-el", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.07932", "abs": "https://arxiv.org/abs/2512.07932", "authors": ["Mohammed Hammam", "Cyprian Lewandowski", "Vladimir Dobrosavljevic", "Sandeep Joy"], "title": "Is disorder a friend or a foe to melting of Wigner-Mott insulators?", "comment": "5 pages, 3 figures, supplemental material will be uploaded later, comments are welcome!", "summary": "Wigner crystals are extremely fragile, which is shown to result from very strong geometric frustration germane to long-range Coulomb interactions. Physically, this is manifested by a very small characteristic energy scale for shear density fluctuations, which are gapless excitations in a translationally invariant system. The presence of disorder, however, breaks translational invariance, thus suppressing gapless excitations and pushing them to higher density. We illustrate this general principle by explicit microscopic model calculations, showing that this mechanism very effectively stabilizes disordered Wigner lattices to much higher temperatures and densities than in the clean limit. On the other hand, we argue that in two dimensions disorder significantly ``smears\" the melting transition, producing spatial coexistence of solid-like and liquid-like regions -- just as recently observed in STM experiments. Our results paint a new physical picture for melting of Wigner-Mott solids in two dimensions, corresponding to a Mott-Hubbard model with spatially varying local electronic bandwidth."}
{"id": "2512.08691", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08691", "abs": "https://arxiv.org/abs/2512.08691", "authors": ["Michele Castellana"], "title": "Order parameter for non-mean-field spin glasses", "comment": null, "summary": "We propose a novel renormalization group (RG) method for non mean-field models of spin glasses, which leads to the emergence of a novel order parameter. Unlike previous approaches where the RG procedure is based on a priori notions on the system, our analysis follows a minimality principle, where no a priori assumption is made. We apply our approach to a spin-glass model built on a hierarchical lattice. In the RG decimation procedure, a novel order parameter spontaneously emerges from the system symmetries, and self-similarity features of the RG transformation only. This order parameter is the projection of the spin configurations on the ground state of the system. Kadanoff's majority rule for ferromagnetic systems is replaced by a more complex scheme, which involves such novel order parameter. The ground state thus acts as a pattern which translates spin configurations from one length scale to another. The rescaling RG procedure is based on a minimal, information-theory approach and, combined with the decimation, it yields a complete RG transformation.\n  Below the upper critical dimension, the predictions for the critical exponent $ν$, which describes the critical divergence of the correlation length, are in excellent agreement with numerical simulations from both this and previous studies. Overall, this study opens new avenues in the understanding of the critical ordering of realistic spin glasses, and it can be applied to spin-glass models on a cubic lattice and nearest-neighbor couplings which directly model spin-glass materials, such as AuFe, CuMn and other magnetic alloys."}
{"id": "2512.07887", "categories": ["q-fin.ST", "econ.GN", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2512.07887", "abs": "https://arxiv.org/abs/2512.07887", "authors": ["Yhlas Sovbetov", "Hami Saka"], "title": "Does it take two to tango: Interaction between Credit Default Swaps and National Stock Indices", "comment": null, "summary": "This paper investigates both short and long-run interaction between BIST-100 index and CDS prices over January 2008 to May 2015 using ARDL technique. The paper documents several findings. First, ARDL analysis shows that 1 TL increase in CDS shrinks BIST-100 index by 22.5 TL in short-run and 85.5 TL in long-run. Second, 1000 TL increase in BIST index price causes 25 TL and 44 TL reducation in Turkey's CDS prices in short- and long-run respectively. Third, a percentage increase in interest rate shrinks BIST index by 359 TL and a percentage increase in inflation rate scales CDS prices up to 13.34 TL both in long-run. In case of short-run, these impacts are limited with 231 TL and 5.73 TL respectively. Fourth, a kurush increase in TL/USD exchange rate leads 24.5 TL (short-run) and 78 TL (long-run) reductions in BIST, while it augments CDS prices by 2.5 TL (short-run) and 3 TL (long-run) respectively. Fifth, each negative political events decreases BIST by 237 TL in short-run and 538 TL in long-run, while it increases CDS prices by 33 TL in short-run and 89 TL in long-run. These findings imply the highly dollar indebted capital structure of Turkish firms, and overly sensitivity of financial markets to the uncertainties in political sphere. Finally, the paper provides evidence for that BIST and CDS with control variables drift too far apart, and converge to a long-run equilibrium at a moderate monthly speed."}
{"id": "2512.08066", "categories": ["eess.SY", "econ.GN", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.08066", "abs": "https://arxiv.org/abs/2512.08066", "authors": ["Alessandro V. M. Oliveira", "Moises D. Vassallo"], "title": "Cabin Layout, Seat Density, and Passenger Segmentation in Air Transport: Implications for Prices, Ancillary Revenues, and Efficiency", "comment": null, "summary": "This study investigates how the layout and density of seats in aircraft cabins influence the pricing of airline tickets on domestic flights. The analysis is based on microdata from boarding passes linked to face-to-face interviews with passengers, allowing us to relate the price paid to the location on the aircraft seat map, as well as market characteristics and flight operations. Econometric models were estimated using the Post-Double-Selection LASSO (PDS-LASSO) procedure, which selects numerous controls for unobservable factors linked to commercial and operational aspects, thus enabling better identification of the effect of variables such as advance purchase, reason for travel, fuel price, market structure, and load factor, among others. The results suggest that a higher density of seat rows is associated with lower prices, reflecting economies of scale with the increase in aircraft size and gains in operational efficiency. An unexpected result was also obtained: in situations where there was no seat selection fee, passengers with more expensive tickets were often allocated middle seats due to purchasing at short notice, when the side alternatives were no longer available. This behavior helps explain the economic logic behind one of the main ancillary revenues of airlines. In addition to quantitative analysis, the study incorporates an exploratory approach to innovative cabin concepts and their possible effects on density and comfort on board."}
{"id": "2512.08434", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.08434", "abs": "https://arxiv.org/abs/2512.08434", "authors": ["Abdella Mohamed", "Xiangyu Hu"], "title": "Trans-Arctic route feasibility on a pan-Arctic grid under bathymetric and sea-ice constraints", "comment": "36 pages, 11 figures, 3 tables, 3 appendix", "summary": "Climate driven reductions in Arctic sea ice have renewed interest in trans Arctic shipping, but adoption remains limited by basic questions of route feasibility, safety and excess distance. Existing studies mostly compare idealised great circle shortcuts or use full weather routing systems, leaving a gap for simple basin scale diagnostics on realistic bathymetry and sea ice. We develop an offline graph based framework on a 0.5 degree pan Arctic grid that combines GEBCO 2024 bathymetry with a summer 2018 Arctic sea ice reanalysis from the Copernicus Marine Environment Monitoring Service (CMEMS). An A* pathfinding algorithm is applied to a canonical Europe Asia origin destination pair to quantify route availability and route length inflation relative to a great circle. Enforcing sea only feasibility increases route length by about 10 percent before depth and ice constraints are applied. Depth thresholds representative of under keel clearance (hmin = 20-50 m) remove up to roughly 15 percent of the sea mask but preserve a trans Arctic connection for hmin = 20 m. Summer sea ice exerts a strong seasonal control: continuous ice safe routes emerge only from mid August, with distances inflated by roughly 20-25 percent even in late summer. When depth and ice constraints are imposed jointly, only about 75 percent of sea cells remain safe and no continuous joint safe trans Arctic route exists in the tested season. The framework provides a basin scale screening tool for Arctic shipping and a baseline for forecast driven, multi objective routing studies."}
{"id": "2512.07905", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.07905", "abs": "https://arxiv.org/abs/2512.07905", "authors": ["Quetzalcoatl Hernandez-Escobedo", "David Muñoz-Rodríguez", "Alejandro Vargas-Casillas", "José Manuel Juárez Lopez", "Pilar Aparicio-Martínez", "María Pilar Martínez-Jiménez", "Alberto-Jesus Perea-Moreno"], "title": "Renewable Energies in the Agricultural Sector: A Perspective Analysis of the Last Three Years", "comment": "18 pages, 10 figures, 5 tables", "summary": "Over the last three years, research on the application of renewable energies in the agricultural sector has grown significantly. In this study, we conducted a bibliometric analysis of global scientific production from 2019 to 2021 to identify trends, leading contributors, and emerging research areas. Based on 1378 documents retrieved from Scopus, we observed a clear upward trend in publications, with a peak in 2021. India, China, the United States, Italy, and the United Kingdom were the most productive countries, while key institutions from China, Iran, and the Netherlands led the research output. Our results reveal five major thematic clusters: renewable energy technologies in agriculture, bioenergy, sustainable agriculture, biomass energy, and the environmental impact of agricultural activities. Notable advances include agrovoltaic systems, the use of agricultural and livestock waste for biogas production, and the development of agricultural robots powered by renewable energy sources. Additionally, there is increasing interest in examining the links among agriculture, renewable energy use, and greenhouse gas emissions, aligned with global sustainability goals. This analysis highlights the evolution of the field, international collaboration patterns, and the most influential research lines, offering valuable insights to guide future scientific developments in integrating renewable energies within the agricultural sector."}
{"id": "2512.08479", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.08479", "abs": "https://arxiv.org/abs/2512.08479", "authors": ["Emmanuel Audusse", "Sébastien Boyaval", "Virgile Dubos", "Minh-Hoang Le"], "title": "Construction and Performance of Kinetic Schemes for Linear Systems of Conservation Laws", "comment": null, "summary": "We describe a methodology to build vectorial kinetic schemes, targetting the numerical solution of linear symmetric-hyperbolic systems of conservation laws -a minimal application case for those schemes. Precisely, we fully detail the construction of kinetic schemes that satisfy a discrete equivalent to a convex extension (an additional non-trivial conservation law) of the target system -the (linear) acoustic and elastodynamics systems, specifically -. Then, we evaluate numerically the convergence of various possible kinetic schemes toward smooth solutions, in comparison with standard finite-difference and finite-volume discretizations on Cartesian meshes. Our numerical results confirm the interest of ensuring a discrete equivalent to a convex extension, and show the influence of remaining parameter variations in terms of error magnitude, both for ''first-order'' and ''second-order'' kinetic schemes\\,: the parameter choice with largest CFL number (equiv., smallest spurious diffusion in the equivalent equation analysis) has the smallest discretization error."}
{"id": "2512.08764", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.08764", "abs": "https://arxiv.org/abs/2512.08764", "authors": ["Nicolas Reche", "Elvys Linhares-Pontes", "Juan-Manuel Torres-Moreno"], "title": "Financial News Summarization: Can extractive methods still offer a true alternative to LLMs?", "comment": "8 pages, 5 tables", "summary": "Financial markets change rapidly due to news, economic shifts, and geopolitical events. Quick reactions are vital for investors to avoid losses or capture short-term gains. As a result, concise financial news summaries are critical for decision-making. With over 50,000 financial articles published daily, automation in summarization is necessary. This study evaluates a range of summarization methods, from simple extractive techniques to advanced large language models (LLMs), using the FinLLMs Challenge dataset. LLMs generated more coherent and informative summaries, but they are resource-intensive and prone to hallucinations, which can introduce significant errors into financial summaries. In contrast, extractive methods perform well on short, well-structured texts and offer a more efficient alternative for this type of article. The best ROUGE results come from fine-tuned LLM model like FT-Mistral-7B, although our data corpus has limited reliability, which calls for cautious interpretation."}
{"id": "2512.08144", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08144", "abs": "https://arxiv.org/abs/2512.08144", "authors": ["Joshua Wasserman", "Michael R. Elliott", "Ben B. Hansen"], "title": "Propensity score adjustment when errors in achievement measures inform treatment assignment", "comment": "28 pages, 3 figures", "summary": "U.S. state education agencies mark schools displaying achievement gaps between demographic subgroups as needing improvement. Some schools may have few students in these subgroups, such that average end-of-year test scores only noisily measure the average \"true\" score--the score one would expect if students took the test many times. This, in addition to the masking of small subgroup averages in publicly available assessment data, poses challenges for evaluating interventions aimed at closing achievement gaps. We introduce propensity score estimates designed to achieve balance on subgroup average true scores. These estimates are available even when noisy measurements are not and improve overlap compared to those that ignore measurement error, leading to greater bias reduction of matching estimators. We demonstrate our methods through simulation and an application to a statewide initiative in Texas for curbing summer learning loss."}
{"id": "2512.08394", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08394", "abs": "https://arxiv.org/abs/2512.08394", "authors": ["Llorenç Balada Gaggioli", "Didier Henrion", "Milan Korda"], "title": "Global optimization of low-rank polynomials", "comment": "17 pages, 3 figures", "summary": "This work considers polynomial optimization problems where the objective admits a low- rank canonical polyadic tensor decomposition. We introduce LRPOP (low-rank polynomial optimization), a new hierarchy of semidefinite programming relaxations for which the size of the semidefinite blocks is determined by the canonical polyadic rank rather than the number of variables. As a result, LRPOP can solve low-rank polynomial optimization problems that are far beyond the reach of existing sparse hierarchies. In particular, we solve problems with up to thousands of variables with total degree in the thousands. Numerical conditioning for problems of this size is improved by using the Bernstein basis. The LRPOP hierarchy converges from below to the global minimum of the polynomial under standard assumptions."}
{"id": "2512.08252", "categories": ["math.ST", "math.PR", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08252", "abs": "https://arxiv.org/abs/2512.08252", "authors": ["Sohom Bhattacharya", "Subhabrata Sen"], "title": "Causal inference under interference: computational barriers and algorithmic solutions", "comment": null, "summary": "We study causal effect estimation under interference from network data. We work under the chain-graph formulation pioneered in Tchetgen Tchetgen et. al (2021). Our first result shows that polynomial time evaluation of treatment effects is computationally hard in this framework without additional assumptions on the underlying chain graph. Subsequently, we assume that the interactions among the study units are governed either by (i) a dense graph or (ii) an i.i.d. Gaussian matrix. In each case, we show that the treatment effects have well-defined limits as the population size diverges to infinity. Additionally, we develop polynomial time algorithms to consistently evaluate the treatment effects in each case. Finally, we estimate the unknown parameters from the observed data using maximum pseudo-likelihood estimates, and establish the stability of our causal effect estimators under this perturbation. Our algorithms provably approximate the causal effects in polynomial time even in low-temperature regimes where the canonical MCMC samplers are slow mixing. For dense graphs, our results use the notion of regularity partitions; for Gaussian interactions, our approach uses ideas from spin glass theory and Approximate Message Passing."}
{"id": "2512.08183", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2512.08183", "abs": "https://arxiv.org/abs/2512.08183", "authors": ["Sanika Damle", "Radhika Krishnan"], "title": "Framing Climate Change on YouTube: North-South Divides in Narratives and Public Engagement", "comment": null, "summary": "Climate change debates have gained increasing visibility on social media, with YouTube emerging as one of the most influential platforms for political communication. Reaching billions of users worldwide, it functions both as a news outlet and as a space for public discourse. While existing studies of climate discourse on YouTube often adopt a global perspective, this study examines the platform through the lens of the Global North-South divide. We analyse a dataset of 758 climate-related videos and their comment sections, applying topic modelling and sentiment analysis to identify recurring discursive patterns. Through these patterns, we recognise parallels with respect to debates in international climate negotiations. The findings reveal notable differences. Videos from the Global North and Global South reflect real-world divides, with the North emphasising the need for policies to curb carbon emissions, while the South highlights developmental priorities. A key area of convergence between the regions lies in the shared recognition of the importance of emissions reduction and international agreements. Audience responses, however, diverge more sharply: comment sections under Global North videos are dominated by criticism, conspiracy, and climate fatigue, whereas those under Global South videos are generally more supportive, constructive, and knowledge-oriented. Overall, the study demonstrates how YouTube reflects and reshapes global climate politics, while also revealing the gap between curated narratives and public sentiment. Bridging these divides may contribute to more inclusive and cooperative approaches to climate action."}
{"id": "2512.07908", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.07908", "abs": "https://arxiv.org/abs/2512.07908", "authors": ["Zachary P. Bradshaw", "Margarite L. LaBorde", "Dillon Montero"], "title": "Symmetry-Based Quantum Codes Beyond the Pauli Group", "comment": "22 pages, 5 figures", "summary": "Typical stabilizer codes aim to solve the general problem of fault-tolerance without regard for the structure of a specific system. By incorporating a broader representation-theoretic perspective, we provide a generalized framework that allows the code designer to take this structure into account. For any representation of a finite group, we produce a quantum code with a code space invariant under the group action, providing passive error mitigation against errors belonging to the image of the representation. Furthermore, errors outside this scope are detected and diagnosed by performing a projective measurement onto the isotypic components corresponding to irreducible representations of the chosen group, effectively generalizing syndrome extraction to symmetry-resolved quantum measurements. We show that all stabilizer codes are a special case of this construction, including qudit stabilizer codes, and show that there is a natural one logical qubit code associated to the dihedral group. Thus we provide a unifying framework for existing codes while simultaneously facilitating symmetry-aware codes tailored to specific systems."}
{"id": "2512.08210", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08210", "abs": "https://arxiv.org/abs/2512.08210", "authors": ["Janik Schüttler", "Robert L. Jack", "Michael E. Cates"], "title": "Nonreciprocal dynamics with weak noise: aperiodic \"Escher cycles\" and their quasipotential landscape", "comment": "25 pages", "summary": "We present an explicit construction of the Freidlin-Wentzell quasipotential of a stochastic system with two degrees of freedom and nonreciprocal interactions. This model undergoes noise-induced transitions between four metastable attractors, forming recurrent but aperiodic ``Escher cycles,'' similar to the cyclic nucleation dynamics observed in the nonreciprocal Ising model. We calculate the quasipotential analytically to first order in nonreciprocality. We characterise it along a one-dimensional reaction coordinate that connects the attractors, and we also obtain the full two-dimensional landscape, at leading order in perturbation theory. The resulting landscapes feature flat regions and extended plateaus, together with non-differentiable switching lines. These singular structures arise from two geometric mechanisms: the handover of dominance between competing transition paths, and the competition between basins of attraction. The system provides a rare case where the geometry of nonequilibrium rare events can be fully resolved, and a simple analytically tractable example of a quasipotential in more than one coordinate that captures a rich set of nonequilibrium features."}
{"id": "2512.08076", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08076", "abs": "https://arxiv.org/abs/2512.08076", "authors": ["Min-Seung Ko", "Jae Woong Shim", "Hao Zhu"], "title": "Mitigation of Datacenter Demand Ramping and Fluctuation using Hybrid ESS and Supercapacitor", "comment": null, "summary": "This paper proposes a hybrid energy storage system (HESS)-based control framework that enables comprehensive power smoothing for hyperscale AI datacenters with large load variations. Datacenters impose severe ramping and fluctuation-induced stresses on the grid frequency and voltage stability. To mitigate such disturbances, the proposed HESS integrates a battery energy storage system (BESS) and a supercapacitor (SC) through coordinated multi-timescale control. A high-pass filter (HPF) separates the datacenter demand into slow and fast components, allocating them respectively to the ESS via a leaky-integral controller and to the SC via a phase-lead proportional-derivative controller enhanced with feedforward and ramp-tracking compensation. Adaptive weighting and repetitive control mechanisms further improve transient and periodic responses. Case studies verify that the proposed method effectively suppresses both ramping and fluctuations, stabilizes the system frequency, and maintains sustainable state-of-charge (SoC) trajectories for both ESS and SC under prolonged, stochastic training cycles."}
{"id": "2512.07947", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.07947", "abs": "https://arxiv.org/abs/2512.07947", "authors": ["Agnes Valenti", "Yaar Vituri", "Yubo Yang", "Daniel E. Parker", "Tomohiro Soejima", "Junkai Dong", "Miguel A. Morales", "Ashvin Vishwanath", "Erez Berg", "Shiwei Zhang"], "title": "Quantum Geometry Driven Crystallization: A Neural-Network Variational Monte Carlo Study", "comment": "16 pages, 13 figures", "summary": "Wigner crystals are a paradigmatic form of interaction driven electronic order. A key open question is how Berry curvature and, more generally, quantum geometry reshape crystallization. The discovery of two-dimensional materials with relatively flat bands and pronounced Berry curvature has added fresh urgency to this question. Recent mean-field studies have proposed a topological variant of the Wigner crystal, the anomalous Hall crystal (AHC), with non-zero Chern number. However it remains unclear whether the AHC survives beyond the mean-field approximation. Here, we map out the ground-state phase diagram of the $λ$-jellium model - a simple model whose interaction strength and Berry curvature are independently tunable - using state-of-the-art neural-network variational Monte Carlo. The AHC is found to remain stable against quantum fluctuations. Surprisingly, quantum geometric effects are found to dramatically enhance crystallization. Both the AHC and the standard Wigner Crystal are stabilized at densities up to an order of magnitude above the critical density in the absence of quantum geometry, yet still significantly below the threshold predicted by mean-field theory. These striking results highlight the rich interplay between quantum fluctuations, quantum geometry, and crystallization, providing concrete guidance for experiments and enabling future explorations of fractionalized crystals and chiral superconductors."}
{"id": "2512.07932", "categories": ["cond-mat.str-el", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.07932", "abs": "https://arxiv.org/abs/2512.07932", "authors": ["Mohammed Hammam", "Cyprian Lewandowski", "Vladimir Dobrosavljevic", "Sandeep Joy"], "title": "Is disorder a friend or a foe to melting of Wigner-Mott insulators?", "comment": "5 pages, 3 figures, supplemental material will be uploaded later, comments are welcome!", "summary": "Wigner crystals are extremely fragile, which is shown to result from very strong geometric frustration germane to long-range Coulomb interactions. Physically, this is manifested by a very small characteristic energy scale for shear density fluctuations, which are gapless excitations in a translationally invariant system. The presence of disorder, however, breaks translational invariance, thus suppressing gapless excitations and pushing them to higher density. We illustrate this general principle by explicit microscopic model calculations, showing that this mechanism very effectively stabilizes disordered Wigner lattices to much higher temperatures and densities than in the clean limit. On the other hand, we argue that in two dimensions disorder significantly ``smears\" the melting transition, producing spatial coexistence of solid-like and liquid-like regions -- just as recently observed in STM experiments. Our results paint a new physical picture for melting of Wigner-Mott solids in two dimensions, corresponding to a Mott-Hubbard model with spatially varying local electronic bandwidth."}
{"id": "2512.08000", "categories": ["q-fin.ST", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2512.08000", "abs": "https://arxiv.org/abs/2512.08000", "authors": ["Junwei Yang"], "title": "Analysis of Contagion in China's Stock Market: A Hawkes Process Perspective", "comment": null, "summary": "This study explores contagion in the Chinese stock market using Hawkes processes to analyze autocorrelation and cross-correlation in multivariate time series data. We examine whether market indices exhibit trending behavior and whether sector indices influence one another. By fitting self-exciting and inhibitory Hawkes processes to daily returns of indices like the Shanghai Composite, Shenzhen Component, and ChiNext, as well as sector indices (CSI Consumer, Healthcare, and Financial), we identify long- term dependencies and trending patterns, including upward, downward, and over- sold rebound trends. Results show that during high trading activity, sector indices tend to sustain their trends, while low activity periods exhibit strong sector rotation. This research models stock price movements using spatiotemporal Hawkes processes, leveraging conditional intensity functions to explain sector rotation, advancing the understanding of financial contagion."}
{"id": "2512.08076", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08076", "abs": "https://arxiv.org/abs/2512.08076", "authors": ["Min-Seung Ko", "Jae Woong Shim", "Hao Zhu"], "title": "Mitigation of Datacenter Demand Ramping and Fluctuation using Hybrid ESS and Supercapacitor", "comment": null, "summary": "This paper proposes a hybrid energy storage system (HESS)-based control framework that enables comprehensive power smoothing for hyperscale AI datacenters with large load variations. Datacenters impose severe ramping and fluctuation-induced stresses on the grid frequency and voltage stability. To mitigate such disturbances, the proposed HESS integrates a battery energy storage system (BESS) and a supercapacitor (SC) through coordinated multi-timescale control. A high-pass filter (HPF) separates the datacenter demand into slow and fast components, allocating them respectively to the ESS via a leaky-integral controller and to the SC via a phase-lead proportional-derivative controller enhanced with feedforward and ramp-tracking compensation. Adaptive weighting and repetitive control mechanisms further improve transient and periodic responses. Case studies verify that the proposed method effectively suppresses both ramping and fluctuations, stabilizes the system frequency, and maintains sustainable state-of-charge (SoC) trajectories for both ESS and SC under prolonged, stochastic training cycles."}
{"id": "2512.08845", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.08845", "abs": "https://arxiv.org/abs/2512.08845", "authors": ["Emanuele Bozzi", "Giulio Pascucci", "Giacomo Rapagnani", "Gian Maria Bocchini", "Rebecca Harrington", "Arantza Ugalde", "Gilberto Saccorotti", "Francesco Grigoli"], "title": "Near real-time channel selection for Distributed Acoustic Sensing technology", "comment": null, "summary": "Distributed Acoustic Sensing (DAS) technology is advancing seismic monitoring by providing dense observations near earthquake sources. However, the resulting data volumes often limit real-time processing capability, with most seismological applications focusing on retrospective analysis of seismic sequences. To address this challenge, we introduce ORION, a fast and versatile selector of high-quality DAS channels that efficiently reduces the amount of data to analyze. The method first adopts spatial clustering to identify cable segments with similar geometrical attributes (e.g, azimuth), and then performs channel selection within each section using waveform attributes (e.g., signal-to-noise ratio); this approach enables spatial sub-sampling while preserving azimuthal coverage. We demonstrate the flexibility of the selector across several cable geometries. Finally, we analyze a seismic sequence using ORION-selected channels and compare the source locations with those from a more conventional uniform distribution of channels along the cable, showing improvements in hypocenter accuracy."}
{"id": "2512.07995", "categories": ["physics.soc-ph", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.07995", "abs": "https://arxiv.org/abs/2512.07995", "authors": ["Noémi Nagy", "Sándor Horváth", "Balázs Maga", "Péter L. Simon"], "title": "On the accuracy of population level approximation of network processes", "comment": "16 pages", "summary": "The individual-based model of simple contagion processes is considered on regular graphs. This model explicitly incorporates the adjacency matrix of the network enabling us to study the effect of network structure on the dynamic of the propagation process. While the asymptotic behaviour of the model is well known, the transient behaviour has been less studied. Our goal in this paper is to give a theoretical estimate on the accuracy of the one-dimensional population-level approximation. This is carried out for arbitrary simple contagion processes and regular Turán graphs. Numerical evidence is shown that the theoretical estimate is rather sharp for dense graphs."}
{"id": "2512.08555", "categories": ["math.NA", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08555", "abs": "https://arxiv.org/abs/2512.08555", "authors": ["Gilles Poncelet", "Jonathan Lambrechts", "Thomas Gillis", "Philippe Chatelain"], "title": "A scalable high-order multigrid-FFT Poisson solver for unbounded domains on adaptive multiresolution grids", "comment": "Submitted to SIAM Journal on Scientific Computing", "summary": "Multigrid solvers are among the most efficient methods for solving the Poisson equation, which is ubiquitous in computational physics. For example, in the context of incompressible flows, it is typically the costliest operation. The present document expounds upon the implementation of a flexible multigrid solver that is capable of handling any type of boundary conditions within murphy, a multiresolution framework for solving partial differential equations (PDEs) on collocated adaptive grids. The utilization of a Fourier-based direct solver facilitates the attainment of flexibility and enhanced performance by accommodating any combination of unbounded and semi-unbounded boundary conditions. The employment of high-order compact stencils contributes to the reduction of communication demands while concurrently enhancing the accuracy of the system. The resulting solver is validated against analytical solutions for periodic and unbounded domains. In conclusion, the solver has been demonstrated to demonstrate scalability to 16,384 cores within the context of leading European high-performance computing infrastructures."}
{"id": "2512.08146", "categories": ["stat.ME", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.08146", "abs": "https://arxiv.org/abs/2512.08146", "authors": ["Fangzheng Xie", "Hsin-Hsiung Huang"], "title": "Uncertainty quantification for mixed membership in multilayer networks with degree heterogeneity using Gaussian variational inference", "comment": null, "summary": "Analyzing multilayer networks is central to understanding complex relational measurements collected across multiple conditions or over time. A pivotal task in this setting is to quantify uncertainty in community structure while appropriately pooling information across layers and accommodating layer-specific heterogeneity. Building on the multilayer degree-corrected mixed-membership (ML-DCMM) model, which captures both stable community membership profiles and layer-specific vertex activity levels, we propose a Bayesian inference framework based on a spectral-assisted likelihood. We then develop a computationally efficient Gaussian variational inference algorithm implemented via stochastic gradient descent. Our theoretical analysis establishes a variational Bernstein--von Mises theorem, which provides a frequentist guarantee for using the variational posterior to construct confidence sets for mixed memberships. We demonstrate the utility of the method on a U.S. airport longitudinal network, where the procedure yields robust estimates, natural uncertainty quantification, and competitive performance relative to state-of-the-art methods."}
{"id": "2512.08422", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08422", "abs": "https://arxiv.org/abs/2512.08422", "authors": ["Jean-Philippe Chancelier", "Michel de Lara", "François Pacaud", "Tanguy Lindegaard", "Teemu Pennanen", "Ari-Pekka Perkkiö"], "title": "Optimal Operation and Valuation of Electricity Storages in Intraday Markets", "comment": null, "summary": "This paper applies computational techniques of convex stochastic optimization to optimal operation and valuation of electricity storages in the face of uncertain electricity prices. Our valuations are based on the indifference pricing principle, which builds on optimal trading strategies and calibrates to the user's financial position, market views and risk preferences. The underlying optimization problem is solved with the Stochastic Dual Dynamic Programming algorithm which is applicable to various specifications of storages, and it allows for e.g. hard constraints on storage capacity and charging speed. We illustrate the approach in intraday trading where the agent charges or discharges a battery over a finite number of delivery periods, and the electricity prices are subject to bid-ask spreads and significant uncertainty. Optimal strategies are found in a matter of minutes on a regular PC. We find that the corresponding trading strategies and battery valuations vary consistently with respect to the agent's risk preferences as well as the physical characteristics of the battery."}
{"id": "2512.08823", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.08823", "abs": "https://arxiv.org/abs/2512.08823", "authors": ["Elena Kulinskaya", "David C. Hoaglin"], "title": "Point and interval estimators of a changepoint in stochastical dominance between two distributions", "comment": "32 pages including 19 figures", "summary": "For differences between means of continuous data from independent groups, the customary scale-free measure of effect is the standardized mean difference (SMD). To justify use of SMD, one should be reasonably confident that the group-level variances are equal. Empirical evidence often contradicts this assumption. Thus, we have investigated an alternate approach, based on stochastic ordering of the treatment and control distributions, that takes into account means and variances. For applying stochastic ordering, our development yields a key quantity, $\\mathsf{A}$, the outcome value at which the direction of the ordering of the treatment and control distributions changes.\n  Using an extensive simulation, we studied relative bias of point estimators of $\\mathsf{A}$ and coverage and relative width of bootstrap confidence intervals."}
{"id": "2512.07915", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07915", "abs": "https://arxiv.org/abs/2512.07915", "authors": ["Frank Phillipson"], "title": "Fair Benchmarking of Optimisation Applications", "comment": null, "summary": "Quantum optimisation is emerging as a promising approach alongside classical heuristics and specialised hardware, yet its performance is often difficult to assess fairly. Traditional benchmarking methods, rooted in digital complexity theory, do not directly capture the continuous dynamics, probabilistic outcomes, and workflow overheads of quantum and hybrid systems. This paper proposes principles and protocols for fair benchmarking of quantum optimisation, emphasising end-to-end workflows, transparency in tuning and reporting, problem diversity, and avoidance of speculative claims. By extending lessons from classical benchmarking and incorporating application-driven and energy-aware metrics, we outline a framework that enables practitioners to evaluate quantum methods responsibly, ensuring reproducibility, comparability, and trust in reported results."}
{"id": "2512.08553", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08553", "abs": "https://arxiv.org/abs/2512.08553", "authors": ["Xinyang Li", "Yuliang Jin"], "title": "Supercritical-subcritical correspondence, asymmetric effects and antisymmetric corrections near a critical point", "comment": "14 pages, 12 figures", "summary": "The second-order phase transitions in the Ising model and liquid-gas systems share a universality class and critical exponents, despite the absence of $Z_2$ symmetry in the liquid-gas Hamiltonian. This discrepancy highlights a central puzzle in critical phenomena: what is the influence of asymmetry on scaling laws? For over a century, this question has been explored through examining violations of the empirical ``rectilinear diameter law'' for the subcritical coexistence curve, where asymmetry could generate singular corrections. Here, we extend this investigation to the supercritical regime. We propose a supercritical-subcritical correspondence, drawing a formal analogy between the subcritical coexistence curve and recently defined supercritical boundary lines ($L^\\pm$ lines). Our theory predicts that the linear mixing of physical fields - a hallmark of asymmetric systems - produces universal scaling corrections, with antisymmetric coefficients, in these supercritical loci. We verify these predictions using liquid-gas data from the NIST database and a model liquid-liquid transition. Furthermore, we demonstrate that the same asymmetric scaling framework governs the behavior of higher-order cumulants in the order parameter distribution."}
{"id": "2512.08134", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08134", "abs": "https://arxiv.org/abs/2512.08134", "authors": ["Mahdi Taheri", "Khashayar Khorasani", "Nader Meskin"], "title": "A Dynamic Coding Scheme to Prevent Covert Cyber-Attacks in Cyber-Physical Systems", "comment": null, "summary": "In this paper, we address two main problems in the context of covert cyber-attacks in cyber-physical systems (CPS). First, we aim to investigate and develop necessary and sufficient conditions in terms of disruption resources of the CPS that enable adversaries to execute covert cyber-attacks. These conditions can be utilized to identify the input and output communication channels that are needed by adversaries to execute these attacks. Second, this paper introduces and develops a dynamic coding scheme as a countermeasure against covert cyber-attacks. Under certain conditions and assuming the existence of one secure input and two secure output communication channels, the proposed dynamic coding scheme prevents adversaries from executing covert cyber-attacks. A numerical case study of a flight control system is provided to demonstrate the capabilities of our proposed and developed dynamic coding scheme."}
{"id": "2512.08220", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.08220", "abs": "https://arxiv.org/abs/2512.08220", "authors": ["Leandro M. Chinellato", "Oleg A. Starykh", "Cristian D. Batista"], "title": "Dynamics of Quantum Chiral Solitons", "comment": "18 + 22 pages, 17 + 1 figures", "summary": "We introduce a non-perturbative framework for quantizing chiral solitons in interacting quantum spin chains. This approach provides a direct lattice extension of the well-established $S$-duality between the sine-Gordon and Thirring models, thereby bridging the gap between continuum dualities and their lattice counterparts. By constructing the quantum chiral-soliton operators explicitly, we show how their unconventional dynamics appear in the excitation spectrum and correlation functions across the full Brillouin zone. A key result is that the dominant soliton tunneling amplitude alternates in sign, $\\operatorname{sgn}(t_{1+}) = (-1)^{2S+1}$, sharply distinguishing half-odd-integer from integer spin chains. We further identify characteristic signatures of these chiral excitations in the dynamical spin structure factor, demonstrating their visibility in inelastic neutron scattering. Our results open a route to experimentally probing non-perturbative features of dual quantum field theories in condensed-matter settings."}
{"id": "2512.08134", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08134", "abs": "https://arxiv.org/abs/2512.08134", "authors": ["Mahdi Taheri", "Khashayar Khorasani", "Nader Meskin"], "title": "A Dynamic Coding Scheme to Prevent Covert Cyber-Attacks in Cyber-Physical Systems", "comment": null, "summary": "In this paper, we address two main problems in the context of covert cyber-attacks in cyber-physical systems (CPS). First, we aim to investigate and develop necessary and sufficient conditions in terms of disruption resources of the CPS that enable adversaries to execute covert cyber-attacks. These conditions can be utilized to identify the input and output communication channels that are needed by adversaries to execute these attacks. Second, this paper introduces and develops a dynamic coding scheme as a countermeasure against covert cyber-attacks. Under certain conditions and assuming the existence of one secure input and two secure output communication channels, the proposed dynamic coding scheme prevents adversaries from executing covert cyber-attacks. A numerical case study of a flight control system is provided to demonstrate the capabilities of our proposed and developed dynamic coding scheme."}
{"id": "2512.08907", "categories": ["physics.geo-ph", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2512.08907", "abs": "https://arxiv.org/abs/2512.08907", "authors": ["Alex J. Vargas", "Ranjiangshang Ran", "Justin C. Burton"], "title": "A microstructural rheological model for transient creep in polycrystalline ice", "comment": "5 pages, 4 figures, plus ancillary (supplemental) pdf", "summary": "The slow creep of glacial ice plays a key role in sea-level rise, yet its transient deformation remains poorly understood. Glen's flow law, where strain rate is simply a function of stress, cannot predict the time-dependent creep behavior observed in experiments. Here we present a physics-based rheological model that captures all three regimes of transient creep in polycrystalline ice. The key components of the model are a series of Kelvin-Voigt mechanical elements that produce a power-law (Andrade) creep, and a single viscous element with microstructure and stress dependence that represents reorientation in the polycrystalline grains. The interplay between these components produces a minimum in the strain rate at approximately 1% strain, which is a universal but unexplained feature reported in experiments. Due to its transient nature, the model exhibits fractional power-law exponents in the stress dependence of the strain rate minimum, which has been conventionally interpreted as independent physical processes. Taken together, we provide a compact, mechanistic framework for transient ice rheology that generalizes to other polycrystalline materials and can be integrated into constitutive laws for ice-sheet models."}
{"id": "2512.08209", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.08209", "abs": "https://arxiv.org/abs/2512.08209", "authors": ["Jiu Zhang", "Zhanwei Du", "Hongwei Hu", "Ke Wu", "Tongchao Li", "Chuan Shi", "Xiaohui Huang", "Yamir Moreno", "Yanqing Hu"], "title": "Restoring Network Evolution from Static Structure", "comment": null, "summary": "The dynamical evolution of complex networks underpins the structure-function relationships in natural and artificial systems. Yet, restoring a network's formation from a single static snapshot remains challenging. Here, we present a transferable machine learning framework that infers network evolutionary trajectories solely from present topology. By integrating graph neural networks with transformers, our approach unlocks a latent temporal dimension directly from the static topology. Evaluated across diverse domains, the framework achieves high transfer accuracy of up to 95.3%, demonstrating its robustness and transferability. Applied to the Drosophila brain connectome, it restores the formation times of over 2.6 million neural connections, revealing that early-forming links support essential behaviors such as mating and foraging, whereas later-forming connections underpin complex sensory and social functions. These results demonstrate that a substantial fraction of evolutionary information is encoded within static network architecture, offering a powerful, general tool for elucidating the hidden temporal dynamics of complex systems."}
{"id": "2512.08597", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.08597", "abs": "https://arxiv.org/abs/2512.08597", "authors": ["Hao Dong", "Liqun Cao"], "title": "A fourth-order multi-scale computational method and its convergence analysis for composite Kirchhoff plates with microscopic periodic configurations", "comment": null, "summary": "The Kirchhoff plate model plays a vital role in modeling, computing and analyzing the mechanical behaviors of thin plate structures. This study propose a novel fourth-order multi-scale (FOMS) computational method for high-accuracy and efficient simulation of composite Kirchhoff plates with highly periodic heterogeneities. At first, two-scale asymptotic expansion theory is employed to establish the high-accuracy fourth-order multi-scale computation model with novel fourth-order correctors for composite Kirchhoff plates, which are governed by fourth-order partial differential equation (PDE) with periodically oscillatory and highly discontinuous coefficients. Then, the locally point-wise error analysis is derived to theoretically illustrate the local balance preserving of fourth-order multi-scale model enabling high-accuracy multi-scale computation. Furthermore, a global error estimation with an explicit order for fourth-order multi-scale solutions is first demonstrated under appropriate assumptions. In contrast to the second- and third-order multi-scale solutions, only the fourth-order one is capable of providing an explicit error order estimate. Additionally, an efficient numerical algorithm is developed to conduct high-accuracy simulation for heterogeneous plate structures. Extensive numerical examples are provided to confirm the theoretical results for the computational convergence and accuracy of the proposed method. This work offers a higher-order (fourth-order) multi-scale computational framework that enables robust simulation and high-accuracy analysis to composite Kirchhoff plates."}
{"id": "2512.08173", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.08173", "abs": "https://arxiv.org/abs/2512.08173", "authors": ["Fatih Kızılaslan", "Valeria Vitelli"], "title": "Bayesian Semiparametric Mixture Cure (Frailty) Models", "comment": "27 pages, 4 tables, 8 figures", "summary": "In recent years, mixture cure models have gained increasing popularity in survival analysis as an alternative to the Cox proportional hazards model, particularly in settings where a subset of patients is considered cured. The proportional hazards mixture cure model is especially advantageous when the presence of a cured fraction can be reasonably assumed, providing a more accurate representation of long-term survival dynamics. In this study, we propose a novel hierarchical Bayesian framework for the semiparametric mixture cure model, which accommodates both the inclusion and exclusion of a frailty component, allowing for greater flexibility in capturing unobserved heterogeneity among patients. Samples from the posterior distribution are obtained using a Markov chain Monte Carlo method, leveraging a hierarchical structure inspired by Bayesian Lasso. Comprehensive simulation studies are conducted across diverse scenarios to evaluate the performance and robustness of the proposed models. Bayesian model comparison and assessment are performed using various criteria. Finally, the proposed approaches are applied to two well-known datasets in the cure model literature: the E1690 melanoma trial and a colon cancer clinical trial."}
{"id": "2512.08431", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08431", "abs": "https://arxiv.org/abs/2512.08431", "authors": ["Giuseppe Buttazzo", "Juan Casado-Díaz", "Faustino Maestre"], "title": "Optimal coefficients for elliptic PDEs", "comment": "15 pages, 9 figures", "summary": "We consider an optimization problem related to elliptic PDEs of the form $-{\\rm div}(a(x)\\nabla u)=f$ with Dirichlet boundary condition on a given domain $Ω$. The coefficient $a(x)$ has to be determined, in a suitable given class of admissible choices, in order to optimize a given criterion. We first deal with the case when the cost is the so-called elastic compliance, and then we discuss the more general case when the problem is written as an optimal control problem."}
{"id": "2512.08146", "categories": ["stat.ME", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.08146", "abs": "https://arxiv.org/abs/2512.08146", "authors": ["Fangzheng Xie", "Hsin-Hsiung Huang"], "title": "Uncertainty quantification for mixed membership in multilayer networks with degree heterogeneity using Gaussian variational inference", "comment": null, "summary": "Analyzing multilayer networks is central to understanding complex relational measurements collected across multiple conditions or over time. A pivotal task in this setting is to quantify uncertainty in community structure while appropriately pooling information across layers and accommodating layer-specific heterogeneity. Building on the multilayer degree-corrected mixed-membership (ML-DCMM) model, which captures both stable community membership profiles and layer-specific vertex activity levels, we propose a Bayesian inference framework based on a spectral-assisted likelihood. We then develop a computationally efficient Gaussian variational inference algorithm implemented via stochastic gradient descent. Our theoretical analysis establishes a variational Bernstein--von Mises theorem, which provides a frequentist guarantee for using the variational posterior to construct confidence sets for mixed memberships. We demonstrate the utility of the method on a U.S. airport longitudinal network, where the procedure yields robust estimates, natural uncertainty quantification, and competitive performance relative to state-of-the-art methods."}
{"id": "2512.07918", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07918", "abs": "https://arxiv.org/abs/2512.07918", "authors": ["Jizhi Zhang", "Ziang Yang", "Zhaoyuan Meng", "Zhen Lu", "Yue Yang"], "title": "Quantum computing of nonlinear reacting flows via the probability density function method", "comment": null, "summary": "Quantum computing offers the promise of speedups for scientific computations, but its application to reacting flows is hindered by nonlinear source terms and the challenges of time-dependent simulations. We present a quantum framework to address these issues. We employ a probability density function (PDF) formulation to transform the nonlinear reacting-flow governing equations into high-dimensional linear ones. The entire temporal evolution is then solved as a single large linear system using the history state method, which avoids the measurement bottleneck of conventional time-marching schemes and fully leverages the advantages of quantum linear system algorithms. To extract the quantity of interest from the resulting quantum state, we develop an efficient algorithm to measure the statistical moments of the PDF, bypassing the need for costly full-state tomography. A computational complexity analysis indicates the potential for a near-exponential speedup over classical algorithms. We validate the framework by simulating a perfectly stirred reactor, demonstrating its capability to capture the PDF evolution and statistics of a nonlinear reactive system. This work establishes a pathway for applying quantum computing to nonlinear reacting flows."}
{"id": "2512.08761", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2512.08761", "abs": "https://arxiv.org/abs/2512.08761", "authors": ["Noah Grodzinski", "Robert L. Jack", "Michael E. Cates"], "title": "Spontaneous Ratchet Currents and Transition Dynamics in Active Wetting", "comment": "9 pages, 4 figures", "summary": "Self-propelled particles accumulate on repulsive barriers in so-called active wetting, but the relationship between this process and equilibrium wetting remains unclear. Using an exact (noiseless) hydrodynamic framework for an active lattice gas, we show, using a slit geometry with periodic boundary conditions, that active matter exhibits both fully- and partially-wet states, with a critical wetting transition between them. Furthermore, we demonstrate the existence of a spontaneous-symmetry-breaking ratchet current in the partially wet state, leading to departure of the bulk densities from their binodal values and the emergence of a novel dynamical pathway for the full-to-partial wetting transition. We elucidate this modified dynamical pathway using a minimal model. The results, while establishing a direct connection between active and equilibrium wetting, also identify the nonequilibrium consequences of activity."}
{"id": "2512.08197", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08197", "abs": "https://arxiv.org/abs/2512.08197", "authors": ["Jianyang Zhou"], "title": "Integrating Delay-Absorption Capability into Flight Departure Delay Prediction", "comment": "12 pages, 9 figures", "summary": "Accurately forecasting flight departure delays is essential for improving operational efficiency and mitigating the cascading disruptions that propagate through tightly coupled aircraft rotations. Traditional machine learning approaches often treat upstream delays as static variables, overlooking the dynamic recovery processes that determine whether a delay is absorbed or transmitted to subsequent legs. This study introduces a two-stage machine learning framework that explicitly models delay-absorption behavior and incorporates it into downstream delay prediction. In Stage I, a CatBoost classifier estimates the probability that a flight successfully absorbs an upstream delay based on operational, temporal, and meteorological features. This probability, termed AbsorbScore, quantifies airport- and flight-specific resilience to delay propagation. In Stage II, an XGBoost classifier integrates AbsorbScore with schedule, weather, and congestion indicators to predict whether a flight will depart more than 15 minutes late. Using U.S. domestic flight and NOAA weather data from Summer 2023, the proposed framework achieves substantial improvements over baseline models, increasing ROC-AUC from 0.865 to 0.898 and enhancing precision to 89.2% in identifying delayed flights. The results demonstrate that modeling delay absorption as an intermediate mechanism significantly improves predictive performance and yields interpretable insights into airport recovery dynamics, offering a practical foundation for data-driven delay management and proactive operational planning."}
{"id": "2512.08370", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.08370", "abs": "https://arxiv.org/abs/2512.08370", "authors": ["Van-Nham Phan"], "title": "Topological spin-up triplet excitonic condensation in two-dimensional electron-hole systems", "comment": "7 pages, 3 figures", "summary": "We investigate topological spin-up triplet excitonic condensation and its competition with other stabilities in a two-dimensional interacting electron-hole system taking into account Rashba spin-orbit coupling and external magnetic fields. Using an unrestricted Hartree-Fock approach, we self-consistently evaluate spin-selective excitonic condensate order parameters and the Chern number. The ground state phase diagram in the dependence on magnetic field and Coulomb interaction shows a spin-up triplet excitonic condensate (EC) with a nonzero Chern number, emerging uniquely away from the topologically trivial singlet and spin-down triplet EC regions. Strong spin-polarized triplet excitonic fluctuations preceding the condensation are further revealed through the signatures of the dynamical excitonic susceptibility spectra. Our results establish a class of topological quantum phases driven by excitonic coherence and suggest a realistic pathway to its realization in a distorted Janus monolayer of transition metal dichalcogenides or some twisted van der Waals heterostructures."}
{"id": "2512.08197", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08197", "abs": "https://arxiv.org/abs/2512.08197", "authors": ["Jianyang Zhou"], "title": "Integrating Delay-Absorption Capability into Flight Departure Delay Prediction", "comment": "12 pages, 9 figures", "summary": "Accurately forecasting flight departure delays is essential for improving operational efficiency and mitigating the cascading disruptions that propagate through tightly coupled aircraft rotations. Traditional machine learning approaches often treat upstream delays as static variables, overlooking the dynamic recovery processes that determine whether a delay is absorbed or transmitted to subsequent legs. This study introduces a two-stage machine learning framework that explicitly models delay-absorption behavior and incorporates it into downstream delay prediction. In Stage I, a CatBoost classifier estimates the probability that a flight successfully absorbs an upstream delay based on operational, temporal, and meteorological features. This probability, termed AbsorbScore, quantifies airport- and flight-specific resilience to delay propagation. In Stage II, an XGBoost classifier integrates AbsorbScore with schedule, weather, and congestion indicators to predict whether a flight will depart more than 15 minutes late. Using U.S. domestic flight and NOAA weather data from Summer 2023, the proposed framework achieves substantial improvements over baseline models, increasing ROC-AUC from 0.865 to 0.898 and enhancing precision to 89.2% in identifying delayed flights. The results demonstrate that modeling delay absorption as an intermediate mechanism significantly improves predictive performance and yields interpretable insights into airport recovery dynamics, offering a practical foundation for data-driven delay management and proactive operational planning."}
{"id": "2512.08339", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.08339", "abs": "https://arxiv.org/abs/2512.08339", "authors": ["Jinghui Wang", "Yutian Zeng", "Cong Xu", "Xiyun Zhang", "Zhanwei Du", "Jiarong Xie", "Jiu Zhang", "Sen Pei", "Zijian Feng", "Yanqing Hu"], "title": "Critical Thresholds in Non-Pharmaceutical Interventions for Epidemic Control", "comment": null, "summary": "Non-pharmaceutical interventions, such as contact tracing and social distancing, are critical for controlling epidemic outbreaks, yet their dynamic interactions remain underexplored. We introduce a probabilistic framework to analyze the synergy between contact tracing speed, quantified by the contact tracing period $τ$, and the average number of close contacts, $\\bar{k}_+$, reflecting social distancing measures. We identify critical thresholds ($R=1$) that separate pandemic and contained phases in the $\\bar{k}_{+}-τ$ plane, validated using high-resolution data from Shenzhen's 2022 Omicron outbreak (1,187 cases, 86,451 contacts). Our findings show that contact tracing alone can contain diseases with $R_0 < 2.12$ (95% CI 2.07-2.16), covering 43.33% of major infectious diseases, while combining with social distancing extends control to $R_0 < 7.82$ (95% CI 7.70-7.93), encompassing 86.67% of pathogens. These results, supported by empirical data, highlight the efficacy of rapid tracing and targeted social distancing as alternatives to mass PCR testing. Our framework offers actionable insights for optimizing NPI strategies, though challenges in scaling to regions with higher tracing miss rates or weaker infrastructure underscore the need for adaptive, data-driven policies."}
{"id": "2512.08611", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.08611", "abs": "https://arxiv.org/abs/2512.08611", "authors": ["Arpit Babbar", "Hendrik Ranocha"], "title": "Compact Runge-Kutta flux reconstruction methods for non-conservative hyperbolic equations", "comment": null, "summary": "Compact Runge-Kutta (cRK) Flux Reconstruction (FR) methods are a variant of RKFR methods for hyperbolic conservation laws with a compact stencil including only immediate neighboring finite elements. We extend cRKFR methods to handle hyperbolic equations with stiff source terms and non-conservative products. To handle stiff source terms, we use IMplicit EXplicit (IMEX) time integration schemes such that the implicitness is local to each solution point, and thus does not increase inter-element communication. Although non-conservative products do not correspond to a physical flux, we formulate the scheme using numerical fluxes at element interfaces. We use similar numerical fluxes for a lower order finite volume scheme on subcells of each element, which is then blended with the high order cRKFR scheme to obtain a robust scheme for problems with non-smooth solutions. Combined with a flux limiter at the element interfaces, the subcell based blending scheme preserves the physical admissibility of the solution, e.g., positivity of density and pressure for compressible Euler equations. The procedure thus leads to an admissibility preserving IMEX cRKFR scheme for hyperbolic equations with stiff source terms and non-conservative products. The capability of the scheme to handle stiff terms is shown through numerical tests involving Burgers' equations, reactive Euler's equations, and the ten moment problem. The non-conservative treatment is tested using variable advection equations, shear shallow water equations, the GLM-MHD, and the multi-ion MHD equations."}
{"id": "2512.08179", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.08179", "abs": "https://arxiv.org/abs/2512.08179", "authors": ["Yating Zou", "Marcos Matabuena", "Michael R. Kosorok"], "title": "Distributional Random Forests for Complex Survey Designs on Reproducing Kernel Hilbert Spaces", "comment": null, "summary": "We study estimation of the conditional law $P(Y|X=\\mathbf{x})$ and continuous functionals $Ψ(P(Y|X=\\mathbf{x}))$ when $Y$ takes values in a locally compact Polish space, $X \\in \\mathbb{R}^p$, and the observations arise from a complex survey design. We propose a survey-calibrated distributional random forest (SDRF) that incorporates complex-design features via a pseudo-population bootstrap, PSU-level honesty, and a Maximum Mean Discrepancy (MMD) split criterion computed from kernel mean embeddings of Hájek-type (design-weighted) node distributions. We provide a framework for analyzing forest-style estimators under survey designs; establish design consistency for the finite-population target and model consistency for the super-population target under explicit conditions on the design, kernel, resampling multipliers, and tree partitions. As far as we are aware, these are the first results on model-free estimation of conditional distributions under survey designs. Simulations under a stratified two-stage cluster design provide finite sample performance and demonstrate the statistical error price of ignoring the survey design. The broad applicability of SDRF is demonstrated using NHANES: We estimate the tolerance regions of the conditional joint distribution of two diabetes biomarkers, illustrating how distributional heterogeneity can support subgroup-specific risk profiling for diabetes mellitus in the U.S. population."}
{"id": "2512.08446", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08446", "abs": "https://arxiv.org/abs/2512.08446", "authors": ["Maximilian Pierer von Esch", "Andreas Völz", "Knut Graichen"], "title": "An Overview of Sensitivity-Based Distributed Optimization and Model Predictive Control", "comment": null, "summary": "This paper presents a concise overview of sensitivity-based methods for solving large-scale optimization problems in distributed fashion. The approach relies on sensitivities and primal decomposition to achieve coordination between the subsystems while requiring only local computations with neighbor-to-neighbor communication. We give a brief historical synopsis of its development and apply it to both static and dynamic optimization problems. Furthermore, a real-time capable distributed model predictive controller is proposed which is experimentally validated on a coupled watertank system."}
{"id": "2512.08173", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.08173", "abs": "https://arxiv.org/abs/2512.08173", "authors": ["Fatih Kızılaslan", "Valeria Vitelli"], "title": "Bayesian Semiparametric Mixture Cure (Frailty) Models", "comment": "27 pages, 4 tables, 8 figures", "summary": "In recent years, mixture cure models have gained increasing popularity in survival analysis as an alternative to the Cox proportional hazards model, particularly in settings where a subset of patients is considered cured. The proportional hazards mixture cure model is especially advantageous when the presence of a cured fraction can be reasonably assumed, providing a more accurate representation of long-term survival dynamics. In this study, we propose a novel hierarchical Bayesian framework for the semiparametric mixture cure model, which accommodates both the inclusion and exclusion of a frailty component, allowing for greater flexibility in capturing unobserved heterogeneity among patients. Samples from the posterior distribution are obtained using a Markov chain Monte Carlo method, leveraging a hierarchical structure inspired by Bayesian Lasso. Comprehensive simulation studies are conducted across diverse scenarios to evaluate the performance and robustness of the proposed models. Bayesian model comparison and assessment are performed using various criteria. Finally, the proposed approaches are applied to two well-known datasets in the cure model literature: the E1690 melanoma trial and a colon cancer clinical trial."}
{"id": "2512.07919", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.07919", "abs": "https://arxiv.org/abs/2512.07919", "authors": ["Shi Jin", "Nana Liu"], "title": "Quantum algorithms for viscosity solutions to nonlinear Hamilton-Jacobi equations based on an entropy penalisation method", "comment": null, "summary": "We present a framework for efficient extraction of the viscosity solutions of nonlinear Hamilton-Jacobi equations with convex Hamiltonians. These viscosity solutions play a central role in areas such as front propagation, mean-field games, optimal control, machine learning, and a direct application to the forced Burgers' equation. Our method is based on an entropy penalisation method proposed by Gomes and Valdinoci, which generalises the Cole-Hopf transform from quadratic to general convex Hamiltonians, allowing a reformulation of viscous Hamilton-Jacobi dynamics by a discrete-time linear dynamics which approximates a linear heat-like parabolic equation, and can also extend to continuous-time dynamics. This makes the method suitable for quantum simulation. The validity of these results hold for arbitrary nonlinearity that correspond to convex Hamiltonians, and for arbitrarily long times, thus obviating a chief obstacle in most quantum algorithms for nonlinear partial differential equations. We provide quantum algorithms, both analog and digital, for extracting pointwise values, gradients, minima, and function evaluations at the minimiser of the viscosity solution, without requiring nonlinear updates or full state reconstruction."}
{"id": "2512.08788", "categories": ["cond-mat.stat-mech", "physics.atm-clus", "physics.chem-ph", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2512.08788", "abs": "https://arxiv.org/abs/2512.08788", "authors": ["Joshua Kohpeiß", "Dominic Batzler", "Beate Bornschein", "Lutz Bornschein", "Robin Größle", "Daniel Kurz", "Ralph Lietzow", "Alexander Marsteller", "Michael Sturm", "Stefan Welte"], "title": "Commissioning of an experiment for thermodynamic and spectroscopic studies of hydrogen isotopologues at cryogenic conditions", "comment": "21 pages, 9 figures", "summary": "To study thermodynamic properties and dynamic phase space behavior of hydrogen isotopologues (Q$_2$) at cryogenic temperatures and at high density, the Tritium Absorption InfraRed Spectroscopy 2 (T$_2$ApIR) experiment has been set up and commissioned at Tritium Laboratory Karlsruhe (TLK). In the frame of the experiment, Q$_2$ behavior in different phases, ortho/para states, temperatures (10 K - 300 K) and pressures (up to 2.5 bar a) will be investigated with optical methods, infrared and Raman spectroscopy. The facility consists of a fully tritium compatible cryostat, which includes an optical cell, ortho/para converter and windows for optical and spectroscopic studies. The cryostat can be cooled below the H$_2$ triple point by a two-stage cryocooler and contains openings in the cryogenic shielding for the optical access. The challenge of combining these scientific requirements in a design with high amounts of tritium (14 g), in a limited space, all while maintaining the TLK safety philosophy was solved by the presented design. The experiment is ready to be fully integrated into the TLK closed loop tritium infrastructure. This contribution reports a comprehensive overview of the commissioning phase of the experimental facility and the results of the first commissioning experiments, including cryogenic performance tests, commissioning experiments with non-radioactive gases, and tests of the analytical instruments."}
{"id": "2512.08201", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08201", "abs": "https://arxiv.org/abs/2512.08201", "authors": ["Jared Miller", "Petros Karamanakos", "Tobias Geyer"], "title": "Bounding the Minimal Current Harmonic Distortion in Optimal Modulation of Single-Phase Power Converters", "comment": "18 pages, 6 tables, 18 figures", "summary": "Optimal pulse patterns (OPPs) are a modulation technique in which a switching signal is computed offline through an optimization process that accounts for selected performance criteria, such as current harmonic distortion. The optimization determines both the switching angles (i.e., switching times) and the pattern structure (i.e., the sequence of voltage levels). This optimization task is a challenging mixed-integer nonconvex problem, involving integer-valued voltage levels and trigono metric nonlinearities in both the objective and the constraints. We address this challenge by reinterpreting OPP design as a periodic mode-selecting optimal control problem of a hybrid system, where selecting angles and levels corresponds to choosing jump times in a transition graph. This time-domain formulation enables the direct use of convex-relaxation techniques from optimal control, producing a hierarchy of semidefinite programs that lower-bound the minimal achievable harmonic distortion and scale subquadratically with the number of converter levels and switching angles. Numerical results demonstrate the effectiveness of the proposed approachs"}
{"id": "2512.08421", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08421", "abs": "https://arxiv.org/abs/2512.08421", "authors": ["Florian Lange", "Frank Göhmann", "Gerhard Wellein", "Holger Fehske"], "title": "Decay of spin helices in XXZ quantum spin chains with single-ion anisotropy", "comment": "6 pages, 6 figures", "summary": "Long-lived spin-helix states facilitate the study of non-equilibrium dynamics in quantum magnets. We consider the decay of transverse spin-helices in antiferromagnetic spin-$S$ XXZ chains with single-ion anisostropy. The spin-helix decay is observable in the time evolution of the local magnetization that we calculate numerically for the system in the thermodynamic limit using infinite time-evolving block decimation simulations. Although the single-ion anisotropy prevents helix states from being eigenstates of the Hamiltonian, they still can be long-lived for appropriately chosen wave numbers. In case of an easy-axis exchange anisotropy the single-ion anisotropy may even stabilize the helices. Within a spin-wave approximation, we obtain a condition giving an estimate for the most stable wave number $Q$ that agrees qualitatively with our numerical results."}
{"id": "2512.08201", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08201", "abs": "https://arxiv.org/abs/2512.08201", "authors": ["Jared Miller", "Petros Karamanakos", "Tobias Geyer"], "title": "Bounding the Minimal Current Harmonic Distortion in Optimal Modulation of Single-Phase Power Converters", "comment": "18 pages, 6 tables, 18 figures", "summary": "Optimal pulse patterns (OPPs) are a modulation technique in which a switching signal is computed offline through an optimization process that accounts for selected performance criteria, such as current harmonic distortion. The optimization determines both the switching angles (i.e., switching times) and the pattern structure (i.e., the sequence of voltage levels). This optimization task is a challenging mixed-integer nonconvex problem, involving integer-valued voltage levels and trigono metric nonlinearities in both the objective and the constraints. We address this challenge by reinterpreting OPP design as a periodic mode-selecting optimal control problem of a hybrid system, where selecting angles and levels corresponds to choosing jump times in a transition graph. This time-domain formulation enables the direct use of convex-relaxation techniques from optimal control, producing a hierarchy of semidefinite programs that lower-bound the minimal achievable harmonic distortion and scale subquadratically with the number of converter levels and switching angles. Numerical results demonstrate the effectiveness of the proposed approachs"}
{"id": "2512.08741", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.08741", "abs": "https://arxiv.org/abs/2512.08741", "authors": ["Louis Boucherie", "Yong-Yeol Ahn", "Sune Lehmann"], "title": "Adaptive cut reveals multiscale complexity in networks", "comment": null, "summary": "Hierarchical clustering and community detection are important problems in machine learning and complex network analysis. A common approach to identify clusters is to simply cut dendrograms at some threshold. However, single-level cuts are often suboptimal in terms of capturing underlying structure in the data, especially when the dendrogram is unbalanced. In this paper, we present the adaptive cut, a novel method that leverages the hierarchical structure of dendrograms by employing multi-level cuts to overcome the limitations of single-level approaches. The adaptive cut optimizes an objective function using a Markov chain Monte Carlo with simulated annealing, resulting in better partitions. We demonstrate the effectiveness of the adaptive cut through applications to link clustering and modularity optimization, but note that the method is applicable to any clustering task that relies on a dendrogram and an objective function. Beyond the adaptive cut, we introduce the balancedness score, an information-theoretic metric that quantifies how balanced a dendrogram is. Balancedness predicts the potential benefits of using multi-level cuts. For the community detection examples, we evaluate our method on more than 200 real-world networks and multiple synthetic datasets, demonstrating significant improvements in partition density and modularity over traditional single-cut approaches. In addition, we show the generality of the adaptive cut by applying it across various hierarchical clustering techniques and objective functions. Our results indicate that the adaptive cut provides a robust and versatile tool for improving clustering outcomes."}
{"id": "2512.08728", "categories": ["math.NA", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.08728", "abs": "https://arxiv.org/abs/2512.08728", "authors": ["Teoman Toprak", "Florian Kummer"], "title": "A Task Parallel Orthonormalization Multigrid Method For Multiphase Elliptic Problems", "comment": "23 pages, 7 figures, 4 tables", "summary": "Multigrid methods have been a popular approach for solving linear systems arising from the discretization of partial differential equations (PDEs) for several decades. They are particularly effective for accelerating convergence rates with optimal complexity in terms of both time and space. K-cycle orthonormalization multigrid is a robust variant of the multigrid method that combines the efficiency of multigrid with the robustness of Krylov-type residual minimalizations for problems with strong anisotropies. However, traditional implementations of K-cycle orthonormalization multigrid often rely on bulk-synchronous parallelism, which can limit scalability on modern high-performance computing (HPC) systems. This paper presents a task- parallel variant of the K-cycle orthonormalization multigrid method that leverages asynchronous execution to improve scalability and performance on large-scale parallel systems."}
{"id": "2512.08182", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08182", "abs": "https://arxiv.org/abs/2512.08182", "authors": ["Yongda Wang", "Shifeng Xiong"], "title": "Nonparametric inference with massive data via grouped empirical likelihood", "comment": null, "summary": "To address the computational issue in empirical likelihood methods with massive data, this paper proposes a grouped empirical likelihood (GEL) method. It divides $N$ observations into $n$ groups, and assigns the same probability weight to all observations within the same group. GEL estimates the $n\\ (\\ll N)$ weights by maximizing the empirical likelihood ratio. The dimensionality of the optimization problem is thus reduced from $N$ to $n$, thereby lowering the computational complexity. We prove that GEL possesses the same first order asymptotic properties as the conventional empirical likelihood method under the estimating equation settings and the classical two-sample mean problem. A distributed GEL method is also proposed with several servers. Numerical simulations and real data analysis demonstrate that GEL can keep the same inferential accuracy as the conventional empirical likelihood method, and achieves substantial computational acceleration compared to the divide-and-conquer empirical likelihood method. We can analyze a billion data with GEL in tens of seconds on only one PC."}
{"id": "2512.08576", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08576", "abs": "https://arxiv.org/abs/2512.08576", "authors": ["Hannah Bakker", "Gianfranco Guastaroba", "Stefan Nickel", "M. Grazia Speranza"], "title": "Enhancing Kernel Search with Pattern Recognition: the Single-Source Capacitated Facility Location Problem", "comment": null, "summary": "We introduce Pattern-based Kernel Search (PaKS), a two-phase matheuristic for the solution of the Single-Source Capacitated Facility Location Problem (SSCFLP). In the first phase, PaKS employs a pattern recognition technique to identify an implicit spatial separation of potential locations and customers into subsets, called regions, within which location and assignment decisions are strongly interdependent. In the second phase, PaKS employs an enhanced Kernel Search (KS) heuristic that leverages the interdependencies among the decision variables identified in the first phase. On a set of 112 benchmark instances, consisting of up to 1,000 locations and 1,000 customers, computational results show that PaKS consistently outperforms both a standard KS implementation and the current state-of-the-art heuristic for solving the SSCFLP, as well as CPLEX when run with a time limit. For these instances, PaKS achieved an average gap compared to the best known solution of 0.02%. Experimental results conducted on a large set of new very large test problems, comprising up to 2,000 locations and 2,000 customers, demonstrate that PaKS outperforms both the standard KS heuristic and CPLEX in terms of quality of the solution found, finding the largest number of best solutions, and achieving the smallest average gap."}
{"id": "2512.08232", "categories": ["stat.ME", "math.PR", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.08232", "abs": "https://arxiv.org/abs/2512.08232", "authors": ["Léo R. Belzile", "Christian Genest", "Frédéric Ouimet", "Donald Richards"], "title": "Wishart kernel density estimation for strongly mixing time series on the cone of positive definite matrices", "comment": "40 pages, 4 figures, 2 tables", "summary": "A Wishart kernel density estimator (KDE) is introduced for density estimation in the cone of positive definite matrices. The estimator is boundary-aware and mitigates the boundary bias suffered by conventional KDEs, while remaining simple to implement. Its mean squared error, uniform strong consistency on expanding compact sets, and asymptotic normality are established under the Lebesgue measure and suitable mixing conditions. This work represents the first study of density estimation on this space under any metric. For independent observations, an asymptotic upper bound on the mean absolute error is also derived. A simulation study compares the performance of the Wishart KDE to another boundary-aware KDE that relies on the matrix-variate lognormal distribution proposed by Schwartzman [Int. Stat. Rev., 2016, 84(3), 456-486]. Results suggest that the Wishart KDE is superior for a selection of autoregressive coefficient matrices and innovation covariance matrices when estimating the stationary marginal density of a Wishart autoregressive process. To illustrate the practical utility of the Wishart KDE, an application to finance is made by estimating the marginal density function of a time series of realized covariance matrices, calculated from 5-minute intra-day returns, between the share prices of Amazon Corp. and the Standard & Poor's 500 exchange-traded fund over a one-year period. All code is publicly available via the R package ksm to facilitate implementation of the method and reproducibility of the findings."}
{"id": "2512.07953", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07953", "abs": "https://arxiv.org/abs/2512.07953", "authors": ["Shreya Kumar", "Alex E Jones", "Daniel Bhatti", "Stefanie Barz"], "title": "Exchange Symmetry in Multiphoton Quantum Interference", "comment": "14 pages, 5 figures", "summary": "Photons are bosons, and yet, when prepared in specific entangled states, they can exhibit non-bosonic behaviour. While this phenomenon has so far been studied in two-photon systems, exchange symmetries and interference effects in multi-photon scenarios remain largely unexplored. In this work, we show that multi-photon states uncover a rich landscape of exchange symmetries. With three photons already, multiple pairwise combinations are possible, where each pair of photons can exhibit either bosonic, fermionic, or anyonic exchange symmetry. This gives rise to mixed symmetry systems that are not possible to achieve with two photon alone. We experimentally investigate how these symmetry configurations manifest themselves in the observed interference of three photons. We show that multi-photon interference can be effectively turned on and off by tuning the symmetry of the constituent pairs. The possibility of accessing and tuning new quantum statistics in a scalable photonic platform not only deepens our understanding of quantum systems, but is also highly relevant for quantum technologies that rely on quantum interference."}
{"id": "2512.08793", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08793", "abs": "https://arxiv.org/abs/2512.08793", "authors": ["Alex V. Plyukhin"], "title": "Langevin equation with potential of mean force: The case of anchored bath", "comment": "19 pages 3 figures", "summary": "The potential of mean force (PMF) is an effective average potential acting on an open system, renormalized due to the interaction with the surrounding thermal bath. The PMF is defined for an equilibrium ensemble, and generally it is not clear how to use it when the system is out of equilibrium and described by a (generalized) Langevin equation. We study a model where the system is a single particle (so there are no complications related to internal forces) and a non-trivial PMF is due to the presence of on-site (anchor) potentials applied to the bath particles. We found that the PMF does not merely replace the external potential, but also makes the dissipation kernel and statistical properties of noise dependent on the system's position. That dependence is determined by the internal bath and system-bath interactions and is a priori unknown. Therefore, in the general case the Langevin equation with the PMF is not closed and thus inoperable. However, for systems with linear forces the aforementioned dependence on the system's position may be canceled. As an example, we consider a model where the bath is formed by the Klein-Gordon chain, i. e. a harmonic chain with on-site harmonic potentials. In that case, the generalized Langevin equation has the standard form with an external potential replaced by a quadratic PMF."}
{"id": "2512.08265", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08265", "abs": "https://arxiv.org/abs/2512.08265", "authors": ["Ali Ameri", "Jun-Chau Chien", "Ali M. Niknejad"], "title": "Theoretical Studies of Sub-THz Active Split-Ring Resonators for Near-Field Imaging", "comment": null, "summary": "This paper develops a theoretical framework for the design of Active Split-Ring Resonators (ASRRs). An ASRR is a Split-Ring Resonator (SRR) equipped with a tunable negative resistor, enabling both switchability and quality factor boosting and tuning. These properties make ASRRs well-suited for integration into dense arrays on silicon chips, where pixelated near-fields are generated and leveraged for high-resolution 2D imaging of samples. Such imagers pave the way for real-time, non-invasive, and low-cost imaging of human body tissue. The paper investigates ASRR coupling to host transmission lines, nonlinear effects, signal flow, and the influence of various noise sources on detection performance. Verified through simulations, these studies provide design guidelines for optimizing the Signal-to-Noise Ratio (SNR) and power consumption of a single pixel, while adhering to the constraints of a scalable array."}
{"id": "2512.08624", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08624", "abs": "https://arxiv.org/abs/2512.08624", "authors": ["Jonas B. Rigo", "Markus Schmitt"], "title": "Operator Lanczos Approach enabling Neural Quantum States as Real-Frequency Impurity Solvers", "comment": "5 pages, 3 figures, appendices", "summary": "To understand the intricate exchange between electrons of different bands in strongly correlated materials, it is essential to treat multi-orbital models accurately. For this purpose, dynamical mean-field theory (DMFT) provides an established framework, whose scope crucially hinges on the availability of efficient quantum impurity solvers. Here we present a real-frequency impurity solver based on neural quantum states (NQS) combined with an operator-Lanczos construction. NQS are an asymptotically unbiased variational ground-state ansatz that employs neural networks to capture long-range correlations on complicated graph structures. We leverage this ability to solve multi-orbital impurity problems using a systematically improvable Segmented Commutator Operator-Lanczos (SCOL) construction. Our benchmarks on both the single-orbital Anderson model and the multi-orbital Hubbard-Kanamori impurity Hamiltonian reveal excellent ground-state precision and the capacity to accurately resolve zero temperature spectral functions and self-energies. These results open avenues for extending DMFT to more challenging problems."}
{"id": "2512.08265", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08265", "abs": "https://arxiv.org/abs/2512.08265", "authors": ["Ali Ameri", "Jun-Chau Chien", "Ali M. Niknejad"], "title": "Theoretical Studies of Sub-THz Active Split-Ring Resonators for Near-Field Imaging", "comment": null, "summary": "This paper develops a theoretical framework for the design of Active Split-Ring Resonators (ASRRs). An ASRR is a Split-Ring Resonator (SRR) equipped with a tunable negative resistor, enabling both switchability and quality factor boosting and tuning. These properties make ASRRs well-suited for integration into dense arrays on silicon chips, where pixelated near-fields are generated and leveraged for high-resolution 2D imaging of samples. Such imagers pave the way for real-time, non-invasive, and low-cost imaging of human body tissue. The paper investigates ASRR coupling to host transmission lines, nonlinear effects, signal flow, and the influence of various noise sources on detection performance. Verified through simulations, these studies provide design guidelines for optimizing the Signal-to-Noise Ratio (SNR) and power consumption of a single pixel, while adhering to the constraints of a scalable array."}
{"id": "2512.08861", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.08861", "abs": "https://arxiv.org/abs/2512.08861", "authors": ["Louis Boucherie", "Sagar Kumar", "Katharina Ledebur", "August Lohse", "Karolina Sliwa"], "title": "Cultural evolution of human beauty standards", "comment": null, "summary": "Beauty standards shape self-perception and health through social comparison and objectification, while exposure to idealized imagery exacerbates body-image concerns. Media and fashion are central arbiters of these ideals, yet long-term, quantitative, intersectional studies on how representation has changed remain scarce. We assembled a dataset of 793199 records spanning 25 years of advertising, magazine covers, runway shows, and editorials to quantify changes in anthropometric and demographic representation. We find a paradox in the evolution of beauty ideals: while representational diversity has increased, the median model physique remains stable. This is driven by selective plus-size inclusion at the upper tail, while the typical physique continues to diverge from the US population. Intersectionally, non-white models are 4.5 times more likely to be plus-size, indicating that progress in size inclusivity falls disproportionately on multiple underrepresented identities. Stratifying the industry via a data-driven prestige hierarchy, we find that thinness is overrepresented at the top tier. Finally, comparing two regulatory interventions we observe that numeric thresholds are more effective at reducing underweight appearances. Our results quantify the cultural evolution in media and fashion, revealing that inclusion has increased; however, gains are uneven and intersectionally concentrated on size and ethnicity, whereas the prevailing thin ideal remains largely unchanged."}
{"id": "2512.08758", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.08758", "abs": "https://arxiv.org/abs/2512.08758", "authors": ["Martin Burger", "Samira Kabri", "Gitta Kutyniok", "Yunseok Lee", "Lukas Weigand"], "title": "Explainable Learning Based Regularization of Inverse Problems", "comment": "38 pages, 3 figures", "summary": "Machine learning techniques for the solution of inverse problems have become an attractive approach in the last decade, while their theoretical foundations are still in their infancy. In this chapter we want to pursue the study of regularization properties, robustness, convergence rates, and structure of regularizers for inverse problems obtained from different learning paradigms. For this sake we study simple architectures that are explainable in the sense that they allow for a theoretical analysis also in the infinite-dimensional limit. In particular we will advance the study of spectral architectures with new results on convergence rates highlighting the role of the smoothness in the training data set, and a study of adversarial robustness. We can show that adversarial training is actually a convergent regularization method. Moreover, we discuss extensions to frame systems and CNN-type architectures for variational regularizers, where we obtain some results on their structure by carefully designed numerical experiments."}
{"id": "2512.08232", "categories": ["stat.ME", "math.PR", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.08232", "abs": "https://arxiv.org/abs/2512.08232", "authors": ["Léo R. Belzile", "Christian Genest", "Frédéric Ouimet", "Donald Richards"], "title": "Wishart kernel density estimation for strongly mixing time series on the cone of positive definite matrices", "comment": "40 pages, 4 figures, 2 tables", "summary": "A Wishart kernel density estimator (KDE) is introduced for density estimation in the cone of positive definite matrices. The estimator is boundary-aware and mitigates the boundary bias suffered by conventional KDEs, while remaining simple to implement. Its mean squared error, uniform strong consistency on expanding compact sets, and asymptotic normality are established under the Lebesgue measure and suitable mixing conditions. This work represents the first study of density estimation on this space under any metric. For independent observations, an asymptotic upper bound on the mean absolute error is also derived. A simulation study compares the performance of the Wishart KDE to another boundary-aware KDE that relies on the matrix-variate lognormal distribution proposed by Schwartzman [Int. Stat. Rev., 2016, 84(3), 456-486]. Results suggest that the Wishart KDE is superior for a selection of autoregressive coefficient matrices and innovation covariance matrices when estimating the stationary marginal density of a Wishart autoregressive process. To illustrate the practical utility of the Wishart KDE, an application to finance is made by estimating the marginal density function of a time series of realized covariance matrices, calculated from 5-minute intra-day returns, between the share prices of Amazon Corp. and the Standard & Poor's 500 exchange-traded fund over a one-year period. All code is publicly available via the R package ksm to facilitate implementation of the method and reproducibility of the findings."}
{"id": "2512.08757", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08757", "abs": "https://arxiv.org/abs/2512.08757", "authors": ["Ujjwal Pratap", "Steffen Hofmann"], "title": "Saturation-based robustly optimal hierarchical operation control of microgrids", "comment": null, "summary": "This paper studies the problem of robustly optimal operation control of microgrids with a high share of renewable energy sources. The main goal is to ensure optimal operation under a wide range of circumstances, given the highly intermittent and uncertain nature of renewable sources and load demand. We formally state this problem, and, in order to solve it, we make effective use of the hierarchical power system control approach. We consider an enhanced primary control layer including droop control and autonomous limitation of power and energy. We prove that this enables the use of constant power setpoints to achieve optimal operation under certain conditions. In order to relax these conditions, the approach is combined with an energy management system, which solves a robust unit commitment problem within a model predictive control framework. Finally, a case study demonstrates the viability of the control design."}
{"id": "2512.07962", "categories": ["quant-ph", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2512.07962", "abs": "https://arxiv.org/abs/2512.07962", "authors": ["M. A. Castellanos-Beltran", "A. J. Sirois", "L. Howe", "D. I. Olaya", "J. Biesecker", "S. P. Benz", "P. F. Hopkins"], "title": "Coherence-limited digital control of a superconducting qubit using a Josephson pulse generator at 3 K", "comment": "9 pages, 8 figures, Applied Physics Letters", "summary": "Compared to traditional semiconductor control electronics (TSCE) located at room temperature, cryogenic single flux quantum (SFQ) electronics can provide qubit measurement and control alternatives that address critical issues related to scalability of cryogenic quantum processors. Single-qubit control and readout have been demonstrated recently using SFQ circuits coupled to superconducting qubits. Experiments where the SFQ electronics are co-located with the qubit have suffered from excess decoherence and loss due to quasiparticle poisoning of the qubit. A previous experiment by our group showed that moving the control electronics to the 3 K stage of the dilution refrigerator avoided this source of decoherence in a high-coherence 3D transmon geometry. In this paper, we also generate the pulses at the 3 K stage but have optimized the qubit design and control lines for scalable 2D transmon devices. We directly compare the qubit lifetime $T_1$, coherence time $T_2^*$ and gate fidelity when the qubit is controlled by the Josephson pulse generator (JPG) circuit versus the TSCE setup. We find agreement to within the daily fluctuations for $T_1$ and $T_2^*$, and agreement to within 10% for randomized benchmarking. We also performed interleaved randomized benchmarking on individual JPG gates demonstrating an average error per gate of $0.46$% showing good agreement with what is expected based on the qubit coherence and higher-state leakage. These results are an order of magnitude improvement in gate fidelity over our previous work and demonstrate that a Josephson microwave source operated at 3 K is a promising component for scalable qubit control."}
{"id": "2512.08298", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08298", "abs": "https://arxiv.org/abs/2512.08298", "authors": ["Zeyu Mu", "Sergei S. Avedisov", "Ahmadreza Moradipari", "B. Brian Park"], "title": "Formation and Investigation of Cooperative Platooning at the Early Stage of Connected and Automated Vehicles Deployment", "comment": null, "summary": "Cooperative platooning, enabled by cooperative adaptive cruise control (CACC), is a cornerstone technology for connected automated vehicles (CAVs), offering significant improvements in safety, comfort, and traffic efficiency over traditional adaptive cruise control (ACC). This paper addresses a key challenge in the initial deployment phase of CAVs: the limited benefits of cooperative platooning due to the sparse distribution of CAVs on the road. To overcome this limitation, we propose an innovative control framework that enhances cooperative platooning in mixed traffic environments. Two techniques are utilized: (1) a mixed cooperative platooning strategy that integrates CACC with unconnected vehicles (CACCu), and (2) a strategic lane-change decision model designed to facilitate safe and efficient lane changes for platoon formation. Additionally, a surrounding vehicle identification system is embedded in the framework to enable CAVs to effectively identify and select potential platooning leaders. Simulation studies across various CV market penetration rates (MPRs) show that incorporating CACCu systems significantly improves safety, comfort, and traffic efficiency compared to existing systems with only CACC and ACC systems, even at CV penetration as low as 10%. The maximized platoon formation increases by up to 24%, accompanied by an 11% reduction in acceleration and a 7% decrease in fuel consumption. Furthermore, the strategic lane-change model enhances CAV performance, achieving notable improvements between 6% and 60% CV penetration, without adversely affecting overall traffic flow."}
{"id": "2512.08712", "categories": ["cond-mat.str-el", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08712", "abs": "https://arxiv.org/abs/2512.08712", "authors": ["Aprem P. Joy", "Roman Lange", "Achim Rosch"], "title": "Diffusion and relaxation of topological excitations in layered spin liquids", "comment": "12 pages, 6 Figures", "summary": "Relaxation processes in topological phases such as quantum spin liquids are controlled by the dynamics and interaction of fractionalized excitations. In layered materials hosting two-dimensional topological phases, elementary quasiparticles can diffuse freely within the layer, whereas only pairs (or more) can hop between layers - a fundamental consequence of topological order. Using exact solutions of emergent nonlinear diffusion equations and particle-based stochastic simulations, we explore how pump-probe experiments can provide unique signatures of the presence of $2d$ topological excitations in a $3d$ material. Here we show that the characteristic time scale of such experiments is inversely proportional to the initial excitation density, set by the pump intensity. A uniform excitation density created on the surface of a sample spreads subdiffusively into the bulk with a mean depth $\\bar z$ scaling as $\\sim t^{1/3}$ when annihilation processes are absent. The propagation becomes logarithmic, $\\bar z \\sim \\log t$, when pair-annihilation is allowed. Furthermore, pair-diffusion between layers leads to a new decay law for the total density, $n(t) \\sim (\\log^2 t)/t$ - slower than in a purely $2d$ system. We discuss possible experimental implications for pump-probe experiments in samples of finite width."}
{"id": "2512.08298", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08298", "abs": "https://arxiv.org/abs/2512.08298", "authors": ["Zeyu Mu", "Sergei S. Avedisov", "Ahmadreza Moradipari", "B. Brian Park"], "title": "Formation and Investigation of Cooperative Platooning at the Early Stage of Connected and Automated Vehicles Deployment", "comment": null, "summary": "Cooperative platooning, enabled by cooperative adaptive cruise control (CACC), is a cornerstone technology for connected automated vehicles (CAVs), offering significant improvements in safety, comfort, and traffic efficiency over traditional adaptive cruise control (ACC). This paper addresses a key challenge in the initial deployment phase of CAVs: the limited benefits of cooperative platooning due to the sparse distribution of CAVs on the road. To overcome this limitation, we propose an innovative control framework that enhances cooperative platooning in mixed traffic environments. Two techniques are utilized: (1) a mixed cooperative platooning strategy that integrates CACC with unconnected vehicles (CACCu), and (2) a strategic lane-change decision model designed to facilitate safe and efficient lane changes for platoon formation. Additionally, a surrounding vehicle identification system is embedded in the framework to enable CAVs to effectively identify and select potential platooning leaders. Simulation studies across various CV market penetration rates (MPRs) show that incorporating CACCu systems significantly improves safety, comfort, and traffic efficiency compared to existing systems with only CACC and ACC systems, even at CV penetration as low as 10%. The maximized platoon formation increases by up to 24%, accompanied by an 11% reduction in acceleration and a 7% decrease in fuel consumption. Furthermore, the strategic lane-change model enhances CAV performance, achieving notable improvements between 6% and 60% CV penetration, without adversely affecting overall traffic flow."}
{"id": "2512.08841", "categories": ["math.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.08841", "abs": "https://arxiv.org/abs/2512.08841", "authors": ["Mukthesh Mahadev", "Marc Gerritsma"], "title": "Space-time discretization for barotropic flow stemming from a multisymplectic variational formulation", "comment": null, "summary": "This study proposes and analyses a novel higher-order, structure preserving discretization method for inviscid barotropic flows from a Lagrangian perspective. The method is built on a multisymplectic variational principle discretized over a full space-time domain. Flow variables are encoded on a staggered space-time mesh, leveraging the principles of mimetic spectral element discretization. Unlike standard Lagrangian methods, which are prone to mesh distortion, this framework computes fluid deformations in a fixed reference configuration and systematically maps them to the physical domain via the Piola-Kirchhoff stress. Further, the structure preserving design ensures that the discrete analogues of the fundamental conservation laws for mass, momentum, and energy are satisfied up to machine precision. The formulation also inherently handles low-Mach number flows without specialized preconditioning. Numerical experiments on expansion and compression flows confirm the accuracy, stability, and exact conservation properties of the discretization."}
{"id": "2512.08258", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08258", "abs": "https://arxiv.org/abs/2512.08258", "authors": ["Yiwei Tang", "Judy Huixia Wang", "Deyuan Li"], "title": "Perturbation-based Inference for Extreme Value Index", "comment": null, "summary": "The extreme value index (EVI) characterizes the tail behavior of a distribution and is crucial for extreme value theory. Inference on the EVI is challenging due to data scarcity in the tail region. We propose a novel method for constructing confidence intervals for the EVI using synthetic exceedances generated via perturbation. Rather than perturbing the entire sample, we add noise to exceedances above a high threshold and apply the generalized Pareto distribution (GPD) approximation. Confidence intervals are derived by simulating the distribution of pivotal statistics from the perturbed data. We show that the pivotal statistic is consistent, ensuring the proposed method provides consistent intervals for the EVI. Additionally, we demonstrate that the perturbed data is differentially private. When the GPD approximation is inadequate, we introduce a refined perturbation method. Simulation results show that our approach outperforms existing methods, providing robust and reliable inference."}
{"id": "2512.08770", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08770", "abs": "https://arxiv.org/abs/2512.08770", "authors": ["Stuart M. Harwood", "Dimitri J. Papageorgiou"], "title": "Computing normalized Nash equilibria for generalized Nash games with nonconvex players", "comment": null, "summary": "Generalized Nash equilibrium (GNE) is a solution concept for complete information games, in which each player's objective function and feasible region depend on other players' actions. While numerical methods for finding GNE when players possess convex structure are relatively mature, the same cannot be said when players optimize nonconvex objective functions over nonconvex feasible regions. Drawing inspiration from the notion of a normalized (or variational) Nash equilibrium, which is a more restrictive class of solutions to generalized Nash games, we extend the ideas of Harwood et al. (\"Equilibrium modeling and solution approaches inspired by nonconvex bilevel programming.\" Computational Optimization and Applications, 87(2):641-676, 2024) to develop an exact method that can find a normalized Nash equilibrium (NNE) of a problem, when such an NNE exists. By adapting the framework of Harwood et al., we are able to find NNE without any convexity assumptions. We demonstrate the effectiveness of our method on several nonconvex games."}
{"id": "2512.07966", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.07966", "abs": "https://arxiv.org/abs/2512.07966", "authors": ["Zhiyi Wu", "Xuandong Sun", "Songlei Wang", "Jiawei Zhang", "Xiaohan Yang", "Ji Chu", "Jingjing Niu", "Youpeng Zhong", "Xiao Chen", "Zhi-Cheng Yang", "Dapeng Yu"], "title": "Measurement-and Feedback-Driven Non-Equilibrium Phase Transitions on a Quantum Processor", "comment": null, "summary": "Mid-circuit measurements and feedback operations conditioned on the measurement outcomes are essential for implementing quantum error-correction on quantum hardware. When integrated in quantum many-body dynamics, they can give rise to novel non-equilibrium phase transitions both at the level of each individual quantum trajectory and the averaged quantum channel. Experimentally resolving both transitions on realistic devices has been challenging due to limitations on the fidelity and the significant latency for performing mid-circuit measurements and feedback operations in real time. Here, we develop a superconducting quantum processor that enables global mid-circuit measurement with an average quantum non-demolition (QND) fidelity of 98.7% and fast conditional feedback with a 200 ns real-time decision latency. Using this platform, we demonstrate the coexistence of an absorbing-state transition in the quantum channel and a measurement-induced entanglement transition at the level of individual quantum trajectories. For the absorbing-state transition, we experimentally extract a set of critical exponents at the transition point, which is in excellent agreement with the directed percolation universality class. Crucially, the two transitions occur at distinct values of the tuning parameter. Our results demonstrate that adaptive quantum circuits provide a powerful platform for exploring non-equilibrium quantum many-body dynamics."}
{"id": "2512.08691", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08691", "abs": "https://arxiv.org/abs/2512.08691", "authors": ["Michele Castellana"], "title": "Order parameter for non-mean-field spin glasses", "comment": null, "summary": "We propose a novel renormalization group (RG) method for non mean-field models of spin glasses, which leads to the emergence of a novel order parameter. Unlike previous approaches where the RG procedure is based on a priori notions on the system, our analysis follows a minimality principle, where no a priori assumption is made. We apply our approach to a spin-glass model built on a hierarchical lattice. In the RG decimation procedure, a novel order parameter spontaneously emerges from the system symmetries, and self-similarity features of the RG transformation only. This order parameter is the projection of the spin configurations on the ground state of the system. Kadanoff's majority rule for ferromagnetic systems is replaced by a more complex scheme, which involves such novel order parameter. The ground state thus acts as a pattern which translates spin configurations from one length scale to another. The rescaling RG procedure is based on a minimal, information-theory approach and, combined with the decimation, it yields a complete RG transformation.\n  Below the upper critical dimension, the predictions for the critical exponent $ν$, which describes the critical divergence of the correlation length, are in excellent agreement with numerical simulations from both this and previous studies. Overall, this study opens new avenues in the understanding of the critical ordering of realistic spin glasses, and it can be applied to spin-glass models on a cubic lattice and nearest-neighbor couplings which directly model spin-glass materials, such as AuFe, CuMn and other magnetic alloys."}
{"id": "2512.08415", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08415", "abs": "https://arxiv.org/abs/2512.08415", "authors": ["Sunggyu Park"], "title": "Integration of AI-Driven CAD Systems in Designing Water and Power Transportation Infrastructure for Industrial and Remote Landscape Applications", "comment": "22 pages total, 3 figures", "summary": "The integration of AI into CAD systems transforms how engineers plan and develop infrastructure projects involving water and power transportation across industrial and remote landscapes. This paper discusses how AI-driven CAD systems improve the efficient, effective, and sustainable design of infrastructure by embedding automation, predictive modeling, and real-time data analytics. This study examines how AI-supported toolsets can enhance design workflows, minimize human error, and optimize resource allocation for projects in underdeveloped environments. It also addresses technical and organizational challenges to AI adoption, including data silos, interoperability issues, and workforce adaptation. The findings demonstrate that AI-powered CAD enables faster project delivery, enhanced design precision, and increased resilience to environmental and logistical constraints. AI helps connect CAD, GIS, and IoT technologies to develop self-learning, adaptive design systems that are needed to meet the increasing global demand for sustainable infrastructure."}
{"id": "2512.08722", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.08722", "abs": "https://arxiv.org/abs/2512.08722", "authors": ["Riju Pal", "Joyal J. Abraham", "Alexander Mistonov", "Swarnamayee Mishra", "Nina Stilkerich", "Suchanda Mondal", "Prabhat Mandal", "Atindra Nath Pal", "Jochen Geck", "Bernd Büchner", "Vladislav Kataev", "Alexey Alfonsov"], "title": "Disentangling the unusual magnetic anisotropy of the near-room-temperature ferromagnet Fe$_{4}$GeTe$_{2}$", "comment": null, "summary": "In the quest for two-dimensional conducting materials with high ferromagnetic ordering temperature the new family of the layered Fe$_{n}$GeTe$_{2}$ compounds, especially the near-room-temperature ferromagnet Fe$_{4}$GeTe$_{2}$, receives a significant attention. Fe$_{4}$GeTe$_{2}$ features a peculiar spin reorientation transition at $T_\\mathrm{SR} \\sim 110$ K suggesting a non-trivial temperature evolution of the magnetic anisotropy (MA) - one of the main contributors to the stabilization of the magnetic order in the low-D systems. An electron spin resonance (ESR) spectroscopic study reported here provides quantitative insights into the unusual magnetic anisotropy of Fe$_{4}$GeTe$_{2}$. At high temperatures the total MA is mostly given by the demagnetization effect with a small contribution of the counteracting intrinsic magnetic anisotropy of an easy-axis type, whose growth below a characteristic temperature $T_{\\rm shape} \\sim 150$ K renders the sample seemingly isotropic at $T_\\mathrm{SR}$. Below one further temperature $T_{\\rm d} \\sim 50$ K the intrinsic MA becomes even more complex. Importantly, all the characteristic temperatures found in the ESR experiment match those observed in transport measurements, suggesting an inherent coupling between magnetic and electronic degrees of freedom in Fe$_{4}$GeTe$_{2}$. This finding together with the observed signatures of the intrinsic two-dimensionality should facilitate optimization routes for the use of Fe$_{4}$GeTe$_{2}$ in the magneto-electronic devices, potentially even in the monolayer limit."}
{"id": "2512.08415", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08415", "abs": "https://arxiv.org/abs/2512.08415", "authors": ["Sunggyu Park"], "title": "Integration of AI-Driven CAD Systems in Designing Water and Power Transportation Infrastructure for Industrial and Remote Landscape Applications", "comment": "22 pages total, 3 figures", "summary": "The integration of AI into CAD systems transforms how engineers plan and develop infrastructure projects involving water and power transportation across industrial and remote landscapes. This paper discusses how AI-driven CAD systems improve the efficient, effective, and sustainable design of infrastructure by embedding automation, predictive modeling, and real-time data analytics. This study examines how AI-supported toolsets can enhance design workflows, minimize human error, and optimize resource allocation for projects in underdeveloped environments. It also addresses technical and organizational challenges to AI adoption, including data silos, interoperability issues, and workforce adaptation. The findings demonstrate that AI-powered CAD enables faster project delivery, enhanced design precision, and increased resilience to environmental and logistical constraints. AI helps connect CAD, GIS, and IoT technologies to develop self-learning, adaptive design systems that are needed to meet the increasing global demand for sustainable infrastructure."}
{"id": "2512.08925", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.08925", "abs": "https://arxiv.org/abs/2512.08925", "authors": ["Shi Chen", "Michael V. Klibanov", "Kevin McGoff", "Trung Truong", "Wangjiaxuan Xin", "Shuhua Yin"], "title": "Toward Practical Forecasts of Public Sentiments via Convexification for Mean Field Games: Evidence from Real World COVID-19 Discussion Data", "comment": "33 pages", "summary": "We apply a convexification-based numerical method to forecast public sentiment dynamics using Mean Field Games (MFGs). The theoretical foundation for the convexification approach, established in our prior work, guarantees global convergence to the unique solution to the MFG system. The present work demonstrates the practical potential of this framework using real-world sentiment data extracted from social media public discussion during the COVID-19 pandemic. The results show that the MFG model with appropriate parameters and convexification yields sentiment density predictions that align closely with observed data and satisfy the governing equations. While current parameter selection relies on manual calibration, our findings establish the first proof-of-concept evidence that MFG models can capture complex temporal patterns in public sentiment, laying the groundwork for future work on systematic parameter identification methods, i.e. solutions of coefficient inverse problems for the MFG system."}
{"id": "2512.08637", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08637", "abs": "https://arxiv.org/abs/2512.08637", "authors": ["Cagatay Ayhan", "Audrey N. Nash", "Roberto Vincis", "Martin Bauer", "Richard Bertram", "Tom Needham"], "title": "A Persistent Homology Pipeline for the Analysis of Neural Spike Train Data", "comment": null, "summary": "In this article, we introduce a Topological Data Analysis (TDA) pipeline for neural spike train data. Understanding how the brain transforms sensory information into perception and behavior requires analyzing coordinated neural population activity. Modern electrophysiology enables simultaneous recording of spike train ensembles, but extracting meaningful information from these datasets remains a central challenge in neuroscience. A fundamental question is how ensembles of neurons discriminate between different stimuli or behavioral states, particularly when individual neurons exhibit weak or no stimulus selectivity, yet their coordinated activity may still contribute to network-level encoding. We describe a TDA framework that identifies stimulus-discriminative structure in spike train ensembles recorded from the mouse insular cortex during presentation of deionized water stimuli at distinct non-nociceptive temperatures. We show that population-level topological signatures effectively differentiate oral thermal stimuli even when individual neurons provide little or no discrimination. These findings demonstrate that ensemble organization can carry perceptually relevant information that standard single-unit analysis may miss. The framework builds on a mathematical representation of spike train ensembles that enables persistent homology to be applied to collections of point processes. At its core is the widely-used Victor-Purpura (VP) distance. Using this metric, we construct persistence-based descriptors that capture multiscale topological features of ensemble geometry. Two key theoretical results support the method: a stability theorem establishing robustness of persistent homology to perturbations in the VP metric parameter, and a probabilistic stability theorem ensuring robustness of topological signatures."}
{"id": "2512.08775", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08775", "abs": "https://arxiv.org/abs/2512.08775", "authors": ["Aleksandr Shestakov", "Nail Bashirov", "Andrei Semenov", "Alexander Gasnikov", "Martin Takáč", "Aleksandr Beznosikov", "Dmitry Kamzolov"], "title": "Adaptive Regularized Newton Method with Inexact Hessian", "comment": null, "summary": "Newton's method is the most widespread high-order method, demanding the gradient and the Hessian of the objective function. However, one of the main disadvantages of Newtons method is its lack of global convergence and high iteration cost. Both these drawbacks are critical for modern optimization motivated primarily by current applications in machine learning. In this paper, we introduce a novel algorithm to deal with these disadvantages. Our method can be implemented with various Hessian approximations, including methods that use only the first-order information. Thus, computational costs might be drastically reduced. Also, it can be adjusted to problems' geometries via the usage of different Bregman divergences. The proposed method converges for nonconvex and convex problems globally and it has the same rates as other well-known methods that lack mentioned properties. We present experiments validating our method performs according to the theoretical bounds and shows competitive performance among other Newton-based methods."}
{"id": "2512.08015", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08015", "abs": "https://arxiv.org/abs/2512.08015", "authors": ["Luis D. Zambrano Palma", "Yusef Maleki", "M. Suhail Zubairy"], "title": "Information-Theoretic Analysis of Weak Measurements and Their Reversal", "comment": null, "summary": "We study trade-off relations in information extraction from quantum systems subject to null-result weak measurements, where the absence of a detected photon continuously updates the system state. We present a detailed analysis of qubit and qutrit systems and investigate a general framework for a multilevel quantum system. We develop a dynamical characterization of null-result weak measurements that quantifies the information extracted over time, revealing the amount of the obtained information and also the rate of the information accumulation. The characterizations are obtained by examining the time-dependent evolution of the information theoretic quantities. More specifically, we consider Shannon entropy, mutual information, fidelity, and relative entropy to characterize the weak measurement dynamics. Our results provide an information theoretic analysis of the weak measurement process and highlight the dynamical nature of information extraction and reversibility in the weak measurement processes."}
{"id": "2512.08709", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08709", "abs": "https://arxiv.org/abs/2512.08709", "authors": ["Alex Gunning", "Aydin Deger", "Sridevi Kuriyattil", "Andrew J. Daley"], "title": "Geometry-driven transitions in sparse long-range spin models with cold atoms", "comment": "14 pages, 10 figures", "summary": "We explore the influence of geometry in the critical behavior of sparse long-range spin models. We examine a model with interactions that can be continuously tuned to induce distinct changes in the metric, topology, and dimensionality of the coupling graph. This underlying geometry acts as the driver of criticality, with structural changes in the graph coinciding with and dictating the phase boundaries. We further discuss how this framework connects naturally to realizations in tweezer arrays with Rydberg excitations. In certain cases, the effective geometry can be incorporated in the layout of atoms in tweezers to realize phase transitions that preserve universal features, simplifying their implementation in near-term experiments."}
{"id": "2512.08436", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08436", "abs": "https://arxiv.org/abs/2512.08436", "authors": ["Nour Mitiche", "Farid Ferguene", "Mourad Oussalah"], "title": "Beyond Wave Variables: A Data-Driven Ensemble Approach for Enhanced Teleoperation Transparency and Stability", "comment": "14 pages, 8 figures, 5 tables", "summary": "Time delays in communication channels present significant challenges for bilateral teleoperation systems, affecting both transparency and stability. Although traditional wave variable-based methods for a four-channel architecture ensure stability via passivity, they remain vulnerable to wave reflections and disturbances like variable delays and environmental noise. This article presents a data-driven hybrid framework that replaces the conventional wave-variable transform with an ensemble of three advanced sequence models, each optimized separately via the state-of-the-art Optuna optimizer, and combined through a stacking meta-learner. The base predictors include an LSTM augmented with Prophet for trend correction, an LSTM-based feature extractor paired with clustering and a random forest for improved regression, and a CNN-LSTM model for localized and long-term dynamics. Experimental validation was performed in Python using data generated from the baseline system implemented in MATLAB/Simulink. The results show that our optimized ensemble achieves a transparency comparable to the baseline wave-variable system under varying delays and noise, while ensuring stability through passivity constraints."}
{"id": "2512.08768", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.08768", "abs": "https://arxiv.org/abs/2512.08768", "authors": ["Thomas Bader", "Shi Feng", "Sasank Budaraju", "Federico Becca", "Johannes Knolle", "Frank Pollmann"], "title": "Triangular $J_1$-$J_2$ Heisenberg Antiferromagnet in a Magnetic Field", "comment": "6 + 11 pages, 3 + 2 figures", "summary": "The behavior of the paradigmatic $J_1-J_2$ triangular lattice Heisenberg antiferromagnet in a magnetic field remains unsettled despite decades of study. We map out the phase diagram using three complementary approaches, including self-consistent nonlinear spin-wave theory, density-matrix renormalization group, and variational Monte Carlo. This combined analysis resolves the competition among different field-induced magnetic orders and magnetization plateaux across the classically frustrated parameter range. In particular, there is a finite range in the parameter regime around $J_2/J_1=\\frac{1}{8}$ in which i) upon the application of the external field, the gapless quantum spin liquid acquires a finite density of monopoles, and ii) by further increasing the field, two plateaux are clearly obtained at $m=\\frac{1}{3}$ and $m=\\frac{1}{2}$. We discuss the experimental importance of the consecutive magnetization plateaux transitions as a signature of an underlying quantum spin-liquid phase."}
{"id": "2512.08436", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08436", "abs": "https://arxiv.org/abs/2512.08436", "authors": ["Nour Mitiche", "Farid Ferguene", "Mourad Oussalah"], "title": "Beyond Wave Variables: A Data-Driven Ensemble Approach for Enhanced Teleoperation Transparency and Stability", "comment": "14 pages, 8 figures, 5 tables", "summary": "Time delays in communication channels present significant challenges for bilateral teleoperation systems, affecting both transparency and stability. Although traditional wave variable-based methods for a four-channel architecture ensure stability via passivity, they remain vulnerable to wave reflections and disturbances like variable delays and environmental noise. This article presents a data-driven hybrid framework that replaces the conventional wave-variable transform with an ensemble of three advanced sequence models, each optimized separately via the state-of-the-art Optuna optimizer, and combined through a stacking meta-learner. The base predictors include an LSTM augmented with Prophet for trend correction, an LSTM-based feature extractor paired with clustering and a random forest for improved regression, and a CNN-LSTM model for localized and long-term dynamics. Experimental validation was performed in Python using data generated from the baseline system implemented in MATLAB/Simulink. The results show that our optimized ensemble achieves a transparency comparable to the baseline wave-variable system under varying delays and noise, while ensuring stability through passivity constraints."}
{"id": "2512.08658", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08658", "abs": "https://arxiv.org/abs/2512.08658", "authors": ["Moritz Fabian Danzer", "Kaspar Rufibach", "Jan Beyersmann", "René Schmidt"], "title": "Exhausting the type I error level in event-driven group-sequential designs with a closed testing procedure for progression-free and overall survival", "comment": "Main manuscript: 18 pages, 5 figures Supplementary Material: 11 pages, 4 figures", "summary": "In oncological clinical trials, overall survival (OS) is the gold-standard endpoint, but long follow-up and treatment switching can delay or dilute detectable effects. Progression-free survival (PFS) often provides earlier evidence and is therefore frequently used together with OS as multiple primary endpoints. Since in certain scenarios trial success may be defined if one of the two hypotheses involved can be rejected, a correction for multiple testing may be deemed necessary. Because PFS and OS are generally highly dependent, their test statistics are typically correlated. Ignoring this dependency (e.g. via a simple Bonferroni correction) is not power optimal. We develop a group-sequential testing procedure for the multiple primary endpoints PFS and OS that fully exhausts the family-wise error rate (FWER) by exploiting their dependence. Specifically, we characterize the joint asymptotic distribution of log-rank statistics across endpoints and multiple event-driven analysis cutoffs. Furthermore, we show that we can consistently estimate the covariance structure. Embedding these results in a closed testing procedure, we can recalculate critical values of the test statistics in order to spend the available type I error optimally. An important extension to the current literature is that we allow for both interim and final analysis to be event-driven. Simulations based on illness-death multi-state models empirically confirm FWER control for moderate to large sample sizes. Compared with a simple Bonferroni correction, the proposed methods recover roughly two thirds of the power loss for OS, increase disjunctive and conjunctive power, and enable meaningful early stopping. In planning, these gains translate into about 5% fewer OS events required to reach the targeted power. We also discuss practical issues in the implementation of such designs and possible extensions of the introduced method."}
{"id": "2512.08852", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.08852", "abs": "https://arxiv.org/abs/2512.08852", "authors": ["Hadi Salloum", "Roland Hildebrand", "Nhat Trung Nguyen", "Vitali Pirau", "Amer Al Badr", "Mohammad Alkousa", "Alexander Gasnikov"], "title": "Speeding up the Goemans-Williamson randomized procedure by difference-of-convex optimization", "comment": null, "summary": "We present a novel approach to accelerate the Goemans-Williamson (GW) randomized rounding procedure for quadratic unconstrained binary optimization (QUBO) problems. Instead of solving the conventional semi-definite programming (SDP) relaxation, which is computationally expensive, we employ a difference-of-convex (DC) optimization framework to efficiently approximate the SDP solution. The DC optimization produces candidate vectors that are then used within the GW randomized rounding scheme to generate high-quality binary solutions. Furthermore, we perform direct expectation minimization over manifolds of matrices with limited rank to further enhance the solution quality. Our method is benchmarked on real-world QUBO instances, including inverse kinematics problems, and compared against state-of-the-art solvers, such as quantum-inspired algorithms, demonstrating competitive approximation guarantees alongside substantial computational gains."}
{"id": "2512.08021", "categories": ["quant-ph", "math-ph", "physics.class-ph"], "pdf": "https://arxiv.org/pdf/2512.08021", "abs": "https://arxiv.org/abs/2512.08021", "authors": ["Ángel E. Reyna-Cruz", "Julio C. Gutiérrez-Vega"], "title": "Classical and quantum dynamics of a particle confined in a paraboloidal cavity", "comment": "24 pages, 8 figures", "summary": "We present a classical and quantum analysis of a particle confined in a three-dimensional paraboloidal cavity formed by two confocal paraboloids. Classically, the system is integrable and presents three independent constants of motion, namely, the energy, the $z$-component of the angular momentum, and a third dynamical constant associated with the paraboloidal geometry, which can be derived from the separability of the Hamilton--Jacobi equation. We derive closed-form analytical expressions for the actions, which allow us to determine the two conditions to get periodic closed trajectories. We classify these trajectories through the indices $(s,t,\\ell)$. The caustic paraboloids that bound the motion provide a complete geometric characterization of admissible trajectories. Quantum mechanically, separability of the Schrödinger equation in parabolic coordinates yields eigenmodes described by Whittaker functions. We determine the energy spectrum and identify degeneracies arising not only from azimuthal symmetry but also from specific cavity deformations. A direct correspondence between classical trajectories and quantum eigenstates reveals that probability densities concentrate in the classically allowed region with controlled penetration into forbidden zones."}
{"id": "2512.08712", "categories": ["cond-mat.str-el", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08712", "abs": "https://arxiv.org/abs/2512.08712", "authors": ["Aprem P. Joy", "Roman Lange", "Achim Rosch"], "title": "Diffusion and relaxation of topological excitations in layered spin liquids", "comment": "12 pages, 6 Figures", "summary": "Relaxation processes in topological phases such as quantum spin liquids are controlled by the dynamics and interaction of fractionalized excitations. In layered materials hosting two-dimensional topological phases, elementary quasiparticles can diffuse freely within the layer, whereas only pairs (or more) can hop between layers - a fundamental consequence of topological order. Using exact solutions of emergent nonlinear diffusion equations and particle-based stochastic simulations, we explore how pump-probe experiments can provide unique signatures of the presence of $2d$ topological excitations in a $3d$ material. Here we show that the characteristic time scale of such experiments is inversely proportional to the initial excitation density, set by the pump intensity. A uniform excitation density created on the surface of a sample spreads subdiffusively into the bulk with a mean depth $\\bar z$ scaling as $\\sim t^{1/3}$ when annihilation processes are absent. The propagation becomes logarithmic, $\\bar z \\sim \\log t$, when pair-annihilation is allowed. Furthermore, pair-diffusion between layers leads to a new decay law for the total density, $n(t) \\sim (\\log^2 t)/t$ - slower than in a purely $2d$ system. We discuss possible experimental implications for pump-probe experiments in samples of finite width."}
{"id": "2512.08452", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08452", "abs": "https://arxiv.org/abs/2512.08452", "authors": ["Maxim Raymond", "Kaouther Moussa", "Mirko Fiacchini", "Jimmy Lauber"], "title": "MPC for tracking for anesthesia dynamics", "comment": null, "summary": "In this paper, an MPC for tracking formulation is proposed for the control of anesthesia dynamics. It seamlessly enables the optimization of the steady-states pair that is not unique due to the MISO nature of the model. Anesthesia dynamics is a multi-time scale system with two types of states characterized, respectively, by fast and slow dynamics. In anesthesia control, the output equation depends only on the fast dynamics. Therefore, the slow states can be treated as disturbances, and compensation terms can be introduced. Subsequently, the system can be reformulated as a nominal one allowing the design of an MPC for tracking strategy. The presented framework ensures recursive feasibility and asymptotic stability, through the design of appropriate terminal ingredients in the MPC for tracking framework. The controller performance is then assessed on a patient in a simulation environment."}
{"id": "2512.08749", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.08749", "abs": "https://arxiv.org/abs/2512.08749", "authors": ["David Blanik", "José Garre-Rubio"], "title": "Non-abelian quantum double models from iterated gauging", "comment": "12 pages, 2 figures", "summary": "We reconstruct all (2+1)D quantum double models of finite groups from their boundary symmetries through the repeated application of a gauging procedure, extending the existing construction for abelian groups. We employ the recently proposed categorical gauging framework, based on matrix product operators (MPOs), to derive the appropriate gauging procedure for the $\\mathsf{Rep}\\, G$ symmetries appearing in our construction and give an explicit description of the dual emergent $G$ symmetry, which is our main technical contribution. Furthermore, we relate the possible gapped boundaries of the quantum double models to the quantum phases of the one-dimensional input state to the iterated gauging procedure. Finally, we propose a gauging procedure for 1-form $\\mathsf{Rep}\\, G$ symmetries on a two-dimensional lattice and use it to extend our results to the construction of (3+1)D quantum doubles models through the iterative gauging of (2+1)-dimensional symmetries."}
{"id": "2512.08452", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08452", "abs": "https://arxiv.org/abs/2512.08452", "authors": ["Maxim Raymond", "Kaouther Moussa", "Mirko Fiacchini", "Jimmy Lauber"], "title": "MPC for tracking for anesthesia dynamics", "comment": null, "summary": "In this paper, an MPC for tracking formulation is proposed for the control of anesthesia dynamics. It seamlessly enables the optimization of the steady-states pair that is not unique due to the MISO nature of the model. Anesthesia dynamics is a multi-time scale system with two types of states characterized, respectively, by fast and slow dynamics. In anesthesia control, the output equation depends only on the fast dynamics. Therefore, the slow states can be treated as disturbances, and compensation terms can be introduced. Subsequently, the system can be reformulated as a nominal one allowing the design of an MPC for tracking strategy. The presented framework ensures recursive feasibility and asymptotic stability, through the design of appropriate terminal ingredients in the MPC for tracking framework. The controller performance is then assessed on a patient in a simulation environment."}
{"id": "2512.08735", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08735", "abs": "https://arxiv.org/abs/2512.08735", "authors": ["Michael Price", "Debdeep Pati", "Ning Ning"], "title": "Stationary Point Constrained Inference via Diffeomorphisms", "comment": null, "summary": "Stationary points or derivative zero crossings of a regression function correspond to points where a trend reverses, making their estimation scientifically important. Existing approaches to uncertainty quantification for stationary points cannot deliver valid joint inference when multiple extrema are present, an essential capability in applications where the relative locations of peaks and troughs carry scientific significance. We develop a principled framework for functions with multiple regions of monotonicity by constraining the number of stationary points. We represent each function in the diffeomorphic formulation as the composition of a simple template and a smooth bijective transformation, and show that this parameterization enables coherent joint inference on the extrema. This construction guarantees a prespecified number of stationary points and provides a direct, interpretable parameterization of their locations. We derive non-asymptotic confidence bounds and establish approximate normality for the maximum likelihood estimators, with parallel results in the Bayesian setting. Simulations and an application to brain signal estimation demonstrate the method's accuracy and interpretability."}
{"id": "2512.08013", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08013", "abs": "https://arxiv.org/abs/2512.08013", "authors": ["Robert Lefringhausen", "Theodor Springer", "Sandra Hirche"], "title": "Learning Dynamics from Infrequent Output Measurements for Uncertainty-Aware Optimal Control", "comment": "Submitted to the 2026 IFAC World Congress", "summary": "Reliable optimal control is challenging when the dynamics of a nonlinear system are unknown and only infrequent, noisy output measurements are available. This work addresses this setting of limited sensing by formulating a Bayesian prior over the continuous-time dynamics and latent state trajectory in state-space form and updating it through a targeted marginal Metropolis-Hastings sampler equipped with a numerical ODE integrator. The resulting posterior samples are used to formulate a scenario-based optimal control problem that accounts for both model and measurement uncertainty and is solved using standard nonlinear programming methods. The approach is validated in a numerical case study on glucose regulation using a Type 1 diabetes model."}
{"id": "2512.08023", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.08023", "abs": "https://arxiv.org/abs/2512.08023", "authors": ["Ethan Decker", "Christopher Watson", "Junyu Zhou", "Yuhao Liu", "Chenxu Liu", "Ang Li", "Gushu Li", "Samuel Stein"], "title": "F2: Offline Reinforcement Learning for Hamiltonian Simulation via Free-Fermionic Subroutine Compilation", "comment": null, "summary": "Compiling shallow and accurate quantum circuits for Hamiltonian simulation remains challenging due to hardware constraints and the combinatorial complexity of minimizing gate count and circuit depth. Existing optimization method pipelines rely on hand-engineered classical heuristics, which cannot learn input-dependent structure and therefore miss substantial opportunities for circuit reduction.\n  We introduce \\textbf{F2}, an offline reinforcement learning framework that exploits free-fermionic structure to efficiently compile Trotter-based Hamiltonian simulation circuits. F2 provides (i) a reinforcement-learning environment over classically simulatable free-fermionic subroutines, (ii) architectural and objective-level inductive biases that stabilize long-horizon value learning, and (iii) a reversible synthetic-trajectory generation mechanism that consistently yields abundant, guaranteed-successful offline data.\n  Across benchmarks spanning lattice models, protein fragments, and crystalline materials (12-222 qubits), F2 reduces gate count by 47\\% and depth by 38\\% on average relative to strong baselines (Qiskit, Cirq/OpenFermion) while maintaining average errors of $10^{-7}$. These results show that aligning deep reinforcement learning with the algebraic structure of quantum dynamics enables substantial improvements in circuit synthesis, suggesting a promising direction for scalable, learning-based quantum compilation"}
{"id": "2512.08464", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08464", "abs": "https://arxiv.org/abs/2512.08464", "authors": ["Jungjin Park", "Osamu Kaneko", "Kiminao Kogiso"], "title": "Quantization and Security Parameter Design for Overflow-Free Confidential FRIT", "comment": null, "summary": "This study proposes a systematic design procedure for determining the quantization gain and the security parameter in the Confidential Fictitious Reference Iterative Tuning (CFRIT), enabling overflow-free and accuracy-guaranteed encrypted controller tuning. Within an encrypted data-driven gain tuning, the range of quantization errors induced during the encoding (encryption) process can be estimated from operational data. Based on this insight, explicit analytical conditions on the quantization gain and the security parameter are derived to prevent overflow in computing over encrypted data. Furthermore, the analysis reveals a quantitative relationship between quantization-induced errors and the deviation between the gains obtained by CFRIT and non-confidential Fictitious Reference Iterative Tuning (FRIT), clarifying how parameter choice affects tuning accuracy. A numerical example verifies the proposed procedure by demonstrating that the designed parameters achieve accurate encrypted tuning within a prescribed tolerance while preventing overflow. In addition, the admissible region of parameter combinations is visualized to examine the characteristics of feasible and infeasible regions, providing practical insights into parameter design for encrypted data-driven control."}
{"id": "2512.08464", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08464", "abs": "https://arxiv.org/abs/2512.08464", "authors": ["Jungjin Park", "Osamu Kaneko", "Kiminao Kogiso"], "title": "Quantization and Security Parameter Design for Overflow-Free Confidential FRIT", "comment": null, "summary": "This study proposes a systematic design procedure for determining the quantization gain and the security parameter in the Confidential Fictitious Reference Iterative Tuning (CFRIT), enabling overflow-free and accuracy-guaranteed encrypted controller tuning. Within an encrypted data-driven gain tuning, the range of quantization errors induced during the encoding (encryption) process can be estimated from operational data. Based on this insight, explicit analytical conditions on the quantization gain and the security parameter are derived to prevent overflow in computing over encrypted data. Furthermore, the analysis reveals a quantitative relationship between quantization-induced errors and the deviation between the gains obtained by CFRIT and non-confidential Fictitious Reference Iterative Tuning (FRIT), clarifying how parameter choice affects tuning accuracy. A numerical example verifies the proposed procedure by demonstrating that the designed parameters achieve accurate encrypted tuning within a prescribed tolerance while preventing overflow. In addition, the admissible region of parameter combinations is visualized to examine the characteristics of feasible and infeasible regions, providing practical insights into parameter design for encrypted data-driven control."}
{"id": "2512.08828", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.08828", "abs": "https://arxiv.org/abs/2512.08828", "authors": ["Swaraj Bose", "Walter Dempsey"], "title": "Prediction Intervals for Individual Treatment Effects in a Multiple Decision Point Framework using Conformal Inference", "comment": null, "summary": "Accurately quantifying uncertainty of individual treatment effects (ITEs) across multiple decision points is crucial for personalized decision-making in fields such as healthcare, finance, education, and online marketplaces. Previous work has focused on predicting non-causal longitudinal estimands or constructing prediction bands for ITEs using cross-sectional data based on exchangeability assumptions. We propose a novel method for constructing prediction intervals using conformal inference techniques for time-varying ITEs with weaker assumptions than prior literature. We guarantee a lower bound for coverage, which is dependent on the degree of non-exchangeability in the data. Although our method is broadly applicable across decision-making contexts, we support our theoretical claims with simulations emulating micro-randomized trials (MRTs) -- a sequential experimental design for mobile health (mHealth) studies. We demonstrate the practical utility of our method by applying it to a real-world MRT - the Intern Health Study (IHS)."}
{"id": "2512.08201", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08201", "abs": "https://arxiv.org/abs/2512.08201", "authors": ["Jared Miller", "Petros Karamanakos", "Tobias Geyer"], "title": "Bounding the Minimal Current Harmonic Distortion in Optimal Modulation of Single-Phase Power Converters", "comment": "18 pages, 6 tables, 18 figures", "summary": "Optimal pulse patterns (OPPs) are a modulation technique in which a switching signal is computed offline through an optimization process that accounts for selected performance criteria, such as current harmonic distortion. The optimization determines both the switching angles (i.e., switching times) and the pattern structure (i.e., the sequence of voltage levels). This optimization task is a challenging mixed-integer nonconvex problem, involving integer-valued voltage levels and trigono metric nonlinearities in both the objective and the constraints. We address this challenge by reinterpreting OPP design as a periodic mode-selecting optimal control problem of a hybrid system, where selecting angles and levels corresponds to choosing jump times in a transition graph. This time-domain formulation enables the direct use of convex-relaxation techniques from optimal control, producing a hierarchy of semidefinite programs that lower-bound the minimal achievable harmonic distortion and scale subquadratically with the number of converter levels and switching angles. Numerical results demonstrate the effectiveness of the proposed approachs"}
{"id": "2512.08037", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2512.08037", "abs": "https://arxiv.org/abs/2512.08037", "authors": ["Justin F. Niedermeyer", "Nathan K. Lysne", "Katherine C. McCormick", "Jonas Keller", "Craig W. Hogle", "Matthew G. Blain", "Roman Schmied", "Robert Jördens", "Susanna L. Todaro", "David J. Wineland", "Andrew C. Wilson", "Daniel H. Slichter", "Dietrich Leibfried"], "title": "Observation of a Topological Berry Phase with a Single Phonon in an Ion Microtrap Array", "comment": null, "summary": "Controlled quantum mechanical motion of trapped atomic ions can be used to simulate and explore collective quantum phenomena and to process quantum information. Groups of cold atomic ions in an externally applied trapping potential self-organize into \"Coulomb crystals\" due to their mutual electrostatic repulsion. The motion of the ions in these crystals is strongly coupled, and the eigenmodes of motion all involve multiple ions. While this enables studies of many-body physics, it limits the flexibility and tunability of the system as a quantum platform. Here, we demonstrate an array of trapped ions in individual trapping sites whose motional modes can be controllably coupled and decoupled by tuning the local applied confining potential for each ion. We show that a single motional quantum, or phonon, can be coherently shared among two or three ions confined at the vertices of an equilateral triangle 30 $μ$m on a side. We can adiabatically tune the ion participation in the motional modes around a closed contour in configuration space, observing that the single-phonon wavefunction acquires a topological Berry phase if the contour encircles a conical intersection of motional eigenvalue surfaces. We observe this phase by single-phonon interference and study its breakdown as the motional mode tuning becomes non-adiabiatic. Our results show that precise, individual quantum control of ion motion in a two-dimensional array can provide unique access to quantum multi-body effects."}
{"id": "2512.08465", "categories": ["eess.SY", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.08465", "abs": "https://arxiv.org/abs/2512.08465", "authors": ["Alexandre Gracia-Calvo", "Francesca Rossi", "Eduardo Iraola", "Juan Carlos Olives-Camps", "Eduardo Prieto-Araujo"], "title": "High-performance computing enabled contingency analysis for modern power networks", "comment": "10 apges, 5 figures, pending to be submitted on IJEPES", "summary": "Modern power networks face increasing vulnerability to cascading failures due to high complexity and the growing penetration of intermittent resources, necessitating rigorous security assessment beyond the conventional $N-1$ criterion. Current approaches often struggle to achieve the computational tractability required for exhaustive $N-2$ contingency analysis integrated with complex stability evaluations like small-signal stability. Addressing this computational bottleneck and the limitations of deterministic screening, this paper presents a scalable methodology for the vulnerability assessment of modern power networks, integrating $N-2$ contingency analysis with small-signal stability evaluation. To prioritize critical components, we propose a probabilistic \\textbf{Risk Index ($R_i$)} that weights the deterministic \\textit{severity} of a contingency (including optimal power flow divergence, islanding, and oscillatory instability) by the \\textit{failure frequency} of the involved elements based on reliability data. The proposed framework is implemented using High-Performance Computing (HPC) techniques through the PyCOMPSs parallel programming library, orchestrating optimal power flow simulations (VeraGrid) and small-signal analysis (STAMP) to enable the exhaustive exploration of massive contingency sets. The methodology is validated on the IEEE 118-bus test system, processing more than \\num{57000} scenarios to identify components prone to triggering cascading failures. Results demonstrate that the risk-based approach effectively isolates critical assets that deterministic $N-1$ criteria often overlook. This work establishes a replicable and efficient workflow for probabilistic security assessment, suitable for large-scale networks and capable of supporting operator decision-making in near real-time environments."}
{"id": "2512.08465", "categories": ["eess.SY", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.08465", "abs": "https://arxiv.org/abs/2512.08465", "authors": ["Alexandre Gracia-Calvo", "Francesca Rossi", "Eduardo Iraola", "Juan Carlos Olives-Camps", "Eduardo Prieto-Araujo"], "title": "High-performance computing enabled contingency analysis for modern power networks", "comment": "10 apges, 5 figures, pending to be submitted on IJEPES", "summary": "Modern power networks face increasing vulnerability to cascading failures due to high complexity and the growing penetration of intermittent resources, necessitating rigorous security assessment beyond the conventional $N-1$ criterion. Current approaches often struggle to achieve the computational tractability required for exhaustive $N-2$ contingency analysis integrated with complex stability evaluations like small-signal stability. Addressing this computational bottleneck and the limitations of deterministic screening, this paper presents a scalable methodology for the vulnerability assessment of modern power networks, integrating $N-2$ contingency analysis with small-signal stability evaluation. To prioritize critical components, we propose a probabilistic \\textbf{Risk Index ($R_i$)} that weights the deterministic \\textit{severity} of a contingency (including optimal power flow divergence, islanding, and oscillatory instability) by the \\textit{failure frequency} of the involved elements based on reliability data. The proposed framework is implemented using High-Performance Computing (HPC) techniques through the PyCOMPSs parallel programming library, orchestrating optimal power flow simulations (VeraGrid) and small-signal analysis (STAMP) to enable the exhaustive exploration of massive contingency sets. The methodology is validated on the IEEE 118-bus test system, processing more than \\num{57000} scenarios to identify components prone to triggering cascading failures. Results demonstrate that the risk-based approach effectively isolates critical assets that deterministic $N-1$ criteria often overlook. This work establishes a replicable and efficient workflow for probabilistic security assessment, suitable for large-scale networks and capable of supporting operator decision-making in near real-time environments."}
{"id": "2512.08847", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08847", "abs": "https://arxiv.org/abs/2512.08847", "authors": ["Nikolaos Ignatiadis", "Li Ma"], "title": "Partially Bayes p-values for large scale inference", "comment": null, "summary": "We seek to conduct statistical inference for a large collection of primary parameters, each with its own nuisance parameters. Our approach is partially Bayesian, in that we treat the primary parameters as fixed while we model the nuisance parameters as random and drawn from an unknown distribution which we endow with a nonparametric prior. We compute partially Bayes p-values by conditioning on nuisance parameter statistics, that is, statistics that are ancillary for the primary parameters and informative about the nuisance parameters. The proposed p-values have a Bayesian interpretation as tail areas computed with respect to the posterior distribution of the nuisance parameters. Similarly to the conditional predictive p-values of Bayarri and Berger, the partially Bayes p-values avoid double use of the data (unlike posterior predictive p-values). A key ingredient of our approach is that we model nuisance parameters hierarchically across problems; the sharing of information across problems leads to improved calibration. We illustrate the proposed partially Bayes p-values in two applications: the normal means problem with unknown variances and a location-scale model with unknown distribution shape. We model the scales via Dirichlet processes in both examples and the distribution shape via Pólya trees in the second. Our proposed partially Bayes p-values increase power and calibration compared to purely frequentist alternatives."}
{"id": "2512.08353", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08353", "abs": "https://arxiv.org/abs/2512.08353", "authors": ["Ruo Li", "Haoyang Liu", "Jun Yin"], "title": "A reconstructed discontinuous approximation for distributed elliptic control problems", "comment": "21 pages, 26 figures", "summary": "In this paper, we present and analyze an internal penalty discontinuous Galerkin method for the distributed elliptic optimal control problems. It is based on a reconstructed discontinuous approximation which admits arbitrarily high-order approximation space with only one unknown per element. Applying this method, we develop a proper discretization scheme that approximates the state and adjoint variables in the approximation space. Our main contributions are twofold: (1) the derivation of both a priori and a posteriori error estimates of the $L^2$-norm and the energy norms, and (2) the implementation of an efficiently solvable discrete system, which is solved via a linearly convergent projected gradient descent method. Numerical experiments are provided to verify the convergence order in a priori estimate and the efficiency of a posteriori error estimate."}
{"id": "2512.08059", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2512.08059", "abs": "https://arxiv.org/abs/2512.08059", "authors": ["Jesse Balgley", "Jinho Park", "Xuanjing Chu", "Jiru Liu", "Madisen Holbrook", "Kenji Watanabe", "Takashi Taniguchi", "Archana Kamal", "Leonardo Ranzani", "Martin V. Gustafsson", "James Hone", "Kin Chung Fong"], "title": "Coherent and compact van der Waals transmon qubits", "comment": null, "summary": "State-of-the-art superconducting qubits rely on a limited set of thin-film materials. Expanding their materials palette can improve performance, extend operating regimes, and introduce new functionalities, but conventional thin-film fabrication hinders systematic exploration of new material combinations. Van der Waals (vdW) materials offer a highly modular crystalline platform that facilitates such exploration while enabling gate-tunability, higher-temperature operation, and compact qubit geometries. Yet it remains unknown whether a fully vdW superconducting qubit can support quantum coherence and what mechanisms dominate loss at both low and elevated temperatures in such a device. Here we demonstrate quantum-coherent merged-element transmons made entirely from vdW Josephson junctions. These first-generation, fully crystalline qubits achieve microsecond lifetimes in an ultra-compact footprint without external shunt capacitors. Energy relaxation measurements, together with microwave characterization of vdW capacitors, point to dielectric loss as the dominant relaxation channel up to hundreds of millikelvin. These results establish vdW materials as a viable platform for compact superconducting quantum devices."}
{"id": "2512.08544", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08544", "abs": "https://arxiv.org/abs/2512.08544", "authors": ["Martina Alutto", "Leonardo Cianfanelli", "Giacomo Como", "Fabio Fagnani", "Francesca Parise"], "title": "Optimal Control of Behavioral-Feedback SIR Epidemic Model", "comment": "14 pages, 3 figures", "summary": "We consider a behavioral-feedback SIR epidemic model, in which the infection rate depends in feedback on the fractions of susceptible and infected agents, respectively. The considered model allows one to account for endogenous adaptation mechanisms of the agents in response to the epidemics, such as voluntary social distancing, or the adoption of face masks. For this model, we formulate an optimal control problem for a social planner that has the ability to reduce the infection rate to keep the infection curve below a certain threshold within an infinite time horizon, while minimizing the intervention cost. Based on the dynamic properties of the model, we prove that, under quite general conditions on the infection rate, the \\emph{filling the box} strategy is the optimal control. This strategy consists in letting the epidemics spread without intervention until the threshold is reached, then applying the minimum control that leaves the fraction of infected individuals constantly at the threshold until the reproduction number becomes less than one and the infection naturally fades out. Our result generalizes one available in the literature for the equivalent problem formulated for the classical SIR model, which can be recovered as a special case of our model when the infection rate is constant. Our contribution enhances the understanding of epidemic management with adaptive human behavior, offering insights for robust containment strategies."}
{"id": "2512.08544", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08544", "abs": "https://arxiv.org/abs/2512.08544", "authors": ["Martina Alutto", "Leonardo Cianfanelli", "Giacomo Como", "Fabio Fagnani", "Francesca Parise"], "title": "Optimal Control of Behavioral-Feedback SIR Epidemic Model", "comment": "14 pages, 3 figures", "summary": "We consider a behavioral-feedback SIR epidemic model, in which the infection rate depends in feedback on the fractions of susceptible and infected agents, respectively. The considered model allows one to account for endogenous adaptation mechanisms of the agents in response to the epidemics, such as voluntary social distancing, or the adoption of face masks. For this model, we formulate an optimal control problem for a social planner that has the ability to reduce the infection rate to keep the infection curve below a certain threshold within an infinite time horizon, while minimizing the intervention cost. Based on the dynamic properties of the model, we prove that, under quite general conditions on the infection rate, the \\emph{filling the box} strategy is the optimal control. This strategy consists in letting the epidemics spread without intervention until the threshold is reached, then applying the minimum control that leaves the fraction of infected individuals constantly at the threshold until the reproduction number becomes less than one and the infection naturally fades out. Our result generalizes one available in the literature for the equivalent problem formulated for the classical SIR model, which can be recovered as a special case of our model when the infection rate is constant. Our contribution enhances the understanding of epidemic management with adaptive human behavior, offering insights for robust containment strategies."}
{"id": "2512.08252", "categories": ["math.ST", "math.PR", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.08252", "abs": "https://arxiv.org/abs/2512.08252", "authors": ["Sohom Bhattacharya", "Subhabrata Sen"], "title": "Causal inference under interference: computational barriers and algorithmic solutions", "comment": null, "summary": "We study causal effect estimation under interference from network data. We work under the chain-graph formulation pioneered in Tchetgen Tchetgen et. al (2021). Our first result shows that polynomial time evaluation of treatment effects is computationally hard in this framework without additional assumptions on the underlying chain graph. Subsequently, we assume that the interactions among the study units are governed either by (i) a dense graph or (ii) an i.i.d. Gaussian matrix. In each case, we show that the treatment effects have well-defined limits as the population size diverges to infinity. Additionally, we develop polynomial time algorithms to consistently evaluate the treatment effects in each case. Finally, we estimate the unknown parameters from the observed data using maximum pseudo-likelihood estimates, and establish the stability of our causal effect estimators under this perturbation. Our algorithms provably approximate the causal effects in polynomial time even in low-temperature regimes where the canonical MCMC samplers are slow mixing. For dense graphs, our results use the notion of regularity partitions; for Gaussian interactions, our approach uses ideas from spin glass theory and Approximate Message Passing."}
{"id": "2512.08432", "categories": ["quant-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08432", "abs": "https://arxiv.org/abs/2512.08432", "authors": ["Zhijian Lai", "Dong An", "Jiang Hu", "Zaiwen Wen"], "title": "A Grover-compatible manifold optimization algorithm for quantum search", "comment": "27 pages, 5 figures", "summary": "Grover's algorithm is a fundamental quantum algorithm that offers a quadratic speedup for the unstructured search problem by alternately applying physically implementable oracle and diffusion operators. In this paper, we reformulate the unstructured search as a maximization problem on the unitary manifold and solve it via the Riemannian gradient ascent (RGA) method. To overcome the difficulty that generic RGA updates do not, in general, correspond to physically implementable quantum operators, we introduce Grover-compatible retractions to restrict RGA updates to valid oracle and diffusion operators. Theoretically, we establish a local Riemannian $μ$-Polyak-Łojasiewicz (PL) inequality with $μ= \\tfrac{1}{2}$, which yields a linear convergence rate of $1 - κ^{-1}$ toward the global solution. Here, the condition number $κ= L_{\\mathrm{Rie}} / μ$, where $L_{\\mathrm{Rie}}$ denotes the Riemannian Lipschitz constant of the gradient. Taking into account both the geometry of the unitary manifold and the special structure of the cost function, we show that $L_{\\mathrm{Rie}} = O(\\sqrt{N})$ for problem size $N = 2^n$. Consequently, the resulting iteration complexity is $O(\\sqrt{N} \\log(1/\\varepsilon))$ for attaining an $\\varepsilon$-accurate solution, which matches the quadratic speedup of $O(\\sqrt{N})$ achieved by Grover's algorithm. These results demonstrate that an optimization-based viewpoint can offer fresh conceptual insights and lead to new advances in the design of quantum algorithms."}
{"id": "2512.08068", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08068", "abs": "https://arxiv.org/abs/2512.08068", "authors": ["James Fullwood", "Boyu Yang"], "title": "On Dirac-type correlations", "comment": "15 pages, no figures", "summary": "Quantum correlations often defy an explanation in terms of fundamental notions of classical physics, such as causality, locality, and realism. While the mathematical theory underpinning quantum correlations between spacelike separated systems has been well-established since the 1930s, the mathematical theory for correlations between non-spacelike separated systems is much less developed. In this work, we develop the theory of what we refer to as \"local-density operators\", which we view as joint states for possibly non-spacelike separated quantum systems. Local-density operators are unit trace operators whose marginals are genuine density operators, which we show not only subsumes the notion of density operator, but also several extensions of the notion of density operator into the spatiotemporal domain, such as pseudo-density operators and quantum states over time. More importantly, we prove a result which establishes a one-to-one correspondence between local-density operators and what we refer to as \"Dirac measures\", which are complex-valued measures on the space of separable projectors associated with two quantum systems. In the case that one of the systems is the trivial quantum system with a one-dimensional Hilbert space, our result recovers the fundamental result known as Gleason's Theorem, which implies that the Born rule from quantum theory is the only way in which one may assign probabilities to the outcomes of measurements performed on quantum systems in a non-contextual manner. As such, our results establish a direct generalization of Gleason's Theorem to measurements performed on possibly non-spacelike separated systems, thus extending the mathematical theory of quantum correlations across space to quantum correlations across space and time."}
{"id": "2512.08607", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.08607", "abs": "https://arxiv.org/abs/2512.08607", "authors": ["Adrian Wiltz", "Dimos V. Dimarogonas"], "title": "Decoupled Design of Time-Varying Control Barrier Functions via Equivariances", "comment": "7 pages, 3 figures", "summary": "This article presents a systematic method for designing time-varying Control Barrier Functions (CBF) composed of a time-invariant component and multiple time-dependent components, leveraging structural properties of the system dynamics. The method involves the construction of a specific class of time-invariant CBFs that encode the system's dynamic capabilities with respect to a given constraint, and augments them subsequently with appropriately designed time-dependent transformations. While transformations uniformly varying the time-invariant CBF can be applied to arbitrary systems, transformations exploiting structural properties in the dynamics - equivariances in particular - enable the handling of a broader and more expressive class of time-varying constraints. The article shows how to leverage such properties in the design of time-varying CBFs. The proposed method decouples the design of time variations from the computationally expensive construction of the underlying CBFs, thereby providing a computationally attractive method to the design of time-varying CBFs. The method accounts for input constraints and under-actuation, and requires only qualitative knowledge on the time-variation of the constraints making it suitable to the application in uncertain environments."}
{"id": "2512.08607", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.08607", "abs": "https://arxiv.org/abs/2512.08607", "authors": ["Adrian Wiltz", "Dimos V. Dimarogonas"], "title": "Decoupled Design of Time-Varying Control Barrier Functions via Equivariances", "comment": "7 pages, 3 figures", "summary": "This article presents a systematic method for designing time-varying Control Barrier Functions (CBF) composed of a time-invariant component and multiple time-dependent components, leveraging structural properties of the system dynamics. The method involves the construction of a specific class of time-invariant CBFs that encode the system's dynamic capabilities with respect to a given constraint, and augments them subsequently with appropriately designed time-dependent transformations. While transformations uniformly varying the time-invariant CBF can be applied to arbitrary systems, transformations exploiting structural properties in the dynamics - equivariances in particular - enable the handling of a broader and more expressive class of time-varying constraints. The article shows how to leverage such properties in the design of time-varying CBFs. The proposed method decouples the design of time variations from the computationally expensive construction of the underlying CBFs, thereby providing a computationally attractive method to the design of time-varying CBFs. The method accounts for input constraints and under-actuation, and requires only qualitative knowledge on the time-variation of the constraints making it suitable to the application in uncertain environments."}
{"id": "2512.08705", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08705", "abs": "https://arxiv.org/abs/2512.08705", "authors": ["Jannik Graebner", "Ryne Beeson"], "title": "Gradient-Informed Monte Carlo Fine-Tuning of Diffusion Models for Low-Thrust Trajectory Design", "comment": null, "summary": "Preliminary mission design of low-thrust spacecraft trajectories in the Circular Restricted Three-Body Problem is a global search characterized by a complex objective landscape and numerous local minima. Formulating the problem as sampling from an unnormalized distribution supported on neighborhoods of locally optimal solutions, provides the opportunity to deploy Markov chain Monte Carlo methods and generative machine learning. In this work, we extend our previous self-supervised diffusion model fine-tuning framework to employ gradient-informed Markov chain Monte Carlo. We compare two algorithms - the Metropolis-Adjusted Langevin Algorithm and Hamiltonian Monte Carlo - both initialized from a distribution learned by a diffusion model. Derivatives of an objective function that balances fuel consumption, time of flight and constraint violations are computed analytically using state transition matrices. We show that incorporating the gradient drift term accelerates mixing and improves convergence of the Markov chain for a multi-revolution transfer in the Saturn-Titan system. Among the evaluated methods, MALA provides the best trade-off between performance and computational cost. Starting from samples generated by a baseline diffusion model trained on a related transfer, MALA explicitly targets Pareto-optimal solutions. Compared to a random walk Metropolis algorithm, it increases the feasibility rate from 17.34% to 63.01% and produces a denser, more diverse coverage of the Pareto front. By fine-tuning a diffusion model on the generated samples and associated reward values with reward-weighted likelihood maximization, we learn the global solution structure of the problem and eliminate the need for a tedious separate data generation phase."}
{"id": "2512.08085", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08085", "abs": "https://arxiv.org/abs/2512.08085", "authors": ["Alberto J. B. Rosal", "Patrick P. Potts", "Gabriel T. Landi"], "title": "Deterministic Equations for Feedback Control of Open Quantum Systems II: Properties of the memory function", "comment": null, "summary": "Feedback uses past detection outcomes to dynamically modify a quantum system and is central to quantum control. These outcomes can be stored in a memory, defined as a stochastic function of past measurements. In this work, we investigate the main properties of a general memory function subject to arbitrary feedback dynamics. We show that the memory can be treated as a classical system coupled to the monitored quantum system, and that their joint evolution is described by a hybrid bipartite state. This framework allows us to introduce information-theoretic measures that quantify the correlations between the system and the memory. Furthermore, we develop a general framework to characterize the statistics of the memory -- such as moments, cumulants, and correlation functions -- which can be applied both to general feedback-control protocols and to monitored systems without feedback. As an application, we analyze feedback schemes based on detection events in a two-level system coupled to a thermal bath, focusing on protocols that stabilize either the excited-state population or Rabi oscillations against thermal dissipation."}
{"id": "2512.08608", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08608", "abs": "https://arxiv.org/abs/2512.08608", "authors": ["Jiajie Xu", "Yifan Guo", "Xiucheng Wang", "Nan Cheng", "Tingting Yang"], "title": "NLoS Localization with Single Base Station Based on Radio Map", "comment": null, "summary": "Accurate outdoor localization in Non-Line-of-Sight (NLoS) environments remains a critical challenge for wireless communication and sensing systems. Existing methods, including positioning based on the Global Navigation Satellite System (GNSS) and triple Base Stations (BSs) techniques, cannot provide reliable performance under NLoS conditions, particularly in dense urban areas with strong multipath effects. To address this limitation, we propose a single BS localization framework that integrates sequential signal measurements with prior radio information embedded in the Radio Map (RM). Using temporal measurement features and matching them with radio maps, the proposed method effectively mitigates the adverse impact of multipath propagation and reduces the dependence on LoS paths. Simulation experiments further evaluate the impact of different radio map construction strategies and the varying lengths of the measurement sequence on localization accuracy. Results demonstrate that the proposed scheme achieves sub-meter positioning accuracy in typical NLoS environments, highlighting its potential as a practical and robust solution for single-base-station deployment."}
{"id": "2512.08608", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08608", "abs": "https://arxiv.org/abs/2512.08608", "authors": ["Jiajie Xu", "Yifan Guo", "Xiucheng Wang", "Nan Cheng", "Tingting Yang"], "title": "NLoS Localization with Single Base Station Based on Radio Map", "comment": null, "summary": "Accurate outdoor localization in Non-Line-of-Sight (NLoS) environments remains a critical challenge for wireless communication and sensing systems. Existing methods, including positioning based on the Global Navigation Satellite System (GNSS) and triple Base Stations (BSs) techniques, cannot provide reliable performance under NLoS conditions, particularly in dense urban areas with strong multipath effects. To address this limitation, we propose a single BS localization framework that integrates sequential signal measurements with prior radio information embedded in the Radio Map (RM). Using temporal measurement features and matching them with radio maps, the proposed method effectively mitigates the adverse impact of multipath propagation and reduces the dependence on LoS paths. Simulation experiments further evaluate the impact of different radio map construction strategies and the varying lengths of the measurement sequence on localization accuracy. Results demonstrate that the proposed scheme achieves sub-meter positioning accuracy in typical NLoS environments, highlighting its potential as a practical and robust solution for single-base-station deployment."}
{"id": "2512.08120", "categories": ["quant-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2512.08120", "abs": "https://arxiv.org/abs/2512.08120", "authors": ["Tommaso Favalli"], "title": "On the Emergence of Time and Space in Closed Quantum Systems", "comment": "PhD Thesis (University of Naples \"Federico II\"), published by Springer Cham in Springer Theses", "summary": "Time, space and entanglement are the main characters in this work. Their nature is still a great mystery in physics and we study here the possibility that these three phenomena are closely connected, showing how entanglement can be at the basis of the emergence of time and space within closed quantum systems. We revisit and extend the Page and Wootters theory that was originally introduced in order to describe the emergence of time through entanglement between subsystems in a globally static, quantum Universe. In the book, after providing a complete review of the salient aspects of the theory, we establish a connection with recent research on the foundations of statistical mechanics and we propose a new understanding of the thermalization process. Furthermore, we generalize the framework in order describe the spatial degree of freedom and we provide a model of 3+1 dimensional, quantum spacetime emerging from entanglement among different subsystems in a globally \"timeless\" and \"positionless\" Universe. Finally, via the Page and Wootters theory, the evolution of quantum clocks within a gravitational field is treated and a time dilation effect is obtained in agreement with the Schwarzschild solution."}
{"id": "2512.08667", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08667", "abs": "https://arxiv.org/abs/2512.08667", "authors": ["Josip Kir Hromatko", "Shambhuraj Sawant", "Šandor Ileš", "Sébastien Gros"], "title": "Direct transfer of optimized controllers to similar systems using dimensionless MPC", "comment": "7 pages, 4 figures", "summary": "Scaled model experiments are commonly used in various engineering fields to reduce experimentation costs and overcome constraints associated with full-scale systems. The relevance of such experiments relies on dimensional analysis and the principle of dynamic similarity. However, transferring controllers to full-scale systems often requires additional tuning. In this paper, we propose a method to enable a direct controller transfer using dimensionless model predictive control, tuned automatically for closed-loop performance. With this reformulation, the closed-loop behavior of an optimized controller transfers directly to a new, dynamically similar system. Additionally, the dimensionless formulation allows for the use of data from systems of different scales during parameter optimization. We demonstrate the method on a cartpole swing-up and a car racing problem, applying either reinforcement learning or Bayesian optimization for tuning the controller parameters. Software used to obtain the results in this paper is publicly available at https://github.com/josipkh/dimensionless-mpcrl."}
{"id": "2512.08667", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.08667", "abs": "https://arxiv.org/abs/2512.08667", "authors": ["Josip Kir Hromatko", "Shambhuraj Sawant", "Šandor Ileš", "Sébastien Gros"], "title": "Direct transfer of optimized controllers to similar systems using dimensionless MPC", "comment": "7 pages, 4 figures", "summary": "Scaled model experiments are commonly used in various engineering fields to reduce experimentation costs and overcome constraints associated with full-scale systems. The relevance of such experiments relies on dimensional analysis and the principle of dynamic similarity. However, transferring controllers to full-scale systems often requires additional tuning. In this paper, we propose a method to enable a direct controller transfer using dimensionless model predictive control, tuned automatically for closed-loop performance. With this reformulation, the closed-loop behavior of an optimized controller transfers directly to a new, dynamically similar system. Additionally, the dimensionless formulation allows for the use of data from systems of different scales during parameter optimization. We demonstrate the method on a cartpole swing-up and a car racing problem, applying either reinforcement learning or Bayesian optimization for tuning the controller parameters. Software used to obtain the results in this paper is publicly available at https://github.com/josipkh/dimensionless-mpcrl."}
{"id": "2512.08141", "categories": ["quant-ph", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.08141", "abs": "https://arxiv.org/abs/2512.08141", "authors": ["Alastair Kay", "Christino Tamon"], "title": "The strength of weak coupling", "comment": "17 pages, 4 figures, 1 table", "summary": "A paradoxical idea in quantum transport is that attaching weakly-coupled edges to a large base graph creates high-fidelity quantum state transfer. We provide a mathematical treatment that rigorously prove this folklore idea. Our proofs are elementary and build upon the Feshbach-Schur method from perturbation theory. We also show the idea is effective in circumventing Anderson localization in spin chains and finding speedups in hitting times useful for quantum search."}
{"id": "2512.08705", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08705", "abs": "https://arxiv.org/abs/2512.08705", "authors": ["Jannik Graebner", "Ryne Beeson"], "title": "Gradient-Informed Monte Carlo Fine-Tuning of Diffusion Models for Low-Thrust Trajectory Design", "comment": null, "summary": "Preliminary mission design of low-thrust spacecraft trajectories in the Circular Restricted Three-Body Problem is a global search characterized by a complex objective landscape and numerous local minima. Formulating the problem as sampling from an unnormalized distribution supported on neighborhoods of locally optimal solutions, provides the opportunity to deploy Markov chain Monte Carlo methods and generative machine learning. In this work, we extend our previous self-supervised diffusion model fine-tuning framework to employ gradient-informed Markov chain Monte Carlo. We compare two algorithms - the Metropolis-Adjusted Langevin Algorithm and Hamiltonian Monte Carlo - both initialized from a distribution learned by a diffusion model. Derivatives of an objective function that balances fuel consumption, time of flight and constraint violations are computed analytically using state transition matrices. We show that incorporating the gradient drift term accelerates mixing and improves convergence of the Markov chain for a multi-revolution transfer in the Saturn-Titan system. Among the evaluated methods, MALA provides the best trade-off between performance and computational cost. Starting from samples generated by a baseline diffusion model trained on a related transfer, MALA explicitly targets Pareto-optimal solutions. Compared to a random walk Metropolis algorithm, it increases the feasibility rate from 17.34% to 63.01% and produces a denser, more diverse coverage of the Pareto front. By fine-tuning a diffusion model on the generated samples and associated reward values with reward-weighted likelihood maximization, we learn the global solution structure of the problem and eliminate the need for a tedious separate data generation phase."}
{"id": "2512.08705", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08705", "abs": "https://arxiv.org/abs/2512.08705", "authors": ["Jannik Graebner", "Ryne Beeson"], "title": "Gradient-Informed Monte Carlo Fine-Tuning of Diffusion Models for Low-Thrust Trajectory Design", "comment": null, "summary": "Preliminary mission design of low-thrust spacecraft trajectories in the Circular Restricted Three-Body Problem is a global search characterized by a complex objective landscape and numerous local minima. Formulating the problem as sampling from an unnormalized distribution supported on neighborhoods of locally optimal solutions, provides the opportunity to deploy Markov chain Monte Carlo methods and generative machine learning. In this work, we extend our previous self-supervised diffusion model fine-tuning framework to employ gradient-informed Markov chain Monte Carlo. We compare two algorithms - the Metropolis-Adjusted Langevin Algorithm and Hamiltonian Monte Carlo - both initialized from a distribution learned by a diffusion model. Derivatives of an objective function that balances fuel consumption, time of flight and constraint violations are computed analytically using state transition matrices. We show that incorporating the gradient drift term accelerates mixing and improves convergence of the Markov chain for a multi-revolution transfer in the Saturn-Titan system. Among the evaluated methods, MALA provides the best trade-off between performance and computational cost. Starting from samples generated by a baseline diffusion model trained on a related transfer, MALA explicitly targets Pareto-optimal solutions. Compared to a random walk Metropolis algorithm, it increases the feasibility rate from 17.34% to 63.01% and produces a denser, more diverse coverage of the Pareto front. By fine-tuning a diffusion model on the generated samples and associated reward values with reward-weighted likelihood maximization, we learn the global solution structure of the problem and eliminate the need for a tedious separate data generation phase."}
{"id": "2512.08150", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08150", "abs": "https://arxiv.org/abs/2512.08150", "authors": ["K. Uriostegui", "C. Pineda", "C. Chryssomalakos", "V. Rascón Barajas", "I. Vázquez Mota"], "title": "Detecting quantum many-body states with imperfect measuring devices", "comment": null, "summary": "We study a coarse-graining map arising from incomplete and imperfect addressing of particles in a multipartite quantum system. In its simplest form, corresponding to a two-qubit state, the resulting channel produces a convex mixture of the two partial traces. We derive the probability density of obtaining a given coarse-grained state, using geometric arguments for two qubits coarse-grained to one, and random-matrix methods for larger systems. As the number of qubits increases, the probability density sharply concentrates around the maximally mixed state, making nearly pure coarse-grained states increasingly unlikely. For two qubits, we also compute the inverse state needed to characterize the effective dynamics under coarse-graining and find that the average preimage of the maximally mixed state contains a finite singlet component. Finally, we validate the analytical predictions by inferring the underlying probabilities from Monte-Carlo-generated coarse-grained statistics."}
{"id": "2512.08731", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08731", "abs": "https://arxiv.org/abs/2512.08731", "authors": ["Qipan Wang", "Zhe Zhang", "Shuangchen Li", "Hongzhong Zheng", "Zheng Liang", "Yibo Lin", "Runsheng Wang", "Ru Huang"], "title": "LaMoSys3.5D: Enabling 3.5D-IC-Based Large Language Model Inference Serving Systems via Hardware/Software Co-Design", "comment": null, "summary": "The success of large language models LLMs amplifies the need for highthroughput energyefficient inference at scale. 3DDRAMbased accelerators provide high memory bandwidth and therefore an opportunity to accelerate the bandwidthbound decode phase. However, how to adequately balance compute density for prefill with bandwidthcapacity for decode remains open. Moreover, most prior designs do not target endtoend serving, leaving the codesign of dataflow, parallel mapping, and scheduling underexplored. To bridge the gap, we present LaMoSys3.5D, to our knowledge the first scalable 3.5DIC architecture for LLM serving. LaMoSys3.5D composes heterogeneous 3DDRAM chiplets on a 2.5D interposer: computerich chiplets for prefill and bandwidthcapacityrich chiplets for decode. To realize efficient serving, we adopt a hardwaresoftware codesign spanning dataflow, parallel mapping, and introduce a thermalaware modeling and hierarchical designspace exploration framework. Across diverse LLMs and workloads, LaMoSys3.5D improves throughputperwatt over DGXA100 systems by 62 and achieves a 4.87 better endtoend latency geomean versus prior 3D designs. We further distill intriguing design guidelines for 3.5DIC architectures and endtoend inference serving."}
{"id": "2512.08731", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08731", "abs": "https://arxiv.org/abs/2512.08731", "authors": ["Qipan Wang", "Zhe Zhang", "Shuangchen Li", "Hongzhong Zheng", "Zheng Liang", "Yibo Lin", "Runsheng Wang", "Ru Huang"], "title": "LaMoSys3.5D: Enabling 3.5D-IC-Based Large Language Model Inference Serving Systems via Hardware/Software Co-Design", "comment": null, "summary": "The success of large language models LLMs amplifies the need for highthroughput energyefficient inference at scale. 3DDRAMbased accelerators provide high memory bandwidth and therefore an opportunity to accelerate the bandwidthbound decode phase. However, how to adequately balance compute density for prefill with bandwidthcapacity for decode remains open. Moreover, most prior designs do not target endtoend serving, leaving the codesign of dataflow, parallel mapping, and scheduling underexplored. To bridge the gap, we present LaMoSys3.5D, to our knowledge the first scalable 3.5DIC architecture for LLM serving. LaMoSys3.5D composes heterogeneous 3DDRAM chiplets on a 2.5D interposer: computerich chiplets for prefill and bandwidthcapacityrich chiplets for decode. To realize efficient serving, we adopt a hardwaresoftware codesign spanning dataflow, parallel mapping, and introduce a thermalaware modeling and hierarchical designspace exploration framework. Across diverse LLMs and workloads, LaMoSys3.5D improves throughputperwatt over DGXA100 systems by 62 and achieves a 4.87 better endtoend latency geomean versus prior 3D designs. We further distill intriguing design guidelines for 3.5DIC architectures and endtoend inference serving."}
{"id": "2512.08165", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08165", "abs": "https://arxiv.org/abs/2512.08165", "authors": ["Ewout van den Berg", "Brad Mitchell", "Ken Xuan Wei", "Moein Malekakhlagh"], "title": "Large-scale Lindblad learning from time-series data", "comment": null, "summary": "In this work, we develop a protocol for learning a time-independent Lindblad model for operations that can be applied repeatedly on a quantum computer. The protocol is highly scalable for models with local interactions and is in principle insensitive to state-preparation errors. At its core, the protocol forms a linear system of equations for the model parameters in terms of a set of observable values and their gradients. The required gradient information is obtained by fitting time-series data with sums of exponentially damped sinusoids and differentiating those curves. We develop a robust curve-fitting procedure that finds the most parsimonious representation of the data up to shot noise. We demonstrate the approach by learning the Lindbladian for a full layer of gates on a 156-qubit superconducting quantum processor, providing the first learning experiment of this kind. We study the effects of state-preparation and measurement errors and limitations on the operations that can be learned. For improved performance under readout errors, we propose an optional fine-tuning strategy that improves the fit between the time-evolved model and the measured data."}
{"id": "2512.08753", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08753", "abs": "https://arxiv.org/abs/2512.08753", "authors": ["Anindya Bhattacharjee", "Nittya Ananda Biswas", "Khondakar Ashik Shahriar", "Kawsain Bin Salim"], "title": "IoT-based Cost-Effective Fruit Quality Monitoring System using Electronic Nose", "comment": "Paper Accepted in ICCIT 2025 Conference", "summary": "Post-harvest losses due to subjective quality assessment cause significant damage to the economy and food safety, especially in countries like Bangladesh. To mitigate such damages, objective decision-making backed by scientific methods is necessary. An IoT-based, cost-effective quality monitoring system can provide a solution by going beyond subjective quality monitoring and decision-making practices. Here, we propose a low-power, cost-effective fruit quality monitoring system with an array of MQ gas sensors, which can be used as an electronic nose. We track the volatile gas emissions, specifically ethanol, methane, and ammonia, encompassing both ripening and decomposition for a set of bananas. Based on the gas concentration thresholds, we develop a mathematical model to accurately assess fruit quality. We also integrate this information into a dashboard for prompt decision-making and monitoring to make it useful to the farmers. This approach has the potential to reduce economic losses, enhance food safety, and provide scalable solutions for the supply chain."}
{"id": "2512.08753", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08753", "abs": "https://arxiv.org/abs/2512.08753", "authors": ["Anindya Bhattacharjee", "Nittya Ananda Biswas", "Khondakar Ashik Shahriar", "Kawsain Bin Salim"], "title": "IoT-based Cost-Effective Fruit Quality Monitoring System using Electronic Nose", "comment": "Paper Accepted in ICCIT 2025 Conference", "summary": "Post-harvest losses due to subjective quality assessment cause significant damage to the economy and food safety, especially in countries like Bangladesh. To mitigate such damages, objective decision-making backed by scientific methods is necessary. An IoT-based, cost-effective quality monitoring system can provide a solution by going beyond subjective quality monitoring and decision-making practices. Here, we propose a low-power, cost-effective fruit quality monitoring system with an array of MQ gas sensors, which can be used as an electronic nose. We track the volatile gas emissions, specifically ethanol, methane, and ammonia, encompassing both ripening and decomposition for a set of bananas. Based on the gas concentration thresholds, we develop a mathematical model to accurately assess fruit quality. We also integrate this information into a dashboard for prompt decision-making and monitoring to make it useful to the farmers. This approach has the potential to reduce economic losses, enhance food safety, and provide scalable solutions for the supply chain."}
{"id": "2512.08255", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08255", "abs": "https://arxiv.org/abs/2512.08255", "authors": ["Ozlem Erkilic", "Aritra Das", "Angela A. Baiju", "Nicholas Zaunders", "Biveen Shajilal", "Timothy C. Ralph"], "title": "The utility of noiseless linear amplification and attenuation in single-rail discrete-variable quantum communications", "comment": null, "summary": "Quantum communication offers many applications, with teleportation and superdense coding being two of the most fundamental. In these protocols, pre-shared entanglement enables either the faithful transfer of quantum states or the transmission of more information than is possible classically. However, channel losses degrade the shared states, reducing teleportation fidelity and the information advantage in superdense coding. Here, we investigate how to mitigate these effects by optimising the measurements applied by the communicating parties. We formulate the problem as an optimisation over general positive operator-valued measurements (POVMs) and compare the results with physically realisable noiseless attenuation (NA) and noiseless linear amplification (NLA) circuits. For teleportation, NLA/NA and optimised POVMs improve the average fidelity by up to 78% while maintaining feasible success probabilities. For superdense coding, they enhance the quantum advantage over the classical channel capacity by more than 100% in some regimes and shift the break-even point, thereby extending the tolerable range of losses. Notably, the optimal POVMs effectively reduce to NA or NLA, showing that simple, experimentally accessible operations already capture the essential performance gains."}
{"id": "2512.08757", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08757", "abs": "https://arxiv.org/abs/2512.08757", "authors": ["Ujjwal Pratap", "Steffen Hofmann"], "title": "Saturation-based robustly optimal hierarchical operation control of microgrids", "comment": null, "summary": "This paper studies the problem of robustly optimal operation control of microgrids with a high share of renewable energy sources. The main goal is to ensure optimal operation under a wide range of circumstances, given the highly intermittent and uncertain nature of renewable sources and load demand. We formally state this problem, and, in order to solve it, we make effective use of the hierarchical power system control approach. We consider an enhanced primary control layer including droop control and autonomous limitation of power and energy. We prove that this enables the use of constant power setpoints to achieve optimal operation under certain conditions. In order to relax these conditions, the approach is combined with an energy management system, which solves a robust unit commitment problem within a model predictive control framework. Finally, a case study demonstrates the viability of the control design."}
{"id": "2512.08757", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.08757", "abs": "https://arxiv.org/abs/2512.08757", "authors": ["Ujjwal Pratap", "Steffen Hofmann"], "title": "Saturation-based robustly optimal hierarchical operation control of microgrids", "comment": null, "summary": "This paper studies the problem of robustly optimal operation control of microgrids with a high share of renewable energy sources. The main goal is to ensure optimal operation under a wide range of circumstances, given the highly intermittent and uncertain nature of renewable sources and load demand. We formally state this problem, and, in order to solve it, we make effective use of the hierarchical power system control approach. We consider an enhanced primary control layer including droop control and autonomous limitation of power and energy. We prove that this enables the use of constant power setpoints to achieve optimal operation under certain conditions. In order to relax these conditions, the approach is combined with an energy management system, which solves a robust unit commitment problem within a model predictive control framework. Finally, a case study demonstrates the viability of the control design."}
{"id": "2512.08279", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08279", "abs": "https://arxiv.org/abs/2512.08279", "authors": ["Mingrui Jing", "Mengbo Guo", "Lin Zhu", "Hongshun Yao", "Xin Wang"], "title": "Programmable Open Quantum Systems", "comment": "5 + 22 pages, 6 figures", "summary": "Programmability is a unifying paradigm for enacting families of quantum transformations via fixed processors and program states, with a fundamental role and broad impact in quantum computation and control. While there has been a shift from viewing open systems solely as a source of error to treating them as a computational resource, their programmability remains largely unexplored. In this work, we develop a framework that characterizes and quantifies the programmability of Lindbladian semigroups by combining physically implementable retrieval maps with time varying program states. Within this framework, we identify quantum programmable classes enabled by symmetry and stochastic structure, including covariant semigroups and fully dissipative Pauli Lindbladians with finite program dimension. We further provide a necessary condition for physical programmability that rules out coherent generators and typical dissipators generating amplitude damping. For such nonphysically programmable cases, we construct explicit protocols with finite resources. Finally, we introduce an operational programming cost, defined via the number of samples required to program the Lindbladian, and establish its core structural properties, such as continuity and faithfulness. These results provide a notion of programming cost for Lindbladians, bridge programmable channel theory and open system dynamics, and yield symmetry driven compression schemes and actionable resource estimates for semigroup simulation and control in noisy quantum technologies."}
{"id": "2512.08293", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08293", "abs": "https://arxiv.org/abs/2512.08293", "authors": ["Pedram Roushan", "Leigh S. Martin"], "title": "Discovering novel quantum dynamics with NISQ simulators", "comment": "This commentary is an expanded version of a perspective originally published in Science as part of the December 2025 special issue celebrating 100 years of quantum mechanics", "summary": "Major technological advances of the past century are rooted in our understanding of quantum physics in the non-interacting limit. A central challenge today is to understand the behavior of complex quantum many-body systems, where interactions play an essential role. About four decades ago, Richard Feynman proposed using controllable quantum systems to efficiently simulate complex physics and chemistry problems, envisioning quantum orreries, highly tunable quantum devices built to emulate less understood quantum systems. Here we ask whether quantum simulators have already uncovered new physical phenomena-and, if so, in which areas and with what impact. We find that, in several notable instances, they have advanced our understanding of many-body quantum dynamics. Although many of these insights could in principle have been obtained theoretically or numerically, they were nevertheless first achieved using quantum processors. While a broad landscape of problems beyond non-equilibrium dynamics still awaits exploration, it is encouraging that quantum simulators are already beginning to challenge and refine our conventional wisdom."}
{"id": "2512.08303", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08303", "abs": "https://arxiv.org/abs/2512.08303", "authors": ["Shangyun Wang", "Songbai Chen", "Jiliang Jing"], "title": "Quantum-classical correspondence in resonant and nonresonant Rabi-Stark model", "comment": "12 pages, 5 figures", "summary": "Testing the correspondence principle in nonlinear quantum systems is a fundamental pursuit in quantum physics. In this paper, we employed mean field approximation theory to study the semiclassical dynamics in the Rabi-Stark model (RSM) and showed that the nonlinear Stark coupling significantly modulates the semiclassical phase space structure. By analyzing the linear entanglement entropy of coherent states prepared in the classical chaotic and regular regions of the semiclassical phase space, we demonstrate that quantum-classical correspondence can be achieved in the RSM with large atom-light frequency ratios. While this correspondence fails in the resonant Rabi model because its truncated photon number is insufficient to approach the large quantum number limit, we discovered that in the resonant RSM when the nonlinear Stark coupling $U \\to \\pm 1$, the time-averaged linear entanglement entropy correlates strongly with the semiclassical phase space. In particular, when $U \\to -1$, the truncated photon number in the resonant RSM is very close to that in the resonant Rabi model, but the time-averaged linear entanglement entropy still corresponds well with the semiclassical phase space. This result demonstrates that quantum-classical correspondence can be realized in the few-body resonant RSM."}
{"id": "2512.08318", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08318", "abs": "https://arxiv.org/abs/2512.08318", "authors": ["Markus Rambach", "Abhishek Roy", "Alexei Gilchrist", "Akitada Sakurai", "William J. Munro", "Kae Nemoto", "Andrew G. White"], "title": "Photonic Quantum-Accelerated Machine Learning", "comment": "9 pages, 7 figures; Supplemental Material: 6 pages, 3 figures", "summary": "Machine learning is widely applied in modern society, but has yet to capitalise on the unique benefits offered by quantum resources. Boson sampling -- a quantum-interference based sampling protocol -- is a resource that is classically hard to simulate and can be implemented on current quantum hardware. Here, we present a quantum accelerator for classical machine learning, using boson sampling to provide a high-dimensional quantum fingerprint for reservoir computing. We show robust performance improvements under various conditions: imperfect photon sources down to complete distinguishability; scenarios with severe class imbalances, classifying both handwritten digits and biomedical images; and sparse data, maintaining model accuracy with twenty times less training data. Crucially, we demonstrate the acceleration and scalability of our scheme on a photonic quantum processing unit, providing the first experimental validation that boson-sampling-enhanced learning delivers real performance gains on actual quantum hardware."}
{"id": "2512.08328", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08328", "abs": "https://arxiv.org/abs/2512.08328", "authors": ["Takeaki Miyamura", "Zhiling Wang", "Kohei Matsuura", "Yoshiki Sunada", "Keika Sunada", "Kenshi Yuki", "Jesper Ilves", "Yasunobu Nakamura"], "title": "Deterministic Quantum Communication Between Fixed-Frequency Superconducting Qubits via Broadband Resonators", "comment": null, "summary": "Quantum communication between remote chips is essential for realizing large-scale superconducting quantum computers. For such communication, itinerant microwave photons propagating through transmission lines offer a promising approach. However, demonstrations to date have relied on frequency-tunable circuit elements to compensate for fabrication-related parameter variations between sender and receiver devices, introducing control complexity and limiting scalability. In this work, we demonstrate deterministic quantum state transfer and remote entanglement generation between fixed-frequency superconducting qubits on separate chips. To compensate for the sender-receiver mismatch, we employ a frequency-tunable photon-generation technique which enables us to adjust the photon frequency without modifying circuit parameters. To enhance the frequency tunability, we implement broadband transfer resonators composed of two coupled coplanar-waveguide resonators, achieving a bandwidth of more than 100 MHz. This broadband design enables successful quantum communication across a 30-MHz range of photon frequencies between the remote qubits. Quantum process tomography reveals state transfer fidelities of around 78% and Bell-state fidelities of around 73% across the full frequency range. Our approach avoids the complexity of the control lines and noise channels, providing a flexible pathway toward scalable quantum networks."}
{"id": "2512.08384", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08384", "abs": "https://arxiv.org/abs/2512.08384", "authors": ["Sören Wilkening"], "title": "Constraint-oriented biased quantum search for general constrained combinatorial optimization problems", "comment": "11 pages, 3 figures", "summary": "We present a quantum algorithmic routine that extends the realm of Grover-based heuristics for tackling combinatorial optimization problems with arbitrary efficiently computable objective and constraint functions. Building on previously developed quantum methods that were primarily restricted to linear constraints, we generalize the approach to encompass a broader class of problems in discrete domains. To evaluate the potential of our algorithm, we assume the existence of sufficiently advanced logical quantum hardware. With this assumption, we demonstrate that our method has the potential to outperform state-of-the-art classical solvers and heuristics in terms of both runtime scaling and solution quality. The same may be true for more realistic implementations, as the logical quantum algorithm can achieve runtime savings of up to $10^2-10^3$."}
{"id": "2512.08390", "categories": ["quant-ph", "physics.bio-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2512.08390", "abs": "https://arxiv.org/abs/2512.08390", "authors": ["Daniele Loco", "Kisa Barkemeyer", "Andre R. R. Carvalho", "Jean-Philip Piquemal"], "title": "Practical protein-pocket hydration-site prediction for drug discovery on a quantum computer", "comment": null, "summary": "Demonstrating the practical utility of Noisy Intermediate-Scale Quantum (NISQ) hardware for recurrent tasks in Computer-Aided Drug Discovery is of paramount importance. We tackle this challenge by performing three-dimensional protein pockets hydration-site prediction on a quantum computer. Formulating the water placement problem as a Quadratic Unconstrained Binary Optimization (QUBO), we use a hybrid approach coupling a classical three-dimensional reference-interaction site model (3D-RISM) to an efficient quantum optimization solver, to run various hardware experiments up to 123 qubits. Matching the precision of classical approaches, our results reproduced experimental predictions on real-life protein-ligand complexes. Furthermore, through a detailed resource estimation analysis, we show that accuracy can be systematically improved with increasing number of qubits, indicating that full quantum utility is in reach. Finally, we provide evidence that advantageous situations could be found for systems where classical optimization struggles to provide optimal solutions. The method has potential for assisting simulations of protein-ligand complexes for drug lead optimization and setup of docking calculations."}
{"id": "2512.08393", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08393", "abs": "https://arxiv.org/abs/2512.08393", "authors": ["Ren-Ze Zhao", "Ze-An Zhao", "Tian-Le Wang", "Peng Wang", "Sheng Zhang", "Xiao-Yan Yang", "Hai-Feng Zhang", "Zhi-Fei Li", "Yuan Wu", "Zi-Hao Fu", "Sheng-Ri Liu", "Peng Duan", "Guo-Ping Guo"], "title": "Single-Step Phase-Engineered Pulse for Active Readout Cavity Reset in Superconducting Circuits", "comment": null, "summary": "In a circuit QED architecture, we experimentally demonstrate a simple and hardware-efficient Single-Step Phase-Engineered (SSPE) pulse scheme for actively depopulating the readout cavity. The method appends a reset segment with tailored amplitude and phase to a normal square readout pulse. Within the linear-response regime, the optimal reset amplitude scales proportionally with the readout amplitude, while the optimal reset phase remains nearly invariant, significantly simplifying the calibration process. By characterizing the cavity photons dynamics, we show that the SSPE pulse accelerates photon depletion by up to a factor of six compared to passive free decay. We further quantify the qubit backaction induced by the readout pulse and find that the SSPE pulse yields the lowest excitation and relaxation rates compared to a Square and CLEAR pulses. Our results establish the SSPE scheme as a practical and scalable approach for achieving fast, smooth, low-backaction cavity reset in superconducting quantum circuits."}
{"id": "2512.08418", "categories": ["quant-ph", "math.OA"], "pdf": "https://arxiv.org/pdf/2512.08418", "abs": "https://arxiv.org/abs/2512.08418", "authors": ["Saptak Bhattacharya"], "title": "Universal recoverability of quantum states in tracial von-Neumann algebras", "comment": "15 pages, 0 figures", "summary": "In this paper, we discuss a refinement of quantum data processing inequality for the sandwiched quasi-relative entropy $\\mathcal{S}_2$ on a tracial von-Neumann algebra. The main result is a universal recoverability bound with the Petz recovery map, which was previously obtained in the finite dimensional setup."}
{"id": "2512.08429", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08429", "abs": "https://arxiv.org/abs/2512.08429", "authors": ["Joseph C. Chapman", "Yanbao Zhang", "Joseph M. Lukens", "Alberto M. Marino", "Eugene Dumitrescu", "Yan Wang", "Nicholas A. Peters"], "title": "Real-time heralded non-Gaussian teleportation resource-state generator", "comment": "Main: 6 pages, 4 figures. Supplemental: 22 pages, 6 figures, 2 tables", "summary": "Quantum teleportation is a fundamental quantum communications primitive that requires an entangled resource state. In the continuous-variable regime, non-Gaussian entangled resources have been shown theoretically to improve teleportation fidelity compared to Gaussian squeezed vacuum. We experimentally demonstrate a heralded two-mode resource state for non-Gaussian teleportation capable of real-time use. We characterize this state with two-mode homodyne tomography showing it has fidelity $F=0.973\\pm 0.005$ with the expected resource state. Real-time use is enabled by a photon-subtraction orchestrator system performing live coincidence detection and outputting low-jitter and low-latency heralding signals. Live collection of real-time quadrature measurements of photon-subtracted states is enabled by the development of a synchronized homodyne detection server where the orchestrator system queries to collect the real-time quadrature samples corresponding to the heralded state. These results demonstrate significant advancement in enabling the use of heralded non-Gaussian states in quantum networking protocols, especially in the context of quantum repeaters, non-Gaussian quantum sensing and measurement-based quantum computing."}
{"id": "2512.08432", "categories": ["quant-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.08432", "abs": "https://arxiv.org/abs/2512.08432", "authors": ["Zhijian Lai", "Dong An", "Jiang Hu", "Zaiwen Wen"], "title": "A Grover-compatible manifold optimization algorithm for quantum search", "comment": "27 pages, 5 figures", "summary": "Grover's algorithm is a fundamental quantum algorithm that offers a quadratic speedup for the unstructured search problem by alternately applying physically implementable oracle and diffusion operators. In this paper, we reformulate the unstructured search as a maximization problem on the unitary manifold and solve it via the Riemannian gradient ascent (RGA) method. To overcome the difficulty that generic RGA updates do not, in general, correspond to physically implementable quantum operators, we introduce Grover-compatible retractions to restrict RGA updates to valid oracle and diffusion operators. Theoretically, we establish a local Riemannian $μ$-Polyak-Łojasiewicz (PL) inequality with $μ= \\tfrac{1}{2}$, which yields a linear convergence rate of $1 - κ^{-1}$ toward the global solution. Here, the condition number $κ= L_{\\mathrm{Rie}} / μ$, where $L_{\\mathrm{Rie}}$ denotes the Riemannian Lipschitz constant of the gradient. Taking into account both the geometry of the unitary manifold and the special structure of the cost function, we show that $L_{\\mathrm{Rie}} = O(\\sqrt{N})$ for problem size $N = 2^n$. Consequently, the resulting iteration complexity is $O(\\sqrt{N} \\log(1/\\varepsilon))$ for attaining an $\\varepsilon$-accurate solution, which matches the quadratic speedup of $O(\\sqrt{N})$ achieved by Grover's algorithm. These results demonstrate that an optimization-based viewpoint can offer fresh conceptual insights and lead to new advances in the design of quantum algorithms."}
{"id": "2512.08433", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08433", "abs": "https://arxiv.org/abs/2512.08433", "authors": ["Michael Stefszky", "Kai-Hong Luo", "Jan-Lucas Eickmann", "Simone Atzeni", "Florian Lütkewitte", "Cheeranjiv Pandey", "Fabian Schlue", "Jonas Lammers", "Mikhail Roiz", "Timon Schapeler", "Laura Ares", "Milad Yahyapour", "Alexander Kastner", "Joschua Martinek", "Michael Mittermair", "Carlos Sevilla", "Marius Leyendecker", "Oskar Kohout", "Dmitriy Mitin", "Ronald Holzwarth", "Jan Sperling", "Tim Bartley", "Fabian Steinlechner", "Benjamin Brecht", "Christine Silberhorn"], "title": "Benchmarking Gaussian and non-Gaussian input states with a hybrid sampling platform", "comment": null, "summary": "The original boson sampling paradigm-consisting of multiple single-photon input states, a large interferometer, and multi-channel click detection-was originally proposed as a photonic route to quantum computational advantage. Its non-Gaussian resources, essential for outperforming any classical system, are provided by single-photon inputs and click detection. Yet the drive toward larger experiments has led to the replacement of experimentally demanding single-photon sources with Gaussian states, thereby diminishing the available non-Gaussianity-a critical quantum resource. As the community broadens its focus from the initial sampling task to possible real-world applications, it becomes crucial to quantify the performance cost associated with reducing non-Gaussian resources and to benchmark sampling platforms that employ different input states.\n  To address this need, we introduce the Paderborn Quantum Sampler (PaQS), a hybrid platform capable of performing sampling experiments with eight Gaussian or non-Gaussian input states in a 12-mode interferometer within a single experimental run. This architecture enables direct, side-by-side benchmarking of distinct sampling regimes under otherwise identical conditions. By employing a semi-device-independent framework, offering certification that does not rely on prior knowledge of the interferometer or the input states, we verify that the observed data cannot be reproduced by any classical model-a prerequisite for demonstrating quantum advantage. Applying this framework, we observe clear performance gains arising from non-Gaussian input states."}
{"id": "2512.08442", "categories": ["quant-ph", "physics.acc-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.08442", "abs": "https://arxiv.org/abs/2512.08442", "authors": ["A. S. Dyatlov", "D. M. Dolgintsev", "V. V. Gerasimov", "V. V. Kobets", "V. P. Nazmov", "M. A. Nozdrin", "A. N. Sergeev", "D. S. Shokin", "K. E. Yunenko", "D. V. Karlovets"], "title": "High-OAM Deep Ultraviolet Twisted Light Generation for RF-Photoinjector Applications", "comment": null, "summary": "We report on the generation and characterization of ultraviolet (wavelength 266 nm) twisted light with high orbital angular momentum (OAM) using three types of fabricated diffractive optical elements (DOEs): a reflective fork grating, a high-charge spiral phase plate (SPP), and binary axicons. All elements were integrated into a drive-laser beamline of an electron RF-photoinjector, enabling direct evaluation under accelerator-relevant conditions.\n  The SPP produced a high-purity Laguerre-Gaussian mode with OAM l = 64 and a measured conversion efficiency of approximately 80\\%. Binary axicons generated quasi-Bessel twisted light with topological charges up to m = 10, exhibiting low divergence and stable multi-lobe ring structures. The fork grating reliably produced lower-order modes, l = 2-8, with good agreement between simulations and cylindrical-lens diagnostics.\n  These results constitute, to our knowledge, the first comprehensive experimental demonstration of deep-UV high-OAM beams generated with fabricated DOEs and validated through mode-conversion measurements. The demonstrated techniques are compatible with high-power UV laser systems used in RF-photoinjectors and offer a practical route toward structured photocathode illumination and the generation of relativistic vortex electrons at a particle accelerator facility."}
{"id": "2512.08458", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08458", "abs": "https://arxiv.org/abs/2512.08458", "authors": ["Sukhjit P. Singh", "Elnaz Bazzazi", "Diego N. Bernal-García", "Simon White", "Hassan Jamal Latief", "Alison Goldingay", "Sven Rogge", "Sergei Slussarenko", "Farzad Ghafari", "Emanuele Polino", "Nora Tischler"], "title": "Heralded generation of a three-mode NOON state", "comment": "16 pages, 7 figures", "summary": "Entangled states of photons form the foundation of quantum communication, computation, and metrology. Yet their generation remains fundamentally constrained: in the absence of intrinsic photon-photon interactions, the generation of such states is inherently probabilistic rather than deterministic. The prevalent technique of post-selection verifies the creation of an entangled state by detecting and thus destroying it. Heralding offers a solution in which measuring ancillary photons in auxiliary modes signals the state generation without the need to measure it. Here, we report an experiment to generate a three-mode two-photon NOON state, where the detection of a single photon in one heralding mode signifies the presence of the state in three target modes. We validate the generated state by estimating a fidelity of 0.823 +/- 0.018 with respect to an ideal three-mode NOON state and certifying genuine multipartite entanglement. By virtue of the high success probability and small resource overhead of our scheme, our work provides a theoretical and experimental stepping stone for entangled multi-mode state generation, which is realizable with current technology. These multi-mode entangled states represent a key direction for linear optical quantum information that is complementary to multi-qubit state encoding."}
{"id": "2512.08470", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.08470", "abs": "https://arxiv.org/abs/2512.08470", "authors": ["Ksenia Shagalov", "David Feldstein-Bofill", "Leo Uhre Jakobsen", "Zhenhai Sun", "Casper Wied", "Amalie T. J. Paulsen", "Johann Bock Severin", "Malthe A. Marciniak", "Clinton A. Potts", "Anders Kringhøj", "Jacob Hastrup", "Karsten Flensberg", "Svend Krøjer", "Morten Kjaergaard"], "title": "Higher Josephson harmonics in a tunable double-junction transmon qubit", "comment": null, "summary": "Tunable Josephson harmonics open up for new qubit design. We demonstrate a superconducting circuit element with a tunnel junction in series with a SQUID loop, yielding a highly magnetic-flux tunable harmonic content of the Josephson potential. We analyze spectroscopy of the first four qubit transitions with a circuit model which includes the internal mode, revealing a second harmonic up to $\\sim10\\%$ of the fundamental harmonic. Interestingly, a sweet spot where the dispersive shift vanishes is achieved by balancing the dispersive couplings to the internal and qubit modes. The highly tunable set-up provides a route toward protected qubits, and customizable nonlinear microwave devices."}
{"id": "2512.08507", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08507", "abs": "https://arxiv.org/abs/2512.08507", "authors": ["Kentaro Imafuku"], "title": "Syntactic Structure, Quantum Weights", "comment": "26 pages, 1 figure", "summary": "Why do local actions and exponential Euclidean weights arise so universally in classical, statistical, and quantum theories? We offer a structural explanation from minimal constraints on finite descriptions of admissible histories. Assume that histories admit finite, self-delimiting (prefix-free) generative codes that can be decoded sequentially in a single forward pass. These purely syntactic requirements define a minimal descriptive cost, interpretable as a smoothed minimal program length, that is additive over local segments. First, any continuous local additive cost whose stationary sector coincides with the empirically identified classical variational sector is forced into a unique Euler--Lagrange equivalence class. Hence the universal form of an action is fixed by descriptional structure alone, while the specific microscopic Lagrangian and couplings remain system-dependent semantic input. Second, independently of microscopic stochasticity, finite prefix-free languages exhibit exponential redundancy: many distinct programs encode the same coarse history, and this redundancy induces a universal exponential multiplicity weight on histories. Requiring this weight to be real and bounded below selects a real Euclidean representative for stable local bosonic systems, yielding the standard Euclidean path-integral form. When Osterwalder--Schrader reflection positivity holds, the Euclidean measure reconstructs a unitary Lorentzian amplitude."}
{"id": "2512.08540", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.08540", "abs": "https://arxiv.org/abs/2512.08540", "authors": ["Niels Tripier-Mondancin", "David Barral", "Ganaël Roeland", "Raúl Leonardo Rincon Celis", "Yann Bouchereau", "Nicolas Treps"], "title": "Tunable passive squeezing of squeezed light through unbalanced double homodyne detection", "comment": "12 pages, 6 figures", "summary": "The full characterization of quantum states of light is a central task in quantum optics and information science. Double homodyne detection provides a powerful method for the direct measurement of the Husimi Q quasi-probability distribution, offering a complete state representation in a simple experimental setting and a limited time frame. Here, we demonstrate that double homodyne detection can serve as more than a passive measurement apparatus. By intentionally unbalancing the input beamsplitter that splits the quantum signal, we show that the detection scheme itself performs an effective squeezing or anti-squeezing transformation on the state being measured. The resulting measurement directly samples the Q function of the input state as if it were acted upon by a squeezing operator whose strength is a tunable experimental parameter : the beamsplitter's reflectivity. We experimentally realize this technique using a robust polarization-encoded double homodyne detection to characterize a squeezed vacuum state. Our results demonstrate the controlled deformation of the measured Q function's phase-space distribution, confirming that unbalanced double homodyne detection is a versatile tool for simultaneous quantum state manipulation and characterization."}
{"id": "2512.08565", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08565", "abs": "https://arxiv.org/abs/2512.08565", "authors": ["D. -S. Wang", "X. Xu", "Y. -D. Liu"], "title": "Quantum simulation in the entanglement picture", "comment": "Comments are welcome", "summary": "The notion of ``picture'' is fundamental in quantum mechanics. In this work, a new picture, which we call entanglement picture, is proposed based on the novel channel-state duality, whose importance is revealed in quantum information science. We illustrate the application of entanglement picture in quantum algorithms for the simulation of many-body dynamics, quantum field theory, thermal physics, and more generic quantities."}
{"id": "2512.08612", "categories": ["quant-ph", "math-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.08612", "abs": "https://arxiv.org/abs/2512.08612", "authors": ["Cham Oumie", "Wu-Ming Liu", "Kashif Ammar Yasir"], "title": "$\\mathcal{PT}$-symmetric cavity magnomechanics with gain-assisted transparency and amplification", "comment": "13 pages, 8 figures", "summary": "We investigate magnomechanically induced transparency in a parity-time-symmetric cavity magnomechanical system with traveling-field-induced non-Hermiticity. The setup consists of a microwave cavity mode coupled to magnons in a single-crystal yttrium iron garnet sphere, which in turn are hybridized with a vibrational mechanical mode through magnetostrictive interaction. In the Hermitian regime, strong photon-magnon coupling generates a single transparency window in the cavity transmission, which splits into a doublet when the magnon is coherently hybridized with the mechanical mode via magnomechanical coupling. This establishes a versatile platform in which the transparency spectrum can be engineered from single- to multi-window response using experimentally accessible, scaled magnomechanical interactions. When a non-Hermitian coupling is introduced, the system enters a parity-time-broken regime in which the transparency ceases to be purely passive and becomes gain assisted, leading to asymmetric transmission with amplification on one side of the resonance and enhanced absorption on the other. By tuning the cavity detuning, we convert magnomechanical transparency into Fano-type line shapes with strongly non-Lorentzian phase dispersion and map their deformation into asymmetric, gain-assisted Fano ridges in the joint space of probe and magnon detunings. Finally, we analyze the associated group delay and show that both slow- and fast-light behavior can be widely tuned by varying the photon-magnon and magnomechanical couplings together with the non-Hermitian strength, highlighting parity-time-symmetric cavity magnomechanics as a promising platform for reconfigurable quantum signal processing and enhanced sensing."}
{"id": "2512.08623", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.08623", "abs": "https://arxiv.org/abs/2512.08623", "authors": ["Esther Hänggi", "Iyán Méndez Veiga", "Ligong Wang"], "title": "An Efficient Secret Communication Scheme for the Bosonic Wiretap Channel", "comment": "5 pages, 2 figures", "summary": "We propose a new secret communication scheme over the bosonic wiretap channel. It uses readily available hardware such as lasers and direct photodetectors. The scheme is based on randomness extractors, pulse-position modulation, and Reed-Solomon codes and is therefore computationally efficient. It is secure against an eavesdropper performing coherent joint measurements on the quantum states it observes. In the low-photon-flow limit, the scheme is asymptotically optimal and achieves the same dominant term as the secrecy capacity of the same channel."}
{"id": "2512.08635", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08635", "abs": "https://arxiv.org/abs/2512.08635", "authors": ["Zixuan Liu", "Ognyan Oreshkov"], "title": "Parity erasure: a foundational principle for indefinite causal order", "comment": "3+2 pages, 2 figures", "summary": "Processes with indefinite causal order can arise when quantum theory is locally valid. Here, we identify an information-theoretic principle, termed parity erasure, that completely characterizes such processes. Our characterization does not rely on the formalism of quantum theory itself, but instead is derived from a set of axioms for general operational probabilistic theories, and thus holds also for a large class of theories beyond quantum theory. This informational approach reveals a fundamental property of information exchange in scenarios with indefinite causal structure."}
{"id": "2512.08638", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.08638", "abs": "https://arxiv.org/abs/2512.08638", "authors": ["Anthony D. Manni", "Christopher R. Schwarze", "David S. Simon", "Abdoulaye Ndao", "Alexander V. Sergienko"], "title": "Strain sensitivity enhancement in a Grover-Michelson interferometer", "comment": "13 pages, 10 figures", "summary": "The Michelson interferometric phase detection resolution can be enhanced by replacing conventional beam splitters with novel directionally unbiased four-port scatterers, such as Grover coins. We present a quantitative analysis of the noise-to-signal ratio of sideband frequencies generated by gravitational wave-induced phase perturbations in a Grover-Michelson interferometer (GMI). We discuss the principles of GMI signal enhancement and demonstrate how combining this configuration with additional light-recycling arrangements further enhances the performance."}
{"id": "2512.08641", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08641", "abs": "https://arxiv.org/abs/2512.08641", "authors": ["Dmitriy Kondaurov", "Evgeny Polyakov"], "title": "Quantum Brownian Motion as a Classical Stochastic Process in Phase Space", "comment": null, "summary": "We establish that the exact quantum dynamics of a Brownian particle in the Caldeira-Leggett model can be mapped, at any temperature, onto a classical, non-Markovian stochastic process in phase space. Starting from a correlated thermal equilibrium state between the particle and bath, we prove that this correspondence is exact for quadratic potentials under arbitrary quantum state preparations of the particle itself. For more general, smooth potentials, we identify and exploit a natural small parameter: the density matrix becomes strongly quasidiagonal in the coordinate representation, with its off-diagonal width shrinking as the bath's spectral cutoff increases, providing a controlled parameter for accurate approximation. The framework is fully general: arbitrary initial quantum states-including highly non-classical superpositions-are incorporated via their Wigner functions, which serve as statistical weights for trajectory ensembles. Furthermore, the formalism naturally accommodates external manipulations and measurements modeled by preparation functions acting at arbitrary times, enabling the simulation of complex driven-dissipative quantum protocols."}
{"id": "2512.08650", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.08650", "abs": "https://arxiv.org/abs/2512.08650", "authors": ["Kangkang Li", "Yue Wang", "Ze Wang", "Xin Zhou", "Jincheng Li", "Yinke Cheng", "Binyan Wu", "Qihuang Gong", "Bei-Bei Li", "Qi-Fan Yang"], "title": "Perfect continuous-variable quantum microcombs", "comment": null, "summary": "Quantum microcombs generated in high-Q microresonators provide compact, multiplexed sources of entangled modes for continuous-variable (CV) quantum information processing. While deterministic generation of CV states via Kerr-induced two-mode squeezing has been demonstrated, achieving spectrally uniform squeezing remains challenging because of asymmetry and anomalies in the dispersion profile. Here we overcome these limitations by combining a microresonator with an engineered mode spectrum and optimized pump conditions. We realize a CV quantum microcomb comprising 14 independent two-mode squeezed states, each exhibiting more than 4 dB of raw squeezing (up to 4.3 dB) across a 0.7 THz bandwidth. This uniform, high-performance quantum resource represents a key step toward scalable, integrated CV quantum technologies operating beyond classical limits."}
{"id": "2512.08662", "categories": ["quant-ph", "cond-mat.quant-gas", "physics.app-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.08662", "abs": "https://arxiv.org/abs/2512.08662", "authors": ["Kashif Ammar Yasir", "Gao Xianlong"], "title": "Spectroscopic readout of chiral photonic topology in a single-cavity spin-orbit-coupled Bose-Einstein condensate", "comment": "29 pages, 7 Figures", "summary": "Topological photonic phases are typically identified through band reconstruction, steady-state transmission, or real-space imaging of edge modes. In this work, we present a framework for spectroscopic readout of chiral photonic topology in a single driven optical cavity containing a spin-orbit-coupled Bose-Einstein condensate. We demonstrate that the cavity transmission power spectral density provides a direct and measurable proxy for a momentum- and frequency-resolved photonic Chern marker, enabling topological characteristics to be inferred from spectral data without the need for bulk-band tomography. In the loss-dominated regime, where cavity decay exceeds atomic dissipation, the power spectral density exhibits Dirac-like gapped hybrid modes with a vanishing Chern marker, indicating a trivial phase. When the dissipation imbalance is reversed, a bright, gap-spanning spectral ridge emerges, co-localized with peaks in both the Chern marker and Berry curvature. The complex spectrum reveals parity-time symmetric coalescences and gain-loss bifurcations, marking exceptional points and enabling chiral, gap-traversing transport. By linking noise spectroscopy to geometric and non-Hermitian topology in a minimal cavity-QED architecture, this work provides a framework for spectroscopic detection of topological order in driven quantum systems. This approach offers a pathway to compact, tunable topological photonics across a broad range of light-matter platforms, providing a method for the study and control of topological phases in hybrid quantum systems."}
{"id": "2512.08675", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08675", "abs": "https://arxiv.org/abs/2512.08675", "authors": ["Chengzhuo Xu", "Xiao Chen", "Xi Li", "Zhihao Liu", "Zhigang Li"], "title": "A Unified Framework for Optimizing Uniformly Controlled Structures in Quantum Circuits", "comment": null, "summary": "Quantum unitaries of the form ${Σ_{c}\\ket{c}\\bra{c}\\otimes U_{c}}$ are ubiquitous in quantum algorithms. This class encompasses not only standard uniformly controlled gates (UCGs) but also a wide range of circuits with uniformly controlled structures. However, their circuit-depth and gate-count complexities have not been systematically analyzed within a unified framework. In this work, we study the general decomposition problem for UCG and UCG-like structure. We then introduce the restricted Uniformly Controlled Gates (rUCGs) as a unified algebraic model, defined by a 2-divisible Abelian group that models the controlled gate set. This model captures uniformly controlled rotations, multi-qubit uniformly controlled gates, and diagonal unitaries. Furthermore, this model also naturally incorporates k-sparse version (k-rUCGs), where only a subset of control qubits participate in each multi-qubit gate. Building on this algebraic model, we develop a general framework. For an n-control rUCG, the framework reduce the gate complexity from ${O(n2^n)}$ to ${O(2^n})$ and the circuit depth from ${O(2^n\\log n)}$ to ${O(2^n\\log n/n)}$. The framework further provides systematic size and depth bounds for k-rUCGs by exploiting sparsity in the control space, with same optimization coefficient as rUCG, respectively. Empirical evaluations on representative QAOA circuits and quantum state preparation both confirm reductions in depth and size. Crucially, these results highlight that the rUCG model and its associated decomposition framework unify circuits previously considered structurally distinct under a single, asymptotically optimal synthesis paradigm."}
{"id": "2512.08687", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08687", "abs": "https://arxiv.org/abs/2512.08687", "authors": ["Tian-Yi Gu", "Gaoyong Sun"], "title": "Non-Hermitian symmetry breaking and Lee-Yang theory for quantum XYZ and clock models", "comment": "7 pages, 4 figures", "summary": "Lee-Yang theory offers a unifying framework for understanding classical phase transitions and dynamical quantum phase transitions through the analysis of partition functions and Loschmidt echoes. Recently, this framework is extended to characterize quantum phase transitions in arXiv:2509.20258 by introducing the concepts of non-Hermitian symmetry breaking and fidelity zeros. Here, we generalize the theory by studying a broad class of quantum models, including the XY model, the XXZ model, the XYZ model, and the $\\mathbb{Z}_3$ clock model in one dimension, subject to complex external magnetic field. For the XY, XXZ and XYZ models, we find that the complex field breaks parity symmetry and induces oscillations of the ground state between the two parity sectors, giving rise to fidelity zeros within the ordered phases. For the $\\mathbb{Z}_3$ clock model, the complex field splits the real part of the ground-state energy between the neutral sector ($q=0$) and the charged sectors ($q=1,2$), while preserving the degeneracy within the charged sector. Fidelity zeros arise only after projecting out one of the charged sectors, and the finite-size scaling of these zeros produces critical exponents fully consistent with analytical predictions."}
{"id": "2512.08709", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.08709", "abs": "https://arxiv.org/abs/2512.08709", "authors": ["Alex Gunning", "Aydin Deger", "Sridevi Kuriyattil", "Andrew J. Daley"], "title": "Geometry-driven transitions in sparse long-range spin models with cold atoms", "comment": "14 pages, 10 figures", "summary": "We explore the influence of geometry in the critical behavior of sparse long-range spin models. We examine a model with interactions that can be continuously tuned to induce distinct changes in the metric, topology, and dimensionality of the coupling graph. This underlying geometry acts as the driver of criticality, with structural changes in the graph coinciding with and dictating the phase boundaries. We further discuss how this framework connects naturally to realizations in tweezer arrays with Rydberg excitations. In certain cases, the effective geometry can be incorporated in the layout of atoms in tweezers to realize phase transitions that preserve universal features, simplifying their implementation in near-term experiments."}
{"id": "2512.08749", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.08749", "abs": "https://arxiv.org/abs/2512.08749", "authors": ["David Blanik", "José Garre-Rubio"], "title": "Non-abelian quantum double models from iterated gauging", "comment": "12 pages, 2 figures", "summary": "We reconstruct all (2+1)D quantum double models of finite groups from their boundary symmetries through the repeated application of a gauging procedure, extending the existing construction for abelian groups. We employ the recently proposed categorical gauging framework, based on matrix product operators (MPOs), to derive the appropriate gauging procedure for the $\\mathsf{Rep}\\, G$ symmetries appearing in our construction and give an explicit description of the dual emergent $G$ symmetry, which is our main technical contribution. Furthermore, we relate the possible gapped boundaries of the quantum double models to the quantum phases of the one-dimensional input state to the iterated gauging procedure. Finally, we propose a gauging procedure for 1-form $\\mathsf{Rep}\\, G$ symmetries on a two-dimensional lattice and use it to extend our results to the construction of (3+1)D quantum doubles models through the iterative gauging of (2+1)-dimensional symmetries."}
{"id": "2512.08880", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.08880", "abs": "https://arxiv.org/abs/2512.08880", "authors": ["Adrian Parra-Rodriguez", "Miguel Clavero-Rubio", "Philippe Gigon", "Tomás Ramos", "Álvaro Gómez-León", "Diego Porras"], "title": "Floquet Topological Frequency-Converting Amplifier", "comment": "12 Pages, 6 figures. Comments are welcome", "summary": "We introduce a driven-dissipative Floquet model in which a single harmonic oscillator with modulated frequency and decay realizes a non-Hermitian synthetic lattice with an effective electric field gradient in frequency space. Using the Floquet-Green's function and its doubled-space representation, we identify a topological regime that supports directional amplification and frequency conversion, accurately captured by a local winding number. The underlying mode structure is well described by a Jackiw-Rebbi-like continuum theory with Dirac cones and solitonic zero modes in synthetic frequency. Our results establish a simple and experimentally feasible route to non-Hermitian topological amplification, naturally implementable in current quantum technologies such as superconducting circuits."}
{"id": "2512.08893", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08893", "abs": "https://arxiv.org/abs/2512.08893", "authors": ["Jalan A. Ziyad", "Robin Blume-Kohout", "Kenneth Rudinger"], "title": "Emergent Non-Markovianity in Logical Qubit Dynamics", "comment": "21 pages, 7 figures", "summary": "Logical qubits encoded in quantum error correcting codes can exhibit non-Markovian dynamical evolution, even when the underlying physical noise is Markovian. To understand this emergent non-Markovianity, we define a Markovianity condition appropriate to logical gate operations, and study it by relating logical operations to their physical implementation (operations on the data qubits into which the logical qubit is encoded). We apply our analysis to small quantum codes, and show that they exhibit non-Markovian dynamics even for very simple physical noise models. We show that non-Markovianity can emerge from Markovian physical operations if (and only if) the physical qubits are not necessarily returned to the code subspace after every round of QEC. In this situation, the syndrome qubits can act as a memory, mediating time correlations and enabling violation of the Markov condition. We quantify the emergent non-Markovianity in simple examples, and propose sufficient conditions for reliable use of gate-based characterization techniques like gate set tomography in early fault-tolerant quantum devices."}
{"id": "2512.08900", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08900", "abs": "https://arxiv.org/abs/2512.08900", "authors": ["Pablo Tikas Pueyo", "Tomás Fernández Martos", "Gabriel Senno"], "title": "Deterministic randomness extraction for semi-device-independent quantum random number generation", "comment": "8+7 pages, 4 figures. Comments welcome!", "summary": "It is a well-known fact in classical information theory that no deterministic procedure can extract close-to-ideal randomness from an arbitrary entropy source. On the other hand, if additional knowledge about the source is available -- e.g., that it is a sequence of independent Bernoulli trials -- then deterministic extractors do exist. For quantum entropy sources, where in addition to classical random variables we consider quantum side information, the use of extra knowledge about their structure was pioneered in a recent publication [C. Foreman and L. Masanes, Quantum 9, 1654 (2025)]. In that work, the authors provide deterministic extractors for device-independent randomness generation with memoryless devices achieving a sufficiently high CHSH score. In this work, we extend their construction to the prepare-and-measure scenario. Specifically, we prove that the considered functions are also extractors for memoryless devices in a semi-device-independent setting under an overlap assumption on the prepared quantum states. We then simulate the resulting randomness generation protocol on a novel and experimentally relevant family of behaviors, observing positive key rates already for $7\\times 10^3$ rounds."}
{"id": "2512.08914", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08914", "abs": "https://arxiv.org/abs/2512.08914", "authors": ["David Zenati", "Eliya Nachmani"], "title": "SAQ: Stabilizer-Aware Quantum Error Correction Decoder", "comment": null, "summary": "Quantum Error Correction (QEC) decoding faces a fundamental accuracy-efficiency tradeoff. Classical methods like Minimum Weight Perfect Matching (MWPM) exhibit variable performance across noise models and suffer from polynomial complexity, while tensor network decoders achieve high accuracy but at prohibitively high computational cost. Recent neural decoders reduce complexity but lack the accuracy needed to compete with computationally expensive classical methods. We introduce SAQ-Decoder, a unified framework combining transformer-based learning with constraint aware post-processing that achieves both near Maximum Likelihood (ML) accuracy and linear computational scalability with respect to the syndrome size. Our approach combines a dual-stream transformer architecture that processes syndromes and logical information with asymmetric attention patterns, and a novel differentiable logical loss that directly optimizes Logical Error Rates (LER) through smooth approximations over finite fields. SAQ-Decoder achieves near-optimal performance, with error thresholds of 10.99% (independent noise) and 18.6% (depolarizing noise) on toric codes that approach the ML bounds of 11.0% and 18.9% while outperforming existing neural and classical baselines in accuracy, complexity, and parameter efficiency. Our findings establish that learned decoders can simultaneously achieve competitive decoding accuracy and computational efficiency, addressing key requirements for practical fault-tolerant quantum computing systems."}
{"id": "2512.08921", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08921", "abs": "https://arxiv.org/abs/2512.08921", "authors": ["Tharon D. Morrison", "Joonhyuk Kwon", "Matthew A. Delaney", "David R. Leibrandt", "Daniel Stick", "Hayden J. McGuinness"], "title": "Autonomous multi-ion optical clock with on-chip integrated photonic light delivery", "comment": "10 pages, 6 figures", "summary": "Integrated photonics in trapped-ion systems are critical for the realization of applications such as portable optical atomic clocks and scalable quantum computers. However, system-level integration of all required functionalities remains a key challenge. In this work, we demonstrate an autonomously operating optical clock having a short-term frequency instability of $3.14(5)\\times 10^{-14} / \\sqrtτ$ using an ensemble of four \\ybion ions trapped in a multi-site surface-electrode trap at room temperature. All clock operations are performed with light delivered via on-chip waveguides. We showcase the system's resilience through sustained, autonomous operation featuring automated ion shuttling and reloading to mitigate ion loss during interleaved clock measurements. This work paves the way beyond component-level functionality to establish a viable and robust architecture for the next generation of portable, multi-ion quantum sensors and computers."}
{"id": "2512.08421", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08421", "abs": "https://arxiv.org/abs/2512.08421", "authors": ["Florian Lange", "Frank Göhmann", "Gerhard Wellein", "Holger Fehske"], "title": "Decay of spin helices in XXZ quantum spin chains with single-ion anisotropy", "comment": "6 pages, 6 figures", "summary": "Long-lived spin-helix states facilitate the study of non-equilibrium dynamics in quantum magnets. We consider the decay of transverse spin-helices in antiferromagnetic spin-$S$ XXZ chains with single-ion anisostropy. The spin-helix decay is observable in the time evolution of the local magnetization that we calculate numerically for the system in the thermodynamic limit using infinite time-evolving block decimation simulations. Although the single-ion anisotropy prevents helix states from being eigenstates of the Hamiltonian, they still can be long-lived for appropriately chosen wave numbers. In case of an easy-axis exchange anisotropy the single-ion anisotropy may even stabilize the helices. Within a spin-wave approximation, we obtain a condition giving an estimate for the most stable wave number $Q$ that agrees qualitatively with our numerical results."}
{"id": "2512.08624", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.08624", "abs": "https://arxiv.org/abs/2512.08624", "authors": ["Jonas B. Rigo", "Markus Schmitt"], "title": "Operator Lanczos Approach enabling Neural Quantum States as Real-Frequency Impurity Solvers", "comment": "5 pages, 3 figures, appendices", "summary": "To understand the intricate exchange between electrons of different bands in strongly correlated materials, it is essential to treat multi-orbital models accurately. For this purpose, dynamical mean-field theory (DMFT) provides an established framework, whose scope crucially hinges on the availability of efficient quantum impurity solvers. Here we present a real-frequency impurity solver based on neural quantum states (NQS) combined with an operator-Lanczos construction. NQS are an asymptotically unbiased variational ground-state ansatz that employs neural networks to capture long-range correlations on complicated graph structures. We leverage this ability to solve multi-orbital impurity problems using a systematically improvable Segmented Commutator Operator-Lanczos (SCOL) construction. Our benchmarks on both the single-orbital Anderson model and the multi-orbital Hubbard-Kanamori impurity Hamiltonian reveal excellent ground-state precision and the capacity to accurately resolve zero temperature spectral functions and self-energies. These results open avenues for extending DMFT to more challenging problems."}
