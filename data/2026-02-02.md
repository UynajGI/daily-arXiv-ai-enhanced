<div id=toc></div>

# Table of Contents

- [stat.ME](#stat.ME) [Total: 11]
- [quant-ph](#quant-ph) [Total: 36]
- [physics.ao-ph](#physics.ao-ph) [Total: 2]
- [math.NA](#math.NA) [Total: 17]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.CE](#cs.CE) [Total: 2]
- [hep-lat](#hep-lat) [Total: 2]
- [cs.ET](#cs.ET) [Total: 1]
- [math.OC](#math.OC) [Total: 16]
- [physics.hist-ph](#physics.hist-ph) [Total: 1]
- [nlin.AO](#nlin.AO) [Total: 1]
- [physics.soc-ph](#physics.soc-ph) [Total: 3]
- [math.ST](#math.ST) [Total: 5]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 7]
- [q-fin.RM](#q-fin.RM) [Total: 1]
- [eess.SY](#eess.SY) [Total: 3]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 9]
- [q-fin.ST](#q-fin.ST) [Total: 1]


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [1] [Changepoint Detection As Model Selection: A General Framework](https://arxiv.org/abs/2601.22481)
*Michael Grantham,Xueheng Shi,Bertrand Clarke*

Main category: stat.ME

TL;DR: 本文提出了一种基于L0模型选择的变点检测通用框架，核心方法为迭代重加权融合套索（IRFL），在多种复杂场景下实现了精确的变点检测，并可扩展至图像数据处理。


<details>
  <summary>Details</summary>
Motivation: 为了提升在存在趋势、季节性和序列相关误差等复杂干扰因素下的变点检测精度，并实现更灵活的结构变化建模。

Method: 采用迭代重加权融合套索（IRFL）方法，通过自适应调整惩罚权重优化支持恢复，并结合BIC等准则进行模型选择，同时可建模季节性、趋势和自回归依赖。

Result: 模拟研究表明IRFL在多种挑战性场景中均能准确检测变点；在图像数据中实现了保边去噪与分割；实际应用中对Mauna Loa CO2数据的分析结果优于传统最小二乘法，且变点与火山喷发及ENSO事件吻合。

Conclusion: IRFL是一种鲁棒且可扩展的工具，适用于复杂数据中的结构变化检测，具有广泛的应用潜力。

Abstract: This dissertation presents a general framework for changepoint detection based on L0 model selection. The core method, Iteratively Reweighted Fused Lasso (IRFL), improves upon the generalized lasso by adaptively reweighting penalties to enhance support recovery and minimize criteria such as the Bayesian Information Criterion (BIC). The approach allows for flexible modeling of seasonal patterns, linear and quadratic trends, and autoregressive dependence in the presence of changepoints.
  Simulation studies demonstrate that IRFL achieves accurate changepoint detection across a wide range of challenging scenarios, including those involving nuisance factors such as trends, seasonal patterns, and serially correlated errors. The framework is further extended to image data, where it enables edge-preserving denoising and segmentation, with applications spanning medical imaging and high-throughput plant phenotyping.
  Applications to real-world data demonstrate IRFL's utility. In particular, analysis of the Mauna Loa CO2 time series reveals changepoints that align with volcanic eruptions and ENSO events, yielding a more accurate trend decomposition than ordinary least squares. Overall, IRFL provides a robust, extensible tool for detecting structural change in complex data.

</details>


### [2] [Group Sequential Methods for the Win Ratio](https://arxiv.org/abs/2601.22525)
*Tracy Bergemann,Tim Hanson*

Main category: stat.ME

TL;DR: 本文研究了在使用赢率作为主要终点时，如何在序贯设计中应用传统的α消耗方法，并证明在某些常见条件下，Lan-DeMets α消耗法可以直接用于赢率的随机试验。


<details>
  <summary>Details</summary>
Motivation: 由于赢率在临床试验中的广泛应用及其对复合终点的整合能力，探索其在适应性设计（如序贯设计）中的统计学性质成为亟需解决的问题。

Method: 推导了用于检验赢率的U统计量在渐近分布下的协方差结构，并通过模拟验证了传统α消耗法在多次中期分析中保持I类错误率的能力。

Result: 结果表明，用于检验赢率的增量U统计量在渐近意义上满足独立增量假设，模拟显示Type I误差率得以控制，实际临床试验数据回顾也展示了早期终止的可能性。

Conclusion: 在满足一定常见条件的情况下，现有的可计算传统序贯边界软件可直接用于基于赢率的随机临床试验设计。

Abstract: The win ratio is increasingly used in randomized trials due to its intuitive clinical interpretation, ability to incorporate the relative importance of composite endpoints, and its capacity for combining different types of outcomes (e.g. time-to-event, binary, counts, etc.) to be combined. There are open questions, however, about how to implement adaptive design approaches when the primary endpoint is a win ratio, including in group sequential designs. A key requirement allowing for straightforward application of classical group sequential methods is the independence of incremental interim test statistics. This paper derives the covariance structure of incremental U-statistics that evaluate the win ratio under its asymptotic distribution. The derived covariance shows that the independent increments assumption holds for the asymptotic distribution of U-statistics that test the win ratio. Simulations confirm that traditional $α$-spending preserves Type I error across interim looks. A retrospective look at the IN.PACT SFA clinical trial data illustrates the potential for stopping early in a group sequential design using the win ratio. We have demonstrated that straightforward use of Lan-De\uppercase{M}ets $α$-spending is possible for randomized trials involving the win ratio under certain common conditions. Thus, existing software capable of computing traditional group sequential boundaries can be employed.

</details>


### [3] [Propensity score weighted Cox regression for survival outcomes in observational studies with multiple or factorial treatments](https://arxiv.org/abs/2601.22572)
*Zixian Zhao,Chengxin Yang,Fan Li*

Main category: stat.ME

TL;DR: 本文提出了一种结合倾向得分加权与边际Cox模型的方法，用于估计多处理组间的因果风险比，并应用于评估三种抗肥胖药物对心力衰竭的比较有效性。


<details>
  <summary>Details</summary>
Motivation: 在具有生存或时间-事件结局的观察性研究中，通常仅有两个处理组的分析方法较为成熟，而针对多个处理组的情况分析方法有限，因此需要发展适用于多处理组的因果推断方法。

Method: 结合多处理组的倾向得分加权方法（包括逆概率处理加权和重叠加权）与包含各处理指标的边际Cox比例风险模型，估计多个处理组相对于一个共同参考处理组的因果边际风险比，并证明了最大加权部分似然估计量的一致性，提出了稳健的 Sandwich 方差估计方法。

Result: 所提方法能够有效估计多处理组之间的因果风险比，在抗肥胖药物对心力衰竭影响的实际数据分析中表现出良好性能，并开发了相应的R软件包'PSsurvival'。

Conclusion: 该方法扩展了倾向得分加权在多处理组生存分析中的应用，为观察性研究中多治疗方案的比较提供了可靠的统计工具。

Abstract: In observational studies with survival or time-to-event outcomes, a propensity score weighted marginal Cox proportional hazard model with the treatment variable as the only predictor is commonly used to estimate the causal marginal hazard ratio between two treatments. Observational studies often have more than two treatments, but corresponding analysis methods are limited. In this paper, we combine the propensity score weighting method for multiple treatments and a marginal Cox model with indicators for each treatment to estimate the causal hazard ratios between multiple treatments and a common reference treatment. We illustrate two weighting schemes: inverse probability of treatment weighting and overlap weighting. We prove the consistency of the maximum weighted partial likelihood estimator of the causal marginal hazard ratio and derive a robust sandwich variance estimator. As an important special case of multiple treatments, we elaborate the Cox model for two-way factorial treatments. We apply the method to evaluate the real-world comparative effectiveness of three types of anti-obesity medications on heart failure. We develop an associated R package 'PSsurvival'.

</details>


### [4] [Quadratic robust methods for causal mediation analysis](https://arxiv.org/abs/2601.22592)
*Zhen Qi,Yuqian Zhang*

Main category: stat.ME

TL;DR: 本文提出了一种新的四重稳健（QR）框架，用于自然效应的无偏识别，并提出了支持机器学习方法的非参数QR估计器和高维设置下的模型四重稳健（MQR）估计器。


<details>
  <summary>Details</summary>
Motivation: 现有的三重稳健框架在估计自然效应时存在局限性，需要扩展模型类别以提高无偏识别的能力。

Method: 采用非参数建模方法提出一般QR估计器，并在高维情况下使用参数建模策略开发MQR估计器。

Result: 通过模拟研究和实际数据应用验证了所提方法在有限样本下的良好表现。

Conclusion: 新提出的QR和MQR框架能够有效提升自然效应估计的鲁棒性和准确性。

Abstract: Estimating natural effects is a core task in causal mediation analysis. Existing triply robust (TR) frameworks (Tchetgen Tchetgen & Shpitser 2012) and their extensions have been developed to estimate the natural effects. In this work, we introduce a new quadruply robust (QR) framework that enlarges the model class for unbiased identification. We study two modeling strategies. The first is a nonparametric modeling approach, under which we propose a general QR estimator that supports the use of machine learning methods for nuisance estimation. We also study high-dimensional settings, where the dimensions of covariates and mediators may both be large. In these settings, we adopt a parametric modeling strategy and develop a model quadruply robust (MQR) estimator to limit the impact of model misspecification. Simulation studies and a real data application demonstrate the finite-sample performance of the proposed methods.

</details>


### [5] [Policy learning under constraint: Maximizing a primary outcome while controlling an adverse event](https://arxiv.org/abs/2601.22717)
*Laura Fuentes-Vicente,Mathieu Even,Gaelle Dormion,Julie Josse,Antoine Chambaz*

Main category: stat.ME

TL;DR: PLUC是一种在观察性设置中通过优化强凸拉格朗日准则来学习条件平均处理效应（CATE）估计器的方法，旨在控制不良事件发生概率的同时实现个体化治疗推荐。


<details>
  <summary>Details</summary>
Motivation: 标准的个体化治疗策略通常只优化单一结果指标，例如基于CATE符号制定政策，但在多结局场景下忽视了不良事件的风险。PLUC旨在解决这一问题，兼顾疗效与安全性。

Method: PLUC受EP-learning启发，通过对凸函数空间上的强凸拉格朗日准则进行优化，并采用交替算法：使用Frank-Wolfe算法迭代最小化当前准则，并通过目标更新步骤使准则在已访问点处逼近理论量的估计值。

Result: PLUC能够生成平滑的治疗策略，在控制不良事件发生概率方面表现良好，并通过一系列数值实验验证了其性能。此外，提供了R语言包PLUC-R以支持实际应用。

Conclusion: PLUC为多结局环境下的个体化政策学习提供了一种有效且稳健的方法，能够在保证治疗效果的同时控制临床风险，具有实际应用价值。

Abstract: A medical policy aims to support decision-making by mapping patient characteristics to individualized treatment recommendations. Standard approaches typically optimize a single outcome criterion. For example, recommending treatment according to the sign of the Conditional Average Treatment Effect (CATE) maximizes the policy "value" by exploiting treatment effect heterogeneity. This point of view shifts policy learning towards the challenge of learning a reliable CATE estimator. However, in multi-outcome settings, such strategies ignore the risk of adverse events, despite their relevance. PLUC (Policy Learning Under Constraint) addresses this challenges by learning an estimator of the CATE that yields smoothed policies controlling the probability of an adverse event in observational settings. Inspired by insights from EP-learning, PLUC involves the optimization of strongly convex Lagrangian criteria over a convex hull of functions. Its alternating procedure iteratively applies the Frank-Wolfe algorithm to minimize the current criterion, then performs a targeting step that updates the criterion so that its evaluations at previously visited landmarks become targeted estimators of the corresponding theoretical quantities. An R package PLUC-R provides a practical implementation. We illustrate PLUC's performance through a series of numerical experiments.

</details>


### [6] [Optimal Sample Splitting for Observational Studies](https://arxiv.org/abs/2601.22782)
*Qishuo Yin,Dylan S. Small*

Main category: stat.ME

TL;DR: 提出一种基于plasmode数据集的方法来确定观察性研究中规划样本与分析样本的最优分配比例，以减少未测量混杂偏倚的敏感性，并在高维结果空间中表现良好。


<details>
  <summary>Details</summary>
Motivation: 观察性研究中的估计可能因未测量混扰因素而产生偏倚，影响结果有效性；现有方法对规划样本和分析样本的划分比例缺乏理论依据，需优化设计以降低偏倚敏感性。

Method: 利用plasmode数据集构建模拟环境，评估不同样本分配比例下的偏倚敏感性，进而确定最优分配比例，并通过高维结果空间的应用验证其性能。

Result: 所提方法能有效识别最优样本分配比例，在高维环境下表现稳健；应用于儿童二手烟暴露效应研究时，提高了结果的可信度。

Conclusion: 该方法为观察性研究的设计提供了数据驱动的样本分配策略，有助于增强研究对未测量混杂偏倚的鲁棒性，提升因果推断的可靠性。

Abstract: In observational studies of treatment effects, estimates may be biased by unmeasured confounders, which can potentially affect the validity of the results. Understanding sensitivity to such biases helps assess how unmeasured confounding impacts credibility. The design of an observational study strongly influences its sensitivity to bias. Previous work has shown that the sensitivity to bias can be reduced by dividing a dataset into a planning sample and a larger analysis sample, where the planning sample guides design decisions. But the choice of what fraction of the data to put in the planning sample vs. the analysis sample was ad hoc. Here, we develop an approach to find the optimal fraction using plasmode datasets. We show that our method works well in high-dimensional outcome spaces. We apply our method to study the effects of exposure to second-hand smoke in children. The OptimalSampling R package implementing our method is available at GitHub.

</details>


### [7] [Depth-based estimation for multivariate functional data with phase variability](https://arxiv.org/abs/2601.22884)
*Ana Arribas-Gil,Sara López-Pintado*

Main category: stat.ME

TL;DR: 提出了一种基于深度的稳健方法，用于在具有个体相位变异和跨成分时间扭曲的多元函数数据中估计主模式函数。


<details>
  <summary>Details</summary>
Motivation: 在多元函数数据中，由于个体相位变异和跨成分时间扭曲的存在，难以准确估计共同的模板函数，因此需要一种稳健且一致的估计方法。

Method: 基于潜变形模型，讨论深度函数需满足的条件，以实现对中心模式的一致估计，并通过模拟评估方法在异常观测和模型假设违反情况下的表现。

Result: 该方法在模拟中表现出良好的性能和鲁棒性，并在两个真实数据集中得到验证。

Conclusion: 所提出的深度函数条件能够支持对主模式函数的稳健一致估计，适用于存在复杂时间扭曲的多元函数数据分析。

Abstract: In the context of multivariate functional data with individual phase variation, we develop a robust depth-based approach to estimate the main pattern function when cross-component time warping is also present. In particular, we consider the latent deformation model (Carroll and Müller, 2023) in which the different components of a multivariate functional variable are also time-distorted versions of a common template function. Rather than focusing on a particular functional depth measure, we discuss the necessary conditions on a depth function to be able to provide a consistent estimation of the central pattern, considering different model assumptions. We evaluate the method performance and its robustness against atypical observations and violations of the model assumptions through simulations, and illustrate its use on two real data sets.

</details>


### [8] [Dynamic modelling and evaluation of preclinical trials in acute leukaemia](https://arxiv.org/abs/2601.22971)
*Julian Wäsche,Romina Ludwig,Irmela Jeremias,Christiane Fuchs*

Main category: stat.ME

TL;DR: 本研究利用指数和逻辑增长模型分析急性白血病PDX模型中基因敲除的效应，相较于传统统计方法，能更可靠地识别细胞动态变化。


<details>
  <summary>Details</summary>
Motivation: 现有实验数据常使用仅比较两个时间点的统计检验进行分析，忽略了生物机制的动态过程和全部时间点的信息，限制了对基因修饰效应的理解。

Method: 采用指数增长和逻辑增长两种群体生长模型，整合所有时间点的数据，通过估计模型参数来推断基因修饰对细胞生长的影响，并在模拟和实际PDX数据中与传统统计方法对比。

Result: 指数增长模型在识别模拟场景中的生长抑制效应方面优于逻辑模型和传统统计方法；应用于实际PDX实验时，该模型能有效评估候选基因敲除的疗效。

Conclusion: 基于动态数学模型（特别是指数增长模型）的分析方法比传统两时间点统计检验更具敏感性和生物学解释力，有助于更全面理解基因修饰对白血病细胞生长的影响。

Abstract: Dynamic models are widely used to mathematically describe biological phenomena that evolve over time. One important area of application is leukaemia research, where leukaemia cells are genetically modified in preclinical studies to explore new therapeutic targets for reducing leukaemic burden. In advanced experiments, these studies are often conducted in mice and generate time-resolved data, the analysis of which may reveal growth-inhibiting effects of the investigated gene modifications. However, the experimental data is often times evaluated using statistical tests which compare measurements from only two different time points. This approach does not only reduce the time series to two instances but also neglects biological knowledge about cell mechanisms. Such knowledge, translated into mathematical models, expands the power to investigate and understand effects of modifications on underlying mechanisms based on experimental data. We utilise two population growth models -- an exponential and a logistic growth model -- to capture cell dynamics over the whole experimental time horizon and to consider all measurement times jointly. This approach enables us to derive modification effects from estimated model parameters. We demonstrate that the exponential growth model recognises simulated scenarios more reliably than the other candidate model and than a statistical test. Moreover, we apply the population growth models to evaluate the efficacy of candidate gene knockouts in patient-derived xenograft (PDX) models of acute leukaemia.

</details>


### [9] [Computationally efficient segmentation for non-stationary time series with oscillatory patterns](https://arxiv.org/abs/2601.22999)
*Nicolas Bianco,Lorenzo Cappello*

Main category: stat.ME

TL;DR: 提出了一种用于检测多变量非平稳时间序列中变点并学习参数的新方法，该方法通过傅里叶基函数将复杂问题转化为线性模型，避免了传统MCMC算法，具有更快的计算速度和理论误差界。


<details>
  <summary>Details</summary>
Motivation: 现有变点检测方法在处理具有振荡行为的非平稳时间序列时依赖复杂的跨维MCMC算法，计算成本高且实现困难，因此需要一种更高效、易实现的替代方案。

Method: 将时间序列建模为分段正弦函数之和，离散化参数空间后转化为基于傅里叶基函数的线性模型，从而可应用标准变点检测算法进行分割与推断。

Result: 在模拟数据上验证了该方法显著快于现有方法且保持相当的精度，并给出了变点定位误差的高概率理论界；在气候和脑电睡眠数据上的应用展示了其实用性。

Conclusion: 所提方法通过傅里叶基近似有效简化了振荡型非平稳时间序列的变点检测与参数学习，兼具计算效率与理论保证，适用于实际应用场景。

Abstract: We propose a novel approach for change-point detection and parameter learning in multivariate non-stationary time series exhibiting oscillatory behaviour. We approximate the process through a piecewise function defined by a sum of sinusoidal functions with unknown frequencies and amplitudes plus noise. The inference for this model is non-trivial. However, discretising the parameter space allows us to recast this complex estimation problem into a more tractable linear model, where the covariates are Fourier basis functions. Then, any change-point detection algorithms for segmentation can be used. The advantage of our proposal is that it bypasses the need for trans-dimensional Markov chain Monte Carlo algorithms used by state-of-the-art methods. Through simulations, we demonstrate that our method is significantly faster than existing approaches while maintaining comparable numerical accuracy. We also provide high probability bounds on the change-point localization error. We apply our methodology to climate and EEG sleep data.

</details>


### [10] [Differences in Performance of Bayesian Dynamic Borrowing and Synthetic Control Methods: A Case Study of Pediatric Atopic Dermatitis](https://arxiv.org/abs/2601.23021)
*Nicole Cizauskas,Foteini Strimenopoulou,Svetlana S. Cherlin,James M. S. Wason*

Main category: stat.ME

TL;DR: 本研究比较了贝叶斯动态借用（BDB）和合成控制方法（SCM）在儿童特应性皮炎临床试验中的统计效能，结果显示SCM具有更高的检验效能且I类错误率相似。


<details>
  <summary>Details</summary>
Motivation: 由于BDB和SCM在应用、产品和评估指标上的差异，此前未进行直接比较，本研究旨在填补这一空白。

Method: 基于六项历史随机对照试验数据，使用RBesT包构建MAP先验用于BDB，使用Synthpop包构建SCM的合成对照组，并比较两者的检验功效和I类错误率。

Result: BDB的检验功效为0.580，I类错误率为0.026；SCM的检验功效为0.641，I类错误率为0.027。

Conclusion: 在该案例中，SCM比BDB具有更高的检验功效且保持相似的I类错误率，但方法选择应根据具体试验需求而定。

Abstract: Bayesian dynamic borrowing (BDB) and synthetic control methods (SCM) are both used in clinical trial design when recruitment, retention, or allocation is a challenge. The performance of these approaches has not previously been directly compared due to differences in application, product, and measurement metrics. This study aims to conduct a comparison of power and type 1 error rates of BDB (using meta-analytic predictive prior (MAP)) and SCM using a case study of Pediatric Atopic Dermatitis. Six historical randomised control trials were selected for use in both the creation of the MAP prior and synthetic control arm. The R library RBesT was used to create a MAP prior and the R library Synthpop was used to create a synthetic control arm for the SCM. Power and type 1 error rate were used as comparison metrics. BDB produced a power of 0.580 and a type 1 error rate of 0.026. SCM produced a power of 0.641 and a type 1 error rate of 0.027. In this case study, the SCM model produced a higher power than the BDB method with a similar type 1 error rate. However, the decision to use SCM or BDB should come from the specific needs of the potential trial, since their power and type 1 error rate may differ on a case-by-case basis.

</details>


### [11] [Robust, partially alive particle Metropolis-Hastings via the Frankenfilter](https://arxiv.org/abs/2601.23173)
*Chris Sherlock,Andrew Golightly,Anthony Lee*

Main category: stat.ME

TL;DR: 本文提出了一种名为Frankenfilter的新型部分存活粒子滤波器，用于解决隐马尔可夫模型中观测似然为零导致的标准粒子滤波失效问题。该方法在固定模拟次数上下界的同时，确保用户定义的成功数量，并提供无偏似然估计，适用于伪边际Metropolis-Hastings算法，显著提高对异常值和参数误设的鲁棒性及计算效率。


<details>
  <summary>Details</summary>
Motivation: 标准粒子滤波在观测似然可能为零时会出现所有粒子权重为零的问题，导致滤波失败；尤其在存在离群点或参数初值不佳时，计算成本极高。需要一种更稳健且高效的替代方法。

Method: 提出Frankenfilter，通过设定用户定义的成功次数目标，在每段观测间隔内动态调整粒子模拟数量，同时设置模拟次数的上下界，实现部分存活机制，保证至少有一定数量的非零似然粒子，并生成无偏似然估计。

Result: Frankenfilter能够在标准粒子滤波失效的情况下仍稳定运行，PMMH结合Frankenfilter后对异常值和参数误设更具鲁棒性，通常比标准粒子滤波效率高2-3倍以上。对于n个精确观测，建议直接设定目标成功次数为n。

Conclusion: Frankenfilter是一种高效、稳健且易于使用的改进粒子滤波方法，解决了传统方法在零似然情况下的崩溃问题，适用于伪边际MCMC推断，具有实际应用价值。

Abstract: When a hidden Markov model permits the conditional likelihood of an observation given the hidden process to be zero, all particle simulations from one observation time to the next could produce zeros. If so, the filtering distribution cannot be estimated and the estimated parameter likelihood is zero. The alive particle filter addresses this by simulating a random number of particles for each inter-observation interval, stopping after a target number of non-zero conditional likelihoods. For outlying observations or poor parameter values, a non-zero result can be extremely unlikely, and computational costs prohibitive. We introduce the Frankenfilter, a principled, partially alive particle filter that targets a user-defined amount of success whilst fixing lower and upper bounds on the number of simulations. The Frankenfilter produces unbiased estimators of the likelihood, suitable for pseudo-marginal Metropolis--Hastings (PMMH). We demonstrate that PMMH with the Frankenfilter is more robust to outliers and mis-specified initial parameter values than PMMH using standard particle filters, and is typically at least 2-3 times more efficient. We also provide advice for choosing the amount of success. In the case of n exact observations, this is particularly simple: target n successes.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [12] [Practical Evaluation of Quantum Kernel Methods for Radar Micro-Doppler Classification on Noisy Intermediate-Scale Quantum (NISQ) Hardware](https://arxiv.org/abs/2601.22194)
*Vikas Agnihotri,Jasleen Kaur,Sarvagya Kaushik*

Main category: quant-ph

TL;DR: 本论文研究了基于量子支持向量机（QSVM）利用微多普勒特征进行雷达空中目标分类的方法，通过PCA降维后使用量子核方法在模拟器和真实量子硬件（IBM Torino和Fez）上实现分类，结果表明QSVM在低维特征下性能与经典SVM相当，并分析了噪声、测量次数及硬件架构对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探索量子机器学习在雷达信号分类中的应用潜力，评估当前NISQ设备上量子核方法的可行性与局限性。

Method: 提取经典微多普勒特征，采用PCA进行降维，利用ZZFeatureMap将数据映射到量子核空间，并基于QSVM进行分类，在模拟器和IBM超导量子处理器上进行验证。

Result: QSVM在显著降低特征维度的情况下达到与经典SVM相当的分类性能；在真实硬件上实验显示噪声、退相干和测量次数影响核估计精度，新型Heron r2架构表现出更优的稳定性和保真度。

Conclusion: 量子核方法在雷达目标分类中具备可行性，但在当前NISQ设备上仍受限于硬件噪声和资源限制，需进一步优化以提升实际应用能力。

Abstract: This paper examines the application of a Quantum Support Vector Machine (QSVM) for radarbased aerial target classification using micro-Doppler signatures. Classical features are extracted and reduced via Principal Component Analysis (PCA) to enable efficient quantum encoding. The reduced feature vectors are embedded into a quantum kernel-induced feature space using a fully entangled ZZFeatureMap and classified using a kernel based QSVM. Performance is first evaluated on a quantum simulator and subsequently validated on NISQ-era superconducting quantum hardware, specifically the IBM Torino (133-qubit) and IBM Fez (156-qubit) processors. Experimental results demonstrate that the QSVM achieves competitive classification performance relative to classical SVM baselines while operating on substantially reduced feature dimensionality. Hardware experiments reveal the impact of noise and decoherence and measurement shot count on quantum kernel estimation, and further show improved stability and fidelity on newer Heron r2 architecture. This study provides a systematic comparison between simulator-based and hardware-based QSVM implementations and highlights both the feasibility and current limitations of deploying quantum kernel methods for practical radar signal classification tasks.

</details>


### [13] [Probing Entanglement and Symmetries in Random States Using a Superconducting Quantum Processor](https://arxiv.org/abs/2601.22224)
*Jia-Nan Yang,Lata Kh Joshi,Filiberto Ares,Yihang Han,Pengfei Zhang,Pasquale Calabrese*

Main category: quant-ph

TL;DR: 实验研究了通过遍历性Floquet模型演化产生的随机多体量子态的纠缠和对称性，结果与Haar随机态系综的预测高度一致。


<details>
  <summary>Details</summary>
Motivation: 多体量子系统虽然复杂，但其许多特性具有普适性。目标是区分这些普适特征与模型细节，利用随机量子态揭示典型行为。

Method: 通过将简单的积态在遍历性Floquet模型下演化，实验生成随机多体量子态，并测量其纠缠熵、子系统对称性和部分转置约化密度矩阵的矩。

Result: 1. 测量了Rényi-2纠缠熵随子系统大小的变化，观察到Page曲线；2. 使用纠缠不对称性探测子系统对称性；3. 测量部分转置约化密度矩阵的矩，揭示了不同的纠缠相。

Conclusion: 实验结果验证了Haar随机态系综对多体量子系统典型纠缠和对称性的预测，提供了理解普遍量子特性的实验视角。

Abstract: Quantum many-body systems display an extraordinary degree of complexity, yet many of their features are universal: they depend not on microscopic details, but on a few fundamental physical aspects such as symmetries. A central challenge is to distill these universal characteristics from model-specific ones. Random quantum states sampled from a uniform distribution, the Haar measure, provide a powerful framework for capturing this typicality. Here, we experimentally study the entanglement and symmetries of random many-body quantum states generated by evolving simple product states under ergodic Floquet models. We find excellent agreement with the predictions from the Haar-random state ensemble. First, we measure the Rényi-2 entanglement entropy as a function of the subsystem size, observing the Page curve. Second, we probe the subsystem symmetries using entanglement asymmetry. Finally, we measure the moments of partially transposed reduced density matrices obtained by tracing out part of the system in the generated ensembles, thereby revealing distinct entanglement phases. Our results offer an experimental perspective on the typical entanglement and symmetries of many-body quantum systems.

</details>


### [14] [The Photonic Foundation of Temperature: Mechanisms of Thermal Equilibrium and Entropy Production](https://arxiv.org/abs/2601.22247)
*David Vaknin*

Main category: quant-ph

TL;DR: 本文通过量子电动力学机制，提出光子是建立和维持物质热平衡与温度特征能量尺度的基本媒介，从微观层面为经典热力学提供了物理基础。


<details>
  <summary>Details</summary>
Motivation: 探讨温度与热平衡的物理本质，弥补经典热力学在微观机制上的缺失。

Method: 基于最小微分标度假设推导玻尔兹曼分布，分析光子交换与非弹性散射在热平衡中的作用。

Result: 发现维持热平衡需要平均能量为2.701倍特征能量的光子持续交换，熵产生源于高能光子转化为多个低能光子的过程。

Conclusion: 温度是光子介导能量交换的涌现性集体属性，热平衡依赖于动态光子浴的维持，经典热库概念是一种有效近似。

Abstract: I examine the physical foundations of temperature and thermal equilibrium by identifying photons as the fundamental agents that establish and maintain the characteristic energy scale $E_c = k_B T$ in ordinary matter. While classical thermodynamics successfully describes equilibrium phenomenologically, the realization of thermal distributions requires concrete microscopic mechanisms provided by quantum electrodynamics. We derive the Boltzmann distribution from a minimal differential scaling postulate and show that sustaining thermal equilibrium demands continuous photon exchange with average energy $\langle hν\rangle = 2.701\,E_c$, quantifying the energetic throughput necessary to counter radiative losses. Entropy production is shown to arise naturally from inelastic photon scattering that converts high-energy photons into many lower-energy quanta, thereby increasing accessible microstates and driving irreversible evolution toward equilibrium. We establish physical criteria distinguishing genuine thermal equilibrium from purely formal temperature assignments and demonstrate that the classical notion of an infinite thermal reservoir emerges as an effective idealization within a hierarchy of dynamically maintained photon baths. This photonic framework complements phenomenological thermodynamics by providing its microscopic foundation and clarifies the physical meaning of temperature as an emergent collective property of photon-mediated energy exchange.

</details>


### [15] [Entanglement and discord classification via deep learning](https://arxiv.org/abs/2601.22253)
*Katherine Muñoz-Mellado,Daniel Uzcátegui-Contreras,Antonio Guerra,Aldo Delgado,Dardo Goyeneche*

Main category: quant-ph

TL;DR: 提出一种基于深度学习的卷积自编码器方法，用于量子纠缠与量子判据的分类，能够在不同维度系统中高效区分纠缠态与可分态，并生成难以构造的束缚纠缠态样本。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠和量子判据的识别在理论和实验上具有挑战性，尤其是束缚纠缠态的构造极为困难，需要高效且自动化的分类方法。

Method: 采用卷积自编码器架构，通过训练模型对d×d系统的纠缠态与可分态进行分类，并用于检测量子判据的存在。利用学习到的表示生成束缚纠缠态样本。

Result: 模型在多种量子态家族上实现了高分类精度，能有效识别自由和束缚纠缠，并可生成束缚纠缠态；同时在量子判据检测任务中表现出高准确率且训练时间更短。

Conclusion: 该方法为量子纠缠与量子判据的自动识别提供了有效的数据驱动框架，尤其在生成和研究束缚纠缠态方面展现出潜力。

Abstract: In this work, we propose a deep learning-based approach for quantum entanglement and discord classification using convolutional autoencoders. We train models to distinguish entangled from separable bipartite states for $d \times d$ systems with local dimension $d$ ranging from two to seven, which enables identification of bound and free entanglement. Through extensive numerical simulations across various quantum state families, we demonstrate that our model achieves high classification accuracy. Furthermore, we leverage the learned representations to generate samples of bound entangled states, the rarest form of entanglement and notoriously difficult to construct analytically. We separately train the same convolutional autoencoders architecture for detecting the presence of quantum discord and show that the model also exhibits high accuracy while requiring significantly less training time.

</details>


### [16] [Some properties of coherent states with singular complex matrix argument](https://arxiv.org/abs/2601.22258)
*Dušan Popov*

Main category: quant-ph

TL;DR: 本文研究了一种新的相干态，其参数是两个特殊奇异方阵的线性组合，并探讨了其与量子比特和冯·诺依曼熵的关系。


<details>
  <summary>Details</summary>
Motivation: 旨在探索一种新型相干态的性质，该相干态基于特殊的2x2奇异矩阵和复变量系数。

Method: 通过理论推导验证这种新相干态满足纯态和混合态（热态）的所有条件，并分析其与qubit及von Neumann熵的关联。

Result: 证明了该相干态满足所有相干态的基本条件，并成功应用于qubit和冯·诺依曼熵的研究中。

Conclusion: 所提出的相干态框架有效且具备应用潜力，特别是在量子信息理论中的熵和量子态表示方面。

Abstract: In the paper our aim was to study the properties of a new version of coherent states whose argument is a linear combination of two special singular square 2 x 2 matrix, having a single nonzero element, equal to 1, and two labeling complex variables as developing coefficients. We have shown that this new version of coherent states satisfies all the conditions imposed on coherent states, both of pure, as well as the mixed (thermal) states characterized by the density operator. As applications, we examined the connection between these coherent states and the notions of qubits and von Neuman entropy.

</details>


### [17] [Compact U(1) Lattice Gauge Theory in Superconducting Circuits with Infinite-Dimensional Local Hilbert Spaces](https://arxiv.org/abs/2601.23150)
*J. M. Alcaine-Cuervo,S. Pradhan,E. Rico,Z. Shi,C. M. Wilson*

Main category: quant-ph

TL;DR: 提出了一种基于超导电路的紧凑型U(1)格点规范理论架构，利用相位和电荷变量的无限维希尔伯特空间直接编码规范和物质场，无需辅助稳定器或惩罚项即可自然涌现高斯定律。


<details>
  <summary>Details</summary>
Motivation: 旨在实现非微扰规范动力学的模拟，克服传统方法中需要辅助手段强制满足规范对称性的局限。

Method: 利用超导电路中的转子变量自由度编码规范与物质场，通过约瑟夫森非线性实现微观的规范-物质耦合，并通过虚物质激发微扰生成磁通量相互作用。

Result: 数值对角化证实了紧凑电动力学和相干涡旋激发的出现，表明在连续极限下需要大的局部希尔伯特空间。

Conclusion: 超导电路可作为可扩展的连续变量平台，用于模拟非微扰规范动力学，且当前实验条件可达。

Abstract: We propose a superconducting-circuit architecture that realizes a compact U(1) lattice gauge theory using the intrinsic infinite-dimensional Hilbert space of phase and charge variables. The gauge and matter fields are encoded directly in the degrees of freedom of the rotor variables associated with the circuit nodes, and Gauss's law emerges exactly from the conservation of local charge, without auxiliary stabilizers, penalty terms, or Hilbert-space truncation. A minimal gauge-matter coupling arises microscopically from Josephson nonlinearities, whereas the magnetic plaquette interaction is generated perturbatively via virtual matter excitations. Numerical diagonalization confirms the emergence of compact electrodynamics and coherent vortex excitations, underscoring the need for large local Hilbert spaces in the continuum regime. The required circuit parameters are within the current experimental capabilities. Our results establish superconducting circuits as a scalable, continuous-variable platform for analog quantum simulation of non-perturbative gauge dynamics.

</details>


### [18] [Three-dimensional squeezing of optically levitated nanospheres](https://arxiv.org/abs/2601.22283)
*Giacomo Marocco,David C. Moore,Daniel Carney*

Main category: quant-ph

TL;DR: 提出了一种通过压缩机械系统状态来突破标准量子极限测量冲量的协议，利用光学悬浮的介电纳米粒子系统中的频率跳变实现三维噪声抑制，并预测当前技术可实现约10 dB的压缩，提升弱冲量的量子增强探测能力。


<details>
  <summary>Details</summary>
Motivation: 为了突破标准量子极限，实现对弱冲量的高灵敏度探测，需要克服量子噪声的限制。

Method: 通过在谐波势能中引入一系列频率跳变，对机械系统的量子态进行压缩，从而在三个空间维度上降低噪声。

Result: 在考虑现实系统中退相干效应的情况下，量化了该协议的灵敏度极限，并预测当前技术条件下可实现约10 dB的压缩效果。

Conclusion: 该协议有望利用现有技术实现量子增强的弱冲量检测，为高精度力学测量提供了可行路径。

Abstract: We propose a protocol to measure impulses beyond the standard quantum limit. The protocol reduces noise in all three spatial dimensions and consists of squeezing a mechanical system's state via a series of jumps in the frequency of the harmonic potential. We quantify how decoherence in a realistic system of an optically levitated, dielectric nanoparticle limits the ultimate sensitivity. We predict that $\sim$10 dB of squeezing is achievable with current technology, enabling quantum-enhanced detection of weak impulses.

</details>


### [19] [Efficient learning of logical noise from syndrome data](https://arxiv.org/abs/2601.22286)
*Han Zheng,Chia-Tung Chu,Senrui Chen,Argyris Giannisis Manes,Su-un Lee,Sisi Zhou,Liang Jiang*

Main category: quant-ph

TL;DR: 本文提出了一种基于综合征数据推断量子电路中逻辑通道的方法，适用于实际的电路级噪声模型，显著降低了表征容错量子设备所需样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 由于容错纠错电路中的逻辑错误概率被抑制到高阶，直接通过逻辑测量进行校准非常困难，因此需要一种更高效的方式来表征逻辑通道。

Method: 从统一的编码理论视角和时空编码形式出发，推导出仅从综合征数据学习逻辑通道的充要条件，并利用傅里叶分析和压缩感知开发了具有可证明保证的高效估计器。

Result: 明确刻画了电路级Pauli故障中可学习的自由度，提出了端到端协议并在多个综合征提取电路上演示了性能，相比直接逻辑基准测试实现了数量级上的样本复杂度节约。

Conclusion: 综合征数据可用于高效且实用地表征容错量子设备中的逻辑通道，为设备校准提供了新途径。

Abstract: Characterizing errors in quantum circuits is essential for device calibration, yet detecting rare error events requires a large number of samples. This challenge is particularly severe in calibrating fault-tolerant, error-corrected circuits, where logical error probabilities are suppressed to higher order relative to physical noise and are therefore difficult to calibrate through direct logical measurements. Recently, Wagner et al. [PRL 130, 200601 (2023)] showed that, for phenomenological Pauli noise models, the logical channel can instead be inferred from syndrome measurement data generated during error correction. Here, we extend this framework to realistic circuit-level noise models. From a unified code-theoretic perspective and spacetime code formalism, we derive necessary and sufficient conditions for learning the logical channel from syndrome data alone and explicitly characterize the learnable degrees of freedom of circuit-level Pauli faults. Using Fourier analysis and compressed sensing, we develop efficient estimators with provable guarantees on sample complexity and computational cost. We further present an end-to-end protocol and demonstrate its performance on several syndrome-extraction circuits, achieving orders-of-magnitude sample-complexity savings over direct logical benchmarking. Our results establish syndrome-based learning as a practical approach to characterizing the logical channel in fault-tolerant quantum devices.

</details>


### [20] [Local-oscillator-agnostic squeezing detection](https://arxiv.org/abs/2601.22291)
*Suchitra Krishnaswamy,Dhrithi Maria,Laura Ares,Lorenzo M. Procopio,Tim J. Bartley,Jan Sperling*

Main category: quant-ph

TL;DR: 提出了一种基于部分正规排序的无参考非经典性检测框架，适用于缺乏相干激光参考的光子系统量子特性评估。


<details>
  <summary>Details</summary>
Motivation: 在无法获得已知参考信号的情况下，传统方法难以有效测量连续变量玻色系统的非经典性，因此需要发展不依赖于参考态的新型判据。

Method: 基于部分正规排序的概念构建了新的非经典性判据，并将其应用于使用任意（可能为非经典）本地振荡器的平衡零差探测中，仅揭示被测信号的量子特性。

Result: 所提出的框架相比标准技术展现出更强的鲁棒性和更高的灵敏度，能够在无相干激光参考时有效识别量子现象。

Conclusion: 该方法提供了一个广泛适用的、适合量子计量和量子信息应用的非经典性检测框架。

Abstract: We address the problem of measuring nonclassicality in continuous-variable bosonic systems without having access to a known reference signal. To this end, we construct broader classes of criteria for nonclassicality which allow us to investigate quantum phenomena regardless of the quantumness of selected subsystems. Such witnesses are based on the notion of partial normal ordering. This approach is applied to balanced homodyne detection using arbitrary, potentially nonclassical local oscillator states, yet only revealing the probed signal's quantumness. Our framework is compared to standard techniques, and the robustness and advanced sensitivity of our approach is shown. Therefore, a widely applicable framework, well-suited for applications in quantum metrology and quantum information, is derived to assess the quantum features of a photonic system when a well-defined coherent laser as a reference state is not available in the physical domain under study.

</details>


### [21] [Quantum bootstrap product codes](https://arxiv.org/abs/2601.22363)
*Meng-Yuan Li*

Main category: quant-ph

TL;DR: 本文提出了量子自举积（QBP），通过求解“自举方程”来构造量子CSS码，统一了多种重要编码（如高维超图积码和分形子码），并引入了“叉复形”结构，揭示了分形子码的拓扑本质。QBP框架还能生成具有自纠错能力的量子码，并突破传统HGP码的码率上限。


<details>
  <summary>Details</summary>
Motivation: 现有基于同调代数的量子码积构造方法难以统一描述分形子码等新型编码，限制了对更优量子纠错码的探索。作者旨在建立一个超越标准同调范式的新型积框架，以更好地理解与设计量子纠错码。

Method: 提出量子自举积（QBP）方法，通过求解称为“自举方程”的一致性条件来构造链复形；引入新的代数结构——叉复形，用于描述QBP生成的多组分链群与边界映射。

Result: QBP成功统一了高维超图积码和X-cube等分形子码；揭示了分形子码的拓扑结构，类似于层化分形序理论；生成的码可具备自纠错能力，并能突破HGP码的码率上界。

Conclusion: QBP提供了一个比传统同调方法更广泛、更灵活的量子码构造框架，拓展了量子积码的研究范围，为构建容错量子存储器提供了新途径。

Abstract: Product constructions constitute a powerful method for generating quantum CSS codes, yielding celebrated examples such as toric codes and asymptotically good low-density parity check (LDPC) codes. Since a CSS code is fully described by a chain complex, existing product formalisms are predominantly homological, defined via the tensor product of the underlying chain complexes of input codes, thereby establishing a natural connection between quantum codes and topology. In this Letter, we introduce the \textit{quantum bootstrap product} (QBP), an approach that extends beyond this standard homological paradigm. Specifically, a QBP code is determined by solving a consistency condition termed the ``bootstrap equation''. We find that the QBP paradigm unifies a wide range of important codes, including general hypergraph product (HGP) codes of arbitrary dimensions and fracton codes typically represented by the X-cube code. Crucially, the solutions to the bootstrap equation yield chain complexes where the chain groups and associated boundary maps consist of multiple components. We term such structures \textit{fork complexes}. This structure elucidates the underlying topological structures of fracton codes, akin to foliated fracton order theories. Beyond conceptual insights, we demonstrate that the QBP paradigm can generate self-correcting quantum codes from input codes with constant energy barriers and surpass the code-rate upper bounds inherent to HGP codes. Our work thus substantially extends the scope of quantum product codes and provides a versatile framework for designing fault-tolerant quantum memories.

</details>


### [22] [Manjushri: A Tool for Equivalence Checking of Quantum Circuits](https://arxiv.org/abs/2601.22372)
*Xuan Du Trinh,Meghana Sistla,Nengkun Yu,Thomas Reps*

Main category: quant-ph

TL;DR: 提出了一种名为Manjushri的新框架，用于可扩展的量子电路等价性验证，使用局部投影和加权二叉决策图实现高效、紧凑的符号表示，在深度不超过38时性能优于ECMC。


<details>
  <summary>Details</summary>
Motivation: 量子程序编译与优化中，验证两个量子电路是否等价是一个核心挑战，现有方法在大规模或深层电路中存在效率或可扩展性问题。

Method: 利用局部投影作为区分性电路指纹，并通过加权二叉决策图（WBDD）进行符号化表示，构建自动化等价性验证框架Manjushri。

Result: 在随机1D Clifford+T电路上实验表明，深度达30时Manjushri比ECMC快约8-10倍；等价情况下在32和64量子比特上成功率接近一致至深度38，之后逐渐下降至50层时75%；128量子比特等价电路在48层时失败率升至100%。ECMC在32和64量子比特上至深度50表现优异，但在128量子比特某些深度遇到困难。

Conclusion: Manjushri是大规模量子电路验证的实用且可扩展的解决方案，在电路深度不超过38时是优选方案。

Abstract: Verifying whether two quantum circuits are equivalent is a central challenge in the compilation and optimization of quantum programs. We introduce \textsc{Manjushri}, a new automated framework for scalable quantum-circuit equivalence checking. \textsc{Manjushri} uses local projections as discriminative circuit fingerprints, implemented with weighted binary decision diagrams (WBDDs), yielding a compact and efficient symbolic representation of quantum behavior. We present an extensive experimental evaluation that, for random 1D Clifford+$T$ circuits, explores the trade-off between \textsc{Manjushri} and \textsc{ECMC}, a tool for equivalence checking based on a much different approach. \textsc{Manjushri} is much faster up to depth 30 (with the crossover point varying from 39--49, depending on the number of qubits and whether the input circuits are equivalent or inequivalent): when inputs are equivalent, \textsc{Manjushri} is about 10$\times$ faster (or more); when inputs are inequivalent, \textsc{Manjushri} is about 8$\times$ faster (or more). For both kinds of equivalence-checking outcomes, \textsc{ECMC}'s success rate out to depth 50 is impressive on 32- and 64-qubit circuits: on such circuits, \textsc{ECMC} is almost uniformly successful. However, \textsc{ECMC} struggled on 128-qubit circuits for some depths. \textsc{Manjushri} is almost uniformly successful out to about depth 38, before tailing off to about 75\% at depth 50 (falling to 0\% at depth 48 for 128-qubit circuits that are equivalent). These results establish that \textsc{Manjushri} is a practical and scalable solution for large-scale quantum-circuit verification, and would be the preferred choice unless clients need to check equivalence of circuits of depth $>$38.

</details>


### [23] [On the undecidability of quantum channel capacities](https://arxiv.org/abs/2601.22471)
*Archishna Bhattacharyya,Arthur Mehta,Yuming Zhao*

Main category: quant-ph

TL;DR: 本文探讨了计算量子信道容量的难度，证明了一般量子信道的量子容量是QMA难计算的，并且最大纠缠辅助零误差一次性经典容量是不可计算的。


<details>
  <summary>Details</summary>
Motivation: 区分经典信道与量子信道能力的一个重要问题是：是否存在一种算法可以计算（或高效计算）信道容量？尽管有大量证据表明量子信道容量可能是不可计算的，但尚未有正式证明。本文旨在启动对计算量子信道容量难度的研究。

Method: 通过理论分析和复杂性理论工具，证明一般量子信道的量子容量是QMA难计算的，并展示最大纠缠辅助零误差一次性经典容量的不可计算性。

Result: 证明了一般量子信道的量子容量是QMA难计算的；同时证明了最大纠缠辅助零误差一次性经典容量是不可计算的。

Conclusion: 计算量子信道容量在理论上具有极高的复杂性，部分容量指标本质上是不可计算的，这为理解量子通信极限提供了新的理论基础。

Abstract: An important distinction in our understanding of capacities of classical versus quantum channels is marked by the following question: is there an algorithm which can compute (or even efficiently compute) the capacity? While there is overwhelming evidence suggesting that quantum channel capacities may be uncomputable, a formal proof of any such statement is elusive. We initiate the study of the hardness of computing quantum channel capacities. We show that, for a general quantum channel, it is QMA-hard to compute its quantum capacity, and that the maximal-entanglement-assisted zero-error one-shot classical capacity is uncomputable.

</details>


### [24] [Dicke States for Accelerated Two Two-Level Atoms](https://arxiv.org/abs/2601.22479)
*Muzzamal I. Shaukat,Charles A. Wallace,Anatoly A. Svidzinsky,Marlan O. Scully*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We explore the formation of Dicke states. A system consisting of two two-level atoms located in the right Rindler wedge, has investigated to determine the conditions under which the superradiant or subradiant state can be formed. The dynamics of N two-level atoms forming symmetric state has also been analyzed and showed that the probability to excite any one atom of a collection of N atoms is related to the probability of exciting a single atom. We derive the analytical expression for the joint excitation probability which demonstrates the the interference effect. These findings provide new insights into the behavior of quantum systems in non-inertial frames and contribute to the broader understanding of relativistic quantum information theory.

</details>


### [25] [Structural Conditions for Native CCZ Magic-State Fountains in qLDPC Codes](https://arxiv.org/abs/2601.22489)
*Mohammad Rowshan*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum low-density parity-check (qLDPC) codes promise constant-rate, linear-distance families with bounded-weight checks, and recent work has realized transversal or constant-depth non-Clifford gates on various (often non-LDPC) codes. However, no explicit \emph{qubit} qLDPC family is known that simultaneously has constant rate, linear distance, bounded stabilizer weight, and a native \emph{magic-state fountain} that prepares many non-Clifford resource states in constant depth.
  We take a structural approach and identify coding-theoretic conditions under which a CSS qLDPC family necessarily supports a constant-depth $\CCZ$ magic-state fountain. The key ingredients are: (i) an algebraic notion of \emph{magic-friendly triples} of $X$-type logical operators, defined by pairwise orthogonality and a triple-overlap form controlling diagonal $\CCZ$ phases, and (ii) a 3-uniform hypergraph model of physical $\CCZ$ circuits combined with a packing lemma that turns large collections of such triples with bounded overlaps into bounded-degree hypergraphs.
  Our main theorem shows that if a CSS code family on $n$ qubits admits $Ω(n^{1+γ})$ magic-friendly triples whose supports have bounded per-qubit participation, then there exists a constant-depth circuit of physical $\CCZ$ gates implementing $Ω(n^γ)$ logical $\CCZ$ gates in parallel while preserving distance up to a constant factor. For asymptotically good qLDPC families such as quantum Tanner codes, this reduces the existence of a native $\CCZ$ magic-state fountain to a concrete combinatorial problem about counting and distributing magic-friendly triples in the logical $X$ space.

</details>


### [26] [Quantum-Enhanced Sensing Enabled by Scrambling-Induced Genuine Multipartite Entanglement](https://arxiv.org/abs/2601.22503)
*Guantian Hu,Wenxuan Zhang,Zhihua Chen,Liuzhu Zhong,Jingchao Zhao,Chilong Liu,Zixing Liu,Yue Xu,Yongchang Lin,Yougui Ri,Guixu Xie,Mingze Liu,Haolan Yuan,Yuxuan Zhou,Yu Zhang,Chang-Kang Hu,Song Liu,Dian Tan,Dapeng Yu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum sensing leverages quantum resources to surpass the standard quantum limit, yet many existing protocols rely on the preparation of complex entangled states and Hamiltonian engineering, posing challenges for universality and scalability. Here, we report an experimental realization of a universal protocol, known as Butterfly Metrology, proposed in [arXiv:2411.12794], demonstrating a scrambling-based approach for quantum-enhanced sensing on a superconducting quantum processor. By exploiting many-body information scrambling, we observe quantum-enhanced sensitivity to an encoded phase beyond the standard quantum limit, with a scaling consistent with a factor-of-two of the Heisenberg limit for system sizes of up to 10 qubits. Importantly, we experimentally establish a connection between the enhanced sensitivity and the dynamics of the out-of-time-order correlator (OTOC), and show that the buildup of scrambling-induced genuine multipartite entanglement underlies the observed sensitivity enhancement. Our results demonstrate a scalable and practical approach for quantum-enhanced sensing in interacting many-body quantum systems.

</details>


### [27] [Analysis of self-thermalization dynamics in the Bose-Hubbard model by using the pseudoclassical approach](https://arxiv.org/abs/2601.22553)
*Andrey R. Kolovsky*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze the self-thermalization dynamics of the $M$-site Bose-Hubbard model in terms of the single-particle density matrix that is calculated by using the pseudoclassical approach. It is shown that a weak inter-particle interaction, which suffices to convert the integrable system of non-interacting bosons into a chaotic system, has a negligible effect on the thermal density matrix given by the Bose-Einstein distribution. This opens the door for equilibration where the two coupled Bose-Hubbard systems, which are initially in different thermal states, relax to the same thermal state. When we couple these two subsystems by using a lattice of the length $L\ll M$, we numerically calculate the quasi-stationary current of Bose particles across the lattice and show that its magnitude is consistent with the solution of the master equation for the boundary driven $L$-site Bose-Hubbard model.

</details>


### [28] [Towards Sample Efficient Entanglement Classification for 3 and 4 Qubit Systems: A Tailored CNN-BiLSTM Approach](https://arxiv.org/abs/2601.22562)
*Qian Sun,Yuedong Sun,Yu Hu,Yihan Ma,Runqi Han,Nan Jiang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate classification of multipartite entanglement in high-dimensional quantum systems is crucial for advancing quantum communication and information processing. However, conventional methods are resource-intensive, and even many machine-learning-based approaches necessitate large training datasets, creating a significant experimental bottleneck for data acquisition. To address this challenge, we propose a hybrid neural network architecture integrating Convolutional and Bidirectional Long Short-Term Memory networks (CNN-BiLSTM). This design leverages CNNs for local feature extraction and BiLSTMs for sequential dependency modeling, enabling robust feature learning from minimal training data. We investigate two fusion paradigms: Architecture 1 (flattening-based) and Architecture 2 (dimensionality-transforming). When trained on only 100 samples, Architecture 2 maintains classification accuracies exceeding 90% for both 3-qubit and 4-qubit systems, demonstrating rapid loss convergence within tens of epochs. Under full-data conditions (400 000 samples), both architectures achieve accuracies above 99.97%. Comparative benchmarks reveal that our CNN-BiLSTM models, especially Architecture 2, consistently outperform standalone CNNs, BiLSTMs, and MLPs in low-data regimes, albeit with increased training time. These results demonstrates that the tailored CNN-BiLSTM fusion significantly alleviates experimental data acquisition burden, offering a practical pathway toward scalable entanglement verification in complex quantum systems.

</details>


### [29] [Two-parameter bipartite entanglement measure](https://arxiv.org/abs/2601.22568)
*Chen-Ming Bai,Yu Luo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Entanglement concurrence is an important bipartite entanglement measure that has found wide applications in quantum technologies. In this work, inspired by unified entropy, we introduce a two-parameter family of entanglement measures, referred to as the unified $(q,s)$-concurrence. Both the standard entanglement concurrence and the recently proposed $q$-concurrence emerge as special cases within this family. By combining the positive partial transposition and realignment criteria, we derive an analytical lower bound for this measure for arbitrary bipartite mixed states, revealing a connection to strong separability criteria. Explicit expressions are obtained for the unified $(q,s)$-concurrence in the cases of isotropic and Werner states under the constraint $q>1$ and $qs\geq 1$. Furthermore, we explore the monogamy properties of the unified $(q,s)$-concurrence for $q\geq 2$, $0\leq s\leq 1$ and $1\leq qs\leq 3$, in qubit systems. In addition, we derive an entanglement polygon inequality for the unified $(q,s)$-concurrence with $q\geq 1$ and $qs\geq 1$, which manifests the relationship among all the marginal entanglements in any multipartite qudit system.

</details>


### [30] [Multipartite entanglement measures based on the thermodynamic framework](https://arxiv.org/abs/2601.22583)
*Chen-Ming Bai,Yu Luo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, we introduce a unified method to characterize and measure multipartite entanglement using the framework of thermodynamics. A family of the new entanglement measures is proposed: \textit{ergotropic-gap concentratable entanglement}. Furthermore, we establish that ergotropic-gap concentratable entanglement constitutes a well-defined entanglement measure within a specific parameter regime, satisfying key properties including continuity, majorization monotonicity and monogamy. We demonstrate the utility of this measure by showing it effectively distinguishes between multi-qubit Greenberger-Horne-Zeilinger states and W states. It also proves effective in detecting entanglement in specific classes of four-partite star quantum network states.

</details>


### [31] [Unconventional Distance Scaling of Casimir-Polder Force between Atomic Arrays](https://arxiv.org/abs/2601.22640)
*Qihang Ye,Qihang Ye,Bing Miao,Lei Ying*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Conventionally, dispersion forces mediated by quantum vacuum fluctuations are known to exhibit universal distance scalings, with retardation typically leading to a faster decay of the interaction. Here, we show that this expectation fails for intrinsically discrete systems. Using the microscopic scattering approach, we study the Casimir-Polder interaction between two atomic arrays, and uncover an unconventional distance scaling in which the force crosses over from a faster decay at short separations to a slower decay in the retarded regime. This behavior originates from the discrete lattice structure and can be consistently understood within the scattering picture. Extending our analysis to Rydberg atomic arrays, we predict an even stronger deviation from conventional scaling and propose an experimentally feasible scheme for direct measurement. Our results provide a new platform for exploring dispersion forces beyond the continuum limit.

</details>


### [32] [Orders of magnitude runtime reduction in quantum error mitigation](https://arxiv.org/abs/2601.22785)
*Raam Uzdin*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum error mitigation (QEM) infers noiseless expectation values by combining outcomes from intentionally modified, noisy variants of a target quantum circuit. Unlike quantum error correction, QEM requires no additional hardware resources and is therefore routinely employed in experiments on contemporary quantum processors. A central limitation of QEM is its substantial sampling overhead, which necessitates long execution times where device noise may drift, potentially compromising the reliability of standard mitigation protocols. QEM strategies based on agnostic noise amplification (ANA) are intrinsically resilient to such noise variations, but their sampling cost remains a major practical bottleneck. Here we introduce a mitigation framework that combines virtual noise scaling with a layered mitigation architecture, yielding orders of magnitude reduction in runtime overhead compared to conventional zero-noise extrapolation post-processing. The proposed approach is compatible with dynamic circuits and can be seamlessly integrated with error detection and quantum error correction schemes. In addition, it naturally extends to ANA-based mitigation of mid-circuit measurements and preparation errors. We validate our post-processing approach by applying it to previously reported experimental data, where we observe a substantial improvement in mitigation efficiency and accuracy.

</details>


### [33] [Scattering of Squeezed Light by a Dielectric Slab](https://arxiv.org/abs/2601.22798)
*G. Pooseh*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We develop a quantum theory for the scattering of squeezed coherent light by a dissipative dielectric slab. Using the Green-function quantization approach, we derive the transformation of the field quadratures and show how dispersion, absorption, and multiple reflections distort the incident squeezing. We find that the slab can selectively attenuate or amplify quadrature noise depending on the slab parameters and provide expressions for the output power spectra.

</details>


### [34] [Steady-State Emission of Quantum-Correlated Light in the Telecom Band from a Single Atom](https://arxiv.org/abs/2601.22821)
*Alex Elliott,Takao Aoki,Scott Parkins*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose and investigate a scheme for the steady-state emission of quantum-correlated, telecom-band light from a single multilevel atom. By appropriately tuning the frequency of a pair of lasers, a two-photon transition is continually driven to an atomic excited state that emits photons at the desired wavelength. We show that resonantly coupling a cavity mode to the telecom transition can enhance the rate of emission while retaining the antibunched counting statistics that are characteristic of atomic light sources. We also explore coupling a second, independent cavity mode to the atom, which increases the telecom emission rate and introduces quantum correlations between the cavity modes. A model for the hyperfine structure of a single cesium atom is then described and numerically integrated to demonstrate the viability of implementing the scheme with a modern cavity QED system.

</details>


### [35] [Are Bell's conditions for local realism general enough?](https://arxiv.org/abs/2601.22833)
*Emilio Santos*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Bell conditions for local realism are critically revisited. In particular for optical experiments I criticize Bell's proposed response of detectors to signals as extremely idealized. More physical conditions are proposed, whence a realistic local model of an optical experiment is possible which violates the Clauser-Horne (Bell) inequality. The possibility rests on the existence of a coincidence-time loophole in the experiments.

</details>


### [36] [Dynamics of states of infinite quantum systems as a cornerstone of the second law of thermodynamics](https://arxiv.org/abs/2601.22863)
*Walter F. Wreszinski*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We improve on our version of the second law of thermodynamics as a deterministic theorem for quantum spin systems in two basic aspects. The first concerns the general statement of the second law: spontaneous changes in an adiabatically closed system will always be in the direction of increasing mean entropy, which rises to a maximal value. Two specific examples concern the transition from pure to mixed states in two different universality classes of dynamics in one dimension, one being the exponential model, the other the Dyson model, the dynamics of the latter exhibiting strong graphical evidence of quantum chaos, as a consequence of the results of Albert and Kiessling on the Cloitre function.

</details>


### [37] [Fast magic state preparation by gauging higher-form transversal gates in parallel](https://arxiv.org/abs/2601.22939)
*Dominic J. Williamson*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Magic states are a foundational resource for universal quantum computation. To survive in a realistic noisy environment, magic states must be prepared fault-tolerantly and protected by a quantum error-correcting code. The recent discovery of highly efficient quantum low-density parity-check codes, together with efficient logic gates, lays the groundwork for low-overhead fault-tolerant quantum computation. This motivates the search for fast and parallel protocols for logical magic state preparation to enable universal quantum computation. Here, we introduce a fast code surgery procedure that performs a fault-tolerant measurement of many transversal logic gates in parallel. This is achieved by performing a generalized gauging measurement on a quantum code that supports a higher-form transversal gate. The time overhead of our procedure is constant, and the qubit overhead is linear. The procedure inherits fault-tolerance properties from the base code and the structure of the higher-form transversal gate. When applied to codes that support higher-form Clifford gates our procedure achieves fast and fault-tolerant preparation of many magic states in parallel. This motivates the search for good quantum low-density parity-check codes that support higher-form Clifford gates.

</details>


### [38] [High-resolution tunable frequency beamsplitter enabled by an integrated silicon pulse shaper](https://arxiv.org/abs/2601.23028)
*Chen-You Su,Kaiyi Wu,Lucas M. Cohen,Saleha Fatema,Navin B. Lingaraju,Hsuan-Hao Lu,Andrew M. Weiner,Joseph M. Lukens,Jason D. McKinney*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We demonstrate high-fidelity, tunable, and ultrafine-resolution on-chip frequency beamsplitters using a quantum frequency processor based on an integrated pulse shaper with six spectral channels. Near-ideal Hadamard gate performance is achieved, with fidelity F > 0.9995 and modified success probability P > 0.9621 maintained across frequency spacings from 2-5 GHz and down to as few as four spectral pulse shaper channels. The system's support of frequency spacings as narrow as 2 GHz significantly surpasses prior bulk demonstrations and enables arbitrary splitting ratios via spectral phase or modulation index control. These results establish a scalable and resource-efficient platform for integrated frequency-bin quantum photonics, opening new directions in quantum information processing, including densely parallel single-qubit operations and multidimensional gate implementations.

</details>


### [39] [Dicke superposition probes for noise-resilient Heisenberg and super-Heisenberg Metrology](https://arxiv.org/abs/2601.23043)
*Sudha,B. N. Karthik,K. S. Akhilesh,A. R. Usha Devi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Phase sensing with entangled multiqubit states in the presence of noise is a central theme of modern quantum metrology. The present work investigates Dicke state superposition probes for quantum phase sensing under parameter encoding generated by one- and two-body interaction Hamiltonians. A class of N-qubit Dicke superposition states that exhibit near-Heisenberg scaling, of the quantum Fisher information, while maintaining significantly enhanced robustness to dephasing noise compared to GHZ, W-superposition, and balanced Dicke states, under unitary encodings generated by one-body interaction Hamiltonians are identified. For two-body interactions, Dicke superposition probes optimizing the quantum Fisher information are identified, and their performance under phase-damping, amplitude-damping, and global depolarizing noise is explored. Within this family, certain Dicke superpositions are found to combine super-Heisenberg scaling with improved resilience to phase damping relative to Fisher information optimal probes. These results establish tailored near-optimal Dicke-state superposition probes as versatile and noise-resilient resources for Heisenberg and super-Heisenberg quantum phase sensing governed by one- and two-body interactions.

</details>


### [40] [Scalable Memory Sharing in Photonic Quantum Memristors for Reservoir Computing](https://arxiv.org/abs/2601.23044)
*Chaehyeon Lim,Hyungchul Park,Beomjoon Chae,Jeonghun Kwak,Soo-Yeon Lee,Namkyoo Park,Sunkyu Yu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Although photons are robust, room-temperature carriers well suited to quantum machine learning, the absence of photon-photon interactions hinder the realization of memory functionalities that are critical for capturing long-range context. Recently, measurement-based implementations of photonic quantum memristors (PQMRs) have enabled tunable non-Markovian responses. However, their memory remains confined to local elements, in contrast to biological or artificial networks where memory is shared across the system. Here, we propose a scalable PQMR network that enables measurement-based memory sharing. Each memristive node updates its internal state using the history of its own and neighbouring quantum states, thereby realizing distributed memory. By modelling each node as a photonic quantum memtransistor, we demonstrate pronounced enhancements in both classical and quantum hysteresis at the device level, as well as enhanced network-level quantum hysteresis. Implemented as a quantum reservoir, the architecture achieves improved Fashion-MNIST classification accuracy and confidence via increased data separability. Our approach paves the way toward high-capacity quantum machine learning using memristive devices compatible with linear-optical quantum computing.

</details>


### [41] [Margin-Based Generalisation Bounds for Quantum Kernel Methods under Local Depolarising Noise](https://arxiv.org/abs/2601.23084)
*Saarisha Govender,Ilya Sinayskiy*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Generalisation refers to the ability of a machine learning (ML) model to successfully apply patterns learned from training data to new, unseen data. Quantum devices in the current Noisy Intermediate-Scale Quantum (NISQ) era are inherently affected by noise, which degrades generalisation performance. In this work, we derive upper and lower margin-based generalisation bounds for Quantum Kernel-Assisted Support Vector Machines (QSVMs) under local depolarising noise. These theoretical bounds characterise noise-induced margin decay and are validated via numerical simulations across multiple datasets, as well as experiments on real quantum hardware. We further justify the focus on margin-based measures by empirically establishing margins as a reliable indicator of generalisation performance for QSVMs. Additionally, we motivate the study of local depolarising noise by presenting empirical evidence demonstrating that the commonly used global depolarising noise model is overly optimistic and fails to accurately capture the degradation of generalisation performance observed in the NISQ era.

</details>


### [42] [TopoLS: Lattice Surgery Compilation via Topological Program Transformations](https://arxiv.org/abs/2601.23109)
*Junyu Zhou,Yuhao Liu,Ethan Decker,Justin Kalloor,Mathias Weiden,Kean Chen,Costin Iancu,Gushu Li*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Fault-tolerant quantum computing with surface codes can be achieved by compiling logical circuits into lattice-surgery instructions. To minimize space-time volume, we present TopoLS, a topological compiler that combines ZX-diagram optimizations with Monte Carlo tree search guided by different operation placements and topology-aware circuit partitioning. Our approach enables scalable exploration of lattice surgery structures and consistently reduces resource overhead. Evaluations of various benchmark algorithms across multiple architectures show that TopoLS achieves an average 33% reduction in space-time volume over prior heuristic-based compilers, while maintaining linear compilation time scaling. Compared to the SAT-solver-based compiler, which provides optimal results only for small circuits before becoming intractable, TopoLS offers an effective and scalable solution for lattice-surgery compilation.

</details>


### [43] [Free encoding capacity: A universal unit for quantum resources](https://arxiv.org/abs/2601.23116)
*Shampa Mondal,Soumajit Das,Preeti Parashar,Tamal Guha*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A perfect d-dimensional quantum channel can convey log d-bits of classical information by encoding messages in d-orthogonal quantum states. Alternatively, for every quantum state at the senders end, there exist d-encoding operations which produce d-orthogonal quantum states. Transmitting which via a d-level perfect quantum channel it is possible to communicate log d-bits of classical information. But what if the set of encoding operations is restricted only within a physically constrained class? Here, we consider such a class of encoding operations to be the set of free operations for any quantum resource theory and show that the constrained capacity - namely, the free encoding capacity (FEC) emerged as a unit of the corresponding quantum resource. Moreover, we show that for the pointed resource theories - a resource theory admitting only a single free state - FEC becomes a faithful resource measure also. We also discuss the implications of FEC in the question of resource-theoretic state transformations and the possibility of extending its faithfulness for general quantum resource theories.

</details>


### [44] [Complete Hierarchies for the Geometric Measure of Entanglement](https://arxiv.org/abs/2601.23243)
*Lisa T. Weinbrenner,Albert Rico,Kenneth Goodenough,Xiao-Dong Yu,Otfried Gühne*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In quantum physics, multiparticle systems are described by quantum states acting on tensor products of Hilbert spaces. This product structure leads to the distinction between product states and entangled states; moreover, one can quantify entanglement by considering the distance of a quantum state to the set of product states. The underlying optimization problem occurs frequently in physics and beyond, for instance in the computation of the injective tensor norm in multilinear algebra. Here, we introduce a method to determine the maximal overlap of a pure multiparticle quantum state with product states based on considering several copies of the pure state. This leads to three types of hierarchical approximations to the problem, all of which we prove to converge to the actual value. Besides allowing for the computation of the geometric measure of entanglement, our results can be used to tackle optimizations over stochastic local transformations, to find entanglement witnesses for weakly entangled bipartite states, and to design strong separability tests for mixed multiparticle states. Finally, our approach sheds light on the complexity of separability tests.

</details>


### [45] [High-gain effects in broadband continuous-wave parametric down conversion sources and measurements with undetected photons](https://arxiv.org/abs/2601.23263)
*Martin Houde,Franz Roeder,Christine Silberhorn,Benjamin Brecht,Nicolás Quesada*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study theoretically how high-gain effects affect the measurement outcome of visible signal spectra in undetected photon measurement schemes. We consider two interferometric configurations: firstly, the SU(1,1) interferometer where the idler incurs loss and additional dispersion in between two identical, lossless, squeezers; secondly, the induced coherence interferometer where the idler incurs loss and additional dispersion in between two identical, lossless, squeezers and where the second squeezer is seeded by the idler and a vacuum ancilla mode. Furthermore, we consider a distributed loss configuration where the idler incurs loss as it propagates in the nonlinear medium. Motivated by experimental evidence and due to the fact that broadband sources are ideal for these measurement schemes, we use the dispersive data of a third-order dispersion engineered integrated waveguide parametric down conversion (PDC) source presented in New Journal of Physics 26, 123025 (2024) to model the PDC spectra in the three configurations. For each configuration we consider the case of idler-only (i) absorption, (ii) additional dispersion, and (iii) the combined effects. We obtain results which outline the strength and weaknesses of the different configurations at different operation points.

</details>


### [46] [Understanding multiscale disorder in superconducting nanowire single photon detectors](https://arxiv.org/abs/2601.23277)
*Nirjhar Sarkar,Ronan Gourgues,Yueh-Chun Wu,Chengyun Hua,Katyayani Seal,Andreas Fognini,Steven Randolph,Eugene Dumitrescu,Gabor B. Halasz,Benjamin Lawrie*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Superconducting nanowire single-photon detectors are central to applications across quantum information science. Yet, their performance is limited by the effects of disorder and electrodynamic inhomogeneities that are not well understood. By combining DC transport, dark-count measurements, and bias-dependent microwave transmission spectroscopy in the presence of controlled nanoscale disorder introduced through helium-ion irradiation, we distinguish local instability-driven processes from intrinsic superconducting depairing and kinetic inductance nonlinearities. This approach enables systematic tuning of kinetic inductance, depairing currents, microwave dissipation, and mode structure within a single device. Bias- and temperature-dependent resonance shifts quantify disorder-induced modifications of the superconducting density of states through the nonlinear kinetic inductance, while the emergence of multiple resonant modes reveals the formation of electrodynamically distinct superconducting regions. Comparing depairing under current, field, and temperature isolates the dominant microwave loss mechanisms, separating vortex, quasiparticle, and two-level-system contributions, thus providing a robust multifunctional foundation for disorder engineering of superconducting nanowire detectors and resonators.

</details>


### [47] [Robust multiparameter estimation using quantum scrambling](https://arxiv.org/abs/2601.23283)
*Wenjie Gong,Bingtian Ye,Daniel Mark,Soonwon Choi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose and analyze a versatile and efficient multiparameter quantum sensing protocol, which simultaneously estimates many non-commuting and time-dependent signals that are coherently or incoherently coupled to sensing particles. Even in the presence of control imperfections and readout errors, our approach can detect exponentially many parameters in the system size while maintaining the optimal scaling of sensitivity. To accomplish this, scrambling dynamics are leveraged to map distinct signals to unique patterns of bitstring measurements, which distinguishes a large number of signals without significant sensitivity loss. Based on this principle, we develop a computationally efficient protocol utilizing random global Clifford unitaries and evaluate its performance both analytically and numerically. Our protocol naturally extends to scrambling dynamics generated by random local Clifford circuits, local random unitary circuits (RUCs), and ergodic Hamiltonian evolution--commonly realized in near-term quantum hardware--and opens the door to applications ranging from precise noise benchmarking of quantum dynamics to learning time-dependent Hamiltonians.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [48] [AI Decodes Historical Chinese Archives to Reveal Lost Climate History](https://arxiv.org/abs/2601.22458)
*Sida He,Lingxi Xie,Xiaopeng Zhang,Qi Tian*

Main category: physics.ao-ph

TL;DR: 提出一种基于生成式AI的新范式，通过分析中国历史档案重建1368-1911年东南中国的逐季降水记录，揭示了厄尔尼诺对降水的长期影响。


<details>
  <summary>Details</summary>
Motivation: 将历史文献中定性的气候记载转化为定量的气候序列是长期存在的挑战，传统方法难以有效提取时空细节。

Method: 开发了一种生成式人工智能框架，通过逆向推断历史记载中描述事件背后的定量气候模式，并应用于中国历史档案。

Result: 重建了1368–1911年东南中国亚年分辨率降水序列，量化了如明朝大旱等极端事件，并揭示了五百年来厄尔尼诺对区域降水的季节性和空间性影响。

Conclusion: 该方法不仅提供了高分辨率的长期气候数据集，还可广泛应用于气候科学及历史与社会科学领域。

Abstract: Historical archives contain qualitative descriptions of climate events, yet converting these into quantitative records has remained a fundamental challenge. Here we introduce a paradigm shift: a generative AI framework that inverts the logic of historical chroniclers by inferring the quantitative climate patterns associated with documented events. Applied to historical Chinese archives, it produces the sub-annual precipitation reconstruction for southeastern China over the period 1368-1911 AD. Our reconstruction not only quantifies iconic extremes like the Ming Dynasty's Great Drought but also, crucially, maps the full spatial and seasonal structure of El Ni$ñ$o influence on precipitation in this region over five centuries, revealing dynamics inaccessible in shorter modern records. Our methodology and high-resolution climate dataset are directly applicable to climate science and have broader implications for the historical and social sciences.

</details>


### [49] [Linking Extratropical Forecast Degradation to Tropical Cyclones in Physical and AI Models](https://arxiv.org/abs/2601.22540)
*Gan Zhang*

Main category: physics.ao-ph

TL;DR: 热带气旋（TC）对全球中期天气预报的准确性有显著影响，无论其路径如何，均可能导致预测技能下降，尤其是在欧洲地区。


<details>
  <summary>Details</summary>
Motivation: 研究热带气旋对中期天气预报失败的影响机制，以提高预测可靠性。

Method: 通过聚类历史TC轨迹并比较基于物理模型（ECMWF-IFS）和AI-物理混合模型（Google-NGCM）在TC生成附近的初始化预报技巧。

Result: 两种模型在中纬度地区表现出相似的大尺度误差增长；TC生成后第二周预报技巧可能降低，与TC路径无关；纬向路径TC也可通过罗斯贝波动力学和远程水汽输送导致显著预报退化；随机NGCM通常优于其确定性版本，且TC相关预报退化在欧洲更明显。

Conclusion: 尽管模型结构不同，TC相关的中期预报不确定性存在共同来源，且TC影响具有区域性特征，尤其对欧洲预报挑战更大。

Abstract: Global medium-range weather forecasts suffer occasional failures ("busts"), often linked to tropical cyclones (TCs). We systematically investigate the TC influences by clustering historical TC tracks and comparing skill of forecasts from a physics-based model (ECMWF-IFS) and an AI-physics hybrid model (Google-NGCM) initialized near TC genesis. Case analysis shows both models exhibit similar large-scale error growth in the extratropics, suggesting prediction skill bounded by similar limits despite model differences in spatial resolution and parameterized physics. Aggregated statistics reveal that low skill of Week-2 forecasts may occur after TC genesis, regardless of whether they recurve or not. While recurving tracks are established error sources, zonal-track clusters can be associated with similarly profound forecast degradation, acting through Rossby wave dynamics and remote moisture transport mechanisms. Furthermore, the stochastic NGCM generally outperforms its deterministic counterpart and suggests that TC-related forecast degradation is more pronounced for Europe than elsewhere in the Northern Hemisphere.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [50] [Large Language Models: A Mathematical Formulation](https://arxiv.org/abs/2601.22170)
*Ricardo Baptista,Andrew Stuart,Son Tran*

Main category: math.NA

TL;DR: 本文提出了一种用于大语言模型（LLM）的数学框架，涵盖文本序列的编码、下一个词预测模型的架构、从数据中学习模型的方法及其在多种任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解大语言模型的工作机制，并为提高其准确性、效率和鲁棒性提供理论基础。

Method: 通过信息论、概率论和优化的基本概念，构建一个描述大语言模型的数学框架。

Result: 建立了一个能够解释大语言模型算法结构的数学框架，该框架不仅有助于理解现有模型，还为开发新的方法提供了方向。

Conclusion: 所提出的数学框架为研究大语言模型的性能提供了坚实的基础，并指出了未来研究的方向。

Abstract: Large language models (LLMs) process and predict sequences containing text to answer questions, and address tasks including document summarization, providing recommendations, writing software and solving quantitative problems. We provide a mathematical framework for LLMs by describing the encoding of text sequences into sequences of tokens, defining the architecture for next-token prediction models, explaining how these models are learned from data, and demonstrating how they are deployed to address a variety of tasks. The mathematical sophistication required to understand this material is not high, and relies on straightforward ideas from information theory, probability and optimization. Nonetheless, the combination of ideas resting on these different components from the mathematical sciences yields a complex algorithmic structure; and this algorithmic structure has demonstrated remarkable empirical successes. The mathematical framework established here provides a platform from which it is possible to formulate and address questions concerning the accuracy, efficiency and robustness of the algorithms that constitute LLMs. The framework also suggests directions for development of modified and new methodologies.

</details>


### [51] [Convergence Analysis of the Discrete Constrained Saddle Dynamics and Their Momentum Variants](https://arxiv.org/abs/2601.22341)
*Qiang Du,Baoming Shi*

Main category: math.NA

TL;DR: 本文研究了离散约束鞍点动力学及其动量变体在流形上寻找鞍点的方法，提出了基于动量的加速算法，并证明其在病态条件下仍能有效收敛，同时降低了对精确不稳定特征向量的依赖。


<details>
  <summary>Details</summary>
Motivation: 为了在流形上高效定位鞍点，克服传统方法在条件数较差时收敛慢的问题，并减少计算成本。

Method: 提出动量增强的约束鞍点动力学，分析其连续与离散形式的局部收敛性，并证明单步特征向量更新即可保证收敛。

Result: 理论证明动量方法改善了收敛速率，尤其在病态情况下表现更优；数值实验验证了方法在Thomson问题、Stiefel流形上的Rayleigh商及玻色-爱因斯坦凝聚能量泛函中的有效性。

Conclusion: 动量加速的约束鞍点动力学能够在较弱假设下实现更快收敛，具有较强的实用性和计算效率。

Abstract: We study the discrete constrained saddle dynamics and their momentum variants for locating saddle points on manifolds. Under the assumption of exact unstable eigenvectors, we establish a local linear convergence of the discrete constrained saddle dynamics and show that the convergence rate depends on the condition number of the Riemannian Hessian. To mitigate this dependence, we introduce a momentum-based constrained saddle dynamics and prove local convergence of the continuous-time dynamics as well as the corresponding discrete scheme, which further demonstrates that momentum accelerates convergence, particularly in ill-conditioned settings. In addition, we show that a single-step eigenvector update is sufficient to guarantee local convergence; thus, the assumption of exact unstable eigenvectors is not necessary, which substantially reduces the computational cost. Finally, numerical experiments, including applications to the Thomson problem, the Rayleigh quotient on the Stiefel manifold, and the energy functional of Bose-Einstein condensates, are presented to complement the theoretical analysis.

</details>


### [52] [Low-Rank Approximation by Randomly Pivoted LU](https://arxiv.org/abs/2601.22344)
*Marc Aurèle Gilles,Heather Wilber*

Main category: math.NA

TL;DR: 分析了随机主元LU分解（RPLU）在低秩逼近中的性质，证明其在奇异值快速衰减的矩阵上期望意义下几何收敛，并在内存受限或矩阵具有特殊结构时优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索一种高效、低存储的低秩矩阵逼近算法，尤其适用于内存受限和具有特定结构的矩阵。

Method: 通过分析随机主元LU分解（RPLU）的迭代过程，研究其在不同矩阵类型下的收敛性与计算复杂度，并结合实际应用验证其有效性。

Result: RPLU在期望意义下具有几何收敛性，计算复杂度为O(k(m+n)+kM(A)+k³)，存储需求为O(k²+m+n)；在内存受限和结构化矩阵（如Cauchy-like矩阵）场景中表现优于现有算法。

Conclusion: RPLU是一种高效的低秩逼近方法，特别适用于资源受限环境和具有可利用结构的矩阵，在实际应用中展现出良好性能。

Abstract: The low-rank approximation properties of Randomly Pivoted LU (RPLU), a variant of Gaussian elimination where pivots are sampled proportional to the squared entries of the Schur complement, are analyzed. It is shown that the RPLU iterates converge geometrically in expectation for matrices with rapidly decaying singular values. RPLU outperforms existing low-rank approximation algorithms in two settings: first, when memory is limited, RPLU can be implemented with $\mathcal{O}(k^2 + m + n)$ storage and $\mathcal{O}( k(m + n)+ k\mathcal{M}(\mat{A}) + k^3)$ operations, where $\mathcal{M}(\mat{A})$ is the cost of a matvec with $\mat{A}\in\mathbb{C}^{n\times m}$ or its adjoint, for a rank-$k$ approximation. Second, when the matrix and its Schur complements share exploitable structure, such as for Cauchy-like matrices. The efficacy of RPLU is illustrated with several examples, including applications in rational approximation and solving large linear systems on GPUs.

</details>


### [53] [Forward-KL Convergence of Time-Inhomogeneous Langevin Diffusions](https://arxiv.org/abs/2601.22349)
*Andreas Habring,Martin Zach*

Main category: math.NA

TL;DR: 本文提出了一个统一的非渐近分析框架，用于研究依赖时间相关漂移（如退火或调温策略）的Langevin扩散及其欧拉-丸山离散化方法，并在前向KL散度下给出了收敛性结果，适用于多种实际相关的退火方案。


<details>
  <summary>Details</summary>
Motivation: 许多实际采样器依赖于时间相关的漂移来提升探索能力和稳定性，这促使需要对相应的Langevin扩散及其离散化进行统一且非渐近的分析。

Method: 在一组关于时间相关漂移的抽象条件下，分析Langevin扩散过程及其欧拉-丸山离散化在前向KL散度下的收敛性。

Result: 得到了连续时间扩散及其离散化方法的非渐近收敛界，并通过数值实验比较了不同退火方案在高低维设置下的表现。

Conclusion: 该理论框架适用于多种实际退火方案（如几何调温和退火Langevin采样），为理解和设计高效采样算法提供了理论支持。

Abstract: Many practical samplers rely on time-dependent drifts -- often induced by annealing or tempering schedules -- to improve exploration and stability. This motivates a unified non-asymptotic analysis of the corresponding Langevin diffusions and their discretizations. We provide a convergence analysis that includes non-asymptotic bounds for the continuous-time diffusion and its Euler--Maruyama discretization in the forward-Kullback--Leibler divergence under a single set of abstract conditions on the time-dependent drift. The results apply to many practically-relevant annealing schemes, including geometric tempering and annealed Langevin sampling. In addition, we provide numerical experiments comparing the annealing schemes covered by our theory in low- and high-dimensional settings.

</details>


### [54] [Inverse acoustic scattering for random obstacles with multi-frequency data](https://arxiv.org/abs/2601.22560)
*Zhiqi Sun,Xiang Xu,Yiwen Lin*

Main category: math.NA

TL;DR: 研究了二维空间中的逆随机障碍散射问题，提出基于高斯过程和KL展开的两阶段反演方法，结合多频数据重建随机散射体的基线形状与边界波动统计特性，并给出理论分析与数值验证。


<details>
  <summary>Details</summary>
Motivation: 针对随机障碍散射问题中传统模型难以兼顾数学合理性和物理一致性的挑战，需建立可参数化的随机边界模型并设计有效反演策略以同时恢复几何与统计信息。

Method: 采用修正协方差函数的高斯过程建模随机散射体边界，通过KL展开实现参数化；提出两阶段反演法：第一阶段利用多频数据重建基线形状，第二阶段估计KL特征值与协方差超参数。

Result: 实现了对简单与复杂形状障碍物的几何形态及边界波动统计特性的稳定恢复，数值实验验证了方法有效性；理论分析证明了模型良定性、两阶段算法收敛性，并讨论了解的唯一性。

Conclusion: 所提高斯过程建模与两阶段反演框架能有效处理二维逆随机障碍散射问题，兼顾数学严谨与物理合理性，可同时准确恢复散射体的几何与统计特征。

Abstract: We study an inverse random obstacle scattering problems in $\mathbb{R}^2$ where the scatterer is formulated by a Gaussian process defined on the angular parameter domain. Equipped with a modified covariance function which is mathematically well-defined and physically consistent, the Gaussian process admits a parameterization via Karhunen--Loève (KL) expansion. Based on observed multi-frequency data, we develop a two-stage inversion method: the first stage reconstructs the baseline shape of the random scatterer and the second stage estimates the statistical characteristics of the boundary fluctuations, including KL eigenvalues and covariance hyperparameters. We further provide theoretical justifications for the modeling and inversion pipeline, covering well-definedness of the Gaussian-process model, convergence for the two-stage procedure and a brief discussion on uniqueness. Numerical experiments demonstrate stable recovery of both geometric and statistical information for obstacles with simple and more complex shapes.

</details>


### [55] [An ultra-weak three-field finite element formulation for the biharmonic and extended Fisher--Kolmogorov equations](https://arxiv.org/abs/2601.22587)
*Rekha Khot,Bishnu P. Lamichhane,Ricardo Ruiz-Baier*

Main category: math.NA

TL;DR: 本文提出了一种求解双调和问题的超弱三场公式，引入解、梯度和拉格朗日乘子作为三个未知量，并基于Raviart-Thomas离散化构造有限元格式，证明了其适定性和先验误差估计，同时推广至时间依赖的非线性Fisher-Kolmogorov方程，数值实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为提高双调和问题数值求解的稳定性与精度，需引入更灵活的变分形式并处理多重未知量之间的耦合关系。

Method: 采用基于Raviart-Thomas元的共形有限元方法，结合鞍点问题的抽象理论分析连续与离散系统的适定性，并利用离散inf-sup条件证明误差估计。

Result: 建立了超弱三场 formulation 的理论基础，获得了离散系统的适定性与收敛性，并成功推广至非线性时间依赖方程。

Conclusion: 该方法能有效求解双调和问题及其非线性扩展，数值结果验证了理论分析的正确性与方法的鲁棒性。

Abstract: This paper discusses a so-called ultra-weak three-field formulation of the biharmonic problem where the solution, its gradient, and an additional Lagrange multiplier are the three unknowns. We establish the well-posedness of the problem using the abstract theory for saddle-point problems, and develop a conforming finite element scheme based on Raviart--Thomas discretisations of the two auxiliary variables. The well-posedness of the discrete formulation and the corresponding a priori error estimate are proved using a discrete inf-sup condition. We further extend the analysis to the time-dependent semilinear equation, namely extended Fisher--Kolmogorov equation. We present a few numerical examples to demonstrate the performance of our approach.

</details>


### [56] [An inertial minimal-deformation-rate framework for shape optimization](https://arxiv.org/abs/2601.22605)
*Falai Chen,Buyang Li,Jiajie Li,Rong Tang*

Main category: math.NA

TL;DR: 提出了一种结合二阶惯性流与最小变形率（MDR）网格运动策略的鲁棒数值框架，用于PDE约束的形状优化和Willmore型曲面补洞，显著提升了收敛速度与网格质量保持能力。


<details>
  <summary>Details</summary>
Motivation: 解决形状优化中因平坦能量景观导致的收敛停滞和几何演化过程中的网格劣化问题。

Method: 将二阶惯性流与最小变形率（MDR）网格运动策略相结合，并在Barrett-Garcke-Nürnberg（BGN）框架内引入曲面扩散正则化，以增强对非光滑或非凸初始几何的鲁棒性；并将该方法扩展至Willmore型曲面补洞。

Result: 数值实验表明，该方法能更快收敛至更低的目标函数值，并在整个演化过程中保持更优的网格质量，避免了重网格划分。

Conclusion: 所提出的惯性MDR框架在处理PDE约束形状优化和曲面补洞问题时具有高效性、鲁棒性和良好的网格保持能力，适用于复杂初始条件下的高阶平滑重构。

Abstract: We propose a robust numerical framework for PDE-constrained shape optimization and Willmore-driven surface hole filling. To address two central challenges -- slow progress in flat energy landscapes, which can trigger premature stagnation at suboptimal configurations, and mesh deterioration during geometric evolution -- we couple a second-order inertial flow with a minimal-deformation-rate (MDR) mesh motion strategy. This coupling accelerates convergence while preserving mesh quality and thus avoids remeshing. To further enhance robustness for non-smooth or non-convex initial geometries, we incorporate surface-diffusion regularization within the Barrett-Garcke-N"urnberg (BGN) framework. Moreover, we extend the inertial MDR methodology to Willmore-type surface hole filling, enabling high-order smooth reconstructions even from incompatible initial data. Numerical experiments demonstrate markedly faster convergence to lower original objective values, together with consistently superior mesh preservation throughout the evolution.

</details>


### [57] [A Mathematical Analysis of a Smooth-Convex-Concave Splitting Scheme for the Swift--Hohenberg Equation](https://arxiv.org/abs/2601.22687)
*Yuki Yonekura,Daiki Iwade,Shun Sato,Takayasu Matsuo*

Main category: math.NA

TL;DR: 提出了一种新的线性隐式有限差分格式来求解三维Swift-Hohenberg方程，该方法保持了能量耗散特性、解的唯一可解性、数值解的有界性，并在时间步长足够小时具有先验误差估计。据作者所知，这是首个同时具备这些性质的线性隐式格式。


<details>
  <summary>Details</summary>
Motivation: 现有保持结构的数值方法多为完全隐式，计算成本高，缺乏高效且能保持能量耗散等关键特性的线性隐式格式。

Method: 基于离散能量不等式，利用Lipschitz连续梯度及凸性或μ-强凸性假设，构建了一种线性隐式的有限差分格式。

Result: 新方法保持了原方程的能量耗散律，保证了解的唯一存在性和数值解的有界性，并在小时间步长下获得先验误差估计。

Conclusion: 所提设计原则有效，构造出的线性隐式格式在保持物理结构的同时显著提升计算效率，为四阶模型提供了更实用的数值求解方案。

Abstract: The Swift--Hohenberg equation is a widely studied fourth-order model, originally proposed to describe hydrodynamic fluctuations. It admits an energy-dissipation law and, under suitable assumptions, bounded solutions. Many structure-preserving numerical schemes have been proposed to retain such properties; however, existing approaches are often fully implicit and therefore computationally expensive. We introduce a simple design principle for constructing dissipation-preserving finite difference schemes and apply it to the Swift--Hohenberg equation in three spatial dimensions. Our analysis relies on discrete inequalities for the underlying energy, assuming a Lipschitz continuous gradient and either convexity or $μ$-strong convexity of the relevant terms. The resulting method is linearly implicit, yet it preserves the original energy-dissipation law, guarantees unique solvability, ensures boundedness of numerical solutions, and admits an a priori error estimate, provided that the time step is sufficiently small. To the best of our knowledge, this is the first linearly implicit finite difference scheme for the Swift--Hohenberg equation for which all of these properties are established.

</details>


### [58] [Numerical Differentiation of Functions of Two Variables Using Chebyshev Polynomials](https://arxiv.org/abs/2601.22762)
*Maksym Kyselov,Sergiy G. Solodky*

Main category: math.NA

TL;DR: 提出了一种基于Chebyshev多项式和双曲交叉思想的截断方法，用于从加权Wiener类中重构任意阶偏导数，并给出了误差估计。


<details>
  <summary>Details</summary>
Motivation: 解决加权Wiener类中双变量函数的高阶数值微分问题，提高在噪声环境下的逼近精度。

Method: 利用Chebyshev多项式的逼近性质和双曲交叉思想设计新的截断方法，并结合权重空间特性进行偏导数重构。

Result: 推导出截断参数的选择规则，并在加权积分范数和一致度量下建立了显式的误差估计。

Conclusion: 该方法有效处理了带噪环境下高阶偏导数的数值微分问题，具有良好的理论误差界。

Abstract: We investigate the problem of numerical differentiation of bivariate functions from weighted Wiener classes using Chebyshev polynomial expansions. We develop and analyze a new version of the truncation method based on Chebyshev polynomials and the idea of hyperbolic cross to reconstruct partial derivatives of arbitrary order. The method exploits the approximation properties of Chebyshev polynomials and their natural connection to weighted spaces through the Chebyshev weight function. We derive a choice rule for the truncation parameter as a function of the noise level, smoothness parameters of the function class, and the order of differentiation. This approach allows us to establish explicit error estimates in both weighted integral norms and uniform metric.

</details>


### [59] [Approximation of PDE solution manifolds: Sparse-grid interpolation and quadrature](https://arxiv.org/abs/2601.22825)
*Dinh Dũng,Van Kien Nguyen,Duong Thanh Pham,Christoph Schwab*

Main category: math.NA

TL;DR: 本文研究了在与希尔伯特空间X和无限张量积Jacobi测度相关的抽象Bochner空间中，无限变元函数的全离散逼近和求积问题。通过构造稀疏网格张量积多项式插值逼近和求积方法，改进了先前的结果，并在两种应用背景下验证了理论假设，避免了“维度灾难”。


<details>
  <summary>Details</summary>
Motivation: 针对具有Jacobi广义多项式混沌展开的无限变元函数，现有离散化方法存在收敛速度受限和维度灾难的问题，因此需要发展更高效的全离散逼近与求积策略。

Method: 采用基于单变量Chebyshev点的稀疏网格张量积多项式插值方法，结合有限维子空间序列(V_m)的稳定离散化，构建线性逼近算子和求积公式，并分析其收敛性。

Result: 获得了目标函数逼近与求积的收敛速率结果，在椭圆扩散方程和希尔伯特空间间解析映射的应用中，利用超球面Jacobi展开系数的反对称项抵消效应，显著提升了收敛速度并克服了维度灾难。

Conclusion: 所提出的全离散稀疏网格方法在满足抽象条件的两类重要应用中实现了高效逼近与求积，为高维和无限维问题提供了可行的数值解决方案。

Abstract: We study fully-discrete approximations and quadratures of infinite-variate functions in abstract Bochner spaces associated with a Hilbert space $X$ and an infinite-tensor-product Jacobi measure. For target infinite-variate functions taking values in $X$ which admit absolutely convergent Jacobi generalized polynomial chaos expansions, with suitable weighted summability conditions for the coefficient sequences, we generalize and improve prior results on construction of sequences of finite sparse-grid tensor-product polynomial interpolation approximations and quadratures, based on the univariate Chebyshev points. For a generic stable discretization of $X$ in terms of a dense sequence $(V_m)_{m \in \mathbb{N}_0}$ of finite-dimensional subspaces, we obtain fully-discrete, linear approximations in terms of so-called sparse-grid tensor-product projectors, with convergence rates of approximations as well as of sparse-grid tensor-product quadratures of the target functions.
  We verify the abstract assumptions in two fundamental application settings: first, a linear elliptic diffusion equation with affine-parametric coefficients and second, abstract holomorphic maps between separable Hilbert spaces with affine-parametric input data encoding. For these settings, as in [37,20], cancellation of anti-symmetric terms in ultra-spherical Jacobi generalized polynomial chaos expansion coefficients implies crucially improved convergence rates of sparse-grid tensor-product quadrature with respect to the infinite-tensor-product Jacobi weight, free from the ``curse-of-dimension".
  Largely self-contained proofs of all results are developed. Approximation convergence rate results in the present setting which are based on construction of neural network surrogates, for unbounded parameter ranges with Gaussian measures, will be developed in extensions of the present work.

</details>


### [60] [On the convergence and efficiency of splitting schemes for the Cahn-Hilliard-Biot model](https://arxiv.org/abs/2601.22854)
*Cedric Riethmüller,Erlend Storvik*

Main category: math.NA

TL;DR: 本文提出了一种针对Cahn-Hilliard-Biot模型的新型求解策略，该模型耦合了多孔介质中的固相分离、流体动力学和弹性变形。通过引入半隐式时间离散化，将问题转化为凸最小化问题，并证明了交替最小化方法的收敛性，数值实验验证了该方法的有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于Cahn-Hilliard-Biot系统的强耦合、非线性和非凸特性，求解该系统具有挑战性，因此需要一种一致且高效的求解策略。

Method: 采用半隐式时间离散化方法，使离散后的系统等价于一个凸最小化问题，并基于凸优化理论证明交替最小化方法的收敛性。

Result: 理论分析表明交替最小化方法在满足标准逆不等式的条件下具有收敛性，数值实验显示该策略在效率和鲁棒性方面表现良好。

Conclusion: 所提出的求解策略为Cahn-Hilliard-Biot模型提供了一种有效且灵活的数值方法，适用于多种空间离散方式。

Abstract: In this paper, we present a novel solution strategy for the Cahn-Hilliard-Biot model, a three-way coupled system that features the interplay of solid phase separation, fluid dynamics, and elastic deformations in porous media. It is a phase-field model that combines the Cahn-Hilliard regularized interface equation and Biot's equations of poroelasticity. Solving the system poses significant challenges due to its coupled, nonlinear, and non-convex nature. The main goal of this work is to provide a consistent and efficient solution strategy. With this in mind, we introduce a semi-implicit time discretization such that the resulting discrete system is equivalent to a convex minimization problem. Then, using abstract theory for convex problems, we prove the convergence of an alternating minimization method to the time-discrete system. The solution strategy is relatively flexible in terms of spatial discretization, although we require standard inverse inequalities for the guaranteed convergence of the alternating minimization method. Finally, we perform some numerical experiments that show the promise of the proposed solution strategy, both in terms of efficiency and robustness.

</details>


### [61] [Randomized Methods for Kernelized DMD](https://arxiv.org/abs/2601.22867)
*Peter Oehme*

Main category: math.NA

TL;DR: 本文提出将RPCholesky算法应用于核化动态模分解（KDMD），利用自适应随机采样近似半正定核矩阵，提升了大规模数据下DMD的计算效率与数值稳定性，并在基准问题上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为加速动态模分解（DMD）在大规模数据集上的应用，需降低计算成本并提升数值稳定性，尤其是在核化DMD（KDMD）中处理高维核矩阵时存在挑战。

Method: 提出采用RPCholesky算法结合核化DMD（KDMD），利用自适应随机采样来近似半正定核矩阵，以降低计算复杂度并提高稳定性，并与其他随机方法进行比较分析。

Result: 新方法在多个DMD基准问题上表现出更高的数值稳定性与计算效率，能够有效处理维度递增的问题，优于现有随机化技术。

Conclusion: RPCholesky算法在KDMD中的应用是一种高效且稳定的方法，适用于大规模数据驱动的动力系统分析，具有良好的扩展潜力。

Abstract: Dynamic Mode Decomposition (DMD) is a data-driven method related to Koopman operator theory that extracts information about dominant dynamics from data snapshots. In this paper we examine techniques to accelerate the application of DMD to large-scale data sets with an eye on randomized techniques. Randomized techniques exploit low-rank matrix approximations at a much smaller computational cost, therefore permitting the use of increased data set sizes. In particular, we propose the application of the RPCholesky algorithm in the setting of kernelized DMD (KDMD). This algorithm relies on adaptive randomized sampling to approximate positive semidefinite kernel matrices and provides better stability guarantees than previously implemented randomized methods for KDMD. Differences between existing competitive randomized techniques and our proposed implementation are discussed with a focus on numerical stability and tradeoff between exploration and exploitation of information obtained from data. The efficacy of this new combination of algorithms is demonstrated on well-established benchmark problems from DMD literature increasing in problem dimension.

</details>


### [62] [FNWoS: Fractional Neural Walk-on-Spheres Methods for High-Dimensional PDEs Driven by $α$-stable Lévy Process on Irregular Domains](https://arxiv.org/abs/2601.22942)
*Ling Guo,Mingxin Qin,Changtao Sheng,Hao Wu,Fanhai Zeng*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we develop a highly parallel and derivative-free fractional neural walk-on-spheres method (FNWoS) for solving high-dimensional fractional Poisson equations on irregular domains. We first propose a simplified fractional walk-on-spheres (FWoS) scheme that replaces the high-dimensional normalized weight integral with a constant weight and adopts a correspondingly simpler sampling density, substantially reducing per-trajectory cost. To mitigate the slow convergence of standard Monte Carlo sampling, FNWoS is then proposed via integrating this simplified FWoS estimator, derived from the Feynman-Kac representation, with a neural network surrogate. By amortizing sampling effort over the entire domain during training, FNWoS achieves more accurate evaluation at arbitrary query points with dramatically fewer trajectories than classical FWoS. To further enhance efficiency in regimes where the fractional order $α$ is close to 2 and trajectories become excessively long, we introduce a truncated path strategy with a prescribed maximum step count. Building on this, we propose a buffered supervision mechanism that caches training pairs and progressively refines their Monte Carlo targets during training, removing the need to precompute a highly accurate training set and yielding the buffered fractional neural walk-on-spheres method (BFNWoS). Extensive numerical experiments, including tests on irregular domains and problems with dimensions up to $1000$, demonstrate the accuracy, scalability, and computational efficiency of the proposed methods.

</details>


### [63] [Preconditioning and Numerical Stability in Neural Network Training for Parametric PDEs](https://arxiv.org/abs/2601.23185)
*Markus Bachmayr,Wolfgang Dahmen,Chenguang Duan,Mathias Oster*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In the context of training neural network-based approximations of solutions of parameter-dependent PDEs, we investigate the effect of preconditioning via well-conditioned frame representations of operators and demonstrate a significant improvement on the performance of standard training methods. We also observe that standard representations of preconditioned matrices are insufficient for obtaining numerical stability and propose a generally applicable form of stable representations that enables computations with single- and half-precision floating point numbers without loss of precision.

</details>


### [64] [Applications of QR-based Vector-Valued Rational Approximation](https://arxiv.org/abs/2601.23237)
*Simon Dirckx*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Several applications of the QR-AAA algorithm, a greedy scheme for vector-valued rational approximation, are presented. The focus is on demonstrating the flexibility and practical effectiveness of QR-AAA in a variety of computational settings, including Stokes flow computation, multivariate rational approximation, function extension, the development of novel quadrature methods and near-field approximation in the boundary element method.

</details>


### [65] [A Primal-Dual Level Set Method for Computing Geodesic Distances](https://arxiv.org/abs/2601.23244)
*Hailiang Liu,Laura Zinnel*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The numerical computation of shortest paths or geodesics on surfaces, along with the associated geodesic distance, has a wide range of applications. Compared to Euclidean distance computation, these tasks are more complex due to the influence of surface geometry on the behavior of shortest paths. This paper introduces a primal-dual level set method for computing geodesic distances. A key insight is that the underlying surface can be implicitly represented as a zero level set, allowing us to formulate a constraint minimization problem. We employ the primal-dual methodology, along with regularization and acceleration techniques, to develop our algorithm. This approach is robust, efficient, and easy to implement. We establish a convergence result for the high-resolution PDE system, and numerical evidence suggests that the method converges to a geodesic in the limit of refinement.

</details>


### [66] [Rank Reduction AutoEncoders for Mechanical Design: Advancing Novel and Efficient Data-Driven Topology Optimization](https://arxiv.org/abs/2601.23269)
*Ismael Ben-Yelun,Mohammed El Fallaki Idrissi,Jad Mounayer,Sebastian Rodriguez,Francisco Chinesta*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work presents a data-driven framework for fast forward and inverse analysis in topology optimization (TO) by combining Rank Reduction Autoencoders (RRAEs) with neural latent-space mappings. The methodology targets the efficient approximation of the relationship between optimized geometries and their corresponding mechanical responses or Quantity of Interest (QoI), with a particular focus on compliance-minimized linear elastic structures. High-dimensional TO results are first compressed using RRAEs, which encode the data into a low-rank approximation via Singular Value Decomposition (SVD), obtained in this sense the most important features that approximate the data. Separate RRAE models are trained for geometry and for different types of QoIs, including scalar metrics, one-dimensional stress fields, and full two-dimensional von Mises stress distributions. The resulting low-dimensional latent coefficients of the latent space are then related through multilayer perceptrons to address both direct problems -- predicting structural responses from geometry -- and inverse problems -- recovering geometries from prescribed performance targets. The proposed approach is demonstrated on a benchmark TO problem based on a half MBB beam, using datasets generated via density-based Solid Isotropic Material with Penalization (SIMP) optimization. Numerical results show that the framework enables accurate and computationally efficient surrogate models, with increasing robustness and fidelity as richer QoIs are considered. The methodology also provides a foundation for generative mechanical design by enabling the synthesis of new geometries and responses through latent-space exploration.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [67] [The Benefit of Collective Intelligence in Community-Based Content Moderation is Limited by Overt Political Signalling](https://arxiv.org/abs/2601.22201)
*Gabriela Juncosa,Saeedeh Mohammadi,Margaret Samahita,Taha Yasseri*

Main category: cs.SI

TL;DR: 协作撰写社区内容审核笔记可提升其质量，但团队成员政治倾向的透明度会削弱这一优势。


<details>
  <summary>Details</summary>
Motivation: 当前基于社区的内容审核系统存在政治偏见问题，影响其有效性，因此需要探索更有效的协作机制。

Method: 通过在线实验，让参与者共同撰写针对政治性帖子的审核笔记，并比较协作与独立撰写的效果差异。

Result: 团队撰写的笔记被认为更有帮助，政治多元团队在评估共和党相关帖子时表现更优，但当成员知晓彼此政治立场时，协作优势减弱。

Conclusion: 协作能提升社区审核笔记的质量，但设计系统时需谨慎处理政治认同对团队协作的负面影响。

Abstract: Social media platforms face increasing scrutiny over the rapid spread of misinformation. In response, many have adopted community-based content moderation systems, including Community Notes (formerly Birdwatch) on X (formerly Twitter), Footnotes on TikTok, and Facebook's Community Notes initiative. However, research shows that the current design of these systems can allow political biases to influence both the development of notes and the rating processes, reducing their overall effectiveness. We hypothesize that enabling users to collaborate on writing notes, rather than relying solely on individually authored notes, can enhance their overall quality. To test this idea, we conducted an online experiment in which participants jointly authored notes on political posts. Our results show that teams produce notes that are rated as more helpful than individually written notes. We also find that politically diverse teams perform better when evaluating Republican posts, while group composition does not affect perceived note quality for Democrat posts. However, the advantage of collaboration diminishes when team members are aware of one another's political affiliations. Taken together, these findings underscore the complexity of community-based content moderation and highlight the importance of understanding group dynamics and political diversity when designing more effective moderation systems.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [68] [Omni-fMRI: A Universal Atlas-Free fMRI Foundation Model](https://arxiv.org/abs/2601.23090)
*Mo Wang,Wenhao Ye,Junfeng Xia,Junxiang Zhang,Xuanye Pan,Minghao Xu,Haotian Deng,Hongkai Wen,Quanying Liu*

Main category: cs.CE

TL;DR: Omni-fMRI是一种无需图谱的fMRI基础模型，通过动态分块机制直接在体素级信号上操作，降低计算成本并保留空间结构信息，在多个数据集上展现出优于现有模型的迁移性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督fMRI基础模型大多依赖预定义的区域分割，丢失了细粒度的体素信息，并引入图谱依赖偏差，限制了模型的可扩展性和泛化能力。

Method: 提出Omni-fMRI，采用动态分块机制直接处理体素级fMRI信号，实现无图谱依赖的建模；在49,497个fMRI会话的九个数据集上进行大规模预训练，并构建包含11个数据集的综合基准套件以支持可重复性和公平比较。

Result: 实验结果表明，Omni-fMRI在多种静息态和任务态fMRI任务中 consistently 优于现有的fMRI基础模型，验证了其在脑表示学习中的有效性与可扩展性。

Conclusion: Omni-fMRI提供了一个可扩展、可复现的无图谱fMRI表示学习框架，推动了脑影像基础模型的发展。

Abstract: Self-supervised fMRI foundation models have shown promising transfer performance, yet most rely on predefined region-level parcellations that discard fine-grained voxel information and introduce atlas-dependent biases. We propose Omni-fMRI, an atlas-free foundation model that operates directly on voxel-level signals. To enable scalable pretraining on 49,497 fMRI sessions across nine datasets, Omni-fMRI introduces a dynamic patching mechanism that substantially reduces computational cost while preserving informative spatial structure. To support reproducibility and fair comparison, we establish a comprehensive benchmark suite spanning 11 datasets and a diverse set of resting-state and task-based fMRI tasks. Experimental results demonstrate that Omni-fMRI consistently outperforms existing foundation models, providing a scalable and reproducible framework for atlas-free brain representation learning. Code and logs are available.

</details>


### [69] [Large Language Models for Patent Classification: Strengths, Trade-offs, and the Long Tail Effect](https://arxiv.org/abs/2601.23200)
*Lorenzo Emer,Marco Lippi,Andrea Mina,Andrea Vandin*

Main category: cs.CE

TL;DR: 本文系统比较了基于编码器的模型和大语言模型（LLM）在高度不平衡的专利分类任务中的表现，发现前者在高频类别上表现更好且推理效率高，而LLM在罕见技术类别上具有优势，表明两者可互补，建议结合二者优势的混合方法。


<details>
  <summary>Details</summary>
Motivation: 由于专利分类具有层次性、多标签和高度不平衡的特点，现有模型在稀有技术类别上表现不佳，因此需要探索大语言模型是否能在这些弱表示的技术类别中提供补充能力。

Method: 在USPTO 70k数据集上系统比较了基于编码器的模型（如BERT、SciBERT、PatentSBERTa）与开源权重的大语言模型，评估了LLM在零样本、少样本及检索增强提示下的表现，并对最佳模型进行了参数高效微调，同时量化了推理时间和能耗。

Result: 基于编码器的模型在总体性能上更优，主要得益于对高频CPC子类的良好表现，但在稀有类别上表现较差；而LLM在低频子类（常对应新兴、跨领域或制度化程度低的技术）上相对表现更好，尤其是在较高层级；同时编码器模型的推理效率比LLM高三个数量级。

Conclusion: 基于编码器的模型和LLM在专利分类中具有互补作用，推荐在计算和环境约束下采用结合编码器效率与LLM长尾覆盖能力的混合分类方法，以支持负责任的专利计量和技术图谱构建。

Abstract: Patent classification into CPC codes underpins large scale analyses of technological change but remains challenging due to its hierarchical, multi label, and highly imbalanced structure. While pre Generative AI supervised encoder based models became the de facto standard for large scale patent classification, recent advances in large language models (LLMs) raise questions about whether they can provide complementary capabilities, particularly for rare or weakly represented technological categories. In this work, we perform a systematic comparison of encoder based classifiers (BERT, SciBERT, and PatentSBERTa) and open weight LLMs on a highly imbalanced benchmark dataset (USPTO 70k). We evaluate LLMs under zero shot, few shot, and retrieval augmented prompting, and further assess parameter efficient fine tuning of the best performing model. Our results show that encoder based models achieve higher aggregate performance, driven by strong results on frequent CPC subclasses, but struggle on rare ones. In contrast, LLMs achieve relatively higher performance on infrequent subclasses, often associated with early stage, cross domain, or weakly institutionalised technologies, particularly at higher hierarchical levels. These findings indicate that encoder based and LLM based approaches play complementary roles in patent classification. We additionally quantify inference time and energy consumption, showing that encoder based models are up to three orders of magnitude more efficient than LLMs. Overall, our results inform responsible patentometrics and technology mapping, and motivate hybrid classification approaches that combine encoder efficiency with the long tail coverage of LLMs under computational and environmental constraints.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [70] [Excited-state uncertainties in lattice-QCD calculations of multi-hadron systems](https://arxiv.org/abs/2601.22272)
*William Detmold,Anthony V. Grebe,Daniel C. Hackett,Marc Illa,Robert J. Perry,Phiala E. Shanahan,Michael L. Wagman*

Main category: hep-lat

TL;DR: 本文提出了一种新的间隙边界方法，用于改进格点量子色动力学中多强子系统的激发态效应分析，相较于Lanczos残差界能提供更紧密的约束，并在核子-核子散射计算中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于在可计算的虚时间范围内激发间隙较小，导致格点QCD谱计算中存在难以量化的系统性不确定性，尤其是在多强子系统中信号噪声比较差的情况下。

Method: 引入了一种新的、更具约束力的间隙边界集合，并利用精确可解的格点场论关联函数在有限和无限统计情况下测试残差界和间隙界的实用性；结合GEVP和Lanczos能量估计器对高统计量核子-核子散射数据进行分析。

Result: 新的间隙界比Lanczos残差界 tighter，在假设阈值以下能级数与非相互作用核子相同的情况下，足以以现象学相关精度约束核子-核子散射振幅；不同插值算符的分析显示统计显著的不一致性，但所有算符的双边界一致；Lanczos方法揭示此前使用的非对称关联函数未在可及虚时间内收敛。

Conclusion: 数据驱动的例子表明，必须引入假设才能确定在此质量下的双核子基态性质，而新提出的间隙界在合理假设下可实现对散射振幅的精确约束。

Abstract: Excited-state effects lead to hard-to-quantify systematic uncertainties in lattice quantum chromodynamics (LQCD) spectroscopy calculations when computationally accessible imaginary times are smaller than inverse excitation gaps, as often arises for multi-hadron systems with signal-to-noise problems. Lanczos residual bounds address this by providing two-sided constraints on energies that do not require assumptions beyond Hermiticity, but often give very conservative systematic uncertainty estimates. Here, a more-constraining set of gap bounds is introduced for hadron spectroscopy. These bounds provide tighter constraints whose validity requires an explicit assumption about an energy gap. Exactly solvable lattice field theory correlators are used to test the utility of residual and gap bounds at finite and infinite statistics. Two-sided bounds and other analysis methods are then applied to a high-statistics LQCD calculation of nucleon-nucleon scattering at $m_π\sim 800$ MeV. Generalized eigenvalue problem (GEVP) and Lanczos energy estimators are compatible when applied to the same correlator data, but analyses including different interpolating operators show statistically significant inconsistencies. However, two-sided bounds from all operators are consistent. Under the assumption that the number of energy levels below $NΔ$ and $ΔΔ$ thresholds is the same as for non-interacting nucleons, gap bounds are sufficient to constrain nucleon-nucleon scattering amplitudes at phenomenologically relevant precision. Lanczos methods further reveal that energy-eigenstate estimates from previously studied asymmetric correlators have not converged over accessible imaginary times. Nevertheless, data-driven examples demonstrate why assumptions are required to draw conclusions about the natures of two-nucleon ground states at these masses.

</details>


### [71] [Excited-state uncertainties in lattice-QCD calculations of hadron masses and scattering phase shifts](https://arxiv.org/abs/2601.22273)
*William Detmold,Anthony V. Grebe,Daniel C. Hackett,Marc Illa,Robert J. Perry,Phiala E. Shanahan,Michael L. Wagman*

Main category: hep-lat

TL;DR: 本文介绍了新的Lanczos方法，能够在较宽松的假设下提供双向边界，并通过高统计量计算量化了这些方法在非物理夸克质量下的表现。


<details>
  <summary>Details</summary>
Motivation: 传统格点QCD能量结果依赖于对渐近行为的隐含假设或仅提供单边上限，缺乏更精确的双向约束方法。

Method: 引入新的Lanczos方法，提供无需强光谱假设的双向边界，并在高统计量下进行非物理夸克质量的计算验证。

Result: 无需光谱假设的双向边界可实现对核子质量的亚百分比级约束；假定某一能量窗口内所有态均被解析时，可对核子-核子散射相移提供有意义的双向约束。

Conclusion: 新Lanczos方法减少了对渐近行为的依赖，提升了格点QCD能量估计的精度和可靠性。

Abstract: Lattice QCD has historically produced energy results interpretable as either estimates relying on implicit assumptions about asymptotic behavior or one-sided upper bounds. New Lanczos methods providing two-sided bounds with less-restrictive assumptions are introduced and quantified in a high-statistics calculation with unphysical quark masses. Two-sided bounds without spectral assumptions provide sub-percent constraints on the nucleon mass. Other bounds, which assume all states in a given energy window are resolved, provide meaningful two-sided constraints on nucleon-nucleon scattering phase shifts.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [72] [MiTa: A Hierarchical Multi-Agent Collaboration Framework with Memory-integrated and Task Allocation](https://arxiv.org/abs/2601.22974)
*XiaoJie Zhang,JianHan Wu,Xiaoyang Qu,Jianzong Wang*

Main category: cs.ET

TL;DR: MiTa是一种层次化的记忆集成任务分配框架，通过管理者-成员层级结构和全局任务分配与情景记忆整合，提升多智能体系统的协作效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型的多智能体系统存在记忆不一致和智能体行为冲突等问题，限制了其在复杂任务中的效率和一致性。

Method: 提出MiTa框架，构建管理者-成员层级结构；管理者包含任务分配模块和摘要模块，前者从全局角度分配任务以避免冲突，后者在任务进展更新时触发，将近期协作历史压缩为简洁摘要以实现情景记忆整合。

Result: 实验结果表明，MiTa在复杂多智能体协作任务中相比强基线方法具有更高的效率和适应性。

Conclusion: 结合任务分配与情景记忆整合的MiTa框架能够增强多智能体系统的全局理解与一致性，有效提升协作性能。

Abstract: Recent advances in large language models (LLMs) have substantially accelerated the development of embodied agents. LLM-based multi-agent systems mitigate the inefficiency of single agents in complex tasks. However, they still suffer from issues such as memory inconsistency and agent behavioral conflicts. To address these challenges, we propose MiTa, a hierarchical memory-integrated task allocative framework to enhance collaborative efficiency. MiTa organizes agents into a manager-member hierarchy, where the manager incorporates additional allocation and summary modules that enable (1) global task allocation and (2) episodic memory integration. The allocation module enables the manager to allocate tasks from a global perspective, thereby avoiding potential inter-agent conflicts. The summary module, triggered by task progress updates, performs episodic memory integration by condensing recent collaboration history into a concise summary that preserves long-horizon context. By combining task allocation with episodic memory, MiTa attains a clearer understanding of the task and facilitates globally consistent task distribution. Experimental results confirm that MiTa achieves superior efficiency and adaptability in complex multi-agent cooperation over strong baseline methods.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [73] [Forecasting in the presence of scale-free noise](https://arxiv.org/abs/2601.22294)
*Serhii Kryhin,Tatiana Mouzykantskii,Vivishek Sudhir*

Main category: math.OC

TL;DR: 提出了一种在尺度自由噪声存在下解决信号预测问题的新方法，并提供了性能保证，具有广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 现有的预测技术要求噪声具有有理功率谱，但在实际中尺度自由噪声普遍存在，因此需要一种新的方法来处理这类噪声下的信号预测问题。

Method: 建立了一种新的估计方法，结合性能保证，能够在尺度自由噪声背景下进行信号预测，并通过估计与控制的对偶性设计分布式系统的控制策略。

Result: 该方法成功解决了尺度自由噪声下的预测问题，具备理论性能保证，并可扩展应用于控制领域。

Conclusion: 所提出的方法为在广泛存在的尺度自由噪声环境中进行信号提取和预测提供了有效解决方案，有望在多个学科领域产生重要影响。

Abstract: The extraction of signals from noise is a common problem in all areas of science and engineering. A particularly useful version is that of forecasting: determining a causal filter that estimates a future value of a hidden process from past observations. Current techniques for deriving the filter require that the noise be well described by rational power spectra. However, scale-free noises, whose spectra scale as a non-integer power of frequency, are ubiquitous in practice. We establish a method, together with performance guarantees, that solves the forecasting problem in the presence of scale-free noise. Via the duality between estimation and control, our technique can be used to design control for distributed systems. These results will have wide-ranging applications in neuroscience, finance, fluid dynamics, and quantum measurements.

</details>


### [74] [Operating Imperfect AI: Reliability Drift and Human Congestion](https://arxiv.org/abs/2601.22295)
*Ziyao Wang,Svetlozar T Rachev*

Main category: math.OC

TL;DR: 提出了一种动态队列控制方法来管理机器学习中的人机协同系统，通过状态依赖的风险阈值优化决策，揭示了拥塞卸载与安全缓冲的结构性规律，并发现了容量相变现象。


<details>
  <summary>Details</summary>
Motivation: 解决现有静态策略无法应对算法可靠性漂移与人类专家资源稀缺且易拥堵之间的矛盾。

Method: 将系统建模为基于（队列积压，可靠性状态）的动态队列控制问题，引入状态相关的风险阈值作为控制变量，并分析影子价格对最优升级策略的影响。

Result: 证明了最优策略受‘容量影子价格’驱动，发现了两个关键单调性结构：拥塞卸载（ backlog上升时提高阈值）和安全缓冲（漂移期间降低阈值），并识别出到达率-漂移参数空间中的容量相变临界点。

Conclusion: 为管理不可靠算法与拥堵专家之间的交互提供了严格的运营规则，揭示了在安全与响应性之间权衡的内在机制。

Abstract: The deployment of machine learning in high-stakes services relies on ``human-in-the-loop'' architectures to mitigate algorithmic uncertainty. However, existing static policies fail to address a fundamental tension: algorithms suffer from stochastic ``reliability drift,'' while human override capacity is scarce and congestible. We formulate the management of such systems as a dynamic queueing control problem. The system state is defined by the tuple (queue backlog, reliability regime), and the control variable is a state-dependent risk threshold. We prove that the optimal escalation policy is driven by the endogenous ``Shadow Price of Capacity.'' We establish two key structural monotonicity results: (i) Congestion Shedding, where the threshold rises with backlog to sacrifice marginal accuracy for responsiveness; and (ii) Safety Buffering, where the threshold lowers during drift to use the queue as a ``risk capacitor.'' Furthermore, we identify a critical ``Capacity Phase Transition'' in the arrival-drift parameter space, beyond which no policy can maintain safety standards without causing structural system failure (infinite queues). Our results provide rigorous operational rules for managing the interface between imperfect algorithms and congested experts.

</details>


### [75] [Square Root-Factorized Covariance Steering](https://arxiv.org/abs/2601.22348)
*Naoya Kumagai,Kenshiro Oguri*

Main category: math.OC

TL;DR: 本文提出了一种新的协方差导引（Covariance Steering, CS）问题求解方法，通过QR分解显式地写出状态协方差矩阵Cholesky因子的传播方程，采用平方根形式提升计算可扩展性和数值可靠性，并证明了在有无机会约束情况下的最优性。


<details>
  <summary>Details</summary>
Motivation: 现有的CS方法在处理长时域、高维系统时存在计算复杂度高和数值不稳定的问题，尤其当不确定性较小时传统方法易出现病态。因此需要一种更高效且鲁棒的求解方式。

Method: 利用QR分解推导状态协方差矩阵Cholesky因子的传播方程，采用平方根形式表示协方差，在无需大型分块矩阵或直接参数化协方差的情况下进行求解，并结合序列凸规划处理非凸性。

Result: 新方法在计算效率和内存使用上优于现有方法，具有更好的可扩展性和数值稳定性；在无机会约束下证明全局最优，在有机会约束时与现有最优方法具有相同局部极小值。数值实验验证了理论结果。

Conclusion: 所提出的基于平方根形式的CS方法在性能、可靠性和优化特性上均表现优越，是解决线性时变系统协方差导引问题的有效新途径。

Abstract: Covariance steering (CS) synthesizes a control policy which drives the state's mean and covariance matrix towards desired values. Offering tractable computation of a closed-loop policy which can obey chance constraints in uncertain environments, application to many real-world control problems have been proposed. We consider the chance-constrained, discrete-time, linear time-varying CS with Gaussian noise. The contribution of this paper is a novel solution method for this problem, explicitly writing the propagation equations of the Cholesky factor of the state covariance matrix by using the QR decomposition. The use of the square-root form of covariance matrices brings two key benefits over other existing methods: (i) computational scalability and (ii) numerical reliability. (i) Compared to solution methods that require large block matrix formulations, the proposed method scales better with the growth in horizon length, shows better optimality, and uses memoryless state feedback. (ii) Compared to another class of methods that explicitly define the covariance matrix as variables, the proposed method allows flexible cost formulations and shows better numerical reliability when uncertainty terms are smaller than the mean. On the other hand, these benefits come with a minor drawback: the propagation equation of covariance square roots is non-convex, necessitating sequential convex programming to solve. However, this paper proves the global optimality of the proposed approach for CS without chance constraints. When chance constraints are present, the existing optimal CS formulation is also non-convex, and we prove that the proposed approach shares the same local minima. We verify the mathematical arguments via extensive numerical simulations.

</details>


### [76] [Operator Splitting with Hamilton-Jacobi-based Proximals](https://arxiv.org/abs/2601.22370)
*Nicholas Di,Eric C. Chi,Samy Wu Fung*

Main category: math.OC

TL;DR: 本文提出了一种基于Hamilton-Jacobi方程的近端算子（HJ-Prox）统一框架，使得在目标函数无法解析求解近端算子时仍可应用算子分裂算法，并证明了其在多种优化算法中保持收敛性。


<details>
  <summary>Details</summary>
Motivation: 由于大多数函数缺乏闭式近端算子，传统算子分裂方法的应用受到限制，本文旨在突破这一局限。

Method: 利用基于Hamilton-Jacobi偏微分方程理论的无导数蒙特卡洛方法HJ-Prox来数值逼近近端算子，并将其嵌入到多种经典算子分裂算法中。

Result: 理论分析表明，在温和假设下，使用HJ-Prox替代精确近端步骤仍能保持收敛性；实验结果显示该方法在多种统计学习任务中有效且具有竞争力。

Conclusion: HJ-Prox为非proximable函数下的算子分裂提供了通用且可靠的解决方案，扩展了现代一阶优化方法的适用范围。

Abstract: Operator splitting algorithms are a cornerstone of modern first-order optimization, decomposing complex problems into simpler subproblems solved via proximal operators. However, most functions lack closed-form proximal operators, which has long restricted these methods to a narrow set of problems. Hamilton-Jacobi-based proximal operator (HJ-Prox) is a recent derivative-free Monte Carlo technique based on Hamilton-Jacobi PDE theory, that approximates proximal operators numerically. In this work, we introduce a unified framework for operator splitting via HJ-Prox, which allows for deployment of operator splitting even when functions are not proximable. We prove that replacing exact proximal steps with HJ-Prox in algorithms such as proximal point, proximal gradient descent, Douglas-Rachford splitting, Davis-Yin splitting, and primal-dual hybrid gradient preserves convergence guarantees under mild assumptions. Numerical experiments demonstrate HJ-Prox is competitive and effective on a wide variety of statistical learning tasks.

</details>


### [77] [Visibility in Polygonal Environments with Holes: Finding Best Spots for Hiding and Surveillance](https://arxiv.org/abs/2601.22405)
*Neilabh Banzal,Jorge Cortés,Sonia Martínez*

Main category: math.OC

TL;DR: 本文研究了在多边形障碍环境中，针对位置未知的对手进行视线检测时，如何为智能体寻找最优隐藏位置的问题。提出了一种基于可见性度量的归一化下降算法，利用非光滑分析理论处理非光滑、非凸优化问题，并通过引入随机性逃离鞍点，确保以高概率收敛到局部极小值。


<details>
  <summary>Details</summary>
Motivation: 在复杂、不确定的环境中，可见性对决策至关重要。现有方法难以有效处理对手位置未知情况下的隐藏策略优化问题，尤其在存在障碍物的环境中缺乏对可见性度量的精细建模与优化保证。

Method: 将环境建模为带孔洞的多边形，利用非光滑分析刻画可见性度量的位置函数特性；提出归一化下降算法，结合非光滑结构与随机扰动机制，实现对非凸可见性函数的有效优化。

Result: 理论分析表明算法能以高概率收敛至局部最小值，突破传统仅收敛至Clarke临界点的局限；仿真验证了算法在两种捉迷藏场景中寻找隐蔽位置的有效性。

Conclusion: 该工作为对抗性隐藏路径规划提供了新的数学工具和优化框架，提升了在复杂环境中对抗视线探测的隐蔽性与鲁棒性。

Abstract: Visibility plays an important role for decision making in cluttered, uncertain environments. This paper considers the problem of identifying optimal hiding spots for an agent against line-of-sight detection by an adversary whose location is unknown. We consider environments modeled as polygons with holes. We develop a set of mathematical tools for reasoning about visibility as a function of position and rely on non-smooth analysis to formally characterize the regularity properties of various visibility-based metrics. These metrics are non-smooth and non-convex, so off-the-shelf optimization algorithms can only guarantee convergence to Clarke critical points. To address this, the proposed Normalized Descent algorithm leverages the structure of non-smooth points in visibility problems and introduces randomness to escape saddle points. Our technical analysis allows for the non-monotonic decrease in the visibility metric and strengthens the algorithm guarantees, ensuring convergence to local minima with high probability. Simulations on two hide-and-seek scenarios showcase the effectiveness of the proposed approach.

</details>


### [78] [Local controllability of the Cahn-Hilliard-Burgers' equation around certain steady states](https://arxiv.org/abs/2601.22611)
*Manika Bag,Sheetal Dharmatti,Subrata Majumdar,Debanjana Mitra*

Main category: math.OC

TL;DR: 研究了一维Cahn-Hilliard-Navier-Stokes方程在特定稳态附近的局部可控性，通过仅作用于浓度方程的内部控制实现。


<details>
  <summary>Details</summary>
Motivation: 分析非线性系统的局部可控性，为复杂流体系统控制提供理论支持。

Method: 对非线性方程在稳态附近线性化，利用对偶性论证证明可观测性不等式，并建立新的Carleman不等式；结合源项法和Banach不动点定理处理非齐次项和非线性系统。

Result: 获得了线性化系统的零可控性，并在适当加权空间中证明了非齐次项存在时的可控性保持，最终得出非线性系统的局部可控性。

Conclusion: 通过局部内部控制可实现一维Cahn-Hilliard-Burgers方程在特定稳态附近的局部可控性。

Abstract: In this article we study the local controllability of the one-dimensional Cahn-Hilliard-Navier-Stokes equation, that is Cahn-Hilliard-Burgers' equation, around a certain steady state using a localized interior control acting only in the concentration equation. To do it, we first linearize the nonlinear equation around the steady state. The linearized system turns out to be a system coupled between second order and fourth order parabolic equations and the control acts in the fourth order parabolic equation. The null controllability of the linearized system is obtained by a duality argument proving an observability inequality. To prove the observability inequality, a new Carleman inequality for the coupled system is derived. Next, using the source term method, it is shown that the null controllability of the linearized system with non-homogeneous terms persists provided the non-homogeneous terms satisfy certain estimates in a suitable weighted space. Finally, using a Banach fixed point theorem in a suitable weighted space, the local controllability of the nonlinear system is obtained.

</details>


### [79] [Enhancing Exploration in Global Optimization by Noise Injection in the Probability Measures Space](https://arxiv.org/abs/2601.22753)
*Gaëtan Serré,Pierre Germain,Samuel Gruffaz,Argyris Kalogeratos*

Main category: math.OC

TL;DR: 本文提出了两种向McKean-Vlasov（MKV）系统中概率分布动力学直接注入噪声的原则性方法，以增强粒子在多峰优化问题中的探索能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于粒子的全局优化方法在均场极限下概率演化具有确定性，限制了在多模态目标函数中的探索能力。

Method: 提出两种噪声注入策略：基于条件MKV理论的微扰方法和利用切空间结构的几何方法，并将其应用于Langevin、Consensus-Based Optimization和Stein Boltzmann Sampling等动力学系统。

Result: 实验表明，所提方法在多种动力学配置和多模态目标函数上均能持续提升探索效率和收敛性能。

Conclusion: 该框架为基于MKV系统的全局优化方法提供了通用且有效的改进工具，增强了其在复杂景观中的优化能力。

Abstract: McKean-Vlasov (MKV) systems provide a unifying framework for recent state-of-the-art particlebased methods for global optimization. While individual particles follow stochastic trajectories, the probability law evolves deterministically in the mean-field limit, potentially limiting exploration in multimodal landscapes. We introduce two principled approaches to inject noise directly into the probability law dynamics: a perturbative method based on conditional MKV theory, and a geometric approach leveraging tangent space structure. While these approaches are of independent interest, the aim of this work is to apply them to global optimization. Our framework applies generically to any method that can be formulated as a MKV system. Extensive experiments on multimodal objective functions demonstrate that both our noise injection strategies enhance consistently the exploration and convergence across different configurations of dynamics, such as Langevin, Consensus-Based Optimization, and Stein Boltzmann Sampling, providing a versatile toolkit for global optimization.

</details>


### [80] [Rapid stabilizability of delayed infinite-dimensional control systems](https://arxiv.org/abs/2601.22819)
*Yaxing Ma,Lijuan Wang,Huaiqiang Yu*

Main category: math.OC

TL;DR: 本文研究了具有常值延迟的线性无限维控制系统的快速稳定化问题，证明了延迟不影响系统的快速稳定化，并指出在观测反馈中无需使用历史信息。


<details>
  <summary>Details</summary>
Motivation: 探讨延迟对无限维控制系统快速稳定化的影响，并寻找更高效的反馈控制策略。

Method: 基于状态算子生成立即紧半群和延迟项系数为常数的假设，通过理论分析证明延迟不影响系统的快速稳定化，并讨论观测反馈中的信息使用问题。

Result: （i）延迟不影响系统的快速稳定化；（ii）在系统可快速稳定化的前提下，观测反馈中无需依赖历史信息进行控制。

Conclusion: 对于满足条件的线性无限维延迟系统，可以实现快速稳定化，且在反馈控制中无需额外存储历史数据，简化了控制器设计。

Abstract: In this paper, the rapid stabilizability of linear infinite-dimensional control system with constant-valued delay is studied. Under assumptions that the state operator generates an immediately compact semigroup and the coefficient of the delay term is constant, we mainly prove the following two results: (i) the delay does not affect rapid stabilizability of the control system; (ii) from the perspective of observation-feedback, it is not necessary to use historical information to stabilize the control system when the system is rapidly stabilizable. Some applications are given.

</details>


### [81] [Convergence Rates for the Alternating Minimization Algorithm in Structured Nonsmooth and Nonconvex Optimization](https://arxiv.org/abs/2601.22850)
*Glaydston C. Bento,Boris S. Mordukhovich,Tiago S. Mota,Antoine Soubeyran*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper is devoted to developing the alternating minimization algorithm for problems of structured nonconvex optimization proposed by Attouch, Bolté, Redont, and Soubeyran in 2010. Our main result provides significant improvements of the convergence rate of the algorithm, especially under the low exponent Polyak-Łojasiewicz-Kurdyka condition when we establish either finite termination of this algorithm or its superlinear convergence rate instead of the previously known linear convergence. We also investigate the PLK exponent calculus and discuss applications to noncooperative games and behavioral science.

</details>


### [82] [Grassmannian Geometry and Global Convergence of Variable Projection for Neural Networks](https://arxiv.org/abs/2601.22897)
*Mathias Dus*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Training deep neural networks and Physics-Informed Neural Networks (PINNs) often leads to ill-conditioned and stiff optimization problems. A key structural feature of these models is that they are linear in the output-layer parameters and nonlinear in the hiddenlayer parameters, yielding a separable nonlinear least-squares formulation. In this work, we study the classical variable projection (VarPro) method for such problems in the context of deep neural networks. We provide a geometric formulation on the Grassmannian and analyze the structure of critical points and convergence properties of the reduced problem. When the feature map is parametrized by a neural network, we show that these properties persist except in rank-deficient regimes, which we address via a regularized Grassmannian framework. Numerical experiments for regression and PINNs, including an efficient solver for the heat equation, illustrate the practical effectiveness of the approach.

</details>


### [83] [Breaking the Stochasticity Barrier: An Adaptive Variance-Reduced Method for Variational Inequalities](https://arxiv.org/abs/2601.23034)
*Yungi Jeong,Takumi Otsuka*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Stochastic non-convex non-concave optimization, formally characterized as Stochastic Variational Inequalities (SVIs), presents unique challenges due to rotational dynamics and the absence of a global merit function. While adaptive step-size methods (like Armijo line-search) have revolutionized convex minimization, their application to this setting is hindered by the Stochasticity Barrier: the noise in gradient estimation masks the true operator curvature, triggering erroneously large steps that destabilize convergence. In this work, we propose VR-SDA-A (Variance-Reduced Stochastic Descent-Ascent with Armijo), a novel algorithm that integrates recursive momentum (STORM) with a rigorous Same-Batch Curvature Verification mechanism. We introduce a theoretical framework based on a Lyapunov potential tracking the Operator Norm, proving that VR- SDA-A achieves an oracle complexity of O(epsilon -3) for finding an epsilon-stationary point in general Lipschitz continuous operators. This matches the optimal rate for non-convex minimization while uniquely enabling automated step-size adaptation in the saddle-point setting. We validate our approach on canonical rotational benchmarks and non-convex robust regression tasks, demonstrating that our method effectively suppresses limit cycles and accelerates convergence with reduced dependence on manual learning rate scheduling.

</details>


### [84] [Accelerated Inertial Gradient Algorithms with Vanishing Tikhonov Regularization](https://arxiv.org/abs/2601.23035)
*Samir Adly,Vinh Thanh Ho,Huu Nhan Nguyen*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we study an explicit Tikhonov-regularized inertial gradient algorithm for smooth convex minimization with Lipschitz continuous gradient. The method is derived via an explicit time discretization of a damped inertial system with vanishing Tikhonov regularization. Under appropriate control of the decay rate of the Tikhonov term, we establish accelerated convergence of the objective values to the minimum together with strong convergence of the iterates to the minimum-norm minimizer. In particular, for polynomial schedules $\varepsilon_k = k^{-p}$ with $0<p<2$, we prove strong convergence to the minimum-norm solution while preserving fast objective decay. In the critical case $p=2$, we still obtain fast rates for the objective values, while our analysis does not guarantee strong convergence to the minimum-norm minimizer. Furthermore, we provide a thorough theoretical analysis for several choices of Tikhonov schedules. Numerical experiments on synthetic, benchmark, and real datasets illustrate the practical performance of the proposed algorithm.

</details>


### [85] [Stationary Mean-Field singular control of an Ornstein-Uhlenbeck process](https://arxiv.org/abs/2601.23036)
*Federico Cannerozzi*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Motivated by continuous-time optimal inventory management, we study a class of stationary mean-field control problems with singular controls. The dynamics are modeled by a mean-reverting Ornstein-Uhlenbeck process, and the performance criterion is given by a quadratic long-time average expected cost functional. The mean-field dependence is through the stationary mean of the controlled process itself, which enters the ergodic cost functional. We characterize the solution to the stationary mean-field control problem in terms of the equilibria of an associated stationary mean-field game, showing that solutions of the control problem are in bijection with the equilibria of this mean-field game. Finally, we solve the stationary mean-field game explicitly, thereby providing a solution to the original stationary mean-field control problem.

</details>


### [86] [A General Tikhonov Regularized Second-Order Dynamical System for Convex-Concave Bilinear Saddle Point Problems](https://arxiv.org/abs/2601.23120)
*Bohan Zhang,Xiaojun Zhang*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we propose a general Tikhonov regularized second-order dynamical system with viscous damping, time scaling and extrapolation coefficients for the convex-concave bilinear saddle point problem. By the Lyapunov function approach, we show that the convergence properties of the proposed dynamical system depend on the choice of the Tikhonov regularization parameter. Specifically, when the Tikhonov regularization parameter tends to zero rapidly, the convergence rate of the primal-dual gap along the generated trajectory is O(1 over t squared times beta(t)); when the Tikhonov regularization parameter tends to zero slowly, the convergence rate of the primal-dual gap is o(1 over beta(t)). We also prove the strong convergence property of the trajectory generated by the Tikhonov regularized dynamical system to the minimum-norm solution of the convex-concave bilinear saddle point problem, and derive several integral estimates. In addition, the effectiveness of the proposed dynamical system is verified through a series of numerical experiments.

</details>


### [87] [General Optimal Stopping without Time Consistency](https://arxiv.org/abs/2601.23187)
*Hanqing Jin,Yanzhao Yang*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we propose a new framework for solving a general dynamic optimal stopping problem without time consistency. A sophisticated solution is proposed and is well-defined for any time setting with general flows of objectives. A backward iteration is proposed to find the solution. The iteration works with an additional condition, which holds in interesting cases including the time inconsistency arising from non-exponential discounting. Even if the iteration does not work, the equilibrium solution can still be studied by a forward definition.

</details>


### [88] [Theoretical Challenges in Learning for Branch-and-Cut](https://arxiv.org/abs/2601.23249)
*Hongyu Cheng,Amitabh Basu*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Machine learning is increasingly used to guide branch-and-cut (B&C) for mixed-integer linear programming by learning score-based policies for selecting branching variables and cutting planes. Many approaches train on local signals from lookahead heuristics such as strong branching, and linear programming (LP) bound improvement for cut selection. Training and evaluation of the learned models often focus on local score accuracy. We show that such local score-based methods can lead to search trees exponentially larger than optimal tree sizes, by identifying two sources of this gap. The first is that these widely used expert signals can be misaligned with overall tree size. LP bound improvement can select a root cut set that yields an exponentially larger strong branching tree than selecting cuts by a simple proxy score, and strong branching itself can be exponentially suboptimal (Dey et al., 2024). The second is that small discrepancies can be amplified by the branch-and-bound recursion. An arbitrarily small perturbation of the right-hand sides in a root cut set can change the minimum tree size from a single node to exponentially many. For branching, arbitrarily small score discrepancies, and differences only in tie-breaking, can produce trees of exponentially different sizes, and even a small number of decision differences along a trajectory can incur exponential growth. These results show that branch-and-cut policies trained and learned using local expert scores do not guarantee small trees, thus motivating the study of data-driven methods that produce policies better aligned with tree size rather than only accuracy on expert scores.

</details>


<div id='physics.hist-ph'></div>

# physics.hist-ph [[Back]](#toc)

### [89] [The Beta-Bound: Drift constraints for Gated Quantum Probabilities](https://arxiv.org/abs/2601.22188)
*Jonathon Sendall*

Main category: physics.hist-ph

TL;DR: 本文提出了一个投影门控的测量理论框架，引入了控制概率分配漂移的β界，并通过实验验证其可证伪性。


<details>
  <summary>Details</summary>
Motivation: 量子力学虽能精确预测概率，但无法解释测量结果的确定性，本文旨在建立一个解释测量过程的理论框架。

Method: 采用测量理论方法，定义β界不等式、相干性见证量和记录保真度差作为诊断工具。

Result: 推导出对称部分门控漂移的上界公式，证明常数2是最优的，并在三个实验中验证了框架的可证伪性。

Conclusion: 该框架具有操作性和解释中立性，适用于多种量子诠释，并为实验检验提供了模板。

Abstract: Quantum mechanics provides extraordinarily accurate probabilistic predictions, yet the framework remains silent on what distinguishes quantum systems from definite measurement outcomes. This paper develops a measurement-theoretic framework for projective gating. The central object is the $β$-bound, an inequality that controls how much probability assignments can drift when gating and measurement fail to commute. For a density operator $ρ$, projector $F$, and effect $E$, with gate-passage probability $s = {\rm Tr}(ρF)$ and commutator norm $\varepsilon = \|[F, E]\|$, the symmetric partial-gating drift satisfies $|Δp_F(E)| \leq 2 \sqrt{(1 - s)/s} \cdot \varepsilon$. The constant 2 is sharp. We introduce two diagnostic quantities: the coherence witness $W(ρ, F) = \|F ρ(I - F)\|_1$, measuring cross-boundary coherence, and the record fidelity gap $Δ_T(ρ_F, R)$, measuring expectation-value change under symmetrisation. Three experimental vignettes demonstrate falsifiability: Hong--Ou--Mandel interferometry, atomic energy-basis dephasing, and decoherence-induced classicality. The framework is operational and interpretation-neutral, compatible with Everettian, Bohmian, QBist, and collapse approaches. It provides quantitative structure that any interpretation must accommodate, along with a template for experimental tests.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [90] [Slow driving induced multistability and remote synchronization in chaotic Chua's circuit](https://arxiv.org/abs/2601.22700)
*Tuhin Mahanty,Ayushi Saxena,Sangeeta Rani Ujjwal*

Main category: nlin.AO

TL;DR: 研究了混沌信号驱动下Chua电路的响应，发现当驱动频率远低于响应频率且驱动强度超过阈值时，系统表现出多稳态吸引子，并观察到不同形式的远程同步现象。


<details>
  <summary>Details</summary>
Motivation: 探索在变时间尺度混沌信号驱动下Chua电路的动力学行为，特别是多稳态和同步现象。

Method: 采用辅助系统方法研究驱动与响应系统之间的广义同步，并分析不同驱动强度和频率条件下的吸引子特性及同步行为。

Result: 发现低频驱动下系统出现双卷或单卷多稳态吸引子；随着驱动强度增加，吸引子形态发生变化；观察到完全同步、滞后同步和轨迹相关等远程同步形式；慢速驱动可引发这些同步态间的多稳性，高频时该现象消失。

Conclusion: 驱动信号的时间尺度和强度显著影响Chua电路的多稳态和同步行为，揭示了慢速混沌驱动下新型远程同步机制的存在。

Abstract: We study the response of Chua's circuit driven by a chaotic signal of variable time-scale. We observe that when the frequency of the drive is significantly lower than that of the response and the driving strength is above a threshold, the Chua's circuit exhibits multiple stable attractors. The features of the attractors change as the driving strength ε increases, for instance the attractors are double-scroll at low ε and are single-scroll when ε is high. We also investigate generalized synchronization(GS) between the drive and the response systems by employing the auxiliary system approach. When the drive is much slower than the response, we observe different scenarios of remote synchronization(RS) between response and auxiliary units. In addition to complete synchrony between response and auxiliary systems indicating GS between drive and response, we notice that the response and auxiliary units can be lag synchronized and can also have correlated trajectories indicating novel forms of RS. The slow drive can induce multistability between these RS states which disappears as the frequency of drive increases and become equivalent to the response Chua's ciruit.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [91] [Correcting temporal bias in mobility data using time-use surveys](https://arxiv.org/abs/2601.22330)
*Sarah A. Sanchez,Hamish Gibbs,Takahiro Yabe,Daniel T. O'Brien,Esteban Moro*

Main category: physics.soc-ph

TL;DR: 本文探讨了GPS移动数据中的时间偏差问题，并提出了一种时间重加权方法来提高基于GPS的移动数据分析结论的准确性，同时利用美国时间使用调查（ATUS）验证行为洞察并量化不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决GPS移动数据中由于位置数据采样的事件驱动特性导致的时间偏差问题，以避免对移动行为表征的扭曲。

Method: 使用美国时间使用调查（ATUS）评估从11个美国城市的大规模移动数据中得出的基于地点的经济隔离度量的准确性，并提出一种时间重加权方法以减轻偏差。

Result: 展示了与高质量时间使用调查（如ATUS）的比较可用于验证移动数据的行为洞察，量化不确定性，并识别分析结果中相对不稳定的区域；所提出的时间重加权方法可提升现有偏倚缓解技术的效果。

Conclusion: 通过结合时间使用调查和时间重加权方法，可以有效减少GPS移动数据中的时间偏差，从而提高基于此类数据所得结论的准确性和可靠性。

Abstract: GPS mobility data is a valuable source of behavioral measurement which is subject to systematic biases including the over- or under-representation of demographic groups, and variations in the quality of location sampling across time. In this paper, we address the challenge of temporal bias in mobility data, which can skew the representation of mobility behaviors due to the event-based nature of location data sampling. We use the American Time Use Survey (ATUS) to assess the accuracy of a place-based measure of economic segregation drawn from large-scale mobility data across 11 U.S. cities. We show that comparisons with high quality time use surveys such as the ATUS can validate behavioral insights from mobility data, while quantifying uncertainty and highlighting areas of relative instability in analytical findings. We also propose a temporal re-weighting method that can complement existing bias-mitigation techniques to improve the accuracy of conclusions drawn from GPS-based mobility data.

</details>


### [92] [Convergent Discovery of Critical Phenomena Mathematics Across Disciplines: A Cross-Domain Analysis](https://arxiv.org/abs/2601.22389)
*Bruce Stephenson,Robin Macomber*

Main category: physics.soc-ph

TL;DR: 多个领域在不同时间独立发展了用于检测临界现象的技术，尽管术语和符号不同，但核心数学原理相同，表明临界性数学是跨学科的基础公共知识。


<details>
  <summary>Details</summary>
Motivation: 揭示不同学科在检测相变和临界现象时所使用的指标（如关联长度、Hurst指数等）本质上测量的是相同的物理量，反映出跨领域的重复独立发现模式。

Method: 通过文献计量分析和概念对比，比较物理学、生物医学、金融、机器学习等领域中用于检测临界现象的数学工具，并使用2D Ising模型进行对应性测试以验证各指标的一致性。

Result: 确认了至少八个领域在1987–2010年间独立发展出等效技术，且这些技术能正确识别2D Ising模型在临界温度T_c=2.269处的相变；提出Metatron Dynamics作为第九个可能的独立发现。

Conclusion: 临界现象的数学基础已被多次独立发现，应被视为基础性的公共知识，这对跨学科教育和研究可及性具有重要意义。

Abstract: Techniques for detecting critical phenomena -- phase transitions where correlation length diverges and small perturbations have large effects -- have been developed across at least eight fields of application over nine decades. We document this convergence pattern. The physicist's correlation length $ξ$, the cardiologist's DFA scaling exponent $α$, the financial analyst's Hurst exponent $H$, and the machine learning engineer's spectral radius $χ$ all measure correlation decay rate, detecting the same critical signatures under different notation. Citation analysis reveals minimal cross-domain awareness during the formative period (1987--2010): researchers in biomedicine, finance, machine learning, power systems, and traffic flow developed equivalent techniques independently, each with distinct notation and terminology. We present Metatron Dynamics, a framework derived from distributed systems engineering, as a candidate ninth independent discovery -- strengthening the convergence pattern while acknowledging that as authors of both the framework and this analysis, external validation would strengthen this claim. Correspondence testing on the 2D Ising model confirms that measures from multiple frameworks correctly identify the critical regime at $T_c = 2.269$. We argue that repeated independent discovery establishes criticality mathematics as fundamental public knowledge, with implications for cross-disciplinary education and research accessibility. Because these findings affect fields beyond mathematics and physics, we include a plain-language summary in Appendix B for non-specialist readers.

</details>


### [93] [A Universal Convolution-Based Pre-processor to Correct the Prevalence-Incidence Gap in SIR, SEIR, and SIRS Modeling](https://arxiv.org/abs/2601.23077)
*Jose de Jesus Bernal-Alvarado,David Delepine*

Main category: physics.soc-ph

TL;DR: 本文指出传统传染病模型（如SIR、SEIR、SIRS）在使用每日发病率数据校准基于患病率的模型时存在根本性方法错误，并提出一种基于指数加权卷积的数据预处理方法，以正确重构活跃病例数，显著提升模型预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统模型常因数据类型错配导致预测偏差，例如低估疫情峰值达50%，本文旨在纠正这一普遍被忽视的方法论问题。

Method: 提出一个通用的指数加权卷积公式：$I(t) \approx \frac{1}{p} \int_{0}^{t} NDC(τ) e^{-γ(t-τ)} dτ$，将报告的每日新增病例（流量）转换为活跃病例数（存量），并整合到经典 compartmental 模型中进行验证。

Result: 实验表明，不进行该数据转换的复杂模型（如SEIR、SIRS）仍会继承系统性偏差，无法准确估计潜伏期和疫情尾部特征；而使用该预处理器后，各类模型的预测一致性与准确性显著提升。

Conclusion: 该卷积变换应作为所有基于 compartmental 框架建模的前置步骤，弥合临床报告数据与机制模型之间的鸿沟。

Abstract: Traditional compartmental models, including SIR, SEIR, and SIRS frameworks, remain the analytical standard for epidemic forecasting. However, real-world data validation consistently reveals significant predictive failures, such as peak underestimations of up to 50%. This research identifies a persistent fundamental methodological error: the calibration of prevalence-based (stock) models using raw daily incidence (flow) data without proper transformation. We propose an integrated protocol utilizing an exponentially weighted convolution to reconstruct active cases from reported incidence: $I(t) \approx \frac{1}{p} \int_{0}^{t} NDC(τ) e^{-γ(t-τ)} dτ$. This transformation accounts for the recovery rate $γ$ and the ascertainment rate $p$. We demonstrate that increasing structural complexity, such as adding latency (SEIR) or waning immunity (SIRS), fails to resolve the incidence-prevalence gap. Simulation results show that without the proposed universal pre-processor, these advanced models inherit the systematic biases of misaligned data types, leading to significant errors in estimating latent periods and the "heavy tail" of endemicity. The proposed convolution transformation must serve as a universal prerequisite for any compartmental framework, bridging the gap between clinical reporting and mechanistic modeling.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [94] [A spectral approach for online covariance change point detection](https://arxiv.org/abs/2601.22602)
*Zhigang Bao,Kha Man Cheong,Yuji Li,Jiaxin Qiu*

Main category: math.ST

TL;DR: 本文提出了一种基于谱的CUSUM型统计量，用于高维序列数据中协方差结构的在线变点检测。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于历史数据中的变点检测，缺乏对实际应用中重要的在线变点问题的研究。

Method: 利用随机矩阵线性谱统计量的极限理论，构建基于Fisher矩阵谱统计量差异的鞅过程，并定义CUSUM型统计量，结合不变性原理开发检测方法。

Result: 模拟结果表明，该方法对变点的发生高度敏感，能够在变点出现后迅速识别，性能优于现有方法。

Conclusion: 所提出的基于谱的CUSUM型方法在高维在线协方差变点检测中具有高效性和优越性。

Abstract: Change point detection in covariance structures is a fundamental and crucial problem for sequential data. Under the high-dimensional setting, most of the existing research has focused on identifying change points in historical data. However, there is a significant lack of studies on the practically relevant online change point problem, which means promptly detecting change points as they occur. In this paper, applying the limiting theory of linear spectral statistics for random matrices, we propose a class of spectrum based CUSUM-type statistic. We first construct a martingale from the difference of linear spectral statistics of sequential sample Fisher matrices, which converges to a Brownian motion. Our CUSUM-type statistic is then defined as the maximum of a variant of this process. Finally, we develop our detection procedure based on the invariance principle. Simulation results show that our detection method is highly sensitive to the occurrence of change point and is able to identify it shortly after they arise, outperforming the existing approaches.

</details>


### [95] [Convergence of Multi-Level Markov Chain Monte Carlo Adaptive Stochastic Gradient Algorithms](https://arxiv.org/abs/2601.22799)
*Antoine Godichon-Baggioni,Gabriel Lang,Sylvain Le Corff,Julien Stoehr,Sobihan Surendran*

Main category: math.ST

TL;DR: 提出了一种多层蒙特卡洛梯度估计器，用于减少随机优化中的偏差，同时保持较低的计算成本，并开发了自适应随机梯度方法的多层变体。


<details>
  <summary>Details</summary>
Motivation: 在学习和推理中，随机优化通常依赖于马尔可夫链蒙特卡洛（MCMC）来近似梯度，但有限时间的MCMC估计器存在偏差，降低偏差通常需要更高的计算成本。

Method: 提出了一个多层蒙特卡洛梯度估计器，其偏差衰减为O(T_n^{-1})，而预期计算成本仅增长为O(log T_n)。基于此方法，引入了用于自适应随机梯度方法的多层MCMC框架，开发了Adagrad和AMSGrad算法的新多层变体。

Result: 在控制估计器偏差及其二阶和三阶矩的条件下，建立了收敛速率为O(n^{-1/2})（最多对数因子）。通过使用所提出的多层自适应方法训练的重要性加权自动编码器验证了这些结果。

Conclusion: 所提出的多层蒙特卡洛梯度估计器有效降低了偏差并保持了较低的计算成本，新开发的多层自适应算法在实际应用中表现出良好的性能。

Abstract: Stochastic optimization in learning and inference often relies on Markov chain Monte Carlo (MCMC) to approximate gradients when exact computation is intractable. However, finite-time MCMC estimators are biased, and reducing this bias typically comes at a higher computational cost. We propose a multilevel Monte Carlo gradient estimator whose bias decays as $O(T_{n}^{-1} )$ while its expected computational cost grows only as $O(log T_n )$, where $T_n$ is the maximal truncation level at iteration n. Building on this approach, we introduce a multilevel MCMC framework for adaptive stochastic gradient methods, leading to new multilevel variants of Adagrad and AMSGrad algorithms. Under conditions controlling the estimator bias and its second and third moments, we establish a convergence rate of order $O(n^{-1/2} )$ up to logarithmic factors. Finally, we illustrate these results on Importance-Weighted Autoencoders trained with the proposed multilevel adaptive methods.

</details>


### [96] [Asymmetric conformal prediction with penalized kernel sum-of-squares](https://arxiv.org/abs/2601.22834)
*Louis Allain,Sébastien Da Veiga,Brian Staber*

Main category: math.ST

TL;DR: 本文提出了一种新的非对称共形预测方法，通过引入促进对称性的惩罚项来适应噪声分布的偏态特性，同时保持预测区间的自适应性。


<details>
  <summary>Details</summary>
Motivation: 现有共形预测方法忽视了噪声或残差可能存在的偏态特征，尤其在预测模型存在偏差时更为显著，本文旨在填补这一研究空白。

Method: 基于再生核希尔伯特空间和核平方和框架，构建带有对称性惩罚项的学习问题，并推导出对偶形式以提高可扩展性；采用新的数据驱动方法选择惩罚强度。

Result: 所提方法能够在对称与非对称预测区间之间平滑过渡，实验证明其在小样本或有偏模型下能更好地适应数据。

Conclusion: 允许一定程度的不对称性有助于提升预测区间的适应性和可靠性，特别是在噪声分布偏斜的情况下。

Abstract: Conformal prediction (CP) is a distribution-free method to construct reliable prediction intervals that has gained significant attention in recent years. Despite its success and various proposed extensions, a significant practical feature which has been overlooked in previous research is the potential skewed nature of the noise, or of the residuals when the predictive model exhibits bias. In this work, we leverage recent developments in CP to propose a new asymmetric procedure that bridges the gap between skewed and non-skewed noise distributions, while still maintaining adaptivity of the prediction intervals. We introduce a new statistical learning problem to construct adaptive and asymmetric prediction bands, with a unique feature based on a penalty which promotes symmetry: when its intensity varies, the intervals smoothly change from symmetric to asymmetric ones. This learning problem is based on reproducing kernel Hilbert spaces and the recently introduced kernel sum-of-squares framework. First, we establish representer theorems to make our problem tractable in practice, and derive dual formulations which are essential for scalability to larger datasets. Second, the intensity of the penalty is chosen using a novel data-driven method which automatically identifies the symmetric nature of the noise. We show that consenting to some asymmetry can let the learned prediction bands better adapt to small sample regimes or biased predictive models.

</details>


### [97] [Persuasive Privacy](https://arxiv.org/abs/2601.22945)
*Joshua J Bon,James Bailie,Judith Rousseau,Christian P Robert*

Main category: math.ST

TL;DR: 提出了一种基于贝叶斯博弈论的隐私度量新框架，能够生成有严格依据的新隐私定义，并解释现有隐私保证，揭示了差分隐私是其特例，且可为确定性算法提供隐私保障。


<details>
  <summary>Details</summary>
Motivation: 现有的隐私标准无法涵盖确定性算法，且缺乏对隐私定义的严谨理论支持，因此需要一个更通用、可解释的隐私度量框架。

Method: 采用贝叶斯博弈论的方法构建隐私度量框架，通过博弈模型分析个体在信息释放中的策略选择，从而形式化隐私保护程度。

Result: 证明了纯差分隐私和概率差分隐私是该框架的特例，重新解释了后处理不等式，并展示了该框架可为确定性算法建立隐私保证。

Conclusion: 所提出的框架为隐私提供了更广泛的理论基础，不仅统一了现有隐私概念，还扩展了隐私保护的适用范围至传统方法忽略的确定性算法。

Abstract: We propose a novel framework for measuring privacy from a Bayesian game-theoretic perspective. This framework enables the creation of new, purpose-driven privacy definitions that are rigorously justified, while also allowing for the assessment of existing privacy guarantees through game theory. We show that pure and probabilistic differential privacy are special cases of our framework, and provide new interpretations of the post-processing inequality in this setting. Further, we demonstrate that privacy guarantees can be established for deterministic algorithms, which are overlooked by current privacy standards.

</details>


### [98] [Semi-knockoffs: a model-agnostic conditional independence testing method with finite-sample guarantees](https://arxiv.org/abs/2601.23124)
*Angel Reyero-Lobo,Bertrand Thirion,Pierre Neuvial*

Main category: math.ST

TL;DR: 提出了一种名为Semi-knockoffs的条件独立性检验方法，适用于任意预训练模型，无需训练-测试分割，提供有效的p值和高维情况下的错误发现率控制。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的条件独立性检验方法通常需要训练-测试分割或强假设（如已知输入分布），限制了统计功效和实用性。

Method: 利用预训练模型结合半敲除变量（semi-knockoffs）构造检验统计量，仅依赖于连续变量的条件期望，并通过稳定性分析与双重稳健性保证推断有效性。

Result: 该方法避免了数据分割，提升了统计功效；在高维设置下仍能提供有效的p值和FDR控制；理论贡献包括正则化模型在零特征下的稳定性及双重稳健性。

Conclusion: Semi-knockoffs是一种更灵活、实用且统计上可靠的CIT方法，便于与现代机器学习模型集成。

Abstract: Conditional independence testing (CIT) is essential for reliable scientific discovery. It prevents spurious findings and enables controlled feature selection. Recent CIT methods have used machine learning (ML) models as surrogates of the underlying distribution. However, model-agnostic approaches require a train-test split, which reduces statistical power. We introduce Semi-knockoffs, a CIT method that can accommodate any pre-trained model, avoids this split, and provides valid p-values and false discovery rate (FDR) control for high-dimensional settings. Unlike methods that rely on the model-$X$ assumption (known input distribution), Semi-knockoffs only require conditional expectations for continuous variables. This makes the procedure less restrictive and more practical for machine learning integration. To ensure validity when estimating these expectations, we present two new theoretical results of independent interest: (i) stability for regularized models trained with a null feature and (ii) the double-robustness property.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [99] [Leveraging Interactions for Efficient Swarm-Based Brownian Computing](https://arxiv.org/abs/2601.22874)
*Alessandro Pignedoli,Atreya Majumdar,Karin Everschor-Sitte*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一种受群体智能启发的优化方法，利用热驱动布朗准粒子之间的短程吸引相互作用实现高效能计算。通过调节相互作用强度和群体规模，该系统能可靠地找到全局最优解，并在动态变化的环境中表现出强适应性。


<details>
  <summary>Details</summary>
Motivation: 受到自然界中群体智能的启发，探索无需中心协调即可实现高效优化的物理机制，以开发低能耗、可扩展的非常规计算平台。

Method: 构建基于布朗准粒子的物理模型，引入短程吸引力，并在空间温度分布构成的优化景观中模拟其行为；通过粗粒化动力学到传感器晶格上，生成类似粒子追踪测量的轨迹，验证实验可行性。

Result: 相互作用的准粒子群在特定参数范围内显著优于非相互作用个体，能够通过局部交互产生协同行为，有效发现全局最优解，并对时变环境具有鲁棒适应能力。

Conclusion: 相互作用的布朗准粒子构成了一种可扩展且节能的非常规计算物理平台，为未来低功耗优化计算提供了新途径。

Abstract: Drawing inspiration from swarm intelligence, we show that short-range attractive interactions between thermally driven Brownian quasiparticles enable energy-efficient optimization. As quasiparticles can be generated directly within a material, the swarm size can be adjusted with minimal energy overhead. Using an optimization task defined by a spatially varying temperature landscape, we quantitatively show that interacting swarms reliably identify global optima and significantly outperform non-interacting searchers within a well-defined regime of interaction strength and swarm size. This improvement arises from emergent cooperative behavior, where local interactions guide the swarm toward high-quality solutions without central coordination. To link our physical model to experimental realizations, we coarse-grain the quasiparticle dynamics onto a sensor lattice and generate trajectories emulating particle-tracking measurements. We further show that the interacting swarm adapts robustly to landscapes that evolve over time. These findings establish interacting Brownian quasiparticles as a physical platform for scalable and energy-efficient unconventional computing.

</details>


### [100] [Smart Walkers in Discrete Space](https://arxiv.org/abs/2601.22235)
*Gianluca Peri,Lorenzo Buffoni,Giacomo Chiti,Duccio Fanelli,Raffaele Marino,Andrea Nocentini,Pier Paolo Panti*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了在离散空间中移动的可训练智能体的统计特性，从完全随机行走者出发，扩展到使用强化学习进行学习和适应的智能体，并提出配置熵作为衡量智能体学习能力的可靠指标。


<details>
  <summary>Details</summary>
Motivation: 探索智能体在离散空间中的运动统计特性及其通过学习适应环境的能力。

Method: 引入数学框架分析两个完全随机行走者的动态，然后扩展到能根据外部奖励信号学习的智能体，利用强化学习方法，并通过数值模拟与分析相结合的方式验证假设。

Result: 发现智能体能够改变遭遇的统计特性以最大化累积奖励；配置熵被证明是评估智能体任务应对能力的可靠指标，即使没有其他信息也可使用。

Conclusion: 配置熵可以有效衡量智能体的学习技能，该结论通过Stockfish国际象棋引擎对抗 quasi-随机未训练对手的实验得到支持。

Abstract: We study the statistical properties of trainable agents moving in discrete space. After introducing the mathematical framework, we first analyze the dynamics of two completely random walkers, mutually competing in a chaser-target interaction scheme. The statistics of the encounters is analytically obtained and the predictions tested versus numerical simulations. We then move forward to extend the baseline case to agents capable of learning and adapting to an external reward signal, using reinforcement learning. Smart walkers morph the statistics of the encounter, to maximize their cumulated reward, as confirmed by combined numerical and analytical insights. More interestingly, configuration entropy proves a reliable proxy to gauge the acquired ability of the agents to cope with the assigned task when no other information about them (i.e. reward signal, policy, etc) is present. We further test the proposed measure of learned skills by operating the Stockfish chess engine against a quasi-random untrained opponent. The obtained conclusions corroborate our claim.

</details>


### [101] [Synchronization and phase transition of two-dimensional self-rotating clock models](https://arxiv.org/abs/2601.22840)
*Xin Wu,Mingcheng Yang*

Main category: cond-mat.stat-mech

TL;DR: 研究了二维局部耦合离散态振荡器在热涨落下的同步现象，发现当q≥5时系统经历两步BKT相变，出现临界同步相和时空模式相，前者表现为代数衰减的空间关联和发散的相干时间，实现了连续时间晶体。


<details>
  <summary>Details</summary>
Motivation: 探索二维离散态振荡器在热噪声下是否能实现稳定同步，并研究其相变行为与时间晶体的可能性。

Method: 采用自旋转q态钟模型作为原型，结合大规模蒙特卡洛模拟和平均场理论进行分析。

Result: 当q≥5时，系统出现两步BKT相变：先到临界同步相（具代数衰减关联和发散相干时间），再到时空模式相（含振荡液滴态和稳定螺旋波态）；q<5时同步相消失；平均场理论预测q_c^MF=4。

Conclusion: 二维局部耦合离散振荡器在q≥5时可实现临界同步相，支持连续时间晶体的存在，但其临界值依赖于维度和涨落效应。

Abstract: We explore possible synchronization in two-dimensional (2D) locally coupled discrete-state oscillators under thermal fluctuations, using the self-rotating $q$-state clock model as a prototype. Large-scale Monte Carlo simulations reveal that for $q \ge q_c$ (with $q_c = 5$), the system undergoes two-step Berezinskii-Kosterlitz-Thouless (BKT) transitions: first from a disordered phase to a critical synchronized phase, and then to a spatiotemporal pattern phase. The latter includes oscillatory droplet states that survive in finite systems and a thermodynamically stable spiral wave state. Notably, the synchronized phase features algebraically decaying spatial correlations, alongside divergent coherence time, thus realizing a continuous time crystal; while it vanishes when $q < q_c$. Mean-field theory supports the existence of the synchronized phase, but predicts a lower critical value $q_c^{MF} = 4$.

</details>


### [102] [Non-Equilibrium Quantum Many-Body Physics with Quantum Circuits](https://arxiv.org/abs/2601.22375)
*Bruno Bertini*

Main category: cond-mat.stat-mech

TL;DR: 本文介绍了砖砌量子电路的设置，并展示了其在研究局域相互作用下非平衡量子多体动力学中的应用，同时提供了若干可精确计算动力学和谱性质的例子。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解局域相互作用下的非平衡量子多体系统，需要一个有效的理论框架来描述量子关联的演化。

Method: 采用砖砌量子电路模型，通过类比局域哈密顿量的方法分析量子关联的演化，并构造可解模型以精确计算动力学和谱性质。

Result: 证明了砖砌量子电路与局域哈密顿量在演化量子关联方面的相似性，并在非平庸相互作用下实现了多个动力学和谱性质的精确计算。

Conclusion: 砖砌量子电路是一个研究非平衡量子多体动力学的有效框架，尤其在存在强相互作用时仍允许部分精确解的存在。

Abstract: These are the notes for the 4.5-hour course with the same title that I delivered in August 2025 at the Les Houches summer school ``Exact Solvability and Quantum Information''. In these notes I pedagogically introduce the setting of brickwork quantum circuits and show that it provides a useful framework to study non-equilibrium quantum many-body dynamics in the presence of local interactions. I first show that brickwork quantum circuits evolve quantum correlations in a way that is fundamentally similar to local Hamiltonians, and then present examples of brickwork quantum circuits where, surprisingly, one can compute exactly several relevant dynamical and spectral properties in the presence of non-trivial interactions.

</details>


### [103] [Noise-Assisted Metastability: From Lévy Flights to Memristors, Quantum Escape, and Josephson-based Axion Searches](https://arxiv.org/abs/2601.22635)
*Claudio Guarcello,Alexander A. Dubkov,Davide Valenti,Bernardo Spagnolo*

Main category: cond-mat.stat-mech

TL;DR: 本文综述了噪声辅助的稳定性和亚稳态动力学的统计特性在多体和复杂系统中的作用，涵盖了从经典到量子系统的非线性弛豫过程。


<details>
  <summary>Details</summary>
Motivation: 理解复杂系统中由于亚稳态构型和环境涨落导致的缓慢非线性弛豫机制，并探索噪声在非平衡系统动力学中的关键作用。

Method: 通过讨论Lévy飞行驱动的逃逸过程、忆阻器件中的随机电阻切换、驱动耗散量子双稳态以及约瑟夫森结中的开关时间统计，建立统一的研究框架。

Result: 揭示了平滑亚稳势中由Lévy飞行引起的非单调驻留时间行为；展示了噪声如何增强忆阻器的稳定性与可重复性；阐明了外部驱动与系统-环境耦合对量子逃逸路径和寿命的影响；提出基于轴子诱导共振激活信号的实验性轴子探测策略。

Conclusion: 噪声在复杂系统的亚稳态动力学中起着关键调控作用，不仅影响经典系统中的弛豫行为，也在量子系统中提供了新的探测手段，如轴子检测。

Abstract: Many-body and complex systems, both classical and quantum, often exhibit slow, nonlinear relaxation toward stationary states due to the presence of metastable configurations and environmental fluctuations. Nonlinear relaxation in a wide variety of natural systems proceeds through metastable states, which arise in condensed-matter physics as well as in fields ranging from cosmology and biology to high-energy physics. Moreover, noise-induced phenomena play a central role in shaping the dynamics of such systems far from equilibrium. This review develops a unifying perspective centered on noise-assisted stabilization and the statistical properties of metastable dynamics. We first discuss escape processes driven by Lévy flights in smooth metastable potentials, emphasizing the emergence of nonmonotonic residence-time behavior. We then connect these concepts to stochastic resistive switching in memristive devices, where noise-induced effects can enhance stability and reproducibility. We further examine driven dissipative quantum bistability, showing how the interplay between external driving and system-environment coupling reshapes escape pathways and lifetimes. Finally, we outline how switching-time statistics in current-biased Josephson junctions can provide an experimentally accessible strategy for axion detection, based on an axion-induced resonant-activation signature.

</details>


### [104] [Spectral insights into active matter: Exceptional Points and the Mathieu equation](https://arxiv.org/abs/2601.22733)
*Horst-Holger Boltz,Thomas Ihle*

Main category: cond-mat.stat-mech

TL;DR: 本文通过微扰理论和具有纯虚参数的Mathieu方程的已知结果，解释了噪声自驱动粒子系统中普遍存在的标度关系，并揭示了高活性极限下异常点级联导致非平凡分数标度指数的现象。


<details>
  <summary>Details</summary>
Motivation: 解释近期在噪声自驱动粒子系统中发现的普适标度关系的物理机制。

Method: 采用微扰理论结合Mathieu方程的数学性质进行分析，重点研究Fokker-Planck算符在自由自驱动情况下的行为。

Result: 发现了由异常点级联引起的非平凡分数标度指数，并指出这些特性源于对应于自由自驱动的Fokker-Planck算符。

Conclusion: 噪声活性物质的动力学中存在一种可视为动力学相变的现象，其普适标度关系可通过微扰理论稳健解释。

Abstract: We show that recent numerical findings of universal scaling relations in systems of noisy, aligning self-propelled particles by Kürsten [Kürsten, arXiv:2402.18711v2 [cond-mat.soft] (2025)] can robustly be explained by perturbation theory and known results for the Mathieu equation with purely imaginary parameter. In particular, we highlight the significance of a cascade of exceptional points that leads to non-trivial fractional scaling exponents in the singular-perturbation limit of high activity. Crucially, these features are rooted in the Fokker-Planck operator corresponding to free self-propulsion. This can be viewed as a dynamical phase transition in the dynamics of noisy active matter.

</details>


### [105] [Entanglement Hamiltonians in dissipative free fermions and the time-dependent GGE](https://arxiv.org/abs/2601.23234)
*Riccardo Travaglino,Federico Rottoli,Pasquale Calabrese*

Main category: cond-mat.stat-mech

TL;DR: 研究了耗散自由费米子系统中纠缠哈密顿量的动力学，发现在弱耗散和长时间极限下，其演化可由普适的时间依赖广义吉布斯系综（t-GGE）描述，且该行为在不同初态下具有普适性。


<details>
  <summary>Details</summary>
Motivation: 理解开放量子系统中纠缠演化的普适规律，特别是在耗散环境下纠缠哈密顿量的动力学行为。

Method: 基于最近提出的准粒子图像的算符形式，研究增益与损失耗散下的淬火后演化，并推导弹道尺度上的纠缠哈密顿量表达式。

Result: 在长时间和弱耗散条件下，纠缠哈密顿量呈现出时间依赖的广义吉布斯系综（t-GGE）形式，且该结构在不同初始状态下具有普适性；准粒子图像可完全解释t-GGE的出现。

Conclusion: 当林德布拉德主方程存在适当的粗粒化表示时，准粒子图像框架下的t-GGE描述仍然成立，表明该机制在自由费米子耗散系统中具有广泛适用性。

Abstract: We investigate the dynamics of Entanglement Hamiltonians (EHs) in dissipative free-fermionic systems using a recent operator-based formulation of the quasiparticle picture. Focusing on gain and loss dissipation, we study the post-quench evolution and derive explicit expressions for the EH at the ballistic scale. In the long-time and weak-dissipation regime, the EH is shown to take the form of a time-dependent Generalized Gibbs Ensemble (t-GGE), with a structure that is universal across different initial states of the quench protocol. Within this framework, the emergence of the t-GGE is fully accounted for by the quasiparticle picture, and we argue that this description remains valid whenever the Lindbladian admits an appropriate coarse-grained representation.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [106] [Stablecoin Design with Adversarial-Robust Multi-Agent Systems via Trust-Weighted Signal Aggregation](https://arxiv.org/abs/2601.22168)
*Shengwei You,Aditya Joshi,Andrey Kuehlkamp,Jarek Nabrzyski*

Main category: q-fin.RM

TL;DR: 本文提出MVF-Composer，一种基于信任加权的均值-方差前沿储备控制器，通过引入压力测试机制和多智能体仿真来增强算法稳定币在极端市场条件下的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有算法稳定币储备控制模型（如SAS）在估计风险时忽略尾部事件，导致在极端波动下失效，例如2020年Black Thursday事件中出现严重脱锚和损失。

Method: 设计MVF-Composer，结合信任评分机制T: A -> [0,1]，利用多智能体模拟作为对抗性压力测试工具，识别危机场景下的储备漏洞，并加权过滤恶意信号以提高鲁棒性。

Result: 在1,200次含黑天鹅冲击的随机场景中，相比SAS基线，峰值脱锚减少57%，平均恢复时间缩短3.1倍；消融实验显示信任层在对抗条件下贡献23%的稳定性增益，且能实现72%的对抗智能体检测率。

Conclusion: MVF-Composer通过引入可信赖的风险状态估计与对抗性压力测试，显著提升算法稳定币在极端市场环境中的韧性，且无需额外链上预言机，具备实际部署与复现价值。

Abstract: Algorithmic stablecoins promise decentralized monetary stability by maintaining a target peg through programmatic reserve management. Yet, their reserve controllers remain vulnerable to regime-blind optimization, calibrating risk parameters on fair-weather data while ignoring tail events that precipitate cascading failures. The March 2020 Black Thursday collapse, wherein MakerDAO's collateral auctions yielded $8.3M in losses and a 15% peg deviation, exposed a critical gap: existing models like SAS systematically omit extreme volatility regimes from covariance estimates, producing allocations optimal in expectation but catastrophic under adversarial stress.
  We present MVF-Composer, a trust-weighted Mean-Variance Frontier reserve controller incorporating a novel Stress Harness for risk-state estimation. Our key insight is deploying multi-agent simulations as adversarial stress-testers: heterogeneous agents (traders, liquidity providers, attackers) execute protocol actions under crisis scenarios, exposing reserve vulnerabilities before they manifest on-chain. We formalize a trust-scoring mechanism T: A -> [0,1] that down-weights signals from agents exhibiting manipulative behavior, ensuring the risk-state estimator remains robust to signal injection and Sybil attacks.
  Across 1,200 randomized scenarios with injected Black-Swan shocks (10% collateral drawdown, 50% sentiment collapse, coordinated redemption attacks), MVF-Composer reduces peak peg deviation by 57% and mean recovery time by 3.1x relative to SAS baselines. Ablation studies confirm the trust layer accounts for 23% of stability gains under adversarial conditions, achieving 72% adversarial agent detection. Our system runs on commodity hardware, requires no on-chain oracles beyond standard price feeds, and provides a reproducible framework for stress-testing DeFi reserve policies.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [107] [Modeling of Non-linear Dynamics of Lithium-ion Batteries via Delay-Embedded Dynamic Mode Decomposition](https://arxiv.org/abs/2601.22403)
*Khalid Mahmud Labib,Shabbir Ahmed*

Main category: eess.SY

TL;DR: 提出了一种基于动态模态分解（DMD）的数据驱动模型，用于高效捕捉锂离子电池的非线性动态特性，仅使用电压和电流数据即可在不同荷电状态和老化水平下预测端电压。


<details>
  <summary>Details</summary>
Motivation: 锂离子电池的复杂电化学行为导致其具有非线性动力学特征，传统建模方法依赖材料细节且计算成本高，因此需要一种不依赖内部结构、高效且准确的建模方法。

Method: 采用动态模态分解（DMD）和带控制的DMD（DMDc）方法，利用HPPC测试中的电压和电流数据构建状态空间矩阵，并通过时间延迟嵌入构造快照；使用60%的单次测试数据训练模型，优化嵌入维度以最小化残差平方和（RSS）。系统矩阵A和B在电池健康状态下识别后固定，仅通过更新输入控制信号来模拟老化电池的行为。

Result: DMDc模型在嵌入维数为1810时达到最低RSS误差3.86，标准DMD为30；输入信号的最佳嵌入维数为6，对应RSS为1.74；该模型能有效捕捉电压骤降和瞬态响应等关键内部动态，即使在电池老化后仍保持良好预测能力。

Conclusion: 所提出的DMDc数据驱动模型能够高效、准确地建模锂离子电池的非线性动态行为，适用于不同SOC和老化程度的电池，具有较高的计算效率和应用潜力于电池管理系统中。

Abstract: The complex electrochemical behavior of lithium-ion batteries results in non-linear dynamics and appropriate modeling of this non-linear dynamical system is of interest for better management and control. In this work, we proposed a family of dynamic mode decomposition (DMD)-based data-driven models that do not require detailed knowledge of the composition of the battery materials but can essentially capture the non-linear dynamics with higher computational efficiency. Only voltage and current data obtained from hybrid pulse power characterization (HPPC) tests were utilized to form the state space matrices and subsequently used for predicting the future terminal voltage at different state of charge (SoC) and aging levels. To construct the system model, 60\% of the data from a single HPPC test was utilized to generate time-delay embedded snapshots, with embedding dimension ranging from 40 to 2000. Among these, an embedding dimension of 1810 resulted in the least residual sum of squares (RSS) error of 3.86 for the dynamic mode decomposition with control (DMDc) model and 30 for the standard DMD model. For DMDc model, delay embeddings (ranging from 1 to 12) were also incorporated into the input current signals. For the input matrix, an embedding dimension of 6 resulted in a minimum RSS error of 1.74. Furthermore, the system matrices A and B, identified from the HPPC test when the cell is in its healthy state, were held fixed and used to simulate the system dynamics for aged batteries by updating only the control input. Despite the presence of nonlinear degradation effects in later cycles, the DMDc model effectively captured key inner dynamics such as voltage dips and transient responses for subsequent charge and discharge cycles.

</details>


### [108] [Approximately Optimal Multi-Stream Quickest Change Detection for Gaussian Streams](https://arxiv.org/abs/2601.22561)
*Joshua Kartzman,Calvin Hawkins,Matthew Hale*

Main category: eess.SY

TL;DR: 本文研究了在未知变化方向和幅度的情况下，带老虎机的快速变化检测问题，提出了一种结合衰减ε-贪婪策略和高效变点检测算法的方法，并证明了其近似最优性。


<details>
  <summary>Details</summary>
Motivation: 在无法观测所有数据流且变化参数未知的情况下，如何快速准确地检测到变化点并控制误报率。

Method: 采用衰减ε-贪婪策略选择观测的数据流，并结合适用于未知后变化均值的变点检测算法。

Result: 给出了检测延迟和平均误报时间的理论界限，证明了算法在常见替代目标下的近似最优性。

Conclusion: 所提算法在无需强假设（如离散化参数空间或变化幅度下限）的情况下，首次在该设定中提供了可证明的性能保证。

Abstract: This paper considers the bandit quickest change detection problem in which one stream contains a change-point that shifts its distribution by an unknown amount in an unknown direction. We consider an agent that can observe only a single stream at each time, and the goal of the agent is to detect this change as quickly as possible while controlling for false alarms. We propose an algorithm that combines a decaying-$ε$-greedy stream switching rule with an efficient change-point detection algorithm for unknown post-change means. We provide bounds on the expected detection delay and average run length to false alarm for our algorithm, and based on these results we prove our algorithm is approximately optimal with respect to a commonly used surrogate. This work is the first to provide provable guarantees in this setting without strong assumptions such as a discretized post-change parameter set or a lower bound on the magnitude of change.

</details>


### [109] [Robust Control of Constrained Linear Systems using Online Convex Optimization and a Reference Governor](https://arxiv.org/abs/2601.23160)
*Marko Nonhoff,Mohammad Taher Al Torshan,Matthias A. Müller*

Main category: eess.SY

TL;DR: 提出了一种针对线性时不变系统在时变未知代价函数和外部扰动下的控制方法，结合在线凸优化、参考调节器与约束收紧策略，保证递归可行性与约束满足，并分析了动态遗憾性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对线性时不变系统在存在时变且先验未知的代价函数以及外部扰动时的控制挑战，同时满足状态和输入约束。

Method: 将在线凸优化框架与参考调节器和约束收紧方法相结合，构建闭环控制系统。

Result: 该方法保证了递归可行性和鲁棒约束满足，且其动态遗憾与代价函数的变化及扰动幅度呈线性关系。

Conclusion: 所提方法有效处理了不确定环境下的约束控制问题，在理论性能和实际应用之间取得了良好平衡。

Abstract: This article develops a control method for linear time-invariant systems subject to time-varying and a priori unknown cost functions, that satisfies state and input constraints, and is robust to exogenous disturbances. To this end, we combine the online convex optimization framework with a reference governor and a constraint tightening approach. The proposed framework guarantees recursive feasibility and robust constraint satisfaction. Its closed-loop performance is studied in terms of its dynamic regret, which is bounded linearly by the variation of the cost functions and the magnitude of the disturbances. The proposed method is illustrated by a numerical case study of a tracking control problem.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [110] [Understanding the sign problem from an exact Path Integral Monte Carlo model of interacting harmonic fermions](https://arxiv.org/abs/2601.22559)
*Siu A. Chin*

Main category: cond-mat.str-el

TL;DR: 本文将算子收缩恒等式应用于费米子系统，提出了一种可精确求解的模型来研究符号问题，并发现相互作用和闭壳层电子数对符号问题的影响。


<details>
  <summary>Details</summary>
Motivation: 探索路径积分中费米子符号问题的根源，并寻找可精确求解的模型以更好地理解该问题。

Method: 应用算子收缩恒等式到任意维度的费米子系统，结合四阶和新提出的变珠算法进行数值计算。

Result: 发现成对相互作用会改变符号问题出现的时间尺度但不加剧其严重性；闭壳层电子数下大虚时间时符号问题消失；成功计算了含至110个电子的量子点基态能量。

Conclusion: 该方法为研究费米子符号问题提供了新的解析与数值工具，揭示了闭壳层结构在抑制符号问题中的关键作用。

Abstract: This work shows that the recently discovered operator contraction identity for solving the discreet Path Integral of the harmonic oscillator can be applied equally to fermions in any dimension. This then yields an exactly solvable model for studying the sign problem where the Path Integral Monte Carlo energy at any time step for any number of fermions is known analytically, or can be computed numerically. It is found that repulsive/attractive pairwise interaction shifts the sign problem to larger/smaller imaginary time, but does not make it more severe than the non-interacting case. More surprisingly, for closed-shell number of fermions, the sign problem goes away at large imaginary time. Fourth-order and newly found variable-bead algorithms are used to compute ground state energies of quantum dots with up to 110 electrons and compared to results obtained by modern neural networks.

</details>


### [111] [Anisotropic Kitaev Spin Glass in Li$_{2}$Ru$_{x}$Ir$_{1-x}$O$_{3}$](https://arxiv.org/abs/2601.22280)
*Mayia A. Vranas,Alejandro Ruiz,Vikram Nagarajan,Erik Lamb,Gerald D. Morris,Zahir Islam,Christie Nelson,Benjamin A. Frandsen,James G. Analytis,Alex Frano*

Main category: cond-mat.str-el

TL;DR: 该研究通过在β-Li₂RuₓIr₁₋ₓO₃中引入稀释的Ru掺杂（x ≲ 10%），发现弱磁性无序可抑制长程反铁磁序，并稳定一种具有Kitaev交换特征的各向异性自旋玻璃态，为探索Kitaev量子自旋液体的退化性、各向异性和竞争相互作用提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 寻找实现量子自旋液体（QSL）的途径，尽管现有Kitaev候选材料在低温下仍出现磁有序，但理论表明Kitaev相互作用依然存在，因此尝试通过掺杂等扰动手段驱动系统进入QSL相。

Method: 采用稀释Ru掺杂的β-Li₂RuₓIr₁₋ₓO₃体系，结合磁化率测量、共振弹性X射线散射、交流热容和μ子自旋弛豫/共振等多种实验技术，研究弱磁性无序对Kitaev系统的影响。

Result: 发现稀释Ru掺杂能抑制长程反铁磁序，诱导形成各向异性自旋玻璃态，该态保留了Kitaev交换的关键特征，如磁化率和热剩磁中的显著方向各向异性。

Conclusion: 稀释磁性无序可实现接近Kitaev量子自旋液体的各向异性自旋玻璃相，冻结了Kitaev的阻挫背景，为理解其退化性与竞争相互作用提供了新视角。

Abstract: Kitaev iridates have been proposed as candidates for realizing an elusive quantum spin liquid (QSL) state, in which strong spin-orbit coupling and bond-directional exchange generate a highly frustrated and entangled ground state. However, all physical systems proposed to host this ground state, including Li$_2$IrO$_3$, Na$_2$IrO$_3$, and RuCl$_3$, develop magnetic order at low temperatures due to competing interactions. Nonetheless, theoretical modeling of experimental data has shown that Kitaev interactions are still present, motivating the application of perturbations such as pressure, magnetic field, and chemical doping to drive the system into the QSL phase. Here we study $β$-Li$_{2}$Ru$_{x}$Ir$_{1-x}$O$_{3}$ with dilute levels of Ru, $x \lesssim 10\%$. Through a combination of magnetometry, resonant elastic X-ray scattering, ac-heat capacity, and muon spin relaxation/resonance, we show that weak magnetic disorder suppresses long-range antiferromagnetic order and stabilizes an anisotropic spin glass that retains key signatures of Kitaev exchange. This Kitaev spin glass shows pronounced directional anisotropy in its magnetic susceptibility and thermoremenant magnetization. These results demonstrate that dilute magnetic disorder can access an anisotropic Kitaev spin glass: a proximate phase that freezes the Kitaev frustration landscape. This could provide a new window into the degeneracy, anisotropy, and competing interactions underlying the Kitaev QSL.

</details>


### [112] [Field-induced transitions from incommensurate to commensurate phases in helical antiferromagnets](https://arxiv.org/abs/2601.22343)
*P. T. Bolokhova,A. V. Syromyatnikov*

Main category: cond-mat.str-el

TL;DR: 研究了具有易面各向异性的海森堡反铁磁体中由Dzyaloshinskii-Moriya相互作用或交换耦合挫败诱导的磁螺旋，分析了小磁场对螺旋的扭曲效应，并推导了临界场表达式，理论应用于RbFe(MoO4)2等材料。


<details>
  <summary>Details</summary>
Motivation: 探讨在存在Dzyaloshinskii-Moriya相互作用或交换耦合挫败的情况下，如何通过外加磁场调控磁螺旋结构及其相变行为。

Method: 采用解析方法描述小磁场对磁螺旋结构的影响，推导出不同整数n对应的临界磁场表达式（n=2, 3, 4），并结合实验数据拟合模型参数。

Result: 发现外加磁场可连续调节磁结构矢量k0，并在k0接近g/n时引发非公度与公度磁序之间的相变；给出了n=2, 3, 4时的临界场表达式；改进了对RbFe(MoO4)2实验数据的描述。

Conclusion: 该理论为理解和调控具有螺旋磁序的低维磁性材料提供了有效框架，且对多种材料具有广泛适用性。

Abstract: Heisenberg antiferromagnet with an easy-plane anisotropy is discussed in which a magnetic spiral is induced by Dzyaloshinskii-Moriya interaction and/or frustration of the exchange coupling. The distortion of the spiral by small in-plane magnetic field is described analytically. It is found that the field can gradually change the vector of the magnetic structure ${\bf k}_0$ and can produce transitions between phases with incommensurate and commensurate magnetic orderings when ${\bf k}_0$ is close to ${\bf g}/n$, where ${\bf g}$ is a reciprocal lattice vector and $n$ is integer. Analytical expressions for critical fields are derived for $n=2$, 3, and 4. Application of the theory to the triangular-lattice compound $\rm RbFe(MoO_4)_2$ is discussed alongside its potential applicability to other materials. As a by-product of the main consideration, model parameters are found which describe more accurately the full set of available experimental data suggested before for $\rm RbFe(MoO_4)_2$.

</details>


### [113] [Electronic band structure, phonon dispersion, and magnetic triple-q state in GdGaI](https://arxiv.org/abs/2601.22463)
*Tatsuya Kaneko,Ryota Mizuno,Shu Kamiyama,Hideo Miyamoto,Masayuki Ochi*

Main category: cond-mat.str-el

TL;DR: 本文通过第一性原理计算研究了磁性范德瓦尔斯材料GdGaI的物理性质，构建了包含Gd 5d和Ga 4p轨道的紧束缚模型，并探讨了由RKKY机制驱动的磁序起源，指出费米能级附近的库仑相互作用可能促进局域自旋有序。


<details>
  <summary>Details</summary>
Motivation: 探究GdGaI这一磁性范德瓦尔斯材料的电子结构与磁性起源，理解其是否存在不稳定性以及磁序形成的微观机制。

Method: 采用第一性原理计算方法分析声子色散和能带结构，构建基于Gd 5d和Ga 4p轨道的紧束缚模型，并引入Gd 5d电子与Gd 4f局域自旋之间的近藤耦合来研究磁结构。

Result: 声子谱无虚频，表明GdGaI不易发生声子驱动的相变；费米能级附近的能带主要由Gd 5d和Ga 4p轨道构成；当局域自旋形成由三个q矢量表征的磁序时，能带结构被调制；RKKY机制和费米面附近的库仑相互作用对自旋有序有贡献。

Conclusion: GdGaI具有良好的晶格动力学稳定性，其磁序可能源于RKKY相互作用，并受近藤耦合和库仑作用共同影响，为理解磁性vdW材料中的多体效应提供了理论依据。

Abstract: We theoretically investigate the physical properties of the magnetic van der Waals material GdGaI. Using first-principles calculations, we compute the phonon dispersion of GdGaI and show no imaginary phonons, suggesting that phonon-driven phase transitions are unlikely to occur in GdGaI. Our band calculation reveals that the electronic bands near the Fermi energy are composed of Gd 5d and Ga 4p orbitals. We construct a tight-binding model that incorporates the Gd 5d and Ga 4p orbitals to investigate the magnetic structure. We introduce Kondo coupling between electrons in Gd 5d orbitals and localized spins in Gd 4f orbitals and present the modified band structure when localized spins form a magnetic order characterized by three q vectors that connect the valence and conduction bands. We discuss the origin of the spin order based on the Ruderman-Kittel-Kasuya-Yosida mechanism and suggest that Coulomb interactions acting on electrons near the Fermi level can contribute to the ordering of localized spins.

</details>


### [114] [Interaction induced topological magnon in electron-magnon coupled systems](https://arxiv.org/abs/2601.22566)
*Kosuke Fujiwara,Takahiro Morimoto*

Main category: cond-mat.str-el

TL;DR: 该研究探讨了在电子-磁振子耦合系统中拓扑磁振子的产生机制，发现即使没有强Dzyaloshinskii-Moriya相互作用，通过与巡游电子系统的耦合，普通铁磁体也能支持拓扑磁振子。


<details>
  <summary>Details</summary>
Motivation: 探索无需强Dzyaloshinskii-Moriya相互作用即可实现拓扑磁振子的新机制。

Method: 理论分析电子-磁振子耦合系统中的磁振子能带结构变化，特别是在铁磁绝缘体和过渡金属二硫化物异质结构中的情况。

Result: 发现在交换耦合下，电子-磁振子相互作用可导致有效时间反演对称性破缺，从而打开拓扑能隙。

Conclusion: 普通铁磁体可通过与巡游电子系统耦合实现拓扑磁振子，为设计拓扑磁学器件提供了新途径。

Abstract: We theoretically study the emergence of topological magnons in electron-magnon coupled systems. The magnon dispersion in a ferromagnet usually possesses an effective time reversal symmetry in the absence of Dzyaloshinskii-Moriya (DM) interaction, preventing the appearance of topological magnons. When a spin system is coupled to itinerant electrons, we find that the magnon band structure of the spin system experiences time-reversal symmetry breaking with the electron-magnon interaction via the exchange coupling, where topological magnons arise without requiring strong DM. Specifically, we consider a heterostructure consisting of a ferromagnetic insulator and a transition metal dichalcogenide (TMD) monolayer and investigate topological gap opening in magnon bands. Our findings reveal that even trivial ferromagnets can host topological magnons via coupling to itinerant electronic systems.

</details>


### [115] [N-state Potts ices as generalizations of classical and quantum spin ice](https://arxiv.org/abs/2601.22909)
*Mark Potts,Roderich Moessner,S. A. Parameswaran*

Main category: cond-mat.str-el

TL;DR: 本文研究了N态Potts冰模型，将其性质与su(N)李代数联系起来，并引入了量子推广版本，揭示了电荷激发在低能物理中的主导作用及对称性对动力学的影响。


<details>
  <summary>Details</summary>
Motivation: 为了更深入理解自旋液体物理，特别是经典和量子自旋冰模型中多U(1)规范场及其激发行为，扩展已有模型至N态Potts冰模型。

Method: 通过将经典N态Potts冰模型与su(N)李代数关联，分析其对称性和激发特性，并构建其量子推广模型，研究低能有效哈密顿量和对称性导致的通量真空阻挫效应。

Result: 建立了经典Potts冰模型与su(N)对称性的联系，揭示了激发粒子的电荷结构；提出了新的量子Potts冰模型，发现N>2时电荷味转换相互作用主导低能物理，并导致通量真空阻挫，显著改变激发的动力学行为。

Conclusion: N态Potts冰模型为研究多规范场和复合激发提供了新平台，su(N)对称性在理解和控制经典与量子冰模型中的激发和动力学中起核心作用。

Abstract: Classical and quantum spin ice models are amongst the most popular settings for the study of spin liquid physics. $N-$state Potts ice models have been constructed that generalize spin ice, hosting multiple emergent $\text{U}(1)$ gauge fields and excitations charged under non-trivial combinations of these fields. We present a general treatment of classical $N-$state Potts ices relating their properties to the $\mathfrak{su}(N)$ Lie algebras, and demonstrate how the properties of charged excitations in the classical model can be related to this symmetry group. We also introduce quantum generalizations of the Potts Ice models, and demonstrate how charge flavor changing interactions unique to $N>2$ models dominate their low energy physics. We further show how symmetries inherited from the $\mathfrak{su}(N)$ can lead to flux vacuum frustration, greatly modifying the dynamical properties of charged excitations.

</details>


### [116] [Spiral Phase and Phase Diagram of the $S$=1/2 XXZ Model on the Shastry-Sutherland Lattice](https://arxiv.org/abs/2601.22924)
*Zhengpeng Yuan,Muwei Wu,Dao-Xin Yao,Han-Qing Wu*

Main category: cond-mat.str-el

TL;DR: 研究了S=1/2 XXZ模型在二维Shastry-Sutherland晶格上的基态相图，结合ED、DMRG和CMFT方法，发现中间空四聚体（EP）相和未被报道的螺旋相，并解释了RE₂Be₂GeO₂中自旋液体样行为的起源。


<details>
  <summary>Details</summary>
Motivation: 探究XXZ各向异性对Shastry-Sutherland模型中基态相图的影响，特别是解释实验材料RE₂Be₂GeO₂中出现的自旋液体样行为。

Method: 采用精确对角化（ED）、密度矩阵重正化群（DMRG）和团簇平均场理论（CMFT）结合DMRG求解器的方法，分析不同Δ值下的基态相图。

Result: 发现中间存在能量更低的空四聚体（EP）相，但其随Δ偏离1而变窄并最终消失；首次识别出小Δ区域的螺旋相；EP、螺旋和xy-AFM相之间的竞争可解释RE₂Be₂GeO₂中的自旋液体样行为。

Conclusion: XXZ各向异性在Shastry-Sutherland模型中起关键作用，螺旋相的发现为理解相关材料中的奇异磁性行为提供了新视角。

Abstract: We investigate the ground-state phase diagram of the $S$=1/2 XXZ model on the two-dimensional Shastry-Sutherland lattice using exact diagonalization (ED), density-matrix renormalization group (DMRG), and cluster mean-field theory (CMFT) with DMRG as a solver. In the isotropic case ($Δ=1$), CMFT results reveal an intermediate empty plaquette (EP) phase that has a lower energy than the full plaquette (FP) phase. However, due to mean-field artifacts, CMFT alone is not suitable for accurately determining phase boundaries. Therefore, we combined three methods to map out the reliable phase diagram. Our calculations show that the EP phase narrows as $Δ$ deviates from unity and eventually vanishes. More importantly, we identify a spiral phase at small $Δ$, which has not been reported in previous studies. This phase is clearly captured by DMRG simulations on long cylindrical geometries. The competition between the EP, spiral, and $xy$-AFM phases near their boundaries provides a plausible explanation for the emergent spin-liquid-like behavior in RE$_2$Be$_2$GeO$_2$, while shedding new light on the role of XXZ anisotropy in the Shastry-Sutherland XXZ model.

</details>


### [117] [Conical Magnetic Structure and Atomic Displacements in Chiral Helimagnet Yb(Ni,Cu)$_3$Al$_9$ in Magnetic Fields along the Helical $c$ Axis](https://arxiv.org/abs/2601.23033)
*Takeshi Matsumura,Mitsuru Tsukagoshi,Shota Nakamura,Shigeo Ohara*

Main category: cond-mat.str-el

TL;DR: 研究了沿c轴施加磁场的单轴手性螺旋磁体Yb(Ni1-xCux)3Al9的圆锥磁态，通过共振X射线衍射观察到磁卫星峰消失，表明从圆锥态到场致铁磁态的转变。临界场在x=0时为4 T，在x=0.05时为7 T，这在磁化曲线中难以察觉。发现与圆锥序起始同时出现具有相同传播矢量的原子位移。基于磁结构的简单q=1模型的平均场计算讨论了TN和H∥c(Hcz)及H⊥c(Hcx)的临界场。提出TN和Hcz主要反映蜂窝Yb层内的主导层内交换相互作用，而Hcx由弱得多的层间耦合控制。


<details>
  <summary>Details</summary>
Motivation: 探究单轴手性螺旋磁体在沿其螺旋轴施加磁场时的磁性状态变化及其微观机制。

Method: 使用共振X射线衍射技术观测磁卫星峰的变化，并结合平均场理论计算分析磁结构模型。

Result: 观察到从圆锥磁态到铁磁态的转变，确定了不同掺杂浓度下的临界磁场值；发现原子位移与磁序同步出现；理论分析表明层内交换作用主导TN和Hcz，而层间耦合决定Hcx。

Conclusion: Yb(Ni1-xCux)3Al9的磁相变行为主要由层内交换相互作用控制，而层间耦合对横向临界场有显著影响。

Abstract: We investigated the conical magnetic state of a uniaxial chiral helimagnet Yb(Ni$_{1-x}$Cu$_x$)$_3$Al$_9$ induced in magnetic fields applied along the $c$ axis, which coincides with the helical axis at zero field. Using resonant X-ray diffraction, we clearly observed the disappearance of magnetic satellite peaks, corresponding to the transition from the conical to the field-induced ferromagnetic state. The critical fields were determined to be 4 T for $x=0$ and 7 T for $x= 0.05$, which were hardly discernible in the magnetization curves. We also found that atomic displacements with the same propagation vector emerge simultaneously with the onset of the conical order. The transition temperature $T_{\text{N}}$ and the critical fields for $H \parallel c$ ($H_{\text{c}}^{z}$) and $H\perp c$ ($H_{\text{c}}^{x}$) are discussed on the basis of a mean-field calculation for a simple $q=1$ model of the magnetic structure. We propose that $T_{\text{N}}$ and $H_{\text{c}}^{z}$ primarily reflect the dominant intralayer exchange interactions within the honeycomb Yb-layer, whereas $H_{\text{c}}^{x}$ is governed by the much weaker interlayer coupling.

</details>


### [118] [Magnetic field control of the excitonic transition in Ta$_2$NiSe$_5$](https://arxiv.org/abs/2601.23136)
*Giacomo Mazza*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The formation of excitonic insulator phases in quantum materials is often masked by structural distortions caused by the coupling between electronic and phononic order parameters. Here we show that the candidate material Ta$_2$NiSe$_5$ is characterized by a metastable excitonic insulating phase that is decoupled from the lattice, and that can be stabilized for sufficiently high applied magnetic fields. By considering the interplay between the excitonic and structural instabilities, we predict a magnetic field induced transition from the low-temperature structurally distorted semiconducting phase to an undistorted excitonic insulator phase with ground state loop currents. Before the transition, the existence of a latent excitonic phase can be detected by the magnetic field softening of the phonon mode associated with the structural distortion. These results highlight an unbiased route towards the disentanglement of the coupled excitonic-structural transition in Ta$_2$NiSe$_5$, and uncover a general mechanism for magnetic field control of competing phases in quantum materials.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [119] [Adaptive Benign Overfitting (ABO): Overparameterized RLS for Online Learning in Non-stationary Time-series](https://arxiv.org/abs/2601.22200)
*Luis Ontaneda Mijares,Nick Firoozye*

Main category: q-fin.ST

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Overparameterized models have recently challenged conventional learning theory by exhibiting improved generalization beyond the interpolation limit, a phenomenon known as benign overfitting. This work introduces Adaptive Benign Overfitting (ABO), extending the recursive least-squares (RLS) framework to this regime through a numerically stable formulation based on orthogonal-triangular updates. A QR-based exponentially weighted RLS (QR-EWRLS) algorithm is introduced, combining random Fourier feature mappings with forgetting-factor regularization to enable online adaptation under non-stationary conditions. The orthogonal decomposition prevents the numerical divergence associated with covariance-form RLS while retaining adaptability to evolving data distributions. Experiments on nonlinear synthetic time series confirm that the proposed approach maintains bounded residuals and stable condition numbers while reproducing the double-descent behavior characteristic of overparameterized models. Applications to forecasting foreign exchange and electricity demand show that ABO is highly accurate (comparable to baseline kernel methods) while achieving speed improvements of between 20 and 40 percent. The results provide a unified view linking adaptive filtering, kernel approximation, and benign overfitting within a stable online learning framework.

</details>
