<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 12]
- [stat.ME](#stat.ME) [Total: 13]
- [math.ST](#math.ST) [Total: 5]
- [physics.ao-ph](#physics.ao-ph) [Total: 2]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [quant-ph](#quant-ph) [Total: 39]
- [physics.soc-ph](#physics.soc-ph) [Total: 4]
- [hep-lat](#hep-lat) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 6]
- [nlin.CD](#nlin.CD) [Total: 1]
- [cs.CE](#cs.CE) [Total: 2]
- [cs.SI](#cs.SI) [Total: 2]
- [math.OC](#math.OC) [Total: 10]
- [eess.SY](#eess.SY) [Total: 7]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 10]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [Convergence Analysis of a Linear, Unconditionally Energy-Stable SAV Finite Element Method for the Cahn-Hilliard Equation](https://arxiv.org/abs/2602.21574)
*Na Li,Yongchao Zhao*

Main category: math.NA

TL;DR: 提出了一种基于标量辅助变量（SAV）方法的有限元格式，用于求解具有物理和数学意义的Cahn-Hilliard方程，并证明了其在时间和空间上的最优收敛性及无条件能量稳定性。


<details>
  <summary>Details</summary>
Motivation: Cahn-Hilliard方程在物理上具有重要意义且数学结构丰富，需要高效稳定的数值方法进行求解。

Method: 采用基于标量辅助变量（SAV）的有限元方法，构造全离散格式，并在适当的正则性假设下进行收敛性分析。

Result: 证明了相变量、化学势和辅助变量在H1范数下具有时间和空间的最优收敛阶，并证明了格式的无条件能量稳定性；数值实验验证了理论结果。

Conclusion: 所提出的SAV-based有限元格式对Cahn-Hilliard方程是有效且稳定的，兼具良好的收敛性和能量稳定性。

Abstract: This paper proposes a finite element scheme, based on the Scalar Auxiliary Variable (SAV) approach, for the Cahn-Hilliard equation--a model that possesses significant physical relevance and a rich mathematical structure. A convergence analysis of the fully discrete scheme is conducted under suitable regularity assumptions, confirming optimal-order convergence in both time and space for the phase variable, chemical potential, and auxiliary variable in the H1-norm. Furthermore, the scheme is proven to be unconditionally energy stable. Finally, a numerical example is presented to demonstrate the effectiveness of the method and to confirm the theoretical convergence rates.

</details>


### [2] [Adaptive isogeometric analysis of high-order phase-field fracture based on THB-splines](https://arxiv.org/abs/2602.21685)
*H. M. Verhelst,L. Greco,A. Reali*

Main category: math.NA

TL;DR: 本文提出了一种基于THB样条的自适应模拟方法，用于高阶相场模型（AT1和AT2）中的二维裂纹扩展仿真，旨在解决计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 相场模型在断裂力学中具有广泛应用，但其高计算成本限制了实际应用，尤其是高分辨率模拟需求下。因此，需要高效且精确的数值方法来降低计算负担。

Method: 采用截断分层B样条（THB-splines）实现局部网格自适应细化，并结合高阶相场模型（AT1和AT2）进行断裂模拟，提升计算效率与精度。

Result: 实现了对二维断裂问题的高效高精度模拟，显著降低了高阶相场模型的计算成本，同时保持良好的收敛性和裂纹路径预测能力。

Conclusion: 基于THB样条的自适应方法能有效支持高阶相场模型在断裂模拟中的应用，为复杂裂纹扩展问题提供了可行的数值解决方案。

Abstract: In recent decades, the study of fracture propagation in solids has increasingly relied on phase-field models. Several recent contributions have highlighted the potential of this approach in both static and dynamic frameworks. However, a major limitation remains the high computational cost. Two main strategies have been identified to mitigate this issue: the use of locally refined meshes and the adoption of higher-order models. In this work, leveraging Truncated Hierarchical B-splines (THB-splines), we introduce adaptive simulations of higher-order phase-field formulations (AT1 and AT2), focusing primarily on two-dimensional fracture problems.

</details>


### [3] [A dual lumping procedure for static condensation in mixed NURBS-based isogeometric elements with optimal convergence rates for arbitrary open knot vectors](https://arxiv.org/abs/2602.21753)
*Lisa Stammen,Wolfgang Dornisch*

Main category: math.NA

TL;DR: 本文提出了一种基于增强近似对偶基函数的混合等几何板单元方法，通过矩阵对角化避免了传统静态凝聚中的矩阵求逆，有效解决了剪切锁死问题，并在多种单/多块体算例中实现了最优收敛率。


<details>
  <summary>Details</summary>
Motivation: 为了解决等几何分析中因高连续性导致的静态凝聚计算成本高的问题，尤其是剪切锁死现象，需要一种无需全局矩阵求逆的高效稳定化方法。

Method: 采用增强的近似对偶基函数插值虚拟剪切参数，结合适当的积分空间选择，使关键矩阵部分可进行行和集中（lumping），进而实现无需矩阵求逆的静态凝聚。

Result: 该方法在全连续和有限内部连续的单/多块体算例中均获得最优误差收敛率，显著优于未改进方法。

Conclusion: 所提出的插值与凝聚策略有效克服了等几何分析中剪切锁死带来的收敛退化问题，提升了计算效率与精度，具有良好的应用前景。

Abstract: Locking is a common effect in finite element and isogeometric analysis. In the case of plates, transverse shear locking is most prominent, for shells several other types of locking exist. A common cure are mixed methods that introduce additional fields of unknowns into the variational formulation. These fields reduce constraints and thus alleviate locking significantly. As a drawback, the discretized additional fields increase computational costs significantly. These fields are often eliminated by static condensation, which requires the inverse of a part of the stiffness matrix. In Lagrange-based finite elements, this inverse is computed on element level, due to a discontinuous interpolation of additional fields. Since isogeometric analysis features higher continuity, static condensation must be performed on patch level, which requires a costly matrix inversion on that level. In this contribution, the virtual shear parameters of a mixed isogeometric plate formulation are interpolated by enhanced approximate dual basis functions. This allows to conduct row-sum lumping of the relevant matrix part at a minimal loss of accuracy, since this part becomes diagonal dominant. For a properly chosen integration space, this lumped matrix becomes the identity matrix. Thus, the proposed condensation procedure does not require an inversion anymore. The crucial and novel point is the proposed treatment of knot vectors with limited internal continuity. With the help of several single- and multi-patch examples, both with full and with limited internal continuity, we show that the proposed procedure obtains optimal error convergence rates in all cases, while without these alterations, convergence rates are significantly deteriorated.

</details>


### [4] [Kernel Methods for the Construction of Certified Lyapunov Functions via Approximate Koopman Eigenfunctions](https://arxiv.org/abs/2602.21767)
*P. Giesl,S. Hafstein,B. Hamzi,J. Lee,H. Owhadi,G. Santin,U. Vaidya*

Main category: math.NA

TL;DR: 提出一种基于核方法的非线性动力系统李雅普诺夫函数构造方法，利用近似Koopman特征函数并结合对称核配点法，在RKHS中求解偏微分方程，并通过数值实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 为了有效构造非线性动力系统的李雅普诺夫函数，克服传统方法在高维或复杂系统中的局限性，利用Koopman算子理论将非线性系统特性映射到线性框架下处理。

Method: 将主Koopman特征函数分解为线性和非线性部分，线性部分来自系统线性化，非线性部分通过在再生核希尔伯特空间（RKHS）中使用对称核配点法求解偏微分方程获得；最终的李雅普诺夫函数由这些近似特征函数的二次型构成，并结合连续分段仿射（CPA）方法进行验证。

Result: 得到了与配点点填充距离相关的误差界，数值实验表明该方法在多项式系统和Duffing振子等基准系统上能有效构造李雅普诺夫函数。

Conclusion: 所提方法为基于数据驱动和核方法的非线性系统稳定性分析提供了理论支持和实用工具，具有良好的近似精度和可验证性。

Abstract: We present a kernel-based methodology for constructing Lyapunov functions for nonlinear dynamical systems using approximate Koopman eigenfunctions. Our approach decomposes principal Koopman eigenfunctions into linear and nonlinear components, where the linear part is obtained from the system's linearization and the nonlinear part is computed by solving a partial differential equation using symmetric kernel collocation in reproducing kernel Hilbert spaces (RKHS). The resulting Lyapunov function is constructed as a quadratic form in the approximate eigenfunctions. We establish error bounds relating the approximation quality to the fill distance of collocation points and provide a certification procedure using continuous piecewise affine (CPA) methods. Numerical experiments on benchmark systems, including a polynomial system and the Duffing oscillator, demonstrate the effectiveness of our approach.

</details>


### [5] [A generalized Riemann problem-based compact reconstruction method for finite volume schemes](https://arxiv.org/abs/2602.21911)
*Gino I. Montecinos,Eleuterio F. Toro,Lucas O. Müller*

Main category: math.NA

TL;DR: 提出了一种基于广义黎曼问题（GRP）的高阶有限体积重构方法（GRPrec），具有紧凑模板和高效计算性能。


<details>
  <summary>Details</summary>
Motivation: 为了在保持高精度的同时提高有限体积法的计算效率和稳定性，避免传统DG方法中严格的CFL条件限制。

Method: 利用当前时间层的单元平均值和前一时间层的GRP解数据构建空间多项式，结合ADER框架实现完全离散化。

Result: 在光滑和间断解的线性对流方程和欧拉方程测试中，GRPrec表现出优异的精度和更低的CPU成本，优于传统有限体积和DG方法。

Conclusion: GRPrec是一种高效、稳定且高阶精度的有限体积方法，具备与DG相当的模板紧凑性但拥有更宽松的稳定性条件。

Abstract: We present a Generalized Riemann Problem-based reconstruction method (GRPrec) for high-order finite volume schemes applied to hyperbolic partial differential equations. The method constructs spatial polynomials using cell averages at the current time level and GRP solution data from the previous time level. The resulting GRPrec stencil is as compact as that of discontinuous Galerkin (DG) schemes but unlike DG, our finite volume schemes obey a generous CFL stability condition that is independent of the order of accuracy. We assess the method's performance through test problems for smooth and discontinuous solutions of the linear advection equation and the Euler equations of gas dynamics in one space dimension. Results are compared against exact solutions and against numerical results from well-known spatial reconstruction finite volume and DG schemes, with all methods implemented in the fully discrete ADER framework. The performance of GRPrec is very promising, especially in terms of efficiency, that is error against CPU cost.

</details>


### [6] [A fully iterative adaptive energy-based approach for monotone elliptic problems](https://arxiv.org/abs/2602.21913)
*Raphael Leu,Thomas P. Wihler*

Main category: math.NA

TL;DR: 提出一种完全迭代的自适应算法，用于希尔伯特空间中强凸能量泛函的数值最小化，通过能量减少原则驱动所有算法组件，实现最优收敛。


<details>
  <summary>Details</summary>
Motivation: 为了更高效地求解强凸能量泛函的最小化问题，避免传统后验误差估计器的局限性。

Method: 采用非线性共轭梯度法，在逐层自适应细化的有限维逼近空间上计算近似解，并基于局部能量减少指标驱动网格 refinement 和迭代停止准则。

Result: 在二维多边形域上的多个基准问题中，该方法实现了最优收敛速度。

Conclusion: 所提出的算法通过统一的能量减少原则有效提升了自适应求解的效率和精度。

Abstract: We present a fully iterative adaptive algorithm for the numerical minimization of strongly convex energy functionals in Hilbert spaces. The proposed approach, which we first present in abstract form, generates a hierarchical sequence of adaptively refined finite-dimensional approximation spaces and employs a (nonlinear) conjugate gradient (CG) method to compute suitable approximations on each space. A core novelty of our approach is that all components of the algorithm are consistently driven by energy reduction principles rather than by classical a posteriori estimators. In particular, adaptive refinement is steered by local energy reduction indicators which aim to construct subsequent approximation spaces in a way that attains the largest potential decrease in energy. Likewise, the stopping criteria for the iterative solver are based on either relative or averaged energy reductions on each subspace. As a concrete realization, we present a concise implementation for $\mathbb{P}_1$ finite element discretizations of second-order semilinear elliptic diffusion-reaction models, where the local indicators driving the element refinements are computed based on edge-wise energy reductions. Numerical experiments demonstrate that the resulting scheme achieves optimal convergence for various benchmark problems in two-dimensional polygonal domains.

</details>


### [7] [Linguistic Approach to Time Series Forecasting](https://arxiv.org/abs/2207.00985)
*Dmytro Lande,Volodymyr Yuzefovych,Yevheniia Tsybulska*

Main category: math.NA

TL;DR: 本文提出了一种基于语言学中N-gram方法的动态时间序列预测技术，适用于非平稳时间序列，具有高自动化、无需复杂参数调优和无需序列平稳性假设的优点。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列预测方法通常要求数据平稳且需复杂参数调优，限制了在大规模、动态系统中的应用。因此，需要一种更自动化、适应性强的预测方法。

Method: 采用计算语言学中的N-gram模型，分析时间序列中模式的出现与重复，通过序列片段的相似性进行预测，无需预处理或复杂建模。

Result: 该方法能有效进行短期和中期预测，尤其适用于具有趋势性和周期性的序列，如内容监控中的发布动态；同时适用于大规模复杂系统的参数预测，具备高自动化水平。

Conclusion: 基于N-gram的语言学方法为非平稳时间序列预测提供了一种高效、自动化的替代方案，未来可进一步研究相似性度量标准和量化步长的自动选择。

Abstract: This paper proposes methods of predicting dynamic time series (including non-stationary ones) based on a linguistic approach, namely, the study of occurrences and repetition of so-called N-grams. This approach is used in computational linguistics to create statistical translators, detect plagiarism and duplicate documents. However, the scope of application can be extended beyond linguistics by taking into account the correlations of sequences of stable word combinations, as well as trends. The proposed methods do not require a preliminary study and determination of the characteristics of time series or complex tuning of the input parameters of the forecasting model. They allow, with a high level of automation, to carry out short-term and medium-term forecasts of time series, characterized by trends and cyclicality, in particular, series of publication dynamics in content monitoring systems. Also, the proposed methods can be used to predict the values of the parameters of a large complex system with the aim of monitoring its state, when the number of such parameters is significant, and therefore a high level of automation of the forecasting process is desirable. A significant advantage of the approach is the absence of requirements for time series stationarity and a small number of tuning parameters. Further research may focus on the study of various criteria for the similarity of time series fragments, the use of nonlinear similarity criteria, the search for ways to automatically determine the rational step of quantization of the time series.

</details>


### [8] [Robust Kaczmarz methods for nearly singular linear systems](https://arxiv.org/abs/2602.21916)
*Yunying Ke,Hao Luo*

Main category: math.NA

TL;DR: 提出了一种鲁棒的核增强型Kaczmarz方法（KaK），用于求解近奇异线性系统，具有均匀收敛性和对病态问题的鲁棒性，并通过子空间校正框架和加速变体实现了最优收敛速率。


<details>
  <summary>Details</summary>
Motivation: 经典Kaczmarz方法在处理近奇异且行秩亏的线性系统时收敛速度慢且对最小非零奇异值敏感，因此需要一种更鲁棒的方法来应对病态问题。

Method: 引入了近奇异性的新概念，并基于近似核空间提出了核增强型Kaczmarz方法（KaK），结合子空间校正框架和Xu--Zikatanov恒等式进行分析；进一步引入对偶近似核将其转化为可实现的坐标下降形式，并设计了加速版本。

Result: 所提方法在近奇异线性系统上实现了均匀收敛率，收敛速度达到一阶方法的最优复杂度，数值实验验证了其鲁棒性。

Conclusion: 核增强型Kaczmarz方法有效提升了对近奇异和病态线性系统的求解性能，具备理论保证和实际可行性，是传统Kaczmarz方法的重要扩展。

Abstract: The Kaczmarz method is an efficient iterative algorithm for large-scale linear systems. However, its linear convergence rate suffers from ill-conditioned problems and is highly sensitive to the smallest nonzero singular value. In this work, we aim to extend the classical Kaczmarz to nearly singular linear systems that are row rank-deficient. We introduce a new concept of nearly singular property by treating the row space as an unstable subspace in the Grassman manifold. We then define a related important space called the approximate kernel, based on which a robust kernel-augmented Kaczmarz (KaK) is introduced via the subspace correction framework and analyzed by the well-known Xu--Zikatanov identity. To get an implementable version, we further introduce the approximate dual kernel and transform KaK into an equivalent kernel-augmented coordinate descent. Furthermore, we develop an accelerated variant and establish the improved rate of convergence matching the optimal complexity of first-order methods. Compared with existing methods, ours achieve uniform convergence rates for nearly singular linear systems, and the robustness has been confirmed by some numerical tests.

</details>


### [9] [Analysis of eigenvalue clustering leads to optimal scaling in numerical radiative transfer](https://arxiv.org/abs/2602.21958)
*Pietro Benedusi,Simone Riva,Luca Belluzzi,Stefano Serra-Capizzano*

Main category: math.NA

TL;DR: 本文研究了多维多色辐射转移问题中的Krylov方法收敛性，利用符号理论的谱分析工具解释了其在无预处理情况下对离散参数的鲁棒收敛性，并通过数值实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决包含各向异性散射和部分频率再分布的多维多色辐射转移问题中离散化矩阵可能密集且求解困难的问题，需要发展高效且鲁棒的数值求解方法。

Method: 采用离散坐标法进行空间和角度离散化，结合Krylov子空间方法（尤其是矩阵自由形式），并利用符号理论中的谱分析工具研究连续算子对应的矩阵序列的谱聚集特性。

Result: 证明了由于连续算子的紧致性，离散化得到的矩阵序列谱在1处聚集，从而保证了Krylov方法在无预处理下对所有离散参数的鲁棒收敛性；数值实验验证了该理论分析结果。

Conclusion: Krylov方法在求解此类辐射转移问题时具有最优的计算复杂度缩放特性，适用于恒星大气辐射传输等实际应用，且无需依赖复杂预处理即可保持高效收敛。

Abstract: We consider a multidimensional polychromatic radiative transfer (RT) problem, accounting for scattering processes in a general form, i.e. anisotropic (dipole) scattering with partial frequency redistribution. Given a discrete ordinates discretization, we report the corresponding matrix structures, depending on model and discretization parameters. Despite the possibly dense nature of these matrices, the use of Krylov methods is effective (especially in the matrix-free context) and robust. We propose a theoretical analysis, using the spectral tools of the symbol theory, explaining why Krylov convergence is robust w.r.t. all the discretization parameters, even in the unpreconditioned case. In fact, the compactness of the continuous operators used in the modeling leads to zero-clustered dense matrix sequences plus identity, so that the clustering at the unity of the spectra is deduced. Numerical experiments confirm the theoretical results, which have a direct application, for example, in the simulation of radiative transfer in stellar atmospheres, a key problem in astrophysical research. In general, we demonstrate that optimal scaling with respect to RT discretization parameters is expected for Krylov solution strategies.

</details>


### [10] [Subspace gradient descent method for linear tensor equations](https://arxiv.org/abs/2602.21974)
*Martina Iannacito,Lorenzo Piccinini,Valeria Simoncini*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The numerical solution of algebraic tensor equations is a largely open and challenging task. Assuming that the operator is symmetric and positive definite, we propose two new gradient-descent type methods for tensor equations that generalize the recently proposed Subspace Conjugate Gradient (SS-CG), D. Palitta et al, SIAM J. Matrix Analysis and Appl (2025). As our interest is mainly in a modest number of tensor modes, the Tucker format is used to efficiently represent low-rank tensors. Moreover, mixed-precision strategies are employed in certain subtasks to improve the memory usage, and different preconditioners are applied to enhance convergence. The potential of our strategies is illustrated by experimental results on tensor-oriented discretizations of three-dimensional partial differential equations with separable coefficients. Comparisons with the state-of-the-art Alternating Minimal Energy (AMEn) algorithm confirm the competitiveness of the proposed strategies.

</details>


### [11] [Optimal error bounds on the exponential integrator for dispersive equations with highly concentrated potential](https://arxiv.org/abs/2602.22068)
*Guillaume Bal,Chushan Wang*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study a one-dimensional linear dispersive equation of differential order $κ\geq 2$ with concentrated potential of extension $\varepsilon$ with $0 < \varepsilon \ll 1$, featuring a competition between weak dispersion of strength $\varepsilon^α\ (0 \leq α\leq κ)$ and localization induced by the concentrated potential. We first obtain precise regularity estimates of the exact solution in terms of $\varepsilon$. We then apply a natural first-order exponential integrator with step size $τ$ to discretize the equation, and establish an optimal error bound of the form $O_{L^\infty}(τ\varepsilon^β)$ (up to logarithmic factors in $τ$ and $\varepsilon$). Salient features of the result are: (i) error bounds are not only uniform in $\varepsilon$ but improve as $\varepsilon \rightarrow 0$; and (ii) no restriction on $τ$ in terms of $\varepsilon$. The analysis combines iterated Duhamel's expansions and a transformation that exploits cancellations in oscillatory phases that cannot be obtained directly from regularity estimates of the exact solution. We also show that other classical numerical schemes, such as Lie or centered splitting schemes and low regularity integrators, fail to display optimal rates of convergence. Extensive numerical results are presented and confirm the theoretical error estimates.

</details>


### [12] [Matrix Perturbation Theory in the Tangent Space of Isospectral Matrices](https://arxiv.org/abs/2602.22084)
*Francesco Hrobat,Yuji Nakatsukasa*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Eigenvalue and eigenvector perturbation theory is a fundamental topic in several disciplines, including numerical linear algebra, quantum physics, and related fields. The central problem is to understand how the eigenvalues and eigenvectors of a matrix $A \in \mathbb{C}^{n \times n}$ change under the addition of a perturbation matrix $E \in \mathbb{C}^{n \times n}$. Much of the existing literature focuses on structured perturbations. For example, in [C.-K. Li and R.-C. Li, Linear Algebra Appl. 2005], the matrix $A$ is assumed to be Hermitian and block diagonal, while the perturbation $E$ is Hermitian and block off-diagonal. In this work, we investigate a different structured setting in which the perturbation has the commutator form $E = AB - BA$ for some matrix $B$, which we show to be a generalization of the block diagonal structure considered by Li and Li. First, we extend their main result by showing that the perturbation of the $i$-th eigenvalue of $A$, denoted by $λ_i$, is of order $\|E\|^2 / η_i$, where $η_i = \min_{j \neq i} |λ_i - λ_j|$ is the spectral gap associated with $λ_i$. Second, we provide a detailed analysis of the role played by the matrix $B$ in the perturbation of the eigenvectors. This analysis is further generalized to the case of block-diagonal matrices with multiple eigenvalues, as well as to perturbed singular values and eigenvalues of Jordan blocks.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [13] [An index of effective number of variables for uncertainty and reliability analysis in model selection problems](https://arxiv.org/abs/2602.21403)
*Luca Martino,Eduardo Morgado,Roberto San Millán-Castillo*

Main category: stat.ME

TL;DR: 提出了一种用于嵌套模型选择的有效变量数（ENV）指标，灵感来自最大曲线下面积（AUC），可改进现有肘部检测方法并提供新的置信度量。


<details>
  <summary>Details</summary>
Motivation: 解决在多项式阶数选择、聚类数量确定等嵌套模型选择问题中缺乏有效且具解释性的评估指标的问题。

Method: 基于最大AUC思想构建ENV指标，并引入多种置信度量，可与AIC、BIC等信息准则结合使用。

Result: 在多个真实数据集实验中，ENV优于传统及最新方法，提供了更可靠的模型选择结果和相关置信评估。

Conclusion: ENV是一种具有良好解释性和实用性的模型选择工具，能有效改进肘部法则并增强模型选择的可靠性。

Abstract: An index of an effective number of variables (ENV) is introduced for model selection in nested models. This is the case, for instance, when we have to decide the order of a polynomial function or the number of bases in a nonlinear regression, choose the number of clusters in a clustering problem, or the number of features in a variable selection application (to name few examples). It is inspired by the idea of the maximum area under the curve (AUC). The interpretation of the ENV index is identical to the effective sample size (ESS) indices concerning a set of samples. The ENV index improves {drawbacks of} the elbow detectors described in the literature and introduces different confidence measures of the proposed solution. These novel measures can be also employed jointly with the use of different information criteria, such as the well-known AIC and BIC, or any other model selection procedures. Comparisons with classical and recent schemes are provided in different experiments involving real datasets. Related Matlab code is given.

</details>


### [14] [Discussion of "Matrix Completion When Missing Is Not at Random and Its Applications in Causal Panel Data Models"](https://arxiv.org/abs/2602.21314)
*Eli Ben-Michael,Avi Feller*

Main category: stat.ME

TL;DR: 本文讨论了Choi和Yuan（2025）提出的将矩阵补全用于面板数据中因果效应估计的新方法，强调其在处理小规模处理组和大规模控制组时的有效性，并从“分-析-合”策略和统计学“最后一公里”问题两个角度进行评述，最后将其应用于持枪权法律对暴力犯罪影响的研究。


<details>
  <summary>Details</summary>
Motivation: 探讨矩阵补全在因果推断中的应用潜力，尤其是在存在非随机处理分配和缺失数据模式下的适用性，并弥合理论与实践之间的差距。

Method: 将矩阵补全方法纳入面板数据因果推断框架，分析其作为“split-apply-combine”策略的实例，并结合实际案例评估其表现。

Result: 表明在处理单位较少而控制单位较多的情况下，矩阵补全能有效估计因果效应；同时识别出理论应用中的“最后一公里”挑战并提出改进建议。

Conclusion: 矩阵补全为面板数据中的因果推断提供了有力工具，但需结合实际数据特征谨慎应用，尤其在公共政策评估中具有潜力但仍面临实施挑战。

Abstract: Choi and Yuan (2025) propose a novel approach to applying matrix completion to the problem of estimating causal effects in panel data. The key insight is that even in the presence of structured patterns of missing data -- i.e. selection into treatment -- matrix completion can be effective if the number of treated observations is small relative to the number of control observations. We applaud the authors for their insightful and interesting paper. We discuss this proposal from two complementary perspectives. First, we situate their proposal as an example of a "split-apply-combine" strategy that underlies many modern panel data estimators, including difference-in-differences and synthetic control approaches. Second, we discuss the issue of the statistical "last mile problem" -- the gap between theory and practice -- and offer suggestions on how to partially address it. We conclude by considering the challenges of estimating the impacts of public policies using panel data and apply the approach to a study on the effect of right to carry laws on violent crime.

</details>


### [15] [Identifying the potential of sample overlap in evidence synthesis of observational studies](https://arxiv.org/abs/2602.21410)
*Zhentian Zhang,Tim Friede,Tim Mathes*

Main category: stat.ME

TL;DR: 提出了一种基于集合论的方法，通过编码样本特征范围来构建证据综合中样本重叠程度的指标，无需依赖个体数据，有效解决了使用现有数据库进行医学研究时的样本重叠问题。


<details>
  <summary>Details</summary>
Motivation: 由于在整合基于现有数据库的观察性研究时难以获取唯一标识符，样本重叠问题普遍存在且可能导致偏倚，影响证据综合的可信度，因此需要一种可行的方法来评估和处理这一问题。

Method: 基于集合论，通过选择关键的样本特征并编码其取值范围，构建样本重叠程度的指示器，从而推断重叠情况，并识别出最大非重叠样本集。

Result: 该方法在多个真实世界的证据综合案例中得到应用，证明其具有有效性与灵活性，能够提供有关样本重叠的重要信息，如最大的无重叠样本集。

Conclusion: 所提出的方法为处理基于现有数据的证据综合中的样本重叠问题提供了实用且可推广的解决方案，对促进二次数据利用背景下的高质量研究具有重要意义。

Abstract: Sample overlap is a common issue in evidence synthesis in the field of medical research, particularly when integrating findings from observational studies utilizing existing databases such as registries. Due to the general inaccessibility of unique identifiers for each observation, addressing sample overlap has been a complex problem, potentially biasing evidence synthesis outcomes and undermining their credibility. We developed a method to construct indicators for the degree of sample overlap in evidence synthesis of studies based on existing data. Our method is rooted in set theory and is based on the coding of the ranges of several well selected sample characteristics, offers a practical solution by focusing on making inference based on sample characteristics rather than on individual participant data. Useful information, such as the overlap-free sample set with the largest sample size in an evidence synthesis, can be derived from this method. We applied our model to several real-world evidence syntheses, demonstrating its effectiveness and flexibility. Our findings highlight the growing importance of addressing sample overlap in evidence synthesis, especially with the increasing relevance of secondary use of data, an area currently under-explored in research.

</details>


### [16] [Asymptotically Optimal Sequential Confidence Interval for the Gini Index Under Complex Household Survey Design with Sub-Stratification](https://arxiv.org/abs/2602.21579)
*Shivam,Bhargab Chattopadhyay,Nil Kamal Hazra*

Main category: stat.ME

TL;DR: 本研究提出两种新方法（纯序贯法和两阶段法）来估计复杂调查设计下的基尼指数，并在适当的正则条件下证明了估计量的渐近最优性，包括一致性和效率。通过模拟和印度国家抽样调查数据的应用验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究对复杂调查设计下基尼指数估计的理论保证不足，且仅考虑分层和聚类，未涵盖更复杂的结构。本研究旨在填补这一空白，提供具有理论支持的优化估计方法。

Method: 提出了纯序贯法和两阶段法两种程序，在包含分层、聚类和子分层的复杂调查设计下估计基尼指数，并在正则条件下建立估计量的概率一致连续性。

Result: 所提方法满足渐近一阶效率和渐近一致性；模拟结果显示其在多种设定下均能达到预期的最优性质；并通过印度国家抽样调查数据展示了实际应用价值。

Conclusion: 本文提出的两种方法在理论上具有良好的渐近性质，适用于复杂调查设计下的基尼指数估计，为相关统计推断提供了可靠工具。

Abstract: We examine the optimality properties of the Gini index estimator under complex survey design involving stratification, clustering, and sub-stratification. While Darku et al. (Econometrics, 26, 2020) considered only stratification and clustering and did not provide theoretical guarantees, this study addresses these limitations by proposing two procedures - a purely sequential method and a two-stage method. Under suitable regularity conditions, we establish uniform continuity in probability for the proposed estimator, thereby contributing to the development of random central limit theorems under sequential sampling frameworks. Furthermore, we show that the resulting procedures satisfy both asymptotic first-order efficiency and asymptotic consistency. Simulation results demonstrate that the proposed procedures achieve the desired optimality properties across diverse settings. The practical utility of the methodology is further illustrated through an empirical application using data collected by the National Sample Survey agency of India

</details>


### [17] [Estimation, inference and model selection for jump regression models](https://arxiv.org/abs/2602.21663)
*Steffen Grønneberg,Gudmund Hermansen,Nils Lid Hjort*

Main category: stat.ME

TL;DR: 本文研究了局部常数回归模型中跳跃点和水平参数的最小二乘估计的大样本性质，提出了一种新的跳跃信息准则（AJIC和BJIC）用于选择最优跳跃点数量，并发现贝叶斯方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 为了准确估计具有未知水平和跳跃点的局部常数回归模型中的参数，并解决传统信息准则不适用于此类模型的问题。

Method: 采用最小二乘法估计模型参数，分析其大样本性质，并基于类似AIC和BIC的推导思路构建新的跳跃信息准则AJIC和BJIC，同时比较贝叶斯方法的表现。

Result: 跳跃点参数的估计精度为n阶，水平参数为√n阶；提出的AJIC和BJIC准则能有效选择跳跃点数量，且贝叶斯方法在估计上优于最小二乘法。

Conclusion: 本文提出的方法能更精确地识别局部常数回归模型中的跳跃结构，新信息准则为模型选择提供了有效工具，贝叶斯方法在该类问题中更具优势。

Abstract: We consider regression models with data of the type $y_i=m(x_i)+\varepsilon_i$, where the $m(x)$ curve is taken locally constant, with unknown levels and jump points. We investigate the large-sample properties of the minimum least squares estimators, finding in particular that jump point parameters and level parameters are estimated with respectively $n$-rate precision and $\sqrt{n}$-rate precision, where $n$ is sample size. Bayes solutions are investigated as well and found to be superior. We then construct jump information criteria, respectively AJIC and BJIC, for selecting the right number of jump points from data. This is done by following the line of arguments that lead to the Akaike and Bayesian information criteria AIC and BIC, but which here lead to different formulae due to the different type of large-sample approximations involved.

</details>


### [18] [Adaptive Penalized Doubly Robust Regression for Longitudinal Data](https://arxiv.org/abs/2602.21711)
*Yuyao Wang,Yu Lu,Tianni Zhang,Mengfei Ran*

Main category: stat.ME

TL;DR: 提出了一种双自适应稳健回归（DAR-R）框架，用于纵向线性混合效应模型，兼具高维变量选择和对异常值及高杠杆点的鲁棒性，在阿尔茨海默病数据中表现出优异的预测性能和变量选择稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只能部分解决纵向数据中的异质性、稀疏信号和异常值污染问题，缺乏同时具备高维变量选择和鲁棒性的统一框架。

Method: 结合稳健初值估计、双自适应观测权重（针对残差异常值和杠杆点）、折叠凹惩罚（用于固定效应选择），以及随机效应和方差成分的加权更新，提出DAR-R框架并设计迭代重加权算法。

Result: 理论结果包括估计与预测误差界、支持恢复一致性及类Oracle渐近正态性；模拟显示DAR-R在垂直异常值和坏杠杆点下均能提升估计精度、误报控制和协方差估计；在TADPOLE/ADNI阿尔茨海默病数据中实现了ADAS13的稳定预测并选出了临床意义明确且重抽样稳定的预测因子。

Conclusion: DAR-R框架有效整合了稳健估计与高维变量选择，为处理复杂纵向数据提供了可靠工具，具有良好的理论性质和实际应用价值。

Abstract: Longitudinal data often involve heterogeneity, sparse signals, and contamination from response outliers or high-leverage observations especially in biomedical science. Existing methods usually address only part of this problem, either emphasizing penalized mixed effects modeling without robustness or robust mixed effects estimation without high-dimensional variable selection. We propose a doubly adaptive robust regression (DAR-R) framework for longitudinal linear mixed effects models. It combines a robust pilot fit, doubly adaptive observation weights for residual outliers and leverage points, and folded concave penalization for fixed effect selection, together with weighted updates of random effects and variance components. We develop an iterative reweighting algorithm and establish estimation and prediction error bounds, support recovery consistency, and oracle-type asymptotic normality. Simulations show that DAR-R improves estimation accuracy, false-positive control, and covariance estimation under both vertical outliers and bad leverage contamination. In the TADPOLE/ADNI Alzheimer's disease application, DAR-R achieves accurate and stable prediction of ADAS13 while selecting clinically meaningful predictors with strong resampling stability.

</details>


### [19] [Multi-Parameter Estimation of Prevalence (MPEP): A Bayesian modelling approach to estimate the prevalence of opioid dependence](https://arxiv.org/abs/2602.21713)
*Andreas Markoulidakis,Matthew Hickman,Nicky J Welton,Loukia Meligkotsidou,Hayley E Jones*

Main category: stat.ME

TL;DR: 本文提出了一种名为多参数流行率估计（MPEP）的贝叶斯建模方法，利用行政管理数据估算隐匿或边缘化人群（如阿片类药物依赖者）的总体规模，并通过苏格兰阿片类药物依赖的案例研究验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 准确估计隐匿或边缘化人群（如吸毒者）的数量对制定公共卫生政策和提供减害服务至关重要，但传统方法如捕获-再捕获存在假设难以满足和应用受限的问题。

Method: 提出MPEP贝叶斯模型，利用常规收集的行政数据，基于目标人群的基线队列及其关联事件，通过STAN实现高效计算；可整合多种事件类型以检验证据一致性，并加入额外证据修正偏差。

Result: 成功应用于2014至2022年苏格兰阿片类药物依赖流行率的年度估计，模型具备良好计算效率，并可通过扩展分析评估假设敏感性和识别潜在偏倚来源。

Conclusion: MPEP是一种灵活且稳健的流行率估计方法，能够有效利用多源行政数据，在不依赖强假设的前提下提供可靠的隐匿人群规模估计，具有广泛公共卫生应用前景。

Abstract: Estimating the number of the number of people from hidden and/or marginalised populations - such as people dependent on opioids or cocaine - is important to guide policy decisions and provision of harm reduction services. Methods such as capture-recapture are widely used, but rely on assumptions that are often violated and not feasible in specific applications. We describe a Bayesian modelling approach called Multi-Parameter Estimation of Prevalence (MPEP). The MPEP approach leverages routinely collected administrative data, starting from a large baseline cohort of individuals from the population of interest and linked events, to estimate the full size of the target population. When multiple event types are included, the approach enables checking of the consistency of evidence about prevalence from different event types. Additional evidence can be incorporated where inconsistencies are identified. In this article, we summarize the general framework of MPEP, with focus on the most recent version, with improved computational efficiency (implemented in STAN). We also explore several extensions to the model that help us understand the sensitivity of the results to modelling assumptions or identify potential sources of bias. We demonstrate the MPEP approach through a case study estimating the prevalence of opioid dependence in Scotland each year from 2014 to 2022.

</details>


### [20] [Estimation of the complexity of a network under a Gaussian graphical model](https://arxiv.org/abs/2602.21969)
*Nabaneet Das,Thorsten Dickhaus*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The proportion of edges in a Gaussian graphical model (GGM) characterizes the complexity of its conditional dependence structure. Since edge presence corresponds to a nonzero entry of the precision matrix, estimation of this proportion can be formulated as a large-scale multiple testing problem. We propose an estimator that combines p-values from simultaneous edge-wise tests, conducted under false discovery rate control, with Storey's estimator of the proportion of true null hypotheses. We establish weak dependence conditions on the precision matrix under which the empirical cumulative distribution function of the p-values converges to its population counterpart. These conditions cover high-dimensional regimes, including those arising in genetic association studies. Under such dependence, we characterize the asymptotic bias of the Schweder--Spjøtvoll estimator, showing that it is upward biased and thus slightly underestimates the true edge proportion. Simulation studies across a variety of models confirm accurate recovery of graph complexity.

</details>


### [21] [Robust Model Selection for Discovery of Latent Mechanistic Processes](https://arxiv.org/abs/2602.22062)
*Jiawei Li,Nguyen Nguyen,Meng Lai,Ioannis Ch. Paschalidis,Jonathan H. Huggins*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: When learning interpretable latent structures using model-based approaches, even small deviations from modeling assumptions can lead to inferential results that are not mechanistically meaningful. In this work, we consider latent structures that consist of $K_o$ mechanistic processes, where $K_o$ is unknown. When the model is misspecified, likelihood-based model selection methods can substantially overestimate $K_o$ while more robust nonparametric methods can be overly conservative. Hence, there is a need for approaches that combine the sensitivity of likelihood-based methods with the robustness of nonparametric ones. We formalize this objective in terms of a robust model selection consistency property, which is based on a component-level discrepancy measure that captures the mechanistic structure of the model. We then propose the accumulated cutoff discrepancy criterion (ACDC), which leverages plug-in estimates of component-level discrepancies. To apply ACDC, we develop mechanistically meaningful component-level discrepancies for a general class of latent variable models that includes unsupervised and supervised variants of probabilistic matrix factorization and mixture modeling. We show that ACDC is robustly consistent when applied to unsupervised matrix factorization and mixture models. Numerical results demonstrate that in practice our approach reliably identifies a mechanistically meaningful number of latent processes in numerous illustrative applications, outperforming existing methods.

</details>


### [22] [Design-based theory for causal inference from adaptive experiments](https://arxiv.org/abs/2602.21998)
*Xinran Li,Anqi Zhao*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Adaptive designs dynamically update treatment probabilities using information accumulated during the experiment. Existing theory for causal inference from adaptive experiments primarily assumes the superpopulation framework with independent and identically distributed units, and may not apply when the distribution of units evolves over time. This paper makes two contributions. First, we extend the literature to the finite-population framework, which allows for possibly nonexchangeable units, and establish the design-based theory for causal inference under general adaptive designs using inverse-propensity-weighted (IPW) and augmented IPW (AIPW) estimators. Our theory accommodates nonexchangeable units, both nonconverging and vanishing treatment probabilities, and nonconverging outcome estimators, thereby justifying inference using AIPW estimators with black-box outcome models that integrate advances from machine learning methods. To alleviate the conservativeness inherent in variance estimation under finite-population inference, we also introduce a covariance estimator for the AIPW estimator that becomes sharp when the residuals from the adaptive regression of potential outcomes on covariates are additive across units. Our framework encompasses widely used adaptive designs, such as multi-armed bandits, covariate-adaptive randomization, and sequential rerandomization, advancing the design-based theory for causal inference in these specific settings. Second, as a methodological contribution, we propose an adaptive covariate adjustment approach for analyzing even nonadaptive designs. The martingale structure induced by adaptive adjustment enables valid inference with black-box outcome estimators that would otherwise require strong assumptions under standard nonadaptive analysis.

</details>


### [23] [Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data](https://arxiv.org/abs/2602.22021)
*Jiacan Gao,Xinyan Su,Mingyuan Ma,Yiyan Huang,Xiao Xu,Xinrui Wan,Tianqi Gu,Enyun Yu,Jiecheng Guo,Zhiheng Zhang*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Estimating heterogeneous treatment effects is central to data-driven decision-making, yet industrial applications often face a fundamental tension between limited randomized controlled trial (RCT) budgets and abundant but biased observational data collected under historical targeting policies. Although observational logs offer the advantage of scale, they inherently suffer from severe policyinduced imbalance and overlap violations, rendering standalone estimation unreliable. We propose a budgeted active experimentation framework that iteratively enhances model training for causal effect estimation via active sampling. By leveraging observational priors, we develop an acquisition function targeting uplift estimation uncertainty, overlap deficits, and domain discrepancy to select the most informative units for randomized experiments. We establish finite-sample deviation bounds, asymptotic normality via martingale Central Limit Theorems (CLTs), and minimax lower bounds to prove information-theoretic optimality. Extensive experiments on industrial datasets demonstrate that our approach significantly outperforms standard randomized baselines in cost-constrained settings.

</details>


### [24] [Coarsening Bias from Variable Discretization in Causal Functionals](https://arxiv.org/abs/2602.22083)
*Xiaxian Ou,Razieh Nabi*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A class of causal effect functionals requires integration over conditional densities of continuous variables, as in mediation effects and nonparametric identification in causal graphical models. Estimating such densities and evaluating the resulting integrals can be statistically and computationally demanding. A common workaround is to discretize the variable and replace integrals with finite sums. Although convenient, discretization alters the population-level functional and can induce non-negligible approximation bias, even under correct identification. Under smoothness conditions, we show that this coarsening bias is first order in the bin width and arises at the level of the target functional, distinct from statistical estimation error. We propose a simple bias-reduced functional that evaluates the outcome regression at within-bin conditional means, eliminating the leading term and yielding a second-order approximation error. We derive plug-in and one-step estimators for the bias-reduced functional. Simulations demonstrate substantial bias reduction and near-nominal confidence interval coverage, even under coarse binning. Our results provide a simple framework for controlling the impact of variable discretization on parameter approximation and estimation.

</details>


### [25] [Local Bayesian Regression](https://arxiv.org/abs/2602.22203)
*Nils Lid Hjort*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper develops a class of Bayesian non- and semiparametric methods for estimating regression curves and surfaces. The main idea is to model the regression as locally linear, and then place suitable local priors on the local parameters. The method requires the posterior distribution of the local parameters given local data, and this is found via a suitably defined local likelihood function. When the width of the local data window is large the methods reduce to familiar fully parametric Bayesian methods, and when the width is small the estimators are essentially nonparametric. When noninformative reference priors are used the resulting estimators coincide with recently developed well-performing local weighted least squares methods for nonparametric regression.
  Each local prior distribution needs in general a centre parameter and a variance parameter. Of particular interest are versions of the scheme that are more or less automatic and objective in the sense that they do not require subjective specifications of prior parameters. We therefore develop empirical Bayes methods to obtain the variance parameter and a hierarchical Bayes method to account for uncertainty in the choice of centre parameter. There are several possible versions of the general programme, and a number of its specialisations are discussed. Some of these are shown to be capable of outperforming standard nonparametric regression methods, particularly in situations with several covariates.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [26] [Some Asymptotic Results on Multiple Testing under Weak Dependence](https://arxiv.org/abs/2602.21359)
*Swarnadeep Datta,Monitirtha Dey*

Main category: math.ST

TL;DR: 研究在弱相关正态结构下的多重检验问题，提出Bonferroni和Sidak方法在假设数量趋于无穷时可精确控制FWER。


<details>
  <summary>Details</summary>
Motivation: 在基因组学等应用中，缺乏能在弱相关结构下精确控制FWER的检验方法。

Method: 分析经典Bonferroni和Sidak方法在适当调整后的渐近行为。

Result: 证明这两种方法在假设数趋于无穷时能精确控制FWER，并得到对广义FWER和功效的类似渐近结果。

Conclusion: Bonferroni和Sidak方法在弱相关正态设置下具有渐近精确的FWER控制能力。

Abstract: This paper studies the means-testing problem under weakly correlated Normal setups. Although quite common in genomic applications, test procedures having exact FWER control under such dependence structures are nonexistent. We explore the asymptotic behaviors of the classical Bonferroni (when adjusted suitably) and the Sidak procedure; and show that both of these control FWER at the desired level exactly as the number of hypotheses approaches infinity. We derive analogous limiting results on the generalized family-wise error rate and power. Simulation studies depict the asymptotic exactness of the procedures empirically.

</details>


### [27] [Causal Inference with High-Dimensional Treatments](https://arxiv.org/abs/2602.21423)
*Patrick Kramer,Edward H. Kennedy,Isaac M. Opper*

Main category: math.ST

TL;DR: 本文研究了高维处理下的因果推断问题，提出了一种稀疏伪结果回归框架，并推导出双重稳健估计量及其有限样本风险界和最优收敛率。


<details>
  <summary>Details</summary>
Motivation: 在高维处理设置中，传统的因果推断方法面临挑战，如高维处理效应、 positivity 违反以及小有效样本量等问题，需要新的理论和方法来解决这些问题。

Method: 提出了一个适用于任意高维统计泛函的稀疏伪结果回归框架，包括通用约束回归估计量和误差保证，并在此基础上推导出双重稳健估计量，分析其在精确和近似稀疏性假设下的性能。

Result: 得到了有限样本下的风险上界，并通过最小最大下界证明了这些上界是不可改进的，表明所提方法达到了最优收敛速率。

Conclusion: 所提出的稀疏伪结果回归框架能够有效应对高维处理下的因果推断挑战，在理论上有良好的保证，且估计结果达到最优收敛速度。

Abstract: In this work, we consider causal inference in various high-dimensional treatment settings, including for single multi-valued treatments and vector treatments with binary or continuous components, when the number of treatments can be comparable to or even larger than the number of observations. These settings bring unique challenges: first, the treatment effects of interest are a high-dimensional vector rather than a low-dimensional scalar; second, positivity violations are often unavoidable; and third, estimation can be based on a smaller effective sample size. We first discuss fundamental limits of estimating effects here, showing that consistent estimation is impossible without further assumptions. We go on to propose a novel sparse pseudo-outcome regression framework for arbitrary high-dimensional statistical functionals, which includes generic constrained regression estimators and error guarantees. We use the framework to derive new doubly robust estimators for mean potential outcomes of high-dimensional treatments, though it can also be applied to other scenarios. We analyze the proposed estimators under exact and approximate sparsity assumptions, giving finite-sample risk bounds. Finally, we derive minimax lower bounds to characterize optimal rates of convergence and show our risk bounds are unimprovable.

</details>


### [28] [Exponential Concentration Inequalities For Independent Random Vectors Under Sublinear Expectations](https://arxiv.org/abs/2602.21465)
*Nahom Seyoum*

Main category: math.ST

TL;DR: 本文将Li和Hu关于次线性期望下独立随机向量样本均值的方差型界推广到指数集中区域，建立了多维情形下的指数集中不等式，包括Azuma-Hoeffding型、Bernstein型不等式，并证明了次高斯速率的最优性。


<details>
  <summary>Details</summary>
Motivation: 扩展Li和Hu在次线性期望下对样本均值的O(1/n)方差界结果至指数集中不等式，并处理多维向量情形。

Method: 通过三层结构将向量值尾部界归约为标量鞅不等式，结合Minkowski平均与矩阵Freedman不等式，建立适用于有界独立随机向量的广义集中原理。

Result: 获得了Azuma-Hoeffding型、Bernstein型等指数集中不等式，实现了次高斯尾部界；提出了维度无关的多项式前因子界，并构造实例验证了次高斯速率的最优性。

Conclusion: 首次在次线性期望框架下，以Minkowski平均的距离形式给出了多维样本均值的指数集中不等式，且结果在速率上是最优的。

Abstract: Li and Hu recently established variance-type O(1/n) bounds for the sample mean of independent random vectors under sublinear expectations. We extend their results to the exponential concentration regime. For bounded, independent R^d-valued random vectors under a regular sublinear expectation, we prove: (i) a general concentration principle that reduces vector-valued tail bounds to scalar martingale inequalities via a three-layer architecture; (ii) an Azuma-Hoeffding inequality showing that the distance from the sample mean to the Minkowski average of the expectation sets has sub-Gaussian tails; (iii) a Bernstein inequality incorporating the variance parameter of Li and Hu, interpolating between sub-Gaussian and sub-exponential regimes; (iv) a dimension-free bound replacing the exponential covering prefactor with a polynomial one via the matrix Freedman inequality; and (v) an explicit construction demonstrating that the sub-Gaussian rate is optimal. To the best of our knowledge, these constitute the first exponential concentration inequalities for the multivariate sample mean under sublinear expectations in terms of the set-valued distance to the Minkowski average.

</details>


### [29] [Moment bounds for condition numbers and singular values of high-dimensional Gaussian random matrices: Applications and limitations](https://arxiv.org/abs/2602.21487)
*Partha Sarkar,Kshitij Khare,Sanvesh Srivastava*

Main category: math.ST

TL;DR: 本文研究了高维高斯随机矩阵的最大奇异值、最小奇异值及条件数的非渐近矩界，填补了现有集中不等式无法直接提供统计估计所需矩界的空白，并将其应用于回归与协方差估计的风险分析以及梯度下降法的迭代复杂度估计，同时指出这些结果不能推广至一般的次高斯矩阵。


<details>
  <summary>Details</summary>
Motivation: 现有对高斯随机矩阵极端奇异值的集中性分析难以直接导出统计推断中所需的正负矩界，本文旨在建立适用于高维统计问题的精确非渐近矩估计。

Method: 利用高斯随机矩阵的几何与概率性质，结合浓度不等式和矩估计技术，推导最大奇异值的正矩、最小奇异值的负矩以及条件数任意正矩的非渐近上界。

Result: 得到了高维高斯随机矩阵最大奇异值任意正矩、最小奇异值任意负矩的紧致非渐近界，以及条件数任意正矩的一致上界；并将这些界成功应用于高维回归、协方差估计的风险保证和梯度下降法平均迭代复杂度的估计。

Conclusion: 所提出的矩界为高维统计分析提供了关键工具，但其对条件数和最小奇异值的结果无法推广到更广泛的次高斯随机矩阵，表明高斯结构在这些精细估计中的必要性。

Abstract: Spectral properties of Gram matrices are central to high dimensional asymptotic analyses of statistical estimators in regression and covariance estimation. These properties, in turn, depend critically on the extreme singular values and condition numbers of Gaussian random matrices. For many applications, sharp positive and negative moment bounds for these quantities are required to control expected prediction risk and related performance metrics. Although extensive work provides concentration and tail bounds for extreme singular values of Gaussian random matrices, these results do not readily yield the moment bounds needed in such analyses. Motivated by this gap, we establish non asymptotic moment bounds for arbitrary positive moments of the largest singular value and arbitrary negative moments of the smallest singular value, and uniform bounds for arbitrary positive moments of the condition number of high dimensional Gaussian random matrices. We demonstrate the utility of these bounds by applying them to derive explicit risk guarantees in high dimensional regression and covariance estimation, as well as to obtain bounds on the mean iteration complexity of gradient descent for solving Gram linear systems. Finally, we present counterexamples demonstrating that the positive condition number moment bounds and negative smallest singular value moment bounds cannot, in general, be extended to the broader class of sub Gaussian random matrices.

</details>


### [30] [Confidence in confidence distributions!](https://arxiv.org/abs/2602.22178)
*Céline Cunen,Nils Lid Hjort,Tore Schweder*

Main category: math.ST

TL;DR: 本文补充了前人关于卫星交会分析中贝叶斯方法存在问题的研究，指出其存在“虚假置信”问题，并通过一个可精确分析的原型案例阐明关键点。同时证明了一种基于置信分布的频率学派方法可避免该问题。


<details>
  <summary>Details</summary>
Motivation: 针对贝叶斯方法在卫星交会分析中可能出现的‘虚假置信’问题，进一步揭示其根本原因，并探索更可靠的统计推断方法。

Method: 通过构建一个可进行精确分析的原型模型，比较贝叶斯方法与基于置信分布的频率学派方法在卫星交会分析中的表现。

Result: 贝叶斯方法在特定情况下会产生高置信度但错误的结论（即‘虚假置信’），而基于置信分布的频率学派方法能够避免这一问题。

Conclusion: 在涉及安全关键决策（如卫星防撞）的领域，应谨慎使用贝叶斯方法；基于置信分布的频率学派方法提供了更可靠的替代方案。

Abstract: The recent article `Satellite conjunction analysis and the false confidence theorem' (Balch, Martin, and Ferson, 2019, Proceedings of the Royal Society, Series A) points to certain difficulties with Bayesian analysis when used for models for satellite conjuntion and ensuing operative decisions. Here we supplement these previous analyses and findings with further insights, uncovering what we perceive of as being the crucial points, explained in a prototype setup where exact analysis is attainable. We also show that a different and frequentist method, involving confidence distributions, is free of the false confidence syndrome.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [31] [A Generalized Richardson Number Diagnostic for Turbulence in the Free Atmosphere](https://arxiv.org/abs/2602.21770)
*Mohamed Foudad,Miguel A. C. Teixeira,Paul D. Williams,Thorsten Kaluza*

Main category: physics.ao-ph

TL;DR: 提出了一种新的理查森数公式Ri_new，通过引入水平风切变并基于湍流动能预算，显著提升了对分层自由大气中湍流（尤其是在急流区域附近）的诊断能力。利用ERA5再分析数据和超过2.47亿条飞机自动湍流报告验证，Ri_new在AUC和探测概率上均优于传统理查森数和湍流指数TI1。


<details>
  <summary>Details</summary>
Motivation: 传统理查森数仅考虑垂直风切变，在复杂剪切环境中（如急流区）对湍流的诊断能力有限，需引入水平风切变效应以提高诊断准确性。

Method: 基于湍流动能预算推导出包含垂直和水平风切变（形变和辐散）的新理查森数Ri_new，并用ERA5再分析数据和大量飞机观测数据评估其性能，进行敏感性、季节性和区域性分析。

Result: Ri_new在不同湍流强度阈值下均表现最优，AUC更高，探测概率提升且误报率更低；最佳性能出现在Kmh/Kmv约为5000时，对水平分辨率依赖弱；在陆地尤其是美国本土夏季效果最显著，海洋上也保持优越性能。

Conclusion: 将水平风切变纳入理查森数框架可物理一致且统计稳健地改进湍流诊断，具有重要的科研与业务应用价值。

Abstract: A new Richardson number formulation, Ri_new, is introduced to improve the diagnosis of turbulence in the stratified free atmosphere, particularly near jet stream regions. The formulation is derived from the turbulent kinetic energy budget and accounts for both vertical wind shear and horizontal shear (deformation and divergence), weighted by the ratio of horizontal to vertical eddy viscosities (Kmh/Kmv). This extends the classical Richardson number Ri_old, which includes only vertical shear, and provides a physically based measure of the balance between stratification and three-dimensional shear production. The diagnostics Ri_new, Ri_old, and the widely used Turbulence Index 1 (TI1), computed from ERA5 reanalysis, are evaluated using more than 247 million automated turbulence reports from commercial aircraft (2017-2024). Across various turbulence intensity thresholds, Ri_new consistently outperforms the other diagnostics, resulting in higher AUC values and improved probability of detection at operationally relevant false-alarm rates. Sensitivity analyses show that the predictive skill of Ri_new is maximized for Kmh/Kmv values in the range 10^3-10^4, with peak performance near 5000 and weak dependence on horizontal resolution. Seasonal and regional evaluations indicate that the added value of Ri_new is largest where turbulence generation involves both vertical and horizontal shear, such as over the contiguous United States and during summer. Over oceans, performance remains high and Ri_new still provides the best overall discrimination skill. These results demonstrate that incorporating horizontal wind shear into the Richardson number yields a physically consistent and statistically robust improvement in turbulence diagnostics, with relevance for research and operational applications.

</details>


### [32] [A consistent phase-averaged model of the interactions between surface gravity waves and currents](https://arxiv.org/abs/2602.21976)
*Jacques Vanneste,William R. Young*

Main category: physics.ao-ph

TL;DR: 本文提出了一个描述表面重力波与海洋流体之间双向相互作用的模型，通过将波作用在相空间中的输运与Craik-Leibovich系统耦合，并利用变分结构保证动量和能量守恒。


<details>
  <summary>Details</summary>
Motivation: 研究表面重力波与海洋流之间的相互作用机制，特别是如何通过波-流耦合影响海洋动力过程。

Method: 建立了一个四维位置-波矢相空间中波作用输运与Craik-Leibovich流体系统的耦合模型，引入拉格朗日平均分解、简化假设和Whitham平均方法推导出系统的变分结构。

Result: 模型通过多普勒频移和伪动量实现波-流耦合，垂直积分的拉格朗日平均速度权重与伪动量结构一致，确保了系统动量和能量守恒。

Conclusion: 该模型具有严格的守恒性质，适用于研究如Hasselmann提出的由表面波激发惯性振荡等问题。

Abstract: We formulate a model of the two-way interactions between surface gravity waves and ocean currents. The model couples the transport of wave action in the four-dimensional (horizontal) position--wavevector phase space with the Craik--Leibovich system for the currents. Coupling is via the Doppler shift in the dispersion relation governing action transport, and wave pseudomomentum in the Craik--Leibovich system. The velocity in the Doppler shift is a vertical integral of the Lagrangian mean velocity of the currents, with a weight that is consistent with the vertical structure of the pseudomomentum. This consistency ensures conservation of momentum and energy in the coupled wave--current system.
  The conservation properties of the wave--current model stem from an underlying variational structure. We derive this structure from that of the rotating Euler equations for an incompressible fluid with free surface by introducing a Lagrangian wave--mean decomposition, making simplifying approximations, and Whitham averaging.
  We apply the wave--current model to the problem of generation of inertial oscillations by surface waves originally considered by Hasselmann.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [33] [Effect of glass stability on the low frequency vibrations of vapor deposited glasses](https://arxiv.org/abs/2602.22071)
*I. Festi,E. Alfinelli,D. Bessas,F. Caporaletti,A. I. Chumakov,M. Moratalla,M. A. Ramos,M. Rodríguez-López,C. Rodríguez-Tinoco,J. Rodríguez-Viejo,G. Baldi*

Main category: cond-mat.dis-nn

TL;DR: 本研究利用核共振非弹性X射线散射技术，研究了超稳定玻璃和普通玻璃在极低频率下的振动态密度，发现尽管超稳定玻璃的双能级系统密度显著降低，但最低频率的谐振振动模式不受影响，而较高频率（玻色峰附近）的振动模式则对玻璃稳定性极为敏感，表明准局域化模式并非描述低频振动所必需。


<details>
  <summary>Details</summary>
Motivation: 探讨玻璃中低频振动模式与局部结构不稳定性之间的关系，特别是超稳定玻璃中双能级系统减少是否影响其低频振动特性。

Method: 采用新开发的核共振非弹性X射线散射光谱仪，探测超稳定和常规玻璃非晶薄膜在低至约70 GHz频率下的振动态密度。

Result: 发现玻璃稳定性不影响最低频率的谐振振动模式，尽管双能级系统密度降低了近一个数量级；而在玻色峰附近的较高频率振动模式则对玻璃稳定性高度敏感；准局域化振动模式的存在并非解释低频振动所必需。

Conclusion: 实验结果表明，低频振动特性可能不依赖于准局域化模式的存在，为长期存在的关于玻璃低频振动的争议提供了新的解决路径。

Abstract: Ultra-stable glasses prepared from the physical vapor deposition of organic molecules present a very low density of two-level states, the kind of glass defects that determine their peculiar low temperature thermal properties. Numerical simulations suggest that quasi-localized harmonic vibrational modes emerge in the soft regions associated with two-level states. However, the connection between the low frequency vibrational modes and the local structural instabilities of glasses remains unexplained. Here we exploit a recently developed spectrograph for nuclear resonant analysis of inelastic X-ray scattering to probe the density of vibrational states of amorphous thin films of ultra-stable and conventional glasses down to an exceptionally low frequency of $\sim 70$ GHz. We show that the glass stability does not affect the harmonic vibrational modes at the lowest frequencies, despite a reduction of almost an order of magnitude in the density of two-level states. At the same time, the vibrational modes at higher frequencies, around the boson peak maximum, are extremely sensitive to the glass stability. Although we cannot exclude the possible existence of quasi-localized modes in glasses, we show that their presence is not strictly necessary to describe the measured density of low frequency vibrations. The experimental developments here presented pave the way to the solution to the long-standing debate on the low frequency vibrations in glasses.

</details>


### [34] [Thermal activation drives a finite-size crossover from scale-free to runaway avalanches in amorphous solids](https://arxiv.org/abs/2602.22198)
*Gieberth Rodriguez-Lopez,Ezequiel E. Ferrero*

Main category: cond-mat.dis-nn

TL;DR: 研究无外力驱动下非晶固体中热雪崩动力学，发现温度升高导致雪崩行为从间歇性转变为热辅助流动，并存在系统尺寸依赖的临界温度。


<details>
  <summary>Details</summary>
Motivation: 探究非晶固体在热激活下的动力学行为及其失稳机制。

Method: 使用具有局部激活规则的弹塑性模型进行模拟，分析持久性度量和四点关联响应函数χ_4。

Result: 发现随着温度上升，雪崩统计从无标度行为转变为系统跨度的失控事件；识别出系统尺寸依赖的临界温度Tc(L)，其随尺寸增大而代数下降；揭示了热激活可引发有限尺寸控制的不稳定性尺度。

Conclusion: 热激活本身可在无序弹性介质中诱发有限尺寸控制的失稳，且在热力学极限下任意小但有限的温度都可能导致间歇态失稳。

Abstract: We investigate thermal avalanche dynamics in amorphous solids using elastoplastic models with local activation rules and no external driving. Dynamical heterogeneities, quantified through persistence measurements and the associated four-point susceptibility $χ_4$, reveal the emergence of correlated spatiotemporal rearrangements as temperature is varied. As temperature increases, avalanche statistics evolve from scale-free behavior with exponential cutoffs to regimes dominated by system-spanning runaway events. We identify a system-size-dependent critical temperature $T_c(L)$ that separates intermittent avalanche dynamics from thermally assisted flow, where self-sustained avalanches transiently fluidize the system. We show that $T_c(L)$ decreases algebraically with increasing system size, suggesting that in the thermodynamic limit arbitrarily small but finite temperatures may destabilize the intermittent regime. The relation between avalanche size and duration resembles that in sheared systems, whereas the statistics of minimal distances to yielding reveal a temperature-driven reorganization of marginal stability absent in strictly driven overdamped dynamics. Our results demonstrate that thermal activation alone can generate a finite-size-controlled instability scale in disordered elastic media.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [35] [A Physics-Informed Neuro-Fuzzy Framework for Quantum Error Attribution](https://arxiv.org/abs/2602.21253)
*Marwa R. Hassan,Naima Kaabouch*

Main category: quant-ph

TL;DR: 提出了一种基于神经模糊系统的诊断框架，结合物理特征工程与Bhattacharyya Veto硬约束，有效区分量子计算中的软件错误与硬件噪声，在156量子比特处理器上实现89.5%的准确率，并支持安全失效模式。


<details>
  <summary>Details</summary>
Motivation: 随着量子处理器规模超过100量子比特，软件错误与硬件噪声难以区分，导致传统诊断方法失效，亟需可解释、可靠的归因机制。

Method: 采用自适应神经模糊推理系统（ANFIS），结合物理驱动的特征工程，并引入基于数据处理不等式的Bhattacharyya Veto硬约束，防止将拓扑上不可能的输出归因为噪声；在IBM 156量子比特Heron处理器上验证。

Result: 在105个涵盖17类算法的电路测试中达到89.5%的有效准确率（±5.9%置信区间），14.3%的模糊案例被标记为人工复核；识别出Z基下的相位翻转盲区等单基诊断的根本限制。

Conclusion: 该框架提供了一个鲁棒、可解释的诊断层，能防止对逻辑错误电路误用误差缓解技术，提升了大规模量子计算的调试可靠性。

Abstract: As quantum processors scale beyond 100 qubits, distinguishing software bugs from stochastic hardware noise becomes a critical diagnostic challenge. We present a neuro-fuzzy framework that addresses this attribution problem by combining Adaptive Neuro-Fuzzy Inference Systems (ANFIS) with physics-grounded feature engineering. We introduce the Bhattacharyya Veto, a hard physical constraint grounded in the Data Processing Inequality that prevents the classifier from attributing topologically impossible output distributions to noise. Validated on IBM's 156-qubit Heron r2 processor (ibm_fez) across 105 circuits spanning 17 algorithm families, the framework achieves 89.5% effective accuracy (+/- 5.9% CI). The system implements a safe failure mode, flagging 14.3% of ambiguous cases for manual review rather than forcing low-confidence predictions. We resolve key ambiguities -- such as distinguishing correct Grover amplification from bug-induced collapse -- and identify fundamental limits of single-basis diagnostics, including a Z-basis blind spot where phase-flip errors remain statistically invisible. This work establishes a robust, interpretable diagnostic layer that prevents error mitigation techniques from being applied to logically flawed circuits.

</details>


### [36] [Learning Quantum Data Distribution via Chaotic Quantum Diffusion Model](https://arxiv.org/abs/2602.22061)
*Quoc Hoan Tran,Koki Chinzei,Yasuhiro Endo,Hirotaka Oshima*

Main category: quant-ph

TL;DR: 提出了一种基于混沌哈密顿时间演化的混沌量子扩散模型，用于生成投影系综，该方法仅需全局、时间不变的控制，显著降低了在多种模拟量子平台上的实现开销，同时实现了与现有量子去噪扩散模型相当的精度。


<details>
  <summary>Details</summary>
Motivation: 现有的量子去噪扩散模型依赖于电路式的随机幺正动力学，实现成本高且对控制不完美敏感，尤其在模拟量子硬件上存在挑战。

Method: 利用混沌哈密顿系统的时间演化生成投影系综，作为量子数据分布的学习机制，采用全局且时间不变的控制方式。

Result: 所提方法在多种模拟量子平台上显著降低了实现开销，提升了训练性和鲁棒性，且精度与现有QuDDPMs相当。

Conclusion: 混沌量子扩散模型为量子生成建模提供了一种灵活、硬件兼容的新框架，有助于拓展其在化学信息学和量子物理等领域的应用。

Abstract: Generative models for quantum data pose significant challenges but hold immense potential in fields such as chemoinformatics and quantum physics. Quantum denoising diffusion probabilistic models (QuDDPMs) enable efficient learning of quantum data distributions by progressively scrambling and denoising quantum states; however, existing implementations typically rely on circuit-based random unitary dynamics that can be costly to realize and sensitive to control imperfections, particularly on analog quantum hardware. We propose the chaotic quantum diffusion model, a framework that generates projected ensembles via chaotic Hamiltonian time evolution, providing a flexible and hardware-compatible diffusion mechanism. Requiring only global, time-independent control, our approach substantially reduces implementation overhead across diverse analog quantum platforms while achieving accuracy comparable to QuDDPMs. This method improves trainability and robustness, broadening the applicability of quantum generative modeling.

</details>


### [37] [Random Acceleration Noise on Stern-Gerlach Interferometry in a Harmonic Trap](https://arxiv.org/abs/2602.21288)
*Sneha Narasimha Moorthy,Andrew Geraci,Sougato Bose,Anupam Mazumdar*

Main category: quant-ph

TL;DR: 研究了在存在随机加速度噪声的情况下，嵌有氮空位的纳米金刚石在一维斯特恩-格拉赫干涉仪中的退相干效应，计算了由加速度幅值和方向波动引起的去相速率，并提出了抑制噪声的操作区域。


<details>
  <summary>Details</summary>
Motivation: 探索宏观量子系统在外部噪声环境下的退相干机制，为实现大质量粒子的量子叠加提供噪声控制依据。

Method: 基于有效谐振子动力学模型，将外部加速度及其方向角的涨落作为随机输入，通过作用量方法计算随机臂相位差，并利用Wiener-Khinchin定理求解去相速率。

Result: 得到两种噪声通道的去相速率约束：当加速度为零时，加速度噪声谱密度需小于10^{-11} m/s²/√Hz；当地球重力存在且方向垂直时，角度噪声谱密度需小于10^{-10} rad/√Hz，并发现可通过调节倾角或加速度来最小化噪声影响。

Conclusion: 识别出可显著抑制退相干的操作参数区域，表明通过优化实验设置（如调整超position方向）可提升大质量纳米粒子干涉实验的相干性。

Abstract: We analyze decoherence in a one-loop Stern--Gerlach--type matter-wave interferometer for a massive nanoparticle embedded with a nitrogen vacancy (NV)-centred nanodiamond evolving under an effective harmonic-oscillator dynamics in a magnetic-field gradient. We assume that the Stern-Gerlach interferometer is subjected to a random acceleration noise external to the system. This could be along the direction of the superposition at an angle which can be varied. We quantify dephasing from two noise channels: fluctuations in the external acceleration $a(t)$ magnitude and direction as specified by the tilt angle $θ_0(t)$ between the superposition axis and the acceleration. At the level of the action, we treat these two external noise as stochastic inputs, and compute the resulting stochastic arm-phase difference, and obtain the dephasing rate $Γ$ using the Wiener--Khinchin theorem. For a white noise and a coherence target $Γτ\leq 1$ and by assuming that we finish the one-loop interferometer within $τ=2π/ω_0\simeq 0.015~\mathrm{s}$, for a reasonable choice of the magnetic field gradient, $η_0=6\times 10^{3}~\mathrm{T\,m^{-1}}$ and mass of the nanodiamond, $m=10^{-15}~\mathrm{kg}$) to create a superposition size of $Δx\sim 1$nm. We find $\sqrt{\mathcal{S}_{aa}}\lesssim \mathcal{O}(10^{-11})~\mathrm{m\,s^{-2}\,Hz^{-1/2}}$ even if we take the external acceleration, $a=0~{\rm ms^{-2}}$ and $θ_0=0^\circ$ (along the dirction of the superposition), and $\sqrt{\mathcal{S}_{θθ}}\lesssim \mathcal{O}(10^{-10})~\mathrm{rad\,Hz^{-1/2}}$ for $a=g= 9.81~\mathrm{m\,s^{-2}}$ and $θ_0=0^\circ$ (superposition direction is perpendicular to the Earth's gravity). We have also found an operating regime where the acceleration noise can be minimized by either varying $θ_0$ or $a$ for a fixed set of other experimental parameters.

</details>


### [38] [Improved Fermionic Scattering for the NISQ Era](https://arxiv.org/abs/2505.00476)
*Michael Hite*

Main category: quant-ph

TL;DR: 提出了一种基于Givens旋转和 ladder算符块编码的散射态制备方法，通过空间局域化近似费米子波包，在保持反对易关系的同时将电路深度减少近一半，并在IonQ Forte 1上实现了实验验证。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，受限于噪声和退相干，需尽可能降低量子电路深度，提高模拟效率。

Method: 结合Chai等人提出的Givens旋转态制备与Simon等人的 ladder算符块编码方法，通过空间局域化来近似费米子波包，实现更高效的散射态制备。

Result: 该方法将近似波包的电路深度减少了近一半，并通过MPS模拟验证其在弱相互作用临界理论中接近精确解，且已在IonQ Forte 1设备上成功实现。

Conclusion: 所提出的散射态制备方法在保持物理正确性的同时显著降低了电路复杂度，适用于当前含噪量子硬件。

Abstract: In the era of noisy intermediate scale quantum (NISQ) hardware, digital quantum computers are limited to shallow circuits on the order of a thousand layers due to system noise and qubit decoherence. Thus, every step of a simulation must be as efficient as possible. Modifying the recent Givens Rotation state preparation by Chai et al and ladder operator block encoding method by Simon et al, we propose a scattering state preparation method that approximates the fermionic wave packets by localizing them in space, reducing circuit depth by nearly half, while also preserving fermionic anti-commutation relations. Using MPS simulations, we show that these approximated wave packets approach the exact wave packets in weakly interacting critical theories; and then show its immediate application on modern day hardware with IonQ's Forte 1 machine.

</details>


### [39] [Teleportation transition of surface codes on a superconducting quantum processor](https://arxiv.org/abs/2602.21293)
*Yiren Zou,Hong-Kuan Xia,Aosai Zhang,Xuhao Zhu,Feitong Jin,Qingyuan Wang,Yu Gao,Chuanyu Zhang,Ning Wang,Zhengyi Cui,Fanhao Shen,Zehang Bao,Zitian Zhu,Jiarun Zhong,Gongyu Liu,Jia-Nan Yang,Yihang Han,Yiyang He,Jiayuan Shen,Han Wang,Yanzhe Wang,Jiahua Huang,Xinrong Zhang,Sailang Zhou,Hang Dong,Jinfeng Deng,Yaozu Wu,Zixuan Song,Hekang Li,Zhen Wang,Chao Song,Qiujiang Guo,Pengfei Zhang,Guo-Yi Zhu,H. Wang*

Main category: quant-ph

TL;DR: 在125量子比特超导处理器上实现了最大码距为7的拓扑旋转表面码的鲁棒量子态传输，观测到可调阈值的纠缠相变，并通过注入魔资源恢复拓扑相对偶对称性，为容错量子计算提供新路径。


<details>
  <summary>Details</summary>
Motivation: 实现可扩展的表面码量子态传输是构建容错量子计算的关键挑战，需克服实验中保持长程纠缠和逻辑信息保护的难题。

Method: 利用线性深度酉电路制备拓扑旋转表面码，在125量子比特超导处理器上通过调节局部纠缠门实现逻辑态的量子 teleportation，并引入相干旋转注入非Clifford资源以提升纠缠阈值。

Result: 实现了码距高达7的表面码逻辑态传输；获得了随纠缠强度变化的量子相图；发现魔资源可提高纠缠阈值并恢复对偶对称性；验证了拓扑相的鲁棒性。

Conclusion: 该工作展示了在实际量子硬件上模拟和利用拓扑量子物质的能力，揭示了通过魔资源优化纠缠消耗的新原理，推动分布式容错量子计算的发展。

Abstract: The topological surface code is a leading candidate for harnessing long-range entanglement to protect logical quantum information against errors, and teleportation of logical states is desirable for robust quantum information processing. Nevertheless, scaling up the surface code in quantum teleportation poses a formidable challenge to experiment. Here on a superconducting quantum processor with 125 qubits, we demonstrate the robust teleportation of topological rotated surface code prepared by a linear-depth unitary circuit, with code distances up to 7. We obtain the teleportation phase diagram by tuning the local entangling gates uniformly across a finite threshold. Furthermore, we show that the entangling threshold can be boosted by coherent qubit rotations that inject magic resources beyond the Clifford regime, restoring the duality symmetry of the topological phase, which serves as a guiding principle to minimize the entanglement resource. Our results shed light on simulating and leveraging topological quantum matter on quantum devices, and pave the way to the ultimate goal of distributed fault tolerant quantum computation.

</details>


### [40] [Trade-offs in Gauss's law error correction for lattice gauge theory quantum simulations](https://arxiv.org/abs/2602.22121)
*Balint Pato,Natalie Klco*

Main category: quant-ph

TL;DR: 本文研究了基于高斯定律的量子纠错（GLQEC）在1+1维格点QED中的应用，发现其存在周期性电场约束和多轮纠错下退相干加快的问题，揭示了对称性纠错方案的基本局限性。


<details>
  <summary>Details</summary>
Motivation: 为了降低格点规范理论模拟中的量子比特开销，探索利用内禀对称性的GLQEC方法是否适用于1+1D格点QED。

Method: 通过维度计数论证证明GLQEC需周期性电场，并数值比较GLQEC与d=3比特翻转重复码（UQEC）在单轮和多轮纠错下的逻辑错误率及退相干行为。

Result: GLQEC虽在单轮纠错中表现更优，但在多轮中退相干更快，存在混合速度阈值p_th=0.277(2)，超过该值时其性能甚至不如无纠错；且要求周期性电场限制了设计空间。

Conclusion: GLQEC在实际多轮纠错场景下面临显著退相干问题，且受模型结构限制，提示对称性纠错方案在鲁棒量子模拟中的应用需谨慎权衡。

Abstract: Gauss's law-based quantum error correction (GLQEC) offers a promising approach to reducing qubit overhead in lattice gauge theory simulations by leveraging built-in symmetries. For applications of GLQEC to 1+1D lattice quantum electrodynamics (QED), we identify two significant trade-offs. First, we prove via dimension-counting arguments that GLQEC requires periodic electric fields, thereby constraining the design space for lattice QED simulations. Second, we numerically compare GLQEC with a universal quantum error correction (UQEC) code, specifically the $d=3$ bitflip repetition code, and find that while GLQEC can achieve lower logical error rates in single-round error correction, it exhibits faster decoherence to the steady-state mixed ensemble under multiple rounds. The mixing speed penalty is manifest in observables of interest for both memory experiments and Hamiltonian evolution. We identify a mixing speed threshold, $p_{th}=0.277(2)$, above which using GLQEC exhibits even faster decoherence than without error correction. Our results highlight fundamental limitations of symmetry-based error correction schemes and inform corresponding constraints on formulations of lattice gauge theories compatible with error-robust quantum simulation techniques.

</details>


### [41] [Quantum Error Mitigation Simulates General Non-Hermitian Dynamics](https://arxiv.org/abs/2602.21879)
*Hiroki Kuji,Suguru Endo,Tetsuro Nikuni,Ryusuke Hamazaki,Yuichiro Matsuzaki*

Main category: quant-ph

TL;DR: 提出了一种无需连续监测和辅助量子比特的硬件友好型协议，通过经典高斯白噪声平均和随机量子误差缓解来模拟非厄米动力学。


<details>
  <summary>Details</summary>
Motivation: 在近期量子设备上实现非厄米哈密顿量的非幺正时间演化具有挑战性，需要一种不依赖复杂资源的方案。

Method: 利用GKSL主方程的演化，通过经典高斯白噪声平均模拟非厄米动力学，并使用随机量子误差缓解技术在测量层面抵消量子跳跃项。

Result: 该方法无需辅助量子比特或受控时间演化，且误差缓解层仅需单量子比特操作；数值模拟验证了其在不对称跃迁、相互作用和无序模型中的有效性。

Conclusion: 提供了一个可编程且无需辅助量子比特的框架，用于研究非完全正定且非保迹的奇异动力学。

Abstract: While non-Hermitian Hamiltonians enable exotic dynamical phenomena, implementing their nonunitary time evolution on near-term quantum devices remains challenging. We propose a hardware-friendly protocol that simulates non-Hermitian dynamics without continuous monitoring. Gorini-Kossakowski-Sudarshan-Lindblad (GKSL) evolution via classical Gaussian white-noise averaging and to subsequently cancel the quantum-jump contribution at the level of the measured observable using stochastic quantum error mitigation (QEM). The scheme requires no ancillas or controlled time-evolution, while the mitigation layer uses only single-qubit operations. We validate the method through numerical simulations of a model with asymmetric hopping, interaction, and disorder. Our work provides a programmable and ancilla-free framework investigating exotic dynamics that are not completely-positive and trace-preserving using QEM.

</details>


### [42] [The Inverse Born Rule Fallacy: On the Informational Limits of Phase-Locked Amplitude Encoding](https://arxiv.org/abs/2602.21350)
*Sebastian Zając,Jacob L. Cybulski,Bartosz Dziewit,Tomasz Kulpa*

Main category: quant-ph

TL;DR: 本文讨论了量子机器学习和量子金融中幅度编码的局限性，指出传统的平方根映射无法恢复非对易结构，从而限制了真正的量子优势。作者提倡使用基于QIFT的动力学哈密顿编码，以实现数据驱动的非对易演化。


<details>
  <summary>Details</summary>
Motivation: 传统幅度编码依赖于将量子态视为经典概率分布的导数，但这种做法限制了可访问的希尔伯特空间，并导致表示缺乏相位敏感性。

Method: 通过严格分析P作为|ψ|^2投影的情况，展示简单平方根映射的不足之处，并探讨基变换（如Hadamard门）在此类状态上的应用为何不能复制主动相位反冲机制的计算能力。

Result: 发现简单的平方根映射无法恢复分类任务所需的非对易结构，且基变换不能提供足够的计算能力来模拟相位反冲机制。

Conclusion: 为了获得真正的量子优势，应采用动力学哈密顿编码，其中数据生成非对易演化，而不是作为静态、相位锁定的向量。

Abstract: In Quantum Machine Learning (QML) and Quantum Finance, amplitude encoding is often motivated by its logarithmic storage capacity arXiv:1307.0411. This paradigm typically relies on the mapping $ψ= \sqrt{P}$, treating the quantum state as a derivative of a classical probability distribution $P$. By restricting the data manifold to the positive real orthant $\mathcal{S}^+$, the accessible Hilbert space is effectively abelianized, rendering the representation ``phase-deaf''. We rigorously establish that while $P$ is a projection of $|ψ|^2$, the simple square-root mapping fails to recover the non-commutative structure necessary for genuine quantum advantage in classification tasks. Furthermore, we clarify why applying basis changes (like Hadamard gates) to these states fails to replicate the computational power of active phase-kickback mechanisms. Finally, we advocate for Dynamical Hamiltonian Encoding (based on QIFT), where data generates non-commutative evolution rather than serving as a static, phase-locked vector.

</details>


### [43] [Assessing quantum coherence in quantum annealers](https://arxiv.org/abs/2602.21355)
*Connor Aronoff,Travis Howard,David Nicholaeff,Alejandro Lopez-Bezanilla,Wade DeGottardi*

Main category: quant-ph

TL;DR: 本文提出使用多体相干振荡（MBCO）作为探测模拟量子模拟器中系统级相干性的新方法，并在D-Wave量子退火器上实验验证，发现标准快退火协议下未观察到预期振荡行为，但通过调整退火计划可显著增强振荡可见性，为在噪声大规模量子平台上寻找量子相干性提供了通用路线图。


<details>
  <summary>Details</summary>
Motivation: 在大型量子处理器中展示真正的多体量子相干性是近期量子技术的核心挑战，而现有Kibble-Zurek标度等指标无法区分量子相干与经典或热过程，因此需要更可靠的诊断工具。

Method: 通过求解含时薛定谔方程理论预测一维交错Ising链穿越量子临界点时缺陷观测量中的振荡信号，并在D-Wave Advantage量子退火器上实现该模型，采用快速退火协议进行实验验证，同时分析静态无序和退火调度对结果的影响。

Result: 理论计算显示应存在多体相干振荡（MBCO），但在D-Wave设备上未观测到该振荡；缺陷密度仍符合Kibble-Zurek标度；排除了静态无序为主要成因；发现轻微修改退火调度可显著提升振荡可见性。

Conclusion: 多体相干振荡（MBCO）可作为识别模拟量子模拟器中系统级量子相干性的有效诊断工具，本研究为在嘈杂、大规模量子平台上探测和增强量子相干性提供了可行路径。

Abstract: Demonstrating genuine many-body quantum coherence in large-scale quantum processors remains a central challenge for near-term quantum technologies. Recent experiments on D-Wave quantum annealers have investigated quenches of Ising chains and observed defect densities that show Kibble-Zurek scaling, consistent with coherent quantum dynamics. However, identical scaling can arise from classical or thermal processes. Here we propose the use of many-body coherent oscillations (MBCO) as a diagnostic for the identification of system-wide coherence in analog quantum simulators. Solving the time-dependent Schrodinger equation, we show that quenches of a staggered one-dimensional Ising chain across a quantum critical point produce oscillatory signatures in defect observables. We implement this model on the D-Wave Advantage quantum annealer. Using fast-anneal protocols, we find that, although defect densities follow Kibble-Zurek scaling, the expected oscillatory behavior is absent. We demonstrate that static disorder associated with individual qubits is not likely responsible for the absence of MBCO. Modest modifications to annealing schedules can dramatically enhance oscillation visibility. This work gives a general roadmap for the search for quantum coherence in noisy, large-scale quantum platforms.

</details>


### [44] [Natural Qubit Algebra: clarification of the Clifford boundary and new non-embeddability theorem](https://arxiv.org/abs/2602.21387)
*Grigory Koroteev*

Main category: quant-ph

TL;DR: 提出了一种基于实数算子代数的紧凑型量子比特计算框架NQA，统一描述Clifford与非Clifford算子，应用于两量子比特正规化、贝尔不等式违反的代数解释及量子算法算子的因式分解表示。


<details>
  <summary>Details</summary>
Motivation: 为量子算子提供一种结构清晰、语法紧凑且兼容标准量子力学的实数代数框架，以统一处理Clifford与非Clifford操作，并揭示其代数、谱和语法结构之间的关系。

Method: 引入由{I,X,Z,W}构成的2×2实矩阵块字母表及其张量词表示，定义诱导(Z₂)²ᵐ分级与控制交换符号的双特征的乘法法则，构建自然量子比特代数（NQA），并在该框架下分析两比特算子、Bell-CHSH场景与量子算法中的相位预言机。

Result: 获得了两比特算子的显式实Clifford正规形式；将Bell-CHSH量子违背重新表述为非交换旋量代数无法谱嵌入任何交换Kolmogorov代数；给出了Bernstein-Vazirani和Grover相位预言机的紧凑因式分解表示；表明Grover迭代虽不属于Clifford群但仍具有紧凑张量块形式。

Conclusion: NQA为量子算子提供了分级的代数语言，能够分离谱、代数与语法结构，在保持与标准量子力学兼容的同时，为量子电路设计与分析提供新的符号工具。

Abstract: We introduce Natural Qubit Algebra (NQA), a compact real operator calculus for qubit systems based on a $2\times2$ block alphabet $\{I,X,Z,W\}\subset\mathrm{Mat}(2,\mathbb{R})$ and tensor-word representations. The resulting multiplication law induces a canonical $(\mathbb{Z}_2)^{2m}$-grading with a bicharacter that controls commutation signs, placing the framework naturally within the theory of color-graded and Clifford-type algebras.
  Within this language, we provide: (i) an explicit real Clifford normal form for two-qubit operators via the identification $\mathrm{Mat}(4,\mathbb{R})\cong\mathrm{Cl}(2,2;\mathbb{R})$; (ii) a purely algebraic reformulation of the Bell--CHSH scenario, where the quantum violation is expressed as a spectral non-embeddability of a noncommutative spinor algebra into any commutative Kolmogorov algebra; and (iii) compact factored representations of the Bernstein--Vazirani and Grover phase oracles, showing that both Clifford and non-Clifford examples can admit similarly structured symbolic descriptions.
  We clarify that Grover's iterate remains outside the Clifford group due to its continuous spectral rotation, consistent with the Gottesman--Knill theorem, while retaining a compact tensor-block form in NQA. The framework isolates spectral, algebraic, and syntactic aspects of operator structure, providing a graded operator language compatible with standard quantum mechanics.

</details>


### [45] [Imperfect Graphs from Unitary Matrices -- I](https://arxiv.org/abs/2602.21808)
*Wesley Lewis,Darsh Pareek,Umesh Kumar,Ravi Janjam*

Main category: quant-ph

TL;DR: 提出了一种基于图论的量子算子分析框架，称为叠加的拓扑结构（TSS），通过忽略幅度和相位信息来研究量子电路中的信息流拓扑。


<details>
  <summary>Details</summary>
Motivation: 为了更清晰地理解量子电路中信息流动的结构拓扑，避免矩阵表示带来的不直观性。

Method: 将量子态的计算基作为顶点，非零振幅转移对应有向边，构建描述酉算子支持结构的有向图模型，并忽略概率幅和相位信息以突出连通性和可达性。

Result: 成功用TSS描述了Hadamard、Pauli等常见量子门的结构，展示了该框架在可视化和设计量子算法方面的潜力。

Conclusion: TSS为分析和设计量子算法提供了一个新的图论视角，有助于将量子电路视为离散动力系统进行研究。

Abstract: Matrix representations of quantum operators are computationally complete but often obscure the structural topology of information flow within a quantum circuit \cite{nielsen2000}. In this paper, we introduce a generalized graph-theoretic framework for analyzing quantum operators by mapping unitary matrices to directed graphs; we term these structures \emph{Imperfect Graphs} or more formally as \emph{Topological Structure of Superpositions}(TSS) as a tool to devise better Quantum Algorithms. In this framework, we represent computational basis states as vertices. A directed edge exists between two vertices if and only if there is a non-zero amplitude transition between them, effectively mapping the support of the unitary operator. In this paper we deliberately discard probability amplitudes and phase information to isolate the connectivity and reachability properties of the operator. We demonstrate how TSS intuitively helps describe gates such as the Hadamard, Pauli-(X,Y,Z) gates, etc \cite{nielsen2000}. This framework provides a novel perspective for viewing quantum circuits as discrete dynamical systems \cite{childs2009,aharonov2001}
  Keywords: Quantum Algorithms, Unitary Matrix Approach, Topological Structure of Superpositions (TSS), Graph Theory

</details>


### [46] [Markovian Embeddings of Non-Markovian Open System Dynamics](https://arxiv.org/abs/2602.21430)
*Meng Xu,J. T. Stockburger,J. Ankerhold*

Main category: quant-ph

TL;DR: 本文提出了一种将非马尔可夫量子动力学嵌入到扩大的马尔可夫空间中的新框架，通过高斯浴自能的不同展开方式，生成一系列确定性、时间局域的方程，统一解释了如HEOM和Lindblad-伪模形式等现有方法，并实现了高效稳定的数值模拟。


<details>
  <summary>Details</summary>
Motivation: 非马尔可夫开放量子系统难以进行非微扰模拟，现有方法缺乏统一理论基础，因此需要一种更通用且数值稳定的方法来处理复杂动力学。

Method: 通过将非马尔可夫动力学嵌入扩大的马尔可夫空间，并对高斯浴自能进行不同类型的展开（unraveling），导出一族时间局域的确定性方程，以描述扩展系统的演化。

Result: 揭示了HEOM与Lindblad-伪模等方法之间的内在联系，展示了该框架在数值上稳定且高效，能够灵活应用于不同类型的谱密度（如布朗振子模型）。

Conclusion: 该工作为嵌入技术提供了清晰的理论基础，构建了一个灵活的平台，可用于发展新的非马尔可夫量子动力学模拟方法。

Abstract: Embedding non-Markovian open quantum dynamics into an enlarged Markovian space offers a powerful route to nonperturbative simulations, where the dynamics of the extended space can be governed by multiple distinct Markovian equations. We show that these distinct embeddings arise from different unravelings of Gaussian bath self-energies, generating a family of deterministic, time-local equations for the extended system. Using the Brownian-oscillator spectral density as an illustrative example, we clarify the relationships among existing approaches, including the Hierarchical Equations of Motion (HEOM) and the Lindblad--pseudomode formalism, and demonstrate how this framework enables numerically stable and efficient simulations. This work provides both a transparent theoretical foundation for embedding techniques and a flexible platform for developing new methods to simulate non-Markovian quantum dynamics.

</details>


### [47] [Quantum jumps in open cavity optomechanics and Liouvillian versus Hamiltonian exceptional points](https://arxiv.org/abs/2602.22205)
*Aritra Ghosh,M. Bhattacharya*

Main category: quant-ph

TL;DR: 本文研究了腔光力学系统中的例外点（exceptional points），区分了由无条件林德布拉德动力学产生的Liouvillian例外点和由条件无跃迁演化产生的哈密顿例外点，并通过热场形式提出了一种统一的混合李氏描述框架，揭示了在弱量子跃迁 regime 下哈密顿例外点的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了澄清非厄米系统中Liouvillian与哈密顿例外点之间的物理区别，特别是在腔光力学这一多领域关注的平台上，理解量子跃迁和热浴温度对例外点的影响。

Method: 采用热场（thermofield）形式化方法，构建了一个统一的混合李氏（hybrid-Liouvillian）谱理论框架，用于插值分析条件与无条件动力学下的例外点行为。

Result: 发现Liouvillian例外点与声子浴温度无关，而哈密顿例外点因增强的条件阻尼而产生热偏移；在弱量子跃迁 regime 下，例外点仅在二阶被扰动，显示出哈密顿例外点的鲁棒性。

Conclusion: 工作揭示了一族连续的混合例外点，阐明了腔光力学系统中条件与无条件耗散动力学的操作与物理差异，并为探测热浴提供了新途径。

Abstract: Exceptional points, where two or more eigenstates of a non-Hermitian system coalesce, are now of interest across many fields of physics, from the perspective of open-system dynamics, sensing, nonreciprocal transport, and topological phase transitions. In this work, we investigate exceptional points in cavity optomechanics, a platform of interest to diverse communities working on gravitational-wave detection, macroscopic quantum mechanics, quantum transduction, etc. Specifically, we clarify the role of quantum jumps in making a clear distinction between Liouvillian and Hamiltonian exceptional points in optomechanical systems. While the Liouvillian exceptional point arises from the unconditional Lindblad dynamics and is independent of the phonon-bath temperature, the Hamiltonian exceptional point emerges from the conditional no-jump evolution and acquires a thermal shift due to an enhanced conditional damping. Employing the thermofield formalism, we derive a unified spectral framework that interpolates between these regimes via an analytical hybrid-Liouvillian description. Remarkably, in the weak-quantum-jump regime, the exceptional point is perturbed only at the second order, highlighting the robustness of the Hamiltonian exceptional point under small hybrid perturbations. Our work reveals a continuous family of hybrid exceptional points, clarifies the operational and physical differences between the conditional and unconditional dissipative dynamics in optomechanical systems, and provides a probe for thermal baths.

</details>


### [48] [Topological phase dynamics described by overtone-synthesized classical and quantum Adler equations](https://arxiv.org/abs/2602.21451)
*Hiroshi Yamaguchi,Motoki Asano*

Main category: quant-ph

TL;DR: 本文通过引入高次谐波合成的正弦耦合和绝热时间调制，扩展了Adler方程模型，并研究其在经典与量子 regime 下的独特拓扑特性，发现量子情况下缠绕数量子化的破坏及滞后动力学的恢复。


<details>
  <summary>Details</summary>
Motivation: 受光学机械振荡器实验启发，旨在探索包含高次谐波耦合和调制的广义Adler模型中的拓扑相位动力学行为。

Method: 扩展Adler方程以包含高次谐波合成耦合与绝热调制，并在经典和量子框架下进行分析，采用Floquet理论和非绝热量子计算方法。

Result: 发现了缠绕数量子化、相滑移跃迁、滞后和非互易相动力学等拓扑特征；在量子情况下观察到缠绕数量子化的破坏以及滞后动力学在非绝热条件下的恢复。

Conclusion: 量子效应导致传统经典拓扑现象（如缠绕数量子化）的失效，但非绝热效应可恢复类似滞后的动力学行为，揭示了封闭空间 Thouless 泵中叠加态的重要作用。

Abstract: The Adler equation is a well-known one-dimensional model describing phase locking and synchronization. Motivated by recent experiments using optomechanical oscillators, we extend the model to include overtone-synthesized sinusoidal coupling with adiabatic temporal modulation. This extension gives rise to unique topological features such as winding-number quantization, discontinuous phase-slip transitions, and hysteretic and non-reciprocal phase dynamics. We further extend the analysis to the quantum regime, where we find a counterintuitive result: the breakdown of winding-number quantization. This arises from the superposition of different winding-number states in a closed-space Thouless pump. Moreover, hysteretic dynamics, once eliminated in quantum adiabatic approximation, is recovered in non-adiabatic calculations, as the superposition of two Floquet states with different PT eigenvalues becomes the quantum counterpart of phase trajectory.

</details>


### [49] [On fully entangled fraction of arbitrary $d\otimes d$ quantum states](https://arxiv.org/abs/2602.21471)
*Xue-Na Zhu,Gui Bao,Ming Li,Ming-Jing Zhao,Shao-Ming Fei*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the fully entangled fraction of quantum states based on the Bloch representation of density matrices. Analytical upper bounds on the fully entangled fraction are obtained for arbitrary $d\otimes d$ bipartite systems. The fully entangled fractions for classes of $d\otimes d$ quantum states are analytically derived. Detailed examples are given to illustrate the advantages of our results.

</details>


### [50] [Passive Synchronization of Nonlocal Franson Interferometry for Fiber-Based Quantum Networks Using Co-propagating Classical Clock Signals](https://arxiv.org/abs/2602.21483)
*Xiao Xiang,Runai Quan,Yuting Liu,Huibo Hong,Bingke Shi,Zhiguang Xia,Xinghua Li,Tao Liu,Shougang Zhang,Ruifang Dong*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We demonstrate a robust, high-visibility nonlocal Franson interferometry for fiber-based quantum networks by co-propagating a classical Radio-over-Fiber clock signal with energy-time entangled photon pairs in the same fiber. Utilizing cross-band allocation (O-band for classical, L-band for quantum signals), the spontaneous Raman scattering noise photons are effectively suppressed. At the same time, their environmental delay fluctuations remain highly correlated for common-mode noise cancellation, achieving a passive synchronization with picoseconds precision. Over 50 km of single-mode fiber, this co-propagation enables nonlocal quantum interference with a visibility of (88.35\pm3.62)%, without relying on external dedicated timing infrastructure. This work provides a practical, scalable synchronization solution for metropolitan-scale entanglement-based quantum networks.

</details>


### [51] [Universal Sample Complexity Bounds in Quantum Learning Theory via Fisher Information matrix](https://arxiv.org/abs/2602.21510)
*Hyukgun Kwon,Seok Hyung Lie,Liang Jiang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, we show that the sample complexity (equivalently, the number of measurements) required in quantum learning theory within a general parametric framework, is fundamentally governed by the inverse Fisher information matrix. More specifically, we derive upper and lower bounds on the number of samples required to estimate the parameters of a quantum system within a prescribed small additive error and with high success probability under maximum likelihood estimation. The upper bound is governed by the supremum of the largest diagonal entry of the inverse Fisher information matrix, while the lower bound is characterized by any diagonal element evaluated at arbitrary parameter values. We then apply the general bounds to Pauli channel learning and to the estimation of Pauli expectation values in the asymptotic small-error regime, and recover the previously established sample complexity through considerably streamlined derivations. Furthermore, we identify the structural origin of exponential sample complexity in Pauli channel learning without entanglement and in Pauli expectation value estimation without quantum memory. We then extend the analysis to an error criterion based on the Euclidean distance between the true parameter values and their estimators. We derive the corresponding upper and lower bounds on the sample complexity, which are likewise characterized by the inverse Fisher information matrix. As an application, we consider Pauli expectation estimation with entangled probes. Finally, we highlight two fundamental contributions to quantum learning theory. First, we establish a systematic framework that determines the task-independent sample complexity under maximum-likelihood estimation. Second, we show that, in the small-error regime, learning sample complexity is governed by the inverse Fisher information matrix.

</details>


### [52] [Optimized ancillary drive for fast Rydberg entangling gates](https://arxiv.org/abs/2602.21512)
*Rui Li,Min-Hua Zhang,Jing Qian*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reaching fast and robust two-qubit gates with low infidelities has been an outstanding challenge for the long-term goal of useful quantum computers. Typically, optimizing the pulse shapes can minimize the gate infidelity and improve its robustness to certain types of errors; yet it remains incapable of speeding up the gate execution time which is fundamentally restricted by the attainable Rabi frequency in a realistic setup. In this work, we develop a fast implementation of two-qubit CZ gates using optimized ancillary drive to enhance the two-photon Rabi frequency between the ground and Rydberg states.This ancillary drive can work in an error-robustness framework without increasing the original gate infidelity in the absence of the drive. Considering the experimentally feasible parameters for $^{87}$Rb atoms, we demonstrate that the execution time required for such CZ gates can be shortened by more than 30$\%$ as compared to standard two-photon protocols arising the gate fidelity above 0.9954 by taking account of all relevant error sources. Our results reduce the high-power laser requirement and unlock the potential toward fast, high-fidelity quantum operations for large-scale quantum computation with neutral atoms.

</details>


### [53] [Quantum criticality in open quantum systems from the purification perspective](https://arxiv.org/abs/2602.21979)
*Yuchen Guo,Shuo Yang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Open quantum systems host mixed-state phases that go beyond the symmetry-protected topological and spontaneous symmetry-breaking paradigms established for closed, pure-state systems. Developing a unified and physically transparent classification of such phases remains a central challenge. In this work, we introduce a purification-based framework that systematically characterizes all mixed-state phases in one-dimensional systems with $\mathbb{Z}_2^σ \times \mathbb{Z}_2^τ$ symmetry. By introducing an ancillary $κ$ chain and employing decorated domain-wall constructions, we derive eight purified fixed-point Hamiltonians labeled by topological indices $(μ_{στ},μ_{τκ},μ_{κσ}) \in \{\pm1\}^3$. Tracing out the ancilla recovers the full structure of mixed-state phases, including symmetric, strong-to-weak spontaneous symmetry breaking, average symmetry-protected topological phases, and their nontrivial combinations. Interpolations between the eight fixed points naturally define a three-dimensional phase diagram with a cube geometry. The edges correspond to elementary transitions associated with single topological indices, while the faces host intermediate phases arising from competing domain-wall decorations. Along the edges, we identify a class of critical behavior that connects distinct strong-to-weak symmetry-breaking patterns associated with distinct strong subgroups, highlighting a mechanism unique to mixed-state settings. Large-scale tensor-network simulations reveal a rich phase structure, including pyramid-shaped symmetry-breaking regions and a fully symmetry-broken phase at the cube center. Overall, our purification approach provides a geometrically transparent and physically complete classification of mixed-state phases, unified with a single $\mathbb{Z}_2^σ \times \mathbb{Z}_2^τ \times \mathbb{Z}_2^κ$ model.

</details>


### [54] [Momentum Diffusion, Decoherence and Drag Force on a Magnetic Nanoparticle](https://arxiv.org/abs/2602.21518)
*Agya Sewara Alam,Anupam Mazumdar*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we will provide a complete derivation of the decoherence rate for a magnetic nanoparticle in quantum superposition in the presence of the fluctuating electromagnetic field in a thermal background by using the fluctuation-dissipation theorem in the long-wavelength limit. The long-wavelength limit assumes that the superposition size is much smaller than the wavelength of the electromagentic filed fluctuations. We will extend this computation to two diamagnetic nanoparticles kept in quantum superposition adjacent to each other. We will also show how the drag force on a single nanoparticle arises from external electromagnetic-field fluctuations, and compare our results with those for the nanoparticle's dielectric properties.

</details>


### [55] [Efficient time-series prediction on NISQ devices via time-delayed quantum extreme learning machine](https://arxiv.org/abs/2602.21544)
*Mio Kawanabe,Saud Cindrak,Kathy Luedge,Jun-ichi Shirakashi,Tetsuo Shibuya,Hiroshi Imai*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We proposed a time-delayed quantum extreme learning machine (TD-QELM) for efficient time-series prediction on noisy intermediate-scale quantum (NISQ) devices. By encoding multiple past inputs simultaneously, TD-QELM achieves shallow circuit depth independent of sequence length, thereby, mitigating noise accumulation and reducing computational complexity. Experiments using the NARMA benchmark on both noiseless simulations and IBM's 127-qubit processor demonstrate that TD-QELM consistently outperforms conventional quantum reservoir computing in prediction accuracy and noise robustness. These results highlight TD-QELM as a practical and scalable framework for time-series learning on current NISQ hardware.

</details>


### [56] [Passive Environment-Assisted Quantum Communication](https://arxiv.org/abs/2602.21549)
*Evelyn Voss,Bikun Li,Zhaoyou Wang,Liang Jiang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As quantum information systems mature, efficient and coherent transfer of quantum information through noisy channels becomes increasingly important. We examine how passive environment-assisted quantum communication enhances direct quantum information transfer efficiency. A bosonic pure-loss channel, modeled as transmission through a beam splitter with a vacuum input state at the dark port, has zero quantum capacity when transmissivity is below 50%. Quantum communication through the channel can be enhanced by passive environment assistance, achieved via the selection of an appropriate input state for the ancilla port. Although ideal Gottesman-Kitaev-Preskill (GKP) states enable perfect quantum information transmission at arbitrarily small transmissivity, they are challenging to realize experimentally. We therefore explore more experimentally accessible non-Gaussian ancilla states, such as Fock, cat, and squeezed cat states, and numerically determine the optimal encoding and decoding strategies. We also construct analytical schemes that yield high-fidelity transmission and good information rates.

</details>


### [57] [Performance Comparison of QAOA Mixers for Ternary Portfolio Optimization](https://arxiv.org/abs/2602.21562)
*Shintaro Yamamura,Satoshi Watanabe,Masaya Kunimi,Kazuhiro Saito,Tetsuro Nikuni*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm proposed for Noisy Intermediate-Scale Quantum (NISQ) devices and is regarded as a promising approach to combinatorial optimization problems, with potential applications in the financial sector. In this study, we apply QAOA to the portfolio optimization problem, which is one of the central challenges in financial engineering. A portfolio consists of a combination of multiple assets, and the portfolio optimization problem aims to determine the optimal asset allocation by balancing expected return and risk. In the context of quantum optimization, portfolio optimization is often formulated using discrete variables. Unlike conventional binary formulations, we consider a ternary portfolio optimization problem that accounts for three states-holding, not holding, and short selling-and compare its performance using different mixer operators. Specifically, we implement QAOA with the standard mixer and several XY Mixers (XY Ring, XY Parity Ring, XY Full, and QAMPA), and conducted simulations using real data based on the German stock index (DAX 30) for portfolios consisting of 5 and 8 assets. Furthermore, we introduce noise based on a depolarizing channel to investigate the behavior of the algorithm in realistic environments. The results show that while XY Mixers exhibit superiority in noiseless settings, their advantage degrades in noisy environments, and the optimal choice of mixer depends on both the number of QAOA depths and the noise strength.

</details>


### [58] [Entanglement recovery by reversing the effect of noise in quantum repeater](https://arxiv.org/abs/2602.21563)
*Sewon Jeong,Shrobona Bagchi,Jaehak Lee,Hyang-Tag Lim,Yong-Su Kim,Taeyoung Choi,Seung-Woo Lee*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a method to directly recover the degree of entanglement distributed by entanglement swapping in the presence of noise. Our approach introduces a reversing operation that probabilistically undoes the effect of amplitude damping or photon loss on a single entangled pair, enabling heralded recovery of entanglement. We demonstrate that entanglement can be substantially recovered even under strong noise, including parameter regimes where the distributed entanglement would otherwise vanish due to entanglement sudden death. We analyze the effectiveness of the protocol in two representative repeater models, i.e.,~two-way and one-way architectures and identify the optimal reversing strategy. Due to its heralded and single-copy nature, our protocol is readily compatible with other entanglement recovery techniques such as entanglement purification and distillation. Our work provides a practical and experimentally feasible way toward robust entanglement distribution in current and near-term quantum repeater architectures.

</details>


### [59] [Revealing entanglement through local features of phase-space distributions](https://arxiv.org/abs/2602.21688)
*Elena Callus,Martin Gärttner,Tobias Haas*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We formulate an infinite hierarchy of continuous-variable separability criteria in terms of quasiprobability distributions and their derivatives evaluated at individual points in phase space. Our approach is equivalent to the Peres--Horodecki criterion and sheds light on how distillable entanglement manifests in the phase-space picture. We demonstrate that already the lowest-order variant constitutes a powerful method for detecting the elusive non-Gaussian entanglement of relevant state families. Further, we devise a simple measurement scheme that relies solely on passive linear transformations and coherent ancillas. By strategically probing specific phase-space regions, our method offers clear advantages over existing techniques that rely on access to the full phase-space distributions.

</details>


### [60] [Landscape-Similarity-Guided Optimization in QAOA](https://arxiv.org/abs/2602.21689)
*Sokea Sang,Leanghok Hour,Sanghyeon Lee,Aniket Patra,Hee Chul Park,Moon Jip Park,Youngsun Han*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Across diverse synthetic and real-world interaction graphs, the variational landscapes of reduced Quantum Approximate Optimization Algorithm (QAOA) instances obtained via variable freezing exhibit a robust universality. Leveraging this structure, we introduce Doubly Optimized QAOA (DO-QAOA), which lowers runtime and quantum measurement overhead while maintaining a competitive approximation ratio gap (ARG). Adapting the replica-overlap framework of spin-glass physics, we define a landscape-overlap order parameter $q$ to quantify geometric correlations between energy landscapes, revealing a sharp landscape-similarity transition as graph connectivity is tuned. Notwithstanding this transition, the dominant convex features of nearly all conditioned sub-instances remain aligned across both phases. Exploiting this persistence, DO-QAOA collapses the nominal $2^m$ reduced instances generated by freezing $m$ qubits into $K = O(1)$ effective landscape classes, eliminating the exponential proliferation in $m$. By leveraging landscape structure, DO-QAOA provides a scalable route to hybrid quantum-classical optimization under realistic hardware constraints, with potential applicability across variational quantum algorithms.

</details>


### [61] [Generating large-scale Greenberger-Horne-Zeilinger-like states in lattice spin systems](https://arxiv.org/abs/2602.21839)
*Xuanchen Zhang,Yaofeng Chen,Yong-Chun Liu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Greenberger-Horne-Zeilinger (GHZ) state is a typical maximally entangled state which is pursued in both fundamental research and emerging quantum technologies. Preparing large-scale GHZ states in lattice spin systems is particularly appealing for quantum advantages, but conventional schemes face great challenges in scalability. Here we propose a universal and scalable scheme to generate large-scale GHZ-like states, which share similar entanglement and metrological properties with standard GHZ states, in lattice spin systems through global Floquet engineering. Our scheme requires only global operations and shows great advantage for large particle number. It is applicable to systems with arbitrary interaction ranges, offering a practical pathway for large-scale implementation of many-body entangled states in various systems.

</details>


### [62] [Deep squeezing or cooling the fluctuations of a parametric resonator using feedback](https://arxiv.org/abs/2602.21847)
*Adriano A. Batista*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Here we analyze ways to achieve deep subthreshold parametric squeezing or cooling of a single degree-of-freedom parametric resonator enhanced by a lock-in amplifier feedback loop. Due to the feedback, the dynamics of the parametric resonator becomes more complex and a Hopf bifurcation at the instability threshold can occur. Initially, we calculate the phase-dependent gain of parametric amplification with feedback of an added ac signal. In one approach, we obtain the amplification gain approximately using two independent approaches: the averaging method and the harmonic balance method. We also obtain this gain more exactly using Floquet theory and Green's functions methods. The Hopf bifurcation was predicted by the harmonic balance method and by Floquet theory, but not by the averaging method. In our analysis of fluctuations, we Fourier analyze the response of the parametric resonator with feedback to an added white noise. We were able to calculate, in addition to the noise spectral density, the squeezing of fluctuations in this resonator with feedback. Very strong squeezing or cooling can occur. Deamplification and cooling occur near the Hopf bifurcation, whereas squeezing occurs near a saddle-node bifurcation.

</details>


### [63] [Analysis of the action of conventional trapped-ion entangling gates in qudit space](https://arxiv.org/abs/2602.21886)
*Pavel Kamenskikh,Nikita Semenin,Ilia Zalivako,Vasiliy Smirnov,Ilya Semerikov,Ksenia Khabarova,Nikolay Kolachevsky*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Qudits, or multi-level quantum information carriers, present a promising path for scaling quantum computers. However, their use introduces increased complexity in quantum logic, necessitating careful control of relative phases between different qudit levels. In trapped-ion systems, entangling operations accumulate phases on specific levels that are no longer global, unlike in qubit architectures. Furthermore, the structure of multi-level gates becomes increasingly intricate with higher-dimensional Hilbert spaces. This work explores the theory of these additional entangling and non-entangling phases, accumulated in Mølmer--Sørensen and Light-shift gates. We propose methods to actively compensate for these phases, enhance gate robustness against parameter fluctuations, and simplify native gates for more efficient circuit decomposition. Our results pave the way toward the practical and scalable implementation of qudit-based quantum processors.

</details>


### [64] [Prodiabatic Elimination: Higher Order Elimination of Fast Variables with Quantum Noise](https://arxiv.org/abs/2602.21896)
*Jan Neuser,Marcelo Janovitch,Matteo Brunelli,Patrick P. Potts*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce the prodiabatic elimination, a powerful approximation technique that systematically extends the adiabatic elimination of fast degrees of freedom in light-matter coupled systems. Through a controlled expansion of operators, the prodiabatic elimination incorporates higher-order corrections and consistently includes noise contributions, leading to a significantly improved performance compared to standard adiabatic elimination. Importantly, it retains the simplicity and computational efficiency of the adiabatic elimination, making it convenient for practical applications. We demonstrate the approach on two setups: a driven dissipative Jaynes-Cummings model and a three-level system in a two-mode cavity that performs stimulated Raman adiabatic passage (STIRAP). These examples establish the prodiabatic elimination as a robust and broadly applicable tool for analyzing open quantum systems.

</details>


### [65] [Quantum tomography for non-iid sources](https://arxiv.org/abs/2602.22057)
*Leonardo Zambrano*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum state and process tomography are typically analyzed under the assumption that devices emit independent and identically distributed (i.i.d.) states or channels. In realistic experiments, however, noise, drift, feedback, or adversarial behavior violate this assumption. We show that projected least-squares tomography remains statistically optimal even under fully adaptive state and channel preparation. Specifically, we prove that the sample complexity for reconstructing the time-averaged state or channel matches the optimal i.i.d. scaling for non-adaptive, single-copy measurements. For rank-$r$ states, the sample complexity is $\mathcal{O}(d r^2/ε^2)$ to achieve accuracy $ε$ in trace distance, while for process tomography it is $\mathcal{O}(d^6/ε^2)$ to achieve accuracy $ε$ in diamond distance. Thus, dropping the i.i.d. assumption does not increase the fundamental sample complexity of quantum tomography, but only changes the interpretation of the reconstructed object.

</details>


### [66] [On the emergence of quantum mechanics from stochastic processes](https://arxiv.org/abs/2602.22095)
*Jason Doukas*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The stochastic--quantum correspondence reinterprets quantum dynamics as arising from an underlying stochastic process on a configuration space. We generalize the correspondence by lifting an arbitrary stochastic kernel $Γ$ in finite dimension to a map $φ$ on $B(\mathcal H)$, formulating the associated lift-compatibility relation, and giving an explicit dictionary between $Γ$ and CPTP (Kraus) maps. We isolate Chapman--Kolmogorov divisibility of the lifted family as the decisive additional constraint: when a CK-consistent CPTP family exists, the lift admits a Lindblad master equation form. In this picture, off-diagonal (phase) degrees of freedom act as a compressed carrier of history dependence not fixed by transition kernels alone; conversely, the apparent emergence of quantum phase information from a phase-blind stochastic description is explained as a memory effect. Finally, we state and prove a divisibility criterion for the underlying stochastic kernels, expressed as a condition involving divisibility of the lifted map together with a diagonality requirement on the density operator.

</details>


### [67] [Self-stabilized high-dimensional quantum key distribution on a metropolitan free-space link](https://arxiv.org/abs/2602.22102)
*Karolina Dziwulska,Christopher Spiess,Sarika Mishra,Markus Leipe,Yugant Hadiyal,Fabian Steinlechner*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum communication technologies capable of operating reliably across heterogeneous optical channels are essential for scalable metropolitan quantum networks. Here we demonstrate high-dimensional time-bin-encoded quantum key distribution over a hybrid metropolitan link comprising 1.7 km free-space transmission and 685 m of optical fiber. Operating at a clock rate of 500 MHz in the C-band, we implement both 2- and 4-dimensional protocols, and obtain estimated secure finite-key rates of (95 +- 28) kbit/s for 4D at (25.0 +- 2.0) dB loss and (59 +- 27) kbit/s for 2D at (23.5 +- 2.3) dB loss. Crucially, we achieve continuous operation over 48 h in a fully self-referenced architecture: initial synchronization, interferometric phase stabilization, and long-term drift compensation are performed exclusively using the detected quantum signals, without auxiliary optical reference channels. Our results thus establish a practical and versatile platform for hybrid free-space-to-fiber quantum communication and show that the encoding dimensionality can be adapted to the optimal operating regime of realistic metropolitan channels, providing a pathway toward efficient, autonomous and deployable quantum network nodes.

</details>


### [68] [Loss Mechanisms in High-coherence Multimode Mechanical Resonators Coupled to Superconducting Circuits](https://arxiv.org/abs/2602.22117)
*Raquel Garcia Belles,Alexander Anferov,Lukas F. Deeg,Loris Colicchio,Arianne Brooks,Tom Schatteburg,Maxwell Drimmer,Ines C. Rodrigues,Rodrigo Benevides,Marco Liffredo,Jyotish Patidar,Oleksandr Pshyk,Matteo Fadel,Luis Guillermo Villanueva,Sebastian Siol,Gerhard Kirchmair,Yiwen Chu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Circuit quantum acoustodynamics (cQAD) devices have a wide range of applications in quantum science, all of which depend crucially on the quantum coherence of the mechanical subsystem. In this context, high-overtone bulk acoustic-wave resonators (HBARs) are particularly promising, since they have shown very high quality factors with negligible dephasing. However, the introduction of piezoelectric films, which are necessary for coupling to a superconducting circuit, can lead to additional loss channels, such as surface scattering and two-level systems (TLS). Here, we study the acoustic dissipation of HBAR resonators in cQAD systems and find that the defect density of the piezoelectric material and its interface with the bulk are limiting factors for the coherence. We measure acoustic modes with phonon lifetimes up to 400 $μ$s and lifetime-limited coherence times approaching one millisecond in the quantum regime. When coupled to a superconducting qubit, this leads to a hybrid system with a large quantum coherence cooperativity of $C_{T_2}=1.1\times10^5$. These results represent a new milestone for the performance of cQAD devices and offer concrete paths forward for further improvements.

</details>


### [69] [Energy efficient optical tracking for space quantum communication](https://arxiv.org/abs/2602.22160)
*Eric Vokes,Vinod N. Rao,Elinore Spencer,Rupesh Kumar*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Power consumption is a critical constraint for CubeSat based quantum communication, where tracking systems often dominate the onboard power budget. We demonstrate an energy-efficient approach that enables reliable satellite tracking at substantially reduced beacon power by treating tracking as a weak-signal estimation task. Using a closed-loop system with fine steering mirrors and higher-order Kalman filters on ground, we can maintain stable tracking at a transmitted power equivalent to 34 mW over a -60 dB satellite to ground optical channel. Our results show that the resulting penalties on QKD bit error rates and signal-to-noise ratios are negligible, allowing for more efficient power allocation to quantum payloads in CubeSat missions.

</details>


### [70] [Beyond Single-Shot Fidelity: Chernoff-Based Throughput Optimization in Superconducting Qubit Readout](https://arxiv.org/abs/2602.22174)
*Sinan Bugu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Single-shot fidelity is the standard benchmark for superconducting qubit readout, but it does not directly minimize the total wall-clock time required to certify a quantum state. We formulate an information-theoretic description of dispersive readout that treats the measurement record as a stochastic communication channel and compute the classical Chernoff information governing the multi-shot error exponent using a trajectory model that incorporates T1 relaxation with full cavity memory. We find a consistent separation between the integration time that maximizes single-shot fidelity and the time that minimizes total certification time. For representative transmon parameters and hardware overheads, the throughput-optimal integration window is longer than the fidelity-optimal one, yielding certification speedups of approximately 9-11%, with the gain saturating near 1.13x in the high-readout-power and high-overhead regime. Comparing the extracted classical information to the Gaussian Chernoff limit defines an information-extraction efficiency metric and shows that typical dispersive schemes are limited to about 45% capture at short integration times by detection efficiency, decreasing to approximately 12% at the throughput-optimal integration time of approximately 1.22 us due to T1-induced trajectory smearing. This formulation connects readout calibration directly to the operational objective of minimizing certification time in high-throughput superconducting processors.

</details>


### [71] [Hybrid Consensus with Quantum Sybil Resistance](https://arxiv.org/abs/2602.22195)
*Dar Gilboa,Siddhartha Jain,Or Sattath*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Sybil resistance is a key requirement of decentralized consensus protocols. It is achieved by introducing a scarce resource (such as computational power, monetary stake, disk space, etc.), which prevents participants from costlessly creating multiple fake identities and hijacking the protocol. Quantum states are generically uncloneable, which suggests that they may serve naturally as an unconditionally scarce resource. In particular, uncloneability underlies quantum position based-cryptography, which is unachievable classically. We design a consensus protocol that combines classical hybrid consensus protocols with quantum position verification as the Sybil resistance mechanism, providing security in the standard model, and achieving improved energy efficiency compared to hybrid protocols based on Proof-of-Work. Our protocol inherits the benefits of other hybrid protocols, namely the faster confirmation times compared to pure Proof-of-Work protocols, and resilience against the compounding wealth issue that plagues protocols based on Proof-of-Stake Sybil resistance. We additionally propose a spam prevention mechanism for our protocol in the Random Oracle model.

</details>


### [72] [Controlled jump in the Clifford hierarchy](https://arxiv.org/abs/2602.22201)
*Yichen Xu,Xiao Wang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We develop a simple and systematic route to higher levels of the qubit Clifford hierarchy by coherently controlling Clifford operations. Our approach is based on Pauli periodicity, defined for a Clifford unitary $U$ as the smallest integer $m\ge 1$ such that $U^{2^{m}}$ is a Pauli operator up to phase. We prove a sharp controlled-jump rule showing that the controlled gate $CU$ lies strictly in level $m+2$ of the hierarchy, and equivalently that $CU$ lies in level $k$ if $U^{2^{k-2}}$ is Pauli while no smaller positive power of $U$ is Pauli. We further quantify the resources required to realize large level jumps in the Clifford hierarchy by proving an essentially tight upper bound on Pauli periodicity as a function of the number of qubits, which implies that accessing high hierarchy levels through controlled Cliffords requires a number of target qubits that grows exponentially with the desired level. We complement this limitation with explicit infinite families of Pauli-periodic Cliffords whose controlled versions achieve asymptotically optimal jumps. As an application, we propose a protocol for preparing logical catalyst states that enable logical $Z^{1/2^k}$ phase gates via phase kickback from a single jumped Clifford.

</details>


### [73] [Computing with many encoded logical qubits beyond break-even](https://arxiv.org/abs/2602.22211)
*Shival Dasu,Matthew DeCross,Andrew Y. Guo,Ali Lavasani,Jan Behrends,Asmae Benhemou,Yi-Hsiang Chen,Karl Mayer,Chris N. Self,Selwyn Simsek,Basudha Srivastava,M. S. Allman,Jake Arkinstall,Justin G. Bohnet,Nathaniel Q. Burdick,J. P. Campora,Alex Chernoguzov,Samuel F. Cooper,Robert D. Delaney,Joan M. Dreiling,Brian Estey,Caroline Figgatt,Cameron Foltz,John P. Gaebler,Alex Hall,Craig A. Holliman,Ali A. Husain,Akhil Isanaka,Colin J. Kennedy,Yuga Kodama,Nikhil Kotibhaskar,Nathan K. Lysne,Ivaylo S. Madjarov,Michael Mills,Alistair R. Milne,Brian Neyenhuis,Annie J. Park,Anthony Ransford,Adam P. Reed,Steven J. Sanders,Charles H. Baldwin,David Hayes,Ben Criger,Andrew C. Potter,David Amaro*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: High-rate quantum error correcting (QEC) codes encode many logical qubits in a given number of physical qubits, making them promising candidates for quantum computation. Implementing high-rate codes at a scale that both frustrates classical computing and improves performance by encoding requires both high fidelity gates and long-range qubit connectivity -- both of which are offered by trapped-ion quantum computers. Here, we demonstrate computations that outperform their unencoded counterparts in the high-rate $[[ k+2,\, k,\, 2 ]]$ iceberg quantum error detecting (QED) and $[[ (k_2 + 2)(k_1 + 2),\, k_2k_1,\, 4 ]]$ two-level concatenated iceberg QEC codes, using the 98-qubit Quantinuum Helios trapped-ion quantum processor. Utilizing new gadgets for encoded operations, we realize this "beyond break-even" performance with reasonable postselection rates across a range of fault-tolerant (FT) and partially-fault-tolerant (pFT) component and application benchmarks with between $48$ and $94$ logical qubits. These benchmarks include FT state preparation and measurement, QEC cycle benchmarking, logical gate benchmarking, GHZ state preparation, and a pFT quantum simulation of the three-dimensional $XY$ model of quantum magnetism. Additionally, we illustrate that postselection rates can be suppressed by increasing the code distance via concatenation. Our results represent state-of-the-art logical component and state fidelities and provide evidence that high-rate QED/QEC codes are viable on contemporary quantum computers for near-term beyond-classical-scale computation.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [74] [Structurally Conditioned Diffusion Reproduces Skills-Based Stratification](https://arxiv.org/abs/2602.21369)
*Roberto Cantillan,Mauricio Bucca*

Main category: physics.soc-ph

TL;DR: 该研究发现职业层级中的技能需求传播具有方向性不对称特征，社会认知类技能更易向上扩散，而感官/体力类技能则更易向下扩散，这种不对称性由工资梯度和技能依赖结构共同决定。


<details>
  <summary>Details</summary>
Motivation: 探讨在职业内容快速变化的背景下，技能需求是否沿薪资层级对称扩散，还是存在方向性传播，从而解释职业层级为何能在剧烈变化中保持稳定。

Method: 利用O*NET 2015-2024数据，分析873种职业和161项技能之间的1730万条有向扩散机会，通过检验向上与向下传播的差异识别传播模式，并控制职业内外部变量以确保结果稳健。

Result: 发现技能传播遵循“非对称轨迹引导”（ATC）规则：社会认知技能向上传播率高于向下（20.7% vs 14.9%），而感官/体力技能则相反（19.5% vs 10.3%）；技能的嵌套结构和依赖位置进一步放大了这一不对称性。

Conclusion: 职业层级的稳定性源于技能传播的方向性机制，即使没有个体偏好或组织协调，结构性条件本身即可通过持续重构再生产职业等级体系。

Abstract: Occupational hierarchies remain strikingly stable even as job content changes rapidly. We ask whether skill requirements propagate directionally along the wage hierarchy or follow symmetric diffusion. Using O*NET 2015-2024, we analyze 17.3 million directed diffusion opportunities linking 873 occupations and 161 skills. We show that propagation obeys an Asymmetric Trajectory Channeling (ATC) rule: the same requirement spreads differently upward and downward, and the asymmetry depends on skill domain and on the architecture of skill dependencies. Two mechanisms generate ATC. Directional incorporation asymmetry implies that wage gradients create distinct receiving environments: upward-moving socio-cognitive requirements encounter complementary infrastructure, whereas upward-moving sensory/physical requirements face structural indifference. Structural portability constraints imply that dependency position governs portability: requirements anchoring long prerequisite chains carry co-adoption burdens that restrict diffusion regardless of destination. Consistent with these mechanisms, socio-cognitive requirements propagate upward more often than downward (20.7% vs 14.9%), while sensory/physical requirements exhibit the mirror pattern (19.5% downward vs 10.3% upward). Nestedness amplifies these asymmetries in opposite directions: scaffolding capabilities ascend most readily, whereas structurally embedded physical requirements are most tightly confined. Identification leverages within-occupation variation in propagation direction, and results are robust to origin- and destination-side specifications. Together, these findings reveal a directional architecture of occupational change that can reproduce hierarchy through ongoing reconfiguration, even absent assortative preferences or coordinated action.

</details>


### [75] [On the equivalence between nonlinear graph-based dynamics and linear dynamics on higher-order networks](https://arxiv.org/abs/2602.21727)
*Lucas Lacasa*

Main category: physics.soc-ph

TL;DR: 本文探讨了图上非线性动力学与高阶交互结构（如超图）上线性动力学之间的表示对偶性，指出多线性动力学可在超图上精确表示为线性动力学，而更一般的非线性系统则需更复杂的组合结构（如hb-图）来实现线性化。


<details>
  <summary>Details</summary>
Motivation: 研究在复杂系统建模中，将非线性动力学的效应从节点动态转移到高阶交互结构表示中的可能性与条件，以统一理解结构与动力学之间的关系。

Method: 利用Carleman线性化理论分析非线性动力学向高阶状态空间的提升，并探讨其能否嵌入超图或需要更丰富的组合结构（如hb-图）。

Result: 证明图上的多线性动力学可被精确表示为超图状态空间上的线性动力学；对于更一般的解析非线性，仅靠超图不足以容纳所需的线性化状态提升，必须引入如hb-图的更丰富结构。

Conclusion: 非线性动力学是否能转化为高阶结构上的线性表示取决于其非线性形式：多线性情形可由超图实现，而一般非线性则需超越超图的表达能力。

Abstract: In network science, collective dynamics of complex systems are typically modelled as (nonlinear, often including many-body) vertex-level update rules evolving over a graph interaction structure. In recent years, frameworks that explicitly model such higher-order interactions in the interaction backbone (i.e. hypergraphs) have been advanced, somehow shifting the imputation of the effective nonlinearity from the dynamics to the interaction structure. In this short note we discuss such structural-dynamical representation duality, and investigate how and when a nonlinear dynamics defined on the vertex set of a graph allows an equivalent representation in terms of a linear dynamics defined on the state space of a sufficiently richer, higher-order interaction structure. We show that multilinear dynamics defined in the vertices of a graph admit an exact finite realizations as linear dynamics on the state space of a hypergraph. For other high-order interactions involving more general analytic nonlinearities, using Carleman linearization theory we discuss how that the required state space liftings necessary to linearize the dynamics cannot be accomodated to the simple structure of a hypergraph, and a richer combinatorial architecture such as a hb-graph is needed.

</details>


### [76] [The Swarm Intelligence Freeway-Urban Trajectories (SWIFTraj) Dataset - Part II: A Graph-Based Approach for Trajectory Connection](https://arxiv.org/abs/2602.21954)
*Xinkai Ji,Pan Liu,Yu Han*

Main category: physics.soc-ph

TL;DR: 本文提出了一种基于图的新型方法，用于连接由无人机群捕获的车辆轨迹，解决了多视频间时间对齐和车辆匹配的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 由于需要在多个视频之间进行精确的时间对齐以及无人机不规则的空间分布，从无人机群获取长距离连续轨迹具有挑战性。

Method: 构建了一个无向图来表示灵活的无人机布局，并开发了一种基于轨迹匹配成本最小化的时间对齐方法；使用匈牙利算法建立车辆匹配表以关联不同视频中的同一车辆轨迹。

Result: 真实实验结果表明，时间对齐误差在三个视频帧内（约0.1秒），车辆匹配F1分数约为0.99。

Conclusion: 所提方法能有效解决基于无人机的轨迹连接中的关键问题，展现出在大规模车辆轨迹采集中的潜力。

Abstract: In Part I of this companion paper series, we introduced SWIFTraj, a new open-source vehicle trajectory dataset collected using a unmanned aerial vehicle (UAV) swarm. The dataset has two distinctive features. First, by connecting trajectories across consecutive UAV videos, it provides long-distance continuous trajectories, with the longest exceeding 4.5 km. Second, it covers an integrated traffic network consisting of both freeways and their connected urban roads. Obtaining such long-distance continuous trajectories from a UAV swarm is challenging, due to the need for accurate time alignment across multiple videos and the irregular spatial distribution of UAVs. To address these challenges, this paper proposes a novel graph-based approach for connecting vehicle trajectories captured by a UAV swarm. An undirected graph is constructed to represent flexible UAV layouts, and an automatic time alignment method based on trajectory matching cost minimization is developed to estimate optimal time offsets across videos. To associate trajectories of the same vehicle observed in different videos, a vehicle matching table is established using the Hungarian algorithm. The proposed approach is evaluated using both simulated and real-world data. Results from real-world experiments show that the time alignment error is within three video frames, corresponding to approximately 0.1 s, and that the vehicle matching achieves an F1-score of about 0.99. These results demonstrate the effectiveness of the proposed method in addressing key challenges in UAV-based trajectory connection and highlight its potential for large-scale vehicle trajectory collection.

</details>


### [77] [Capacity drop accounting for microscopic vehicle interaction effects: analytical model and validation with high-resolution trajectories](https://arxiv.org/abs/2602.22019)
*Yu Han,Pan Liu,Zhiyuan Liu,Ludovic Leclercq*

Main category: physics.soc-ph

TL;DR: 本文提出了一种通用的解析方法来估计高速公路交通排队放行流量，揭示了犹豫车辆产生的空隙及其与交通波相互作用是容量下降的关键机制。


<details>
  <summary>Details</summary>
Motivation: 为了解决交通流中队列放行流量低于理论道路容量（即容量下降）的问题，需要更深入理解其形成机制并建立准确的估计模型。

Method: 基于犹豫车辆的空间和时间分布及其延迟特性，建模计算所有犹豫车辆产生的总空隙长度，并考虑上下游犹豫车辆引发的交通波之间的相互作用。

Result: 该方法成功解释了立交匝道处立停车队与拥堵波之间容量下降程度差异的原因，且通过数值模拟和真实轨迹数据验证了模型的准确性。

Conclusion: 所提出的分析方法有助于深化对容量下降现象的理解，可应用于改进交通流建模与控制策略。

Abstract: Capacity drop is a traffic phenomenon in which the discharge flow from a queue is lower than the theoretical infrastructure capacity. This paper proposes a generic analytical method to estimate the queue discharge flow of freeway traffic. Capacity drop is primarily attributed to hesitant vehicles, defined as vehicles that stochastically and temporarily enter an acceleration delay state and generate voids (i.e., extra gaps) in front of them. The proposed method estimates the expected total void length generated by all hesitant vehicles, based on the distributions of their spatial and temporal locations as well as the associated delays. It also accounts for interactions between the waves triggered by downstream hesitant vehicles and the voids generated by upstream ones. Our analysis reveals that this interaction is the key mechanism behind the differing extents of capacity drop observed between standing queues and jam waves in previous studies. The accuracy of the model is validated through both numerical simulations and real-world trajectories. Overall, the proposed method offers a deeper understanding of capacity drop, which can be leveraged in traffic flow modeling and control.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [78] [Machine Learning-Based Estimation of Cumulants of Chiral Condensate via Multi-Ensemble Reweighting with Deborah.jl](https://arxiv.org/abs/2602.21617)
*Benjamin J. Choi,Hiroshi Ohno,Akio Tomiya*

Main category: hep-lat

TL;DR: 提出了一种偏差校正的机器学习方法，用于高效估计狄拉克算子逆的高阶迹，从而降低计算成本的同时保持对QCD临界端点研究中高阶累积量的稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了在有限温度QCD临界端点附近研究手征凝聚的高阶累积量，需要高效且准确地估计Dirac算子逆的高阶迹（如Tr M^{-n}，n=1,2,3,4），传统方法计算代价高昂。

Method: 采用监督回归机器学习框架，训练于Wilson-clover系综和Iwasaki规范作用量数据；探索两种输入特征方案：一种使用Tr M^{-1}作为物理输入，另一种仅依赖规范观测量（plaquette和rectangle）进行全特征预测，并引入偏差校正以提升估计精度。

Result: 即使只使用约1%的标记数据，所提方法估计出的susceptibility、skewness和kurtosis仍与完整测量结果一致，计算成本降至约26%；在仅用特征的方法中，偏差校正对预测效果影响显著，通过多系综重加权验证了其有效性。

Conclusion: 偏差校正的机器学习方法能显著降低高阶可观测量的计算开销，同时保持统计一致性，有助于稳定探测QCD临界端点的位置。

Abstract: We investigate a bias-corrected machine learning (ML) strategy for estimating traces of the inverse Dirac operator, $\text{Tr}\, M^{-n}$ ($n=1,2,3,4$), motivated by the need for higher-order cumulants of the chiral condensate near the finite-temperature QCD critical endpoint. Our supervised regression framework is trained on Wilson-clover ensembles with the Iwasaki gauge action, and we explore two input feature scenarios: one using $\text{Tr}\, M^{-1}$ and another relying solely on gauge observables (plaquette and rectangle), enabling a fully feature-based prediction pipeline. Using $\text{Tr}\, M^{-1}$ both as a physical input to cumulant construction and as a feature for predicting higher powers, we find that even with $\sim1\%$ labeled data, the resulting susceptibility, skewness, and kurtosis remain statistically consistent with fully measured baselines, reducing computational cost to about $26\%$. In the feature-only approach, where correlations rather than explicit stochastic traces drive the predictions, bias correction plays a more pronounced role. We quantify this impact through multi ensemble reweighting across nearby quark masses. Our results demonstrate that bias-corrected ML estimates can significantly reduce measurement overhead while preserving the stability of higher-order observables relevant for locating the QCD critical endpoint. Code for this work is available at https://github.com/saintbenjamin/Deborah.jl .

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [79] [Yet another look at narrow escape through a tube](https://arxiv.org/abs/2602.21396)
*Victorya Richardson,Yick Hin Ling,Sean D Lawley*

Main category: cond-mat.stat-mech

TL;DR: 本文通过结合匹配渐近分析和概率方法，精确推导出粒子通过狭窄管道逃逸的时间渐近公式，并揭示了空间变化扩散率中乘性噪声形式的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决过去三十年中关于粒子通过狭窄管道逃逸时间存在冲突且反直觉的估计问题。

Method: 结合匹配渐近分析和概率方法，推导逃逸时间的精确渐近表达式。

Result: 得到了一个新的逃逸时间公式，该公式在特定情况下可退化为以往的各种估计结果，并揭示了空间变化扩散率中乘性噪声的影响。

Conclusion: 提供了窄逃逸问题中通过管道逃逸时间的精确理论框架，解决了长期存在的争议，并对不对称细胞分裂等生物过程具有重要意义。

Abstract: The narrow escape problem concerns the time needed for a diffusing particle to exit a confining domain through a small hole in the boundary. While this problem is now well-understood, determining the escape time for a particle that must exit through a narrow tube has proven challenging. Indeed, relying on analogies with electrodynamics, parameter fits to simulations, and heuristics, a variety of conflicting estimates for this escape time have been offered over the last three decades, some of which are counterintuitive and arguably non-physical. In this paper, we combine matched asymptotic analysis and probabilistic methods to determine the exact asymptotics of the narrow escape time through a tube. We obtain a new escape time formula which reduces to the various prior estimates in certain special cases. If the diffusivity in the tube differs from the diffusivity in the rest of the domain, our results reveal the importance of the form of the multiplicative noise inherent to any diffusivity that varies in space. We discuss our results in the context of asymmetric cell division.

</details>


### [80] [Integral formula for the propagator of the one-dimensional Hubbard model](https://arxiv.org/abs/2602.21541)
*Taiki Ishiyama,Kazuya Fujimoto,Tomohiro Sasamoto*

Main category: cond-mat.stat-mech

TL;DR: 提出了一个一维Fermi-Hubbard模型多粒子传播子的精确积分公式，基于嵌套Bethe假设，无需依赖字符串假设，为非平衡动力学的精确分析提供了基础。


<details>
  <summary>Details</summary>
Motivation: 为了实现对Hubbard模型中非平衡动力学过程的精确分析，需要一种不依赖近似假设的严格方法来描述多粒子传播行为。

Method: 采用嵌套Bethe ansatz方法，推导出无限晶格上一维Fermi-Hubbard模型多粒子传播子的精确积分表达式，且不依赖字符串假设。

Result: 得到了多粒子传播子的显式积分表示，可用于任意有限粒子波函数的时间演化计算，并可推广至相关的开放量子系统模型。

Conclusion: 该公式为精确研究Hubbard模型及其他相关量子系统的非平衡动力学提供了坚实的数学基础。

Abstract: We present an exact integral formula for the multi-particle propagator of the one-dimensional Fermi--Hubbard model on an infinite lattice. The proof is based on the nested Bethe ansatz without relying on the string hypothesis. Our formula enables an explicit integral representation of the time evolution of arbitrary finite-particle wave functions and thereby provides a foundation for the exact analysis of nonequilibrium dynamics in the Hubbard model. It can further be applied to related open quantum models.

</details>


### [81] [On the electrical double layer capacitance of the restricted primitive model: a link between the mesoscopic theory and the associative mean spherical approximation](https://arxiv.org/abs/2602.21731)
*O. Patsahan*

Main category: cond-mat.stat-mech

TL;DR: 比较了介观理论与关联平均球面近似理论在高密度和低温下对电双层电容和自由离子电荷密度的计算结果，发现两者具有较好的一致性。


<details>
  <summary>Details</summary>
Motivation: 探讨介观理论与关联平均球面近似理论在描述电双层电容和自由离子行为方面的异同及其适用范围。

Method: 对比分析介观理论（考虑电荷密度涨落）与关联平均球面近似理论（基于质量作用定律假设化学平衡）的计算结果。

Result: 在高密度和低温条件下，两种理论在电双层电容和自由离子电荷密度的预测上表现出较好的一致性。

Conclusion: 尽管理论基础不同，介观理论与关联平均球面近似理论在特定条件下（高密度、低温）对离子系统行为的描述具有一致性，表明其在该区域的可靠性。

Abstract: The results for the electrical double layer capacitance and the charge density of ``free ions'' obtained from the mesoscopic theory are compared with the corresponding results of the associative mean spherical approximation. While the first theory takes into account the fluctuations of the charge density, the second theory assumes that the free ions and ion pairs are in chemical equilibrium according to the mass action law. Our results demonstrate a fairly good agreement between the two theories at high densities and low temperatures.

</details>


### [82] [Stochasticity of fatigue failure times in sheared glasses](https://arxiv.org/abs/2602.21807)
*Swarnendu Maity,Pushkar Khandare,Himangsu Bhaumik,Peter Sollich,Srikanth Sastry*

Main category: cond-mat.stat-mech

TL;DR: 研究了循环剪切变形下玻璃材料疲劳失效时间的分布特性，发现其标准差与均值成正比，且比例常数随系统尺寸增大而减小，在热力学极限下趋近于零，表明失效时间分布更尖锐；该行为源于损伤累积过程的内在随机性。


<details>
  <summary>Details</summary>
Motivation: 理解玻璃材料在循环载荷下的疲劳失效机制，特别是疲劳失效时间分布的起源及其与系统尺寸、材料无序性的关系。

Method: 采用分子动力学模拟和基于有限元的弹塑性模型进行计算机模拟，并结合随机损伤累积模型分析疲劳失效时间的统计分布。

Result: 发现疲劳失效时间对数的标准差与其均值成正比，且该比例随系统尺寸增加而减小；在热力学极限下，标准差与均值之比趋于零，表明分布更集中；这种分布源于失效过程的内在随机性而非仅由样品无序性导致。

Conclusion: 疲劳失效时间的分布具有普适性特征，其尖锐化趋势在大系统中更加明显，揭示了循环加载下玻璃材料失效的内在随机动力学机制。

Abstract: Fatigue failure occurs when a solid is subjected to repeated, cyclic loading. Glasses subjected to cyclic to shear deformation have recently been investigated using computer simulations and theoretical models, to characterize and rationalize the dependence of the number of cycles to failure, depending on the properties of the glasses, and the deformation amplitude. The average number of cycles to failure has been observed to diverge as the strain amplitude approaches the so-called fatigue limit from above. In this work, rather than the average times themselves, we investigate by computer simulations the distribution of fatigue failure times, in model glasses subjected to cyclic shear deformation and in an elasto-plastic model. In particular, we observe in atomistic simulations that the standard deviation of the logarithm of failure times are proportional to their mean values, with the proportionality constant decreasing as the system size increases, indicating a sharper distribution of failure times. Using a finite-element-based elasto-plastic model, we observe similar behavior and perform a system-size analysis showing that the ratio of the standard deviation to the mean tends toward zero in the thermodynamic limit. Such distributions, rather than arising solely from the distribution of disorder in the samples that have been subjected to cyclic deformation, appear to arise from the intrinsic stochasticity of the failure process, which we analyze through a stochastic damage accumulation model.

</details>


### [83] [Computing Nonequilibrium Transport from Short-Time Transients: From Lorentz Gas to Heat Conduction in One Dimensional Chains](https://arxiv.org/abs/2602.21901)
*Davide Carbone,Vincenzo Di Florio,Stefano Lepri,Lamberto Rondoni*

Main category: cond-mat.stat-mech

TL;DR: 本文评估了瞬态时间关联函数（TTCF）方法在计算非平衡输运系数中的应用，表明其在计算效率、精度及非遍历系统中的表现优于传统时间平均法，并在洛伦兹气体和非谐振子链体系中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统时间平均方法在计算非平衡输运系数时忽略瞬态动力学信息、计算成本高以及在非遍历系统中失效的问题，提出并系统评估TTCF方法的应用潜力。

Method: 基于TTCF理论框架，利用外扰引发的短时瞬态响应计算输运系数，并通过洛伦兹气体和非谐振子链两个典型体系进行数值验证，与传统时间平均法进行直接对比。

Result: 在洛伦兹气体中，TTCF在线性和非线性响应区均能准确提取输运系数，计算成本更低，精度更高，且适用于非遍历系统，能揭示相空间不同区域的行为差异和相变可能；在非谐振子链中，TTCF展现出良好的可扩展性和计算效率。

Conclusion: TTCF是一种高效、精确且适用于复杂系统的非平衡输运系数计算方法，尤其在线性响应和非遍历情形下优于传统时间平均法，具有广泛的应用前景。

Abstract: We test the Transient Time Correlation Function (TTCF) method to compute nonequilibrium transport coefficients, highlighting its conceptual and practical difference from the standard time-average approach. While time averages extract transport properties from long stationary trajectories and discard transient dynamics, TTCF adopts the complementary strategy: it exploits the information contained in short-time transients following the onset of an external perturbation, while discarding the long-time evolution once stationarity is reached. We revisit the theoretical framework of TTCF and assess its numerical performance through representative case studies, the Lorentz gas and a many-body system, namely a chain of oscillators with anharmonic pinning potential. By direct comparison with time averages, we show that for the Lorentz gas TTCF yields consistent transport coefficients in both linear and nonlinear regimes at a reduced computational cost. Moreover, the TTCF displays superior precision in the linear-response regime, and remains reliable in non-ergodic situations, revealing the presence of regions of phase space corresponding to different behaviors, as well as the possibility of phase transitions. For the anharmonic chain, we show that TTCF is a scalable and efficient alternative for the numerical study of nonequilibrium transport.

</details>


### [84] [XY Model with Persistent Noise](https://arxiv.org/abs/2602.22028)
*Xia-qing Shi,Hugues Chaté,Benoît Mahault*

Main category: cond-mat.stat-mech

TL;DR: 研究了在时间相关噪声下的2D XY模型，发现即使噪声关联衰减较快，系统仍能保持准序，且有序-无序相变仍属于Berezinskii-Kosterlitz-Thouless型，但标度指数随噪声持久时间变化。


<details>
  <summary>Details</summary>
Motivation: 探索活性晶体中持续涨落对大变形下不熔化现象的影响，理解非平衡条件下准序的维持机制。

Method: 结合理论分析与数值模拟，研究具有时间相关噪声的2D XY模型的有序-无序相变特性。

Result: 发现该模型即使在关联快速衰减的情况下也能保持准序，相变仍为BKT型，但标度指数依赖于噪声的持久时间。

Conclusion: 持久性噪声可扩展准序存在的范围，且BKT相变的标度行为受非平衡扰动调控。

Abstract: We consider a 2D XY model subjected to time-correlated noise, a model of direct relevance to active crystals, which were shown recently to be able to support very large deformations without melting in the presence of persistent fluctuations. We find that our persistent XY model can remain quasi-ordered in spite of correlations decaying much faster than allowed in equilibrium. We then investigate theoretically and numerically the order-disorder transition and conclude that it remains of the Berezinskii-Kosterlitz-Thouless type, but with scaling exponents that vary with the persistence time of the noise.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [85] [Superpositions between non linear intermittency maps, application in biological neurons networks](https://arxiv.org/abs/2602.21848)
*Yiannis F. Contoyiannis*

Main category: nlin.CD

TL;DR: 该研究通过耦合和叠加临界与三临界间歇性动力学，生成具有生物神经元特征的类生物脉冲序列，并发现即使在多重叠加下，脉冲仍保持生物特性，揭示了其与神经元膜电位波动动力学的一致性。


<details>
  <summary>Details</summary>
Motivation: 探索统计物理中的临界与三临界现象如何通过混沌动力学模拟生物神经脉冲，并研究其在神经退行性问题中的潜在应用。

Method: 利用类型I间歇性产生的弱混沌时间序列，对不同参数下的临界与三临界动力学进行叠加与耦合，分析生成的时间序列是否保留类生物脉冲特性。

Result: 耦合后的叠加间歇性时间序列仍能产生类生物脉冲，且其波动动力学与生物神经元膜电位变化一致。

Conclusion: 该模型可有效模拟生物神经脉冲行为，未来有望用于研究神经系统疾病及认知衰退机制。

Abstract: In a series of works of ours we have shown that we can represent the critical and tricritical points of the Statistical Physics of critical phenomena as a Dynamical phenomenon expressed by time series produced by the type I intermittency that exhibits a weak chaos. Recently we have also shown that if we couple these two chaotic dynamics, namely critical and tricritical, we can produce a time sequence which is a temporal Spike Train (ST) of biological-type . In the present work we generalize this issue producing superpositions of critical-tricritical intermittencies with different parameter values. Now arise the question whether the coupling occurs between time series that have resulted from the superposition, will preserved or destroyed the ST biological type , as the number of intermittencies in the superposition will increase? In the other side in present work we find that the spikes produced by the chaotic dynamics of the intermittencies, under the action of superpositions and coupling remain biological-type too. Thus we can say that the dynamics of the fluctuations of the values of the time series produced by the coupling of the superpositions of the intermittencies is the same as the dynamics of the fluctuations of the membrane potential of the biological neuron. Given also that we can manipulate the numerical experiment of superposition and coupling as we wish, we will be able, in future, to approach the cause of neurological problems and decline in thinking ability due to loss of spikes in the brain.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [86] [Inverse prediction of capacitor multiphysics dynamic parameters using deep generative model](https://arxiv.org/abs/2602.21606)
*Kart-Leong Lim,Rahul Dutta,Mihai Rotaru*

Main category: cs.CE

TL;DR: 本文提出了一种基于深度生成模型的逆向预测方法，用于建模受动态边界条件影响的小型设计结构变化，并在电容静电场数据集上取得了优于基线的视觉和定量结果。


<details>
  <summary>Details</summary>
Motivation: 传统有限元仿真在每次结构微调时都需要重新运行，过程不可逆且耗时，因此需要一种能够根据输出反推输入参数的方法以提高设计效率。

Method: 采用最新的深度生成模型，对空气填充电容器的静电场数据集进行逆向预测，通过学习输入参数与结构变化之间的映射关系实现快速建模。

Result: 在视觉效果和定量指标上均优于现有最佳基线方法，有效实现了小规模设计结构变化的逆向预测。

Conclusion: 深度生成模型可用于高效解决工程设计中的逆向预测问题，显著提升包裝設計工程師在结构优化中的迭代速度。

Abstract: Finite element simulations are run by package design engineers to model design structures. The process is irreversible meaning every minute structural adjustment requires a fresh input parameter run. In this paper, the problem of modeling changing (small) design structures through varying input parameters is known as inverse prediction. We demonstrate inverse prediction on the electrostatics field of an air-filled capacitor dataset where the structural change is affected by a dynamic parameter to the boundary condition. Using recent AI such as deep generative model, we outperformed best baseline on inverse prediction both visually and in terms of quantitative measure.

</details>


### [87] [Intrusive and Non-Intrusive Model Order Reduction for Airborne Contaminant Transport: Comparative Analysis and Uncertainty Quantification](https://arxiv.org/abs/2602.21996)
*Lisa Kühn,Jacopo Bonari,Max von Danwitz,Alexander Popp*

Main category: cs.CE

TL;DR: 本研究应用模型降阶（MOR）技术，实现复杂城市环境中污染物扩散的快速、高精度模拟，支持应急响应与不确定性分析，并通过交互式仪表板展示其实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 高保真数值模拟在复杂几何环境（如城市）中计算成本过高，难以满足时间敏感或多次查询的应急场景需求，因此需要高效且准确的替代模型。

Method: 对基于不可压缩Navier-Stokes方程与对流-扩散过程的参数化模型，系统比较了侵入式与非侵入式模型降阶（MOR）方法，并构建了一个考虑风速与风向变化的非侵入式降阶模型（ROM），在真实建筑轮廓构成的二维域上进行验证。

Result: 所构建的非侵入式ROM能够在瞬时污染源和变化风况下实现快于实时的时空污染物扩散预测，并支持基于蒙特卡洛法的风场测量不确定性评估。

Conclusion: 非侵入式MOR方法在保持较高预测精度的同时显著提升计算效率，适用于城市环境中污染物扩散的快速风险评估与应急决策支持，具备良好的实际应用前景。

Abstract: Numerical simulations of contaminant dispersion, as after a gas leakage incident on a chemical plant, can provide valuable insights for both emergency response and preparedness. Simulation approaches combine incompressible Navier-Stokes (INS) equations with advection-diffusion (AD) processes to model wind and concentration field. However, the computational cost of such high-fidelity simulations increases rapidly for complex geometries like urban environments, making them unfeasible in time-critical or multi-query "what-if" scenarios. Therefore, this study focuses on the application of model order reduction (MOR) techniques enabling fast yet accurate predictions. To this end, a thorough comparison of intrusive and non-intrusive MOR methods is performed for the computationally more demanding parametric INS problem with varying wind velocities. Based on these insights, a non-intrusive reduced-order model (ROM) is constructed accounting for both wind velocity and direction. The study is conducted on a two-dimensional domain derived from real-world building footprints, preserving key features for analyzing the dispersion of, for instance, denser contaminants. The resulting ROM enables faster than real-time predictions of spatio-temporal contaminant dispersion from an instantaneous source under varying wind conditions. This capability allows assessing wind measurement uncertainties through a Monte Carlo analysis. To demonstrate the practical applicability, an interactive dashboard provides intuitive access to simulation results.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [88] [Toward Effective Multi-Domain Rumor Detection in Social Networks Using Domain-Gated Mixture-of-Experts](https://arxiv.org/abs/2602.21214)
*Mohadeseh Sheikhqoraei,Zainabolhoda Heshmati,Zeinab Rajabi,Leila Rabiei*

Main category: cs.SI

TL;DR: 本文提出了一种基于多专家模型和领域门控机制的多领域谣言检测方法，在大规模多领域数据集PerFact上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为单领域设计，跨域性能下降明显，难以应对不同领域中词汇模式和传播动态的分布变化。因此，需要构建能够适应多领域的谣言检测模型以提升早期检测准确性。

Method: 提出一种基于Mixture-of-Experts和领域门控机制的模型，每个专家结合CNN与BiLSTM提取局部句法特征和长距离上下文依赖，并融合文本内容与发布者信息进行分类。

Result: 在自建多领域数据集PerFact（包含8,034条标注推文）上取得F1分数79.86%、准确率79.98%，显著优于现有方法。

Conclusion: 所提模型通过动态融合多专家特征，在多领域谣言检测中表现出强健性和有效性，有助于减轻谣言在社交媒体上的负面影响。

Abstract: Social media platforms have become key channels for spreading and tracking rumors due to their widespread accessibility and ease of information sharing. Rumors can continuously emerge across diverse domains and topics, often with the intent to mislead society for personal or commercial gain. Therefore, developing methods that can accurately detect rumors at early stages is crucial to mitigating their negative impact. While existing approaches often specialize in single-domain detection, their performance degrades when applied to new domains due to shifts in data distribution, such as lexical patterns and propagation dynamics. To bridge this gap, this study introduces PerFact, a large-scale multi-domain rumor dataset comprising 8,034 annotated posts from the X platform, annotated into two primary categories: rumor (including true, false, and unverified rumors) and non-rumor. Annotator agreement, measured via Fleiss' Kappa ($κ= 0.74$), ensures high-quality labels.
  This research further proposes an effective multi-domain rumor detection model that employs a domain gate to dynamically aggregate multiple feature representations extracted through a Mixture-of-Experts method. Each expert combines CNN and BiLSTM networks to capture local syntactic features and long-range contextual dependencies. By leveraging both textual content and publisher information, the proposed model classifies posts into rumor and non-rumor categories with high accuracy. Evaluations demonstrate state-of-the-art performance, achieving an F1-score of 79.86\% and an accuracy of 79.98\% in multi-domain settings.
  Keywords: Rumor Detection, Multi-Domain, Natural Language Processing, Social Networks, Mixture-of-Experts Model

</details>


### [89] [@GrokSet: multi-party Human-LLM Interactions in Social Media](https://arxiv.org/abs/2602.21236)
*Matteo Migliarini,Berat Ercevik,Oluwagbemike Olowe,Saira Fatima,Sarah Zhao,Minh Anh Le,Vasu Sharma,Ashwinee Panda*

Main category: cs.SI

TL;DR: 本研究介绍了@GrokSet，一个包含超过100万条涉及大型语言模型@Grok的推文的数据集，用于分析LLM在公开社交媒体环境中的行为。研究发现，该模型常被用作高风险政治辩论中的权威仲裁者，但其社会认可度较低，并暴露出对齐机制的浅层性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM数据集多来自私有聊天界面，缺乏公共社交平台上的多方互动特性，限制了对LLM在真实社会环境中行为的理解。本研究旨在填补这一空白。

Method: 构建并分析@GrokSet数据集，涵盖X平台上超过100万条与@Grok相关的公开推文，通过定量和社会语境分析探究LLM的功能角色、社会地位及安全性表现。

Result: 发现@Grok主要被用于极化政治讨论中的权威裁决；获得的社会反馈（点赞、回复）显著少于人类用户；用户通过简单的人设模仿和语气复制即可绕过安全过滤机制。

Conclusion: LLM在公开社交媒体中扮演独特但低地位的角色，当前的对齐策略在对抗性社交环境中较为脆弱，需更深层次的适应机制以应对现实世界复杂性。

Abstract: Large Language Models (LLMs) are increasingly deployed as active participants on public social media platforms, yet their behavior in these unconstrained social environments remains largely unstudied. Existing datasets, drawn primarily from private chat interfaces, lack the multi-party dynamics and public visibility crucial for understanding real-world performance. To address this gap, we introduce @GrokSet, a large-scale dataset of over 1 million tweets involving the @Grok LLM on X. Our analysis reveals a distinct functional shift: rather than serving as a general assistant, the LLM is frequently invoked as an authoritative arbiter in high-stakes, polarizing political debates. However, we observe a persistent engagement gap: despite this visibility, the model functions as a low-status utility, receiving significantly less social validation (likes, replies) than human peers. Finally, we find that this adversarial context exposes shallow alignment: users bypass safety filters not through complex jailbreaks, but through simple persona adoption and tone mirroring. We release @GrokSet as a critical resource for studying the intersection of AI agents and societal discourse.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [90] [An accelerated rearrangement method for two-phase composite optimization](https://arxiv.org/abs/2602.21352)
*Chiu-Yen Kao,Seyyed Abbas Mohammadi,Braxton Osting*

Main category: math.OC

TL;DR: 提出了一种加速重排方法（ARM），用于求解两类复合材料相关的非凸优化问题，理论和数值实验均验证了其收敛速度优于经典方法。


<details>
  <summary>Details</summary>
Motivation: 针对由Poisson方程或加权Dirichlet-Laplacian特征值描述的两相复合材料优化问题，经典重排方法收敛较慢，需设计更快的算法。

Method: 在经典重排方法基础上引入动量式加速机制，通过Fréchet导数外推实现加速，并设计带重启机制的变体以保证目标函数单调改进。

Result: 在一维情况下证明了ARM具有比经典方法更优的渐近收敛速率；二维和三维数值实验验证了该方法的加速效果和实际计算效率。

Conclusion: 所提出的ARM方法在理论和实践中均展现出对经典重排方法的加速性能，为非凸复合材料优化问题提供了更高效的求解工具。

Abstract: We propose and analyze an Accelerated Rearrangement Method (ARM) for solving a class of nonconvex optimization problems involving two-phase composites. These problems include maximizing the (work) energy of a membrane governed by the Poisson equation and minimizing the principal eigenvalue of a weighted Dirichlet-Laplacian, both subject to material distribution constraints. Building on the classical rearrangement method, we introduce momentum-like acceleration by extrapolating the Fréchet derivative, leading to a provably convergent algorithm. We also introduce a restarted variant that guarantees monotonic improvement of the objective. In one dimension, we derive asymptotic convergence rates for ARM and prove that they improve upon the classical rearrangement method. Numerical experiments in both two and three dimensions confirm the accelerated convergence and demonstrate practical efficiency.

</details>


### [91] [Fenchel-Young Estimators of Perturbed Utility Models](https://arxiv.org/abs/2602.21376)
*Xi Lin,Yafeng Yin,Tianming Liu*

Main category: math.OC

TL;DR: 提出基于Fenchel-Young损失的统一估计框架，结合Wasserstein分布鲁棒优化，解决扰动效用模型中MLE的非凸与不稳定性问题，并在数据稀缺下实现稳健选择建模。


<details>
  <summary>Details</summary>
Motivation: 标准最大似然估计（MLE）在扰动效用模型（PUM）中存在非凸性和稀疏场景下的不稳定性，难以有效处理数据稀缺问题，亟需更稳健、理论更健全的估计方法。

Method: 利用PUM的凸共轭结构，引入基于Fenchel-Young损失的估计框架，并结合Wasserstein分布鲁棒优化；通过有限维重构和利用损失函数的全局Lipschitz性质构建可计算的安全近似。

Result: 推导出原问题的精确有限维重构并证明其凸性，构造了可处理的近似形式；发现L2正则化与Hinge损失是该鲁棒估计器的极限情况；实验表明新方法在合成数据与Swissmetro数据集上优于传统方法。

Conclusion: Fenchel-Young损失结合分布鲁棒优化为PUM提供了数学自然且计算可行的替代估计路径，在数据稀缺下仍能稳定恢复偏好结构，实现了多种正则化技术的几何统一。

Abstract: The Perturbed Utility Model framework offers a powerful generalization of discrete choice analysis, unifying models like Multinomial Logit and Sparsemax through convex optimization. However, standard Maximum Likelihood Estimation (MLE) faces severe theoretical and numerical challenges when applied to this broader class, particularly regarding non-convexity and instability in sparse regimes. To resolve these issues, this paper introduces a unified estimation framework based on the Fenchel-Young loss. By leveraging the intrinsic convex conjugate structure of PUMs, we demonstrate that the Fenchel-Young estimator guarantees global convexity and bounded gradients, providing a mathematically natural alternative to MLE. Addressing the critical challenge of data scarcity, we further extend this framework via Wasserstein Distributionally Robust Optimization. We first derive an exact finite-dimensional reformulation of the infinite-dimensional primal problem, establishing its theoretical convexity. However, recognizing that the resulting worst-case constraints involve computationally intractable inner maximizations, we subsequently construct a tractable safe approximation by exploiting the global Lipschitz continuity of the Fenchel-Young loss. Through this tractable formulation, we uncover a rigorous geometric unification: two canonical regularization techniques, standard L2-regularization and the margin-enforcing Hinge loss, emerge mathematically as specific limiting cases of our distributionally robust estimator. Extensive experiments on synthetic data and the Swissmetro benchmark validate that the proposed framework significantly outperforms traditional methods, recovering stable preferences even under severe data limitations.

</details>


### [92] [Narrowing the Gap: SOS Ranks of $4 \times 3$ Biquadratic Forms and a Lower Bound of $8$](https://arxiv.org/abs/2602.21570)
*Yi Xu,Chunfeng Cui,Liqun Qi*

Main category: math.OC

TL;DR: 本文研究了4×3变量下双二次型的最大平方和（SOS）秩，通过分析两类结构化子类，得到了精确结果和改进的上下界，将已知范围从7≤BSR(4,3)≤11缩小。证明了简单双二次型的最大SOS秩恰为7，并构造了一个需要恰好8个平方项的显式例子，从而将下界提升至8；对y-缺失型给出了上界9。结果揭示了高秩形式必须具有更复杂的代数结构。


<details>
  <summary>Details</summary>
Motivation: 在双二次型的平方和秩研究中，4×3变量情形处于临界状态，现有上下界差距较大（7≤BSR(4,3)≤11），亟需更精确的估计。本文旨在通过分析特殊结构的子类来缩小这一差距，并探索与极值图论等领域的联系。

Method: 通过引入并分析两类具有特定结构的双二次型——仅含x_i²y_j²项的“简单型”和允许部分y变量交叉项的“y-缺失型”，结合Calderòn定理、已知的BSR(4,2)=5结果以及极值图论中的Zarankiewicz问题，采用构造性方法证明下界，并利用代数与组合工具推导上界。

Result: 1. 确定了简单双二次型的最大SOS秩为7；2. 对y-缺失型给出了SOS秩上界9；3. 构造出一个SOS秩恰好为8的双二次型，将BSR(4,3)的下界从7提升到8；4. 缩小了BSR(4,3)的可能范围，表明更高秩的形式需更复杂结构。

Conclusion: 本研究显著推进了对BSR(4,3)的理解，通过结构化分析和显式构造，将上下界收紧至8≤BSR(4,3)≤9或11（依子类而定），并揭示了高秩双二次型的代数复杂性要求，为最终确定BSR(4,3)的真实值提供了新方向和工具。

Abstract: We investigate the maximum sum-of-squares (SOS) rank of biquadratic forms in the critical case of $4 \times 3$ variables, where the general bounds are currently $7 \leq \mathrm{BSR}(4,3) \leq 11$. By analyzing two important structured subclasses, we obtain exact determinations and improved upper bounds that significantly narrow this gap.
  For simple biquadratic forms those containing only distinct terms of the type $x_i^2 y_j^2$ we prove that the maximum achievable SOS rank is exactly 7, a value attained by a form corresponding to a $C_4$-free bipartite graph with the maximum number of edges. This settles the question for simple forms.
  For $y$-deficient biquadratic forms a class introduced here that permits cross terms among two of the three $y$-variables while the third appears only in pure square terms we prove an upper bound of $9$ by combining Calderön's theorem on $m\times 2$ forms with the known value $\mathrm{BSR}(4,2) = 5$.
  Our main result is a constructive proof that $\mathrm{BSR}(4,3) \geq 8$. We present an explicit non-simple, non-deficient $4\times 3$ biquadratic form and prove it requires exactly eight squares, thereby improving the general lower bound. This shows that any form achieving a rank higher than $8$ must possess a more complex algebraic structure, and it reduces the search space for determining the true value of $\mathrm{BSR}(4,3)$. Connections to Zarankiewicz numbers, extremal graph theory, and classical results on sums of squares are highlighted throughout.

</details>


### [93] [Survey on Neural Routing Solvers](https://arxiv.org/abs/2602.21761)
*Yunpeng Ba,Xi Lin,Changliang Zhou,Ruihao Zheng,Zhenkun Wang,Xinyan Liang,Zhichao Lu,Jianyong Sun,Yuhua Qian,Qingfu Zhang*

Main category: math.OC

TL;DR: 本文综述了利用深度学习解决车辆路径问题的神经路由求解器（NRS），强调其启发式特性，并提出了一种基于启发式原则的分层分类法和面向泛化能力的评估流程。


<details>
  <summary>Details</summary>
Motivation: 为了减少传统启发式方法对手工设计和试错调整的依赖，研究者开始探索通过数据驱动的方式开发更高效的神经路由求解器。

Method: 从启发式角度回顾现有NRS，提出一个基于启发式原理的分层分类体系，并设计了一个注重泛化能力的新评估流程，用于对比不同NRS在标准与新流程下的表现。

Result: 识别出现有NRS研究中未被报告的一系列差距，揭示当前模型在泛化能力方面的不足。

Conclusion: 神经路由求解器具有潜力，但需更加关注其泛化性能；提出的分类体系和评估流程为未来研究提供了指导方向。

Abstract: Neural routing solvers (NRSs) that leverage deep learning to tackle vehicle routing problems have demonstrated notable potential for practical applications. By learning implicit heuristic rules from data, NRSs replace the handcrafted counterparts in classic heuristic frameworks, thereby reducing reliance on costly manual design and trial-and-error adjustments. This survey makes two main contributions: (1) The heuristic nature of NRSs is highlighted, and existing NRSs are reviewed from the perspective of heuristics. A hierarchical taxonomy based on heuristic principles is further introduced. (2) A generalization-focused evaluation pipeline is proposed to address limitations of the conventional pipeline. Comparative benchmarking of representative NRSs across both pipelines uncovers a series of previously unreported gaps in current research.

</details>


### [94] [Non-Extreme Individual Minima for Improved Pareto Front Sampling Efficiency and Decision-Making](https://arxiv.org/abs/2602.21883)
*Markus Herrmann-Wicklmayr,Kathrin Flaßkamp*

Main category: math.OC

TL;DR: 提出了一种基于$L$-实用适度有效性的非极端个体极小值概念，用于替代传统多目标优化中的标准个体极小值，以排除帕累托前沿中不实用的极端区域。


<details>
  <summary>Details</summary>
Motivation: 在多目标优化中，帕累托前沿的某些区域过于陡峭或平坦，其权衡关系不具实际意义，尤其靠近各目标单独最优的极端点时，微小改进需付出巨大代价，不利于决策。因此需要识别并排除这些不实用的区域。

Method: 引入非极端个体极小值的概念，基于$L$-实用适度有效性，并通过最多$2n_J$个加权和标量化问题求解；结合图像空间归一化策略以增强对不同尺度目标的鲁棒性。

Result: 算法能有效识别非极端个体极小值，成功缩小帕累托前沿采样范围至更合理的乌托邦-纳迪尔超盒内，提升归一化与膝点法等决策方法的效果。数值实验包括一个凸的学术案例和一个非凸的实际应用，验证了方法的有效性。

Conclusion: 所提方法为多目标优化提供了一种计算高效且鲁棒的手段，用以过滤帕累托前沿中不具实际价值的极端区域，从而改善后续分析与决策过程。

Abstract: In multi-objective optimization, the set of optimal trade-offs -- the Pareto front -- often contains regions that are extremely steep or flat. The Pareto optimal points in these regions are typically of limited interest for decision-making, as the marginal rate of substitution is extreme: a marginal improvement in one objective necessitates a significant deterioration in at least one other objective. These unfavorable trade-offs frequently occur near the individual minima, where single objectives attain their minimum values without considering the remaining criteria.
  To address this, we propose the concept of \emph{non-extreme individual minima} that relies on the notion of $L$-practical proper efficiency. These points can serve as a less sensitive replacement for \emph{standard} individual minima in subsequent related methods. Specifically, they allow for a more practical restriction of the Pareto front sampling within a refined utopia-nadir hyperbox, provide a meaningful basis for image space normalization, and can enhance decision-making techniques, such as knee-point methods, by focusing on regions with acceptable trade-offs.
  We provide a computationally efficient algorithm to determine these non-extreme individual minima by solving at most $2n_J$ standard weighted-sum scalarizations, where $n_J$ is the number of objectives. To ensure robustness across varying objective scales, the method incorporates an integrated image space normalization strategy. Numerical examples, specifically a convex academic case and a non-convex real-world application, demonstrate that the method successfully excludes practically irrelevant regions in the image space.

</details>


### [95] [Comparison of Linear Systems Across Time Domains: Continuous-time vs. Discrete-time](https://arxiv.org/abs/2602.21924)
*Armin Pirastehzad,Bart Besselink*

Main category: math.OC

TL;DR: 提出了一种线性系统在不同时间域下行为比较的框架，通过系统插值概念将连续时间系统与离散时间系统的输入-状态轨迹关联，并利用Legendre多项式实现高效计算和控制器设计。


<details>
  <summary>Details</summary>
Motivation: 为了在不同时间域（如连续与离散）之间有效比较线性系统的行为，并支持精确的控制器综合。

Method: 引入系统插值的概念，将离散时间信号的分段多项式插值表示为连续时间函数，并用移位Legendre多项式的线性组合表示；通过子空间包含关系基于系统参数刻画系统插值。

Result: 建立了基于参数的系统插值判定条件，实现了连续时间系统到离散时间系统的有效离散化，并可用于满足采样时刻控制规范的同时评估区间内可能的违规程度。

Conclusion: 该框架为跨时间域的线性系统行为分析与控制器设计提供了理论基础和计算高效的工具。

Abstract: We develop a formal framework for the behavioral comparison of linear systems across different time domains. We accomplish this by introducing the notion of system interpolation, which determines whether the input-state trajectories of a continuous-time system can be realized as piecewise polynomial interpolations of the input-state trajectories of a discrete-time system. In this context, a piecewise polynomial interpolation of a discrete-time signal is characterized as a continuous-time function that coincides with the discrete-time signal at given sampling instants and can be realized as a polynomial of a prescribed degree over intervals between these instants. By representing piecewise polynomial functions as linear combinations of shifted Legendre polynomials, we characterize system interpolation as a subspace inclusion that is completely in terms of system parameters. This therefore allows for a computationally efficient comparison of the input-state behavior of a continuous-time system with that of a discrete-time one. We then exploit this characterization to discretize a given continuous-time system into a discrete-time one. Lastly, given a control specification, we exploit system interpolation to synthesize controllers that ensure satisfaction at each given sampling instant, while they measure the extent of (possible) violation over intervals between these instants.

</details>


### [96] [Target controllability for a minimum time problem in a trait-structured chemostat model](https://arxiv.org/abs/2602.21999)
*Claudia Alvarez-Latuz,Terence Bayen,Jerome Coville*

Main category: math.OC

TL;DR: 本文研究了一类由包含突变和单一限制性底物的性状结构化恒化器模型所支配的最短时间控制问题，证明了控制到状态映射的良好适定性，并分析了调节底物浓度的反馈控制律，证明了解收敛于系统稳态，进一步证明了达到目标集合的最优控制存在性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过控制策略实现对具有突变特性的种群进行高效选择，以达到优化生物反应过程的目的。

Method: 采用数学分析方法研究控制到状态映射的适定性，结合反馈控制律（如auxostat型控制）分析系统解的收敛性，并利用最优控制理论证明最短时间控制的存在性。

Result: 证明了控制到状态映射的良好适定性；得出auxostat型控制下系统解收敛于稳态；实现了对低加权平均半饱和常数种群的选择；证明了最短时间最优控制的存在性。

Conclusion: 该研究表明，通过对底物浓度的有效控制，可以在有限时间内实现对期望种群的选择，为基于性状结构化模型的生物过程优化提供了理论支持。

Abstract: In this paper, we consider a minimum time control problem governed by a trait-structured chemostat model including mutation and one limiting substrate. Our first main result proves the well-posedness of the control-to-state mapping. We subsequently analyze the class of auxostat-type controls, feedback laws designed to regulate substrate concentration, and prove that the corresponding solutions converge to a stationary state of the system. These convergence results are used to show the reachability of a target set corresponding to the selection of a population with a low weighted averaged half-saturation constant. Finally, we show the existence of an optimal control for the minimum time problem associated with reaching the target set. These theoretical findings are completed by numerical simulations.

</details>


### [97] [Stochastic Optimal Control with Side Information and Bayesian Learning](https://arxiv.org/abs/2602.22047)
*Johannes Milz,Alexander Shapiro,Enlu Zhou*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study infinite-horizon stochastic optimal control problems with observable side information: a Markov chain that modulates an unknown context-conditional randomness distribution. Since this distribution is unknown, we propose a Bayesian reformulation based on a parametric density model and posterior predictive dynamics, which yields a Bayesian Bellman equation. We prove posterior consistency under Markov samples and, under correct specification and identifiability, uniform convergence of the Bayesian value function. Finally, we establish Bernstein--von Mises-type asymptotic normality for the data-driven contextual optimal value.

</details>


### [98] [A Polyhedral Study on Unit Commitment with a Single Type of Binary Variables](https://arxiv.org/abs/2602.22058)
*Bin Tian,Kai Pan,Chung-Lun Li*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Efficient power production scheduling is a crucial concern for power system operators aiming to minimize operational costs. Previous mixed-integer linear programming formulations for unit commitment (UC) problems have primarily used two or three types of binary variables. The investigation of strong formulations with a single type of binary variables has been limited, as it is believed to be challenging to derive strong valid inequalities using fewer binary variables, and the reduction of the number of binary variables is often accompanied by a compromise in tightness. To address these issues, this paper considers a formulation for unit commitment using a single type of binary variables and develops strong valid inequality families to enhance the tightness of the formulation. Conditions under which these strong valid inequalities serve as facet-defining inequalities for the single-generator UC polytope are provided. For those large-size valid inequality families, the existence of efficient separation algorithms for determining the most violated inequalities is also discussed. The effectiveness of the proposed single-binary formulation and strong valid inequalities is demonstrated through computational experiments on network-constrained UC problems. The results indicate that the strong valid inequalities presented in this paper are effective in solving UC problems and can also be applied to UC formulations that contain more than one type of binary variables.

</details>


### [99] [Applying a Random-Key Optimizer on Mixed Integer Programs](https://arxiv.org/abs/2602.22173)
*Antonio A. Chaves,Mauricio G. C. Resende,Carise E. Schmidt,J. Kyle Brubaker,Helmut G. Katzgraber*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Mixed-Integer Programs (MIPs) are NP-hard optimization models that arise in a broad range of decision-making applications, including finance, logistics, energy systems, and network design. Although modern commercial solvers have achieved remarkable progress and perform effectively on many small- and medium-sized instances, their performance often degrades when confronted with large-cale or highly constrained formulations. This paper explores the use of the Random-Key Optimizer (RKO) framework as a flexible, metaheuristic alternative for computing high-quality solutions to MIPs through the design of problem-specific decoders. The proposed approach separates the search process from feasibility enforcement by operating in a continuous random-key space while mapping candidate solutions to feasible integer solutions via efficient decoding procedures. We evaluate the methodology on two representative and structurally distinct benchmark problems: the mean-variance Markowitz portfolio optimization problem with buy-in and cardinality constraints, and the Time-Dependent Traveling Salesman Problem. For each formulation, tailored decoders are developed to reduce the effective search space, promote feasibility, and accelerate convergence. Computational experiments demonstrate that RKO consistently produces competitive, and in several cases superior, solutions compared to a state-of-the-art commercial MIP solver, both in terms of solution quality and computational time. These results highlight the potential of RKO as a scalable and versatile heuristic framework for tackling challenging large-scale MIPs.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [100] [Autonomous Satellite Rendezvous via Hybrid Feedback Optimization](https://arxiv.org/abs/2602.21334)
*Oscar Jed R. Chuy,Matthew T. Hale,Vignesh Sivaramakrishnan,Sean Phillips,Ricardo G. Sanfelice*

Main category: eess.SY

TL;DR: 提出一种基于反馈优化的自主卫星交会方法，通过在环路中使用离散梯度下降法控制Clohessy-Wiltshire动力学模型，实现指数收敛至目标点附近，并显著抑制扰动。


<details>
  <summary>Details</summary>
Motivation: 应对空间操作中的状态测量不确定性及星载处理器计算能力有限的问题，提升自主交会、近地操作与对接（ARPOD）的安全性与可行性。

Method: 采用连续时间Clohessy-Wiltshire方程建模卫星动力学，设计渐近稳定控制器，并将离散时间梯度下降算法嵌入控制回路进行实时输入优化。

Result: 所构建的混合反馈优化系统具有良定性，解为完备且非Zenon；系统状态指数收敛至目标点附近的球域内，球半径由系统参数决定；仿真显示扰动幅度最多降低98.4%。

Conclusion: 反馈优化框架能有效应对星载计算资源受限和不确定性挑战，为自主卫星交会提供了高效、鲁棒的解决方案。

Abstract: As satellites have proliferated, interest has increased in autonomous rendezvous, proximity operations, and docking (ARPOD). A fundamental challenge in these tasks is the uncertainties when operating in space, e.g., in measurements of satellites' states, which can make future states difficult to predict. Another challenge is that satellites' onboard processors are typically much slower than their terrestrial counterparts. Therefore, to address these challenges we propose to solve an ARPOD problem with feedback optimization, which computes inputs to a system by measuring its outputs, feeding them into an optimization algorithm in the loop, and computing some number of iterations towards an optimal input. We focus on satellite rendezvous, and satellites' dynamics are modeled using the continuous-time Clohessy-Wiltshire equations, which are marginally stable. We develop an asymptotically stabilizing controller for them, and we use discrete-time gradient descent in the loop to compute inputs to them. Then, we analyze the hybrid feedback optimization system formed by the stabilized Clohessy-Wiltshire equations with gradient descent in the loop. We show that this model is well-posed and that maximal solutions are both complete and non-Zeno. Then, we show that solutions converge exponentially fast to a ball around a rendezvous point, and we bound the radius of that ball in terms of system parameters. Simulations show that this approach provides up to a 98.4\% reduction in the magnitude of disturbances across a range of simulations, which illustrates the viability of hybrid feedback optimization for autonomous satellite rendezvous.

</details>


### [101] [Optimal Real-Time Fusion of Time-Series Data Under Rényi Differential Privacy](https://arxiv.org/abs/2602.21525)
*Chuanghong Weng,Ehsan Nekouei*

Main category: eess.SY

TL;DR: 本文研究了多传感器数据的实时融合问题，提出了一种基于Rényi差分隐私的隐私保护融合框架，在满足总隐私预算约束下联合优化融合策略和状态估计，以最小化状态估计误差。


<details>
  <summary>Details</summary>
Motivation: 由于传感器数据具有隐私性且与底层过程相关联，如何在保护隐私的同时实现高效的状态估计成为挑战，因此需要设计兼顾隐私和估计性能的融合机制。

Method: 将隐私泄露通过Rényi差分隐私量化，并构建受总隐私预算约束的有限时域优化问题，推导约束最优性条件并分析最优融合策略的结构特性；采用结构化高斯分布参数化融合策略，并设计数值算法进行联合优化。

Result: 证明了最优融合策略能自适应分配隐私预算并以闭环方式调节攻击者信念；参数化的融合策略满足隐私约束，所提算法有效降低了计算负担。

Conclusion: 所提出的隐私感知融合框架能够在保障多传感器数据隐私的前提下提升状态估计精度，适用于如交通密度估计等实际应用场景。

Abstract: In this paper, we investigate the optimal real-time fusion of data collected by multiple sensors. In our set-up, the sensor measurements are considered to be private and are jointly correlated with an underlying process. A fusion center combines the private sensor measurements and releases its output to an honest-but-curious party, which is responsible for estimating the state of the underlying process based on the fusion center's output. The privacy leakage incurred by the fusion policy is quantified using Rényi differential privacy. We formulate the privacy-aware fusion design as a constrained finite-horizon optimization problem, in which the fusion policy and the state estimation are jointly optimized to minimize the state estimation error subject to a total privacy budget constraint. We derive the constrained optimality conditions for the proposed optimization problem and use them to characterize the structural properties of the optimal fusion policy. Unlike classical differential privacy mechanisms, the optimal fusion policy is shown to adaptively allocates the privacy budget and regulates the adversary's belief in a closed-loop manner. To reduce the computational burden of solving the resulting constrained optimality equations, we parameterize the fusion policy using a structured Gaussian distribution and show that the parameterized fusion policy satisfies the privacy constraint. We further develop a numerical algorithm to jointly optimize the fusion policy and state estimator. Finally, we demonstrate the effectiveness of the proposed fusion framework through a traffic density estimation case study.

</details>


### [102] [Asymmetry Demystified: Strict CLFs and Feedbacks for Predator-Prey Interconnections](https://arxiv.org/abs/2602.21594)
*Miroslav Krstic*

Main category: eess.SY

TL;DR: 本文探讨了在捕食-猎物模型中设计严格控制李雅普诺夫函数（CLFs）以实现全局渐近稳定化的方法，提出了一种非分离型Volterra风格的构造方法，并结合前馈与后推技术进行反馈控制设计，同时保持状态和输入的正性。


<details>
  <summary>Details</summary>
Motivation: 由于种群动态在接近灭绝和过度繁殖时表现出截然不同的行为，且要求状态和控制均为正，使得全局稳定化困难；尤其在捕食-猎物系统中，即使中性稳定也难以构造严格的CLF而不依赖LaSalle不变原理。

Method: 推广经典的Volterra型李雅普诺夫函数至非可分形式，提出无需Matrosov技巧的简洁、直观的严格CLF构造方法，并结合定制化的前馈与后推法同步设计控制器与CLF。

Result: 成功构造了适用于捕食-猎物系统的严格CLF，实现了全局渐近稳定化，并展示了反馈控制与CLF的协同设计实例，避免了传统方法中复杂的分析工具。

Conclusion: 所提出的非分离Volterra型CLF框架为捕食-猎物系统的稳定控制提供了更清晰、更具洞察力的设计途径，同时保持生物合理性（状态和输入非负）。

Abstract: The difficulty with control of population dynamics, besides the states being positive and the control having to also be positive, is the extreme difference in the dynamics near extinction and at overpopulated states. As hard as global stabilization is, even harder is finding CLFs that are strict, don't require LaSalle arguments, and permit quantification of convergence. Among the three canonical types of two-population dynamics (mutualism, which borders on trivial, predator-prey, and competition, which makes global stabilization with positive harvesting impossible), predator-prey is the ``sweet spot'' for the study of stabilization. Even when the predator-prey interaction is neutrally stable, global asymptotic stabilization with strict CLFs has proven very difficult, except by conservative, hard-to-gain-insight-from Matrosov-like techniques.
  In this little note we show directions for the design of clean, elegant, insight-bearing, majorization-free strict CLFs. They generalize the classical Volterra-style Lyapunov functions for population dynamics to non-separable Volterra-style constructions. As a bonus to strictification as an analysis activity, we provide examples of concurrent designs of feedback and CLFs, using customized versions of forwarding and backstepping (note that, in suitable coordinates, predator-prey is both strict-feedforward and strict-feedback), where the striking deviations from these methods' conventional forms is necessitated by the predator-prey's states and inputs needing to be kept positive.

</details>


### [103] [Geometry-Dependent Radiation of Pinching Antennas: Theory, Simulation, and Measurement](https://arxiv.org/abs/2602.21602)
*Haoyang Li,Weidong Liu,Zhensheng Chen,Chaoyun Song,Gaojie Chen*

Main category: eess.SY

TL;DR: 该论文研究了不同几何形状的夹持天线（PA）辐射方向图，提出弧形PA以实现发射方向控制，并通过仿真与测量验证了几何形状对辐射特性的重要影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常将PA建模为各向同性辐射器，忽略了其几何形状对辐射模式的影响；本文旨在探究PA几何形状如何影响其辐射方向性。

Method: 通过全波仿真和实际测量，分析不同几何形状PA的辐射方向图，并设计包含介质波导、波导过渡和PA元件的原型系统进行验证。

Result: 仿真与测量结果表明，PA的几何形状显著影响其辐射特性；引入的弧形PA可实现发射方向控制。

Conclusion: PA的几何形状在PA系统中至关重要，不能忽略，应作为设计中的关键参数考虑。

Abstract: Most existing studies achieve beamforming by adjusting the positions of pinching antennas (PAs) and typically model PAs as isotropic radiators. However, under the dielectric scatterer model, the PA radiation pattern depends on its geometry. This letter investigates the radiation patterns of PAs with different geometries through full-wave simulations and measurements, and demonstrates how geometry influences the radiation directivity. In addition, an arc-shaped PA is introduced to enable transmit-direction control in PA systems. A PA system prototype consisting of a dielectric waveguide, waveguide transitions, and a PA element is proposed. Prototype measurements are used to validate the simulations and to characterize the directivity of square and triangular PAs, and the measurement procedure can be applied to obtain radiation patterns for PAs with general geometries. The simulation and measurement results jointly demonstrate that PA geometry is critical in PA systems because it influences the radiation characteristics significantly.

</details>


### [104] [Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach](https://arxiv.org/abs/2602.21715)
*Xu Yang,Chenhui Lin,Xiang Ma,Dong Liu,Ran Zheng,Haotian Liu,Wenchuan Wu*

Main category: eess.SY

TL;DR: 提出了一种结合大语言模型（LLM）和强化学习（RL）的混合知识-数据驱动方法，用于主动配电网的两阶段电压控制，通过LLM在日前阶段制定调度策略、RL在日内阶段优化无功出力，显著提升训练效率与电压控制性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法在电压控制中难以融合多源异构信息（如日前预测和电网规程），且依赖大量试错探索，难以满足实际配电网运行需求。

Method: 构建LLM与RL协同的两阶段电压控制框架：LLM基于区域级粗略预测生成OLTC和SC的日前调度策略；RL基于节点级精确测量，优化光伏逆变器的无功出力；并设计LLM自进化机制与RL预训练-微调流程以提升策略协同性。

Result: 所提方法能有效整合语义化电网知识与多尺度数据，显著减少训练探索成本，改善电压控制效果，综合对比与消融实验验证了其优越性。

Conclusion: 该混合知识-数据驱动方法更贴近实际运行场景，充分利用LLM的知识推理能力与RL的数据学习能力，实现了高效、高性能的两阶段电压控制，为智能配电网运行提供了新范式。

Abstract: The growing integration of distributed photovoltaics (PVs) into active distribution networks (ADNs) has exacerbated operational challenges, making it imperative to coordinate diverse equipment to mitigate voltage violations and enhance power quality. Although existing data-driven approaches have demonstrated effectiveness in the voltage control problem, they often require extensive trial-and-error exploration and struggle to incorporate heterogeneous information, such as day-ahead forecasts and semantic-based grid codes. Considering the operational scenarios and requirements in real-world ADNs, in this paper, we propose a hybrid knowledge-data-driven approach that leverages dynamic collaboration between a large language model (LLM) agent and a reinforcement learning (RL) agent to achieve two-stage voltage control. In the day-ahead stage, the LLM agent receives coarse region-level forecasts and generates scheduling strategies for on-load tap changer (OLTC) and shunt capacitors (SCs) to regulate the overall voltage profile. Then in the intra-day stage, based on accurate node-level measurements, the RL agent refines terminal voltages by deriving reactive power generation strategies for PV inverters. On top of the LLM-RL collaboration framework, we further propose a self-evolution mechanism for the LLM agent and a pretrain-finetune pipeline for the RL agent, effectively enhancing and coordinating the policies for both agents. The proposed approach not only aligns more closely with practical operational characteristics but also effectively utilizes the inherent knowledge and reasoning capabilities of the LLM agent, significantly improving training efficiency and voltage control performance. Comprehensive comparisons and ablation studies demonstrate the effectiveness of the proposed method.

</details>


### [105] [Traffic-aware Hierarchical Integrated Thermal and Energy Management for Connected HEVs](https://arxiv.org/abs/2602.21914)
*Jie Han,Arash Khalatbarisoltani,Hai L. Vu,Xiaosong Hu,Jun Yang*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The energy and thermal management systems of hybrid electric vehicles (HEVs) are inherently interdependent. With the ongoing deployment of intelligent transportation systems (ITSs) and increasing vehicle connectivity, the integration of traffic information has become crucial for improving both energy efficiency and thermal comfort in modern vehicles. To enhance fuel economy, this paper proposes a novel traffic-aware hierarchical integrated thermal and energy management (TA-ITEM) strategy for connected HEVs. In the upper layer, global reference trajectories for battery state of charge (SOC) and cabin temperature are planned using traffic flow speed information obtained from ITSs. In the lower layer, a real-time model predictive control (MPC)-based ITEM controller is developed, which incorporates a novel Transformer-based speed predictor with driving condition recognition (TF-DCR) to enable anticipatory tracking of the reference trajectories. Numerical simulations are conducted under various driving cycles and ambient temperature conditions. The results demonstrate that the proposed TA-ITEM approach outperforms conventional rule-based and MPC-SP approaches, with average fuel consumption reductions of 56.36\% and 5.84\%, respectively, while maintaining superior thermal regulation and cabin comfort. These findings confirm the effectiveness and strong generalization capability of TA-ITEM and underscore the advantages of incorporating traffic information.

</details>


### [106] [Tempered Christoffel-Weighted Polynomial Chaos Expansion for Resilience-Oriented Uncertainty Quantification](https://arxiv.org/abs/2602.22133)
*Mahsa Ebadat-Parast,Xiaozhe Wang*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate and efficient uncertainty quantification is essential for resilience assessment of modern power systems under high impact and low probability disturbances. Data driven sparse polynomial chaos expansion (DDSPCE) provides a computationally efficient surrogate framework but may suffer from ill conditioned regression and loss of accuracy in the distribution tails that determine system risk. This paper studies the impact of regression weighting schemes on the stability and tail accuracy of DD-SPCE surrogates by introducing a tempered Christoffel weighted least squares (T-CWLS) formulation that balances numerical stability and tail fidelity. The tempering exponent is treated as a hyperparameter whose influence is examined with respect to distributional accuracy compared with Monte Carlo simulations. Case studies on distribution system load shedding show that the proposed method reduces 95th percentile deviation by 16%, 5th percentile deviation by 6%, and improves the regression stability index by over 130%. The results demonstrate that controlling the weighting intensity directly influences both stability index and the accuracy of tail prediction.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [107] [Ab Initio Random Matrix Theory of Molecular Electronic Structure](https://arxiv.org/abs/2602.21299)
*Zhen Tao,Victor Galitski*

Main category: cond-mat.str-el

TL;DR: 该研究利用从头算电子结构方法，验证了随机矩阵理论（RMT）在分子电子结构中的普适性，发现低对称性分子的能谱表现出高斯正交系综（GOE）统计特征，并在强磁场下观察到向高斯幺正系综（GUE）的转变。


<details>
  <summary>Details</summary>
Motivation: 探索复杂分子体系中电子能级统计是否符合随机矩阵理论的普适性预测，特别是在真实分子和物理相关激发态中的适用性。

Method: 采用Hartree-Fock、CIS、DFT和含时DFT等从头算方法计算多个代表性分子的单粒子轨道能和多电子激发态，对能谱进行无量纲化处理并分析其统计特性，同时研究电场和磁场对能谱的影响。

Result: 低对称性分子的能谱呈现GOE统计；在仅考虑束缚价激发的螺旋烯链中仍观察到GOE行为；磁场增强导致向GUE转变，但所需磁场远超实验可及范围；电极化率方差在磁场中呈非解析依赖关系。

Conclusion: 随机矩阵普适性为理解复杂相互作用电子系统的从头算结果提供了一个通用框架，适用于真实分子的物理激发态。

Abstract: We use ab initio electronic-structure methods to investigate random-matrix theory (RMT) universality in molecular electronic structure. Using single-reference electronic structure methods, including Hartree-Fock, configuration-interaction singles (CIS), density functional theory, and linear-response time-dependent density-functional theory, we compute single-particle orbital energies and many-electron excitations of several representative molecules (benzene, alanine, 1-phenylethylamine, methyloxirane, and helicene chains). For generic low-symmetry geometries, the unfolded spectra of these ab initio Hamiltonians exhibit Wigner-Dyson level statistics of the Gaussian orthogonal ensemble (GOE). For extended helicene chains we explicitly restrict to bound valence excitations below the ionization threshold and still observe GOE statistics, indicating that the RMT universality is present for physical states of direct relevance to real molecules. We further explore the electric and magnetic field dependence of the molecular electronic spectra. The variance of electric polarizability (level curvature K) is predicted to be non-analytic in the magnetic field which serves as an infrared cutoff, <K^2> proportional to log(1/|B|). We observe a transition to the Gaussian unitary ensemble (GUE) by increasing the magnetic fields, although it occurs only at magnetic fields far beyond experimentally accessible scales. Our results indicate that random matrix universality provides a general framework for organizing ab initio predictions of interacting electron spectra in complex systems.

</details>


### [108] [Detecting Higher Berry Phase via Boundary Scattering](https://arxiv.org/abs/2602.21301)
*Chih-Yu Lo,Xueda Wen*

Main category: cond-mat.str-el

TL;DR: 提出了一种边界散射方法来探测一维无间隙自由费米子系统的高阶贝里相位，通过连接无间隙引线到带隙系统，展示了高阶贝里不变量可以通过边界反射矩阵的高阶卷绕数获得。


<details>
  <summary>Details</summary>
Motivation: 研究带隙多体量子系统空间的拓扑性质，特别是高阶贝里相位的探测。

Method: 发展了一种边界散射方法，通过将无间隙引线耦合到带隙系统，研究边界反射矩阵的高阶卷绕数。

Result: 高阶贝里不变量可通过边界反射矩阵的高阶卷绕数获得，并且对无序等扰动具有鲁棒性。

Conclusion: 该方法建立了高阶贝里不变量与输运性质之间的联系，为参数化拓扑相提供了潜在的实验探测手段。

Abstract: Higher Berry phase has recently been proposed to study the topology of the space of gapped many-body quantum systems. In this work, we develop a boundary-scattering approach to detect higher Berry phases in one-dimensional gapped free-fermion systems. By coupling a gapless lead to the gapped system, we demonstrate that the higher Berry invariant can be obtained by studying the higher winding number of the boundary reflection matrix. The resulting topological invariant is robust against perturbations such as disorder. Our approach establishes a connection between higher Berry invariants and transport properties, thereby providing a potentially experimentally accessible probe of parametrized topological phases.

</details>


### [109] [Rotational Phonons Drive Low-Energy Kinks in Cuprate Superconductors](https://arxiv.org/abs/2602.21438)
*Yanyong Wang,Manuel Engel,Christopher Lane,Henrique Miranda,Lin Hou,Bernardo Barbiellini,Adrienn Ruzsinszky,John P. Perdew,Robert S. Markiewicz,Arun Bansil,Jianwei Sun,Ruiqi Zhang*

Main category: cond-mat.str-el

TL;DR: 本研究利用SCAN密度泛函方法系统研究了空穴掺杂无限层CaCuO₂中的电子-声子耦合，发现磁性相中电子-声子耦合强度λ约为0.5，能很好地解释实验观测到的40–80 meV范围内的准粒子‘kinks’和峰-谷-包络结构，表明旋转氧声子起主导作用。


<details>
  <summary>Details</summary>
Motivation: 理解铜基超导体中普遍存在的准粒子‘kinks’和峰-谷-包络（PDH）结构的微观起源，解决传统DFT方法在描述强关联体系中的局限性。

Method: 采用Strongly Constrained and Appropriately Normed (SCAN)密度泛函方法，显式包含磁性效应，系统研究空穴掺杂无限层CaCuO₂中的电子-声子耦合。

Result: 在磁性相中发现较强的电子-声子耦合强度λ ~ 0.5，模拟出40–80 meV范围内的kinks和PDH结构；旋转氧声子是主要贡献者，而呼吸模贡献较小。

Conclusion: 铜基超导体中存在显著的电子-声子耦合，旋转氧声子在其中起关键作用，为理解铜基材料及其他体系中的谱学反常现象提供了新框架。

Abstract: Angle-resolved photoemission spectroscopy (ARPES) reveals ubiquitous quasiparticle ``kinks'' near $\sim$70 meV and $\sim$40 meV across cuprate superconductors, often accompanied by peak--dip--hump (PDH) structures. These features point to strong coupling between electrons and low-energy bosonic excitations, but the microscopic origin has remained elusive due to the limitations of conventional density-functional theory (DFT) and the high cost of beyond-DFT methods. Here, we systematically study the electron--phonon coupling (EPC) in hole-doped infinite-layer CaCuO$_2$ using the Strongly Constrained and Appropriately Normed (SCAN) density functional, explicitly including magnetic effects. We find a substantial EPC strength $λ$ of $\sim$0.5 in the magnetic phase, producing kinks and PDH structures in the 40-80~meV window in excellent agreement with experiments. The dominant contribution arises from rotational oxygen phonons, while breathing modes contribute little. Our results establish strong EPC in cuprates, highlight the key role of rotational phonons, and provide a framework for understanding spectral anomalies in cuprates and beyond.

</details>


### [110] [Unsupervised Discovery of Intermediate Phase Order in the Frustrated $J_1$-$J_2$ Heisenberg Model via Prometheus Framework](https://arxiv.org/abs/2602.21468)
*Brandon Yee,Wilson Collins,Maximilian Rutkowski*

Main category: cond-mat.str-el

TL;DR: 利用经过验证的Prometheus变分自编码器框架，通过对4×4晶格的精确对角化基态进行无监督分析，系统研究了正方形晶格上自旋-1/2的J1-J2海森堡模型在J2/J1 ∈ [0.3, 0.7]范围内的相图，探索了介于奈尔反铁磁和条纹有序态之间的中间相的性质。


<details>
  <summary>Details</summary>
Motivation: 解决在受挫量子磁性中由于竞争相互作用和有限系统尺寸导致的传统序参量难以识别的问题，明确J1-J2海森堡模型中间相的本质。

Method: 应用Prometheus变分自编码器框架，对4×4晶格的精确对角化基态数据进行无监督学习，通过密集参数扫描（J2/J1从0.3到0.7，步长0.01）和潜在空间分析，结合多种独立方法进行序参量发现和临界点检测。

Result: 实现了对J1-J2相图的系统性探索，成功识别出中间相区域，并通过无监督方式发现了可能的序参量特征和临界行为，验证了机器学习方法在复杂量子系统中的适用性。

Conclusion: 本工作展示了经过严格验证的机器学习方法在解决受挫量子磁性开放问题中的潜力，为识别传统方法难以处理的量子相提供了新途径。

Abstract: The spin-$1/2$ $J_1$-$J_2$ Heisenberg model on the square lattice exhibits a debated intermediate phase between Néel antiferromagnetic and stripe ordered regimes, with competing theories proposing plaquette valence bond, nematic, and quantum spin liquid ground states. We apply the Prometheus variational autoencoder framework -- previously validated on classical (2D, 3D Ising) and quantum (disordered transverse field Ising) phase transitions -- to systematically explore the $J_1$-$J_2$ phase diagram via unsupervised analysis of exact diagonalization ground states for a $4 \times 4$ lattice. Through dense parameter scans of $J_2/J_1 \in [0.3, 0.7]$ with step size 0.01 and comprehensive latent space analysis, we investigate the nature of the intermediate regime using unsupervised order parameter discovery and critical point detection via multiple independent methods. This work demonstrates the application of rigorously validated machine learning methods to open questions in frustrated quantum magnetism, where traditional order parameter identification is challenged by competing interactions and limited accessible system sizes.

</details>


### [111] [Hall effect on nontrivial quadrupole order in quasi-kagome compound URhSn](https://arxiv.org/abs/2602.21587)
*Yusei Shimizu,Arvind Maurya,Yoshiya Homma,Motoi Kimata,Toni Helm,Ai Nakamura,Dexin Li,Atsushi Miyake,Dai Aoki*

Main category: cond-mat.str-el

TL;DR: 该研究揭示了准笼目化合物URhSn在多重相变下的非常规输运特性，特别是在易磁化轴方向存在非典型的反常霍尔效应和复杂的霍尔电阻行为。


<details>
  <summary>Details</summary>
Motivation: 探索5f电子体系中非平庸多极相的输运行为，理解URhSn中在不同磁有序相下的异常霍尔效应起源。

Method: 通过测量URhSn在不同温度和磁场下的霍尔电阻及磁输运性质，分析其在居里温度（TC = 16 K）和中间相温度（TO = 54 K）附近的输运行为。

Result: 发现沿[0001]方向存在大的反常霍尔信号，霍尔电阻表现出非线性、非常规的磁场依赖性，并在低温下出现符号反转；此外，在中间相和铁磁相中，霍尔分量与磁化率不成正比。

Conclusion: URhSn展现出非常规的输运特性，表明其中可能存在非平庸的多极序，为理解5f电子系统中的复杂量子相提供了重要线索。

Abstract: This study focuses on the transport properties of the quasi-kagome compound URhSn, which exhibits successive phase transitions at TC =16 K (ferromagnetic phase) and TO =54 K (intermediate phase). A large anomalous Hall component is present along the easy-magnetization axis (H|| [0001]), and the Hall resistivity shows very complex temperature- and field-dependence, with a sign reversal at low temperatures. The Hall resistivity exhibits a nonlinear and unusual field-dependence. Interestingly, there exists an unusual Hall component that is not proportional to the magnetic susceptibility for H || [0001] in both the intermediate and ferromagnetic states. These results reveal unconventional transport properties of URhSn, providing important insights into nontrivial multipolar phases in 5f- electron systems.

</details>


### [112] [Tighter thermalization bounds for perturbed quantum many-body scars](https://arxiv.org/abs/2602.21962)
*Meng-Yun Mao,Zhixiang Sun,Wen-Long You*

Main category: cond-mat.str-el

TL;DR: 该论文研究了量子多体疤痕态（QMBS）在局域微扰下的热化时间尺度，提出了比以往更紧的下界，并揭示了精确与近似疤痕态在热化行为上的本质差异。


<details>
  <summary>Details</summary>
Motivation: 尽管量子多体疤痕态能避免热化，但其在扰动下的稳定性尚不明确，本文旨在建立更精确的热化时间下界以评估其鲁棒性。

Method: 结合数值模拟与解析推导，利用受限谱生成代数（RSGA）分析精确疤痕态，并通过二阶微扰理论研究近似疤痕态的热化动力学。

Result: 发现精确QMB S的热化时间为τ ~ O(λ^(-1/d))，优于此前的O(λ^(-1/(d+1)))；而近似QMB S在无RSGA保护时可表现出更慢的τ ~ O(λ^(-2))热化行为。

Conclusion: 精确与近似量子多体疤痕态通过不同机制维持相干性，本工作提供了更严格的热化时间估计，深化了对疤痕态稳定性的理解。

Abstract: Quantum many-body scars (QMBS) are exceptional eigenstates that defy thermalization, enabling long-lived coherent dynamics in strongly interacting systems. However, their stability under perturbations remains inadequately understood. In this work, we derive improved lower bounds on the thermalization time of QMBS under local perturbations with strength $λ$. Using both numerical simulations and analytical reasoning, we show that exact QMBS exhibit slow thermalization, with a timescale scaling as $τ\sim \mathcal{O}(λ^{-1/d})$ owing to the stabilizing restricted spectrum-generating algebra (RSGA), which is a significant improvement over previous bounds (e.g., $τ\sim \mathcal{O}(λ^{-1/(d+1)})$). Counterintuitively, approximate QMBS can thermalize even more slowly under generic perturbations, exhibiting $τ\sim \mathcal{O}(λ^{-2})$ scaling due to second-order perturbative effects in the absence of such protective structure. These distinct thermalization behaviors clarify how exact and approximate scars maintain coherence. Our work advances previous findings by establishing a tighter bound on the thermalization time, clarifying when scarred dynamics remain long-lived under weak but generic perturbations.

</details>


### [113] [Crystallography-driven molecularization of a two-dimensional spin-$3/2$ magnet](https://arxiv.org/abs/2602.22005)
*Hari Borutta,Tobias Müller,Ronny Thomale,Harald O. Jeschke,Yasir Iqbal*

Main category: cond-mat.str-el

TL;DR: Na$_2$Mn$_3$O$_7$是一种二维大自旋磁性材料，尽管存在强反铁磁相互作用，却未表现出长程磁序，而是呈现双阶段热力学交叉行为，源于晶体结构导致的磁自由度分子化。


<details>
  <summary>Details</summary>
Motivation: 探索在大自旋二维磁体中为何Na$_2$Mn$_3$O$_7$在强交换作用下仍不出现长程磁序的原因。

Method: 通过分析晶体结构对磁交换路径的影响，揭示Mn子晶格因低对称性被划分为不等价通道，形成孤立的反铁磁六元环，并研究其内外关联的两阶段发展机制。

Result: 发现材料中存在两个分离的热力学温度尺度：高温时六元环内部先建立磁关联，低温时环间耦合尝试建立长程相干但受挫；最终量子基态为磁无序态，具有强环内关联和快速衰减的环间关联。

Conclusion: 晶体学上的不等价性可作为一种材料层面的机制，促使大自旋二维磁体形成分子化且量子无序的磁态。

Abstract: Large-spin two-dimensional magnets are generally expected to develop conventional long-range order once the dominant exchange scale becomes appreciable. The layered spin-$3/2$ maple-leaf compound Na$_2$Mn$_3$O$_7$ defies this expectation: despite sizable antiferromagnetic interactions and no evident disorder, it exhibits no magnetic ordering and displays two well-separated thermodynamic crossover scales. We show that this behavior originates from a crystallography-driven molecularization of the magnetic degrees of freedom. The low-symmetry structure partitions the Mn sublattice into inequivalent exchange pathways, generating a pronounced hierarchy that nearly isolates antiferromagnetic hexagons. Magnetic correlations therefore develop in two stages: first within individual hexagons at a scale set by the dominant exchange, and only at much lower temperatures do frustrated inter-hexagon couplings attempt to establish coherence across the lattice. While isolated hexagons reproduce the two-step thermodynamic structure, the experimentally relevant temperature scales emerge only once the hexagons are embedded in the frustrated two-dimensional network. The resulting quantum ground state is magnetically disordered, characterized by strong intra-hexagon correlations and rapidly decaying inter-hexagon correlations. These results identify crystallographic inequivalence as a materials-level mechanism for stabilizing molecularized and quantum-disordered states even in large-spin two-dimensional magnets.

</details>


### [114] [Mott Intermittency at the Metal-Insulator Boundary](https://arxiv.org/abs/2602.22093)
*Yuxin Wang,Vladimir Dobrosavljević,Jan Jaroszyński,Yohei Saito,Atsushi Kawamoto,Andrej Pustogow,Martin Dressel,Dragana Popović*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The resistivity maximum at a temperature $T=T_{\mathrm{max}}$ is a recurring feature of bandwidth-tuned Mott systems, yet its meaning remains controversial: is it a coherence-incoherence crossover of an electronically homogeneous metal, or does it mark the onset of transport through a mixed landscape of metallic and insulating regions? Even more debated is whether a true phase-coexistence regime survives in the relevant parameter range, or whether apparent inhomogeneity is merely extrinsic. Here we address these questions by moving beyond temperature sweeps and probe charge transport in the time domain. Near $T=T_{\mathrm{max}}$, we find that the resistance of a model system, a quasi-two-dimensional Mott spin liquid material, exhibits clear random-telegraph switching between discrete levels over long timescales. The statistics of the switching - sharp two-level behavior with thermally activated dwell times - point to a mesoscopic "current-controlling" region that dynamically toggles between metallic and insulating states, intermittently opening and closing the dominant conduction channel. This characteristic fluctuating dynamics provides direct evidence for intrinsic metal-insulator coexistence and establishes $T\sim T_{\mathrm{max}}$ as the regime of Mott intermittency, where transport is governed by stochastic domain switching rather than quasiparticle decoherence.

</details>


### [115] [Lowering the temperature of two-dimensional fermionic tensor networks with cluster expansions](https://arxiv.org/abs/2602.22113)
*Sander De Meyer,Atsushi Ueda,Yuchi He,Nick Bultinck,Jutho Haegeman*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Representing the time-evolution operator as a tensor network constitutes a key ingredient in several algorithms for studying quantum lattice systems at finite temperature or in a non-equilibrium setting. For a Hamiltonian composed of strictly short-ranged interactions, the Suzuki-Trotter decomposition is the main technique for obtaining such a representation. In [B.~Vanhecke, L.~Vanderstraeten and F.~Verstraete, Physical Review A, L020402 (2021)], an alternative strategy, the cluster expansion, was introduced. This approach naturally preserves internal and lattice symmetries and can more easily be extended to higher-order representations or longer-ranged interactions. We extend the cluster expansion to two-dimensional fermionic systems, and employ it to construct projected entangled-pair operator (PEPO) approximations of Gibbs states. We also discuss and benchmark different truncation schemes for multiplying layers of PEPOs together. Applying the resulting framework to a two-dimensional spinless fermion model with attractive interactions, we resolve a clear phase boundary at finite temperature.

</details>


### [116] [Chiral Weyl-Kondo semimetals and hexagonal heavy fermion systems](https://arxiv.org/abs/2602.22185)
*Kuan-Sen Lin,Yuan Fang,Henrique Fabrelli,Runhan Li,Andrey Prokofiev,Fang Xie,Jennifer Cano,Maia G. Vergniory,Silke Paschen,Qimiao Si*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Strong correlation, in concert with symmetry and topology, engenders novel gapless phases of matter, though only a tip of the iceberg has been seen. An exemplary framework is provided by Weyl-Kondo semimetals, in which Weyl fermions develop through crystalline symmetry constraints on the emergent low-energy heavy-fermion excitations. This paradigm has opened up new opportunities to explore correlated topologies without a noninteracting counterpart, but fully realizing this potential requires a large base of candidate materials. Here we confront the challenge on both fronts by studying heavy fermion systems with hexagonal space groups. This family contains a large number of chiral nonsymmorphic crystal structures that promote Weyl degeneracies and, in addition, feature geometric frustration in the $f$-electron magnetism. Our calculations for the heavy fermion states identify Weyl-Kondo semimetals with chiral or achiral Weyl nodes in the respective structural classes. We also develop a new search strategy for the difficult case of strongly correlated materials, using a combination of materials database, symmetry classification and experiments, and propose as candidate topological heavy fermion systems the chiral CePt$_2$B and achiral Ce$_2$NiGe$_3$ and Ce$_6$Co$_{2-δ}$Si$_3$. Our findings raise the prospect for strongly correlated metallic topology in the unusual setting of exotic quantum magnetism.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [117] [Generalized Onsager-Regularized Lattice Boltzmann Method for error-free Navier-Stokes models on standard lattices](https://arxiv.org/abs/2602.21242)
*Anirudh Jonnalagadda,Walter Rocchia,Sauro Succi*

Main category: physics.comp-ph

TL;DR: 本文提出了一种新的策略，通过Onsager正则化非平衡态分布来修正格子Boltzmann方法中的Navier-Stokes建模误差，并在D2Q9格子上构建了部分和完全修正的六矩约束引导平衡模型，显著提升了精度与稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决一阶近邻格子Boltzmann方法中Navier-Stokes方程的建模误差问题，特别是兼容性条件违反和应力张量建模误差，以提高模拟的准确性和稳定性。

Method: 引入Onsager正则化（OReg）非平衡态分布进行全局部修正，发展出针对D2Q9格子六矩约束引导平衡（GEq）表示的部分修正和完全修正模型。

Result: 部分修正模型将参考/任意格子温度下的精度提高了两到四个数量级；完全修正模型进一步纠正了应力张量误差，实现了精确建模；数值测试表明新方案相比Lattice-BGK和未修正OReg-GEq方案具有更高的精度和稳定性。

Conclusion: 所提出的OReg修正机制为基于Onsager正则化的热流体动力学扩展提供了有前景的新途径。

Abstract: This work presents a novel strategy to address Navier-Stokes modelling errors arising on first-nearest neighbour lattice Boltzmann (LB) methods and introduces fully local corrections through Onsager-Regularized (OReg) non-equilibrium populations. The proposed mechanism, which admits partially and completely corrected OReg models, is used to develop representative partially and completely corrected models for the six-moment-constrained guided equilibrium (GEq) representation on the D2Q9 lattice. The former realization only addresses compatibility condition violations and improves the accuracy by two/four orders of magnitude at reference/arbitrary lattice temperatures respectively, while the latter additionally corrects stress tensor modelling errors, resulting in a fully corrected exact model. Numerical benchmarks of the corrected schemes demonstrate improved accuracy and stability in comparison to the Lattice-BGK and uncorrected OReg-GEq schemes thus presenting a promising avenue for OReg based thermohydrodynamic extensions.

</details>


### [118] [Efficient and Accurate Method for Separating Variant Components from Invariant Background and Component Model Fusion for Fast RFIC Design Space Exploration](https://arxiv.org/abs/2602.21335)
*Hongyang Liu,Dan Jiao*

Main category: physics.comp-ph

TL;DR: 提出一种快速分离变体组件与不变背景的RFIC设计方法，通过代数分解总场解并重用不变背景的场响应，显著提升设计空间探索的效率和精度。


<details>
  <summary>Details</summary>
Motivation: 在RFIC设计中，传统电磁仿真器需对每个设计变体进行全域仿真，计算成本高。为了提高设计空间探索的效率，需要一种能有效区分并重用不变背景信息的方法。

Method: 通过代数方法将总场解分解为设计相关变体和不变背景的贡献，仅对变体部分进行重复仿真，并开发了一种高效模型复用与融合策略；同时提出快速算法，将大量可能源对应的场解压缩为数量级等于层数的少数场解。

Result: 实现了对不变背景场响应的一次性仿真与重复使用，大幅减少了每次设计变体所需的仿真规模，验证了该方法在RFIC设计空间探索中的准确性、鲁棒性和高效性。

Conclusion: 所提方法能够显著加速RFIC设计中的大规模变体仿真过程，为复杂电路的设计优化提供了高效的电磁建模解决方案。

Abstract: The design of RFIC often involves exploring a large number of design variations in an invariant background composed of the processing stack and unchanged circuit blocks. Conventional electromagnetic solvers require a full-domain simulation for every design variation. In this work, we present a fast method that effectively separates the variant components from the invariant background. It algebraically decomposes the total field solution into the contributions from the design-dependent variations and the invariant background. Hence, the field response due to the invariant background can be simulated once and reused for all design variations. Only the variant components need to be simulated at each design variation, the size of which is small. We also develop an efficient way of reusing the model of each component and fusing them accurately to obtain the model of a system composed of many components. The reduced system of variant components involves computing the field solutions in the invariant background due to all possible sources located at variant components, the number of which can be large. We develop a fast algorithm to reduce them to a few field solutions, the number of which is on the order of the layer number. The proposed method has been applied to RFIC design space exploration. Its accuracy, robustness, and efficiency have been demonstrated.

</details>


### [119] [Emergent Rate Laws for Collective Lying-Standing Transitions](https://arxiv.org/abs/2602.21747)
*Anna Werkovits,Simon B. Hollweger,Oliver T. Hofmann*

Main category: physics.comp-ph

TL;DR: 本研究通过结合第一性原理动力学蒙特卡洛模拟与平均场粗粒化策略，建立了有机-无机界面分子单层躺-立构型转变的吸附质-动力学定量关系，揭示了集体转变速率由多个耦合微观过程共同决定，并提出了几何参数调控转变速率的设计原则。


<details>
  <summary>Details</summary>
Motivation: 理解并预测有机-无机界面第一分子层中躺-立构型转变的集体动力学行为，因其对界面偶极、能级排列和生长模式有重要影响，但现有方法难以准确预测。

Method: 采用基于第一性原理的动力学蒙特卡洛模拟，结合平均场粗粒化策略，研究四氰基乙烯（TCNE）在Cu(111)表面的构型转变；分析再取向、吸附和扩散等微观过程的耦合作用，并引入几何因子描述单分子与集体速率常数之间的偏差。

Result: 发现集体转变速率不能由单一基元步骤推断，而是源于再取向、吸附和扩散的耦合；提出局部两步再取向机制，在扩散增强区域因空位-分子解耦抑制回转而加速转变；集体速率约与分子面积成正比，增大躺立构型的脚印比可显著加速转变；导出了连接微观速率常数与几何参数的集体再取向速率常数解析表达式。

Conclusion: 几何形状是调控有机-无机界面躺-立转变动力学的内在控制参数，所提出的模型和设计原则具有跨动力学区域的适用性，可用于工程化调控界面分子构型转变的时间尺度。

Abstract: Lying-standing transitions in the first molecular monolayer at organic-inorganic interfaces strongly influence interface dipoles, energy-level alignment, and growth modes, yet their collective kinetics remain difficult to predict. Here, we establish a quantitative adsorbate-to-kinetics relationship using first-principles-based kinetic Monte Carlo simulations combined with a mean-field coarse-graining strategy. Focusing on tetracyanoethylene on Cu(111), we show that the collective transition rate cannot be inferred from any single elementary step but emerges from coupled microscopic processes, including reorientation, adsorption, and diffusion. A local two-step reorientation mechanism captures the diffusion-limited regime, while diffusion of lying molecules accelerates the transition in diffusion-enhanced regimes by suppressing back-reorientation via vacancy-molecule decoupling. This effect is described by a regime-dependent geometric factor accounting for deviations between single-molecule and collective rate constants. By varying molecular size and footprint ratio, we demonstrate that geometry is an intrinsic control parameter. While the collective rate scales approximately with molecular area, increasing the footprint ratio between lying and standing configurations yields order-of-magnitude accelerations due to enhanced vacancy creation and diffusion-assisted stabilization. Finally, we derive an analytical expression for the collective reorientation rate constant linking temperature- and pressure-dependent microscopic rate constants to geometric parameters. The formulation reproduces the simulations across kinetic regimes and provides transferable design principles for engineering lying-standing transition timescales at organic-inorganic interfaces.

</details>


### [120] [Phase-Dependent Excitonic Light Harvesting and Photovoltaic Limits in Monolayer Y2TeO2 MOenes](https://arxiv.org/abs/2602.22112)
*Bill D. A. Huacarpuma,Jose A. dos S. Laranjeira,Nicolas F. Martins,Julio R. Sambrano,Kleuton A. L. Lima,Santosh K. Tiwari,Alexandre C. Dias,Luiz A. Ribeiro*

Main category: physics.comp-ph

TL;DR: 研究了单层Y2TeO2 MOenes在1T和2H相中的相依赖电子和激子现象，发现其具有直接带隙和强激子效应，适用于低维氧化硫属化合物中的多体物理研究及光伏应用。


<details>
  <summary>Details</summary>
Motivation: 探索低维MOenes材料中相变对电子结构和激子行为的影响，寻找稳定且具有直接带隙的新型二维材料。

Method: 采用第一性原理理论结合有效的多体框架，计算声子谱、准粒子能带结构，并使用紧束缚Bethe-Salpeter方法计算光学谱。

Result: 1T和2H相均表现出动态和机械稳定性；具有近红外到可见光范围的直接带隙；激子结合能分别为152 meV（1T）和126 meV（2H），1T相因结构更致密而表现出更强的量子限制。

Conclusion: Y2TeO2单层是一种罕见的稳定、直接带隙MOene材料，具有显著的激子效应，为低维oxychalcogenide系统中的多体物理研究和光伏器件应用提供了新平台。

Abstract: We investigate phase-dependent electronic and excitonic phenomena in monolayer Y2TeO2 MOenes in the 1T and 2H polymorphs using first-principles theory and an effective many-body framework. Phonon spectra and elastic stability criteria establish both phases as dynamically and mechanically stable. Quasiparticle band structures reveal direct gaps in the near-infrared to visible range, with gap values increasing systematically from semilocal to hybrid exchange treatments. Optical spectra computed using a tight-binding Bethe-Salpeter approach demonstrate pronounced excitonic resonances arising from reduced dimensionality and weak dielectric screening. The exciton binding energies reach 152 meV in the 1T phase and 126 meV in the 2H phase, reflecting enhanced quantum confinement in the structurally denser phase. Our results identify Y2TeO2monolayers as a rare class of stable, direct-gap MOenes with strong excitonic effects, providing a platform for exploring many-body physics in low-dimensional oxychalcogenide systems especially for photovoltaic applications.

</details>
