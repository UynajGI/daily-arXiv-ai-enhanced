{"id": "2512.03049", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.03049", "abs": "https://arxiv.org/abs/2512.03049", "authors": ["Kirk Roffi"], "title": "State Transition Block Diagram of the Generalized Maxwell Slip Friction Model", "comment": "6 pages, 4 figures", "summary": "Dynamic friction models (DFMs) encode essential information for the simulation and control of systems with friction. Traditionally, DFMs have been published with conceptual block diagrams, promoting clarity and reproducibility in simulation. However, modern DFMs have grown increasingly complex and block diagrams are now rarely presented, limiting accessibility. This letter presents a block diagram representation of the Generalized Maxwell Slip (GMS) friction model, an advanced multi-state DFM capable of simulating a wide range of nonlinear friction phenomena. The diagram can be implemented in the MATLAB-Simulink environment using a Stateflow chart or embedded if-else logic to represent the state transition criteria, but it is not limited to this platform. Closed-loop and open-loop simulations were conducted to verify that the block diagram reproduces non-drifting behavior and stick-slip friction, including benchmarking against the LuGre model. The proposed diagram improves accessibility to advanced dynamic friction models and provides the engineering community with a practical tool for the simulation and control of systems with friction."}
{"id": "2512.03200", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.03200", "abs": "https://arxiv.org/abs/2512.03200", "authors": ["Luis Miguel Osco Vasquez"], "title": "Deteccion de intrusiones en redes mediante algoritmos de aprendizaje automatico: Un estudio multiclase sobre el conjunto de datos NSL-KDD", "comment": "in Spanish language", "summary": "Intrusion detection is a critical component of cybersecurity, responsible for identifying unauthorized access or anomalous behavior in computer networks. This paper presents a comprehensive study on intrusion detection in networks using classical machine learning algorithms applied to the multiclass version of the NSL-KDD dataset (Normal, DoS, Probe, R2L, and U2R classes). The characteristics of NSL-KDD are described in detail, including its variants and class distribution, and the data preprocessing process (cleaning, coding, and normalization) is documented. Four supervised classification models were implemented: Logistic Regression, Decision Tree, Random Forest, and XGBoost, whose performance is evaluated using standard metrics (accuracy, recall, F1 score, confusion matrix, and area under the ROC curve). Experiments show that models based on tree sets (Random Forest and XGBoost) achieve the best performance, with accuracies approaching 99%, significantly outperforming logistic regression and individual decision trees. The ability of each model to detect each attack category is also analyzed, highlighting the challenges in identifying rare attacks (R2L and U2R). Finally, the implications of the results are discussed, comparing them with the state of the art, and potential avenues for future research are proposed, such as the application of class balancing techniques and deep learning models to improve intrusion detection."}
{"id": "2512.03555", "categories": ["cs.CE", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.03555", "abs": "https://arxiv.org/abs/2512.03555", "authors": ["Lucie Kubíčková", "Onřej Gebouský", "Jan Haidl", "Martin Isoz"], "title": "Accelerating shape optimization by deep neural networks with on-the-fly determined architecture", "comment": "Initial submitted manuscript version", "summary": "In component shape optimization, the component properties are often evaluated by computationally expensive simulations. Such optimization becomes unfeasible when it is focused on a global search requiring thousands of simulations to be evaluated. Here, we present a viable global shape optimization methodology based on multi-objective evolutionary algorithms accelerated by deep neural networks (DNNs). Our methodology alternates between evaluating simulations and utilizing the generated data to train DNNs with various architectures. When a suitable DNN architecture is identified, the DNN replaces the simulation in the rest of the global search. Our methodology was tested on five ZDT benchmark functions, showing itself at the level of and sometimes more flexible than other state-of-the-art acceleration approaches. Then, it was applied to a real-life optimization problem, namely the shape optimization of a single-phase ejector. Compared with a non-accelerated methodology, ours was able to save weeks of CPU time in solving this problem. To experimentally confirm the performance of the optimized ejector shapes, four of them were 3D printed and tested on the lab scale confirming the predicted performance. This suggests that our methodology could be used for acceleration of other real-life shape optimization problems."}
{"id": "2512.03839", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.03839", "abs": "https://arxiv.org/abs/2512.03839", "authors": ["Weilian Li", "Jun Zhu", "Saied Pirasteh", "Qing Zhu", "Yukun Guo", "Lan Luo", "Youness Dehbi"], "title": "A 3D virtual geographic environment for flood representation towards risk communication", "comment": null, "summary": "Risk communication seeks to develop a shared understanding of disaster among stakeholders, thereby amplifying public awareness and empowering them to respond more effectively to emergencies. However, existing studies have overemphasized specialized numerical modelling, making the professional output challenging to understand and use by non-research stakeholders. In this context, this article proposes a 3D virtual geographic environment for flood representation towards risk communication, which integrates flood modelling, parallel computation, and 3D representation in a pipeline. Finally, a section of the Rhine River in Bonn, Germany, is selected for experiment analysis. The experimental results show that the proposed approach is capable of flood modelling and 3D representation within a few hours, the parallel speedup ratio reached 6.45. The intuitive flood scene with 3D city models is beneficial for promoting flood risk communication and is particularly helpful for participants without direct experience of floods to understand its spatiotemporal process. It also can be embedded in the Geospatial Infrastructure Management Ecosystem (GeoIME) cloud application for intelligent flood systems."}
{"id": "2512.03728", "categories": ["cs.ET", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03728", "abs": "https://arxiv.org/abs/2512.03728", "authors": ["Pradnya Taksande", "Shwetha Kiran", "Pranav Jha", "Prasanna Chaporkar"], "title": "AI/ML in 3GPP 5G Advanced - Services and Architecture", "comment": null, "summary": "The 3rd Generation Partnership Project (3GPP), the standards body for mobile networks, is in the final phase of Release 19 standardization and is beginning Release 20. Artificial Intelligence/ Machine Learning (AI/ML) has brought about a paradigm shift in technology and it is being adopted across industries and verticals. 3GPP has been integrating AI/ML into the 5G advanced system since Release 18. This paper focuses on the AI/ML related technological advancements and features introduced in Release 19 within the Service and System Aspects (SA) Technical specifications group of 3GPP. The advancements relate to two paradigms: (i) enhancements that AI/ML brought to the 5G advanced system (AI for network), e.g. resource optimization, and (ii) enhancements that were made to the 5G system to support AI/ML applications (Network for AI), e.g. image recognition."}
{"id": "2512.03600", "categories": ["nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.03600", "abs": "https://arxiv.org/abs/2512.03600", "authors": ["Akshay S Harish", "Gaurav Dar"], "title": "Explosive synchronization in networks of Type-I neurons with electrical synapses", "comment": "7 pages, 6 figures", "summary": "Explosive synchronization (ES), which was observed in the scale-free network of the Kuramoto model, has been studied widely in the oscillator model. However, investigations of ES in neuronal networks, in spite of their importance in neuroscience, are limited and restricted to specific models. In this work, we explore the nature of the transition to synchronization in a class of neurons, namely Type-I neurons. Leveraging the mapping between Type-I neurons and the Kuramoto model, we investigate whether the conditions known to induce ES in the Kuramoto model also do so in Type-I neurons. The neurons are coupled through electrical synapses and placed on a scale-free and star networks with complete and partial degree-frequency correlation conditions. Our simulations show ES in networks of Quadratic Integrate and Fire (QIF) neurons, the normal form of Type-I neurons, under weak heterogeneity. We further confirm this phenomenon in networks of Morris-Lecar neurons, in the regime of Type-I excitability, under similar conditions to the QIF neurons. Thus, this work establishes a set of universal conditions that allows ES to arise in Type-I neurons."}
{"id": "2512.04070", "categories": ["hep-lat", "hep-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.04070", "abs": "https://arxiv.org/abs/2512.04070", "authors": ["V. Braguta", "M. Chernodub", "E. Eremeev", "I. Kudrov", "A. Roenko", "D. Sychev"], "title": "On the angular momentum and free energy of rotating gluon plasma", "comment": "9 pages, 3 figures, Proceedings of the XXVIth International Baldin Seminar on High Energy Physics Problems \"Relativistic Nuclear Physics and Quantum Chromodynamics\", 15-20 September 2025, Dubna, Russia", "summary": "We study the free energy and the angular momentum of rotating hot gluon matter using first-principle numerical simulations of the $\\textrm{SU}(3)$ lattice Yang-Mills theory. We calculate the specific moment of inertia and the specific deformation of the gluon matter as, respectively, the leading and next-to-leading terms in a series in angular velocity over a broad range of temperatures and various spatial boundary conditions. We show that the specific deformation, similarly to the moment of inertia, takes negative values in a phenomenologically interesting region of temperatures above the phase transition and turns positive at higher temperatures."}
{"id": "2512.03149", "categories": ["physics.comp-ph", "cond-mat.dis-nn", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03149", "abs": "https://arxiv.org/abs/2512.03149", "authors": ["Jinjing Yi", "Daniel Massatt", "Andrew Horning", "Mitchell Luskin", "J. H. Pixley", "Jason Kaye"], "title": "A high-order regularized delta-Chebyshev method for computing spectral densities", "comment": null, "summary": "We introduce a numerical method for computing spectral densities, and apply it to the evaluation of the local density of states (LDOS) of sparse Hamiltonians derived from tight-binding models. The approach, which we call the high-order delta-Chebyshev method, can be viewed as a variant of the popular regularized Chebyshev kernel polynomial method (KPM), but it uses a high-order accurate approximation of the $δ$-function to achieve rapid convergence to the thermodynamic limit for smooth spectral densities. The costly computational steps are identical to those for KPM, with high-order accuracy achieved by an inexpensive post-processing procedure. We apply the algorithm to tight-binding models of graphene and twisted bilayer graphene, demonstrating high-order convergence to the LDOS at non-singular points."}
{"id": "2512.03137", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.03137", "abs": "https://arxiv.org/abs/2512.03137", "authors": ["Penghao Zhu", "Archisman Panigrahi", "Leonid Levitov", "Nandini Trivedi"], "title": "Strain Response as a Probe of Spinons in Quantum Spin Liquids", "comment": "8+7 pages,5+3 figures", "summary": "Quantum spin liquids (QSLs) host emergent, fractionalized fermionic excitations that are charge-neutral. Identifying clear experimental signatures of these excitations remains a central challenge in the field of strongly correlated systems, as they do not couple to conventional electromagnetic probes. Here, we propose lattice strain as a powerful and tunable probe: Mechanical deformation of the lattice generates large pseudomagnetic fields, inducing pseudo-Landau levels that serve as distinctive spectroscopic signatures of these excitations. Using the Kitaev model on the honeycomb lattice, we show that distinct QSL phases exhibit strikingly different strain responses. The semimetallic Kitaev spin liquid and the gapped chiral spin liquid display pronounced Landau quantization and a diamagnetic-like response to strain, whereas the Majorana metal phase shows a paramagnetic-like response without forming Landau levels. These contrasting behaviors provide a direct route to experimentally identifying and distinguishing QSL phases hosting fractionalized excitations. We further outline how local resonant ultrasound spectroscopy can detect the strain-induced resonances associated with these responses, offering a practical pathway towards identifying fractionalized excitations in candidate materials."}
{"id": "2512.03113", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03113", "abs": "https://arxiv.org/abs/2512.03113", "authors": ["Zhenglong Chen", "Zhao Zhang", "Xia Yan", "Jiayu Zhai", "Piyang Liu", "Kai Zhang"], "title": "A Discrete Neural Operator with Adaptive Sampling for Surrogate Modeling of Parametric Transient Darcy Flows in Porous Media", "comment": null, "summary": "This study proposes a new discrete neural operator for surrogate modeling of transient Darcy flow fields in heterogeneous porous media with random parameters. The new method integrates temporal encoding, operator learning and UNet to approximate the mapping between vector spaces of random parameter and spatiotemporal flow fields. The new discrete neural operator can achieve higher prediction accuracy than the SOTA attention-residual-UNet structure. Derived from the finite volume method, the transmissibility matrices rather than permeability is adopted as the inputs of surrogates to enhance the prediction accuracy further. To increase sampling efficiency, a generative latent space adaptive sampling method is developed employing the Gaussian mixture model for density estimation of generalization error. Validation is conducted on test cases of 2D/3D single- and two-phase Darcy flow field prediction. Results reveal consistent enhancement in prediction accuracy given limited training set."}
{"id": "2512.03061", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.03061", "abs": "https://arxiv.org/abs/2512.03061", "authors": ["Paulina Kaczyńska", "Julian Sienkiewicz", "Dominik Ślęzak"], "title": "Accumulated Local Effects and Graph Neural Networks for link prediction", "comment": null, "summary": "We investigate how Accumulated Local Effects (ALE), a model-agnostic explanation method, can be adapted to visualize the influence of node feature values in link prediction tasks using Graph Neural Networks (GNNs), specifically Graph Convolutional Networks and Graph Attention Networks. A key challenge addressed in this work is the complex interactions of nodes during message passing within GNN layers, complicating the direct application of ALE. Since a straightforward solution of modifying only one node at once substantially increases computation time, we propose an approximate method that mitigates this challenge. Our findings reveal that although the approximate method offers computational efficiency, the exact method yields more stable explanations, particularly when smaller data subsets are used. However, the explanations produced with the approximate method are not significantly different from the ones obtained with the exact method. Additionally, we analyze how varying parameters affect the accuracy of ALE estimation for both approaches."}
{"id": "2512.03770", "categories": ["physics.soc-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03770", "abs": "https://arxiv.org/abs/2512.03770", "authors": ["Xingyu Guo", "Xiaoyang Wang", "Lingxiao Wang"], "title": "Quantum Simulations of Opinion Dynamics", "comment": "9 pages, 12 figures, comments are welcome", "summary": "Quantum computing offers powerful new approaches for modeling complex social phenomena. Here, we propose and demonstrate quantum simulations of opinion dynamics, leveraging quantum superposition, measurement-induced state collapse, and entanglement to model realistic psychological and social processes. Specifically, we develop quantum models of opinion dynamics, solving exactly and simulating on IBM Quantum hardware. Our results, based on quantum devices and validated with practical quantum circuits, illustrate how quantum effects can enhance understanding of consensus formation, polarization, and collective decision-making. These findings pave the way for further exploration into quantum-enhanced social modeling, highlighting the potential of near-term quantum computers for simulating collective behavior in complex systems."}
{"id": "2512.03524", "categories": ["math.OC", "cs.ET", "cs.MA", "econ.TH", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03524", "abs": "https://arxiv.org/abs/2512.03524", "authors": ["Grzegorz Jamróz", "Rafał Kucharski", "David Watling"], "title": "Market share maximizing strategies of CAV fleet operators may cause chaos in our cities", "comment": "34 pages, 9 figures", "summary": "We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities."}
{"id": "2512.03395", "categories": ["cond-mat.stat-mech", "hep-lat"], "pdf": "https://arxiv.org/pdf/2512.03395", "abs": "https://arxiv.org/abs/2512.03395", "authors": ["Satoshi Morita", "Naoki Kawashima"], "title": "Tensor renormalization group calculations of partition-function ratios", "comment": "9 pages, 7 figures", "summary": "The behavior of dimensionless quantities defined as ratios of partition functions is analyzed to investigate phase transitions and critical phenomena. At criticality, the universal values of these ratios can be predicted from conformal field theory (CFT) through the modular-invariant partition functions on a torus. We perform numerical calculations using the bond-weighted tensor renormalization group for three two-dimensional models belonging to different universality classes: the Ising model, the three-state Potts model, and the four-state Potts model. The partition-function ratios obey the same finite-size scaling form as the Binder parameter, and their critical values agree well with the universal values predicted by CFT. In the four-state Potts model, we observe logarithmic corrections in the system-size dependence of these ratios."}
{"id": "2512.03706", "categories": ["physics.comp-ph", "cs.LG", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.03706", "abs": "https://arxiv.org/abs/2512.03706", "authors": ["Vahid Nateghi", "Lara Neureither", "Selma Moqvist", "Carsten Hartmann", "Simon Olsson", "Feliks Nüske"], "title": "Consistent Projection of Langevin Dynamics: Preserving Thermodynamics and Kinetics in Coarse-Grained Models", "comment": null, "summary": "Coarse graining (CG) is an important task for efficient modeling and simulation of complex multi-scale systems, such as the conformational dynamics of biomolecules. This work presents a projection-based coarse-graining formalism for general underdamped Langevin dynamics. Following the Zwanzig projection approach, we derive a closed-form expression for the coarse grained dynamics. In addition, we show how the generator Extended Dynamic Mode Decomposition (gEDMD) method, which was developed in the context of Koopman operator methods, can be used to model the CG dynamics and evaluate its kinetic properties, such as transition timescales. Finally, we combine our approach with thermodynamic interpolation (TI), a generative approach to transform samples between thermodynamic conditions, to extend the scope of the approach across thermodynamic states without repeated numerical simulations. Using a two-dimensional model system, we demonstrate that the proposed method allows to accurately capture the thermodynamic and kinetic properties of the full-space model."}
{"id": "2512.03147", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03147", "abs": "https://arxiv.org/abs/2512.03147", "authors": ["Aleksandar Razpopov", "Shirin Mozaffari", "Takahiro Matsuoka", "Matthew Cothrine", "Nan Huang", "Roser Valentí", "David Mandrus"], "title": "$α$-RuCl$_3$ intercalated into graphite: a new three-dimensional platform for exotic quantum phases", "comment": "14 pages, 10 figures, including supplementary information", "summary": "Multilayer graphene with different stacking sequences has emerged as a powerful setting for correlated and topological phases. In parallel, progress in graphene heterostructures with magnetic or correlated materials-most notably the Kitaev candidate $α$-RuCl$_3$-has demonstrated charge transfer, magnetic proximity effects, and interfacial reconstruction, creating new opportunities for engineered quantum systems. Motivated by these developments, we explore a three-dimensional analogue in which $α$-RuCl$_3$ layers are inserted directly into the van der Waals gaps of graphite, forming an intercalated system. Here, we report the successful synthesis and comprehensive characterization of graphite intercalated with $α$-RuCl$_3$. Using a combination of X-ray diffraction, quantum oscillation measurements, and first-principles electronic structure calculations, we study the structural and electronic properties of these intercalated crystals. Our results demonstrate that graphite intercalated with $α$-RuCl$_3$ offers a robust route to develop three-dimensional materials with access to novel correlated and topological states."}
{"id": "2512.03330", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.03330", "abs": "https://arxiv.org/abs/2512.03330", "authors": ["Juan Antonio Rojas-Quintero", "François Dubois", "Frédéric Jourdan"], "title": "Simpson variational integrator for nonlinear systems: a tutorial on the Lagrange top", "comment": "22 pages, 14 figures, 6 tables, journal submission", "summary": "This contribution presents an integration method based on the Simpson quadrature. The integrator is designed for finite-dimensional nonlinear mechanical systems that derive from variational principles. The action is discretized using quadratic finite elements interpolation of the state and Simpson's quadrature, leading to discrete motion equations. The scheme is implicit, symplectic, and fourth-order accurate. The proposed integrator is compared with the implicit midpoint variational integrator on two examples of systems with inseparable Hamiltonians. First, the example of the nonlinear double pendulum illustrates how the method can be applied to multibody systems. The analytical solution of the Lagrange top is then used as a reference to analyze accuracy, convergence, and precision of the numerical method. A reduced Lagrange top system is also proposed and solved with a classical fourth-order method. Its solution is compared with the Simpson solution of the complete system, and the convergence order of the difference between both is consistent with the order of the classical method."}
{"id": "2512.03063", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2512.03063", "abs": "https://arxiv.org/abs/2512.03063", "authors": ["Ehsaneddin Jalilian", "Bernd Resch"], "title": "Unsupervised Multimodal Graph-based Model for Geo-social Analysis", "comment": null, "summary": "The systematic analysis of user-generated social media content, especially when enriched with geospatial context, plays a vital role in domains such as disaster management and public opinion monitoring. Although multimodal approaches have made significant progress, most existing models remain fragmented, processing each modality separately rather than integrating them into a unified end-to-end model. To address this, we propose an unsupervised, multimodal graph-based methodology that jointly embeds semantic and geographic information into a shared representation space. The proposed methodology comprises two architectural paradigms: a mono graph (MonoGrah) model that jointly encodes both modalities, and a multi graph (MultiGraph) model that separately models semantic and geographic relationships and subsequently integrates them through multi-head attention mechanisms. A composite loss, combining contrastive, coherence, and alignment objectives, guides the learning process to produce semantically coherent and spatially compact clusters. Experiments on four real-world disaster datasets demonstrate that our models consistently outperform existing baselines in topic quality, spatial coherence, and interpretability. Inherently domain-independent, the framework can be readily extended to diverse forms of multimodal data and a wide range of downstream analysis tasks."}
{"id": "2512.03980", "categories": ["physics.soc-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03980", "abs": "https://arxiv.org/abs/2512.03980", "authors": ["Pak Shen Choong", "Nurisya Mohd Shah", "Yung Szen Yap"], "title": "Quantum Diplomacy within the Southeast Asia Quantum Ecosystem", "comment": "Comments are welcomed!", "summary": "Amid the International Year of Quantum Science and Technology 2025 (IYQ 2025), a significant portion of global funding has been dedicated to various quantum initiatives, with over 30 countries announcing their respective quantum strategies. Within the Southeast Asia context, Singapore, Thailand, and the Philippines have launched their respective quantum strategies and roadmaps. Meanwhile, six out of eleven Southeast Asia countries have expressed interest in formulating a regional quantum ecosystem to pursue a set of common goals. Quantum technologies, though still in their infancy within the second quantum revolution, have advanced rapidly in recent years. Due to their dual-use nature, quantum technologies are considered emerging and disruptive, often raising concerns from the cybersecurity perspective. While several discussions regarding Malaysia's quantum initiative and strategy are ongoing, it is vital to broaden the conversation and position Malaysia within the regional ecosystem. This paper provides an overview of Malaysia's quantum landscape and a summary of the regional initiatives since the establishment of Southeast Asia Quantum Network. We then analyse Malaysia's strengths in quantum research and provide four recommendations to strengthen the regional ecosystem."}
{"id": "2512.03051", "categories": ["physics.ao-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.03051", "abs": "https://arxiv.org/abs/2512.03051", "authors": ["Benjamin A. Storer", "Mehrnoush Kharghani", "Alistair Adcroft", "Hussein Aluie"], "title": "Harmonic Extension for Multiscale Analysis and Modeling Near Boundaries, with an Ocean Application", "comment": "19 pages, 5 figures", "summary": "Treatment of fields near domain boundaries is a long-standing problem in signal processing that has come into renewed focus following recent efforts in convolution-based multiscale coarse-graining and in machine-learned parameterizations due to ocean boundary artifacts. Here, we propose a general method for extending fields beyond the domain boundaries by solving a Laplace boundary-value problem. Construction of the harmonic extension is well-posed, including uniqueness, and is consistent with the boundary conditions by design. The formulation applies to irregular boundaries such as discretized coastlines. The harmonic extension is physically desirable since it has minimum spatial variability among all admissible extensions satisfying the boundary conditions. The method is simple to implement using well-established numerical approaches, and is broadly applicable to extending oceanic variables over land boundaries. Other applications include machine learning parametrization and subgrid modeling of wall-bounded flows and multiphase flows. We demonstrate the method by extending sea-surface temperature (SST) over land using fixed temperature (Dirichlet) and no-flux (Neumann) boundary conditions: the land-filled solution is smooth with SST values between the coastal minimum and maximum."}
{"id": "2512.03403", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2512.03403", "abs": "https://arxiv.org/abs/2512.03403", "authors": ["E. N. Bulgakov", "K. N. Pichugin", "D. N. Maksimov"], "title": "Transient chaos and Rayleigh particle escape out of a time modulated optical trap", "comment": null, "summary": "We consider Rayleigh particles in a periodically modulated optical trap formed by two counter-propagating Gaussian beams. It is shown that for certain values of parameters the system exhibits transient chaos which manifests itself in particle acceleration and subsequent directional ejection out of the trap. The escape flights are terminated at the distance of hundreds wavelengths from the trap centrum and the particles return to the trap under the action of the Stokes force. The particle escape is shown to be a threshold effect that can be potentially employed for particle sorting."}
{"id": "2512.03283", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03283", "abs": "https://arxiv.org/abs/2512.03283", "authors": ["Ali Tozar"], "title": "Symmetry-Protected Bipolar Skin Effect and its Topological Breakdown in Disordered Non-Hermitian Systems", "comment": "7 Pages, 8 figures", "summary": "The interplay between non-Hermitian topology and disorder remains a central puzzle in open quantum systems. While the non-Hermitian skin effect (NHSE) is known to be robust against weak perturbations, its fate under strong disorder, particularly in the presence of spin-orbit coupling (SOC), is not fully understood. Here, we uncover a Z_2 topological bipolar skin effect in a non-Hermitian Rashba chain, where spin-up and spin-down eigenstates localize at opposite boundaries. By strictly computing the Lyapunov exponents and introducing a biorthogonal spin-separation index, we map the global phase diagram and reveal a hierarchical breakdown of topology. We demonstrate that the Z_2 skin effect is protected against moderate disorder but collapses into a trivial skin phase before the ultimate onset of Anderson localization. Our results establish a distinct regime of disorder-robust topological non-reciprocity, distinguishable from both the trivial bulk limit and the Anderson localized phase."}
{"id": "2512.03325", "categories": ["math.ST", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03325", "abs": "https://arxiv.org/abs/2512.03325", "authors": ["Garrett G. Wen", "Hong Hu", "Yue M. Lu", "Zhou Fan", "Theodor Misiakiewicz"], "title": "When does Gaussian equivalence fail and how to fix it: Non-universal behavior of random features with quadratic scaling", "comment": null, "summary": "A major effort in modern high-dimensional statistics has been devoted to the analysis of linear predictors trained on nonlinear feature embeddings via empirical risk minimization (ERM). Gaussian equivalence theory (GET) has emerged as a powerful universality principle in this context: it states that the behavior of high-dimensional, complex features can be captured by Gaussian surrogates, which are more amenable to analysis. Despite its remarkable successes, numerical experiments show that this equivalence can fail even for simple embeddings -- such as polynomial maps -- under general scaling regimes.\n  We investigate this breakdown in the setting of random feature (RF) models in the quadratic scaling regime, where both the number of features and the sample size grow quadratically with the data dimension. We show that when the target function depends on a low-dimensional projection of the data, such as generalized linear models, GET yields incorrect predictions. To capture the correct asymptotics, we introduce a Conditional Gaussian Equivalent (CGE) model, which can be viewed as appending a low-dimensional non-Gaussian component to an otherwise high-dimensional Gaussian model. This hybrid model retains the tractability of the Gaussian framework and accurately describes RF models in the quadratic scaling regime. We derive sharp asymptotics for the training and test errors in this setting, which continue to agree with numerical simulations even when GET fails.\n  Our analysis combines general results on CLT for Wiener chaos expansions and a careful two-phase Lindeberg swapping argument. Beyond RF models and quadratic scaling, our work hints at a rich landscape of universality phenomena in high-dimensional ERM."}
{"id": "2512.03685", "categories": ["quant-ph", "cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.03685", "abs": "https://arxiv.org/abs/2512.03685", "authors": ["Seng W. Loke"], "title": "Distributed Quantum Computing with Fan-Out Operations and Qudits: the Case of Distributed Global Gates (a Preliminary Study)", "comment": "8 pages, 10 figures; preliminary version (if mistakes found - please contact the author)", "summary": "Much recent work on distributed quantum computing have focused on the use of entangled pairs and distributed two qubit gates. But there has also been work on efficient schemes for achieving multipartite entanglement between nodes in a single shot, removing the need to generate multipartite entangled states using many entangled pairs. This paper looks at how multipartite entanglement resources (e.g., GHZ states) can be useful for distributed fan-out operations; we also consider the use of qudits of dimension four for distributed quantum circuit compression. In particular, we consider how such fan-out operations and qudits can be used to implement circuits which are challenging for distributed quantum computation, involving pairwise qubit interactions, i.e., what has been called global gates (a.k.a. global Mølmer-Sørensen gates). Such gates have been explored to possibly yield more efficient computations via reduced circuit depth, and can be carried out efficiently in some types of quantum hardware (e.g., trapped-ion quantum computers); we consider this as an exploration of an ``extreme'' case for distribution given the global qubit-qubit interactions. We also conclude with some implications for future work on quantum circuit compilation and quantum data centre design."}
{"id": "2512.03858", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.03858", "abs": "https://arxiv.org/abs/2512.03858", "authors": ["Cael Warner"], "title": "Comparing time and frequency domain numerical methods with Born-Rytov approximations for far-field electromagnetic scattering from single biological cells", "comment": "18 pages (main), 13 figures (main), 6 pages (supp), 1 figure (supp), 3 pages (references)", "summary": "The Born-Rytov approximation estimates effective refractive index of biological cells from measurements of scattered light intensity, polarization and phase. Effective refractive index is useful for estimating a biological cell's dry mass, volume, and internal morphology directly from its elastic light scattering pattern. This work compares the Born-Rytov approximation with analytical, Yee-lattice finite-difference time-domain, and discrete-dipole approximations to Maxwell's equations in the cases of electromagnetic scattering from a sphere and a tomographic reconstruction of Saccharomyces cerevisiae. Practical advantages and limitations of each numerical method are compared for modeling electromagnetic scattering of both near-field intensity and the far-field projected intensity, in terms of accuracy, memory, and compute time. When compared with a commercial software implementation of the Yee-lattice finite-difference time domain method, the Born-Rytov scattering approximation and discrete dipole approximation show better agreement with the far-field light scattering pattern from Saccharomyces cerevisiae."}
{"id": "2512.03148", "categories": ["cond-mat.str-el", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.03148", "abs": "https://arxiv.org/abs/2512.03148", "authors": ["Yuting Bai", "Philip W. Phillips"], "title": "Proof that Momentum Mixing Hatsugai Kohmoto equals the Twisted Hubbard Model", "comment": null, "summary": "We prove formally that the momentum-mixing Hatsugai-Kohmoto model (MMHK) is the Hubbard model with a twist. With this result in tow, we rely on the proof of Watanabe's that two models which differ by a twist must have the same bulk physics. Consequently, we have proven that MMHK=Hubbard in the charge sector."}
{"id": "2512.03452", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.03452", "abs": "https://arxiv.org/abs/2512.03452", "authors": ["Jingyuan Hu", "Zhongjian Wang", "Jack Xin", "Zhiwen Zhang"], "title": "A fast stochastic interacting particle-field method for 3D parabolic parabolic Chemotaxis systems: numerical algorithms and error analysis", "comment": "35 pages, 35 figures", "summary": "In this paper, we develop a novel numerical framework, the stochastic interacting particle-field method with particle-in-cell acceleration (SIPF-PIC), for the efficient simulation of the three-dimensional (3D) parabolic-parabolic Keller-Segel (KS) systems. The SIPF-PIC method integrates Lagrangian particle dynamics with spectral field solvers, by leveraging localized particle-grid interpolations and fast Fourier transform (FFT) techniques. For $P$ particles and $H$ Fourier modes per spatial dimension, the SIPF-PIC method achieves a computational complexity of $\\mathcal{O}(P + H^3 \\log H)$ per time step, a significant improvement over the original SIPF method (proposed in \\cite{SIPF1}), which has a complexity of $\\mathcal{O}(PH^3)$, while preserving numerical accuracy. Moreover, we establish a rigorous error analysis, proving that the discretization errors are of order $\\mathcal{O}(H^{-16/13}+P^{-1/2}H^{4/13})$. Finally, we present numerical experiments to validate the theoretical convergence rates and demonstrate the computational efficiency of our new method. Notably, these experiments also show that the method captures complex blowup dynamics beyond single-point collapse, including ring-type singularities, where mass dynamically concentrates into evolving annular structures."}
{"id": "2512.03064", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2512.03064", "abs": "https://arxiv.org/abs/2512.03064", "authors": ["Hao Yang", "Angela Yao", "Eric Chang", "Hexiang Wang"], "title": "Demographic Inference from Social Media Data with Multimodal Foundation Models: Strategies, Evaluation, and Benchmarking", "comment": "21 pages, 10 figures and 4 tables", "summary": "Demographic inference plays a crucial role in understanding the representativeness and equity of social media-based research. However, existing methods typically rely on a single modality, such as text, image, or network, and are limited to predicting one or two demographic attributes, constraining their generalizability and robustness across populations. This study leverages GPT-5, a state-of-the-art multimodal foundation model, to infer age, gender, and race from social media profiles. Using a dataset of 263 publicly available X (formerly Twitter) users, we design a progressive multimodal framework that incrementally incorporates usernames, profile descriptions, tweets, and profile images to examine how each information source contributes to inference accuracy. Results show a consistent improvement across all conditions, with the inclusion of textual and visual cues substantially enhancing performance. GPT-5 achieves an overall accuracy of 0.90 for age, 0.98 for gender, and 0.85 for race, outperforming existing models under equivalent inputs. These findings demonstrate the potential of large multimodal foundation models to capture complex, cross-modal demographic cues with minimal task-specific training. The study further highlights a transparent, interpretable approach to multimodal reasoning that advances the accuracy, fairness, and scalability of demographic inference in social data analytics."}
{"id": "2512.04073", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.04073", "abs": "https://arxiv.org/abs/2512.04073", "authors": ["Raphael Korbmacher", "Parthib Khound", "Antoine Tordeux", "Frank Gronwald"], "title": "Noise-induced stop-and-go traffic dynamics: Modelling and control", "comment": "19 pages, 8 figures", "summary": "This contribution investigates an original stochastic approach for the emergence of stop-and-go waves in traffic flow, a collective phenomenon with significant safety and environmental implications. Using a stable nonlinear car-following model, the study shows that minimal white Gaussian noise can destabilise the flow, leading to a phase transition from laminar to periodic dynamics through a nonlinear instability phenomenon, analogous to Kapitza's pendulum. Furthermore, a simple linear transformation of the model, which amplifies the response and introduces a positive acceleration bias, counteracts noise-induced effects and recovers the stability of uniform solutions. The findings are supported by simulations, offering new insights into the modelling and mitigation of oscillatory traffic dynamics."}
{"id": "2512.03066", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2512.03066", "abs": "https://arxiv.org/abs/2512.03066", "authors": ["Yiguo Zhang"], "title": "The Iris Illusion in the Tropical Sky Seen Through Two Decades of Aura MLS Ice Water Contents", "comment": null, "summary": "I analyzed ice water content (IWC) data from the Aura Microwave Limb Sounder (MLS) and sea surface temperature (SST) data from NOAA's Optimum Interpolation SST (OISST) product from 2004 to 2024. Using these data, I derived monthly infrared (IR) leakage over the tropics and computed derivatives of both the IR leakage and tropical SST time series from 2005 to 2023. These two derivatives produced a Pearson correlation of -0.49, indicating that IR leakage decreases when SST increases. This behavior contradicts the trend predicted by the Iris hypothesis, suggesting that tropical cirrus clouds strengthen, rather than weaken, as the ocean warms."}
{"id": "2512.03871", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2512.03871", "abs": "https://arxiv.org/abs/2512.03871", "authors": ["Zheng Sun", "Wenkong Wang", "Zizhong Wei", "Xin Ma"], "title": "Adaptive Parameter Control Using AAN for Lower Limb Rehabilitation Exoskeletons", "comment": "6 pages, 7 figures, 2 tables. Proceedings of the 44th Chinese Control Conference, July 28-30, 2025, Chongqing, China", "summary": "Exoskeletons play a crucial role in assisting patients with varying mobility levels during rehabilitation. However, existing control strategies face challenges such as imprecise trajectory tracking, interaction torque oscillations, and limited adaptability to diverse patient conditions. To address these issues, this paper proposes an assist-as-needed (AAN) control algorithm that integrates a human-robot coupling dynamics model, a human torque-momentum observer (HTMO), and an adaptive parameter controller (APC). The algorithm first employs inverse dynamics to compute the joint torques required for the rehabilitation trajectory. The HTMO then estimates the torque exerted by the patient's joints and determines the torque error, which the exoskeleton compensates for via a spring-damper system, ultimately generating the target trajectory. Finally, the APC ensures adaptive assistive control. The proposed method is validated for its effectiveness in MATLAB/Simulink."}
{"id": "2512.03526", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03526", "abs": "https://arxiv.org/abs/2512.03526", "authors": ["G. -X. Tang", "J. -Z. Zhuang", "L. -M. Duan", "Y. -K. Wu"], "title": "Stretched Exponential Scaling of Parity-Restricted Energy Gaps in a Random Transverse-Field Ising Model", "comment": "14 pages, 3 figures", "summary": "The success of a quantum annealing algorithm requires a polynomial scaling of the energy gap. Recently it was shown that a two-dimensional transverse-field Ising model on a square lattice with nearest-neighbor $\\pm J$ random coupling has a polynomial energy gap in the symmetric subspace of the parity operator [Nature 631, 749-754 (2024)], indicating the efficient preparation of its ground states by quantum annealing. However, it is not clear if this result can be generalized to other spin glass models with continuous or biased randomness. Here we prove that under general independent and identical distributions (i.i.d.) of the exchange energies, the energy gap of a one-dimensional random transverse-field Ising model follows a stretched exponential scaling even in the parity-restricted subspace. We discuss the implication of this result to quantum annealing problems."}
{"id": "2512.03266", "categories": ["stat.ME", "math.ST", "stat.OT"], "pdf": "https://arxiv.org/pdf/2512.03266", "abs": "https://arxiv.org/abs/2512.03266", "authors": ["Merlise A Clyde"], "title": "Invited Discussion of \"Model Uncertainty and Missing Data: An Objective Bayesian Perspective\" by Gonzalo García-Donato , María Eugenia Castellanos , Stefano Cabras Alicia Quirós , and Anabel Forte", "comment": null, "summary": "The article by Garc{í}a-Donato and co-authors addresses the dual challenges of accounting for model uncertainty and missing data within the Gaussian regression frameworks from an objective Bayesian perspective. Thru the use of an imputation $g$-prior that replaces $X_γ^TX_γ$ for model $γ$ in the covariance of $β_γ$ with $Σ_{X_γ}$, the authors develop a coherent approach to addressing the missing data problem and model uncertainty simultaneously with random $X_γ$ in the missing at random (MAR) or missing completely at random (MCAR) settings, while still being computationally tractable. I discuss the connection of the imputation $g$-prior to the $g$-prior with imputed $X$, and to model selection for graphical models that provide an alternative justification for the $g$-prior for random $X$s."}
{"id": "2512.03559", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.03559", "abs": "https://arxiv.org/abs/2512.03559", "authors": ["Dye SK Sato", "Takane Hori", "Takeshi Iinuma", "Masayuki Kano", "Yusuke Tanaka"], "title": "Postseismicity of slow-slip doublets discerned on the outermost of the Nankai Trough subduction megathrust", "comment": "33 pages, 4 figures,", "summary": "Despite dissimilar slip rates, slow earthquakes are faulting as ordinary earthquakes are. It is therefore physically natural that slow earthquakes also cause postseismic motions similarly to ordinary earthquakes, even though coseismic and postseismic slips remain undifferentiated for slow earthquakes. We pursue the slow-earthquake postseismicity based on the analysis of a fault slip beneath the Bungo Channel, the westernmost region of the Nankai Trough subduction zone in southwestern Japan. Its 2010 long-term slow slip event (SSE) was mispredicted by physics-based models, which concludes that the initial acceleration of this SSE was too abrupt for a slow variant of a fault rupture. We identify that a mispredicted GNSS signal evolves logarithmically in time, preceded by minor signals that evolve exponentially, lasting about two years west and about half a year east. By performing sparse inverse modeling on the GNSS, we have estimated that exponential slips occur at the same depth, bracketing a logarithmic slip that occurs beneath the channel. The regions of exponential slips match repeating slow-slip regions, and deep tremors synchronize exclusively with the logarithmic slip. This source complexity can be explained as a neighboring rupture doublet and its afterslip and aftershocks by the known mechanics of ordinary earthquakes. If slow earthquakes have a dual origin in exponentially nucleating slow rupture and logarithmically decelerating postseismic creep, it is possible to pick the slow earthquake nuclei that could accelerate into megathrust catastrophes."}
{"id": "2512.03974", "categories": ["physics.comp-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03974", "abs": "https://arxiv.org/abs/2512.03974", "authors": ["Paul Fuchs", "Julija Zavadlav"], "title": "Refining Machine Learning Potentials through Thermodynamic Theory of Phase Transitions", "comment": null, "summary": "Foundational Machine Learning Potentials can resolve the accuracy and transferability limitations of classical force fields. They enable microscopic insights into material behavior through Molecular Dynamics simulations, which can crucially expedite material design and discovery. However, insufficiently broad and systematically biased reference data affect the predictive quality of the learned models. Often, these models exhibit significant deviations from experimentally observed phase transition temperatures, in the order of several hundred kelvins. Thus, fine-tuning is necessary to achieve adequate accuracy in many practical problems. This work proposes a fine-tuning strategy via top-down learning, directly correcting the wrongly predicted transition temperatures to match the experimental reference data. Our approach leverages the Differentiable Trajectory Reweighting algorithm to minimize the free energy differences between phases at the experimental target pressures and temperatures. We demonstrate that our approach can accurately correct the phase diagram of pure Titanium in a pressure range of up to 5 GPa, matching the experimental reference within tenths of kelvins and improving the liquid-state diffusion constant. Our approach is model-agnostic, applicable to multi-component systems with solid-solid and solid-liquid transitions, and compliant with top-down training on other experimental properties. Therefore, our approach can serve as an essential step towards highly accurate application-specific and foundational machine learning potentials."}
{"id": "2512.03618", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03618", "abs": "https://arxiv.org/abs/2512.03618", "authors": ["Frank Steglich"], "title": "Fermionic Critical Fluctuations: Potential Driver of Strange Metallicity and Violation of the Wiedemann-Franz Law in YbRh2Si2", "comment": "7 pages, 5 figures", "summary": "Results of combined thermal and electrical transport measurements through the magnetic field-induced quantum critical point in the heavy-fermion compound YbRh2Si2 are revisited to explore the relationship between the strange-metal behavior, observed in both the electrical and electronic thermal resistivity, and the violation of the Wiedemann-Franz law in the zero-temperature limit. A new type of inelastic scattering center for the charge and heat carriers has been detected and ascribed to the small-to-large Fermi-surface fluctuations. These are operating in the vicinity of and at the Kondo-destroying quantum critical point as fermionic quantum critical fluctuations and are considered the primary driver of the strange-metal behavior and the violation of the Wiedemann-Franz law."}
{"id": "2512.03483", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.03483", "abs": "https://arxiv.org/abs/2512.03483", "authors": ["Binjie Li", "Qin Zhou"], "title": "Numerical Analysis of the 2D Stochastic Navier-Stokes Equations: Convergence under Transport Noise and No-slip Boundary Conditions", "comment": null, "summary": "This work is concerned with the numerical approximation of the two-dimensional stochastic Navier-Stokes equation with transport noise and no-slip boundary conditions on a convex polygonal domain. The analysis is challenged by the solution's low spatial regularity and the non-Lipschitz nonlinearity. We derive a convergence rate in the mean-square sense for a spatial semidiscretization. Furthermore, for the full discretization, we prove convergence in probability and establish an explicit rate with respect to the time step."}
{"id": "2512.03067", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03067", "abs": "https://arxiv.org/abs/2512.03067", "authors": ["Difu Feng", "Qianqian Xu", "Zitai Wang", "Cong Hua", "Zhiyong Yang", "Qingming Huang"], "title": "Quantifying the Potential to Escape Filter Bubbles: A Behavior-Aware Measure via Contrastive Simulation", "comment": null, "summary": "Nowadays, recommendation systems have become crucial to online platforms, shaping user exposure by accurate preference modeling. However, such an exposure strategy can also reinforce users' existing preferences, leading to a notorious phenomenon named filter bubbles. Given its negative effects, such as group polarization, increasing attention has been paid to exploring reasonable measures to filter bubbles. However, most existing evaluation metrics simply measure the diversity of user exposure, failing to distinguish between algorithmic preference modeling and actual information confinement. In view of this, we introduce Bubble Escape Potential (BEP), a behavior-aware measure that quantifies how easily users can escape from filter bubbles. Specifically, BEP leverages a contrastive simulation framework that assigns different behavioral tendencies (e.g., positive vs. negative) to synthetic users and compares the induced exposure patterns. This design enables decoupling the effect of filter bubbles and preference modeling, allowing for more precise diagnosis of bubble severity. We conduct extensive experiments across multiple recommendation models to examine the relationship between predictive accuracy and bubble escape potential across different groups. To the best of our knowledge, our empirical results are the first to quantitatively validate the dilemma between preference modeling and filter bubbles. What's more, we observe a counter-intuitive phenomenon that mild random recommendations are ineffective in alleviating filter bubbles, which can offer a principled foundation for further work in this direction."}
{"id": "2512.03061", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.03061", "abs": "https://arxiv.org/abs/2512.03061", "authors": ["Paulina Kaczyńska", "Julian Sienkiewicz", "Dominik Ślęzak"], "title": "Accumulated Local Effects and Graph Neural Networks for link prediction", "comment": null, "summary": "We investigate how Accumulated Local Effects (ALE), a model-agnostic explanation method, can be adapted to visualize the influence of node feature values in link prediction tasks using Graph Neural Networks (GNNs), specifically Graph Convolutional Networks and Graph Attention Networks. A key challenge addressed in this work is the complex interactions of nodes during message passing within GNN layers, complicating the direct application of ALE. Since a straightforward solution of modifying only one node at once substantially increases computation time, we propose an approximate method that mitigates this challenge. Our findings reveal that although the approximate method offers computational efficiency, the exact method yields more stable explanations, particularly when smaller data subsets are used. However, the explanations produced with the approximate method are not significantly different from the ones obtained with the exact method. Additionally, we analyze how varying parameters affect the accuracy of ALE estimation for both approaches."}
{"id": "2512.03081", "categories": ["physics.ao-ph", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03081", "abs": "https://arxiv.org/abs/2512.03081", "authors": ["Zhewen Hou", "Jiajin Sun", "Subashree Venkatasubramanian", "Peter Jin", "Shuolin Li", "Tian Zheng"], "title": "Calibrating Geophysical Predictions under Constrained Probabilistic Distributions", "comment": null, "summary": "Machine learning (ML) has shown significant promise in studying complex geophysical dynamical systems, including turbulence and climate processes. Such systems often display sensitive dependence on initial conditions, reflected in positive Lyapunov exponents, where even small perturbations in short-term forecasts can lead to large deviations in long-term outcomes. Thus, meaningful inference requires not only accurate short-term predictions, but also consistency with the system's long-term attractor that is captured by the marginal distribution of state variables. Existing approaches attempt to address this challenge by incorporating spatial and temporal dependence, but these strategies become impractical when data are extremely sparse. In this work, we show that prior knowledge of marginal distributions offers valuable complementary information to short-term observations, motivating a distribution-informed learning framework. We introduce a calibration algorithm based on normalization and the Kernelized Stein Discrepancy (KSD) to enhance ML predictions. The method here employs KSD within a reproducing kernel Hilbert space to calibrate model outputs, improving their fidelity to known physical distributions. This not only sharpens pointwise predictions but also enforces consistency with non-local statistical structures rooted in physical principles. Through synthetic experiments-spanning offline climatological CO2 fluxes and online quasi-geostrophic flow simulations-we demonstrate the robustness and broad utility of the proposed framework."}
{"id": "2512.03799", "categories": ["cond-mat.dis-nn", "cond-mat.soft", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03799", "abs": "https://arxiv.org/abs/2512.03799", "authors": ["Purba Chatterjee", "Marcelo Guzman", "Andrea J. Liu"], "title": "Remembrance of Tasks Past in Tunable Physical Networks", "comment": null, "summary": "Sequential learning in physical networks is hindered by catastrophic forgetting, where training a new task erases solutions to earlier ones. We show that we can significantly enhance memory of previous tasks by introducing a hard threshold in the learning rule, allowing only edges with sufficiently large training signals to be altered. Thresholding confines tuning to the spatial vicinity of inputs and outputs for each task, effectively partitioning the network into weakly overlapping functional regions. Using simulations of tunable resistor networks, we demonstrate that this strategy enables robust memory of multiple sequential tasks while reducing the number of edges and the overall tuning cost. Our results hint at constrained training as a simple, local, and scalable mechanism to overcome catastrophic forgetting in tunable matter."}
{"id": "2512.03333", "categories": ["quant-ph", "math.NA", "math.ST", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03333", "abs": "https://arxiv.org/abs/2512.03333", "authors": ["Xun Tang", "Haoxuan Chen", "Yuehaw Khoo", "Lexing Ying"], "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State", "comment": null, "summary": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation."}
{"id": "2512.03119", "categories": ["physics.ao-ph", "astro-ph.EP", "astro-ph.IM", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.03119", "abs": "https://arxiv.org/abs/2512.03119", "authors": ["Jordan W. Bishop", "Philip Blom", "Chris Carr", "Jeremy Webster"], "title": "An infrasound source analysis of the OSIRIS-REx sample return capsule hypersonic re-entry", "comment": "49 pages, 9 figures; In Press at the Journal of the Acoustical Society of America", "summary": "The OSIRIS-REx sample return capsule hypersonic re-entry into the atmosphere is a rare opportunity to test a variety of sonic boom source models since the projectile dimensions are well characterized. While the as-flown flight path is unknown, the predicted flight path enables a rough approximation of the source Mach number and location. Six infrasound microphones deployed in the boom carpet along the predicted flight path recorded impulsive signals from the OSIRIS-REx re-entry. Using a suite of atmosphere profiles and the geometric acoustics approximation, we estimate locations with uncertainty estimates along the flight path from which the signals were emitted. Acoustic overpressure and signal duration predictions from Whitham's far field theory, Carlson's simplified sonic boom prediction method, and a drag-dominated hypersonic model are analyzed with uncertainty estimates from the location estimate. While the Carlson simplified sonic boom prediction method could be accurate, our preference is for the drag-dominated source model. Using this source model with an inviscid Burgers' equation solver for propagation, we obtained an excellent match to the recorded data. These results will help better inform future sample return capsule re-entry observation campaigns as well as contribute to a better understanding of high altitude infrasonic sources."}
{"id": "2512.03116", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03116", "abs": "https://arxiv.org/abs/2512.03116", "authors": ["Joseph de Vilmarest", "Olivier Wintenberger"], "title": "Assessing Extrapolation of Peaks Over Thresholds with Martingale Testing", "comment": null, "summary": "We present the winning strategy for the EVA2025 Data Challenge, which aimed to estimate the probability of extreme precipitation events. These events occurred at most once in the dataset making the challenge fundamentally one of extrapolating extreme values. Given the scarcity of extreme events, we argue that a simple, robust modeling approach is essential. We adopt univariate models instead of multivariate ones and model Peaks Over Thresholds using Extreme Value Theory. Specifically, we fit an exponential distribution to model exceedances of the target variable above a high quantile (after seasonal adjustment). The novelty of our approach lies in using martingale testing to evaluate the extrapolation power of the procedure and to agnostically select the level of the high quantile. While this method has several limitations, we believe that framing extrapolation as a game opens the door to other agnostic approaches in Extreme Value Analysis."}
{"id": "2512.04024", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2512.04024", "abs": "https://arxiv.org/abs/2512.04024", "authors": ["V. A. Ulitko", "D. N. Yasinskaya", "S. A. Bezzubin", "A. A. Koshelev", "Y. D. Panov"], "title": "Predicting parameters of a model cuprate superconductor using machine learning", "comment": "22 pages, 8 figures, 2 tables", "summary": "The computational complexity of calculating phase diagrams for multi-parameter models significantly limits the ability to select parameters that correspond to experimental data. This work presents a machine learning method for solving the inverse problem - forecasting the parameters of a model Hamiltonian for a cuprate superconductor based on its phase diagram. A comparative study of three deep learning architectures was conducted: VGG, ResNet, and U-Net. The latter was adapted for regression tasks and demonstrated the best performance. Training the U-Net model was performed on an extensive dataset of phase diagrams calculated within the mean-field approximation, followed by validation on data obtained using a semi-classical heat bath algorithm for Monte Carlo simulations. It is shown that the model accurately predicts all considered Hamiltonian parameters, and areas of low prediction accuracy correspond to regions of parametric insensitivity in the phase diagrams. This allows for the extraction of physically interpretable patterns and validation of the significance of parameters for the system. The results confirm the promising potential of applying machine learning to analyze complex physical models in condensed matter physics."}
{"id": "2512.03689", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03689", "abs": "https://arxiv.org/abs/2512.03689", "authors": ["Edoardo Zavatti", "Gabriele Bellomia", "Samuele Giuli", "Matteo Ferraretto", "Massimo Capone"], "title": "More is uncorrelated: Tuning the local correlations of SU($N$) Fermi-Hubbard systems via controlled symmetry breaking", "comment": "9 pages + references, 8 figures. Comments welcome!", "summary": "Cold-atom experiments based on alkali-like atoms provide us with a tool to experimentally realize Hubbard models with a large number $N$ of components. The value of $N$ can be seen as a new handle to tune the properties of the system, leading to new physics both in the case of fully SU($N$) symmetric systems, or in the presence of controlled symmetry breaking.\n  We focus on the Mott transition at global half filling and we characterize local correlations between particles complementing conventional estimates with the inter-flavor mutual information. We prove that these correlations have classical nature and, using Dynamical Mean-Field Theory, we show that the SU(4) system has significantly smaller correlations than the SU(2) counterpart. In the atomic limit we prove that increasing $N$ further decreases the strength of the correlations. This suggests that a controlled reduction of the symmetry, reducing the number of effective components, can be used to enhance the degree of correlation.\n  We confirm this scenario solving the model for $N=4$ and gradually breaking the symmetry via a Raman field, revealing an evolution from the SU(4) to the SU(2) Mott transition as the symmetry-breaking term increases, with a sudden recovery of the large correlations of the SU(2) model at weak Raman coupling in the Mott state. By further exploring the interplay between energy repulsion and the Raman field, we obtain a rich phase diagram with three different phases -- a metal, a band insulator, and a Mott insulator -- all coexisting at a single tricritical point."}
{"id": "2512.03496", "categories": ["math.NA", "gr-qc", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.03496", "abs": "https://arxiv.org/abs/2512.03496", "authors": ["Yuchen Huang", "Manting Peng", "Kailiang Wu"], "title": "Constraint-Preserving High-Order Compact OEDG Method for Spherically Symmetric Einstein-Euler System", "comment": null, "summary": "Numerical simulation of the spherically symmetric Einstein--Euler (EE) system faces severe challenges due to the stringent physical admissibility constraints of relativistic fluids and the geometric singularities inherent in metric evolution. This paper proposes a high-order Constraint-Preserving (CP) compact Oscillation-Eliminating Discontinuous Galerkin (cOEDG) method specifically tailored to address these difficulties. The method integrates a scale-invariant oscillation-eliminating mechanism [M. Peng, Z. Sun, K. Wu, Math. Comp., 94: 1147--1198, 2025] into a compact Runge--Kutta DG framework. By characterizing the convex invariant region of the hydrodynamic subsystem with general barotropic equations of state, we prove that the proposed scheme preserves physical realizability (specifically, positive density and subluminal velocity) directly in terms of conservative variables, thereby eliminating the need for complex primitive-variable checks. To ensure the geometric validity of the spacetime, we introduce a bijective transformation of the metric potentials. Rather than evolving the constrained metric components directly, the scheme advances unconstrained auxiliary variables whose inverse mapping automatically enforces strict positivity and asymptotic bounds without any limiters. Combined with a compatible high-order boundary treatment, the resulting CPcOEDG method exhibits robust stability and design-order accuracy in capturing strong gravity-fluid interactions, as demonstrated by simulations of black hole accretion and relativistic shock waves."}
{"id": "2512.03092", "categories": ["cs.SI", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2512.03092", "abs": "https://arxiv.org/abs/2512.03092", "authors": ["Maxwell H Wang", "Till Hoffmann", "Jukka-Pekka Onnela"], "title": "Approximate Bayesian Inference on Mechanisms of Network Growth and Evolution", "comment": "24 pages, 8 figures", "summary": "Mechanistic models can provide an intuitive and interpretable explanation of network growth by specifying a set of generative rules. These rules can be defined by domain knowledge about real-world mechanisms governing network growth or may be designed to facilitate the appearance of certain network motifs. In the formation of real-world networks, multiple mechanisms may be simultaneously involved; it is then important to understand the relative contribution of each of these mechanisms. In this paper, we propose the use of a conditional density estimator, augmented with a graph neural network, to perform inference on a flexible mixture of network-forming mechanisms. This event-wise mixture-of-mechanisms model assigns mechanisms to each edge formation event rather than stipulating node-level mechanisms, thus allowing for an explanation of the network generation process, as well as the dynamic evolution of the network over time. We demonstrate that our approximate Bayesian approach yields valid inferences for the relative weights of the mechanisms in our model, and we utilize this method to investigate the mechanisms behind the formation of a variety of real-world networks."}
{"id": "2512.03766", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.03766", "abs": "https://arxiv.org/abs/2512.03766", "authors": ["Katherine Betz"], "title": "Inaccessibility in Public Transit Networks", "comment": "12 figures, 4 tables", "summary": "The study of networks derived from infrastructure systems has received considerable attention, yet the accessibility of such systems, particularly within public transit networks, remains comparatively underexplored. Accessibility encompasses a broad range of considerations, from infrastructure-based features such as elevators and step-free access to spatial factors such as the geographic distribution of accessible stations. In this work, we investigate infrastructure-based accessibility in two major transit systems: the London Underground and the New York City Subway. We construct network models in which nodes represent accessible stations and edges represent adjacency along transit lines. Using tools from network analysis, we examine the structural properties of these accessibility networks, including clustering patterns and the spatial distribution of accessible nodes. We further employ centrality measures to identify stations that serve as major accessible hubs. Finally, we analyze socioeconomic and tourism-related variables to assess the influence of neighborhood wealth and popularity on the prevalence of accessible stations. Our findings highlight significant disparities in accessibility across both systems and demonstrate the utility of mathematical and network-theoretic methods in understanding and improving modern transit infrastructure."}
{"id": "2512.03119", "categories": ["physics.ao-ph", "astro-ph.EP", "astro-ph.IM", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.03119", "abs": "https://arxiv.org/abs/2512.03119", "authors": ["Jordan W. Bishop", "Philip Blom", "Chris Carr", "Jeremy Webster"], "title": "An infrasound source analysis of the OSIRIS-REx sample return capsule hypersonic re-entry", "comment": "49 pages, 9 figures; In Press at the Journal of the Acoustical Society of America", "summary": "The OSIRIS-REx sample return capsule hypersonic re-entry into the atmosphere is a rare opportunity to test a variety of sonic boom source models since the projectile dimensions are well characterized. While the as-flown flight path is unknown, the predicted flight path enables a rough approximation of the source Mach number and location. Six infrasound microphones deployed in the boom carpet along the predicted flight path recorded impulsive signals from the OSIRIS-REx re-entry. Using a suite of atmosphere profiles and the geometric acoustics approximation, we estimate locations with uncertainty estimates along the flight path from which the signals were emitted. Acoustic overpressure and signal duration predictions from Whitham's far field theory, Carlson's simplified sonic boom prediction method, and a drag-dominated hypersonic model are analyzed with uncertainty estimates from the location estimate. While the Carlson simplified sonic boom prediction method could be accurate, our preference is for the drag-dominated source model. Using this source model with an inviscid Burgers' equation solver for propagation, we obtained an excellent match to the recorded data. These results will help better inform future sample return capsule re-entry observation campaigns as well as contribute to a better understanding of high altitude infrasonic sources."}
{"id": "2512.03917", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.03917", "abs": "https://arxiv.org/abs/2512.03917", "authors": ["Václav Janiš"], "title": "A microscopic theory of Anderson localization of electrons in random lattices", "comment": "16 pages RevTeX 4.2, 2PDF figures", "summary": "The existence of Anderson localization, characterized by vanishing diffusion due to strong randomness, has been demonstrated in numerous ways. A systematic approach based on the Anderson quantum model of the Fermi gas in random lattices that can describe both diffusive and localized regimes has not yet been fully established. We build upon a recent publication \\cite{Janis:2025ab} and present a microscopic theory of disordered electrons covering both the metallic phase with extended Bloch waves and the localized phase where the propagating particle forms a quantum bound state with the hole left behind at the origin. The general theory provides a framework for constructing controlled approximations to one-particle and two-particle Green functions that satisfy the necessary conservation laws and causality requirements in the whole range of disorder strength. It is used explicitly to derive a local, mean-field-like approximation for the two-particle irreducible vertices, enabling quantitative analysis of the solution's properties in both metallic and localized phases, including critical behavior at the Anderson localization transition."}
{"id": "2512.04058", "categories": ["quant-ph", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.04058", "abs": "https://arxiv.org/abs/2512.04058", "authors": ["Shashaank Khanna", "Matthew Pusey", "Roger Colbeck"], "title": "Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap", "comment": "5 pages, 3 figures, 1 table", "summary": "The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures."}
{"id": "2512.03235", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.03235", "abs": "https://arxiv.org/abs/2512.03235", "authors": ["Sijie Zheng"], "title": "Estimation of Semiparametric Factor Models with Missing Data", "comment": null, "summary": "We study semiparametric factor models in high-dimensional panels where the factor loadings consist of a nonparametric component explained by observed covariates and an idiosyncratic component capturing unobserved heterogeneity. A key challenge in empirical applications is the presence of missing observations, which can distort both factor recovery and loading estimation. To address this issue, we develop a projected principal component analysis (PPCA) procedure that accommodates general missing-at-random mechanisms through inverse-probability weighting. We establish consistency and derive the asymptotic distributions of the estimated factors and loading functions, allowing the sieve dimension to diverge and permitting the time dimension to be either fixed or growing. Unlike classical PCA, PPCA achieves consistent factor estimation even when T is fixed, and the limiting distributions under missing data exhibit mixture normality with enlarged asymptotic variances. Theoretical results are supported by simulations and an empirical application. Our findings demonstrate that PPCA provides an effective and robust framework for estimating semiparametric factor models in the presence of missing data."}
{"id": "2512.03075", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03075", "abs": "https://arxiv.org/abs/2512.03075", "authors": ["J. A. S. Lima", "M. H. Benetti"], "title": "Kappa Entropy and its Thermodynamic Connection", "comment": "5 pages, 2 figures", "summary": "Adopting a bottom-up perspective, we propose a novel two-parametric nonadditive entropy, $S_{κ\\ell}$, associated with a Kappa-type power-law velocity distribution, $F_{κ\\ell}(v)$, recently derived in the literature. By formulating an extended Neo-Boltzmannian microstate counting procedure and employing standard averaging techniques, we demonstrate that the fundamental laws of thermodynamics are preserved within this generalized power-law framework only whether $\\ell=-5/2$, regardless of the values assumed by the $κ$-parameter."}
{"id": "2512.03160", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03160", "abs": "https://arxiv.org/abs/2512.03160", "authors": ["Feiya Zhu", "Tarun Pati", "Sze Zheng Yong"], "title": "Time-Invariant Polytopic and Interval Observers for Uncertain Linear Systems via Non-Square Transformation", "comment": null, "summary": "This paper presents novel polytopic and interval observer designs for uncertain linear continuous-time (CT) and discrete-time (DT) systems subjected to bounded disturbances and noise. Our approach guarantees enclosure of the true state and input-to-state stability (ISS) of the polytopic and interval set estimates. Notably, our approach applies to all detectable systems that are stabilized by any optimal observer design, utilizing a potentially non-square (lifted) time-invariant coordinate transformation based on polyhedral Lyapunov functions and mixed-monotone embedding systems that do not impose any positivity constraints, enabling feasible and optimal observer designs, even in cases where previous methods fail. The effectiveness of our approach is demonstrated through several examples of uncertain linear CT and DT systems."}
{"id": "2512.03160", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03160", "abs": "https://arxiv.org/abs/2512.03160", "authors": ["Feiya Zhu", "Tarun Pati", "Sze Zheng Yong"], "title": "Time-Invariant Polytopic and Interval Observers for Uncertain Linear Systems via Non-Square Transformation", "comment": null, "summary": "This paper presents novel polytopic and interval observer designs for uncertain linear continuous-time (CT) and discrete-time (DT) systems subjected to bounded disturbances and noise. Our approach guarantees enclosure of the true state and input-to-state stability (ISS) of the polytopic and interval set estimates. Notably, our approach applies to all detectable systems that are stabilized by any optimal observer design, utilizing a potentially non-square (lifted) time-invariant coordinate transformation based on polyhedral Lyapunov functions and mixed-monotone embedding systems that do not impose any positivity constraints, enabling feasible and optimal observer designs, even in cases where previous methods fail. The effectiveness of our approach is demonstrated through several examples of uncertain linear CT and DT systems."}
{"id": "2512.03330", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.03330", "abs": "https://arxiv.org/abs/2512.03330", "authors": ["Juan Antonio Rojas-Quintero", "François Dubois", "Frédéric Jourdan"], "title": "Simpson variational integrator for nonlinear systems: a tutorial on the Lagrange top", "comment": "22 pages, 14 figures, 6 tables, journal submission", "summary": "This contribution presents an integration method based on the Simpson quadrature. The integrator is designed for finite-dimensional nonlinear mechanical systems that derive from variational principles. The action is discretized using quadratic finite elements interpolation of the state and Simpson's quadrature, leading to discrete motion equations. The scheme is implicit, symplectic, and fourth-order accurate. The proposed integrator is compared with the implicit midpoint variational integrator on two examples of systems with inseparable Hamiltonians. First, the example of the nonlinear double pendulum illustrates how the method can be applied to multibody systems. The analytical solution of the Lagrange top is then used as a reference to analyze accuracy, convergence, and precision of the numerical method. A reduced Lagrange top system is also proposed and solved with a classical fourth-order method. Its solution is compared with the Simpson solution of the complete system, and the convergence order of the difference between both is consistent with the order of the classical method."}
{"id": "2512.04056", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.04056", "abs": "https://arxiv.org/abs/2512.04056", "authors": ["Ryan Larson", "Rubem Mondaini", "Richard T. Scalettar"], "title": "Sign-Resolved Statistics and the Origin of Bias in Quantum Monte Carlo", "comment": "6+6 pages; 4+6 figures", "summary": "Quantum simulations are a powerful tool for exploring strongly correlated many-body phenomena. Yet, their reach is limited by the fermion sign problem, which causes configuration weights to become negative, compromising statistical sampling. In auxiliary-field Quantum Monte Carlo calculations of the doped Hubbard model, neglecting the sign ${\\cal S}$ of the weight leads to qualitatively wrong results -- most notably, an apparent suppression rather than enhancement of $d$-wave pairing at low temperature. Here we approach the problem from a different perspective: instead of identifying negative-weight paths, we examine the statistics of measured observables in a sign-resolved manner. By analyzing histograms of key quantities (kinetic energy, antiferromagnetic structure factor, and pair susceptibilities) for configurations with ${\\cal S}=\\pm1$, we derive an exact relation linking the bias from ignoring the sign to the difference between sign-resolved means, $Δμ$, and the average sign, $\\langle {\\cal S}\\rangle$. Our framework provides a precise diagnostic of the origin of measurement bias in Quantum Monte Carlo and clarifies why observables such as the $d$-wave susceptibility are especially sensitive to the sign problem."}
{"id": "2512.03586", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.03586", "abs": "https://arxiv.org/abs/2512.03586", "authors": ["Domenico Caparello", "Tommaso Tenna"], "title": "A Coupled IMEX Domain Decomposition Method for High-Order Time Integration of the ES-BGK Model of the Boltzmann Equation", "comment": null, "summary": "In this paper, we propose a high-order domain decomposition method for the ES-BGK model of the Boltzmann equation, which dynamically detects regions of equilibrium and non-equilibrium. Our implementation automatically switches between Euler equations in regions where the fluid is at equilibrium, and the ES-BGK model elsewhere. The main challenge addressed in this work is the development of a coupled strategy between the macroscopic and the kinetic solvers, which preserves the overall temporal order of accuracy of the scheme. A coupled IMEX method is introduced across decomposed subdomains and solvers. This approach is based on a coupled IMEX method and allows high accuracy and computational efficiency. Several numerical simulations in two space dimensions are performed, in order to validate the robustness of our approach and the expected temporal high-order convergence."}
{"id": "2512.03095", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03095", "abs": "https://arxiv.org/abs/2512.03095", "authors": ["Motaz Ben Hassine"], "title": "Community Quality and Influence Maximization: An Empirical Study", "comment": null, "summary": "Influence maximization in social networks plays a vital role in applications such as viral marketing, epidemiology, product recommendation, opinion mining, and counter-terrorism. A common approach identifies seed nodes by first detecting disjoint communities and subsequently selecting representative nodes from these communities. However, whether the quality of detected communities consistently affects the spread of influence under the Independent Cascade model remains unclear. This paper addresses this question by extending a previously proposed disjoint community detection method, termed $α$-Hierarchical Clustering, to the influence maximization problem under the Independent Cascade model. The proposed method is compared with an alternative approach that employs the same seed selection criteria but relies on communities of lower quality obtained through standard Hierarchical Clustering. The former is referred to as Hierarchical Clustering-based Influence Maximization, while the latter, which leverages higher-quality community structures to guide seed selection, is termed $α$-Hierarchical Clustering-based Influence Maximization. Extensive experiments are performed on multiple real-world datasets to assess the effectiveness of both methods. The results demonstrate that higher-quality community structures substantially improve information diffusion under the Independent Cascade model, particularly when the propagation probability is low. These findings underscore the critical importance of community quality in guiding effective seed selection for influence maximization in complex networks."}
{"id": "2512.03889", "categories": ["physics.hist-ph", "astro-ph.IM", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.03889", "abs": "https://arxiv.org/abs/2512.03889", "authors": ["Maria Florencia Muratore", "Alejandro Gangui", "Juan Antonio Belmonte", "Carmelo Cabrera"], "title": "Comparing land- and skyscapes in the three main manorial-conquered lands of the Canary Islands", "comment": "PDF document including 4 figures", "summary": "This work is a study of the relationship between astronomy and landscape focused on the orientation of Christian churches of the three main Manorial (Señorío) Islands of the Canary archipelago (Spain): Lanzarote, La Gomera and Fuerteventura. As a background, we have the information provided by the texts of early Christian writers, which imposed that churches should be oriented towards the east [..]. The fieldwork that supports our comparative study is based on the measurement of the precise location coordinates, axis' azimuth and angular height of the horizon for most of the churches of the three islands, which amounts to about 120 sets of measurements. For the study of the sample, we have employed various analyses, both statistical, as well as calendric and orographic. Our results show that on all the islands, the pattern of double orientations is repeated, which contemplates the canonical tradition of orienting the altars of churches within the solar range (pointing either eastward or westward). Very few cases also occur where it is possible to identify constructions whose orientation follows solstitial patterns, perhaps as imitation of aboriginal worship. But this double pattern also includes a high proportion of churches with orientations far from this range. An example is Lanzarote and Fuerteventura, both islands subjected to the same flow of the prevailing trade winds in the region, but each with its own characteristics. Another example is given by the particular orography of deep ravines of La Gomera, which determines the orientation of the temples located in those geographical accidents. In this paper we show how the combination of elements of the land- and skyscape can, with a high degree of probability, offer a satisfactory explanation to the particular orientation of these insular centres of worship, which were built during the first decades after the European conquest."}
{"id": "2512.03258", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2512.03258", "abs": "https://arxiv.org/abs/2512.03258", "authors": ["Jack William Skinner", "Jörn Callies", "Albion Lawrence", "Xihan Zhang"], "title": "Isolating Balanced Ocean Dynamics in SWOT Data", "comment": "36 pages, 11 figures, submitted to JGR Oceans", "summary": "The Surface Water and Ocean Topography (SWOT) mission provides two-dimensional sea surface height (SSH) maps at unprecedented resolution, but its signal is a combination of balanced meso- and submesoscale turbulence, unbalanced internal waves, and small-scale noise. Interpreting the meso- and submesoscale flow features captured by SWOT requires a careful isolation of the balanced signal. We present a statistical method to do so in regions where internal-wave signals are negligible, such as western boundary current regions and the Southern Ocean. Our method assumes Gaussian statistics for both the balanced flow and the noise, which we infer by fitting parametric models to the observed SSH wavenumber spectrum. Using these inferred parameters, we perform a Bayesian inversion to reconstruct swath-aligned SSH maps that fill the nadir gap. We evaluate the method using synthetic data from a high-resolution simulation with realistic SWOT-like noise added. Comparisons with the underlying model data show that our reconstruction successfully removes small-scale noise while preserving meso- and submesoscale eddies, fronts, and filaments down to a feature scale of 10km. The comparison also demonstrates that the posterior uncertainty is a reliable estimate of the error."}
{"id": "2512.04037", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.04037", "abs": "https://arxiv.org/abs/2512.04037", "authors": ["Lorenzo Tonetti", "Leticia F. Cugliandolo", "Marco Tarzia"], "title": "Testing the Localization Landscape Theory on the Bethe Lattice", "comment": null, "summary": "The Localization Landscape Theory (LLT) provides a classical picture of Anderson localization by introducing an effective confining potential whose percolation is proposed to coincide with the mobility edge. Although this proposal shows remarkable numerical agreement in three dimensions, its fundamental validity remains unsettled. Here we test the LLT analytically on the Bethe lattice, where both the Anderson localization transition and the LLT percolation problem are exactly solvable. We find that the two transitions do not coincide, and their critical behaviors differ markedly. In particular, LLT percolation displays standard mean-field percolation criticality that is fundamentally distinct from the peculiar critical behavior of the Anderson transition on the Bethe lattice. Our results provide an exact benchmark showing that, while geometrically intuitive, the LLT does not capture the true quantum critical properties of localization."}
{"id": "2512.04059", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.04059", "abs": "https://arxiv.org/abs/2512.04059", "authors": ["Alden Green", "Jonathan Taylor"], "title": "Inference for location and height of peaks of a standardized field after selection", "comment": null, "summary": "Peak inference concerns the use of local maxima (\"peaks\") of a noisy random field to detect and localize regions where underlying signal is present. We propose a peak inference method that first subjects observed peaks to a significance test of the null hypothesis that no signal is present, and then uses the peaks that are declared significant to construct post-selectively valid confidence regions for the location and height of nearby true peaks. We analyze the performance of this method in a smooth signal plus constant variance noise model under a high-curvature asymptotic assumption, and prove that it asymptotically controls both the number of false discoveries, and the number of confidence regions that do not contain a true peak, relative to the number of points at which inference is conducted. An important intermediate theoretical result uses the Kac-Rice formula to derive a novel approximation to the intensity function of a point process that counts local maxima, which is second-order accurate under the alternative, nearby high-curvature true peaks."}
{"id": "2512.03254", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.03254", "abs": "https://arxiv.org/abs/2512.03254", "authors": ["Philippe A. Boileau", "Hani Zaki", "Gabriele Lileikyte", "Niklas Nielsen", "Patrick R. Lawler", "Mireille E. Schnitzer"], "title": "Assumption-Lean Differential Variance Inference for Heterogeneous Treatment Effect Detection", "comment": null, "summary": "The conditional average treatment effect (CATE) is frequently estimated to refute the homogeneous treatment effect assumption. Under this assumption, all units making up the population under study experience identical benefit from a given treatment. Uncovering heterogeneous treatment effects through inference about the CATE, however, requires that covariates truly modifying the treatment effect be reliably collected at baseline. CATE-based techniques will necessarily fail to detect violations when effect modifiers are omitted from the data due to, for example, resource constraints. Severe measurement error has a similar impact. To address these limitations, we prove that the homogeneous treatment effect assumption can be gauged through inference about contrasts of the potential outcomes' variances. We derive causal machine learning estimators of these contrasts and study their asymptotic properties. We establish that these estimators are doubly robust and asymptotically linear under mild conditions, permitting formal hypothesis testing about the homogeneous treatment effect assumption even when effect modifiers are missing or mismeasured. Numerical experiments demonstrate that these estimators' asymptotic guarantees are approximately achieved in experimental and observational data alike. These inference procedures are then used to detect heterogeneous treatment effects in the re-analysis of randomized controlled trials investigating targeted temperature management in cardiac arrest patients."}
{"id": "2512.03316", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.03316", "abs": "https://arxiv.org/abs/2512.03316", "authors": ["Issei Sakai", "Takuma Akimoto"], "title": "Symmetry Breaking of Current Response in Disordered Exclusion Processes", "comment": "6 pages, 3 figures + 7 pages of supplemental material", "summary": "The bias-reversal symmetry -- where reversing an external bias inverts the current without changing its magnitude -- is a hallmark of nonequilibrium transport. While this property holds in homogeneous systems such as the asymmetric simple exclusion process, how disorder and its interplay with particle interactions affect this symmetry has remained unclear. Here, we establish a general criterion showing that the bias-reversal symmetry holds if and only if the local left-right bond-bias ratio is spatially uniform. Analytical and numerical analyses reveal that bond disorder preserves the symmetry beyond linear response, whereas site disorder breaks it through an interplay between heterogeneity and particle interactions. Our results demonstrate how environmental disorder and interparticle interactions cooperate to generate asymmetric transport, thereby providing a unified theoretical framework relevant to transport through biological and artificial nanochannels."}
{"id": "2512.03459", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.03459", "abs": "https://arxiv.org/abs/2512.03459", "authors": ["Hidaka Asai", "Tomoyuki Noda", "Jun Morimoto"], "title": "Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion", "comment": "12 pages, 11 figures. Submitted to IEEE Transactions on Systems, Man, and Cybernetics: Systems", "summary": "Human motor control remains agile and robust despite limited sensory information for feedback, a property attributed to the body's ability to perform morphological computation through muscle coordination with variable impedance. However, it remains unclear how such low-level mechanical computation reduces the control requirements of the high-level controller. In this study, we implement a hierarchical controller consisting of a high-level neural network trained by reinforcement learning and a low-level variable-impedance muscle coor dination model with mono- and biarticular muscles in monoped locomotion task. We systematically restrict the high-level controller by varying the control frequency and by introducing biologically inspired observation conditions: delayed, partial, and substituted observation. Under these conditions, we evaluate how the low-level variable-impedance muscle coordination contributes to learning process of high-level neural network. The results show that variable-impedance muscle coordination enables stable locomotion even under slow-rate control frequency and limited observation conditions. These findings demonstrate that the morphological computation of muscle coordination effectively offloads high-frequency feedback of the high-level controller and provide a design principle for the controller in motor control."}
{"id": "2512.03459", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.03459", "abs": "https://arxiv.org/abs/2512.03459", "authors": ["Hidaka Asai", "Tomoyuki Noda", "Jun Morimoto"], "title": "Variable-Impedance Muscle Coordination under Slow-Rate Control Frequencies and Limited Observation Conditions Evaluated through Legged Locomotion", "comment": "12 pages, 11 figures. Submitted to IEEE Transactions on Systems, Man, and Cybernetics: Systems", "summary": "Human motor control remains agile and robust despite limited sensory information for feedback, a property attributed to the body's ability to perform morphological computation through muscle coordination with variable impedance. However, it remains unclear how such low-level mechanical computation reduces the control requirements of the high-level controller. In this study, we implement a hierarchical controller consisting of a high-level neural network trained by reinforcement learning and a low-level variable-impedance muscle coor dination model with mono- and biarticular muscles in monoped locomotion task. We systematically restrict the high-level controller by varying the control frequency and by introducing biologically inspired observation conditions: delayed, partial, and substituted observation. Under these conditions, we evaluate how the low-level variable-impedance muscle coordination contributes to learning process of high-level neural network. The results show that variable-impedance muscle coordination enables stable locomotion even under slow-rate control frequency and limited observation conditions. These findings demonstrate that the morphological computation of muscle coordination effectively offloads high-frequency feedback of the high-level controller and provide a design principle for the controller in motor control."}
{"id": "2512.03222", "categories": ["math.OC", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.03222", "abs": "https://arxiv.org/abs/2512.03222", "authors": ["Gehui Xu", "Kaiwen Chen", "Thomas Parisini", "Andreas A. Malikopoulos"], "title": "Game-Theoretic Learning-Based Mitigation of Insider Threats", "comment": null, "summary": "An insider is defined as a team member who covertly deviates from the team's optimal collaborative control strategy in pursuit of a private objective, while maintaining an outward appearance of cooperation. Such insider threats can severely undermine cooperative systems: subtle deviations may degrade collective performance, jeopardize mission success, and compromise operational safety. This paper presents a comprehensive framework for identifying and mitigating insider threats in cooperative control settings. We introduce an insider-aware, game-theoretic formulation in which the insider's hidden intention is parameterized, allowing the threat identification task to be reformulated as a parameter estimation problem. To address this challenge, we employ an online indirect dual adaptive control approach that simultaneously infers the insider's control strategy and counteracts its negative influence. By injecting properly designed probing signals, the resulting mitigation policy asymptotically recovers the nominal optimal control law - one that would be achieved under full knowledge of the insider's objective. Simulation results validate the effectiveness of the proposed identification-mitigation framework and illustrate its capability to preserve team performance even in the presence of covert adversarial behavior."}
{"id": "2512.03333", "categories": ["quant-ph", "math.NA", "math.ST", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03333", "abs": "https://arxiv.org/abs/2512.03333", "authors": ["Xun Tang", "Haoxuan Chen", "Yuehaw Khoo", "Lexing Ying"], "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State", "comment": null, "summary": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation."}
{"id": "2512.03149", "categories": ["physics.comp-ph", "cond-mat.dis-nn", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03149", "abs": "https://arxiv.org/abs/2512.03149", "authors": ["Jinjing Yi", "Daniel Massatt", "Andrew Horning", "Mitchell Luskin", "J. H. Pixley", "Jason Kaye"], "title": "A high-order regularized delta-Chebyshev method for computing spectral densities", "comment": null, "summary": "We introduce a numerical method for computing spectral densities, and apply it to the evaluation of the local density of states (LDOS) of sparse Hamiltonians derived from tight-binding models. The approach, which we call the high-order delta-Chebyshev method, can be viewed as a variant of the popular regularized Chebyshev kernel polynomial method (KPM), but it uses a high-order accurate approximation of the $δ$-function to achieve rapid convergence to the thermodynamic limit for smooth spectral densities. The costly computational steps are identical to those for KPM, with high-order accuracy achieved by an inexpensive post-processing procedure. We apply the algorithm to tight-binding models of graphene and twisted bilayer graphene, demonstrating high-order convergence to the LDOS at non-singular points."}
{"id": "2512.03632", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.03632", "abs": "https://arxiv.org/abs/2512.03632", "authors": ["Robert E. Bird", "William M. Coombs", "Michael J. Brown", "Charles E. Augarde", "Yaseen U. Sharif", "Giuliano Pretti", "Catriona Macdonald", "Duncan Stevens", "Gareth Carter"], "title": "Three-dimensional modelling of drag anchor penetration using the material point method", "comment": "46 pages, 10 Tables, 27 Figures", "summary": "Drag embedment anchors are a key threat to buried subsea linear infrastructure, such as power/data cables and pipelines. For cables, selecting a burial depth is a compromise between protecting the cable from anchor strike and the increased cost of deeper installation. This presents an efficient large deformation, elasto-plastic Material Point Method-based soil-structure interaction predictive tool for the estimation of anchor penetration based on Cone Penetration Test (CPT) site investigation data. The tool builds on earlier work by the authors supplemented by three developments: modelling assemblies of rigid bodies (necessary for articulated anchors), a partitioned domain approach to enable accurate and efficient modelling of long anchor pulls and an improved means of modelling rotational inertia. The tool is validated against scaled physical tests conducted in a geotechnical centrifuge on sands with a range of relative densities with good agreement across the tested conditions. Numerical simulations identify key issues with the UK Cable Burial Risk Assessment (CBRA) approach for estimating anchor penetration and reveal the potentially non-conservatism of the CBRA framework for sandy seabeds. The numerical model enables site-specific anchor-penetration assessment along cable routes and can be used to evaluate the performance of different anchor designs and sizes in varied soil conditions."}
{"id": "2512.03103", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.03103", "abs": "https://arxiv.org/abs/2512.03103", "authors": ["Shampa Saha", "Shovan Roy"], "title": "Public Sentiment Analysis of Traffic Management Policies in Knoxville: A Social Media Driven Study", "comment": null, "summary": "This study presents a comprehensive analysis of public sentiment toward traffic management policies in Knoxville, Tennessee, utilizing social media data from Twitter and Reddit platforms. We collected and analyzed 7906 posts spanning January 2022 to December 2023, employing Valence Aware Dictionary and sEntiment Reasoner (VADER) for sentiment analysis and Latent Dirichlet Allocation (LDA) for topic modeling. Our findings reveal predominantly negative sentiment, with significant variations across platforms and topics. Twitter exhibited more negative sentiment compared to Reddit. Topic modeling identified six distinct themes, with construction-related topics showing the most negative sentiment while general traffic discussions were more positive. Spatiotemporal analysis revealed geographic and temporal patterns in sentiment expression. The research demonstrates social media's potential as a real-time public sentiment monitoring tool for transportation planning and policy evaluation."}
{"id": "2512.03149", "categories": ["physics.comp-ph", "cond-mat.dis-nn", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03149", "abs": "https://arxiv.org/abs/2512.03149", "authors": ["Jinjing Yi", "Daniel Massatt", "Andrew Horning", "Mitchell Luskin", "J. H. Pixley", "Jason Kaye"], "title": "A high-order regularized delta-Chebyshev method for computing spectral densities", "comment": null, "summary": "We introduce a numerical method for computing spectral densities, and apply it to the evaluation of the local density of states (LDOS) of sparse Hamiltonians derived from tight-binding models. The approach, which we call the high-order delta-Chebyshev method, can be viewed as a variant of the popular regularized Chebyshev kernel polynomial method (KPM), but it uses a high-order accurate approximation of the $δ$-function to achieve rapid convergence to the thermodynamic limit for smooth spectral densities. The costly computational steps are identical to those for KPM, with high-order accuracy achieved by an inexpensive post-processing procedure. We apply the algorithm to tight-binding models of graphene and twisted bilayer graphene, demonstrating high-order convergence to the LDOS at non-singular points."}
{"id": "2512.03255", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.03255", "abs": "https://arxiv.org/abs/2512.03255", "authors": ["Federica Spoto", "Alessia Caponera", "Pierpaolo Brutti"], "title": "Change Point Detection for Functional Autoregressive Processes on the Sphere", "comment": null, "summary": "We introduce a novel framework for change point detection in spherical functional autoregressive (SPHAR) processes, enabling the identification of structural breaks in spatio-temporal random fields on the sphere. Our LASSO-regularized estimator, based on penalized dynamic programming in the harmonic domain, operates without knowledge of the number or locations of change points and offers non-asymptotic theoretical guarantees. This approach provides a new tool for analyzing nonstationary phenomena on the sphere, relevant to climate science, cosmology, and beyond."}
{"id": "2512.03395", "categories": ["cond-mat.stat-mech", "hep-lat"], "pdf": "https://arxiv.org/pdf/2512.03395", "abs": "https://arxiv.org/abs/2512.03395", "authors": ["Satoshi Morita", "Naoki Kawashima"], "title": "Tensor renormalization group calculations of partition-function ratios", "comment": "9 pages, 7 figures", "summary": "The behavior of dimensionless quantities defined as ratios of partition functions is analyzed to investigate phase transitions and critical phenomena. At criticality, the universal values of these ratios can be predicted from conformal field theory (CFT) through the modular-invariant partition functions on a torus. We perform numerical calculations using the bond-weighted tensor renormalization group for three two-dimensional models belonging to different universality classes: the Ising model, the three-state Potts model, and the four-state Potts model. The partition-function ratios obey the same finite-size scaling form as the Binder parameter, and their critical values agree well with the universal values predicted by CFT. In the four-state Potts model, we observe logarithmic corrections in the system-size dependence of these ratios."}
{"id": "2512.03545", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03545", "abs": "https://arxiv.org/abs/2512.03545", "authors": ["Nicolas Kirsch", "Catalin Arghir", "Silvia Mastellone", "Giancarlo Ferrari-Trecate"], "title": "Resilient AFE Drive Control using Neural Networks with Tracking Guarantees", "comment": null, "summary": "Industrial installations across several sectors have seen a dramatic increase in productivity, accuracy and efficiency over the last decade due to expanded utilization of medium voltage, variable speed power electronic converters to drive their processes. Specifically, active front-end (AFE) drives have become popular due to their ability to deliver power while maintaining safe electrical setpoints. However, under abnormal grid conditions such as phase loss, conventional AFE control may fail to enforce safety constraints, potentially leading to drive shutdown and significant financial losses. In this work, we propose using reference-tracking Performance Boosting (rPB) to improve the resilience of standard AFE control to faults. This neural-network control framework provides a principled way to optimize transient performance while preserving the steady-state tracking properties of AFE-based drives. By carefully shaping the input signals to the rPB controller, we ensure that it activates only during grid faults, leaving nominal operation unaffected. Simulation results show that the proposed approach successfully maintains the DC bus voltage and the grid current within safe limits during single-phase loss events."}
{"id": "2512.03545", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03545", "abs": "https://arxiv.org/abs/2512.03545", "authors": ["Nicolas Kirsch", "Catalin Arghir", "Silvia Mastellone", "Giancarlo Ferrari-Trecate"], "title": "Resilient AFE Drive Control using Neural Networks with Tracking Guarantees", "comment": null, "summary": "Industrial installations across several sectors have seen a dramatic increase in productivity, accuracy and efficiency over the last decade due to expanded utilization of medium voltage, variable speed power electronic converters to drive their processes. Specifically, active front-end (AFE) drives have become popular due to their ability to deliver power while maintaining safe electrical setpoints. However, under abnormal grid conditions such as phase loss, conventional AFE control may fail to enforce safety constraints, potentially leading to drive shutdown and significant financial losses. In this work, we propose using reference-tracking Performance Boosting (rPB) to improve the resilience of standard AFE control to faults. This neural-network control framework provides a principled way to optimize transient performance while preserving the steady-state tracking properties of AFE-based drives. By carefully shaping the input signals to the rPB controller, we ensure that it activates only during grid faults, leaving nominal operation unaffected. Simulation results show that the proposed approach successfully maintains the DC bus voltage and the grid current within safe limits during single-phase loss events."}
{"id": "2512.03376", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03376", "abs": "https://arxiv.org/abs/2512.03376", "authors": ["Yu-Wei Li", "Gui-Hua Lin", "Xide Zhu"], "title": "Theoretical and numerical comparison of seven single-level reformulations for bilevel programs", "comment": null, "summary": "This paper considers a bilevel program. To solve this bilevel program, it is generally necessary to transform it into some single-level optimization problem. One approach is to replace the lower-level program by its KKT conditions to transform the bilevel program as a mathematical program with complementarity constraints (MPCC). Another approach is to apply the lower-level Wolfe/Mond-Weir/extended Mond-Weir duality to transform the bilevel program into some duality-based single-level reformulations, called WDP, MDP, and eMDP respectively in the literature. In this paper, inspired by a conjecture from a recent publication that the tighter feasible region of a reformulation, the better its numerical performance, we present three new duality-based single-level reformulations, called TWDP/TMDP/eTMDP, with tighter feasible regions. Our main goal is to compare all above-mentioned reformulations by designing some direct and relaxation algorithms with projection and implementing these algorithms on 450 test examples generated randomly. Our numerical experiments show that, whether overall comparison or pairwise comparison, at least in our tests, the WDP/MDP/TWDP/TMDP reformulations were always better than the MPCC reformulation, while the eMDP/eTMDP reformulations were always the worst ones among six duality-based reformulations, which indicates that the above conjecture is incorrect. In particular, for the relaxation algorithms, the WDP/MDP/TWDP/TMDP reformulations performed 3-5 times better than the MPCC reformulation, while the eMDP/eTMDP reformulations performed 2 times better than the MPCC reformulation."}
{"id": "2512.03496", "categories": ["math.NA", "gr-qc", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.03496", "abs": "https://arxiv.org/abs/2512.03496", "authors": ["Yuchen Huang", "Manting Peng", "Kailiang Wu"], "title": "Constraint-Preserving High-Order Compact OEDG Method for Spherically Symmetric Einstein-Euler System", "comment": null, "summary": "Numerical simulation of the spherically symmetric Einstein--Euler (EE) system faces severe challenges due to the stringent physical admissibility constraints of relativistic fluids and the geometric singularities inherent in metric evolution. This paper proposes a high-order Constraint-Preserving (CP) compact Oscillation-Eliminating Discontinuous Galerkin (cOEDG) method specifically tailored to address these difficulties. The method integrates a scale-invariant oscillation-eliminating mechanism [M. Peng, Z. Sun, K. Wu, Math. Comp., 94: 1147--1198, 2025] into a compact Runge--Kutta DG framework. By characterizing the convex invariant region of the hydrodynamic subsystem with general barotropic equations of state, we prove that the proposed scheme preserves physical realizability (specifically, positive density and subluminal velocity) directly in terms of conservative variables, thereby eliminating the need for complex primitive-variable checks. To ensure the geometric validity of the spacetime, we introduce a bijective transformation of the metric potentials. Rather than evolving the constrained metric components directly, the scheme advances unconstrained auxiliary variables whose inverse mapping automatically enforces strict positivity and asymptotic bounds without any limiters. Combined with a compatible high-order boundary treatment, the resulting CPcOEDG method exhibits robust stability and design-order accuracy in capturing strong gravity-fluid interactions, as demonstrated by simulations of black hole accretion and relativistic shock waves."}
{"id": "2512.03530", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03530", "abs": "https://arxiv.org/abs/2512.03530", "authors": ["Yoshihito Kuno"], "title": "Edge bits in average symmetry protected topological mixed state", "comment": "6+4 pages, 3+2 figures", "summary": "Edge bit in an average symmetry protected topological (ASPT) mixed state is studied. The state is protected by one strong $Z_2$ and one weak (average) $Z_2$ symmetries. As analogous objects of pure symmetry protected topological (SPT) states, the ASPT possesses edge bits. In particular, the analogous operator response exists, that is, symmetry fractionalization. The fractionalization preserves the presence of the ASPT in the bulk, and the fractionalized edge operators acting on the edge bits of the ASPT. %analogous to the ones in the pure SPTs. In this work, based on the cluster model and by employing Choi mapping, we discuss generic features of the edge bits and numerically clarify the behavior of the edge bits and their robustness for varying decoherence and perturbative interactions. By using an operator-space mutual information (OSMI), we track the flow of quantum correlations between the two edges. Remarkably, even in the ASPT regime, a finite portion of the initial edge-to-edge correlation survives."}
{"id": "2512.03650", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.03650", "abs": "https://arxiv.org/abs/2512.03650", "authors": ["Francis Filbet", "L Miguel Rodrigues", "Kim Han Trinh"], "title": "Convergence analysis of a Crank-Nicolson scheme for strongly magnetized plasmas", "comment": null, "summary": "The present paper is devoted to the convergence analysis of an asymptotic preserving particle scheme designed to serve as a particle pusher in a Particle-In-Cell (PIC) method for the Vlasov equation with a strong inhomogeneous magnetic field. The asymptotic preserving scheme that we study removes classical strong restrictive stability constraints on discretization steps while capturing the large-scale dynamics, even when the discretization is too coarse to capture fastest scales. Our error bounds are explicit regarding the discretization and stiffness parameters and match sharply numerical tests. The present analysis is expected to be representative of the general analysis of a class of schemes, developed by the authors, conceived as implicit-explicit schemes on augmented formulations."}
{"id": "2512.03296", "categories": ["cs.SI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03296", "abs": "https://arxiv.org/abs/2512.03296", "authors": ["Hsiao-Ying Lu", "Kwan-Liu Ma"], "title": "Associating Healthcare Teamwork with Patient Outcomes for Predictive Analysis", "comment": null, "summary": "Cancer treatment outcomes are influenced not only by clinical and demographic factors but also by the collaboration of healthcare teams. However, prior work has largely overlooked the potential role of human collaboration in shaping patient survival. This paper presents an applied AI approach to uncovering the impact of healthcare professionals' (HCPs) collaboration-captured through electronic health record (EHR) systems-on cancer patient outcomes. We model EHR-mediated HCP interactions as networks and apply machine learning techniques to detect predictive signals of patient survival embedded in these collaborations. Our models are cross validated to ensure generalizability, and we explain the predictions by identifying key network traits associated with improved outcomes. Importantly, clinical experts and literature validate the relevance of the identified crucial collaboration traits, reinforcing their potential for real-world applications. This work contributes to a practical workflow for leveraging digital traces of collaboration and AI to assess and improve team-based healthcare. The approach is potentially transferable to other domains involving complex collaboration and offers actionable insights to support data-informed interventions in healthcare delivery."}
{"id": "2512.03162", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03162", "abs": "https://arxiv.org/abs/2512.03162", "authors": ["George Grattan", "Pratik Sathe", "Cristiano Nisoli"], "title": "Classical Thermometry of Quantum Annealers", "comment": "George Grattan and Pratik Sathe contributed equally", "summary": "Quantum annealers are emerging as programmable, dynamical experimental platforms for probing strongly correlated spin systems. Yet key thermal assumptions, chiefly a Gibbs-distributed output ensemble, remain unverified in the large-scale regime. Here, we experimentally and quantitatively assess Gibbs sampling fidelity across system sizes spanning over three orders of magnitude. We explore a wide parameter space of coupling strengths, system sizes, annealing times, and D-wave hardware architectures. We find that the naively assumed scaling law for the effective temperature requires a non-negligible, coupling-independent offset that is robust across machines and parameter regimes, quantifying residual non-thermal effects that still conform to an effective Gibbs description. These non-idealities are further reflected in a systematic discrepancy between the physical temperature inferred from the sampled ensemble and the nominal cryogenic temperature of the device. Our results systematically assess the viability of quantum annealers as experimental platforms for probing classical thermodynamics, correct previous assumptions, and provide a physically grounded thermometry framework to benchmark these machines for future thermodynamic experiments."}
{"id": "2512.03266", "categories": ["stat.ME", "math.ST", "stat.OT"], "pdf": "https://arxiv.org/pdf/2512.03266", "abs": "https://arxiv.org/abs/2512.03266", "authors": ["Merlise A Clyde"], "title": "Invited Discussion of \"Model Uncertainty and Missing Data: An Objective Bayesian Perspective\" by Gonzalo García-Donato , María Eugenia Castellanos , Stefano Cabras Alicia Quirós , and Anabel Forte", "comment": null, "summary": "The article by Garc{í}a-Donato and co-authors addresses the dual challenges of accounting for model uncertainty and missing data within the Gaussian regression frameworks from an objective Bayesian perspective. Thru the use of an imputation $g$-prior that replaces $X_γ^TX_γ$ for model $γ$ in the covariance of $β_γ$ with $Σ_{X_γ}$, the authors develop a coherent approach to addressing the missing data problem and model uncertainty simultaneously with random $X_γ$ in the missing at random (MAR) or missing completely at random (MCAR) settings, while still being computationally tractable. I discuss the connection of the imputation $g$-prior to the $g$-prior with imputed $X$, and to model selection for graphical models that provide an alternative justification for the $g$-prior for random $X$s."}
{"id": "2512.03857", "categories": ["cond-mat.stat-mech", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.03857", "abs": "https://arxiv.org/abs/2512.03857", "authors": ["Cecile Monthus"], "title": "Classification of diffusion processes in dimension $d$ via the Carleman approach with applications to models involving additive, multiplicative or square-root noises", "comment": "69 pages", "summary": "The Carleman approach is well-known in the field of deterministic classical dynamics as a method to replace a finite number $d$ of non-linear differential equations by an infinite-dimensional linear system. Here this approach is applied to a system of $d$ stochastic differential equations for $[x_1(t),..,x_d(t)]$ when the forces and the diffusion-matrix elements are polynomials, in order to write the linear system governing the dynamics of the averaged values ${\\mathbb E} ( x_1^{n_1}(t) x_2^{n_2}(t) ... x_d^{n_d}(t) )$ labelled by the $d$ integers $(n_1,..,n_d)$. The natural decomposition of the Carleman matrix into blocks associated to the global degree $n=n_1+n_2+..+n_d$ is useful to identify the models that have the simplest spectral decompositions in the bi-orthogonal basis of right and left eigenvectors. This analysis is then applied to models with a single noise per coordinate, that can be either additive or multiplicative or square-root, or with two types of noises per coordinate, with many examples in dimensions $d=1,2$. In $d=1$, the Carleman matrix governing the dynamics of the moments ${\\mathbb E} ( x^{n}(t) )$ is diagonal for the Geometric Brownian motion, while it is lower-triangular for the family of Pearson diffusions containing the Ornstein-Uhlenbeck and the Square-Root processes, as well as the Kesten, the Fisher-Snedecor and the Student processes that converge towards steady states with power-law-tails. In dimension $d=2$, the Carleman matrix governing the dynamics of the correlations ${\\mathbb E} ( x_1^{n_1}(t) x_2^{n_2}(t) )$ has a natural decomposition into blocks associated to the global degree $n=n_1+n_2$, and we discuss the simplest models where the Carleman matrix is either block-diagonal or block-lower-triangular or block-upper-triangular."}
{"id": "2512.03604", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03604", "abs": "https://arxiv.org/abs/2512.03604", "authors": ["Abbas Tariverdi"], "title": "Physics-Based Communication Compression via Lyapunov-Weighted Event-Triggered Control", "comment": null, "summary": "Event-Triggered Control (ETC) reduces communication overhead in networked systems by transmitting only when stability requires it. Conventional mechanisms use isotropic error thresholds ($\\|e\\| \\le σ\\|x\\|$), treating all directions equally. This ignores stability geometry and triggers conservatively. We propose a static directional triggering mechanism that exploits this asymmetry. By weighting errors via the Lyapunov matrix $P$, we define an anisotropic half-space scaling with instantaneous energy margins: larger deviations tolerated along stable modes, strict bounds where instability threatens. We prove global asymptotic stability and exclusion of Zeno behavior. Monte Carlo simulations ($N=100$) show 43.6\\% fewer events than optimally tuned isotropic methods while achieving $2.1\\times$ better control performance than time-varying alternatives. The mechanism functions as a runtime safety gate for learning-based controllers operating under communication constraints."}
{"id": "2512.03604", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03604", "abs": "https://arxiv.org/abs/2512.03604", "authors": ["Abbas Tariverdi"], "title": "Physics-Based Communication Compression via Lyapunov-Weighted Event-Triggered Control", "comment": null, "summary": "Event-Triggered Control (ETC) reduces communication overhead in networked systems by transmitting only when stability requires it. Conventional mechanisms use isotropic error thresholds ($\\|e\\| \\le σ\\|x\\|$), treating all directions equally. This ignores stability geometry and triggers conservatively. We propose a static directional triggering mechanism that exploits this asymmetry. By weighting errors via the Lyapunov matrix $P$, we define an anisotropic half-space scaling with instantaneous energy margins: larger deviations tolerated along stable modes, strict bounds where instability threatens. We prove global asymptotic stability and exclusion of Zeno behavior. Monte Carlo simulations ($N=100$) show 43.6\\% fewer events than optimally tuned isotropic methods while achieving $2.1\\times$ better control performance than time-varying alternatives. The mechanism functions as a runtime safety gate for learning-based controllers operating under communication constraints."}
{"id": "2512.03410", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03410", "abs": "https://arxiv.org/abs/2512.03410", "authors": ["Steven van Leeuwen", "Ilya Kolmanovsky"], "title": "Suboptimal Shrinking Horizon MPC with a Lower Hessian Condition Number from Adjustable Terminal Cost", "comment": null, "summary": "A strategy for reducing the number of iterations and computational burden in shrinking horizon Model Predictive Control (SH-MPC) when steering into a prescribed terminal set despite unmeasured disturbances is proposed. This strategy exploits dynamic adjustment of the terminal cost weight and horizon length while ensuring that the terminal set is reached within a desired number of steps. A lower Hessian condition number which facilitates the computational reduction is proved under assumptions, and an example of spacecraft nutation damping using the proposed approach is reported."}
{"id": "2512.03093", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03093", "abs": "https://arxiv.org/abs/2512.03093", "authors": ["Isaac Dobes"], "title": "New Identity for Cayley's First Hyperdeterminant with Applications to Symmetric Tensors and Entanglement", "comment": "16 pages", "summary": "In this article, a new formula for computing Cayley's first hyperdeterminant in terms of the Levi-Civita symbol is given. It is then shown that this formula can be used to compute the hyperdeterminant of symmetric hypermatrices in polynomial time with respect to their order (assuming fixed side length). Applications to the quantum entanglement of bosons are then discussed. Additionally, in order to obtain the fast calculation of the hyperdeterminant on symmetric hypermatrices, hypermatrix generalizations of elimination and duplication matrices are defined, and explicit formulas for them are derived in the appendix of this article."}
{"id": "2512.03898", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03898", "abs": "https://arxiv.org/abs/2512.03898", "authors": ["Yu Wang", "Martina Nibbi", "Maxine Luo", "Isabel Nha Minh Le", "Yanbin Chen", "J. Ignacio Cirac", "Christian Mendl"], "title": "Polylogarithmic-Depth Quantum Algorithm for Simulating the Extended Hubbard Model on a Two-Dimensional Lattice Using the Fast Multipole Method", "comment": null, "summary": "The extended Hubbard model on a two-dimensional lattice captures key physical phenomena, but is challenging to simulate due to the presence of long-range interactions. In this work, we present an efficient quantum algorithm for simulating the time evolution of this model. Our approach, inspired by the fast multipole method, approximates pairwise interactions by interactions between hierarchical levels of coarse-graining boxes. We discuss how to leverage recent advances in two-dimensional neutral atom quantum computing, supporting non-local operations such as long-range gates and shuttling. The resulting circuit depth for a single Trotter step scales polylogarithmically with system size."}
{"id": "2512.03679", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.03679", "abs": "https://arxiv.org/abs/2512.03679", "authors": ["Thi Tam Dang", "Trung Hau Hoang"], "title": "From Memory Model to CPU Time: Exponential Integrators for Advection-Dominated Problems", "comment": "14 pages, 11 figures", "summary": "In this paper, we investigate the application of exponential integrators to advection-dominated problems. We focus on Krylov subspace and Leja interpolation methods to compute the action of exponential and related matrix functions. Complementing our earlier paper, arXiv:2410.12765 (to appear in Advances in Applied Mathematics and Mechanics, 2025) based on a performance model, we extend the numerical investigation to higher-order Krylov approximations and new numerical regime, and assess their CPU-time efficiency relative to explicit Runge--Kutta schemes. We show that, depending on the problem setting, exponential integrators can either outperform or match explicit Runge--Kutta schemes. We also observe that Leja-based methods outperform Krylov iterations for large time steps, whereas for small time steps, Krylov-based methods provide better results than Leja-based methods."}
{"id": "2512.03337", "categories": ["cs.SI", "cs.CL", "cs.CY", "cs.DL"], "pdf": "https://arxiv.org/pdf/2512.03337", "abs": "https://arxiv.org/abs/2512.03337", "authors": ["Aliakbar Mehdizadeh", "Martin Hilbert"], "title": "Epistemic Substitution: How Grokipedia's AI-Generated Encyclopedia Restructures Authority", "comment": null, "summary": "A quarter century ago, Wikipedia's decentralized, crowdsourced, and consensus-driven model replaced the centralized, expert-driven, and authority-based standard for encyclopedic knowledge curation. The emergence of generative AI encyclopedias, such as Grokipedia, possibly presents another potential shift in epistemic evolution. This study investigates whether AI- and human-curated encyclopedias rely on the same foundations of authority. We conducted a multi-scale comparative analysis of the citation networks from 72 matched article pairs, which cite a total of almost 60,000 sources. Using an 8-category epistemic classification, we mapped the \"epistemic profiles\" of the articles on each platform. Our findings reveal several quantitative and qualitative differences in how knowledge is sourced and encyclopedia claims are epistemologically justified. Grokipedia replaces Wikipedia's heavy reliance on peer-reviewed \"Academic & Scholarly\" work with a notable increase in \"User-generated\" and \"Civic organization\" sources. Comparative network analyses further show that Grokipedia employs very different epistemological profiles when sourcing leisure topics (such as Sports and Entertainment) and more societal sensitive civic topics (such as Politics & Conflicts, Geographical Entities, and General Knowledge & Society). Finally, we find a \"scaling-law for AI-generated knowledge sourcing\" that shows a linear relationship between article length and citation density, which is distinct from collective human reference sourcing. We conclude that this first implementation of an LLM-based encyclopedia does not merely automate knowledge production but restructures it. Given the notable changes and the important role of encyclopedias, we suggest the continuation and deepening of algorithm audits, such as the one presented here, in order to understand the ongoing epistemological shifts."}
{"id": "2512.03316", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.03316", "abs": "https://arxiv.org/abs/2512.03316", "authors": ["Issei Sakai", "Takuma Akimoto"], "title": "Symmetry Breaking of Current Response in Disordered Exclusion Processes", "comment": "6 pages, 3 figures + 7 pages of supplemental material", "summary": "The bias-reversal symmetry -- where reversing an external bias inverts the current without changing its magnitude -- is a hallmark of nonequilibrium transport. While this property holds in homogeneous systems such as the asymmetric simple exclusion process, how disorder and its interplay with particle interactions affect this symmetry has remained unclear. Here, we establish a general criterion showing that the bias-reversal symmetry holds if and only if the local left-right bond-bias ratio is spatially uniform. Analytical and numerical analyses reveal that bond disorder preserves the symmetry beyond linear response, whereas site disorder breaks it through an interplay between heterogeneity and particle interactions. Our results demonstrate how environmental disorder and interparticle interactions cooperate to generate asymmetric transport, thereby providing a unified theoretical framework relevant to transport through biological and artificial nanochannels."}
{"id": "2512.03543", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.03543", "abs": "https://arxiv.org/abs/2512.03543", "authors": ["Pavel Krupskii", "Boris Berangér"], "title": "Parsimonious Factor Models for Asymmetric Dependence in Multivariate Extremes", "comment": "51 pages, 8 figures, and 4 tables", "summary": "Modelling multivariate extreme events is essential when extrapolating beyond the range of observed data. Parametric models that are suitable for real-world extremes must be flexible -- particularly in their ability to capture asymmetric dependence structures -- while also remaining parsimonious for interpretability and computationally scalable in high dimensions. Although many models have been proposed, it is rare for any single construction to satisfy all of these requirements. For instance, the popular Hüsler-Reiss model is limited to symmetric dependence structures. In this manuscript, we introduce a class of additive factor models and derive their extreme-value limits. This leads to a broad and tractable family of models characterised by a manageable number of parameters. These models naturally accommodate asymmetric tail dependence and allow for non-stationary behaviour. We present the limiting models from both the componentwise-maxima and Peaks-over-Thresholds perspectives, via the multivariate extreme value and multivariate generalized Pareto distributions, respectively. Simulation studies illustrate identifiability properties based on existing inference methodologies. Finally, applications to summer temperature maxima in Melbourne, Australia, and to weekly negative returns from four major UK banks demonstrate improved fit compared with the Hüsler-Reiss model."}
{"id": "2512.03950", "categories": ["cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.03950", "abs": "https://arxiv.org/abs/2512.03950", "authors": ["Paul Pineau", "Samuel Bell", "Raphaël Voituriez", "Ram M. Adar"], "title": "Collective dynamics of trail-interacting particles", "comment": "19 pages, 8 figures, submitted to PRL", "summary": "Trail interactions occur when past particle trajectories bias future motion, rendering the system out of thermodynamic equilibrium. While such systems are abundant in nature, their understanding is limited to the single-particle level or phenomenological mean-field theories. Here, we introduce a minimal model of many trail-interacting particles that extends this paradigm to the fluctuating collective level. Particles diffuse while depositing long-lasting repelling/attracting trails that act as a shared memory field, coupling their dynamics across time and space. Using stochastic density functional theory, we derive fluctuating hydrodynamic equations and analyze analytically and numerically the resulting behaviors. We show that memory, coupled with fluctuations, fundamentally reshapes collective dynamics; In the repulsive case, the particle density displays superdiffusive spreading characterized by transient clustering and ballistic motion; In the attractive case, the system condensates in finite time into frozen, localized states. Our results establish general principles for trail-interacting systems and reveal how persistent fields generate novel instabilities and self-organization."}
{"id": "2512.03605", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03605", "abs": "https://arxiv.org/abs/2512.03605", "authors": ["Eduardo Espindola", "Yu Tang"], "title": "A Perception-feedback position-tracking control for quadrotors", "comment": null, "summary": "In this paper a position-tracking controller for quadrotors based on perception feedback is developed, which directly uses measurements from onboard sensors such as low cost IMUs and GPS to generate the control commands without state estimation. Bias in gyros sensors are corrected to enhance the tracking performance. Practical stability of the origin of the tracking error system in the presence of external disturbances is proved using the Lyapunov analysis, which turns out to exponential stability in the absence of external disturbances. Numerical simulations are included to illustrate the proposed control scheme and to verify the robustness of the proposed controller under noisy measurements and parameter uncertainties."}
{"id": "2512.03605", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03605", "abs": "https://arxiv.org/abs/2512.03605", "authors": ["Eduardo Espindola", "Yu Tang"], "title": "A Perception-feedback position-tracking control for quadrotors", "comment": null, "summary": "In this paper a position-tracking controller for quadrotors based on perception feedback is developed, which directly uses measurements from onboard sensors such as low cost IMUs and GPS to generate the control commands without state estimation. Bias in gyros sensors are corrected to enhance the tracking performance. Practical stability of the origin of the tracking error system in the presence of external disturbances is proved using the Lyapunov analysis, which turns out to exponential stability in the absence of external disturbances. Numerical simulations are included to illustrate the proposed control scheme and to verify the robustness of the proposed controller under noisy measurements and parameter uncertainties."}
{"id": "2512.03516", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03516", "abs": "https://arxiv.org/abs/2512.03516", "authors": ["Qi Lü", "Bowen Ma", "Enrique Zuazua"], "title": "Mean-Square Stability of Continuous-Time Stochastic Model Predictive Control", "comment": null, "summary": "We propose a stochastic model predictive control (SMPC) framework for a broad class of unconstrained controlled stochastic differential equations (SDEs) and establish its mean-square exponential stability in the infinite-horizon limit. At each prediction step of the MPC iteration, the nonlinear controlled SDE is approximated by its linearization at the origin, with the sampled state of the nonlinear system as initial condition, yielding a finite-horizon stochastic linear-quadratic (SLQ) optimal control problem. The resulting optimal control is then applied to the original nonlinear stochastic dynamics until the next sampling instant. This construction leads to a delayed SMPC scheme whose closed-loop behavior is governed by a coupled time-delay SDE system, a setting that has not been analyzed before. We prove global mean-square exponential stability for linear and mildly nonlinear SDEs by exploiting the exponential convergence of the Riccati equation to the algebraic Riccati equation (ARE). For strongly nonlinear SDEs, we establish local mean-square exponential stability by combining exponential Riccati convergence with stopping-time techniques and Grönwall-type estimates. It is observed that, to ensure the desired local stability properties, the nonlinearities of the SDE are allowed to have polynomial growth but not exponential growth, distinguishing SMPC from its deterministic counterpart.\n  These results provide the first rigorous mean-square stability guarantees for SMPC of SDE systems with delayed state information, thereby advancing the theoretical foundations of stochastic predictive control."}
{"id": "2512.03094", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03094", "abs": "https://arxiv.org/abs/2512.03094", "authors": ["Tomás Villalba-Ferreiro", "Eduardo Mosqueira-Rey", "Diego Alvarez-Estevez"], "title": "Performance Analysis of Quantum Support Vector Classifiers and Quantum Neural Networks", "comment": "7 pages, 7 figures, conference", "summary": "This study explores the performance of Quantum Support Vector Classifiers (QSVCs) and Quantum Neural Networks (QNNs) in comparison to classical models for machine learning tasks. By evaluating these models on the Iris and MNIST-PCA datasets, we find that quantum models tend to outperform classical approaches as the problem complexity increases. While QSVCs generally provide more consistent results, QNNs exhibit superior performance in higher-complexity tasks due to their increased quantum load. Additionally, we analyze the impact of hyperparameter tuning, showing that feature maps and ansatz configurations significantly influence model accuracy. We also compare the PennyLane and Qiskit frameworks, concluding that Qiskit provides better optimization and efficiency for our implementation. These findings highlight the potential of Quantum Machine Learning (QML) for complex classification problems and provide insights into model selection and optimization strategies"}
{"id": "2512.03733", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.03733", "abs": "https://arxiv.org/abs/2512.03733", "authors": ["Yingzhou Li", "Jingyu Liu"], "title": "A Superfast Direct Solver for Type-III Inverse Nonuniform Discrete Fourier Transform", "comment": null, "summary": "The nonuniform discrete Fourier transform (NUDFT) and its inverse are widely used in various fields of scientific computing. In this article, we propose a novel superfast direct inversion method for type-III NUDFT. The proposed method approximates the type-III NUDFT matrix as a product of a type-II NUDFT matrix and an HSS matrix, where the type-II NUDFT matrix is further decomposed into the product of an HSS matrix and an uniform discrete Fourier transform (DFT) matrix as in [Wilber, Epperly, and Barnett, SIAM Journal on Scientific Computing, 47(3):A1702-A1732, 2025]. This decomposition enables both the forward application and the backward inversion to be accomplished with quasi-linear complexity. The fast inversion can serve as a high-accuracy direct solver or as an efficient preconditioner. Additionally, we provide an error bound for the approximation under specific sample distributions. Numerical results are presented to verify the relevant theoretical properties and demonstrate the efficiency of the proposed methods."}
{"id": "2512.03766", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.03766", "abs": "https://arxiv.org/abs/2512.03766", "authors": ["Katherine Betz"], "title": "Inaccessibility in Public Transit Networks", "comment": "12 figures, 4 tables", "summary": "The study of networks derived from infrastructure systems has received considerable attention, yet the accessibility of such systems, particularly within public transit networks, remains comparatively underexplored. Accessibility encompasses a broad range of considerations, from infrastructure-based features such as elevators and step-free access to spatial factors such as the geographic distribution of accessible stations. In this work, we investigate infrastructure-based accessibility in two major transit systems: the London Underground and the New York City Subway. We construct network models in which nodes represent accessible stations and edges represent adjacency along transit lines. Using tools from network analysis, we examine the structural properties of these accessibility networks, including clustering patterns and the spatial distribution of accessible nodes. We further employ centrality measures to identify stations that serve as major accessible hubs. Finally, we analyze socioeconomic and tourism-related variables to assess the influence of neighborhood wealth and popularity on the prevalence of accessible stations. Our findings highlight significant disparities in accessibility across both systems and demonstrate the utility of mathematical and network-theoretic methods in understanding and improving modern transit infrastructure."}
{"id": "2512.03738", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.03738", "abs": "https://arxiv.org/abs/2512.03738", "authors": ["Jaeyoung Shin", "Chi Hyun Lee", "Sangwook Kang"], "title": "Weighted Conformal Prediction for Survival Analysis under Covariate Shift", "comment": "16 pages, 0 figure", "summary": "Reliable uncertainty quantification is essential in survival prediction, particularly in clinical settings where erroneous decisions carry high risk. Conformal prediction has attracted substantial attention as it offers a model-agnostic framework with finite-sample coverage guarantees. Extending it to right-censored outcomes poses nontrivial challenges. Several adaptations of conformal approaches for survival outcomes have been developed, but they either rely on restrictive censoring settings or substantial computation. A recent conformal approach for right-censored data constructs censoring-adjusted p-values and enables prediction intervals in general survival settings. However, the empirical coverage depends sensitively on heuristic tuning choices and its validity is limited to scenarios without covariate shift. In this paper, we establish theoretical justification for its prediction-set construction, providing a principled basis for defining prediction-set bounds, and extend the approach to covariate-shift settings. Simulation studies and a real data application demonstrate that the proposed method achieves robust coverage and coherent interval structure across varying censoring levels and covariate-shift settings."}
{"id": "2512.03162", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03162", "abs": "https://arxiv.org/abs/2512.03162", "authors": ["George Grattan", "Pratik Sathe", "Cristiano Nisoli"], "title": "Classical Thermometry of Quantum Annealers", "comment": "George Grattan and Pratik Sathe contributed equally", "summary": "Quantum annealers are emerging as programmable, dynamical experimental platforms for probing strongly correlated spin systems. Yet key thermal assumptions, chiefly a Gibbs-distributed output ensemble, remain unverified in the large-scale regime. Here, we experimentally and quantitatively assess Gibbs sampling fidelity across system sizes spanning over three orders of magnitude. We explore a wide parameter space of coupling strengths, system sizes, annealing times, and D-wave hardware architectures. We find that the naively assumed scaling law for the effective temperature requires a non-negligible, coupling-independent offset that is robust across machines and parameter regimes, quantifying residual non-thermal effects that still conform to an effective Gibbs description. These non-idealities are further reflected in a systematic discrepancy between the physical temperature inferred from the sampled ensemble and the nominal cryogenic temperature of the device. Our results systematically assess the viability of quantum annealers as experimental platforms for probing classical thermodynamics, correct previous assumptions, and provide a physically grounded thermometry framework to benchmark these machines for future thermodynamic experiments."}
{"id": "2512.03615", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03615", "abs": "https://arxiv.org/abs/2512.03615", "authors": ["Kaouther Moussa", "Dimitri Peaucelle"], "title": "Covariance Control for a class of Stochastic Discrete-time Linear Systems using the S-Variable Approach", "comment": null, "summary": "This paper deals with the problem of covariance control for a class of linear stochastic discrete-time systems in the Stochastic Model Predictive Control (SMPC) framework. The considered systems are affected by independent and identically distributed (i.i.d.) additive and parametric stochastic uncertainties (potentially unbounded), in addition to polytopic deterministic uncertainties bounding the mean of the state and input parameters. The control design conditions presented in this paper are formulated as Linear Matrix Inequalities (LMIs), using the S-variable approach in order to reduce the potential conservatism. These conditions are derived using a deterministic exact characterization of the covariance dynamics, the latter involves bilinear terms in the control gain. A technique to linearize such dynamics is presented, it results in a descriptor representation allowing to derive sufficient conditions for covariance control design. The derived condition is firstly compared to a known necessary and sufficient stability condition for systems without deterministic uncertainties and additive stochastic noise, although more conservative, it turns out to be more numerically tractable. Then, the same condition is used to design controllers that are robust to both deterministic and stochastic uncertainties. Several numerical examples are presented for comparison and illustration."}
{"id": "2512.03615", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03615", "abs": "https://arxiv.org/abs/2512.03615", "authors": ["Kaouther Moussa", "Dimitri Peaucelle"], "title": "Covariance Control for a class of Stochastic Discrete-time Linear Systems using the S-Variable Approach", "comment": null, "summary": "This paper deals with the problem of covariance control for a class of linear stochastic discrete-time systems in the Stochastic Model Predictive Control (SMPC) framework. The considered systems are affected by independent and identically distributed (i.i.d.) additive and parametric stochastic uncertainties (potentially unbounded), in addition to polytopic deterministic uncertainties bounding the mean of the state and input parameters. The control design conditions presented in this paper are formulated as Linear Matrix Inequalities (LMIs), using the S-variable approach in order to reduce the potential conservatism. These conditions are derived using a deterministic exact characterization of the covariance dynamics, the latter involves bilinear terms in the control gain. A technique to linearize such dynamics is presented, it results in a descriptor representation allowing to derive sufficient conditions for covariance control design. The derived condition is firstly compared to a known necessary and sufficient stability condition for systems without deterministic uncertainties and additive stochastic noise, although more conservative, it turns out to be more numerically tractable. Then, the same condition is used to design controllers that are robust to both deterministic and stochastic uncertainties. Several numerical examples are presented for comparison and illustration."}
{"id": "2512.03524", "categories": ["math.OC", "cs.ET", "cs.MA", "econ.TH", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03524", "abs": "https://arxiv.org/abs/2512.03524", "authors": ["Grzegorz Jamróz", "Rafał Kucharski", "David Watling"], "title": "Market share maximizing strategies of CAV fleet operators may cause chaos in our cities", "comment": "34 pages, 9 figures", "summary": "We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities."}
{"id": "2512.03099", "categories": ["quant-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03099", "abs": "https://arxiv.org/abs/2512.03099", "authors": ["Haribandhu Jena", "Jyotirmaya Shivottam", "Subhankar Mishra"], "title": "QGShap: Quantum Acceleration for Faithful GNN Explanations", "comment": "Accepted in the QC+AI Workshop at AAAI 2026", "summary": "Graph Neural Networks (GNNs) have become indispensable in critical domains such as drug discovery, social network analysis, and recommendation systems, yet their black-box nature hinders deployment in scenarios requiring transparency and accountability. While Shapley value-based methods offer mathematically principled explanations by quantifying each component's contribution to predictions, computing exact values requires evaluating $2^n$ coalitions (or aggregating over $n!$ permutations), which is intractable for real-world graphs. Existing approximation strategies sacrifice either fidelity or efficiency, limiting their practical utility. We introduce QGShap, a quantum computing approach that leverages amplitude amplification to achieve quadratic speedups in coalition evaluation while maintaining exact Shapley computation. Unlike classical sampling or surrogate methods, our approach provides fully faithful explanations without approximation trade-offs for tractable graph sizes. We conduct empirical evaluations on synthetic graph datasets, demonstrating that QGShap achieves consistently high fidelity and explanation accuracy, matching or exceeding the performance of classical methods across all evaluation metrics. These results collectively demonstrate that QGShap not only preserves exact Shapley faithfulness but also delivers interpretable, stable, and structurally consistent explanations that align with the underlying graph reasoning of GNNs. The implementation of QGShap is available at https://github.com/smlab-niser/qgshap."}
{"id": "2512.03741", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.03741", "abs": "https://arxiv.org/abs/2512.03741", "authors": ["Saray Busto"], "title": "An arbitrary Lagrangian-Eulerian semi-implicit hybrid method for continuum mechanics with GLM cleaning", "comment": null, "summary": "This paper proposes a semi-implicit arbitrary Lagrangian-Eulerian (ALE) method for the solution of the unified Godunov-Peshkov-Romenski (GPR) model of continuum mechanics. To handle the curl free involutions arising in the solid limit of the model, the original system is augmented by adopting a thermodynamically compatible generalized Lagrangian multiplier (GLM) approach. Next, an operator splitting strategy decouples the computation of fast pressure waves from the bulk velocity of the medium yielding a transport subsystem, containing convective terms and non-conservative products, and a Poisson-type subsystem, for the pressure. A second splitting yields an ODE subsystem comprising only the potentially stiff source terms, responsible for the relaxation of the model between its fluid and solid limits.\n  The mesh motion can be driven by two sources: the local fluid velocity and a prescribed boundary displacement. For the spatial discretization, we employ unstructured staggered grids, with the pressure defined on the primal mesh and all remaining variables on the dual grid. The transport subsystem is advanced via an explicit finite volume method, in which integration over closed space-time control volumes ensures verification of the geometric conservation law (GCL). On the other hand, implicit continuous finite elements are used for the discretization of the pressure subsystem and an implicit DIRK scheme is employed to solve the ODE subsystem. Consequently, the proposed approach is well suited to address all Mach number flows. A comprehensive set of benchmarks is employed to assess the accuracy and robustness of the proposed methodology in tackling both fluid and solid mechanics problems."}
{"id": "2512.03937", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2512.03937", "abs": "https://arxiv.org/abs/2512.03937", "authors": ["Giulia Preti", "Matteo Riondato", "Aristides Gionis", "Gianmarco De Francisci Morales"], "title": "DSP: A Statistically-Principled Structural Polarization Measure", "comment": "Accepted for publication at ACM WSDM 2026", "summary": "Social and information networks may become polarized, leading to echo chambers and political gridlock. Accurately measuring this phenomenon is a critical challenge. Existing measures often conflate genuine structural division with random topological features, yielding misleadingly high polarization scores on random networks, and failing to distinguish real-world networks from randomized null models. We introduce DSP, a Diffusion-based Structural Polarization measure designed from first principles to correct for such biases. DSP removes the arbitrary concept of 'influencers' used by the popular Random Walk Controversy (RWC) score, instead treating every node as a potential origin for a random walk. To validate our approach, we introduce a set of desirable properties for polarization measures, expressed through reference topologies with known structural properties. We show that DSP satisfies these desiderata, being near-zero for non-polarized structures such as cliques and random networks, while correctly capturing the expected polarization of reference topologies such as monochromatic-splittable networks. Our method applied to U.S. Congress datasets uncovers trends of increasing polarization in recent years. By integrating a null model into its core definition, DSP provides a reliable and interpretable diagnostic tool, highlighting the necessity of statistically-grounded metrics to analyze societal fragmentation."}
{"id": "2512.03761", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.03761", "abs": "https://arxiv.org/abs/2512.03761", "authors": ["Pablo Martinez-Camblor"], "title": "Using functional information for binary classifications", "comment": null, "summary": "The adequate use of information measured in a continuous manner along a period of time represents a methodological challenge. In the last decades, most of traditional statistical procedures have been extended for accommodating these functional data. The binary classification problem, which aims to correctly identify units as positive or negative based on marker values, is not aside of this scenario. The crucial point for making binary classifications based on a marker is to establish an order in the marker values, which is not immediate when these values are presented as functions. Here, we argue that if the marker is related to the characteristic under study, a trajectory from a positive participant should be more similar to trajectories from the positive population than to those drawn from the negative. With this criterion, a classification procedure based on the distance between the involved functions is proposed. Besides, we propose a fully non-parametric estimator for this so-called probability-based criterion, PBC. We explore its asymptotic properties, and its finite-sample behavior from an extensive Monte Carlo study. The observed results suggest that the proposed methodology works adequately, and frequently better than its competitors, for a wide variety of situations when the sample size in both the training and the testing cohorts is adequate. The practical use of the proposal is illustrated from real-world dataset. As online supplementary material, the manuscript includes a document with further simulations and additional comments. An R function which wraps up the implemented routines is also provided."}
{"id": "2512.03274", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03274", "abs": "https://arxiv.org/abs/2512.03274", "authors": ["Lucas P. Kamizaki", "Marcus V. S. Bonança"], "title": "Excess work in counterdiabatic driving", "comment": null, "summary": "Many years have passed since the conception of the quintessential method of shortcut to adiabaticity known as counterdiabatic driving (or transitionless quantum driving). Yet, this method appears to be energetically cost-free and thus continually challenges the task of quantifying the amount of energy it demands to be accomplished. This paper proposes that the energy cost of controlling a closed quantum system using the counterdiabatic method can also be assessed using the instantaneous excess work during the process and related quantities, as the time-averaged excess work. Starting from the Mandelstam-Tamm bound for driven dynamics, we have shown that the speed-up of counterdiabatic driving is linked with the spreading of energy between the eigenstates of the total Hamiltonian, which is necessarily accompanied by transitions between these eigenstates. Nonetheless, although excess work can be used to quantify energetically these transitions, it is well known that the excess work is zero throughout the entire process under counterdiabatic driving. To recover the excess work as an energetic cost quantifier for counterdiabatic driving, we will propose a different interpretation of the parameters of the counterdiabatic Hamiltonian, leading to an excess work different from zero. We have illustrated our findings with the Landau-Zener model."}
{"id": "2512.03680", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03680", "abs": "https://arxiv.org/abs/2512.03680", "authors": ["Dawei Zhao", "Kai Wang", "Xianglong Zhou", "Xin Ma", "Lei Jia"], "title": "Output-Constrained Controller with Fuzzy-Tuned Parameters for Overhead Cranes", "comment": null, "summary": "This study proposes a fuzzy-adjusted nonlinear control method based on torque jitter output limit constraints for overhead crane systems with double pendulum effects. The proposed control method can effectively suppress swing and achieve precise positioning. Firstly, by enhancing the coupling relationship between the trolley displacement and swing angle, a composite signal with an error term was designed. Then, an energy-based Lyapunov function was constructed using the composite error signal, which incorporated a new formulation of the inertia matrix and potential energy function. Subsequently, using the backstepping method in conjunction with the hyperbolic tangent function, a controller with partial performance constraints was designed. In addition, to further enhance the system's dynamic performance, a fuzzy control scheme with online adjustable system parameters was designed. Finally, the stability of the system is proven using Lyapunov theory combined with LaSalle's invariance principle. Simulation results demonstrate that the proposed controller exhibits superior performance and robustness."}
{"id": "2512.03680", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03680", "abs": "https://arxiv.org/abs/2512.03680", "authors": ["Dawei Zhao", "Kai Wang", "Xianglong Zhou", "Xin Ma", "Lei Jia"], "title": "Output-Constrained Controller with Fuzzy-Tuned Parameters for Overhead Cranes", "comment": null, "summary": "This study proposes a fuzzy-adjusted nonlinear control method based on torque jitter output limit constraints for overhead crane systems with double pendulum effects. The proposed control method can effectively suppress swing and achieve precise positioning. Firstly, by enhancing the coupling relationship between the trolley displacement and swing angle, a composite signal with an error term was designed. Then, an energy-based Lyapunov function was constructed using the composite error signal, which incorporated a new formulation of the inertia matrix and potential energy function. Subsequently, using the backstepping method in conjunction with the hyperbolic tangent function, a controller with partial performance constraints was designed. In addition, to further enhance the system's dynamic performance, a fuzzy control scheme with online adjustable system parameters was designed. Finally, the stability of the system is proven using Lyapunov theory combined with LaSalle's invariance principle. Simulation results demonstrate that the proposed controller exhibits superior performance and robustness."}
{"id": "2512.03535", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03535", "abs": "https://arxiv.org/abs/2512.03535", "authors": ["Bing-Chang Wang", "Huanshui Zhang", "Ji-Feng Zhang"], "title": "Leader-Follower Mean Field LQG Games with Multiplicative Noise", "comment": null, "summary": "This paper studies open-loop and feedback solutions to leader-follower mean field linear-quadratic-Gaussian games with multiplicative noise by the direct approach. The leader-follower game involves a leader and many followers, where the state and control weight matrices in their costs are not limited to be positive definite. From variational analysis with mean field approximations, we obtain a set of open-loop controls in terms of solutions to mean field forward-backward stochastic differential equations. By applying the matrix maximum principle, a set of decentralized feedback strategies is constructed. Distinct from traditional works, a cross term has appeared in derivation due to the presence of mean field terms. For open-loop and feedback solutions, the corresponding optimal costs of all players are explicitly given in terms of the solutions to two Riccati equations, respectively."}
{"id": "2512.03131", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03131", "abs": "https://arxiv.org/abs/2512.03131", "authors": ["Samuel J. Sheldon", "Pieter Kok"], "title": "Generating redundantly encoded resource states for photonic quantum computing", "comment": null, "summary": "Measurement-based quantum computing relies on the generation of large entangled cluster states that act as a universal resource on which logical circuits can be imprinted and executed through local measurements. A number of strategies for constructing sufficiently large photonic cluster states propose fusing many smaller resource states generated by a series of quantum emitters. However, the fusion process is inherently probabilistic with a 50% success probability in standard guise. A recent proposal has shown that, in the limit of low loss, the probability of achieving successful fusion may be boosted to near unity by redundantly encoding the vertices of linear graph states using Greenberger-Horne-Zeilinger states [Quantum 7, 992 (2023)]. Here we present a protocol for deterministically generating redundantly encoded photonic resource states using single quantum emitters, and study the impact of protocol errors and photonic losses on the generated resource states and type-II photonic fusion. Our work provides a route for efficiently constructing complex entangled photonic qubit states for photonic quantum computing and quantum repeaters."}
{"id": "2512.03840", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.03840", "abs": "https://arxiv.org/abs/2512.03840", "authors": ["Chuchu Chen", "Xinyu Chen", "Jialin Hong", "Yuqian Miao"], "title": "Symplectic methods for stochastic Hamiltonian systems: asymptotic error distributions and Hamiltonian-specific analysis", "comment": null, "summary": "In this paper, we investigate the asymptotic error distributions of symplectic methods for stochastic Hamiltonian systems and further provide Hamiltonian-specific analysis that clarifies the superiority of symplectic methods. Our contribution is threefold. First, we derive the asymptotic error distributions of symplectic methods for stochastic Hamiltonian systems with multiplicative noise and additive noise, respectively, and show that the obtained limiting stochastic processes satisfy equations retaining the Hamiltonian formulations. Second, we propose a new approach for calculating the asymptotic error distribution, revealing the connection between the stochastic modified equation and the asymptotic error distribution. Third, we characterize the limiting distribution of the normalized Hamiltonian deviation, thereby illustrating through test equations the superiority of symplectic methods for long-time simulations of the Hamiltonians, even in the limit as the step size tends to zero."}
{"id": "2512.03777", "categories": ["stat.ME", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03777", "abs": "https://arxiv.org/abs/2512.03777", "authors": ["Federico P. Cortese", "Luca Rossini"], "title": "A comparison between initialization strategies for the infinite hidden Markov model", "comment": null, "summary": "Infinite hidden Markov models provide a flexible framework for modelling time series with structural changes and complex dynamics, without requiring the number of latent states to be specified in advance. This flexibility is achieved through the hierarchical Dirichlet process prior, while efficient Bayesian inference is enabled by the beam sampler, which combines dynamic programming with slice sampling to truncate the infinite state space adaptively. Despite extensive methodological developments, the role of initialization in this framework has received limited attention. This study addresses this gap by systematically evaluating initialization strategies commonly used for finite hidden Markov models and assessing their suitability in the infinite setting. Results from both simulated and real datasets show that distance-based clustering initializations consistently outperform model-based and uniform alternatives, the latter being the most widely adopted in the existing literature."}
{"id": "2512.03283", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03283", "abs": "https://arxiv.org/abs/2512.03283", "authors": ["Ali Tozar"], "title": "Symmetry-Protected Bipolar Skin Effect and its Topological Breakdown in Disordered Non-Hermitian Systems", "comment": "7 Pages, 8 figures", "summary": "The interplay between non-Hermitian topology and disorder remains a central puzzle in open quantum systems. While the non-Hermitian skin effect (NHSE) is known to be robust against weak perturbations, its fate under strong disorder, particularly in the presence of spin-orbit coupling (SOC), is not fully understood. Here, we uncover a Z_2 topological bipolar skin effect in a non-Hermitian Rashba chain, where spin-up and spin-down eigenstates localize at opposite boundaries. By strictly computing the Lyapunov exponents and introducing a biorthogonal spin-separation index, we map the global phase diagram and reveal a hierarchical breakdown of topology. We demonstrate that the Z_2 skin effect is protected against moderate disorder but collapses into a trivial skin phase before the ultimate onset of Anderson localization. Our results establish a distinct regime of disorder-robust topological non-reciprocity, distinguishable from both the trivial bulk limit and the Anderson localized phase."}
{"id": "2512.03712", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03712", "abs": "https://arxiv.org/abs/2512.03712", "authors": ["Sary Yehia", "Alessandra Parisio"], "title": "A Hybrid Sequential Convex Programming Framework for Unbalanced Three-Phase AC OPF", "comment": null, "summary": "This paper presents a hybrid Sequential Convex Programming (SCP) framework for solving the unbalanced three-phase AC Optimal Power Flow (OPF) problem. The method combines a fixed McCormick outer approximation of bilinear voltage-current terms, first-order Taylor linearisations, and an adaptive trust-region constraint to preserve feasibility and promote convergence. The resulting formulation remains convex at each iteration and ensures convergence to a stationary point that satisfies the first-order Karush-Kuhn-Tucker (KKT) conditions of the nonlinear OPF. Case studies on standard IEEE feeders and a real low-voltage (LV) network in Cyprus demonstrate high numerical accuracy with optimality gap below 0.1% and up to 2x faster runtimes compared to IPOPT. These results confirm that the method is accurate and computationally efficient for large-scale unbalanced distribution networks."}
{"id": "2512.03712", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03712", "abs": "https://arxiv.org/abs/2512.03712", "authors": ["Sary Yehia", "Alessandra Parisio"], "title": "A Hybrid Sequential Convex Programming Framework for Unbalanced Three-Phase AC OPF", "comment": null, "summary": "This paper presents a hybrid Sequential Convex Programming (SCP) framework for solving the unbalanced three-phase AC Optimal Power Flow (OPF) problem. The method combines a fixed McCormick outer approximation of bilinear voltage-current terms, first-order Taylor linearisations, and an adaptive trust-region constraint to preserve feasibility and promote convergence. The resulting formulation remains convex at each iteration and ensures convergence to a stationary point that satisfies the first-order Karush-Kuhn-Tucker (KKT) conditions of the nonlinear OPF. Case studies on standard IEEE feeders and a real low-voltage (LV) network in Cyprus demonstrate high numerical accuracy with optimality gap below 0.1% and up to 2x faster runtimes compared to IPOPT. These results confirm that the method is accurate and computationally efficient for large-scale unbalanced distribution networks."}
{"id": "2512.03547", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03547", "abs": "https://arxiv.org/abs/2512.03547", "authors": ["Stefan Clarke", "Bartolomeo Stellato"], "title": "Learning-Based Hierarchical Approach for Fast Mixed-Integer Optimization", "comment": null, "summary": "We propose a hierarchical architecture for efficiently computing high-quality solutions to structured mixed-integer programs (MIPs). To reduce computational effort, our approach decouples the original problem into a higher level problem and a lower level problem, both of smaller size. We solve both problems sequentially, where decisions of the higher level problem become parameters of the constraints of the lower level problem. We formulate this learning task as a convex optimization problem using decision-focused learning techniques and solve it by differentiating through the higher and the lower level problems in our architecture. To ensure robustness, we derive out-of-sample performance guarantees using conformal prediction. Numerical experiments in facility location, knapsack problems, and vehicle routing problems demonstrate that our approach significantly reduces computation time while maintaining feasibility and high solution quality compared to state-of-the-art solvers."}
{"id": "2512.03135", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.03135", "abs": "https://arxiv.org/abs/2512.03135", "authors": ["Alan Gardin", "Emilio Cobanera", "Giuseppe C. Tettamanzi"], "title": "Many-body symmetry-protected zero boundary modes of synthetic photo-magnonic crystals", "comment": null, "summary": "The topological classification of insulators and superconductors, the \"ten-fold way\", is grounded on fermionic many-body symmetries and has had a dramatic impact on many fields of physics. Therefore, it seems equally important to investigate a similar approach for bosons as tightly analogous to the fermionic prototype as possible. There are, however, several obstacles coming from the fundamental physical differences between fermions and bosons. Here, we propose a potentially optimal way forward: a theory of free boson topology (topological classification and bulk-boundary correspondence) protected by bosonic many-body symmetry operations, namely, squeezing transformations, particle number, and bosonic time reversal. We identify two symmetry classes that are topologically non-trivial in one dimension. They include key models like the bosonic Kitaev chain, protected by a squeezing symmetry within our framework, and the celebrated bosonic SSH model, protected by a squeezing symmetry and particle number. To provide a robust experimental platform for testing our theory, we introduce a new quantum meta-material: photo-magnonic crystals. They consist of arrays of interconnected photo-magnonic cavities. They are remarkable for their experimental flexibility and natural affinity for displaying band topological physics at microwave frequencies. We engineer a many-body symmetry-protected topological photo-magnonic chain with boundary modes mandated by a Pfaffian invariant. Using an electromagnetic finite-element modelling, we simulate its reflection and transmission and identify experimental signatures of its boundary modes. The experimental tuning of the crystal to its symmetry-protected topological phase is also addressed. Our modelling of the photo-magnonic chain provides a thorough blueprint for its experimental realisation and the unambiguous observation of its exotic physics."}
{"id": "2512.04003", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.04003", "abs": "https://arxiv.org/abs/2512.04003", "authors": ["Amireh Mousavi"], "title": "Mixed finite element approximation for non-divergence form elliptic equations with random input data", "comment": null, "summary": "We consider an elliptic partial differential equation in non-divergence form with a random diffusion matrix and random forcing term. To address this, we propose a mixed-type continuous finite element discretization in the physical domain, combined with a collocation discretization in the stochastic domain. For the mixed formulation, we first introduce a stochastic cost functional at the continuous level. This formulation is then enhanced to incorporate the vanishing tangential trace constraint directly into a mesh-dependent cost functional, rather than enforcing it in the solution's function space. In this context, we define a mesh-dependent norm and provide an error analysis based on this norm. We employ the collocation method by collocating the stochastic equation at the zeros of suitable tensor product orthogonal polynomials. This approach leads to a system of uncoupled deterministic problems, simplifying computation. Furthermore, we establish an a poriori error bound for the fully discrete approximation, detailing the convergence rates with respect to the discretization parameters. Finally, numerical results are presented to confirm and validate the theoretical findings."}
{"id": "2512.03859", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.03859", "abs": "https://arxiv.org/abs/2512.03859", "authors": ["Kehan Wang", "Wenxuan Song", "Wangli Xu", "Linglong Kong"], "title": "SUP: An Inferable Private Multiple Testing Framework with Super Uniformity", "comment": null, "summary": "Multiple testing is widely applied across scientific fields, particularly in genomic and health data analysis, where protecting sensitive personal information is imperative. However, developing private multiple testing algorithms for super uniform $p$-values remains an open question, as privacy mechanisms introduce intricate dependence among the peeled $p$-values and disrupt their super uniformity, complicating post-selection inference. To address this, we introduce a general Super Uniform Private (SUP) multiple testing framework with three key components. First, we develop a novel \\( p \\)-value transformation that is compatible with diverse privacy regimes while retaining the super uniformity. Next, a reversed peeling algorithm is designed to reduce privacy budgets while facilitating inference. Then, we provide diverse rejection thresholds that are privacy-parameter-free and tailored for different Type-I errors, including the family-wise error rate (FWER) and the false discovery rate (FDR). Building upon these, we advance adaptive techniques to determine the peeling number and boost thresholds. Theoretically, we propose a technique overcoming the post-selection obstacle to Type-I error control, quantify the privacy-induced power loss of SUP relative to its non-private counterpart, and demonstrate that SUP surpasses existing private methods in terms of power. The results of extensive simulations and a real data application validate our theories."}
{"id": "2512.03341", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03341", "abs": "https://arxiv.org/abs/2512.03341", "authors": ["Ching-Tai Huang", "Yu-Cheng Lin", "Ferenc Igloi"], "title": "Quench dynamics of the quantum XXZ chain with staggered interactions: Exact results and simulations on digital quantum computers", "comment": "15 pages, 16 figures", "summary": "We investigate quench dynamics in the quantum $S=1/2$ XXZ antiferromagnetic chain with staggered and anisotropic interactions in the flat-band limit. Our quench protocol interchanges the odd- and even-bond strengths of a fully dimerized chain, enabling us to derive exact time-dependent states for arbitrary even system sizes by working in the Bell basis. We obtain closed-form, size-independent expressions for the von Neumann and second-order Rényi entanglement entropies. We further calculate exact Loschmidt echoes and the corresponding return rate functions across various anisotropies and system sizes, and identify Loschmidt zeros in finite chains. Our analysis reveals the precise conditions on the anisotropy parameter that govern the periodicity of the dynamical observables. In addition to the analytic study, we perform two types of numerical experiments on IBM-Q quantum devices. First, we use the Hadamard test to estimate the Bell-basis expansion coefficients and reconstruct the dynamical states, achieving accurate entanglement entropies and the Loschmidt echo for small systems. Second, we implement Trotter-error-free time-evolution circuits combined with randomized Pauli measurements. Post-processing via statistical correlations and classical shadows yields reliable estimates of the second-order Rényi entanglement entropy and the Loschmidt echo, showing satisfactory agreement with exact results."}
{"id": "2512.03764", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03764", "abs": "https://arxiv.org/abs/2512.03764", "authors": ["Bowen Song", "Sebastien Gros", "Andrea Iannelli"], "title": "Sample-Efficient Model-Free Policy Gradient Methods for Stochastic LQR via Robust Linear Regression", "comment": null, "summary": "Policy gradient algorithms are widely used in reinforcement learning and belong to the class of approximate dynamic programming methods. This paper studies two key policy gradient algorithms - the Natural Policy Gradient and the Gauss-Newton Method - for solving the Linear Quadratic Regulator (LQR) problem in unknown stochastic linear systems. The main challenge lies in obtaining an unbiased gradient estimate from noisy data due to errors-in-variables in linear regression. This issue is addressed by employing a primal-dual estimation procedure. Using this novel gradient estimation scheme, the paper establishes convergence guarantees with a sample complexity of order O(1/epsilon). Theoretical results are further supported by numerical experiments, which demonstrate the effectiveness of the proposed algorithms."}
{"id": "2512.03764", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03764", "abs": "https://arxiv.org/abs/2512.03764", "authors": ["Bowen Song", "Sebastien Gros", "Andrea Iannelli"], "title": "Sample-Efficient Model-Free Policy Gradient Methods for Stochastic LQR via Robust Linear Regression", "comment": null, "summary": "Policy gradient algorithms are widely used in reinforcement learning and belong to the class of approximate dynamic programming methods. This paper studies two key policy gradient algorithms - the Natural Policy Gradient and the Gauss-Newton Method - for solving the Linear Quadratic Regulator (LQR) problem in unknown stochastic linear systems. The main challenge lies in obtaining an unbiased gradient estimate from noisy data due to errors-in-variables in linear regression. This issue is addressed by employing a primal-dual estimation procedure. Using this novel gradient estimation scheme, the paper establishes convergence guarantees with a sample complexity of order O(1/epsilon). Theoretical results are further supported by numerical experiments, which demonstrate the effectiveness of the proposed algorithms."}
{"id": "2512.03557", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03557", "abs": "https://arxiv.org/abs/2512.03557", "authors": ["Ziqi Xu", "Lin Cheng", "Shengping Gong"], "title": "Parameters Optimization in Trajectory Planning Using Diffrentiable Convex Programing", "comment": null, "summary": "Sequential convex programming has been established as an effective framework for solving nonconvex trajectory planning problems. However, its performance is highly sensitive to problem parameters, including trajectory variables, algorithmic hyperparameters, and physical vehicle parameters. This paper introduces a differentiable sequential convex programming framework that integrates differentiable convex optimization with sequential convex programming to enable end-to-end parameter optimization. By deriving first-order sensitivity relations of second-order cone programming solutions with respect to problem data, exact gradients of trajectory performance metrics with respect to arbitrary parameters are obtained and propagated through iterations. The effectiveness of the proposed framework is validated through three representative applications: optimal terminal-time prediction for powered landing, trust-region penalty optimization in subproblems, and surface-to-mass ratio optimization for hypersonic gliding vehicles. Simulation results show that the proposed framework enables reliable gradient-based parameter learning and significantly improves numerical performance, convergence behavior, and design efficiency. These results indicate that differentiable sequential convex programming framework provides a powerful and general tool for vehicle design, mission optimization, and hyperparameter selection in aerospace trajectory planning."}
{"id": "2512.03138", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03138", "abs": "https://arxiv.org/abs/2512.03138", "authors": ["Ibukunoluwa Adisa", "Won Chan Lee", "Kevin C. Cox", "Alicia J. Kollár"], "title": "The Pound-Drever-Hall Method for Superconducting-Qubit Readout", "comment": null, "summary": "Scaling quantum computers to large sizes requires the implementation of many parallel qubit readouts. Here we present an ultrastable superconducting-qubit readout method using the multi-tone self-phase-referenced Pound-Drever-Hall (PDH) technique, originally developed for use with optical cavities. In this work, we benchmark PDH readout of a single transmon qubit, using room-temperature heterodyne detection of all tones to reconstruct the PDH signal. We demonstrate that PDH qubit readout is insensitive to microwave phase drift, displaying $0.73^\\circ$ phase stability over 2 hours, and capable of single-shot readout in the presence of phase errors exceeding the phase shift induced by the qubit state. We show that the PDH sideband tones do not cause unwanted measurement-induced state transitions for a transmon qubit, leading to a potential signal enhancement of at least $14$~dB over traditional heterodyne readout."}
{"id": "2512.04046", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.04046", "abs": "https://arxiv.org/abs/2512.04046", "authors": ["L. Bruni Bruno", "P. Massa", "E. Perracchione", "M. Trombini"], "title": "Greedy techniques for inverse problems", "comment": null, "summary": "Inverse imaging problems rely on limited and indirect measurements, making reconstruction highly dependent on both regularization and sample locations. We introduce a novel greedy framework for the optimal selection of indirect measurements in the operator codomain, specifically tailored to inverse problems. Our approach employs a two-step scheme combining kernel-based interpolation and extrapolation. Within this framework, greedy schemes can be residual-based, where points are selected according to the current approximation error for a specific target function, or error-based, where points are chosen using a priori error indicators independent of the residual. For the latter, we derive explicit error bounds that quantify the propagation of approximation errors through both interpolation and extrapolation. Numerical applications to solar hard X-ray imaging demonstrate that the proposed greedy sampling strategy achieves high-quality reconstructions using only a few available measurements."}
{"id": "2512.03912", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.03912", "abs": "https://arxiv.org/abs/2512.03912", "authors": ["Yixi Xu", "Yi Zhao"], "title": "Parsimonious Clustering of Covariance Matrices", "comment": null, "summary": "Functional connectivity (FC) derived from functional magnetic resonance imaging (fMRI) data offers vital insights for understanding brain function and neurological and psychiatric disorders. Unsupervised clustering methods are desired to group individuals based on shared features, facilitating clinical diagnosis. In this study, a parsimonious clustering model is proposed, which integrates the Mixture-of-Experts (MoE) and covariance regression framework, to cluster individuals based on FC captured by data covariance matrices in resting-state fMRI studies. The model assumes common linear projections across covariance matrices and a generalized linear model with covariates, allowing for flexible yet interpretable projection-specific clustering solutions. To evaluate the performance of the proposed framework, extensive simulation studies are conducted to assess clustering accuracy and robustness. The approach is applied to resting-state fMRI data from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Subgroups are identified based on brain coherence and simultaneously uncover the association with demographic factors and cognitive functions."}
{"id": "2512.03530", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03530", "abs": "https://arxiv.org/abs/2512.03530", "authors": ["Yoshihito Kuno"], "title": "Edge bits in average symmetry protected topological mixed state", "comment": "6+4 pages, 3+2 figures", "summary": "Edge bit in an average symmetry protected topological (ASPT) mixed state is studied. The state is protected by one strong $Z_2$ and one weak (average) $Z_2$ symmetries. As analogous objects of pure symmetry protected topological (SPT) states, the ASPT possesses edge bits. In particular, the analogous operator response exists, that is, symmetry fractionalization. The fractionalization preserves the presence of the ASPT in the bulk, and the fractionalized edge operators acting on the edge bits of the ASPT. %analogous to the ones in the pure SPTs. In this work, based on the cluster model and by employing Choi mapping, we discuss generic features of the edge bits and numerically clarify the behavior of the edge bits and their robustness for varying decoherence and perturbative interactions. By using an operator-space mutual information (OSMI), we track the flow of quantum correlations between the two edges. Remarkably, even in the ASPT regime, a finite portion of the initial edge-to-edge correlation survives."}
{"id": "2512.03767", "categories": ["eess.SY", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03767", "abs": "https://arxiv.org/abs/2512.03767", "authors": ["Bo Qian", "Hanlin Wu", "Jiacheng Chen", "Yunting Xu", "Xiaoyu Wang", "Haibo Zhou", "Yusheng Ji"], "title": "CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond", "comment": null, "summary": "The fundamental design of wireless systems toward AI-native 6G and beyond is driven by the need for ever-increasing demand of mobile data traffic, extreme spectral efficiency, and adaptability across diverse service scenarios. To overcome the limitations posed by feedback-based multiple-input and multiple-output (MIMO) transmission, we propose a novel frequency-domain Correlation-aware Feedback-free MIMO Transmission and Resource Allocation (CaFTRA) framework tailored for fully-decoupled radio access networks (FD-RAN) to meet the emerging requirements of AI-Native 6G and beyond. By leveraging artificial intelligence (AI), CaFTRA effectively eliminates real-time uplink feedback by predicting channel state information (CSI) based solely on user geolocation. We introduce a Learnable Queries-driven Transformer Network for CSI mapping from user geolocation, which utilizes multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks (RBs), thereby significantly improving the precision of CSI prediction. Once base stations (BSs) adopt feedback-free transmission, their downlink transmission coverage can be significantly expanded due to the elimination of frequent uplink feedback. To enable efficient resource scheduling under such extensive-coverage scenarios, we apply a low-complexity many-to-one matching theory-based algorithm for efficient multi-BS association and multi-RB resource allocation, which is proven to converge to a stable matching within limited iterations. Simulation results demonstrate that CaFTRA achieves stable matching convergence and significant gains in spectral efficiency and user fairness compared to 5G, underscoring its potential value for 6G standardization efforts."}
{"id": "2512.03767", "categories": ["eess.SY", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.03767", "abs": "https://arxiv.org/abs/2512.03767", "authors": ["Bo Qian", "Hanlin Wu", "Jiacheng Chen", "Yunting Xu", "Xiaoyu Wang", "Haibo Zhou", "Yusheng Ji"], "title": "CaFTRA: Frequency-Domain Correlation-Aware Feedback-Free MIMO Transmission and Resource Allocation for 6G and Beyond", "comment": null, "summary": "The fundamental design of wireless systems toward AI-native 6G and beyond is driven by the need for ever-increasing demand of mobile data traffic, extreme spectral efficiency, and adaptability across diverse service scenarios. To overcome the limitations posed by feedback-based multiple-input and multiple-output (MIMO) transmission, we propose a novel frequency-domain Correlation-aware Feedback-free MIMO Transmission and Resource Allocation (CaFTRA) framework tailored for fully-decoupled radio access networks (FD-RAN) to meet the emerging requirements of AI-Native 6G and beyond. By leveraging artificial intelligence (AI), CaFTRA effectively eliminates real-time uplink feedback by predicting channel state information (CSI) based solely on user geolocation. We introduce a Learnable Queries-driven Transformer Network for CSI mapping from user geolocation, which utilizes multi-head attention and learnable query embeddings to accurately capture frequency-domain correlations among resource blocks (RBs), thereby significantly improving the precision of CSI prediction. Once base stations (BSs) adopt feedback-free transmission, their downlink transmission coverage can be significantly expanded due to the elimination of frequent uplink feedback. To enable efficient resource scheduling under such extensive-coverage scenarios, we apply a low-complexity many-to-one matching theory-based algorithm for efficient multi-BS association and multi-RB resource allocation, which is proven to converge to a stable matching within limited iterations. Simulation results demonstrate that CaFTRA achieves stable matching convergence and significant gains in spectral efficiency and user fairness compared to 5G, underscoring its potential value for 6G standardization efforts."}
{"id": "2512.03562", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03562", "abs": "https://arxiv.org/abs/2512.03562", "authors": ["Yumeng Fang", "Tai-Yu Ma"], "title": "A hybrid large neighborhood search algorithm for the integrated dial-a-ride problem using electric vehicles", "comment": null, "summary": "Integrating demand-responsive mobility services with transit systems is recognized as a practical and effective strategy to mitigate their impact on traffic congestion and the environment. This study develops an efficient hybrid metaheuristic to solve the integrated dial-a-ride problem by utilizing electric vehicles to minimize operational costs and customer travel time. Customer transfer inconvenience is restricted by a maximum intermodal transfer time to synchronize demand-responsive buses' arrival and transit departures. The proposed metaheuristic addresses the challenges of integrating demand-responsive vehicle routing and charging operations with fixed-route transit systems with capacitated charging stations and partial recharge. We benchmarked our algorithm against a state-of-the-art mixed-integer programming solver on instances with 10-50 customers and two transit lines. Our approach achieves solutions that are, on average, 23.8% better in solution quality within around 2 minutes, outperforming those obtained by the solver using an 8-hour computational time limit. We evaluate the impact of various system parameters to bridge the gap between theory and practice. The results suggest that, from the operator's perspective, while the integrated dial-a-ride service reduces vehicle kilometers traveled, the used fleet size may not necessarily be reduced when ensuring high-quality service for passengers. Moreover, operating the integrated systems is more beneficial in areas with dense transit networks, compared with increases in transit frequency. The findings provide valuable insights for developing integrated dial-a-ride services in practice."}
{"id": "2512.03162", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03162", "abs": "https://arxiv.org/abs/2512.03162", "authors": ["George Grattan", "Pratik Sathe", "Cristiano Nisoli"], "title": "Classical Thermometry of Quantum Annealers", "comment": "George Grattan and Pratik Sathe contributed equally", "summary": "Quantum annealers are emerging as programmable, dynamical experimental platforms for probing strongly correlated spin systems. Yet key thermal assumptions, chiefly a Gibbs-distributed output ensemble, remain unverified in the large-scale regime. Here, we experimentally and quantitatively assess Gibbs sampling fidelity across system sizes spanning over three orders of magnitude. We explore a wide parameter space of coupling strengths, system sizes, annealing times, and D-wave hardware architectures. We find that the naively assumed scaling law for the effective temperature requires a non-negligible, coupling-independent offset that is robust across machines and parameter regimes, quantifying residual non-thermal effects that still conform to an effective Gibbs description. These non-idealities are further reflected in a systematic discrepancy between the physical temperature inferred from the sampled ensemble and the nominal cryogenic temperature of the device. Our results systematically assess the viability of quantum annealers as experimental platforms for probing classical thermodynamics, correct previous assumptions, and provide a physically grounded thermometry framework to benchmark these machines for future thermodynamic experiments."}
{"id": "2512.03193", "categories": ["quant-ph", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.03193", "abs": "https://arxiv.org/abs/2512.03193", "authors": ["Yulong Dong", "Christopher Kang", "Murphy Yuezhen Niu"], "title": "In Situ Quantum Analog Pulse Characterization via Structured Signal Processing", "comment": "48 pages, 10 figures", "summary": "Analog quantum simulators can directly emulate time-dependent Hamiltonian dynamics, enabling the exploration of diverse physical phenomena such as phase transitions, quench dynamics, and non-equilibrium processes. Realizing accurate analog simulations requires high-fidelity time-dependent pulse control, yet existing calibration schemes are tailored to digital gate characterization and cannot be readily extended to learn continuous pulse trajectories. We present a characterization algorithm for in situ learning of pulse trajectories by extending the Quantum Signal Processing (QSP) framework to analyze time-dependent pulses. By combining QSP with a logical-level analog-digital mapping paradigm, our method reconstructs a smooth pulse directly from queries of the time-ordered propagator, without requiring mid-circuit measurements or additional evolution. Unlike conventional Trotterization-based methods, our approach avoids unscalable performance degradation arising from accumulated local truncation errors as the logical-level segmentation increases. Through rigorous theoretical analysis and extensive numerical simulations, we demonstrate that our method achieves high accuracy with strong efficiency and robustness against SPAM as well as depolarizing errors, providing a lightweight and optimal validation protocol for analog quantum simulators capable of detecting major hardware faults."}
{"id": "2512.03946", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.03946", "abs": "https://arxiv.org/abs/2512.03946", "authors": ["Nate Wiecha", "Emily Griffith", "Brian J. Reich", "Jane A. Hoppin"], "title": "When are novel methods for analyzing complex chemical mixtures in epidemiology beneficial?", "comment": null, "summary": "Estimating the health impacts of exposure to a mixture of chemicals poses many statistical challenges: multiple correlated exposure variables, moderate to high dimensionality, and possible nonlinear and interactive health effects of mixture components. Reviews of chemical mixture methods aim to help researchers select a statistical method suited to their goals and data, but examinations of empirical performance have emphasized novel methods purpose-built for analyzing complex chemical mixtures, or other more advanced methods, over more general methods which are widely used in many application domains. We conducted a broad experimental comparison, across simulated scenarios, of both more general methods (such as generalized linear models) and novel methods (such as Bayesian Kernel Machine Regression) designed to study chemical mixtures. We assessed methods based on their ability to control Type I error rate, maximize power, provide interpretable results, and make accurate predictions. We find that when there is moderate correlation between mixture components and the exposure-response function does not have complicated interactions, or when mixture components have opposite effects, general methods are preferred over novel ones. With highly interactive exposure-response functions or highly correlated exposures, novel methods provide important benefits. We provide a comprehensive summary of when different methods are most suitable."}
{"id": "2512.03799", "categories": ["cond-mat.dis-nn", "cond-mat.soft", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03799", "abs": "https://arxiv.org/abs/2512.03799", "authors": ["Purba Chatterjee", "Marcelo Guzman", "Andrea J. Liu"], "title": "Remembrance of Tasks Past in Tunable Physical Networks", "comment": null, "summary": "Sequential learning in physical networks is hindered by catastrophic forgetting, where training a new task erases solutions to earlier ones. We show that we can significantly enhance memory of previous tasks by introducing a hard threshold in the learning rule, allowing only edges with sufficiently large training signals to be altered. Thresholding confines tuning to the spatial vicinity of inputs and outputs for each task, effectively partitioning the network into weakly overlapping functional regions. Using simulations of tunable resistor networks, we demonstrate that this strategy enables robust memory of multiple sequential tasks while reducing the number of edges and the overall tuning cost. Our results hint at constrained training as a simple, local, and scalable mechanism to overcome catastrophic forgetting in tunable matter."}
{"id": "2512.03779", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.03779", "abs": "https://arxiv.org/abs/2512.03779", "authors": ["Toshiyuki Ohtsuka"], "title": "Exact and Parametric Dynamical System Representation of Nonlinear Functions", "comment": "7 pages, 3 figures", "summary": "Parametric representations of various functions are fundamental tools in science and engineering. This paper introduces a fixed-initial-state constant-input dynamical system (FISCIDS) representation, which provides an exact and parametric model for a broad class of nonlinear functions. A FISCIDS representation of a given nonlinear function consists of an input-affine dynamical system with a fixed initial state and constant input. The argument of the function is applied as the constant input to the input-affine system, and the value of the function is the output of the input-affine system at a fixed terminal time. We show that any differentially algebraic function has a quadratic FISCIDS representation. We also show that there exists an analytic function that is not differentially algebraic but has a quadratic FISCIDS representation. Therefore, most functions in practical problems in science and engineering can be represented by a quadratic FISCIDS representation."}
{"id": "2512.03779", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.03779", "abs": "https://arxiv.org/abs/2512.03779", "authors": ["Toshiyuki Ohtsuka"], "title": "Exact and Parametric Dynamical System Representation of Nonlinear Functions", "comment": "7 pages, 3 figures", "summary": "Parametric representations of various functions are fundamental tools in science and engineering. This paper introduces a fixed-initial-state constant-input dynamical system (FISCIDS) representation, which provides an exact and parametric model for a broad class of nonlinear functions. A FISCIDS representation of a given nonlinear function consists of an input-affine dynamical system with a fixed initial state and constant input. The argument of the function is applied as the constant input to the input-affine system, and the value of the function is the output of the input-affine system at a fixed terminal time. We show that any differentially algebraic function has a quadratic FISCIDS representation. We also show that there exists an analytic function that is not differentially algebraic but has a quadratic FISCIDS representation. Therefore, most functions in practical problems in science and engineering can be represented by a quadratic FISCIDS representation."}
{"id": "2512.03626", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03626", "abs": "https://arxiv.org/abs/2512.03626", "authors": ["Gabriel Velho", "Jean Auriol", "Riccardo Bonalli"], "title": "A Gradient Method for Risk Averse Control of a PDE-SDE Interconnected System", "comment": null, "summary": "In this paper, we design a risk-averse controller for an interconnected system composed of a linear Stochastic Differential Equation (SDE) actuated through a linear parabolic heat equation. These dynamics arise in various applications, such as coupled heat transfer systems and chemical reaction processes that are subject to disturbances. While existing optimal control methods for these systems focus on minimizing average performance, this risk-neutral perspective may allow rare but highly undesirable system behaviors. To account for such events, we instead minimize the cost within a coherent risk measure. Our approach reformulates the coupled dynamics as a stochastic PDE, approximates it by a finite-dimensional SDE system, and applies a gradient-based method to compute a riskaverse feedback controller. Numerical simulations show that the proposed controller substantially reduces the tail of the cost distribution, improving reliability with only a minor reduction in average performance."}
{"id": "2512.03177", "categories": ["quant-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.03177", "abs": "https://arxiv.org/abs/2512.03177", "authors": ["Antonio Francesco Mello", "Mario Collura", "E. Miles Stoudenmire", "Ryan Levy"], "title": "Magic of the Well: assessing quantum resources of fluid dynamics data", "comment": "6+5 pages. Comments welcome", "summary": "We investigate the quantum resource requirements of a dataset generated from simulations of two-dimensional, periodic, incompressible shear flow, aimed at training machine learning models. By measuring entanglement and non-stabilizerness on MPS-encoded functions, we estimate the computational complexity encountered by a stabilizer or a tensor network solver applied to Computational Fluid Dynamics (CFD) simulations across different flow regimes. Our analysis reveals that, under specific initial conditions, the shear width identifies a transition between resource-efficient and resource-intensive regimes for non-trivial evolution. Furthermore, we find that the two resources qualitatively track each other in time, and that the mesh resolution along with the sign structure play a crucial role in determining the resource content of the encoded state. These findings offer useful guidelines for the development of scalable, quantum-inspired approaches to fluid dynamics."}
{"id": "2512.03333", "categories": ["quant-ph", "math.NA", "math.ST", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03333", "abs": "https://arxiv.org/abs/2512.03333", "authors": ["Xun Tang", "Haoxuan Chen", "Yuehaw Khoo", "Lexing Ying"], "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State", "comment": null, "summary": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation."}
{"id": "2512.03983", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.03983", "abs": "https://arxiv.org/abs/2512.03983", "authors": ["Maximilian Baum", "Francesco Sanna Passino", "Axel Gandy"], "title": "Statistical hypothesis testing for differences between layers in dynamic multiplex networks", "comment": "11 pages, 2 figures", "summary": "With the emergence of dynamic multiplex networks, corresponding to graphs where multiple types of edges evolve over time, a key inferential task is to determine whether the layers associated with different edge types differ in their connectivity. In this work, we introduce a hypothesis testing framework, under a latent space network model, for assessing whether the layers share a common latent representation. The method we propose extends previous literature related to the problem of pairwise testing for random graphs and enables global testing of differences between layers in multiplex graphs. While we introduce the method as a test for differences between layers, it can easily be adapted to test for differences between time points. We construct a test statistic based on a spectral embedding of an unfolded representation of the graph adjacency matrices and demonstrate its ability to detect differences across layers in the asymptotic regime where the number of nodes in each graph tends to infinity. The finite-sample properties of the test are empirically demonstrated by assessing its performance on both simulated data and a biological dataset describing the neural activity of larval Drosophila."}
{"id": "2512.03850", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03850", "abs": "https://arxiv.org/abs/2512.03850", "authors": ["Keun-Young Kim", "Kuntal Pal"], "title": "Density of states of quantum systems from free probability theory: a brief overview", "comment": null, "summary": "We provide a brief overview of approaches for calculating the density of states of quantum systems and random matrix Hamiltonians using the tools of free probability theory. For a given Hamiltonian of a quantum system or a generic random matrix Hamiltonian, which can be written as a sum of two non-commutating operators, one can obtain an expression for the density of states of the Hamiltonian from the known density of states of the two component operators by assuming that these operators are mutually free and by using the free additive convolution. In many examples of interacting quantum systems and random matrix models, this procedure is known to provide a reasonably accurate approximation to the exact numerical density of states. We review some of the examples that are known in the literature where this procedure works very well, and also discuss some of the limitations of this method in situations where the free probability approximation fails to provide a sufficiently accurate description of the exact density of states. Subsequently, we describe a perturbation scheme that can be developed from the subordination formulas for the Cauchy transform of the density of states and use it to obtain approximate analytical expressions for the density of states in various models, such as the Rosenzweig-Porter random matrix ensemble and the Anderson model with on-site disorder."}
{"id": "2512.03835", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03835", "abs": "https://arxiv.org/abs/2512.03835", "authors": ["Ghoshana Bista", "Abbas Bradai", "Emmanuel Moulay", "Abdulhalim Dandoush"], "title": "Multi-Agent Deep Reinforcement Learning for UAV-Assisted 5G Network Slicing: A Comparative Study of MAPPO, MADDPG, and MADQN", "comment": "19 pages, 13 figures. Under review for journal submission", "summary": "The growing demand for robust, scalable wireless networks in the 5G-and-beyond era has led to the deployment of Unmanned Aerial Vehicles (UAVs) as mobile base stations to enhance coverage in dense urban and underserved rural areas. This paper presents a Multi-Agent Deep Reinforcement Learning (MADRL) framework that integrates Proximal Policy Optimization (MAPPO), Multi-Agent Deep Deterministic Policy Gradient (MADDPG), and Multi-Agent Deep Q-Networks (MADQN) to jointly optimize UAV positioning, resource allocation, Quality of Service (QoS), and energy efficiency through 5G network slicing. The framework adopts Centralized Training with Decentralized Execution (CTDE), enabling autonomous real-time decision-making while preserving global coordination. Users are prioritized into Premium (A), Silver (B), and Bronze (C) slices with distinct QoS requirements. Experiments in realistic urban and rural scenarios show that MAPPO achieves the best overall QoS-energy tradeoff, especially in interference-rich environments; MADDPG offers more precise continuous control and can attain slightly higher SINR in open rural settings at the cost of increased energy usage; and MADQN provides a computationally efficient baseline for discretized action spaces. These findings demonstrate that no single MARL algorithm is universally dominant; instead, algorithm suitability depends on environmental topology, user density, and service requirements. The proposed framework highlights the potential of MARL-driven UAV systems to enhance scalability, reliability, and differentiated QoS delivery in next-generation wireless networks."}
{"id": "2512.03835", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03835", "abs": "https://arxiv.org/abs/2512.03835", "authors": ["Ghoshana Bista", "Abbas Bradai", "Emmanuel Moulay", "Abdulhalim Dandoush"], "title": "Multi-Agent Deep Reinforcement Learning for UAV-Assisted 5G Network Slicing: A Comparative Study of MAPPO, MADDPG, and MADQN", "comment": "19 pages, 13 figures. Under review for journal submission", "summary": "The growing demand for robust, scalable wireless networks in the 5G-and-beyond era has led to the deployment of Unmanned Aerial Vehicles (UAVs) as mobile base stations to enhance coverage in dense urban and underserved rural areas. This paper presents a Multi-Agent Deep Reinforcement Learning (MADRL) framework that integrates Proximal Policy Optimization (MAPPO), Multi-Agent Deep Deterministic Policy Gradient (MADDPG), and Multi-Agent Deep Q-Networks (MADQN) to jointly optimize UAV positioning, resource allocation, Quality of Service (QoS), and energy efficiency through 5G network slicing. The framework adopts Centralized Training with Decentralized Execution (CTDE), enabling autonomous real-time decision-making while preserving global coordination. Users are prioritized into Premium (A), Silver (B), and Bronze (C) slices with distinct QoS requirements. Experiments in realistic urban and rural scenarios show that MAPPO achieves the best overall QoS-energy tradeoff, especially in interference-rich environments; MADDPG offers more precise continuous control and can attain slightly higher SINR in open rural settings at the cost of increased energy usage; and MADQN provides a computationally efficient baseline for discretized action spaces. These findings demonstrate that no single MARL algorithm is universally dominant; instead, algorithm suitability depends on environmental topology, user density, and service requirements. The proposed framework highlights the potential of MARL-driven UAV systems to enhance scalability, reliability, and differentiated QoS delivery in next-generation wireless networks."}
{"id": "2512.03708", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03708", "abs": "https://arxiv.org/abs/2512.03708", "authors": ["Loaie Solyman", "Aamir Ahmad", "Ayman El-Badawy"], "title": "A Lyapunov-based MPC for Distributed Multi Agent Systems with Time Delays and Packet Dropouts using Hidden Markov Models", "comment": "12 pages, 12 figures", "summary": "We propose a SCHMM LMPC framework, integrating Semi Continuous Hidden Markov Models with Lyapunov based Model Predictive Control, for distributed optimal control of multi agent systems under network imperfections. The SCHMM captures the stochastic network behavior in real time, while LMPC ensures consensus and optimality via Linear Matrix Inequalities LMIs. The developed optimal control problem simultaneously minimizes three elements. First, the control effort is reduced to avoid aggressive inputs and second, the network induced error caused by time delays and packet dropouts. Third, the topology-induced error, as the distributed graph restricts agents access to global information. This error is inherent to the communication graph and cannot be addressed through offline learning. To overcome this, the study also introduces the incremental Expectation Maximization EM algorithm, enabling online learning of the SCHMM. This adaptation allows the framework to mitigate both network and topology errors while maintaining optimality through MPC. Simulations validate the effectiveness of the proposed SCHMM LMPC, demonstrating adaptability in multi agent systems with diverse topologies."}
{"id": "2512.03193", "categories": ["quant-ph", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.03193", "abs": "https://arxiv.org/abs/2512.03193", "authors": ["Yulong Dong", "Christopher Kang", "Murphy Yuezhen Niu"], "title": "In Situ Quantum Analog Pulse Characterization via Structured Signal Processing", "comment": "48 pages, 10 figures", "summary": "Analog quantum simulators can directly emulate time-dependent Hamiltonian dynamics, enabling the exploration of diverse physical phenomena such as phase transitions, quench dynamics, and non-equilibrium processes. Realizing accurate analog simulations requires high-fidelity time-dependent pulse control, yet existing calibration schemes are tailored to digital gate characterization and cannot be readily extended to learn continuous pulse trajectories. We present a characterization algorithm for in situ learning of pulse trajectories by extending the Quantum Signal Processing (QSP) framework to analyze time-dependent pulses. By combining QSP with a logical-level analog-digital mapping paradigm, our method reconstructs a smooth pulse directly from queries of the time-ordered propagator, without requiring mid-circuit measurements or additional evolution. Unlike conventional Trotterization-based methods, our approach avoids unscalable performance degradation arising from accumulated local truncation errors as the logical-level segmentation increases. Through rigorous theoretical analysis and extensive numerical simulations, we demonstrate that our method achieves high accuracy with strong efficiency and robustness against SPAM as well as depolarizing errors, providing a lightweight and optimal validation protocol for analog quantum simulators capable of detecting major hardware faults."}
{"id": "2512.04059", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.04059", "abs": "https://arxiv.org/abs/2512.04059", "authors": ["Alden Green", "Jonathan Taylor"], "title": "Inference for location and height of peaks of a standardized field after selection", "comment": null, "summary": "Peak inference concerns the use of local maxima (\"peaks\") of a noisy random field to detect and localize regions where underlying signal is present. We propose a peak inference method that first subjects observed peaks to a significance test of the null hypothesis that no signal is present, and then uses the peaks that are declared significant to construct post-selectively valid confidence regions for the location and height of nearby true peaks. We analyze the performance of this method in a smooth signal plus constant variance noise model under a high-curvature asymptotic assumption, and prove that it asymptotically controls both the number of false discoveries, and the number of confidence regions that do not contain a true peak, relative to the number of points at which inference is conducted. An important intermediate theoretical result uses the Kac-Rice formula to derive a novel approximation to the intensity function of a point process that counts local maxima, which is second-order accurate under the alternative, nearby high-curvature true peaks."}
{"id": "2512.03935", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03935", "abs": "https://arxiv.org/abs/2512.03935", "authors": ["Baibhab Bose", "Devvrat Tiwari", "Subhashish Banerjee"], "title": "Thermodynamics of an Open $\\mathcal{PT-}$Symmetric Quantum System", "comment": "10 pages, 4 figures", "summary": "For a subclass of a general $\\mathcal{PT}-$symmetric Hamiltonian obeying anti-commutation relation with its conjugate, a Hermitian basis is found that spans the bi-orthonormal energy eigenvectors. Using the modified projectors constructed from these eigenvectors, the generalized density matrix of the $\\mathcal{PT}-$symmetric evolution is calculated, and subsequently, ergotropy for a closed system is obtained. The $\\mathcal{PT}-$symmetric system, in an open system scenario, is studied to understand ergotropy under different regimes of non-Hermiticity of the Hamiltonian. The consistency of the three laws of thermodynamics for the $\\mathcal{PT}-$symmetric system in an open system scenario is also analyzed."}
{"id": "2512.03846", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03846", "abs": "https://arxiv.org/abs/2512.03846", "authors": ["Mojtaba Fanoodi", "Farzaneh Abdollahi", "Mahdi Aliyari Shoorehdeli"], "title": "Fault-Tolerant Control of Steam Temperature in HRSG Superheater under Actuator Fault Using a Sliding Mode Observer and PINN", "comment": null, "summary": "This paper presents a novel fault-tolerant control framework for steam temperature regulation in Heat Recovery Steam Generators (HRSGs) subject to actuator faults. Addressing the critical challenge of valve degradation in superheater spray attemperators, we propose a synergistic architecture comprising three components: (1) a Sliding Mode Observer (SMO) for estimation of unmeasured thermal states, (2) a Physics-Informed Neural Network (PINN) for estimating multiplicative actuator faults using physical laws as constraints, and (3) a one-sided Sliding Mode Controller (SMC) that adapts to the estimated faults while minimizing excessive actuation.\n  The key innovation lies in the framework of closed-loop physics-awareness, where the PINN continuously informs both the observer and controller about fault severity while preserving thermodynamic consistency.\n  Rigorous uniform ultimate boundedness (UUB) is established via Lyapunov analysis under practical assumptions. Validated on real HRSG operational data, the framework demonstrates effective fault adaptation, reduced temperature overshoot, and maintains steam temperature within 1°C of the setpoint under valve effectiveness loss.\n  This work bridges control theory and physics-guided machine learning to deliver a practically deployable solution for power plant resilience, with extensions applicable to thermal systems subject to multiplicative faults."}
{"id": "2512.03846", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03846", "abs": "https://arxiv.org/abs/2512.03846", "authors": ["Mojtaba Fanoodi", "Farzaneh Abdollahi", "Mahdi Aliyari Shoorehdeli"], "title": "Fault-Tolerant Control of Steam Temperature in HRSG Superheater under Actuator Fault Using a Sliding Mode Observer and PINN", "comment": null, "summary": "This paper presents a novel fault-tolerant control framework for steam temperature regulation in Heat Recovery Steam Generators (HRSGs) subject to actuator faults. Addressing the critical challenge of valve degradation in superheater spray attemperators, we propose a synergistic architecture comprising three components: (1) a Sliding Mode Observer (SMO) for estimation of unmeasured thermal states, (2) a Physics-Informed Neural Network (PINN) for estimating multiplicative actuator faults using physical laws as constraints, and (3) a one-sided Sliding Mode Controller (SMC) that adapts to the estimated faults while minimizing excessive actuation.\n  The key innovation lies in the framework of closed-loop physics-awareness, where the PINN continuously informs both the observer and controller about fault severity while preserving thermodynamic consistency.\n  Rigorous uniform ultimate boundedness (UUB) is established via Lyapunov analysis under practical assumptions. Validated on real HRSG operational data, the framework demonstrates effective fault adaptation, reduced temperature overshoot, and maintains steam temperature within 1°C of the setpoint under valve effectiveness loss.\n  This work bridges control theory and physics-guided machine learning to deliver a practically deployable solution for power plant resilience, with extensions applicable to thermal systems subject to multiplicative faults."}
{"id": "2512.03726", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03726", "abs": "https://arxiv.org/abs/2512.03726", "authors": ["Christophe Vauthier"], "title": "Variational Analysis in the Wasserstein Hierarchy", "comment": null, "summary": "Let $M$ be a complete connected Riemannian manifold. For $n \\geq 0$, we endow the Wasserstein space $P^{(n)}_2(M) = P_2(\\ldots P_2(M)\\ldots)$, equipped with the Wasserstein distance $W_2$, with a variational structure that generalizes the standard variational structure on $P_2(M)$ provided by optimal transport theory. Our approach makes use of tools from category theory to lift the geometric structure of the manifold $M$ to the spaces $P^{(n)}_2(M)$, in order to establish in a principled way a rigorous theoretical framework for variational analysis on the space $P^{(n)}_2(M)$. In particular, we obtain a precise characterization of the constant speed geodesics of the space $P^{(n)}_2(M)$ in terms of optimal velocity plans. Moreover, we introduce a notion of gradient for functionals defined on $P^{(n)}_2(M)$, which allows us to study the differentiability and the convexity of various types of such functionals."}
{"id": "2512.03274", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03274", "abs": "https://arxiv.org/abs/2512.03274", "authors": ["Lucas P. Kamizaki", "Marcus V. S. Bonança"], "title": "Excess work in counterdiabatic driving", "comment": null, "summary": "Many years have passed since the conception of the quintessential method of shortcut to adiabaticity known as counterdiabatic driving (or transitionless quantum driving). Yet, this method appears to be energetically cost-free and thus continually challenges the task of quantifying the amount of energy it demands to be accomplished. This paper proposes that the energy cost of controlling a closed quantum system using the counterdiabatic method can also be assessed using the instantaneous excess work during the process and related quantities, as the time-averaged excess work. Starting from the Mandelstam-Tamm bound for driven dynamics, we have shown that the speed-up of counterdiabatic driving is linked with the spreading of energy between the eigenstates of the total Hamiltonian, which is necessarily accompanied by transitions between these eigenstates. Nonetheless, although excess work can be used to quantify energetically these transitions, it is well known that the excess work is zero throughout the entire process under counterdiabatic driving. To recover the excess work as an energetic cost quantifier for counterdiabatic driving, we will propose a different interpretation of the parameters of the counterdiabatic Hamiltonian, leading to an excess work different from zero. We have illustrated our findings with the Landau-Zener model."}
{"id": "2512.04024", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2512.04024", "abs": "https://arxiv.org/abs/2512.04024", "authors": ["V. A. Ulitko", "D. N. Yasinskaya", "S. A. Bezzubin", "A. A. Koshelev", "Y. D. Panov"], "title": "Predicting parameters of a model cuprate superconductor using machine learning", "comment": "22 pages, 8 figures, 2 tables", "summary": "The computational complexity of calculating phase diagrams for multi-parameter models significantly limits the ability to select parameters that correspond to experimental data. This work presents a machine learning method for solving the inverse problem - forecasting the parameters of a model Hamiltonian for a cuprate superconductor based on its phase diagram. A comparative study of three deep learning architectures was conducted: VGG, ResNet, and U-Net. The latter was adapted for regression tasks and demonstrated the best performance. Training the U-Net model was performed on an extensive dataset of phase diagrams calculated within the mean-field approximation, followed by validation on data obtained using a semi-classical heat bath algorithm for Monte Carlo simulations. It is shown that the model accurately predicts all considered Hamiltonian parameters, and areas of low prediction accuracy correspond to regions of parametric insensitivity in the phase diagrams. This allows for the extraction of physically interpretable patterns and validation of the significance of parameters for the system. The results confirm the promising potential of applying machine learning to analyze complex physical models in condensed matter physics."}
{"id": "2512.03977", "categories": ["eess.SY", "cs.IT", "math.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.03977", "abs": "https://arxiv.org/abs/2512.03977", "authors": ["Giannis Delimpaltadakis", "Gabriel Gleizer"], "title": "An Information Theory of Finite Abstractions and their Fundamental Scalability Limits", "comment": null, "summary": "Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy\" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system."}
{"id": "2512.03977", "categories": ["eess.SY", "cs.IT", "math.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.03977", "abs": "https://arxiv.org/abs/2512.03977", "authors": ["Giannis Delimpaltadakis", "Gabriel Gleizer"], "title": "An Information Theory of Finite Abstractions and their Fundamental Scalability Limits", "comment": null, "summary": "Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy\" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system."}
{"id": "2512.03732", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03732", "abs": "https://arxiv.org/abs/2512.03732", "authors": ["Zhongxin Hu", "Christina Imdahl", "Zumbul Atan"], "title": "Strategic Selection of Remanufacturing Business Models: A Consumer Perception Perspective", "comment": null, "summary": "As a key circular economy strategy, remanufacturing allows original equipment manufacturers (OEMs) to reduce waste by restoring used products to ``as-new'' conditions. This paper investigates an OEM's optimal remanufacturing business model by incorporating consumer perceptions into price and production quantity decisions. We analyze three alternative models: no remanufacturing, OEM in-house remanufacturing, and third-party remanufacturer (TPR) authorized remanufacturing. We extend the authorization with a two-part tariff contract and consider a stochastic market size. Through a numerical approach, we optimize price and quantity decisions based on consumer perceptions and develop a hierarchical decision roadmap to guide model selection. Our findings show that when consumer's perceived value of remanufactured products is high, OEM in-house remanufacturing is most profitable and reduces environmental impacts, but generally leads to a market dominated by remanufactured products. In contrast, when consumer's perceived value of remanufactured products is moderate and TPR remanufacturing significantly increases the perceived value of new products, the TPR-authorized remanufacturing is most profitable. It typically boosts total market sales, but accordingly increases environmental impacts. In addition, sensitivity analysis indicates that two-part authorization contracts are more advanced in meeting stringent environmental requirements than one-part contracts. Incorporating market size stochasticity enhances system profitability while keeping environmental impacts within a limited scope."}
{"id": "2512.03333", "categories": ["quant-ph", "math.NA", "math.ST", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.03333", "abs": "https://arxiv.org/abs/2512.03333", "authors": ["Xun Tang", "Haoxuan Chen", "Yuehaw Khoo", "Lexing Ying"], "title": "Sketch Tomography: Hybridizing Classical Shadow and Matrix Product State", "comment": null, "summary": "We introduce Sketch Tomography, an efficient procedure for quantum state tomography based on the classical shadow protocol used for quantum observable estimations. The procedure applies to the case where the ground truth quantum state is a matrix product state (MPS). The density matrix of the ground truth state admits a tensor train ansatz as a result of the MPS assumption, and we estimate the tensor components of the ansatz through a series of observable estimations, thus outputting an approximation of the density matrix. The procedure is provably convergent with a sample complexity that scales quadratically in the system size. We conduct extensive numerical experiments to show that the procedure outputs an accurate approximation to the quantum state. For observable estimation tasks involving moderately large subsystems, we show that our procedure gives rise to a more accurate estimation than the classical shadow protocol. We also show that sketch tomography is more accurate in observable estimation than quantum states trained from the maximum likelihood estimation formulation."}
{"id": "2512.04037", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.04037", "abs": "https://arxiv.org/abs/2512.04037", "authors": ["Lorenzo Tonetti", "Leticia F. Cugliandolo", "Marco Tarzia"], "title": "Testing the Localization Landscape Theory on the Bethe Lattice", "comment": null, "summary": "The Localization Landscape Theory (LLT) provides a classical picture of Anderson localization by introducing an effective confining potential whose percolation is proposed to coincide with the mobility edge. Although this proposal shows remarkable numerical agreement in three dimensions, its fundamental validity remains unsettled. Here we test the LLT analytically on the Bethe lattice, where both the Anderson localization transition and the LLT percolation problem are exactly solvable. We find that the two transitions do not coincide, and their critical behaviors differ markedly. In particular, LLT percolation displays standard mean-field percolation criticality that is fundamentally distinct from the peculiar critical behavior of the Anderson transition on the Bethe lattice. Our results provide an exact benchmark showing that, while geometrically intuitive, the LLT does not capture the true quantum critical properties of localization."}
{"id": "2512.03990", "categories": ["eess.SY", "physics.app-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.03990", "abs": "https://arxiv.org/abs/2512.03990", "authors": ["Soha Ilbeigi", "Ashkan Bagherzadeh", "Alireza Sharifi"], "title": "Applied Neural Network-Based Active Control for Vortex-Induced Vibrations Suppression in a Two-Degree-of-Freedom Cylinder", "comment": null, "summary": "Vortex-Induced Vibrations (VIVs) of cylindrical structures present significant challenges in various engineering applications, including marine risers, tall buildings, and renewable energy systems. Hence, it is vital to control Vortex-Induced Vibrations of cylindrical structures. For this purpose, in this study a novel approach is introduced to VIV control, based on a model-based active control strategy integrated with a Neural Network (NN) in the presence of uncertainty modeling. The proposed method utilizes a closed-loop control system, where feedback from the system's dynamic state is used to generate adaptive control commands, enabling the system to respond to changing flow conditions and nonlinearities. Then, the controllability analysis is conducted to assess the efficiency of the control strategy in mitigating VIV. Two control approaches are implemented: simple learning and composite learning. Both strategies significantly enhance vibration suppression, achieving up to 99% reduction in vibrations despite uncertainties in the system. The results demonstrate the potential of the proposed method to enhance the efficiency, stability, and lifespan of structures subject to VIV."}
{"id": "2512.03990", "categories": ["eess.SY", "physics.app-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.03990", "abs": "https://arxiv.org/abs/2512.03990", "authors": ["Soha Ilbeigi", "Ashkan Bagherzadeh", "Alireza Sharifi"], "title": "Applied Neural Network-Based Active Control for Vortex-Induced Vibrations Suppression in a Two-Degree-of-Freedom Cylinder", "comment": null, "summary": "Vortex-Induced Vibrations (VIVs) of cylindrical structures present significant challenges in various engineering applications, including marine risers, tall buildings, and renewable energy systems. Hence, it is vital to control Vortex-Induced Vibrations of cylindrical structures. For this purpose, in this study a novel approach is introduced to VIV control, based on a model-based active control strategy integrated with a Neural Network (NN) in the presence of uncertainty modeling. The proposed method utilizes a closed-loop control system, where feedback from the system's dynamic state is used to generate adaptive control commands, enabling the system to respond to changing flow conditions and nonlinearities. Then, the controllability analysis is conducted to assess the efficiency of the control strategy in mitigating VIV. Two control approaches are implemented: simple learning and composite learning. Both strategies significantly enhance vibration suppression, achieving up to 99% reduction in vibrations despite uncertainties in the system. The results demonstrate the potential of the proposed method to enhance the efficiency, stability, and lifespan of structures subject to VIV."}
{"id": "2512.03739", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03739", "abs": "https://arxiv.org/abs/2512.03739", "authors": ["Guilherme Freitas", "Luiz Carlos da Costa Junior", "Tiago Andrade", "Alexandre Street"], "title": "Penalty-Free SDDP: Feasibility Cuts for Robust Multi-Stage Stochastic Optimization in Energy Planning", "comment": "8 pages, 1 figure, 1 table", "summary": "Multi-stage decision problems under uncertainty can be efficiently solved with the Stochastic Dual Dynamic Programming (SDDP) algorithm. However, traditional implementations require all stage problems to be feasible. Feasibility is usually enforced by adding slack variables and penalizing them in the objective function, a process that depends on case-specific calibration and often distorts the economic interpretation of results. This paper proposes the Penalty-Free SDDP, an extension that introduces a Future Feasibility Function alongside the traditional Future Cost Function. The new recursion handles infeasibilities automatically, distinguishing between temporary and truly infeasible cases, and propagates feasibility information across stages through dedicated feasibility cuts. The approach was validated in a large-scale deterministic case inspired by the Brazilian hydrothermal system, achieving equivalent feasibility to the benchmark solution while eliminating miscalibrated artificial penalties. Results confirm its robustness and practicality as a foundation for future stochastic, multi-stage applications."}
{"id": "2512.03341", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03341", "abs": "https://arxiv.org/abs/2512.03341", "authors": ["Ching-Tai Huang", "Yu-Cheng Lin", "Ferenc Igloi"], "title": "Quench dynamics of the quantum XXZ chain with staggered interactions: Exact results and simulations on digital quantum computers", "comment": "15 pages, 16 figures", "summary": "We investigate quench dynamics in the quantum $S=1/2$ XXZ antiferromagnetic chain with staggered and anisotropic interactions in the flat-band limit. Our quench protocol interchanges the odd- and even-bond strengths of a fully dimerized chain, enabling us to derive exact time-dependent states for arbitrary even system sizes by working in the Bell basis. We obtain closed-form, size-independent expressions for the von Neumann and second-order Rényi entanglement entropies. We further calculate exact Loschmidt echoes and the corresponding return rate functions across various anisotropies and system sizes, and identify Loschmidt zeros in finite chains. Our analysis reveals the precise conditions on the anisotropy parameter that govern the periodicity of the dynamical observables. In addition to the analytic study, we perform two types of numerical experiments on IBM-Q quantum devices. First, we use the Hadamard test to estimate the Bell-basis expansion coefficients and reconstruct the dynamical states, achieving accurate entanglement entropies and the Loschmidt echo for small systems. Second, we implement Trotter-error-free time-evolution circuits combined with randomized Pauli measurements. Post-processing via statistical correlations and classical shadows yields reliable estimates of the second-order Rényi entanglement entropy and the Loschmidt echo, showing satisfactory agreement with exact results."}
{"id": "2512.03434", "categories": ["quant-ph", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03434", "abs": "https://arxiv.org/abs/2512.03434", "authors": ["Zihao Ren", "Daniel Quevedo", "Salah Sukkarieh", "Guodong Shi"], "title": "Quantum Encrypted Control of Networked Systems", "comment": "24 pages", "summary": "Encrypted control has been extensively studied to ensure the confidentiality of system states and control inputs for networked control systems. This paper presents a computationally efficient encrypted control framework for networked systems enabled by quantum communication. A quantum channel between sensors and actuators is used to generate identical secret keys, whose security is further enhanced through quantum key distribution. These keys enable lightweight encryption and decryption while preserving confidentiality and control accuracy. We develop a novel encryption-decryption architecture for state-feedback control of linear systems based on quantum keys, and characterize the impact of quantum state errors on closed-loop stability. In particular, we establish the existence of a critical threshold on intrinsic quantum noise below which stability is guaranteed. In contrast to classical encrypted control schemes, which may collapse under a single key-bit error, the proposed quantum encrypted control exhibits strong robustness to key imperfections. We further adopt quantization techniques to address the scenarios with limited communication bits in practical situations, and implement privacy protection for quantum keys based on a stochastic quantizer. These results demonstrate that integrating quantum technologies into control systems in a nontrivial and principled manner, even at their current level of maturity, can yield substantial performance gains in reducing computational complexity and improving resilience to key errors while ensuring security against multiple eavesdropping sources."}
{"id": "2512.03434", "categories": ["quant-ph", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03434", "abs": "https://arxiv.org/abs/2512.03434", "authors": ["Zihao Ren", "Daniel Quevedo", "Salah Sukkarieh", "Guodong Shi"], "title": "Quantum Encrypted Control of Networked Systems", "comment": "24 pages", "summary": "Encrypted control has been extensively studied to ensure the confidentiality of system states and control inputs for networked control systems. This paper presents a computationally efficient encrypted control framework for networked systems enabled by quantum communication. A quantum channel between sensors and actuators is used to generate identical secret keys, whose security is further enhanced through quantum key distribution. These keys enable lightweight encryption and decryption while preserving confidentiality and control accuracy. We develop a novel encryption-decryption architecture for state-feedback control of linear systems based on quantum keys, and characterize the impact of quantum state errors on closed-loop stability. In particular, we establish the existence of a critical threshold on intrinsic quantum noise below which stability is guaranteed. In contrast to classical encrypted control schemes, which may collapse under a single key-bit error, the proposed quantum encrypted control exhibits strong robustness to key imperfections. We further adopt quantization techniques to address the scenarios with limited communication bits in practical situations, and implement privacy protection for quantum keys based on a stochastic quantizer. These results demonstrate that integrating quantum technologies into control systems in a nontrivial and principled manner, even at their current level of maturity, can yield substantial performance gains in reducing computational complexity and improving resilience to key errors while ensuring security against multiple eavesdropping sources."}
{"id": "2512.03747", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03747", "abs": "https://arxiv.org/abs/2512.03747", "authors": ["Margarita A. Guerrero", "Rodrigo A. González", "Cristian R. Rojas"], "title": "Sample-Efficient Counterfactual Tuning for Compressor Pressure Control", "comment": "8 pages", "summary": "In controlled industrial environments, ensuring safety and performance during controller tuning is a challenging and critical task. In particular, control loops in compressor-plenum-throttle systems cannot tolerate costly interruptions, and aggressive excitation may lead to unsafe operating regimes. Given the wide availability of historical data, this paper introduces a counterfactual explainability approach for sample-efficient retuning of compressor control loops. The proposed data-driven algorithm determines, without an explicit plant model or previous control law, the smallest controller adjustment required to achieve predefined performance specifications while guaranteeing stability. The effectiveness of the method is demonstrated through an extensive Monte Carlo simulation study."}
{"id": "2512.03362", "categories": ["quant-ph", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2512.03362", "abs": "https://arxiv.org/abs/2512.03362", "authors": ["Danial Davoudi", "Abdul Mohamed", "Shabir Barzanjeh"], "title": "Hybridized-Mode Parametric Amplifier in Kinetic-Inductance Circuits", "comment": null, "summary": "Parametric amplification is essential for quantum measurement, enabling the amplification of weak microwave signals with minimal added noise. While Josephson-junction-based amplifiers have become standard in superconducting quantum circuits, their magnetic sensitivity, limited saturation power, and sub-kelvin operating requirements motivate the development of alternative nonlinear platforms. Here we demonstrate a two-mode kinetic-inductance parametric amplifier based on a pair of capacitively coupled Kerr-nonlinear resonators fabricated from NbTiN and NbN thin films. The distributed Kerr nonlinearity of these materials enables nondegenerate four-wave-mixing amplification with gains approaching 40 dB, gain-bandwidth products up to 6.9 MHz, and 1-dB compression powers two to three orders of magnitude higher than those of state-of-the-art Josephson amplifiers. A coupled-mode theoretical model accurately captures the pump-induced modification of the hybridized modes and quantitatively reproduces the observed signal and idler responses. The NbN device exhibits a significantly larger Kerr coefficient and superior gain-bandwidth performance, highlighting the advantages of high-kinetic-inductance materials. Our results establish coupled kinetic-inductance resonators as a robust platform for broadband, high-power, and magnetically resilient quantum-limited amplification, offering a scalable route for advanced readout in superconducting qubits, spin ensembles, quantum dots, and other microwave-quantum technologies."}
{"id": "2512.03524", "categories": ["math.OC", "cs.ET", "cs.MA", "econ.TH", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03524", "abs": "https://arxiv.org/abs/2512.03524", "authors": ["Grzegorz Jamróz", "Rafał Kucharski", "David Watling"], "title": "Market share maximizing strategies of CAV fleet operators may cause chaos in our cities", "comment": "34 pages, 9 figures", "summary": "We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities."}
{"id": "2512.03524", "categories": ["math.OC", "cs.ET", "cs.MA", "econ.TH", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03524", "abs": "https://arxiv.org/abs/2512.03524", "authors": ["Grzegorz Jamróz", "Rafał Kucharski", "David Watling"], "title": "Market share maximizing strategies of CAV fleet operators may cause chaos in our cities", "comment": "34 pages, 9 figures", "summary": "We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities."}
{"id": "2512.03915", "categories": ["math.OC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.03915", "abs": "https://arxiv.org/abs/2512.03915", "authors": ["X. Y. Han", "Yuan Zhong"], "title": "A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models", "comment": null, "summary": "In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models."}
{"id": "2512.03423", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03423", "abs": "https://arxiv.org/abs/2512.03423", "authors": ["Weijun Cheng", "Da-Wei Wang", "Yang Xue", "Zhihai Wang", "Liantuan Xiao"], "title": "Engineering photonic dispersion relation and atomic dynamics in waveguide QED setup via long-range hoppings", "comment": "11 pages, 7 figures", "summary": "Non-trivial dispersion relations engineered in photonic waveguide for the precise control of atomic dynamics has recently attracted considerable attention. Here, we study a system in which atoms are coupled to one-dimensional coupled-resonator waveguides with long-range hoppings. By carefully engineering the jth-order nearest neighbor (JNN) hoppings between resonators, we construct linear dispersion relations with the chiral characteristic. To quantify the degree of linearity, we analyze the propagation fidelities of Gaussian wave packets in these waveguides. Furthermore, we demonstrate that such coupled-resonator waveguides can serve as versatile platforms for enabling directional atomic radiation and absorption. Beyond linear dispersion relations, more general forms, including quadratic and cubic relations, can also be achieved through tailored JNN-hoppings. Our study thus provides a unified framework for simulating atom-environment couplings with arbitrary dispersion relations."}
{"id": "2512.03934", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03934", "abs": "https://arxiv.org/abs/2512.03934", "authors": ["Nguyen Thi Van Hang", "Felipe Lara", "Nguyen Dong Yen"], "title": "Discontinuous Strongly Quasiconvex Functions", "comment": "15 pages", "summary": "A fundamental open question asking whether all real-valued strongly quasiconvex functions defined on $\\mathbb R^n$ are necessarily continuous, akin to their convex counterparts, is answered in detail in this paper. Among other things, we show that such functions can have infinitely many points of discontinuity. The failure of lower semicontinuity together with the lack of upper semicontinuity at infinitely many points of certain real-valued strongly quasiconvex functions are also shown."}
{"id": "2512.03434", "categories": ["quant-ph", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.03434", "abs": "https://arxiv.org/abs/2512.03434", "authors": ["Zihao Ren", "Daniel Quevedo", "Salah Sukkarieh", "Guodong Shi"], "title": "Quantum Encrypted Control of Networked Systems", "comment": "24 pages", "summary": "Encrypted control has been extensively studied to ensure the confidentiality of system states and control inputs for networked control systems. This paper presents a computationally efficient encrypted control framework for networked systems enabled by quantum communication. A quantum channel between sensors and actuators is used to generate identical secret keys, whose security is further enhanced through quantum key distribution. These keys enable lightweight encryption and decryption while preserving confidentiality and control accuracy. We develop a novel encryption-decryption architecture for state-feedback control of linear systems based on quantum keys, and characterize the impact of quantum state errors on closed-loop stability. In particular, we establish the existence of a critical threshold on intrinsic quantum noise below which stability is guaranteed. In contrast to classical encrypted control schemes, which may collapse under a single key-bit error, the proposed quantum encrypted control exhibits strong robustness to key imperfections. We further adopt quantization techniques to address the scenarios with limited communication bits in practical situations, and implement privacy protection for quantum keys based on a stochastic quantizer. These results demonstrate that integrating quantum technologies into control systems in a nontrivial and principled manner, even at their current level of maturity, can yield substantial performance gains in reducing computational complexity and improving resilience to key errors while ensuring security against multiple eavesdropping sources."}
{"id": "2512.03947", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.03947", "abs": "https://arxiv.org/abs/2512.03947", "authors": ["Matthew Hough", "Stephen A. Vavasis"], "title": "Data-Dependent Complexity of First-Order Methods for Binary Classification", "comment": null, "summary": "Large-scale problems in data science are often modeled with optimization, and the optimization model is usually solved with first-order methods that may converge at a sublinear rate. Therefore, it is of interest to terminate the optimization algorithm as soon as the underlying data science task is accomplished. We consider FISTA for solving two binary classification problems: the ellipsoid separation problem (ESP), and the soft-margin support-vector machine (SVM). For the ESP, we cast the dual second-order cone program into a form amenable to FISTA and show that the FISTA residual converges to the infimal displacement vector of the primal-dual hybrid gradient (PDHG) algorithm, that directly encodes a separating hyperplane. We further derive a data-dependent iteration upper bound scaling as $\\mathcal{O}(1/δ_{\\mathcal{A}}^2)$, where $δ_{\\mathcal{A}}$ is the minimal perturbation that destroys separability. For the SVM, we propose a strongly-concave perturbed dual that admits efficient FISTA updates under a linear time projection scheme, and with our parameter choices, the objective has small condition number, enabling rapid convergence. We prove that, under a reasonable data model, early-stopped iterates identify well-classified points and yield a hyperplane that exactly separates them, where the accuracy required of the dual iterate is governed by geometric properties of the data. In particular, the proposed early-stopping criteria diminish the need for hard-to-select tolerance-based stopping conditions. Our numerical experiments on ESP instances derived from MNIST data and on soft-margin SVM benchmarks indicate competitive runtimes and substantial speedups from stopping early."}
{"id": "2512.03457", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03457", "abs": "https://arxiv.org/abs/2512.03457", "authors": ["Ke Wang", "Zhiyan Ding"], "title": "Beyond Lindblad Dynamics: Rigorous Guarantees for Thermal and Ground State Preservation under System Bath Interactions", "comment": null, "summary": "We establish new theoretical results demonstrating the efficiency and robustness of system bath interaction models for quantum thermal and ground state preparation. Unlike existing analyses, which relies on the weak coupling Lindblad limit and require $O(ε)$ coupling strengths for $ε$ accuracy, leading to slow mixing, we rigorously show that accurate state preparation remains possible far beyond this regime. In particular, even when the cumulative coupling strength remains constant rather than vanishing, the induced quantum channel still approximately fixes the target state. Our proof introduces new techniques for controlling all orders of the Dyson expansion and for analyzing the associated multidimensional operator Fourier transforms. These bounds substantially improve upon prior results, and numerical simulations on the TFIM and Hubbard models further confirm the robustness of the system bath interaction framework across both weak and strong coupling regimes."}
{"id": "2512.03555", "categories": ["cs.CE", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.03555", "abs": "https://arxiv.org/abs/2512.03555", "authors": ["Lucie Kubíčková", "Onřej Gebouský", "Jan Haidl", "Martin Isoz"], "title": "Accelerating shape optimization by deep neural networks with on-the-fly determined architecture", "comment": "Initial submitted manuscript version", "summary": "In component shape optimization, the component properties are often evaluated by computationally expensive simulations. Such optimization becomes unfeasible when it is focused on a global search requiring thousands of simulations to be evaluated. Here, we present a viable global shape optimization methodology based on multi-objective evolutionary algorithms accelerated by deep neural networks (DNNs). Our methodology alternates between evaluating simulations and utilizing the generated data to train DNNs with various architectures. When a suitable DNN architecture is identified, the DNN replaces the simulation in the rest of the global search. Our methodology was tested on five ZDT benchmark functions, showing itself at the level of and sometimes more flexible than other state-of-the-art acceleration approaches. Then, it was applied to a real-life optimization problem, namely the shape optimization of a single-phase ejector. Compared with a non-accelerated methodology, ours was able to save weeks of CPU time in solving this problem. To experimentally confirm the performance of the optimized ejector shapes, four of them were 3D printed and tested on the lab scale confirming the predicted performance. This suggests that our methodology could be used for acceleration of other real-life shape optimization problems."}
{"id": "2512.03505", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03505", "abs": "https://arxiv.org/abs/2512.03505", "authors": ["Kyu-Won Park", "Jongin Jeong"], "title": "Complex Wigner entropy and Fisher control of negativity in an oval quantum billiard", "comment": "7 pages, 4 figures", "summary": "We develop a complex-entropy framework for Wigner negativity and apply it to avoided crossings in an oval quantum billiard. For a real Wigner function the Gibbs--Shannon functional becomes complex; its imaginary part, proportional to the Wigner-negative volume, serves as an entropy-like measure of phase-space nonclassicality. A sign-resolved decomposition separates the total negative weight from its phase-space distribution and defines a negative-channel Fisher information that quantifies how sensitively the negative lobe reshapes as a control parameter is varied. This structure yields a Cauchy--Schwarz bound that limits how rapidly the imaginary entropy, and hence the Wigner negativity, can change with the parameter. In the oval billiard, avoided crossings display enhanced negativity and an amplified negative-channel Fisher response, providing a clear phase-space signature of mode hybridization. The construction is generic and extends to other wave-chaotic and mesoscopic systems with phase-space representations."}
{"id": "2512.03977", "categories": ["eess.SY", "cs.IT", "math.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.03977", "abs": "https://arxiv.org/abs/2512.03977", "authors": ["Giannis Delimpaltadakis", "Gabriel Gleizer"], "title": "An Information Theory of Finite Abstractions and their Fundamental Scalability Limits", "comment": null, "summary": "Finite abstractions are discrete approximations of dynamical systems, such that the set of abstraction trajectories contains, in a formal sense, all system trajectories. There is a consensus that abstractions suffer from the curse of dimensionality: for the same ``accuracy\" (how closely the abstraction represents the system), the abstraction size scales poorly with system dimensions. And, yet, after decades of research on abstractions, there are no formal results concerning their accuracy-size tradeoff. In this work, we derive a statistical, quantitative theory of abstractions' accuracy-size tradeoff and uncover fundamental limits on their scalability, through rate-distortion theory -- the branch of information theory studying lossy compression. Abstractions are viewed as encoder-decoder pairs, encoding trajectories of dynamical systems in a higher-dimensional ambient space. Rate represents abstraction size, while distortion describes abstraction accuracy, defined as the spatial average deviation between abstract trajectories and system ones. We obtain a fundamental lower bound on the minimum abstraction distortion, given the system dynamics and a threshold on abstraction size. The bound depends on the complexity of the dynamics, through generalized entropy. We demonstrate the bound's tightness on certain dynamical systems. Finally, we showcase how the developed theory can be employed to construct optimal abstractions, in terms of the size-accuracy tradeoff, through an example on a chaotic system."}
{"id": "2512.03530", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03530", "abs": "https://arxiv.org/abs/2512.03530", "authors": ["Yoshihito Kuno"], "title": "Edge bits in average symmetry protected topological mixed state", "comment": "6+4 pages, 3+2 figures", "summary": "Edge bit in an average symmetry protected topological (ASPT) mixed state is studied. The state is protected by one strong $Z_2$ and one weak (average) $Z_2$ symmetries. As analogous objects of pure symmetry protected topological (SPT) states, the ASPT possesses edge bits. In particular, the analogous operator response exists, that is, symmetry fractionalization. The fractionalization preserves the presence of the ASPT in the bulk, and the fractionalized edge operators acting on the edge bits of the ASPT. %analogous to the ones in the pure SPTs. In this work, based on the cluster model and by employing Choi mapping, we discuss generic features of the edge bits and numerically clarify the behavior of the edge bits and their robustness for varying decoherence and perturbative interactions. By using an operator-space mutual information (OSMI), we track the flow of quantum correlations between the two edges. Remarkably, even in the ASPT regime, a finite portion of the initial edge-to-edge correlation survives."}
{"id": "2512.03581", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03581", "abs": "https://arxiv.org/abs/2512.03581", "authors": ["Mohana Priya Thinesh Kumar", "Pranavishvar Hariprakash"], "title": "Quantum Hash Function Based on Spectral Properties of Graphs and Discrete Walker Dynamics", "comment": "19 pages, 11 figures", "summary": "We present Quantum Graph Hash (QGH-256), a novel quantum spectral hashing algorithm that generates high-entropy fingerprints from message-induced graphs. Each input message is mapped to a weighted graph via a discrete random walk on an n X n toroidal grid, where the walk dynamics determine the edge weights. Quantum Phase Estimation (QPE) is then used to extract the phase spectrum of the graph Laplacian. Unlike standard QPE settings, the phase estimation is performed with respect to a superposition state (a uniform superposition over all node basis states) rather than an eigenvector, ensuring that all eigencomponents contribute to the resulting spectrum. This yields spectral features that distinguish even co-spectral but non-isomorphic message-induced graphs. The final spectral fingerprint is converted into a 256-bit digest, producing a compact representation of the input. As the fingerprint encodes both spectral and dynamical properties of the message-induced graph, the resulting hash exhibits strong sensitivity to input perturbations and provides a structurally rich foundation for post-quantum hashing. To demonstrate the feasibility of the approach, we implement QGH-256 on a 4 X 4 toroidal grid, chosen empirically: smaller grids exhibit collisions, whereas larger grids significantly increase execution time. The entire pipeline is implemented in Qiskit, and we use a seeded statevector simulator to obtain stable, noise-free results."}
{"id": "2512.03583", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03583", "abs": "https://arxiv.org/abs/2512.03583", "authors": ["Gui-Zhong Luo", "Matthew Otten"], "title": "Energy-Scaled Zero-Noise Extrapolation for Gottesman-Kitaev-Preskill Code", "comment": null, "summary": "The performance of Gottesman-Kitaev-Preskill (GKP) codes, an approach to hardware-efficient quantum error correction, is limited by the finite squeezing capabilities of current experimental platforms. To circumvent this hardware demand, we introduce Energy-Scaled Zero-Noise Extrapolation (ES-ZNE), a quantum error mitigation protocol that uses the mean photon number of the GKP code as a tunable effective noise parameter. The protocol measures logical observables at a series of accessible finite energies and extrapolates the results to the ideal, infinite-energy limit using an ansatz based on the code's asymptotic error scaling. Through simulating a GKP qubit under a pure-loss channel, we demonstrate that ES-ZNE successfully mitigates finite-energy errors, recovering the ideal expectation values (within numerical uncertainty) in the shallow-noise regime. Furthermore, by computationally removing artifacts arising from the finite-energy encoding, our method characterizes the intrinsic performance of the ideal GKP code, revealing a sharp error threshold beyond which the code's corrective power diminishes. These results establish ES-ZNE as a practical, software-based strategy for enhancing the performance of near-term bosonic quantum processors, trading sampling overhead for demanding physical resources like high squeezing."}
{"id": "2512.03659", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03659", "abs": "https://arxiv.org/abs/2512.03659", "authors": ["Francis Marcellino", "Mingsong Wu", "Rob Thew"], "title": "Experimental quantum voting using photonic GHZ states", "comment": null, "summary": "Quantum communication protocols seek to leverage the unique properties of quantum systems for coordination or communication tasks, usually with guarantees of security or anonymity that exceed what is possible classically. One promising domain of application is elections, where strong such guarantees are essential to ensure legitimacy. We experimentally implement a recently proposed election protocol from Centrone et al. such that no one, including a potential central authority, can know the preferred candidate of any voter other than themself. We conduct a four-party election, generating and distributing four-partite GHZ states with $\\approx 89\\%$ fidelity and successfully recording voters' intentions $\\approx 87\\%$ of the time."}
{"id": "2512.03681", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03681", "abs": "https://arxiv.org/abs/2512.03681", "authors": ["Lilith Zschetzsche", "Refik Mansuroglu", "András Molnár", "Norbert Schuch"], "title": "Direct Equivalence between Dynamics of Quantum Walks and Coupled Classical Oscillators", "comment": "17 pages, 3 figures", "summary": "Continuous time quantum walks on exponentially large, sparse graphs form a powerful paradigm for quantum computing: On the one hand, they can be efficiently simulated on a quantum computer. On the other hand, they are themselves BQP-complete, providing an alternative framework for thinking about quantum computing -- a perspective which has indeed led to a number of novel algorithms and oracle problems. Recently, simulating the dynamics of a system of harmonic oscillators (that is, masses and springs) was set forth as another BQP-complete problem defined on exponentially large, sparse graphs. In this work, we establish a direct and transparent mapping between these two classes of problems. As compared to linking the two classes of problems via their BQP-completeness, our mapping has several desirable features: It is transparent, in that it respects the structure of the problem, including the geometry of the underlying graph, initialization, read-out, and efficient oracle access, resulting in low overhead in terms of both space and time; it allows to map also between restricted subsets of instances of both problems which are not BQP-complete; it provides a recipe to directly translate any quantum algorithm designed in the quantum walk paradigm to harmonic oscillators (and vice versa); and finally, it provides an alternative, transparent way to prove BQP-completeness of the harmonic oscillator problem by mapping it to BQP-completeness construction for the quantum walk problem (or vice versa)."}
{"id": "2512.03685", "categories": ["quant-ph", "cs.DC", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.03685", "abs": "https://arxiv.org/abs/2512.03685", "authors": ["Seng W. Loke"], "title": "Distributed Quantum Computing with Fan-Out Operations and Qudits: the Case of Distributed Global Gates (a Preliminary Study)", "comment": "8 pages, 10 figures; preliminary version (if mistakes found - please contact the author)", "summary": "Much recent work on distributed quantum computing have focused on the use of entangled pairs and distributed two qubit gates. But there has also been work on efficient schemes for achieving multipartite entanglement between nodes in a single shot, removing the need to generate multipartite entangled states using many entangled pairs. This paper looks at how multipartite entanglement resources (e.g., GHZ states) can be useful for distributed fan-out operations; we also consider the use of qudits of dimension four for distributed quantum circuit compression. In particular, we consider how such fan-out operations and qudits can be used to implement circuits which are challenging for distributed quantum computation, involving pairwise qubit interactions, i.e., what has been called global gates (a.k.a. global Mølmer-Sørensen gates). Such gates have been explored to possibly yield more efficient computations via reduced circuit depth, and can be carried out efficiently in some types of quantum hardware (e.g., trapped-ion quantum computers); we consider this as an exploration of an ``extreme'' case for distribution given the global qubit-qubit interactions. We also conclude with some implications for future work on quantum circuit compilation and quantum data centre design."}
{"id": "2512.03690", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03690", "abs": "https://arxiv.org/abs/2512.03690", "authors": ["Jialin Li", "Guangyu Zhang", "Zhang-qi Yin"], "title": "Sympathetic Cooling of Levitated Optomechanics through Nonreciprocal Coupling", "comment": "9 pages, 4 figures", "summary": "Optomechanical cooling of levitated nanoparticles has become an essential topic in modern quantum physics, providing a platform for exploring macroscopic quantum phenomena and high-precision sensing. However, conventional cavity-assisted cooling is fundamentally constrained by cavity dissipation and environmental noise, limiting the attainable minimum temperature. In this work, we propose a non-Hermitian optomechanical cooling scheme through nonreciprocal coupling between two levitated nanoparticles, where one particle is directly cooled by an optical cavity and the other is cooled indirectly through a non-Hermitian interaction. Both analytical solutions and numerical simulations reveal that increasing nonreciprocity enhances directional energy transfer, enabling the target particle to reach a lower phonon occupation than is achievable in conventional cavity cooling. This study demonstrates a new cooling mechanism driven by non-Hermitian interactions, offering theoretical guidance for realizing controllable energy flow and deep cooling in levitated optomechanical systems, and paving the way for future developments in quantum control and sensing technologies."}
{"id": "2512.03717", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03717", "abs": "https://arxiv.org/abs/2512.03717", "authors": ["Alex E. Bernardini"], "title": "Geometrical structure of the Wigner flow information quantifiers and hyperbolic stability in the phase-space framework", "comment": "33 pages, 3 figures", "summary": "Quantifiers of stationarity, classicality, purity and vorticity are derived from phase-space differential geometrical structures within the Weyl-Wigner framework, after which they are related to the hyperbolic stability of classical and quantum-modified Hamiltonian (non-linear) equations of motion. By examining the equilibrium regime produced by such an autonomous system of ordinary differential equations, a correspondence between Wigner flow properties and hyperbolic stability boundaries in the phase-space is identified. Explicit analytical expressions for equilibrium-stability parameters are obtained for quantum Gaussian ensembles, wherein information quantifiers driven by Wigner currents are identified. Illustrated by an application to a Harper-like system, the results provide a self-contained analysis for identifying the influence of quantum fluctuations associated to the emergence of phase-space vorticity in order to quantify equilibrium and stability properties of Hamiltonian non-linear dynamics."}
{"id": "2512.03735", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03735", "abs": "https://arxiv.org/abs/2512.03735", "authors": ["Pritam Chattopadhyay"], "title": "Non-Gaussian Dissipative Quantum Thermometry Beyond Gaussian Bounds", "comment": null, "summary": "The fundamental metrological limits of temperature sensing in open quantum systems remain largely unresolved, particularly regarding the role of non-Gaussian quantum resources. In this letter, we establish analytic bounds on the quantum Fisher information (QFI) for temperature estimation using non-Gaussian states undergoing dissipative bosonic evolution. By focusing on the short-time regime governed by a time-local master equation, we derive precise scaling laws that elucidate when and how non-Gaussian probes decisively outperform Gaussian states under identical energy constraints. Our analysis uncovers a distinct linear-in-time QFI enhancement unique to Fock states, in contrast to the inherently weaker, quadratic scaling of Gaussian probes. These theoretical insights are substantiated through exact numerical simulations and mapped onto experimentally accessible platforms such as circuit QED. Our results not only clarify the quantum thermometric advantage of non-Gaussianity but also chart a realistic pathway toward harnessing it in noisy quantum technologies."}
{"id": "2512.03740", "categories": ["quant-ph", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.03740", "abs": "https://arxiv.org/abs/2512.03740", "authors": ["Tea Štrekelj"], "title": "Quantum Max Cut for complete tripartite graphs", "comment": "15 pages", "summary": "The Quantum Max-$d$-Cut ($d$-QMC) problem is a special instance of a $2$-local Hamiltonian problem, representing the quantum analog of the classical Max-$d$-Cut problem. The $d$-QMC problem seeks the largest eigenvalue of a Hamiltonian defined on a graph with $n$ vertices, where edges correspond to swap operators acting on $(\\mathbb{C}^d)^{\\otimes n}$. In recent years, progress has been made by investigating the algebraic structure of the $d$-QMC Hamiltonian. Building on this approach, this article solves the $d$-QMC problem for complete tripartite graphs for small local dimensions, $d \\le 3$."}
{"id": "2512.03748", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2512.03748", "abs": "https://arxiv.org/abs/2512.03748", "authors": ["Orlando D. Cunha", "Filipe Camarneiro", "João P. Silva", "Hariharan Nhalil", "Ariel Zaig", "Lior Klein", "Jana B. Nieder"], "title": "Widefield Quantum Sensor for Vector Magnetic Field Imaging of Micromagnetic Structures", "comment": "9 pages, 5 figures, original article", "summary": "Many spintronic, magnetic-memory, and neuromorphic devices rely on spatially varying magnetic fields. Quantitatively imaging these fields with full vector information over extended areas remains a major challenge. Existing probes either offer nanoscale resolution at the cost of slow scanning, or widefield imaging with limited vector sensitivity or material constraints. Quantum sensing with nitrogen-vacancy (NV) centers in diamond promises to bridge this gap, but a practical camera-based vector magnetometry implementation on relevant microstructures has not been demonstrated. Here we adapt a commercial widefield microscope to implement a camera-compatible pulsed optically detected magnetic resonance protocol to reconstruct stray-field vectors from microscale devices. By resolving the Zeeman shifts of the four NV orientations, we reconstruct the stray-field vector generated by microfabricated permalloy structures that host multiple stable remanent states. Our implementation achieves a spatial resolution of $\\approx 0.52 ~μ\\mathrm{m}$ across an $83~μ\\mathrm{m} \\times 83~μ\\mathrm{m}$ field of view and a peak sensitivity of $ (828 \\pm 142)~\\mathrm{nT\\,Hz^{-1}}$, with acquisition times of only a few minutes. These results establish pulsed widefield NV magnetometry on standard microscopes as a practical and scalable tool for routine vector-resolved imaging of complex magnetic devices."}
{"id": "2512.03758", "categories": ["quant-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.03758", "abs": "https://arxiv.org/abs/2512.03758", "authors": ["David Jennings", "Kamil Korzekwa", "Matteo Lostaglio", "Richard Ashworth", "Emanuele Marsili", "Stephen Rolston"], "title": "An end-to-end quantum algorithm for nonlinear fluid dynamics with bounded quantum advantage", "comment": "69 pages, 9 figures. Comments welcome!", "summary": "Computational fluid dynamics (CFD) is a cornerstone of classical scientific computing, and there is growing interest in whether quantum computers can accelerate such simulations. To date, the existing proposals for fault-tolerant quantum algorithms for CFD have almost exclusively been based on the Carleman embedding method, used to encode nonlinearities on a quantum computer. In this work, we begin by showing that these proposals suffer from a range of severe bottlenecks that negate conjectured quantum advantages: lack of convergence of the Carleman method, prohibitive time-stepping requirements, unfavorable condition number scaling, and inefficient data extraction. With these roadblocks clearly identified, we develop a novel algorithm for the incompressible lattice Boltzmann equation that circumvents these obstacles, and then provide a detailed analysis of our algorithm, including all potential sources of algorithmic complexity, as well as gate count estimates. We find that for an end-to-end problem, a modest quantum advantage may be preserved for selected observables in the high-error-tolerance regime. We lower bound the Reynolds number scaling of our quantum algorithm in dimension $D$ at Kolmogorov microscale resolution with $O(\\mathrm{Re}^{\\frac{3}{4}(1+\\frac{D}{2})} \\times q_M)$, where $q_M$ is a multiplicative overhead for data extraction with $q_M = O(\\mathrm{Re}^{\\frac{3}{8}})$ for the drag force. This upper bounds the scaling improvement over classical algorithms by $O(\\mathrm{Re}^{\\frac{3D}{8}})$. However, our numerical investigations suggest a lower speedup, with a scaling estimate of $O(\\mathrm{Re}^{1.936} \\times q_M)$ for $D=2$. Our results give robust evidence that small, but nontrivial, quantum advantages can be achieved in the context of CFD, and motivate the need for additional rigorous end-to-end quantum algorithm development."}
{"id": "2512.03769", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03769", "abs": "https://arxiv.org/abs/2512.03769", "authors": ["Jiajie Guo", "Shuheng Liu", "Boxuan Jing", "Qiongyi He", "Manuel Gessner"], "title": "Metrological Sensitivity beyond Gaussian Limits with Cubic Phase States", "comment": "21 pages, 8 figures", "summary": "Cubic phase states provide the essential non-Gaussian resource for continuous-variable quantum computing. We show that they also offer significant potential for quantum metrology, surpassing the phase-sensing sensitivity of all Gaussian states at equal average photon number. Optimal sensitivity requires only moderate initial squeezing, and the non-Gaussian advantage remains robust against loss and detection noise. We identify optimal measurement strategies and show that several experimentally relevant preparation schemes surpass Gaussian limits, in some cases reaching the sensitivity of cubic phase states. Our results establish cubic phase states as a promising resource for quantum-enhanced precision measurements beyond Gaussian limits."}
{"id": "2512.03788", "categories": ["quant-ph", "cs.DS"], "pdf": "https://arxiv.org/pdf/2512.03788", "abs": "https://arxiv.org/abs/2512.03788", "authors": ["Kamil Khadiev", "Vladislav Remidovskii", "Timur Bikmullin", "Aliya Khadieva"], "title": "Quantum Algorithm for Searching for the Longest Segment and the Largest Empty Rectangle", "comment": "accepted in SOFSEM2026 conference, In Proceedings LNCS vol.16448", "summary": "In the paper, we consider the problem of searching for the Largest empty rectangle in a 2D map, and the one-dimensional version of the problem is the problem of searching for the largest empty segment. We present a quantum algorithm for the Largest Empty Square problem and the Largest Empty Rectangle of a fixed width $d$ for $n\\times n$-rectangular map. Query complexity of the algorithm is $\\tilde{O}(n^{1.5})$ for the square case, and $\\tilde{O}(n\\sqrt{d})$ for the rectangle with a fixed width $d$ case, respectively. At the same time, the lower bounds for the classical case are $Ω(n^2)$, and $Ω(nd)$, respectively. The Quantum algorithm for the one-dimensional version of the problem has $O(\\sqrt{n}\\log n\\log\\log n)$ query complexity. The quantum lower bound for the problem is $Ω(\\sqrt{n})$ which is almost equal to the upper bound up to a log factor. The classical lower bound is $Ω(n)$. So, we obtain the quadratic speed-up for the problem."}
{"id": "2512.03808", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.03808", "abs": "https://arxiv.org/abs/2512.03808", "authors": ["Rui Chen", "Teng-Yang Ma", "Meng-Han Dou", "Chao-Fu Wang"], "title": "Solution of the Electric Field Integral Equation Using a Hybrid Quantum-Classical Scheme: Investigation of Accuracy and Efficiency", "comment": "6 pages, 6 figures", "summary": "Conventional classical solvers are commonly used for solving matrix equation systems resulting from the discretization of SIEs in computational electromagnetics (CEM). However, the memory requirement would become a bottleneck for classical computing as the electromagentic problems become much larger. As an alternative, quantum computing has a natural \"parallelization\" advantage with much lower storage complexity due to the superposition and entanglement in quantum mechanics. Even though several quantum algorithms have been applied for the SIEs-based methods in the literature, the size of the matrix equation systems solvable using them is still limited. In this work, we use a hybrid quantum-classical scheme to solve the EFIE for analyzing electromagentic scattering from three-dimensional (3D) perfect electrically conducting objects with arbitrary shapes in CEM for the first time. Instead of directly solving the original EFIE matrix equation system using the quantum algorithms, the hybrid scheme first designs the preconditioned linear system and then uses a double-layer iterative strategy for its solution, where the external iteration layer builds subspace matrix equation systems with smaller dimension and the internal iteration layer solves the smaller systems using the quantum algorithms. Two representative quantum algorithms, HHL and VQLS, are considered in this work, which are executed on the quantum simulator and quantum computer platforms. We present the theoretical time complexity analysis of the hybrid quantum-classical scheme and perform numerical experiments to investigate the accuracy and efficiency of the hybrid scheme. The results show that the computational complexity of the hybrid VQLS-classical scheme is lower than the conventional fast solvers in classical computing, which indicates the hybrid scheme is more promising for analyzing large-scale electromagnetic problems."}
{"id": "2512.03850", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03850", "abs": "https://arxiv.org/abs/2512.03850", "authors": ["Keun-Young Kim", "Kuntal Pal"], "title": "Density of states of quantum systems from free probability theory: a brief overview", "comment": null, "summary": "We provide a brief overview of approaches for calculating the density of states of quantum systems and random matrix Hamiltonians using the tools of free probability theory. For a given Hamiltonian of a quantum system or a generic random matrix Hamiltonian, which can be written as a sum of two non-commutating operators, one can obtain an expression for the density of states of the Hamiltonian from the known density of states of the two component operators by assuming that these operators are mutually free and by using the free additive convolution. In many examples of interacting quantum systems and random matrix models, this procedure is known to provide a reasonably accurate approximation to the exact numerical density of states. We review some of the examples that are known in the literature where this procedure works very well, and also discuss some of the limitations of this method in situations where the free probability approximation fails to provide a sufficiently accurate description of the exact density of states. Subsequently, we describe a perturbation scheme that can be developed from the subordination formulas for the Cauchy transform of the density of states and use it to obtain approximate analytical expressions for the density of states in various models, such as the Rosenzweig-Porter random matrix ensemble and the Anderson model with on-site disorder."}
{"id": "2512.03853", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.03853", "abs": "https://arxiv.org/abs/2512.03853", "authors": ["Jack J. Turner", "Christian W. Binder", "Guido Burkard", "Andrew J. Fisher"], "title": "Modelling the Impact of Device Imperfections on Electron Shuttling in SiMOS devices", "comment": null, "summary": "Extensive theoretical and experimental work has established high-fidelity electron shuttling in Si/SiGe systems, whereas demonstrations in Si/SiO2 (SiMOS) remain at an early stage. To help address this, we perform full 3D simulations of conveyor-belt charge shuttling in a realistic SiMOS device, building on earlier 2D modelling. We solve the Poisson and time-dependent Schrodinger equations for varying shuttling speeds and gate voltages, focusing on potential pitfalls of typical SiMOS devices such as oxide-interface roughness, gate fabrication imperfections, and charge defects along the transport path. The simulations reveal that for low clavier-gate voltages, the additional oxide screening in multi-layer gate architectures causes conveyor-belt shuttling to collapse to the bucket-brigade mode, inducing considerable orbital excitation in the process. Increasing the confinement restores conveyor-belt operation, which we find to be robust against interface roughness, gate misalignment, and charge defects buried in the oxide. However, our results indicate that defects located at the Si/SiO2-interface can induce considerable orbital excitation. For lower conveyor gate biases, positive defects in the transport channel can even capture passing electrons. Hence we identify key challenges and find operating regimes for reliable charge transport in SiMOS architectures."}
{"id": "2512.03898", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.03898", "abs": "https://arxiv.org/abs/2512.03898", "authors": ["Yu Wang", "Martina Nibbi", "Maxine Luo", "Isabel Nha Minh Le", "Yanbin Chen", "J. Ignacio Cirac", "Christian Mendl"], "title": "Polylogarithmic-Depth Quantum Algorithm for Simulating the Extended Hubbard Model on a Two-Dimensional Lattice Using the Fast Multipole Method", "comment": null, "summary": "The extended Hubbard model on a two-dimensional lattice captures key physical phenomena, but is challenging to simulate due to the presence of long-range interactions. In this work, we present an efficient quantum algorithm for simulating the time evolution of this model. Our approach, inspired by the fast multipole method, approximates pairwise interactions by interactions between hierarchical levels of coarse-graining boxes. We discuss how to leverage recent advances in two-dimensional neutral atom quantum computing, supporting non-local operations such as long-range gates and shuttling. The resulting circuit depth for a single Trotter step scales polylogarithmically with system size."}
{"id": "2512.03924", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03924", "abs": "https://arxiv.org/abs/2512.03924", "authors": ["Nicolas Laurent-Puig", "Matilde Baroni", "Federico Centrone", "Eleni Diamanti"], "title": "Experimental Quantum Electronic Voting", "comment": "11 pages", "summary": "Quantum information protocols offer significant advantages in properties such as security, anonymity, and privacy for communication and computing tasks. An application where guaranteeing the highest possible security and privacy is critical for democratic societies is electronic voting. As computational power continues to evolve, classical voting schemes may become increasingly vulnerable to information leakage. In this work, we present the experimental demonstration of an information-theoretically secure and efficient electronic voting protocol that, crucially, does not rely on election authorities, leveraging the unique properties of quantum states. Our experiment is based on a high-performance source of Greenberger-Horne-Zeilinger (GHZ) states and realizes a proof-of-principle implementation of the protocol in two scenarios: a configuration with four voters and two candidates employing privacy enhancement techniques and an election scenario supporting up to eight voters and sixteen candidates. The latter is particularly well-suited for secure board-level elections within organizations or small-scale governmental contexts."}
{"id": "2512.03925", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03925", "abs": "https://arxiv.org/abs/2512.03925", "authors": ["David Ribes", "Tatiana Gonzalez Grandon"], "title": "Towards Quantum Stochastic Optimization for Energy Systems under Uncertainty: Joint Chance Constraints with Quantum Annealing", "comment": "24 pages, 9 figures", "summary": "Uncertainty is fundamental in modern power systems, where renewable generation and fluctuating demand make stochastic optimization indispensable. The chance constrained unit commitment problem (UCP) captures this uncertainty but rapidly becomes computationally challenging as the number of scenarios grows. Quantum computing has been proposed as a potential route to overcome such scaling barriers. In this work, we evaluate the applicability of quantum annealing platforms to the chance constrained UCP. Focusing on a scenario approximation, we reformulated the problem as a mixed integer linear program and solved it using DWave hybrid quantum classical solver alongside Gurobi. The hybrid solver proved competitive under strict runtime limits for large scenario sets (15,000 in our experiments), while Gurobi remained superior on smaller cases. QUBO reformulations were also tested, but current annealers cannot accommodate stochastic UCPs due to hardware limits, and deterministic cases suffered from embedding overhead. Our study delineates where chance constrained UCPs can already be addressed with hybrid quantum classical methods, and where current quantum annealers remain fundamentally limited."}
{"id": "2512.03929", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03929", "abs": "https://arxiv.org/abs/2512.03929", "authors": ["Dagomir Kaszlikowski", "Pawel Kurzynski"], "title": "Rethinking Collapse: Coupling Quantum States to Classical Bits with quasi-probabilities", "comment": "12 pages", "summary": "We propose a formulation of quantum measurement within a modified framework of frames, in which a quantum system - a single qubit - is directly coupled to a classical measurement bit. The qubit is represented as a positive probability distribution over two classical bits, a and a', denoted by p(aa'). The measurement apparatus is described by a classical bit $α= \\pm 1$, initialized in the pure distribution $p(α) = \\frac{1}{2}(1 + α)$. The measurement interaction is modeled by a quasi-bistochastic process $ S(bb'β\\mid aa'α)$ - a bistochastic map that may include negative transition probabilities, while acting on an entirely positive state space. When this process acts on the joint initial state $p(aa')p(α)$, it produces a collapsed state $p(bb'\\midβ)$, yielding the measurement outcome $β$ with the correct quantum-mechanical probability $p(β)$. This approach bypasses the von Neumann chain of infinite couplings by treating the measurement register classically, while capturing the nonclassical nature of measurement through the quasi-bistochastic structure of the interaction."}
{"id": "2512.03933", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03933", "abs": "https://arxiv.org/abs/2512.03933", "authors": ["Emanuel Hubenschmid", "Victor Rueskov Christiansen"], "title": "Phase-space open-systems dynamics of second-order nonlinear interactions with pulsed quantum light", "comment": "21 pages, 8 figures", "summary": "The theoretical description of broadband, multimode quantum pulses undergoing a second-order $χ^{(2)}$-nonlinear interaction can be quite intricate, due to the large dimensionality of the underlying phase space. However, in many cases only a few broadband (temporal) modes are relevant before and after the nonlinear interaction. Here we present an efficient framework to calculate the relation between the quantum states at the input and output of a nonlinear element in their respective relevant modes. Since the number of relevant input and output modes may differ, resulting in an open quantum system, we introduce the generalized Bloch-Messiah decomposition (GBMD), reducing the description to an equal number of input and output modes. The GBMD enables us to calculate the multimode Wigner function of the output state by convolving the rescaled Wigner function of the reduced input quantum pulse with a multivariate Gaussian phase-space function. We expand on this result by considering two examples input states: A Fock state in a single broadband mode and a two-mode squeezed vacuum, both in the THz-frequency regime, up-converted to a single output broadband mode of optical frequencies. We investigate the effect, the convolution and thermalization due to entanglement breakage have on the output Wigner function by calculating the von Neumann entropy of the output Wigner function. The methods presented here can be used to optimize the amplification or frequency conversion of broadband quantum states, opening an avenue to the generation and characterization of optical quantum states on ultrafast time scales."}
{"id": "2512.03935", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.03935", "abs": "https://arxiv.org/abs/2512.03935", "authors": ["Baibhab Bose", "Devvrat Tiwari", "Subhashish Banerjee"], "title": "Thermodynamics of an Open $\\mathcal{PT-}$Symmetric Quantum System", "comment": "10 pages, 4 figures", "summary": "For a subclass of a general $\\mathcal{PT}-$symmetric Hamiltonian obeying anti-commutation relation with its conjugate, a Hermitian basis is found that spans the bi-orthonormal energy eigenvectors. Using the modified projectors constructed from these eigenvectors, the generalized density matrix of the $\\mathcal{PT}-$symmetric evolution is calculated, and subsequently, ergotropy for a closed system is obtained. The $\\mathcal{PT}-$symmetric system, in an open system scenario, is studied to understand ergotropy under different regimes of non-Hermiticity of the Hamiltonian. The consistency of the three laws of thermodynamics for the $\\mathcal{PT}-$symmetric system in an open system scenario is also analyzed."}
{"id": "2512.03953", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03953", "abs": "https://arxiv.org/abs/2512.03953", "authors": ["Joachim Guyomard", "Serge Reynaud", "Pierre Cladé"], "title": "Image Theory for the Single Bounce Quantum Gravimeter", "comment": null, "summary": "We develop an image theory for the recently proposed single-bounce quantum gravimeter. Free fall and quantum bounce of a matter wave-packet are described through decompositions over a basis of continuous energies. This leads to a much clearer interpretation of the origin of quantum interferences, associated to semi-classical estimations. We then give new tools to explore the space of parameters, and discuss the expected accuracy of the free-fall acceleration measurement."}
{"id": "2512.03984", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03984", "abs": "https://arxiv.org/abs/2512.03984", "authors": ["Marlene Funck", "Ilija Funk", "Tizian Schmidt", "René Schwonnek"], "title": "Entanglement Detection with Rotationally Covariant Measurements - From Compton Scattering to Lemonade", "comment": "7+5 pages, 6 figures", "summary": "The accurate and efficient detection of quantum entanglement remains a central challenge in quantum information science. In this work, we study the detection of entanglement of polarized photons for measurement devices that are solely specified by rotational symmetry. We derive explicit positive operator valued measures (POVMs) showing that from a quantum information perspective any such setting is classified by one real measurable parameter r. In Particular, we give a POVM formulation of the Klein--Nishina formula for Compton scattering of polarized photons. We provide an SDP-based entanglement certification method that operates on the full measured statistics and gives tight bounds, also considering semi-device independent scenarios. Furthermore, we show that, while Bell violations are impossible with rotationally covariant measurements, EPR steering can still be certified under one-sided symmetry constraints. Finally, we present a rotationally covariant showcase experiment, analyzing the scattering of polarized optical light in a selection of soft drinks. Our results suggest that lemonade-based detectors are suitable for entanglement detection."}
{"id": "2512.03987", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03987", "abs": "https://arxiv.org/abs/2512.03987", "authors": ["Sebastián de-la-Peña", "Heiko Appel", "Angel Rubio", "Ofer Neufeld"], "title": "Fully quantum theory of strong-field driven tunable entangled multi-photon states in HHG", "comment": "8 pages, 4 figures", "summary": "Quantum high-harmonic generation (HHG) is a growing field of research with capabilities of providing high photon-number entangled states of light. However, there is an open debate regarding the theory level required for correctly describing the quantum aspects of HHG emission, such as squeezing or entanglement. Previous approaches have employed non-interacting classical ensembles of trajectories, or perturbation theory utilizing the classical trajectories as a starting point, missing out key entanglement features. In this Letter, we develop a full quantum theory for entanglement measures in HHG solving exactly the light-matter interaction Hamiltonian and employ it for evaluating the entanglement between emitted photons of different harmonics. For the first time, we reach qualitative agreement of theory with recent experiments showing that the R entanglement parameter decreases with increasing laser power for below-threshold harmonics. Our results indicate that fine-tuning the laser power could enhance HHG entanglement features, which are observed to oscillate with the driving power and exhibit local non-classical maxima structures. Similarly, our theory predicts that the oscillatory behavior of entanglement observed for below-threshold harmonics also appears for entanglement involving above-threshold harmonics. We also show that the long-range behavior of driven electronic trajectories can qualitatively change the resulting entanglement. Lastly, we show that focal averaging over classical degrees of freedom, which has thus far been ignored in quantum HHG theories, plays a key role in entanglement measures and can change the qualitative behavior of observables. Our work establishes the state-of-the art in exploring entanglement features in HHG, and paves way for analysis and engineering of 'truly-quantum' multi-photon states in the XUV and ultrafast regime for more complex matter systems."}
{"id": "2512.04016", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.04016", "abs": "https://arxiv.org/abs/2512.04016", "authors": ["Davut Emre Tasar", "Ceren Ocal Tasar"], "title": "TARA Test-by-Adaptive-Ranks for Quantum Anomaly Detection with Conformal Prediction Guarantees", "comment": null, "summary": "Quantum key distribution (QKD) security fundamentally relies on the ability to distinguish genuine quantum correlations from classical eavesdropper simulations, yet existing certification methods lack rigorous statistical guarantees under finite-sample conditions and adversarial scenarios. We introduce TARA (Test by Adaptive Ranks), a novel framework combining conformal prediction with sequential martingale testing for quantum anomaly detection that provides distribution-free validity guarantees. TARA offers two complementary approaches. TARA k, based on Kolmogorov Smirnov calibration against local hidden variable (LHV) null distributions, achieving ROC AUC = 0.96 for quantum-classical discrimination. And TARA-m, employing betting martingales for streaming detection with anytime valid type I error control that enables real time monitoring of quantum channels. We establish theoretical guarantees proving that under (context conditional) exchangeability, conformal p-values remain uniformly distributed even for strongly contextual quantum data, confirming that quantum contextuality does not break conformal prediction validity a result with implications beyond quantum certification to any application of distribution-free methods to nonclassical data. Extensive validation on both IBM Torino (superconducting, CHSH = 2.725) and IonQ Forte Enterprise (trapped ion, CHSH = 2.716) quantum processors demonstrates cross-platform robustness, achieving 36% security margins above the classical CHSH bound of 2. Critically, our framework reveals a methodological concern affecting quantum certification more broadly: same-distribution calibration can inflate detection performance by up to 44 percentage points compared to proper cross-distribution calibration, suggesting that prior quantum certification studies using standard train test splits may have systematically overestimated adversarial robustness."}
{"id": "2512.04028", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.04028", "abs": "https://arxiv.org/abs/2512.04028", "authors": ["M. Harinarayanan", "Karthik Rajeev"], "title": "Thermalization from quenching in coupled oscillators", "comment": "12 pages, 9 figures", "summary": "We introduce a finite-time protocol that thermalizes a quantum harmonic oscillator, initially in its ground state, without requiring a macroscopic bath. The method uses a second oscillator as an effective environment and implements sudden quenches of the oscillator frequencies and coupling. Owing to the Gaussian nature of the dynamics, the thermalization condition reduces to three solvable equations, yielding exact analytic solutions for a dense discrete set of temperatures and numerical solutions in all other cases. Any target temperature can be approximated with arbitrary precision, with a trade-off between speed and accuracy. The simplicity of the protocol makes it a promising tool for rapid, controlled thermalization in quantum thermodynamics experiments and state preparation."}
{"id": "2512.04058", "categories": ["quant-ph", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.04058", "abs": "https://arxiv.org/abs/2512.04058", "authors": ["Shashaank Khanna", "Matthew Pusey", "Roger Colbeck"], "title": "Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap", "comment": "5 pages, 3 figures, 1 table", "summary": "The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures."}
{"id": "2512.03526", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03526", "abs": "https://arxiv.org/abs/2512.03526", "authors": ["G. -X. Tang", "J. -Z. Zhuang", "L. -M. Duan", "Y. -K. Wu"], "title": "Stretched Exponential Scaling of Parity-Restricted Energy Gaps in a Random Transverse-Field Ising Model", "comment": "14 pages, 3 figures", "summary": "The success of a quantum annealing algorithm requires a polynomial scaling of the energy gap. Recently it was shown that a two-dimensional transverse-field Ising model on a square lattice with nearest-neighbor $\\pm J$ random coupling has a polynomial energy gap in the symmetric subspace of the parity operator [Nature 631, 749-754 (2024)], indicating the efficient preparation of its ground states by quantum annealing. However, it is not clear if this result can be generalized to other spin glass models with continuous or biased randomness. Here we prove that under general independent and identical distributions (i.i.d.) of the exchange energies, the energy gap of a one-dimensional random transverse-field Ising model follows a stretched exponential scaling even in the parity-restricted subspace. We discuss the implication of this result to quantum annealing problems."}
{"id": "2512.03689", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03689", "abs": "https://arxiv.org/abs/2512.03689", "authors": ["Edoardo Zavatti", "Gabriele Bellomia", "Samuele Giuli", "Matteo Ferraretto", "Massimo Capone"], "title": "More is uncorrelated: Tuning the local correlations of SU($N$) Fermi-Hubbard systems via controlled symmetry breaking", "comment": "9 pages + references, 8 figures. Comments welcome!", "summary": "Cold-atom experiments based on alkali-like atoms provide us with a tool to experimentally realize Hubbard models with a large number $N$ of components. The value of $N$ can be seen as a new handle to tune the properties of the system, leading to new physics both in the case of fully SU($N$) symmetric systems, or in the presence of controlled symmetry breaking.\n  We focus on the Mott transition at global half filling and we characterize local correlations between particles complementing conventional estimates with the inter-flavor mutual information. We prove that these correlations have classical nature and, using Dynamical Mean-Field Theory, we show that the SU(4) system has significantly smaller correlations than the SU(2) counterpart. In the atomic limit we prove that increasing $N$ further decreases the strength of the correlations. This suggests that a controlled reduction of the symmetry, reducing the number of effective components, can be used to enhance the degree of correlation.\n  We confirm this scenario solving the model for $N=4$ and gradually breaking the symmetry via a Raman field, revealing an evolution from the SU(4) to the SU(2) Mott transition as the symmetry-breaking term increases, with a sudden recovery of the large correlations of the SU(2) model at weak Raman coupling in the Mott state. By further exploring the interplay between energy repulsion and the Raman field, we obtain a rich phase diagram with three different phases -- a metal, a band insulator, and a Mott insulator -- all coexisting at a single tricritical point."}
{"id": "2512.03770", "categories": ["physics.soc-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03770", "abs": "https://arxiv.org/abs/2512.03770", "authors": ["Xingyu Guo", "Xiaoyang Wang", "Lingxiao Wang"], "title": "Quantum Simulations of Opinion Dynamics", "comment": "9 pages, 12 figures, comments are welcome", "summary": "Quantum computing offers powerful new approaches for modeling complex social phenomena. Here, we propose and demonstrate quantum simulations of opinion dynamics, leveraging quantum superposition, measurement-induced state collapse, and entanglement to model realistic psychological and social processes. Specifically, we develop quantum models of opinion dynamics, solving exactly and simulating on IBM Quantum hardware. Our results, based on quantum devices and validated with practical quantum circuits, illustrate how quantum effects can enhance understanding of consensus formation, polarization, and collective decision-making. These findings pave the way for further exploration into quantum-enhanced social modeling, highlighting the potential of near-term quantum computers for simulating collective behavior in complex systems."}
{"id": "2512.03980", "categories": ["physics.soc-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.03980", "abs": "https://arxiv.org/abs/2512.03980", "authors": ["Pak Shen Choong", "Nurisya Mohd Shah", "Yung Szen Yap"], "title": "Quantum Diplomacy within the Southeast Asia Quantum Ecosystem", "comment": "Comments are welcomed!", "summary": "Amid the International Year of Quantum Science and Technology 2025 (IYQ 2025), a significant portion of global funding has been dedicated to various quantum initiatives, with over 30 countries announcing their respective quantum strategies. Within the Southeast Asia context, Singapore, Thailand, and the Philippines have launched their respective quantum strategies and roadmaps. Meanwhile, six out of eleven Southeast Asia countries have expressed interest in formulating a regional quantum ecosystem to pursue a set of common goals. Quantum technologies, though still in their infancy within the second quantum revolution, have advanced rapidly in recent years. Due to their dual-use nature, quantum technologies are considered emerging and disruptive, often raising concerns from the cybersecurity perspective. While several discussions regarding Malaysia's quantum initiative and strategy are ongoing, it is vital to broaden the conversation and position Malaysia within the regional ecosystem. This paper provides an overview of Malaysia's quantum landscape and a summary of the regional initiatives since the establishment of Southeast Asia Quantum Network. We then analyse Malaysia's strengths in quantum research and provide four recommendations to strengthen the regional ecosystem."}
