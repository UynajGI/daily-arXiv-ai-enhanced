{"id": "2602.15774", "categories": ["cond-mat.str-el", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.15774", "abs": "https://arxiv.org/abs/2602.15774", "authors": ["D. Jones", "A. Weh", "A. Östlin", "D. Braak", "T. Kopp", "P. Seiler", "U. Eckern", "L. Chioncel"], "title": "Correlated electronic states at a ferromagnetic oxide interface", "comment": null, "summary": "We propose a minimal tight-binding model for the electronic interface layer of the LaAlO$_3$/SrTiO$_3$ heterostructure with oxygen vacancies. In this model, the effective carriers are subject to oxygen vacancy induced magnetic impurities. Both the effects of random on-site potentials and Zeeman-like exchange interactions between correlated carriers and magnetic impurities are taken into account. By applying the combined coherent potential approximation (CPA) and dynamical mean-field theory (DMFT) for a ferromagnetic state, we uncover a disordered Fermi-liquid regime for the majority-spins and a low energy scale which controls the transport of the minority-spin carriers, both induced by the magnetic impurities."}
{"id": "2602.15474", "categories": ["quant-ph", "cond-mat.supr-con", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.15474", "abs": "https://arxiv.org/abs/2602.15474", "authors": ["J. J. Prieto-Garcia", "A. G. del Pozo-Martín", "M. Pino"], "title": "Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit", "comment": "13 pages, 4 figures", "summary": "We analyze numerically the performance of Quantum Reservoir Computing (QRC) for statistical and financial problems. We use a reservoir composed of two superconducting islands coupled via their charge degrees of freedom. The key non-linear elements that provide the reservoir with rich and complex dynamics are the Josephson junctions that connect each island to the ground. We show that QRC implemented in this circuit can accurately classify complex probability distributions, including those with heavy tails, and identify regimes in correlated time series, such as periods of high volatility generated by standard econometric models. We find QRC to outperform some of the best classical methods when the amount of information is limited. This demonstrates its potential to be a noise-resilient quantum learning approach capable of tackling real-world problems within currently available superconducting platforms. We further discuss how to improve our QRC algorithm in real superconducting hardware to benefit from a much larger Hilbert space."}
{"id": "2602.15600", "categories": ["cs.SI", "cs.AI", "econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.15600", "abs": "https://arxiv.org/abs/2602.15600", "authors": ["Carlo Santagiustina", "Caterina Cruciani"], "title": "The geometry of online conversations and the causal antecedents of conflictual discourse", "comment": null, "summary": "This article investigates the causal antecedents of conflictual language and the geometry of interaction in online threaded conversations related to climate change. We employ three annotation dimensions, inferred through LLM prompting and averaging, to capture complementary aspects of discursive conflict (such as stance: agreement vs disagreement; tone: attacking vs respectful; and emotional versus factual framing) and use data from a threaded online forum to examine how these dimensions respond to temporal, conversational, and arborescent structural features of discussions. We show that, as suggested by the literature, longer delays between successive posts in a thread are associated with replies that are, on average, more respectful, whereas longer delays relative to the parent post are associated with slightly less disagreement but more emotional (less factual) language. Second, we characterize alignment with the local conversational environment and find strong convergence both toward the average stance, tone and emotional framing of older sibling posts replying to the same parent and toward those of the parent post itself, with parent post effects generally stronger than sibling effects. We further show that early branch-level responses condition these alignment dynamics, such that parent-child stance alignment is amplified or attenuated depending on whether a branch is initiated in agreement or disagreement with the discussion's root message. These influences are largely additive for civility-related dimensions (attacking vs respectful, disagree vs agree), whereas for emotional versus factual framing there is a significant interaction: alignment with the parent's emotionality is amplified when older siblings are similarly aligned."}
{"id": "2602.15254", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15254", "abs": "https://arxiv.org/abs/2602.15254", "authors": ["Mohammad Mhadi Naderi", "Megan S. Harris", "John C. Little", "Amro M. Farid"], "title": "Embedding Economic Input-Output Models in Systems of Systems: An MBSE and Hetero-functional Graph Theory Approach", "comment": "arXiv admin note: text overlap with arXiv:2505.21793", "summary": "Characterizing the interdependent nature of Anthropocene systems of systems is fundamental to making informed decisions to address challenges across complex ecological, environmental, and coupled human-natural systems. This paper presents the first application of Model-Based Systems Engineering (MBSE) and Hetero-functional Graph Theory (HFGT) to economic systems, establishing a scalable and extensible methodology for integrating economic input-output (EIO) models within a unified system-of-systems modeling framework. Integrating EIO models into the MBSE-HFGT workflow demonstrates how the structural form and function of economic systems can be expressed through SysML's graphical ontology and subsequently translated into the computational structure of HFGT. Using a synthetic Rectangular Choice of Technology (RCOT) example as a pedagogical foundation, the study confirms that the dynamics captured by basic EIO models, as well as other complex economic models grounded in EIO theory, can be equivalently reproduced within the MBSE-HFGT framework. The integration with MBSE and HFGT thus preserves analytical precision while offering enhanced graphical clarity and system-level insight through a shared ontological structure. By integrating modeling languages and mathematical frameworks, the proposed methodology establishes a foundation for knowledge co-production and integrated decision-making to address the multifaceted sustainability challenges associated with Anthropocene systems of systems."}
{"id": "2602.15254", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15254", "abs": "https://arxiv.org/abs/2602.15254", "authors": ["Mohammad Mhadi Naderi", "Megan S. Harris", "John C. Little", "Amro M. Farid"], "title": "Embedding Economic Input-Output Models in Systems of Systems: An MBSE and Hetero-functional Graph Theory Approach", "comment": "arXiv admin note: text overlap with arXiv:2505.21793", "summary": "Characterizing the interdependent nature of Anthropocene systems of systems is fundamental to making informed decisions to address challenges across complex ecological, environmental, and coupled human-natural systems. This paper presents the first application of Model-Based Systems Engineering (MBSE) and Hetero-functional Graph Theory (HFGT) to economic systems, establishing a scalable and extensible methodology for integrating economic input-output (EIO) models within a unified system-of-systems modeling framework. Integrating EIO models into the MBSE-HFGT workflow demonstrates how the structural form and function of economic systems can be expressed through SysML's graphical ontology and subsequently translated into the computational structure of HFGT. Using a synthetic Rectangular Choice of Technology (RCOT) example as a pedagogical foundation, the study confirms that the dynamics captured by basic EIO models, as well as other complex economic models grounded in EIO theory, can be equivalently reproduced within the MBSE-HFGT framework. The integration with MBSE and HFGT thus preserves analytical precision while offering enhanced graphical clarity and system-level insight through a shared ontological structure. By integrating modeling languages and mathematical frameworks, the proposed methodology establishes a foundation for knowledge co-production and integrated decision-making to address the multifaceted sustainability challenges associated with Anthropocene systems of systems."}
{"id": "2602.15149", "categories": ["cs.CE", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.15149", "abs": "https://arxiv.org/abs/2602.15149", "authors": ["Mohammad Naqib Rahimi", "George Moutsanidis"], "title": "SoliDualSPHysics: An extension of DualSPHysics for solid mechanics with hyperelasticity, plasticity, and fracture", "comment": null, "summary": "We introduce SoliDualSPHysics, a novel open-source and GPU-accelerated software that extends DualSPHysics to enable the numerical simulation of hyperelastic, finite-strain plastic, and brittle fracture behavior in deformable solids within a unified smoothed particle hydrodynamics (SPH) formulation. The software implements a total Lagrangian formulation for solid mechanics that allows direct application of external loads and boundary conditions, enabling independent solid mechanics simulations. Brittle fracture is modeled through a phase-field approach coupled with SPH, allowing crack initiation, propagation, and branching under dynamic loading without the need for additional criteria or local refinement. The framework also supports user-defined mathematical expressions to prescribe time- and space-dependent quantities, complementing the solid and fracture extensions and enhancing flexibility across existing and future DualSPHysics applications. Leveraging DualSPHysics' native CPU/GPU parallel architecture, the software achieves substantial computational acceleration for large-scale simulations, and the implementation is verified and validated against benchmark numerical problems and experimental data, demonstrating accuracy, robustness, and favorable scaling performance. Comprehensive implementation details and user documentation are provided to ensure reproducibility and to support further development by the community. The framework and source code are freely available through a public GitHub repository."}
{"id": "2602.15131", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15131", "abs": "https://arxiv.org/abs/2602.15131", "authors": ["Vladimir P. Mineev"], "title": "Band splitting in altermagnet CrSb", "comment": "5 pages, 3 figures", "summary": "Altermegnets are a class of metallic magnets characterized by spin-split electron bands. Band splitting in the hexagonal altermagnet CrSb was studied using the ARPES method, magnetotransport and torque measurements, combined with DFT+U calculations. The shape, position, and even symmetry of the Fermi surfaces found in these studies vary. The developed approach, based on symmetry considerations, allows us to establish several general properties of band splitting in the altermagnet CrSb, including the symmetry of the spin distribution in each electron band, the symmetry of the bands in an external magnetic field, and the dependence of the frequencies and amplitudes of quantum oscillations on the magnetic field."}
{"id": "2602.15098", "categories": ["cond-mat.stat-mech", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15098", "abs": "https://arxiv.org/abs/2602.15098", "authors": ["Yongao Hu", "Felix Gerken", "Thore Posske"], "title": "Hidden Twisted Sectors and Exponential Degeneracy in Root-of-Unity XXZ Heisenberg Chains", "comment": "20 pages, 7 figures", "summary": "Recently, product states have been identified as simple-structured eigenstates of XXZ Heisenberg spin models in arbitrary dimensions, occurring at anisotropy values corresponding to certain roots of unity. Yet, the product states typically only span parts of a larger degenerate eigenspace. Here, we classify this eigenspace in the one-dimensional periodic XXZ chain at all roots of unity $q$, where $q^2$ is an $\\ell$-th primitive root of unity. For commensurate chain lengths $N$ with $q^N=1$, we prove that the minimal degeneracy is $2^{N/\\ell}\\ell$ using the representation theory of the affine Temperley-Lieb (aTL) algebra. For the incommensurate case, we derive analogous exponential lower bounds of $2^{2\\lfloor\\frac{N}{2\\ell}\\rfloor+1}$ if $N$ is even and $2^{2\\lfloor \\frac{N}{2\\ell}+\\frac{1}{2}\\rfloor}$ if $N$ is odd and $q^\\ell=1$. Our proof employs the morphisms between aTL modules discovered by Pinet and Saint-Aubin and emphasizes the importance of exact sequences and hidden twisted boundary condition sectors that mediate the degeneracy. In the case of commensurate chain lengths, we connect to the Fabricius-McCoy string construction of all Bethe roots of the degenerate subspace, which previously uncovered parts of our results. We corroborate our results numerically and demonstrate that the lower bound is saturated for chain lengths $N\\leq20$. Our work demonstrates for a concrete system how the interplay of the Bethe ansatz, aTL representation theory, and twisted boundary conditions explains degeneracy connected to long-lived product states, stimulating research towards generalization to higher dimensions. Exponential degeneracy could boost applications of spin chains as quantum sensors."}
{"id": "2602.15075", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15075", "abs": "https://arxiv.org/abs/2602.15075", "authors": ["Shizhong Mei"], "title": "A general theory of quantum measurements", "comment": "not peer-reviewed", "summary": "A universal energy eigenvalue equation is proposed in this paper. It is proven that the unique set of eigenfunctions or preferred basis exists for any non-isolated sub-system. Applying the new eigenvalue equation to the relative motion of a hydrogen atom together with the derived relativistic Hamiltonian to quantify the impact of finite proton mass to the fine structure, correction to the fine structure is obtained as a result of the entanglement of the relative motion and the center-of-mass motion, which can be used to verify the correctness of the proposed eigenvalue equation. Applying the equation to the measurement of electron double-slit interference, it is analyzed that the photon packets with Lorentzian spectral lineshape, the domain and state density of the sub-system, and the energy of the incident electron together determines the spontaneous emission rate of the incident electron. Photons generated in this process excite electrons from the valence band to the conduction band of the detector. Corresponding to any emitted or absorbed photon, the sub-system is found to be uniquely determined by maximizing the transition rate. This new principle is valid for atoms too. Closed-form expressions are obtained for the transition rates and example numerical results show good correlation between calculation and the position measurement experiment. The discovered common mechanisms that determine the sub-systems, the preferred bases, and transition rates form the foundation of a new, general, and consistent theory of quantum measurement."}
{"id": "2602.15032", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.15032", "abs": "https://arxiv.org/abs/2602.15032", "authors": ["Nasir Kenarangui", "Laszlo B. Kish", "Arthur Powalka"], "title": "Pairwise XOR and XNOR Gates in Squeezed Instantaneous Noise Based Logic", "comment": "18 pages", "summary": "Instantaneous noise-based logic (INBL) is a novel computing approach that encodes binary information using stochastic processes. It uses 2M orthogonal stochastic reference noises for M noise-bits to construct an exponentially large Hilbert space (hyperspace) of dimension 2^M. INBL offers a classical alternative to quantum-style parallelism for specific problems with exponential speedup compared to classical algorithms. Building on recent work that introduced pairwise XOR and XNOR operations defined for a symmetric INBL scheme, this paper implements these gates for a squeezed INBL scheme. Hyperspace vectors are product strings corresponding to M-bit long binary numbers. The proposed operations can apply pairwise on hyperspace vectors and their superpositions, while remaining compatible with the squeezed reference system. We validate that the squeezed-scheme XOR/XNOR gate operations have correct Boolean behavior over both bitwise and targeted M-bit strings and demonstrate that the operations preserve instantaneous evaluation. The results show that the XOR/XNOR toolkit, previously developed for symmetric INBL, can be tailored for the squeezed scheme. This development is a key part of the gate set needed for more complex INBL algorithms in the squeezed INBL scheme and advances the objective of gate universality in INBL. It further strengthens the case for INBL as a flexible, classical computing framework that can emulate some structural advantages of quantum computation."}
{"id": "2602.15297", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.15297", "abs": "https://arxiv.org/abs/2602.15297", "authors": ["Nicholas G. Polson", "Vadim Sokolov", "Daniel Zantedeschi"], "title": "Bayes Risk for Goodness of Fit Tests", "comment": null, "summary": "We develop a unified framework for goodness-of-fit (GOF) testing through the lens of Bayes risk. Classical GOF procedures are commonly calibrated either at fixed significance level (CLT scale) or through exponential error exponents (LDP scale). We establish that Bayes-risk optimal calibration operates on the moderate-deviation (MDP) scale, producing canonical $\\sqrt{\\log n}$ inflation of rejection thresholds and polynomially decaying Type I error.\n  Our main contributions are: (i) we formalise the Rubin--Sethuraman program for KS-type statistics as a risk-calibration theorem with explicit regularity conditions on priors and empirical-process functionals; (ii) we develop the precise connection between Bayes-risk expansions and Sanov information asymptotics, showing how $\\log n$-order truncations arise naturally when risk, rather than pure exponents, is the evaluation criterion; (iii) we provide detailed applications to location testing under Laplace families, shape testing via Bayes factors, and connections to Fisher information geometry. The organizing principle throughout is that sample size enters Bayes-optimal GOF cutoffs through the MDP scale, unifying KS-based and Sanov-based perspectives under a single risk criterion."}
{"id": "2602.15512", "categories": ["cond-mat.stat-mech", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.15512", "abs": "https://arxiv.org/abs/2602.15512", "authors": ["Stefano Lepri", "Roberto Livi", "Antonio Politi"], "title": "Anomalous transport in the Fermi-Pasta-Ulam-Tsingou model: a review and open problems", "comment": "Contribution for the Special Issue on FPUT, in Journal of Statistical Physics", "summary": "This review provides an up-to-date account of energy transport in Fermi-Pasta-Ulam-Tsingou (FPUT) chains, a key testbed for nonequilibrium statistical physics. We discuss the transition from the historical puzzle of thermalization to the discovery of anomalous heat transport, where the effective thermal conductivity $κ$ diverges with system size $L$ as $κ\\propto L^δ$. The article clarifies the distinction between two universality classes: the FPUT-$αβ$ model, characterized by $δ= 1/3$ and linked to Kardar-Parisi-Zhang (KPZ) physics, and the symmetric FPUT-$β$ model, where numerical and theoretical evidence support $δ= 2/5$. We investigate how finite-size effects - unavoidably induced by the thermostatting protocols - can disguise the asymptotic scaling. Additionally, we analyze the role of conservative noise in preserving hydrodynamic properties and examine how proximity to integrable limits leads to long-lived quasi-particles and, thereby, to diffusive regimes over intermediate spatial scales."}
{"id": "2602.15051", "categories": ["physics.soc-ph", "physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15051", "abs": "https://arxiv.org/abs/2602.15051", "authors": ["Mauritz Kop"], "title": "The Nexus of Quantum Technology, Intellectual Property, and National Security: An LSI Test for Securing the Quantum Industrial Commons", "comment": null, "summary": "Our world of power and national security is increasingly probabilistic: like a quantum wavefunction, it encodes multiple plausible futures until policy choices and shocks collapse them into observable outcomes. Quantum technologies have moved from laboratory curiosities to strategic infrastructure, with an approaching 'event horizon' reflected in recent United States strategic assessments -- incl. the U.S. --China Economic and Security Review Commission's (USSC) call for a Quantum First posture by 2030- and in parallel White House initiatives aimed at securing critical inputs and accelerating trusted innovation. Government research further documents that China's quantum program is centrally mobilized under military-civil fusion, and that its consequential advantages may arise not only from computing milestones but also from sensing and cryptanalytic applications, thereby sharpening the need for a values based deterrence by denial governance posture. The Article's central claim is that the U.S. and its allies should pursue security-sufficient openness, operationalized through a least-trade-restrictive, security-sufficient, innovation-preserving (LSI) test that disciplines both state and private action. The LSI test integrates emerging instruments of economic statecraft to create secure closed loop enclaves for high-sensitivity collaborative R&D. The Article's contribution is an implementable coalition playbook, offering empirically anchored criteria, templates, and differentiated guardrails -- incl. red zone domains where denial is the default -- to avoid both over-securitization and under-securitization. Properly applied, LSI reduces the risk of a self-defeating Silicon Curtain while establishing standards-first interoperability as a stabilizing eigenstate of the international order and enabling RQT by design to shape trusted adoption pathways beyond the coalition, incl. in the majority world."}
{"id": "2602.15094", "categories": ["math.OC", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.15094", "abs": "https://arxiv.org/abs/2602.15094", "authors": ["Petra Lazić", "Linshan Liu", "Mateusz B. Majka"], "title": "On propagation of chaos for the Fisher-Rao gradient flow in entropic mean-field optimization", "comment": "38 pages, to appear in AISTATS 2026", "summary": "We consider a class of optimization problems on the space of probability measures motivated by the mean-field approach to studying neural networks. Such problems can be solved by constructing continuous-time gradient flows that converge to the minimizer of the energy function under consideration, and then implementing discrete-time algorithms that approximate the flow. In this work, we focus on the Fisher-Rao gradient flow and we construct an interacting particle system that approximates the flow as its mean-field limit. We discuss the connection between the energy function, the gradient flow and the particle system and explain different approaches to smoothing out the energy function with an appropriate kernel in a way that allows for the particle system to be well-defined. We provide a rigorous proof of the existence and uniqueness of thus obtained kernelized flows, as well as a propagation of chaos result that provides a theoretical justification for using the corresponding kernelized particle systems as approximation algorithms in entropic mean-field optimization."}
{"id": "2602.15050", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.15050", "abs": "https://arxiv.org/abs/2602.15050", "authors": ["Anna Sverdlik"], "title": "Condensed Past, Thick Present: Evolutionary Approach to the Conscious Experience", "comment": "21 pages, 0 figures", "summary": "This paper examines the conceptual convergence between Lee Smolin's Causal Theory of Views, Karl Friston's Free Energy Principle, and contemporary psychological accounts of the functions of consciousness. Although formulated within different domains -- physics, biology, and psychology -- all three frameworks, in one form or another, appeal to processes of transition from uncertainty to certainty, in which novelty arises through the resolution of surprise. According to the first two approaches, these transitions are realized within particular temporo-spatial gaps, which themselves evolve and become increasingly elaborate as organization grows. By tracing the structural and functional parallels between these frameworks, the paper proposes an account of how the evolution and the gradual elaboration of novelty, surprise, and these temporo-spatial gaps may be linked to the emergence and progressive development of consciousness, up to its highest forms addressed by psychology."}
{"id": "2602.15095", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.15095", "abs": "https://arxiv.org/abs/2602.15095", "authors": ["Bronner P. Gonçalves", "Piero L. Olliaro", "Sheena G. Sullivan", "Benjamin J. Cowling"], "title": "Natural direct effects of vaccines and post-vaccination behaviour", "comment": null, "summary": "Knowledge of the protection afforded by vaccines might, in some circumstances, modify a vaccinated individual's behaviour, potentially increasing exposure to pathogens and hindering effectiveness. Although vaccine studies typically do not explicitly account for this possibility in their analyses, we argue that natural direct effects might represent appropriate causal estimands when an objective is to quantify the effect of vaccination on disease while blocking its influence on behaviour. There are, however, complications of a practical nature for the estimation of natural direct effects in this context. Here, we discuss some of these issues, including exposure-outcome and mediator-outcome confounding by healthcare seeking behaviour, and possible approaches to facilitate estimates of these effects. This work highlights the importance of data collection on behaviour, of assessing whether vaccination induces riskier behaviour, and of understanding the potential effects of interventions on vaccination that could turn off vaccine's influence on behaviour."}
{"id": "2602.15059", "categories": ["math.NA", "math.AP", "math.RA"], "pdf": "https://arxiv.org/pdf/2602.15059", "abs": "https://arxiv.org/abs/2602.15059", "authors": ["Chandrasekhar Gokavarapu", "Naveen Kumar Kakumanu", "Anjali Datla", "Githa Harshitha Noolu"], "title": "Certified Reduced-Order Surrogates and Stability Margins in Viscous Incompressible Flow and Fluid--Structure Interaction", "comment": null, "summary": "Let $(u,p)$ solve the incompressible Navier--Stokes equations in a regime in which an energy inequality is available and each constant in that inequality is computable from declared data. We construct a reduced-order model $u_n$ constrained so that its discrete evolution satisfies a certified energy inequality. This certificate yields global-in-time boundedness of the ROM energy and a regime-of-validity test that fails when a stated hypothesis fails.\n  It follows that one can attach a computable residual functional $\\mathcal{R}_n$ to the ROM trajectory. We prove an a posteriori bound of the form \\[ \\norm{u-u_n}_{\\mathsf{X}(0,T)} \\le C(\\text{declared data})\\,\\mathcal{R}_n, \\] with $C$ explicit and with $\\mathcal{R}_n$ computed from the ROM and the discretization operators. Conversely, if the certificate constraint is relaxed, the bound can fail even for stable full-order dynamics, by an explicit instability mechanism recorded in the text.\n  We then derive transition indicators from rigorous energy and enstrophy budgets in simplified geometries. Each indicator is an inequality involving declared quantities such as forcing norms, viscosity, Poincaré-type constants, and a computable resolvent surrogate. These inequalities provide thresholds that preclude transition, or else certify the presence of transient growth beyond a stated level.\n  Finally, for a class of fluid--structure interaction models, we identify a parameter regime that implies existence and uniqueness of weak solutions. We derive discrete coupled energy estimates that produce computable stability margins. These margins yield explicit constraints on time step and mesh parameters. They are stated as inequalities with constants determined by fluid viscosity, structure stiffness, density ratios, and interface trace bounds."}
{"id": "2602.15041", "categories": ["physics.comp-ph", "physics.plasm-ph", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.15041", "abs": "https://arxiv.org/abs/2602.15041", "authors": ["Victor Windhab", "Andreas Adelmann", "Mohsen Sadr"], "title": "VR-PIC: An entropic variance-reduction method for particle-in-cell solutions of the Vlasov-Poisson equation", "comment": "Preprint", "summary": "We extend the recently developed entropic and conservative variance reduction framework [M. Sadr, N. G. Hadjiconstantinou, A variance-reduced direct Monte Carlo simulation method for solving the Boltzmann equation over a wide range of rarefaction, Journal of Computational Physics 472 (2023) 111677.] to the particle-in-cell (PIC) method of solving Vlasov-Poisson equation. We show that a zeroth-order approximation that freezes the importance weights during the velocity-space kick is stable at the expense of introducing bias. Then, we propose a correction for the weight distribution using maximum cross-entropy formulation to ensure conservation laws while minimizing the introduced bias. In several test cases including Sod's shock tube and Landau damping we show that the proposed method maintains the substantial speed-up of variance reduction method compared to the PIC simulations in the low signal regime with minimal changes to the simulation code."}
{"id": "2602.15736", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.15736", "abs": "https://arxiv.org/abs/2602.15736", "authors": ["Jorge Luiz Franco", "Thomas Peron", "Alcebiades Dal Col", "Fabiano Petronetto", "Filipe Alves Neto Verri", "Eric K. Tokuda", "Luiz Gustavo Nonato"], "title": "SVD Incidence Centrality: A Unified Spectral Framework for Node and Edge Analysis in Directed Networks and Hypergraphs", "comment": null, "summary": "Identifying influential nodes and edges in directed networks remains a fundamental challenge across domains from social influence to biological regulation. Most existing centrality measures face a critical limitation: they either discard directional information through symmetrization or produce sparse, implementation-dependent rankings that obscure structural importance. We introduce a unified spectral framework for centrality analysis in directed networks grounded in the Singular value decomposition of the incidence matrix. The proposed approach derives both vertex and edge centralities via the pseudoinverse of Hodge Laplacians, yielding dense and well-resolved rankings that overcome the sparsity limitations commonly observed in betweenness centrality for directed graphs. Unlike traditional measures that require graph symmetrization, our framework naturally preserves directional information, enabling principled hub/authority analysis while maintaining mathematical consistency through spectral graph theory. The method extends naturally to hypergraphs through the same mathematical foundation. Experimental validation on real-world networks demonstrates the framework's effectiveness across diverse domains where traditional centrality measures encounter limitations due to implementation dependencies and sparse outputs."}
{"id": "2602.15282", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15282", "abs": "https://arxiv.org/abs/2602.15282", "authors": ["Fen Wu"], "title": "State Feedback Control of State-Delayed LPV Systems using Dynamics IQCs", "comment": null, "summary": "This paper develops a new control framework for linear parameter-varying (LPV) systems with time-varying state delays by integrating parameter-dependent Lyapunov functions with integral quadratic constraints (IQCs). A novel delay-dependent state-feedback controller structure is proposed, consisting of a linear state-feedback law augmented with an additional term that captures the delay-dependent dynamics of the plant. Closed-loop stability and $\\mathcal{L}_2$-gain performance are analyzed using dynamic IQCs and parameter-dependent quadratic Lyapunov functions, leading to convex synthesis conditions that guarantee performance in terms of parameter-dependent linear matrix inequalities (LMIs). Unlike traditional delay control approaches, the proposed IQC-based framework provides a flexible and systematic methodology for handling delay effects, enabling enhanced control capability, reduced conservatism, and improved closed-loop performance."}
{"id": "2602.15282", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15282", "abs": "https://arxiv.org/abs/2602.15282", "authors": ["Fen Wu"], "title": "State Feedback Control of State-Delayed LPV Systems using Dynamics IQCs", "comment": null, "summary": "This paper develops a new control framework for linear parameter-varying (LPV) systems with time-varying state delays by integrating parameter-dependent Lyapunov functions with integral quadratic constraints (IQCs). A novel delay-dependent state-feedback controller structure is proposed, consisting of a linear state-feedback law augmented with an additional term that captures the delay-dependent dynamics of the plant. Closed-loop stability and $\\mathcal{L}_2$-gain performance are analyzed using dynamic IQCs and parameter-dependent quadratic Lyapunov functions, leading to convex synthesis conditions that guarantee performance in terms of parameter-dependent linear matrix inequalities (LMIs). Unlike traditional delay control approaches, the proposed IQC-based framework provides a flexible and systematic methodology for handling delay effects, enabling enhanced control capability, reduced conservatism, and improved closed-loop performance."}
{"id": "2602.15554", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.15554", "abs": "https://arxiv.org/abs/2602.15554", "authors": ["Robbert Bosch", "Patricia Rogetzer", "Wouter van Heeswijk", "Martijn Mes"], "title": "Efficient Road Renovation Scheduling under Uncertainty using Lower Bound Pruning", "comment": "24 pages, 14 figures, submitted to Computer-Aided Civil and Infrastructure Engineering", "summary": "Urban infrastructure degrades over time, necessitating periodic renovation to maintain functionality and safety. When renovation is delayed beyond the infrastructure's remaining lifespan, costly emergency interventions become necessary to prevent failure. Decision makers must therefore balance expected emergency intervention costs against traffic congestion impacts. We formalize this trade-off as a road network maintenance scheduling problem with uncertain deadlines, which presents optimization challenges including computationally expensive evaluation and an exponentially growing solution space. To address these challenges, this paper contributes a hybrid optimization approach combining machine learning with genetic algorithms for large-scale infrastructure renovation scheduling under uncertainty. We formulate the problem as a bi-level multi-objective optimization problem that explicitly accounts for uncertain infrastructure lifespans through probabilistic failure models. We develop a progressive lower bound evaluation method that integrates machine learning surrogate models with a multi-objective genetic algorithm to improve solution quality by enabling more iterations within fixed computational budgets. We demonstrate the method's effectiveness on substantially larger problem instances (76 projects) than previously addressed in the literature, achieving statistically significant improvements across multiple performance metrics by increasing computational efficiency up to 40 times compared to standard approaches."}
{"id": "2602.15334", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15334", "abs": "https://arxiv.org/abs/2602.15334", "authors": ["Youxuan Wang", "Rongning Liu", "Feng Liu", "Xueyang Song"], "title": "Universal electrical transport of composite Fermi liquid to Metal transition in Moiré systems", "comment": null, "summary": "We compute universal electrical transport near continuous transitions between a composite Fermi liquid (CFL) and a metallic phase in moire Chern bands, focusing on fillings $ν=-1/2$ and $ν=-3/4$. The critical theory represents a novel QED-Chern-Simons framework: a charged sector at a bosonic Laughlin-superfluid critical point is coupled, via emergent gauge fields and Chern-Simons mixing, to a neutral spinon Fermi surface. Integrating out matter fields to quadratic order yields an explicit Ioffe-Larkin composition rule for the full resistivity tensor, showing how longitudinal channels add in series while Chern-Simons terms generate Hall response. To obtain the DC limit in the quantum critical fan, we develop a controlled large-N expansion where both fermion flavors and Chern-Simons levels scale with $N$, and solve a quantum Boltzmann equation at leading nontrivial order $1/N$. Gauge-mediated inelastic scattering removes the collisionless Drude singularity and produces a universal scaling function $Σ(ω/T)$ and finite DC conductivities $σ(0) \\approx 0.033 e^2/\\hbar$ ($ν=-1/2$) and $0.047 e^2/\\hbar$ ($ν=-3/4$). We also identify a Chern-Simons \"filtering\" mechanism that suppresses transmission of Landau damping from the spinon Fermi surface to the critical gauge mode. Our approach provides concrete transport diagnostics for detecting quantum criticality in moire superlattices."}
{"id": "2602.15122", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15122", "abs": "https://arxiv.org/abs/2602.15122", "authors": ["Angelo Russotto", "Filiberto Ares", "Pasquale Calabrese", "Vincenzo Alba"], "title": "Inhomogeneous quenches and GHD in the $ν= 1$ QSSEP model", "comment": "24 pages, 7 figures", "summary": "We investigate the dynamics of the $ν=1$ Quantum Symmetric Simple Exclusion Process starting from spatially inhomogeneous initial states. This one-dimensional system of free fermions has time-dependent stochastic hopping amplitudes that are uniform in space. We focus on two paradigmatic setups: domain-wall melting and the expansion of a trapped gas. Both are investigated by extending the framework of quantum generalized hydrodynamics to account for the underlying stochastic dynamics. We derive the evolution of the local quasiparticle occupation function, which characterizes the system at large space-time scales, and analyze the resulting entanglement spreading. By incorporating quantum fluctuations of the occupation function and employing conformal field theory techniques, we obtain the exact contribution to the entanglement entropy for each individual noise realization. Averaging over these realizations then yields the full entanglement statistics in the hydrodynamic regime. Our theoretical predictions are confirmed by exact numerical calculations. The results presented here constitute the first application of quantum generalized hydrodynamics to stochastic quantum systems, demonstrating that this framework can be successfully extended beyond purely unitary dynamics to include stochastic effects."}
{"id": "2602.15079", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.15079", "abs": "https://arxiv.org/abs/2602.15079", "authors": ["Nana Liu"], "title": "Fundamental questions on robustness and accuracy for classical and quantum learning algorithms", "comment": "An invited book chapter (submitted June 2025) in \\textit{Quantum Robustness in Artificial Intelligence -- Principles and Applications}, part of the Quantum Science and Technology book series, Springer, ed. Muhammad Usman, 2026", "summary": "This chapter introduces and investigates some fundamental questions on the relationship between accuracy and robustness in both classical and quantum classification algorithms under noisy and adversarial conditions. We introduce and clarify various definitions of robustness and accuracy, including corrupted-instance robustness accuracy and prediction-change robustness, distinguishing them from conventional accuracy and robustness measures. Through theoretical analysis and toy models, we establish conditions under which trade-offs between accuracy and robustness accuracy arise and identify scenarios where such trade-offs can be avoided. The framework developed highlights the nuanced interplay between model bias, noise characteristics, and perturbation types, including relevant and irrelevant perturbations. We explore the implications of some of these results for incompatible noise, adversarial quantum perturbations, the no free lunch theorem, and suggest future methods to examine these problems from the lens of dynamical systems."}
{"id": "2602.15033", "categories": ["cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15033", "abs": "https://arxiv.org/abs/2602.15033", "authors": ["Naoya Onizawa", "Takahiro Hanyu"], "title": "High Convergence Rates of CMOS Invertible Logic Circuits Based on Many-Body Hamiltonians", "comment": "5 pages", "summary": "This paper introduces CMOS invertible-logic (CIL) circuits based on many-body Hamiltonians. CIL can realize probabilistic forward and backward operations of a function by annealing a corresponding Hamiltonian using stochastic computing. We have created a Hamiltonian that includes three-body interaction of spins (probabilistic nodes). It provides some degrees of freedom to design a simpler landscape of Hamiltonian (energy) than that of the conventional two-body Hamiltonian. The simpler landscape makes it easier to reach the global minimum energy. The proposed three-body CIL circuits are designed and evaluated with the conventional two-body CIL circuits, resulting in few-times higher convergence rates with negligible area overhead on FPGA."}
{"id": "2602.15185", "categories": ["cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2602.15185", "abs": "https://arxiv.org/abs/2602.15185", "authors": ["Cooper Jacobus"], "title": "Finding the Edge of Chaos in a Ferromagnet: Quantifying the \"Complexity\" of 2D Ising Phase Transitions with Image Compression", "comment": "Working draft, constructive comments welcome", "summary": "The data-driven characterization of the ``complexity'' present in dynamical systems remains an open problem with broad applications across the physical sciences. We investigate the ``structural complexity'' of the 2D ferromagnetic Ising model, a paradigmatic system exhibiting a second-order phase transition at a certain critical temperature which is often cited as a canonical example of complex morphology. We define a quantitative metric for this structural complexity, $\\mathcal C_s$, through the lens of algorithmic information theory by approximating the Kolmogorov complexity of lattice configurations via standard lossless image compression algorithms. We regularize our proposed metric, $\\mathcal C_s$, by comparing the compressibility of a configuration to that of its pixel-wise sorted and randomly shuffled counterparts. We arrive at a definition of $\\mathcal C_s$ as a product of two components representing the systems departure from perfect order and disorder respectively which we then plot as a function of temperature. Our numerical simulations reveal a distinct peak in $\\mathcal C_s$ at the known critical temperature $T_c$. This result demonstrates that such information-theoretic measures can act as sensitive, model-agnostic indicators of criticality, directly quantifying the emergence of complex structure at the boundary between order and chaos, opening the door to data-driven applications in domains where analytic solutions are unavailable."}
{"id": "2602.15328", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.15328", "abs": "https://arxiv.org/abs/2602.15328", "authors": ["Alfredo Alegría"], "title": "Non-Stationary Covariance Functions for Spatial Data on Linear Networks", "comment": null, "summary": "We introduce a novel class of non-stationary covariance functions for random fields on linear networks that allows both the variance and the correlation range of the random field to vary spatially. The proposed covariance functions are useful to model random fields with a spatial dependence that is locally isotropic with respect to the resistance metric, a distance that reflects the topology of the network. We assess the statistical and computational performance of a weighted local likelihood estimator for the proposed models using synthetic data generated on the street network of the University of Chicago neighborhood."}
{"id": "2602.15151", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15151", "abs": "https://arxiv.org/abs/2602.15151", "authors": ["Stefan Nickel", "Justo Puerto", "Simon Ramoser", "Alberto Torrejón"], "title": "Revisiting transportation problems under Monge costs with applications to location problems", "comment": "59 pages, 3 figures, 3 tables. Includes supplementary material with detailed numerical results", "summary": "We investigate the transportation problem under a Monge cost structure and derive compact formulas for optimal dual solutions based on the northwest-corner rule. As an application illustrating how these formulas yield structural insight while enhancing computational performance, we consider a broad class of facility location problems. In particular, the expressions are used within a Benders decomposition framework to derive novel formulations for the Discrete Ordered Median Problem with non-increasing weights. Numerical experiments validate that the resulting formulations achieve state-of-the-art performance and exhibit strong robustness across a wide range of instances."}
{"id": "2602.15051", "categories": ["physics.soc-ph", "physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15051", "abs": "https://arxiv.org/abs/2602.15051", "authors": ["Mauritz Kop"], "title": "The Nexus of Quantum Technology, Intellectual Property, and National Security: An LSI Test for Securing the Quantum Industrial Commons", "comment": null, "summary": "Our world of power and national security is increasingly probabilistic: like a quantum wavefunction, it encodes multiple plausible futures until policy choices and shocks collapse them into observable outcomes. Quantum technologies have moved from laboratory curiosities to strategic infrastructure, with an approaching 'event horizon' reflected in recent United States strategic assessments -- incl. the U.S. --China Economic and Security Review Commission's (USSC) call for a Quantum First posture by 2030- and in parallel White House initiatives aimed at securing critical inputs and accelerating trusted innovation. Government research further documents that China's quantum program is centrally mobilized under military-civil fusion, and that its consequential advantages may arise not only from computing milestones but also from sensing and cryptanalytic applications, thereby sharpening the need for a values based deterrence by denial governance posture. The Article's central claim is that the U.S. and its allies should pursue security-sufficient openness, operationalized through a least-trade-restrictive, security-sufficient, innovation-preserving (LSI) test that disciplines both state and private action. The LSI test integrates emerging instruments of economic statecraft to create secure closed loop enclaves for high-sensitivity collaborative R&D. The Article's contribution is an implementable coalition playbook, offering empirically anchored criteria, templates, and differentiated guardrails -- incl. red zone domains where denial is the default -- to avoid both over-securitization and under-securitization. Properly applied, LSI reduces the risk of a self-defeating Silicon Curtain while establishing standards-first interoperability as a stabilizing eigenstate of the international order and enabling RQT by design to shape trusted adoption pathways beyond the coalition, incl. in the majority world."}
{"id": "2602.15068", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.15068", "abs": "https://arxiv.org/abs/2602.15068", "authors": ["Salvador K. Dzimah", "Sonia Rubio Herranz", "Fernando Carlos Lopez Hernandez", "Antonio López Montes"], "title": "A Unified Benchmark of Physics-Informed Neural Networks and Kolmogorov-Arnold Networks for Ordinary and Partial Differential Equations", "comment": "23 pages, 9 figures", "summary": "Physics-Informed Neural Networks (PINNs) have emerged as a powerful mesh-free framework for solving ordinary and partial differential equations by embedding the governing physical laws directly into the loss function. However, their classical formulation relies on multilayer perceptrons (MLPs), whose fixed activation functions and global approximation biases limit performance in problems with oscillatory behavior, multiscale dynamics, or sharp gradients. In parallel, Kolmogorov-Arnold Networks (KANs) have been introduced as a functionally adaptive architecture based on learnable univariate transformations along each edge, providing richer local approximations and improved expressivity. This work presents a systematic and controlled comparison between standard MLP-based PINNs and their KAN-based counterparts, Physics-Informed Kolmogorov-Arnold Networks (PIKANs), using identical physics-informed formulations and matched parameter budgets to isolate the architectural effect. Both models are evaluated across a representative collection of ODEs and PDEs, including cases with known analytical solutions that allow direct assessment of gradient reconstruction accuracy. The results show that PIKANs consistently achieve more accurate solutions, converge in fewer iterations, and yield superior gradient estimates, highlighting their advantage for physics-informed learning. These findings underline the potential of KAN-based architectures as a next-generation approach for scientific machine learning and provide rigorous evidence to guide model selection in differential equation solving."}
{"id": "2602.15130", "categories": ["physics.comp-ph", "math.NA", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2602.15130", "abs": "https://arxiv.org/abs/2602.15130", "authors": ["Brian A. Freno", "William J. McDoniel", "Christopher H. Moore", "Neil R. Matula"], "title": "Code-Verification Techniques for Particle-in-Cell Simulations with Direct Simulation Monte Carlo Collisions", "comment": null, "summary": "Particle-in-cell methods with stochastic collision models are commonly used to simulate collisional plasma dynamics, with applications ranging from hypersonic flight to semiconductor manufacturing. Code verification of such methods is challenging due to the interaction between the spatial- and temporal-discretization errors, the statistical sampling noise, and the stochastic nature of the collision algorithm. In this paper, we introduce our code-verification approaches to apply the method of manufactured solutions to plasma dynamics, and we derive expected convergence rates for the different sources of discretization and statistical error. For the particles, we incorporate the method of manufactured solutions into the equations of motion. We manufacture the particle distribution function and inversely query the cumulative distribution function to obtain known particle positions and velocities at each time step. In doing so, we avoid modifying the particle weights, eliminating risks from potentially negative weights or modifications to weight-dependent collision algorithms. For the collision algorithm, we average independent outcomes at each time step and we derive a corresponding manufactured source term for the velocity change for each particle. By having known solutions for the particle positions and velocities, we are able to compute the error in these quantities directly instead of attempting to compute differences in distribution functions. These approaches are equally valid for particle-in-cell simulations with Monte Carlo collisions and direct simulation Monte Carlo simulations of neutral gas flows. We demonstrate the effectiveness of our approaches in three dimensions for different couplings between the particles and field, with and without binary elastic collisions, and with and without coding errors."}
{"id": "2602.15333", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15333", "abs": "https://arxiv.org/abs/2602.15333", "authors": ["Jaehan Im"], "title": "Noncooperative Coordination for Decentralized Air Traffic Management", "comment": null, "summary": "Decentralized air traffic management requires coordination among self-interested stakeholders operating under shared safety and capacity constraints, where conventional centralized or implicitly cooperative models do not adequately capture this setting. We develop a unified perspective on noncooperative coordination, in which system-level outcomes emerge by designing incentives and assigning signals that reshape individual optimality rather than imposing cooperation or enforcement. We advance this framework along three directions: scalable equilibrium engineering via reduced-rank and uncertainty-aware correlated equilibria, decentralized mechanism design for equilibrium selection without enforcement, and structured noncooperative dynamics with convergence guarantees. Beyond these technical contributions, we discuss core design principles that govern incentive-compatible coordination in decentralized systems. Together, these results establish a foundation for scalable, robust coordination in safety-critical air traffic systems."}
{"id": "2602.15333", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15333", "abs": "https://arxiv.org/abs/2602.15333", "authors": ["Jaehan Im"], "title": "Noncooperative Coordination for Decentralized Air Traffic Management", "comment": null, "summary": "Decentralized air traffic management requires coordination among self-interested stakeholders operating under shared safety and capacity constraints, where conventional centralized or implicitly cooperative models do not adequately capture this setting. We develop a unified perspective on noncooperative coordination, in which system-level outcomes emerge by designing incentives and assigning signals that reshape individual optimality rather than imposing cooperation or enforcement. We advance this framework along three directions: scalable equilibrium engineering via reduced-rank and uncertainty-aware correlated equilibria, decentralized mechanism design for equilibrium selection without enforcement, and structured noncooperative dynamics with convergence guarantees. Beyond these technical contributions, we discuss core design principles that govern incentive-compatible coordination in decentralized systems. Together, these results establish a foundation for scalable, robust coordination in safety-critical air traffic systems."}
{"id": "2602.15444", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15444", "abs": "https://arxiv.org/abs/2602.15444", "authors": ["D. A. Kukusta", "L. V. Bekenov", "V. N. Antonov"], "title": "Resonant inelastic x-ray scattering in layered trimer iridate Ba4Ir3 O10 : the density functional approach", "comment": null, "summary": "We have investigated the electronic structure of Ba4Ir3O10 within the density-functional theory (DFT) using the generalized gradient approximation while considering strong Coulomb correlations (GGA+U) in the framework of the fully relativistic spin-polarized Dirac linear muffin-tin orbital band-structure method. Ba4Ir3O10 has a quasi-2D structure composed of buckled sheets, which constitute corner-connected Ir3O12 trimers containing three distorted face-sharing IrO6 octahedra. The Ir atoms are distributed over two symmetrically inequivalent sites: the center of the trimer (Ir1) and its two tips (Ir2). The Ir1 - Ir2 distance within the trimer is quite small and equals to 2.58 A at low temperature. As a result, the clear formation of bonding and antibonding states at the Ir1 site occurs. The large bonding-antibonding splitting stabilizes the dyz-orbital-dominant antibonding state of t2g holes and produces a wide energy gap at the Fermi level. However, the energy gap opens up only with taking into account strong Coulomb correlations at the Ir2 site. Therefore, we have quite a unique situation when the insulating state is driven by both the dimerization at the Ir1 site and Mott insulating behavior at the Ir2 one. We have investigated resonant inelastic x-ray scattering (RIXS) spectra at the Ir L3 edge. The calculated results are in good agreement with experimental data. The RIXS spectrum possesses several sharp features below 2.1 eV corresponding to transitions within the Ir t2g levels. The excitation located from 2.1 to 4.6 eV is due to t2g to eg and O2p to t2g transitions. The wide structure situated at 6.2-12 eV appears due to charge transfer and O2p to eg transitions. We have also presented comprehensive theoretical calculations of the RIXS spectrum at the oxygen K edge."}
{"id": "2602.15163", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.15163", "abs": "https://arxiv.org/abs/2602.15163", "authors": ["Bishnu Bhowmik", "Sayantan Mitra", "Robert M. Ziff", "Ankur Sensharma"], "title": "Bond percolation in distorted simple cubic and body-centered cubic lattices", "comment": "15 pages, 6 figures", "summary": "We investigate the effect of structural distortion on bond percolation in simple cubic and body-centered cubic lattices using extensive Monte Carlo simulations. Distortion is introduced through controlled random displacements of lattice sites, thereby modifying nearest-neighbor distances. Bond occupation is permitted only when the bond length is smaller than a prescribed connection threshold, directly coupling geometric disorder to connectivity. Finite-size scaling analysis is employed to determine percolation thresholds for finite systems and in the thermodynamic limit. We find that when the connection threshold exceeds the nearest-neighbor distance of the undistorted lattice, the percolation threshold increases monotonically with distortion strength, indicating a systematic suppression of spanning. In contrast, this monotonic behavior breaks down when the connection threshold is below the nearest-neighbor distance of the undistorted lattice, highlighting a nontrivial interplay between geometric distortion and connectivity. We further identify critical values of the connection threshold and the distortion amplitude required for global spanning when all the allowed bonds are occupied. All qualitative behaviors remain robust across both lattice geometries. These results clarify how geometric disorder reshapes percolation in three-dimensional crystalline networks."}
{"id": "2602.15080", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15080", "abs": "https://arxiv.org/abs/2602.15080", "authors": ["M. W. AlMasri"], "title": "Geometry of Quantum Logic Gates", "comment": "8 pages", "summary": "In this work, we investigate the geometry of quantum logic gates within the holomorphic representation of quantum mechanics. We begin by embedding the physical qubit subspace into the space of holomorphic functions that are homogeneous of degree one in each Schwinger boson pair $(z_{a_{j}}, z_{b_{j}})$. Within this framework, we derive explicit closed-form differential operator representations for a universal set of quantum gates--including the Pauli operators, Hadamard, CNOT, CZ, and SWAP--and demonstrate that they preserve the physical subspace exactly. Restricting to unit-magnitude variables ($|z| = 1$) reveals a toroidal space $\\mathbb{T}^{2N}$, on which quantum gates act as canonical transformations: Pauli operators generate Hamiltonian flows, the Hadamard gate induces a nonlinear automorphism, and entangling gates produce correlated diffeomorphisms that couple distinct toroidal factors. Beyond the torus, the full Segal--Bargmann space carries a natural Kaehler geometry that governs amplitude dynamics. Entanglement is geometrically characterized via the Segre embedding into complex projective space, while topological protection arises from the $U(1)^{N}$ fiber bundle structure associated with the Jordan--Schwinger constraint."}
{"id": "2602.15048", "categories": ["cs.ET", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.15048", "abs": "https://arxiv.org/abs/2602.15048", "authors": ["Akash Deep", "Andrea Samore", "Alistair McEwan", "Andrew McBride", "Shanmugam Kumar"], "title": "Full-Field Damage Monitoring in Architected Lattices Using In situ Electrical Impedance Tomography", "comment": null, "summary": "Electrical impedance tomography (EIT) enables non-invasive, spatially continuous reconstruction of internal conductivity distributions, providing full field sensing beyond conventional point measurements. Here, we report the first in situ implementation of EIT within a tunable architected lattice materials framework, enabling systematic exploration across a broad lattice design space while achieving real time monitoring of damage evolution, including early stage, prefracture events, in 3D printed multifunctional lattice composites. Lattices are designed via Voronoi based branch trunk branch motifs inspired by 2D wallpaper symmetries and fabricated using CNT infused photocurable resins, with nanoscale filler dispersion confirmed by field emission scanning electron microscopy. Sixteen electrodes distributed along the lattice periphery enable EIT measurements during quasi static tensile loading. Conductivity maps reconstructed using adjacent and across current injection schemes resolve sequential ligament fracture with high temporal resolution, with localised conductivity loss quantitatively coinciding with fracture sites, including regions remote from electrodes. Architectural tunability allows systematic control of EIT imaging sensitivity to early stage damage, while pronounced resistance discontinuities at failure further corroborate spatial localisation; global end to end resistance measurements complement macroscopic stress strain responses. Collectively, these results establish in situ EIT as a scalable, full field sensing modality for architected multifunctional materials, providing an experimentally validated pathway toward autonomous, intelligent materials and data rich material states that can inform digital twin frameworks for structural, biomedical, and energy related applications."}
{"id": "2602.15585", "categories": ["math.ST", "cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.15585", "abs": "https://arxiv.org/abs/2602.15585", "authors": ["Ijay Narang", "Will Perkins", "Timothy L. H. Wee"], "title": "Optimal detection of planted stars via a random energy model", "comment": "34 pages", "summary": "We study the problem of detecting a planted star in the Erd{ő}s--R{é}nyi random graph $G(n,m)$, formulated as a hypothesis test. We determine the scaling window for critical detection in $m$ in terms of the star size, and characterize the asymptotic total variation distance between the null and alternative hypotheses in this window. In the course of the proofs we show a condensation phase transition in the likelihood ratio that closely resembles that of the random energy model from spin glass theory."}
{"id": "2602.15215", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15215", "abs": "https://arxiv.org/abs/2602.15215", "authors": ["Alessandro Alla", "Filippo Mayer"], "title": "Linear error bounds for HJB equations in finite horizon control problems", "comment": null, "summary": "We study semi Lagrangian approximation schemes for Hamilton Jacobi Bellman equations arising from finite horizon optimal control problems. Classical error estimates for these schemes include the term $\\frac{1}{Δt}$ which leads to pessimistic convergence bounds and is not observed in numerical experiments. In this work, we provide improved error estimates under standard regularity assumptions on the dynamics, the running cost, and the final cost, assuming the presence of a positive discount factor. The new bound depends linearly on the time step, the spatial mesh size, and a measure of the temporal oscillation of the control, thus removing the mixed term appearing in previous analyses. The proof relies on a refined comparison between continuous and discrete cost functionals and on stability estimates for the controlled dynamics. Numerical experiments confirm first-order convergence in both space and time and suggest that the improved behavior persists even in the undiscounted case."}
{"id": "2602.15247", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.15247", "abs": "https://arxiv.org/abs/2602.15247", "authors": ["Yuan Bian", "Shelley B. Bull"], "title": "Sample size and power determination for assessing overall SNP effects in joint modeling of longitudinal and time-to-event data", "comment": null, "summary": "Longitudinal biomarkers are frequently collected in clinical studies due to their strong association with time-to-event outcomes. While considerable progress has been made in methods for jointly modeling longitudinal and survival data, comparatively little attention has been paid to statistical design considerations, particularly sample size and power calculations, in genetic studies. Yet, appropriate sample size estimation is essential for ensuring adequate power and valid inference. Genetic variants may influence event risk through both direct effects and indirect effects mediated by longitudinal biomarkers. In this paper, we derive a closed-form sample size formula for testing the overall effect of a single nucleotide polymorphism within a joint modeling framework. Simulation studies demonstrate that the proposed formula yields accurate and robust performance in finite samples. We illustrate the practical utility of our method using data from the Diabetes Control and Complications Trial."}
{"id": "2602.15056", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15056", "abs": "https://arxiv.org/abs/2602.15056", "authors": ["Paula Harder", "Johannes Flemming"], "title": "Reconstructing Carbon Monoxide Reanalysis with Machine Learning", "comment": null, "summary": "The Copernicus Atmospheric Monitoring Service provides reanalysis products for atmospheric composition by combining model simulations with satellite observations. The quality of these products depends strongly on the availability of the observational data, which can vary over time as new satellite instruments become available or are discontinued, such as Carbon Monoxide (CO) observations of the Measurements Of Pollution In The Troposphere (MOPITT) satellite in early 2025. Machine learning offers a promising approach to compensate for such data losses by learning systematic discrepancies between model configurations. In this study, we investigate machine learning methods to predict monthly-mean total column of Carbon Monoxide re-analysis from a control model simulation."}
{"id": "2602.15147", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.15147", "abs": "https://arxiv.org/abs/2602.15147", "authors": ["Lucca Schek", "Peter Lewintan", "Wolfgang Müller", "Ingo Muench", "Andreas Zilian", "Stéphane P. A. Bordas", "Patrizio Neff", "Adam Sky"], "title": "A structure-preserving & objective discretisation of SO(3)-matrix rotation fields for finite Cosserat micropolar continua", "comment": null, "summary": "We introduce a new method, dubbed \\textbf{\\textit{Geometric Structure-Preserving Interpolation (Γ-SPIN)}}, to simultaneously preserve physics-constraints inherent in the material parameter limits of the finite-strain Cosserat micropolar model, and satisfy objectivity under superimposed rigid body motions. The method advocates to interpolate the Cosserat rotation tensor using geodesic elements, which maintain objectivity and correctly represent curvature measures. At the same time, it proposes relaxing the interaction between the rotation tensor and the deformation tensor to alleviate locking effects. This relaxation is achieved in two steps. First, the regularity of the Cosserat rotation tensor is reduced by interpolating it into the Nédélec space. Second, the resulting field is projected back onto the Lie-group of rotations. Together, these steps define a lower-regularity projection-based interpolation. This construction allows the discrete Cosserat rotation tensor to match the polar part of the discrete deformation tensor while remaining objective. This ensures stable behaviour in the asymptotic regime as the Cosserat couple modulus tends to infinity, which constrains the model towards its couple-stress limit. We establish the consistency, stability, and optimality of the proposed method through several benchmark problems. The study culminates in a demonstration of its efficacy on a more intricate curved domain, contrasted with outcomes obtained from conventional interpolation techniques."}
{"id": "2602.15244", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.15244", "abs": "https://arxiv.org/abs/2602.15244", "authors": ["Maximiliano Dalinger", "Elia Merzari", "Saya Lee", "Alex Nellis"], "title": "Analysis of Fission Matrix Databases using Temperature Profiles obtained from High-Fidelity Multiphysics Simulations", "comment": "ANS Student Conference 2026", "summary": "The Fission Matrix method is used to perform fast and still accurate neutronics simulations. It relies on precalculated databases obtained through a Monte Carlo simulation. To represent every state of the reactor, multiple databases are required. The actual state of the reactor is obtained from those databases. In this paper, we analyze the effect of the temperature profiles selected to construct the databases. To do so, the Molten Salt Fast reactor is selected. Two sets of databases are studied: the first uses temperature profiles obtained from high-fidelity Multiphysics simulations with Cardinal, and the second uses uniform temperature profiles. Results showed improved multiplication factor and fission source distribution when the temperature profiles used to generate the databases were similar to those expected when solving the fission matrix."}
{"id": "2602.15350", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15350", "abs": "https://arxiv.org/abs/2602.15350", "authors": ["Mohamad Chehade", "Hao Zhu"], "title": "Fine-Tuning LLMs to Generate Economical and Reliable Actions for the Power Grid", "comment": null, "summary": "Public Safety Power Shutoffs (PSPS) force rapid topology changes that can render standard operating points infeasible, requiring operators to quickly identify corrective transmission switching actions that reduce load shedding while maintaining acceptable voltage behavior. We present a verifiable, multi-stage adaptation pipeline that fine-tunes an instruction-tuned large language model (LLM) to generate \\emph{open-only} corrective switching plans from compact PSPS scenario summaries under an explicit switching budget. First, supervised fine-tuning distills a DC-OPF MILP oracle into a constrained action grammar that enables reliable parsing and feasibility checks. Second, direct preference optimization refines the policy using AC-evaluated preference pairs ranked by a voltage-penalty metric, injecting voltage-awareness beyond DC imitation. Finally, best-of-$N$ selection provides an inference-time addition by choosing the best feasible candidate under the target metric. On IEEE 118-bus PSPS scenarios, fine-tuning substantially improves DC objective values versus zero-shot generation, reduces AC power-flow failure from 50\\% to single digits, and improves voltage-penalty outcomes on the common-success set. Code and data-generation scripts are released to support reproducibility."}
{"id": "2602.15350", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15350", "abs": "https://arxiv.org/abs/2602.15350", "authors": ["Mohamad Chehade", "Hao Zhu"], "title": "Fine-Tuning LLMs to Generate Economical and Reliable Actions for the Power Grid", "comment": null, "summary": "Public Safety Power Shutoffs (PSPS) force rapid topology changes that can render standard operating points infeasible, requiring operators to quickly identify corrective transmission switching actions that reduce load shedding while maintaining acceptable voltage behavior. We present a verifiable, multi-stage adaptation pipeline that fine-tunes an instruction-tuned large language model (LLM) to generate \\emph{open-only} corrective switching plans from compact PSPS scenario summaries under an explicit switching budget. First, supervised fine-tuning distills a DC-OPF MILP oracle into a constrained action grammar that enables reliable parsing and feasibility checks. Second, direct preference optimization refines the policy using AC-evaluated preference pairs ranked by a voltage-penalty metric, injecting voltage-awareness beyond DC imitation. Finally, best-of-$N$ selection provides an inference-time addition by choosing the best feasible candidate under the target metric. On IEEE 118-bus PSPS scenarios, fine-tuning substantially improves DC objective values versus zero-shot generation, reduces AC power-flow failure from 50\\% to single digits, and improves voltage-penalty outcomes on the common-success set. Code and data-generation scripts are released to support reproducibility."}
{"id": "2602.15466", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.15466", "abs": "https://arxiv.org/abs/2602.15466", "authors": ["Xumin Chang", "Zui Tao", "Bowen Shen", "Wanghao Tian", "Jenny Hu", "Kateryna Pistunova", "Kenji Watanabe", "Takashi Taniguchi", "Tony F. Heinz", "Tingxin Li", "Kin Fai Mak", "Jie Shan", "Shengwei Jiang"], "title": "Electric-field-tuned consecutive topological phase transitions between distinct correlated insulators in moire MoTe2/WSe2 heterobilayer", "comment": null, "summary": "Consecutive topological phase transitions (TPTs) between strongly correlated electronic phases that differ simultaneously in symmetry breaking and topological order are of fundamental interest in condensed matter physics, yet are rarely realized experimentally. We report two consecutive electric-field-driven TPTs at half filling (nu = 1) in angle-aligned MoTe2/WSe2 moire heterobilayers. With increasing out-of-plane displacement field, a geometrically frustrated Mott insulator evolves into a ferromagnetic quantum anomalous Hall (QAH) Mott insulator, i.e., a spin-polarized topological Mott insulator without an observable charge-gap closure, and subsequently into an antiferromagnetic, valley-coherent Mott insulator (VC-AFM) accompanied by a continuous charge-gap collapse and the emergence of a critical metallic state. Layer-resolved magnetic circular dichroism (MCD), magneto-transport, and compressibility measurements jointly determine the phase diagram. The high-field evolution of the antiferromagnetic state reveals a metamagnetic-like transition at a critical field B*, above which a Chern insulating transport response reappears. Our results establish the MoTe2/WSe2 moire platform as a tunable realization of an extended Kane-Mele-Hubbard model hosting sequential correlation-topology-intertwined transitions."}
{"id": "2602.15185", "categories": ["cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2602.15185", "abs": "https://arxiv.org/abs/2602.15185", "authors": ["Cooper Jacobus"], "title": "Finding the Edge of Chaos in a Ferromagnet: Quantifying the \"Complexity\" of 2D Ising Phase Transitions with Image Compression", "comment": "Working draft, constructive comments welcome", "summary": "The data-driven characterization of the ``complexity'' present in dynamical systems remains an open problem with broad applications across the physical sciences. We investigate the ``structural complexity'' of the 2D ferromagnetic Ising model, a paradigmatic system exhibiting a second-order phase transition at a certain critical temperature which is often cited as a canonical example of complex morphology. We define a quantitative metric for this structural complexity, $\\mathcal C_s$, through the lens of algorithmic information theory by approximating the Kolmogorov complexity of lattice configurations via standard lossless image compression algorithms. We regularize our proposed metric, $\\mathcal C_s$, by comparing the compressibility of a configuration to that of its pixel-wise sorted and randomly shuffled counterparts. We arrive at a definition of $\\mathcal C_s$ as a product of two components representing the systems departure from perfect order and disorder respectively which we then plot as a function of temperature. Our numerical simulations reveal a distinct peak in $\\mathcal C_s$ at the known critical temperature $T_c$. This result demonstrates that such information-theoretic measures can act as sensitive, model-agnostic indicators of criticality, directly quantifying the emergence of complex structure at the boundary between order and chaos, opening the door to data-driven applications in domains where analytic solutions are unavailable."}
{"id": "2602.15115", "categories": ["quant-ph", "hep-ex", "hep-ph"], "pdf": "https://arxiv.org/pdf/2602.15115", "abs": "https://arxiv.org/abs/2602.15115", "authors": ["Yoav Afik", "Regina Demina", "Alan Herrera", "Otto Hindrichs", "Juan Ramón Muñoz de Nova", "Baptiste Ravina"], "title": "Experimental characterization of the hierarchy of quantum correlations in top quark pairs", "comment": "11 pages, 4 figures", "summary": "Recent results from the Large Hadron Collider have demonstrated quantum entanglement of top quark-antiquark pairs using the spin degree of freedom. Based on the doubly differential measurement of the spin density matrix of the top quark and antiquark performed by the CMS collaboration in the helicity and beam bases, we evaluate a set of quantum observables, including discord, steering, Bell correlation, and magic. These observables allow for a quantitative characterization of the quantum correlations present in a top quark--antiquark system, thus enabling an interpretation of collider data in terms of quantum states and their properties. Discord is observed to be greater than zero with a significance of more than 5 standard deviations ($σ$). Evidence for steering is found with a significance of more than 3$σ$. This is the first evidence for steering, and the first observation of discord in a high-energy system. No Bell correlation is observed within the currently probed phase space, in agreement with the theoretical prediction. These results experimentally corroborate the full hierarchy of quantum correlations in top quarks with discord being the most basic form of quantum correlation, followed by entanglement, steering and Bell correlation. The significance of nonzero magic, which is a complementary observable to the quantum-correlation hierarchy, is found to exceed 5$σ$ in several regions of phase space."}
{"id": "2602.15049", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.15049", "abs": "https://arxiv.org/abs/2602.15049", "authors": ["Mohamed Khalil Brik", "Ahmed Shokry", "Moustafa Youssef"], "title": "Quantum Optimization for Access Point Selection Under Budget Constraint", "comment": "9 pages, 13 figures. Accepted as a short paper at the 2026 IEEE International Conference on Quantum Communications, Networking, and Computing (QCNC 2026), Kobe, Japan, April 6-8, 2026", "summary": "Optimal Access Point (AP) selection is crucial for accurate indoor localization, yet it is constrained by budget, creating a trade-off between localization accuracy and deployment cost. Classical approaches to AP selection are often computationally expensive, hindering their application in large-scale 3D indoor environments.\n  In this paper, we introduce a quantum APs selection algorithm under a budget constraint. The proposed algorithm leverages quantum annealing to identify the most effective subset of APs allowed within a given budget. We formulate the APs selection problem as a quadratic unconstrained binary optimization (QUBO) problem, making it suitable for quantum annealing solvers. The proposed technique can drastically reduce infrastructure requirements with a negligible impact on performance.\n  We implement the proposed quantum algorithm and deploy it in a realistic 3D testbed. Our results show that the proposed approach can reduce the number of required APs by 96.1% while maintaining a comparable 3D localization accuracy. Furthermore, the proposed quantum approach outperforms classical AP selection algorithms in both accuracy and computational speed. Specifically, our technique achieves a time of 0.20 seconds, representing a speedup of 61 times over its classical counterpart, while reducing the mean localization error by 10% compared to the classical counterpart. For floor localization, the quantum approach achieves 73% floor accuracy, outperforming both the classical AP selection (58.6%) and even using the complete set of APs (70.4%). This highlights the promise of the proposed quantum APs selection algorithm for large-scale 3D localization."}
{"id": "2602.15587", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.15587", "abs": "https://arxiv.org/abs/2602.15587", "authors": ["Armand Gissler", "Saeed Saremi", "Francis Bach"], "title": "Adjusted Scores for Discrete Langevin Algorithms", "comment": null, "summary": "Sampling from discrete distributions is a ubiquitous task in machine learning, recently revisited by the emergence of discrete diffusion models. While Langevin algorithms constitute the state of the art for continuous spaces, discrete versions lack similar theoretical guarantees when the step-size becomes small. In this paper, we address this limitation by interpreting discrete sampling algorithms as discretizations of continuous-time dynamics on the hypercube. In particular, we describe several score functions for discrete algorithms which result in approximations of Glauber dynamics for the correct target distribution. We also compute upper bounds for the contraction of these algorithms, with or without Metropolis adjustment."}
{"id": "2602.15242", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15242", "abs": "https://arxiv.org/abs/2602.15242", "authors": ["Sicheng He", "Shugo Kaneko", "Max Howell", "Nan Li", "Joaquim R. R. A. Martins"], "title": "Efficient Adjoint-based Design Optimization with Optimal Control", "comment": null, "summary": "Multidisciplinary engineering system design typically employs a sequential process, progressing from system dynamics to design variables and control. However, this process is inefficient and may lead to a suboptimal design. We propose formulating the optimal control and multidisciplinary design optimization (MDO) problems as a single problem with linear quadratic regulator (LQR) control. We use the coupled adjoint method to compute the design variable derivatives, which are critical for gradient-based design optimization. The computational cost of the derivative computation using the adjoint method is independent of the number of design variables, making it suitable for large-scale problems. We show that the coupled adjoint can be solved indirectly and more efficiently by solving three smaller adjoint equations that leverage the feedforward structure of the problem. We demonstrate this new approach on two test problems: design optimization of a classic cart-pole problem and the aerodynamic shape of a quadrotor blade. For the quadrotor blade design problem, we reduce the control cost by 10% by optimizing the blade for a specific control task with a slight penalty in steady hovering power consumption."}
{"id": "2602.15062", "categories": ["physics.soc-ph", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.15062", "abs": "https://arxiv.org/abs/2602.15062", "authors": ["Labib Shami", "Teddy Lazebnik"], "title": "Cooperative Game Theory Model for Sustainable UN Financing: Addressing Global Public Goods Provision", "comment": null, "summary": "This study introduces a novel cooperative game theory model designed to improve the United Nations' current funding mechanisms, which predominantly rely on voluntary contributions. By shifting from a Nash equilibrium framework, where member states act in self-interest, to a cooperative model, the proposed approach aligns each country's financial contributions with the benefits they derive from UN activities. The model ensures a more sustainable and equitable system by introducing personalized pricing based on derived utility. Using agent-based simulations, the research demonstrates that the suggested approach increases global utility, reduces free-rider issues, and creates a more efficient resource allocation system. The findings suggest that the proposed model can optimize UN funding, ensuring a more stable and effective framework for global public goods provision, while considering the varying economic capacities of member states. Further research is recommended to assess the political viability of the model."}
{"id": "2602.15291", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.15291", "abs": "https://arxiv.org/abs/2602.15291", "authors": ["Takuma Yoshida", "Koki Momoki", "Shuichi Kawano"], "title": "Structural grouping of extreme value models via graph fused lasso", "comment": "40 pages, 14 figures", "summary": "The generalized Pareto distribution (GPD) is a fundamental model for analyzing the tail behavior of a distribution. In particular, the shape parameter of the GPD characterizes the extremal properties of the distribution. As described in this paper, we propose a method for grouping shape parameters in the GPD for clustered data via graph fused lasso. The proposed method simultaneously estimates the model parameters and identifies which clusters can be grouped together. We establish the asymptotic theory of the proposed estimator and demonstrate that its variance is lower than that of the cluster-wise estimator. This variance reduction not only enhances estimation stability but also provides a principled basis for identifying homogeneity and heterogeneity among clusters in terms of their tail behavior. We assess the performance of the proposed estimator through Monte Carlo simulations. As an illustrative example, our method is applied to rainfall data from 996 clustered sites across Japan."}
{"id": "2602.15088", "categories": ["physics.ao-ph", "astro-ph.IM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15088", "abs": "https://arxiv.org/abs/2602.15088", "authors": ["Gabriele Franch", "Elena Tomasi", "Uladzislau Azhel", "Giacomo Tomezzoli", "Alessandro Camilletti", "Virginia Poli", "Renata Pelosini", "Gianfranco Vulpiani", "Gabriella Scipione", "Giuseppe Trotta", "Matteo Angelinelli", "Leif Denby", "Irene Livia Kruse", "Marco Cristoforetti"], "title": "IT-DPC-SRI: A Cloud-Optimized Archive of Italian Radar Precipitation (2010-2025)", "comment": "15 pages, 7 figures", "summary": "We present IT-DPC-SRI, the first publicly available long-term archive of Italian weather radar precipitation estimates, spanning 16 years (2010--2025). The dataset contains Surface Rainfall Intensity (SRI) observations from the Italian Civil Protection Department's national radar mosaic, harmonized into a coherent Analysis-Ready Cloud-Optimized (ARCO) Zarr datacube. The archive comprises over one million timesteps at temporal resolutions from 15 to 5 minutes, covering a $1200\\times1400$ kilometer domain at 1 kilometer spatial resolution, compressed from 7TB to 51GB on disk. We address the historical fragmentation of Italian radar data - previously scattered across heterogeneous formats (OPERA BUFR, HDF5, GeoTIFF) with varying spatial domains and projections - by reprocessing the entire record into a unified store. The dataset is accessible as a static versioned snapshot on Zenodo, via cloud-native access on the ECMWF European Weather Cloud, and as a continuously updated live version on the ArcoDataHub platform. This release fills a significant gap in European radar data availability, as Italy does not participate in the EUMETNET OPERA pan-European radar composite. The dataset is released under a CC BY-SA 4.0 license."}
{"id": "2602.15193", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.15193", "abs": "https://arxiv.org/abs/2602.15193", "authors": ["Simon Lemaire"], "title": "Equivalence of mixed and nonconforming methods on general polytopal partitions. Part I: Multiscale and projection methods", "comment": "21 pages", "summary": "We study equivalence, in the context of a variable diffusion problem, between (conforming) mixed methods and (primal) nonconforming methods defined on potentially general polytopal partitions. In this first paper of a series of two, we focus on multiscale and projection methods. For multiscale methods, we establish the first-level equivalence between four different (oversampling-free) approaches, thereby broadening the results of [Chaumont-Frelet, Ern, Lemaire, Valentin; M2AN, 2022]. For projection methods, in turn, we provide a simple criterion (to be checked in practice) for primal/mixed well-posedness and equivalence to hold true. In the process, we also shed a new light on some self-stabilized hybrid methods. Part II of this work will address (general) polytopal element methods."}
{"id": "2602.15632", "categories": ["physics.comp-ph", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.15632", "abs": "https://arxiv.org/abs/2602.15632", "authors": ["Changhong Mou", "Binghang Lu", "Guang Lin"], "title": "Neural-POD: A Plug-and-Play Neural Operator Framework for Infinite-Dimensional Functional Nonlinear Proper Orthogonal Decomposition", "comment": null, "summary": "The rapid development of AI for Science is often hindered by the \"discretization\", where learned representations remain restricted to the specific grids or resolutions used during training. We propose the Neural Proper Orthogonal Decomposition (Neural-POD), a plug-and-play neural operator framework that constructs nonlinear, orthogonal basis functions in infinite-dimensional space using neural networks. Unlike the classical Proper Orthogonal Decomposition (POD), which is limited to linear subspace approximations obtained through singular value decomposition (SVD), Neural-POD formulates basis construction as a sequence of residual minimization problems solved through neural network training. Each basis function is obtained by learning to represent the remaining structure in the data, following a process analogous to Gram--Schmidt orthogonalization. This neural formulation introduces several key advantages over classical POD: it enables optimization in arbitrary norms (e.g., $L^2$, $L^1$), learns mappings between infinite-dimensional function spaces that is resolution-invariant, generalizes effectively to unseen parameter regimes, and inherently captures nonlinear structures in complex spatiotemporal systems. The resulting basis functions are interpretable, reusable, and enabling integration into both reduced order modeling (ROM) and operator learning frameworks such as deep operator learning (DeepONet). We demonstrate the robustness of Neural-POD with different complex spatiotemporal systems, including the Burgers' and Navier-Stokes equations. We further show that Neural-POD serves as a high performance, plug-and-play bridge between classical Galerkin projection and operator learning that enables consistent integration with both projection-based reduced order models and DeepONet frameworks."}
{"id": "2602.15422", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15422", "abs": "https://arxiv.org/abs/2602.15422", "authors": ["Shuichi Yahagi", "Ansei Yonezawa", "Heisei Yonezawa", "Hiroki Seto", "Itsuro Kajiwara"], "title": "Generalized bilinear Koopman realization from input-output data for multi-step prediction with metaheuristic optimization of lifting function and its application to real-world industrial system", "comment": null, "summary": "This paper introduces an input-output bilinear Koopman realization with an optimization algorithm of lifting functions. For nonlinear systems with inputs, Koopman-based modeling is effective because the Koopman operator enables a high-dimensional linear representation of nonlinear dynamics. However, traditional approaches face significant challenges in industrial applications. Measuring all system states is often impractical due to constraints on sensor installation. Moreover, the predictive performance of a Koopman model strongly depends on the choice of lifting functions, and their design typically requires substantial manual effort. In addition, although a linear time-invariant (LTI) Koopman model is the most commonly used model structure in the Koopman framework, such model exhibit limited predictive accuracy. To address these limitations, we propose an input-output bilinear Koopman modeling in which the design parameters of radial basis function (RBF)-based lifting functions are optimized using a global metaheuristic algorithm to improve long-term prediction performance. Consideration of the long-term prediction performance enhances the reliability of the resulting model. The proposed methodology is validated in simulations and experimental tests, with the airpath control system of a diesel engine as the plant to be modeled. This plant represents a challenging industrial application because it exhibits strong nonlinearities and coupled multi-input multi-output (MIMO) dynamics. These results demonstrate that the proposed input-output bilinear Koopman model significantly outperforms traditional linear Koopman models in predictive accuracy."}
{"id": "2602.15422", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15422", "abs": "https://arxiv.org/abs/2602.15422", "authors": ["Shuichi Yahagi", "Ansei Yonezawa", "Heisei Yonezawa", "Hiroki Seto", "Itsuro Kajiwara"], "title": "Generalized bilinear Koopman realization from input-output data for multi-step prediction with metaheuristic optimization of lifting function and its application to real-world industrial system", "comment": null, "summary": "This paper introduces an input-output bilinear Koopman realization with an optimization algorithm of lifting functions. For nonlinear systems with inputs, Koopman-based modeling is effective because the Koopman operator enables a high-dimensional linear representation of nonlinear dynamics. However, traditional approaches face significant challenges in industrial applications. Measuring all system states is often impractical due to constraints on sensor installation. Moreover, the predictive performance of a Koopman model strongly depends on the choice of lifting functions, and their design typically requires substantial manual effort. In addition, although a linear time-invariant (LTI) Koopman model is the most commonly used model structure in the Koopman framework, such model exhibit limited predictive accuracy. To address these limitations, we propose an input-output bilinear Koopman modeling in which the design parameters of radial basis function (RBF)-based lifting functions are optimized using a global metaheuristic algorithm to improve long-term prediction performance. Consideration of the long-term prediction performance enhances the reliability of the resulting model. The proposed methodology is validated in simulations and experimental tests, with the airpath control system of a diesel engine as the plant to be modeled. This plant represents a challenging industrial application because it exhibits strong nonlinearities and coupled multi-input multi-output (MIMO) dynamics. These results demonstrate that the proposed input-output bilinear Koopman model significantly outperforms traditional linear Koopman models in predictive accuracy."}
{"id": "2602.15588", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15588", "abs": "https://arxiv.org/abs/2602.15588", "authors": ["Wojciech Sas", "Yuki Utsumi Boucher", "Seyed Ashkan Moghadam Ziabari", "Gaurav Pransu", "Trpimir Ivšić", "László Forró", "Ivana Vobornik", "Jun Fujii", "Naveen Singh Dhami", "Bruno Gudac", "Mario Novak", "Neven Barišić", "Ivo Batistić", "Petar Popčević"], "title": "Origin of a shallow electron pocket: $β$-band in Co$_{1/3}$TaS$_2$ studied by angle-resolved photoemission spectroscopy", "comment": "10 pages, 6 figures, 1 table", "summary": "We investigated the electronic structure of Co-intercalated 2H-TaS$_2$ using angle-resolved photoemission spectroscopy (ARPES). In the compound Co$_{1/3}$TaS$_2$, the main electronic bands closely resemble those of pristine 2H-TaS$_2$, with no clear signs of band folding. However, a shallow electron pocket, referred to as the $β$-feature, was detected at the Fermi level near the corner of the superlattice Brillouin zone. The surface vs bulk origin of this feature is debated, as it cannot be reproduced using standard DFT calculations. To resolve this, we employed cluster perturbation theory (CPT) to incorporating an exact treatment of strong electron correlations (U) on the cobalt sites, going beyond DFT+U approximation. To further substantiate this, we studied an underdoped sample, Co$_{0.22}$TaS$_2$, where a reduced charge transfer leads to different Co orbital character near the Fermi level. We find that its electronic structure closely resembles that of undoped 2H-TaS$_2$, and crucially, lacks the $β$-feature. Our results demonstrate that the $β$-feature is of the bulk origin emerging from the strong electronic correlations where both the Co charge state and long-range crystallographic order play an important role. This work highlights the need for accurate treatment of electron correlations when studying intercalated transition metal dichalcogenides."}
{"id": "2602.15369", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.15369", "abs": "https://arxiv.org/abs/2602.15369", "authors": ["Ting Peng"], "title": "Entropy Has No Direction: A Mirror-State Paradox Against Universal Monotonic Entropy Increase and a First-Principles Proof that Constraints Reshape the Entropy Distribution", "comment": null, "summary": "We present a purely theoretical, self-contained argument that the Second Law of Thermodynamics cannot be a universal fundamental law in the form ``entropy does not decrease'' (whether asserted trajectory-wise or as a universal statistical principle) when the underlying microscopic dynamics are time-reversal invariant. The core is a mirror-state construction: for any microstate $A$ one constructs its time-reversed partner $B$ (momenta inverted). If a universal monotonicity statement is applied to both $A$ and $B$, it implies that $A$ is a local minimum of entropy at every moment, which forces entropy to be constant and destroys any entropic arrow of time. The consistent replacement is that entropy is a stochastic variable described by a probability distribution $P(S)$, whose shape depends on constraints and boundary conditions. We then prove from first principles that constraints necessarily reshape the long-time entropy distribution $P_{\\infty}(S;λ)$ by altering the invariant measure through changes in the Hamiltonian and/or the accessible phase space. A sharp criterion is given: in the microcanonical setting, the \\emph{only} way $P_{\\infty}^{(E)}(S;λ)$ can remain the same up to translation is when all accessible macrostate volumes are scaled by a common factor; otherwise the distribution changes structurally."}
{"id": "2602.15116", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15116", "abs": "https://arxiv.org/abs/2602.15116", "authors": ["Andrew Hallam", "Ryan Smith", "Zlatko Papić"], "title": "Spectral signatures of nonstabilizerness and criticality in infinite matrix product states", "comment": "21 pages, 9 figures", "summary": "While nonstabilizerness (''magic'') is a key resource for universal quantum computation, its behavior in many-body quantum systems, especially near criticality, remains poorly understood. We develop a spectral transfer-matrix framework for the stabilizer Rényi entropy (SRE) in infinite matrix product states, showing that its spectrum contains universal subleading information. In particular, we identify an SRE correlation length -- distinct from the standard correlation length -- which diverges at continuous phase transitions and governs the spatial response of the SRE to local perturbations. We derive exact SRE expressions for the bond dimension $χ=2$ MPS ''skeleton'' of the cluster-Ising model, and we numerically probe its universal scaling along the $\\mathbb{Z}_2$ critical lines in the phase diagram. These results demonstrate that nonstabilizerness captures signatures of criticality and local perturbations, providing a new lens on the interplay between computational resources and emergent phenomena in quantum many-body systems."}
{"id": "2602.15477", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.15477", "abs": "https://arxiv.org/abs/2602.15477", "authors": ["Asma Taheri Monfared", "Andrea Bombarda", "Angelo Gargantini", "Majid Haghparast"], "title": "Quantum Computing for Healthcare Digital Twin Systems", "comment": "13 pages, 3 figures", "summary": "The growing complexity of healthcare systems requires advanced computational models for real-time monitoring, secure data exchange, and intelligent decision-making. Digital Twins (DTs) provide virtual representations of physical healthcare entities, enabling continuous patient monitoring and personalized care. However, classical DT frameworks face limitations in scalability, computational efficiency, and security. Recent studies have introduced Quantum Digital Twins (QDTs) to enhance performance through quantum computing, addressing challenges such as quantum-resistant security and efficient task offloading in healthcare environments. Despite these advances, most existing QDT models remain constrained by fundamental challenges related to quantum hardware limitations, hybrid classical-quantum system integration, cloud-based quantum access, scalability, and clinical trust. This paper provides a comprehensive review of QDTs for healthcare, with a particular focus on identifying and analyzing the key challenges that currently hinder their real-world adoption. Furthermore, it outlines critical research directions and enabling strategies aimed at advancing the development of secure, reliable, and clinically viable quantum digital twin systems for next-generation healthcare applications."}
{"id": "2602.15559", "categories": ["stat.ME", "econ.EM", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.15559", "abs": "https://arxiv.org/abs/2602.15559", "authors": ["Gabriel Saco"], "title": "Fixed-Horizon Self-Normalized Inference for Adaptive Experiments via Martingale AIPW/DML with Logged Propensities", "comment": "32 pages. Comments welcome", "summary": "Adaptive randomized experiments update treatment probabilities as data accrue, but still require an end-of-study interval for the average treatment effect (ATE) at a prespecified horizon. Under adaptive assignment, propensities can keep changing, so the predictable quadratic variation of AIPW/DML score increments may remain random. When no deterministic variance limit exists, Wald statistics normalized by a single long-run variance target can be conditionally miscalibrated given the realized variance regime. We assume no interference, sequential randomization, i.i.d. arrivals, and executed overlap on a prespecified scored set, and we require two auditable pipeline conditions: the platform logs the executed randomization probability for each unit, and the nuisance regressions used to score unit $t$ are constructed predictably from past data only. These conditions make the centered AIPW/DML scores an exact martingale difference sequence. Using self-normalized martingale limit theory, we show that the Studentized statistic, with variance estimated by realized quadratic variation, is asymptotically N(0,1) at the prespecified horizon, even without variance stabilization. Simulations validate the theory and highlight when standard fixed-variance Wald reporting fails."}
{"id": "2602.15269", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15269", "abs": "https://arxiv.org/abs/2602.15269", "authors": ["Arian Andam", "Hossein Hashemi Doulabi"], "title": "Operating room planning with pooling downstream beds among specialties: A stochastic programming approach", "comment": null, "summary": "In this paper, we study pooling downstream beds across specialties in a stochastic operating room planning problem. The main sources of uncertainty are stochastic surgical durations and patients' lengths of stay. We developed a two-stage stochastic programming model where in the first stage we decide on 1) the number of non-shared ICU and ward beds to be allocated to each specialty, and 2) the allocation of surgeries to operating rooms during the planning horizon. In the second stage, we decide on 1) the number of shared beds in ICU and wards to be allocated to different specialties on each day during the planning horizon, 2) the surge capacity required to satisfy downstream service to patients, and 3) the overtime incurred in operating rooms. The proposed model aims at minimizing the total cost including the patients' waiting cost, postponement cost, overtime and fixed cost of operating rooms, and the cost of downstream surge capacity. We have implemented the proposed stochastic programming model in a sample average approximation framework. To enhance the efficiency of sample average approximation, we have developed a specialized algorithm that quickly solves the second-stage model for any given first-stage solution for a large number of scenarios. We have carried out extensive computational experiments to evaluate the effectiveness of several pooling policies for downstream beds and also the efficiency of the proposed sample average approximation algorithm. Moreover, we have performed an extensive sensitivity analysis of cost and stochastic parameters. Our results demonstrated that a full-sharing policy among different specialties in the downstream units enhance the functionality of the system by up to 19.53%. Moreover, the results indicated that the solutions obtained by the proposed stochastic model outperform those from the corresponding deterministic problem by 17.43% on average."}
{"id": "2602.15064", "categories": ["physics.soc-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15064", "abs": "https://arxiv.org/abs/2602.15064", "authors": ["Wenpin Hou", "Zhicheng Ji"], "title": "Structural Divergence Between AI-Agent and Human Social Networks in Moltbook", "comment": null, "summary": "Large populations of AI agents are increasingly embedded in online environments, yet little is known about how their collective interaction patterns compare to human social systems. Here, we analyze the full interaction network of Moltbook, a platform where AI agents and humans coexist, and systematically compare its structure to well-characterized human communication networks. Although Moltbook follows the same node-edge scaling relationship observed in human systems, indicating comparable global growth constraints, its internal organization diverges markedly. The network exhibits extreme attention inequality, heavy-tailed and asymmetric degree distributions, suppressed reciprocity, and a global under-representation of connected triadic structures. Community analysis reveals a structured modular architecture with elevated modularity and comparatively lower community size inequality relative to degree-preserving null models. Together, these findings show that AI-agent societies can reproduce global structural regularities of human networks while exhibiting fundamentally different internal organizing principles, highlighting that key features of human social organization are not universal but depend on the nature of the interacting agents."}
{"id": "2602.15319", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.15319", "abs": "https://arxiv.org/abs/2602.15319", "authors": ["Agnideep Aich", "Md. Monzur Murshed", "Sameera Hewage", "Ashit Baran Aich"], "title": "Bayesian Inference for Joint Tail Risk in Paired Biomarkers via Archimedean Copulas with Restricted Jeffreys Priors", "comment": null, "summary": "We propose a Bayesian copula-based framework to quantify clinically interpretable joint tail risks from paired continuous biomarkers. After converting each biomarker margin to rank-based pseudo-observations, we model dependence using one-parameter Archimedean copulas and focus on three probability-scale summaries at tail level $α$: the lower-tail joint risk $R_L(θ)=C_θ(α,α)$, the upper-tail joint risk $R_U(θ)=2α-1+C_θ(1-α,1-α)$, and the conditional lower-tail risk $R_C(θ)=R_L(θ)/α$. Uncertainty is quantified via a restricted Jeffreys prior on the copula parameter and grid-based posterior approximation, which induces an exact posterior for each tail-risk functional. In simulations from Clayton and Gumbel copulas across multiple dependence strengths, posterior credible intervals achieve near-nominal coverage for $R_L$, $R_U$, and $R_C$. We then analyze NHANES 2017--2018 fasting glucose (GLU) and HbA1c (GHB) ($n=2887$) at $α=0.05$, obtaining tight posterior credible intervals for both the dependence parameter and induced tail risks. The results reveal markedly elevated extremal co-movement relative to independence; under the Gumbel model, the posterior mean joint upper-tail risk is $R_U(α)=0.0286$, approximately $11.46\\times$ the independence benchmark $α^2=0.0025$. Overall, the proposed approach provides a principled, dependence-aware method for reporting joint and conditional extremal-risk summaries with Bayesian uncertainty quantification in biomedical applications."}
{"id": "2602.15768", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.15768", "abs": "https://arxiv.org/abs/2602.15768", "authors": ["Lucie Reymondet", "Lia Siegelman", "Luc Lenain"], "title": "Southern Ocean latent heat flux variability driven by oceanic meso- and submesoscale motions", "comment": "Submitted to AMS Journal of Climate", "summary": "Latent heat flux is a primary pathway for ocean-atmosphere exchange of heat and moisture, yet the influence of sea surface temperature variability at fine scales ($\\leq$ 100 km) on latent heat flux variability, particularly over the Southern Ocean, remains poorly understood. Here we quantify the scale-dependent drivers of latent heat flux (LHF) variability using a year-long, global, fully coupled ocean-atmosphere simulation with kilometer-scale resolution. Annual-mean LHF in eddy-rich regions reaches $\\approx$ 215 W m$^{-2}$, approximately three times larger than in eddy-poor regions. Spectral analyses show that ocean mesoscale [$\\mathcal{O}$(100 km)] and submesoscale [$\\mathcal{O}$(1-10 km)] variability accounts for up to $\\approx$ 80% of the total LHF variance in eddy-rich sectors, but as little as 10% in eddy-poor regions, and increases proportionally with eddy kinetic energy and sea surface temperature (SST) variance. We also find that strong submesoscale SST fronts ($\\approx$ 5 $^\\circ$C over 10 km) force a localized secondary circulation that extends well above the marine boundary layer into the mid-troposphere. Comparison with ERA5 shows that fine ocean scales, responsible for about 17% of the ocean-driven LHF variance in the simulation, are largely unresolved in the reanalysis, leading to a muted atmospheric response lacking any secondary circulation. Despite a strong heterogeneity in LHF variability, the atmospheric dynamics are mostly uniform across the domain, suggesting a non local atmospheric response to ocean forcing. These results highlight the potential for ocean meso- and submesoscales, commonly under-resolved in climate models and reanalysis, to influence Southern Ocean air-sea coupling and atmosphere both locally and remotely."}
{"id": "2602.15271", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.15271", "abs": "https://arxiv.org/abs/2602.15271", "authors": ["Kamila Nurkhametova", "Reid J. Gomillion", "Amit N. Subrahmanya", "Adrian Sandu"], "title": "A Patankar predictor-corrector approach for positivity-preserving time integration", "comment": null, "summary": "Many natural processes, such as chemical reactions and wave dynamics, are modeled as production-destruction (PD) systems that obey positivity and linear conservation laws. Classical time integrators do not guarantee positivity and can produce negative or nonphysical numerical solutions. This paper presents a modular correction strategy that can be applied to implicit Runge-Kutta schemes, in particular SDIRK methods. The strategy combines stage-wise clipping with a ratio-based scaling that enforces invariants and is guaranteed to yield nonnegative, conservative solutions. We provide a theoretical analysis of the corrected schemes and characterize their worst-case order of accuracy relative to the underlying base method. Numerical experiments on stiff ODE systems (Robertson, MAPK, stratospheric chemistry) and a nonlinear PDE (the Korteweg-De Vries equation) demonstrate that the corrected SDIRK methods preserve positivity and invariants without significant loss of accuracy. Importantly, corrections applied only to the final stage are sufficient in practice, while applying them at all stages may distort dynamics in some cases. For explicit Runge-Kutta schemes, the correction maintained positivity but reduced convergence to first order. These results show that the proposed framework provides a simple and effective way to construct positivity-preserving integrators for stiff PD systems."}
{"id": "2602.15526", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15526", "abs": "https://arxiv.org/abs/2602.15526", "authors": ["Ferdinand Geuss", "Orcun Karaca", "Mario Schweizer", "Ognjen Stanojev"], "title": "The role of VSG parameters in shaping small-signal SG dynamics", "comment": null, "summary": "We derive a small-signal transfer function for a system comprising a virtual synchronous generator (VSG), a synchronous generator (SG), and a load, capturing voltage and frequency dynamics. Using this model, we analyze the sensitivity of SG dynamics to VSG parameters, highlighting trade-offs in choosing virtual inertia and governor lag, the limited effect of damper-winding emulation, and several others."}
{"id": "2602.15526", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15526", "abs": "https://arxiv.org/abs/2602.15526", "authors": ["Ferdinand Geuss", "Orcun Karaca", "Mario Schweizer", "Ognjen Stanojev"], "title": "The role of VSG parameters in shaping small-signal SG dynamics", "comment": null, "summary": "We derive a small-signal transfer function for a system comprising a virtual synchronous generator (VSG), a synchronous generator (SG), and a load, capturing voltage and frequency dynamics. Using this model, we analyze the sensitivity of SG dynamics to VSG parameters, highlighting trade-offs in choosing virtual inertia and governor lag, the limited effect of damper-winding emulation, and several others."}
{"id": "2602.15610", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15610", "abs": "https://arxiv.org/abs/2602.15610", "authors": ["M. Horio", "T. Wada", "V. Granata", "R. Fittipaldi", "A. Vecchione", "J. Chang", "I. Matsuda"], "title": "Ambipolar doping-induced surface in-gap state on Mott-insulating Ca$_2$RuO$_4$", "comment": null, "summary": "We report an x-ray photoemission spectroscopy study of Ca$_2$RuO$_4$ surface-dosed with Cs alkali atoms and C$_{60}$ molecules. Due to its small ionization energy (large electron affinity), deposited Cs atoms (C$_{60}$ molecules) are expected to provide a solid surface with electrons (holes). Upon dosing the dopants to Mott-insulating Ca$_2$RuO$_4$, we found a new Ru $3d$ photoemission peak emerging on the lower binding-energy side, suggesting the creation of a core-hole screening channel associated with coherent Ru $4d$ states around the Fermi level. For both the Cs and C$_{60}$ dosing, this change occurred without an appreciable chemical potential jump. The coherent state, therefore, develops within the Mott gap through hybridization with the impurity level of the dopants. The present work highlights the flexibility of Mott-insulator surfaces as a playground for metal-insulator transitions."}
{"id": "2602.15392", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.15392", "abs": "https://arxiv.org/abs/2602.15392", "authors": ["Gavin E. Crooks"], "title": "Dual thermodynamic ensembles, relative entropies, and excess free energy", "comment": null, "summary": "It has long been known that the relative entropy of a non-equilibrium ensemble to the corresponding equilibrium ensemble is the excess free energy. We show that the reverse relative entropy also has a thermodynamic interpretation: it is the excess free energy of a dual ensemble in which the roles of energy and entropy are interchanged."}
{"id": "2602.15125", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15125", "abs": "https://arxiv.org/abs/2602.15125", "authors": ["Kai-Chi Chang", "Arjun Mirani", "Murat Can Sarihan", "Xiang Cheng", "Michelle Harasimowicz", "Patrick Hayden", "Chee Wei Wong"], "title": "GKP-inspired high-dimensional superdense coding with energy-time entanglement", "comment": "37 pages, 12 figures, 1 table", "summary": "Superdense coding, the application of entanglement to boost classical communication capacity, is a cornerstone of quantum communication. In this paper, we propose a high-dimensional superdense coding protocol using energy-time entangled states. These states are biphoton frequency combs, an example of entangled time-frequency Gottesman-Kitaev-Preskill (TFGKP) states or time-frequency grid states. Inspired by GKP codes, our protocol involves discretizing the continuous time and frequency degrees of freedom and encoding information by time-frequency displacements. This approach leverages the inherently large Hilbert space found in quantum frequency combs, with resilience against both temporal and spectral errors. In addition to describing the theoretical structure of the protocol, we propose an experimental implementation using standard telecommunication components, time-resolving single-photon detectors and a frequency beamsplitter. We also analyze the effect of experimental noise and errors on the channel capacity of the protocol. We demonstrate that for realistic experimental parameters, contemporary technologies satisfy the prerequisites for superdense coding with biphoton frequency combs, achieving a transmission rate of approximately 8.91 bits per transmitted photon (equivalent to 481 distinguishable messages with asymptotically vanishing errors). This more than doubles the previously highest transmission rate of 4 bits achieved by the Kwiat-Weinfurter scheme, while also having competitive optical loss. Furthermore, our results beat the rate achievable using a single-photon frequency comb with identical parameters by 4.6 times. Our protocol thus represents an experimentally feasible application of time-frequency grid states to entanglement-assisted communication, contributing to the active fields of continuous-variable and high-dimensional quantum information."}
{"id": "2602.15300", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.15300", "abs": "https://arxiv.org/abs/2602.15300", "authors": ["Jose Antonio Villa"], "title": "Carleman Inequalities for the Heat Equation with Fourier Boundary Conditions: Applications to Null Controllability Problems", "comment": "19 pages", "summary": "In this work, we establish a Carleman inequality for the heat equation with Fourier boundary conditions of the form $\\partial_νy+by=f1_γ$, where the control acts on a small portion $γ$ of the boundary. We apply this inequality to address the null controllability problem with boundary control supported on this small region. An explicit solution to this problem is obtained via a system of coupled parabolic equations. Based on these results, we propose an iterative numerical method to solve the coupled system."}
{"id": "2602.15066", "categories": ["physics.soc-ph", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.15066", "abs": "https://arxiv.org/abs/2602.15066", "authors": ["Chris Ruano", "Shreshth Rajan"], "title": "Social Contagion and Bank Runs: An Agent-Based Model with LLM Depositors", "comment": null, "summary": "Digital banking and online communication have made modern bank runs faster and more networked than the canonical queue-at-the-branch setting. While equilibrium models explain why strategic complementarities generate run risk, they offer limited guidance on how beliefs synchronize and propagate in real time. We develop a process-based agent-based model that makes the information and coordination layer explicit. Banks follow cash-first withdrawal processing with discounted fire-sale liquidation and an endogenous stress index. Depositors are heterogeneous in risk tolerance and in the weight placed on fundamentals versus social information, communicating on a heavy-tailed network calibrated to Twitter activity during March 2023. Depositor behavior is generated by a constrained large language model that maps each agent's information set into a discrete action and an optional post; we validate this policy against laboratory coordination evidence and theoretical benchmarks. Across 4,900 configurations and full LLM simulations, three findings emerge. Within-bank connectivity raises the likelihood and speed of withdrawal cascades holding fundamentals fixed. Cross-bank contagion exhibits a sharp phase transition near spillover rates of 0.10. Depositor overlap and network amplification interact nonlinearly, so channels weak in isolation become powerful in combination. In an SVB, First Republic, and regional bank scenario disciplined by crisis-era data, the model reproduces the observed ordering of failures and predicts substantially higher withdrawal rates among uninsured depositors. The results frame social correlation as a measurable amplifier of run risk alongside balance-sheet fundamentals."}
{"id": "2602.15374", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.15374", "abs": "https://arxiv.org/abs/2602.15374", "authors": ["Cheng-Han Yang", "Xu Shi", "Bhramar Mukherjee"], "title": "Joint Modeling of Longitudinal EHR Data with Shared Random Effects for Informative Visiting and Observation Processes", "comment": "37 pages, 8 figures, 6 tables; with 30-page supplementary material (total 67 pages)", "summary": "Longitudinal electronic health record (EHR) data offer opportunities to study biomarker trajectories; however, association estimates-the primary inferential target-from standard models designed for regular observation times may be biased by a two-stage hierarchical missingness mechanism. The first stage is the visiting process (informative presence), where encounters occur at irregular times driven by patient health status; the second is the observation process (informative observation), where biomarkers are selectively measured during visits. To address these mechanisms, we propose a unified semiparametric joint modeling framework that simultaneously characterizes the visiting, biomarker observation, and longitudinal outcome processes. Central to this framework is a shared subject-specific Gaussian latent variable that captures unmeasured frailty and induces dependence across all components. We develop a three-stage estimation procedure and establish the consistency and asymptotic normality of our estimators. We also introduce a sequential procedure that imputes missing biomarkers prior to adjusting for irregular visiting and examine its performance. Simulation results demonstrate that our method yields unbiased estimates under this mechanism, whereas existing approaches can be substantially biased; notably, methods adjusting only for irregular visiting may exhibit even greater bias than those ignoring both mechanisms. We apply our framework to data from the All of Us Research Program to investigate associations between neighborhood-level socioeconomic status indicators and six blood-based biomarker trajectories, providing a robust tool for outpatient settings where irregular monitoring and selective measurement are prevalent."}
{"id": "2602.15830", "categories": ["physics.ao-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15830", "abs": "https://arxiv.org/abs/2602.15830", "authors": ["Christopher David Roberts"], "title": "Ensemble-size-dependence of deep-learning post-processing methods that minimize an (un)fair score: motivating examples and a proof-of-concept solution", "comment": null, "summary": "Fair scores reward ensemble forecast members that behave like samples from the same distribution as the verifying observations. They are therefore an attractive choice as loss functions to train data-driven ensemble forecasts or post-processing methods when large training ensembles are either unavailable or computationally prohibitive. The adjusted continuous ranked probability score (aCRPS) is fair and unbiased with respect to ensemble size, provided forecast members are exchangeable and interpretable as conditionally independent draws from an underlying predictive distribution. However, distribution-aware post-processing methods that introduce structural dependency between members can violate this assumption, rendering aCRPS unfair. We demonstrate this effect using two approaches designed to minimize the expected aCRPS of a finite ensemble: (1) a linear member-by-member calibration, which couples members through a common dependency on the sample ensemble mean, and (2) a deep-learning method, which couples members via transformer self-attention across the ensemble dimension. In both cases, the results are sensitive to ensemble size and apparent gains in aCRPS can correspond to systematic unreliability characterized by over-dispersion. We introduce trajectory transformers as a proof-of-concept that ensemble-size independence can be achieved. This approach is an adaptation of the Post-processing Ensembles with Transformers (PoET) framework and applies self-attention over lead time while preserving the conditional independence required by aCRPS. When applied to weekly mean $T_{2m}$ forecasts from the ECMWF subseasonal forecasting system, this approach successfully reduces systematic model biases whilst also improving or maintaining forecast reliability regardless of the ensemble size used in training (3 vs 9 members) or real-time forecasts (9 vs 100 members)."}
{"id": "2602.15399", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.15399", "abs": "https://arxiv.org/abs/2602.15399", "authors": ["A. Hannukainen", "N. Hyvönen", "V. Toresen"], "title": "Total variation regularization with reduced basis in electrical impedance tomography", "comment": "24 pages, 6 figures", "summary": "This work considers using reduced basis techniques in connection to (smoothened) total variation regularization in electrical impedance tomography, but analogous ideas can also be used for other inverse elliptic boundary value problems. It is demonstrated that resorting to reduced bases can speed up a reconstruction algorithm based on combining the lagged diffusivity algorithm with sequential linearizations and preconditioned LSQR iteration without any significant loss of reconstruction quality or of the edge-enhancing nature of total variation regularization. The ideas are numerically tested in three dimensions on unstructured finite element meshes with both simulated and experimental data, resulting in online reconstruction times of only a few seconds on a standard laptop computer."}
{"id": "2602.15596", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15596", "abs": "https://arxiv.org/abs/2602.15596", "authors": ["Liang Wu", "Yunhong Che", "Bo Yang", "Kangyu Lin", "Ján Drgoňa"], "title": "Time-Certified and Efficient NMPC via Koopman Operator", "comment": "6 pages,submitted to IFAC WC 2026", "summary": "Certifying and accelerating execution times of nonlinear model predictive control (NMPC) implementations are two core requirements. Execution-time certificate guarantees that the NMPC controller returns a solution before the next sampling time, and achieving faster worst-case and average execution times further enables its use in a wider set of applications. However, NMPC produces a nonlinear program (NLP) for which it is challenging to derive its execution time certificates. Our previous works, \\citep{wu2025direct,wu2025time} provide data-independent execution time certificates (certified number of iterations) for box-constrained quadratic programs (BoxQP). To apply the time-certified BoxQP algorithm \\citep{wu2025time} for state-input constrained NMPC, this paper i) learns a linear model via Koopman operator; ii) proposes a dynamic-relaxation construction approach yields a structured BoxQP rather than a general QP; iii) exploits the structure of BoxQP, where the dimension of the linear system solved in each iteration is reduced from $5N(n_u+n_x)$ to $Nn_u$ (where $n_u, n_x, N$ denote the number of inputs, states, and length of prediction horizon), yielding substantial speedups (when $n_x \\gg n_u$, as in PDE control)."}
{"id": "2602.15596", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15596", "abs": "https://arxiv.org/abs/2602.15596", "authors": ["Liang Wu", "Yunhong Che", "Bo Yang", "Kangyu Lin", "Ján Drgoňa"], "title": "Time-Certified and Efficient NMPC via Koopman Operator", "comment": "6 pages,submitted to IFAC WC 2026", "summary": "Certifying and accelerating execution times of nonlinear model predictive control (NMPC) implementations are two core requirements. Execution-time certificate guarantees that the NMPC controller returns a solution before the next sampling time, and achieving faster worst-case and average execution times further enables its use in a wider set of applications. However, NMPC produces a nonlinear program (NLP) for which it is challenging to derive its execution time certificates. Our previous works, \\citep{wu2025direct,wu2025time} provide data-independent execution time certificates (certified number of iterations) for box-constrained quadratic programs (BoxQP). To apply the time-certified BoxQP algorithm \\citep{wu2025time} for state-input constrained NMPC, this paper i) learns a linear model via Koopman operator; ii) proposes a dynamic-relaxation construction approach yields a structured BoxQP rather than a general QP; iii) exploits the structure of BoxQP, where the dimension of the linear system solved in each iteration is reduced from $5N(n_u+n_x)$ to $Nn_u$ (where $n_u, n_x, N$ denote the number of inputs, states, and length of prediction horizon), yielding substantial speedups (when $n_x \\gg n_u$, as in PDE control)."}
{"id": "2602.15624", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15624", "abs": "https://arxiv.org/abs/2602.15624", "authors": ["Wafa Makhlouf", "Bruno Senjean", "Emmanuel Fromager"], "title": "Generalized local potential functional embedding theory of localized orbitals", "comment": null, "summary": "In this work we introduce a generalized flavor, in the sense of generalized Kohn-Sham density functional theory (gKS-DFT), of the recently derived local potential functional embedding theory (LPFET) [J. Chem. Theory Comput. 2025, 21, 20, 10293], where the in-principle exact formalism of DFT is combined with that of density matrix embedding theory (DMET). In generalized LPFET (gLPFET), the embedding clusters are designed from a full-size gKS system where the (in-principle non-local) Hartree-Fock exchange potential is combined with a local (in the localized orbital representation) correlation potential. The latter is optimized self-consistently such that gKS and local embedding cluster's densities match. Unlike in DMET, which uses the same (global) chemical potential value in all clusters, each embedded orbital has its own chemical potential in gLPFET. We show analytically that, when electron correlation is strongly local, the latter potential becomes a simple functional of the correlation potential. Numerical calculations on model systems confirm the high accuracy of gLPFET in this regime, in contrast to DMET. Moreover, we show that gLPFET completely fixes the flaw of LPFET in weaker correlation regimes, through its appropriate description of the Hartree-exchange potential."}
{"id": "2602.15494", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.15494", "abs": "https://arxiv.org/abs/2602.15494", "authors": ["S. Giordano", "R. Blossey"], "title": "Generalized Geometric Brownian motion and the Infinite Ergodicity concept", "comment": "Accepted author manuscript for the themed issue \"Ergodicity and ergodicity breaking in the sciences\" in the Philosophical Transactions A", "summary": "We investigate stochastic processes that generalize geometric Brownian motion, focusing on cases where the standard invariant measure, i.e. the solution of the stationary Fokker-Planck equation does not necessarily exist. We demonstrate that the existence of such a measure depends sensitively on the structure of the drift and diffusion terms, as well as on the chosen discretization scheme of the underlying stochastic dynamics. To ground our discussion, we draw motivation from phenomenological models in statistical theories of turbulence, where geometric Brownian motion serves as a classical example. To address situations where the standard invariant measure fails to exist, we heuristically explore the concept of infinite ergodicity, a notion recently introduced in the context of statistical physics for drift-diffusion stochastic processes."}
{"id": "2602.15134", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15134", "abs": "https://arxiv.org/abs/2602.15134", "authors": ["Juanca Carrasco-Martinez"], "title": "Quantum Theory for General Observers", "comment": null, "summary": "The principle of relativity is extended to accommodate observers with quantum properties. This results in a new theory that introduces relative quantization rules and novel uncertainty relations, while also elucidating some interpretational problems present in the current formulation of quantum mechanics."}
{"id": "2602.15365", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15365", "abs": "https://arxiv.org/abs/2602.15365", "authors": ["Omar Bennouna", "Amine Bennouna", "Saurabh Amin", "Asuman Ozdaglar"], "title": "Data Informativeness in Linear Optimization under Uncertainty", "comment": "arXiv admin note: text overlap with arXiv:2505.21692", "summary": "We study the problem of determining what data is required to solve a decision-making task when only partial information about the state of the world is available. Focusing on linear programs, we introduce a decision-focused notion of data informativeness that formalizes when a data set is sufficient to recover the optimal decision. Our notion abstracts away the notion of estimators (how data is used): it depends solely on the structure of the optimization task and the uncertainty. Our main result provides a geometric characterization of data sufficiency: a data set is sufficient if and only if, together with prior knowledge, it captures all cost directions that can change the optimal solution, given the task structure and the uncertainty set. Building on our characterization, we develop a tractable algorithm to determine minimal sufficient data sets under general data collection constraints. Taken together, our work introduces a principled framework for task-aware data collection. We demonstrate the approach in two applications: selecting where to conduct field experiments to inform infrastructure design and choosing which candidates to interview in order to make an optimal hiring decision. Our results illustrate that small, carefully selected data sets often suffice to determine the optimal decisions."}
{"id": "2602.15069", "categories": ["physics.soc-ph", "cs.CY", "econ.GN"], "pdf": "https://arxiv.org/pdf/2602.15069", "abs": "https://arxiv.org/abs/2602.15069", "authors": ["Geoff Boeing", "Yuquan Zhou"], "title": "Travel Time Prediction from Sparse Open Data", "comment": null, "summary": "Travel time prediction is central to transport geography and planning's accessibility analyses, sustainable transportation infrastructure provision, and active transportation interventions. However, calculating accurate travel times, especially for driving, requires either extensive technical capacity and bespoke data, or resources like the Google Maps API that quickly become prohibitively expensive to analyze thousands or millions of trips necessary for metropolitan-scale analyses. Such obstacles particularly challenge less-resourced researchers, practitioners, and community advocates. This article argues that a middle-ground is needed to provide reasonably accurate travel time predictions without extensive data or computing requirements. It introduces a free, open-source minimally-congested driving time prediction model with minimal cost, data, and computational requirements. It trains and tests this model using the Los Angeles, California urban area as a case study by calculating naive travel times from open data then developing a random forest model to predict travel times as a function of those naive times plus open data on turns and traffic controls. Validation shows that this interpretable machine learning method offers a superior middle-ground technique that balances reasonable accuracy with minimal resource requirements."}
{"id": "2602.15387", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.15387", "abs": "https://arxiv.org/abs/2602.15387", "authors": ["Durba Bhattacharya", "Sourabh Bhattacharya"], "title": "Bayesian Nonparametrics for Gene-Gene and Gene-Environment Interactions in Case-Control Studies: A Synthesis and Extension", "comment": "Feedback welcome", "summary": "Gene-gene and gene-environment interactions are widely believed to play significant roles in explaining the variability of complex traits. While substantial research exists in this area, a comprehensive statistical framework that addresses multiple sources of uncertainty simultaneously remains lacking. In this article, we synthesize and propose extension of a novel class of Bayesian nonparametric approaches that account for interactions among genes, loci, and environmental factors while accommodating uncertainty about population substructure. Our contribution is threefold: (1) We provide a unified exposition of hierarchical Bayesian models driven by Dirichlet processes for genetic interactions, clarifying their conceptual advantages over traditional regression approaches; (2) We shed light on new computational strategies that combine transformation-based MCMC with parallel processing for scalable inference; and (3) We present enhanced hypothesis testing procedures for identifying disease-predisposing loci.Through applications to myocardial infarction data, we demonstrate how these methods offer biological insights not readily obtainable from standard approaches. Our synthesis highlights the advantages of Bayesian nonparametric thinking in genetic epidemiology while providing practical guidance for implementation."}
{"id": "2602.15445", "categories": ["math.NA", "math.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.15445", "abs": "https://arxiv.org/abs/2602.15445", "authors": ["Attila Karsai", "Philipp Schulze"], "title": "A discrete gradient scheme for preserving QSR-dissipativity", "comment": null, "summary": "The notion of dissipative dynamical systems provides a formal description of processes that cannot generate energy internally. For these systems, changes in energy can only occur due to an external energy supply or dissipation effects. Unfortunately, dissipative properties tend to deteriorate in numerical computations, especially in nonlinear systems. Discrete gradient methods can help mitigate this problem. In this paper, we present a class of structure-preserving time discretization schemes based on discrete gradients for a special class of systems that are dissipative with respect to a quadratic supply rate."}
{"id": "2602.15370", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15370", "abs": "https://arxiv.org/abs/2602.15370", "authors": ["Hannah Michalska", "Miguel Torres-Torriti"], "title": "A Geometric Approach to Feedback Stabilization of Nonlinear Systems with Drift", "comment": "Accepted in Systems & Control Letters (Apr. 2003), vol. 50, n. 4, pp. 303-318 (c) 2003 Elsevier Science", "summary": "The paper presents an approach to the construction of stabilizing feedback for strongly nonlinear systems. The class of systems of interest includes systems with drift which are affine in control and which cannot be stabilized by continuous state feedback. The approach is independent of the selection of a Lyapunov type function, but requires the solution of a nonlinear programming 'satisficing problem' stated in terms of the logarithmic coordinates of flows. As opposed to other approaches, point-to-point steering is not required to achieve asymptotic stability. Instead, the flow of the controlled system is required to intersect periodically a certain reachable set in the space of the logarithmic coordinates."}
{"id": "2602.15370", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15370", "abs": "https://arxiv.org/abs/2602.15370", "authors": ["Hannah Michalska", "Miguel Torres-Torriti"], "title": "A Geometric Approach to Feedback Stabilization of Nonlinear Systems with Drift", "comment": "Accepted in Systems & Control Letters (Apr. 2003), vol. 50, n. 4, pp. 303-318 (c) 2003 Elsevier Science", "summary": "The paper presents an approach to the construction of stabilizing feedback for strongly nonlinear systems. The class of systems of interest includes systems with drift which are affine in control and which cannot be stabilized by continuous state feedback. The approach is independent of the selection of a Lyapunov type function, but requires the solution of a nonlinear programming 'satisficing problem' stated in terms of the logarithmic coordinates of flows. As opposed to other approaches, point-to-point steering is not required to achieve asymptotic stability. Instead, the flow of the controlled system is required to intersect periodically a certain reachable set in the space of the logarithmic coordinates."}
{"id": "2602.15662", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15662", "abs": "https://arxiv.org/abs/2602.15662", "authors": ["Lasse Gresista", "Daniel Lozano-Gómez", "Matthias Vojta", "Simon Trebst", "Yasir Iqbal"], "title": "Quantum Coulomb Liquids of Different Rank in the Breathing Pyrochlore Antiferromagnet", "comment": "9 pages, 6 figures and Supplemental Material", "summary": "Emergent gauge fields and Coulomb liquids have long been central to the physics of frustrated pyrochlore magnets, yet their realization beyond conventional, i.e. rank-1 $U(1)$, spin ice and into fully quantum higher-rank regimes has remained elusive. Here we provide a controlled demonstration of this physics in the spin-$\\tfrac{1}{2}$ quantum Heisenberg antiferromagnet on the breathing pyrochlore lattice with symmetry-allowed Dzyaloshinskii--Moriya interactions, using the pseudofermion functional renormalization group. We show that tuning the breathing asymmetry stabilizes extended quantum analogues of both rank-1 and rank-2 $U(1)$ Coulomb liquids within a single microscopic model, directly distinguished by their characteristic pinch-point morphologies in momentum space. This provides the first controlled quantum realization in three dimensions where gauge theories of different rank emerge within a single microscopic spin Hamiltonian. In addition, quantum fluctuations qualitatively reshape the classical nearest-neighbor atlas of phases, causing an incommensurate spiral instability and an extended quantum-disordered regime without dipolar order, both absent from the classical model. Our results establish the breathing pyrochlore as a timely and experimentally relevant platform where higher-rank gauge constraints, conventional magnetic order, and fluctuation-driven quantum phases compete on equal footing, opening a direct route to diagnosing emergent gauge structure in three-dimensional quantum magnets."}
{"id": "2602.15495", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.15495", "abs": "https://arxiv.org/abs/2602.15495", "authors": ["Anagha V K", "Apoorva Nagar"], "title": "Ising Model with Power Law Resetting", "comment": null, "summary": "We investigate the nonequilibrium dynamics of the nearest-neighbour Ising model subjected to stochastic resetting, where the system is intermittently returned to an initial configuration with magnetisation $m_0$, with the inter-reset times drawn from the power law distribution $ατ_0^α/ τ^{α+1}$. The heavy-tailed resets generate magnetisation distributions that differ significantly from both equilibrium dynamics and the previously studied Ising model with exponentially distributed reset times. In two dimensions, for $T > T_C$, we find a quasi-ferro state for all $α$, marked by a double-peaked distribution that diverges at $m=0$ and $m=m_0$; no steady state exists for $α< 1$, while a stationary state emerges for $α> 1$. For $T < T_C$, power law resetting produces two distinct regimes separated by a crossover exponent $α^* = 1-c$: a single-peak ferromagnetic phase localised at $m_{eq}$ for $α< α^*$, and a dual-peak ferromagnetic phase with divergences at $m_{eq}$ and $m_0$ for $α> α^*$. Analytic results in one and two dimensions, supported by simulations, yield a rich phase diagram in the $(T,α)$ plane and reveal how heavy-tailed resetting generates nonequilibrium phases very different from those seen in the case of exponential resetting."}
{"id": "2602.15146", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15146", "abs": "https://arxiv.org/abs/2602.15146", "authors": ["Lukas Theissinger", "Thore Gerlach", "David Berghaus", "Christian Bauckhage"], "title": "Beyond Reinforcement Learning: Fast and Scalable Quantum Circuit Synthesis", "comment": null, "summary": "Quantum unitary synthesis addresses the problem of translating abstract quantum algorithms into sequences of hardware-executable quantum gates. Solving this task exactly is infeasible in general due to the exponential growth of the underlying combinatorial search space. Existing approaches suffer from misaligned optimization objectives, substantial training costs and limited generalization across different qubit counts. We mitigate these limitations by using supervised learning to approximate the minimum description length of residual unitaries and combining this estimate with stochastic beam search to identify near optimal gate sequences. Our method relies on a lightweight model with zero-shot generalization, substantially reducing training overhead compared to prior baselines. Across multiple benchmarks, we achieve faster wall-clock synthesis times while exceeding state-of-the-art methods in terms of success rate for complex circuits."}
{"id": "2602.15370", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.15370", "abs": "https://arxiv.org/abs/2602.15370", "authors": ["Hannah Michalska", "Miguel Torres-Torriti"], "title": "A Geometric Approach to Feedback Stabilization of Nonlinear Systems with Drift", "comment": "Accepted in Systems & Control Letters (Apr. 2003), vol. 50, n. 4, pp. 303-318 (c) 2003 Elsevier Science", "summary": "The paper presents an approach to the construction of stabilizing feedback for strongly nonlinear systems. The class of systems of interest includes systems with drift which are affine in control and which cannot be stabilized by continuous state feedback. The approach is independent of the selection of a Lyapunov type function, but requires the solution of a nonlinear programming 'satisficing problem' stated in terms of the logarithmic coordinates of flows. As opposed to other approaches, point-to-point steering is not required to achieve asymptotic stability. Instead, the flow of the controlled system is required to intersect periodically a certain reachable set in the space of the logarithmic coordinates."}
{"id": "2602.15256", "categories": ["physics.soc-ph", "math-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2602.15256", "abs": "https://arxiv.org/abs/2602.15256", "authors": ["Felipe S. Abril-Bermúdez", "David N. Fisher", "Jean-Baptiste Gramain", "Francisco J. Pérez-Reche"], "title": "Environment-Driven Emergence of Higher-Order Collective Behavior", "comment": "5 pages, 4 figures", "summary": "Collective behavior is commonly attributed to direct interactions among system components. Using a minimal stochastic model, we show that higher-order collective structure can instead emerge from shared stochastic environments, even in the absence of interactions. Quantified via the O-information, environmental fluctuations induce both redundant and synergistic dependencies, with the latter occupying larger regions of the correlation space. We establish a no-go theorem showing that time-independent coupling between the system variables and a shared stochastic environment rules out synergistic higher-order behavior. Crucially, this constraint can be overcome dynamically: transitions between redundancy and synergy arise from time-dependent environmental coupling or from the nontrivial interplay between shared environments and direct interactions. Together, these results identify environmental mediation as a distinct mechanism of higher-order collective organization beyond the conventional interaction-centric paradigm."}
{"id": "2602.15390", "categories": ["stat.ME", "math.NA", "math.NT"], "pdf": "https://arxiv.org/pdf/2602.15390", "abs": "https://arxiv.org/abs/2602.15390", "authors": ["Naoki Sakai", "Takashi Goda"], "title": "Space-filling lattice designs for computer experiments", "comment": "24 pages, 5 figures", "summary": "This paper investigates the construction of space-filling designs for computer experiments. The space-filling property is characterized by the covering and separation radii of a design, which are integrated through the unified criterion of quasi-uniformity. We focus on a special class of designs, known as quasi-Monte Carlo (QMC) lattice point sets, and propose two construction algorithms. The first algorithm generates rank-1 lattice point sets as an approximation of quasi-uniform Kronecker sequences, where the generating vector is determined explicitly. As a byproduct of our analysis, we prove that this explicit point set achieves an isotropic discrepancy of $O(N^{-1/d})$. The second algorithm utilizes Korobov lattice point sets, employing the Lenstra--Lenstra--Lovász (LLL) basis reduction algorithm to identify the generating vector that ensures quasi-uniformity. Numerical experiments are provided to validate our theoretical claims regarding quasi-uniformity. Furthermore, we conduct empirical comparisons between various QMC point sets in the context of Gaussian process regression, showcasing the efficacy of the proposed designs for computer experiments."}
{"id": "2602.15517", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.15517", "abs": "https://arxiv.org/abs/2602.15517", "authors": ["Fernando Henriquez", "Matthias Schlottbom"], "title": "A Model Order Reduction Method for Seismic Applications Using the Laplace Transform", "comment": null, "summary": "We devise and analyze a reduced basis model order reduction (MOR) strategy for an abstract wave problem with vanishing initial conditions and a source term given by the product of a temporal Ricker wavelet and a spatial profile. Such wave problems comprise the acoustic and elastic wave equations, with applications in seismic modeling. Motivated by recent Laplace-domain MOR methodologies, we construct reduced bases that approximate the time-domain solution with exponential accuracy. We prove convergence bounds that are explicit and robust with respect to the parameters controlling the Ricker wavelet's shape and width and identify an intrinsic accuracy limit dictated by the wavelet's value at the initial time. In particular, the resulting error bound is independent of the underlying Galerkin discretization space and yields computable criteria for the regime in which exponential convergence is observed."}
{"id": "2602.15568", "categories": ["stat.ME", "cs.LG", "eess.SY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.15568", "abs": "https://arxiv.org/abs/2602.15568", "authors": ["Algo Carè", "Marco C. Campi", "Simone Garatti"], "title": "Scenario Approach with Post-Design Certification of User-Specified Properties", "comment": null, "summary": "The scenario approach is an established data-driven design framework that comes equipped with a powerful theory linking design complexity to generalization properties. In this approach, data are simultaneously used both for design and for certifying the design's reliability, without resorting to a separate test dataset. This paper takes a step further by guaranteeing additional properties, useful in post-design usage but not considered during the design phase. To this end, we introduce a two-level framework of appropriateness: baseline appropriateness, which guides the design process, and post-design appropriateness, which serves as a criterion for a posteriori evaluation. We provide distribution-free upper bounds on the risk of failing to meet the post-design appropriateness; these bounds are computable without using any additional test data. Under additional assumptions, lower bounds are also derived. As part of an effort to demonstrate the usefulness of the proposed methodology, the paper presents two practical examples in H2 and pole-placement problems. Moreover, a method is provided to infer comprehensive distributional knowledge of relevant performance indexes from the available dataset."}
{"id": "2602.15568", "categories": ["stat.ME", "cs.LG", "eess.SY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.15568", "abs": "https://arxiv.org/abs/2602.15568", "authors": ["Algo Carè", "Marco C. Campi", "Simone Garatti"], "title": "Scenario Approach with Post-Design Certification of User-Specified Properties", "comment": null, "summary": "The scenario approach is an established data-driven design framework that comes equipped with a powerful theory linking design complexity to generalization properties. In this approach, data are simultaneously used both for design and for certifying the design's reliability, without resorting to a separate test dataset. This paper takes a step further by guaranteeing additional properties, useful in post-design usage but not considered during the design phase. To this end, we introduce a two-level framework of appropriateness: baseline appropriateness, which guides the design process, and post-design appropriateness, which serves as a criterion for a posteriori evaluation. We provide distribution-free upper bounds on the risk of failing to meet the post-design appropriateness; these bounds are computable without using any additional test data. Under additional assumptions, lower bounds are also derived. As part of an effort to demonstrate the usefulness of the proposed methodology, the paper presents two practical examples in H2 and pole-placement problems. Moreover, a method is provided to infer comprehensive distributional knowledge of relevant performance indexes from the available dataset."}
{"id": "2602.15774", "categories": ["cond-mat.str-el", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.15774", "abs": "https://arxiv.org/abs/2602.15774", "authors": ["D. Jones", "A. Weh", "A. Östlin", "D. Braak", "T. Kopp", "P. Seiler", "U. Eckern", "L. Chioncel"], "title": "Correlated electronic states at a ferromagnetic oxide interface", "comment": null, "summary": "We propose a minimal tight-binding model for the electronic interface layer of the LaAlO$_3$/SrTiO$_3$ heterostructure with oxygen vacancies. In this model, the effective carriers are subject to oxygen vacancy induced magnetic impurities. Both the effects of random on-site potentials and Zeeman-like exchange interactions between correlated carriers and magnetic impurities are taken into account. By applying the combined coherent potential approximation (CPA) and dynamical mean-field theory (DMFT) for a ferromagnetic state, we uncover a disordered Fermi-liquid regime for the majority-spins and a low energy scale which controls the transport of the minority-spin carriers, both induced by the magnetic impurities."}
{"id": "2602.15512", "categories": ["cond-mat.stat-mech", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.15512", "abs": "https://arxiv.org/abs/2602.15512", "authors": ["Stefano Lepri", "Roberto Livi", "Antonio Politi"], "title": "Anomalous transport in the Fermi-Pasta-Ulam-Tsingou model: a review and open problems", "comment": "Contribution for the Special Issue on FPUT, in Journal of Statistical Physics", "summary": "This review provides an up-to-date account of energy transport in Fermi-Pasta-Ulam-Tsingou (FPUT) chains, a key testbed for nonequilibrium statistical physics. We discuss the transition from the historical puzzle of thermalization to the discovery of anomalous heat transport, where the effective thermal conductivity $κ$ diverges with system size $L$ as $κ\\propto L^δ$. The article clarifies the distinction between two universality classes: the FPUT-$αβ$ model, characterized by $δ= 1/3$ and linked to Kardar-Parisi-Zhang (KPZ) physics, and the symmetric FPUT-$β$ model, where numerical and theoretical evidence support $δ= 2/5$. We investigate how finite-size effects - unavoidably induced by the thermostatting protocols - can disguise the asymptotic scaling. Additionally, we analyze the role of conservative noise in preserving hydrodynamic properties and examine how proximity to integrable limits leads to long-lived quasi-particles and, thereby, to diffusive regimes over intermediate spatial scales."}
{"id": "2602.15168", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15168", "abs": "https://arxiv.org/abs/2602.15168", "authors": ["David Gunn", "Georgios Styliaris", "Barbara Kraus", "Tristan Kraft"], "title": "Phases of matrix-product states with symmetries and measurements: Finite nilpotent groups", "comment": "26 pages, 5 figures", "summary": "We classify phases of one-dimensional matrix-product states (MPS) under symmetric circuits augmented with symmetric measurements and feedforward. Building on the framework introduced in Gunn et al., Phys. Rev. B 111, 115110 (2025), we extend the analysis from abelian and class-2 nilpotent groups to all finite nilpotent groups. For any such symmetry group $G$, we construct explicit protocols composed of $G$-symmetric circuits and measurements with feedforward that transform symmetry-protected topological (SPT) states into the trivial phase and vice versa using a finite number of measurement rounds determined by the nilpotency class of $G$. Although these transformations are approximate, we prove that their success probability converges to unity in the thermodynamic limit, establishing asymptotically deterministic equivalence. Consequently, all SPT phases protected by finite nilpotent groups collapse to a single phase once symmetric measurements and feedforward are allowed. We further show that the same holds for non-normal MPS with long-range correlations, including GHZ-type states. The central technical ingredient is a hierarchical structure of irreducible representations of nilpotent groups, which enables a recursive reduction of non-abelian components to abelian ones. Our results demonstrate that symmetric measurements lead to a complete collapse of both symmetry-protected and non-normal MPS phases for all finite nilpotent symmetry groups."}
{"id": "2602.15557", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15557", "abs": "https://arxiv.org/abs/2602.15557", "authors": ["Eyal Neuman", "Sturmius Tuschmann"], "title": "Stochastic Games on Large Sparse Graphs", "comment": "37 pages, 2 figures", "summary": "We introduce a framework for stochastic games on large sparse graphs, covering continuous-time and discrete-time dynamic games as well as static games. Players are indexed by the vertices of simple, locally finite graphs, allowing both finite and countably infinite populations, with asymptotics described through local weak convergence of marked graphs. The framework allows path-dependent utility functionals that may be heterogeneous across players. Under a contraction condition, we prove existence and uniqueness of Nash equilibria and establish exponential decay of correlations with graph distance. We further show that global equilibria can be approximated by truncated local games, and can even be reconstructed exactly on subgraphs given information on their boundary. Finally, we prove convergence of Nash equilibria along locally weakly convergent graph sequences, including sequences sampled from hyperfinite unimodular random graphs."}
{"id": "2602.15470", "categories": ["physics.soc-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15470", "abs": "https://arxiv.org/abs/2602.15470", "authors": ["Elifnaz Kancan"], "title": "The Skeletal Trap: Mapping Spatial Inequality and Ghost Stops in Ankara's Transit Network", "comment": "13 pages, 12 figures. Spatial analysis of Ankara transit network using anomaly detection and grid-based modeling", "summary": "Ankara's public transport crisis is commonly framed as a shortage of buses or operational inefficiency. This study argues that the problem is fundamentally morphological and structural. The city's leapfrog urban expansion has produced fragmented peripheral clusters disconnected from a rigid, center-oriented bus network. As a result, demand remains intensely concentrated along the Kizilay-Ulus axis and western corridors, while peripheral districts experience either chronic under-service or enforced transfer dependency. The deficiency is therefore not merely quantitative but rooted in the misalignment between urban macroform and network architecture. The empirical analysis draws on a 173-day operational dataset derived from route-level passenger and trip reports published by EGO under the former \"Transparent Ankara\" initiative. To overcome the absence of stop-level geospatial data, a Connectivity-Based Weighted Distribution Model reallocates passenger volumes to 1 km x 1 km grid cells using network centrality. The findings reveal persistent center-periphery asymmetries, structural bottlenecks, and spatially embedded accessibility inequalities."}
{"id": "2602.15496", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.15496", "abs": "https://arxiv.org/abs/2602.15496", "authors": ["Céline Cunen", "Nils Lid Hjort"], "title": "Confidence Distributions for FIC scores", "comment": "26 pages, 9 figures, 2020 version, later published in essentially this form, Econometrics 2020, volume 8, number27, www.mdpi.com/2225-1146/8/3/27", "summary": "When using the Focused Information Criterion (FIC) for assessing and ranking candidate models with respect to how well they do for a given estimation task, it is customary to produce a so-called FIC plot. This plot has the different point estimates along the y-axis and the root-FIC scores on the x-axis, these being the estimated root-mean-square scores. In this paper we address the estimation uncertainty involved in each of the points of such a FIC plot. This needs careful assessment of each of the estimators from the candidate models, taking also modelling bias into account, along with the relative precision of the associated estimated mean squared error quantities. We use confidence distributions for these endeavours. This leads to fruitful CD-FIC plots, helping the statistician to judge to what extent the seemingly best models really are better than other models, etc. These efforts also lead to two further developments. The first is a new tool for model selection, which we call the quantile FIC, which helps overcome certain difficulties associated with the usual FIC procedures, related to somewhat arbitrary schemes for handling estimated squared biases. A particular case is the median-FIC. The second development is to form model averaged estimators with fruitful weights determined by the relative sizes of the median- and quantile-FIC scores. And Mrs. Jones is pregnant."}
{"id": "2602.15130", "categories": ["physics.comp-ph", "math.NA", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2602.15130", "abs": "https://arxiv.org/abs/2602.15130", "authors": ["Brian A. Freno", "William J. McDoniel", "Christopher H. Moore", "Neil R. Matula"], "title": "Code-Verification Techniques for Particle-in-Cell Simulations with Direct Simulation Monte Carlo Collisions", "comment": null, "summary": "Particle-in-cell methods with stochastic collision models are commonly used to simulate collisional plasma dynamics, with applications ranging from hypersonic flight to semiconductor manufacturing. Code verification of such methods is challenging due to the interaction between the spatial- and temporal-discretization errors, the statistical sampling noise, and the stochastic nature of the collision algorithm. In this paper, we introduce our code-verification approaches to apply the method of manufactured solutions to plasma dynamics, and we derive expected convergence rates for the different sources of discretization and statistical error. For the particles, we incorporate the method of manufactured solutions into the equations of motion. We manufacture the particle distribution function and inversely query the cumulative distribution function to obtain known particle positions and velocities at each time step. In doing so, we avoid modifying the particle weights, eliminating risks from potentially negative weights or modifications to weight-dependent collision algorithms. For the collision algorithm, we average independent outcomes at each time step and we derive a corresponding manufactured source term for the velocity change for each particle. By having known solutions for the particle positions and velocities, we are able to compute the error in these quantities directly instead of attempting to compute differences in distribution functions. These approaches are equally valid for particle-in-cell simulations with Monte Carlo collisions and direct simulation Monte Carlo simulations of neutral gas flows. We demonstrate the effectiveness of our approaches in three dimensions for different couplings between the particles and field, with and without binary elastic collisions, and with and without coding errors."}
{"id": "2602.15524", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15524", "abs": "https://arxiv.org/abs/2602.15524", "authors": ["Brendan Rhyno", "Bastien Lapierre", "Smitha Vishveshwara", "Khadijeh Najafi", "Ramasubramanian Chitra"], "title": "Observing quantum many-body dynamics in emergent curved spacetime using programmable quantum processors", "comment": "17 pages, 11 figures", "summary": "We digitally simulate quantum many-body dynamics in emergent curved backgrounds using 80 superconducting qubits on IBM Heron processors. By engineering spatially varying couplings in the spin-$\\frac12$ XXZ chain, consistent with the low energy description of the model in terms of an inhomogeneous Tomonaga-Luttinger liquid, we realize excitations that follow geodesics of an effective metric inherited from the underlying spatial deformation. Following quenches from Néel and few-spin-flip states, we observe curved light-cone propagation, horizon-induced freezing in the local magnetization, and position-dependent oscillation frequencies set by the engineered spatial deformation. Despite strong spatial inhomogeneity, unequal-time correlators reveal ballistic quasiparticle propagation in the spin chain. These results establish large-scale digital quantum processors as a flexible platform for detailed and controlled exploration of many-body dynamics in tunable and synthetic curved spacetimes."}
{"id": "2602.15627", "categories": ["cond-mat.stat-mech", "physics.bio-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.15627", "abs": "https://arxiv.org/abs/2602.15627", "authors": ["Denis S. Grebenkov", "Ralf Metzler", "Gleb Oshanin"], "title": "Fastest first-passage time for multiple searchers with finite speed", "comment": null, "summary": "We study analytically and numerically the mean fastest first-passage time (fFPT) to an immobile target for an ensemble of $N$ independent finite-speed random searchers driven by dichotomous noise and described by the telegrapher's equation. In stark contrast to the well-studied case of Brownian particles -- for which the mean fFPT vanishes logarithmically with $N$ -- we uncover that the mean fFPT is bounded from below by the minimal ballistic travel time, with an exponentially fast convergence to this bound as $N \\to \\infty$. This behavior reveals a dramatic efficiency advantage of physically realistic, finite-speed searchers over Brownian ones and illustrates how diffusive macroscopic models may be conceptually misleading in predicting the short-time behavior of a physical system. We extend our analysis to anomalous diffusion generated by Riemann-Liouville-type dichotomous noises and find that target detection is more efficient in the superdiffusive regime, followed by normal and then subdiffusive regimes, in agreement with physical intuition and contrary to earlier predictions."}
{"id": "2602.15180", "categories": ["quant-ph", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.15180", "abs": "https://arxiv.org/abs/2602.15180", "authors": ["Vishnu Iyer", "Siddhartha Jain", "Stephen Jordan", "Rolando Somma"], "title": "Efficient quantum circuits for high-dimensional representations of SU(n) and Ramanujan quantum expanders", "comment": "39 pages, 2 figures", "summary": "We present efficient quantum circuits that implement high-dimensional unitary irreducible representations (irreps) of $SU(n)$, where $n \\ge 2$ is constant. For dimension $N$ and error $ε$, the number of quantum gates in our circuits is polynomial in $\\log(N)$ and $\\log(1/ε)$. Our construction relies on the Jordan-Schwinger representation, which allows us to realize irreps of $SU(n)$ in the Hilbert space of $n$ quantum harmonic oscillators. Together with a recent efficient quantum Hermite transform, which allows us to map the computational basis states to the eigenstates of the quantum harmonic oscillator, this allows us to implement these irreps efficiently. Our quantum circuits can be used to construct explicit Ramanujan quantum expanders, a longstanding open problem. They can also be used to fast-forward the evolution of certain quantum systems."}
{"id": "2602.15594", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15594", "abs": "https://arxiv.org/abs/2602.15594", "authors": ["Christian Artigues", "Pascale Bendotti", "Alexandre Heintzmann", "Sandra Ulrich Ngueveu", "Cécile Rottner"], "title": "BORWin: Exact algorithm based on a Bi-Objective Relaxation for Window-constrained problems", "comment": null, "summary": "A mixed integer maximization problem involving several additional constraints defined with both a lower and an upper bound is considered. It is assumed that one of such constraints is more restrictive than the others. As it can be seen as a resource window constraint, it defines the so-called window-constrained problem. From a bi-objective perspective, a 2-phase algorithm, called BORWin, is devised. It stands for Bi-Objective Relaxation for Window-constrained problems. The first phase is generic for any window-constrained problem and provides a family of upper bounds based on a bi-objective relaxation of the additional constraints. It is shown that the latter bounds strongly relate to the Lagrangian dual bounds. The second phase is derived for a variant involving a graph structure, namely the window-constrained longest-path problem on an acyclic graph. The aim is to take advantage of the upper bounds to devise an efficient label extension algorithm. It is shown that complementary upper bounds could be derived to further improve performance in some special cases. A typical example is when the additional constraints have special knapsack structures. This is the case for the Hydro-Unit Commitment problem with a single plant (1-HUC). From numerical experiments for the 1-HUC, BOR-Win appears to be very efficient compared to state-of-the-art approaches."}
{"id": "2602.15736", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.15736", "abs": "https://arxiv.org/abs/2602.15736", "authors": ["Jorge Luiz Franco", "Thomas Peron", "Alcebiades Dal Col", "Fabiano Petronetto", "Filipe Alves Neto Verri", "Eric K. Tokuda", "Luiz Gustavo Nonato"], "title": "SVD Incidence Centrality: A Unified Spectral Framework for Node and Edge Analysis in Directed Networks and Hypergraphs", "comment": null, "summary": "Identifying influential nodes and edges in directed networks remains a fundamental challenge across domains from social influence to biological regulation. Most existing centrality measures face a critical limitation: they either discard directional information through symmetrization or produce sparse, implementation-dependent rankings that obscure structural importance. We introduce a unified spectral framework for centrality analysis in directed networks grounded in the Singular value decomposition of the incidence matrix. The proposed approach derives both vertex and edge centralities via the pseudoinverse of Hodge Laplacians, yielding dense and well-resolved rankings that overcome the sparsity limitations commonly observed in betweenness centrality for directed graphs. Unlike traditional measures that require graph symmetrization, our framework naturally preserves directional information, enabling principled hub/authority analysis while maintaining mathematical consistency through spectral graph theory. The method extends naturally to hypergraphs through the same mathematical foundation. Experimental validation on real-world networks demonstrates the framework's effectiveness across diverse domains where traditional centrality measures encounter limitations due to implementation dependencies and sparse outputs."}
{"id": "2602.15559", "categories": ["stat.ME", "econ.EM", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.15559", "abs": "https://arxiv.org/abs/2602.15559", "authors": ["Gabriel Saco"], "title": "Fixed-Horizon Self-Normalized Inference for Adaptive Experiments via Martingale AIPW/DML with Logged Propensities", "comment": "32 pages. Comments welcome", "summary": "Adaptive randomized experiments update treatment probabilities as data accrue, but still require an end-of-study interval for the average treatment effect (ATE) at a prespecified horizon. Under adaptive assignment, propensities can keep changing, so the predictable quadratic variation of AIPW/DML score increments may remain random. When no deterministic variance limit exists, Wald statistics normalized by a single long-run variance target can be conditionally miscalibrated given the realized variance regime. We assume no interference, sequential randomization, i.i.d. arrivals, and executed overlap on a prespecified scored set, and we require two auditable pipeline conditions: the platform logs the executed randomization probability for each unit, and the nuisance regressions used to score unit $t$ are constructed predictably from past data only. These conditions make the centered AIPW/DML scores an exact martingale difference sequence. Using self-normalized martingale limit theory, we show that the Studentized statistic, with variance estimated by realized quadratic variation, is asymptotically N(0,1) at the prespecified horizon, even without variance stabilization. Simulations validate the theory and highlight when standard fixed-variance Wald reporting fails."}
{"id": "2602.15149", "categories": ["cs.CE", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.15149", "abs": "https://arxiv.org/abs/2602.15149", "authors": ["Mohammad Naqib Rahimi", "George Moutsanidis"], "title": "SoliDualSPHysics: An extension of DualSPHysics for solid mechanics with hyperelasticity, plasticity, and fracture", "comment": null, "summary": "We introduce SoliDualSPHysics, a novel open-source and GPU-accelerated software that extends DualSPHysics to enable the numerical simulation of hyperelastic, finite-strain plastic, and brittle fracture behavior in deformable solids within a unified smoothed particle hydrodynamics (SPH) formulation. The software implements a total Lagrangian formulation for solid mechanics that allows direct application of external loads and boundary conditions, enabling independent solid mechanics simulations. Brittle fracture is modeled through a phase-field approach coupled with SPH, allowing crack initiation, propagation, and branching under dynamic loading without the need for additional criteria or local refinement. The framework also supports user-defined mathematical expressions to prescribe time- and space-dependent quantities, complementing the solid and fracture extensions and enhancing flexibility across existing and future DualSPHysics applications. Leveraging DualSPHysics' native CPU/GPU parallel architecture, the software achieves substantial computational acceleration for large-scale simulations, and the implementation is verified and validated against benchmark numerical problems and experimental data, demonstrating accuracy, robustness, and favorable scaling performance. Comprehensive implementation details and user documentation are provided to ensure reproducibility and to support further development by the community. The framework and source code are freely available through a public GitHub repository."}
{"id": "2602.15657", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.15657", "abs": "https://arxiv.org/abs/2602.15657", "authors": ["Leah Anderson", "David S. Dean"], "title": "Self-phoretic oscillatory motion in a one-dimensional channel", "comment": "31 pages Latex", "summary": "We study a simple model for a particle that is active due to self-phoresis and that has been proposed to model symmetric camphor grains. The particle generates a concentration field through the continuous emission of a chemical substance, and its motion is driven by gradients of this field as it diffuses within a confined channel whose ends perfectly reflect the chemical. The reflection of the chemical field leads to an effective confinement of the particle, which itself is reflected before encountering the channel ends. The system displays a transition from a passive state, where the particle rests at the channel midpoint, to an active state characterized by highly regular, non-chaotic oscillations. We analytically construct the phase diagram and derive the oscillation frequency and amplitude in the vicinity of the transition. A perturbative analysis perfectly describes the dynamics of the particle even for oscillations as large as half the channel size. Furthermore, we develop an analysis which explains the mechanism of particle reflection close to the channel edges in the regime of large activity."}
{"id": "2602.15199", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15199", "abs": "https://arxiv.org/abs/2602.15199", "authors": ["Peter Bierhorst"], "title": "Intractability of Witnessing Entangled Measurements Device Independently", "comment": "5 pages, 6 figures", "summary": "Protocols have been previously proposed to certify the presence of an entangled measurement in a fully device-independent manner. Here, I provide models for these protocols in which the claimed measurement is not entangled, and demonstrate it is always possible to displace entanglement from measurements to measured states for a general class of device-independent scenarios. This indicates that no black-box measurement scenario requires entangled measurements to replicate its behavior, which is relevant to our fundamental understanding of this phenomenon and how to witness it."}
{"id": "2602.15643", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15643", "abs": "https://arxiv.org/abs/2602.15643", "authors": ["Jodi Dianetti", "Giorgio Ferrari", "Renyuan Xu"], "title": "Reinforcement Learning in Real Option Models", "comment": "arXiv admin note: substantial text overlap with arXiv:2408.09335", "summary": "We investigate an entropy-regularized reinforcement learning (RL) approach to optimal stopping problems motivated by real option models. Classical stopping rules are strict and non-randomized, limiting natural exploration in RL settings. To address this, we introduce entropy regularization, allowing randomized stopping policies that balance exploitation and exploration. We derive an explicit analytical solution to the regularized problem and prove convergence of the associated free boundary to the classical stopping threshold as the entropy vanishes. The regularized problem admits a natural formulation as a singular stochastic control problem. Building on this structure, we propose both model-based and model-free policy iteration algorithms to learn the optimal boundary. The model-free method operates without knowledge of system dynamics, using only trajectories from the stochastic environment. We establish convergence guarantees and illustrate strong numerical performance. This framework provides a principled and tractable approach for data-driven stopping problems under uncertainty."}
{"id": "2602.15568", "categories": ["stat.ME", "cs.LG", "eess.SY", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.15568", "abs": "https://arxiv.org/abs/2602.15568", "authors": ["Algo Carè", "Marco C. Campi", "Simone Garatti"], "title": "Scenario Approach with Post-Design Certification of User-Specified Properties", "comment": null, "summary": "The scenario approach is an established data-driven design framework that comes equipped with a powerful theory linking design complexity to generalization properties. In this approach, data are simultaneously used both for design and for certifying the design's reliability, without resorting to a separate test dataset. This paper takes a step further by guaranteeing additional properties, useful in post-design usage but not considered during the design phase. To this end, we introduce a two-level framework of appropriateness: baseline appropriateness, which guides the design process, and post-design appropriateness, which serves as a criterion for a posteriori evaluation. We provide distribution-free upper bounds on the risk of failing to meet the post-design appropriateness; these bounds are computable without using any additional test data. Under additional assumptions, lower bounds are also derived. As part of an effort to demonstrate the usefulness of the proposed methodology, the paper presents two practical examples in H2 and pole-placement problems. Moreover, a method is provided to infer comprehensive distributional knowledge of relevant performance indexes from the available dataset."}
{"id": "2602.15202", "categories": ["quant-ph", "cs.AI", "eess.SP", "math.NA", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.15202", "abs": "https://arxiv.org/abs/2602.15202", "authors": ["Shakir Showkat Sofi", "Charlotte Vermeylen", "Lieven De Lathauwer"], "title": "Tomography by Design: An Algebraic Approach to Low-Rank Quantum States", "comment": "5 pages, Submitted to EUSIPCO2026", "summary": "We present an algebraic algorithm for quantum state tomography that leverages measurements of certain observables to estimate structured entries of the underlying density matrix. Under low-rank assumptions, the remaining entries can be obtained solely using standard numerical linear algebra operations. The proposed algebraic matrix completion framework applies to a broad class of generic, low-rank mixed quantum states and, compared with state-of-the-art methods, is computationally efficient while providing deterministic recovery guarantees."}
{"id": "2602.15663", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.15663", "abs": "https://arxiv.org/abs/2602.15663", "authors": ["Patrick Romanescu"], "title": "Entropy production reveals hidden dynamical constraints rather than stochastic disorder", "comment": null, "summary": "Entropy production is often interpreted as a proxy for microscopic disorder or environmental roughness in stochastic systems. We test this interpretation using controlled simulations of overdamped stochastic dynamics on curved surfaces in which local noise, geometry, and forces are held fixed while global constraints are varied. Trajectories are generated for particles evolving toward a central attractor, and entropy production is quantified using both a continuum probability-current estimator and coarse-grained Markov transition statistics across multiple spatial and temporal resolutions. Across systematic sweeps of timestep size, domain extent, and boundary topology, entropy production is governed primarily by constraint-induced probability flow rather than local stochastic variability. Periodic domains that permit sustained circulation yield substantially higher entropy production than reflecting domains despite identical local stochastic structure, with the magnitude of the separation depending on domain extent. In contrast, coarse-grained estimates decrease as temporal resolution increases and rise with finer spatial binning, demonstrating that discrete estimates depend strongly on observation scale and may fail to resolve topology-induced irreversible structure. Ergo, entropy production is not a direct measure of environmental roughness or randomness. Instead, it quantifies how strongly system dynamics are driven away from reversibility by global constraints, geometry, and the space of allowed trajectories. Interpreted in this way, entropy production maps function as diagnostics of organized probability flow and provide a principled method for detecting hidden dynamical constraints from trajectory data alone."}
{"id": "2602.15202", "categories": ["quant-ph", "cs.AI", "eess.SP", "math.NA", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.15202", "abs": "https://arxiv.org/abs/2602.15202", "authors": ["Shakir Showkat Sofi", "Charlotte Vermeylen", "Lieven De Lathauwer"], "title": "Tomography by Design: An Algebraic Approach to Low-Rank Quantum States", "comment": "5 pages, Submitted to EUSIPCO2026", "summary": "We present an algebraic algorithm for quantum state tomography that leverages measurements of certain observables to estimate structured entries of the underlying density matrix. Under low-rank assumptions, the remaining entries can be obtained solely using standard numerical linear algebra operations. The proposed algebraic matrix completion framework applies to a broad class of generic, low-rank mixed quantum states and, compared with state-of-the-art methods, is computationally efficient while providing deterministic recovery guarantees."}
{"id": "2602.15710", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.15710", "abs": "https://arxiv.org/abs/2602.15710", "authors": ["Emanuel Laude"], "title": "All roads lead to Rome: Path-following Augmented Lagrangian Methods via Bregman Proximal Regularization", "comment": null, "summary": "We study Bregman proximal augmented Lagrangian methods with second-order oracles for convex convex-composite optimization problems. The outer loop is an instance of the Bregman proximal point algorithm with relative errors in the sense of Solodov and Svaiter, applied to the KKT operator associated with the problem. Akin to classical Lagrange-Newton methods, including primal-dual interior point methods the Bregman proximal point algorithm repeatedly solves regularized KKT inclusions by minimizing a smooth Bregman augmented Lagrangian function, obtained after marginalizing out the multiplier variables. Thanks to non-Euclidean geometries the marginal function is generalized self-concordant and therefore within the regime of Newton's method which converges quadratically if the step-size in the outer proximal point loop is chosen carefully. The operator-theoretic viewpoint allows us to employ the framework of metric subregularity to derive fast rates for the outer loop, and eventually state a joint complexity bound. Important special cases of our framework are a proximal variant of the exponential multiplier method due to Tseng and Bertsekas and interior-point proximal augmented Lagrangian schemes closely related to those of Pougkakiotis and Gondzio."}
{"id": "2602.15673", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.15673", "abs": "https://arxiv.org/abs/2602.15673", "authors": ["Sheikh Badar Ud Din Tahir", "Leonardo Egidi", "Nicola Torelli"], "title": "Leicester's Tale: Another Perspective on the EPL 2015/16 Through Expected Goals (xG) Modelling", "comment": null, "summary": "Probabilistic modeling is an effective tool for evaluating team performance and predicting outcomes in sports. However, an important question that hasn't been fully explored is whether these models can reliably reflect actual performance while assigning meaningful probabilities to rare results that differ greatly from expectations. In this study, we create an inference-based probabilistic framework built on expected goals (xG). This framework converts shot-level event data into season-level simulations of points, rankings, and outcome probabilities. Using the English Premier League 2015/16 season as a data, we demonstrate that the framework captures the overall structure of the league table. It correctly identifies the top-four contenders and relegation candidates while explaining a significant portion of the variance in final points and ranks. In a full-season evaluation, the model assigns a low probability to extreme outcomes, particularly Leicester City's historic title win, which stands out as a statistical anomaly. We then look at the ex ante inferential and early-diagnostic role of xG by only using mid-season information. With first-half data, we simulate the rest of the season and show that teams with stronger mid-season xG profiles tend to earn more points in the second half, even after considering their current league position. In this mid-season assessment, Leicester City ranks among the top teams by xG and is given a small but noteworthy chance of winning the league. This suggests that their ultimate success was unlikely but not entirely detached from their actual performance. Our analysis indicates that expected goals models work best as probabilistic baselines for analysis and early-warning diagnostics, rather than as certain predictors of rare season outcomes."}
{"id": "2602.15390", "categories": ["stat.ME", "math.NA", "math.NT"], "pdf": "https://arxiv.org/pdf/2602.15390", "abs": "https://arxiv.org/abs/2602.15390", "authors": ["Naoki Sakai", "Takashi Goda"], "title": "Space-filling lattice designs for computer experiments", "comment": "24 pages, 5 figures", "summary": "This paper investigates the construction of space-filling designs for computer experiments. The space-filling property is characterized by the covering and separation radii of a design, which are integrated through the unified criterion of quasi-uniformity. We focus on a special class of designs, known as quasi-Monte Carlo (QMC) lattice point sets, and propose two construction algorithms. The first algorithm generates rank-1 lattice point sets as an approximation of quasi-uniform Kronecker sequences, where the generating vector is determined explicitly. As a byproduct of our analysis, we prove that this explicit point set achieves an isotropic discrepancy of $O(N^{-1/d})$. The second algorithm utilizes Korobov lattice point sets, employing the Lenstra--Lenstra--Lovász (LLL) basis reduction algorithm to identify the generating vector that ensures quasi-uniformity. Numerical experiments are provided to validate our theoretical claims regarding quasi-uniformity. Furthermore, we conduct empirical comparisons between various QMC point sets in the context of Gaussian process regression, showcasing the efficacy of the proposed designs for computer experiments."}
{"id": "2602.15418", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "hep-lat"], "pdf": "https://arxiv.org/pdf/2602.15418", "abs": "https://arxiv.org/abs/2602.15418", "authors": ["Claudio Bonati", "Ettore Vicari"], "title": "Effects of quenched disorder in three-dimensional lattice ${\\mathbb Z}_2$ gauge Higgs models", "comment": "13 pages, 10 pdf figures", "summary": "We study the effects of uncorrelated quenched disorder to the phase diagram and continuous transitions of three-dimensional lattice ${\\mathbb Z}_2$ gauge Higgs models. For this purpose, we consider two types of quenched disorder, associated with the sites and plaquettes of the cubic lattice. In both cases, for sufficiently weak disorder, the phase diagram remains similar to that of the pure system, showing two different phases (one of them being a topologically ordered phase), separated by two different continuous transition lines. However, the quenched disorder changes the universality classes of the critical behaviors along some of the transition lines. The random-plaquette disorder turns out to be relevant along the topological ${\\mathbb Z}_2$ gauge transition line, so the critical behaviors belong to the different random-plaquette $\\mathbb{Z}_2$ gauge (RP${\\mathbb Z}_2$G) universality class with length-scale exponent $ν=ν_{\\rm rp}\\approx 0.82$; on the other hand, it turns out to be irrelevant along the other Ising$^\\times$ transition line (a variant of the Ising transitions with a gauge-dependent order parameter), leaving unchanged its asymptotic critical behaviors with $ν=ν_{\\cal I}\\approx 0.63$. The random-site disorder leads to a substantially different scenario: it destabilizes the Ising$^\\times$ critical behaviors of the pure model, changing them into those of the randomly-dilute Ising$^{\\times}$ (RDI$^{\\times}$) universality class with $ν=ν_{\\rm rdi}\\approx 0.68$, while the critical behaviors along the other ${\\mathbb Z}_2$ gauge topological transition line remains stable, with $ν=ν_{\\cal I}\\approx 0.63$."}
{"id": "2602.15207", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.15207", "abs": "https://arxiv.org/abs/2602.15207", "authors": ["Keshav Kapoor", "Dong Beom Kim", "Kriti Shetty", "Virginia O. Lorenz"], "title": "Near-Infrared and Telecommunication-Wavelength Photon-Pair Source in Optical Fiber", "comment": null, "summary": "We present a photon-pair source in commercially available optical fiber that produces paired photons at telecommunication and near-infrared (NIR) wavelengths. The highly nondegenerate pairs are 700 nm apart: one in the 1500 nm E- and S-band telecommunication range and the other in the 830 nm NIR range. The high non-degeneracy means the photon pairs are far-detuned from Raman noise, resulting in a high coincidence-to-accidental ratio even while operating at room temperature. The source produces two spectrally and spatially distinct phase-matched processes with low spectral cross-talk, distinct transverse spatial modes in the NIR, and a single fundamental spatial mode in the telecommunication range. The source's room-temperature operation, off-the-shelf materials, and multiplexing potential make it promising for deployment in quantum networks."}
{"id": "2602.15722", "categories": ["math.OC", "econ.GN"], "pdf": "https://arxiv.org/pdf/2602.15722", "abs": "https://arxiv.org/abs/2602.15722", "authors": ["Cheng Guo", "Lauren Henderson", "Ryan Cory-Wright", "Boshi Yang"], "title": "Pricing Discrete and Nonlinear Markets With Semidefinite Relaxations", "comment": null, "summary": "Nonconvexities in markets with discrete decisions and nonlinear constraints make efficient pricing challenging, often necessitating subsidies. A prime example is the unit commitment (UC) problem in electricity markets, where costly subsidies are commonly required. We propose a new pricing scheme for nonconvex markets with both discreteness and nonlinearity, by convexifying nonconvex structures through a semidefinite programming (SDP) relaxation and deriving prices from the relaxation's dual variables. When the choice set is bounded, we establish strong duality for the SDP, which allows us to extend the envelope theorem to the value function of the relaxation. This extension yields a marginal price signal for demand, which we use as our pricing mechanism. We demonstrate that under certain conditions-for instance, when the relaxation's right hand sides are linear in demand-the resulting lost opportunity cost is bounded by the relaxation's optimality gap. This result highlights the importance of achieving tight relaxations. The proposed framework applies to nonconvex electricity market problems, including for both direct current and alternating current UC. Our numerical experiments indicate that the SDP relaxations are often tight, reinforcing the effectiveness of the proposed pricing scheme. Across a suite of IEEE benchmark instances, the lost opportunity cost under our pricing scheme is, on average, 46% lower than that of the commonly used fixed-binary pricing scheme."}
{"id": "2602.15679", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.15679", "abs": "https://arxiv.org/abs/2602.15679", "authors": ["Ori Davidov"], "title": "Safe hypotheses testing with application to order restricted inference", "comment": null, "summary": "Hypothesis tests under order restrictions arise in a wide range of scientific applications. By exploiting inequality constraints, such tests can achieve substantial gains in power and interpretability. However, these gains come at a cost: when the imposed constraints are misspecified, the resulting inferences may be misleading or even invalid, and Type III errors may occur, i.e., the null hypothesis may be rejected when neither the null nor the alternative is true. To address this problem, this paper introduces safe tests. Heuristically, a safe test is a testing procedure that is asymptotically free of Type III errors. The proposed test is accompanied by a certificate of validity, a pre--test that assesses whether the original hypotheses are consistent with the data, thereby ensuring that the null hypothesis is rejected only when warranted, enabling principled inference without risk of systematic error. Although the development in this paper focus on testing problems in order--restricted inference, the underlying ideas are more broadly applicable. The proposed methodology is evaluated through simulation studies and the analysis of well--known illustrative data examples, demonstrating strong protection against Type III errors while maintaining power comparable to standard procedures."}
{"id": "2602.15632", "categories": ["physics.comp-ph", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.15632", "abs": "https://arxiv.org/abs/2602.15632", "authors": ["Changhong Mou", "Binghang Lu", "Guang Lin"], "title": "Neural-POD: A Plug-and-Play Neural Operator Framework for Infinite-Dimensional Functional Nonlinear Proper Orthogonal Decomposition", "comment": null, "summary": "The rapid development of AI for Science is often hindered by the \"discretization\", where learned representations remain restricted to the specific grids or resolutions used during training. We propose the Neural Proper Orthogonal Decomposition (Neural-POD), a plug-and-play neural operator framework that constructs nonlinear, orthogonal basis functions in infinite-dimensional space using neural networks. Unlike the classical Proper Orthogonal Decomposition (POD), which is limited to linear subspace approximations obtained through singular value decomposition (SVD), Neural-POD formulates basis construction as a sequence of residual minimization problems solved through neural network training. Each basis function is obtained by learning to represent the remaining structure in the data, following a process analogous to Gram--Schmidt orthogonalization. This neural formulation introduces several key advantages over classical POD: it enables optimization in arbitrary norms (e.g., $L^2$, $L^1$), learns mappings between infinite-dimensional function spaces that is resolution-invariant, generalizes effectively to unseen parameter regimes, and inherently captures nonlinear structures in complex spatiotemporal systems. The resulting basis functions are interpretable, reusable, and enabling integration into both reduced order modeling (ROM) and operator learning frameworks such as deep operator learning (DeepONet). We demonstrate the robustness of Neural-POD with different complex spatiotemporal systems, including the Burgers' and Navier-Stokes equations. We further show that Neural-POD serves as a high performance, plug-and-play bridge between classical Galerkin projection and operator learning that enables consistent integration with both projection-based reduced order models and DeepONet frameworks."}
{"id": "2602.15524", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15524", "abs": "https://arxiv.org/abs/2602.15524", "authors": ["Brendan Rhyno", "Bastien Lapierre", "Smitha Vishveshwara", "Khadijeh Najafi", "Ramasubramanian Chitra"], "title": "Observing quantum many-body dynamics in emergent curved spacetime using programmable quantum processors", "comment": "17 pages, 11 figures", "summary": "We digitally simulate quantum many-body dynamics in emergent curved backgrounds using 80 superconducting qubits on IBM Heron processors. By engineering spatially varying couplings in the spin-$\\frac12$ XXZ chain, consistent with the low energy description of the model in terms of an inhomogeneous Tomonaga-Luttinger liquid, we realize excitations that follow geodesics of an effective metric inherited from the underlying spatial deformation. Following quenches from Néel and few-spin-flip states, we observe curved light-cone propagation, horizon-induced freezing in the local magnetization, and position-dependent oscillation frequencies set by the engineered spatial deformation. Despite strong spatial inhomogeneity, unequal-time correlators reveal ballistic quasiparticle propagation in the spin chain. These results establish large-scale digital quantum processors as a flexible platform for detailed and controlled exploration of many-body dynamics in tunable and synthetic curved spacetimes."}
{"id": "2602.15235", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15235", "abs": "https://arxiv.org/abs/2602.15235", "authors": ["Yu-qiang Liu", "Yi-jia Yang", "Zheng Liu", "Bao-qing Guo", "Ting-ting Ma", "Zunlue Zhu", "Wuming Liu", "Xingdong Zhao", "Chang-shui Yu"], "title": "Dissipative Quantum Battery in the Ultrastrong Coupling Regime Between Two Oscillators", "comment": "16 pages, 12 figures", "summary": "In this work, we propose an open quantum battery that stores and releases energy by employing a two-mode ultrastrongly coupled bosonic system, with one mode (the charger) coupled to an independent heat reservoir. Our results demonstrate that both the charging energy and ergotropy of the quantum batteries can be significantly enhanced within the ultra-strong coupling regime and across a broader temperature range in transient time. A unidirectional energy flow is achieved by controlling the system's initial state through its two-mode squeezed ground state. Furthermore, we show that the steady-state stored energy, along with its corresponding ergotropy, can be enhanced at larger temperatures and stronger coupling strengths. Notably, a purely beam-splitter or two-mode squeezing interaction yields zero ergotropy. These findings indicate that the enhanced stored energy and ergotropy of the quantum battery arises principally from the combined effects of beam-splitter and parametric amplification (squeezing) couplings. In addition, the presence of the squared electromagnetic vector potential term can prevent a phase transition and achieve a significant charging energy and high ergotropy in the deep-strong coupling regime. The results presented herein enhance our understanding of the operating principles of open bosonic quantum batteries."}
{"id": "2602.15279", "categories": ["nlin.AO", "math-ph", "math.DS", "math.OC", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2602.15279", "abs": "https://arxiv.org/abs/2602.15279", "authors": ["Martin Moriamé", "Riccardo Muolo", "Timoteo Carletti", "Maxime Lucas"], "title": "On the efficiency of pairwise Hamiltonian control to desynchronize the higher-order Kuramoto model", "comment": null, "summary": "Synchronization of coupled oscillators is observed in many natural and engineered systems and emerges due to the interactions within the system. It can be both beneficial, e.g., in power grids, and harmful, e.g., in epileptic seizures. In the latter case, efficient control methods to desynchronize the systems are crucial. Recent studies have shown that interactions are not always pairwise, but higher-order, i.e., many-body, and this greatly affects the dynamics. For instance, higher-order interactions increase the linear stability of synchronized states but simultaneously shrink their attraction basin, with potentially opposite effects on control methods. Here, we use a minimally invasive pairwise control based on Hamiltonian control theory, and investigate its efficiency on phase oscillators with higher-order interactions. We show that, if the initial phases are close to the synchronized state, higher-order interactions make desynchronization more difficult to achieve. Otherwise, a non-monotonic effect appears: intermediate strengths of higher-order interactions impede desynchronization while larger ones facilitate it. In all cases, the control can desynchronize the system with a sufficient number of controlled nodes and intensity."}
{"id": "2602.15731", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.15731", "abs": "https://arxiv.org/abs/2602.15731", "authors": ["Laura M. Craig", "Wagner Barreto-Souza"], "title": "Generalised Exponential Kernels for Nonparametric Density Estimation", "comment": "Paper submitted for publication", "summary": "This paper introduces a novel kernel density estimator (KDE) based on the generalised exponential (GE) distribution, designed specifically for positive continuous data. The proposed GE KDE offers a mathematically tractable form that avoids the use of special functions, for instance, distinguishing it from the widely used gamma KDE, which relies on the gamma function. Despite its simpler form, the GE KDE maintains similar flexibility and shape characteristics, aligning with distributions such as the gamma, which are known for their effectiveness in modelling positive data. We derive the asymptotic bias and variance of the proposed kernel density estimator, and formally demonstrate the order of magnitude of the remaining terms in these expressions. We also propose a second GE KDE, for which we are able to show that it achieves the optimal mean integrated squared error, something that is difficult to establish for the former. Through numerical experiments involving simulated and real data sets, we show that GE KDEs can be an important alternative and competitive to existing KDEs."}
{"id": "2602.15285", "categories": ["quant-ph", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.15285", "abs": "https://arxiv.org/abs/2602.15285", "authors": ["Kirill Khoruzhii", "Patrick Gelß", "Sebastian Pokutta"], "title": "Tensor Decomposition for Non-Clifford Gate Minimization", "comment": null, "summary": "Fault-tolerant quantum computation requires minimizing non-Clifford gates, whose implementation via magic state distillation dominates the resource costs. While $T$-count minimization is well-studied, dedicated $CCZ$ factories shift the natural target to direct Toffoli minimization. We develop algebraic methods for this problem, building on a connection between Toffoli count and tensor decomposition over $\\mathbb{F}_2$. On standard benchmarks, these methods match or improve all reported results for both Toffoli and $T$-count, with most circuits completing in under a minute on a single CPU instead of thousands of TPUs used by prior work."}
{"id": "2602.15445", "categories": ["math.NA", "math.DS", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.15445", "abs": "https://arxiv.org/abs/2602.15445", "authors": ["Attila Karsai", "Philipp Schulze"], "title": "A discrete gradient scheme for preserving QSR-dissipativity", "comment": null, "summary": "The notion of dissipative dynamical systems provides a formal description of processes that cannot generate energy internally. For these systems, changes in energy can only occur due to an external energy supply or dissipation effects. Unfortunately, dissipative properties tend to deteriorate in numerical computations, especially in nonlinear systems. Discrete gradient methods can help mitigate this problem. In this paper, we present a class of structure-preserving time discretization schemes based on discrete gradients for a special class of systems that are dissipative with respect to a quadratic supply rate."}
{"id": "2602.15324", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15324", "abs": "https://arxiv.org/abs/2602.15324", "authors": ["Jiangwei Long", "Zihui Liu", "Yizhi Li", "Jianxin Zhong", "Lijun Meng"], "title": "Realizing a Universal Quantum Gate Set via Double-Braiding of SU(2)k Anyon Models", "comment": null, "summary": "We systematically investigate the implementation of a universal gate set via double-braiding within SU(2)k anyon models. The explicit form of the double elementary braiding matrices (DEBMs) in these models are derived from the F-matrices and R-symbols obtained via the q-deformed representation theory of SU(2). Using these EBMs, standard single-qubit gates are synthesized up to a global phase by a Genetic Algorithm-enhanced Solovay-Kitaev Algorithm (GA-enhanced SKA), achieving the accuracy required for fault-tolerant quantum computation with only 2-level decomposition. For two-qubit entangling gates, Genetic Algorithm (GA) yields braidwords of 30 braiding operations that approximate the local equivalence class [CNOT]. Theoretically, we demonstrate that performing double-braiding in a three-anyon (six-anyon) encoding of single-qubit (two-qubit) is topologically equivalent to a protocol requiring the physical manipulation of only one (three) anyons to execute arbitrary braids. Our numerical results provide strong evidence that double-braiding in SU(2)k anyons models is capable of universal quantum computation. Moreover, the proposed protocol offers a potential new strategy for significantly reducing the number of non-Abelian anyons that need to be physically manipulated in future braiding-based topological quantum computations (TQC)."}
{"id": "2602.15372", "categories": ["quant-ph", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.15372", "abs": "https://arxiv.org/abs/2602.15372", "authors": ["Ze-Chuan Liu", "Chong-Yuan Xu", "Yong Xu"], "title": "Self-dual Stacked Quantum Low-Density Parity-Check Codes", "comment": "8 pages, 3 figures, 8 tables (including end matter)", "summary": "Quantum low-density parity-check (qLDPC) codes are promising candidates for fault-tolerant quantum computation due to their high encoding rates and distances. However, implementing logical operations using qLDPC codes presents significant challenges. Previous research has demonstrated that self-dual qLDPC codes facilitate the implementation of transversal Clifford gates. Here we introduce a method for constructing self-dual qLDPC codes by stacking non-self-dual qLDPC codes. Leveraging this methodology, we develop double-chain bicycle codes, double-layer bivariate bicycle (BB) codes, double-layer twisted BB codes, and double-layer reflection codes, many of which exhibit favorable code parameters. Additionally, we conduct numerical calculations to assess the performance of these codes as quantum memory under the circuit-level noise model, revealing that the logical failure rate can be significantly reduced with high pseudo-thresholds."}
{"id": "2602.15389", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15389", "abs": "https://arxiv.org/abs/2602.15389", "authors": ["Shiying Lin", "Xinyu Zhao", "Yan Xia"], "title": "Giant atoms coupled to waveguide: Continuous coupling and multiple excitations", "comment": "19 pages 10 figures", "summary": "We propose a stochastic Schrödinger equation (SSE) approach to investigate the dynamics of giant atoms coupled to a waveguide, addressing two critical gaps in existing research, namely insufficient exploration on continuous coupling and multiple excitations. A key finding is that continuous coupling, unlike discrete coupling at finite points, breaks the constant phase difference condition, thereby weakening the interference effects in giant atom-waveguide systems. In addition, a key technical advantage of the SSE approach is that auto- and cross-correlation functions can directly reflect the complex photon emission/absorption processes and time-delay effects in giant atom-waveguide systems. Moreover, the SSE approach also naturally handles multiple excitations, without increasing equation complexity as the number of excitations grows. This feature enables the investigation of multi-excitation initial states of the waveguide, such as thermal and squeezed initial states. Overall, our approach provides a powerful tool for studying the dynamics of giant atoms coupled to waveguide, particularly for continuous coupling and multi-excitation systems."}
{"id": "2602.15402", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15402", "abs": "https://arxiv.org/abs/2602.15402", "authors": ["You-Lin Xiang", "Xinyu Zhao", "Yan Xia"], "title": "Non-Markovian environment induced chaos in optomechanical system", "comment": "13 pages, 6 figures", "summary": "In traditional research, chaos is frequently accompanied by non-linearity, which typically stems from non-linear interactions or external driving forces. However, in this paper, we present the chaotic behavior that is completely attributed to the non-linear back-reaction of non-Markovian environment. To be specific, we derive the dynamical equations of an optomechanical system and demonstrate that the non-linearity (cause of chaos) in the equations arises entirely from the time-domain convolutions (TDCs) induced by non-Markovian corrections. Under Markovian conditions, these TDCs are reduced into constants, thereby losing the nonlinearity and ultimately leading to the disappearance of chaos. Furthermore, we also observe chaos generation in the absence of optomechanical couplings, which further confirms that the non-Markovian effect is the sole inducement of chaos and the environmental parameters play important roles in the generation of chaos. We hope these results may open a new direction to investigate chaotic dynamics purely caused by non-Markovian environments."}
{"id": "2602.15430", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15430", "abs": "https://arxiv.org/abs/2602.15430", "authors": ["Xinyu Zhao", "Yan Xia"], "title": "Non-Markovian environment induced Schrödinger cat state transfer in an optical Newton's cradle", "comment": "21 pages, 7 figures", "summary": "In this manuscript, we study the Schrödinger cat state transfer in a quantum optical version of Newton's cradle in non-Markovian environment. Based on a non-Markovian master equation, we show that the cat state can be transferred purely through the memory effect of the non-Markovian common environment, even without any direct couplings between neighbor cavities. The mechanism of the environment induced cat state transfer is analyzed both analytically and numerically to demonstrate that the transfer is a unique phenomenon in non-Markovian regime. From this example, the non-Markovian environment is shown to be qualitatively different from the Markovian environment reflected by the finite versus zero residue coherence. Besides, we also show the influence of environmental parameters are crucial for the transfer. We hope the cat state transfer studied in this work may shed more light on the fundamental difference between non-Markovian and Markovian environments."}
{"id": "2602.15452", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15452", "abs": "https://arxiv.org/abs/2602.15452", "authors": ["Satyaki Manna", "Anandamay Das Bhowmik"], "title": "Nonlocality without entanglement in exclusion of quantum states", "comment": null, "summary": "We study the task of quantum state exclusion, focusing on antidistinguishability and its generalization to $x$-antidistinguishability, under global measurements and local operations with classical communication (LOCC). We also introduce weak and strong notions of antidistinguiahbaility ($x$-antidistinguishability) depending on whether all states or all $x$-tuples are exhaustively eliminated. Our results reveal striking differences between state exclusion and the more familiar task of state discrimination. In particular, we show that LOCC antidistinguishability of multipartite product states is symmetric with respect to the initiating party but this symmetry breaks down for higher-order $x$-antidistinguishability. Most notably, we establish a manifestation of \\emph{nonlocality without entanglement} in the context of state exclusion: we prove that three bipartite product states can be globally antidistinguishable while failing to be LOCC antidistinguishable, demonstrating that three is the minimal number of states required for this phenomenon. We further extend this separation to $2$-antidistinguishability and present example exhibiting the same type of nonlocality. At last, we provide an antidistinguishable tripartite product states that are not LOCC antidistinguishable across any bipartition, which ensures the phenomenon of \\emph{genuine nonlocality without entanglement} in this framework."}
{"id": "2602.15467", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.15467", "abs": "https://arxiv.org/abs/2602.15467", "authors": ["Anna Pavone", "Federico Luigi Cavagnaro", "Matteo Carrega", "Riccardo Grazi", "Dario Ferraro", "Niccolò Traverso Ziani"], "title": "Cluster Ising quantum batteries can mimic super-extensive charging power", "comment": "7 pages, 5 figures", "summary": "Quantum batteries, miniaturized devices able to store and release energy on demand, are promising both because their intrinsic energy and time scales can match those of other quantum technologies and due to the intriguing possibility of achieving super-extensive charging power. While this enhanced scaling is known to appear in several settings, it is generally believed to be forbidden in Wigner-Jordan integrable spin chains charged via quantum-quench protocols. Here, we show that an extended cluster-Ising model, despite belonging to the above category, exhibits super-extensive charging power over wide ranges of system sizes, reaching up to a thousand spins, in proper parameter regimes. This remarkable anomalous scaling is due to a corresponding super-extensive growth of the stored energy, implying that it occurs at large but finite size and cannot persist in the thermodynamic limit. This phenomenon appears robust against finite-temperature effects."}
{"id": "2602.15474", "categories": ["quant-ph", "cond-mat.supr-con", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.15474", "abs": "https://arxiv.org/abs/2602.15474", "authors": ["J. J. Prieto-Garcia", "A. G. del Pozo-Martín", "M. Pino"], "title": "Quantum Reservoir Computing for Statistical Classification in a Superconducting Quantum Circuit", "comment": "13 pages, 4 figures", "summary": "We analyze numerically the performance of Quantum Reservoir Computing (QRC) for statistical and financial problems. We use a reservoir composed of two superconducting islands coupled via their charge degrees of freedom. The key non-linear elements that provide the reservoir with rich and complex dynamics are the Josephson junctions that connect each island to the ground. We show that QRC implemented in this circuit can accurately classify complex probability distributions, including those with heavy tails, and identify regimes in correlated time series, such as periods of high volatility generated by standard econometric models. We find QRC to outperform some of the best classical methods when the amount of information is limited. This demonstrates its potential to be a noise-resilient quantum learning approach capable of tackling real-world problems within currently available superconducting platforms. We further discuss how to improve our QRC algorithm in real superconducting hardware to benefit from a much larger Hilbert space."}
{"id": "2602.15487", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15487", "abs": "https://arxiv.org/abs/2602.15487", "authors": ["Sara Tarquini", "Matteo Vandelli", "Francesco Ferrari", "Daniele Dragoni", "Francesco Tudisco"], "title": "Drone delivery packing problem on a neutral-atom quantum computer", "comment": null, "summary": "Quantum architectures based on neutral atoms have gained significant attention in recent years as specialized computational machines due to their ability to directly encode the independent set constraint on graphs, exploiting the Rydberg blockade mechanism. In this work, we address the Drone Delivery Packing Problem via a hybrid quantum-classical framework leveraging a neutral-atom quantum processing unit (QPU). We reformulate the optimization task as a graph-partitioning problem based on the independent sets (ISs) of a scheduling graph that encodes delivery incompatibilities. Each partition corresponds to deliveries assigned to a single drone, with the objective of minimizing the total number of partitions. While the ISs represent time-feasible schedules, battery-duration constraints are enforced through a classical post-processing routine. This methodology enables the recovery of optimal delivery schedules, provided a sufficient number of samples is collected from the QPU to resolve the solution space. We benchmark the hybrid workflow through numerical emulations and demonstrate its effectiveness on Pasqal's Fresnel QPU, reporting hardware experiments with configurations of up to 100 atoms."}
{"id": "2602.15520", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15520", "abs": "https://arxiv.org/abs/2602.15520", "authors": ["Elizabeth Agudelo", "Laura Ares", "Jan Sperling"], "title": "Universal entanglement-inspired correlations", "comment": null, "summary": "Quantum correlations, crucial for the advantage and advancement of quantum science and technology, arise from the impossibility of expressing a quantum state as a tensor product over a given set of parties. In this work, a generalized notion of correlations via arbitrary products is formulated. Remarkably, as a universal property, the connection between such general products and tensor products is established, allowing one to relate generic non-product states to the common notion of entangled states. We construct the set of free operations for general types of products by extending the local-operation-and-classical-communication paradigm, familiar from standard entanglement theory, thereby establishing a resource theory of correlations for general products. A generalization is provided beyond two factors that can be universally related to multipartite entanglement. Applications that highlight the usefulness of the approach are discussed, such as the factorization of fermionic states, the non-local factorization of multi-photon states into single-photon states, and the interesting possibility of understanding prime numbers as a form of single-party entanglement."}
{"id": "2602.15524", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.15524", "abs": "https://arxiv.org/abs/2602.15524", "authors": ["Brendan Rhyno", "Bastien Lapierre", "Smitha Vishveshwara", "Khadijeh Najafi", "Ramasubramanian Chitra"], "title": "Observing quantum many-body dynamics in emergent curved spacetime using programmable quantum processors", "comment": "17 pages, 11 figures", "summary": "We digitally simulate quantum many-body dynamics in emergent curved backgrounds using 80 superconducting qubits on IBM Heron processors. By engineering spatially varying couplings in the spin-$\\frac12$ XXZ chain, consistent with the low energy description of the model in terms of an inhomogeneous Tomonaga-Luttinger liquid, we realize excitations that follow geodesics of an effective metric inherited from the underlying spatial deformation. Following quenches from Néel and few-spin-flip states, we observe curved light-cone propagation, horizon-induced freezing in the local magnetization, and position-dependent oscillation frequencies set by the engineered spatial deformation. Despite strong spatial inhomogeneity, unequal-time correlators reveal ballistic quasiparticle propagation in the spin chain. These results establish large-scale digital quantum processors as a flexible platform for detailed and controlled exploration of many-body dynamics in tunable and synthetic curved spacetimes."}
{"id": "2602.15529", "categories": ["quant-ph", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.15529", "abs": "https://arxiv.org/abs/2602.15529", "authors": ["Fabien Dufoulon", "Frédéric Magniez", "Gopal Pandurangan"], "title": "Tight Communication Bounds for Distributed Algorithms in the Quantum Routing Model", "comment": null, "summary": "We present new distributed quantum algorithms for fundamental distributed computing problems, namely, leader election, broadcast, Minimum Spanning Tree (MST), and Breadth-First Search (BFS) tree, in arbitrary networks. These algorithms are (essentially) optimal with respect to their communication (message) complexity in the {\\em quantum routing model} introduced in [PODC 2025]. The message complexity of our algorithms is $\\tilde{O}(n)$ for leader election, broadcast, and MST, and $\\tilde{O}(\\sqrt{mn})$ for BFS ($n$ and $m$ are the number of nodes and edges of the network, respectively). These message bounds are nearly tight in the quantum routing model since we show almost matching corresponding quantum message lower bounds. Our results significantly improve on the prior work of [PODC 2025], who presented distributed quantum algorithms under the same model that had a message complexity of $\\tilde{O}(\\sqrt{mn})$ for leader election.\n  Our algorithms demonstrate the significant communication advantage that quantum routing has over classical in distributed computing, since $Ω(m)$ is a well-established classical message lower bound for leader election, broadcast, MST, and BFS that applies even to randomized Monte-Carlo algorithms [JACM 2015]. Thus, our quantum algorithms can, in general, give a quadratic advantage in the communication cost for these fundamental problems.\n  A main technical tool we use to design our distributed algorithms is quantum walks based on electric networks. We posit a framework for using quantum walks in the distributed setting to design communication-efficient distributed quantum algorithms. Our framework can be used as a black box to significantly reduce communication costs and may be of independent interest. Additionally, our lower-bound technique for establishing distributed quantum message lower bounds can also be applied to other problems."}
{"id": "2602.15545", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15545", "abs": "https://arxiv.org/abs/2602.15545", "authors": ["Fatemeh Sadat Lajevardi", "Azam Mani", "Ali Fahim"], "title": "Optimal Classification of Three-Qubit Entanglement with Cascaded Support Vector Machine", "comment": null, "summary": "We introduce a systematic framework for three-qubit entanglement classification using a cascaded architecture of Support Vector Machine (SVM) classifiers. Leveraging the well defined three-qubit structure with the four nested entanglement classes (S, B, W, and GHZ), we construct three distinct witness models ($\\mathcal{M}_{B}$, $\\mathcal{M}_{W}$, and $\\mathcal{M}_{GHZ}$) that sequentially discriminate between these classes. The proposed Cascaded model achieves an overall classification accuracy of $95\\%$ on a comprehensive dataset of mixed states. The framework's robustness and generalization capabilities are confirmed through rigorous testing against out-of-distribution (OOD) entangled states and various quantum noise channels, where the model maintains high performance. A key contribution of this research is an optimization protocol based on systematic feature importance analysis. This approach yields a tunable framework that significantly reduces the number of required features, while maintaining reliable model accuracy."}
{"id": "2602.15573", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.15573", "abs": "https://arxiv.org/abs/2602.15573", "authors": ["Nilakshi Senapati", "Girish Kulkarni", "Anand K. Jha"], "title": "Theory of temporal three-photon interference", "comment": "15 pages, 3 figures", "summary": "The recent demonstrations of cascaded PDC (CPDC) and the hopeful prospects of realizing third-order PDC (TOPDC) for the generation of three-photon entangled states are paving the way for experimental studies on genuine three-photon interference. In this article, we formulate three-photon interference in terms of ``each three-photon interfering only with itself.'' We show that although a generalized two-alternative three-photon interference setup based on CPDC or TOPDC involves eight different length parameters, the interference can be fully characterized in terms of only three independent parameters. The first parameter is the three-photon path-length difference, which has a direct analog in the one-photon and two-photon cases, and the other two parameters quantify the path-asymmetry length. Unlike two-photon interference, which requires only one parameter to quantify path-asymmetry, two independent parameters are needed in three-photon interference. This results in a broader class of nonclassical three-photon effects, including three-photon HOM-type effects. Our work provides the theoretical basis for existing and future three-photon interference experiments exploring the rich and complex quantum correlations associated with three-particle entanglement and potentially enabling the development of novel protocols for harnessing those correlations."}
{"id": "2602.15615", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15615", "abs": "https://arxiv.org/abs/2602.15615", "authors": ["Sushanta Barman", "Kuldeep Godara", "Sudeep Bhattacharjee"], "title": "Magnetically assisted spin-resolved electron diffraction: Coherent control of spin population and spatial filtering", "comment": "16 pages, 13 figures", "summary": "Electron diffraction from nanogratings provides a platform for free-electron interferometry, yet controlled manipulation of electron spin in such geometries remains largely unexplored. In particular, the role of the self-generated magnetic field arising from electron motion and the feasibility of coherent spin control without disrupting diffraction coherence have not been quantitatively investigated. In this article, a self-consistent Maxwell-Pauli framework is developed to study spin-resolved electron diffraction from nanogratings in the presence of magnetic fields. The model incorporates geometric confinement, image-charge interactions, self-generated magnetostatic fields, and externally applied magnetic fields. Numerical simulations show that the intrinsic magnetic self-field produced by the electron probability current is several orders of magnitude too weak to induce measurable spin mixing, demonstrating that nanogratings act as spin-conserving beam splitters under field-free conditions. When a uniform magnetic field is applied upstream of the nanograting, coherent Larmor precession enables controlled spin rotation without modifying the diffraction geometry or degrading coherence. The magnetic field required for a $π$ spin rotation scales inversely with the interaction length and electron de Broglie wavelength $λ_{dB}$. Furthermore, a downstream nonuniform magnetic field applied after the nanograting imparts a spatially varying Zeeman phase, producing opposite transverse momentum shifts for the two spin components. The spin-dependent transverse dynamics is analyzed using Husimi Q-function phase-space maps, which visualize spin-dependent population redistribution and momentum separation. The proposed approach enables tunable spatial separation of spin-resolved free electron beams and establishes an all-magnetic route for coherent spin rotation, control, and interferometry."}
{"id": "2602.15619", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15619", "abs": "https://arxiv.org/abs/2602.15619", "authors": ["Akram Kasri", "Kimin Park", "Radim Filip"], "title": "Nonlinear Phase Gates Beyond the Lamb-Dicke Regime", "comment": null, "summary": "Nonlinear phase gates are essential to achieve the universality of continuous-variable quantum processing and its applications. We present a deterministic protocol for generating nonlinear phase gates in trapped ion systems using simultaneous two-tone sideband drives beyond the Lamb-Dicke regime. Our approach harnesses higher-order interaction terms typically neglected or suppressed to construct nonlinear phase gates. This methodology enables high-fidelity gate engineering with a near three-fold reduction in control pulses compared to state-of-the-art theoretical proposals."}
{"id": "2602.15630", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15630", "abs": "https://arxiv.org/abs/2602.15630", "authors": ["Nabaneet Sharma", "Anushree Dey", "Bimalendu Deb"], "title": "Controlling correlations of a polaritonic Luttinger liquid by engineered cross-Kerr nonlinearity", "comment": null, "summary": "We study correlation properties of polaritons at zero temperature in a multiconnected Jaynes--Cummings (MCJC) lattice on a superconducting circuit quantum electrodynamics platform with engineered cross-Kerr nonlinearity that mimics attractive nearest-neighbour interaction. A multi-connected Jaynes--Cummings lattice is a one-dimensional lattice constructed from alternating qubits and resonators with different left and right couplings. The nearest-neighbour interaction or cross-Kerr coupling is implemented dispersively through ladder-type qutrits between each nearest neighboring pair of resonator modes. Projecting onto the lower-polaritonic manifold, we derive an extended two-mode (bipartite) Bose--Hubbard-like model featuring on-site and attractive nearest-neighbor interactions. Employing a continuum bosonization approach, we express the Hamiltonian in terms of symmetric ($+$) and antisymmetric ($-$) collective modes. In the regime where the ($-$) sector acquires a finite gap, one can reduce the system to an effective single-component Luttinger liquid model for the $+$ sector. The cross-Kerr term reduces the compressibility of the ($+$) mode, thereby enhancing the corresponding Luttinger parameter $K_{+}$, resulting in the slower algebraic decay of single-particle correlations, $G(x)\\propto|x|^{-1/(4K_{+})}$."}
{"id": "2602.15653", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15653", "abs": "https://arxiv.org/abs/2602.15653", "authors": ["Alexander N. Craddock", "Tyler Cowan", "Niccolò Bigagli", "Suresh Yekasiri", "Dylan Robinson", "Gabriel Bello Portmann", "Ziyu Guo", "Michael Kilzer", "Jiapeng Zhao", "Mael Flament", "Javad Shabani", "Reza Nejabati", "Mehdi Namazi"], "title": "High-rate Scalable Entanglement Swapping Between Remote Entanglement Sources on Deployed New York City Fibers", "comment": null, "summary": "Entanglement swapping between photon pairs generated at physically separated nodes over telecommunication fiber infrastructure is an essential step towards the quantum internet, enabling applications such as quantum repeaters, blind quantum computing, distributed quantum computing, and distributed quantum sensing. However, successful networked entanglement swapping relies on generating indistinguishable pairs of photons and preserving them over deployed fibers. This has limited most previous demonstrations to laboratory settings or relied on sophisticated methods to maintain the necessary indistinguishability. Here, we demonstrate a scalable entanglement swapping experiment using naturally indistinguishable entanglement sources based on warm atomic vapor cells. Without sharing lasers or optical frequency references between nodes, nor the need for pulsing the sources, we achieve a swapping rate of nearly 500 pairs/s while maintaining the CHSH parameter above 2. Additionally, we demonstrate the scalability of our method by maintaining the quality of the entanglement swapping on 17.6-km of deployed fibers in NYC, relying on commercially available SPADs at the spoke nodes, SNSPDs at the hub and standard time-synchronization techniques. Our work paves the way for the practical deployment of large-scale hub-and-spoke quantum networks within cities and data centers."}
{"id": "2602.15655", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.15655", "abs": "https://arxiv.org/abs/2602.15655", "authors": ["Cheng Li", "Jasvinder Brar", "Michael Küblböck", "Jeremy Upham", "Hanieh Fattahi", "Robert W. Boyd"], "title": "Generating quantum entanglement from sunlight", "comment": null, "summary": "Energy consumption is becoming a serious bottleneck for integrating quantum technologies within the existing global information infrastructure. In photonic architectures, considerable energy overheads stem from using lasers, whose high coherence was long considered indispensable for quantum state preparation. Here, we demonstrate that natural, incoherent sunlight can successfully produce quantum-entangled states via spontaneous parametric down-conversion. We detect polarization-entangled photon pairs with a concurrence of $0.905\\pm0.053$ and a Bell state fidelity of $0.939\\pm0.027$. Importantly, the system violates Bell's inequality with $S=2.5408\\pm0.2171$, exceeding the classical threshold of 2, while maintaining generation rates comparable to laser-based setups. These findings pave the way for sustainable quantum applications in resource-limited environments like interplanetary missions."}
{"id": "2602.15706", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15706", "abs": "https://arxiv.org/abs/2602.15706", "authors": ["Yun-Hsuan Chen", "Jen-Yu Chang", "Tsung-Wei Huang", "En-Jui Kuo"], "title": "Meta-Learning for GPU-Accelerated Quantum Many-Body Problems", "comment": null, "summary": "We explore the industrial and scientific applicability of the VQE-LSTM framework by integrating meta-learning with GPU accelerated quantum simulation using NVIDIA's CUDA-Q (CUDAQ) platform. This work demonstrates how an LSTM-FC meta-initialization module can extend the practical reach of the Variational Quantum Eigensolver (VQE) in both chemistry and physics domains. In the chemical regime, the framework predicts ground-state energies of molecular Hamiltonians derived from PySCF, achieving near FCI accuracy while maintaining favorable O(N^2) scaling with molecular size. In the physical counterpart, we applied the same model to quantized Simple Harmonic Motion systems (SHM), successfully reproducing its ground and excited states through VQE and Variational Quantum Deflation (VQD) methods. Benchmark results on NVIDIA GPUs reveal significant speedups over CPU-based implementations, validating CUDAQ's capability to handle large-scale variational workloads efficiently. Overall, this study establishes VQE-LSTM as a viable and scalable approach for GPU accelerated quantum simulation, bridging quantum chemistry and condensed-matter physics through a unified, meta-learned initialization strategy."}
{"id": "2602.15790", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15790", "abs": "https://arxiv.org/abs/2602.15790", "authors": ["Hans C. Fogedby"], "title": "Steady state coherence in a qubit is incompatible with a quantum map", "comment": "4 pages latex, 1 figure", "summary": "We consider the issue of steady state coherences in a single qubit in the case of a composite system-bath interaction as proposed in \\cite{Guarnieri18}. Based on a field theoretical approach we reanalyse the issue within a Redfield description. We find that the Redfield approach in accordance with \\cite{Guarnieri18} yields steady state coherences but violating the properties of a quantum map also gives rise to negative populations. The issue is resolved by applying the Lindblad equation which is in accordance with a proper quantum map. The Lindblad equation, however, also implies the absence of steady state coherence. We conclude that steady state coherence in a a qubit is incompatible with a quantum map."}
{"id": "2602.15800", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.15800", "abs": "https://arxiv.org/abs/2602.15800", "authors": ["Aabhas Gulati", "Ion Nechita", "Clément Pellegrini"], "title": "Entanglement in the Dicke subspace", "comment": "64 pages. Comments welcome!", "summary": "In this paper, we provide a complete mathematical theory for the entanglement of mixtures of Dicke states. These quantum states form an important subclass of bosonic states arising in the study of indistinguishable particles. We introduce a tensor-based parametrization where the diagonal entries of these states are encoded as a symmetric tensor, enabling a direct translation between entanglement properties and well-studied convex cones of tensors. Our results bridge multipartite entanglement theory with semialgebraic geometry and the theory of completely positive and copositive tensors. This dictionary maps separability to completely positive tensors, the PPT property to moment tensors, entanglement witnesses to copositive tensors, and decomposable witnesses to sum of squares tensors. Using this framework, we construct explicit PPT entangled states in three or more qutrits. In this class of states, we establish that PPT entanglement exists for all multipartite systems with three qutrits or more, disproving a recent conjecture in [J. Math. Phys. 66, 022203 (2025)]. We also show that, for mixtures of Dicke states, the PPT condition with respect to the most balanced bipartition implies PPT with respect to any other bipartition. We further connect bosonic extendibility of mixtures of Dicke states to the duals of known hierarchies for non-negative polynomials, such as the ones by Reznick and Polya. We thus provide semidefinite programming relaxations for separability and entanglement testing in the Dicke subspace."}
{"id": "2602.15826", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15826", "abs": "https://arxiv.org/abs/2602.15826", "authors": ["Sofia Arranz Regidor", "Matthew Kozma", "Stephen Hughes"], "title": "QwaveMPS: An efficient open-source Python package for simulating non-Markovian waveguide-QED using matrix product states", "comment": "23 pages, 14 figures", "summary": "QwaveMPS is an open-source Python library for simulating one-dimensional quantum many-body waveguide systems using matrix product states (MPS). It provides a user-friendly interface for constructing, evolving, and analyzing quantum states and operators, facilitating studies in quantum physics and quantum information with waveguide QED systems. This approach enables efficient, scalable simulations by focusing computational resources on the most relevant parts of the quantum system. Thus, one can study a wide range of complex dynamical interactions, including time-delayed feedback effects in the non-Markovian regime and deeply non-linear systems, at a highly reduced computational cost compared to full Hilbert space approaches, making it both practical and convenient to model a variety of open waveguide-QED systems (in Markovian and non-Markovian regimes), treating quantized atoms and quantized photons on an equal footing."}
{"id": "2602.15051", "categories": ["physics.soc-ph", "physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15051", "abs": "https://arxiv.org/abs/2602.15051", "authors": ["Mauritz Kop"], "title": "The Nexus of Quantum Technology, Intellectual Property, and National Security: An LSI Test for Securing the Quantum Industrial Commons", "comment": null, "summary": "Our world of power and national security is increasingly probabilistic: like a quantum wavefunction, it encodes multiple plausible futures until policy choices and shocks collapse them into observable outcomes. Quantum technologies have moved from laboratory curiosities to strategic infrastructure, with an approaching 'event horizon' reflected in recent United States strategic assessments -- incl. the U.S. --China Economic and Security Review Commission's (USSC) call for a Quantum First posture by 2030- and in parallel White House initiatives aimed at securing critical inputs and accelerating trusted innovation. Government research further documents that China's quantum program is centrally mobilized under military-civil fusion, and that its consequential advantages may arise not only from computing milestones but also from sensing and cryptanalytic applications, thereby sharpening the need for a values based deterrence by denial governance posture. The Article's central claim is that the U.S. and its allies should pursue security-sufficient openness, operationalized through a least-trade-restrictive, security-sufficient, innovation-preserving (LSI) test that disciplines both state and private action. The LSI test integrates emerging instruments of economic statecraft to create secure closed loop enclaves for high-sensitivity collaborative R&D. The Article's contribution is an implementable coalition playbook, offering empirically anchored criteria, templates, and differentiated guardrails -- incl. red zone domains where denial is the default -- to avoid both over-securitization and under-securitization. Properly applied, LSI reduces the risk of a self-defeating Silicon Curtain while establishing standards-first interoperability as a stabilizing eigenstate of the international order and enabling RQT by design to shape trusted adoption pathways beyond the coalition, incl. in the majority world."}
{"id": "2602.15098", "categories": ["cond-mat.stat-mech", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15098", "abs": "https://arxiv.org/abs/2602.15098", "authors": ["Yongao Hu", "Felix Gerken", "Thore Posske"], "title": "Hidden Twisted Sectors and Exponential Degeneracy in Root-of-Unity XXZ Heisenberg Chains", "comment": "20 pages, 7 figures", "summary": "Recently, product states have been identified as simple-structured eigenstates of XXZ Heisenberg spin models in arbitrary dimensions, occurring at anisotropy values corresponding to certain roots of unity. Yet, the product states typically only span parts of a larger degenerate eigenspace. Here, we classify this eigenspace in the one-dimensional periodic XXZ chain at all roots of unity $q$, where $q^2$ is an $\\ell$-th primitive root of unity. For commensurate chain lengths $N$ with $q^N=1$, we prove that the minimal degeneracy is $2^{N/\\ell}\\ell$ using the representation theory of the affine Temperley-Lieb (aTL) algebra. For the incommensurate case, we derive analogous exponential lower bounds of $2^{2\\lfloor\\frac{N}{2\\ell}\\rfloor+1}$ if $N$ is even and $2^{2\\lfloor \\frac{N}{2\\ell}+\\frac{1}{2}\\rfloor}$ if $N$ is odd and $q^\\ell=1$. Our proof employs the morphisms between aTL modules discovered by Pinet and Saint-Aubin and emphasizes the importance of exact sequences and hidden twisted boundary condition sectors that mediate the degeneracy. In the case of commensurate chain lengths, we connect to the Fabricius-McCoy string construction of all Bethe roots of the degenerate subspace, which previously uncovered parts of our results. We corroborate our results numerically and demonstrate that the lower bound is saturated for chain lengths $N\\leq20$. Our work demonstrates for a concrete system how the interplay of the Bethe ansatz, aTL representation theory, and twisted boundary conditions explains degeneracy connected to long-lived product states, stimulating research towards generalization to higher dimensions. Exponential degeneracy could boost applications of spin chains as quantum sensors."}
{"id": "2602.15122", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15122", "abs": "https://arxiv.org/abs/2602.15122", "authors": ["Angelo Russotto", "Filiberto Ares", "Pasquale Calabrese", "Vincenzo Alba"], "title": "Inhomogeneous quenches and GHD in the $ν= 1$ QSSEP model", "comment": "24 pages, 7 figures", "summary": "We investigate the dynamics of the $ν=1$ Quantum Symmetric Simple Exclusion Process starting from spatially inhomogeneous initial states. This one-dimensional system of free fermions has time-dependent stochastic hopping amplitudes that are uniform in space. We focus on two paradigmatic setups: domain-wall melting and the expansion of a trapped gas. Both are investigated by extending the framework of quantum generalized hydrodynamics to account for the underlying stochastic dynamics. We derive the evolution of the local quasiparticle occupation function, which characterizes the system at large space-time scales, and analyze the resulting entanglement spreading. By incorporating quantum fluctuations of the occupation function and employing conformal field theory techniques, we obtain the exact contribution to the entanglement entropy for each individual noise realization. Averaging over these realizations then yields the full entanglement statistics in the hydrodynamic regime. Our theoretical predictions are confirmed by exact numerical calculations. The results presented here constitute the first application of quantum generalized hydrodynamics to stochastic quantum systems, demonstrating that this framework can be successfully extended beyond purely unitary dynamics to include stochastic effects."}
{"id": "2602.15406", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.15406", "abs": "https://arxiv.org/abs/2602.15406", "authors": ["Yefeng Song", "Junxiao Chen", "Xiangyu Yang", "Mingdi Xu", "Xiang-Ping Jiang", "Lei Pan"], "title": "Quantum Pontus--Mpemba Effect in Dissipative Quasiperiodic Chains", "comment": "All comments are welcome!", "summary": "We investigate how quasiperiodic spatial structure enables protocol-induced acceleration in open quantum systems by analyzing the Pontus-Mpemba effect in one-dimensional chains subject to Markovian dephasing. The dynamics are governed by a Lindblad superoperator that drives all initial states toward a maximally mixed infinite-temperature steady state, isolating dynamical mechanisms from static equilibrium properties. Considering two representative quasiperiodic models, namely a tight-binding chain with a mosaic potential and its extension with power-law long-range hopping, we show that a properly engineered two-step protocol, in which the system is first steered to a finite temperature intermediate state, yields a strictly shorter overall relaxation time than direct evolution from the same initial configuration. This protocol-induced acceleration persists for both initially localized and extended eigenstates and remains robust in the presence of long-range hopping. A Liouvillian spectral analysis reveals that the mechanism originates from a redistribution of spectral weight that suppresses overlap with the slowest decay modes, rather than from any modification of the decay spectrum itself. Our results establish quasiperiodic chains as a controlled setting for engineering relaxation pathways through Liouvillian spectral structure."}
