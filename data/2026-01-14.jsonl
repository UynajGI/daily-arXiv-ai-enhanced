{"id": "2601.07914", "categories": ["cond-mat.str-el", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2601.07914", "abs": "https://arxiv.org/abs/2601.07914", "authors": ["Grigor Adamyan", "Bastian Pradenas", "Boris Ivanov", "Oleg Tchernyshyov"], "title": "Geometric Spin Rotation in Triangular Antiferromagnets", "comment": "5 pages, 2 figures", "summary": "We describe a geometric phenomenon in which a traveling wave made of degenerate Goldstone modes leaves behind a transformed ground state. In a triangular Heisenberg antiferromagnet, a pulse of circularly polarized spin waves rotates the spins within their plane. An exact solution of the nonlinear equations of motion demonstrates that the accumulated rotation is a geometric phase related to parallel transport of the order parameter. We point out a curious analogy between the motion of the magnetic order parameter and that of a wobbling coin. This phenomenon opens a new route for controlling antiferromagnetic order by spin waves and may extend to other frustrated magnets as well as other physical systems with noncommuting broken-symmetry generators."}
{"id": "2601.07923", "categories": ["cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.07923", "abs": "https://arxiv.org/abs/2601.07923", "authors": ["Hao-Ran Cui", "Hart Goldman"], "title": "Extraordinary boundary correlations at deconfined quantum critical points", "comment": "55 pages, 2 figures", "summary": "Recent years have seen a growing appreciation for the effects of quantum critical fluctuations on gapless boundary degrees of freedom. Here we consider the boundary dynamics of the non-compact $\\mathbb{CP}^{N-1}$ (NCCP$^{N-1}$) model in two spatial dimensions, with $N$ complex boson species coupled to a fluctuating $\\mathrm{U}(1)$ gauge field. These models describe quantum phase transitions beyond the Landau paradigm, such as the deconfined quantum critical point between superconducting (SC) and quantum spin Hall (QSH) phases. We show that, in a large-$N$ limit and with the bulk tuned to criticality, boundaries of the NCCP$^{N-1}$ model display logarithmically decaying, or ``extraordinary-log,'' correlations. In particular, when monopole operators exhibit quasi-long-ranged order at the boundary, we find that the extraordinary-log exponent of the NCCP$^{N-1}$ model in the large-$N$ limit is $q=N/4$, signifying a new family of boundary universality classes parameterized by $N$. In the context of the QSH -- SC transition, the quantum critical point inherits helical edge modes from the QSH phase, and this extraordinary-log behavior manifests in their Cooper pair correlations."}
{"id": "2601.08239", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.08239", "abs": "https://arxiv.org/abs/2601.08239", "authors": ["Jiajun Ma", "Jiaxing Liao", "Yazhou Li", "Yuwei Zhang", "Jialu Wang", "Jinke Bao", "Yan Sun", "Shuang Jia", "Yuke Li"], "title": "Large room temperature anomalous Nernst effect coupled with topological Nernst effect from incommensurate spin structure in a Kagome antiferromagnet", "comment": "12 pages, 4 figures", "summary": "Kagome magnets exhibit a range of novel and nontrivial topological properties due to the strong interplay between topology and magnetism, which also extends to their thermoelectric applications. Recent advances in the study of magnetic topological materials have highlighted their intriguing anomalous Hall and thermoelectric effects, arising primarily from large intrinsic Berry curvature. Here, we report observation of a large room-temperature (RT) anomalous Nernst effects (ANE) of S_xy^A ~ 1.3 μV K^(-1) in the kagome antiferromagnet (AFM) ErMn6Sn6, which is comparable to the largest signals observed in known magnetic materials. Surprisingly, we further found that a significant topological Nernst signal at RT and peaking a maximum of approximately 0.2 μV K^(-1) at 180 K, exactly coupling with ANE in the spiral AFM state, originates from the real-space nonzero spin chirality caused by incommensurate spin structure. This study demonstrates a potential room-temperature thermoelectric application platform based on Nernst effect, and provides insights for discovering significant anomalous and topological transverse transport effects in the incommensurate AFM system."}
{"id": "2601.08376", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.08376", "abs": "https://arxiv.org/abs/2601.08376", "authors": ["Masahiro Kawamata", "Ryuji Higashinaka", "Takeshi Matsumura", "Maxim Avdeev", "Kazuaki Iwasa", "Hironori Nakao", "Kazumasa Hattori", "Tatsuma D. Matsuda"], "title": "Collinear Magnetic Structure in the Diamond Network Magnet EuTi$_2$Al$_{20}$", "comment": null, "summary": "The magnetic structure of EuTi$_2$Al$_{20}$, in which magnetic Eu$^{2+}$ ions form a diamond network, was investigated using neutron and resonant X-ray diffraction on powder and single-crystal samples. The propagation vector was determined to be $\\textbf{\\textit{q}}_{\\rm m}=(1,0,0)$~r.l.u. from these diffraction measurements. All possible magnetic structures in the space group $Fd\\bar{3}m$ with this propagation vector were examined using the irreducible representation method and magnetic space group analysis. This magnetic structure was identified as a collinear antiferromagnetic structure with the magnetic space group $P_Inna$ (\\#52.320) or $P_Inn2$ (\\#34.164) under zero magnetic field. In these magnetic structure, frustration arises from competing magnetic interactions on the diamond network. These findings provide a concrete experimental reference for assessing the role of competing interactions in diamond-network magnets and motivate further studies of interaction-driven quantum states."}
{"id": "2601.07884", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07884", "abs": "https://arxiv.org/abs/2601.07884", "authors": ["Xiaodan Wang", "Yanbin Liu", "Shiqing Wu", "Ziying Zhao", "Yuxuan Hu", "Weihua Li", "Quan Bai"], "title": "Ideological Isolation in Online Social Networks: A Survey of Computational Definitions, Metrics, and Mitigation Strategies", "comment": "31 pages, double column, submitted to the Information Sciences journal for review", "summary": "The proliferation of online social networks has significantly reshaped the way individuals access and engage with information. While these platforms offer unprecedented connectivity, they may foster environments where users are increasingly exposed to homogeneous content and like-minded interactions. Such dynamics are associated with selective exposure and the emergence of filter bubbles, echo chambers, tunnel vision, and polarization, which together can contribute to ideological isolation and raise concerns about information diversity and public discourse. This survey provides a comprehensive computational review of existing studies that define, analyze, quantify, and mitigate ideological isolation in online social networks. We examine the mechanisms underlying content personalization, user behavior patterns, and network structures that reinforce content-exposure concentration and narrowing dynamics. This paper also systematically reviews methodological approaches for detecting and measuring these isolation-related phenomena, covering network-, content-, and behavior-based metrics. We further organize computational mitigation strategies, including network-topological interventions and recommendation-level controls, and discuss their trade-offs and deployment considerations. By integrating definitions, metrics, and interventions across structural/topological, content-based, interactional, and cognitive isolation, this survey provides a unified computational framework. It serves as a reference for understanding and addressing the key challenges and opportunities in promoting information diversity and reducing ideological fragmentation in the digital age."}
{"id": "2601.07967", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.07967", "abs": "https://arxiv.org/abs/2601.07967", "authors": ["Ludovico Bruni Bruno", "Giacomo Cappellazzo", "Wolfgang Erb", "Mohammad Karimnejad Esfahani"], "title": "Scattered Data Histopolation in Averaging Kernel Hilbert Spaces", "comment": "27 pages, 8 figures, 1 table", "summary": "Kernel-based methods offer a powerful and flexible mathematical framework for addressing histopolation problems. In histopolation, the available input data does not consist of pointwise function samples but of averages taken over intervals or higher-dimensional regions, and these mean values serve as a basis for reconstructing or approximating the target function. While classical interpolation requires continuity of the underlying function, histopolation can be performed in larger function spaces. In the framework of kernel methods, we will introduce and study the so-called averaging kernel Hilbert spaces (AKHS's) for this purpose. Within this setting, we develop systematic construction principles for averaging kernels and provide characterizations based on the Fourier-Plancherel transform. In addition, we analyze several representative histopolation scenarios in order to highlight properties of this approximation method, including conditions for unisolvence and possible error estimates. Finally, we present numerical experiments that shed some light on the convergence behavior of the presented approach and demonstrate its practical effectiveness."}
{"id": "2601.08663", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.08663", "abs": "https://arxiv.org/abs/2601.08663", "authors": ["Heping Fang", "Peng Yang"], "title": "Efficient Parameter Calibration of Numerical Weather Prediction Models via Evolutionary Sequential Transfer Optimization", "comment": "14 pages, 6 figures, 4 tables", "summary": "The configuration of physical parameterization schemes in Numerical Weather Prediction (NWP) models plays a critical role in determining the accuracy of the forecast. However, existing parameter calibration methods typically treat each calibration task as an isolated optimization problem. This approach suffers from prohibitive computational costs and necessitates performing iterative searches from scratch for each task, leading to low efficiency in sequential calibration scenarios. To address this issue, we propose the SEquential Evolutionary Transfer Optimization (SEETO) algorithm driven by the representations of the meteorological state. First, to accurately measure the physical similarity between calibration tasks, a meteorological state representation extractor is introduced to map high-dimensional meteorological fields into latent representations. Second, given the similarity in the latent space, a bi-level adaptive knowledge transfer mechanism is designed. At the solution level, superior populations from similar historical tasks are reused to achieve a \"warm start\" for optimization. At the model level, an ensemble surrogate model based on source task data is constructed to assist the search, employing an adaptive weighting mechanism to dynamically balance the contributions of source domain knowledge and target domain data. Extensive experiments across 10 distinct calibration tasks, which span varying source-target similarities, highlight SEETO's superior efficiency. Under a strict budget of 20 expensive evaluations, SEETO achieves a 6% average improvement in Hypervolume (HV) over two state-of-the-art baselines. Notably, to match SEETO's performance at this stage, the comparison algorithms would require an average of 64% and 28% additional evaluations, respectively. This presents a new paradigm for the efficient and accurate automated calibration of NWP model parameters."}
{"id": "2601.07926", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.07926", "abs": "https://arxiv.org/abs/2601.07926", "authors": ["Massimo Bernaschi", "Luis Antonio Fernández", "Isidoro González-Adalid Pemartín", "Víctor Martín-Mayor", "Giorgio Parisi", "Federico Ricci-Tersenghi"], "title": "Low energy excitations in a long prism geometry: computing the lower critical dimension of the Ising spin glass", "comment": null, "summary": "We propose a general method for studying systems that display excitations with arbitrarily low energy in their low-temperature phase. We argue that in a rectangular right prism geometry, with longitudinal size much larger than the transverse size, correlations decay exponentially (at all temperatures) along the longitudinal dimension, but the scaling of the correlation length with the transverse size carries crucial information from which the lower critical dimension can be inferred. The method is applied in the particularly demanding context of Ising spin glasses at zero magnetic field. The lower critical dimension and the multifractal spectrum for the correlation function are computed from large-scale numerical simulations. Several technical novelties (such as the unexpectedly crucial performance of Houdayer's cluster method or the convenience of using open - rather than periodic - boundary conditions) allow us to study three-dimensional prisms with transverse dimensions up to $L=24$ and effectively infinite longitudinal dimensions down to low temperatures. The value that we find for the lower critical dimension turns out to be in agreement with expectations from both the Replica Symmetry Breaking theory and the Droplet model for spin glasses. We argue that our novel setting holds promise in clarifying which of the two competing theories more accurately describes three-dimensional spin glasses."}
{"id": "2601.07993", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.07993", "abs": "https://arxiv.org/abs/2601.07993", "authors": ["Damjana Kokol Bukovšek", "Petra Lazić", "Blaž Mojškerc", "Nik Stopar"], "title": "The exact region determined by Spearman's footrule, Gini's gamma and Kendall's tau", "comment": "24 pages, 5 figures", "summary": "Concordance measures are used to express the degree of association between random variables. Practitioners may use several distinct concordance measures to narrow the space of possible dependence structures. Consequently, the relations between different (weak) concordance measures have been extensively studied in recent years. The goal of this paper is to study the relation between Kendall's tau, Gini's gamma and Spearman's footrule. In particular, we describe the exact region determined by these three measures, using shuffles of $M$ and ordinal sums of copulas. We also provide the formulas for five main (weak) concordance measures and Chatterjee's xi of ordinal sums of copulas."}
{"id": "2601.08540", "categories": ["q-fin.RM"], "pdf": "https://arxiv.org/pdf/2601.08540", "abs": "https://arxiv.org/abs/2601.08540", "authors": ["Shiyu Zhang", "Zining Wang", "Jin Zheng", "John Cartlidge"], "title": "Systemic Risk in DeFi: A Network-Based Fragility Analysis of TVL Dynamics", "comment": "9 pages, 7 figures", "summary": "Systemic risk refers to the overall vulnerability arising from the high degree of interconnectedness and interdependence within the financial system. In the rapidly developing decentralized finance (DeFi) ecosystem, numerous studies have analyzed systemic risk through specific channels such as liquidity pressures, leverage mechanisms, smart contract risks, and historical risk events. However, these studies are mostly event-driven or focused on isolated risk channels, paying limited attention to the structural dimension of systemic risk. Overall, this study provides a unified quantitative framework for ecosystem-level analysis and continuous monitoring of systemic risk in DeFi. From a network-based perspective, this paper proposes the DeFi Correlation Fragility Indicator (CFI), constructed from time-varying correlation networks at the protocol category level. The CFI captures ecosystem-wide structural fragility associated with correlation concentration and increasing synchronicity. Furthermore, we define a Risk Contribution Score (RCS) to quantify the marginal contribution of different protocol types to overall systemic risk. By combining the CFI and RCS, the framework enables both the tracking of time-varying systemic risk and identification of structurally important functional modules in risk accumulation and amplification."}
{"id": "2601.07864", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.07864", "abs": "https://arxiv.org/abs/2601.07864", "authors": ["Mengta Chung"], "title": "A Symmetric Random Scan Collapsed Gibbs Sampler for Fully Bayesian Variable Selection with Spike-and-Slab Priors", "comment": null, "summary": "We introduce a symmetric random scan Gibbs sampler for scalable Bayesian variable selection that eliminates storage of the full cross-product matrix by computing required quantities on-the-fly. Data-informed proposal weights, constructed from marginal correlations, concentrate sampling effort on promising candidates while a uniform mixing component ensures theoretical validity. We provide explicit guidance for selecting tuning parameters based on the ratio of signal to null correlations, ensuring adequate posterior exploration. The posterior-mean-size selection rule provides an adaptive alternative to the median probability model that automatically calibrates to the effective signal density without requiring an arbitrary threshold. In simulations with one hundred thousand predictors, the method achieves sensitivity of 1.000 and precision above 0.76. Application to a genomic dataset studying riboflavin production in Bacillus subtilis identifies six genes, all validated by previous studies using alternative methods. The underlying model combines a Dirac spike-and-slab prior with Laplace-type shrinkage: the Dirac spike enforces exact sparsity by setting inactive coefficients to precisely zero, while the Laplace-type slab provides adaptive regularization for active coefficients through a local-global scale mixture."}
{"id": "2601.07956", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.07956", "abs": "https://arxiv.org/abs/2601.07956", "authors": ["Harrison M. Bonner", "Matthew R. Kirchner"], "title": "Human as an Actuator Dynamic Model Identification", "comment": "To appear in the 2026 IEEE Aerospace Conference", "summary": "This paper presents a method for estimating parameters that form a general model for human pilot response for specific tasks. The human model is essential for the dynamic analysis of piloted vehicles. Data are generated on a simulator with multiple trials being incorporated to find the single model that best describes the data. The model is found entirely in the time domain by constructing a constrained optimization problem. This optimization problem implicitly represents the state of the underlying system, making it robust to natural variation in human responses. It is demonstrated by estimating the human response model for a position control task with a quadcopter drone."}
{"id": "2601.07956", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.07956", "abs": "https://arxiv.org/abs/2601.07956", "authors": ["Harrison M. Bonner", "Matthew R. Kirchner"], "title": "Human as an Actuator Dynamic Model Identification", "comment": "To appear in the 2026 IEEE Aerospace Conference", "summary": "This paper presents a method for estimating parameters that form a general model for human pilot response for specific tasks. The human model is essential for the dynamic analysis of piloted vehicles. Data are generated on a simulator with multiple trials being incorporated to find the single model that best describes the data. The model is found entirely in the time domain by constructing a constrained optimization problem. This optimization problem implicitly represents the state of the underlying system, making it robust to natural variation in human responses. It is demonstrated by estimating the human response model for a position control task with a quadcopter drone."}
{"id": "2601.07837", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.07837", "abs": "https://arxiv.org/abs/2601.07837", "authors": ["Elvin Rada"], "title": "Convergence of a Multi-Inertial-Iteration Scheme in Cone b, p-Normed Banach Spaces", "comment": null, "summary": "We propose and analyze a multi-inertial-iteration scheme in cone b, p-normed Banach spaces. This framework extends the classical Krasnoselskii-Mann and two-step inertial iterations by incorporating three independent inertial parameters and multiple error-control sequences. Under mild assumptions such as quasi-nonexpansiveness, weak contraction, and compatibility of mappings, we establish convergence theorems guaranteeing the existence and uniqueness of fixed points. Illustrative numerical examples demonstrate accelerated convergence compared with the classical Krasnoselskii-Mann method."}
{"id": "2601.07851", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.07851", "abs": "https://arxiv.org/abs/2601.07851", "authors": ["Phuong-Nam Nguyen"], "title": "LOTUS: Layer-ordered Temporally Unified Schedules For Quantum Approximate Optimization Algorithms", "comment": null, "summary": "In this paper, we introduce LOTUS (Layer-Ordered Temporally-Unified Schedules), which is a framework that restructures QAOA from a high-dimensional, chaotic search into a low-dimensional dynamical system. By replacing independent layer-wise angles with a Hybrid Fourier-Autoregressive (HFA) mapping, LOTUS enforces global temporal coherence while maintaining local flexibility. LOTUS consistently outperforms standard optimizers, achieving up to a $27.2\\%$ improvement in expectation values over L-BFGS-B and $20.8\\%$ compared with COBYLA. Besides, our proposed method drastically reduces computational costs, requiring over $90\\%$ fewer iterations than methods like Powell or SLSQP."}
{"id": "2601.08356", "categories": ["physics.geo-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.08356", "abs": "https://arxiv.org/abs/2601.08356", "authors": ["Sudip Sarkar", "Soumyajyoti Biswas"], "title": "Large earthquakes follow highly unequal ones", "comment": "6 pages, 7 figures", "summary": "It was conjectured for a long time that the tectonic plates are in a self-organized state of criticality and that the Gutenberg-Richter (power) law is a manifestation of that. It was recently shown that for a system near criticality, the inequality of their responses toward external driving could indicate proximity to the critical point. In this work, we show with numerical simulations and seismic data analysis that large earthquake events have a tendency to follow events that are highly unequal. We have applied this framework to various tectonically active regions, such as North America, Southern Japan, parts of South-East Asia and Indonesia."}
{"id": "2601.07943", "categories": ["cond-mat.stat-mech", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.07943", "abs": "https://arxiv.org/abs/2601.07943", "authors": ["Francesco Coghi", "Amarjit Budhiraja", "Juan P. Garrahan"], "title": "Level 2.5 large deviations and uncertainty relations for non-Markov self-interacting dynamics", "comment": "6 pages, 1 figure", "summary": "We address the general problem of formulating the dynamical large deviations of non-Markovian systems in a closed form. Specifically, we consider a broad class of ``self-interacting'' jump processes whose dynamics depends on the past through a functional of a state-dependent empirical observable. Exploiting a natural separation of timescales, we obtain the exact (so-called ``level 2.5'') large deviation joint statistics of the empirical measure over configurations and of the empirical flux of transitions. As an application of this general framework, we derive explicit general bounds on the fluctuations of trajectory observables, generalising to the non-Markovian case both thermodynamic and kinetic uncertainty relations. We illustrate our theory with simple examples, and discuss potential applications of these results."}
{"id": "2601.08552", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.08552", "abs": "https://arxiv.org/abs/2601.08552", "authors": ["Tu Hong", "Kun Chen", "Xiao Yan Xu"], "title": "Linear Canonical-Ensemble Quantum Monte Carlo: From Dilute Fermi Gas to Flat-Band Ferromagnetism", "comment": "5+11 pages, 4+2 figures", "summary": "We present a finite-temperature canonical-ensemble determinant quantum Monte Carlo algorithm that enforces an exact fermion number and enables stable simulations of correlated lattice electrons. We propose a stabilized QR update that reduces the computational complexity from standard cubic scaling $O(βN^3)$ to linear scaling $O(βN N_e^2)$ with respect to the system size $N$, where $N_e$ is the particle number. This yields a dramatic speedup in dilute regimes ($N_e \\ll N$), opening unbiased access to large-scale simulations of strongly correlated low-density phases. We validate the method on the dilute electron gas with onsite Hubbard interactions, observing the suppression of the fermion sign problem in the dilute limit. Furthermore, we apply this approach to an one-dimensional flat-band system, where the canonical ensemble allows for precise control over filling. We reveal a ferromagnetic instability at low temperatures in the half-filling regime. Our linear-scaling approach provides a powerful tool for investigating emergent phenomena in dilute quantum matter."}
{"id": "2601.08554", "categories": ["cs.SI", "cs.DB", "cs.GR"], "pdf": "https://arxiv.org/pdf/2601.08554", "abs": "https://arxiv.org/abs/2601.08554", "authors": ["Chunxu Lin", "Yumao Xie", "Yixiang Fang", "Yongmin Hu", "Yingqian Hu", "Chen Cheng"], "title": "Efficient Maintenance of Leiden Communities in Large Dynamic Graphs", "comment": null, "summary": "As a well-known community detection algorithm, Leiden has been widely used in various scenarios such as large language model generation (e.g., Graph-RAG), anomaly detection, and biological analysis. In these scenarios, the graphs are often large and dynamic, where vertices and edges are inserted and deleted frequently, so it is costly to obtain the updated communities by Leiden from scratch when the graph has changed. Recently, one work has attempted to study how to maintain Leiden communities in the dynamic graph, but it lacks a detailed theoretical analysis, and its algorithms are inefficient for large graphs. To address these issues, in this paper, we first theoretically show that the existing algorithms are relatively unbounded via the boundedness analysis (a powerful tool for analyzing incremental algorithms on dynamic graphs), and also analyze the memberships of vertices in communities when the graph changes. Based on theoretical analysis, we develop a novel efficient maintenance algorithm, called Hierarchical Incremental Tree Leiden (HIT-Leiden), which effectively reduces the range of affected vertices by maintaining the connected components and hierarchical community structures. Comprehensive experiments in various datasets demonstrate the superior performance of HIT-Leiden. In particular, it achieves speedups of up to five orders of magnitude over existing methods."}
{"id": "2601.08001", "categories": ["math.NA", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08001", "abs": "https://arxiv.org/abs/2601.08001", "authors": ["Qinying Chen", "Arnab Roy", "Tobin A. Driscoll"], "title": "Operator learning for models of tear film breakup", "comment": null, "summary": "Tear film (TF) breakup is a key driver of understanding dry eye disease, yet estimating TF thickness and osmolarity from fluorescence (FL) imaging typically requires solving computationally expensive inverse problems. We propose an operator learning framework that replaces traditional inverse solvers with neural operators trained on simulated TF dynamics. This approach offers a scalable path toward rapid, data-driven analysis of tear film dynamics."}
{"id": "2601.08324", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08324", "abs": "https://arxiv.org/abs/2601.08324", "authors": ["F. Iwase"], "title": "Critical quantum states and hierarchical spectral statistics in a Cantor potential", "comment": "13 pages, 6 figures", "summary": "We study the spectral statistics and wave-function properties of a one-dimensional quantum system subject to a Cantor-type fractal potential. By analyzing the nearest-neighbor level spacings, inverse participation ratio (IPR), and the scaling behavior of the integrated density of states (IDS), we demonstrate how the self-similar geometry of the potential is imprinted on the quantum spectrum. The energy-resolved level spacings form a hierarchical, filamentary structure, in sharp contrast to those of periodic and random systems. The normalized level-spacing distribution exhibits a bimodal structure, reflecting the deterministic recurrence of spectral gaps. A multifractal analysis of eigenstates reveals critical behavior: the generalized fractal dimensions $D_q$ lie strictly between the limits of extended and localized states, exhibiting a distinct $q$-dependence. Consistently, the IPR indicates the coexistence of quasi-extended and localized features, characteristic of critical wave functions. The IDS shows anomalous power-law scaling at low energies, with an exponent close to the Hausdorff dimension of the underlying Cantor set, indicating that the geometric fractality governs the spectral dimensionality. At higher energies, this scaling crosses over to the semiclassical Weyl law. Our results establish a direct connection between deterministic fractal geometry, hierarchical spectral statistics, and quantum criticality."}
{"id": "2601.08353", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.08353", "abs": "https://arxiv.org/abs/2601.08353", "authors": ["Markus Reiß", "Lars Winkelmann"], "title": "Rank tests for time-varying covariance matrices observed under noise", "comment": null, "summary": "We consider a $d$-dimensional continuous martingale $X(t)$ with quadratic variation matrix $\\langle X\\rangle_t=\\int_0^t Σ(s)\\,ds$ and develop tests for the rank of its spot covariance matrix $Σ(t)$, $t\\in[0,1]$. The process $X$ is observed under observational noise, as is standard for microstructure noise models in high-frequency finance. We test the null hypothesis ${\\mathcal H}_0:rank(Σ(t))\\le r$ against local alternatives ${\\mathcal H}_{1,n}:λ_{r+1}(Σ(t))\\ge v_n$, where $λ_{r+1}$ denotes the $(r+1)$st eigenvalue and $v_n\\downarrow 0$ as the sample size $n\\to\\infty$. We construct test statistics based on eigenvalues of carefully calibrated localized spectral covariance matrix estimates. Critical values are provided non-asymptotically as well as asymptotically via maximal eigenvalues of Gaussian orthogonal ensembles. The power analysis establishes asymptotic consistency for a separation rate $v_n\\thicksim (\\underlineλ_r^{-1/(β+1)}n^{-β/(β+1)})\\wedge n^{-β/(β+2)}$, depending on the Hölder-regularity $β$ of $Σ$ and a possible spectral gap $\\underlineλ_r\\ge 0$ under ${\\mathcal H}_0$. A lower bound shows the optimality of this rate. We discuss why the rate is much faster than conventional estimation rates. The theory is illustrated by simulations and a real data example with German government bonds of varying maturity."}
{"id": "2601.07977", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.07977", "abs": "https://arxiv.org/abs/2601.07977", "authors": ["K. Ken Peng", "Charmaine B. Dean", "Robert Delatolla", "X. Joan Hu", "Elizabeth Renouf"], "title": "Joint Modeling of Two Stochastic Processes, with Application to Learning Hospitalization Dynamics from Wastewater Viral Concentrations", "comment": null, "summary": "In the post-pandemic era of COVID-19, hospitalization remains a primary public health concern and wastewater surveillance has become an important tool for monitoring its dynamics at the level of community. However, there is usually no sufficient information to know the infection process that results in both wastewater viral signals and hospital admissions. That key challenge has motived a statistical framework proposed in this paper. We formulate the connection of overtime wastewater viral signals and hospitalization counts through a latent process of infection at the level of individual subject. We provide a strategy for accommodating aggregated data, a typical form of surveillance data. Moreover, we ease the conventional procedure of the statistical learning with the joint modeling using available information on the infection process, which can be under-reporting. A simulation study demonstrates that the proposed approach yields stable inference under different degrees of under-ascertainment. The COVID-19 surveillance data from Ottawa, Canada shows that the framework recovers coherent temporal patterns in infection prevalence and variant-specific hospitalization risk under several reporting assumptions."}
{"id": "2601.07997", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07997", "abs": "https://arxiv.org/abs/2601.07997", "authors": ["Yuwen Ma", "Sarah K. Spurgeon", "Tao Li", "Boli Chen"], "title": "Can Inherent Communication Noise Guarantee Privacy in Distributed Cooperative Control ?", "comment": null, "summary": "This paper investigates privacy-preserving distributed cooperative control for multi-agent systems within the framework of differential privacy. In cooperative control, communication noise is inevitable and is usually regarded as a disturbance that impairs coordination. This work revisits such noise as a potential privacy-enhancing factor. A linear quadratic regulator (LQR)-based framework is proposed for agents communicating over noisy channels, \\textcolor{black}{where the noise variance depends on the relative state differences between neighbouring agents.} The resulting controller achieves formation while protecting the reference signals from inference attacks. It is analytically proven that the inherent communication noise can guarantee bounded $(ε,δ)$-differential privacy without adding dedicated privacy noise, while the \\textcolor{black}{system cooperative tracking error} remains bounded and convergent in both the mean-square and almost-sure sense."}
{"id": "2601.07997", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07997", "abs": "https://arxiv.org/abs/2601.07997", "authors": ["Yuwen Ma", "Sarah K. Spurgeon", "Tao Li", "Boli Chen"], "title": "Can Inherent Communication Noise Guarantee Privacy in Distributed Cooperative Control ?", "comment": null, "summary": "This paper investigates privacy-preserving distributed cooperative control for multi-agent systems within the framework of differential privacy. In cooperative control, communication noise is inevitable and is usually regarded as a disturbance that impairs coordination. This work revisits such noise as a potential privacy-enhancing factor. A linear quadratic regulator (LQR)-based framework is proposed for agents communicating over noisy channels, \\textcolor{black}{where the noise variance depends on the relative state differences between neighbouring agents.} The resulting controller achieves formation while protecting the reference signals from inference attacks. It is analytically proven that the inherent communication noise can guarantee bounded $(ε,δ)$-differential privacy without adding dedicated privacy noise, while the \\textcolor{black}{system cooperative tracking error} remains bounded and convergent in both the mean-square and almost-sure sense."}
{"id": "2601.08153", "categories": ["math.OC", "math.FA"], "pdf": "https://arxiv.org/pdf/2601.08153", "abs": "https://arxiv.org/abs/2601.08153", "authors": ["Nguyen Duy Cuong"], "title": "Dual characterizations of norm minimization problems", "comment": "26 pages", "summary": "The paper studies a general norm minimization problem on a product of normed vector spaces. We establish dual necessary and sufficient optimality conditions and derive explicit formulas for the corresponding solution sets. These formulas are obtained under the assumption that one optimal solution together with its associated dual vectors arising from the optimality conditions is known. Three important cases of product norms, namely the sum norm, maximum norm and $p$-norm, are also studied. Several examples in finite and infinite dimensional spaces equipped with various types of norms are presented to illustrate the established results."}
{"id": "2601.07856", "categories": ["quant-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07856", "abs": "https://arxiv.org/abs/2601.07856", "authors": ["Yu Wu", "Qianli Zhou", "Jie Geng", "Xinyang Deng", "Wen Jiang"], "title": "Feature Entanglement-based Quantum Multimodal Fusion Neural Network", "comment": null, "summary": "Multimodal learning aims to enhance perceptual and decision-making capabilities by integrating information from diverse sources. However, classical deep learning approaches face a critical trade-off between the high accuracy of black-box feature-level fusion and the interpretability of less outstanding decision-level fusion, alongside the challenges of parameter explosion and complexity. This paper discusses the accuracy-interpretablity-complexity dilemma under the quantum computation framework and propose a feature entanglement-based quantum multimodal fusion neural network. The model is composed of three core components: a classical feed-forward module for unimodal processing, an interpretable quantum fusion block, and a quantum convolutional neural network (QCNN) for deep feature extraction. By leveraging the strong expressive power of quantum, we have reduced the complexity of multimodal fusion and post-processing to linear, and the fusion process also possesses the interpretability of decision-level fusion. The simulation results demonstrate that our model achieves classification accuracy comparable to classical networks with dozens of times of parameters, exhibiting notable stability and performance across multimodal image datasets."}
{"id": "2601.08021", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.08021", "abs": "https://arxiv.org/abs/2601.08021", "authors": ["Meitar Goldfarb", "Stanislav Burov"], "title": "Boundary-Induced Drift and Negative Mobility in Constrained Stochastic Systems", "comment": null, "summary": "We study overdamped stochastic dynamics confined by hard reflecting boundaries and show that the combination of boundary geometry and an anisotropic diffusion tensor generically generates directed motion. At the level of individual trajectories, the no-flux condition enforces an oblique reflection at the boundary, which produces a systematic drift parallel to the surface. The resulting local velocity takes the general form $v_B(\\mathbf{x})=\\mathbf{t}(\\mathbf{x})^{\\!\\top}\\mathbf{D}\\,\\mathbf{n}(\\mathbf{x})$, determined by the diffusion tensor $\\mathbf{D}$ and the local boundary geometry encoded in the normal $\\mathbf{n}$ and tangent $\\mathbf{t}$. While this boundary-induced drift is local, it can accumulate into a macroscopic response, depending on the statistics of boundary encounters. We illustrate how this local boundary-induced drift gives rise to macroscopic transport using a minimal one-dimensional dimer composed of two particles with unequal diffusion coefficients. The repeated collisions act as reflections in configuration space and lead to sustained center-of-mass motion, including regimes of absolute negative mobility under constant forcing."}
{"id": "2601.08072", "categories": ["nlin.CD", "nlin.SI"], "pdf": "https://arxiv.org/pdf/2601.08072", "abs": "https://arxiv.org/abs/2601.08072", "authors": ["Ashleigh Simonis", "Sergey Nazarenko", "Jalal Shatah", "Yulin Pan"], "title": "Wave kinetics in an integrable model -- the Kaup-Boussinesq system", "comment": "22 pages, 15 figures", "summary": "We study wave turbulence in one-dimensional (1-D) bidirectional shallow water waves described by the Kaup-Boussinesq (KB) equation, which is known to be an integrable system. In contrast to the generally accepted empirical belief that an integrable system yields no kinetic theory, we derive and validate a non-trivial wave kinetic equation (WKE) for the KB system with a non-zero interaction coefficient on the four-wave resonant manifold. This WKE is non-homogeneous in nature due to the non-homogeneity in the dispersion relation of the KB system; however, approximate Kolomogrov-Zakharov (KZ) solutions can be derived in a novel way under certain approximations. We numerically verify the theoretical findings in two cases: (i) In free-evolution cases, although the discrete (nonlinear) spectrum remains unchanged as guaranteed by an integrable system's isospectrality, an initial arbitrary wavenumber spectrum quickly evolves into a thermo-equilibrium state, demonstrating the kinetic aspect of the system; (ii) in forced-dissipated cases, we find stationary power-law spectra that agree with the theoretical predictions."}
{"id": "2601.08735", "categories": ["hep-lat", "hep-ex", "hep-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.08735", "abs": "https://arxiv.org/abs/2601.08735", "authors": ["Airton Deppman"], "title": "QCD phase-transition under the light of Thermofractal", "comment": "9 pages, 1 figure", "summary": "The deconfining transition in $SU(3)$ gauge theory, traditionally interpreted through the Gross-Witten-Wadia (GWW) model as a sharp third-order phase transition in the large-$N_c$ limit, appears as a smooth crossover in lattice QCD. This work demonstrates that the transition is topologically smoothed into a crossover by incorporating the fractal momentum space structure inherent to thermofractals. By matching the non-extensive $β$-function to one-loop QCD results, a fundamental scaling of the thermofractal index $q$ is derived as a function of the number of flavours $N_f$. It is proven that applying a $q$-deformed derivative operator $\\mathcal{D}_q$ to the $q$-logarithm of the eigenvalue distance results in a non-extensive measure that effectively smears the topological stiffness of the gauge vacuum. A unified master equation for the Polyakov loop $\\langle L \\rangle$ is presented, governed by the thermofractal index $q$ and a single variance parameter $σ^2(T)$ that scales as $T^{1/(q-1)}$. The observed phase dynamics are shown to be asymptotic limits of this unified density: a ``soft'' algebraic growth $\\langle L \\rangle \\propto T^{11}$ in the 1D string-like confined regime for $N_f=0$, and a rapid $1 - \\langle L \\rangle \\propto T^{-21}$ suppression in the 3D deconfined volume for $N_f=3$. This approach provides a microscopic foundation for partial deconfinement theory and reproduces lattice QCD data with a reduced $χ^2 \\approx 1.12$, offering a rigorous reconciliation between matrix model topology and the continuous QCD crossover."}
{"id": "2601.08099", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.08099", "abs": "https://arxiv.org/abs/2601.08099", "authors": ["Andrew Adamatzky"], "title": "Directional Electrical Spiking, Bursting, and Information Propagation in Oyster Mycelium Recorded with a Star-Shaped Electrode Array", "comment": null, "summary": "Electrical activity in fungal mycelium has been reported in numerous species and experimental contexts, yet its spatial organisation and propagation remain insufficiently characterised. In this study we investigate the spatiotemporal structure of electrical potential dynamics in oyster mushroom (\\textit{Pleurotus ostreatus}) mycelium colonising a wood-shavings substrate. Electrical signals were recorded using an eight-channel star-shaped differential electrode array providing angular resolution around a central region of colonised substrate. We analyse spike statistics, bursting behaviour, inter-channel correlations, and event-based propagation delays. The results reveal strong directional heterogeneity in spiking frequency and amplitude, clustered bursting dynamics, partial and localised coupling between channels, and reproducible propagation patterns across spatial sectors. Electrical bursts originate preferentially in specific directions and recruit other regions with with characteristic delays ranging from seconds to minutes to hours. These findings support the interpretation of fungal mycelium as a spatially extended excitable medium capable of slow, distributed electrical signalling and signal integration."}
{"id": "2601.07844", "categories": ["physics.soc-ph", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2601.07844", "abs": "https://arxiv.org/abs/2601.07844", "authors": ["A. Y. Klimenko", "A. Rozycki", "Y. Lu"], "title": "From Agent-Based Markov Dynamics to Hierarchical Closures on Networks: Emergent Complexity and Epidemic Applications", "comment": "22 pages, 10 figures", "summary": "We explore a rigorous formulation of agent-based SIR epidemic dynamics as a discrete-state Markov process, capturing the stochastic propagation of infection or an invading agent on networks. Using indicator functions and corresponding marginal probabilities, we derive a hierarchy of evolution equations that resembles the classical BBGKY hierarchy in statistical mechanics. The structure of these equations clarifies the challenges of closure and highlights the principal problem of systemic complexity arising from stochastic but generally not fully chaotic interactions. Monte Carlo simulations are used to validate simplified closures and approximations, offering a unified perspective on the interplay between network topology, stochasticity, and infection dynamics. We also explore the impact of lockdown measures within a networked agent framework, illustrating how SIR dynamics and structural complexity of the network shape epidemic with propagation of the COVID-19 pandemic in Northern Italy taken as an example."}
{"id": "2601.08385", "categories": ["physics.comp-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.08385", "abs": "https://arxiv.org/abs/2601.08385", "authors": ["Raj Maddipati", "Dhruthi Boddapati", "Elangannan Arunan", "Phani Motamarri", "Konduri Aditya"], "title": "ChemXDyn: Dynamics-informed species and reaction detection methodology from atomistic simulations", "comment": null, "summary": "Accurate identification of chemical species and reaction pathways from molecular dynamics (MD) trajectories is a prerequisite for deriving predictive chemical-kinetic models and for mechanistic discovery in reactive systems. However, state-of-the-art trajectory analysis methods infer bonding from instantaneous distance thresholds, which can misclassify transient, nonreactive encounters as bonds and thereby introduce spurious intermediates, distorted reaction networks, and biased rate estimates. Here, we introduce ChemXDyn, a dynamics-aware computational methodology that leverages time-resolved interatomic distance signatures as a core principle to robustly identify chemically consistent bonded interactions and, consequently, extract meaningful reaction pathways. In particular, ChemXDyn propagates molecular connectivity through time while enforcing atomic valence and coordination constraints to distinguish genuine bond-breaking and bond-forming events from transient, nonreactive encounters. We evaluate ChemXDyn on ReaxFF MD simulations of hydrogen and ammonia oxidation and on neural-network potential MD simulations of methane oxidation, and benchmark its performance against widely used trajectory analysis methods. Across these cases, ChemXDyn suppresses unphysical species prevalent in static analyses, recovers experimentally consistent reaction pathways, and improves the fidelity of rate constant estimation. In ammonia oxidation, ChemXDyn removes unphysical intermediates and resolves key NOx- and N2O-forming and -consuming routes. In methane oxidation, it reconstructs the canonical progression from CH4 to CO2. By linking atomistic dynamics to chemically consistent reaction identification, ChemXDyn provides a transferable foundation for MD-derived reaction networks and kinetics, with potential utility spanning combustion, catalysis, plasma chemistry, and electrochemical environments."}
{"id": "2601.08615", "categories": ["cond-mat.str-el", "hep-th", "math.QA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08615", "abs": "https://arxiv.org/abs/2601.08615", "authors": ["Kansei Inamura", "Shuhei Ohyama"], "title": "Generalized cluster states in 2+1d: non-invertible symmetries, interfaces, and parameterized families", "comment": "93 pages + appendices", "summary": "We construct 2+1-dimensional lattice models of symmetry-protected topological (SPT) phases with non-invertible symmetries and investigate their properties using tensor networks. These models, which we refer to as generalized cluster models, are constructed by gauging a subgroup symmetry $H \\subset G$ in models with a finite group 0-form symmetry $G$. By construction, these models have a non-invertible symmetry described by the group-theoretical fusion 2-category $\\mathcal{C}(G; H)$. After identifying the tensor network representations of the symmetry operators, we study the symmetry acting on the interface between two generalized cluster states. In particular, we will see that the symmetry at the interface is described by a multifusion category known as the strip 2-algebra. By studying possible interface modes allowed by this symmetry, we show that the interface between generalized cluster states in different SPT phases must be degenerate. This result generalizes the ordinary bulk-boundary correspondence. Furthermore, we construct parameterized families of generalized cluster states and study the topological charge pumping phenomena, known as the generalized Thouless pump. We exemplify our construction with several concrete cases, and compare them with known phases, such as SPT phases with $2\\mathrm{Rep}((\\mathbb{Z}_{2}^{[1]}\\times\\mathbb{Z}_{2}^{[1]})\\rtimes\\mathbb{Z}_{2}^{[0]})$ symmetry."}
{"id": "2601.08720", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.08720", "abs": "https://arxiv.org/abs/2601.08720", "authors": ["Monica V. Prates", "Arthur A. B. Pessa", "Sebastian Goncalves", "Matjaz Perc", "Haroldo V. Ribeiro"], "title": "Bipartite structure and dynamics of political corruption networks", "comment": "12 pages, 6 figures, accepted for publication in Physica A", "summary": "Political corruption is inherently an affiliation process linking agents to corruption cases; yet it is often studied via one-mode projections that connect co-offenders within the same scandal, implying a loss of information that potentially confounds properties of agents and cases. Here, we adopt a bipartite representation to analyze datasets of corruption scandals in Brazil and Spain spanning nearly three decades. By tracking the temporal growth of these networks, we quantify density and redundancy measures to capture partner reuse and co-occurrence across cases. Networks in both countries become progressively sparser over time, and agent redundancy is systematically higher than case redundancy, indicating a small cadre of recidivists who recombine largely with novice partners rather than forming durable co-offending ties. These networks exhibit near-exponential degree distributions, reflecting low recidivism and likely high coordination costs and secrecy constraints of large-scale scandals. Our bipartite view further reveals a moderate cross-mode disassortative degree mixing between agents and cases, with high-degree agents distributing their activity across small cases and large scandals mainly comprising low-degree participants. Finally, identifying atypical individuals within the bipartite structure reveals criminal trajectories marked by a gradual rise in network embeddedness that can appear ordinary in agent-projected networks."}
{"id": "2601.08006", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.08006", "abs": "https://arxiv.org/abs/2601.08006", "authors": ["Hamad El Kahza", "Luis Chacón", "William Taitano", "Jingmei Qiu", "Jingwei Hu"], "title": "A Structure-Preserving Penalization Method for the Single-species Rosenbluth-Fokker-Planck Equation", "comment": null, "summary": "The Rosenbluth-Fokker-Planck (RFP) equation describes Coulomb collisional dynamics within and across species in plasmas. It belongs to the broader class of anisotropic-diffusion-advection equations, whose numerical approximation is highly-nontrivial due to its nonlinearity, stiffness, and structural properties such as conservation and entropy dissipation (hence with the Maxwellian distribution as the equilibrium state). In this paper, we propose a structure-preserving penalization scheme for the stiff, single-species RFP equation. The scheme features three novel components: 1) a novel generalization of the well-known Chang-Cooper discretization for the RFP equation that is equilibrium-preserving and enables positivity while preserving mass, momentum, and energy; 2) an easy-to-invert isotropic variable-coefficient penalization operator to deal with the temporal stiffness without resorting to a fully implicit scheme, borrowing ideas from explicit-implicit-null (EIN) methods, and 3) an adaptive timestepping strategy that preserves the positivity of the full penalized scheme. The resulting scheme conserves mass, momentum, and energy strictly, is unconditionally stable, and robustly positivity preserving. The scheme is demonstrated with linear and nonlinear anisotropic diffusion examples of increasing complexity, including several single-species RFP examples."}
{"id": "2601.08347", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08347", "abs": "https://arxiv.org/abs/2601.08347", "authors": ["Maksym Serbyn", "Alexander Avdoshkin", "Oriana K. Diessel", "David A. Huse"], "title": "Eigenstate thermalization in thermal first-order phase transitions", "comment": "11 pages, 8 figures", "summary": "The eigenstate thermalization hypothesis (ETH) posits how isolated quantum many-body systems thermalize, assuming that individual eigenstates at the same energy density have identical expectation values of local observables in the limit of large systems. While the ETH apparently holds across a wide range of interacting quantum systems, in this work we show that it requires generalization in the presence of thermal first-order phase transitions. We introduce a class of all-to-all spin models, featuring first-order thermal phase transitions that stem from two distinct mean-field solutions (two ``branches'') that exchange dominance in the many-body density of states as the energy is varied. We argue that for energies in the vicinity of the thermal phase transition, eigenstate expectation values do not need to converge to the same thermal value. The system has a regime with coexistence of two classes of eigenstates corresponding to the two branches with distinct expectation values at the same energy density, and another regime with Schrodinger-cat-like eigenstates that are inter-branch superpositions; these two regimes are separated by an eigenstate phase transition. We support our results by semiclassical calculations and an exact diagonalization study of a microscopic spin model, and argue that the structure of eigenstates in the vicinity of thermal first-order phase transitions can be experimentally probed via non-equilibrium dynamics."}
{"id": "2601.08775", "categories": ["math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.08775", "abs": "https://arxiv.org/abs/2601.08775", "authors": ["Tameem Adel", "Abhishek Agarwal", "Stéphane Chrétien", "Estelle Massart", "Danila Mokeev", "Ivan Rungger", "Andrew Thompson"], "title": "A Langevin sampler for quantum tomography", "comment": null, "summary": "Quantum tomography involves obtaining a full classical description of a prepared quantum state from experimental results. We propose a Langevin sampler for quantum tomography, that relies on a new formulation of Bayesian quantum tomography exploiting the Burer-Monteiro factorization of Hermitian positive-semidefinite matrices. If the rank of the target density matrix is known, this formulation allows us to define a posterior distribution that is only supported on matrices whose rank is upper-bounded by the rank of the target density matrix. Conversely, if the target rank is unknown, any upper bound on the rank can be used by our algorithm, and the rank of the resulting posterior mean estimator is further reduced by the use of a low-rank promoting prior density. This prior density is a complex extension of the one proposed in (Annales de l'Institut Henri Poincare Probability and Statistics, 56(2):1465-1483, 2020). We derive a PAC-Bayesian bound on our proposed estimator that matches the best bounds available in the literature, and we show numerically that it leads to strong scalability improvements compared to existing techniques when the rank of the density matrix is known to be small."}
{"id": "2601.07979", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.07979", "abs": "https://arxiv.org/abs/2601.07979", "authors": ["Hanzhang Lu", "Keiran Malott", "Venkat Suprabath Bitra", "Kirsty Milligan", "Sanjeena Subedi", "Edana Cassol", "Vinita Chauhan", "Connor McNairn", "Bryan Muir", "Prarthana Pasricha", "Sangeeta Murugkar", "Rowan Thomson", "Andrew Jirasek", "Jeffrey L. Andrews"], "title": "Spatial Covariance Constraints for Gaussian Mixture Models", "comment": "19 pages, 7 figures", "summary": "Although extensive research exists in spatial modeling, few studies have addressed finite mixture model-based clustering methods for spatial data. Finite mixture models, especially Gaussian mixture models, particularly suffer from high dimensionality due to the number of free covariance parameters. This study introduces a spatial covariance constraint for Gaussian mixture models that requires only four free parameters for each component, independent of dimensionality. Using a coordinate system, the spatially constrained Gaussian mixture model enables clustering of multi-way spatial data and inference of spatial patterns. The parameter estimation is conducted by combining the expectation-maximization (EM) algorithm with the generalized least squares (GLS) estimator. Simulation studies and applications to Raman spectroscopy data are provided to demonstrate the proposed model."}
{"id": "2601.08050", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08050", "abs": "https://arxiv.org/abs/2601.08050", "authors": ["Prashant Solanki", "Isabelle El-Hajj", "Jasper van Beers", "Erik-Jan van Kampen", "Coen de Visser"], "title": "Formalizing the Relationship between Hamilton-Jacobi Reachability and Reinforcement Learning", "comment": null, "summary": "We unify Hamilton-Jacobi (HJ) reachability and Reinforcement Learning (RL) through a proposed running cost formulation. We prove that the resultant travel-cost value function is the unique bounded viscosity solution of a time-dependent Hamilton-Jacobi Bellman (HJB) Partial Differential Equation (PDE) with zero terminal data, whose negative sublevel set equals the strict backward-reachable tube. Using a forward reparameterization and a contraction inducing Bellman update, we show that fixed points of small-step RL value iteration converge to the viscosity solution of the forward discounted HJB. Experiments on a classical benchmark compare learned values to semi-Lagrangian HJB ground truth and quantify error."}
{"id": "2601.08050", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08050", "abs": "https://arxiv.org/abs/2601.08050", "authors": ["Prashant Solanki", "Isabelle El-Hajj", "Jasper van Beers", "Erik-Jan van Kampen", "Coen de Visser"], "title": "Formalizing the Relationship between Hamilton-Jacobi Reachability and Reinforcement Learning", "comment": null, "summary": "We unify Hamilton-Jacobi (HJ) reachability and Reinforcement Learning (RL) through a proposed running cost formulation. We prove that the resultant travel-cost value function is the unique bounded viscosity solution of a time-dependent Hamilton-Jacobi Bellman (HJB) Partial Differential Equation (PDE) with zero terminal data, whose negative sublevel set equals the strict backward-reachable tube. Using a forward reparameterization and a contraction inducing Bellman update, we show that fixed points of small-step RL value iteration converge to the viscosity solution of the forward discounted HJB. Experiments on a classical benchmark compare learned values to semi-Lagrangian HJB ground truth and quantify error."}
{"id": "2601.08362", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.08362", "abs": "https://arxiv.org/abs/2601.08362", "authors": ["Chenglong Bao", "Chao Ding", "Fuxiaoyue Feng", "Jingyu Li"], "title": "Stratification for Nonlinear Semidefinite Programming", "comment": "48 pages, 2 figures", "summary": "This paper introduces a stratification framework for nonlinear semidefinite programming (NLSDP) that reveals and utilizes the geometry behind the nonsmooth KKT system. Based on the \\emph{index stratification} of $\\mathbb{S}^n$ and its lift to the primal--dual space, a stratified variational analysis is developed. Specifically, we define the stratum-restricted regularity property, characterize it by the verifiable weak second order condition (W-SOC) and weak strict Robinson constraint qualification (W-SRCQ), and interpret the W-SRCQ geometrically via transversality, which provides its genericity over ambient space and stability along strata. The interactions of these properties across neighboring strata are further examined, leading to the conclusion that classical strong-form regularity conditions correspond to the local uniform validity of stratum-restricted counterparts. On the algorithmic side, a stratified Gauss--Newton method with normal steps and a correction mechanism is proposed for globally solving the KKT equation through a least-squares merit function. We demonstrate that the algorithm converges globally to directional stationary points. Moreover, under the W-SOC and the strict Robinson constraint qualification (SRCQ), it achieves local quadratic convergence to KKT pairs and eventually identifies the active stratum."}
{"id": "2601.07860", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.07860", "abs": "https://arxiv.org/abs/2601.07860", "authors": ["Soham Bhadra", "Diyansha Singh", "Angana Chowdhury"], "title": "Fault-Tolerant Quantum Error Correction: Implementing Hamming-Based Codes with Advanced Syndrome Extraction Techniques", "comment": null, "summary": "Building reliable quantum computers requires protecting fragile quantum states from inevitable environmental noise and operational errors. While quantum error correction codes like the Steane $[\\![7,1,3]\\!]$ code provide elegant theoretical solutions, their practical success hinges critically on how we measure errors - a process called syndrome extraction. The challenge lies in the ancilla qubits used for measurement: when they fail, errors can cascade across the entire quantum system, destroying the very information we're trying to protect. We address this fundamental problem by implementing and comparing three sophisticated syndrome measurement strategies: Shor's cat-state approach, which distributes measurements across multiple entangled ancillas achieving 85-92% preparation success; Steane's encoded-ancilla method using complete error-corrected logical qubits reaching 97.8% syndrome fidelity; and a flexible unified framework that adapts strategies based on hardware capabilities. Through extensive simulations using IBM's Qiskit platform spanning randomized benchmarking and T-heavy circuits, we demonstrate that intelligent ancilla management improves error suppression by up to 2.4$\\times$ compared to standard approaches. Our implementations achieve logical error rates as low as $5.1 \\times 10^{-5}$ under realistic noise conditions with physical error rates of $10^{-3}$, while maintaining near-unity logical fidelity (0.99997) even for deep circuits. The threshold analysis reveals robust performance across distance-3 to distance-13 codes with characteristic threshold curves showing exponential error suppression below the critical physical error rate. These results provide immediately deployable tools for near-term quantum devices and establish practical design principles for scaling toward fault-tolerant quantum computers."}
{"id": "2601.08083", "categories": ["cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.08083", "abs": "https://arxiv.org/abs/2601.08083", "authors": ["Gabriel Barreiro", "Vladimir Pérez-Veloz"], "title": "A Nonlinear Mechanism for Transient Anomalous Diffusion", "comment": null, "summary": "Diffusion is a fundamental physical phenomenon with critical applications in fields such as metallurgy, cell biology, and population dynamics. While standard diffusion is well-understood, anomalous diffusion often requires complex non-local models. This paper investigates a nonlinear diffusion equation where the diffusion coefficient is linearly dependent on concentration. We demonstrate through a perturbative analysis that this physically-grounded model exhibits transient anomalous diffusion. The system displays a clear crossover from an initial subdiffusive regime to standard Fickian behavior at long times. This result establishes an important mechanism for trasient anomalous diffusion that arises purely from local interactions, providing an intuitive alternative to models based on fractional calculus or non-local memory effects."}
{"id": "2601.08104", "categories": ["nlin.CD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.08104", "abs": "https://arxiv.org/abs/2601.08104", "authors": ["Julian Evan Chrisnanto", "Salsabila Rahma Alia", "Nurfauzi Fadillah", "Yulison Herry Chrisnanto"], "title": "High-Fidelity Modeling of Stochastic Chemical Dynamics on Complex Manifolds: A Multi-Scale SIREN-PINN Framework for the Curvature-Perturbed Ginzburg-Landau Equation", "comment": "25 pages, 9 figures", "summary": "The accurate identification and control of spatiotemporal chaos in reaction-diffusion systems remains a grand challenge in chemical engineering, particularly when the underlying catalytic surface possesses complex, unknown topography. In the \\textit{Defect Turbulence} regime, system dynamics are governed by topological phase singularities (spiral waves) whose motion couples to manifold curvature via geometric pinning. Conventional Physics-Informed Neural Networks (PINNs) using ReLU or Tanh activations suffer from fundamental \\textit{spectral bias}, failing to resolve high-frequency gradients and causing amplitude collapse or phase drift. We propose a Multi-Scale SIREN-PINN architecture leveraging periodic sinusoidal activations with frequency-diverse initialization, embedding the appropriate inductive bias for wave-like physics directly into the network structure. This enables simultaneous resolution of macroscopic wave envelopes and microscopic defect cores. Validated on the complex Ginzburg-Landau equation evolving on latent Riemannian manifolds, our architecture achieves relative state prediction error $ε_{L_2} \\approx 1.92 \\times 10^{-2}$, outperforming standard baselines by an order of magnitude while preserving topological invariants ($|ΔN_{defects}| < 1$). We solve the ill-posed \\textit{inverse pinning problem}, reconstructing hidden Gaussian curvature fields solely from partial observations of chaotic wave dynamics (Pearson correlation $ρ= 0.965$). Training dynamics reveal a distinctive Spectral Phase Transition at epoch $\\sim 2,100$, where cooperative minimization of physics and geometry losses drives the solver to Pareto-optimal solutions. This work establishes a new paradigm for Geometric Catalyst Design, offering a mesh-free, data-driven tool for identifying surface heterogeneity and engineering passive control strategies in turbulent chemical reactors."}
{"id": "2601.08687", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.08687", "abs": "https://arxiv.org/abs/2601.08687", "authors": ["Marco Tonnarelli", "Filippo Scaramuzza", "Simon Harrer", "Linus W. Dietz"], "title": "Data Product MCP: Chat with your Enterprise Data", "comment": "7 pages, preprint", "summary": "Computational data governance aims to make the enforcement of governance policies and legal obligations more efficient and reliable. Recent advances in natural language processing and agentic AI offer ways to improve how organizations share and use data. But many barriers remain. Today's tools require technical skills and multiple roles to discover, request, and query data. Automating data access using enterprise AI agents is limited by the means to discover and autonomously access distributed data. Current solutions either compromise governance or break agentic workflows through manual approvals. To close this gap, we introduce Data Product MCP integrated in a data product marketplace. This data marketplace, already in use at large enterprises, enables AI agents to find, request, and query enterprise data products while enforcing data contracts in real time without lowering governance standards. The system is built on the Model Context Protocol (MCP) and links the AI-driven marketplace with cloud platforms such as Snowflake, Databricks, and Google Cloud Platform. It supports semantic discovery of data products based on business context, automates access control by validating generated queries against approved business purposes using AI-driven checks, and enforces contracts in real time by blocking unauthorized queries before they run. We assessed the system with feedback from $n=16$ experts in data governance. Our qualitative evaluation demonstrates effectiveness through enterprise scenarios such as customer analytics. The findings suggest that Data Product MCP reduces the technical burden for data analysis without weakening governance, filling a key gap in enterprise AI adoption."}
{"id": "2601.08074", "categories": ["physics.soc-ph", "cs.SD", "eess.AS", "physics.pop-ph"], "pdf": "https://arxiv.org/pdf/2601.08074", "abs": "https://arxiv.org/abs/2601.08074", "authors": ["X. Hernandez", "Luis Nasser", "Pablo Garcia-Valenzuela"], "title": "Elastic overtones: an equal temperament 12 tone music system with \"perfect\" fifths", "comment": "14 pages, 4 figures, 6 audio files", "summary": "The impossibility of a transposable 12 semitone tuning of the octave arises from the mathematical fact that $2 \\times 2^{7/12} \\neq 3$ i.e., the second harmonic of the fifth can not exactly match the third harmonic of the fundamental. This in turn, stems from the whole number harmonic structure of western music, and the subsequent fundamental character of the octave interval as multiples of 2 in frequency, a property inherited by our music system from the physics of instruments with vibrating elements being to a good approximation one dimensional. In the current era of electronic music, one can relax the above assumptions to construct an analogous music system where all the structural properties of the standard music system are preserved, but where harmonics are not whole number multiples of the fundamental frequency, and the octave is no longer a factor of 2 in frequency. This now allows to construct a transposable 12 semitone music system where the second harmonic of the fifth exactly matches the third harmonic of the fundamental. The enhanced harmonic qualities of this system recover to a good approximation the musical qualities of Just Intonation, whilst retaining by construction all the versatility and modulating ability of 12TET."}
{"id": "2601.08486", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.08486", "abs": "https://arxiv.org/abs/2601.08486", "authors": ["Chengqian Zhang", "Duo Zhang", "Anyang Peng", "Mingyu Guo", "Yuzhi Zhang", "Lei Wang", "Guolin Ke", "Linfeng Zhang", "Tiejun Li", "Han Wang"], "title": "Multi-Task Fine-Tuning Enables Robust Out-of-Distribution Generalization in Atomistic Models", "comment": null, "summary": "Accurate de novo molecular and materials design requires structure-property models that generalize beyond known regimes. Although pretrained atomistic models achieve strong in-distribution accuracy after fine-tuning, their reliability under out-of-distribution (OOD) conditions remains unclear. We identify a critical failure mode in downstream adaptation: standard fine-tuning induces representation collapse, erasing pretrained chemical and structural priors and severely degrading OOD performance. To address this limitation, we propose multi-task fine-tuning (MFT), which jointly optimizes downstream property prediction with a physically grounded force-field objective inherited from pretraining. This approach preserves essential chemical priors while enabling task-specific adaptation. Across molecular and materials benchmarks, MFT consistently improves OOD generalization, approaching the theoretical limit set by in-distribution accuracy, while outperforming standard fine-tuning, training from scratch, and state-of-the-art task-specific models. These results establish safe adaptation as a central requirement for large atomistic models and position MFT as a practical and data-efficient pathway toward robust molecular and materials discovery."}
{"id": "2601.08616", "categories": ["cond-mat.str-el", "hep-th", "math.QA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08616", "abs": "https://arxiv.org/abs/2601.08616", "authors": ["Shuhei Ohyama", "Kansei Inamura"], "title": "Parameterized families of 2+1d $G$-cluster states", "comment": "70 pages", "summary": "We construct a $G$-cluster Hamiltonian in 2+1 dimensions and analyze its properties. This model exhibits a $G\\times2\\mathrm{Rep}(G)$ symmetry, where the $2\\mathrm{Rep}(G)$ sector realizes a non-invertible symmetry obtained by condensing appropriate algebra objects in $\\mathrm{Rep}(G)$. Using the symmetry interpolation method, we construct $S^1$- and $S^2$-parameterized families of short-range-entangled (SRE) states by interpolating an either invertible $0$-form or $1$-form symmetry contained in $G\\times2\\mathrm{Rep}(G)$. Applying an adiabatic evolution argument to this family, we analyze the pumped interface mode generated by this adiabatic process. We then explicitly construct the symmetry operator acting on the interface and show that the interface mode carries a nontrivial charge under this symmetry, thereby demonstrating the nontriviality of the parameterized family."}
{"id": "2601.08051", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.08051", "abs": "https://arxiv.org/abs/2601.08051", "authors": ["Jay Gopalakrishnan", "Gabriel Pinochet-Soto"], "title": "Reliable eigenspace error estimation using source error estimators", "comment": "30 pages", "summary": "We introduce a framework for repurposing error estimators for source problems to compute an estimator for the gap between eigenspaces and their discretizations. Of interest are eigenspaces of finite clusters of eigenvalues of unbounded nonselfadjoint linear operators with compact resolvent. Eigenspaces and eigenvalues of rational functions of such operators are studied as a first step. Under an assumption of convergence of resolvent approximations in the operator norm and an assumption on global reliability of source problem error estimators, we show that the gap in eigenspace approximations can be bounded by a globally reliable and computable error estimator. Also included are applications of the theoretical framework to first-order system least squares (FOSLS) discretizations and discontinuous Petrov-Galerkin (DPG) discretizations, both yielding new estimators for the error gap. Numerical experiments with a selfadjoint model problem and with a leaky nonselfadjoint waveguide eigenproblem show that adaptive algorithms using the new estimators give refinement patterns that target the cluster as a whole instead of individual eigenfunctions."}
{"id": "2601.07400", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.07400", "abs": "https://arxiv.org/abs/2601.07400", "authors": ["Wai Leong Ng", "Xinyi Tang", "Mun Lau Cheung", "Jiacheng Gao", "Chun Yip Yau", "Holger Dette"], "title": "Inference for Multiple Change-points in Piecewise Locally Stationary Time Series", "comment": null, "summary": "Change-point detection and locally stationary time series modeling are two major approaches for the analysis of non-stationary data. The former aims to identify stationary phases by detecting abrupt changes in the dynamics of a time series model, while the latter employs (locally) time-varying models to describe smooth changes in dependence structure of a time series. However, in some applications, abrupt and smooth changes can co-exist, and neither of the two approaches alone can model the data adequately. In this paper, we propose a novel likelihood-based procedure for the inference of multiple change-points in locally stationary time series. In contrast to traditional change-point analysis where an abrupt change occurs in a real-valued parameter, a change in locally stationary time series occurs in a parameter curve, and can be classified as a jump or a kink depending on whether the curve is discontinuous or not. We show that the proposed method can consistently estimate the number, locations, and the types of change-points. Two different asymptotic distributions corresponding respectively to jump and kink estimators are also established.Extensive simulation studies and a real data application to financial time series are provided."}
{"id": "2601.07980", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.07980", "abs": "https://arxiv.org/abs/2601.07980", "authors": ["K. Ken Peng", "X. Joan Hu", "Tim B. Swartz"], "title": "Modeling Event Dynamics by Self-Exciting Processes with Random Memory", "comment": null, "summary": "Event history data from sports competitions have recently drawn increasing attention in sports analytics to generate data-driven strategies. Such data often exhibit self-excitation in the event occurrence and dependence within event clusters. The conventional event models based on gap times may struggle to capture those features. In particular, while consecutive events may occur within a short timeframe, the self-excitation effect caused by previous events is often transient and continues for a period of uncertain time. This paper introduces an extended Hawkes process model with random self-excitation duration to formulate the dynamics of event occurrence. We present examples of the proposed model and procedures for estimating the associated model parameters. We employ the collection of the corner kicks in the games of the 2019 regular season of the Chinese Super League to motivate and illustrate the modeling and its usefulness. We also design algorithms for simulating the event process under proposed models. The proposed approach can be adapted with little modification in many other research fields such as Criminology and Infectious Disease."}
{"id": "2601.08060", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.08060", "abs": "https://arxiv.org/abs/2601.08060", "authors": ["Ahmed A. Hassan", "Ahmad Adnan Qidan", "Taisir Elgorashi", "Jaafar Elmirghani"], "title": "DRL-based Power Allocation in LiDAL-Assisted RLNC-NOMA OWC Systems", "comment": null, "summary": "Non-orthogonal multiple access (NOMA) is a promising technique for optical wireless communication (OWC), enabling multiple users to share the optical spectrum simultaneously through the power domain. However, the imperfection of channel state information (CSI) and residual errors in decoding process deteriorate the performance of NOMA, especially when multi-parameteric and realistic dense-user indoor scenarios are considered. In this work, we model a LiDAL-assisted RLNC-NOMA OWC system, where the light detection and localization (LiDAL) technique exploits spatio-temporal information to improve user CSI, while random linear network coding (RLNC) enhances data resilience in the NOMA successive decoding process. Power allocation (PA) is a crucial issue in communication systems, particularly in the modeled system, due to the complex interactions between multiple users and the coding and detection processes. However, optimizing continuous PA dynamically requires advanced techniques to avoid excessive computational complexity. Therefore, we adopt a deep reinforcement learning (DRL) framework to efficiently learn near-optimal power allocation strategies, enabling enhanced system performance. In particular, a DRL-based normalized advantage function (NAF) algorithm is proposed to maximize the average sum rate of the system, and its performance is analyzed and compared to other widely used DRL-based and conventional PA schemes, such as deep deterministic policy gradient (DDPG), gain ratio PA (GRPA), and exhaustive search."}
{"id": "2601.08060", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.08060", "abs": "https://arxiv.org/abs/2601.08060", "authors": ["Ahmed A. Hassan", "Ahmad Adnan Qidan", "Taisir Elgorashi", "Jaafar Elmirghani"], "title": "DRL-based Power Allocation in LiDAL-Assisted RLNC-NOMA OWC Systems", "comment": null, "summary": "Non-orthogonal multiple access (NOMA) is a promising technique for optical wireless communication (OWC), enabling multiple users to share the optical spectrum simultaneously through the power domain. However, the imperfection of channel state information (CSI) and residual errors in decoding process deteriorate the performance of NOMA, especially when multi-parameteric and realistic dense-user indoor scenarios are considered. In this work, we model a LiDAL-assisted RLNC-NOMA OWC system, where the light detection and localization (LiDAL) technique exploits spatio-temporal information to improve user CSI, while random linear network coding (RLNC) enhances data resilience in the NOMA successive decoding process. Power allocation (PA) is a crucial issue in communication systems, particularly in the modeled system, due to the complex interactions between multiple users and the coding and detection processes. However, optimizing continuous PA dynamically requires advanced techniques to avoid excessive computational complexity. Therefore, we adopt a deep reinforcement learning (DRL) framework to efficiently learn near-optimal power allocation strategies, enabling enhanced system performance. In particular, a DRL-based normalized advantage function (NAF) algorithm is proposed to maximize the average sum rate of the system, and its performance is analyzed and compared to other widely used DRL-based and conventional PA schemes, such as deep deterministic policy gradient (DDPG), gain ratio PA (GRPA), and exhaustive search."}
{"id": "2601.08396", "categories": ["math.OC", "cs.DS", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.08396", "abs": "https://arxiv.org/abs/2601.08396", "authors": ["Jérémie Bigot", "Luis Fredes"], "title": "Kantorovich Distance via Spanning Trees: Properties and Algorithms", "comment": "37 pages, 43 figures", "summary": "We study optimal transport between probability measures supported on the same finite metric space, where the ground cost is a distance induced by a weighted connected graph. Building on recent work showing that the resulting Kantorovich distance can be expressed as a minimization problem over the set of spanning trees of this underlying graph, we investigate the implications of this reformulation on the construction of an optimal transport plan and a dual potential based on the solution of such an optimization problem. In this setting, we derive an explicit formula for the Kantorovich potential in terms of the imbalanced cumulative mass (a generalization of the cumulative distribution in R) along an optimal spanning tree solving such a minimization problem, under a weak non-degeneracy condition on the pair of measures that guarantees the uniqueness of a dual potential. Our second contribution establishes the existence of an optimal transport plan that can be computed efficiently by a dynamic programming procedure once an optimal spanning tree is known. Finally, we propose a stochastic algorithm based on simulated annealing on the space of spanning trees to compute such an optimal spanning tree. Numerical experiments illustrate the theoretical results and demonstrate the practical relevance of the proposed approach for optimal transport on finite metric spaces."}
{"id": "2601.07872", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.07872", "abs": "https://arxiv.org/abs/2601.07872", "authors": ["E. Wes Bethel", "Roel Van Beeumen", "Talita Perciano"], "title": "Quantum Computing and Visualization Research Challenges and Opportunities", "comment": "Accepted for publication in IEEE Computer Graphics and Applications, Mar/Apr 2026, to appear", "summary": "Quantum computing (QC) has experienced rapid growth in recent years with the advent of robust programming environments, readily accessible software simulators and cloud-based QC hardware platforms, and growing interest in learning how to design useful methods that leverage this emerging technology for practical applications. From the perspective of the field of visualization, this article examines research challenges and opportunities along the path from initial feasibility to practical use of QC platforms applied to meaningful problems."}
{"id": "2601.08347", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08347", "abs": "https://arxiv.org/abs/2601.08347", "authors": ["Maksym Serbyn", "Alexander Avdoshkin", "Oriana K. Diessel", "David A. Huse"], "title": "Eigenstate thermalization in thermal first-order phase transitions", "comment": "11 pages, 8 figures", "summary": "The eigenstate thermalization hypothesis (ETH) posits how isolated quantum many-body systems thermalize, assuming that individual eigenstates at the same energy density have identical expectation values of local observables in the limit of large systems. While the ETH apparently holds across a wide range of interacting quantum systems, in this work we show that it requires generalization in the presence of thermal first-order phase transitions. We introduce a class of all-to-all spin models, featuring first-order thermal phase transitions that stem from two distinct mean-field solutions (two ``branches'') that exchange dominance in the many-body density of states as the energy is varied. We argue that for energies in the vicinity of the thermal phase transition, eigenstate expectation values do not need to converge to the same thermal value. The system has a regime with coexistence of two classes of eigenstates corresponding to the two branches with distinct expectation values at the same energy density, and another regime with Schrodinger-cat-like eigenstates that are inter-branch superpositions; these two regimes are separated by an eigenstate phase transition. We support our results by semiclassical calculations and an exact diagonalization study of a microscopic spin model, and argue that the structure of eigenstates in the vicinity of thermal first-order phase transitions can be experimentally probed via non-equilibrium dynamics."}
{"id": "2601.07860", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.07860", "abs": "https://arxiv.org/abs/2601.07860", "authors": ["Soham Bhadra", "Diyansha Singh", "Angana Chowdhury"], "title": "Fault-Tolerant Quantum Error Correction: Implementing Hamming-Based Codes with Advanced Syndrome Extraction Techniques", "comment": null, "summary": "Building reliable quantum computers requires protecting fragile quantum states from inevitable environmental noise and operational errors. While quantum error correction codes like the Steane $[\\![7,1,3]\\!]$ code provide elegant theoretical solutions, their practical success hinges critically on how we measure errors - a process called syndrome extraction. The challenge lies in the ancilla qubits used for measurement: when they fail, errors can cascade across the entire quantum system, destroying the very information we're trying to protect. We address this fundamental problem by implementing and comparing three sophisticated syndrome measurement strategies: Shor's cat-state approach, which distributes measurements across multiple entangled ancillas achieving 85-92% preparation success; Steane's encoded-ancilla method using complete error-corrected logical qubits reaching 97.8% syndrome fidelity; and a flexible unified framework that adapts strategies based on hardware capabilities. Through extensive simulations using IBM's Qiskit platform spanning randomized benchmarking and T-heavy circuits, we demonstrate that intelligent ancilla management improves error suppression by up to 2.4$\\times$ compared to standard approaches. Our implementations achieve logical error rates as low as $5.1 \\times 10^{-5}$ under realistic noise conditions with physical error rates of $10^{-3}$, while maintaining near-unity logical fidelity (0.99997) even for deep circuits. The threshold analysis reveals robust performance across distance-3 to distance-13 codes with characteristic threshold curves showing exponential error suppression below the critical physical error rate. These results provide immediately deployable tools for near-term quantum devices and establish practical design principles for scaling toward fault-tolerant quantum computers."}
{"id": "2601.08720", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.08720", "abs": "https://arxiv.org/abs/2601.08720", "authors": ["Monica V. Prates", "Arthur A. B. Pessa", "Sebastian Goncalves", "Matjaz Perc", "Haroldo V. Ribeiro"], "title": "Bipartite structure and dynamics of political corruption networks", "comment": "12 pages, 6 figures, accepted for publication in Physica A", "summary": "Political corruption is inherently an affiliation process linking agents to corruption cases; yet it is often studied via one-mode projections that connect co-offenders within the same scandal, implying a loss of information that potentially confounds properties of agents and cases. Here, we adopt a bipartite representation to analyze datasets of corruption scandals in Brazil and Spain spanning nearly three decades. By tracking the temporal growth of these networks, we quantify density and redundancy measures to capture partner reuse and co-occurrence across cases. Networks in both countries become progressively sparser over time, and agent redundancy is systematically higher than case redundancy, indicating a small cadre of recidivists who recombine largely with novice partners rather than forming durable co-offending ties. These networks exhibit near-exponential degree distributions, reflecting low recidivism and likely high coordination costs and secrecy constraints of large-scale scandals. Our bipartite view further reveals a moderate cross-mode disassortative degree mixing between agents and cases, with high-degree agents distributing their activity across small cases and large scandals mainly comprising low-degree participants. Finally, identifying atypical individuals within the bipartite structure reveals criminal trajectories marked by a gradual rise in network embeddedness that can appear ordinary in agent-projected networks."}
{"id": "2601.07926", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.07926", "abs": "https://arxiv.org/abs/2601.07926", "authors": ["Massimo Bernaschi", "Luis Antonio Fernández", "Isidoro González-Adalid Pemartín", "Víctor Martín-Mayor", "Giorgio Parisi", "Federico Ricci-Tersenghi"], "title": "Low energy excitations in a long prism geometry: computing the lower critical dimension of the Ising spin glass", "comment": null, "summary": "We propose a general method for studying systems that display excitations with arbitrarily low energy in their low-temperature phase. We argue that in a rectangular right prism geometry, with longitudinal size much larger than the transverse size, correlations decay exponentially (at all temperatures) along the longitudinal dimension, but the scaling of the correlation length with the transverse size carries crucial information from which the lower critical dimension can be inferred. The method is applied in the particularly demanding context of Ising spin glasses at zero magnetic field. The lower critical dimension and the multifractal spectrum for the correlation function are computed from large-scale numerical simulations. Several technical novelties (such as the unexpectedly crucial performance of Houdayer's cluster method or the convenience of using open - rather than periodic - boundary conditions) allow us to study three-dimensional prisms with transverse dimensions up to $L=24$ and effectively infinite longitudinal dimensions down to low temperatures. The value that we find for the lower critical dimension turns out to be in agreement with expectations from both the Replica Symmetry Breaking theory and the Droplet model for spin glasses. We argue that our novel setting holds promise in clarifying which of the two competing theories more accurately describes three-dimensional spin glasses."}
{"id": "2601.08702", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.08702", "abs": "https://arxiv.org/abs/2601.08702", "authors": ["Myung-Hwan Whangbo", "Reinhard K. Kremer", "Hyun-Joo Koo"], "title": "Reduction of Ordered Spin Moments in Antiferromagnets of S = 5/2 Ions (Fe3+, Mn2+) Driven by Local Magnetic Excitation", "comment": "38 pages, 13 figures, 16 tables; Accepted for publication in Inorganic Chemistry as a Communication", "summary": "For antiferromagnets composed of spin five-half ions, the moments of these ions in the ordered antiferromagnetic state can be significantly smaller than 5 BM (i.e., 1.56 - 4.48 BM) if these ions form quantum fluctuating entities (QFEs), for example, quasi one-dimensional uniform antiferromagnetic chains or quasi zero-spin antiferromagnetic spin dimers. It is reasonable to suppose that the stronger the quantum fluctuation in such an antiferromagnet, the greater the reduction in its ordered moment would become, but this supposition has not yet been confirmed because quantifying the strength of quantum fluctuation is not a straightforward matter. Here we show that the local magnetic excitations involving the QFEs can be used to quantify the strength of quantum fluctuation by analyzing six antiferromagnets showing significant reduction in their ordered spin moments."}
{"id": "2601.08188", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.08188", "abs": "https://arxiv.org/abs/2601.08188", "authors": ["Lei Zhang", "Xiangcheng Zheng", "Shangqin Zhu"], "title": "Numerical analysis of spatiotemporal high-index saddle dynamics for finding multiple solutions of semilinear elliptic problems", "comment": null, "summary": "This paper presents a rigorous numerical framework for computing multiple solutions of semilinear elliptic problems by spatiotemporal high-index saddle dynamics (HiSD), which extends the traditional HiSD to the continuous-in-space setting, explicitly incorporating spatial differential operators. To enforce the Stiefel manifold constraint without introducing the analytical complications of retraction-based updates, we design a fully discrete retraction-free orthonormality-preserving scheme for spatiotemporal HiSD. This scheme exhibits favorable structural properties that substantially reduce the difficulties arising from coupling and gradient nonlinearities in spatiotemporal HiSD. Exploiting these properties, we establish gradient stability and error estimates, which consequently ensure the preservation of the Morse index for the computed saddle points. The framework is further extended to the semilinear advection-reaction-diffusion equation. Numerical experiments demonstrate the efficiency of the proposed method in finding multiple solutions and constructing the solution landscape of semilinear elliptic problems. To the best of our knowledge, this work presents the first rigorous full space--time accuracy analysis of the HiSD system. It reveals intrinsic connections between saddle-search algorithms and numerical methods for PDEs, enhancing their mutual compatibility for a broad range of problems."}
{"id": "2601.08396", "categories": ["math.OC", "cs.DS", "math.PR", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.08396", "abs": "https://arxiv.org/abs/2601.08396", "authors": ["Jérémie Bigot", "Luis Fredes"], "title": "Kantorovich Distance via Spanning Trees: Properties and Algorithms", "comment": "37 pages, 43 figures", "summary": "We study optimal transport between probability measures supported on the same finite metric space, where the ground cost is a distance induced by a weighted connected graph. Building on recent work showing that the resulting Kantorovich distance can be expressed as a minimization problem over the set of spanning trees of this underlying graph, we investigate the implications of this reformulation on the construction of an optimal transport plan and a dual potential based on the solution of such an optimization problem. In this setting, we derive an explicit formula for the Kantorovich potential in terms of the imbalanced cumulative mass (a generalization of the cumulative distribution in R) along an optimal spanning tree solving such a minimization problem, under a weak non-degeneracy condition on the pair of measures that guarantees the uniqueness of a dual potential. Our second contribution establishes the existence of an optimal transport plan that can be computed efficiently by a dynamic programming procedure once an optimal spanning tree is known. Finally, we propose a stochastic algorithm based on simulated annealing on the space of spanning trees to compute such an optimal spanning tree. Numerical experiments illustrate the theoretical results and demonstrate the practical relevance of the proposed approach for optimal transport on finite metric spaces."}
{"id": "2601.08067", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.08067", "abs": "https://arxiv.org/abs/2601.08067", "authors": ["André F. B. Menezes", "Andrew C. Parnell", "Keefe Murphy"], "title": "Bayesian nonparametric models for zero-inflated count-compositional data using ensembles of regression trees", "comment": null, "summary": "Count-compositional data arise in many different fields, including high-throughput microbiome sequencing and palynology experiments, where a common, important goal is to understand how covariates relate to the observed compositions. Existing methods often fail to simultaneously address key challenges inherent in such data, namely: overdispersion, an excess of zeros, cross-sample heterogeneity, and nonlinear covariate effects. To address these concerns, we propose novel Bayesian models based on ensembles of regression trees. Specifically, we leverage the recently introduced zero-and-$N$-inflated multinomial distribution and assign independent nonparametric Bayesian additive regression tree (BART) priors to both the compositional and structural zero probability components of our model, to flexibly capture covariate effects. We further extend this by adding latent random effects to capture overdispersion and more general dependence structures among the categories. We develop an efficient inferential algorithm combining recent data augmentation schemes with established BART sampling routines. We evaluate our proposed models in simulation studies and illustrate their applicability with two case studies in microbiome and palaeoclimate modelling."}
{"id": "2601.08113", "categories": ["eess.SY", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.08113", "abs": "https://arxiv.org/abs/2601.08113", "authors": ["Nardos Belay Abera", "Yize Chen"], "title": "Coordinated Cooling and Compute Management for AI Datacenters", "comment": "In Submission, 12 pages, 8 pages", "summary": "The AI datacenters are currently being deployed on a large scale to support the training and deployment of power-intensive large-language models (LLMs). Extensive amount of computation and cooling required in datacenters increase concerns about the energy use and carbon emissions of AI datacenters. Although current state-of-the-art has examined the energy efficiency of LLM inference, most prior research focused on optimizing compute-side scheduling without considering thermal objectives or constraints. Since GPU-intensive inference generates substantial heat that can degrade datacenter performance, ignoring thermal effects can increase total energy consumption and reduce the efficiency of LLM serving. To fill this gap, we profile the characteristics of GPU servers under varying cooling and AI jobs, and develop a joint cooling and computing modeling approach for AI datacenters. Built upon such workload and thermal dynamics models, a novel hierarchical control framework is proposed to co-optimize computing and thermal management by identifying the optimal GPU parallelism, frequency (DVFS), and cooling control knobs. Using real Azure inference traces and detailed GPU profiling, our model balances serving latency and thermal constraints in AI datacenters while significantly improving AI datacenters' energy efficiency."}
{"id": "2601.08113", "categories": ["eess.SY", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.08113", "abs": "https://arxiv.org/abs/2601.08113", "authors": ["Nardos Belay Abera", "Yize Chen"], "title": "Coordinated Cooling and Compute Management for AI Datacenters", "comment": "In Submission, 12 pages, 8 pages", "summary": "The AI datacenters are currently being deployed on a large scale to support the training and deployment of power-intensive large-language models (LLMs). Extensive amount of computation and cooling required in datacenters increase concerns about the energy use and carbon emissions of AI datacenters. Although current state-of-the-art has examined the energy efficiency of LLM inference, most prior research focused on optimizing compute-side scheduling without considering thermal objectives or constraints. Since GPU-intensive inference generates substantial heat that can degrade datacenter performance, ignoring thermal effects can increase total energy consumption and reduce the efficiency of LLM serving. To fill this gap, we profile the characteristics of GPU servers under varying cooling and AI jobs, and develop a joint cooling and computing modeling approach for AI datacenters. Built upon such workload and thermal dynamics models, a novel hierarchical control framework is proposed to co-optimize computing and thermal management by identifying the optimal GPU parallelism, frequency (DVFS), and cooling control knobs. Using real Azure inference traces and detailed GPU profiling, our model balances serving latency and thermal constraints in AI datacenters while significantly improving AI datacenters' energy efficiency."}
{"id": "2601.08426", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.08426", "abs": "https://arxiv.org/abs/2601.08426", "authors": ["Odysseas Kanavetas", "Ekaterina Kosarevskaia"], "title": "Two-Product Make-to-Stock System: Strategic Joining and Optimal Inventory Levels", "comment": null, "summary": "This paper analyzes a two-product make-to-stock queueing system where a single production facility serves two customer classes with independent Poisson arrivals. Customers make strategic join-or-balk decisions without observing current inventory levels. The analysis establishes the existence and uniqueness of Nash equilibria in customer joining strategies for various inventory scenarios. Optimal base-stock levels are characterized from both profit-maximizing and welfare-maximizing perspectives, with closed-form expressions for key performance measures."}
{"id": "2601.07882", "categories": ["quant-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07882", "abs": "https://arxiv.org/abs/2601.07882", "authors": ["Ratun Rahman", "Shaba Shaon", "Dinh C. Nguyen"], "title": "Tackling Heterogeneity in Quantum Federated Learning: An Integrated Sporadic-Personalized Approach", "comment": "Accepted at IEEE Transactions on Computers", "summary": "Quantum federated learning (QFL) emerges as a powerful technique that combines quantum computing with federated learning to efficiently process complex data across distributed quantum devices while ensuring data privacy in quantum networks. Despite recent research efforts, existing QFL frameworks struggle to achieve optimal model training performance primarily due to inherent heterogeneity in terms of (i) quantum noise where current quantum devices are subject to varying levels of noise due to varying device quality and susceptibility to quantum decoherence, and (ii) heterogeneous data distributions where data across participating quantum devices are naturally non-independent and identically distributed (non-IID). To address these challenges, we propose a novel integrated sporadic-personalized approach called SPQFL that simultaneously handles quantum noise and data heterogeneity in a single QFL framework. It is featured in two key aspects: (i) for quantum noise heterogeneity, we introduce a notion of sporadic learning to tackle quantum noise heterogeneity across quantum devices, and (ii) for quantum data heterogeneity, we implement personalized learning through model regularization to mitigate overfitting during local training on non-IID quantum data distributions, thereby enhancing the convergence of the global model. Moreover, we conduct a rigorous convergence analysis for the proposed SPQFL framework, with both sporadic and personalized learning considerations. Theoretical findings reveal that the upper bound of the SPQFL algorithm is strongly influenced by both the number of quantum devices and the number of quantum noise measurements. Extensive simulation results in real-world datasets also illustrate that the proposed SPQFL approach yields significant improvements in terms of training performance and convergence stability compared to the state-of-the-art methods."}
{"id": "2601.08381", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.08381", "abs": "https://arxiv.org/abs/2601.08381", "authors": ["Koretaka Yuge"], "title": "Unavoidable Canonical Nonlinearity Induced by Gaussian Measures Discretization", "comment": "4 pages", "summary": "When we consider canonical averages for classical discrete systems, typically referred to as substitutional alloys, the map from many-body interatomic interactions to thermodynamic equilibrium configurations generally exhibits complicated nonlinearity. This canonical nonlinearity is fundamentally rooted in deviations of the discrete configurational density of states (CDOS) from continuous Gaussian families, and has conventionally been characterized by the Kullback-Leibler (KL) divergence on discrete statistical manifold. Thus, the previous works inevitablly missed intrinsic nonlinearities induced by discretization of Gaussian families, which remains invisible within conventional information-geometric descriptions. In the present work, we identify and quantify such unavoidable canonical nonlinearity by employing the 2-Wasserstein distance with a cost function aligned with the Fisher metric for Gaussian families. We derive an explicit expression for the Wasserstein distance in the limit of vanishing discretization scale d to 0: W2 = d*sqrt(Tr(Gamma)^(-1)/12), where Gamma denotes covariance matrix of the CDOS. We further show that this limiting Wasserstein distance admits a clear geometric interpretation on the statistical manifold, equivalent to a KL divergence associated with the expected parallel translations of continuous Gaussian. Our framework thus provides a transport-information-geometric characterization of discretization-induced nonlinearity in classical discrete systems, with future potential applications to configurational thermodynamics."}
{"id": "2601.08213", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.08213", "abs": "https://arxiv.org/abs/2601.08213", "authors": ["Anastasiia Butko", "Artem Marisov", "David I. Santiago", "Irfan Siddiqi"], "title": "Quantum State Discrimination Enhanced by FPGA-Based AI Engine Technology", "comment": null, "summary": "Identifying the state of a quantum bit (qubit), known as quantum state discrimination, is a crucial operation in quantum computing. However, it has been the most error-prone and time-consuming operation on superconducting quantum processors. Due to stringent timing constraints and algorithmic complexity, most qubit state discrimination methods are executed offline. In this work, we present an enhanced real-time quantum state discrimination system leveraging FPGA-based AI Engine technology. A multi-layer neural network has been developed and implemented on the AMD Xilinx VCK190 FPGA platform, enabling accurate in-situ state discrimination and supporting mid-circuit measurement experiments for multiple qubits. Our approach leverages recent advancements in architecture research and design, utilizing specialized AI/ML accelerators to optimize quantum experiments and reduce the use of FPGA resources."}
{"id": "2601.08754", "categories": ["physics.soc-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.08754", "abs": "https://arxiv.org/abs/2601.08754", "authors": ["Cesar I. N. Sampaio Filho", "Humberto A. Carmona", "Antonio S. Lima Neto", "Monica V. Prates", "Haroldo V. Ribeiro", "Marcia C. Castro", "Jose S. Andrade"], "title": "Evolving spatiotemporal patterns and urban scaling of deaths from external causes", "comment": "16 pages, 8 figures, supplementary information; accepted for publication in Scientific Reports", "summary": "Urban scaling theory posits that urban indicators follow power-law relations with population, yet the evolution of these patterns - and the role of regional differences in settings marked by social inequalities and unplanned urbanization - remains poorly understood. Here, we analyze nearly three decades of mortality data from Brazilian cities to investigate the scaling of external causes of death: homicides, suicides, and accidents. Using a hierarchical Bayesian framework and spatial correlation analysis, we find that these mortality indicators exhibit distinct, regionally heterogeneous scaling trajectories. Homicide mortality has significantly attenuated its typical superlinear scaling with increased spatial clustering, suggesting a redistribution of violence to smaller cities and intensified intercity interactions, possibly linked to the consolidation of organized crime. Suicide mortality, usually sublinear, has trended upward, implying a weakening of urban agglomerations' protective effect. Accident mortality remains superlinear, with transport fatalities scaling nearly proportionally, and non-transport accidents becoming superlinear. The scaling changes for suicides and accidents coincide with less correlated and stable spatial patterns, suggesting that the underlying processes predominantly operate within city boundaries. Finally, while scaling exponents have evolved more homogeneously across Brazilian states, scale-adjusted mortality remains highly heterogeneous, indicating that fundamental processes govern scaling laws, whereas state-specific factors drive scale-adjusted metrics."}
{"id": "2601.08137", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.08137", "abs": "https://arxiv.org/abs/2601.08137", "authors": ["Kazuhiro Seki", "Yuta Kikuchi", "Tomoya Hayata", "Seiji Yunoki"], "title": "Dissipative ground-state preparation of a quantum spin chain on a trapped-ion quantum computer", "comment": "15 pages, 9 figures", "summary": "We demonstrate a dissipative protocol for ground-state preparation of a quantum spin chain on a trapped-ion quantum computer. As a first step, we derive a Kraus representation of a dissipation channel for the protocol recently proposed by Ding et al. [Phys. Rev. Res. 6, 033147 (2024)] that still holds for arbitrary temporal discretization steps, extending the analysis beyond the Lindblad dynamics regime. The protocol guarantees that the fidelity with the ground state monotonically increases (or remains unchanged) under repeated applications of the channel to an arbitrary initial state, provided that the ground state is the unique steady state of the dissipation channel. Using this framework, we implement dissipative ground-state preparation of a transverse-field Ising chain for up to 19 spins on the trapped-ion quantum computer Reimei provided by Quantinuum. Despite the presence of hardware noise, the dynamics consistently converges to a low-energy state far away from the maximally mixed state even when the corresponding quantum circuits contain as many as 4110 entangling gates, demonstrating the intrinsic robustness of the protocol. By applying zero-noise extrapolation, the resulting energy expectation values are systematically improved to agree with noiseless simulations within statistical uncertainties."}
{"id": "2601.08228", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.08228", "abs": "https://arxiv.org/abs/2601.08228", "authors": ["Aneesh Panchal", "Ratikanta Behera"], "title": "Second-Generation Wavelet-inspired Tensor Product with Applications in Hyperspectral Imaging", "comment": null, "summary": "This paper introduces the $w$-product, a novel wavelet-based tensor multiplication scheme leveraging second-generation wavelet transforms to achieve linear transformation complexity while preserving essential algebraic properties. The $w$-product outperforms existing tensor multiplication approaches by enabling fast and numerically stable tensor decompositions by proposing ``$w$-svd'' and its sparse variant ``sp-$w$-svd'', for efficient low-rank approximations with significantly reduced computational costs. Experiments on low-rank hyperspectral image reconstruction demonstrate up to a $92.21$ times speedup compared to state-of-the-art ``$t$-svd'', with comparable PSNR and SSIM metrics. We discuss the Moore-Penrose inverse of tensors based on the $w$-product and examine its essential properties. Numerical examples are provided to support the theoretical results. Then, hyperspectral image deblurring experiments demonstrate up to $27.88$ times speedup with improved image quality. In particular, the $w$-product and the sp-$w$-product exhibit exponentially increasing acceleration with the decomposition level compared to the traditional approach of the $t$-product. This work provides a scalable framework for multidimensional data analysis, with future research directions including adaptive wavelet designs, higher-order tensor extensions, and real-time implementations."}
{"id": "2601.08588", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.08588", "abs": "https://arxiv.org/abs/2601.08588", "authors": ["Jacob Paul Simpson", "Efstratios Palias", "Sharu Theresa Jose"], "title": "Sample Complexity of Composite Quantum Hypothesis Testing", "comment": "Under review", "summary": "This paper investigates symmetric composite binary quantum hypothesis testing (QHT), where the goal is to determine which of two uncertainty sets contains an unknown quantum state. While asymptotic error exponents for this problem are well-studied, the finite-sample regime remains poorly understood. We bridge this gap by characterizing the sample complexity -- the minimum number of state copies required to achieve a target error level. Specifically, we derive lower bounds that generalize the sample complexity of simple QHT and introduce new upper bounds for various uncertainty sets, including of both finite and infinite cardinalities. Notably, our upper and lower bounds match up to universal constants, providing a tight characterization of the sample complexity. Finally, we extend our analysis to the differentially private setting, establishing the sample complexity for privacy-preserving composite QHT."}
{"id": "2601.08084", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.08084", "abs": "https://arxiv.org/abs/2601.08084", "authors": ["Xiaoping Shi", "Baisuo Jin", "Xianhui Liu", "Qiong Li"], "title": "REAMP: A Stochastic Resonance Approach for Multi-Change Point Detection in High-Dimensional Data", "comment": "15 pages, 5 figures", "summary": "Detecting multiple structural breaks in high-dimensional data remains a challenge, particularly when changes occur in higher-order moments or within complex manifold structures. In this paper, we propose REAMP (Resonance-Enhanced Analysis of Multi-change Points), a novel framework that integrates optimal transport theory with the physical principles of stochastic resonance. By utilizing a two-stage dimension reduction via the Earth Movers Distance (EMD) and Shortest Hamiltonian Paths (SHP), we map high-dimensional observations onto a graph-based count statistic. To overcome the locality constraints of traditional search algorithms, we implement a stochastic resonance system that utilizes randomized Beta-density priors to vibrate the objective function. This process allows multiple change points to resonate as global minima across iterative simulations, generating a candidate point cloud. A double-sharpening procedure is then applied to these candidates to pinpoint precise change point locations. We establish the asymptotic consistency of the resonance estimator and demonstrate through simulations that REAMP outperforms state-of-the-art methods, especially in scenarios involving simultaneous mean and variance shifts. The practical utility of the method is further validated through an application to time-lapse embryo monitoring, where REAMP provides both accurate detection and intuitive visualization of cell division stages."}
{"id": "2601.08168", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08168", "abs": "https://arxiv.org/abs/2601.08168", "authors": ["Syue-Cian Lin", "Wei-Yu Chiu", "Chien-Feng Wu"], "title": "Memetic Covariance Matrix Adaptation Evolution Strategy for Bilinear Matrix Inequality Problems in Control System Design", "comment": "24 pages, 5 figures", "summary": "Bilinear Matrix Inequalities (BMIs) are fundamental to control system design but are notoriously difficult to solve due to their nonconvexity. This study addresses BMI-based control optimization problems by adapting and integrating advanced evolutionary strategies. Specifically, a memetic Covariance Matrix Adaptation Evolution Strategy (memetic CMA-ES) is proposed, which incorporates a local refinement phase via a (1+1)-CMA-ES within the global search process. While these algorithmic components are established in evolutionary computing, their tailored integration and specific tuning for control design tasks represent a novel application in this context. Experimental evaluations on $H_{\\infty}$ controller synthesis and spectral abscissa optimization demonstrate that the proposed method achieves superior performance compared to existing BMI solvers in terms of both solution quality and robustness. This work bridges the gap between evolutionary computation and control theory, providing a practical and effective approach to tackling challenging BMI-constrained problems."}
{"id": "2601.08168", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08168", "abs": "https://arxiv.org/abs/2601.08168", "authors": ["Syue-Cian Lin", "Wei-Yu Chiu", "Chien-Feng Wu"], "title": "Memetic Covariance Matrix Adaptation Evolution Strategy for Bilinear Matrix Inequality Problems in Control System Design", "comment": "24 pages, 5 figures", "summary": "Bilinear Matrix Inequalities (BMIs) are fundamental to control system design but are notoriously difficult to solve due to their nonconvexity. This study addresses BMI-based control optimization problems by adapting and integrating advanced evolutionary strategies. Specifically, a memetic Covariance Matrix Adaptation Evolution Strategy (memetic CMA-ES) is proposed, which incorporates a local refinement phase via a (1+1)-CMA-ES within the global search process. While these algorithmic components are established in evolutionary computing, their tailored integration and specific tuning for control design tasks represent a novel application in this context. Experimental evaluations on $H_{\\infty}$ controller synthesis and spectral abscissa optimization demonstrate that the proposed method achieves superior performance compared to existing BMI solvers in terms of both solution quality and robustness. This work bridges the gap between evolutionary computation and control theory, providing a practical and effective approach to tackling challenging BMI-constrained problems."}
{"id": "2601.08431", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.08431", "abs": "https://arxiv.org/abs/2601.08431", "authors": ["Ralf Möller"], "title": "Exploring an Alternative Line-Search Method for Lagrange-Newton Optimization", "comment": null, "summary": "In the Lagrange-Newton method, where Newton's method is applied to a Lagrangian function that includes equality constraints, all stationary points are saddle points. It is therefore not possible to use a line-search method based on the value of the objective function; instead, the line search can operate on merit functions. In this report, we explore an alternative line-search method which is applicable to this case; it particulary addresses the damping of the step length in tight valleys. We propose a line-search criterion based on the divergence of the field of Newton step vectors. The visualization of the criterion for two-dimensional test functions reveals a network of ravines with flat bottom at the zero points of the criterion. The ravines are typically connected to stationary points. To traverse this ravine network in order to approach a stationary point, a zigzag strategy is devised. Numerical experiments demonstrate that the novel line-search strategy succeeds from most starting points in all test functions, but only exhibits the desired damping of the step length in some situations. At the present stage it is therefore difficult to appraise the utility of this contribution."}
{"id": "2601.07883", "categories": ["quant-ph", "gr-qc", "hep-th", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2601.07883", "abs": "https://arxiv.org/abs/2601.07883", "authors": ["Indrajit Sen", "Matthew Leifer"], "title": "Local Scale Invariance in Quantum Theory: Experimental Predictions", "comment": "13 pages, 3 figures", "summary": "We explore the experimental predictions of the local scale invariant, non-Hermitian pilot-wave (de Broglie-Bohm) formulation of quantum theory introduced in arXiv:2601.03567. We use Weyl's definition of gravitational radius of charge to obtain the fine-structure constant for non-integrable scale effects $α_S$. The minuteness of $α_S$ relative to $α$ ($α_S/α\\sim 10^{-21}$) effectively hides the effects in usual quantum experiments. In an Aharonov-Bohm double-slit experiment, the theory predicts that the position probability density depends on which slit the particle trajectory crosses, due to a non-integrable scale induced by the magnetic flux. This experimental prediction can be realistically tested for an electrically neutral, heavy molecule with mass $m \\sim 10^{-19} \\text{g}$ at a $\\sim 10^6 \\text{ esu}$ flux regime. We analyse the Weyl-Einstein debate on the second-clock effect using the theory and show that spectral frequencies are history-independent. We thereby resolve Einstein's key objection against local scale invariance, and obtain two further experimental predictions. First, spectral intensities turn out to be history-dependent. Second, energy eigenvalues are modified by tiny imaginary corrections that modify spectral linewidths. We argue that the trajectory dependence of the probabilities renders our theory empirically distinguishable from other quantum formulations that do not use pilot-wave trajectories, or their mathematical equivalents, to derive experimental predictions."}
{"id": "2601.08740", "categories": ["cond-mat.stat-mech", "math.AP", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.08740", "abs": "https://arxiv.org/abs/2601.08740", "authors": ["Hwai-Ray Tung", "Sean D Lawley"], "title": "Stochastic search with space-dependent diffusivity", "comment": "15 pages, 5 figures", "summary": "The canonical model of stochastic search tracks a randomly diffusing \"searcher\" until it finds a \"target.\" Owing to its many applications across science and engineering, this perennially popular problem has been thoroughly investigated in a variety of models. However, aside from some exactly solvable one-dimensional examples, very little is known if the searcher diffusivity varies in space. For such space-dependent or \"heterogeneous\" diffusion, one must specify the interpretation of the multiplicative noise, which is termed the Itô-Stratonovich dilemma. In this paper, we investigate how stochastic search with space-dependent diffusivity depends on this interpretation. We obtain general formulas for the probability distribution and all the moments of the stochastic search time and the so-called splitting probabilities assuming that the targets are small or weakly reactive. These asymptotic results are valid for general space-dependent diffusivities in general domains in any space dimension with targets of general shape which may be in the interior or on the boundary of the domain. We illustrate our theory with stochastic simulations. Our analysis predicts that stochastic search can depend strongly and counterintuitively on the multiplicative noise interpretation."}
{"id": "2601.08578", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.08578", "abs": "https://arxiv.org/abs/2601.08578", "authors": ["Marvin Erdmann", "Lukas Karch", "Abhishek Awasthi", "Caitlin Isobel Jones", "Pallavi Bhardwaj", "Florian Krellner", "Jonas Stein", "Claudia Linnhoff-Popien", "Nico Kraus", "Peter Eder", "Sarah Braun", "Tong Liu"], "title": "Quantum Computing -- Strategic Recommendations for the Industry", "comment": null, "summary": "This whitepaper surveys the current landscape and short- to mid-term prospects for quantum-enabled optimization and machine learning use cases in industrial settings. Grounded in the QCHALLenge program, it synthesizes hardware trajectories from different quantum architectures and providers, and assesses their maturity and potential for real-world use cases under a standardized traffic-light evaluation framework. We provide a concise summary of relevant hardware roadmaps, distinguishing superconducting and ion-trap technologies, their current states, modalities, and projected scaling trajectories. The core of the presented work are the use case evaluations in the domains of optimization problems and machine learning applications. For the conducted experiments, we apply a consistent set of evaluation criteria (model formulation, scalability, solution quality, runtime, and transferability) which are assessed in a shared system of three categories, ranging from optimistic (solutions produced by quantum computers are competitive with classical methods and/or a clear path to a quantum advantage is shown) to pessimistic (significant hurdles prevent practical application of quantum solutions now and potentially in the future). The resulting verdicts illuminate where quantum approaches currently offer promise, where hybrid classical-quantum strategies are most viable, and where classical methods are expected to remain superior."}
{"id": "2601.08299", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.08299", "abs": "https://arxiv.org/abs/2601.08299", "authors": ["Mingzhe Li", "Yang Kuang", "Zhicheng Hu"], "title": "A multi-mesh adaptive finite element method for solving the Gross-Pitaevskii equation", "comment": null, "summary": "It is found that the wave functions of the Gross-Pitaevskii equation (GPE) often vary significantly in different spatial regions, with some components exhibiting sharp variations while others remain smooth. Solving the GPE on a single mesh, even with adaptive refinement, can lead to excessive computational costs due to the need to accommodate the most oscillatory solution. To address this issue, we present a multi-mesh adaptive finite element method for solving the GPE. To this end, we first convert it into a time-dependent equation through the imaginary time propagation method. Then the equation is discretized by the backward Euler method temporally and the multi-mesh adaptive finite element method spatially. The proposed method is compared with the single-mesh adaptive method through a series of numerical experiments, which demonstrate that the multi-mesh adaptive method can achieve the same numerical accuracy with less computational consumption."}
{"id": "2601.08610", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.08610", "abs": "https://arxiv.org/abs/2601.08610", "authors": ["Wenxuan Guo", "Panos Toulis", "Yuhao Wang"], "title": "Permutation Inference under Multi-way Clustering and Missing Data", "comment": "55 pages, 5 figures", "summary": "Econometric applications with multi-way clustering often feature a small number of effective clusters or heavy-tailed data, making standard cluster-robust and bootstrap inference unreliable in finite samples. In this paper, we develop a framework for finite-sample valid permutation inference in linear regression with multi-way clustering under an assumption of conditional exchangeability of the errors. Our assumption is closely related to the notion of separate exchangeability studied in earlier work, but can be more realistic in many economic settings as it imposes minimal restrictions on the covariate distribution. We construct permutation tests of significance that are valid in finite samples and establish theoretical power guarantees, in contrast to existing methods that are justified only asymptotically. We also extend our methodology to settings with missing data and derive power results that reveal phase transitions in detectability. Through simulation studies, we demonstrate that the proposed tests maintain correct size and competitive power, while standard cluster-robust and bootstrap procedures can exhibit substantial size distortions."}
{"id": "2601.08596", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.08596", "abs": "https://arxiv.org/abs/2601.08596", "authors": ["Marcus Gehrmann", "Håkon Tjelmeland"], "title": "Sparsifying transform priors in Gaussian graphical models", "comment": null, "summary": "Bayesian methods constitute a popular approach for estimating the conditional independence structure in Gaussian graphical models, since they can quantify the uncertainty through the posterior distribution. Inference in this framework is typically carried out with Markov chain Monte Carlo (MCMC). However, the most widely used choice of prior distribution for the precision matrix, the so called G-Wishart distribution, suffers from an intractable normalizing constant, which gives rise to the problem of double intractability in the updating steps of the MCMC algorithm. In this article, we propose a new class of prior distributions for the precision matrix, termed ST priors, that allow for the construction of MCMC algorithms that do not suffer from double intractability issues. A realization from an ST prior distribution is obtained by applying a sparsifying transform on a matrix from a distribution with support in the set of all positive definite matrices. We carefully present the theory behind the construction of our proposed class of priors and also perform some numerical experiments, where we apply our methods on a human gene expression dataset. The results suggest that our proposed MCMC algorithm is able to converge and achieve acceptable mixing when applied on the real data."}
{"id": "2601.08177", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08177", "abs": "https://arxiv.org/abs/2601.08177", "authors": ["Hongbing Yu", "Jiyu Wang", "Xiaojun Zhang", "Mingsheng Zhao"], "title": "Research on Mechanical Properties and Deformation-Fracture Energy Consumption Characteristics of Plateau Frozen Rocks", "comment": null, "summary": "The exploitation of mineral resources in plateau regions is confronted with critical challenges including low blasting efficiency, excessive energy consumption,and compromised operational safety when dealing with low-temperature water-bearing frozen rock masses.This study systematically investigates the dynamic-static mechanical properties,deformation-fracture behaviors,and energy consumption characteristics of plateau frozen sandstone under the coupled effects of temperature and moisture content (5%-15%).The research methodology integrates field sampling, low-pressure low-temperature simulation tests, graded impact loading tests, and numerical inversion analysis. Results demonstrate that freezing significantly enhances the dynamic strength and brittleness of saturated sandstone.The pore structure undergoes substantial evolution with decreasing temperature, with the porosity increasing by 63.15%.Based on PFC3D microscopic simulations, the mechanism of frost heave damage and the regulatory effect of water-ice phase transition on rock mechanical behaviors are elucidated.A quantitative analysis method for energy dissipation is proposed, revealing that the energy absorption increment of frozen rocks is higher than that of room-temperature samples.The findings provide a theoretical basis and technical support for optimizing blasting parameters, realizing directional energy release,and promoting green construction of frozen rock masses in high-altitude areas."}
{"id": "2601.08177", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08177", "abs": "https://arxiv.org/abs/2601.08177", "authors": ["Hongbing Yu", "Jiyu Wang", "Xiaojun Zhang", "Mingsheng Zhao"], "title": "Research on Mechanical Properties and Deformation-Fracture Energy Consumption Characteristics of Plateau Frozen Rocks", "comment": null, "summary": "The exploitation of mineral resources in plateau regions is confronted with critical challenges including low blasting efficiency, excessive energy consumption,and compromised operational safety when dealing with low-temperature water-bearing frozen rock masses.This study systematically investigates the dynamic-static mechanical properties,deformation-fracture behaviors,and energy consumption characteristics of plateau frozen sandstone under the coupled effects of temperature and moisture content (5%-15%).The research methodology integrates field sampling, low-pressure low-temperature simulation tests, graded impact loading tests, and numerical inversion analysis. Results demonstrate that freezing significantly enhances the dynamic strength and brittleness of saturated sandstone.The pore structure undergoes substantial evolution with decreasing temperature, with the porosity increasing by 63.15%.Based on PFC3D microscopic simulations, the mechanism of frost heave damage and the regulatory effect of water-ice phase transition on rock mechanical behaviors are elucidated.A quantitative analysis method for energy dissipation is proposed, revealing that the energy absorption increment of frozen rocks is higher than that of room-temperature samples.The findings provide a theoretical basis and technical support for optimizing blasting parameters, realizing directional energy release,and promoting green construction of frozen rock masses in high-altitude areas."}
{"id": "2601.08460", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.08460", "abs": "https://arxiv.org/abs/2601.08460", "authors": ["Topias Terho", "Fabricio Oliveira", "Ahti Salo", "Pedro Munari"], "title": "An efficient mixed-integer linear programming formulation for solving influence diagrams", "comment": null, "summary": "Influence diagrams represent decision-making problems with interdependencies between random events, decisions, and consequences. Traditionally, they have been solved using algorithms that determine the expected utility-maximizing decision strategy. In contrast, state-of-the-art solution approaches convert influence diagrams into a mixed-integer linear programming (MILP) model, which can be solved with powerful off-the-shelf MILP solvers. From a computational standpoint, the existing MILP formulations can be efficiently solved when applied to influence diagrams that represent periodic (or sequential) decision processes, which can be cast as partially observable Markov Decision Processes. However, they are inefficient in problems that lack a periodic structure or if the nodes in the influence diagram have large state spaces, thus limiting their practical use. In this paper, we present an efficient MILP formulation that is specifically designed for influence diagrams that are challenging for the earlier MILP formulation-based methods. Additionally, we present how the proposed formulation can be adapted to maximize conditional value-at-risk and how chance and logical constraints can be incorporated into the formulation, thus retaining the modeling flexibility of the MILP-based methods. Finally, we perform computational experiments addressing problems from the literature and compare the computational efficiency of the proposed formulation against the available MILP formulations for the reported influence diagrams. We find that the MILP models based on the proposed formulations can be solved significantly more efficiently compared to the state-of-the-art when solving influence diagrams that cannot be cast as partially observable Markov decision processes."}
{"id": "2601.07890", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.07890", "abs": "https://arxiv.org/abs/2601.07890", "authors": ["Renata Wong"], "title": "Quantum circuit compilation for fermionic excitations using the Jordan-Wigner mapping", "comment": "6 pages", "summary": "This note bridges the gap between theoretical second quantization and practical quantum hardware by detailing the Jordan-Wigner mapping for the Unitary Coupled Cluster Singles and Doubles (UCCSD) ansatz. Using the hydrogen molecule in a minimal basis as a case study, we explicitly derive the Pauli strings required for single and double excitations. Additionally, we discuss the translation of these operators into quantum circuits, with a focus on implementation nuances such as the difference between mathematical rotations and physical gates like the $\\sqrt{X}$ (SX) gate."}
{"id": "2601.08783", "categories": ["cond-mat.stat-mech", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.08783", "abs": "https://arxiv.org/abs/2601.08783", "authors": ["Eline K. Kempkes", "Alberto Pérez de Alba Ortíz"], "title": "Bayesian umbrella quadrature accelerates free-energy calculations across diverse molecular systems and processes", "comment": "42 pages, 8 figures, SI included", "summary": "Biased sampling in molecular dynamics simulations overcomes timescale limitations and delivers free-energy landscapes, essential to understand complex atomistic phenomena. However, when applied across diverse systems and processes, biasing protocols often require time- and resource-consuming fine-tuning. In search for robustness, we boost a prominent biasing method, Umbrella Sampling. To estimate the value of an integral, i.e., the free energy, our Bayesian Umbrella Quadrature (BUQ) method iteratively selects gradient samples, i.e., bias locations, that most reduce the posterior integral variance based on a noise-tolerant Gaussian process model, which also effectively interpolates between samples. We validate the method for a conformational change in a small peptide, a water-to-ice phase transition, and a substitution chemical reaction; obtaining excellent accuracies and speedups. To ease adoption of this more automated and universal free-energy method, we interface BUQ with wide-spread simulation packages and share hyperparametrization guidelines."}
{"id": "2601.08478", "categories": ["math.NA", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2601.08478", "abs": "https://arxiv.org/abs/2601.08478", "authors": ["Mattia Corti", "Andrew Ahern", "Alain Goriely", "Ellen Kuhl", "Paola F. Antonietti"], "title": "A whole-brain model of amyloid beta accumulation and cerebral hypoperfusion in Alzheimer's disease", "comment": null, "summary": "Accumulation of amyloid beta proteins is a defining feature of Alzheimer's disease, and is usually accompanied by cerebrovascular pathology. Evidence suggests that amyloid beta and cerebrovascular pathology are mutually reinforcing; in particular, amyloid beta suppresses perfusion by constricting capillaries, and hypoperfusion promotes the production of amyloid beta. Here, we propose a whole-brain model coupling amyloid beta and blood vessel through a hybrid model consisting of a reaction-diffusion system for the protein dynamics and porous-medium model of blood flow within and between vascular networks: arterial, capillary and venous. We discretize the resulting parabolic--elliptic system of PDEs by means of a high-order discontinuous Galerkin method in space and an implicit Euler scheme in time. Simulations in realistic brain geometries demonstrate the emergence of multistability, implying that a sufficiently large pathogenic protein seeds is necessary to trigger disease outbreak. Motivated by the \"two-hit vascular hypothesis\" of Alzheimer's disease that hypoperfusive vascular damage triggers amyloid beta pathology, we also demonstrate that localized hypoperfusion, in response to injury, can destabilize the healthy steady state and trigger brain-wide disease outbreak."}
{"id": "2601.08707", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.08707", "abs": "https://arxiv.org/abs/2601.08707", "authors": ["Kosuke Morikawa", "Jae Kwang Kim"], "title": "Semiparametric Efficient Data Integration Using the Dual-Frame Sampling Framework", "comment": null, "summary": "Integrating probability and non-probability samples is increasingly important, yet unknown sampling mechanisms in non-probability sources complicate identification and efficient estimation. We develop semiparametric theory for dual-frame data integration and propose two complementary estimators. The first models the non-probability inclusion probability parametrically and attains the semiparametric efficiency bound. We introduce an identifiability condition based on strong monotonicity that identifies sampling-model parameters without instrumental variables, even under informative (non-ignorable) selection, using auxiliary information from the probability sample; it remains valid without record linkage between samples. The second estimator, motivated by a two-stage sampling approximation, avoids explicit modeling of the non-probability mechanism; though not fully efficient, it is efficient within a restricted augmentation class and is robust to misspecification. Simulations and an application to the Culture and Community in a Time of Crisis public simulation dataset show efficiency gains under correct specification and stable performance under misspecification and weak identification. Methods are implemented in the R package \\texttt{dfSEDI}."}
{"id": "2601.08600", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.08600", "abs": "https://arxiv.org/abs/2601.08600", "authors": ["Rodrigo M. R. de Medeiros", "Francisco F. Queiroz"], "title": "Flexible modeling of nonnegative continuous data: Box-Cox symmetric regression and its zero-adjusted extension", "comment": null, "summary": "The Box-Cox symmetric distributions constitute a broad class of probability models for positive continuous data, offering flexibility in modeling skewness and tail behavior. Their parameterization allows a straightforward quantile-based interpretation, which is particularly useful in regression modeling. Despite their potential, only a few specific distributions within this class have been explored in regression contexts, and zero-adjusted extensions have not yet been formally addressed in the literature. This paper formalizes the class of Box-Cox symmetric regression models and introduces a new zero-adjusted extension suitable for modeling data with a non-negligible proportion of observations equal to zero. We discuss maximum likelihood estimation, assess finite-sample performance through simulations, and develop diagnostic tools including residual analysis, local influence measures, and goodness-of-fit statistics. An empirical application on basic education expenditure illustrates the models' ability to capture complex patterns in zero-inflated and highly skewed nonnegative data. To support practical use, we developed the new BCSreg R package, which implements all proposed methods."}
{"id": "2601.08214", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08214", "abs": "https://arxiv.org/abs/2601.08214", "authors": ["Jinghao Cao", "Wanchun Liu", "Yonghui Li", "Branka Vucetic"], "title": "Hybrid Centralized Distributed Control for Lifelong MAPF over Wireless Connections", "comment": "11pages, 9 figures", "summary": "In lifelong multi-agent path finding (MAPF) with many robots, unreliable wireless links and stochastic executions are the norm. Existing approaches typically either rely on centralized planning under idealized communication, or run fully distributed local controllers with fixed communication patterns; they rarely couple communication scheduling with policy learning, and thus struggle when bandwidth is scarce or packets are frequently dropped. We address this joint control--communication problem and propose a hybrid centralized--distributed scheme: a centralized cloud policy sends small residual corrections only when selected, while a lightweight on-board Gated recurrent unit (GRU) policy provides a safe default fallback when wireless connection is not available."}
{"id": "2601.08214", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08214", "abs": "https://arxiv.org/abs/2601.08214", "authors": ["Jinghao Cao", "Wanchun Liu", "Yonghui Li", "Branka Vucetic"], "title": "Hybrid Centralized Distributed Control for Lifelong MAPF over Wireless Connections", "comment": "11pages, 9 figures", "summary": "In lifelong multi-agent path finding (MAPF) with many robots, unreliable wireless links and stochastic executions are the norm. Existing approaches typically either rely on centralized planning under idealized communication, or run fully distributed local controllers with fixed communication patterns; they rarely couple communication scheduling with policy learning, and thus struggle when bandwidth is scarce or packets are frequently dropped. We address this joint control--communication problem and propose a hybrid centralized--distributed scheme: a centralized cloud policy sends small residual corrections only when selected, while a lightweight on-board Gated recurrent unit (GRU) policy provides a safe default fallback when wireless connection is not available."}
{"id": "2601.08494", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.08494", "abs": "https://arxiv.org/abs/2601.08494", "authors": ["Michael Cummins", "Eric Kerrigan"], "title": "A New Duality-Free Framework for Convex Optimisation with Superlinear Convergence and Effective Warm-Starting", "comment": null, "summary": "Modern second order solvers for convex optimisation, such as interior point methods, rely on primal dual information and are difficult to warm start, limiting their applicability in real time control. We propose the PVM, a duality free framework that reformulates the constrained problem as the unconstrained minimisation of a value function. The resulting problem always has a solution, yields a certificate of infeasibility and is amenable to warm starting. We develop a second order algorithm for Quadratic Programming based on the PPA and semismooth Newton methods, and establish sufficient conditions for superlinear convergence to an arbitrarily small neighbourhood of the solution. Numerical experiments on a MPC problem demonstrate competitive performance with state of the art solvers from a cold start and up to 70\\% reduction in Newton iterations when warm starting."}
{"id": "2601.07932", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2601.07932", "abs": "https://arxiv.org/abs/2601.07932", "authors": ["A. S. Sanz"], "title": "Bohmian mechanics: A legitimate hydrodynamic picture for quantum mechanics, and beyond", "comment": "22 pages, 6 figures; based on the talk given at the Basil Hiley Memorial Symposium (UCL, June 30, 2025)", "summary": "Since its inception, Bohmian mechanics has been surrounded by a halo of controversy. Originally proposed to bypass the limitations imposed by von Neumann's theorem on the impossibility of hidden-variable models in quantum mechanics, it faced strong opposition from the outset. Over time, however, its use in tackling specific problems across various branches of physics has led to a gradual shift in attitude, turning the early resistance into a more moderate acceptance. A plausible explanation for this change may be that, since the late 1990s and early 2000s, Bohmian mechanics has been taking on a more operational and practical role. The original hidden-variable idea has gradually faded from its framework, giving way to a more pragmatic approach that treats it as a suitable analytical and computational tool. This discussion explores how and why such a shift in perspective has occurred and, therefore, answers questions such as whether Bohmian mechanics should be considered once and for all a legitimate quantum representation (i.e., worth being taught in elementary quantum mechanics courses) or, by extension, whether these ideas can be transferred to and benefit other fields. Here, the Schrödinger equation and several specific numerical examples are re-examined in the light of a less restrictive view than the standard one usually adopted in quantum mechanics."}
{"id": "2601.07926", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.07926", "abs": "https://arxiv.org/abs/2601.07926", "authors": ["Massimo Bernaschi", "Luis Antonio Fernández", "Isidoro González-Adalid Pemartín", "Víctor Martín-Mayor", "Giorgio Parisi", "Federico Ricci-Tersenghi"], "title": "Low energy excitations in a long prism geometry: computing the lower critical dimension of the Ising spin glass", "comment": null, "summary": "We propose a general method for studying systems that display excitations with arbitrarily low energy in their low-temperature phase. We argue that in a rectangular right prism geometry, with longitudinal size much larger than the transverse size, correlations decay exponentially (at all temperatures) along the longitudinal dimension, but the scaling of the correlation length with the transverse size carries crucial information from which the lower critical dimension can be inferred. The method is applied in the particularly demanding context of Ising spin glasses at zero magnetic field. The lower critical dimension and the multifractal spectrum for the correlation function are computed from large-scale numerical simulations. Several technical novelties (such as the unexpectedly crucial performance of Houdayer's cluster method or the convenience of using open - rather than periodic - boundary conditions) allow us to study three-dimensional prisms with transverse dimensions up to $L=24$ and effectively infinite longitudinal dimensions down to low temperatures. The value that we find for the lower critical dimension turns out to be in agreement with expectations from both the Replica Symmetry Breaking theory and the Droplet model for spin glasses. We argue that our novel setting holds promise in clarifying which of the two competing theories more accurately describes three-dimensional spin glasses."}
{"id": "2601.08498", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.08498", "abs": "https://arxiv.org/abs/2601.08498", "authors": ["Jan Giesselmann", "Philipp Öffner", "Robert Sauerborn"], "title": "A Structure Preserving Finite Volume Scheme for the Navier-Stokes-Korteweg Equations", "comment": null, "summary": "We present a semi-discrete finite volume scheme for the local NavierStokes-Korteweg and Euler-Korteweg systems. Our scheme is applicable for equidistant Cartesian meshes in one and two space dimensions. In contrast to other works, which employ, for example, hyperbolic approximations of the equations or auxiliary-variable approaches leading to extended systems, our scheme operates directly on the original system. We prove that it conserves mass and momentum and is energy stable. Numerical experiments complement our theoretical findings, showing that the scheme is convergent of order one if employed with explicit or implicit time discretisation."}
{"id": "2601.08610", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.08610", "abs": "https://arxiv.org/abs/2601.08610", "authors": ["Wenxuan Guo", "Panos Toulis", "Yuhao Wang"], "title": "Permutation Inference under Multi-way Clustering and Missing Data", "comment": "55 pages, 5 figures", "summary": "Econometric applications with multi-way clustering often feature a small number of effective clusters or heavy-tailed data, making standard cluster-robust and bootstrap inference unreliable in finite samples. In this paper, we develop a framework for finite-sample valid permutation inference in linear regression with multi-way clustering under an assumption of conditional exchangeability of the errors. Our assumption is closely related to the notion of separate exchangeability studied in earlier work, but can be more realistic in many economic settings as it imposes minimal restrictions on the covariate distribution. We construct permutation tests of significance that are valid in finite samples and establish theoretical power guarantees, in contrast to existing methods that are justified only asymptotically. We also extend our methodology to settings with missing data and derive power results that reveal phase transitions in detectability. Through simulation studies, we demonstrate that the proposed tests maintain correct size and competitive power, while standard cluster-robust and bootstrap procedures can exhibit substantial size distortions."}
{"id": "2601.08335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08335", "abs": "https://arxiv.org/abs/2601.08335", "authors": ["Moussa Labbadi", "Christophe Roman", "Yacine Chitour"], "title": "On Robust Fixed-Time Stabilization of the Cauchy Problem in Hilbert Spaces", "comment": null, "summary": "This paper presents finite-time and fixed-time stabilization results for inhomogeneous abstract evolution problems, extending existing theories. We prove well-posedness for strong and weak solutions, and estimate upper bounds for settling times for both homogeneous and inhomogeneous systems. We generalize finite-dimensional results to infinite-dimensional systems and demonstrate partial state stabilization with actuation on a subset of the domain. The interest of these results are illustrated through an application of a heat equation with memory term."}
{"id": "2601.08335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08335", "abs": "https://arxiv.org/abs/2601.08335", "authors": ["Moussa Labbadi", "Christophe Roman", "Yacine Chitour"], "title": "On Robust Fixed-Time Stabilization of the Cauchy Problem in Hilbert Spaces", "comment": null, "summary": "This paper presents finite-time and fixed-time stabilization results for inhomogeneous abstract evolution problems, extending existing theories. We prove well-posedness for strong and weak solutions, and estimate upper bounds for settling times for both homogeneous and inhomogeneous systems. We generalize finite-dimensional results to infinite-dimensional systems and demonstrate partial state stabilization with actuation on a subset of the domain. The interest of these results are illustrated through an application of a heat equation with memory term."}
{"id": "2601.08547", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08547", "abs": "https://arxiv.org/abs/2601.08547", "authors": ["Jona-Maria Diederen", "Holger Rauhut", "Ulrich Terstiege"], "title": "Convergence of gradient flow for learning convolutional neural networks", "comment": "17 pages", "summary": "Convolutional neural networks are widely used in imaging and image recognition. Learning such networks from training data leads to the minimization of a non-convex function. This makes the analysis of standard optimization methods such as variants of (stochastic) gradient descent challenging. In this article we study the simplified setting of linear convolutional networks. We show that the gradient flow (to be interpreted as an abstraction of gradient descent) applied to the empirical risk defined via certain loss functions including the square loss always converges to a critical point, under a mild condition on the training data."}
{"id": "2601.07934", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.07934", "abs": "https://arxiv.org/abs/2601.07934", "authors": ["Samuel Goodwin", "Brian K. McFarland", "Manuel H. Muñoz-Arias", "Edward C. Tortorici", "Melissa C. Revelle", "Christopher G. Yale", "Daniel S. Lobser", "Susan M. Clark", "Mohan Sarovar"], "title": "Data-driven learning of non-Markovian quantum dynamics", "comment": "15 pages, 7 figures", "summary": "Fault-tolerant quantum computing requires extremely precise knowledge and control of qubit dynamics during the application of a gate. We develop a data-driven learning protocol for characterizing quantum gates that builds off previous work on learning the Nakajima-Mori-Zwanzig (NMZ) formulation of open system dynamics from time series data, which allows detailed reconstruction of quantum evolution, including non-Markovian dynamics. We demonstrate this learning technique on three different systems: a simulation of a qubit whose dynamics are purely Markovian, a simulation of a driven qubit coupled to stochastic noise produced by an Ornstein-Uhlenbeck process, and trapped-ion experimental data of a driven qubit whose noise environment is not characterized ahead of time. Our technique is able to learn the generators of time evolution, or the NMZ operators, in all three cases and can learn the timescale in which the qubit dynamics can no longer be accurately described by a purely Markovian model. Our technique complements existing quantum gate characterization methods such as gate set tomography by explicitly capturing non-Markovianity in the gate generator, thus allowing for more thorough diagnosis of noise sources."}
{"id": "2601.07937", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.07937", "abs": "https://arxiv.org/abs/2601.07937", "authors": ["Zihao Qi", "Christopher Earls"], "title": "Attention in Krylov Space", "comment": "13 pages, 9 figures", "summary": "The Universal Operator Growth Hypothesis formulates time evolution of operators through Lanczos coefficients. In practice, however, numerical instability and memory cost limit the number of coefficients that can be computed exactly. In response to these challenges, the standard approach relies on fitting early coefficients to asymptotic forms, but such procedures can miss subleading, history-dependent structures in the coefficients that subsequently affect reconstructed observables. In this work, we treat the Lanczos coefficients as a causal time sequence and introduce a transformer-based model to autoregressively predict future Lanczos coefficients from short prefixes. For both classical and quantum systems, our machine-learning model outperforms asymptotic fits, in both coefficient extrapolation and physical observable reconstruction, by achieving an order-of-magnitude reduction in error. Our model also transfers across system sizes: it can be trained on smaller systems and then be used to extrapolate coefficients on a larger system without retraining. By probing the learned attention patterns and performing targeted attention ablations, we identify which portions of the coefficient history are most influential for accurate forecasts."}
{"id": "2601.08527", "categories": ["math.NA", "cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.08527", "abs": "https://arxiv.org/abs/2601.08527", "authors": ["Chenguang Duan", "Yuling Jiao", "Gabriele Steidl", "Christian Wald", "Jerry Zhijian Yang", "Ruizhe Zhang"], "title": "Sampling via Stochastic Interpolants by Langevin-based Velocity and Initialization Estimation in Flow ODEs", "comment": null, "summary": "We propose a novel method for sampling from unnormalized Boltzmann densities based on a probability-flow ordinary differential equation (ODE) derived from linear stochastic interpolants. The key innovation of our approach is the use of a sequence of Langevin samplers to enable efficient simulation of the flow. Specifically, these Langevin samplers are employed (i) to generate samples from the interpolant distribution at intermediate times and (ii) to construct, starting from these intermediate times, a robust estimator of the velocity field governing the flow ODE. For both applications of the Langevin diffusions, we establish convergence guarantees. Extensive numerical experiments demonstrate the efficiency of the proposed method on challenging multimodal distributions across a range of dimensions, as well as its effectiveness in Bayesian inference tasks."}
{"id": "2601.08707", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.08707", "abs": "https://arxiv.org/abs/2601.08707", "authors": ["Kosuke Morikawa", "Jae Kwang Kim"], "title": "Semiparametric Efficient Data Integration Using the Dual-Frame Sampling Framework", "comment": null, "summary": "Integrating probability and non-probability samples is increasingly important, yet unknown sampling mechanisms in non-probability sources complicate identification and efficient estimation. We develop semiparametric theory for dual-frame data integration and propose two complementary estimators. The first models the non-probability inclusion probability parametrically and attains the semiparametric efficiency bound. We introduce an identifiability condition based on strong monotonicity that identifies sampling-model parameters without instrumental variables, even under informative (non-ignorable) selection, using auxiliary information from the probability sample; it remains valid without record linkage between samples. The second estimator, motivated by a two-stage sampling approximation, avoids explicit modeling of the non-probability mechanism; though not fully efficient, it is efficient within a restricted augmentation class and is robust to misspecification. Simulations and an application to the Culture and Community in a Time of Crisis public simulation dataset show efficiency gains under correct specification and stable performance under misspecification and weak identification. Methods are implemented in the R package \\texttt{dfSEDI}."}
{"id": "2601.08338", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.08338", "abs": "https://arxiv.org/abs/2601.08338", "authors": ["Luca Ballotta", "Geethu Joseph"], "title": "Minimal Actuator Selection", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Selecting a few available actuators to ensure the controllability of a linear system is a fundamental problem in control theory. Previous works either focus on optimal performance, simplifying the controllability issue, or make the system controllable under structural assumptions, such as in graphs or when the input matrix is a design parameter. We generalize these approaches to offer a precise characterization of the general minimal actuator selection problem where a set of actuators is given, described by a fixed input matrix, and goal is to choose the fewest actuators that make the system controllable. We show that this problem can be equivalently cast as an integer linear program and, if actuation channels are sufficiently independent, as a set multicover problem under multiplicity constraints. The latter equivalence is always true if the state matrix has all distinct eigenvalues, in which case it simplifies to the set cover problem. Such characterizations hold even when a robust selection that tolerates a given number of faulty actuators is desired. Our established connection legitimates a designer to use algorithms from the rich literature on the set multicover problem to select the smallest subset of actuators, including exact solutions that do not require brute-force search."}
{"id": "2601.08338", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.08338", "abs": "https://arxiv.org/abs/2601.08338", "authors": ["Luca Ballotta", "Geethu Joseph"], "title": "Minimal Actuator Selection", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Selecting a few available actuators to ensure the controllability of a linear system is a fundamental problem in control theory. Previous works either focus on optimal performance, simplifying the controllability issue, or make the system controllable under structural assumptions, such as in graphs or when the input matrix is a design parameter. We generalize these approaches to offer a precise characterization of the general minimal actuator selection problem where a set of actuators is given, described by a fixed input matrix, and goal is to choose the fewest actuators that make the system controllable. We show that this problem can be equivalently cast as an integer linear program and, if actuation channels are sufficiently independent, as a set multicover problem under multiplicity constraints. The latter equivalence is always true if the state matrix has all distinct eigenvalues, in which case it simplifies to the set cover problem. Such characterizations hold even when a robust selection that tolerates a given number of faulty actuators is desired. Our established connection legitimates a designer to use algorithms from the rich literature on the set multicover problem to select the smallest subset of actuators, including exact solutions that do not require brute-force search."}
{"id": "2601.08551", "categories": ["math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.08551", "abs": "https://arxiv.org/abs/2601.08551", "authors": ["Guangyu Wu", "Anders Lindquist"], "title": "Truncated Multidimensional Trigonometric Moment Problem: A Choice of Bases and the Unique Solution", "comment": "16 pages, 3 figures", "summary": "In this prelinimary version of paper, we propose to give a complete solution to the Truncated Multidimensional Trigonometric Moment Problem (TMTMP) from a system and signal processing perspective. In mathematical TMTMPs, people care about whether a solution exists for a given sequence of multidimensional trigonometric moments. The solution can have the form of an atomic measure. However, for the TMTMPs in system and signal processing, a solution as an analytic rational function, of which the numerator and the denominator are positive polynomials, is desired for the ARMA modelling of a stochastic process, which is the so-called Multidimensional Rational Covariance Extension problem (RCEP) . In the literature, the feasible domain of the TMTMPs, where the spectral density is positive, is difficult to obtain given a specific choice of basis functions, which causes severe problems in the Multidimensional RCEP. In this paper, we propose a choice of basis functions, and a corresponding estimation scheme by convex optimization, for the TMTMPs, with which the trigonometric moments of the spectral estimate are exactly the sample moments. We propose an explicit condition for the convex optimization problem for guaranteeing the positiveness of the spectral estimation. The map from the parameters of the estimate to the trigonometric moments is proved to be a diffeomorphism, which ensures the existence and uniqueness of solution. The statistical properties of the proposed spectral density estimation scheme are comprehensively proved, including the consistency, (asymptotical) unbiasedness, convergence rate and efficiency under a mild assumption. This well-posed treatment is then applied to a system identification task, and the simulation results validate our proposed treatment for the TMTMP in system and signal processing."}
{"id": "2601.07937", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.07937", "abs": "https://arxiv.org/abs/2601.07937", "authors": ["Zihao Qi", "Christopher Earls"], "title": "Attention in Krylov Space", "comment": "13 pages, 9 figures", "summary": "The Universal Operator Growth Hypothesis formulates time evolution of operators through Lanczos coefficients. In practice, however, numerical instability and memory cost limit the number of coefficients that can be computed exactly. In response to these challenges, the standard approach relies on fitting early coefficients to asymptotic forms, but such procedures can miss subleading, history-dependent structures in the coefficients that subsequently affect reconstructed observables. In this work, we treat the Lanczos coefficients as a causal time sequence and introduce a transformer-based model to autoregressively predict future Lanczos coefficients from short prefixes. For both classical and quantum systems, our machine-learning model outperforms asymptotic fits, in both coefficient extrapolation and physical observable reconstruction, by achieving an order-of-magnitude reduction in error. Our model also transfers across system sizes: it can be trained on smaller systems and then be used to extrapolate coefficients on a larger system without retraining. By probing the learned attention patterns and performing targeted attention ablations, we identify which portions of the coefficient history are most influential for accurate forecasts."}
{"id": "2601.08137", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.08137", "abs": "https://arxiv.org/abs/2601.08137", "authors": ["Kazuhiro Seki", "Yuta Kikuchi", "Tomoya Hayata", "Seiji Yunoki"], "title": "Dissipative ground-state preparation of a quantum spin chain on a trapped-ion quantum computer", "comment": "15 pages, 9 figures", "summary": "We demonstrate a dissipative protocol for ground-state preparation of a quantum spin chain on a trapped-ion quantum computer. As a first step, we derive a Kraus representation of a dissipation channel for the protocol recently proposed by Ding et al. [Phys. Rev. Res. 6, 033147 (2024)] that still holds for arbitrary temporal discretization steps, extending the analysis beyond the Lindblad dynamics regime. The protocol guarantees that the fidelity with the ground state monotonically increases (or remains unchanged) under repeated applications of the channel to an arbitrary initial state, provided that the ground state is the unique steady state of the dissipation channel. Using this framework, we implement dissipative ground-state preparation of a transverse-field Ising chain for up to 19 spins on the trapped-ion quantum computer Reimei provided by Quantinuum. Despite the presence of hardware noise, the dynamics consistently converges to a low-energy state far away from the maximally mixed state even when the corresponding quantum circuits contain as many as 4110 entangling gates, demonstrating the intrinsic robustness of the protocol. By applying zero-noise extrapolation, the resulting energy expectation values are systematically improved to agree with noiseless simulations within statistical uncertainties."}
{"id": "2601.08553", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.08553", "abs": "https://arxiv.org/abs/2601.08553", "authors": ["Mahvish Samar", "Abdual Shahkoor"], "title": "A note on condition numbers for generalized inverse C^‡_A and their statistical estimation", "comment": null, "summary": "In this paper, we consider the condition number for the generalized inverse C^‡_A. We first present the explicit expression of normwise mixed and componentwise condition numbers. Then, we derive the explicit expression of normwise condition number without Kronecker product using the classical method for condition numbers. With the intermediate result, i.e., the derivative of C^‡_A, we can recover the explicit expressions of condition numbers for solution of Indefinite least squares problem with equality constraint. To estimate these condition numbers with high reliability, we choose the probabilistic spectral norm estimator and the small-sample statistical condition estimation method and devise three algorithms. Numerical experiments are provided to illustrate the obtained results"}
{"id": "2601.08736", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.08736", "abs": "https://arxiv.org/abs/2601.08736", "authors": ["Ping Zhao", "Long Feng"], "title": "Note on High Dimensional Spatial-Sign Test for One Sample Problem", "comment": null, "summary": "We revisit the null distribution of the high-dimensional spatial-sign test of Wang et al. (2015) under mild structural assumptions on the scatter matrix. We show that the standardized test statistic converges to a non-Gaussian limit, characterized as a mixture of a normal component and a weighted chi-square component. To facilitate practical implementation, we propose a wild bootstrap procedure for computing critical values and establish its asymptotic validity. Numerical experiments demonstrate that the proposed bootstrap test delivers accurate size control across a wide range of dependence settings and dimension-sample-size regimes."}
{"id": "2601.08339", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08339", "abs": "https://arxiv.org/abs/2601.08339", "authors": ["Wei-Jen Liu", "Wei-Yu Chiu", "Weiqi Hua"], "title": "Blockchain-Enabled Renewable Energy Certificate Trading: A Secure and Privacy-Preserving Approach", "comment": "26 pages, 7 figures", "summary": "In the 21st century, transitioning to renewable energy sources is imperative, with fossil fuel reserves depleting rapidly and recognizing critical environmental issues such as climate change, air pollution, water pollution, and habitat destruction. Embracing renewable energy is not only an environmental necessity but also a strategic move with multiple benefits. By shifting to renewable energy sources and supporting their production through the acquisition of renewable energy certificates, we foster innovation and drive economic growth in the renewable energy sector. This, in turn, reduces greenhouse gas emissions, aligning with global efforts to mitigate climate change. Additionally, renewable energy certificates ensure compliance with regulations that mandate the use of renewable energy, enhancing legal adherence while promoting transparency and trust in energy sourcing. To monitor the uptake of renewable energy, governments have implemented Renewable Energy Certificates (RECs) as a tracking mechanism for the production and consumption of renewable energy. However, there are two main challenges to the existing REC schema: 1) The RECs have not been globally adopted due to inconsistent design; 2) The consumer privacy has not been well incorporated in the design of blockchain. In this study, we investigate the trading of RECs between suppliers and consumers using the directed acyclic graph (DAG) blockchain system and introduce a trading schema to help protect consumer information. Our results demonstrate lower transaction time by 41\\% and energy consumption by 65\\% compared to proof-of-stake."}
{"id": "2601.08339", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08339", "abs": "https://arxiv.org/abs/2601.08339", "authors": ["Wei-Jen Liu", "Wei-Yu Chiu", "Weiqi Hua"], "title": "Blockchain-Enabled Renewable Energy Certificate Trading: A Secure and Privacy-Preserving Approach", "comment": "26 pages, 7 figures", "summary": "In the 21st century, transitioning to renewable energy sources is imperative, with fossil fuel reserves depleting rapidly and recognizing critical environmental issues such as climate change, air pollution, water pollution, and habitat destruction. Embracing renewable energy is not only an environmental necessity but also a strategic move with multiple benefits. By shifting to renewable energy sources and supporting their production through the acquisition of renewable energy certificates, we foster innovation and drive economic growth in the renewable energy sector. This, in turn, reduces greenhouse gas emissions, aligning with global efforts to mitigate climate change. Additionally, renewable energy certificates ensure compliance with regulations that mandate the use of renewable energy, enhancing legal adherence while promoting transparency and trust in energy sourcing. To monitor the uptake of renewable energy, governments have implemented Renewable Energy Certificates (RECs) as a tracking mechanism for the production and consumption of renewable energy. However, there are two main challenges to the existing REC schema: 1) The RECs have not been globally adopted due to inconsistent design; 2) The consumer privacy has not been well incorporated in the design of blockchain. In this study, we investigate the trading of RECs between suppliers and consumers using the directed acyclic graph (DAG) blockchain system and introduce a trading schema to help protect consumer information. Our results demonstrate lower transaction time by 41\\% and energy consumption by 65\\% compared to proof-of-stake."}
{"id": "2601.08614", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08614", "abs": "https://arxiv.org/abs/2601.08614", "authors": ["Dmitry Bylinkin", "Sergey Skorik", "Dmitriy Bystrov", "Leonid Berezin", "Aram Avetisyan", "Aleksandr Beznosikov"], "title": "Accelerated Methods with Complexity Separation Under Data Similarity for Federated Learning Problems", "comment": "30 pages, 4 theorems, 2 figures", "summary": "Heterogeneity within data distribution poses a challenge in many modern federated learning tasks. We formalize it as an optimization problem involving a computationally heavy composite under data similarity. By employing different sets of assumptions, we present several approaches to develop communication-efficient methods. An optimal algorithm is proposed for the convex case. The constructed theory is validated through a series of experiments across various problems."}
{"id": "2601.07953", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.07953", "abs": "https://arxiv.org/abs/2601.07953", "authors": ["Zheng-Zhi Sun", "Qi Ye", "Dong-Ling Deng"], "title": "Quantum automated theorem proving", "comment": null, "summary": "Automated theorem proving, or more broadly automated reasoning, aims at using computer programs to automatically prove or disprove mathematical theorems and logical statements. It takes on an essential role across a vast array of applications and the quest for enhanced theorem-proving capabilities remains a prominent pursuit in artificial intelligence. Here, we propose a generic framework for quantum automated theorem proving, where the intrinsic quantum superposition and entanglement features would lead to potential advantages. In particular, we introduce quantum representations of knowledge bases and propose corresponding reasoning algorithms for a variety of tasks. We show how automated reasoning can be achieved with quantum resolution in both propositional and first-order logic with quadratically reduced query complexity. In addition, we propose the quantum algebraic proving method for geometric theorems, extending Wu's algebraic approach beyond the classical setting. Through concrete examples, including geometry problems from the International Mathematical Olympiad, we demonstrate how a quantum computer may prove geometric theorems with quadratic better query complexity. Our results establish a primary approach towards building quantum automatic theorem provers, which would be crucial for practical applications of both near-term and future quantum technologies."}
{"id": "2601.08356", "categories": ["physics.geo-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.08356", "abs": "https://arxiv.org/abs/2601.08356", "authors": ["Sudip Sarkar", "Soumyajyoti Biswas"], "title": "Large earthquakes follow highly unequal ones", "comment": "6 pages, 7 figures", "summary": "It was conjectured for a long time that the tectonic plates are in a self-organized state of criticality and that the Gutenberg-Richter (power) law is a manifestation of that. It was recently shown that for a system near criticality, the inequality of their responses toward external driving could indicate proximity to the critical point. In this work, we show with numerical simulations and seismic data analysis that large earthquake events have a tendency to follow events that are highly unequal. We have applied this framework to various tectonically active regions, such as North America, Southern Japan, parts of South-East Asia and Indonesia."}
{"id": "2601.08561", "categories": ["math.NA", "math.FA"], "pdf": "https://arxiv.org/pdf/2601.08561", "abs": "https://arxiv.org/abs/2601.08561", "authors": ["V. Temlyakov"], "title": "Sampling recovery on classes defined by integral operators and sparse approximation with adaptive dictionaries", "comment": null, "summary": "In this paper we continue to develop the following general approach. We study asymptotic behavior of the errors of sampling recovery not for an individual smoothness class, how it is usually done, but for the collection of classes, which are defined by integral operators with kernels coming from a given class of functions. Earlier, such approach was realized for the Kolmogorov widths and very recently for the entropy numbers. It turns out that the above problem is closely related to the sparse approximation problem with respect to different redundant dictionaries. Specifically, the problem of sampling recovery is connected with sparse nonlinear approximation with respect to adaptive dictionaries, which means that the dictionary depends on the function under approximation."}
{"id": "2601.08551", "categories": ["math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.08551", "abs": "https://arxiv.org/abs/2601.08551", "authors": ["Guangyu Wu", "Anders Lindquist"], "title": "Truncated Multidimensional Trigonometric Moment Problem: A Choice of Bases and the Unique Solution", "comment": "16 pages, 3 figures", "summary": "In this prelinimary version of paper, we propose to give a complete solution to the Truncated Multidimensional Trigonometric Moment Problem (TMTMP) from a system and signal processing perspective. In mathematical TMTMPs, people care about whether a solution exists for a given sequence of multidimensional trigonometric moments. The solution can have the form of an atomic measure. However, for the TMTMPs in system and signal processing, a solution as an analytic rational function, of which the numerator and the denominator are positive polynomials, is desired for the ARMA modelling of a stochastic process, which is the so-called Multidimensional Rational Covariance Extension problem (RCEP) . In the literature, the feasible domain of the TMTMPs, where the spectral density is positive, is difficult to obtain given a specific choice of basis functions, which causes severe problems in the Multidimensional RCEP. In this paper, we propose a choice of basis functions, and a corresponding estimation scheme by convex optimization, for the TMTMPs, with which the trigonometric moments of the spectral estimate are exactly the sample moments. We propose an explicit condition for the convex optimization problem for guaranteeing the positiveness of the spectral estimation. The map from the parameters of the estimate to the trigonometric moments is proved to be a diffeomorphism, which ensures the existence and uniqueness of solution. The statistical properties of the proposed spectral density estimation scheme are comprehensively proved, including the consistency, (asymptotical) unbiasedness, convergence rate and efficiency under a mild assumption. This well-posed treatment is then applied to a system identification task, and the simulation results validate our proposed treatment for the TMTMP in system and signal processing."}
{"id": "2601.08372", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.08372", "abs": "https://arxiv.org/abs/2601.08372", "authors": ["Hiroki Sakamoto", "Kazuhiro Sato"], "title": "Data-Driven Time-Limited h2 Optimal Model Reduction for Linear Discrete-Time Systems", "comment": null, "summary": "This paper develops a data-driven h2 model reduction method for discrete-time linear time-invariant systems. Specifically, we solve the h2 model reduction problem defined over a finite horizon using only impulse response data. Furthermore, we show that the proposed data-driven algorithm converges to a stationary point under certain assumptions. Numerical experiments demonstrate that the proposed method constructs a good reduced-order model in terms of the h2 norm defined over the finite horizon using a SLICOT benchmark (the CD player model)."}
{"id": "2601.08372", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.08372", "abs": "https://arxiv.org/abs/2601.08372", "authors": ["Hiroki Sakamoto", "Kazuhiro Sato"], "title": "Data-Driven Time-Limited h2 Optimal Model Reduction for Linear Discrete-Time Systems", "comment": null, "summary": "This paper develops a data-driven h2 model reduction method for discrete-time linear time-invariant systems. Specifically, we solve the h2 model reduction problem defined over a finite horizon using only impulse response data. Furthermore, we show that the proposed data-driven algorithm converges to a stationary point under certain assumptions. Numerical experiments demonstrate that the proposed method constructs a good reduced-order model in terms of the h2 norm defined over the finite horizon using a SLICOT benchmark (the CD player model)."}
{"id": "2601.08630", "categories": ["math.OC", "math.AP", "math.CA"], "pdf": "https://arxiv.org/pdf/2601.08630", "abs": "https://arxiv.org/abs/2601.08630", "authors": ["Grégoire Nadin", "David Nahmani", "Nicolas Vauchelet"], "title": "Optimal Dirac controls for time-periodic bistable ODEs, application to population replacement", "comment": null, "summary": "This work addresses an optimal control problem on a dynamics governed by a nonlinear differential equation with a bistable time-periodic nonlinearity. This problem, relevant in population dynamics, models the strategy of replacing a population of A-type individuals by a population of B-type individuals in a time-varying environment, focusing on the evolution of the proportion of B-type individuals among the whole population. The control term accounts for the instant release of B-type individuals. Our main goal, after noting some interesting properties on the differential equation, is to determine the optimal time at which this release should be operated to ensure population replacement while minimizing the release effort. The results establish that the optimal release time appears to be the minimizer of a function involving the carrying capacity of the environment and the threshold periodic solution of the dynamics; they also describe the convergence of the whole optimal release strategy. An application to the biocontrol of mosquito populations using Wolbachia-infected individuals illustrates the relevance of the theoretical results. Wolbachia is a bacterium that helps preventing the transmission of some viruses from mosquitoes to humans, making the optimization of Wolbachia propagation in a mosquito population a crucial issue."}
{"id": "2601.08007", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08007", "abs": "https://arxiv.org/abs/2601.08007", "authors": ["Frank Victor Kowalski"], "title": "Interferometric discrepancy between the Schrödinger and Klein-Gordon wave equations due to their dissimilar phase velocities", "comment": null, "summary": "The Schrödinger equation predicts interference when a beamsplitter's trajectory includes a segment where its speed exceeds the phase velocity of a free non-zero rest mass particle that is in a momentum eigenstate. Such interference is neither possible for electromagnetic waves nor for eigenstates of momentum in the non-relativistic limit of the Klein-Gordon equation since the speed of the beamsplitter cannot exceed the phase velocity of the wave. The dual behavior of reflection and transmission in this case is discussed for dielectric and diffracting beamsplitters."}
{"id": "2601.08606", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.08606", "abs": "https://arxiv.org/abs/2601.08606", "authors": ["Alice Marché", "Hironobu Yoshida", "Alberto Nardin", "Hosho Katsura", "Leonardo Mazza"], "title": "Open quantum spin chains with non-reciprocity: a theoretical approach based on the time-dependent generalized Gibbs ensemble", "comment": "25 pages, 6 figues", "summary": "We study an open quantum spin chain with non-reciprocal dissipation using a theoretical approach known as time-dependent generalized Gibbs ensemble. In the regime of weak dissipation the system is fully characterized by its rapidity distribution and we derive a closed set of coupled differential equations governing their time evolution. We check the accuracy of this theory by benchmarking the results against numerical simulations. Using this framework we are able to compute both the magnetization density and current dynamics, identifying some relations between the two. The problem of the anomalous power-law exponents identified in a previous work is discussed. Our work constitutes a theoretical approach that is able to describe the physics of non-reciprocal open quantum spin chains beyond analyses based on non-interacting fermions."}
{"id": "2601.08594", "categories": ["math.NA", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.08594", "abs": "https://arxiv.org/abs/2601.08594", "authors": ["Rishi Leburu", "Levon Nurbekyan", "Lars Ruthotto"], "title": "Differentiating through Stochastic Differential Equations: A Primer", "comment": "20 pages, 3 figures", "summary": "Dynamical systems are essential to model various phenomena in physics, finance, economics, and are also of current interest in machine learning. A central modeling task is investigating parameter sensitivity, whether tuning atmospheric coefficients, computing financial Greeks, or optimizing neural networks. These sensitivities are mathematically expressed as derivatives of an objective function with respect to parameters of interest and are rarely available analytically, necessitating numerical methods for approximating them. While the literature for differentiation of deterministic systems is well-covered, the treatment of stochastic systems, such as stochastic differential equations (SDEs), in most curricula is less comprehensive than the subtleties arising from the interplay of noise and discretization require.\n  This paper provides a primer on numerical differentiation of SDEs organized as a two-tale narrative. Tale 1 demonstrates differentiating through discretized SDEs, known the discretize-optimize approach, is reliable for both Itô and Stratonovich calculus. Tale 2 examines the optimize-discretize approach, investigating the continuous limit of backward equations from Tale 1 corresponding to the desired gradients. Our aim is to equip readers with a clear guide on the numerical differentiation of SDEs: computing gradients correctly in both Itô and Stratonovich settings, understanding when discretize-optimize and optimize-discretize agree or diverge, and developing intuition for reasoning about stochastic differentiation beyond the cases explicitly covered."}
{"id": "2601.08445", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08445", "abs": "https://arxiv.org/abs/2601.08445", "authors": ["Guan-Ting Lin", "Wei-Yu Chiu", "Chien-Feng Wu", "Asef Nazari", "Dhananjay Thiruvady"], "title": "Multiobjective Model Predictive Control for Residential Demand Response Management Under Uncertainty", "comment": "29 pages, 5 figures", "summary": "Residential users in demand response programs must balance electricity costs and user dissatisfaction under real-time pricing. This study proposes a multiobjective model predictive control approach for home energy management systems with battery storage, aiming to minimize both objectives while mitigating uncertainties. Laguerre functions parameterize control signals, transforming the optimization problem into one with linear inequalities for efficient exploration. A constrained multiobjective evolutionary algorithm, incorporating convex sampler-based crossover and mutation, is developed to ensure feasible solutions. Simulations show that the proposed method outperforms existing approaches, limiting cost increases to 0.52\\% under uncertainties, compared to at least 2.3\\% with other methods."}
{"id": "2601.08445", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08445", "abs": "https://arxiv.org/abs/2601.08445", "authors": ["Guan-Ting Lin", "Wei-Yu Chiu", "Chien-Feng Wu", "Asef Nazari", "Dhananjay Thiruvady"], "title": "Multiobjective Model Predictive Control for Residential Demand Response Management Under Uncertainty", "comment": "29 pages, 5 figures", "summary": "Residential users in demand response programs must balance electricity costs and user dissatisfaction under real-time pricing. This study proposes a multiobjective model predictive control approach for home energy management systems with battery storage, aiming to minimize both objectives while mitigating uncertainties. Laguerre functions parameterize control signals, transforming the optimization problem into one with linear inequalities for efficient exploration. A constrained multiobjective evolutionary algorithm, incorporating convex sampler-based crossover and mutation, is developed to ensure feasible solutions. Simulations show that the proposed method outperforms existing approaches, limiting cost increases to 0.52\\% under uncertainties, compared to at least 2.3\\% with other methods."}
{"id": "2601.08672", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.08672", "abs": "https://arxiv.org/abs/2601.08672", "authors": ["Jiacheng Wu", "Qi Zhang"], "title": "The Ergodic Linear-Quadratic Optimal Control Problems with Random Periodic Coefficients", "comment": null, "summary": "In this paper, we concern with the ergodic linear-quadratic closed-loop optimal control problems with random periodic coefficients. We put forward the random periodic mean-square exponentially stable condition, and prove the random periodicity of solutions to state equation based on it. Then we prove the existence and uniqueness of random periodic solutions to two types of backward stochastic differential equations which serve as stochastic Riccati equations in the procedure of completing the square. With the random periodicity of state equation and stochastic Riccati equations, the ergodic cost functional on infinite horizon is simplified to an equivalent cost functional over a single periodic interval without limit. Finally, the closed-loop optimal controls are explicitly given based on random periodic solutions to state equation and stochastic Riccati equations."}
{"id": "2601.08014", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08014", "abs": "https://arxiv.org/abs/2601.08014", "authors": ["Yariv Yanay"], "title": "Learning Better Error Correction Codes with Hybrid Quantum-Assisted Machine Learning", "comment": "5 pages, 8 figures", "summary": "Quantum error correction is one of the fundamental building blocks of digital quantum computation. The Quantum Lego formalism has introduced a systematic way of constructing new stabilizer codes out of basic lego-like building blocks, which in previous work we have used to generate improved error correcting codes via an automated reinforcement learning process. Here, we take this a step further and show the use of a hybrid classical-quantum algorithm. We combine classical reinforcement learning with calls to two commercial quantum devices to search for a stabilizer code to correct errors specific to the device, as well as an induced photon loss error."}
{"id": "2601.08709", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08709", "abs": "https://arxiv.org/abs/2601.08709", "authors": ["Marc Salvadó-Benasco", "Aymane Kssim", "Alexander Heinlein", "Rolf Krause", "Serge Gratton", "Alena Kopaničáková"], "title": "Multi-Preconditioned LBFGS for Training Finite-Basis PINNs", "comment": "13 pages", "summary": "A multi-preconditioned LBFGS (MP-LBFGS) algorithm is introduced for training finite-basis physics-informed neural networks (FBPINNs). The algorithm is motivated by the nonlinear additive Schwarz method and exploits the domain-decomposition-inspired additive architecture of FBPINNs, in which local neural networks are defined on subdomains, thereby localizing the network representation. Parallel, subdomain-local quasi-Newton corrections are then constructed on the corresponding local parts of the architecture. A key feature is a novel nonlinear multi-preconditioning mechanism, in which subdomain corrections are optimally combined through the solution of a low-dimensional subspace minimization problem. Numerical experiments indicate that MP-LBFGS can improve convergence speed, as well as model accuracy over standard LBFGS while incurring lower communication overhead."}
{"id": "2601.08459", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08459", "abs": "https://arxiv.org/abs/2601.08459", "authors": ["Joseph Ross", "Damien Frost", "Stratos Chatzinikolaou", "Stephen Duncan", "David Howey"], "title": "Current and temperature imbalances in parallel-connected grid storage battery modules", "comment": null, "summary": "A key challenge with large battery systems is heterogeneous currents and temperatures in modules with parallel-connected cells. Although extreme currents and temperatures are detrimental to the performance and lifetime of battery cells, there is not a consensus on the scale of typical imbalances within grid storage modules. Here, we quantify these imbalances through simulations and experiments on an industrially representative grid storage battery module consisting of prismatic lithium iron phosphate cells, elucidating the evolution of current and temperature imbalances and their dependence on individual cell and module parameter variations. Using a sensitivity analysis, we find that varying contact resistances and cell resistances contribute strongly to temperature differences between cells, from which we define safety thresholds on cell-to-cell variability. Finally, we investigate how these thresholds change for different applications, to outline a set of robustness metrics that show how cycling at lower C-rates and narrower SOC ranges can mitigate failures."}
{"id": "2601.08459", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08459", "abs": "https://arxiv.org/abs/2601.08459", "authors": ["Joseph Ross", "Damien Frost", "Stratos Chatzinikolaou", "Stephen Duncan", "David Howey"], "title": "Current and temperature imbalances in parallel-connected grid storage battery modules", "comment": null, "summary": "A key challenge with large battery systems is heterogeneous currents and temperatures in modules with parallel-connected cells. Although extreme currents and temperatures are detrimental to the performance and lifetime of battery cells, there is not a consensus on the scale of typical imbalances within grid storage modules. Here, we quantify these imbalances through simulations and experiments on an industrially representative grid storage battery module consisting of prismatic lithium iron phosphate cells, elucidating the evolution of current and temperature imbalances and their dependence on individual cell and module parameter variations. Using a sensitivity analysis, we find that varying contact resistances and cell resistances contribute strongly to temperature differences between cells, from which we define safety thresholds on cell-to-cell variability. Finally, we investigate how these thresholds change for different applications, to outline a set of robustness metrics that show how cycling at lower C-rates and narrower SOC ranges can mitigate failures."}
{"id": "2601.08700", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.08700", "abs": "https://arxiv.org/abs/2601.08700", "authors": ["Nam Van Tran"], "title": "Novel Dynamical Systems with Finite-Time and Fixed-Time Stability for Generalized Inverse Mixed Variational Inequality Problems", "comment": null, "summary": "This paper investigates a class of generalized inverse mixed variational inequality problems (GIMVIPs), which consist in finding a vector $\\overline{w}\\in \\R^d$ such that \\[ F(\\bar w)\\in Ω\\quad \\text{and} \\quad \\langle h(\\bar w), v-F(\\bar w) \\rangle + g(v)-g(F(\\bar w)) \\ge 0, \\quad \\forall v\\in Ω, \\] where \\(h,F:\\R^d\\to\\R^d\\) are single-valued operators, \\(g:Ω\\to\\R\\cup\\{+\\infty\\}\\) is a proper function, and \\(Ω\\) is a closed convex set.\n  Two novel continuous-time dynamical systems are proposed to analyze the finite-time and fixed-time stability of solutions to GIMVIPs in finite-dimensional Hilbert spaces. Under suitable assumptions on the operators and model parameters, Lyapunov-based techniques are employed to establish finite-time and fixed-time convergence of the generated trajectories.\n  While both systems exhibit accelerated convergence, the settling time of the finite-time stable system depends on the initial condition, whereas the fixed-time stable system admits a uniform upper bound on the convergence time that is independent of the initial state. Moreover, an explicit forward Euler discretization of the continuous-time dynamics leads to a proximal point-type algorithm that preserves the fixed-time convergence property. Rigorous convergence analysis of the resulting iterative scheme is provided. A numerical experiment is presented to demonstrate the effectiveness of the proposed methods."}
{"id": "2601.08029", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08029", "abs": "https://arxiv.org/abs/2601.08029", "authors": ["Andrey Kardashin", "Konstantin Antipin"], "title": "On measurement-dependent variance in quantum neural networks", "comment": "20 pages, 9 figures", "summary": "Variational quantum circuits have become a widely used tool for performing quantum machine learning (QML) tasks on labeled quantum states. In some specific tasks or for specific variational ansätze, one may perform measurements on a restricted part of the overall input state. This is the case for, e.g., quantum convolutional neural networks (QCNNs), where after each layer of the circuit a subset of qubits of the processed state is measured or traced out, and at the end of the network one typically measures a local observable. In this work, we demonstrate that measuring observables with restricted support results in larger label prediction variance in regression QML tasks. We show that the reason for this is, essentially, the number of distinct eigenvalues of the observable one measures after the application of a variational circuit."}
{"id": "2601.08759", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.08759", "abs": "https://arxiv.org/abs/2601.08759", "authors": ["Eligio Colmenares", "Ricardo Ruiz-Baier", "Dalidet Sanhueza"], "title": "Convergence analysis and adaptive computation of a Banach-space mixed finite element method for generalized bioconvective flows", "comment": null, "summary": "We develop and analyse an adaptive fully mixed finite element method for stationary generalized bioconvective flows, where the Navier--Stokes equations with concentration-dependent viscosity are coupled with a conservation law for swimming microorganisms. The formulation introduces auxiliary variables including the trace-free velocity gradient, a symmetric pseudo-stress tensor, the concentration gradient, and a semi-advective microorganism flux, which also allows for a consistent treatment of Robin-type boundary condition. The variational problem is posed within a Banach space framework and reformulated as a fixed-point operator. Existence of solutions follows from Schauder's theorem, while uniqueness is obtained under suitable data assumptions. The discrete problem is constructed using Raviart--Thomas finite element spaces together with piecewise polynomial approximations on macroelement-structured meshes, and existence of discrete solutions is established via Brouwer's theorem. An a priori error analysis yields optimal convergence rates. We further derive a residual-based a posteriori error estimator and prove its reliability using global inf-sup conditions, Helmholtz decompositions, and suitable projection operators, while efficiency is ensured through localization techniques and bubble functions. Numerical experiments in two and three dimensions confirm the theoretical results, demonstrate the effectiveness of adaptive refinement for singular solutions and complex geometries with inclusions, and illustrate the robustness of the method for a bioconvective benchmark with plume formation governed by an Einstein--Batchelor-type viscosity law."}
{"id": "2601.08488", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08488", "abs": "https://arxiv.org/abs/2601.08488", "authors": ["Zezhi Tang", "Christopher Passmore", "Andrew I Campbell", "Jonathan Howse", "J Anthony Rossiter", "Stephen Ebbens", "George Panoutsos"], "title": "Disturbance observer-based tracking control for roll-to-roll slot die coating systems under gap and pump rate disturbances", "comment": "11 pages, 13 figures", "summary": "Roll-to-roll slot die coating is a widely used industrial manufacturing technique applied in a diverse range of applications such as the production of lithium-ion batteries, solar cells and optical films. The efficiency of roll-to-roll slot die coating depends on the precise control of various input parameters such as pump rate, substrate velocity and coating gap. However, these inputs are sensitive to disturbances in process conditions, leading to inconsistencies in the various characteristics of the produced film. To address this challenge, a \\gls{DO} is utilized for detecting disturbances, which may occur in the same or different channels as the control signal within the system. A generalized compensator is then implemented to mitigate the impact of these disturbances on the output, thereby enhancing uncertainty suppression. Additionally, integrating the disturbance rejection system with an output tracking controller enables the coating system to maintain the desired thickness under varying input conditions and disturbances. The effectiveness of this approach is then validated using a test rig equipped with a camera system, which facilitates the development of a data-driven model of the dynamic process, represented by state-space equations. The simulation results were demonstrated to showcase the effectiveness of the DOBOTC system, which provides a resilient solution for the output tracking issue in a data-driven model with generalized disturbances."}
{"id": "2601.08488", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08488", "abs": "https://arxiv.org/abs/2601.08488", "authors": ["Zezhi Tang", "Christopher Passmore", "Andrew I Campbell", "Jonathan Howse", "J Anthony Rossiter", "Stephen Ebbens", "George Panoutsos"], "title": "Disturbance observer-based tracking control for roll-to-roll slot die coating systems under gap and pump rate disturbances", "comment": "11 pages, 13 figures", "summary": "Roll-to-roll slot die coating is a widely used industrial manufacturing technique applied in a diverse range of applications such as the production of lithium-ion batteries, solar cells and optical films. The efficiency of roll-to-roll slot die coating depends on the precise control of various input parameters such as pump rate, substrate velocity and coating gap. However, these inputs are sensitive to disturbances in process conditions, leading to inconsistencies in the various characteristics of the produced film. To address this challenge, a \\gls{DO} is utilized for detecting disturbances, which may occur in the same or different channels as the control signal within the system. A generalized compensator is then implemented to mitigate the impact of these disturbances on the output, thereby enhancing uncertainty suppression. Additionally, integrating the disturbance rejection system with an output tracking controller enables the coating system to maintain the desired thickness under varying input conditions and disturbances. The effectiveness of this approach is then validated using a test rig equipped with a camera system, which facilitates the development of a data-driven model of the dynamic process, represented by state-space equations. The simulation results were demonstrated to showcase the effectiveness of the DOBOTC system, which provides a resilient solution for the output tracking issue in a data-driven model with generalized disturbances."}
{"id": "2601.08717", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.08717", "abs": "https://arxiv.org/abs/2601.08717", "authors": ["Isabel Barros Garcia", "Jérémie Messud"], "title": "Portfolio Optimization with 'Physical' Decision Variables and Non-Linear Performance Metrics: Diversification Challenge and Proposals", "comment": null, "summary": "Portfolio optimization (PO) is a core tool in financial and operational decision-making, typically balancing expected profit and risk. In real-world applications, particularly in the energy sector, decision variables can be expressed as physical quantities (e.g., production volumes), and nonlinear performance metrics such as Return on Investment (ROI) may be requested. These modeling choices introduce challenges, including the non-additivity of the objective function. This often results in highly concentrated optimized portfolios and thus limited diversification, which can be problematic for decision-makers seeking balanced investment strategies. This paper proposes two strategies to enhance diversification in ROI-based PO models, both based on the Herfindahl-Hirschman Index (HHI). The first incorporates an HHI term directly into the objective function, with its corresponding weight allowing control over diversification. The second directly maximizes diversification while controlling expected profit and risk degradation around the optimum portfolio (obtained through conventional PO). Both strategies are evaluated using synthetic data (energy assets) to illustrate their behavior and practical trade-offs. The results highlight how each method can support different decision-making needs and enhance portfolio robustness."}
{"id": "2601.08068", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08068", "abs": "https://arxiv.org/abs/2601.08068", "authors": ["Ariane Soret", "Nessim Dridi", "Stephen C. Wein", "Valérian Giesz", "Shane Mansfield", "Pierre-Emmanuel emeriau"], "title": "Quantum Energetic Advantage before Computational Advantage in Boson Sampling", "comment": null, "summary": "Understanding the energetic efficiency of quantum computers is essential for assessing their scalability and for determining whether quantum technologies can outperform classical computation beyond runtime alone. In this work, we analyze the energy required to solve the Boson Sampling problem, a paradigmatic task for quantum advantage, using a realistic photonic quantum computing architecture. Using the Metric-Noise-Resource methodology, we establish a quantitative connection between experimental control parameters, dominant noise processes, and energetic resources through a performance metric tailored to Boson Sampling. We estimate the energy cost per sample and identify operating regimes that optimize energetic efficiency. By comparing the energy consumption of quantum and state-of-the-art classical implementations, we demonstrate the existence of a quantum energetic advantage -- defined as a lower energy cost per sample compared to the best-known classical implementation -- that emerges before the onset of computational advantage, even in regimes where classical algorithms remain faster. Finally, we propose an experimentally feasible Boson Sampling architecture, including a complete noise and loss budget, that enables a near-term observation of quantum energetic advantage."}
{"id": "2601.08787", "categories": ["math.NA", "math.CA", "math.FA"], "pdf": "https://arxiv.org/pdf/2601.08787", "abs": "https://arxiv.org/abs/2601.08787", "authors": ["F. Dai", "V. Temlyakov"], "title": "A survey on sampling recovery", "comment": "68 pages", "summary": "The reconstruction of unknown functions from a finite number of samples is a fundamental challenge in pure and applied mathematics. This survey provides a comprehensive overview of recent developments in sampling recovery, focusing on the accuracy of various algorithms and the relationship between optimal recovery errors, nonlinear approximation, and the Kolmogorov widths of function classes. A central theme is the synergy between the theory of universal sampling discretization and Lebesgue-type inequalities for greedy algorithms. We discuss three primary algorithmic frameworks: weighted least squares and $\\ell_p$ minimization, sparse approximation methods, and greedy algorithms such as the Weak Orthogonal Matching Pursuit (WOMP) in Hilbert spaces and the Weak Tchebychev Greedy Algorithm (WCGA) in Banach spaces. These methods are applied to function classes defined by structural conditions, like the $A_β^r$ and Wiener-type classes, as well as classical Sobolev-type classes with dominated mixed derivatives. Notably, we highlight recent findings showing that nonlinear sampling recovery can provide superior error guarantees compared to linear methods for certain multivariate function classes."}
{"id": "2601.08518", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08518", "abs": "https://arxiv.org/abs/2601.08518", "authors": ["Alexandre Sanfelici Bazanella", "Mateus Gaspary de Freitas"], "title": "Improving the GMAW process through current control", "comment": null, "summary": "A control strategy for the electrical current in GMAW processes is proposed. The control is in closed-loop, designed by formal methods, based on a mathematical model of the electrical behavior of the GMAW process, and implemented in C+ language in a microcontroller. The model consists of a switched equivalent electrical circuit whose parameters are obtained in a data-driven manner. The strategy is tested in numerous experiments with both manual and robot welding, showing improvements in the overall welding process."}
{"id": "2601.08518", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08518", "abs": "https://arxiv.org/abs/2601.08518", "authors": ["Alexandre Sanfelici Bazanella", "Mateus Gaspary de Freitas"], "title": "Improving the GMAW process through current control", "comment": null, "summary": "A control strategy for the electrical current in GMAW processes is proposed. The control is in closed-loop, designed by formal methods, based on a mathematical model of the electrical behavior of the GMAW process, and implemented in C+ language in a microcontroller. The model consists of a switched equivalent electrical circuit whose parameters are obtained in a data-driven manner. The strategy is tested in numerous experiments with both manual and robot welding, showing improvements in the overall welding process."}
{"id": "2601.08751", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.08751", "abs": "https://arxiv.org/abs/2601.08751", "authors": ["Timothé Taminiau", "Estelle Massart", "Geovani Nunes Grapiglia"], "title": "Riemannian optimization with finite-difference gradient approximations", "comment": null, "summary": "Derivative-free Riemannian optimization (DFRO) aims to minimize an objective function using only function evaluations, under the constraint that the decision variables lie on a Riemannian manifold. The rapid increase in problem dimensions over the years calls for computationally cheap DFRO algorithms, that is, algorithms requiring as few function evaluations and retractions as possible. We propose a novel DFRO method based on finite-difference gradient approximations that relies on an adaptive selection of the finite-difference accuracy and stepsize that is novel even in the Euclidean setting. When endowed with an intrinsic finite-difference scheme, that measures variations of the objective in tangent directions using retractions, our proposed method requires $O(dε^{-2})$ function evaluations and retractions to find an $ε$-critical point, where $d$ is the manifold dimension. We then propose a variant of our method when the search space is a Riemannian submanifold of an $n$-dimensional Euclidean space. This variant relies on an extrinsic finite-difference scheme, approximating the Riemannian gradient directly in the embedding space, assuming that the objective function can be evaluated outside of the manifold. This approach leads to worst-case complexity bounds of $O(dε^{-2})$ function evaluations and $O(ε^{-2})$ retractions. We also present numerical results showing that the proposed methods achieve superior performance over existing derivative-free methods on various problems in both Euclidean and Riemannian settings."}
{"id": "2601.08085", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08085", "abs": "https://arxiv.org/abs/2601.08085", "authors": ["Vicente Peña Pérez", "Matthew D. Grace", "Christian Arenz", "Alicia B. Magann"], "title": "Learning parameter curves in feedback-based quantum optimization algorithms", "comment": "13 pages, 6 figures. To be submitted to Physical Review Research Journal", "summary": "Feedback-based quantum algorithms (FQAs) operate by iteratively growing a quantum circuit to optimize a given task. At each step, feedback from qubit measurements is used to inform the next quantum circuit update. In practice, the sampling cost associated with these measurements can be significant. Here, we ask whether FQA parameter sequences can be predicted using classical machine learning, obviating the need for qubit measurements altogether. To this end, we train a teacher-student model to map a MaxCut problem instance to an associated FQA parameter curve in a single classical inference step. Numerical experiments show that this model can accurately predict FQA parameter curves across a range of problem sizes, including problem sizes not seen during model training. To evaluate performance, we compare the predicted parameter curves in simulation against FQA reference curves and linear quantum annealing schedules. We observe similar results to the former and performance improvements over the latter. These results suggest that machine learning can offer a heuristic, practical path to reducing sampling costs and resource overheads in quantum algorithms."}
{"id": "2601.08753", "categories": ["math.OC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08753", "abs": "https://arxiv.org/abs/2601.08753", "authors": ["Rishav Sen", "Amutheezan Sivagnanam", "Aron Laszka", "Ayan Mukhopadhyay", "Abhishek Dubey"], "title": "Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit", "comment": "7 pages, 7 figures, 4 algorithms. Published in the Proceedings of the 2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)", "summary": "The rapid growth of urban populations and the increasing need for sustainable transportation solutions have prompted a shift towards electric buses in public transit systems. However, the effective management of mixed fleets consisting of both electric and diesel buses poses significant operational challenges. One major challenge is coping with dynamic electricity pricing, where charging costs vary throughout the day. Transit agencies must optimize charging assignments in response to such dynamism while accounting for secondary considerations such as seating constraints. This paper presents a comprehensive mixed-integer linear programming (MILP) model to address these challenges by jointly optimizing charging schedules and trip assignments for mixed (electric and diesel bus) fleets while considering factors such as dynamic electricity pricing, vehicle capacity, and route constraints. We address the potential computational intractability of the MILP formulation, which can arise even with relatively small fleets, by employing a hierarchical approach tailored to the fleet composition. By using real-world data from the city of Chattanooga, Tennessee, USA, we show that our approach can result in significant savings in the operating costs of the mixed transit fleets."}
{"id": "2601.08753", "categories": ["math.OC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08753", "abs": "https://arxiv.org/abs/2601.08753", "authors": ["Rishav Sen", "Amutheezan Sivagnanam", "Aron Laszka", "Ayan Mukhopadhyay", "Abhishek Dubey"], "title": "Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit", "comment": "7 pages, 7 figures, 4 algorithms. Published in the Proceedings of the 2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)", "summary": "The rapid growth of urban populations and the increasing need for sustainable transportation solutions have prompted a shift towards electric buses in public transit systems. However, the effective management of mixed fleets consisting of both electric and diesel buses poses significant operational challenges. One major challenge is coping with dynamic electricity pricing, where charging costs vary throughout the day. Transit agencies must optimize charging assignments in response to such dynamism while accounting for secondary considerations such as seating constraints. This paper presents a comprehensive mixed-integer linear programming (MILP) model to address these challenges by jointly optimizing charging schedules and trip assignments for mixed (electric and diesel bus) fleets while considering factors such as dynamic electricity pricing, vehicle capacity, and route constraints. We address the potential computational intractability of the MILP formulation, which can arise even with relatively small fleets, by employing a hierarchical approach tailored to the fleet composition. By using real-world data from the city of Chattanooga, Tennessee, USA, we show that our approach can result in significant savings in the operating costs of the mixed transit fleets."}
{"id": "2601.08753", "categories": ["math.OC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.08753", "abs": "https://arxiv.org/abs/2601.08753", "authors": ["Rishav Sen", "Amutheezan Sivagnanam", "Aron Laszka", "Ayan Mukhopadhyay", "Abhishek Dubey"], "title": "Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit", "comment": "7 pages, 7 figures, 4 algorithms. Published in the Proceedings of the 2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC)", "summary": "The rapid growth of urban populations and the increasing need for sustainable transportation solutions have prompted a shift towards electric buses in public transit systems. However, the effective management of mixed fleets consisting of both electric and diesel buses poses significant operational challenges. One major challenge is coping with dynamic electricity pricing, where charging costs vary throughout the day. Transit agencies must optimize charging assignments in response to such dynamism while accounting for secondary considerations such as seating constraints. This paper presents a comprehensive mixed-integer linear programming (MILP) model to address these challenges by jointly optimizing charging schedules and trip assignments for mixed (electric and diesel bus) fleets while considering factors such as dynamic electricity pricing, vehicle capacity, and route constraints. We address the potential computational intractability of the MILP formulation, which can arise even with relatively small fleets, by employing a hierarchical approach tailored to the fleet composition. By using real-world data from the city of Chattanooga, Tennessee, USA, we show that our approach can result in significant savings in the operating costs of the mixed transit fleets."}
{"id": "2601.08102", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08102", "abs": "https://arxiv.org/abs/2601.08102", "authors": ["Maria Violaris"], "title": "Quantum observers can communicate across multiverse branches", "comment": null, "summary": "It is commonly thought that observers in distinct branches of an Everettian multiverse cannot communicate without violating the linearity of quantum theory. Here we show a counterexample, demonstrating that inter-branch communication is in fact possible, entirely within standard quantum theory. We do this by considering a Wigner's-friend scenario, where an observer (Wigner) can have quantum control over another observer (the friend). We present a thought experiment where the friend in superposition can receive a message written by a distinct copy of themselves in the multiverse, with the aid of Wigner. To maintain the unitarity of quantum theory, the observers must have no memory of the message that they sent. Our thought experiment challenges conventional wisdom regarding the ultimate limits of what is possible in an Everettian multiverse. It has a surprising potential application which involves using knowledge-creation paradoxes for testing Everettian quantum theory against single-world theories."}
{"id": "2601.07956", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.07956", "abs": "https://arxiv.org/abs/2601.07956", "authors": ["Harrison M. Bonner", "Matthew R. Kirchner"], "title": "Human as an Actuator Dynamic Model Identification", "comment": "To appear in the 2026 IEEE Aerospace Conference", "summary": "This paper presents a method for estimating parameters that form a general model for human pilot response for specific tasks. The human model is essential for the dynamic analysis of piloted vehicles. Data are generated on a simulator with multiple trials being incorporated to find the single model that best describes the data. The model is found entirely in the time domain by constructing a constrained optimization problem. This optimization problem implicitly represents the state of the underlying system, making it robust to natural variation in human responses. It is demonstrated by estimating the human response model for a position control task with a quadcopter drone."}
{"id": "2601.08132", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08132", "abs": "https://arxiv.org/abs/2601.08132", "authors": ["Thomas Barthel"], "title": "Cost scaling of MPS and TTNS simulations for 2D and 3D systems with area-law entanglement", "comment": "8.5 pages, 5 figures, 3 tables", "summary": "Tensor network states are an indispensable tool for the simulation of strongly correlated quantum many-body systems. In recent years, tree tensor network states (TTNS) have been successfully used for two-dimensional systems and to benchmark quantum simulation approaches for condensed matter, nuclear, and particle physics. In comparison to the more traditional approach based on matrix product states (MPS), the graph distance of physical degrees of freedom can be drastically reduced in TTNS. Surprisingly, it turns out that, for large systems in $D>1$ spatial dimensions, MPS simulations of low-energy states are nevertheless more efficient than TTNS simulations. With a focus on $D=2$ and 3, the scaling of computational costs for different boundary conditions is determined under the assumption that the system obeys an entanglement (log-)area law, implying that bond dimensions scale exponentially in the surface area of the associated subsystems."}
{"id": "2601.08338", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.08338", "abs": "https://arxiv.org/abs/2601.08338", "authors": ["Luca Ballotta", "Geethu Joseph"], "title": "Minimal Actuator Selection", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Selecting a few available actuators to ensure the controllability of a linear system is a fundamental problem in control theory. Previous works either focus on optimal performance, simplifying the controllability issue, or make the system controllable under structural assumptions, such as in graphs or when the input matrix is a design parameter. We generalize these approaches to offer a precise characterization of the general minimal actuator selection problem where a set of actuators is given, described by a fixed input matrix, and goal is to choose the fewest actuators that make the system controllable. We show that this problem can be equivalently cast as an integer linear program and, if actuation channels are sufficiently independent, as a set multicover problem under multiplicity constraints. The latter equivalence is always true if the state matrix has all distinct eigenvalues, in which case it simplifies to the set cover problem. Such characterizations hold even when a robust selection that tolerates a given number of faulty actuators is desired. Our established connection legitimates a designer to use algorithms from the rich literature on the set multicover problem to select the smallest subset of actuators, including exact solutions that do not require brute-force search."}
{"id": "2601.08137", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.08137", "abs": "https://arxiv.org/abs/2601.08137", "authors": ["Kazuhiro Seki", "Yuta Kikuchi", "Tomoya Hayata", "Seiji Yunoki"], "title": "Dissipative ground-state preparation of a quantum spin chain on a trapped-ion quantum computer", "comment": "15 pages, 9 figures", "summary": "We demonstrate a dissipative protocol for ground-state preparation of a quantum spin chain on a trapped-ion quantum computer. As a first step, we derive a Kraus representation of a dissipation channel for the protocol recently proposed by Ding et al. [Phys. Rev. Res. 6, 033147 (2024)] that still holds for arbitrary temporal discretization steps, extending the analysis beyond the Lindblad dynamics regime. The protocol guarantees that the fidelity with the ground state monotonically increases (or remains unchanged) under repeated applications of the channel to an arbitrary initial state, provided that the ground state is the unique steady state of the dissipation channel. Using this framework, we implement dissipative ground-state preparation of a transverse-field Ising chain for up to 19 spins on the trapped-ion quantum computer Reimei provided by Quantinuum. Despite the presence of hardware noise, the dynamics consistently converges to a low-energy state far away from the maximally mixed state even when the corresponding quantum circuits contain as many as 4110 entangling gates, demonstrating the intrinsic robustness of the protocol. By applying zero-noise extrapolation, the resulting energy expectation values are systematically improved to agree with noiseless simulations within statistical uncertainties."}
{"id": "2601.08372", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.08372", "abs": "https://arxiv.org/abs/2601.08372", "authors": ["Hiroki Sakamoto", "Kazuhiro Sato"], "title": "Data-Driven Time-Limited h2 Optimal Model Reduction for Linear Discrete-Time Systems", "comment": null, "summary": "This paper develops a data-driven h2 model reduction method for discrete-time linear time-invariant systems. Specifically, we solve the h2 model reduction problem defined over a finite horizon using only impulse response data. Furthermore, we show that the proposed data-driven algorithm converges to a stationary point under certain assumptions. Numerical experiments demonstrate that the proposed method constructs a good reduced-order model in terms of the h2 norm defined over the finite horizon using a SLICOT benchmark (the CD player model)."}
{"id": "2601.08213", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.08213", "abs": "https://arxiv.org/abs/2601.08213", "authors": ["Anastasiia Butko", "Artem Marisov", "David I. Santiago", "Irfan Siddiqi"], "title": "Quantum State Discrimination Enhanced by FPGA-Based AI Engine Technology", "comment": null, "summary": "Identifying the state of a quantum bit (qubit), known as quantum state discrimination, is a crucial operation in quantum computing. However, it has been the most error-prone and time-consuming operation on superconducting quantum processors. Due to stringent timing constraints and algorithmic complexity, most qubit state discrimination methods are executed offline. In this work, we present an enhanced real-time quantum state discrimination system leveraging FPGA-based AI Engine technology. A multi-layer neural network has been developed and implemented on the AMD Xilinx VCK190 FPGA platform, enabling accurate in-situ state discrimination and supporting mid-circuit measurement experiments for multiple qubits. Our approach leverages recent advancements in architecture research and design, utilizing specialized AI/ML accelerators to optimize quantum experiments and reduce the use of FPGA resources."}
{"id": "2601.08594", "categories": ["math.NA", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.08594", "abs": "https://arxiv.org/abs/2601.08594", "authors": ["Rishi Leburu", "Levon Nurbekyan", "Lars Ruthotto"], "title": "Differentiating through Stochastic Differential Equations: A Primer", "comment": "20 pages, 3 figures", "summary": "Dynamical systems are essential to model various phenomena in physics, finance, economics, and are also of current interest in machine learning. A central modeling task is investigating parameter sensitivity, whether tuning atmospheric coefficients, computing financial Greeks, or optimizing neural networks. These sensitivities are mathematically expressed as derivatives of an objective function with respect to parameters of interest and are rarely available analytically, necessitating numerical methods for approximating them. While the literature for differentiation of deterministic systems is well-covered, the treatment of stochastic systems, such as stochastic differential equations (SDEs), in most curricula is less comprehensive than the subtleties arising from the interplay of noise and discretization require.\n  This paper provides a primer on numerical differentiation of SDEs organized as a two-tale narrative. Tale 1 demonstrates differentiating through discretized SDEs, known the discretize-optimize approach, is reliable for both Itô and Stratonovich calculus. Tale 2 examines the optimize-discretize approach, investigating the continuous limit of backward equations from Tale 1 corresponding to the desired gradients. Our aim is to equip readers with a clear guide on the numerical differentiation of SDEs: computing gradients correctly in both Itô and Stratonovich settings, understanding when discretize-optimize and optimize-discretize agree or diverge, and developing intuition for reasoning about stochastic differentiation beyond the cases explicitly covered."}
{"id": "2601.08238", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08238", "abs": "https://arxiv.org/abs/2601.08238", "authors": ["Jia-Wei Ying", "Shi-Pu Gu", "Xing-Fu Wang", "Wei Zhong", "Ming-Ming Du", "Xi-Yun Li", "Shu-Ting Shen", "An-Lei Zhang", "Lan Zhou", "Yu-Bo Sheng"], "title": "Reference-frame-independent Quantum secure direct communication", "comment": null, "summary": "Current quantum secure direct communication (QSDC) protocols guarantee communication security by estimating the error rates of photons in the X and Z bases. This take the reference frame calibration between communicating parties as a necessary prerequisite. However, in mobile communications scenarios, achieving continuous and accurate reference frame calibration poses significant challenges. To address this issue, this paper proposes a reference-frame-independent (RFI) QSDC protocol. This protocol only requires ensuring the calibration accuracy of one direction of the reference frame, while allowing a misalignment angle $β$ in the other two directions. To improve the protocol's robustness against reference frame fluctuations, we introduce a $β$-independent parameter C into the security analysis framework and rederive the protocol's security bounds. Additionally, we construct a system model and optimize the pulse intensity of the signal states, enabling the protocol to achieve optimal performance under each level of channel attenuation. At an attenuation of 10 dB (corresponding to a communication distance of 25 km), the secrecy message capacities for $β= 0^{ \\circ} $ and $45^{ \\circ} $ are $8.765 \\times10^{-6}$ bit/pulse and $4.150 \\times10^{-6}$ bit/pulse, respectively. Compared with the single-photon-based QSDC, the communication distance of the protocol proposed in this paper is significantly extended. When $β= 0^{ \\circ} $ and $45^{ \\circ} $, the maximum transmission distances of the RFI QSDC protocol are 27.875 km and 26.750 km, which is about 155.9 % and 149.7 % of that of the single-photon-based QSDC protocol."}
{"id": "2601.08289", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08289", "abs": "https://arxiv.org/abs/2601.08289", "authors": ["Xiaodong Zheng", "Xu Jing", "Chenbo Liu", "Yufu Li", "Runqiu He", "Lina Xia", "Fei Wang", "Yuechan Kong", "Tangsheng Chen", "Liangliang Lu", "Jiayun Dai", "Bin Niu"], "title": "Efficient and broadband quantum frequency comb generation in a monolithic AlGaAs-on-insulator microresonator", "comment": "23 pages, 12 figures", "summary": "The exploration of photonic systems for quantum information processing has generated widespread interest in multiple cutting-edge research fields. Photonic frequency encoding stands out as an especially viable approach, given its natural alignment with established optical communication technologies, including fiber networks and wavelength-division multiplexing systems. Substantial reductions in hardware resources and improvements in quantum performance can be expected by utilizing multiple frequency modes. The integration of nonlinear photonics with microresonators provides a compelling way for generating frequency-correlated photon pairs across discrete spectral modes. Here, by leveraging the high material nonlinearity and low nonlinear loss, we demonstrate an efficient chip-scale multi-wavelength quantum light source based on AlGaAs-on-insulator, featuring a free spectral range of approximately 200 GHz at telecom wavelengths. The optimized submicron waveguide geometry provides both high effective nonlinearity (~550 m$^{-1}$W$^{-1}$) and broad generation bandwidth, producing eleven distinct wavelength pairs across a 35.2 nm bandwidth with an average spectral brightness of 2.64 GHz mW$^{-2}$nm$^{-1}$. The generation of energy-time entanglement for each pair of frequency modes is verified through Franson interferometry, yielding an average net visibility of 93.1%. With its exceptional optical gain and lasing capabilities, the AlGaAs-on-insulator platform developed here shows outstanding potential for realizing fully integrated, ready-to-deploy quantum photonic systems on chip."}
{"id": "2601.08290", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2601.08290", "abs": "https://arxiv.org/abs/2601.08290", "authors": ["Prosanta Pal", "Shubhanshu Karoliya", "Gargee Sharma", "Ramakrishna Podila"], "title": "A Preparation Nonstationarity Loophole in Superconducting-Qubit Bell Tests", "comment": "10+pages, 4 figures", "summary": "Bell or Clauser-Horne-Shimony-Holt (CHSH) tests on superconducting quantum processors are commonly interpreted under the assumption that repeated circuit executions sample a single, stationary preparation ensemble. Here we show that this assumption can be violated on contemporary hardware, with direct implications for the interpretation of observed Bell violations. We introduce an ensemble-divergence framework in which slow temporal drift of the preparation process induces context-dependent effective ensembles, even when measurement independence and locality are preserved. This leads to a relaxed Bell bound $|S| \\le 2 + 6δ_{\\mathrm{ens}}$, where $δ_{\\mathrm{ens}}$ quantifies preparation nonstationarity. Because $δ_{\\mathrm{ens}}$ is not directly observable, we develop an operational witness $δ_{\\mathrm{op}}$ based on bin-resolved outcome statistics for fixed measurement channels. Using Pauli-axis measurements on IBM superconducting processors, we observe statistically significant operational drift that persists after full two-qubit readout mitigation, ruling out measurement artifacts. In contrast, drift extracted from CHSH-optimal measurements is eliminated by mitigation, demonstrating that such settings are unsuitable for diagnosing preparation nonstationarity. We further show that the observed Bell violations imply only modest ensemble divergences, comparable in scale to those required in Hall-type measurement-dependence models, but arising here solely from preparation drift combined with experimental scheduling. Our results identify a preparation-dependent loophole relevant to Bell tests on noisy intermediate-scale quantum devices and highlight the necessity of drift-aware protocols for reliable quantum certification."}
{"id": "2601.08315", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08315", "abs": "https://arxiv.org/abs/2601.08315", "authors": ["Qi Yao", "Jun Zhang", "Wenxian Zhang", "Chaohong Lee"], "title": "Extending Qubit Coherence Time via Hybrid Dynamical Decoupling", "comment": "10 pages, 5 Figures, Welcome to comment", "summary": "Dynamical decoupling (DD) and bath engineering are two parallel techniques employed to mitigate qubit decoherence resulting from their unavoidable coupling to the environment. Here, we present a hybrid DD approach that integrates pulsed DD with bath spin polarization to enhance qubit coherence within the central spin model. This model, which can be realized using GaAs semiconductor quantum dots or analogous quantum simulators, demonstrates a significant extension of the central spin's coherence time by approximately 2 to 3 orders of magnitude that compared with the free-induced decay time, where the dominant contribution from DD and a moderate improvement from spin-bath polarization. This study, which integrates uniaxial dynamical decoupling and auxiliary bath-spin engineering, paves the way for prolonging coherence times in various practical quantum systems, including GaAs/AlGaAs, silicon and Si/SiGe. And this advancement holds substantial promise for applications in quantum information processing."}
{"id": "2601.08349", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08349", "abs": "https://arxiv.org/abs/2601.08349", "authors": ["Benoît Boulanger", "Gaspar Mougin-Trichon", "Véronique Boutou"], "title": "Quantum fluctuations of vacuum versus photon-pairs concerning Spontaneous-Parametric Down-Conversion and Four-Wave-Mixing", "comment": "13 pages, 4 figures", "summary": "The limit between the two regimes of spontaneous-parametric down-conversion (SPDC) or four-wave-mixing (FWM) regarding the pump intensity has been theoretically investigated using a semi-classical model and analytical calculations. A unitless quantity has been defined, corresponding to the photon-pairs flux per frequency unit: it has been found equal to 0.369 at this limit. The ratio between the magnitudes of the electric fields of the generated photons and of vacuum has been also calculated, equal to 1.718, and the pump intensity has been plotted as a function of the interaction length for different values of the second-order electric susceptibility in the case of SPDC and of the third-order electric susceptibility for FWM. These quantitative results confirm that below the limit, the nonlinear process can be truly considered as spontaneous, i.e. mainly seeded by the quantum fluctuations of vacuum, while the generated photons mainly govern the pump photon splitting above the limit, which corresponds more to an optical parametric amplification / difference frequency generation regime. Knowing quantitatively the limit between the two regimes thanks to the present calculations will be a useful guide for further quantum calculations and measurements from either side of the limit in order to catch the full quantum picture of SPDC and FWM from low to high pump intensities."}
{"id": "2601.08364", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.08364", "abs": "https://arxiv.org/abs/2601.08364", "authors": ["Sanjukta Kundu", "Balakrishnan Viswanathan", "Pawel Szczypkowski", "Gabriela Barreto Lemos", "Mayukh Lahiri", "Radek Lapkiewicz"], "title": "Verification of continuous variable entanglement with undetected photons", "comment": "12 pages, 4 figures", "summary": "We verify transverse spatial entanglement of photon-pairs generated in spontaneous parametric down conversion using a nonlinear interferometric technique without relying on any coincidence detection. We experimentally demonstrate the violation of the Einstein-Podolsky-Rosen criterion and of the Mancini-Giovannetti-Vitali-Tombesi criterion using single photon interference of one of the photons of the pairs. We also provide a comprehensive theoretical analysis. The experimental results that we have obtained show good agreement with the theoretical values. Our method performs well under experimental losses and can be applied to highly non-degenerate sources, where there are no suitable detectors for one of the photons in the quantum state and our method could also be extended to the discrete degrees of freedom to certify high-dimensional (OAM) entanglement."}
{"id": "2601.08367", "categories": ["quant-ph", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.08367", "abs": "https://arxiv.org/abs/2601.08367", "authors": ["Yuechen Li", "Minqi Shao", "Jianjun Zhao", "Qichen Wang"], "title": "A Methodological Analysis of Empirical Studies in Quantum Software Testing", "comment": "57 pages, 18 figures, Contains dataset and code", "summary": "In quantum software engineering (QSE), quantum software testing (QST) has attracted increasing attention as quantum software systems grow in scale and complexity. Since QST evaluates quantum programs through execution under designed test inputs, empirical studies are widely used to assess the effectiveness of testing approaches. However, the design and reporting of empirical studies in QST remain highly diverse, and a shared methodological understanding has yet to emerge, making it difficult to interpret results and compare findings across studies. This paper presents a methodological analysis of empirical studies in QST through a systematic examination of 59 primary studies identified from a literature pool of size 384. We organize our analysis around ten research questions that cover key methodological dimensions of QST empirical studies, including objects under test, baseline comparison, testing setup, experimental configuration, and tool and artifact support. Through cross-study analysis along these dimensions, we characterize current empirical practices in QST, identify recurring limitations and inconsistencies, and highlight open methodological challenges. Based on our findings, we derive insights and recommendations to inform the design, execution, and reporting of future empirical studies in QST."}
{"id": "2601.08389", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08389", "abs": "https://arxiv.org/abs/2601.08389", "authors": ["Giovanni de Felice", "Boldizsár Poór", "Cole Comfort", "Lia Yeh", "Mateusz Kupper", "William Cashman", "Bob Coecke"], "title": "A dataflow programming framework for linear optical distributed quantum computing", "comment": null, "summary": "Photonic systems offer a promising platform for interconnecting quantum processors and enabling scalable, networked architectures. Designing and verifying such architectures requires a unified formalism that integrates linear algebraic reasoning with probabilistic and control-flow structures. In this work, we introduce a graphical framework for distributed quantum computing that brings together linear optics, the ZX-calculus, and dataflow programming. Our language supports the formal analysis and optimization of distributed protocols involving both qubits and photonic modes, with explicit interfaces for classical control and feedforward, all expressed within a synchronous dataflow model with discrete-time dynamics. Within this setting, we classify entangling photonic fusion measurements, show how their induced Pauli errors can be corrected via a novel flow structure for fusion networks, and establish correctness proofs for new repeat-until-success protocols enabling arbitrary fusions. Layer by layer, we construct qubit architectures incorporating practical optical components such as beam splitters, switches, and photon sources, with graphical proofs that they are deterministic and support universal quantum computation. Together, these results establish a foundation for verifiable compilation and automated optimization in networked quantum computing."}
{"id": "2601.08392", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08392", "abs": "https://arxiv.org/abs/2601.08392", "authors": ["Maddalena Genzini", "Caterina Vigliar", "Mujtaba Zahidy", "Hamid Tebyanian", "Andrzej Gajda", "Klaus Petermann", "Lars Zimmermann", "Davide Bacco", "Francesco Da Ros"], "title": "On-chip semi-device-independent quantum random number generator exploiting contextuality", "comment": null, "summary": "We present a semi-device-independent quantum random number generator (QRNG) based on the violation of a contextuality inequality, implemented by the integration of two silicon photonic chips. Our system combines a heralded single-photon source with a reconfigurable interferometric mesh to implement qutrit state preparation, transformations, and measurements suitable for testing a KCBS contextuality inequality. This architecture enables the generation of random numbers from the intrinsic randomness of single-photon interference in a complex optical network, while simultaneously allowing a quantitative certification of their security without requiring entanglement. We observe a contextuality violation exceeding the classical bound by more than 10σ, unambiguously confirming non-classical behavior. From this violation, we certify a conditional min-entropy per experimental round of Hmin = 0.077 +- 0.002, derived via a tailored semidefinite-programming-based security analysis. Each measurement outcome therefore contains at least 0.077 +- 0.002 bits of extractable genuine randomness, corresponding to an asymptotic generation rate of 21.7 +- 0.5 bits/s. These results establish a viable route towards general-purpose, untrusted quantum random number generators compatible with practical integrated photonic quantum networks."}
{"id": "2601.08417", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08417", "abs": "https://arxiv.org/abs/2601.08417", "authors": ["Guillermo Currás-Lorenzo", "Margarida Pereira", "Kiyoshi Tamaki", "Marcos Curty"], "title": "Rigorous phase-error-estimation security framework for QKD with correlated sources", "comment": "19 pages, 1 figure", "summary": "Practical QKD modulators introduce correlations between consecutively emitted pulses due to bandwidth limitations, violating key assumptions underlying many security proof techniques. Here, we address this problem by introducing a simple yet powerful mathematical framework to directly extend phase-error-estimation-based security proofs for imperfect but uncorrelated sources to also incorporate encoding correlations. Our framework overcomes important limitations of previous approaches in terms of generality and rigor, significantly narrowing the gap between theoretical security guarantees and real-world QKD implementations."}
{"id": "2601.08495", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08495", "abs": "https://arxiv.org/abs/2601.08495", "authors": ["Andreas Conta", "Santiago Bogino", "Frodo Köhncke", "Ferdinand Schmidt-Kaler", "Ulrich Poschinger"], "title": "Toolchain for shuttling trapped-ion qubits in segmented traps", "comment": null, "summary": "Scalable trapped-ion quantum computing requires fast and reliable transport of ions through complex, segmented radiofrequency trap architectures without inducing excessive motional excitation. We present a numerical toolchain for the systematic generation of time-dependent electrode voltages enabling fast, low-excitation ion shuttling in segmented radiofrequency traps. Based on a model of the trap electrode geometry, the framework combines an electrostatic field solver, efficient unconstrained optimization, waveform postprocessing, and dynamical simulations of ion motion to compute voltage waveforms that realize prescribed transport trajectories while respecting experimental constraints such as voltage limits and bandwidth. The toolchain supports arbitrary trap geometries, including junctions and multi-zone layouts, and allows for the flexible incorporation of optimization objectives. We provide a detailed assessment of the accuracy of the framework by investigating its numerical stability and by comparing measured and predicted secular frequencies. The framework is optimized for numerical performance, enabling rapid numerical prototyping of trap architectures of increasing complexity. As application examples, we apply the framework to the transport of a potential well along a linear, uniformly segmented trap, and we compute a solution for shuttling a potential well around the corner of an X-type trap junction. The presented approach provides an extensible and highly efficient numerical foundation for designing and validating transport protocols in current and next-generation trapped-ion processors."}
{"id": "2601.08504", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08504", "abs": "https://arxiv.org/abs/2601.08504", "authors": ["Francisco Romão", "Daniel Vonk", "Emmanuil Giortamis", "Pramod Bhatotia"], "title": "MultiQ: Multi-Programming Neutral Atom Quantum Architectures", "comment": null, "summary": "Neutral atom Quantum Processing Units (QPUs) are emerging as a popular quantum computing technology due to their large qubit counts and flexible connectivity. However, performance challenges arise as large circuits experience significant fidelity drops, while small circuits underutilize hardware and face initialization latency issues. To tackle these problems, we propose $\\textit{multi-programming on neutral atom QPUs}$, allowing the co-execution of multiple circuits by logically partitioning the qubit array. This approach increases resource utilization and mitigates initialization latency while maintaining result fidelity. Currently, state-of-the-art compilers for neutral atom architectures do not support multi-programming.\n  To fill this gap, we introduce MultiQ, the first system designed for this purpose. MultiQ addresses three main challenges: (i) it compiles circuits into a $\\textit{virtual zone layout}$ to optimize spatio-temporal hardware utilization; (ii) it parallelizes the execution of co-located circuits, allowing single hardware instructions to operate on different circuits; and (iii) it includes an algorithm to verify the functional independence of the bundled circuits. MultiQ functions as a cross-layer system comprising a compiler, controller, and checker. Our compiler generates \\emph{virtual zone layouts} to enhance performance, while the controller efficiently maps these layouts onto the hardware and resolves any conflicts. The checker ensures the correct bundling of circuits.\n  Experimental results show a throughput increase from 3.8$\\times$ to 12.3$\\times$ when multi-programming 4 to 14 circuits, with fidelity largely maintained, ranging from a 1.3% improvement for four circuits to only a 3.5% loss for fourteen circuits. Overall, MultiQ facilitates concurrent execution of multiple quantum circuits, boosting throughput and hardware utilization."}
{"id": "2601.08533", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08533", "abs": "https://arxiv.org/abs/2601.08533", "authors": ["Viktor Khinevich", "Wataru Mizukami"], "title": "Symmetry-Adapted State Preparation for Quantum Chemistry on Fault-Tolerant Quantum Computers", "comment": null, "summary": "We present systematic and resource-efficient constructions of continuous symmetry projectors, particularly $U(1)$ particle number and $SU(2)$ total spin, tailored for fault-tolerant quantum computations. Our approach employs a linear combination of unitaries (LCU) as well as generalized quantum signal processing (GQSP and GQSVT) to implement projectors. These projectors can then be coherently applied as state filters prior to quantum phase estimation (QPE). We analyze their asymptotic gate complexities for explicit circuit realizations. For the particle number and $S_z$ symmetries, GQSP offers favorable resource usage features owing to its low ancilla qubit requirements and robustness to finite precision rotation gate synthesis. For the total spin projection, the structured decomposition of $\\hat{P}_{S,M_S}$ reduces the projector T gate count. Numerical simulations show that symmetry filtering substantially increases the QPE success probability, leading to a lower overall cost compared to that of unfiltered approaches across representative molecular systems. Resource estimates further indicate that the cost of symmetry filtering is $3$ to $4$ orders of magnitude lower than that of the subsequent phase estimation step This advantage is especially relevant in large, strongly correlated systems, such as FeMoco, a standard strongly correlated open-shell benchmark. For FeMoco, the QPE cost is estimated at ${\\sim}10^{10}$ T gates, while our symmetry projector requires only ${\\sim}10^{6}$--$10^{7}$ T gates. These results establish continuous-symmetry projectors as practical and scalable tools for state preparation in quantum chemistry and provide a pathway toward realizing more efficient fault-tolerant quantum simulations."}
{"id": "2601.08568", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.08568", "abs": "https://arxiv.org/abs/2601.08568", "authors": ["K. Sai Mineesh Reddy", "Navin Kashyap"], "title": "Asymptotically good CSS codes that realize the logical transversal Clifford group fault-tolerantly", "comment": null, "summary": "This paper introduces a framework for constructing Calderbank-Shor-Steane (CSS) codes that support fault-tolerant logical transversal $Z$-rotations. Using this framework, we obtain asymptotically good CSS codes that fault-tolerantly realize the logical transversal Clifford group. Furthermore, investigating CSS-T codes, we: (a) demonstrate asymptotically good CSS-T codes wherein the transversal $T$ realizes the logical transversal $S^{\\dagger}$; (b) show that the condition $C_2 \\ast C_1 \\subseteq C_1^{\\perp}$ is necessary but not sufficient for CSS-T codes; and (c) revise the characterizations of CSS-T codes wherein the transversal $T$ implements the logical identity and the logical transversal $T$, respectively."}
{"id": "2601.08578", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.08578", "abs": "https://arxiv.org/abs/2601.08578", "authors": ["Marvin Erdmann", "Lukas Karch", "Abhishek Awasthi", "Caitlin Isobel Jones", "Pallavi Bhardwaj", "Florian Krellner", "Jonas Stein", "Claudia Linnhoff-Popien", "Nico Kraus", "Peter Eder", "Sarah Braun", "Tong Liu"], "title": "Quantum Computing -- Strategic Recommendations for the Industry", "comment": null, "summary": "This whitepaper surveys the current landscape and short- to mid-term prospects for quantum-enabled optimization and machine learning use cases in industrial settings. Grounded in the QCHALLenge program, it synthesizes hardware trajectories from different quantum architectures and providers, and assesses their maturity and potential for real-world use cases under a standardized traffic-light evaluation framework. We provide a concise summary of relevant hardware roadmaps, distinguishing superconducting and ion-trap technologies, their current states, modalities, and projected scaling trajectories. The core of the presented work are the use case evaluations in the domains of optimization problems and machine learning applications. For the conducted experiments, we apply a consistent set of evaluation criteria (model formulation, scalability, solution quality, runtime, and transferability) which are assessed in a shared system of three categories, ranging from optimistic (solutions produced by quantum computers are competitive with classical methods and/or a clear path to a quantum advantage is shown) to pessimistic (significant hurdles prevent practical application of quantum solutions now and potentially in the future). The resulting verdicts illuminate where quantum approaches currently offer promise, where hybrid classical-quantum strategies are most viable, and where classical methods are expected to remain superior."}
{"id": "2601.08579", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.08579", "abs": "https://arxiv.org/abs/2601.08579", "authors": ["Xiaotong Wang", "Shunlong Luo", "Yue Zhang"], "title": "Phase-sensitive superposition of quantum states", "comment": null, "summary": "Although the principle of superposition lies at the heart of quantum mechanics and is the root of almost all quantum phenomena such as coherence and entanglement, its quantification, except for that related to the resource theory of coherence and interference, remains relatively less studied. In this work, we address quantification of superposition from an information-theoretic perspective. We introduce a family of quantifiers of superposition, the phase-sensitive superposition, by taking into account the phases of amplitudes in the superposition of a fixed basis states (e.g., computational basis states). We establish a conservation relation for the phase-sensitive superposition, which is a kind of complementary relation and is reminiscent of wave-particle duality. We evaluate explicitly the second moment of phase-sensitive superposition and show that it is intrinsically related to the $l^2$-norm coherence. We characterize the dephasing channel induced by the maximally superposed states. We investigate the minimum and maximum superpositions, reveal their basic properties, and illustrate them through various examples. We further explore the dynamics of superposition in the Grover search algorithm, and demonstrate a complementary relation between superposition and success probability of the search algorithm. These results and quantifiers offer tools for analyzing structural features and implications of quantum superposition."}
{"id": "2601.08581", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08581", "abs": "https://arxiv.org/abs/2601.08581", "authors": ["Mir Alimuddin", "Jaemin Kim", "Acín", "Leonardo Zambrano"], "title": "Entanglement-swapping measurements for deterministic entanglement distribution", "comment": null, "summary": "Entanglement swapping is a key primitive for distributing entanglement across nodes in quantum networks. In standard protocols, the outcome of the intermediate measurement determines the resulting state, making the process inherently probabilistic and requiring postselection. In this work, we fully characterize those measurements under which entanglement swapping becomes deterministic: for arbitrary pure inputs, every measurement outcome produces local-unitarily equivalent states. We also show that an optimal measurement, maximizing a concurrence-type entanglement measure, is built from complex Hadamard matrices. For this optimal protocol, we provide a complete, dimension-dependent classification of deterministic entanglement-swapping measurements: unique in dimensions $d=2,3$, infinite for $d=4$, and comprising $72$ inequivalent classes for $d=5$. We further consider a general network with multiple swapping nodes and show that, for $d=2,3$ the resulting end-to-end state is independent of the order in which the repeaters perform the optimal measurements. Our results establish optimal entanglement-swapping schemes that are post-selection free, in the sense that they distribute entanglement across generic quantum network architectures without unfavorable measurement outcomes."}
{"id": "2601.08588", "categories": ["quant-ph", "cs.IT", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.08588", "abs": "https://arxiv.org/abs/2601.08588", "authors": ["Jacob Paul Simpson", "Efstratios Palias", "Sharu Theresa Jose"], "title": "Sample Complexity of Composite Quantum Hypothesis Testing", "comment": "Under review", "summary": "This paper investigates symmetric composite binary quantum hypothesis testing (QHT), where the goal is to determine which of two uncertainty sets contains an unknown quantum state. While asymptotic error exponents for this problem are well-studied, the finite-sample regime remains poorly understood. We bridge this gap by characterizing the sample complexity -- the minimum number of state copies required to achieve a target error level. Specifically, we derive lower bounds that generalize the sample complexity of simple QHT and introduce new upper bounds for various uncertainty sets, including of both finite and infinite cardinalities. Notably, our upper and lower bounds match up to universal constants, providing a tight characterization of the sample complexity. Finally, we extend our analysis to the differentially private setting, establishing the sample complexity for privacy-preserving composite QHT."}
{"id": "2601.08606", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.08606", "abs": "https://arxiv.org/abs/2601.08606", "authors": ["Alice Marché", "Hironobu Yoshida", "Alberto Nardin", "Hosho Katsura", "Leonardo Mazza"], "title": "Open quantum spin chains with non-reciprocity: a theoretical approach based on the time-dependent generalized Gibbs ensemble", "comment": "25 pages, 6 figues", "summary": "We study an open quantum spin chain with non-reciprocal dissipation using a theoretical approach known as time-dependent generalized Gibbs ensemble. In the regime of weak dissipation the system is fully characterized by its rapidity distribution and we derive a closed set of coupled differential equations governing their time evolution. We check the accuracy of this theory by benchmarking the results against numerical simulations. Using this framework we are able to compute both the magnetization density and current dynamics, identifying some relations between the two. The problem of the anomalous power-law exponents identified in a previous work is discussed. Our work constitutes a theoretical approach that is able to describe the physics of non-reciprocal open quantum spin chains beyond analyses based on non-interacting fermions."}
{"id": "2601.08712", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08712", "abs": "https://arxiv.org/abs/2601.08712", "authors": ["Andrew Kolmer Forbes", "Marco A. Rodríguez-García", "Ivan H. Deutsch"], "title": "Fragility of Optimal Measurements due to Noise in Probe States for Quantum Sensing", "comment": "17 pages, 9 figures", "summary": "For a given quantum state used in sensing, the quantum Cramér-Rao bound (QCRB) sets a fundamental limit on the precision achievable by an unbiased estimator of an unknown parameter, determined by the inverse of the quantum Fisher information (QFI). The QFI serves as an upper bound on the classical Fisher information (CFI), representing the maximum extractable information about the unknown parameter from measurements on a physical system. Thus, a central goal in quantum parameter estimation is to find a measurement, described by a POVM, that saturates the QFI (achieves maximum CFI), and thereby achieves the QCRB. In the idealization that one uses pure states and unitary encodings for sensing, discontinuities can appear in the CFI but not the QFI. In this article, we demonstrate that these discontinuities are important features, quantifying how much Fisher information is lost in the presence of noise. We refer to this as the Fisher information \"fragility\". We present a simple framework for understanding how discontinuities increase fragility through Jensen's inequality, and demonstrate how one can use this framework to design more robust POVMs for quantum advantage in metrology."}
{"id": "2601.08724", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.08724", "abs": "https://arxiv.org/abs/2601.08724", "authors": ["Yasushi Hasegawa", "Masayuki Ohzeki"], "title": "Kernel Learning for Regression via Quantum Annealing Based Spectral Sampling", "comment": "15pages, 5 figures, 4 tables", "summary": "While quantum annealing (QA) has been developed for combinatorial optimization, practical QA devices operate at finite temperature and under noise, and their outputs can be regarded as stochastic samples close to a Gibbs--Boltzmann distribution. In this study, we propose a QA-in-the-loop kernel learning framework that integrates QA not merely as a substitute for Markov-chain Monte Carlo sampling but as a component that directly determines the learned kernel for regression. Based on Bochner's theorem, a shift-invariant kernel is represented as an expectation over a spectral distribution, and random Fourier features (RFF) approximate the kernel by sampling frequencies. We model the spectral distribution with a (multi-layer) restricted Boltzmann machine (RBM), generate discrete RBM samples using QA, and map them to continuous frequencies via a Gaussian--Bernoulli transformation. Using the resulting RFF, we construct a data-adaptive kernel and perform Nadaraya--Watson (NW) regression. Because the RFF approximation based on $\\cos(\\bmω^{\\top}Δ\\bm{x})$ can yield small negative values and cancellation across neighbors, the Nadaraya--Watson denominator $\\sum_j k_{ij}$ may become close to zero. We therefore employ nonnegative squared-kernel weights $w_{ij}=k(\\bm{x}_i,\\bm{x}_j)^2$, which also enhances the contrast of kernel weights. The kernel parameters are trained by minimizing the leave-one-out NW mean squared error, and we additionally evaluate local linear regression with the same squared-kernel weights at inference. Experiments on multiple benchmark regression datasets demonstrate a decrease in training loss, accompanied by structural changes in the kernel matrix, and show that the learned kernel tends to improve $R^2$ and RMSE over the baseline Gaussian-kernel NW. Increasing the number of random features at inference further enhances accuracy."}
{"id": "2601.08772", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08772", "abs": "https://arxiv.org/abs/2601.08772", "authors": ["Ruiqi Zhang", "Fuchuan Wei", "Zhaohui Wei"], "title": "Enhancing classical simulation with noisy quantum devices", "comment": "24 pages, 11 figures. Comments are welcome", "summary": "As quantum devices continue to improve in scale and precision, a central challenge is how to effectively utilize noisy hardware for meaningful computation. Most existing approaches aim to recover noiseless circuit outputs from noisy ones through error mitigation or correction. Here, we show that noisy quantum devices can be directly leveraged as computational resources to enhance the classical simulation of quantum circuits. We introduce the Noisy-device-enhanced Classical Simulation (NDE-CS) protocol, which improves stabilizer-based classical Monte Carlo simulation methods by incorporating data obtained from noisy quantum hardware. Specifically, NDE-CS uses noisy executions of a target circuit together with noisy Clifford circuits to learn how the target circuit can be expressed in terms of Clifford circuits under realistic noise. The same learned relation can then be reused in the noiseless Clifford limit, enabling accurate estimation of ideal expectation values with substantially reduced sampling cost. Numerical simulations on Trotterized Ising circuits demonstrate that NDE-CS achieves orders-of-magnitude reductions in sampling cost compared to the underlying purely classical Monte Carlo approaches from which it is derived, while maintaining the same accuracy. We also compare NDE-CS with Sparse Pauli Dynamics (SPD), a powerful classical framework capable of simulating quantum circuits at previously inaccessible scales, and provide an example where the cost of SPD scales exponentially with system size, while NDE-CS scales much more favorably. These results establish NDE-CS as a scalable hybrid simulation approach for quantum circuits, where noise can be harnessed as a computational asset."}
{"id": "2601.08782", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08782", "abs": "https://arxiv.org/abs/2601.08782", "authors": ["Tangyou Huang", "Lei Du", "Lingzhen Guo"], "title": "Single-Period Floquet Control of Bosonic Codes with Quantum Lattice Gates", "comment": null, "summary": "Bosonic codes constitute a promising route to fault-tolerant quantum computing. {Existing Floquet protocols enable analytical construction of bosonic codes but typically rely on slow adiabatic ramps with thousands of driving periods.} In this work, we circumvent this bottleneck by introducing an analytical and deterministic Floquet method that directly synthesizes arbitrary unitaries within a single period. The phase-space unitary ensembles generated by our approach reproduce the Haar-random statistics, enabling practical pseudorandom unitaries in continuous-variable systems. We prepare various prototypical bosonic codes from vacuum and implement single-qubit logical gates with high fidelities using quantum lattice gates. By harnessing the full intrinsic nonlinearity of Josephson junctions, quantum lattice gates decompose quantum circuits into primitive operations for efficient continuous-variable quantum computing."}
{"id": "2601.08820", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08820", "abs": "https://arxiv.org/abs/2601.08820", "authors": ["Simon D. Reiß", "Peter van Loock"], "title": "Optimal logical Bell measurements on stabilizer codes with linear optics", "comment": "68 pages, 32 figures", "summary": "Bell measurements (BMs) are ubiquitous in quantum information and technology. They are basic elements for quantum commmunication, computation, and error correction. In particular, when performed on logical qubits encoded in physical photonic qubits, they allow for a read-out of stabilizer syndrome information to enhance loss tolerance in qubit-state transmission and fusion. However, even in an ideal setting without photon loss, BMs cannot be done perfectly based on the simplest experimental toolbox of linear optics. Here we demonstrate that any logical BM on stabilizer codes can always be mapped onto a single physical BM perfomed on any qubit pair from the two codes. As a necessary condition for the success of a logical BM, this provides a general upper bound on its success probability, especially ruling out the possibility that the stabilizer information obtainable from only partially succeeding, physical linear-optics BMs could be combined into the full logical stabilizer information. We formulate sufficient criteria to find schemes for which a single successful BM on the physical level will always allow to obtain the full logical information by suitably adapting the subsequent physical measurements. Our approach based on stabilizer group theory is generally applicable to any stabilizer code, which we demonstrate for quantum parity, five-qubit, standard and rotated planar surface, tree, and seven-qubit Steane codes. Our schemes attain the general upper bound for all these codes, while this bound had previously only been reached for the quantum parity code."}
{"id": "2601.08824", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.08824", "abs": "https://arxiv.org/abs/2601.08824", "authors": ["Kenta Kasai"], "title": "Breaking the Orthogonality Barrier in Quantum LDPC Codes", "comment": null, "summary": "Classical low-density parity-check (LDPC) codes are a widely deployed and well-established technology, forming the backbone of modern communication and storage systems. It is well known that, in this classical setting, increasing the girth of the Tanner graph while maintaining regular degree distributions leads simultaneously to good belief-propagation (BP) decoding performance and large minimum distance. In the quantum setting, however, this principle does not directly apply because quantum LDPC codes must satisfy additional orthogonality constraints between their parity-check matrices. When one enforces both orthogonality and regularity in a straightforward manner, the girth is typically reduced and the minimum distance becomes structurally upper bounded.\n  In this work, we overcome this limitation by using permutation matrices with controlled commutativity and by restricting the orthogonality constraints to only the necessary parts of the construction, while preserving regular check-matrix structures. This design breaks the conventional trade-off between orthogonality, regularity, girth, and minimum distance, allowing us to construct quantum LDPC codes with large girth and without the usual distance upper bounds. As a concrete demonstration, we construct a girth-8, (3,12)-regular $[[9216,4612, \\leq 48]]$ quantum LDPC code and show that, under BP decoding combined with a low-complexity post-processing algorithm, it achieves a frame error rate as low as $10^{-8}$ on the depolarizing channel with error probability $4 \\%$."}
{"id": "2601.08324", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08324", "abs": "https://arxiv.org/abs/2601.08324", "authors": ["F. Iwase"], "title": "Critical quantum states and hierarchical spectral statistics in a Cantor potential", "comment": "13 pages, 6 figures", "summary": "We study the spectral statistics and wave-function properties of a one-dimensional quantum system subject to a Cantor-type fractal potential. By analyzing the nearest-neighbor level spacings, inverse participation ratio (IPR), and the scaling behavior of the integrated density of states (IDS), we demonstrate how the self-similar geometry of the potential is imprinted on the quantum spectrum. The energy-resolved level spacings form a hierarchical, filamentary structure, in sharp contrast to those of periodic and random systems. The normalized level-spacing distribution exhibits a bimodal structure, reflecting the deterministic recurrence of spectral gaps. A multifractal analysis of eigenstates reveals critical behavior: the generalized fractal dimensions $D_q$ lie strictly between the limits of extended and localized states, exhibiting a distinct $q$-dependence. Consistently, the IPR indicates the coexistence of quasi-extended and localized features, characteristic of critical wave functions. The IDS shows anomalous power-law scaling at low energies, with an exponent close to the Hausdorff dimension of the underlying Cantor set, indicating that the geometric fractality governs the spectral dimensionality. At higher energies, this scaling crosses over to the semiclassical Weyl law. Our results establish a direct connection between deterministic fractal geometry, hierarchical spectral statistics, and quantum criticality."}
{"id": "2601.08347", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08347", "abs": "https://arxiv.org/abs/2601.08347", "authors": ["Maksym Serbyn", "Alexander Avdoshkin", "Oriana K. Diessel", "David A. Huse"], "title": "Eigenstate thermalization in thermal first-order phase transitions", "comment": "11 pages, 8 figures", "summary": "The eigenstate thermalization hypothesis (ETH) posits how isolated quantum many-body systems thermalize, assuming that individual eigenstates at the same energy density have identical expectation values of local observables in the limit of large systems. While the ETH apparently holds across a wide range of interacting quantum systems, in this work we show that it requires generalization in the presence of thermal first-order phase transitions. We introduce a class of all-to-all spin models, featuring first-order thermal phase transitions that stem from two distinct mean-field solutions (two ``branches'') that exchange dominance in the many-body density of states as the energy is varied. We argue that for energies in the vicinity of the thermal phase transition, eigenstate expectation values do not need to converge to the same thermal value. The system has a regime with coexistence of two classes of eigenstates corresponding to the two branches with distinct expectation values at the same energy density, and another regime with Schrodinger-cat-like eigenstates that are inter-branch superpositions; these two regimes are separated by an eigenstate phase transition. We support our results by semiclassical calculations and an exact diagonalization study of a microscopic spin model, and argue that the structure of eigenstates in the vicinity of thermal first-order phase transitions can be experimentally probed via non-equilibrium dynamics."}
{"id": "2601.08615", "categories": ["cond-mat.str-el", "hep-th", "math.QA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08615", "abs": "https://arxiv.org/abs/2601.08615", "authors": ["Kansei Inamura", "Shuhei Ohyama"], "title": "Generalized cluster states in 2+1d: non-invertible symmetries, interfaces, and parameterized families", "comment": "93 pages + appendices", "summary": "We construct 2+1-dimensional lattice models of symmetry-protected topological (SPT) phases with non-invertible symmetries and investigate their properties using tensor networks. These models, which we refer to as generalized cluster models, are constructed by gauging a subgroup symmetry $H \\subset G$ in models with a finite group 0-form symmetry $G$. By construction, these models have a non-invertible symmetry described by the group-theoretical fusion 2-category $\\mathcal{C}(G; H)$. After identifying the tensor network representations of the symmetry operators, we study the symmetry acting on the interface between two generalized cluster states. In particular, we will see that the symmetry at the interface is described by a multifusion category known as the strip 2-algebra. By studying possible interface modes allowed by this symmetry, we show that the interface between generalized cluster states in different SPT phases must be degenerate. This result generalizes the ordinary bulk-boundary correspondence. Furthermore, we construct parameterized families of generalized cluster states and study the topological charge pumping phenomena, known as the generalized Thouless pump. We exemplify our construction with several concrete cases, and compare them with known phases, such as SPT phases with $2\\mathrm{Rep}((\\mathbb{Z}_{2}^{[1]}\\times\\mathbb{Z}_{2}^{[1]})\\rtimes\\mathbb{Z}_{2}^{[0]})$ symmetry."}
{"id": "2601.08616", "categories": ["cond-mat.str-el", "hep-th", "math.QA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.08616", "abs": "https://arxiv.org/abs/2601.08616", "authors": ["Shuhei Ohyama", "Kansei Inamura"], "title": "Parameterized families of 2+1d $G$-cluster states", "comment": "70 pages", "summary": "We construct a $G$-cluster Hamiltonian in 2+1 dimensions and analyze its properties. This model exhibits a $G\\times2\\mathrm{Rep}(G)$ symmetry, where the $2\\mathrm{Rep}(G)$ sector realizes a non-invertible symmetry obtained by condensing appropriate algebra objects in $\\mathrm{Rep}(G)$. Using the symmetry interpolation method, we construct $S^1$- and $S^2$-parameterized families of short-range-entangled (SRE) states by interpolating an either invertible $0$-form or $1$-form symmetry contained in $G\\times2\\mathrm{Rep}(G)$. Applying an adiabatic evolution argument to this family, we analyze the pumped interface mode generated by this adiabatic process. We then explicitly construct the symmetry operator acting on the interface and show that the interface mode carries a nontrivial charge under this symmetry, thereby demonstrating the nontriviality of the parameterized family."}
