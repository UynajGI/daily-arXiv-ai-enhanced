{"id": "2602.17872", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.17872", "abs": "https://arxiv.org/abs/2602.17872", "authors": ["Weihang Lu", "Camron Farhang", "Yuchuan Yao", "Pratap Pal", "Hao Zhang", "Shaofeng Han", "Shi-Zeng Lin", "Chang-Beom Eom", "Jing Xia"], "title": "Direct imaging of a topological nematic phase in a spin-compensated magnet", "comment": null, "summary": "Density waves conventionally describe the periodic modulation of charge or spin, yet the spatial modulation of electronic topology has remained elusive. Here, we report the discovery of a Berry-curvature density wave in the noncollinear antiferromagnet Mn3NiN with compensated spins. Using high-precision Sagnac Kerr microscopy, we directly image micrometer-scale modulations of the Berry curvature. These topological ripples exhibit orientations unpinned to the crystal lattice, forming a nematic phase that spontaneously breaks rotational symmetry. We attribute this instability to field-induced spatial variations of the spin texture driven by competing magnetic interactions. This discovery unveils a new class of collective order in spin-compensated magnets arising from the geometric phase of the wavefunction itself and offering a tunable degree of freedom for topological spintronics based on antiferromagnets and altermagnets."}
{"id": "2602.17906", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.17906", "abs": "https://arxiv.org/abs/2602.17906", "authors": ["Hongtao Yan", "Chun-Chih Tseng", "Anzhuoer Li", "Manish Kumar", "Kaile Wang", "Shizai Chu", "Kenji Watanabe", "Takashi Taniguchi", "Allan H. MacDonald", "Matthew Yankowitz", "Keji Lai"], "title": "Microwave Imaging of Edge Conductivity in Graphene at Charge Neutrality and Quantum Hall States", "comment": null, "summary": "We report local conductivity imaging of edge states in monolayer graphene by millikelvin microwave impedance microscopy (MIM). At the charge-neutrality point, as the magnetic field increases, the local conductivity at the edge drops to zero more slowly than in the bulk. This behavior is consistent with the calculated spatial profile of the charge gap in the canted antiferromagnetic phase. For comparison, we also perform microwave imaging of integer quantum Hall states away from neutrality, which host dissipationless chiral edge channels. The evolution of the edge signal as a function of the bulk gap is fundamentally different between the Landau level filling factor $ν= 0$ and $|ν| \\ge 1$ integer quantum Hall states, which can be qualitatively explained by numerical simulations and theoretical analysis. Our results provide a comprehensive microscopic picture of the edge and bulk states as the Fermi level moves across the unique Landau-level spectrum of graphene."}
{"id": "2602.17915", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.17915", "abs": "https://arxiv.org/abs/2602.17915", "authors": ["Qinwen Deng", "Andrea Capa Salinas", "Suchismita Sarker", "Leon Balents", "Stephen D. Wilson", "Liang Wu"], "title": "Observation of Room-temperature Charge Density Wave Correlations via Coherent Phonon Spectroscopy in Sn-doped Kagome Superconductor CsV$_3$Sb$_5$", "comment": "Accepted to Physical Review B", "summary": "In this work, we perform ultrafast time-resolved reflectivity measurements to track the evolution of charge density wave (CDW) correlations in Sn-doped Kagome superconductor CsV$_3$Sb$_{5-x}$Sn$_x$. By extracting the coherent phonon spectrum, we evidence robust signatures of CDW correlations at temperature and doping ranges far beyond the phase boundary of long-range CDW order. Remarkably, we unveil short-range CDW correlations survive up to room temperature in $x = 0.32$ Sn-doped CsV$_3$Sb$_5$, supported by synchrotron X-ray diffraction measurements. We point out the introduction of quenched disorder by Sn doping can pin the CDW and form static short-range CDW, which can explain the observed persistent CDW signatures. Our results thus corroborate the ubiquity and robustness of CDW correlations in Sn-doped CsV$_3$Sb$_5$ and provide new insights on the role of disorders on the CDW correlations in AV$_3$Sb$_5$ family."}
{"id": "2602.17959", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.17959", "abs": "https://arxiv.org/abs/2602.17959", "authors": ["Xinyue Liu", "Tao Li"], "title": "Optical and Hall conductivity of the two dimensional Hubbard model: effective theory description, sign-problem-free Monte Carlo simulation and applications to the cuprate superconductors", "comment": "19 pages, 7 figures. Some results of arXiv:2404.11224 are included here, but rewritten in a much broader perspective", "summary": "Exact formulas for the optical conductivity and the Hall conductivity of the two dimensional Hubbard model are derived in terms of an effective theory description of the local moment fluctuation in the system. In this framework, the quantum Monte Carlo simulation of the electromagnetic response of such a strongly correlated electron system becomes sign-problem-free in many physically relevant cases. In particular, it is sign-problem-free when we assume the widely used Millis-Monien-Pines form for the phenomenological susceptibility in the effective action of the fluctuating local moment, even though these local moments are now subjected to Landau damping as a result of their coupling to the itinerant quasiparticle on the fermi surface. This is true more generally when a $\\varphi^{4}$ term is included in the effective action and is thus not restricted to the Gaussian limit. Here we demonstrate the power of this framework by studying the effect of thermal fluctuation of the local moment on the optical conductivity $σ^{xx}(ω)$ and the Hall conductivity $σ^{xy}(ω)$ of the cuprate superconductors. Both $σ^{xx}(ω)$ and $σ^{xy}(ω)$ calculated are found to exhibit a two-component structure, with a Drude component at low energy and a mid-infrared component at higher energy. Depending on the relative importance of the hole pocket and the electron pocket on the reconstructed fermi surface and the coupling strength to the local moment, the Drude component in $\\mathrm{Im}σ^{xy}(ω)$ can be either positive or negative.(full-length abstract can be found in the main text.)"}
{"id": "2602.18334", "categories": ["physics.hist-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.18334", "abs": "https://arxiv.org/abs/2602.18334", "authors": ["G. V. Pavan Kumar"], "title": "C.V. Raman's Exploration in Optics -- A Spectrum of History", "comment": "Invited review. Submitted to Journal of Optical Society of America B - Special issue on \"Optics in South Asia\"", "summary": "C.V. Raman (1888-1970) was one of the pioneering scientists to have emerged from India during the colonial era. His scientific explorations were driven by his curiosity to understand wave phenomena. Naturally, optics and related physical effects were at the heart of such an exploration. Apart from his Nobel prize-winning discovery of the Raman effect, his research included topics such as oblique diffraction, light scattering from liquids and amorphous solids, classical and quantum nature of light, acousto-optics, haloes and coronae (speckles), crystal dynamics and soft modes, optics of minerals, floral colors, physiology of vision and many other aspects related to light in natural settings. In this article, I give a historical overview of some of the work by C.V. Raman and his group that had a direct connection to optics and optical spectroscopy."}
{"id": "2602.17802", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.17802", "abs": "https://arxiv.org/abs/2602.17802", "authors": ["Edson D. Leonel", "Mayla A. M. de Almeida", "Juan Pedro Tarigo", "Arturo C. Marti", "Diego F. M. Oliveira"], "title": "Universal Second-Order Phase Transition from Integrability to Chaos", "comment": null, "summary": "We report a dynamical phase transition from integrability to non-integrability in a simple oval-like billiard with boundary $R(θ)=1+ε\\cos(pθ)$. For $ε=0$, the phase space is {\\it foliated} by invariant curves corresponding to periodic or quasiperiodic motion, whereas for small $ε$ a thin chaotic layer separates rotational and librational trajectories. As $ε$ increases, this layer grows according to a well-defined scaling law whose chaotic dispersion follows $ω_{\\rm rms,sat}\\simε^{\\tildeα}$, where the exponent $\\tildeα$ coincides with those of the Fermi-Ulam model, periodically corrugated waveguides, and a family of discrete mappings, revealing a universal mechanism for the onset of chaos in weakly perturbed integrable systems. The deviation of the reflection angle in the billiard, $ω_{\\rm rms,sat}$, acts as an order parameter: it vanishes continuously as $ε\\to 0$, signalling an ordered (integrable) phase, while its susceptibility $χ=dω_{\\rm rms,sat}/dε$ diverges, indicating a second-order phase transition. A symmetry breaking and an analytically solvable diffusion process complete the near-critical phenomenology. These results establish a unified framework for the emergence of chaos from integrability."}
{"id": "2602.17971", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.17971", "abs": "https://arxiv.org/abs/2602.17971", "authors": ["Danyang Li", "John Taylor", "Quanling Deng"], "title": "Domain-Decomposed Lagrangian Data Assimilation for Drifting Sea-Ice Floe Dynamics", "comment": null, "summary": "Sea ice dynamics are crucial to the global climate system, yet traditional continuum (e.g., viscous-plastic) models often fail to represent the discrete floe interactions that dominate in the marginal ice zone. Lagrangian discrete element methods (DEMs) resolve floe-scale physics more realistically, but their high particle counts make ensemble data assimilation (DA) more expensive. We consider a highly-simplified floe model and propose a scalable, domain-decomposed DA framework that couples Lagrangian particle observations with an ensemble transform Kalman filter (ETKF) to recover the underlying ocean flow field in a multiscale setting. The Eulerian domain is first partitioned into subdomains. We then impose an ETKF in each subdomain to recover the local fine-scale ocean features. A Gaussian-weighted blending step then reconstructs a globally consistent flow field across subdomain boundaries. Numerical experiments demonstrate consistently better skill scores that are characterised by normalised root mean square error (NRMSE) and pattern correlation coefficients (PCC), compared to the global and expensive DA baseline. Results suggest that the domain-decomposed DA method is an alternative, scalable approach for particle-based sea-ice floe dynamics and ocean flow recovery."}
{"id": "2602.18056", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.18056", "abs": "https://arxiv.org/abs/2602.18056", "authors": ["Akihito Nagahama", "Nichika Asai", "Claudio Feliciani", "Xiaolu Jia", "Katsuhiro Nishinari"], "title": "Effect of vehicle groups on heterogeneous disordered traffic flow", "comment": "All of the abstract is in the PDF file", "summary": "In heterogeneous disordered traffic, where various vehicle types operate without strict lane discipline, self-organized vehicle groups often emerge. While the formation of such groups has been recognized, their influence on macroscopic traffic dynamics remains unclear. This study investigates how the prevalence and composition of vehicle groups affect flow-density relationships in heterogeneous disordered traffic. Using trajectory data from real-world video observations, we apply three distinct Passenger Car Unit (PCU) estimation methods to construct flow-density diagrams that account for traffic heterogeneity. The analysis reveals that group proportions, i.e., the proportion of vehicles that are classified as belonging to groups, have a nonlinear and traffic-situation-dependent impact on flow characteristics. Specifically, moderate group proportions (30-60%) are associated with higher flow rates in medium- and high-density conditions, whereas proportions exceeding 50% correspond to skewed traffic distributions toward low- or high-density extremes. Comparisons between vehicle-count-based and PCU-based group proportions indicate that normalization methods significantly affect the interpretation of group dynamics, particularly when groups consist mainly of small-PCU vehicles such as motorcycles. Additionally, lower group proportions enhance flow under free-flow conditions, while the entropy-based analysis indicates that the association between entropy alone and speed is not consistently observed across traffic situations. By contrasting representative trends and extreme high-flow cases, the results further suggest that traffic under similar density and group-proportion conditions can exhibit low-efficiency and high-efficiency modes."}
{"id": "2602.17776", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17776", "abs": "https://arxiv.org/abs/2602.17776", "authors": ["Yuhe Wang", "Min Wang"], "title": "Solving and learning advective multiscale Darcian dynamics with the Neural Basis Method", "comment": null, "summary": "Physics-governed models are increasingly paired with machine learning for accelerated predictions, yet most \"physics--informed\" formulations treat the governing equations as a penalty loss whose scale and meaning are set by heuristic balancing. This blurs operator structure, thereby confounding solution approximation error with governing-equation enforcement error and making the solving and learning progress hard to interpret and control. Here we introduce the Neural Basis Method, a projection-based formulation that couples a predefined, physics-conforming neural basis space with an operator-induced residual metric to obtain a well-conditioned deterministic minimization. Stability and reliability then hinge on this metric: the residual is not merely an optimization objective but a computable certificate tied to approximation and enforcement, remaining stable under basis enrichment and yielding reduced coordinates that are learnable across parametric instances. We use advective multiscale Darcian dynamics as a concrete demonstration of this broader point. Our method produce accurate and robust solutions in single solves and enable fast and effective parametric inference with operator learning."}
{"id": "2602.18042", "categories": ["cs.CE", "cs.NE", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.18042", "abs": "https://arxiv.org/abs/2602.18042", "authors": ["Karkulali Pugalenthi", "Jian Cheng Wong", "Qizheng Yang", "Pao-Hsiung Chiu", "My Ha Dao", "Nagarajan Raghavan", "Chinchun Ooi"], "title": "PINEAPPLE: Physics-Informed Neuro-Evolution Algorithm for Prognostic Parameter Inference in Lithium-Ion Battery Electrodes", "comment": null, "summary": "Accurate, real-time, yet non-destructive estimation of internal states in lithium-ion batteries is critical for predicting degradation, optimizing usage strategies, and extending operational lifespan. Here, we introduce PINEAPPLE (Physics-Informed Neuro-Evolution Algorithm for Prognostic Parameter inference in Lithium-ion battery Electrodes), a novel framework that integrates physics-informed neural networks (PINNs) with an evolutionary search algorithm to enable rapid, scalable, and interpretable parameter inference with potential for application to next-generation batteries. The meta-learned PINN utilizes fundamental physics principles to achieve accurate zero-shot prediction of electrode behavior with test errors below 0.1$\\%$ while maintaining an order-of-magnitude speed-up over conventional solvers. PINEAPPLE demonstrates robust parameter inference solely from voltage-time discharge curves across multiple batteries from the open-source CALCE repository, recovering the evolution of key internal state parameters such as Li-ion diffusion coefficients across usage cycles. Notably, the inferred cycle-dependent evolution of these parameters exhibit consistent trends across different batteries without any customized degradation physics-embedded heuristic, highlighting the effective regularizing effect and robustness that can be conferred through incorporation of fundamental physics in PINEAPPLE. By enabling computationally efficient, real-time parameter estimation, PINEAPPLE offers a promising route towards the non-destructive, physics-based characterization of inter-cell and intra-cell variability of battery modules and battery packs, thereby unlocking new opportunities for downstream on-the-fly needs in next-generation battery management systems such as individual cell-scale state-of-health diagnostics."}
{"id": "2602.17772", "categories": ["stat.ME", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.17772", "abs": "https://arxiv.org/abs/2602.17772", "authors": ["Guoxuan Ma", "Yuan Zhong", "Moyan Li", "Yuxiao Nie", "Jian Kang"], "title": "Sparse Bayesian Modeling of EEG Channel Interactions Improves P300 Brain-Computer Interface Performance", "comment": null, "summary": "Electroencephalography (EEG)-based P300 brain-computer interfaces (BCIs) enable communication without physical movement by detecting stimulus-evoked neural responses. Accurate and efficient decoding remains challenging due to high dimensionality, temporal dependence, and complex interactions across EEG channels. Most existing approaches treat channels independently or rely on black-box machine learning models, limiting interpretability and personalization. We propose a sparse Bayesian time-varying regression framework that explicitly models pairwise EEG channel interactions while performing automatic temporal feature selection. The model employs a relaxed-thresholded Gaussian process prior to induce structured sparsity in both channel-specific and interaction effects, enabling interpretable identification of task-relevant channels and channel pairs. Applied to a publicly available P300 speller dataset of 55 participants, the proposed method achieves a median character-level accuracy of 100\\% using all stimulus sequences and attains the highest overall decoding performance among competing statistical and deep learning approaches. Incorporating channel interactions yields subgroup-specific gains of up to 7\\% in character-level accuracy, particularly among participants who abstained from alcohol (up to 18\\% improvement). Importantly, the proposed method improves median BCI-Utility by approximately 10\\% at its optimal operating point, achieving peak throughput after only seven stimulus sequences. These results demonstrate that explicitly modeling structured EEG channel interactions within a principled Bayesian framework enhances predictive accuracy, improves user-centric throughput, and supports personalization in P300 BCI systems."}
{"id": "2602.17851", "categories": ["q-fin.CP", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.17851", "abs": "https://arxiv.org/abs/2602.17851", "authors": ["Krishna Neupane", "Prem Sapkota", "Ujjwal Prajapati"], "title": "Beyond the Numbers: Causal Effects of Financial Report Sentiment on Bank Profitability", "comment": null, "summary": "This study establishes the causal effects of market sentiment on firm profitability, moving beyond traditional correlational analyses. It leverages a causal forest machine learning methodology to control for numerous confounding variables, enabling systematic analysis of heterogeneity and non-linearities often overlooked. A key innovation is the use of a pre-trained FinancialBERT to generate sentiment scores from quarterly reports, which are then treated as causal interventions impacting profitability dynamics like returns and volatilities. Utilizing a comprehensive dataset from NEPSE, NRB, and individual financial institutions, the research employs SHAP analysis to identify influential profit predictors. A two-pronged causal analysis further explores how sentiment's impact is conditioned by Loan Portfolio/Asset Composition and Balance Sheet Strength/Leverage. Average Treatment Effect analyses, combined with SHAP insights, reveal statistically significant causal associations between certain balance sheet and expense management variables and profitability. This advanced causal machine learning framework significantly extends existing literature, providing a more robust understanding of how financial sentiment truly impacts firm performance."}
{"id": "2602.17874", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.17874", "abs": "https://arxiv.org/abs/2602.17874", "authors": ["J. Liu", "F. Milano"], "title": "Modal Energy for Power System Analysis: Definitions and Requirements", "comment": null, "summary": "Modal energy provides information complementary to and based on conventional eigenvalues and participation factors for power system modal analysis. However, modal energy definition is not unique. This letter clarifies the definitions and applicability of mainstream modal energy approaches, focusing on their mappings to eigenvalues and to the total system energy. It is shown that these mappings hold only under restrictive conditions, notably system normality, which limits their applicability in inverter-dominated power systems."}
{"id": "2602.17874", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.17874", "abs": "https://arxiv.org/abs/2602.17874", "authors": ["J. Liu", "F. Milano"], "title": "Modal Energy for Power System Analysis: Definitions and Requirements", "comment": null, "summary": "Modal energy provides information complementary to and based on conventional eigenvalues and participation factors for power system modal analysis. However, modal energy definition is not unique. This letter clarifies the definitions and applicability of mainstream modal energy approaches, focusing on their mappings to eigenvalues and to the total system energy. It is shown that these mappings hold only under restrictive conditions, notably system normality, which limits their applicability in inverter-dominated power systems."}
{"id": "2602.18088", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.18088", "abs": "https://arxiv.org/abs/2602.18088", "authors": ["Igor Hołowacz", "Piotr Bródka"], "title": "Beyond Individual Influence: The Role of Echo Chambers and Community Seeding in the Multilayer three state q-Voter Model", "comment": "Preprint of the paper submitted to WAW 2026 - 21st Workshop on Modelling and Mining Networks", "summary": "The diffusion of complex opinions is severely hindered in multilayer social networks by echo chambers and cognitive consistency mechanisms. We investigate Influence Maximization strategies within the 3-state multilayer q-voter model. Utilizing the mABCD benchmark, we simulate social environments ranging from integrated Open Worlds to segregated Fortress Worlds. Our results reveal a topological paradox that we term the \"Fortress Trap\". In highly modular networks, strategies maximizing local density such as Clique Influence Maximization (CIM) and k-Shell fail to trigger global cascades, creating isolated bunkers of consensus due to the Overkill Effect. Furthermore, we identify a Redundancy Trap in perfectly aligned Clan topologies, where the structural overlap of layers creates a \"Perfect Prison,\" rendering it the most resistant environment to diffusion. We demonstrate that VoteRank, a strategy that prioritizes diversity of reach over local intensity, consistently outperforms structure-based methods. These findings suggest that, for complex contagion, maximizing topological entropy is more effective than reinforcing local clusters."}
{"id": "2602.17839", "categories": ["cond-mat.stat-mech", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.17839", "abs": "https://arxiv.org/abs/2602.17839", "authors": ["Edson D. Leonel", "Diego F. M. Oliveira"], "title": "Scaling invariance: a bridge between geometry, dynamics and criticality", "comment": null, "summary": "Scale invariance is a central organizing principle in physics, underlying phenomena that range from critical behaviour in statistical mechanics to transport and chaos in nonlinear dynamical systems. Here we present a unified and physically motivated exploration of scaling concepts, emphasizing how invariance under rescaling transformations emerges across systems of increasing dynamical complexity. Rather than adopting a purely abstract approach, we combine simple geometrical constructions, analytical arguments, and prototypical dynamical models to build physical intuition. We begin with elementary, easily reproducible examples governed by a single control parameter, showing how power-law behaviour naturally arises when characteristic scales are absent. We then extend the discussion to nonlinear dynamical systems exhibiting local bifurcations, where two scaling variables control the relaxation toward stationary states. In this context, scaling invariance manifests through critical exponents, crossover phenomena, and critical slowing down, allowing systems of different dimensionality to be grouped into universality classes. Finally, we address continuous phase transitions in chaotic dynamical systems, including transitions from integrability to non-integrability and from bounded to unbounded diffusion. By drawing on concepts traditionally associated with statistical mechanics, such as order parameters, susceptibilities, symmetry breaking, elementary excitations, and topological defects, we show how these transitions can be interpreted within a coherent scaling framework. Taken together, the examples discussed here demonstrate that scaling invariance provides a unifying language for understanding structure, transport, and criticality in nonlinear systems, bridging deterministic dynamics and nonequilibrium statistical physics in a transparent and physically intuitive manner."}
{"id": "2602.17748", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.17748", "abs": "https://arxiv.org/abs/2602.17748", "authors": ["Hyunho Cha"], "title": "A dimension-independent strict submultiplicativity for the transposition map in diamond norm", "comment": "4 pages", "summary": "We prove that there exists an absolute constant $α<1$ such that for every finite dimension $d$ and every quantum channel $T$ on $\\mathsf{L}(\\mathbb{C}^d)$, $\\left\\|Θ\\circ(\\mathrm{id}-T)\\right\\|_\\diamond \\le α\\,\\left\\|Θ\\right\\|_\\diamond\\,\\left\\|\\mathrm{id}-T\\right\\|_\\diamond$, where $Θ$ is the transposition map. In fact we show the explicit choice $α=1/\\sqrt{2}$ works."}
{"id": "2602.17896", "categories": ["math.ST", "stat.OT"], "pdf": "https://arxiv.org/pdf/2602.17896", "abs": "https://arxiv.org/abs/2602.17896", "authors": ["Mingao Yuan", "Md. Niamul Islam Sium"], "title": "Central limit theorem for the global clustering coefficient of random geometric graphs", "comment": null, "summary": "The global clustering coefficient serves as a powerful metric for the structural analysis and comparison of complex networks. Random geometric graphs offer a realistic framework for representing the spatial constraints and geometry often found in real-world network datasets. In this paper, we establish a central limit theorem for the global clustering coefficient of random geometric graphs. Our main result identifies the centering and scaling sequences required for convergence in law to the standard normal distribution. Our approach varies by regime: in the dense case, we employ the Lyapunov CLT; in the intermediate case, we utilize the asymptotic theory of $U$-statistics with sample-size-dependent kernels; and in the sparse regime, we use the method of moments to derive the asymptotic distribution. Notably, the convergence rates for non-uniform and uniform random geometric graphs diverge in the dense regime, yet they coincide in the sparse regime. In addition, we find that the global clustering coefficient for both uniform and non-uniform RGGs is asymptotically equal to $3/4$"}
{"id": "2602.18335", "categories": ["cond-mat.dis-nn", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.18335", "abs": "https://arxiv.org/abs/2602.18335", "authors": ["Guy Greenbaum", "Will R. Branford", "Andrew L. Goodwin"], "title": "Responsive Disorder in a Metal-Organic Framework Enables Solid-State Reservoir Computing", "comment": null, "summary": "Complex systems with nonlinear response mechanisms can be applied as reservoir computers for energy-efficient machine learning tasks. Historically explored at the macro- and meso-scale, physical reservoir computing has recently been extended to the atomic scale via chemical mixtures with strong and dynamic heterogeneity. Here we explore the possibility that configurational degeneracy within disordered materials might form the basis for solid-state atomic-scale reservoirs. Our proof-of-concept uses the disordered metal-organic framework DUT-8, which undergoes a series of disorder-disorder transitions on exposure to different guest species. We show that variations in X-ray diffuse scattering associated with these transitions function as suitable readouts for machine learning applications. A combination of nonlinearity and memory effects in the DUT-8 response allows the system to carry out both classification and time-series machine learning tasks with accuracies comparable to those of mesoscale physical reservoir computers. Our results suggest a new avenue for exploiting correlated disorder in solid phases whenever the nature of that disorder can be modulated through external perturbations-a phenomenon we term `responsive disorder'."}
{"id": "2602.17924", "categories": ["hep-lat", "hep-ph", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.17924", "abs": "https://arxiv.org/abs/2602.17924", "authors": ["Lucas Chandler", "Frank X. Lee", "Andrei Alexandru"], "title": "Higher order quantization conditions for two-body scattering with spin", "comment": "53 pages, 3 figures, 26 tables, 1 supplement", "summary": "We examine the Lüscher quantization condition to high order for the scattering of a spinless particle and a spin-1/2 particle in a periodic box. First, we derive the quantization conditions in a non-relativistic framework up to total angular momentum $J=11/2$ in both cubic and elongated geometries, and for both rest and moving frames. Then, we introduce a method to transparently cross-check their convergence, using both quantized energy levels in the box and infinite-volume phase shifts for the same potential. We clarify how to incorporate spin-orbit coupling into the formalism and show in detail how the quantization conditions converge order by order in the various irreducible representations. In all, we validated 19 quantization conditions (12 in cubic box, 7 in elongated box). This is a necessary step in applying the method in precision studies of systems in finite volume with half-integer spin, such as meson-baryon scattering."}
{"id": "2602.17782", "categories": ["math.OC", "math.DG"], "pdf": "https://arxiv.org/pdf/2602.17782", "abs": "https://arxiv.org/abs/2602.17782", "authors": ["Adriano Da Silva", "Lino Grama", "Douglas Duarte Novaes", "Margarita Quispe Tusco"], "title": "Maxwell Strata in the sub-Riemannian problem on solvable, nonnilpotent regular three-dimensional Lie groups", "comment": null, "summary": "In this paper, we study the sub-Riemannian problem associated with contact structures on connected, simply connected, solvable, non-nilpotent, regular three-dimensional Lie groups. For these groups, the vertical component of the Hamiltonian system takes the form of a perturbed pendulum. A qualitative phase-space analysis allows us to prove that this vertical component exhibits nontrivial symmetries. In particular, we are able to fully characterize the Maxwell set corresponding to these symmetries, and show that its first Maxwell time coincides with the period of the pendulum for almost all geodesics. This result yields an explicit upper bound for the cut time in terms of the period of the pendulum."}
{"id": "2602.18213", "categories": ["cond-mat.str-el", "cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.18213", "abs": "https://arxiv.org/abs/2602.18213", "authors": ["Gia-Wei Chern", "Yunhao Fan", "Sheng Zhang", "Puhan Zhang"], "title": "Machine-learning force-field models for dynamical simulations of metallic magnets", "comment": "9 pages, 5 figures", "summary": "We review recent advances in machine learning (ML) force-field methods for Landau-Lifshitz-Gilbert (LLG) simulations of itinerant electron magnets, focusing on scalability and transferability. Built on the principle of locality, a deep neural network model is developed to efficiently and accurately predict the electron-mediated forces governing spin dynamics. Symmetry-aware descriptors constructed through a group-theoretical approach ensure rigorous incorporation of both lattice and spin-rotation symmetries. The framework is demonstrated using the prototypical s-d exchange model widely employed in spintronics. ML-enabled large-scale simulations reveal novel nonequilibrium phenomena, including anomalous coarsening of tetrahedral spin order on the triangular lattice and the freezing of phase separation dynamics in lightly hole-doped, strong-coupling square-lattice systems. These results establish ML force-field frameworks as scalable, accurate, and versatile tools for modeling nonequilibrium spin dynamics in itinerant magnets."}
{"id": "2602.17810", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.17810", "abs": "https://arxiv.org/abs/2602.17810", "authors": ["Edson D. Leonel", "Mayla A. M. de Almeida", "Juan Pedro Tarigo", "Arturo C. Marti", "Diego F. M. Oliveira"], "title": "Describing a Universal Critical Behavior in a transition from order to chaos", "comment": null, "summary": "We present a comprehensive discussion of a transition from integrability to non-integrability in an oval billiard with a static boundary. This transition is controlled by a deformation parameter $ε$, which modifies the boundary shape from circular, corresponding to $ε=0$ and an integrable dynamics, to oval for $ε\\neq 0$, where non-integrability emerges. The deformation of the circular billiard gives rise to a chaotic layer that develops along a well-defined stripe in phase space. By introducing a set of transformations that isolate this chaotic stripe, we characterise the diffusive spreading of ensembles of trajectories and identify an observable, $ω_{rms,{\\rm sat}}$, which plays the role of an order parameter for the transition. For small deformations, the saturation value of the diffusion obeys the scaling law $ω_{rms,{\\rm sat}}\\proptoε^{\\tildeα}$, with a critical exponent $\\tildeα=0.507(2)$, vanishing continuously as $ε\\rightarrow 0$. The associated susceptibility, $χ=dω_{rms,{\\rm sat}}/dε$, diverges in the same limit, signalling the presence of critical behavior analogous to that observed in second-order (continuous) phase transitions in statistical mechanics."}
{"id": "2602.18042", "categories": ["cs.CE", "cs.NE", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.18042", "abs": "https://arxiv.org/abs/2602.18042", "authors": ["Karkulali Pugalenthi", "Jian Cheng Wong", "Qizheng Yang", "Pao-Hsiung Chiu", "My Ha Dao", "Nagarajan Raghavan", "Chinchun Ooi"], "title": "PINEAPPLE: Physics-Informed Neuro-Evolution Algorithm for Prognostic Parameter Inference in Lithium-Ion Battery Electrodes", "comment": null, "summary": "Accurate, real-time, yet non-destructive estimation of internal states in lithium-ion batteries is critical for predicting degradation, optimizing usage strategies, and extending operational lifespan. Here, we introduce PINEAPPLE (Physics-Informed Neuro-Evolution Algorithm for Prognostic Parameter inference in Lithium-ion battery Electrodes), a novel framework that integrates physics-informed neural networks (PINNs) with an evolutionary search algorithm to enable rapid, scalable, and interpretable parameter inference with potential for application to next-generation batteries. The meta-learned PINN utilizes fundamental physics principles to achieve accurate zero-shot prediction of electrode behavior with test errors below 0.1$\\%$ while maintaining an order-of-magnitude speed-up over conventional solvers. PINEAPPLE demonstrates robust parameter inference solely from voltage-time discharge curves across multiple batteries from the open-source CALCE repository, recovering the evolution of key internal state parameters such as Li-ion diffusion coefficients across usage cycles. Notably, the inferred cycle-dependent evolution of these parameters exhibit consistent trends across different batteries without any customized degradation physics-embedded heuristic, highlighting the effective regularizing effect and robustness that can be conferred through incorporation of fundamental physics in PINEAPPLE. By enabling computationally efficient, real-time parameter estimation, PINEAPPLE offers a promising route towards the non-destructive, physics-based characterization of inter-cell and intra-cell variability of battery modules and battery packs, thereby unlocking new opportunities for downstream on-the-fly needs in next-generation battery management systems such as individual cell-scale state-of-health diagnostics."}
{"id": "2602.18088", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.18088", "abs": "https://arxiv.org/abs/2602.18088", "authors": ["Igor Hołowacz", "Piotr Bródka"], "title": "Beyond Individual Influence: The Role of Echo Chambers and Community Seeding in the Multilayer three state q-Voter Model", "comment": "Preprint of the paper submitted to WAW 2026 - 21st Workshop on Modelling and Mining Networks", "summary": "The diffusion of complex opinions is severely hindered in multilayer social networks by echo chambers and cognitive consistency mechanisms. We investigate Influence Maximization strategies within the 3-state multilayer q-voter model. Utilizing the mABCD benchmark, we simulate social environments ranging from integrated Open Worlds to segregated Fortress Worlds. Our results reveal a topological paradox that we term the \"Fortress Trap\". In highly modular networks, strategies maximizing local density such as Clique Influence Maximization (CIM) and k-Shell fail to trigger global cascades, creating isolated bunkers of consensus due to the Overkill Effect. Furthermore, we identify a Redundancy Trap in perfectly aligned Clan topologies, where the structural overlap of layers creates a \"Perfect Prison,\" rendering it the most resistant environment to diffusion. We demonstrate that VoteRank, a strategy that prioritizes diversity of reach over local intensity, consistently outperforms structure-based methods. These findings suggest that, for complex contagion, maximizing topological entropy is more effective than reinforcing local clusters."}
{"id": "2602.17819", "categories": ["math.NA", "math.AP", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.17819", "abs": "https://arxiv.org/abs/2602.17819", "authors": ["Eric Lindström", "Larisa Beilina"], "title": "Variational optimization approach for reconstruction of dielectric permittivity and conductivity functions using partial boundary measurements", "comment": null, "summary": "We present a variational optimization approach for the solution of a coefficient inverse problem of simultaneous reconstruction of the dielectric permittivity and conductivity functions in time-dependent Maxwell's system using limited boundary observations of the electric field.\n  The variational optimization approach is based on constructing a weak form of a Lagrangian which allows to use finite element based reconstruction algorithms.\n  The optimality conditions for the Lagrangian and stability estimate for the adjoint problem are derived, as well as Frechét differentiability of it and of the regularized Tikhonov functional are also presented. Two- and three-dimensional numerical studies confirm our theoretical investigations."}
{"id": "2602.18213", "categories": ["cond-mat.str-el", "cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.18213", "abs": "https://arxiv.org/abs/2602.18213", "authors": ["Gia-Wei Chern", "Yunhao Fan", "Sheng Zhang", "Puhan Zhang"], "title": "Machine-learning force-field models for dynamical simulations of metallic magnets", "comment": "9 pages, 5 figures", "summary": "We review recent advances in machine learning (ML) force-field methods for Landau-Lifshitz-Gilbert (LLG) simulations of itinerant electron magnets, focusing on scalability and transferability. Built on the principle of locality, a deep neural network model is developed to efficiently and accurately predict the electron-mediated forces governing spin dynamics. Symmetry-aware descriptors constructed through a group-theoretical approach ensure rigorous incorporation of both lattice and spin-rotation symmetries. The framework is demonstrated using the prototypical s-d exchange model widely employed in spintronics. ML-enabled large-scale simulations reveal novel nonequilibrium phenomena, including anomalous coarsening of tetrahedral spin order on the triangular lattice and the freezing of phase separation dynamics in lightly hole-doped, strong-coupling square-lattice systems. These results establish ML force-field frameworks as scalable, accurate, and versatile tools for modeling nonequilibrium spin dynamics in itinerant magnets."}
{"id": "2602.17792", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.17792", "abs": "https://arxiv.org/abs/2602.17792", "authors": ["Isaque Vieira Machado Pim", "Luiz Max Fagundes de Carvalho", "Marcos Oliveira Prates"], "title": "Spatial Confounding: A review of concepts, challenges, and current approaches", "comment": "34 pages, 4 figures", "summary": "Spatial confounding is a persistent challenge in spatial statistics, influencing the validity of statistical inference in models that analyze spatially-structured data. The concept has been interpreted in various ways but is broadly defined as bias in estimates arising from unmeasured spatial variation. In this paper we review definitions, classical spatial models, and recent methodological advances, including approaches from spatial statistics and causal inference. We provide an unified view of the many available approaches for areal as well as geostatistical data and discuss their relative merits both theoretically and empirically with a head-to-head comparison on real datasets. Finally, we leverage the results of the empirical comparisons to discuss directions for future research."}
{"id": "2602.17890", "categories": ["q-fin.CP"], "pdf": "https://arxiv.org/pdf/2602.17890", "abs": "https://arxiv.org/abs/2602.17890", "authors": ["Krishna Neupane"], "title": "The Information Dynamics of Insider Intent: How Reporting Inversions (Form 144) Mask Informational Rents in Insider Sales (Form 4)", "comment": null, "summary": "This study identifies and quantifies a significant informational friction embedded in the SEC Form 144 disclosure regime, characterized as predictive decoupling. Drawing on a theoretical foundation of welfare economics, the article argues that the current reporting inversion -- where trade execution (Form 4) frequently precedes the public notice of intent (Form 144) -- violates the conditions for Pareto efficiency by inducing non-symmetric pricing. Utilizing an event-study framework of intent-to-sell windows, the analysis examines cases where insiders file a notice of proposed sale but fail to execute within the statutory 90-day period. The machine learning audit reveals a persistent 52.4 percent opacity rate, where aborted signals remain statistically indistinguishable from routine executions, creating a structural information ceiling that prevents the market from exhausting the signal's informational content. Contrary to the traditional small-firm effect, the study documents a large-cap significance paradox: while small-cap portfolios yield higher absolute abnormal returns (32.21 bps), statistically significant alpha is concentrated in large-cap firms (14.49 bps, $p = 0.021$). The results suggest that Institutional Salience enables more reliable processing of this negative non-event when reputational costs are maximized. Cross-sectional tests confirm that prior idiosyncratic volatility serves as a signal amplifier, with causal estimators identifying an illiquidity jump of up to 2.63 times. To mitigate this market failure, the study proposes a mandatory execution confirmation (Form 144-A) to transition the regime toward bilateral accountability, converting a predictive blind spot into a verifiable data stream and restoring the informational symmetry requisite for efficient capital allocation."}
{"id": "2602.17877", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.17877", "abs": "https://arxiv.org/abs/2602.17877", "authors": ["Markus Heinrichs", "Aydin Sezgin", "Rainer Kronberger"], "title": "A Scalable Reconfigurable Intelligent Surface with 3 Bit Phase Resolution and High Bandwidth for 3.6 GHz 5G/6G Applications", "comment": null, "summary": "Reconfigurable Intelligent Surfaces enable active control of wireless propagation channels, which is crucial for future 5G and 6G networks. This work presents a scalable RIS design operating at 3.6 GHz with both 1 bit and 3 bit phase resolution, supporting wideband applications. The unit cells employ low-cost printed circuit board technology with an innovative spring-contact feeding structure, enabling efficient assembly and reduced manufacturing complexity for large-area arrays. The design achieves broadband phase control, low power consumption, and high scalability, with experimental results demonstrating phase tunability across the n78 frequency band and competitive reflection performance compared to existing solutions. This RIS architecture provides a practical platform for experimental studies of smart radio environments, beam steering, and sensing applications in next-generation wireless networks."}
{"id": "2602.17877", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.17877", "abs": "https://arxiv.org/abs/2602.17877", "authors": ["Markus Heinrichs", "Aydin Sezgin", "Rainer Kronberger"], "title": "A Scalable Reconfigurable Intelligent Surface with 3 Bit Phase Resolution and High Bandwidth for 3.6 GHz 5G/6G Applications", "comment": null, "summary": "Reconfigurable Intelligent Surfaces enable active control of wireless propagation channels, which is crucial for future 5G and 6G networks. This work presents a scalable RIS design operating at 3.6 GHz with both 1 bit and 3 bit phase resolution, supporting wideband applications. The unit cells employ low-cost printed circuit board technology with an innovative spring-contact feeding structure, enabling efficient assembly and reduced manufacturing complexity for large-area arrays. The design achieves broadband phase control, low power consumption, and high scalability, with experimental results demonstrating phase tunability across the n78 frequency band and competitive reflection performance compared to existing solutions. This RIS architecture provides a practical platform for experimental studies of smart radio environments, beam steering, and sensing applications in next-generation wireless networks."}
{"id": "2602.18091", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2602.18091", "abs": "https://arxiv.org/abs/2602.18091", "authors": ["Filippo Faedi", "Erik Kalz", "Ralf Metzler", "Abhinav Sharma"], "title": "A mobility based approach to transport in chiral fluids", "comment": null, "summary": "Chiral fluids, for which the mobility tensor has antisymmetric, off-diagonal components, exhibit transport phenomena absent in conventional systems, including interaction-enhanced diffusion and negative mobility. While these effects have been predicted theoretically and observed in simulations, their microscopic origin has remained unclear. Here, we address this question using a mobility-based nonequilibrium approach, analysing the steady-state drift of a tracer driven through an interacting chiral fluid. We show that, under strong chirality, the tracer generates a reversed density wake, in which regions of particle accumulation and depletion are inverted compared to the achiral case. This structural inversion of the wake provides a unified physical mechanism underlying both enhanced diffusion and negative mobility. Furthermore, we demonstrate that these phenomena are robust to changes in the interaction potential, highlighting their generality as a consequence of odd mobility."}
{"id": "2602.17765", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2602.17765", "abs": "https://arxiv.org/abs/2602.17765", "authors": ["Dominik Nemeth", "Ahsan Nazir", "Alessandro Principi", "Robert-Jan Slager"], "title": "Topological Boundary Time Crystal Oscillations", "comment": "12 pages, 7 figures", "summary": "Boundary time crystals (BTCs) break time-translation symmetry and exhibit long-lived, robust oscillations insensitive to initial conditions. We show that collective spin BTCs can admit emergent topological winding numbers in operator space. Expanding the density operator in a spherical tensor basis, we map the Lindblad dynamics onto an effective local hopping problem, where collective degrees of freedom label sites of an emergent two-dimensional operator space lattice and identify topological obstructions that enforce the delocalization of operator modes on the lattice. The resulting spectral delocalization provides a natural explanation for the robust oscillatory dynamics observed in BTCs. When combined with non-reciprocal transport of operator weight across operator space, this mechanism moreover also leads to the universality of long-time dynamics across a broad class of initial states. Our results frame BTC dynamics as a form of topologically constrained operator space transport and suggest a close connection to non-Hermitian skin-effects."}
{"id": "2602.17967", "categories": ["math.ST", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17967", "abs": "https://arxiv.org/abs/2602.17967", "authors": ["Hanxiao Chen", "Debarghya Mukherjee"], "title": "Minimax optimal adaptive structured transfer learning through semi-parametric domain-varying coefficient model", "comment": "86 pages, 8 figures", "summary": "Transfer learning aims to improve inference in a target domain by leveraging information from related source domains, but its effectiveness critically depends on how cross-domain heterogeneity is modeled and controlled. When the conditional mechanism linking covariates and responses varies across domains, indiscriminate information pooling can lead to negative transfer, degrading performance relative to target-only estimation. We study a multi-source, single-target transfer learning problem under conditional distributional drift and propose a semiparametric domain-varying coefficient model (DVCM), in which domain-relatedness is encoded through an observable domain identifier. This framework generalizes classical varying-coefficient models to structured transfer learning and interpolates between invariant and fully heterogeneous regimes. Building on this model, we develop an adaptive transfer learning estimator that selectively borrows strength from informative source domains while provably safeguarding against negative transfer. Our estimator is computationally efficient and easy to implement; we also show that it is minimax rate-optimal and derive its asymptotic distribution, enabling valid uncertainty quantification and hypothesis testing despite data-adaptive pooling and shrinkage. Our results precisely characterize the interplay among domain heterogeneity, the smoothness of the underlying mean function, and the number of source domains and are corroborated by comprehensive numerical experiments and two real-data applications."}
{"id": "2602.18399", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.18399", "abs": "https://arxiv.org/abs/2602.18399", "authors": ["Silvio Franz", "Giorgio Parisi", "Federico Ricci-Tersenghi"], "title": "Overlap locking and non-perturbative effects in spin glasses", "comment": "15 pages, 9 figures, submitted to PNAS", "summary": "We study the phenomenon of the locking of the order parameter (or synchronization) in spin glasses at low temperatures. When two systems with independent disorders are coupled, their overlaps become similar. A crucial question is how this effect depends on the strength of the coupling between the two systems. Non-perturbative phenomena are present when $1 \\ll ΔH \\ll N$, being $ΔH$ the coupling Hamiltonian and $N$ the size of the system. In this intermediate-coupling region, the effect is related to finite-size free-energy corrections and to the correlations in the Dyson hierarchical spin glass, a model that mimics the physics of finite-dimensional systems. We study this phenomenon in the mean-field approach, both analytically and numerically, and we finally compute the critical exponents for finite-volume corrections in mean-field theory and for the decay of correlations in the Dyson hierarchical model."}
{"id": "2602.18080", "categories": ["hep-lat", "cond-mat.str-el", "hep-th", "nucl-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18080", "abs": "https://arxiv.org/abs/2602.18080", "authors": ["Fran Ilčić", "Ritajit Majumdar", "Emil Mathew", "Nathan Earnest-Noble", "Indrakshi Raychowdhury"], "title": "Observation of Robust and Coherent Non-Abelian Hadron Dynamics on Noisy Quantum Processors", "comment": "19 pages, 13 figres including supplementary information", "summary": "The real-time evolution of strongly interacting matter remains a frontier of fundamental physics, as classical simulations are hampered by exponential Hilbert space growth and entanglement-driven bottlenecks in tensor networks. This study reports the quantum simulation of hadron dynamics within a $(1+1)$-dimensional SU(2) lattice gauge theory using a 156-qubit IBM superconducting processor. Leveraging a hardware-efficient Loop-String-Hadron (LSH) encoding, we simulate the dynamics of the physical degrees of freedom on a $60$-site lattice in the weak-coupling regime, as a crucial step toward the continuum limit. We successfully observe the light-cone propagation of a confined meson and internal oscillations indicative of early-time hadronic breathing modes. Notably, these high-fidelity results were obtained directly from the quantum data via a differential measurement protocol, together with measurement error mitigation, demonstrating a robust pathway for large-scale simulations even on noisy hardware. To validate the results, we benchmarked the quantum algorithm and outcome from the quantum processor against state-of-the-art approximated classical algorithms using CPU -- based on tensor network methods and Pauli propagation method, respectively. Furthermore, we provide a quantitative comparison demonstrating that as the system approaches the weak-coupling or the continuum limit, the quantum processor maintains a consistent structural robustness where classical tensor networks and Pauli propagation methods encounter an onset of exponential complexity or symmetry violations as an artifact of approximation in the algorithm. These results establish a scalable pathway for simulating non-Abelian dynamics on near-term quantum hardware and mark a critical step toward achieving a practical quantum advantage in high-energy physics."}
{"id": "2602.17795", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.17795", "abs": "https://arxiv.org/abs/2602.17795", "authors": ["Vsevolod Ivanov Ivanov"], "title": "Optimality conditions via exact penalty functions", "comment": "10 pages", "summary": "In this paper, we obtain optimality conditions for the problem with inequality, equality and closed set constraints in terms of the lower Hadamard derivative. The results are obtained applying exact penalty functions."}
{"id": "2602.18229", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.18229", "abs": "https://arxiv.org/abs/2602.18229", "authors": ["Jing Guo", "Pengyu Wang", "Cheng Huang", "Chengkang Zhou", "Menghan Song", "Xintian Chen", "Ting-Tung Wang", "Wenshan Hong", "Shu Cai", "Jinyu Zhao", "Jinyu Han", "Yazhou Zhou", "Qi Wu", "Shiliang Li", "Zi Yang Meng", "Liling Sun"], "title": "T-linear specific heat in pressurized and magnetized Shastry-Sutherland Mott insulator SrCu2(BO3)2", "comment": "20 pages, 4 figures", "summary": "The pressurized Shastry-Sutherland Mott insulator SrCu2(BO3)2 has been found to host a plaquette-singlet phase and an antiferromagnetic phase that break different symmetries spontaneously.The recent experiment showed that their transition is of a first order nature, which seems against the pursuit of exotic and deconfined degrees of freedom in this famous frustrated quantum magnet. We found a new direction in this study. By applying a magnetic field to the material, we discover that SrCu2(BO3)2 exhibits a universal and metallic T-linear specific heat behavior in a large magnetitic field range close to the pressure of zero-field first order transition between plaquette-singlet and antiferromagnetic phases. Such an unexpected gapless response from an electronically gapped Mott insulator could be attributed to magnetized Dirac spinons liberated by the combined effect of magnetic field and pressure, consistently seen from our quantum many-body thermal tensor network computation of the Shastry-Sutherland model under magnetic field. Such a robust and universal T-linear specific heat phase points out the richness of the phase diagram of the material expanded by the axes of pressure and magnetic field and is calling for new theoretical frameworks to its full explanation."}
{"id": "2602.17836", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.17836", "abs": "https://arxiv.org/abs/2602.17836", "authors": ["Bonaventure Nana", "Krystian Polczyński", "Paul Woafo", "Jan Awrejcewicz"], "title": "Nonlinear dynamics of a vertical pendulum driven by magnetic field provided by two coils magnets: analytical, numerical and experimental studies", "comment": "25 pages, 21 figures", "summary": "In the present work, we analyzed theoretically and experimentally the nonlinear dynamics of a magnetic pendulum excited through the interactions of a strong neodymium magnet and two coils placed symmetrically around the zero angular position. The forces between the magnet and coils and generated torques acting on the pendulum are derived using the magnetic charges interaction model and an experimentally fitted model. System equilibrium points are obtained, and their stability is investigated. It is found that when the currents in two coils are negative, the shape of the mechanical potential is bistable. The bistable potential might be symmetric if the currents have the same values and asymmetric when they are different. Asymmetric bistable potential is observed when coil currents have different signs. However, in the case of positive coil currents, a symmetric tristable potential is detected when the currents are the same, and an asymmetric tristable potential takes place when the positive currents have different values. Considering the sinusoidal coil current signals, analytical calculations using the harmonic balance method and numerical simulations are carried out for this electric-magneto-mechanical system. The obtained results are shown in terms of frequency-response diagrams, displacement time series, and phase portraits. The two-parameter bifurcation diagrams are plotted showing the different dynamical behaviors considering the current amplitudes and frequency as the control parameters. Amplitude jumps, hysteresis, and multistability are also observed. Some phase portraits and the coexistence of attractors are obtained numerically and confirmed experimentally. A good agreement between the numerical simulation and experimental measurement is achieved."}
{"id": "2602.18130", "categories": ["cs.CE", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.18130", "abs": "https://arxiv.org/abs/2602.18130", "authors": ["Michael Loibl", "Guilherme H. Teixeira", "Teoman Toprak", "Irina Shishkina", "Chen Miao", "Josef Kiendl", "Florian Kummer", "Benjamin Marussig"], "title": "Comparative study of different quadrature methods for cut elements", "comment": "preprint; in journal review process", "summary": "The quadrature of cut elements is crucial for all Finite Element Methods that do not apply boundary-fitted meshes. It should be efficient, accurate, and robust. Various approaches balancing these requirements have been published, with some available as open-source implementations. This work reviews these open-sources codes and the methods used. Furthermore, benchmarking examples are developed for 2D and 3D geometries. Implicit and explicit boundary descriptions are available for all models. The different examples test the efficiency, accuracy, versatility, and robustness of the codes. Special focus is set on the influence of the input parameter, which controls the desired quadrature order, on the actual integration error. A detailed comparison of the discussed codes is carried out. The benchmarking allows a conclusive comparison and presents a valuable tool for future code development. All tests are published in an accompanying open-source repository."}
{"id": "2602.17843", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.17843", "abs": "https://arxiv.org/abs/2602.17843", "authors": ["Sarah Nataj", "David C. Del Rey Fernández", "David Brown", "Rajeev Jaiman"], "title": "A finite-difference summation-by-parts, conditionally stable partitioned algorithm for conjugate heat transfer problems", "comment": null, "summary": "In this work, we design and analyze a novel, provably conditionally stable, weakly coupled partitioned scheme to solve the conjugate heat transfer (CHT) problem. We consider a model CHT problem consisting of linear advection-diffusion and heat equations, coupled at an interface through continuity of temperature and heat flux. We employ high-order summation-by-parts finite-difference operators in conjunction with simultaneous-approximation-terms (SATs) in curvilinear coordinates for spatial derivatives, combined with first- and second-order time discretizations and temporal extrapolation at the interface. Energy stability is maintained by carefully selecting SAT parameters at the interface. A range of coupling parameters are explored to identify those that yield a stable scheme, and a stepwise approach for choosing SAT parameters that ensure stability is given. The effectiveness of the method is demonstrated through numerical experiments in a two-dimensional model problem on a rectangular domain with curvilinear grids. The proposed approach enables the development of high-order, conditionally stable partitioned solvers suitable for general geometries."}
{"id": "2602.17923", "categories": ["stat.ME", "math.NA", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.17923", "abs": "https://arxiv.org/abs/2602.17923", "authors": ["Mridula Kuppa", "Khachik Sargsyan", "Marco Panesi", "Habib N. Najm"], "title": "Model Error Embedding with Orthogonal Gaussian Processes", "comment": "30 pages, 26 figures", "summary": "Computational models of complex physical systems often rely on simplifying assumptions which inevitably introduce model error, with consequent predictive errors. Given data on model observables, the estimation of parameterized model-error representations, along with other model parameters, would be ideally done while separating the contributions of each of the two sets of parameters, in order to ensure meaningful stand-alone model predictions. This work builds an embedded model error framework using a weight-space representation of Gaussian processes (GPs) to flexibly capture model-error spatiotemporal correlations and enable inference with GP-embedding in non-linear models. To disambiguate model and model-error/bias parameters, we extend an existing orthogonal GP method to the embedded model-error setting and derive appropriate orthogonality constraints. To address the increased dimensionality introduced by the GP representation, we employ the likelihood-informed subspace method. The construction is demonstrated on linear and non-linear examples, where it effectively corrects model predictions to match data trends. Extrapolation beyond the training data recovers the prior predictive distribution, and the orthogonality constraints lead to meaningful stand-alone model predictions and nearly uncorrelated posteriors between model and model-error parameters."}
{"id": "2602.17895", "categories": ["q-fin.CP", "q-fin.GN"], "pdf": "https://arxiv.org/pdf/2602.17895", "abs": "https://arxiv.org/abs/2602.17895", "authors": ["Krishna Neupane"], "title": "The Strategic Gap: How AI-Driven Timing and Complexity Shape Investor Trust in the Age of Digital Agents", "comment": null, "summary": "Traditional models of market efficiency assume that equity prices incorporate information based on content alone, often neglecting the structural influence of reporting timing and cadence. This study introduces the Autonomous Disclosure Regulator, a multi-node AI framework designed to audit the intersection of disclosure complexity and filing unpredictability. Analyzing a population of 484,796 regulatory filings, the research identifies a structural Strategic Gap: a state where companies use confusing language and unpredictable timing to slow down how fast the market learns the truth by 60%. The results demonstrate a fundamental computational asymmetry in contemporary capital markets. While investors are now good at spotting \"copy-paste\" text, they remain vulnerable to strategic timing that obscures structural deterioration. The framework isolates 39 high-priority failures where the convergence of dense text and temporal surprises facilitated significant information rent extraction by insiders. By implementing a recursive agentic audit, the system identifies a cumulative welfare recovery potential of over 360\\% and demonstrates near-perfect resilience against technical data interruptions. The study concludes by proposing a transition toward an agentic regulatory state, arguing that as information integration costss rise, infrastructure must evolve from passive data repositories into active auditing nodes capable of real-time synthesis to preserve market integrity."}
{"id": "2602.18031", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18031", "abs": "https://arxiv.org/abs/2602.18031", "authors": ["Yan Chen", "Ruyi Huang", "Cheng Liu"], "title": "Decision Support under Prediction-Induced Censoring", "comment": null, "summary": "In many data-driven online decision systems, actions determine not only operational costs but also the data availability for future learning -- a phenomenon termed Prediction-Induced Censoring (PIC). This challenge is particularly acute in large-scale resource allocation for generative AI (GenAI) serving: insufficient capacity triggers shortages but hides the true demand, leaving the system with only a \"greater-than\" constraint. Standard decision-making approaches that rely on uncensored data suffer from selection bias, often locking the system into a self-reinforcing low-provisioning trap. To break this loop, this paper proposes an adaptive approach named PIC-Reinforcement Learning (PIC-RL), a closed-loop framework that transforms censoring from a data quality problem into a decision signal. PIC-RL integrates (1) Uncertainty-Aware Demand Prediction to manage the information-cost trade-off, (2) Pessimistic Surrogate Inference to construct decision-aligned conservative feedback from shortage events, and (3) Dual-Timescale Adaptation to stabilize online learning against distribution drift. The analysis provides theoretical guarantees that the feedback design corrects the selection bias inherent in naive learning. Experiments on production Alibaba GenAI traces demonstrate that PIC-RL consistently outperforms state-of-the-art baselines, reducing service degradation by up to 50% while maintaining cost efficiency."}
{"id": "2602.18031", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18031", "abs": "https://arxiv.org/abs/2602.18031", "authors": ["Yan Chen", "Ruyi Huang", "Cheng Liu"], "title": "Decision Support under Prediction-Induced Censoring", "comment": null, "summary": "In many data-driven online decision systems, actions determine not only operational costs but also the data availability for future learning -- a phenomenon termed Prediction-Induced Censoring (PIC). This challenge is particularly acute in large-scale resource allocation for generative AI (GenAI) serving: insufficient capacity triggers shortages but hides the true demand, leaving the system with only a \"greater-than\" constraint. Standard decision-making approaches that rely on uncensored data suffer from selection bias, often locking the system into a self-reinforcing low-provisioning trap. To break this loop, this paper proposes an adaptive approach named PIC-Reinforcement Learning (PIC-RL), a closed-loop framework that transforms censoring from a data quality problem into a decision signal. PIC-RL integrates (1) Uncertainty-Aware Demand Prediction to manage the information-cost trade-off, (2) Pessimistic Surrogate Inference to construct decision-aligned conservative feedback from shortage events, and (3) Dual-Timescale Adaptation to stabilize online learning against distribution drift. The analysis provides theoretical guarantees that the feedback design corrects the selection bias inherent in naive learning. Experiments on production Alibaba GenAI traces demonstrate that PIC-RL consistently outperforms state-of-the-art baselines, reducing service degradation by up to 50% while maintaining cost efficiency."}
{"id": "2602.18099", "categories": ["cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18099", "abs": "https://arxiv.org/abs/2602.18099", "authors": ["Gioele Zambotti", "Erik Tonni"], "title": "A contour for the entanglement negativity of bosonic Gaussian states", "comment": "62 pages, 14 figures", "summary": "We construct a contour function for the logarithmic negativity and the logarithm of the moments of the partial transpose of the reduced density matrix for multimode bosonic Gaussian states of a free lattice model. In one spatial dimension, numerical results are obtained for harmonic chains either in the ground state or at finite temperature, by considering, respectively, either a subsystem made by two adjacent or disjoint blocks on the line or a bipartition of the circle. The contour function of the logarithmic negativity diverges only at the entangling points, while the contour function for the logarithm of the moments of the partial transpose is divergent also at the boundary of the bipartite subsystem, as functions of the position. In a two-dimensional conformal field theory, analytic expressions that describe these divergencies are discussed. In one spatial dimension, we explore the partial derivative of the logarithmic negativity of two adjacent intervals with respect to the logarithm of the harmonic ratio of their lengths while their ratio and the other parameters are kept fixed. Considering the ground state of the harmonic chain on the line and in the massive regime, we report numerical results showing that this quantity displays a monotonically decreasing behaviour."}
{"id": "2602.17775", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.17775", "abs": "https://arxiv.org/abs/2602.17775", "authors": ["Arend-Jan Quist", "Tim Coopmans", "Alfons Laarman"], "title": "Exact quantum decision diagrams with scaling guarantees for Clifford+$T$ circuits and beyond", "comment": null, "summary": "A decision diagram (DD) is a graph-like data structure for homomorphic compression of Boolean and pseudo-Boolean functions. Over the past decades, decision diagrams have been successfully applied to verification, linear algebra, stochastic reasoning, and quantum circuit analysis. Floating-point errors have, however, significantly slowed down practical implementations of real- and complex-valued decision diagrams. In the context of quantum computing, attempts to mitigate this numerical instability have thus far lacked theoretical scaling guarantees and have had only limited success in practice. Here, we focus on the analysis of quantum circuits consisting of Clifford gates and $T$ gates (a common universal gate set). We first hand-craft an algebraic representation for complex numbers, which replace the floating point coefficients in a decision diagram. Then, we prove that the sizes of these algebraic representations are linearly bounded in the number of $T$ gates and qubits, and constant in the number of Clifford gates. Furthermore, we prove that both the runtime and the number of nodes of decision diagrams are upper bounded as $2^t \\cdot poly(g, n)$, where $t$ ($g$) is the number of $t$ gates (Clifford gates) and $n$ the number of qubits. Our proofs are based on a $T$-count dependent characterization of the density matrix entries of quantum states produced by circuits with Clifford+$T$ gates, and uncover a connection between a quantum state's stabilizer nullity and its decision diagram width. With an open source implementation, we demonstrate that our exact method resolves the inaccuracies occurring in floating-point-based counterparts and can outperform them due to lower node counts. Our contributions are, to the best of our knowledge, the first scaling guarantees on the runtime of (exact) quantum decision diagram simulation for a universal gate set."}
{"id": "2602.18184", "categories": ["math.ST", "math.PR", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.18184", "abs": "https://arxiv.org/abs/2602.18184", "authors": ["Aristides V. Doumas", "S. Spektor"], "title": "Kolmogorov-Type Maximal Inequalities for Independent and Dependent Negative Binomial Random Variables: Sharp Bounds, Sub-Exponential Refinements, and Applications to Overdispersed Count Data", "comment": "11 pages, 8 figures, 2 tables", "summary": "This paper develops Kolmogorov-type maximal inequalities for sums of Negative Binomial random variables under both independence and dependence structures. For independent heterogeneous Negative Binomial variables we derive sharp Markov-type deviation inequalities and Kolmogorov-type bounds expressed in terms of Tweedie dispersion parameters, providing explicit control limits for NB2 generalized linear model monitoring. For dependent count data arising through a shared Gamma mixing variable, we establish a \\emph{sub-exponential Bernstein-type refinement} that exploits the Poisson-Gamma hierarchical structure to yield exponentially decaying tail probabilities -- this refinement is new in the literature. Through moment-matched Monte Carlo experiments ($n=20$, 2{,}000 replications), we document a 55\\% reduction in mean maximum deviation under appropriate dependence structures, a stabilization effect we explain analytically. A concrete epidemiological application with NB2 parameters calibrated from COVID-19 surveillance data demonstrates practical utility. These results materially advance the applicability of classical maximal inequalities to overdispersed and dependent count data prevalent in public health, insurance, and ecological modeling."}
{"id": "2602.18419", "categories": ["cond-mat.dis-nn", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18419", "abs": "https://arxiv.org/abs/2602.18419", "authors": ["Geri Skenderi", "Lorenzo Buffoni", "Francesco D'Amico", "David Machado", "Raffaele Marino", "Matteo Negri", "Federico Ricci-Tersenghi", "Carlo Lucibello", "Maria Chiara Angelini"], "title": "Benchmarking Graph Neural Networks in Solving Hard Constraint Satisfaction Problems", "comment": null, "summary": "Graph neural networks (GNNs) are increasingly applied to hard optimization problems, often claiming superiority over classical heuristics. However, such claims risk being unsolid due to a lack of standard benchmarks on truly hard instances. From a statistical physics perspective, we propose new hard benchmarks based on random problems. We provide these benchmarks, along with performance results from both classical heuristics and GNNs. Our fair comparison shows that classical algorithms still outperform GNNs. We discuss the challenges for neural networks in this domain. Future claims of superiority can be made more robust using our benchmarks, available at https://github.com/ArtLabBocconi/RandCSPBench."}
{"id": "2602.18360", "categories": ["hep-lat", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.18360", "abs": "https://arxiv.org/abs/2602.18360", "authors": ["Sandip Maiti", "Debasish Banerjee", "Shailesh Chandrasekharan", "Marina K. Marinkovic"], "title": "Phase diagram of a lattice fermion model with symmetric mass generation", "comment": "19 pages, 12 figures, 4 tables", "summary": "We study the phase structure of a model containing two flavors of massless staggered fermions interacting through two independent four-fermion couplings, UI and UB, formulated on a three-dimensional Euclidean space-time lattice. At UB = 0, this model is known to exhibit a direct second-order quantum phase transition between a massless fermion (MF) phase and a phase in which fermions acquire masses through the mechanism commonly referred to as symmetric mass generation (SMG). We demonstrate that introducing a small nonzero value of UB qualitatively alters this structure: the single exotic transition at UB = 0 splits into two distinct, conventional transitions, separated by an intermediate phase in which fermion masses arise through the standard mechanism of spontaneous symmetry breaking (SSB). The first of these is a Gross-Neveu transition separating the MF phase from the SSB-induced massive phase, while the second is a three-dimensional XY transition between the SSB phase and the SMG phase. Using the fermion-bag Monte Carlo method, we verify that the critical exponents associated with both transitions are consistent with the literature, thereby yielding a quantitative characterization of the resulting phase structure of the model."}
{"id": "2602.17823", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.17823", "abs": "https://arxiv.org/abs/2602.17823", "authors": ["Peter Bank", "Filippo de Feo"], "title": "Duality methods in stochastic optimal control", "comment": null, "summary": "We prove two duality descriptions of the value function for a generic stochastic optimal problem. These descriptions also hold when the diffusion is controlled, a case left open by the literature so far."}
{"id": "2602.17839", "categories": ["cond-mat.stat-mech", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.17839", "abs": "https://arxiv.org/abs/2602.17839", "authors": ["Edson D. Leonel", "Diego F. M. Oliveira"], "title": "Scaling invariance: a bridge between geometry, dynamics and criticality", "comment": null, "summary": "Scale invariance is a central organizing principle in physics, underlying phenomena that range from critical behaviour in statistical mechanics to transport and chaos in nonlinear dynamical systems. Here we present a unified and physically motivated exploration of scaling concepts, emphasizing how invariance under rescaling transformations emerges across systems of increasing dynamical complexity. Rather than adopting a purely abstract approach, we combine simple geometrical constructions, analytical arguments, and prototypical dynamical models to build physical intuition. We begin with elementary, easily reproducible examples governed by a single control parameter, showing how power-law behaviour naturally arises when characteristic scales are absent. We then extend the discussion to nonlinear dynamical systems exhibiting local bifurcations, where two scaling variables control the relaxation toward stationary states. In this context, scaling invariance manifests through critical exponents, crossover phenomena, and critical slowing down, allowing systems of different dimensionality to be grouped into universality classes. Finally, we address continuous phase transitions in chaotic dynamical systems, including transitions from integrability to non-integrability and from bounded to unbounded diffusion. By drawing on concepts traditionally associated with statistical mechanics, such as order parameters, susceptibilities, symmetry breaking, elementary excitations, and topological defects, we show how these transitions can be interpreted within a coherent scaling framework. Taken together, the examples discussed here demonstrate that scaling invariance provides a unifying language for understanding structure, transport, and criticality in nonlinear systems, bridging deterministic dynamics and nonequilibrium statistical physics in a transparent and physically intuitive manner."}
{"id": "2602.18296", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.18296", "abs": "https://arxiv.org/abs/2602.18296", "authors": ["Muhammad Tayyab Khana", "Lequn Chen", "Wenhe Feng", "Seung Ki Moon"], "title": "Context-Aware Mapping of 2D Drawing Annotations to 3D CAD Features Using LLM-Assisted Reasoning for Manufacturing Automation", "comment": null, "summary": "Manufacturing automation in process planning, inspection planning, and digital-thread integration depends on a unified specification that binds the geometric features of a 3D CAD model to the geometric dimensioning and tolerancing (GD&T) callouts, datum definitions, and surface requirements carried by the corresponding 2D engineering drawing. Although Model-Based Definition (MBD) allows such specifications to be embedded directly in 3D models, 2D drawings remain the primary carrier of manufacturing intent in automotive, aerospace, shipbuilding, and heavy-machinery industries. Correctly linking drawing annotations to the corresponding 3D features is difficult because of contextual ambiguity, repeated feature patterns, and the need for transparent and traceable decisions. This paper presents a deterministic-first, context-aware framework that maps 2D drawing entities to 3D CAD features to produce a unified manufacturing specification. Drawing callouts are first semantically enriched and then scored against candidate features using an interpretable metric that combines type compatibility, tolerance-aware dimensional agreement, and conservative context consistency, along with engineering-domain heuristics. When deterministic scoring cannot resolve an ambiguity, the system escalates to multimodal and constrained large-language-model reasoning, followed by a single human-in-the-loop (HITL) review step. Experiments on 20 real CAD-drawing pairs achieve a mean precision of 83.67%, recall of 90.46%, and F1 score of 86.29%. An ablation study shows that each pipeline component contributes to overall accuracy, with the full system outperforming all reduced variants. By prioritizing deterministic rules, clear decision tracking, and retaining unresolved cases for human review, the framework provides a practical foundation for downstream manufacturing automation in real-world industrial environments."}
{"id": "2602.17892", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.17892", "abs": "https://arxiv.org/abs/2602.17892", "authors": ["Ryan Bentley", "Mirjeta Pasha", "Malena Sabaté Landman", "Luisa Yang", "Jeffery Zhang"], "title": "Hybrid ABBA-GMRES for Unmatched Backprojectors in Large Scale X-Ray Computerized Tomography", "comment": "10 pages, 5 figures, Code available at: https://github.com/rbentley5/Hybrid-ABBA-GMRES-Toolbox", "summary": "In large-scale X-ray computed tomography (CT), matrix-free iterative methods are essential due to the prohibitive cost of explicitly forming the system matrix. In practice, forward projectors and backprojectors are often implemented with different discretizations or accelerations, leading to unmatched projector pairs. This mismatch violates the adjointness assumptions underlying classical least-squares solvers, so the resulting iterations no longer correspond to a true least-squares problem and can exhibit non-symmetric or inconsistent behavior. Prior work has explored Krylov subspace solvers such as AB-GMRES and BA-GMRES to handle unmatched projector pairs, where these methods exhibit semi-convergent regularizing behavior. Under matched conditions, AB-GMRES and BA-GMRES reduce to LSQR and LSMR, respectively. However, in the presence of unmatched projectors, AB- and BA-GMRES have been observed to yield improved reconstruction quality compared to classical least-squares solvers. In this paper, we develop hybrid AB- and BA-GMRES methods that incorporate Tikhonov regularization directly into the Krylov subspace iterations. We also examine the relationship between the proposed methods and hybrid variants of LSQR and LSMR, considering both matched and unmatched backprojectors. We propose automatic strategies for selecting regularization parameters, including approaches based on the L-curve and generalized cross validation (GCV), and analyze their effect on convergence behavior and image quality. Numerical experiments on two-dimensional CT problems using GPU-accelerated projectors demonstrate that the proposed hybrid AB- and BA-GMRES methods mitigate semi-convergence, produce higher-quality reconstructions, and exhibit more stable stopping behavior than their non-hybrid counterparts."}
{"id": "2602.17956", "categories": ["stat.ME", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.17956", "abs": "https://arxiv.org/abs/2602.17956", "authors": ["Tâm LeMinh", "Julyan Arbel", "Florence Forbes", "Hien Duy Nguyen"], "title": "A variational framework for modal estimation", "comment": null, "summary": "We approach multivariate mode estimation through Gibbs distributions and introduce GERVE (Gibbs-measure Entropy-Regularised Variational Estimation), a likelihood-free framework that approximates Gibbs measures directly from samples by maximizing an entropy-regularised variational objective with natural-gradient updates. GERVE brings together kernel density estimation, mean-shift, variational inference, and annealing in a single platform for mode estimation. It fits Gaussian mixtures that concentrate on high-density regions and yields cluster assignments from responsibilities, with reduced sensitivity to the chosen number of components. We provide theory in two regimes: as the Gibbs temperature approaches zero, mixture components converge to population modes; at fixed temperature, maximisers of the empirical objective exist, are consistent, and are asymptotically normal. We also propose a bootstrap procedure for per-mode confidence ellipses and stability scores. Simulation and real-data studies show accurate mode recovery and emergent clustering, robust to mixture overspecification. GERVE is a practical likelihood-free approach when the number of modes or groups is unknown and full density estimation is impractical."}
{"id": "2602.18062", "categories": ["q-fin.CP", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2602.18062", "abs": "https://arxiv.org/abs/2602.18062", "authors": ["Daniel Chee", "Noufel Frikha", "Libo Li"], "title": "A Monotone Limit Approach to Entropy-Regularized American Options", "comment": null, "summary": "Recent advances in continuous-time optimal stopping have been driven by entropy-regularized formulations of randomized stopping problems, with most existing approaches relying on partial differential equation methods. In this paper, we propose a fully probabilistic framework based on the Doob-Meyer-Mertens decomposition of the Snell envelope and its representation through reflected backward stochastic differential equations. We introduce an entropy-regularized penalization scheme yielding a monotone approximation of the value function and establish explicit convergence rates under suitable regularity assumptions. In addition, we develop a policy improvement algorithm based on linear backward stochastic differential equations and illustrate its performance through a simple numerical experiment for an American-style max call option"}
{"id": "2602.18048", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18048", "abs": "https://arxiv.org/abs/2602.18048", "authors": ["N. Naveen Mukesh", "Debraj Chakraborty"], "title": "Incremental Data Driven Transfer Identification", "comment": "15 Pages, 7 figures", "summary": "We introduce a geometric method for online transfer identification of a deterministic linear time-invariant system. At the beginning of the identification process, we assume access to abundant data from a system that is similar, though not identical, to the true system. In the early stages of data collection from the true system, the dataset generated is still not sufficiently informative to enable precise identification. Consequently, multiple candidate models remain consistent with the observations available at that point. Our method picks, at each instant, the model closest to the similar system that is consistent with the current data. As more data are collected, the proposed model gradually moves away from the initial similar system and eventually converges to the true system when the data set grows to be informative. Numerical examples demonstrate the effectiveness of the incremental transfer identification paradigm, where identified models with minimal data are used to solve the pole placement problem."}
{"id": "2602.18048", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18048", "abs": "https://arxiv.org/abs/2602.18048", "authors": ["N. Naveen Mukesh", "Debraj Chakraborty"], "title": "Incremental Data Driven Transfer Identification", "comment": "15 Pages, 7 figures", "summary": "We introduce a geometric method for online transfer identification of a deterministic linear time-invariant system. At the beginning of the identification process, we assume access to abundant data from a system that is similar, though not identical, to the true system. In the early stages of data collection from the true system, the dataset generated is still not sufficiently informative to enable precise identification. Consequently, multiple candidate models remain consistent with the observations available at that point. Our method picks, at each instant, the model closest to the similar system that is consistent with the current data. As more data are collected, the proposed model gradually moves away from the initial similar system and eventually converges to the true system when the data set grows to be informative. Numerical examples demonstrate the effectiveness of the incremental transfer identification paradigm, where identified models with minimal data are used to solve the pole placement problem."}
{"id": "2602.18265", "categories": ["cond-mat.stat-mech", "physics.bio-ph", "q-bio.MN"], "pdf": "https://arxiv.org/pdf/2602.18265", "abs": "https://arxiv.org/abs/2602.18265", "authors": ["Julian B. Voits", "Ulrich S. Schwarz"], "title": "Emergence of generic first-passage time distributions for large Markovian networks", "comment": "15 pages, 7 figures, mathematical supplement with one additional figure", "summary": "First-passage times are often the most relevant aspect of a complex Markovian network, because they signify when information processing has resulted in a definite decision. Previous studies have shown that for kinetic proofreading networks in the limit of large network size the first-passage time distribution converges either to a delta or to an exponential distribution. Remarkably, these two forms correspond to the two extreme distributions of minimal and maximal entropy for a fixed mean, respectively. Here we build on the connection between first-passage times and graph theory to show that these two limits are not model-specific, but arise generically in Markovian networks from the distribution of the eigenvalues of the generator matrix. A deterministic peak emerges when infinitely many eigenvalues contribute, while the exponential limit arises from a single dominant eigenvalue. We also show that the exponential limit emerges robustly for reversible networks when a backward bias exists. In contrast, the deterministic limit is not obtained from a simple reversal of this condition, but under structurally tighter conditions, revealing a fundamental asymmetry between both regimes. Our theoretical analysis is illustrated and validated by computer simulations of one-step master equations and random networks."}
{"id": "2602.17786", "categories": ["quant-ph", "cond-mat.other", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2602.17786", "abs": "https://arxiv.org/abs/2602.17786", "authors": ["Adolfo del Campo"], "title": "Shortcuts to Adiabaticity via Adaptive Quantum Zeno Measurements", "comment": "6+2pp", "summary": "We consider the quantum Zeno dynamics arising from monitoring a time-dependent projector. Starting from a stroboscopic measurement protocol, it is shown that the effective Hamiltonian for Zeno dynamics involves a nonadiabatic geometric connection that takes the form of the Kato-Avron Hamiltonian for parallel transport, stirring the evolution within the time-dependent Zeno subspace. The latter reduces to counterdiabatic driving when projective measurements are performed in the instantaneous energy eigenbasis of the quantum system. The effective Zeno Hamiltonian can also be derived in the context of continuous quantum measurements of a time-dependent observable and the non-Hermitian evolution with a complex absorbing potential varying in time. Our results thus provide a unified framework for realizing shortcuts to adiabaticity via adaptive quantum Zeno measurements."}
{"id": "2602.18214", "categories": ["math.ST", "math-ph", "math.SP"], "pdf": "https://arxiv.org/pdf/2602.18214", "abs": "https://arxiv.org/abs/2602.18214", "authors": ["Max Kämper", "Christoph Schumacher", "Fabian Schwarzenberger", "Ivan Veselic"], "title": "Quantitative concentration inequalities for the uniform approximation of the IDS", "comment": null, "summary": "The integrated density of states (IDS) is a fundamental spectral quantity for quantum Hamiltonians modeling condensed matter systems, describing how densely energy levels are distributed. It can be interpreted as a volume-averaged spectral distribution. Hence, there are two equivalent definitions of the IDS related by the Pastur-Shubin formula: an operator-theoretic trace formula and a limit of normalized eigenvalue counting functions on finite volumes. We study a discrete random Schrödinger operator with bounded random potentials of finite-range correlations and prove a quantitative concentration inequality ensuring, with explicit high probability, that the empirical IDS (normalized eigenvalue counting function) uniformly approximates the abstract IDS trace formula within a prescribed error, thereby implying confidence regions for the IDS."}
{"id": "2602.17828", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.17828", "abs": "https://arxiv.org/abs/2602.17828", "authors": ["Oliver Mason"], "title": "A note on diffusive solutions of the Lyapunov and Riccati inequalities for quasi-monotone (QM) mappings on cones", "comment": "Accepted for publication in Communications in Optimization Theory", "summary": "We consider three key properties of Metzler and nonnegative matrices and extensions of these to classes of self-dual proper convex cones. Specifically, we study mappings that are quasi-monotone (QM) with respect to a cone $K$ and discuss results extending D-stability, diagonal Lyapunov stability, and diagonal Riccati stability to this setting. Mappings that act diffusively with respect to the cone are used as generalisations of diagonal matrices. Relationships with recent results for symmetric cones obtained using Jordan algebraic methods are also discussed."}
{"id": "2602.18080", "categories": ["hep-lat", "cond-mat.str-el", "hep-th", "nucl-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18080", "abs": "https://arxiv.org/abs/2602.18080", "authors": ["Fran Ilčić", "Ritajit Majumdar", "Emil Mathew", "Nathan Earnest-Noble", "Indrakshi Raychowdhury"], "title": "Observation of Robust and Coherent Non-Abelian Hadron Dynamics on Noisy Quantum Processors", "comment": "19 pages, 13 figres including supplementary information", "summary": "The real-time evolution of strongly interacting matter remains a frontier of fundamental physics, as classical simulations are hampered by exponential Hilbert space growth and entanglement-driven bottlenecks in tensor networks. This study reports the quantum simulation of hadron dynamics within a $(1+1)$-dimensional SU(2) lattice gauge theory using a 156-qubit IBM superconducting processor. Leveraging a hardware-efficient Loop-String-Hadron (LSH) encoding, we simulate the dynamics of the physical degrees of freedom on a $60$-site lattice in the weak-coupling regime, as a crucial step toward the continuum limit. We successfully observe the light-cone propagation of a confined meson and internal oscillations indicative of early-time hadronic breathing modes. Notably, these high-fidelity results were obtained directly from the quantum data via a differential measurement protocol, together with measurement error mitigation, demonstrating a robust pathway for large-scale simulations even on noisy hardware. To validate the results, we benchmarked the quantum algorithm and outcome from the quantum processor against state-of-the-art approximated classical algorithms using CPU -- based on tensor network methods and Pauli propagation method, respectively. Furthermore, we provide a quantitative comparison demonstrating that as the system approaches the weak-coupling or the continuum limit, the quantum processor maintains a consistent structural robustness where classical tensor networks and Pauli propagation methods encounter an onset of exponential complexity or symmetry violations as an artifact of approximation in the algorithm. These results establish a scalable pathway for simulating non-Abelian dynamics on near-term quantum hardware and mark a critical step toward achieving a practical quantum advantage in high-energy physics."}
{"id": "2602.18261", "categories": ["eess.SY", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.18261", "abs": "https://arxiv.org/abs/2602.18261", "authors": ["Philippe Jacquod", "Laurent Pagnier", "Daniel J. Gauthier"], "title": "Accurate Data-Based State Estimation from Power Loads Inference in Electric Power Grids", "comment": "10 pages, 10 figures", "summary": "Accurate state estimation is a crucial requirement for the reliable operation and control of electric power systems. Here, we construct a data-driven, numerical method to infer missing power load values in large-scale power grids. Given partial observations of power demands, the method estimates the operational state using a linear regression algorithm, exploiting statistical correlations within synthetic training datasets. We evaluate the performance of the method on three synthetic transmission grid test systems. Numerical experiments demonstrate the high accuracy achieved by the method in reconstructing missing demand values under various operating conditions. We further apply the method to real data for the transmission power grid of Switzerland. Despite the restricted number of observations in this dataset, the method infers missing power loads rather accurately. Furthermore, Newton-Raphson power flow solutions show that deviations between true and inferred values for power loads result in smaller deviations between true and inferred values for flows on power lines. This ensures that the estimated operational state correctly captures potential line contingencies. Overall, our results indicate that simple data-based regression techniques can provide an efficient and reliable alternative for state estimation in modern power grids."}
{"id": "2602.17936", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.17936", "abs": "https://arxiv.org/abs/2602.17936", "authors": ["Changhui Yao", "Yunpan Ma", "Lingxiao Li"], "title": "Optimal error estimate of an isoparametric upwind discontinuous Galerkin method for radiation transport equation on curved domains", "comment": null, "summary": "This work investigates the isoparametric upwind discontinuous Galerkin method for solving the radiation transport equation defined on a bounded domain $D$ with a piecewise $C^{k+1}$ smooth curved boundary. An auxiliary mapping is constructed to approximate the original curved domain. The analysis delineates a high-order optimal convergence rate under the DG norm, which comprehensively balances the errors stemming from the numerical discretization and the geometric approximation. Two- and three-dimensional numerical experiments validate the theoretical results."}
{"id": "2602.17984", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.17984", "abs": "https://arxiv.org/abs/2602.17984", "authors": ["Albert Osom", "Camden Lopez", "Ashley Alexander", "Suresh Chari", "Ziding Feng", "Ying-Qi Zhao"], "title": "Developing Performance-Guaranteed Biomarker Combination Rules with Integrated External Information under Practical Constraint", "comment": null, "summary": "In clinical practice, there is significant interest in integrating novel biomarkers with existing clinical data to construct interpretable and robust decision rules. Motivated by the need to improve decision-making for early disease detection, we propose a framework for developing an optimal biomarker-based clinical decision rule that is both clinically meaningful and practically feasible. Specifically, our procedure constructs a linear decision rule designed to achieve optimal performance among class of linear rules by maximizing the true positive rate while adhering to a pre-specified positive predictive value constraint. Additionally, our method can adaptively incorporate individual risk information from external source to enhance performance when such information is beneficial. We establish the asymptotic properties of our proposed estimator and compare to the standard approach used in practice through extensive simulation studies. Results indicate that our approach offers strong finite-sample performance. We also apply the proposed methods to develop biomarker-based screening rules for pancreatic ductal adenocarcinoma (PDAC) among new-onset diabetes (NOD) patients."}
{"id": "2602.18059", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18059", "abs": "https://arxiv.org/abs/2602.18059", "authors": ["Junseon Park", "Hyeongon Park", "Rahul K. Gupta"], "title": "Iterative McCormick Relaxation for Joint Impedance Control and Network Topology Optimization", "comment": null, "summary": "Power system operators are increasingly deploying Variable Impedance Devices (VIDs), e.g., Smart Wires, and Network Topology Optimization (NTO) schemes for mitigating operational challenges such as line and transformer congestion, and voltage violations. This work aims to optimize and coordinate the operation of distributed VIDs considering fixed and optimized topologies. This problem is inherently non-linear due to power flow equations as well as bilinear terms introduced due to variable line impedance of VIDs. Furthermore, the topology optimization scheme makes it a mixed integer nonlinear problem. To tackle this, we introduce using McCormick relaxation scheme, which converts the bilinear constraints into a linear set of constraints along with the DC power flow equations. We propose an iterative correction of the McCormick relaxation to enhance its accuracy. The proposed framework is validated on standard IEEE benchmark test systems, and we present a performance comparison of the iterative McCormick method against the non-linear, SOS2 piecewise linear approximation, and original McCormick relaxation."}
{"id": "2602.18059", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18059", "abs": "https://arxiv.org/abs/2602.18059", "authors": ["Junseon Park", "Hyeongon Park", "Rahul K. Gupta"], "title": "Iterative McCormick Relaxation for Joint Impedance Control and Network Topology Optimization", "comment": null, "summary": "Power system operators are increasingly deploying Variable Impedance Devices (VIDs), e.g., Smart Wires, and Network Topology Optimization (NTO) schemes for mitigating operational challenges such as line and transformer congestion, and voltage violations. This work aims to optimize and coordinate the operation of distributed VIDs considering fixed and optimized topologies. This problem is inherently non-linear due to power flow equations as well as bilinear terms introduced due to variable line impedance of VIDs. Furthermore, the topology optimization scheme makes it a mixed integer nonlinear problem. To tackle this, we introduce using McCormick relaxation scheme, which converts the bilinear constraints into a linear set of constraints along with the DC power flow equations. We propose an iterative correction of the McCormick relaxation to enhance its accuracy. The proposed framework is validated on standard IEEE benchmark test systems, and we present a performance comparison of the iterative McCormick method against the non-linear, SOS2 piecewise linear approximation, and original McCormick relaxation."}
{"id": "2602.18273", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.18273", "abs": "https://arxiv.org/abs/2602.18273", "authors": ["Y. J. Kang", "S. K. So", "Kyungsik Kim"], "title": "Analytical solutions for a charged particle with white, thermal, and active noises in the presence of a uniform magnetic field", "comment": "21 pages", "summary": "We study the two-dimensional equations of motion for a charged particle subjected to white, thermal, and active noises in uniform a magnetic field. By deriving the corresponding Fokker Planck equation, analytical solutions for the joint probability density are obtained in different time domains."}
{"id": "2602.17803", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.17803", "abs": "https://arxiv.org/abs/2602.17803", "authors": ["Ray Ganardi", "Jeongrak Son", "Jakub Czartowski", "Seok Hyung Lie", "Nelly H. Y. Ng"], "title": "Manipulating heterogeneous quantum resources over a network", "comment": "13+7 pages, 2 figures", "summary": "Quantum information processing relies on a variety of resources, including entanglement, coherence, non-Gaussianity, and magic. In realistic settings, protocols run on networks of parties with heterogeneous local resource constraints, so different resources coexist and interact. Yet, resource theories have mostly treated each resource in isolation, and a general theory for manipulation in such distributed settings has been lacking. We develop a unified framework for composite quantum resource theories that describes distributed networks of locally constrained parties. We formulate natural axioms a composite theory should satisfy to respect the local structure, and from these axioms derive fundamental bounds on resource manipulation that hold universally, independent of the particular network characteristics. We apply our results to central operational tasks, including resource conversion and assisted distillation, and introduce new methods to construct new resource monotones from this setup. Our framework further reveals previously unexplored phenomena in the remote certification of quantum resources. Together, these results establish foundational laws for distributed quantum resource manipulation across diverse physical platforms."}
{"id": "2602.17956", "categories": ["stat.ME", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.17956", "abs": "https://arxiv.org/abs/2602.17956", "authors": ["Tâm LeMinh", "Julyan Arbel", "Florence Forbes", "Hien Duy Nguyen"], "title": "A variational framework for modal estimation", "comment": null, "summary": "We approach multivariate mode estimation through Gibbs distributions and introduce GERVE (Gibbs-measure Entropy-Regularised Variational Estimation), a likelihood-free framework that approximates Gibbs measures directly from samples by maximizing an entropy-regularised variational objective with natural-gradient updates. GERVE brings together kernel density estimation, mean-shift, variational inference, and annealing in a single platform for mode estimation. It fits Gaussian mixtures that concentrate on high-density regions and yields cluster assignments from responsibilities, with reduced sensitivity to the chosen number of components. We provide theory in two regimes: as the Gibbs temperature approaches zero, mixture components converge to population modes; at fixed temperature, maximisers of the empirical objective exist, are consistent, and are asymptotically normal. We also propose a bootstrap procedure for per-mode confidence ellipses and stability scores. Simulation and real-data studies show accurate mode recovery and emergent clustering, robust to mixture overspecification. GERVE is a practical likelihood-free approach when the number of modes or groups is unknown and full density estimation is impractical."}
{"id": "2602.17845", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.17845", "abs": "https://arxiv.org/abs/2602.17845", "authors": ["Bryce Christopherson", "Farhad Jafari"], "title": "A Refinement in Čech Cohomology of Coron's Necessary Condition", "comment": "12 pages", "summary": "Coron established a homological obstruction to continuous feedback stabilization of nonlinear control systems $\\dot{x}=f(x,u)$ with $f \\in C(Ω,\\mathbb{R}^n)$ and $f(0,0)=0$, showing that local asymptotic stabilizability implies the induced homomorphism $f_*$ satisfies $f_*\\big(H_{n-1}(Σ_ε)\\big)=H_{n-1}(S^{n-1})$, where $Σ_ε:=\\Big(\\big(\\mathbb{B}_ε^{\\mathbb{R}^n}(0)\\times\\mathbb{B}_ε^{\\mathbb{R}^m}(0)\\big)\\cap Ω\\Big)\\setminus f^{-1}(0)$. In this paper, we refine Coron's necessary condition using Čech cohomology and the Vietoris-Begle mapping theorem. Specifically, we prove that the closed version of $Σ_ε$ must be a Čech cohomology $(n-1)$-sphere and that the restriction of $f$ to this subset induces an isomorphism on its Čech cohomology groups in all degrees. This strengthens Coron's condition from a constraint on the top class to a full cohomological rigidity statement."}
{"id": "2602.18360", "categories": ["hep-lat", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.18360", "abs": "https://arxiv.org/abs/2602.18360", "authors": ["Sandip Maiti", "Debasish Banerjee", "Shailesh Chandrasekharan", "Marina K. Marinkovic"], "title": "Phase diagram of a lattice fermion model with symmetric mass generation", "comment": "19 pages, 12 figures, 4 tables", "summary": "We study the phase structure of a model containing two flavors of massless staggered fermions interacting through two independent four-fermion couplings, UI and UB, formulated on a three-dimensional Euclidean space-time lattice. At UB = 0, this model is known to exhibit a direct second-order quantum phase transition between a massless fermion (MF) phase and a phase in which fermions acquire masses through the mechanism commonly referred to as symmetric mass generation (SMG). We demonstrate that introducing a small nonzero value of UB qualitatively alters this structure: the single exotic transition at UB = 0 splits into two distinct, conventional transitions, separated by an intermediate phase in which fermion masses arise through the standard mechanism of spontaneous symmetry breaking (SSB). The first of these is a Gross-Neveu transition separating the MF phase from the SSB-induced massive phase, while the second is a three-dimensional XY transition between the SSB phase and the SMG phase. Using the fermion-bag Monte Carlo method, we verify that the critical exponents associated with both transitions are consistent with the literature, thereby yielding a quantitative characterization of the resulting phase structure of the model."}
{"id": "2602.18412", "categories": ["quant-ph", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.18412", "abs": "https://arxiv.org/abs/2602.18412", "authors": ["Ariel A. Galindo Duque", "Miguel A. Prado Reynoso", "Miguel Gonzalez", "Jorge G. Hirsch"], "title": "Participation Ratio as a Quantum Probe of Hierarchical Stickiness", "comment": "9 pages, 4 figures", "summary": "We investigate how quantum localization encodes the hierarchical stickiness that governs transport in mixed classical phase spaces. Using the periodically driven kicked top, we show that the participation ratio (PR) of coherent states in the Floquet eigenbasis resolves the same layered structure that appears classically as a multimodal distribution of finite-time Lyapunov exponents (FTLEs). To establish a quantitative correspondence, we introduce a Gaussian coarse graining of the FTLE matched to the intrinsic semiclassical resolution of coherent states. Both local correlations and global comparisons of probability distributions demonstrate that quantum and classical indicators agree optimally within a finite window of evolution times, where sticky structures are most clearly resolved. Our results promote the participation ratio from a global measure of chaos to a sensitive probe of hierarchical transport and provide a practical route for diagnosing anomalous localization in driven quantum systems."}
{"id": "2602.17950", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.17950", "abs": "https://arxiv.org/abs/2602.17950", "authors": ["Jing Wang", "Wei Yang", "Yongjun Yuan", "Yong Zhang"], "title": "Mathematical and numerical study on the ground states of rotating spin-orbit coupled spin-1 Bose-Einstein condensates", "comment": "25 pages, 6 figures", "summary": "In this article, we study mathematically and numerically the ground states of three-component rotating spin-orbit coupled (SOC) spin-1 Bose-Einstein condensates modeled by the coupled Gross-Pitaevskii equations (CGPEs). Firstly, we rigorously prove existence result of the ground state and derive some analytical properties, including the virial identity and negativity of SOC energy. Secondly, we propose an efficient and accurate preconditioned nonlinear conjugate gradient (PCG) algorithm to compute the ground states. We truncate the whole space into a bounded rectangular domain and readily apply the Fourier spectral method to approximate the wave function. The PCG method is successfully adapted with appropriate modifications to the adaptive step size control strategy for the one-parameter energy minimization problem and to the choice of preconditioners, achieving great performance in terms of accuracy and efficiency. Lastly, we carry out extensive numerical experiments to verify the existence and property results of the ground states, confirm the spatial spectral accuracy by traversing the most commonly-used initial guesses for each component thanks to its great efficiency, which is also attributed to a utilization of cascadic multigrid and discrete Fast Fourier Transform (FFT). Moreover, we investigate the effects of local interaction, rotation and spin-orbit coupling and external trapping potential on the ground state, and unveil some interesting physical phenomena, such as giant vortex and U-shape vortex line."}
{"id": "2602.17995", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.17995", "abs": "https://arxiv.org/abs/2602.17995", "authors": ["Kana Yamada", "Hisato Sunami", "Kentaro Takeda", "Keisuke Hanada", "Masahiro Kojima"], "title": "Hybrid Non-informative and Informative Prior Model-assisted Designs for Mid-trial Dose Insertion", "comment": null, "summary": "In oncology phase I trials, model-assisted designs have been increasingly adopted because they enable adaptive yet operationally simple dose adjustment based on accumulating safety data, leading to a paradigm shift in dose-escalation methodology. In practice, a single mid-trial dose insertion may be considered to examine safer doses and/or to collect more informative efficacy data. In this study, we investigate methods to improve dose assignment and the selection of the maximum tolerated dose (MTD) or the optimal biological dose (OBD) when a new dose level is added during an ongoing trial under a model-assisted framework, by assigning informative prior information to the inserted dose. We propose a hybrid design that uses a non-informative model-assisted design at trial initiation and, upon dose insertion, applies an informative-prior extension only to the newly added dose. In addition, to address potential skeleton misspecification, we propose two adaptive extensions: (i) an online-weighting approach that updates the skeleton over time, and (ii) a Bayesian-mixture approach that robustly combines multiple candidate skeletons. We evaluate the proposed methods through simulation studies."}
{"id": "2602.18247", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18247", "abs": "https://arxiv.org/abs/2602.18247", "authors": ["Fen Wu", "Chengzhi Yuan"], "title": "Hybrid Control of ADT Switched Linear Systems subject to Actuator Saturation", "comment": null, "summary": "This paper develops a hybrid output-feedback control framework for average dwell-time (ADT) switched linear systems subject to actuator saturation. The considered subsystems may be exponentially unstable, and the saturation nonlinearity is explicitly handled through a deadzone-based representation. The proposed hybrid controller combines mode-dependent full-order dynamic output-feedback controllers with a supervisory reset mechanism that updates controller states at switching instants. By incorporating the reset rule directly into the synthesis conditions, switching boundary constraints and performance requirements are addressed in a unified convex formulation. Sufficient conditions are derived in terms of linear matrix inequalities (LMIs) to guarantee exponential stability under ADT switching and a prescribed weighted ${\\cal L}_2$-gain disturbance attenuation level for energy-bounded disturbances. An explicit controller construction algorithm is provided based on feasible LMI solutions. Simulation results demonstrate the effectiveness and computational tractability of the proposed approach and highlight its advantages over existing output-feedback saturation control methods."}
{"id": "2602.18247", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18247", "abs": "https://arxiv.org/abs/2602.18247", "authors": ["Fen Wu", "Chengzhi Yuan"], "title": "Hybrid Control of ADT Switched Linear Systems subject to Actuator Saturation", "comment": null, "summary": "This paper develops a hybrid output-feedback control framework for average dwell-time (ADT) switched linear systems subject to actuator saturation. The considered subsystems may be exponentially unstable, and the saturation nonlinearity is explicitly handled through a deadzone-based representation. The proposed hybrid controller combines mode-dependent full-order dynamic output-feedback controllers with a supervisory reset mechanism that updates controller states at switching instants. By incorporating the reset rule directly into the synthesis conditions, switching boundary constraints and performance requirements are addressed in a unified convex formulation. Sufficient conditions are derived in terms of linear matrix inequalities (LMIs) to guarantee exponential stability under ADT switching and a prescribed weighted ${\\cal L}_2$-gain disturbance attenuation level for energy-bounded disturbances. An explicit controller construction algorithm is provided based on feasible LMI solutions. Simulation results demonstrate the effectiveness and computational tractability of the proposed approach and highlight its advantages over existing output-feedback saturation control methods."}
{"id": "2602.18321", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.18321", "abs": "https://arxiv.org/abs/2602.18321", "authors": ["Jann van der Meer", "Andreas Dechant"], "title": "Near-optimality of conservative driving in discrete systems", "comment": null, "summary": "Transferring a physical system from an initial to a final state while minimizing energetic losses is an interdisciplinary control problem that bridges stochastic thermodynamics and optimal transport theory. Recent research typically considers problems in which the optimal solution is realized via conservative forces, but whether this situation applies depends on the problem's constraints. In systems with complex topologies like discrete networks, the optimal, dissipation-minimizing protocol involves applying nonconservative forces along cycles if the timescales of the transitions in the network are fixed. We show that although nonconservative driving is optimal in this setting, a conservative protocol exists whose dissipation is at most twice the optimal one. This finding is complemented with an example modeling transport across an energy barrier, which illustrates such improvements of order 1 explicitly. Qualitatively, conservative driving falls short of achieving optimality because direct transport across the barrier is avoided. We conclude with a discussion that the optimality of nonconservative driving might be a generic phenomenon: As fewer degrees of freedom can be optimized, additional degrees of freedom due to adding nonconservative forces become more significant."}
{"id": "2602.17806", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.17806", "abs": "https://arxiv.org/abs/2602.17806", "authors": ["Kelvin Yip", "Alessandro Monteros", "Sahel Ashhab", "Lin Tian"], "title": "Digital Quantum Simulation of the Holstein-Primakoff Transformation on Noisy Qubits", "comment": "12 pages, 8 figures", "summary": "Quantum simulation of many-body systems offers a powerful approach to exploring collective quantum dynamics beyond classical computational reach. Although spin and fermionic models have been extensively simulated on digital quantum computers, the simulation of bosonic systems on programmable quantum processors is often hindered by the intrinsically large Hilbert space of bosonic modes. In this work, we study the digital quantum simulation of bosonic modes using the Holstein-Primakoff (HP) transformation and implement this protocol on a cloud-based superconducting quantum processor. Two representative models are realized on quantum hardware: (i) the driven harmonic oscillator and (ii) the Jaynes-Cummings model. Using data obtained from the quantum simulations, we systematically examine the interplay between algorithmic and hardware-induced errors to identify optimal simulation parameters. The dominant algorithmic errors arise from the finite number of qubits used in the HP mapping and the finite number of Trotter steps in the time evolution, while hardware errors mainly originate from gate infidelity, decoherence, and readout errors. This study advances the digital quantum simulation of many-body systems involving bosonic degrees of freedom on currently available cloud quantum processors and provides a framework that can be extended to more complex spin-boson and multimode cavity models."}
{"id": "2602.18210", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.18210", "abs": "https://arxiv.org/abs/2602.18210", "authors": ["Francesco Gili", "Geurt Jongbloed"], "title": "Semiparametric Uncertainty Quantification via Isotonized Posterior for Deconvolutions", "comment": null, "summary": "We address the problem of uncertainty quantification for the deconvolution model \\(Z = X + Y\\), where \\(X\\) and \\(Y\\) are nonnegative random variables and the goal is to estimate the signal's distribution of \\(X \\sim F_0\\) supported on~\\([0,\\infty)\\), from observations where the noise distribution is known. Existing frequentist methods often produce confidence intervals for $F_0(x)$ that depend on unknown nuisance parameters, such as the density of \\(X\\) and its derivative, which are difficult to estimate in practice. This paper introduces a novel and computationally efficient nonparametric Bayesian approach, based on projecting the posterior, to overcome this limitation. Our method leverages the solution \\(p\\) to a specific Volterra integral equation as in \\cite{74}, which relates the cumulative distribution function (CDF) of the signal, \\(F_0\\), to the distribution of the observables. We place a Dirichlet Process prior directly on the distribution of the observed data $Z$, yielding a simple, conjugate posterior. To ensure the resulting estimates for \\(F_0\\) are valid CDFs, we isotonize posterior draws taking the Greatest Convex Majorant of the primitive of the posterior draws and defining what we term the Isotonic Inverse Posterior. We show that this framework yields posterior credible sets for \\(F_0\\) that are not only computationally fast to generate but also possess asymptotically correct frequentist coverage after a straightforward recalibration technique for the so-called Bayes Chernoff distribution introduced in \\cite{54}. Our approach thus does not require the estimation of nuisance parameters to deliver uncertainty quantification for the parameter of interest $F_0(x)$. The practical effectiveness and robustness of the method are demonstrated through a simulation study with various noise distributions for $Y$."}
{"id": "2602.17847", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.17847", "abs": "https://arxiv.org/abs/2602.17847", "authors": ["Bryce Christopherson", "Farhad Jafari"], "title": "Stabilization of Nonlinear Systems by Gain-Limited Feedback Laws", "comment": "18 pages, 1 figure", "summary": "We study local stabilization of nonlinear control systems under explicit gain constraints on the feedback law. Using a quantitative refinement of Brockett's openness condition, we introduce the notion of a maximal continuous openness rate for the system vector field near equilibrium. Combining this with a local-section characterization of stabilizability, we derive a general necessary condition for the existence of gain-limited stabilizing feedback. This condition yields sharp no-go results for broad classes of nonlinear systems, including systems that are stabilizable only by nonsmooth feedback. Several examples illustrate how openness rates impose fundamental lower bounds on stabilizing feedback growth near an equilibrium point."}
{"id": "2602.18021", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.18021", "abs": "https://arxiv.org/abs/2602.18021", "authors": ["Agus L. Soenjaya"], "title": "Strong convergence of finite element schemes for the stochastic Landau--Lifshitz--Bloch equation", "comment": null, "summary": "The dynamics of magnetisation in a bounded ferromagnet in $\\mathbb{R}^d$ ($d=1,2$) at high temperatures can be described by the stochastic Landau--Lifshitz--Bloch (sLLB) equation, which is a vector-valued quasilinear stochastic partial differential equation. In this paper, assuming adequate regularity of the initial data, we establish strong convergence in $L^2(Ω)$ of several semi-implicit and implicit fully discrete finite element schemes for the sLLB equation, together with explicit convergence rates. The analysis relies on localised error estimates and new exponential moment bounds for the exact solution. As a by-product, these moment bounds yield mean-square exponential stability of solutions and uniqueness of the invariant measure in one spatial dimension under a small noise assumption. We also sharpen existing convergence-in-probability results for the numerical schemes. Numerical experiments are presented to illustrate and support the theoretical findings."}
{"id": "2602.18004", "categories": ["stat.ME", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.18004", "abs": "https://arxiv.org/abs/2602.18004", "authors": ["Ryan P. Kelly", "David T. Frazier", "David J. Warne", "Christopher C. Drovandi"], "title": "Preconditioned Robust Neural Posterior Estimation for Misspecified Simulators", "comment": null, "summary": "Simulation-based inference (SBI) enables parameter estimation for complex stochastic models with intractable likelihoods when model simulation is feasible. Neural posterior estimation (NPE) is a popular SBI approach that often achieves accurate inference with far fewer simulations than classical approaches. But in practice, neural approaches can be unreliable for two reasons: incompatible data summaries arising from model misspecification yield unreliable posteriors due to extrapolation, and prior-predictive draws can produce extreme summaries that lead to difficulties in obtaining an accurate posterior for the observed data of interest. Existing preconditioning schemes target well-specified settings, and their behaviour under misspecification remains unexplored. We study preconditioning under misspecification and propose preconditioned robust neural posterior estimation, which computes data-dependent weights that focus training near the observed summaries and fits a robust neural posterior approximation. We also introduce a forest-proximity preconditioning approach that uses tree-based proximity scores to down-weight outlying simulations and concentrate computation around the observed dataset. Across two synthetic examples and one real example with incompatible summaries and extreme prior-predictive behaviour, we demonstrate that preconditioning combined with robust NPE increases stability and improves accuracy, calibration, and posterior-predictive fit over standard baseline methods."}
{"id": "2602.18261", "categories": ["eess.SY", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.18261", "abs": "https://arxiv.org/abs/2602.18261", "authors": ["Philippe Jacquod", "Laurent Pagnier", "Daniel J. Gauthier"], "title": "Accurate Data-Based State Estimation from Power Loads Inference in Electric Power Grids", "comment": "10 pages, 10 figures", "summary": "Accurate state estimation is a crucial requirement for the reliable operation and control of electric power systems. Here, we construct a data-driven, numerical method to infer missing power load values in large-scale power grids. Given partial observations of power demands, the method estimates the operational state using a linear regression algorithm, exploiting statistical correlations within synthetic training datasets. We evaluate the performance of the method on three synthetic transmission grid test systems. Numerical experiments demonstrate the high accuracy achieved by the method in reconstructing missing demand values under various operating conditions. We further apply the method to real data for the transmission power grid of Switzerland. Despite the restricted number of observations in this dataset, the method infers missing power loads rather accurately. Furthermore, Newton-Raphson power flow solutions show that deviations between true and inferred values for power loads result in smaller deviations between true and inferred values for flows on power lines. This ensures that the estimated operational state correctly captures potential line contingencies. Overall, our results indicate that simple data-based regression techniques can provide an efficient and reliable alternative for state estimation in modern power grids."}
{"id": "2602.18261", "categories": ["eess.SY", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.18261", "abs": "https://arxiv.org/abs/2602.18261", "authors": ["Philippe Jacquod", "Laurent Pagnier", "Daniel J. Gauthier"], "title": "Accurate Data-Based State Estimation from Power Loads Inference in Electric Power Grids", "comment": "10 pages, 10 figures", "summary": "Accurate state estimation is a crucial requirement for the reliable operation and control of electric power systems. Here, we construct a data-driven, numerical method to infer missing power load values in large-scale power grids. Given partial observations of power demands, the method estimates the operational state using a linear regression algorithm, exploiting statistical correlations within synthetic training datasets. We evaluate the performance of the method on three synthetic transmission grid test systems. Numerical experiments demonstrate the high accuracy achieved by the method in reconstructing missing demand values under various operating conditions. We further apply the method to real data for the transmission power grid of Switzerland. Despite the restricted number of observations in this dataset, the method infers missing power loads rather accurately. Furthermore, Newton-Raphson power flow solutions show that deviations between true and inferred values for power loads result in smaller deviations between true and inferred values for flows on power lines. This ensures that the estimated operational state correctly captures potential line contingencies. Overall, our results indicate that simple data-based regression techniques can provide an efficient and reliable alternative for state estimation in modern power grids."}
{"id": "2602.03234", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.03234", "abs": "https://arxiv.org/abs/2602.03234", "authors": ["Ha Eum Kim", "Andrew D. Kim", "Jong Yeon Lee"], "title": "Liouvillian Gap in Dissipative Haar-Doped Clifford Circuits", "comment": "29 pages, 8 figures", "summary": "Quantum chaos is commonly assessed through probe-dependent signatures such as spectral statistics, OTOCs, and entanglement growth, which need not coincide. Recently, a dissipative diagnostic of chaos has been proposed, in which an infinitesimal coupling to a bath yields a finite Liouvillian gap in chaotic systems, marking the onset of intrinsic relaxation. This raises a conceptual question: what is the minimal departure from Clifford dynamics needed for this intrinsically relaxing behavior to emerge? In this work, we investigate the dynamics under the Floquet two-qubit Clifford circuit interleaved with a finite density of Haar-random single-site gates, followed by a depolarizing channel with strength $γ$. For Floquet Clifford circuits built from an \\textit{i}SWAP-class two-qubit gate, our analysis identifies two distinct regimes for the Liouvillian gap in the thermodynamic limit, exemplified by the undoped and fully doped extreme cases. In both regimes, the dissipative diagnostic signals chaotic behavior, differing only in how the gap scales with system size. In the undoped circuit, the gap scales as $Δ\\sim γN$, whereas in the fully doped circuit it remains finite as $N\\to\\infty$. We find that the doping density $p_h$ governs the crossover: as $p_h\\to 0$, any spatial structure remains undoped-like, whereas for finite $p_h$ certain structures can enter a finite-gap regime. These results are analytically established in the strongly dissipative regime $γ\\gg 1$ by deriving lower bounds on the gap as a function of $p_h$ and explicit finite-gap constructions, and their extension toward $γ\\to 0$ is supported by numerics. Importantly, our analytic treatment depends only on the spatial doping structure, so the same gap scaling persists even when the Haar rotations are independently resampled each Floquet period."}
{"id": "2602.17862", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.17862", "abs": "https://arxiv.org/abs/2602.17862", "authors": ["James W. Gardner", "Federico Belliardo", "Gideon Lee", "Tuvia Gefen", "Liang Jiang"], "title": "Quantum superresolution and noise spectroscopy with quantum computing", "comment": "8 pages, 1 figure", "summary": "Quantum metrology of an incoherent signal is a canonical sensing problem related to superresolution and noise spectroscopy. We show that quantum computing can accelerate searches for a weak incoherent signal when the signal and noise are not precisely known. In particular, we consider weak Schur sampling, density matrix exponentiation, and quantum signal processing for testing the rank, purity, and spectral gap of the unknown quantum state to detect the incoherent signal. We show that these algorithms are faster than full-state tomography, which scales with the dimension of the Hilbert space. We apply our results to detecting exoplanets, stochastic gravitational waves, ultralight dark matter, geontropic quantum gravity, and Pauli noise."}
{"id": "2602.18383", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.18383", "abs": "https://arxiv.org/abs/2602.18383", "authors": ["Xinyuan Chen", "Fan Li"], "title": "Design-based inference for generalized causal effects in randomized experiments", "comment": null, "summary": "Generalized causal effect estimands, including the Mann-Whitney parameter and causal net benefit, provide flexible summaries of treatment effects in randomized experiments with non-Gaussian or multivariate outcomes. We develop a unified design-based inference framework for regression adjustment and variance estimation of a broad class of generalized causal effect estimands defined through pairwise contrast functions. Leveraging the theory of U-statistics and finite-population asymptotics, we establish the consistency and asymptotic normality of regression estimators constructed from individual pairs and per-unit pair averages, even when the working models are misspecified. Consequently, these estimators are model-assisted rather than model-based. In contrast to classical average treatment effect estimands, we show that for nonlinear contrast functions, covariate adjustment preserves consistency but does not admit a universal efficiency guarantee. For inference, we demonstrate that standard heteroskedasticity-robust and cluster-robust variance estimators are generally inconsistent in this setting. As a remedy, we prove that a complete two-way cluster-robust variance estimator, which fully accounts for pairwise dependence and reverse comparisons, is consistent."}
{"id": "2602.17878", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.17878", "abs": "https://arxiv.org/abs/2602.17878", "authors": ["Matthew X. Burns", "Jiaming Liang"], "title": "Improved Analysis of Restarted Accelerated Gradient and Augmented Lagrangian Methods via Inexact Proximal Point Frameworks", "comment": "53 pages, 4 figures", "summary": "This paper studies a class of double-loop (inner-outer) algorithms for convex composite optimization. For unconstrained problems, we develop a restarted accelerated composite gradient method that attains the optimal first-order complexity in both the convex and strongly convex settings. For linearly constrained problems, we introduce inexact augmented Lagrangian methods, including a basic method and an outer-accelerated variant, and establish near-optimal first-order complexity for both methods. The established complexity bounds follow from a unified analysis based on new inexact proximal point frameworks that accommodate relative and absolute inexactness, acceleration, and strongly convex objectives. Numerical experiments on LASSO and linearly constrained quadratic programs demonstrate the practical efficiency of the proposed methods."}
{"id": "2602.18134", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.18134", "abs": "https://arxiv.org/abs/2602.18134", "authors": ["Zhengbo Zhou", "Françoise Tisseur", "Marcus Webb"], "title": "Computing accurate singular values using a mixed-precision one-sided Jacobi algorithm", "comment": "22 pages", "summary": "We present a relative forward error analysis of a mixed-precision preconditioned one-sided Jacobi algorithm, analogous to a two-sided version introduced in [N. J. Higham, F. Tisseur, M. Webb and Z. Zhou, SIAM J. Matrix Anal. Appl. 46 (2025), pp. 2423-2448], which uses low precision to compute the preconditioner, applies it in high precision, and computes the singular value decomposition using the one-sided Jacobi algorithm at working precision. Our analysis yields smaller relative forward error bounds for the computed singular values than those of standard SVD algorithms. We present and analyse two approaches for constructing effective preconditioners. Our numerical experiments support the theoretical results and demonstrate that our algorithm achieves smaller relative forward errors than the LAPACK routines $\\texttt{DGESVJ}$ and $\\texttt{DGEJSV}$, as well as the MATLAB function $\\texttt{svd}$, particularly for ill-conditioned matrices. Timing tests show that our approach accelerates the convergence of the Jacobi iterations and that the dominant cost arises from a single high-precision matrix-matrix multiplication. With improved software or hardware support for this bottleneck, our algorithm would be faster than the LAPACK one-sided Jacobi algorithm $\\texttt{DGESVJ}$ and comparable in speed to the state-of-the-art preconditioned one-sided Jacobi algorithm $\\texttt{DGEJSV}$, but much more accurate."}
{"id": "2602.18045", "categories": ["stat.ME", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.18045", "abs": "https://arxiv.org/abs/2602.18045", "authors": ["Petrus H. Zwart"], "title": "Conformal Tradeoffs: Guarantees Beyond Coverage", "comment": null, "summary": "Deployed conformal predictors are long-lived decision infrastructure operating over finite operational windows. The real-world question is not only ``Does the true label lie in the prediction set at the target rate?'' (marginal coverage), but ``How often does the system commit versus defer? What error exposure does it induce when it acts? How do these rates trade off?'' Marginal coverage does not determine these deployment-facing quantities: the same calibrated thresholds can yield different operational profiles depending on score geometry. We provide a framework for operational certification and planning beyond coverage with three contributions. (1) Small-Sample Beta Correction (SSBC): we invert the exact finite-sample Beta/rank law for split conformal to map a user request $(α^\\star,δ)$ to a calibrated grid point with PAC-style semantics, yielding explicit finite-window coverage guarantees. (2) Calibrate-and-Audit: since no distribution-free pivot exists for rates beyond coverage, we introduce a two-stage design in which an independent audit set produces a reusable region -- label table and certified finite-window envelopes (Binomial/Beta-Binomial) for operational quantities -- commitment frequency, deferral, decisive error exposure, and commit purity -- via linear projection. (3) Geometric characterization: we describe feasibility constraints, regime boundaries (hedging vs.\\ rejection), and cost-coherence conditions induced by a fixed conformal partition, explaining why operational rates are coupled and how calibration navigates their trade-offs. The output is an auditable operational menu: for a fixed scoring model, we trace attainable operational profiles across calibration settings and attach finite-window uncertainty envelopes. We demonstrate the approach on Tox21 toxicity prediction (12 endpoints) and aqueous solubility screening using AquaSolDB."}
{"id": "2602.18331", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18331", "abs": "https://arxiv.org/abs/2602.18331", "authors": ["Liang Wu", "Wallace Gian Yion Tan", "Richard D. Braatz", "Ján Drgoňa"], "title": "Koopman-BoxQP: Solving Large-Scale NMPC at kHz Rates", "comment": "Accepted by the 8th Annual Learning for Dynamics and Control Conference (L4DC 2026). arXiv admin note: text overlap with arXiv:2602.15596", "summary": "Solving large-scale nonlinear model predictive control (NMPC) problems at kilohertz (kHz) rates on standard processors remains a formidable challenge. This paper proposes a Koopman-BoxQP framework that i) learns a linear Koopman high-dimensional model, ii) eliminates the high-dimensional observables to construct a multi-step prediction model of the states and control inputs, iii) penalizes the multi-step prediction model into the objective, which results in a structured box-constrained quadratic program (BoxQP) whose decision variables include both the system states and control inputs, iv) develops a structure-exploited and warm-starting-supported variant of the feasible Mehrotra's interior-point algorithm for BoxQP. Numerical results demonstrate that Koopman-BoxQP can solve a large-scale NMPC problem with $1040$ variables and $2080$ inequalities at a kHz rate."}
{"id": "2602.18331", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18331", "abs": "https://arxiv.org/abs/2602.18331", "authors": ["Liang Wu", "Wallace Gian Yion Tan", "Richard D. Braatz", "Ján Drgoňa"], "title": "Koopman-BoxQP: Solving Large-Scale NMPC at kHz Rates", "comment": "Accepted by the 8th Annual Learning for Dynamics and Control Conference (L4DC 2026). arXiv admin note: text overlap with arXiv:2602.15596", "summary": "Solving large-scale nonlinear model predictive control (NMPC) problems at kilohertz (kHz) rates on standard processors remains a formidable challenge. This paper proposes a Koopman-BoxQP framework that i) learns a linear Koopman high-dimensional model, ii) eliminates the high-dimensional observables to construct a multi-step prediction model of the states and control inputs, iii) penalizes the multi-step prediction model into the objective, which results in a structured box-constrained quadratic program (BoxQP) whose decision variables include both the system states and control inputs, iv) develops a structure-exploited and warm-starting-supported variant of the feasible Mehrotra's interior-point algorithm for BoxQP. Numerical results demonstrate that Koopman-BoxQP can solve a large-scale NMPC problem with $1040$ variables and $2080$ inequalities at a kHz rate."}
{"id": "2602.18269", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.18269", "abs": "https://arxiv.org/abs/2602.18269", "authors": ["Arthur Rotari", "Mihai A. Macovei"], "title": "Higher-order spatial photon interference versus dipole blockade effect", "comment": "10 pages, 3 figures", "summary": "The steady-state quantum dynamics of three dipole-dipole coupled two-level emitters, fixed at the vertices of an equilateral triangle, and interacting via the environmental thermostat is investigated. We have analytically obtained the populations of the involved three-atom cooperative states as well as of the second- and third-order spatial photon correlation functions of the light scattered by the few-qubit sample. As a consequence, we have demonstrated that this incoherently excited system spontaneously generates streams of single photons possessing sub-Poissonian photon statistics. In analogy to the dipole-dipole blockade, one may expect that at smaller inter particle distances, compared to the photon emission wavelength, the reported phenomenon has the same origin. However, we have shown that the quantum photon features are due to the interaction's nature of the few symmetrically arranged two-level emitters with the surrounding thermal reservoir. Respectively, at larger atomic intervals the effect occurs because of high-order spatial interference phenomena. Sub-wavelength interference fringes can be observed too, via measurements of spatial higher-order photon correlation functions."}
{"id": "2602.17899", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.17899", "abs": "https://arxiv.org/abs/2602.17899", "authors": ["Jiheng Duan", "Fernando Torres-Leal", "John M. Nichol"], "title": "Measuring and correcting nanosecond pulse distortions in quantum-dot spin qubits", "comment": "19 pages, 12 figures", "summary": "Gate-defined semiconductor quantum dots utilize fast electrical control to manipulate spin and charge states of individual electrons. Electrical pulse distortions can limit control fidelities but are difficult to measure at the device level. Here, we use detuning-axis pulsed spectroscopy to characterize baseband pulse distortions in a silicon double quantum-dot. We extract the gate-voltage impulse response and apply a digital pre-distortion filter to eliminate pulse distortions on timescales longer than 1~ns. With the pre-distortion, we reduce the frequency chirp of coherent exchange oscillations in a singlet-triplet qubit. Our results suggest a scalable and tuning-efficient method for characterizing pulse distortions in quantum-dot spin qubits."}
{"id": "2602.17879", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.17879", "abs": "https://arxiv.org/abs/2602.17879", "authors": ["Andreas Sojmark", "Zeng Zhang"], "title": "The mean-field control problem for heterogeneous forward-backward systems", "comment": "28 pages", "summary": "We study the problem of mean-field control when the state dynamics are given by general systems of forward-backward stochastic differential equations (FBSDEs) with heterogeneous mean-field interactions. Firstly, we introduce a novel methodology for reducing the well-posedness of such systems to that of a single randomized mean-field FBSDE. As a consequence, we show that, in the fully coupled case, smallness conditions yield existence and uniqueness for both the system itself and the associated variational and adjoint systems. Secondly, we derive a stochastic maximum principle and a verification for the mean-field control problem. This provides necessary and sufficient conditions for optimality."}
{"id": "2602.18159", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.18159", "abs": "https://arxiv.org/abs/2602.18159", "authors": ["Arisa Kawase", "Kensuke Aihara"], "title": "Theoretical insights on the residual transformation from bi-conjugate gradient into bi-conjugate residual via a smoothing scheme", "comment": "11 pages, 1 figure", "summary": "Bi-conjugate gradient (Bi-CG) and bi-conjugate residual (Bi-CR) methods are underlying iterative solvers for linear systems with nonsymmetric matrices. Residual smoothing is a standard technique for obtaining smooth convergence behavior of residual norms; additionally, it represents the transformation between iterative methods. For example, the residuals of the CR method can be obtained by applying a smoothing scheme to those of the CG method for symmetric linear systems. Based on this relationship, the transformation from Bi-CG residuals to Bi-CR residuals using a smoothing scheme was examined in our previous study [Kawase, A., Aihara, K.: Transformation from Bi-CG into Bi-CR Using a Residual Smoothing-like Scheme. AIP Conference Proceedings (2026)]; however, we only provided heuristic and experimental observations. In the present study, we provide a detailed discussion on the theoretical aspects of these transformations. Specifically, we prove that the resulting algorithm transformed from the Bi-CG method using the residual smoothing technique has the same bi-orthogonal properties as those of the original Bi-CR method. We also present a more concise transformation algorithm and its numerical example. These analyses complement our previous study and provide theoretical validity of the residual transformation between the Bi-CG and Bi-CR methods."}
{"id": "2602.18087", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.18087", "abs": "https://arxiv.org/abs/2602.18087", "authors": ["Céline Cunen", "Nils Lid Hjort"], "title": "Optimal inference via confidence distributions for two-by-two tables modelled as Poisson pairs: fixed and random effects", "comment": "6 pages, 3 figures; this article has appeared in essentially this form in the International Statistical Institute 2015 Rio World Conference proceedings volume. The present 2026 arXiv'd version might be further extended by the authors for a fuller journal publication", "summary": "This paper presents methods for meta-analysis of $2 \\times 2$ tables, both with and without allowing heterogeneity in the treatment effects. Meta-analysis is common in medical research, but most existing methods are unsuited for $2 \\times 2$ tables with rare events. Usually the tables are modelled as pairs of binomial variables, but we will model them as Poisson pairs. The methods presented here are based on confidence distributions, and offer optimal inference for the treatment effect parameter. We also propose an optimal method for inference on the ratio between treatment effects, and illustrate our methods on a real dataset."}
{"id": "2602.18365", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18365", "abs": "https://arxiv.org/abs/2602.18365", "authors": ["Feng Zhao", "Tongxin Zheng", "Dane Schiro", "Xiaochu Wang"], "title": "A Marginal Reliability Impact Based Accreditation Framework for Capacity Markets", "comment": null, "summary": "This paper presents a Marginal Reliability Impact (MRI) based resource accreditation framework for capacity market design. Under this framework, a resource is accredited based on its marginal impact on system reliability, thus aligning the resource accreditation value with its reliability contribution. A key feature of the MRI based accreditation is that the accredited capacities supplied by different resources to the capacity market are substitutable in reliability contribution, a desired feature of homogeneous products. Moreover, with MRI based capacity demand, substitutability between supply and demand for capacity is also achieved. As a result, a capacity market with the MRI based capacity product can better characterize the underlying resource adequacy problem and lead to more efficient market outcomes."}
{"id": "2602.18365", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18365", "abs": "https://arxiv.org/abs/2602.18365", "authors": ["Feng Zhao", "Tongxin Zheng", "Dane Schiro", "Xiaochu Wang"], "title": "A Marginal Reliability Impact Based Accreditation Framework for Capacity Markets", "comment": null, "summary": "This paper presents a Marginal Reliability Impact (MRI) based resource accreditation framework for capacity market design. Under this framework, a resource is accredited based on its marginal impact on system reliability, thus aligning the resource accreditation value with its reliability contribution. A key feature of the MRI based accreditation is that the accredited capacities supplied by different resources to the capacity market are substitutable in reliability contribution, a desired feature of homogeneous products. Moreover, with MRI based capacity demand, substitutability between supply and demand for capacity is also achieved. As a result, a capacity market with the MRI based capacity product can better characterize the underlying resource adequacy problem and lead to more efficient market outcomes."}
{"id": "2602.17933", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.17933", "abs": "https://arxiv.org/abs/2602.17933", "authors": ["Gikyu Yamamoto", "Osamu Hirota"], "title": "Comparison of security mechanisms of Mathematical cipher, Wyner scheme, QKD, and Quantum stream cipher", "comment": "14 pages, 14 figures, Lecture note in the seminar", "summary": "A new generation of global communications technology has been emerging. These systems, which utilize established device technologies and quantum effect devices, require ultra-high speeds, low cost, and strong security. In recent years, global communication systems have faced various practical security challenges depending on their configurations, and research efforts are underway to address these issues. In particular, the issue of the security of physical layer security from microwave wireless systems to quantum optical communication systems is urgent problem. However, concepts of cryptographic schemes have also been diversifying. Typical examples are mathematical ciphers, the Wyner scheme and QKD. Then, the Y-00 protocol has recently emerged as a third pillar cryptographic technology in the optical quantum domain. These security principles differ significantly from one another. This makes it difficult for different fields to understand each other. At this stage, comparative explanations of the security principles underlying these various cryptographic technologies are likely to promote mutual understanding among researchers across different fields. As the first trial, this lecture note explains the security mechanism of the third pillar (Y-00), comparing it with the principles of other mechanisms."}
{"id": "2602.17885", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.17885", "abs": "https://arxiv.org/abs/2602.17885", "authors": ["Christina Frederick", "Haomin Zhou"], "title": "Multi-agent path-planning in a moving medium via Wasserstein Hamiltonian Flow", "comment": null, "summary": "We present a finite dimensional variational model for multi-agent path-planning in which a group of agents traverses from initial positions to a target distribution in a moving medium. The model is derived using the agent-based formulation of the Wasserstein Hamiltonian flows that transport between probability distributions while optimizing a running cost. The objective is the mismatch between their final positions and the target distribution. The constraints are a system of Hamiltonian equations that provide the trajectories of the agents. The free variables on which the optimization is defined form a finite vector of the initial velocities for the agents. The model is solved numerically by the L-BFGS method in conjunction with a shooting strategy. Several simulation examples, including a time-dependent moving medium, are presented to illustrate the performance of the model."}
{"id": "2602.18226", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.18226", "abs": "https://arxiv.org/abs/2602.18226", "authors": ["Tokuhiro Eto", "Harald Garcke", "Robert Nürnberg"], "title": "A Parametric Finite Element Approach for an Anisotropic Multi-Phase Mullins-Sekerka Problem with Kinetic Undercooling", "comment": "22 pages, 16 figures", "summary": "We consider a sharp interface formulation for an anisotropic multi-phase Mullins-Sekerka problem with kinetic undercooling. The flow is characterized by a cluster of surfaces evolving such that the total surface energy plus a weighted sum of the volumes of the enclosed phases decreases in time. Upon deriving a suitable variational formulation, we introduce a fully discrete unfitted finite element method. In this approach, the approximations of the moving interfaces are independent of the triangulations used for the equations in the bulk. Our method can be shown to be unconditionally stable. Several numerical examples demonstrate the capabilities of the introduced method. In particular, it is demonstrated that the evolution of multiple ice crystals with junctions can be modeled using the proposed approach."}
{"id": "2602.18150", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.18150", "abs": "https://arxiv.org/abs/2602.18150", "authors": ["Arshi Rizvi", "Rahul Singh"], "title": "Inclusive Ranking of Indian States via Bayesian Bradley-Terry Model", "comment": "24 pages, 15 figures", "summary": "Evaluating the performance of different administrative regions within a country is crucial for its development and policy formulation. The performance evaluators are mostly based on health, education, per capita income, awareness, family planning and so on. Not only evaluating regions, but also ranking them is a crucial step, and various methods have been proposed to date. We aim to provide a ranking system for Indian states that uses a Bayesian approach via the famous Bradley-Terry model for paired comparisons. The ranking method uses indicators from the NFHS-5 dataset with the prior information of per-capita incomes of the states/UTs, thus leading to a holistic ranking, which not only includes human development factors but also take account the economic background of the states. We also carried out various Markov chain Monte Carlo diagnostics required for the reliability of the estimates of merits for these states. These merits thus provide a ranking for the states/UTs and can further be utilised to make informed policy decisions."}
{"id": "2602.18376", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18376", "abs": "https://arxiv.org/abs/2602.18376", "authors": ["Ashwin P. Dani"], "title": "Parameter Update Laws for Adaptive Control with Affine Equality Parameter Constraints", "comment": null, "summary": "In this paper, constrained parameter update laws for adaptive control with convex equality constraint on the parameters are developed, one based on a gradient only update and the other incorporating concurrent learning (CL) update. The update laws are derived by solving a constrained optimization problem with affine equality constraints. This constrained problem is reformulated as an equivalent unconstrained problem in a new variable, thereby eliminating the equality constraints. The resulting update law is integrated with an adaptive trajectory tracking controller, enabling online learning of the unknown system parameters. Lyapunov stability of the closed-loop system with the equality-constrained parameter update law is established. The effectiveness of the proposed equality-constrained adaptive control law is demonstrated through simulations, validating its ability to maintain constraints on the parameter estimates, achieving convergence to the true parameters for CL-based update law, and achieving asymptotic and exponential tracking performance for constrained gradient and constrained CL-based update laws, respectively."}
{"id": "2602.18376", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.18376", "abs": "https://arxiv.org/abs/2602.18376", "authors": ["Ashwin P. Dani"], "title": "Parameter Update Laws for Adaptive Control with Affine Equality Parameter Constraints", "comment": null, "summary": "In this paper, constrained parameter update laws for adaptive control with convex equality constraint on the parameters are developed, one based on a gradient only update and the other incorporating concurrent learning (CL) update. The update laws are derived by solving a constrained optimization problem with affine equality constraints. This constrained problem is reformulated as an equivalent unconstrained problem in a new variable, thereby eliminating the equality constraints. The resulting update law is integrated with an adaptive trajectory tracking controller, enabling online learning of the unknown system parameters. Lyapunov stability of the closed-loop system with the equality-constrained parameter update law is established. The effectiveness of the proposed equality-constrained adaptive control law is demonstrated through simulations, validating its ability to maintain constraints on the parameter estimates, achieving convergence to the true parameters for CL-based update law, and achieving asymptotic and exponential tracking performance for constrained gradient and constrained CL-based update laws, respectively."}
{"id": "2602.17969", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.17969", "abs": "https://arxiv.org/abs/2602.17969", "authors": ["Aygul Azatovna Galimova"], "title": "Distributed Hyperbolic Floquet Codes under Depolarizing and Erasure Noise", "comment": null, "summary": "Distributing qubits across quantum processing units (QPUs) connected by shared entanglement enables scaling beyond monolithic architectures. Hyperbolic Floquet codes use only weight-2 measurements and are good candidates for distributed quantum error correcting codes. We construct hyperbolic and semi-hyperbolic Floquet codes from $\\{8,3\\}$, $\\{10,3\\}$, and $\\{12,3\\}$ tessellations via the Wythoff kaleidoscopic construction with the Low-Index Normal Subgroups (LINS) algorithm and distribute them across QPUs via spectral bisection. The $\\{10,3\\}$ and $\\{12,3\\}$ families are new to hyperbolic Floquet codes.\n  We simulate these distributed codes under four noise models: depolarizing, SDEM3, correlated EM3, and erasure. With depolarizing noise ($p_{\\text{local}} = 0.03\\%$), fine-grained codes achieve non-local pseudo-thresholds up to 3.0\\% for $\\{8,3\\}$, 3.0\\% for $\\{10,3\\}$, and 1.75\\% for $\\{12,3\\}$. Correlated EM3 yields pseudo-thresholds up to 0.75\\% for $\\{8,3\\}$, 0.75\\% for $\\{10,3\\}$, and 0.50\\% for $\\{12,3\\}$; crossing-based thresholds from same-$k$ families are ${\\sim}1.75$--$2.9\\%$ across all tessellations. Using the SDEM3 model, fine-grained codes achieve distributed pseudo-thresholds of 1.75\\% for $\\{8,3\\}$, 1.25\\% for $\\{10,3\\}$, and 1.00\\% for $\\{12,3\\}$. Under erasure noise motivated by spin-optical architectures, thresholds at 1\\% local loss are 35--40\\% for $\\{8,3\\}$, 30--35\\% for $\\{10,3\\}$, and 25--30\\% for $\\{12,3\\}$."}
{"id": "2602.17968", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.17968", "abs": "https://arxiv.org/abs/2602.17968", "authors": ["Robert Parker", "Manuel Garcia", "Russell Bent"], "title": "Exploiting block triangular submatrices in KKT systems", "comment": null, "summary": "We propose a method for solving Karush-Kuhn-Tucker (KKT) systems that exploits block triangular submatrices by first using a Schur complement decomposition to isolate the block triangular submatrices then performing a block backsolve where only diagonal blocks of the block triangular form need to be factorized. We show that factorizing reducible symmetric-indefinite matrices with standard 1$\\times$1 or 2$\\times$2 pivots yields fill-in outside the diagonal blocks of the block triangular form, in contrast to our proposed method. While exploiting a block triangular submatrix has limited fill-in, unsymmetric matrix factorization methods do not reveal inertia, which is required by interior point methods for nonconvex optimization. We show that our target matrix has inertia that is known \\textit{a priori}, letting us compute inertia of the KKT matrix by Sylvester's law. Finally, we demonstrate the computational advantage of this method on KKT systems from optimization problems with neural network surrogates in their constraints. Our method achieves up to 15$\\times$ speedups over state-of-the-art symmetric indefinite matrix factorization methods MA57 and MA86 in a constant-hardware comparison."}
{"id": "2602.18404", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.18404", "abs": "https://arxiv.org/abs/2602.18404", "authors": ["Sebastian Franz", "Natalia Kopteva"], "title": "Well-posedness and time stepping adaptivity for a class of collocation discretisations of time-fractional subdiffusion equations", "comment": "23 pages, 9 figures", "summary": "Time-fractional parabolic equations with a Caputo time derivative of order $α\\in(0,1)$ are discretised in time using collocation methods, which assume that the Caputo derivative of the computed solution is piecewise-polynomial. For such discretisations of any order $m\\ge 0$, with any choice of collocation points, we give sufficient conditions for existence and uniqueness of collocation solutions. Furthermore, we investigate the applicability and performance of such schemes in the context of the a-posteriori error estimation and adaptive time stepping algorithms."}
{"id": "2602.18161", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.18161", "abs": "https://arxiv.org/abs/2602.18161", "authors": ["Simon Bond"], "title": "Equal Marginal Power for Co-Primary Endpoints", "comment": "10 pages, 3 figures", "summary": "The choice of sample size in the context of co-primary endpoints for a randomised trial is discussed. Current guidance can leave endpoints with unequal marginal power. A method is provided to achieve equal marginal power by using the flexibility provided in multiple testing procedures. A comparison is made to several choices of rule to determine the sample size, in terms of the study design and its operating characteristics."}
{"id": "2602.18382", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18382", "abs": "https://arxiv.org/abs/2602.18382", "authors": ["Yu Kawano", "Simone Betteti", "Alexander Davydov", "Francesco Bullo"], "title": "Incremental Input-to-State Stability and Equilibrium Tracking for Stochastic Contracting Dynamics", "comment": null, "summary": "In this paper, we study the contractivity of nonlinear stochastic differential equations (SDEs) driven by deterministic inputs and Brownian motions. Given a weighted $\\ell_2$-norm for the state space, we show that an SDE is incrementally noise- and input-to-state stable if its vector field is uniformly contracting in the state and uniformly Lipschitz in the input. This result is applied to error estimation for time-varying equilibrium tracking in the presence of noise affecting both the system dynamics and the input signals. We consider both Ornstein-Uhlenbeck processes modeling unbounded noise and Jacobi diffusion processes modeling bounded noise. Finally, we turn our attention to the associated Fokker-Planck equation of an SDE. For this context, we prove incremental input-to-state stability with respect to an arbitrary $p$-Wasserstein metric when the drift vector field is uniformly contracting in the state and uniformly Lipschitz in the input with respect to an arbitrary norm."}
{"id": "2602.18382", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18382", "abs": "https://arxiv.org/abs/2602.18382", "authors": ["Yu Kawano", "Simone Betteti", "Alexander Davydov", "Francesco Bullo"], "title": "Incremental Input-to-State Stability and Equilibrium Tracking for Stochastic Contracting Dynamics", "comment": null, "summary": "In this paper, we study the contractivity of nonlinear stochastic differential equations (SDEs) driven by deterministic inputs and Brownian motions. Given a weighted $\\ell_2$-norm for the state space, we show that an SDE is incrementally noise- and input-to-state stable if its vector field is uniformly contracting in the state and uniformly Lipschitz in the input. This result is applied to error estimation for time-varying equilibrium tracking in the presence of noise affecting both the system dynamics and the input signals. We consider both Ornstein-Uhlenbeck processes modeling unbounded noise and Jacobi diffusion processes modeling bounded noise. Finally, we turn our attention to the associated Fokker-Planck equation of an SDE. For this context, we prove incremental input-to-state stability with respect to an arbitrary $p$-Wasserstein metric when the drift vector field is uniformly contracting in the state and uniformly Lipschitz in the input with respect to an arbitrary norm."}
{"id": "2602.17974", "categories": ["quant-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.17974", "abs": "https://arxiv.org/abs/2602.17974", "authors": ["Zhaonan Meng", "Yuehaw Khoo", "Jiajia Li", "E. Miles Stoudenmire"], "title": "Recursive Sketched Interpolation: Efficient Hadamard Products of Tensor Trains", "comment": "20 pages, 15 figures", "summary": "The Hadamard product of two tensors in the tensor-train (TT) format is a fundamental operation across various applications, such as TT-based function multiplication for nonlinear differential equations or convolutions. However, conventional methods for computing this product typically scale as at least $\\mathcal{O}(χ^4)$ with respect to the TT bond dimension (TT-rank) $χ$, creating a severe computational bottleneck in practice. By combining randomized tensor-train sketching with slice selection via interpolative decomposition, we introduce Recursive Sketched Interpolation (RSI), a ``scale product'' algorithm that computes the Hadamard product of TTs at a computational cost of $\\mathcal{O}(χ^3)$. Benchmarks across various TT scenarios demonstrate that RSI offers superior scalability compared to traditional methods while maintaining comparable accuracy. We generalize RSI to compute more complex operations, including Hadamard products of multiple TTs and other element-wise nonlinear mappings, without increasing the complexity beyond $\\mathcal{O}(χ^3)$."}
{"id": "2602.18003", "categories": ["math.OC", "cs.CC"], "pdf": "https://arxiv.org/pdf/2602.18003", "abs": "https://arxiv.org/abs/2602.18003", "authors": ["Jongmin Lee", "Ernest K. Ryu"], "title": "Policy Gradient Algorithms in Average-Reward Multichain MDPs", "comment": "arXiv admin note: text overlap with arXiv:2510.18340", "summary": "While there is an extensive body of research analyzing policy gradient methods for discounted cumulative-reward MDPs, prior work on policy gradient methods for average-reward MDPs has been limited, with most existing results restricted to ergodic or unichain settings. In this work, we first establish a policy gradient theorem for average-reward multichain MDPs based on the invariance of the classification of recurrent and transient states. Building on this foundation, we develop refined analyses and obtain a collection of convergence and sample-complexity results that advance the understanding of this setting. In particular, we show that the proposed $α$-clipped policy mirror ascent algorithm attains an $ε$-optimal policy with respect to positive policies."}
{"id": "2602.17923", "categories": ["stat.ME", "math.NA", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.17923", "abs": "https://arxiv.org/abs/2602.17923", "authors": ["Mridula Kuppa", "Khachik Sargsyan", "Marco Panesi", "Habib N. Najm"], "title": "Model Error Embedding with Orthogonal Gaussian Processes", "comment": "30 pages, 26 figures", "summary": "Computational models of complex physical systems often rely on simplifying assumptions which inevitably introduce model error, with consequent predictive errors. Given data on model observables, the estimation of parameterized model-error representations, along with other model parameters, would be ideally done while separating the contributions of each of the two sets of parameters, in order to ensure meaningful stand-alone model predictions. This work builds an embedded model error framework using a weight-space representation of Gaussian processes (GPs) to flexibly capture model-error spatiotemporal correlations and enable inference with GP-embedding in non-linear models. To disambiguate model and model-error/bias parameters, we extend an existing orthogonal GP method to the embedded model-error setting and derive appropriate orthogonality constraints. To address the increased dimensionality introduced by the GP representation, we employ the likelihood-informed subspace method. The construction is demonstrated on linear and non-linear examples, where it effectively corrects model predictions to match data trends. Extrapolation beyond the training data recovers the prior predictive distribution, and the orthogonality constraints lead to meaningful stand-alone model predictions and nearly uncorrelated posteriors between model and model-error parameters."}
{"id": "2602.18170", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.18170", "abs": "https://arxiv.org/abs/2602.18170", "authors": ["Nils Lid Hjort"], "title": "Minimum L2 and robust Kullback-Leibler estimation", "comment": "4 pages, 0 figure. This arXiv'd February 2026 paper is from the 12th Prague Conference on Information Theory, Statistical Decision Functions and Random Processes proceedings volume, 1994, pages 102-105. The material preshadows local likelihood and BHHJ estimation", "summary": "This paper introduces two new robust methods for estimation of parameters in a given parametric family. The first method is that of `minimum weighted L2', effectively minimising an estimate of the integrated (and possibly weighted) squared error. The second is `robust Kullback-Leibler', consisting of minimising a robust version of the empirical Kullback-Leibler distance, and can be viewed as a general robust modification of the maximum likelihood procedure. This second method is also related to recent local likelihood ideas for semiparametric density estimation. The methods are described, influence functions are found, as are formulae for asymptotic variances. In particular large-sample efficiencies are computed under the home turf conditions of the underlying parametric model. The methods and formulae are illustrated for the normal model."}
{"id": "2602.18416", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18416", "abs": "https://arxiv.org/abs/2602.18416", "authors": ["Kenshiro Oguri", "Gregory Lantoine"], "title": "Convex Block-Cholesky Approach to Risk-Constrained Low-thrust Trajectory Design under Operational Uncertainty", "comment": null, "summary": "Designing robust trajectories under uncertainties is an emerging technology that may represent a key paradigm shift in space mission design. As we pursue more ambitious scientific goals (e.g., multi-moon tours, missions with extensive components of autonomy), it becomes more crucial that missions are designed with navigation (Nav) processes in mind. The effect of Nav processes is statistical by nature, as they consist of orbit determination (OD) and flight-path control (FPC). Thus, this mission design paradigm calls for techniques that appropriately quantify statistical effects of Nav, evaluate associated risks, and design missions that ensure sufficiently low risk while minimizing a statistical performance metric; a common metric is Delta-V99: worst-case (99%-quantile) Delta-V expenditure including statistical FPC efforts. In response to the need, this paper develops an algorithm for risk-constrained trajectory optimization under operational uncertainties due to initial state dispersion, navigation error, maneuver execution error, and imperfect dynamics modeling. We formulate it as a nonlinear stochastic optimal control problem and develop a computationally tractable algorithm that combines optimal covariance steering and sequential convex programming (SCP). Specifically, the proposed algorithm takes a block-Cholesky approach for convex formulation of optimal covariance steering, and leverages a recent SCP algorithm, SCvx*, for reliable numerical convergence. We apply the developed algorithm to risk-constrained, statistical trajectory optimization for exploration of dwarf planet Ceres with a Mars gravity assist, and demonstrate the robustness of the statistically-optimal trajectory and FPC policies via nonlinear Monte Carlo simulation."}
{"id": "2602.18416", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18416", "abs": "https://arxiv.org/abs/2602.18416", "authors": ["Kenshiro Oguri", "Gregory Lantoine"], "title": "Convex Block-Cholesky Approach to Risk-Constrained Low-thrust Trajectory Design under Operational Uncertainty", "comment": null, "summary": "Designing robust trajectories under uncertainties is an emerging technology that may represent a key paradigm shift in space mission design. As we pursue more ambitious scientific goals (e.g., multi-moon tours, missions with extensive components of autonomy), it becomes more crucial that missions are designed with navigation (Nav) processes in mind. The effect of Nav processes is statistical by nature, as they consist of orbit determination (OD) and flight-path control (FPC). Thus, this mission design paradigm calls for techniques that appropriately quantify statistical effects of Nav, evaluate associated risks, and design missions that ensure sufficiently low risk while minimizing a statistical performance metric; a common metric is Delta-V99: worst-case (99%-quantile) Delta-V expenditure including statistical FPC efforts. In response to the need, this paper develops an algorithm for risk-constrained trajectory optimization under operational uncertainties due to initial state dispersion, navigation error, maneuver execution error, and imperfect dynamics modeling. We formulate it as a nonlinear stochastic optimal control problem and develop a computationally tractable algorithm that combines optimal covariance steering and sequential convex programming (SCP). Specifically, the proposed algorithm takes a block-Cholesky approach for convex formulation of optimal covariance steering, and leverages a recent SCP algorithm, SCvx*, for reliable numerical convergence. We apply the developed algorithm to risk-constrained, statistical trajectory optimization for exploration of dwarf planet Ceres with a Mars gravity assist, and demonstrate the robustness of the statistically-optimal trajectory and FPC policies via nonlinear Monte Carlo simulation."}
{"id": "2602.17991", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.17991", "abs": "https://arxiv.org/abs/2602.17991", "authors": ["Seokho Jeong", "Minhyuk Kim"], "title": "Enhanced Maximum Independent Set Preparation with Rydberg Atoms Guided by the Spectral Gap", "comment": null, "summary": "Adiabatic quantum computation with Rydberg atoms provides a natural route for solving combinatorial optimization problems such as the maximum independent set (MIS). However, its performance is fundamentally limited by the reduction of the spectral gap with increasing system size and connectivity, which induces population leakage from the ground state during finite-time evolution. Here we introduce the Adjusted Detuning for Ground-Energy Leakage Blockade (ADGLB), a spectral-gap-guided schedule engineering method that modifies the laser detuning profile to suppress leakage without introducing additional Hamiltonian terms or iterative optimization loops. We experimentally benchmark ADGLB on a quasi-one-dimensional chain of $N=10$ atoms, and the MIS preparation probability increases substantially compared with the standard adiabatic schedule. Furthermore, we show that the schedule optimized for smaller instances can be directly applied to larger two-dimensional triangular lattices with $N=25$ and $N=37$. With a small heuristic offset, the method also remains effective for instances with higher hardness parameters. These findings demonstrate that spectral-gap-guided schedule engineering offers a scalable and hardware-efficient strategy for enhancing adiabatic quantum optimization on neutral-atom platforms."}
{"id": "2602.18293", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.18293", "abs": "https://arxiv.org/abs/2602.18293", "authors": ["Camilla Brizzi", "Lorenzo Portinale"], "title": "On the $q$-integrability of $p$-Wasserstein barycenters", "comment": null, "summary": "We study the $L^q$-regularity of the density of barycenters of $N$ probability measures on $\\mathbb{R}^d$ with respect to the $p$-Wasserstein metric ($1<p<\\infty$). According to a previous result by the first author and collaborators, if one marginal is absolutely continuous, so is the $W_p$-barycenter. The next natural question is whether the $L^q$- regularity on the marginals is also preserved for any $q > 1$, as in the classical case ($p=2$) of Agueh--Carlier, or for $W_p$-geodesics ($N=2$). Here we prove that this is the case if one marginal belongs to $L^q$ and the supports of all the marginals satisfy suitable geometric assumptions. However, we show that, as soon as $N>2$, it is possible to find examples of $W_p$-barycenters which are not $q$-integrable, even if one marginal is compactly supported and bounded, thus highlighting the role played by the geometry of the supports. Furthermore, we provide a general estimate of the $L^q$-norm, including a detailed study of the sources of singularities, and a characterization of the $W_p$-barycenters à la Agueh--Carlier in terms of the associated Kantorovich potentials. Finally, we explicitly compute the $W_p$-barycenters of measures obtained as push-forward of special affine transformations. In this case, regularity holds without any additional requirement on the supports."}
{"id": "2602.17974", "categories": ["quant-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.17974", "abs": "https://arxiv.org/abs/2602.17974", "authors": ["Zhaonan Meng", "Yuehaw Khoo", "Jiajia Li", "E. Miles Stoudenmire"], "title": "Recursive Sketched Interpolation: Efficient Hadamard Products of Tensor Trains", "comment": "20 pages, 15 figures", "summary": "The Hadamard product of two tensors in the tensor-train (TT) format is a fundamental operation across various applications, such as TT-based function multiplication for nonlinear differential equations or convolutions. However, conventional methods for computing this product typically scale as at least $\\mathcal{O}(χ^4)$ with respect to the TT bond dimension (TT-rank) $χ$, creating a severe computational bottleneck in practice. By combining randomized tensor-train sketching with slice selection via interpolative decomposition, we introduce Recursive Sketched Interpolation (RSI), a ``scale product'' algorithm that computes the Hadamard product of TTs at a computational cost of $\\mathcal{O}(χ^3)$. Benchmarks across various TT scenarios demonstrate that RSI offers superior scalability compared to traditional methods while maintaining comparable accuracy. We generalize RSI to compute more complex operations, including Hadamard products of multiple TTs and other element-wise nonlinear mappings, without increasing the complexity beyond $\\mathcal{O}(χ^3)$."}
{"id": "2602.18210", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.18210", "abs": "https://arxiv.org/abs/2602.18210", "authors": ["Francesco Gili", "Geurt Jongbloed"], "title": "Semiparametric Uncertainty Quantification via Isotonized Posterior for Deconvolutions", "comment": null, "summary": "We address the problem of uncertainty quantification for the deconvolution model \\(Z = X + Y\\), where \\(X\\) and \\(Y\\) are nonnegative random variables and the goal is to estimate the signal's distribution of \\(X \\sim F_0\\) supported on~\\([0,\\infty)\\), from observations where the noise distribution is known. Existing frequentist methods often produce confidence intervals for $F_0(x)$ that depend on unknown nuisance parameters, such as the density of \\(X\\) and its derivative, which are difficult to estimate in practice. This paper introduces a novel and computationally efficient nonparametric Bayesian approach, based on projecting the posterior, to overcome this limitation. Our method leverages the solution \\(p\\) to a specific Volterra integral equation as in \\cite{74}, which relates the cumulative distribution function (CDF) of the signal, \\(F_0\\), to the distribution of the observables. We place a Dirichlet Process prior directly on the distribution of the observed data $Z$, yielding a simple, conjugate posterior. To ensure the resulting estimates for \\(F_0\\) are valid CDFs, we isotonize posterior draws taking the Greatest Convex Majorant of the primitive of the posterior draws and defining what we term the Isotonic Inverse Posterior. We show that this framework yields posterior credible sets for \\(F_0\\) that are not only computationally fast to generate but also possess asymptotically correct frequentist coverage after a straightforward recalibration technique for the so-called Bayes Chernoff distribution introduced in \\cite{54}. Our approach thus does not require the estimation of nuisance parameters to deliver uncertainty quantification for the parameter of interest $F_0(x)$. The practical effectiveness and robustness of the method are demonstrated through a simulation study with various noise distributions for $Y$."}
{"id": "2602.18011", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18011", "abs": "https://arxiv.org/abs/2602.18011", "authors": ["Takafumi Oka", "Michal Hajdušek", "Shota Nagayama", "Rodney Van Meter"], "title": "A Tailored Fidelity Estimation and Purification Method for Entangled Quantum Networks", "comment": "10 pages, 6 figures; comments welcome", "summary": "We present a method to conduct both quantum state reconstruction and entanglement purification simultaneously that is advantageous in several respects over previous work in this direction, showing that the number of Bell pairs necessary to boot a quantum network can be significantly reduced compared to an existing method. The existing method requires at least $10^5$ Bell pairs for the state reconstruction phase to estimate that the state is of fidelity $0.99$ within the error range of $10^{-2}$, whereas our approach only requires around $2,841$ to be certain with $99.7\\%$ of confidence that the estimated fidelity lies within $[0.99-0.01, 0.99+0.01]$. In addition, in our approach we can start with a lower fidelity Bell pair and purify it multiple times, estimating at the same time the resultant fidelity with guarantee of $99.7\\%$ that the fidelity estimate lies within a certain range. Moreover, the existing method cannot correct both bit-flip and phase-flip errors at the same time and can only correct one of these, whereas our approach can correct both bit-flip and phase-flip errors simultaneously. This research produces numerical estimates for the number of Bell pairs actually needed to guarantee a certain threshold fidelity $F$. The research can support the functioning real-world quantum networking by providing the information of the time needed for the bootstrapping of a quantum network to finish."}
{"id": "2602.17819", "categories": ["math.NA", "math.AP", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.17819", "abs": "https://arxiv.org/abs/2602.17819", "authors": ["Eric Lindström", "Larisa Beilina"], "title": "Variational optimization approach for reconstruction of dielectric permittivity and conductivity functions using partial boundary measurements", "comment": null, "summary": "We present a variational optimization approach for the solution of a coefficient inverse problem of simultaneous reconstruction of the dielectric permittivity and conductivity functions in time-dependent Maxwell's system using limited boundary observations of the electric field.\n  The variational optimization approach is based on constructing a weak form of a Lagrangian which allows to use finite element based reconstruction algorithms.\n  The optimality conditions for the Lagrangian and stability estimate for the adjoint problem are derived, as well as Frechét differentiability of it and of the regularized Tikhonov functional are also presented. Two- and three-dimensional numerical studies confirm our theoretical investigations."}
{"id": "2602.18130", "categories": ["cs.CE", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.18130", "abs": "https://arxiv.org/abs/2602.18130", "authors": ["Michael Loibl", "Guilherme H. Teixeira", "Teoman Toprak", "Irina Shishkina", "Chen Miao", "Josef Kiendl", "Florian Kummer", "Benjamin Marussig"], "title": "Comparative study of different quadrature methods for cut elements", "comment": "preprint; in journal review process", "summary": "The quadrature of cut elements is crucial for all Finite Element Methods that do not apply boundary-fitted meshes. It should be efficient, accurate, and robust. Various approaches balancing these requirements have been published, with some available as open-source implementations. This work reviews these open-sources codes and the methods used. Furthermore, benchmarking examples are developed for 2D and 3D geometries. Implicit and explicit boundary descriptions are available for all models. The different examples test the efficiency, accuracy, versatility, and robustness of the codes. Special focus is set on the influence of the input parameter, which controls the desired quadrature order, on the actual integration error. A detailed comparison of the discussed codes is carried out. The benchmarking allows a conclusive comparison and presents a valuable tool for future code development. All tests are published in an accompanying open-source repository."}
{"id": "2602.18241", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.18241", "abs": "https://arxiv.org/abs/2602.18241", "authors": ["Seohwa Hwang", "Junyong Park"], "title": "Online FDR Controlling procedures for statistical SIS Model and its application to COVID19 data", "comment": "20 pages, 7 figures", "summary": "We propose an online false discovery rate (FDR) controlling method based on conditional local FDR (LIS), designed for infectious disease datasets that are discrete and exhibit complex dependencies. Unlike existing online FDR methods, which often assume independence or suffer from low statistical power in dependent settings, our approach effectively controls FDR while maintaining high detection power in realistic epidemic scenarios. For disease modeling, we establish a Dynamic Bayesian Network (DBN) structure within the Susceptible-Infected-Susceptible (SIS) model, a widely used epidemiological framework for infectious diseases. Our method requires no additional tuning parameters apart from the width of the sliding window, making it practical for real-time disease monitoring. From a statistical perspective, we prove that our method ensures valid FDR control under stationary and ergodic dependencies, extending online hypothesis testing to a broader range of dependent and discrete datasets. Additionally, our method achieves higher statistical power than existing approaches by leveraging LIS, which has been shown to be more powerful than traditional $p$-value-based methods. We validate our method through extensive simulations and real-world applications, including the analysis of infectious disease incidence data. Our results demonstrate that the proposed approach outperforms existing methods by achieving higher detection power while maintaining rigorous FDR control."}
{"id": "2602.18034", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.18034", "abs": "https://arxiv.org/abs/2602.18034", "authors": ["Mohammed Barhoush", "Tomoyuki Morimae", "Ryo Nishimaki", "Takashi Yamakawa"], "title": "Separating Non-Interactive Classical Verification of Quantum Computation from Falsifiable Assumptions", "comment": "36 pages", "summary": "Mahadev [SIAM J. Comput. 2022] introduced the first protocol for classical verification of quantum computation based on the Learning-with-Errors (LWE) assumption, achieving a 4-message interactive scheme. This breakthrough naturally raised the question of whether fewer messages are possible in the plain model. Despite its importance, this question has remained unresolved.\n  In this work, we prove that there is no quantum black-box reduction of non-interactive classical verification of quantum computation of $\\textsf{QMA}$ to any falsifiable assumption. Here, \"non-interactive\" means that after an instance-independent setup, the protocol consists of a single message. This constitutes a strong negative result given that falsifiable assumptions cover almost all standard assumptions used in cryptography, including LWE. Our separation holds under the existence of a $\\textsf{QMA} \\text{-} \\textsf{QCMA}$ gap problem. Essentially, these problems require a slightly stronger assumption than $\\textsf{QMA}\\neq \\textsf{QCMA}$. To support the existence of such problems, we present a construction relative to a quantum unitary oracle."}
{"id": "2602.18247", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18247", "abs": "https://arxiv.org/abs/2602.18247", "authors": ["Fen Wu", "Chengzhi Yuan"], "title": "Hybrid Control of ADT Switched Linear Systems subject to Actuator Saturation", "comment": null, "summary": "This paper develops a hybrid output-feedback control framework for average dwell-time (ADT) switched linear systems subject to actuator saturation. The considered subsystems may be exponentially unstable, and the saturation nonlinearity is explicitly handled through a deadzone-based representation. The proposed hybrid controller combines mode-dependent full-order dynamic output-feedback controllers with a supervisory reset mechanism that updates controller states at switching instants. By incorporating the reset rule directly into the synthesis conditions, switching boundary constraints and performance requirements are addressed in a unified convex formulation. Sufficient conditions are derived in terms of linear matrix inequalities (LMIs) to guarantee exponential stability under ADT switching and a prescribed weighted ${\\cal L}_2$-gain disturbance attenuation level for energy-bounded disturbances. An explicit controller construction algorithm is provided based on feasible LMI solutions. Simulation results demonstrate the effectiveness and computational tractability of the proposed approach and highlight its advantages over existing output-feedback saturation control methods."}
{"id": "2602.18271", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.18271", "abs": "https://arxiv.org/abs/2602.18271", "authors": ["Seohwa Hwang", "Mark Louie Ramos", "DoHwan Park", "Junyong Park", "Johan Lim", "Erin Green"], "title": "Two-Stage Multiple Test Procedures Controlling False Discovery Rate with auxiliary variable and their Application to Set4Delta Mutant Data", "comment": "24 pages, 5 figures", "summary": "In this paper, we present novel methodologies that incorporate auxiliary variables for multiple hypotheses testing related to the main point of interest while effectively controlling the false discovery rate. When dealing with multiple tests concerning the primary variable of interest, researchers can use auxiliary variables to set preconditions for the significance of primary variables, thereby enhancing test efficacy. Depending on the auxiliary variable's role, we propose two approaches: one terminates testing of the primary variable if it does not meet predefined conditions, and the other adjusts the evaluation criteria based on the auxiliary variable. Employing the copula method, we elucidate the dependence between the auxiliary and primary variables by deriving their joint distribution from individual marginal distributions.Our numerical studies, compared with existing methods, demonstrate that the proposed methodologies effectively control the FDR and yield greater statistical power than previous approaches solely based on the primary variable. As an illustrative example, we apply our methods to the Set4$Δ$ mutant dataset. Our findings highlight the distinctions between our methodologies and traditional approaches, emphasising the potential advantages of our methods in introducing the auxiliary variable for selecting more genes."}
{"id": "2602.18044", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18044", "abs": "https://arxiv.org/abs/2602.18044", "authors": ["Hjalmar Rall"], "title": "Gaussian Dynamical Quantum State Tomography", "comment": "14 pages", "summary": "Standard quantum state tomography assumes sufficient control of a system to measure an informationally complete set of observables. Dynamical quantum state tomography (DQST) presents an alternative: given a system with known dynamics and a single fixed observable, it almost always suffices to control only the time at which each i.i.d. copy of the system is measured. This work presents an analogous scheme for tomography of multi-mode Bosonic Gaussian states undergoing Gaussian evolution, using a fixed single-mode homodyne measurement and only assuming control of the time of measurement. I prove that the scheme enables tomography for all discrete homogenous Gaussian evolutions and Gaussian quantum dynamical semigroups except for a null set which includes unitary evolution. When the state is known to be pure, a smaller number of measurement times is shown to be sufficient."}
{"id": "2602.18382", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18382", "abs": "https://arxiv.org/abs/2602.18382", "authors": ["Yu Kawano", "Simone Betteti", "Alexander Davydov", "Francesco Bullo"], "title": "Incremental Input-to-State Stability and Equilibrium Tracking for Stochastic Contracting Dynamics", "comment": null, "summary": "In this paper, we study the contractivity of nonlinear stochastic differential equations (SDEs) driven by deterministic inputs and Brownian motions. Given a weighted $\\ell_2$-norm for the state space, we show that an SDE is incrementally noise- and input-to-state stable if its vector field is uniformly contracting in the state and uniformly Lipschitz in the input. This result is applied to error estimation for time-varying equilibrium tracking in the presence of noise affecting both the system dynamics and the input signals. We consider both Ornstein-Uhlenbeck processes modeling unbounded noise and Jacobi diffusion processes modeling bounded noise. Finally, we turn our attention to the associated Fokker-Planck equation of an SDE. For this context, we prove incremental input-to-state stability with respect to an arbitrary $p$-Wasserstein metric when the drift vector field is uniformly contracting in the state and uniformly Lipschitz in the input with respect to an arbitrary norm."}
{"id": "2602.18383", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.18383", "abs": "https://arxiv.org/abs/2602.18383", "authors": ["Xinyuan Chen", "Fan Li"], "title": "Design-based inference for generalized causal effects in randomized experiments", "comment": null, "summary": "Generalized causal effect estimands, including the Mann-Whitney parameter and causal net benefit, provide flexible summaries of treatment effects in randomized experiments with non-Gaussian or multivariate outcomes. We develop a unified design-based inference framework for regression adjustment and variance estimation of a broad class of generalized causal effect estimands defined through pairwise contrast functions. Leveraging the theory of U-statistics and finite-population asymptotics, we establish the consistency and asymptotic normality of regression estimators constructed from individual pairs and per-unit pair averages, even when the working models are misspecified. Consequently, these estimators are model-assisted rather than model-based. In contrast to classical average treatment effect estimands, we show that for nonlinear contrast functions, covariate adjustment preserves consistency but does not admit a universal efficiency guarantee. For inference, we demonstrate that standard heteroskedasticity-robust and cluster-robust variance estimators are generally inconsistent in this setting. As a remedy, we prove that a complete two-way cluster-robust variance estimator, which fully accounts for pairwise dependence and reverse comparisons, is consistent."}
{"id": "2602.18096", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18096", "abs": "https://arxiv.org/abs/2602.18096", "authors": ["Jake Horder", "Hugo Quard", "Kenji Watanabe", "Takashi Taniguchi", "Nathan Coste", "Igor Aharonovich"], "title": "Pulsed coherent spectroscopy of a quantum emitter in hexagonal Boron Nitride", "comment": "12 pages, 3 figures", "summary": "Defects in solid-state systems constitute a promising platform for the realization of deterministic quantum emitters. Among many candidate materials and emitters, point defects in hexagonal Boron Nitride (hBN) have recently emerged as particularly promising. In this work, we probe the coherence of an individual B center with a zero phonon line at 436 nm, under pulsed resonant excitation. We observe power-dependent Rabi oscillations up to 5π, demonstrating optical coherent control of the transition. We achieve an excellent single photon purity of 93% at π-pulse. Furthermore, we probe the coherence of the two-level system using Ramsey interferometry, revealing an inhomogeneous coherence time of T_2*=0.60 ns. These results establish B centers in hBN as viable candidates for triggered, coherent quantum emitters and represent an important step towards their integration into quantum photonic platforms."}
{"id": "2602.18416", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.18416", "abs": "https://arxiv.org/abs/2602.18416", "authors": ["Kenshiro Oguri", "Gregory Lantoine"], "title": "Convex Block-Cholesky Approach to Risk-Constrained Low-thrust Trajectory Design under Operational Uncertainty", "comment": null, "summary": "Designing robust trajectories under uncertainties is an emerging technology that may represent a key paradigm shift in space mission design. As we pursue more ambitious scientific goals (e.g., multi-moon tours, missions with extensive components of autonomy), it becomes more crucial that missions are designed with navigation (Nav) processes in mind. The effect of Nav processes is statistical by nature, as they consist of orbit determination (OD) and flight-path control (FPC). Thus, this mission design paradigm calls for techniques that appropriately quantify statistical effects of Nav, evaluate associated risks, and design missions that ensure sufficiently low risk while minimizing a statistical performance metric; a common metric is Delta-V99: worst-case (99%-quantile) Delta-V expenditure including statistical FPC efforts. In response to the need, this paper develops an algorithm for risk-constrained trajectory optimization under operational uncertainties due to initial state dispersion, navigation error, maneuver execution error, and imperfect dynamics modeling. We formulate it as a nonlinear stochastic optimal control problem and develop a computationally tractable algorithm that combines optimal covariance steering and sequential convex programming (SCP). Specifically, the proposed algorithm takes a block-Cholesky approach for convex formulation of optimal covariance steering, and leverages a recent SCP algorithm, SCvx*, for reliable numerical convergence. We apply the developed algorithm to risk-constrained, statistical trajectory optimization for exploration of dwarf planet Ceres with a Mars gravity assist, and demonstrate the robustness of the statistically-optimal trajectory and FPC policies via nonlinear Monte Carlo simulation."}
{"id": "2602.17967", "categories": ["math.ST", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.17967", "abs": "https://arxiv.org/abs/2602.17967", "authors": ["Hanxiao Chen", "Debarghya Mukherjee"], "title": "Minimax optimal adaptive structured transfer learning through semi-parametric domain-varying coefficient model", "comment": "86 pages, 8 figures", "summary": "Transfer learning aims to improve inference in a target domain by leveraging information from related source domains, but its effectiveness critically depends on how cross-domain heterogeneity is modeled and controlled. When the conditional mechanism linking covariates and responses varies across domains, indiscriminate information pooling can lead to negative transfer, degrading performance relative to target-only estimation. We study a multi-source, single-target transfer learning problem under conditional distributional drift and propose a semiparametric domain-varying coefficient model (DVCM), in which domain-relatedness is encoded through an observable domain identifier. This framework generalizes classical varying-coefficient models to structured transfer learning and interpolates between invariant and fully heterogeneous regimes. Building on this model, we develop an adaptive transfer learning estimator that selectively borrows strength from informative source domains while provably safeguarding against negative transfer. Our estimator is computationally efficient and easy to implement; we also show that it is minimax rate-optimal and derive its asymptotic distribution, enabling valid uncertainty quantification and hypothesis testing despite data-adaptive pooling and shrinkage. Our results precisely characterize the interplay among domain heterogeneity, the smoothness of the underlying mean function, and the number of source domains and are corroborated by comprehensive numerical experiments and two real-data applications."}
{"id": "2602.18103", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.18103", "abs": "https://arxiv.org/abs/2602.18103", "authors": ["Carolina del Río", "Marcos Rubín-Osanz", "David Rodriguez", "Sebastián Roca-Jerat", "María Carmen Pallarés", "J. Alejandro de Sousa", "Paweł Pakulski", "José Luis García Palacios", "Daniel Granados", "Dawid Pinkowicz", "Núria Crivillers", "Anabel Lostao", "David Zueco", "Alicia Gomez", "Fernando Luis"], "title": "Polariton-polariton coherent coupling in a molecular spin-superconductor chip", "comment": "27 pages, 28 figures", "summary": "The ability to establish coherent communication channels is key for scaling up quantum devices. Here, we engineer interactions between distant polaritons, hybrid spin-photon excitations formed at different lumped-element superconducting resonators within a chip. The chip consists of several resonator pairs, slightly detuned in frequency to make them addressable, capacitively coupled within each pair and inductively coupled to a common readout line. They interact locally with samples of PTMr and Tripak$^{-}$ organic free radicals, deposited onto their inductors, which provide model $S = 1/2$, $g \\simeq 2$ spin ensembles. Frequency-dependent microwave transmission experiments, performed at very low temperatures, measure polariton frequencies as a function of magnetic field in different scenarios. When only one resonator within a pair hosts a molecular sample, the results evidence that spins couple remotely to the empty LER as well as to the local cavity mode. If both resonators interact with a spin ensemble, the magnetic field tunes the polariton frequencies relative to each other, on account of the different spin-photon interactions at each LER. When polaritons are brought into mutual resonance, an avoided level crossing emerges that gives direct spectroscopic evidence for a coherent polariton-polariton interaction mediated by the circuit. Pump-probe experiments reveal that the excitation of a polariton within a connected pair is felt, thus it can be read out, by the other one. These observations, backed by model calculations, illustrate the control and detection of distant photon-photon and spin-spin correlations and entanglement in a scalable modular chip."}
{"id": "2602.18184", "categories": ["math.ST", "math.PR", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.18184", "abs": "https://arxiv.org/abs/2602.18184", "authors": ["Aristides V. Doumas", "S. Spektor"], "title": "Kolmogorov-Type Maximal Inequalities for Independent and Dependent Negative Binomial Random Variables: Sharp Bounds, Sub-Exponential Refinements, and Applications to Overdispersed Count Data", "comment": "11 pages, 8 figures, 2 tables", "summary": "This paper develops Kolmogorov-type maximal inequalities for sums of Negative Binomial random variables under both independence and dependence structures. For independent heterogeneous Negative Binomial variables we derive sharp Markov-type deviation inequalities and Kolmogorov-type bounds expressed in terms of Tweedie dispersion parameters, providing explicit control limits for NB2 generalized linear model monitoring. For dependent count data arising through a shared Gamma mixing variable, we establish a \\emph{sub-exponential Bernstein-type refinement} that exploits the Poisson-Gamma hierarchical structure to yield exponentially decaying tail probabilities -- this refinement is new in the literature. Through moment-matched Monte Carlo experiments ($n=20$, 2{,}000 replications), we document a 55\\% reduction in mean maximum deviation under appropriate dependence structures, a stabilization effect we explain analytically. A concrete epidemiological application with NB2 parameters calibrated from COVID-19 surveillance data demonstrates practical utility. These results materially advance the applicability of classical maximal inequalities to overdispersed and dependent count data prevalent in public health, insurance, and ecological modeling."}
{"id": "2602.18106", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18106", "abs": "https://arxiv.org/abs/2602.18106", "authors": ["Bin Yi"], "title": "Directional Dynamics of the Non-Hermitian Skin Effect", "comment": null, "summary": "The dynamical consequences of the non-Hermitian skin effect (NHSE) remain largely unexplored despite extensive studies of its static properties. Here we address this gap by applying quantum Liang information flow (QLIF) an inherently directional measure of causal influence to the nonHermitian Su Schrieffer Heeger model with non reciprocal hopping. Unlike symmetric correlation functions, QLIF directly captures the directional asymmetry characteristic of non reciprocal systems. We demonstrate a scissors effect where the asymmetry varies approximately linearly with the non-reciprocity parameter gamma for small gamma, and exhibits non-monotonic dependence on the skin length, with optimal asymmetry at moderate skin localization. The velocity ordering reveals NHSE-induced blocking of information flow against the skin direction. Three distinct temporal regimes emerge: light-cone-bounded spreading, gamma-dependent stabilization, and coherent oscillations. These results establish the first quantitative connection between static skin localization and directional information dynamics, offering new insights into information propagation in non-reciprocal quantum systems."}
{"id": "2602.18122", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18122", "abs": "https://arxiv.org/abs/2602.18122", "authors": ["Fernando Valadares", "Aleksandr Dorogov", "Tanjung Krisnanda", "May Chee Loke", "Ni-Ni Huang", "Pengtao Song", "Yvonne Y. Gao"], "title": "Flux-Activated Resonant Control of a Bosonic Quantum Memory", "comment": null, "summary": "Universal control of bosonic degrees of freedom provides a hardware-efficient route for quantum information processing with high-dimensional systems. Bosonic circuit quantum electrodynamics (cQED), which leverages transmon ancillae to coherently control long-lived superconducting cavities, is well suited to this goal. However, the cavity transitions are nearly degenerate in the usual dispersive regime, which limits the direct addressability of individual excitation levels and increases the complexity of engineered gates. Here, we integrate an on-chip flux-control architecture with a long-lived bosonic memory housed in a 3D superconducting cavity to dynamically access resonant Jaynes-Cummings (JC) interactions, and realize efficient arbitrary rotations between any pair of Fock levels in the memory. This on-demand access to JC interactions offers a versatile toolbox for implementing robust Fock-basis qudits and harnessing the rich dynamics of high-dimensional bosonic elements for quantum information processing."}
{"id": "2602.18147", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18147", "abs": "https://arxiv.org/abs/2602.18147", "authors": ["Justin Yu Xiang Peh", "Darren Ming Zhi Koh", "Zifang Xu", "Xi Jie Yeo", "Peng Kian Tan", "Christian Kurtsiefer"], "title": "Clock Synchronization with Weakly Correlated Photons", "comment": "8 pages, 5 figures", "summary": "Clock synchronization is necessary for communication and distributed computing tasks. Previous schemes based on photon timing correlations use pulsed light or photon pairs for their strong timing correlations. In this work, we demonstrate successful synchronization of crystal clocks using weakly time-correlated photons of 180 ns coherence time from a bunched light source. A synchronization timing jitter of 10 ns is achieved over symmetric -102 dB optical channel loss between two parties, over a span of 25 hours. We also present a model that gives better estimates to the coherence peak finding success probabilities under low signal."}
{"id": "2602.18153", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.18153", "abs": "https://arxiv.org/abs/2602.18153", "authors": ["Nils Heinisch", "Francesco Salusti", "Mark R. Hogg", "Timon L. Baltisberger", "Malwina A. Marczak", "Sascha R. Valentin", "Arne Ludwig", "Klaus D. Jöns", "Richard J. Warburton", "Stefan Schumacher"], "title": "High-quality single photons from cavity-enhanced biexciton-to-exciton transition", "comment": "20 pages, 8 figures", "summary": "Resonant laser excitation of a two-level system with subsequent single-photon emission can be used to generate single photons with high indistinguishability or Hong-Ou-Mandel (HOM) visibility. However, spectral overlap between excitation laser and emitted photons generally poses significant challenges. Furthermore, emitter re-excitation intrinsically limits achievable single-photon purity. Established solutions mitigate these issues at significant cost to source efficiency and with increased source complexity. This motivates the use of few-level systems with spectral separation of excitation and emission pathways. One option is a three-level cascade. However, without targeted lifetime engineering of emitting states, the cascade naturally limits achievable photon indistinguishability. Here we study a semiconductor quantum dot with resonant and selective cavity-enhancement of biexciton-to-exciton transition. Following resonant two-photon excitation of the biexciton state, we collect the emitted single photon with the cavity. This approach circumvents emitter re-excitation and naturally introduces spectral separation of excitation laser and emitted single photon. Supported by first experimental results, we demonstrate theoretically that with selective Purcell enhancement, the observed quality quantifiers of single-photon emission (purity, equivalently $g^{(2)}(0)$, and HOM visibility $\\mathcal{V}$, equivalently indistinguishability) are competitive with respect to high-quality deterministic quantum-dot single-photon sources. This is already achieved without systematic optimization or targeted system engineering, which firmly places the reported approach as a viable route to the next generation of highest-quality quantum-dot based deterministic single-photon sources."}
{"id": "2602.18156", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18156", "abs": "https://arxiv.org/abs/2602.18156", "authors": ["T. J. Walstra", "A. J. Hasenack", "P. W. H. Pinkse", "B. Skoric"], "title": "Dispersive Hong-Ou-Mandel Interference with Finite Coincidence Windows", "comment": null, "summary": "Hong-Ou-Mandel (HOM) interference is a fundamental tool for assessing photon indistinguishability in quantum information processing. While the effect of chromatic dispersion on HOM interference has been widely studied, the interplay between dispersion and the finite detection window of realistic measurement devices remains under-explored. In this work, we demonstrate that the rectangular coincidence window inherent to modern time-tagging modules, which effectively acts as a temporal filter, breaks the standard dispersion cancellation condition and restores sensitivity to symmetric group velocity dispersion. We derive an analytical model for type-II SPDC processes that predicts a modification of the HOM dip shape, specifically the emergence of characteristic oscillations and dip broadening. We experimentally validate this theoretical framework using a ppKTP source and transmission through optical fibers of lengths up to 29 km. The experimental data show excellent agreement with the model, confirming the presence of window-induced oscillations and allowing for the precise extraction of the fiber dispersion parameter. These findings underscore the importance of accounting for finite timing resolution in the design and characterization of dispersive quantum communication links."}
{"id": "2602.18177", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18177", "abs": "https://arxiv.org/abs/2602.18177", "authors": ["Unathi Skosana", "Byron Alexander", "Changhyoup Lee", "Mark Tame"], "title": "Experimental realization of a photonic weighted graph state for quantum metrology", "comment": "11 pages, 8 figures, appendix", "summary": "Quantum metrology seeks to push the boundaries of measurement precision by harnessing quantum phenomena. Conventional methods often rely on maximally entangled resources, with states that are usually challenging to produce and sustain in practical setups. Here, we show that the maximally entangled constraint can be lifted by experimentally realizing a photonic two-qubit weighted graph state with an arbitrarily tunable graph weight. We use the generated state as a resource for quantum-enhanced phase sensing. We experimentally characterize the state and study its minimum estimator variance for two distinct local measurement bases as the graph weight varies from the maximally entangled to weakly entangled limit. We find excellent quantitative agreement with theoretical predictions, and observe a gain in precision beyond the classically attainable precision limit for graph weights substantially below the maximally entangled limit. This confirms that considerably less entanglement is required to achieve a quantum advantage. Albeit non-scalable in our test setup, this work represents the first experimental realization of weighted graph states with a tunable graph weight using linear optics. We expect more scalable versions of the model to be possible in an on-chip photonic platform."}
{"id": "2602.18180", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.18180", "abs": "https://arxiv.org/abs/2602.18180", "authors": ["Fatemeh Taghipoor", "Mojtaba Golshani", "Mostafa Motamedifar", "Khatereh Jafari"], "title": "High-Fidelity Teleportation of Continuous-Variable Quantum States Via Non-Ideal Qutrit Entangled Resources", "comment": "12 pages, 7 figures", "summary": "Achieving near-unity fidelity in conventional continuous-variable quantum teleportation schemes based on two-mode squeezed vacuum states is fundamentally unattainable. To overcome this limitation, alternative approaches utilizing ensembles of two-dimensional entangled qubits have been proposed. In this work, we investigate continuous-variable quantum teleportation employing entangled qutrit resources under realistic noise effects. The results demonstrate that the proposed scheme performs well in both ideal and noisy conditions, enabling high-fidelity teleportation with a reasonable success probability."}
{"id": "2602.18192", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18192", "abs": "https://arxiv.org/abs/2602.18192", "authors": ["Maryam Hadipour", "Soroush Haseli"], "title": "Geometry-Controlled Work Extraction in a Non-Markovian Quantum Battery", "comment": "9 pages, 8 figures, comments are welcome", "summary": "We investigate the role of spatial geometry in controlling energy storage and work extraction in a non-Markovian quantum battery. The model consists of two identical two-level systems embedded in a structured waveguide environment, where one qubit acts as the charger and the other as the battery. The relative separation between the qubits introduces a geometry-dependent phase that governs collective interference effects and modulates."}
{"id": "2602.18269", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.18269", "abs": "https://arxiv.org/abs/2602.18269", "authors": ["Arthur Rotari", "Mihai A. Macovei"], "title": "Higher-order spatial photon interference versus dipole blockade effect", "comment": "10 pages, 3 figures", "summary": "The steady-state quantum dynamics of three dipole-dipole coupled two-level emitters, fixed at the vertices of an equilateral triangle, and interacting via the environmental thermostat is investigated. We have analytically obtained the populations of the involved three-atom cooperative states as well as of the second- and third-order spatial photon correlation functions of the light scattered by the few-qubit sample. As a consequence, we have demonstrated that this incoherently excited system spontaneously generates streams of single photons possessing sub-Poissonian photon statistics. In analogy to the dipole-dipole blockade, one may expect that at smaller inter particle distances, compared to the photon emission wavelength, the reported phenomenon has the same origin. However, we have shown that the quantum photon features are due to the interaction's nature of the few symmetrically arranged two-level emitters with the surrounding thermal reservoir. Respectively, at larger atomic intervals the effect occurs because of high-order spatial interference phenomena. Sub-wavelength interference fringes can be observed too, via measurements of spatial higher-order photon correlation functions."}
{"id": "2602.18300", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.18300", "abs": "https://arxiv.org/abs/2602.18300", "authors": ["Gabrielle Barsky-Giles", "Alessandro Prositto", "Matthew Gerry", "Dvira Segal"], "title": "Impossibility of Refrigeration and Engine Operation in Minimal Qubit Repeated-Interaction Models", "comment": null, "summary": "We investigate the operation of a qubit as a quantum thermal device within the repeated interaction framework, allowing for strong system-bath coupling and finite interaction times. We analyze two minimal models: an alternating-coupling setup, in which the qubit sequentially interacts with hot and cold baths, and a simultaneous-coupling setup, where both baths interact with the qubit during each collision. For the alternating model, we obtain an exact analytical solution for the limit-cycle state, valid for arbitrary coupling strengths and collision durations. Using this solution, we rigorously prove a no-go theorem for quantum refrigeration. We further demonstrate that, although work can be generated locally at individual system-bath contacts, the total work over a cycle is always nonpositive, precluding engine operation. In the absence of work, the model describes pure heat conduction, for which we derive a closed-form expression for the heat current and show that it exhibits a nonmonotonic turnover behavior. The simultaneous-coupling model is analyzed perturbatively. In the short-collision-time limit, it reproduces the same steady-state behavior as the alternating model, reinforcing the generality of the constraints identified. Our results establish fundamental limitations on qubit-based quantum thermal machines operating under Markovian repeated interactions and highlight the need for enriched models to realize functional quantum thermal devices."}
{"id": "2602.18323", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18323", "abs": "https://arxiv.org/abs/2602.18323", "authors": ["Goni Yoeli", "Gilad Gour"], "title": "Instability as a Quantum Resource", "comment": "5+19 pages, 2 figures, 1 table", "summary": "We consolidate coherence, athermality, and nonuniformity as sub-resources within an underlying quantum resource theory: instability. We formulate instability axiomatically as the transient information within a decaying physical system. Specifying a decay mechanism (e.g., dephasing, thermalization) recovers these familiar resources as specific manifestations of instability. We compute the one-shot distillation yield and dilution cost in various operational paradigms, and use them to pin down the extremal additive monotones. In the asymptotic regime, we show that all conversion rates are governed by a single additive monotone, and thereby we establish a universal second law for instability."}
{"id": "2602.18327", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18327", "abs": "https://arxiv.org/abs/2602.18327", "authors": ["Francesco Atzori", "Salvatore Virzì", "Francesco Devecchi", "Domenico Abbondandolo", "Alessio Avella", "Fabrizio Piacentini", "Marco Gramegna", "Ivo Pietro Degiovanni", "Marco Genovese"], "title": "Universal Protection of Quantum States from Decoherence", "comment": null, "summary": "The fragility of quantum coherence fundamentally limits the scalability of quantum technologies, as unavoidable environmental interactions induce decoherence and rapidly degrade quantum properties. The Quantum Zeno Effect offers a powerful route to suppress quantum evolution and protect coherence through frequent measurements, irrespective of the underlying dynamics. However, existing implementations require prior knowledge of the quantum state, severely restricting their applicability. Here we introduce a state- and dynamics-independent protection protocol embedding the system in a larger Hilbert space, temporarily swapping the quantum information from its original degree of freedom to a decoherence-free ancillary one. We experimentally validate the protocol on a quantum optical platform, demonstrating robust preservation of coherence and purity for arbitrary polarization qubits under decoherence, thereby enabling the universal safeguarding of unknown quantum states."}
{"id": "2602.18347", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18347", "abs": "https://arxiv.org/abs/2602.18347", "authors": ["Jindi Wu", "Tianjie Hu", "Qun Li"], "title": "A Fine-Grained and Efficient Reliability Analysis Framework for Noisy Quantum Circuits", "comment": null, "summary": "Evaluating the reliability of noisy quantum circuits is essential for implementing quantum algorithms on noisy quantum devices. However, current quantum hardware exhibits diverse noise mechanisms whose compounded effects make accurate and efficient reliability evaluation challenging. While state fidelity is the most faithful indicator of circuit reliability, it is experimentally and computationally prohibitive to obtain. Alternative metrics, although easier to compute, often fail to accurately reflect circuit reliability, lack universality across circuit types, or offer limited interpretability. To address these challenges, we propose a fine-grained, scalable, and interpretable framework for efficient and accurate reliability evaluation of noisy quantum circuits. Our approach performs a state-independent analysis to model how circuit reliability progressively degrades during execution. We introduce the Noise Proxy Circuit (NPC), which removes all logical operations while preserving the complete sequence of noise channels, thereby providing an abstraction of cumulative noise effects. Based on the NPC, we define Proxy Fidelity, a reliability metric that quantifies both qubit-level and circuit-level reliability. We further develop an analytical algorithm to estimate Proxy Fidelity under depolarizing, thermal relaxation, and readout error channels. The proposed framework achieves fidelity-level reliability estimation while remaining execution-free, scalable, and interpretable. Experimental results show that our method accurately estimates circuit fidelity, with an average absolute difference (AAD) ranging from 0.031 to 0.069 across diverse circuits and devices."}
{"id": "2602.18350", "categories": ["quant-ph", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18350", "abs": "https://arxiv.org/abs/2602.18350", "authors": ["Qi Zhang", "Anton Simen", "Carlos Flores-Garrigós", "Gabriel Alvarado Barrios", "Paolo A. Erdman", "Enrique Solano", "Aaron C. Kemp", "Vincent Beltrani", "Vedangi Pathak", "Hamed Mohammadbagherpoor"], "title": "Quantum-enhanced satellite image classification", "comment": null, "summary": "We demonstrate the application of a quantum feature extraction method to enhance multi-class image classification for space applications. By harnessing the dynamics of many-body spin Hamiltonians, the method generates expressive quantum features that, when combined with classical processing, lead to quantum-enhanced classification accuracy. Using a strong and well-established ResNet50 baseline, we achieved a maximum classical accuracy of 83%, which can be improved to 84% with a transfer learning approach. In contrast, applying our quantum-classical method the performance is increased to 87% accuracy, demonstrating a clear and reproducible improvement over robust classical approaches. Implemented on several of IBM's quantum processors, our hybrid quantum-classical approach delivers consistent gains of 2-3% in absolute accuracy. These results highlight the practical potential of current and near-term quantum processors in high-stakes, data-driven domains such as satellite imaging and remote sensing, while suggesting broader applicability in real-world machine learning tasks."}
{"id": "2602.18354", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18354", "abs": "https://arxiv.org/abs/2602.18354", "authors": ["Romain Dalidet", "Anthony Martin", "Gregory Sauder", "Sébastien Tanzilli", "Laurent Labonté"], "title": "Quantum-enhanced phase sensitivity in an all-fiber Mach-Zehnder interferometer", "comment": null, "summary": "Recent advances in quantum photonics have enabled increasingly robust protocols in optical phase estimation, achieving precisions beyond the standard quantum limit and approaching the Heisenberg limit. While intrinsic losses hinder the realization of unconditional super-sensitivity, reaching quantum advantage, defined as sensitivity surpassing that of any classical counterpart with identical resources, remains achievable. Here we experimentally demonstrate such an advantage using a fully fibered Mach-Zehnder-type interferometer operating at telecom wavelengths, free of post-selection. The scheme relies on the conversion of polarization-entangled photon pairs, a degree of freedom commonly favored for experimental convenience, into energy-time entanglement, which is particularly well suited for scalable fiber-based sensors. All system imperfections, including asymmetric losses and detector inefficiencies, are accounted for in the Fisher information analysis, yielding a measured quantum advantage of 10%. This result highlights the practicality of compact, alignment-free quantum interferometers for real-world sensing applications."}
{"id": "2602.18363", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18363", "abs": "https://arxiv.org/abs/2602.18363", "authors": ["Vidisha Aggarwal", "Boxi Li", "Eloisa Cuestas", "Tommaso Calarco", "Robert Zeier", "Alexei Ourjoumtsev", "Felix Motzoi"], "title": "Improving Single Excitation Fidelity in Rydberg Superatoms for Efficient Single Photon Emission", "comment": null, "summary": "Deterministic single photon emission from a Rydberg ensemble coupled to an optical cavity requires high-fidelity preparation of collective single excitations. In such a setup imperfect Rydberg blockade can lead to unwanted double excitations, which degrade photon indistinguishability. In this work we adapt the Derivative Removal by Adiabatic Gate (DRAG) technique, originally developed for superconducting qubits, to shape optical pulses that suppress double excitations in this atomic platform. By combining analytical modeling with numerical optimization, DRAG provides an improvement over conventional sine-squared pulses. Further optimization of pulse duration and atomic ensemble size identifies a parameter regime, distinct from that used in [Nature Photonics 17, 688 (2023)], that enhances the single excitation probability from the previous theoretical benchmark of 77% to 91.9%, approaching the fundamental limits set by decoherence in the system. Benchmarking against GRAPE (Gradient Ascent Pulse Engineering) confirms that DRAG operates close to the optimal control limit, while maintaining smooth, experimentally feasible pulse shapes. These results demonstrate the effectiveness and cross platform adaptability of DRAG for a high-fidelity single photon source."}
{"id": "2602.18375", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18375", "abs": "https://arxiv.org/abs/2602.18375", "authors": ["Bora Baran", "Tommaso Calarco", "Matthias M. Mueller", "Felix Motzoi"], "title": "Towards scalable multi-qubit optimal control via interaction decomposition in the diagonal frame", "comment": "18 pages, 6 Figures, 1 Table", "summary": "In this work, we introduce a general n-qubit formulation of control objectives that allows a control target to be specified in a diagonal frame, so that only the diagonal entries must be characterized, thus quadratically reducing the complexity of the cost functional in constrast to a full target matrix. We do so by representing any n-qubit unitary transformation as a diagonal phase map on the computational basis states, as they are naturally diagonalizable by unitarity. By using discrete derivative operators to analytically construct support-selective phase invariants, we enable to deterministically isolate and quantify any multi-qubit interactions encoded in the phase map. These phase invariants form a coordinate system for the formulation of specific control targets in terms of arbitrary desired multi-qubit interactions, without having to invert the diagonalization during the optimizatiion, solely relying on the experimentally accesible diagonal phases. To illustrate the framework, we synthesize two genuinely tripartite entangling gates, both, diagonal and non-diagonal. These are obtained with a single shaped microwave pulse, for a numerically simulated room-temperature nitrogen-vacancy center with a three qubit nuclear spin register, with durations of about a microsecond. These results represent a factor 10-100 reduction in operation time compared with the fastest existing NV-based entanglers that act on more than two qubits at once."}
{"id": "2602.18377", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.18377", "abs": "https://arxiv.org/abs/2602.18377", "authors": ["Markus Gross", "Hans-Martin Rieser"], "title": "Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach", "comment": "34 pages, 12 figures", "summary": "Quantum reservoir computers (QRCs) have emerged as a promising approach to quantum machine learning, since they utilize the natural dynamics of quantum systems for data processing and are simple to train. Here, we consider n-qubit quantum extreme learning machines (QELMs) with continuous-time reservoir dynamics. QELMs are memoryless QRCs capable of various ML tasks, including image classification and time series forecasting. We apply the Pauli transfer matrix (PTM) formalism to theoretically analyze the influence of encoding, reservoir dynamics, and measurement operations, including temporal multiplexing, on the QELM performance. This formalism makes explicit that the encoding determines the complete set of (nonlinear) features available to the QELM, while the quantum channels linearly transform these features before they are probed by the chosen measurement operators. Optimizing a QELM can therefore be cast as a decoding problem in which one shapes the channel-induced transformations such that task-relevant features become available to the regressor. The PTM formalism allows one to identify the classical representation of a QELM and thereby guide its design towards a given training objective. As a specific application, we focus on learning nonlinear dynamical systems and show that a QELM trained on such trajectories learns a surrogate-approximation to the underlying flow map."}
{"id": "2602.18381", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18381", "abs": "https://arxiv.org/abs/2602.18381", "authors": ["Marek Żukowski", "Paweł Cieśliński", "Marcin Markiewicz", "Konrad Schlichtholz"], "title": "Bell-GHZ nonclassicality of many-observer interwoven frustrated down conversions", "comment": "10 pages, 1 figure", "summary": "Frustrated down conversion is a process in which a quantum superposition of emissions from two separate parametric down-conversion processes gives rise to observable interference. Depending on the phase relation between the probability amplitudes associated with emissions by the first and second crystal, the process can be enhanced or suppressed. This is achieved by aligning the setup so that the signal and idler modes from the first crystal are fed into the second and constitute its signal-idler modes.\n  In Sci. Adv. 11, 1794 (2025), two-observer interwoven frustrated PDC processes produced interference effects based on path identity [Phys. Rev. Lett. 118, 080401 (2017)]. The signal and idler modes of source crystals I and II are arranged to fully overlap with the emission modes of crystals A and B, which serve as elements of measurement stations controlled by Alice and Bob. In the interwoven configuration, crystal A (B) receives the signal mode of crystal I (II) and the idler mode of crystal II (I), enabling interference between joint emission processes at the sources and at the measurement stations. It was conjectured that such interference may lead to new non-classical phenomena.\n  In arXiv:2508.19207 it was shown that the process violates the standard Clauser-Horne Bell inequality without additional assumptions, provided suitable measurement settings are used. Here we extend the interference scheme to more than two measurement stations and demonstrate a violation of one of the WWWZB inequalities. This indicates that the proposed approach may provide a general method for revealing non-classicality in a range of phenomena discussed in [Rev. Mod. Phys. 94, 025007 (2022)]. We also present a GHZ/Hardy-type argument that further highlights the paradoxical character of the interference."}
{"id": "2602.18388", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18388", "abs": "https://arxiv.org/abs/2602.18388", "authors": ["G. R. Di Carlo", "M. Samiotis", "A. Kamlapure", "M. Finkel", "N. Muthusubramanian", "M. W. Beekman", "N. Haider", "B. Segers", "S. Vallés-Sanclemente", "L. DiCarlo"], "title": "Qubit error bursts in superconducting quantum processors of Quantum Inspire: quasiparticle pumping and anomalous time dependence", "comment": null, "summary": "We investigate qubit error bursts in 5- and 7-transmon processors of similar design, fabrication and packaging, but with different types of qubit Josephson junctions. Measurements for each are performed in two refrigerators to discern device-specific from refrigerator-dependent characteristics. The duration and rate of bursts are device specific but within the range of prior experiments and consistent with ionizing radiation. We observe two unforeseen signatures specifically in the processor with Dolan junctions. First, increasing the rate of $π$ pulsing in the detection scheme shortens the recovery time to equilibrium, which is explained by a quasiparticle pumping mechanism. The second signature is an anomalous time dependence in the burst rate: a surge happens days or weeks after cooldown, followed by a strong suppression that persists until thermal cycling."}
{"id": "2602.18412", "categories": ["quant-ph", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.18412", "abs": "https://arxiv.org/abs/2602.18412", "authors": ["Ariel A. Galindo Duque", "Miguel A. Prado Reynoso", "Miguel Gonzalez", "Jorge G. Hirsch"], "title": "Participation Ratio as a Quantum Probe of Hierarchical Stickiness", "comment": "9 pages, 4 figures", "summary": "We investigate how quantum localization encodes the hierarchical stickiness that governs transport in mixed classical phase spaces. Using the periodically driven kicked top, we show that the participation ratio (PR) of coherent states in the Floquet eigenbasis resolves the same layered structure that appears classically as a multimodal distribution of finite-time Lyapunov exponents (FTLEs). To establish a quantitative correspondence, we introduce a Gaussian coarse graining of the FTLE matched to the intrinsic semiclassical resolution of coherent states. Both local correlations and global comparisons of probability distributions demonstrate that quantum and classical indicators agree optimally within a finite window of evolution times, where sticky structures are most clearly resolved. Our results promote the participation ratio from a global measure of chaos to a sensitive probe of hierarchical transport and provide a practical route for diagnosing anomalous localization in driven quantum systems."}
{"id": "2602.18080", "categories": ["hep-lat", "cond-mat.str-el", "hep-th", "nucl-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18080", "abs": "https://arxiv.org/abs/2602.18080", "authors": ["Fran Ilčić", "Ritajit Majumdar", "Emil Mathew", "Nathan Earnest-Noble", "Indrakshi Raychowdhury"], "title": "Observation of Robust and Coherent Non-Abelian Hadron Dynamics on Noisy Quantum Processors", "comment": "19 pages, 13 figres including supplementary information", "summary": "The real-time evolution of strongly interacting matter remains a frontier of fundamental physics, as classical simulations are hampered by exponential Hilbert space growth and entanglement-driven bottlenecks in tensor networks. This study reports the quantum simulation of hadron dynamics within a $(1+1)$-dimensional SU(2) lattice gauge theory using a 156-qubit IBM superconducting processor. Leveraging a hardware-efficient Loop-String-Hadron (LSH) encoding, we simulate the dynamics of the physical degrees of freedom on a $60$-site lattice in the weak-coupling regime, as a crucial step toward the continuum limit. We successfully observe the light-cone propagation of a confined meson and internal oscillations indicative of early-time hadronic breathing modes. Notably, these high-fidelity results were obtained directly from the quantum data via a differential measurement protocol, together with measurement error mitigation, demonstrating a robust pathway for large-scale simulations even on noisy hardware. To validate the results, we benchmarked the quantum algorithm and outcome from the quantum processor against state-of-the-art approximated classical algorithms using CPU -- based on tensor network methods and Pauli propagation method, respectively. Furthermore, we provide a quantitative comparison demonstrating that as the system approaches the weak-coupling or the continuum limit, the quantum processor maintains a consistent structural robustness where classical tensor networks and Pauli propagation methods encounter an onset of exponential complexity or symmetry violations as an artifact of approximation in the algorithm. These results establish a scalable pathway for simulating non-Abelian dynamics on near-term quantum hardware and mark a critical step toward achieving a practical quantum advantage in high-energy physics."}
{"id": "2602.18099", "categories": ["cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.18099", "abs": "https://arxiv.org/abs/2602.18099", "authors": ["Gioele Zambotti", "Erik Tonni"], "title": "A contour for the entanglement negativity of bosonic Gaussian states", "comment": "62 pages, 14 figures", "summary": "We construct a contour function for the logarithmic negativity and the logarithm of the moments of the partial transpose of the reduced density matrix for multimode bosonic Gaussian states of a free lattice model. In one spatial dimension, numerical results are obtained for harmonic chains either in the ground state or at finite temperature, by considering, respectively, either a subsystem made by two adjacent or disjoint blocks on the line or a bipartition of the circle. The contour function of the logarithmic negativity diverges only at the entangling points, while the contour function for the logarithm of the moments of the partial transpose is divergent also at the boundary of the bipartite subsystem, as functions of the position. In a two-dimensional conformal field theory, analytic expressions that describe these divergencies are discussed. In one spatial dimension, we explore the partial derivative of the logarithmic negativity of two adjacent intervals with respect to the logarithm of the harmonic ratio of their lengths while their ratio and the other parameters are kept fixed. Considering the ground state of the harmonic chain on the line and in the massive regime, we report numerical results showing that this quantity displays a monotonically decreasing behaviour."}
