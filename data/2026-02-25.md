<div id=toc></div>

# Table of Contents

- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 4]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 7]
- [nlin.CD](#nlin.CD) [Total: 3]
- [quant-ph](#quant-ph) [Total: 47]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [stat.ME](#stat.ME) [Total: 13]
- [hep-lat](#hep-lat) [Total: 4]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [math.OC](#math.OC) [Total: 11]
- [nlin.AO](#nlin.AO) [Total: 1]
- [eess.SY](#eess.SY) [Total: 3]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [cs.CE](#cs.CE) [Total: 2]
- [math.NA](#math.NA) [Total: 9]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [math.ST](#math.ST) [Total: 7]


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [1] [Spectral Decimation of Quantum Many-Body Hamiltonians](https://arxiv.org/abs/2602.20256)
*Feng He,Arthur Hutsalyuk,Giuseppe Mussardo,Andrea Stampiggi*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一种用于量子多体哈密顿量的谱退火理论，建立了谱统计与希尔伯特空间结构之间的定量联系，并通过特征对称性熵等指标揭示了系统中隐藏的对称性和可积性的涌现。


<details>
  <summary>Details</summary>
Motivation: 旨在发展一种系统性的谱退火理论，以定量探测统计混合谱中涌现的对称性，解决传统谱分析难以识别隐藏结构的问题。

Method: 基于统计混合的解析描述，推导出特征对称性子空间（CSS）大小的显式表达式，并引入特征对称性熵（CSE）作为有限尺度下的可观测量，应用于希尔伯特空间碎片化和无序导致的多体局域化体系。

Result: 发现CSS维度是底层对称性子空间的规模加权平均，能有效分离相关子空间；在碎片化系统中成功识别出近似泊松谱下的关联子系，在无序海森堡链中观察到可积性通过CSS缩小逐渐出现，并提取了交叉指数。

Conclusion: 谱退火是一种无偏、可控且计算成本低的多体谱分析工具，能够区分混沌动力学、统计混合和涌现可积性，为研究复杂量子系统提供了新方法。

Abstract: We develop a systematic theory of spectral decimation for quantum many-body Hamiltonians and show that it provides a quantitative probe of emergent symmetries in statistically mixed spectra. Building on an analytical description of statistical mixtures, we derive an explicit expression for the size of a characteristic symmetry sector (CSS), defined as the largest subsequence of levels exhibiting non-Poissonian correlations. The CSS dimension is shown to be the size-biased average of the underlying symmetry sectors, establishing a direct link between spectral statistics and Hilbert-space structure. We apply this framework to two paradigmatic settings: Hilbert-space fragmentation and disorder-induced many-body localization (MBL). In fragmented systems, the CSS reproduces the mixture prediction and isolates correlated subsectors even when the full spectrum appears nearly Poissonian. In the disordered Heisenberg chain, spectral decimation reveals the gradual emergence of integrability through a shrinking CSS, whose statistics exhibit signatures consistent with local integrals of motion. We introduce a characteristic symmetry entropy (CSE) as a finite-size scaling observable and extract, within accessible system sizes, the crossover exponents. Our results establish spectral decimation as a controlled, unbiased and computationally inexpensive diagnostic of hidden structure in many-body spectra, capable of distinguishing between chaotic dynamics, statistical mixtures, and emergent integrability.

</details>


### [2] [Hyperuniformity in active fluids reshape nucleation and capillary-wave dynamics](https://arxiv.org/abs/2602.20308)
*Raphaël Maire*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了非平衡超均匀流体中的成核现象，发现其受非平衡准势控制，且由于超均匀涨落的抑制，成核概率不再可分离为表面和体积项，并揭示了非互易动力学导致的细致平衡破缺。


<details>
  <summary>Details</summary>
Motivation: 探讨在大尺度涨落被强烈抑制时，非平衡超均匀流体中成核行为与传统平衡态成核的差异。

Method: 通过将全密度场动力学投影到相关集体变量上，分析非平衡超均匀流体中的成核过程。

Result: 发现成核由非平衡准势而非可逆形成功控制；成核概率无法分离为表面和体积贡献；考虑毛细波后显示出非互易动力学引起的细致平衡破缺。

Conclusion: 非平衡超均匀流体中的成核机制显著偏离经典理论，提出的新框架可用于识别常规活性流体中的非平衡特征。

Abstract: While nucleation in typical active and driven fluids often appears equilibrium-like, striking departures emerge when large-scale fluctuations are strongly suppressed. Here, we investigate nucleation in nonequilibrium hyperuniform fluids by projecting the full density-field dynamics onto relevant collective variables. We demonstrate that nucleation is governed by a nonequilibrium quasi-potential rather than the reversible work of formation. Surprisingly, because of the reduced hyperuniform fluctuations, the nucleation probability no longer separates into the usual surface and volume contributions. Furthermore, accounting for capillary waves reveals a clear breakdown of detailed balance driven by nonreciprocal dynamics. More broadly, our framework can be readily extended to identify nonequilibrium signatures in conventional active fluids.

</details>


### [3] [Fluctuation theorems for a non-Gaussian system](https://arxiv.org/abs/2602.20579)
*A. Saravanan,I. Iyyappan*

Main category: cond-mat.stat-mech

TL;DR: 本研究通过数值方法验证了非高斯系统中Jarzynski等式和Crook涨落定理的适用性，采用扩散-扩散系数模型描述异质热浴中的布朗粒子，并在时变谐势下进行等温过程，结果表明即使在较大过程时间下功分布仍为非高斯，但两个定理依然成立。


<details>
  <summary>Details</summary>
Motivation: 探究在非高斯位置分布和异质热浴环境下，传统涨落定理如Jarzynski等式和Crook定理是否仍然适用。

Method: 使用扩散-扩散系数模型将热浴异质性纳入考虑，令粒子迁移率随时间波动，并在时变谐势中对布朗粒子进行等温压缩或扩展；基于随机热力学框架计算做功并分析其统计特性。

Result: 数值结果表明Jarzynski等式和Crook涨落定理在该非高斯系统中仍被很好地满足，且功的分布始终呈现非高斯特征，即使在较长的过程时间下亦然。

Conclusion: Jarzynski等式与Crook涨落定理在具有非高斯统计特性的异质系统中依然成立，说明其普适性超越了高斯假设的限制。

Abstract: In this work, we numerically verify the Jarzynski equality and Crook fluctuation theorem for a Brownian particle diffusing in a heterogeneous thermal bath and hence having a non-Gaussian position distribution. We use the diffusing-diffusivity model to take the account of heterogeneity of the thermal bath where the mobility is considered as a fluctuating quantity. The Brownian particle is confined by a time-dependent harmonic potential. By changing the stiffness coefficient, we perform an isothermal process. We use the stochastic thermodynamics framework to calculate the work. We find that the Jarzynski equality and the Crook fluctuation theorem are convincingly satisfied for a non-Gaussion system. We also find that the work distribution is non-Gaussian for diffusing-diffusivity system even at a larger process time.

</details>


### [4] [Criticality Beyond Nonanalyticity: Intrinsic Microcanonical Signatures of Phase Transitions](https://arxiv.org/abs/2602.21003)
*Loris Di Cairano*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种基于有限系统大小下微正则熵导数的形态结构（如拐点和极值）来定义临界性的新方法，揭示了相变奇异性是系统尺寸增大过程中逐渐 sharpening 的结果，而非定义本身。


<details>
  <summary>Details</summary>
Motivation: 传统上相变由热力学极限下热力学势的非解析性定义，但该文旨在突破这一限制，探索在任意有限尺寸系统中即可识别的内在临界特征，从而建立更本质的临界性概念。

Method: 结合微正则拐点分析（MIPA）与Berlin-Kac球形模型，利用已知的有限N下闭式密度态函数，系统分析熵的一阶和二阶导数（如β_N(ε)和γ_N(ε)）中的拐点和峰值结构。

Result: 发现在逆温度β_N(ε)中的拐点和其导数γ_N(ε)中的显著峰构成了可控的拟临界轨迹，随着系统尺寸增大，该轨迹逐渐锐化并趋近于热力学极限下的宏观尖点。

Conclusion: 临界性本质上源于有限系统中熵导数的内在形态结构，奇异性只是其在热力学极限下的渐近表现；该方法提供了一种无需序参量的内在临界性定义。

Abstract: Phase transitions are conventionally defined by nonanalyticities of thermodynamic potentials in the thermodynamic limit. In this Letter, we show that the singularity is not the definition of criticality but its asymptotic outcome: criticality is already written in the microcanonical entropy derivatives at any finite size as intrinsic morphological structures -- inflection points and extrema. The singularity is then the endpoint of a sharpening process that evolves with increasing system size. Combining microcanonical inflection-point analysis (MIPA) with the Berlin-Kac spherical model -- for which the microcanonical density of states is known in closed form at every finite $N$ -- we systematically identify these structures in the energy profiles of entropy derivatives that encode the transition. An inflection point in the inverse temperature $β_N(ε)=\partial_εS_N$ and a pronounced peak in its derivative $γ_N(ε)=\partial^2_εS_N$ define a well-controlled pseudocritical trajectory whose controlled sharpening and drift culminate in the macroscopic cusp at the critical energy $ε_c$ in the thermodynamic limit. This establishes an intrinsic, order-parameter-free notion of criticality that precedes its singular asymptotic representation.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [5] [Elliptic mirror of the quantum Hall effect](https://arxiv.org/abs/2602.20174)
*C. A. Lütken*

Main category: cond-mat.str-el

TL;DR: 本文通过全纯模对称性统一了整数和分数量子霍尔效应，并利用镜像对称将其映射到可解的镜像模型，通过椭圆模型的相图和标度性质与实验及数值数据对比，发现理论预测与实验结果高度一致，但需改进的有限尺寸标度实验来确认其普适类归属。


<details>
  <summary>Details</summary>
Motivation: 试图通过模对称性和镜像对称性统一量子霍尔效应中的整数和分数现象，并解释实验中观测到的标度行为和临界指数。

Method: 利用镜像对称将难以处理的环面σ模型映射到具有拓扑保护的椭圆镜像模型，分析其相图和标度流几何，并与实验及数值模拟结果比较。

Result: 理论模型预测的临界去局域化指数ν_tor = 2.6051与数值模拟结果ν_num = 2.607±0.004高度一致；实验测得ν_exp = 2.3±0.2，模型提供了调和理论与实验差异的可能性。

Conclusion: 该模对称模型可能是描述量子霍尔效应的正确理论框架，但需更高精度的有限尺寸标度实验验证其是否真正属于量子霍尔普适类。

Abstract: Toroidal sigma models of magneto-transport are analyzed, in which integer and fractional quantum Hall effects automatically are unified by a {holomorphic modular symmetry}. By exploiting a quantum equivalence called \emph{mirror symmetry}, these models are mapped to tractable mirror models (also elliptic), in which topological protection is provided by more familiar winding numbers. Phase diagrams and scaling properties of elliptic models are compared to some of the experimental and numerical data accumulated over the past three decades. The geometry of scaling flows extracted from quantum Hall experiments is in good agreement with modular predictions, including the location of many quantum critical points. One conspicuous model %(arguably the simplest and most natural one) has a critical delocalization exponent $ν_{\rm tor} = 18 \ln 2 /(π^2 G^4) = 2.6051\dots$ ($G$ is Gauss' constant) that is in excellent agreement with the value $ν_{\rm num} = 2.607\pm\,.004$ calculated in the numerical Chalker-Coddington model, suggesting that these models are in the same universality class. The real delocalization exponent may be disentangled from other scaling exponents in finite size scaling experiments, giving an experimental value $ν_{\rm exp} = 2.3\pm 0.2$. The modular model suggests how these theoretical and experimental results may be reconciled, but in order to determine if these theoretical models really are in the quantum Hall universality class, improved finite size scaling experiments are urgently needed.

</details>


### [6] [Real-space construction and classification for time-reversal symmetric crystalline superconductors in 2D interacting fermionic systems](https://arxiv.org/abs/2602.20560)
*Yi-Ming Liu,Wei-Qiang Chen,Zheng-Cheng Gu*

Main category: cond-mat.str-el

TL;DR: 本文系统研究了在晶体对称性和时间反演对称性保护下，二维相互作用费米子体系中的拓扑超导体分类，发现了仅在相互作用费米子体系中存在的本征拓扑相，并给出了实空间构造方法。


<details>
  <summary>Details</summary>
Motivation: 现有的拓扑分类在包含晶体对称性和时间反演对称性的相互作用费米子体系中尚不完整，需要建立系统的分类框架。

Method: 采用显式的实空间构造方法，结合对称性群分析，对二维相互作用费米系统中的拓扑超导体进行系统分类。

Result: 发现了具有Z4和Z2分类的本征相互作用拓扑超导相，这些相无法在自由费米子或玻色子体系中实现；识别出由1D块（如双马约拉纳链）装饰形成的根态，并发现其可导致支持角零模的高阶拓扑相；验证了包含晶体与内禀对称性的二维FSPT体系的晶体等价原理。

Conclusion: 本文建立了二维相互作用费米子在晶体和时间反演对称保护下的拓扑超导体完整分类体系，揭示了本征相互作用效应带来的新拓扑物态，并为高阶拓扑超导体提供了实空间构造范式。

Abstract: Crystalline symmetry and time-reversal symmetry are commonly present in real superconducting materials. However, the topological classification of systems respecting these symmetries, particularly for interacting fermions, remains incomplete. In this work, we systematically classify time-reversal symmetry-protected crystalline topological superconductors in two-dimensional interacting fermionic systems using an explicit real-space construction. Among the resulting phases, we identify intrinsically interacting fermionic topological superconductors, i.e., phases that cannot be realized in either free-fermion or interacting bosonic systems. For spinless fermions with protecting symmetry group $C_4 \times Z_2^T$ or $D_4 \times Z_2^T$ (plus fermion parity), the intrinsic sector has a $Z_4$ classification. The corresponding root phases generating this $Z_4$ classification admit a transparent real-space construction in terms of decorated 1D blocks. These blocks are 1D fermionic symmetry-protected topological (FSPT) phases, realizable as double Majorana chains. We further find the corresponding $Z_4$ spinless intrinsic phases for wallpaper groups $p4$, $p4m$, and $p4g$. We also find an additional $Z_2$ intrinsically interacting phase for spinless fermions with wallpaper group $pm$, which is absent with the corresponding point-group symmetry alone. Moreover, these intrinsic phases naturally give rise to higher-order FSPT phases that support corner zero modes. Finally, we verify the crystalline equivalence principle for generic 2D interacting FSPT systems with both crystalline and internal symmetries.

</details>


### [7] [Kondo breakdown as an entanglement transition driven by continuous measurement](https://arxiv.org/abs/2602.20600)
*Debraj Debata,Abhirup Mukherjee,Siddhartha Lal*

Main category: cond-mat.str-el

TL;DR: 研究了局域磁场通过测量驱动的纠缠相变破坏Kondo屏蔽的现象，利用非微扰的URG方法推导出Kondo交换和局域磁场的耦合RG流方程，获得场依赖的RG相图，揭示了Kondo屏蔽相与局域磁矩相之间的转变及其临界行为。


<details>
  <summary>Details</summary>
Motivation: 从测量驱动的纠缠相变角度理解Kondo屏蔽被局域磁场破坏的机制，探索退相干与测量在量子系统动力学中的相互作用。

Method: 采用非微扰的Unitary Renormalization Group (URG) 方法，推导Kondo交换和局域磁场的耦合重正化群流方程，并构建场依赖的相图。

Result: 得到了描述Kondo屏蔽相、局域磁矩相及临界区域的固定点哈密顿量，发现相变对应于一种新的非费米液体行为；通过杂质谱函数和热化行为等特征识别纠缠相变。

Conclusion: 揭示了局域磁场作为连续观测者抑制杂质-环境纠缠的机制，阐明了Kondo物理中测量与退相干对量子态演化的关键影响。

Abstract: We study the breakdown of Kondo screening by a local magnetic field from the perspective of a measurement-driven entanglement transition in a monitored quantum system. Here, the Kondo coupling leads to the growth in entanglement of an impurity spin with it's fermionic environment, while the local field plays the role of a continuous observer. Using a non-perturbative Unitary Renormalization Group (URG) approach, we derive coupled renormalization-group flow equations for the Kondo exchange and the local field, and obtain a field-dependent RG phase diagram. The RG flows separate a low-energy Kondo-screened phase, where the impurity is absorbed into the Fermi sea and forms an entangled singlet with the conduction bath, from a polarized local-moment phase in which screening is frustrated and impurity-bath entanglement is suppressed. We identify the fixed-point Hamiltonians governing the two phases and the critical regime, and relate the transition to the emergence of a novel non-Fermi liquid. Various impurity signatures such as the spectral function and thermalisation of impurity observables are used to characterise this entanglement transition. These results offer insight into the interplay of decoherence and measurement in governing the dynamics of a prototypical quantum system.

</details>


### [8] [Parameterizing DFT+U+V from Hybrid Functionals: A Wannier-Function-Based Approach for Strongly Correlated Materials](https://arxiv.org/abs/2602.20814)
*Dmitry M. Korotin,Anna A. Anisimova,Vladimir I. Anisimov*

Main category: cond-mat.str-el

TL;DR: 提出了一种基于杂化泛函计算和Wannier函数投影的DFT+U+V参数化方法，通过构建共同的局域Wannier基组并最小化哈密顿量失配来确定有效的U和V参数，该方法在三种氧化物体系中验证有效，能准确再现杂化泛函结果且计算成本低。


<details>
  <summary>Details</summary>
Motivation: 为了在保持计算效率的同时提高DFT对强关联材料电子结构描述的准确性，需要一种可靠的方法来参数化包含 onsite 和 intersite Hubbard 项的DFT+U+V 方法。

Method: 使用Wannier函数投影构建半局域DFT与杂化泛函之间的共同局域基组，并通过最小化相关子空间内的哈密顿量失配来确定有效的Hubbard参数U和V。

Result: 该方法成功获得了可重现杂化泛函电子结构（包括带隙、态密度和磁矩）的DFT+U+V参数，并在MgO、NiO和V2O5三种不同电子特性的氧化物中验证了其有效性。

Conclusion: 所提出的参数化方法能够在显著降低计算成本的同时，准确描述强关联氧化物的电子结构，适用于结构弛豫和进一步的多体计算，兼具精度与效率。

Abstract: We present an approach to parameterize DFT+$U$+$V$ from hybrid-functional calculations using Wannier-function projections. The method constructs a common localized Wannier basis for both semilocal DFT and hybrid-functional calculations, then determines effective on-site ($U$) and intersite ($V$) Hubbard parameters by minimizing the Hamiltonian mismatch within the correlated subspace. This procedure yields interaction parameters that reproduce the hybrid-functional electronic structure at a fraction of the computational cost and allow efficient structural relaxations and further many-body calculations. We validate the workflow on three oxide systems with different electronic characters: MgO (wide-gap insulator), NiO (antiferromagnetic charge-transfer insulator), and V$_2$O$_5$ (d$^0$ transition-metal oxide). In all cases, the mapped DFT+$U$+$V$ parameters reproduce hybrid-functional band gaps, densities of states, and magnetic moments and improve upon semilocal DFT while maintaining computational efficiency.

</details>


### [9] [Entanglement Properties of the One-Dimensional Dimerized Fermi-Hubbard Model](https://arxiv.org/abs/2602.20990)
*Min-Chul Cha,Hoon Beom Kwon,Ji-Woo Lee,Myung-Hoon Chung*

Main category: cond-mat.str-el

TL;DR: 研究了一维二聚费米- Hubbard 模型的纠缠特性，发现1/2和3/4填充时存在两种不同的绝缘相，分别由能带隙和Mott间隙导致，可通过纠缠谱和纠缠熵区分。


<details>
  <summary>Details</summary>
Motivation: 探索一维二聚费米-Hubbard模型中不同填充下的绝缘相机制及其纠缠特性差异。

Method: 采用矩阵乘积态方法计算基态，并分析纠缠谱和半链纠缠熵的标度性质。

Result: 识别出1/2填充的电荷间隙源于能带结构并被排斥相互作用增强，3/4填充则呈现由相互作用主导的Mott间隙，两种绝缘相在纠缠谱分布和纠缠熵标度上有明显区别。

Conclusion: 1/2和3/4填充的绝缘相具有不同的物理起源，可通过纠缠特性有效区分。

Abstract: We study the entanglement properties of the one-dimensional dimerized Fermi-Hubbard model. Using a matrix-product-state approach, we compute the ground state and identify two insulating phases at 1/2- and 3/4-filling, along with a metallic phase, whose mechanisms can be characterized by their entanglement spectra. Our findings indicate that the two insulating phases are distinct, implying that the phase at 1/2-filling has a charge gap arising from the band gap, which is enhanced by repulsive interactions, while the phase at 3/4-filling exhibits a Mott gap resulting from particle interactions. This difference between the two insulating phases is reflected in the scaling properties of the half-chain entanglement entropy and the distribution of the entanglement spectrum.

</details>


### [10] [Probing frustrated spin systems with impurities](https://arxiv.org/abs/2602.21086)
*Maksymilian Kliczkowski,Jakub Grabowski,Maciej M. Maśka*

Main category: cond-mat.str-el

TL;DR: 研究了在受挫自旋-1/2 $J_1\!-\!J_2$ 海森堡链中两个局域自旋杂质之间的有效相互作用，结合微扰理论与大规模DMRG计算，揭示了杂质间相互作用随距离、耦合强度和磁阻挫的变化规律。


<details>
  <summary>Details</summary>
Motivation: 探索量子自旋液体中的局域杂质相互作用，以理解受挫磁性系统中不同相的特征及其探测手段。

Method: 采用二阶微扰理论结合大规模密度矩阵重正化群（DMRG）方法，计算杂质与宿主耦合下的杂质-杂质相互作用。

Result: 在弱耦合下，相互作用由宿主的静态自旋 susceptiblity 决定，在无能隙相中呈现振荡幂律衰减，并在SU(2)对称临界点有普适对数修正；在能隙二聚化相中呈指数衰减。中强耦合下出现边界主导的转变，表现出显著奇偶效应，表明RKKY类描述失效。

Conclusion: 杂质-杂质相互作用可作为探测受挫量子自旋液体的敏感工具，并为通过局域扰动区分无能隙和能隙相提供了可控框架。

Abstract: We investigate the effective interaction between two localized spin impurities embedded in a frustrated spin-1/2 $J_1\!-\!J_2$ Heisenberg chain. Treating the impurity spins as classical moments coupled locally to the host, we combine second--order perturbation theory with large--scale density matrix renormalization group (DMRG) calculations to determine the impurity--impurity interaction as a function of separation, coupling strength, and magnetic frustration. In the weak--coupling regime, we show that the interaction is governed by the the static spin susceptibility of the host and exhibits oscillatory power--law decay in the gapless phase, modified by universal logarithmic corrections at the SU(2)--symmetric critical point. In the gapped dimerized phase, the interaction decays exponentially with distance. For intermediate and strong impurity--host coupling, we observe a crossover to a boundary--dominated regime characterized by pronounced parity effects associated with the length of the chain segment between impurities, signaling a breakdown of the simple RKKY--like description. Our results establish impurity--impurity interactions as a sensitive probe of frustrated quantum spin liquids and provide a controlled framework for distinguishing gapless and gapped phases through local perturbations.

</details>


### [11] [Minimal loop currents in doped Mott insulators](https://arxiv.org/abs/2602.21206)
*Can Cui,Jing-Yu Zhao,Zheng-Yu Weng*

Main category: cond-mat.str-el

TL;DR: 本文研究了t-J模型在掺杂情况下的变分波函数，发现单空穴和双空穴态表现出截然不同的行为：单空穴形成共振‘猫态’，而双空穴则通过补偿局域环流形成紧束缚的d_xy配对，并与d_x²-y²超导通道共振，构成潜在的最小超导单元。


<details>
  <summary>Details</summary>
Motivation: 理解高温超导中掺杂对反铁磁背景的影响以及准粒子和配对机制的起源，特别是在偏离半填充时的非传统行为。

Method: 基于半填充时反铁磁性的精确描述和掺杂下的相位弦符号结构，构建变分波函数，并采用变分蒙特卡洛（VMC）模拟分析单空穴和双空穴掺杂态的性质。

Result: 单空穴态为共振‘猫态’，准粒子谱权重Z_k在k₀=(±π/2,±π/2)处峰值，但Landau对应关系失效，出现源自2×2环流的4×4磁化图案；双空穴态中，两个空穴融合成紧束缚的d_xy配对，并强烈共振于d_xy与d_x²-y²超导通道之间，尺寸约4×4格点，远小于AFM关联长度。

Conclusion: 揭示了一种新的空穴配对机制，表明即使在稀释掺杂下，这种由环流补偿形成的微型配对仍可作为稳定的超导基本单元，挑战了传统的准粒子图像并支持非朗道型激发的存在。

Abstract: For the $t$-$J$ model, variational wave functions can generally be constructed based on an accurate description of antiferromagnetism (AFM) at half-filling and an exact phase-string sign structure under doping. The single-hole-doped and two-hole-doped states, as determined by variational Monte Carlo (VMC) simulations, display sharply contrasting behaviors. The single-hole state constitutes a ``cat state'' that resonates strongly between a quasiparticle component and a local loop-current component, with approximately equal weights. In the ground state, the quasiparticle spectral weight $Z_{\mathbf{k}}$ peaks at momenta $\mathbf{k}_0 \equiv (\pm\fracπ{2},\pm\fracπ{2})$. The total-energy dispersion versus $\mathbf{k}$ agrees remarkably well with the Green function Monte Carlo results. However, Landau's one-to-one correspondence hypothesis for quasiparticles breaks down here with the incoherent component exhibiting intrinsic magnetization originating from a minimal $2\times2$ loop current that forms a $4\times4$ pattern on the square lattice--a finding in excellent agreement with density matrix renormalization group (DMRG) calculations. In the two-hole ground state, a new pairing mechanism is revealed: the two holes are automatically fused into a tightly bound object consisting of an incoherent $d_{xy}$ pairing along the diagonal direction by compensating the local loop currents. This hole pair is again a ``cat state'' that resonates strongly between the incoherent $d_{xy}$ and a coherent $d_{x^2-y^2}$ Cooper channel to gain substantial hopping energy. Its size extends over an area of about $4\times 4$ lattice spacings, much smaller than the divergent AFM correlation length, implying that it should survive as a minimal superconducting building block even in the dilute doping regime. Experimental implications and the generalization to the finite-doping case are briefly addressed.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [12] [Geometric investigation of chaos unfolding in Hamiltonian systems](https://arxiv.org/abs/2602.20682)
*L. Salasnich,F. Sattin*

Main category: nlin.CD

TL;DR: 本文通过Jacobi-Levi-Civita方程（JLCE）重新审视哈密顿系统中混沌的几何方法，发现混沌轨道中相邻轨迹的指数发散更接近于乘法离散过程，且在轨迹与能量边界碰撞的转折点处相对分离急剧增加。作者通过解析和数值分析论证了边界的散射细节决定了轨迹的混沌特性，并用参数共振理论（特别是Mathieu方程）解释了这些结果。


<details>
  <summary>Details</summary>
Motivation: 探索哈密顿系统中混沌行为的几何机制，理解混沌轨道中轨迹分离的非连续性特征及其物理根源。

Method: 采用Jacobi-Levi-Civita方程（JLCE），结合数值模拟和解析分析，研究两个低维动力系统的混沌行为，并结合参数共振理论进行解释。

Result: 发现混沌轨道中相邻轨迹的指数发散表现为离散的跳跃式增长，尤其在轨迹与边界碰撞时显著增强；边界的散射细节是决定混沌与否的关键因素。

Conclusion: 混沌行为在几何框架下可被理解为由边界散射引发的离散化指数发散，可通过参数共振（如Mathieu方程）有效建模。

Abstract: In this work we revisit the geometric approach to chaos in Hamiltonian dynamics, by means of the Jacobi-Levi-Civita equation (JLCE). We inspect numerically two low-dimensional dynamical systems; show that, along chaotic orbits, the exponential divergence between nearby trajectories quantified by the JLCE does not unfold in a continuous manner, rather is closer to a multiplicative discrete process: in correspondence of each turning point, where the trajectory bounces away from the boundary of the energetically allowed region, the relative separation increases sharply and abruptly. We highlight through analytical and numerical arguments that the chaotic rather than regular nature of the trajectory is determined by the details of the scattering with the boundary, and interpret these results in terms of parametric resonance theory, and specifically the Mathieu equation.

</details>


### [13] [Dynamics and non-integrability of the variable-length double pendulum: exploring chaos and periodicity via the Lyapunov refined maps](https://arxiv.org/abs/2602.21123)
*Wojciech Szumiński,Tomasz Kapitaniak*

Main category: nlin.CD

TL;DR: 本论文研究了变长度双摆系统的动力学与可积性，结合经典双摆和Atwood机的特点，采用Lyapunov精细图和Morales-Ramis理论分析混沌行为与非可积性。


<details>
  <summary>Details</summary>
Motivation: 理解高维非线性系统中的复杂动力学行为，如混沌、共振和分岔，并探索经典双摆系统长期未解的非可积性问题。

Method: 使用Lyapunov精细图（结合Poincaré截面、相-参数图和Lyapunov指数）分析系统的动力学行为，并应用Morales-Ramis理论结合Kovacic算法研究其可积性。

Result: 揭示了系统的周期、准周期和混沌行为，量化了混沌强度，并在特定参数下证明了系统的非可积性。

Conclusion: 该研究深化了对变长度双摆系统动力学的理解，提出的新方法有助于推动非线性动力学研究，并为经典双摆的非可积性证明迈出关键一步。

Abstract: This paper extends our previous work~(Szumiński and Maciejewski, 2024), where we explored the dynamics and integrability of the double-spring pendulum. Here, we investigate the variable-length double pendulum, a three-degree-of-freedom Hamiltonian system combining features of the classic double pendulum and the swinging Atwood machine. With its intricate dynamics, this system is crucial for studying nonlinear phenomena such as high-order resonances, chaos, and bifurcations. We address the challenges posed by high-dimensional phase spaces using a novel tool, the \textit{Lyapunov refined maps}, which integrates Poincaré sections, phase-parametric diagrams, and Lyapunov exponents. This framework comprehensively analyzes periodic, quasi-periodic, and chaotic behaviors. By measuring the strength of chaos, it also offers insights into the system's dynamical structure. Additionally, we apply Morales-Ramis theory to examine integrability, leveraging the differential Galois group of variational equations to establish non-integrability conditions. The Kovacic algorithm is used to analyze the solvability of higher-dimensional differential equations, complemented by Lyapunov exponent diagrams to exclude integrable dynamics under certain parameters. Our findings advance the fundamental understanding of variable-length pendulum dynamics, offering new insights and methodologies for further research with potential applications in adaptive robotics, energy harvesting, and biomechanics. Additionally, this work represents a significant step toward proving the long-sought non-integrability of the classical double pendulum.

</details>


### [14] [Geometry- and inertia-limited chaotic growth in classical many-body systems](https://arxiv.org/abs/2602.21149)
*Swetamber Das*

Main category: nlin.CD

TL;DR: 本文建立了局域相互作用经典多体系统的最大李雅普诺夫指数的哈密顿特异性上界，区分了不可违反的界限和包含集体模式信息的遍历天花板，并在热力学极限下发现遍历天花板趋近于惯性上限，表明混沌增长受惯性和相互作用几何结构的内在限制。


<details>
  <summary>Details</summary>
Motivation: 混沌不稳定性通常由最大李雅普诺夫指数量化，但对经典相互作用系统中其大小的普遍约束仍缺乏理解。因此，研究局域相互作用经典多体系统中最大李雅普诺夫指数的上界具有重要意义。

Method: 基于哈密顿流的瞬时稳定性约束，结合惯性尺度和相互作用势的曲率，推导出最大李雅普诺夫指数的显式上界，并通过一维耦合转子链（约瑟夫森结阵列）模型进行数值验证。

Result: 提出了两类上界：由局部曲率和惯性决定的不可违反界限，以及保留谱信息并反映集体模式的遍历天花板；后者在热力学极限下趋近于与温度和相互作用强度无关的惯性上限，并揭示了持续混沌增长的动力学禁阻区域。

Conclusion: 尽管经典系统不存在普适的混沌界限，但本研究表明一大类自然哈密顿系统中的混沌增长本质上受限于惯性和相互作用几何结构，从而设定了初始条件长期记忆丢失的最小微观时间尺度。

Abstract: Chaotic instability in many-body systems is commonly quantified by the largest Lyapunov exponent, yet general constraints on its magnitude in classical interacting systems remain poorly understood. Here we establish explicit, Hamiltonian-specific upper bounds on the largest Lyapunov exponent for classical many-body systems with local interactions. These bounds arise from instantaneous stability constraints on the Hamiltonian flow and are expressed in terms of inertial scales and the curvature of the interaction potential. We show that they naturally separate into two qualitatively distinct classes: non-violable bounds, controlled by worst-case local curvature scales and inertia and insensitive to spatial structure, and ergodic ceilings, which retain spectral information and encode collective modes and finite-size effects under generic dynamical evolution. For a paradigmatic one-dimensional coupled-rotor chain (Josephson junction array), the ergodic ceiling admits a closed analytic form and produces a dynamically inaccessible region for sustained chaotic growth in the Lyapunov exponent-energy plane, which we confirm numerically. In contrast to non-violable estimates, the ergodic ceiling yields a sharper constraint on chaotic growth by capturing collective suppression mechanisms absent at the level of local curvature alone. Remarkably, in the thermodynamic limit the ergodic ceiling asymptotically approaches an inertial ceiling that limits sustained Lyapunov growth, becoming independent of temperature and interaction strength. While classical systems do not admit universal chaos bounds, our results identify a broad class of natural Hamiltonian systems in which chaotic growth is inherently limited by inertia and interaction geometry, thereby setting a minimal microscopic timescale for long-time loss of memory of initial conditions.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [15] [Entanglement Barriers from Computational Complexity: Matrix-Product-State Approach to Satisfiability](https://arxiv.org/abs/2602.20299)
*Tim Pokart,Frank Pollmann,Jan Carl Budich*

Main category: quant-ph

TL;DR: 研究使用量子启发的虚时间传播（ITP）方法结合矩阵乘积态（MPS）求解3-SAT问题，发现其受限于由经典计算复杂性引起的纠缠壁垒，并揭示了#3-SAT的经典难度与量子纠缠之间的联系。


<details>
  <summary>Details</summary>
Motivation: 探索量子启发算法在NP完全问题上的应用极限，理解经典计算复杂性如何影响量子态的纠缠特性。

Method: 采用虚时间传播结合矩阵乘积态的方法处理3-SAT实例，并通过随机模型分析#3-SAT计数问题的复杂性与MPS纠缠性质的关系。

Result: 发现ITP中的纠缠壁垒源于经典的#P复杂性；非稳定化资源（non-Clifford操作）需求随系统规模超线性增长，表明该方法资源开销巨大。

Conclusion: 经典计算复杂性可在量子纠缠中体现，且ITP求解3-SAT需大量非Clifford资源，限制了其在经典和量子架构上的可扩展性。

Abstract: We approach the 3-SAT satisfiability problem with the quantum-inspired method of imaginary time propagation (ITP) applied to matrix product states (MPS) on a classical computer. This ansatz is fundamentally limited by a quantum entanglement barrier that emerges in imaginary time, reflecting the exponential hardness expected for this NP-complete problem. Strikingly, we argue based on careful analysis of the structure imprinted onto the MPS by the 3-SAT instances that this barrier arises from classical computational complexity. To reveal this connection, we elucidate with stochastic models the specific relationship between the classical hardness of the $\sharp$P $\supseteq$ NP-complete counting problem $\sharp$3-SAT and the entanglement properties of the quantum state. Our findings illuminate the limitations of this quantum-inspired approach and demonstrate how purely classical computational complexity can manifest in quantum entanglement. Furthermore, we present estimates of the non-stabilizerness required by the protocol, finding a similar resource barrier. Specifically, the necessary amount of non-Clifford operations scales superlinearly in system size, thus implying extensive resource requirements of ITP on different architectures such as Clifford circuits or gate-based quantum computers.

</details>


### [16] [A Symplectic Proof of the Quantum Singleton Bound](https://arxiv.org/abs/2602.20186)
*Frederick Dehmel,Shilun Li*

Main category: quant-ph

TL;DR: 本文提出了一种基于辛线性代数的稳定子量子纠错码的量子单例界证明，并用Lean4进行了形式化验证。


<details>
  <summary>Details</summary>
Motivation: 为了简化量子单例界的证明并使其更适合形式化验证，避免使用复杂的分析工具。

Method: 采用有限维辛向量空间的语言建模泡利算符，结合基于距离的擦除可纠正性和清洗引理，通过维度计数论证在辛稳定子框架内推导出界限。

Result: 成功推导出任意[[n, k, d]]稳定子码满足k + 2(d - 1) ≤ n，并完成了Lean4中的形式化证明。

Conclusion: 该方法突出了支撑量子单例界的代数结构，提供了一种更简洁且适合形式化验证的证明途径。

Abstract: We present a symplectic linear-algebraic proof of the Quantum Singleton Bound for stabiliser quantum error-correcting codes together with a Lean4 formalisation of the linear-algebraic argument. The proof is formulated in the language of finite-dimensional symplectic vector spaces modelling Pauli operators and relies on distance-based erasure correctability and the cleaning lemma. Using a dimension-counting argument within the symplectic stabiliser framework, we derive the bound \( k + 2(d - 1) \le n \) for any [[n, k, d]] stabiliser code. This approach isolates the algebraic structure underlying the bound and avoids the heavier analytic machinery that appears in entropy-based proofs, while remaining well-suited to formal verification.

</details>


### [17] [Quantum Simulations for Extreme Ultraviolet Photolithography](https://arxiv.org/abs/2602.20234)
*Tyler D. Kharazi,Stepan Fomichev,Shu Kanno,Takao Kobayashi,Juan Miguel Arrazola,Qi Gao,Torin F. Stetina*

Main category: quant-ph

TL;DR: 本文提出了一种基于量子模拟的算法，用于精确计算极紫外光刻中关键的光电吸收和光电子发射过程，以解决传统方法难以处理的高能衰变通道建模问题，并给出了资源估算，表明该方法在未来有望突破半导体微缩中的电子模糊瓶颈。


<details>
  <summary>Details</summary>
Motivation: 由于经典方法在模拟高能衰变通道（如光电吸收和光电子发射）时存在计算复杂度高或无法有效解析电离连续态的问题，导致EUV光刻中的‘blur’效应难以精确建模，因此需要发展新的计算方法。

Method: 提出了两种量子模拟算法：一是优化的相干时域光谱算法，用于解析92 eV下的光电吸收截面；二是基于第一性原理平面波的真实时间动力学模拟方法，结合能量窗口技术统一处理束缚态与离域散射态，以计算光电子动能谱。同时对典型光刻胶单体IMePh进行了逻辑资源估算。

Result: 对于IMePh分子，光电吸收模拟约需200个逻辑量子比特和10^9个非Clifford门每电路，约10^3次采样；而更复杂的光电子发射模拟则需要数千个逻辑量子比特、≥10^13个非Clifford门每电路及10^4次采样。

Conclusion: 高保真度量子模拟有望成为参数化多尺度宏观模型的关键工具，进而帮助克服半导体微缩中的电子模糊瓶颈。

Abstract: Extreme Ultraviolet (EUV) lithography is the state-of-the-art process in semiconductor fabrication, yet its spatial resolution is fundamentally limited by the ``blur'' originating from absorption of photons at 92 eV, which induce physical and chemical changes in the photoresist via excited state processes and electron cascades. Accurate modeling of these phenomena requires precise ab initio data for high-energy decay channels, specifically photoabsorption and photoelectron emission. These are computationally difficult for classical methods due to prohibitive scaling in simulating electron dynamics, or due to the inability to resolve the ionization continuum in an efficient manner. In this work, we present quantum simulation algorithms to compute these key observables. First, we introduce a coherent time-domain spectroscopy algorithm optimized to resolve the photoabsorption cross-section at the 92 eV operating frequency. Second, we develop a first-quantized plane-wave simulation to compute the photoelectron kinetic energy spectrum, utilizing real-time dynamics and energy windowing to treat bound and delocalized scattering states on equal footing. Additionally, we provide logical resource estimation for a model photoresist monomer, 4-iodo-2-methylphenol (IMePh), and demonstrate that 92 eV absorption sensitivity can be resolved using roughly $200$ logical qubits and $10^{9}$ total non-Clifford gates per circuit with approximately $10^3$ shots for the smallest instance. The more sophisticated photoemission algorithm that models the continuum explicitly, incurs gate costs of $\geq 10^{13}$ total non-Clifford gates per circuit, $10^4$ shots, and requires a few thousand logical qubits. These results establish high-fidelity quantum simulations as a key component to parameterize the multi-scale macroscopic models required to overcome the electron blur bottleneck in semiconductor miniaturization.

</details>


### [18] [Proof of a finite threshold for the union-find decoder](https://arxiv.org/abs/2602.20238)
*Satoshi Yoshida,Ethan Lake,Hayata Yamasaki*

Main category: quant-ph

TL;DR: 本文证明了在电路级局部随机误差模型下，表面码的并查集（UF）解码器存在有限的容错阈值，并提出了一个改进的误差聚类框架，为UF解码器和贪心解码器提供了严格的理论基础。


<details>
  <summary>Details</summary>
Motivation: 尽管UF解码器在数值模拟中表现出良好的错误抑制能力，但缺乏严格的阈值定理来证明其在超越仿真范围的误差模型下仍可实现容错，限制了其在容错量子计算中的理论可信度。

Method: 提出了一种精细化的误差聚类框架，扩展了以往用于分析元胞自动机和重正化群解码器的技术，通过证明误差簇可被更大缓冲区分离，从而实现对UF解码器行为的解析控制，并进一步分析其平均运行时间与容错性能。

Result: 证明了UF解码器在电路级局部随机误差模型下存在有限阈值；给出了并行UF解码器关于码长的拟多对数级平均运行时间上界；该框架同样证明了贪心解码器的有限阈值。

Conclusion: 本工作为UF类解码器在容错量子计算机中的实际应用提供了坚实的理论支撑，并建立了一个统一的分析框架，可用于研究多种实用解码器的容错性。

Abstract: Fast decoders that achieve strong error suppression are essential for fault-tolerant quantum computation (FTQC) from both practical and theoretical perspectives. The union-find (UF) decoder for the surface code is widely regarded as a promising candidate, offering almost-linear time complexity and favorable empirical error suppression supported by numerical evidence. However, the lack of a rigorous threshold theorem has left open whether the UF decoder can achieve fault tolerance beyond the error models and parameter regimes tested in numerical simulations. Here, we provide a rigorous proof of a finite threshold for the UF decoder on the surface code under the circuit-level local stochastic error model. To this end, we develop a refined error-clustering framework that extends techniques previously used to analyze cellular-automaton and renormalization-group decoders, by showing that error clusters can be separated by substantially larger buffers, thereby enabling analytical control over the behavior of the UF decoder. Using this guarantee, we further prove a quasi-polylogarithmic upper bound on the average runtime of a parallel UF decoder in terms of the code size. We also show that this framework yields a finite threshold for the greedy decoder, a simpler decoder with lower complexity but weaker empirical error suppression. These results provide a solid theoretical foundation for the practical use of UF-based decoders in the development of fault-tolerant quantum computers, while offering a unified framework for studying fault tolerance across these practical decoders.

</details>


### [19] [Time Crystals as Passively Protected Oscillating Qubits](https://arxiv.org/abs/2602.20269)
*Mert Esencan,A. I. Lvovsky,Berislav Buča*

Main category: quant-ph

TL;DR: 本文提出了一种通过耗散性玻色系统实现噪声子空间中持续振荡量子比特编码的方法，利用Bose-Hubbard双体模型中的强宇称对称性实现对退相干的被动保护。


<details>
  <summary>Details</summary>
Motivation: 保护开放量子系统中的信息免受退相干影响是量子计算的核心挑战，尤其是缺乏适用于动态量子比特的被动纠错方案。

Method: 采用驱动-耗散的玻色系统，在Bose-Hubbard双体模型中构建具有强宇称对称性的系统，分析其在热力学极限下的非定态行为及李维尔谱的相变特性。

Result: 发现当驱动强度超过临界点时，非定态可将量子信息存储在噪声子空间中；该系统对全局损耗和全局去相位均具有鲁棒性，相位扰动也能被动恢复。

Conclusion: 耗散性时间晶体动力学可作为保护动态量子信息的机制，为自稳定振荡量子比特提供了新途径。

Abstract: Protecting information against decoherence in open quantum systems remains a central challenge for quantum computing. In particular, passive error correction schemes have so far been limited to static memories rather than dynamical qubits. We demonstrate that a driven-dissipative bosonic system can encode a persistently oscillating qubit within a noiseless subsystem, realized explicitly in the Bose-Hubbard dimer (BHD). The strong parity symmetry of the model leads to degenerate stationary states. This symmetry is further broken into non-stationary states in the thermodynamic limit, which exhibit persistent oscillations. As the driving force increases, the Liouvillian spectrum of these states features a phase transition. Above the transition point, the non-stationary state encodes quantum information, preserving it in a noiseless subsystem. In addition to global loss that affects both bosonic modes identically, we further add global dephasing and show that the oscillating qubit is preserved. Finally, in order to gain additional physical insight, we study the effect of phase perturbation to both modes and observe that likewise they are passively protected, returning approximately to their initial configurations. These results establish dissipative time-crystalline dynamics as a mechanism for passive protection of dynamical quantum information, enabling autonomously stabilized oscillating qubits.

</details>


### [20] [Quantum algorithm for simulating resonant inelastic X-ray scattering in battery materials](https://arxiv.org/abs/2602.20270)
*Ignacio Loaiza,Alexander Kunitsa,Stepan Fomichev,Danial Motlagh,Diksha Dhawan,Soran Jahangiri,Juliane Holst Fuglsbjerg,Artur Izmaylov,Nathan Wiebe,Yaser Abu-Lebdeh,Juan Miguel Arrazola,Alain Delgado*

Main category: quant-ph

TL;DR: 提出了一种用于模拟富锂正极材料中分子团簇RIXS光谱的量子算法，利用量子相位估计和量子信号处理技术，展示了在不同活性空间下模拟的资源估算。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏精确的模拟方法，实验RIXS光谱的解释具有挑战性，因此需要开发准确的量子算法来辅助理解高容量正极材料的结构退化。

Method: 采用量子相位估计采样RIXS光谱，通过块编码偶极算符和量子信号处理实现格林函数传播子，制备包含散射跃迁振幅的量子态。

Result: 在PennyLane平台上对含20个轨道的类经典难题活性空间进行模拟，算法需要2.0×10^10个Toffoli门和414个逻辑量子比特。

Conclusion: 该量子算法为模拟复杂分子团簇的RIXS光谱提供了可行路径，尽管资源需求较高，但为未来研究富锂正极材料的电子结构提供了工具。

Abstract: Resonant inelastic X-ray scattering (RIXS) is the workhorse experimental technique for probing the structural degradation of higher-capacity cathode materials. However, the interpretation of experimental spectra is challenging due to the lack of accurate simulations. In this work, we propose a quantum algorithm for simulating the RIXS spectrum of molecular clusters hypothesized to form in Li-excess cathodes. The algorithm uses quantum phase estimation to sample the spectrum from a state encoding the scattering transition amplitudes of the cluster valence excitations. We prepare this state in the quantum computer using a block-encoding of the dipole operator and quantum signal processing to implement the Green's function propagator over intermediate core-excited states. To showcase the algorithm, we use a model cluster proposed in recent experimental works consisting of an oxygen dimer bonded to a manganese atom. Using the PennyLane software platform, we report resource estimation for simulating RIXS spectra for chemically motivated active spaces of increasing sizes. For a classically challenging active space with 20 orbitals, the algorithm requires $2.0 \times 10^{10}$ Toffoli gates and $414$ logical qubits.

</details>


### [21] [Pulse-level control for quantum resource preparation](https://arxiv.org/abs/2602.20275)
*K. De La Ossa Doria,T. Merlo Vergara,D. Goyeneche*

Main category: quant-ph

TL;DR: 提出一种基于优化电磁脉冲序列的超导transmon量子比特系统中的量子态制备方法，通过直接优化纠缠资源实现最小时间内的最大纠缠态制备。


<details>
  <summary>Details</summary>
Motivation: 缩短量子态制备时间以抑制退相干，提升近期量子硬件上算法的实用性。

Method: 采用优化的电磁脉冲序列而非离散量子门，直接针对量子关联（如concurrence和three-tangle）进行优化。

Result: 在两比特和三比特系统中均实现了最大纠缠态（如Bell、GHZ和W态），并减少了控制方案的有效表达性。

Conclusion: 该资源导向的方法不仅实现了快速高保真态制备，还在算法场景中因控制自由度降低而具备优势。

Abstract: Minimizing the time required for quantum state preparation is crucial to mitigate decoherence and enable practical quantum algorithms on near-term hardware. In this work, we introduce a technique for quantum state preparation in transmon-qubit systems using optimized electromagnetic pulse sequences rather than discrete quantum gates. By directly targeting quantum correlations instead of specific target states, we identify minimal-time pulse protocols that optimize relevant entanglement resources, such as concurrence and the three-tangle for two and three qubit systems, respectively. For the figures of merit considered, this approach successfully achieves maximal entanglement in each case: Bell, GHZ and W like states. Beyond state preparation, the resource-oriented nature of the approach leads to a reduced effective expressivity of the control scheme, a feature that represents an advantage in algorithmic settings where excessive control freedom is known to hinder performance.

</details>


### [22] [Spatial Entanglement Sudden Death in Spin Chains at All Temperatures](https://arxiv.org/abs/2602.20694)
*Samuel O. Scalet*

Main category: quant-ph

TL;DR: 证明了在任何有限温度下，自旋链上任意局域哈密顿量的吉布斯态具有有限的纠缠长度：移除至少等于纠缠长度的区间后，剩余的左右半链处于可分离态。


<details>
  <summary>Details</summary>
Motivation: 研究自旋链系统在有限温度下的纠缠特性，特别是吉布斯态的纠缠长度问题。

Method: 通过理论证明的方法，分析局域哈密顿量在有限温度下的吉布斯态的纠缠性质。

Result: 证明了在任何有限温度下，自旋链上任意局域哈密顿量的吉布斯态具有有限的纠缠长度。

Conclusion: 移除足够长的区间后，系统的左右部分将不再纠缠，处于可分离态。

Abstract: We prove a finite entanglement length for the Gibbs state of any local Hamiltonian on a spin chain at any finite temperature: After removing an interval of size at least equal to the entanglement length, the remaining left and right half-chains are in a separable state.

</details>


### [23] [Quantifying Effective Heterodyne Detection Efficiency with SI-Traceable Standards](https://arxiv.org/abs/2602.20301)
*Luiz Couto Correa Pinto Filho,Jesper B. Christensen,Anders Brusch,Mikael Lassen*

Main category: quant-ph

TL;DR: 提出了一种可追溯至国际单位制（SI）的平衡相干光接收机有效外差检测效率的校准方法，利用电谱分析仪测量外差拍频功率和本振散粒噪声方差，并结合等效噪声带宽进行修正，通过辐射计量标准实现光子通量的SI溯源，验证了该方法在自由空间和光纤耦合接收机中的有效性与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 准确校准相干光接收机对于评估相干通信、精密传感及连续变量量子密钥分发（CV-QKD）等系统的性能至关重要，特别是检测效率直接影响信道参数估计，但缺乏可溯源且具有不确定度评定的校准方法。

Method: 基于散粒噪声参考的测量方法，利用电谱分析仪获取外差拍频功率和本振散粒噪声方差，结合等效噪声带宽（ENBW）修正，并通过经校准的辐射计量标准将信号路径中的光子通量溯源至SI单位。

Result: 在自由空间接收机上验证了该协议，结果与独立构建的光学衰减链一致；进一步应用于光纤耦合偏振保持平衡接收机，证实其在MHz中频下的实用性和鲁棒性。

Conclusion: 建立了一个可溯源、具有不确定度边界的实时接收机校准框架，为CV-QKD及其他相干光系统提供了实用的校准路径。

Abstract: Accurate calibration of coherent optical receivers is essential for reliable performance assessment in coherent communications, precision and quantum sensing, and continuous-variable quantum key distribution (CV-QKD), where the effective detection efficiency directly impacts channel parameter estimation. We present a methodology traceable to the International System of Units (SI) to determine the effective heterodyne detection efficiency of balanced receivers using shot-noise-referenced measurements. The protocol relies on two observables acquired with an electrical spectrum analyzer: the heterodyne beat-note power and the local oscillator shot-noise variance, with explicit treatment of the analyzer's equivalent noise bandwidth (ENBW). The photon flux in the signal path is referenced to SI units via calibrated radiometric standards. We first validate the protocol on a free-space receiver, demonstrating consistency with an independently constructed optical loss chain across a wide range of signal powers and under controlled, calibrated attenuation. Extending the same estimator to a fiber-coupled, polarization-maintaining balanced receiver confirms that the protocol is robust for practical coherent-receiver architectures and intermediate frequencies in the MHz range. These results establish a traceable, uncertainty-bounded framework for real-time receiver calibration, providing a practical route for CV-QKD and other coherent optical systems.

</details>


### [24] [Non-Clifford symmetry protected topological higher-order cluster states in multi-qubit measurement-based quantum computation](https://arxiv.org/abs/2602.20612)
*Motohiko Ezawa*

Main category: quant-ph

TL;DR: 本文通过引入C^N Z门生成了具有(2N+1)体纠缠的非Clifford簇态，并研究了其对称性、边界态和在测量型量子计算中的应用。


<details>
  <summary>Details</summary>
Motivation: 探索超越传统Clifford簇态的强纠缠资源态，以支持更广泛的量子计算能力，特别是利用非Clifford操作实现通用量子计算。

Method: 通过将C^N Z门作用于|+>^n初态，系统性地构造短程纠缠的非Clifford簇态，并分析其Z_2^{even}×Z_2^{odd}对称性、非可逆对称性、Kennedy-Tasaki变换和弦序参量。

Result: 构造出由C^N Z门生成的(2N+1)体纠缠簇态；发现开链下存在2^{2N}重简并基态，对应每端N个自由边缘自旋；当N≥3时，系统的Z_2对称性为非Clifford型；这些态可用于测量型量子计算中的N-量子比特输入输出。

Conclusion: 推广的C^N Z簇态是具有丰富对称结构和拓扑边界态的非Clifford资源态，为基于测量的量子计算提供了新的多体纠缠平台。

Abstract: A cluster state is a strongly entangled state, which is a source of measurement-based quantum computation. It is generated by applying controlled-Z (CZ) gates to the state $\left\vert ++\cdots +\right\rangle $. It is protected by the $\mathbb{Z}_{2}^{\text{even}}\times \mathbb{Z}_{2}^{ \text{odd}}$ symmetry. By applying general quantum gates to the state $ \left\vert ++\cdots +\right\rangle $, we systematically obtain a general short-range entangled cluster state. If we use a non-Clifford gate such as the controlled phase-shift gate, we obtain a non-Clifford cluster state. Furthermore, if we use the controlled-controlled Z (CCZ) gate instead of the CZ gate, we obtain non-Clifford cluster states with five-body entanglement. We generalize it to the C$^{N}$Z gate, where $(2N+1)$-body entangled states are generated. The $\mathbb{Z}_{2}^{\text{even}}\times \mathbb{Z}_{2}^{\text{odd}}$ symmetry is non-Clifford for $N\geq 3$. We demonstrate that there emerge $2^{2N}$ fold degenerate ground states for an open chain, indicating the emergence of $N$ free spins at each edge. They can be used as an $N$-qubit input and an $N$-qubit output in measurement-based quantum computation. We also study the non-invertible symmetry, the Kennedy-Tasaki transformation and the string-order parameter in addition to the $\mathbb{Z}_{2}^{\text{even}}\times \mathbb{Z}_{2}^{\text{odd}}$ symmetry in these models.

</details>


### [25] [No change in Hilbert space fundamentalism](https://arxiv.org/abs/2602.20331)
*Ovidiu Cristinel Stoica*

Main category: quant-ph

TL;DR: 本文探讨了希尔伯特空间基本主义（HSF）无法解释物理世界随时间变化的观测现象。


<details>
  <summary>Details</summary>
Motivation: 探讨HSF是否能够充分描述现实中的时间演化问题。

Method: 通过分析HSF框架下时间变化的可观测性，指出其在描述动态物理世界时的不足。

Result: 发现HSF不能解释我们观察到的物理世界随时间变化的现象。

Conclusion: HSF在当前形式下不足以完全描述现实世界的动力学特性。

Abstract: Hilbert space fundamentalism (HSF) states that everything about the physical world is encoded in the Hamiltonian operator and the state vector (as a unit vector, not a wavefunction, which requires additional specification of a configuration space, a position basis, or the position observables). That all structures needed to describe reality, including subsystems, space, fields, emerge from these.
  I show that HSF can't account for our observations that the physical world changes in time.

</details>


### [26] [Exact quantum transport in non-Markovian open Gaussian systems](https://arxiv.org/abs/2602.21190)
*Guglielmo Pellitteri,Vittorio Giovannetti,Vasco Cavina*

Main category: quant-ph

TL;DR: 提出了一种基于全计数统计和非马尔可夫主方程的精确框架，用于研究高斯热库与二次量子系统之间的热、能量和粒子输运，适用于任意耦合强度和初始状态，并揭示了依赖初态的瞬态负热导现象。


<details>
  <summary>Details</summary>
Motivation: 为了在任意强耦合和非平衡瞬态条件下精确描述量子系统中的热和粒子输运，克服传统方法如Landauer-Büttiker公式的局限性。

Method: 结合全计数统计与新发展的非马尔可夫主方程方法，构建了一个有效的主方程，可用于生成任意数量热库下热流统计的任意阶矩。

Result: 该理论适用于费米子和玻色子系统，在稳态弱耦合极限下可恢复类似Landauer-Büttiker的结果；并发现了一种依赖于系统初始制备的瞬态负热导现象。

Conclusion: 所提出的框架能够精确刻画多热库耦合量子系统的非平衡输运行为，揭示了初态调控下的非平庸瞬态动力学，为量子热力学实验提供了理论工具。

Abstract: We build an exact framework to evaluate heat, energy, and particle transport between Gaussian reservoirs mediated by a quadratic quantum system. By combining full counting statistics with newly developed non-Markovian master equation approaches, we introduce an effective master equation whose solution can be used to generate arbitrary moments of the heat statistics for any number of reservoirs. This theory applies equally to fermionic and bosonic systems, holds at arbitrarily strong coupling, and resolves out-of-equilibrium transient dynamics determined by the system's initial state. In the steady-state, weak-coupling limit, we recover results analogous to those of the well-known Landauer-Büttiker formalism. We conclude our discussion by demonstrating an application of the method to a prototypical fermionic system. Our results uncover a regime of transient negative heat conductance contingent upon the initial system preparation, providing a clear signature of non-trivial out-of-equilibrium dynamics.

</details>


### [27] [Measurement-Guided State Refinement for Shallow Feedback-Based Quantum Optimization Algorithm](https://arxiv.org/abs/2602.20407)
*Lucas A. M. Rattighieri,Pedro M. Prado,Marcos C. de Oliveira,Felipe F. Fanchini*

Main category: quant-ph

TL;DR: 提出了一种名为测量引导初始化（MGI）的迭代策略，利用先前测量结果优化后续运行的初态制备，提升浅层量子优化算法在NISQ设备上的性能。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，电路深度受限，浅层量子线路难以将概率充分集中在低能状态，限制了优化性能。需要一种不依赖经典参数优化的方法来提升浅层电路的优化能力。

Method: 从主导测量结果中提取单比特边缘概率，构造有偏的乘积态初态，用于后续迭代运行的初始化。该方法与FALQON结合，在无需经典参数优化的情况下实现信息复用。

Result: 数值实验表明，MGI能显著提升浅层电路在加权MaxCut问题上的优化性能，并支持解的质量随迭代逐步提升，同时保持算法的非变分结构。

Conclusion: 利用测量统计信息进行初态引导是一种有效增强浅层量子优化协议性能的方法，适用于当前NISQ设备。

Abstract: Limited circuit depth remains a central constraint for quantum optimization in the noisy intermediate-scale quantum (NISQ) regime, where shallow unitary dynamics may fail to sufficiently concentrate probability on low-energy configurations. We introduce Measurement-Guided Initialization (MGI), an iterative strategy that uses measurement outcomes from previous executions to update the initialization of subsequent runs. The method extracts single-qubit marginal probabilities from dominant measurement outcomes and prepares a biased product-state initialization, allowing information obtained during optimization to be reused without introducing classical parameter optimization. We implement this approach in the context of the Feedback-Based Algorithm for Quantum Optimization (FALQON) and evaluate its performance on weighted MaxCut instances. Numerical results show that measurement-guided initialization improves the performance of shallow-depth circuits and enables iterative refinement toward high-quality solutions while preserving the non-variational structure of the algorithm. These results indicate that measurement statistics can be exploited to improve shallow quantum optimization protocols compatible with NISQ devices.

</details>


### [28] [Quantum circuit design from a retraction-based Riemannian optimization framework](https://arxiv.org/abs/2602.20605)
*Zhijian Lai,Hantao Nie,Jiayuan Wu,Dong An*

Main category: quant-ph

TL;DR: 本文提出了一种基于黎曼优化的量子电路设计新框架，通过引入二阶优化方法RRSN，在更少的迭代次数内实现了高精度基态制备，显著优于传统变分量子算法和一阶梯度方法。


<details>
  <summary>Details</summary>
Motivation: 标准的变分量子算法受限于参数化电路表达能力不足和优化困难，现有几何方法主要集中于一阶梯度法，缺乏高效的二阶优化方法。

Method: 采用几何视角，将问题表述为在幺正群上直接最小化能量代价函数，建立了一个可实现在量子硬件上的回缩型黎曼优化框架，并提出了黎曼随机子空间牛顿（RRSN）方法，利用参数移动规则直接在量子硬件上估计黎曼海森矩阵。

Result: 数值模拟显示RRSN具有二次收敛性，相比一阶梯度法和标准VQA基线，能在显著更少的迭代中获得高精度基态。

Conclusion: 该工作为应用更广泛的高效黎曼算法进行量子电路设计提供了系统性基础。

Abstract: Designing quantum circuits for ground state preparation is a fundamental task in quantum information science. However, standard Variational Quantum Algorithms (VQAs) are often constrained by limited ansatz expressivity and difficult optimization landscapes. To address these issues, we adopt a geometric perspective, formulating the problem as the minimization of an energy cost function directly over the unitary group. We establish a retraction-based Riemannian optimization framework for this setting, ensuring that all algorithmic procedures are implementable on quantum hardware. Within this framework, we unify existing randomized gradient approaches under a Riemannian Random Subspace Gradient Projection (RRSGP) method. While recent geometric approaches have predominantly focused on such first-order gradient descent techniques, efficient second-order methods remain unexplored. To bridge this gap, we derive explicit expressions for the Riemannian Hessian and show that it can be estimated directly on quantum hardware via parameter-shift rules. Building on this, we propose the Riemannian Random Subspace Newton (RRSN) method, a scalable second-order algorithm that constructs a Newton system from measurement data. Numerical simulations indicate that RRSN achieves quadratic convergence, yielding high-precision ground states in significantly fewer iterations compared to both existing first-order approaches and standard VQA baselines. Ultimately, this work provides a systematic foundation for applying a broader class of efficient Riemannian algorithms to quantum circuit design.

</details>


### [29] [A quantum mechanical analysis of the coherence de Broglie wavelength for superresolution and enhanced sensitivity in a coupled interferometer scheme](https://arxiv.org/abs/2602.20410)
*B. S. Ham*

Main category: quant-ph

TL;DR: 本文提出了一种基于反称耦合马赫-曾德尔干涉仪中实现的相干德布罗意波长（CBW）的新型量子传感方法，可在无损耗情况下实现超分辨率和增强灵敏度，并给出了原理验证实验。


<details>
  <summary>Details</summary>
Motivation: 克服传统量子传感在光子损耗、N00N态光子数和压缩态压缩水平方面的限制，特别是在LiDAR和环形激光陀螺仪等对光子损耗敏感或需要大有效N的应用中。

Method: 采用纯量子力学分析方法，研究在反称耦合Mach-Zehnder干涉仪架构中实现的相干德布罗意波长（CBW）的特性，并进行原理验证实验。

Result: 实现了无光子损耗情况下的超分辨率和增强灵敏度的量子传感机制，并通过实验验证了CBW的可行性。

Conclusion: CBW为突破经典与量子传感限制提供了一种可行的新路径，具有在实际应用中推广的潜力。

Abstract: Quantum sensing has drawn considerable attention as a means to overcome the fundamental limitations in classical sensing. In practice, however, quantum sensing has been strongly constrained by the photon loss, the achievable photon number N in N00N states, and by a finite squeezing level in squeezed states. These limitations are particularly critical to photon-loss-sensitive applications such as LiDAR as well as to general sensing platforms that require large effective N, such as ring-laser gyroscopes. Recently, fundamentally different sensing platforms have been reported to overcome both classical and quantum constraints in a practical regime. One such approach exploits the coherence de Broglie wavelength (CBW) realized in an anti-symmetrically coupled Mach-Zehnder interferometer (MZI) architecture. Here, a pure quantum mechanical analysis of the CBW is presented for a loss-free sensing mechanism of superresolution with enhanced sensitivity. A proof-of-principle demonstration of CBW is also presented.

</details>


### [30] [A Unified Error Correction Code for Universal Quantum Computing with Identical Particles](https://arxiv.org/abs/2602.20452)
*S. L. Wu,Lian-Ao Wu*

Main category: quant-ph

TL;DR: 提出了一种基于相同粒子量子比特（IPQ）的通用容错量子计算架构，通过推广纠错操作至物理可实现的非幺正反向操作，实现了在物理比特内直接构建最简单的量子纠错码，并验证了动力学解耦和类无退相干子空间结构的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统量子比特与环境的一阶相互作用模型在相同粒子量子比特中不再适用，需重新设计抗退相干策略以适应新的物理机制。

Method: 引入可物理实现的非幺正反转操作，推广传统的纠错与恢复过程，并结合解析可解的IPQ-环境模型，分析动力学解耦和无退相干子空间结构的表现。

Result: 发现最简单的量子纠错码可直接在物理比特内实现，动力学解耦依然有效，并自然形成类似无退相干子空间的结构；模型具有解析解，且数值模拟验证了策略的有效性。

Conclusion: 该架构将逻辑比特与物理比特置于同等地位，为基于相同粒子量子比特的容错量子计算提供了严格且可行的理论基础与实现路径。

Abstract: We present a universal fault-tolerant quantum computing architecture based on identical particle qubits (IPQs), where we find that the first-order IPQ - bath interaction fundamentally differs from the conventional first-order qubit-bath interaction. This key distinction necessitates a redesign of existing strategies to fight decoherence. We propose that the simplest quantum error correction code can be realized directly within the physical qubit, provided that conventional correction and restoration are generalized beyond unitary operations to employ physically implementable reversal operations -- naturally placing logical and physical qubits on equal footing. We further demonstrate that dynamical decoupling (DD) remains effective within this unified framework, and that a decoherence-free subspace (DFS) -- like structure emerges. Unlike previous approximate treatments, our analytically solvable IPQ-Bath model enables rigorous testing of these strategies, with numerical simulations validating their effectiveness.

</details>


### [31] [Fundamentals of Quantum Machine Learning and Robustness](https://arxiv.org/abs/2602.20499)
*Lirandë Pira,Patrick Rebentrost*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum machine learning (QML) sits at the intersection of quantum computing and classical machine learning, offering the prospect of new computational paradigms and advantages for processing complex data. This chapter introduces the fundamentals of QML for readers from both communities, establishing a shared conceptual foundation. We connect the worst-case, adversarial perspective from theoretical computer science with the physical principles of quantum systems, highlighting how superposition, entanglement, and measurement collapse influence learning and robustness. Special attention is given to adversarial robustness, understood as the ability of QML models to resist inputs designed to cause failure. We motivate the study of QML in adversarial settings, outlining distinctions between classical and quantum data and computations when the adversary is a core element. This chapter serves as a starting point to adversarial and robust quantum machine learning in subsequent chapters.

</details>


### [32] [Hilbert Space Black Hole Analog: Unidirectional Transport without Driving](https://arxiv.org/abs/2602.20508)
*Elvira Bilokon,Valeriia Bilokon,Frank Großmann,Jason R. Williams,Denys I. Bondar*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Black holes permit matter to cross their event horizon in only one direction. We show that interacting bosons in optical lattices with asymmetric barrier exhibit an analogous phenomenon, creating unidirectional quantum transport without external driving or dissipation. This directionality emerges purely from many-body interactions, which cause asymmetric projection of the initial state onto transport-enabled or transport-forbidden sectors. The resulting dynamics create an effective one-way boundary in Hilbert space, forming a quantum analog of a black-hole event horizon. Our results establish interactions as a fundamentally new route to directional transport, enabling coherent rectification in atomtronic circuits by the use of intrinsic properties of the system only.

</details>


### [33] [Aging of coupled qubits](https://arxiv.org/abs/2602.20534)
*Huining Zhang,Dianzhen Cui,W. Wang,X. X. Yi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The aging transition refers to the shift from an oscillatory state to a globally ceased state due to some forms of deterioration in classical physics. Similar behavior has also been observed in quantum oscillators. Although it has received extensive attention in coupled oscillator systems, it has not yet been studied in coupled qubits. In this manuscript, we explore the aging transition in a network of coupled qubits. Our model describes {numerous} qubits driven by a laser, with both dissipative and coherent qubit-qubit couplings. The ratio of inactive qubits to total qubits and the population in the excited state of the qubits are employed to characterize the aging transition. We find a transition where the population in the excited states suddenly drops when the ratio exceeds a threshold. This behavior is intriguing and contrasts with coupled oscillators, where no sudden drop is observed. Additionally, we demonstrate how the couplings and driving laser influence the threshold. The underlying physics of the sudden drop is elucidated. The region where the aging transition occurs is determined based on stability analysis theory.

</details>


### [34] [Distilling Magic States in the Bicycle Architecture](https://arxiv.org/abs/2602.20546)
*Shifan Xu,Kun Liu,Patrick Rall,Zhiyang He,Yongshan Ding*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Magic State Distillation is considered to be one of the promising methods for supplying the non-Clifford resources required to achieve universal fault tolerance. Conventional MSD protocols implemented in surface codes often require multiple code blocks and lattice surgery rounds, resulting in substantial qubit overhead, especially at low target error rates.
  In this work, we present practical magic state distillation factories on Bivariate Bicycle (BB) codes that execute Pauli-measurement-based Clifford circuits inside a single BB code block. We formulate distillation circuit design as a joint optimization of logical qubit mapping, gate scheduling, measurement nativization, and protocol compression via qubit recycling. Based on detailed resource analysis and simulations, our BB factories have space-time volume comparable to that of leading distillation factories while delivering lower target error at a smaller qubit footprint, and are particularly compelling as second-round distillers following magic state cultivations.

</details>


### [35] [Assessing the Practical Feasibility of the Clader-Jacobs-Sprouse Quantum Algorithm for Calculating Radar Cross Sections](https://arxiv.org/abs/2602.20553)
*Edward Parker,Nicholas A. O'Donoughue,Alvin Moon,Nicolas M. Robles*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In 2013, Clader, Jacobs, and Sprouse developed a quantum computing algorithm that solves electromagnetic scattering problems exponentially faster than the best known classical algorithm for that problem. We examine this quantum algorithm's potential practical feasibility for modeling a target's radar cross section. Doing so could be important for modeling and predicting radar behavior against emerging targets.

</details>


### [36] [Effect of atom-oscillator interaction on the aging transition in coupled oscillators](https://arxiv.org/abs/2602.20568)
*Huining Zhang,X. Z. Hao,X. X. Yi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Oscillators are often employed as a model of radiation fields, which may couple to an atom and play an important role for creating and manipulating nonclassical states in quantum metrology, quantum simulation, and quantum information. Aging transitions in coupled oscillators have been studied extensively in both the classical and quantum contexts. It is well known that the onset of aging transitions can be modulated by the dissipative coupling between oscillators. In this study, we propose an alternative way to modulate the aging transition through coherent couplings between a two-level atom and the oscillators. Our findings reveal that, compared to atom-free systems in both classical and quantum regimes, the atom-oscillator coherent interaction reduces the inactive-to-total oscillator ratio required for aging transitions. Analytical results of the transition for both the classical oscillators and quantum oscillators suggest that the decay rate of the atom and the atom-oscillator coupling strength jointly change the aging transition point. The physics behind the observation is also elucidated in this article. Our research introduces a readily implementable strategy for manipulating aging transitions in more intricate systems, thereby advancing the control and understanding of these critical transitions in quantum technologies.

</details>


### [37] [First- and Second-Order Digital Quantum Simulation of Three-Level Jaynes-Cummings Dynamics on Superconducting Quantum Processors](https://arxiv.org/abs/2602.20614)
*J. Thirunirai Selvam,S. Saravana Veni,Ria Rushin Joseph*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work presents a digital quantum simulation of a three-level atomic system interacting with a single-mode electromagnetic field based on the Jaynes-Cummings model, implemented on IBM Quantum superconducting processors. A qutrit is encoded using two physical qubits to represent the atomic states, while an additional qubit encodes the truncated field mode, enabling the realization of effective $Λ$-type atomic dynamics.The continuous-time light-matter interaction is implemented in a digital form by discretizing the evolution using Suzuki-Trotter decomposition. In contrast to an analog realization, the digital simulation replaces the continuous evolution with a sequence of quantum gates whose parameters are explicitly controlled. Phase evolution arising from the interaction Hamiltonian is digitally encoded using calibrated $R_Z$ gates, whose rotation angles are fixed by the physically relevant coupling scale and the chosen Trotter time step.State preparation is achieved using Hadamard and parametrized rotation gates, while the interaction dynamics are implemented through controlled operations. A comparative analysis between first- and second-order Trotter implementations reveals a trade-off between digital accuracy and hardware-induced noise. Overall, the results demonstrate that calibrated gate operations and noise-aware circuit design enable reliable digital simulation of multi-level light-matter interactions on noisy intermediate-scale quantum platforms.

</details>


### [38] [Qudit stabiliser codes for $\mathbb{Z}_N$ lattice gauge theories with matter](https://arxiv.org/abs/2602.20661)
*Luca Spagnoli,Alessandro Roggero,Nathan Wiebe*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work we extend the connection between Quantum Error Correction (QEC) and Lattice Gauge Theories (LGTs) by showing that a $\mathbb{Z}_N$ gauge theory with prime dimension $N$ coupled to dynamical matter can be expressed as a qudit stabilizer code. Using the stabilizer formalism we show how to formulate an exact mapping of the encoded $\mathbb{Z}_N$ gauge theory onto two different bosonic models, uncovering a logical duality generated by error correction itself. From this perspective, quantum error correction provides a unifying language to expose dual descriptions of lattice gauge theories. In addition, we generalize earlier $\mathbb{Z}_2$ constructions on qubits to $\mathbb{Z}_N$ on $N$-level qudits and demonstrate how universal fault-tolerant gates can be implemented via state injection between compatible qudit codes.

</details>


### [39] [Task Concurrency and Compatibility in Measurement-Based Quantum Networks](https://arxiv.org/abs/2602.20674)
*Jakob Kaltoft Søndergaard,René Bødker Christensen,Petar Popovski*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Measurement-Based Quantum Networks (MBQNs) rely on multipartite pre-shared entanglement resources to satisfy entanglement requests. Traditional designs optimize these resources for individual tasks, neglecting that multiple tasks may arrive concurrently and compete for the same entanglement. We introduce compatibility as a design-level metric, capturing whether concurrent tasks can be satisfied by the same entanglement resources. We define a worst-case notion of compatibility where nodes are prevented from coordinating after task arrival and illustrate why tasks may be incompatible. Furthermore, we explore compatibility extensions that account for stochastic arrivals and the capability to supplement the pre-shared entanglement with additional entanglement on-demand, and show that incompatibility differs structurally dependent on the set of concurrent tasks. We argue that compatibility should be used for resource state design, building the foundation for determining which task pairs the network should support with pre-shared entanglement and which require execution-time coordination. Numerical simulations demonstrate this potential, with $(G,1)$-compatibility achieving a 40%-55% gain in simultaneously supported tasks relative to the single-task baseline. By incorporating compatibility as a fundamental design objective, quantum networks can move beyond single-task optimization towards scalable, robust architectures that effectively balance proactive entanglement distribution and supplemental reactive coordination.

</details>


### [40] [A note on entanglement detection via the generalized realignment moments](https://arxiv.org/abs/2602.20763)
*Xiaofen Huang,Xishun Zhu,Bin Chen,Naihuan Jing,Shao-Ming Fei*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The experimental detection of quantum entanglement is of great importance in quantum information processing. We present two separability criteria based on the generalized realignment moments. By incorporating additional parameters, these criteria prove to be more flexible and stronger than some of existing ones. Detailed examples are given to demonstrate their availability and feasibility for entanglement detection.

</details>


### [41] [Generative Deep Learning for the Two-Dimensional Quantum Rotor Model](https://arxiv.org/abs/2602.20772)
*Yanyang Wang,Feng Gao,Kui Tuo,Wei Li*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The advancement of diverse generative deep learning models and their variants has furnished substantial insights for investigating quantum many-body problems. In this work, we design two models based on the foundational architecture of generative adversarial networks (GANs) to investigate the ground-state properties and phase transition characteristics of the two-dimensional quantum rotor model (QRM). Within a semi-supervised learning framework, we incorporate multiple layers of transposed convolutions in the generator, enabling the conditional GAN to more efficiently extract low-dimensional encoded information. Analysis of one-dimensional latent variables associated with ground-state samples for different system sizes allows us to pinpoint the location of the critical point. In addition, we introduce dynamically adaptive weighting factors related to the distributional characteristics into the loss function of the deep convolutional GAN, and utilize upsampling techniques to enlarge the generated sample sizes. Comparisons of the optimization processes for mean magnetization and potential energy density across different magnetization regimes of QRM demonstrate that our model can efficiently generate valid ground-state samples, significantly reducing computational time. Our results highlight the promising potential of generative deep learning in quantum phase transition research, especially in critical point identification and the auxiliary generation of simulation data for quantum many-body models.

</details>


### [42] [Toward speedup without quantum coherent access](https://arxiv.org/abs/2602.20781)
*Nhat A. Nghiem*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Along with the development of quantum technology, finding useful applications of quantum computers has been a central pursuit. Despite various quantum algorithms have been developed, many of them often require strong input assumptions, which is hardware demanding. In particular, recent advances on dequantization have revealed that the quantum advantage is more of a mere artifact of strong input assumptions. In this work, we propose a variant of these algorithms, leveraging both classical and quantum resources. Provided the classical knowledge (the entries) of the matrix/vector of interest, a classical procedure is used to pre-process this information. Then they are fed into a quantum circuit which is shown to be a block encoding of the matrix of interest. From this block-encoding, we show how to use it to tackle a wide range of problems, including principal component analysis, linear equation solving, Hamiltonian simulation, preparing ground state, and data fitting. We also analyze our protocol, showing that both the classical and quantum procedure can achieve logarithmic complexity in the input dimension, thus implying its potential for near term realization. We then discuss several implications and corollaries of our result. First,, our results suggest there are certain matrices/Hamiltonians where our method can provide exponential improvement compared to the existing ones with respect to the sparsity. Regarding dense linear systems, our method achieves exponential speed-up with respect to the inverse of error tolerance, compared to the best previously known quantum algorithm for dense systems. Last, and most importantly, regarding quantum data fitting, we show how the output of our quantum algorithms can be leveraged to predict unseen data. Thus, it provides an end-to-end application, which has been an open aspect of the previous quantum data fitting algorithm.

</details>


### [43] [Quantum coherence of mixed states under noisy channels in noninertial frames](https://arxiv.org/abs/2602.20785)
*Tangrui Liao,Junhao Yang,Tinggui Zhang,Xiaofen Huang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We focus our attention on tripartite mixed states as initial states, and apply coherence concurrence to investigate quantum coherence properties in the background of a Schwarzschild black hole under phase damping, phase flip and bit flip channels, respectively. Several analytic complementary relationships based on coherence concurrence for tripartite subsystems are proposed. In the case of the bit flip channel, the behavior of the coherence concurrence is similar to the one of the phase damping channel, the accessible coherence concurrence always degrades as the Hawking acceleration rising, but sudden death never occurs, while the inaccessible coherence increases from zero monotonically. Interestingly, the coherence concurrence is decreasing at first and then increasing as the decay probability rising under phase flip channel. Unlike the case of tripartite pure states, the coherence concurrence of mixed state with X shape is equal to $l_1$ -norm of coherence.

</details>


### [44] [Quantum discord of mixed states under noisy channels in the curved spacetime](https://arxiv.org/abs/2602.20819)
*Yuxuan Xiong,Zhiling Pi,Tinggui Zhang,Xiaofen Huang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We focus our attention on two-qubit mixed states as initial states, and apply the geometric measure of quantum discord to investigate quantum discord properties in the background of a Schwarzschild black hole under phase damping, phase flip and bit flip channels, respectively. Several analytical complementary relationships based on quantum discords for bipartite subsystems are proposed. For the three channel noises, the behaviors of discords are similar, the accessible discords always degrade as the Hawking acceleration rising, but sudden death never occurs, while the inaccessible discords increase from zero monotonically. Interestingly, in the case of the bit flip channel and phase flip channel, the discords perform symmetrically with the decay probability rising.

</details>


### [45] [Mach-Zehnder interferometer for in-situ characterization of atom traps](https://arxiv.org/abs/2602.20824)
*Alexander Wolf,Maxim A. Efremov*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Manipulating cold atoms in traps is a key tool for numerous realizations of quantum simulators and quantum sensors. They require accurate modeling and characterization of the underlying trapping potentials. We introduce a technique based on the Mach-Zehnder interferometer for in-situ characterization of weakly anharmonic potentials. By simulating the interferometer in an optical dipole trap, we can accurately determine its trap frequency and upper bounds onto anharmonicity magnitudes.

</details>


### [46] [Simulating Microwave-Controlled Spin Imaging with Free-Space Electrons](https://arxiv.org/abs/2602.20852)
*Santiago Beltrán-Romero,Stefan Löffler,Dennis Rätzel,Philipp Haslinger*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Coherent spin resonance techniques, such as nuclear and electron spin resonance spectroscopy, have revolutionized non-invasive imaging by providing spectrally resolved information about spin dynamics. Motivated by the recent emergence of electron microscopy methods capable of sensing microwave-excitations, we establish a theoretical framework for Spin Resonance Spectroscopy (SRS) in transmission electron microscopy (TEM). This technique combines microwave pump fields with focused electron probe beams to enable state-selective spin imaging at the atomic scale. Using scattering theory, we model the interaction between free-space electrons and electron spin systems, capturing both elastic and inelastic processes. The strongest effect of the spin system on the free electron is a magnetic phase shift. Our simulations demonstrate that phase shifts from individual electron spins are detectable in both image mode and diffraction mode. In principle, differential measurements under microwave control allow the extraction of local resonance frequencies that are influenced by the surrounding spin environment. By evaluating the Classical Fisher Information (CFI), we identify imaging conditions that maximize the signal-to-noise ratio (SNR), showing how defocus and beam width affect the measurement sensitivity. These findings establish a foundation for integrating SRS with high-resolution TEM, bridging spin spectroscopy and atomic-scale imaging, and enabling new capabilities in quantum spin research and nanoscale materials characterization.

</details>


### [47] [$σ$-VQE: Excited-state preparation of quantum many-body scars with shallow circuits](https://arxiv.org/abs/2602.20881)
*Eoin Carolan,Nathan Keenan,Gabriele Cenedese,Giuliano Benenti*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present and benchmark a type of variational quantum eigensolver (VQE), which we denote the $σ$-VQE. It is designed to target mid-spectrum eigenstates and prepare quantum many-body scar states. The approach leverages the fact that noisy intermediate-scale quantum devices are limited in their ability to generate generic highly-entangled states. This modified VQE pairs a low-depth circuit with an energy-selective objective that explicitly penalizes energy variance around a chosen target energy. The cost function exploits the limited expressibility of the shallow circuit as atypical low-entanglement eigenstates such as scar states are preferentially selected. We validate this mechanism across two complementary families of models that contain many-body scar states: the Shiraishi-Mori embedding approach, and the matrix-product state parent Hamiltonian construction. We define an unbiased estimation scheme for the nonlinear cost function that is compatible with qubit-wise commuting grouping and bitstring reuse. A proof-of-principle demonstration using a small-system instance was carried out on IBM Fez (Heron r2 QPU). These results motivate its use both as a practical "scar detector" and as a state-preparation primitive for initializing nonthermal eigenstate-supported dynamics.

</details>


### [48] [Error correction with brickwork Clifford circuits](https://arxiv.org/abs/2602.20900)
*Twan Kroll,Jonas Helsen*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We prove that random 1D Clifford brickwork circuits form (in expectation) good approximate quantum error correction codes in logarithmic depth. Our proof makes use of the statistical mechanics techniques for random circuits developed by Dalzell et al. [PRX Quantum 3, 010333], adapted extensively to our own purpose. We also consider exact error correction, where we give matching upper and lower bounds for the required depth in which random 1D Clifford brickwork circuits become error correcting.

</details>


### [49] [Enhancing low-temperature quantum thermometry and magnetometry via quadratic interactions in optomechanical-like systems](https://arxiv.org/abs/2602.20905)
*Asghar Ullah,Özgür E. Müstecaplıoğlu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Standard optomechanical sensors operating in the low-temperature regime often face fundamental precision limits imposed by vacuum fluctuations. Here, we demonstrate that moving beyond conventional radiation-pressure interactions and exploiting quadratic coupling can surpass these limits, generating intrinsic squeezing and non-Gaussian features in the probe state. We study quantum thermometry and magnetometry in a coupled two-resonator system, focusing on the estimation of a thermal bath temperature and an external magnetic field. The resonators are assumed to be in thermal equilibrium with a common bath, while a weak magnetic field acts on one of the resonators. We perform measurements on a single resonator, which serves as the probe for estimating both parameters. We compute the quantum Fisher information of the probe for two different interaction models between the resonators. Our results show that the counter-rotating terms in the quadratic interaction naturally induce squeezing at intermediate coupling and strong non-Gaussian correlations as the coupling increases further. These effects yield orders-of-magnitude enhancement in sensitivity in the low-temperature and weak-field regimes compared to standard radiation-pressure couplings. Finally, we investigate multiparameter estimation and find that, although the optimal measurements remain compatible, statistical correlations between parameters prevent the simultaneous estimation of temperature and magnetic field from attaining single-parameter precision.

</details>


### [50] [Experimental Asynchronous Measurement-Device-Independent Quantum Cryptographic Conferencing](https://arxiv.org/abs/2602.20927)
*Yifeng Du,Yang Hu,Yufeng Liu,Wenhan Yan,Jinghao Zhang,Shining Zhu,Xiao-Song Ma*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The quantum cryptographic conferencing (QCC) protocol, which distributes identical secure keys to user groups, is a crucial component of the quantum network. Previous experimental works have implemented the measurement-device-independent (MDI) QCC, of which the key rate in an $N$-user network scales down as $R\sim O(η^N)$, respectively. Building on the MDI QCC protocol, the asynchronous MDI (AMDI) QCC protocol theoretically integrates the mode pairing scheme into QCC, significantly boosting the key rate to $R\sim O(η)$, which is independent of the number of users, and thus demonstrating greater application potential. Experimentally, in this work, we implement the three-user AMDI QCC network without global phase tracking by adopting the fast Fourier transform-based frequency difference estimation and the phase drift compensation technique. Finally, we achieve a key rate of about $4.470\times10^{-9}$ bits per pulse under a maximum overall loss of about 59.6 dB. This work provides a scalable solution for the development of large-scale quantum communication networks in the future.

</details>


### [51] [Adversarial Information Gain in Non-ideal Quantum Measurements](https://arxiv.org/abs/2602.20941)
*Andrés Muñoz-Moller,Leevi Leppäjärvi,Teiko Heinosaari*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Performing a quantum measurement yields two different results: a classical outcome drawn from a probability distribution, according to Born's rule, and a quantum outcome corresponding to the post-measurement state. Quantum devices that provide both outcomes can be described through quantum instruments. In a realistic scenario, one can expect that the observer's obtained classical and quantum outcomes are non-ideal: this can be due to experimental limitations, but could also be explained by adversarial interference, that is, a second party that disturbs the device through a concealed measurement to obtain information. The second scenario can be interpreted through quantum compatibility, as it implies that both the observer's instrument and the adversary's measurement can be performed simultaneously. In this work, we show how the noise of the observer's device relates to the amount of information that the adversary can obtain. We study scenarios in which the adversary aims to acquire information on the same basis as the observer's measurement, or on a mutually unbiased basis with respect to the observer's basis. In both cases, we derive necessary and sufficient conditions for the compatibility of a single qubit non-ideal quantum instrument and a noisy meter, from which we obtain the maximum amount of information that the adversary can extract in terms of the noise parameters of the observer's instrument. Finally, we provide the device implementation from the adversary's point of view for the same basis scenario.

</details>


### [52] [Quantum-limited detection of arrival time and carrier frequency of time-dependent signals](https://arxiv.org/abs/2602.20962)
*Patrick Folge,Laura Serino,Ladislav Mišta,Benjamin Brecht,Christine Silberhorn,Jaroslav Řeháček,Zdeněk Hradil*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Precise measurements of both the arrival time and carrier frequency of light pulses are essential for time-frequency-encoded quantum technologies. Quantum mechanics, however, imposes fundamental limits on the simultaneous determination of these quantities. In this work, we derive and experimentally verify the quantum uncertainty bounds governing joint time-frequency measurements. We show that when detection is restricted to finite time windows, the problem is naturally described by a quantum rotor, rendering the commonly used Heisenberg uncertainty relation inapplicable. We further propose an optimal detection scheme that saturates these fundamental limits. By sampling the Q-function, we demonstrate the reconstruction of the Wigner function beyond the harmonic oscillator. Using an experimental implementation based on a quantum pulse gate, we confirm that the proposed scheme approaches the ultimate quantum limit for simultaneous time-frequency measurements. These results provide a new framework for joint time-frequency detection with direct implications for precision measurements and quantum information processing.

</details>


### [53] [Entanglement-Induced Resilience of Quantum Dynamics](https://arxiv.org/abs/2602.20987)
*Tianfeng Feng,Yue Cao,Wenjun Yu,Junkai Zeng,Xiaopeng Li,Xiu-Hao Deng,Qi Zhao*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum many-body devices suffer from imperfections that destabilize dynamics and limit scalability. We show that the dynamical growth of entanglement can intrinsically protect generic quantum dynamics against coherent and perturbative noise. Through rigorous theoretical analysis of general quantum dynamics and numerical simulations of spin chains and fermionic lattices, we prove that entanglement-entropy growth confines the influence of local Hamiltonian perturbations, thereby suppressing errors in dynamical errors. The degree of protection correlates quantitatively with the entanglement entropy of subsystems on which the perturbations act, and applies broadly to both analog quantum simulators and real-time control protocols. This entanglement-induced resilience is conceptually distinct from quantum error correction or dynamical decoupling: it passively leverages native many-body correlations without additional qubits, measurements, or control overhead. Our results reveal a generic mechanism linking entanglement growth to dynamical stability and provide practical guidelines for designing noise-resilient quantum devices.

</details>


### [54] [Characterization-free classification and identification of the environment between two quantum players](https://arxiv.org/abs/2602.20997)
*Masahito Hayashi,Longyang Cao,Baichu Yu,Yuan-Yuan Zhao*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Classifying the causal structure of quantum channels is essential for verifying quantum networks and certifying quantum resources. We introduce a characterization-free protocol enabling two isolated players, Alice and Bob, to classify and identify the definite-order strategy adopted by an unknown environment mediating their channels. Without assuming knowledge of their devices or the environment, the players infer the causal order solely from input-output statistics by testing Markovian conditions that we prove are necessary and sufficient for each strategy class. Remarkably, we prove that even with a minimal random channel consisting of two-outcome POVMs and two-state preparations, the protocol retains full performance with probability one. We experimentally demonstrate the protocol on an optical platform, reliably distinguishing between several strategies. Our results provide a strong and robust tool for causal inference in quantum networks.

</details>


### [55] [Telemetry-Based Server Selection in the Quantum Internet via Cross-Layer Runtime Estimation](https://arxiv.org/abs/2602.21007)
*Masaki Nagai,Hideaki Kawaguchi,Shin Nishio,Takahiko Satoh*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Quantum Internet will allow clients to delegate quantum workloads to remote servers over heterogeneous networks, but choosing the server that minimizes end-to-end execution time is difficult because server processing, feedforward classical communication, and entanglement distribution can overlap in protocol-dependent ways and shift the runtime bottleneck. We propose $T_{\max}$, a lightweight runtime score that sums coarse telemetry from multiple layers to obtain a conservative ranking for online server selection without calibrating weights for each deployment. Using NetSquid discrete-event simulations of a modified parameter-blind VQE (PB-VQE) workload, we evaluate $T_{\max}$ on pools of 10,000 heterogeneous candidates (selecting among up to 100 per decision) across crossover and bottleneck-dominated regimes, including temporal jitter scenarios and jobs with multiple shots. $T_{\max}$ achieves single-digit mean regret normalized by the oracle (below 10%) in both regimes and remains in the single-digit range under classical communication latency jitter for multi-shot jobs, while performance degrades for single-shot jobs under severe jitter. To connect performance to deployment planning, we derive an operating map based on requirements relating distance and entanglement rate requirements to protocol level counts, quantify how simple multiuser contention shifts the crossover, and use Sobol global sensitivity analysis to identify regime-dependent bottlenecks. These findings suggest that simple cross-layer telemetry can enable practical server selection while providing actionable provisioning guidance for emerging Quantum Internet services.

</details>


### [56] [Restriction-Based Certificate of Bipartite Schmidt Rank in Hypergraph States](https://arxiv.org/abs/2602.21016)
*C. Fajardo,M. Paraschiv*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate bipartite entanglement in qubit hypergraph states across an arbitrary fixed bipartition. Using the real equally weighted (REW) representation, the Schmidt rank across the cut can be computed as the real rank of a phase-cleaned cross-cut sign matrix. Whereas graph states admit an exact cut-rank rule, because the cross-cut phase is purely bilinear, hypergraph states typically contain higher-degree cross-cut interactions, for which the cut-rank rule fails. Our approach certifies entanglement by fixing a single computational-basis assignment on a subset of qubits, thereby selecting a submatrix on an active slice. When this restriction removes all higher-degree cross-cut residues, the remaining cross-cut phase becomes bilinear up to cut-local terms. We call the resulting submatrices residual-free bilinear cores and show that they yield an exponential Schmidt-rank lower bound in terms of the $\mathbb{F}_2$-rank of an exposed core matrix. We further give a combinatorial sufficient condition, phrased as a disjoint bridge matching, that guarantees the existence of large full-rank cores for broad families of CCZ-type bridge patterns, and we present a search-and-verify procedure that constructs and certifies such cores directly from the hyperedge description.

</details>


### [57] [Asynchronous Multi-photon Interference for Quantum Networks](https://arxiv.org/abs/2602.21050)
*Baghdasar Baghdasaryan,Karen Lozano-Méndez,Markus Leipe,Meritxell Cabrejo-Ponce,Sabine Häussler,Kaushik Joarder,Tim Gühring,Stephan Fritzsche,Thorsten A. Goebel,Ria G. Krämer,Stefan Nolte,Carlos Andres Melo Luna,Yoshiaki Tsujimoto,Fabian Steinlechner*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Advanced quantum communication protocols require high-visibility quantum interference between photons generated at distant nodes, which places stringent demands on optical synchronization. Conventionally, synchronization of optical wave packets relies on pulsed sources and precise optical path stabilization. An alternative approach employs continuous-wave (CW) photon-pair sources, where temporal indistinguishability is enforced by post-selecting detection events within a coincidence window $τ_w$ shorter than the photon coherence time $T_c$. Despite its conceptual simplicity, the quantitative relation between relevant time scales, achievable interference visibility, and usable multi-photon rates has remained unclear. Here, we develop in detail and experimentally validate a theoretical framework that quantitatively describes time-resolved multi-photon interference in the CW regime. We explicitly incorporate detector timing jitter, photon coherence time, and temporal post-selection. The model is verified using four-photon Hong-Ou-Mandel interference measurements. Based on this validated framework, we determine the coincidence window that maximizes usable four-photon rates for a target visibility. Finally, we compare CW and pulsed SPDC sources under equivalent indistinguishability constraints and show that CW operation can achieve comparable rates while relaxing optical synchronization requirements.

</details>


### [58] [Correcting coherent quantum errors by going with the flow](https://arxiv.org/abs/2602.21076)
*Wayne M. Witzel,Anand Ganti,Tzvetan S. Metodi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The performance of a given quantum error correction (QEC) code depends upon the noise model that is assumed. Independent Pauli noise, applied after each quantum operation, is a simplistic noise model that is easy to simulate and understand in the context of stabilizer codes. Although such a noise model is artificial, it is equivalent to independent, random, unbiased qubit rotations. What about spatially or temporally correlated qubit rotations? Such a noise model is applicable to global operations (e.g., NMR or ESR), common control sources (e.g., lasers), or slow drift (e.g., charge or magnetic noise) in various qubit technologies. In the worst case, such errors can combine constructively and result in a post-correction failure rate that increases with the number of error correction cycles. However, we show that this worst case does not generally arise unless taking active corrective actions while performing QEC. That is, by employing virtual Pauli frame updates ("passive" error correction) rather than physical corrections ("active" error correction), coherent errors do not compound appreciably. Starting in a random Pauli frame is also advantageous. In fact, through perturbation theory arguments and supporting numerical simulations, we show that the logical qubit performance beyond distance 3 for correlated single-qubit Hamiltonian noise models (i.e., global errant qubit rotations), when employing these "lazy" strategies, essentially matches the performance of Pauli noise model with the same process fidelity (fidelity after one application). In a more general circuit model of noise, correlations may add constructively within syndrome extraction rounds but Pauli frame randomization from passive error correction mitigates this effect across multiple rounds.

</details>


### [59] [Quantum feedback algorithms for DNA assembly using FALQON variants](https://arxiv.org/abs/2602.21080)
*Pedro M. Prado,Lucas A. M. Rattighieri,Rafael Simões do Carmo,Giovanni S. Franco,Guilherme E. L. Pexe,Alexandre Drinko,Erick G. Dorlass,Tatiana F. de Almeida,Felipe F. Fanchini*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Reconstructing DNA sequences without a reference, known as de novo assembly, is a complex computational task involving the alignment of overlapping fragments. To address this problem, a usual strategy is to map the assembly to a Quadratic Unconstrained Binary Optimization (QUBO) formulation, which can be solved by different quantum algorithms. In this work, we focus on three versions of the Feedback-based Algorithm, a protocol that eliminates classical optimization loops via measurement feedback. We analyze long-read DNA fragments from SARS-CoV-2 and human mitochondrial DNA using standard FALQON, second-order FALQON (SO-FALQON), and time-rescaled FALQON (TR-FALQON). Numerical results show that both variants improve convergence to the ground state and increase success probabilities at reduced circuit depths. These findings indicate that enhanced feedback-driven dynamics are effective for solving combinatorial problems on near-term quantum hardware.

</details>


### [60] [On Hydrodynamic Formulations of Quantum Mechanics and the Problem of Sparse Ontology](https://arxiv.org/abs/2602.21106)
*Aric Hackebill,Bill Poirier*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Hydrodynamic reformulations of the Schrödinger equation suggest an interpretation of quantum mechanics in terms of a fluid flowing on configuration space. In the discrete hydrodynamic view, this fluid is not fundamental but emerges from many underlying microscopic fluid components whose collective behavior reproduces quantum phenomena. The most developed realization of this idea is the discrete many interacting worlds (MIW) framework, in which discrete particle-like worlds interact via inter-world forces and quantum probabilities are grounded in direct world counting. But there is also an older, continuous version of MIW. After reviewing the hydrodynamic and MIW formalisms, and emphasizing some of their interpretational advantages over the Everettian Many Worlds and Bohmian approaches, we argue that all discrete hydrodynamic models face a generic structural difficulty, which we call the problem of sparse ontology. Because wavefunctions typically branch under decoherence, the discrete components of the fluid are repeatedly partitioned into sub-ensembles, thereby thinning their density in configuration space and driving the dynamics away from the quantum regime once the components become sufficiently sparse. We conclude that successful hydrodynamic completions of quantum mechanics plausibly require an essentially continuous ontology.

</details>


### [61] [Quantum Approximate Optimization for Decoding of Low-Density Parity-Check Codes](https://arxiv.org/abs/2602.21124)
*Krishnakanta Barik,Goutam Paul*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Decoding Low-Density Parity-Check (LDPC) codes is a fundamental problem in coding theory, and Belief Propagation (BP) is one of the most popular methods for LDPC code decoding. However, BP may encounter convergence issues and suboptimal performance, especially for short-length codes and in high-noise channels. The Quantum Approximate Optimization Algorithm (QAOA) is a type of Variational Quantum Algorithm (VQA) designed to solve combinatorial optimization problems by minimizing a problem-specific cost function. In this paper, we present a QAOA-based decoding framework for LDPC codes by formulating a decoding cost function that incorporates both parity-check constraints and soft channel reliability information. The resulting optimization problem is solved using QAOA to search for low-energy configurations corresponding to valid codewords. We test the proposed method through extensive numerical experiments and compare its performance with BP decoding. The experimental results demonstrate that the QAOA-based decoder achieves a higher probability of correctly recovering the transmitted codeword than BP across multiple experimental settings.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [62] [The UK and Ireland Geophysical Array -- Concept and Design](https://arxiv.org/abs/2602.20984)
*Andrew Curtis,Karen Lythgoe,Stephen P. Hicks,Lidong Bie,Dominik Strutz,Emma Chambers,Brian Baptie,Dave Cornwell,Juliane Huebert,Jessica Irving,Glenn Jones,Sergei Lebedev,Walid Ben Mansour,Aideliz Montiel Álvarez,Stuart Nippress,Koen Van Noten,Tim Pharaoh,Romesh Palamakumbura,Nick Rawlinson,Pablo Rodriguez Salgado,James Verdon,Chuanbin Zhu,Wen Zhou,Jelle Assink,Ian Bastow,Dino Bindi,Tom Blenkinsop,Raffaele Bonadio,Michael Braim,Tim Craig,Elizabeth Day,Giovanni Diaferia,Stuart Dunning,Ben Edwards,Ake Fagereng,Stewart Fishwick,Amy Gilligan,David Green,David Healy,Anna Horleston,Mark Ireland,Jenny Jenkins,Jessica Johnson,Mike Kendall,Tom Kettlety,Duygu Kiyan,Paula Koelemeijer,Rita Kounoudis,Victoria Lane,Chuanchuan Lu,Alan MacDonald,Fabrizio Magrini,Auggie Marignier,Carl Martin,Martin Möllhoff,Iain Neill,Andy Nowacki,Bob Paap,Simone Pilia,Sjoerd de Ridder,Elmer Ruigrok,Peidong Shi,Anna Stork,Alice Turner,Jim Whiteley,Anton Ziolkowski*

Main category: physics.geo-ph

TL;DR: 本文提出了一项覆盖英国和爱尔兰的地震学仪器阵列（UKI Array）愿景，旨在通过多类型地球物理传感器研究地球深浅结构，解决资源与灾害问题，并促进公众特别是新一代对地球科学的兴趣。


<details>
  <summary>Details</summary>
Motivation: 为了最大化利用现有设备资源，推动对地球内部结构和自然现象的研究，应对地质灾害和资源挑战，并加强科学家与公众之间的联系。

Method: 通过社区参与的方式设计了一个覆盖广泛的地震学仪器阵列（UKI Array），并结合其他地球物理传感器进行综合观测。

Result: 提出了一个可行的UKI Array概念与设计方案，为后续科学研究、教育资源整合及公众参与提供了基础。

Conclusion: 该计划有望提升英国和爱尔兰在地球科学领域的研究能力，促进可持续发展和公众科学素养的提高。

Abstract: Scientific exploration of the UK and Ireland's subsurface has made important contributions to scholarship and prosperity for people and the planet, including economic growth, sustainable use of natural resources, storage of greenhouse gases, and inspiring curiosity about the Earth beneath our feet. This article outlines a vision for an array of seismological instruments spanning the UK and Ireland, UKI Array, augmented by other types of geophysical sensors, to maximise the value offered by existing equipment pools. The mission is to research natural phenomena and structure in the deep and shallow Earth, to solve problems concerning hazards and resources, to connect scientists to schools and the broader public, and thus to inspire a new generation to learn about geophysics. The vision was created through a community driven process of engagement and participation. This paper describes the concept and design of the UKI-Array; a companion paper discusses related opportunities and potential applications.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [63] [Modelling Interaction Duration in Relational Event Models](https://arxiv.org/abs/2602.21000)
*Rumana Lakdawala,Roger Leenders,Peter Ejbye-Ernst,Joris Mulder*

Main category: cs.SI

TL;DR: 本文提出了一种新的持续时间关系事件模型（DuREM），将事件的持续时间信息纳入分析，扩展了传统模型以同时建模事件的开始与结束，并通过两个案例展示了其应用。


<details>
  <summary>Details</summary>
Motivation: 传统的关系事件模型通常忽略事件的持续时间信息，而现实中许多关系事件数据包含持续时间。为了更全面地理解互动动态，有必要将持续时间纳入建模过程。

Method: 提出持续时间关系事件模型（DuREM），在现有框架基础上引入过去事件的持续时间作为内生统计量，并扩展风险集以同时包含可能结束的进行中事件和可能发起新事件的空闲配对，从而建模事件的开始与结束。

Result: 成功开发了DuREM模型及其对应的R包`durem`，并通过团队动态和人际暴力两个案例验证了模型的有效性与适用性。

Conclusion: DuREM能够有效整合事件持续时间信息，提升对关系事件动态的理解，为社会互动的时间模式分析提供了更丰富的工具。

Abstract: The study of relational events, which are interactions occurring between actors over time, has gained significant traction recently. Traditional relational event models typically focus on modelling the occurrence and sequence of events without considering their duration even though duration information is frequently available in empirical relational event data. We introduce a novel Duration Relational Event Model (DuREM) that incorporates the temporal duration of events into the analysis. The proposed model extends the existing framework by (i) allowing the inclusion of past event durations in the endogenous statistics to account for how the duration of past events affects the rate of future interactions, and (ii) extending the traditional relational event model by also modelling when events will end based on past event history and covariates. This is achieved by extending the risk set to include both ongoing events at risk of ending and idle dyads at risk of starting new events. The methodology is implemented in a new R package `durem'. Two case studies concerning team dynamics and inter-personal violence are presented to illustrate the applicability of the model.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [64] [Detecting and Mitigating Group Bias in Heterogeneous Treatment Effects](https://arxiv.org/abs/2602.20383)
*Joel Persson,Jurriën Bakker,Dennis Bohle,Stefan Feuerriegel,Florian von Wangenheim*

Main category: stat.ME

TL;DR: 本文提出了一种统一的统计框架，用于检测和缓解随机实验中因聚合个体预测治疗效果而导致的群体层面因果效应的系统性偏差，并提出了基于收缩的偏差校正方法。


<details>
  <summary>Details</summary>
Motivation: 在实践中，个体层面的治疗效果预测通常被聚合到更广泛的子群体中，但这种聚合可能导致群体层面因果效应的系统性偏差。

Method: 定义了群体偏差为模型隐含的与实验识别的GATE之间的差异，推导出渐近正态估计量，并提供简单的统计检验；提出基于收缩的偏差校正方法。

Result: 该框架具有通用性，仅需计算样本矩，且理论最优和实证可行解有闭式表达；应用大规模数字平台实验数据验证了理论结果和实证表现。

Conclusion: 所提出的框架能有效检测和缓解群体偏差，对利润最大化的个性化定位具有经济意义。

Abstract: Heterogeneous treatment effects (HTEs) are increasingly estimated using machine learning models that produce highly personalized predictions of treatment effects. In practice, however, predicted treatment effects are rarely interpreted, reported, or audited at the individual level but, instead, are often aggregated to broader subgroups, such as demographic segments, risk strata, or markets. We show that such aggregation can induce systematic bias of the group-level causal effect: even when models for predicting the individual-level conditional average treatment effect (CATE) are correctly specified and trained on data from randomized experiments, aggregating the predicted CATEs up to the group level does not, in general, recover the corresponding group average treatment effect (GATE). We develop a unified statistical framework to detect and mitigate this form of group bias in randomized experiments. We first define group bias as the discrepancy between the model-implied and experimentally identified GATEs, derive an asymptotically normal estimator, and then provide a simple-to-implement statistical test. For mitigation, we propose a shrinkage-based bias-correction, and show that the theoretically optimal and empirically feasible solutions have closed-form expressions. The framework is fully general, imposes minimal assumptions, and only requires computing sample moments. We analyze the economic implications of mitigating detected group bias for profit-maximizing personalized targeting, thereby characterizing when bias correction alters targeting decisions and profits, and the trade-offs involved. Applications to large-scale experimental data at major digital platforms validate our theoretical results and demonstrate empirical performance.

</details>


### [65] [Posterior Mode Guided Dimension Reduction for Bayesian Model Averaging in Heavy-Tailed Linear Regression](https://arxiv.org/abs/2602.20448)
*Shamriddha De,Joyee Ghosh*

Main category: stat.ME

TL;DR: 提出了一种结合最大后验估计与MCMC随机搜索的混合方法，用于在重尾误差框架下提高回归模型中变量选择和不确定性量化的效率和推断丰富性。


<details>
  <summary>Details</summary>
Motivation: 解决传统MCMC方法在大模型空间中易陷入局部、计算效率低，以及MAP估计无法提供不确定性量化的问题。

Method: 在双曲误差假设下，构建一个两步期望条件最大化（ECM）引导的MCMC算法：第一步通过ECM进行后验最大化并筛选变量，缩小模型空间；第二步在缩小后的空间上运行Gibbs抽样器进行后验计算。

Result: 模拟研究和真实数据实验表明，该方法在变量选择准确性和不确定性量化方面优于多种现有先进方法。

Conclusion: 所提混合方法有效平衡了计算效率与推断质量，适用于高维回归中的贝叶斯变量选择与后验推断。

Abstract: For large model spaces, the potential entrapment of Markov chain Monte Carlo (MCMC) based methods with spike-and-slab priors poses significant challenges in posterior computation in regression models. On the other hand, maximum a posteriori (MAP) estimation, which is a more computationally viable alternative, fails to provide uncertainty quantification. To address these problems simultaneously and efficiently, this paper proposes a hybrid method that blends MAP estimation with MCMC-based stochastic search algorithms within a heavy-tailed error framework. Under hyperbolic errors, the current work develops a two-step expectation conditional maximization (ECM) guided MCMC algorithm. In the first step, we conduct an ECM-based posterior maximization and perform variable selection, thereby identifying a reduced model space in a high posterior probability region. In the second step, we execute a Gibbs sampler on the reduced model space for posterior computation. Such a method is expected to improve the efficiency of posterior computation and enhance its inferential richness. Through simulation studies and benchmark real life examples, our proposed method is shown to exhibit several advantages in variable selection and uncertainty quantification over various state-of-the-art methods.

</details>


### [66] [Fast Algorithms for Exact Confidence Intervals in Randomized Experiments with Binary Outcomes](https://arxiv.org/abs/2602.20498)
*Peng Zhang*

Main category: stat.ME

TL;DR: 提出了一种基于随机化检验的精确平均处理效应置信区间构造方法，适用于所有样本量，在特定设计下显著减少所需检验次数。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖大样本近似，小样本或特定随机化设计下不适用，需要一种不依赖渐近理论的精确推断方法。

Method: 利用随机化检验序列构建精确置信区间，在平衡伯努利设计和配对设计下通过仅O(log n)次检验实现，在完全随机化设计下扩展至O(n log n)，并推广到一般伯努利设计使用O(n²)次检验。

Result: 实现了在多种随机化设计下的精确推断；在平衡设计下仅需O(log n)次检验，达到信息论下界，证明其最优性；揭示了不同设计间的计算复杂度差异。

Conclusion: 该方法为二元结果的随机实验提供了高效且精确的因果推断工具，尤其在小样本和特定设计下优于现有方法。

Abstract: We construct exact confidence intervals for the average treatment effect in randomized experiments with binary outcomes using sequences of randomization tests. Our approach does not rely on large-sample approximations and is valid for all sample sizes. Under a balanced Bernoulli design or a matched-pairs design, we show that exact confidence intervals can be computed using only $O(\log n)$ randomization tests, yielding an exponential reduction in the number of tests compared to brute-force. We further prove an information-theoretic lower bound showing that this rate is optimal. In contrast, under balanced complete randomization, the most efficient known procedures require $O(n\log n)$ randomization tests (Aronow et al., 2023), establishing a sharp separation between these designs. In addition, we extend our algorithm to general Bernoulli designs using $O(n^2)$ randomization tests.

</details>


### [67] [Hawkes Identification with a Prescribed Causal Basis: Closed-Form Estimators and Asymptotics](https://arxiv.org/abs/2602.20795)
*Xinhui Rong,Girish N. Nair*

Main category: stat.ME

TL;DR: 本文提出了一种用于Hawkes过程核函数识别的闭式最小二乘估计框架，证明了估计量在正确设定和模型误设下的收敛性，并建立了完整的渐近理论。


<details>
  <summary>Details</summary>
Motivation: Hawkes过程在建模具有记忆性的随机事件序列中广泛应用，但其核函数的非线性导致参数识别困难；现有基于预设基核的方法多依赖迭代似然法，且在模型误设下缺乏严格分析。

Method: 采用闭式最小二乘方法对带有预设核的Hawkes过程进行参数估计，利用经验Gram矩阵的几乎必然正定性保证估计量的存在性，并推导出两种情形下的中心极限定理。

Result: 证明了估计量在正确设定下收敛至真实参数，在误设下收敛至伪真参数，并给出了显式的渐近协方差结构；数值实验验证了理论结果。

Conclusion: 所提方法提供了可解释、稳健且具有完整渐近理论支持的Hawkes过程参数估计方案，适用于实际应用中可能存在的模型误设情况。

Abstract: Driven by the recent surge in neural-inspired modeling, point processes have gained significant traction in systems and control. While the Hawkes process is the standard model for characterizing random event sequences with memory, identifying its unknown kernels is often hindered by nonlinearity. Approaches using prescribed basis kernels have emerged to enable linear parameterization, yet they typically rely on iterative likelihood methods and lack rigorous analysis under model misspecification. This paper justifies a closed-form Least Squares identification framework for Hawkes processes with prescribed kernels. We guarantee estimator existence via the almost-sure positive definiteness of the empirical Gram matrix and prove convergence to the true parameters under correct specification, or to well-defined pseudo-true parameters under misspecification. Furthermore, we derive explicit Central Limit Theorems for both regimes, providing a complete and interpretable asymptotic theory. We demonstrate these theoretical findings through comparative numerical simulations.

</details>


### [68] [Local Fréchet regression with toroidal predictors](https://arxiv.org/abs/2602.20572)
*Chang Jun Im,Jeong Min Jeon*

Main category: stat.ME

TL;DR: 提出了首个同时处理一般度量空间响应和环面预测变量的回归框架，提出尊重响应和预测空间几何结构的局部常数和局部线性估计方法，并建立了其渐近性质。


<details>
  <summary>Details</summary>
Motivation: 现有回归方法难以处理响应变量位于一般度量空间且预测变量位于环面的情形，缺乏能同时尊重两种空间几何结构的回归框架。

Method: 提出基于内在距离的局部常数和局部线性估计器，利用流形上的几何结构进行非参数回归估计，并推导其渐近性质如一致性和收敛速率。

Result: 所提估计器在模拟研究和实际数据应用中表现出优越性能，局部线性估计器即使在标量响应情形下也具有新颖性。

Conclusion: 该框架有效整合了响应与预测变量的几何结构，为复杂数据类型提供了新的回归分析工具。

Abstract: We provide the first regression framework that simultaneously accommodates responses taking values in a general metric space and predictors lying on a general torus. We propose intrinsic local constant and local linear estimators that respect the underlying geometries of both the response and predictor spaces. Our local linear estimator is novel even in the case of scalar responses. We further establish their asymptotic properties, including consistency and convergence rates. Simulation studies, together with an application to real data, illustrate the superior performance of the proposed methodology.

</details>


### [69] [Combining Information Across Diverse Sources: The II-CC-FF Paradigm](https://arxiv.org/abs/2602.20885)
*Céline Cunen,Nils Lid Hjort*

Main category: stat.ME

TL;DR: 提出了一种结合多源数据信息的通用范式，包含独立检验、置信转换和聚焦融合三个步骤，适用于传统及复杂问题。


<details>
  <summary>Details</summary>
Motivation: 为了有效整合来自不同数据源的信息，特别是在传统方法难以处理的复杂问题中提供更优的统计推断方法。

Method: 该方法分为三步：首先对每个数据源进行独立检验，得到各参数的置信分布；然后通过置信转换技术将置信分布转化为置信对数似然函数；最后利用聚焦融合技术构建目标参数的置信分布。

Result: 在传统设置下，该方法与现有先进方法相当，并在实际应用示例中展示了其潜力。

Conclusion: II-CC-FF范式是一种具有广泛应用前景的多源信息融合框架，尤其适合处理复杂的统计问题。

Abstract: We introduce and develop a general paradigm for combining information across diverse data sources. In broad terms, suppose $φ$ is a parameter of interest, built up via components $ψ_1,\ldots,ψ_k$ from data sources $1,\ldots,k$. The proposed scheme has three steps. First, the Independent Inspection (II) step amounts to investigating each separate data source, translating statistical information to a confidence distribution $C_j(ψ_j)$ for the relevant focus parameter $ψ_j$ associated with data source $j$. Second, Confidence Conversion (CC) techniques are used to translate the confidence distributions to confidence log-likelihood functions, say $\ell_{{\rm con},j}(ψ_j)$. Finally, the Focused Fusion (FF) step uses relevant and context-driven techniques to construct a confidence distribution for the primary focus parameter $φ=φ(ψ_1,\ldots,ψ_k)$, acting on the combined confidence log-likelihood. In traditional setups, the II-CC-FF strategy amounts to versions of meta-analysis, and turns out to be competitive against state-of-the-art methods. Its potential lies in applications to harder problems, however. Illustrations are presented, related to actual applications.

</details>


### [70] [A Statistical Framework for Detecting Emergent Narratives in Longitudinal Text Corpora](https://arxiv.org/abs/2602.20939)
*Cynthia Medeiros,John Quigley,Matthew Revie*

Main category: stat.ME

TL;DR: 本文提出了一种基于潜在狄利克雷分配（LDA）的统计框架，用于检测经济文本语料库中叙事主题的出现，并通过学术出版物数据验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 叙事在经济行为和政策中具有重要影响，但其出现的统计识别方法尚不完善，尤其难以区分语言使用的常规变化与真正的结构性转变。

Method: 采用LDA模型分析纵向文本语料库，将“叙事出现”定义为主题相对显著性的持续上升，并构建统计框架来解释主题比例的时间轨迹。

Result: 在1970-2018年经济学文献数据中，与诺贝尔奖成果相关的主题显示出持续增长的趋势，且与引用活跃期和学科认可时期一致。

Conclusion: 基于模型的主题轨迹能够反映经济话语中的真实变化，为分析纵向文本数据中的主题演变提供了统计基础。

Abstract: Narratives about economic events and policies are widely recognised as influential drivers of economic and business behaviour. Yet the statistical identification of narrative emergence remains underdeveloped. Narratives evolve gradually, exhibit subtle shifts in content, and may exert influence disproportionate to their observable frequency, making it difficult to determine when observed changes reflect genuine structural shifts rather than routine variation in language use. We propose a statistical framework for detecting narrative emergence in longitudinal text corpora using Latent Dirichlet Allocation (LDA). We define emergence as a sustained increase in a topic's relative prominence over time and articulate a statistical framework for interpreting such trajectories, recognising that topic proportions are latent, model-estimated quantities. We illustrate the approach using a corpus of academic publications in economics spanning 1970-2018, where Nobel Prize-recognised contributions serve as externally observable signals of influential narratives. Topics associated with these contributions display sustained increases in estimated prevalence that coincide with periods of heightened citation activity and broader disciplinary recognition. These findings indicate that model-based topic trajectories can reflect identifiable shifts in economic discourse and provide a statistically grounded basis for analysing thematic change in longitudinal textual data.

</details>


### [71] [Estimating the Partially Linear Zero-Inflated Poisson Regression Model: a Robust Approach Using a EM-like Algorithm](https://arxiv.org/abs/2602.20965)
*María José Llop,Andrea Bergesio,Anne-Françoise Yao*

Main category: stat.ME

TL;DR: 本文提出了一种针对部分线性零膨胀泊松（PLZIP）模型的首个鲁棒估计方法，解决了传统模型在处理含过多零值且存在非线性关系的计数数据时对异常值敏感的问题。通过EM-like算法实现，并证明了算法收敛性和估计量的一致性，模拟和实际数据分析表明新方法具有良好的有限样本性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统计数模型难以有效处理含有过多零值且预测变量间存在非线性关系的数据，且基于似然的现有估计方法对异常值和模型假设偏离极为敏感，因此需要发展更鲁棒的估计方法。

Method: 提出一种新的鲁棒估计方法，利用PLZIP模型的混合结构特性，采用类似期望最大化（EM-like）算法来处理响应变量和协变量中的极端观测，并从理论上证明算法的收敛性和估计量的渐近一致性。

Result: 模拟研究表明，在不同污染情景下，所提方法相比经典估计方法在有限样本中表现出更强的鲁棒性和效率；并通过真实数据实例验证了该方法的应用效果。

Conclusion: 本文提出的鲁棒估计方法为PLZIP模型提供了更稳定可靠的分析工具，尤其适用于存在异常值或偏离假设条件的实际应用场景，具有良好的理论支持和应用前景。

Abstract: Count data with an excessive number of zeros frequently arise in fields such as economics, medicine, and public health. Traditional count models often fail to adequately handle such data, especially when the relationship between the response and some predictors is nonlinear. To overcome these limitations, the partially linear zero-inflated Poisson (PLZIP) model has been proposed as a flexible alternative. However, all existing estimation approaches for this model are based on likelihood, which is known to be highly sensitive to outliers and slight deviations from the model assumptions. This article presents the first robust estimation method specifically developed for the PLZIP model. An Expectation-Maximization-like algorithm is used to take advantage of the mixture nature of the model and to address extreme observations in both the response and the covariates. Results of the algorithm convergence and the consistency of the estimators are proved. A simulation study under various contamination schemes showed the robustness and efficiency of the proposed estimators in finite samples, compared to classical estimators. Finally, the application of the methodology is illustrated through an example using real data.

</details>


### [72] [Exchangeable Gaussian Processes for Staggered-Adoption Policy Evaluation](https://arxiv.org/abs/2602.21031)
*Hayk Gevorgyan,Konstantinos Kalogeropoulos,Angelos Alexopoulos*

Main category: stat.ME

TL;DR: 本文研究了在面板数据因果推断中使用可交换多任务高斯过程（GPs）的方法，适用于单一处理单位和多个处理单位的交错处理场景。


<details>
  <summary>Details</summary>
Motivation: 传统方法在建模非线性时间趋势和单位间异质性方面存在局限，需要更灵活的模型来提高因果推断的准确性。

Method: 提出使用可交换多任务高斯过程，通过GP先验建模处理组和对照组结果的联合演化，并采用不同核函数实现多种变体模型。

Result: 模型能够生成未处理潜在结果的后验预测分布，用于估计点态和累积处理效应及可信区间；在预干预窗口内进行安慰剂式验证以评估预测准确性。

Conclusion: 可交换高斯过程是面板数据政策评估中一种灵活有效的工具，尤其适用于具有大量处理和对照单位的交错处理设计。

Abstract: We study the use of exchangeable multi-task Gaussian processes (GPs) for causal inference in panel data, applying the framework to two settings: one with a single treated unit subject to a once-and-for-all treatment and another with multiple treated units and staggered treatment adoption. Our approach models the joint evolution of outcomes for treated and control units through a GP prior that ensures exchangeability across units while allowing for flexible nonlinear trends over time. The resulting posterior predictive distribution for the untreated potential outcomes of the treated unit provides a counterfactual path, from which we derive pointwise and cumulative treatment effects, along with credible intervals to quantify uncertainty. We implement several variations of the exchangeable GP model using different kernel functions. To assess prediction accuracy, we conduct a placebo-style validation within the pre-intervention window by selecting a ``fake'' intervention date. Ultimately, this study illustrates how exchangeable GPs serve as a flexible tool for policy evaluation in panel data settings and proposes a novel approach to staggered-adoption designs with a large number of treated and control units.

</details>


### [73] [Detecting Where Effects Occur by Testing Hypotheses in Order](https://arxiv.org/abs/2602.21068)
*Jake Bowers,David Kim,Nuole Chen*

Main category: stat.ME

TL;DR: 提出一种基于树结构的自上而下多重检验方法，显著提高在多区块政策实验中检测真实效应的能力，相比传统方法检测率提升约四倍，并提供R包manytestsr。


<details>
  <summary>Details</summary>
Motivation: 在公共政策的多区块随机试验中，传统多重检验校正方法（如Hommel）统计功效低，难以定位效应发生的具体区块，政策制定者需要更有效的分析工具。

Method: 构建树形检验结构：从整体效应开始，逐层检验区块组和单个区块，采用自上而下顺序检验并结合停止规则；通过分析拒绝概率在路径上的累积行为控制强族-wise错误率（FWER），必要时引入自适应α调整。

Result: 在模拟的44区块教育试验中，新方法在非零效应区块中的检测率达到44%，是Hommel方法（11%）的四倍；在25个MDRC教育试验中验证了方法的有效性，并开发了R包manytestsr供实际应用。

Conclusion: 该树形检验方法大幅提升了多重假设检验的检测能力，同时保持对FWER的有效控制，为公共政策评估提供了更敏感、可解释的分析框架。

Abstract: Experimental evaluations of public policies often randomize a new intervention within many sites or blocks. After a report of an overall result -- statistically significant or not -- the natural question from a policy maker is: \emph{where} did any effects occur? Standard adjustments for multiple testing provide little power to answer this question. In simulations modeled after a 44-block education trial, the Hommel adjustment -- among the most powerful procedures controlling the family-wise error rate (FWER) -- detects effects in only 11\% of truly non-null blocks. We develop a procedure that tests hypotheses top-down through a tree: test the overall null at the root, then groups of blocks, then individual blocks, stopping any branch where the null is not rejected. In the same 44-block design, this approach detects effects in 44\% of non-null blocks -- roughly four times the detection rate. A stopping rule and valid tests at each node suffice for weak FWER control. We show that the strong-sense FWER depends on how rejection probabilities accumulate along paths through the tree. This yields a diagnostic: when power decays fast enough relative to branching, no adjustment is needed; otherwise, an adaptive $α$-adjustment restores control. We apply the method to 25 MDRC education trials and provide an R package, \texttt{manytestsr}.

</details>


### [74] [Empirically Calibrated Conditional Independence Tests](https://arxiv.org/abs/2602.21036)
*Milleno Pan,Antoine de Mathelin,Wesley Tansey*

Main category: stat.ME

TL;DR: 提出了一种名为ECCIT的方法，用于校正条件独立性检验中的误校准问题，从而在控制错误发现率的同时提高检测功效。


<details>
  <summary>Details</summary>
Motivation: 现有的条件独立性检验在小样本或模型误设时难以准确控制错误发现率，缺乏实际有效的频率保证。

Method: 通过优化一个选择特征和响应函数以最大化误校准度量的对抗者，ECCIT测量并修正基测试的p值，拟合单调校准映射来调整p值。

Result: 在合成和真实数据上的实验表明，ECCIT相比现有校准策略能更有效地实现FDR控制，并具有更高的检验功效。

Conclusion: ECCIT是一种与具体检验方法无关的校准框架，能够在多种条件下提供可靠的统计推断结果。

Abstract: Conditional independence tests (CIT) are widely used for causal discovery and feature selection. Even with false discovery rate (FDR) control procedures, they often fail to provide frequentist guarantees in practice. We highlight two common failure modes: (i) in small samples, asymptotic guarantees for many CITs can be inaccurate and even correctly specified models fail to estimate the noise levels and control the error, and (ii) when sample sizes are large but models are misspecified, unaccounted dependencies skew the test's behavior and fail to return uniform p-values under the null. We propose Empirically Calibrated Conditional Independence Tests (ECCIT), a method that measures and corrects for miscalibration. For a chosen base CIT (e.g., GCM, HRT), ECCIT optimizes an adversary that selects features and response functions to maximize a miscalibration metric. ECCIT then fits a monotone calibration map that adjusts the base-test p-values in proportion to the observed miscalibration. Across empirical benchmarks on synthetic and real data, ECCIT achieves valid FDR with higher power than existing calibration strategies while remaining test agnostic.

</details>


### [75] [Robust and Sparse Generalized Linear Models for High-Dimensional Data via Maximum Mean Discrepancy](https://arxiv.org/abs/2602.21132)
*Xiaoning Kang,Lulu Kang*

Main category: stat.ME

TL;DR: 本文提出了一种基于最大均值差异（MMD）的L1正则化框架，用于广义线性模型（GLM）中的鲁棒估计与特征选择，解决了高维数据中异常值和重尾噪声导致传统方法偏差的问题。


<details>
  <summary>Details</summary>
Motivation: 高维数据常受异常值和重尾噪声影响，导致标准正则化估计量（如Lasso）产生严重偏差，而现有鲁棒方法在GLM中的变量选择方面研究不足。

Method: 提出一种L1正则化的MMD目标函数，构建了完整版（O(n²)）和高效近似版（O(n)）两种估计器，并采用结合AdaGrad的ADMM算法求解非凸优化问题。

Result: 在高斯线性回归和二元逻辑回归的仿真研究中，所提方法显著优于经典正则化GLM及现有鲁棒方法，尤其在处理高杠杆点和重尾误差分布时表现突出。

Conclusion: 该框架为高维GLM提供了一种有效的鲁棒估计与变量选择方法，在存在异常值和重尾噪声的情况下具有优越性能。

Abstract: High-dimensional datasets are frequently subject to contamination by outliers and heavy-tailed noise, which can severely bias standard regularized estimators like the Lasso. While Maximum Mean Discrepancy (MMD) has recently been introduced as a "universal" framework for robust regression, its application to high-dimensional Generalized Linear Models (GLMs) remains largely unexplored, particularly regarding variable selection. In this paper, we propose a penalized MMD framework for robust estimation and feature selection in GLMs. We introduce an $\ell_1$-penalized MMD objective and develop two versions of the estimator: a full $O(n^2)$ version and a computationally efficient $O(n)$ approximation. To solve the resulting non-convex optimization problem, we employ an algorithm based on the Alternating Direction Method of Multipliers (ADMM) combined with AdaGrad. Through extensive simulation studies involving Gaussian linear regression and binary logistic regression, we demonstrate that our proposed methods significantly outperform classical penalized GLMs and existing robust benchmarks. Our approach shows particular strength in handling high-leverage points and heavy-tailed error distributions, where traditional methods often fail.

</details>


### [76] [A Time-Varying and Covariate-Dependent Correlation Model for Multivariate Longitudinal Studies](https://arxiv.org/abs/2602.21200)
*Qingzhi Liu,Gen Li,Anastasia K. Yocum,Melvin McInnis,Brian D. Athey,Veerabhadran Baladandayuthapani*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In multivariate longitudinal studies, associations between outcomes often exhibit time-varying and individual level heterogeneity, motivating the modeling of correlations as an explicit function of time and covariates. However, most existing methods for correlation analysis fail to simultaneously capture the time-varying and covariate-dependent effects. We propose a Time-Varying and Covariate-Dependent (TiVAC) correlation model that jointly allows covariate effects on correlation to change flexibly and smoothly across time. TiVAC employs a bivariate Gaussian model where the covariate-dependent correlations are modeled semiparametrically using penalized splines. We develop a penalized maximum likelihood-based Newton-Raphson algorithm, and inference on time-varying effects is provided through simultaneous confidence bands. Simulation studies show that TiVAC consistently outperforms existing methods in accurately estimating correlations across a wide range of settings, including binary and continuous covariates, sparse to dense observation schedules, and across diverse correlation trajectory patterns. We apply TiVAC to a psychiatric case study of 291 bipolar I patients, modeling the time-varying correlation between depression and anxiety scores as a function of their clinical variables. Our analyses reveal significant heterogeneity associated with gender and nervous-system medication use, which varies with age, revealing the complex dynamic relationship between depression and anxiety in bipolar disorders.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [77] [Resolving the structure of bound states using lattice quantum field theories](https://arxiv.org/abs/2602.20373)
*Joseph Moscoso,Felipe G. Ortega-Gama,Raúl A. Briceño,Andrew W. Jackura,Charles Kacir,Amy N. Nicholson*

Main category: hep-lat

TL;DR: 本文首次通过格点计算研究了局部流的二粒子到二粒子矩阵元，利用无π介子有效场论在有限体积中精确对角化哈密顿量，结合Lüscher形式和近期推导的关系式，成功提取了无限体积下的散射振幅和束缚态弹性形状因子，并验证了深束缚态与浅束缚态下结果的预期行为。


<details>
  <summary>Details</summary>
Motivation: 实现对局部流的二粒子矩阵元的格点计算，并通过有限体积谱和矩阵元提取无限体积下的物理量，特别是束缚态的弹性形状因子，检验不同束缚深度下的理论预测。

Method: 采用领头阶无π介子有效场论描述两个核子，在三维有限空间体积中精确对角化哈密顿量；利用Lüscher形式约束无限体积下的纯强子振幅，并结合已有公式将有限体积矩阵元映射到包含流插入的反应振幅，进而提取束缚态弹性形状因子。

Result: 成功计算了支持氘核类束缚态耦合范围内的有限体积谱和局部矢量流矩阵元；通过形式论提取了无限体积下的反应振幅和弹性形状因子；发现深束缚态下有限体积效应可忽略，而浅束缚态下必须依赖有限体积形式论才能获得合理结果；在浅束缚极限下与反常阈值预言符合良好。

Conclusion: 该工作验证了有限体积格点方法用于局部流矩阵元计算的可行性，明确了浅束缚态下应用有限体积形式论的必要性，为未来QCD层面的类似计算提供了可靠框架和详细分析流程。

Abstract: This work presents the first lattice calculation of a two-to-two particle matrix element of a local current. This exploratory calculation is performed using a leading-order pionless effective field theory of two nucleons in a finite 3D spatial volume, where the Hamiltonian can be diagonalized exactly for moderate volumes. By considering a range of couplings where the theory supports a deuteron-like bound state, we determine the finite-volume spectra and matrix elements of the conserved local vector current. Using the Lüscher formalism, we constrain the infinite-volume, purely hadronic amplitude for this theory. Using previously derived formalism, we then map the finite-volume matrix elements to scattering amplitudes describing a reaction coupling two-particle states via a current insertion, $\2+\Jc \to \2$. We then use a recently derived relation between this class of amplitudes and the bound-state elastic form factor to directly constrain the infinite-volume form factor. By varying over a range of values of the coupling of the theory, we explore the effects of this analysis for deep-bound states and shallow-bound states. We reproduce the expected result that for deep bound states, the finite-volume formalism is largely unnecessary, while for shallow bound states, it is absolutely critical to obtain a sensible result. We present a detailed outline of the analysis of this class of matrix elements, including the determination of the charge radius of the bound state. In the shallow bound state limit, we find good agreement with the prediction stemming from the anomalous threshold.

</details>


### [78] [Lattice Gauge Theory via LLVM-Level Automatic Differentiation](https://arxiv.org/abs/2602.20516)
*Yuki Nagai,Akio Tomiya,Hiroshi Ohno*

Main category: hep-lat

TL;DR: 本文提出了一种基于LLVM中间表示的反向模式自动微分方法，用于在格点规范理论中自动生成Hybrid Monte Carlo（HMC）力，实现了从作用量代码自动导出HMC力而无需手动编写和维护独立的力计算代码。


<details>
  <summary>Details</summary>
Motivation: 传统HMC模拟中，HMC力需要手动推导和实现，容易出错且难以维护，尤其在复杂或组合型作用量下开发成本高。作者希望通过自动微分技术消除手动编码过程，提升开发效率与代码可维护性。

Method: 采用反向模式自动微分，在优化后的LLVM中间表示层进行微分操作，适用于任何能降低到LLVM的语言。该方法直接对格点作用量（包括规范场和Wilson费米子作用量）的计算路径进行端到端微分，并支持原地计算和常规的命令式编程风格。

Result: 自动生成的Wilson费米子作用力性能与手工编写的实现相当，并且同一管道可同时支持CPU和GPU后端，展现出良好的性能可移植性。

Conclusion: 该方法实现了单源代码工作流，显著简化了HMC力的开发与维护，为组合型格点作用量提供了实用、高效且性能可移植的力生成途径。

Abstract: We enable the automatic construction of Hybrid Monte Carlo (HMC) forces in lattice gauge theory by performing reverse-mode automatic differentiation at the level of optimized LLVM intermediate representation, making the approach applicable to any language that lowers lattice action code to LLVM. In practice, this means that once the action evaluation routine is implemented, the corresponding HMC force can be generated automatically from the same code path, without deriving or maintaining a separate force routine. The method preserves conventional imperative, in-place implementations and enables a single-source workflow in which forces are generated directly from the action code while inheriting compiler optimizations. We perform end-to-end reverse-mode differentiation of both gauge and Wilson fermion actions. For the Wilson fermion case, we find that the force generated by automatic differentiation achieves performance comparable to a conventional hand-written fermion force implementation. The same differentiation pipeline targets both CPU and GPU backends, providing a practical route to performance-portable force construction for compositional lattice actions.

</details>


### [79] [Importance of local tetraquark operators for $T_{cc}(3875)^+$](https://arxiv.org/abs/2602.20848)
*Andres Stump,Jeremy R. Green*

Main category: hep-lat

TL;DR: 研究了包含局部四夸克算符对双粲四夸克 $T_{cc}(3875)^+$ 能谱的影响，发现其显著改变了能量水平估计，并影响了从单通道s波Lüscher分析得到的散射相移。


<details>
  <summary>Details</summary>
Motivation: 准确确定 $T_{cc}(3875)^+$ 的有限体积能谱，探讨局部四夸克算符在其中的作用。

Method: 采用Wilson-clover费米子和蒸馏框架，结合位置空间采样方法，使用包含双局域和局部四夸克算符的大基组进行变分分析。

Result: 加入局部四夸克算符后，多个能级估计出现显著偏移，并影响了DD*散射相移的计算结果。

Conclusion: 局部四夸克算符在精确提取 $T_{cc}$ 能谱中起重要作用，不可忽略。

Abstract: The doubly charmed tetraquark $T_{cc}(3875)^+$ observed at LHCb has attracted considerable interest in recent years. To accurately determine its finite-volume spectrum, a variational analysis using a large basis of operators, including bilocal scattering operators, but also local tetraquark operators, should be employed. Using Wilson-clover fermions at the $SU(3)$-flavour-symmetric point, we investigated the importance of local tetraquark operators for the $T_{cc}$ spectrum by adding them to a large basis of bilocal $DD^*$ and $D^*D^*$ scattering operators. We performed this calculation using the distillation framework combined with a position-space sampling method that we recently developed. This method makes local tetraquark operators affordable in distillation. Upon including local tetraquark operators, we observe significant shifts in the estimates of several energy levels. Finally, we show the effect of these shifts on the $DD^*$ scattering phase shifts obtained from a single-channel $s$-wave Lüscher analysis.

</details>


### [80] [Reducing the Gate Count with Efficient Trotter-Suzuki Schemes](https://arxiv.org/abs/2602.21145)
*Marko Maležič,Johann Ostmeyer*

Main category: hep-lat

TL;DR: 本文综述了Trotter-Suzuki分解在格点场论哈密顿量模拟中的应用，提出通过优化框架发现的新高效高阶方案，并在海森堡模型上验证其性能。


<details>
  <summary>Details</summary>
Motivation: 由于低阶Trotter化仍是主流，但高阶方案可能提升效率，因此需要系统研究并优化Trotter-Suzuki方案以提高模拟效率。

Method: 提出一个优化框架来寻找更高效的Trotter-Suzuki分解方案，并将其应用于海森堡模型的模拟中进行性能评估。

Result: 发现了新的高效高阶Trotter-Suzuki方案，在模拟中表现出优于传统低阶方法的效率。

Conclusion: 高阶Trotter-Suzuki方案结合优化策略可显著提升格点场论时间演化的计算效率，具有在经典和量子模拟中的广泛应用前景。

Abstract: Hamiltonian formulations of lattice field theories provide access to real-time dynamics, but their simulation is difficult to implement efficiently. Trotter-Suzuki decompositions are at the center of time evolution computation, either on quantum hardware or classically, for instance with the use of tensor networks. While low-order Trotterizations remain the standard choice due to their simplicity, higher-order schemes offer the potential for improved efficiency. In this work we outline a short guide to Trotter-Suzuki schemes and their implementations in general. To help with this, we highlight new efficient schemes found by our optimization framework, and demonstrate their performance on the Heisenberg model.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [81] [Construction of a Neural Network with Temperature-Dependent Recall Patterns](https://arxiv.org/abs/2602.20620)
*Munetaka Sasaki*

Main category: cond-mat.dis-nn

TL;DR: 提出一个简单模型，通过调节温度实现不同模式的回忆，其中两种模式分别嵌入全连接图和稀疏图中，模拟显示该系统在模式切换时发生一级相变。


<details>
  <summary>Details</summary>
Motivation: 希望通过温度变化控制模式回忆，探索不同图结构对热波动的响应差异。

Method: 将两种模式分别嵌入全连接图和稀疏图，并通过调节两者相对权重，结合平衡蒙特卡洛和退火模拟研究温度依赖的回忆行为。

Result: 模拟表明温度变化可导致回忆模式切换，且该过程伴随一级相变；退火模拟显示低温下若自由能垒过高，稀疏图中的模式无法被成功回忆。

Conclusion: 通过图结构差异和温度调控可实现可控的模式切换，但动力学限制可能阻碍稀疏图模式在低温下的回忆。

Abstract: We present a simple model that recalls two different patterns depending on the temperature. To realize a change in recall pattern due to temperature change, we embed two patterns to different graphs: the first pattern into a fully connected graph and the second pattern into a sparse graph. Because a fully connected graph is more resistant to thermal fluctuations than a sparse graph, we can realize a change in recall pattern by tuning relative weights of the two patterns properly. We demonstrate by equilibrium Monte-Carlo simulations that such a temperature-dependent change in recall patterns does occur in our model. Simulation results strongly indicate that the system undergoes a first-order phase transition when the change in recall patterns occurs. It is also demonstrated by annealing simulations that the system fails to recall the pattern embedded in the sparse graph at low temperatures if the free-energy barrier is too high to overcome within the given simulation timescale.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [82] [A unified solution framework for truck-and-drone routing problems](https://arxiv.org/abs/2602.20310)
*Ke Xu,John Gunnar Carlsson*

Main category: math.OC

TL;DR: 本文提出了一种基于Lin-Kernighan-Helsgaun算法的统一三阶段求解框架，用于解决多种卡车-无人机协同配送问题，具有良好的灵活性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究中，结构或操作特性的微小变化会导致问题变体差异大，需设计专用算法；因此需要一个能适应多种运行特征且保持结构有效性的通用求解框架。

Method: 采用基于Lin-Kernighan-Helsgaun算法的统一三阶段求解框架，应用于FSTSP、TSP-mD和VRP-D三种问题变体，并通过数值实验与现有高效算法进行对比验证。

Result: 该框架在小规模实例上可逼近最优解，在中等规模实例上甚至改进了多个已知最优解，展现出良好的求解性能和扩展潜力。

Conclusion: 所提出的框架具有较强的通用性与有效性，能够灵活应对多种卡车-无人机协同配送问题，为复杂变体提供统一解决方案。

Abstract: Coordinated truck-and-drone routing integrates the high capacity and range of ground vehicles with the flexible routing and speed of drones, enabling simultaneous service. Increasingly applied in last-mile delivery, this synchronization helps reduce completion time and operational costs. To improve its efficiency, various coordination modes between trucks and drones have been proposed. Each mode accommodates diverse operational constraints tailored to particular delivery requirements. In existing work, a slight change in the structural framework or operational characteristics could generate a totally different problem variant, which often requires the design of specialized algorithms. Consequently, under the requirement of maintaining structural validation and adapting to multiple operational features, this paper presents a unified three-phase solution framework based on the Lin-Kernighan-Helsgaun algorithm to solve a wide family of truck-and-drone routing problems. To validate its flexibility and effectiveness, we carry out numerical experiments on three problem variants: the Flying Sidekick Traveling Salesman Problem (FSTSP), the Traveling Salesman Problem with Multiple Drones (TSP-mD), and the Vehicle Routing Problem with Drones (VRP-D), benchmarking each against an effective algorithm. Computational results show that the framework can closely match optimal solutions on small-size instances and even improve the best-known solutions for several medium-size instances. Moreover, additional extensions are discussed to further highlight its versatility.

</details>


### [83] [Poisson Hamiltonian Pontryagin Dynamics and Optimal Control of Mechanical Systems on Lie Groupoids](https://arxiv.org/abs/2602.20326)
*Ghorbanali Haghighatdoost*

Main category: math.OC

TL;DR: 提出了一种基于李群胚的Poisson哈密顿Pontryagin动力学框架，用于机械系统的最优控制，证明了辛叶是比余伴随轨道更自然的约化相空间，并展示了与变分公式等价及适用于具有依赖构型惯性和局部对称性的系统。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和控制在李群胚上的机械系统的最优控制问题，需要一个内在的、几何上自然的约化动力学框架。

Method: 利用李代胚对偶上的线性Poisson结构建立Poisson哈密顿形式的Pontryagin动力学，并研究其在辛叶上的演化性质。

Result: 证明了辛叶作为Pontryagin动力学的自然约化相空间；在适当正则性条件下，建立了变分公式与Poisson哈密顿系统的等价性；显示了群胚不变拉格朗日量导致Euler-Poincaré型的约化最优性条件。

Conclusion: 辛叶比余伴随轨道更适合描述李群胚上最优控制问题的约化动力学，该框架为具有对称性和构型依赖参数的机械系统提供了统一而自然的处理方法。

Abstract: We develop a Poisson Hamiltonian formulation of Pontryagin dynamics for optimal control of mechanical systems on Lie groupoids. The reduced dynamics is formulated intrinsically on the dual Lie algebroid endowed with its canonical linear Poisson structure and evolves on its symplectic leaves. The main result of this work shows that symplectic leaves, rather than coadjoint orbits, provide the natural reduced phase spaces for Pontryagin dynamics on Lie groupoids. Under suitable regularity assumptions, we prove the equivalence between the variational formulation of the optimal control problem and the associated Poisson Hamiltonian Pontryagin system, and we show that groupoid invariant Lagrangians lead to reduced optimality conditions of Euler Poincare type. Several mechanical examples, including systems with configuration dependent inertia and local symmetries, are presented to illustrate the theory.

</details>


### [84] [A variance reduced framework for (non)smooth nonconvex-nonconcave stochastic minimax problems with extended Kurdyka-Lojasiewicz property](https://arxiv.org/abs/2602.20357)
*Muhammad Khan,Yangyang Xu*

Main category: math.OC

TL;DR: 本文提出了一种新的方差缩减算法，用于求解具有弱凸性和扩展KL性质的非凸-非凹随机约束极小极大优化问题，在有限和在线两种设置下均达到了先进的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 由于非凸-非凹结构带来的固有挑战，现有方法通常需要对偶部分满足强凹性或附加几何假设，限制了适用范围，因此需要更宽松条件下的可靠高效算法。

Method: 提出一种基于方差缩减的技术，并仅假设原变量的弱凸性和对偶变量的扩展Kurdyka-Łojasiewicz（KL）性质（指数θ∈[0,1]），构建了一个统一框架来处理一般情况。

Result: 在光滑有限和设置下样本复杂度为O(√N ε^{-max{4θ,2}})，在线光滑设置下为O(ε^{-max{6θ,3}})；对于非光滑问题也给出了相应复杂度上界，是首个同时兼容弱凸性、扩展KL性质与方差缩减更新的统一框架。

Conclusion: 该方法显著拓宽了可处理的极小极大问题类别，适用于大规模应用场景，且在理论和实用性方面均有提升。

Abstract: In this paper, we study stochastic constrained minimax optimization problems with nonconvex-nonconcave structure, a central problem in modern machine learning, for which reliable and efficient algorithms remain largely unexplored due to its inherent challenges. Prior approaches for nonconvex minimax optimization often require (strong) concavity on the maximization part, or certain restrictive geometric assumptions on the joint objective to have guaranteed convergence. In contrast, our method only assumes weak convexity in the primal variable and the extended Kurdyka-Lojasiewicz (KL) property, with exponent $θ\in [0,1]$, in the dual variable, significantly broadening the class of tractable problems. To this end, we propose a variance reduced algorithm that provably handles this general setting and achieves an $\varepsilon$-stationary solution with state-of-the-art sample complexity: in the smooth finite-sum setting, the sample complexity is $\mathcal{O}\left(\sqrt{N}\,\varepsilon^{-\max\{4θ,2\}}\right)$, where $N$ is the number of total samples, and in the online smooth setting, it is $\mathcal{O}\Big(\varepsilon^{-\max\{6θ,3\}}\Big)$. For the structured nonsmooth problem, the sample complexity is $\mathcal{O}\left(\sqrt{N}\,\max\Big\{\varepsilon^{-3}, \varepsilon^{-5θ}, \varepsilon^{-\frac{11θ-3}{2θ}}\Big\}\right)$ and $\mathcal{O}\left(\max\left\{\varepsilon^{-4}, \varepsilon^{-\frac{15θ-1}{2}}, \varepsilon^{-\frac{31θ-9}{4θ}}\right\}\right)$ respectively for the two settings. To the best of our knowledge, this is the first unified framework that jointly accommodates weak convexity, the extended KL property, and variance-reduced stochastic updates, making it highly suitable for large-scale applications.

</details>


### [85] [Stochastic Control Problems with Infinite Horizon and Regime Switching Arising in Optimal Liquidation with Semimartingale Strategies](https://arxiv.org/abs/2602.20552)
*Xinman Cheng,Guanxing Fu,Xiaonyu Xia*

Main category: math.OC

TL;DR: 研究了具有半鞅策略、随机系数和状态转换的无限时间范围最优控制问题，通过三类无限水平向后随机微分方程（BSDEs）刻画值函数和最优策略，其中一类为具有无界系数的线性BSDE系统，属文献中新类型。利用BMO分析和多维BSDE的比较定理证明解的存在性，并验证问题适定性及最优策略的唯一性。


<details>
  <summary>Details</summary>
Motivation: 针对带有随机系数和状态转换机制的无限时间最优控制问题，现有BSDE方法难以处理无界系数和半鞅策略的复杂性，亟需建立新的理论框架以确保解的存在性和控制问题的适定性。

Method: 引入三类无限水平BSDE系统，结合BMO分析与多维BSDE比较定理证明解的存在性；通过将代价泛函重写为二次泛函与候选值函数之和，验证控制问题的适定性，并在附加条件下得出唯一最优策略。

Result: 建立了具有无界系数的线性无限水平BSDE系统的解的存在性；证明了该最优控制问题的适定性（值函数有限且最优策略若存在则唯一）；在额外假设下获得了唯一的最优策略。

Conclusion: 该研究为带随机系数、状态切换和半鞅策略的无限时间最优控制问题提供了严格的BSDE刻画方法，拓展了无限水平BSDE理论的应用边界，并为相关金融与控制问题提供了理论基础。

Abstract: We study an optimal control problem on infinite time horizon with semimartingale strategies, random coefficients and regime switching. The value function and the optimal strategy can be characterized in terms of three systems of backward stochastic differential equations (BSDEs) with infinite horizon. One of them is a system of linear BSDEs with unbounded coefficients and infinite horizon, which seems to be new in literature. We establish the existence of the solutions to these BSDEs by BMO analysis and comparison theorem for multi-dimensional BSDEs. Next, we establish that the optimal control problem is well posed, in the sense that the value function is finite and the optimal strategy-when it exists-is unique. This is achieved by reformulating the cost functional as the sum of a quadratic functional and the candidate value function. The reformulation crucially relies on the well-established well-posedness results for systems of BSDEs. Finally, under additional assumptions, we obtain the unique optimal strategy.

</details>


### [86] [Robustness certificates in data-driven non-convex optimization with additively-uncertain constraints](https://arxiv.org/abs/2602.21090)
*Alexander J Gallo,Massimiliano Zoggia,Alessandro Falsone,Maria Prandini,Simone Garatti*

Main category: math.OC

TL;DR: 本文研究了在非凸优化问题中，通过场景鲁棒优化范式处理约束中不确定性的问题，提出了一种计算高效的分布无关的鲁棒性验证方法，并可用于确定数据集大小以保证指定鲁棒水平。


<details>
  <summary>Details</summary>
Motivation: 针对非凸优化中不确定性约束的鲁棒性分析通常计算复杂且保守性强，现有通用场景理论结果在此类结构化问题中效率不高。

Method: 利用约束结构推导出先验和后验的分布无关鲁棒性证书，提出了无需重复求解非凸问题的一次性和增量式数据集定容方法。

Result: 所提方法在不需重新求解非凸场景规划的情况下实现鲁棒性评估与数据集扩展，应用于实际机组承诺问题时相比通用方法显著节省计算成本且保守性增加有限。

Conclusion: 该方法为具有特定结构的非凸鲁棒优化问题提供了高效、低保守性的数据驱动解决方案，具备良好的实用价值。

Abstract: We consider decision-making problems that are formulated as non-convex optimization programs where uncertainty enters the constraints through an additive term, independent of the decision variables, and robustness is imposed using a finite data-set, according to the scenario robust optimization paradigm. By exploiting the structure of the constraints, we show that both a priori and a posteriori distribution-free probabilistic robustness certificates for a possibly sub-optimal solution to the resulting data-driven optimization problem can be obtained with minimal computational effort. Building on these results, we also discuss a one-shot and an incremental procedure to determine the size of the data-set so as to guarantee a user-chosen robustness level. Notably, both the a posteriori robustness assessment and incremental data-set sizing do not require to solve the non-convex scenario program. A comparative analysis performed on the unit commitment problem using real data reveals a limited increase in conservativeness with a significant computational saving with respect to the application of scenario theory results for general, non necessarily structured, non-convex problems.

</details>


### [87] [On the Convergence of Stochastic Gradient Descent with Perturbed Forward-Backward Passes](https://arxiv.org/abs/2602.20646)
*Boao Kong,Hengrui Zhang,Kun Yuan*

Main category: math.OC

TL;DR: 本文研究了在前向和反向传播中存在扰动的情况下，具有N个顺序算子的复合优化问题的随机梯度下降（SGD）。与传统将梯度噪声视为加性且局部化的分析不同，本文考虑了扰动在计算图中的级联和几何增长效应，并提供了该设定下的首个全面理论分析。


<details>
  <summary>Details</summary>
Motivation: 传统的梯度噪声模型无法准确描述深度学习中由于中间输出和梯度扰动在计算图中传播而导致的复杂行为，尤其是梯度尖峰现象。因此需要一种更精确的理论框架来分析此类扰动的影响。

Method: 通过分析前向和反向扰动在单个梯度步长内的传播与放大机制，推导出针对非凸目标函数及满足Polyak--Łojasiewicz条件函数的收敛性保证，并识别扰动不恶化渐近收敛阶的条件。

Result: 揭示了扰动如何在多层结构中几何级数放大，给出了收敛性理论结果，解释了梯度尖峰现象的发生与恢复条件，并通过逻辑回归实验验证了前向与反向扰动敏感性的不对称性。

Conclusion: 该工作为理解深度学习中梯度扰动的传播提供了新的理论视角，表明在特定条件下扰动不会破坏收敛性，同时为梯度尖峰等实际现象提供了理论解释。

Abstract: We study stochastic gradient descent (SGD) for composite optimization problems with $N$ sequential operators subject to perturbations in both the forward and backward passes. Unlike classical analyses that treat gradient noise as additive and localized, perturbations to intermediate outputs and gradients cascade through the computational graph, compounding geometrically with the number of operators. We present the first comprehensive theoretical analysis of this setting. Specifically, we characterize how forward and backward perturbations propagate and amplify within a single gradient step, derive convergence guarantees for both general non-convex objectives and functions satisfying the Polyak--Łojasiewicz condition, and identify conditions under which perturbations do not deteriorate the asymptotic convergence order. As a byproduct, our analysis furnishes a theoretical explanation for the gradient spiking phenomenon widely observed in deep learning, precisely characterizing the conditions under which training recovers from spikes or diverges. Experiments on logistic regression with convex and non-convex regularization validate our theories, illustrating the predicted spike behavior and the asymmetric sensitivity to forward versus backward perturbations.

</details>


### [88] [Convergent Lifted Lasserre Hierarchy of SDPs for Minimizing Expectation of Piecewise Polynomial Loss over Wasserstein Balls](https://arxiv.org/abs/2602.20660)
*N. D. Dizon,Q. Y. Huang,T. D. Chuong,G. Li,V. Jeyakumar*

Main category: math.OC

TL;DR: 本文研究了在Wasserstein球上分段多项式损失函数期望的最小化问题，提出了半定规划松弛的层次结构，并证明其渐近收敛性，通过新的提升正性证书和SOS表示实现有限收敛，应用于收益估计与投资组合优化。


<details>
  <summary>Details</summary>
Motivation: 解决分布鲁棒优化中的核心子问题，即在Wasserstein球上最小化分段多项式损失函数的期望，因其为无限维优化问题而难以直接求解。

Method: 构建半定规划（SDP）松弛的层次结构，提出新的提升正性证书，利用结构化的SOS表示证明分段多项式在阿基米德半代数集上的正性，并在凸性条件下证明有限收敛性。

Result: 建立了SDP松弛序列的渐近收敛性，证明在适当条件下具有有限收敛性，并通过收益估计和投资组合优化的数值实验验证了方法的有效性和通用性。

Conclusion: 所提框架能有效逼近无限维优化问题的最优值，为处理Wasserstein分布鲁棒优化中的分段多项式损失提供了理论支持与实用算法。

Abstract: This paper investigates the minimization of the expectation of piecewise polynomial loss functions over Wasserstein balls. This optimization problem often appears as a key sub-problem of distributionally robust optimization problems. We establish the asymptotic convergence of a hierarchy of semi-definite programming (SDP) relaxations, providing a framework for approximating the optimal values of these inherently infinite-dimensional optimization problems. A central foundational contribution is the development of a new lifted positivity certificate: we demonstrate that piecewise polynomials positive over Archimedean basic semi-algebraic sets admit a structured system of sum-of-squares (SOS) representations. Furthermore, we prove that the proposed hierarchy achieves finite convergence under suitable conditions when the defining polynomials are convex. The practical utility and versatility of this approach are demonstrated via numerical experiments in revenue estimation and portfolio optimization.

</details>


### [89] [Implicit Decision Diagrams](https://arxiv.org/abs/2602.20793)
*Isaac Rudich,Louis-Martin Rousseau*

Main category: math.OC

TL;DR: 本文提出了隐式决策图（implicit Decision Diagrams），通过隐式存储弧来降低每层的构建复杂度至O(w)，并在理论上证明了该复杂度是最优的。基于此理论，开发了一个开源Julia求解器ImplicitDDs.jl，并在子集和问题上表现出优于Gurobi的性能。


<details>
  <summary>Details</summary>
Motivation: 标准决策图构建的复杂度较高，限制了其在大规模问题中的应用。为了提升决策图在离散优化中的效率，需要降低构建过程的时间和空间开销。

Method: 提出隐式决策图，将弧隐式存储而非显式存储，从而将受限和松弛决策图的每层复杂度从O(w log w)和O(w^2)降低到O(w)，并证明该复杂度在黑盒操作框架下是最优的。

Result: 实现了每层O(w)的最优复杂度，开发了ImplicitDDs.jl求解器，并在实验中显示其在子集和问题上优于Gurobi。

Conclusion: 隐式决策图显著降低了构建复杂度，使决策图方法更高效，具备实际应用潜力，尤其在结合MIP求解器时表现优异。

Abstract: Decision Diagrams (DDs) have emerged as a powerful tool for discrete optimization, with rapidly growing adoption. DDs are directed acyclic layered graphs; restricted DDs are a generalized greedy heuristic for finding feasible solutions, and relaxed DDs compute combinatorial relaxed bounds. There is substantial theory that leverages DD-based bounding, yet the complexity of constructing the DDs themselves has received little attention. Standard restricted DD construction requires $O(w \log(w))$ per layer; standard relaxed DD construction requires $O(w^2)$, where $w$ is the width of the DD. Increasing $w$ improves bound quality at the cost of more time and memory.
  We introduce implicit Decision Diagrams, storing arcs implicitly rather than explicitly, and reducing per-layer complexity to $O(w)$ for restricted and relaxed DDs. We prove this is optimal: any framework treating state-update and merge operations as black boxes cannot do better.
  Optimal complexity shifts the challenge from algorithmic overhead to low-level engineering. We show how implicit DDs can drive a MIP solver, and release ImplicitDDs.jl, an open-source Julia solver exploiting the implementation refinements our theory enables. Experiments demonstrate the solver outperforms Gurobi on Subset Sum.

</details>


### [90] [A subdifferential characterization via Busemann functions and applications to DC optimization on Hadamard manifolds](https://arxiv.org/abs/2602.20931)
*O. P. Ferreira,D. S. Gonçalves,M. S. Louzeiro,S. Z. Németh,J. Zhu*

Main category: math.OC

TL;DR: 本文研究了在Hadamard流形上Busemann函数的性质及其在黎曼优化算法中的应用，提出了一种基于Busemann函数的次微分新刻画，并利用其凹性设计了适用于黎曼流形的差凸优化方法。


<details>
  <summary>Details</summary>
Motivation: 传统黎曼优化中次梯度提供的全局下界模型缺乏良好的凸性或凹性结构，限制了优化算法的设计与分析。因此，需要一种更适合黎曼环境的次微分刻画方法。

Method: 利用Busemann函数的关键性质，提出新的次微分刻画方式，构建具有凹性边界的函数，并在此基础上将经典的差凸算法（DCA）推广到黎曼流形上，形成新的Busemann DCA算法。

Result: 所提出的Busemann DCA能生成测地线凸子问题，在初步数值实验中表现出与经典黎曼DCA相当或更优的性能。同时，新方法具备良好的收敛性理论保证。

Conclusion: 基于Busemann函数的次微分刻画为黎曼优化提供了更强的建模能力，所提出的DC算法为在Hadamard流形上求解非光滑优化问题提供了有效的新工具。

Abstract: This paper investigates the properties of Busemann functions on Hadamard manifolds and their use in optimization algorithms in Riemannian settings. We present a new Busemann-based characterization of the subdifferential, which is particularly well suited to Riemannian optimization. In the classical Hadamard manifold framework, a subgradient provides a global lower model of a convex function expressed through the inverse exponential map. However, this model may fail to exhibit a useful convexity or concavity structure. By contrast, our characterization yields a concave bounding function by exploiting key properties of Busemann functions. We use this concavity to design and analyze difference-of-convex (DC) optimization methods on Hadamard manifolds. In particular, we reformulate the classical DC algorithm (DCA) for Riemannian contexts and study its convergence properties. We also report preliminary numerical experiments comparing the proposed Busemann DCA, which leads to geodesically convex subproblems, with the classical Riemannian DCA.

</details>


### [91] [Asymptotics of solutions to the linear search problem](https://arxiv.org/abs/2602.20991)
*Robin A. Heinonen*

Main category: math.OC

TL;DR: 本文研究了对称线性搜索问题解的精确主导渐近行为，适用于具有单调且足够正则尾部的任意正概率密度函数，结果同样适用于紧区间上的密度函数。


<details>
  <summary>Details</summary>
Motivation: 为了理解在不同概率密度分布下对称线性搜索问题的渐近行为，特别是当尾部分布具有单调性和正则性时的表现。

Method: 通过分析具有单调和足够正则尾部的概率密度函数，推导出对称线性搜索问题解的主导渐近形式，并扩展到紧区间情形。

Result: 得到了对称线性搜索问题在实数线上及紧区间上概率密度函数下的精确主导渐近解。

Conclusion: 对于具有单调且足够正则尾部的任意正概率密度，可以准确描述对称线性搜索问题解的渐近行为。

Abstract: The exact leading asymptotics of solutions to the symmetric linear search problem are obtained for any positive probability density on the real line with a monotonic, sufficiently regular tail. A similar result holds for densities on a compact interval.

</details>


### [92] [Complexity of Classical Acceleration for $\ell_1$-Regularized PageRank](https://arxiv.org/abs/2602.21138)
*Kimon Fountoulakis,David Martínez-Rubio*

Main category: math.OC

TL;DR: 研究了使用加速近端梯度法（FISTA）计算ℓ₁正则化PageRank的度加权计算复杂度，提出在适当条件下可保持局部性并实现加速收敛。


<details>
  <summary>Details</summary>
Motivation: 探讨FISTA是否能在保持ℓ₁正则化PageRank局部性的同时改善对参数α的依赖关系。

Method: 分析在轻微过正则化目标函数上FISTA的表现，并引入可验证的限制条件以控制虚假激活范围。

Result: 得到了包含加速项和边界开销项的复杂度界，并给出了保证节点激活局限在边界集内的图结构性条件。

Conclusion: 在满足特定图结构和参数条件下，FISTA可在度加权模型下实现优于非加速方法的收敛速度。

Abstract: We study the degree-weighted work required to compute $\ell_1$-regularized PageRank using the standard one-gradient-per-iteration accelerated proximal-gradient method (FISTA). For non-accelerated local methods, the best known worst-case work scales as $\widetilde{O} ((αρ)^{-1})$, where $α$ is the teleportation parameter and $ρ$ is the $\ell_1$-regularization parameter. A natural question is whether FISTA can improve the dependence on $α$ from $1/α$ to $1/\sqrtα$ while preserving the $1/ρ$ locality scaling. The challenge is that acceleration can break locality by transiently activating nodes that are zero at optimality, thereby increasing the cost of gradient evaluations. We analyze FISTA on a slightly over-regularized objective and show that, under a checkable confinement condition, all spurious activations remain inside a boundary set $\mathcal{B}$. This yields a bound consisting of an accelerated $(ρ\sqrtα)^{-1}\log(α/\varepsilon)$ term plus a boundary overhead $\sqrt{vol(\mathcal{B})}/(ρα^{3/2})$. We provide graph-structural conditions that imply such confinement. Experiments on synthetic and real graphs show the resulting speedup and slowdown regimes under the degree-weighted work model.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [93] [Half a century of the theory of synchronization](https://arxiv.org/abs/2602.20505)
*Yoshiki Kuramoto*

Main category: nlin.AO

TL;DR: 本文回顾了过去半个世纪耦合振子与同步理论的发展，重点介绍了作者在其中三项关键工作：Kuramoto-Sivashinsky方程、Kuramoto模型和chimera态的发现，并强调这些成果均源于对复Ginzburg-Landau方程的相位约化，同时指出动力学约化方法对该领域深入研究的重要性。


<details>
  <summary>Details</summary>
Motivation: 总结作者在过去五十年中对耦合振子与同步领域的重要贡献，并展示该领域的演进脉络。

Method: 基于复Ginzburg-Landau方程（或其变体）的相位约化方法，推导出描述时空混沌、同步相变及相干与非相干共存态的关键模型。

Result: 提出了Kuramoto-Sivashinsky方程、Kuramoto模型和chimera态三项标志性成果，推动了同步理论的发展，并凸显了动力学约化方法的核心作用。

Conclusion: 动力学约化方法，特别是相位约化，在深入理解耦合振子系统中起着根本性作用，是推动该领域持续发展的关键工具。

Abstract: This review offers a retrospective of the development of the theory of coupled oscillators and synchronization over the past half century. Among the various works made by myself during this period, the following three specific works will be focused on, serving as some key points to illustrate the field's evolution. They are the derivation of (1) a simple partial differential equation exhibiting spatio-tempoeral chaos (Kuramoto-Sivashinsky equaiton), (2) a solvable mathematical model describing synchronization phase transition (Kuramoto model), and the discovery of (3) coexistence of coherence and incoherence in nonlocally coupled oscillators (chimera states). It is emphasized that all these works resulted fron the phase reduction of the complex Ginzburg-Landau equation (or its variants), the equation which was derived with a coworker in 1974 from a certain reaction-diffusion model. A quick overview will also be made on how the above three works influenced the subsequent development of the field of coupled oscillators and synchronization. Finally, a few comments will be made on how the methods of dynamical reduction, such as the center-manifold reduction and phase reduction, are crucial for exploring this field in depth. This article is a largely faithful reproduction of the content presented in my award lecture.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [94] [StochasticBarrier.jl: A Toolbox for Stochastic Barrier Function Synthesis](https://arxiv.org/abs/2602.20359)
*Rayan Mazouz,Frederik Baymler Mathiesen,Luca Laurenti,Morteza Lahijanian*

Main category: eess.SY

TL;DR: StochasticBarrier.jl是一个基于Julia的开源工具箱，用于生成随机屏障函数（SBF），以验证带有加性高斯噪声的离散时间随机系统的安全性，支持线性、多项式和分段仿射系统，并在计算速度、安全概率界和可扩展性方面显著优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 为了提高离散时间随机系统的安全性验证效率和适用范围，尤其是处理非线性系统和高维系统时的性能瓶颈。

Method: 采用Sum-of-Squares（SOS）优化和基于分段常数（PWC）函数的方法，结合半定规划求解器、线性规划和梯度下降算法生成随机屏障函数。

Result: 在30多个案例研究中，StochasticBarrier.jl相比现有工具在计算时间上快达四个数量级，提供了更优的安全概率边界，并支持更高维度的系统。

Conclusion: StochasticBarrier.jl在安全性验证的效率、精度和可扩展性方面显著优于当前最先进的工具，适用于广泛的动力系统类型。

Abstract: We present StochasticBarrier.jl, an open-source Julia-based toolbox for generating Stochastic Barrier Functions (SBFs) for safety verification of discrete-time stochastic systems with additive Gaussian noise. StochasticBarrier.jl certifies linear, polynomial, and piecewise affine (PWA) systems. The latter enables verification for a wide range of system dynamics, including general nonlinear types. The toolbox implements a Sum-of-Squares (SOS) optimization approach, as well as methods based on piecewise constant (PWC) functions. For SOS-based SBFs, StochasticBarrier.jl leverages semi-definite programming solvers, while for PWC SBFs, it offers three engines: two using linear programming (LP) and one based on gradient descent (GD). Benchmarking StochasticBarrier.jl against the state-of-the-art shows that the tool outperforms existing tools in computation time, safety probability bounds, and scalability across over 30 case studies. Compared to its closest competitor, StochasticBarrier.jl is up to four orders of magnitude faster, achieves significant safety probability improvements, and supports higher-dimensional systems.

</details>


### [95] [IoT-Driven Building Energy Management Systems (BEMS) for Net Zero Energy Buildings: Concept, Integration and Future Directions](https://arxiv.org/abs/2602.20453)
*Haizum Hanim Ab Halim,Dalila Alias,Akmal Zaini Arsad,Lewis Tee Jen Looi,Rosdiadee Nordin,Denny Ng Kok Sum*

Main category: eess.SY

TL;DR: 本文综述了物联网赋能的建筑能源管理系统（BEMS），评估了支持人工智能预测控制的真实数据集，分析了互操作性、智能电网和净零能耗策略的集成挑战，并通过案例研究总结了全球最佳实践。


<details>
  <summary>Details</summary>
Motivation: 建筑行业是全球温室气体排放的主要来源之一，人为因素导致的能源使用低效进一步加剧了能耗问题，因此需要更高效的BEMS来实现净零能耗建筑目标。

Method: 采用系统性文献回顾、真实世界数据集评估、集成挑战分析以及案例研究的方法。

Result: 提出了物联网BEMS的系统架构与功能特性，评估了适用于AI控制的数据集，识别了在互操作性与智能电网整合方面的关键挑战，并总结了先进BEMS规模化部署的最佳实践。

Conclusion: 集成物联网与数据驱动智能的BEMS对于提升建筑能效至关重要，未来需解决标准化与系统集成问题以推动NZEB目标的实现。

Abstract: Construction and operating of buildings is one of the major contributors to global greenhouse emissions. With the inefficient usage of energy due to human behavior and manual operation, the energy consumption of buildings is further increased. These challenges highlight the need for improved Building Energy Management Systems (BEMS) integrated with Internet of Things (IoT) and data driven intelligence to enhance energy-efficiency in a building and contribute to Net-Zero Energy Buildings (NZEB) targets. This paper offers four keys contributions: i) a systematic review of IoT enabled BEMS including components, network architecture and functional capabilities, ii) an evaluation of real-world BEMS datasets to support Artificial Intelligence (AI) based predictive control, iii) an analysis of integration challenges related to interoperability, smart grids and net-zero energy strategies, and iv) a case study highlighting global best practices, performances outcomes, and lesson learned for scaling advanced BEMS solutions.

</details>


### [96] [Fast-Response Balancing Capacity of Alkaline Electrolyzers](https://arxiv.org/abs/2602.20842)
*Marvin Dorn,Julian Hoffmann,André Weber,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: 大型碱性电解槽系统在解耦总功率与平衡市场提供功率的情况下，具备提供快速响应平衡服务的技术能力，可覆盖德国全部平衡容量市场，并节省约13%的电力成本。


<details>
  <summary>Details</summary>
Motivation: 评估大型碱性电解槽系统在电网平衡服务中的动态能力，解决其动态性能与系统稳定性之间的权衡问题。

Method: 利用真实制造商数据，提出电解槽总功率与用于平衡市场的部分功率解耦的方法，并基于现有方法分析德国及欧洲范围内的碱性电解槽系统。

Result: 大型电解槽能够提供快速响应的平衡服务，动态要求显著低于此前假设；德国规划的电解槽可完全覆盖其平衡容量市场需求，节省约13%电费（不含能量平衡收入）；解耦策略有助于制造商设计更稳定、低动态性的系统。

Conclusion: 通过功率解耦，大型碱性电解槽可在不影响稳定性的情况下参与电网平衡服务，提升经济性并促进能源转型中灵活性技术的发展。

Abstract: The energy transition requires flexible technologies to maintain grid stability, and electrolyzers are playing an increasingly important role in meeting this need. While previous studies often question the dynamic capabilities of large-scale alkaline electrolyzer systems, we assess their potential to provide balancing services using real manufacturer data. Unlike common approaches, we propose the decoupling between the total electrolyzer power and a smaller fractions of power actually offered on balancing markets. Adapting an existing methodology, we analyze alkaline electrolyzer systems and extend the assessment to Germany and Europe. Our results show that large-scale electrolyzers are technically capable of delivering fast-response balancing services, with significantly lower dynamic requirements than previously assumed. The planned electrolyzers in Germany could cover the entire balancing capacity market, potentially saving around 13 % of their electricity costs, excluding energy balancing revenues. The decoupling also resolves part of the trade-off for electrolyzer manufacturers, enabling the design of less dynamic but more stable systems.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [97] [Relationship between ideology and language in the Catalan independence context](https://arxiv.org/abs/2602.20821)
*Julia Atienza-Barthelemy,Samuel Martin-Gutierrez,Juan C. Losada,Rosa M. Benito*

Main category: physics.soc-ph

TL;DR: 本文通过分析推特数据，研究了加泰罗尼亚独立领土争端中的舆论和语言使用分布，发现舆论呈双峰分布并存在一个中间温和派，极端立场用户更活跃且影响力更大，语言使用与政治立场密切相关。


<details>
  <summary>Details</summary>
Motivation: 研究领土争端中社交媒体上的舆论极化现象及其与语言使用的关系，揭示社会极化的复杂结构。

Method: 基于转发互动构建连续意见分布模型，识别具有对立观点的精英用户，并分析其语言使用特征。

Result: 意见分布呈现主要双峰形态并存在第三个中间群体；极端立场用户更具影响力；语言使用与政治立场相关，反独立者主要使用西班牙语，支持独立者双语混用，中间群体语言行为类似反独立者。

Conclusion: 加泰罗尼亚独立争议下的社会并非完全两极分化，存在中间意见群体，但最活跃用户持更极端立场，语言使用模式反映并强化了政治分歧。

Abstract: Political polarization generates strong effects on society, driving controversial debates and influencing the institutions. Territorial disputes are one of the most important polarized scenarios and have been consistently related to the use of language. In this work, we analyzed the opinion and language distributions through Twitter data of a particular territorial dispute around the independence of Catalonia. We infer a continuous opinion distribution by applying a model based on retweet interactions, previously detecting elite users with fixed and antagonist opinions. The resulting distribution presents a mainly bimodal behavior with an intermediate third pole that shows a less polarized society with the presence of not only antagonist opinions. We find that the more active, engaged and influential users hold more extreme positions. Also we prove that there is a clear relationship between political positions and the use of language, showing that against independence users speak mainly Spanish while pro-independence users speak Catalan and Spanish almost indistinctly. However, the third pole, closer in political opinion to the pro-independence pole, behaves similarly to the against-independence one concerning the use of language.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [98] [Application of Large Language Models for Container Throughput Forecasting: Incorporating Contextual Information in Port Logistics](https://arxiv.org/abs/2602.20489)
*Minseop Kim,Jaeeun Kwon,Hanbyeol Park,Kikun Park,Taekhyun Park,Hyerim Bae*

Main category: cs.CE

TL;DR: 本研究探讨了大语言模型（LLM）在港口物流中预测集装箱吞吐量的应用，提出了一种融合港口操作上下文特征的新提示结构，并通过实验证明其优于现有模型的表现。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能在多个领域已展现出巨大潜力，但在港口物流中的应用仍待探索。港口环境复杂、信息多样，亟需研究如何有效利用生成式AI提升运营效率。

Method: 采用最先进的大语言模型（LLM），设计了一种新的提示结构以融入港口操作的多层上下文信息，并用于集装箱吞吐量预测。

Result: 实验表明所提方法在预测性能上优于竞争性基准模型，且LLM能有效学习和利用多层上下文信息进行推理。

Conclusion: 研究验证了LLM在港口物流中的有效性，分析了其应用的关键制约因素，并提出了未来研究方向，为生成式AI在该领域的部署提供了技术与实践洞察。

Abstract: Recent advancements in generative artificial intelligence (AI) have demonstrated its substantial potential in various fields. However, its application in port logistics remains underexplored. Ports are complex operational environments where diverse types of contextual information coexist, making them a promising domain for the implementation of generative AI and highlighting the urgency of related research. In this study, we applied a large language model (LLM)-a leading generative AI technique-to forecast container throughput, which is a critical challenge in port logistics. To this end, we adopted a state-of-the-art LLM approach and proposed a novel prompt structure designed to incorporate the contextual characteristics of port operations. Extensive experiments confirm the superiority of our method, showing that the proposed approach outperforms competitive benchmark models. Furthermore, additional experiments revealed that LLMs can effectively learn and utilize multiple layers of contextual information for inference in port logistics. Based on these findings, we explore the key constraints affecting LLM adoption in this domain and outline future research directions aimed at addressing them. Accordingly, we offer both technical and practical insights to support the effective deployment of generative AI in port logistics.

</details>


### [99] [Generative AI and Machine Learning Collaboration for Container Dwell Time Prediction via Data Standardization](https://arxiv.org/abs/2602.20540)
*Minseop Kim,Takhyeong Kim,Taekhyun Park,Hanbyeol Park,Hyerim Bae*

Main category: cs.CE

TL;DR: 本研究提出了一种结合生成式人工智能（Gen AI）与机器学习的协作框架，用于提升集装箱码头进口集装箱滞留时间（ICDT）预测的准确性。通过Gen AI将非结构化的货主和货物信息标准化为国际编码，并结合电子数据交换状态更新进行动态重预测，显著提升了预测性能。实验结果显示，相较于传统模型，该方法在平均绝对误差上改善了13.88%，并使堆场翻箱次数最多减少14.68%。


<details>
  <summary>Details</summary>
Motivation: 准确预测进口集装箱滞留时间对提高码头作业效率至关重要，但关键影响因素（如货主和货物信息）常以非结构化文本形式存在，限制了其在机器学习中的有效应用。

Method: 提出一个融合生成式人工智能与机器学习的协作框架：利用Gen AI将非结构化文本信息自动转换为标准国际编码，并基于EDI状态变化触发动态重预测，从而为机器学习模型提供高质量输入以实现更精准的ICDT预测。

Result: 在真实码头数据上的实验表明，该方法相比未使用标准化信息的传统模型，平均绝对误差（MAE）降低了13.88%；应用于堆场堆放策略后，翻箱次数最多减少了14.68%。

Conclusion: 本研究验证了生成式AI在港口物流中处理非结构化数据的有效性，为提升集装箱码头运营效率提供了可行的技术路径和方法论支持。

Abstract: Import container dwell time (ICDT) prediction is a key task for improving productivity in container terminals, as accurate predictions enable the reduction of container re-handling operations by yard cranes. Achieving this objective requires accurately predicting the dwell time of individual containers. However, the primary determinants of dwell time-owner information and cargo information-are recorded as unstructured text, which limits their effective use in machine learning models. This study addresses this limitation by proposing a collaborative framework that integrates generative artificial intelligence (Gen AI) with machine learning. The proposed framework employs Gen AI to standardize unstructured information into standard international codes, with dynamic re-prediction triggered by electronic data interchange state updates, enabling the machine learning model to predict ICDT accurately. Extensive experiments conducted on real container terminal data demonstrate that the proposed methodology achieves a 13.88% improvement in mean absolute error compared to conventional models that do not utilize standardized information. Furthermore, applying the improved predictions to container stacking strategies achieves up to 14.68% reduction in the number of relocations, thereby empirically validating the potential of Gen AI to enhance productivity in container terminal operations. Overall, this study provides both technical and methodological insights into the adoption of Gen AI in port logistics and its effectiveness.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [100] [Two approaches to low-parametric SimRank computation](https://arxiv.org/abs/2602.20282)
*Egor P. Berezin,Robert T. Zaks,German Z. Alekhin,Stanislav V. Morozov,Sergey A. Matveev*

Main category: math.NA

TL;DR: 本文提出了两种低参数化方法来近似SimRank矩阵，以在保持高精度的同时减少内存消耗，并通过真实数据验证了算法的有效性。


<details>
  <summary>Details</summary>
Motivation: SimRank矩阵计算和存储需要大量内存，现有方法主要关注算法复杂度，而忽视了内存效率问题。

Method: 提出两种经济型嵌入格式：一种采用非对称形式并结合交替优化算法；另一种基于对称表示并使用牛顿型迭代。两种方法均避免处理稠密矩阵，保持低内存占用。

Result: 在真实数据集上的实验表明，所提算法能有效逼近SimRank矩阵，在误差范数（尤其是切比雪夫范数）和保留每个节点最相似元素数量方面表现良好。

Conclusion: 所提出的低参数化嵌入方法在控制内存使用的同时，能够提供高质量的SimRank近似结果，适用于大规模图数据的节点相似性计算。

Abstract: In this work, we discuss low-parametric approaches for approximating SimRank matrices, which estimate the similarity between pairs of nodes in a graph. Although SimRank matrices and their computation require a significant amount of memory, common approaches mostly address the problem of algorithmic complexity. We propose two major formats for the economical embedding of target data. The first approach adopts a non-symmetric form that can be computed using a specialized alternating optimization algorithm. The second is based on a symmetric representation and Newton-type iterations. We propose numerical implementations for both methodologies that avoid working with dense matrices and maintain low memory consumption. Furthermore, we study both types of embeddings numerically using real data from publicly available datasets. The results show that our algorithms yield a good approximation of the SimRank matrices, both in terms of the error norm (particularly the Chebyshev norm) and in preserving the average number of the most similar elements for each given node.

</details>


### [101] [The largest 5th pivot may be the root of a 61st degree polynomial](https://arxiv.org/abs/2602.20390)
*James Chen,Alan Edelman,John Urschel*

Main category: math.NA

TL;DR: 本文研究了高斯消元法完全选主元时的最大增长因子问题，结合JuMP、Groebner基和判别式多项式方法以及区间运算，给出了n=5时最大增长因子的精确代数表达（61次多项式的根），并将上界从4.94略微降低至4.84。


<details>
  <summary>Details</summary>
Motivation: 高斯消元法中完全选主元的最大增长因子长期难以精确求解，传统数值方法受限于精度与组合爆炸，需结合符号计算与现代优化工具以获得更精确结果。

Method: 提出并应用JuMP + Groebner基 + 判别式多项式 + 区间算术的混合方法，结合数值优化与符号计算，在满足等式约束下求解极值，并验证其代数结构。

Result: 对n=5重现了4.1325...的最大增长值，证明其为一个61次多项式的根；在相同约束下确认其为极大值；将n=5的上界从4.94降至4.84；并将该方法推广至n=6,7,8的情形。

Conclusion: 通过融合数值与符号计算，获得了n=5时最大增长因子的精确代数形式，并提出了其为全局最大值的猜想，同时改进了理论上界，为该经典问题提供了新进展。

Abstract: This paper introduces a number of new techniques in the study of the famous question from numerical linear algebra: what is the largest possible growth factor when performing Gaussian elimination with complete pivoting? This question is highly complex, due to a complicated set of polynomial inequalities that need to be simultaneously satisfied. This paper introduces the JuMP + Groebner basis + discriminant polynomial approach as well as the use of interval arithmetic computations. Thus, we are introducing a marriage of numerical and exact mathematical computations.
  In 1988, Day and Peterson performed numerical optimization on $n=5$ with NPSOL and obtained a largest seen value of $4.1325...$. This same best value was reproduced by Gould with LANCELOT in 1991. We ran extensive comparable experiments with the modern software tool JuMP and also saw the same value $4.1325...$. While the combinatorial explosion of possibilities prevents us from knowing there may not be a larger maximum, we succeed in obtaining the exact mathematical value: the number $4.1325...$ is exactly the root of a 61st degree polynomial provided in this work, and is a maximum given the equality constraints seen by JuMP. In light of the numerics, we pose the conjecture that this lower bound is indeed the maximum. We also apply this technique to $n = 6$, $7$, and $8$.
  Furthermore, in 1969, an upper bound of $4\frac{17}{18}\approx 4.94$ was produced for the maximum possible growth for $n = 5$. We slightly lower this upper bound to $4.84$.

</details>


### [102] [Implicit-explicit all-speed schemes for compressible Cahn-Hilliard-Navier-Stokes equations](https://arxiv.org/abs/2602.20679)
*Andreu Martorell,Pep Mulet,Dionisio F. Yáñez*

Main category: math.NA

TL;DR: 提出了一种用于低马赫数下等熵可压缩Cahn-Hilliard-Navier-Stokes方程的二阶隐式-显式（IMEX）时间推进格式，采用 staggered 网格上的有限差分法，并通过 IMEX 方法处理刚性项以克服时间步长限制。


<details>
  <summary>Details</summary>
Motivation: 在低马赫数极限下，传统显式格式因第四阶扩散项和声波刚性导致严重的时间步长限制，难以高效求解。

Method: 基于 staggered 网格的有限差分法，采用二阶 IMEX 时间推进策略，将压力、粘性力和 Cahn-Hilliard 项等刚性部分隐式处理，其余非刚性项显式处理。

Result: 该方法有效缓解了低马赫数下的时间步长限制，能够稳定地逼近不可压缩极限行为。

Conclusion: 所提出的 IMEX 格式在保持精度的同时显著提升了计算稳定性，适用于低马赫数下多相流的高效模拟。

Abstract: We propose a second-order implicit-explicit (IMEX) time-stepping scheme for the isentropic, compressible Cahn-Hilliard-Navier-Stokes equations in the low Mach number regime.
  The method is based on finite differences on staggered grids and is specifically designed to handle the challenges posed by the low Mach number limit, where the system approaches to an incompressible behavior.
  In this regime, standard explicit schemes suffer from severe time-step restrictions due to fourth-order diffusion terms and the stiffness induced by fast acoustic waves.
  To overcome this, we employ an IMEX strategy which splits the governing equations into stiff and non-stiff components.
  The stiff terms, arising from pressure, viscous forces and fourth-order Cahn-Hilliard contributions, are treated implicitly, while the remaining are dealt explicitly.

</details>


### [103] [Reduced-order computational homogenization for hyperelastic media using gradient based sensitivity analysis of microstructures](https://arxiv.org/abs/2602.20697)
*Vladimír Lukeš,Eduard Rohan*

Main category: math.NA

TL;DR: 提出了一种用于局部周期性超弹性结构在大变形下计算均匀化的算法，通过宏观变形聚类和基于敏感性分析的模型降阶方法，显著减少了微观问题求解数量，提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了加速非线性模拟中微观问题的求解过程，减少计算成本，特别是在处理大变形和局部周期性结构时。

Method: 采用宏观变形聚类（centroid clustering）并结合对微观构型关于宏观变形的敏感性分析，近似均质化系数，实现模型降阶；在SfePy有限元框架中实现该算法。

Result: 相比本征正交分解方法和完整的FE²模拟，所提算法显著减少了需求解的微观问题数量，且计算效率更高，同时可通过误差容限参数控制降阶程度。

Conclusion: 该算法有效提升了计算效率，具有可调节的降阶精度，适用于二维测试案例，并具备向更广泛问题扩展的潜力。

Abstract: We propose an algorithm for the computational homogenization of locally periodic hyperelastic structures undergoing large deformations due to external quasi-static loading. The algorithm performs clustering of macroscopic deformations into subsets called "centroids", and, as a new ingredient, approximates the homogenized coefficients using sensitivity analysis of micro-configurations with respect to the macroscopic deformation. The novel "model-order reduction" approach significantly reduces the number of microscopic problems that must be solved in nonlinear simulations, thereby accelerating the overall computational process. The degree of reduction can be controlled by a user-defined error tolerance parameter. The algorithm is implemented in the finite element framework SfePy, and its performance effectiveness is demonstrated using two-dimensional test examples, when compared with solutions obtained by the proper orthogonal decomposition method, and by the full "FE-square" simulations. Extensions beyond the present implementations and the scope of tractable problems are discussed.

</details>


### [104] [Convergence analysis of $L^{p+1}$-normalized gradient flow for action ground state of nonlinear Schrödinger equation](https://arxiv.org/abs/2602.20820)
*Wei Liu,Tingfeng Wang,Xiaofei Zhao*

Main category: math.NA

TL;DR: 本文对用于计算聚焦非线性薛定谔方程作用基态的$L^{p+1}$归一化梯度流结合渐近拉格朗日乘子（GFALM）方法，进行了严格的收敛性分析，建立了半离散和全离散格式的全局与局部指数收敛性理论。


<details>
  <summary>Details</summary>
Motivation: 由于$L^{p+1}$约束缺乏内积结构，传统能量基态的收敛分析方法难以直接应用，因此需要发展新的理论框架来分析作用基态计算方法的收敛性。

Method: 通过刻画邻近基态处$L^{p+1}$约束流形的局部几何结构，建立能量泛函的二次增长性质，并推导出一类Łojasiewicz型梯度不等式，进而分析半离散和全离散GFALM格式的收敛性。

Result: 证明了半离散GFALM格式存在聚点和收敛子列，并在非退化假设下获得局部指数收敛率；该结果被推广至基于傅里叶伪谱法的空间全离散情形，同时揭示了连续时间梯度流的指数收敛性。

Conclusion: 本文为GFALM方法计算非线性薛定谔方程的作用基态提供了坚实的理论基础，拓展了现有基态计算的收敛性分析框架，特别应对了$L^{p+1}$约束带来的数学挑战。

Abstract: This paper presents a rigorous convergence analysis of the $L^{p+1}$-normalized gradient flow with asymptotic Lagrange multiplier (GFALM) method for computing the action ground state of the nonlinear Schrödinger equation in the focusing case. First, a general global convergence theory is established for the semi-discrete GFALM scheme, guaranteeing the existence of an accumulation point and a convergent subsequence. Then, under additional non-degeneracy assumptions, a local exponential convergence rate is rigorously proven. This result is further extended to the fully discrete case using a Fourier pseudo-spectral discretization. The analysis is achieved by characterizing the local geometry of the $L^{p+1}$-constrained manifold near the ground state, establishing a quadratic growth property of the energy functional, and deriving a Łojasiewicz-type gradient inequality. Finally, the paper also investigates the exponential convergence of the associated continuous-time gradient flow, providing a theoretical foundation for future numerical discretizations. This work extends existing convergence analyses for energy ground states, addressing the challenges posed by the $L^{p+1}$ constraint, especially the absence of an inner-product structure.

</details>


### [105] [Hölder-Logarithmic Stability and Convergence Rates for an Inverse Random Source Problem](https://arxiv.org/abs/2602.20822)
*Philipp Mickan,Thorsten Hohage*

Main category: math.NA

TL;DR: 本文研究了一类随机声源反问题，旨在从时间谐波声波的相关测量中恢复非相关随机声源的强度。通过引入复几何光学解和变分源条件，建立了在Sobolev光滑性假设下的Hölder-对数型稳定性估计与收敛速率，并给出了谱正则化方法的理论分析与数值验证。


<details>
  <summary>Details</summary>
Motivation: 逆随机源问题在气动声学和地震成像中有重要应用。尽管此类问题在无噪声下具有唯一性，但其本质上的不适定性要求必须采用正则化方法以稳定地重建源强度。本文旨在建立严格的稳定性估计和收敛速率理论。

Method: 采用复几何光学（CGO）解推导条件Hölder-对数稳定性估计，并通过建立变分源条件，分析谱正则化方法的收敛速率。同时在固定频率下讨论了Sobolev正则性对估计指数的影响，并辅以数值实验验证理论结果。

Result: 得到了在Sobolev光滑性假设下的条件Hölder-对数稳定性估计和收敛速率；发现当源的Sobolev正则性增强时，固定频率下的估计指数会无界增长；数值实验支持了理论分析结果。

Conclusion: 本文为逆随机声源问题提供了严格的数学分析框架，揭示了正则性与稳定性之间的内在关系，证明了谱正则化方法的有效性，为实际应用中的稳定求解提供了理论依据。

Abstract: In this paper, we investigate an inverse random source problem concerned with recovering the strength of a random, uncorrelated acoustic source from correlation measurements of emitted time-harmonic acoustic waves. Such problems arise in applications including aeroacoustics and seismic imaging. Unlike their deterministic counterparts, inverse random source problems are known to be uniquely solvable in the absence of noise. Nevertheless, due to their inherent ill-posedness, regularization is required to stably reconstruct the source strength.
  We derive conditional Hölder-logarithmic stability estimates under Sobolev smoothness assumptions by employing complex geometrical optics solutions. Moreover, by establishing a variational source condition, we obtain Hölder-logarithmic convergence rates for spectral regularization methods. At fixed frequency, the exponents in the logarithmic stability and convergence estimates grow unboundedly as the Sobolev regularity of the source increases. Finally, we present numerical experiments supporting our theoretical findings.

</details>


### [106] [Lanczos with compression for symmetric eigenvalue problems](https://arxiv.org/abs/2602.20948)
*Angelo A. Casulli,Daniel Kressner,Nian Shao*

Main category: math.NA

TL;DR: 提出了一种新的Lanczos压缩方法，用于大型对称矩阵的外部特征对计算，相比传统的多项式过滤重启策略，该方法在理论和实践中均表现出更优的性能。


<details>
  <summary>Details</summary>
Motivation: 为了限制内存使用和正交化成本，传统Lanczos方法依赖于多项式滤波的隐式重启，但缺乏理论保证；本文旨在提出一种更具理论保障且高效的替代方案。

Method: 提出Lanczos with compression方法，通过有理逼近压缩Krylov子空间，牺牲部分结构但保持与后续Lanczos步骤兼容，整个算法仍仅基于矩阵-向量乘法。

Result: 理论分析表明，压缩引入的误差很小，对收敛性影响可忽略；实验显示该方法在矩阵-向量乘法次数上常优于Krylov-Schur方法。

Conclusion: Lanczos压缩是一种高效且理论可靠的新策略，为大规模特征值计算提供了优于传统隐式重启的替代方案。

Abstract: The Lanczos method with implicit restarting is one of the most popular methods for finding a few exterior eigenpairs of a large symmetric matrix $A$. Usually based on polynomial filtering, restarting is crucial to limit memory and the cost of orthogonalization. In this work, we propose a novel strategy for the same purpose, called Lanczos with compression. Unlike polynomial filtering, our approach compresses the Krylov subspace using rational approximation and, in doing so, it sacrifices the structure of the associated Krylov decomposition. Nevertheless, it remains compatible with subsequent Lanczos steps and the overall algorithm is still solely based on matrix-vector products with $A$. On the theoretical side, we show that compression introduces only a small error compared to standard (unrestarted) Lanczos and therefore has only a negligible impact on convergence. Comparable guarantees are not available for commonly used implicit restarting strategies, including the Krylov--Schur method. On the practical side, our numerical experiments demonstrate that compression often outperforms the Krylov--Schur method in terms of matrix-vector products.

</details>


### [107] [Orthonormal polynomial wavelets associated with de la Vallée Poussin-type interpolation on $[-1,1]$](https://arxiv.org/abs/2602.20955)
*Woula Themistoclakis,Marc Van Barel*

Main category: math.NA

TL;DR: 本文提出了一种新的正交多项式尺度与小波基，用于非标准多分辨率分析中的逼近和细节空间，具有与已有的插值基相似的良好局部化特性，并证明了其傅里叶投影和离散正交投影的勒贝格常数一致有界且具有一致收敛性，数值实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 由于在许多应用中正交基比插值基更受青睐，因此需要构造适用于相同逼近和细节空间的正交多项式基。

Method: 基于de la Vallée Poussin型插值构造新的正交多项式尺度与小波基，研究其连续与离散傅里叶类正交投影，并分析勒贝格常数的有界性和收敛性。

Result: 新基具有良好的局部化和正交性，勒贝格常数一致有界，收敛速度可与最佳一致多项式逼近相比，数值实验验证了理论结果。

Conclusion: 所提出的正交VP尺度与小波基是有效的，适用于非标准多分辨率分析，且性能优于或类似于先前的插值基。

Abstract: Starting from de la Vallée Poussin type (VP) interpolation, the authors have recently introduced a family of interpolating polynomial scaling and wavelet bases generating the approximation and detail spaces of a non-standard multiresolution analysis. Motivated by the fact that, in many applications, orthonormal rather than interpolating bases are preferable, the present study develops a new family of scaling and wavelet polynomials that provide well-localized and orthonormal bases for the same approximation and detail spaces.
  We show that the proposed new bases have a behavior very similar to the interpolating bases already introduced, presenting similar features although they are not interpolating but orthonormal. In particular, we study the Fourier projection corresponding to the proposed orthonormal scaling basis, and introduce a discrete version of it by approximating the Fourier--like coefficients. For both continuous and discrete orthogonal projections, we prove the uniform boundedness of the Lebesgue constants and the uniform convergence with an asymptotic rate comparable with the best uniform polynomial approximation.
  Numerical experiments confirm the theoretical results and compare the new orthonormal VP scaling and wavelet bases with the interpolating case previously treated by the authors.

</details>


### [108] [Variants of Raviart-Thomas mixed elements for curved domains using straight-edged tetrahedra](https://arxiv.org/abs/2602.21197)
*Vittoriano Ruas*

Main category: math.NA

TL;DR: 本文研究了在曲面空间域上使用四面体Raviart-Thomas混合有限元方法求解二阶边值问题的数值方法，重点分析了边界法向通量已知时如何最优施加边界自由度的问题，并验证了二维Petrov-Galerkin方法可自然推广至三维情形，通过数值实验比较了不同策略的精度表现。


<details>
  <summary>Details</summary>
Motivation: 针对曲面区域上带有法向通量边界条件的二阶边值问题，探讨在使用混合有限元方法时如何合理施加边界条件以避免因节点偏移导致的精度下降问题。

Method: 采用基于参数化单元的标准Galerkin格式和结合直边三角形单元的Petrov-Galerkin格式，其中测试通量空间允许节点沿法向偏移，而试通量空间则满足真实边界上的通量条件；并将二维方法推广至三维四面体情形，进行最低阶及类Hermite改进格式的数值实验对比。

Result: 数值结果表明，将Petrov-Galerkin方法推广至三维后能有效保持精度，优于直接在近似多面体边界上施加边界条件的‘do-nothing’策略，且在最低阶情况下其Hermite类比版本也显示出良好性能。

Conclusion: 通过适当分离测试与试函数空间中的边界处理方式，可在三维情况下有效提升混合有限元方法对曲面边界问题的求解精度，验证了该方法在三维应用中的可行性和优越性。

Abstract: A numerical study of tetrahedral Raviart-Thomas mixed finite element methods is presented in the solution of model second order boundary value problems posed in a curved spatial domain. An emphasis is given to the case where normal fluxes are prescribed on a boundary portion. In this case the question on the best way to enforce known boundary degrees of freedom is raised. It seems intuitive that the normal component of the flux variable should preferably not take up corresponding prescribed values at nodes shifted to the boundary of the approximating polyhedron in the underlying normal direction. This is because an accuracy downgrade is to be expected, as shown in https://doi.org/10.1137/15M1045442 and https://doi.org/10.1051/m2an/2025028. In the former work accuracy improvement is achieved by means of a standard Galerkin formulation with parametric elements. The latter one in turn advocates the use of straight-edged triangles combined with a Petrov-Galerkin formulation, in which the aforementioned shift applies only to the test-flux space, while the shape-flux space consists of fields whose fluxes satisfy the prescribed conditions on the true boundary. The first purpose of this article is to show that the method studied in https://doi.org/10.1051/m2an/2025028 for two-dimensional problems can be extended quite naturally to the three-dimensional case. More particularly we illustrate this by carrying out numerical experimentation with such a version for the two lowest order methods of this family, as compared to the corresponding do-nothing strategy. In the case of the lowest order method this comparative study is enriched by assessing as well the performance of its Hermite analog introduced in https://doi.org/10.1016/j.cam.2012.08.027.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [109] [A Novel NPT Thermodynamic Integration Scheme to Derive Rigorous Gibbs Free Energies for Crystalline Solids](https://arxiv.org/abs/2602.20738)
*Karel L. K. De Witte,Tom Braeckevelt,Massimo Bocus,Sander Vandenhaute,Veronique Van Speybroeck*

Main category: physics.comp-ph

TL;DR: 提出了一种全新的在NPT系综中进行的两步热力学积分（TI）方法，用于精确计算固体的吉布斯自由能，避免了传统方法中近似的NVT到NPT校正步骤。


<details>
  <summary>Details</summary>
Motivation: 传统TI方法在从NVT谐波参考态出发时忽略了完整的晶胞柔性，导致NVT到NPT校正不准确，尤其是在复杂晶胞形状波动的体系中。因此需要一种更严格且普适的方法。

Method: 开发了一种全新的NPT参考态，明确考虑了完整的晶胞涨落，并构建了一个完全在NPT系综中运行的两步TI方案，从而省略了传统的近似校正步骤。

Result: 新方法在冰多晶型物中与传统TI结果高度一致；在具有复杂晶胞形状行为的CsPbI3黑相中，表现出更高的准确性。同时保持了相当的计算成本并简化了工作流程。

Conclusion: 该NPT TI方案为固体提供了严格且直接的吉布斯自由能计算途径，优于传统方法，尤其适用于晶胞柔性显著的体系。

Abstract: Thermodynamic Integration (TI) is the state-of-the-art computational technique for accurate Gibbs free energy predictions of solids. Conventional TI schemes start from an NVT harmonic reference and require three successive corrections to recover the Gibbs free energy of the real crystal in the NPT ensemble. However, the NVT-to-NPT correction neglects full cell flexibility. Here, we present a rigorous (and only) two-step TI scheme that operates entirely in the NPT ensemble, eliminating the need for the approximate NVT-to-NPT step. The key methodological advancement is the novel NPT reference that explicitly accounts for full cell fluctuations. The new approach is compared with the conventional one via two complementary case studies. For ice polymorphs, having simple cell-shape distributions, the new approach reproduces conventional TI results with excellent agreement. For CsPbI3, whose black phase exhibits complex cell-shape behavior, we demonstrate that our novel method provides more accurate Gibbs free energy differences than the conventional one. Moreover, the proposed framework maintains comparable computational cost while offering a simplified workflow. Overall, the new NPT TI scheme provides rigorous and direct Gibbs free energy calculations for solids.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [110] [Semi-parametric Bayesian inference under Neyman orthogonality](https://arxiv.org/abs/2602.20371)
*Magid Sabbagh,David A. Stephens*

Main category: math.ST

TL;DR: 本文研究了在贝叶斯框架下，当满足Neyman正交性时，两步法或插件推断方法在半参数模型中的有效性，并利用Dirichlet过程和贝叶斯自助法证明了目标参数的边际后验具有良好频率性质。


<details>
  <summary>Details</summary>
Motivation: 质疑贝叶斯框架中两步法或插件推断方法的有效性，特别是在处理非参数建模的干扰成分时。

Method: 采用基于Dirichlet过程和贝叶斯自助法的非参数贝叶斯公式，研究满足Neyman正交性的半参数模型。

Result: 证明了即使不考虑干扰参数的推断不确定性，目标参数的边际后验仍具有良好的频率特性；在因果推断问题中，倾向得分的插件对因果效应参数的边际后验推断影响可忽略。

Conclusion: 在满足一定条件（如Neyman正交性）下，两步法是进行贝叶斯推断的有效方式，且后验分布收敛所需条件比频率学派更宽松。

Abstract: The validity of two-step or plug-in inference methods is questioned in the Bayesian framework. We study semi-parametric models where the plug-in of a non-parametrically modelled nuisance component is used. We show that when the nuisance and targeted parameters satisfy a Neyman orthogonal score property, the approach of cutting feedback through a two-step procedure is a valid way of conducting Bayesian inference. Our method relies on a non-parametric Bayesian formulation based on the Dirichlet process and the Bayesian bootstrap. We show that the marginal posterior of the targeted parameter exhibits good frequentist properties despite not accounting for the inferential uncertainty of the nuisance parameter. We adopt this approach in Bayesian causal inference problems where the nuisance propensity score model is estimated to obtain marginal inference for the treatment effect parameter, and demonstrate that a plug-in of the propensity score has a negligible effect on marginal posterior inference for the causal contrast. We investigate the absence of Neyman orthogonality and exploit our findings to show that in conventional two-step procedures, the posterior distribution converges under weaker restrictions than those needed in the frequentist sequel. For a simple family of useful scores, we demonstrate that even in the absence of Neyman orthogonality, the posterior distribution is asymptotically unchanged by the estimation of the nuisance parameter, merely provided the latter estimator is consistent.

</details>


### [111] [Scalable multitask Gaussian processes for complex mechanical systems with functional covariates](https://arxiv.org/abs/2602.20640)
*Razak Christophe Sabi Gninkou,Andrés F. López-Lopera,Franck Massa,Rodolphe Le Riche*

Main category: math.ST

TL;DR: 本文提出了一种具有函数协变量的多任务高斯过程模型，通过可分离核结构和Kronecker积实现跨任务与函数输入的依赖建模，并在合成与实际铆接结构问题中验证了其高效性与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有高斯过程模型在同时处理函数型协变量和多相关函数任务方面研究不足，难以满足数字仿真中对预测及其置信区间的需求。

Method: 引入完全可分离的核结构，利用Kronecker结构的协方差矩阵实现模型可扩展性，构建能联合处理函数协变量和多任务的高斯过程框架。

Result: 在合成基准和铆接组件实际案例中，所提模型显著优于单任务高斯过程，仅需不到100个样本即可获得准确的均值与置信区间预测，且计算学习更高效。

Conclusion: 所提出的函数型多任务高斯过程模型有效结合了函数协变量与多任务学习，具备良好的可扩展性、预测精度和不确定性量化能力，适用于工程中的复杂仿真问题。

Abstract: Functional covariates arise in many scientific and engineering applications when model inputs take the form of time-dependent or spatially distributed profiles, such as varying boundary conditions or changing material behaviours. In addition, new practices in digital simulation require predictions accompanied by confidence intervals. Models based on Gaussian processes (GPs) provide principled uncertainty quantification. However, GPs capable of jointly handling functional covariates and multiple correlated functional tasks remain largely under-explored. In this work, we extend the framework of GPs with functional covariates to multitask problems by introducing a fully separable kernel structure that captures dependencies across tasks and functional inputs. By taking advantage of the Kronecker structure of the covariance matrix, the model is made scalable. The proposed model is validated on a synthetic benchmark and applied to a realistic structure, a riveted assembly with functional descriptions of the material behaviour and response forces. The proposed functional multitask GP significantly improves over single task GPs. For the riveted assembly, it requires less than 100 samples to produce an accurate mean and confidence interval prediction. Despite its larger number of parameters, the multitask GP is computationally easier to learn than its single task pendant.

</details>


### [112] [Statistical Inference in Causal Partial Identification with Smooth Densities](https://arxiv.org/abs/2602.20681)
*Sirui Lin,Zijun Gao,Jose Blanchet,Peter Glynn*

Main category: math.ST

TL;DR: 本文提出了一种基于小波的条件最优传输（COT）估计方法，用于因果推断中的部分识别问题，在多变量协变量和结果下实现渐近正态性，并支持有效的统计推断。


<details>
  <summary>Details</summary>
Motivation: 由于潜在结果缺失，许多因果量只能部分识别，现有的COT方法在高维协变量和结果下易受维度诅咒影响，难以进行统计推断。

Method: 利用协变量和潜在结果密度的平滑性，提出一种基于小波的COT原问题估计方法，并针对二次代价函数建立稳定性结果。

Result: 所提方法克服了维度诅咒，在多变量设置下实现了渐近正态性，数值实验表明其在估计和推断性能上优于现有基准方法。

Conclusion: 该方法为条件最优传输下的部分识别提供了可进行有效统计推断的新工具，适用于高维场景。

Abstract: Many causal quantities are only partially identifiable due to the inherent missingness of potential outcomes, and the associated partial identification (PI) sets can be obtained by solving an optimal transport (OT) problem. Covariates often provide additional information about the potential outcomes and thus yield tighter PI sets, which can be obtained via conditional optimal transport (COT). However, COT-based PI set estimators are susceptible to the curse of dimensionality in the covariates and outcomes, which precludes the asymptotic normality and hinders statistical inference. In this paper, we exploit smoothness in the marginal densities of covariates and potential outcomes and develop a wavelet-based primal method for COT with multivariate outcomes and covariates. Moreover, for quadratic cost functions, we establish a stability result for COT and prove asymptotic normality of the proposed estimator. This characterization of the asymptotic distribution enables valid statistical inference for the partial identification set. Empirically, we validate the estimation and inference performance of our approach through numerical experiments in comparison with existing benchmarks.

</details>


### [113] [Upper Bounds for the I-MSE and max-MSE of Kernel Density Estimators](https://arxiv.org/abs/2602.20815)
*Nils Lid Hjort,Nikolai G. Ushakov*

Main category: math.ST

TL;DR: 本文在有限样本情况下直接研究核密度估计量的性能，推导了积分和最大均方误差函数的上界，并比较了传统核与非传统的sinc核的表现差异。


<details>
  <summary>Details</summary>
Motivation: 通常通过泰勒展开和渐近逼近来研究核密度估计的性能，但本文关注的是有限样本情况下的表现。

Method: 利用特征函数和经验特征函数相关的方法，推导出传统核（概率密度函数）和非传统sinc核（不可积且取负值）在不同假设下的误差上界。

Result: 得到了积分和最大均方误差的有用上界，并指出sinc核在某些方面优于传统核估计器。

Conclusion: sinc核基估计器在特定条件下比传统核估计器表现更优，展示了其潜在优势。

Abstract: The performance of kernel density estimators is usually studied via Taylor expansions and asymptotic approximation arguments, in which the bandwidth parameter tends to zero with increasing sample size. In contrast, this paper focusses directly on the finite-sample situation. Informative upper bounds are derived both for the integrated and the maximal mean squared error function. Results are reached for the traditional case, where the kernel is a probability density function, under various sets of assumptions on the underlying density to be estimated. Results are also derived for the important non-conventional case of the sinc kernel, which is not integrable and also takes negative values. We pin-point ways in which the sinc-based estimator performs better than the conventional kernel estimators. When proving our results we rely on methods related to characteristic and empirical characteristic functions.

</details>


### [114] [Efficient Online Learning in Interacting Particle Systems](https://arxiv.org/abs/2602.20875)
*Louis Sharrock,Nikolas Kantas,Grigorios A. Pavliotis*

Main category: math.ST

TL;DR: 提出了一种基于连续观测少量粒子的随机相互作用粒子系统的在线参数估计新方法，通过递归更新模型参数并利用渐近对数似然梯度的随机逼近来实现，并在理论和数值上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在仅能观测到少量粒子的情况下，对复杂的随机相互作用粒子系统进行有效的在线参数估计，克服传统方法在高维或大规模系统中的局限性。

Method: 采用基于连续观测的递归更新机制，使用渐近对数似然函数梯度的随机逼近进行参数估计，并分析其在时间趋于无穷和粒子数趋于无穷双重极限下的收敛性。

Result: 在适当假设下证明了该方法收敛到渐近对数似然的平稳点，建立了L²收敛速率和中心极限定理；数值实验表明该方法在理论假设不满足时仍有效。

Conclusion: 所提方法为复杂相互作用粒子系统的在线参数估计提供了有效且鲁棒的解决方案，兼具理论保证和实际应用价值。

Abstract: We introduce a new method for online parameter estimation in stochastic interacting particle systems, based on continuous observation of a small number of particles from the system. Our method recursively updates the model parameters using a stochastic approximation of the gradient of the asymptotic log likelihood, which is computed using the continuous stream of observations. Under suitable assumptions, we rigorously establish convergence of our method to the stationary points of the asymptotic log-likelihood of the interacting particle system. We consider asymptotics both in the limit as the time horizon $t\rightarrow\infty$, for a fixed and finite number of particles, and in the joint limit as the number of particles $N\rightarrow\infty$ and the time horizon $t\rightarrow\infty$. Under additional assumptions on the asymptotic log-likelihood, we also establish an $\mathrm{L}^2$ convergence rate and a central limit theorem. Finally, we present several numerical examples of practical interest, including a model for systemic risk, a model of interacting FitzHugh--Nagumo neurons, and a Cucker--Smale flocking model. Our numerical results corroborate our theoretical results, and also suggest that our estimator is effective even in cases where the assumptions required for our theoretical analysis do not hold.

</details>


### [115] [On Stein's test of uniformity on the hypersphere](https://arxiv.org/abs/2602.20896)
*Paul Axmann,Bruno Ebner,Eduardo García-Portugués*

Main category: math.ST

TL;DR: 提出了一种基于Laplace-Beltrami算子的Stein特征化的新球面均匀性检验方法，利用Gegenbauer多项式进行调和分解，并引入可调参数以增强检验功效。


<details>
  <summary>Details</summary>
Motivation: 为了改进在超球面上对数据分布是否均匀的检测能力，特别是在面对不同替代假设时提高检验的功效。

Method: 基于Laplace-Beltrami算子的Stein特征化方法，结合Gegenbauer多项式的调和分解，并引入含可调参数的检验统计量；推导了零假设和固定备择假设下统计量的分布形式。

Result: 得到了检验统计量在零假设和备择假设下的闭式分布表达式，提出了基于数据驱动的参数选择策略，并通过数值实验验证其在多种情形下优于现有Sobolev类检验方法。

Conclusion: 该方法属于Sobolev检验类，具有良好的理论性质和实际表现，尤其在适当选择调参时能显著提升对多种非均匀替代方案的检测能力。

Abstract: We propose a new test of uniformity on the hypersphere based on a Stein characterization associated with the Laplace--Beltrami operator. We identify a sufficient class of test functions for this characterization, linked to the moment generating function. Exploiting the operator's eigenfunctions to obtain a harmonic decomposition in terms of Gegenbauer polynomials, we show that the proposed procedure belongs to the class of Sobolev tests. We derive closed-form expressions for the distribution of the test statistic under the null hypothesis and under fixed alternatives. To enhance power against a range of alternatives, we introduce a tuning parameter into the characterization and study its impact on rejection probabilities. We discuss data-driven strategies for selecting this parameter to maximize rejection rates for a given alternative and compare the resulting performance with that of related parametric tests. Additional numerical experiments compare the proposed test with competing Sobolev-class procedures, highlighting settings in which it offers clear advantages.

</details>


### [116] [Parameterising the effect of a continuous treatment using average derivative effects](https://arxiv.org/abs/2109.13124)
*Oliver J. Hines,Karla Diaz-Ordaz,Stijn Vansteelandt*

Main category: math.ST

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The average treatment effect (ATE) is commonly used to quantify the main effect of a binary treatment on an outcome. Extensions to continuous treatments are usually based on the dose-response curve or shift interventions, but both require strong overlap conditions and the resulting curves may be difficult to summarise. We focus instead on average derivative effects (ADEs) that are scalar estimands related to infinitesimal shift interventions requiring only local overlap assumptions. ADEs, however, are rarely used in practice because their estimation usually requires estimating conditional density functions. By characterising the Riesz representers of weighted ADEs, we propose a new class of estimands that provides a unified view of weighted ADEs/ATEs when the treatment is continuous/binary. We derive the estimand in our class that minimises the nonparametric efficiency bound, thereby extending optimal weighting results from the binary treatment literature to the continuous setting. We develop efficient estimators for two weighted ADEs that avoid density estimation and are amenable to modern machine learning methods, which we evaluate in simulations and an applied analysis of Warfarin dosage effects.

</details>
