{"id": "2601.04396", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.04396", "abs": "https://arxiv.org/abs/2601.04396", "authors": ["Rebekah White", "Rileigh Bandy", "Teresa Portone"], "title": "Inference in the presence of model-form uncertainties: Leveraging a prediction-oriented approach to improve uncertainty characterization", "comment": null, "summary": "Bayesian inference is a popular approach to calibrating uncertainties, but it can underpredict such uncertainties when model misspecification is present, impacting its reliability to inform decision making. Recently, the statistics and machine learning communities have developed prediction-oriented inference approaches that provide better calibrated uncertainties and adapt to the level of misspecification present. However, these approaches have yet to be demonstrated in the context of complex scientific applications where phenomena of interest are governed by physics-based models. Such settings often involve single realizations of high-dimensional spatio-temporal data and nonlinear, computationally expensive parameter-to-observable maps. This work investigates variational prediction-oriented inference in problems exhibiting these relevant features; namely, we consider a polynomial model and a contaminant transport problem governed by advection-diffusion equations. The prediction-oriented loss is formulated as the log-predictive probability of the calibration data. We study the effects of increasing misspecification and noise, and we assess approximations of the predictive density using Monte Carlo sampling and component-wise kernel density estimation. A novel aspect of this work is applying prediction-oriented inference to the calibration of model-form uncertainty (MFU) representations, which are embedded physics-based modifications to the governing equations that aim to reduce (but rarely eliminate) model misspecification. The computational results demonstrate that prediction-oriented frameworks can provide better uncertainty characterizations in comparison to standard inference while also being amenable to the calibration of MFU representations."}
{"id": "2601.04507", "categories": ["cs.CE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04507", "abs": "https://arxiv.org/abs/2601.04507", "authors": ["Fang Wu"], "title": "A Semi-supervised Molecular Learning Framework for Activity Cliff Estimation", "comment": null, "summary": "Machine learning (ML) enables accurate and fast molecular property predictions, which are of interest in drug discovery and material design. Their success is based on the principle of similarity at its heart, assuming that similar molecules exhibit close properties. However, activity cliffs challenge this principle, and their presence leads to a sharp decline in the performance of existing ML algorithms, particularly graph-based methods. To overcome this obstacle under a low-data scenario, we propose a novel semi-supervised learning (SSL) method dubbed SemiMol, which employs predictions on numerous unannotated data as pseudo-signals for subsequent training. Specifically, we introduce an additional instructor model to evaluate the accuracy and trustworthiness of proxy labels because existing pseudo-labeling approaches require probabilistic outputs to reveal the model's confidence and fail to be applied in regression tasks. Moreover, we design a self-adaptive curriculum learning algorithm to progressively move the target model toward hard samples at a controllable pace. Extensive experiments on 30 activity cliff datasets demonstrate that SemiMol significantly enhances graph-based ML architectures and outpasses state-of-the-art pretraining and SSL baselines."}
{"id": "2601.04510", "categories": ["cs.CE", "cs.AI", "cs.CV", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.04510", "abs": "https://arxiv.org/abs/2601.04510", "authors": ["Christophe Bonneville", "Nathan Bieberdorf", "Pieterjan Robbe", "Mark Asta", "Habib Najm", "Laurent Capolungo", "Cosmin Safta"], "title": "Towards Spatio-Temporal Extrapolation of Phase-Field Simulations with Convolution-Only Neural Networks", "comment": null, "summary": "Phase-field simulations of liquid metal dealloying (LMD) can capture complex microstructural evolutions but can be prohibitively expensive for large domains and long time horizons. In this paper, we introduce a fully convolutional, conditionally parameterized U-Net surrogate designed to extrapolate far beyond its training data in both space and time. The architecture integrates convolutional self-attention, physically informed padding, and a flood-fill corrector method to maintain accuracy under extreme extrapolation, while conditioning on simulation parameters allows for flexible time-step skipping and adaptation to varying alloy compositions. To remove the need for costly solver-based initialization, we couple the surrogate with a conditional diffusion model that generates synthetic, physically consistent initial conditions. We train our surrogate on simulations generated over small domain sizes and short time spans, but, by taking advantage of the convolutional nature of U-Nets, we are able to run and extrapolate surrogate simulations for longer time horizons than what would be achievable with classic numerical solvers. Across multiple alloy compositions, the framework is able to reproduce the LMD physics accurately. It predicts key quantities of interest and spatial statistics with relative errors typically below 5% in the training regime and under 15% during large-scale, long time-horizon extrapolations. Our framework can also deliver speed-ups of up to 36,000 times, bringing the time to run weeks-long simulations down to a few seconds. This work is a first stepping stone towards high-fidelity extrapolation in both space and time of phase-field simulation for LMD."}
{"id": "2601.04569", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.04569", "abs": "https://arxiv.org/abs/2601.04569", "authors": ["Hailiang Zhao", "Ziqi Wang", "Daojiang Hu", "Zhiwei Ling", "Wenzhuo Qian", "Jiahui Zhai", "Yuhao Yang", "Zhipeng Gao", "Mingyi Liu", "Kai Di", "Xinkui Zhao", "Zhongjie Wang", "Jianwei Yin", "MengChu Zhou", "Shuiguang Deng"], "title": "Industrial Data-Service-Knowledge Governance: Toward Integrated and Trusted Intelligence for Industry 5.0", "comment": null, "summary": "The convergence of artificial intelligence, cyber-physical systems, and cross-enterprise data ecosystems has propelled industrial intelligence to unprecedented scales. Yet, the absence of a unified trust foundation across data, services, and knowledge layers undermines reliability, accountability, and regulatory compliance in real-world deployments. While existing surveys address isolated aspects, such as data governance, service orchestration, and knowledge representation, none provides a holistic, cross-layer perspective on trustworthiness tailored to industrial settings. To bridge this gap, we present \\textsc{Trisk} (TRusted Industrial Data-Service-Knowledge governance), a novel conceptual and taxonomic framework for trustworthy industrial intelligence. Grounded in a five-dimensional trust model (quality, security, privacy, fairness, and explainability), \\textsc{Trisk} unifies 120+ representative studies along three orthogonal axes: governance scope (data, service, and knowledge), architectural paradigm (centralized, federated, or edge-embedded), and enabling technology (knowledge graphs, zero-trust policies, causal inference, etc.). We systematically analyze how trust propagates across digital layers, identify critical gaps in semantic interoperability, runtime policy enforcement, and operational/information technologies alignment, and evaluate the maturity of current industrial implementations. Finally, we articulate a forward-looking research agenda for Industry 5.0, advocating for an integrated governance fabric that embeds verifiable trust semantics into every layer of the industrial intelligence stack. This survey serves as both a foundational reference for researchers and a practical roadmap for engineers to deploy trustworthy AI in complex and multi-stakeholder environments."}
{"id": "2601.04782", "categories": ["hep-lat", "hep-ph", "nucl-ex", "nucl-th"], "pdf": "https://arxiv.org/pdf/2601.04782", "abs": "https://arxiv.org/abs/2601.04782", "authors": ["D. A. Clarke", "H. -T. Ding", "J. -B. Gu", "S. -T. Li", "Swagato Mukherjee", "P. Petreczky", "C. Schmidt", "H. -T. Shu", "K. -F. Ye"], "title": "QCD Crossover at Low Temperatures from Lee-Yang Edge Singularity", "comment": "18 pages, 8 figures", "summary": "We provide the first lattice-QCD estimate of the crossover line down to $T\\simeq108$~MeV. We introduce a new method that combines the Lee-Yang edge in the complex plane of baryon chemical potential $μ_B$ with universal chiral scaling to determine the $μ_B$ dependence of the QCD chiral critical and pseudo-critical temperatures. By performing $(2\\!+\\!1)$-flavor lattice QCD simulations at $T\\simeq108$~MeV and purely imaginary $μ_B$ with a single lattice spacing and two volumes, we compute $μ_B$-dependent baryon-number susceptibilities and extract the location of the Lee-Yang edge. Together with universal scaling near the QCD chiral transition, it constrains the mapping function between $\\{T,μ_B\\}$ and the scaling variable (\\textit{i.e.}\\ the argument of the universal scaling functions). This mapping function then yields the $μ_B$ dependence of the critical and pseudo-critical temperatures for $T\\gtrsim108$~MeV. While our calculation is performed only at a single value of low temperature without explicit input from small-$μ_B$ expansion, the resulting $μ_B$ dependence of the pseudo-critical temperature is consistent with established lattice-QCD determinations at small $μ_B$ and compatible with chemical freeze-out parameters of heavy-ion collisions down to low temperatures, demonstrating the validity and robustness of the method. Application of this method can be systematically extended to additional temperatures and finer discretizations, opening a pathway to charting the QCD phase diagram in the low-$T$, high-$μ_B$ regime."}
{"id": "2601.04602", "categories": ["q-fin.CP", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2601.04602", "abs": "https://arxiv.org/abs/2601.04602", "authors": ["Jack Fanshawe", "Rumi Masih", "Alexander Cameron"], "title": "Forecasting Equity Correlations with Hybrid Transformer Graph Neural Network", "comment": "23 pages, 9 large figures, detailed appendix", "summary": "This paper studies forward-looking stock-stock correlation forecasting for S\\&P 500 constituents and evaluates whether learned correlation forecasts can improve graph-based clustering used in basket trading strategies. We cast 10-day ahead correlation prediction in Fisher-z space and train a Temporal-Heterogeneous Graph Neural Network (THGNN) to predict residual deviations from a rolling historical baseline. The architecture combines a Transformer-based temporal encoder, which captures non-stationary, complex, temporal dependencies, with an edge-aware graph attention network that propagates cross-asset information over the equity network. Inputs span daily returns, technicals, sector structure, previous correlations, and macro signals, enabling regime-aware forecasts and attention-based feature and neighbor importance to provide interpretability. Out-of-sample results from 2019-2024 show that the proposed model meaningfully reduces correlation forecasting error relative to rolling-window estimates. When integrated into a graph-based clustering framework, forward-looking correlations produce adaptable and economically meaningfully baskets, particularly during periods of market stress. These findings suggest that improvements in correlation forecasts translate into meaningful gains during portfolio construction tasks."}
{"id": "2601.04499", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04499", "abs": "https://arxiv.org/abs/2601.04499", "authors": ["Baolin Chen", "Mengfei Ran"], "title": "A Generalized Adaptive Joint Learning Framework for High-Dimensional Time-Varying Models", "comment": null, "summary": "In modern biomedical and econometric studies, longitudinal processes are often characterized by complex time-varying associations and abrupt regime shifts that are shared across correlated outcomes. Standard functional data analysis (FDA) methods, which prioritize smoothness, often fail to capture these dynamic structural features, particularly in high-dimensional settings. This article introduces Adaptive Joint Learning (AJL), a regularization framework designed to simultaneously perform functional variable selection and structural changepoint detection in multivariate time-varying coefficient models. We propose a convex optimization procedure that synergizes adaptive group-wise penalization with fused regularization, effectively borrowing strength across multiple outcomes to enhance estimation efficiency. We provide a rigorous theoretical analysis of the estimator in the ultra-high-dimensional regime (p >> n), establishing non-asymptotic error bounds and proving that AJL achieves the oracle property--performing as well as if the true active set and changepoint locations were known a priori. A key theoretical contribution is the explicit handling of approximation bias via undersmoothing conditions to ensure valid asymptotic inference. The proposed method is validated through comprehensive simulations and an application to Primary Biliary Cirrhosis (PBC) data. The analysis uncovers synchronized phase transitions in disease progression and identifies a parsimonious set of time-varying prognostic markers."}
{"id": "2601.04198", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.04198", "abs": "https://arxiv.org/abs/2601.04198", "authors": ["Léo Simpson", "Moritz Diehl"], "title": "Identification of a Kalman filter: consistency of local solutions", "comment": "Submitted for review to the proceedings of the IFAC World Congress 2026", "summary": "Prediction error and maximum likelihood methods are powerful tools for identifying linear dynamical systems and, in particular, enable the joint estimation of model parameters and the Kalman filter used for state estimation. A key limitation, however, is that these methods require solving a generally non-convex optimization problem to global optimality. This paper analyzes the statistical behavior of local minimizers in the special case where only the Kalman gain is estimated. We prove that these local solutions are statistically consistent estimates of the true Kalman gain. This follows from asymptotic unimodularity: as the dataset grows, the objective function converges to a limit with a unique local (and therefore global) minimizer. We further provide guidelines for designing the optimization problem for Kalman filter tuning and discuss extensions to the joint estimation of additional linear parameters and noise covariances. Finally, the theoretical results are illustrated using three examples of increasing complexity. The main practical takeaway of this paper is that difficulties caused by local minimizers in system identification are, at least, not attributable to the tuning of the Kalman gain."}
{"id": "2601.04681", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.04681", "abs": "https://arxiv.org/abs/2601.04681", "authors": ["Hans van Haren"], "title": "Deep Mediterranean turbulence motions under stratified-water conditions", "comment": "35 pages, 10 figures", "summary": "Vertically stable in density, stratified-water conditions 'SW' exist in the deep Mediterranean Sea that are characterized by temperature differences of 0.0002-0.01degrC over 125 m above a flat seafloor. These result in a mean buoyancy frequency of N = (1.5-2)f, where f denotes the inertial frequency. Although the stability values are one order of magnitude smaller than found in the ocean, they govern a dynamical deep sea as demonstrated using observations from a 3D mooring-array equipped with nearly 3000 high-resolution temperature sensors. SW-conditions can last up to a fortnight, before waters become near-homogeneous, and occur about 40% of the time, slightly more often in winter than in summer. Under SW, up to 60 m above seafloor is dominated by convection turbulence that is partially driven by geothermal heating 'GH' suppressed by stratification above. The upper-half of the array shows dominant shear turbulence driven by two sources. Interfacial internal waves generate weakly-nonlinear, resonant parametric instabilities that, upon breaking, provide mean turbulence dissipation rates of about one-third of that via general GH. It is about equal to open-ocean values away from boundaries and may represent the dominant source of turbulence there. Like GH, the observed turbulence is local up- and down-going. Tenfold larger mean dissipation rates are observed when slanted convection drives turbulent overturns >10 m and unstable clouds are advected with the mean flow. It confirms theoretical marginal stability analyses, previous vertical waterflow observations, and suggests a relationship between turbulence and sub-mesoscale eddies across the internal wave band. Movies support the findings."}
{"id": "2601.04198", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.04198", "abs": "https://arxiv.org/abs/2601.04198", "authors": ["Léo Simpson", "Moritz Diehl"], "title": "Identification of a Kalman filter: consistency of local solutions", "comment": "Submitted for review to the proceedings of the IFAC World Congress 2026", "summary": "Prediction error and maximum likelihood methods are powerful tools for identifying linear dynamical systems and, in particular, enable the joint estimation of model parameters and the Kalman filter used for state estimation. A key limitation, however, is that these methods require solving a generally non-convex optimization problem to global optimality. This paper analyzes the statistical behavior of local minimizers in the special case where only the Kalman gain is estimated. We prove that these local solutions are statistically consistent estimates of the true Kalman gain. This follows from asymptotic unimodularity: as the dataset grows, the objective function converges to a limit with a unique local (and therefore global) minimizer. We further provide guidelines for designing the optimization problem for Kalman filter tuning and discuss extensions to the joint estimation of additional linear parameters and noise covariances. Finally, the theoretical results are illustrated using three examples of increasing complexity. The main practical takeaway of this paper is that difficulties caused by local minimizers in system identification are, at least, not attributable to the tuning of the Kalman gain."}
{"id": "2601.04473", "categories": ["math.ST", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04473", "abs": "https://arxiv.org/abs/2601.04473", "authors": ["Jiaheng Chen", "Daniel Sanz-Alonso"], "title": "Convergence Rates for Learning Pseudo-Differential Operators", "comment": "72 pages, 1 figure", "summary": "This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale sparsity. Building on this structure, we propose a sparse, data- and computation-efficient estimator, which leverages a novel matrix compression scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing."}
{"id": "2601.04358", "categories": ["cond-mat.stat-mech", "cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.04358", "abs": "https://arxiv.org/abs/2601.04358", "authors": ["Alberto Rolandi", "Paolo Abiuso", "Patryk Lipka-Bartosik", "Maxwell Aifer", "Patrick J. Coles", "Martí Perarnau-Llobet"], "title": "Energy-Time-Accuracy Tradeoffs in Thermodynamic Computing", "comment": "10 pages (+ 6 pages of appendix), 7 figures", "summary": "In the paradigm of thermodynamic computing, instead of behaving deterministically, hardware undergoes a stochastic process in order to sample from a distribution of interest. While it has been hypothesized that thermodynamic computers may achieve better energy efficiency and performance, a theoretical characterization of the resource cost of thermodynamic computations is still lacking. Here, we analyze the fundamental trade-offs between computational accuracy, energy dissipation, and time in thermodynamic computing. Using geometric bounds on entropy production, we derive general limits on the energy-delay-deficiency product (EDDP), a stochastic generalization of the traditional energy-delay product (EDP). While these limits can in principle be saturated, the corresponding optimal driving protocols require full knowledge of the final equilibrium distribution, i.e., the solution itself. To overcome this limitation, we develop quasi-optimal control schemes that require no prior information of the solution and demonstrate their performance for matrix inversion in overdamped quadratic systems. The derived bounds extend beyond this setting to more general potentials, being directly relevant to recent proposals based on non-equilibrium Langevin dynamics."}
{"id": "2601.04326", "categories": ["nlin.AO", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.04326", "abs": "https://arxiv.org/abs/2601.04326", "authors": ["Cameron Ziegler", "Per Sebastian Skardal", "Dane Taylor"], "title": "Hodge Decomposition Guides the Optimization of Synchronization over Simplicial Complexes", "comment": "31 pages; 12 figures", "summary": "Despite growing interest in synchronization dynamics over \"higher-order\" network models, optimization theory for such systems is limited. Here, we study a family of Kuramoto models inspired by algebraic topology in which oscillators are coupled over simplicial complexes (SCs) using their associated Hodge Laplacian matrices. We optimize such systems by extending the synchrony alignment function -- an optimization framework for synchronizing graph-coupled heterogeneous oscillators. Computational experiments are given to illustrate how this approach can effectively solve a variety of combinatorial problems including the joint optimization of projected synchronization dynamics onto lower- and upper-dimensional simplices within SCs. We also investigate the role of SC homology and develop bifurcation theory to characterize the extent to which optimal solutions are contained within (or spread across) the three Hodge subspaces. Our work extends optimization theory to the setting of higher-order networks, provides practical algorithms for Hodge-Laplacian-related dynamics including (but not limited to) Kuramoto oscillators, and paves the way for an emerging field that interfaces algebraic topology, combinatorial optimization, and dynamical systems."}
{"id": "2601.04898", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.04898", "abs": "https://arxiv.org/abs/2601.04898", "authors": ["Ao Zhou", "Salma Zahran", "Chi Chen", "Zhengyang Zhang", "Yanming Wang"], "title": "A joint voxel flow - phase field framework for ultra-long microstructure evolution prediction with physical regularization", "comment": "33 pages, 7 figures.Submitted waiting for review", "summary": "Phase-field (PF) modeling is a powerful tool for simulating microstructure evolution. To overcome the high computational cost of PF in solving complex PDEs, machine learning methods such as PINNs, convLSTM have been used to predict PF evolution. However, current methods still face shortages of low flexibility, poor generalization and short predicting time length. In this work, we present a joint framework coupling voxel-flow network (VFN) with PF simulations in an alternating manner for long-horizon temporal prediction of microstructure evolution. The VFN iteratively predicts future evolution by learning the flow of pixels from past snapshots, with periodic boundaries preserved in the process. Periodical PF simulations suppresses nonphysical artifacts, reduces accumulated error, and extends reliable prediction time length. The VFN is about 1,000 times faster than PF simulation on GPU. In validation using grain growth and spinodal decomposition, MSE and SSIM remain 6.76% and 0.911 when predicted 18 frames from only 2 input frames, outperforming similar predicting methods. For an ultra-long grain growth prediction for 82 frames from 2 input frames, grain number decreases from 600 to 29 with NMSE of average grain area remaining 1.64%. This joint framework enables rapid, generalized, flexible and physically consistent microstructure forecasting from image-based data for ultra-long time scales."}
{"id": "2601.04296", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.04296", "abs": "https://arxiv.org/abs/2601.04296", "authors": ["J. L. Cardoso", "V. G. Ibarra-Sierra", "J. C. Sandoval-Santana", "A. Kunold"], "title": "The thermodynamics of liquid-vapor coexistence for a van der Waals fluid. Analytical solution of the Clausius-Clapeyron equation", "comment": "24 pages, 5 figures", "summary": "This work presents a pedagogical derivation of the thermodynamics of a van der Waals fluid by explicitly incorporating pairwise molecular interactions and the finite size of particles into the statistical-mechanical description. Starting from the Lennard-Jones potential, we evaluate the second virial coefficient to infer the virial expansion of the equation of state and recover the van der Waals equation using only its leading correction. The corresponding partition function allows us to obtain all thermodynamic potentials for both monoatomic and diatomic fluids in a transparent and instructive manner.\n  Building on this framework, we formulate and solve analytically the Clausius-Clapeyron equation in the vicinity of the critical point, obtaining the liquid-vapor coexistence curve in closed form. This approach not only clarifies the microscopic origin of van der Waals thermodynamics but also complements-and in several aspects improves upon-traditional treatments that rely heavily on numerical methods or heuristic arguments.\n  In addition, because the van der Waals equation naturally predicts the liquid-vapor equilibrium, the existence of critical points, and the functional form of the saturation curve of the pressure as a function of temperature, it provides an analytically tractable framework for studying a 150-year-old problem that has historically been addressed using graphical constructions or numerical solutions. As such, the formulation developed here offers a coherent, accessible, and conceptually unified route for students and instructors to understand phase coexistence in simple fluids from first principles."}
{"id": "2601.04818", "categories": ["nlin.CD", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.04818", "abs": "https://arxiv.org/abs/2601.04818", "authors": ["Julia Cantisán", "Alexandre R. Nieto", "Jesús M. Seoane"], "title": "Chaotic resetting: A resetting strategy for deterministic chaotic systems", "comment": null, "summary": "Restarting a stochastic search process can accelerate its completion by providing an opportunity to take a more favorable path with each reset. This strategy, known as stochastic resetting, is well studied in random processes. Here, we introduce chaotic resetting, a fundamentally different resetting strategy designed for deterministic chaotic systems. Unlike stochastic resetting, where randomness is intrinsic to the dynamics, chaotic resetting exploits the extreme sensitivity to initial conditions inherent to chaotic motion: unavoidable uncertainties in the reset conditions effectively generate new realizations of the deterministic process. This extension is nontrivial because some realizations may significantly speed up the search, while others may significantly slow it down. We study the conditions required for chaotic resetting to be consistently advantageous, concluding that it requires the presence of a mixed phase space in which fractal and smooth regions coexist. We quantify its effectiveness by demonstrating substantial reductions in average search times when an optimal resetting interval is used. These results establish a clear conceptual bridge between deterministic chaos and search optimization, opening new avenues for accelerating processes in real-world chaotic systems where perfect control or knowledge of initial conditions is unattainable."}
{"id": "2601.04305", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.04305", "abs": "https://arxiv.org/abs/2601.04305", "authors": ["Umberto Borla", "Achilleas Lazarides", "Christian Groß", "Jad C. Halimeh"], "title": "Microscopic Dynamics of False Vacuum Decay in the $2+1$D Quantum Ising Model", "comment": "$9+3$ pages, $5+3$ figures", "summary": "False vacuum decay, which is understood to happen through bubble nucleation, is a prominent phenomenon relevant to elementary particle physics and early-universe cosmology. Understanding its microscopic dynamics in higher spatial dimensions is currently a major challenge and research thrust. Recent advances in numerical techniques allow for the extraction of related signatures in tractable systems in two spatial dimensions over intermediate timescales. Here, we focus on the $2+1$D quantum Ising model, where a longitudinal field is used to energetically separate the two $\\mathbb{Z}_2$ symmetry-broken ferromagnetic ground states, turning them into a ``true'' and ``false'' vacuum. Using tree tensor networks, we simulate the microscopic dynamics of a spin-down domain in a spin-up background after a homogeneous quench, with parameters chosen so that the domain corresponds to a bubble of the true vacuum in a false-vacuum background. Our study identifies how the ultimate fate of the bubble -- indefinite expansion or collapse -- depends on its geometrical features and on the microscopic parameters of the Ising Hamiltonian. We further provide a realistic quantum-simulation scheme, aimed at probing bubble dynamics on atomic Rydberg arrays."}
{"id": "2601.04652", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.04652", "abs": "https://arxiv.org/abs/2601.04652", "authors": ["Na Xiang", "Jingtao Shi"], "title": "Stochastic Linear-Quadratic Optimal Control Problems with Markovian Regime Switching and $H_\\infty$ Constraint under Partial Information", "comment": "46 pages, 10 figures", "summary": "This paper is concerned with a stochastic linear-quadratic optimal control problem of Markovian regime switching system with model uncertainty and partial information, where the information available to the control is based on a sub-$σ$-algebra of the filtration generated by the underlying Brownian motion and the Markov chain. Based on $H_\\infty$ control theory, we turn to deal with a soft-constrained zero-sum linear-quadratic stochastic differential game with Markov chain and partial information. By virtue of the filtering technique, the Riccati equation approach, the method of orthogonal decomposition, and the completion-of-squares method, we obtain the closed-loop saddle point of the zero-sum game via the optimal feedback control-strategy pair. Subsequently, we prove that the corresponding outcome of the closed-loop saddle point satisfies the $H_\\infty$ performance criterion. Finally, the obtained theoretical results are applied to a stock market investment problem to further illustrate the practical significance and effectiveness."}
{"id": "2601.04303", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.04303", "abs": "https://arxiv.org/abs/2601.04303", "authors": ["J. Sears", "V. O. Garlea", "D. Lederman", "J. M. Tranquada", "I. A. Zaliznyak"], "title": "Altermagnetic and dipolar splitting of magnons in FeF$_2$", "comment": null, "summary": "FeF$_2$ is a prototypical rutile antiferromagnet recently proposed as an altermagnet, with a magnetic symmetry that permits spin-split electronic bands and chiral magnons. Using very-high-resolution inelastic neutron scattering on a single crystal of FeF$_2$, we show that the dominant source of magnon splitting is in fact the long-range dipolar interaction rather than altermagnetic exchange terms. At momenta where the dipolar splitting vanishes, we observe additional broadening due to altermagnetic chiral splitting and estimate this splitting to be $\\sim$35 $μ$eV. Polarized measurements further reveal that, where dipolar splitting is present, the chiral magnon modes become mixed and the resulting modes are predominantly linearly polarized, with at most a small chiral component. These findings highlight the significant effect of dipolar interactions on magnon chirality, particularly when altermagnetic interactions are weak."}
{"id": "2601.04429", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04429", "abs": "https://arxiv.org/abs/2601.04429", "authors": ["Ming Zhou", "Klaus Neymeyr"], "title": "Toward genuine efficiency and cluster robustness of preconditioned CG-like eigensolvers", "comment": "25 pages, 8 figures", "summary": "The performance of eigenvalue problem solvers (eigensolvers) depends on various factors such as preconditioning and eigenvalue distribution. Developing stable and rapidly converging vectorwise eigensolvers is a crucial step in improving the overall efficiency of their blockwise implementations. The present paper is concerned with the locally optimal block preconditioned conjugate gradient (LOBPCG) method for Hermitian eigenvalue problems, and motivated by two recently proposed alternatives for its single-vector version LOPCG. A common basis of these eigensolvers is the well-known CG method for linear systems. However, the optimality of CG search directions cannot perfectly be transferred to CG-like eigensolvers. In particular, while computing clustered eigenvalues, LOPCG and its alternatives suffer from frequent delays, leading to a staircase-shaped convergence behavior which cannot be explained by the existing estimates. Keeping this in mind, we construct a class of cluster robust vector iterations where LOPCG is replaced by asymptotically equivalent two-term recurrences and the search directions are timely corrected by selecting a far previous iterate as augmentation. The new approach significantly reduces the number of required steps and the total computational time."}
{"id": "2601.04643", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.04643", "abs": "https://arxiv.org/abs/2601.04643", "authors": ["Cui Yakun", "Yanting Zhang", "Zhu Lei", "Jian Xie", "Zhizhuo Kou", "Hang Du", "Zhenghao Zhu", "Sirui Han"], "title": "MMFCTUB: Multi-Modal Financial Credit Table Understanding Benchmark", "comment": null, "summary": "The advent of multi-modal language models (MLLMs) has spurred research into their application across various table understanding tasks. However, their performance in credit table understanding (CTU) for financial credit review remains largely unexplored due to the following barriers: low data consistency, high annotation costs stemming from domain-specific knowledge and complex calculations, and evaluation paradigm gaps between benchmark and real-world scenarios. To address these challenges, we introduce MMFCTUB (Multi-Modal Financial Credit Table Understanding Benchmark), a practical benchmark, encompassing more than 7,600 high quality CTU samples across 5 table types. MMFCTUB employ a minimally supervised pipeline that adheres to inter-table constraints and maintains data distributions consistency. The benchmark leverages capacity-driven questions and mask-and-recovery strategy to evaluate models' cross-table structure perception, domain knowledge utilization, and numerical calculation capabilities. Utilizing MMFCTUB, we conduct comprehensive evaluations of both proprietary and open-source MLLMs, revealing their strengths and limitations in CTU tasks. MMFCTUB serves as a valuable resource for the research community, facilitating rigorous evaluation of MLLMs in the domain of CTU."}
{"id": "2601.04896", "categories": ["q-fin.CP"], "pdf": "https://arxiv.org/pdf/2601.04896", "abs": "https://arxiv.org/abs/2601.04896", "authors": ["Khabbab Zakaria", "Jayapaulraj Jerinsh", "Andreas Maier", "Patrick Krauss", "Stefano Pasquali", "Dhagash Mehta"], "title": "Deep Reinforcement Learning for Optimum Order Execution: Mitigating Risk and Maximizing Returns", "comment": null, "summary": "Optimal Order Execution is a well-established problem in finance that pertains to the flawless execution of a trade (buy or sell) for a given volume within a specified time frame. This problem revolves around optimizing returns while minimizing risk, yet recent research predominantly focuses on addressing one aspect of this challenge. In this paper, we introduce an innovative approach to Optimal Order Execution within the US market, leveraging Deep Reinforcement Learning (DRL) to effectively address this optimization problem holistically. Our study assesses the performance of our model in comparison to two widely employed execution strategies: Volume Weighted Average Price (VWAP) and Time Weighted Average Price (TWAP). Our experimental findings clearly demonstrate that our DRL-based approach outperforms both VWAP and TWAP in terms of return on investment and risk management. The model's ability to adapt dynamically to market conditions, even during periods of market stress, underscores its promise as a robust solution."}
{"id": "2601.04538", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.04538", "abs": "https://arxiv.org/abs/2601.04538", "authors": ["Kumar Utkarsh", "Nirmish R. Shah", "Tanvi Banerjee", "Daniel M. Abrams"], "title": "A new method for augmenting short time series, with application to pain events in sickle cell disease", "comment": "15 pages, 9 figures", "summary": "Researchers across different fields, including but not limited to ecology, biology, and healthcare, often face the challenge of sparse data. Such sparsity can lead to uncertainties, estimation difficulties, and potential biases in modeling. Here we introduce a novel data augmentation method that combines multiple sparse time series datasets when they share similar statistical properties, thereby improving parameter estimation and model selection reliability. We demonstrate the effectiveness of this approach through validation studies comparing Hawkes and Poisson processes, followed by application to subjective pain dynamics in patients with sickle cell disease (SCD), a condition affecting millions worldwide, particularly those of African, Mediterranean, Middle Eastern, and Indian descent."}
{"id": "2601.04504", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04504", "abs": "https://arxiv.org/abs/2601.04504", "authors": ["Sojin Park", "Ross Baldick", "Hunyoung Shin"], "title": "Definition and Formulation of Inertia Service Incorporating Inverter-Based Resources", "comment": "10 pages, 5 figures", "summary": "Increasing concerns over the scarcity of inertia have motivated the procurement of inertia as an ancillary service (AS). Despite numerous academic and practical efforts, there remains a lack of consensus regarding the definition and treatment of inertia service in market operations, particularly the specification of inertia variables and the separation between synchronous inertia (SI) from synchronous generators and virtual inertia (VI) from inverter-based resources. To address these issues, this paper proposes a power-oriented (P-oriented) definition based on inertial response, which establishes conceptual consistency between SI and VI and makes the inertia service commensurable with other ASs. This definition explicitly incorporates both positive and negative inertial responses during frequency drop events. We then formulate a security-constrained economic dispatch framework based on this P-oriented definition and demonstrate its practical effectiveness through simulations. Case studies on a modified IEEE 30-bus system show that the proposed bidirectional service definition ensures price signals that reflect the economic value of inertial provision."}
{"id": "2601.04684", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.04684", "abs": "https://arxiv.org/abs/2601.04684", "authors": ["Hans van Haren"], "title": "Deep Mediterranean turbulence motions under near-homogeneous conditions", "comment": "31 pages, 9 figures", "summary": "Very weakly density-stratified, near-homogeneous 'NH' conditions are found in the deep Western Mediterranean Sea. Under these conditions, over vertical ranges of several hundreds of meters water temperature varies only a few 0.0001degrC and the buoyancy frequency is smaller than the local inertial frequency. While such waters are characterized as 'quiescent', they are not stagnant and demonstrate regular bursts of turbulent overturns across scales larger than 10 m that are relevant for deep-sea life. As will be shown from a 3D mooring-array with nearly 3000 high-resolution temperature 'T-'sensors, consecutive NH conditions can last up to a fortnight, before stratified waters are advected over the array. At the site, NH conditions occur about 60% of the time. The majority of NH periods is governed by convection turbulence that is driven by geothermal heating from below. The associated turbulence dissipation rate, which is calculated from Ellison scales after precise band-pass filtering, compares with historic geophysical heat-flux measurements. Convection turbulence leads to buoyancy-driven scaling of spectra, not only of temperature in the turbulence range, but also suggesting extensions across the internal-wave band into sub-mesoscales, and (limited observations of) kinetic energy and waterflow differences. Such spectra are found to be uniform over the 124-m vertical T-sensor range above the flat seafloor. Small spectral deviations are observed when very weakly stratified waters are advected sideways or from above, whereby turbulence levels increase by about 30%. Movies show the alternation between calm periods, turbulent clouds passing, and geothermal-heat flares of various sizes."}
{"id": "2601.04504", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04504", "abs": "https://arxiv.org/abs/2601.04504", "authors": ["Sojin Park", "Ross Baldick", "Hunyoung Shin"], "title": "Definition and Formulation of Inertia Service Incorporating Inverter-Based Resources", "comment": "10 pages, 5 figures", "summary": "Increasing concerns over the scarcity of inertia have motivated the procurement of inertia as an ancillary service (AS). Despite numerous academic and practical efforts, there remains a lack of consensus regarding the definition and treatment of inertia service in market operations, particularly the specification of inertia variables and the separation between synchronous inertia (SI) from synchronous generators and virtual inertia (VI) from inverter-based resources. To address these issues, this paper proposes a power-oriented (P-oriented) definition based on inertial response, which establishes conceptual consistency between SI and VI and makes the inertia service commensurable with other ASs. This definition explicitly incorporates both positive and negative inertial responses during frequency drop events. We then formulate a security-constrained economic dispatch framework based on this P-oriented definition and demonstrate its practical effectiveness through simulations. Case studies on a modified IEEE 30-bus system show that the proposed bidirectional service definition ensures price signals that reflect the economic value of inertial provision."}
{"id": "2601.04906", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.04906", "abs": "https://arxiv.org/abs/2601.04906", "authors": ["Mohammed Es-Salih Benjrada", "Cecile Durot", "Tommaso Lando"], "title": "Inference for concave distribution functions under measurement error", "comment": null, "summary": "We propose an estimator of a concave cumulative distribution function under the measurement error model, where the non-negative variables of interest are perturbed by additive independent random noise. The estimator is defined as the least concave majorant on the positive half-line of the deconvolution estimator of the distribution function. We show its uniform consistency and its square root convergence in law in $\\ell_\\infty(\\mathbb R)$. To assess the validity of the concavity assumption, we construct a test for the nonparametric null hypothesis that the distribution function is concave on the positive half-line, against the alternative that it is not. We calibrate the test using bootstrap methods. The theoretical justification for calibration led us to establish a bootstrap version of Theorem 1 in Söhl and Trabs (2012), a Donsker-type result from which we obtain, as a special case, the limiting behavior of the deconvolution estimator of the distribution function in a bootstrap setting with measurement error. Combining this Donsker-type theorem with the functional delta method, we show that the test statistic and its bootstrap version have the same limiting distribution under the null hypothesis, whereas under the alternative, the bootstrap statistic is stochastically smaller. Consequently, the power of the test tends to one, for any fixed alternative, as the sample size tends to infinity. In addition to the theoretical results for the estimator and the test, we investigate their finite-sample performance in simulation studies."}
{"id": "2601.04983", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.04983", "abs": "https://arxiv.org/abs/2601.04983", "authors": ["Rupayan Bhattacharjee", "Sergi Abadal", "Carmen G. Almudever", "Eduard Alarcon"], "title": "Quantum Neural Network Training and Inference with Low Resolution Control Electronics", "comment": "5 pages, 4 figures", "summary": "Scaling quantum computers requires tight integration of cryogenic control electronics with quantum processors, where Digital-to-Analog Converters (DACs) face severe power and area constraints. We investigate quantum neural network (QNN) training and inference under finite DAC resolution constraints across various DAC resolutions. Pre-trained QNNs achieve accuracy nearly indistinguishable from infinite-precision baselines when deployed on quantum systems with 6-bit DAC control electronics, exhibiting an elbow curve with diminishing returns beyond 4 bits. However, training under quantization reveals gradient deadlock below 12-bit resolution as gradient magnitudes fall below quantization step sizes. We introduce temperature-controlled stochasticity that overcomes this through probabilistic parameter updates, enabling successful training at 4-10 bit resolutions that remarkably matches or exceeds infinite-precision baseline performance. Our findings demonstrate that low-resolution control electronics need not compromise QML performance, enabling significant power and area reduction in cryogenic control systems for practical deployment as quantum hardware scales."}
{"id": "2601.04450", "categories": ["nlin.AO", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.04450", "abs": "https://arxiv.org/abs/2601.04450", "authors": ["Byung Gyu Chae"], "title": "Self-Organized Criticality from Protected Mean-Field Dynamics: Loop Stability and Internal Renormalization in Reflective Neural Systems", "comment": "15 pages, 4 figures", "summary": "The reflective homeostatic dynamics provides a minimal mechanism for self-organized criticality in neural systems. Starting from a reduced stochastic description, we demonstrate within the MSRJD field-theoretic framework that fluctuation effects do not destabilize the critical manifold. Instead, loop corrections are dynamically regularized by homeostatic curvature, yielding a protected mean-field critical surface that remains marginally stable under coarse-graining. Beyond robustness, we show that response-driven structural adaptation generates intrinsic parameter flows that attract the system toward this surface without external fine tuning. Together, these results unify loop renormalization and adaptive response in a single framework and establish a concrete route to autonomous criticality in reentrant neural dynamics."}
{"id": "2601.04450", "categories": ["nlin.AO", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.04450", "abs": "https://arxiv.org/abs/2601.04450", "authors": ["Byung Gyu Chae"], "title": "Self-Organized Criticality from Protected Mean-Field Dynamics: Loop Stability and Internal Renormalization in Reflective Neural Systems", "comment": "15 pages, 4 figures", "summary": "The reflective homeostatic dynamics provides a minimal mechanism for self-organized criticality in neural systems. Starting from a reduced stochastic description, we demonstrate within the MSRJD field-theoretic framework that fluctuation effects do not destabilize the critical manifold. Instead, loop corrections are dynamically regularized by homeostatic curvature, yielding a protected mean-field critical surface that remains marginally stable under coarse-graining. Beyond robustness, we show that response-driven structural adaptation generates intrinsic parameter flows that attract the system toward this surface without external fine tuning. Together, these results unify loop renormalization and adaptive response in a single framework and establish a concrete route to autonomous criticality in reentrant neural dynamics."}
{"id": "2601.04337", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.04337", "abs": "https://arxiv.org/abs/2601.04337", "authors": ["Pierre Nazé"], "title": "Unifying Kibble-Zurek Mechanism in Weakly Driven Processes", "comment": "16 pages, 7 figures", "summary": "A description of the Kibble-Zurek mechanism with linear response theory has been done previously, but ad hoc hypotheses were used, like the use of the rate-dependent impulse window via the Zurek equation in the context of no driving in the relaxation time. In this work, I present a new framework where such hypotheses are unnecessary, preserving all the characteristics of the phenomenon. The Kibble-Zurek scaling obtained for the excess work is close to 2/5, a result that holds for open and thermally isolated systems whose relaxation time diverges at the critical point and the first zero of the relaxation function is finite. I exemplify the results using four different but significant types of scaling functions."}
{"id": "2601.05238", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.05238", "abs": "https://arxiv.org/abs/2601.05238", "authors": ["Sibaram Ruidas", "Sthitadhi Roy", "Subhro Bhattacharjee", "Roderich Moessner"], "title": "How many-body chaos emerges in the presence of quasiparticles", "comment": "18 pages, 15 figures", "summary": "Many-body chaos is a default property of many-body systems; at the same time, near-integrable behaviour due to weakly interacting quasiparticles is ubiquitous throughout condensed matter at low temperature. There must therefore be a, possibly generic, crossover between these very different regimes. Here, we develop a theory encapsulating the notion of a cascade of lightcones seeded by sequences of scattering of weakly interacting harmonic modes as witnessed by a suitably defined chaos diagnostic (classical decorrelator) that measures the spatiotemporal profile of many-body chaos. Our numerics deals with the concrete case of a classical Heisenberg chain, for either sign of the interaction, at low temperatures where the short-time dynamics are well captured in terms of non-interacting spin waves. To model low-temperature dynamics, we use ensembles of initial states with randomly embedded point defects in an otherwise ordered background, which provides a controlled setting for studying the scattering events. The decorrelator exhibits a short-time integrable regime followed by an intermediate `scarred' regime of the cascade of lightcones in progress; these then overlap, leading to an avalanche of scattering events which finally yields the standard long-time signature of many-body chaos."}
{"id": "2601.04313", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04313", "abs": "https://arxiv.org/abs/2601.04313", "authors": ["Robert Ott", "Torsten V. Zache", "Soonwon Choi", "Adam M. Kaufman", "Hannes Pichler"], "title": "Rare-Event Quantum Sensing using Logical Qubits", "comment": "12 pages, 4 figures", "summary": "We present a novel protocol to detect rare signals in a noisy environment using quantum error correction (QEC). The key feature of our protocol is the discrimination between signal and noise through distinct higher-order correlations, realized by the non-linear processing that occurs during syndrome extraction in QEC. In this scheme, QEC has two effects: First, it sacrifices part of the signal $ε$ by recording a reduced, stochastic, logical phase $φ_L = \\mathcal{O}(ε^3)$. Second, it corrects the physical noise and extends the (logical) coherence time for signal acquisition. For rare signals occurring at random times in the presence of local Markovian noise, we explicitly demonstrate an improved sensitivity of our approach over more conventional sensing strategies."}
{"id": "2601.04965", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.04965", "abs": "https://arxiv.org/abs/2601.04965", "authors": ["Liqun Qi", "Chunfeng Cui", "Yi Yu"], "title": "Sum of Squares Decompositions and Rank Bounds for Biquadratic Forms", "comment": null, "summary": "We study positive semi-definite (PSD) biquadratic forms and their sum-of-squares (SOS) representations. For the class of partially symmetric biquadratic forms, we establish necessary and sufficient conditions for positive semi-definiteness and prove that every PSD partially symmetric biquadratic form is a sum of squares of bilinear forms. This extends the known result for fully symmetric biquadratic forms. We describe an efficient computational procedure for constructing SOS decompositions, exploiting the Kronecker-product structure of the associated matrix representation. We present a $2 \\times 2$ PSD biquadratic form, and show that it can be expressed as the sum of three squares, but cannot be expressed as the sum of two squares. Furthermore, we present a $3 \\times 2$ PSD biquadratic form, and show that it can be expressed as the sum of four squares, but cannot be expressed as the sum of three squares. These show that previously proved results that a $2 \\times 2$ PSD biquadratic form can be expressed as the sum of three squares, and a $3 \\times 2$ PSD biquadratic form can be expressed as the sum of four squares, are tight."}
{"id": "2601.04451", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.04451", "abs": "https://arxiv.org/abs/2601.04451", "authors": ["Takuya Okugawa", "Jens Paaske", "Martin Eckstein", "Michael A. Sentef", "Angel Rubio", "Andrew J. Millis"], "title": "Dynamical instability in a Floquet-Driven Dissipative System", "comment": null, "summary": "We analyse the magnon spectrum and distribution function of the antiferromagnetic phase of the Floquet-driven Hubbard model. Above a critical drive strength, we find a dynamical instability, resulting from a change in sign of the magnon damping at a non-zero wavevector. The change in sign means that infinitesimal fluctuations grow with time, corresponding to an instability of the driven state. Implications for the nonequilibrium distribution function and the strong drive nonlinear dynamics are discussed."}
{"id": "2601.04479", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04479", "abs": "https://arxiv.org/abs/2601.04479", "authors": ["Ren-Cang Li"], "title": "Approximations of Extremal Eigenspace and Orthonormal Polar Factor", "comment": null, "summary": "This paper is concerned with two extremal problems from matrix analysis. One is about approximating the top eigenspaces of a Hermitian matrix and the other one about approximating the orthonormal polar factor of a general matrix. Tight error bounds on the quality of the approximations are obtained."}
{"id": "2601.04251", "categories": ["cs.SI", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.04251", "abs": "https://arxiv.org/abs/2601.04251", "authors": ["Kevin Matthe Caramancion"], "title": "Using Grok to Avoid Personal Attacks While Correcting Misinformation on X", "comment": "5 pages, 2 columns, 2 tables, 1 figure", "summary": "Correcting misinformation in public online spaces often exposes users to hostility and ad hominem attacks, discouraging participation in corrective discourse. This study presents empirical evidence that invoking Grok, the native large language model on X, rather than directly confronting other users, is associated with different social responses during misinformation correction. Using an observational design, 100 correction replies across five high-conflict misinformation topics were analyzed, with corrections balanced between Grok-mediated and direct human-issued responses. The primary outcome was whether a correction received at least one ad hominem attack within a 24-hour window. Ad hominem attacks occurred in 72 percent of human-issued corrections and in none of the Grok-mediated corrections. A chi-square test confirmed a statistically significant association with a large effect size. These findings suggest that AI-mediated correction may alter the social dynamics of public disagreement by reducing interpersonal hostility during misinformation responses."}
{"id": "2601.04702", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.04702", "abs": "https://arxiv.org/abs/2601.04702", "authors": ["Samantha Fournier", "Pierfrancesco Urbani"], "title": "Chaos in high-dimensional dynamical systems with tunable non-reciprocity", "comment": null, "summary": "High-dimensional dynamical systems of interacting degrees of freedom are ubiquitous in the study of complex systems. When the directed interactions are totally uncorrelated, sufficiently strong and non-linear, many of these systems exhibit a chaotic attractor characterized by a positive maximal Lyapunov exponent (MLE). On the contrary, when the interactions are completely symmetric, the dynamics takes the form of a gradient descent on a carefully defined cost function, and it exhibits slow dynamics and aging. In this work, we consider the intermediate case in which the interactions are partially symmetric, with a parameter α tuning the degree of non-reciprocity. We show that for any value of α for which the corresponding system has non-reciprocal interactions, the dynamics lands on a chaotic attractor. Correspondingly, the MLE is a non-monotonous function of the degree of non-reciprocity. This implies that conservative forcing deriving from the gradient field of a rough energy landscape can make the system more chaotic."}
{"id": "2601.04231", "categories": ["physics.soc-ph", "cs.MA", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2601.04231", "abs": "https://arxiv.org/abs/2601.04231", "authors": ["Hossein Amiri", "Akshay Deverakonda", "Yuke Wang", "Andreas Züfle"], "title": "Where do We Poop? City-Wide Simulation of Defecation Behavior for Wastewater-Based Epidemiology", "comment": null, "summary": "Wastewater surveillance, which regularly examines the pathogen biomarkers in wastewater samples, is a valuable tool for monitoring infectious diseases circulating in communities. Yet, most wastewater-based epidemiology methods, which use wastewater surveillance results for disease inferences, implicitly assume that individuals excrete only at their residential locations and that the population contribute to wastewater samples are static. These simplifying assumptions ignore daily mobility, social interactions, and heterogeneous toilet use behavior patterns, which can lead to biased interpretation of wastewater results, especially at upstream sampling locations such as neighborhoods, institutions, or buildings. Here, we introduce an agent-based geospatial simulation framework: Building on an established Patterns of Life model, we simulate daily human activities, mobility, and social contacts within a realistic urban environment and extend this agent-based framework with a physiologically motivated defecation cycle and toilet usage patterns. We couple this behavioral model with an infectious disease model to simulate transmissions through spatial and social interactions. When a defecation occurs for an infected agent, we use a pathogen shedding model to determine the amount of pathogen shed in the feces. Such a framework, integrating population mobility, disease transmission, toilet use behavior, and pathogen shedding models, is capable to simulate the Spatial-temporal dynamics of wastewater signals for a city. Using a case study of 10,000 simulated agents in Fulton County, Georgia, we examine how varying infection rates alter epidemic trajectories, pathogen loads in wastewater, and the spatial distribution of contamination across time."}
{"id": "2601.04826", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.04826", "abs": "https://arxiv.org/abs/2601.04826", "authors": ["Ingo Steldermann", "Julia Kowalski"], "title": "Zoomy: flexible modeling and simulation software for free-surface flows", "comment": "34 pages", "summary": "Free-surface flow is relevant to many researchers in water resources engineering, geohazard assessment, as well as coastal and river engineering. Many different free-surface models have been proposed, which span modeling complexity from the hydrostatic Saint-Venant equations to the Reynolds-averaged Navier-Stokes equations. Particularly efficient methods can be derived by depth-averaging, resulting in dimensionally reduced models. Typically, this yields hierarchies of models -- models with a variable system structure depending on the polynomial expansion of the flow variables -- that need to be analyzed and numerically solved.\n  This description, analysis, and simulation are challenging, and existing software solutions only cover a specific subset of models generated by these hierarchies. We propose a new software framework to address this issue. Zoomy allows for an efficient description, symbolic analysis, and numerical solution of depth-averaged hierarchies of free-surface flow models. Zoomy handles a numerical discretization in one- and two-dimensional space on unstructured grids.\n  With this framework, systematic evaluation of hierarchies of depth-averaged free-surface flows becomes feasible. Additionally, our open-source framework increases the accessibility of these depth-averaged systems to application engineers interested in efficient methods for free-surface flows."}
{"id": "2601.04625", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.04625", "abs": "https://arxiv.org/abs/2601.04625", "authors": ["Santiago Marin", "Bronwyn Loong", "Anton H. Westveld"], "title": "Bayesian nonparametric modeling of dynamic pollution clusters through an autoregressive logistic-beta Stirling-gamma process", "comment": "24 pages, 10 figures", "summary": "Fine suspended particulates (FSP), commonly known as PM2.5, are among the most harmful air pollutants, posing serious risks to population health and environmental integrity. As such, accurately identifying latent clusters of FSP is essential for effective air quality and public health management. This task, however, is notably nontrivial as FSP clusters may depend on various regional and temporal factors, which should be incorporated in the modeling process. Thus, we capitalize on Bayesian nonparametric dynamic clustering ideas, in which clustering structures may be influenced by complex dependencies. Existing implementations of dynamic clustering, however, rely on copula-based dependent Dirichlet processes (DPs), presenting considerable computational challenges for real-world deployment. With this in mind, we propose a more efficient alternative for dynamic clustering by incorporating the novel ideas of logistic-beta dependent DPs. We also adopt a Stirling-gamma prior, a novel distribution family, on the concentration parameter of our underlying DP, easing the process of incorporating prior knowledge into the model. Efficient computational strategies for posterior inference are also presented. We apply our proposed method to identify dynamic FSP clusters across Chile and demonstrate its superior performance over existing approaches."}
{"id": "2601.04796", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04796", "abs": "https://arxiv.org/abs/2601.04796", "authors": ["Xi Ru", "Xiaoyu Peng", "Xinghua Chen", "Zhaojian Wang", "Peng Yang", "Feng Liu"], "title": "Matrix-Valued Passivity Indices: Foundations, Properties, and Stability Implications", "comment": "12 pages, 4 figures", "summary": "The passivity index, a quantitative measure of a system's passivity deficiency or excess, has been widely used in stability analysis and control. Existing studies mostly rely on scalar forms of indices, which are restrictive for multi-input, multi-output (MIMO) systems. This paper extends the classical scalar indices to a systematic matrix-valued framework, referred to as passivity matrices. A broad range of classical results in passivity theory can be naturally generalized in this framework. We first show that, under the matrix representation, passivity indices essentially correspond to the curvature of the dissipativity functional under a second-variation interpretation. This result reveals that the intrinsic geometric structure of passivity consists of its directions and intensities, which a scalar index cannot fully capture. For linear time-invariant (LTI) systems, we examine the structural properties of passivity matrices with respect to the Loewner partial order and propose two principled criteria for selecting representative matrices. Compared with conventional scalar indices, the matrix-valued indices capture the passivity coupling among different input-output channels in MIMO systems and provide a more comprehensive description of system passivity. This richer information leads to lower passivation effort and less conservative stability assessment."}
{"id": "2601.04701", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.04701", "abs": "https://arxiv.org/abs/2601.04701", "authors": ["Hannah M. Christensen", "Jack Barker", "Bobby Antonio", "Massimo Bonavita", "Mohamed Dahoui", "Patricia de Rosnay"], "title": "Error in ERA5 2m Temperature identified using GraphCast", "comment": "Submitted to Quarterly Journal of the Royal Meteorological Society", "summary": "Reanalyses such as ERA5 have long been foundational for weather and climate science. They have also found a new use case, as training and verification data for machine-learnt weather prediction (MLWP) models. Here we compare short-lead time (6h) forecasts from the MLWP model GraphCast against ERA5. In doing so, we identify a recurrent, spatially coherent error in 2m Temperature centred on the Ethiopian Highlands, that occurs predominantly at 0600 UTC. We show that these error events are not an error in the forecast from GraphCast, but are in fact an error in ERA5, and are also present in the ECMWF operational analysis. They arise from the 2D optimal interpolation procedure, when surface reports are assimilated that are temporally displaced compared to the background forecast. This produces spuriously warm analysis increments over Ethiopia on approximately 7\\% of dates at 0600 UTC across the reanalysis record. The spread from the ensemble of data assimilation partially flags these cases but is underdispersive. We assess the impact on GraphCast, which was trained on ERA5. While GraphCast can largely ignore these unphysical error events, a small systematic degradation in forecast skill over the region is observed. We discuss implications for using reanalysis as truth in machine learning training and verification, and recommend simple changes to reduce such artefacts in future analyses."}
{"id": "2601.04796", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04796", "abs": "https://arxiv.org/abs/2601.04796", "authors": ["Xi Ru", "Xiaoyu Peng", "Xinghua Chen", "Zhaojian Wang", "Peng Yang", "Feng Liu"], "title": "Matrix-Valued Passivity Indices: Foundations, Properties, and Stability Implications", "comment": "12 pages, 4 figures", "summary": "The passivity index, a quantitative measure of a system's passivity deficiency or excess, has been widely used in stability analysis and control. Existing studies mostly rely on scalar forms of indices, which are restrictive for multi-input, multi-output (MIMO) systems. This paper extends the classical scalar indices to a systematic matrix-valued framework, referred to as passivity matrices. A broad range of classical results in passivity theory can be naturally generalized in this framework. We first show that, under the matrix representation, passivity indices essentially correspond to the curvature of the dissipativity functional under a second-variation interpretation. This result reveals that the intrinsic geometric structure of passivity consists of its directions and intensities, which a scalar index cannot fully capture. For linear time-invariant (LTI) systems, we examine the structural properties of passivity matrices with respect to the Loewner partial order and propose two principled criteria for selecting representative matrices. Compared with conventional scalar indices, the matrix-valued indices capture the passivity coupling among different input-output channels in MIMO systems and provide a more comprehensive description of system passivity. This richer information leads to lower passivation effort and less conservative stability assessment."}
{"id": "2601.05217", "categories": ["math.ST", "cs.IT", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.05217", "abs": "https://arxiv.org/abs/2601.05217", "authors": ["Martin Larsson", "Johannes Ruf", "Aaditya Ramdas"], "title": "A complete characterization of testable hypotheses", "comment": "28 pages", "summary": "We revisit a fundamental question in hypothesis testing: given two sets of probability measures $\\mathcal{P}$ and $\\mathcal{Q}$, when does a nontrivial (i.e.\\ strictly unbiased) test for $\\mathcal{P}$ against $\\mathcal{Q}$ exist? Le~Cam showed that, when $\\mathcal{P}$ and $\\mathcal{Q}$ have a common dominating measure, a test that has power exceeding its level by more than $\\varepsilon$ exists if and only if the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ are separated in total variation distance by more than $\\varepsilon$. The requirement of a dominating measure is frequently violated in nonparametric statistics. In a passing remark, Le~Cam described an approach to address more general scenarios, but he stopped short of stating a formal theorem. This work completes Le~Cam's program, by presenting a matching necessary and sufficient condition for testability: for the aforementioned theorem to hold without assumptions, one must take the closures of the convex hulls of $\\mathcal{P}$ and $\\mathcal{Q}$ in the space of bounded finitely additive measures. We provide simple elucidating examples, and elaborate on various subtle measure theoretic and topological points regarding compactness and achievability."}
{"id": "2601.04926", "categories": ["nlin.AO", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.04926", "abs": "https://arxiv.org/abs/2601.04926", "authors": ["Jinshan Xu", "Changgui Gu", "Alain Pumir", "Nicolas Garnier", "Zonghua Liu"], "title": "Entrainment of the suprachiasmatic nucleus network by a light-dark cycle", "comment": null, "summary": "The synchronization of biological activity with the alternation of day and night (circadian rhythm) is performed in the brain by a group of neurons, constituting the suprachiasmatic nucleus (SCN). The SCN is divided into two subgroups of oscillating cells: the ventro-lateral (VL) neurons, which are exposed to light (photic signal) and the dorso-medial (DM) neurons which are coupled to the VL cells. When the coupling between these neurons is strong enough, the system synchronizes with the photic period. Upon increasing the cell coupling, the entrainment of the DM cells has been recently shown to occur via a very sharp (jumping) transition when the period of the photic input is larger than the intrinsic period of the cells. Here, we characterize this transition with a simple realistic model. We show that two bifurcations possibly lead to the disappearance of the endogenous mode. Using a mean field model, we show that the jumping transition results from a supercritical Hopf-like bifurcation. This finding implies that both the period and strength of the stimulating photic signal, and the relative fraction of cells in the VL and DM compartments are crucial in determining the synchronization of the system."}
{"id": "2601.05161", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.05161", "abs": "https://arxiv.org/abs/2601.05161", "authors": ["Ioannis Kolotouros", "Adithya Sireesh", "Stuart Ferguson", "Sean Thrasher", "Petros Wallden", "Julien Michel"], "title": "Quantum Elastic Network Models and their Application to Graphene", "comment": "42 pages, 11 figures", "summary": "Molecular dynamics simulations are a central computational methodology in materials design for relating atomic composition to mechanical properties. However, simulating materials with atomic-level resolution on a macroscopic scale is infeasible on current classical hardware, even when using the simplest elastic network models (ENMs) that represent molecular vibrations as a network of coupled oscillators. To address this issue, we introduce Quantum Elastic Network Models (QENMs) and utilize the quantum algorithm of Babbush et al. (PRX, 2023), which offers an exponential advantage when simulating systems of coupled oscillators under some specific conditions and assumptions. Here, we demonstrate how our method enables the efficient simulation of planar materials. As an example, we apply our algorithm to the task of simulating a 2D graphene sheet. We analyze the exact complexity for initial-state preparation, Hamiltonian simulation, and measurement of this material, and provide two real-world applications: heat transfer and the out-of-plane rippling effect. We estimate that an atomistic simulation of a graphene sheet on the centimeter scale, classically requiring hundreds of petabytes of memory and prohibitive runtimes, could be encoded and simulated with as few as $\\sim 160$ logical qubits."}
{"id": "2601.04358", "categories": ["cond-mat.stat-mech", "cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.04358", "abs": "https://arxiv.org/abs/2601.04358", "authors": ["Alberto Rolandi", "Paolo Abiuso", "Patryk Lipka-Bartosik", "Maxwell Aifer", "Patrick J. Coles", "Martí Perarnau-Llobet"], "title": "Energy-Time-Accuracy Tradeoffs in Thermodynamic Computing", "comment": "10 pages (+ 6 pages of appendix), 7 figures", "summary": "In the paradigm of thermodynamic computing, instead of behaving deterministically, hardware undergoes a stochastic process in order to sample from a distribution of interest. While it has been hypothesized that thermodynamic computers may achieve better energy efficiency and performance, a theoretical characterization of the resource cost of thermodynamic computations is still lacking. Here, we analyze the fundamental trade-offs between computational accuracy, energy dissipation, and time in thermodynamic computing. Using geometric bounds on entropy production, we derive general limits on the energy-delay-deficiency product (EDDP), a stochastic generalization of the traditional energy-delay product (EDP). While these limits can in principle be saturated, the corresponding optimal driving protocols require full knowledge of the final equilibrium distribution, i.e., the solution itself. To overcome this limitation, we develop quasi-optimal control schemes that require no prior information of the solution and demonstrate their performance for matrix inversion in overdamped quadratic systems. The derived bounds extend beyond this setting to more general potentials, being directly relevant to recent proposals based on non-equilibrium Langevin dynamics."}
{"id": "2601.04364", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.04364", "abs": "https://arxiv.org/abs/2601.04364", "authors": ["Yinan Chen", "Sara Murciano", "Pablo Sala", "Jason Alicea"], "title": "Quantum sensing with critical systems: impact of symmetry, imperfections, and decoherence", "comment": null, "summary": "Entangled many-body states enable high-precision quantum sensing beyond the standard quantum limit. We develop interferometric sensing protocols based on quantum critical wavefunctions and compare their performance with Greenberger-Horne-Zeilinger (GHZ) and spin-squeezed states. Building on the idea of symmetries as a metrological resource, we introduce a symmetry-based algorithm to identify optimal measurement strategies. We illustrate this algorithm both for magnetic systems with internal symmetries and Rydberg-atom arrays with spatial symmetries. We study the robustness of criticality for quantum sensing under non-unitary deformations, symmetry-preserving and symmetry-breaking decoherence, and qubit loss -- identifying regimes where critical systems outperform GHZ states and showing that non-unitary deformation can even enhance sensing precision. Combined with recent results on log-depth preparation of critical wavefunctions, interferometric sensing in this setting appears increasingly promising."}
{"id": "2601.05029", "categories": ["math.OC", "math.FA", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.05029", "abs": "https://arxiv.org/abs/2601.05029", "authors": ["Evie Nielen", "Oliver Tse"], "title": "Stochastic convergence of a class of greedy-type algorithms for Configuration Optimization Problems", "comment": "32 pages, 9 figures", "summary": "Greedy Sampling Methods (GSMs) are widely used to construct approximate solutions of Configuration Optimization Problems (COPs), where a loss functional is minimized over finite configurations of points in a compact domain. While effective in practice, deterministic convergence analyses of greedy-type algorithms are often restrictive and difficult to verify. We propose a stochastic framework in which greedy-type methods are formulated as continuous- time Markov processes on the space of configurations. This viewpoint enables convergence analysis in expectation and in probability under mild structural assumptions on the error functional and the transition kernel. For global error functionals, we derive explicit convergence rates, including logarithmic, polynomial, and exponential decay, depending on an abstract improvement condition. As a pedagogical example, we study stochastic greedy sampling for one-dimensional piece- wise linear interpolation and prove exponential convergence of the $L^1$-interpolation error for $C^2$- functions. Motivated by this analysis, we introduce the Randomized Polytope Division Method (R-PDM), a randomized variant of the classical Polytope Division Method, and demonstrate its effectiveness and variance reduction in numerical experiments"}
{"id": "2601.04560", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.04560", "abs": "https://arxiv.org/abs/2601.04560", "authors": ["Jie Ren", "Yi-Ran Xue", "Run-Jia Luo", "Rui Wang", "Baigeng Wang"], "title": "Artificial Gauge Field Engineered Excited-State Topology: Control of Dynamical Evolution of Localized Spinons", "comment": "5 pages, 4 figures", "summary": "Spinons are elementary excitations at the core of frustrated quantum magnets. Although it is well-established that a pair of spinons can emerge from a magnon via deconfinement, controlled manipulation of individual spinons and direct observation of their deconfinement remain elusive. We propose an artificial gauge field scenario that enables the engineering of specific excited states in quantum spin models. This generates spatially localized individual spinons with high controllability. By applying time-dependent gauge fields, we realize adiabatic braiding of these spinons, as well as their dynamical evolution in a controllable manner. These results not only provide the first direct visualization of individual spinons localized in the bulk, but also point to new possibilities to simulate their confinement process. Finally, we demonstrate the feasibility of our scenario in Rydberg atoms, which suggests an experimentally viable direction--gauge field engineering of correlated phenomena in excited states."}
{"id": "2601.04482", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04482", "abs": "https://arxiv.org/abs/2601.04482", "authors": ["Haojun Qin", "Zhiwei Gao", "Jinye Shen", "George Karniadakis"], "title": "Nonlinear parametrization solver for fractional Burgers equations", "comment": null, "summary": "Fractional Burgers equations pose substantial challenges for classical numerical methods due to the combined effects of nonlocality and shock-forming nonlinear dynamics. In particular, linear approximation frameworks-such as spectral, finite-difference, or discontinuous Galerkin methods-often suffer from Gibbs-type oscillations or require carefully tuned stabilization mechanisms, whose effectiveness degrades in transport-dominated and long-time integration regimes. In this work, we introduce a sequential-in-time nonlinear parametrization (STNP) for solving fractional Burgers equations, including models with a fractional Laplacian or with nonlocal nonlinear fluxes. The solution is represented by a nonlinear parametric ansatz, and the parameter evolution is obtained by projecting the governing dynamics onto the tangent space of the parameter manifold through a regularized least-squares formulation at each time step. This yields a well-posed and stable time-marching scheme that preserves causality and avoids global-in-time optimization. We provide a theoretical analysis of the resulting projected dynamics, including a stability estimate and an a posteriori error bound that explicitly decomposes the total error into contributions from initial condition fitting, projection residuals, and discretization of fractional operators. Our analysis clarifies the stabilizing role of regularization and quantifies its interaction with the nonlocal discretization error. Numerical experiments for both fractional Burgers models demonstrate that STNP achieves oscillation-free shock resolution and accurately captures long-time dynamics. The method consistently outperforms high-order spectral schemes augmented with spectral vanishing viscosity, while requiring significantly fewer degrees of freedom and avoiding ad hoc stabilization."}
{"id": "2601.04253", "categories": ["cs.SI", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.04253", "abs": "https://arxiv.org/abs/2601.04253", "authors": ["Sophie Greenwood", "Nikhil Garg"], "title": "Paper Skygest: Personalized Academic Recommendations on Bluesky", "comment": null, "summary": "We build, deploy, and evaluate Paper Skygest, a custom personalized social feed for scientific content posted by a user's network on Bluesky and the AT Protocol. We leverage a new capability on emerging decentralized social media platforms: the ability for anyone to build and deploy feeds for other users, to use just as they would a native platform-built feed. To our knowledge, Paper Skygest is the first and largest such continuously deployed personalized social media feed by academics, with over 50,000 weekly uses by over 1,000 daily active users, all organically acquired. First, we quantitatively and qualitatively evaluate Paper Skygest usage, showing that it has sustained usage and satisfies users; we further show adoption of Paper Skygest increases a user's interactions with posts about research, and how interaction rates change as a function of post order. Second, we share our full code and describe our system architecture, to support other academics in building and deploying such feeds sustainably. Third, we overview the potential of custom feeds such as Paper Skygest for studying algorithm designs, building for user agency, and running recommender system experiments with organic users without partnering with a centralized platform."}
{"id": "2601.04986", "categories": ["cond-mat.dis-nn", "cond-mat.other", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2601.04986", "abs": "https://arxiv.org/abs/2601.04986", "authors": ["Soumya Ranjan Padhi", "Souvik Roy", "Debashree Chowdhury", "Tapan Mishra"], "title": "Spin-aligned butterfly spectral map in Non-Hermitian quasicrystals", "comment": "5 pages, 4 figures", "summary": "The Non-Hermitian spinful Aubry-André-Harper (AAH) model in the presence of Rashba-type spin-orbit coupling (RSOC) and a spatially varying textured magnetic field is studied. Interestingly, our analysis produces a butterfly spectral map due to the non-trivial extent of localization of the states in the spectrum. This spectral map also exhibits an asymmetric spin alignment with respect to the wings of the butterfly. Our analysis also suggests that the onset of such a spectral map is a combined effect of the non-hermiticity, spin-orbit interaction, and the textured magnetic field."}
{"id": "2601.04267", "categories": ["physics.soc-ph", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.04267", "abs": "https://arxiv.org/abs/2601.04267", "authors": ["Ritwick Mishra", "Abhijin Adiga", "Madhav Marathe", "S. S. Ravi", "Ravi Tandon", "Anil Vullikanti"], "title": "Information Theoretic Optimal Surveillance for Epidemic Prevalence in Networks", "comment": "25 pages, 26 figures", "summary": "Estimating the true prevalence of an epidemic outbreak is a key public health problem. This is challenging because surveillance is usually resource intensive and biased. In the network setting, prior work on cost sensitive disease surveillance has focused on choosing a subset of individuals (or nodes) to minimize objectives such as probability of outbreak detection. Such methods do not give insights into the outbreak size distribution which, despite being complex and multi-modal, is very useful in public health planning. We introduce TESTPREV, a problem of choosing a subset of nodes which maximizes the mutual information with disease prevalence, which directly provides information about the outbreak size distribution. We show that, under the independent cascade (IC) model, solutions computed by all prior disease surveillance approaches are highly sub-optimal for TESTPREV in general. We also show that TESTPREV is hard to even approximate. While this mutual information objective is computationally challenging for general networks, we show that it can be computed efficiently for various network classes. We present a greedy strategy, called GREEDYMI, that uses estimates of mutual information from cascade simulations and thus can be applied on any network and disease model. We find that GREEDYMI does better than natural baselines in terms of maximizing the mutual information as well as reducing the expected variance in outbreak size, under the IC model."}
{"id": "2601.04663", "categories": ["stat.ME", "econ.EM"], "pdf": "https://arxiv.org/pdf/2601.04663", "abs": "https://arxiv.org/abs/2601.04663", "authors": ["Tomohiro Ando", "Tadao Hoshino", "Ruey Tsay"], "title": "Quantile Vector Autoregression without Crossing", "comment": null, "summary": "This paper considers estimation and model selection of quantile vector autoregression (QVAR). Conventional quantile regression often yields undesirable crossing quantile curves, violating the monotonicity of quantiles. To address this issue, we propose a simplex quantile vector autoregression (SQVAR) framework, which transforms the autoregressive (AR) structure of the original QVAR model into a simplex, ensuring that the estimated quantile curves remain monotonic across all quantile levels. In addition, we impose the smoothly clipped absolute deviation (SCAD) penalty on the SQVAR model to mitigate the explosive nature of the parameter space. We further develop a Bayesian information criterion (BIC)-based procedure for selecting the optimal penalty parameter and introduce new frameworks for impulse response analysis of QVAR models. Finally, we establish asymptotic properties of the proposed method, including the convergence rate and asymptotic normality of the estimator, the consistency of AR order selection, and the validity of the BIC-based penalty selection. For illustration, we apply the proposed method to U.S. financial market data, highlighting the usefulness of our SQVAR method."}
{"id": "2601.04817", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04817", "abs": "https://arxiv.org/abs/2601.04817", "authors": ["Mattia Merluzzi", "Olivier Bouchet", "Ali Balador", "Gilles Callebaut", "Anastasius Gavras", "Liesbet Van der Perre", "Albert Banchs", "Mauro Renato Boldi", "Emilio Calvanese Strinati", "Bahare M Khorsandi", "Marja Matinmikko-Blue", "Lars Christoph Schmelz"], "title": "Towards Sustainable 6G: A Holistic View of Trade-offs and Enablers", "comment": "This work has been submitted to IEEE Communications Magazine", "summary": "The sixth generation of mobile networks (6G) can play a central role in shaping a sustainable future, the most compelling contemporary challenge. Connecting the unconnected, reducing carbon emissions of vertical sectors, and allowing heterogeneous types of intelligence (including humans) to safely and constructively interact in complex environments, are only a few of the several challenges that can be supported by 6G. However, this requires a careful design that balances positive and negative impacts of 6G, towards a sustainable and sustainability-enabling technology. This paper presents a holistic view that translates the complex interplay between the 6G enabling effects and the sustainability of 6G by design, into concrete trade-offs and research questions. Starting from today's challenges for society and associated key values, we unfold the dilemma into a set of technical trade-offs, whose solutions span from technological innovations to standardization actions towards applicability."}
{"id": "2601.04713", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.04713", "abs": "https://arxiv.org/abs/2601.04713", "authors": ["Hans van Haren"], "title": "Heat-flash travel just above a deep Mediterranean seafloor", "comment": "27 pages, 9 figures", "summary": "The deep sea is weakly stratified in density but shows considerable variations in turbulent motions in all three directions. When registered by moored high-resolution temperature 'T'-sensors, the motions cause variations of 0.01degrC or less and in time of minutes or less, which is much faster than hours or longer of internal waves. Occasionally, T-sensors close to the seafloor register minute-long flashes of 0.0005-0.001degrC warmer than the environment. When singular, such flashes may be artefacts. However, in a large mooring-array with 45 vertical lines at 9.5-m horizontal distances, near-seafloor heat flashes are seen to travel, most likely with internal-wave instabilities in overlying stratified waters. The instabilities seem to release the flashes from a geothermally heated seafloor of which turbulence convection is suppressed by warmer waters from above. The forms and turbulence intensity of these rare signals are compared with those induced by a Remotely Operated Vehicle working near the array. Other causes like unidentified marine mammal passing are hypothesized."}
{"id": "2601.04817", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04817", "abs": "https://arxiv.org/abs/2601.04817", "authors": ["Mattia Merluzzi", "Olivier Bouchet", "Ali Balador", "Gilles Callebaut", "Anastasius Gavras", "Liesbet Van der Perre", "Albert Banchs", "Mauro Renato Boldi", "Emilio Calvanese Strinati", "Bahare M Khorsandi", "Marja Matinmikko-Blue", "Lars Christoph Schmelz"], "title": "Towards Sustainable 6G: A Holistic View of Trade-offs and Enablers", "comment": "This work has been submitted to IEEE Communications Magazine", "summary": "The sixth generation of mobile networks (6G) can play a central role in shaping a sustainable future, the most compelling contemporary challenge. Connecting the unconnected, reducing carbon emissions of vertical sectors, and allowing heterogeneous types of intelligence (including humans) to safely and constructively interact in complex environments, are only a few of the several challenges that can be supported by 6G. However, this requires a careful design that balances positive and negative impacts of 6G, towards a sustainable and sustainability-enabling technology. This paper presents a holistic view that translates the complex interplay between the 6G enabling effects and the sustainability of 6G by design, into concrete trade-offs and research questions. Starting from today's challenges for society and associated key values, we unfold the dilemma into a set of technical trade-offs, whose solutions span from technological innovations to standardization actions towards applicability."}
{"id": "2601.04499", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04499", "abs": "https://arxiv.org/abs/2601.04499", "authors": ["Baolin Chen", "Mengfei Ran"], "title": "A Generalized Adaptive Joint Learning Framework for High-Dimensional Time-Varying Models", "comment": null, "summary": "In modern biomedical and econometric studies, longitudinal processes are often characterized by complex time-varying associations and abrupt regime shifts that are shared across correlated outcomes. Standard functional data analysis (FDA) methods, which prioritize smoothness, often fail to capture these dynamic structural features, particularly in high-dimensional settings. This article introduces Adaptive Joint Learning (AJL), a regularization framework designed to simultaneously perform functional variable selection and structural changepoint detection in multivariate time-varying coefficient models. We propose a convex optimization procedure that synergizes adaptive group-wise penalization with fused regularization, effectively borrowing strength across multiple outcomes to enhance estimation efficiency. We provide a rigorous theoretical analysis of the estimator in the ultra-high-dimensional regime (p >> n), establishing non-asymptotic error bounds and proving that AJL achieves the oracle property--performing as well as if the true active set and changepoint locations were known a priori. A key theoretical contribution is the explicit handling of approximation bias via undersmoothing conditions to ensure valid asymptotic inference. The proposed method is validated through comprehensive simulations and an application to Primary Biliary Cirrhosis (PBC) data. The analysis uncovers synchronized phase transitions in disease progression and identifies a parsimonious set of time-varying prognostic markers."}
{"id": "2601.04640", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.04640", "abs": "https://arxiv.org/abs/2601.04640", "authors": ["Daiki Hashimoto", "Masaya Kunimi", "Tetsuro Nikuni"], "title": "Construction of asymptotic quantum many-body scar states in the SU($N$) Hubbard model", "comment": null, "summary": "We construct asymptotic quantum many-body scars (AQMBS) in one-dimensional SU($N$) Hubbard chains ($N\\geq 3$) by embedding the scar subspace into an auxiliary Hilbert subspace $\\mathcal{H}_P$ and identifying a parent Hamiltonian within it, together with a corresponding extension of the restricted spectrum-generating algebra to the multi-ladder case. Unlike previous applications of the parent-Hamiltonian scheme, we show that the parent Hamiltonian becomes the SU($N$) ferromagnetic Heisenberg model rather than the spin-1/2 case, so that its gapless magnons realize explicit AQMBS of the original model. Working in the doublon-holon subspace, we derive this mapping, obtain the one-magnon dispersion for periodic and open boundaries, and prove (i) orthogonality to the tower of scar states, (ii) vanishing energy variance in the thermodynamic limit, and (iii) subvolume entanglement entropy with rigorous MPS/MPO bounds. Our results broaden the parent-Hamiltonian family for AQMBS beyond spin-1/2 and provide analytic, low-entanglement excitations in SU($N$)-symmetric systems."}
{"id": "2601.04372", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04372", "abs": "https://arxiv.org/abs/2601.04372", "authors": ["Nikolaos Cheimarios"], "title": "Solving nonlinear PDEs with Quantum Neural Networks: A variational approach to the Bratu Equation", "comment": null, "summary": "We present a variational quantum algorithm (VQA) to solve the nonlinear one-dimensional Bratu equation. By formulating the boundary value problem within a variational framework and encoding the solution in a parameterized quantum neural network (QNN), the problem reduces to an optimization task over quantum circuit parameters. The trial solution incorporates both classical approximations and boundary-enforcing terms, allowing the circuit to focus on minimizing the residual of the differential operator. Using a noiseless quantum simulator, we demonstrate that the method accurately captures both solution branches of the Bratu equation and shows excellent agreement with classical pseudo arc-length continuation results."}
{"id": "2601.05056", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05056", "abs": "https://arxiv.org/abs/2601.05056", "authors": ["Silan Zhang", "Yujie Tang"], "title": "ZIVR: An Incremental Variance Reduction Technique For Zeroth-Order Composite Problems", "comment": null, "summary": "This paper investigates zeroth-order (ZO) finite-sum composite optimization. Recently, variance reduction techniques have been applied to ZO methods to mitigate the non-vanishing variance of 2-point estimators in constrained/composite optimization, yielding improved convergence rates. However, existing ZO variance reduction methods typically involve batch sampling of size at least $Θ(n)$ or $Θ(d)$, which can be computationally prohibitive for large-scale problems. In this work, we propose a general variance reduction framework, Zeroth-Order Incremental Variance Reduction (ZIVR), which supports flexible implementations$\\unicode{x2014}$including a pure 2-point zeroth-order algorithm that eliminates the need for large batch sampling. Furthermore, we establish comprehensive convergence guarantees for ZIVR across strongly-convex, convex, and non-convex settings that match their first-order counterparts. Numerical experiments validate the effectiveness of our proposed algorithm."}
{"id": "2601.04729", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.04729", "abs": "https://arxiv.org/abs/2601.04729", "authors": ["Tao Yang", "Z. Y. Xie", "Rui Wang", "Baigeng Wang"], "title": "Probing quantum critical crossover via impurity renormalization group", "comment": "15 pages total (7 pages main text + 8 pages supplement), 15 figures total (5 figures main text + 10 figures supplement)", "summary": "Quantum impurities can host exotic many-body states that serve as sensitive probes of bath correlations. However, quantitative and non-perturbative methods for determining impurity thermodynamics in such settings remain scarce. Here, we introduce an impurity renormalization group approach that merges the tensor-network representation with the numerical renormalization group cutoff scheme. This method overcomes conventional limitations by treating bath correlations and impurity interactions on an equal footing. Applying our approach to the finite-temperature quantum critical regime of quantum spin systems, we uncover striking impurity-induced phenomena. In a coupled Heisenberg ladder, the impurity triggers a fractionalization of the local magnetic moment. Moreover, the derivative of the impurity susceptibility develops cusps that mark the crossover into the quantum critical regime. We also observe an exotic evolution of the spin correlation function driven by the interplay between bath correlations and the impurity. Our results demonstrate that this method can efficiently solve correlated systems with defects, opening new pathways to discovering novel impurity physics beyond those in non-interacting thermal baths."}
{"id": "2601.04496", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04496", "abs": "https://arxiv.org/abs/2601.04496", "authors": ["Jie Jiang", "Yuesheng Xu"], "title": "Adaptive Multi-Grade Deep Learning for Highly Oscillatory Fredholm Integral Equations of the Second Kind", "comment": null, "summary": "This paper studies the use of Multi-Grade Deep Learning (MGDL) for solving highly oscillatory Fredholm integral equations of the second kind. We provide rigorous error analyses of continuous and discrete MGDL models, showing that the discrete model retains the convergence and stability of its continuous counterpart under sufficiently small quadrature error. We identify the DNN training error as the primary source of approximation error, motivating a novel adaptive MGDL algorithm that selects the network grade based on training performance. Numerical experiments with highly oscillatory (including wavenumber 500) and singular solutions confirm the accuracy, effectiveness and robustness of the proposed approach."}
{"id": "2601.04259", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.04259", "abs": "https://arxiv.org/abs/2601.04259", "authors": ["Cunlai Pu", "Xingyu Gao", "Jinbi Liang", "Jianhui Guo", "Xiangbo Shu", "Yongxiang Xia", "Rajput Ramiz Sharafat"], "title": "IGA-LWP: An Iterative Gradient-based Adversarial Attack for Link Weight Prediction", "comment": null, "summary": "Link weight prediction extends classical link prediction by estimating the strength of interactions rather than merely their existence, and it underpins a wide range of applications such as traffic engineering, social recommendation, and scientific collaboration analysis. However, the robustness of link weight prediction against adversarial perturbations remains largely unexplored.In this paper, we formalize the link weight prediction attack problem as an optimization task that aims to maximize the prediction error on a set of target links by adversarially manipulating the weight values of a limited number of links. Based on this formulation, we propose an iterative gradient-based attack framework for link weight prediction, termed IGA-LWP. By employing a self-attention-enhanced graph autoencoder as a surrogate predictor, IGA-LWP leverages backpropagated gradients to iteratively identify and perturb a small subset of links. Extensive experiments on four real-world weighted networks demonstrate that IGA-LWP significantly degrades prediction accuracy on target links compared with baseline methods. Moreover, the adversarial networks generated by IGA-LWP exhibit strong transferability across several representative link weight prediction models. These findings expose a fundamental vulnerability in weighted network inference and highlight the need for developing robust link weight prediction methods."}
{"id": "2601.05177", "categories": ["cond-mat.dis-nn", "cond-mat.quant-gas", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05177", "abs": "https://arxiv.org/abs/2601.05177", "authors": ["Asmi Haldar", "Thibault Scoquart", "Fabien Alet", "Nicolas Laflorencie"], "title": "Beyond the imbalance: site-resolved dynamics probing resonances in many-body localization", "comment": "(13 + 9) pages and (8 + 2) figures", "summary": "We explore the limitations of using imbalance dynamics as a diagnostic tool for many-body localization (MBL) and show that spatial averaging can mask important microscopic features. Focusing on the strongly disordered regime of the random-field XXZ chain, we use state-of-the-art numerical techniques (Krylov time evolution and full diagonalization) to demonstrate that site-resolved spin autocorrelators reveal a rich and complex dynamical behavior that is obscured by the imbalance observable. By analyzing the time evolution and infinite-time limits of these local probes, we reveal resonant structures and rare local instabilities within the MBL phase. These numerical findings are supported by an analytical, few-site toy model that captures the emergence of a multiple-peak structure in local magnetization histograms, which is a hallmark of local resonances. These few-body local effects provide a more detailed understanding of ergodicity-breaking dynamics, and also allow us to explain the finite-size effects of long-time imbalance, and its sensitivity to the initial conditions in quench protocols. Overall, our experimentally testable predictions highlight the necessity of a refined, site-resolved approach to fully understand the complexities of MBL and its connection to rare-region effects."}
{"id": "2601.04369", "categories": ["physics.soc-ph", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.04369", "abs": "https://arxiv.org/abs/2601.04369", "authors": ["Owen Terry"], "title": "Generalization to Political Beliefs from Fine-Tuning on Sports Team Preferences", "comment": null, "summary": "Fine-tuned LLMs often exhibit unexpected behavior as a result of generalizing beyond the data they're shown. We present results in which an LLM fine-tuned to prefer either coastal sports teams or Southern sports teams adopt political beliefs that diverge significantly from those of the base model. While we hypothesized that the coastal model would become more liberal and the southern model would become more conservative, we find that their responses are usually similar to each other, without a clear-cut liberal or conservative bias. In addition to asking the models for numerical ratings of agreement with relevant political statements, we ask them to elaborate on their more radical answers, finding varying degrees of willingness to justify themselves. Further work is needed to understand the mechanisms by which fine-tuning on simple, narrow datasets leads to seemingly unrelated changes in model behavior."}
{"id": "2601.04913", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.04913", "abs": "https://arxiv.org/abs/2601.04913", "authors": ["Jan Martin Wenkel", "Michael Stanley Smith", "Nadja Klein"], "title": "Bayesian Additive Regression Tree Copula Processes for Scalable Distributional Prediction", "comment": null, "summary": "We show how to construct the implied copula process of response values from a Bayesian additive regression tree (BART) model with prior on the leaf node variances. This copula process, defined on the covariate space, can be paired with any marginal distribution for the dependent variable to construct a flexible distributional BART model. Bayesian inference is performed via Markov chain Monte Carlo on an augmented posterior, where we show that key sampling steps can be realized as those of Chipman et al. (2010), preserving scalability and computational efficiency even though the copula process is high dimensional. The posterior predictive distribution from the copula process model is derived in closed form as the push-forward of the posterior predictive distribution of the underlying BART model with an optimal transport map. Under suitable conditions, we establish posterior consistency for the regression function and posterior means and prove convergence in distribution of the predictive process and conditional expectation. Simulation studies demonstrate improved accuracy of distributional predictions compared to the original BART model and leading benchmarks. Applications to five real datasets with 506 to 515,345 observations and 8 to 90 covariates further highlight the efficacy and scalability of our proposed BART copula process model."}
{"id": "2601.04957", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04957", "abs": "https://arxiv.org/abs/2601.04957", "authors": ["Xinyi Tao", "Panfeng Huang", "Fan Zhang"], "title": "Safe Reinforcement Learning Beyond Baseline Control: A Hierarchical Framework for Space Triangle Tethered Formation System", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Triangular tethered formation system (TTFS) provide a promising platform for deep space exploration and distributed sensing due to its intrinsic spatial-orientation stability and capability of adjusting distances among node satellites through deployment and retrieval of tethers. However, due to the coupled tether-satellite dynamics and disturbance sensitivity of TTFS, traditional control methods struggle to achieve a balanced trade-off among configuration accuracy requirements, tension constraints, and energy efficiency consumption throughout the deployment process.In this paper, a novel model-reference reinforcement learning control framework is proposed for TTFS. By integrating baseline model-based control with a Soft Actor-Critic (SAC) compensator, the proposed method simultaneously achieves high-precision tracking, fuel efficiency, and compliance with tension limits. A hierarchical training scheme is developed to address the convergence difficulties arising from strongly coupled states in centralized training, while tailored reward functions, reset conditions, and normalization criteria are designed to accelerate training convergence. Closed-loop stability of the overall control law is rigorously proven using Lyapunov methods. Simulation results demonstrate that the proposed controller reduces steady-state tracking errors by over 96% for tethers and 99% for node satellites, while cutting fuel consumption by two orders of magnitude compared with the baseline method. These results validate the effectiveness and stability of the proposed approach for TTFS deployment control."}
{"id": "2601.04957", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.04957", "abs": "https://arxiv.org/abs/2601.04957", "authors": ["Xinyi Tao", "Panfeng Huang", "Fan Zhang"], "title": "Safe Reinforcement Learning Beyond Baseline Control: A Hierarchical Framework for Space Triangle Tethered Formation System", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Triangular tethered formation system (TTFS) provide a promising platform for deep space exploration and distributed sensing due to its intrinsic spatial-orientation stability and capability of adjusting distances among node satellites through deployment and retrieval of tethers. However, due to the coupled tether-satellite dynamics and disturbance sensitivity of TTFS, traditional control methods struggle to achieve a balanced trade-off among configuration accuracy requirements, tension constraints, and energy efficiency consumption throughout the deployment process.In this paper, a novel model-reference reinforcement learning control framework is proposed for TTFS. By integrating baseline model-based control with a Soft Actor-Critic (SAC) compensator, the proposed method simultaneously achieves high-precision tracking, fuel efficiency, and compliance with tension limits. A hierarchical training scheme is developed to address the convergence difficulties arising from strongly coupled states in centralized training, while tailored reward functions, reset conditions, and normalization criteria are designed to accelerate training convergence. Closed-loop stability of the overall control law is rigorously proven using Lyapunov methods. Simulation results demonstrate that the proposed controller reduces steady-state tracking errors by over 96% for tethers and 99% for node satellites, while cutting fuel consumption by two orders of magnitude compared with the baseline method. These results validate the effectiveness and stability of the proposed approach for TTFS deployment control."}
{"id": "2601.04924", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.04924", "abs": "https://arxiv.org/abs/2601.04924", "authors": ["Rotem Degany", "Michael Assaf", "Baruch Meerson"], "title": "Short-time statistics of extinction and blowup in reaction kinetics", "comment": "9 pages, 5 figures", "summary": "We study the statistics of extinction and blowup times in well-mixed systems of stochastically reacting particles. We focus on the short-time tail, $T \\to 0$, of the extinction- or blowup-time distribution $\\mathcal{P}_m(T)$, where $m$ is the number of particles at $t=0$. This tail often exhibits an essential singularity at $T=0$, and we show that the singularity is captured by a time-dependent WKB (Wentzel-Kramers-Brillouin) approximation applied directly to the master equation. This approximation, however, leaves undetermined a large pre-exponential factor. Here we show how to calculate this factor by applying a leading- and a subleading-order WKB approximation to the Laplace-transformed backward master equation. Accurate asymptotic results can be obtained when this WKB solution can be matched to another approximate solution (the ``inner\" solution), valid for not too large $m$. We demonstrate and verify this method on three examples of reactions which are also solvable without approximations."}
{"id": "2601.04402", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04402", "abs": "https://arxiv.org/abs/2601.04402", "authors": ["Emery Doucet", "Zakaria Mzaouali", "Reece Robertson", "Bartłomiej Gardas", "Sebastian Deffner", "Krzysztof Domino"], "title": "Thermodynamic significance of QUBO encoding on quantum annealers", "comment": "17 pages, 8 figures", "summary": "Quadratic unconstrained binary optimization (QUBO) is the standard interface to quantum annealers, yet a single constrained task admits many QUBO encodings whose penalty choices reshape the energy landscape experienced by hardware. We study a Job Shop Scheduling instance using a two-parameter family of encodings controlled by penalty weights $p_{\\rm sum}$ (one-hot/sum constraints) and $p_{\\rm pair}$ (precedence constraints). Sweeping $(p_{\\rm sum},p_{\\rm pair})$, we observe sharp transitions in feasibility and solver success across classical annealing-inspired heuristics and on a D-Wave Advantage processor. Going beyond solution probability, we treat the annealer as an open thermodynamic system and perform cyclic reverse-annealing experiments initialized from thermal samples, measuring the stochastic processor energy change. From the first two moments of this energy change we infer lower bounds on entropy production, work, and exchanged heat via thermodynamic uncertainty relations, and corroborate the observed trends with adiabatic master equation simulations. We find that the same encoding transitions that govern computational hardness also reorganize dissipation: weak penalties generate low-energy infeasible manifolds, while overly strong penalties suppress the effective problem energy scale and increase irreversibility, reducing the thermodynamic efficiency. Our results establish QUBO penalties as thermodynamic control knobs and motivate thermodynamics-aware encoding strategies for noisy intermediate-scale quantum annealers."}
{"id": "2601.05207", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.05207", "abs": "https://arxiv.org/abs/2601.05207", "authors": ["Sebastián Álvarez", "Julio Deride", "Cristopher Hermosilla"], "title": "On the Value Function of Convex Bolza Problems Governed by Stochastic Difference Equations", "comment": null, "summary": "In this paper we study the value function of Bolza problems governed by stochastic difference equations, with particular emphasis on the convex non-anticipative case. Our goal is to provide some insights on the structure of the subdiferential of the value function. In particular, we establish a connection between the evolution of the subgradients of the value function and a stochastic difference equation of Hamiltonian type. This result can be seen as a transposition of the method of characteristics, introduced by Rockafellar and Wolenski in the 2000s, to the stochastic discrete-time setting. Similarly as done in the literature for the deterministic case, the analysis is based on a duality approach. For this reason we study first a dual representation for the value function in terms of the value function of a dual problem, which is a pseudo Bolza problem. The main difference with the deterministic case is that (due to the non-anticipativity) the symmetry between the Bolza problem and its dual is no longer valid. This in turn implies that ensuring the existence of minimizers for the Bolza problem (which is a key point for establishing the method of characteristics) is not as simple as in the deterministic case, and it should be addressed differently. To complete the exposition, we study the existence of minimizers for a particular class of Bolza problems governed by linear stochastic difference equations, the so-called linear-convex optimal control problems."}
{"id": "2601.04811", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.04811", "abs": "https://arxiv.org/abs/2601.04811", "authors": ["Florian Johannesmann", "Asliddin Khudoyberdiev", "Götz S. Uhrig"], "title": "Switching magnetization of quantum antiferromagnets: Schwinger boson mean-field theory compared to exact diagonalization", "comment": "14 pages, 17 figures", "summary": "Antiferromagnets have attracted significant attention because of their considerable potential in engineering high-density and ultrafast memory devices, a crucial and increasingly demanded component of contemporary high-performance information technology. Theoretical and experimental investigations are actively progressing to provide the capability of efficient switching and precise control of the Néel vector, which is crucial for the intended practical applications of antiferromagnets. Recently, a time-dependent Schwinger boson mean-field theory has been successfully developed to study the sublattice magnetization switching in anisotropic quantum antiferromagnets [K. Bolsmann $et \\, al.$, \\textcolor{blue}{\\hyperlink{10.1103/PRXQuantum.4.030332}{PRX Quantum $\\mathbf{4}$, 030332 (2023)}}]. Here we use a complementary exact diagonalization method to study such sublattice magnetization switching, but in small-cluster quantum antiferromagnets, by means of an external magnetic field. Furthermore, this article aims to support the findings of the Schwinger boson approach. We show that the results of both approaches are consistent at short time scales, with only about 12.5 $\\%$ deviations. The consistency of the outcomes obtained through this alternative exact approach demonstrates that the time-dependent Schwinger boson mean-field theory is a versatile framework to capture the essentials of the switching process in quantum antiferromagnets. Thereby, the findings of current article pave the way for further theoretical and computational progress in the study of antiferromagnets for engineering spintronic devices with ultrahigh density and ultrafast speed."}
{"id": "2601.04557", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04557", "abs": "https://arxiv.org/abs/2601.04557", "authors": ["Conor Rowan"], "title": "The explicit constraint force method for optimal experimental design", "comment": null, "summary": "The explicit constraint force method (ECFM) was recently introduced as a novel formulation of the physics-informed solution reconstruction problem, and was subsequently extended to inverse problems. In both solution reconstruction and inverse problems, model parameters are estimated with the help of measurement data. In practice, experimentalists seek to design experiments such that the acquired data leads to the most robust recovery of the missing parameters in a subsequent inverse problem. While there are well-established techniques for designing experiments with standard approaches to the inverse problem, optimal experimental design (OED) has yet to be explored with the ECFM formulation. In this work, we investigate OED with a constraint force objective. First, we review traditional approaches to OED based on the Fisher information matrix, and propose an analogous formulation based on constraint forces. Next, we reflect on the different interpretations of the objective from standard and constraint force-based inverse problems. We then test our method on several example problems. These examples suggest that an experiment which is optimal in the sense of constraint forces tends to position measurements in the stiffest regions of the system. Because the responses -- and thus the measurements -- are small in these regions, this strategy is impractical in the presence of measurement noise and/or finite measurement precision. As such, our provisional conclusion is that ECFM is not a viable approach to OED."}
{"id": "2601.04367", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.04367", "abs": "https://arxiv.org/abs/2601.04367", "authors": ["Heba Zahran", "M. Omair Shafiq"], "title": "Graph Integrated Transformers for Community Detection in Social Networks", "comment": "Paper accepted at IEEE GLOBECOM 2025", "summary": "Community detection is crucial for applications like targeted marketing and recommendation systems. Traditional methods rely on network structure, and embedding-based models integrate semantic information. However, there is a challenge when a model leverages local and global information from complex structures like social networks. Graph Neural Networks (GNNs) and Transformers have shown superior performance in capturing local and global relationships. In this paper, We propose Graph Integrated Transformer for Community Detection (GIT-CD), a hybrid model combining GNNs and Transformer-based attention mechanisms to enhance community detection in social networks. Specifically, the GNN module captures local graph structures, while the Transformer module models long-range dependencies. A self-optimizing clustering module refines community assignments using K-Means, silhouette loss, and KL divergence minimization. Experimental results on benchmark datasets show that GIT-CD outperforms state-of-the-art models, making it a robust approach for detecting meaningful communities in complex social networks."}
{"id": "2601.04434", "categories": ["physics.soc-ph", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2601.04434", "abs": "https://arxiv.org/abs/2601.04434", "authors": ["João Brázia", "István Z. Kiss", "Alexandre P. Francisco", "Andreia Sofia Teixeira"], "title": "Reconstructing MSM Sexual Networks to Guide PrEP Distribution Strategies for HIV Prevention", "comment": "21 Pages, 15 Figures, 1 Table", "summary": "Men who have sex with men (MSM) remain disproportionately affected by HIV, yet optimizing the distribution of pre-exposure prophylaxis (PrEP) in this population remains a major public health challenge. Current PrEP eligibility guidelines and most modelling studies do not incorporate sociodemographic or network-level factors that shape transmission. We present a novel network reconstruction framework that generates MSM sexual contact networks from individual-level behavioral data, incorporating clustering and demographic assortativity by age, race, and sexual activity. Using data from 4667 MSM participants, we reconstructed networks with varying topological properties and simulated HIV transmission over 50 years. Network structure strongly influenced outcomes: assortative by degree networks showed 18% lower equilibrium prevalence (63% vs 80% in assortative by race networks) due to hub isolation within communities. Targeted PrEP strategies based on degree or k-shell centrality achieved similar reductions with 20 to 40% coverage, matching random allocation at 60 to 80% coverage, particularly in assortative by age and race networks where hubs bridge demographic groups. Empirical PrEP distribution was suboptimal, underperforming by up to 30% compared with network-based strategies. Our findings demonstrate that integrating demographic mixing patterns into network reconstruction fundamentally alters optimal intervention design, offering a practical framework for improving HIV prevention in MSM populations where complete contact data are unavailable."}
{"id": "2601.05128", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.05128", "abs": "https://arxiv.org/abs/2601.05128", "authors": ["Alex Ocampo", "Enrico Giudice", "Zachary R. McCaw", "Tim P. Morris"], "title": "Revealing the Truth: Calculating True Values in Causal Inference Simulation Studies via Gaussian Quadrature", "comment": null, "summary": "Simulation studies are used to understand the properties of statistical methods. A key luxury in many simulation studies is knowledge of the true value (i.e. the estimand) being targeted. With this oracle knowledge in-hand, the researcher conducting the simulation study can assess across repeated realizations of the data how well a given method recovers the truth. In causal inference simulation studies, the truth is rarely a simple parameter of the statistical model chosen to generate the data. Instead, the estimand is often an average treatment effect, marginalized over the distribution of confounders and/or mediators. Luckily, these variables are often generated from common distributions such as the normal, uniform, exponential, or gamma. For all these distributions, Gaussian quadratures provide efficient and accurate calculation for integrands with integral kernels that stem from known probability density functions. We demonstrate through four applications how to use Gaussian quadrature to accurately and efficiently compute the true causal estimand. We also compare the pros and cons of Gauss-Hermite quadrature to Monte Carlo integration approaches, which we use as benchmarks. Overall, we demonstrate that the Gaussian quadrature is an accurate tool with negligible computation time, yet is underused for calculating the true causal estimands in simulation studies."}
{"id": "2601.05070", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05070", "abs": "https://arxiv.org/abs/2601.05070", "authors": ["Maitraya Avadhut Desai", "Ognjen Stanojev", "Simon Muntwiler", "Gabriela Hug"], "title": "Effect of Dispatch Decisions on Small-Signal Stability of Converter-Dominated Power Systems", "comment": null, "summary": "Small-signal stability of modern converter-dominated power systems has been the subject of extensive research, particularly from the perspective of device-level control design for grid-forming (GFM) and grid-following (GFL) converters. However, the influence of power flow variables on system stability has received limited attention. Conventional small-signal stability analyses are typically conducted at a specific operating point, emphasizing the selection of control or system design parameters while neglecting the sensitivity of stability characteristics to operating conditions. This paper seeks to bridge this gap by systematically investigating the impact of dispatch decisions on the small-signal stability of converter-based power systems. Our findings are first illustrated on a three-bus system and then validated on the standard IEEE 39-bus test system to demonstrate scalability. Across the test systems, we find that high-voltage capacitive operation of GFL converters limits its active power injection, whereas inductive operation permits higher injections, and it is generally preferable for the GFM converter to supply more active power."}
{"id": "2601.05070", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05070", "abs": "https://arxiv.org/abs/2601.05070", "authors": ["Maitraya Avadhut Desai", "Ognjen Stanojev", "Simon Muntwiler", "Gabriela Hug"], "title": "Effect of Dispatch Decisions on Small-Signal Stability of Converter-Dominated Power Systems", "comment": null, "summary": "Small-signal stability of modern converter-dominated power systems has been the subject of extensive research, particularly from the perspective of device-level control design for grid-forming (GFM) and grid-following (GFL) converters. However, the influence of power flow variables on system stability has received limited attention. Conventional small-signal stability analyses are typically conducted at a specific operating point, emphasizing the selection of control or system design parameters while neglecting the sensitivity of stability characteristics to operating conditions. This paper seeks to bridge this gap by systematically investigating the impact of dispatch decisions on the small-signal stability of converter-based power systems. Our findings are first illustrated on a three-bus system and then validated on the standard IEEE 39-bus test system to demonstrate scalability. Across the test systems, we find that high-voltage capacitive operation of GFL converters limits its active power injection, whereas inductive operation permits higher injections, and it is generally preferable for the GFM converter to supply more active power."}
{"id": "2601.04951", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.04951", "abs": "https://arxiv.org/abs/2601.04951", "authors": ["Indranil Mukherjee", "Seema Chahal", "Anupam Kundu"], "title": "Microscopic and hydrodynamic correlation in 1d hard rod gas", "comment": "28 pages, 5 figures", "summary": "We compute mass density correlations of a one-dimensional gas of hard rods at both microscopic and macroscopic scales. We provide exact analytical calculations of the microscopic correlation. For the correlation at macroscopic scale,, we utilize Ballistic Macroscopic Fluctuation Theory (BMFT) to derive an explicit expression for the correlations of a coarse-grained mass density, which reveals the emergence of long-range correlations on the Euler space-time scale. By performing a systematic coarse-graining of our exact microscopic results, we establish a micro-macro correspondence and demonstrate that the resulting macroscopic correlations agree precisely with the predictions of BMFT. This analytical verification provides a concrete validation of the underlying assumptions of hydrodynamic theory in the context of hard rod gas."}
{"id": "2601.04407", "categories": ["quant-ph", "cond-mat.mes-hall", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.04407", "abs": "https://arxiv.org/abs/2601.04407", "authors": ["Mustafa Bakr", "Robin Wopalenski"], "title": "Exact Multimode Quantization of Superconducting Circuits via Boundary Admittance", "comment": null, "summary": "We show that the Schur complement of the nodal admittance matrix, which reduces a multiport electromagnetic environment to the driving-point admittance $Y_{\\mathrm{in}}(s)$ at the Josephson junction, naturally leads to an eigenvalue-dependent boundary condition determining the dressed mode spectrum. This identification provides a four-step quantization procedure: (i) compute or measure $Y_{\\mathrm{in}}(s)$, (ii) solve the boundary condition $sY_{\\mathrm{in}}(s) + 1/L_J = 0$ for dressed frequencies, (iii) synthesize an equivalent passive network, (iv) quantize with the full cosine nonlinearity retained. Within passive lumped-element circuit theory, we prove that junction participation decays as, we prove that junction participation decays as $O(ω_n^{-1})$ at high frequencies when the junction port has finite shunt capacitance, ensuring ultraviolet convergence of perturbative sums without imposed cutoffs. The standard circuit QED parameters, coupling strength $g$, anharmonicity $α$, and dispersive shift $χ$, emerge as controlled limits with explicit validity conditions."}
{"id": "2601.04832", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.04832", "abs": "https://arxiv.org/abs/2601.04832", "authors": ["Léo Gaspard", "Cyril Martins"], "title": "Affordable Five-Orbital Dynamical Mean-Field Theory for Layered Iridates and Rhodates", "comment": "14 pages, 6 figures", "summary": "Full $d$-manifold DMFT with numerically exact solvers has remained computationally prohibitive for spin-orbit materials due their scaling and severe sign problem, forcing the community to rely on simplified one- and three-band models that omit the $e_g$ states despite their proximity with the $t_{2g}$ orbitals. We present the first full five-orbital Dynamical Mean-Field Theory (DMFT) calculations including spin-orbit coupling for the layered iridates and rhodates \\bio~and \\bro, revealing that the correlation effects shift significantly the $e_g$ states through static mean-field corrections rather than dynamical fluctuations. Motivated by this insight, we introduce hybrid-DMFT (hDMFT), which treats these orbitals and their coupling to the low-energy manifold at the mean-field level while maintaining near quantitative accuracy at a drastically reduced computational cost. These calculation establish hDMFT as a practical and accurate method for full $d$-manifold studies of layered iridates and rhodates, enabling systematic investigations of temperature, doping and pressure dependence that were previously computationally intractable."}
{"id": "2601.04628", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04628", "abs": "https://arxiv.org/abs/2601.04628", "authors": ["S. M. Mallikarjunaiah"], "title": "An HHT-$α$-based finite element framework for wave propagation in constitutively nonlinear elastic materials", "comment": null, "summary": "This paper presents a computational framework for modeling wave propagation in geometrically linear elastic materials characterized by algebraically nonlinear constitutive relations. We derive a specific form of the nonlinear wave equation in which the nonlinearity explicitly appears in the time-derivative terms that govern the evolution of the mechanical fields. The numerical solution is established using a fully discrete formulation that combines the standard finite element method for spatial discretization with the implicit Hilber-Hughes-Taylor (HHT)-$α$ scheme for time integration. To address the nonlinear nature of the discrete system, we employ Newton's method to iteratively solve the linearized equations at each time step. The accuracy and robustness of the proposed framework are rigorously verified through convergence analyses, which demonstrate optimal convergence rates in both space and time. Furthermore, a detailed parametric study is conducted to elucidate the influence of the model's constitutive parameters. The results reveal that the magnitude parameter of the stress-dependent variation in wave speed leads to wavefront steepening and the formation of shock discontinuities. Conversely, the exponent parameter acts as a nonlinearity filter; high values suppress nonlinear effects in small-strain regimes, whereas low values allow significant dispersive behavior. This work provides a validated tool for analyzing shock formation in advanced nonlinear materials."}
{"id": "2601.05065", "categories": ["cs.SI", "cond-mat.stat-mech", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.05065", "abs": "https://arxiv.org/abs/2601.05065", "authors": ["Lucas Böttcher", "Mason A. Porter", "Santo Fortunato"], "title": "Graph energy as a measure of community detectability in networks", "comment": "12 pages, 3 figures, 1 table", "summary": "A key challenge in network science is the detection of communities, which are sets of nodes in a network that are densely connected internally but sparsely connected to the rest of the network. A fundamental result in community detection is the existence of a nontrivial threshold for community detectability on sparse graphs that are generated by the planted partition model (PPM). Below this so-called ``detectability limit'', no community-detection method can perform better than random chance. Spectral methods for community detection fail before this detectability limit because the eigenvalues corresponding to the eigenvectors that are relevant for community detection can be absorbed by the bulk of the spectrum. One can bypass the detectability problem by using special matrices, like the non-backtracking matrix, but this requires one to consider higher-dimensional matrices. In this paper, we show that the difference in graph energy between a PPM and an Erdős--Rényi (ER) network has a distinct transition at the detectability threshold even for the adjacency matrices of the underlying networks. The graph energy is based on the full spectrum of an adjacency matrix, so our result suggests that standard graph matrices still allow one to separate the parameter regions with detectable and undetectable communities."}
{"id": "2601.04579", "categories": ["physics.soc-ph", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.04579", "abs": "https://arxiv.org/abs/2601.04579", "authors": ["Gavin Cook"], "title": "Towards a Sociology of Sociology: Inequality, Elitism, and Prestige in the Sociological Enterprise From 1970 to the Present", "comment": null, "summary": "There is a science of science and an informal economics of economics, but there is not a cohesive sociology of sociology. We turn the central findings and theoretical lenses of the sociological tradition and the sociological study of stratification inward on sociology itself to investigate how sociology has changed since the 1970s. We link two bibliometric databases to trace diachronic relationships between PhD training and publication outcomes, both of which are understudied in the science of science and sociology of science. All of sociology's top 3 journals remained biased against alum of less prestigious PhD programs, and while most forms of bias in elite sociological publishing have ameliorated over time, the house bias of the American Journal of Sociology in favor PhD alumnae of UChicago has intensified."}
{"id": "2601.05087", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05087", "abs": "https://arxiv.org/abs/2601.05087", "authors": ["Francesco Bianchin", "Robert Lefringhausen", "Sandra Hirche"], "title": "Online Bayesian Learning of Agent Behavior in Differential Games", "comment": null, "summary": "This work introduces an online Bayesian game-theoretic method for behavior identification in multi-agent dynamical systems. By casting Hamilton-Jacobi-Bellman optimality conditions as linear-in-parameter residuals, the method enables fast sequential Bayesian updates, uncertainty-aware inference, and robust prediction from limited, noisy data-without history stacks. The approach accommodates nonlinear dynamics and nonquadratic value functions through basis expansions, providing flexible models. Experiments, including linear-quadratic and nonlinear shared-control scenarios, demonstrate accurate prediction with quantified uncertainty, highlighting the method's relevance for adaptive interaction and real-time decision making."}
{"id": "2601.05087", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05087", "abs": "https://arxiv.org/abs/2601.05087", "authors": ["Francesco Bianchin", "Robert Lefringhausen", "Sandra Hirche"], "title": "Online Bayesian Learning of Agent Behavior in Differential Games", "comment": null, "summary": "This work introduces an online Bayesian game-theoretic method for behavior identification in multi-agent dynamical systems. By casting Hamilton-Jacobi-Bellman optimality conditions as linear-in-parameter residuals, the method enables fast sequential Bayesian updates, uncertainty-aware inference, and robust prediction from limited, noisy data-without history stacks. The approach accommodates nonlinear dynamics and nonquadratic value functions through basis expansions, providing flexible models. Experiments, including linear-quadratic and nonlinear shared-control scenarios, demonstrate accurate prediction with quantified uncertainty, highlighting the method's relevance for adaptive interaction and real-time decision making."}
{"id": "2601.05079", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.05079", "abs": "https://arxiv.org/abs/2601.05079", "authors": ["Botond C. Nagy", "Marton Kormos", "Gabor Takacs"], "title": "Full counting statistics in the sine--Gordon model", "comment": null, "summary": "Full counting statistics (FCS) is a dynamical generalisation of the free energy, encapsulating detailed information about the distribution and large-scale correlation functions of conserved charges and their associated currents. In this work, we present a comprehensive numerical study of the FCS and the cumulants of the three lowest charges across the full parameter space of the sine--Gordon field theory. To this end, we extend the thermodynamic Bethe Ansatz (TBA) formulation of the FCS to the sine--Gordon model, emphasise the methodological subtleties for a reliable numerical implementation, and compare numerical results with analytical predictions in certain limits."}
{"id": "2601.04422", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04422", "abs": "https://arxiv.org/abs/2601.04422", "authors": ["Aaron C. Hoyt", "Jonathan S. Bersson", "Sean Garner", "Chenxu Liu", "Ang Li"], "title": "Implementation of Tensor Network Simulation TN-Sim under NWQ-Sim", "comment": null, "summary": "Large-scale tensor network simulations are crucial for developing robust complexity-theoretic bounds on classical quantum simulation, enabling circuit cutting approaches, and optimizing circuit compilation, all of which aid efficient quantum computation on limited quantum resources. Modern exascale high-performance computing platforms offer significant potential for advancing tensor network quantum circuit simulation capabilities. We implement TN-Sim, a tensor network simulator backend within the NWQ-Sim software package that utilizes the Tensor Algebra for Many-body Methods (TAMM) framework to support both distributed HPC-scale computations and local simulations with ITensor. To optimize the scale up in computation across multiple nodes we implement a task based parallelization scheme to demonstrate parallelized gate contraction for wide quantum circuits with many gates per layer. Through the integration of the TAMM framework with Matrix Product State (MPS) tensor network approaches, we deliver a simulation environment that can scale from local systems to HPC clusters. We demonstrate an MPS tensor network simulator running on the state-of-the-art Perlmutter (NVIDIA) supercomputer and discuss the potential portability of this software to HPC clusters such as Frontier (AMD) and Aurora (Intel). We also discuss future improvements including support for different tensor network topologies and enhanced computational efficiency."}
{"id": "2601.04908", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.04908", "abs": "https://arxiv.org/abs/2601.04908", "authors": ["Vincent C. Morano", "Zeno Maesen", "Stanislav Nikitin", "Jonathan S. White", "Takashi Honda", "Tsuyoshi Kimura", "Michel Kenzelmann", "Daniel Pajerowski", "Oksana Zaharko"], "title": "Coupled sawtooth chain exchange network in olivine Mn$_2$GeO$_4$", "comment": "21 pages, 12 figures", "summary": "Sawtooth chain magnets have been a subject of historical interest in the field of frustrated magnetism, with classical olivine family $M_2TX_4$, ($M$ - 3d, $T$ - 4p, $X$ - chalcogen elements) typically realizing simple $\\mathbf{k} = (000)$ states. The magnetism of the Mn$_2$GeO$_4$ olivine is surprisingly complex, proceeding from commensurate states to a multiferroic commensurate + incommensurate phase. Here we report inelastic neutron scattering results from a Mn$_2$GeO$_4$ single crystal and develop an effective Hamiltonian including long-distance bilinear and dipolar interactions. The magnetic interactions are predominantly antiferromagnetic and span a three-dimensional exchange network consisting of coupled sawtooth chains. Based on the determined strength of the couplings, the dominant sawtooth chains appear at third- and fourth- rather than next-nearest-neighbor. However the next-nearest-neighbor interaction is, along with a modest Dzyaloshinskii-Moriya interaction, important for modeling the observed incommensurability. We use the best-fit Hamiltonian as the basis for Langevin dynamics simulations and Luttinger-Tisza calculations of the high-temperature commensurate transition."}
{"id": "2601.04708", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04708", "abs": "https://arxiv.org/abs/2601.04708", "authors": ["Congpei An", "Alvise Sommariva", "Marco Vianello"], "title": "On the role of weak Marcinkiewicz-Zygmund constants in polynomial approximation by orthogonal bases", "comment": null, "summary": "We compute numerically the $L^2$ Marcinkiewicz-Zygmund constants of cubature rules, with a special attention to their role in polynomial approximation by orthogonal bases. We test some relevant rules on domains such as the interval, the square, the disk, the triangle, the cube and the sphere. The approximation power of the corresponding least squares (LS) projection is compared with standard hyperinterpolation and its recently proposed ``exactness-relaxed'' version. The Matlab codes used for these tests are available in open-source form."}
{"id": "2601.05093", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.05093", "abs": "https://arxiv.org/abs/2601.05093", "authors": ["Yuan Zhang", "Laia Castro", "Frank Esser", "Alexandre Bovet"], "title": "Why Are Some Countries More Politically Fragmented Online Than Others?", "comment": null, "summary": "Online political divisions, such as fragmentation or polarization, are a growing global concern that can foster radicalization and hinder democratic cooperation; however, not all divisions are detrimental, some reflect pluralism and healthy diversity of opinion in a democracy. While prior research has predominantly focused on polarization in the United States, there remains a limited body of research on political divides in multiparty systems, and no universal method for comparing fragmentation across countries. Moreover, cross-country comparison is rare. This study first develops a novel measure of structural political fragmentation built on multi-scale community detection and the effective branching factor. Using a dataset of 18,325 political influencers from Brazil, Spain, and the United States, we assess online fragmentation in their Twitter/X co-following networks. We compare the fragmentation of the three countries, as well as the ideological groups within each. We further investigate factors associated with the level of fragmentation in each country. We find that political fragmentation differs across countries and is asymmetric between ideological groups. Brazil is the most fragmented, with higher fragmentation among the left-wing group, while Spain and the United States exhibit similar overall levels, with the left more fragmented in Spain and the right more fragmented in the United States. Additionally, we find that social identity plays a central role in political fragmentation. A strong alignment between ideological and social identities, with minimal overlap between ideologies, tends to promote greater integration and reduce fragmentation. Our findings provide explanations for cross-national and ideological differences in political fragmentation."}
{"id": "2601.04917", "categories": ["physics.soc-ph", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.04917", "abs": "https://arxiv.org/abs/2601.04917", "authors": ["H. R. Paz"], "title": "Homeostasis Under Technological Transition: How High-Friction Universities Adapt Through Early Filtering Rather Than Reconfiguration", "comment": "22 pages, 6 figures, 1 table", "summary": "Universities are widely expected to respond to technological transitions through rapid reconfiguration of programme demand and curricular supply. Using four decades of longitudinal administrative cohorts (1980-2019) from a large public university, we examine whether technological change is translated into observable shifts in programme hierarchy, or instead absorbed by institutional mechanisms that preserve structural stability. We show that programme rankings by entrant volume remain remarkably stable over time, while the translation of technological transitions into enrolment composition occurs with substantial delay. Short-run adjustment appears primarily in early persistence dynamics: attrition reacts sooner than choice, and \"growth\" in entrants can coexist with declining early survival - producing false winners in which expansion is decoupled from persistence. Macroeconomic volatility amplifies attrition and compresses between-programme differences, masking technological signals that would otherwise be interpreted as preference shifts. To explain why stability dominates responsiveness, we situate these patterns within nationally regulated constraints governing engineering education - minimum total hours and mandated practice intensity - which materially limit the speed of curricular adaptation (Ministerio de Educacion, 2021; Ley de Educacion Superior, 1995). National system metrics further support the plausibility of a high-friction equilibrium in which large inflows coexist with standardised outputs (Secretaria de Politicas Universitarias [SPU], 2022). These findings suggest that apparent rigidity is not an anomaly but the predictable outcome of a system optimised for stability over responsiveness."}
{"id": "2601.05056", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05056", "abs": "https://arxiv.org/abs/2601.05056", "authors": ["Silan Zhang", "Yujie Tang"], "title": "ZIVR: An Incremental Variance Reduction Technique For Zeroth-Order Composite Problems", "comment": null, "summary": "This paper investigates zeroth-order (ZO) finite-sum composite optimization. Recently, variance reduction techniques have been applied to ZO methods to mitigate the non-vanishing variance of 2-point estimators in constrained/composite optimization, yielding improved convergence rates. However, existing ZO variance reduction methods typically involve batch sampling of size at least $Θ(n)$ or $Θ(d)$, which can be computationally prohibitive for large-scale problems. In this work, we propose a general variance reduction framework, Zeroth-Order Incremental Variance Reduction (ZIVR), which supports flexible implementations$\\unicode{x2014}$including a pure 2-point zeroth-order algorithm that eliminates the need for large batch sampling. Furthermore, we establish comprehensive convergence guarantees for ZIVR across strongly-convex, convex, and non-convex settings that match their first-order counterparts. Numerical experiments validate the effectiveness of our proposed algorithm."}
{"id": "2601.05056", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.05056", "abs": "https://arxiv.org/abs/2601.05056", "authors": ["Silan Zhang", "Yujie Tang"], "title": "ZIVR: An Incremental Variance Reduction Technique For Zeroth-Order Composite Problems", "comment": null, "summary": "This paper investigates zeroth-order (ZO) finite-sum composite optimization. Recently, variance reduction techniques have been applied to ZO methods to mitigate the non-vanishing variance of 2-point estimators in constrained/composite optimization, yielding improved convergence rates. However, existing ZO variance reduction methods typically involve batch sampling of size at least $Θ(n)$ or $Θ(d)$, which can be computationally prohibitive for large-scale problems. In this work, we propose a general variance reduction framework, Zeroth-Order Incremental Variance Reduction (ZIVR), which supports flexible implementations$\\unicode{x2014}$including a pure 2-point zeroth-order algorithm that eliminates the need for large batch sampling. Furthermore, we establish comprehensive convergence guarantees for ZIVR across strongly-convex, convex, and non-convex settings that match their first-order counterparts. Numerical experiments validate the effectiveness of our proposed algorithm."}
{"id": "2601.05198", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2601.05198", "abs": "https://arxiv.org/abs/2601.05198", "authors": ["Rémi Goerlich", "Antoine Tartar", "Yael Roichman", "Igor M Sokolov"], "title": "Fluctuation-response relation for a nonequilibrium system with resolved Markovian embedding", "comment": null, "summary": "Fluctuation-response relations must be modified to describe nonequilibrium systems with non-Markovian dynamics. Here, we experimentally demonstrate that such relation is quantitatively recovered when the appropriate Markovian embedding of the dynamics is explicitly resolved. Using a colloidal particle optically trapped in a harmonic potential and driven out of equilibrium by a controlled colored noise, we study the response to a perturbation of the stiffness of the confining potential. While the reduced dynamics violates equilibrium fluctuation-response relations, we show that the dynamical response to the stiffness perturbation is fully determined by steady-state correlations involving the exact conjugate observable in the Markovian embedding."}
{"id": "2601.04439", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04439", "abs": "https://arxiv.org/abs/2601.04439", "authors": ["Karla Baumann", "Youcef Modheb", "Roman Randrianarisoa", "Roland Katz", "Aoife Boyle", "Frédéric Holweck"], "title": "Solving nonlinear differential equations on noisy $156$-qubit quantum computers", "comment": "12 pages, 8 figues, 3 tables", "summary": "In this paper, we report on the resolution of nonlinear differential equations using IBM's quantum platform. More specifically, we demonstrate that the hybrid classical-quantum algorithm H-DES successfully solves a one-dimensional material deformation problem and the inviscid Burgers' equation on IBM's 156-qubit quantum computers. These results constitute a step toward performing physically relevant simulations on present-day Noisy Intermediate-Scale Quantum (NISQ) devices."}
{"id": "2601.05001", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.05001", "abs": "https://arxiv.org/abs/2601.05001", "authors": ["Zeyu Kao", "Yimeng Gu", "Yiqing Gu", "Hao Zhang", "Shiyi Zheng", "Naoki Murai", "Seiko Ohira-Kawamura", "Jun Zhao"], "title": "Kitaev interactions in the van der Waals antiferromagnet VBr3", "comment": "30 pages, 14 figures", "summary": "Van der Waals materials hosting Kitaev interactions are promising platforms for exploring exotic quantum phenomena. Here, we report inelastic neutron scattering investigations of the van der Waals antiferromagnet VBr3, which forms a honeycomb lattice structure at room temperature and exhibits zigzag-type magnetic order below 26.5 K. Our observations reveal distinctive low-energy spin excitations arising from gamma, gamma', and M' points, each featuring a spin gap of around 2.5 meV. The overall spin excitation spectra can be effectively described by a spin Hamiltonian incorporating substantial nearest-neighbor Kitaev and biquadratic interactions, along with Heisenberg interactions. Our findings not only establish VBr3 as a new Kitaev magnet but also suggest that ligand engineering may provide a promising strategy to modulate Kitaev interactions, offering new opportunities for designing Kitaev materials with tailored quantum properties."}
{"id": "2601.04839", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04839", "abs": "https://arxiv.org/abs/2601.04839", "authors": ["Abdolreza Amiri", "Gabriel R. Barrenechea", "Tristan Pryer"], "title": "A finite element method preserving the eigenvalue range of symmetric tensor fields", "comment": "29 pages, 8 figures", "summary": "This paper presents a finite element method that preserves (at the degrees of freedom) the eigenvalue range of the solution of tensor-valued time-dependent convection--diffusion equations. Starting from a high-order spatial baseline discretisation (in this case, the CIP stabilised finite element method), our approach formulates the fully discrete problem as a variational inequality posed on a closed convex set of tensor-valued functions that respect the same eigenvalue bounds at their degrees of freedom. The numerical realisation of the scheme relies on the definition of a projection that, at each node, performs the diagonalisation of the tensor and then truncates the eigenvalues to lie within the prescribed bounds. The temporal discretisation is carried out using the implicit Euler method, and unconditional stability and optimal-order error estimates are proven for this choice. Numerical experiments confirm the theoretical findings and illustrate the method's ability to maintain eigenvalue constraints while accurately approximating solutions in the convection-dominated regime."}
{"id": "2601.05169", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.05169", "abs": "https://arxiv.org/abs/2601.05169", "authors": ["Jaume Llabrés", "Raúl Toral", "Maxi San Miguel", "Federico Vázquez"], "title": "Reducibility of higher-order to pairwise interactions: Social impact models on hypergraphs", "comment": null, "summary": "We show that a general class of social impact models with higher-order interactions on hypergraphs can be exactly reduced to an equivalent model with pairwise interactions on a weighted projected network. This reduction is made by a mapping that preserves the microscopic probabilities of changing the state of the nodes. As a particular case, we introduce hypergraph-voter models, for which we compute the weights of the projected network both analytically and numerically across several hypergraph ensembles, and we characterize their ordering dynamics through simulations of both higher-order and reduced dynamics. For a linear social impact function (hypergraph-linear voter model) the weights of the projected network are static, allowing us to develop a pair approximation that describes with accuracy the time evolution of macroscopic observables, which turn out to be independent of those weights. The macroscopic dynamics is thus equivalent to that of the standard voter model on the unweighted projected network. For a power-law social impact function (hypergraph-nonlinear voter model) the weights of the projected network depend on the instantaneous system configuration. Nevertheless, the nonlinear voter model on the unweighted projected network still reproduces the main macroscopic trends for well connected hypergraphs."}
{"id": "2601.05238", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.05238", "abs": "https://arxiv.org/abs/2601.05238", "authors": ["Sibaram Ruidas", "Sthitadhi Roy", "Subhro Bhattacharjee", "Roderich Moessner"], "title": "How many-body chaos emerges in the presence of quasiparticles", "comment": "18 pages, 15 figures", "summary": "Many-body chaos is a default property of many-body systems; at the same time, near-integrable behaviour due to weakly interacting quasiparticles is ubiquitous throughout condensed matter at low temperature. There must therefore be a, possibly generic, crossover between these very different regimes. Here, we develop a theory encapsulating the notion of a cascade of lightcones seeded by sequences of scattering of weakly interacting harmonic modes as witnessed by a suitably defined chaos diagnostic (classical decorrelator) that measures the spatiotemporal profile of many-body chaos. Our numerics deals with the concrete case of a classical Heisenberg chain, for either sign of the interaction, at low temperatures where the short-time dynamics are well captured in terms of non-interacting spin waves. To model low-temperature dynamics, we use ensembles of initial states with randomly embedded point defects in an otherwise ordered background, which provides a controlled setting for studying the scattering events. The decorrelator exhibits a short-time integrable regime followed by an intermediate `scarred' regime of the cascade of lightcones in progress; these then overlap, leading to an avalanche of scattering events which finally yields the standard long-time signature of many-body chaos."}
{"id": "2601.04440", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04440", "abs": "https://arxiv.org/abs/2601.04440", "authors": ["Sayan Gangopadhyay", "Sasan V. Grayli", "Sathursan Kokilathasan", "Michael E. Reimer"], "title": "A Broadband Nanowire Quantum Dot Cavity Design for the Efficient Extraction of Entangled Photons", "comment": null, "summary": "A bright source of on-demand entangled photons is needed for quantum networks. A single quantum dot in a site-selected nanowire waveguide is a promising candidate for realizing such sources. However, such sources are associated with poor single-photon indistinguishability, limiting their applicability in quantum networks. A common approach for enhancing the single-photon indistinguishability in quantum dot-based entangled photon sources is to implement a broadband optical cavity. Achieving a high-Purcell cavity while retaining the advantages of the nanowire, such as directional emission, a broad operational bandwidth, and high light extraction efficiency, has been a significant challenge. Here, we propose a nanowire cavity based on quasi-bound states in the continuum formed by the strong coupling of two resonant optical modes. We numerically predict this design to support a cavity mode with 4 nm bandwidth and a Purcell enhancement of $\\sim$17. This cavity mode enables a directional far-field emission profile (88% overlap with a Gaussian) with a light extraction efficiency of $\\sim$74%. Our solution opens up a route for generating entangled photon pairs with enhanced extraction efficiency and single-photon indistinguishability for the practical realization of quantum networks."}
{"id": "2601.05126", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.05126", "abs": "https://arxiv.org/abs/2601.05126", "authors": ["E. -O. Eljaouhari", "B. V. Schwarze", "K. Kliemt", "C. Krellner", "F. Husstedt", "J. Wosnitza", "S. Zherlitsyn", "G. Zwicknagl", "J. Sourd"], "title": "Acoustic signatures of the field-induced electronic-topological transitions in YbNi$_4$P$_2$", "comment": null, "summary": "We investigated the magnetoelastic properties of an YbNi$_4$P$_2$ single crystal at low temperatures under magnetic fields directed along the crystallographic [001] axis. We report a series of strong anomalies in the sound velocity, which is consistent with the cascade of electronic-topological transitions reported previously for this compound. In particular, we identify the vanishing of a small orbit on the Fermi surface, associated with a quantum-oscillation frequency of 34 T. Furthermore, the different transitions are better resolved with acoustic modes of particular symmetry. Using a microscopic model adapted to the strongly correlated electronic structure of YbNi$_4$P$_2$, we describe our results by inspecting realistic electron-phonon couplings in reciprocal space for each acoustic mode. This shows how the $k$ selectivity of ultrasound experiments allows to investigate Fermi-surface reconstructions in strongly correlated electronic systems."}
{"id": "2601.04866", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04866", "abs": "https://arxiv.org/abs/2601.04866", "authors": ["Paola F. Antonietti", "Lourenço Beirão da Veiga", "Michele Botti", "André Harnist", "Giuseppe Vacca", "Marco Verani"], "title": "Virtual Element methods for non-Newtonian shear-thickening fluid flow problems", "comment": null, "summary": "In this work, we present a comprehensive theoretical analysis for Virtual Element discretizations of incompressible non-Newtonian flows governed by the Carreau-Yasuda constitutive law, in the shear-thickening regime (r > 2) including both degenerate (delta = 0) and non-degenerate (delta > 0) cases. The proposed Virtual Element method features two distinguishing advantages: the construction of an exactly divergence-free discrete velocity field and compatibility with general polygonal meshes. The analysis presented in this work extends a previous work, where only shear-thinning behavior (1 < r < 2) was considered. Indeed, the theoretical analysis of the shear-thickening setting requires several novel analytical tools, including: an inf-sup stability analysis of the discrete velocity-pressure coupling in non-Hilbertian norms, a stabilization term specifically designed to address the nonlinear structure as the exponent r > 2; and the introduction of a suitable discrete norm tailored to the underlying nonlinear constitutive relation. Numerical results demonstrate the practical performance of the proposed formulation."}
{"id": "2601.05065", "categories": ["cs.SI", "cond-mat.stat-mech", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.05065", "abs": "https://arxiv.org/abs/2601.05065", "authors": ["Lucas Böttcher", "Mason A. Porter", "Santo Fortunato"], "title": "Graph energy as a measure of community detectability in networks", "comment": "12 pages, 3 figures, 1 table", "summary": "A key challenge in network science is the detection of communities, which are sets of nodes in a network that are densely connected internally but sparsely connected to the rest of the network. A fundamental result in community detection is the existence of a nontrivial threshold for community detectability on sparse graphs that are generated by the planted partition model (PPM). Below this so-called ``detectability limit'', no community-detection method can perform better than random chance. Spectral methods for community detection fail before this detectability limit because the eigenvalues corresponding to the eigenvectors that are relevant for community detection can be absorbed by the bulk of the spectrum. One can bypass the detectability problem by using special matrices, like the non-backtracking matrix, but this requires one to consider higher-dimensional matrices. In this paper, we show that the difference in graph energy between a PPM and an Erdős--Rényi (ER) network has a distinct transition at the detectability threshold even for the adjacency matrices of the underlying networks. The graph energy is based on the full spectrum of an adjacency matrix, so our result suggests that standard graph matrices still allow one to separate the parameter regions with detectable and undetectable communities."}
{"id": "2601.03787", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.03787", "abs": "https://arxiv.org/abs/2601.03787", "authors": ["Sara Najem", "Amer E. Mouawad"], "title": "Finding Graph Isomorphisms in Heated Spaces in Almost No Time", "comment": null, "summary": "Determining whether two graphs are structurally identical is a fundamental problem with applications spanning mathematics, computer science, chemistry, and network science. Despite decades of study, graph isomorphism remains a challenging algorithmic task, particularly for highly symmetric structures. Here we introduce a new algorithmic approach based on ideas from spectral graph theory and geometry that constructs candidate correspondences between vertices using their curvatures. Any correspondence produced by the algorithm is explicitly verified, ensuring that non-isomorphic graphs are never incorrectly identified as isomorphic. Although the method does not yet guarantee success on all isomorphic inputs, we find that it correctly resolves every instance tested in deterministic polynomial time, including a broad collection of graphs known to be difficult for classical spectral techniques. These results demonstrate that enriched spectral methods can be far more powerful than previously understood, and suggest a promising direction for the practical resolution of the complexity of the graph isomorphism problem."}
{"id": "2601.04444", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04444", "abs": "https://arxiv.org/abs/2601.04444", "authors": ["Sabee Grewal", "Meghal Gupta", "William He", "Aniruddha Sen", "Mihir Singhal"], "title": "Pauli Measurements Are Near-Optimal for Pure State Tomography", "comment": null, "summary": "We give an algorithm for pure state tomography with near-optimal copy complexity using single-qubit measurements. Specifically, given $\\widetilde{O}(2^n/ε)$ copies of an unknown pure $n$-qubit state $\\lvertψ\\rangle$, the algorithm performs only \\textit{nonadaptive Pauli measurements}, runs in time $\\mathrm{poly}(2^n,1/ε)$, and outputs $\\lvert \\widehatψ \\rangle$ that has fidelity $1-ε$ with $\\lvert ψ\\rangle$ with high probability. This improves upon the previous best copy complexity bound of $\\widetilde{O}(3^n/ε)$."}
{"id": "2601.05140", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.05140", "abs": "https://arxiv.org/abs/2601.05140", "authors": ["Jan Verlage", "Peter Kratzer"], "title": "Enhanced Electron Reflectionat Mott-Insulator Interfaces", "comment": null, "summary": "The Klein paradox describes an incoming electron being scattered at a supercritical barrier to create electron-positron pairs, a phenomenon widely discussed in textbooks. While demonstrating this phenomenon experimentally with the fundamental particles remains challenging, condensed matter analogs are more accessible to experimental realization. For spinless quasi-particles, theoretical works show an enhancement of the pair production rate, and analogs of this effect in condensed matter systems have been studied theoretically. Here, we present another condensed matter system, a heterostructure comprised of two materials with strongly and weakly interacting electrons, that allows for constructing analytical solutions using the hierarchy-of-correlations method. The results show enhanced electron reflection related with the production of doublon-holon pairs, as known from the Klein paradox."}
{"id": "2601.04999", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.04999", "abs": "https://arxiv.org/abs/2601.04999", "authors": ["Alessandro Lanza", "Serena Morigi", "Youwei Wen", "Li Yang"], "title": "Guided Variational Network for Image Decomposition", "comment": null, "summary": "Cartoon-texture image decomposition is a critical preprocessing problem bottlenecked by the numerical intractability of classical variational or optimization models and the tedious manual tuning of global regularization parameters.We propose a Guided Variational Decomposition (GVD) model which introduces spatially adaptive quadratic norms whose pixel-wise weights are learned either through local probabilistic statistics or via a lightweight neural network within a bilevel framework.This leads to a unified, interpretable, and computationally efficient model that bridges classical variational ideas with modern adaptive and data-driven methodologies. Numerical experiments on this framework, which inherently includes automatic parameter selection, delivers GVD as a robust, self-tuning, and superior solution for reliable image decomposition."}
{"id": "2601.04305", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.04305", "abs": "https://arxiv.org/abs/2601.04305", "authors": ["Umberto Borla", "Achilleas Lazarides", "Christian Groß", "Jad C. Halimeh"], "title": "Microscopic Dynamics of False Vacuum Decay in the $2+1$D Quantum Ising Model", "comment": "$9+3$ pages, $5+3$ figures", "summary": "False vacuum decay, which is understood to happen through bubble nucleation, is a prominent phenomenon relevant to elementary particle physics and early-universe cosmology. Understanding its microscopic dynamics in higher spatial dimensions is currently a major challenge and research thrust. Recent advances in numerical techniques allow for the extraction of related signatures in tractable systems in two spatial dimensions over intermediate timescales. Here, we focus on the $2+1$D quantum Ising model, where a longitudinal field is used to energetically separate the two $\\mathbb{Z}_2$ symmetry-broken ferromagnetic ground states, turning them into a ``true'' and ``false'' vacuum. Using tree tensor networks, we simulate the microscopic dynamics of a spin-down domain in a spin-up background after a homogeneous quench, with parameters chosen so that the domain corresponds to a bubble of the true vacuum in a false-vacuum background. Our study identifies how the ultimate fate of the bubble -- indefinite expansion or collapse -- depends on its geometrical features and on the microscopic parameters of the Ising Hamiltonian. We further provide a realistic quantum-simulation scheme, aimed at probing bubble dynamics on atomic Rydberg arrays."}
{"id": "2601.04467", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04467", "abs": "https://arxiv.org/abs/2601.04467", "authors": ["Kwok Ho Wan", "H. C. W. Price", "Qing Yao"], "title": "Holographic codes seen through ZX-calculus", "comment": null, "summary": "We re-visit the pentagon holographic quantum error correcting code from a ZX-calculus perspective. By expressing the underlying tensors as ZX-diagrams, we study the stabiliser structure of the code via Pauli webs. In addition, we obtain a diagrammatic understanding of its logical operators, encoding isometries, Rényi entropy and toy models of black holes/wormholes. Then, motivated by the pentagon holographic code's ZX-diagram, we introduce a family of codes constructed from ZX-diagrams on its dual hyperbolic tessellations and study their logical error rates using belief propagation decoders."}
{"id": "2601.05185", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.05185", "abs": "https://arxiv.org/abs/2601.05185", "authors": ["Xu-Ping Yao", "Chao-Kai Li", "Gang v. Chen"], "title": "Surface chiral Abelian topological order on multilayer cluster Mott insulators", "comment": "Main: 7 pages, 3 figures; SM: 13 pages, 3 figures", "summary": "The surface states of a symmetry protected topological state can have many possibilities. Here we propose a chiral Abelian topological order on a distinct surface of a multilayer-stacked cluster Mott insulating system. The first-principle calculation and the slave-rotor mean-field theory are applied to study the surface states of the relevant material system. The angle-resolved photoemission spectroscopic measurement is further suggested to detect the anomalous surface fractionalization of the chiral Abelian topological order on the surface. The connection with real materials is further discussed. We expect our results to inspire the interest in the emergent exotic and correlation physics among the cluster Mott insulating systems and in the interplay between the two different branches of topological phases."}
{"id": "2601.05146", "categories": ["math.NA", "math.AP", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.05146", "abs": "https://arxiv.org/abs/2601.05146", "authors": ["Jan Bouwe van den Berg", "Maxime Breden"], "title": "A simple rigorous integrator for semilinear parabolic PDEs", "comment": null, "summary": "Simulations of the dynamics generated by partial differential equations (PDEs) provide approximate, numerical solutions to initial value problems. Such simulations are ubiquitous in scientific computing, but the correctness of the results is usually not guaranteed. We propose a new method for the rigorous integration of parabolic PDEs, i.e., the derivation of rigorous and explicit error bounds between the numerically obtained approximate solution and the exact one, which is then proven to exist over the entire time interval considered. These guaranteed error bounds are obtained a posteriori, using a fixed point reformulation based on a piece-wise in time constant approximation of the linearization around the numerical solution. Our setup leads to relatively simple-to-understand estimates, which has several advantages. Most critically, it allows us to optimize various aspects of the proof, and in particular to provide an adaptive time-stepping strategy. In case the solution converges to a stable hyperbolic equilibrium, we are also able to prove this convergence, applying our rigorous integrator with a final, infinitely long timestep. We showcase the ability of our method to rigorously integrate over relatively long time intervals, and to capture non-trivial dynamics, via examples on the Swift--Hohenberg equation, the Ohta--Kawasaki equation and the Kuramoto--Sivashinsky equation. We expect that the simplicity and efficiency of the approach will enable generalization to a wide variety of other parabolic PDEs, as well as applications to boundary value problems."}
{"id": "2601.04364", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.04364", "abs": "https://arxiv.org/abs/2601.04364", "authors": ["Yinan Chen", "Sara Murciano", "Pablo Sala", "Jason Alicea"], "title": "Quantum sensing with critical systems: impact of symmetry, imperfections, and decoherence", "comment": null, "summary": "Entangled many-body states enable high-precision quantum sensing beyond the standard quantum limit. We develop interferometric sensing protocols based on quantum critical wavefunctions and compare their performance with Greenberger-Horne-Zeilinger (GHZ) and spin-squeezed states. Building on the idea of symmetries as a metrological resource, we introduce a symmetry-based algorithm to identify optimal measurement strategies. We illustrate this algorithm both for magnetic systems with internal symmetries and Rydberg-atom arrays with spatial symmetries. We study the robustness of criticality for quantum sensing under non-unitary deformations, symmetry-preserving and symmetry-breaking decoherence, and qubit loss -- identifying regimes where critical systems outperform GHZ states and showing that non-unitary deformation can even enhance sensing precision. Combined with recent results on log-depth preparation of critical wavefunctions, interferometric sensing in this setting appears increasingly promising."}
{"id": "2601.04535", "categories": ["quant-ph", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2601.04535", "abs": "https://arxiv.org/abs/2601.04535", "authors": ["Kaiyuan Cao", "Mingzhi Li", "Xiang-Ping Jiang", "Shu Chen", "Jian Wang"], "title": "Momentum-Space Entanglement Entropy as a Universal Signature of Dynamical Quantum Phase Transitions", "comment": "5 pages", "summary": "We introduce a momentum-space entanglement entropy to quantify quantum correlations between distinct momentum modes following a quench. We prove analytically in the transverse-field Ising (TFI) model and the Su-Schrieffer-Heeger (SSH) chain that every critical momentum $k^{*}$ associated with a dynamical quantum phase transition (DQPT) saturates its entanglement entropy to the maximal value $\\ln{d}$ ($d=2$ in TFI and SSH models), coinciding with the vanishing of the Loschmidt echo. This saturation of mode entanglement thus provides a universal, direct signature of DQPTs. Our work thus establishes a unified, entanglement-based perspective on dynamical quantum phase transitions."}
{"id": "2601.05196", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05196", "abs": "https://arxiv.org/abs/2601.05196", "authors": ["Min Long", "Zeno Bacciconi", "Hongyu Lu", "Hernan B. Xavier", "Zi Yang Meng", "Marcello Dalmonte"], "title": "Chiral Graviton Modes in Fermionic Fractional Chern Insulators", "comment": "24 pages,22 figures", "summary": "Chiral graviton modes are hallmark collective excitations of Fractional Quantum Hall (FQH) liquids. However, their existence on the lattice, where continuum symmetries that protect them from decay are lost, is still an open and urgent question, especially considering the recent advances in the realization of Fractional Chern Insulators (FCI) in transition metal dichalcogenides and rhombohedral pentalayer graphene. Here we present a comprehensive theoretical and numerical study of graviton-modes in fermionic FCI, and thoroughly demonstrate their existence. We first derive a lattice stress tensor operator in the context of the fermionic Harper-Hofstadter(HH) model which captures the graviton in the flat band limit. Importantly, we discover that such lattice stress-tensor operators are deeply connected to lattice quadrupolar density correlators, readily generalizable to generic Chern bands. We then explicitly show the adiabatic connection between FQH and FCI chiral graviton modes by interpolating from a low flux HH model to a Checkerboard lattice model that hosts a topological flat band. In particular, using state-of-the-art matrix product state and exact diagonalization simulations, we provide strong evidence that chiral graviton modes are long-lived excitations in FCIs despite the lack of continuous symmetries and the scattering with a two-magnetoroton continuum. By means of a careful finite-size analysis, we show that the lattice generates a finite but small intrinsic decay rate for the graviton mode. We discuss the relevance of our results for the exploration of graviton modes in FCI phases realized in solid state settings, as well as cold atom experiments."}
{"id": "2601.05224", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.05224", "abs": "https://arxiv.org/abs/2601.05224", "authors": ["Delfina B. Comerso Salzer", "Malena I. Español", "Gabriela Jeronimo"], "title": "Variable Projection Methods for Solving Regularized Separable Inverse Problems with Applications to Semi-Blind Image Deblurring", "comment": "26 pages", "summary": "Separable nonlinear least squares problems appear in many inverse problems, including semi-blind image deblurring. The variable projection (VarPro) method provides an efficient approach for solving such problems by eliminating linear variables and reducing the problem to a smaller, nonlinear one. In this work, we extend VarPro to solve minimization problems containing a differentiable regularization term on the nonlinear parameters, along with a general-form Tikhonov regularization term on the linear variables. Furthermore, we develop a quasi-Newton method for solving the resulting reduced problem, and provide a local convergence analysis under standard smoothness assumptions, establishing conditions for superlinear or quadratic convergence. For large-scale settings, we introduce an inexact LSQR-based variant and prove its local convergence despite inner-solve and Hessian approximations. Numerical experiments on semi-blind deblurring show that parameter regularization prevents degenerate no-blur solutions and that the proposed methods achieve accurate reconstructions, with the inexact variant offering a favorable accuracy-cost tradeoff consistent with the theory."}
{"id": "2601.04905", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.04905", "abs": "https://arxiv.org/abs/2601.04905", "authors": ["Sachin Sonkar", "Ramandeep S. Johal"], "title": "Virtual temperatures as a key quantifier for passive states in quantum thermodynamic processes", "comment": "20 pages, 3 figures. Comments are welcome", "summary": "We analyze the role of virtual temperatures for passive quantum states through the lens of majorization theory. A mean temperature over the virtual temperatures of adjacent energy levels is defined to compare the passive states of the system resulting from isoenergetic and isoentropic transformations. The role of the minimum and the maximum (min-max) values of the virtual temperatures in determining the direction of heat flow between the system and the environment is argued based on majorization relations. We characterize the intermediate passive states in a quantum Otto engine using these virtual temperatures and derive an upper bound for the Otto efficiency that can be expressed in terms of the min-max virtual temperatures of the working medium. An explicit example of the coupled-spins system is worked out. Moreover, virtual temperatures serve to draw interesting parallels between the quantum thermodynamic processes and their classical counterparts. Thus, virtual temperature emerges as a key operational quantity linking passivity and majorization to the optimal performance of quantum thermal machines."}
{"id": "2601.04543", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.04543", "abs": "https://arxiv.org/abs/2601.04543", "authors": ["Venkat Abhignan", "Mohit Mittal", "Aditi Das", "Megha Shrivastava"], "title": "Increasing the secret key rates and point-to-multipoint extension for experimental coherent-one-way quantum key distribution protocol", "comment": null, "summary": "Using quantum key distribution (QKD) protocols, a secret key is created between two distant users (transmitter and receiver) at a particular key rate. Quantum technology can facilitate secure communication for cryptographic applications, combining QKD with one-time-pad (OTP) encryption. In order to ensure the continuous operation of QKD in real-world networks, efforts have been concentrated on optimizing the use of components and effective QKD protocols to improve secret key rates and increase the transmission between multiple users. Generally, in experimental implementations, the secret key rates are limited by single-photon detectors, which are used at the receivers of QKD and create a bottleneck due to their limited detection rates (detectors with low detection efficiency and high detector dead-time). We experimentally show that secret key rates can be increased by combining the time-bin information of two such detectors on the data line of the receiver for the coherent-one-way (COW) QKD protocol with a minimal increase in quantum bit error rate (QBER, the proportion of erroneous bits). Further, we implement a point-to-multipoint COW QKD protocol, introducing an additional receiver module. The three users (one transmitter and two receivers) share the secret key in post-processing, relying on OTP encryption. Typically, the dual-receiver extension can improve the combined secret key rates of the system; however, one has to optimise the experimental parameters to achieve this within security margins. These methods are general and can be applied to any implementation of the COW protocol."}
{"id": "2601.05236", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.05236", "abs": "https://arxiv.org/abs/2601.05236", "authors": ["M. F. DiScala", "A. de la Torre", "J. W. Krizan", "J. Wouters", "V. Bisogni", "J. Pelliciari", "R. J. Cava", "K. W. Plumb"], "title": "Stability of the Local Ni$^{2+}$ Electronic Structure to $A$-site Disorder in the Pyrochlore Antiferromagnet NaCaNi$_2$F$_7$", "comment": "12 pages, 7 figures", "summary": "NaCaNi$_2$F$_7$ is a unique example of spin-1 Heisenberg antiferromagnet on the pyrochlore lattice, but the presence of Na$^{1+}$/Ca$^{2+}$ $A$-site disorder complicates the local electronic and magnetic environment of the Ni$^{2+}$ $B$-site. We utilize resonant inelastic X-ray scattering (RIXS) to study the influence of $A$-site disorder on the $B$-site electronic structure of NaCaNi$_2$F$_7$. Ni L-edge RIXS measurements reveal a Ni$^{2+}$ electronic structure in nearly ideal octahedral coordination, with only a small trigonal compression ($δ$ = -200$\\;$meV) required to capture all spectral features. Within the $D_{3d}$ symmetry of the Ni local environment, we extract an anisotropic $g$-factor of $g_{\\parallel} = 2.26$ and $g_{\\perp} = 2.27$, and a corresponding paramagnetic moment of $μ_{\\rm{eff}}=3.2\\;μ_B$. To simulate disorder, RIXS spectra were calculated with realistic distributions of crystal field parameters; however, these spectra are invariant relative to a disorder-free model, demonstrating the robustness of the Ni$^{2+}$ electronic environment to the $A$-site disorder, within the resolution of our measurement."}
{"id": "2601.04473", "categories": ["math.ST", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.04473", "abs": "https://arxiv.org/abs/2601.04473", "authors": ["Jiaheng Chen", "Daniel Sanz-Alonso"], "title": "Convergence Rates for Learning Pseudo-Differential Operators", "comment": "72 pages, 1 figure", "summary": "This paper establishes convergence rates for learning elliptic pseudo-differential operators, a fundamental operator class in partial differential equations and mathematical physics. In a wavelet-Galerkin framework, we formulate learning over this class as a structured infinite-dimensional regression problem with multiscale sparsity. Building on this structure, we propose a sparse, data- and computation-efficient estimator, which leverages a novel matrix compression scheme tailored to the learning task and a nested-support strategy to balance approximation and estimation errors. In addition to obtaining convergence rates for the estimator, we show that the learned operator induces an efficient and stable Galerkin solver whose numerical error matches its statistical accuracy. Our results therefore contribute to bringing together operator learning, data-driven solvers, and wavelet methods in scientific computing."}
{"id": "2601.05065", "categories": ["cs.SI", "cond-mat.stat-mech", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.05065", "abs": "https://arxiv.org/abs/2601.05065", "authors": ["Lucas Böttcher", "Mason A. Porter", "Santo Fortunato"], "title": "Graph energy as a measure of community detectability in networks", "comment": "12 pages, 3 figures, 1 table", "summary": "A key challenge in network science is the detection of communities, which are sets of nodes in a network that are densely connected internally but sparsely connected to the rest of the network. A fundamental result in community detection is the existence of a nontrivial threshold for community detectability on sparse graphs that are generated by the planted partition model (PPM). Below this so-called ``detectability limit'', no community-detection method can perform better than random chance. Spectral methods for community detection fail before this detectability limit because the eigenvalues corresponding to the eigenvectors that are relevant for community detection can be absorbed by the bulk of the spectrum. One can bypass the detectability problem by using special matrices, like the non-backtracking matrix, but this requires one to consider higher-dimensional matrices. In this paper, we show that the difference in graph energy between a PPM and an Erdős--Rényi (ER) network has a distinct transition at the detectability threshold even for the adjacency matrices of the underlying networks. The graph energy is based on the full spectrum of an adjacency matrix, so our result suggests that standard graph matrices still allow one to separate the parameter regions with detectable and undetectable communities."}
{"id": "2601.04549", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04549", "abs": "https://arxiv.org/abs/2601.04549", "authors": ["Jie Feng", "XiaoDi Liu", "Haian Xu", "Pu Wang", "Graeme J. Ackland", "Eugene Gregoryanz"], "title": "Observation of ΔJ=0 Rotational Excitation in Dense Hydrogens", "comment": null, "summary": "Raman measurements performed on dense H2, D2 and H2+D2 in a wide pressure-temperature range reveal the presence of the ΔJ=0 rotational excitation. In the gas/fluid state this excitation has zero Raman shift, but in the solid, the crystal field drive s it away from the zero value e.g. 75 cm-1 at around 50 GPa and 10 K for both isotopes and their mixture. In the case of deuterium, the ΔJ=0 mode splits upon entering phase II suggesting a very complex molecular environment of the broken symmetry phase (BSP). In the fluid state and phases I and II the frequencies (energies) of the ΔJ=0 transition for H2 and D2 do not scale either as rotational (by factor of 2) nor vibrational (by square 2) modes and appear to be completely isotope independent. This independence on mass marks this transition as unique and a fundamentally different type of excitation from the commonly considered harmonic oscillator and quantum rotor."}
{"id": "2601.04305", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.04305", "abs": "https://arxiv.org/abs/2601.04305", "authors": ["Umberto Borla", "Achilleas Lazarides", "Christian Groß", "Jad C. Halimeh"], "title": "Microscopic Dynamics of False Vacuum Decay in the $2+1$D Quantum Ising Model", "comment": "$9+3$ pages, $5+3$ figures", "summary": "False vacuum decay, which is understood to happen through bubble nucleation, is a prominent phenomenon relevant to elementary particle physics and early-universe cosmology. Understanding its microscopic dynamics in higher spatial dimensions is currently a major challenge and research thrust. Recent advances in numerical techniques allow for the extraction of related signatures in tractable systems in two spatial dimensions over intermediate timescales. Here, we focus on the $2+1$D quantum Ising model, where a longitudinal field is used to energetically separate the two $\\mathbb{Z}_2$ symmetry-broken ferromagnetic ground states, turning them into a ``true'' and ``false'' vacuum. Using tree tensor networks, we simulate the microscopic dynamics of a spin-down domain in a spin-up background after a homogeneous quench, with parameters chosen so that the domain corresponds to a bubble of the true vacuum in a false-vacuum background. Our study identifies how the ultimate fate of the bubble -- indefinite expansion or collapse -- depends on its geometrical features and on the microscopic parameters of the Ising Hamiltonian. We further provide a realistic quantum-simulation scheme, aimed at probing bubble dynamics on atomic Rydberg arrays."}
{"id": "2601.04510", "categories": ["cs.CE", "cs.AI", "cs.CV", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.04510", "abs": "https://arxiv.org/abs/2601.04510", "authors": ["Christophe Bonneville", "Nathan Bieberdorf", "Pieterjan Robbe", "Mark Asta", "Habib Najm", "Laurent Capolungo", "Cosmin Safta"], "title": "Towards Spatio-Temporal Extrapolation of Phase-Field Simulations with Convolution-Only Neural Networks", "comment": null, "summary": "Phase-field simulations of liquid metal dealloying (LMD) can capture complex microstructural evolutions but can be prohibitively expensive for large domains and long time horizons. In this paper, we introduce a fully convolutional, conditionally parameterized U-Net surrogate designed to extrapolate far beyond its training data in both space and time. The architecture integrates convolutional self-attention, physically informed padding, and a flood-fill corrector method to maintain accuracy under extreme extrapolation, while conditioning on simulation parameters allows for flexible time-step skipping and adaptation to varying alloy compositions. To remove the need for costly solver-based initialization, we couple the surrogate with a conditional diffusion model that generates synthetic, physically consistent initial conditions. We train our surrogate on simulations generated over small domain sizes and short time spans, but, by taking advantage of the convolutional nature of U-Nets, we are able to run and extrapolate surrogate simulations for longer time horizons than what would be achievable with classic numerical solvers. Across multiple alloy compositions, the framework is able to reproduce the LMD physics accurately. It predicts key quantities of interest and spatial statistics with relative errors typically below 5% in the training regime and under 15% during large-scale, long time-horizon extrapolations. Our framework can also deliver speed-ups of up to 36,000 times, bringing the time to run weeks-long simulations down to a few seconds. This work is a first stepping stone towards high-fidelity extrapolation in both space and time of phase-field simulation for LMD."}
{"id": "2601.04591", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04591", "abs": "https://arxiv.org/abs/2601.04591", "authors": ["Wonhyeong Choi", "Jiyong Kang", "Kyunghye Kim", "Jaehun You", "Kyungmin Lee", "Taehyun Kim"], "title": "Multimode Fock-State Measurements using Dispersive Shifts in a Trapped Ion", "comment": null, "summary": "Trapped ions naturally host multiple motional modes alongside long-lived spin qubits, providing a scalable multimode bosonic register. Efficiently characterizing such bosonic registers requires the ability to access many motional modes with limited spin resources. Here we introduce a single-spin, multimode measurement primitive using dispersive shifts in the far-detuned multimode Jaynes-Cummings interaction. We implement a Ramsey sequence that maps phonon-number-dependent phases onto the spin, thereby realizing a multimode spin-dependent rotation (SDR). We also introduce a selective-decoupling scheme that cancels the phase induced by the carrier AC-Stark shift while preserving the phonon-number-dependent phase induced by the dispersive shift. Using this SDR-based Ramsey sequence on a single trapped ion, we experimentally extract two-mode Fock-state distributions, perform parity-based filtering of two-mode motional states, and realize a nondestructive single-shot measurement of a single-mode Fock state via repeated filtering steps."}
{"id": "2601.05177", "categories": ["cond-mat.dis-nn", "cond-mat.quant-gas", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05177", "abs": "https://arxiv.org/abs/2601.05177", "authors": ["Asmi Haldar", "Thibault Scoquart", "Fabien Alet", "Nicolas Laflorencie"], "title": "Beyond the imbalance: site-resolved dynamics probing resonances in many-body localization", "comment": "(13 + 9) pages and (8 + 2) figures", "summary": "We explore the limitations of using imbalance dynamics as a diagnostic tool for many-body localization (MBL) and show that spatial averaging can mask important microscopic features. Focusing on the strongly disordered regime of the random-field XXZ chain, we use state-of-the-art numerical techniques (Krylov time evolution and full diagonalization) to demonstrate that site-resolved spin autocorrelators reveal a rich and complex dynamical behavior that is obscured by the imbalance observable. By analyzing the time evolution and infinite-time limits of these local probes, we reveal resonant structures and rare local instabilities within the MBL phase. These numerical findings are supported by an analytical, few-site toy model that captures the emergence of a multiple-peak structure in local magnetization histograms, which is a hallmark of local resonances. These few-body local effects provide a more detailed understanding of ergodicity-breaking dynamics, and also allow us to explain the finite-size effects of long-time imbalance, and its sensitivity to the initial conditions in quench protocols. Overall, our experimentally testable predictions highlight the necessity of a refined, site-resolved approach to fully understand the complexities of MBL and its connection to rare-region effects."}
{"id": "2601.05029", "categories": ["math.OC", "math.FA", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.05029", "abs": "https://arxiv.org/abs/2601.05029", "authors": ["Evie Nielen", "Oliver Tse"], "title": "Stochastic convergence of a class of greedy-type algorithms for Configuration Optimization Problems", "comment": "32 pages, 9 figures", "summary": "Greedy Sampling Methods (GSMs) are widely used to construct approximate solutions of Configuration Optimization Problems (COPs), where a loss functional is minimized over finite configurations of points in a compact domain. While effective in practice, deterministic convergence analyses of greedy-type algorithms are often restrictive and difficult to verify. We propose a stochastic framework in which greedy-type methods are formulated as continuous- time Markov processes on the space of configurations. This viewpoint enables convergence analysis in expectation and in probability under mild structural assumptions on the error functional and the transition kernel. For global error functionals, we derive explicit convergence rates, including logarithmic, polynomial, and exponential decay, depending on an abstract improvement condition. As a pedagogical example, we study stochastic greedy sampling for one-dimensional piece- wise linear interpolation and prove exponential convergence of the $L^1$-interpolation error for $C^2$- functions. Motivated by this analysis, we introduce the Randomized Polytope Division Method (R-PDM), a randomized variant of the classical Polytope Division Method, and demonstrate its effectiveness and variance reduction in numerical experiments"}
{"id": "2601.04604", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.04604", "abs": "https://arxiv.org/abs/2601.04604", "authors": ["Amartya Bose"], "title": "Path Integral Lindblad Dynamics in Presence of Time-Dependent Fields", "comment": "4 pages, 2 figures", "summary": "The path integral Lindblad dynamics (PILD) method [A. Bose, J. Phys. Chem. Lett. 15(12), 3363-3368 (2024)] had been introduced as a way of incorporating the impact of certain empirical processes like pumps and drains on the dynamics of quantum systems interacting with thermal environments. The method being based on the time-translational invariance of the Nakajima-Zwanzig memory kernel, however, was not able to account for time-dependent external fields. In this communication, we give an alternate, simpler formulation of PILD, that allows us to go beyond this limitation. It does not require the evaluation of the non-Markovian memory kernel directly, and consequently can be applied to Floquet systems as well."}
{"id": "2601.05238", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.05238", "abs": "https://arxiv.org/abs/2601.05238", "authors": ["Sibaram Ruidas", "Sthitadhi Roy", "Subhro Bhattacharjee", "Roderich Moessner"], "title": "How many-body chaos emerges in the presence of quasiparticles", "comment": "18 pages, 15 figures", "summary": "Many-body chaos is a default property of many-body systems; at the same time, near-integrable behaviour due to weakly interacting quasiparticles is ubiquitous throughout condensed matter at low temperature. There must therefore be a, possibly generic, crossover between these very different regimes. Here, we develop a theory encapsulating the notion of a cascade of lightcones seeded by sequences of scattering of weakly interacting harmonic modes as witnessed by a suitably defined chaos diagnostic (classical decorrelator) that measures the spatiotemporal profile of many-body chaos. Our numerics deals with the concrete case of a classical Heisenberg chain, for either sign of the interaction, at low temperatures where the short-time dynamics are well captured in terms of non-interacting spin waves. To model low-temperature dynamics, we use ensembles of initial states with randomly embedded point defects in an otherwise ordered background, which provides a controlled setting for studying the scattering events. The decorrelator exhibits a short-time integrable regime followed by an intermediate `scarred' regime of the cascade of lightcones in progress; these then overlap, leading to an avalanche of scattering events which finally yields the standard long-time signature of many-body chaos."}
{"id": "2601.04636", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04636", "abs": "https://arxiv.org/abs/2601.04636", "authors": ["Duc Manh Doan", "Hung Q. Nguyen"], "title": "Hardy nonlocality for entangled pairs in a four-particle system", "comment": null, "summary": "Nonlocality can be studied through different approaches, such as Bell's inequalities, and it can be found in numerous quantum states, including GHZ states or graph states. Hardy's paradox, or Hardy-type nonlocality, provides a way to investigate nonlocality for entangled states of particles without using inequalities. Previous studies of Hardy's nonlocality have mostly focused on the fully entangled systems, while other entanglement configurations remain less explored. In this work, the system under investigation consists of four particles arranged in a cyclic entanglement configuration, where each particle forms entangled pairs with two neighbors, while non-neighboring particles remain unentangled. We found that this entanglement structure offers a larger set of conditions that lead to the contradiction with the LHV model, compared to the fully entangled systems. This enhancement can be attributed to the presence of multiple excluded states and correlations, in which the measurement result of a particle only influences the result of its paired partners. We implement quantum circuits compatible with the cyclic entanglement structure, and through simulation, the correlation patterns and the states of interest are identified. We further execute the proposed circuits on IBM Brisbane, a practical backend; however, the results show considerable deviations from the simulation counterparts."}
{"id": "2601.04645", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04645", "abs": "https://arxiv.org/abs/2601.04645", "authors": ["Xinxuan Chen", "Hongxiang Zhu", "Zhaohui Yang", "Zhaofeng Su", "Jianxin Chen", "Feng Wu", "Hui-Hai Zhao"], "title": "SurgeQ: A Hybrid Framework for Ultra-Fast Quantum Processor Design and Crosstalk-Aware Circuit Execution", "comment": "7 pages, 4 figures; accepted by DATE 2026", "summary": "Executing quantum circuits on superconducting platforms requires balancing the trade-off between gate errors and crosstalk. To address this, we introduce SurgeQ, a hardware-software co-design strategy consisting of a design phase and an execution phase, to achieve accelerated circuit execution and improve overall program fidelity. SurgeQ employs coupling-strengthened, faster two-qubit gates while mitigating their increased crosstalk through a tailored scheduling strategy. With detailed consideration of composite noise models, we establish a systematic evaluation pipeline to identify the optimal coupling strength. Evaluations on a comprehensive suite of real-world benchmarks show that SurgeQ generally achieves higher fidelity than up-to-date baselines, and remains effective in combating exponential fidelity decay, achieving up to a million-fold improvement in large-scale circuits."}
{"id": "2601.04685", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04685", "abs": "https://arxiv.org/abs/2601.04685", "authors": ["Eliahu Cohen", "Tomer Shushi"], "title": "Regularization from Superpositions of Time Evolutions", "comment": "11 pages, comments are welcome", "summary": "Short-time approximations and path integrals can be dominated by high-energy or large-field contributions, especially in the presence of singular interactions, motivating regulators that are suppressive yet removable. Standard regulators typically impose such suppressions by hand (e.g. cutoffs, higher-derivative terms, heat-kernel smearing, lattice discretizations), while here we show that closely related smooth filters can arise as the conditional map produced by interference in a coherently controlled, postselected superposition of evolutions. A successful postselection implements a single heralded operator that is a coherent linear combination of time-evolution operators. For a Gaussian superposition of time translations in quantum mechanics, the postselected step is $V_{σ,Δt}=e^{-iHΔt}\\,e^{-\\frac12σ^2Δt^2H^2}$, i.e.\\ the desired unitary step multiplied by a Gaussian energy filter suppressing energies above order $1/(σΔt)$. This renders short-time kernels in time-sliced path-integral approximations well behaved for singular potentials, while the target unitary dynamics is recovered as $σ\\to0$ and (for fixed $σ$) also as $Δt\\to0$ at fixed $t$. In scalar QFT, a local Gaussian smearing of the quartic coupling induces a positive $(σ^2/2)φ^8$ term in the Euclidean action, providing a symmetry-compatible large-field stabilizer; it is naturally viewed as an irrelevant operator whose effects can be renormalized at fixed $σ$ (together with a conventional UV regulator) and removed by taking $σ\\to0$. We give short-time error bounds and analyze multi-step success probabilities."}
{"id": "2601.04732", "categories": ["quant-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.04732", "abs": "https://arxiv.org/abs/2601.04732", "authors": ["Dominik Freinberger", "Philipp Moser"], "title": "The Role of Quantum in Hybrid Quantum-Classical Neural Networks: A Realistic Assessment", "comment": "16 pages, 6 figures", "summary": "Quantum machine learning has emerged as a promising application domain for near-term quantum hardware, particularly through hybrid quantum-classical models that leverage both classical and quantum processing. Although numerous hybrid architectures have been proposed and demonstrated successfully on benchmark tasks, a significant open question remains regarding the specific contribution of quantum components to the overall performance of these models. In this work, we aim to shed light on the impact of quantum processing within hybrid quantum-classical neural network architectures through a rigorous statistical study. We systematically assess common hybrid models on medical signal data as well as planar and volumetric images, examining the influence attributable to classical and quantum aspects such as encoding schemes, entanglement, and circuit size. We find that in best-case scenarios, hybrid models show performance comparable to their classical counterparts, however, in most cases, performance metrics deteriorate under the influence of quantum components. Our multi-modal analysis provides realistic insights into the contributions of quantum components and advocates for cautious claims and design choices for hybrid models in near-term applications."}
{"id": "2601.04733", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.04733", "abs": "https://arxiv.org/abs/2601.04733", "authors": ["Nicholas S. Yama", "Chun-Chi Wu", "Fariba Hatami", "Kai-Mei C. Fu"], "title": "A scalable gallium-phosphide-on-diamond spin-photon interface", "comment": null, "summary": "The efficient interfacing of quantum emitters and photons is fundamental to quantum networking. Quantum defects embedded in integrated nanophotonic circuits are promising for such applications due to the deterministic light-matter interactions of high-cooperativity ($C>1$) cavity quantum electrodynamics and potential for scalable integration with active photonic processing. Silicon-vacancy (SiV) centers embedded in diamond nanophotonic cavities are a leading approach due to their excellent optical and spin coherence, however their long-term scalability is limited by the diamond itself, as its suspended geometry and weak nonlinearity necessitates coupling to a second processing chip. Here we realize the first high-cooperativity coupling of quantum defects to hybrid-integrated nanophotonics in a scalable, planar platform. We integrate more than 600 gallium phosphide (GaP) nanophotonic cavities on a diamond substrate with near-surface SiV centers. We examine a particular device with two strongly coupled SiV centers in detail, confirming above-unity cooperativity via multiple independent measurements. Application of an external magnetic field via a permanent magnet enables optical resolution of the SiV spin transitions from which we determine a spin-relaxation time $T_1>0.4$ ms at 4 K. We utilize the high cooperativity coupling to observe spin-dependent transmission switching and the quantum jumps of the SiV spin via single-shot readout. These results, coupled with GaP's strong nonlinear properties, establish GaP-on-diamond as a scalable planar platform for quantum network applications."}
{"id": "2601.04806", "categories": ["quant-ph", "math-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2601.04806", "abs": "https://arxiv.org/abs/2601.04806", "authors": ["Mohamed Améziane Sadoun", "Redouane Zamoum", "Abdellah Touati"], "title": "Bound state solutions with a linear combination of Yuakawa plus four-parameter diatomic potentials using path integral approach: Thermodynamic properties", "comment": null, "summary": "In this paper, we investigate the approximate analytical bound states with a linear combination of two diatomic molecule potentials, Yukawa and four parameters potentials, within the framework of the path integral formalism. With the help of an appropriate approximation to evaluate the centrifugal term, the energy spectrum and the normalized wave functions of the bound states are derived from the poles of Green's function and its residues. The partition function and other thermodynamic properties were obtained using the compact form of the energy equation."}
{"id": "2601.04810", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04810", "abs": "https://arxiv.org/abs/2601.04810", "authors": ["Alexander van Lomwel", "Paul M. Schindler", "Modesto Orozco-Ruiz", "Marin Bukov", "Nguyen H. Le", "Florian Mintert"], "title": "Fast thermal state preparation beyond native interactions", "comment": null, "summary": "While questions on quantum simulation of ground state physics are mostly focussed on the realization of effective interactions, most work on quantum simulation of thermal physics explores the realization of dynamics towards a thermal mixed state under native interactions. Many open questions that could be answered with quantum simulations, however, involve thermal states with respect to synthetic interactions. We present a framework based solely on unitary dynamics to design quantum simulations for thermal states with respect to Hamiltonians that include non-native interactions, suitable for both present-day digital and analogue devices. By classical means, our method finds the control sequence to reach a target thermal state for system sizes well out of reach of state-vector or density-matrix control methods, even though quantum hardware is required to explicitly simulate the thermal state dynamics. With the illustrative example of the cluster Ising model that includes non-native three-body interactions, we find that required experimental resources, such as the total evolution time, are independent of temperature and criticality."}
{"id": "2601.04812", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04812", "abs": "https://arxiv.org/abs/2601.04812", "authors": ["Alessio Benavoli", "Felix Binder"], "title": "Quantum Wiener architecture for quantum reservoir computing", "comment": null, "summary": "This work focuses on quantum reservoir computing and, in particular, on quantum Wiener architectures (qWiener), consisting of quantum linear dynamic networks with weak continuous measurements and classical nonlinear static readouts. We provide the first rigorous proof that qWiener systems retain the fading-memory property and universality of classical Wiener architectures, despite quantum constraints on linear dynamics and measurement back-action. Furthermore, we develop a kernel-theoretic interpretation showing that qWiener reservoirs naturally induce deep kernels, providing a principled framework for analysing their expressiveness. We further characterise the simplest qWiener instantiation, consisting of concatenated quantum harmonic oscillators, and show the difference with respect to the classical case. Finally, we empirically evaluate the architecture on standard reservoir computing benchmarks, demonstrating systematic performance gains over prior classical and quantum reservoir computing models."}
{"id": "2601.04827", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04827", "abs": "https://arxiv.org/abs/2601.04827", "authors": ["Tran Xuan Hieu Le", "Tuan Hai Vu", "Vu Trung Duong Le", "Hoai Luan Pham", "Yasuhiko Nakashima"], "title": "PACOX: A FPGA-based Pauli Composer Accelerator for Pauli String Computation", "comment": "5 pages, 6 figures. This paper is submitted to IEEE Signal Processing Letter", "summary": "Pauli strings are a fundamental computational primitive in hybrid quantum-classical algorithms. However, classical computation of Pauli strings suffers from exponential complexity and quickly becomes a performance bottleneck as the number of qubits increases. To address this challenge, this paper proposes the Pauli Composer Accelerator (PACOX), the first dedicated FPGA-based accelerator for Pauli string computation. PACOX employs a compact binary encoding with XOR-based index permutation and phase accumulation. Based on this formulation, we design a parallel and pipelined processing element (PE) cluster architecture that efficiently exploits data-level parallelism on FPGA. Experimental results on a Xilinx ZCU102 FPGA show that PACOX operates at 250 MHz with a dynamic power consumption of 0.33 W, using 8,052 LUTs, 10,934 FFs, and 324 BRAMs. For Pauli strings of up to 19 qubits, PACOX achieves speedups of up to 100 times compared with state-of-the-art CPU-based methods, while requiring significantly less memory and achieving a much lower power-delay product. These results demonstrate that PACOX delivers high computational speed with superior energy efficiency for Pauli-based workloads in hybrid quantum-classical systems."}
{"id": "2601.04830", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04830", "abs": "https://arxiv.org/abs/2601.04830", "authors": ["Thibault Scoquart", "Hugo Perrin", "Kyrylo Snizhko"], "title": "Noise tailoring for error mitigation and for diagnozing digital quantum computers", "comment": "27 pages, 16 figures", "summary": "Error mitigation (EM) methods are crucial for obtaining reliable results in the realm of noisy intermediate-scale quantum (NISQ) computers, where noise significantly impacts output accuracy. Some EM protocols are particularly efficient for specific types of noise. Yet the noise in the actual hardware may not align with that. In this article, we introduce Noise Tailoring (NT) -- an innovative strategy designed to modify the structure of the noise associated with two-qubit gates through statistical sampling. We perform classical emulation of the protocol behavior and find that the NT+EM results can be up to 5 times more accurate than the results of EM alone for realistic Pauli noise acting on two-qubit gates. At the same time, on actual IBM quantum computers, the NT method falls victim to various small error sources beyond Markovian Pauli noise. We propose to use the NT method for characterizing such error sources on quantum computers in order to inform hardware development."}
{"id": "2601.04848", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04848", "abs": "https://arxiv.org/abs/2601.04848", "authors": ["Mariagrazia Iuliano", "Nicolas Demetriou", "H. Benjamin van Ommen", "Constantijn Karels", "Tim H. Taminiau", "Ronald Hanson"], "title": "Unconditionally teleported quantum gates between remote solid-state qubit registers", "comment": null, "summary": "Quantum networks connecting quantum processing nodes via photonic links enable distributed and modular quantum computation. In this framework, quantum gates between remote qubits can be realized using quantum teleportation protocols. The essential requirements for such non-local gates are remote entanglement, local quantum logic within each processor, and classical communication between nodes to perform operations based on measurement outcomes. Here, we demonstrate an unconditional Controlled-NOT quantum gate between remote diamond-based qubit devices. The control and target qubits are Carbon-13 nuclear spins, while NV electron spins enable local logic, readout, and remote entanglement generation. We benchmark the system by creating a Greenberger-Horne-Zeilinger state, showing genuine 4-partite entanglement shared between nodes. Using deterministic logic, single-shot readout, and real-time feed-forward, we implement non-local gates without post-selection. These results demonstrate a key capability for solid-state quantum networks, enabling exploration of distributed quantum computing and testing of complex network protocols on fully integrated systems."}
{"id": "2601.04856", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04856", "abs": "https://arxiv.org/abs/2601.04856", "authors": ["Zeyu Liu", "Pengfei Zhang"], "title": "Distinguishing Coherent and Incoherent Errors in Multi-Round Time-Reversed Dynamics via Scramblons", "comment": "8 pages, 4 figures + Supplementary Material", "summary": "Despite the rapid development of quantum science and technology, errors are inevitable and play a crucial role in quantum simulation and quantum computation. In quantum chaotic systems, coherent errors arising from imperfect Hamiltonian control and incoherent errors induced by coupling to the environment are both exponentially amplified during time evolution due to information scrambling. A fundamental question is how these two classes of errors imprint distinct signatures on the emergent irreversibility of many-body dynamics. In this Letter, we address this question by investigating multi-round time-reversed dynamics in the presence of both coherent and incoherent errors. By applying scramblon theory, we obtain closed-form expressions for the Loschmidt echo over different rounds of time-reversed evolution. For incoherent errors, the error accumulates linearly with the number of rounds, whereas coherent errors exhibit a crossover from quadratic to linear accumulation. These predictions are explicitly verified using the solvable Sachdev-Ye-Kitaev model. Our results provide a theoretical foundation for characterizing and calibrating coherent and incoherent errors in reversed dynamics, with particular relevance to nuclear magnetic resonance systems."}
{"id": "2601.04880", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.04880", "abs": "https://arxiv.org/abs/2601.04880", "authors": ["Tobias Starke"], "title": "Quantenlogische Systeme und Tensorproduktraeume", "comment": "in German language", "summary": "In this work we present an intuitive construction of the quantum logical axiomatic system provided by George Mackey. The goal of this work is a detailed discussion of the results from the paper 'Physical justification for using the tensor product to describe two quantum systems as one joint system' [1] published by Diederik Aerts and Ingrid Daubechies. This means that we want to show how certain composed physical systems from classical and quantum mechanics should be described logically. To reach this goal, we will, like in [1], discuss a special class of axiomatically defined composed physical systems. With the help of certain results from lattice and c-morphism theory (see [2] and [23]), we will present a detailed proof of the statement, that in the quantum mechanical case, a composed physical system must be described via a tensor product space."}
{"id": "2601.04905", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.04905", "abs": "https://arxiv.org/abs/2601.04905", "authors": ["Sachin Sonkar", "Ramandeep S. Johal"], "title": "Virtual temperatures as a key quantifier for passive states in quantum thermodynamic processes", "comment": "20 pages, 3 figures. Comments are welcome", "summary": "We analyze the role of virtual temperatures for passive quantum states through the lens of majorization theory. A mean temperature over the virtual temperatures of adjacent energy levels is defined to compare the passive states of the system resulting from isoenergetic and isoentropic transformations. The role of the minimum and the maximum (min-max) values of the virtual temperatures in determining the direction of heat flow between the system and the environment is argued based on majorization relations. We characterize the intermediate passive states in a quantum Otto engine using these virtual temperatures and derive an upper bound for the Otto efficiency that can be expressed in terms of the min-max virtual temperatures of the working medium. An explicit example of the coupled-spins system is worked out. Moreover, virtual temperatures serve to draw interesting parallels between the quantum thermodynamic processes and their classical counterparts. Thus, virtual temperature emerges as a key operational quantity linking passivity and majorization to the optimal performance of quantum thermal machines."}
{"id": "2601.04949", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04949", "abs": "https://arxiv.org/abs/2601.04949", "authors": ["Xin Liu", "Zhicheng Luo", "Kaibiao Qin", "Jiawang Liu", "Zhenrong Zhang", "Kejin Wei"], "title": "High-Rate Free-Running Reference-Frame-Independent Measurement-Device-Independent Quantum Key Distribution with Classified Distillation", "comment": "5 pages, 4 figures", "summary": "Reference-frame-independent measurement-device-independent quantum key distribution (RFI-MDI-QKD) eliminates detector side-channel attacks and avoids reference-frame calibration. While its feasibility has been widely demonstrated, existing implementations typically assume fixed or slowly drifting reference-frame misalignment, conditions rarely satisfied outside the laboratory. In realistic environments, rapid and free-running reference-frame variations can severely degrade both the key rate and transmission distance of conventional RFI-MDI-QKD. Here we propose a free-running RFI-MDI-QKD protocol that maintains high-rate key generation under rapid reference-frame variations. By introducing a classification-distillation method that reclassifies total detection events, secure keys can be extracted without modifying the experimental setup. Our protocol achieves a key rate more than nine times higher than the best previous RFI-MDI-QKD scheme and tolerates channel losses exceeding 24 dB, where earlier approaches fail. These results enable practical quantum key distribution on mobile platforms, including satellite-to-ground links and airborne nodes."}
{"id": "2601.04975", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04975", "abs": "https://arxiv.org/abs/2601.04975", "authors": ["Guillaume Beaulieu", "Jun-Zhe Chen", "Marco Scigliuzzo", "Othmane Benhayoune-Khadraoui", "Alex A. Chapple", "Peter A. Spring", "Alexandre Blais", "Pasquale Scarlino"], "title": "Fast, high-fidelity Transmon readout with intrinsic Purcell protection via nonperturbative cross-Kerr coupling", "comment": "22 pages, 22 figures", "summary": "Dispersive readout of superconducting qubits relies on a transverse capacitive coupling that hybridizes the qubit with the readout resonator, subjecting the qubit to Purcell decay and measurement-induced state transitions (MIST). Despite the widespread use of Purcell filters to suppress qubit decay and near-quantum-limited amplifiers, dispersive readout often lags behind single- and two-qubit gates in both speed and fidelity. Here, we experimentally demonstrate junction readout, a simple readout architecture that realizes a strong qubit-resonator cross-Kerr interaction without relying on a transverse coupling. This interaction is achieved by coupling a transmon qubit to its readout resonator through both a capacitance and a Josephson junction. By varying the qubit frequency, we show that this hybrid coupling provides intrinsic Purcell protection and enhanced resilience to MIST, enabling readout at high photon numbers. While junction readout is compatible with conventional linear measurement, in this work we exploit the nonlinear coupling to intentionally engineer a large Kerr nonlinearity in the resonator, enabling bifurcation-based readout. Using this approach, we achieve a 99.4 % assignment fidelity with a 68 ns integration time and a 98.4 % QND fidelity without an external Purcell filter or a near-quantum-limited amplifier. These results establish the junction readout architecture with bifurcation-based readout as a scalable and practical alternative to dispersive readout, enabling fast, high-fidelity qubit measurement with reduced hardware overhead."}
{"id": "2601.04976", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04976", "abs": "https://arxiv.org/abs/2601.04976", "authors": ["Ting Lin", "Zhihua Chen", "Kai Wu", "Zhihua Guo", "Zhihao Ma", "Shao-Ming Fei"], "title": "Machine learning-aided direct estimation of coherence and entanglement for unknown states", "comment": null, "summary": "Quantum coherence and entanglement are fundamental resources in quantum technologies, yet their efficient estimation for unknown states by employing minimal resources in experimental settings remains challenging, particularly in high-dimensional systems. We present a machine learning approach based on support vector regression (SVR) that directly estimates the coherence measures and the geometric measure of quantum entanglement using minimal experimental resources. Our method requires only the diagonal entries of the density matrix, along with the traces of the squared and cubed density matrices for quantum coherence, and additionally along with the traces of the squared and cubed reduced density matrix for estimating quantum entanglement. These quantities can be obtained through random measurements or a hybrid quantum-classical framework. This approach significantly reduces the resource overhead compared to quantum state tomography while maintaining high accuracy. {Furthermore, the support vector quantile regression (SVQR) with pinball loss is employed to prevent SVR overestimation. This model not only ensures that over 95\\% of predictions are conservative lower bounds in most cases, but also maintains this lower-bound reliability for over 93\\% of predictions, despite 2\\% perturbations in the input features.} The proposed technique provides a practical and scalable tool for characterizing quantum resources across computation, communication, and metrology applications."}
{"id": "2601.04981", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.04981", "abs": "https://arxiv.org/abs/2601.04981", "authors": ["Hanna T. Fridman", "Rotem Malkinson", "Amir Hen", "Shira Yochelis", "Yossi Paltiel", "Nir Bar-gill"], "title": "Signatures of Spin Coherence in Chiral Coupled Quantum Dots", "comment": null, "summary": "Chiral-induced spin selectivity (CISS) enables spin selectivity of charge carriers in chiral molecular systems without magnetic materials. While spin selectivity has been widely investigated, its quantum coherence has not yet been explored. Here, we in- vestigate spin-dependent photoluminescence (PL) dynamics in multilayer quantum-dot (QD) assemblies coupled by chiral linkers. Using circularly polarized excitation in the presence of an external magnetic field, we observe a pronounced modulation of the PL lifetime that depends on the magnetic field magnitude and geometry. The lifetime difference between left- and right-circularly polarized excitations exhibits a field-angle dependence, consistent with spin precession driven by the transverse magnetic-field component relative to the chiral axis. A model incorporating coupled spin precession and decay processes reproduces the experimental trends. These results establish chiral QD assemblies as a room-temperature platform for probing quantum coherent manifestations of the CISS effect, with implications for spintronic and quantum technologies."}
{"id": "2601.04983", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.04983", "abs": "https://arxiv.org/abs/2601.04983", "authors": ["Rupayan Bhattacharjee", "Sergi Abadal", "Carmen G. Almudever", "Eduard Alarcon"], "title": "Quantum Neural Network Training and Inference with Low Resolution Control Electronics", "comment": "5 pages, 4 figures", "summary": "Scaling quantum computers requires tight integration of cryogenic control electronics with quantum processors, where Digital-to-Analog Converters (DACs) face severe power and area constraints. We investigate quantum neural network (QNN) training and inference under finite DAC resolution constraints across various DAC resolutions. Pre-trained QNNs achieve accuracy nearly indistinguishable from infinite-precision baselines when deployed on quantum systems with 6-bit DAC control electronics, exhibiting an elbow curve with diminishing returns beyond 4 bits. However, training under quantization reveals gradient deadlock below 12-bit resolution as gradient magnitudes fall below quantization step sizes. We introduce temperature-controlled stochasticity that overcomes this through probabilistic parameter updates, enabling successful training at 4-10 bit resolutions that remarkably matches or exceeds infinite-precision baseline performance. Our findings demonstrate that low-resolution control electronics need not compromise QML performance, enabling significant power and area reduction in cryogenic control systems for practical deployment as quantum hardware scales."}
{"id": "2601.04998", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.04998", "abs": "https://arxiv.org/abs/2601.04998", "authors": ["Yiting Mao", "Peigeng Zhong", "Haiqing Lin", "Xiaoqun Wang", "Shijie Hu"], "title": "Encoding complex-balanced thermalization in quantum circuits", "comment": "Main Text (4 pages + 4 figures), End Matter (1 page), Supplemental Material (3 pages + 2 figures)", "summary": "We propose a protocol for effectively implementing complex-balanced thermalization via Markovian processes on a quantum-circuit platform that couples the system with engineered reservoir qubits. The non-orthogonality of qubit eigenstates facilitates non-uniform heating through a modified Kubo-Martin-Schwinger relation, while simultaneously supports amplification-dissipation dynamics by violating microscopic time-reversibility. This offers a new approach to realizing out-of-equilibrium states at given temperatures. We show two applications of this platform: temporally-correlated dichromatic emission and Liouvillian exception point protected quantum synchronization at finite temperatures, both of which are challenging to achieve with conventional thermal reservoirs."}
{"id": "2601.05013", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05013", "abs": "https://arxiv.org/abs/2601.05013", "authors": ["Mohammad Abdullah Sadi", "Tiamike Dudley", "Luca Basso", "Thomas Poirier", "James H. Edgar", "Jacob Henshaw", "Peter A. Bermel", "Yong P. Chen", "Andrew Mounce"], "title": "Landau Zener Interaction Enhanced Quantum Sensing in Spin Defects of Hexagonal Boron Nitride", "comment": null, "summary": "Negatively charged boron vacancies (V$_{\\text{B}}^{-}$) in hexagonal boron nitride (hBN) comprise a promising quantum sensing platform, optically addressable at room temperature and transferrable onto samples. However, broad hyperfine-split spin transitions of the ensemble pose challenges for quantum sensing with conventional resonant excitation due to limited spectral coverage. While isotopically enriched hBN using $^{10}$B and $^{15}$N isotopes (h$^{10}$B$^{15}$N) exhibits sharper spectral features, significant inhomogeneous broadening persists. We demonstrate that, implemented via frequency modulation on an FPGA, a frequency-ramped microwave pulse achieves around 4-fold greater $|0\\rangle\\rightarrow|-1\\rangle$ spin-state population transfer and thus contrast than resonant microwave excitation and thus 16-fold shorter measurement time for spin relaxation based quantum sensing. Quantum dynamics simulations reveal that an effective two-state Landau-Zener model captures the complex relationship between population inversion and pulse length with relaxations incorporated. Our approach is robust and valuable for quantum relaxometry with spin defects in hBN in noisy environments."}
{"id": "2601.05036", "categories": ["quant-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.05036", "abs": "https://arxiv.org/abs/2601.05036", "authors": ["Milan Liepelt", "Julien Baglio"], "title": "Exponential capacity scaling of classical GANs compared to hybrid latent style-based quantum GANs", "comment": "34 pages, 7 figures, 7 tables", "summary": "Quantum generative modeling is a very active area of research in looking for practical advantage in data analysis. Quantum generative adversarial networks (QGANs) are leading candidates for quantum generative modeling and have been applied to diverse areas, from high-energy physics to image generation. The latent style-based QGAN, relying on a classical variational autoencoder to encode the input data into a latent space and then using a style-based QGAN for data generation has been proven to be efficient for image generation or drug design, hinting at the use of far less trainable parameters than their classical counterpart to achieve comparable performance, however this advantage has never been systematically studied. We present in this work the first comprehensive experimental analysis of this advantage of QGANS applied to SAT4 image generation, obtaining an exponential advantage in capacity scaling for a quantum generator in the hybrid latent style-based QGAN architecture. Careful tuning of the autoencoder is crucial to obtain stable, reliable results. Once this tuning is performed and defining training optimality as when the training is stable and the FID score is low and stable as well, the optimal capacity (or number of trainable parameters) of the classical discriminator scales exponentially with respect to the capacity of the quantum generator, and the same is true for the capacity of the classical generator. This hints toward a type of quantum advantage for quantum generative modeling."}
{"id": "2601.05046", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05046", "abs": "https://arxiv.org/abs/2601.05046", "authors": ["Pritam Chattopadhyay", "Jonas F. G. Santos", "Avijit Misra"], "title": "Anomaly to Resource: The Mpemba Effect in Quantum Thermometry", "comment": null, "summary": "Quantum thermometry provides a key capability for nanoscale devices and quantum technologies, but most existing strategies rely on probes initialized near equilibrium. This equilibrium paradigm imposes intrinsic limitations: sensitivity is tied to long-time thermalization and often cannot be improved in fast, noisy, or nonstationary settings. In contrast, the \\textit{Mpemba effect}, the counterintuitive phenomenon where hotter states relax faster than colder ones, has mostly been viewed as a thermodynamic anomaly. Here, we bridge this gap by proving that Mpemba-type inversions generically yield a finite-time enhancement of the quantum Fisher information (QFI) for temperature estimation, thereby converting an anomalous relaxation effect into a concrete metrological resource. Through explicit analyses of two-level and $Λ$-level probes coupled to bosonic baths, we show that nonequilibrium initializations can transiently outperform both equilibrium strategies and colder states, realizing a \\emph{metrological Mpemba effect}. Our results establish anomalous relaxation as a general design principle for nonequilibrium quantum thermometry, enabling ultrafast and nanoscale sensing protocols that exploit, rather than avoid, transient dynamics."}
{"id": "2601.05077", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05077", "abs": "https://arxiv.org/abs/2601.05077", "authors": ["Gumaro Rendon", "Stepan Smid"], "title": "Preconditioned Multivariate Quantum Solution Extraction", "comment": null, "summary": "Numerically solving partial differential equations is a ubiquitous computational task with broad applications in many fields of science. Quantum computers can potentially provide high-degree polynomial speed-ups for solving PDEs, however many algorithms simply end with preparing the quantum state encoding the solution in its amplitudes. Trying to access explicit properties of the solution naively with quantum amplitude estimation can subsequently diminish the potential speed-up. In this work, we present a technique for extracting a smooth positive function encoded in the amplitudes of a quantum state, which achieves the Heisenberg limit scaling. We improve upon previous methods by allowing higher dimensional functions, by significantly reducing the quantum complexity with respect to the number of qubits encoding the function, and by removing the dependency on the minimum of the function using preconditioning. Our technique works by sampling the cumulative distribution of the given function, fitting it with Chebyshev polynomials, and subsequently extracting a representation of the whole encoded function. Finally, we trial our method by carrying out small scale numerical simulations."}
{"id": "2601.05113", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05113", "abs": "https://arxiv.org/abs/2601.05113", "authors": ["Luis Colmenarez", "Remmy Zen", "Jan Olle", "Florian Marquardt", "Markus Müller"], "title": "Unitary fault-tolerant encoding of Pauli states in surface codes", "comment": null, "summary": "In fault-tolerant quantum computation, the preparation of logical states is a ubiquitous subroutine, yet significant challenges persist even for the simplest states required. In the present work, we present a unitary, scalable, distance-preserving encoding scheme for preparing Pauli eigenstates in surface codes. Unlike previous unitary approaches whose fault-distance remains constant with increasing code distance, our scheme ensures that the protection offered by the code is preserved during state preparation. Building on strategies discovered by reinforcement learning for the surface-17 code, we generalize the construction to arbitrary code distances and both rotated and unrotated surface codes. The proposed encoding relies only on geometrically local gates, and is therefore fully compatible with planar 2D qubit connectivity, and it achieves circuit depth scaling as $\\mathcal{O}(d)$, consistent with fundamental entanglement-generation bounds. We design explicit stabilizer-expanding circuits with and without ancilla-mediated connectivity and analyze their error-propagation behavior. Numerical simulations under depolarizing noise show that our unitary encoding without ancillas outperforms standard stabilizer-measurement-based schemes, reducing logical error rates by up to an order of magnitude. These results make the scheme particularly relevant for platforms such as trapped ions and neutral atoms, where measurements are costly relative to gates and idling noise is considerably weaker than gate noise. Our work bridges the gap between measurement-based and unitary encodings of surface-code states and opens new directions for distance-preserving state preparation in fault-tolerant quantum computation."}
{"id": "2601.05118", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.05118", "abs": "https://arxiv.org/abs/2601.05118", "authors": ["Ming Li", "Weizhou Cai", "Ziyue Hua", "Yifang Xu", "Yilong Zhou", "Zi-Jie Chen", "Xu-Bo Zou", "Guang-Can Guo", "Luyan Sun", "Chang-Ling Zou"], "title": "Scalable Generation of Macroscopic Fock States Exceeding 10,000 Photons", "comment": "6 pages, 3 figures", "summary": "The scalable preparation of bosonic quantum states with macroscopic excitations poses a fundamental challenge in quantum technologies, limited by control complexity and photon-loss rates that severely constrain prior theoretical and experimental efforts to merely dozens of excitations per mode. Here, based on the duality of the quantum state evolution in Fock state space and the optical wave-function propagation in a waveguide array, we introduce a Kerr-engineered multi-lens protocol in a single bosonic mode to deterministically generate Fock states exceeding $10,000$ photons. By optimizing phase and displacement operations across lens groups, our approach compensates for non-paraxial aberrations, achieving fidelities above $73\\%$ in numerical simulations for photon numbers up to $N=100,000$. Counterintuitively, the protocol's execution time scales as $N^{-1/2}$ with the target photon number $N$, exhibiting robustness against the photon loss. Our framework enables exploration of quantum-to-classical transitions of giant Fock states, paving the way for advanced quantum metrology with significant quantum gains, and error-corrected quantum information processing in high-dimensional Hilbert spaces."}
{"id": "2601.05131", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05131", "abs": "https://arxiv.org/abs/2601.05131", "authors": ["Janek Denzler", "Jose Carrasco", "Jens Eisert", "Tommaso Guaita"], "title": "Simulation of noisy quantum circuits using frame representations", "comment": "17 pages, 5 figures", "summary": "One of the core research questions in the theory of quantum computing is to find out to what precise extent the classical simulation of a noisy quantum circuits is possible and where potential quantum advantages can set in. In this work, we introduce a unified framework for the classical simulation of quantum circuits based on frame theory, encompassing and generalizing a broad class of existing simulation strategies. Within this framework, the computational cost of a simulation algorithm is determined by the one-norm of an associated quasi-probability distribution, providing a common quantitative measure across different simulation approaches. This enables a comprehensive perspective on common methods for the simulation of noisy circuits based on different quantum resources, such as entanglement or non-stabilizerness. It further provides a clear scheme for generating novel classical simulation algorithms. Indeed, by exploring different choices of frames within this formalism and resorting to tools of convex optimization, we are able not only to obtain new insights and improved bounds for existing methods -- such as stabilizer state simulation or Pauli back-propagation -- but also to discover a new approach with an improved performance based on a generalization of the Pauli frame. We, thereby, show that classical simulation techniques can directly benefit from a perspective -- that of frames -- that goes beyond the traditional classification of quantum resources."}
{"id": "2601.05158", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05158", "abs": "https://arxiv.org/abs/2601.05158", "authors": ["Matilde Baroni", "Dominik Leichtle", "Ivan Šupić", "Damian Markham", "Marco Túlio Quintino"], "title": "Composable simultaneous purification: when all communication scenarios reduce to spatial correlations", "comment": "10 pages, 3 figures", "summary": "Bell non-locality is a powerful framework to distinguish classical, quantum and post-quantum resources, which relies on non-communicating players. Under which restriction can we have the same separations, if we allow for communication? Non-signalling state assemblages, and the fact that they can always be simultaneously purified, turned out to be the key element to restrict the simplest bipartite communication scenario, the prepare-and-measure, to the standard bipartite Bell scenario. Yet, many distinctive features of quantum theory are genuinely multipartite and cannot be reduced to two-party behaviour. In this work we are interested in extending this simultaneous purification inspired result to all multipartite communication schemes. As a first step, we unify and extend the simultaneous purification result from states to instruments and super-instruments, which are composable structures, and open up the possibility to explore more complex communication scenarios. Our main contribution is to establish that arbitrary compositions of non-signalling assemblages cannot escape the standard spatial quantum Bell correlations set. As a consequence, any interactive quantum realization of correlations outside of this set must involve at least one signalling assemblage of quantum operations, even when the resulting correlations are non-signalling."}
{"id": "2601.05161", "categories": ["quant-ph", "cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.05161", "abs": "https://arxiv.org/abs/2601.05161", "authors": ["Ioannis Kolotouros", "Adithya Sireesh", "Stuart Ferguson", "Sean Thrasher", "Petros Wallden", "Julien Michel"], "title": "Quantum Elastic Network Models and their Application to Graphene", "comment": "42 pages, 11 figures", "summary": "Molecular dynamics simulations are a central computational methodology in materials design for relating atomic composition to mechanical properties. However, simulating materials with atomic-level resolution on a macroscopic scale is infeasible on current classical hardware, even when using the simplest elastic network models (ENMs) that represent molecular vibrations as a network of coupled oscillators. To address this issue, we introduce Quantum Elastic Network Models (QENMs) and utilize the quantum algorithm of Babbush et al. (PRX, 2023), which offers an exponential advantage when simulating systems of coupled oscillators under some specific conditions and assumptions. Here, we demonstrate how our method enables the efficient simulation of planar materials. As an example, we apply our algorithm to the task of simulating a 2D graphene sheet. We analyze the exact complexity for initial-state preparation, Hamiltonian simulation, and measurement of this material, and provide two real-world applications: heat transfer and the out-of-plane rippling effect. We estimate that an atomistic simulation of a graphene sheet on the centimeter scale, classically requiring hundreds of petabytes of memory and prohibitive runtimes, could be encoded and simulated with as few as $\\sim 160$ logical qubits."}
{"id": "2601.05226", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05226", "abs": "https://arxiv.org/abs/2601.05226", "authors": ["Giorgio Facelli", "Hamza Fawzi", "Omar Fawzi"], "title": "Fast convergence of Majorana Propagation for weakly interacting fermions", "comment": "22 pages, 2 figures", "summary": "Simulating the time dynamics of an observable under Hamiltonian evolution is one of the most promising candidates for quantum advantage as we do not expect efficient classical algorithms for this problem except in restricted settings. Here, we introduce such a setting by showing that Majorana Propagation, a simple algorithm combining Trotter steps and truncations, efficiently finds a low-degree approximation of the time-evolved observable as soon as such an approximation exists. This provides the first provable guarantee about Majorana Propagation for Hamiltonian evolution. As an application of this result, we prove that Majorana Propagation can efficiently simulate the time dynamics of any sparse quartic Hamiltonian up to time $t_{\\text{max}}(u)$ depending on the interaction strength $u$. For a time horizon $t \\leq t_{\\text{max}}(u)$, the runtime of the algorithm is $N^{O(\\log(t/\\varepsilon))}$ where $N$ is the number of Majorana modes and $\\varepsilon$ is the error measured in the normalized Frobenius norm. Importantly, in the limit of small $u$, $t_{\\text{max}}(u)$ goes to $+\\infty$, formalizing the intuition that the algorithm is accurate at all times when the Hamiltonian is quadratic."}
{"id": "2601.05231", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05231", "abs": "https://arxiv.org/abs/2601.05231", "authors": ["Hui-Hang Chen", "Chiao-Hsuan Wang"], "title": "Scalable Suppression of XY Crosstalk by Pulse-Level Control in Superconducting Quantum Processors", "comment": "19 pages, 19 figures", "summary": "As superconducting quantum processors continue to scale, high-performance quantum control becomes increasingly critical. In densely integrated architectures, unwanted interactions between nearby qubits give rise to crosstalk errors that limit operational performance. In particular, direct exchange-type (XY) interactions are typically minimized by designing large frequency detunings between neighboring qubits at the hardware level. However, frequency crowding in large-scale systems ultimately restricts the achievable frequency separation. While such XY coupling facilitates entangling gate operations, its residual presence poses a key challenge during single-qubit controls. Here, we propose a scalable pulse-level control framework, incorporating frequency modulation (FM) and dynamical decoupling (DD), to suppress XY crosstalk errors. This framework operates independently of coupling strengths, reducing calibration overhead and naturally supporting multi-qubit connectivity. Numerical simulations show orders-of-magnitude reductions in infidelity for both idle and single-qubit gates in a two-qubit system. We further validate scalability in a five-qubit layout, where crosstalk between a central qubit and four neighbors is simultaneously suppressed. Our crosstalk suppression framework provides a practical route toward high-fidelity operation in dense superconducting architectures."}
{"id": "2601.05177", "categories": ["cond-mat.dis-nn", "cond-mat.quant-gas", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05177", "abs": "https://arxiv.org/abs/2601.05177", "authors": ["Asmi Haldar", "Thibault Scoquart", "Fabien Alet", "Nicolas Laflorencie"], "title": "Beyond the imbalance: site-resolved dynamics probing resonances in many-body localization", "comment": "(13 + 9) pages and (8 + 2) figures", "summary": "We explore the limitations of using imbalance dynamics as a diagnostic tool for many-body localization (MBL) and show that spatial averaging can mask important microscopic features. Focusing on the strongly disordered regime of the random-field XXZ chain, we use state-of-the-art numerical techniques (Krylov time evolution and full diagonalization) to demonstrate that site-resolved spin autocorrelators reveal a rich and complex dynamical behavior that is obscured by the imbalance observable. By analyzing the time evolution and infinite-time limits of these local probes, we reveal resonant structures and rare local instabilities within the MBL phase. These numerical findings are supported by an analytical, few-site toy model that captures the emergence of a multiple-peak structure in local magnetization histograms, which is a hallmark of local resonances. These few-body local effects provide a more detailed understanding of ergodicity-breaking dynamics, and also allow us to explain the finite-size effects of long-time imbalance, and its sensitivity to the initial conditions in quench protocols. Overall, our experimentally testable predictions highlight the necessity of a refined, site-resolved approach to fully understand the complexities of MBL and its connection to rare-region effects."}
{"id": "2601.05196", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.05196", "abs": "https://arxiv.org/abs/2601.05196", "authors": ["Min Long", "Zeno Bacciconi", "Hongyu Lu", "Hernan B. Xavier", "Zi Yang Meng", "Marcello Dalmonte"], "title": "Chiral Graviton Modes in Fermionic Fractional Chern Insulators", "comment": "24 pages,22 figures", "summary": "Chiral graviton modes are hallmark collective excitations of Fractional Quantum Hall (FQH) liquids. However, their existence on the lattice, where continuum symmetries that protect them from decay are lost, is still an open and urgent question, especially considering the recent advances in the realization of Fractional Chern Insulators (FCI) in transition metal dichalcogenides and rhombohedral pentalayer graphene. Here we present a comprehensive theoretical and numerical study of graviton-modes in fermionic FCI, and thoroughly demonstrate their existence. We first derive a lattice stress tensor operator in the context of the fermionic Harper-Hofstadter(HH) model which captures the graviton in the flat band limit. Importantly, we discover that such lattice stress-tensor operators are deeply connected to lattice quadrupolar density correlators, readily generalizable to generic Chern bands. We then explicitly show the adiabatic connection between FQH and FCI chiral graviton modes by interpolating from a low flux HH model to a Checkerboard lattice model that hosts a topological flat band. In particular, using state-of-the-art matrix product state and exact diagonalization simulations, we provide strong evidence that chiral graviton modes are long-lived excitations in FCIs despite the lack of continuous symmetries and the scattering with a two-magnetoroton continuum. By means of a careful finite-size analysis, we show that the lattice generates a finite but small intrinsic decay rate for the graviton mode. We discuss the relevance of our results for the exploration of graviton modes in FCI phases realized in solid state settings, as well as cold atom experiments."}
