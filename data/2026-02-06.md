<div id=toc></div>

# Table of Contents

- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 3]
- [cs.SI](#cs.SI) [Total: 1]
- [stat.ME](#stat.ME) [Total: 13]
- [nlin.CD](#nlin.CD) [Total: 1]
- [math.NA](#math.NA) [Total: 9]
- [math.OC](#math.OC) [Total: 23]
- [physics.ao-ph](#physics.ao-ph) [Total: 2]
- [eess.SY](#eess.SY) [Total: 10]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [cs.CE](#cs.CE) [Total: 3]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 11]
- [physics.soc-ph](#physics.soc-ph) [Total: 2]
- [cs.ET](#cs.ET) [Total: 2]
- [quant-ph](#quant-ph) [Total: 48]
- [hep-lat](#hep-lat) [Total: 1]
- [math.ST](#math.ST) [Total: 5]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 5]


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [1] [Heterogeneity dominates irreversibility in random Markov models](https://arxiv.org/abs/2602.04905)
*Faheem Mosam,Eric De Giuli*

Main category: cond-mat.dis-nn

TL;DR: 提出了一种双参数随机离散时间马尔可夫模型，统一描述临界减缓和破坏细致平衡现象，并应用于人脑fMRI和EEG数据，发现其运行接近预测的临界线，表现出超越随机模型的个体特异性结构。


<details>
  <summary>Details</summary>
Motivation: 旨在构建一个能同时捕捉临界减缓和非平衡特性（如破坏细致平衡）的统一框架，以更好地理解复杂生物系统（如人脑）的动力学行为。

Method: 基于随机矩阵理论，扩展了异质性马尔可夫系综，引入不对称参数γ和异质性参数ε，分析熵产生、预测信息和弛豫动力学等可观测量；并通过最大似然推断应用于人类fMRI和EEG数据。

Result: 识别出松弛时间发散且谱普适性破裂的临界线ε_c(γ,N)；发现多数观测量强烈依赖于异质性而非不对称性（除对称极限附近）；实证数据显示人脑活动接近该临界线，且在ε-γ平面上具有相似分布，但表现出比系综平均更强的变异性。

Conclusion: 该模型成功统一了临界性和非平衡态特征，揭示了二者在复杂生物动力学中的交织作用，并支持人脑动力学存在超普适性的观点，同时提示个体间存在超出随机预期的结构特征。

Abstract: We introduce a two-parameter ensemble of random discrete-time Markov models that simultaneously captures critical slowing down and broken detailed balance. Extending a previously studied heterogeneous Markov ensemble, we incorporate correlations between forward and backward transition rates through a single asymmetry parameter $γ$, while heterogeneity is controlled by $ε$. Using results from random matrix theory, we identify a critical locus $ε_c(γ,N)$ at which relaxation times diverge and spectral universality breaks down. We characterize the behavior of entropy production, predictive information, and relaxation dynamics across the ensemble, showing that many observables depend strongly on heterogeneity but only weakly on asymmetry, except near the symmetric limit. Applying maximum-likelihood inference to human fMRI and EEG data, we find that both modalities operate near the predicted critical locus and occupy a similar region of the $ε-γ$ plane, supporting a super-universality of human brain dynamics. While ensemble averages are well captured by the null model, empirical data exhibit substantially enhanced variability, indicating subject-specific structure beyond random expectations. Our results unify criticality and nonequilibrium measures within a single framework and clarify their intertwined role in the analysis of complex biological dynamics.

</details>


### [2] [Beyond overcomplication: a linear model suffices to decode hidden structure-property relationships in glasses](https://arxiv.org/abs/2602.05313)
*Chenyan Wang,Mouyang Cheng,Ji Chen*

Main category: cond-mat.dis-nn

TL;DR: 本文基于一阶微扰理论，提出了一种普适的线性关系，将玻璃材料的结构特征与无序诱导的性质响应联系起来，并通过线性机器学习模型实现了高精度预测，同时利用正则化分析增强了模型的物理可解释性。


<details>
  <summary>Details</summary>
Motivation: 建立可靠且可解释的玻璃材料结构-性能关系是凝聚态物理中的长期挑战，现有机器学习模型常因缺乏物理可解释性和任务特异性而受限。

Method: 基于一阶微扰理论推导出结构分布与无序响应之间的近似线性关系，并采用线性机器学习模型进行数值验证，结合正则化分析提升模型可解释性。

Result: 该线性关系在不同维度和相互作用类型的玻璃系统中具有普适性，线性模型在多种玻璃材料中均实现了高预测精度。

Conclusion: 该工作建立了结构无序与玻璃谱性质之间的简洁而强大的联系，为玻璃材料的研究提供了新途径。

Abstract: Establishing reliable and interpretable structure-property relationships in glasses is a longstanding challenge in condensed matter physics. While modern data-driven machine learning techniques have proven highly effective in establishing structure-property correlations, many models are criticized for lacking physical interpretability and being task-specific. In this work, we identify an approximate linear relation between structure profiles and disorder-induced responses of glass properties based on first order perturbation theory. We analytically demonstrate that this relationship holds universally across glassy systems with varying dimensions and distinct interaction types. This robust theoretical relationship motivates the adoption of linear machine learning models, which we show numerically to achieve surprisingly high predictive accuracy for structure-property mapping in a wide variety of glassy materials. We further devise regularization analysis to further enhance the interpretability of our model, bridging the gap between predictive performance and physical insight. Overall, this linear relation establishes a simple yet powerful connection between structural disorder and spectral properties in glasses, opening a new avenue for advancing their studies.

</details>


### [3] [The weak and strong disorder regimes in the continuous random field Ising model](https://arxiv.org/abs/2602.05839)
*G. O. Heymans,N. F. Svaiter,B. F. Svaiter,A. M. S. Macêdo*

Main category: cond-mat.dis-nn

TL;DR: 本文利用分布zeta函数方法对连续随机场伊辛模型的弱无序和强无序区域进行了非微扰分析，揭示了不同无序强度下相关函数的行为特征。


<details>
  <summary>Details</summary>
Motivation: 研究随机场伊辛模型在不同无序强度下的临界行为，特别是红外结构和标度性质。

Method: 采用分布zeta函数方法，在有效作用量层面进行淬火无序平均，推导出精确的二次项和相互作用项。

Result: 在弱无序极限下，发现两点关联函数具有1/p^4行为，使上临界维度变为6；在强无序区域，得到具有离散质量模式谱的精确对角二次作用量，且无质量less模式，表明缺乏传统临界性。

Conclusion: 该方法揭示了随机场伊辛模型在弱无序和强无序区域的不同物理机制，为理解无序系统中的相变提供了新的视角。

Abstract: We present a nonperturbative analysis of the weak- and strong-disorder regimes of the continuous random-field Ising model using the distributional zeta-function method. By performing the quenched-disorder average at the level of the effective action, we derive exact quadratic and interaction terms. In the weak-disorder limit, we show that the infrared structure of the two-point correlation functions yields a decomposition of the physical field into correlated components with distinct scaling dimensions. This mechanism exhibits the characteristic $1/p^4$ behavior, which shifts the upper critical dimension to $d_c^{+}=6$. The universal critical behavior of the RFIM near this dimension is governed by a minimal infrared effective action. In the strong-disorder regime, we obtain an exact diagonal quadratic action with a discrete spectrum of massive modes. Here, the absence of massless modes implies the absence of conventional criticality. The resulting spectral representation of correlation functions converges rapidly and remains well controlled in the infrared regime.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [4] [Supply vs. Demand in Community-Based Fact-Checking on Social Media](https://arxiv.org/abs/2602.06005)
*Moritz Pilarski,Nicolas Pröllochs*

Main category: cs.SI

TL;DR: 研究分析了X平台Community Notes在2024年6月至2025年5月间的110万条事实核查请求与核查记录，发现用户更关注高曝光度内容，而实际核查覆盖更广；请求能显著加快“顶级撰稿人”的响应速度，揭示供需错配及用户请求对贡献行为的引导作用。


<details>
  <summary>Details</summary>
Motivation: 探讨社交媒体事实核查生态系统中用户需求与贡献供给之间的匹配程度，填补先前研究将二者孤立分析的空白。

Method: 基于X平台Community Notes的真实数据集（2024年6月–2025年5月，共110万条记录），采用描述性统计分析需求与供给的分布特征，并通过准实验生存分析评估展示请求对后续注释创建的影响。

Result: 用户请求集中于高浏览量、高互动和影响力账户发布的内容，而实际事实核查在语言、情感和主题上分布更广泛；展示请求显著加速了Top Writers的事实核查贡献。

Conclusion: 事实核查的需求与供给存在结构性错配，但用户请求能够引导贡献者行为，促进供需对齐，该发现对平台治理和在线虚假信息研究具有重要意义。

Abstract: Fact-checking ecosystems on social media depend on the interplay between what users want checked and what contributors are willing to supply. Prior research has largely examined these forces in isolation, yet it remains unclear to what extent supply meets demand. We address this gap with an empirical analysis of a unique dataset of 1.1 million fact-checks and fact-checking requests from X's Community Notes platform between June 2024 and May 2025. We find that requests disproportionately target highly visible posts - those with more views and engagement and authored by influential accounts - whereas fact-checks are distributed more broadly across languages, sentiments, and topics. Using a quasi-experimental survival analysis, we further estimate the effect of displaying requests on subsequent note creation. Results show that requests significantly accelerate contributions from Top Writers. Altogether, our findings highlight a gap between the content that attracts requests for fact-checking and the content that ultimately receives fact-checks, while showing that user requests can steer contributors toward greater alignment. These insights carry important implications for platform governance and future research on online misinformation.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [5] [Penalized Likelihood Parameter Estimation for Differential Equation Models: A Computational Tutorial](https://arxiv.org/abs/2602.04891)
*Matthew J Simpson,James S Bennett,Alexander Johnston,Ruth E Baker*

Main category: stat.ME

TL;DR: 本文介绍了广义轮廓法（generalized profiling）在常微分方程模型参数估计中的应用，通过自指导的计算练习帮助读者掌握该方法，并提供开源Jupyter笔记本以实现可重复计算。


<details>
  <summary>Details</summary>
Motivation: 由于传统参数估计方法依赖反复求解模型，计算成本高，而广义轮廓法直接基于微分方程，兼顾数据拟合与模型拟合，具有优势但应用较少，因此需要推广其使用。

Method: 采用教程式教学设计，通过一系列自导向的计算练习，结合惩罚似然函数，直接连接数据与微分方程模型，实现参数估计。

Result: 开发了一套可在GitHub获取的可重复使用的开源Jupyter笔记本，使学习者能够实践并掌握广义轮廓法在不同常微分方程模型中的应用。

Conclusion: 广义轮廓法是一种高效且有潜力的参数估计方法，通过本教程提供的工具和练习，有助于推动其在实际研究中的广泛应用。

Abstract: Parameter estimation connects mathematical models to real-world data and decision making across many scientific and industrial applications. Standard approaches such as maximum likelihood estimation and Markov chain Monte Carlo estimate parameters by repeatedly solving the model, which often requires numerical solutions of differential equation models. In contrast, generalized profiling (also called parameter cascading) focuses directly on the governing differential equation(s), linking the model and data through a penalized likelihood that explicitly measures both the data fit and model fit. Despite several advantages, generalized profiling is relatively rarely used in practice. This tutorial-style article outlines a set of self-directed computational exercises that facilitate skills development in applying generalized profiling to a range of ordinary differential equation models. All calculations can be repeated using reproducible open-source Jupyter notebooks that are available on GitHub.

</details>


### [6] [Double Variable Importance Matching to Estimate Distinct Causal Effects on Event Probability and Timing](https://arxiv.org/abs/2602.05022)
*Yuqi Li,Quinn Lanners,Matthew M. Engelhard*

Main category: stat.ME

TL;DR: 提出一种基于匹配的框架，用于在存在治愈亚群体的时间-事件数据中估计治疗对治愈概率和事件时间的异质性效应。


<details>
  <summary>Details</summary>
Motivation: 标准生存分析和因果推断方法通常未区分治愈与非治愈个体，导致无法清晰识别治疗对治愈概率和事件发生时间的不同影响机制。

Method: 采用混合治愈模型识别关键特征，并据此构建加权距离度量进行高维空间匹配；在匹配组内使用Kaplan-Meier估计器分别估计治愈概率和事件时间，进而推导个体层面的治疗效应。

Result: 该方法能够有效分离治疗对治愈概率和非治愈者事件时间的影响，在模拟和真实数据中表现出良好的可解释性和鲁棒性。

Conclusion: 所提匹配框架结合混合治愈模型，能更准确地估计具有潜在治愈亚群的复杂临床场景中的异质性治疗效应。

Abstract: In many clinical contexts, estimating effects of treatment in time-to-event data is complicated not only by confounding, censoring, and heterogeneity, but also by the presence of a cured subpopulation in which the event of interest never occurs. In such settings, treatment may have distinct effects on (1) the probability of being cured and (2) the event timing among non-cured individuals. Standard survival analysis and causal inference methods typically do not separate cured from non-cured individuals, obscuring distinct treatment mechanisms on cure probability and event timing. To address these challenges, we propose a matching-based framework that constructs distinct match groups to estimate heterogeneous treatment effects (HTE) on cure probability and event timing, respectively. We use mixture cure models to identify feature importance for both estimands, which in turn informs weighted distance metrics for matching in high-dimensional spaces. Within matched groups, Kaplan-Meier estimators provide estimates of cure probability and expected time to event, from which individual-level treatment effects are derived. We provide theoretical guarantees for estimator consistency and distance metric optimality under an equal-scale constraint. We further decompose estimation error into contributions from censoring, model fitting, and irreducible noise. Simulations and real-world data analyses demonstrate that our approach delivers interpretable and robust HTE estimates in time-to-event settings.

</details>


### [7] [A Flexible Modeling of Extremes in the Presence of Inliers](https://arxiv.org/abs/2602.05351)
*Shivshankar Nila,Ishapathik Das,N. Balakrishna*

Main category: stat.ME

TL;DR: 本文提出了一种灵活的极值混合模型，用于处理包含极端值、零内点（inliers at zero）及尾部比例估计问题的数据，通过最大似然法进行参数估计，并在模拟研究和实际数据分析中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 许多随机现象（如寿命测试和环境数据）具有正值和过多零值的特点，标准模型难以有效处理零内点，且现有极值混合模型在阈值选择和尾部比例建模方面存在不足，影响参数估计和极端事件预测的准确性。

Method: 提出一种新的灵活极值混合模型，能够同时处理极端值、零内点以及尾部比例；采用最大似然估计法进行参数估计，并与经典的均值超量图、参数稳定性图和Pickands图等方法进行比较。

Result: 理论结果表明该模型具有一致性，在模拟研究和真实数据应用中表现出更优的性能，能更准确地识别阈值并改善尾部推断。

Conclusion: 所提出的模型为包含零内点和极端值的数据提供了一个统一且有效的分析框架，显著提升了极值分析的准确性和可靠性。

Abstract: Many random phenomena, including life-testing and environmental data, show positive values and excess zeros, which pose modeling challenges. In life testing, immediate failures result in zero lifetimes, often due to defects or poor quality, especially in electronics and clinical trials. These failures, called inliers at zero, are difficult to model using standard approaches. The presence and proportion of inliers may influence the accuracy of extreme value analysis, bias parameter estimates, or even lead to severe events or extreme effects, such as drought or crop failure. In such scenarios, a key issue in extreme value analysis is determining a suitable threshold to capture tail behaviour accurately. Although some extreme value mixture models address threshold and tail estimation, they often inadequately handle inliers, resulting in suboptimal results. Bulk model misspecification can affect the threshold, extreme value estimates, and, in particular, the tail proportion. There is no unified framework for defining extreme value mixture models, especially the tail proportion. This paper proposes a flexible model that handles extremes, inliers, and the tail proportion. Parameters are estimated using maximum likelihood estimation. Compared the proposed model estimates with the classical mean excess plot, parameter stability plot, and Pickands plot estimates. Theoretical results are established, and the proposed model outperforms traditional methods in both simulation studies and real data analysis.

</details>


### [8] [Billions-Scale Forecast Reconciliation](https://arxiv.org/abs/2602.05030)
*Tianyu,Wang,Matthew C. Johnson,Steven Klee,Matthew L. Malloy*

Main category: stat.ME

TL;DR: 本文研究了大规模分层预测协调问题，提出并评估了多种优化算法，在超过四十亿预测值的维度上展示了有效性，并证明了加权最小二乘法与基于份额的预测协调在特定条件下的等价性。


<details>
  <summary>Details</summary>
Motivation: 解决大型零售商面临的海量相关预测量之间的协调问题，提升预测准确性与一致性。

Method: 采用基于优化的方法，实现并比较了多种求解分层预测协调的算法，使用大规模数据进行验证。

Result: 成功解决了超过四十亿预测值的协调问题，是目前已知最大规模的约束最小二乘问题之一；并在理论上证明了加权最小二乘与份额法在特定条件下的等价性。

Conclusion: 优化方法不仅适用于超大规模预测协调，还可作为份额法的推广形式，适用于多个重叠的数据层次结构。

Abstract: The problem of combining multiple forecasts of related quantities that obey expected equality and additivity constraints, often referred to a hierarchical forecast reconciliation, is naturally stated as a simple optimization problem. In this paper we explore optimization-based point forecast reconciliation at scales faced by large retailers. We implement and benchmark several algorithms to solve the forecast reconciliation problem, showing efficacy when the dimension of the problem exceeds four billion forecasted values. To the best of our knowledge, this is the largest forecast reconciliation problem, and perhaps on-par with the largest constrained least-squares-problem ever solved. We also make several theoretical contributions. We show that for a restricted class of problems and when the loss function is weighted appropriately, least-squares forecast reconciliation is equivalent to share-based forecast reconciliation. This formalizes how the optimization based approach can be thought of as a generalization of share-based reconciliation, applicable to multiple, overlapping data hierarchies.

</details>


### [9] [A Weighting Framework for Clusters as Confounders in Observational Studies](https://arxiv.org/abs/2602.05041)
*Eli Ben-Michael,Avi Feller,Luke Keele*

Main category: stat.ME

TL;DR: 本文提出了一种统一的加权框架，用于在聚类观察性研究中同时控制全局和局部协变量不平衡，并提出了两种新方法：分层平衡权重和Mundlak平衡权重，分别适用于不同假设条件下的因果推断。


<details>
  <summary>Details</summary>
Motivation: 在聚类观察性研究中，传统的逆概率加权方法仅控制跨集群的整体不平衡，而忽略了集群内部的局部不平衡，因此需要更全面的平衡方法以提高因果效应估计的准确性。

Method: 提出统一的加权框架，分析IPW、分层平衡权重和Mundlak平衡权重三种方法；其中分层平衡权重通过约束优化同时控制全局与局部平衡，Mundlak方法则利用集群层面的充分统计量进行调整，并适用于全处理或无处理的小集群。

Result: 研究表明，传统随机效应IPW仅保证全局平衡，而新提出的两种方法能有效实现全局与局部双重平衡；模拟和实证显示其在不同聚类结构下具有更优的性能。

Conclusion: 为聚类观察性研究中的混杂控制提供了更灵活和稳健的方法选择，强调应根据数据结构和建模假设选用适当的加权策略以提升因果推断的可靠性。

Abstract: When units in observational studies are clustered in groups, such as students in schools or patients in hospitals, researchers often address confounding by adjusting for cluster-level covariates or cluster membership. In this paper, we develop a unified weighting framework that clarifies how different estimation methods control two distinct sources of imbalance: global balance (differences between treated and control units across clusters) and local balance (differences within clusters). We show that inverse propensity score weighting (IPW) with a random effects propensity score model -- the current standard in the literature -- targets only global balance and constant level shifts across clusters, but imposes no constraints on local balance. We then present two approaches that target both forms of balance. First, hierarchical balancing weights directly control global and local balance through a constrained optimization problem. Second, building on the recently proposed Generalized Mundlak approach, we develop a novel Mundlak balancing weights estimator that adjusts for cluster-level sufficient statistics rather than cluster indicators; this approach can accommodate small clusters where all units are treated or untreated. Critically, these approaches rest on different assumptions: hierarchical balancing weights require only that treatment is ignorable given covariates and cluster membership, while Mundlak methods additionally require an exponential family structure. We then compare these methods in a simulation study and in two applications in education and health services research that exhibit very different cluster structures.

</details>


### [10] [Impact Range Assessment (IRA): An Interpretable Sensitivity Measure for Regression Modelling](https://arxiv.org/abs/2602.05239)
*Jihao You,Dan Tulpan,Jiaojiao Diao,Jennifer L. Ellis*

Main category: stat.ME

TL;DR: 本文提出了一种名为影响范围评估（IRA）的可解释性方法，用于量化每个预测变量对响应变量的最大影响，验证表明该方法能有效区分相关与无关变量，并具有良好的稳健性和直观性。


<details>
  <summary>Details</summary>
Motivation: 现有的回归模型缺乏直观理解预测变量对结果影响的方法，因此需要一种更易解释的技术来提升模型透明度。

Method: 提出影响范围评估（IRA），通过测量在预测变量取值范围内响应变量的总潜在变化来量化各预测变量的最大影响，并在合成数据和实际案例中进行验证。

Result: 在合成的线性和非线性数据集上，相关变量的IRA值显著高于无关变量；重复实验结果稳定，显示方法具有鲁棒性；在颗粒质量预测案例中，IRA能直观地排序变量重要性。

Conclusion: IRA是一种简单、直观且稳健的模型解释方法，有助于提高回归模型的可解释性、透明度和可靠性。

Abstract: While regression models capture the relationship between predictors and the response variable, they often lack intuitive accompanying methods to understand the influence of predictors on the outcome. To address this, we introduce an interpretability method called Impact Range Assessment (IRA), which quantifies the maximal influence of each predictor by measuring the total potential change in the response variable, across the predictor range. Validation using synthetic linear and nonlinear datasets demonstrates that relevant predictors produced higher IRA values than irrelevant ones. Moreover, repeated evaluations produced results closely aligned with those from the single-execution analysis, confirming the robustness of the method. A case study using a model that predicts pellet quality demonstrated that the IRA provides a simple and intuitive approach to interpret and rank predictor influence, thereby improving model transparency and reliability.

</details>


### [11] [Boxplots and quartile plots for grouped and periodic angular data](https://arxiv.org/abs/2602.05335)
*Joshua D. Berlinski,Fan Dai,Ranjan Maitra*

Main category: stat.ME

TL;DR: 本文提出了一种用于可视化分组圆形数据分布的同心圆箱线图方法，并通过调整箱体宽度以解决视觉感知问题，同时提出了圆形四分位数图和三维环面显示方法，应用于心理学、基因组学和气象学等领域。


<details>
  <summary>Details</summary>
Motivation: 为了更好地描述、分析和可视化来自不同领域的角度数据（即单位圆上的观测值），需要专门的方法来处理这些具有周期性特征的数据。

Method: 提出了同心圆箱线图，将箱体宽度设置为距中心距离平方根的倒数以优化视觉感知；引入圆形四分位数图用于大量分组的情况；并开发了三维环面显示方法用于周期性角度数据。通过感知调查验证箱体宽度设计的有效性。

Result: 所提方法在心理学（运动共鸣）、基因组学（时钟基因峰值相位）和气象学（风向的年度周期变化）的实际数据集中得到了成功应用，有效展示了多组角度数据的分布特征。

Conclusion: 该研究提供了一套有效的圆形数据可视化工具，能够清晰展示分组角度数据的分布，解决了视觉感知问题，适用于多种科学领域中的周期性数据分析。

Abstract: Angular observations, or observations lying on the unit circle, arise in many disciplines and require special care in their description, analysis, interpretation and visualization. We provide methods to construct concentric circular boxplot displays of distributions of groups of angular data. The use of concentric boxplots brings challenges of visual perception, so we set the boxwidths to be inversely proportional to the square root of their distance from the centre. A perception survey supports this scaled boxwidth choice. For a large number of groups, we propose circular quartile plots. A three-dimensional toroidal display is also implemented for periodic angular distributions. We illustrate our methods on datasets in (1) psychology, to display motor resonance under different conditions, (2) genomics, to understand the distribution of peak phases for ancillary clock genes, and (3) meteorology and wind turbine power generation, to study the changing and periodic distribution of wind direction over the course of a year.

</details>


### [12] [The stochastic view used in climate sciences: (some) perspectives from (some of) mathematical statistics](https://arxiv.org/abs/2602.05611)
*Nils Lid Hjort*

Main category: stat.ME

TL;DR: 本文综述了与气候统计相关的若干统计方法主题，包括气象时间序列建模、趋势预测与不确定性评估、气候对海洋生物学的影响、模型稳定性监测、多源信息融合以及极端事件概率分析。


<details>
  <summary>Details</summary>
Motivation: 旨在从统计方法的角度指出对气候统计具有重要意义且共同关注的主题，推动更精确的气候建模与预测。

Method: 从统计学方法出发，探讨时间序列建模、趋势跨越阈值的预测、不确定性度量、模型监控、多源数据整合及极端事件概率分析等技术。

Result: 提出了六个关键方法论主题，有助于提升气候统计中的建模精度、预测能力和不确定性量化水平。

Conclusion: 这些统计方法主题对于改进气候模型、理解气候变化影响以及应对极端天气事件具有重要意义。

Abstract: Climate statistics is of course a very broad field, along with the many connections and impacts for yet other areas, with a history as long as mankind has been recording temperatures, describing drastic weather events, etc. The important work of Klaus Hasselmann, with crucial contributions to the field, along with various other connected strands of work,is being reviewed and discussed in other chapters. The aim of the present chapter is to point to a few statistical methodology themes of relevance for and joint interest with climate statistics. These themes, presented from a statistical methods perspective, include (i) more careful modelling and model selection strategies for meteorological type time series; (ii) methods for prediction, not only for future values of a time series, but for assessing when a trend might be crossing a barrier, along with relevant measures of uncertainty for these; (iii) climatic influence on marine biology; (iv) monitoring processes to assess whether and then to what extent models and their parameters have stayed reasonably constant over time; (v) combination of outputs from different information sources; and (vi) analysing probabilities and their uncertainties related to extreme events.

</details>


### [13] [Copula-based models for spatially dependent cylindrical data](https://arxiv.org/abs/2602.05778)
*Francesca Labanca,Anna Gottard,Nadja Klein*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Cylindrical data frequently arise across various scientific disciplines, including meteorology (e.g., wind direction and speed), oceanography (e.g., marine current direction and speed or wave heights), ecology (e.g., telemetry), and medicine (e.g., seasonality and intensity in disease onset). Such data often occur as spatially correlated series of intensities and angles, thereby representing dependent bivariate response vectors of linear and circular components. To accommodate both the circular-linear dependence and spatial autocorrelation, while remaining flexible in marginal specifications, copula-based models for cylindrical data have been developed in the literature. However, existing approaches typically treat the copula parameters as constants unrelated to covariates, and regression specifications for marginal distributions are frequently restricted to linear predictors, thereby ignoring spatial correlation. In this work, we propose a structured additive conditional copula regression model for cylindrical data. The circular component is modeled using a wrapped Gaussian process, and the linear component follows a distributional regression model. Both components allow for the inclusion of linear covariate effects. Furthermore, by leveraging the empirical equivalence between Gaussian random fields (GRFs) and Gaussian Markov random fields, our approach avoids the computational burden typically associated with GRFs, while simultaneously allowing for non-stationarity in the covariance structure. Posterior estimation is performed via Markov chain Monte Carlo simulation. We evaluate the proposed model in a simulation study and subsequently in an analysis of wind directions and speed in Germany.

</details>


### [14] [Correcting Measurement Error and Zero Inflation in Functional Covariates for Scalar-on-Function Quantile Regression](https://arxiv.org/abs/2602.05784)
*Caihong Qin,Lan Xue,Ufuk Beyaztas,Roger S. Zoh,Mark Benden,Jeff Goldsmith,Carmen D. Tekwe*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Wearable devices collect time-varying biobehavioral data, offering opportunities to investigate how behaviors influence health outcomes. However, these data often contain measurement error and excess zeros (due to nonwear, sedentary behavior, or connectivity issues), each characterized by subject-specific distributions. Current statistical methods fail to address these issues simultaneously. We introduce a novel modeling framework for zero-inflated and error-prone functional data by incorporating a subject-specific time-varying validity indicator that explicitly distinguishes structural zeros from intrinsic values. We iteratively estimate the latent functional covariates and zero-inflation probabilities via maximum likelihood, using basis expansions and linear mixed models to adjust for measurement error. To assess the effects of the recovered latent covariates, we apply joint quantile regression across multiple quantile levels. Through extensive simulations, we demonstrate that our approach significantly improves estimation accuracy over methods that only address measurement error, and joint estimation yields substantial improvements compared with fitting separate quantile regressions. Applied to a childhood obesity study, our approach effectively corrects for zero inflation and measurement error in step counts, yielding results that closely align with energy expenditure and supporting their use as a proxy for physical activity.

</details>


### [15] [Learning False Discovery Rate Control via Model-Based Neural Networks](https://arxiv.org/abs/2602.05798)
*Arnau Vilella,Jasin Machkour,Michael Muma,Daniel P. Palomar*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Controlling the false discovery rate (FDR) in high-dimensional variable selection requires balancing rigorous error control with statistical power. Existing methods with provable guarantees are often overly conservative, creating a persistent gap between the realized false discovery proportion (FDP) and the target FDR level. We introduce a learning-augmented enhancement of the T-Rex Selector framework that narrows this gap. Our approach replaces the analytical FDP estimator with a neural network trained solely on diverse synthetic datasets, enabling a substantially tighter and more accurate approximation of the FDP. This refinement allows the procedure to operate much closer to the desired FDR level, thereby increasing discovery power while maintaining effective approximate control. Through extensive simulations and a challenging synthetic genome-wide association study (GWAS), we demonstrate that our method achieves superior detection of true variables compared to existing approaches.

</details>


### [16] [SpARCD: A Spectral Graph Framework for Revealing Differential Functional Connectivity in fMRI Data](https://arxiv.org/abs/2602.05807)
*Shira Yoffe,Ziv Ben-Zion,Talma Hendler,Malka Gorfine,Ariel Jaffe*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Identifying brain regions that exhibit altered functional connectivity across cognitive or emotional states is a key problem in neuroscience. Existing methods, such as edge-wise testing, seed-based psychophysiological interaction (PPI) analysis, or correlation network comparison, typically suffer from low statistical power, arbitrary thresholding, and limited ability to capture distributed or nonlinear dependence patterns. We propose SpARCD (Spectral Analysis of Revealing Connectivity Differences), a novel statistical framework for detecting differences in brain connectivity between two experimental conditions. SpARCD leverages distance correlation, a dependence measure sensitive to both linear and nonlinear associations, to construct a weighted graph for each condition. It then constructs a differential operator via spectral filtering and uncovers connectivity changes by computing its leading eigenvectors. Inference is achieved via a permutation-based testing scheme that yields interpretable, region-level significance maps. Extensive simulation studies demonstrate that SpARCD achieves superior power relative to conventional edge-wise or univariate approaches, particularly in the presence of complex dependency structures. Application to fMRI data from 113 early PTSD patients performing an emotional face-matching task reveals distinct networks associated with emotional reactivity and regulatory processes. Overall, SpARCD provides a statistically rigorous and computationally efficient framework for comparing high-dimensional connectivity structures, with broad applicability to neuroimaging and other network-based scientific domains.

</details>


### [17] [A Bayesian approach to differential prevalence analysis with applications in microbiome studies](https://arxiv.org/abs/2602.05938)
*Juho Pelto,Kari Auranen,Janne V. Kujala,Leo Lahti*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Recent evidence suggests that analyzing the presence/absence of taxonomic features can offer a compelling alternative to differential abundance analysis in microbiome studies. However, standard approaches face challenges with boundary cases and multiple testing. To address these challenges, we developed DiPPER (Differential Prevalence via Probabilistic Estimation in R), a method based on Bayesian hierarchical modeling. We benchmarked our method against existing differential prevalence and abundance methods using data from 67 publicly available human gut microbiome studies. We observed considerable variation in performance across methods, with DiPPER outperforming alternatives by combining high sensitivity with effective error control. DiPPER also demonstrated superior replication of findings across independent studies. Furthermore, DiPPER provides differential prevalence estimates and uncertainty intervals that are inherently adjusted for multiple testing.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [18] [Active Soft-Impact Oscillator: Dynamics of a Walking Droplet in a Non-Smooth Potential](https://arxiv.org/abs/2602.05913)
*Titir Mukherjee,Rahil N Valani,Soumitro Banerjee*

Main category: nlin.CD

TL;DR: 提出了一种主动软碰撞振子模型，用于描述在分段光滑势场中运动的行走液滴，揭示了多种非线性行为和分岔现象。


<details>
  <summary>Details</summary>
Motivation: 为行走液滴在非光滑外势中的运动建立最小理论模型，以研究其类量子行为和非线性动力学特性。

Method: 将非光滑软碰撞力与波-粒耦合的Lorenz类动力学相结合，进行理论分析和全参数空间的数值模拟。

Result: 发现了由擦边和碰撞引发的周期与混沌运动之间的转换、擦边介导的吸引子切换以及无碰撞吸引子切换等丰富动力学行为。

Conclusion: 该模型为研究活性系统中的非线性碰撞动力学及非光滑势下的流体类量子现象提供了通用平台。

Abstract: Walking droplets are millimetric fluid drops that propel themselves across a vibrated liquid bath through interaction with their self-generated waves. They constitute classical active wave-particle entities and exhibit a range of hydrodynamic quantum analogs. We investigate an \emph{active soft-impact oscillator} as a minimal model for a walking droplet moving within a piecewise-smooth external potential, analogous to classical mass-spring soft-impact oscillators and recently explored quantum soft-impact oscillators. Our active soft-impact oscillator model couples a non-smooth soft-impact force to the Lorenz-like dynamics arising from the wave-particle entity. Theoretical and numerical exploration of the full parameter space reveals a wide variety of nonlinear behaviors and bifurcations driven by impact and grazing events. These include grazing-induced and impact-induced transitions between periodic and chaotic motion, as well as grazing-mediated attractor switching and impact-free (invisible) attractor switching. The active soft-impact oscillator thus provides a versatile platform for probing nonlinear impact dynamics in active systems and exploring hydrodynamic quantum analogs in non-smooth potentials.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [19] [A uniformly accurate multiscale time integrator for the nonlinear Klein-Gordon equation in the nonrelativistic regime via simplified transmission conditions](https://arxiv.org/abs/2602.04988)
*Weizhu Bao,Caoyi Liu*

Main category: math.NA

TL;DR: 提出了一种新的多尺度时间积分傅里叶伪谱（MTI-FP）方法用于非线性Klein-Gordon方程，在非相对论极限下实现了对时间的统一一阶精度，并具有时间上的超分辨率特性。


<details>
  <summary>Details</summary>
Motivation: 在非相对论极限下，非线性Klein-Gordon方程的解在时间上高度振荡，给设计统一精确的数值方法带来困难，因此需要开发一种能有效处理高频振荡且在小ε情况下仍保持精度的方法。

Method: 基于频率的多尺度分解和简化的传输条件，结合指数波积分器进行时间离散化以及傅里叶伪谱方法进行空间离散化，构建MTI-FP方法。

Result: 得到了H1范数下的两个误差界，证明了该方法在ε∈(0,1]范围内具有关于时间步长和网格尺寸的统一精度，并展现出时间上的超分辨率特性，即使时间步长大于O(ε²)波长也能获得精确解。

Conclusion: MTI-FP方法在非相对论极限下对非线性Klein-Gordon方程具有良好的收敛性和稳定性，能够高效准确地模拟其动力学行为，并可用于研究其向不同极限模型的收敛速率。

Abstract: We propose a new and simplified multiscale time integrator Fourier pseudospectral (MTI-FP) method for the nonlinear Klein-Gordon equation (NKGE) with a dimensionless parameter epsilon in (0,1] inversely proportional to the speed of light, and establish its uniform first-order accuracy in time in the nonrelativistic regime, i.e. 0 < epsilon << 1. In this regime, the solution of the NKGE is highly oscillatory in time with O(epsilon^2)-wavelength, which brings significant difficulties in designing uniformly accurate numerical methods. The MTI-FP is based on (i) a multiscale decomposition by frequency of the NKGE in each time interval with simplified transmission conditions, and (ii) an exponential wave integrator for temporal discretization and a Fourier pseudospectral method for spatial discretization. By adapting the energy method and the mathematical induction, we obtain two error bounds in H1-norm at O(h^{m0}+tau^2/epsilon^2) and O(h^{m0}+tau+epsilon^2) with mesh size h, time step tau and m0 an integer dependent on the regularity of the solution, which immediately implies a uniformly accurate error bound O(h^{m0}+tau) with respect to epsilon in (0,1]. In addition, by adopting a linear interpolation of the micro variables with the multiscale decomposition in each time interval, we obtain a uniformly accurate numerical solution for any time t larger than zero. Thus the proposed MTI-FP method has a super resolution property in time in terms of the Shannon sampling theory, i.e. accurate numerical solutions can be obtained even when the time step is much bigger than the O(epsilon^2)-wavelength. Extensive numerical results are reported to confirm our error bounds and demonstrate their super resolution in time. Finally the proposed MTI-FP method is applied to study numerically convergence rates of the NKGE to its different limiting models in the nonrelativistic regime.

</details>


### [20] [Acoustic scattering by fractal inhomogeneities via geometry-conforming Galerkin methods for the Lippmann-Schwinger equation](https://arxiv.org/abs/2602.05005)
*Joshua Bannister,David P. Hewett,Andrew Gibbs*

Main category: math.NA

TL;DR: 提出并分析了一种用于具有分形边界的可穿透散射体在二维和三维空间中时间谐波声散射的数值方法，基于Lippmann-Schwinger体积积分方程的Galerkin离散化，并采用具有分形边界元素的几何共形网格。


<details>
  <summary>Details</summary>
Motivation: 针对具有分形边界的非均匀介质（可穿透散射体）的声波散射问题，传统方法难以精确处理其复杂几何结构，因此需要发展一种能有效适应分形边界的高精度数值方法。

Method: 采用基于Lippmann-Schwinger体积积分方程的Galerkin离散化方法，使用在几何共形网格上的间断分片多项式逼近空间，网格单元本身也具有分形边界；对h-和p-版本方法进行了半离散适定性和误差分析，并为h-版本设计了适用于分形结构的奇异积分规则。

Result: 证明了对于任意无正则性假设的非均匀介质，该方法均具有收敛性和超收敛性，且分形自相似性可用于生成几何共形网格；数值实验表明该方法比使用光滑预分形近似的方法更精确。

Conclusion: 所提出的方法能够高效、高精度地处理具有分形边界的可穿透散射体的声散射问题，尤其在保持几何真实性方面优于传统近似方法。

Abstract: We propose and analyse a numerical method for time-harmonic acoustic scattering in $\mathbb{R}^n$, $n=2,3$, by a class of inhomogeneities (penetrable scatterers) with fractal boundary. Our method is based on a Galerkin discretisation of the Lippmann-Schwinger volume integral equation, using a discontinuous piecewise-polynomial approximation space on a geometry-conforming mesh comprising elements which themselves have fractal boundary. We first provide a semi-discrete well-posedness and error analysis for both the $h$- and $p$-versions of our method for completely arbitrary inhomogeneities (without any regularity assumption on the boundary of the inhomogeneity or of the mesh elements). We prove convergence estimates for the integral equation solution and superconvergence estimates for linear functionals such as scattered field and far-field pattern evaluations, and elucidate how the regularity of the inhomogeneity boundary and the regularity of the refractive index affect the rates of convergence predicted. We then specialise to the case where the inhomogeneity is an ``$n$-attractor'', i.e.\ the fractal attractor of an iterated function system satisfying the open set condition with non-empty interior, showing how in this case the self-similarity of the inhomogeneity can be used to generate geometry-conforming meshes. For the $h$-version with piecewise constant approximation we also present singular quadrature rules, supported by a fully discrete error analysis, permitting practical implementation of our method. We present numerical results for two-dimensional examples, which validate our theoretical results and show that our method is significantly more accurate than a comparable method involving replacement of the fractal inhomogeneity by a smoother prefractal approximation.

</details>


### [21] [Scalable Fixed-Point Framework for High-Dimensional Hamilton-Jacobi Equations](https://arxiv.org/abs/2602.05124)
*Yesom Park,Stanley Osher*

Main category: math.NA

TL;DR: 提出了一种基于Hopf-Lax公式的无网格、无梯度的不动点方法，用于高效求解高维Hamilton-Jacobi方程，具有良好的可扩展性和精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法在求解高维HJ方程时受限于网格和梯度计算，导致维度灾难；需要一种更高效且可扩展的方法。

Method: 利用Hopf-Lax公式将问题转化为变分问题，并通过Picard迭代进行不动点求解，无需网格、特征线或微分操作。

Result: 在高达100维的数值实验中验证了方法的有效性，能够高效处理控制问题和非光滑解，计算时间几乎不随维度增加而增长。

Conclusion: 该方法为高维Hamilton-Jacobi方程提供了一种高效、精确且可扩展的求解方案，适用于复杂控制问题。

Abstract: We propose a novel, mesh-free, and gradient-free fixed-point approach for computing viscosity solutions of high-dimensional Hamilton-Jacobi (HJ) equations. By leveraging the Hopf-Lax formula, our approach iteratively solves the associated variational problem via a Picard iteration, enabling efficient evaluation of both the solution and its corresponding control without relying on grids, characteristics, or differentiation. We demonstrate the practical efficacy and scalability of the approach through numerical experiments in up to 100 dimensions, including control problems and non-smooth solutions. Our results show that the proposed scheme achieves high accuracy, is highly efficient, and exhibits computational times that are largely independent of dimensionality, highlighting its suitability for high-dimensional problems.

</details>


### [22] [Linear Systems and Eigenvalue Problems: Open Questions from a Simons Workshop](https://arxiv.org/abs/2602.05394)
*Noah Amsel,Yves Baumann,Paul Beckman,Peter Bürgisser,Chris Camaño,Tyler Chen,Edmond Chow,Anil Damle,Michal Derezinski,Mark Embree,Ethan N. Epperly,Robert Falgout,Mark Fornace,Anne Greenbaum,Chen Greif,Diana Halikias,Zhen Huang,Elias Jarlebring,Yiannis Koutis,Daniel Kressner,Rasmus Kyng,Jörg Liesen,Jackie Lok,Raphael A. Meyer,Yuji Nakatsukasa,Kate Pearce,Richard Peng,David Persson,Eliza Rebrova,Ryan Schneider,Rikhav Shah,Edgar Solomonik,Nikhil Srivastava,Alex Townsend,Robert J. Webber,Jess Williams*

Main category: math.NA

TL;DR: 本文档总结了2025年秋季Simons研究所“复杂性与线性代数”研讨会期间提出的矩阵计算中的若干开放性问题，涵盖线性系统迭代求解、特征值计算、低秩逼近、随机 sketching 及其他相关领域。


<details>
  <summary>Details</summary>
Motivation: 促进理论计算机科学与数值分析领域的交叉合作，明确矩阵计算中尚未解决的关键问题。

Method: 通过研讨会中来自不同领域研究者的讨论，整理出具有代表性的开放性问题。

Result: 形成了五个类别的开放问题：线性系统的迭代求解器、特征值计算、低秩近似、随机sketching，以及其他包括张量、量子系统和矩阵函数的领域。

Conclusion: 这些问题的提出有助于推动线性代数数值方法的理论与实践发展，并加强跨学科交流。

Abstract: This document presents a series of open questions arising in matrix computations, i.e., the numerical solution of linear algebra problems. It is a result of working groups at the workshop \emph{Linear Systems and Eigenvalue Problems}, which was organized at the Simons Institute for the Theory of Computing program on \emph{Complexity and Linear Algebra} in Fall 2025. The complexity and numerical solution of linear algebra problems %in matrix computations and related fields is a crosscutting area between theoretical computer science and numerical analysis. The value of the particular problem formulations here is that they were produced via discussions between researchers from both groups.
  The open questions are organized in five categories: iterative solvers for linear systems, eigenvalue computation, low-rank approximation, randomized sketching, and other areas including tensors, quantum systems, and matrix functions.

</details>


### [23] [Numerical stationary states for nonlocal Fokker-Planck equations via fixed points of consistency maps](https://arxiv.org/abs/2602.05632)
*José A. Carrillo,Yurij Salmaniw,Antonio León Villares*

Main category: math.NA

TL;DR: 提出一种基于不动点的数值框架，用于计算非局部Fokker-Planck型方程的定态解，采用矩阵自由的Newton-Krylov方法求解，不依赖时间演化，可捕捉稳定与不稳定定态，精度主要由卷积和数值积分决定。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖时间演化且对动态稳定性敏感，难以有效计算非局部Fokker-Planck方程的稳定与不稳定定态解，因此需要一种更鲁棒、精确且不受稳定性限制的新方法。

Method: 将定态问题重构为基于原PDE及其非局部相互作用项的非线性不动点映射，并使用矩阵自由的Newton-Krylov方法求解有限维问题；比较了使用解析Frechet导数与中心差分近似两种实现方式。

Result: 该方法成功应用于三个带线性扩散的模型问题，输出结果与已知解析解一致，复现了已知分岔图，并发现了此前未观察到的新分岔行为。

Conclusion: 所提方法不依赖时间演化，对动力学稳定性无偏好，能准确计算稳定与不稳定定态，其精度主要取决于卷积和数值积分的处理，而非微分格式，具有良好的通用性和准确性。

Abstract: We propose a fixed-point-based numerical framework for computing stationary states of nonlocal Fokker-Planck-type equations. Instead of discretising the differential operators directly, we reformulate the stationary problem as a nonlinear fixed-point map built from the original PDE and its nonlocal interaction terms, and solve the resulting finite-dimensional problem with a matrix-free Newton-Krylov method. We compare implementations using the analytic Frechet derivative of this map with a simple central-difference approximation. Because the method does not rely on time evolution, it is agnostic to dynamical stability and can detect both stable and unstable stationary states. Its accuracy is determined mainly by the numerical treatment of convolutions and quadrature, rather than by differentiation stencils. We apply the approach to three model problems with linear diffusion, use existing analytical results to verify the outputs, and reproduce known bifurcation diagrams, as well as new bifurcation behaviour not previously observed in this kind of problem.

</details>


### [24] [A penalized φ-FEM scheme for the Poisson Dirichlet problem](https://arxiv.org/abs/2602.05698)
*Raphaël Bulle,Michel Duprez,Vanessa Lleras,Killian Vuillemot*

Main category: math.NA

TL;DR: 本文提出了一种基于惩罚项的φ-FEM方法变体，用于求解具有Dirichlet边界条件的Poisson方程，该方法仅需在靠近边界的单元上提供水平集函数，并结合幽灵罚技术实现稳定，理论分析和数值实验表明其具有最优或拟最优收敛性。


<details>
  <summary>Details</summary>
Motivation: 避免使用边界拟合网格，同时简化对水平集函数的需求，提高非拟合有限元方法的灵活性和实用性。

Method: 采用惩罚项来施加边界条件，并结合幽灵罚技术进行方案稳定化，仅需在邻近边界的单元上定义水平集函数。

Result: 推导了先验误差估计，显示在H1半范数下具有最优收敛性，在L2范数下具有拟最优收敛性，数值实验验证了理论结果，并与原始φ-FEM及标准拟合有限元方法进行了比较。

Conclusion: 所提出的惩罚型φ-FEM方法有效且稳定，能够在减少水平集函数依赖的同时保持良好的收敛性能，适用于复杂几何下的Poisson方程求解。

Abstract: In this work, we analyze a penalized variant of the φ-FEM scheme for the Poisson equation with Dirichlet boundary conditions. The φ-FEM is a recently introduced unfitted finite element method based on a level-set description of the geometry, which avoids the need for boundary-fitted meshes. Unlike the original φ-FEM formulation, the method proposed here enforces boundary conditions through a penalization term. This approach has the advantage that the level-set function is required only on the cells adjacent to the boundary in the variational formulation. The scheme is stabilized using a ghost penalty technique. We derive a priori error estimates, showing optimal convergence in the H1 semi-norm and quasi-optimal convergence in the L2 norm under suitable regularity assumptions. Numerical experiments are presented to validate the theoretical results and to compare the proposed method with both the original φ-FEM and the standard fitted finite element method.

</details>


### [25] [Finite element approximation for a reformulation of a 3D fluid-2D plate interaction system](https://arxiv.org/abs/2602.05701)
*Lander Besabe,Hyesuk Lee*

Main category: math.NA

TL;DR: 本文研究了一种三维不可压缩粘性流体与二维弹性板耦合的有限元逼近方法，通过引入辅助变量将四阶板方程转化为二阶方程组，并利用拉格朗日乘子处理界面耦合条件。


<details>
  <summary>Details</summary>
Motivation: 为了避免使用H²-协调或非协调P₂-Morley板单元，简化数值实现并提高计算稳定性。

Method: 将四阶板方程重构为耦合的二阶方程系统，采用拉格朗日乘子施加界面耦合条件，并设计基于不动点迭代的分区域分解算法求解。

Result: 建立了时间离散和全离散问题的适定性和稳定性结果，推导了先验误差估计，数值实验验证了空间和时间上的收敛率，并展示了方法在实际物理问题中的适用性。

Conclusion: 所提方法有效避免了高阶单元的使用，具有良好的收敛性和稳定性，适用于流固耦合问题的数值模拟。

Abstract: We study a finite element approximation of a coupled fluid-structure interaction consisting of a three-dimensional incompressible viscous fluid governed by the unsteady Stokes equations and a two-dimensional elastic plate. To avoid the use of $H^2-$conforming or nonconforming $\mathbb{P}_2$-Morley plate elements, the fourth-order plate equation is reformulated into a system of coupled second-order equations using an auxiliary variable. The coupling condition is enforced using a Lagrange multiplier representing the trace of the mean-zero fluid pressure on the interface.
  We establish well-posedness and stability results for the time-discrete and fully-discrete problems, and derive a priori error estimates. A partitioned domain decomposition algorithm based on a fixed-point iteration is employed for the numerical solution. Numerical experiments verify the theoretical rates of convergence in space and time using manufactured solutions, and demonstrate the applicability of the method to a physical problem.

</details>


### [26] [Optimal boundary closures for diagonal-norm upwind SBP operators](https://arxiv.org/abs/2602.05727)
*Ken Mattsson,David Niemelä,Andrew R. Winters*

Main category: math.NA

TL;DR: 提出了一种基于非等距网格点的高阶边界优化迎风有限差分算子，结合SBP框架和SAT或投影方法处理边界与界面条件，显著提升了计算精度与效率，并通过一维双曲方程和二维欧拉方程的数值实验验证了其稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高有限差分法在边界附近的精度和计算效率，克服传统等距网格上SBP算子的局限性，特别是在处理复杂几何和曲线网格时的性能瓶颈。

Method: 采用非等距网格点设计高阶（最高九阶）迎风型有限差分算子，在对角范数SBP框架下构建边界闭合，并使用SAT方法弱施加或投影法强施加边界与界面条件。

Result: 所提算子相比等距网格上的SBP算子显著提升了精度和计算效率；所得离散格式生成完全显式的常微分方程系统，并在一维线性双曲问题和二维可压缩欧拉方程中验证了良好的稳定性和高精度。

Conclusion: 该研究成功发展了高阶边界优化的SBP有限差分格式，结合非等距网格与迎风特性，实现了高效稳定的数值求解，适用于多块曲线网格，具有良好的应用前景。

Abstract: By employing non-equispaced grid points near boundaries, boundary-optimized upwind finite-difference operators of orders up to nine are developed. The boundary closures are constructed within a diagonal-norm summation-by-parts (SBP) framework, ensuring linear stability on piecewise curvilinear multiblock grids. Boundary and interface conditions are imposed using either weak enforcement through simultaneous approximation terms (SAT) or strong enforcement via the projection method.
  The proposed operators yield significantly improved accuracy and computational efficiency compared with SBP operators constructed on equidistant grids. The resulting SBP--SAT and SBP--projection discretizations produce fully explicit systems of ordinary differential equations. The accuracy and stability properties of the proposed operators are demonstrated through numerical experiments for linear hyperbolic problems in one spatial dimension and for the compressible Euler equations in two spatial dimensions.

</details>


### [27] [Spectral Analysis of Block Diagonally Preconditioned Multiple Saddle-Point Matrices with Inexact Schur Complements](https://arxiv.org/abs/2602.05952)
*Marco Pilotto,Luca Bergamaschi,Angeles Martinez*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We derive eigenvalue bounds for symmetric block-tridiagonal multiple saddle-point systems preconditioned with block-diagonal Schur complement matrices. This analysis applies to an arbitrary number of blocks and accounts for the case where the Schur complements are approximated, generalizing the findings in [Bergamaschi et al., Linear Algebra and its Applications, 2026]. Numerical experiments are carried out to validate the proposed estimates.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [28] [Banach Control Barrier Functions for Large-Scale Swarm Control](https://arxiv.org/abs/2602.05011)
*Xuting Gao,Guillem Pascual,Scott Brown,Sonia Martínez*

Main category: math.OC

TL;DR: 提出了一种基于Banach控制屏障函数（B-CBFs）的大型多智能体系统安全控制框架，通过宏观分布建模与微观算法设计实现 swarm 的安全与稳定控制，并支持分布式局部信息求解。


<details>
  <summary>Details</summary>
Motivation: 针对大规模多智能体系统（如智能体群）的安全控制难题，传统方法难以处理宏观约束与微观行为的一致性，因此需要一种可扩展且保证安全性的统一框架。

Method: 将大规模 swarm 建模为空间域上的概率分布，引入Banach控制屏障函数（B-CBFs）来刻画宏观安全约束；结合最优传输理论设计稳定的过滤梯度流，并推导出与宏观动态一致的微观控制算法；分析仅依赖局部通信的分布式实现条件。

Result: 建立了B-CBFs在大规模swarm控制中的有效性，实现了宏观安全约束下的稳定动态；提出了可分布式执行的微观控制策略，仅需局部通信即可收敛；在仿真中验证了理论结果的有效性。

Conclusion: 该框架为大规模多智能体系统的安全控制提供了新的数学工具和设计方法，连接了宏观控制理论与微观实现，具有良好的可扩展性和实用性。

Abstract: This paper studies the safe control of very large multi-agent systems via a generalized framework that employs so-called Banach Control Barrier Functions (B-CBFs). Modeling a large swarm as probability distribution over a spatial domain, we show how B-CBFs can be used to appropriately capture a variety of macroscopic constraints that can integrate with large-scale swarm objectives. Leveraging this framework, we define stable and filtered gradient flows for large swarms, paying special attention to optimal transport algorithms. Further, we show how to derive agent-level, microscopical algorithms that are consistent with macroscopic counterparts in the large-scale limit. We then identify conditions for which a group of agents can compute a distributed solution that only requires local information from other agents within a communication range. Finally, we showcase the theoretical results over swarm systems in the simulations section.

</details>


### [29] [Decaying Sensitivity of the Zero Solution for a Class of Nonlinear Optimal Control Problems](https://arxiv.org/abs/2602.05020)
*Lars Grüne,Mario Sperl*

Main category: math.OC

TL;DR: 研究了图结构相互作用拓扑下非线性最优控制问题中灵敏度的空间衰减特性，证明局部扰动导致的最优轨迹随图距离呈指数衰减。


<details>
  <summary>Details</summary>
Motivation: 将已知的线性-二次系统的空间衰减结果推广到非线性系统。

Method: 基于非线性可控性条件，分析非线性解耦动态和二次成本下的系统响应。

Result: 局部扰动引起的最优轨迹随图距离呈指数衰减。

Conclusion: 为扩展线性-二次系统到非线性系统的空间衰减理论提供了第一步。

Abstract: We study spatial decay properties of sensitivities in a nonlinear optimal control problem with a graph--structured interaction topology. For a problem with nonlinear decoupled dynamics and quadratic cost, we show that a localized perturbation of the zero reference leads to an optimal trajectory that decays exponentially with the graph distance. The analysis, based on a nonlinear controllability condition, provides a first step toward extending known spatial decay results from linear--quadratic to nonlinear systems. A numerical example illustrates the theoretical findings.

</details>


### [30] [Safe Optimal Control using Log Barrier Constrained iLQR](https://arxiv.org/abs/2602.05046)
*Abhijeet,Suman Chakravorty*

Main category: math.OC

TL;DR: 提出了一种基于对数障碍函数的约束iLQR框架，用于处理状态和控制输入的盒式约束非线性最优控制问题，具有良好的收敛性和数值稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统iLQR在处理状态和控制输入的盒式约束时存在困难，需要一种能自然融入原有框架且保证数值稳定性的方法。

Method: 通过在阶段成本中引入对数障碍函数，将约束条件转化为光滑的内点法形式，并结合标准iLQR的前后向递推过程。利用障碍函数的凸性和正定Hessian矩阵提升二次近似的正定性，实现内在正则化。

Result: 该方法有效保持了对盒式约束的满足，在控制量饱和时反馈增益自动趋零，转变为前馈控制；数值实验表明其具备可靠的约束满足能力和良好的收敛性。

Conclusion: 所提出的障碍增强型iLQR方法为带盒式约束的非线性最优控制提供了一个稳定、高效且结构自然的求解框架。

Abstract: This paper presents a constrained iterative Linear Quadratic Regulator (iLQR) framework for nonlinear optimal control problems with box constraints on both states and control inputs. We incorporate logarithmic barrier functions into the stage cost to enforce box constraints (upper and lower bounds on variables), yielding a smooth interior-point formulation that integrates seamlessly with the standard iLQR backward-forward pass. The Hessian contributions from the log barriers are positive definite, preserving and enhancing the positive definiteness of the quadratic approximations in iLQR and providing an intrinsic regularization effect that improves numerical stability and convergence. Moreover, since the negative logarithm is convex, the addition of log barrier terms preserves convexity if the cost is already convex. We further analyze how the barrier-augmented iLQR naturally adapts feedback gains near constraint boundaries. In particular, at convergence, the feedback terms associated with saturated control channels go to zero, recovering a purely feedforward behavior whenever control is saturated. Numerical examples on constrained nonlinear control problems demonstrate that the proposed method reliably respects box constraints and maintains favorable convergence properties.

</details>


### [31] [An Adaptive Framework for Robust Structural Shape Optimization under Uncertainty](https://arxiv.org/abs/2602.05054)
*Oğuz Han Altıntaş,Hamdullah Yücel*

Main category: math.OC

TL;DR: 提出了一种基于误差估计的自适应随机优化框架，用于求解考虑载荷和材料不确定性的鲁棒结构形状优化问题，并在腿部类结构上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了提高结构在不确定载荷和材料输入下的鲁棒性，需发展能够自适应调整计算精度与优化参数的形状优化方法。

Method: 构建了后验误差估计器，用于动态调整样本量、网格尺寸和优化步长；考虑了形变双线性形式和弹性系统离散化带来的误差，并基于随机形状导数的方差和Lipschitz常数实现自适应控制。

Result: 实现了对随机形状导数的存在性分析与分布形式推导，所提框架能有效最小化在不确定接触力作用下的触地柔顺性。

Conclusion: 该自适应框架能有效平衡计算成本与优化精度，在处理不确定性影响的结构优化问题中具有良好的应用前景。

Abstract: This work proposes an adaptive framework to solve a robust structural shape optimization problem governed by linear elasticity models that account for uncertainties in the loading and material inputs. A posteriori error estimators are constructed to adjust the sample size, mesh size, and step length. The size of the sample set in the stochastic gradient approximation is dynamically determined depending on the variance of the shape derivative. When constructing the a posteriori error estimator in the physical domain, errors arising from the discretization of the deformation bilinear form, which provides a descent direction, are considered, in addition to errors from the discretization of the linear elasticity system. The step length in gradient-based optimization is also adaptively adjusted by estimating the Lipschitz constant of the stochastic shape derivative. Moreover, an analysis of the existence and distributed-form derivation of the stochastic shape derivative is provided. Finally, the proposed estimation-based adaptive stochastic optimization framework is validated on leg-like structural components, demonstrating its effectiveness in minimizing touchdown compliance under uncertain contact forces.

</details>


### [32] [From Sequential to Parallel: Reformulating Dynamic Programming as GPU Kernels for Large-Scale Stochastic Combinatorial Optimization](https://arxiv.org/abs/2602.05179)
*Jingyi Zhao,Linxin Yang,Haohua Zhang,Tian Ding*

Main category: math.OC

TL;DR: 提出了一种基于GPU的框架，通过硬件感知的批处理并行计算，使大规模场景下的整数第二阶段模型在随机规划中变得可解，显著提升了决策质量。


<details>
  <summary>Details</summary>
Motivation: 传统基于场景的样本平均近似（SAA）方法在求解包含NP难组合结构的精确第二阶段问题时计算成本过高，限制了高保真整数模型的应用。

Method: 设计了面向GPU的硬件感知批处理核函数，跨场景、动态规划层和动作选项暴露并行性，实现单次遍历超百万场景的Bellman更新。

Result: 在两类典型SP问题中验证，求解规模接近线性扩展，速度提升4-5个数量级，支持更大场景集和更优第一阶段决策。

Conclusion: 全保真整数第二阶段模型在大规模随机离散优化中已具备实际可行性，为现实场景的随机优化提供了新路径。

Abstract: A major bottleneck in scenario-based Sample Average Approximation (SAA) for stochastic programming (SP) is the cost of solving an exact second-stage problem for every scenario, especially when each scenario contains an NP-hard combinatorial structure. This has led much of the SP literature to restrict the second stage to linear or simplified models. We develop a GPU-based framework that makes full-fidelity integer second-stage models tractable at scale. The key innovation is a set of hardware-aware, scenario-batched GPU kernels that expose parallelism across scenarios, dynamic-programming (DP) layers, and route or action options, enabling Bellman updates to be executed in a single pass over more than 1,000,000 realizations. We evaluate the approach in two representative SP settings: a vectorized split operator for stochastic vehicle routing and a DP for inventory reinsertion. Implementation scales nearly linearly in the number of scenarios and achieves a one-two to four-five orders of magnitude speedup, allowing far larger scenario sets and reliably stronger first-stage decisions. The computational leverage directly improves decision quality: much larger scenario sets and many more first-stage candidates can be evaluated within fixed time budgets, consistently yielding stronger SAA solutions. Our results show that full-fidelity integer second-stage models are tractable at scales previously considered impossible, providing a practical path to large-scale, realistic stochastic discrete optimization.

</details>


### [33] [Twice Epi-Differentiability of Spectral Functions and its applications](https://arxiv.org/abs/2602.05357)
*Chao Ding,Ebrahim Sarabi,Shiwei Wang*

Main category: math.OC

TL;DR: 本文提出了一种新的方法来刻画谱函数的二阶e-可微性，通过其对称部分的性质进行表征，并去除了以往工作中常见的凸性假设，拓展了在优化问题中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有研究中对凸性假设的依赖，进一步推广谱函数二阶变分性质的适用范围，特别是针对在统计学和鲁棒PCA中有重要应用的非光滑函数。

Method: 利用谱表示的对称部分来刻画谱函数的二阶e-可微性，建立其与特征值函数之间的等价关系，并结合变分分析工具研究子梯度映射和邻近映射的方向可微性。

Result: 成功去除了凸性假设，给出了谱函数二阶e-可微性的新刻画；证明了子梯度映射的原微分性和邻近映射的方向可微性；并将理论应用于最大特征值函数和实际正则化项的分析。

Conclusion: 该研究为广泛谱函数提供了更强的二阶变分分析工具，增强了对非光滑优化模型的理论支持，具有重要的理论与应用价值。

Abstract: Second-order variational properties have been shown to play important theoretical and numerical roles for different classes of optimization problems. Among such properties, twice epi-differentiability has a special place because of its ubiquitous presence in various classes of extended-real-valued functions that are important for optimization problems. We provide a useful characterization of this property for spectral functions by demonstrating that it can be characterized via the same property of the symmetric part of the spectral representation of an eigenvalue function. Our approach allows us to bypass the rather restrictive convexity assumption, used in many recent works that targeted second-order variational properties of spectral functions. By this theoretical tool, several applications on the proto-differentiability of subgradient mappings, the directional differentiability of the proximal mapping of spectral functions are achieved. We finally use our established theory to study twice epi-differentiability of leading eigenvalue functions and practical regularization terms that have important applications in statistics and the robust PCA.

</details>


### [34] [Relationship between MP and DPP for Risk-Sensitive Stochastic Optimal Control Problems: Viscosity Solution Framework](https://arxiv.org/abs/2602.05361)
*Huanqing Dong,Jingtao Shi*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we study the relationship between general maximum principle and dynamic programming principle for risk-sensitive stochastic optimal control problems, where the control domain is not necessarily convex. The original problem is equivalent to a stochastic recursive optimal control problem of a forward-backward system with quadratic generators. Relations among the adjoint processes, the generalized Hamiltonian function and the value function are proved under the framework of viscosity solutions. Some examples are given to illustrate the theoretical results.

</details>


### [35] [Hybrid Quantum-Classical Optimization for Multi-Objective Supply Chain Logistics](https://arxiv.org/abs/2602.05364)
*Raoul Heese,Timothée Leleu,Sam Reifenstein,Christian Nietner,Yoshihisa Yamamoto*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A multi-objective logistics optimization problem from a real-world supply chain is formulated as a Quadratic Unconstrained Binary Optimization Problem (QUBO) that minimizes cost, emissions, and delivery time, while maintaining target distributions of supplier workshare. The model incorporates realistic constraints, including part dependencies, double sourcing, and multimodal transport. Two hybrid quantum-classical solvers are proposed: a structure-aware informed tree search (IQTS) and a modular bilevel framework (HBS), combining quantum subroutines with classical heuristics. Experimental results on IonQ's Aria-1 hardware demonstrate a methodology to map real-world logistics problems onto emerging combinatorial optimization-specialized hardware, yielding high-quality, Pareto-optimal solutions.

</details>


### [36] [Distributed Model Predictive Control for Energy and Comfort Optimization in Large Buildings Using Piecewise Affine Approximation](https://arxiv.org/abs/2602.05376)
*Hongyi Li,Jun Xu,Jinfeng Liu*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The control of large buildings encounters challenges in computational efficiency due to their size and nonlinear components. To address these issues, this paper proposes a Piecewise Affine (PWA)-based distributed scheme for Model Predictive Control (MPC) that optimizes energy and comfort through PWA-based quadratic programming. We utilize the Alternating Direction Method of Multipliers (ADMM) for effective decomposition and apply the PWA technique to handle the nonlinear components. To solve the resulting large-scale nonconvex problems, the paper introduces a convex ADMM algorithm that transforms the nonconvex problem into a series of smaller convex problems, significantly enhancing computational efficiency. Furthermore, we demonstrate that the convex ADMM algorithm converges to a local optimum of the original problem. A case study involving 36 zones validates the effectiveness of the proposed method. Our proposed method reduces execution time by 86\% compared to the centralized version.

</details>


### [37] [Optimistic Bilevel Optimization with Composite Lower-Level Problem](https://arxiv.org/abs/2602.05417)
*Mattia Solla,Johannes O. Royset*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper introduces a novel double regularization scheme for bilevel optimization problems whose lower-level problem is composite and convex, but not necessarily strongly convex, in the lower-level variable. The analysis focuses on the primal-dual solution mapping of the regularized lower-level problem and exploits its properties to derive an almost-everywhere formula for the gradient of the regularized hyper-objective under mild assumptions. The paper then establishes conditions under which the hyper-objective of the actual problem is well defined and shows that its gradient can be approximated by the gradient of the regularized hyper-objective. Building on these results, a gradient sampling-based algorithm computes approximately stationary points of the regularized hyper-objective, and we prove its convergence to stationary points of the actual problem. Two numerical examples from machine learning demonstrate the proposed approach.

</details>


### [38] [Relaxation in infinite convex programming under Slater-type regularity conditions](https://arxiv.org/abs/2602.05457)
*Rafael Correa,Abderrahim Hantoute,Marco A. López*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The main purpose of this paper is to close the gap between the optimal values of an infinite convex program and that of its biconjugate relaxation. It is shown that Slater and continuity-type conditions guarantee such a zero-duality gap. The approach uses calculus rules for the conjugation and biconjugation of the sum and pointwise supremum operations. A second important objective of this work is to exploit these results on relaxation by applying them in the context of duality theory.

</details>


### [39] [Convergence Rate of the Last Iterate of Stochastic Proximal Algorithms](https://arxiv.org/abs/2602.05489)
*Kevin Kurian Thomas Vaidyan,Michael P. Friedlander,Ahmet Alacaoglu*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze two classical algorithms for solving additively composite convex optimization problems where the objective is the sum of a smooth term and a nonsmooth regularizer: proximal stochastic gradient method for a single regularizer; and the randomized incremental proximal method, which uses the proximal operator of a randomly selected function when the regularizer is given as the sum of many nonsmooth functions. We focus on relaxing the bounded variance assumption that is common, yet stringent, for getting last iterate convergence rates. We prove the $\widetilde{O}(1/\sqrt{T})$ rate of convergence for the last iterate of both algorithms under componentwise convexity and smoothness, which is optimal up to log terms. Our results apply directly to graph-guided regularizers that arise in multi-task and federated learning, where the regularizer decomposes as a sum over edges of a collaboration graph.

</details>


### [40] [Normalization of ReLU Dual for Cut Generation in Stochastic Mixed-Integer Programs](https://arxiv.org/abs/2602.05974)
*Akul Bansal,Simge Küçükyavuz*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the Rectified Linear Unit (ReLU) dual, an existing dual formulation for stochastic programs that reformulates non-anticipativity constraints using ReLU functions to generate tight, non-convex, and mixed-integer representable cuts. While this dual reformulation guarantees convergence with mixed-integer state variables, it admits multiple optimal solutions that can yield weak cuts. To address this issue, we propose normalizing the dual in the extended space to identify solutions that yield stronger cuts. We prove that the resulting normalized cuts are tight and Pareto-optimal in the original state space. We further compare normalization with existing regularization-based approaches for handling dual degeneracy and explain why normalization offers key advantages. In particular, we show that normalization can recover any cut obtained via regularization, whereas the converse does not hold. Computational experiments demonstrate that the proposed approach outperforms existing methods by consistently yielding stronger cuts and reducing solution times on harder instances.

</details>


### [41] [Continuized Nesterov Momentum Achieves the $O(\varepsilon^{-7/4})$ Complexity without Additional Mechanisms](https://arxiv.org/abs/2602.05504)
*Julien Hermant,Jean-François Aujol,Charles Dossal,Lorick Huang,Aude Rondepierre*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: For first-order optimization of non-convex functions with Lipschitz continuous gradient and Hessian, the best known complexity for reaching an $\varepsilon$-approximation of a stationary point is $O(\varepsilon^{-7/4})$. Existing algorithms achieving this bound are based on momentum, but are always complemented with safeguard mechanisms, such as restarts or negative-curvature exploitation steps. Whether such mechanisms are fundamentally necessary has remained an open question. Leveraging the continuized method, we show that a Nesterov momentum algorithm with stochastic parameters alone achieves the same complexity in expectation. This result holds up to a multiplicative stochastic factor with unit expectation and a restriction to a subset of the realizations, both of which are independent of the objective function. We empirically verify that these constitute mild limitations.

</details>


### [42] [Solving Stochastic Variational Inequalities without the Bounded Variance Assumption](https://arxiv.org/abs/2602.05531)
*Ahmet Alacaoglu,Jun-Hyun Kim*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze algorithms for solving stochastic variational inequalities (VI) without the bounded variance or bounded domain assumptions, where our main focus is min-max optimization with possibly unbounded constraint sets. We focus on two classes of problems: monotone VIs; and structured nonmonotone VIs that admit a solution to the weak Minty VI. The latter assumption allows us to solve structured nonconvex-nonconcave min-max problems. For both classes of VIs, to make the expected residual norm less than $\varepsilon$, we show an oracle complexity of $\widetilde{O}(\varepsilon^{-4})$, which is the best-known for constrained VIs. In our setting, this complexity had been obtained with the bounded variance assumption in the literature, which is not even satisfied for bilinear min-max problems with an unbounded domain. We obtain this complexity for stochastic oracles whose variance can grow as fast as the squared norm of the optimization variable.

</details>


### [43] [Efficient Algorithms for Robust Markov Decision Processes with $s$-Rectangular Ambiguity Sets](https://arxiv.org/abs/2602.05591)
*Chin Pang Ho,Marek Petrik,Wolfram Wiesemann*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Robust Markov decision processes (MDPs) have attracted significant interest due to their ability to protect MDPs from poor out-of-sample performance in the presence of ambiguity. In contrast to classical MDPs, which account for stochasticity by modeling the dynamics through a stochastic process with a known transition kernel, a robust MDP additionally accounts for ambiguity by optimizing against the most adverse transition kernel from an ambiguity set constructed via historical data. In this paper, we develop a unified solution framework for a broad class of robust MDPs with $s$-rectangular ambiguity sets, where the most adverse transition probabilities are considered independently for each state. Using our algorithms, we show that $s$-rectangular robust MDPs with $1$- and $2$-norm as well as $φ$-divergence ambiguity sets can be solved several orders of magnitude faster than with state-of-the-art commercial solvers, and often only a logarithmic factor slower than classical MDPs. We demonstrate the favorable scaling properties of our algorithms on a range of synthetically generated as well as standard benchmark instances.

</details>


### [44] [Nonsmooth Optimization with Zeroth Order Comparison Feedback](https://arxiv.org/abs/2602.05622)
*Taha El Bakkali,El Mahdi Chayti,Omar Saadi*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study unconstrained optimization problems of nonsmooth, nonconvex Lipschitz functions, using only noisy pairwise comparisons governed by a known link function. Our goal is to compute a $(δ,\varepsilon)$-Goldstein stationary point. We combine randomized smoothing with a novel unbiased reduction from comparisons to local value differences. By leveraging a Russian-roulette truncation on the Bernoulli-product expansion of the inverse link, we construct an exactly unbiased estimator for directional differences. This estimator has finite expected cost and variance scaling quadratically with the function gap, $\mathcal{O}(B^2)$, under mild conditions. Plugging this into the smoothed gradient identity enables a standard nonconvex SGD analysis, yielding explicit comparison-complexity bounds for common symmetric links such as logistic, probit, and cauchit.

</details>


### [45] [A Smooth Locally Exact Penalty Method for Optimization Problems over Generalized Stiefel Manifolds](https://arxiv.org/abs/2602.05631)
*Linshuo Jiang,Nachuan Xiao,Xin Liu*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we consider a class of optimization problems constrained to the generalized Stiefel manifold. Such problems are fundamental to a wide range of real-world applications, including generalized canonical correlation analysis, linear discriminant analysis, and electronic structure calculations. Existing works mainly focuses on cases where the generalized orthogonality constraint is induced by a symmetric positive definite matrix M, a setting where the geometry essentially reduces to that of the standard Stiefel manifold. However, many practical scenarios involve a singular M, which introduces significant analytical and computational challenges. Therefore, we propose a Smooth Locally Exact Penalty model (SLEP) and establish its equivalence to the original problem in the aspect of stationary points under a finitly large penalty parameter. This penalty model admits the direct application of various unconstrained optimization techniques, with convergence guarantees inherited from established results. Compared to Riemannian optimization approaches, our proposed penalty mode eliminates the need for retractions and vector transports, hence significantly reducing per-iteration computational costs. Extensive numerical experiments validate our theoretical results and demonstrate the effectiveness and practical potential of the proposed penalty model SLEP.

</details>


### [46] [Characterizations of the Aubin property of the KKT-mapping in composite optimization by SC derivatives and quadratic bundles](https://arxiv.org/abs/2602.05684)
*Helmut Gfrerer,Jiri V. Outrata*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: For general set-valued mappings, the Aubin property is ultimately tied to limiting coderivatives by the Mordukhovich criterion. Likewise, the existence of single-valued Lipschitzian localizations is related to strict graphical derivatives. In this paper we will show that for the special case of the KKT-mapping from composite optimization, the Aubin property and the existence of single-valued Lipschitzian localizations can be characterized by SC derivatives and quadratic bundles, respectively, which are easier accessible than limiting coderivatives and strict graphical derivatives.

</details>


### [47] [On Circuit Diameter and Straight Line Complexity](https://arxiv.org/abs/2602.05699)
*Daniel Dadush,Stefan Kober,Zhuan Khye Koh*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The circuit diameter of a polyhedron is the maximum length (number of steps) of a shortest circuit walk between any two vertices of the polyhedron. Introduced by Borgwardt, Finhold and Hemmecke (SIDMA 2015), it is a relaxation of the combinatorial diameter of a polyhedron. These two notions of diameter lower bound the number of iterations taken by circuit augmentation algorithms and the simplex method respectively for solving linear programs.
  Recently, an analogous lower bound for path-following interior point methods was introduced by Allamigeon, Dadush, Loho, Natura and Végh (SICOMP 2025). Termed straight line complexity, it refers to the minimum number of pieces of any piecewise linear curve that traverses a specified neighborhood of the central path.
  In this paper, we study the relationship between circuit diameter and straight line complexity. For a polyhedron $P:=\{x\in \mathbb{R}^n: Ax = b, x\geq \mathbf{0}\}$, we show that its circuit diameter is up to a $\mathrm{poly}(n)$ factor upper bounded by the straight line complexity of linear programs defined over $P$. This yields a strongly polynomial circuit diameter bound for polyhedra with at most 2 variables per inequality. We also give a circuit augmentation algorithm with matching iteration complexity.

</details>


### [48] [Non-Stationary Inventory Control with Lead Times](https://arxiv.org/abs/2602.05799)
*Nele H. Amiri,Sean R. Sinclair,Maximiliano Udenio*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study non-stationary single-item, periodic-review inventory control problems in which the demand distribution is unknown and may change over time. We analyze how demand non-stationarity affects learning performance across inventory models, including systems with demand backlogging or lost-sales, both with and without lead times. For each setting, we propose an adaptive online algorithm that optimizes over the class of base-stock policies and establish performance guarantees in terms of dynamic regret relative to the optimal base-stock policy at each time step. Our results reveal a sharp separation across inventory models. In backlogging systems and lost-sales models with zero lead time, we show that it is possible to adapt to demand changes without incurring additional performance loss in stationary environments, even without prior knowledge of the demand distributions or the number of demand shifts. In contrast, for lost-sales systems with positive lead times, we establish weaker guarantees that reflect fundamental limitations imposed by delayed replenishment in combination with censored feedback. Our algorithms leverage the convexity and one-sided feedback structure of inventory costs to enable counterfactual policy evaluation despite demand censoring. We complement the theoretical analysis with simulation results showing that our methods significantly outperform existing benchmarks.

</details>


### [49] [Objective-Function Free Multi-Objective Optimization: Rate of Convergence and Performance of an Adagrad-like algorithm](https://arxiv.org/abs/2602.05893)
*Marianna De Santis,Gabriele Eichfelder,Margherita Porcelli*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose an Adagrad-like algorithm for multi-objective unconstrained optimization that relies on the computation of a common descent direction only. Unlike classical local algorithms for multi-objective optimization, our approach does not rely on the dominance property to accept new iterates, which allows for a flexible and function-free optimization framework. New points are obtained using an adaptive stepsize that does not require neither knowledge of Lipschitz constants nor the use of line search procedures. The rate of convergence is analyzed and is shown to be $\mathcal{O}(1 / \sqrt{ k+1})$ with respect to the norm of the common descent direction. The method is extensively validated on a broad class of unconstrained multi-objective problems and simple multi-task learning instances, and compared against a first-order line search algorithm. Additionally, we present a preliminary study of the behavior under noisy multi-objective settings, highlighting the robustness of the method.

</details>


### [50] [The Signed Wasserstein Barycenter Problem](https://arxiv.org/abs/2602.05976)
*Matt Jacobs,Bohan Zhou*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Barycenter problems encode important geometric information about a metric space. While these problems are typically studied with positive weight coefficients associated to each distance term, more general signed Wasserstein barycenter problems have recently drawn a great deal of interest. These mixed sign problems have appeared in statistical inference setting as a way to generalize least squares regression to measure valued outputs and have appeared in numerical methods to improve the accuracy of Wasserstein gradient flow solvers. Unfortunately, the presence of negatively weighted distance terms destroys the Euclidean convexity of the unsigned problem, resulting in a much more challenging optimization task. The main focus of this work is to study properties of the signed barycenter problem for a general transport cost with a focus on establishing uniqueness of solutions. In particular, when there is only one positive weight, we extend the uniqueness result of Tornabene et al. (2025) to any cost satisfying a certain convexity property. In the case of arbitrary weights, we introduce the dual problem in terms of Kantorovich potentials and provide a sufficient condition for a stationary solution of the dual problem to induce an optimal signed barycenter.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [51] [Large-Ensemble Simulations Reveal Links Between Atmospheric Blocking Frequency and Sea Surface Temperature Variability](https://arxiv.org/abs/2602.05083)
*Zilu Meng,Gregory J. Hakim,Wenchang Yang,Gabriel A. Vecchi*

Main category: physics.ao-ph

TL;DR: 该研究利用两个深度学习大气环流模型的长时间大样本模拟，揭示了海表温度（SST）对中纬度大气阻塞事件频率的显著影响，发现SST变化与格陵兰和欧洲冬季阻塞频率的变化存在稳健遥相关，并表明基于深度学习的大样本模拟是分离外部强迫信号与内部变率噪声的有效工具。


<details>
  <summary>Details</summary>
Motivation: 大气阻塞事件导致中纬度地区持续性极端天气，但海表温度（SST）强迫与大气内部变率对该类事件的影响难以区分，本文旨在利用新型深度学习模型的大样本长时间模拟，明确SST对阻塞频率的强迫作用。

Method: 采用两个计算高效的深度学习大气环流模型，进行1900–2010年间的百年大样本集合模拟，通过集合平均滤除大气内部噪声，提取SST强迫分量，并与再分析数据及传统气候模型（CMIP6）结果对比，分析SST与阻塞频率的时空关联及趋势。

Result: 深度学习模型能准确再现观测到的阻塞气候态，性能优于或媲美传统高分辨率模型；集合平均显著提升了与再分析数据的相关性；识别出格陵兰阻塞频率与北大西洋SST及类厄尔尼诺模式之间的稳健遥相关；SST强迫下的趋势显示冬季格陵兰阻塞减少，而欧洲阻塞增加。

Conclusion: 海表温度变率对大气阻塞频率具有显著且物理可解释的影响，深度学习驱动的大样本模拟为分离外部强迫信号与内部变率提供了强大新工具。

Abstract: Atmospheric blocking events drive persistent weather extremes in midlatitudes, but isolating the influence of sea surface temperature (SST) from chaotic internal atmospheric variability on these events remains a challenge. We address this challenge using century-long (1900-2010), large-ensemble simulations with two computationally efficient deep-learning general circulation models. We find these models skillfully reproduce the observed blocking climatology, matching or exceeding the performance of a traditional high-resolution model and representative CMIP6 models. Averaging the large ensembles filters internal atmospheric noise to isolate the SST-forced component of blocking variability, yielding substantially higher correlations with reanalysis than for individual ensemble members. We identify robust teleconnections linking Greenland blocking frequency to North Atlantic SST and El Niño-like patterns. Furthermore, SST-forced trends in blocking frequency show a consistent decline in winter over Greenland, and an increase over Europe. These results demonstrate that SST variability exerts a significant and physically interpretable influence on blocking frequency and establishes large ensembles from deep learning models as a powerful tool for separating forced SST signals from internal noise.

</details>


### [52] [Thermodynamic Origin of Degree-Day Scaling in Phase-Change Systems](https://arxiv.org/abs/2602.05248)
*Zhiang Xie*

Main category: physics.ao-ph

TL;DR: 提出了一种“潜温度”概念，通过能量守恒与最优输运理论揭示相变过程中隐藏的热演化轨迹，并由此导出了冰盖融化经验法则的物理基础。


<details>
  <summary>Details</summary>
Motivation: 解决相变边界上因热力学变量受限而导致的能量波动信息丢失问题，特别是在熔化过程中温度被锁定的现象。

Method: 引入“潜温度”作为反事实热演化轨迹，结合能量守恒和Wasserstein-1距离构建数学框架，并应用于冰盖表面融化的能量平衡分析。

Result: 建立了潜热量与潜温度超调之间的严格对偶关系，该关系等价于一维Wasserstein-1距离；成功推导出正度日定律并预测了无需标定的合理度日因子。

Conclusion: 相变可被视为一种将连续能量变化投影到受限热力学边界的最优输运过程，为理解相变动力学提供了新的理论框架。

Abstract: Phase transitions impose topological constraints on thermodynamic state variables, masking energetic fluctuations at the phase boundary. This constraint is most apparent in melting systems, where temperature remains pinned despite continued energy input. Here we resolve this information loss by introducing a latent temperature-a counterfactual trajectory describing the system's unconstrained thermal evolution. We show that energy conservation alone enforces a rigorous duality between the total latent heat dissipated during phase change and the accumulated exceedance of the latent temperature above the melting point. This duality is mathematically equivalent to the one-dimensional Wasserstein-1 distance between the latent and observed temperature trajectories, with the transport cost set by a characteristic surface dissipation timescale and melting energy. Applied to ice-sheet surface melting, this timescale admits a direct physical interpretation in terms of radiative and turbulent heat loss. The same framework yields a first-principles derivation of the empirical Positive Degree Day law and predicts realistic degree-day factors that emerge from surface energy balance, without ad hoc calibration. More broadly, phase change emerges as an optimal transport process that projects continuous energetic variability onto a constrained thermodynamic boundary.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [53] [Multi-Sensor Scheduling for Remote State Estimation over Wireless MIMO Fading Channels with Semantic Over-the-Air Aggregation](https://arxiv.org/abs/2602.04971)
*Minjie Tang,Photios A. Stavrou,Marios Kountouris*

Main category: eess.SY

TL;DR: 提出了一种基于语义的空中聚合（SemOTA）方法，用于无线MIMO衰落信道下的多传感器调度与远程状态估计，通过动态规划和PSD锥分解实现高效、低功耗的调度策略。


<details>
  <summary>Details</summary>
Motivation: 传统空中聚合（OTA）在远程状态估计中存在发射功率限制，难以兼顾功率效率与估计性能，需设计更优的多传感器调度机制。

Method: 将调度任务建模为有限时域动态规划问题，分析最优Q函数结构以获得具有语义结构的调度策略，并通过正半定（PSD）锥分解推导Q函数的可计算上界，提出近似调度策略和低复杂度估计算法。

Result: 所提方案在估计精度和功率效率方面均优于现有方法，数值结果验证了其有效性。

Conclusion: SemOTA聚合方法能有效适应估计误差协方差与信道变化，为多传感器远程估计提供了高效、实用的调度解决方案。

Abstract: In this work, we study multi-sensor scheduling for remote state estimation over wireless multiple-input multiple-output (MIMO) fading channels using a novel semantic over-the-air (SemOTA) aggregation approach. We first revisit Kalman filtering with conventional over-the-air (OTA) aggregation and highlight its transmit power limitations. To balance power efficiency and estimation performance, we formulate the scheduling task as a finite-horizon dynamic programming (DP) problem. By analyzing the structure of the optimal Q-function, we show that the resulting scheduling policy exhibits a semantic structure that adapts online to the estimation error covariance and channel variations. To obtain a practical solution, we derive a tractable upper bound on the Q-function via a positive semidefinite (PSD) cone decomposition, which enables an efficient approximate scheduling policy and a low-complexity remote estimation algorithm. Numerical results confirm that the proposed scheme outperforms existing methods in both estimation accuracy and power efficiency.

</details>


### [54] [Learning Nonlinear Continuous-Time Systems for Formal Uncertainty Propagation and Probabilistic Evaluation](https://arxiv.org/abs/2602.05103)
*Peter Amorese,Morteza Lahijanian*

Main category: eess.SY

TL;DR: 提出了一种基于连续动力学视角的模型学习新方法，通过构建概率事件的泰勒级数近似实现非线性ODE中初始不确定性传播。


<details>
  <summary>Details</summary>
Motivation: 解决在非线性动力学系统中，尤其是当ODE未知且需从数据中学习时，初始状态不确定性传播的难题。

Method: 引入连续动力学视角，利用泰勒级数逼近方法对概率事件进行建模，并建立保证方法有效性的充分条件和渐近收敛性证明。

Result: 实验证明该框架在不确定性传播方面有效，尤其在预测罕见事件时表现突出。

Conclusion: 该方法为从数据中学习的非线性ODE提供了形式化的不确定性传播途径，具有理论保证和实际应用潜力。

Abstract: Nonlinear ordinary differential equations (ODEs) are powerful tools for modeling real-world dynamical systems. However, propagating initial state uncertainty through nonlinear dynamics, especially when the ODE is unknown and learned from data, remains a major challenge. This paper introduces a novel continuum dynamics perspective for model learning that enables formal uncertainty propagation by constructing Taylor series approximations of probabilistic events. We establish sufficient conditions for the soundness of the approach and prove its asymptotic convergence. Empirical results demonstrate the framework's effectiveness, particularly when predicting rare events.

</details>


### [55] [GPU-to-Grid: Voltage Regulation via GPU Utilization Control](https://arxiv.org/abs/2602.05116)
*Zhirui Liang,Jae-Won Chung,Mosharaf Chowdhury,Jiasi Chen,Vladimir Dvorkin*

Main category: eess.SY

TL;DR: 提出GPU-to-Grid框架，通过调节LLM推理批处理大小实现配电系统电压调节，揭示降低GPU功耗并非总是对电网最有利。


<details>
  <summary>Details</summary>
Motivation: 现有研究将数据中心抽象为聚合资源或仅关注GPU能效，缺乏设备级控制与电力系统目标的协同，需建立跨层级联合优化框架。

Method: 构建耦合设备级GPU控制与电力系统目标的GPU-to-Grid框架，以批处理大小为控制变量，结合电网与GPU系统测量数据，设计在线反馈优化控制器解决电压越限问题。

Result: 实验证明该方法可有效缓解配电网电压越限问题，发现降低GPU功耗有助于缓解下限越限，而增加功耗可抑制上限越限，挑战了最小化GPU功耗总有裨益的传统认知。

Conclusion: GPU计算负载具有双向电压调节潜力，通过联合优化可实现数据中心与电网的协同运行，为灵活负载参与电网调控提供新思路。

Abstract: While the rapid expansion of data centers poses challenges for power grids, it also offers new opportunities as potentially flexible loads. Existing power system research often abstracts data centers as aggregate resources, while computer system research primarily focuses on optimizing GPU energy efficiency and largely ignores the grid impacts of optimized GPU power consumption. To bridge this gap, we develop a GPU-to-Grid framework that couples device-level GPU control with power system objectives. We study distribution-level voltage regulation enabled by flexibility in LLM inference, using batch size as a control knob that trades off the voltage impacts of GPU power consumption against inference latency and token throughput. We first formulate this problem as an optimization problem and then realize it as an online feedback optimization controller that leverages measurements from both the power grid and GPU systems. Our key insight is that reducing GPU power consumption alleviates violations of lower voltage limits, while increasing GPU power mitigates violations near upper voltage limits in distribution systems; this runs counter to the common belief that minimizing GPU power consumption is always beneficial to power grids.

</details>


### [56] [Nonlinear Predictive Cost Adaptive Control of Pseudo-Linear Input-Output Models Using Polynomial, Fourier, and Cubic Spline Observables](https://arxiv.org/abs/2602.05263)
*Rami Abdulelah Alhazmi,Achinth Suresh Babu,Syed Aseem Ul Islam,Dennis S. Bernstein*

Main category: eess.SY

TL;DR: 本文提出了一种基于在线系统辨识的自适应非线性模型预测控制方法（NPCAC），无需先验建模或训练即可实现对高度不确定非线性系统的控制。


<details>
  <summary>Details</summary>
Motivation: 针对具有高度不确定性的非线性系统，传统控制方法难以有效应对，需要一种不依赖先验知识且能在线适应变化的控制策略。

Method: 采用递归最小二乘法结合信息子空间遗忘机制（RLS with SIFt）进行在线辨识，构建离散时间伪线性输入-输出模型，并将其与迭代MPC结合用于非线性滚动时域优化。

Result: 通过多项式、傅里叶和三次样条基函数验证了NPCAC方法的有效性，在不同非线性系统中表现出良好控制性能。

Conclusion: NPCAC能够在无初始模型和数据训练的前提下，有效控制高度不确定的非线性系统，具备较强的在线适应能力和应用潜力。

Abstract: Control of nonlinear systems with high levels of uncertainty is practically relevant and theoretically challenging. This paper presents a numerical investigation of an adaptive nonlinear model predictive control (MPC) technique that relies entirely on online system identification without prior modeling, training, or data collection. In particular, the paper considers predictive cost adaptive control (PCAC), which is an extension of generalized predictive control. Nonlinear PCAC (NPCAC) uses recursive least squares (RLS) with subspace of information forgetting (SIFt) to identify a discrete-time, pseudo-linear, input-output model, which is used with iterative MPC for nonlinear receding-horizon optimization. The performance of NPCAC is illustrated using polynomial, Fourier, and cubic-spline basis functions.

</details>


### [57] [Toward Operationalizing Rasmussen: Drift Observability on the Simplex for Evolving Systems](https://arxiv.org/abs/2602.05483)
*Anatoly A. Krasnovsky*

Main category: eess.SY

TL;DR: 提出在Aitchison几何框架下对软件系统中的漂移和边界接近性进行可观测性的新方法，以应对动态安全模型中信号组合性和架构变化带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基于欧氏空间的异常检测难以区分安全操作权衡与风险累积，且固定模式在架构频繁变更下迅速失效；同时，Rasmussen的动态安全模型虽解释了压力下的行为漂移，但难以应用于软件系统中不断演化的高价值组合信号。

Method: 将信号表示在单纯形空间中，采用Aitchison几何建模漂移与安全距离，在平衡坐标系下实现坐标不变的方向与距离度量；通过持续从工程资产中更新组成部分和策略定义的边界，并结合谱系感知聚合来应对外部变更。

Result: 提出了一种可在架构演化中保持可比性的漂移监控框架，支持可解释的平衡坐标表达和持续更新的监测能力。

Conclusion: 该方法为软件系统的动态安全性提供了可适应演化、可解释且具早期预警潜力的漂移观测方案。

Abstract: Monitoring drift into failure is hindered by Euclidean anomaly detection that can conflate safe operational trade-offs with risk accumulation in signals expressed as shares, and by architectural churn that makes fixed schemas (and learned models) stale before rare boundary events occur. Rasmussen's dynamic safety model motivates drift under competing pressures, but operationalizing it for software is difficult because many high-value operational signals (effort, remaining margin, incident impact) are compositional and their parts evolve. We propose a vision for drift observability on the simplex: model drift and boundary proximity in Aitchison geometry to obtain coordinate-invariant direction and distance-to-safety in interpretable balance coordinates. To remain comparable under churn, a monitor would continuously refresh its part inventory and policy-defined boundaries from engineering artifacts and apply lineage-aware aggregation. We outline early-warning diagnostics and falsifiable hypotheses for future evaluation.

</details>


### [58] [Fairness-aware design of nudging policies under stochasticity and prejudices](https://arxiv.org/abs/2602.05584)
*Lisa Piccinin,Camilla Quaresmini,Edoardo Vitale,Mara Tanelli,Valentina Breschi*

Main category: eess.SY

TL;DR: 提出了一种考虑不公平性的创新扩散模型，并设计了公平的激励分配机制，以避免加剧社会不平等。


<details>
  <summary>Details</summary>
Motivation: 现有创新扩散模型未充分考虑社会不公对个体采纳行为的影响，且激励政策可能加剧不平等。

Method: 扩展广义线性阈值模型，采用Beta分布设定个体激活阈值，并结合模型预测控制（MPC）引入公平性目标进行激励分配。

Result: 基于真实移动行为数据的仿真表明，不公正会降低整体采纳率，而追求平等可均衡激励分配，追求公平可减少最终结果差异。

Conclusion: 在创新扩散中纳入公平性考量，可在促进有效传播的同时缓解而非加剧原有社会不平等。

Abstract: We present an injustice-aware innovation-diffusion model extending the Generalized Linear Threshold framework by assigning agents activation thresholds drawn from a Beta distribution to capture the stochastic nature of adoption shaped by inequalities. Because incentive policies themselves can inadvertently amplify these inequalities, building on this model, we design a fair Model Predictive Control (MPC) scheme that incorporates equality and equity objectives for allocating incentives. Simulations using real mobility-habit data show that injustice reduces overall adoption, while equality smooths incentive distribution and equity reduces disparities in the final outcomes. Thus, incorporating fairness ensures effective diffusion without exacerbating existing social inequalities.

</details>


### [59] [Observer-based Control of Multi-agent Systems under STL Specifications](https://arxiv.org/abs/2602.05586)
*Tommaso Zaccherini,Siyuan Liu,Dimos V. Dimarogonas*

Main category: eess.SY

TL;DR: 提出了一种用于大规模异构多智能体系统的去中心化控制器，结合k-hop PPSO状态观测器估计非通信智能体的状态，并通过修正STL任务的空间鲁棒性来保证在有界干扰和估计误差下满足时序逻辑任务。


<details>
  <summary>Details</summary>
Motivation: 针对存在外部干扰且智能体间无直接通信的大规模异构多智能体系统，如何确保满足合作性的信号时序逻辑（STL）任务仍具挑战性，尤其在缺乏全局状态信息的情况下。

Method: 采用去中心化的k-hop PPSO观测器为各智能体提供无法直接通信的其他智能体的状态估计，并利用其误差性能边界修正STL任务的空间鲁棒性，进而设计连续时间反馈控制器以保证任务执行。

Result: 所提方法能够在最坏情况下的估计误差和外部干扰下，仍确保STL任务的满足，仿真结果验证了该框架的有效性。

Conclusion: 本文提出的结合k-hop PPSO与鲁棒性修正的去中心化控制框架，有效解决了非通信环境下多智能体系统在扰动中满足STL任务的问题，具有良好的鲁棒性和可扩展性。

Abstract: This paper proposes a decentralized controller for large-scale heterogeneous multi-agent systems subject to bounded external disturbances, where agents must satisfy Signal Temporal Logic (STL) specifications requiring cooperation among non-communicating agents. To address the lack of direct communication, we employ a decentralized k-hop Prescribed Performance State Observer (k-hop PPSO) to provide each agent with state estimates of those agents it cannot communicate with. By leveraging the performance bounds on the state estimation errors guaranteed by the k-hop PPSO, we first modify the space robustness of the STL tasks to account for these errors, and then exploit the modified robustness to design a decentralized continuous-time feedback controller that ensures satisfaction of the STL tasks even under worst-case estimation errors. A simulation result is provided to validate the proposed framework.

</details>


### [60] [UAV Trajectory Optimization via Improved Noisy Deep Q-Network](https://arxiv.org/abs/2602.05644)
*Zhang Hengyu,Maryam Cheraghy,Liu Wei,Armin Farhadi,Meysam Soltanpour,Zhong Zhuoqing*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper proposes an Improved Noisy Deep Q-Network (Noisy DQN) to enhance the exploration and stability of Unmanned Aerial Vehicle (UAV) when applying deep reinforcement learning in simulated environments. This method enhances the exploration ability by combining the residual NoisyLinear layer with an adaptive noise scheduling mechanism, while improving training stability through smooth loss and soft target network updates. Experiments show that the proposed model achieves faster convergence and up to $+40$ higher rewards compared to standard DQN and quickly reach to the minimum number of steps required for the task 28 in the 15 * 15 grid navigation environment set up. The results show that our comprehensive improvements to the network structure of NoisyNet, exploration control, and training stability contribute to enhancing the efficiency and reliability of deep Q-learning.

</details>


### [61] [Privacy-Preserving Dynamic Average Consensus by Masking Reference Signals](https://arxiv.org/abs/2602.05803)
*Mihitha Maithripala,Zongli Lin*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In multi-agent systems, dynamic average consensus (DAC) is a decentralized estimation strategy in which a set of agents tracks the average of time-varying reference signals. Because DAC requires exchanging state information with neighbors, attackers may gain access to these states and infer private information. In this paper, we develop a privacy-preserving method that protects each agent's reference signal from external eavesdroppers and honest-but-curious agents while achieving the same convergence accuracy and convergence rate as conventional DAC. Our approach masks the reference signals by having each agent draw a random real number for each neighbor, exchanges that number over an encrypted channel at the initialization, and computes a masking value to form a masked reference. Then the agents run the conventional DAC algorithm using the masked references. Convergence and privacy analyses show that the proposed algorithm matches the convergence properties of conventional DAC while preserving the privacy of the reference signals. Numerical simulations validate the effectiveness of the proposed privacy-preserving DAC algorithm.

</details>


### [62] [GUARDIAN: Safety Filtering for Systems with Perception Models Subject to Adversarial Attacks](https://arxiv.org/abs/2602.06026)
*Nicholas Rober,Alex Rose,Jonathan P. How*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Safety filtering is an effective method for enforcing constraints in safety-critical systems, but existing methods typically assume perfect state information. This limitation is especially problematic for systems that rely on neural network (NN)-based state estimators, which can be highly sensitive to noise and adversarial input perturbations. We address these problems by introducing GUARDIAN: Guaranteed Uncertainty-Aware Reachability Defense against Adversarial INterference, a safety filtering framework that provides formal safety guarantees for systems with NN-based state estimators. At runtime, GUARDIAN uses neural network verification tools to provide guaranteed bounds on the system's state estimate given possible perturbations to its observation. It then uses a modified Hamilton-Jacobi reachability formulation to construct a safety filter that adjusts the nominal control input based on the verified state bounds and safety constraints. The result is an uncertainty-aware filter that ensures safety despite the system's reliance on an NN estimator with noisy, possibly adversarial, input observations. Theoretical analysis and numerical experiments demonstrate that GUARDIAN effectively defends systems against adversarial attacks that would otherwise lead to a violation of safety constraints.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [63] [Path Sampling for Rare Events Boosted by Machine Learning](https://arxiv.org/abs/2602.05167)
*Porhouy Minh,Sapna Sarupria*

Main category: physics.comp-ph

TL;DR: AIMMD是一种结合机器学习的新型采样算法，可提高过渡路径采样的效率，并能实时估计承诺概率和提取可解释的反应坐标，有助于揭示复杂分子过程的机制路径。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统过渡路径采样方法在复杂分子系统中效率低、难以识别有效反应坐标的问题，研究者提出了AIMMD框架。

Method: AIMMD通过集成机器学习模型，在运行过程中动态估计承诺概率，并同时构建人类可解释的反应坐标，从而加速分子机制发现中的路径采样过程。

Result: 该方法显著提升了过渡路径采样的效率，并成功应用于复杂分子过程的机制解析，同时提供了对反应路径的直观理解。

Conclusion: AIMMD为分子机制发现提供了一个强大且可解释的新工具，具有广泛的应用前景，但其性能依赖于训练数据质量和系统的复杂性，存在一定局限性。

Abstract: The study by Jung et al. (Jung H, Covino R, Arjun A, et al., Nat Comput Sci. 3:334-345 (2023)) introduced Artificial Intelligence for Molecular Mechanism Discovery (AIMMD), a novel sampling algorithm that integrates machine learning to enhance the efficiency of transition path sampling (TPS). By enabling on-the-fly estimation of the committor probability and simultaneously deriving a human-interpretable reaction coordinate, AIMMD offers a robust framework for elucidating the mechanistic pathways of complex molecular processes. This commentary provides a discussion and critical analysis of the core AIMMD framework, explores its recent extensions, and offers an assessment of the method's potential impact and limitations.

</details>


### [64] [Numerical Evaluation of Angle-Dependent IR-Transparent Radiative Cooling Performance for Asymmetric Periodic Structures](https://arxiv.org/abs/2602.05613)
*Junwoo Gim,Jun Heo,Weng Cho Chew,Dong-Yeop Na*

Main category: physics.comp-ph

TL;DR: 本文研究了红外透明被动辐射冷却（PRC）中角度分布的非对称红外透明性的重要性，指出仅在法向入射下表现出的非对称性不足以预测实际冷却性能。通过全角度电磁建模与热平衡模型结合，揭示了宽角积分下的冷却效果可能远低于法向近似预测，甚至可能导致净加热，提出了宽角非对称透明作为PRC设计的关键原则。


<details>
  <summary>Details</summary>
Motivation: 传统研究多关注法向入射下的非对称红外传输，但其是否能反映真实冷却性能尚不明确。为准确评估非接触式PRC的实际效果，需探究全角度范围内非对称透明的作用。

Method: 采用基于布洛赫周期边界条件和弗洛凯模式分解的角度分辨全波电磁模型，计算周期性PRC结构的波长和角度依赖双向反射与透射，并耦合基于能量平衡的热模型，模拟冷却物体的瞬态温度演化。

Result: 发现法向入射下显著的非对称传输在斜入射时通常无法保持，经半球积分后实际冷却效果微弱或出现净加热；仅使用法向入射的模型会高估冷却性能。

Conclusion: 有效的非接触式PRC必须考虑角度分布的非对称红外透明性，宽角范围内的集成响应是决定实际性能的关键，应成为PRC和宽角非对称超表面设计的核心电磁准则。

Abstract: Infrared (IR)-transparent passive radiative cooling (PRC) enables non-contact thermal management by regulating radiative heat exchange without direct attachment to the cooling object. While asymmetric IR transmission at a specific incidence angle -- typically normal incidence -- is often emphasized, we show that such single-angle asymmetry is neither sufficient nor predictive of practical cooling performance. In this work, we demonstrate that effective non-contact PRC requires angularly distributed asymmetric IR transparency evaluated through hemispherical integration over emission directions, rather than asymmetry at a single incidence angle. To quantify this effect, an angle-resolved full-wave electromagnetic (EM) model with Bloch periodic boundary conditions and Floquet mode decomposition is employed to compute wavelength- and angle-dependent bidirectional reflection and transmission of periodic PRC structures. The resulting EM response is coupled to an energy-balance-based thermal model to predict the transient temperature evolution of the cooling object. By comparing models that account for the full angular distribution with normal-incidence-only approximations, we show that pronounced asymmetric transmission at normal incidence is generally not preserved at oblique angles. As a result, angular integration yields only marginal cooling or may even result in net heating, whereas normal-incidence-based models can substantially overestimate cooling performance. These results establish angularly distributed asymmetric transparency as a key EM design principle for IR-transparent PRC and wide-angle asymmetric metasurfaces.

</details>


### [65] [The near-continuum mechanism for extended Boltzmann theory: the non-equilibrium relaxation](https://arxiv.org/abs/2602.05775)
*Sha Liu,Ningchao Ding,Ming Fang,Hao Jin,Rui Zhang,Congshan Zhuo,Chengwen Zhong*

Main category: physics.comp-ph

TL;DR: 本文采用具有可积碰撞核并满足细致平衡约束的Pullin方程，首次获得了宏观变量（应力、温度、热流等）弛豫过程的显式解析表达式，并在Chapman-Enskog框架下推导出依赖于热非平衡程度的输运系数，验证了长期以来关于热导率应受非平衡影响的猜想。基于此提出了一个新的Rykov型松弛模型，能够恢复平动与转动热流在弛豫过程中的耦合作用，并通过一系列基准测试验证了其精度。


<details>
  <summary>Details</summary>
Motivation: 现有聚原子气体碰撞模型（如Borgnakke-Larsen模型）缺乏内在细致平衡且不可积，无法准确描述近连续区的弛豫机制，因而需要一个更严格的理论框架来分析非平衡演化和输运系数的非平衡依赖性。

Method: 采用Pullin方程作为扩展Boltzmann方程，结合混合Hermite-Laguerre展开近似分布函数，计算碰撞算子矩，从而推导宏观变量弛豫的解析表达式，并在Chapman-Enskog框架下得到输运系数；进一步提出一种新型Rykov型松弛模型以捕捉平动与转动热流的耦合效应。

Result: 1. 首次获得应力、温度、热流等宏观变量弛豫的显式解析解；2. 严格证实并量化了热导率对热非平衡的依赖性；3. 在热平衡极限下，结果退化为Mason和Monchick的经典结论；4. 提出的新Rykov型模型能准确恢复平动与转动热流的相互作用。

Conclusion: Pullin方程为研究聚原子气体近连续区非平衡弛豫提供了严谨的理论基础，所提出的模型不仅揭示了非平衡效应对输运系数的影响，还显著提升了对多模式能量交换过程的模拟能力，经基准测试验证具有高精度。

Abstract: The collision phenomenon of polyatomic gases is described by the collision operator of extended Boltzmann equation or the energy-exchange model in particle direct simulations, for example, the Borgnakke-Larsen model. However, as a collision kernel, it dose not guarantee the entrinsic detailed balance and is not integrable. In this work, the Pullin equation, which possesses an integrable collision kernel and satisfies the detailed balance constraint, is adopted as an extended Boltzmann equation for the theoretical analysis of near-continuum relaxation mechanisms. For clarity, only the translational and rotational degrees are considered in this work. Explicit analytical expressions for the temporal relaxation of macroscopic variables, including the stress force, (translational/rotational) temperature and heat flux, are obtained at the first time. This is achieved by approximating the distribution function in mixed Hermite and Laguerre for rotation and computing the collision operator moments, enabling a direct description of macroscopic non-equilibrium evolution. Base on the same elementary moment (integral) of collision operator, the macroscopic transport coefficients is found in Chapman-Enskog framework. The long-standing speculation, that thermal conduction coefficient should be depended on the degrees of thermal non-equilibrium, is rigorously confirmed and evaluated. When thermal equilibrium is enforced, the present thermal conduction coefficients can be degenerated to the famous results of Mason and Monchick. Given the correct relaxation rate, a Rykov-type novel relaxation model for Pullin equation is proposed. It can recover the interaction of transaltional and rotatioanl heat fluxes in relaxation process, which is ignored in the widely used Rykov equation. Finally, the precision of this new Rykov-type equation is examined using a series of benchmark test cases.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [66] [A General-Purpose Diversified 2D Seismic Image Dataset from NAMSS](https://arxiv.org/abs/2602.04890)
*Lucas de Magalhães Araujo,Otávio Oliveira Napoli,Sandra Avila,Edson Borin*

Main category: physics.geo-ph

TL;DR: 本文介绍了Unicamp-NAMSS数据集，一个大规模、多样化且地理分布广泛的迁移2D地震剖面数据集，旨在支持地球物理学中的现代机器学习研究。


<details>
  <summary>Details</summary>
Motivation: 为了支持现代机器学习在地球物理领域的研究，需要一个具有广泛地质和采集条件多样性的高质量地震数据集。现有数据集覆盖范围有限，难以有效评估模型的泛化能力，因此构建一个更具代表性和鲁棒性的数据集成为迫切需求。

Method: 基于美国国家海洋地震调查档案（NAMSS）中多年积累的公开海上地震数据，经过全面的数据收集与筛选流程，最终从122个调查区域中提取出2588条清洗并标准化的地震剖面。通过平衡各调查区域的样本分布，并按非重叠的大区域划分训练、验证和测试集，实现地理上分离的划分策略，以确保实验可靠性。

Result: 定量分析和嵌入空间分析表明，Unicamp-NAMSS在区域内和区域间均表现出显著变异性，同时保持了不同采集大区和调查类型之间的结构一致性。与Parihaka和F3 Block等常用解释数据集相比，该数据集覆盖更广的地震外观空间。

Conclusion: Unicamp-NAMSS是一个适用于机器学习任务的宝贵资源，可用于自监督表示学习、迁移学习、超分辨率或属性预测等有监督任务的基准测试，以及地震解释中的领域适应研究，尤其适合作为预训练数据集提升模型泛化性能。

Abstract: We introduce the Unicamp-NAMSS dataset, a large, diverse, and geographically distributed collection of migrated 2D seismic sections designed to support modern machine learning research in geophysics. We constructed the dataset from the National Archive of Marine Seismic Surveys (NAMSS), which contains decades of publicly available marine seismic data acquired across multiple regions, acquisition conditions, and geological settings. After a comprehensive collection and filtering process, we obtained 2588 cleaned and standardized seismic sections from 122 survey areas, covering a wide range of vertical and horizontal sampling characteristics. To ensure reliable experimentation, we balanced the dataset so that no survey dominates the distribution, and partitioned it into non-overlapping macro-regions for training, validation, and testing. This region-disjoint split allows robust evaluation of generalization to unseen geological and acquisition conditions.
  We validated the dataset through quantitative and embedding-space analyses using both convolutional and transformer-based models. These analyses showed that Unicamp-NAMSS exhibits substantial variability within and across regions, while maintaining coherent structure across acquisition macro-region and survey types. Comparisons with widely used interpretation datasets (Parihaka and F3 Block) further demonstrated that Unicamp-NAMSS covers a broader portion of the seismic appearance space, making it a strong candidate for machine learning model pretraining. The dataset, therefore, provides a valuable resource for machine learning tasks, including self-supervised representation learning, transfer learning, benchmarking supervised tasks such as super-resolution or attribute prediction, and studying domain adaptation in seismic interpretation.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [67] [Rule-Based Spatial Mixture-of-Experts U-Net for Explainable Edge Detection](https://arxiv.org/abs/2602.05100)
*Bharadwaj Dogga,Kaaustaaub Shankar,Gibin Raju,Wilhelm Louw,Kelly Cohen*

Main category: cs.CE

TL;DR: 提出了一种结合空间自适应混合专家系统与模糊逻辑的U-Net变体（sMoE U-Net），在保持边缘检测性能的同时实现像素级可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型如U-Net在边缘检测中表现优异但缺乏可解释性，难以应用于安全关键领域，本文旨在构建一个兼具高性能与透明决策过程的模型。

Method: 在解码器跳跃连接中引入空间自适应混合专家（sMoE）模块，并用基于Takagi-Sugeno-Kang（TSK）的模糊头替代传统分类层，通过显式的IF-THEN规则融合深度语义特征与启发式边缘信号。

Result: 在BSDS500数据集上达到0.7628的ODS F-score，接近HED（0.7688），优于标准U-Net（0.7437），同时提供规则激活图和策略图实现像素级可解释性。

Conclusion: 所提方法在不显著牺牲性能的前提下，实现了对边缘检测决策过程的可视化与解释，为高安全性场景下的可信赖AI提供了新路径。

Abstract: Deep learning models like U-Net and its variants, have established state-of-the-art performance in edge detection tasks and are used by Generative AI services world-wide for their image generation models. However, their decision-making processes remain opaque, operating as "black boxes" that obscure the rationale behind specific boundary predictions. This lack of transparency is a critical barrier in safety-critical applications where verification is mandatory. To bridge the gap between high-performance deep learning and interpretable logic, we propose the Rule-Based Spatial Mixture-of-Experts U-Net (sMoE U-Net). Our architecture introduces two key innovations: (1) Spatially-Adaptive Mixture-of-Experts (sMoE) blocks integrated into the decoder skip connections, which dynamically gate between "Context" (smooth) and "Boundary" (sharp) experts based on local feature statistics; and (2) a Takagi-Sugeno-Kang (TSK) Fuzzy Head that replaces the standard classification layer. This fuzzy head fuses deep semantic features with heuristic edge signals using explicit IF-THEN rules. We evaluate our method on the BSDS500 benchmark, achieving an Optimal Dataset Scale (ODS) F-score of 0.7628, effectively matching purely deep baselines like HED (0.7688) while outperforming the standard U-Net (0.7437). Crucially, our model provides pixel-level explainability through "Rule Firing Maps" and "Strategy Maps," allowing users to visualize whether an edge was detected due to strong gradients, high semantic confidence, or specific logical rule combinations.

</details>


### [68] [Uncovering Residual Factors in Financial Time Series via PCA and MTP2-constrained Gaussian Graphical Models](https://arxiv.org/abs/2602.05580)
*Koshi Watanabe,Ryota Ozaki,Kentaro Imajo,Masanori Hirano*

Main category: cs.CE

TL;DR: 本文提出了一种分层应用主成分分析（PCA）和高斯图模型（GGM）的方法，用于从金融时间序列中提取残差因子，相较于传统PCA方法具有更强的正交性和更优的交易表现。


<details>
  <summary>Details</summary>
Motivation: 金融时间序列通常具有近奇异的特征结构，导致残差因子估计不稳定，难以有效剥离市场共性风险，从而影响基于残差因子的交易策略表现。

Method: 采用分层方法，先使用PCA提取市场因子，再利用MTP2约束的高斯图模型（GGM）进一步净化残差因子，以更好地消除未被PCA捕捉的共享波动并提升估计稳定性。

Result: 所提方法在S&P 500和TOPIX 500成分股上的实验表明，其生成的残差因子比单独使用PCA更具正交性，并在不同测试周期和训练长度下保持稳定；回测显示交易策略的夏普比率更高。

Conclusion: 分层结合PCA与MTP2约束GGM能更有效地提取稳定的残差因子，提升对市场噪声的鲁棒性，为残差驱动的量化策略提供了更优的因子构建框架。

Abstract: Financial time series are commonly decomposed into market factors, which capture shared price movements across assets, and residual factors, which reflect asset-specific deviations. To hedge the market-wide risks, such as the COVID-19 shock, trading strategies that exploit residual factors have been shown to be effective. However, financial time series often exhibit near-singular eigenstructures, which hinder the stable and accurate estimation of residual factors. This paper proposes a method for extracting residual factors from financial time series that hierarchically applies principal component analysis (PCA) and Gaussian graphical model (GGM). Our hierarchical approach balances stable estimation with elimination of factors that PCA alone cannot fully remove, enabling efficient extraction of residual factors. We use multivariate totally positive of order 2 (MTP2)-constrained GGM to capture the predominance of positive correlations in financial data. Our analysis proves that the resulting residual factors exhibit stronger orthogonality than those obtained with PCA alone. Across multiple experiments with varying test periods and training set lengths, the proposed method consistently achieved superior orthogonality of the residual factors. Backtests on the S&P 500 and TOPIX 500 constituents further indicate improved trading performance, including higher Sharpe ratios.

</details>


### [69] [Smoothed aggregation algebraic multigrid for problems with heterogeneous and anisotropic materials](https://arxiv.org/abs/2602.05686)
*Max Firmbach,Malachi Phillips,Christian Glusa,Alexander Popp,Christopher M. Siefert,Matthias Mayr*

Main category: cs.CE

TL;DR: 本文提出了一种材料感知的光滑聚合代数多重网格强度连接度量方法，通过引入材料张量信息改进了传统方法在异质和各向异性材料中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的强度连接度量方法仅依赖矩阵元素或几何距离，难以准确捕捉材料界面间的弱耦合或各向异性方向，导致收敛性能差。

Method: 将材料张量信息直接融入粗化过程，以可靠识别弱连接并保持问题的真实结构。

Result: 新方法能有效处理系数突变和方向性各向异性，在多种学术测试和实际应用中表现出对材料对比度、各向异性和网格变化的鲁棒性。

Conclusion: 该方法提升了代数多重网格法在复杂材料环境下的收敛性和可扩展性，适用于大规模高性能计算场景。

Abstract: This paper introduces a material-aware strength-of-connection measure for smoothed aggregation algebraic multigrid methods, aimed at improving robustness for scalar partial differential equations with heterogeneous and anisotropic material properties. Classical strength-of-connection measures typically rely only on matrix entries or geometric distances, which often fail to capture weak couplings across material interfaces or align with anisotropy directions, ultimately leading to poor convergence. The proposed approach directly incorporates material tensor information into the coarsening process, enabling a reliable detection of weak connections and ensuring that coarse levels preserve the true structure of the underlying problem. As a result, smooth error components are represented properly and sharp coefficient jumps or directional anisotropies are handled consistently. A wide range of academic tests and real-world applications, including thermally activated batteries and solar cells, demonstrate that the proposed method maintains robustness across material contrasts, anisotropies, and mesh variations. Scalability and parallel performance of the algebraic multigrid method highlight the suitability for large-scale, high-performance computing environments.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [70] [Graph--Theoretic Analysis of Phase Optimization Complexity in Variational Wave Functions for Heisenberg Antiferromagnets](https://arxiv.org/abs/2602.04943)
*Mahmud Ashraf Shamim,Moshiur Rahman,Mohamed Hibat-Allah,Paulo T Araujo*

Main category: cond-mat.str-el

TL;DR: 提出了一种将受挫海森堡反铁磁体波函数相位结构映射为希尔伯特图上加权Max-Cut问题的新方法，揭示了波函数符号结构与组合优化之间的联系。


<details>
  <summary>Details</summary>
Motivation: 系统刻画受挫海森堡反铁磁体波函数的相位结构尚未解决。

Method: 将希尔伯特空间表示为加权图（希尔伯特图），顶点为自旋构型，边由哈密顿量的非对角项生成，权重由波函数振幅乘积决定；固定振幅，限制相位为Z2值，将相位相关的变分能量映射为经典伊辛反铁磁模型。

Result: 相位重构问题转化为加权Max-Cut问题，证明其在最坏情况下是NP难的。

Conclusion: 建立了波函数符号结构与组合优化之间的直接联系，为研究受挫量子磁性提供了新视角。

Abstract: Despite extensive study, the phase structure of the wavefunctions in frustrated Heisenberg antiferromagnets (HAF) is not yet systematically characterized. In this work, we represent the Hilbert space of an HAF as a weighted graph, which we term the Hilbert graph (HG), whose vertices are spin configurations and whose edges are generated by off-diagonal spin-flip terms of the Heisenberg Hamiltonian, with weights set by products of wavefunction amplitudes. Holding the amplitudes fixed and restricting phases to $\mathbb{Z}_2$ values, the phase-dependent variational energy can be recast as a classical Ising antiferromagnet on the HG, so that phase reconstruction of the ground state reduces to a weighted Max-Cut instance. This shows that phase reconstruction HAF is worst-case NP-hard and provides a direct link between wavefunction sign structure and combinatorial optimization.

</details>


### [71] [Incommensurate pair-density-wave correlations in two-leg ladder $t$--$J$--$J_\perp$ model](https://arxiv.org/abs/2602.04945)
*Hanbit Oh,Julian May-Mann,Ya-Hui Zhang*

Main category: cond-mat.str-el

TL;DR: 发现了一种具有非公度对偶密度波关联的广义Luther-Emery液体相，该相在双链t-J模型中通过调控层间极化得以实现，并在掺杂和极化范围内稳定存在。


<details>
  <summary>Details</summary>
Motivation: 探索在双链t-J-J⊥ ladder模型中是否存在新的量子态，特别是在有限层极化下的配对机制和关联效应。

Method: 结合密度矩阵重整化群（DMRG）模拟与玻色化分析，研究不同层极化下的自旋和电荷关联行为。

Result: 发现了一个自旋能隙相，其中层间和层内对关联均呈现振荡但具有不同周期：层间表现为FFLO-like振荡，由费米动量失配驱动；层内则源于一层电荷与另一层自旋涨落的耦合。该iC-PDW态在较宽的掺杂和极化范围内稳定，但有限的层间跃迁会使其转变为具有电荷-4e关联的态。

Conclusion: 揭示了非公度对偶密度波态的存在及其物理机制，提出该模型可在光晶格平台实现，并可能与双层镍酸盐La3Ni2O7中的现象相关。

Abstract: We report the discovery of a generalized Luther-Emery liquid phase characterized by incommensurate pair-density-wave (iC-PDW) correlations in the two-leg $t$-$J$-$J_\perp$ ladder model. By tuning the potential difference between the legs, we explore the regime of intermediate layer polarization $P$. Combining density-matrix renormalization group (DMRG) simulations with bosonization analysis, we identify a spin-gapped phase at finite $P$, where the interlayer and intralayer pair correlations both oscillate, but with distinct periodicities. The interlayer correlations exhibit FFLO-like oscillations, driven by pairing between layers with mismatched Fermi momenta, with a period determined by their momentum difference. In contrast, the intralayer pair correlations arise from the coupling between charges on one layer and spin fluctuations on the opposite layer, with a momentum equal to twice the Fermi momentum of the opposite layer. The iC-PDW state is robust across a wide range of doping and polarization, although finite interlayer hopping eventually destabilizes it toward a state with charge-$4e$ correlations. We conclude by discussing the experimental realization of this model in optical lattice platforms and its relevance to the bilayer nickelate La$_3$Ni$_2$O$_7$.

</details>


### [72] [Giant bubbles of Fisher zeros in the quantum XY chain](https://arxiv.org/abs/2602.05899)
*Songtai Lv,Yang Liu,Erhai Zhao,Haiyuan Zou,Tao Xiang*

Main category: cond-mat.str-el

TL;DR: 提出基于复值逆温度和配分函数的新方法，利用热场动力学研究量子物质相，揭示XY链中非平凡的费舍尔零点行为与动力学关联。


<details>
  <summary>Details</summary>
Motivation: 探索强关联多体系统中非常规能隙行为的物理机制，特别是具有非平庸谱和动力学的量子物态。

Method: 采用复值逆温度和配分函数结合热场动力学（TFD），分析低能激发与费舍尔零点的对应关系，并通过量子XY链在外场中的模型进行验证。

Result: 发现振荡能隙在TFD谱形因子的长时动力学中表现为振荡行为；识别出靠近无能隙XX极限的大规模闭合费舍尔零点‘巨泡’，其对应的能量尺度与Luttinger液体理论预测不符，并发现该能量尺度与谱权重从高能向低能转移相关。

Conclusion: 费舍尔零点、动力学与激发之间存在深刻联系，为理解强关联体系中的非常规能隙行为提供了新途径。

Abstract: We demonstrate an alternative approach based on complex-valued inverse temperature and partition function to probe quantum phases of matter with nontrivial spectra and dynamics. It leverages thermofield dynamics (TFD) to quantitatively characterize quantum and thermal fluctuations, and exploit the correspondence between low-energy excitations and Fisher zeros. Using the quantum XY chain in an external field as a testbed, we show that the oscillatory gap behavior manifests as oscillations in the long-time dynamics of the TFD spectral form factor. We also identify giant bubbles, i.e. large-scale closed lines, of Fisher-zeros near the gapless XX limit. They provide a characteristic energy scale that seems to contradict the predictions of the low energy theory of a featureless Luttinger liquid. We identify this energy scale and relate the motion of these giant bubbles with varying external field to the transfer of spectral weight from high to low energies. The deep connection between Fisher zeros, dynamics, and excitations opens up promising avenues for understanding the unconventional gap behaviors in strongly correlated many-body systems.

</details>


### [73] [Information, Dissipation, and Planckian Optimality](https://arxiv.org/abs/2602.04953)
*Debanjan Chowdhury*

Main category: cond-mat.str-el

TL;DR: 提出了一种普适的量子费舍信息衡量下，耗散功在有限温度下产生可区分量子多体态变化的效率界限，该界限仅依赖于平衡态多体关联函数的解析结构，并在普朗克尺度处表现出特征交叉。


<details>
  <summary>Details</summary>
Motivation: 探索在有限温度下，耗散如何高效地生成可区分的量子态变化，并建立不依赖微观细节的普适界限。

Method: 基于平衡态多体关联函数的解析性质推导出频率分辨形式的普适界限，并分析其在普朗克能量尺度下的行为。

Result: 发现普朗克散射体处于最优性的边缘，表现出最大弛豫速率，同时维持信息-耗散效率；该界限可通过强关联电子系统的光学电导测量直接验证。

Conclusion: 奇异金属不仅是快速耗散系统，而且是在保持高效生成可区分性方面的最快系统，为理解耗散在量子态演化中的作用提供了新视角。

Abstract: We derive a universal bound on the efficiency with which "dissipated" work can generate distinguishable changes in a quantum many-body state at a finite temperature, as quantified by the quantum Fisher information. The bound follows solely from the analytic structure of equilibrium many-body correlators and is independent of all microscopic details. It takes a frequency-resolved form with a characteristic crossover at the Planckian scale, $ω_\star\sim k_B T/\hbar$. We find that Planckian scatterers sit at the edge of optimality, displaying maximal relaxation rate before information-dissipation efficiency collapses. This suggests strange metals are not just fast dissipators, but the fastest that remain efficient in generating distinguishability. The bounded quantity can be evaluated directly from optical conductivity measurements in strongly correlated electronic systems, offering a unique window into how dissipation generates distinguishable changes.

</details>


### [74] [lrux: Fast low-rank updates of determinants and Pfaffians in JAX](https://arxiv.org/abs/2602.05255)
*Ao Chen,Christopher Roth*

Main category: cond-mat.str-el

TL;DR: lrux是一个基于JAX的软件包，用于加速量子蒙特卡洛算法中行列式和Pfaffian的低秩更新，显著降低计算成本并支持现代加速器上的高效计算。


<details>
  <summary>Details</summary>
Motivation: 针对量子蒙特卡洛算法中波函数评估的计算瓶颈，需要高效更新行列式和Pfaffian的方法以提升计算效率。

Method: 实现低秩更新算法，将复杂度从O(n^3)降至O(n^2k)，支持延迟更新策略，并与JAX的JIT、自动微分等特性原生集成。

Result: 在GPU上的基准测试显示，大型矩阵下可达1000倍加速，有效减少内存流量并提升计算性能。

Conclusion: lrux能高效、可扩展地评估反对称波函数，可作为即插即用组件广泛应用于各类量子蒙特卡洛工作流。

Abstract: We present lrux, a JAX-based software package for fast low-rank updates of determinants and Pfaffians, targeting the dominant computational bottleneck in various quantum Monte Carlo (QMC) algorithms. The package implements efficient low-rank updates that reduce the cost of successive wavefunction evaluations from $\mathcal{O}(n^3)$ to $\mathcal{O}(n^2k)$ when the update rank $k$ is smaller than the dimension $n$ of matrices. Both determinant and Pfaffian updates are supported, together with delayed-update strategies that trade floating-point operations for reduced memory traffic on modern accelerators. lrux natively integrates with JAX transformations such as JIT compilation, vectorization, and automatic differentiation, and supports both real and complex data types. Benchmarks on GPUs demonstrate up to $1000\times$ speedup at large matrix sizes. lrux enables scalable, high-performance evaluation of antisymmetric wavefunctions and is designed as a drop-in component for a wide range of QMC workflows. lrux is available at https://github.com/ChenAo-Phys/lrux.

</details>


### [75] [Spin current generation via magnetic skyrmion, bimeron, and meron crystals](https://arxiv.org/abs/2602.05332)
*Aoi Kajihara,Shun Okumura,Yukitoshi Motome*

Main category: cond-mat.str-el

TL;DR: 本研究探讨了二维拓扑自旋结构（如斯格明子、双半子和半子晶体）在无净磁化情况下生成自旋电流的能力，发现自旋轨道耦合和贝里曲率在调控自旋输运中起关键作用，拓展了基于拓扑磁性金属的自旋电子器件设计。


<details>
  <summary>Details</summary>
Motivation: 开发高效生成自旋电流的方法是自旋电子学的核心挑战，特别是探索无需净磁化的新型自旋源。

Method: 通过理论分析二维拓扑自旋纹理（SkX、BmX、MX）的自旋输运行为，结合自旋轨道耦合效应与磁对称性分析其产生的自旋电流特征。

Result: 发现SkX和BmX在无自旋轨道耦合时沿磁化方向产生自旋电流，MX不产生；引入自旋轨道耦合后，BmX可在多方向产生电流，而MX因能带简并增强的自旋贝里曲率表现出显著的面外自旋极化电流。

Conclusion: 拓扑自旋纹理即使在零净磁化下也能高效产生自旋电流，其输运特性由磁对称性和自旋贝里曲率决定，为拓扑磁性金属器件提供了新设计路径。

Abstract: Spin current offers a promising route toward energy-efficient and high-speed information processing. Developing efficient methods for their generation remains a central challenge in spintronics. Here, we investigate spin current generation via two-dimensional topological spin textures: a skyrmion crystal (SkX) with out-of-plane magnetization, a bimeron crystal (BmX) with in-plane magnetization, and a meron crystal (MX) with zero net magnetization. We show that these distinct spin textures generate spin currents with characteristic spin polarization directions. In the absence of spin--orbit coupling, the SkX and BmX generate spin currents polarized along their magnetization directions, whereas the MX yields no spin current. Upon introducing spin--orbit coupling, while the behavior of the SkX does not qualitatively change, the BmX generates nonzero spin currents in multiple polarization directions. Notably, the MX, despite its zero net magnetization, exhibits a pronounced spin current with out-of-plane spin polarization, driven by an enhanced spin Berry curvature associated with characteristic band degeneracy. We further demonstrate that the electronic and spin transport properties of each texture are governed by their magnetic symmetries. Our results highlight the topological spin textures as efficient sources of spin current even without net magnetization, expanding the design for spintronics devices based on topological magnetic metals.

</details>


### [76] [Spectroscopic Evidence of Competing Diagonal Spin Interactions and Spin Disproportionation in the Bilayer Nickelate La$_3$Ni$_2$O$_7$](https://arxiv.org/abs/2602.05365)
*Dong-Hyeon Gim,Dirk Wulferding,Hengyuan Zhang,Meng Wang,Kee Hoon Kim*

Main category: cond-mat.str-el

TL;DR: 该研究通过拉曼散射揭示了双层镍酸盐La₃Ni₂O₇在自旋密度波态下的电子、磁性和晶格激发特性，发现其基态具有竞争性键对角相互作用、自旋歧化和晶格不稳定性，为理解镍酸盐超导机制提供了关键线索。


<details>
  <summary>Details</summary>
Motivation: 理解双层镍酸盐中电子关联、磁性与晶格耦合的本质，探索其超导机制的关键因素。

Method: 在常压下利用拉曼散射技术系统研究La₃Ni₂O₇的电子、磁性和晶格激发谱，并结合自旋波理论计算分析双 magnon 激发来源。

Result: 在153 K以下观测到A_{1g}通道的电子能隙及等吸点；B_{1g}和B_{2g}通道呈现显著的双magnon激发，表明存在两种不同的面内自旋交换作用；B_{2g}中的双magnon模式源于d_{x²-y²}轨道介导的竞争性反铁磁相互作用；发现低于10 meV的低能双magnon激发，支持自旋歧化；同时观察到B_{1g}声子从280 K到4.5 K的异常软化，暗示存在导致棋盘型呼吸模调制的晶格不稳定性。

Conclusion: 双层镍酸盐La₃Ni₂O₇的基态由竞争性键对角相互作用、自旋歧化和晶格不稳定性共同决定，这些要素是理解其超导机制的核心。

Abstract: A comprehensive spectroscopic map of the electronic, magnetic, and lattice excitations is presented for the bilayer nickelate La$_3$Ni$_2$O$_7$ using Raman scattering at ambient pressure. Upon entering the spin density wave state below 153 K, the $A_{1g}$ channel exhibits an abrupt electronic spectral gap with a clear isosbestic point. In contrast, the $B_{1g}$ and $B_{2g}$ channels are dominated by pronounced two-magnon (2M) excitations, representing an unambiguous signature of incipient Mottness. These 2M signals in both channels constitute direct evidence for two distinct in-plane spin exchange interactions along the Ni-O bonding and its diagonal directions. Calculations based on the spin wave theory further reveal that the 2M mode in the $B_{2g}$ channel arises from the competition between two bond-diagonal antiferromagnetic interactions mediated by nickel $d_{x^2-y^2}$ orbitals. Furthermore, emergent low-energy 2M excitations below 10 meV are found to originate from distinct, weaker spin moments, strongly supporting spin disproportionation. Simultaneously, an anomalous softening of $B_{1g}$ phonons from 280 down to 4.5 K is uncovered, suggesting the presence of an incipient lattice instability leading to checkerboard-type breathing modulations. Collectively, these findings identify a ground state of the bilayer nickelate characterized by competing bond-diagonal interactions, spin disproportionation, and an incipient lattice instability, establishing key ingredients for understanding the mechanism of nickelate superconductivity.

</details>


### [77] [Microscopic origin of an exceptionally large phonon thermal Hall effect from charge puddles in a topological insulator](https://arxiv.org/abs/2602.05569)
*Rohit Sharma,Yongjian Wang,Yoichi Ando,Achim Rosch,Thomas Lorenz*

Main category: cond-mat.str-el

TL;DR: 在拓扑绝缘体TlBi$_{0.15}$Sb$_{0.85}$Te$_2$中观察到显著增强的热霍尔效应，尽管热输运由声子主导，但在几特斯拉的磁场下热霍尔比超过2%，归因于电荷杂质形成的局域导电区域通过电子-声子耦合对声子产生显著热霍尔效应。


<details>
  <summary>Details</summary>
Motivation: 探索非磁性拓扑绝缘体材料中热霍尔效应的微观起源，尤其是声子主导热输运下为何仍能观察到显著的热霍尔信号。

Method: 通过实验测量TlBi$_{0.15}$Sb$_{0.85}$Te$_2$在不同磁场下的横向与纵向热导率，并结合电子-声子耦合模型分析其场依赖特性以确定效应来源。

Result: 观测到热霍尔比κ_{xy}/κ_{xx}超过2%，且κ_{xy}在几特斯拉磁场下出现峰值，该行为可通过局域电荷聚集区（电荷水坑）与声子的耦合机制解释。

Conclusion: 电荷杂质诱导的局域导电区域通过电子-声子相互作用将大热霍尔效应传递给声子，揭示了非磁性材料中巨热霍尔效应的微观机制。

Abstract: We present the experimental observation of a drastically enhanced thermal Hall effect in the topological insulator material TlBi$_{0.15}$Sb$_{0.85}$Te$_2$. Although heat transport is dominated by phonons, moderate magnetic fields generate a thermal Hall ratio ($κ_{xy}/κ_{xx}$) above 2\%, an unprecedented value for a nonmagnetic material. The transverse thermal conductivity $κ_{xy}$ exhibits a pronounced maximum in fields of a few Tesla. This characteristic field dependence allows us to identify the microscopic origin of the thermal Hall effect in this system. Small densities of charged impurities induce locally conducting regions, so-called charge puddles, within the bulk insulating matrix. Via electron-phonon coupling, these charge puddles imprint a large thermal Hall effect onto the phonons accounting for both the magnitude and the magnetic-field dependence of the observed effect.

</details>


### [78] [A steady-state study of the nonequilibrium properties of realistic materials: Application of the mixed-configuration approximation](https://arxiv.org/abs/2602.05664)
*Tommaso Maria Mazzocchi,Markus Aichhorn,Enrico Arrigoni*

Main category: cond-mat.str-el

TL;DR: 提出基于辅助主方程方法的混合构型近似（MCA），用于在平衡和非平衡条件下研究多轨道关联体系，验证其在SrVO3中的应用并展示其在电压偏置下捕捉轨道电荷转移的能力。


<details>
  <summary>Details</summary>
Motivation: 发展一种适用于平衡与非平衡多轨道强关联体系的有效动力学平均场理论（DMFT）方法，以克服现有数值求解器在处理复杂系统时的局限性。

Method: 采用基于辅助主方程的混合构型近似（MCA）作为DMFT的杂质求解器，并在体相和层状SrVO3中进行基准测试，同时应用于施加电压偏置的非平衡几何结构。

Result: MCA在中等相互作用强度下重现了SrVO3的金属态，但相较于QMC和FTPS方法高估了下带权重，并提前预测金属-绝缘体转变；在层状SrVO3中部分捕捉到xy轨道的极化，在单次计算中结合QMC初值得到更强的电荷极化；在偏压下成功观测到显著的轨道占据再分布。

Conclusion: MCA是一种可用于研究多轨道杂质问题的有效方法，尤其适合无需完整DMFT自洽循环即可评估系统性质的情况，并能有效捕捉非平衡条件下的轨道电荷转移现象。

Abstract: We present the mixed-configuration approximation (MCA) based on the auxiliary master equation approach impurity solver to study multiorbital correlated systems under equilibrium and nonequilibrium conditions within dynamical mean-field theory (DMFT). We benchmark the method for bulk and layered SrVO$_3$ in equilibrium and apply it to a prototypical nonequilibrium geometry in which a voltage bias is applied perpendicular to the layer via reservoirs held at different chemical potentials. For bulk SrVO$_3$, MCA reproduces the metallic state at moderate interaction strengths, but it overestimates the weight of the lower band relative to quantum Monte Carlo (QMC) and fork tensor product state (FTPS) solvers. With respect to QMC and FTPS, MCA yields an earlier metal-to-insulator transition as the electron-electron interaction is increased. In layered SrVO$_3$ at equilibrium, MCA partially captures the orbital polarization in favor of the in-plane $xy$ orbital, although not as strong as in the DMFT-converged results obtained with QMC. However, when performing a one-shot impurity calculation initialized with the DFMT-QMC results, MCA yields orbital occupations which show a stronger charge polarization in favor of orbital $xy$. This suggests that our approach can be used to study multiorbital impurity problems when the focus is to assess properties without performing the full DMFT self-consistent loop. Finally, under applied bias, we observe a pronounced redistribution of orbital occupations, demonstrating that the method captures bias-driven orbital charge transfer in realistic materials in nonequilibrium conditions.

</details>


### [79] [Suppressed coarsening after an interaction quench in the Holstein chain](https://arxiv.org/abs/2602.05815)
*Ho Jang,Gia-Wei Chern*

Main category: cond-mat.str-el

TL;DR: 研究了半填充的半经典Holstein模型中由相互作用淬火引发的非平衡动力学，发现三种不同的动力学区域，并揭示了一种由内部量子动力学驱动的反常缺陷动力学机制。


<details>
  <summary>Details</summary>
Motivation: 探索孤立混合量子-经典系统中非平衡动力学的行为，特别是在淬火后电声耦合变化下的演化特性。

Method: 在Ehrenfest非绝热框架下，通过数值模拟分析相互作用淬火后的半经典Holstein模型的动力学演化，重点研究电子-声子耦合对缺陷密度演化的影响。

Result: 识别出三个动力学区域：无CDW序的金属态、具有慢标度不变序的中间态和冻结的CDW态；中间区域中kink密度呈反常代数衰减 $n \sim t^{-1/3}$，源于电子自由度作为内禀热浴导致的扩散运动但无能量耗散。

Conclusion: 揭示了孤立混合量子-经典系统中一种新的粗化机制，表明内部量子自由度可显著改变非平衡条件下的缺陷动力学行为。

Abstract: We investigate the nonequilibrium dynamics induced by an interaction quench in the semiclassical Holstein model within the Ehrenfest nonadiabatic framework, which describes an isolated hybrid quantum-classical system with strictly conserved total energy. Focusing on the half-filled case, where the equilibrium ground state exhibits commensurate charge-density-wave (CDW) order for any nonzero coupling, we identify three distinct post-quench dynamical regimes as a function of the final electron-phonon coupling: a nonequilibrium metallic state without CDW order, an intermediate regime characterized by slow scale-invariant ordering dynamics, and a frozen CDW state with arrested coarsening and immobile kinks. We analyze the intermediate regime in detail and uncover an unconventional algebraic decay of the kink density, $n \sim t^{-1/3}$, distinct from both ballistic annihilation and diffusive coarsening in classical dissipative systems. We show that this anomalous exponent arises from the hybrid nature of the dynamics: while the lattice evolves deterministically, the electronic degrees of freedom act as an effective internal bath that induces diffusive kink motion without energy dissipation. An effective reaction-diffusion description, incorporating both annihilation and elastic scattering of kinks, quantitatively accounts for the observed scaling behavior. Our results reveal a distinct coarsening mechanism in isolated hybrid systems, demonstrating how internal quantum dynamics can qualitatively reshape defect kinetics far from equilibrium.

</details>


### [80] [Topological piezomagnetic effect in two-dimensional Dirac quadrupole altermagnets](https://arxiv.org/abs/2602.05894)
*H. Radhakrishnan,B. Bell,C. Ortix,J. W. F. Venderbos*

Main category: cond-mat.str-el

TL;DR: 本文提出了一类二维绝缘体中的狄拉克四极型反铁磁材料，并基于微观模型揭示其轨道压磁极化率具有拓扑贡献，表明应变通过调控形成四极的狄拉克点引发拓扑压磁效应。


<details>
  <summary>Details</summary>
Motivation: 探索反铁磁材料中压磁性的新机制，特别是利用拓扑响应理论理解应变对电子结构的影响。

Method: 构建并分析两个微观最小模型：描述s和d态带反转的无自旋两带模型，以及具有共线奈尔序的Lieb晶格模型。

Result: 发现狄拉克四极型反铁磁体的压磁响应存在拓扑贡献，其低能电子结构源于狄拉克四极半金属相，且应变可调控狄拉克点从而产生拓扑压磁效应。

Conclusion: 狄拉克四极型反铁磁体为实现和调控拓扑压磁效应提供了理想平台，相关模型与近期提出的材料体系密切相关，具有潜在应用价值。

Abstract: Altermagnets provide a natural platform for studying and exploiting piezomagnetism. In this paper, we introduce a class of insulating altermagnets in two dimensions (2D) referred to as Dirac quadrupole altermagnets, and show based on microscopic minimal models that the orbital piezomagnetic polarizability of such altermagnets has a topological contribution described by topological response theory. The essential low-energy electronic structure of Dirac quadrupole altermagnets can be understood from a gapless parent phase (i.e., the Dirac quadrupole semimetal), which has important implications for their response to external fields. Focusing on the strain-induced response, here we demonstrate that the topological piezomagnetic effect is a consequence of the way in which strain affects the Dirac points forming a quadrupole. We consider two microscopic models: a spinless two-band model describing a band inversion of $s$ and $d$ states, and a Lieb lattice model with collinear Néel order. The latter is a prototypical minimal model for altermagnetism in 2D and is realized in a number of recently proposed material compounds, which are discussed.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [81] [Higher-order adaptive behaviors outperform pairwise strategies in mitigating contagion dynamics](https://arxiv.org/abs/2602.05915)
*Marco Mancastroppa,Márton Karsai,Alain Barrat*

Main category: physics.soc-ph

TL;DR: 该研究探讨了基于高阶和成对交互的适应性行为对传染病传播的影响，发现基于高阶信息的适应性行为在抑制传播方面更有效，并且社会成本更低。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解个体在面对传染风险时的适应性行为如何通过高阶交互影响传播动态，以及这些行为的社会成本。

Method: 通过数值模拟和平均场解析方法，比较了基于高阶和成对信息的适应性行为在不同传播过程中的效果。

Result: 基于高阶信息的适应性行为比基于成对信息的行为更能有效限制传播，同时减少社会互动强度，降低社会成本。高阶信息导致群体内异质性风险感知，阻止传播利用高超度节点和大群体的特性。

Conclusion: 高阶信息驱动的适应性行为在控制传染病传播方面优于成对信息机制，且具有更低的社会成本。

Abstract: When exposed to a contagion phenomenon, individuals may respond to the perceived risk of infection by adopting behavioral changes, aiming to reduce their exposure or their risk of infecting others. The social cost of such adaptive behaviors and their impact on the contagion dynamics have been investigated in pairwise networks, with binary interactions driving both contagion and risk perception. However, contagion and adaptive mechanisms can also be driven by group (higher-order) interactions. Here, we consider several adaptive behaviors triggered by awareness of risk perceived through higher-order and pairwise interactions, and we compare their impact on pairwise and higher-order contagion processes. By numerical simulations and a mean-field analytic approach, we show that adaptive behaviors driven by higher-order information are more effective in limiting the spread of a contagion, than similar mechanisms based on pairwise information. Meanwhile, they also entail a lower social cost, measured as the reduction of the intensity of interactions in the population. Indeed, adaptive mechanisms based on higher-order information lead to a heterogeneous risk perception within the population, producing a higher alert on nodes with large hyperdegree (i.e., participating in many groups), on their neighborhoods, and on large groups. This in turn prevents the spreading process to exploit the properties of these nodes and groups, which tend to drive and sustain the dynamics in the absence of adaptive behaviors.

</details>


### [82] [Modelling Pedestrian Behaviour in Autonomous Vehicle Encounters Using Naturalistic Dataset](https://arxiv.org/abs/2602.05142)
*Rulla Al-Haideri,Bilal Farooq*

Main category: physics.soc-ph

TL;DR: 本研究基于NuScenes数据集，采用ResLogit混合模型分析行人与自动驾驶车辆在路段中段交互时的微观行为，发现风险感知存在方向不对称性，且剩余距离可能存在阈值效应。


<details>
  <summary>Details</summary>
Motivation: 理解行人在与自动驾驶车辆互动时如何调整移动行为，对提升混合交通环境下的安全性至关重要。

Method: 采用基于Residual Logit（ResLogit）模型的混合离散选择-机器学习框架，结合时间、空间、运动学和感知指标（如相对速度、视觉逼近、剩余距离和方向性碰撞风险 proximity, CRP）分析行人行为。

Result: 部分变量显著影响行人的运动调整，但模型预测性能中等；边际效应和弹性分析显示风险感知存在强烈的方向不对称性，前向与后向CRP影响相反；剩余距离可能存在中段穿越阈值；相对速度的影响相对较弱。

Conclusion: 行人的行为模式可能同时受到风险感知和移动效率双重因素驱动，研究结果有助于优化自动驾驶车辆的决策系统以更好适应行人行为。

Abstract: Understanding how pedestrians adjust their movement when interacting with autonomous vehicles (AVs) is essential for improving safety in mixed traffic. This study examines micro-level pedestrian behaviour during midblock encounters in the NuScenes dataset using a hybrid discrete choice-machine learning framework based on the Residual Logit (ResLogit) model. The model incorporates temporal, spatial, kinematic, and perceptual indicators. These include relative speed, visual looming, remaining distance, and directional collision risk proximity (CRP) measures. Results suggest that some of these variables may meaningfully influence movement adjustments, although predictive performance remains moderate. Marginal effects and elasticities indicate strong directional asymmetries in risk perception, with frontal and rear CRP showing opposite influences. The remaining distance exhibits a possible mid-crossing threshold. Relative speed cues appear to have a comparatively less effect. These patterns may reflect multiple behavioural tendencies driven by both risk perception and movement efficiency.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [83] [Evaluating Kubernetes Performance for GenAI Inference: From Automatic Speech Recognition to LLM Summarization](https://arxiv.org/abs/2602.04900)
*Sai Sindhur Malleni,Raúl Sevilla,Aleksei Vasilevskii,José Castillo Lema,André Bauer*

Main category: cs.ET

TL;DR: 本文探讨了Kubernetes生态系统如何通过新兴的原生项目（如Kueue、DAS和GAIE）支持生成式AI推理工作负载，提升语音识别与文本摘要等多阶段AI任务的性能。实验结果表明，这些工具在批处理和在线推理场景中显著优化了执行效率和响应速度。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI特别是推理任务成为主流工作负载，传统系统难以满足其对可扩展性和资源效率的需求，因此需要利用Kubernetes原生技术来统一管理复杂的AI工作流。

Method: 结合使用Kueue进行批处理作业调度、动态加速器切片（DAS）提高并行执行能力，以及基于Kubernetes Gateway API推理扩展（GAIE）的llm-d方案优化在线推理请求路由，构建端到端的AI推理平台。

Result: 实验结果显示：Kueue最多减少15%的总执行时间；DAS使平均任务完成时间缩短36%；GAIE将首令牌时间加快82%。

Conclusion: Kueue、DAS和GAIE等Kubernetes原生组件能够协同构建高性能、统一的生成式AI基础设施，验证了Kubernetes作为AI工作负载基础平台的潜力。

Abstract: As Generative AI (GenAI), particularly inference, rapidly emerges as a dominant workload category, the Kubernetes ecosystem is proactively evolving to natively support its unique demands. This industry paper demonstrates how emerging Kubernetes-native projects can be combined to deliver the benefits of container orchestration, such as scalability and resource efficiency, to complex AI workflows. We implement and evaluate an illustrative, multi-stage use case consisting of automatic speech recognition and summarization. First, we address batch inference by using Kueue to manage jobs that transcribe audio files with Whisper models and Dynamic Accelerator Slicer (DAS) to increase parallel job execution. Second, we address a discrete online inference scenario by feeding the transcripts to a Large Language Model for summarization hosted using llm-d, a novel solution utilizing the recent developments around the Kubernetes Gateway API Inference Extension (GAIE) for optimized routing of inference requests. Our findings illustrate that these complementary components (Kueue, DAS, and GAIE) form a cohesive, high-performance platform, proving Kubernetes' capability to serve as a unified foundation for demanding GenAI workloads: Kueue reduced total makespan by up to 15%; DAS shortened mean job completion time by 36%; and GAIE improved Time to First Token by 82\%.

</details>


### [84] [Task-Adaptive Physical Reservoir Computing via Tunable Molecular Communication Dynamics](https://arxiv.org/abs/2602.05931)
*Saad Yousuf,Kaan Burak Ikiz,Murat Kuscu*

Main category: cs.ET

TL;DR: 本文提出了一种基于分子通信通道的可重构物理储层计算模型，通过调节生物物理参数实现任务自适应计算，并利用贝叶斯优化识别不同计算模式的操作区间，展示了其在时间序列预测与非线性数据转换中的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的物理储层计算系统多为静态结构，计算能力受限于固定架构，难以适应多样化的时序任务。本文旨在探索一种动态可调、具备生物启发性的储层计算范式，以提升物理计算系统的灵活性与通用性。

Method: 采用双模拟方法：基于确定性均场模型进行高效计算，结合高保真粒子级随机模拟工具Smoldyn；通过调控配体-受体动力学和扩散动态等关键生物物理参数，重构分子通信通道的计算特性，并使用贝叶斯优化在高维参数空间中搜索最优配置。

Result: 发现两类显著不同的操作模式：高信道记忆的参数组擅长混沌时间序列预测（如Mackey-Glass），而强受体非线性的设置更适用于非线性数据变换；并通过后处理方法有效抑制分子噪声，提升随机储层性能。

Conclusion: 分子通信通道可作为可调谐、生物启发的计算平台的设计蓝图，不仅拓展了物理储层计算的能力边界，还为未来湿件AI系统的实现提供了明确的优化框架。

Abstract: Physical Reservoir Computing (PRC) offers an efficient paradigm for processing temporal data, yet most physical implementations are static, limiting their performance to a narrow range of tasks. In this work, we demonstrate in silico that a canonical Molecular Communication (MC) channel can function as a highly versatile and task-adaptive PRC whose computational properties are reconfigurable. Using a dual-simulation approach -- a computationally efficient deterministic mean-field model and a high-fidelity particle-based stochastic model (Smoldyn) -- we show that tuning the channel's underlying biophysical parameters, such as ligand-receptor kinetics and diffusion dynamics, allows the reservoir to be optimized for distinct classes of computation. We employ Bayesian optimization to efficiently navigate this high-dimensional parameter space, identifying discrete operational regimes. Our results reveal a clear trade-off: parameter sets rich in channel memory excel at chaotic time-series forecasting tasks (e.g., Mackey Glass), while regimes that promote strong receptor nonlinearity are superior for nonlinear data transformation. We further demonstrate that post-processing methods improve the performance of the stochastic reservoir by mitigating intrinsic molecular noise. These findings establish the MC channel not merely as a computational substrate, but as a design blueprint for tunable, bioinspired computing systems, providing a clear optimization framework for future wetware AI implementations.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [85] [Scalable testing of quantum error correction](https://arxiv.org/abs/2602.04921)
*John Zhuoyang Ye,Jens Palsberg*

Main category: quant-ph

TL;DR: 提出了一种结合分层故障注入与外推的可扩展量子纠错基准测试方法，显著提升了大规模系统下的测试效率。


<details>
  <summary>Details</summary>
Motivation: 现有的量子纠错基准测试工具（如\stim）在低物理错误率和大距离情况下扩展性差，难以高效评估大尺度系统的逻辑错误率。

Method: 采用分层故障注入策略，对可高效采样的故障空间进行采样，并利用外推法完成整体错误率估计。

Result: 在物理错误率为0.0005的情况下，该方法可在桌面计算机两小时内扩展到距离17，估计逻辑错误率为$1.51 \times 10^{-11}$且具有高置信度。

Conclusion: 所提出的分层采样结合外推的方法显著提高了量子纠错基准测试的可扩展性和效率，适用于大距离和低错误率场景。

Abstract: The standard method for benchmarking quantum error-correction is randomized fault-injection testing. The state-of-the-art tool \stim is efficient for error correction implementations with distances of up to 10, but scales poorly to larger distances for low physical error rates. In this paper, we present a scalable approach that combines stratified fault injection with extrapolation. Our insight is that some of the fault space can be sampled efficiently, after which extrapolation is sufficient to complete the testing task. As a result, our tool scales to distance 17 for a physical error rate of 0.0005 with a two-hour time budget on a desktop. For this case, it estimated a logical error rate of $1.51 \times 10^{-11}$ with high confidence.

</details>


### [86] [Agnostic Parameter Estimation with Large Spins](https://arxiv.org/abs/2602.04934)
*Huining Zhang,X. X. Yi*

Main category: quant-ph

TL;DR: 本文提出利用大自旋探针与辅助量子比特的纠缠，在无需先验知道旋转轴的情况下实现旋转角度估计的最优量子费舍信息，扩展了此前仅适用于自旋-1/2系统的方法，并指出大自旋情况下通常需要后选择，且成功率依赖于希尔伯特空间维度。


<details>
  <summary>Details</summary>
Motivation: 在量子传感中，当旋转轴未知时，传统方法无法达到最大的量子费舍信息，限制了估计精度；本文旨在突破这一限制，尤其拓展到大自旋探针以获得更高的计量优势。

Method: 利用大自旋探针与辅助量子比特之间的纠缠，在旋转轴揭示后通过测量辅助比特实现探针态的最优制备，并研究从最大纠缠态到一般纠缠态的推广方案。

Result: 实现了对任意未知旋转轴下旋转角度估计的最优量子费舍信息；发现大自旋系统通常需后选择，其成功概率依赖于希尔伯特空间的维度；即使使用非最大纠缠态，仍可在一定成功概率下实现最优计量。

Conclusion: 通过大自旋与辅助比特的纠缠可克服旋转轴未知带来的限制，实现最优参数估计，为高精度量子传感提供了可扩展的新途径。

Abstract: The quantum Fisher information of a quantum state with respect to a certain parameter quantifies the sensitivity of the quantum state to changes in that parameter. Maximizing the quantum Fisher information is essential for achieving the optimal estimation precision of quantum sensors. A typical quantum sensor involves a qubit(e.g. a spin-1/2) probe undergoing an unknown rotation, here the unknown rotation angle is the parameter to be estimated. A well known limitation is that if the rotation axis is unknown, the maximal quantum Fisher information is impossible to attain. This limitation has been lifted recently by leveraging entanglement between the probe qubit and an ancilla qubit. Namely, through measurement of the ancilla after the axis is revealed, one can prepare the probe that is optimal for any unknown rotation axis. This proposal, however, works only for a spin-1/2. Considering large spin probes can achieve a larger quantum Fisher information, offering enhanced metrological advantage, we here utilize the entanglement between a large spin probe and an ancilla to achieve optimal quantum Fisher information for estimating the rotation angle, without prior knowledge of the rotation axis. Different from the previous spin-1/2 case, achieving the optimal precision with large spins generally requires post-selection, resulting in a success probability dependent on the dimension of the Hilbert space. Furthermore, we extend the encoding state from the maximally entangled case to general entangled states, showing that optimal metrology can still be achieved with a certain success probability.

</details>


### [87] [Instance-optimal high-precision shadow tomography with few-copy measurements: A metrological approach](https://arxiv.org/abs/2602.04952)
*Senrui Chen,Weiyuan Gong,Sisi Zhou*

Main category: quant-ph

TL;DR: 本文研究了在高精度和现实测量约束下的阴影层析成像的样本复杂度，提出了一个实例最优的样本复杂度刻画 $\tildeΘ(Γ_p/ε^2)$，并建立了量子学习与计量学之间的定量联系。


<details>
  <summary>Details</summary>
Motivation: 在高精度条件下，现有方法对阴影层析成像的样本复杂度分析不足，尤其缺乏对一般可观测量集合和Lp范数误差下的紧界刻画。

Method: 通过定义基于逆Fisher信息矩阵的优化公式来刻画 $Γ_p$，分析单拷贝和多拷贝测量下的样本复杂度，并提出结合粗略层析与局部估计的两步算法实现上界。

Result: 得到了适用于一般情况的样本复杂度紧界 $\tildeΘ(Γ_p/ε^2)$，证明了该界在无偏有界估计下是必要且充分的，并揭示了允许c拷贝测量最多仅能将样本复杂度改善 $Ω(1/c)$。

Conclusion: 本文实现了量子学习与量子计量学之间的统一，为高精度阴影层析提供了实例最优的理论保证。

Abstract: We study the sample complexity of shadow tomography in the high-precision regime under realistic measurement constraints. Given an unknown $d$-dimensional quantum state $ρ$ and a known set of observables $\{O_i\}_{i=1}^m$, the goal is to estimate expectation values $\{\mathrm{tr}(O_iρ)\}_{i=1}^m$ to accuracy $ε$ in $L_p$-norm, using possibly adaptive measurements that act on $O(\mathrm{polylog}(d))$ number of copies of $ρ$ at a time. We focus on the regime where $ε$ is below an instance-dependent threshold.
  Our main contribution is an instance-optimal characterization of the sample complexity as $\tildeΘ(Γ_p/ε^2)$, where $Γ_p$ is a function of $\{O_i\}_{i=1}^m$ defined via an optimization formula involving the inverse Fisher information matrix. Previously, tight bounds were known only in special cases, e.g. Pauli shadow tomography with $L_\infty$-norm error. Concretely, we first analyze a simpler oblivious variant where the goal is to estimate an observable of the form $\sum_{i=1}^m α_i O_i$ with $\|α\|_q = 1$ (where $q$ is dual to $p$) revealed after the measurement. For single-copy measurements, we obtain a sample complexity of $Θ(Γ^{\mathrm{ob}}_p/ε^2)$. We then show $\tildeΘ(Γ_p/ε^2)$ is necessary and sufficient for the original problem, with the lower bound applying to unbiased, bounded estimators. Our upper bounds rely on a two-step algorithm combining coarse tomography with local estimation. Notably, $Γ^{\mathrm{ob}}_\infty = Γ_\infty$. In both cases, allowing $c$-copy measurements improves the sample complexity by at most $Ω(1/c)$.
  Our results establish a quantitative correspondence between quantum learning and metrology, unifying asymptotic metrological limits with finite-sample learning guarantees.

</details>


### [88] [Adaptive controllable architecture of analog Ising machine](https://arxiv.org/abs/2602.05595)
*Langyu Li,Ruoyu Wu,Yong Wang,Guofeng Zhang,Jinhu Lü,Qing Gao,Yu Pan*

Main category: quant-ph

TL;DR: 本文提出了一种可控模拟伊辛机（CAIM），通过将二值化约束提升为控制变量，并结合控制李雅普诺夫函数与动量优化算法，实现了对传统模拟伊辛机性能瓶颈的突破，在50节点MaxCut问题上实现了两倍加速和7%精度提升。


<details>
  <summary>Details</summary>
Motivation: 尽管模拟伊辛机（AIM）作为一种量子启发的非传统模拟求解架构展现出潜力，但其数学原理尚不清晰，且求解速度与精度的优化仍面临挑战，亟需建立统一理论框架并突破性能上限。

Method: 本文建立了AIM多种实现方式的统一数学模型，将二值化约束视为优化中的拉格朗日乘子，并结合动力系统理论中的李雅普诺夫分析，构建了解释和评估求解速度与精度的分析框架；进一步地，通过将该约束升格为控制变量，提出了可控模拟伊辛机（CAIM），引入控制李雅普诺夫函数与动量优化算法，实现自适应采样反馈控制。

Result: 在基于FPGA控制的LC振荡器伊辛机实验中，CAIM在50节点全连接加权MaxCut问题上相比传统AIM实现了两倍的速度提升和7%的精度改善，验证了所提理论框架的有效性与可解释性。

Conclusion: 本文提出的CAIM架构及其理论分析框架不仅揭示了传统AIM的性能理论上限，还通过控制理论方法成功突破该限制，为高性能模拟计算系统的设计提供了新的可解释路径。

Abstract: As a quantum-inspired, non-traditional analog solver architecture, the analog Ising machine (AIM) has emerged as a distinctive computational paradigm to address the rapidly growing demand for computational power. However, the mathematical understanding of its principles, as well as the optimization of its solution speed and accuracy, remain unclear. In this work, we for the first time systematically discuss multiple implementations of AIM and establish a unified mathematical formulation. On this basis, by treating the binarization constraint of AIM (such as injection locking) as a Lagrange multiplier in optimization theory and combining it with a Lyapunov analysis from dynamical systems theory, an analytical framework for evaluating solution speed and accuracy is constructed, and further demonstrate that conventional AIMs possess a theoretical performance upper bound. Subsequently, by elevating the binarization constraint to a control variable, we propose the controllable analog Ising machine (CAIM), which integrates control Lyapunov functions and momentum-based optimization algorithms to realize adaptive sampling-feedback control, thereby surpassing the performance limits of conventional AIMs. In a proof-of-concept CAIM demonstration implemented using an FPGA-controlled LC-oscillator Ising machine, CAIM achieves a twofold speedup and a 7\% improvement in accuracy over AIM on a 50-node all-to-all weighted MaxCut problem, validating both the effectiveness and interpretability of the proposed theoretical framework.

</details>


### [89] [Efficient time-evolution of matrix product states using average Hamiltonians](https://arxiv.org/abs/2602.04955)
*Belal Abouraya,Jirawat Saiphet,Fedor Jelezko,Ressa S. Said*

Main category: quant-ph

TL;DR: 提出了一种增强的矩阵乘积态（MPS）方法，用于更高效地模拟含时哈密顿量下的量子多体系统动力学，相比标准方法具有二阶收敛性，误差降低约1000倍。


<details>
  <summary>Details</summary>
Motivation: 由于希尔伯特空间随系统规模指数增长，模拟量子多体系统动力学极具挑战；现有MPS方法在处理含时哈密顿量时仅具有一阶收敛性，精度和效率受限。

Method: 通过改进现有的MPS算法，引入一种简单而高效的增强方法，实现对含时哈密顿量下系统演化的二阶收敛求解。

Result: 在氮-空位色心自旋链系统中验证了该方法，结果显示在中等时间步长下，平均误差比传统方法降低了约1000倍，且收敛速度更快。

Conclusion: 所提方法显著提升了MPS在模拟含时量子多体系统中的精度与效率，为实际量子技术应用中的系统仿真提供了有力工具。

Abstract: Simulating quantum many-body systems (QMBS) is one of the long-standing, highly non-trivial challenges in condensed matter physics and quantum information due to the exponentially growing size of the system's Hilbert space. To date, tensor networks have been an essential tool for studying such quantum systems, owing to their ability to efficiently capture the entanglement properties of the systems they represent. One of the well-known tensor network architectures, namely matrix product states (MPS), is the standard method for simulating one-dimensional QMBS. Here, we propose a simple, yet efficient, method to augment the already available MPS algorithms to simulate the dynamics of time-dependent Hamiltonians with better accuracy and a faster convergence rate, giving a second-order convergence compared to the first-order convergence of the standard method. We apply our proposed method to simulate the dynamics of a chain of single spins associated with nitrogen-vacancy color centers in diamonds, which has potential applications for practical and scalable quantum technologies, and find that our method improves the average error for a system of few NV centers by a factor of about 1000 for moderate step sizes. Our work paves the way for efficient simulation of QMBS under the influence of time-dependent Hamiltonians.

</details>


### [90] [Taming multiparty entanglement at measurement-induced phase transitions](https://arxiv.org/abs/2602.04969)
*Liuke Lyu,James Allen,Yi Hong Teoh,Roger G Melko,William Witczak-Krempa*

Main category: quant-ph

TL;DR: 本文通过大规模数值模拟研究了囚禁离子系统中的测量诱导相变（MIPT），发现其临界行为接近渗流普适类，并揭示了多体纠缠在不同粒子数下的代数衰减规律及其临界指数。


<details>
  <summary>Details</summary>
Motivation: 探索测量与幺正演化竞争下量子物质的新奇动力学态，特别是多体纠缠在临界点附近的标度行为。

Method: 采用有限尺寸标度分析确定临界测量速率和关联长度指数，并利用半定规划计算单调量来研究多体纠缠和多体互信息的代数衰减。

Result: 获得的关联长度指数接近渗流值；发现两体、三体和四体的真正多体纠缠（GME）具有稳健的代数衰减；给出了GME和多体互信息的下界，并推测k体互信息的临界指数为(k+2)。

Conclusion: 该模型属于Haar非幺正共形场论描述的普适类，且多体纠缠在临界点表现出普适的代数衰减行为，支持其与渗流模型的深层联系。

Abstract: Measurement-induced phase transitions (MIPT) give rise to novel dynamical states of quantum matter realized by balancing unitary evolution and measurements. We present large-scale numerical simulations of a trapped-ion native MIPT, argued to belong to the universality class described by the Haar non-unitary conformal field theory. First, through a finite-size analysis we obtained the critical measurement rate, and correlation length exponent, which falls close to the percolation value. Second, by leveraging a monotone computable via semi-definite programming, we uncover robust algebraic decay of genuine multiparty entanglement (GME) versus separation for 2, 3, and 4 parties. The corresponding critical exponents are lower-bounded by those of the multiparty mutual information, which we determine up to 4 parties, and conjecture to be (k+2) for k parties. Additionally, we derive lower bounds for both GME and multiparty mutual information.

</details>


### [91] [Improving Ground State Accuracy of Variational Quantum Eigensolvers with Soft-coded Orthogonal Subspace Representations](https://arxiv.org/abs/2602.05980)
*Giuseppe Clemente,Marco Intini*

Main category: quant-ph

TL;DR: 提出一种通过软编码正交性约束的子空间表示方法，以提高变分量子本征求解器（VQE）在基态估计中的准确性，相比硬编码方法可实现更浅的量子电路并保持高保真度。


<details>
  <summary>Details</summary>
Motivation: 为了在保持低能态子空间高重叠的同时减少量子电路深度，改进现有VQE方法中因硬编码正交性带来的电路复杂性问题。

Method: 采用在成本函数中加入惩罚项的方式软编码子空间中状态之间的正交性约束，并优化参数以最大化与哈密顿量低能段的子空间重叠，随后对限制在该子空间上的哈密顿量进行对角化。

Result: 在3×3横向场伊辛模型和4×4埃德华兹-安德森自旋玻璃模型上验证了该方法，结果表明其相比标准VQE、SSVQE和MCVQE能在更浅的电路下保持高保真度。

Conclusion: 软编码正交性约束的子空间方法在降低电路深度的同时维持了高精度，是提升VQE算法实用性的有效途径。

Abstract: We propose a new approach to improve the accuracy of ground state estimates in Variational Quantum Eigensolver (VQE) algorithms by employing subspace representations with soft-coded orthogonality constraints. As in other subspace-based VQE methods, such as the Subspace-Search VQE (SSVQE) and Multistate Contracted VQE (MCVQE), once the parameters are optimized to maximize the subspace overlap with the low-energy sector of the Hamiltonian, one diagonalizes the Hamiltonian restricted to the subspace. Unlike these methods, where \emph{hard-coded} orthogonality constraints are enforced at the circuit level among the states spanning the subspace, we consider a subspace representation where orthogonality is \emph{soft-coded} via penalty terms in the cost function. We show that this representation allows for shallower quantum circuits while maintaining high fidelity when compared to single-state (standard VQE) and multi-state (SSVQE or MCVQE) representations, on two benchmark cases: a $3\times 3$ transverse-field Ising model and random realizations of the Edwards--Anderson spin-glass model on a $4\times 4$ lattice.

</details>


### [92] [Topological frustration and quantum resources](https://arxiv.org/abs/2602.04960)
*Alberto Giuseppe Catalano,Gianpaolo Torre,Salvatore Marco Giampaolo,Fabio Franchini*

Main category: quant-ph

TL;DR: 本文研究了拓扑阻挫（TF）对量子资源（如纠缠熵和非稳定化Renyi熵）的影响，发现TF会引入稳定的、离域的拓扑激发，从而显著增强这些资源，并可类比W态进行解析计算。


<details>
  <summary>Details</summary>
Motivation: 探索边界条件引发的拓扑阻挫如何影响量子系统的体性质，特别是量子资源的行为，以揭示其在基础物理和技术创新中的潜力。

Method: 通过分析存在拓扑阻挫的量子系统中纠缠熵和非稳定化Renyi熵的变化，结合与W态的类比，解析计算TF带来的额外贡献。

Result: 发现拓扑阻挫会为量子资源带来显著且稳定的额外贡献，这种贡献源于离域的拓扑激发，并可通过与W态的相似性进行解析描述。

Conclusion: 拓扑阻挫能够显著改变量子资源的特性，提供了调控和增强量子资源的新途径，在量子信息处理中具有潜在应用价值。

Abstract: Although in general boundary conditions do not affect the bulk properties of a system, some of them are special and defy such expectation. This is the case, for instance, of those inducing geometrical frustration in a classical magnet. Recently, the study of such settings in quantum systems (dubbed topological frustration) has uncovered peculiar features, interesting both from a fundamental and technological point of view. In this work, we present and discuss the behavior of several quantum resources in presence of TF, namely the (disconnected) entanglement entropy and the non-stabilizerness Renyi entropy. We will show that, compared to their non-frustrated counterparts, TF adds a distinct contribution to these resources, due to a stable, delocalized, topological excitation. Remarkably, this contribution can be calculated analytically, due to its similarities with that of a W-state.

</details>


### [93] [Tighter Asymptotic Key Rates for Intensity-Correlated Decoy-State QKD via Nonlinear Programming](https://arxiv.org/abs/2602.04966)
*Matej Pivoluska,Mateus Araújo*

Main category: quant-ph

TL;DR: 提出了一种基于Cauchy-Schwarz约束和IPOPT求解器的可重复方法，用于解决实际QKD系统中强度相关漂移带来的安全性问题，相较传统线性化方法获得了更紧的密钥率下界。


<details>
  <summary>Details</summary>
Motivation: 现实量子密钥分发（QKD）系统的光源可能存在强度相关漂移，破坏传统诱骗态分析的安全性假设，需更鲁棒的方法保障安全性。

Method: 采用Cauchy-Schwarz约束重建n光子产额关联，并利用非线性内点法求解器IPOPT求解完整参数估计问题，以其结果作为外层优化的线性化点以认证渐近密钥率下界。

Result: 在粗粒度模型无关和细粒度截断高斯模型下均获得比传统参考点更紧的密钥率界限，某些情况下两阶段优化结果一致时可认证最优性。

Conclusion: 该方法提供了一种可重复且更精确的密钥率估算方案，能有效应对实际系统中的强度相关误差，提升安全性分析的实用性与严谨性。

Abstract: Decoy-state QKD with phase-randomized weak coherent pulses is typically analyzed assuming independent, precisely prepared intensities. Real sources, however, can exhibit correlated intensity drift across rounds, potentially leaking intensity information and breaking the standard decoy-state reduction to linear programs. Cauchy--Schwarz (CS) constraints can restore security by coupling $n$-photon yields across intensities, but they introduce nonlinear square-root constraints that are commonly handled via outer linearisation around channel-model-based reference points. We propose a reproducible alternative: first solve the full CS-constrained parameter-estimation problems using the interior-point nonlinear solver IPOPT, then use the resulting candidate solution as the linearisation point for the outer optimisation that certifies a valid lower bound on the asymptotic key rate. Simulations for both coarse-grained model-independent correlations and fine-grained truncated-Gaussian models show consistently tighter key-rate bounds than canonical reference points, and in some cases allow certifying optimality when both optimisation stages coincide.

</details>


### [94] [Quantum Key Distribution with Imperfections: Recent Advances in Security Proofs](https://arxiv.org/abs/2602.05057)
*Patrick Andriolo,Esteban Vasques,Elizabeth Agudelo,Max Riegler,Matej Pivoluska,Gláucia Murta*

Main category: quant-ph

TL;DR: 本文综述了量子密钥分发（QKD）安全证明中近期的分析和数值发展，重点在于如何在现实条件下考虑实际系统中的缺陷以重新建立安全性。


<details>
  <summary>Details</summary>
Motivation: 由于理论安全证明通常基于理想化模型，而实际实现中存在各种不完美性，导致理论与实践之间存在差距，因此需要发展能够包含实际缺陷的安全分析方法。

Method: 总结并回顾了近年来在QKD安全证明方面的分析和数值方法进展，这些方法能够灵活地纳入实际系统中的各种非理想因素。

Result: 提出了一套适用于现实条件的QKD安全分析框架，能够有效弥补理论与实验之间的安全差距。

Conclusion: 通过引入更贴近实际的模型，可以重新确立QKD在真实世界应用中的信息论安全性。

Abstract: In contrast to classical cryptography, where the security of encoded messages typically relies on the inability of standard algorithms to overcome computational complexity assumptions, Quantum Key Distribution (QKD) can enable two spatially separated parties to establish an information-theoretically secure encryption, provided that the QKD protocol is underpinned by a security proof. In the last decades, security proofs robust against a wide range of eavesdropping strategies have established the theoretical soundness of several QKD protocols. However, most proofs are based on idealized models of the physical systems involved in such protocols and often include assumptions that are not satisfied in practical implementations. This mismatch creates a gap between theoretical security guarantees and actual experimental realizations, making QKD protocols vulnerable to attacks. To ensure the security of real-world QKD systems, it is therefore essential to account for imperfections in security analyses. In this article, we present an overview of recent analytical and numerical developments in QKD security proofs, which provide a versatile approach for incorporating imperfections and re-establishing the security of quantum communication protocols under realistic conditions.

</details>


### [95] [Quantum statistical functions](https://arxiv.org/abs/2602.05821)
*Haruki Emori*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Statistical functions such as the moment-generating function, characteristic function, cumulant-generating function, and second characteristic function are cornerstone tools in classical statistics and probability theory. They provide a powerful means to analyze the statistical properties of a system and find applications in diverse fields, including statistical physics and field theory. While these functions are ubiquitous in classical theory, a quantum counterpart has remained elusive due to the fundamental hurdle of noncommutativity of operators. The lack of such a framework has obscured the deep connections between standard statistical measures and the non-classical features of quantum mechanics. Here, we establish a comprehensive framework for quantum statistical functions that transcends these limitations, naturally unifying the disparate languages of standard quantum statistics, quasiprobability distributions, and weak values. We show that these functions, defined as expectation values with respect to the purified state, naturally reproduce fundamental quantum statistical quantities like expectation values, variance, and covariance upon differentiation. Crucially, by extending this framework to include the concepts of pre- and post-selection, we define conditional quantum statistical functions that uniquely yield weak values and weak variance. We further demonstrate that multivariable quantum statistical functions, when defined with specific operator orderings, correspond to well-known quasiprobability distributions. Our framework provides a cohesive mathematical structure that not only reproduces standard quantum statistical measures but also incorporates nonclassical features of quantum mechanics, thus laying the foundation for a deeper understanding of quantum statistics.

</details>


### [96] [Learning fermionic linear optics with Heisenberg scaling and physical operations](https://arxiv.org/abs/2602.05058)
*Aria Christensen,Andrew Zhao*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We revisit the problem of learning fermionic linear optics (FLO), also known as fermionic Gaussian unitaries. Given black-box query access to an unknown FLO, previous proposals required $\widetilde{\mathcal{O}}(n^5 / \varepsilon^2)$ queries, where $n$ is the system size and $\varepsilon$ is the error in diamond distance. These algorithms also use unphysical operations (i.e., violating fermionic superselection rules) and/or $n$ auxiliary modes to prepare Choi states of the FLO. In this work, we establish efficient and experimentally friendly protocols that obey superselection, use minimal ancilla (at most $1$ extra mode), and exhibit improved dependence on both parameters $n$ and $\varepsilon$. For arbitrary (active) FLOs this algorithm makes at most $\widetilde{\mathcal{O}}(n^4 / \varepsilon)$ queries, while for number-conserving (passive) FLOs we show that $\mathcal{O}(n^3 / \varepsilon)$ queries suffice. The complexity of the active case can be further reduced to $\widetilde{\mathcal{O}}(n^3 / \varepsilon)$ at the cost of using $n$ ancilla. This marks the first FLO learning algorithm that attains Heisenberg scaling in precision. As a side result, we also demonstrate an improved copy complexity of $\widetilde{\mathcal{O}}(n η^2 / \varepsilon^2)$ for time-efficient state tomography of $η$-particle Slater determinants in $\varepsilon$ trace distance, which may be of independent interest.

</details>


### [97] [Near-frustration-free electronic structure Hamiltonian representations and lower bound certificates](https://arxiv.org/abs/2602.05069)
*Nicholas C. Rubin,Guang Hao Low,A. Eugene DePrince*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Hamiltonian representations based on the sum-of-squares (SOS) hierarchy provide rigorous lower bounds on ground-state energies and facilitate the design of efficient classical and quantum simulation algorithms. This work presents a unified framework connecting SOS decompositions with variational two-particle reduced density matrix (v2RDM) theory. We demonstrate that the ``weighted'' SOS ansatz naturally recovers the dual of the v2RDM program, enabling the strict enforcement of symmetry constraints such as particle number and spin. We provide explicit SOS constructions for the Hubbard model and electronic structure Hamiltonians, ranging from spin-free approximations to full rank-2 expansions. We also highlight theoretical connections to block-invariant symmetry shifts. Numerical benchmarks on molecular systems and Iron-Sulfur clusters validate these near frustration-free representations, demonstrating their utility in improving spectral gap amplification and reducing block encoding costs in quantum algorithms.

</details>


### [98] [Photonic entanglement enhanced multidimensional spectroscopy for probing exciton correlations: theory and applications to photosynthetic aggregates](https://arxiv.org/abs/2602.05080)
*Arunangshu Debnath,Shaul Mukamel*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Nonlinear spectroscopic techniques using entangled photon pairs provide an opportunity to exploit non-classical correlations encoded in two-photon wavefunctions to manipulate two-exciton wavefunctions. We propose an entangled photon pair-enhanced multidimensional spectroscopic technique which is sensitive to exciton-exciton interactions and correlations at the ultrafast timescale. Simulations for a dissipative photosynthetic aggregate reveal the superior ability of entangled photon pairs, compared to both transform-limited and frequency-chirped laser pulses, to manipulate excited-state absorption pathways. The corresponding spectral features in the two-dimensional spectrogram are interpreted in terms of one- and two-exciton resonances. The signal scales linearly with the incoming intensity of the photon sources. It is argued that classifying these resonances using entangled photon source at the perturbative limit allow for probing exciton correlations at the natural energy scale. These insights can be used to explore multi-exciton dynamics using multiphoton entanglement.

</details>


### [99] [Quantum computational imaging and sensing](https://arxiv.org/abs/2602.05102)
*Mohan Sarovar*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a new framework for imaging and sensing based on utilizing a quantum computer to coherently process quantum information in an electromagnetic field. We describe the framework, its potential to provide improvements in imaging and sensing performance and present an example application, the design of coherent receivers for optical communication. Finally, we go over the improvements in quantum technologies required to fully realize quantum computational imaging and sensing.

</details>


### [100] [Dissipative Dicke Time Quasicrystals](https://arxiv.org/abs/2602.05994)
*Sk Anisur,Sayan Choudhury*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the emergence of time quasicrystals (TQCs) in the open Dicke model, subjected to a quasi-periodic Fibonacci drive. TQCs are characterized by a robust sub-harmonic quasi-periodic response that is qualitatively distinct from the external drive. By directly analyzing the dynamics of the system in the thermodynamic limit, we establish the existence of TQC order in this system for a wide parameter regime. Remarkably, we demonstrate that this behavior persists even in the deep quantum regime with only two qubits. We systematically study the dependence of the TQC lifetime, $τ^{\ast}$, on the number of qubits and demonstrate that $τ^{\ast}$ increases monotonically with the system size. Our work demonstrates that quasi-periodically driven dissipative quantum systems can serve as a powerful platform for realizing novel non-equilibrium phases of matter.

</details>


### [101] [Quantum Sequential Circuits](https://arxiv.org/abs/2602.05166)
*D. -S. Wang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work introduces and characterizes quantum sequential circuits (QSCs) as a hardware-oriented paradigm for quantum computing, built upon a novel foundational element termed the quantum transistor. Unlike conventional qubit-based architectures, QSCs employ symmetry-protected topological junctions where quantum gates are encoded as Choi states via channel-state duality and activated through bulk measurements, utilizing ebits to realize the functional analog of feedback loops in classical sequential circuits. This framework establishes a universal model for quantum computation that inherently incorporates memory and temporal sequencing, complementing existing combinational quantum circuit model. Our work advances the conceptual bridge towards a quantum von Neumann architecture, underscoring the potential of hybrid and modular design principles for the development of large-scale, integrated quantum information processors.

</details>


### [102] [Broadband Population Transfer Based on Suture Adiabatic Pulses](https://arxiv.org/abs/2602.05199)
*Jiaming Li,Xi-Wang Luo,Guang-Can Guo,Zheng-Wei Zhou*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: High-fidelity coherent population transfer plays a vital role in the realization of quantum memories. However, population transfer with high performance across a broad frequency range is still challenging due to the finite Rabi coupling strength limited by laser powers. Here we propose a novel population-transfer scheme by suturing adiabatic control pulses with each pulse covering certain frequency interval, which are connected in a way that neighboring adiabatic pulses have opposite chirping directions. Taking the widely utilized hyperbolic-square-hyperbolic pulse as an example, we demonstrate that rapid and robust population transfer can be achieved. The transfer bandwidth scales linearly with the number of suture pulses while maintaining high fidelity, even at the suture points where adiabaticity breaks down. Crucially, these pulses can be realized by a single laser by means of temporal multiplexing. For a given bandwidth, this strategy substantially reduces the operational time which is necessary for on demand read-out and suppressing decoherence effects. Our scheme enables a dramatic increase in multimode storage capacity and paves the way for realizing practical quantum networks.

</details>


### [103] [Practical continuous-variable quantum key distribution using dynamic digital signal processing: security proof and experimental demonstration](https://arxiv.org/abs/2602.05206)
*Lu Fan,Zhengyu Li,Sheng Liu,Xuesong Xu,Tianyu Zhang,Jiale Mi,Dong Wang,Dechao Zhang,Han Li,Song Yu,Yichen Zhang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Digital signal processing technology has paved the way for the realization of high-speed continuous-variable quantum key distribution systems. However, existing security proofs are limited to static digital signal processing algorithms, while practical systems rely on dynamic multiple-input multiple-output algorithms to compensate for time-varying channel impairments. Our analysis reveals that the conventional dynamic algorithm, due to its non-unitary nature, systematically underestimates the excess noise, which in turn leads to security issues and the generation of insecure keys. To close this gap, we propose a secure algorithm model, mapping the dynamic algorithm to an equivalent physical optical model whose security can be rigorously assessed. Simulations illustrate the algorithm's non-unitary property and provide a quantitative analysis of the excess noise underestimation caused by the conventional algorithm. We further experimentally validate the necessity of the proposed modeling for dynamic digital signal processing, achieving a secret key rate of 14.4 Mbps based on estimated excess noise of 0.07 shot noise unit; whereas the conventional algorithm would have dangerously overestimated the key rate to 28.2 Mbps with noise of 0.008 shot noise unit. This work provides the essential security framework for dynamic digital signal processing, overcoming a critical impediment for the development of high-performance continuous-variable quantum key distribution systems.

</details>


### [104] [Robust Negativity in the Quantum-to-Classical Transition of Kerr Dynamics](https://arxiv.org/abs/2602.05223)
*Mohsin Raza,John B. DeBrota,Ariel Shlosberg,Noah Lordi,Ivan H. Deutsch*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We quantify the quantum-to-classical transition of the single-mode Kerr nonlinear dynamics in the presence of loss. We establish three time scales that govern the dynamics, each with distinct characteristics. For times short compared to the Ehrenfest time, the evolution is classical, characterized by Gaussian dynamics. For sufficiently long times, as we increase the initial photon number, unitary Kerr evolution would generate macroscopic superpositions of coherent states (so-called kitten states), but this is severely restricted in the presence of small photon loss so that expectation values of observables coincide with their classical values. The intermediate time scale, however, shows resilient quantum behavior in the macroscopic limit. We show that in the mean-field non-Gaussian regime, the Kerr Hamiltonian (with small photon loss) generates a significant amount of Wigner-negativity, and classical flow is recovered only if the loss rate grows with system size. Our results broaden the usual understanding of quantum-to-classical transitions and demonstrate the potential for creating robust nonclassical resources for continuous-variable quantum information processing in the presence of loss.

</details>


### [105] [Quantum scattering in helically twisted geometries: Coulomb-like interaction and Aharonov-Bohm effect](https://arxiv.org/abs/2602.05229)
*Augusto Tadeu P. de Araújo,Edilberto O. Silva*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the scattering of a charged quantum particle in a helically twisted background that induces an effective Coulomb-like interaction, in the presence of an Aharonov-Bohm (AB) flux. Starting from the nonrelativistic Schrödinger equation in the twisted metric, we derive the radial equation and show that, after including the AB potential, it can be mapped onto the same Kummer-type differential equation that governs the planar $2D$ Coulomb $+$ AB problem, with a geometry-induced Coulomb strength and the azimuthal quantum number shifted as $m\to m-λ$. We construct the exact scattering solutions, obtain closed expressions for the partial-wave $S$ matrix and phase shifts, and derive the corresponding scattering amplitude, differential cross section, and total cross section. We also show that the pole structure of the $S$ matrix is consistent with the bound-state quantization previously obtained for the helically twisted Coulomb-like problem.

</details>


### [106] [Gradient Analysis of Barren Plateau in Parameterized Quantum Circuits with multi-qubit gates](https://arxiv.org/abs/2602.05288)
*Yuhan Yao,Yoshihiko Hasegawa*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The emergence of the Barren Plateau phenomenon poses a significant challenge to quantum machine learning. While most Barren Plateau analyses focus on single-qubit rotation gates, the gradient behavior of Parameterized Quantum Circuits built from multi-qubit gates remains largely unexplored. In this work, we present a general theoretical framework for analyzing the gradient properties of Parameterized Quantum Circuits with multi-qubit gates. Our method generalizes the direct computation framework, bypassing the Haar random assumption on parameters and enabling the calculation of the gradient expectation and variance. We apply this framework to single-layer and deep-layer circuits, deriving analytical results that quantify how gradient variance is co-determined by the size of the multi-qubit gate and the number of qubits, layers, and effective parameters. Numerical simulations validate our findings. Our study provides a refined framework for analyzing and optimizing Parameterized Quantum Circuits with complex multi-qubit gates.

</details>


### [107] [Entanglement-enhanced quantum metrology via alternating in-phase and quadrature modulation](https://arxiv.org/abs/2602.05337)
*Jihao Ma,Jiahao Huang,Chaohong Lee*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum metrology harnesses quantum entanglement to improve measurement precision beyond standard quantum limit. Although nonlinear interaction is essential for generating entanglement, during signal accumulation, it becomes detrimental and therefore must be suppressed. To address this challenge, we propose an alternating in-phase and quadrature modulation (AIQM) scheme, designed to operate under a fixed nonlinear interaction. During signal accumulation, our time-interleaved approach sequentially applies the in-phase and quadrature driving fields, thereby eliminating the effects of nonlinear interaction on signal accumulation. Our AIQM scheme achieves better metrological performance than conventional schemes, particularly under strong nonlinear interaction and prolonged signal accumulation, with pronounced robustness against parameter variations. By selectively eliminating and utilizing nonlinear interactions via AIQM, our work enables high-precision and high-accuracy entanglement-enhanced sensing without the need for active control of the nonlinear interaction.

</details>


### [108] [High-order dynamical decoupling in the weak-coupling regime](https://arxiv.org/abs/2602.05343)
*Leeseok Kim,Milad Marvian*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce a high-order dynamical decoupling (DD) scheme for arbitrary system-bath interactions in the weak-coupling regime. Given any decoupling group $\mathcal G$ that averages the interaction to zero, our construction yields pulse sequences whose length scales as $\mathcal{O}(|\mathcal G| K)$, while canceling all error terms linear in the system-bath coupling strength up to order $K$ in the total evolution time. As a corollary, for an $n$-qubit system with $k$-local system-bath interactions, we obtain an $\mathcal{O}(n^{k-1}K)$-pulse sequence, a significant improvement over existing schemes with $\mathcal{O}(\exp(n))$ pulses (for $k=\mathcal{O}(1)$). The construction is obtained via a mapping to the continuous necklace-splitting problem, which asks how to cut a multi-colored interval into pieces that give each party the same share of every color. We provide explicit pulse sequences for suppressing general single-qubit decoherence, prove that the pulse count is asymptotically optimal, and verify the predicted error scaling in numerical simulations. For the same number of pulses, we observe that our sequences outperform the state-of-the-art Quadratic DD in the weak-coupling regime. We also note that the same construction extends to suppress slow, time-dependent Hamiltonian noise.

</details>


### [109] [Matchgate synthesis via Clifford matchgates and $T$ gates](https://arxiv.org/abs/2602.05425)
*Berta Casas,Paolo Braccia,Élie Gouzien,M. Cerezo,Diego García-Martín*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Matchgate unitaries are ubiquitous in quantum computation due to their relation to non-interacting fermions and because they can be used to benchmark quantum computers. Implementing such unitaries on fault-tolerant devices requires first compiling them into a discrete universal gate set, typically Clifford$+T$. Here, we propose a different approach for their synthesis: compile matchgate unitaries using only matchgate gates. To this end, we first show that the matchgate-Clifford group (the intersection of the matchgate and Clifford groups) plus the $\overline{T}$ gate (a $T$ unitary up to a phase) is universal for the matchgate group. Our approach leverages the connection between $n$-qubit matchgate circuits and the standard representation of $\mathbb{SO}(2n)$, which reduces the compilation from $2^n\times 2^n$ unitaries to $2n\times2n$ ones, thus reducing exponentially the size of the target matrix. Moreover, we rigorously show that this scheme is efficient, as an approximation error $\varepsilon_{\mathbb{SO}(2n)}$ incurred in this smaller-dimensional representation translates at most into an $O(n \,\varepsilon_{\mathbb{SO}(2n)})$ error in the exponentially large unitary. In addition, we study the exact version of the matchgate synthesis problem, and we prove that all matchgate unitaries $U$ such that $U\otimes U^*$ has entries in the ring $\mathbb{Z}\big[1/\sqrt 2,i\big]$ can be exactly synthesized by a finite sequence of gates from the matchgate-Clifford$+\overline{T}$ set, without ancillas. We then use this insight to map optimal exact matchgate synthesis to Boolean satisfiability, and compile the circuits that diagonalize the free-fermionic $XX$ Hamiltonian on $n=4,\,8$ qubits.

</details>


### [110] [Quantum-Enhanced Deterministic Inference of $k$-Independent Set Instances on Neutral Atom Arrays](https://arxiv.org/abs/2602.05432)
*Juyoung Park,Junwoo Jung,Jaewook Ahn*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Noisy quantum annealing experiments on Rydberg atom arrays produce measurement outcomes that deviate from ideal distributions, complicating performance evaluation. To enable a data-driven benchmarking methodology for quantum devices that accounts for both solution quality and the classical computational cost of inference from noisy measurements, we introduce deterministic error mitigation (DEM), a shot-level inference procedure informed by experimentally characterized noise. We demonstrate this approach using the decision version of the $k$-independent set problem. Within a Hamming-shell framework, the DEM candidate volume is governed by the binary entropy of the bit-flip error rate, yielding an entropy-controlled classical postprocessing cost. Using experimental measurement data, DEM reduces postprocessing overhead relative to classical inference baselines. Numerical simulations and experimental results from neutral atom devices validate the predicted scaling with system size and error rate. These scalings indicate that one hour of classical computation on an Intel i9 processor corresponds to neutral atom experiments with up to $N=250-450$ atoms at effective error rates, enabling a direct, cost-based comparison between noisy quantum experiments and classical algorithms.

</details>


### [111] [Bell and EPR experiments with signalling data](https://arxiv.org/abs/2602.05507)
*Lucas Maquedano,Sophie Egelhaaf,Amro Abou-Hachem,Jef Pauwels,Armin Tavakoli,Ana C. S. Costa,Roope Uola*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The no-signalling principle is a fundamental assumption in Bell-inequality and quantum-steering experiments. Nonetheless, experimental imperfections can lead to apparent violations beyond those expected from finite-sample statistics. Here, we propose extensions of local hidden variable and local hidden state theories that allow for bounded, operationally quantifiable, amounts of signalling. We show how non-classicality tests can be developed for these models, both through exact methods based on the full set of observed statistics and through corrections to the standard Bell and steering inequalities. We demonstrate the applicability of these methods via two scenarios that feature apparent signalling: an IBM quantum processor and post-selected data from inefficient detectors.

</details>


### [112] [Single shot distinguishability of noisy quantum channels](https://arxiv.org/abs/2602.05521)
*Satyaki Manna*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Among the intriguing features of quantum theory, the problem of distinguishing quantum channels is of fundamental interest. In this paper, we focus on the single-shot discrimination of two noisy quantum channels using two distinct classes of probes: single-system (product) probes and entangled probes. Our aim is to identify optimal probing state for specific discrimination tasks and to analyze the necessity and role of entanglement in enhancing channel distinguishability. We show that maximally entangled probes are optimal for discriminating two qubit depolarizing channels, with any nonzero entanglement providing an advantage over single-system probes. In contrast, for dephasing channels in arbitrary dimensions, we prove that single-system probe can be optimal and that entanglement offers no improvement, even when the dephasing unitary is generalized. For qubit amplitude-damping channels, we identify distinct noise-dependent regimes in which either single-system probe outperforms maximally entangled probes and vice-versa. Moreover, we demonstrate that non-maximally entangled probes can act as the optimum probe if the noise parameters restricted to certain values in this task. We also present examples of noisy unitary channels for which discrimination is possible using non-maximally entangled probe, while both single-systems and maximally entangled probes fail. We introduce another class of noisy unitary channels for which perfect discrimination is achievable with a single system, while maximally entangled probes are insufficient. Finally, we show that two erasure channels can be optimally discriminated using any pure single-system probe, with no advantage gained from entanglement.

</details>


### [113] [Arithmetic Reconciliation for CVQKD: Challenges and Feasibility](https://arxiv.org/abs/2602.05526)
*Rávilla R. S. Leite,Juliana M. de Assis,Micael A. Dias,Francisco M. de Assis*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Continuous variable quantum key distribution allows two legitimate parties to share a common secret key and encompasses reconciliation protocols. A relatively new reconciliation protocol, Arithmetic Reconciliation, presents low complexity and has increasing reconciliation efficiency with lower SNRs. In this paper, we obtain reconciliation efficiencies for this protocol in realistic scenarios, by means of estimation of mutual information, and we also present rates for sequence match of secret keys by Alice and Bob. Results show that this technique is feasible and promising to continuous variable quantum key distribution applications.

</details>


### [114] [Reducing the Complexity of Matrix Multiplication to $O(N^2log_2N)$ by an Asymptotically Optimal Quantum Algorithm](https://arxiv.org/abs/2602.05541)
*Jiaqi Yao,Ding Liu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Matrix multiplication is a fundamental classical computing operation whose efficiency becomes a major challenge at scale, especially for machine learning applications. Quantum computing, with its inherent parallelism and exponential storage capacity, offers a potential solution to these limitations. This work presents a quantum kernel-based matrix multiplication algorithm (QKMM) that achieves an asymptotically optimal computational complexity of $ O(N^2 \log_2 N) $, outperforming the classical optimal complexity of $ O(N^{2.371552}) $, where $N$ denotes the matrix dimension. Through noiseless and noisy quantum simulation experiments, we demonstrate that the proposed algorithm not only exhibits superior theoretical efficiency but also shows practical advantages in runtime performance and stability.

</details>


### [115] [Simulation of boson sampling with optical feedback](https://arxiv.org/abs/2602.05566)
*Yu. A. Biriukov,I. V. Dyakonov*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work presents a theoretical model of boson sampling with optical feedback, in which a subset of the interferometer's output modes is looped back into the input modes. If the bosons are injected periodically into the input modes of the interferometer and optical feedback lines' length match the period of injection, it allows for interference between bosons injected at the consequent time iterations. We propose several methods methods for computing the output photon distributions in both output spacial and temporal modes, including not only standard spatiotemporal mode-unfolding technique, but also the Kraus-operator formalism, and a correlation-tensor-based approach. The two latter approaches help us to reveal that for random interferometers this system evolves to a unique stationary state over time. Because of the existence of the stationary state, we introduce new computational problem \textit{Stationary Distribution Boson Sampling} which appears to be harder than conventional boson sampling problem and contains it as a special case when there are no optical feedback lines.

</details>


### [116] [Simultaneous reconstruction of quantum process and noise via corrupted sensing](https://arxiv.org/abs/2602.05604)
*Mengru Ma,Jiangwei Shang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum processes, including quantum gates and channels, are integral to various quantum information tasks, making the efficient characterization of these processes and their underlying noise critically important. Here, we propose a framework for quantum process tomography in the presence of corrupted noise that is able to simultaneously reconstruct the process and corrupted noise. Firstly, within the Choi-state representation, we derive the corresponding generalized restricted isometry property and demonstrate the simultaneous reconstruction of various quantum gates under sparse noise. Moreover, in comparison with the Choi-state scheme, the process-matrix representation is employed to simultaneously reconstruct sparse noise and a broader range of target quantum gates. Our results demonstrate that significant reduction in experimental configurations is achievable even under corrupted noise.

</details>


### [117] [Hamiltonian Benchmark of a Solid-State Spin-Photon Interface for Computation](https://arxiv.org/abs/2602.05637)
*Tejas Acharya,Loïc Lanco,Olivier Krebs,Hui Khoon Ng,Alexia Auffèves,Maria Maffei*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Light-matter interfaces are pivotal for quantum computation and communication. While typically analyzed using single-mode or open-quantum-system approximations, these models often neglect multi-mode field states and light-matter entanglement, hindering exact protocol modeling. Here, we solve the full Hamiltonian dynamics of a solid-state spin-photon interface for three key protocols: the generation of photon-number superpositions, a controlled photon-photon gate, and the production of photonic cluster states. By deriving exact fidelities, we identify fundamental performance limits. Our results reveal that while realistic imperfections severely limit photon-photon gates, they only slightly affect linear photonic clusters and are nearly harmless for photon-number state superpositions.

</details>


### [118] [Investigations on Quantum Correlations and Open Quantum System Dynamics Through Nuclear Spins](https://arxiv.org/abs/2602.05661)
*Arijit Chatterjee*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Nuclear spins provide an ideal platform for studying quantum correlations and open quantum system dynamics across diverse areas, including quantum information, quantum foundations, and many-body physics. This is enabled by their long longitudinal (T1) and transverse (T2) coherence times and precise control using radio frequency pulses. In this thesis, I present my work using nuclear spins to explore these themes.
  First, I study temporal quantum correlations quantified by the Leggett Garg inequality (LGI) for a qubit evolving under a superposition of unitary operators. Using a three qubit quantum register, we experimentally realized superposed unitaries and observed LGI violations exceeding the maximal quantum bound of 1.5, indicating enhanced non-classicality. Notably, this superposed unitary dynamics also showed improved robustness against decoherence.
  Next, I investigate Lee Yang zeros, which are zeros of the partition function in the complex plane that reveal thermodynamic behavior near criticality. We proposed and experimentally demonstrated a method to determine the full set of Lee Yang zeros of an asymmetric Ising model using a single quantum probe in a three-qubit nuclear spin register. We further showed that the mutual information between the probe and system peaks at times corresponding to these zeros.
  I then report our study of the quantum Mpemba effect in nuclear spin relaxation, where systems farther from equilibrium can relax faster than those closer to steady state, verified both theoretically and experimentally using NMR. Finally, I discuss our work on entanglement localization and delocalization induced by local interactions, leading to an apparent violation of the quantum data processing inequality. We showed that this violation is only apparent by constructing a completely positive and trace preserving map describing the dynamics.

</details>


### [119] [Numerical approaches to entangling dynamics from variational principles](https://arxiv.org/abs/2602.05726)
*Christian Offen,Boris Wembe,Laura Ares,Jan Sperling,Sina Ober-Blöbaum*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this work, we address the numerical identification of entanglement in dynamical scenarios. To this end, we consider different programs based on the restriction of the evolution to the set of separable (i.e., non-entangled) states, together with the discretization of the space of variables for numerical computations. As a first approach, we apply linear splitting methods to the restricted, continuous equations of motion derived from variational principles. We utilize an exchange interaction Hamiltonian to confirm that the numerical and analytical solutions coincide in the limit of small time steps. The application to different Hamiltonians shows the wide applicability of the method to detect dynamical entanglement. To avoid the derivation of analytical solutions for complex dynamics, we consider variational, numerical integration schemes, introducing a variational discretization for Lagrangians linear in velocities. Here, we examine and compare two approaches: one in which the system is discretized before the restriction is applied, and another in which the restriction precedes the discretization. We find that the "first-discretize-then-restrict" method becomes numerically unstable, already for the example of an exchange-interaction Hamiltonian, which can be an important consideration for the numerical analysis of constrained quantum dynamics. Thereby, broadly applicable numerical tools, including their limitations, for studying entanglement over time are established for assessing the entangling power of processes that are used in quantum information theory.

</details>


### [120] [Efficient implementation of arbitrary Hermitian-preserving and trace-preserving maps](https://arxiv.org/abs/2602.05777)
*Weizhou Cai,Zi-Jie Chen,Xuanqiang Zhao,Xin Wang,Guang-Can Guo,Luyan Sun,Chang-Ling Zou*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum control has been a cornerstone of quantum information science, driving major advances in quantum computing, quantum communication, and quantum sensing. Over the years, it has enabled the implementation of arbitrary completely positive and trace-preserving (CPTP) maps; an important next step is to extend control to Hermitian-preserving and trace-preserving (HPTP) maps, which underpin applications such as entanglement detection, quantum error mitigation, quantum simulation, and quantum machine learning. Here we present an efficient and fully constructive method for implementing arbitrary HPTP maps. Unlike existing methods that decompose an HPTP map into multiple CPTP maps or approximate it using bipartite Hamiltonians with large Hilbert spaces, our approach compiles a target HPTP map into a single executable CPTP map whose Kraus rank is guaranteed to be no larger than the intrinsic rank of the target HPTP map plus one, followed by simple classical post-processing. Numerical results for inverse noise channels used in quantum error mitigation, including bosonic photon loss, confirm substantial reductions in resources and highlight scalability in higher-dimensional settings. Together with our numerical benchmarks, these results validate the efficiency and versatility of the proposed framework, opening a route to broader quantum-information applications enabled by HPTP processing.

</details>


### [121] [Advanced Quantum Communication and Quantum Networks -- From basic research to future applications](https://arxiv.org/abs/2602.05781)
*Björn Kubala,Alexander Sauer,Alessandro Tarantola,David Fabian,Anke Ginter,Olga Kulikovska,Fabio Di Pumpo,Johannes Seiler,Wolfgang P. Schleich,Matthias Zimmermann*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Classical communication is the basis for many of our current and future technologies, such as mobile phones, video conferences, autonomous vehicles and particularly the internet. In contrast, quantum communication is governed by the laws of quantum mechanics. Due to this fundamental difference, it might offer enormous benefits for security applications, more precise measurements, faster computations, and many other fields of application by interconnecting different quantum devices, such as quantum sensors, quantum computers, or quantum memories. This review provides an overview of the specific properties of quantum information networks. This includes the interfaces between the classical and the quantum regime, the transmission of the quantum information by physical implementations, and potential future applications of quantum networks. We aim to provide a starting point based on fundamental concepts of quantum information processing for further research on a future quantum internet.

</details>


### [122] [The Quantum Message Complexity of Distributed Wake-Up with Advice](https://arxiv.org/abs/2602.05801)
*Peter Robinson,Ming Ming Tan*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider the distributed wake-up problem with advice, where nodes are equipped with initial knowledge about the network at large. After the adversary awakens a subset of nodes, an oracle computes a bit string (``the advice'') for each node, and the goal is to wake up all sleeping nodes efficiently. We present the first upper and lower bounds on the message complexity for wake-up in the quantum routing model, introduced by Dufoulon, Magniez, and Pandurangan (PODC 2025). In more detail, we give a distributed advising scheme that, given $α$ bits of advice per node, wakes up all nodes with a message complexity of $O( \sqrt{\frac{n^3}{2^{\max\{\lfloor (α-1)/2 \rfloor},0\}}}\cdot\log n )$ with high probability. Our result breaks the $Ω( \frac{n^2}{2^α} )$ barrier known for the classical port numbering model in sufficiently dense graphs. To complement our algorithm, we give a lower bound on the message complexity for distributed quantum algorithms: By leveraging a lower bound result for the single-bit descriptor problem in the query complexity model, we show that wake-up has a quantum message complexity of $Ω( n^{3/2} )$ without advice, which holds independently of how much time we allow. In the setting where an adversary decides which nodes start the algorithm, most graph problems of interest implicitly require solving wake-up, and thus the same lower bound also holds for other fundamental problems such as single-source broadcast and spanning tree construction.

</details>


### [123] [Assessing the Sensitivity of Niobium- and Tantalum-Based Superconducting Qubits to Infrared Radiation](https://arxiv.org/abs/2602.05806)
*Michael Kerschbaum,Felix Wagner,Uroš Ognjanović,Giovanni Vio,Kuno Knapp,Dante Colao Zanuz,Alexander Flasby,Mohsen Bahrami Panah,Andreas Wallraff,Jean-Claude Besse*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The use of tantalum films for superconducting qubits has recently extended qubit coherence times significantly, primarily due to reduced dielectric losses at the metal-air interface. However, the choice of base material also influences the sensitivity to quasiparticle-induced decoherence. In this study, we investigate quasiparticle tunneling rates in niobium and tantalum-based offset-charge-sensitive qubits. Using a source of thermal radiation, we characterize the sensitivity of either material to infrared radiation and explore the impact of the infrared background through the targeted use of in-line filters in the wiring and ambient infrared absorbers. We identify both radiation channels as significant contributions to decoherence for tantalum but not for niobium qubits and achieve tunneling rates of 100 Hz and 300 Hz for niobium and tantalum respectively upon installation of infrared filters. Additionally, we find a time-dependence in the observed tunneling rates on the scale of days, which we interpret as evidence of slowly cooling, thermally radiating components in the experimental setup. Our findings indicate that continued improvements in coherence times may require renewed attention to radiative backgrounds and experimental setup design, especially when introducing new material platforms.

</details>


### [124] [Simulation of Adjoints and Petz Recovery Maps for Unknown Quantum Channels](https://arxiv.org/abs/2602.05828)
*Chengkai Zhu,Ziao Tang,Guocheng Zhen,Yinan Li,Ge Bai,Xin Wang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Transformations of quantum channels, such as the transpose, complex conjugate, and adjoint, are fundamental to quantum information theory. Given access to an unknown channel, a central problem is whether these transformations can be implemented physically with quantum supermaps. While such supermaps are known for unitary operations, the situation for general quantum channels is fundamentally different. In this work, we establish a strict hierarchy of physical realizability for the transposition, complex conjugation, and adjoint transformation of an unknown quantum channel. We present a probabilistic protocol that exactly implements the transpose with a single query. In contrast, we prove no-go theorems showing that neither the complex conjugate nor the adjoint can be implemented by any completely positive supermap, even probabilistically. We then overcome this impossibility by designing a virtual protocol for the complex conjugate based on quasi-probability decomposition, and show its optimality in terms of the diamond norm. As a key application, we propose a protocol to estimate the expectation values resulting from the Petz recovery map of an unknown channel, achieving an improved query complexity compared to existing methods.

</details>


### [125] [Entropy Bounds via Hypothesis Testing and Its Applications to Two-Way Key Distillation in Quantum Cryptography](https://arxiv.org/abs/2602.05870)
*Rutvij Bhavsar,Junguk Moon,Joonwoo Bae*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum key distribution (QKD) achieves information-theoretic security, without relying on computational assumptions, by distributing quantum states. To establish secret bits, two honest parties exploit key distillation protocols over measurement outcomes resulting after the the distribution of quantum states. In this work, we establish a rigorous connection between the key rate achievable by applying two-way key distillation, such as advantage distillation, and quantum asymptotic hypothesis testing, via an integral representation of the relative entropy. This connection improves key rates at small to intermediate blocklengths relative to existing fidelity-based bounds and enables the computation of entropy bounds for intermediate to large blocklengths. Moreover, this connection allows one to close the gap between known sufficient and conjectured necessary conditions for key generation in the asymptotic regime, while the precise finite blocklegth conditions remain open. More broadly, our work shows how advances in quantum multiple hypothesis testing can directly sharpen the security analyses of QKD.

</details>


### [126] [Thermal-Drift Sampling: Generating Random Thermal Ensembles for Quantum Chaos Diagnostics](https://arxiv.org/abs/2602.05912)
*Jiyu Jiang,Mingrui Jing,Jizhe Lai,Xin Wang,Lei Zhang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Random thermal states of many-body Hamiltonians underpin studies of thermalization, chaos, and quantum phase transitions, yet their generation remains costly when each Hamiltonian must be prepared individually. We introduce the thermal-drift channel, a measurement-based operation that implements a tunable nonunitary drift along a chosen Pauli term. Based on this channel, we present a measurement-controlled sampling algorithm that generates thermal states together with their Hamiltonian "labels" for general physical models. We prove that the total gate count of our algorithm scales cubically with system size, quadratically with inverse temperature, and as the inverse error tolerance to the two-thirds power, with logarithmic dependence on the allowed failure probability. We also show that the induced label distribution approaches a normal distribution reweighted by the thermal partition function, which makes an explicit trade-off between accuracy and effective range. Numerical simulations for a 2D Heisenberg model validate the predicted scaling and distribution. As an application, we compute unfolding-free level-spacing ratio statistics from sampled thermal states of a 2D transverse-field Ising model and observe a crossover toward the Wigner--Dyson prediction, demonstrating a practical and scalable route to chaos diagnostics and random matrix universality studies on near-term quantum hardware.

</details>


### [127] [Quantum Error Mitigation at the pre-processing stage](https://arxiv.org/abs/2602.05916)
*Juan F. Martin,Giuseppe Cocco,Javier Fonollosa*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The realization of fault-tolerant quantum computers remains a challenging endeavor, forcing state-of-the-art quantum hardware to rely heavily on noise mitigation techniques. Standard quantum error mitigation is typically based on post-processing strategies. In contrast, the present work explores a pre-processing approach, in which the effects of noise are mitigated before performing a measurement on the output state. The main idea is to find an observable $Y$ such that its expectation value on a noisy quantum state $\mathcal{E(ρ)}$ matches the expectation value of a target observable $X$ on the noiseless quantum state $ρ$. Our method requires the execution of a noisy quantum circuit, followed by the measurement of the surrogate observable $Y$. The main enablers of our method in practical scenarios are Tensor Networks. The proposed method improves over Tensor Error Mitigation (TEM) in terms of average error, circuit depth, and complexity, attaining a measurement overhead that approaches the theoretical lower bound. The improvement in terms of classical computation complexity is in the order of $\sim 10^6$ times when compared to the post-processing computational cost of TEM in practical scenarios. Such gain comes from eliminating the need to perform the set of informationally complete positive operator-valued measurements (IC-POVM) required by TEM, as well as any other tomographic strategy.

</details>


### [128] [Quantum Approximate Optimization of Integer Graph Problems and Surpassing Semidefinite Programming for Max-k-Cut](https://arxiv.org/abs/2602.05956)
*Anuj Apte,Sami Boulebnane,Yuwei Jin,Sivaprasad Omanakuttan,Michael A. Perlin,Ruslan Shaydulin*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum algorithms for binary optimization problems have been the subject of extensive study. However, the application of quantum algorithms to integer optimization problems remains comparatively unexplored. In this paper, we study the Quantum Approximate Optimization Algorithm (QAOA) applied to integer problems on graphs, with each integer variable encoded in a qudit. We derive a general iterative formula for depth-$p$ QAOA expectation on high-girth $d$-regular graphs of arbitrary size. The cost of evaluating the formula is exponential in the QAOA depth $p$ but does not depend on the graph size. Evaluating this formula for Max-$k$-Cut problem for $p\leq 4$, we identify parameter regimes ($k=3$ with degree $d \leq 10$ and $k=4$ with $d \leq 40$) in which QAOA outperforms the Frieze-Jerrum semi-definite programming (SDP) algorithm, which provides the best worst-case guarantee on the approximation ratio. To strengthen the classical baseline we introduce a new heuristic algorithm, based on the degree-of-saturation, that empirically outperforms both the Frieze-Jerrum algorithm and shallow-depth QAOA. Nevertheless, we provide numerical evidence that QAOA may overtake this heuristic at depth $p\leq 20$. Our results show that moving beyond binary to integer optimization problems can open up new avenues for quantum advantage.

</details>


### [129] [One-Way Quantum Secure Direct Communication with Choice of Measurement Basis as the Secret](https://arxiv.org/abs/2602.05972)
*Santiago Bustamante,Boris A. Rodríguez,Elizabeth Agudelo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Motivated by the question of the distinguishability of ensembles described by the same compressed density operator, we propose a model for one-way quantum secure direct communication using finite ensembles of shared EPR pairs per bit and a public authenticated classical channel, where the local choice of one of two mutually-unbiased measurement bases is the secret bit. In this model, both the encoding and decoding of classical information in quantum systems are implemented by measurements in either the computational or the Hadamard basis. Using the quantum wiretap channel theory, we study the secure net bit rates and certify information-theoretic security of different implementations of our model when the quantum channel is subjected to BB84-symmetric attacks. Since no local unitary operations need to be performed by the receiver, the proposed model is suitable for real-life implementation of secure direct communication in star network configurations.

</details>


### [130] [Improved Rodeo Algorithm Performance for Spectral Functions and State Preparation](https://arxiv.org/abs/2602.05978)
*Matthew Patkowski,Onat Ayyildiz,Katherine Hunt,Nathan Jansen,Dean Lee*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Rodeo Algorithm is a quantum computing method for computing the energy spectrum of a Hamiltonian and preparing its energy eigenstates. We discuss how to improve the performance of the rodeo algorithm for each of these two applications. In particular, we demonstrate that using a geometric series of time samples offers a near-optimal optimization space for a given total runtime by studying the Rodeo Algorithm performance on a model Hamiltonian representative of gapped many-body quantum systems. Analytics explain the performance of this time sampling and the conditions for it to maintain the established exponential performance of the Rodeo Algorithm. We finally demonstrate this sampling protocol on various physical Hamiltonians, showing its practical applicability. Our results suggest that geometric series of times provide a practical, near-optimal, and robust time-sampling strategy for quantum state preparation with the Rodeo Algorithm across varied Hamiltonians without requiring model-specific fine-tuning.

</details>


### [131] [Quantum noise scaling in continuously operating multiparameter sensors](https://arxiv.org/abs/2602.05991)
*Aleksandra Sierant,Diana Méndez-Avalos,Santiago Tabares Giraldo,Morgan W. Mitchell*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We experimentally investigate the quantum noise mechanisms that limit continuously operating multiparameter quantum sensors. Using a hybrid rf-dc optically pumped magnetometer, we map the photon shot noise, spin projection noise, and measurement back-action noise over an order of magnitude in probe power and a factor of three in pump power while remaining quantum-noise-limited. We observe linear, quadratic, and cubic scaling of the respective total noise powers with probe photon flux, together with a quadratic dependence of back-action on pump photon flux, in quantitative agreement with a stochastic Bloch-equation model. At higher probe powers, additional probe-induced relaxation modifies the spin-noise spectrum while preserving the integrated noise scaling. Our results reveal fundamental, resource-dependent trade-offs unique to continuously monitored multiparameter sensors and establish experimentally the quantum limits governing their optimal operation.

</details>


### [132] [Modeling integrated frequency shifters and beam splitters](https://arxiv.org/abs/2602.06003)
*Manuel H. Muñoz-Arias,Kevin J. Randles,Nils T. Otterstrom,Paul S. Davids,Michael Gehl,Mohan Sarovar*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Photonic quantum computing is a strong contender in the race to fault-tolerance. Recent proposals using qubits encoded in frequency modes promise a large reduction in hardware footprint, and have garnered much attention. In this encoding, linear optics, i.e., beam splitters and phase shifters, is necessarily not energy-conserving, and is costly to implement. In this work, we present designs of frequency-mode beam splitters based on modulated arrays of coupled resonators. We develop a methodology to construct their effective transfer matrices based on the SLH formalism for quantum input-output networks. Our methodology is flexible and highly composable, allowing us to define $N$-mode beam splitters either natively based on arrays of $N$-resonators of arbitrary connectivity or as networks of interconnected $l$-mode beam splitters, with $l<N$. We apply our methodology to analyze a two-resonator device, a frequency-domain phase shifter and a Mach-Zehnder interferometer obtained from composing these devices, a four-resonator device, and present a formal no-go theorem on the possibility of natively generating certain $N$-mode frequency-domain beam splitters with arrays of $N$-resonators.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [133] [Quantum Simulation of Bound and Resonant Doubly-Bottom Tetraquark](https://arxiv.org/abs/2602.05941)
*Ayanendu Dutta*

Main category: hep-lat

TL;DR: 首次在量子模拟中研究了基于QCD启发的夸克模型中的双底四夸克束缚态和共振态，使用变分量子本征求解器在16量子比特系统上发现了特定同位旋通道中的深束缚态。


<details>
  <summary>Details</summary>
Motivation: 探索传统方法难以处理的奇特多夸克态，验证量子模拟在强相互作用物理中的应用潜力。

Method: 采用QCD启发的手征夸克模型构建有效四夸克哈密顿量，并映射到16量子比特系统，编码颜色、自旋和空间自由度，结合介子-介子和双夸克-反双夸克构型，使用变分量子本征求解器进行计算。

Result: 在低能S波段发现束缚态和共振态，深束缚态仅出现在同位旋I(J^P)=0(1+)通道，主要由单态介子-介子成分构成，并有不可忽略的隐色贡献，质量与结合能与经典模型预测一致。

Conclusion: 量子模拟可作为研究超出传统方法能力范围的奇特多夸克态的有效框架。

Abstract: We present the first quantum-simulation study of bound and resonant doubly-bottom tetraquark states within a QCD-inspired chiral quark model. An effective four-quark Hamiltonian is mapped onto a 16-qubit register, encoding color, spin, and spatial degrees of freedom, and incorporating both meson-meson and diquark-antidiquark configurations with complete color bases. Using a variational quantum eigensolver, we identify bound and resonance states in the low-lying $S$-wave sector. Deeply bound states are found exclusively in the isoscalar $I(J^{P})=0(1^{+})$ channel, dominated by color-singlet meson-meson components with non-negligible hidden-color contributions. The resulting masses and binding energies are consistent with classical chiral quark model predictions, establishing quantum simulation as a viable framework for studying exotic multiquark states beyond the reach of conventional methods.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [134] [Metric space valued Fr{é}chet regression](https://arxiv.org/abs/2602.05225)
*László Györfi,Pierre Humbert,Batiste Le Bars*

Main category: math.ST

TL;DR: 提出了一种基于随机量化技术的Fréchet均值估计器，并证明了其在任意可分度量空间中的普适一致性；同时提出了条件Fréchet均值估计器，具有数据驱动划分和量化方法，在Banach空间中也具有一致性。


<details>
  <summary>Details</summary>
Motivation: 在非欧几里得空间（如一般度量空间）中缺乏通用且实用的Fréchet均值估计方法，现有方法无法普遍适用。

Method: 利用随机量化技术构建Fréchet均值估计器，并结合数据驱动的划分方法设计条件Fréchet均值估计器。

Result: 所提出的两种估计器在任意可分度量空间和Banach空间中均具有普适一致性。

Conclusion: 该研究为度量空间中的Fréchet均值和条件Fréchet均值估计提供了通用且可计算的解决方案，具有广泛的适用性。

Abstract: We consider the problem of estimating the Fr{é}chet and conditional Fr{é}chet mean from data taking values in separable metric spaces. Unlike Euclidean spaces, where well-established methods are available, there is no practical estimator that works universally for all metric spaces. Therefore, we introduce a computable estimator for the Fr{é}chet mean based on random quantization techniques and establish its universal consistency across any separable metric spaces. Additionally, we propose another estimator for the conditional Fr{é}chet mean, leveraging data-driven partitioning and quantization, and demonstrate its universal consistency when the output space is any Banach space.

</details>


### [135] [An Asymptotic Law of the Iterated Logarithm for $\mathrm{KL}_{\inf}$](https://arxiv.org/abs/2602.05259)
*Ashwin Ram,Aaditya Ramdas*

Main category: math.ST

TL;DR: 本文研究了经验KL散度（empirical KL_{inf}）在非渐近集中性方面的基本极限，提出了适用于非常广泛（无界）数据的紧致迭代对数律（law of the iterated logarithm），为带算法和序贯检验提供了更优的理论基础。


<details>
  <summary>Details</summary>
Motivation: 由于经验KL_{inf}在纯探索型随机多臂老虎机算法的最优遗憾下界和序贯检验的最优停止时间中起核心作用，现有非渐近集中性界限的常数和速率未必最优且适用范围有限（通常限于有界观测），因此需要更紧致和更一般的理论刻画。

Method: 通过分析统计量的渐近波动行为，建立经验KL_{inf}的上下迭代对数律，适用于极为广泛的无界数据分布。

Result: 得到了经验KL_{inf}的紧致上界和下界形式的迭代对数律，突破了传统结果对有界观测的依赖，提升了集中性分析的最优性和普适性。

Conclusion: 该结果揭示了经验KL_{inf}在非渐近情形下的根本极限，为设计和分析最优序贯决策算法提供了更强有力的理论工具。

Abstract: The population $\mathrm{KL}_{\inf}$ is a fundamental quantity that appears in lower bounds for (asymptotically) optimal regret of pure-exploration stochastic bandit algorithms, and optimal stopping time of sequential tests. Motivated by this, an empirical $\mathrm{KL}_{\inf}$ statistic is frequently used in the design of (asymptotically) optimal bandit algorithms and sequential tests. While nonasymptotic concentration bounds for the empirical $\mathrm{KL}_{\inf}$ have been developed, their optimality in terms of constants and rates is questionable, and their generality is limited (usually to bounded observations). The fundamental limits of nonasymptotic concentration are often described by the asymptotic fluctuations of the statistics. With that motivation, this paper presents a tight (upper and lower) law of the iterated logarithm for empirical $\mathrm{KL}_{\inf}$ applying to extremely general (unbounded) data.

</details>


### [136] [Asymptotically optimal sequential change detection for bounded means](https://arxiv.org/abs/2602.05272)
*Ashwin Ram,Aaditya Ramdas*

Main category: math.ST

TL;DR: 本文研究了在平均运行长度（ARL）约束下的最快变点检测问题，提出了在低型I误差情况下通用的sharp下界，并证明了在有界均值检测设置中该下界的可实现性。


<details>
  <summary>Details</summary>
Motivation: 解决当“最难”的变化前分布依赖于未知的变化后分布时，如何刻画最佳检测延迟的问题。

Method: 推导出任意ARL校准的变点检测器在低型I误差情况下的通用sharp下界，并在重要且有界均值检测设定中证明该下界的可实现性。

Result: 得到了一个通用的sharp下界，形式为log(γ)/KL_inf(Q,P)，并在有界均值检测设置中实现了这一下界。对于分离的均值偏移，还给出了替代方案上的统一极小极大保证。

Conclusion: 所提出的下界是通用且sharp的，在特定条件下可以被现有方法达到，为复合假设下的 quickest changepoint detection 提供了理论基础。

Abstract: We consider the problem of quickest changepoint detection under the Average Run Length (ARL) constraint where the pre-change and post-change laws lie in composite families $\mathscr{P}$ and $\mathscr{Q}$ respectively. In such a problem, a massive challenge is characterizing the best possible detection delay when the "hardest" pre-change law in $\mathscr{P}$ depends on the unknown post-change law $Q\in\mathscr{Q}$. And typical simple-hypothesis likelihood-ratio arguments for Page-CUSUM and Shiryaev-Roberts do not at all apply here. To that end, we derive a universal sharp lower bound in full generality for any ARL-calibrated changepoint detector in the low type-I error ($γ\to\infty$ regime) of the order $\log(γ)/\mathrm{KL}_{\mathrm{inf}}(Q,\mathscr{P})$. We show achievability of this universal lower bound by proving a tight matching upper bound (with the same sharp $\logγ$ constant) in the important bounded mean detection setting. In addition, for separated mean shifts, we also we derive a uniform minimax guarantee of this achievability over the alternatives.

</details>


### [137] [Complexity reduction in online stochastic Newton methods with potential O(N d) total cost](https://arxiv.org/abs/2602.05460)
*Antoine Godichon-Baggioni,Bruno Portier,Guillaume Sallé*

Main category: math.ST

TL;DR: 本文提出了一种在线小批量随机牛顿算法，通过随机掩码策略选择Hessian矩阵的子集列，显著降低了每步计算成本，在单次遍历N个数据点时总计算成本为O(Nd)，与一阶方法相当，同时保留了二阶信息的优势，并证明了估计量的几乎必然收敛性和渐近有效性。


<details>
  <summary>Details</summary>
Motivation: 在只有梯度和Hessian估计噪声的随机设置中优化平滑凸函数是一个基本问题。一阶方法虽然每次迭代成本低，但在病态问题上收敛速度慢；而利用二阶信息的随机牛顿方法因高维下O(d^3)的计算和求逆全Hessian矩阵的成本而在高维场景中不可行。

Method: 引入一种在线小批量随机牛顿算法，采用随机掩码策略在每次迭代时选择Hessian矩阵的部分列，从而大幅降低每步的计算成本。

Result: 该方法在小批量设置下，对N个数据点单次遍历的总计算成本达到O(Nd)，与一阶方法相当，同时保留了二阶信息的优势；并建立了所得到估计量的几乎必然收敛性和渐近有效性。

Conclusion: 所提出的算法在保持二阶方法优势的同时，实现了与一阶方法相当的计算效率，并且无需迭代平均即可获得良好的收敛性质，区别于以往的研究。

Abstract: Optimizing smooth convex functions in stochastic settings, where only noisy estimates of gradients and Hessians are available, is a fundamental problem in optimization. While first-order methods possess a low per-iteration cost, their convergence is slow for ill-conditioned problems. Stochastic Newton methods utilize second-order information to correct for local curvature, but the O(d 3 ) per-iteration cost of computing and inverting a full Hessian, where d is the problem dimension, is prohibitive in high dimensions. This paper introduces an online mini-batch stochastic Newton algorithm. The method employs a random masking strategy that selects a subset of Hessian columns at each iteration, substantially reducing the per-step computational cost. This approach allows the algorithm, in the mini-batch setting, to achieve a total computational cost for a single pass over N data points of O(N d), which is comparable to first-order methods while retaining the advantages of second-order information. We establish the almost sure convergence and asymptotic efficiency of the resulting estimator. This property is obtained without requiring iterate averaging, which distinguishes this work from prior analyses.

</details>


### [138] [An invariant modification of the bilinear form test](https://arxiv.org/abs/2602.05592)
*Angelo Garate,Felipe Osorio,Federico Crudu*

Main category: math.ST

TL;DR: 本文研究了双线性形式检验在极值估计中关于参数重参数化的不变性，并提出了满足不变性的条件及修正的检验统计量，蒙特卡洛模拟显示其表现良好。


<details>
  <summary>Details</summary>
Motivation: 双线性形式检验在一对一参数变换下缺乏不变性，影响其在不同参数化下的可靠性，因此需要建立其不变性条件并进行修正。

Method: 通过理论分析提出保证双线性形式检验在重参数化下保持不变的一组合适条件，并对检验统计量进行简化修正，同时通过蒙特卡洛模拟实验评估其性能。

Result: 提出的修正检验统计量在理论上满足重参数化不变性，且蒙特卡洛模拟结果表明其在有限样本中表现良好。

Conclusion: 双线性形式检验可通过适当修正实现重参数化不变性，增强了其在实际应用中的稳健性和适用性。

Abstract: The invariance properties of certain likelihood-based asymptotic tests as well as their extensions for M-estimation, estimating functions and the generalized method of moments have been well studied. The simulation study reported in Crudu and Osorio [Econ. Lett. 187: 108885, 2020] shows that the bilinear form test is not invariant to one-to-one transformations of the parameter space. This paper provides a set of suitable conditions to establish the invariance property under reparametrization of the bilinear form test for linear or nonlinear hypotheses that arise in extremum estimation which leads to a simple modification of the test statistic. Evidence from a Monte Carlo simulation experiment suggests good performance of the proposed methodology.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [139] [Constraints on stability and renormalization group flows in nonequilibrium matter](https://arxiv.org/abs/2602.04961)
*Yu-Hsueh Chen,Tarun Grover*

Main category: cond-mat.stat-mech

TL;DR: 本文利用量子信息不等式推导了非平衡系统中重正化群流和相稳定性的约束，引入条件互信息（CMI）作为关键度量，提出了非微扰稳定性判据，并通过多个实例说明其应用。


<details>
  <summary>Details</summary>
Motivation: 探索非平衡系统中重正化群流的约束条件及相稳定性的基本原理，特别是在存在量子信道扰动的情况下对称性破缺态的稳定性问题。

Method: 基于量子信息不等式，假设条件互信息在紫外区域有限，分析其在重正化群流中的单调性；并通过不等式估计混合态的条件互信息，推断对称性破缺态的微扰稳定性。

Result: 发现与条件互信息相关的标度函数在重正化群流中是单调的，提出固定点间不可逆转变的非微扰稳定性标准；同时得出混合态条件下互信息的上界关系，并应用于多种物理实例。

Conclusion: 条件互信息为研究非平衡系统中RG流和相稳定性提供了有效工具，所提出的约束不仅适用于量子系统，也对经典非平衡稳态具有启示意义。

Abstract: We derive constraints on renormalization group (RG) flows and stability of phases in nonequilibrium systems using quantum information inequalities. These constraints involve conditional mutual information (CMI), which quantifies correlations between spatially separated regions not mediated by their surroundings. First, assuming CMI is UV finite, we show that the scaling function associated with CMI is monotonic along the RG flow. This implies a non-perturbative stability criterion: a fixed point with smaller CMI cannot be destabilized toward one with larger CMI. Second, we bound the CMI of a convex mixture of states in terms of the CMI of individual components. We use this inequality to infer perturbative stability of spontaneous symmetry breaking states against quantum channels that explicitly break symmetry. We illustrate these constraints through several examples, including decoherence-driven transitions in classical symmetry-broken states, strong-to-weak symmetry breaking criticality in two dimensions, and even transitions in pure quantum states. We also discuss implications for classical nonequilibrium steady states.

</details>


### [140] [Instability of G/M/c queues under stochastic resetting in the interval](https://arxiv.org/abs/2602.05009)
*José Giral-Barajas,Paul C. Bressloff*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了在有界域内具有随机重置的搜索过程对有限服务台队列系统资源数量稳态收敛性的影响，发现了重置率的阈值现象，并指出该阈值随服务台数量指数增长。


<details>
  <summary>Details</summary>
Motivation: 由于资源到达和服务受环境随机性影响，如何有效管理这类系统成为一个关键问题，尤其是在搜索过程受限于有界域且服务资源有限的情况下。

Method: 结合排队论与有界域内带随机重置的搜索过程理论，分析搜索重置策略对队列稳态收敛性的影响，并通过参数空间划分确定收敛区域及阈值行为。

Result: 得到了确保队列资源数量收敛到稳态的参数区域，发现存在一个重置率阈值，其作用在降低和扩大收敛区域之间转变，且该阈值随服务台数指数增长。

Conclusion: 随着服务台数量增加，随机重置更难改善队列系统的收敛性，表明系统规模增大时重置策略的效果受到限制。

Abstract: Proper management of resources whose arrival and consumption are subject to environmental randomness is an intrinsic process in both natural and artificial systems. This phenomenon can be modeled as a queuing process whose arrival distribution is determined by a search process with stochastic resetting. When the queuing system has a limited number of servers and the search process occurs within a bounded domain, the dynamics of expediting or delaying the search through stochastic resetting interact with the long-term dynamics of the number of resources in the queue. We combine results from queuing theory with those from search processes with stochastic resetting in a bounded domain to obtain regions of the parameter space of the search process that ensure convergence of the number of resources in the queue to a steady state. Furthermore, we find a threshold resetting rate at which the effects of stochastic resetting shift from reducing convergence regions to expanding them. Finally, we demonstrate that this threshold value grows exponentially with the number of servers, making it harder for stochastic resetting to improve the convergence of the queueing system.

</details>


### [141] [Mean-field behavior of the finite size Ising model near its critical point](https://arxiv.org/abs/2602.05212)
*D. Olascoaga-Rodríguez,F. Sastre,V. Romero-Rochín*

Main category: cond-mat.stat-mech

TL;DR: 该论文通过蒙特卡洛模拟研究三维有限尺寸Ising模型的临界行为，发现其在接近临界点时符合平均场Landau理论，但随着系统尺寸增大，平均场区域逐渐缩小至零；通过自由能的有限尺度标度形式，成功提取出热力学极限下的临界温度及Ising类临界指数，挑战了传统对平均场理论适用范围的理解。


<details>
  <summary>Details</summary>
Motivation: 重新审视平均场理论在描述临界现象中的作用，特别是在三维有限尺寸Ising系统中是否能在临界点附近正确描述其行为，并探讨Ising普适类与平均场理论之间的关系。

Method: 采用蒙特卡洛模拟方法，计算三维Ising模型的自由能每自旋f(T,m;L)和零磁场下的共存曲线（自发磁化）m_coex(T;L)，结合有限尺寸标度分析，提取临界温度和临界指数ν、γ、β。

Result: 发现有限尺寸系统在临界点附近表现出平均场行为，但该区域随系统尺寸L增大而缩小；通过自由能的有限尺寸标度形式可准确得到热力学极限下的Ising临界指数和Tc；平均场区域在热力学极限下消失。

Conclusion: 平均场理论可在有限尺寸Ising系统中有效描述临界行为，但其适用范围随系统增大而受限；结果表明需重新评估平均场理论在临界现象解释中的角色，强调有限尺寸效应对普适类识别的重要性。

Abstract: Universality classes encompass the analogous thermodynamic behavior of unlike physical systems, at different spatial dimensions $d$, in the vicinity of their critical point. Critical exponents define these classes, with the Ising model being the outstanding prototype that elucidates the differences from the mean-field category, believed to be valid above a critical dimension only. Here, in apparent striking contradiction to the Ising universality class, we demonstrate that the critical behavior of a finite Ising system of $N$ spins in $d = 3$ obeys mean-field Landau theory in the vicinity of its critical point, with classical critical exponents. Yet, when expressed in terms of the linear size $L$ of the system, the free energy unveils its proper finite-size scaling form, from which the thermodynamic limit critical temperature $T_c$ and the Ising critical exponents $ν$, $γ$ and $β$ can be identified. We find that the larger the size $L$, the smaller the mean-field region, shrinking to zero in the thermodynamic limit. These conclusions are achieved via the use of an alternative approach to collect data from a Monte Carlo simulation of a three-dimensional Ising model that allows for the evaluation of the free energy per spin $f = f(T,m;L)$ and of the coexistence curve, or spontaneous magnetization at zero magnetic field, $m_{\rm coex} = m(T;L)$ as functions of temperature $T$ and magnetization per spin $m = M/N$. Our results suggest a revision of the role of mean-field theory in the elucidation of critical phenomena.

</details>


### [142] [Exchange Monte Carlo for continuous-space Path Integral Monte Carlo simulation](https://arxiv.org/abs/2602.05500)
*Xun Zhao,Synge Todo*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种用于有限温度下连续空间路径积分蒙特卡罗模拟的新型交换蒙特卡罗（EMC）方法，通过引入交换更新方案和随机势能切换（SPS），显著提高了涉及粒子置换效应的全局观测量的计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统PIMC方法在处理受粒子置换影响的观测量（如缠绕数）时存在自相关时间过长的问题，尤其是在玻色系统中。

Method: 引入一种交换更新方案，促进不同相互作用区域间的复制体转移，并结合随机势能切换（SPS）来高效分解长程原子间对势（如Lennard-Jones和Aziz势）。

Result: 新方法显著加速了蒙特卡罗动力学，特别是在涉及置换效应的全局观测量上表现突出，同时提升了长程势能计算的效率。

Conclusion: 该EMC方法有效缓解了传统PIMC中的慢动力学问题，为研究强关联玻色系统提供了更高效的模拟工具。

Abstract: We present a novel Exchange Monte Carlo (EMC) method designed for application in continuous-space Path Integral Monte Carlo (PIMC) simulations at finite temperature. Traditional PIMC methods for bosonic systems suffer from long autocorrelation times, particularly when measuring observables affected by particle permutations, such as the winding number. To address this issue, we introduce an exchange update scheme that facilitates replica transitions between different interaction regimes, significantly accelerating Monte Carlo dynamics-especially for global observables sensitive to permutation effects. Furthermore, we incorporate Stochastic Potential Switching (SPS) to efficiently decompose interactions, substantially enhancing computational efficiency for long-range interatomic pair potentials such as the Lennard-Jones and Aziz potentials.

</details>


### [143] [A Novel Mechanism of Ordering in a Coupled Driven System: Vacancy Induced Phase Separation](https://arxiv.org/abs/2602.05537)
*Chandradip Khamrai,Sakuntala Chatterjee*

Main category: cond-mat.stat-mech

TL;DR: 研究了一个包含两种粒子和空位的耦合驱动系统，发现空位的存在会削弱反向偏置，导致新的有序相出现，包括有限电流部分相分离（FPPS）和空位诱导相分离（VIPS）相。


<details>
  <summary>Details</summary>
Motivation: 探索在有空位存在的情况下，不同偏置机制如何影响系统的有序性，并揭示新奇的相变行为。

Method: 通过平均场近似方法分析模型，研究空位对系统中正向和反向偏置竞争的影响。

Result: 发现了两种新的有序相：FPPS和VIPS；空位有效削弱了反向偏置，即使正向偏置较弱也能实现长程有序；景观在FPPS中形成宏观山丘或山谷，在VIPS中形成与系统尺寸平方根成比例的平台。

Conclusion: 空位在调控偏置竞争中起关键作用，能够引发以往未见的新奇有序相，扩展了对驱动系统中自组织行为的理解。

Abstract: We study a coupled driven system where two different species of particles, along with some vacancies or holes, move on a landscape whose shape fluctuates with time. The movement of the particles is guided by the local shape of the landscape, and this shape is also affected by the presence of different particle species. When a particle species push the landscape in the same (opposite) direction of its own motion, it is called an aligned (a reverse) bias. Aligned bias promotes ordering while reverse bias destroys it. In absence of vacancies, the system reduces to previously studied LH model with different kinds of ordered and disordered phases which could be explained as a competition or cooperation between aligned bias and reverse bias. This interplay is expected to remain unaffected even when vacancies are present since vacancies do not impart any kind of bias on the landscape. However, we find presence of vacancies effectively weakens the reverse bias and this significantly changes the outcome of the competition between the two bias types. As a result novel ordered phases emerge which were not seen before. We analytically calculate the new phase boundaries within mean field approximation. We show even when aligned bias is weaker than reverse bias, it is possible to find long range order in the system. We discover two new phases where particle species showing weak aligned bias phase separate and the other species with strong reverse bias stays mixed with the vacancies. We call these phases finite current with partial phase separation (FPPS) and vacancy induced phase separation (VIPS). The landscape beneath the phase separated species takes the form of a macroscopic hill or valley in FPPS phase. But in VIPS phase it has the shape like a plateau whose height scales as square root of system size. The landscape in the remaining part of the system is disordered in both these phases.

</details>
