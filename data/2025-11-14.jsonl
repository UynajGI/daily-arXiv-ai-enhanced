{"id": "2511.09685", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.09685", "abs": "https://arxiv.org/abs/2511.09685", "authors": ["Harold Triedman", "Alexios Mantzarlis"], "title": "What did Elon change? A comprehensive analysis of Grokipedia", "comment": "23 pages, 16 figures, 5 tables", "summary": "Elon Musk released Grokipedia on 27 October 2025 to provide an alternative to Wikipedia, the crowdsourced online encyclopedia. In this paper, we provide the first comprehensive analysis of Grokipedia and compare it to a dump of Wikipedia, with a focus on article similarity and citation practices. Although Grokipedia articles are much longer than their corresponding English Wikipedia articles, we find that much of Grokipedia's content (including both articles with and without Creative Commons licenses) is highly derivative of Wikipedia. Nevertheless, citation practices between the sites differ greatly, with Grokipedia citing many more sources deemed \"generally unreliable\" or \"blacklisted\" by the English Wikipedia community and low quality by external scholars, including dozens of citations to sites like Stormfront and Infowars. We then analyze article subsets: one about elected officials, one about controversial topics, and one random subset for which we derive article quality and topic. We find that the elected official and controversial article subsets showed less similarity between their Wikipedia version and Grokipedia version than other pages. The random subset illustrates that Grokipedia focused rewriting the highest quality articles on Wikipedia, with a bias towards biographies, politics, society, and history. Finally, we publicly release our nearly-full scrape of Grokipedia, as well as embeddings of the entire Grokipedia corpus."}
{"id": "2511.10384", "categories": ["cs.SI", "cs.AI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.10384", "abs": "https://arxiv.org/abs/2511.10384", "authors": ["Raj Gaurav Maurya", "Vaibhav Shukla", "Raj Abhijit Dandekar", "Rajat Dandekar", "Sreedath Panat"], "title": "Simulating Misinformation Propagation in Social Networks using Large Language Models", "comment": "Accepted to CIKM 2025 Workshop LASS", "summary": "Misinformation on social media thrives on surprise, emotion, and identity-driven reasoning, often amplified through human cognitive biases. To investigate these mechanisms, we model large language model (LLM) personas as synthetic agents that mimic user-level biases, ideological alignments, and trust heuristics. Within this setup, we introduce an auditor--node framework to simulate and analyze how misinformation evolves as it circulates through networks of such agents. News articles are propagated across networks of persona-conditioned LLM nodes, each rewriting received content. A question--answering-based auditor then measures factual fidelity at every step, offering interpretable, claim-level tracking of misinformation drift. We formalize a misinformation index and a misinformation propagation rate to quantify factual degradation across homogeneous and heterogeneous branches of up to 30 sequential rewrites. Experiments with 21 personas across 10 domains reveal that identity- and ideology-based personas act as misinformation accelerators, especially in politics, marketing, and technology. By contrast, expert-driven personas preserve factual stability. Controlled-random branch simulations further show that once early distortions emerge, heterogeneous persona interactions rapidly escalate misinformation to propaganda-level distortion. Our taxonomy of misinformation severity -- spanning factual errors, lies, and propaganda -- connects observed drift to established theories in misinformation studies. These findings demonstrate the dual role of LLMs as both proxies for human-like biases and as auditors capable of tracing information fidelity. The proposed framework provides an interpretable, empirically grounded approach for studying, simulating, and mitigating misinformation diffusion in digital ecosystems."}
{"id": "2511.10542", "categories": ["cs.SI", "cs.LG", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.10542", "abs": "https://arxiv.org/abs/2511.10542", "authors": ["Stefano Maria Iacus", "Giuseppe Porro"], "title": "Two Americas of Well-Being: Divergent Rural-Urban Patterns of Life Satisfaction and Happiness from 2.6 B Social Media Posts", "comment": null, "summary": "Using 2.6 billion geolocated social-media posts (2014-2022) and a fine-tuned generative language model, we construct county-level indicators of life satisfaction and happiness for the United States. We document an apparent rural-urban paradox: rural counties express higher life satisfaction while urban counties exhibit greater happiness. We reconcile this by treating the two as distinct layers of subjective well-being, evaluative vs. hedonic, showing that each maps differently onto place, politics, and time. Republican-leaning areas appear more satisfied in evaluative terms, but partisan gaps in happiness largely flatten outside major metros, indicating context-dependent political effects. Temporal shocks dominate the hedonic layer: happiness falls sharply during 2020-2022, whereas life satisfaction moves more modestly. These patterns are robust across logistic and OLS specifications and align with well-being theory. Interpreted as associations for the population of social-media posts, the results show that large-scale, language-based indicators can resolve conflicting findings about the rural-urban divide by distinguishing the type of well-being expressed, offering a transparent, reproducible complement to traditional surveys."}
{"id": "2511.10585", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10585", "abs": "https://arxiv.org/abs/2511.10585", "authors": ["Raman Ebrahimi", "Sean Fuhrman", "Kendrick Nguyen", "Harini Gurusankar", "Massimo Franceschetti"], "title": "Textual understanding boost in the WikiRace", "comment": null, "summary": "The WikiRace game, where players navigate between Wikipedia articles using only hyperlinks, serves as a compelling benchmark for goal-directed search in complex information networks. This paper presents a systematic evaluation of navigation strategies for this task, comparing agents guided by graph-theoretic structure (betweenness centrality), semantic meaning (language model embeddings), and hybrid approaches. Through rigorous benchmarking on a large Wikipedia subgraph, we demonstrate that a purely greedy agent guided by the semantic similarity of article titles is overwhelmingly effective. This strategy, when combined with a simple loop-avoidance mechanism, achieved a perfect success rate and navigated the network with an efficiency an order of magnitude better than structural or hybrid methods. Our findings highlight the critical limitations of purely structural heuristics for goal-directed search and underscore the transformative potential of large language models to act as powerful, zero-shot semantic navigators in complex information spaces."}
{"id": "2511.10508", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2511.10508", "abs": "https://arxiv.org/abs/2511.10508", "authors": ["Steven A. Silber", "Mikko Karttunen"], "title": "Parallel and GPU accelerated code for phase-field and reaction-diffusion simulations", "comment": null, "summary": "We present SymPhas 2.0, a major update of the compile-time symbolic algebra simulation framework SymPhas for phase-field and reaction-diffusion models. This release introduces significant expansions and enhancements that enable the definition of a phase-field model directly from the free-energy functional via compile-time evaluated functional differentiation. It also introduces directional derivatives, symbolic summation, tensor-valued expressions, and compile-time derived finite difference stencils of arbitrary order and accuracy. Furthermore, the code has been parallelized for CPUs with MPI, and GPU computing has been added using CUDA (Compute Unified Device Architecture). For the latter, symbolic expressions are compiled into optimized CUDA kernels, allowing large-scale simulations to execute entirely on the GPU. For large systems ($32,768^2$ in 2D and $1,024^3$ in 3D with double precision), speedups up to $\\sim \\!\\!1,000 \\times$ were obtained compared to the first version of SymPhas using multi-threaded CPU execution on a single system. These developments establish SymPhas 2.0 as a flexible and scalable framework for efficient implementation of phase-field and reaction-diffusion models on GPU-based high-performance computing platforms."}
{"id": "2511.09797", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.09797", "abs": "https://arxiv.org/abs/2511.09797", "authors": ["Kerry A. Nice", "Mark Stevenson"], "title": "Urban Density and Equity of Access to Social Services in Australian Urban Areas", "comment": null, "summary": "To measure access to social services (primary health care, early childhood care/education, and public transport), we create a social service access index (SSI) for Australian capital cities. We show that only two, Melbourne and Sydney, have some limited characteristics of a compact or 15-minute city, but only in city centres and inner cities where population densities are highest and have less low density housing types. In the outer suburban and peri-urban areas as well as across all of the remaining cities, proximity to social services is poor and residents suffer the consequences of spatial inequity."}
{"id": "2511.10064", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.10064", "abs": "https://arxiv.org/abs/2511.10064", "authors": ["Lennart Justin Schulze", "Vito Zago", "Giuseppe Bilotta", "Robert Anthony Dalrymple"], "title": "Localized kernel gradient correction for SPH simulations of water wave propagation", "comment": "Parts of this manuscript have been previously presented in the internal proceedings of the SPHERIC 2022 International Workshop, June 7-9 2022, Catania, Italy", "summary": "Basic Smoothed Particle Hydrodynamics (SPH) models exhibit excessive, numerical dissipation in the simulation of water wave propagation. This can be remedied using higher-order approaches such as kernel gradient correction, which introduce additional computational effort. The present work demonstrates, that the higher-order scheme is only required in a limited part of the water wave in order to obtain satisfying results. The criterion for distinguishing particles in need of special treatment from those that do not is motivated by water wave mechanics. Especially for deep water waves, the approach potentially spares large amounts of computational effort. The present paper also proposes a remedy for issues of the kernel gradient correction occurring at the free surface. Satisfying results for the proposed approach are shown for a standing wave in a basin and a progressive wave train in a long wave tank."}
{"id": "2511.09859", "categories": ["cond-mat.stat-mech", "physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.09859", "abs": "https://arxiv.org/abs/2511.09859", "authors": ["Shreya Shukla", "Abhijith Jayakumar", "Andrey Y. Lokhov"], "title": "Learning of Statistical Field Theories", "comment": null, "summary": "Recovering microscopic couplings directly from data provides a route to solving the inverse problem in statistical field theories, one that complements the traditional-often computationally intractable-forward approach of predicting observables from an action or Hamiltonian. Here, we propose an approach for the inverse problem that uniformly accommodates systems with discrete, continuous, and hybrid variables. We demonstrate accurate parameter recovery in several benchmark systems-including Wegner's Ising gauge theory, $φ^4$ theory, Schwinger and Sine-Gordon models, and mixed spin-gauge systems, and show how iterating the procedure under coarse-graining reconstructs full non-perturbative renormalization-group flows. This gives direct access to phase boundaries, fixed points, and emergent interactions without relying on perturbation theory. We also address a realistic setting where full gauge configurations may be unavailable, and reformulate learning algorithms for multiple field theories so that they are recovered directly using observables such as correlations from scattering data or quantum simulators. We anticipate that our methodology will find widespread use in practical learning of field theories in strongly coupled regimes where analytical tools might fail."}
{"id": "2511.10193", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.10193", "abs": "https://arxiv.org/abs/2511.10193", "authors": ["Siyu He", "Qin Li", "Minyu Feng", "Attila Szolnoki"], "title": "Reputation assimilation mechanism for sustaining cooperation", "comment": null, "summary": "Keeping a high reputation, by contributing to common efforts, plays a key role in explaining the evolution of collective cooperation among unrelated agents in a complex society. Nevertheless, it is not necessarily an individual feature, but may also reflect the general state of a local community. Consequently, a person with a high reputation becomes attractive not just because we can expect cooperative acts with higher probability, but also because such a person is involved in a more efficient group venture. These observations highlight the cumulative and socially transmissible nature of reputation. Interestingly, these aspects were completely ignored by previous works. To reveal the possible consequences, we introduce a spatial public goods game in which we use an assimilated reputation simultaneously characterizing the individual and its neighbors' reputation. Furthermore, a reputation-dependent synergy factor is used to capture the high (or low) quality of a specific group. Through extensive numerical simulations, we investigate how cooperation and extended reputation co-evolve, thereby revealing the dynamic influence of the assimilated reputation mechanism on the emergence and persistence of cooperation. By fostering social learning from high-reputation individuals and granting payoff advantages to high-reputation groups via an adaptive multiplier, the assimilated reputation mechanism promotes cooperation, ultimately to the systemic level."}
{"id": "2511.09747", "categories": ["physics.ao-ph", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.09747", "abs": "https://arxiv.org/abs/2511.09747", "authors": ["Justin Cooke", "Kathleen Donohue", "Clark D Rowley", "Prasad G Thoppil", "D Randolph Watts"], "title": "The Role of Deep Mesoscale Eddies in Ensemble Forecast Performance", "comment": "12 pages, 10 figures", "summary": "Present forecasting efforts rely on assimilation of observational data captured in the upper ocean (< 1000 m depth). These observations constrain the upper ocean and minimally influence the deep ocean. Nevertheless, development of the full water column circulation critically depends upon the dynamical interactions between upper and deep fields. Forecasts demonstrate that the initialization of the deep field is influential for the development and evolution of the surface in the forecast. Deep initial conditions that better agree with observations have lower upper ocean uncertainty as the forecast progresses. Here, best and worst ensemble members in two 92-day forecasts are identified and contrasted in order to determine how the deep ocean differs between these groups. The forecasts cover the duration of the Loop Current Eddy Thor separation event, which coincides with available deep observations in the Gulf. Model member performance is assessed by comparing surface variables against verifying analysis and satellite altimeter data during the forecast time-period. Deep cyclonic and anticyclonic features are reviewed, and compared against deep observations, indicating subtle differences in locations of deep eddies at relevant times. These results highlight both the importance of deep circulation in the dynamics of the Loop Current system and more broadly motivate efforts to assimilate deep observations to better constrain the deep initial fields and improve surface predictions."}
{"id": "2511.10193", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.10193", "abs": "https://arxiv.org/abs/2511.10193", "authors": ["Siyu He", "Qin Li", "Minyu Feng", "Attila Szolnoki"], "title": "Reputation assimilation mechanism for sustaining cooperation", "comment": null, "summary": "Keeping a high reputation, by contributing to common efforts, plays a key role in explaining the evolution of collective cooperation among unrelated agents in a complex society. Nevertheless, it is not necessarily an individual feature, but may also reflect the general state of a local community. Consequently, a person with a high reputation becomes attractive not just because we can expect cooperative acts with higher probability, but also because such a person is involved in a more efficient group venture. These observations highlight the cumulative and socially transmissible nature of reputation. Interestingly, these aspects were completely ignored by previous works. To reveal the possible consequences, we introduce a spatial public goods game in which we use an assimilated reputation simultaneously characterizing the individual and its neighbors' reputation. Furthermore, a reputation-dependent synergy factor is used to capture the high (or low) quality of a specific group. Through extensive numerical simulations, we investigate how cooperation and extended reputation co-evolve, thereby revealing the dynamic influence of the assimilated reputation mechanism on the emergence and persistence of cooperation. By fostering social learning from high-reputation individuals and granting payoff advantages to high-reputation groups via an adaptive multiplier, the assimilated reputation mechanism promotes cooperation, ultimately to the systemic level."}
{"id": "2511.10355", "categories": ["cs.CE", "cond-mat.mtrl-sci", "physics.app-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2511.10355", "abs": "https://arxiv.org/abs/2511.10355", "authors": ["Y. Tu", "B. Wu", "E. Martínez-Pañeda"], "title": "Phase field modelling of cracking and capacity fade in core-shell cathode particles for lithium-ion batteries", "comment": null, "summary": "Core-shell electrode particles are a promising morphology control strategy for high-performance lithium-ion batteries. However, experimental observations reveal that these structures remain prone to mechanical failure, with shell fractures and core-shell debonding occurring after a single charge. In this work, we present a novel, comprehensive computational framework to predict and gain insight into the failure of core-shell morphologies and the associated degradation in battery performance. The fully coupled chemo-mechano-damage model presented captures the interplay between mechanical damage and electrochemical behaviours, enabling the quantification of particle cracking and capacity fade. Both bulk material fracture and interface debonding are captured by utilising the phase field method. We quantify the severity of particle cracking and capacity loss through case studies on a representative core-shell system (NMC811@NMC532). The results bring valuable insights into cracking patterns, underlying mechanisms, and their impact on capacity loss. Surface cracks are found to initiate when a significantly higher lithium concentration accumulates in the core compared to the shell. Interfacial debonding is shown to arise from localised hoop stresses near the core-shell interface, due to greater shell expansion. This debonding develops rapidly, impedes lithium-ion transport, and can lead to more than 10\\% capacity loss after a single discharge. Furthermore, larger particles may experience crack branching driven by extensive tensile zones, potentially fragmenting the entire particle. The framework developed can not only bring new insight into the degradation mechanisms of core-shell particles but also be used to design electrode materials with improved performance and extended lifetime."}
{"id": "2511.10236", "categories": ["cond-mat.stat-mech", "physics.chem-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.10236", "abs": "https://arxiv.org/abs/2511.10236", "authors": ["Mohammad Rahbar", "Christopher J. Stein"], "title": "Exact fluctuation relation for open systems beyond the Jarzynski equality", "comment": "10 pages, 3 figures", "summary": "We derive exact fluctuation equalities for open systems that recover free energy differences between two equilibrium endpoints connected by nonequilibrium processes with arbitrary dynamics and coupling. The exponential of the free energy difference is expressed in terms of ensemble averages of the Hamiltonian of mean force (HMF) shift and the chi-squared divergence between the initial and final marginal probability distribution of the open system. A trajectory counterpart of this relation follows from an asymptotic equilibration postulate, which treats relaxation to the final stationary canonical state as a boundary condition rather than as a consequence of constraints on the driven dynamics. In the frozen-coupling regime, the HMF shift reduces to the bare-system Hamiltonian shift, yielding a clear heat-work decomposition. The Jarzynski equality (JE) is recovered under the assumption of Hamiltonian dynamics for the combined system. We validate the theory on a dissipative, phase-space-compressing drive followed by an underdamped Langevin relaxation, where the assumptions underlying the JE break down, whereas our equality reproduces the exact free energy differences."}
{"id": "2511.10549", "categories": ["physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2511.10549", "abs": "https://arxiv.org/abs/2511.10549", "authors": ["Clara Bradley", "James Owen Weatherall"], "title": "We Have Never Been Sophisticated", "comment": "26 pages", "summary": "Many philosophers of physics maintain that a physical theory that exhibits (certain kinds of) symmetries is flawed, on the grounds that such theories posit \"excess structure\". In an influential paper, Dewar [2019, \"Sophistication about Symmetries\", \\emph{Brit. J. Phil. Sci.} \\textbf{70}: 485-521] introduces a distinction between \"reduction\" and \"sophistication\" as alternative ways of removing excess structure. In this paper we re-examine the distinction as Dewar draws it, and we argue that there is no physically or philosophically important distinction between what Dewar calls \"reduction\" and what he calls \"internal sophistication\". We then argue that there are multiple notions of \"reduction\" in the literature that ought to be distinguished, both in motivation and in outcome."}
{"id": "2511.09747", "categories": ["physics.ao-ph", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.09747", "abs": "https://arxiv.org/abs/2511.09747", "authors": ["Justin Cooke", "Kathleen Donohue", "Clark D Rowley", "Prasad G Thoppil", "D Randolph Watts"], "title": "The Role of Deep Mesoscale Eddies in Ensemble Forecast Performance", "comment": "12 pages, 10 figures", "summary": "Present forecasting efforts rely on assimilation of observational data captured in the upper ocean (< 1000 m depth). These observations constrain the upper ocean and minimally influence the deep ocean. Nevertheless, development of the full water column circulation critically depends upon the dynamical interactions between upper and deep fields. Forecasts demonstrate that the initialization of the deep field is influential for the development and evolution of the surface in the forecast. Deep initial conditions that better agree with observations have lower upper ocean uncertainty as the forecast progresses. Here, best and worst ensemble members in two 92-day forecasts are identified and contrasted in order to determine how the deep ocean differs between these groups. The forecasts cover the duration of the Loop Current Eddy Thor separation event, which coincides with available deep observations in the Gulf. Model member performance is assessed by comparing surface variables against verifying analysis and satellite altimeter data during the forecast time-period. Deep cyclonic and anticyclonic features are reviewed, and compared against deep observations, indicating subtle differences in locations of deep eddies at relevant times. These results highlight both the importance of deep circulation in the dynamics of the Loop Current system and more broadly motivate efforts to assimilate deep observations to better constrain the deep initial fields and improve surface predictions."}
{"id": "2511.09859", "categories": ["cond-mat.stat-mech", "physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.09859", "abs": "https://arxiv.org/abs/2511.09859", "authors": ["Shreya Shukla", "Abhijith Jayakumar", "Andrey Y. Lokhov"], "title": "Learning of Statistical Field Theories", "comment": null, "summary": "Recovering microscopic couplings directly from data provides a route to solving the inverse problem in statistical field theories, one that complements the traditional-often computationally intractable-forward approach of predicting observables from an action or Hamiltonian. Here, we propose an approach for the inverse problem that uniformly accommodates systems with discrete, continuous, and hybrid variables. We demonstrate accurate parameter recovery in several benchmark systems-including Wegner's Ising gauge theory, $φ^4$ theory, Schwinger and Sine-Gordon models, and mixed spin-gauge systems, and show how iterating the procedure under coarse-graining reconstructs full non-perturbative renormalization-group flows. This gives direct access to phase boundaries, fixed points, and emergent interactions without relying on perturbation theory. We also address a realistic setting where full gauge configurations may be unavailable, and reformulate learning algorithms for multiple field theories so that they are recovered directly using observables such as correlations from scattering data or quantum simulators. We anticipate that our methodology will find widespread use in practical learning of field theories in strongly coupled regimes where analytical tools might fail."}
{"id": "2511.10198", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.10198", "abs": "https://arxiv.org/abs/2511.10198", "authors": ["Hao Huang", "Yuming Lin", "Jiazhen Liu"], "title": "Population-mobility coevolution drives spatial heterogeneity of cities", "comment": null, "summary": "The spatial heterogeneity of cities -- the uneven distribution of population and activities -- is fundamental to urban dynamics and related to critical issues such as infrastructure overload, housing affordability, and social inequality. Despite sharing similar scaling laws of population and mobility, cities exhibit vastly different spatial patterns. This paradox call for a mechanistic explanation for the emergence of spatial heterogeneity, while existing qualitative or descriptive studies fail to capture the underlying mechanisms. Here, we propose a coupled dynamical model that describe the intra-city population-mobility coevolution, explaining spatial heterogeneity as an emergent outcome of mutual feedback between the fast-changing mobility and the slow-adapting population. Our model is validated on over 388 million records from eight diverse global cities, successfully reproduces both the statistical laws and realistic spatial patterns. We find out realistic heterogeneity emerges as a distinct stable state, intermediate between disordered homogeneity and unsustainable super-hub dominance. Moreover, we theoretically and empirically show that populated areas are predominantly shaped by coevolution strength, while the increasing distance decay leads cities through a three-phase transition of homogeneity-heterogeneity-homogeneity. Besides, functional attractiveness between areas consistently enhances the ordered heterogeneous structure. Simulations of real-world planning scenarios -- including crisis-induced lockdown, planned zone expansions, and dispersal from congested centers -- indicate that integrated population-mobility policies are more cost-effective than single interventions. Our model can provides mechanistic, high-resolution insights to rigorously inform policy design."}
{"id": "2511.10337", "categories": ["cond-mat.stat-mech", "physics.bio-ph", "physics.chem-ph", "q-bio.MN"], "pdf": "https://arxiv.org/pdf/2511.10337", "abs": "https://arxiv.org/abs/2511.10337", "authors": ["D. Evan Piephoff", "Jianshu Cao"], "title": "Stochastic Thermodynamics of Cooperative Biomolecular Machines: Fluctuation Relations and Hidden Detailed Balance Breaking", "comment": null, "summary": "We examine a biomolecular machine involving a driven, observable process coupled to a hidden process in a kinetically cooperative manner. A stochastic thermodynamics framework is employed to analyze a fluctuation theorem for the first-passage time of the observable process under nonequilibrium steady-state conditions. Based on a generic kinetic model, we demonstrate that, along first-passage trajectories, entropy production remains constant when the changes in stochastic entropy and free energy of the machine are balanced, which corresponds to zero net hidden flux through the initial state manifold. Under this condition, which we define quite generally, this first-passage time fluctuation theorem can be established, with its violation serving as an experimentally detectable signature of hidden detailed balance breaking (which we subsequently characterize). In addition, using an enzymatic model, we show that the violation of our first-passage time fluctuation theorem can be thought of as a consequence of the breakdown of local detailed balance in the steps linking coarse-grained states that correspond to the initial and intermediate state manifolds. In the absence of hidden current, the fluctuation theorem is restored, and a mesoscopic local detailed balance condition can be established, which has implications for the thermodynamic analysis of driven, coarse-grained systems. This work sheds significant light on the unique connections between stochastic thermodynamic quantities and kinetic measurements in complex cooperative networks."}
{"id": "2511.10342", "categories": ["physics.soc-ph", "nlin.AO", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.10342", "abs": "https://arxiv.org/abs/2511.10342", "authors": ["Christos Charalambous"], "title": "Regret, Uncertainty, and Bounded Rationality in Norm-Driven Decisions", "comment": "22 pages, 16 figures", "summary": "This study introduces an agent-based model that explains how regret, uncertainty, and social norms interact to shape vaccination behavior during epidemics. The model integrates three behavioral mechanisms, anticipated regret, evolving norms, and uncertainty-dependent trust, within a unified learning framework. Grounded in psychology and behavioral economics, it captures how individuals make probabilistic choices influenced by material payoffs, fear, trust, and social approval. Simulations of the Susceptible-Infected-Recovered process show that collective outcomes are best when agents display an intermediate level of rationality; they deliberate enough to respond to risk but remain flexible enough to adapt, avoiding the instability of both random and overly rigid decision-making. Regret exerts a dual influence; moderate levels encourage adaptive self-correction, while excessive regret or greed destabilize choices. Uncertainty has a similarly non-linear effect; moderate ambiguity promotes caution, but too much uncertainty disrupts coordination. Social norms restore cooperation by compensating for incomplete information. Among them, personal norms drive behavior when individuals have clear information and moral confidence; injunctive norms, reflecting perceived approval, gain influence under uncertainty; and descriptive norms, based on observing others' actions, serve as informational cues that guide behavior when direct knowledge is limited. Overall, the model provides a psychologically grounded, computationally explicit account of how emotion, cognition, and social norms govern preventive behavior during epidemics."}
{"id": "2511.09639", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.09639", "abs": "https://arxiv.org/abs/2511.09639", "authors": ["Bastien Lapierre", "Per Moosavi", "Blagoje Oblak"], "title": "Nonequilibrium Probes of Quantum Geometry in Gapless Systems", "comment": "38 pages, LaTeX, 6 figures", "summary": "Much of our understanding of gapless many-body quantum systems stems from their low-energy descriptions as conformal field theories. This is especially true in 1+1 dimensions, where such theories have an infinite-dimensional parameter space induced by their conformal symmetry. We reveal the associated quantum geometry by considering finite systems driven by time-dependent conformal transformations. For small deformations, perturbation theory predicts absorption rates and linear responses that are intrinsically related to components of the quantum geometric tensor. For arbitrarily large but adiabatic deformations, we show that periodic drives give rise to nontrivial return amplitudes involving the quantum metric, beyond the familiar leading order that only features a Berry phase. Our field-theoretic findings are universal, comprising general relations between measurable quantities and quantum geometry that only depend on the central charge of the conformal symmetry. This is supported by both analytical results for quantum dynamics under certain Floquet drives, and numerical simulations of gapless lattice models."}
{"id": "2511.09679", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2511.09679", "abs": "https://arxiv.org/abs/2511.09679", "authors": ["Samantha J. Fournier", "Pierfrancesco Urbani"], "title": "High-dimensional dynamical systems: co-existence of attractors, phase transitions, maximal Lyapunov exponent and response to periodic drive", "comment": null, "summary": "We study the dynamical properties of a broad class of high-dimensional random dynamical systems exhibiting chaotic as well as fixed point and periodic attractors. We consider cases in which attractors can co-exists in some regions of the phase diagrams and we characterize their nature by computing the maximal Lyapunov exponent. For a specific choice of the dynamical system we show that this quantity can be computed explicitly in the whole chaotic phase due to an underlying integrability of a properly defined Schrödinger problem. Furthermore, we consider the response of this dynamical systems to periodic perturbations. We show that these dynamical systems act as filters in the frequency-amplitude spectrum of the periodic forcing: only in some regions of the frequency-amplitude plane the periodic forcing leads to a synchronization of the dynamics. All in all, the results that we present mirror closely the ones observed in the past forty years in the study of standard models of random recurrent neural networks. However, the dynamical systems that we consider are easier to study and we believe that this may be an advantage if one wants to go beyond random dynamical systems and consider specific training strategies."}
{"id": "2511.10342", "categories": ["physics.soc-ph", "nlin.AO", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.10342", "abs": "https://arxiv.org/abs/2511.10342", "authors": ["Christos Charalambous"], "title": "Regret, Uncertainty, and Bounded Rationality in Norm-Driven Decisions", "comment": "22 pages, 16 figures", "summary": "This study introduces an agent-based model that explains how regret, uncertainty, and social norms interact to shape vaccination behavior during epidemics. The model integrates three behavioral mechanisms, anticipated regret, evolving norms, and uncertainty-dependent trust, within a unified learning framework. Grounded in psychology and behavioral economics, it captures how individuals make probabilistic choices influenced by material payoffs, fear, trust, and social approval. Simulations of the Susceptible-Infected-Recovered process show that collective outcomes are best when agents display an intermediate level of rationality; they deliberate enough to respond to risk but remain flexible enough to adapt, avoiding the instability of both random and overly rigid decision-making. Regret exerts a dual influence; moderate levels encourage adaptive self-correction, while excessive regret or greed destabilize choices. Uncertainty has a similarly non-linear effect; moderate ambiguity promotes caution, but too much uncertainty disrupts coordination. Social norms restore cooperation by compensating for incomplete information. Among them, personal norms drive behavior when individuals have clear information and moral confidence; injunctive norms, reflecting perceived approval, gain influence under uncertainty; and descriptive norms, based on observing others' actions, serve as informational cues that guide behavior when direct knowledge is limited. Overall, the model provides a psychologically grounded, computationally explicit account of how emotion, cognition, and social norms govern preventive behavior during epidemics."}
{"id": "2511.10342", "categories": ["physics.soc-ph", "nlin.AO", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.10342", "abs": "https://arxiv.org/abs/2511.10342", "authors": ["Christos Charalambous"], "title": "Regret, Uncertainty, and Bounded Rationality in Norm-Driven Decisions", "comment": "22 pages, 16 figures", "summary": "This study introduces an agent-based model that explains how regret, uncertainty, and social norms interact to shape vaccination behavior during epidemics. The model integrates three behavioral mechanisms, anticipated regret, evolving norms, and uncertainty-dependent trust, within a unified learning framework. Grounded in psychology and behavioral economics, it captures how individuals make probabilistic choices influenced by material payoffs, fear, trust, and social approval. Simulations of the Susceptible-Infected-Recovered process show that collective outcomes are best when agents display an intermediate level of rationality; they deliberate enough to respond to risk but remain flexible enough to adapt, avoiding the instability of both random and overly rigid decision-making. Regret exerts a dual influence; moderate levels encourage adaptive self-correction, while excessive regret or greed destabilize choices. Uncertainty has a similarly non-linear effect; moderate ambiguity promotes caution, but too much uncertainty disrupts coordination. Social norms restore cooperation by compensating for incomplete information. Among them, personal norms drive behavior when individuals have clear information and moral confidence; injunctive norms, reflecting perceived approval, gain influence under uncertainty; and descriptive norms, based on observing others' actions, serve as informational cues that guide behavior when direct knowledge is limited. Overall, the model provides a psychologically grounded, computationally explicit account of how emotion, cognition, and social norms govern preventive behavior during epidemics."}
{"id": "2511.10393", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.10393", "abs": "https://arxiv.org/abs/2511.10393", "authors": ["Ming Li", "Youjin Deng", "Jesper Lykke Jacobsen", "Jesús Salas"], "title": "Backbone three-point correlation function in the two-dimensional Potts model", "comment": "The document contains the paper (pdflatex, 14 pages) and 7 pdf figures", "summary": "We study the three-point correlation function of the backbone in the two-dimensional $Q$-state Potts model using the Fortuin-Kasteleyn (FK) representation. The backbone is defined as the bi-connected skeleton of an FK cluster after removing all dangling ends and bridges. To circumvent the severe critical slowing down in direct Potts simulations for large $Q$, we employ large-scale Monte Carlo simulations of the O$(n)$ loop model on the hexagonal lattice, which is regarded to correspond to the Potts model with $Q=n^2$. Using a highly efficient cluster algorithm, we compute the universal three-point amplitude ratios for the backbone ($R_\\text{BB}$) and FK clusters ($R_\\text{FK}$). Our computed $R_\\text{FK}$ exhibits excellent agreement with exact conformal field theory predictions, validating the reliability of our numerical approach. In the critical regime, we find that $R_\\text{BB}$ is systematically larger than $R_\\text{FK}$. Conversely, along the tricritical branch, $R_\\text{BB}$ and $R_\\text{FK}$ coincide within numerical accuracy, strongly suggesting that $R_\\text{BB}=R_\\text{FK}$ holds throughout this regime. This finding mirrors the known equality of the backbone and FK cluster fractal dimensions at tricriticality, jointly indicating that both structures share the same geometric universality."}
{"id": "2511.09860", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.09860", "abs": "https://arxiv.org/abs/2511.09860", "authors": ["Zhongchen Xu", "Xinyang Liu", "Cuiwei Zhang", "Shuai Zhang", "Feng Jin", "Junsen Xiang", "Quansheng Wu", "Xianmin Zhang", "Peijie Sun", "Youguo Shi"], "title": "Quantum fluctuations associated with first-order magnetic transition in a frustrated kagome lattice antiferromagnet", "comment": "13+20 pages, 6+12 figures. Submitted to Physical Review B", "summary": "Intense quantum fluctuations arising from geometrical frustrations in kagome-lattice magnets provide a feasible approach to exotic quantum states. Here, we document an unexpected isosymmetric first-order magnetic transition in the recently synthesized frustrated kagome-lattice antiferromagnet Nd3ScBi5, which is characterized by significant latent heat and a pronounced magnetocaloric effect, as well as discontinuous Raman shifts and negligible hysteresis. Employing the magnetocaloric effect as a detection method, in conjunction with systematical field-dependent physical properties, we uncover a distinctive 1/2 magnetization plateau phase with significant quantum fluctuations. Our study unveils Nd3ScBi5 as a prototypical model with an emerging phase of enhanced quantum fluctuations triggered by first-order magnetic transitions."}
{"id": "2511.10156", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.10156", "abs": "https://arxiv.org/abs/2511.10156", "authors": ["S Rahul", "A Harshitha"], "title": "Competing Localizations on Disordered Non-Hermitian Random Graph Lattice", "comment": "Comments and Suggestions are welcome", "summary": "Phase transitions in one-dimensional lattice systems are well established and have been extensively studied within both Hermitian and non-Hermitian frameworks. In this work, we extend this understanding to a more general setting by investigating localization and delocalization transitions and the behavior of the non-Hermitian skin effect (NHSE) using a tight binding model on a generalized random graph lattice. Our model incorporates three key parameters, asymmetric hopping $Δ$, on site disorder $W$, and a random long-range coupling $p$ that render the underlying nature of random graph. By varying $p,$ $Δ$ and the disorder, we explore the interplay between topology, randomness, and non-Hermiticity in determining localization properties. Our results show the competition between skin effect driven and Anderson driven localizations in the parameter regimes. Despite the presence of large disorder, the skin effect driven localization coexists with Anderson driven localization."}
{"id": "2511.09661", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09661", "abs": "https://arxiv.org/abs/2511.09661", "authors": ["Elias Milios", "Kim P. Wabersich", "Felix Berkel", "Felix Gruber", "Melanie N. Zeilinger"], "title": "Statistically Consistent Approximate Model Predictive Control", "comment": null, "summary": "Model Predictive Control (MPC) offers rigorous safety and performance guarantees but is computationally intensive. Approximate MPC (AMPC) aims to circumvent this drawback by learning a computationally cheaper surrogate policy. Common approaches focus on imitation learning (IL) via behavioral cloning (BC), minimizing a mean-squared-error loss on a collection of state-input pairs. However, BC fundamentally fails to provide accurate approximations when MPC solutions are set-valued due to non-convex constraints or local minima. We propose a two-stage IL procedure to accurately approximate nonlinear, potentially set-valued MPC policies. The method integrates an approximation of the MPC's optimal value function into a one-step look-ahead loss function, and thereby embeds the MPC's constraint and performance objectives into the IL objective.This is achieved by adopting a stabilizing soft constrained MPC formulation, which reflects constraint violations in the optimal value function by combining a constraint tightening with slack penalties. We prove statistical consistency for policies that exactly minimize our IL objective, implying convergence to a safe and stabilizing control law, and establish input-to-state stability guarantees for approximate minimizers. Simulations demonstrate improved performance compared to BC."}
{"id": "2511.09589", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.09589", "abs": "https://arxiv.org/abs/2511.09589", "authors": ["Changjian Xie", "Cheng Wang"], "title": "Convergence analysis of a third order semi-implicit projection method for Landau-Lifshitz-Gilbert equation", "comment": "This work is essentially different with arXiv:2510.25172 since this numerical method with linear system of variable coefficients is proposed, that is highly depends on the numerical solver. The analysis for the gyromagnetic term is different. The constraint for the main result is different", "summary": "The convergence analysis of a third-order scheme for the highly nonlinear Landau-Lifshitz-Gilbert equation with a non-convex constraint is considered. In this paper, we first present a fully discrete semi-implicit method for solving the Landau-Lifshitz-Gilbert equation based on the third-order backward differentiation formula and the one-sided extrapolation (using previous time-step numerical values). A projection step is further used to preserve the length of the magnetization. We provide a rigorous convergence analysis for the fully discrete numerical solution by the introduction of two sets of approximated solutions where one set of solutions solves the Landau-Lifshitz-Gilbert equation and the other is projected onto the unit sphere. Third-order accuracy in time and fourth order accuracy in space is obtained provided that the spatial step-size is the same order as the temporal step-size and slightly large damping parameter $α$ (greater than $\\sqrt{2}/2$). And also, the unique solvability of the numerical solution without any assumption for the step-size in both time and space is theoretically justified, using a monotonicity analysis. All these theoretical results are guaranteed by numerical examples in both 1D and 3D spaces."}
{"id": "2511.09686", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.09686", "abs": "https://arxiv.org/abs/2511.09686", "authors": ["Isaac H. Goldstein", "Julia A. Palacios"], "title": "Coalescent Inference for Epidemics with Latent Periods", "comment": "26 pages, 10 figures, 3 tables", "summary": "Coalescent models are used to study the transmission dynamics of rapidly evolving pathogens from molecular sequence data obtained from infected individuals. However coalescent parameters, such as effective population size, offer limited interpretability for transmission dynamics. In this work, we derive a coalescent model for exposed-infected population dynamics that allows us to infer the number of infected individuals and the effective reproduction number over time from the sample genealogy. The model can be interpreted as a two-deme model in which coalescence is restricted to individuals from different demes (exposed and infected). We propose a new data-augmentation framework with Phase-type distribution for Bayesian inference of epidemiological parameters. We study the performance of our approach on simulations and apply it to re-analyze the 2014 Ebola outbreak in Liberia."}
{"id": "2511.10405", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.10405", "abs": "https://arxiv.org/abs/2511.10405", "authors": ["Shu-Chiuan Chang", "Robert Shrock"], "title": "Chromatic Zeros on the Limit $G^{(p,\\ell)}_\\infty$ of the Family $G^{(p,\\ell)}_m$ of Hierarchical Graphs", "comment": "78 pages, 40 figures", "summary": "We calculate the continuous accumulation set ${\\cal B}_q(p,\\ell)$ of zeros of the chromatic polynomial $P(G^{(p,\\ell)}_m,q)$ in the limit $m \\to \\infty$, on a family of graphs $G^{(p,\\ell)}_m$ defined such that $G^{(p,\\ell)}_m$ is obtained from $G^{(p,\\ell)}_{m-1}$ by replacing each edge (i.e., bond) on $G^{(p,\\ell)}_m$ by $p$ paths each of length $\\ell$ edges, starting with the tree graph $T_2$. Our method uses the property that the chromatic polynomial $P(G,q)$ of a graph $G$ is equal to the $v=-1$ evaluation of the partition function of the $q$-state Potts model, together with (i) the property that $Z(G^{(p,\\ell)}_m,q,v)$ can be expressed via an exact closed-form real-space renormalization (RG) group transformation in terms of $Z(G^{(p,\\ell)}_{m-1},q,v')$, where $v'=F_{(p,\\ell),q}(v)$ is a rational function of $v$ and $q$ and (ii) ${\\cal B}_q(p,\\ell)(v)$ is the locus in the complex $q$-plane that separates regions of different asymptotic behavior of the $m$-fold iterated RG transformation $F_{(p,\\ell),q}(v)$ in the $m \\to \\infty$ limit. Thus, our results involve calculations of region diagrams in the complex $q$-plane showing the type of behavior that occurs in the $m \\to \\infty$ limit of the $m$-fold iterated RG transformation mapping $F_{(p,\\ell),q}(v)$ starting with the initial value $v=v_0=-1$. Calculations are presented of the maximal point $q_c(G^{(p,\\ell)}_\\infty)$ at which the locus ${\\cal B}_q$ crosses the real-$q$ axis, as well as several other points at which, depending on $p$ and $\\ell$, the locus ${\\cal B}_q$ crosses this axis. We give explicit results for a variety of $(p,\\ell)$ cases and observe a number of interesting features. Calculations of the ground-state degeneracy of the Potts antiferromagnet at $q_c(G^{(p,\\ell)}_\\infty)$ are presented. This work extends a previous study with R. Roeder of the $(p,\\ell)=(2,2)$ case to higher $p$ and $\\ell$ values."}
{"id": "2511.09986", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.09986", "abs": "https://arxiv.org/abs/2511.09986", "authors": ["Hui Zhang", "Daming Tian", "Xiaobing Chen", "Lu Chen", "Min Li", "Yetong Bai", "Fengxia Hu", "Baogen Shen", "Jirong Sun", "Weisheng Zhao"], "title": "Competition between Weak Localization and Antilocalization of Dirac-like Fermions in a Spin-Polarized Two-Dimensional Electron Gas at KTaO3 (111) Interface", "comment": null, "summary": "Quantum transport phenomena in two-dimensional electron gases (2DEGs) at oxide interfaces have garnered significant interest owing to their potential in spintronic and quantum information technologies. Here, we systematically investigate the quantum conductance corrections of spin-polarized 2DEGs formed at the interfaces between two insulating oxides, ferromagnetic EuTiO3 (ETO) films and (111)-oriented KTaO3 (KTO) substrates. The anomalous Hall effect and hysteretic magnetoresistance provide clear evidence for long-range ferromagnetic order in the 2DEGs, which could be attributed to interfacial Eu doping in combination with the magnetic proximity effect of the ETO layer. The breaking of time-reversal symmetry by ferromagnetism in the 2DEGs, and with the assistance of spin-orbit coupling effect, gives rise to a nontrivial Berry phase. This results in a competition between weak localization (WL) and weak antilocalization (WAL) in the quantum transport of Dirac-like fermions at the KTO (111) interfaces. Notably, this competitive behavior can be effectively tuned by optical gating via a photoexcitation-induced shift of the Fermi level. Our findings demonstrate a controllable platform based on spin-polarized oxide 2DEGs for quantum transport, opening new avenues for spin-orbitronic and topological electronic applications."}
{"id": "2511.09784", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09784", "abs": "https://arxiv.org/abs/2511.09784", "authors": ["Jungbae Chun", "Felix Biertümpfel", "Peter Seiler"], "title": "Robust Time-Varying Control Barrier Functions with Sector-Bounded Nonlinearities", "comment": "Submitted to the 2026 American Control Conference", "summary": "This paper presents a novel approach for ensuring safe operation of systems subject to input nonlinearities and time-varying safety constraints. We formulate robust time-varying control barrier functions by combining two ingredients: (i) time-varying control barrier functions which capture the time-varying safety constraints, and (ii) pointwise-in-time quadratic constraints that bound the nonlinearity. These ingredients are used to design a safety filter. This filter ensures safety while minimally altering the command from a given baseline controller. The safety filter is implemented as the solution of a second-order cone program, which can be efficiently computed online. The approach is demonstrated on a simple car obstacle avoidance scenario."}
{"id": "2511.09680", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.09680", "abs": "https://arxiv.org/abs/2511.09680", "authors": ["Shunyuan Shang", "Ziyuan Shi", "Mohamed-Slim Alouini"], "title": "SLIPT for Underwater IoT: System Modeling and Performance Analysis", "comment": null, "summary": "This paper presents a unified analytical framework for a two phase underwater wireless optical communication (UWOC) system that integrates Simultaneous Lightwave Information and Power Transfer (SLIPT) using a photovoltaic (PV) panel receiver. The proposed architecture enables self powered underwater sensor nodes by leveraging wide area and low cost PV panels for concurrent optical signal detection and energy harvesting. We develop a composite statistical channel that combines distance dependent absorption, turbulence induced fading characterized by the mixture Exponential Generalized Gamma (EGG )distribution, and beam misalignment due to pointing errors. Based on this model we derive closed form expressions for the probability density function, the cumulative distribution function, the outage probability (OP), the average bit error rate, the ergodic capacity, and the harvested power using Meijer G and Fox H functions. Overall, the paper introduces a practical analytical framework that provides clear guidance for design, optimization, and operation of SLIPT based UWOC systems."}
{"id": "2511.09698", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.09698", "abs": "https://arxiv.org/abs/2511.09698", "authors": ["Samuel J. Eschker", "Antik Chakraborty", "Melanie Gall", "Peter Jevtic", "Jianxi Su"], "title": "State Space Modeling of Mortgage Default Rates under Natural Hazard Shocks", "comment": "To appear in North American Actuarial Journal", "summary": "Mortgage default rates, on the one hand, serve as a measure of economic health to support decision-making by insurance companies, and on the other hand, is a key risk factor in the asset-liability management (ALM) practice, as mortgage related assets constitute a significant proportion of insurers' investment portfolios. This paper studies the relationship between economic losses due to natural hazards and mortgage default rates. The topic is greatly relevant to the insurance industry, as excessive insurance losses from natural hazards can lead to a surge in mortgage defaults, creating compounded challenges for insurers. To this end, we apply a state-space modeling approach to decouple the effect of natural hazard losses on mortgage default rates after controlling for other economic determinants through the inclusion of latent variables. Moreover, we consider a sliced variant of the classical SSM to capture the subtle relationship that only emerges when natural hazard losses are sufficiently high. Our model verifies the significance of this relationship and provides insights into how natural hazard losses manifest as increased mortgage default rates."}
{"id": "2511.09674", "categories": ["physics.geo-ph", "cs.LG", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.09674", "abs": "https://arxiv.org/abs/2511.09674", "authors": ["Hannah Lu", "Lluıs Salo-Salgado", "Ruben Juanes"], "title": "Lithological Controls on the Permeability of Geologic Faults: Surrogate Modeling and Sensitivity Analysis", "comment": null, "summary": "Fault zones exhibit complex and heterogeneous permeability structures influenced by stratigraphic, compositional, and structural factors, making them critical yet uncertain components in subsurface flow modeling. In this study, we investigate how lithological controls influence fault permeability using the PREDICT framework: a probabilistic workflow that couples stochastic fault geometry generation, physically constrained material placement, and flow-based upscaling. The flow-based upscaling step, however, is a very computationally expensive component of the workflow and presents a major bottleneck that makes global sensitivity analysis (GSA) intractable, as it requires millions of model evaluations. To overcome this challenge, we develop a neural network surrogate to emulate the flow-based upscaling step. This surrogate model dramatically reduces the computational cost while maintaining high accuracy, thereby making GSA feasible. The surrogate-model-enabled GSA reveals new insights into the effects of lithological controls on fault permeability. In addition to identifying dominant parameters and negligible ones, the analysis uncovers significant nonlinear interactions between parameters that cannot be captured by traditional local sensitivity methods."}
{"id": "2511.09807", "categories": ["math.ST", "math.AP", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.09807", "abs": "https://arxiv.org/abs/2511.09807", "authors": ["Alberto González-Sanz", "Eustasio del Barrio", "Marcel Nutz"], "title": "Sample Complexity of Quadratically Regularized Optimal Transport", "comment": null, "summary": "It is well known that optimal transport suffers from the curse of dimensionality: when the prescribed marginals are approximated by i.i.d. samples, the convergence of the empirical optimal transport problem to the population counterpart slows exponentially with increasing dimension. Entropically regularized optimal transport (EOT) has become the standard bearer in many statistical applications as it avoids this curse. Indeed, EOT has parametric sample complexity, as has been shown in a series of works based on the smoothness of the EOT potentials or the strong concavity of the dual EOT problem. However, EOT produces full-support approximations to the (sparse) OT problem, leading to overspreading in applications, and is computationally unstable for small regularization parameters. The most popular alternative is quadratically regularized optimal transport (QOT), which penalizes couplings by $L^2$ norm instead of relative entropy. QOT produces sparse approximations of OT and is computationally stable. However, its potentials are not smooth (do not belong to a Donsker class) and its dual problem is not strongly concave, hence QOT is often assumed to suffer from the curse of dimensionality. In this paper, we show that QOT nevertheless has parametric sample complexity. More precisely, we establish central limit theorems for its dual potentials, optimal couplings, and optimal costs. Our analysis is based on novel arguments that focus on the regularity of the support of the optimal QOT coupling. Specifically, we establish a Lipschitz property of its sections and leverage VC theory to bound its statistical complexity. Our analysis also leads to gradient estimates of independent interest, including $C^{1,1}$ regularity of the population potentials."}
{"id": "2511.09639", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.09639", "abs": "https://arxiv.org/abs/2511.09639", "authors": ["Bastien Lapierre", "Per Moosavi", "Blagoje Oblak"], "title": "Nonequilibrium Probes of Quantum Geometry in Gapless Systems", "comment": "38 pages, LaTeX, 6 figures", "summary": "Much of our understanding of gapless many-body quantum systems stems from their low-energy descriptions as conformal field theories. This is especially true in 1+1 dimensions, where such theories have an infinite-dimensional parameter space induced by their conformal symmetry. We reveal the associated quantum geometry by considering finite systems driven by time-dependent conformal transformations. For small deformations, perturbation theory predicts absorption rates and linear responses that are intrinsically related to components of the quantum geometric tensor. For arbitrarily large but adiabatic deformations, we show that periodic drives give rise to nontrivial return amplitudes involving the quantum metric, beyond the familiar leading order that only features a Berry phase. Our field-theoretic findings are universal, comprising general relations between measurable quantities and quantum geometry that only depend on the central charge of the conformal symmetry. This is supported by both analytical results for quantum dynamics under certain Floquet drives, and numerical simulations of gapless lattice models."}
{"id": "2511.10163", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.10163", "abs": "https://arxiv.org/abs/2511.10163", "authors": ["Yixin Ma", "Chao Xu", "Shenghan Jiang"], "title": "Measurement protocol for detecting correlated topological insulators in synthetic quantum systems", "comment": "7+11 pages, 4+2 figures", "summary": "Two-dimensional topological insulators, characterized by symmetry-protected anomalous boundary modes, have been generalized to the strongly correlated regime for both bosonic and fermionic systems. As correlated topological insulators (TI) approach experimental realization in quantum simulators, conventional probes, such as transport measurements, are not easily applicable to these synthetic platforms. In this study, we focus on two examples of correlated TI: a bosonic TI protected by $\\mathbb{Z}_2\\times U(1)$ symmetry and the fermionic quantum spin Hall insulator protected by time-reversal symmetry. We propose a unified, readily implementable protocol based on measuring the disorder parameter $\\langle\\exp(\\mathrm{i}θ\\hat{Q}_A)\\rangle$ for a large subregion $A$, with $\\hat{Q}_A$ the total charge operator within $A$. Our key finding is that this quantity exhibits non-analytical dependence on $θ$ for correlated TI, a signature robust against decoherence. We establish this diagnostic through both numerical simulations and analytical derivations. This protocol is well-suited for implementation on near-term quantum simulation platforms, providing a direct route to experimentally confirm correlated TI."}
{"id": "2511.09799", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09799", "abs": "https://arxiv.org/abs/2511.09799", "authors": ["Lyes Smaili", "Soulaimane Berkane"], "title": "A Smooth Penalty-Based Feedback Law for Reactive Obstacle Avoidance with Convergence Guarantees", "comment": null, "summary": "This paper addresses the problem of safe autonomous navigation in unknown obstacle-filled environments using only local sensory information. We propose a smooth feedback controller derived from an unconstrained penalty-based formulation that guarantees safety by construction. The controller modifies an arbitrary nominal input through a closed-form expression. The resulting closed-form feedback has a projection structure that interpolates between the nominal control and its orthogonal projection onto the obstacle boundary, ensuring forward invariance of a user-defined safety margin. The control law depends only on the distance and bearing to obstacles and requires no map, switching, or set construction. When the nominal input is a gradient descent of a navigation potential, we prove that the closed-loop system achieves almost global asymptotic stability (AGAS) to the goal. Undesired equilibria are shown to be unstable under a mild geometric curvature condition, which compares the normal curvature of the obstacle boundary with that of the potential level sets. We refer to the proposed method as SPF (Safe Penalty-based Feedback), which ensures safe and smooth navigation with minimal computational overhead, as demonstrated through simulations in complex 2D and 3D environments."}
{"id": "2511.09728", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.09728", "abs": "https://arxiv.org/abs/2511.09728", "authors": ["Mohammad Mahabubur Rahman", "Deepanshu Verma"], "title": "Regularity and error estimates in physics-informed neural networks for the Kuramoto-Sivashinsky equation", "comment": null, "summary": "Due to its nonlinearity, bi-harmonic dissipation, and backward heat-like term in the absence of a divergence-free condition, the $2$-D/$3$-D Kuramoto-Sivashinsky equation poses significant challenges for both mathematical analysis and numerical approximation. These difficulties motivate the development of methods that blend classical analysis with numerical approximation approaches embodied in the framework of the physics-informed neural networks (PINNs). In addition, despite the extensive use of PINN frameworks for various linear and nonlinear PDEs, no study had previously established rigorous error estimates for the Kuramoto-Sivashinsky equation within a PINN setting. In this work, we overcome the inherent challenges, and establish several global regularity criteria based on space-time integrability conditions in Besov spaces. We then derive the first rigorous error estimates for the PINNs approximation of the Kuramoto-Sivashinsky equation and validate our theoretical error bounds through numerical simulations."}
{"id": "2511.09759", "categories": ["stat.ME", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.09759", "abs": "https://arxiv.org/abs/2511.09759", "authors": ["Borna Bateni", "Yubai Yuan", "Qi Xu", "Annie Qu"], "title": "Distributional Treatment Effect Estimation across Heterogeneous Sites via Optimal Transport", "comment": null, "summary": "We propose a novel framework for synthesizing counterfactual treatment group data in a target site by integrating full treatment and control group data from a source site with control group data from the target. Departing from conventional average treatment effect estimation, our approach adopts a distributional causal inference perspective by modeling treatment and control as distinct probability measures on the source and target sites. We formalize the cross-site heterogeneity (effect modification) as a push-forward transformation that maps the joint feature-outcome distribution from the source to the target site. This transformation is learned by aligning the control group distributions between sites using an Optimal Transport-based procedure, and subsequently applied to the source treatment group to generate the synthetic target treatment distribution. Under general regularity conditions, we establish theoretical guarantees for the consistency and asymptotic convergence of the synthetic treatment group data to the true target distribution. Simulation studies across multiple data-generating scenarios and a real-world application to patient-derived xenograft data demonstrate that our framework robustly recovers the full distributional properties of treatment effects."}
{"id": "2511.09805", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2511.09805", "abs": "https://arxiv.org/abs/2511.09805", "authors": ["Albert Leonardo Aguilar Suarez", "Gregory Beroza"], "title": "Pervasive Label Errors in Seismological Machine Learning Datasets", "comment": null, "summary": "The recent boom in artificial intelligence and machine learning has been powered by large datasets with accurate labels, combined with algorithmic advances and efficient computing. The quality of data can be a major factor in determining model performance. Here, we detail observations of commonly occurring errors in popular seismological machine learning datasets. We used an ensemble of available deep learning models PhaseNet and EQTransformer to evaluate the dataset labels and found four types of errors ranked from most prevalent to least prevalent: (1) unlabeled earthquakes; (2) noise samples that contain earthquakes; (3) inaccurately labeled arrival times, and (4) absent earthquake signals. We checked a total of 8.6 million examples from the following datasets: Iquique, ETHZ, PNW, TXED, STEAD, INSTANCE, AQ2009, and CEED. The average error rate across all datasets is 3.9 %, ranging from nearly zero to 8 % for individual datasets. These faulty data and labels are likely to degrade model training and performance. By flagging these errors, we aim to increase the quality of the data used to train machine learning models, especially for the measurement of arrival times, and thereby to improve the reliability of the models. We present a companion list of examples that contain problems, aiming to integrate them into training routines so that only the reliable data is used for training."}
{"id": "2511.09959", "categories": ["math.ST", "math.DG"], "pdf": "https://arxiv.org/pdf/2511.09959", "abs": "https://arxiv.org/abs/2511.09959", "authors": ["Ayumu Fukushi", "Yoshinori Nakanishi-Ohno", "Takeru Matsuda"], "title": "Flatness of location-scale-shape models under the Wasserstein metric", "comment": null, "summary": "In Wasserstein geometry, one-dimensional location-scale models are flat both intrinsically and extrinsically-that is, they are curvature-free as well as totally geodesic in the space of probability distributions. In this study, we introduce a class of one-dimensional statistical models, termed the location-scale-shape model, which generalizes several distributions used in extreme-value theory. This model has a shape parameter that specifies the tail heaviness. We investigate the Wasserstein geometry of the location-scale-shape model and show that it is intrinsically flat but extrinsically curved."}
{"id": "2511.09661", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09661", "abs": "https://arxiv.org/abs/2511.09661", "authors": ["Elias Milios", "Kim P. Wabersich", "Felix Berkel", "Felix Gruber", "Melanie N. Zeilinger"], "title": "Statistically Consistent Approximate Model Predictive Control", "comment": null, "summary": "Model Predictive Control (MPC) offers rigorous safety and performance guarantees but is computationally intensive. Approximate MPC (AMPC) aims to circumvent this drawback by learning a computationally cheaper surrogate policy. Common approaches focus on imitation learning (IL) via behavioral cloning (BC), minimizing a mean-squared-error loss on a collection of state-input pairs. However, BC fundamentally fails to provide accurate approximations when MPC solutions are set-valued due to non-convex constraints or local minima. We propose a two-stage IL procedure to accurately approximate nonlinear, potentially set-valued MPC policies. The method integrates an approximation of the MPC's optimal value function into a one-step look-ahead loss function, and thereby embeds the MPC's constraint and performance objectives into the IL objective.This is achieved by adopting a stabilizing soft constrained MPC formulation, which reflects constraint violations in the optimal value function by combining a constraint tightening with slack penalties. We prove statistical consistency for policies that exactly minimize our IL objective, implying convergence to a safe and stabilizing control law, and establish input-to-state stability guarantees for approximate minimizers. Simulations demonstrate improved performance compared to BC."}
{"id": "2511.10489", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.10489", "abs": "https://arxiv.org/abs/2511.10489", "authors": ["Matías G. Gonzalez", "Johannes Reuther"], "title": "Spin Liquids on the Tetratrillium Lattice", "comment": null, "summary": "The tetratrillium lattice has recently been proposed as responsible for the dynamical properties observed in the $S=1$ langbeinite compound K$_2$Ni$_2$(SO$_4$)$_3$. Here, we study in detail the classical spin liquid properties of this lattice of tri-coordinated tetrahedra using classical Monte Carlo and large-$N$ theory calculations. In the large-$N$ limit, we find that the system presents a gapped spectrum with flat bottom bands, giving rise to a fragile spin liquid with exponentially decaying correlations according to the classification of classical spin liquids. We confirm that this scenario also holds in the more realistic Ising and Heisenberg cases, for which the system does not exhibit any finite-temperature phase transition, and the low-temperature spin structure factors exhibit excellent quantitative agreement with the large-$N$ theory. We also provide insight into the quantum $S=1/2$ limit by performing pseudo-Majorana functional renormalization group calculations at finite temperatures, and discuss the possible phases that can arise in the ground state due to quantum fluctuations."}
{"id": "2511.09830", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09830", "abs": "https://arxiv.org/abs/2511.09830", "authors": ["Md Saiful Islam", "Rahul Bhadani"], "title": "Resilient Controller Design with Exponential Reaching Law for Enhanced Load Frequency Stability in Multi-Area Interconnected Microgrids", "comment": null, "summary": "We present a load frequency control strategy deploying a decentralized robust global integral terminal sliding mode control (GITSMC) method to maintain stable frequency and tie-line power in multi-area interconnected microgrids with aggregated uncertainties. To achieve this, firstly, we have developed a mathematical model of the multi-area interconnected system incorporating disturbances from solar photovoltaic (PV), wind turbine (WT) generation and load demand, as aggregated uncertainties. Secondly, we have designed a global integral terminal sliding surface with an exponential reaching law for each area to enhance system dynamic performance and suppress chattering within a finite time. Thirdly, the overall stability of the closed-loop system is analyzed using the Lyapunov stability theorem. Finally, extensive simulations are conducted on the IEEE 10-generator New England 39-bus power system, including load disturbances and variable PV and WT generation. The results demonstrate the performance of the proposed GITSMC approach, achieving approximately 94.9% improvement in ITSE and 94.4% improvement in ISE, confirming its superior accuracy and dynamic performance compared to the existing controller."}
{"id": "2511.09753", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.09753", "abs": "https://arxiv.org/abs/2511.09753", "authors": ["Nicolas Venkovic", "Hartwig Anzt"], "title": "Global iterative methods for sparse approximate inverses of symmetric positive-definite matrices", "comment": "49 pages, 10 figures, 5 tables", "summary": "The nonlinear (preconditioned) conjugate gradient N(P)CG method and the locally optimal (preconditioned) minimal residual LO(P)MR method, both of which are used for the iterative computation of sparse approximate inverses (SPAIs) of symmetric positive-definite (SPD) matrices, are introduced and analyzed. The (preconditioned) conjugate gradient (P)CG method is also employed and presented for comparison. The N(P)CG method is defined as a one-dimensional projection with residuals made orthogonal to the current search direction, itself made $A$-orthogonal to the last search direction. The residual orthogonality, expressed via Frobenius inner product, actually holds against all previous search directions, making each iterate globally optimal, that is, that minimizes the Frobenius A-norm of the error over the affine Krylov subspace of $A^2$ generated by the initial gradient. The LO(P)MR method is a two-dimensional projection method that enriches iterates produced by the (preconditioned) minimal residual (P)MR method. These approaches differ from existing descent methods and aim to accelerate convergence compared to other global iteration methods, including (P)MR and (preconditioned) steepest descent (P)SD, previously used for SPAI computation. The methods are implemented with practical dropping strategies to control the growth of nonzero components in the approximate inverse. Numerical experiments are performed in which approximate inverses of several sparse SPD matrices are computed. N(P)CG provides a slight improvement over (P)SD, but remains generally less effective than (P)MR. On the other hand, while (P)CG does improve (P)MR, its convergence is more affected by the dropping of nonzero components, ill-conditioning, and small eigenvalues. LO(P)MR is more robust than (P)MR and (P)CG, consistently outperforms other methods, converging faster to better and often sparser approximations."}
{"id": "2511.09767", "categories": ["stat.ME", "cs.LG", "econ.GN", "eess.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.09767", "abs": "https://arxiv.org/abs/2511.09767", "authors": ["Alessandro V. M. Oliveira"], "title": "Modelos Empiricos de Pos-Dupla Selecao por LASSO: Discussoes para Estudos do Transporte Aereo", "comment": "Article in Portuguese", "summary": "This paper presents and discusses forms of estimation by regularized regression and model selection using the LASSO method - Least Absolute Shrinkage and Selection Operator. LASSO is recognized as one of the main supervised learning methods applied to high-dimensional econometrics, allowing work with large volumes of data and multiple correlated controls. Conceptual issues related to the consequences of high dimensionality in modern econometrics and the principle of sparsity, which underpins regularization procedures, are addressed. The study examines the main post-double selection and post-regularization models, including variations applied to instrumental variable models. A brief description of the lassopack routine package, its syntaxes, and examples of HD, HDS (High-Dimension Sparse), and IV-HDS models, with combinations involving fixed effects estimators, is also presented. Finally, the potential application of the approach in research focused on air transport is discussed, with emphasis on an empirical study on the operational efficiency of airlines and aircraft fuel consumption."}
{"id": "2511.10033", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2511.10033", "abs": "https://arxiv.org/abs/2511.10033", "authors": ["Changxin Wei", "Xintong Dong", "Xinyang Wang"], "title": "2.5D Transformer: An Efficient 3D Seismic Interpolation Method without Full 3D Training", "comment": null, "summary": "Transformer has emerged as a powerful deep-learning technique for two-dimensional (2D) seismic data interpolation, owing to its global modeling ability. However, its core operation introduces heavy computational burden due to the quadratic complexity, hindering its further application to higher-dimensional data. To achieve Transformer-based three-dimensional (3D) seismic interpolation, we propose a 2.5-dimensional Transformer network (T-2.5D) that adopts a cross-dimensional transfer learning (TL) strategy, so as to adapt the 2D Transformer encoders to 3D seismic data. The proposed T-2.5D is mainly composed of 2D Transformer encoders and 3D seismic dimension adapters (SDAs). Each 3D SDA is placed before a Transformer encoder to learn spatial correlation information across seismic lines. The proposed cross-dimensional TL strategy comprises two stages: 2D pre-training and 3D fine-tuning. In the first stage, we optimize the 2D Transformer encoders using a large amount of 2D data patches. In the second stage, we freeze the 2D Transformer encoders and fine-tune the 3D SDAs using limited 3D data volumes. Extensive experiments on multiple datasets are conducted to assess the effectiveness and efficiency of T-2.5D. Experimental results demonstrate that the proposed method achieves comparable performance to that of full 3D Transformer at a significantly low cost."}
{"id": "2511.10078", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.10078", "abs": "https://arxiv.org/abs/2511.10078", "authors": ["Spandan Ghoshal", "Bilol Banerjee", "Anil K. Ghosh"], "title": "On High-Dimensional Change-Point Detection Based on Pairwise Distances", "comment": null, "summary": "In change-point analysis, one aims at finding the locations of abrupt distributional changes (if any) in a sequence of multivariate observations. In this article, we propose some nonparametric methods based on averages of pairwise distances for this purpose. These distance-based methods can be conveniently used for high-dimensional data even when the dimension is much larger than the sample size (i.e., the length of the sequence). We carry out some theoretical investigations on the behaviour of these methods not only when the dimension of the data remains fixed and the sample size grows to infinity, but also in situations where the dimension diverges to infinity while the sample size may or may not grow with the dimension. Several high-dimensional datasets are analyzed to compare the empirical performance of these proposed methods against some state-of-the-art methods."}
{"id": "2511.09784", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09784", "abs": "https://arxiv.org/abs/2511.09784", "authors": ["Jungbae Chun", "Felix Biertümpfel", "Peter Seiler"], "title": "Robust Time-Varying Control Barrier Functions with Sector-Bounded Nonlinearities", "comment": "Submitted to the 2026 American Control Conference", "summary": "This paper presents a novel approach for ensuring safe operation of systems subject to input nonlinearities and time-varying safety constraints. We formulate robust time-varying control barrier functions by combining two ingredients: (i) time-varying control barrier functions which capture the time-varying safety constraints, and (ii) pointwise-in-time quadratic constraints that bound the nonlinearity. These ingredients are used to design a safety filter. This filter ensures safety while minimally altering the command from a given baseline controller. The safety filter is implemented as the solution of a second-order cone program, which can be efficiently computed online. The approach is demonstrated on a simple car obstacle avoidance scenario."}
{"id": "2511.10503", "categories": ["cond-mat.str-el", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2511.10503", "abs": "https://arxiv.org/abs/2511.10503", "authors": ["Mateo Cárdenes Wuttig", "Andrew J. Millis"], "title": "From One to Two Dimensions: Magnetic Phases in Weakly Coupled Spin Ladders", "comment": null, "summary": "A large variety of materials can be approximately described by means of spin-1/2 Heisenberg ladders. Here, the Density Matrix Renormalization Group (DMRG) algorithm together with a previously established numerical self-consistent mean-field approximation is used to investigate the magnetic properties of spin ladders coupled in a second dimension. The full ground state phase diagram including spin-gapped, antiferromagnetic, ferrimagnetic and fully polarized phases is presented as a function of interladder and intraladder coupling and magnetic field. Measurement of the dependence of magnetization on applied magnetic field is shown to enable location of a material on the phase diagram and determination of the Hamiltonian parameters. These results provide a practical route toward identifying and characterizing magnetic materials composed of coupled spin ladders."}
{"id": "2511.10015", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10015", "abs": "https://arxiv.org/abs/2511.10015", "authors": ["Dejin Ren", "Yiling Xue", "Taoran Wu", "Bai Xue"], "title": "Efficient Verification and Falsification of ReLU Neural Barrier Certificates", "comment": null, "summary": "Barrier certificates play an important role in verifying the safety of continuous-time systems, including autonomous driving, robotic manipulators and other critical applications. Recently, ReLU neural barrier certificates -- barrier certificates represented by the ReLU neural networks -- have attracted significant attention in the safe control community due to their promising performance. However, because of the approximate nature of neural networks, rigorous verification methods are required to ensure the correctness of these certificates. This paper presents a necessary and sufficient condition for verifying the correctness of ReLU neural barrier certificates. The proposed condition can be encoded as either an Satisfiability Modulo Theories (SMT) or optimization problem, enabling both verification and falsification. To the best of our knowledge, this is the first approach capable of falsifying ReLU neural barrier certificates. Numerical experiments demonstrate the validity and effectiveness of the proposed method in both verifying and falsifying such certificates."}
{"id": "2511.09779", "categories": ["math.NA", "math.DG"], "pdf": "https://arxiv.org/pdf/2511.09779", "abs": "https://arxiv.org/abs/2511.09779", "authors": ["Max Kreider", "John Harlim", "Daning Huang"], "title": "A model-free method for discovering symmetry in differential equations", "comment": null, "summary": "Symmetry in differential equations reveals invariances and offers a powerful means to reduce model complexity. Lie group analysis characterizes these symmetries through infinitesimal generators, which provide a local, linear criterion for invariance. However, identifying Lie symmetries directly from scattered data, without explicit knowledge of the governing equations, remains a significant challenge. This work introduces a numerical scheme that approximates infinitesimal generators from data sampled on an unknown smooth manifold, enabling the recovery of continuous symmetries without requiring the analytical form of the differential equations. We employ a manifold learning technique, Generalized Moving Least Squares, to prolongate the data, from which a linear system is constructed whose null space encodes the infinitesimal generators representing the symmetries. Convergence bounds for the proposed approach are derived. Several numerical experiments, including ordinary and partial differential equations, demonstrate the method's accuracy, robustness, and convergence, highlighting its potential for data-driven discovery of symmetries in dynamical systems."}
{"id": "2511.09814", "categories": ["stat.ME", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09814", "abs": "https://arxiv.org/abs/2511.09814", "authors": ["Yuki Murakami", "Takumi Hattori", "Kohsuke Kubota"], "title": "Multiple Treatments Causal Effects Estimation with Task Embeddings and Balanced Representation Learning", "comment": "33 pages", "summary": "The simultaneous application of multiple treatments is increasingly common in many fields, such as healthcare and marketing. In such scenarios, it is important to estimate the single treatment effects and the interaction treatment effects that arise from treatment combinations. Previous studies have proposed using independent outcome networks with subnetworks for interactions, or combining task embedding networks that capture treatment similarity with variational autoencoders. However, these methods suffer from the lack of parameter sharing among related treatments, or the estimation of unnecessary latent variables reduces the accuracy of causal effect estimation. To address these issues, we propose a novel deep learning framework that incorporates a task embedding network and a representation learning network with the balancing penalty. The task embedding network enables parameter sharing across related treatment patterns because it encodes elements common to single effects and contributions specific to interaction effects. The representation learning network with the balancing penalty learns representations nonparametrically from observed covariates while reducing distances in representation distributions across different treatment patterns. This process mitigates selection bias and avoids model misspecification. Simulation studies demonstrate that the proposed method outperforms existing baselines, and application to real-world marketing datasets confirms the practical implications and utility of our framework."}
{"id": "2511.10452", "categories": ["math.NA", "math.OC", "physics.flu-dyn", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2511.10452", "abs": "https://arxiv.org/abs/2511.10452", "authors": ["Gonzalo G. de Diego", "Georg Stadler"], "title": "Learning parameter-dependent shear viscosity from data, with application to sea and land ice", "comment": null, "summary": "Complex physical systems which exhibit fluid-like behavior are often modeled as non-Newtonian fluids. A crucial element of a non-Newtonian model is the rheology, which relates inner stresses with strain-rates. We propose a framework for inferring rheological models from data that represents the fluid's effective viscosity with a neural network. By writing the rheological law in terms of tensor invariants and tailoring the network's properties, the inferred model satisfies key physical and mathematical properties, such as isotropic frame-indifference and existence of a convex potential of dissipation. Within this framework, we propose two approaches to learning a fluid's rheology: 1) a standard regression that fits the rheological model to stress data and 2) a PDE-constrained optimization method that infers rheological models from velocity data. For the latter approach, we combine finite element and machine learning libraries. We demonstrate the accuracy and robustness of our method on land and sea ice rheologies which also depend on external parameters. For land ice, we infer the temperature-dependent Glen's law and, for sea ice, the concentration-dependent shear component of the viscous-plastic model. For these two models, we explore the effects of large data errors. Finally, we infer an unknown concentration-dependent model that reproduces Lagrangian ice floe simulation data. Our method discovers a rheology that generalizes well outside of the training dataset and exhibits both shear-thickening and thinning behaviors depending on the concentrations."}
{"id": "2511.10103", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.10103", "abs": "https://arxiv.org/abs/2511.10103", "authors": ["Fabian Mies", "Benedikt Wilkens"], "title": "Rough Hurst function estimation", "comment": null, "summary": "The fractional Brownian motion (fBm) is parameterized by the Hurst exponent $H\\in(0,1)$, which determines the dependence structure and regularity of sample paths. Empirical findings suggest that the Hurst exponent may be non-constant in time, giving rise to the so-called multifractional Brownian motion (mBm). The Itô-mBm is an alternative to the classical mBm, and has been shown to admit more intuitive sample path properties in case the Hurst function is rough. In this paper, we show that the Itô-mBm also allows for a simplified statistical treatment compared to the classical mBm. In particular, estimation of the local Hurst parameter $H(t)$ with Hölder exponent $η>0$ achieves rates of convergence which are standard in nonparametric regression, whereas similar results for the classical mBm only hold for the smoother regime $η>1$. Furthermore, we derive an estimator of the integrated Hurst exponent $\\int_0^t H(s)\\, ds$ which achieves a parametric rate of convergence, and use it to construct goodness-of-fit tests."}
{"id": "2511.09799", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09799", "abs": "https://arxiv.org/abs/2511.09799", "authors": ["Lyes Smaili", "Soulaimane Berkane"], "title": "A Smooth Penalty-Based Feedback Law for Reactive Obstacle Avoidance with Convergence Guarantees", "comment": null, "summary": "This paper addresses the problem of safe autonomous navigation in unknown obstacle-filled environments using only local sensory information. We propose a smooth feedback controller derived from an unconstrained penalty-based formulation that guarantees safety by construction. The controller modifies an arbitrary nominal input through a closed-form expression. The resulting closed-form feedback has a projection structure that interpolates between the nominal control and its orthogonal projection onto the obstacle boundary, ensuring forward invariance of a user-defined safety margin. The control law depends only on the distance and bearing to obstacles and requires no map, switching, or set construction. When the nominal input is a gradient descent of a navigation potential, we prove that the closed-loop system achieves almost global asymptotic stability (AGAS) to the goal. Undesired equilibria are shown to be unstable under a mild geometric curvature condition, which compares the normal curvature of the obstacle boundary with that of the potential level sets. We refer to the proposed method as SPF (Safe Penalty-based Feedback), which ensures safe and smooth navigation with minimal computational overhead, as demonstrated through simulations in complex 2D and 3D environments."}
{"id": "2511.09845", "categories": ["math.OC", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.09845", "abs": "https://arxiv.org/abs/2511.09845", "authors": ["Cac Phan"], "title": "Bridging Constraints and Stochasticity: A Fully First-Order Method for Stochastic Bilevel Optimization with Linear Constraints", "comment": "40 pages, 2 figures", "summary": "This work provides the first finite-time convergence guarantees for linearly constrained stochastic bilevel optimization using only first-order methods, requiring solely gradient information without any Hessian computations or second-order derivatives. We address the unprecedented challenge of simultaneously handling linear constraints, stochastic noise, and finite-time analysis in bilevel optimization, a combination that has remained theoretically intractable until now. While existing approaches either require second-order information, handle only unconstrained stochastic problems, or provide merely asymptotic convergence results, our method achieves finite-time guarantees using gradient-based techniques alone. We develop a novel framework that constructs hypergradient approximations via smoothed penalty functions, using approximate primal and dual solutions to overcome the fundamental challenges posed by the interaction between linear constraints and stochastic noise. Our theoretical analysis provides explicit finite-time bounds on the bias and variance of the hypergradient estimator, demonstrating how approximation errors interact with stochastic perturbations. We prove that our first-order algorithm converges to $(δ, ε)$-Goldstein stationary points using $Θ(δ^{-1}ε^{-5})$ stochastic gradient evaluations, establishing the first finite-time complexity result for this challenging problem class and representing a significant theoretical breakthrough in constrained stochastic bilevel optimization."}
{"id": "2511.10117", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10117", "abs": "https://arxiv.org/abs/2511.10117", "authors": ["Hossein Kavianirad", "Satoshi Endo", "Davide Astarita", "Lorenzo Amato", "Emilio Trigili", "Sandra Hirche"], "title": "Cooperative Control of Hybrid FES-Exoskeleton: Dynamic Allocation", "comment": "14 pages, 6 figures", "summary": "Hybrid assistive systems that integrate functional electrical stimulation (FES) and robotic exoskeletons offer a promising approach for neurorehabilitation. However, control of these systems remains challenging due to actuator redundancy and heterogeneous assistive device constraints. This paper introduces a novel cooperative control architecture based on dynamic allocation to address actuator redundancy in a hybrid FES-exoskeleton system. The proposed approach employs a modular control allocator that redistributes required control torques between FES and exoskeleton actuators in real time, accounting for device-specific limitations and user preferences (e.g., prioritizing one assistive device over another). Within this framework, the high-level controller determines the total assistance level, while the allocator dynamically distributes control effort based on these assistive device-specific considerations. Simulation results and experimental validation demonstrate the method's effectiveness in resolving actuator redundancy in the FES-exoskeleton system while reflecting actuator constraints, indicating its potential for deployment in clinical studies to assess patient acceptance and clinical efficacy."}
{"id": "2511.09798", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.09798", "abs": "https://arxiv.org/abs/2511.09798", "authors": ["Mohamed El Guide", "Khalide Jbilou", "Kamal Lachhab", "Driss Ouazar"], "title": "Efficient Krylov-Regularization Solvers for Multiquadric RBF Discretizations of the 3D Helmholtz Equation", "comment": null, "summary": "Meshless collocation with multiquadric radial basis functions (MQ-RBFs) delivers high accuracy for the three-dimensional Helmholtz equation but produces dense, severely ill-conditioned linear systems. We develop and evaluate three complementary methods that embed regularization in Krylov projections to overcome this instability at scale: (i) an inexpensive TSVD that replaces the full SVD by a short Golub-Kahan bidiagonalization and a small projected SVD, retaining the dominant spectral content at greatly reduced cost; (ii) classical Tikhonov regularization with principled parameter choice (GCV/L-curve), expressed in SVD form for transparent filtering; and (iii) a hybrid Krylov-Tikhonov (HKT) scheme that first projects with Golub-Kahan and then selects the regularization parameter on the reduced problem, yielding stable solutions in few iterations. Extensive tests on canonical domains (cube and sphere) and a realistic industrial pump-casing geometry demonstrate that HKT consistently matches or surpasses the accuracy of full TSVD/Tikhonov at a fraction of the runtime and memory, while inexpensive TSVD provides the fastest viable reconstructions when only the leading modes are needed. These results show that coupling Krylov projection with TSVD/Tikhonov regularization provides a robust, scalable pathway for MQ-RBF Helmholtz methods in complex three-dimensional settings."}
{"id": "2511.09886", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.09886", "abs": "https://arxiv.org/abs/2511.09886", "authors": ["Feifei Chen", "Kaiming Zhang", "Yanni Zhang", "Hua Liang"], "title": "Goodness-of-fit Test for Generalized Functional Linear Models via Projection Averaging", "comment": null, "summary": "Assessing model adequacy is a crucial step in regression analysis, ensuring the validity of statistical inferences. For Generalized Functional Linear Models (GFLMs), which are widely used for modeling relationships between scalar responses and functional predictors, there is a recognized need for formal goodness-of-fit testing procedures. Current literature on this specific topic remains limited. This paper introduces a novel goodness-of-fit test for GFLMs. The test statistic is formulated as a U-statistic derived from a Cramér-von-Mises metric integrated over all one-dimensional projections of the functional predictor. This projection averaging strategy is designed to effectively mitigate the curse of dimensionality. We establish the asymptotic normality of the test statistic under the null hypothesis and prove the consistency under the alternatives. As the asymptotic variance of the limiting null distribution can be complex for practical use, we also propose practical bootstrap resampling methods for both continuous and discrete responses to compute p-values. Simulation studies confirm that the proposed test demonstrates good power performance across various settings, showing advantages over existing methods."}
{"id": "2511.10132", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.10132", "abs": "https://arxiv.org/abs/2511.10132", "authors": ["Théo Leblanc"], "title": "Hawkes autoregressive processes: a new model for multiscale and heterogeneous processes", "comment": null, "summary": "Both Hawkes processes and autoregressive processes depend on linear functionals of their past while modelling different types of data. As different datasets obtained through the recording of the same phenomena may be heterogeneous and occur at different timescales, it is important to study multiscale and heterogenous processes, such as those obtained by combining Hawkes and autoregressive processes. In this paper, we present probabilistic results for this new Hawkes autoregressive (HAR) model, including the existence of a stationary version, a cluster representation, exponential moments and asymptotic behaviour. We also derive statistical results for estimating interactions, extending the well-known LASSO estimation method to Hawkes Autoregressive (HAR) processes."}
{"id": "2511.09830", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09830", "abs": "https://arxiv.org/abs/2511.09830", "authors": ["Md Saiful Islam", "Rahul Bhadani"], "title": "Resilient Controller Design with Exponential Reaching Law for Enhanced Load Frequency Stability in Multi-Area Interconnected Microgrids", "comment": null, "summary": "We present a load frequency control strategy deploying a decentralized robust global integral terminal sliding mode control (GITSMC) method to maintain stable frequency and tie-line power in multi-area interconnected microgrids with aggregated uncertainties. To achieve this, firstly, we have developed a mathematical model of the multi-area interconnected system incorporating disturbances from solar photovoltaic (PV), wind turbine (WT) generation and load demand, as aggregated uncertainties. Secondly, we have designed a global integral terminal sliding surface with an exponential reaching law for each area to enhance system dynamic performance and suppress chattering within a finite time. Thirdly, the overall stability of the closed-loop system is analyzed using the Lyapunov stability theorem. Finally, extensive simulations are conducted on the IEEE 10-generator New England 39-bus power system, including load disturbances and variable PV and WT generation. The results demonstrate the performance of the proposed GITSMC approach, achieving approximately 94.9% improvement in ITSE and 94.4% improvement in ISE, confirming its superior accuracy and dynamic performance compared to the existing controller."}
{"id": "2511.09892", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.09892", "abs": "https://arxiv.org/abs/2511.09892", "authors": ["Zhiyuan Yao", "Anita Schöbel", "Lei Nie", "Sven Jäger"], "title": "Benders Decomposition for Passenger-Oriented Train Timetabling with Hybrid Periodicity", "comment": null, "summary": "Periodic timetables are widely adopted in passenger railway operations due to their regular service patterns and well-coordinated train connections. However, fluctuations in passenger demand require varying train services across different periods, necessitating adjustments to the periodic timetable. This study addresses a hybrid periodic train timetabling problem, which enhances the flexibility and demand responsiveness of a given periodic timetable through schedule adjustments and aperiodic train insertions, taking into account the rolling stock circulation. Since timetable modifications may affect initial passenger routes, passenger routing is incorporated into the problem to guide planning decisions towards a passenger-oriented objective. Using a time-space network representation, the problem is formulated as a dynamic railway service network design model with resource constraints. To handle the complexity of real-world instances, we propose a decomposition-based algorithm integrating Benders decomposition and column generation, enhanced with multiple preprocessing and accelerating techniques. Numerical experiments demonstrate the effectiveness of the algorithm and highlight the advantage of hybrid periodic timetables in reducing passenger travel costs."}
{"id": "2511.10118", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10118", "abs": "https://arxiv.org/abs/2511.10118", "authors": ["Zoltan Nagy", "Irinel-Constantin Morarescu", "Lucian Busoniu"], "title": "Consensus approximation and impulsive control for a class of uncertain multi-agent dynamics", "comment": null, "summary": "This paper studies a class of consensus dynamics where the interactions between agents are affected by a time-varying unknown scaling factor. This situation is encountered in the control of robotic fleets over a wireless network or in opinion dynamics where the confidence given to the peers varies in time. Firstly, we establish conditions under which practical upper and lower bounds on the consensus value can be determined. Secondly, we propose control strategies for allocating a given control budget to shift agent states towards a desired consensus value despite the uncertainty. We provide computationally efficient linear programming-based approaches for both problems and validate the obtained results in numerical simulations."}
{"id": "2511.09872", "categories": ["math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.09872", "abs": "https://arxiv.org/abs/2511.09872", "authors": ["Dong-Yue Xie", "Xi Yang"], "title": "Randomized batch-sampling Kaczmarz methods for general linear systems", "comment": null, "summary": "To conduct a more in-depth investigation of randomized solvers for general linear systems, we adopt a unified randomized batch-sampling Kaczmarz framework with per-iteration costs as low as cyclic block methods, and develop a general analysis technique to establish its convergence guarantee. With concentration inequalities, we derive new expected linear convergence rate bounds. The analysis applies to any randomized non-extended block Kaczmarz methods with static stochastic samplings. In addition, the new rate bounds are scale-invariant which eliminate the dependence on the magnitude of the data matrix. In most experiments, the new bounds are significantly tighter than existing ones and better reflect the empirical convergence behavior of block methods. Within this new framework, the batch-sampling distribution, as a learnable parameter, provides the possibility for block methods to achieve efficient performance in specific application scenarios, which deserves further investigation."}
{"id": "2511.09890", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.09890", "abs": "https://arxiv.org/abs/2511.09890", "authors": ["Masahiro Kojima", "Keisuke Hanada", "Atsuya Sato"], "title": "A Clustering Approach for Basket Trials Based on Treatment Response Trajectories", "comment": null, "summary": "Heterogeneity in efficacy is sometimes observed across baskets in basket trials. In this study, we propose a model-free clustering framework that groups baskets based on transition probabilities derived from the trajectories of treatment response, rather than relying solely on a single efficacy endpoint such as the objective response rate. The number of clusters is not predetermined but is automatically determined in a data-driven manner based on the similarity structure among baskets. After clustering, baskets within the same cluster are analyzed using a hierarchical Bayesian model. This framework aims to improve the estimation precision of efficacy endpoints and enhance statistical power while maintaining the type~I error rate at the nominal level. The performance of the proposed method was evaluated through simulation studies. The results demonstrated that the proposed method can accurately identify cluster structures in heterogeneous settings and, even under such conditions, maintain the type~I error rate at the nominal level while improving statistical power."}
{"id": "2511.10141", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.10141", "abs": "https://arxiv.org/abs/2511.10141", "authors": ["Rosa M. Fernández-Alcalá", "José D. Jiménez-López", "Jesús Navarro-Moreno", "Juan C. Ruiz-Molina"], "title": "Multi-sensor Distributed Fusion Estimation for $\\mathbb{T}_k$-proper Factorizable Signals in Sensor Networks with Fading Measurements", "comment": null, "summary": "The challenge of distributed fusion estimation is investigated for a class of four-dimensional (4D) commutative hypercomplex signals that are $\\mathbb{T}_k$-proper factorizable, within the framework of multiple-sensor networks with different fading measurement rates. The fading effects affecting each sensor's measurements are modeled as a stochastic variables with known second-order statistical properties. The estimation process is conducted exclusively based on these second-order statistics. Then, by exploiting the $\\mathbb{T}_k$-properness property within a tessarine framework, the dimensionality of the problem is significantly reduced. This reduction in dimensionality enables the development of distributed fusion filtering, prediction, and smoothing algorithms that entail lower computational effort compared with real-valued approaches.\n  The performance of the suggested algorithms is assessed through numerical experiments under various uncertainty conditions and $T_k$-proper contexts. Furthermore, simulation results confirm that $\\mathbb{T}_k$-proper estimators outperform their quaternion-domain counterparts, underscoring their practical advantages. These findings highlight the potential of $\\mathbb{T}_k$-proper estimation techniques for improving multi-sensor data fusion in applications where efficient signal processing is essential."}
{"id": "2511.10015", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10015", "abs": "https://arxiv.org/abs/2511.10015", "authors": ["Dejin Ren", "Yiling Xue", "Taoran Wu", "Bai Xue"], "title": "Efficient Verification and Falsification of ReLU Neural Barrier Certificates", "comment": null, "summary": "Barrier certificates play an important role in verifying the safety of continuous-time systems, including autonomous driving, robotic manipulators and other critical applications. Recently, ReLU neural barrier certificates -- barrier certificates represented by the ReLU neural networks -- have attracted significant attention in the safe control community due to their promising performance. However, because of the approximate nature of neural networks, rigorous verification methods are required to ensure the correctness of these certificates. This paper presents a necessary and sufficient condition for verifying the correctness of ReLU neural barrier certificates. The proposed condition can be encoded as either an Satisfiability Modulo Theories (SMT) or optimization problem, enabling both verification and falsification. To the best of our knowledge, this is the first approach capable of falsifying ReLU neural barrier certificates. Numerical experiments demonstrate the validity and effectiveness of the proposed method in both verifying and falsifying such certificates."}
{"id": "2511.09925", "categories": ["math.OC", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.09925", "abs": "https://arxiv.org/abs/2511.09925", "authors": ["Minrui Luo", "Weihang Xu", "Xiang Gao", "Maryam Fazel", "Simon Shaolei Du"], "title": "Global Convergence of Four-Layer Matrix Factorization under Random Initialization", "comment": null, "summary": "Gradient descent dynamics on the deep matrix factorization problem is extensively studied as a simplified theoretical model for deep neural networks. Although the convergence theory for two-layer matrix factorization is well-established, no global convergence guarantee for general deep matrix factorization under random initialization has been established to date. To address this gap, we provide a polynomial-time global convergence guarantee for randomly initialized gradient descent on four-layer matrix factorization, given certain conditions on the target matrix and a standard balanced regularization term. Our analysis employs new techniques to show saddle-avoidance properties of gradient decent dynamics, and extends previous theories to characterize the change in eigenvalues of layer weights."}
{"id": "2511.10158", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10158", "abs": "https://arxiv.org/abs/2511.10158", "authors": ["Jeppe H. Mikkelsen", "Thomas T. Enevoldsen", "Bugge T. Jensen", "Michael Jeppesen", "Roberto Galeazzi", "Dimitrios Papageorgiou"], "title": "Closed Form Modelling and Identification of Banking Effects in Confined Waters", "comment": null, "summary": "Vessels navigating in confined waters are subject to banking effects, which are hydrodynamic forces and moments arising from pressure differentials between the vessel sides, significantly affecting manoeuvrability and safety. Existing numerical approaches such as computational fluid dynamics (CFD) can accurately capture these effects but are computationally expensive and unsuitable for real-time control or estimation. This paper presents a closed-form, first-principles model of banking effects. The model coefficients are identified using physics-informed regression on towing tank experiment data for a scaled container vessel. Validation through Shapley value analysis confirms the significance of the banking terms in reproducing the measured forces and moments. Lastly, the derived coefficients are shown to be non-dimensional, making the model applicable across different scales that preserve vessel geometry."}
{"id": "2511.09916", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.09916", "abs": "https://arxiv.org/abs/2511.09916", "authors": ["Kunjing Yang", "Libin Zheng", "Minru Bai"], "title": "Implicit Multiple Tensor Decomposition", "comment": null, "summary": "Recently, triple decomposition has attracted increasing attention for decomposing third-order tensors into three factor tensors. However, this approach is limited to third-order tensors and enforces uniformity in the lower dimensions across all factor tensors, which restricts its flexibility and applicability. To address these issues, we propose the Multiple decomposition, a novel framework that generalizes triple decomposition to arbitrary order tensors and allows the short dimensions of the factor tensors to differ. We establish its connections with other classical tensor decompositions. Furthermore, implicit neural representation (INR) is employed to continuously represent the factor tensors in Multiple decomposition, enabling the method to generalize to non-grid data. We refer to this INR-based Multiple decomposition as Implicit Multiple Tensor Decomposition (IMTD). Then, the Proximal Alternating Least Squares (PALS) algorithm is utilized to solve the IMTD-based tensor reconstruction models. Since the objective function in IMTD-based models often lacks the Kurdyka-Lojasiewicz (KL) property, we establish a KL-free convergence analysis for the algorithm. Finally, extensive numerical experiments further validate the effectiveness of the proposed method."}
{"id": "2511.09946", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.09946", "abs": "https://arxiv.org/abs/2511.09946", "authors": ["Susan Eldhose", "Bhargava Rama Chilukuri", "Chandrasekharan Rajendran"], "title": "Leader-Follower Identification Methodology for Non-Lane Disciplined Heterogeneous Traffic Using Steady State Features", "comment": null, "summary": "Road traffic in developing countries, such as India, features a heterogeneous mix of vehicles operating under weak lane discipline (HWLD), encompassing both motorised and non-motorised modes with diverse sizes and manoeuvrability. These conditions lead to complex driver interactions, complicating the reliable identification of vehicle-following (VF) behaviour and leader-follower (LF) pairs. Traditional identification methods based on fixed thresholds for longitudinal and lateral proximity often misclassify non-following instances as valid LF pairs, degrading model performance. This study presents a refined and adaptive method for LF identification in HWLD traffic. It employs vehicle-type- and speed-specific desirable gap thresholds derived from the fundamental density-speed diagram to eliminate false-positive pairs. Additionally, Mexican Hat Wavelet Transform (MWT) is employed to analyse LV and SV speed profiles, verifying LV-SV interaction for LF pair identification. The three-stage filtering includes: (i) speed-gap consistency, (ii) approach/diverge detection via relative velocity sign changes and gap range, and (iii) wavelet-based speed correlation using MWT to confirm LV influence on SV. The framework effectively filters out LF pairs associated with overtaking, tailgating, and inconsistent gap dynamics, retaining only those with consistent VF behaviour and improving model accuracy. Analysis across thirteen LF combinations shows that VF dynamics depend on both SV and LV types. Symmetric pairs (e.g., CAR-CAR, AUTO-CAR) exhibit higher predictability and lower errors, while asymmetric pairs with heavy vehicles or two-wheelers show greater variability. The framework offers a robust foundation for traffic modelling and behaviour analysis."}
{"id": "2511.10625", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.10625", "abs": "https://arxiv.org/abs/2511.10625", "authors": ["Armeen Taeb", "F. Richard Guo", "Leonard Henckel"], "title": "Model-oriented Graph Distances via Partially Ordered Sets", "comment": null, "summary": "A well-defined distance on the parameter space is key to evaluating estimators, ensuring consistency, and building confidence sets. While there are typically standard distances to adopt in a continuous space, this is not the case for combinatorial parameters such as graphs that represent statistical models. Existing proposals like the structural Hamming distance are defined on the graphs rather than the models they represent and can hence lead to undesirable behaviors. We propose a model-oriented framework for defining the distance between graphs that is applicable across many different graph classes. Our approach treats each graph as a statistical model and organizes the graphs in a partially ordered set based on model inclusion. This induces a neighborhood structure, from which we define the model-oriented distance as the length of a shortest path through neighbors, yielding a metric in the space of graphs. We apply this framework to both probabilistic graphical models (e.g., undirected graphs and completed partially directed acyclic graphs) and causal graphical models (e.g., directed acyclic graphs and maximally oriented partially directed acyclic graphs). We analyze the theoretical and empirical behaviors of model-oriented distances. Algorithmic tools are also developed for computing and bounding these distances."}
{"id": "2511.10117", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10117", "abs": "https://arxiv.org/abs/2511.10117", "authors": ["Hossein Kavianirad", "Satoshi Endo", "Davide Astarita", "Lorenzo Amato", "Emilio Trigili", "Sandra Hirche"], "title": "Cooperative Control of Hybrid FES-Exoskeleton: Dynamic Allocation", "comment": "14 pages, 6 figures", "summary": "Hybrid assistive systems that integrate functional electrical stimulation (FES) and robotic exoskeletons offer a promising approach for neurorehabilitation. However, control of these systems remains challenging due to actuator redundancy and heterogeneous assistive device constraints. This paper introduces a novel cooperative control architecture based on dynamic allocation to address actuator redundancy in a hybrid FES-exoskeleton system. The proposed approach employs a modular control allocator that redistributes required control torques between FES and exoskeleton actuators in real time, accounting for device-specific limitations and user preferences (e.g., prioritizing one assistive device over another). Within this framework, the high-level controller determines the total assistance level, while the allocator dynamically distributes control effort based on these assistive device-specific considerations. Simulation results and experimental validation demonstrate the method's effectiveness in resolving actuator redundancy in the FES-exoskeleton system while reflecting actuator constraints, indicating its potential for deployment in clinical studies to assess patient acceptance and clinical efficacy."}
{"id": "2511.09940", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.09940", "abs": "https://arxiv.org/abs/2511.09940", "authors": ["Ruyu Liu", "Shaohua Pan"], "title": "Convergence analysis of inexact MBA method for constrained upper-$\\mathcal{C}^2$ optimization problems", "comment": null, "summary": "This paper concerns a class of constrained optimization problems in which, the objective and constraint functions are both upper-$\\mathcal{C}^2$. For such nonconvex and nonsmooth optimization problems, we develop an inexact moving balls approximation (MBA) method by a workable inexactness criterion for the solving of subproblems. By leveraging a global error bound for the strongly convex program associated with parametric optimization problems, we establish the full convergence of the iterate sequence under the partial bounded multiplier property (BMP) and the Kurdyka-Łojasiewicz (KL) property of the constructed potential function, and achieve the local convergence rate of the iterate and objective value sequences if the potential function satisfies the KL property of exponent $q\\in[1/2,1)$. A verifiable condition is also provided to check whether the potential function satisfies the KL property of exponent $q\\in[1/2,1)$ at the given critical point. To the best of our knowledge, this is the first implementable inexact MBA method with a full convergence certificate for the constrained nonconvex and nonsmooth optimization problem."}
{"id": "2511.10172", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10172", "abs": "https://arxiv.org/abs/2511.10172", "authors": ["Francesco Capolupo"], "title": "Equivalent Mechanical Models for Sloshing", "comment": null, "summary": "Propellant sloshing is a well-known, but not completely mastered phenomenon in space vehicles. It is particularly critical in both microgravity environments - such as interplanetary spacecraft requiring high pointing stability - and high-g conditions, as encountered during launch, re-entry, and landing. In both cases, sloshing can significantly affect vehicle performance and stability, and must often be explicitly considered in the design of the guidance, navigation, and control (GNC) subsystem.\n  For stability analysis and control design, the most common approach to modeling sloshing is through an equivalent mechanical representation, where the moving propellant is treated as a mechanical system interacting with the rigid (or flexible) spacecraft. Pendulum-based models and mass-spring-damper systems are widely used by control analysts to assess sloshing-induced perturbations on vehicles subjected to persistent non-gravitational acceleration along one of their body axes.\n  In this work, we present a rigorous mathematical formulation of pendulum dynamics, starting from a single spherical pendulum attached to a rigid spacecraft. We derive the nonlinear equations of motion for this 8-degree-of-freedom multi-body system, and then extend the formulation to include multiple pendulums, representing multiple sloshing modes within a tank and/or multiple tanks on the same vehicle. Furthermore, we derive the corresponding linearized equations of motion, explicitly accounting for a nominal longitudinal force acting on the vehicle - consistent with the high-g sloshing regime - expressed in either the inertial or body frame. Finally, we demonstrate the mathematical equivalence between the pendulum and mass-spring-damper models and validate the proposed models through time-domain simulation and frequency-domain analysis."}
{"id": "2511.10044", "categories": ["math.NA", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2511.10044", "abs": "https://arxiv.org/abs/2511.10044", "authors": ["Sebastian Bleecke", "Abhijit Biswas", "David I. Ketcheson", "Hendrik Ranocha", "Jochen Schutz"], "title": "Asymptotic-preserving and energy-conserving methods for a hyperbolic approximation of the BBM equation", "comment": null, "summary": "We study the hyperbolic approximation of the Benjamin-Bona-Mahony (BBM) equation proposed recently by Gavrilyuk and Shyue (2022). We develop asymptotic-preserving numerical methods using implicit-explicit (additive) Runge-Kutta methods that are implicit in the stiff linear part. The new discretization of the hyperbolization conserves important invariants converging to invariants of the BBM equation. We use the entropy relaxation approach to make the fully discrete schemes energy-preserving. Numerical experiments demonstrate the effectiveness of these discretizations."}
{"id": "2511.09972", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.09972", "abs": "https://arxiv.org/abs/2511.09972", "authors": ["Heyang Ji", "Lan Xue", "Ufuk Beyaztas", "Roger S. Zoh", "Jeff Goldsmith", "Mark E. Benden", "Carmen D. Tekwe"], "title": "Addressing zero-inflated and mis-measured functional predictors in scalar-on-function regression model", "comment": null, "summary": "Wearable devices are often used in clinical and epidemiological studies to monitor physical activity behavior and its influence on health outcomes. These devices are worn over multiple days to record activity patterns, such as step counts recorded at the minute level, resulting in multi-level, longitudinal, high-dimensional, or functional data. When monitoring patterns of step counts over multiple days, devices may record excess zeros during periods of sedentary behavior or non-wear times. Additionally, it has been demonstrated that the accuracy of wearable devices in monitoring true physical activity patterns depends on the intensity of the activities and wear times. While work on adjusting for biases due to measurement errors in functional data is a growing field, relatively less work has been done to study the occurrence of excess zeros along with measurement errors and their combined influence on estimation and inference in multi-level scalar-on-function regression models. We propose semi-continuous modeling approaches to adjust for biases due to zero inflation and measurement errors in scalar-on-function regression models. We provide theoretical justifications for our proposed methods and, through extensive simulations, we demonstrated their finite sample properties. Finally, the developed methods are applied to a school-based intervention study examining the association between school day physical activity with age- and sex-adjusted body mass index among elementary school-aged children."}
{"id": "2511.09759", "categories": ["stat.ME", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.09759", "abs": "https://arxiv.org/abs/2511.09759", "authors": ["Borna Bateni", "Yubai Yuan", "Qi Xu", "Annie Qu"], "title": "Distributional Treatment Effect Estimation across Heterogeneous Sites via Optimal Transport", "comment": null, "summary": "We propose a novel framework for synthesizing counterfactual treatment group data in a target site by integrating full treatment and control group data from a source site with control group data from the target. Departing from conventional average treatment effect estimation, our approach adopts a distributional causal inference perspective by modeling treatment and control as distinct probability measures on the source and target sites. We formalize the cross-site heterogeneity (effect modification) as a push-forward transformation that maps the joint feature-outcome distribution from the source to the target site. This transformation is learned by aligning the control group distributions between sites using an Optimal Transport-based procedure, and subsequently applied to the source treatment group to generate the synthetic target treatment distribution. Under general regularity conditions, we establish theoretical guarantees for the consistency and asymptotic convergence of the synthetic treatment group data to the true target distribution. Simulation studies across multiple data-generating scenarios and a real-world application to patient-derived xenograft data demonstrate that our framework robustly recovers the full distributional properties of treatment effects."}
{"id": "2511.10118", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10118", "abs": "https://arxiv.org/abs/2511.10118", "authors": ["Zoltan Nagy", "Irinel-Constantin Morarescu", "Lucian Busoniu"], "title": "Consensus approximation and impulsive control for a class of uncertain multi-agent dynamics", "comment": null, "summary": "This paper studies a class of consensus dynamics where the interactions between agents are affected by a time-varying unknown scaling factor. This situation is encountered in the control of robotic fleets over a wireless network or in opinion dynamics where the confidence given to the peers varies in time. Firstly, we establish conditions under which practical upper and lower bounds on the consensus value can be determined. Secondly, we propose control strategies for allocating a given control budget to shift agent states towards a desired consensus value despite the uncertainty. We provide computationally efficient linear programming-based approaches for both problems and validate the obtained results in numerical simulations."}
{"id": "2511.09963", "categories": ["math.OC", "eess.SY", "math.AP", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2511.09963", "abs": "https://arxiv.org/abs/2511.09963", "authors": ["Iasson Karafyllis", "Dionysis Theodosis", "Miroslav Krstic"], "title": "The Age-Structured Chemostat with Substrate Dynamics as a Control System", "comment": "32 pages", "summary": "In this work we study an age-structured chemostat model with a renewal boundary condition and a coupled substrate equation. The model is nonlinear and consists of a hyperbolic partial differential equation and an ordinary differential equation with nonlinear, nonlocal terms appearing both in the ordinary differential equation and the boundary condition. Both differential equations contain a non-negative control input, while the states of the model are required to be positive. Under an appropriate weak solution framework, we determine the state space and the input space for this model. We prove global existence and uniqueness of solutions for all admissible initial conditions and all allowable control inputs. To this purpose we employ a combination of Banach's fixed-point theorem with implicit solution formulas and useful solution estimates. Finally, we show that the age-structured chemostat model gives a well-defined control system on a metric space."}
{"id": "2511.10207", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10207", "abs": "https://arxiv.org/abs/2511.10207", "authors": ["Johannes Autenrieb", "Ole Ostermann"], "title": "Generalized Intelligence for Tactical Decision-Making: Large Language Model-Driven Dynamic Weapon Target Assignment", "comment": "8 Pages, 6 figures, submitted to IEEE Transactions on Aerospace and Electronic Systems", "summary": "Modern aerospace defense systems increasingly rely on autonomous decision-making to coordinate large numbers of interceptors against multiple incoming threats. Conventional weapon-target assignment (WTA) algorithms, including mixed-integer programming and auction-based methods, show limitations in dynamic and uncertain tactical environments where human-like reasoning and adaptive prioritization are required. This paper introduces a large language model (LLM) driven WTA framework that integrates generalized intelligence into cooperative missile guidance. The proposed system formulates the tactical decision process as a reasoning problem, in which an LLM evaluates spatial and temporal relationships among interceptors, targets, and defended assets to generate real-time assignments. In contrast to classical optimization methods, the approach leverages contextual mission data such as threat direction, asset priority, and closing velocity to adapt dynamically and reduce assignment switching. A dedicated simulation environment supports both static and dynamic assignment modes. Results demonstrate improved consistency, adaptability, and mission-level prioritization, establishing a foundation for integrating generalized artificial intelligence into tactical guidance systems."}
{"id": "2511.10100", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.10100", "abs": "https://arxiv.org/abs/2511.10100", "authors": ["Xiaofeng Cai", "Yibing Chen", "Kunkai Fu", "Liujun Pan"], "title": "A Third-order Conservative Semi-Lagrangian Discontinuous Galerkin Scheme For the Transport Equation on Curvilinear Unstructured Meshes", "comment": null, "summary": "We develop a third-order conservative semi-Lagrangian discontinuous Galerkin (SLDG) scheme for solving linear transport equations on curvilinear unstructured triangular meshes, tailored for complex geometries. To ensure third-order spatial accuracy while strictly preserving mass, we develop a high-order conservative intersection-based remapping algorithm for curvilinear unstructured meshes, which enables accurate and conservative data transfer between distinct curvilinear meshes. Incorporating this algorithm, we construct a non-splitting high-order SLDG method equipped with weighted essentially non-oscillatory and positivity-preserving limiters to effectively suppress numerical oscillations and maintain solution positivity. For the linear problem, the semi-Lagrangian update enables large time stepping, yielding an explicit and efficient implementation. Rigorous numerical analysis confirms that our scheme achieves third-order accuracy in both space and time, as validated by consistent error analysis in terms of $L^1$ and $L^2$-norms. Numerical benchmarks, including rigid body rotation and swirling deformation flows with smooth and discontinuous initial conditions, validate the scheme's accuracy, stability, and robustness."}
{"id": "2511.10016", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.10016", "abs": "https://arxiv.org/abs/2511.10016", "authors": ["Divan A. Burger", "Janet van Niekerk", "Peter C. le Roux", "Morgan J. Raath-Krüger"], "title": "Outlier-robust copula regression for bivariate continuous proportions: an application to cushion plant vitality", "comment": null, "summary": "Continuous proportions measured on the same experimental unit often pose two challenges: interior outliers that inflate variance beyond the beta ceiling and residual dependence that invalidates independent-margin models. We introduce a Bayesian copula modeling approach that combines rectangular-beta margins, which temper interior outliers by reallocating mass from the peak to a uniform component, with a single-parameter copula to capture concordance. Gaussian, Gumbel, and Clayton copula families are fitted, and log marginal likelihoods are obtained via bridge sampling to guide model selection. Applied to a 13-year survey (2003-2016) of Azorella selago cushion plants on sub-Antarctic Marion Island, the copula models outperform independence baselines in explaining percent dead stem cover. Accounting for between-year dependence uncovers a positive west-slope effect and weakens the cushion size effect. Simulation results show negligible bias and near-nominal 95% highest posterior density coverage across a range of tail weight and dependence scenarios, confirming good frequentist properties. The method integrates readily with JAGS and provides a robust default for paired proportion data in ecology and other disciplines where bounded outcomes and occasional outliers coincide."}
{"id": "2511.10048", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.10048", "abs": "https://arxiv.org/abs/2511.10048", "authors": ["Yanjiao Yang", "Daniel Suen", "Yen-Chi Chen"], "title": "Masking criteria for selecting an imputation model", "comment": "55 pages, 4 figures, 4 tables", "summary": "The masking-one-out (MOO) procedure, masking an observed entry and comparing it versus its imputed values, is a very common procedure for comparing imputation models. We study the optimum of this procedure and generalize it to a missing data assumption and establish the corresponding semi-parametric efficiency theory. However, MOO is a measure of prediction accuracy, which is not ideal for evaluating an imputation model. To address this issue, we introduce three modified MOO criteria, based on rank transformation, energy distance, and likelihood principle, that allow us to select an imputation model that properly account for the stochastic nature of data. The likelihood approach further enables an elegant framework of learning an imputation model from the data and we derive its statistical and computational learning theories as well as consistency of BIC model selection. We also show how MOO is related to the missing-at-random assumption. Finally, we introduce the prediction-imputation diagram, a two-dimensional diagram visually comparing both the prediction and imputation utilities for various imputation models."}
{"id": "2511.10158", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10158", "abs": "https://arxiv.org/abs/2511.10158", "authors": ["Jeppe H. Mikkelsen", "Thomas T. Enevoldsen", "Bugge T. Jensen", "Michael Jeppesen", "Roberto Galeazzi", "Dimitrios Papageorgiou"], "title": "Closed Form Modelling and Identification of Banking Effects in Confined Waters", "comment": null, "summary": "Vessels navigating in confined waters are subject to banking effects, which are hydrodynamic forces and moments arising from pressure differentials between the vessel sides, significantly affecting manoeuvrability and safety. Existing numerical approaches such as computational fluid dynamics (CFD) can accurately capture these effects but are computationally expensive and unsuitable for real-time control or estimation. This paper presents a closed-form, first-principles model of banking effects. The model coefficients are identified using physics-informed regression on towing tank experiment data for a scaled container vessel. Validation through Shapley value analysis confirms the significance of the banking terms in reproducing the measured forces and moments. Lastly, the derived coefficients are shown to be non-dimensional, making the model applicable across different scales that preserve vessel geometry."}
{"id": "2511.10058", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.10058", "abs": "https://arxiv.org/abs/2511.10058", "authors": ["Shiqi Chen", "Xuesong Chen"], "title": "An inexact semismooth Newton-Krylov method for semilinear elliptic optimal control problem", "comment": "17 pages, 3 figures", "summary": "An inexact semismooth Newton method has been proposed for solving semi-linear elliptic optimal control problems in this paper. This method incorporates the generalized minimal residual (GMRES) method, a type of Krylov subspace method, to solve the Newton equations and utilizes nonmonotonic line search to adjust the iteration step size. The original problem is reformulated into a nonlinear equation through variational inequality principles and discretized using a second-order finite difference scheme. By leveraging slanting differentiability, the algorithm constructs semismooth Newton directions and employs GMRES method to inexactly solve the Newton equations, significantly reducing computational overhead. A dynamic nonmonotonic line search strategy is introduced to adjust stepsizes adaptively, ensuring global convergence while overcoming local stagnation. Theoretical analysis demonstrates that the algorithm achieves superlinear convergence near optimal solutions when the residual control parameter $η_k$ approaches to 0. Numerical experiments validate the method's accuracy and efficiency in solving semilinear elliptic optimal control problems, corroborating theoretical insights."}
{"id": "2511.10296", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.10296", "abs": "https://arxiv.org/abs/2511.10296", "authors": ["Florian Ebmeier", "Nicole Ludwig", "Jannik Thuemmel", "Georg Martius", "Volker H. Franz"], "title": "Fault Detection in Solar Thermal Systems using Probabilistic Reconstructions", "comment": null, "summary": "Solar thermal systems (STS) present a promising avenue for low-carbon heat generation, with a well-running system providing heat at minimal cost and carbon emissions. However, STS can exhibit faults due to improper installation, maintenance, or operation, often resulting in a substantial reduction in efficiency or even damage to the system. As monitoring at the individual level is economically prohibitive for small-scale systems, automated monitoring and fault detection should be used to address such issues. Recent advances in data-driven anomaly detection, particularly in time series analysis, offer a cost-effective solution by leveraging existing sensors to identify abnormal system states.\n  Here, we propose a probabilistic reconstruction-based framework for anomaly detection. We evaluate our method on the publicly available PaSTS dataset of operational domestic STS, which features real-world complexities and diverse fault types. Our experiments show that reconstruction-based methods can detect faults in domestic STS both qualitatively and quantitatively, while generalizing to previously unseen systems. We also demonstrate that our model outperforms both simple and more complex deep learning baselines. Additionally, we show that heteroscedastic uncertainty estimation is essential to fault detection performance. Finally, we discuss the engineering overhead required to unlock these improvements and make a case for simple deep learning models."}
{"id": "2511.10129", "categories": ["math.NA", "physics.class-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.10129", "abs": "https://arxiv.org/abs/2511.10129", "authors": ["Mouhammed Achhab", "Pierre Jehel", "Fabrice Gatuingt"], "title": "Accelerating the Serviceability-Based Design of Reinforced Concrete Rail Bridges under Geometric Uncertainties induced by unforeseen events: A Surrogate Modeling approach", "comment": null, "summary": "Reinforced concrete rail bridges are essential components of railway infrastructure, where reliability, durability, and adaptability are key design priorities. However, the design process is often complicated by uncertainties stemming from unforeseen construction constraints, such as the need to reposition piers or alter geometric characteristics. These design adaptations can lead to repeated redesigns, added costs, and project delays if not anticipated in the early design stages, as well as significant computational overhead when using traditional finite element (FE) simulations. To address this and anticipate such unexpected events, this study adopts surrogate modeling as an efficient probabilistic design approach. This methodology integrates key geometric parameters as random variables, capturing the uncertainties that may arise during the design and construction phases and propagating them on the bridge's performance functions. By doing so, we aim to enable the efficient exploration of a large number of design scenarios with minimal reliance on time-consuming finite element (FE) simulations, represent the performance functions of a reinforced concrete bridge as a function of our variable design parameters, and classify the overall design scenarios into failure and safe scenarios In this study, a four-span reinforced concrete bridge deck is modeled using a multi-fiber finite element approach in Cast3M software. This FE model is used to generate the required design of experiments to train the surrogate models. Within this framework, a comparative performance assessment is conducted to evaluate the performance of the Kriging surrogate against alternative methods, including polynomial chaos expansion (implemented in UQLab) and support vector regression (SVR). This methodology supports early-stage uncertainty-informed design, enhancing the robustness and adaptability of reinforced concrete rail bridges in the face of practical constraints and changing site conditions."}
{"id": "2511.10048", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.10048", "abs": "https://arxiv.org/abs/2511.10048", "authors": ["Yanjiao Yang", "Daniel Suen", "Yen-Chi Chen"], "title": "Masking criteria for selecting an imputation model", "comment": "55 pages, 4 figures, 4 tables", "summary": "The masking-one-out (MOO) procedure, masking an observed entry and comparing it versus its imputed values, is a very common procedure for comparing imputation models. We study the optimum of this procedure and generalize it to a missing data assumption and establish the corresponding semi-parametric efficiency theory. However, MOO is a measure of prediction accuracy, which is not ideal for evaluating an imputation model. To address this issue, we introduce three modified MOO criteria, based on rank transformation, energy distance, and likelihood principle, that allow us to select an imputation model that properly account for the stochastic nature of data. The likelihood approach further enables an elegant framework of learning an imputation model from the data and we derive its statistical and computational learning theories as well as consistency of BIC model selection. We also show how MOO is related to the missing-at-random assumption. Finally, we introduce the prediction-imputation diagram, a two-dimensional diagram visually comparing both the prediction and imputation utilities for various imputation models."}
{"id": "2511.10172", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10172", "abs": "https://arxiv.org/abs/2511.10172", "authors": ["Francesco Capolupo"], "title": "Equivalent Mechanical Models for Sloshing", "comment": null, "summary": "Propellant sloshing is a well-known, but not completely mastered phenomenon in space vehicles. It is particularly critical in both microgravity environments - such as interplanetary spacecraft requiring high pointing stability - and high-g conditions, as encountered during launch, re-entry, and landing. In both cases, sloshing can significantly affect vehicle performance and stability, and must often be explicitly considered in the design of the guidance, navigation, and control (GNC) subsystem.\n  For stability analysis and control design, the most common approach to modeling sloshing is through an equivalent mechanical representation, where the moving propellant is treated as a mechanical system interacting with the rigid (or flexible) spacecraft. Pendulum-based models and mass-spring-damper systems are widely used by control analysts to assess sloshing-induced perturbations on vehicles subjected to persistent non-gravitational acceleration along one of their body axes.\n  In this work, we present a rigorous mathematical formulation of pendulum dynamics, starting from a single spherical pendulum attached to a rigid spacecraft. We derive the nonlinear equations of motion for this 8-degree-of-freedom multi-body system, and then extend the formulation to include multiple pendulums, representing multiple sloshing modes within a tank and/or multiple tanks on the same vehicle. Furthermore, we derive the corresponding linearized equations of motion, explicitly accounting for a nominal longitudinal force acting on the vehicle - consistent with the high-g sloshing regime - expressed in either the inertial or body frame. Finally, we demonstrate the mathematical equivalence between the pendulum and mass-spring-damper models and validate the proposed models through time-domain simulation and frequency-domain analysis."}
{"id": "2511.10069", "categories": ["math.OC", "cs.DC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.10069", "abs": "https://arxiv.org/abs/2511.10069", "authors": ["Zhangcheng Feng", "Defeng Sun", "Yancheng Yuan", "Guojun Zhang"], "title": "dHPR: A Distributed Halpern Peaceman--Rachford Method for Non-smooth Distributed Optimization Problems", "comment": null, "summary": "This paper introduces the distributed Halpern Peaceman--Rachford (dHPR) method, an efficient algorithm for solving distributed convex composite optimization problems with non-smooth objectives, which achieves a non-ergodic $O(1/k)$ iteration complexity regarding Karush--Kuhn--Tucker residual. By leveraging the symmetric Gauss--Seidel decomposition, the dHPR effectively decouples the linear operators in the objective functions and consensus constraints while maintaining parallelizability and avoiding additional large proximal terms, leading to a decentralized implementation with provably fast convergence. The superior performance of dHPR is demonstrated through comprehensive numerical experiments on distributed LASSO, group LASSO, and $L_1$-regularized logistic regression problems."}
{"id": "2511.10335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10335", "abs": "https://arxiv.org/abs/2511.10335", "authors": ["Oscar Damanik", "Giacomo Bastianel", "Dirk Van Hertem", "Hakan Ergun"], "title": "Security-Constrained AC/DC Grid Optimal Power Flow Considering Asymmetrical HVDC Grid Operation using Sparse Tableau Formulation", "comment": null, "summary": "This paper presents a security-constrained optimal power flow (SCOPF) model for HVDC grids that optimizes the asymmetrical operation of bipolar converter stations, i.e., different current injections of the positive and negative converter poles, to minimize operational costs under post-contingency conditions caused by single converter pole outages. The optimization model allows the selection of the number of converter stations that operate asymmetrically. The results indicate that increasing the number of asymmetrical stations lowers operational costs. The analysis also provides insight into the sensitivity of these costs to the level of asymmetrical operation. However, increased asymmetrical operation leads to higher DC neutral voltage offsets that can rise to undesired levels. Imposing limits on these offsets can, in turn, increase operational costs. To mitigate these effects, a neutral line switching (NLS) strategy is proposed for the post-contingency state."}
{"id": "2511.10214", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.10214", "abs": "https://arxiv.org/abs/2511.10214", "authors": ["Federica Ferrarese"], "title": "Control strategies for magnetized plasma: a polar coordinates framework", "comment": null, "summary": "In this work, we provide an overview of various control strategies aimed at steering plasma toward desired configurations using an external magnetic field. From a modeling perspective, we focus on the Vlasov equation in a two-dimensional bounded domain, accounting for both a self-induced electric field and a strong external magnetic field. The results are presented in a polar coordinate framework, which is particularly well-suited for simulating toroidal devices such as Tokamaks and Stellarators. A key feature of the proposed control strategies is their feedback mechanism, which is based on an instantaneous prediction of the discretized system. Finally, different numerical experiments in the two-dimensional polar coordinate setting demonstrate the effectiveness of the approaches."}
{"id": "2511.10077", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.10077", "abs": "https://arxiv.org/abs/2511.10077", "authors": ["Yi Liu", "Yuan Wang", "Ying Gao", "Tonia Poteat", "Roland A. Matsouaka"], "title": "A tutorial for propensity score weighting methods under violations of the positivity assumption", "comment": null, "summary": "Violations of the positivity assumption can render conventional causal estimands unidentifiable, including the average treatment effect (ATE), the average treatment effect on the treated (ATT), and the average treatment effect on the controls (ATC). Shifting the inferential focus to their alternative counterparts -- the weighted ATE (WATE), the weighted ATT (WATT), and the weighted ATC (WATC) -- offers valuable insights into treatment effects while preserving internal validity. In this tutorial, we provide a comprehensive review of recent advances in propensity score (PS) weighting methods, along with practical guidance on how to select a primary target estimand (while other estimands serve as supplementary analyses), implement the corresponding PS-weighted estimators, and conduct post-weighting diagnostic assessments. The tutorial is accompanied by a user-friendly R package, ChiPS. We demonstrate the pertinence of various estimators through extensive simulation studies. We illustrate the flow of the tutorial on two real-world case studies: (i) Effect of smoking on blood lead level using data from the 2007-2008 National Health and Nutrition Examination Survey (NHANES); and (ii) Impact of history of sex work on HIV status among transgender women in South Africa."}
{"id": "2511.10207", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10207", "abs": "https://arxiv.org/abs/2511.10207", "authors": ["Johannes Autenrieb", "Ole Ostermann"], "title": "Generalized Intelligence for Tactical Decision-Making: Large Language Model-Driven Dynamic Weapon Target Assignment", "comment": "8 Pages, 6 figures, submitted to IEEE Transactions on Aerospace and Electronic Systems", "summary": "Modern aerospace defense systems increasingly rely on autonomous decision-making to coordinate large numbers of interceptors against multiple incoming threats. Conventional weapon-target assignment (WTA) algorithms, including mixed-integer programming and auction-based methods, show limitations in dynamic and uncertain tactical environments where human-like reasoning and adaptive prioritization are required. This paper introduces a large language model (LLM) driven WTA framework that integrates generalized intelligence into cooperative missile guidance. The proposed system formulates the tactical decision process as a reasoning problem, in which an LLM evaluates spatial and temporal relationships among interceptors, targets, and defended assets to generate real-time assignments. In contrast to classical optimization methods, the approach leverages contextual mission data such as threat direction, asset priority, and closing velocity to adapt dynamically and reduce assignment switching. A dedicated simulation environment supports both static and dynamic assignment modes. Results demonstrate improved consistency, adaptability, and mission-level prioritization, establishing a foundation for integrating generalized artificial intelligence into tactical guidance systems."}
{"id": "2511.10133", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.10133", "abs": "https://arxiv.org/abs/2511.10133", "authors": ["Maoran Wang", "Xingju Cai", "Yongxin Chen"], "title": "S-D-RSM: Stochastic Distributed Regularized Splitting Method for Large-Scale Convex Optimization Problems", "comment": null, "summary": "This paper investigates the problems large-scale distributed composite convex optimization, with motivations from a broad range of applications, including multi-agent systems, federated learning, smart grids, wireless sensor networks, compressed sensing, and so on. Stochastic gradient descent (SGD) and its variants are commonly employed to solve such problems. However, existing algorithms often rely on vanishing step sizes, strong convexity assumptions, or entail substantial computational overhead to ensure convergence or obtain favorable complexity. To bridge the gap between theory and practice, we integrate consensus optimization and operator splitting techniques (see Problem Reformulation) to develop a novel stochastic splitting algorithm, termed the \\emph{stochastic distributed regularized splitting method} (S-D-RSM). In practice, S-D-RSM performs parallel updates of proximal mappings and gradient information for only a randomly selected subset of agents at each iteration. By introducing regularization terms, it effectively mitigates consensus discrepancies among distributed nodes. In contrast to conventional stochastic methods, our theoretical analysis establishes that S-D-RSM achieves global convergence without requiring diminishing step sizes or strong convexity assumptions. Furthermore, it achieves an iteration complexity of $\\mathcal{O}(1/ε)$ with respect to both the objective function value and the consensus error. Numerical experiments show that S-D-RSM achieves up to 2--3$\\times$ speedup compared to state-of-the-art baselines, while maintaining comparable or better accuracy. These results not only validate the algorithm's theoretical guarantees but also demonstrate its effectiveness in practical tasks such as compressed sensing and empirical risk minimization."}
{"id": "2511.10380", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10380", "abs": "https://arxiv.org/abs/2511.10380", "authors": ["Cornelia Skaga", "Mahdieh S. Sadabadi", "Gilbert Bergna-Diaz"], "title": "Large-Signal Stability Guarantees for a Scalable DC Microgrid with Nonlinear Distributed Control: The Slow Communication Scenario", "comment": "11 pages, 7 figures", "summary": "The increasing integration of renewable energy sources into electrical grids necessitates a paradigm shift toward advanced control schemes that guarantee safe and stable operations with scalable properties. Hence, this study explores large-signal stability guarantees of a promising distributed control framework for cyber-physical DC microgrids, ensuring proportional current sharing and voltage containment within pre-specified limits. The proposed control framework adopts nonlinear nested control loops--inner (decentralized) and outer (distributed)--specifically designed to simultaneously achieve the control objectives. Our scalable stability result relies on singular perturbation theory to prove global exponential stability by imposing a sufficient time-scale separation at the border between the nested control loops. In particular, by saturating the influence of the outer loop controller in the inner loop, the proposed controller preserves a more convenient mathematical structure, facilitating the scalability of the stability proof using Lyapunov arguments. The effectiveness of our proposed control strategy is supported through time-domain simulations of a case-specific low-voltage DC microgrid following a careful tuning strategy, and a small-signal stability analysis is conducted to derive practical guidelines that enhance the applicability of the method."}
{"id": "2511.10242", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.10242", "abs": "https://arxiv.org/abs/2511.10242", "authors": ["Ruizhi Wang", "Weibing Deng"], "title": "A Stabilized Unfitted Space-time Finite Element Method for Parabolic Problems on Moving Domains", "comment": null, "summary": "This paper presents a space-time finite element method (FEM) based on an unfitted mesh for solving parabolic problems on moving domains. Unlike other unfitted space-time finite element approaches that commonly employ the discontinuous Galerkin (DG) method for time-stepping, the proposed method employs a fully coupled space-time discretization. To stabilize the time-advection term, the streamline upwind Petrov-Galerkin (SUPG) scheme is applied in the temporal direction. A ghost penalty stabilization term is further incorporated to mitigate the small cut issue, thereby ensuring the well-conditioning of the stiffness matrix. Moreover, an a priori error estimate is derived in a discrete energy norm, which achieves an optimal convergence rate with respect to the mesh size. In particular, a space-time Poincare-Friedrichs inequality is established to support the condition number analysis. Several numerical examples are provided to validate the theoretical findings."}
{"id": "2511.10293", "categories": ["stat.ME", "math.OC", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.10293", "abs": "https://arxiv.org/abs/2511.10293", "authors": ["Athanasios Christou Micheas"], "title": "Zeroes and Extrema of Functions via Random Measures", "comment": "Function extrema and zeroes; Optimization; Poisson point process; Random counting measures; Riemann's zeta function", "summary": "We present methods that provide all zeroes and extrema of a function that do not require differentiation. Using point process theory, we are able to describe the locations of zeroes or maxima, their number, as well as their distribution over a given window of observation. The algorithms in order to accomplish the theoretical development are also provided, and they are exemplified using many illustrative examples, for real and complex functions."}
{"id": "2511.10296", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.10296", "abs": "https://arxiv.org/abs/2511.10296", "authors": ["Florian Ebmeier", "Nicole Ludwig", "Jannik Thuemmel", "Georg Martius", "Volker H. Franz"], "title": "Fault Detection in Solar Thermal Systems using Probabilistic Reconstructions", "comment": null, "summary": "Solar thermal systems (STS) present a promising avenue for low-carbon heat generation, with a well-running system providing heat at minimal cost and carbon emissions. However, STS can exhibit faults due to improper installation, maintenance, or operation, often resulting in a substantial reduction in efficiency or even damage to the system. As monitoring at the individual level is economically prohibitive for small-scale systems, automated monitoring and fault detection should be used to address such issues. Recent advances in data-driven anomaly detection, particularly in time series analysis, offer a cost-effective solution by leveraging existing sensors to identify abnormal system states.\n  Here, we propose a probabilistic reconstruction-based framework for anomaly detection. We evaluate our method on the publicly available PaSTS dataset of operational domestic STS, which features real-world complexities and diverse fault types. Our experiments show that reconstruction-based methods can detect faults in domestic STS both qualitatively and quantitatively, while generalizing to previously unseen systems. We also demonstrate that our model outperforms both simple and more complex deep learning baselines. Additionally, we show that heteroscedastic uncertainty estimation is essential to fault detection performance. Finally, we discuss the engineering overhead required to unlock these improvements and make a case for simple deep learning models."}
{"id": "2511.10239", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.10239", "abs": "https://arxiv.org/abs/2511.10239", "authors": ["Reza Rahimi Baghbadorani", "Sergio Grammatico", "Peyman Mohajerin Esfahani"], "title": "Locally Linear Convergence for Nonsmooth Convex Optimization via Coupled Smoothing and Momentum", "comment": null, "summary": "We propose an adaptive accelerated smoothing technique for a nonsmooth convex optimization problem where the smoothing update rule is coupled with the momentum parameter. We also extend the setting to the case where the objective function is the sum of two nonsmooth functions. With regard to convergence rate, we provide the global (optimal) sublinear convergence guarantees of O(1/k), which is known to be provably optimal for the studied class of functions, along with a local linear rate if the nonsmooth term fulfills a so-call locally strong convexity condition. We validate the performance of our algorithm on several problem classes, including regression with the l1-norm (the Lasso problem), sparse semidefinite programming (the MaxCut problem), Nuclear norm minimization with application in model free fault diagnosis, and l_1-regularized model predictive control to showcase the benefits of the coupling. An interesting observation is that although our global convergence result guarantees O(1/k) convergence, we consistently observe a practical transient convergence rate of O(1/k^2), followed by asymptotic linear convergence as anticipated by the theoretical result. This two-phase behavior can also be explained in view of the proposed smoothing rule."}
{"id": "2511.10401", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10401", "abs": "https://arxiv.org/abs/2511.10401", "authors": ["Cornelia Skaga", "Babak Abdolmaleki", "Gilbert Bergna-Diaz"], "title": "Stability Analysis of a Nonlinear Distributed Control Framework for Current Sharing and Voltage Containment in DC Microgrids: The Fast Communication Scenario", "comment": "10 pages, 7 figures", "summary": "As renewable energy generation becomes increasingly integrated into electrical grids, there is a critical need for a paradigm shift toward control schemes that ensure safe, stable, and scalable operations. Hence, in this study, we explore the stability guarantees of a promising control proposal for cyber-physical DC microgrids (MGs), specifically designed to simultaneously achieve proportional current sharing and voltage containment within pre-specified limits. Our scalable stability result relies on singular perturbation theory to prove global exponential stability by imposing a sufficient time-scale separation at the border between the inner(decentralized) and outer(distributed) nested loops, and thus, ensuring that the system reaches the desired (optimal) steady state under appropriate tuning verifying some stability conditions. To prove the effectiveness of our method, our findings are supported by testing the control method in a time-domain simulation case study involving a low-voltage DC microgrid, as well as a small-signal stability analysis"}
{"id": "2511.10369", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.10369", "abs": "https://arxiv.org/abs/2511.10369", "authors": ["Caterina B. Leimer Saglio", "Mattia Corti", "Stefano Pagani", "Paola F. Antonietti"], "title": "A novel mathematical and computational framework of amyloid-beta triggered seizure dynamics in Alzheimer's disease", "comment": null, "summary": "The association of epileptic activity and Alzheimer's disease (AD) has been increasingly reported in both clinical and experimental studies, suggesting that amyloid-$β$ accumulation may directly affect neuronal excitability. Capturing these interactions requires a quantitative description that bridges the molecular alterations of AD with the fast electrophysiological dynamics of epilepsy. We introduce a novel mathematical model that extends the Barreto-Cressman ionic formulation by incorporating multiple mechanisms of calcium dysregulation induced by amyloid-$β$, including formation of $\\mathrm{Ca}^{2+}$-permeable pores, overactivation of voltage-gated $\\mathrm{Ca}^{2+}$ channels, and suppression of $\\mathrm{Ca}^{2+}$-sensitive potassium currents. The resulting ionic model is coupled with the monodomain equation and discretized using a $p$-adaptive discontinuous Galerkin method on polytopal meshes, providing an effective balance between efficiency and accuracy in capturing the sharp spatiotemporal electrical wavefronts associated with epileptiform discharges. Numerical simulations performed on idealized and realistic brain geometries demonstrate that progressive amyloid-\\textbeta{} accumulation leads to severe alterations in calcium homeostasis, increased neuronal hyperexcitability, and pathological seizure propagation. Specifically, high amyloid-$β$ concentrations produce secondary epileptogenic sources and spatially heterogeneous wavefronts, indicating that biochemical inhomogeneities play a critical role in shaping seizure dynamics. These results illustrate how multiscale modeling provides new mechanistic insights into the interplay between neurodegeneration and epilepsy in Alzheimer's disease."}
{"id": "2511.10336", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.10336", "abs": "https://arxiv.org/abs/2511.10336", "authors": ["Sophia Loizidou", "Christophe Ley", "Shogo Kato", "Kanti V. Mardia"], "title": "Modelling toroidal and cylindrical data via the trivariate wrapped Cauchy copula with non-uniform marginals", "comment": "13 pages, 3 figures", "summary": "In this paper, we propose a new flexible family of distributions for data that consist of three angles, two angles and one linear component, or one angle and two linear components. To achieve this, we equip the recently proposed trivariate wrapped Cauchy copula with non-uniform marginals and develop a parameter estimation procedure. We compare our model to its main competitors for analyzing trivariate data and provide some evidence of its advantages. We illustrate our new model using toroidal data from protein bioinformatics of conformational angles, and cylindrical data from climate science related to buoy in the Adriatic Sea. The paper is motivated by these real trivariate datasets."}
{"id": "2511.10335", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10335", "abs": "https://arxiv.org/abs/2511.10335", "authors": ["Oscar Damanik", "Giacomo Bastianel", "Dirk Van Hertem", "Hakan Ergun"], "title": "Security-Constrained AC/DC Grid Optimal Power Flow Considering Asymmetrical HVDC Grid Operation using Sparse Tableau Formulation", "comment": null, "summary": "This paper presents a security-constrained optimal power flow (SCOPF) model for HVDC grids that optimizes the asymmetrical operation of bipolar converter stations, i.e., different current injections of the positive and negative converter poles, to minimize operational costs under post-contingency conditions caused by single converter pole outages. The optimization model allows the selection of the number of converter stations that operate asymmetrically. The results indicate that increasing the number of asymmetrical stations lowers operational costs. The analysis also provides insight into the sensitivity of these costs to the level of asymmetrical operation. However, increased asymmetrical operation leads to higher DC neutral voltage offsets that can rise to undesired levels. Imposing limits on these offsets can, in turn, increase operational costs. To mitigate these effects, a neutral line switching (NLS) strategy is proposed for the post-contingency state."}
{"id": "2511.10372", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.10372", "abs": "https://arxiv.org/abs/2511.10372", "authors": ["Liwei Zhang", "Fanli Zhuang", "Ning Zhang"], "title": "Halpern Acceleration of the Inexact Proximal Point Method of Rockafellar", "comment": "25pages", "summary": "This paper investigates a Halpern acceleration of the inexact proximal point method for solving maximal monotone inclusion problems in Hilbert spaces. The proposed Halpern inexact proximal point method (HiPPM) is shown to be globally convergent, and a unified framework is developed to analyze its worst-case convergence rate. Under mild summability conditions on the inexactness tolerances, HiPPM achieves an $\\mathcal{O}(1/k^{2})$ rate in terms of the squared fixed-point residual. Furthermore, under additional mild condition, the method retains a fast linear convergence rate. Building upon this framework, we further extend the acceleration technique to constrained convex optimization through the augmented Lagrangian formulation. In analogy to Rockafellar's classical results, the resulting accelerated inexact augmented Lagrangian method inherits the convergence rate and complexity guarantees of HiPPM. The analysis thus provides a unified theoretical foundation for accelerated inexact proximal algorithms and their augmented Lagrangian extensions."}
{"id": "2511.10426", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10426", "abs": "https://arxiv.org/abs/2511.10426", "authors": ["Max Mowbray", "Nilay Shah", "Benoît Chachuat"], "title": "A Decomposition Approach to Solving Numerical Constraint Satisfaction Problems on Directed Acyclic Graphs", "comment": null, "summary": "Certifying feasibility in decision-making, critical in many industries, can be framed as a constraint satisfaction problem. This paper focuses on characterising a subset of parameter values from an a priori set that satisfy constraints on a directed acyclic graph of constituent functions. The main assumption is that these functions and constraints may be evaluated for given parameter values, but they need not be known in closed form and could result from expensive or proprietary simulations. This setting lends itself to using sampling methods to gain an inner approximation of the feasible domain. To mitigate the curse of dimensionality, the paper contributes new methodology to leverage the graph structure for decomposing the problem into lower-dimensional subproblems defined on the respective nodes. The working hypothesis that the Cartesian product of the solution sets yielded by the subproblems will tighten the a priori parameter domain, before solving the full problem defined on the graph, is demonstrated through four case studies relevant to machine learning and engineering. Future research will extend this approach to cyclic graphs and account for parametric uncertainty."}
{"id": "2511.10452", "categories": ["math.NA", "math.OC", "physics.flu-dyn", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2511.10452", "abs": "https://arxiv.org/abs/2511.10452", "authors": ["Gonzalo G. de Diego", "Georg Stadler"], "title": "Learning parameter-dependent shear viscosity from data, with application to sea and land ice", "comment": null, "summary": "Complex physical systems which exhibit fluid-like behavior are often modeled as non-Newtonian fluids. A crucial element of a non-Newtonian model is the rheology, which relates inner stresses with strain-rates. We propose a framework for inferring rheological models from data that represents the fluid's effective viscosity with a neural network. By writing the rheological law in terms of tensor invariants and tailoring the network's properties, the inferred model satisfies key physical and mathematical properties, such as isotropic frame-indifference and existence of a convex potential of dissipation. Within this framework, we propose two approaches to learning a fluid's rheology: 1) a standard regression that fits the rheological model to stress data and 2) a PDE-constrained optimization method that infers rheological models from velocity data. For the latter approach, we combine finite element and machine learning libraries. We demonstrate the accuracy and robustness of our method on land and sea ice rheologies which also depend on external parameters. For land ice, we infer the temperature-dependent Glen's law and, for sea ice, the concentration-dependent shear component of the viscous-plastic model. For these two models, we explore the effects of large data errors. Finally, we infer an unknown concentration-dependent model that reproduces Lagrangian ice floe simulation data. Our method discovers a rheology that generalizes well outside of the training dataset and exhibits both shear-thickening and thinning behaviors depending on the concentrations."}
{"id": "2511.09845", "categories": ["math.OC", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.09845", "abs": "https://arxiv.org/abs/2511.09845", "authors": ["Cac Phan"], "title": "Bridging Constraints and Stochasticity: A Fully First-Order Method for Stochastic Bilevel Optimization with Linear Constraints", "comment": "40 pages, 2 figures", "summary": "This work provides the first finite-time convergence guarantees for linearly constrained stochastic bilevel optimization using only first-order methods, requiring solely gradient information without any Hessian computations or second-order derivatives. We address the unprecedented challenge of simultaneously handling linear constraints, stochastic noise, and finite-time analysis in bilevel optimization, a combination that has remained theoretically intractable until now. While existing approaches either require second-order information, handle only unconstrained stochastic problems, or provide merely asymptotic convergence results, our method achieves finite-time guarantees using gradient-based techniques alone. We develop a novel framework that constructs hypergradient approximations via smoothed penalty functions, using approximate primal and dual solutions to overcome the fundamental challenges posed by the interaction between linear constraints and stochastic noise. Our theoretical analysis provides explicit finite-time bounds on the bias and variance of the hypergradient estimator, demonstrating how approximation errors interact with stochastic perturbations. We prove that our first-order algorithm converges to $(δ, ε)$-Goldstein stationary points using $Θ(δ^{-1}ε^{-5})$ stochastic gradient evaluations, establishing the first finite-time complexity result for this challenging problem class and representing a significant theoretical breakthrough in constrained stochastic bilevel optimization."}
{"id": "2511.10380", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10380", "abs": "https://arxiv.org/abs/2511.10380", "authors": ["Cornelia Skaga", "Mahdieh S. Sadabadi", "Gilbert Bergna-Diaz"], "title": "Large-Signal Stability Guarantees for a Scalable DC Microgrid with Nonlinear Distributed Control: The Slow Communication Scenario", "comment": "11 pages, 7 figures", "summary": "The increasing integration of renewable energy sources into electrical grids necessitates a paradigm shift toward advanced control schemes that guarantee safe and stable operations with scalable properties. Hence, this study explores large-signal stability guarantees of a promising distributed control framework for cyber-physical DC microgrids, ensuring proportional current sharing and voltage containment within pre-specified limits. The proposed control framework adopts nonlinear nested control loops--inner (decentralized) and outer (distributed)--specifically designed to simultaneously achieve the control objectives. Our scalable stability result relies on singular perturbation theory to prove global exponential stability by imposing a sufficient time-scale separation at the border between the nested control loops. In particular, by saturating the influence of the outer loop controller in the inner loop, the proposed controller preserves a more convenient mathematical structure, facilitating the scalability of the stability proof using Lyapunov arguments. The effectiveness of our proposed control strategy is supported through time-domain simulations of a case-specific low-voltage DC microgrid following a careful tuning strategy, and a small-signal stability analysis is conducted to derive practical guidelines that enhance the applicability of the method."}
{"id": "2511.10414", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.10414", "abs": "https://arxiv.org/abs/2511.10414", "authors": ["Masoud Ahookhosh", "Susan Ghaderi", "Alireza Kabgani", "Morteza Rahimi"], "title": "Minimizing smooth Kurdyka-Łojasiewicz functions via generalized descent methods: Convergence rate and complexity", "comment": null, "summary": "This paper addresses the generalized descent algorithm (DEAL) for minimizing smooth functions, which is analyzed under the Kurdyka-Łojasiewicz (KL) inequality. In particular, the suggested algorithm guarantees a sufficient decrease by adapting to the cost function's geometry. We leverage the KL property to establish the global convergence, convergence rates, and complexity. A particular focus is placed on the linear convergence of generalized descent methods. We show that the constant step-size and Armijo line search strategies along a generalized descent direction satisfy our generalized descent condition. Additionally, for nonsmooth functions by leveraging the smoothing techniques such as forward-backward and high-order Moreau envelopes, we show that the boosted proximal gradient method (BPGA) and the boosted high-order proximal-point (BPPA) methods are also specific cases of DEAL, respectively. It is notable that if the order of the high-order proximal term is chosen in a certain way (depending on the KL exponent), then the sequence generated by BPPA converges linearly for an arbitrary KL exponent. Our preliminary numerical experiments on inverse problems and LASSO demonstrate the efficiency of the proposed methods, validating our theoretical findings."}
{"id": "2511.10510", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.10510", "abs": "https://arxiv.org/abs/2511.10510", "authors": ["Jun Liu"], "title": "Formal Verification of Control Lyapunov-Barrier Functions for Safe Stabilization with Bounded Controls", "comment": null, "summary": "We present verifiable conditions for synthesizing a single smooth Lyapunov function that certifies both asymptotic stability and safety under bounded controls. These sufficient conditions ensure the strict compatibility of a control barrier function (CBF) and a control Lyapunov function (CLF) on the exact safe set certified by the barrier. An explicit smooth control Lyapunov-barrier function (CLBF) is then constructed via a patching formula that is provably correct by design. Two examples illustrate the computational procedure, showing that the proposed approach is less conservative than sum-of-squares (SOS)-based compatible CBF-CLF designs."}
{"id": "2511.10599", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.10599", "abs": "https://arxiv.org/abs/2511.10599", "authors": ["Jiarui Du", "Zhijian He"], "title": "The $L_p$-error rate for randomized quasi-Monte Carlo self-normalized importance sampling of unbounded integrands", "comment": null, "summary": "Self-normalized importance sampling (SNIS) is a fundamental tool in Bayesian inference when the posterior distribution involves an unknown normalizing constant. Although $L_1$-error (bias) and $L_2$-error (root mean square error) estimates of SNIS are well established for bounded integrands, results for unbounded integrands remain limited, especially under randomized quasi-Monte Carlo (RQMC) sampling. In this work, we derive $L_p$-error rate $(p\\ge1)$ for RQMC-based SNIS (RQMC-SNIS) estimators with unbounded integrands on unbounded domains. A key step in our analysis is to first establish the $L_p$-error rate for plain RQMC integration. Our results allow for a broader class of transport maps used to generate samples from RQMC points. Under mild function boundary growth conditions, we further establish \\(L_p\\)-error rate of order \\(\\mathcal{O}(N^{-β+ ε})\\) for RQMC-SNIS estimators, where $ε>0$ is arbitrarily small, $N$ is the sample size, and \\(β\\in (0,1]\\) depends on the boundary growth rate of the resulting integrand. Numerical experiments validate the theoretical results."}
{"id": "2511.10625", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.10625", "abs": "https://arxiv.org/abs/2511.10625", "authors": ["Armeen Taeb", "F. Richard Guo", "Leonard Henckel"], "title": "Model-oriented Graph Distances via Partially Ordered Sets", "comment": null, "summary": "A well-defined distance on the parameter space is key to evaluating estimators, ensuring consistency, and building confidence sets. While there are typically standard distances to adopt in a continuous space, this is not the case for combinatorial parameters such as graphs that represent statistical models. Existing proposals like the structural Hamming distance are defined on the graphs rather than the models they represent and can hence lead to undesirable behaviors. We propose a model-oriented framework for defining the distance between graphs that is applicable across many different graph classes. Our approach treats each graph as a statistical model and organizes the graphs in a partially ordered set based on model inclusion. This induces a neighborhood structure, from which we define the model-oriented distance as the length of a shortest path through neighbors, yielding a metric in the space of graphs. We apply this framework to both probabilistic graphical models (e.g., undirected graphs and completed partially directed acyclic graphs) and causal graphical models (e.g., directed acyclic graphs and maximally oriented partially directed acyclic graphs). We analyze the theoretical and empirical behaviors of model-oriented distances. Algorithmic tools are also developed for computing and bounding these distances."}
{"id": "2511.10401", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10401", "abs": "https://arxiv.org/abs/2511.10401", "authors": ["Cornelia Skaga", "Babak Abdolmaleki", "Gilbert Bergna-Diaz"], "title": "Stability Analysis of a Nonlinear Distributed Control Framework for Current Sharing and Voltage Containment in DC Microgrids: The Fast Communication Scenario", "comment": "10 pages, 7 figures", "summary": "As renewable energy generation becomes increasingly integrated into electrical grids, there is a critical need for a paradigm shift toward control schemes that ensure safe, stable, and scalable operations. Hence, in this study, we explore the stability guarantees of a promising control proposal for cyber-physical DC microgrids (MGs), specifically designed to simultaneously achieve proportional current sharing and voltage containment within pre-specified limits. Our scalable stability result relies on singular perturbation theory to prove global exponential stability by imposing a sufficient time-scale separation at the border between the inner(decentralized) and outer(distributed) nested loops, and thus, ensuring that the system reaches the desired (optimal) steady state under appropriate tuning verifying some stability conditions. To prove the effectiveness of our method, our findings are supported by testing the control method in a time-domain simulation case study involving a low-voltage DC microgrid, as well as a small-signal stability analysis"}
{"id": "2511.10421", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.10421", "abs": "https://arxiv.org/abs/2511.10421", "authors": ["Alireza Kabgani", "Masoud Ahookhosh"], "title": "On fundamental properties of high-order forward-backward envelope", "comment": null, "summary": "This paper studies the fundamental properties of the high-order forward-backward splitting mapping (HiFBS) and its associated forward-backward envelope (HiFBE) through the lens of high-order regularization for nonconvex composite functions. Specifically, we (i) establish the boundedness and uniform boundedness of HiFBS, along with the Hölder and Lipschitz continuity of HiFBE; (ii) derive an explicit form for the subdifferentials of HiFBE; and (iii) investigate necessary and sufficient conditions for the differentiability and weak smoothness of HiFBE under suitable assumptions. By leveraging the prox-regularity of $g$ and the concept of $p$-calmness, we further demonstrate the local single-valuedness and continuity of HiFBS, which in turn guarantee the differentiability of HiFBE in neighborhoods of calm points. This paves the way for the development of gradient-based algorithms tailored to nonconvex composite optimization problems."}
{"id": "2511.10586", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.10586", "abs": "https://arxiv.org/abs/2511.10586", "authors": ["Omid Mirzaeedodangeh", "Eliot Shekhtman", "Nikolai Matni", "Lars Lindemann"], "title": "Safe Planning in Interactive Environments via Iterative Policy Updates and Adversarially Robust Conformal Prediction", "comment": null, "summary": "Safe planning of an autonomous agent in interactive environments -- such as the control of a self-driving vehicle among pedestrians and human-controlled vehicles -- poses a major challenge as the behavior of the environment is unknown and reactive to the behavior of the autonomous agent. This coupling gives rise to interaction-driven distribution shifts where the autonomous agent's control policy may change the environment's behavior, thereby invalidating safety guarantees in existing work. Indeed, recent works have used conformal prediction (CP) to generate distribution-free safety guarantees using observed data of the environment. However, CP's assumption on data exchangeability is violated in interactive settings due to a circular dependency where a control policy update changes the environment's behavior, and vice versa. To address this gap, we propose an iterative framework that robustly maintains safety guarantees across policy updates by quantifying the potential impact of a planned policy update on the environment's behavior. We realize this via adversarially robust CP where we perform a regular CP step in each episode using observed data under the current policy, but then transfer safety guarantees across policy updates by analytically adjusting the CP result to account for distribution shifts. This adjustment is performed based on a policy-to-trajectory sensitivity analysis, resulting in a safe, episodic open-loop planner. We further conduct a contraction analysis of the system providing conditions under which both the CP results and the policy updates are guaranteed to converge. We empirically demonstrate these safety and convergence guarantees on a two-dimensional car-pedestrian case study. To the best of our knowledge, these are the first results that provide valid safety guarantees in such interactive settings."}
{"id": "2511.10058", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.10058", "abs": "https://arxiv.org/abs/2511.10058", "authors": ["Shiqi Chen", "Xuesong Chen"], "title": "An inexact semismooth Newton-Krylov method for semilinear elliptic optimal control problem", "comment": "17 pages, 3 figures", "summary": "An inexact semismooth Newton method has been proposed for solving semi-linear elliptic optimal control problems in this paper. This method incorporates the generalized minimal residual (GMRES) method, a type of Krylov subspace method, to solve the Newton equations and utilizes nonmonotonic line search to adjust the iteration step size. The original problem is reformulated into a nonlinear equation through variational inequality principles and discretized using a second-order finite difference scheme. By leveraging slanting differentiability, the algorithm constructs semismooth Newton directions and employs GMRES method to inexactly solve the Newton equations, significantly reducing computational overhead. A dynamic nonmonotonic line search strategy is introduced to adjust stepsizes adaptively, ensuring global convergence while overcoming local stagnation. Theoretical analysis demonstrates that the algorithm achieves superlinear convergence near optimal solutions when the residual control parameter $η_k$ approaches to 0. Numerical experiments validate the method's accuracy and efficiency in solving semilinear elliptic optimal control problems, corroborating theoretical insights."}
{"id": "2511.10426", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10426", "abs": "https://arxiv.org/abs/2511.10426", "authors": ["Max Mowbray", "Nilay Shah", "Benoît Chachuat"], "title": "A Decomposition Approach to Solving Numerical Constraint Satisfaction Problems on Directed Acyclic Graphs", "comment": null, "summary": "Certifying feasibility in decision-making, critical in many industries, can be framed as a constraint satisfaction problem. This paper focuses on characterising a subset of parameter values from an a priori set that satisfy constraints on a directed acyclic graph of constituent functions. The main assumption is that these functions and constraints may be evaluated for given parameter values, but they need not be known in closed form and could result from expensive or proprietary simulations. This setting lends itself to using sampling methods to gain an inner approximation of the feasible domain. To mitigate the curse of dimensionality, the paper contributes new methodology to leverage the graph structure for decomposing the problem into lower-dimensional subproblems defined on the respective nodes. The working hypothesis that the Cartesian product of the solution sets yielded by the subproblems will tighten the a priori parameter domain, before solving the full problem defined on the graph, is demonstrated through four case studies relevant to machine learning and engineering. Future research will extend this approach to cyclic graphs and account for parametric uncertainty."}
{"id": "2511.10425", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.10425", "abs": "https://arxiv.org/abs/2511.10425", "authors": ["Susan Ghaderi", "Morteza Rahimi", "Yves Moreau", "Masoud Ahookhosh"], "title": "(Adaptive) Scaled gradient methods beyond locally Holder smoothness: Lyapunov analysis, convergence rate and complexity", "comment": "25 pages", "summary": "This paper addresses the unconstrained minimization of smooth convex functions whose gradients are locally Holder continuous. Building on these results, we analyze the Scaled Gradient Algorithm (SGA) under local smoothness assumptions, proving its global convergence and iteration complexity. Furthermore, under local strong convexity and the Kurdyka-Lojasiewicz (KL) inequality, we establish linear convergence rates and provide explicit complexity bounds. In particular, we show that when the gradient is locally Lipschitz continuous, SGA attains linear convergence for any KL exponent. We then introduce and analyze an adaptive variant of SGA (AdaSGA), which automatically adjusts the scaling and step-size parameters. For this method, we show global convergence, and derive local linear rates under strong convexity."}
{"id": "2511.10596", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10596", "abs": "https://arxiv.org/abs/2511.10596", "authors": ["Ahmed Gamal Eldin"], "title": "The Resonance Principle: Empirical Evidence for Emergent Phase Synchronization in Human Causal Reasoning", "comment": null, "summary": "Current artificial intelligence systems excel at correlational pattern matching but fail to achieve genuine causal understanding, a limitation often described as the \"Kepler versus Newton\" problem. We argue that this limitation is inherent to deterministic digital architectures. We introduce the Resonance Principle, a theoretical framework proposing that causal understanding emerges only in stochastic, bounded agents with intrinsic cost functions. The agent's substrate is modeled as a network of weakly coupled oscillators, where action proposals arise as stable resonant modes excited by intrinsic noise. We hypothesize that the brain, a stochastic and resonant system, operates according to this principle. To test this, we analyzed high-density EEG data (25 recordings, 500 trials) from a P300 BCI task. We computed the Kuramoto Order Parameter (R) to measure global phase synchronization (resonance) and compared it to the Event-Related Potential (ERP) voltage. Global resonance and voltage were statistically uncorrelated (r = 0.048), yet trial-level analysis revealed a strong correlation (r = 0.590, p < 0.0001). This suggests that resonance is a hidden mechanism coordinating neural firing, giving rise to measurable ERPs. We conclude that phase synchronization is not a byproduct but a fundamental signature of emergent causal understanding."}
{"id": "2511.10496", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.10496", "abs": "https://arxiv.org/abs/2511.10496", "authors": ["François Clément", "Linhang Huang", "Woorim Lee", "Cole Smidt", "Braeden Sodt", "Xuan Zhang"], "title": "Low-Discrepancy Set Post-Processing via Gradient Descent", "comment": null, "summary": "The construction of low-discrepancy sets, used for uniform sampling and numerical integration, has recently seen great improvements based on optimization and machine learning techniques. However, these methods are computationally expensive, often requiring days of computation or access to GPU clusters. We show that simple gradient descent-based techniques allow for comparable results when starting with a reasonably uniform point set. Not only is this method much more efficient and accessible, but it can be applied as post-processing to any low-discrepancy set generation method for a variety of standard discrepancy measures."}
{"id": "2511.10510", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.10510", "abs": "https://arxiv.org/abs/2511.10510", "authors": ["Jun Liu"], "title": "Formal Verification of Control Lyapunov-Barrier Functions for Safe Stabilization with Bounded Controls", "comment": null, "summary": "We present verifiable conditions for synthesizing a single smooth Lyapunov function that certifies both asymptotic stability and safety under bounded controls. These sufficient conditions ensure the strict compatibility of a control barrier function (CBF) and a control Lyapunov function (CLF) on the exact safe set certified by the barrier. An explicit smooth control Lyapunov-barrier function (CLBF) is then constructed via a patching formula that is provably correct by design. Two examples illustrate the computational procedure, showing that the proposed approach is less conservative than sum-of-squares (SOS)-based compatible CBF-CLF designs."}
{"id": "2511.10473", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.10473", "abs": "https://arxiv.org/abs/2511.10473", "authors": ["Florian Messerer", "Yunfan Gao", "Jonathan Frey", "Moritz Diehl"], "title": "Riccati-ZORO: An efficient algorithm for heuristic online optimization of internal feedback laws in robust and stochastic model predictive control", "comment": null, "summary": "We present Riccati-ZORO, an algorithm for tube-based optimal control problems (OCP). Tube OCPs predict a tube of trajectories in order to capture predictive uncertainty. The tube induces a constraint tightening via additional backoff terms. This backoff can significantly affect the performance, and thus implicitly defines a cost of uncertainty. Optimizing the feedback law used to predict the tube can significantly reduce the backoffs, but its online computation is challenging.\n  Riccati-ZORO jointly optimizes the nominal trajectory and uncertainty tube based on a heuristic uncertainty cost design. The algorithm alternates between two subproblems: (i) a nominal OCP with fixed backoffs, (ii) an unconstrained tube OCP, which optimizes the feedback gains for a fixed nominal trajectory. For the tube optimization, we propose a cost function informed by the proximity of the nominal trajectory to constraints, prioritizing reduction of the corresponding backoffs. These ideas are developed in detail for ellipsoidal tubes under linear state feedback. In this case, the decomposition into the two subproblems yields a substantial reduction of the computational complexity with respect to the state dimension from $\\mathcal{O}(n_x^6)$ to $\\mathcal{O}(n_x^3)$, i.e., the complexity of a nominal OCP.\n  We investigate the algorithm in numerical experiments, and provide two open-source implementations: a prototyping version in CasADi and a high-performance implementation integrated into the acados OCP solver."}
{"id": "2511.09767", "categories": ["stat.ME", "cs.LG", "econ.GN", "eess.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.09767", "abs": "https://arxiv.org/abs/2511.09767", "authors": ["Alessandro V. M. Oliveira"], "title": "Modelos Empiricos de Pos-Dupla Selecao por LASSO: Discussoes para Estudos do Transporte Aereo", "comment": "Article in Portuguese", "summary": "This paper presents and discusses forms of estimation by regularized regression and model selection using the LASSO method - Least Absolute Shrinkage and Selection Operator. LASSO is recognized as one of the main supervised learning methods applied to high-dimensional econometrics, allowing work with large volumes of data and multiple correlated controls. Conceptual issues related to the consequences of high dimensionality in modern econometrics and the principle of sparsity, which underpins regularization procedures, are addressed. The study examines the main post-double selection and post-regularization models, including variations applied to instrumental variable models. A brief description of the lassopack routine package, its syntaxes, and examples of HD, HDS (High-Dimension Sparse), and IV-HDS models, with combinations involving fixed effects estimators, is also presented. Finally, the potential application of the approach in research focused on air transport is discussed, with emphasis on an empirical study on the operational efficiency of airlines and aircraft fuel consumption."}
{"id": "2511.10586", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.10586", "abs": "https://arxiv.org/abs/2511.10586", "authors": ["Omid Mirzaeedodangeh", "Eliot Shekhtman", "Nikolai Matni", "Lars Lindemann"], "title": "Safe Planning in Interactive Environments via Iterative Policy Updates and Adversarially Robust Conformal Prediction", "comment": null, "summary": "Safe planning of an autonomous agent in interactive environments -- such as the control of a self-driving vehicle among pedestrians and human-controlled vehicles -- poses a major challenge as the behavior of the environment is unknown and reactive to the behavior of the autonomous agent. This coupling gives rise to interaction-driven distribution shifts where the autonomous agent's control policy may change the environment's behavior, thereby invalidating safety guarantees in existing work. Indeed, recent works have used conformal prediction (CP) to generate distribution-free safety guarantees using observed data of the environment. However, CP's assumption on data exchangeability is violated in interactive settings due to a circular dependency where a control policy update changes the environment's behavior, and vice versa. To address this gap, we propose an iterative framework that robustly maintains safety guarantees across policy updates by quantifying the potential impact of a planned policy update on the environment's behavior. We realize this via adversarially robust CP where we perform a regular CP step in each episode using observed data under the current policy, but then transfer safety guarantees across policy updates by analytically adjusting the CP result to account for distribution shifts. This adjustment is performed based on a policy-to-trajectory sensitivity analysis, resulting in a safe, episodic open-loop planner. We further conduct a contraction analysis of the system providing conditions under which both the CP results and the policy updates are guaranteed to converge. We empirically demonstrate these safety and convergence guarantees on a two-dimensional car-pedestrian case study. To the best of our knowledge, these are the first results that provide valid safety guarantees in such interactive settings."}
{"id": "2511.10483", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.10483", "abs": "https://arxiv.org/abs/2511.10483", "authors": ["Welington de Oliveira", "Valentina Sessa", "David Sossa"], "title": "Measuring dissimilarity between convex cones by means of max-min angles", "comment": null, "summary": "This work introduces a novel dissimilarity measure between two convex cones, based on the max-min angle between them. We demonstrate that this measure is closely related to the Pompeiu-Hausdorff distance, a well-established metric for comparing compact sets. Furthermore, we examine cone configurations where the measure admits simplified or analytic forms. For the specific case of polyhedral cones, a nonconvex cutting-plane method is deployed to compute, at least approximately, the measure between them. Our approach builds on a tailored version of Kelley's cutting-plane algorithm, which involves solving a challenging master program per iteration. When this master program is solved locally, our method yields an angle that satisfies certain necessary optimality conditions of the underlying nonconvex optimization problem yielding the dissimilarity measure between the cones. As an application of the proposed mathematical and algorithmic framework, we address the image-set classification task under limited data conditions, a task that falls within the scope of the \\emph{Few-Shot Learning} paradigm. In this context, image sets belonging to the same class are modeled as polyhedral cones, and our dissimilarity measure proves useful for understanding whether two image sets belong to the same class."}
{"id": "2511.09963", "categories": ["math.OC", "eess.SY", "math.AP", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2511.09963", "abs": "https://arxiv.org/abs/2511.09963", "authors": ["Iasson Karafyllis", "Dionysis Theodosis", "Miroslav Krstic"], "title": "The Age-Structured Chemostat with Substrate Dynamics as a Control System", "comment": "32 pages", "summary": "In this work we study an age-structured chemostat model with a renewal boundary condition and a coupled substrate equation. The model is nonlinear and consists of a hyperbolic partial differential equation and an ordinary differential equation with nonlinear, nonlocal terms appearing both in the ordinary differential equation and the boundary condition. Both differential equations contain a non-negative control input, while the states of the model are required to be positive. Under an appropriate weak solution framework, we determine the state space and the input space for this model. We prove global existence and uniqueness of solutions for all admissible initial conditions and all allowable control inputs. To this purpose we employ a combination of Banach's fixed-point theorem with implicit solution formulas and useful solution estimates. Finally, we show that the age-structured chemostat model gives a well-defined control system on a metric space."}
{"id": "2511.10596", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10596", "abs": "https://arxiv.org/abs/2511.10596", "authors": ["Ahmed Gamal Eldin"], "title": "The Resonance Principle: Empirical Evidence for Emergent Phase Synchronization in Human Causal Reasoning", "comment": null, "summary": "Current artificial intelligence systems excel at correlational pattern matching but fail to achieve genuine causal understanding, a limitation often described as the \"Kepler versus Newton\" problem. We argue that this limitation is inherent to deterministic digital architectures. We introduce the Resonance Principle, a theoretical framework proposing that causal understanding emerges only in stochastic, bounded agents with intrinsic cost functions. The agent's substrate is modeled as a network of weakly coupled oscillators, where action proposals arise as stable resonant modes excited by intrinsic noise. We hypothesize that the brain, a stochastic and resonant system, operates according to this principle. To test this, we analyzed high-density EEG data (25 recordings, 500 trials) from a P300 BCI task. We computed the Kuramoto Order Parameter (R) to measure global phase synchronization (resonance) and compared it to the Event-Related Potential (ERP) voltage. Global resonance and voltage were statistically uncorrelated (r = 0.048), yet trial-level analysis revealed a strong correlation (r = 0.590, p < 0.0001). This suggests that resonance is a hidden mechanism coordinating neural firing, giving rise to measurable ERPs. We conclude that phase synchronization is not a byproduct but a fundamental signature of emergent causal understanding."}
{"id": "2511.10496", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.10496", "abs": "https://arxiv.org/abs/2511.10496", "authors": ["François Clément", "Linhang Huang", "Woorim Lee", "Cole Smidt", "Braeden Sodt", "Xuan Zhang"], "title": "Low-Discrepancy Set Post-Processing via Gradient Descent", "comment": null, "summary": "The construction of low-discrepancy sets, used for uniform sampling and numerical integration, has recently seen great improvements based on optimization and machine learning techniques. However, these methods are computationally expensive, often requiring days of computation or access to GPU clusters. We show that simple gradient descent-based techniques allow for comparable results when starting with a reasonably uniform point set. Not only is this method much more efficient and accessible, but it can be applied as post-processing to any low-discrepancy set generation method for a variety of standard discrepancy measures."}
{"id": "2511.09767", "categories": ["stat.ME", "cs.LG", "econ.GN", "eess.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.09767", "abs": "https://arxiv.org/abs/2511.09767", "authors": ["Alessandro V. M. Oliveira"], "title": "Modelos Empiricos de Pos-Dupla Selecao por LASSO: Discussoes para Estudos do Transporte Aereo", "comment": "Article in Portuguese", "summary": "This paper presents and discusses forms of estimation by regularized regression and model selection using the LASSO method - Least Absolute Shrinkage and Selection Operator. LASSO is recognized as one of the main supervised learning methods applied to high-dimensional econometrics, allowing work with large volumes of data and multiple correlated controls. Conceptual issues related to the consequences of high dimensionality in modern econometrics and the principle of sparsity, which underpins regularization procedures, are addressed. The study examines the main post-double selection and post-regularization models, including variations applied to instrumental variable models. A brief description of the lassopack routine package, its syntaxes, and examples of HD, HDS (High-Dimension Sparse), and IV-HDS models, with combinations involving fixed effects estimators, is also presented. Finally, the potential application of the approach in research focused on air transport is discussed, with emphasis on an empirical study on the operational efficiency of airlines and aircraft fuel consumption."}
{"id": "2511.10498", "categories": ["math.OC", "math.MG"], "pdf": "https://arxiv.org/pdf/2511.10498", "abs": "https://arxiv.org/abs/2511.10498", "authors": ["Jun Kitagawa", "Cecilia Mikat"], "title": "Time-periodic branched transport", "comment": "36 pages, comments welcome!", "summary": "We develop a new framework for branched transport between probability measures which are allowed to vary in time. This framework can be used to model problems where the underlying transportation network displays a branched structure, but the source and target mass distributions can change cyclically over time, such as road networks or circulatory systems. We introduce the notion of time-dependent transport paths along with associated energies and distances, and prove existence of transport paths whose energy achieves the distance. We also show the time-dependent transport yields a metric structure on subsets of appropriately defined measure-valued Sobolev spaces."}
{"id": "2511.09963", "categories": ["math.OC", "eess.SY", "math.AP", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2511.09963", "abs": "https://arxiv.org/abs/2511.09963", "authors": ["Iasson Karafyllis", "Dionysis Theodosis", "Miroslav Krstic"], "title": "The Age-Structured Chemostat with Substrate Dynamics as a Control System", "comment": "32 pages", "summary": "In this work we study an age-structured chemostat model with a renewal boundary condition and a coupled substrate equation. The model is nonlinear and consists of a hyperbolic partial differential equation and an ordinary differential equation with nonlinear, nonlocal terms appearing both in the ordinary differential equation and the boundary condition. Both differential equations contain a non-negative control input, while the states of the model are required to be positive. Under an appropriate weak solution framework, we determine the state space and the input space for this model. We prove global existence and uniqueness of solutions for all admissible initial conditions and all allowable control inputs. To this purpose we employ a combination of Banach's fixed-point theorem with implicit solution formulas and useful solution estimates. Finally, we show that the age-structured chemostat model gives a well-defined control system on a metric space."}
{"id": "2511.09807", "categories": ["math.ST", "math.AP", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.09807", "abs": "https://arxiv.org/abs/2511.09807", "authors": ["Alberto González-Sanz", "Eustasio del Barrio", "Marcel Nutz"], "title": "Sample Complexity of Quadratically Regularized Optimal Transport", "comment": null, "summary": "It is well known that optimal transport suffers from the curse of dimensionality: when the prescribed marginals are approximated by i.i.d. samples, the convergence of the empirical optimal transport problem to the population counterpart slows exponentially with increasing dimension. Entropically regularized optimal transport (EOT) has become the standard bearer in many statistical applications as it avoids this curse. Indeed, EOT has parametric sample complexity, as has been shown in a series of works based on the smoothness of the EOT potentials or the strong concavity of the dual EOT problem. However, EOT produces full-support approximations to the (sparse) OT problem, leading to overspreading in applications, and is computationally unstable for small regularization parameters. The most popular alternative is quadratically regularized optimal transport (QOT), which penalizes couplings by $L^2$ norm instead of relative entropy. QOT produces sparse approximations of OT and is computationally stable. However, its potentials are not smooth (do not belong to a Donsker class) and its dual problem is not strongly concave, hence QOT is often assumed to suffer from the curse of dimensionality. In this paper, we show that QOT nevertheless has parametric sample complexity. More precisely, we establish central limit theorems for its dual potentials, optimal couplings, and optimal costs. Our analysis is based on novel arguments that focus on the regularity of the support of the optimal QOT coupling. Specifically, we establish a Lipschitz property of its sections and leverage VC theory to bound its statistical complexity. Our analysis also leads to gradient estimates of independent interest, including $C^{1,1}$ regularity of the population potentials."}
{"id": "2511.09916", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.09916", "abs": "https://arxiv.org/abs/2511.09916", "authors": ["Kunjing Yang", "Libin Zheng", "Minru Bai"], "title": "Implicit Multiple Tensor Decomposition", "comment": null, "summary": "Recently, triple decomposition has attracted increasing attention for decomposing third-order tensors into three factor tensors. However, this approach is limited to third-order tensors and enforces uniformity in the lower dimensions across all factor tensors, which restricts its flexibility and applicability. To address these issues, we propose the Multiple decomposition, a novel framework that generalizes triple decomposition to arbitrary order tensors and allows the short dimensions of the factor tensors to differ. We establish its connections with other classical tensor decompositions. Furthermore, implicit neural representation (INR) is employed to continuously represent the factor tensors in Multiple decomposition, enabling the method to generalize to non-grid data. We refer to this INR-based Multiple decomposition as Implicit Multiple Tensor Decomposition (IMTD). Then, the Proximal Alternating Least Squares (PALS) algorithm is utilized to solve the IMTD-based tensor reconstruction models. Since the objective function in IMTD-based models often lacks the Kurdyka-Lojasiewicz (KL) property, we establish a KL-free convergence analysis for the algorithm. Finally, extensive numerical experiments further validate the effectiveness of the proposed method."}
{"id": "2511.10293", "categories": ["stat.ME", "math.OC", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.10293", "abs": "https://arxiv.org/abs/2511.10293", "authors": ["Athanasios Christou Micheas"], "title": "Zeroes and Extrema of Functions via Random Measures", "comment": "Function extrema and zeroes; Optimization; Poisson point process; Random counting measures; Riemann's zeta function", "summary": "We present methods that provide all zeroes and extrema of a function that do not require differentiation. Using point process theory, we are able to describe the locations of zeroes or maxima, their number, as well as their distribution over a given window of observation. The algorithms in order to accomplish the theoretical development are also provided, and they are exemplified using many illustrative examples, for real and complex functions."}
{"id": "2511.10452", "categories": ["math.NA", "math.OC", "physics.flu-dyn", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2511.10452", "abs": "https://arxiv.org/abs/2511.10452", "authors": ["Gonzalo G. de Diego", "Georg Stadler"], "title": "Learning parameter-dependent shear viscosity from data, with application to sea and land ice", "comment": null, "summary": "Complex physical systems which exhibit fluid-like behavior are often modeled as non-Newtonian fluids. A crucial element of a non-Newtonian model is the rheology, which relates inner stresses with strain-rates. We propose a framework for inferring rheological models from data that represents the fluid's effective viscosity with a neural network. By writing the rheological law in terms of tensor invariants and tailoring the network's properties, the inferred model satisfies key physical and mathematical properties, such as isotropic frame-indifference and existence of a convex potential of dissipation. Within this framework, we propose two approaches to learning a fluid's rheology: 1) a standard regression that fits the rheological model to stress data and 2) a PDE-constrained optimization method that infers rheological models from velocity data. For the latter approach, we combine finite element and machine learning libraries. We demonstrate the accuracy and robustness of our method on land and sea ice rheologies which also depend on external parameters. For land ice, we infer the temperature-dependent Glen's law and, for sea ice, the concentration-dependent shear component of the viscous-plastic model. For these two models, we explore the effects of large data errors. Finally, we infer an unknown concentration-dependent model that reproduces Lagrangian ice floe simulation data. Our method discovers a rheology that generalizes well outside of the training dataset and exhibits both shear-thickening and thinning behaviors depending on the concentrations."}
{"id": "2511.10510", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.10510", "abs": "https://arxiv.org/abs/2511.10510", "authors": ["Jun Liu"], "title": "Formal Verification of Control Lyapunov-Barrier Functions for Safe Stabilization with Bounded Controls", "comment": null, "summary": "We present verifiable conditions for synthesizing a single smooth Lyapunov function that certifies both asymptotic stability and safety under bounded controls. These sufficient conditions ensure the strict compatibility of a control barrier function (CBF) and a control Lyapunov function (CLF) on the exact safe set certified by the barrier. An explicit smooth control Lyapunov-barrier function (CLBF) is then constructed via a patching formula that is provably correct by design. Two examples illustrate the computational procedure, showing that the proposed approach is less conservative than sum-of-squares (SOS)-based compatible CBF-CLF designs."}
