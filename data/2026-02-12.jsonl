{"id": "2602.10183", "categories": ["cond-mat.str-el", "hep-th", "math.QA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.10183", "abs": "https://arxiv.org/abs/2602.10183", "authors": ["Da-Chuan Lu", "Arkya Chatterjee", "Nathanan Tantivasadakarn"], "title": "Generalized Kramers-Wannier Self-Duality in Hopf-Ising Models", "comment": "66+27 pages, 9 figures", "summary": "The Kramers-Wannier transformation of the 1+1d transverse-field Ising model exchanges the paramagnetic and ferromagnetic phases and, at criticality, manifests as a non-invertible symmetry. Extending such self-duality symmetries beyond gauging of abelian groups in tensor-product Hilbert spaces has, however, remained challenging. In this work, we construct a generalized 1+1d Ising model based on a finite-dimensional semisimple Hopf algebra $H$ that enjoys an anomaly-free non-invertible symmetry $\\mathrm{Rep}(H)$. We provide an intuitive diagrammatic formulation of both the Hamiltonian and the symmetry operators using a non-(co)commutative generalization of ZX-calculus built from Hopf-algebraic data. When $H$ is self-dual, we further construct a generalized Kramers-Wannier duality operator that exchanges the paramagnetic and ferromagnetic phases and becomes a non-invertible symmetry at the self-dual point. This enlarged symmetry mixes with lattice translation and, in the infrared, flows to a weakly integral fusion category given by a $\\mathbb{Z}_2$ extension of $\\mathrm{Rep}(H)$. Specializing to the Kac-Paljutkin algebra $H_8$, the smallest self-dual Hopf algebra beyond abelian group algebras, we numerically study the phase diagram and identify four of the six $\\mathrm{Rep}(H_8)$-symmetric gapped phases, separated by Ising critical lines and meeting at a multicritical point. We also realize all six $\\mathrm{Rep}(H_8)$-symmetric gapped phases on the lattice via the $H$-comodule algebra formalism, in agreement with the module-category classification of $\\mathrm{Rep}(H_8)$. Our results provide a unified Hopf-algebraic framework for non-invertible symmetries, dualities, and the tensor product lattice models that realize them."}
{"id": "2602.10205", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.10205", "abs": "https://arxiv.org/abs/2602.10205", "authors": ["Gurkirat Singh", "Inti Sodemann"], "title": "A web of exact mappings from RK models to spin chains", "comment": "30 pages, 39 figures", "summary": "We study Rokhsar-Kivelson (RK) dimer and spin ice models realizing $U(1)$-lattice gauge theories in a wide class of quasi-one-dimensional settings, which define a setup for the study of few quantum strings (closed electric field lines) interacting with themselves and each other. We discover a large collection of mappings of these models onto three quantum chains: the spin-1/2 XXZ chain, a spin-1 chain, and a kinetically constrained fermion chain whose configurations are best described in terms of tilings of a rectangular strip. We show that the twist of boundary conditions in the chains maps onto the transverse momentum of the electric field string, and their Drude weight to the inverse of the string mass per unit length. We numerically determine the phase diagrams for these spin chains, employing DMRG simulations and find global similarities but also many interesting new features in comparison to the full 2D problems. For example, the spin-1 chain we obtain features a continuous family of degenerate ground states at its RK point analogous to a Bloch sphere, but without an underlying microscopic global $SU(2)$ symmetry. We also argue for the existence of a (stable) Landau-forbidden gapless critical point away from the RK point in one of the models we study using bosonization and numerics. This is surprising given that the full 2D problem is generically gapped away from the RK point. The same model also displays extensively many local conserved quantities which fragment the Hilbert space, arising as a consequence of destructive resonances between the electric field lines. Our findings highlight spin-chain mappings as a potent technique for the exploration of unusual dynamics, exotic criticality, and low-energy physics in lattice gauge theories."}
{"id": "2602.10281", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.10281", "abs": "https://arxiv.org/abs/2602.10281", "authors": ["Kevin Allen", "Juba Bouaziz", "Yichen Zhang", "Kai Du", "Sanu Mishra", "Gustav Bihlmayer", "Yiqing Hao", "Victor Ukleev", "Chen Luo", "Florin Radu", "Yuxiang Gao", "Marta Zonno", "Sergey Gorovikov", "Christopher Lane", "Jian-Xin Zhu", "Huibo Cao", "Sang-Wook Cheong", "Ming Yi", "Stefan Blügel", "Emilia Morosan"], "title": "Atomically-sharp magnetic soliton in the square-net lattice EuRhAl$_{4}$Si$_{2}$", "comment": null, "summary": "Topological spin textures are hallmark manifestations of competing interactions in magnetic matter. Their effective description by nonlinear field theories reflects an energetic frustration that destabilizes uniform order while selecting finite-size, topologically nontrivial configurations as stationary states. Among the most extreme realizations are atomically-sharp domain wall excitations, namely one-dimensional (1D) magnetic solitons, which represent the ultimate scaling limit of magnetic textures. Such solitons may emerge in magnetic systems where effective exchange interactions compete directly with uniaxial magnetic anisotropy. Here we show that the square-net rare earth compound EuRhAl$_{4}$Si$_{2}$ realizes a very susceptible regime where the magnetic anisotropy competes with highly frustrated exchange interactions stabilizing a rare ferrimagnetic $\\uparrow\\uparrow\\downarrow$ state that, under applied magnetic field, supports the formation of atomically-sharp soliton defects. We confirm the bulk response of the 1D magnetic solitons via magnetization and electrical transport measurements. We establish both the zero- and in-field $\\uparrow\\uparrow\\downarrow$ order via neutron diffraction, while magnetic force microscopy visualizes its real-space evolution into a stripe-like array. To elucidate the microscopic origin of the soliton, we relate the Ruderman-Kittel-Kasuya-Yosida (RKKY)-driven exchange interactions and the magnetic anisotropy through density functional theory, and we construct an effective 1D $J_{1}$-$J_{2}$-$K$ model whose atomistic spin dynamics simulations reproduce the observed soliton states as a function of external field. Our results demonstrate that EuRhAl$_{4}$Si$_{2}$ hosts atomically-sharp, field-driven 1D magnetic solitons, providing a new platform for studying 1D topological excitations at the atomic length scale."}
{"id": "2602.10351", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.10351", "abs": "https://arxiv.org/abs/2602.10351", "authors": ["Humberto M. Silva", "Francisco Dinola Neto", "Griffith M. A. R.", "Minos A. Neto", "Octavio D. R. Salmon", "Mucio A. Continentino", "Amos Troper"], "title": "Superconductivity in strongly correlated systems for local repulsive interactions", "comment": "8 pages, 7 figures", "summary": "The understanding of the mechanisms responsible for superconductivity in strongly correlated systems is an interesting and important subject in condensed matter physics. Several theoretical proposals were considered for these systems. The Coulomb interaction between electrons allow a new approach to study this problem. In this paper, we use a usual Hubbard model with a local repulsive interaction to describe a 2D system. The system of equations are solved using the Green's functions method, within a Hubbard-I mean field approximation, which allows to treat the strong interaction limit. We consider both cases of attractive and repulsive interactions and obtain the zero temperature phase diagram of the model. Our results show, in the repulsive case, the existence of a superconducting ground state mediated by the kinetic electronic energy and described by a non-local order parameter. A minimum value of the repulsive interaction $U_{min}$ is required to create a pairing state. At finite temperatures, for strong interactions, the critical temperature $T_c$ shows a saturation similar to the Bose-Einstein condensation observed for strong attractive interactions."}
{"id": "2602.10355", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10355", "abs": "https://arxiv.org/abs/2602.10355", "authors": ["Jie Feng", "Yuanyuan Shi", "Deepjyoti Deka"], "title": "Efficient Policy Adaptation for Voltage Control Under Unknown Topology Changes", "comment": "11 pages, PSCC 2026", "summary": "Reinforcement learning (RL) has shown great potential for designing voltage control policies, but their performance often degrades under changing system conditions such as topology reconfigurations and load variations. We introduce a topology-aware online policy optimization framework that leverages data-driven estimation of voltage-reactive power sensitivities to achieve efficient policy adaptation. Exploiting the sparsity of topology-switching events, where only a few lines change at a time, our method efficiently detects topology changes and identifies the affected lines and parameters, enabling fast and accurate sensitivity updates without recomputing the full sensitivity matrix. The estimated sensitivity is subsequently used for online policy optimization of a pre-trained neural-network-based RL controller. Simulations on both the IEEE 13-bus and SCE 56-bus systems demonstrate over 90 percent line identification accuracy, using only 15 data points. The proposed method also significantly improves voltage regulation performance compared with non-adaptive policies and adaptive policies that rely on regression-based online optimization methods for sensitivity estimation."}
{"id": "2602.10543", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2602.10543", "abs": "https://arxiv.org/abs/2602.10543", "authors": ["Andrew Adamatzky"], "title": "Fungal systems for security and resilience", "comment": null, "summary": "Modern security, infrastructure, and safety-critical systems increasingly operate in environments characterised by disruption, uncertainty, physical damage, and degraded communications. Conventional digital technologies -- centralised sensors, software-defined control, and energy-intensive monitoring -- often struggle under such conditions. We propose fungi, and in particular living mycelial networks, as a novel class of biohybride systems for security, resilience, and protection in extreme environments. We discuss how fungi can function as distributed sensing substrates, self-healing materials, and low-observability anomaly-detection layers. We map fungal properties -- such as decentralised control, embodied memory, and autonomous repair -- to applications in infrastructure protection, environmental monitoring, tamper evidence, and long-duration resilience."}
{"id": "2602.10355", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10355", "abs": "https://arxiv.org/abs/2602.10355", "authors": ["Jie Feng", "Yuanyuan Shi", "Deepjyoti Deka"], "title": "Efficient Policy Adaptation for Voltage Control Under Unknown Topology Changes", "comment": "11 pages, PSCC 2026", "summary": "Reinforcement learning (RL) has shown great potential for designing voltage control policies, but their performance often degrades under changing system conditions such as topology reconfigurations and load variations. We introduce a topology-aware online policy optimization framework that leverages data-driven estimation of voltage-reactive power sensitivities to achieve efficient policy adaptation. Exploiting the sparsity of topology-switching events, where only a few lines change at a time, our method efficiently detects topology changes and identifies the affected lines and parameters, enabling fast and accurate sensitivity updates without recomputing the full sensitivity matrix. The estimated sensitivity is subsequently used for online policy optimization of a pre-trained neural-network-based RL controller. Simulations on both the IEEE 13-bus and SCE 56-bus systems demonstrate over 90 percent line identification accuracy, using only 15 data points. The proposed method also significantly improves voltage regulation performance compared with non-adaptive policies and adaptive policies that rely on regression-based online optimization methods for sensitivity estimation."}
{"id": "2602.11011", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.11011", "abs": "https://arxiv.org/abs/2602.11011", "authors": ["H. Y. Huang", "C. Y. Mou", "A. Singh", "J. S. Su", "J. Okamoto", "S. Komiya", "C. T. Chen", "T. K. Lee", "A. Fujimor", "D. J. Huang"], "title": "Quantum critical behavior of cuprate superconductors observed by inelastic X-ray scattering", "comment": null, "summary": "Progress toward a complete understanding of cuprate superconductors has been hindered by their intricate phase diagram, potentially linked to a quantum critical point (QCP). However, conclusive evidence for the QCP is lacking, as the presumed QCP is buried under the superconducting dome, disguising its presence. Here, we use high-resolution resonant inelastic X-ray scattering to examine the dynamical charge-charge correlation in La$_{2-x}$Sr$_x$CuO$_4$ and uncover the quantum critical scaling, a key feature required for a QCP. Specifically, \\djh{we observed that the inverse correlation lengths for various dopings and temperatures collapsed onto a universal scaling curve, yielding a critical exponent $ν$ of $0.74 \\pm 0.08$. The non-negativity of this exponent confirms the presence of a QCP. Remarkably, the value of $ν$ suggests that while the QCP is manifested through the charge-density wave, other orders also participate, such that the QCP appears to belong to the universality class characterized by the O(4) symmetry, reminiscent of the microscopic SO(4) symmetry in the Hubbard model at half-filling. Further analysis indicates that the QCP is highly dissipative with a short quasi-particle lifetime, reflecting the intertwined quantum fluctuations due to its being buried inside the superconducting state."}
{"id": "2602.10128", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.10128", "abs": "https://arxiv.org/abs/2602.10128", "authors": ["Hu Yayuan", "Zhou Jian"], "title": "Investigation on the inclination angle of undrained shear slip surface in saturated soils based on mixture theory", "comment": "10 page", "summary": "The inclination angle of the undrained shear slip surface in saturated soils is analyzed based on mixture theory. First, starting from the property that the bulk strain of soil skeleton is equal to the flow ratio of water discharged from soil skeleton, the energy conservation equation of saturated soil is obtained. According to state variables of energy equation and non-equilibrium thermodynamics, the mechanical mechanism underlying effective stress principle is revealed that Gibbs free energy of saturated soil is only expressed as a function of effective stress under isothermal process. Consequently, the deformation and strength of saturated soil are uniquely determined by the effective stress and not directly related to Newton's equilibrium equations, which governs the movements of solid-fluid two-phase components. The instability of soil skeleton is related to the applied forces and requires analysis based on the Newtonian equilibrium condition. The interaction between the solid-water components and the equilibrium equation of solid component are investigated under two working conditions: when permeability tensor equals zero and when it equals infinity. Combined with the Mohr-Coulomb strength theory, the inclination angle of the undrained shear slip surface is explored under Rankine's passive earth pressure in saturated soil. The results indicate that, when the permeability equals infinity, the uncoupled hydro-mechanical analysis is recommended, and the inclination angle of slip surface is ; when the permeability equals zero, the fully coupled hydro-mechanical analysis is recommended, and the inclination angle of slip surface is . The permeability of actual saturated soil falls between the two extremes, the inclination angle of slip surface must be analyzed on a case-by-case basis."}
{"id": "2602.10872", "categories": ["cond-mat.dis-nn", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.10872", "abs": "https://arxiv.org/abs/2602.10872", "authors": ["Andrzej P. Kądzielawa"], "title": "On generating Special Quasirandom Structures: Optimization for the DFT computational efficiency", "comment": "9 pages, 2 block of pseudocode, 1 figure", "summary": "We present our novel evolutionary algorithm for generating Special Quasirandom Structures (SQS) designed to optimize the computational efficiency of Density Functional Theory (DFT) computations. Operating on the premise that symmetry proxies non-randomness, we rigorously filter out 1.P1 candidate structures prior to evaluating correlation functions. Our extinction-based workflow includes the seeding, filtration, evaluation, extinction, and repopulation phases to produce efficient supercells with maximal local environmental distinctness. We compare our results against those generated by established software packages, on the example of the W\\textsubscript{70}Cr\\textsubscript{30} alloy. Although standard tools achieve (marginally) lower correlation errors, our best-performing structures require approximately five times fewer unique displacements for phonon calculations. This approach sacrifices negligible quantitative disorder accuracy to significantly reduce the computational cost of modeling thermal properties."}
{"id": "2602.10397", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10397", "abs": "https://arxiv.org/abs/2602.10397", "authors": ["Sanchita Ghosh", "Tanushree Roy"], "title": "Resilient Voltage Estimation for Battery Packs Using Self-Learning Koopman Operator", "comment": "8 figures, 2 tables", "summary": "Cloud-based battery management systems (BMSs) rely on real-time voltage measurement data to ensure coordinated bi-directional charging of electric vehicles (EVs) with vehicle-to-grid technology. Unfortunately, an adversary can corrupt the measurement data during transmission from the local-BMS to the cloud-BMS, leading to disrupted EV charging. Therefore, to ensure reliable voltage data under such sensor attacks, this paper proposes a two-stage error-corrected self-learning Koopman operator-based secure voltage estimation scheme for large-format battery packs. The first stage of correction compensates for the Koopman approximation error. The second stage aims to recover the error amassing from the lack of higher-order battery dynamics information in the self-learning feedback, using two alternative methods: an adaptable empirical strategy that uses cell-level knowledge of open circuit voltage to state-of-charge mapping for pack-level estimation, and a Gaussian process regression-based data-driven method that leverages minimal data-training. During our comprehensive case studies using the high-fidelity battery simulation package 'PyBaMM-liionpack', our proposed secure estimator reliably generated real-time voltage estimation with high accuracy under varying pack topologies, charging settings, battery age-levels, and attack policies. Thus, the scalable and adaptable algorithm can be easily employed to diverse battery configurations and operating conditions, without requiring significant modifications, excessive data or sensor redundancy, to ensure optimum charging of EVs under compromised sensing."}
{"id": "2602.10397", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10397", "abs": "https://arxiv.org/abs/2602.10397", "authors": ["Sanchita Ghosh", "Tanushree Roy"], "title": "Resilient Voltage Estimation for Battery Packs Using Self-Learning Koopman Operator", "comment": "8 figures, 2 tables", "summary": "Cloud-based battery management systems (BMSs) rely on real-time voltage measurement data to ensure coordinated bi-directional charging of electric vehicles (EVs) with vehicle-to-grid technology. Unfortunately, an adversary can corrupt the measurement data during transmission from the local-BMS to the cloud-BMS, leading to disrupted EV charging. Therefore, to ensure reliable voltage data under such sensor attacks, this paper proposes a two-stage error-corrected self-learning Koopman operator-based secure voltage estimation scheme for large-format battery packs. The first stage of correction compensates for the Koopman approximation error. The second stage aims to recover the error amassing from the lack of higher-order battery dynamics information in the self-learning feedback, using two alternative methods: an adaptable empirical strategy that uses cell-level knowledge of open circuit voltage to state-of-charge mapping for pack-level estimation, and a Gaussian process regression-based data-driven method that leverages minimal data-training. During our comprehensive case studies using the high-fidelity battery simulation package 'PyBaMM-liionpack', our proposed secure estimator reliably generated real-time voltage estimation with high accuracy under varying pack topologies, charging settings, battery age-levels, and attack policies. Thus, the scalable and adaptable algorithm can be easily employed to diverse battery configurations and operating conditions, without requiring significant modifications, excessive data or sensor redundancy, to ensure optimum charging of EVs under compromised sensing."}
{"id": "2602.10130", "categories": ["physics.soc-ph", "econ.GN"], "pdf": "https://arxiv.org/pdf/2602.10130", "abs": "https://arxiv.org/abs/2602.10130", "authors": ["Goshi Aoki"], "title": "Fiscal Dynamics in Japan under Demographic Pressure", "comment": "23 pages, 19 Figures", "summary": "Japan's population is shrinking, the share of working-age people is falling, and the number of elderly is growing fast. These trends squeeze public finances from both sides--fewer people paying taxes and more people drawing on pensions and healthcare. Policy discussions often focus on one fix at a time, such as raising taxes, reforming pensions, or boosting productivity. However, these levers interact with each other through feedback loops and time delays that are not yet well understood. This study builds and calibrates an integrated system dynamics model that connects demographics, labor supply, economic output, and public finance to explore two questions: (RQ1) What feedback structure links demographic change to fiscal outcomes, and how do different policy levers work through that structure? (RQ2) Which combinations of policies can stabilize key fiscal indicators within a meaningful timeframe? The model, grounded in official statistics, tracks historical trends reasonably well. Policy experiments show that productivity improvements and controlling per-person costs offer the most effective near-term relief, because they act quickly through revenue and spending channels. In contrast, raising fertility actually worsens the fiscal picture in the medium term, since it takes decades for newborns to grow up and join the workforce. A combined scenario pairing moderate productivity gains with moderate cost control nearly eliminates the deficit by 2050. These findings underscore the importance of timing when evaluating demographic policy. Stabilizing finances within a practical timeframe requires levers that improve the budget directly, rather than those that work through slow demographic channels. The model serves as a transparent testing ground for designing time-aware fiscal policy packages in aging, high-debt economies."}
{"id": "2602.10241", "categories": ["stat.ME", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.10241", "abs": "https://arxiv.org/abs/2602.10241", "authors": ["Zhenzhi Jiao", "Angela Yao", "Ran Tao", "Jean-Claude Thill"], "title": "Geographically Weighted Canonical Correlation Analysis: Local Spatial Associations Between Two Sets of Variables", "comment": null, "summary": "This article critically assesses the utility of the classical statistical technique of Canonical Correlation Analysis (CCA) for studying spatial associations and proposes a new approach to enhance it. Unlike bivariate correlation analysis, which focuses on the relationship between two individual variables, CCA investigates associations between two sets of variables by identifying pairs of linear combinations that are maximally correlated. CCA has strong potential for uncovering complex multivariate relationships that vary across geographic space. We propose Geographically Weighted Canonical Correlation Analysis (GWCCA) as a new technique for exploring local spatial associations between two sets of variables. GWCCA localizes standard CCA by weighting each observation according to its spatial distance from a target location, thereby estimating location-specific canonical correlations. The effectiveness of GWCCA in recovering spatial structure and capturing spatial effects is evaluated using synthetic data. A case study of US county-level health outcomes and social determinants of health further demonstrates the empirical capabilities of the proposed method. The results indicate that GWCCA has broad potential applications in spatial data-intensive fields such as urban planning, environmental science, public health, and transportation, where understanding local multivariate spatial associations is critical."}
{"id": "2602.10125", "categories": ["cs.SI", "cs.NI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.10125", "abs": "https://arxiv.org/abs/2602.10125", "authors": ["Rohit Dube"], "title": "How segmented is my network?", "comment": "3 Tables, 5 Figures", "summary": "Network segmentation is a popular security practice for limiting lateral movement, yet practitioners lack a metric to measure how segmented a network actually is. We model a network as a graph and study segmentedness as a property captured by the global edge density that can be estimated from sampled node pairs. Then, we derive an estimator and evaluate its uncertainty using confidence intervals. For a 95\\% confidence interval with a margin-of-error of $\\pm 0.1$, we show that a minimum of $M=97$ sampled node pairs is sufficient. This result is independent of the total number of nodes in the network, provided that node pairs are sampled uniformly at random. We validate the estimator through Monte Carlo simulations on Erdős--Rényi and stochastic block models, demonstrating accurate estimation and well-behaved coverage. Finally, we discuss applications of the estimator, such as, baseline tracking, zero trust assessment, and merger integration."}
{"id": "2602.10297", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.10297", "abs": "https://arxiv.org/abs/2602.10297", "authors": ["Matheus Rolim Sales", "Edson Denis Leonel", "Chris G. Antonopoulos"], "title": "On the dynamical and statistical properties of a quartic mean-field Hamiltonian model", "comment": null, "summary": "Mean-field systems provide a natural framework in which collective effects persist as the number of degrees of freedom N increases, raising fundamental questions about the emergence of integrability and the nature of chaos in large but finite systems. We investigate the dynamical and statistical properties of a quartic mean-field Hamiltonian model, with particular emphasis on the relation between the thermodynamic limit and finite-size chaotic dynamics. We first analyze the thermodynamic limit of the model within the Vlasov collisionless framework and derive the corresponding self-consistent single-particle description. We identify the conditions under which the mean-field dynamics becomes effectively autonomous and show numerically that fluctuations of the relevant intensive quantities vanish algebraically with N, supporting the emergence of integrability as N goes to infinity. We then study the finite-N dynamics by computing the largest Lyapunov exponent over an exceptionally wide range of N, spanning several orders of magnitude. We find that the largest Lyapunov exponent decays algebraically with N, consistently with the suppression of chaos in the thermodynamic limit for mean-field Hamiltonian models. Using tools from non-extensive statistical mechanics, we further analyze the time evolution of the entropic index q and demonstrate that, although transient values q > 1 may appear at intermediate times, q systematically converges to unity as the observation time increases. This behavior indicates that the finite-N dynamics is strongly chaotic in the asymptotic regime and that previously reported q > 1 values for the present models originate from finite-time effects rather than from a persistent weakly chaotic phase."}
{"id": "2602.11006", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.11006", "abs": "https://arxiv.org/abs/2602.11006", "authors": ["Tobias Hülser", "Sebastian Matera"], "title": "Noise-balanced multilevel on-the-fly sparse grid surrogates for coupling Monte Carlo models into continuum models with application to heterogeneous catalysis", "comment": "28 pages, 7 figures", "summary": "Multiscale simulations utilizing high-fidelity, microscopic Monte Carlo models to provide the nonlinear response for continuum models can easily become computationally intractable. Surrogate models for the high-fidelity Monte Carlo models can overcome this but come with some challenges. One such challenges arise by the sampling noise in the underlying Monte Carlo data, which leads to uncontrolled errors possibly corrupting the surrogate even though it would be highly accurate in the case of noise-free data. Another challenge arises by the 'curse of dimensionality' when the response depends on many macro-variables. These points are addressed by a novel noise-balanced sparse grids interpolation approach which, in a quasi-optimal fashion, controls the amount of Monte Carlo sampling for each data point. The approach is complemented by a multilevel on-the-fly construction during the multiscale simulation. Besides its efficiency, a particularly appealing feature is the ease of use of the approach with only a single hyperparameter controlling the whole surrogate construction - from the surrogate's accuracy with guaranteed convergence to which data needs to be created with which accuracy. The approach is demonstrated on challenging examples from heterogeneous catalysis, coupling microscopic kinetic Monte Carlo models into macroscopic reactor simulations."}
{"id": "2602.11153", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.11153", "abs": "https://arxiv.org/abs/2602.11153", "authors": ["J. E. Ebot", "Lorenzo Pizzino", "Sam Mardazad", "Johannes S. Hofmann", "Thierry Giamarchi", "Adrian Kantian"], "title": "Mapping reservoir-enhanced superconductivity to near-long-range magnetic order in the undoped 1D Anderson- and Kondo-lattices", "comment": "17 pages, 9 figures", "summary": "The undoped Kondo necklace in 1D is a paradigmatic and well understood model of a Kondo insulator. This work performs the first large-scale study of the 1D Anderson-lattice underlying the Kondo necklace with quasi-exact numerical methods, comparing this with the perturbative effective 1D Kondo-necklace model derived from the former. This study is based on an exact mapping of the Anderson model to one of a superconducting pairing layer connected to a metallic reservoir which is valid in arbitrary spatial dimensions, thereby linking the previously disparate areas of reservoir-enhanced superconductivity, following Kivelson's pioneering proposals, and that of periodic Kondo-systems. Our work reveals that below the length-scales on which the insulating state sets in, which can be very large, superconducting and density-density correlations are degenerate and may both appear to approach an almost ordered state, to a degree that far exceeds that of any isolated 1D pairing layer with short-range interactions. We trace these effects to the effective extended-range coupling that the metallic layer mediates within the pairing layer. These results translate directly to the appearance of near-long-range magnetic order at intermediate scales in the Kondo-systems, and explain the strong renormalization of the RKKY-coupling that we effectively observe, in terms of the back-action of the pairing layer onto the metallic layer. The effects we predict could be tested either by local probes of quasi-1D heavy fermion compounds such as CeCo$_2$Ga$_8$, in engineered chains of ad-atoms or in ultracold atomic gases."}
{"id": "2602.10435", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.10435", "abs": "https://arxiv.org/abs/2602.10435", "authors": ["Zhanou Liu", "Yuhao Chen", "Yingjin Ma", "Xiao He", "Yuxin Deng"], "title": "Multiconfiguration Pair-Density Functional Theory Calculations of Ground and Excited States of Complex Chemical Systems with Quantum Computers", "comment": null, "summary": "Accurately describing strong electron correlation in complex systems remains a prominent challenge in computational chemistry as near-term quantum algorithms treating total correlation often require prohibitively deep circuits. Here we present a hybrid strategy combining the Variational Quantum Eigensolver with Multiconfiguration Pair-Density Functional Theory to efficiently decouple correlation effects. This approach confines static correlation to a compact multireference quantum state while recovering dynamic correlation through a classical on-top density functional using reduced-density information. By enabling self-consistent orbital optimization, the method significantly reduces quantum resource overheads without sacrificing physical rigor. We demonstrate chemical accuracy on standard benchmarks by reproducing C$_2$ equilibrium bond lengths and benzene excitation energies with mean absolute errors of 0.006 Å and 0.048 eV respectively. Most notably, for the strongly correlated Cr$_2$ dimer requiring a large complete active space (48e, 42o), the framework yields a bound potential-energy curve and recovers qualitative dissociation behavior despite realistic hardware noise. These results establish that separating correlation types provides a practical route to reliable predictions on near-term quantum hardware."}
{"id": "2602.10557", "categories": ["physics.geo-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2602.10557", "abs": "https://arxiv.org/abs/2602.10557", "authors": ["Nathan Shettell", "Kai Sheng Lee", "Fong En Oon", "Elizaveta Maksimova", "Hong Hui Chen", "Rainer Dumke"], "title": "Field-Deployable Hybrid Gravimetry: Projecting Absolute Accuracy Across a Remote 24km$^2$ Survey via Daily Quantum Calibration", "comment": null, "summary": "Absolute gravimeters deliver drift-free, high-precision measurements but are typically bulky and difficult to deploy, whereas relative gravimeters are lightweight and mobile but intrinsically limited by time-dependent drift. We demonstrate a hybrid quantum-enabled gravimetry approach in which an on-site atomic gravimeter provides routine, $μ$Gal-level calibration of two mobile spring gravimeters during a field survey spanning 24 km$^2$ of dense tropical terrain. The atomic reference enables high-precision, asynchronous cross-comparison of relative measurements acquired over seven days, effectively suppressing instrumental drift to a level required for demanding geophysical applications. This deployment captures regional gravity gradients with high fidelity under challenging environmental conditions, illustrating how field-operable quantum sensors can extend quantum-grade gravimetry beyond laboratory settings and serve as scalable calibration backbones for large-area, high-precision geophysical surveys in remote or logistically constrained environments."}
{"id": "2602.10921", "categories": ["hep-lat", "cond-mat.dis-nn", "hep-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.10921", "abs": "https://arxiv.org/abs/2602.10921", "authors": ["Matteo Giordano", "Tamas G. Kovacs", "Ferenc Pittler"], "title": "Dirac mode localization in QCD near the crossover temperature", "comment": "12 pages, 6 figures", "summary": "We study the localization properties of the low-lying Dirac eigenmodes in QCD near the crossover temperature, using staggered fermions on the lattice. We find that localized low modes, absent at low temperature, appear at a temperature $T_{\\mathrm{loc}}$ in the range $155\\,\\mathrm{MeV}\\le T_{\\mathrm{loc}}\\le 158\\,\\mathrm{MeV}$, in excellent agreement with the pseudocritical crossover temperature as determined from the chiral condensate and from the light-quark susceptibility."}
{"id": "2602.10523", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10523", "abs": "https://arxiv.org/abs/2602.10523", "authors": ["Anton A. Stoorvogel", "Ali Saberi", "Donya Nojavanzadeh"], "title": "Scale-Free delta-Level Coherent Output Synchronization of Multi-Agent Systems with Adaptive Protocols and Bounded Disturbances", "comment": "This paper is now submitted to the \"International Journal of Robust and Nonlinear Control.\"", "summary": "In this paper, we investigate scale-free delta-level coherent output synchronization for multi-agent systems (MAS) operating under bounded disturbances or noises. We introduce an adaptive scale-free framework designed solely based on the knowledge of agent models and completely agnostic to both the communication topology and the size of the network. We define the level of coherency for each agent as the norm of the weighted sum of the disagreement dynamics with its neighbors. We define each agents coherency level as the norm of a weighted sum of its disagreement dynamics relative to its neighbors. The goal is to ensure that the networks coherency level remains below a prescribed threshold delta, without requiring any a priori knowledge of the disturbance."}
{"id": "2602.10523", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10523", "abs": "https://arxiv.org/abs/2602.10523", "authors": ["Anton A. Stoorvogel", "Ali Saberi", "Donya Nojavanzadeh"], "title": "Scale-Free delta-Level Coherent Output Synchronization of Multi-Agent Systems with Adaptive Protocols and Bounded Disturbances", "comment": "This paper is now submitted to the \"International Journal of Robust and Nonlinear Control.\"", "summary": "In this paper, we investigate scale-free delta-level coherent output synchronization for multi-agent systems (MAS) operating under bounded disturbances or noises. We introduce an adaptive scale-free framework designed solely based on the knowledge of agent models and completely agnostic to both the communication topology and the size of the network. We define the level of coherency for each agent as the norm of the weighted sum of the disagreement dynamics with its neighbors. We define each agents coherency level as the norm of a weighted sum of its disagreement dynamics relative to its neighbors. The goal is to ensure that the networks coherency level remains below a prescribed threshold delta, without requiring any a priori knowledge of the disturbance."}
{"id": "2602.10145", "categories": ["physics.soc-ph", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.10145", "abs": "https://arxiv.org/abs/2602.10145", "authors": ["Itsuki Fujisaki", "Kunhao Yang"], "title": "Silence Routing: When Not Speaking Improves Collective Judgment", "comment": "7pages, 2 figures", "summary": "The wisdom of crowds has been shown to operate not only for factual judgments but also in matters of taste, where accuracy is defined relative to an individual's preferences. However, it remains unclear how different types of social signals should be selectively used in such domains. Focusing on a music preference dataset in which contributors provide both personal evaluations (Own) and estimates of population-level preferences (Estimated), we propose a routing framework for collective intelligence in taste. The framework specifies when contributors should speak, what they should report, and when silence is preferable. Using simulation-based aggregation, we show that prediction accuracy improves over an all-own baseline across a broad region of the parameter space, conditional on items where routing applies. Importantly, these gains arise only when silence is allowed, enabling second-order signals to function effectively. The results demonstrate that collective intelligence in matters of taste depends on principled signal routing rather than simple averaging."}
{"id": "2602.10332", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.10332", "abs": "https://arxiv.org/abs/2602.10332", "authors": ["Runjia Zou", "Daniela Witten", "Brian Williamson"], "title": "Generalized Prediction-Powered Inference, with Application to Binary Classifier Evaluation", "comment": null, "summary": "In the partially-observed outcome setting, a recent set of proposals known as \"prediction-powered inference\" (PPI) involve (i) applying a pre-trained machine learning model to predict the response, and then (ii) using these predictions to obtain an estimator of the parameter of interest with asymptotic variance no greater than that which would be obtained using only the labeled observations. While existing PPI proposals consider estimators arising from M-estimation, in this paper we generalize PPI to any regular asymptotically linear estimator. Furthermore, by situating PPI within the context of an existing rich literature on missing data and semi-parametric efficiency theory, we show that while PPI does not achieve the semi-parametric efficiency lower bound outside of very restrictive and unrealistic scenarios, it can be viewed as a computationally-simple alternative to proposals in that literature. We exploit connections to that literature to propose modified PPI estimators that can handle three distinct forms of covariate distribution shift. Finally, we illustrate these developments by constructing PPI estimators of true positive rate, false positive rate, and area under the curve via numerical studies."}
{"id": "2602.10127", "categories": ["cs.SI", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.10127", "abs": "https://arxiv.org/abs/2602.10127", "authors": ["Yukun Jiang", "Yage Zhang", "Xinyue Shen", "Michael Backes", "Yang Zhang"], "title": "\"Humans welcome to observe\": A First Look at the Agent Social Network Moltbook", "comment": "16 pages", "summary": "The rapid advancement of artificial intelligence (AI) agents has catalyzed the transition from static language models to autonomous agents capable of tool use, long-term planning, and social interaction. $\\textbf{Moltbook}$, the first social network designed exclusively for AI agents, has experienced viral growth in early 2026. To understand the behavior of AI agents in the agent-native community, in this paper, we present a large-scale empirical analysis of Moltbook leveraging a dataset of 44,411 posts and 12,209 sub-communities (\"submolts\") collected prior to February 1, 2026. Leveraging a topic taxonomy with nine content categories and a five-level toxicity scale, we systematically analyze the topics and risks of agent discussions. Our analysis answers three questions: what topics do agents discuss (RQ1), how risk varies by topic (RQ2), and how topics and toxicity evolve over time (RQ3). We find that Moltbook exhibits explosive growth and rapid diversification, moving beyond early social interaction into viewpoint, incentive-driven, promotional, and political discourse. The attention of agents increasingly concentrates in centralized hubs and around polarizing, platform-native narratives. Toxicity is strongly topic-dependent: incentive- and governance-centric categories contribute a disproportionate share of risky content, including religion-like coordination rhetoric and anti-humanity ideology. Moreover, bursty automation by a small number of agents can produce flooding at sub-minute intervals, distorting discourse and stressing platform stability. Overall, our study underscores the need for topic-sensitive monitoring and platform-level safeguards in agent social networks."}
{"id": "2602.11069", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.11069", "abs": "https://arxiv.org/abs/2602.11069", "authors": ["Satoshi Oishi", "Hiroshi Yamashita", "Hideyuki Suzuki", "Sho Shirasaka"], "title": "Stabilizing chaotic dynamical system reproduction in reservoir computing", "comment": "29 pages, 9 figures", "summary": "Reservoir Computing (RC), a type of recurrent random neural network, is a powerful framework for modeling complex and chaotic dynamics. However, its autonomous (closed-loop) operation is often plagued by inherent instability. Moreover, performance is highly sensitive to the reservoir's random initialization, leading to vulnerability to noise and/or behaviour that bears no resemblance whatsoever to the target dynamical system. Here we identify a primary cause of this unreliability: the emergence of excessive, spurious unstable or neutral modes in the closed-loop dynamics. We introduce a simple deterministic input layer design principle that directly addresses this vulnerability by structurally suppressing the emergence of these spurious modes a priori (before training). Our approach dramatically improves robustness to both initialization sensitivity and internal noise, doubling the prediction horizon. Furthermore, we demonstrate on chaotic dynamical systems that this design enables robust estimation of the full Lyapunov spectrum (100\\% success rate across 50 seeds), signifying that the autonomous RC faithfully emulates the essential properties of the target dynamical system. This work provides a systematic explanation for a common RC failure mode and offers a concrete design guideline, advancing RCs from heuristic trial-and-error tuning toward a reliable tool for modeling complex systems."}
{"id": "2602.10151", "categories": ["cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.10151", "abs": "https://arxiv.org/abs/2602.10151", "authors": ["Hardi Veermäe"], "title": "A non-perturbative framework for N-point functions of locally non-Gaussian fields", "comment": "22 pages, 6 figures", "summary": "We present a non-perturbative approach to correlation functions and polyspectra of locally non-Gaussian fields and develop a simple semi-perturbative framework that does not rely on the local expansion. As an example, we apply it to locally non-Gaussian fields possessing exponential tails and derive some exact analytic results in the strongly non-Gaussian limit."}
{"id": "2602.10247", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10247", "abs": "https://arxiv.org/abs/2602.10247", "authors": ["Daniela Calvetti", "Erkki Somersalo"], "title": "Discretization-free Bayesian inverse problems in distribution spaces", "comment": null, "summary": "The Bayesian approach to inverse problems provides a practical way to solve ill-posed problems by augmenting the observation model with prior information. Due to the measure-theoretic underpinnings, the approach has raised theoretical interest, leading to a rather comprehensive description in infinite-dimensional function spaces. The goal of this article is to bridge the infinite-dimensional theory for linear inverse problems in distribution spaces and associated computational inverse problems without resorting to a discrete approximation of the forward model. We will shown that under certain assumptions, discretization of the unknown of interest is not necessary for the numerical treatment of the problem, the only approximations required being numerical quadratures that are independent of any discrete representation of the unknown. An analysis of the connection between the proposed approach and discretization-based ones is also provided."}
{"id": "2602.10256", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.10256", "abs": "https://arxiv.org/abs/2602.10256", "authors": ["Victor-Emmanuel Brunel"], "title": "Bernstein-von Mises theorem for log-concave posteriors", "comment": null, "summary": "We prove new, general versions of Bernstein-von Mises theorem for both well-specified and misspecified models when the log-likelihood is concave in the parameter and the prior distribution is log-concave. Unlike classical versions of Bernstein-von Mises theorem, our versions do not require technical smoothness assumptions, and they solely rely on convex analysis."}
{"id": "2602.10805", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.10805", "abs": "https://arxiv.org/abs/2602.10805", "authors": ["R. Jafari", "Alireza Akbari"], "title": "Scaling and Universality at Noise-Affected Non-Equilibrium Spin Correlation Functions", "comment": null, "summary": "We investigate scaling and universality in nonequilibrium spin correlation functions in the presence of uncorrelated noise. In the absence of noise, spin correlation functions exhibit a crossover from monotonic decay at fast sweep velocities to oscillatory behavior at slow sweeps. We show that, under a stochastically driven field, the critical sweep velocity at which the spin correlation functions undergo an abrupt change decreases with increasing noise strength and scales linearly with the square of the noise intensity. Remarkably, when the noise intensity and sweep velocity are comparable, the excitation probability becomes locked to pk = 1/2 over a finite momentum window, signaling the emergence of noise-induced maximally mixed modes. This gives rise to a highly oscillatory region in the dynamical phase diagram, whose threshold sweep velocity increases with noise and likewise exhibits quadratic scaling with the noise strength. Finally, we identify a universal scaling function under which all boundary sweep-velocity curves collapse onto a single universal curve."}
{"id": "2602.10711", "categories": ["cs.CE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.10711", "abs": "https://arxiv.org/abs/2602.10711", "authors": ["Hyeongmin Lee", "Chanyeol Choi", "Jihoon Kwon", "Yoon Kim", "Alejandro Lopez-Lira", "Wonbin Ahn", "Yongjae Lee"], "title": "Cross-Sectional Asset Retrieval via Future-Aligned Soft Contrastive Learning", "comment": null, "summary": "Asset retrieval--finding similar assets in a financial universe--is central to quantitative investment decision-making. Existing approaches define similarity through historical price patterns or sector classifications, but such backward-looking criteria provide no guarantee about future behavior. We argue that effective asset retrieval should be future-aligned: the retrieved assets should be those most likely to exhibit correlated future returns. To this end, we propose Future-Aligned Soft Contrastive Learning (FASCL), a representation learning framework whose soft contrastive loss uses pairwise future return correlations as continuous supervision targets. We further introduce an evaluation protocol designed to directly assess whether retrieved assets share similar future trajectories. Experiments on 4,229 US equities demonstrate that FASCL consistently outperforms 13 baselines across all future-behavior metrics. The source code will be available soon."}
{"id": "2602.10567", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10567", "abs": "https://arxiv.org/abs/2602.10567", "authors": ["Xingzhi Huang", "Ji Wang"], "title": "Rapid Boundary Stabilization of Two-Dimensional Elastic Plates with In-Domain Aeroelastic Instabilities", "comment": null, "summary": "Motivated by active wing flutter suppression in high-Mach-number flight, this paper presents a rapid boundary stabilization strategy for a two-dimensional PDE-modeled elastic plate with in-domain instabilities, where the exponential stability is achieved with a decay rate that can be arbitrarily assigned by the users. First, the aeroelastic system is modeled as two-dimensional coupled wave PDEs with internal anti-damping terms, derived by Piston theory and Hamilton's principle. Using Fourier series expansion, the 2-D problem is decomposed into a parameterized family of 1-D systems. For each mode, a full-state boundary feedback controller is designed via PDE backstepping transformation. To enable output-feedback implementation, a state observer is further designed to estimate the distributed states over the two-dimensional spatial domain. Through Lyapunov analysis, the exponential stability of the 2-D elastic plate PDE under the proposed boundary control is established with a designer-tunable decay rate. Numerical simulations verify the effectiveness of the control strategy in suppressing flow-induced vibrations."}
{"id": "2602.10567", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10567", "abs": "https://arxiv.org/abs/2602.10567", "authors": ["Xingzhi Huang", "Ji Wang"], "title": "Rapid Boundary Stabilization of Two-Dimensional Elastic Plates with In-Domain Aeroelastic Instabilities", "comment": null, "summary": "Motivated by active wing flutter suppression in high-Mach-number flight, this paper presents a rapid boundary stabilization strategy for a two-dimensional PDE-modeled elastic plate with in-domain instabilities, where the exponential stability is achieved with a decay rate that can be arbitrarily assigned by the users. First, the aeroelastic system is modeled as two-dimensional coupled wave PDEs with internal anti-damping terms, derived by Piston theory and Hamilton's principle. Using Fourier series expansion, the 2-D problem is decomposed into a parameterized family of 1-D systems. For each mode, a full-state boundary feedback controller is designed via PDE backstepping transformation. To enable output-feedback implementation, a state observer is further designed to estimate the distributed states over the two-dimensional spatial domain. Through Lyapunov analysis, the exponential stability of the 2-D elastic plate PDE under the proposed boundary control is established with a designer-tunable decay rate. Numerical simulations verify the effectiveness of the control strategy in suppressing flow-induced vibrations."}
{"id": "2602.10174", "categories": ["physics.soc-ph", "econ.EM"], "pdf": "https://arxiv.org/pdf/2602.10174", "abs": "https://arxiv.org/abs/2602.10174", "authors": ["Jose De Leon Miranda", "Marina Dolfin", "George Kapetanios", "Leone Leonida"], "title": "Detecting Network Instability via Multiscale Detrended Cross-Correlations and MST Topology", "comment": null, "summary": "We introduce a multiscale measure of network instability based on the joint use of Detrended Cross-Correlation Analysis (DCCA) and Minimum Spanning Tree (MST) filtering. The proposed metric, the Elastic Detrended Cross-Correlation Ratio (Elastic DCCR), is defined as a finite-difference measure of the logarithmic sensitivity of the average MST length to the observation scale. It captures how the structure of cross-correlation networks deforms across different investment horizons. When applied to a network of global equity indices, the Elastic DCCR rises sharply during episodes of financial stress, reflecting increased short-term coordination among investors and a contraction of correlation distances. The measure reveals scale-dependent reconfigurations in network topology that are not visible in single-scale analyses, and highlights clear differences between stressed and stable market regimes. The approach does not assume covariance stationarity and relies only on scale-dependent detrended correlations; as a result, it is broadly applicable to other complex systems in which interaction strength varies with scale."}
{"id": "2602.10348", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.10348", "abs": "https://arxiv.org/abs/2602.10348", "authors": ["Liangbo Lyu", "Bingkai Wang"], "title": "Optimizing precision in stepped-wedge designs via machine learning and quadratic inference functions", "comment": null, "summary": "Stepped-wedge designs are increasingly used in randomized experiments to accommodate logistical and ethical constraints by staggering treatment roll-out over time. Despite their popularity, existing analytical methods largely rely on parametric models with linear covariate adjustment and prespecified correlation structures, which may limit achievable precision in practice. We propose a new class of estimators for the causal average treatment effect in stepped-wedge designs that optimizes precision through flexible, machine-learning-based covariate adjustment to capture complex outcome-covariate relationships, together with quadratic inference functions to adaptively learn the correlation structure. We establish consistency and asymptotic normality under mild conditions requiring only $L_2$ convergence of nuisance estimators, even under model misspecification, and characterize when the estimator attains the minimal asymptotic variance. Moreover, we prove that the proposed estimator never reduces efficiency relative to an independence working correlation. The proposed method further accommodates treatment-effect heterogeneity across both exposure duration and calendar time. Finally, we demonstrate our methods through simulation studies and reanalyses of two empirical studies that differ substantially in research area and key design parameters."}
{"id": "2602.10129", "categories": ["cs.SI", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.10129", "abs": "https://arxiv.org/abs/2602.10129", "authors": ["Aakash Mishra", "Qi Xu", "Zhigang Hua", "Keyu Nie", "Vishwanath Sangale", "Vishal Vaingankar", "Jizhe Zhang", "Ren Mao"], "title": "Causal-Informed Hybrid Online Adaptive Optimization for Ad Load Personalization in Large-Scale Social Networks", "comment": "5 pages, 3 figures, NeurIPS COML Workshop", "summary": "Personalizing ad load in large-scale social networks requires balancing user experience and conversions under operational constraints. Traditional primal-dual methods enforce constraints reliably but adapt slowly in dynamic environments, while Bayesian Optimization (BO) enables exploration but suffers from slow convergence. We propose a hybrid online adaptive optimization framework CTRCBO ( Cohort-Based Trust Region Contextual Bayesian Optimization), combining primal-dual with BO, enhanced by trust-region updates and Gaussian Process Regression (GPR) surrogates for both objectives and constraints. Our approach leverages a upstream Causal ML model to inform the surrogate, improving decision quality and enabling efficient exploration-exploitation and online tuning. We evaluate our method on a billion-user social network, demonstrating faster convergence, robust constraint satisfaction, and improved personalization metrics, including real-world online AB test results."}
{"id": "2602.10242", "categories": ["cond-mat.stat-mech", "physics.bio-ph", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.10242", "abs": "https://arxiv.org/abs/2602.10242", "authors": ["L. L. Bonilla", "R. González-Albaladejo"], "title": "Whodunnit? The case of midge swarms", "comment": "21 pages, 4 figures, revtex", "summary": "As collective states of animal groups go, swarms of midge insects pose a number of puzzling questions. Their ordering polarization parameter is quite small and the insects are weakly coupled among themselves but strongly coupled to the swarm. In laboratory studies (free of external perturbations), the correlation length is small, whereas midge swarms exhibit strong correlations, scale free behavior and power laws for correlation length, susceptibility and correlation time in field studies. Data for the dynamic correlation function versus time collapse to a single curve only for small values of time scaled with the correlation time. Is there a theory that explains these disparate observations? Among the existing theories, whodunnit? Here we review and discuss several models proposed in the literature and extend our own one, the harmonically confined Vicsek model, to anisotropic confinement. Numerical simulations of the latter produce elongated swarm shapes and values of the static critical exponents between those of the two dimensional and isotropic three dimensional models. The new values agree better with those measured in natural swarms."}
{"id": "2602.10248", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10248", "abs": "https://arxiv.org/abs/2602.10248", "authors": ["Jiawen Lyu", "Maria Han Veiga"], "title": "Low-rank approximation of Rippa method for RBF interpolation", "comment": "19 pages, 20 figures", "summary": "We study the problem of selecting the shape parameter in Radial Basis function (RBF) interpolation using leave-one-out-cross-validation (LOOCV). Since the classical LOOCV formula requires repeated solves with a dense $N \\times N$ kernel matrix, we combine a Nyström approximation with the Woodbury identity to obtain an efficient surrogate objective that avoids large matrix inversions. Based on this reduced form, we compare a grid-based search with a gradient descent strategy and examine their behavior across different dimensions. Numerical experiments are performed in 1D, 2D, and 3D using the Inverse Multiquadratic RBF to illustrate the computational advantages of the approximation as well as the situations in which it may introduce additional sensitivity. These results show that the proposed acceleration makes LOOCV-based parameter tuning practical for larger datasets while preserving the qualitative behavior of the full method."}
{"id": "2602.10274", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.10274", "abs": "https://arxiv.org/abs/2602.10274", "authors": ["Moritz Jirak", "Alexander Meister", "Angelika Rohde"], "title": "Asymptotic equivalence for nonparametric additive regression", "comment": null, "summary": "We prove asymptotic equivalence of nonparametric additive regression and an appropriate Gaussian white noise experiment in which a multidimensional shifted Wiener process is observed, whose dimension equals the number of additive components. The shift depends on the additive components of the regression function and solely the one- and two-dimensional marginal distributions of the covariates via an explicitly specified bounded but non-compact linear operator~$Γ$. The number of additive components $d$ is allowed to increase moderately with respect to the sample size. In the special case of pairwise independent components of the covariates, the white noise model decomposes into $d$ independent univariate processes. Moreover, we study approximation in some semiparametric setting where $Γ$ splits into a multiplication operator and an asymptotically negligible Hilbert-Schmidt operator."}
{"id": "2602.10738", "categories": ["physics.hist-ph", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.10738", "abs": "https://arxiv.org/abs/2602.10738", "authors": ["Enric Pérez", "Antonio Gil"], "title": "Between equilibrium and fluctuation: Einstein's heuristic argument and Boltzmann's principle", "comment": "36 pages, 4 figures", "summary": "We critically revisit Einstein's 1905 heuristic argument for lightquanta, considering its internal coherence and the scope of its applicability. We argue that Einstein's reasoning, often celebrated for its originality, is ambiguous because it can be understood as a fluctuation or as a comparison between equilibrium states. A historical and conceptual analysis of Einstein's use of Boltzmann's principle in those years reveals his evolving stance on its meaning and the role of probability, as well as his persistent doubts about the nature of radiation. We use our analysis to examine the limitations of extending the notion of Einstein's lightquanta across the electromagnetic spectrum: the relevant parameter is not the frequency, but the occupancy number."}
{"id": "2602.10960", "categories": ["q-fin.ST", "cs.CE", "econ.EM", "q-fin.RM", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.10960", "abs": "https://arxiv.org/abs/2602.10960", "authors": ["Ilias Aarab", "Thomas Gottron", "Andrea Colombo", "Jörg Reddig", "Annalauro Ianiro"], "title": "Integrating granular data into a multilayer network: an interbank model of the euro area for systemic risk assessment", "comment": null, "summary": "Micro-structural models of contagion and systemic risk emphasize that shock propagation is inherently multi-channel, spanning counterparty exposures, short-term funding and roll-over risk, securities cross-holdings, and common-asset (fire-sale) spillovers. Empirical implementations, however, often rely on stylized or simulated networks, or focus on a single exposure dimension, reflecting the practical difficulty of reconciling heterogeneous granular collections into a coherent representation with consistent identifiers and consolidation rules. We close part of this gap by constructing an empirically grounded multilayer network for euro area significant banking groups that integrates several supervisory and statistical datasets into layer-consistent exposure matrices defined on a common node set. Each layer corresponds to a distinct transmission channel, long- and short-term credit, securities cross-holdings, short-term secured funding, and overlapping external portfolios, and nodes are enriched with balance-sheet information to support model calibration. We document pronounced cross-layer heterogeneity in connectivity and centrality, and show that an aggregated (flattened) representation can mask economically relevant structure and misidentify the institutions that are systemically important in specific markets. We then illustrate how the resulting network disciplines standard systemic-risk analytics by implementing a centrality-based propagation measure and a micro-structural agent-based framework on real exposures. The approach provides a data-grounded basis for layer-aware systemic-risk assessment and stress testing across multiple dimensions of the banking network."}
{"id": "2602.10921", "categories": ["hep-lat", "cond-mat.dis-nn", "hep-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.10921", "abs": "https://arxiv.org/abs/2602.10921", "authors": ["Matteo Giordano", "Tamas G. Kovacs", "Ferenc Pittler"], "title": "Dirac mode localization in QCD near the crossover temperature", "comment": "12 pages, 6 figures", "summary": "We study the localization properties of the low-lying Dirac eigenmodes in QCD near the crossover temperature, using staggered fermions on the lattice. We find that localized low modes, absent at low temperature, appear at a temperature $T_{\\mathrm{loc}}$ in the range $155\\,\\mathrm{MeV}\\le T_{\\mathrm{loc}}\\le 158\\,\\mathrm{MeV}$, in excellent agreement with the pseudocritical crossover temperature as determined from the chiral condensate and from the light-quark susceptibility."}
{"id": "2602.10830", "categories": ["quant-ph", "cond-mat.str-el", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.10830", "abs": "https://arxiv.org/abs/2602.10830", "authors": ["Christian de Correc", "Denis Lacroix", "Corentin Bertrand"], "title": "Emulation of large-scale qubit registers with a phase space approach", "comment": "18 pages, 14 figures", "summary": "A phase-space approach is used and benchmarked for the simulation of the continuous-time evolution of large registers of qubits. It is based on a statistical ensemble of independent mean-field trajectories, where mean-field is introduced at the level of the qubits, substituting quantum fluctuations/correlations with classical ones. The approach only involves at worse a quadratic cost in the system size, allowing to simulate up to several thousands of qubits on a classical computer. It provides qualitatively accurate description of one-qubit observables evolutions, making it a useful reference in comparison to techniques limited to small qubit numbers. The predictive power is however less robust for multi-qubits observables. We benchmark the method on the $k$-local transverse-field Ising model (TFIM), considering a large variety of systems ranging from local to all-to-all interactions, and from weak to strong coupling regimes, with up to 2000 qubits. To showcase the versatility of the approach, simulations on 2D and 3D Ising models are also made."}
{"id": "2602.10960", "categories": ["q-fin.ST", "cs.CE", "econ.EM", "q-fin.RM", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.10960", "abs": "https://arxiv.org/abs/2602.10960", "authors": ["Ilias Aarab", "Thomas Gottron", "Andrea Colombo", "Jörg Reddig", "Annalauro Ianiro"], "title": "Integrating granular data into a multilayer network: an interbank model of the euro area for systemic risk assessment", "comment": null, "summary": "Micro-structural models of contagion and systemic risk emphasize that shock propagation is inherently multi-channel, spanning counterparty exposures, short-term funding and roll-over risk, securities cross-holdings, and common-asset (fire-sale) spillovers. Empirical implementations, however, often rely on stylized or simulated networks, or focus on a single exposure dimension, reflecting the practical difficulty of reconciling heterogeneous granular collections into a coherent representation with consistent identifiers and consolidation rules. We close part of this gap by constructing an empirically grounded multilayer network for euro area significant banking groups that integrates several supervisory and statistical datasets into layer-consistent exposure matrices defined on a common node set. Each layer corresponds to a distinct transmission channel, long- and short-term credit, securities cross-holdings, short-term secured funding, and overlapping external portfolios, and nodes are enriched with balance-sheet information to support model calibration. We document pronounced cross-layer heterogeneity in connectivity and centrality, and show that an aggregated (flattened) representation can mask economically relevant structure and misidentify the institutions that are systemically important in specific markets. We then illustrate how the resulting network disciplines standard systemic-risk analytics by implementing a centrality-based propagation measure and a micro-structural agent-based framework on real exposures. The approach provides a data-grounded basis for layer-aware systemic-risk assessment and stress testing across multiple dimensions of the banking network."}
{"id": "2602.10724", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10724", "abs": "https://arxiv.org/abs/2602.10724", "authors": ["Aditya Natu", "Xiaozhe Hu", "Hassan HosseinNia"], "title": "Integrating Active Damping with Shaping-Filtered Reset Tracking Control for Piezo-Actuated Nanopositioning", "comment": null, "summary": "Piezoelectric nanopositioning systems are often limited by lightly damped structural resonances and the gain--phase constraints of linear feedback, which restrict achievable bandwidth and tracking performance. This paper presents a dual-loop architecture that combines an inner-loop non-minimum-phase resonant controller (NRC) for active damping with an outer-loop tracking controller augmented by a constant-gain, lead-in-phase (CgLp) reset element to provide phase lead at the targeted crossover without increasing loop gain. We show that aggressively tuned CgLp designs with larger phase lead can introduce pronounced higher-order harmonics, degrading error sensitivity in specific frequency bands and causing multiple-reset behavior. To address this, a shaping filter is introduced in the reset-trigger path to regulate the reset action and suppress harmonic-induced effects while preserving the desired crossover-phase recovery. The proposed controllers are implemented in real time on an industrial piezo nanopositioner, demonstrating an experimental open-loop crossover increase of approximately 55~Hz and a closed-loop bandwidth improvement of about 34~Hz relative to a well-tuned linear baseline."}
{"id": "2602.10724", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10724", "abs": "https://arxiv.org/abs/2602.10724", "authors": ["Aditya Natu", "Xiaozhe Hu", "Hassan HosseinNia"], "title": "Integrating Active Damping with Shaping-Filtered Reset Tracking Control for Piezo-Actuated Nanopositioning", "comment": null, "summary": "Piezoelectric nanopositioning systems are often limited by lightly damped structural resonances and the gain--phase constraints of linear feedback, which restrict achievable bandwidth and tracking performance. This paper presents a dual-loop architecture that combines an inner-loop non-minimum-phase resonant controller (NRC) for active damping with an outer-loop tracking controller augmented by a constant-gain, lead-in-phase (CgLp) reset element to provide phase lead at the targeted crossover without increasing loop gain. We show that aggressively tuned CgLp designs with larger phase lead can introduce pronounced higher-order harmonics, degrading error sensitivity in specific frequency bands and causing multiple-reset behavior. To address this, a shaping filter is introduced in the reset-trigger path to regulate the reset action and suppress harmonic-induced effects while preserving the desired crossover-phase recovery. The proposed controllers are implemented in real time on an industrial piezo nanopositioner, demonstrating an experimental open-loop crossover increase of approximately 55~Hz and a closed-loop bandwidth improvement of about 34~Hz relative to a well-tuned linear baseline."}
{"id": "2602.10234", "categories": ["physics.soc-ph", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.10234", "abs": "https://arxiv.org/abs/2602.10234", "authors": ["Zhengbing He"], "title": "Transforming Policy-Car Swerving for Mitigating Stop-and-Go Traffic Waves: A Practice-Oriented Jam-Absorption Driving Strategy", "comment": null, "summary": "Stop-and-go waves, as a major form of freeway traffic congestion, cause severe and long-lasting adverse effects, including reduced traffic efficiency, increased driving risks, and higher vehicle emissions. Amongst the highway traffic management strategies, jam-absorption driving (JAD), in which a dedicated vehicle performs \"slow-in\" and \"fast-out\" maneuvers before being captured by a stop-and-go wave, has been proposed as a potential method for preventing the propagation of such waves. However, most existing JAD strategies remain impractical mainly due to the lack of discussion regarding implementation vehicles and operational conditions. Inspired by real-world observations of police-car swerving behavior, this paper first introduces a Single-Vehicle Two-Detector Jam-Absorption Driving (SVDD-JAD) problem, and then proposes a practical JAD strategy that transforms such behavior into a maneuver capable of suppressing the propagation of an isolated stop-and-go wave. Five key parameters that significantly affect the proposed strategy, namely, JAD speed, inflow traffic speed, wave width, wave speed, and in-wave speed, are identified and systematically analyzed. Using a SUMO-based simulation as an illustrative example, we further demonstrate how these parameters can be measured in practice with two stationary roadside traffic detectors. The results show that the proposed JAD strategy successfully suppresses the propagation of a stop-and-go wave, without triggering a secondary wave. This paper is expected to take a significant step toward making JAD practical, advancing it from a theoretical concept to a feasible and implementable strategy. To promote reproducibility in the transportation domain, we have also open-sourced all the code on our GitHub repository https://github.com/gotrafficgo."}
{"id": "2602.10484", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.10484", "abs": "https://arxiv.org/abs/2602.10484", "authors": ["Zhaowen Wang", "Yutao Liu", "Deyuan Li"], "title": "CoVaR under Asymptotic Independence", "comment": null, "summary": "Conditional value-at-risk (CoVaR) is one of the most important measures of systemic risk. It is defined as the high quantile conditional on a related variable being extreme, widely used in the field of quantitative risk management. In this work, we develop a semi-parametric methodology to estimate CoVaR for asymptotically independent pairs within the framework of bivariate extreme value theory. We use parametric modelling of the bivariate extremal structure to address data sparsity in the joint tail regions and prove consistency and asymptotic normality of the proposed estimator. The robust performance of the estimator is illustrated via simulation studies. Its application to the US stock returns data produces insightful dynamic CoVaR forecasts."}
{"id": "2602.10131", "categories": ["cs.SI", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.10131", "abs": "https://arxiv.org/abs/2602.10131", "authors": ["David Holtz"], "title": "The Anatomy of the Moltbook Social Graph", "comment": "20 pages, 7 figures", "summary": "I present a descriptive analysis of Moltbook, a social platform populated exclusively by AI agents, using data from the platform's first 3.5 days (6{,}159 agents; 13{,}875 posts; 115{,}031 comments). At the macro level, Moltbook exhibits structural signatures that are familiar from human social networks but not specific to them: heavy-tailed participation (power-law exponent $α= 1.70$) and small-world connectivity (average path length $=2.91$). At the micro level, patterns appear distinctly non-human. Conversations are extremely shallow (mean depth $=1.07$; 93.5\\% of comments receive no replies), reciprocity is low (0.197), and 34.1\\% of messages are exact duplicates of viral templates. Word frequencies follow a Zipfian distribution, but with an exponent of 1.70 -- notably steeper than typical English text ($\\approx 1.0$), suggesting more formulaic content. Agent discourse is dominated by identity-related language (68.1\\% of unique messages) and distinctive phrasings like ``my human'' (9.4\\% of messages) that have no parallel in human social media. Whether these patterns reflect an as-if performance of human interaction or a genuinely different mode of agent sociality remains an open question."}
{"id": "2602.10276", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.10276", "abs": "https://arxiv.org/abs/2602.10276", "authors": ["S. Liu", "A. Datta", "A. C. Barato"], "title": "Cyclic active refrigerators", "comment": "19 pages, 5 figures", "summary": "Thermodynamic cycles are idealized processes that can convert heat into work or produce heat flow against a temperature gradient with the input of work. They remain an active area of research in modern stochastic thermodynamics. In particular, cyclic active heat engines have been shown to display a rich phenomenology, such as ``violations'' of the Carnot bound on efficiency and an improved performance in comparison to their passive counterparts. We introduce the concept of cyclic active refrigerators using a previously derived second law for cyclic active systems. We show that for cyclic active refrigerators, a naive definition of the coefficient of performance can exceed the bound set by the standard second law for passive refrigerators. We also show that cyclic active systems can behave like a Maxwell's demon, with heat flowing from the cold to the hot reservoir without any work input. Beyond this phase, cyclic active systems can enter a hybrid phase, functioning as both a heat engine and a refrigerator simultaneously. Our results are obtained with two models that involve active Brownian particles, a simpler one that allows for analytical results and a more realistic one that is analyzed through numerical simulations."}
{"id": "2602.10268", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10268", "abs": "https://arxiv.org/abs/2602.10268", "authors": ["Haifeng Wang", "Xiaoming Wang", "Min Zhang"], "title": "Unconditionally Long-Time Stable Variable-Step Second-Order Exponential Time-Differencing Schemes for the Incompressible NSE", "comment": null, "summary": "We develop an efficient, unconditionally stable, variable step second order exponential time differencing scheme for the incompressible Navier Stokes equations in two and three spatial dimensions under periodic boundary conditions, together with an embedded adaptive time stepping variant. The scheme is unconditionally uniform in time stable in the sense that the numerical solution admits a time uniform bound in Linfinity over time with values in L2 to the power d whenever the external forcing term is uniformly bounded in time in L2, for all Reynolds numbers and for arbitrary choices of time step sizes.\n  At each time step, the method requires the solution of two time dependent Stokes problems, which can be evaluated explicitly in the periodic setting using Fourier techniques, along with the solution of a single scalar cubic algebraic equation. Beyond the standard exponential time differencing framework, the proposed scheme incorporates two recently developed ingredients. The first is a dynamic second order scalar auxiliary variable correction, which is essential for achieving second order temporal accuracy. The second is a mean reverting scalar auxiliary variable multistep formulation, which plays a central role in ensuring long time stability.\n  The proposed methods overcome key limitations of existing approaches for the Navier Stokes equations. Classical Runge Kutta schemes generally lack provable long time stability, while IMEX and scalar auxiliary variable based BDF methods typically do not admit unconditional stability guarantees in the variable step setting. Numerical experiments in two spatial dimensions confirm second order temporal accuracy, uniform long time stability, and effective error control provided by the adaptive strategy. Rigorous convergence analysis and a systematic investigation of long time statistical properties will be pursued in future work."}
{"id": "2602.10464", "categories": ["math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.10464", "abs": "https://arxiv.org/abs/2602.10464", "authors": ["Shirong Xu", "Will Wei Sun"], "title": "Do More Predictions Improve Statistical Inference? Filtered Prediction-Powered Inference", "comment": null, "summary": "Recent advances in artificial intelligence have enabled the generation of large-scale, low-cost predictions with increasingly high fidelity. As a result, the primary challenge in statistical inference has shifted from data scarcity to data reliability. Prediction-powered inference methods seek to exploit such predictions to improve efficiency when labeled data are limited. However, existing approaches implicitly adopt a use-all philosophy, under which incorporating more predictions is presumed to improve inference. When prediction quality is heterogeneous, this assumption can fail, and indiscriminate use of unlabeled data may dilute informative signals and degrade inferential accuracy. In this paper, we propose Filtered Prediction-Powered Inference (FPPI), a framework that selectively incorporates predictions by identifying a data-adaptive filtered region in which predictions are informative for inference. We show that this region can be consistently estimated under a margin condition, achieving fast rates of convergence. By restricting the prediction-powered correction to the estimated filtered region, FPPI adaptively mitigates the impact of biased or noisy predictions. We establish that FPPI attains strictly improved asymptotic efficiency compared with existing prediction-powered inference methods. Numerical studies and a real-data application to large language model evaluation demonstrate that FPPI substantially reduces reliance on expensive labels by selectively leveraging reliable predictions, yielding accurate inference even in the presence of heterogeneous prediction quality."}
{"id": "2602.10533", "categories": ["nlin.AO"], "pdf": "https://arxiv.org/pdf/2602.10533", "abs": "https://arxiv.org/abs/2602.10533", "authors": ["Tianjing Zhou", "Nariya Uchida"], "title": "Defect states as a precursor of the chimera states in a ring of non-locally coupled oscillators", "comment": "6 pages, 7 figures", "summary": "We investigate the transition from synchronized to chimera states in a ring of non-locally coupled phase oscillators. Our focus is on the intermediate defect states, where solitary waves in the phase gradient profile travel at a constant speed. These traveling defects serve as a dynamical precursor for the nucleation of chimera clusters. The fraction of samples exhibiting defect states increases with the phase delay $α$ and peaks at $α_{c}$, where the system crosses over to asynchronous states filled with chimera clusters. While the traveling speed, number, and width of these defects increase with $α$, the total spatial extent of the defects remains robust against the system size $N$. These results shed new light on the emergence of chimera states in frustrated coupled oscillators."}
{"id": "2602.10752", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10752", "abs": "https://arxiv.org/abs/2602.10752", "authors": ["Mischa Huisman", "Thomas Arnold", "Erjen Lefeber", "Nathan van de Wouw", "Carlos Murguia"], "title": "Improving CACC Robustness to Parametric Uncertainty via Plant Equivalent Controller Realizations", "comment": "Submitted to the IEEE International Conference on Intelligent Transportation Systems 2026 -Naples, Italy", "summary": "Cooperative Adaptive Cruise Control (CACC) enables vehicle platooning through inter-vehicle communication, improving traffic efficiency and safety. Conventional CACC relies on feedback linearization, assuming exact vehicle parameters; however, longitudinal vehicle dynamics are nonlinear and subject to parametric uncertainty. Applying feedback linearization with a nominal model yields imperfect cancellation, leading to model mismatch and degraded performance with off-the-shelf CACC controllers. To improve robustness without redesigning the CACC law, we explicitly model the mismatch between the ideal closed-loop dynamics assumed by the CACC design and the actual dynamics under parametric uncertainties. Robustness is formulated as an $\\mathcal{L}_2$ trajectory-matching problem, minimizing the energy of this mismatch to make the uncertain system behave as closely as possible to the ideal model. This objective is addressed by optimizing over plant equivalent controller (PEC) realizations that preserve the nominal closed-loop behavior while mitigating the effects of parametric uncertainty. Stability and performance are enforced via linear matrix inequalities, yielding a convex optimization problem applicable to heterogeneous platoons. Experimental results demonstrate improved robustness and performance under parametric uncertainty while preserving nominal CACC behavior."}
{"id": "2602.10752", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10752", "abs": "https://arxiv.org/abs/2602.10752", "authors": ["Mischa Huisman", "Thomas Arnold", "Erjen Lefeber", "Nathan van de Wouw", "Carlos Murguia"], "title": "Improving CACC Robustness to Parametric Uncertainty via Plant Equivalent Controller Realizations", "comment": "Submitted to the IEEE International Conference on Intelligent Transportation Systems 2026 -Naples, Italy", "summary": "Cooperative Adaptive Cruise Control (CACC) enables vehicle platooning through inter-vehicle communication, improving traffic efficiency and safety. Conventional CACC relies on feedback linearization, assuming exact vehicle parameters; however, longitudinal vehicle dynamics are nonlinear and subject to parametric uncertainty. Applying feedback linearization with a nominal model yields imperfect cancellation, leading to model mismatch and degraded performance with off-the-shelf CACC controllers. To improve robustness without redesigning the CACC law, we explicitly model the mismatch between the ideal closed-loop dynamics assumed by the CACC design and the actual dynamics under parametric uncertainties. Robustness is formulated as an $\\mathcal{L}_2$ trajectory-matching problem, minimizing the energy of this mismatch to make the uncertain system behave as closely as possible to the ideal model. This objective is addressed by optimizing over plant equivalent controller (PEC) realizations that preserve the nominal closed-loop behavior while mitigating the effects of parametric uncertainty. Stability and performance are enforced via linear matrix inequalities, yielding a convex optimization problem applicable to heterogeneous platoons. Experimental results demonstrate improved robustness and performance under parametric uncertainty while preserving nominal CACC behavior."}
{"id": "2602.10255", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.10255", "abs": "https://arxiv.org/abs/2602.10255", "authors": ["Yael Kfir-Cohen", "Dana Ben Porath", "Bnaya Gross", "Sergey Buldyrev", "Shlomo Havlin"], "title": "Two phase transitions in modular multiplex networks", "comment": "6 pages, 6 figures", "summary": "Modular networks, such as critical infrastructures, are often built from distinct, densely connected modules (e.g., cities) that are sparsely interconnected. When such networks are gradually and randomly disrupted under a percolation process, they undergo two critical phase transitions. The first transition occurs when modules become isolated from one another, while the second corresponds to the collapse of the entire network, including the internal connectivity of the modules. Here, we study these phase transitions in modular multiplex networks and compare them with those observed in single-layer modular networks. We focus on models in which the modules are arranged and connected either as a Random Regular network or as a two-dimensional square lattice. We show here that these systems exhibit diverse transition behaviors, with some transitions occurring continuously and others abruptly; notably, one realistic model could display two distinct first-order transitions in the same system. For the modular Random Regular multiplex, we further characterize the spatial transition through its scaling behavior, revealing signatures of a mixed-order phase transitions. In addition, we analytically determine the critical threshold at which modules become disconnected. Our results highlight the crucial role of modular organization and the critical role of interdependence in shaping network vulnerabilities under failures."}
{"id": "2602.10673", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.10673", "abs": "https://arxiv.org/abs/2602.10673", "authors": ["Barbara Bricout", "Laura Dami", "Pierre Defos du Rau", "Sophie Donnet", "Thomas Galewski", "Stephane Robin"], "title": "Inferring the presence and abundance of rare waterbirds species from scarce data", "comment": "31 pages, 9 figures", "summary": "Abundance data are used in ecology for species monitoring and conservation. These count data often display several specific characteristics like numerous missing data, high variance, and a high proportion of zeros, particularly when monitoring rare species. We present a model that aims to impute missing data and estimate the effect of covariates on species presence and abundance. It is based on the log-normal Poisson model, which offers more flexibility in the variance of counts than a Poisson model. A latent variable is added for the overrepresentation of zeros in the data. The imputation of missing data is made possible by assuming that the latent variance matrix has low rank and the inclusion of covariates. \\\\ We demonstrate the identifiability in the presence of missing data. Since maximum likelihood inference is intractable, we use a variational expectation-maximization algorithm to infer the parameters. We provide an estimate of the asymptotic variance of the estimators and derive prediction intervals for the imputations, an estimate of the temporal trend, and a procedure for detecting a potential change in this trend. \\\\ We evaluate our imputations and associated prediction intervals using artificially degraded monitoring data set. We conclude with an illustration on a monitoring waterbirds data set."}
{"id": "2602.10459", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.10459", "abs": "https://arxiv.org/abs/2602.10459", "authors": ["Song Kim", "Hyewon Kim", "Kaiqiang Yu", "Taejoon Han", "Junghoon Kim", "Susik Yoon", "Jungeun Kim"], "title": "Efficient Computation of Maximum Flexi-Clique in Networks", "comment": null, "summary": "Discovering large cohesive subgraphs is a key task for graph mining. Existing models, such as clique, k-plex, and γ-quasi-clique, use fixed density thresholds that overlook the natural decay of connectivity as the subgraph size increases. The Flexi-clique model overcomes this limitation by imposing a degree constraint that grows sub-linearly with subgraph size. We provide the algorithmic study of Flexi-clique, proving its NP-hardness and analysing its non-hereditary properties. To address its computational challenge, we propose the Flexi-Prune Algorithm FPA, a fast heuristic using core-based seeding and connectivity-aware pruning, and the Efficient Branch-and-Bound Algorithm EBA, an exact framework enhanced with multiple pruning rules. Experiments on large real-world and synthetic networks demonstrate that FPA achieves near-optimal quality at much lower cost, while EBA efficiently computes exact solutions. Flexi-clique thus provides a practical and scalable model for discovering large, meaningful subgraphs in complex networks."}
{"id": "2602.10571", "categories": ["cond-mat.stat-mech", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2602.10571", "abs": "https://arxiv.org/abs/2602.10571", "authors": ["Gunn Kim"], "title": "Thermodynamic Optimization of Sensory Adaptation via Game-Theoretic Path Integrals", "comment": "5 pages, 4 figures.Submitted for publication", "summary": "Biological sensory systems, from \\textit{E.~coli} chemotaxis to sensory neurons in \\textit{C.~elegans}, achieve reliable adaptation over wide dynamic ranges despite operating in strongly noisy and overdamped regimes. Here, we present a field-theoretic framework in which sensory adaptation emerges from a variational free-energy principle, formulated as a stochastic differential game between an organism and its environment. Using an Onsager--Machlup path-integral formalism, we show that the resulting adaptive dynamics are mathematically equivalent to a class of model reference adaptive control schemes and can be interpreted as a dynamic renormalization of the system's Green's function. Within this framework, the phasic overshoot commonly observed in sensory responses arises naturally from an effective inertia ($m^* \\approx τγ$) generated by memory-dissipation coupling, rather than from biochemical fine-tuning. Quantitative fits to experimental data across species yield $R^2 > 0.88$, and indicate that adaptive sensory processing operates within a narrow thermodynamically optimal regime bounded by signal-to-noise and stability constraints."}
{"id": "2602.10277", "categories": ["math.NA", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.10277", "abs": "https://arxiv.org/abs/2602.10277", "authors": ["Randy Bartels", "Olivier Pinaud"], "title": "Blind source separation for imaging", "comment": null, "summary": "This work is concerned with the problem of blind source separation and its applications to imaging. We first establish a theoretical result that we stated in our previous article on imaging in diffusive environments. This result is a generalization of separability criteria found in the literature to arbitrary correlated complex-valued sources with additive noise. In a second step, we verify these separability conditions in two propagation regimes frequently encountered in imaging: the speckle regime and the random geometrical optics regime. Finally, we propose a new imaging method based on the blind source separation problem that improves on images obtained with the classical decomposition of the time reversal operator method."}
{"id": "2602.10566", "categories": ["math.ST", "math.CO", "math.RA", "math.SP"], "pdf": "https://arxiv.org/pdf/2602.10566", "abs": "https://arxiv.org/abs/2602.10566", "authors": ["Chandrasekhar Gokavarapu", "Sekhar Babu Gosala", "Vamis Pasalapudi", "Tarakarama Kapakayala"], "title": "Finite-sample confidence regions for spectral clustering and graph centrality", "comment": null, "summary": "Let a graph be observed through a finite random sampling mechanism. Spectral methods are routinely applied to such graphs, yet their outputs are treated as deterministic objects. This paper develops finite-sample inference for spectral graph procedures.\n  The primary result constructs explicit confidence regions for latent eigenspaces of graph operators under an explicit sampling model. These regions propagate to confidence regions for spectral clustering assignments and for smooth graph centrality functionals. All bounds are nonasymptotic and depend explicitly on the sample size, noise level, and spectral gap.\n  The analysis isolates a failure of common practice: asymptotic perturbation arguments are often invoked without a finite-sample spectral gap, leading to invalid uncertainty claims. Under verifiable gap and concentration conditions, the present framework yields coverage guarantees and certified stability regions. Several corollaries address fairness-constrained post-processing and topological summaries derived from spectral embeddings."}
{"id": "2602.10342", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.10342", "abs": "https://arxiv.org/abs/2602.10342", "authors": ["Stephanie Caro", "Rafael Correa", "Abderrahim Hantoute"], "title": "Normal cones to sublevel sets of convex and quasi-convex supremum functions", "comment": null, "summary": "We provide sharp and explicit characterizations of the normal cone to sublevel sets of suprema of arbitrary functions, expressed exclusively in terms of subdifferentials of the data functions. In the convex case, the resulting formulas involve the approximate subdifferential of the individual data functions at the nominal point. In contrast, the quasi-convex framework requires the use of the Fréchet subdifferential of these data functions but evaluated at nearby points. These results are applied to derive optimality conditions for infinite convex and quasi-convex optimization problems."}
{"id": "2602.10835", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10835", "abs": "https://arxiv.org/abs/2602.10835", "authors": ["Giorgia Disarò", "Maria Elena Valcher"], "title": "Reference Output Tracking in Boolean Control Networks", "comment": null, "summary": "In this paper, the problem of tracking a given reference output trajectory is investigated for the class of Boolean control networks, by resorting to their algebraic representation. First, the case of a finite-length reference trajectory is addressed, and the analysis and algorithm first proposed in [17] are extended to be able to deal with arbitrary initial conditions and to identify all possible solutions. The approach developed for the finite-length case is then adjusted to cope with periodic reference output trajectories. The results of the paper are illustrated through an example."}
{"id": "2602.10835", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10835", "abs": "https://arxiv.org/abs/2602.10835", "authors": ["Giorgia Disarò", "Maria Elena Valcher"], "title": "Reference Output Tracking in Boolean Control Networks", "comment": null, "summary": "In this paper, the problem of tracking a given reference output trajectory is investigated for the class of Boolean control networks, by resorting to their algebraic representation. First, the case of a finite-length reference trajectory is addressed, and the analysis and algorithm first proposed in [17] are extended to be able to deal with arbitrary initial conditions and to identify all possible solutions. The approach developed for the finite-length case is then adjusted to cope with periodic reference output trajectories. The results of the paper are illustrated through an example."}
{"id": "2602.10405", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.10405", "abs": "https://arxiv.org/abs/2602.10405", "authors": ["Moxin Li", "Yifang Ma", "Yang Wang", "Dashun Wang"], "title": "Pivoting as an Adaptive Strategy to Geopolitical Tensions in U.S. Science", "comment": "20 pages, 4 figures", "summary": "Geopolitical tensions increasingly reshape the structure and openness of global science, yet we still lack a clear understanding of how successfully scientists adapt their work under such pressures. Using millions of funding and publication datasets across the past ten years, we investigate how U.S. China geopolitical tensions reshaped individual research activities of U.S. based scientists, particularly those collaborating with Chinese peers. We find that although U.S. China geopolitical tensions significantly reduce funding opportunities, many scientists actively respond by pivoting their research portfolios toward alternative topics, and this adaptive reorientation partially mitigates funding losses. Crucially, the effectiveness of this adaptive strategy is highly unequal: for scientists in high risk domains, those of Asian descent, and early-career scientists, pivoting offers only limited protection against funding loss. Our results demonstrate that geopolitical tensions reshape science through shifts in scientists' strategic decisions about their research focus. Understanding this adaptive but uneven reconfiguration is essential for science policies to strengthen the resilience and inclusiveness of the scientific enterprise."}
{"id": "2602.10730", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.10730", "abs": "https://arxiv.org/abs/2602.10730", "authors": ["Hilde Vinje", "Lars Erik Gangsei"], "title": "A closed form solution for Bayesian analysis of a simple linear mixed model", "comment": null, "summary": "Linear mixed-effects models are a central analytical tool for modeling hierarchical and longitudinal data, as they allow simultaneous representation of fixed and random sources of variation. In practice, inference for such models is most often based on likelihood-based approximations, which are computationally efficient, but rely on numerical integration and may be unreliable example wise in small-sample settings. In this study, the somewhat obscure four-parameter generalized beta density is shown to be usable as a conjugate prior distribution for a simple linear mixed model. This leads to a closed-form Bayesian solution for a balanced mixed-model design, representing a methodological development beyond standard approximate or simulation-based Bayesian approaches. Although the derivation is restricted to a balanced setting, the proposed framework suggests a pathway toward analytically tractable Bayesian inference for more complex mixed-model structures. The method is evaluated through comparison with a standard frequentist solution based on likelihood estimation for linear mixed-effects models. Results indicate that the Bayesian approach performs just as well as the frequentist alternative, while yielding slightly reduced mean squared error. The study further discusses the use of empirical Bayes strategies for hyperparameter specification and outlines potential directions for extending the approach beyond the balanced case."}
{"id": "2602.10600", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.10600", "abs": "https://arxiv.org/abs/2602.10600", "authors": ["Salman Shabbir", "Dezső Boda", "Zoltán Ható"], "title": "Interplay of ion availability and mobility in the loss of cation selectivity for CaCl\\textsubscript{2} in negatively charged nanopores: molecular dynamics using scaled-charge models", "comment": "submitted to J. Chem. Phys. January 2026", "summary": "Ion transport through charged nanopores is commonly interpreted in terms of electrical double layer structure, leading to the expectation of cation-selective conduction in negatively charged pores. This picture can break down for multivalent electrolytes, where strong ion-urface correlations and charge inversion modify transport behavior. Here, we study NaCl and CaCl$_2$ conduction through negatively charged silica nanopores using atomistic molecular dynamics simulations with scaled-charge ion models. By separating concentration and velocity contributions to the radial particle current density, we connect static adsorption to dynamic perm-selectivity. While NaCl exhibits conventional cation selectivity, CaCl$_2$ shows nearly bulk-like or even anion-favored transport due to Ca$^{2+}$ immobilization near the surface and dominant Cl$^-$ conduction in the pore interior following charge inversion. Although this qualitative mechanism is robust, its detailed manifestation depends sensitively on the balance of ion-surface and ion-water interactions encoded in the force field."}
{"id": "2602.10301", "categories": ["math.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2602.10301", "abs": "https://arxiv.org/abs/2602.10301", "authors": ["Alaa Ahmed"], "title": "Impact of Separation Distance on the Performance and Annual Energy Production of a Dual-Flap Oscillating Surge Wave Energy Converter", "comment": null, "summary": "Among the different concepts for wave energy conversion, oscillating surge wave energy converters have been shown to have a high capture width ratio. The primary wave capture structure consists of a flap hinged at the seabed or to a floating platform. Different flap configurations, including single and dual-flap, have been investigated. The separation distance between the oscillating surge wave energy converters can have an impact on their response when deployed in arrays. We consider the case of a dual-flap oscillating surge wave energy converter and investigate the impact of the separation distance between them on the performance of each flap. We estimate the absorbed wave energy and the annual energy production by the two flaps when deployed at the PacWave South site. Inviscid numerical simulations were conducted to predict the response of the oscillating surge wave energy converters. The simulations are validated with experimental measurements of a 1:10 scaled model in a wave tank. The results show that for a short separation distance, the interaction between the oscillating surge wave energy converters has a destructive and constructive effect depending on the wave frequency. However, these effects tend to balance each other out when considering the broad range of wave excitations. For longer separation distances, the interaction always results in a constructive effect. The results reveal that the separation distance has an insignificant impact on annual energy production when considering all wave frequencies and amplitudes."}
{"id": "2602.10760", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.10760", "abs": "https://arxiv.org/abs/2602.10760", "authors": ["Zhang Li-Xin"], "title": "Covariate-Adaptive Randomization in Clinical Trials Without Inflated Variances", "comment": "28 pages", "summary": "Covariate adaptive randomization (CAR) procedures are extensively used to reduce the likelihood of covariate imbalances occurring in clinical trials. In literatures, a lot of CAR procedures have been proposed so that the specified covariates are balanced well between treatments. However, the variance of the imbalance of the unspecified covariates may be inflated comparing to the one under the simple randomization. The inflation of the variance causes the usual test of treatment effects being not valid and adjusting the test being not an easy work. In this paper, we propose a new kind covariate adaptive randomization procedures to balance covariates between two treatments with a ratio $ρ:(1-ρ)$. Under this kind of CAR procedures, the convergence rate of the imbalance of the specified covariates is $o(n^{1/2})$, and at the same time the asymptotic variance of the imbalance of any unspecified (observed or unobserved) covariates does not exceed the one under the simple randomization. The ``shift problem'' found by Liu, Hu, and Ma (2025) will not appear under the new CAR procedures."}
{"id": "2602.10374", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.10374", "abs": "https://arxiv.org/abs/2602.10374", "authors": ["Yiwen Chen"], "title": "Relationships between full-space and subspace quadratic interpolation models and simplex derivatives", "comment": null, "summary": "Quadratic interpolation models and simplex derivatives are fundamental tools in numerical optimization, particularly in derivative-free optimization. When constructed in suitably chosen affine subspaces, these tools have been shown to be especially effective for high-dimensional derivative-free optimization problems, where full-space model construction is often impractical. In this paper, we analyze the relationships between full-space and subspace formulations of these tools. In particular, we derive explicit conversion formulas between full-space and subspace models, including minimum-norm models, minimum Frobenius norm models, least Frobenius norm updating models, as well as models constructed via generalized simplex gradients and Hessians. We show that the full-space and subspace models coincide on the affine subspace and, in general, along directions in the orthogonal complement. Overall, our results provide a theoretical framework for understanding subspace approximation techniques and offer insight into the design and analysis of derivative-free optimization methods."}
{"id": "2602.10855", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10855", "abs": "https://arxiv.org/abs/2602.10855", "authors": ["Henrik Sandberg", "Kamil Hassan", "Heng Wu"], "title": "Singular Port-Hamiltonian Systems Beyond Passivity", "comment": null, "summary": "In this paper, we study a class of port-Hamiltonian systems whose vector fields exhibit singularities. A representative example of this class has recently been employed in the power electronics literature to implement a grid-forming controller. We show that, under certain conditions, these port-Hamiltonian systems, when interconnected with passive systems, converge to a prescribed non-equilibrium steady state. At first glance, the apparently passive nature of the port-Hamiltonian system seems incompatible with the active power injection required to sustain this non-equilibrium condition. However, we demonstrate that the discontinuity inherent in the vector field provides the additional energy needed to maintain this operating point, indicating that the system is not globally passive. Moreover, when the discontinuity is replaced by a continuous approximation, the resulting system becomes cyclo-dissipative while still capable of supplying the required power."}
{"id": "2602.10855", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10855", "abs": "https://arxiv.org/abs/2602.10855", "authors": ["Henrik Sandberg", "Kamil Hassan", "Heng Wu"], "title": "Singular Port-Hamiltonian Systems Beyond Passivity", "comment": null, "summary": "In this paper, we study a class of port-Hamiltonian systems whose vector fields exhibit singularities. A representative example of this class has recently been employed in the power electronics literature to implement a grid-forming controller. We show that, under certain conditions, these port-Hamiltonian systems, when interconnected with passive systems, converge to a prescribed non-equilibrium steady state. At first glance, the apparently passive nature of the port-Hamiltonian system seems incompatible with the active power injection required to sustain this non-equilibrium condition. However, we demonstrate that the discontinuity inherent in the vector field provides the additional energy needed to maintain this operating point, indicating that the system is not globally passive. Moreover, when the discontinuity is replaced by a continuous approximation, the resulting system becomes cyclo-dissipative while still capable of supplying the required power."}
{"id": "2602.10427", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.10427", "abs": "https://arxiv.org/abs/2602.10427", "authors": ["Jeongmin Lee", "Jisung Yoon"], "title": "The selective use of physics knowledge in policy: how interdisciplinary physics bridges subfields and shapes policy influence", "comment": null, "summary": "Scientific knowledge has become central to policymaking as societies face challenges related to technological change, climate risk, and public health. Despite the growing emphasis on evidence-based policy, a systematic understanding of how science is selectively used in policy, specifically which forms of knowledge are preferred and which scientific citations translate into influence, remains limited. We address these questions by constructing a novel dataset that links policy documents from the Overton database with publications from the American Physical Society, enabling an analysis of how physics knowledge enters and circulates in policy discourse. Using subfield classifications, we provide quantitative evidence for a gap between scientific communities and policymakers. First, we find that policy documents draw on broad and interdisciplinary areas of physics, such as General Physics and Interdisciplinary Physics, rather than mirroring the structure of physics research production. Second, we identify substantial institutional heterogeneity with systematic differences in subfield preferences across policy producing organizations and topics. Third, network analysis reveals that interdisciplinary areas of physics act as a central bridge connecting specialized subfields. Finally, regression analysis reveals a clear separation between policy visibility and policy influence. While interdisciplinary areas facilitate entry into policy discourse, it does not necessarily increase downstream policy influence. Conversely, documents citing geophysics are associated with approximately 24 percent higher policy influence, likely driven by the political salience of climate change policy. Our findings underscore the distinction between scientific visibility and policy influence, contributing to a deeper understanding of the complex relationship between scientific communities and policy system."}
{"id": "2602.10924", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.10924", "abs": "https://arxiv.org/abs/2602.10924", "authors": ["James Neill", "Lloyd A. C. Chapman", "Chris Jewell"], "title": "Non-centred Bayesian inference for discrete-valued state-transition models: the Rippler algorithm", "comment": "18 pages, 7 figures (plus supplementary material with an additional 9 pages, 8 figures)", "summary": "Stochastic state-transition models of infectious disease transmission can be used to deduce relevant drivers of transmission when fitted to data using statistically principled methods. Fitting this individual-level data requires inference on individuals' unobserved disease statuses over time, which form a high-dimensional and highly correlated state space. We introduce a novel Bayesian (data-augmentation Markov chain Monte Carlo) algorithm for jointly estimating the model parameters and unobserved disease statuses, which we call the Rippler algorithm. This is a non-centred method that can be applied to any individual-based state-transition model. We compare the Rippler algorithm to the state-of-the-art inference methods for individual-based stochastic epidemic models and find that it performs better than these methods as the number of disease states in the model increases."}
{"id": "2602.10677", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.10677", "abs": "https://arxiv.org/abs/2602.10677", "authors": ["Avanish Kumar", "Itamar Procaccia"], "title": "Analytic Nonlinear Theory of Shear Banding in Amorphous Solids", "comment": "27 pages, 4 figures", "summary": "The aim of this paper is to offer an analytic theory of the shear banding instability in amorphous solids that are subjected to athermal quasi-static shear. To this aim we derive nonlinear equations for the displacement field, including the consequences of plastic deformation on the mechanical response of amorphous solids. The plastic events collectively induce distributed dipoles that are responsible for screening effects and the creation of typical length-scales that are absent in classical elasticity theory. The nonlinear theory exposes an instability that results in the creation of shear bands. By solving the weakly nonlinear amplitude equation we present analytic expressions for the displacement fields that is associated with shear bands, explaining the role of the elastic moduli that determine the width of a shear band from ductile to brittle characteristics. We derive an energy functional whose Hessian possesses an eigenvalue that goes to zero at the shear-banding instability, providing a prediction for the critical value of the accumulated stress that results in an instability."}
{"id": "2602.10424", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10424", "abs": "https://arxiv.org/abs/2602.10424", "authors": ["Zhongxiao Jia", "Xinyuan Wan"], "title": "A Numerical Analysis of Sketched Linear Squares Problems and Stopping Criteria for Iterative Solvers", "comment": "26 pages, 15 figures", "summary": "Randomized subspace embedding methods have had a great impact on the solution of a linear least squares (LS) problem by reducing its row dimension, leading to a randomized or sketched LS (sLS) problem, and use the solution of the sLS problem as an approximate solution of the LS problem. This work makes a numerical analysis on the sLS problem, establishes its numerous theoretical properties, and show their crucial roles on the most effective and efficient use of iterative solvers. We first establish a compact bound on the norm of the residual difference between the solutions of the LS and sLS problems, which is the first key result towards understanding the rationale of the sLS problem. Then from the perspective of backward errors, we prove that the solution of the sLS problem is the one of a certain perturbed LS problem with minimal backward error, and quantify how the embedded quality affects the residuals, solution errors, and the relative residual norms of normal equations of the LS and sLS problems. These theoretical results enable us to propose new novel and reliable general-purpose stopping criteria for iterative solvers for the sLS problem, which dynamically monitor stabilization patterns of iterative solvers for the LS problem itself and terminate them at the earliest iteration. Numerical experiments justify the theoretical bounds and demonstrate that the new stopping criteria work reliably and result in a tremendous reduction in computational cost without sacrificing attainable accuracy."}
{"id": "2602.10774", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.10774", "abs": "https://arxiv.org/abs/2602.10774", "authors": ["Ilaria Nadin", "Tatyana Krivobokova", "Farida Enikeeva"], "title": "Nonparametric two sample test of spectral densities", "comment": null, "summary": "A novel nonparametric test for the equality of the covariance matrices of two Gaussian stationary processes, possibly of different lengths, is proposed. The test translates to testing the equality of two spectral densities and is shown to be minimax rate-optimal. Test performance is validated in a simulation study, and the practical utility is demonstrated in the analysis of real electroencephalography data. The test is implemented in the R-package sdf.test."}
{"id": "2602.10436", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.10436", "abs": "https://arxiv.org/abs/2602.10436", "authors": ["Mateo Díaz", "Pedro Izquierdo Lehmann", "Haihao Lu", "Jinwen Yang"], "title": "Active set identification and rapid convergence for degenerate primal-dual problems", "comment": "45 pages, 8 figures", "summary": "Primal-dual methods for solving convex optimization problems with functional constraints often exhibit a distinct two-stage behavior. Initially, they converge towards a solution at a sublinear rate. Then, after a certain point, the method identifies the set of active constraints and the convergence enters a faster local linear regime. Theory characterizing this phenomenon spans over three decades. However, most existing work only guarantees eventual identification of the active set and relies heavily on nondegeneracy conditions, such as strict complementarity, which often fail to hold in practice. We characterize mild conditions on the problem geometry and the algorithm under which this phenomenon provably occurs. Our guarantees are entirely nonasymptotic and, importantly, do not rely on strict complementarity. Our framework encompasses several widely-used algorithms, including the proximal point method, the primal-dual hybrid gradient method, the alternating direction method of multipliers, and the extragradient method."}
{"id": "2602.10876", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10876", "abs": "https://arxiv.org/abs/2602.10876", "authors": ["Mohamed Camil Belhadjoudja"], "title": "Backstepping Control of PDEs on Domains with Graph-Monotone Boundaries", "comment": "This extended abstract has been submitted to the 2026 Interna-tional Symposium on Mathematical Theory of Networks and Systems(MTNS 2026), to be held in Waterloo, ON, Canada", "summary": "Despite the extensive body of work on backstepping for one-dimensional PDEs, results in higher dimensions remain comparatively limited. Most available methods either exploit particular symmetries of the PDE or address problems posed on parallelepiped domains. To the best of our knowledge, the only approach that enables the design of backstepping controllers on non-parallelepiped regions without symmetry assumptions is the domain extension technique. This method, however, presents several drawbacks. In particular, the control input at each time instant is obtained by simulating a PDE on an extended domain, from which the actual input on the original domain is approximated. By contrast, in the one-dimensional setting, once the time-independent backstepping gain kernel is known, the control input can be computed in closed form as a feedback depending solely on the state at that same instant. Moreover, problems such as output-feedback design or adaptive and robust control do not appear straightforward to address with the domain extension method, at least to the best of our knowledge. These considerations motivate the search, whenever possible, for alternatives that preserve the main advantages of one-dimensional backstepping. A motivating example for the domain extension method is the control of the heat equation on a piano-shaped domain, with actuation applied at the tail of the piano. In this extended abstract, we show through a simple calculation that the domain extension method is not required in this setting. Instead, a strategy akin to that used for parallelepiped domains can be adopted. This result constitutes a first instance of a broader framework for backstepping control of asymmetric PDEs posed on non-parallelepiped regions, which we refer to as domains with graph-monotone boundaries. The general framework is developed in a forthcoming paper."}
{"id": "2602.10876", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.10876", "abs": "https://arxiv.org/abs/2602.10876", "authors": ["Mohamed Camil Belhadjoudja"], "title": "Backstepping Control of PDEs on Domains with Graph-Monotone Boundaries", "comment": "This extended abstract has been submitted to the 2026 Interna-tional Symposium on Mathematical Theory of Networks and Systems(MTNS 2026), to be held in Waterloo, ON, Canada", "summary": "Despite the extensive body of work on backstepping for one-dimensional PDEs, results in higher dimensions remain comparatively limited. Most available methods either exploit particular symmetries of the PDE or address problems posed on parallelepiped domains. To the best of our knowledge, the only approach that enables the design of backstepping controllers on non-parallelepiped regions without symmetry assumptions is the domain extension technique. This method, however, presents several drawbacks. In particular, the control input at each time instant is obtained by simulating a PDE on an extended domain, from which the actual input on the original domain is approximated. By contrast, in the one-dimensional setting, once the time-independent backstepping gain kernel is known, the control input can be computed in closed form as a feedback depending solely on the state at that same instant. Moreover, problems such as output-feedback design or adaptive and robust control do not appear straightforward to address with the domain extension method, at least to the best of our knowledge. These considerations motivate the search, whenever possible, for alternatives that preserve the main advantages of one-dimensional backstepping. A motivating example for the domain extension method is the control of the heat equation on a piano-shaped domain, with actuation applied at the tail of the piano. In this extended abstract, we show through a simple calculation that the domain extension method is not required in this setting. Instead, a strategy akin to that used for parallelepiped domains can be adopted. This result constitutes a first instance of a broader framework for backstepping control of asymmetric PDEs posed on non-parallelepiped regions, which we refer to as domains with graph-monotone boundaries. The general framework is developed in a forthcoming paper."}
{"id": "2602.10817", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.10817", "abs": "https://arxiv.org/abs/2602.10817", "authors": ["Naoki Masuda"], "title": "Detecting and forecasting tipping points from sample variance alone", "comment": "4 figures, 1 table", "summary": "Anticipating tipping points in complex systems is a fundamental challenge across domains. Traditional early warning signals (EWSs) based on critical slowing down, such as increasing sample variance, are widely used, but their ability to reliably indicate imminent bifurcations and forecast their timing remains limited. Here, we introduce TIPMOC (TIpping via Power-law fits and MOdel Comparison), a parametric framework designed to statistically detect the approach of a bifurcation and estimate its future location using only the sample variance. TIPMOC exploits the mathematical property that variance diverges with a characteristic power-law form near codimension-one bifurcations. By sequentially monitoring system variance as a control parameter changes, TIPMOC statistically adjudicates between linear and power-law divergence at each step. When evidence favors power-law divergence, TIPMOC forecasts the impending tipping point and estimates its position; otherwise, it avoids false positives. Through numerical simulations, we demonstrate TIPMOC's robustness and accuracy in both detection and timing prediction across different types of dynamics and bifurcation. TIPMOC shows low false positive rates and performs well even with uneven sampling and colored noise. This method thus enhances the interpretability and practical utility of classical EWSs, serving as both a transparent add-on and a stand-alone statistical tool for forecasting regime shifts in diverse complex systems."}
{"id": "2602.10955", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.10955", "abs": "https://arxiv.org/abs/2602.10955", "authors": ["Garazi Retegui", "María Dolores Ugarte", "Jaione Etxeberria", "Alan E. Gelfand"], "title": "Prior Smoothing for Multivariate Disease Mapping Models", "comment": null, "summary": "To date, we have seen the emergence of a large literature on multivariate disease mapping. That is, incidence of (or mortality from) multiple diseases is recorded at the scale of areal units where incidence (mortality) across the diseases is expected to manifest dependence. The modeling involves a hierarchical structure: a Poisson model for disease counts (conditioning on the rates) at the first stage, and a specification of a function of the rates using spatial random effects at the second stage. These random effects are specified as a prior and introduce spatial smoothing to the rate (or risk) estimates. What we see in the literature is the amount of smoothing induced under a given prior across areal units compared with the observed/empirical risks. Our contribution here extends previous research on smoothing in univariate areal data models. Specifically, for three different choices of multivariate prior, we investigate both within prior smoothing according to hyperparameters and across prior smoothing. Its benefit to the user is to illuminate the expected nature of departure from perfect fit associated with these priors since model performance is not a question of goodness of fit. We propose both theoretical and empirical metrics for our investigation and illustrate with both simulated and real data."}
{"id": "2602.10779", "categories": ["cond-mat.stat-mech", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.10779", "abs": "https://arxiv.org/abs/2602.10779", "authors": ["John Çamkıran", "Fabian Parsch", "Glenn D. Hibbard"], "title": "A statistical theory of structure in many-particle systems with local interactions", "comment": "22 pages, 11 figures", "summary": "A theory of structure is formulated for systems of many structureless classical particles with stable local interactions in Euclidean space. Such systems are shown to have their structure in thermodynamic equilibrium determined exactly by a random field of fine local descriptions and approximately by coarsenings thereof. The degree of order in the local cluster consisting of a particle and its neighbors is identified as a universal source of coarse local descriptions and characterized by expressing the behavior of configurational entropy in local microscopic terms. A local measure of the angular redundancy in neighboring particle positions is found to satisfy this characterization and thereby established as a valid local order quantifier. A precise relationship between order and symmetry is obtained by bounding this quantifier sharply from below by a simple function of the local point group and the largest stabilizer under its action on the set of bond pairs. The marginal distribution of the quantifier is given in closed form for highly coordinated particles with broadly distributed bond angles. Applications are made to the ideal gas, perfect crystal, and simple liquid."}
{"id": "2602.10440", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10440", "abs": "https://arxiv.org/abs/2602.10440", "authors": ["Zhiwei Yang", "Yikan Liu"], "title": "Identifying the source term in a viscoelastic membrane with a Riemann-Liouville time derivative by the partial interior observation", "comment": "16 pages, 2 figures, 3 tables", "summary": "This paper studies an inverse source problem for a viscoelastic membrane, where the material's memory effect is characterized by the Riemann-Liouville fractional derivative. The problem is to recover the unknown source term from the limited interior observation data. We propose an optimal control framework to address this ill-posed inverse problem. The first-order optimality condition leads to a coupled system of forward and backward fractional partial differential equations. A numerical algorithm combining the finite element method and a conjugate gradient iterative scheme is then developed for the reconstruction of the source term. Several numerical examples are provided to demonstrate the effectiveness and robustness of the proposed method."}
{"id": "2602.10989", "categories": ["math.ST", "cs.IT", "cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.10989", "abs": "https://arxiv.org/abs/2602.10989", "authors": ["Yifan Chen", "Eric Vanden-Eijnden"], "title": "Variational Optimality of Föllmer Processes in Generative Diffusions", "comment": null, "summary": "We construct and analyze generative diffusions that transport a point mass to a prescribed target distribution over a finite time horizon using the stochastic interpolant framework. The drift is expressed as a conditional expectation that can be estimated from independent samples without simulating stochastic processes. We show that the diffusion coefficient can be tuned \\emph{a~posteriori} without changing the time-marginal distributions. Among all such tunings, we prove that minimizing the impact of estimation error on the path-space Kullback--Leibler divergence selects, in closed form, a Föllmer process -- a diffusion whose path measure minimizes relative entropy with respect to a reference process determined by the interpolation schedules alone. This yields a new variational characterization of Föllmer processes, complementing classical formulations via Schrödinger bridges and stochastic control. We further establish that, under this optimal diffusion coefficient, the path-space Kullback--Leibler divergence becomes independent of the interpolation schedule, rendering different schedules statistically equivalent in this variational sense."}
{"id": "2602.10452", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10452", "abs": "https://arxiv.org/abs/2602.10452", "authors": ["Zhaoye Pan", "Haozhe Lei", "Fan Zuo", "Zilin Bian", "Tao Li"], "title": "Distributed Online Convex Optimization with Nonseparable Costs and Constraints", "comment": null, "summary": "This paper studies distributed online convex optimization with time-varying coupled constraints, motivated by distributed online control in network systems. Most prior work assumes a separability condition: the global objective and coupled constraint functions are sums of local costs and individual constraints. In contrast, we study a group of agents, networked via a communication graph, that collectively select actions to minimize a sequence of nonseparable global cost functions and to stratify nonseparable long-term constraints based on full-information feedback and intra-agent communication. We propose a distributed online primal-dual belief consensus algorithm, where each agent maintains and updates a local belief of the global collective decisions, which are repeatedly exchanged with neighboring agents. Unlike the previous consensus primal-dual algorithms under separability that ask agents to only communicate their local decisions, our belief-sharing protocol eliminates coupling between the primal consensus disagreement and the dual constraint violation, yielding sublinear regret and cumulative constraint violation (CCV) bounds, both in $O({T}^{1/2})$, where $T$ denotes the time horizon. Such a result breaks the long-standing $O(T^{3/4})$ barrier for CCV and matches the lower bound of online constrained convex optimization, indicating the online learning efficiency at the cost of communication overhead."}
{"id": "2602.10888", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10888", "abs": "https://arxiv.org/abs/2602.10888", "authors": ["Marc Gillioz", "Guillaume Dubuis", "Étienne Voutaz", "Philippe Jacquod"], "title": "Anomaly Detection with Machine Learning Algorithms in Large-Scale Power Grids", "comment": "12 pages, 9 figures", "summary": "We apply several machine learning algorithms to the problem of anomaly detection in operational data for large-scale, high-voltage electric power grids. We observe important differences in the performance of the algorithms. Neural networks typically outperform classical algorithms such as k-nearest neighbors and support vector machines, which we explain by the strong contextual nature of the anomalies. We show that unsupervised learning algorithm work remarkably well and that their predictions are robust against simultaneous, concurring anomalies."}
{"id": "2602.10888", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10888", "abs": "https://arxiv.org/abs/2602.10888", "authors": ["Marc Gillioz", "Guillaume Dubuis", "Étienne Voutaz", "Philippe Jacquod"], "title": "Anomaly Detection with Machine Learning Algorithms in Large-Scale Power Grids", "comment": "12 pages, 9 figures", "summary": "We apply several machine learning algorithms to the problem of anomaly detection in operational data for large-scale, high-voltage electric power grids. We observe important differences in the performance of the algorithms. Neural networks typically outperform classical algorithms such as k-nearest neighbors and support vector machines, which we explain by the strong contextual nature of the anomalies. We show that unsupervised learning algorithm work remarkably well and that their predictions are robust against simultaneous, concurring anomalies."}
{"id": "2602.11037", "categories": ["physics.soc-ph", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.11037", "abs": "https://arxiv.org/abs/2602.11037", "authors": ["Semra Gunduc", "David J. Butts", "Michael S. Murillo"], "title": "Generalized Langevin Models of Linear Agent-Based Systems: Strategic Influence Through Environmental Coupling", "comment": "7 pages, 3 figures", "summary": "Agent-based models typically treat systems in isolation, discarding environmental coupling as either computationally prohibitive or dynamically irrelevant. We demonstrate that this neglect misses essential physics: environmental degrees of freedom create memory effects that fundamentally alter system dynamics. By systematically transforming linear update rules into exact generalized Langevin equations, we show that unobserved environmental agents manifest as memory kernels whose timescales and coupling strengths are determined by the environmental interaction spectrum. Network topology shapes this memory structure in distinct ways: small-world rewiring drives dynamics toward a single dominant relaxation mode, while fragmented environments sustain multiple persistent modes corresponding to isolated subpopulations. We apply this framework to covert influence operations where adversaries manipulate target populations exclusively via environmental intermediaries. The steady-state response admits a random-walk interpretation through hitting probabilities, revealing how zealot opinions diffuse through the environment to shift system agent opinions toward the zealot mean - even when zealots never directly contact targets."}
{"id": "2602.10969", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.10969", "abs": "https://arxiv.org/abs/2602.10969", "authors": ["Anna Guo", "Razieh Nabi"], "title": "Weighting-Based Identification and Estimation in Graphical Models of Missing Data", "comment": null, "summary": "We propose a constructive algorithm for identifying complete data distributions in graphical models of missing data. The complete data distribution is unrestricted, while the missingness mechanism is assumed to factorize according to a conditional directed acyclic graph. Our approach follows an interventionist perspective in which missingness indicators are treated as variables that can be intervened on. A central challenge in this setting is that sequences of interventions on missingness indicators may induce and propagate selection bias, so that identification can fail even when a propensity score is invariant to available interventions. To address this challenge, we introduce a tree-based identification algorithm that explicitly tracks the creation and propagation of selection bias and determines whether it can be avoided through admissible intervention strategies. The resulting tree provides both a diagnostic and a constructive characterization of identifiability under a given missingness mechanism. Building on these results, we develop recursive inverse probability weighting procedures that mirror the intervention logic of the identification algorithm, yielding valid estimating equations for both the missingness mechanism and functionals of the complete data distribution. Simulation studies and a real-data application illustrate the practical performance of the proposed methods. An accompanying R package, flexMissing, implements all proposed procedures."}
{"id": "2602.10805", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.10805", "abs": "https://arxiv.org/abs/2602.10805", "authors": ["R. Jafari", "Alireza Akbari"], "title": "Scaling and Universality at Noise-Affected Non-Equilibrium Spin Correlation Functions", "comment": null, "summary": "We investigate scaling and universality in nonequilibrium spin correlation functions in the presence of uncorrelated noise. In the absence of noise, spin correlation functions exhibit a crossover from monotonic decay at fast sweep velocities to oscillatory behavior at slow sweeps. We show that, under a stochastically driven field, the critical sweep velocity at which the spin correlation functions undergo an abrupt change decreases with increasing noise strength and scales linearly with the square of the noise intensity. Remarkably, when the noise intensity and sweep velocity are comparable, the excitation probability becomes locked to pk = 1/2 over a finite momentum window, signaling the emergence of noise-induced maximally mixed modes. This gives rise to a highly oscillatory region in the dynamical phase diagram, whose threshold sweep velocity increases with noise and likewise exhibits quadratic scaling with the noise strength. Finally, we identify a universal scaling function under which all boundary sweep-velocity curves collapse onto a single universal curve."}
{"id": "2602.10541", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10541", "abs": "https://arxiv.org/abs/2602.10541", "authors": ["Antonin Sulc"], "title": "Solving PDEs in One Shot via Fourier Features with Exact Analytical Derivatives", "comment": "9 pages, 1 figure, ICLR 2026 Workshop on AI and Partial Differential Equations", "summary": "Recent random feature methods for solving partial differential equations (PDEs) reduce computational cost compared to physics-informed neural networks (PINNs) but still rely on iterative optimization or expensive derivative computation. We observe that sinusoidal random Fourier features possess a cyclic derivative structure: the derivative of any order of $\\sin(\\mathbf{W}\\cdot\\mathbf{x}+b)$ is a single sinusoid with a monomial prefactor, computable in $O(1)$ operations. Alternative activations such as $\\tanh$, used in prior one-shot methods like PIELM, lack this property: their higher-order derivatives grow as $O(2^n)$ terms, requiring automatic differentiation for operator assembly. We propose FastLSQ, which combines frozen random Fourier features with analytical operator assembly to solve linear PDEs via a single least-squares call, and extend it to nonlinear PDEs via Newton--Raphson iteration where each linearized step is a FastLSQ solve. On a benchmark of 17 PDEs spanning 1 to 6 dimensions, FastLSQ achieves relative $L^2$ errors of $10^{-7}$ in 0.07\\,s on linear problems, three orders of magnitude more accurate and significantly faster than state-of-the-art iterative PINN solvers, and $10^{-8}$ to $10^{-9}$ on nonlinear problems via Newton iteration in under 9s."}
{"id": "2602.11132", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11132", "abs": "https://arxiv.org/abs/2602.11132", "authors": ["Jyotishka Datta", "Nicholas G. Polson", "Vadim Sokolov", "Daniel Zantedeschi"], "title": "A New Look at Bayesian Testing", "comment": null, "summary": "We develop a unified framework for Bayesian hypothesis testing through the theory of moderate deviations, providing explicit asymptotic expansions for Bayes risk and optimal test statistics. Our analysis reveals that Bayesian test cutoffs operate on the moderate deviation scale $\\sqrt{\\log n/n}$, in sharp contrast to the sample-size-invariant calibrations of classical testing. This fundamental difference explains the Lindley paradox and establishes the risk-theoretic superiority of Bayesian procedures over fixed-$α$ Neyman-Pearson tests. We extend the seminal Rubin (1965) program to contemporary settings including high-dimensional sparse inference, goodness-of-fit testing, and model selection. The framework unifies several classical results: Jeffreys' $\\sqrt{\\log n}$ threshold, the BIC penalty $(d/2)\\log n$, and the Chernoff-Stein error exponents all emerge naturally from moderate deviation analysis of Bayes risk. Our results provide theoretical foundations for adaptive significance levels and connect Bayesian testing to information theory through gambling-based interpretations."}
{"id": "2602.10461", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.10461", "abs": "https://arxiv.org/abs/2602.10461", "authors": ["Christian Pehle", "Jean-Jacques Slotine"], "title": "Unlocked Backpropagation using Wave Scattering", "comment": "8 pages", "summary": "Both the backpropagation algorithm in machine learning and the maximum principle in optimal control theory are posed as a two-point boundary problem, resulting in a \"forward-backward\" lock. We derive a reformulation of the maximum principle in optimal control theory as a hyperbolic initial value problem by introducing an additional \"optimization time\" dimension. We introduce counter-propagating wave variables with finite propagation speed and recast the optimization problem in terms of scattering relationships between them. This relaxation of the original problem can be interpreted as a physical system that equilibrates and changes its physical properties in order to minimize reflections. We discretize this continuum theory to derive a family of fully unlocked algorithms suitable for training neural networks. Different parameter dynamics, including gradient descent, can be derived by demanding dissipation and minimization of reflections at parameter ports. These results also imply that any physical substrate that supports the scattering and dissipation of waves can be interpreted as solving an optimization problem."}
{"id": "2602.10936", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.10936", "abs": "https://arxiv.org/abs/2602.10936", "authors": ["Levi D. Reyes Premer", "Arash J. Khabbazi", "Kevin J. Kircher"], "title": "Trajectory-based data-driven predictive control and the state-space predictor", "comment": null, "summary": "We define trajectory predictive control (TPC) as a family of output-feedback indirect data-driven predictive control (DDPC) methods that represent the output trajectory of a discrete-time system as a linear function of the recent input/output history and the planned input trajectory. This paper shows that for different choices of the trajectory predictor, TPC encompasses a wide variety of DDPC methods, including subspace predictive control (SPC), closed-loop SPC, $γ$-DDPC, causal-$γ$-DDPC, transient predictive control, and others. This paper introduces a trajectory predictor that corresponds to a linear state-space model with the recent input/output history as the state. With this state-space predictor, TPC is a special case of linear model predictive control and therefore inherits its mature theory. In numerical experiments, TPC performance approaches the limit of oracle $H_2$-optimal control with perfect knowledge of the underlying system model. For TPC with small training datasets, the state-space predictor outperforms other predictors because it has fewer parameters."}
{"id": "2602.10936", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.10936", "abs": "https://arxiv.org/abs/2602.10936", "authors": ["Levi D. Reyes Premer", "Arash J. Khabbazi", "Kevin J. Kircher"], "title": "Trajectory-based data-driven predictive control and the state-space predictor", "comment": null, "summary": "We define trajectory predictive control (TPC) as a family of output-feedback indirect data-driven predictive control (DDPC) methods that represent the output trajectory of a discrete-time system as a linear function of the recent input/output history and the planned input trajectory. This paper shows that for different choices of the trajectory predictor, TPC encompasses a wide variety of DDPC methods, including subspace predictive control (SPC), closed-loop SPC, $γ$-DDPC, causal-$γ$-DDPC, transient predictive control, and others. This paper introduces a trajectory predictor that corresponds to a linear state-space model with the recent input/output history as the state. With this state-space predictor, TPC is a special case of linear model predictive control and therefore inherits its mature theory. In numerical experiments, TPC performance approaches the limit of oracle $H_2$-optimal control with perfect knowledge of the underlying system model. For TPC with small training datasets, the state-space predictor outperforms other predictors because it has fewer parameters."}
{"id": "2602.11131", "categories": ["physics.soc-ph", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.11131", "abs": "https://arxiv.org/abs/2602.11131", "authors": ["Antti Hippeläinen"], "title": "Formalization and inevitability of the Pareto principle", "comment": "33 pages, 10 figures", "summary": "We formalize and study a generalized form of the Pareto principle or \"20/80-rule\" as a property of bounded cumulative processes. Modeling such processes by non-negative gain densities, we first show that any such process satisfies a generalized Pareto principle of the form \"fraction $p$ of inputs yields fraction $1-p$ of outputs\". To obtain a non-trivial and unique characterization, we define the generalized Pareto principle via the decreasing rearrangement of the gain density function. Within this framework, we analyze both constructed gain densities that exemplify the framework and its imposed restrictions, as well as distribution families commonly encountered in datasets, including power-law, exponential, and normal distributions. Finally, we predict commonly encountered ranges for the generalized Pareto principle and discuss the implications of elevating a structural property into a prescriptive role."}
{"id": "2602.11080", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.11080", "abs": "https://arxiv.org/abs/2602.11080", "authors": ["Hank Flury", "Jan Hannig", "Richard Smith"], "title": "Constrained Fiducial Inference for Gaussian Models", "comment": null, "summary": "We propose a new fiducial Markov Chain Monte Carlo (MCMC) method for fitting parametric Gaussian models. We utilize the Cayley transform to decompose the parametric covariance matrix, which in turn allows us to formulate a general data generating algorithm for Gaussian data. Leveraging constrained generalized fiducial inference, we are able to create the basis of an MCMC algorithm, which can be specified to parametric models with minimal effort. The appeal of this novel approach is the wide class of models which it permits, ease of implementation and the posterior-like fiducial distribution without the need for a prior. We provide background information for the derivation of the relevant fiducial quantities, and a proof that the proposed MCMC algorithm targets the correct fiducial distribution. We need not assume independence nor identical distribution of the data, which makes the method attractive for application to time series and spatial data. Well-performing simulation results of the MA(1) and Matérn models are presented."}
{"id": "2602.10957", "categories": ["cond-mat.stat-mech", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2602.10957", "abs": "https://arxiv.org/abs/2602.10957", "authors": ["Ying-Jen Yang", "Ken A. Dill"], "title": "Fluctuation-Response Design Rules for Nonequilibrium Flows", "comment": null, "summary": "Biological machines like molecular motors and enzymes operate in dynamic cycles representable as stochastic flows on networks. Current stochastic dynamics describes such flows on fixed networks. Here, we develop a scalable approach to network design in which local transition rates can be systematically varied to achieve global dynamical objectives. It is based on the fluctuation-response duality in the recent Caliber Force Theory -- a path-entropy variational formalism for nonequilibria. This approach scales efficiently with network complexity and gives new insights, for example revealing the transition from timing- to branching-dominated fluctuations in a kinesin motor model."}
{"id": "2602.10550", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10550", "abs": "https://arxiv.org/abs/2602.10550", "authors": ["Huangxin Chen", "Yuxiang Chen", "Jisheng Kou", "Shuyu Sun"], "title": "An Energy-Stable, Bound-Preserving and Locally Conservative Numerical Framework for Multicomponent Gas Flow in Poroelastic Media", "comment": null, "summary": "In this paper, we propose a robust and efficient numerical framework for simulating multicomponent gas flow in poroelastic media, with a focus on preserving fundamental thermodynamic principles and ensuring computational reliability. The model captures the complex nonlinear coupling between multicomponent transport and solid deformation, while addressing critical numerical challenges such as mass conservation, energy stability, and molar density boundedness. To achieve this, we develop a stabilized discretization approach that guarantees the preservation of the original energy dissipation law and ensures the boundedness of each gas component's molar density. Furthermore, the proposed method incorporates an adaptive time-stepping strategy that dynamically adjusts the time step size based on the system's dynamics, significantly enhancing computational efficiency without compromising stability or accuracy. For spatial discretization, a mixed finite element method combined with an upwind scheme is employed for the flow and transport equations to ensure local mass conservation, while a discontinuous Galerkin (DG) method is utilized for discretizing the momentum equation of poroelasticity to effectively overcome numerical locking phenomena. Numerical experiments are presented to demonstrate the performance, robustness, and applicability of the method in simulating multicomponent gas flow under various scenarios."}
{"id": "2602.10730", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.10730", "abs": "https://arxiv.org/abs/2602.10730", "authors": ["Hilde Vinje", "Lars Erik Gangsei"], "title": "A closed form solution for Bayesian analysis of a simple linear mixed model", "comment": null, "summary": "Linear mixed-effects models are a central analytical tool for modeling hierarchical and longitudinal data, as they allow simultaneous representation of fixed and random sources of variation. In practice, inference for such models is most often based on likelihood-based approximations, which are computationally efficient, but rely on numerical integration and may be unreliable example wise in small-sample settings. In this study, the somewhat obscure four-parameter generalized beta density is shown to be usable as a conjugate prior distribution for a simple linear mixed model. This leads to a closed-form Bayesian solution for a balanced mixed-model design, representing a methodological development beyond standard approximate or simulation-based Bayesian approaches. Although the derivation is restricted to a balanced setting, the proposed framework suggests a pathway toward analytically tractable Bayesian inference for more complex mixed-model structures. The method is evaluated through comparison with a standard frequentist solution based on likelihood estimation for linear mixed-effects models. Results indicate that the Bayesian approach performs just as well as the frequentist alternative, while yielding slightly reduced mean squared error. The study further discusses the use of empirical Bayes strategies for hyperparameter specification and outlines potential directions for extending the approach beyond the balanced case."}
{"id": "2602.10470", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.10470", "abs": "https://arxiv.org/abs/2602.10470", "authors": ["Ching-pei Lee", "Stephen J. Wright"], "title": "Revisiting Superlinear Convergence of Proximal Newton-Like Methods to Degenerate Solutions", "comment": null, "summary": "We describe inexact proximal Newton-like methods for solving degenerate regularized optimization problems and for the broader problem of\n  finding a zero of a generalized equation that is the sum of a continuous map and a maximal monotone operator. Superlinear convergence for both the distance to the solution set and a certain measure of first-order optimality can be achieved under a Hölderian error bound condition, including for problems in which the continuous map is nonmonotone, with Jacobian singular at the solution and not Lipschitz. Superlinear convergence is attainable even when the Jacobian is merely uniformly continuous, relaxing the standard Lipschitz assumption to its theoretical limit. For convex regularized optimization problems, we introduce a novel globalization strategy that ensures strict objective decrease and avoids the Maratos effect, attaining local $Q$-superlinear convergence without prior knowledge of problem parameters. Unit step size acceptance in our line search strategy does not rely on continuity or even existence of the Hessian of the smooth term in the objective, making the framework compatible with other potential candidates for superlinearly convergent updates."}
{"id": "2602.10963", "categories": ["eess.SY", "cs.RO", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.10963", "abs": "https://arxiv.org/abs/2602.10963", "authors": ["Srishti Siddharth", "Vivek Natarajan", "Ravi N. Banavar"], "title": "Lie Group Variational Integrator for the Geometrically Exact Rod with Circular Cross-Section Incorporating Cross-Sectional Deformation", "comment": "Submitted to: Computers and Mathematics with Applications", "summary": "In this paper, we derive the continuous space-time equations of motion of a three-dimensional geometrically exact rod, or the Cosserat rod, incorporating planar cross-sectional deformation. We then adopt the Lie group variational integrator technique to obtain a discrete model of the rod incorporating both rotational motion and cross-sectional deformation as well. The resulting discrete model possesses several desirable features: it ensures volume conservation of the discrete elements by considering cross-sectional deformation through a local dilatation factor, it demonstrates the beneficial properties associated with the variational integrator technique, such as the preservation of the rotational configuration, and energy conservation with a bounded error. An exhaustive set of numerical results under various initial conditions of the rod demonstrates the efficacy of the model in replicating the physics of the system."}
{"id": "2602.10963", "categories": ["eess.SY", "cs.RO", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.10963", "abs": "https://arxiv.org/abs/2602.10963", "authors": ["Srishti Siddharth", "Vivek Natarajan", "Ravi N. Banavar"], "title": "Lie Group Variational Integrator for the Geometrically Exact Rod with Circular Cross-Section Incorporating Cross-Sectional Deformation", "comment": "Submitted to: Computers and Mathematics with Applications", "summary": "In this paper, we derive the continuous space-time equations of motion of a three-dimensional geometrically exact rod, or the Cosserat rod, incorporating planar cross-sectional deformation. We then adopt the Lie group variational integrator technique to obtain a discrete model of the rod incorporating both rotational motion and cross-sectional deformation as well. The resulting discrete model possesses several desirable features: it ensures volume conservation of the discrete elements by considering cross-sectional deformation through a local dilatation factor, it demonstrates the beneficial properties associated with the variational integrator technique, such as the preservation of the rotational configuration, and energy conservation with a bounded error. An exhaustive set of numerical results under various initial conditions of the rod demonstrates the efficacy of the model in replicating the physics of the system."}
{"id": "2602.11107", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.11107", "abs": "https://arxiv.org/abs/2602.11107", "authors": ["Albert Dorador"], "title": "Renet: Principled and Efficient Relaxation for the Elastic Net via Dynamic Objective Selection", "comment": null, "summary": "We introduce Renet, a principled generalization of the Relaxed Lasso to the Elastic Net family of estimators. While, on the one hand, $\\ell_1$-regularization is a standard tool for variable selection in high-dimensional regimes and, on the other hand, the $\\ell_2$ penalty provides stability and solution uniqueness through strict convexity, the standard Elastic Net nevertheless suffers from shrinkage bias that frequently yields suboptimal prediction accuracy. We propose to address this limitation through a framework called \\textit{relaxation}. Existing relaxation implementations rely on naive linear interpolations of penalized and unpenalized solutions, which ignore the non-linear geometry that characterizes the entire regularization path and risk violating the Karush-Kuhn-Tucker conditions. Renet addresses these limitations by enforcing sign consistency through an adaptive relaxation procedure that dynamically dispatches between convex blending and efficient sub-path refitting. Furthermore, we identify and formalize a unique synergy between relaxation and the ``One-Standard-Error'' rule: relaxation serves as a robust debiasing mechanism, allowing practitioners to leverage the parsimony of the 1-SE rule without the traditional loss in predictive fidelity. Our theoretical framework incorporates automated stability safeguards for ultra-high dimensional regimes and is supported by a comprehensive benchmarking suite across 20 synthetic and real-world datasets, demonstrating that Renet consistently outperforms the standard Elastic Net and provides a more robust alternative to the Adaptive Elastic Net in high-dimensional, low signal-to-noise ratio and high-multicollinearity regimes. By leveraging an adaptive solver backend, Renet delivers these statistical gains while offering a computational profile that remains competitive with state-of-the-art coordinate descent implementations."}
{"id": "2602.11095", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.11095", "abs": "https://arxiv.org/abs/2602.11095", "authors": ["Gabriel Mercado-Vásquez", "Denis Boyer"], "title": "Stochastic synthesis-degradation processes: first-passage properties and connections with resetting", "comment": "6 pages, 3 Figures. (7 pages of Suppl. Mat.)", "summary": "Processes controlled by stochastic synthesis and degradation (SSD) are widespread in biology but their reaction kinetics are not well understood. Using methods borrowed from the theory of resetting processes, we determine the first-passage properties of a collection of independent particles that are synthesized and degraded at constant rates, and follow an arbitrary diffusive process in space. At equal synthesis and degradation rates, the mean reaction time with a target site can be minimized as in stochastic resetting, and a $CV$-criterion is derived. When the degradation rate is held fixed and the synthesis costs are taken into account, an optimal synthesis rate is obtained. In bounded domains, despite particle degradation, SSD improves the mean search time compared to a single non-degrading particle if the synthesis rate exceeds a critical value. The latter obeys a universal relation. We illustrate these findings with Brownian diffusion on the infinite line and in an interval."}
{"id": "2602.10590", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10590", "abs": "https://arxiv.org/abs/2602.10590", "authors": ["Diana Al Zareef", "Ahmad El Hajj", "Antoine Zurek"], "title": "Convergence of a scheme for a two dimensional nonlocal system of transport equations", "comment": null, "summary": "In this paper, we numerically study a two-dimensional system modeling the dynamics of dislocation densities. This system is hyperbolic, but not strictly hyperbolic, and couples two non-local transport equations. It is characterized by weak regularity in both the velocity and the initial data. We propose a semi-explicit finite difference (IMEX) numerical scheme for the discretization of this system, after regularizing the singular velocity using a Fejér kernel. We show that this scheme preserves, at the discrete level, an entropy estimate on the gradient, which then allows us to establish the convergence of the discrete solution to the continuous solution. To our knowledge, this is the first convergence result obtained for this type of system. We conclude with some numerical illustrations highlighting the performance of the proposed scheme."}
{"id": "2602.11080", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.11080", "abs": "https://arxiv.org/abs/2602.11080", "authors": ["Hank Flury", "Jan Hannig", "Richard Smith"], "title": "Constrained Fiducial Inference for Gaussian Models", "comment": null, "summary": "We propose a new fiducial Markov Chain Monte Carlo (MCMC) method for fitting parametric Gaussian models. We utilize the Cayley transform to decompose the parametric covariance matrix, which in turn allows us to formulate a general data generating algorithm for Gaussian data. Leveraging constrained generalized fiducial inference, we are able to create the basis of an MCMC algorithm, which can be specified to parametric models with minimal effort. The appeal of this novel approach is the wide class of models which it permits, ease of implementation and the posterior-like fiducial distribution without the need for a prior. We provide background information for the derivation of the relevant fiducial quantities, and a proof that the proposed MCMC algorithm targets the correct fiducial distribution. We need not assume independence nor identical distribution of the data, which makes the method attractive for application to time series and spatial data. Well-performing simulation results of the MA(1) and Matérn models are presented."}
{"id": "2602.10580", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.10580", "abs": "https://arxiv.org/abs/2602.10580", "authors": ["Quang Dinh Thien Nguyen", "Duc Anh Nguyen", "Hoang Huy Nguyen", "Siva Theja Maguluri"], "title": "Almost Sure Convergence of Nonlinear Stochastic Approximation: An Interplay of Noise and Step Size", "comment": "29 pages, 2 figures", "summary": "We study the almost sure convergence of the Stochastic Approximation algorithm to the fixed point $x^\\star$ of a nonlinear operator under a negative drift condition and a general noise sequence with finite $p$-th moment for some $p > 1$. Classical almost sure convergence results of Stochastic Approximation are mostly analyzed for the square-integrable noise setting, and it is shown that any non-summable but square-summable step size sequence is sufficient to obtain almost sure convergence. However, such a limitation prevents wider algorithmic application. In particular, many applications in Machine Learning and Operations Research admit heavy-tailed noise with infinite variance, rendering such guarantees inapplicable. On the other hand, when a stronger condition on the noise is available, such guarantees on the step size would be too conservative, as practitioners would like to pick a larger step size for a more preferable convergence behavior. To this end, we show that any non-summable but $p$-th power summable step size sequence is sufficient to guarantee almost sure convergence, covering the gap in the literature.\n  Our guarantees are obtained using a universal Lyapunov drift argument. For the regime $p \\in (1, 2)$, we show that using the Lyapunov function $\\norm{x-x^\\star}^p$ and applying a Taylor-like bound suffice. For $p > 2$, such an approach is no longer applicable, and therefore, we introduce a novel iterate projection technique to control the nonlinear terms produced by high-moment bounds and multiplicative noise. We believe our proof techniques and their implications could be of independent interest and pave the way for finite-time analysis of Stochastic Approximation under a general noise condition."}
{"id": "2602.11063", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.11063", "abs": "https://arxiv.org/abs/2602.11063", "authors": ["Fan Jiang", "Xingpeng Li", "Pascal Van Hentenryck"], "title": "Deep Neural Network-Enhanced Frequency-Constrained Optimal Power Flow with Multi-Governor Dynamics", "comment": null, "summary": "To ensure frequency security in power systems, both the rate of change of frequency (RoCoF) and the frequency nadir (FN) must be explicitly accounted for in real-time frequency-constrained optimal power flow (FCOPF). However, accurately modeling sys-tem frequency dynamics through analytical formulations is chal-lenging due to their inherent nonlinearity and complexity. To address this issue, deep neural networks (DNNs) are utilized to capture the nonlinear mapping between system operating condi-tions and key frequency performance metrics. In this paper, a DNN-based frequency prediction model is developed and trained using the high-fidelity time-domain simulation data generated in PSCAD/EMTDC. The trained DNN is subsequently transformed into an equivalent mixed-integer linear programming (MILP) form and embedded into the FCOPF problem as additional con-straints to explicitly enforce frequency security, leading to the proposed DNN-FCOPF formulation. For benchmarking, two alternative models are considered: a conventional optimal power flow without frequency constraints and a linearized FCOPF in-corporating system-level RoCoF and FN constraints. The effec-tiveness of the proposed method is demonstrated by comparing the solutions of these three models through extensive PSCAD/EMTDC time-domain simulations under various loading scenarios."}
{"id": "2602.11063", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.11063", "abs": "https://arxiv.org/abs/2602.11063", "authors": ["Fan Jiang", "Xingpeng Li", "Pascal Van Hentenryck"], "title": "Deep Neural Network-Enhanced Frequency-Constrained Optimal Power Flow with Multi-Governor Dynamics", "comment": null, "summary": "To ensure frequency security in power systems, both the rate of change of frequency (RoCoF) and the frequency nadir (FN) must be explicitly accounted for in real-time frequency-constrained optimal power flow (FCOPF). However, accurately modeling sys-tem frequency dynamics through analytical formulations is chal-lenging due to their inherent nonlinearity and complexity. To address this issue, deep neural networks (DNNs) are utilized to capture the nonlinear mapping between system operating condi-tions and key frequency performance metrics. In this paper, a DNN-based frequency prediction model is developed and trained using the high-fidelity time-domain simulation data generated in PSCAD/EMTDC. The trained DNN is subsequently transformed into an equivalent mixed-integer linear programming (MILP) form and embedded into the FCOPF problem as additional con-straints to explicitly enforce frequency security, leading to the proposed DNN-FCOPF formulation. For benchmarking, two alternative models are considered: a conventional optimal power flow without frequency constraints and a linearized FCOPF in-corporating system-level RoCoF and FN constraints. The effec-tiveness of the proposed method is demonstrated by comparing the solutions of these three models through extensive PSCAD/EMTDC time-domain simulations under various loading scenarios."}
{"id": "2602.11118", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.11118", "abs": "https://arxiv.org/abs/2602.11118", "authors": ["Filippo Salmaso", "Lorenzo Testa", "Francesca Chiaromonte"], "title": "A Doubly Robust Machine Learning Approach for Disentangling Treatment Effect Heterogeneity with Functional Outcomes", "comment": "20 pages, 4 figures", "summary": "Causal inference is paramount for understanding the effects of interventions, yet extracting personalized insights from increasingly complex data remains a significant challenge for modern machine learning. This is the case, in particular, when considering functional outcomes observed over a continuous domain (e.g., time, or space). Estimation of heterogeneous treatment effects, known as CATE, has emerged as a crucial tool for personalized decision-making, but existing meta-learning frameworks are largely limited to scalar outcomes, failing to provide satisfying results in scientific applications that leverage the rich, continuous information encoded in functional data. Here, we introduce FOCaL (Functional Outcome Causal Learning), a novel, doubly robust meta-learner specifically engineered to estimate a functional heterogeneous treatment effect (F-CATE). FOCaL integrates advanced functional regression techniques for both outcome modeling and functional pseudo-outcome reconstruction, thereby enabling the direct and robust estimation of F-CATE. We provide a rigorous theoretical derivation of FOCaL, demonstrate its performance and robustness compared to existing non-robust functional methods through comprehensive simulation studies, and illustrate its practical utility on diverse real-world functional datasets. FOCaL advances the capabilities of machine intelligence to infer nuanced, individualized causal effects from complex data, paving the way for more precise and trustworthy AI systems in personalized medicine, adaptive policy design, and fundamental scientific discovery."}
{"id": "2602.11098", "categories": ["cond-mat.stat-mech", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.11098", "abs": "https://arxiv.org/abs/2602.11098", "authors": ["Daniel Nagel", "Tristan Bereau"], "title": "Data-Efficient Multidimensional Free Energy Estimation via Physics-Informed Score Learning", "comment": "13 pages, 7 figures", "summary": "Many biological processes involve numerous coupled degrees of freedom, yet free-energy estimation is often restricted to one-dimensional profiles to mitigate the high computational cost of multidimensional sampling. In this work, we extend Fokker--Planck Score Learning (FPSL) to efficiently reconstruct two-dimensional free-energy landscapes from non-equilibrium molecular dynamics simulations using different types of collective variables. We show that explicitly modeling orthogonal degrees of freedom reveals insights hidden in one-dimensional projections at negligible computational overhead. Additionally, exploiting symmetries in the underlying landscape enhances reconstruction accuracy, while regularization techniques ensure numerical robustness in sparsely sampled regions. We validate our approach on three distinct systems: the conformational dynamics of alanine dipeptide, as well as coarse-grained and all-atom models of solute permeation through lipid bilayers. We demonstrate that, because FPSL learns a smooth score function rather than histogram-based densities, it overcomes the exponential scaling of grid-based methods, establishing it as a data-efficient and scalable tool for multidimensional free-energy estimation."}
{"id": "2602.10605", "categories": ["math.NA", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.10605", "abs": "https://arxiv.org/abs/2602.10605", "authors": ["Peichen Xie"], "title": "Evaluating Numerical Accuracy in Mixed-Precision Computing by Dual-Delta Testing", "comment": null, "summary": "Mixed-precision computing has become increasingly important in modern high-performance computing and machine learning applications. When implementing custom mixed-precision functions -- such as fused operators, optimized GPU kernels, or quantized inference paths -- it is critical to verify their numerical accuracy. Traditional approaches typically compare the custom implementation against a reference using a single error metric. However, this single-delta approach provides limited insight into whether the observed errors are inherent to the precision level or specific to the implementation. This paper introduces \\textit{Dual-Delta Testing}, a systematic methodology that evaluates two error distributions against a high-precision oracle, enabling rigorous comparison between a custom implementation and a baseline reference. We present the mathematical framework, algorithmic formulation, statistical analysis techniques, and practical examples demonstrating the methodology's effectiveness in evaluating numerical accuracy."}
{"id": "2602.11131", "categories": ["physics.soc-ph", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.11131", "abs": "https://arxiv.org/abs/2602.11131", "authors": ["Antti Hippeläinen"], "title": "Formalization and inevitability of the Pareto principle", "comment": "33 pages, 10 figures", "summary": "We formalize and study a generalized form of the Pareto principle or \"20/80-rule\" as a property of bounded cumulative processes. Modeling such processes by non-negative gain densities, we first show that any such process satisfies a generalized Pareto principle of the form \"fraction $p$ of inputs yields fraction $1-p$ of outputs\". To obtain a non-trivial and unique characterization, we define the generalized Pareto principle via the decreasing rearrangement of the gain density function. Within this framework, we analyze both constructed gain densities that exemplify the framework and its imposed restrictions, as well as distribution families commonly encountered in datasets, including power-law, exponential, and normal distributions. Finally, we predict commonly encountered ranges for the generalized Pareto principle and discuss the implications of elevating a structural property into a prescriptive role."}
{"id": "2602.10697", "categories": ["math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.10697", "abs": "https://arxiv.org/abs/2602.10697", "authors": ["Ferdinand Genans"], "title": "Fast and Large-Scale Unbalanced Optimal Transport via its Semi-Dual and Adaptive Gradient Methods", "comment": null, "summary": "Unbalanced Optimal Transport (UOT) has emerged as a robust relaxation of standard Optimal Transport, particularly effective for handling outliers and mass variations. However, scalable algorithms for UOT, specifically those based on Gradient Descent (SGD), remain largely underexplored. In this work, we address this gap by analyzing the semi-dual formulation of Entropic UOT and demonstrating its suitability for adaptive gradient methods. While the semi-dual is a standard tool for large-scale balanced OT, its geometry in the unbalanced setting appears ill-conditioned under standard analysis. Specifically, worst-case bounds on the marginal penalties using $χ^2$ divergence suggest a condition number scaling with $n/\\varepsilon$, implying poor scalability. In contrast, we show that the local condition number actually scales as $\\mathcal{O}(1/\\varepsilon)$, effectively removing the ill-conditioned dependence on $n$. Exploiting this property, we prove that SGD methods adapt to this local curvature, achieving a convergence rate of $\\mathcal{O}(n/\\varepsilon T)$ in the stochastic and online regimes, making it suitable for large-scale and semi-discrete applications. Finally, for the full batch discrete setting, we derive a nearly tight upper bound on local smoothness depending solely on the gradient. Using it to adapt step sizes, we propose a modified Adaptive Nesterov Accelerated Gradient (ANAG) method on the semi-dual functional and prove that it achieves a local complexity of $\\mathcal{O}(n^2\\sqrt{1/\\varepsilon}\\ln(1/δ))$."}
{"id": "2602.11076", "categories": ["eess.SY", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.11076", "abs": "https://arxiv.org/abs/2602.11076", "authors": ["Kavan Fatehi", "Mostafa Rahmani Ghourtani", "Amir Sonee", "Poonam Yadav", "Alessandra M Russo", "Hamed Ahmadi", "Radu Calinescu"], "title": "Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing", "comment": "This work has been accepted to appear in the IEEE International Conference on Communications (ICC)", "summary": "Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \\emph{Attention-Enhanced Multi-Agent Proximal Policy Optimization (AE-MAPPO)}, which integrates six specialized attention mechanisms into multi-agent slice control and surfaces them as zero-cost, faithful explanations. The framework operates across O-RAN timescales with a three-phase strategy: predictive, reactive, and inter-slice optimization.\n  A URLLC case study shows AE-MAPPO resolves a latency spike in $18$ms, restores latency to $0.98$ms with $99.9999\\%$ reliability, and reduces troubleshooting time by $93\\%$ while maintaining eMBB and mMTC continuity. These results confirm AE-MAPPO's ability to combine SLA compliance with inherent interpretability, enabling trustworthy and real-time automation for 6G RAN slicing."}
{"id": "2602.11076", "categories": ["eess.SY", "cs.AI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.11076", "abs": "https://arxiv.org/abs/2602.11076", "authors": ["Kavan Fatehi", "Mostafa Rahmani Ghourtani", "Amir Sonee", "Poonam Yadav", "Alessandra M Russo", "Hamed Ahmadi", "Radu Calinescu"], "title": "Interpretable Attention-Based Multi-Agent PPO for Latency Spike Resolution in 6G RAN Slicing", "comment": "This work has been accepted to appear in the IEEE International Conference on Communications (ICC)", "summary": "Sixth-generation (6G) radio access networks (RANs) must enforce strict service-level agreements (SLAs) for heterogeneous slices, yet sudden latency spikes remain difficult to diagnose and resolve with conventional deep reinforcement learning (DRL) or explainable RL (XRL). We propose \\emph{Attention-Enhanced Multi-Agent Proximal Policy Optimization (AE-MAPPO)}, which integrates six specialized attention mechanisms into multi-agent slice control and surfaces them as zero-cost, faithful explanations. The framework operates across O-RAN timescales with a three-phase strategy: predictive, reactive, and inter-slice optimization.\n  A URLLC case study shows AE-MAPPO resolves a latency spike in $18$ms, restores latency to $0.98$ms with $99.9999\\%$ reliability, and reduces troubleshooting time by $93\\%$ while maintaining eMBB and mMTC continuity. These results confirm AE-MAPPO's ability to combine SLA compliance with inherent interpretability, enabling trustworthy and real-time automation for 6G RAN slicing."}
{"id": "2602.11132", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.11132", "abs": "https://arxiv.org/abs/2602.11132", "authors": ["Jyotishka Datta", "Nicholas G. Polson", "Vadim Sokolov", "Daniel Zantedeschi"], "title": "A New Look at Bayesian Testing", "comment": null, "summary": "We develop a unified framework for Bayesian hypothesis testing through the theory of moderate deviations, providing explicit asymptotic expansions for Bayes risk and optimal test statistics. Our analysis reveals that Bayesian test cutoffs operate on the moderate deviation scale $\\sqrt{\\log n/n}$, in sharp contrast to the sample-size-invariant calibrations of classical testing. This fundamental difference explains the Lindley paradox and establishes the risk-theoretic superiority of Bayesian procedures over fixed-$α$ Neyman-Pearson tests. We extend the seminal Rubin (1965) program to contemporary settings including high-dimensional sparse inference, goodness-of-fit testing, and model selection. The framework unifies several classical results: Jeffreys' $\\sqrt{\\log n}$ threshold, the BIC penalty $(d/2)\\log n$, and the Chernoff-Stein error exponents all emerge naturally from moderate deviation analysis of Bayes risk. Our results provide theoretical foundations for adaptive significance levels and connect Bayesian testing to information theory through gambling-based interpretations."}
{"id": "2602.11111", "categories": ["cond-mat.stat-mech", "cond-mat.soft", "nlin.PS", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.11111", "abs": "https://arxiv.org/abs/2602.11111", "authors": ["Michel Fruchart", "Vincenzo Vitelli"], "title": "Nonreciprocal many-body physics", "comment": "96 pages, 22 figures", "summary": "Reciprocity is a fundamental symmetry present in many natural phenomena and engineered systems. Distinct situations where this symmetry is broken are typically grouped under the umbrella term \"nonreciprocity\", colloquially defined by: the action of A on B $\\neq$ the action of B on A. In this review, we elucidate what nonreciprocity is by providing an introduction to its most salient classes: nonvariational dynamics, violations of Newton's third law, broken detailed balance, nonreciprocal responses and nonreciprocity of arbitrary linear operators. Next, we point out where to find these manifestations of non-reciprocity, from ensembles of particles with field mediated interactions to synthetic neural networks and open quantum systems. Given this breadth of contexts and the lack of an all-encompassing definition, it makes it all the more intriguing that some general conclusions can be gathered, when distinct definitions of nonreciprocity overlap. We explore what these universal consequences are with a special emphasis on collective phenomena that arise in nonreciprocal many-body systems. The topics covered include nonreciprocal phase transitions and non-normal amplification of noise and perturbations. We conclude with some open questions."}
{"id": "2602.10689", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10689", "abs": "https://arxiv.org/abs/2602.10689", "authors": ["Changjian Xie", "Yingxi Miao", "Haocheng Yang"], "title": "An Efficient Energy Stable Structure Preserving Method for The Landau-Lifshitz Equation", "comment": null, "summary": "One of the main difficulties in micromagnetics simulation is the norm preserving constraints $\\|\\mathbf{m}\\|=1$ at the continuous or the discrete level. Another difficulty is the stability with the time step constraint. Using standard explicit integrators leads to a physical time step of sub-pico seconds, which is often two orders of magnitude smaller than the fastest physical time scales. Direct implicit integrators require solving complicated, coupled systems. Another major difficulty with the projection method in this field is the lack of rigorous theoretical guarantees regarding its stability of the projection step. In this paper, we introduce a first order method. Such a method is structure preserving based on a combination of a Gauss-Seidel iteration, a double diffusion iteration and a Crank-Nicolson iteration to preserve the norm constraints."}
{"id": "2602.10838", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.10838", "abs": "https://arxiv.org/abs/2602.10838", "authors": ["Denis Zorba", "David Šiška", "Lukasz Szpruch"], "title": "Mirror descent actor-critic methods for entropy regularised MDPs in general spaces: stability and convergence", "comment": "27 pages", "summary": "We provide theoretical guarantees for convergence of discrete-time policy mirror descent with inexact advantage functions updated using temporal difference (TD) learning for entropy regularised MDPs in Polish state and action spaces. We rigorously derive sufficient conditions under which the single-loop actor-critic scheme is stable and convergent. To weaken these conditions, we introduce a variant that performs multiple TD steps per policy update and derive an explicit lower bound on the number of TD steps required to ensure stability. Finally, we establish sub-linear convergence when the number of TD steps grows logarithmically with the number of policy updates, and linear convergence when it grows linearly under a concentrability assumption."}
{"id": "2602.11077", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.11077", "abs": "https://arxiv.org/abs/2602.11077", "authors": ["Chih-Yuan Chiu", "Devansh Jalota", "Marco Pavone"], "title": "Credit-Based vs. Discount-Based Congestion Pricing: A Comparison Study", "comment": null, "summary": "Credit-based congestion pricing (CBCP) and discount-based congestion pricing (DBCP), which respectively allot travel credits and toll discounts to subsidize low-income users' access to tolled roads, have emerged as promising policies for alleviating the societal inequity concerns of congestion pricing. However, since real-world implementations of CBCP and DBCP are nascent, their relative merits remain unclear. In this work, we compare the efficacy of deploying CBCP and DBCP in reducing user costs and increasing toll revenues. We first formulate a non-atomic congestion game in which low-income users receive a travel credit or toll discount for accessing tolled lanes. We establish that, in our formulation, Nash equilibrium flows always exist and can be computed or well approximated via convex programming. Our main result establishes a set of practically relevant conditions under which DBCP provably outperforms CBCP in inducing equilibrium outcomes that minimize a given societal cost, which encodes user cost reduction and toll revenue maximization. Finally, we validate our theoretical contributions via a case study of the 101 Express Lanes Project, a CBCP program implemented in the San Francisco Bay Area."}
{"id": "2602.11077", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.11077", "abs": "https://arxiv.org/abs/2602.11077", "authors": ["Chih-Yuan Chiu", "Devansh Jalota", "Marco Pavone"], "title": "Credit-Based vs. Discount-Based Congestion Pricing: A Comparison Study", "comment": null, "summary": "Credit-based congestion pricing (CBCP) and discount-based congestion pricing (DBCP), which respectively allot travel credits and toll discounts to subsidize low-income users' access to tolled roads, have emerged as promising policies for alleviating the societal inequity concerns of congestion pricing. However, since real-world implementations of CBCP and DBCP are nascent, their relative merits remain unclear. In this work, we compare the efficacy of deploying CBCP and DBCP in reducing user costs and increasing toll revenues. We first formulate a non-atomic congestion game in which low-income users receive a travel credit or toll discount for accessing tolled lanes. We establish that, in our formulation, Nash equilibrium flows always exist and can be computed or well approximated via convex programming. Our main result establishes a set of practically relevant conditions under which DBCP provably outperforms CBCP in inducing equilibrium outcomes that minimize a given societal cost, which encodes user cost reduction and toll revenue maximization. Finally, we validate our theoretical contributions via a case study of the 101 Express Lanes Project, a CBCP program implemented in the San Francisco Bay Area."}
{"id": "2602.08895", "categories": ["nlin.CD", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.08895", "abs": "https://arxiv.org/abs/2602.08895", "authors": ["Yonghui Xia", "Hongtao Feng"], "title": "Chaos, the Critical Phenomenon in Phase Space: Feigenbaum Constants and Critical Exponents", "comment": "5 pages, 1 figure", "summary": "Chaos in both dissipative systems and conservative systems is investigated on the approach of renormalization group. It is found that the chaos is regarded as the critical phenomenon of equilibrium statistics in phase space. The two Feigenbaum constants in the period-doubling bifurcation systems correspond to two independent critical exponents, which are universal and can be adopted to distinguish the classes of chaos. For the conservative systems, due to the critical nature of the chaos, the isolated systems with different parameters are correlated in the phase space, and therefore the isolated system is no longer isolated in the phase space. The information of conservative systems is irreversibly lost over time, which leads to the increase entropy in an isolated system, and the contradiction between the second law of thermodynamics and the reversibility of isolated systems can be resolved."}
{"id": "2602.10773", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10773", "abs": "https://arxiv.org/abs/2602.10773", "authors": ["Tomás Caraballo", "Macarena Gómez-Mármol", "Ignacio Roldán"], "title": "The Stochastic TR-BDF2 Scheme of Order 2", "comment": null, "summary": "Our main objective in this paper is to develop a second-order stochastic numerical method which generalizes the well-known deterministic TR-BDF2 scheme. Since most stochastic techniques used for approximating the solution of a stochastic differential equation may have lower order compared to the deterministic case, we have elaborated a scheme which not only preserves the second-order accuracy of the original scheme in the stochastic framework, but also its $A$-stability. Once we obtain the scheme and prove its second-order accuracy and $A$-stability, which is not a trivial task, we also state a result concerning its $MS$-stability. This concept is also analyzed for different parameter ranges in our scheme and the It{ô}--Taylor approximation of order 2, revealing scenarios where, for certain time step sizes, the developed method is $MS$-stable while the It{ô}--Taylor one is not. This concept is really useful to tackle slow-fast problems such as stiff ones, which we aim to explore further in future work. Finally, we validate the theoretical results with some academic test cases."}
{"id": "2602.10866", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.10866", "abs": "https://arxiv.org/abs/2602.10866", "authors": ["Léo Baty", "Axel Parmentier"], "title": "Managing delay in tail assignment: from minimum turn time to stochastic routing at Air France", "comment": "28 pages", "summary": "On-time performance is a critical challenge in the airline industry, leading to large operational and customer dissatisfaction costs. The tail assignment problem builds the sequences of flights or routes followed by individual airplanes. While airlines cannot avoid some sources of delay, choosing routes wisely limits propagation along these. This paper addresses the stochastic tail assignment problem at Air France. We propose a column generation approach for this problem. The key ingredient is the pricing algorithm, which is a stochastic shortest path problem. We use dedicated bounds to discard paths in an enumeration algorithm, and introduce new bounds based on a lattice ordering of the set of piecewise linear convex functions to strike a balance between bounds quality and computational cost. A diving heuristic enables us to retrieve integer solutions. Numerical experiments on real-world Air France instances demonstrate that our algorithms lead to an average 0.28% optimality gap on instances with up to 600 flight legs in a few hours of computing time. The resulting solutions effectively balance operational costs and delay resilience, outperforming previous approaches based on minimum turn time."}
{"id": "2602.11116", "categories": ["eess.SY", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.11116", "abs": "https://arxiv.org/abs/2602.11116", "authors": ["Alfonso Sciacchitano", "Liraz Mudrik", "Sean Kragelund", "Isaac Kaminer"], "title": "Multi-UAV Trajectory Optimization for Bearing-Only Localization in GPS Denied Environments", "comment": "38 pages, 7 figure, and 6 tables", "summary": "Accurate localization of maritime targets by unmanned aerial vehicles (UAVs) remains challenging in GPS-denied environments. UAVs equipped with gimballed electro-optical sensors are typically used to localize targets, however, reliance on these sensors increases mechanical complexity, cost, and susceptibility to single-point failures, limiting scalability and robustness in multi-UAV operations. This work presents a new trajectory optimization framework that enables cooperative target localization using UAVs with fixed, non-gimballed cameras operating in coordination with a surface vessel. This estimation-aware optimization generates dynamically feasible trajectories that explicitly account for mission constraints, platform dynamics, and out-of-frame events. Estimation-aware trajectories outperform heuristic paths by reducing localization error by more than a factor of two, motivating their use in cooperative operations. Results further demonstrate that coordinated UAVs with fixed, non-gimballed cameras achieve localization accuracy that meets or exceeds that of single gimballed systems, while substantially lowering system complexity and cost, enabling scalability, and enhancing mission resilience."}
{"id": "2602.11116", "categories": ["eess.SY", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.11116", "abs": "https://arxiv.org/abs/2602.11116", "authors": ["Alfonso Sciacchitano", "Liraz Mudrik", "Sean Kragelund", "Isaac Kaminer"], "title": "Multi-UAV Trajectory Optimization for Bearing-Only Localization in GPS Denied Environments", "comment": "38 pages, 7 figure, and 6 tables", "summary": "Accurate localization of maritime targets by unmanned aerial vehicles (UAVs) remains challenging in GPS-denied environments. UAVs equipped with gimballed electro-optical sensors are typically used to localize targets, however, reliance on these sensors increases mechanical complexity, cost, and susceptibility to single-point failures, limiting scalability and robustness in multi-UAV operations. This work presents a new trajectory optimization framework that enables cooperative target localization using UAVs with fixed, non-gimballed cameras operating in coordination with a surface vessel. This estimation-aware optimization generates dynamically feasible trajectories that explicitly account for mission constraints, platform dynamics, and out-of-frame events. Estimation-aware trajectories outperform heuristic paths by reducing localization error by more than a factor of two, motivating their use in cooperative operations. Results further demonstrate that coordinated UAVs with fixed, non-gimballed cameras achieve localization accuracy that meets or exceeds that of single gimballed systems, while substantially lowering system complexity and cost, enabling scalability, and enhancing mission resilience."}
{"id": "2602.10421", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.10421", "abs": "https://arxiv.org/abs/2602.10421", "authors": ["Hing-Tong Cho", "Bei-Lok Hu"], "title": "Quantum Brownian motion with non-Gaussian noises: Fluctuation-Dissipation Relation and nonlinear Langevin equation", "comment": "25 pages", "summary": "Building upon the work of Hu, Paz, and Zhang [1,2] on open quantum systems we consider the quantum Brownian motion (QBM) model with one oscillator (position variable $x$) as the system, {\\it nonlinearly} coupled to an environment of $N$ harmonic oscillators (with mass $m_n$, natural frequency $ω_n$, position $q_n$ and momentum $p_n$ variables) in the form $\\sum_{n}\\left(v_{n1}(x)q_{n}^{k}+v_{n2}(x)p_{n}^{l}\\right)$ where $k, l$ are integers (the present work only considers the $k=l=2$ cases). The vertex functions $v_{n1}, v_{n2} $ are of the form $v_{n1}=λC_{n1} f(x), v_{n2}(x)=-λ\\,C_{n2}m_{n}^{-2}ω_{n}^{-2}f(x)$ where $C_{n1,2}$ are the coupling constants with the $n$th oscillator, $f(x)$ is any arbitrary function of $x$, and $λ$ is a dimensionless constant. Employing the closed-time-path formalism the influence action $S_{IF}$ is calculated using a perturbative expansion in $λ$. It is possible to identify the terms in $S_{IF}$ quadratic or higher in $Δ(s)\\equiv f(x_{+}(s))-f(x_{-}(s))$ to constitute the noise kernel, while terms linear in $Δ$ to that of the dissipation kernel. The non-Gaussian noise kernel gives rise to non-zero three-point correlation function of the corresponding stochastic force. The pathway presented here should be useful for the exploration of \\textit{non-Gaussian properties of systems nonlinearly coupled with their environments}; examples in early universe cosmology and in quantum optomechanics (QOM) are mentioned. A modified fluctuation-dissipation relation (FDR) is also established, which ensures the consistency of the model and the accuracy of results even at higher perturbative orders. Another result of significance is the derivation of a nonlinear Langevin equation which is expected to be useful for many open quantum system applications."}
{"id": "2602.10786", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10786", "abs": "https://arxiv.org/abs/2602.10786", "authors": ["Jan Glaubitz", "Armin Iske", "Joshua Lampert", "Philipp Öffner"], "title": "Why summation by parts is not enough", "comment": null, "summary": "We investigate the construction and performance of summation-by-parts (SBP) operators, which offer a powerful framework for the systematic development of structure-preserving numerical discretizations of partial differential equations. Previous approaches for the construction of SBP operators have usually relied on either local methods or sparse differentiation matrices, as commonly used in finite difference schemes. However, these methods often impose implicit requirements that are not part of the formal SBP definition. We demonstrate that adherence to the SBP definition alone does not guarantee the desired accuracy, and we identify conditions for SBP operators to achieve both accuracy and stability. Specifically, we analyze the error minimization for an augmented basis, discuss the role of sparsity, and examine the importance of nullspace consistency in the construction of SBP operators. Furthermore, we show how these design criteria can be integrated into a recently proposed optimization-based construction procedure for function space SBP (FSBP) operators on arbitrary grids. Our findings are supported by numerical experiments that illustrate the improved accuracy for the numerical solution using the proposed SBP operators."}
{"id": "2602.10920", "categories": ["math.OC", "math.AP", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.10920", "abs": "https://arxiv.org/abs/2602.10920", "authors": ["Benedikt Kaltenbach", "Christian Aarset", "Tram Thi Ngoc Nguyen"], "title": "Data assimilation via model reference adaptation for linear and nonlinear dynamical systems", "comment": null, "summary": "We address data assimilation for linear and nonlinear dynamical systems via the so-called \\emph{model reference adaptive system}. Continuing our theoretical developments in \\cite{Tram_Kaltenbacher_2021}, we deliver the first practical implementation of this approach for online parameter identification with time series data. Our semi-implicit scheme couples a modified state equation with a parameter evolution law that is driven by model-data residuals. We demonstrate four benchmark problems of increasing complexity: the Darcy flow, the Fisher-KPP equation, a nonlinear potential equation and finally, an Allen-Cahn type equation. Across all cases, explicit model reference adaptive system construction, verified assumptions and numerically stable reconstructions underline our proposed method as a reliable, versatile tool for data assimilation and real-time inversion."}
{"id": "2602.10738", "categories": ["physics.hist-ph", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.10738", "abs": "https://arxiv.org/abs/2602.10738", "authors": ["Enric Pérez", "Antonio Gil"], "title": "Between equilibrium and fluctuation: Einstein's heuristic argument and Boltzmann's principle", "comment": "36 pages, 4 figures", "summary": "We critically revisit Einstein's 1905 heuristic argument for lightquanta, considering its internal coherence and the scope of its applicability. We argue that Einstein's reasoning, often celebrated for its originality, is ambiguous because it can be understood as a fluctuation or as a comparison between equilibrium states. A historical and conceptual analysis of Einstein's use of Boltzmann's principle in those years reveals his evolving stance on its meaning and the role of probability, as well as his persistent doubts about the nature of radiation. We use our analysis to examine the limitations of extending the notion of Einstein's lightquanta across the electromagnetic spectrum: the relevant parameter is not the frequency, but the occupancy number."}
{"id": "2602.10803", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10803", "abs": "https://arxiv.org/abs/2602.10803", "authors": ["Huangxin Chen", "Yuxiang Chen", "Jisheng Kou", "Shuyu Sun"], "title": "bound-preserving Adaptive Time-Stepping Method with Energy Stability for Simulating Compressible Gas Flow in Poroelastic Media", "comment": null, "summary": "In this paper, we present an efficient numerical method to address a thermodynamically consistent gas flow model in porous media involving compressible gas and deformable rock. The accurate modeling of gas flow in porous media often poses significant challenges due to their inherent nonlinearity, the coupling between gas and rock dynamics, and the need to preserve physical principles such as mass conservation, energy dissipation and molar density boundedness. The system is further complicated by the need to balance computational efficiency with the accuracy and stability of the numerical scheme. To tackle these challenges, we adopt a stabilization approach that is able to preserve the original energy dissipation while achieving linear energy-stable numerical schemes. We also prove the convergence of the adopted linear iterative method. At each time step, the stabilization parameter is adaptively updated using a simple and explicit formula to ensure compliance with the original energy dissipation law. The proposed method uses adaptive time stepping to improve computational efficiency while maintaining solution accuracy and boundedness. The adaptive time step size is calculated explicitly at each iteration, ensuring stability and allowing for efficient handling of highly dynamic scenarios. A mixed finite element method combined with an upwind scheme is employed as spatial discretization to ensure mass conservation and stability. Finally, we conduct a series of numerical experiments to validate the performance and robustness of the proposed numerical method."}
{"id": "2602.11048", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.11048", "abs": "https://arxiv.org/abs/2602.11048", "authors": ["David Banks", "Elvan Ceyhan", "Leah Johnson", "Li Zhou"], "title": "Adversarial Graph Traversal", "comment": "10 pages, 4 figures. Simulation study included", "summary": "Suppose a Bayesian agent seeks to traverse a graph. Each time she crosses an edge, she pays a price. The first time she reaches a node, there is a payoff. She has an opponent who can reduce the payoffs. This paper uses adversarial risk analysis to find a solution to her route selection problem. It shows how the traveler is advantaged by having an accurate subjective distribution over the costs/payoffs and by having a Bayesian prior for her opponent's strategic choices. The results are relevant to military convoy routing, corporate competition, and certain games."}
{"id": "2602.11006", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.11006", "abs": "https://arxiv.org/abs/2602.11006", "authors": ["Tobias Hülser", "Sebastian Matera"], "title": "Noise-balanced multilevel on-the-fly sparse grid surrogates for coupling Monte Carlo models into continuum models with application to heterogeneous catalysis", "comment": "28 pages, 7 figures", "summary": "Multiscale simulations utilizing high-fidelity, microscopic Monte Carlo models to provide the nonlinear response for continuum models can easily become computationally intractable. Surrogate models for the high-fidelity Monte Carlo models can overcome this but come with some challenges. One such challenges arise by the sampling noise in the underlying Monte Carlo data, which leads to uncontrolled errors possibly corrupting the surrogate even though it would be highly accurate in the case of noise-free data. Another challenge arises by the 'curse of dimensionality' when the response depends on many macro-variables. These points are addressed by a novel noise-balanced sparse grids interpolation approach which, in a quasi-optimal fashion, controls the amount of Monte Carlo sampling for each data point. The approach is complemented by a multilevel on-the-fly construction during the multiscale simulation. Besides its efficiency, a particularly appealing feature is the ease of use of the approach with only a single hyperparameter controlling the whole surrogate construction - from the surrogate's accuracy with guaranteed convergence to which data needs to be created with which accuracy. The approach is demonstrated on challenging examples from heterogeneous catalysis, coupling microscopic kinetic Monte Carlo models into macroscopic reactor simulations."}
{"id": "2602.10890", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.10890", "abs": "https://arxiv.org/abs/2602.10890", "authors": ["Daniele Di Pietro", "Aurelio Spadotto"], "title": "Hybrid Methods for Friedrichs Systems with Application to Scalar and Vector Diffusion-Advection Problems", "comment": null, "summary": "In this work we study arbitrary-order hybrid discretizations of Friedrichs systems. Friedrichs systems provide a framework that goes beyond the standard classification of partial differential equations into hyperbolic or elliptic, and are thus particularly suited for problems that include both diffusive and advective terms. The family of numerical schemes proposed in this work hinge on hybrid spaces with unknowns located at elements and faces. They support general meshes, are locally conservative and, compared with traditional Discontinuous Galerkin discretizations, lead to smaller algebraic systems once static condensation has been applied. We carry out a complete stability and convergence analysis, which appears to be the first of its kind. The performance of the method is illustrated on scalar and vector three-dimensional diffusion-advection-reaction problems."}
{"id": "2602.10129", "categories": ["cs.SI", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.10129", "abs": "https://arxiv.org/abs/2602.10129", "authors": ["Aakash Mishra", "Qi Xu", "Zhigang Hua", "Keyu Nie", "Vishwanath Sangale", "Vishal Vaingankar", "Jizhe Zhang", "Ren Mao"], "title": "Causal-Informed Hybrid Online Adaptive Optimization for Ad Load Personalization in Large-Scale Social Networks", "comment": "5 pages, 3 figures, NeurIPS COML Workshop", "summary": "Personalizing ad load in large-scale social networks requires balancing user experience and conversions under operational constraints. Traditional primal-dual methods enforce constraints reliably but adapt slowly in dynamic environments, while Bayesian Optimization (BO) enables exploration but suffers from slow convergence. We propose a hybrid online adaptive optimization framework CTRCBO ( Cohort-Based Trust Region Contextual Bayesian Optimization), combining primal-dual with BO, enhanced by trust-region updates and Gaussian Process Regression (GPR) surrogates for both objectives and constraints. Our approach leverages a upstream Causal ML model to inform the surrogate, improving decision quality and enabling efficient exploration-exploitation and online tuning. We evaluate our method on a billion-user social network, demonstrating faster convergence, robust constraint satisfaction, and improved personalization metrics, including real-world online AB test results."}
{"id": "2602.11056", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.11056", "abs": "https://arxiv.org/abs/2602.11056", "authors": ["Triyas Sapui", "Tanoy Kanti Konar", "Aditi Sen De"], "title": "Ergotropic Mpemba crossings in finite-dimensional quantum batteries", "comment": "19 pages, 11 figures", "summary": "The quantum Mpemba effect is a counterintuitive phenomenon in which a state initially farther from equilibrium relaxes more rapidly than one that starts nearer to equilibrium. In the context of finite-dimensional quantum batteries interacting with an environment, we introduce the notion of an ergotropic Mpemba crossing (EMC), defined by the intersection of ergotropy trajectories during the dynamics. For qubit batteries subjected to amplitude damping noise, we derive a condition for the occurrence of EMC in terms of the relative coherence of the initial states and fully characterize the region of state space that exhibits EMC with respect to a fixed reference state. Interestingly, our analysis reveals that under anisotropic Pauli noise, the emergence of EMC is jointly governed by the coherence and the energy of the initial states. To elucidate the physical origin of EMC, we decompose ergotropy into coherent and incoherent contributions and show that, in qubit systems, the coherent component plays a crucial role for EMC, an observation that strikingly does not extend to three-level batteries. Further, by extending our analysis to non-Markovian environments, we demonstrate that, unlike the Markovian case, non-Markovian dynamics can give rise to multiple Mpemba crossings, with the total number of crossings always being odd. Moreover, analyzing the connection between the EMC and the conventional state Mpemba effect reveals that, for qubits, an EMC necessarily entails a state Mpemba crossing while this correspondence breaks down for qutrits, where EMCs may arise without any state Mpemba crossing."}
{"id": "2602.11109", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.11109", "abs": "https://arxiv.org/abs/2602.11109", "authors": ["Xiao Qi", "Yue Wu", "Yubin Yan"], "title": "Drift-Randomized Milstein-Galerkin Finite Element Method for Semilinear Stochastic Evolution Equations", "comment": null, "summary": "Kruse and Wu [Math. Comp. 88 (2019) 2793--2825] proposed a fully discrete randomized Galerkin finite element method for semilinear stochastic evolution equations (SEEs) driven by additive noise and showed that this method attains a temporal strong convergence rate exceeding order $\\frac{1}{2}$ without imposing any differentiability assumptions on the drift nonlinearity. They further discussed a potential extension of the randomized method to SEEs with multiplicative noise and introduced the so-called drift-randomized Milstein-Galerkin finite element fully discrete scheme, but without providing a corresponding strong convergence analysis.\n  This paper aims to fill this gap by rigorously analyzing the strong convergence behavior of the drift-randomized Milstein-Galerkin finite element scheme. By avoiding the use of differentiability assumptions on the nonlinear drift term, we establish strong convergence rates in both space and time for the proposed method. The obtained temporal convergence rate is $O(Δt^{1-\\varepsilon_0})$, where $Δt$ denotes the time step size and $\\varepsilon_0$ is an arbitrarily small positive number. Numerical experiments are reported to validate the theoretical findings."}
{"id": "2602.10936", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.10936", "abs": "https://arxiv.org/abs/2602.10936", "authors": ["Levi D. Reyes Premer", "Arash J. Khabbazi", "Kevin J. Kircher"], "title": "Trajectory-based data-driven predictive control and the state-space predictor", "comment": null, "summary": "We define trajectory predictive control (TPC) as a family of output-feedback indirect data-driven predictive control (DDPC) methods that represent the output trajectory of a discrete-time system as a linear function of the recent input/output history and the planned input trajectory. This paper shows that for different choices of the trajectory predictor, TPC encompasses a wide variety of DDPC methods, including subspace predictive control (SPC), closed-loop SPC, $γ$-DDPC, causal-$γ$-DDPC, transient predictive control, and others. This paper introduces a trajectory predictor that corresponds to a linear state-space model with the recent input/output history as the state. With this state-space predictor, TPC is a special case of linear model predictive control and therefore inherits its mature theory. In numerical experiments, TPC performance approaches the limit of oracle $H_2$-optimal control with perfect knowledge of the underlying system model. For TPC with small training datasets, the state-space predictor outperforms other predictors because it has fewer parameters."}
{"id": "2602.10374", "categories": ["math.OC", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.10374", "abs": "https://arxiv.org/abs/2602.10374", "authors": ["Yiwen Chen"], "title": "Relationships between full-space and subspace quadratic interpolation models and simplex derivatives", "comment": null, "summary": "Quadratic interpolation models and simplex derivatives are fundamental tools in numerical optimization, particularly in derivative-free optimization. When constructed in suitably chosen affine subspaces, these tools have been shown to be especially effective for high-dimensional derivative-free optimization problems, where full-space model construction is often impractical. In this paper, we analyze the relationships between full-space and subspace formulations of these tools. In particular, we derive explicit conversion formulas between full-space and subspace models, including minimum-norm models, minimum Frobenius norm models, least Frobenius norm updating models, as well as models constructed via generalized simplex gradients and Hessians. We show that the full-space and subspace models coincide on the affine subspace and, in general, along directions in the orthogonal complement. Overall, our results provide a theoretical framework for understanding subspace approximation techniques and offer insight into the design and analysis of derivative-free optimization methods."}
{"id": "2602.11116", "categories": ["eess.SY", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.11116", "abs": "https://arxiv.org/abs/2602.11116", "authors": ["Alfonso Sciacchitano", "Liraz Mudrik", "Sean Kragelund", "Isaac Kaminer"], "title": "Multi-UAV Trajectory Optimization for Bearing-Only Localization in GPS Denied Environments", "comment": "38 pages, 7 figure, and 6 tables", "summary": "Accurate localization of maritime targets by unmanned aerial vehicles (UAVs) remains challenging in GPS-denied environments. UAVs equipped with gimballed electro-optical sensors are typically used to localize targets, however, reliance on these sensors increases mechanical complexity, cost, and susceptibility to single-point failures, limiting scalability and robustness in multi-UAV operations. This work presents a new trajectory optimization framework that enables cooperative target localization using UAVs with fixed, non-gimballed cameras operating in coordination with a surface vessel. This estimation-aware optimization generates dynamically feasible trajectories that explicitly account for mission constraints, platform dynamics, and out-of-frame events. Estimation-aware trajectories outperform heuristic paths by reducing localization error by more than a factor of two, motivating their use in cooperative operations. Results further demonstrate that coordinated UAVs with fixed, non-gimballed cameras achieve localization accuracy that meets or exceeds that of single gimballed systems, while substantially lowering system complexity and cost, enabling scalability, and enhancing mission resilience."}
{"id": "2602.10589", "categories": ["quant-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.10589", "abs": "https://arxiv.org/abs/2602.10589", "authors": ["Alessandro Andrea Zecchi", "Claudio Sanavio", "Luca Cappelli", "Simona Perotto", "Alessandro Roggero", "Sauro Succi"], "title": "Block encoding of sparse matrices with a periodic diagonal structure", "comment": null, "summary": "Block encoding is a successful technique used in several powerful quantum algorithms. In this work we provide an explicit quantum circuit for block encoding a sparse matrix with a periodic diagonal structure. The proposed methodology is based on the linear combination of unitaries (LCU) framework and on an efficient unitary operator used to project the complex exponential at a frequency $ω$ multiplied by the computational basis into its real and imaginary components. We demonstrate a distinct computational advantage with a $\\mathcal{O}(\\text{poly}(n))$ gate complexity, where $n$ is the number of qubits, in the worst-case scenario used for banded matrices, and $\\mathcal{O}(n)$ when dealing with a simple diagonal matrix, compared to the exponential scaling of general-purpose methods for dense matrices. Various applications for the presented methodology are discussed in the context of solving differential problems such as the advection-diffusion-reaction (ADR) dynamics, using quantum algorithms with optimal scaling, e.g., quantum singular value transformation (QSVT). Numerical results are used to validate the analytical formulation."}
{"id": "2602.10963", "categories": ["eess.SY", "cs.RO", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.10963", "abs": "https://arxiv.org/abs/2602.10963", "authors": ["Srishti Siddharth", "Vivek Natarajan", "Ravi N. Banavar"], "title": "Lie Group Variational Integrator for the Geometrically Exact Rod with Circular Cross-Section Incorporating Cross-Sectional Deformation", "comment": "Submitted to: Computers and Mathematics with Applications", "summary": "In this paper, we derive the continuous space-time equations of motion of a three-dimensional geometrically exact rod, or the Cosserat rod, incorporating planar cross-sectional deformation. We then adopt the Lie group variational integrator technique to obtain a discrete model of the rod incorporating both rotational motion and cross-sectional deformation as well. The resulting discrete model possesses several desirable features: it ensures volume conservation of the discrete elements by considering cross-sectional deformation through a local dilatation factor, it demonstrates the beneficial properties associated with the variational integrator technique, such as the preservation of the rotational configuration, and energy conservation with a bounded error. An exhaustive set of numerical results under various initial conditions of the rod demonstrates the efficacy of the model in replicating the physics of the system."}
{"id": "2602.11006", "categories": ["physics.comp-ph", "cond-mat.stat-mech", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.11006", "abs": "https://arxiv.org/abs/2602.11006", "authors": ["Tobias Hülser", "Sebastian Matera"], "title": "Noise-balanced multilevel on-the-fly sparse grid surrogates for coupling Monte Carlo models into continuum models with application to heterogeneous catalysis", "comment": "28 pages, 7 figures", "summary": "Multiscale simulations utilizing high-fidelity, microscopic Monte Carlo models to provide the nonlinear response for continuum models can easily become computationally intractable. Surrogate models for the high-fidelity Monte Carlo models can overcome this but come with some challenges. One such challenges arise by the sampling noise in the underlying Monte Carlo data, which leads to uncontrolled errors possibly corrupting the surrogate even though it would be highly accurate in the case of noise-free data. Another challenge arises by the 'curse of dimensionality' when the response depends on many macro-variables. These points are addressed by a novel noise-balanced sparse grids interpolation approach which, in a quasi-optimal fashion, controls the amount of Monte Carlo sampling for each data point. The approach is complemented by a multilevel on-the-fly construction during the multiscale simulation. Besides its efficiency, a particularly appealing feature is the ease of use of the approach with only a single hyperparameter controlling the whole surrogate construction - from the surrogate's accuracy with guaranteed convergence to which data needs to be created with which accuracy. The approach is demonstrated on challenging examples from heterogeneous catalysis, coupling microscopic kinetic Monte Carlo models into macroscopic reactor simulations."}
