{"id": "2602.21590", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.21590", "abs": "https://arxiv.org/abs/2602.21590", "authors": ["Kart Leong Lim", "Rahul Dutta", "Mihai Rotaru"], "title": "Physics Informed Neural Network using Finite Difference Method", "comment": null, "summary": "In recent engineering applications using deep learning, physics-informed neural network (PINN) is a new development as it can exploit the underlying physics of engineering systems. The novelty of PINN lies in the use of partial differential equations (PDE) for the loss function. Most PINNs are implemented using automatic differentiation (AD) for training the PDE loss functions. A lesser well-known study is the use of finite difference method (FDM) as an alternative. Unlike an AD based PINN, an immediate benefit of using a FDM based PINN is low implementation cost. In this paper, we propose the use of finite difference method for estimating the PDE loss functions in PINN. Our work is inspired by computational analysis in electromagnetic systems that traditionally solve Laplace's equation using successive over-relaxation. In the case of Laplace's equation, our PINN approach can be seen as taking the Laplacian filter response of the neural network output as the loss function. Thus, the implementation of PINN can be very simple. In our experiments, we tested PINN on Laplace's equation and Burger's equation. We showed that using FDM, PINN consistently outperforms non-PINN based deep learning. When comparing to AD based PINNs, we showed that our method is faster to compute as well as on par in terms of error reduction."}
{"id": "2602.21606", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.21606", "abs": "https://arxiv.org/abs/2602.21606", "authors": ["Kart-Leong Lim", "Rahul Dutta", "Mihai Rotaru"], "title": "Inverse prediction of capacitor multiphysics dynamic parameters using deep generative model", "comment": null, "summary": "Finite element simulations are run by package design engineers to model design structures. The process is irreversible meaning every minute structural adjustment requires a fresh input parameter run. In this paper, the problem of modeling changing (small) design structures through varying input parameters is known as inverse prediction. We demonstrate inverse prediction on the electrostatics field of an air-filled capacitor dataset where the structural change is affected by a dynamic parameter to the boundary condition. Using recent AI such as deep generative model, we outperformed best baseline on inverse prediction both visually and in terms of quantitative measure."}
{"id": "2602.21996", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2602.21996", "abs": "https://arxiv.org/abs/2602.21996", "authors": ["Lisa Kühn", "Jacopo Bonari", "Max von Danwitz", "Alexander Popp"], "title": "Intrusive and Non-Intrusive Model Order Reduction for Airborne Contaminant Transport: Comparative Analysis and Uncertainty Quantification", "comment": "Paper submitted to \"Reliability Engineering & System Safety\" and currently under review", "summary": "Numerical simulations of contaminant dispersion, as after a gas leakage incident on a chemical plant, can provide valuable insights for both emergency response and preparedness. Simulation approaches combine incompressible Navier-Stokes (INS) equations with advection-diffusion (AD) processes to model wind and concentration field. However, the computational cost of such high-fidelity simulations increases rapidly for complex geometries like urban environments, making them unfeasible in time-critical or multi-query \"what-if\" scenarios. Therefore, this study focuses on the application of model order reduction (MOR) techniques enabling fast yet accurate predictions. To this end, a thorough comparison of intrusive and non-intrusive MOR methods is performed for the computationally more demanding parametric INS problem with varying wind velocities. Based on these insights, a non-intrusive reduced-order model (ROM) is constructed accounting for both wind velocity and direction. The study is conducted on a two-dimensional domain derived from real-world building footprints, preserving key features for analyzing the dispersion of, for instance, denser contaminants. The resulting ROM enables faster than real-time predictions of spatio-temporal contaminant dispersion from an instantaneous source under varying wind conditions. This capability allows assessing wind measurement uncertainties through a Monte Carlo analysis. To demonstrate the practical applicability, an interactive dashboard provides intuitive access to simulation results."}
{"id": "2602.21403", "categories": ["stat.ME", "cs.CE", "eess.SP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.21403", "abs": "https://arxiv.org/abs/2602.21403", "authors": ["Luca Martino", "Eduardo Morgado", "Roberto San Millán-Castillo"], "title": "An index of effective number of variables for uncertainty and reliability analysis in model selection problems", "comment": null, "summary": "An index of an effective number of variables (ENV) is introduced for model selection in nested models. This is the case, for instance, when we have to decide the order of a polynomial function or the number of bases in a nonlinear regression, choose the number of clusters in a clustering problem, or the number of features in a variable selection application (to name few examples). It is inspired by the idea of the maximum area under the curve (AUC). The interpretation of the ENV index is identical to the effective sample size (ESS) indices concerning a set of samples. The ENV index improves {drawbacks of} the elbow detectors described in the literature and introduces different confidence measures of the proposed solution. These novel measures can be also employed jointly with the use of different information criteria, such as the well-known AIC and BIC, or any other model selection procedures. Comparisons with classical and recent schemes are provided in different experiments involving real datasets. Related Matlab code is given."}
{"id": "2602.21869", "categories": ["physics.soc-ph", "physics.app-ph", "physics.data-an", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.21869", "abs": "https://arxiv.org/abs/2602.21869", "authors": ["Mattia Marzi", "Tiziano Squartini"], "title": "A Bayesian approach to out-of-sample network reconstruction", "comment": "25 pages, 13 figures", "summary": "Networks underpin systems that range from finance to biology, yet their structure is often only partially observed. Current reconstruction methods typically fit the parameters of a model anew to each snapshot, thus offering no guidance to predict future configurations. Here, we develop a Bayesian approach that uses the information about past network snapshots to inform a prior and predict the subsequent ones, while quantifying uncertainty. Instantiated with a single-parameter fitness model, our method infers link probabilities from node strengths and carries information forward in time. When applied to the Electronic Market for Interbank Deposit across the years 1999-2012, our method accurately recovers the number of connections per bank at subsequent times, outperforming probabilistic benchmarks designed for analogous, link prediction tasks. Notably, each predicted snapshot serves as a reliable prior for the next one, thus enabling self-sustained, out-of-sample reconstruction of evolving networks with a minimal amount of additional data."}
{"id": "2602.21848", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.21848", "abs": "https://arxiv.org/abs/2602.21848", "authors": ["Yiannis F. Contoyiannis"], "title": "Superpositions between non linear intermittency maps, application in biological neurons networks", "comment": "29 pages, 9 figures", "summary": "In a series of works of ours we have shown that we can represent the critical and tricritical points of the Statistical Physics of critical phenomena as a Dynamical phenomenon expressed by time series produced by the type I intermittency that exhibits a weak chaos. Recently we have also shown that if we couple these two chaotic dynamics, namely critical and tricritical, we can produce a time sequence which is a temporal Spike Train (ST) of biological-type . In the present work we generalize this issue producing superpositions of critical-tricritical intermittencies with different parameter values. Now arise the question whether the coupling occurs between time series that have resulted from the superposition, will preserved or destroyed the ST biological type , as the number of intermittencies in the superposition will increase? In the other side in present work we find that the spikes produced by the chaotic dynamics of the intermittencies, under the action of superpositions and coupling remain biological-type too. Thus we can say that the dynamics of the fluctuations of the values of the time series produced by the coupling of the superpositions of the intermittencies is the same as the dynamics of the fluctuations of the membrane potential of the biological neuron. Given also that we can manipulate the numerical experiment of superposition and coupling as we wish, we will be able, in future, to approach the cause of neurological problems and decline in thinking ability due to loss of spikes in the brain."}
{"id": "2602.21617", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2602.21617", "abs": "https://arxiv.org/abs/2602.21617", "authors": ["Benjamin J. Choi", "Hiroshi Ohno", "Akio Tomiya"], "title": "Machine Learning-Based Estimation of Cumulants of Chiral Condensate via Multi-Ensemble Reweighting with Deborah.jl", "comment": "10 pages, 3 figures, 2 tables, Proceedings of the 42nd International Symposium on Lattice Field Theory (Lattice 2025), November 2nd - 8th, 2025, TIFR Mumbai, India", "summary": "We investigate a bias-corrected machine learning (ML) strategy for estimating traces of the inverse Dirac operator, $\\text{Tr}\\, M^{-n}$ ($n=1,2,3,4$), motivated by the need for higher-order cumulants of the chiral condensate near the finite-temperature QCD critical endpoint. Our supervised regression framework is trained on Wilson-clover ensembles with the Iwasaki gauge action, and we explore two input feature scenarios: one using $\\text{Tr}\\, M^{-1}$ and another relying solely on gauge observables (plaquette and rectangle), enabling a fully feature-based prediction pipeline. Using $\\text{Tr}\\, M^{-1}$ both as a physical input to cumulant construction and as a feature for predicting higher powers, we find that even with $\\sim1\\%$ labeled data, the resulting susceptibility, skewness, and kurtosis remain statistically consistent with fully measured baselines, reducing computational cost to about $26\\%$. In the feature-only approach, where correlations rather than explicit stochastic traces drive the predictions, bias correction plays a more pronounced role. We quantify this impact through multi ensemble reweighting across nearby quark masses. Our results demonstrate that bias-corrected ML estimates can significantly reduce measurement overhead while preserving the stability of higher-order observables relevant for locating the QCD critical endpoint. Code for this work is available at https://github.com/saintbenjamin/Deborah.jl ."}
{"id": "2602.21396", "categories": ["cond-mat.stat-mech", "math.AP", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.21396", "abs": "https://arxiv.org/abs/2602.21396", "authors": ["Victorya Richardson", "Yick Hin Ling", "Sean D Lawley"], "title": "Yet another look at narrow escape through a tube", "comment": "21 pages, 2 figures", "summary": "The narrow escape problem concerns the time needed for a diffusing particle to exit a confining domain through a small hole in the boundary. While this problem is now well-understood, determining the escape time for a particle that must exit through a narrow tube has proven challenging. Indeed, relying on analogies with electrodynamics, parameter fits to simulations, and heuristics, a variety of conflicting estimates for this escape time have been offered over the last three decades, some of which are counterintuitive and arguably non-physical. In this paper, we combine matched asymptotic analysis and probabilistic methods to determine the exact asymptotics of the narrow escape time through a tube. We obtain a new escape time formula which reduces to the various prior estimates in certain special cases. If the diffusivity in the tube differs from the diffusivity in the rest of the domain, our results reveal the importance of the form of the multiplicative noise inherent to any diffusivity that varies in space. We discuss our results in the context of asymmetric cell division."}
{"id": "2602.21359", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21359", "abs": "https://arxiv.org/abs/2602.21359", "authors": ["Swarnadeep Datta", "Monitirtha Dey"], "title": "Some Asymptotic Results on Multiple Testing under Weak Dependence", "comment": null, "summary": "This paper studies the means-testing problem under weakly correlated Normal setups. Although quite common in genomic applications, test procedures having exact FWER control under such dependence structures are nonexistent. We explore the asymptotic behaviors of the classical Bonferroni (when adjusted suitably) and the Sidak procedure; and show that both of these control FWER at the desired level exactly as the number of hypotheses approaches infinity. We derive analogous limiting results on the generalized family-wise error rate and power. Simulation studies depict the asymptotic exactness of the procedures empirically."}
{"id": "2602.21274", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.21274", "abs": "https://arxiv.org/abs/2602.21274", "authors": ["Johanna Garzón", "Jhonatan S. Mora Rodríguez", "Harold A. Moreno-Franco"], "title": "Optimal extraction with an impact on diffusion-jump pricing", "comment": null, "summary": "We study an optimal extraction problem where the agent's actions in the spot market exert an additive proportional negative impact on the commodity price. The commodity price dynamics, prior to any activity by the agent, are evolved by a drifted Brownian motion with jumps. The agent's primary aim is to identify an optimal extraction strategy that maximizes their expected net profits."}
{"id": "2602.21448", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.21448", "abs": "https://arxiv.org/abs/2602.21448", "authors": ["Linheng Ruan", "Ilja Kröker", "Sergey Oladyshkin", "Iryna Rybak"], "title": "Surrogate-assisted global sensitivity analysis of a hybrid-dimensional Stokes--Brinkman--Darcy model", "comment": null, "summary": "Development of new multiscale mathematical models often entails considerable complexity and multiple undetermined parameters, typically arising from closure relations. To enable reliable simulations, one must quantify how uncertain physical parameters influence model predictions. We propose surrogate-assisted global sensitivity analysis that combines computational efficiency with a rigorous assessment of parameter influence. In this work, we analyze the recently proposed hybrid-dimensional Stokes--Brinkman--Darcy model, which describes fluid flows in coupled free-flow and porous-medium systems with arbitrary flow directions at the fluid--porous interface. The model results from vertical averaging and contains several unknown parameters. We perform surrogate-assisted global sensitivity analysis using Sobol' indices to investigate the sensitivity of the model to variations of physical parameters for two test cases: filtration and splitting flows. However, constructing surrogates for higher-dimensional random fields requires either many training runs or sophisticated sampling strategies. To address this, we compare polynomial chaos surrogates, including sparse and multi-resolution representations, for their efficiency in global sensitivity analysis, using a predefined Sobol' sequence of training samples. Across the tested cases, multi-resolution approach delivers the most accurate estimation of Sobol' indices."}
{"id": "2602.21334", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21334", "abs": "https://arxiv.org/abs/2602.21334", "authors": ["Oscar Jed R. Chuy", "Matthew T. Hale", "Vignesh Sivaramakrishnan", "Sean Phillips", "Ricardo G. Sanfelice"], "title": "Autonomous Satellite Rendezvous via Hybrid Feedback Optimization", "comment": "41 pages, 8 figures, 2 tables, Submitted to Nonlinear Analysis: Hybrid Systems 2026", "summary": "As satellites have proliferated, interest has increased in autonomous rendezvous, proximity operations, and docking (ARPOD). A fundamental challenge in these tasks is the uncertainties when operating in space, e.g., in measurements of satellites' states, which can make future states difficult to predict. Another challenge is that satellites' onboard processors are typically much slower than their terrestrial counterparts. Therefore, to address these challenges we propose to solve an ARPOD problem with feedback optimization, which computes inputs to a system by measuring its outputs, feeding them into an optimization algorithm in the loop, and computing some number of iterations towards an optimal input. We focus on satellite rendezvous, and satellites' dynamics are modeled using the continuous-time Clohessy-Wiltshire equations, which are marginally stable. We develop an asymptotically stabilizing controller for them, and we use discrete-time gradient descent in the loop to compute inputs to them. Then, we analyze the hybrid feedback optimization system formed by the stabilized Clohessy-Wiltshire equations with gradient descent in the loop. We show that this model is well-posed and that maximal solutions are both complete and non-Zeno. Then, we show that solutions converge exponentially fast to a ball around a rendezvous point, and we bound the radius of that ball in terms of system parameters. Simulations show that this approach provides up to a 98.4\\% reduction in the magnitude of disturbances across a range of simulations, which illustrates the viability of hybrid feedback optimization for autonomous satellite rendezvous."}
{"id": "2602.21239", "categories": ["physics.comp-ph", "nucl-ex"], "pdf": "https://arxiv.org/pdf/2602.21239", "abs": "https://arxiv.org/abs/2602.21239", "authors": ["Wilson Lin", "Catherine E Apgar", "Lee A Bernstein", "YunHsuan Lee", "Alan B McIntosh", "Dmitri G Medvedev", "Ellen M OBrien", "Christiaan E Vermeulen", "Andrew S Voyles", "Jonathan T Morrell"], "title": "Using Neural Networks to Accelerate TALYS-2.0 Nuclear Reaction Simulations", "comment": "10 pages, 3 figures, 10 supplementary figures", "summary": "Recent efforts to improve the predictability of TALYS-2.0 calculated charged-particle residual product cross sections have focused on adjusting parameters related to the optical model potential and pre-equilibrium process. Although adjusted TALYS-2.0 outputs show marked improvements in agreement with experimental data over the default parameters, the procedure is generally time-consuming due to the need for sequential TALYS-2.0 calculations. Since the models and model parameters must be defined and constrained prior to adjustment, we show in this work that an artificial neural network can serve as a surrogate model to successfully predict TALYS-2.0 outputs within this domain of input parameters. No practical differences were observed in the trained model's performance between uniform random, Latin hypercube and Sobol sequence sampling for generating the training datasets. Once validated, trained neural network models were used to adjust TALYS-2.0 nuclear model parameters, where a multi-parameter fitting procedure was not only feasible but optimal for this process. The neural network approach is >1000x faster at generating residual product cross sections than using TALYS-2.0 directly, and a high-fidelity surrogate model could be implemented with about 1500 TALYS-2.0 files to achieve adjusted cross sections comparable to the previous publication."}
{"id": "2602.21214", "categories": ["cs.SI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.21214", "abs": "https://arxiv.org/abs/2602.21214", "authors": ["Mohadeseh Sheikhqoraei", "Zainabolhoda Heshmati", "Zeinab Rajabi", "Leila Rabiei"], "title": "Toward Effective Multi-Domain Rumor Detection in Social Networks Using Domain-Gated Mixture-of-Experts", "comment": null, "summary": "Social media platforms have become key channels for spreading and tracking rumors due to their widespread accessibility and ease of information sharing. Rumors can continuously emerge across diverse domains and topics, often with the intent to mislead society for personal or commercial gain. Therefore, developing methods that can accurately detect rumors at early stages is crucial to mitigating their negative impact. While existing approaches often specialize in single-domain detection, their performance degrades when applied to new domains due to shifts in data distribution, such as lexical patterns and propagation dynamics. To bridge this gap, this study introduces PerFact, a large-scale multi-domain rumor dataset comprising 8,034 annotated posts from the X platform, annotated into two primary categories: rumor (including true, false, and unverified rumors) and non-rumor. Annotator agreement, measured via Fleiss' Kappa ($κ= 0.74$), ensures high-quality labels.\n  This research further proposes an effective multi-domain rumor detection model that employs a domain gate to dynamically aggregate multiple feature representations extracted through a Mixture-of-Experts method. Each expert combines CNN and BiLSTM networks to capture local syntactic features and long-range contextual dependencies. By leveraging both textual content and publisher information, the proposed model classifies posts into rumor and non-rumor categories with high accuracy. Evaluations demonstrate state-of-the-art performance, achieving an F1-score of 79.86\\% and an accuracy of 79.98\\% in multi-domain settings.\n  Keywords: Rumor Detection, Multi-Domain, Natural Language Processing, Social Networks, Mixture-of-Experts Model"}
{"id": "2602.21314", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21314", "abs": "https://arxiv.org/abs/2602.21314", "authors": ["Eli Ben-Michael", "Avi Feller"], "title": "Discussion of \"Matrix Completion When Missing Is Not at Random and Its Applications in Causal Panel Data Models\"", "comment": "Invited discussion of Choi and Yuan \"Matrix Completion When Missing Is Not at Random and Its Applications in Causal Panel Data Models\" at JSM 2025", "summary": "Choi and Yuan (2025) propose a novel approach to applying matrix completion to the problem of estimating causal effects in panel data. The key insight is that even in the presence of structured patterns of missing data -- i.e. selection into treatment -- matrix completion can be effective if the number of treated observations is small relative to the number of control observations. We applaud the authors for their insightful and interesting paper. We discuss this proposal from two complementary perspectives. First, we situate their proposal as an example of a \"split-apply-combine\" strategy that underlies many modern panel data estimators, including difference-in-differences and synthetic control approaches. Second, we discuss the issue of the statistical \"last mile problem\" -- the gap between theory and practice -- and offer suggestions on how to partially address it. We conclude by considering the challenges of estimating the impacts of public policies using panel data and apply the approach to a study on the effect of right to carry laws on violent crime."}
{"id": "2602.21334", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21334", "abs": "https://arxiv.org/abs/2602.21334", "authors": ["Oscar Jed R. Chuy", "Matthew T. Hale", "Vignesh Sivaramakrishnan", "Sean Phillips", "Ricardo G. Sanfelice"], "title": "Autonomous Satellite Rendezvous via Hybrid Feedback Optimization", "comment": "41 pages, 8 figures, 2 tables, Submitted to Nonlinear Analysis: Hybrid Systems 2026", "summary": "As satellites have proliferated, interest has increased in autonomous rendezvous, proximity operations, and docking (ARPOD). A fundamental challenge in these tasks is the uncertainties when operating in space, e.g., in measurements of satellites' states, which can make future states difficult to predict. Another challenge is that satellites' onboard processors are typically much slower than their terrestrial counterparts. Therefore, to address these challenges we propose to solve an ARPOD problem with feedback optimization, which computes inputs to a system by measuring its outputs, feeding them into an optimization algorithm in the loop, and computing some number of iterations towards an optimal input. We focus on satellite rendezvous, and satellites' dynamics are modeled using the continuous-time Clohessy-Wiltshire equations, which are marginally stable. We develop an asymptotically stabilizing controller for them, and we use discrete-time gradient descent in the loop to compute inputs to them. Then, we analyze the hybrid feedback optimization system formed by the stabilized Clohessy-Wiltshire equations with gradient descent in the loop. We show that this model is well-posed and that maximal solutions are both complete and non-Zeno. Then, we show that solutions converge exponentially fast to a ball around a rendezvous point, and we bound the radius of that ball in terms of system parameters. Simulations show that this approach provides up to a 98.4\\% reduction in the magnitude of disturbances across a range of simulations, which illustrates the viability of hybrid feedback optimization for autonomous satellite rendezvous."}
{"id": "2602.21770", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.21770", "abs": "https://arxiv.org/abs/2602.21770", "authors": ["Mohamed Foudad", "Miguel A. C. Teixeira", "Paul D. Williams", "Thorsten Kaluza"], "title": "A Generalized Richardson Number Diagnostic for Turbulence in the Free Atmosphere", "comment": "This article has been submitted to Journal of the Atmospheric Sciences", "summary": "A new Richardson number formulation, Ri_new, is introduced to improve the diagnosis of turbulence in the stratified free atmosphere, particularly near jet stream regions. The formulation is derived from the turbulent kinetic energy budget and accounts for both vertical wind shear and horizontal shear (deformation and divergence), weighted by the ratio of horizontal to vertical eddy viscosities (Kmh/Kmv). This extends the classical Richardson number Ri_old, which includes only vertical shear, and provides a physically based measure of the balance between stratification and three-dimensional shear production. The diagnostics Ri_new, Ri_old, and the widely used Turbulence Index 1 (TI1), computed from ERA5 reanalysis, are evaluated using more than 247 million automated turbulence reports from commercial aircraft (2017-2024). Across various turbulence intensity thresholds, Ri_new consistently outperforms the other diagnostics, resulting in higher AUC values and improved probability of detection at operationally relevant false-alarm rates. Sensitivity analyses show that the predictive skill of Ri_new is maximized for Kmh/Kmv values in the range 10^3-10^4, with peak performance near 5000 and weak dependence on horizontal resolution. Seasonal and regional evaluations indicate that the added value of Ri_new is largest where turbulence generation involves both vertical and horizontal shear, such as over the contiguous United States and during summer. Over oceans, performance remains high and Ri_new still provides the best overall discrimination skill. These results demonstrate that incorporating horizontal wind shear into the Richardson number yields a physically consistent and statistically robust improvement in turbulence diagnostics, with relevance for research and operational applications."}
{"id": "2602.21953", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.21953", "abs": "https://arxiv.org/abs/2602.21953", "authors": ["Taehyun Kim", "Israel F. Araujo", "Daniel K. Park"], "title": "Noise-adaptive hybrid quantum convolutional neural networks based on depth-stratified feature extraction", "comment": "22 pages, 9 figures, 4 tables (including Supplementary Information)", "summary": "Hierarchical quantum classifiers, such as quantum convolutional neural networks (QCNNs), represent recent progress toward designing effective and feasible architectures for quantum classification. However, their performance on near-term quantum hardware remains highly sensitive to noise accumulation across circuit depth, calling for strategies beyond circuit-architecture design alone. We propose a noise-adaptive hybrid QCNN that improves classification under noise by exploiting depth-stratified intermediate measurements. Instead of discarding qubits removed during pooling operations, we measure them and use the resulting outcomes as classical features that are jointly processed by a classical neural network. This hybrid hierarchical design enables noise-adaptive inference by integrating quantum intermediate measurements with classical post-processing. Systematic experiments across multiple circuit sizes and noise settings, including hardware-calibrated noise models derived from IBM Quantum backend data, demonstrate more stable convergence, reduced loss variability, and consistently higher classification accuracy compared with standard QCNNs. Moreover, we observe that this performance advantage significantly amplifies as the circuit size increases, confirming that the hybrid architecture mitigates the scaling limitations of standard architectures. Notably, the multi-basis measurement variant attains performance close to the noiseless limit even under realistic noise. While demonstrated for QCNNs, the proposed depth-stratified feature extraction applies more broadly to hierarchical quantum classifiers that progressively discard qubits."}
{"id": "2602.22071", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.22071", "abs": "https://arxiv.org/abs/2602.22071", "authors": ["I. Festi", "E. Alfinelli", "D. Bessas", "F. Caporaletti", "A. I. Chumakov", "M. Moratalla", "M. A. Ramos", "M. Rodríguez-López", "C. Rodríguez-Tinoco", "J. Rodríguez-Viejo", "G. Baldi"], "title": "Effect of glass stability on the low frequency vibrations of vapor deposited glasses", "comment": "19 pages, 13 figures. Phys. Rev. X - Accepted 23 February, 2026. DOI: https://doi.org/10.1103/311v-1ftn", "summary": "Ultra-stable glasses prepared from the physical vapor deposition of organic molecules present a very low density of two-level states, the kind of glass defects that determine their peculiar low temperature thermal properties. Numerical simulations suggest that quasi-localized harmonic vibrational modes emerge in the soft regions associated with two-level states. However, the connection between the low frequency vibrational modes and the local structural instabilities of glasses remains unexplained. Here we exploit a recently developed spectrograph for nuclear resonant analysis of inelastic X-ray scattering to probe the density of vibrational states of amorphous thin films of ultra-stable and conventional glasses down to an exceptionally low frequency of $\\sim 70$ GHz. We show that the glass stability does not affect the harmonic vibrational modes at the lowest frequencies, despite a reduction of almost an order of magnitude in the density of two-level states. At the same time, the vibrational modes at higher frequencies, around the boson peak maximum, are extremely sensitive to the glass stability. Although we cannot exclude the possible existence of quasi-localized modes in glasses, we show that their presence is not strictly necessary to describe the measured density of low frequency vibrations. The experimental developments here presented pave the way to the solution to the long-standing debate on the low frequency vibrations in glasses."}
{"id": "2602.21369", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.21369", "abs": "https://arxiv.org/abs/2602.21369", "authors": ["Roberto Cantillan", "Mauricio Bucca"], "title": "Structurally Conditioned Diffusion Reproduces Skills-Based Stratification", "comment": "19 pages, 4 figures. Preprint", "summary": "Occupational hierarchies remain strikingly stable even as job content changes rapidly. We ask whether skill requirements propagate directionally along the wage hierarchy or follow symmetric diffusion. Using O*NET 2015-2024, we analyze 17.3 million directed diffusion opportunities linking 873 occupations and 161 skills. We show that propagation obeys an Asymmetric Trajectory Channeling (ATC) rule: the same requirement spreads differently upward and downward, and the asymmetry depends on skill domain and on the architecture of skill dependencies. Two mechanisms generate ATC. Directional incorporation asymmetry implies that wage gradients create distinct receiving environments: upward-moving socio-cognitive requirements encounter complementary infrastructure, whereas upward-moving sensory/physical requirements face structural indifference. Structural portability constraints imply that dependency position governs portability: requirements anchoring long prerequisite chains carry co-adoption burdens that restrict diffusion regardless of destination. Consistent with these mechanisms, socio-cognitive requirements propagate upward more often than downward (20.7% vs 14.9%), while sensory/physical requirements exhibit the mirror pattern (19.5% downward vs 10.3% upward). Nestedness amplifies these asymmetries in opposite directions: scaffolding capabilities ascend most readily, whereas structurally embedded physical requirements are most tightly confined. Identification leverages within-occupation variation in propagation direction, and results are robust to origin- and destination-side specifications. Together, these findings reveal a directional architecture of occupational change that can reproduce hierarchy through ongoing reconfiguration, even absent assortative preferences or coordinated action."}
{"id": "2602.21299", "categories": ["cond-mat.str-el", "physics.chem-ph", "physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21299", "abs": "https://arxiv.org/abs/2602.21299", "authors": ["Zhen Tao", "Victor Galitski"], "title": "Ab Initio Random Matrix Theory of Molecular Electronic Structure", "comment": "8 pages, 8 figures", "summary": "We use ab initio electronic-structure methods to investigate random-matrix theory (RMT) universality in molecular electronic structure. Using single-reference electronic structure methods, including Hartree-Fock, configuration-interaction singles (CIS), density functional theory, and linear-response time-dependent density-functional theory, we compute single-particle orbital energies and many-electron excitations of several representative molecules (benzene, alanine, 1-phenylethylamine, methyloxirane, and helicene chains). For generic low-symmetry geometries, the unfolded spectra of these ab initio Hamiltonians exhibit Wigner-Dyson level statistics of the Gaussian orthogonal ensemble (GOE). For extended helicene chains we explicitly restrict to bound valence excitations below the ionization threshold and still observe GOE statistics, indicating that the RMT universality is present for physical states of direct relevance to real molecules. We further explore the electric and magnetic field dependence of the molecular electronic spectra. The variance of electric polarizability (level curvature K) is predicted to be non-analytic in the magnetic field which serves as an infrared cutoff, <K^2> proportional to log(1/|B|). We observe a transition to the Gaussian unitary ensemble (GUE) by increasing the magnetic fields, although it occurs only at magnetic fields far beyond experimentally accessible scales. Our results indicate that random matrix universality provides a general framework for organizing ab initio predictions of interacting electron spectra in complex systems."}
{"id": "2602.21253", "categories": ["quant-ph", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.21253", "abs": "https://arxiv.org/abs/2602.21253", "authors": ["Marwa R. Hassan", "Naima Kaabouch"], "title": "A Physics-Informed Neuro-Fuzzy Framework for Quantum Error Attribution", "comment": null, "summary": "As quantum processors scale beyond 100 qubits, distinguishing software bugs from stochastic hardware noise becomes a critical diagnostic challenge. We present a neuro-fuzzy framework that addresses this attribution problem by combining Adaptive Neuro-Fuzzy Inference Systems (ANFIS) with physics-grounded feature engineering. We introduce the Bhattacharyya Veto, a hard physical constraint grounded in the Data Processing Inequality that prevents the classifier from attributing topologically impossible output distributions to noise. Validated on IBM's 156-qubit Heron r2 processor (ibm_fez) across 105 circuits spanning 17 algorithm families, the framework achieves 89.5% effective accuracy (+/- 5.9% CI). The system implements a safe failure mode, flagging 14.3% of ambiguous cases for manual review rather than forcing low-confidence predictions. We resolve key ambiguities -- such as distinguishing correct Grover amplification from bug-induced collapse -- and identify fundamental limits of single-basis diagnostics, including a Z-basis blind spot where phase-flip errors remain statistically invisible. This work establishes a robust, interpretable diagnostic layer that prevents error mitigation techniques from being applied to logically flawed circuits."}
{"id": "2602.22061", "categories": ["quant-ph", "cs.LG", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.22061", "abs": "https://arxiv.org/abs/2602.22061", "authors": ["Quoc Hoan Tran", "Koki Chinzei", "Yasuhiro Endo", "Hirotaka Oshima"], "title": "Learning Quantum Data Distribution via Chaotic Quantum Diffusion Model", "comment": "12 pages, 7 figures; extended version from Poster in Workshop: Machine Learning and the Physical Sciences https://neurips.cc/virtual/2025/loc/san-diego/123072", "summary": "Generative models for quantum data pose significant challenges but hold immense potential in fields such as chemoinformatics and quantum physics. Quantum denoising diffusion probabilistic models (QuDDPMs) enable efficient learning of quantum data distributions by progressively scrambling and denoising quantum states; however, existing implementations typically rely on circuit-based random unitary dynamics that can be costly to realize and sensitive to control imperfections, particularly on analog quantum hardware. We propose the chaotic quantum diffusion model, a framework that generates projected ensembles via chaotic Hamiltonian time evolution, providing a flexible and hardware-compatible diffusion mechanism. Requiring only global, time-independent control, our approach substantially reduces implementation overhead across diverse analog quantum platforms while achieving accuracy comparable to QuDDPMs. This method improves trainability and robustness, broadening the applicability of quantum generative modeling."}
{"id": "2602.21705", "categories": ["hep-lat", "cond-mat.str-el", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.21705", "abs": "https://arxiv.org/abs/2602.21705", "authors": ["Jian-Gang Kong", "Shinichiro Akiyama", "Tao Shi", "Z. Y. Xie"], "title": "Phase diagram of the single-flavor Gross--Neveu--Wilson model from the Grassmann corner transfer matrix renormalization group", "comment": null, "summary": "We investigate the phase structure of the single-flavor Gross--Neveu model with Wilson fermions using the Grassmann corner transfer matrix renormalization group (CTMRG). The path integral is formulated as a two-dimensional Grassmann tensor network and approximately contracted by the Grassmann CTMRG algorithm. We investigate the phase diagram by varying the fermion mass and the four-fermion coupling, using the pseudoscalar condensate as an order parameter for the $\\mathbb{Z}_{2}$ parity symmetry breaking phase. The universality classes of the phase boundaries are identified through the central charge $c$ obtained via scaling analysis of the entanglement entropy. Furthermore, we extract the quantity related to the entanglement spectrum from the converged CTMRG environments, allowing us to distinguish the topological insulator phase and the trivial phase. The resulting phase structure suggests that the Aoki phase is separated from the other phases by critical lines characterized by $c=1/2$, while the critical lines with $c=1$ separate the topological insulating and trivial phases. Our numerical results also indicate that the Aoki phase does not persist in the strong-coupling regime for the single-flavor theory."}
{"id": "2602.21541", "categories": ["cond-mat.stat-mech", "cond-mat.quant-gas", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.21541", "abs": "https://arxiv.org/abs/2602.21541", "authors": ["Taiki Ishiyama", "Kazuya Fujimoto", "Tomohiro Sasamoto"], "title": "Integral formula for the propagator of the one-dimensional Hubbard model", "comment": null, "summary": "We present an exact integral formula for the multi-particle propagator of the one-dimensional Fermi--Hubbard model on an infinite lattice. The proof is based on the nested Bethe ansatz without relying on the string hypothesis. Our formula enables an explicit integral representation of the time evolution of arbitrary finite-particle wave functions and thereby provides a foundation for the exact analysis of nonequilibrium dynamics in the Hubbard model. It can further be applied to related open quantum models."}
{"id": "2602.21423", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21423", "abs": "https://arxiv.org/abs/2602.21423", "authors": ["Patrick Kramer", "Edward H. Kennedy", "Isaac M. Opper"], "title": "Causal Inference with High-Dimensional Treatments", "comment": null, "summary": "In this work, we consider causal inference in various high-dimensional treatment settings, including for single multi-valued treatments and vector treatments with binary or continuous components, when the number of treatments can be comparable to or even larger than the number of observations. These settings bring unique challenges: first, the treatment effects of interest are a high-dimensional vector rather than a low-dimensional scalar; second, positivity violations are often unavoidable; and third, estimation can be based on a smaller effective sample size. We first discuss fundamental limits of estimating effects here, showing that consistent estimation is impossible without further assumptions. We go on to propose a novel sparse pseudo-outcome regression framework for arbitrary high-dimensional statistical functionals, which includes generic constrained regression estimators and error guarantees. We use the framework to derive new doubly robust estimators for mean potential outcomes of high-dimensional treatments, though it can also be applied to other scenarios. We analyze the proposed estimators under exact and approximate sparsity assumptions, giving finite-sample risk bounds. Finally, we derive minimax lower bounds to characterize optimal rates of convergence and show our risk bounds are unimprovable."}
{"id": "2602.21352", "categories": ["math.OC", "math.AP", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.21352", "abs": "https://arxiv.org/abs/2602.21352", "authors": ["Chiu-Yen Kao", "Seyyed Abbas Mohammadi", "Braxton Osting"], "title": "An accelerated rearrangement method for two-phase composite optimization", "comment": "21 pages, 7 figures", "summary": "We propose and analyze an Accelerated Rearrangement Method (ARM) for solving a class of nonconvex optimization problems involving two-phase composites. These problems include maximizing the (work) energy of a membrane governed by the Poisson equation and minimizing the principal eigenvalue of a weighted Dirichlet-Laplacian, both subject to material distribution constraints. Building on the classical rearrangement method, we introduce momentum-like acceleration by extrapolating the Fréchet derivative, leading to a provably convergent algorithm. We also introduce a restarted variant that guarantees monotonic improvement of the objective. In one dimension, we derive asymptotic convergence rates for ARM and prove that they improve upon the classical rearrangement method. Numerical experiments in both two and three dimensions confirm the accelerated convergence and demonstrate practical efficiency."}
{"id": "2602.21574", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.21574", "abs": "https://arxiv.org/abs/2602.21574", "authors": ["Na Li", "Yongchao Zhao"], "title": "Convergence Analysis of a Linear, Unconditionally Energy-Stable SAV Finite Element Method for the Cahn-Hilliard Equation", "comment": null, "summary": "This paper proposes a finite element scheme, based on the Scalar Auxiliary Variable (SAV) approach, for the Cahn-Hilliard equation--a model that possesses significant physical relevance and a rich mathematical structure. A convergence analysis of the fully discrete scheme is conducted under suitable regularity assumptions, confirming optimal-order convergence in both time and space for the phase variable, chemical potential, and auxiliary variable in the H1-norm. Furthermore, the scheme is proven to be unconditionally energy stable. Finally, a numerical example is presented to demonstrate the effectiveness of the method and to confirm the theoretical convergence rates."}
{"id": "2602.21525", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21525", "abs": "https://arxiv.org/abs/2602.21525", "authors": ["Chuanghong Weng", "Ehsan Nekouei"], "title": "Optimal Real-Time Fusion of Time-Series Data Under Rényi Differential Privacy", "comment": null, "summary": "In this paper, we investigate the optimal real-time fusion of data collected by multiple sensors. In our set-up, the sensor measurements are considered to be private and are jointly correlated with an underlying process. A fusion center combines the private sensor measurements and releases its output to an honest-but-curious party, which is responsible for estimating the state of the underlying process based on the fusion center's output. The privacy leakage incurred by the fusion policy is quantified using Rényi differential privacy. We formulate the privacy-aware fusion design as a constrained finite-horizon optimization problem, in which the fusion policy and the state estimation are jointly optimized to minimize the state estimation error subject to a total privacy budget constraint. We derive the constrained optimality conditions for the proposed optimization problem and use them to characterize the structural properties of the optimal fusion policy. Unlike classical differential privacy mechanisms, the optimal fusion policy is shown to adaptively allocates the privacy budget and regulates the adversary's belief in a closed-loop manner. To reduce the computational burden of solving the resulting constrained optimality equations, we parameterize the fusion policy using a structured Gaussian distribution and show that the parameterized fusion policy satisfies the privacy constraint. We further develop a numerical algorithm to jointly optimize the fusion policy and state estimator. Finally, we demonstrate the effectiveness of the proposed fusion framework through a traffic density estimation case study."}
{"id": "2602.21242", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.21242", "abs": "https://arxiv.org/abs/2602.21242", "authors": ["Anirudh Jonnalagadda", "Walter Rocchia", "Sauro Succi"], "title": "Generalized Onsager-Regularized Lattice Boltzmann Method for error-free Navier-Stokes models on standard lattices", "comment": null, "summary": "This work presents a novel strategy to address Navier-Stokes modelling errors arising on first-nearest neighbour lattice Boltzmann (LB) methods and introduces fully local corrections through Onsager-Regularized (OReg) non-equilibrium populations. The proposed mechanism, which admits partially and completely corrected OReg models, is used to develop representative partially and completely corrected models for the six-moment-constrained guided equilibrium (GEq) representation on the D2Q9 lattice. The former realization only addresses compatibility condition violations and improves the accuracy by two/four orders of magnitude at reference/arbitrary lattice temperatures respectively, while the latter additionally corrects stress tensor modelling errors, resulting in a fully corrected exact model. Numerical benchmarks of the corrected schemes demonstrate improved accuracy and stability in comparison to the Lattice-BGK and uncorrected OReg-GEq schemes thus presenting a promising avenue for OReg based thermohydrodynamic extensions."}
{"id": "2602.21236", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.21236", "abs": "https://arxiv.org/abs/2602.21236", "authors": ["Matteo Migliarini", "Berat Ercevik", "Oluwagbemike Olowe", "Saira Fatima", "Sarah Zhao", "Minh Anh Le", "Vasu Sharma", "Ashwinee Panda"], "title": "@GrokSet: multi-party Human-LLM Interactions in Social Media", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed as active participants on public social media platforms, yet their behavior in these unconstrained social environments remains largely unstudied. Existing datasets, drawn primarily from private chat interfaces, lack the multi-party dynamics and public visibility crucial for understanding real-world performance. To address this gap, we introduce @GrokSet, a large-scale dataset of over 1 million tweets involving the @Grok LLM on X. Our analysis reveals a distinct functional shift: rather than serving as a general assistant, the LLM is frequently invoked as an authoritative arbiter in high-stakes, polarizing political debates. However, we observe a persistent engagement gap: despite this visibility, the model functions as a low-status utility, receiving significantly less social validation (likes, replies) than human peers. Finally, we find that this adversarial context exposes shallow alignment: users bypass safety filters not through complex jailbreaks, but through simple persona adoption and tone mirroring. We release @GrokSet as a critical resource for studying the intersection of AI agents and societal discourse."}
{"id": "2602.21383", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21383", "abs": "https://arxiv.org/abs/2602.21383", "authors": ["Mengbing Li", "Inbal Nahum-Shani", "Walter Dempsey"], "title": "Evaluating time-varying treatment effects in hybrid SMART-MRT designs", "comment": null, "summary": "Recently a new experimental approach, the hybrid experimental design (HED), was introduced to enable investigators to answer scientific questions about building behavioral interventions in which human-delivered and digital components are integrated and adapted on multiple timescales: slow (e.g., every few weeks) and fast (e.g., every few hours), respectively. An increasingly common HED involves the integration of the sequential, multiple assignment, randomized trial (SMART) with the micro-randomized trial (MRT), allowing investigators to answer scientific questions about potential synergistic effects of digital and human-delivered interventions. Approaches to formalize these questions in terms of causal estimands and associated data analytic methods are limited. In this paper, we formally define and assess these synergistic effects in hybrid SMART-MRTs on both proximal and distal outcomes. Practical utility is shown through the analysis of M-Bridge, a hybrid SMART-MRT aimed at reducing binge drinking among first-year college students."}
{"id": "2602.21525", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21525", "abs": "https://arxiv.org/abs/2602.21525", "authors": ["Chuanghong Weng", "Ehsan Nekouei"], "title": "Optimal Real-Time Fusion of Time-Series Data Under Rényi Differential Privacy", "comment": null, "summary": "In this paper, we investigate the optimal real-time fusion of data collected by multiple sensors. In our set-up, the sensor measurements are considered to be private and are jointly correlated with an underlying process. A fusion center combines the private sensor measurements and releases its output to an honest-but-curious party, which is responsible for estimating the state of the underlying process based on the fusion center's output. The privacy leakage incurred by the fusion policy is quantified using Rényi differential privacy. We formulate the privacy-aware fusion design as a constrained finite-horizon optimization problem, in which the fusion policy and the state estimation are jointly optimized to minimize the state estimation error subject to a total privacy budget constraint. We derive the constrained optimality conditions for the proposed optimization problem and use them to characterize the structural properties of the optimal fusion policy. Unlike classical differential privacy mechanisms, the optimal fusion policy is shown to adaptively allocates the privacy budget and regulates the adversary's belief in a closed-loop manner. To reduce the computational burden of solving the resulting constrained optimality equations, we parameterize the fusion policy using a structured Gaussian distribution and show that the parameterized fusion policy satisfies the privacy constraint. We further develop a numerical algorithm to jointly optimize the fusion policy and state estimator. Finally, we demonstrate the effectiveness of the proposed fusion framework through a traffic density estimation case study."}
{"id": "2602.21976", "categories": ["physics.ao-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2602.21976", "abs": "https://arxiv.org/abs/2602.21976", "authors": ["Jacques Vanneste", "William R. Young"], "title": "A consistent phase-averaged model of the interactions between surface gravity waves and currents", "comment": null, "summary": "We formulate a model of the two-way interactions between surface gravity waves and ocean currents. The model couples the transport of wave action in the four-dimensional (horizontal) position--wavevector phase space with the Craik--Leibovich system for the currents. Coupling is via the Doppler shift in the dispersion relation governing action transport, and wave pseudomomentum in the Craik--Leibovich system. The velocity in the Doppler shift is a vertical integral of the Lagrangian mean velocity of the currents, with a weight that is consistent with the vertical structure of the pseudomomentum. This consistency ensures conservation of momentum and energy in the coupled wave--current system.\n  The conservation properties of the wave--current model stem from an underlying variational structure. We derive this structure from that of the rotating Euler equations for an incompressible fluid with free surface by introducing a Lagrangian wave--mean decomposition, making simplifying approximations, and Whitham averaging.\n  We apply the wave--current model to the problem of generation of inertial oscillations by surface waves originally considered by Hasselmann."}
{"id": "2602.22198", "categories": ["cond-mat.dis-nn", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2602.22198", "abs": "https://arxiv.org/abs/2602.22198", "authors": ["Gieberth Rodriguez-Lopez", "Ezequiel E. Ferrero"], "title": "Thermal activation drives a finite-size crossover from scale-free to runaway avalanches in amorphous solids", "comment": "14 pages, 10 figures", "summary": "We investigate thermal avalanche dynamics in amorphous solids using elastoplastic models with local activation rules and no external driving. Dynamical heterogeneities, quantified through persistence measurements and the associated four-point susceptibility $χ_4$, reveal the emergence of correlated spatiotemporal rearrangements as temperature is varied. As temperature increases, avalanche statistics evolve from scale-free behavior with exponential cutoffs to regimes dominated by system-spanning runaway events. We identify a system-size-dependent critical temperature $T_c(L)$ that separates intermittent avalanche dynamics from thermally assisted flow, where self-sustained avalanches transiently fluidize the system. We show that $T_c(L)$ decreases algebraically with increasing system size, suggesting that in the thermodynamic limit arbitrarily small but finite temperatures may destabilize the intermittent regime. The relation between avalanche size and duration resembles that in sheared systems, whereas the statistics of minimal distances to yielding reveal a temperature-driven reorganization of marginal stability absent in strictly driven overdamped dynamics. Our results demonstrate that thermal activation alone can generate a finite-size-controlled instability scale in disordered elastic media."}
{"id": "2602.21491", "categories": ["physics.soc-ph", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.21491", "abs": "https://arxiv.org/abs/2602.21491", "authors": ["Varun K. Rao", "Ryan Higgs", "Hautahi Kingi", "Filippo Radicchi", "Santo Fortunato", "Maria Litvinova"], "title": "Modeling plant disease spread via high-resolution human mobility networks", "comment": "11 pages, 7 figures", "summary": "Human mobility plays a crucial role in the spread of human diseases, but is rarely quantified in plant disease epidemics. To address this gap, we integrate a unique, high-resolution network of human movements in New Zealand with a metapopulation model to mechanistically simulate pathogen transmission. We calibrate the model on the nationwide 2010 kiwifruit vine disease (Psa-V) outbreak, and show that it accurately reproduces the observed spatiotemporal spread, confirming that the human mobility network is a strong foundation for modeling transmission dynamics. By analyzing spatial infection trends, we find that most dispersal occurs locally, as often illustrated in the plant-outbreak literature. However, sporadic long-range connections are necessary to model a nationwide outbreak. Using the model as an in-silico laboratory, we demonstrate that enhanced surveillance accelerates detection and that outbreak severity is highly sensitive to the timing and location of initial disease importation. We observe a potential causal link between seasonal labor patterns and epidemic risk in high-traffic seasons. This study provides a robust, data-driven framework for modeling and predicting the spatiotemporal spread of agricultural pathogens. It underscores the importance of leveraging human mobility networks to design timely interventions and surveillance systems, protecting global food security."}
{"id": "2602.21301", "categories": ["cond-mat.str-el", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21301", "abs": "https://arxiv.org/abs/2602.21301", "authors": ["Chih-Yu Lo", "Xueda Wen"], "title": "Detecting Higher Berry Phase via Boundary Scattering", "comment": null, "summary": "Higher Berry phase has recently been proposed to study the topology of the space of gapped many-body quantum systems. In this work, we develop a boundary-scattering approach to detect higher Berry phases in one-dimensional gapped free-fermion systems. By coupling a gapless lead to the gapped system, we demonstrate that the higher Berry invariant can be obtained by studying the higher winding number of the boundary reflection matrix. The resulting topological invariant is robust against perturbations such as disorder. Our approach establishes a connection between higher Berry invariants and transport properties, thereby providing a potentially experimentally accessible probe of parametrized topological phases."}
{"id": "2602.21288", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21288", "abs": "https://arxiv.org/abs/2602.21288", "authors": ["Sneha Narasimha Moorthy", "Andrew Geraci", "Sougato Bose", "Anupam Mazumdar"], "title": "Random Acceleration Noise on Stern-Gerlach Interferometry in a Harmonic Trap", "comment": "13 pages, 7 figures", "summary": "We analyze decoherence in a one-loop Stern--Gerlach--type matter-wave interferometer for a massive nanoparticle embedded with a nitrogen vacancy (NV)-centred nanodiamond evolving under an effective harmonic-oscillator dynamics in a magnetic-field gradient. We assume that the Stern-Gerlach interferometer is subjected to a random acceleration noise external to the system. This could be along the direction of the superposition at an angle which can be varied. We quantify dephasing from two noise channels: fluctuations in the external acceleration $a(t)$ magnitude and direction as specified by the tilt angle $θ_0(t)$ between the superposition axis and the acceleration. At the level of the action, we treat these two external noise as stochastic inputs, and compute the resulting stochastic arm-phase difference, and obtain the dephasing rate $Γ$ using the Wiener--Khinchin theorem. For a white noise and a coherence target $Γτ\\leq 1$ and by assuming that we finish the one-loop interferometer within $τ=2π/ω_0\\simeq 0.015~\\mathrm{s}$, for a reasonable choice of the magnetic field gradient, $η_0=6\\times 10^{3}~\\mathrm{T\\,m^{-1}}$ and mass of the nanodiamond, $m=10^{-15}~\\mathrm{kg}$) to create a superposition size of $Δx\\sim 1$nm. We find $\\sqrt{\\mathcal{S}_{aa}}\\lesssim \\mathcal{O}(10^{-11})~\\mathrm{m\\,s^{-2}\\,Hz^{-1/2}}$ even if we take the external acceleration, $a=0~{\\rm ms^{-2}}$ and $θ_0=0^\\circ$ (along the dirction of the superposition), and $\\sqrt{\\mathcal{S}_{θθ}}\\lesssim \\mathcal{O}(10^{-10})~\\mathrm{rad\\,Hz^{-1/2}}$ for $a=g= 9.81~\\mathrm{m\\,s^{-2}}$ and $θ_0=0^\\circ$ (superposition direction is perpendicular to the Earth's gravity). We have also found an operating regime where the acceleration noise can be minimized by either varying $θ_0$ or $a$ for a fixed set of other experimental parameters."}
{"id": "2505.00476", "categories": ["quant-ph", "hep-lat"], "pdf": "https://arxiv.org/pdf/2505.00476", "abs": "https://arxiv.org/abs/2505.00476", "authors": ["Michael Hite"], "title": "Improved Fermionic Scattering for the NISQ Era", "comment": null, "summary": "In the era of noisy intermediate scale quantum (NISQ) hardware, digital quantum computers are limited to shallow circuits on the order of a thousand layers due to system noise and qubit decoherence. Thus, every step of a simulation must be as efficient as possible. Modifying the recent Givens Rotation state preparation by Chai et al and ladder operator block encoding method by Simon et al, we propose a scattering state preparation method that approximates the fermionic wave packets by localizing them in space, reducing circuit depth by nearly half, while also preserving fermionic anti-commutation relations. Using MPS simulations, we show that these approximated wave packets approach the exact wave packets in weakly interacting critical theories; and then show its immediate application on modern day hardware with IonQ's Forte 1 machine."}
{"id": "2602.21635", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.21635", "abs": "https://arxiv.org/abs/2602.21635", "authors": ["Tobias Galla"], "title": "A diffusion approximation for systems with frequent weak resetting", "comment": "6+2+12 pages, 5+6 figures", "summary": "We develop a diffusion approximation for systems subject to fast random resetting by small amplitudes. Equivalently, this describes systems with frequent but small catastrophes. We demonstrate the validity of the approximation by computing the stationary distribution and mean first-passage times of simple one-dimensional systems. The approximation captures dynamically induced correlations in multi-particle systems, and it can be used to generalise the conditionally independent and identically distributed structure recently found in systems with full resetting. Finally, we show that resetting can induce cycles and patterns, which can be characterised using the diffusion approximation."}
{"id": "2602.21465", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2602.21465", "abs": "https://arxiv.org/abs/2602.21465", "authors": ["Nahom Seyoum"], "title": "Exponential Concentration Inequalities For Independent Random Vectors Under Sublinear Expectations", "comment": null, "summary": "Li and Hu recently established variance-type O(1/n) bounds for the sample mean of independent random vectors under sublinear expectations. We extend their results to the exponential concentration regime. For bounded, independent R^d-valued random vectors under a regular sublinear expectation, we prove: (i) a general concentration principle that reduces vector-valued tail bounds to scalar martingale inequalities via a three-layer architecture; (ii) an Azuma-Hoeffding inequality showing that the distance from the sample mean to the Minkowski average of the expectation sets has sub-Gaussian tails; (iii) a Bernstein inequality incorporating the variance parameter of Li and Hu, interpolating between sub-Gaussian and sub-exponential regimes; (iv) a dimension-free bound replacing the exponential covering prefactor with a polynomial one via the matrix Freedman inequality; and (v) an explicit construction demonstrating that the sub-Gaussian rate is optimal. To the best of our knowledge, these constitute the first exponential concentration inequalities for the multivariate sample mean under sublinear expectations in terms of the set-valued distance to the Minkowski average."}
{"id": "2602.21376", "categories": ["math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21376", "abs": "https://arxiv.org/abs/2602.21376", "authors": ["Xi Lin", "Yafeng Yin", "Tianming Liu"], "title": "Fenchel-Young Estimators of Perturbed Utility Models", "comment": "48 pages, 11 figures", "summary": "The Perturbed Utility Model framework offers a powerful generalization of discrete choice analysis, unifying models like Multinomial Logit and Sparsemax through convex optimization. However, standard Maximum Likelihood Estimation (MLE) faces severe theoretical and numerical challenges when applied to this broader class, particularly regarding non-convexity and instability in sparse regimes. To resolve these issues, this paper introduces a unified estimation framework based on the Fenchel-Young loss. By leveraging the intrinsic convex conjugate structure of PUMs, we demonstrate that the Fenchel-Young estimator guarantees global convexity and bounded gradients, providing a mathematically natural alternative to MLE. Addressing the critical challenge of data scarcity, we further extend this framework via Wasserstein Distributionally Robust Optimization. We first derive an exact finite-dimensional reformulation of the infinite-dimensional primal problem, establishing its theoretical convexity. However, recognizing that the resulting worst-case constraints involve computationally intractable inner maximizations, we subsequently construct a tractable safe approximation by exploiting the global Lipschitz continuity of the Fenchel-Young loss. Through this tractable formulation, we uncover a rigorous geometric unification: two canonical regularization techniques, standard L2-regularization and the margin-enforcing Hinge loss, emerge mathematically as specific limiting cases of our distributionally robust estimator. Extensive experiments on synthetic data and the Swissmetro benchmark validate that the proposed framework significantly outperforms traditional methods, recovering stable preferences even under severe data limitations."}
{"id": "2602.21685", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.21685", "abs": "https://arxiv.org/abs/2602.21685", "authors": ["H. M. Verhelst", "L. Greco", "A. Reali"], "title": "Adaptive isogeometric analysis of high-order phase-field fracture based on THB-splines", "comment": null, "summary": "In recent decades, the study of fracture propagation in solids has increasingly relied on phase-field models. Several recent contributions have highlighted the potential of this approach in both static and dynamic frameworks. However, a major limitation remains the high computational cost. Two main strategies have been identified to mitigate this issue: the use of locally refined meshes and the adoption of higher-order models. In this work, leveraging Truncated Hierarchical B-splines (THB-splines), we introduce adaptive simulations of higher-order phase-field formulations (AT1 and AT2), focusing primarily on two-dimensional fracture problems."}
{"id": "2602.21567", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21567", "abs": "https://arxiv.org/abs/2602.21567", "authors": ["Linhan Fang", "Elias Raffoul", "Xingpeng Li"], "title": "Diagnosis-Driven Co-planning of Network Reinforcement and BESS for Distribution Grid with High Penetration of Electric Vehicles", "comment": null, "summary": "While the rapid proliferation of electric vehicles (EVs) accelerates net-zero goals, uncoordinated charging activities impose severe operational challenges on distribution grids, including exacerbated peak loads, thermal overloading, and voltage violations. To overcome the computational intractability of jointly optimizing grid infrastructure reinforcements and battery energy storage system (BESS) installations, this paper proposes a novel three-stage diagnosis-driven co-planning (DDCP) framework. The methodology integrates a violation detection and quantification (VDQ) model to systematically identify system breaches, and a violation-mitigated BESS planning (VMBP) model for optimal BESS sitting and sizing. Specifically, Stage I of the DDCP framework diagnoses critical bottleneck lines that render standalone BESS solutions infeasible. Stage II targets cable upgrades exclusively at the Top-N prioritized bottleneck lines and Stage III then executes the optimal BESS deployment using a network-enhanced VMBP model. Furthermore, this study quantifies the EV hosting capacity thresholds before and after BESS integration across varying EV adoption rates and base voltages. Finally, a comprehensive comparative analysis evaluates four mitigation approaches: the VDQ-driven cable upgrade (VCU) model, the VMBP model, system-wide voltage uprating, and the proposed DDCP framework. The results demonstrate that the DDCP framework not only resolves the complex joint-optimization hurdle but also achieves the high techno-economic superiority in addressing high-EV-penetration challenges."}
{"id": "2602.21244", "categories": ["physics.comp-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2602.21244", "abs": "https://arxiv.org/abs/2602.21244", "authors": ["Ehsan Roohi", "Ahmad Shoja-Sani", "Stefan Stefanov"], "title": "Physics Constrained Neural Collision Operators for Variable Hard Sphere Surrogates and Ab Initio Angle Prediction in Direct Simulation Monte Carlo", "comment": null, "summary": "The Direct Simulation Monte Carlo (DSMC) method is the gold standard for non-equilibrium rarefied gas dynamics, yet its computational cost can be prohibitive, especially for near-continuum regimes and high-fidelity \\emph{ab initio} potentials. This work develops a unified, physics-constrained neural-operator framework that accelerates DSMC while preserving physical invariants and stochasticity required for long-time kinetic simulations. First, we introduce a local neural collision kernel replacing the phenomenological Variable Hard Sphere (VHS) model. To overcome the variance suppression and artificial cooling inherent to purely deterministic regression surrogates, we augment inference with a physics-constrained stochastic layer. Controlled latent-noise injection restores thermal fluctuations, while cell-wise moment-matching strictly enforces momentum and kinetic-energy conservation. Remarkably, this operator exhibits zero-shot spatial and thermodynamic generalization: a model trained exclusively on 1D Couette flow accurately simulates a complex 2D lid-driven cavity, capturing high-order non-equilibrium moments without retraining.Second, to bypass the extreme cost of quantum-mechanical scattering, we develop a dedicated \\emph{ab initio} neural operator for the Jäger interaction potential. Trained via a \\emph{physics harvesting} strategy on large-scale collision pairs, it efficiently captures the high-energy scattering dynamics dominating hypersonic regimes. Validated on a Mach~10 rarefied argon flow over a cylinder, the framework reproduces transport behaviors and shock features with high fidelity, achieving an approximate 20\\% cost reduction relative to direct numerical integration."}
{"id": "2602.21650", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21650", "abs": "https://arxiv.org/abs/2602.21650", "authors": ["Zichen Song", "Weijia Li"], "title": "PPCR-IM: A System for Multi-layer DAG-based Public Policy Consequence Reasoning and Social Indicator Mapping", "comment": null, "summary": "Public policy decisions are typically justified using a narrow set of headline indicators, leaving many downstream social impacts unstructured and difficult to compare across policies. We propose PPCR-IM, a system for multi-layer DAG-based consequence reasoning and social indicator mapping that addresses this gap. Given a policy description and its context, PPCR-IM uses an LLM-driven, layer-wise generator to construct a directed acyclic graph of intermediate consequences, allowing child nodes to have multiple parents to capture joint influences. A mapping module then aligns these nodes to a fixed indicator set and assigns one of three qualitative impact directions: increase, decrease, or ambiguous change. For each policy episode, the system outputs a structured record containing the DAG, indicator mappings, and three evaluation measures: an expected-indicator coverage score, a discovery rate for overlooked but relevant indicators, and a relative focus ratio comparing the systems coverage to that of the government. PPCR-IM is available both as an online demo and as a configurable XLSX-to-JSON batch pipeline."}
{"id": "2602.21403", "categories": ["stat.ME", "cs.CE", "eess.SP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.21403", "abs": "https://arxiv.org/abs/2602.21403", "authors": ["Luca Martino", "Eduardo Morgado", "Roberto San Millán-Castillo"], "title": "An index of effective number of variables for uncertainty and reliability analysis in model selection problems", "comment": null, "summary": "An index of an effective number of variables (ENV) is introduced for model selection in nested models. This is the case, for instance, when we have to decide the order of a polynomial function or the number of bases in a nonlinear regression, choose the number of clusters in a clustering problem, or the number of features in a variable selection application (to name few examples). It is inspired by the idea of the maximum area under the curve (AUC). The interpretation of the ENV index is identical to the effective sample size (ESS) indices concerning a set of samples. The ENV index improves {drawbacks of} the elbow detectors described in the literature and introduces different confidence measures of the proposed solution. These novel measures can be also employed jointly with the use of different information criteria, such as the well-known AIC and BIC, or any other model selection procedures. Comparisons with classical and recent schemes are provided in different experiments involving real datasets. Related Matlab code is given."}
{"id": "2602.21567", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21567", "abs": "https://arxiv.org/abs/2602.21567", "authors": ["Linhan Fang", "Elias Raffoul", "Xingpeng Li"], "title": "Diagnosis-Driven Co-planning of Network Reinforcement and BESS for Distribution Grid with High Penetration of Electric Vehicles", "comment": null, "summary": "While the rapid proliferation of electric vehicles (EVs) accelerates net-zero goals, uncoordinated charging activities impose severe operational challenges on distribution grids, including exacerbated peak loads, thermal overloading, and voltage violations. To overcome the computational intractability of jointly optimizing grid infrastructure reinforcements and battery energy storage system (BESS) installations, this paper proposes a novel three-stage diagnosis-driven co-planning (DDCP) framework. The methodology integrates a violation detection and quantification (VDQ) model to systematically identify system breaches, and a violation-mitigated BESS planning (VMBP) model for optimal BESS sitting and sizing. Specifically, Stage I of the DDCP framework diagnoses critical bottleneck lines that render standalone BESS solutions infeasible. Stage II targets cable upgrades exclusively at the Top-N prioritized bottleneck lines and Stage III then executes the optimal BESS deployment using a network-enhanced VMBP model. Furthermore, this study quantifies the EV hosting capacity thresholds before and after BESS integration across varying EV adoption rates and base voltages. Finally, a comprehensive comparative analysis evaluates four mitigation approaches: the VDQ-driven cable upgrade (VCU) model, the VMBP model, system-wide voltage uprating, and the proposed DDCP framework. The results demonstrate that the DDCP framework not only resolves the complex joint-optimization hurdle but also achieves the high techno-economic superiority in addressing high-EV-penetration challenges."}
{"id": "2602.21293", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.21293", "abs": "https://arxiv.org/abs/2602.21293", "authors": ["Yiren Zou", "Hong-Kuan Xia", "Aosai Zhang", "Xuhao Zhu", "Feitong Jin", "Qingyuan Wang", "Yu Gao", "Chuanyu Zhang", "Ning Wang", "Zhengyi Cui", "Fanhao Shen", "Zehang Bao", "Zitian Zhu", "Jiarun Zhong", "Gongyu Liu", "Jia-Nan Yang", "Yihang Han", "Yiyang He", "Jiayuan Shen", "Han Wang", "Yanzhe Wang", "Jiahua Huang", "Xinrong Zhang", "Sailang Zhou", "Hang Dong", "Jinfeng Deng", "Yaozu Wu", "Zixuan Song", "Hekang Li", "Zhen Wang", "Chao Song", "Qiujiang Guo", "Pengfei Zhang", "Guo-Yi Zhu", "H. Wang"], "title": "Teleportation transition of surface codes on a superconducting quantum processor", "comment": null, "summary": "The topological surface code is a leading candidate for harnessing long-range entanglement to protect logical quantum information against errors, and teleportation of logical states is desirable for robust quantum information processing. Nevertheless, scaling up the surface code in quantum teleportation poses a formidable challenge to experiment. Here on a superconducting quantum processor with 125 qubits, we demonstrate the robust teleportation of topological rotated surface code prepared by a linear-depth unitary circuit, with code distances up to 7. We obtain the teleportation phase diagram by tuning the local entangling gates uniformly across a finite threshold. Furthermore, we show that the entangling threshold can be boosted by coherent qubit rotations that inject magic resources beyond the Clifford regime, restoring the duality symmetry of the topological phase, which serves as a guiding principle to minimize the entanglement resource. Our results shed light on simulating and leveraging topological quantum matter on quantum devices, and pave the way to the ultimate goal of distributed fault tolerant quantum computation."}
{"id": "2602.21727", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.21727", "abs": "https://arxiv.org/abs/2602.21727", "authors": ["Lucas Lacasa"], "title": "On the equivalence between nonlinear graph-based dynamics and linear dynamics on higher-order networks", "comment": null, "summary": "In network science, collective dynamics of complex systems are typically modelled as (nonlinear, often including many-body) vertex-level update rules evolving over a graph interaction structure. In recent years, frameworks that explicitly model such higher-order interactions in the interaction backbone (i.e. hypergraphs) have been advanced, somehow shifting the imputation of the effective nonlinearity from the dynamics to the interaction structure. In this short note we discuss such structural-dynamical representation duality, and investigate how and when a nonlinear dynamics defined on the vertex set of a graph allows an equivalent representation in terms of a linear dynamics defined on the state space of a sufficiently richer, higher-order interaction structure. We show that multilinear dynamics defined in the vertices of a graph admit an exact finite realizations as linear dynamics on the state space of a hypergraph. For other high-order interactions involving more general analytic nonlinearities, using Carleman linearization theory we discuss how that the required state space liftings necessary to linearize the dynamics cannot be accomodated to the simple structure of a hypergraph, and a richer combinatorial architecture such as a hb-graph is needed."}
{"id": "2602.21438", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.21438", "abs": "https://arxiv.org/abs/2602.21438", "authors": ["Yanyong Wang", "Manuel Engel", "Christopher Lane", "Henrique Miranda", "Lin Hou", "Bernardo Barbiellini", "Adrienn Ruzsinszky", "John P. Perdew", "Robert S. Markiewicz", "Arun Bansil", "Jianwei Sun", "Ruiqi Zhang"], "title": "Rotational Phonons Drive Low-Energy Kinks in Cuprate Superconductors", "comment": "7 pages 2 figures", "summary": "Angle-resolved photoemission spectroscopy (ARPES) reveals ubiquitous quasiparticle ``kinks'' near $\\sim$70 meV and $\\sim$40 meV across cuprate superconductors, often accompanied by peak--dip--hump (PDH) structures. These features point to strong coupling between electrons and low-energy bosonic excitations, but the microscopic origin has remained elusive due to the limitations of conventional density-functional theory (DFT) and the high cost of beyond-DFT methods. Here, we systematically study the electron--phonon coupling (EPC) in hole-doped infinite-layer CaCuO$_2$ using the Strongly Constrained and Appropriately Normed (SCAN) density functional, explicitly including magnetic effects. We find a substantial EPC strength $λ$ of $\\sim$0.5 in the magnetic phase, producing kinks and PDH structures in the 40-80~meV window in excellent agreement with experiments. The dominant contribution arises from rotational oxygen phonons, while breathing modes contribute little. Our results establish strong EPC in cuprates, highlight the key role of rotational phonons, and provide a framework for understanding spectral anomalies in cuprates and beyond."}
{"id": "2602.21293", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.21293", "abs": "https://arxiv.org/abs/2602.21293", "authors": ["Yiren Zou", "Hong-Kuan Xia", "Aosai Zhang", "Xuhao Zhu", "Feitong Jin", "Qingyuan Wang", "Yu Gao", "Chuanyu Zhang", "Ning Wang", "Zhengyi Cui", "Fanhao Shen", "Zehang Bao", "Zitian Zhu", "Jiarun Zhong", "Gongyu Liu", "Jia-Nan Yang", "Yihang Han", "Yiyang He", "Jiayuan Shen", "Han Wang", "Yanzhe Wang", "Jiahua Huang", "Xinrong Zhang", "Sailang Zhou", "Hang Dong", "Jinfeng Deng", "Yaozu Wu", "Zixuan Song", "Hekang Li", "Zhen Wang", "Chao Song", "Qiujiang Guo", "Pengfei Zhang", "Guo-Yi Zhu", "H. Wang"], "title": "Teleportation transition of surface codes on a superconducting quantum processor", "comment": null, "summary": "The topological surface code is a leading candidate for harnessing long-range entanglement to protect logical quantum information against errors, and teleportation of logical states is desirable for robust quantum information processing. Nevertheless, scaling up the surface code in quantum teleportation poses a formidable challenge to experiment. Here on a superconducting quantum processor with 125 qubits, we demonstrate the robust teleportation of topological rotated surface code prepared by a linear-depth unitary circuit, with code distances up to 7. We obtain the teleportation phase diagram by tuning the local entangling gates uniformly across a finite threshold. Furthermore, we show that the entangling threshold can be boosted by coherent qubit rotations that inject magic resources beyond the Clifford regime, restoring the duality symmetry of the topological phase, which serves as a guiding principle to minimize the entanglement resource. Our results shed light on simulating and leveraging topological quantum matter on quantum devices, and pave the way to the ultimate goal of distributed fault tolerant quantum computation."}
{"id": "2602.22121", "categories": ["quant-ph", "hep-lat", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.22121", "abs": "https://arxiv.org/abs/2602.22121", "authors": ["Balint Pato", "Natalie Klco"], "title": "Trade-offs in Gauss's law error correction for lattice gauge theory quantum simulations", "comment": null, "summary": "Gauss's law-based quantum error correction (GLQEC) offers a promising approach to reducing qubit overhead in lattice gauge theory simulations by leveraging built-in symmetries. For applications of GLQEC to 1+1D lattice quantum electrodynamics (QED), we identify two significant trade-offs. First, we prove via dimension-counting arguments that GLQEC requires periodic electric fields, thereby constraining the design space for lattice QED simulations. Second, we numerically compare GLQEC with a universal quantum error correction (UQEC) code, specifically the $d=3$ bitflip repetition code, and find that while GLQEC can achieve lower logical error rates in single-round error correction, it exhibits faster decoherence to the steady-state mixed ensemble under multiple rounds. The mixing speed penalty is manifest in observables of interest for both memory experiments and Hamiltonian evolution. We identify a mixing speed threshold, $p_{th}=0.277(2)$, above which using GLQEC exhibits even faster decoherence than without error correction. Our results highlight fundamental limitations of symmetry-based error correction schemes and inform corresponding constraints on formulations of lattice gauge theories compatible with error-robust quantum simulation techniques."}
{"id": "2602.21673", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.21673", "abs": "https://arxiv.org/abs/2602.21673", "authors": ["Kazuya Saito"], "title": "Plausible universality of uniaxial order in self-assembly of cross junctions in space dimension $d \\ge 3$", "comment": "5 pages, 2 figures", "summary": "We consider the self-assembly of cross junctions in a general space dimension ($d$) as an extension of the problem studied in a previous paper for $d = 3$. This problem is equivalent to constructing a $d$-dimensional hypercubic jungle gym, at all junctions of which $2d$ rods with different colours meet. The analysis reveals a unique feature of the $d = 3$ case: the forced presence of at least one perfectly-ordered (singly coloured) direction (axis), in contrast to the possible absence of such a direction in $d \\ge 4$. However, we will show that the uniaxial order is overwhelming not only in $d = 3$ but also for $d \\ge 4$ in a sufficiently large system."}
{"id": "2602.21487", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.21487", "abs": "https://arxiv.org/abs/2602.21487", "authors": ["Partha Sarkar", "Kshitij Khare", "Sanvesh Srivastava"], "title": "Moment bounds for condition numbers and singular values of high-dimensional Gaussian random matrices: Applications and limitations", "comment": null, "summary": "Spectral properties of Gram matrices are central to high dimensional asymptotic analyses of statistical estimators in regression and covariance estimation. These properties, in turn, depend critically on the extreme singular values and condition numbers of Gaussian random matrices. For many applications, sharp positive and negative moment bounds for these quantities are required to control expected prediction risk and related performance metrics. Although extensive work provides concentration and tail bounds for extreme singular values of Gaussian random matrices, these results do not readily yield the moment bounds needed in such analyses. Motivated by this gap, we establish non asymptotic moment bounds for arbitrary positive moments of the largest singular value and arbitrary negative moments of the smallest singular value, and uniform bounds for arbitrary positive moments of the condition number of high dimensional Gaussian random matrices. We demonstrate the utility of these bounds by applying them to derive explicit risk guarantees in high dimensional regression and covariance estimation, as well as to obtain bounds on the mean iteration complexity of gradient descent for solving Gram linear systems. Finally, we present counterexamples demonstrating that the positive condition number moment bounds and negative smallest singular value moment bounds cannot, in general, be extended to the broader class of sub Gaussian random matrices."}
{"id": "2602.21570", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.21570", "abs": "https://arxiv.org/abs/2602.21570", "authors": ["Yi Xu", "Chunfeng Cui", "Liqun Qi"], "title": "Narrowing the Gap: SOS Ranks of $4 \\times 3$ Biquadratic Forms and a Lower Bound of $8$", "comment": null, "summary": "We investigate the maximum sum-of-squares (SOS) rank of biquadratic forms in the critical case of $4 \\times 3$ variables, where the general bounds are currently $7 \\leq \\mathrm{BSR}(4,3) \\leq 11$. By analyzing two important structured subclasses, we obtain exact determinations and improved upper bounds that significantly narrow this gap.\n  For simple biquadratic forms those containing only distinct terms of the type $x_i^2 y_j^2$ we prove that the maximum achievable SOS rank is exactly 7, a value attained by a form corresponding to a $C_4$-free bipartite graph with the maximum number of edges. This settles the question for simple forms.\n  For $y$-deficient biquadratic forms a class introduced here that permits cross terms among two of the three $y$-variables while the third appears only in pure square terms we prove an upper bound of $9$ by combining Calderön's theorem on $m\\times 2$ forms with the known value $\\mathrm{BSR}(4,2) = 5$.\n  Our main result is a constructive proof that $\\mathrm{BSR}(4,3) \\geq 8$. We present an explicit non-simple, non-deficient $4\\times 3$ biquadratic form and prove it requires exactly eight squares, thereby improving the general lower bound. This shows that any form achieving a rank higher than $8$ must possess a more complex algebraic structure, and it reduces the search space for determining the true value of $\\mathrm{BSR}(4,3)$. Connections to Zarankiewicz numbers, extremal graph theory, and classical results on sums of squares are highlighted throughout."}
{"id": "2602.21753", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.21753", "abs": "https://arxiv.org/abs/2602.21753", "authors": ["Lisa Stammen", "Wolfgang Dornisch"], "title": "A dual lumping procedure for static condensation in mixed NURBS-based isogeometric elements with optimal convergence rates for arbitrary open knot vectors", "comment": "52 pages, 18 figures, 2 tables, Preprint submitted to Computer Methods in Applied Mechanics and Engineering", "summary": "Locking is a common effect in finite element and isogeometric analysis. In the case of plates, transverse shear locking is most prominent, for shells several other types of locking exist. A common cure are mixed methods that introduce additional fields of unknowns into the variational formulation. These fields reduce constraints and thus alleviate locking significantly. As a drawback, the discretized additional fields increase computational costs significantly. These fields are often eliminated by static condensation, which requires the inverse of a part of the stiffness matrix. In Lagrange-based finite elements, this inverse is computed on element level, due to a discontinuous interpolation of additional fields. Since isogeometric analysis features higher continuity, static condensation must be performed on patch level, which requires a costly matrix inversion on that level. In this contribution, the virtual shear parameters of a mixed isogeometric plate formulation are interpolated by enhanced approximate dual basis functions. This allows to conduct row-sum lumping of the relevant matrix part at a minimal loss of accuracy, since this part becomes diagonal dominant. For a properly chosen integration space, this lumped matrix becomes the identity matrix. Thus, the proposed condensation procedure does not require an inversion anymore. The crucial and novel point is the proposed treatment of knot vectors with limited internal continuity. With the help of several single- and multi-patch examples, both with full and with limited internal continuity, we show that the proposed procedure obtains optimal error convergence rates in all cases, while without these alterations, convergence rates are significantly deteriorated."}
{"id": "2602.21594", "categories": ["eess.SY", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.21594", "abs": "https://arxiv.org/abs/2602.21594", "authors": ["Miroslav Krstic"], "title": "Asymmetry Demystified: Strict CLFs and Feedbacks for Predator-Prey Interconnections", "comment": null, "summary": "The difficulty with control of population dynamics, besides the states being positive and the control having to also be positive, is the extreme difference in the dynamics near extinction and at overpopulated states. As hard as global stabilization is, even harder is finding CLFs that are strict, don't require LaSalle arguments, and permit quantification of convergence. Among the three canonical types of two-population dynamics (mutualism, which borders on trivial, predator-prey, and competition, which makes global stabilization with positive harvesting impossible), predator-prey is the ``sweet spot'' for the study of stabilization. Even when the predator-prey interaction is neutrally stable, global asymptotic stabilization with strict CLFs has proven very difficult, except by conservative, hard-to-gain-insight-from Matrosov-like techniques.\n  In this little note we show directions for the design of clean, elegant, insight-bearing, majorization-free strict CLFs. They generalize the classical Volterra-style Lyapunov functions for population dynamics to non-separable Volterra-style constructions. As a bonus to strictification as an analysis activity, we provide examples of concurrent designs of feedback and CLFs, using customized versions of forwarding and backstepping (note that, in suitable coordinates, predator-prey is both strict-feedforward and strict-feedback), where the striking deviations from these methods' conventional forms is necessitated by the predator-prey's states and inputs needing to be kept positive."}
{"id": "2602.21335", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.21335", "abs": "https://arxiv.org/abs/2602.21335", "authors": ["Hongyang Liu", "Dan Jiao"], "title": "Efficient and Accurate Method for Separating Variant Components from Invariant Background and Component Model Fusion for Fast RFIC Design Space Exploration", "comment": "This paper has been accepted for publication at the 2026 IEEE International Microwave Symposium (IMS) RFTT (RF Technology and Techniques), to be held in Boston, on June 8-11, 2026", "summary": "The design of RFIC often involves exploring a large number of design variations in an invariant background composed of the processing stack and unchanged circuit blocks. Conventional electromagnetic solvers require a full-domain simulation for every design variation. In this work, we present a fast method that effectively separates the variant components from the invariant background. It algebraically decomposes the total field solution into the contributions from the design-dependent variations and the invariant background. Hence, the field response due to the invariant background can be simulated once and reused for all design variations. Only the variant components need to be simulated at each design variation, the size of which is small. We also develop an efficient way of reusing the model of each component and fusing them accurately to obtain the model of a system composed of many components. The reduced system of variant components involves computing the field solutions in the invariant background due to all possible sources located at variant components, the number of which can be large. We develop a fast algorithm to reduce them to a few field solutions, the number of which is on the order of the layer number. The proposed method has been applied to RFIC design space exploration. Its accuracy, robustness, and efficiency have been demonstrated."}
{"id": "2602.21749", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.21749", "abs": "https://arxiv.org/abs/2602.21749", "authors": ["Longlong Zhang", "Xi Wang", "Haotong Du", "Yangyi Xu", "Zhuo Liu", "Yang Liu"], "title": "RABot: Reinforcement-Guided Graph Augmentation for Imbalanced and Noisy Social Bot Detection", "comment": null, "summary": "Social bot detection is pivotal for safeguarding the integrity of online information ecosystems. Although recent graph neural network (GNN) solutions achieve strong results, they remain hindered by two practical challenges: (i) severe class imbalance arising from the high cost of generating bots, and (ii) topological noise introduced by bots that skillfully mimic human behavior and forge deceptive links. We propose the Reinforcement-guided graph Augmentation social Bot detector (RABot), a multi-granularity graph-augmentation framework that addresses both issues in a unified manner. RABot employs a neighborhood-aware oversampling strategy that linearly interpolates minority-class embeddings within local subgraphs, thereby stabilizing the decision boundary under low-resource regimes. Concurrently, a reinforcement-learning-driven edge-filtering module combines similarity-based edge features with adaptive threshold optimization to excise spurious interactions during message passing, yielding a cleaner topology. Extensive experiments on three real-world benchmarks and four GNN backbones demonstrate that RABot consistently surpasses state-of-the-art baselines. In addition, since its augmentation and filtering modules are orthogonal to the underlying architecture, RABot can be seamlessly integrated into existing GNN pipelines to boost performance with minimal overhead."}
{"id": "2602.21410", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21410", "abs": "https://arxiv.org/abs/2602.21410", "authors": ["Zhentian Zhang", "Tim Friede", "Tim Mathes"], "title": "Identifying the potential of sample overlap in evidence synthesis of observational studies", "comment": "36 pages,17 figures", "summary": "Sample overlap is a common issue in evidence synthesis in the field of medical research, particularly when integrating findings from observational studies utilizing existing databases such as registries. Due to the general inaccessibility of unique identifiers for each observation, addressing sample overlap has been a complex problem, potentially biasing evidence synthesis outcomes and undermining their credibility. We developed a method to construct indicators for the degree of sample overlap in evidence synthesis of studies based on existing data. Our method is rooted in set theory and is based on the coding of the ranges of several well selected sample characteristics, offers a practical solution by focusing on making inference based on sample characteristics rather than on individual participant data. Useful information, such as the overlap-free sample set with the largest sample size in an evidence synthesis, can be derived from this method. We applied our model to several real-world evidence syntheses, demonstrating its effectiveness and flexibility. Our findings highlight the growing importance of addressing sample overlap in evidence synthesis, especially with the increasing relevance of secondary use of data, an area currently under-explored in research."}
{"id": "2602.21594", "categories": ["eess.SY", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.21594", "abs": "https://arxiv.org/abs/2602.21594", "authors": ["Miroslav Krstic"], "title": "Asymmetry Demystified: Strict CLFs and Feedbacks for Predator-Prey Interconnections", "comment": null, "summary": "The difficulty with control of population dynamics, besides the states being positive and the control having to also be positive, is the extreme difference in the dynamics near extinction and at overpopulated states. As hard as global stabilization is, even harder is finding CLFs that are strict, don't require LaSalle arguments, and permit quantification of convergence. Among the three canonical types of two-population dynamics (mutualism, which borders on trivial, predator-prey, and competition, which makes global stabilization with positive harvesting impossible), predator-prey is the ``sweet spot'' for the study of stabilization. Even when the predator-prey interaction is neutrally stable, global asymptotic stabilization with strict CLFs has proven very difficult, except by conservative, hard-to-gain-insight-from Matrosov-like techniques.\n  In this little note we show directions for the design of clean, elegant, insight-bearing, majorization-free strict CLFs. They generalize the classical Volterra-style Lyapunov functions for population dynamics to non-separable Volterra-style constructions. As a bonus to strictification as an analysis activity, we provide examples of concurrent designs of feedback and CLFs, using customized versions of forwarding and backstepping (note that, in suitable coordinates, predator-prey is both strict-feedforward and strict-feedback), where the striking deviations from these methods' conventional forms is necessitated by the predator-prey's states and inputs needing to be kept positive."}
{"id": "2602.21468", "categories": ["cond-mat.str-el", "cond-mat.dis-nn", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21468", "abs": "https://arxiv.org/abs/2602.21468", "authors": ["Brandon Yee", "Wilson Collins", "Maximilian Rutkowski"], "title": "Unsupervised Discovery of Intermediate Phase Order in the Frustrated $J_1$-$J_2$ Heisenberg Model via Prometheus Framework", "comment": null, "summary": "The spin-$1/2$ $J_1$-$J_2$ Heisenberg model on the square lattice exhibits a debated intermediate phase between Néel antiferromagnetic and stripe ordered regimes, with competing theories proposing plaquette valence bond, nematic, and quantum spin liquid ground states. We apply the Prometheus variational autoencoder framework -- previously validated on classical (2D, 3D Ising) and quantum (disordered transverse field Ising) phase transitions -- to systematically explore the $J_1$-$J_2$ phase diagram via unsupervised analysis of exact diagonalization ground states for a $4 \\times 4$ lattice. Through dense parameter scans of $J_2/J_1 \\in [0.3, 0.7]$ with step size 0.01 and comprehensive latent space analysis, we investigate the nature of the intermediate regime using unsupervised order parameter discovery and critical point detection via multiple independent methods. This work demonstrates the application of rigorously validated machine learning methods to open questions in frustrated quantum magnetism, where traditional order parameter identification is challenged by competing interactions and limited accessible system sizes."}
{"id": "2602.21869", "categories": ["physics.soc-ph", "physics.app-ph", "physics.data-an", "q-fin.ST"], "pdf": "https://arxiv.org/pdf/2602.21869", "abs": "https://arxiv.org/abs/2602.21869", "authors": ["Mattia Marzi", "Tiziano Squartini"], "title": "A Bayesian approach to out-of-sample network reconstruction", "comment": "25 pages, 13 figures", "summary": "Networks underpin systems that range from finance to biology, yet their structure is often only partially observed. Current reconstruction methods typically fit the parameters of a model anew to each snapshot, thus offering no guidance to predict future configurations. Here, we develop a Bayesian approach that uses the information about past network snapshots to inform a prior and predict the subsequent ones, while quantifying uncertainty. Instantiated with a single-parameter fitness model, our method infers link probabilities from node strengths and carries information forward in time. When applied to the Electronic Market for Interbank Deposit across the years 1999-2012, our method accurately recovers the number of connections per bank at subsequent times, outperforming probabilistic benchmarks designed for analogous, link prediction tasks. Notably, each predicted snapshot serves as a reliable prior for the next one, thus enabling self-sustained, out-of-sample reconstruction of evolving networks with a minimal amount of additional data."}
{"id": "2602.21468", "categories": ["cond-mat.str-el", "cond-mat.dis-nn", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21468", "abs": "https://arxiv.org/abs/2602.21468", "authors": ["Brandon Yee", "Wilson Collins", "Maximilian Rutkowski"], "title": "Unsupervised Discovery of Intermediate Phase Order in the Frustrated $J_1$-$J_2$ Heisenberg Model via Prometheus Framework", "comment": null, "summary": "The spin-$1/2$ $J_1$-$J_2$ Heisenberg model on the square lattice exhibits a debated intermediate phase between Néel antiferromagnetic and stripe ordered regimes, with competing theories proposing plaquette valence bond, nematic, and quantum spin liquid ground states. We apply the Prometheus variational autoencoder framework -- previously validated on classical (2D, 3D Ising) and quantum (disordered transverse field Ising) phase transitions -- to systematically explore the $J_1$-$J_2$ phase diagram via unsupervised analysis of exact diagonalization ground states for a $4 \\times 4$ lattice. Through dense parameter scans of $J_2/J_1 \\in [0.3, 0.7]$ with step size 0.01 and comprehensive latent space analysis, we investigate the nature of the intermediate regime using unsupervised order parameter discovery and critical point detection via multiple independent methods. This work demonstrates the application of rigorously validated machine learning methods to open questions in frustrated quantum magnetism, where traditional order parameter identification is challenged by competing interactions and limited accessible system sizes."}
{"id": "2602.21306", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21306", "abs": "https://arxiv.org/abs/2602.21306", "authors": ["Shubha Deutschle", "Lőrinc Sárkány", "Milán János Negyedi", "József Fortágh", "Andreas Günther", "Philippe Wilhelm Courteille"], "title": "Optical repumping and atom number balancing in a two-color MOT", "comment": "13 pages, 7 figures", "summary": "We study a novel repumping transition for $^{88}$Sr atoms trapped in a 'blue' magneto-optical trap. We show that, while the repumping efficiency is about three orders of magnitude smaller than for traditional schemes, it is sufficient for recycling all atoms, provided the repumping laser beams are arranged to form a 'green' magneto- optical trap (MOT) helping to cool and confine the atoms and preventing their loss. Our main findings are: (i) that the green MOT configuration is able to trap 10 times more atoms in the blue MOT than using the green transition merely as a repump, and (ii) that the atom numbers in the two-color MOT can be balanced through experimental control parameters. The interest of this scheme lies in its capability of reaching low temperature and its suitability for continuous atomic beam generation."}
{"id": "2602.21731", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.21731", "abs": "https://arxiv.org/abs/2602.21731", "authors": ["O. Patsahan"], "title": "On the electrical double layer capacitance of the restricted primitive model: a link between the mesoscopic theory and the associative mean spherical approximation", "comment": "9 pages, 2 figures", "summary": "The results for the electrical double layer capacitance and the charge density of ``free ions'' obtained from the mesoscopic theory are compared with the corresponding results of the associative mean spherical approximation. While the first theory takes into account the fluctuations of the charge density, the second theory assumes that the free ions and ion pairs are in chemical equilibrium according to the mass action law. Our results demonstrate a fairly good agreement between the two theories at high densities and low temperatures."}
{"id": "2602.21569", "categories": ["math.ST", "cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.21569", "abs": "https://arxiv.org/abs/2602.21569", "authors": ["Huan Qing"], "title": "How many asymmetric communities are there in multi-layer directed networks?", "comment": "44 pages, 4 tables, 2 figures", "summary": "Estimating the asymmetric numbers of communities in multi-layer directed networks is a challenging problem due to the multi-layer structures and inherent directional asymmetry, leading to possibly different numbers of sender and receiver communities. This work addresses this issue under the multi-layer stochastic co-block model, a model for multi-layer directed networks with distinct community structures in sending and receiving sides, by proposing a novel goodness-of-fit test. The test statistic relies on the deviation of the largest singular value of an aggregated normalized residual matrix from the constant 2. The test statistic exhibits a sharp dichotomy: Under the null hypothesis of correct model specification, its upper bound converges to zero with high probability; under underfitting, the test statistic itself diverges to infinity. With this property, we develop a sequential testing procedure that searches through candidate pairs of sender and receiver community numbers in a lexicographic order. The process stops at the smallest such pair where the test statistic drops below a decaying threshold. For robustness, we also propose a ratio-based variant algorithm, which detects sharp changes in the sequence of test statistics by comparing consecutive candidates. Both methods are proven to consistently determine the true numbers of sender and receiver communities under the multi-layer stochastic co-block model."}
{"id": "2602.21592", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.21592", "abs": "https://arxiv.org/abs/2602.21592", "authors": ["Hiroki Kuroda", "Renato Luis Garrido Cavalcante"], "title": "Sum-Rate Maximization via Convex Optimization Using Subgradient Projections Onto Nonlinear Spectral Radius Constraint Sets", "comment": null, "summary": "We solve the (weighted) sum-rate maximization problem over the set of achievable rates characterized by a nonlinear spectral radius function. This set has been recently shown to be convex in some practically relevant settings in modern wireless networks, including cell-less networks. However, even under convexity, sum-rate maximization is challenging because the nonlinear spectral radius characterization of the achievable rate region is difficult to handle directly. We overcome this difficulty by exploiting subgradient projections onto the level sets of suitably reformulated spectral radius functions. Notably, the derived subgradient projection algorithm provably converges to the global optimum of the sum-rate maximization problem under the convexity condition. The efficacy of the proposed algorithm is illustrated in simulations for cell-less networks."}
{"id": "2602.21767", "categories": ["math.NA", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.21767", "abs": "https://arxiv.org/abs/2602.21767", "authors": ["P. Giesl", "S. Hafstein", "B. Hamzi", "J. Lee", "H. Owhadi", "G. Santin", "U. Vaidya"], "title": "Kernel Methods for the Construction of Certified Lyapunov Functions via Approximate Koopman Eigenfunctions", "comment": null, "summary": "We present a kernel-based methodology for constructing Lyapunov functions for nonlinear dynamical systems using approximate Koopman eigenfunctions. Our approach decomposes principal Koopman eigenfunctions into linear and nonlinear components, where the linear part is obtained from the system's linearization and the nonlinear part is computed by solving a partial differential equation using symmetric kernel collocation in reproducing kernel Hilbert spaces (RKHS). The resulting Lyapunov function is constructed as a quadratic form in the approximate eigenfunctions. We establish error bounds relating the approximation quality to the fill distance of collocation points and provide a certification procedure using continuous piecewise affine (CPA) methods. Numerical experiments on benchmark systems, including a polynomial system and the Duffing oscillator, demonstrate the effectiveness of our approach."}
{"id": "2602.21602", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21602", "abs": "https://arxiv.org/abs/2602.21602", "authors": ["Haoyang Li", "Weidong Liu", "Zhensheng Chen", "Chaoyun Song", "Gaojie Chen"], "title": "Geometry-Dependent Radiation of Pinching Antennas: Theory, Simulation, and Measurement", "comment": "The manuscript has been submitted to an IEEE letter/journal for possible publication", "summary": "Most existing studies achieve beamforming by adjusting the positions of pinching antennas (PAs) and typically model PAs as isotropic radiators. However, under the dielectric scatterer model, the PA radiation pattern depends on its geometry. This letter investigates the radiation patterns of PAs with different geometries through full-wave simulations and measurements, and demonstrates how geometry influences the radiation directivity. In addition, an arc-shaped PA is introduced to enable transmit-direction control in PA systems. A PA system prototype consisting of a dielectric waveguide, waveguide transitions, and a PA element is proposed. Prototype measurements are used to validate the simulations and to characterize the directivity of square and triangular PAs, and the measurement procedure can be applied to obtain radiation patterns for PAs with general geometries. The simulation and measurement results jointly demonstrate that PA geometry is critical in PA systems because it influences the radiation characteristics significantly."}
{"id": "2602.21747", "categories": ["physics.comp-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2602.21747", "abs": "https://arxiv.org/abs/2602.21747", "authors": ["Anna Werkovits", "Simon B. Hollweger", "Oliver T. Hofmann"], "title": "Emergent Rate Laws for Collective Lying-Standing Transitions", "comment": null, "summary": "Lying-standing transitions in the first molecular monolayer at organic-inorganic interfaces strongly influence interface dipoles, energy-level alignment, and growth modes, yet their collective kinetics remain difficult to predict. Here, we establish a quantitative adsorbate-to-kinetics relationship using first-principles-based kinetic Monte Carlo simulations combined with a mean-field coarse-graining strategy. Focusing on tetracyanoethylene on Cu(111), we show that the collective transition rate cannot be inferred from any single elementary step but emerges from coupled microscopic processes, including reorientation, adsorption, and diffusion. A local two-step reorientation mechanism captures the diffusion-limited regime, while diffusion of lying molecules accelerates the transition in diffusion-enhanced regimes by suppressing back-reorientation via vacancy-molecule decoupling. This effect is described by a regime-dependent geometric factor accounting for deviations between single-molecule and collective rate constants. By varying molecular size and footprint ratio, we demonstrate that geometry is an intrinsic control parameter. While the collective rate scales approximately with molecular area, increasing the footprint ratio between lying and standing configurations yields order-of-magnitude accelerations due to enhanced vacancy creation and diffusion-assisted stabilization. Finally, we derive an analytical expression for the collective reorientation rate constant linking temperature- and pressure-dependent microscopic rate constants to geometric parameters. The formulation reproduces the simulations across kinetic regimes and provides transferable design principles for engineering lying-standing transition timescales at organic-inorganic interfaces."}
{"id": "2602.21755", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.21755", "abs": "https://arxiv.org/abs/2602.21755", "authors": ["Jeonghan Son", "Kyungsik Han", "Yeon-Chang Lee"], "title": "Embedding-aware Polarization Management in Signed Networks", "comment": null, "summary": "Signed network embeddings (SNE) are widely used to represent networks with positive and negative relations, but their repeated use in downstream analysis pipelines can inadvertently reinforce structural polarization. Existing polarization measures are largely designed for unsigned networks or rely on predefined opinion states, limiting their applicability to embedding-based analysis in signed settings. We propose EPM, a unified polarization management framework that jointly measures and mitigates polarization in the embedding space. EPM introduces an embedding-based polarization measure grounded in effective resistance and a structure-aware mitigation strategy via localized augmentation through structurally balanced intermediary nodes. Experiments on real-world signed networks demonstrate that EPM effectively mitigates polarization while preserving task-relevant network structure. The codebase of EPM is available at https://github.com/JeonghanSon/EPM-Embedding-aware-Polarization-Management."}
{"id": "2602.21490", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21490", "abs": "https://arxiv.org/abs/2602.21490", "authors": ["Dingzi Guo", "Diqing Li", "Jingyi Wang", "Wen-Xin Zhou"], "title": "Connection Probabilities Estimation in Multi-layer Networks via Iterative Neighborhood Smoothing", "comment": null, "summary": "Understanding the structural mechanisms of multi-layer networks is essential for analyzing complex systems characterized by multiple interacting layers. This work studies the problem of estimating connection probabilities in multi-layer networks and introduces a new Multi-layer Iterative Connection Probability Estimation (MICE) method. The proposed approach employs an iterative framework that jointly refines inter-layer and intra-layer similarity sets by dynamically updating distance metrics derived from current probability estimates. By leveraging both layer-level and node-level neighborhood information, MICE improves estimation accuracy while preserving computational efficiency. Theoretical analysis establishes the consistency of the estimator and shows that, under mild regularity conditions, the proposed method achieves an optimal convergence rate comparable to that of an oracle estimator. Extensive simulation studies across diverse graphon structures demonstrate the superior performance of MICE relative to existing methods. Empirical evaluations using brain network data from patients with Attention-Deficit/Hyperactivity Disorder (ADHD) and global food and agricultural trade network data further illustrate the robustness and effectiveness of the method in link prediction tasks. Overall, this work provides a theoretically grounded and practically scalable framework for probabilistic modeling and inference in multi-layer network systems."}
{"id": "2602.21602", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21602", "abs": "https://arxiv.org/abs/2602.21602", "authors": ["Haoyang Li", "Weidong Liu", "Zhensheng Chen", "Chaoyun Song", "Gaojie Chen"], "title": "Geometry-Dependent Radiation of Pinching Antennas: Theory, Simulation, and Measurement", "comment": "The manuscript has been submitted to an IEEE letter/journal for possible publication", "summary": "Most existing studies achieve beamforming by adjusting the positions of pinching antennas (PAs) and typically model PAs as isotropic radiators. However, under the dielectric scatterer model, the PA radiation pattern depends on its geometry. This letter investigates the radiation patterns of PAs with different geometries through full-wave simulations and measurements, and demonstrates how geometry influences the radiation directivity. In addition, an arc-shaped PA is introduced to enable transmit-direction control in PA systems. A PA system prototype consisting of a dielectric waveguide, waveguide transitions, and a PA element is proposed. Prototype measurements are used to validate the simulations and to characterize the directivity of square and triangular PAs, and the measurement procedure can be applied to obtain radiation patterns for PAs with general geometries. The simulation and measurement results jointly demonstrate that PA geometry is critical in PA systems because it influences the radiation characteristics significantly."}
{"id": "2602.21879", "categories": ["quant-ph", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.21879", "abs": "https://arxiv.org/abs/2602.21879", "authors": ["Hiroki Kuji", "Suguru Endo", "Tetsuro Nikuni", "Ryusuke Hamazaki", "Yuichiro Matsuzaki"], "title": "Quantum Error Mitigation Simulates General Non-Hermitian Dynamics", "comment": null, "summary": "While non-Hermitian Hamiltonians enable exotic dynamical phenomena, implementing their nonunitary time evolution on near-term quantum devices remains challenging. We propose a hardware-friendly protocol that simulates non-Hermitian dynamics without continuous monitoring. Gorini-Kossakowski-Sudarshan-Lindblad (GKSL) evolution via classical Gaussian white-noise averaging and to subsequently cancel the quantum-jump contribution at the level of the measured observable using stochastic quantum error mitigation (QEM). The scheme requires no ancillas or controlled time-evolution, while the mitigation layer uses only single-qubit operations. We validate the method through numerical simulations of a model with asymmetric hopping, interaction, and disorder. Our work provides a programmable and ancilla-free framework investigating exotic dynamics that are not completely-positive and trace-preserving using QEM."}
{"id": "2602.21954", "categories": ["physics.soc-ph", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.21954", "abs": "https://arxiv.org/abs/2602.21954", "authors": ["Xinkai Ji", "Pan Liu", "Yu Han"], "title": "The Swarm Intelligence Freeway-Urban Trajectories (SWIFTraj) Dataset - Part II: A Graph-Based Approach for Trajectory Connection", "comment": null, "summary": "In Part I of this companion paper series, we introduced SWIFTraj, a new open-source vehicle trajectory dataset collected using a unmanned aerial vehicle (UAV) swarm. The dataset has two distinctive features. First, by connecting trajectories across consecutive UAV videos, it provides long-distance continuous trajectories, with the longest exceeding 4.5 km. Second, it covers an integrated traffic network consisting of both freeways and their connected urban roads. Obtaining such long-distance continuous trajectories from a UAV swarm is challenging, due to the need for accurate time alignment across multiple videos and the irregular spatial distribution of UAVs. To address these challenges, this paper proposes a novel graph-based approach for connecting vehicle trajectories captured by a UAV swarm. An undirected graph is constructed to represent flexible UAV layouts, and an automatic time alignment method based on trajectory matching cost minimization is developed to estimate optimal time offsets across videos. To associate trajectories of the same vehicle observed in different videos, a vehicle matching table is established using the Hungarian algorithm. The proposed approach is evaluated using both simulated and real-world data. Results from real-world experiments show that the time alignment error is within three video frames, corresponding to approximately 0.1 s, and that the vehicle matching achieves an F1-score of about 0.99. These results demonstrate the effectiveness of the proposed method in addressing key challenges in UAV-based trajectory connection and highlight its potential for large-scale vehicle trajectory collection."}
{"id": "2602.21582", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.21582", "abs": "https://arxiv.org/abs/2602.21582", "authors": ["Zhongyuan Jiang", "Zhiwei Zhang", "Kesen Zhao", "Wenjie Meng", "Yuanyuan Zhao", "Yubin Hou", "Zhangzhang Cui", "Jian Zhang", "Zheling Shan", "Haoliang Huang", "Qingyou Lu", "Yalin Lu"], "title": "Magnetic anisotropic pinning and symmetric breaking induced by interfacial coupling in topological-like ruthenate superlattices", "comment": "14 pages, 5 figures", "summary": "Interfacial engineering enables various emergent effects such as spin reorientations and transport anisotropy. Noncollinear spin textures are essential for realizing many emergent quantum transport phenomena. However, driving such spin structures requires precise control of the interfacial magnetic coupling in complex oxide heterostructures. Here, by utilizing competing exchange interactions at the interface between ferromagnetic metal SrRuO3 and ferromagnetic insulator LaCoO3, we discovered a noncollinear spin configuration in SrRuO3 sublayers. Magnetic stripes were induced by out-of-plane rather than in-plane magnetic fields, indicating strong anisotropy pinning in our superlattices. The observed magneto-transport anisotropy is well explained by our proposed spin configurations, accounting for contributions from both bulk and interface of the SrRuO3 layers. More interestingly, magnetic skymionic textures were absent even at high magnetic fields. The interfacial exchange interaction overwhelms the Dzyaloshinskii-Moriya interaction (DMI) that stabilizes skyrmions, featuring a higher exchange coupling energy than that for the topological spin textures. Our work highlights the potential of interfacial engineering in tuning the spintronic properties by designing proper interfacial interactions."}
{"id": "2602.21350", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21350", "abs": "https://arxiv.org/abs/2602.21350", "authors": ["Sebastian Zając", "Jacob L. Cybulski", "Bartosz Dziewit", "Tomasz Kulpa"], "title": "The Inverse Born Rule Fallacy: On the Informational Limits of Phase-Locked Amplitude Encoding", "comment": "6 pages, submitted to ICCS2026", "summary": "In Quantum Machine Learning (QML) and Quantum Finance, amplitude encoding is often motivated by its logarithmic storage capacity arXiv:1307.0411. This paradigm typically relies on the mapping $ψ= \\sqrt{P}$, treating the quantum state as a derivative of a classical probability distribution $P$. By restricting the data manifold to the positive real orthant $\\mathcal{S}^+$, the accessible Hilbert space is effectively abelianized, rendering the representation ``phase-deaf''. We rigorously establish that while $P$ is a projection of $|ψ|^2$, the simple square-root mapping fails to recover the non-commutative structure necessary for genuine quantum advantage in classification tasks. Furthermore, we clarify why applying basis changes (like Hadamard gates) to these states fails to replicate the computational power of active phase-kickback mechanisms. Finally, we advocate for Dynamical Hamiltonian Encoding (based on QIFT), where data generates non-commutative evolution rather than serving as a static, phase-locked vector."}
{"id": "2602.21807", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.21807", "abs": "https://arxiv.org/abs/2602.21807", "authors": ["Swarnendu Maity", "Pushkar Khandare", "Himangsu Bhaumik", "Peter Sollich", "Srikanth Sastry"], "title": "Stochasticity of fatigue failure times in sheared glasses", "comment": "14 pages, 9 figures", "summary": "Fatigue failure occurs when a solid is subjected to repeated, cyclic loading. Glasses subjected to cyclic to shear deformation have recently been investigated using computer simulations and theoretical models, to characterize and rationalize the dependence of the number of cycles to failure, depending on the properties of the glasses, and the deformation amplitude. The average number of cycles to failure has been observed to diverge as the strain amplitude approaches the so-called fatigue limit from above. In this work, rather than the average times themselves, we investigate by computer simulations the distribution of fatigue failure times, in model glasses subjected to cyclic shear deformation and in an elasto-plastic model. In particular, we observe in atomistic simulations that the standard deviation of the logarithm of failure times are proportional to their mean values, with the proportionality constant decreasing as the system size increases, indicating a sharper distribution of failure times. Using a finite-element-based elasto-plastic model, we observe similar behavior and perform a system-size analysis showing that the ratio of the standard deviation to the mean tends toward zero in the thermodynamic limit. Such distributions, rather than arising solely from the distribution of disorder in the samples that have been subjected to cyclic deformation, appear to arise from the intrinsic stochasticity of the failure process, which we analyze through a stochastic damage accumulation model."}
{"id": "2602.21764", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.21764", "abs": "https://arxiv.org/abs/2602.21764", "authors": ["William Wu", "Qidi Peng"], "title": "Estimation of the Self-similarity Index of Non-stationary Increments Self-similar Processes via Lamperti Transformations", "comment": null, "summary": "We introduce a novel method for estimating the self-similarity index of a general $H$-self-similar process with either stationary or non-stationary increments. The estimation algorithm is developed based on a modified Lamperti transformation, which transforms $H$-self-similar processes to stationary ones. As an application, we show how to use this approach to estimate the self-similarity index of fractional Brownian motion, subfractional Brownian motion, bifractional Brownian motion, and trifractional Brownian motion. Simulation study is performed to support the consistency of our estimators. Implementation in Python is publicly shared. Application on the estimation of the self-similarity index of the Nile river water level data from the year 900 to 1200 C.E.."}
{"id": "2602.21761", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.21761", "abs": "https://arxiv.org/abs/2602.21761", "authors": ["Yunpeng Ba", "Xi Lin", "Changliang Zhou", "Ruihao Zheng", "Zhenkun Wang", "Xinyan Liang", "Zhichao Lu", "Jianyong Sun", "Yuhua Qian", "Qingfu Zhang"], "title": "Survey on Neural Routing Solvers", "comment": null, "summary": "Neural routing solvers (NRSs) that leverage deep learning to tackle vehicle routing problems have demonstrated notable potential for practical applications. By learning implicit heuristic rules from data, NRSs replace the handcrafted counterparts in classic heuristic frameworks, thereby reducing reliance on costly manual design and trial-and-error adjustments. This survey makes two main contributions: (1) The heuristic nature of NRSs is highlighted, and existing NRSs are reviewed from the perspective of heuristics. A hierarchical taxonomy based on heuristic principles is further introduced. (2) A generalization-focused evaluation pipeline is proposed to address limitations of the conventional pipeline. Comparative benchmarking of representative NRSs across both pipelines uncovers a series of previously unreported gaps in current research."}
{"id": "2602.21911", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.21911", "abs": "https://arxiv.org/abs/2602.21911", "authors": ["Gino I. Montecinos", "Eleuterio F. Toro", "Lucas O. Müller"], "title": "A generalized Riemann problem-based compact reconstruction method for finite volume schemes", "comment": "38 pages, 13 figures, 10 tables", "summary": "We present a Generalized Riemann Problem-based reconstruction method (GRPrec) for high-order finite volume schemes applied to hyperbolic partial differential equations. The method constructs spatial polynomials using cell averages at the current time level and GRP solution data from the previous time level. The resulting GRPrec stencil is as compact as that of discontinuous Galerkin (DG) schemes but unlike DG, our finite volume schemes obey a generous CFL stability condition that is independent of the order of accuracy. We assess the method's performance through test problems for smooth and discontinuous solutions of the linear advection equation and the Euler equations of gas dynamics in one space dimension. Results are compared against exact solutions and against numerical results from well-known spatial reconstruction finite volume and DG schemes, with all methods implemented in the fully discrete ADER framework. The performance of GRPrec is very promising, especially in terms of efficiency, that is error against CPU cost."}
{"id": "2602.21715", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21715", "abs": "https://arxiv.org/abs/2602.21715", "authors": ["Xu Yang", "Chenhui Lin", "Xiang Ma", "Dong Liu", "Ran Zheng", "Haotian Liu", "Wenchuan Wu"], "title": "Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach", "comment": null, "summary": "The growing integration of distributed photovoltaics (PVs) into active distribution networks (ADNs) has exacerbated operational challenges, making it imperative to coordinate diverse equipment to mitigate voltage violations and enhance power quality. Although existing data-driven approaches have demonstrated effectiveness in the voltage control problem, they often require extensive trial-and-error exploration and struggle to incorporate heterogeneous information, such as day-ahead forecasts and semantic-based grid codes. Considering the operational scenarios and requirements in real-world ADNs, in this paper, we propose a hybrid knowledge-data-driven approach that leverages dynamic collaboration between a large language model (LLM) agent and a reinforcement learning (RL) agent to achieve two-stage voltage control. In the day-ahead stage, the LLM agent receives coarse region-level forecasts and generates scheduling strategies for on-load tap changer (OLTC) and shunt capacitors (SCs) to regulate the overall voltage profile. Then in the intra-day stage, based on accurate node-level measurements, the RL agent refines terminal voltages by deriving reactive power generation strategies for PV inverters. On top of the LLM-RL collaboration framework, we further propose a self-evolution mechanism for the LLM agent and a pretrain-finetune pipeline for the RL agent, effectively enhancing and coordinating the policies for both agents. The proposed approach not only aligns more closely with practical operational characteristics but also effectively utilizes the inherent knowledge and reasoning capabilities of the LLM agent, significantly improving training efficiency and voltage control performance. Comprehensive comparisons and ablation studies demonstrate the effectiveness of the proposed method."}
{"id": "2602.22112", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.22112", "abs": "https://arxiv.org/abs/2602.22112", "authors": ["Bill D. A. Huacarpuma", "Jose A. dos S. Laranjeira", "Nicolas F. Martins", "Julio R. Sambrano", "Kleuton A. L. Lima", "Santosh K. Tiwari", "Alexandre C. Dias", "Luiz A. Ribeiro"], "title": "Phase-Dependent Excitonic Light Harvesting and Photovoltaic Limits in Monolayer Y2TeO2 MOenes", "comment": "In preparation for Journal Submission", "summary": "We investigate phase-dependent electronic and excitonic phenomena in monolayer Y2TeO2 MOenes in the 1T and 2H polymorphs using first-principles theory and an effective many-body framework. Phonon spectra and elastic stability criteria establish both phases as dynamically and mechanically stable. Quasiparticle band structures reveal direct gaps in the near-infrared to visible range, with gap values increasing systematically from semilocal to hybrid exchange treatments. Optical spectra computed using a tight-binding Bethe-Salpeter approach demonstrate pronounced excitonic resonances arising from reduced dimensionality and weak dielectric screening. The exciton binding energies reach 152 meV in the 1T phase and 126 meV in the 2H phase, reflecting enhanced quantum confinement in the structurally denser phase. Our results identify Y2TeO2monolayers as a rare class of stable, direct-gap MOenes with strong excitonic effects, providing a platform for exploring many-body physics in low-dimensional oxychalcogenide systems especially for photovoltaic applications."}
{"id": "2602.21926", "categories": ["cs.SI", "cs.DL", "cs.LG", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.21926", "abs": "https://arxiv.org/abs/2602.21926", "authors": ["Somyajit Chakraborty", "Angshuman Jana", "Avijit Gayen"], "title": "Bridging Through Absence: How Comeback Researchers Bridge Knowledge Gaps Through Structural Re-emergence", "comment": "Preprint; 25 pages, 14 figures, 7 tables, Submitted to Scientometrics 2025", "summary": "Understanding the role of researchers who return to academia after prolonged inactivity, termed \"comeback researchers\", is crucial for developing inclusive models of scientific careers. This study investigates the structural and semantic behaviors of comeback researchers, focusing on their role in cross-disciplinary knowledge transfer and network reintegration. Using the AMiner citation dataset, we analyze 113,637 early-career researchers and identify 1,425 comeback cases based on a three-year-or-longer publication gap followed by renewed activity. We find that comeback researchers cite 126% more distinct communities and exhibit 7.6% higher bridging scores compared to dropouts. They also demonstrate 74% higher gap entropy, reflecting more irregular yet strategically impactful publication trajectories. Predictive models trained on these bridging- and entropy-based features achieve a 97% ROC-AUC, far outperforming the 54% ROC-AUC of baseline models using traditional metrics like publication count and h-index. Finally, we substantiate these results via a multi-lens validation. These findings highlight the unique contributions of comeback researchers and offer data-driven tools for their early identification and institutional support."}
{"id": "2602.21579", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21579", "abs": "https://arxiv.org/abs/2602.21579", "authors": ["Shivam", "Bhargab Chattopadhyay", "Nil Kamal Hazra"], "title": "Asymptotically Optimal Sequential Confidence Interval for the Gini Index Under Complex Household Survey Design with Sub-Stratification", "comment": null, "summary": "We examine the optimality properties of the Gini index estimator under complex survey design involving stratification, clustering, and sub-stratification. While Darku et al. (Econometrics, 26, 2020) considered only stratification and clustering and did not provide theoretical guarantees, this study addresses these limitations by proposing two procedures - a purely sequential method and a two-stage method. Under suitable regularity conditions, we establish uniform continuity in probability for the proposed estimator, thereby contributing to the development of random central limit theorems under sequential sampling frameworks. Furthermore, we show that the resulting procedures satisfy both asymptotic first-order efficiency and asymptotic consistency. Simulation results demonstrate that the proposed procedures achieve the desired optimality properties across diverse settings. The practical utility of the methodology is further illustrated through an empirical application using data collected by the National Sample Survey agency of India"}
{"id": "2602.21715", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.21715", "abs": "https://arxiv.org/abs/2602.21715", "authors": ["Xu Yang", "Chenhui Lin", "Xiang Ma", "Dong Liu", "Ran Zheng", "Haotian Liu", "Wenchuan Wu"], "title": "Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach", "comment": null, "summary": "The growing integration of distributed photovoltaics (PVs) into active distribution networks (ADNs) has exacerbated operational challenges, making it imperative to coordinate diverse equipment to mitigate voltage violations and enhance power quality. Although existing data-driven approaches have demonstrated effectiveness in the voltage control problem, they often require extensive trial-and-error exploration and struggle to incorporate heterogeneous information, such as day-ahead forecasts and semantic-based grid codes. Considering the operational scenarios and requirements in real-world ADNs, in this paper, we propose a hybrid knowledge-data-driven approach that leverages dynamic collaboration between a large language model (LLM) agent and a reinforcement learning (RL) agent to achieve two-stage voltage control. In the day-ahead stage, the LLM agent receives coarse region-level forecasts and generates scheduling strategies for on-load tap changer (OLTC) and shunt capacitors (SCs) to regulate the overall voltage profile. Then in the intra-day stage, based on accurate node-level measurements, the RL agent refines terminal voltages by deriving reactive power generation strategies for PV inverters. On top of the LLM-RL collaboration framework, we further propose a self-evolution mechanism for the LLM agent and a pretrain-finetune pipeline for the RL agent, effectively enhancing and coordinating the policies for both agents. The proposed approach not only aligns more closely with practical operational characteristics but also effectively utilizes the inherent knowledge and reasoning capabilities of the LLM agent, significantly improving training efficiency and voltage control performance. Comprehensive comparisons and ablation studies demonstrate the effectiveness of the proposed method."}
{"id": "2602.22019", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.22019", "abs": "https://arxiv.org/abs/2602.22019", "authors": ["Yu Han", "Pan Liu", "Zhiyuan Liu", "Ludovic Leclercq"], "title": "Capacity drop accounting for microscopic vehicle interaction effects: analytical model and validation with high-resolution trajectories", "comment": null, "summary": "Capacity drop is a traffic phenomenon in which the discharge flow from a queue is lower than the theoretical infrastructure capacity. This paper proposes a generic analytical method to estimate the queue discharge flow of freeway traffic. Capacity drop is primarily attributed to hesitant vehicles, defined as vehicles that stochastically and temporarily enter an acceleration delay state and generate voids (i.e., extra gaps) in front of them. The proposed method estimates the expected total void length generated by all hesitant vehicles, based on the distributions of their spatial and temporal locations as well as the associated delays. It also accounts for interactions between the waves triggered by downstream hesitant vehicles and the voids generated by upstream ones. Our analysis reveals that this interaction is the key mechanism behind the differing extents of capacity drop observed between standing queues and jam waves in previous studies. The accuracy of the model is validated through both numerical simulations and real-world trajectories. Overall, the proposed method offers a deeper understanding of capacity drop, which can be leveraged in traffic flow modeling and control."}
{"id": "2602.21587", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.21587", "abs": "https://arxiv.org/abs/2602.21587", "authors": ["Yusei Shimizu", "Arvind Maurya", "Yoshiya Homma", "Motoi Kimata", "Toni Helm", "Ai Nakamura", "Dexin Li", "Atsushi Miyake", "Dai Aoki"], "title": "Hall effect on nontrivial quadrupole order in quasi-kagome compound URhSn", "comment": "5 pages, 4 figures, accepted for publication in J. Phys. Soc. Jpn", "summary": "This study focuses on the transport properties of the quasi-kagome compound URhSn, which exhibits successive phase transitions at TC =16 K (ferromagnetic phase) and TO =54 K (intermediate phase). A large anomalous Hall component is present along the easy-magnetization axis (H|| [0001]), and the Hall resistivity shows very complex temperature- and field-dependence, with a sign reversal at low temperatures. The Hall resistivity exhibits a nonlinear and unusual field-dependence. Interestingly, there exists an unusual Hall component that is not proportional to the magnetic susceptibility for H || [0001] in both the intermediate and ferromagnetic states. These results reveal unconventional transport properties of URhSn, providing important insights into nontrivial multipolar phases in 5f- electron systems."}
{"id": "2602.21355", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2602.21355", "abs": "https://arxiv.org/abs/2602.21355", "authors": ["Connor Aronoff", "Travis Howard", "David Nicholaeff", "Alejandro Lopez-Bezanilla", "Wade DeGottardi"], "title": "Assessing quantum coherence in quantum annealers", "comment": "10 pages, 6 figures", "summary": "Demonstrating genuine many-body quantum coherence in large-scale quantum processors remains a central challenge for near-term quantum technologies. Recent experiments on D-Wave quantum annealers have investigated quenches of Ising chains and observed defect densities that show Kibble-Zurek scaling, consistent with coherent quantum dynamics. However, identical scaling can arise from classical or thermal processes. Here we propose the use of many-body coherent oscillations (MBCO) as a diagnostic for the identification of system-wide coherence in analog quantum simulators. Solving the time-dependent Schrodinger equation, we show that quenches of a staggered one-dimensional Ising chain across a quantum critical point produce oscillatory signatures in defect observables. We implement this model on the D-Wave Advantage quantum annealer. Using fast-anneal protocols, we find that, although defect densities follow Kibble-Zurek scaling, the expected oscillatory behavior is absent. We demonstrate that static disorder associated with individual qubits is not likely responsible for the absence of MBCO. Modest modifications to annealing schedules can dramatically enhance oscillation visibility. This work gives a general roadmap for the search for quantum coherence in noisy, large-scale quantum platforms."}
{"id": "2602.21901", "categories": ["cond-mat.stat-mech", "math-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.21901", "abs": "https://arxiv.org/abs/2602.21901", "authors": ["Davide Carbone", "Vincenzo Di Florio", "Stefano Lepri", "Lamberto Rondoni"], "title": "Computing Nonequilibrium Transport from Short-Time Transients: From Lorentz Gas to Heat Conduction in One Dimensional Chains", "comment": null, "summary": "We test the Transient Time Correlation Function (TTCF) method to compute nonequilibrium transport coefficients, highlighting its conceptual and practical difference from the standard time-average approach. While time averages extract transport properties from long stationary trajectories and discard transient dynamics, TTCF adopts the complementary strategy: it exploits the information contained in short-time transients following the onset of an external perturbation, while discarding the long-time evolution once stationarity is reached. We revisit the theoretical framework of TTCF and assess its numerical performance through representative case studies, the Lorentz gas and a many-body system, namely a chain of oscillators with anharmonic pinning potential. By direct comparison with time averages, we show that for the Lorentz gas TTCF yields consistent transport coefficients in both linear and nonlinear regimes at a reduced computational cost. Moreover, the TTCF displays superior precision in the linear-response regime, and remains reliable in non-ergodic situations, revealing the presence of regions of phase space corresponding to different behaviors, as well as the possibility of phase transitions. For the anharmonic chain, we show that TTCF is a scalable and efficient alternative for the numerical study of nonequilibrium transport."}
{"id": "2602.22178", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.22178", "abs": "https://arxiv.org/abs/2602.22178", "authors": ["Céline Cunen", "Nils Lid Hjort", "Tore Schweder"], "title": "Confidence in confidence distributions!", "comment": "5 pages, 2 figures. Statistical Research Report, Department of Mathematics, University of Oslo, February 2020, here arXiv'd February 2026. Published in Proceedings of the Royal Society, Series A, 2020, vo. 476, at this url: royalsocietypublishing.org/rspa/article/476/2237/20190781/56889", "summary": "The recent article `Satellite conjunction analysis and the false confidence theorem' (Balch, Martin, and Ferson, 2019, Proceedings of the Royal Society, Series A) points to certain difficulties with Bayesian analysis when used for models for satellite conjuntion and ensuing operative decisions. Here we supplement these previous analyses and findings with further insights, uncovering what we perceive of as being the crucial points, explained in a prototype setup where exact analysis is attainable. We also show that a different and frequentist method, involving confidence distributions, is free of the false confidence syndrome."}
{"id": "2602.21883", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.21883", "abs": "https://arxiv.org/abs/2602.21883", "authors": ["Markus Herrmann-Wicklmayr", "Kathrin Flaßkamp"], "title": "Non-Extreme Individual Minima for Improved Pareto Front Sampling Efficiency and Decision-Making", "comment": null, "summary": "In multi-objective optimization, the set of optimal trade-offs -- the Pareto front -- often contains regions that are extremely steep or flat. The Pareto optimal points in these regions are typically of limited interest for decision-making, as the marginal rate of substitution is extreme: a marginal improvement in one objective necessitates a significant deterioration in at least one other objective. These unfavorable trade-offs frequently occur near the individual minima, where single objectives attain their minimum values without considering the remaining criteria.\n  To address this, we propose the concept of \\emph{non-extreme individual minima} that relies on the notion of $L$-practical proper efficiency. These points can serve as a less sensitive replacement for \\emph{standard} individual minima in subsequent related methods. Specifically, they allow for a more practical restriction of the Pareto front sampling within a refined utopia-nadir hyperbox, provide a meaningful basis for image space normalization, and can enhance decision-making techniques, such as knee-point methods, by focusing on regions with acceptable trade-offs.\n  We provide a computationally efficient algorithm to determine these non-extreme individual minima by solving at most $2n_J$ standard weighted-sum scalarizations, where $n_J$ is the number of objectives. To ensure robustness across varying objective scales, the method incorporates an integrated image space normalization strategy. Numerical examples, specifically a convex academic case and a non-convex real-world application, demonstrate that the method successfully excludes practically irrelevant regions in the image space."}
{"id": "2602.21913", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.21913", "abs": "https://arxiv.org/abs/2602.21913", "authors": ["Raphael Leu", "Thomas P. Wihler"], "title": "A fully iterative adaptive energy-based approach for monotone elliptic problems", "comment": null, "summary": "We present a fully iterative adaptive algorithm for the numerical minimization of strongly convex energy functionals in Hilbert spaces. The proposed approach, which we first present in abstract form, generates a hierarchical sequence of adaptively refined finite-dimensional approximation spaces and employs a (nonlinear) conjugate gradient (CG) method to compute suitable approximations on each space. A core novelty of our approach is that all components of the algorithm are consistently driven by energy reduction principles rather than by classical a posteriori estimators. In particular, adaptive refinement is steered by local energy reduction indicators which aim to construct subsequent approximation spaces in a way that attains the largest potential decrease in energy. Likewise, the stopping criteria for the iterative solver are based on either relative or averaged energy reductions on each subspace. As a concrete realization, we present a concise implementation for $\\mathbb{P}_1$ finite element discretizations of second-order semilinear elliptic diffusion-reaction models, where the local indicators driving the element refinements are computed based on edge-wise energy reductions. Numerical experiments demonstrate that the resulting scheme achieves optimal convergence for various benchmark problems in two-dimensional polygonal domains."}
{"id": "2602.21738", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21738", "abs": "https://arxiv.org/abs/2602.21738", "authors": ["Pelin Sekercioglu", "Angela Fontan", "Dimos V. Dimarogonas"], "title": "Stability of Open Multi-agent Systems over Dynamic Signed Digraphs", "comment": null, "summary": "We address the synchronization problem in open multi-agent systems (OMAS) containing both cooperative and antagonistic interactions. In these systems, agents can join or leave the network over time, and the interaction structure may evolve accordingly. To capture these dynamical structural changes, we represent the network as a switched system interconnected over a dynamic and directed signed graph. Additionally, the network may contain one or multiple leader groups that influence the behavior of the remaining agents. In general, we show that the OMAS exhibit a more general form of synchronization, including trivial consensus, bipartite consensus and containment. Our approach uses the signed edge-based agreement protocol, and constructs strict Lyapunov functions for signed networks described by signed edge-Laplacian matrices containing multiple zero eigenvalues. Numerical simulations validate our theoretical results."}
{"id": "2602.21299", "categories": ["cond-mat.str-el", "physics.chem-ph", "physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21299", "abs": "https://arxiv.org/abs/2602.21299", "authors": ["Zhen Tao", "Victor Galitski"], "title": "Ab Initio Random Matrix Theory of Molecular Electronic Structure", "comment": "8 pages, 8 figures", "summary": "We use ab initio electronic-structure methods to investigate random-matrix theory (RMT) universality in molecular electronic structure. Using single-reference electronic structure methods, including Hartree-Fock, configuration-interaction singles (CIS), density functional theory, and linear-response time-dependent density-functional theory, we compute single-particle orbital energies and many-electron excitations of several representative molecules (benzene, alanine, 1-phenylethylamine, methyloxirane, and helicene chains). For generic low-symmetry geometries, the unfolded spectra of these ab initio Hamiltonians exhibit Wigner-Dyson level statistics of the Gaussian orthogonal ensemble (GOE). For extended helicene chains we explicitly restrict to bound valence excitations below the ionization threshold and still observe GOE statistics, indicating that the RMT universality is present for physical states of direct relevance to real molecules. We further explore the electric and magnetic field dependence of the molecular electronic spectra. The variance of electric polarizability (level curvature K) is predicted to be non-analytic in the magnetic field which serves as an infrared cutoff, <K^2> proportional to log(1/|B|). We observe a transition to the Gaussian unitary ensemble (GUE) by increasing the magnetic fields, although it occurs only at magnetic fields far beyond experimentally accessible scales. Our results indicate that random matrix universality provides a general framework for organizing ab initio predictions of interacting electron spectra in complex systems."}
{"id": "2602.21663", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21663", "abs": "https://arxiv.org/abs/2602.21663", "authors": ["Steffen Grønneberg", "Gudmund Hermansen", "Nils Lid Hjort"], "title": "Estimation, inference and model selection for jump regression models", "comment": "33 pages, 3 figures; Statistical Research Report, Department of Mathematics, University of Oslo, from June 2014, and arXiv'd February 2026. This paper constituted a part of the doctoral dissertations for respectively Gudmund Hermansen and Steffen Grønneberg. An extended and polished version will be written up for journal publication", "summary": "We consider regression models with data of the type $y_i=m(x_i)+\\varepsilon_i$, where the $m(x)$ curve is taken locally constant, with unknown levels and jump points. We investigate the large-sample properties of the minimum least squares estimators, finding in particular that jump point parameters and level parameters are estimated with respectively $n$-rate precision and $\\sqrt{n}$-rate precision, where $n$ is sample size. Bayes solutions are investigated as well and found to be superior. We then construct jump information criteria, respectively AJIC and BJIC, for selecting the right number of jump points from data. This is done by following the line of arguments that lead to the Akaike and Bayesian information criteria AIC and BIC, but which here lead to different formulae due to the different type of large-sample approximations involved."}
{"id": "2602.21738", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21738", "abs": "https://arxiv.org/abs/2602.21738", "authors": ["Pelin Sekercioglu", "Angela Fontan", "Dimos V. Dimarogonas"], "title": "Stability of Open Multi-agent Systems over Dynamic Signed Digraphs", "comment": null, "summary": "We address the synchronization problem in open multi-agent systems (OMAS) containing both cooperative and antagonistic interactions. In these systems, agents can join or leave the network over time, and the interaction structure may evolve accordingly. To capture these dynamical structural changes, we represent the network as a switched system interconnected over a dynamic and directed signed graph. Additionally, the network may contain one or multiple leader groups that influence the behavior of the remaining agents. In general, we show that the OMAS exhibit a more general form of synchronization, including trivial consensus, bipartite consensus and containment. Our approach uses the signed edge-based agreement protocol, and constructs strict Lyapunov functions for signed networks described by signed edge-Laplacian matrices containing multiple zero eigenvalues. Numerical simulations validate our theoretical results."}
{"id": "2602.22031", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.22031", "abs": "https://arxiv.org/abs/2602.22031", "authors": ["Mingrong She", "Jan Bachmann", "Fariba Karimi", "Leto Peel"], "title": "Academic collaborations and movements towards successful careers in physics", "comment": "14 pages, 8 figures", "summary": "Collaboration networks evolve throughout academic careers, yet few studies systematically examine how these network dynamics relate to long-term career success and mobility. Analysing 35,708 physicists' careers spanning at least 15 years, we use time series clustering to identify ten distinct evolution patterns of network size and clustering coefficient across career years 5 to 15. We report three key results. First, authors who begin with loosely connected networks and progressively tighten their networks while expanding network size during mid-career achieve the highest PI attainment rates, publication output, and citation impact. Second, despite different starting points, network evolution patterns associated with better outcomes converge toward moderate clustering by career year 15, suggesting an optimal balance between core team cohesion and diverse external connections. Third, mobility is positively associated with these successful network evolution patterns and remains positively associated with scientific outcomes even after controlling for network evolution patterns."}
{"id": "2602.21695", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.21695", "abs": "https://arxiv.org/abs/2602.21695", "authors": ["Quentin Staelens", "Daan Verraes", "Daan Vrancken", "Tom Braeckevelt", "Jutho Haegeman", "Veronique Van Speybroeck"], "title": "Combining matrix product states and mean-field theory to capture magnetic order in quasi-1D cuprates", "comment": null, "summary": "We study quasi-one-dimensional strongly correlated materials using a multi-step approach based on density functional theory, downfolding techniques, and tensor-network simulations. The downfolding procedure yields effective multiband Hubbard models that capture the competition between electron hopping and local Coulomb interactions relevant to the system's low-energy properties. The resulting multiband Hubbard models are solved using matrix product states. Applied to Sr$_2$CuO$_3$, SrBaCuO$_3$, and Ba$_2$CuO$_3$, this purely one-dimensional treatment yields no long-range magnetic order, in contrast to the magnetic ordering observed experimentally. To account for this behavior, we extend the multi-step approach by incorporating interchain couplings through a self-consistent mean-field scheme. This combined approach stabilizes finite staggered magnetizations, providing a consistent description of magnetic order in agreement with experiment. For Sr$_2$CuO$_{3.5}$ and SrCuO$_2$, we also tested an approach proposed for ladder materials, however, we find that these materials are not well suited for this approach due to the small magnitude of the intraladder hopping parameters."}
{"id": "2602.21387", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21387", "abs": "https://arxiv.org/abs/2602.21387", "authors": ["Grigory Koroteev"], "title": "Natural Qubit Algebra: clarification of the Clifford boundary and new non-embeddability theorem", "comment": "26 pages", "summary": "We introduce Natural Qubit Algebra (NQA), a compact real operator calculus for qubit systems based on a $2\\times2$ block alphabet $\\{I,X,Z,W\\}\\subset\\mathrm{Mat}(2,\\mathbb{R})$ and tensor-word representations. The resulting multiplication law induces a canonical $(\\mathbb{Z}_2)^{2m}$-grading with a bicharacter that controls commutation signs, placing the framework naturally within the theory of color-graded and Clifford-type algebras.\n  Within this language, we provide: (i) an explicit real Clifford normal form for two-qubit operators via the identification $\\mathrm{Mat}(4,\\mathbb{R})\\cong\\mathrm{Cl}(2,2;\\mathbb{R})$; (ii) a purely algebraic reformulation of the Bell--CHSH scenario, where the quantum violation is expressed as a spectral non-embeddability of a noncommutative spinor algebra into any commutative Kolmogorov algebra; and (iii) compact factored representations of the Bernstein--Vazirani and Grover phase oracles, showing that both Clifford and non-Clifford examples can admit similarly structured symbolic descriptions.\n  We clarify that Grover's iterate remains outside the Clifford group due to its continuous spectral rotation, consistent with the Gottesman--Knill theorem, while retaining a compact tensor-block form in NQA. The framework isolates spectral, algebraic, and syntactic aspects of operator structure, providing a graded operator language compatible with standard quantum mechanics."}
{"id": "2602.22028", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2602.22028", "abs": "https://arxiv.org/abs/2602.22028", "authors": ["Xia-qing Shi", "Hugues Chaté", "Benoît Mahault"], "title": "XY Model with Persistent Noise", "comment": "7 pages, 5 figures", "summary": "We consider a 2D XY model subjected to time-correlated noise, a model of direct relevance to active crystals, which were shown recently to be able to support very large deformations without melting in the presence of persistent fluctuations. We find that our persistent XY model can remain quasi-ordered in spite of correlations decaying much faster than allowed in equilibrium. We then investigate theoretically and numerically the order-disorder transition and conclude that it remains of the Berezinskii-Kosterlitz-Thouless type, but with scaling exponents that vary with the persistence time of the noise."}
{"id": "2207.00985", "categories": ["math.NA", "cs.DM", "math.ST", "stat.AP", "stat.ME"], "pdf": "https://arxiv.org/pdf/2207.00985", "abs": "https://arxiv.org/abs/2207.00985", "authors": ["Dmytro Lande", "Volodymyr Yuzefovych", "Yevheniia Tsybulska"], "title": "Linguistic Approach to Time Series Forecasting", "comment": "8 pages, 9 figures", "summary": "This paper proposes methods of predicting dynamic time series (including non-stationary ones) based on a linguistic approach, namely, the study of occurrences and repetition of so-called N-grams. This approach is used in computational linguistics to create statistical translators, detect plagiarism and duplicate documents. However, the scope of application can be extended beyond linguistics by taking into account the correlations of sequences of stable word combinations, as well as trends. The proposed methods do not require a preliminary study and determination of the characteristics of time series or complex tuning of the input parameters of the forecasting model. They allow, with a high level of automation, to carry out short-term and medium-term forecasts of time series, characterized by trends and cyclicality, in particular, series of publication dynamics in content monitoring systems. Also, the proposed methods can be used to predict the values of the parameters of a large complex system with the aim of monitoring its state, when the number of such parameters is significant, and therefore a high level of automation of the forecasting process is desirable. A significant advantage of the approach is the absence of requirements for time series stationarity and a small number of tuning parameters. Further research may focus on the study of various criteria for the similarity of time series fragments, the use of nonlinear similarity criteria, the search for ways to automatically determine the rational step of quantization of the time series."}
{"id": "2602.21924", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.21924", "abs": "https://arxiv.org/abs/2602.21924", "authors": ["Armin Pirastehzad", "Bart Besselink"], "title": "Comparison of Linear Systems Across Time Domains: Continuous-time vs. Discrete-time", "comment": null, "summary": "We develop a formal framework for the behavioral comparison of linear systems across different time domains. We accomplish this by introducing the notion of system interpolation, which determines whether the input-state trajectories of a continuous-time system can be realized as piecewise polynomial interpolations of the input-state trajectories of a discrete-time system. In this context, a piecewise polynomial interpolation of a discrete-time signal is characterized as a continuous-time function that coincides with the discrete-time signal at given sampling instants and can be realized as a polynomial of a prescribed degree over intervals between these instants. By representing piecewise polynomial functions as linear combinations of shifted Legendre polynomials, we characterize system interpolation as a subspace inclusion that is completely in terms of system parameters. This therefore allows for a computationally efficient comparison of the input-state behavior of a continuous-time system with that of a discrete-time one. We then exploit this characterization to discretize a given continuous-time system into a discrete-time one. Lastly, given a control specification, we exploit system interpolation to synthesize controllers that ensure satisfaction at each given sampling instant, while they measure the extent of (possible) violation over intervals between these instants."}
{"id": "2602.21916", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21916", "abs": "https://arxiv.org/abs/2602.21916", "authors": ["Yunying Ke", "Hao Luo"], "title": "Robust Kaczmarz methods for nearly singular linear systems", "comment": null, "summary": "The Kaczmarz method is an efficient iterative algorithm for large-scale linear systems. However, its linear convergence rate suffers from ill-conditioned problems and is highly sensitive to the smallest nonzero singular value. In this work, we aim to extend the classical Kaczmarz to nearly singular linear systems that are row rank-deficient. We introduce a new concept of nearly singular property by treating the row space as an unstable subspace in the Grassman manifold. We then define a related important space called the approximate kernel, based on which a robust kernel-augmented Kaczmarz (KaK) is introduced via the subspace correction framework and analyzed by the well-known Xu--Zikatanov identity. To get an implementable version, we further introduce the approximate dual kernel and transform KaK into an equivalent kernel-augmented coordinate descent. Furthermore, we develop an accelerated variant and establish the improved rate of convergence matching the optimal complexity of first-order methods. Compared with existing methods, ours achieve uniform convergence rates for nearly singular linear systems, and the robustness has been confirmed by some numerical tests."}
{"id": "2602.21752", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.21752", "abs": "https://arxiv.org/abs/2602.21752", "authors": ["Minjie Tang", "Zunqi Li", "Photios A. Stavrou", "Marios Kountouris"], "title": "Pilot-Free Optimal Control over Wireless Networks: A Control-Aided Channel Prediction Approach", "comment": null, "summary": "A recurring theme in optimal controller design for wireless networked control systems (WNCS) is the reliance on real-time channel state information (CSI). However, acquiring accurate CSI a priori is notoriously challenging due to the time-varying nature of wireless channels. In this work, we propose a pilot-free framework for optimal control over wireless channels in which control commands are generated from plant states together with control-aided channel prediction. For linear plants operating over an orthogonal frequency-division multiplexing (OFDM) architecture, channel prediction is performed via a Kalman filter (KF), and the optimal control policy is derived from the Bellman principle. To alleviate the curse of dimensionality in computing the optimal control policy, we approximate the solution using a coupled algebraic Riccati equation (CARE), which can be computed efficiently via a stochastic approximation (SA) algorithm. Rigorous performance guarantees are established by proving the stability of both the channel predictor and the closed-loop system under the resulting control policy, providing sufficient conditions for the existence and uniqueness of a stabilizing approximate CARE solution, and establishing convergence of the SA-based control algorithm. The framework is further extended to nonlinear plants under general wireless architectures by combining a KalmanNet-based predictor with a Markov-modulated deep deterministic policy gradient (MM-DDPG) controller. Numerical results show that the proposed pilot-free approach outperforms benchmark schemes in both control performance and channel prediction accuracy for linear and nonlinear scenarios."}
{"id": "2602.21808", "categories": ["quant-ph", "math-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.21808", "abs": "https://arxiv.org/abs/2602.21808", "authors": ["Wesley Lewis", "Darsh Pareek", "Umesh Kumar", "Ravi Janjam"], "title": "Imperfect Graphs from Unitary Matrices -- I", "comment": null, "summary": "Matrix representations of quantum operators are computationally complete but often obscure the structural topology of information flow within a quantum circuit \\cite{nielsen2000}. In this paper, we introduce a generalized graph-theoretic framework for analyzing quantum operators by mapping unitary matrices to directed graphs; we term these structures \\emph{Imperfect Graphs} or more formally as \\emph{Topological Structure of Superpositions}(TSS) as a tool to devise better Quantum Algorithms. In this framework, we represent computational basis states as vertices. A directed edge exists between two vertices if and only if there is a non-zero amplitude transition between them, effectively mapping the support of the unitary operator. In this paper we deliberately discard probability amplitudes and phase information to isolate the connectivity and reachability properties of the operator. We demonstrate how TSS intuitively helps describe gates such as the Hadamard, Pauli-(X,Y,Z) gates, etc \\cite{nielsen2000}. This framework provides a novel perspective for viewing quantum circuits as discrete dynamical systems \\cite{childs2009,aharonov2001}\n  Keywords: Quantum Algorithms, Unitary Matrix Approach, Topological Structure of Superpositions (TSS), Graph Theory"}
{"id": "2602.21711", "categories": ["stat.ME", "math.ST", "stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.21711", "abs": "https://arxiv.org/abs/2602.21711", "authors": ["Yuyao Wang", "Yu Lu", "Tianni Zhang", "Mengfei Ran"], "title": "Adaptive Penalized Doubly Robust Regression for Longitudinal Data", "comment": null, "summary": "Longitudinal data often involve heterogeneity, sparse signals, and contamination from response outliers or high-leverage observations especially in biomedical science. Existing methods usually address only part of this problem, either emphasizing penalized mixed effects modeling without robustness or robust mixed effects estimation without high-dimensional variable selection. We propose a doubly adaptive robust regression (DAR-R) framework for longitudinal linear mixed effects models. It combines a robust pilot fit, doubly adaptive observation weights for residual outliers and leverage points, and folded concave penalization for fixed effect selection, together with weighted updates of random effects and variance components. We develop an iterative reweighting algorithm and establish estimation and prediction error bounds, support recovery consistency, and oracle-type asymptotic normality. Simulations show that DAR-R improves estimation accuracy, false-positive control, and covariance estimation under both vertical outliers and bad leverage contamination. In the TADPOLE/ADNI Alzheimer's disease application, DAR-R achieves accurate and stable prediction of ADAS13 while selecting clinically meaningful predictors with strong resampling stability."}
{"id": "2602.21752", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2602.21752", "abs": "https://arxiv.org/abs/2602.21752", "authors": ["Minjie Tang", "Zunqi Li", "Photios A. Stavrou", "Marios Kountouris"], "title": "Pilot-Free Optimal Control over Wireless Networks: A Control-Aided Channel Prediction Approach", "comment": null, "summary": "A recurring theme in optimal controller design for wireless networked control systems (WNCS) is the reliance on real-time channel state information (CSI). However, acquiring accurate CSI a priori is notoriously challenging due to the time-varying nature of wireless channels. In this work, we propose a pilot-free framework for optimal control over wireless channels in which control commands are generated from plant states together with control-aided channel prediction. For linear plants operating over an orthogonal frequency-division multiplexing (OFDM) architecture, channel prediction is performed via a Kalman filter (KF), and the optimal control policy is derived from the Bellman principle. To alleviate the curse of dimensionality in computing the optimal control policy, we approximate the solution using a coupled algebraic Riccati equation (CARE), which can be computed efficiently via a stochastic approximation (SA) algorithm. Rigorous performance guarantees are established by proving the stability of both the channel predictor and the closed-loop system under the resulting control policy, providing sufficient conditions for the existence and uniqueness of a stabilizing approximate CARE solution, and establishing convergence of the SA-based control algorithm. The framework is further extended to nonlinear plants under general wireless architectures by combining a KalmanNet-based predictor with a Markov-modulated deep deterministic policy gradient (MM-DDPG) controller. Numerical results show that the proposed pilot-free approach outperforms benchmark schemes in both control performance and channel prediction accuracy for linear and nonlinear scenarios."}
{"id": "2602.21926", "categories": ["cs.SI", "cs.DL", "cs.LG", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.21926", "abs": "https://arxiv.org/abs/2602.21926", "authors": ["Somyajit Chakraborty", "Angshuman Jana", "Avijit Gayen"], "title": "Bridging Through Absence: How Comeback Researchers Bridge Knowledge Gaps Through Structural Re-emergence", "comment": "Preprint; 25 pages, 14 figures, 7 tables, Submitted to Scientometrics 2025", "summary": "Understanding the role of researchers who return to academia after prolonged inactivity, termed \"comeback researchers\", is crucial for developing inclusive models of scientific careers. This study investigates the structural and semantic behaviors of comeback researchers, focusing on their role in cross-disciplinary knowledge transfer and network reintegration. Using the AMiner citation dataset, we analyze 113,637 early-career researchers and identify 1,425 comeback cases based on a three-year-or-longer publication gap followed by renewed activity. We find that comeback researchers cite 126% more distinct communities and exhibit 7.6% higher bridging scores compared to dropouts. They also demonstrate 74% higher gap entropy, reflecting more irregular yet strategically impactful publication trajectories. Predictive models trained on these bridging- and entropy-based features achieve a 97% ROC-AUC, far outperforming the 54% ROC-AUC of baseline models using traditional metrics like publication count and h-index. Finally, we substantiate these results via a multi-lens validation. These findings highlight the unique contributions of comeback researchers and offer data-driven tools for their early identification and institutional support."}
{"id": "2602.21962", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.21962", "abs": "https://arxiv.org/abs/2602.21962", "authors": ["Meng-Yun Mao", "Zhixiang Sun", "Wen-Long You"], "title": "Tighter thermalization bounds for perturbed quantum many-body scars", "comment": "9 pages, 6 figures", "summary": "Quantum many-body scars (QMBS) are exceptional eigenstates that defy thermalization, enabling long-lived coherent dynamics in strongly interacting systems. However, their stability under perturbations remains inadequately understood. In this work, we derive improved lower bounds on the thermalization time of QMBS under local perturbations with strength $λ$. Using both numerical simulations and analytical reasoning, we show that exact QMBS exhibit slow thermalization, with a timescale scaling as $τ\\sim \\mathcal{O}(λ^{-1/d})$ owing to the stabilizing restricted spectrum-generating algebra (RSGA), which is a significant improvement over previous bounds (e.g., $τ\\sim \\mathcal{O}(λ^{-1/(d+1)})$). Counterintuitively, approximate QMBS can thermalize even more slowly under generic perturbations, exhibiting $τ\\sim \\mathcal{O}(λ^{-2})$ scaling due to second-order perturbative effects in the absence of such protective structure. These distinct thermalization behaviors clarify how exact and approximate scars maintain coherence. Our work advances previous findings by establishing a tighter bound on the thermalization time, clarifying when scarred dynamics remain long-lived under weak but generic perturbations."}
{"id": "2602.21430", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21430", "abs": "https://arxiv.org/abs/2602.21430", "authors": ["Meng Xu", "J. T. Stockburger", "J. Ankerhold"], "title": "Markovian Embeddings of Non-Markovian Open System Dynamics", "comment": "9 pages", "summary": "Embedding non-Markovian open quantum dynamics into an enlarged Markovian space offers a powerful route to nonperturbative simulations, where the dynamics of the extended space can be governed by multiple distinct Markovian equations. We show that these distinct embeddings arise from different unravelings of Gaussian bath self-energies, generating a family of deterministic, time-local equations for the extended system. Using the Brownian-oscillator spectral density as an illustrative example, we clarify the relationships among existing approaches, including the Hierarchical Equations of Motion (HEOM) and the Lindblad--pseudomode formalism, and demonstrate how this framework enables numerically stable and efficient simulations. This work provides both a transparent theoretical foundation for embedding techniques and a flexible platform for developing new methods to simulate non-Markovian quantum dynamics."}
{"id": "2602.22205", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech", "math-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.22205", "abs": "https://arxiv.org/abs/2602.22205", "authors": ["Aritra Ghosh", "M. Bhattacharya"], "title": "Quantum jumps in open cavity optomechanics and Liouvillian versus Hamiltonian exceptional points", "comment": null, "summary": "Exceptional points, where two or more eigenstates of a non-Hermitian system coalesce, are now of interest across many fields of physics, from the perspective of open-system dynamics, sensing, nonreciprocal transport, and topological phase transitions. In this work, we investigate exceptional points in cavity optomechanics, a platform of interest to diverse communities working on gravitational-wave detection, macroscopic quantum mechanics, quantum transduction, etc. Specifically, we clarify the role of quantum jumps in making a clear distinction between Liouvillian and Hamiltonian exceptional points in optomechanical systems. While the Liouvillian exceptional point arises from the unconditional Lindblad dynamics and is independent of the phonon-bath temperature, the Hamiltonian exceptional point emerges from the conditional no-jump evolution and acquires a thermal shift due to an enhanced conditional damping. Employing the thermofield formalism, we derive a unified spectral framework that interpolates between these regimes via an analytical hybrid-Liouvillian description. Remarkably, in the weak-quantum-jump regime, the exceptional point is perturbed only at the second order, highlighting the robustness of the Hamiltonian exceptional point under small hybrid perturbations. Our work reveals a continuous family of hybrid exceptional points, clarifies the operational and physical differences between the conditional and unconditional dissipative dynamics in optomechanical systems, and provides a probe for thermal baths."}
{"id": "2602.21711", "categories": ["stat.ME", "math.ST", "stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.21711", "abs": "https://arxiv.org/abs/2602.21711", "authors": ["Yuyao Wang", "Yu Lu", "Tianni Zhang", "Mengfei Ran"], "title": "Adaptive Penalized Doubly Robust Regression for Longitudinal Data", "comment": null, "summary": "Longitudinal data often involve heterogeneity, sparse signals, and contamination from response outliers or high-leverage observations especially in biomedical science. Existing methods usually address only part of this problem, either emphasizing penalized mixed effects modeling without robustness or robust mixed effects estimation without high-dimensional variable selection. We propose a doubly adaptive robust regression (DAR-R) framework for longitudinal linear mixed effects models. It combines a robust pilot fit, doubly adaptive observation weights for residual outliers and leverage points, and folded concave penalization for fixed effect selection, together with weighted updates of random effects and variance components. We develop an iterative reweighting algorithm and establish estimation and prediction error bounds, support recovery consistency, and oracle-type asymptotic normality. Simulations show that DAR-R improves estimation accuracy, false-positive control, and covariance estimation under both vertical outliers and bad leverage contamination. In the TADPOLE/ADNI Alzheimer's disease application, DAR-R achieves accurate and stable prediction of ADAS13 while selecting clinically meaningful predictors with strong resampling stability."}
{"id": "2602.21999", "categories": ["math.OC", "math.AP", "math.DS"], "pdf": "https://arxiv.org/pdf/2602.21999", "abs": "https://arxiv.org/abs/2602.21999", "authors": ["Claudia Alvarez-Latuz", "Terence Bayen", "Jerome Coville"], "title": "Target controllability for a minimum time problem in a trait-structured chemostat model", "comment": null, "summary": "In this paper, we consider a minimum time control problem governed by a trait-structured chemostat model including mutation and one limiting substrate. Our first main result proves the well-posedness of the control-to-state mapping. We subsequently analyze the class of auxostat-type controls, feedback laws designed to regulate substrate concentration, and prove that the corresponding solutions converge to a stationary state of the system. These convergence results are used to show the reachability of a target set corresponding to the selection of a population with a low weighted averaged half-saturation constant. Finally, we show the existence of an optimal control for the minimum time problem associated with reaching the target set. These theoretical findings are completed by numerical simulations."}
{"id": "2602.21958", "categories": ["math.NA", "astro-ph.SR"], "pdf": "https://arxiv.org/pdf/2602.21958", "abs": "https://arxiv.org/abs/2602.21958", "authors": ["Pietro Benedusi", "Simone Riva", "Luca Belluzzi", "Stefano Serra-Capizzano"], "title": "Analysis of eigenvalue clustering leads to optimal scaling in numerical radiative transfer", "comment": null, "summary": "We consider a multidimensional polychromatic radiative transfer (RT) problem, accounting for scattering processes in a general form, i.e. anisotropic (dipole) scattering with partial frequency redistribution. Given a discrete ordinates discretization, we report the corresponding matrix structures, depending on model and discretization parameters. Despite the possibly dense nature of these matrices, the use of Krylov methods is effective (especially in the matrix-free context) and robust. We propose a theoretical analysis, using the spectral tools of the symbol theory, explaining why Krylov convergence is robust w.r.t. all the discretization parameters, even in the unpreconditioned case. In fact, the compactness of the continuous operators used in the modeling leads to zero-clustered dense matrix sequences plus identity, so that the clustering at the unity of the spectra is deduced. Numerical experiments confirm the theoretical results, which have a direct application, for example, in the simulation of radiative transfer in stellar atmospheres, a key problem in astrophysical research. In general, we demonstrate that optimal scaling with respect to RT discretization parameters is expected for Krylov solution strategies."}
{"id": "2602.21768", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21768", "abs": "https://arxiv.org/abs/2602.21768", "authors": ["Omayra Yago Nieto", "Leonardo Colombo"], "title": "Learning-Based Geometric Leader-Follower Control for Cooperative Rigid-Payload Transport with Aerial Manipulators", "comment": null, "summary": "This paper presents a learning-based tracking control framework for cooperative transport of a rigid payload by multiple aerial manipulators under rigid grasp constraints. A unified geometric model is developed, yielding a coupled agent--payload differential--algebraic system that explicitly captures contact wrenches, payload dynamics, and internal force redundancy. A leader--follower architecture is adopted in which a designated leader generates a desired payload wrench based on geometric tracking errors, while the remaining agents realize this wrench through constraint-consistent force allocation.\n  Unknown disturbances and modeling uncertainties are compensated using Gaussian Process (GP) regression. High-probability bounds on the learning error are explicitly incorporated into the control design, combining GP feedforward compensation with geometric feedback. Lyapunov analysis establishes uniform ultimate boundedness of the payload tracking errors with high probability, with an ultimate bound that scales with the GP predictive uncertainty."}
{"id": "2602.21901", "categories": ["cond-mat.stat-mech", "math-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.21901", "abs": "https://arxiv.org/abs/2602.21901", "authors": ["Davide Carbone", "Vincenzo Di Florio", "Stefano Lepri", "Lamberto Rondoni"], "title": "Computing Nonequilibrium Transport from Short-Time Transients: From Lorentz Gas to Heat Conduction in One Dimensional Chains", "comment": null, "summary": "We test the Transient Time Correlation Function (TTCF) method to compute nonequilibrium transport coefficients, highlighting its conceptual and practical difference from the standard time-average approach. While time averages extract transport properties from long stationary trajectories and discard transient dynamics, TTCF adopts the complementary strategy: it exploits the information contained in short-time transients following the onset of an external perturbation, while discarding the long-time evolution once stationarity is reached. We revisit the theoretical framework of TTCF and assess its numerical performance through representative case studies, the Lorentz gas and a many-body system, namely a chain of oscillators with anharmonic pinning potential. By direct comparison with time averages, we show that for the Lorentz gas TTCF yields consistent transport coefficients in both linear and nonlinear regimes at a reduced computational cost. Moreover, the TTCF displays superior precision in the linear-response regime, and remains reliable in non-ergodic situations, revealing the presence of regions of phase space corresponding to different behaviors, as well as the possibility of phase transitions. For the anharmonic chain, we show that TTCF is a scalable and efficient alternative for the numerical study of nonequilibrium transport."}
{"id": "2602.21713", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21713", "abs": "https://arxiv.org/abs/2602.21713", "authors": ["Andreas Markoulidakis", "Matthew Hickman", "Nicky J Welton", "Loukia Meligkotsidou", "Hayley E Jones"], "title": "Multi-Parameter Estimation of Prevalence (MPEP): A Bayesian modelling approach to estimate the prevalence of opioid dependence", "comment": null, "summary": "Estimating the number of the number of people from hidden and/or marginalised populations - such as people dependent on opioids or cocaine - is important to guide policy decisions and provision of harm reduction services. Methods such as capture-recapture are widely used, but rely on assumptions that are often violated and not feasible in specific applications. We describe a Bayesian modelling approach called Multi-Parameter Estimation of Prevalence (MPEP). The MPEP approach leverages routinely collected administrative data, starting from a large baseline cohort of individuals from the population of interest and linked events, to estimate the full size of the target population. When multiple event types are included, the approach enables checking of the consistency of evidence about prevalence from different event types. Additional evidence can be incorporated where inconsistencies are identified. In this article, we summarize the general framework of MPEP, with focus on the most recent version, with improved computational efficiency (implemented in STAN). We also explore several extensions to the model that help us understand the sensitivity of the results to modelling assumptions or identify potential sources of bias. We demonstrate the MPEP approach through a case study estimating the prevalence of opioid dependence in Scotland each year from 2014 to 2022."}
{"id": "2602.21768", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21768", "abs": "https://arxiv.org/abs/2602.21768", "authors": ["Omayra Yago Nieto", "Leonardo Colombo"], "title": "Learning-Based Geometric Leader-Follower Control for Cooperative Rigid-Payload Transport with Aerial Manipulators", "comment": null, "summary": "This paper presents a learning-based tracking control framework for cooperative transport of a rigid payload by multiple aerial manipulators under rigid grasp constraints. A unified geometric model is developed, yielding a coupled agent--payload differential--algebraic system that explicitly captures contact wrenches, payload dynamics, and internal force redundancy. A leader--follower architecture is adopted in which a designated leader generates a desired payload wrench based on geometric tracking errors, while the remaining agents realize this wrench through constraint-consistent force allocation.\n  Unknown disturbances and modeling uncertainties are compensated using Gaussian Process (GP) regression. High-probability bounds on the learning error are explicitly incorporated into the control design, combining GP feedforward compensation with geometric feedback. Lyapunov analysis establishes uniform ultimate boundedness of the payload tracking errors with high probability, with an ultimate bound that scales with the GP predictive uncertainty."}
{"id": "2602.22005", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.22005", "abs": "https://arxiv.org/abs/2602.22005", "authors": ["Hari Borutta", "Tobias Müller", "Ronny Thomale", "Harald O. Jeschke", "Yasir Iqbal"], "title": "Crystallography-driven molecularization of a two-dimensional spin-$3/2$ magnet", "comment": "11 pages, 5 figures, 1 table, and Supplementary Material", "summary": "Large-spin two-dimensional magnets are generally expected to develop conventional long-range order once the dominant exchange scale becomes appreciable. The layered spin-$3/2$ maple-leaf compound Na$_2$Mn$_3$O$_7$ defies this expectation: despite sizable antiferromagnetic interactions and no evident disorder, it exhibits no magnetic ordering and displays two well-separated thermodynamic crossover scales. We show that this behavior originates from a crystallography-driven molecularization of the magnetic degrees of freedom. The low-symmetry structure partitions the Mn sublattice into inequivalent exchange pathways, generating a pronounced hierarchy that nearly isolates antiferromagnetic hexagons. Magnetic correlations therefore develop in two stages: first within individual hexagons at a scale set by the dominant exchange, and only at much lower temperatures do frustrated inter-hexagon couplings attempt to establish coherence across the lattice. While isolated hexagons reproduce the two-step thermodynamic structure, the experimentally relevant temperature scales emerge only once the hexagons are embedded in the frustrated two-dimensional network. The resulting quantum ground state is magnetically disordered, characterized by strong intra-hexagon correlations and rapidly decaying inter-hexagon correlations. These results identify crystallographic inequivalence as a materials-level mechanism for stabilizing molecularized and quantum-disordered states even in large-spin two-dimensional magnets."}
{"id": "2602.21451", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.21451", "abs": "https://arxiv.org/abs/2602.21451", "authors": ["Hiroshi Yamaguchi", "Motoki Asano"], "title": "Topological phase dynamics described by overtone-synthesized classical and quantum Adler equations", "comment": "Main text: 11 pages, 5 figures; Supplemental Materials included in the PDF (total: 25 pages, 6 figures)", "summary": "The Adler equation is a well-known one-dimensional model describing phase locking and synchronization. Motivated by recent experiments using optomechanical oscillators, we extend the model to include overtone-synthesized sinusoidal coupling with adiabatic temporal modulation. This extension gives rise to unique topological features such as winding-number quantization, discontinuous phase-slip transitions, and hysteretic and non-reciprocal phase dynamics. We further extend the analysis to the quantum regime, where we find a counterintuitive result: the breakdown of winding-number quantization. This arises from the superposition of different winding-number states in a closed-space Thouless pump. Moreover, hysteretic dynamics, once eliminated in quantum adiabatic approximation, is recovered in non-adiabatic calculations, as the superposition of two Floquet states with different PT eigenvalues becomes the quantum counterpart of phase trajectory."}
{"id": "2602.22047", "categories": ["math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.22047", "abs": "https://arxiv.org/abs/2602.22047", "authors": ["Johannes Milz", "Alexander Shapiro", "Enlu Zhou"], "title": "Stochastic Optimal Control with Side Information and Bayesian Learning", "comment": null, "summary": "We study infinite-horizon stochastic optimal control problems with observable side information: a Markov chain that modulates an unknown context-conditional randomness distribution. Since this distribution is unknown, we propose a Bayesian reformulation based on a parametric density model and posterior predictive dynamics, which yields a Bayesian Bellman equation. We prove posterior consistency under Markov samples and, under correct specification and identifiability, uniform convergence of the Bayesian value function. Finally, we establish Bernstein--von Mises-type asymptotic normality for the data-driven contextual optimal value."}
{"id": "2602.22047", "categories": ["math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.22047", "abs": "https://arxiv.org/abs/2602.22047", "authors": ["Johannes Milz", "Alexander Shapiro", "Enlu Zhou"], "title": "Stochastic Optimal Control with Side Information and Bayesian Learning", "comment": null, "summary": "We study infinite-horizon stochastic optimal control problems with observable side information: a Markov chain that modulates an unknown context-conditional randomness distribution. Since this distribution is unknown, we propose a Bayesian reformulation based on a parametric density model and posterior predictive dynamics, which yields a Bayesian Bellman equation. We prove posterior consistency under Markov samples and, under correct specification and identifiability, uniform convergence of the Bayesian value function. Finally, we establish Bernstein--von Mises-type asymptotic normality for the data-driven contextual optimal value."}
{"id": "2602.21974", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.21974", "abs": "https://arxiv.org/abs/2602.21974", "authors": ["Martina Iannacito", "Lorenzo Piccinini", "Valeria Simoncini"], "title": "Subspace gradient descent method for linear tensor equations", "comment": "21 pages, 2 figures, 4 tables", "summary": "The numerical solution of algebraic tensor equations is a largely open and challenging task. Assuming that the operator is symmetric and positive definite, we propose two new gradient-descent type methods for tensor equations that generalize the recently proposed Subspace Conjugate Gradient (SS-CG), D. Palitta et al, SIAM J. Matrix Analysis and Appl (2025). As our interest is mainly in a modest number of tensor modes, the Tucker format is used to efficiently represent low-rank tensors. Moreover, mixed-precision strategies are employed in certain subtasks to improve the memory usage, and different preconditioners are applied to enhance convergence. The potential of our strategies is illustrated by experimental results on tensor-oriented discretizations of three-dimensional partial differential equations with separable coefficients. Comparisons with the state-of-the-art Alternating Minimal Energy (AMEn) algorithm confirm the competitiveness of the proposed strategies."}
{"id": "2602.21852", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21852", "abs": "https://arxiv.org/abs/2602.21852", "authors": ["Haoran Su", "Hanxiao Deng"], "title": "LightSim: A Lightweight Cell Transmission Model Simulator for Traffic Signal Control Research", "comment": null, "summary": "Reinforcement learning for traffic signal control is bottlenecked by simulators: training in SUMO takes hours, reproducing results often requires days of platform-specific setup, and the slow iteration cycle discourages the multi-seed experiments that rigorous evaluation demands. Much of this cost is unnecessary, since for signal timing optimization the relevant dynamics are queue formation and discharge, which the Cell Transmission Model (CTM) captures as a macroscopic flow model.\n  We introduce LightSim, a pure Python, pip-installable traffic simulator with Gymnasium and PettingZoo interfaces that runs over 20000 steps per second on a single CPU. Across cross-simulator experiments spanning single intersections, grid networks, arterial corridors, and six real-world city networks, LightSim preserves controller rankings from SUMO for both classical and reinforcement learning strategies while training 3 to 7 times faster. LightSim is released as an open-source benchmark with nineteen built-in scenarios, seven controllers, and full reinforcement learning pipelines, lowering the barrier to signal control research from days to minutes."}
{"id": "2602.21969", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21969", "abs": "https://arxiv.org/abs/2602.21969", "authors": ["Nabaneet Das", "Thorsten Dickhaus"], "title": "Estimation of the complexity of a network under a Gaussian graphical model", "comment": null, "summary": "The proportion of edges in a Gaussian graphical model (GGM) characterizes the complexity of its conditional dependence structure. Since edge presence corresponds to a nonzero entry of the precision matrix, estimation of this proportion can be formulated as a large-scale multiple testing problem. We propose an estimator that combines p-values from simultaneous edge-wise tests, conducted under false discovery rate control, with Storey's estimator of the proportion of true null hypotheses. We establish weak dependence conditions on the precision matrix under which the empirical cumulative distribution function of the p-values converges to its population counterpart. These conditions cover high-dimensional regimes, including those arising in genetic association studies. Under such dependence, we characterize the asymptotic bias of the Schweder--Spjøtvoll estimator, showing that it is upward biased and thus slightly underestimates the true edge proportion. Simulation studies across a variety of models confirm accurate recovery of graph complexity."}
{"id": "2602.21852", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21852", "abs": "https://arxiv.org/abs/2602.21852", "authors": ["Haoran Su", "Hanxiao Deng"], "title": "LightSim: A Lightweight Cell Transmission Model Simulator for Traffic Signal Control Research", "comment": null, "summary": "Reinforcement learning for traffic signal control is bottlenecked by simulators: training in SUMO takes hours, reproducing results often requires days of platform-specific setup, and the slow iteration cycle discourages the multi-seed experiments that rigorous evaluation demands. Much of this cost is unnecessary, since for signal timing optimization the relevant dynamics are queue formation and discharge, which the Cell Transmission Model (CTM) captures as a macroscopic flow model.\n  We introduce LightSim, a pure Python, pip-installable traffic simulator with Gymnasium and PettingZoo interfaces that runs over 20000 steps per second on a single CPU. Across cross-simulator experiments spanning single intersections, grid networks, arterial corridors, and six real-world city networks, LightSim preserves controller rankings from SUMO for both classical and reinforcement learning strategies while training 3 to 7 times faster. LightSim is released as an open-source benchmark with nineteen built-in scenarios, seven controllers, and full reinforcement learning pipelines, lowering the barrier to signal control research from days to minutes."}
{"id": "2602.22093", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2602.22093", "abs": "https://arxiv.org/abs/2602.22093", "authors": ["Yuxin Wang", "Vladimir Dobrosavljević", "Jan Jaroszyński", "Yohei Saito", "Atsushi Kawamoto", "Andrej Pustogow", "Martin Dressel", "Dragana Popović"], "title": "Mott Intermittency at the Metal-Insulator Boundary", "comment": "6 pages, 4 figures + Suppl. Mat. (2 pages + 6 figures)", "summary": "The resistivity maximum at a temperature $T=T_{\\mathrm{max}}$ is a recurring feature of bandwidth-tuned Mott systems, yet its meaning remains controversial: is it a coherence-incoherence crossover of an electronically homogeneous metal, or does it mark the onset of transport through a mixed landscape of metallic and insulating regions? Even more debated is whether a true phase-coexistence regime survives in the relevant parameter range, or whether apparent inhomogeneity is merely extrinsic. Here we address these questions by moving beyond temperature sweeps and probe charge transport in the time domain. Near $T=T_{\\mathrm{max}}$, we find that the resistance of a model system, a quasi-two-dimensional Mott spin liquid material, exhibits clear random-telegraph switching between discrete levels over long timescales. The statistics of the switching - sharp two-level behavior with thermally activated dwell times - point to a mesoscopic \"current-controlling\" region that dynamically toggles between metallic and insulating states, intermittently opening and closing the dominant conduction channel. This characteristic fluctuating dynamics provides direct evidence for intrinsic metal-insulator coexistence and establishes $T\\sim T_{\\mathrm{max}}$ as the regime of Mott intermittency, where transport is governed by stochastic domain switching rather than quasiparticle decoherence."}
{"id": "2602.21471", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21471", "abs": "https://arxiv.org/abs/2602.21471", "authors": ["Xue-Na Zhu", "Gui Bao", "Ming Li", "Ming-Jing Zhao", "Shao-Ming Fei"], "title": "On fully entangled fraction of arbitrary $d\\otimes d$ quantum states", "comment": "9 pages,2 figures", "summary": "We study the fully entangled fraction of quantum states based on the Bloch representation of density matrices. Analytical upper bounds on the fully entangled fraction are obtained for arbitrary $d\\otimes d$ bipartite systems. The fully entangled fractions for classes of $d\\otimes d$ quantum states are analytically derived. Detailed examples are given to illustrate the advantages of our results."}
{"id": "2602.22062", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.22062", "abs": "https://arxiv.org/abs/2602.22062", "authors": ["Jiawei Li", "Nguyen Nguyen", "Meng Lai", "Ioannis Ch. Paschalidis", "Jonathan H. Huggins"], "title": "Robust Model Selection for Discovery of Latent Mechanistic Processes", "comment": null, "summary": "When learning interpretable latent structures using model-based approaches, even small deviations from modeling assumptions can lead to inferential results that are not mechanistically meaningful. In this work, we consider latent structures that consist of $K_o$ mechanistic processes, where $K_o$ is unknown. When the model is misspecified, likelihood-based model selection methods can substantially overestimate $K_o$ while more robust nonparametric methods can be overly conservative. Hence, there is a need for approaches that combine the sensitivity of likelihood-based methods with the robustness of nonparametric ones. We formalize this objective in terms of a robust model selection consistency property, which is based on a component-level discrepancy measure that captures the mechanistic structure of the model. We then propose the accumulated cutoff discrepancy criterion (ACDC), which leverages plug-in estimates of component-level discrepancies. To apply ACDC, we develop mechanistically meaningful component-level discrepancies for a general class of latent variable models that includes unsupervised and supervised variants of probabilistic matrix factorization and mixture modeling. We show that ACDC is robustly consistent when applied to unsupervised matrix factorization and mixture models. Numerical results demonstrate that in practice our approach reliably identifies a mechanistically meaningful number of latent processes in numerous illustrative applications, outperforming existing methods."}
{"id": "2602.22058", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.22058", "abs": "https://arxiv.org/abs/2602.22058", "authors": ["Bin Tian", "Kai Pan", "Chung-Lun Li"], "title": "A Polyhedral Study on Unit Commitment with a Single Type of Binary Variables", "comment": null, "summary": "Efficient power production scheduling is a crucial concern for power system operators aiming to minimize operational costs. Previous mixed-integer linear programming formulations for unit commitment (UC) problems have primarily used two or three types of binary variables. The investigation of strong formulations with a single type of binary variables has been limited, as it is believed to be challenging to derive strong valid inequalities using fewer binary variables, and the reduction of the number of binary variables is often accompanied by a compromise in tightness. To address these issues, this paper considers a formulation for unit commitment using a single type of binary variables and develops strong valid inequality families to enhance the tightness of the formulation. Conditions under which these strong valid inequalities serve as facet-defining inequalities for the single-generator UC polytope are provided. For those large-size valid inequality families, the existence of efficient separation algorithms for determining the most violated inequalities is also discussed. The effectiveness of the proposed single-binary formulation and strong valid inequalities is demonstrated through computational experiments on network-constrained UC problems. The results indicate that the strong valid inequalities presented in this paper are effective in solving UC problems and can also be applied to UC formulations that contain more than one type of binary variables."}
{"id": "2602.22068", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.22068", "abs": "https://arxiv.org/abs/2602.22068", "authors": ["Guillaume Bal", "Chushan Wang"], "title": "Optimal error bounds on the exponential integrator for dispersive equations with highly concentrated potential", "comment": "40 pages, 8 figures", "summary": "We study a one-dimensional linear dispersive equation of differential order $κ\\geq 2$ with concentrated potential of extension $\\varepsilon$ with $0 < \\varepsilon \\ll 1$, featuring a competition between weak dispersion of strength $\\varepsilon^α\\ (0 \\leq α\\leq κ)$ and localization induced by the concentrated potential. We first obtain precise regularity estimates of the exact solution in terms of $\\varepsilon$. We then apply a natural first-order exponential integrator with step size $τ$ to discretize the equation, and establish an optimal error bound of the form $O_{L^\\infty}(τ\\varepsilon^β)$ (up to logarithmic factors in $τ$ and $\\varepsilon$). Salient features of the result are: (i) error bounds are not only uniform in $\\varepsilon$ but improve as $\\varepsilon \\rightarrow 0$; and (ii) no restriction on $τ$ in terms of $\\varepsilon$. The analysis combines iterated Duhamel's expansions and a transformation that exploits cancellations in oscillatory phases that cannot be obtained directly from regularity estimates of the exact solution. We also show that other classical numerical schemes, such as Lie or centered splitting schemes and low regularity integrators, fail to display optimal rates of convergence. Extensive numerical results are presented and confirm the theoretical error estimates."}
{"id": "2602.21868", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21868", "abs": "https://arxiv.org/abs/2602.21868", "authors": ["Lucas Souza e Silva", "Luis Rodrigues"], "title": "On the airspace complexity metrics for predecessor-follower operations", "comment": "3 pages, 2 figures", "summary": "This technical note proposes a novel airspace complexity metric that quantifies the air traffic controller workload and coordination effort for pairwise predecessor-follower aircraft operations in cruise. The pairwise dynamic workload (PDW) is proposed as a continuous function that depends on the relevant parameters of these operations, such as the aircraft separation and separation rate. A comparison of this metric with the dynamic density (DD) shows that it is capable of continuously evaluating the variation of airspace complexity over time and monitoring the aircraft parameters that might lead to conflicts. This metric can be used to support the implementation of autonomous and supervised aircraft procedures, to achieve a more structured and coordinated airspace."}
{"id": "2602.21998", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21998", "abs": "https://arxiv.org/abs/2602.21998", "authors": ["Xinran Li", "Anqi Zhao"], "title": "Design-based theory for causal inference from adaptive experiments", "comment": null, "summary": "Adaptive designs dynamically update treatment probabilities using information accumulated during the experiment. Existing theory for causal inference from adaptive experiments primarily assumes the superpopulation framework with independent and identically distributed units, and may not apply when the distribution of units evolves over time. This paper makes two contributions. First, we extend the literature to the finite-population framework, which allows for possibly nonexchangeable units, and establish the design-based theory for causal inference under general adaptive designs using inverse-propensity-weighted (IPW) and augmented IPW (AIPW) estimators. Our theory accommodates nonexchangeable units, both nonconverging and vanishing treatment probabilities, and nonconverging outcome estimators, thereby justifying inference using AIPW estimators with black-box outcome models that integrate advances from machine learning methods. To alleviate the conservativeness inherent in variance estimation under finite-population inference, we also introduce a covariance estimator for the AIPW estimator that becomes sharp when the residuals from the adaptive regression of potential outcomes on covariates are additive across units. Our framework encompasses widely used adaptive designs, such as multi-armed bandits, covariate-adaptive randomization, and sequential rerandomization, advancing the design-based theory for causal inference in these specific settings. Second, as a methodological contribution, we propose an adaptive covariate adjustment approach for analyzing even nonadaptive designs. The martingale structure induced by adaptive adjustment enables valid inference with black-box outcome estimators that would otherwise require strong assumptions under standard nonadaptive analysis."}
{"id": "2602.21868", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21868", "abs": "https://arxiv.org/abs/2602.21868", "authors": ["Lucas Souza e Silva", "Luis Rodrigues"], "title": "On the airspace complexity metrics for predecessor-follower operations", "comment": "3 pages, 2 figures", "summary": "This technical note proposes a novel airspace complexity metric that quantifies the air traffic controller workload and coordination effort for pairwise predecessor-follower aircraft operations in cruise. The pairwise dynamic workload (PDW) is proposed as a continuous function that depends on the relevant parameters of these operations, such as the aircraft separation and separation rate. A comparison of this metric with the dynamic density (DD) shows that it is capable of continuously evaluating the variation of airspace complexity over time and monitoring the aircraft parameters that might lead to conflicts. This metric can be used to support the implementation of autonomous and supervised aircraft procedures, to achieve a more structured and coordinated airspace."}
{"id": "2602.22113", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.22113", "abs": "https://arxiv.org/abs/2602.22113", "authors": ["Sander De Meyer", "Atsushi Ueda", "Yuchi He", "Nick Bultinck", "Jutho Haegeman"], "title": "Lowering the temperature of two-dimensional fermionic tensor networks with cluster expansions", "comment": null, "summary": "Representing the time-evolution operator as a tensor network constitutes a key ingredient in several algorithms for studying quantum lattice systems at finite temperature or in a non-equilibrium setting. For a Hamiltonian composed of strictly short-ranged interactions, the Suzuki-Trotter decomposition is the main technique for obtaining such a representation. In [B.~Vanhecke, L.~Vanderstraeten and F.~Verstraete, Physical Review A, L020402 (2021)], an alternative strategy, the cluster expansion, was introduced. This approach naturally preserves internal and lattice symmetries and can more easily be extended to higher-order representations or longer-ranged interactions. We extend the cluster expansion to two-dimensional fermionic systems, and employ it to construct projected entangled-pair operator (PEPO) approximations of Gibbs states. We also discuss and benchmark different truncation schemes for multiplying layers of PEPOs together. Applying the resulting framework to a two-dimensional spinless fermion model with attractive interactions, we resolve a clear phase boundary at finite temperature."}
{"id": "2602.21474", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21474", "abs": "https://arxiv.org/abs/2602.21474", "authors": ["N. Amaral", "A. R. C. Buarque", "W. S. Dias"], "title": "Nonlinearity-Inhomogeneity Competition in Discrete-Time Quantum Walks", "comment": "7 pages, 4 figures", "summary": "We investigate the interplay between nonlinearity and inhomogeneities in discrete-time quantum walks on one-dimensional lattices. Nonlinear effects are introduced through a Kerr-like, intensity-dependent local phase, while spatial and temporal inhomogeneities are implemented via random variations of the quantum gate operations. By analyzing typical quantities, such as the return probability and the participation function, we identify distinct quantum walking regimes as the nonlinear parameter $χ$ and the quantum gate parameter $θ$ are varied. Spatial inhomogeneities weaken nonlinear self-trapping and constrict the region of robust localization. In this process, partially localized regimes emerge, characterized by the coexistence of a confined core and dispersive wave-packet components. In contrast, temporal inhomogeneities act as time-dependent perturbations that continuously disrupt the phase coherence required for self-trapped excitation, thereby enhancing dispersive emission and promoting delocalization. By using $χ$ versus $θ$ diagrams, we display a comprehensive characterization of how inhomogeneities modify the stability and extent of prevailing dynamical regimes, elucidating the competition between nonlinearity and inhomogeneities in discrete-time quantum walks."}
{"id": "2602.22173", "categories": ["math.OC", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.22173", "abs": "https://arxiv.org/abs/2602.22173", "authors": ["Antonio A. Chaves", "Mauricio G. C. Resende", "Carise E. Schmidt", "J. Kyle Brubaker", "Helmut G. Katzgraber"], "title": "Applying a Random-Key Optimizer on Mixed Integer Programs", "comment": "29 pages, 8 figures, 6 tables, 4 algorithm pseudocodes", "summary": "Mixed-Integer Programs (MIPs) are NP-hard optimization models that arise in a broad range of decision-making applications, including finance, logistics, energy systems, and network design. Although modern commercial solvers have achieved remarkable progress and perform effectively on many small- and medium-sized instances, their performance often degrades when confronted with large-cale or highly constrained formulations. This paper explores the use of the Random-Key Optimizer (RKO) framework as a flexible, metaheuristic alternative for computing high-quality solutions to MIPs through the design of problem-specific decoders. The proposed approach separates the search process from feasibility enforcement by operating in a continuous random-key space while mapping candidate solutions to feasible integer solutions via efficient decoding procedures. We evaluate the methodology on two representative and structurally distinct benchmark problems: the mean-variance Markowitz portfolio optimization problem with buy-in and cardinality constraints, and the Time-Dependent Traveling Salesman Problem. For each formulation, tailored decoders are developed to reduce the effective search space, promote feasibility, and accelerate convergence. Computational experiments demonstrate that RKO consistently produces competitive, and in several cases superior, solutions compared to a state-of-the-art commercial MIP solver, both in terms of solution quality and computational time. These results highlight the potential of RKO as a scalable and versatile heuristic framework for tackling challenging large-scale MIPs."}
{"id": "2602.22084", "categories": ["math.NA", "math.SP"], "pdf": "https://arxiv.org/pdf/2602.22084", "abs": "https://arxiv.org/abs/2602.22084", "authors": ["Francesco Hrobat", "Yuji Nakatsukasa"], "title": "Matrix Perturbation Theory in the Tangent Space of Isospectral Matrices", "comment": "27 pages, 6 figures", "summary": "Eigenvalue and eigenvector perturbation theory is a fundamental topic in several disciplines, including numerical linear algebra, quantum physics, and related fields. The central problem is to understand how the eigenvalues and eigenvectors of a matrix $A \\in \\mathbb{C}^{n \\times n}$ change under the addition of a perturbation matrix $E \\in \\mathbb{C}^{n \\times n}$. Much of the existing literature focuses on structured perturbations. For example, in [C.-K. Li and R.-C. Li, Linear Algebra Appl. 2005], the matrix $A$ is assumed to be Hermitian and block diagonal, while the perturbation $E$ is Hermitian and block off-diagonal. In this work, we investigate a different structured setting in which the perturbation has the commutator form $E = AB - BA$ for some matrix $B$, which we show to be a generalization of the block diagonal structure considered by Li and Li. First, we extend their main result by showing that the perturbation of the $i$-th eigenvalue of $A$, denoted by $λ_i$, is of order $\\|E\\|^2 / η_i$, where $η_i = \\min_{j \\neq i} |λ_i - λ_j|$ is the spectral gap associated with $λ_i$. Second, we provide a detailed analysis of the role played by the matrix $B$ in the perturbation of the eigenvectors. This analysis is further generalized to the case of block-diagonal matrices with multiple eigenvalues, as well as to perturbed singular values and eigenvalues of Jordan blocks."}
{"id": "2602.21914", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21914", "abs": "https://arxiv.org/abs/2602.21914", "authors": ["Jie Han", "Arash Khalatbarisoltani", "Hai L. Vu", "Xiaosong Hu", "Jun Yang"], "title": "Traffic-aware Hierarchical Integrated Thermal and Energy Management for Connected HEVs", "comment": null, "summary": "The energy and thermal management systems of hybrid electric vehicles (HEVs) are inherently interdependent. With the ongoing deployment of intelligent transportation systems (ITSs) and increasing vehicle connectivity, the integration of traffic information has become crucial for improving both energy efficiency and thermal comfort in modern vehicles. To enhance fuel economy, this paper proposes a novel traffic-aware hierarchical integrated thermal and energy management (TA-ITEM) strategy for connected HEVs. In the upper layer, global reference trajectories for battery state of charge (SOC) and cabin temperature are planned using traffic flow speed information obtained from ITSs. In the lower layer, a real-time model predictive control (MPC)-based ITEM controller is developed, which incorporates a novel Transformer-based speed predictor with driving condition recognition (TF-DCR) to enable anticipatory tracking of the reference trajectories. Numerical simulations are conducted under various driving cycles and ambient temperature conditions. The results demonstrate that the proposed TA-ITEM approach outperforms conventional rule-based and MPC-SP approaches, with average fuel consumption reductions of 56.36\\% and 5.84\\%, respectively, while maintaining superior thermal regulation and cabin comfort. These findings confirm the effectiveness and strong generalization capability of TA-ITEM and underscore the advantages of incorporating traffic information."}
{"id": "2602.22021", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.22021", "abs": "https://arxiv.org/abs/2602.22021", "authors": ["Jiacan Gao", "Xinyan Su", "Mingyuan Ma", "Yiyan Huang", "Xiao Xu", "Xinrui Wan", "Tianqi Gu", "Enyun Yu", "Jiecheng Guo", "Zhiheng Zhang"], "title": "Budgeted Active Experimentation for Treatment Effect Estimation from Observational and Randomized Data", "comment": null, "summary": "Estimating heterogeneous treatment effects is central to data-driven decision-making, yet industrial applications often face a fundamental tension between limited randomized controlled trial (RCT) budgets and abundant but biased observational data collected under historical targeting policies. Although observational logs offer the advantage of scale, they inherently suffer from severe policyinduced imbalance and overlap violations, rendering standalone estimation unreliable. We propose a budgeted active experimentation framework that iteratively enhances model training for causal effect estimation via active sampling. By leveraging observational priors, we develop an acquisition function targeting uplift estimation uncertainty, overlap deficits, and domain discrepancy to select the most informative units for randomized experiments. We establish finite-sample deviation bounds, asymptotic normality via martingale Central Limit Theorems (CLTs), and minimax lower bounds to prove information-theoretic optimality. Extensive experiments on industrial datasets demonstrate that our approach significantly outperforms standard randomized baselines in cost-constrained settings."}
{"id": "2602.21914", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.21914", "abs": "https://arxiv.org/abs/2602.21914", "authors": ["Jie Han", "Arash Khalatbarisoltani", "Hai L. Vu", "Xiaosong Hu", "Jun Yang"], "title": "Traffic-aware Hierarchical Integrated Thermal and Energy Management for Connected HEVs", "comment": null, "summary": "The energy and thermal management systems of hybrid electric vehicles (HEVs) are inherently interdependent. With the ongoing deployment of intelligent transportation systems (ITSs) and increasing vehicle connectivity, the integration of traffic information has become crucial for improving both energy efficiency and thermal comfort in modern vehicles. To enhance fuel economy, this paper proposes a novel traffic-aware hierarchical integrated thermal and energy management (TA-ITEM) strategy for connected HEVs. In the upper layer, global reference trajectories for battery state of charge (SOC) and cabin temperature are planned using traffic flow speed information obtained from ITSs. In the lower layer, a real-time model predictive control (MPC)-based ITEM controller is developed, which incorporates a novel Transformer-based speed predictor with driving condition recognition (TF-DCR) to enable anticipatory tracking of the reference trajectories. Numerical simulations are conducted under various driving cycles and ambient temperature conditions. The results demonstrate that the proposed TA-ITEM approach outperforms conventional rule-based and MPC-SP approaches, with average fuel consumption reductions of 56.36\\% and 5.84\\%, respectively, while maintaining superior thermal regulation and cabin comfort. These findings confirm the effectiveness and strong generalization capability of TA-ITEM and underscore the advantages of incorporating traffic information."}
{"id": "2602.22185", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.22185", "abs": "https://arxiv.org/abs/2602.22185", "authors": ["Kuan-Sen Lin", "Yuan Fang", "Henrique Fabrelli", "Runhan Li", "Andrey Prokofiev", "Fang Xie", "Jennifer Cano", "Maia G. Vergniory", "Silke Paschen", "Qimiao Si"], "title": "Chiral Weyl-Kondo semimetals and hexagonal heavy fermion systems", "comment": "25+59 pages, 3+31 figures", "summary": "Strong correlation, in concert with symmetry and topology, engenders novel gapless phases of matter, though only a tip of the iceberg has been seen. An exemplary framework is provided by Weyl-Kondo semimetals, in which Weyl fermions develop through crystalline symmetry constraints on the emergent low-energy heavy-fermion excitations. This paradigm has opened up new opportunities to explore correlated topologies without a noninteracting counterpart, but fully realizing this potential requires a large base of candidate materials. Here we confront the challenge on both fronts by studying heavy fermion systems with hexagonal space groups. This family contains a large number of chiral nonsymmorphic crystal structures that promote Weyl degeneracies and, in addition, feature geometric frustration in the $f$-electron magnetism. Our calculations for the heavy fermion states identify Weyl-Kondo semimetals with chiral or achiral Weyl nodes in the respective structural classes. We also develop a new search strategy for the difficult case of strongly correlated materials, using a combination of materials database, symmetry classification and experiments, and propose as candidate topological heavy fermion systems the chiral CePt$_2$B and achiral Ce$_2$NiGe$_3$ and Ce$_6$Co$_{2-δ}$Si$_3$. Our findings raise the prospect for strongly correlated metallic topology in the unusual setting of exotic quantum magnetism."}
{"id": "2602.21483", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21483", "abs": "https://arxiv.org/abs/2602.21483", "authors": ["Xiao Xiang", "Runai Quan", "Yuting Liu", "Huibo Hong", "Bingke Shi", "Zhiguang Xia", "Xinghua Li", "Tao Liu", "Shougang Zhang", "Ruifang Dong"], "title": "Passive Synchronization of Nonlocal Franson Interferometry for Fiber-Based Quantum Networks Using Co-propagating Classical Clock Signals", "comment": null, "summary": "We demonstrate a robust, high-visibility nonlocal Franson interferometry for fiber-based quantum networks by co-propagating a classical Radio-over-Fiber clock signal with energy-time entangled photon pairs in the same fiber. Utilizing cross-band allocation (O-band for classical, L-band for quantum signals), the spontaneous Raman scattering noise photons are effectively suppressed. At the same time, their environmental delay fluctuations remain highly correlated for common-mode noise cancellation, achieving a passive synchronization with picoseconds precision. Over 50 km of single-mode fiber, this co-propagation enables nonlocal quantum interference with a visibility of (88.35\\pm3.62)%, without relying on external dedicated timing infrastructure. This work provides a practical, scalable synchronization solution for metropolitan-scale entanglement-based quantum networks."}
{"id": "2602.21768", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21768", "abs": "https://arxiv.org/abs/2602.21768", "authors": ["Omayra Yago Nieto", "Leonardo Colombo"], "title": "Learning-Based Geometric Leader-Follower Control for Cooperative Rigid-Payload Transport with Aerial Manipulators", "comment": null, "summary": "This paper presents a learning-based tracking control framework for cooperative transport of a rigid payload by multiple aerial manipulators under rigid grasp constraints. A unified geometric model is developed, yielding a coupled agent--payload differential--algebraic system that explicitly captures contact wrenches, payload dynamics, and internal force redundancy. A leader--follower architecture is adopted in which a designated leader generates a desired payload wrench based on geometric tracking errors, while the remaining agents realize this wrench through constraint-consistent force allocation.\n  Unknown disturbances and modeling uncertainties are compensated using Gaussian Process (GP) regression. High-probability bounds on the learning error are explicitly incorporated into the control design, combining GP feedforward compensation with geometric feedback. Lyapunov analysis establishes uniform ultimate boundedness of the payload tracking errors with high probability, with an ultimate bound that scales with the GP predictive uncertainty."}
{"id": "2602.21352", "categories": ["math.OC", "math.AP", "math.NA"], "pdf": "https://arxiv.org/pdf/2602.21352", "abs": "https://arxiv.org/abs/2602.21352", "authors": ["Chiu-Yen Kao", "Seyyed Abbas Mohammadi", "Braxton Osting"], "title": "An accelerated rearrangement method for two-phase composite optimization", "comment": "21 pages, 7 figures", "summary": "We propose and analyze an Accelerated Rearrangement Method (ARM) for solving a class of nonconvex optimization problems involving two-phase composites. These problems include maximizing the (work) energy of a membrane governed by the Poisson equation and minimizing the principal eigenvalue of a weighted Dirichlet-Laplacian, both subject to material distribution constraints. Building on the classical rearrangement method, we introduce momentum-like acceleration by extrapolating the Fréchet derivative, leading to a provably convergent algorithm. We also introduce a restarted variant that guarantees monotonic improvement of the objective. In one dimension, we derive asymptotic convergence rates for ARM and prove that they improve upon the classical rearrangement method. Numerical experiments in both two and three dimensions confirm the accelerated convergence and demonstrate practical efficiency."}
{"id": "2602.21936", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21936", "abs": "https://arxiv.org/abs/2602.21936", "authors": ["Leonardo Colombo", "Thomas Beckers", "Juan Giribet"], "title": "Aggressiveness-Aware Learning-based Control of Quadrotor UAVs with Safety Guarantees", "comment": null, "summary": "This paper presents an aggressiveness-aware control framework for quadrotor UAVs that integrates learning-based oracles to mitigate the effects of unknown disturbances. Starting from a nominal tracking controller on $\\mathrm{SE}(3)$, unmodeled generalized forces and moments are estimated using a learning-based oracle and compensated in the control inputs. An aggressiveness-aware gain scheduling mechanism adapts the feedback gains based on probabilistic model-error bounds, enabling reduced feedback-induced aggressiveness while guaranteeing a prescribed practical exponential tracking performance. The proposed approach makes explicit the trade-off between model accuracy, robustness, and control aggressiveness, and provides a principled way to exploit learning for safer and less aggressive quadrotor maneuvers."}
{"id": "2602.22062", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2602.22062", "abs": "https://arxiv.org/abs/2602.22062", "authors": ["Jiawei Li", "Nguyen Nguyen", "Meng Lai", "Ioannis Ch. Paschalidis", "Jonathan H. Huggins"], "title": "Robust Model Selection for Discovery of Latent Mechanistic Processes", "comment": null, "summary": "When learning interpretable latent structures using model-based approaches, even small deviations from modeling assumptions can lead to inferential results that are not mechanistically meaningful. In this work, we consider latent structures that consist of $K_o$ mechanistic processes, where $K_o$ is unknown. When the model is misspecified, likelihood-based model selection methods can substantially overestimate $K_o$ while more robust nonparametric methods can be overly conservative. Hence, there is a need for approaches that combine the sensitivity of likelihood-based methods with the robustness of nonparametric ones. We formalize this objective in terms of a robust model selection consistency property, which is based on a component-level discrepancy measure that captures the mechanistic structure of the model. We then propose the accumulated cutoff discrepancy criterion (ACDC), which leverages plug-in estimates of component-level discrepancies. To apply ACDC, we develop mechanistically meaningful component-level discrepancies for a general class of latent variable models that includes unsupervised and supervised variants of probabilistic matrix factorization and mixture modeling. We show that ACDC is robustly consistent when applied to unsupervised matrix factorization and mixture models. Numerical results demonstrate that in practice our approach reliably identifies a mechanistically meaningful number of latent processes in numerous illustrative applications, outperforming existing methods."}
{"id": "2602.21936", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21936", "abs": "https://arxiv.org/abs/2602.21936", "authors": ["Leonardo Colombo", "Thomas Beckers", "Juan Giribet"], "title": "Aggressiveness-Aware Learning-based Control of Quadrotor UAVs with Safety Guarantees", "comment": null, "summary": "This paper presents an aggressiveness-aware control framework for quadrotor UAVs that integrates learning-based oracles to mitigate the effects of unknown disturbances. Starting from a nominal tracking controller on $\\mathrm{SE}(3)$, unmodeled generalized forces and moments are estimated using a learning-based oracle and compensated in the control inputs. An aggressiveness-aware gain scheduling mechanism adapts the feedback gains based on probabilistic model-error bounds, enabling reduced feedback-induced aggressiveness while guaranteeing a prescribed practical exponential tracking performance. The proposed approach makes explicit the trade-off between model accuracy, robustness, and control aggressiveness, and provides a principled way to exploit learning for safer and less aggressive quadrotor maneuvers."}
{"id": "2602.21293", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.21293", "abs": "https://arxiv.org/abs/2602.21293", "authors": ["Yiren Zou", "Hong-Kuan Xia", "Aosai Zhang", "Xuhao Zhu", "Feitong Jin", "Qingyuan Wang", "Yu Gao", "Chuanyu Zhang", "Ning Wang", "Zhengyi Cui", "Fanhao Shen", "Zehang Bao", "Zitian Zhu", "Jiarun Zhong", "Gongyu Liu", "Jia-Nan Yang", "Yihang Han", "Yiyang He", "Jiayuan Shen", "Han Wang", "Yanzhe Wang", "Jiahua Huang", "Xinrong Zhang", "Sailang Zhou", "Hang Dong", "Jinfeng Deng", "Yaozu Wu", "Zixuan Song", "Hekang Li", "Zhen Wang", "Chao Song", "Qiujiang Guo", "Pengfei Zhang", "Guo-Yi Zhu", "H. Wang"], "title": "Teleportation transition of surface codes on a superconducting quantum processor", "comment": null, "summary": "The topological surface code is a leading candidate for harnessing long-range entanglement to protect logical quantum information against errors, and teleportation of logical states is desirable for robust quantum information processing. Nevertheless, scaling up the surface code in quantum teleportation poses a formidable challenge to experiment. Here on a superconducting quantum processor with 125 qubits, we demonstrate the robust teleportation of topological rotated surface code prepared by a linear-depth unitary circuit, with code distances up to 7. We obtain the teleportation phase diagram by tuning the local entangling gates uniformly across a finite threshold. Furthermore, we show that the entangling threshold can be boosted by coherent qubit rotations that inject magic resources beyond the Clifford regime, restoring the duality symmetry of the topological phase, which serves as a guiding principle to minimize the entanglement resource. Our results shed light on simulating and leveraging topological quantum matter on quantum devices, and pave the way to the ultimate goal of distributed fault tolerant quantum computation."}
{"id": "2602.21510", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21510", "abs": "https://arxiv.org/abs/2602.21510", "authors": ["Hyukgun Kwon", "Seok Hyung Lie", "Liang Jiang"], "title": "Universal Sample Complexity Bounds in Quantum Learning Theory via Fisher Information matrix", "comment": "32 pages, 2 figures", "summary": "In this work, we show that the sample complexity (equivalently, the number of measurements) required in quantum learning theory within a general parametric framework, is fundamentally governed by the inverse Fisher information matrix. More specifically, we derive upper and lower bounds on the number of samples required to estimate the parameters of a quantum system within a prescribed small additive error and with high success probability under maximum likelihood estimation. The upper bound is governed by the supremum of the largest diagonal entry of the inverse Fisher information matrix, while the lower bound is characterized by any diagonal element evaluated at arbitrary parameter values. We then apply the general bounds to Pauli channel learning and to the estimation of Pauli expectation values in the asymptotic small-error regime, and recover the previously established sample complexity through considerably streamlined derivations. Furthermore, we identify the structural origin of exponential sample complexity in Pauli channel learning without entanglement and in Pauli expectation value estimation without quantum memory. We then extend the analysis to an error criterion based on the Euclidean distance between the true parameter values and their estimators. We derive the corresponding upper and lower bounds on the sample complexity, which are likewise characterized by the inverse Fisher information matrix. As an application, we consider Pauli expectation estimation with entangled probes. Finally, we highlight two fundamental contributions to quantum learning theory. First, we establish a systematic framework that determines the task-independent sample complexity under maximum-likelihood estimation. Second, we show that, in the small-error regime, learning sample complexity is governed by the inverse Fisher information matrix."}
{"id": "2602.21916", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21916", "abs": "https://arxiv.org/abs/2602.21916", "authors": ["Yunying Ke", "Hao Luo"], "title": "Robust Kaczmarz methods for nearly singular linear systems", "comment": null, "summary": "The Kaczmarz method is an efficient iterative algorithm for large-scale linear systems. However, its linear convergence rate suffers from ill-conditioned problems and is highly sensitive to the smallest nonzero singular value. In this work, we aim to extend the classical Kaczmarz to nearly singular linear systems that are row rank-deficient. We introduce a new concept of nearly singular property by treating the row space as an unstable subspace in the Grassman manifold. We then define a related important space called the approximate kernel, based on which a robust kernel-augmented Kaczmarz (KaK) is introduced via the subspace correction framework and analyzed by the well-known Xu--Zikatanov identity. To get an implementable version, we further introduce the approximate dual kernel and transform KaK into an equivalent kernel-augmented coordinate descent. Furthermore, we develop an accelerated variant and establish the improved rate of convergence matching the optimal complexity of first-order methods. Compared with existing methods, ours achieve uniform convergence rates for nearly singular linear systems, and the robustness has been confirmed by some numerical tests."}
{"id": "2602.22133", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.22133", "abs": "https://arxiv.org/abs/2602.22133", "authors": ["Mahsa Ebadat-Parast", "Xiaozhe Wang"], "title": "Tempered Christoffel-Weighted Polynomial Chaos Expansion for Resilience-Oriented Uncertainty Quantification", "comment": "Accepted to 2026 IEEE Power & Energy Society General Meeting", "summary": "Accurate and efficient uncertainty quantification is essential for resilience assessment of modern power systems under high impact and low probability disturbances. Data driven sparse polynomial chaos expansion (DDSPCE) provides a computationally efficient surrogate framework but may suffer from ill conditioned regression and loss of accuracy in the distribution tails that determine system risk. This paper studies the impact of regression weighting schemes on the stability and tail accuracy of DD-SPCE surrogates by introducing a tempered Christoffel weighted least squares (T-CWLS) formulation that balances numerical stability and tail fidelity. The tempering exponent is treated as a hyperparameter whose influence is examined with respect to distributional accuracy compared with Monte Carlo simulations. Case studies on distribution system load shedding show that the proposed method reduces 95th percentile deviation by 16%, 5th percentile deviation by 6%, and improves the regression stability index by over 130%. The results demonstrate that controlling the weighting intensity directly influences both stability index and the accuracy of tail prediction."}
{"id": "2602.22083", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.22083", "abs": "https://arxiv.org/abs/2602.22083", "authors": ["Xiaxian Ou", "Razieh Nabi"], "title": "Coarsening Bias from Variable Discretization in Causal Functionals", "comment": null, "summary": "A class of causal effect functionals requires integration over conditional densities of continuous variables, as in mediation effects and nonparametric identification in causal graphical models. Estimating such densities and evaluating the resulting integrals can be statistically and computationally demanding. A common workaround is to discretize the variable and replace integrals with finite sums. Although convenient, discretization alters the population-level functional and can induce non-negligible approximation bias, even under correct identification. Under smoothness conditions, we show that this coarsening bias is first order in the bin width and arises at the level of the target functional, distinct from statistical estimation error. We propose a simple bias-reduced functional that evaluates the outcome regression at within-bin conditional means, eliminating the leading term and yielding a second-order approximation error. We derive plug-in and one-step estimators for the bias-reduced functional. Simulations demonstrate substantial bias reduction and near-nominal confidence interval coverage, even under coarse binning. Our results provide a simple framework for controlling the impact of variable discretization on parameter approximation and estimation."}
{"id": "2602.22133", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.22133", "abs": "https://arxiv.org/abs/2602.22133", "authors": ["Mahsa Ebadat-Parast", "Xiaozhe Wang"], "title": "Tempered Christoffel-Weighted Polynomial Chaos Expansion for Resilience-Oriented Uncertainty Quantification", "comment": "Accepted to 2026 IEEE Power & Energy Society General Meeting", "summary": "Accurate and efficient uncertainty quantification is essential for resilience assessment of modern power systems under high impact and low probability disturbances. Data driven sparse polynomial chaos expansion (DDSPCE) provides a computationally efficient surrogate framework but may suffer from ill conditioned regression and loss of accuracy in the distribution tails that determine system risk. This paper studies the impact of regression weighting schemes on the stability and tail accuracy of DD-SPCE surrogates by introducing a tempered Christoffel weighted least squares (T-CWLS) formulation that balances numerical stability and tail fidelity. The tempering exponent is treated as a hyperparameter whose influence is examined with respect to distributional accuracy compared with Monte Carlo simulations. Case studies on distribution system load shedding show that the proposed method reduces 95th percentile deviation by 16%, 5th percentile deviation by 6%, and improves the regression stability index by over 130%. The results demonstrate that controlling the weighting intensity directly influences both stability index and the accuracy of tail prediction."}
{"id": "2602.21705", "categories": ["hep-lat", "cond-mat.str-el", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.21705", "abs": "https://arxiv.org/abs/2602.21705", "authors": ["Jian-Gang Kong", "Shinichiro Akiyama", "Tao Shi", "Z. Y. Xie"], "title": "Phase diagram of the single-flavor Gross--Neveu--Wilson model from the Grassmann corner transfer matrix renormalization group", "comment": null, "summary": "We investigate the phase structure of the single-flavor Gross--Neveu model with Wilson fermions using the Grassmann corner transfer matrix renormalization group (CTMRG). The path integral is formulated as a two-dimensional Grassmann tensor network and approximately contracted by the Grassmann CTMRG algorithm. We investigate the phase diagram by varying the fermion mass and the four-fermion coupling, using the pseudoscalar condensate as an order parameter for the $\\mathbb{Z}_{2}$ parity symmetry breaking phase. The universality classes of the phase boundaries are identified through the central charge $c$ obtained via scaling analysis of the entanglement entropy. Furthermore, we extract the quantity related to the entanglement spectrum from the converged CTMRG environments, allowing us to distinguish the topological insulator phase and the trivial phase. The resulting phase structure suggests that the Aoki phase is separated from the other phases by critical lines characterized by $c=1/2$, while the critical lines with $c=1$ separate the topological insulating and trivial phases. Our numerical results also indicate that the Aoki phase does not persist in the strong-coupling regime for the single-flavor theory."}
{"id": "2602.21512", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21512", "abs": "https://arxiv.org/abs/2602.21512", "authors": ["Rui Li", "Min-Hua Zhang", "Jing Qian"], "title": "Optimized ancillary drive for fast Rydberg entangling gates", "comment": "PRA in press", "summary": "Reaching fast and robust two-qubit gates with low infidelities has been an outstanding challenge for the long-term goal of useful quantum computers. Typically, optimizing the pulse shapes can minimize the gate infidelity and improve its robustness to certain types of errors; yet it remains incapable of speeding up the gate execution time which is fundamentally restricted by the attainable Rabi frequency in a realistic setup. In this work, we develop a fast implementation of two-qubit CZ gates using optimized ancillary drive to enhance the two-photon Rabi frequency between the ground and Rydberg states.This ancillary drive can work in an error-robustness framework without increasing the original gate infidelity in the absence of the drive. Considering the experimentally feasible parameters for $^{87}$Rb atoms, we demonstrate that the execution time required for such CZ gates can be shortened by more than 30$\\%$ as compared to standard two-photon protocols arising the gate fidelity above 0.9954 by taking account of all relevant error sources. Our results reduce the high-power laser requirement and unlock the potential toward fast, high-fidelity quantum operations for large-scale quantum computation with neutral atoms."}
{"id": "2602.21936", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2602.21936", "abs": "https://arxiv.org/abs/2602.21936", "authors": ["Leonardo Colombo", "Thomas Beckers", "Juan Giribet"], "title": "Aggressiveness-Aware Learning-based Control of Quadrotor UAVs with Safety Guarantees", "comment": null, "summary": "This paper presents an aggressiveness-aware control framework for quadrotor UAVs that integrates learning-based oracles to mitigate the effects of unknown disturbances. Starting from a nominal tracking controller on $\\mathrm{SE}(3)$, unmodeled generalized forces and moments are estimated using a learning-based oracle and compensated in the control inputs. An aggressiveness-aware gain scheduling mechanism adapts the feedback gains based on probabilistic model-error bounds, enabling reduced feedback-induced aggressiveness while guaranteeing a prescribed practical exponential tracking performance. The proposed approach makes explicit the trade-off between model accuracy, robustness, and control aggressiveness, and provides a principled way to exploit learning for safer and less aggressive quadrotor maneuvers."}
{"id": "2602.22203", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.22203", "abs": "https://arxiv.org/abs/2602.22203", "authors": ["Nils Lid Hjort"], "title": "Local Bayesian Regression", "comment": "28 pages; statistical Research Report, Department of Mathematics, University of Oslo, August 1994, but arXiv'd in February 2026. A journal paper can be written up based on this report, requiring though numerical studies and good illustrations", "summary": "This paper develops a class of Bayesian non- and semiparametric methods for estimating regression curves and surfaces. The main idea is to model the regression as locally linear, and then place suitable local priors on the local parameters. The method requires the posterior distribution of the local parameters given local data, and this is found via a suitably defined local likelihood function. When the width of the local data window is large the methods reduce to familiar fully parametric Bayesian methods, and when the width is small the estimators are essentially nonparametric. When noninformative reference priors are used the resulting estimators coincide with recently developed well-performing local weighted least squares methods for nonparametric regression.\n  Each local prior distribution needs in general a centre parameter and a variance parameter. Of particular interest are versions of the scheme that are more or less automatic and objective in the sense that they do not require subjective specifications of prior parameters. We therefore develop empirical Bayes methods to obtain the variance parameter and a hierarchical Bayes method to account for uncertainty in the choice of centre parameter. There are several possible versions of the general programme, and a number of its specialisations are discussed. Some of these are shown to be capable of outperforming standard nonparametric regression methods, particularly in situations with several covariates."}
{"id": "2602.21979", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.21979", "abs": "https://arxiv.org/abs/2602.21979", "authors": ["Yuchen Guo", "Shuo Yang"], "title": "Quantum criticality in open quantum systems from the purification perspective", "comment": "24 pages, 10 figures", "summary": "Open quantum systems host mixed-state phases that go beyond the symmetry-protected topological and spontaneous symmetry-breaking paradigms established for closed, pure-state systems. Developing a unified and physically transparent classification of such phases remains a central challenge. In this work, we introduce a purification-based framework that systematically characterizes all mixed-state phases in one-dimensional systems with $\\mathbb{Z}_2^σ \\times \\mathbb{Z}_2^τ$ symmetry. By introducing an ancillary $κ$ chain and employing decorated domain-wall constructions, we derive eight purified fixed-point Hamiltonians labeled by topological indices $(μ_{στ},μ_{τκ},μ_{κσ}) \\in \\{\\pm1\\}^3$. Tracing out the ancilla recovers the full structure of mixed-state phases, including symmetric, strong-to-weak spontaneous symmetry breaking, average symmetry-protected topological phases, and their nontrivial combinations. Interpolations between the eight fixed points naturally define a three-dimensional phase diagram with a cube geometry. The edges correspond to elementary transitions associated with single topological indices, while the faces host intermediate phases arising from competing domain-wall decorations. Along the edges, we identify a class of critical behavior that connects distinct strong-to-weak symmetry-breaking patterns associated with distinct strong subgroups, highlighting a mechanism unique to mixed-state settings. Large-scale tensor-network simulations reveal a rich phase structure, including pyramid-shaped symmetry-breaking regions and a fully symmetry-broken phase at the cube center. Overall, our purification approach provides a geometrically transparent and physically complete classification of mixed-state phases, unified with a single $\\mathbb{Z}_2^σ \\times \\mathbb{Z}_2^τ \\times \\mathbb{Z}_2^κ$ model."}
{"id": "2602.21518", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21518", "abs": "https://arxiv.org/abs/2602.21518", "authors": ["Agya Sewara Alam", "Anupam Mazumdar"], "title": "Momentum Diffusion, Decoherence and Drag Force on a Magnetic Nanoparticle", "comment": "28 pages, includes appendices, no figures", "summary": "In this paper, we will provide a complete derivation of the decoherence rate for a magnetic nanoparticle in quantum superposition in the presence of the fluctuating electromagnetic field in a thermal background by using the fluctuation-dissipation theorem in the long-wavelength limit. The long-wavelength limit assumes that the superposition size is much smaller than the wavelength of the electromagentic filed fluctuations. We will extend this computation to two diamagnetic nanoparticles kept in quantum superposition adjacent to each other. We will also show how the drag force on a single nanoparticle arises from external electromagnetic-field fluctuations, and compare our results with those for the nanoparticle's dielectric properties."}
{"id": "2602.21359", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21359", "abs": "https://arxiv.org/abs/2602.21359", "authors": ["Swarnadeep Datta", "Monitirtha Dey"], "title": "Some Asymptotic Results on Multiple Testing under Weak Dependence", "comment": null, "summary": "This paper studies the means-testing problem under weakly correlated Normal setups. Although quite common in genomic applications, test procedures having exact FWER control under such dependence structures are nonexistent. We explore the asymptotic behaviors of the classical Bonferroni (when adjusted suitably) and the Sidak procedure; and show that both of these control FWER at the desired level exactly as the number of hypotheses approaches infinity. We derive analogous limiting results on the generalized family-wise error rate and power. Simulation studies depict the asymptotic exactness of the procedures empirically."}
{"id": "2602.21544", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21544", "abs": "https://arxiv.org/abs/2602.21544", "authors": ["Mio Kawanabe", "Saud Cindrak", "Kathy Luedge", "Jun-ichi Shirakashi", "Tetsuo Shibuya", "Hiroshi Imai"], "title": "Efficient time-series prediction on NISQ devices via time-delayed quantum extreme learning machine", "comment": "8 pages, 4 figures. Corresponding author: Jun-ichi Shirakashi", "summary": "We proposed a time-delayed quantum extreme learning machine (TD-QELM) for efficient time-series prediction on noisy intermediate-scale quantum (NISQ) devices. By encoding multiple past inputs simultaneously, TD-QELM achieves shallow circuit depth independent of sequence length, thereby, mitigating noise accumulation and reducing computational complexity. Experiments using the NARMA benchmark on both noiseless simulations and IBM's 127-qubit processor demonstrate that TD-QELM consistently outperforms conventional quantum reservoir computing in prediction accuracy and noise robustness. These results highlight TD-QELM as a practical and scalable framework for time-series learning on current NISQ hardware."}
{"id": "2602.21376", "categories": ["math.OC", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21376", "abs": "https://arxiv.org/abs/2602.21376", "authors": ["Xi Lin", "Yafeng Yin", "Tianming Liu"], "title": "Fenchel-Young Estimators of Perturbed Utility Models", "comment": "48 pages, 11 figures", "summary": "The Perturbed Utility Model framework offers a powerful generalization of discrete choice analysis, unifying models like Multinomial Logit and Sparsemax through convex optimization. However, standard Maximum Likelihood Estimation (MLE) faces severe theoretical and numerical challenges when applied to this broader class, particularly regarding non-convexity and instability in sparse regimes. To resolve these issues, this paper introduces a unified estimation framework based on the Fenchel-Young loss. By leveraging the intrinsic convex conjugate structure of PUMs, we demonstrate that the Fenchel-Young estimator guarantees global convexity and bounded gradients, providing a mathematically natural alternative to MLE. Addressing the critical challenge of data scarcity, we further extend this framework via Wasserstein Distributionally Robust Optimization. We first derive an exact finite-dimensional reformulation of the infinite-dimensional primal problem, establishing its theoretical convexity. However, recognizing that the resulting worst-case constraints involve computationally intractable inner maximizations, we subsequently construct a tractable safe approximation by exploiting the global Lipschitz continuity of the Fenchel-Young loss. Through this tractable formulation, we uncover a rigorous geometric unification: two canonical regularization techniques, standard L2-regularization and the margin-enforcing Hinge loss, emerge mathematically as specific limiting cases of our distributionally robust estimator. Extensive experiments on synthetic data and the Swissmetro benchmark validate that the proposed framework significantly outperforms traditional methods, recovering stable preferences even under severe data limitations."}
{"id": "2602.21549", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21549", "abs": "https://arxiv.org/abs/2602.21549", "authors": ["Evelyn Voss", "Bikun Li", "Zhaoyou Wang", "Liang Jiang"], "title": "Passive Environment-Assisted Quantum Communication", "comment": "17 pages, 11 figures", "summary": "As quantum information systems mature, efficient and coherent transfer of quantum information through noisy channels becomes increasingly important. We examine how passive environment-assisted quantum communication enhances direct quantum information transfer efficiency. A bosonic pure-loss channel, modeled as transmission through a beam splitter with a vacuum input state at the dark port, has zero quantum capacity when transmissivity is below 50%. Quantum communication through the channel can be enhanced by passive environment assistance, achieved via the selection of an appropriate input state for the ancilla port. Although ideal Gottesman-Kitaev-Preskill (GKP) states enable perfect quantum information transmission at arbitrarily small transmissivity, they are challenging to realize experimentally. We therefore explore more experimentally accessible non-Gaussian ancilla states, such as Fock, cat, and squeezed cat states, and numerically determine the optimal encoding and decoding strategies. We also construct analytical schemes that yield high-fidelity transmission and good information rates."}
{"id": "2602.21423", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.21423", "abs": "https://arxiv.org/abs/2602.21423", "authors": ["Patrick Kramer", "Edward H. Kennedy", "Isaac M. Opper"], "title": "Causal Inference with High-Dimensional Treatments", "comment": null, "summary": "In this work, we consider causal inference in various high-dimensional treatment settings, including for single multi-valued treatments and vector treatments with binary or continuous components, when the number of treatments can be comparable to or even larger than the number of observations. These settings bring unique challenges: first, the treatment effects of interest are a high-dimensional vector rather than a low-dimensional scalar; second, positivity violations are often unavoidable; and third, estimation can be based on a smaller effective sample size. We first discuss fundamental limits of estimating effects here, showing that consistent estimation is impossible without further assumptions. We go on to propose a novel sparse pseudo-outcome regression framework for arbitrary high-dimensional statistical functionals, which includes generic constrained regression estimators and error guarantees. We use the framework to derive new doubly robust estimators for mean potential outcomes of high-dimensional treatments, though it can also be applied to other scenarios. We analyze the proposed estimators under exact and approximate sparsity assumptions, giving finite-sample risk bounds. Finally, we derive minimax lower bounds to characterize optimal rates of convergence and show our risk bounds are unimprovable."}
{"id": "2602.21562", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21562", "abs": "https://arxiv.org/abs/2602.21562", "authors": ["Shintaro Yamamura", "Satoshi Watanabe", "Masaya Kunimi", "Kazuhiro Saito", "Tetsuro Nikuni"], "title": "Performance Comparison of QAOA Mixers for Ternary Portfolio Optimization", "comment": null, "summary": "The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm proposed for Noisy Intermediate-Scale Quantum (NISQ) devices and is regarded as a promising approach to combinatorial optimization problems, with potential applications in the financial sector. In this study, we apply QAOA to the portfolio optimization problem, which is one of the central challenges in financial engineering. A portfolio consists of a combination of multiple assets, and the portfolio optimization problem aims to determine the optimal asset allocation by balancing expected return and risk. In the context of quantum optimization, portfolio optimization is often formulated using discrete variables. Unlike conventional binary formulations, we consider a ternary portfolio optimization problem that accounts for three states-holding, not holding, and short selling-and compare its performance using different mixer operators. Specifically, we implement QAOA with the standard mixer and several XY Mixers (XY Ring, XY Parity Ring, XY Full, and QAMPA), and conducted simulations using real data based on the German stock index (DAX 30) for portfolios consisting of 5 and 8 assets. Furthermore, we introduce noise based on a depolarizing channel to investigate the behavior of the algorithm in realistic environments. The results show that while XY Mixers exhibit superiority in noiseless settings, their advantage degrades in noisy environments, and the optimal choice of mixer depends on both the number of QAOA depths and the noise strength."}
{"id": "2602.21569", "categories": ["math.ST", "cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.21569", "abs": "https://arxiv.org/abs/2602.21569", "authors": ["Huan Qing"], "title": "How many asymmetric communities are there in multi-layer directed networks?", "comment": "44 pages, 4 tables, 2 figures", "summary": "Estimating the asymmetric numbers of communities in multi-layer directed networks is a challenging problem due to the multi-layer structures and inherent directional asymmetry, leading to possibly different numbers of sender and receiver communities. This work addresses this issue under the multi-layer stochastic co-block model, a model for multi-layer directed networks with distinct community structures in sending and receiving sides, by proposing a novel goodness-of-fit test. The test statistic relies on the deviation of the largest singular value of an aggregated normalized residual matrix from the constant 2. The test statistic exhibits a sharp dichotomy: Under the null hypothesis of correct model specification, its upper bound converges to zero with high probability; under underfitting, the test statistic itself diverges to infinity. With this property, we develop a sequential testing procedure that searches through candidate pairs of sender and receiver community numbers in a lexicographic order. The process stops at the smallest such pair where the test statistic drops below a decaying threshold. For robustness, we also propose a ratio-based variant algorithm, which detects sharp changes in the sequence of test statistics by comparing consecutive candidates. Both methods are proven to consistently determine the true numbers of sender and receiver communities under the multi-layer stochastic co-block model."}
{"id": "2602.21563", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21563", "abs": "https://arxiv.org/abs/2602.21563", "authors": ["Sewon Jeong", "Shrobona Bagchi", "Jaehak Lee", "Hyang-Tag Lim", "Yong-Su Kim", "Taeyoung Choi", "Seung-Woo Lee"], "title": "Entanglement recovery by reversing the effect of noise in quantum repeater", "comment": "13 pages, 6 figures", "summary": "We propose a method to directly recover the degree of entanglement distributed by entanglement swapping in the presence of noise. Our approach introduces a reversing operation that probabilistically undoes the effect of amplitude damping or photon loss on a single entangled pair, enabling heralded recovery of entanglement. We demonstrate that entanglement can be substantially recovered even under strong noise, including parameter regimes where the distributed entanglement would otherwise vanish due to entanglement sudden death. We analyze the effectiveness of the protocol in two representative repeater models, i.e.,~two-way and one-way architectures and identify the optimal reversing strategy. Due to its heralded and single-copy nature, our protocol is readily compatible with other entanglement recovery techniques such as entanglement purification and distillation. Our work provides a practical and experimentally feasible way toward robust entanglement distribution in current and near-term quantum repeater architectures."}
{"id": "2602.21629", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.21629", "abs": "https://arxiv.org/abs/2602.21629", "authors": ["Kan Takase", "Mamoru Endo", "Fumiya Hanamura", "Kazuki Hirota", "Masahiro Yabuno", "Hirotaka Terai", "Shigehito Miki", "Takahiro Kashiwazaki", "Asuka Inoue", "Takeshi Umeki", "Petr Marek", "Radim Filip", "Warit Asavanant", "Akira Furusawa"], "title": "Tuning Wave-Particle Duality of Quantum Light by Generalized Photon Subtraction", "comment": "6 pages, 3 figures", "summary": "Wave--particle duality is a hallmark of quantum mechanics. For bosonic systems, there exists a continuum of intermediate states bridging wave-like Schrödinger cat states and particle-like Fock states. Such states have recently been recognized as valuable resources for enhancing fault-tolerant quantum computation (FTQC) with propagating light. Here we experimentally demonstrate tunable generation of these intermediate states by employing generalized photon subtraction (GPS). By detecting up to three photons from squeezed-light sources with a photon-number-resolving detector, we continuously control the balance between wave- and particle-like features. This approach allows us to construct a spectral family of quantum states with high generation rates, optimized according to the required fault-tolerance threshold. Our results establish GPS as a versatile toolbox for tailoring non-Gaussian resources, opening a pathway to efficient Gottesman--Kitaev--Preskill (GKP) qubit generation and addressing a central bottleneck in optical quantum computing."}
{"id": "2602.21671", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21671", "abs": "https://arxiv.org/abs/2602.21671", "authors": ["Lucas Alves Zischler", "Amirhossein Ghazisaeidi", "Antonio Mecozzi", "Cristian Antonelli"], "title": "Secret Key Rate Limits in Coexisting Classical-Quantum Optical Links", "comment": "Submitted for the Journal of Lightwave and Technology", "summary": "Classical-quantum coexistence enables cost-effective transmission of data and quantum signals over the same fiber-optic channel. Nevertheless, weak quantum-key distribution (QKD) signals are susceptible to non-linear interference generated from the classical traffic, primarily spontaneous Raman scattering (SpRS) and four-wave-mixing (FWM), as well as to unfiltered noise. In QKD protocols, increased channel loss and excess noise both reduce the secret key rates (SKRs), as illustrated in this work for the two-state BB84 and Gaussian-modulated coherent-states (GMCS) protocols. In this study, we derive closed-form expressions for evaluating the accumulated interference power from coexisting classical signals in a quantum frequency channel. Our model enables effective design of classical-quantum systems in single-mode fibers (SMFs), capturing the evolution of interference arising from the relevant physical phenomena. We utilize the model to examine frequency allocation in multiband transmission systems, demonstrating that, contrary to common practice of allocating QKD channels in the O-band, increased SKR is achieved by placing quantum channels in the upper E-/lower S-band across the relevant scenarios."}
{"id": "2602.21688", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21688", "abs": "https://arxiv.org/abs/2602.21688", "authors": ["Elena Callus", "Martin Gärttner", "Tobias Haas"], "title": "Revealing entanglement through local features of phase-space distributions", "comment": "14 pages, 8 figures. Feedback and comments are welcome!", "summary": "We formulate an infinite hierarchy of continuous-variable separability criteria in terms of quasiprobability distributions and their derivatives evaluated at individual points in phase space. Our approach is equivalent to the Peres--Horodecki criterion and sheds light on how distillable entanglement manifests in the phase-space picture. We demonstrate that already the lowest-order variant constitutes a powerful method for detecting the elusive non-Gaussian entanglement of relevant state families. Further, we devise a simple measurement scheme that relies solely on passive linear transformations and coherent ancillas. By strategically probing specific phase-space regions, our method offers clear advantages over existing techniques that rely on access to the full phase-space distributions."}
{"id": "2602.21689", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21689", "abs": "https://arxiv.org/abs/2602.21689", "authors": ["Sokea Sang", "Leanghok Hour", "Sanghyeon Lee", "Aniket Patra", "Hee Chul Park", "Moon Jip Park", "Youngsun Han"], "title": "Landscape-Similarity-Guided Optimization in QAOA", "comment": null, "summary": "Across diverse synthetic and real-world interaction graphs, the variational landscapes of reduced Quantum Approximate Optimization Algorithm (QAOA) instances obtained via variable freezing exhibit a robust universality. Leveraging this structure, we introduce Doubly Optimized QAOA (DO-QAOA), which lowers runtime and quantum measurement overhead while maintaining a competitive approximation ratio gap (ARG). Adapting the replica-overlap framework of spin-glass physics, we define a landscape-overlap order parameter $q$ to quantify geometric correlations between energy landscapes, revealing a sharp landscape-similarity transition as graph connectivity is tuned. Notwithstanding this transition, the dominant convex features of nearly all conditioned sub-instances remain aligned across both phases. Exploiting this persistence, DO-QAOA collapses the nominal $2^m$ reduced instances generated by freezing $m$ qubits into $K = O(1)$ effective landscape classes, eliminating the exponential proliferation in $m$. By leveraging landscape structure, DO-QAOA provides a scalable route to hybrid quantum-classical optimization under realistic hardware constraints, with potential applicability across variational quantum algorithms."}
{"id": "2602.21808", "categories": ["quant-ph", "math-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2602.21808", "abs": "https://arxiv.org/abs/2602.21808", "authors": ["Wesley Lewis", "Darsh Pareek", "Umesh Kumar", "Ravi Janjam"], "title": "Imperfect Graphs from Unitary Matrices -- I", "comment": null, "summary": "Matrix representations of quantum operators are computationally complete but often obscure the structural topology of information flow within a quantum circuit \\cite{nielsen2000}. In this paper, we introduce a generalized graph-theoretic framework for analyzing quantum operators by mapping unitary matrices to directed graphs; we term these structures \\emph{Imperfect Graphs} or more formally as \\emph{Topological Structure of Superpositions}(TSS) as a tool to devise better Quantum Algorithms. In this framework, we represent computational basis states as vertices. A directed edge exists between two vertices if and only if there is a non-zero amplitude transition between them, effectively mapping the support of the unitary operator. In this paper we deliberately discard probability amplitudes and phase information to isolate the connectivity and reachability properties of the operator. We demonstrate how TSS intuitively helps describe gates such as the Hadamard, Pauli-(X,Y,Z) gates, etc \\cite{nielsen2000}. This framework provides a novel perspective for viewing quantum circuits as discrete dynamical systems \\cite{childs2009,aharonov2001}\n  Keywords: Quantum Algorithms, Unitary Matrix Approach, Topological Structure of Superpositions (TSS), Graph Theory"}
{"id": "2602.21839", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21839", "abs": "https://arxiv.org/abs/2602.21839", "authors": ["Xuanchen Zhang", "Yaofeng Chen", "Yong-Chun Liu"], "title": "Generating large-scale Greenberger-Horne-Zeilinger-like states in lattice spin systems", "comment": null, "summary": "Greenberger-Horne-Zeilinger (GHZ) state is a typical maximally entangled state which is pursued in both fundamental research and emerging quantum technologies. Preparing large-scale GHZ states in lattice spin systems is particularly appealing for quantum advantages, but conventional schemes face great challenges in scalability. Here we propose a universal and scalable scheme to generate large-scale GHZ-like states, which share similar entanglement and metrological properties with standard GHZ states, in lattice spin systems through global Floquet engineering. Our scheme requires only global operations and shows great advantage for large particle number. It is applicable to systems with arbitrary interaction ranges, offering a practical pathway for large-scale implementation of many-body entangled states in various systems."}
{"id": "2602.21847", "categories": ["quant-ph", "physics.app-ph", "physics.class-ph"], "pdf": "https://arxiv.org/pdf/2602.21847", "abs": "https://arxiv.org/abs/2602.21847", "authors": ["Adriano A. Batista"], "title": "Deep squeezing or cooling the fluctuations of a parametric resonator using feedback", "comment": "25 pages, 8 figures", "summary": "Here we analyze ways to achieve deep subthreshold parametric squeezing or cooling of a single degree-of-freedom parametric resonator enhanced by a lock-in amplifier feedback loop. Due to the feedback, the dynamics of the parametric resonator becomes more complex and a Hopf bifurcation at the instability threshold can occur. Initially, we calculate the phase-dependent gain of parametric amplification with feedback of an added ac signal. In one approach, we obtain the amplification gain approximately using two independent approaches: the averaging method and the harmonic balance method. We also obtain this gain more exactly using Floquet theory and Green's functions methods. The Hopf bifurcation was predicted by the harmonic balance method and by Floquet theory, but not by the averaging method. In our analysis of fluctuations, we Fourier analyze the response of the parametric resonator with feedback to an added white noise. We were able to calculate, in addition to the noise spectral density, the squeezing of fluctuations in this resonator with feedback. Very strong squeezing or cooling can occur. Deamplification and cooling occur near the Hopf bifurcation, whereas squeezing occurs near a saddle-node bifurcation."}
{"id": "2602.21879", "categories": ["quant-ph", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2602.21879", "abs": "https://arxiv.org/abs/2602.21879", "authors": ["Hiroki Kuji", "Suguru Endo", "Tetsuro Nikuni", "Ryusuke Hamazaki", "Yuichiro Matsuzaki"], "title": "Quantum Error Mitigation Simulates General Non-Hermitian Dynamics", "comment": null, "summary": "While non-Hermitian Hamiltonians enable exotic dynamical phenomena, implementing their nonunitary time evolution on near-term quantum devices remains challenging. We propose a hardware-friendly protocol that simulates non-Hermitian dynamics without continuous monitoring. Gorini-Kossakowski-Sudarshan-Lindblad (GKSL) evolution via classical Gaussian white-noise averaging and to subsequently cancel the quantum-jump contribution at the level of the measured observable using stochastic quantum error mitigation (QEM). The scheme requires no ancillas or controlled time-evolution, while the mitigation layer uses only single-qubit operations. We validate the method through numerical simulations of a model with asymmetric hopping, interaction, and disorder. Our work provides a programmable and ancilla-free framework investigating exotic dynamics that are not completely-positive and trace-preserving using QEM."}
{"id": "2602.21886", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2602.21886", "abs": "https://arxiv.org/abs/2602.21886", "authors": ["Pavel Kamenskikh", "Nikita Semenin", "Ilia Zalivako", "Vasiliy Smirnov", "Ilya Semerikov", "Ksenia Khabarova", "Nikolay Kolachevsky"], "title": "Analysis of the action of conventional trapped-ion entangling gates in qudit space", "comment": "19 pages, 9 figures", "summary": "Qudits, or multi-level quantum information carriers, present a promising path for scaling quantum computers. However, their use introduces increased complexity in quantum logic, necessitating careful control of relative phases between different qudit levels. In trapped-ion systems, entangling operations accumulate phases on specific levels that are no longer global, unlike in qubit architectures. Furthermore, the structure of multi-level gates becomes increasingly intricate with higher-dimensional Hilbert spaces. This work explores the theory of these additional entangling and non-entangling phases, accumulated in Mølmer--Sørensen and Light-shift gates. We propose methods to actively compensate for these phases, enhance gate robustness against parameter fluctuations, and simplify native gates for more efficient circuit decomposition. Our results pave the way toward the practical and scalable implementation of qudit-based quantum processors."}
{"id": "2602.21896", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21896", "abs": "https://arxiv.org/abs/2602.21896", "authors": ["Jan Neuser", "Marcelo Janovitch", "Matteo Brunelli", "Patrick P. Potts"], "title": "Prodiabatic Elimination: Higher Order Elimination of Fast Variables with Quantum Noise", "comment": null, "summary": "We introduce the prodiabatic elimination, a powerful approximation technique that systematically extends the adiabatic elimination of fast degrees of freedom in light-matter coupled systems. Through a controlled expansion of operators, the prodiabatic elimination incorporates higher-order corrections and consistently includes noise contributions, leading to a significantly improved performance compared to standard adiabatic elimination. Importantly, it retains the simplicity and computational efficiency of the adiabatic elimination, making it convenient for practical applications. We demonstrate the approach on two setups: a driven dissipative Jaynes-Cummings model and a three-level system in a two-mode cavity that performs stimulated Raman adiabatic passage (STIRAP). These examples establish the prodiabatic elimination as a robust and broadly applicable tool for analyzing open quantum systems."}
{"id": "2602.21953", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.21953", "abs": "https://arxiv.org/abs/2602.21953", "authors": ["Taehyun Kim", "Israel F. Araujo", "Daniel K. Park"], "title": "Noise-adaptive hybrid quantum convolutional neural networks based on depth-stratified feature extraction", "comment": "22 pages, 9 figures, 4 tables (including Supplementary Information)", "summary": "Hierarchical quantum classifiers, such as quantum convolutional neural networks (QCNNs), represent recent progress toward designing effective and feasible architectures for quantum classification. However, their performance on near-term quantum hardware remains highly sensitive to noise accumulation across circuit depth, calling for strategies beyond circuit-architecture design alone. We propose a noise-adaptive hybrid QCNN that improves classification under noise by exploiting depth-stratified intermediate measurements. Instead of discarding qubits removed during pooling operations, we measure them and use the resulting outcomes as classical features that are jointly processed by a classical neural network. This hybrid hierarchical design enables noise-adaptive inference by integrating quantum intermediate measurements with classical post-processing. Systematic experiments across multiple circuit sizes and noise settings, including hardware-calibrated noise models derived from IBM Quantum backend data, demonstrate more stable convergence, reduced loss variability, and consistently higher classification accuracy compared with standard QCNNs. Moreover, we observe that this performance advantage significantly amplifies as the circuit size increases, confirming that the hybrid architecture mitigates the scaling limitations of standard architectures. Notably, the multi-basis measurement variant attains performance close to the noiseless limit even under realistic noise. While demonstrated for QCNNs, the proposed depth-stratified feature extraction applies more broadly to hierarchical quantum classifiers that progressively discard qubits."}
{"id": "2602.21979", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.21979", "abs": "https://arxiv.org/abs/2602.21979", "authors": ["Yuchen Guo", "Shuo Yang"], "title": "Quantum criticality in open quantum systems from the purification perspective", "comment": "24 pages, 10 figures", "summary": "Open quantum systems host mixed-state phases that go beyond the symmetry-protected topological and spontaneous symmetry-breaking paradigms established for closed, pure-state systems. Developing a unified and physically transparent classification of such phases remains a central challenge. In this work, we introduce a purification-based framework that systematically characterizes all mixed-state phases in one-dimensional systems with $\\mathbb{Z}_2^σ \\times \\mathbb{Z}_2^τ$ symmetry. By introducing an ancillary $κ$ chain and employing decorated domain-wall constructions, we derive eight purified fixed-point Hamiltonians labeled by topological indices $(μ_{στ},μ_{τκ},μ_{κσ}) \\in \\{\\pm1\\}^3$. Tracing out the ancilla recovers the full structure of mixed-state phases, including symmetric, strong-to-weak spontaneous symmetry breaking, average symmetry-protected topological phases, and their nontrivial combinations. Interpolations between the eight fixed points naturally define a three-dimensional phase diagram with a cube geometry. The edges correspond to elementary transitions associated with single topological indices, while the faces host intermediate phases arising from competing domain-wall decorations. Along the edges, we identify a class of critical behavior that connects distinct strong-to-weak symmetry-breaking patterns associated with distinct strong subgroups, highlighting a mechanism unique to mixed-state settings. Large-scale tensor-network simulations reveal a rich phase structure, including pyramid-shaped symmetry-breaking regions and a fully symmetry-broken phase at the cube center. Overall, our purification approach provides a geometrically transparent and physically complete classification of mixed-state phases, unified with a single $\\mathbb{Z}_2^σ \\times \\mathbb{Z}_2^τ \\times \\mathbb{Z}_2^κ$ model."}
{"id": "2602.22057", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.22057", "abs": "https://arxiv.org/abs/2602.22057", "authors": ["Leonardo Zambrano"], "title": "Quantum tomography for non-iid sources", "comment": null, "summary": "Quantum state and process tomography are typically analyzed under the assumption that devices emit independent and identically distributed (i.i.d.) states or channels. In realistic experiments, however, noise, drift, feedback, or adversarial behavior violate this assumption. We show that projected least-squares tomography remains statistically optimal even under fully adaptive state and channel preparation. Specifically, we prove that the sample complexity for reconstructing the time-averaged state or channel matches the optimal i.i.d. scaling for non-adaptive, single-copy measurements. For rank-$r$ states, the sample complexity is $\\mathcal{O}(d r^2/ε^2)$ to achieve accuracy $ε$ in trace distance, while for process tomography it is $\\mathcal{O}(d^6/ε^2)$ to achieve accuracy $ε$ in diamond distance. Thus, dropping the i.i.d. assumption does not increase the fundamental sample complexity of quantum tomography, but only changes the interpretation of the reconstructed object."}
{"id": "2602.22061", "categories": ["quant-ph", "cs.LG", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.22061", "abs": "https://arxiv.org/abs/2602.22061", "authors": ["Quoc Hoan Tran", "Koki Chinzei", "Yasuhiro Endo", "Hirotaka Oshima"], "title": "Learning Quantum Data Distribution via Chaotic Quantum Diffusion Model", "comment": "12 pages, 7 figures; extended version from Poster in Workshop: Machine Learning and the Physical Sciences https://neurips.cc/virtual/2025/loc/san-diego/123072", "summary": "Generative models for quantum data pose significant challenges but hold immense potential in fields such as chemoinformatics and quantum physics. Quantum denoising diffusion probabilistic models (QuDDPMs) enable efficient learning of quantum data distributions by progressively scrambling and denoising quantum states; however, existing implementations typically rely on circuit-based random unitary dynamics that can be costly to realize and sensitive to control imperfections, particularly on analog quantum hardware. We propose the chaotic quantum diffusion model, a framework that generates projected ensembles via chaotic Hamiltonian time evolution, providing a flexible and hardware-compatible diffusion mechanism. Requiring only global, time-independent control, our approach substantially reduces implementation overhead across diverse analog quantum platforms while achieving accuracy comparable to QuDDPMs. This method improves trainability and robustness, broadening the applicability of quantum generative modeling."}
{"id": "2602.22095", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.22095", "abs": "https://arxiv.org/abs/2602.22095", "authors": ["Jason Doukas"], "title": "On the emergence of quantum mechanics from stochastic processes", "comment": "31 pages, 1 figure", "summary": "The stochastic--quantum correspondence reinterprets quantum dynamics as arising from an underlying stochastic process on a configuration space. We generalize the correspondence by lifting an arbitrary stochastic kernel $Γ$ in finite dimension to a map $φ$ on $B(\\mathcal H)$, formulating the associated lift-compatibility relation, and giving an explicit dictionary between $Γ$ and CPTP (Kraus) maps. We isolate Chapman--Kolmogorov divisibility of the lifted family as the decisive additional constraint: when a CK-consistent CPTP family exists, the lift admits a Lindblad master equation form. In this picture, off-diagonal (phase) degrees of freedom act as a compressed carrier of history dependence not fixed by transition kernels alone; conversely, the apparent emergence of quantum phase information from a phase-blind stochastic description is explained as a memory effect. Finally, we state and prove a divisibility criterion for the underlying stochastic kernels, expressed as a condition involving divisibility of the lifted map together with a diagonality requirement on the density operator."}
{"id": "2602.22102", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.22102", "abs": "https://arxiv.org/abs/2602.22102", "authors": ["Karolina Dziwulska", "Christopher Spiess", "Sarika Mishra", "Markus Leipe", "Yugant Hadiyal", "Fabian Steinlechner"], "title": "Self-stabilized high-dimensional quantum key distribution on a metropolitan free-space link", "comment": null, "summary": "Quantum communication technologies capable of operating reliably across heterogeneous optical channels are essential for scalable metropolitan quantum networks. Here we demonstrate high-dimensional time-bin-encoded quantum key distribution over a hybrid metropolitan link comprising 1.7 km free-space transmission and 685 m of optical fiber. Operating at a clock rate of 500 MHz in the C-band, we implement both 2- and 4-dimensional protocols, and obtain estimated secure finite-key rates of (95 +- 28) kbit/s for 4D at (25.0 +- 2.0) dB loss and (59 +- 27) kbit/s for 2D at (23.5 +- 2.3) dB loss. Crucially, we achieve continuous operation over 48 h in a fully self-referenced architecture: initial synchronization, interferometric phase stabilization, and long-term drift compensation are performed exclusively using the detected quantum signals, without auxiliary optical reference channels. Our results thus establish a practical and versatile platform for hybrid free-space-to-fiber quantum communication and show that the encoding dimensionality can be adapted to the optimal operating regime of realistic metropolitan channels, providing a pathway toward efficient, autonomous and deployable quantum network nodes."}
{"id": "2602.22117", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.22117", "abs": "https://arxiv.org/abs/2602.22117", "authors": ["Raquel Garcia Belles", "Alexander Anferov", "Lukas F. Deeg", "Loris Colicchio", "Arianne Brooks", "Tom Schatteburg", "Maxwell Drimmer", "Ines C. Rodrigues", "Rodrigo Benevides", "Marco Liffredo", "Jyotish Patidar", "Oleksandr Pshyk", "Matteo Fadel", "Luis Guillermo Villanueva", "Sebastian Siol", "Gerhard Kirchmair", "Yiwen Chu"], "title": "Loss Mechanisms in High-coherence Multimode Mechanical Resonators Coupled to Superconducting Circuits", "comment": null, "summary": "Circuit quantum acoustodynamics (cQAD) devices have a wide range of applications in quantum science, all of which depend crucially on the quantum coherence of the mechanical subsystem. In this context, high-overtone bulk acoustic-wave resonators (HBARs) are particularly promising, since they have shown very high quality factors with negligible dephasing. However, the introduction of piezoelectric films, which are necessary for coupling to a superconducting circuit, can lead to additional loss channels, such as surface scattering and two-level systems (TLS). Here, we study the acoustic dissipation of HBAR resonators in cQAD systems and find that the defect density of the piezoelectric material and its interface with the bulk are limiting factors for the coherence. We measure acoustic modes with phonon lifetimes up to 400 $μ$s and lifetime-limited coherence times approaching one millisecond in the quantum regime. When coupled to a superconducting qubit, this leads to a hybrid system with a large quantum coherence cooperativity of $C_{T_2}=1.1\\times10^5$. These results represent a new milestone for the performance of cQAD devices and offer concrete paths forward for further improvements."}
{"id": "2602.22121", "categories": ["quant-ph", "hep-lat", "nucl-th"], "pdf": "https://arxiv.org/pdf/2602.22121", "abs": "https://arxiv.org/abs/2602.22121", "authors": ["Balint Pato", "Natalie Klco"], "title": "Trade-offs in Gauss's law error correction for lattice gauge theory quantum simulations", "comment": null, "summary": "Gauss's law-based quantum error correction (GLQEC) offers a promising approach to reducing qubit overhead in lattice gauge theory simulations by leveraging built-in symmetries. For applications of GLQEC to 1+1D lattice quantum electrodynamics (QED), we identify two significant trade-offs. First, we prove via dimension-counting arguments that GLQEC requires periodic electric fields, thereby constraining the design space for lattice QED simulations. Second, we numerically compare GLQEC with a universal quantum error correction (UQEC) code, specifically the $d=3$ bitflip repetition code, and find that while GLQEC can achieve lower logical error rates in single-round error correction, it exhibits faster decoherence to the steady-state mixed ensemble under multiple rounds. The mixing speed penalty is manifest in observables of interest for both memory experiments and Hamiltonian evolution. We identify a mixing speed threshold, $p_{th}=0.277(2)$, above which using GLQEC exhibits even faster decoherence than without error correction. Our results highlight fundamental limitations of symmetry-based error correction schemes and inform corresponding constraints on formulations of lattice gauge theories compatible with error-robust quantum simulation techniques."}
{"id": "2602.22126", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.22126", "abs": "https://arxiv.org/abs/2602.22126", "authors": ["Zhenhuan Liu", "Qi Ye", "Zhenyu Cai", "Jens Eisert"], "title": "Exponential speedup in measurement property learning with post-measurement states", "comment": null, "summary": "Learning properties of quantum states and channels is known to benefit from resources such as entangled operations, auxiliary qubits, and adaptivity, whereas the resource structure of measurement learning, namely, learning properties of quantum measurement operators, remains poorly understood. In this work, we identify a measurement learning task for which access limited to classical measurement outcomes leads to an exponential lower bound on the query complexity, established via a distinguishing task between a genuine quantum projective measurement and a purely classical random number generator. Remarkably, this hardness persists even when arbitrary entangled operations, auxiliary systems, and fully adaptive strategies are allowed, indicating that conventional resources for state and channel learning are ineffective in this task. In contrast, when access to the post-measurement quantum state is available, the same task can be solved with constant query complexity using a simple measuring-twice protocol, without requiring resources that are useful for state and channel learning. Our results reveal post-measurement states as a qualitatively new and decisive resource for measurement learning, suggesting potential implications for the design of practical quantum certification protocols."}
{"id": "2602.22160", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.22160", "abs": "https://arxiv.org/abs/2602.22160", "authors": ["Eric Vokes", "Vinod N. Rao", "Elinore Spencer", "Rupesh Kumar"], "title": "Energy efficient optical tracking for space quantum communication", "comment": "10 pages, 9 figures", "summary": "Power consumption is a critical constraint for CubeSat based quantum communication, where tracking systems often dominate the onboard power budget. We demonstrate an energy-efficient approach that enables reliable satellite tracking at substantially reduced beacon power by treating tracking as a weak-signal estimation task. Using a closed-loop system with fine steering mirrors and higher-order Kalman filters on ground, we can maintain stable tracking at a transmitted power equivalent to 34 mW over a -60 dB satellite to ground optical channel. Our results show that the resulting penalties on QKD bit error rates and signal-to-noise ratios are negligible, allowing for more efficient power allocation to quantum payloads in CubeSat missions."}
{"id": "2602.22174", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.22174", "abs": "https://arxiv.org/abs/2602.22174", "authors": ["Sinan Bugu"], "title": "Beyond Single-Shot Fidelity: Chernoff-Based Throughput Optimization in Superconducting Qubit Readout", "comment": null, "summary": "Single-shot fidelity is the standard benchmark for superconducting qubit readout, but it does not directly minimize the total wall-clock time required to certify a quantum state. We formulate an information-theoretic description of dispersive readout that treats the measurement record as a stochastic communication channel and compute the classical Chernoff information governing the multi-shot error exponent using a trajectory model that incorporates T1 relaxation with full cavity memory. We find a consistent separation between the integration time that maximizes single-shot fidelity and the time that minimizes total certification time. For representative transmon parameters and hardware overheads, the throughput-optimal integration window is longer than the fidelity-optimal one, yielding certification speedups of approximately 9-11%, with the gain saturating near 1.13x in the high-readout-power and high-overhead regime. Comparing the extracted classical information to the Gaussian Chernoff limit defines an information-extraction efficiency metric and shows that typical dispersive schemes are limited to about 45% capture at short integration times by detection efficiency, decreasing to approximately 12% at the throughput-optimal integration time of approximately 1.22 us due to T1-induced trajectory smearing. This formulation connects readout calibration directly to the operational objective of minimizing certification time in high-throughput superconducting processors."}
{"id": "2602.22195", "categories": ["quant-ph", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.22195", "abs": "https://arxiv.org/abs/2602.22195", "authors": ["Dar Gilboa", "Siddhartha Jain", "Or Sattath"], "title": "Hybrid Consensus with Quantum Sybil Resistance", "comment": null, "summary": "Sybil resistance is a key requirement of decentralized consensus protocols. It is achieved by introducing a scarce resource (such as computational power, monetary stake, disk space, etc.), which prevents participants from costlessly creating multiple fake identities and hijacking the protocol. Quantum states are generically uncloneable, which suggests that they may serve naturally as an unconditionally scarce resource. In particular, uncloneability underlies quantum position based-cryptography, which is unachievable classically. We design a consensus protocol that combines classical hybrid consensus protocols with quantum position verification as the Sybil resistance mechanism, providing security in the standard model, and achieving improved energy efficiency compared to hybrid protocols based on Proof-of-Work. Our protocol inherits the benefits of other hybrid protocols, namely the faster confirmation times compared to pure Proof-of-Work protocols, and resilience against the compounding wealth issue that plagues protocols based on Proof-of-Stake Sybil resistance. We additionally propose a spam prevention mechanism for our protocol in the Random Oracle model."}
{"id": "2602.22201", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.22201", "abs": "https://arxiv.org/abs/2602.22201", "authors": ["Yichen Xu", "Xiao Wang"], "title": "Controlled jump in the Clifford hierarchy", "comment": "25 pages. Comments are welcomed", "summary": "We develop a simple and systematic route to higher levels of the qubit Clifford hierarchy by coherently controlling Clifford operations. Our approach is based on Pauli periodicity, defined for a Clifford unitary $U$ as the smallest integer $m\\ge 1$ such that $U^{2^{m}}$ is a Pauli operator up to phase. We prove a sharp controlled-jump rule showing that the controlled gate $CU$ lies strictly in level $m+2$ of the hierarchy, and equivalently that $CU$ lies in level $k$ if $U^{2^{k-2}}$ is Pauli while no smaller positive power of $U$ is Pauli. We further quantify the resources required to realize large level jumps in the Clifford hierarchy by proving an essentially tight upper bound on Pauli periodicity as a function of the number of qubits, which implies that accessing high hierarchy levels through controlled Cliffords requires a number of target qubits that grows exponentially with the desired level. We complement this limitation with explicit infinite families of Pauli-periodic Cliffords whose controlled versions achieve asymptotically optimal jumps. As an application, we propose a protocol for preparing logical catalyst states that enable logical $Z^{1/2^k}$ phase gates via phase kickback from a single jumped Clifford."}
{"id": "2602.22205", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech", "math-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.22205", "abs": "https://arxiv.org/abs/2602.22205", "authors": ["Aritra Ghosh", "M. Bhattacharya"], "title": "Quantum jumps in open cavity optomechanics and Liouvillian versus Hamiltonian exceptional points", "comment": null, "summary": "Exceptional points, where two or more eigenstates of a non-Hermitian system coalesce, are now of interest across many fields of physics, from the perspective of open-system dynamics, sensing, nonreciprocal transport, and topological phase transitions. In this work, we investigate exceptional points in cavity optomechanics, a platform of interest to diverse communities working on gravitational-wave detection, macroscopic quantum mechanics, quantum transduction, etc. Specifically, we clarify the role of quantum jumps in making a clear distinction between Liouvillian and Hamiltonian exceptional points in optomechanical systems. While the Liouvillian exceptional point arises from the unconditional Lindblad dynamics and is independent of the phonon-bath temperature, the Hamiltonian exceptional point emerges from the conditional no-jump evolution and acquires a thermal shift due to an enhanced conditional damping. Employing the thermofield formalism, we derive a unified spectral framework that interpolates between these regimes via an analytical hybrid-Liouvillian description. Remarkably, in the weak-quantum-jump regime, the exceptional point is perturbed only at the second order, highlighting the robustness of the Hamiltonian exceptional point under small hybrid perturbations. Our work reveals a continuous family of hybrid exceptional points, clarifies the operational and physical differences between the conditional and unconditional dissipative dynamics in optomechanical systems, and provides a probe for thermal baths."}
{"id": "2602.22211", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.22211", "abs": "https://arxiv.org/abs/2602.22211", "authors": ["Shival Dasu", "Matthew DeCross", "Andrew Y. Guo", "Ali Lavasani", "Jan Behrends", "Asmae Benhemou", "Yi-Hsiang Chen", "Karl Mayer", "Chris N. Self", "Selwyn Simsek", "Basudha Srivastava", "M. S. Allman", "Jake Arkinstall", "Justin G. Bohnet", "Nathaniel Q. Burdick", "J. P. Campora", "Alex Chernoguzov", "Samuel F. Cooper", "Robert D. Delaney", "Joan M. Dreiling", "Brian Estey", "Caroline Figgatt", "Cameron Foltz", "John P. Gaebler", "Alex Hall", "Craig A. Holliman", "Ali A. Husain", "Akhil Isanaka", "Colin J. Kennedy", "Yuga Kodama", "Nikhil Kotibhaskar", "Nathan K. Lysne", "Ivaylo S. Madjarov", "Michael Mills", "Alistair R. Milne", "Brian Neyenhuis", "Annie J. Park", "Anthony Ransford", "Adam P. Reed", "Steven J. Sanders", "Charles H. Baldwin", "David Hayes", "Ben Criger", "Andrew C. Potter", "David Amaro"], "title": "Computing with many encoded logical qubits beyond break-even", "comment": null, "summary": "High-rate quantum error correcting (QEC) codes encode many logical qubits in a given number of physical qubits, making them promising candidates for quantum computation. Implementing high-rate codes at a scale that both frustrates classical computing and improves performance by encoding requires both high fidelity gates and long-range qubit connectivity -- both of which are offered by trapped-ion quantum computers. Here, we demonstrate computations that outperform their unencoded counterparts in the high-rate $[[ k+2,\\, k,\\, 2 ]]$ iceberg quantum error detecting (QED) and $[[ (k_2 + 2)(k_1 + 2),\\, k_2k_1,\\, 4 ]]$ two-level concatenated iceberg QEC codes, using the 98-qubit Quantinuum Helios trapped-ion quantum processor. Utilizing new gadgets for encoded operations, we realize this \"beyond break-even\" performance with reasonable postselection rates across a range of fault-tolerant (FT) and partially-fault-tolerant (pFT) component and application benchmarks with between $48$ and $94$ logical qubits. These benchmarks include FT state preparation and measurement, QEC cycle benchmarking, logical gate benchmarking, GHZ state preparation, and a pFT quantum simulation of the three-dimensional $XY$ model of quantum magnetism. Additionally, we illustrate that postselection rates can be suppressed by increasing the code distance via concatenation. Our results represent state-of-the-art logical component and state fidelities and provide evidence that high-rate QED/QEC codes are viable on contemporary quantum computers for near-term beyond-classical-scale computation."}
{"id": "2602.21299", "categories": ["cond-mat.str-el", "physics.chem-ph", "physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21299", "abs": "https://arxiv.org/abs/2602.21299", "authors": ["Zhen Tao", "Victor Galitski"], "title": "Ab Initio Random Matrix Theory of Molecular Electronic Structure", "comment": "8 pages, 8 figures", "summary": "We use ab initio electronic-structure methods to investigate random-matrix theory (RMT) universality in molecular electronic structure. Using single-reference electronic structure methods, including Hartree-Fock, configuration-interaction singles (CIS), density functional theory, and linear-response time-dependent density-functional theory, we compute single-particle orbital energies and many-electron excitations of several representative molecules (benzene, alanine, 1-phenylethylamine, methyloxirane, and helicene chains). For generic low-symmetry geometries, the unfolded spectra of these ab initio Hamiltonians exhibit Wigner-Dyson level statistics of the Gaussian orthogonal ensemble (GOE). For extended helicene chains we explicitly restrict to bound valence excitations below the ionization threshold and still observe GOE statistics, indicating that the RMT universality is present for physical states of direct relevance to real molecules. We further explore the electric and magnetic field dependence of the molecular electronic spectra. The variance of electric polarizability (level curvature K) is predicted to be non-analytic in the magnetic field which serves as an infrared cutoff, <K^2> proportional to log(1/|B|). We observe a transition to the Gaussian unitary ensemble (GUE) by increasing the magnetic fields, although it occurs only at magnetic fields far beyond experimentally accessible scales. Our results indicate that random matrix universality provides a general framework for organizing ab initio predictions of interacting electron spectra in complex systems."}
{"id": "2602.21301", "categories": ["cond-mat.str-el", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21301", "abs": "https://arxiv.org/abs/2602.21301", "authors": ["Chih-Yu Lo", "Xueda Wen"], "title": "Detecting Higher Berry Phase via Boundary Scattering", "comment": null, "summary": "Higher Berry phase has recently been proposed to study the topology of the space of gapped many-body quantum systems. In this work, we develop a boundary-scattering approach to detect higher Berry phases in one-dimensional gapped free-fermion systems. By coupling a gapless lead to the gapped system, we demonstrate that the higher Berry invariant can be obtained by studying the higher winding number of the boundary reflection matrix. The resulting topological invariant is robust against perturbations such as disorder. Our approach establishes a connection between higher Berry invariants and transport properties, thereby providing a potentially experimentally accessible probe of parametrized topological phases."}
{"id": "2602.21468", "categories": ["cond-mat.str-el", "cond-mat.dis-nn", "cs.LG", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.21468", "abs": "https://arxiv.org/abs/2602.21468", "authors": ["Brandon Yee", "Wilson Collins", "Maximilian Rutkowski"], "title": "Unsupervised Discovery of Intermediate Phase Order in the Frustrated $J_1$-$J_2$ Heisenberg Model via Prometheus Framework", "comment": null, "summary": "The spin-$1/2$ $J_1$-$J_2$ Heisenberg model on the square lattice exhibits a debated intermediate phase between Néel antiferromagnetic and stripe ordered regimes, with competing theories proposing plaquette valence bond, nematic, and quantum spin liquid ground states. We apply the Prometheus variational autoencoder framework -- previously validated on classical (2D, 3D Ising) and quantum (disordered transverse field Ising) phase transitions -- to systematically explore the $J_1$-$J_2$ phase diagram via unsupervised analysis of exact diagonalization ground states for a $4 \\times 4$ lattice. Through dense parameter scans of $J_2/J_1 \\in [0.3, 0.7]$ with step size 0.01 and comprehensive latent space analysis, we investigate the nature of the intermediate regime using unsupervised order parameter discovery and critical point detection via multiple independent methods. This work demonstrates the application of rigorously validated machine learning methods to open questions in frustrated quantum magnetism, where traditional order parameter identification is challenged by competing interactions and limited accessible system sizes."}
{"id": "2602.22113", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.22113", "abs": "https://arxiv.org/abs/2602.22113", "authors": ["Sander De Meyer", "Atsushi Ueda", "Yuchi He", "Nick Bultinck", "Jutho Haegeman"], "title": "Lowering the temperature of two-dimensional fermionic tensor networks with cluster expansions", "comment": null, "summary": "Representing the time-evolution operator as a tensor network constitutes a key ingredient in several algorithms for studying quantum lattice systems at finite temperature or in a non-equilibrium setting. For a Hamiltonian composed of strictly short-ranged interactions, the Suzuki-Trotter decomposition is the main technique for obtaining such a representation. In [B.~Vanhecke, L.~Vanderstraeten and F.~Verstraete, Physical Review A, L020402 (2021)], an alternative strategy, the cluster expansion, was introduced. This approach naturally preserves internal and lattice symmetries and can more easily be extended to higher-order representations or longer-ranged interactions. We extend the cluster expansion to two-dimensional fermionic systems, and employ it to construct projected entangled-pair operator (PEPO) approximations of Gibbs states. We also discuss and benchmark different truncation schemes for multiplying layers of PEPOs together. Applying the resulting framework to a two-dimensional spinless fermion model with attractive interactions, we resolve a clear phase boundary at finite temperature."}
