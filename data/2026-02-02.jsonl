{"id": "2601.22395", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22395", "abs": "https://arxiv.org/abs/2601.22395", "authors": ["Ismaeel Babur", "Jane Macfarlane"], "title": "Regional Transportation Modeling for Equitable Electric Vehicle Charging Infrastructure Design", "comment": null, "summary": "The widespread adoption of battery electric vehicles (BEVs) holds promise for mitigating emission-related health impacts, particularly for low-income communities disproportionately affected by exposure to traffic-related air pollution. However, designing effective charging infrastructure necessitates a regional modeling approach that accounts for the inherent cross-jurisdictional nature of mobility patterns. This study underscores the importance of regional modeling in optimizing charging station deployment and evaluating the environmental justice implications for equity priority communities. We present a large-scale regional transportation modeling analysis leveraging Mobiliti, a cloud-based platform that employs parallel discrete event simulation to enable rapid computation. Our approach identifies the spatial demand density for charging infrastructure by analyzing over 19 million trips in the San Francisco Bay Area and determining the threshold points where BEVs may require charging across a typical day. By transitioning these trips that originate outside equity priority communities to BEVs, we quantify the potential emission reductions within these vulnerable areas. The regional modeling framework captures the complex interactions between travel behavior, vehicle characteristics, and charging needs, while accounting for the interconnectivity of infrastructure across municipal boundaries. This study demonstrates the critical role of regional modeling in designing equitable BEV charging networks that address environmental justice concerns. The findings inform strategies for deploying charging infrastructure that maximizes accessibility, minimizes range anxiety, and prioritizes the health and well-being of communities disproportionately burdened by transportation emissions."}
{"id": "2601.22403", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22403", "abs": "https://arxiv.org/abs/2601.22403", "authors": ["Khalid Mahmud Labib", "Shabbir Ahmed"], "title": "Modeling of Non-linear Dynamics of Lithium-ion Batteries via Delay-Embedded Dynamic Mode Decomposition", "comment": "7 pages,10 figures", "summary": "The complex electrochemical behavior of lithium-ion batteries results in non-linear dynamics and appropriate modeling of this non-linear dynamical system is of interest for better management and control. In this work, we proposed a family of dynamic mode decomposition (DMD)-based data-driven models that do not require detailed knowledge of the composition of the battery materials but can essentially capture the non-linear dynamics with higher computational efficiency. Only voltage and current data obtained from hybrid pulse power characterization (HPPC) tests were utilized to form the state space matrices and subsequently used for predicting the future terminal voltage at different state of charge (SoC) and aging levels. To construct the system model, 60\\% of the data from a single HPPC test was utilized to generate time-delay embedded snapshots, with embedding dimension ranging from 40 to 2000. Among these, an embedding dimension of 1810 resulted in the least residual sum of squares (RSS) error of 3.86 for the dynamic mode decomposition with control (DMDc) model and 30 for the standard DMD model. For DMDc model, delay embeddings (ranging from 1 to 12) were also incorporated into the input current signals. For the input matrix, an embedding dimension of 6 resulted in a minimum RSS error of 1.74. Furthermore, the system matrices A and B, identified from the HPPC test when the cell is in its healthy state, were held fixed and used to simulate the system dynamics for aged batteries by updating only the control input. Despite the presence of nonlinear degradation effects in later cycles, the DMDc model effectively captured key inner dynamics such as voltage dips and transient responses for subsequent charge and discharge cycles."}
{"id": "2601.22561", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22561", "abs": "https://arxiv.org/abs/2601.22561", "authors": ["Joshua Kartzman", "Calvin Hawkins", "Matthew Hale"], "title": "Approximately Optimal Multi-Stream Quickest Change Detection for Gaussian Streams", "comment": null, "summary": "This paper considers the bandit quickest change detection problem in which one stream contains a change-point that shifts its distribution by an unknown amount in an unknown direction. We consider an agent that can observe only a single stream at each time, and the goal of the agent is to detect this change as quickly as possible while controlling for false alarms. We propose an algorithm that combines a decaying-$ε$-greedy stream switching rule with an efficient change-point detection algorithm for unknown post-change means. We provide bounds on the expected detection delay and average run length to false alarm for our algorithm, and based on these results we prove our algorithm is approximately optimal with respect to a commonly used surrogate. This work is the first to provide provable guarantees in this setting without strong assumptions such as a discretized post-change parameter set or a lower bound on the magnitude of change."}
{"id": "2601.22865", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22865", "abs": "https://arxiv.org/abs/2601.22865", "authors": ["Tanay Raghunandan Srinivasa", "Vivek Deulkar", "Jia Bhargava", "Mohammad Hajiesmaili", "Prashant Shenoy"], "title": "Degradation-Aware Frequency Regulation of a Heterogeneous Battery Fleet via Reinforcement Learning", "comment": "11 pages, 2 figures", "summary": "Battery energy storage systems are increasingly deployed as fast-responding resources for grid balancing services such as frequency regulation and for mitigating renewable generation uncertainty. However, repeated charging and discharging induces cycling degradation and reduces battery lifetime. This paper studies the real-time scheduling of a heterogeneous battery fleet that collectively tracks a stochastic balancing signal subject to per-battery ramp-rate and capacity constraints, while minimizing long-term cycling degradation.\n  Cycling degradation is fundamentally path-dependent: it is determined by charge-discharge cycles formed by the state-of-charge (SoC) trajectory and is commonly quantified via rainflow cycle counting. This non-Markovian structure makes it difficult to express degradation as an additive per-time-step cost, complicating classical dynamic programming approaches. We address this challenge by formulating the fleet scheduling problem as a Markov decision process (MDP) with constrained action space and designing a dense proxy reward that provides informative feedback at each time step while remaining aligned with long-term cycle-depth reduction.\n  To scale learning to large state-action spaces induced by fine-grained SoC discretization and asymmetric per-battery constraints, we develop a function-approximation reinforcement learning method using an Extreme Learning Machine (ELM) as a random nonlinear feature map combined with linear temporal-difference learning. We evaluate the proposed approach on a toy Markovian signal model and on a Markovian model trained from real-world regulation signal traces obtained from the University of Delaware, and demonstrate consistent reductions in cycle-depth occurrence and degradation metrics compared to baseline scheduling policies."}
{"id": "2601.22734", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22734", "abs": "https://arxiv.org/abs/2601.22734", "authors": ["Yuri Yu. Tarasevich"], "title": "Electrical conductivity of a random nanowire network: comparison of two-dimensional and quasi-three-dimensional models", "comment": "4 pages, 3 figures", "summary": "It is shown that the widely used two-dimensional model of random networks of metallic nanowires or carbon nanotubes significantly overestimates the number of contacts between elements compared to real systems, which, within the mean-field approach, leads to overestimated estimates of electrical conductivity, especially when the contact resistances between conductors make the main contribution to the electrical conductivity of the system. In the case of a two-dimensional model, the electrical conductivity of the system depends quadratically on the number density of conductors, whereas in the case of a three-dimensional model this dependence is linear."}
{"id": "2601.22559", "categories": ["cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.22559", "abs": "https://arxiv.org/abs/2601.22559", "authors": ["Siu A. Chin"], "title": "Understanding the sign problem from an exact Path Integral Monte Carlo model of interacting harmonic fermions", "comment": "40 pages with 14 figures", "summary": "This work shows that the recently discovered operator contraction identity for solving the discreet Path Integral of the harmonic oscillator can be applied equally to fermions in any dimension. This then yields an exactly solvable model for studying the sign problem where the Path Integral Monte Carlo energy at any time step for any number of fermions is known analytically, or can be computed numerically. It is found that repulsive/attractive pairwise interaction shifts the sign problem to larger/smaller imaginary time, but does not make it more severe than the non-interacting case. More surprisingly, for closed-shell number of fermions, the sign problem goes away at large imaginary time. Fourth-order and newly found variable-bead algorithms are used to compute ground state energies of quantum dots with up to 110 electrons and compared to results obtained by modern neural networks."}
{"id": "2601.22201", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.22201", "abs": "https://arxiv.org/abs/2601.22201", "authors": ["Gabriela Juncosa", "Saeedeh Mohammadi", "Margaret Samahita", "Taha Yasseri"], "title": "The Benefit of Collective Intelligence in Community-Based Content Moderation is Limited by Overt Political Signalling", "comment": null, "summary": "Social media platforms face increasing scrutiny over the rapid spread of misinformation. In response, many have adopted community-based content moderation systems, including Community Notes (formerly Birdwatch) on X (formerly Twitter), Footnotes on TikTok, and Facebook's Community Notes initiative. However, research shows that the current design of these systems can allow political biases to influence both the development of notes and the rating processes, reducing their overall effectiveness. We hypothesize that enabling users to collaborate on writing notes, rather than relying solely on individually authored notes, can enhance their overall quality. To test this idea, we conducted an online experiment in which participants jointly authored notes on political posts. Our results show that teams produce notes that are rated as more helpful than individually written notes. We also find that politically diverse teams perform better when evaluating Republican posts, while group composition does not affect perceived note quality for Democrat posts. However, the advantage of collaboration diminishes when team members are aware of one another's political affiliations. Taken together, these findings underscore the complexity of community-based content moderation and highlight the importance of understanding group dynamics and political diversity when designing more effective moderation systems."}
{"id": "2601.22170", "categories": ["math.NA", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22170", "abs": "https://arxiv.org/abs/2601.22170", "authors": ["Ricardo Baptista", "Andrew Stuart", "Son Tran"], "title": "Large Language Models: A Mathematical Formulation", "comment": "51 pages, 2 figures", "summary": "Large language models (LLMs) process and predict sequences containing text to answer questions, and address tasks including document summarization, providing recommendations, writing software and solving quantitative problems. We provide a mathematical framework for LLMs by describing the encoding of text sequences into sequences of tokens, defining the architecture for next-token prediction models, explaining how these models are learned from data, and demonstrating how they are deployed to address a variety of tasks. The mathematical sophistication required to understand this material is not high, and relies on straightforward ideas from information theory, probability and optimization. Nonetheless, the combination of ideas resting on these different components from the mathematical sciences yields a complex algorithmic structure; and this algorithmic structure has demonstrated remarkable empirical successes. The mathematical framework established here provides a platform from which it is possible to formulate and address questions concerning the accuracy, efficiency and robustness of the algorithms that constitute LLMs. The framework also suggests directions for development of modified and new methodologies."}
{"id": "2601.22380", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.22380", "abs": "https://arxiv.org/abs/2601.22380", "authors": ["Chaoyi Lu", "Riccardo Rastelli"], "title": "Mixed Latent Position Cluster Models for Networks", "comment": null, "summary": "Over the last two decades, the Latent Position Model (LPM) has become a prominent tool to obtain model-based visualizations of networks. However, the geometric structure of the LPM is inherently symmetric, in the sense that outgoing and incoming edges are assumed to follow the same statistical distribution. As a consequence, the canonical LPM framework is not ideal for the analysis of directed networks. In addition, edges may be weighted to describe the duration or intensity of a connection. This can lead to disassortative patterns and other motifs that cannot be easily captured by the underlying geometry. To address these limitations, we develop a novel extension of the LPM, called the Mixed Latent Position Cluster Model (MLPCM), which can deal with asymmetry and non-Euclidean patterns, while providing new interpretations of the latent space. We dissect the directed edges of the network by formally disentangling how a node behaves from how it is perceived by others. This leads to a dual representation of a node's profile, identifying its ``overt'' and ``covert'' social positions. In order to efficiently estimate the parameters of our model, we develop a variational Bayes approach to approximate the posterior distribution. Unlike many existing variational frameworks, our algorithm does not require any additional numerical approximations. Model selection is performed by introducing a novel partially integrated complete likelihood criteria, which builds upon the literature on penalized likelihood methods. We demonstrate the accuracy of our proposed methodology using synthetic datasets, and we illustrate its practical utility with an application to a dataset of international arms transfers."}
{"id": "2601.22654", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.22654", "abs": "https://arxiv.org/abs/2601.22654", "authors": ["Michael Urs Lars Kastor", "Jan Rottmayer", "Anna Hundertmark", "Nicolas Ralph Gauger"], "title": "Parameter conditioned interpretable U-Net surrogate model for data-driven predictions of convection-diffusion-reaction processes", "comment": null, "summary": "We present a combined numerical and data-driven workflow for efficient prediction of nonlinear, instationary convection-diffusion-reaction dynamics on a two-dimensional phenotypic domain, motivated by macroscopic modeling of cancer cell plasticity. A finite-difference solver, implemented in C++, is developed using second-order spatial discretizations and a step-size controlled Runge-Kutta time integrator. A mesh refinement study confirms the second-order convergence for the spatial discretizations error. Based on simulated input-output pairs and corresponding parameterizations for the diffusion, advection, and reaction mechanisms, we train a parameter-conditioned U-Net surrogate to approximate the fixed-horizon solution map. The surrogate incorporates Feature-wise Linear Modulation (FiLM) for parameter conditioning, coordinate encoding to incorporate spatial location information, and residual blocks to enable multiscale representation learning in combination with the U-Nets skip connections. The trained model achieves low prediction error on held-out test data and provides favorable prediction times due to the GPU based parallelization. Generalization is analyzed using a factorial test dataset, separating initial conditions from parameter conditioning. The results reveal that approximation difficulty varies primarily with the conditioning vector (i.e., the induced PDE regime), rather than with the initial conditions."}
{"id": "2601.22880", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22880", "abs": "https://arxiv.org/abs/2601.22880", "authors": ["Tanay Raghunandan Srinivasa", "Vivek Deulkar", "Aviruch Bhatia", "Vishal Garg"], "title": "Reinforcement Learning-Based Co-Design and Operation of Chiller and Thermal Energy Storage for Cost-Optimal HVAC Systems", "comment": "11 pages, 3 figures", "summary": "We study the joint operation and sizing of cooling infrastructure for commercial HVAC systems using reinforcement learning, with the objective of minimizing life-cycle cost over a 30-year horizon. The cooling system consists of a fixed-capacity electric chiller and a thermal energy storage (TES) unit, jointly operated to meet stochastic hourly cooling demands under time-varying electricity prices. The life-cycle cost accounts for both capital expenditure and discounted operating cost, including electricity consumption and maintenance. A key challenge arises from the strong asymmetry in capital costs: increasing chiller capacity by one unit is far more expensive than an equivalent increase in TES capacity. As a result, identifying the right combination of chiller and TES sizes, while ensuring zero loss-of-cooling-load under optimal operation, is a non-trivial co-design problem. To address this, we formulate the chiller operation problem for a fixed infrastructure configuration as a finite-horizon Markov Decision Process (MDP), in which the control action is the chiller part-load ratio (PLR). The MDP is solved using a Deep Q Network (DQN) with a constrained action space. The learned DQN RL policy minimizes electricity cost over historical traces of cooling demand and electricity prices. For each candidate chiller-TES sizing configuration, the trained policy is evaluated. We then restrict attention to configurations that fully satisfy the cooling demand and perform a life-cycle cost minimization over this feasible set to identify the cost-optimal infrastructure design. Using this approach, we determine the optimal chiller and thermal energy storage capacities to be 700 and 1500, respectively."}
{"id": "2601.23241", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.23241", "abs": "https://arxiv.org/abs/2601.23241", "authors": ["Damien Barbier"], "title": "When low-loss paths make a binary neuron trainable: detecting algorithmic transitions with the connected ensemble", "comment": null, "summary": "We study the connected ensemble, a statistical-mechanics framework that characterizes the formation of low-loss paths in rugged landscapes. First introduced in a previous paper, this ensemble allows one to identify when a network can be trained on a simple task and which minima should be targeted during training. We apply this new framework to the symmetric binary perceptron model (SBP), and study how its typical {connected} minima behave. We show that {connected} minima exist only above a critical threshold $κ_{\\rm connected}$, or equivalently below a critical constraint density $α_{\\rm connected}$. This defines a parameter range in which training the network is easy, as local algorithms can efficiently access this connected manifold. We also highlight that these minima become increasingly robust and closer to one another as the task on which the network is trained becomes more difficult."}
{"id": "2601.22606", "categories": ["physics.geo-ph", "astro-ph.EP", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.22606", "abs": "https://arxiv.org/abs/2601.22606", "authors": ["Shenyi Zhang", "Lei Zhang", "Yutian Ke", "Jinhai Zhang"], "title": "Sculpting of Martian brain terrain reveals the drying of ancient Mars", "comment": null, "summary": "The Martian brain terrain (MBT), characterized by its unique brain-like morphology, is a potential geological archive for finding hints of paleoclimatic conditions during its formation period. The morphological similarity of MBT to self-organized patterned ground on Earth suggests a shared formation mechanism. However, the lack of quantitative descriptions and robust physical modeling of self-organized stone transport jointly limits the study of the thermal and aqueous conditions governing MBT's formation. Here we established a specialized quantitative system for extracting the morphological features of MBT, taking a typical region located in the northern Arabia Terra as an example, and then employed a numerical model to investigate its formation mechanisms. Our simulation results accurately replicate the observed morphology of MBT, matching its key geometric metrics with deviations $<10\\%$. Crucially, however, we find that the self-organized transport can solely produce relief $<0.5$ m, insufficient to explain the formation of MBT with average relief of $3.29 \\pm 0.65$ m. We attribute this discrepancy to sculpting driven by late-stage sublimation, constraining cumulative subsurface ice loss in this region to $\\sim 3$ meters over the past $\\sim 3$ Ma. These findings demonstrate that MBT's formation is a multi-stage process: initial patterning driven by freeze-thaw cycles (implying liquid water) followed by vertical sculpting via sublimation (requiring a dry environment). This evolution provides physical evidence for the transition of the ancient Martian climate from a wetter period to a colder hyper-arid state."}
{"id": "2601.23193", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.23193", "abs": "https://arxiv.org/abs/2601.23193", "authors": ["Anthony Bonato", "Morganna Hinds"], "title": "Network analysis and link prediction in competitive women's basketball", "comment": null, "summary": "Network structure and its role in prediction are examined in competitive basketball at the team and player levels. Adversarial game outcome networks from NCAA Division I women's basketball from 2021 to 2024 are used to compute the common out-neighbor score and PageRank, which are combined into a low-key leader strength that identifies competitors influential through structural similarity despite relatively low centrality. This measure is related to changes in NCAA NET rankings by grouping teams into quantiles and comparing average rank changes across seasons for both previous-to-current and current-to-next transitions. Link prediction is then studied using node2vec embeddings across three interaction settings. For NCAA regular-season game networks, cosine similarity between team embeddings is used in a logistic regression model to predict March Madness matchups. For WNBA shot-blocking networks, future directed blocking interactions are predicted via logistic regression on concatenated source-target player embeddings. For WNBA passing networks, region embeddings learned from first-quarter passes are evaluated for their ability to predict subsequent passing connections. Across NCAA and WNBA settings, embedding-based models provide statistically significant evidence that higher-order network structure contains predictive signals for future interactions, while the passing experiment shows weaker predictive performance but yields interpretable similarity patterns consistent with passing feasibility."}
{"id": "2601.22174", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22174", "abs": "https://arxiv.org/abs/2601.22174", "authors": ["Berke Şahin", "İsmail Aslan"], "title": "On the $L^p$-Convergence and Denoising Performance of Durrmeyer-Type Max-Min Neural Network Operators", "comment": null, "summary": "In this paper, we investigate Durrmeyer-type generalizations of maximum-minimum neural network operators. The primary objective of this study is to establish the convergence of these operators in the $L^{p}$ norm for functions $f\\in L^{p}([a,b],[0,1])$ with $1\\leq p<\\infty$. To this end, we analyze the properties of sigmoidal functions and maximum-minimum operations, subsequently establishing the convergence of the proposed operator in pointwise, supremum, and $L^{p}$ norms. Furthermore, we derive quantitative estimates for the rates of convergence. In the applications section, numerical and graphical examples demonstrate that the proposed Durrmeyer-type operators provide smoother approximations compared to Kantorovich-type and standard max-min operators. Finally, we highlight the superior filtering performance of these operators in signal analysis, validating their effectiveness in both approximation and data processing tasks."}
{"id": "2601.22481", "categories": ["stat.ME", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22481", "abs": "https://arxiv.org/abs/2601.22481", "authors": ["Michael Grantham", "Xueheng Shi", "Bertrand Clarke"], "title": "Changepoint Detection As Model Selection: A General Framework", "comment": null, "summary": "This dissertation presents a general framework for changepoint detection based on L0 model selection. The core method, Iteratively Reweighted Fused Lasso (IRFL), improves upon the generalized lasso by adaptively reweighting penalties to enhance support recovery and minimize criteria such as the Bayesian Information Criterion (BIC). The approach allows for flexible modeling of seasonal patterns, linear and quadratic trends, and autoregressive dependence in the presence of changepoints.\n  Simulation studies demonstrate that IRFL achieves accurate changepoint detection across a wide range of challenging scenarios, including those involving nuisance factors such as trends, seasonal patterns, and serially correlated errors. The framework is further extended to image data, where it enables edge-preserving denoising and segmentation, with applications spanning medical imaging and high-throughput plant phenotyping.\n  Applications to real-world data demonstrate IRFL's utility. In particular, analysis of the Mauna Loa CO2 time series reveals changepoints that align with volcanic eruptions and ENSO events, yielding a more accurate trend decomposition than ordinary least squares. Overall, IRFL provides a robust, extensible tool for detecting structural change in complex data."}
{"id": "2601.23090", "categories": ["cs.CE", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.23090", "abs": "https://arxiv.org/abs/2601.23090", "authors": ["Mo Wang", "Wenhao Ye", "Junfeng Xia", "Junxiang Zhang", "Xuanye Pan", "Minghao Xu", "Haotian Deng", "Hongkai Wen", "Quanying Liu"], "title": "Omni-fMRI: A Universal Atlas-Free fMRI Foundation Model", "comment": null, "summary": "Self-supervised fMRI foundation models have shown promising transfer performance, yet most rely on predefined region-level parcellations that discard fine-grained voxel information and introduce atlas-dependent biases. We propose Omni-fMRI, an atlas-free foundation model that operates directly on voxel-level signals. To enable scalable pretraining on 49,497 fMRI sessions across nine datasets, Omni-fMRI introduces a dynamic patching mechanism that substantially reduces computational cost while preserving informative spatial structure. To support reproducibility and fair comparison, we establish a comprehensive benchmark suite spanning 11 datasets and a diverse set of resting-state and task-based fMRI tasks. Experimental results demonstrate that Omni-fMRI consistently outperforms existing foundation models, providing a scalable and reproducible framework for atlas-free brain representation learning. Code and logs are available."}
{"id": "2601.22194", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22194", "abs": "https://arxiv.org/abs/2601.22194", "authors": ["Vikas Agnihotri", "Jasleen Kaur", "Sarvagya Kaushik"], "title": "Practical Evaluation of Quantum Kernel Methods for Radar Micro-Doppler Classification on Noisy Intermediate-Scale Quantum (NISQ) Hardware", "comment": null, "summary": "This paper examines the application of a Quantum Support Vector Machine (QSVM) for radarbased aerial target classification using micro-Doppler signatures. Classical features are extracted and reduced via Principal Component Analysis (PCA) to enable efficient quantum encoding. The reduced feature vectors are embedded into a quantum kernel-induced feature space using a fully entangled ZZFeatureMap and classified using a kernel based QSVM. Performance is first evaluated on a quantum simulator and subsequently validated on NISQ-era superconducting quantum hardware, specifically the IBM Torino (133-qubit) and IBM Fez (156-qubit) processors. Experimental results demonstrate that the QSVM achieves competitive classification performance relative to classical SVM baselines while operating on substantially reduced feature dimensionality. Hardware experiments reveal the impact of noise and decoherence and measurement shot count on quantum kernel estimation, and further show improved stability and fidelity on newer Heron r2 architecture. This study provides a systematic comparison between simulator-based and hardware-based QSVM implementations and highlights both the feasibility and current limitations of deploying quantum kernel methods for practical radar signal classification tasks."}
{"id": "2601.22458", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22458", "abs": "https://arxiv.org/abs/2601.22458", "authors": ["Sida He", "Lingxi Xie", "Xiaopeng Zhang", "Qi Tian"], "title": "AI Decodes Historical Chinese Archives to Reveal Lost Climate History", "comment": "60 pages, 4 figures in the main text, 25 figures and 10 tables in the appendix", "summary": "Historical archives contain qualitative descriptions of climate events, yet converting these into quantitative records has remained a fundamental challenge. Here we introduce a paradigm shift: a generative AI framework that inverts the logic of historical chroniclers by inferring the quantitative climate patterns associated with documented events. Applied to historical Chinese archives, it produces the sub-annual precipitation reconstruction for southeastern China over the period 1368-1911 AD. Our reconstruction not only quantifies iconic extremes like the Ming Dynasty's Great Drought but also, crucially, maps the full spatial and seasonal structure of El Ni$ñ$o influence on precipitation in this region over five centuries, revealing dynamics inaccessible in shorter modern records. Our methodology and high-resolution climate dataset are directly applicable to climate science and have broader implications for the historical and social sciences."}
{"id": "2601.22606", "categories": ["physics.geo-ph", "astro-ph.EP", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.22606", "abs": "https://arxiv.org/abs/2601.22606", "authors": ["Shenyi Zhang", "Lei Zhang", "Yutian Ke", "Jinhai Zhang"], "title": "Sculpting of Martian brain terrain reveals the drying of ancient Mars", "comment": null, "summary": "The Martian brain terrain (MBT), characterized by its unique brain-like morphology, is a potential geological archive for finding hints of paleoclimatic conditions during its formation period. The morphological similarity of MBT to self-organized patterned ground on Earth suggests a shared formation mechanism. However, the lack of quantitative descriptions and robust physical modeling of self-organized stone transport jointly limits the study of the thermal and aqueous conditions governing MBT's formation. Here we established a specialized quantitative system for extracting the morphological features of MBT, taking a typical region located in the northern Arabia Terra as an example, and then employed a numerical model to investigate its formation mechanisms. Our simulation results accurately replicate the observed morphology of MBT, matching its key geometric metrics with deviations $<10\\%$. Crucially, however, we find that the self-organized transport can solely produce relief $<0.5$ m, insufficient to explain the formation of MBT with average relief of $3.29 \\pm 0.65$ m. We attribute this discrepancy to sculpting driven by late-stage sublimation, constraining cumulative subsurface ice loss in this region to $\\sim 3$ meters over the past $\\sim 3$ Ma. These findings demonstrate that MBT's formation is a multi-stage process: initial patterning driven by freeze-thaw cycles (implying liquid water) followed by vertical sculpting via sublimation (requiring a dry environment). This evolution provides physical evidence for the transition of the ancient Martian climate from a wetter period to a colder hyper-arid state."}
{"id": "2601.22168", "categories": ["q-fin.RM", "cs.AI", "cs.CR", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2601.22168", "abs": "https://arxiv.org/abs/2601.22168", "authors": ["Shengwei You", "Aditya Joshi", "Andrey Kuehlkamp", "Jarek Nabrzyski"], "title": "Stablecoin Design with Adversarial-Robust Multi-Agent Systems via Trust-Weighted Signal Aggregation", "comment": null, "summary": "Algorithmic stablecoins promise decentralized monetary stability by maintaining a target peg through programmatic reserve management. Yet, their reserve controllers remain vulnerable to regime-blind optimization, calibrating risk parameters on fair-weather data while ignoring tail events that precipitate cascading failures. The March 2020 Black Thursday collapse, wherein MakerDAO's collateral auctions yielded $8.3M in losses and a 15% peg deviation, exposed a critical gap: existing models like SAS systematically omit extreme volatility regimes from covariance estimates, producing allocations optimal in expectation but catastrophic under adversarial stress.\n  We present MVF-Composer, a trust-weighted Mean-Variance Frontier reserve controller incorporating a novel Stress Harness for risk-state estimation. Our key insight is deploying multi-agent simulations as adversarial stress-testers: heterogeneous agents (traders, liquidity providers, attackers) execute protocol actions under crisis scenarios, exposing reserve vulnerabilities before they manifest on-chain. We formalize a trust-scoring mechanism T: A -> [0,1] that down-weights signals from agents exhibiting manipulative behavior, ensuring the risk-state estimator remains robust to signal injection and Sybil attacks.\n  Across 1,200 randomized scenarios with injected Black-Swan shocks (10% collateral drawdown, 50% sentiment collapse, coordinated redemption attacks), MVF-Composer reduces peak peg deviation by 57% and mean recovery time by 3.1x relative to SAS baselines. Ablation studies confirm the trust layer accounts for 23% of stability gains under adversarial conditions, achieving 72% adversarial agent detection. Our system runs on commodity hardware, requires no on-chain oracles beyond standard price feeds, and provides a reproducible framework for stress-testing DeFi reserve policies."}
{"id": "2601.22395", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22395", "abs": "https://arxiv.org/abs/2601.22395", "authors": ["Ismaeel Babur", "Jane Macfarlane"], "title": "Regional Transportation Modeling for Equitable Electric Vehicle Charging Infrastructure Design", "comment": null, "summary": "The widespread adoption of battery electric vehicles (BEVs) holds promise for mitigating emission-related health impacts, particularly for low-income communities disproportionately affected by exposure to traffic-related air pollution. However, designing effective charging infrastructure necessitates a regional modeling approach that accounts for the inherent cross-jurisdictional nature of mobility patterns. This study underscores the importance of regional modeling in optimizing charging station deployment and evaluating the environmental justice implications for equity priority communities. We present a large-scale regional transportation modeling analysis leveraging Mobiliti, a cloud-based platform that employs parallel discrete event simulation to enable rapid computation. Our approach identifies the spatial demand density for charging infrastructure by analyzing over 19 million trips in the San Francisco Bay Area and determining the threshold points where BEVs may require charging across a typical day. By transitioning these trips that originate outside equity priority communities to BEVs, we quantify the potential emission reductions within these vulnerable areas. The regional modeling framework captures the complex interactions between travel behavior, vehicle characteristics, and charging needs, while accounting for the interconnectivity of infrastructure across municipal boundaries. This study demonstrates the critical role of regional modeling in designing equitable BEV charging networks that address environmental justice concerns. The findings inform strategies for deploying charging infrastructure that maximizes accessibility, minimizes range anxiety, and prioritizes the health and well-being of communities disproportionately burdened by transportation emissions."}
{"id": "2601.23108", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.23108", "abs": "https://arxiv.org/abs/2601.23108", "authors": ["Finn Vehlhaber", "Mauro Salazar"], "title": "Energy Management Strategies for Electric Aircraft Charging Leveraging Active Landside Vehicle-to-Grid", "comment": null, "summary": "The deployment of medium-range battery electric aircraft is a promising pathway to improve the environmental footprint of air mobility. Yet such a deployment would be accompanied by significant electric power requirements at airports due to aircraft charging. Given the growing prevalence of electric vehicles and their bi-directional charging capabilities--so-called vehicle-to-grid (V2G)--we study energy buffer capabilities of parked electric vehicles to alleviate pressure on grid connections. To this end, we present energy management strategies for airports providing cost-optimal apron and landside V2G charge scheduling. Specifically, we first formulate the optimal energy management problem of joint aircraft charging and landside V2G coordination as a linear program, whereby we use partial differential equations to model the aggregated charging dynamics of the electric vehicle fleet. Second, we consider a shuttle flight network with a single hub of a large Dutch airline, real-world grid prices, and synthetic parking garage occupancy data to test our framework. Our results show that V2G at even a single airport can indeed reduce energy costs to charge the aircraft fleet: Compared to a baseline scenario without V2G, the proposed concept yields cost savings of up to 32%, depending on the schedule and amount of participating vehicles, and has other potential beneficial effects on the local power grid, e.g., the reduction of potential power peaks."}
{"id": "2601.22874", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "nlin.AO", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.22874", "abs": "https://arxiv.org/abs/2601.22874", "authors": ["Alessandro Pignedoli", "Atreya Majumdar", "Karin Everschor-Sitte"], "title": "Leveraging Interactions for Efficient Swarm-Based Brownian Computing", "comment": "9 pages, 3 figures", "summary": "Drawing inspiration from swarm intelligence, we show that short-range attractive interactions between thermally driven Brownian quasiparticles enable energy-efficient optimization. As quasiparticles can be generated directly within a material, the swarm size can be adjusted with minimal energy overhead. Using an optimization task defined by a spatially varying temperature landscape, we quantitatively show that interacting swarms reliably identify global optima and significantly outperform non-interacting searchers within a well-defined regime of interaction strength and swarm size. This improvement arises from emergent cooperative behavior, where local interactions guide the swarm toward high-quality solutions without central coordination. To link our physical model to experimental realizations, we coarse-grain the quasiparticle dynamics onto a sensor lattice and generate trajectories emulating particle-tracking measurements. We further show that the interacting swarm adapts robustly to landscapes that evolve over time. These findings establish interacting Brownian quasiparticles as a physical platform for scalable and energy-efficient unconventional computing."}
{"id": "2601.23246", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.23246", "abs": "https://arxiv.org/abs/2601.23246", "authors": ["Anthony Bonato", "MacKenzie Carr", "Ketan Chaudhary", "Trent G. Marbach", "Teddy Mishura"], "title": "The Iterated Local Model for tournaments", "comment": null, "summary": "Transitivity is a central, generative principle in social and other complex networks, capturing the tendency for two nodes with a common neighbor to form a direct connection. We propose a new model for highly dense, complex networks based on transitivity, called the Iterated Local Model Tournament (ILMT). In ILMT, we iteratively apply transitivity to form new tournaments by cloning nodes and their adjacencies, and either preserving or reversing the orientation of existing arcs between clones. The resulting model generates tournaments with small diameters and high connectivity as observed in real-world complex networks. We analyze subtournaments or motifs in the ILMT model and their universality properties. For many parameter choices, the model generates sequences of quasirandom tournaments. We also study the graph-theoretic properties of ILMT tournaments, including their cop number, domination number, and chromatic number. We finish with a set of open problems and variants of the ILMT model for oriented graphs."}
{"id": "2601.22341", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22341", "abs": "https://arxiv.org/abs/2601.22341", "authors": ["Qiang Du", "Baoming Shi"], "title": "Convergence Analysis of the Discrete Constrained Saddle Dynamics and Their Momentum Variants", "comment": null, "summary": "We study the discrete constrained saddle dynamics and their momentum variants for locating saddle points on manifolds. Under the assumption of exact unstable eigenvectors, we establish a local linear convergence of the discrete constrained saddle dynamics and show that the convergence rate depends on the condition number of the Riemannian Hessian. To mitigate this dependence, we introduce a momentum-based constrained saddle dynamics and prove local convergence of the continuous-time dynamics as well as the corresponding discrete scheme, which further demonstrates that momentum accelerates convergence, particularly in ill-conditioned settings. In addition, we show that a single-step eigenvector update is sufficient to guarantee local convergence; thus, the assumption of exact unstable eigenvectors is not necessary, which substantially reduces the computational cost. Finally, numerical experiments, including applications to the Thomson problem, the Rayleigh quotient on the Stiefel manifold, and the energy functional of Bose-Einstein condensates, are presented to complement the theoretical analysis."}
{"id": "2601.22525", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22525", "abs": "https://arxiv.org/abs/2601.22525", "authors": ["Tracy Bergemann", "Tim Hanson"], "title": "Group Sequential Methods for the Win Ratio", "comment": "26 pages, 2 figures, 2 tables", "summary": "The win ratio is increasingly used in randomized trials due to its intuitive clinical interpretation, ability to incorporate the relative importance of composite endpoints, and its capacity for combining different types of outcomes (e.g. time-to-event, binary, counts, etc.) to be combined. There are open questions, however, about how to implement adaptive design approaches when the primary endpoint is a win ratio, including in group sequential designs. A key requirement allowing for straightforward application of classical group sequential methods is the independence of incremental interim test statistics. This paper derives the covariance structure of incremental U-statistics that evaluate the win ratio under its asymptotic distribution. The derived covariance shows that the independent increments assumption holds for the asymptotic distribution of U-statistics that test the win ratio. Simulations confirm that traditional $α$-spending preserves Type I error across interim looks. A retrospective look at the IN.PACT SFA clinical trial data illustrates the potential for stopping early in a group sequential design using the win ratio. We have demonstrated that straightforward use of Lan-De\\uppercase{M}ets $α$-spending is possible for randomized trials involving the win ratio under certain common conditions. Thus, existing software capable of computing traditional group sequential boundaries can be employed."}
{"id": "2601.23200", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.23200", "abs": "https://arxiv.org/abs/2601.23200", "authors": ["Lorenzo Emer", "Marco Lippi", "Andrea Mina", "Andrea Vandin"], "title": "Large Language Models for Patent Classification: Strengths, Trade-offs, and the Long Tail Effect", "comment": "44 pages, 8 figures", "summary": "Patent classification into CPC codes underpins large scale analyses of technological change but remains challenging due to its hierarchical, multi label, and highly imbalanced structure. While pre Generative AI supervised encoder based models became the de facto standard for large scale patent classification, recent advances in large language models (LLMs) raise questions about whether they can provide complementary capabilities, particularly for rare or weakly represented technological categories. In this work, we perform a systematic comparison of encoder based classifiers (BERT, SciBERT, and PatentSBERTa) and open weight LLMs on a highly imbalanced benchmark dataset (USPTO 70k). We evaluate LLMs under zero shot, few shot, and retrieval augmented prompting, and further assess parameter efficient fine tuning of the best performing model. Our results show that encoder based models achieve higher aggregate performance, driven by strong results on frequent CPC subclasses, but struggle on rare ones. In contrast, LLMs achieve relatively higher performance on infrequent subclasses, often associated with early stage, cross domain, or weakly institutionalised technologies, particularly at higher hierarchical levels. These findings indicate that encoder based and LLM based approaches play complementary roles in patent classification. We additionally quantify inference time and energy consumption, showing that encoder based models are up to three orders of magnitude more efficient than LLMs. Overall, our results inform responsible patentometrics and technology mapping, and motivate hybrid classification approaches that combine encoder efficiency with the long tail coverage of LLMs under computational and environmental constraints."}
{"id": "2601.22224", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.22224", "abs": "https://arxiv.org/abs/2601.22224", "authors": ["Jia-Nan Yang", "Lata Kh Joshi", "Filiberto Ares", "Yihang Han", "Pengfei Zhang", "Pasquale Calabrese"], "title": "Probing Entanglement and Symmetries in Random States Using a Superconducting Quantum Processor", "comment": null, "summary": "Quantum many-body systems display an extraordinary degree of complexity, yet many of their features are universal: they depend not on microscopic details, but on a few fundamental physical aspects such as symmetries. A central challenge is to distill these universal characteristics from model-specific ones. Random quantum states sampled from a uniform distribution, the Haar measure, provide a powerful framework for capturing this typicality. Here, we experimentally study the entanglement and symmetries of random many-body quantum states generated by evolving simple product states under ergodic Floquet models. We find excellent agreement with the predictions from the Haar-random state ensemble. First, we measure the Rényi-2 entanglement entropy as a function of the subsystem size, observing the Page curve. Second, we probe the subsystem symmetries using entanglement asymmetry. Finally, we measure the moments of partially transposed reduced density matrices obtained by tracing out part of the system in the generated ensembles, thereby revealing distinct entanglement phases. Our results offer an experimental perspective on the typical entanglement and symmetries of many-body quantum systems."}
{"id": "2601.22540", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.22540", "abs": "https://arxiv.org/abs/2601.22540", "authors": ["Gan Zhang"], "title": "Linking Extratropical Forecast Degradation to Tropical Cyclones in Physical and AI Models", "comment": null, "summary": "Global medium-range weather forecasts suffer occasional failures (\"busts\"), often linked to tropical cyclones (TCs). We systematically investigate the TC influences by clustering historical TC tracks and comparing skill of forecasts from a physics-based model (ECMWF-IFS) and an AI-physics hybrid model (Google-NGCM) initialized near TC genesis. Case analysis shows both models exhibit similar large-scale error growth in the extratropics, suggesting prediction skill bounded by similar limits despite model differences in spatial resolution and parameterized physics. Aggregated statistics reveal that low skill of Week-2 forecasts may occur after TC genesis, regardless of whether they recurve or not. While recurving tracks are established error sources, zonal-track clusters can be associated with similarly profound forecast degradation, acting through Rossby wave dynamics and remote moisture transport mechanisms. Furthermore, the stochastic NGCM generally outperforms its deterministic counterpart and suggests that TC-related forecast degradation is more pronounced for Europe than elsewhere in the Northern Hemisphere."}
{"id": "2601.23178", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2601.23178", "abs": "https://arxiv.org/abs/2601.23178", "authors": ["Chenxi Kong", "Michael Gurnis", "Zachary E. Ross"], "title": "Forward and Inverse Mantle Convection with Neural Operators", "comment": "Manuscript submitted to Geophysical Journal International; revision in preparation", "summary": "Thermal state reconstruction -- reversing convection to recover the thermal structure of the mantle at an earlier geologic time -- is an important tool to understand the evolution of mantle convection and its relation to seismic tomographic images and observations at the surface. Thermal state reconstructions are computationally expensive. Here we transformed the basic computational element, numerical solvers, into neural operators, a class of machine learning models for learning mappings between function spaces. Focusing on a specific architecture, Fourier Neural Operators, we demonstrate that they can represent not only a surrogate model like the Stokes system of equations using a purely physics informed approach, but also discover operators without explicit mathematical formulations or even ill-posedness from data, including the direct mapping between two convecting thermal states separated by a long time interval much larger than the Courant Fredrich Lewy condition and its reversal. These neural operators significantly accelerate forward and inverse convection modeling by transforming forward physical processes into surrogate models with lower complexity while utilizing auto-differentiation to calculate gradients. With this framework, we demonstrate the strength and weaknesses of four methods for thermal state reconstructions: Reverse buoyancy, reverse convection operator, an inversion with only the terminal thermal state, and a joint inversion with the terminal thermal state and surface velocity evolution. The reverse convection operator is shown to perform poorly in the presence of observational noise, but the joint inversion overcomes this limitation. The joint technique could probably become a solution to large-scale thermal state inversion problems using seismic tomography and plate tectonic reconstructions."}
{"id": "2601.22403", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22403", "abs": "https://arxiv.org/abs/2601.22403", "authors": ["Khalid Mahmud Labib", "Shabbir Ahmed"], "title": "Modeling of Non-linear Dynamics of Lithium-ion Batteries via Delay-Embedded Dynamic Mode Decomposition", "comment": "7 pages,10 figures", "summary": "The complex electrochemical behavior of lithium-ion batteries results in non-linear dynamics and appropriate modeling of this non-linear dynamical system is of interest for better management and control. In this work, we proposed a family of dynamic mode decomposition (DMD)-based data-driven models that do not require detailed knowledge of the composition of the battery materials but can essentially capture the non-linear dynamics with higher computational efficiency. Only voltage and current data obtained from hybrid pulse power characterization (HPPC) tests were utilized to form the state space matrices and subsequently used for predicting the future terminal voltage at different state of charge (SoC) and aging levels. To construct the system model, 60\\% of the data from a single HPPC test was utilized to generate time-delay embedded snapshots, with embedding dimension ranging from 40 to 2000. Among these, an embedding dimension of 1810 resulted in the least residual sum of squares (RSS) error of 3.86 for the dynamic mode decomposition with control (DMDc) model and 30 for the standard DMD model. For DMDc model, delay embeddings (ranging from 1 to 12) were also incorporated into the input current signals. For the input matrix, an embedding dimension of 6 resulted in a minimum RSS error of 1.74. Furthermore, the system matrices A and B, identified from the HPPC test when the cell is in its healthy state, were held fixed and used to simulate the system dynamics for aged batteries by updating only the control input. Despite the presence of nonlinear degradation effects in later cycles, the DMDc model effectively captured key inner dynamics such as voltage dips and transient responses for subsequent charge and discharge cycles."}
{"id": "2601.22294", "categories": ["math.OC", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22294", "abs": "https://arxiv.org/abs/2601.22294", "authors": ["Serhii Kryhin", "Tatiana Mouzykantskii", "Vivishek Sudhir"], "title": "Forecasting in the presence of scale-free noise", "comment": "6 pages, 1 figure, 8 sections of Supplementary Information", "summary": "The extraction of signals from noise is a common problem in all areas of science and engineering. A particularly useful version is that of forecasting: determining a causal filter that estimates a future value of a hidden process from past observations. Current techniques for deriving the filter require that the noise be well described by rational power spectra. However, scale-free noises, whose spectra scale as a non-integer power of frequency, are ubiquitous in practice. We establish a method, together with performance guarantees, that solves the forecasting problem in the presence of scale-free noise. Via the duality between estimation and control, our technique can be used to design control for distributed systems. These results will have wide-ranging applications in neuroscience, finance, fluid dynamics, and quantum measurements."}
{"id": "2601.22602", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22602", "abs": "https://arxiv.org/abs/2601.22602", "authors": ["Zhigang Bao", "Kha Man Cheong", "Yuji Li", "Jiaxin Qiu"], "title": "A spectral approach for online covariance change point detection", "comment": null, "summary": "Change point detection in covariance structures is a fundamental and crucial problem for sequential data. Under the high-dimensional setting, most of the existing research has focused on identifying change points in historical data. However, there is a significant lack of studies on the practically relevant online change point problem, which means promptly detecting change points as they occur. In this paper, applying the limiting theory of linear spectral statistics for random matrices, we propose a class of spectrum based CUSUM-type statistic. We first construct a martingale from the difference of linear spectral statistics of sequential sample Fisher matrices, which converges to a Brownian motion. Our CUSUM-type statistic is then defined as the maximum of a variant of this process. Finally, we develop our detection procedure based on the invariance principle. Simulation results show that our detection method is highly sensitive to the occurrence of change point and is able to identify it shortly after they arise, outperforming the existing approaches."}
{"id": "2601.23160", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.23160", "abs": "https://arxiv.org/abs/2601.23160", "authors": ["Marko Nonhoff", "Mohammad Taher Al Torshan", "Matthias A. Müller"], "title": "Robust Control of Constrained Linear Systems using Online Convex Optimization and a Reference Governor", "comment": "Presented at 2024 IEEE 63rd Conference on Decision and Control (CDC)", "summary": "This article develops a control method for linear time-invariant systems subject to time-varying and a priori unknown cost functions, that satisfies state and input constraints, and is robust to exogenous disturbances. To this end, we combine the online convex optimization framework with a reference governor and a constraint tightening approach. The proposed framework guarantees recursive feasibility and robust constraint satisfaction. Its closed-loop performance is studied in terms of its dynamic regret, which is bounded linearly by the variation of the cost functions and the magnitude of the disturbances. The proposed method is illustrated by a numerical case study of a tracking control problem."}
{"id": "2601.22874", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "nlin.AO", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.22874", "abs": "https://arxiv.org/abs/2601.22874", "authors": ["Alessandro Pignedoli", "Atreya Majumdar", "Karin Everschor-Sitte"], "title": "Leveraging Interactions for Efficient Swarm-Based Brownian Computing", "comment": "9 pages, 3 figures", "summary": "Drawing inspiration from swarm intelligence, we show that short-range attractive interactions between thermally driven Brownian quasiparticles enable energy-efficient optimization. As quasiparticles can be generated directly within a material, the swarm size can be adjusted with minimal energy overhead. Using an optimization task defined by a spatially varying temperature landscape, we quantitatively show that interacting swarms reliably identify global optima and significantly outperform non-interacting searchers within a well-defined regime of interaction strength and swarm size. This improvement arises from emergent cooperative behavior, where local interactions guide the swarm toward high-quality solutions without central coordination. To link our physical model to experimental realizations, we coarse-grain the quasiparticle dynamics onto a sensor lattice and generate trajectories emulating particle-tracking measurements. We further show that the interacting swarm adapts robustly to landscapes that evolve over time. These findings establish interacting Brownian quasiparticles as a physical platform for scalable and energy-efficient unconventional computing."}
{"id": "2601.22344", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22344", "abs": "https://arxiv.org/abs/2601.22344", "authors": ["Marc Aurèle Gilles", "Heather Wilber"], "title": "Low-Rank Approximation by Randomly Pivoted LU", "comment": null, "summary": "The low-rank approximation properties of Randomly Pivoted LU (RPLU), a variant of Gaussian elimination where pivots are sampled proportional to the squared entries of the Schur complement, are analyzed. It is shown that the RPLU iterates converge geometrically in expectation for matrices with rapidly decaying singular values. RPLU outperforms existing low-rank approximation algorithms in two settings: first, when memory is limited, RPLU can be implemented with $\\mathcal{O}(k^2 + m + n)$ storage and $\\mathcal{O}( k(m + n)+ k\\mathcal{M}(\\mat{A}) + k^3)$ operations, where $\\mathcal{M}(\\mat{A})$ is the cost of a matvec with $\\mat{A}\\in\\mathbb{C}^{n\\times m}$ or its adjoint, for a rank-$k$ approximation. Second, when the matrix and its Schur complements share exploitable structure, such as for Cauchy-like matrices. The efficacy of RPLU is illustrated with several examples, including applications in rational approximation and solving large linear systems on GPUs."}
{"id": "2601.22572", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22572", "abs": "https://arxiv.org/abs/2601.22572", "authors": ["Zixian Zhao", "Chengxin Yang", "Fan Li"], "title": "Propensity score weighted Cox regression for survival outcomes in observational studies with multiple or factorial treatments", "comment": "Correspondence: Fan Li, fl35@duke.edu", "summary": "In observational studies with survival or time-to-event outcomes, a propensity score weighted marginal Cox proportional hazard model with the treatment variable as the only predictor is commonly used to estimate the causal marginal hazard ratio between two treatments. Observational studies often have more than two treatments, but corresponding analysis methods are limited. In this paper, we combine the propensity score weighting method for multiple treatments and a marginal Cox model with indicators for each treatment to estimate the causal hazard ratios between multiple treatments and a common reference treatment. We illustrate two weighting schemes: inverse probability of treatment weighting and overlap weighting. We prove the consistency of the maximum weighted partial likelihood estimator of the causal marginal hazard ratio and derive a robust sandwich variance estimator. As an important special case of multiple treatments, we elaborate the Cox model for two-way factorial treatments. We apply the method to evaluate the real-world comparative effectiveness of three types of anti-obesity medications on heart failure. We develop an associated R package 'PSsurvival'."}
{"id": "2601.23268", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.23268", "abs": "https://arxiv.org/abs/2601.23268", "authors": ["Milton Gomez", "Marie McGraw", "Saranya Ganesh S.", "Frederick Iat-Hin Tam", "Ilia Azizi", "Samuel Darmon", "Monika Feldmann", "Stella Bourdin", "Louis Poulain--Auzéau", "Suzana J. Camargo", "Jonathan Lin", "Dan Chavas", "Chia-Ying Lee", "Ritwik Gupta", "Andrea Jenney", "Tom Beucler"], "title": "TCBench: A Benchmark for Tropical Cyclone Track and Intensity Forecasting at the Global Scale", "comment": "28 Pages, Including SI", "summary": "TCBench is a benchmark for evaluating global, short to medium-range (1-5 days) forecasts of tropical cyclone (TC) track and intensity. To allow a fair and model-agnostic comparison, TCBench builds on the IBTrACS observational dataset and formulates TC forecasting as predicting the time evolution of an existing tropical system conditioned on its initial position and intensity. TCBench includes state-of-the-art dynamical (TIGGE) and neural weather models (AIFS, Pangu-Weather, FourCastNet v2, GenCast). If not readily available, baseline tracks are consistently derived from model outputs using the TempestExtremes library. For evaluation, TCBench provides deterministic and probabilistic storm-following metrics. On 2023 test cases, neural weather models skillfully forecast TC tracks, while skillful intensity forecasts require additional steps such as post-processing. Designed for accessibility, TCBench helps AI practitioners tackle domain-relevant TC challenges and equips tropical meteorologists with data-driven tools and workflows to improve prediction and TC process understanding. By lowering barriers to reproducible, process-aware evaluation of extreme events, TCBench aims to democratize data-driven TC forecasting."}
{"id": "2601.22247", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22247", "abs": "https://arxiv.org/abs/2601.22247", "authors": ["David Vaknin"], "title": "The Photonic Foundation of Temperature: Mechanisms of Thermal Equilibrium and Entropy Production", "comment": null, "summary": "I examine the physical foundations of temperature and thermal equilibrium by identifying photons as the fundamental agents that establish and maintain the characteristic energy scale $E_c = k_B T$ in ordinary matter. While classical thermodynamics successfully describes equilibrium phenomenologically, the realization of thermal distributions requires concrete microscopic mechanisms provided by quantum electrodynamics. We derive the Boltzmann distribution from a minimal differential scaling postulate and show that sustaining thermal equilibrium demands continuous photon exchange with average energy $\\langle hν\\rangle = 2.701\\,E_c$, quantifying the energetic throughput necessary to counter radiative losses. Entropy production is shown to arise naturally from inelastic photon scattering that converts high-energy photons into many lower-energy quanta, thereby increasing accessible microstates and driving irreversible evolution toward equilibrium. We establish physical criteria distinguishing genuine thermal equilibrium from purely formal temperature assignments and demonstrate that the classical notion of an infinite thermal reservoir emerges as an effective idealization within a hierarchy of dynamically maintained photon baths. This photonic framework complements phenomenological thermodynamics by providing its microscopic foundation and clarifies the physical meaning of temperature as an emergent collective property of photon-mediated energy exchange."}
{"id": "2601.23190", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.23190", "abs": "https://arxiv.org/abs/2601.23190", "authors": ["Giovanni De Cillis", "Alberto Carrassi", "Julien Brajard", "Laurent Bertino", "Matteo Broccoli", "Dorotea Iovino", "Tobias Sebastian Finn", "Marc Bocquet"], "title": "Hybrid physics-data-driven modeling for sea ice thermodynamics and transfer learning", "comment": null, "summary": "This study explores a physics-data driven hybrid approach for sea-ice column physics models, in which a machine learning (ML) component acts as a state-dependent parameterization of forecast errors. We examine how perturbations in snow thermodynamics and sea-ice radiative properties affect forecast errors, and train dedicated neural networks (NNs) for each model configuration. The performance of the hybrid models is evaluated for long lead-time forecasts and compared against a benchmark system based on climatological forecast-error estimates. The NN-based hybrids prove to be stable, robust to initial condition and atmospheric forcing errors, and consistently outperform their climatology-based counterpart. To derive guiding principles for efficiently handling possible physical model updates, we perform transfer learning experiments to test whether pretrained NNs optimized for one model configuration can be successfully adapted to another. Results indicate that direct evaluation of pretrained networks on the target task provides useful insights into their adaptability, recommending transfer learning whenever performance exceeds a trivial baseline. Finally, a feature-importance analysis shows that atmospheric forcing inputs have negligible influence on NN predictive skill, while ice-layer enthalpies play a key role in achieving satisfactory performance."}
{"id": "2601.22561", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22561", "abs": "https://arxiv.org/abs/2601.22561", "authors": ["Joshua Kartzman", "Calvin Hawkins", "Matthew Hale"], "title": "Approximately Optimal Multi-Stream Quickest Change Detection for Gaussian Streams", "comment": null, "summary": "This paper considers the bandit quickest change detection problem in which one stream contains a change-point that shifts its distribution by an unknown amount in an unknown direction. We consider an agent that can observe only a single stream at each time, and the goal of the agent is to detect this change as quickly as possible while controlling for false alarms. We propose an algorithm that combines a decaying-$ε$-greedy stream switching rule with an efficient change-point detection algorithm for unknown post-change means. We provide bounds on the expected detection delay and average run length to false alarm for our algorithm, and based on these results we prove our algorithm is approximately optimal with respect to a commonly used surrogate. This work is the first to provide provable guarantees in this setting without strong assumptions such as a discretized post-change parameter set or a lower bound on the magnitude of change."}
{"id": "2601.22295", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22295", "abs": "https://arxiv.org/abs/2601.22295", "authors": ["Ziyao Wang", "Svetlozar T Rachev"], "title": "Operating Imperfect AI: Reliability Drift and Human Congestion", "comment": null, "summary": "The deployment of machine learning in high-stakes services relies on ``human-in-the-loop'' architectures to mitigate algorithmic uncertainty. However, existing static policies fail to address a fundamental tension: algorithms suffer from stochastic ``reliability drift,'' while human override capacity is scarce and congestible. We formulate the management of such systems as a dynamic queueing control problem. The system state is defined by the tuple (queue backlog, reliability regime), and the control variable is a state-dependent risk threshold. We prove that the optimal escalation policy is driven by the endogenous ``Shadow Price of Capacity.'' We establish two key structural monotonicity results: (i) Congestion Shedding, where the threshold rises with backlog to sacrifice marginal accuracy for responsiveness; and (ii) Safety Buffering, where the threshold lowers during drift to use the queue as a ``risk capacitor.'' Furthermore, we identify a critical ``Capacity Phase Transition'' in the arrival-drift parameter space, beyond which no policy can maintain safety standards without causing structural system failure (infinite queues). Our results provide rigorous operational rules for managing the interface between imperfect algorithms and congested experts."}
{"id": "2601.22799", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.22799", "abs": "https://arxiv.org/abs/2601.22799", "authors": ["Antoine Godichon-Baggioni", "Gabriel Lang", "Sylvain Le Corff", "Julien Stoehr", "Sobihan Surendran"], "title": "Convergence of Multi-Level Markov Chain Monte Carlo Adaptive Stochastic Gradient Algorithms", "comment": null, "summary": "Stochastic optimization in learning and inference often relies on Markov chain Monte Carlo (MCMC) to approximate gradients when exact computation is intractable. However, finite-time MCMC estimators are biased, and reducing this bias typically comes at a higher computational cost. We propose a multilevel Monte Carlo gradient estimator whose bias decays as $O(T_{n}^{-1} )$ while its expected computational cost grows only as $O(log T_n )$, where $T_n$ is the maximal truncation level at iteration n. Building on this approach, we introduce a multilevel MCMC framework for adaptive stochastic gradient methods, leading to new multilevel variants of Adagrad and AMSGrad algorithms. Under conditions controlling the estimator bias and its second and third moments, we establish a convergence rate of order $O(n^{-1/2} )$ up to logarithmic factors. Finally, we illustrate these results on Importance-Weighted Autoencoders trained with the proposed multilevel adaptive methods."}
{"id": "2601.22272", "categories": ["hep-lat", "hep-ph", "nucl-th"], "pdf": "https://arxiv.org/pdf/2601.22272", "abs": "https://arxiv.org/abs/2601.22272", "authors": ["William Detmold", "Anthony V. Grebe", "Daniel C. Hackett", "Marc Illa", "Robert J. Perry", "Phiala E. Shanahan", "Michael L. Wagman"], "title": "Excited-state uncertainties in lattice-QCD calculations of multi-hadron systems", "comment": null, "summary": "Excited-state effects lead to hard-to-quantify systematic uncertainties in lattice quantum chromodynamics (LQCD) spectroscopy calculations when computationally accessible imaginary times are smaller than inverse excitation gaps, as often arises for multi-hadron systems with signal-to-noise problems. Lanczos residual bounds address this by providing two-sided constraints on energies that do not require assumptions beyond Hermiticity, but often give very conservative systematic uncertainty estimates. Here, a more-constraining set of gap bounds is introduced for hadron spectroscopy. These bounds provide tighter constraints whose validity requires an explicit assumption about an energy gap. Exactly solvable lattice field theory correlators are used to test the utility of residual and gap bounds at finite and infinite statistics. Two-sided bounds and other analysis methods are then applied to a high-statistics LQCD calculation of nucleon-nucleon scattering at $m_π\\sim 800$ MeV. Generalized eigenvalue problem (GEVP) and Lanczos energy estimators are compatible when applied to the same correlator data, but analyses including different interpolating operators show statistically significant inconsistencies. However, two-sided bounds from all operators are consistent. Under the assumption that the number of energy levels below $NΔ$ and $ΔΔ$ thresholds is the same as for non-interacting nucleons, gap bounds are sufficient to constrain nucleon-nucleon scattering amplitudes at phenomenologically relevant precision. Lanczos methods further reveal that energy-eigenstate estimates from previously studied asymmetric correlators have not converged over accessible imaginary times. Nevertheless, data-driven examples demonstrate why assumptions are required to draw conclusions about the natures of two-nucleon ground states at these masses."}
{"id": "2601.22188", "categories": ["physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22188", "abs": "https://arxiv.org/abs/2601.22188", "authors": ["Jonathon Sendall"], "title": "The Beta-Bound: Drift constraints for Gated Quantum Probabilities", "comment": "18 pages", "summary": "Quantum mechanics provides extraordinarily accurate probabilistic predictions, yet the framework remains silent on what distinguishes quantum systems from definite measurement outcomes. This paper develops a measurement-theoretic framework for projective gating. The central object is the $β$-bound, an inequality that controls how much probability assignments can drift when gating and measurement fail to commute. For a density operator $ρ$, projector $F$, and effect $E$, with gate-passage probability $s = {\\rm Tr}(ρF)$ and commutator norm $\\varepsilon = \\|[F, E]\\|$, the symmetric partial-gating drift satisfies $|Δp_F(E)| \\leq 2 \\sqrt{(1 - s)/s} \\cdot \\varepsilon$. The constant 2 is sharp. We introduce two diagnostic quantities: the coherence witness $W(ρ, F) = \\|F ρ(I - F)\\|_1$, measuring cross-boundary coherence, and the record fidelity gap $Δ_T(ρ_F, R)$, measuring expectation-value change under symmetrisation. Three experimental vignettes demonstrate falsifiability: Hong--Ou--Mandel interferometry, atomic energy-basis dephasing, and decoherence-induced classicality. The framework is operational and interpretation-neutral, compatible with Everettian, Bohmian, QBist, and collapse approaches. It provides quantitative structure that any interpretation must accommodate, along with a template for experimental tests."}
{"id": "2601.22746", "categories": ["cs.ET", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22746", "abs": "https://arxiv.org/abs/2601.22746", "authors": ["Pingping Liu", "Jiamiao Liu", "Zijian Zhang", "Hao Miao", "Qi Jiang", "Qingliang Li", "Qiuzhan Zhou", "Irwin King"], "title": "UrbanMoE: A Sparse Multi-Modal Mixture-of-Experts Framework for Multi-Task Urban Region Profiling", "comment": "12 pages, 6 figures, 5tables, Proceedings of the ACM Web Conference 2026 (WWW '26), April 13--17, 2026, Dubai, United Arab Emirates", "summary": "Urban region profiling, the task of characterizing geographical areas, is crucial for urban planning and resource allocation. However, existing research in this domain faces two significant limitations. First, most methods are confined to single-task prediction, failing to capture the interconnected, multi-faceted nature of urban environments where numerous indicators are deeply correlated. Second, the field lacks a standardized experimental benchmark, which severely impedes fair comparison and reproducible progress. To address these challenges, we first establish a comprehensive benchmark for multi-task urban region profiling, featuring multi-modal features and a diverse set of strong baselines to ensure a fair and rigorous evaluation environment. Concurrently, we propose UrbanMoE, the first sparse multi-modal, multi-expert framework specifically architected to solve the multi-task challenge. Leveraging a sparse Mixture-of-Experts architecture, it dynamically routes multi-modal features to specialized sub-networks, enabling the simultaneous prediction of diverse urban indicators. We conduct extensive experiments on three real-world datasets within our benchmark, where UrbanMoE consistently demonstrates superior performance over all baselines. Further in-depth analysis validates the efficacy and efficiency of our approach, setting a new state-of-the-art and providing the community with a valuable tool for future research in urban analytics"}
{"id": "2601.22330", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.22330", "abs": "https://arxiv.org/abs/2601.22330", "authors": ["Sarah A. Sanchez", "Hamish Gibbs", "Takahiro Yabe", "Daniel T. O'Brien", "Esteban Moro"], "title": "Correcting temporal bias in mobility data using time-use surveys", "comment": null, "summary": "GPS mobility data is a valuable source of behavioral measurement which is subject to systematic biases including the over- or under-representation of demographic groups, and variations in the quality of location sampling across time. In this paper, we address the challenge of temporal bias in mobility data, which can skew the representation of mobility behaviors due to the event-based nature of location data sampling. We use the American Time Use Survey (ATUS) to assess the accuracy of a place-based measure of economic segregation drawn from large-scale mobility data across 11 U.S. cities. We show that comparisons with high quality time use surveys such as the ATUS can validate behavioral insights from mobility data, while quantifying uncertainty and highlighting areas of relative instability in analytical findings. We also propose a temporal re-weighting method that can complement existing bias-mitigation techniques to improve the accuracy of conclusions drawn from GPS-based mobility data."}
{"id": "2601.22294", "categories": ["math.OC", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22294", "abs": "https://arxiv.org/abs/2601.22294", "authors": ["Serhii Kryhin", "Tatiana Mouzykantskii", "Vivishek Sudhir"], "title": "Forecasting in the presence of scale-free noise", "comment": "6 pages, 1 figure, 8 sections of Supplementary Information", "summary": "The extraction of signals from noise is a common problem in all areas of science and engineering. A particularly useful version is that of forecasting: determining a causal filter that estimates a future value of a hidden process from past observations. Current techniques for deriving the filter require that the noise be well described by rational power spectra. However, scale-free noises, whose spectra scale as a non-integer power of frequency, are ubiquitous in practice. We establish a method, together with performance guarantees, that solves the forecasting problem in the presence of scale-free noise. Via the duality between estimation and control, our technique can be used to design control for distributed systems. These results will have wide-ranging applications in neuroscience, finance, fluid dynamics, and quantum measurements."}
{"id": "2601.22349", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.22349", "abs": "https://arxiv.org/abs/2601.22349", "authors": ["Andreas Habring", "Martin Zach"], "title": "Forward-KL Convergence of Time-Inhomogeneous Langevin Diffusions", "comment": null, "summary": "Many practical samplers rely on time-dependent drifts -- often induced by annealing or tempering schedules -- to improve exploration and stability. This motivates a unified non-asymptotic analysis of the corresponding Langevin diffusions and their discretizations. We provide a convergence analysis that includes non-asymptotic bounds for the continuous-time diffusion and its Euler--Maruyama discretization in the forward-Kullback--Leibler divergence under a single set of abstract conditions on the time-dependent drift. The results apply to many practically-relevant annealing schemes, including geometric tempering and annealed Langevin sampling. In addition, we provide numerical experiments comparing the annealing schemes covered by our theory in low- and high-dimensional settings."}
{"id": "2601.22592", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22592", "abs": "https://arxiv.org/abs/2601.22592", "authors": ["Zhen Qi", "Yuqian Zhang"], "title": "Quadratic robust methods for causal mediation analysis", "comment": null, "summary": "Estimating natural effects is a core task in causal mediation analysis. Existing triply robust (TR) frameworks (Tchetgen Tchetgen & Shpitser 2012) and their extensions have been developed to estimate the natural effects. In this work, we introduce a new quadruply robust (QR) framework that enlarges the model class for unbiased identification. We study two modeling strategies. The first is a nonparametric modeling approach, under which we propose a general QR estimator that supports the use of machine learning methods for nuisance estimation. We also study high-dimensional settings, where the dimensions of covariates and mediators may both be large. In these settings, we adopt a parametric modeling strategy and develop a model quadruply robust (MQR) estimator to limit the impact of model misspecification. Simulation studies and a real data application demonstrate the finite-sample performance of the proposed methods."}
{"id": "2601.22253", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22253", "abs": "https://arxiv.org/abs/2601.22253", "authors": ["Katherine Muñoz-Mellado", "Daniel Uzcátegui-Contreras", "Antonio Guerra", "Aldo Delgado", "Dardo Goyeneche"], "title": "Entanglement and discord classification via deep learning", "comment": null, "summary": "In this work, we propose a deep learning-based approach for quantum entanglement and discord classification using convolutional autoencoders. We train models to distinguish entangled from separable bipartite states for $d \\times d$ systems with local dimension $d$ ranging from two to seven, which enables identification of bound and free entanglement. Through extensive numerical simulations across various quantum state families, we demonstrate that our model achieves high classification accuracy. Furthermore, we leverage the learned representations to generate samples of bound entangled states, the rarest form of entanglement and notoriously difficult to construct analytically. We separately train the same convolutional autoencoders architecture for detecting the presence of quantum discord and show that the model also exhibits high accuracy while requiring significantly less training time."}
{"id": "2601.22865", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22865", "abs": "https://arxiv.org/abs/2601.22865", "authors": ["Tanay Raghunandan Srinivasa", "Vivek Deulkar", "Jia Bhargava", "Mohammad Hajiesmaili", "Prashant Shenoy"], "title": "Degradation-Aware Frequency Regulation of a Heterogeneous Battery Fleet via Reinforcement Learning", "comment": "11 pages, 2 figures", "summary": "Battery energy storage systems are increasingly deployed as fast-responding resources for grid balancing services such as frequency regulation and for mitigating renewable generation uncertainty. However, repeated charging and discharging induces cycling degradation and reduces battery lifetime. This paper studies the real-time scheduling of a heterogeneous battery fleet that collectively tracks a stochastic balancing signal subject to per-battery ramp-rate and capacity constraints, while minimizing long-term cycling degradation.\n  Cycling degradation is fundamentally path-dependent: it is determined by charge-discharge cycles formed by the state-of-charge (SoC) trajectory and is commonly quantified via rainflow cycle counting. This non-Markovian structure makes it difficult to express degradation as an additive per-time-step cost, complicating classical dynamic programming approaches. We address this challenge by formulating the fleet scheduling problem as a Markov decision process (MDP) with constrained action space and designing a dense proxy reward that provides informative feedback at each time step while remaining aligned with long-term cycle-depth reduction.\n  To scale learning to large state-action spaces induced by fine-grained SoC discretization and asymmetric per-battery constraints, we develop a function-approximation reinforcement learning method using an Extreme Learning Machine (ELM) as a random nonlinear feature map combined with linear temporal-difference learning. We evaluate the proposed approach on a toy Markovian signal model and on a Markovian model trained from real-world regulation signal traces obtained from the University of Delaware, and demonstrate consistent reductions in cycle-depth occurrence and degradation metrics compared to baseline scheduling policies."}
{"id": "2601.22348", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22348", "abs": "https://arxiv.org/abs/2601.22348", "authors": ["Naoya Kumagai", "Kenshiro Oguri"], "title": "Square Root-Factorized Covariance Steering", "comment": "8 pages, 5 figures. Under review", "summary": "Covariance steering (CS) synthesizes a control policy which drives the state's mean and covariance matrix towards desired values. Offering tractable computation of a closed-loop policy which can obey chance constraints in uncertain environments, application to many real-world control problems have been proposed. We consider the chance-constrained, discrete-time, linear time-varying CS with Gaussian noise. The contribution of this paper is a novel solution method for this problem, explicitly writing the propagation equations of the Cholesky factor of the state covariance matrix by using the QR decomposition. The use of the square-root form of covariance matrices brings two key benefits over other existing methods: (i) computational scalability and (ii) numerical reliability. (i) Compared to solution methods that require large block matrix formulations, the proposed method scales better with the growth in horizon length, shows better optimality, and uses memoryless state feedback. (ii) Compared to another class of methods that explicitly define the covariance matrix as variables, the proposed method allows flexible cost formulations and shows better numerical reliability when uncertainty terms are smaller than the mean. On the other hand, these benefits come with a minor drawback: the propagation equation of covariance square roots is non-convex, necessitating sequential convex programming to solve. However, this paper proves the global optimality of the proposed approach for CS without chance constraints. When chance constraints are present, the existing optimal CS formulation is also non-convex, and we prove that the proposed approach shares the same local minima. We verify the mathematical arguments via extensive numerical simulations."}
{"id": "2601.22834", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.22834", "abs": "https://arxiv.org/abs/2601.22834", "authors": ["Louis Allain", "Sébastien Da Veiga", "Brian Staber"], "title": "Asymmetric conformal prediction with penalized kernel sum-of-squares", "comment": null, "summary": "Conformal prediction (CP) is a distribution-free method to construct reliable prediction intervals that has gained significant attention in recent years. Despite its success and various proposed extensions, a significant practical feature which has been overlooked in previous research is the potential skewed nature of the noise, or of the residuals when the predictive model exhibits bias. In this work, we leverage recent developments in CP to propose a new asymmetric procedure that bridges the gap between skewed and non-skewed noise distributions, while still maintaining adaptivity of the prediction intervals. We introduce a new statistical learning problem to construct adaptive and asymmetric prediction bands, with a unique feature based on a penalty which promotes symmetry: when its intensity varies, the intervals smoothly change from symmetric to asymmetric ones. This learning problem is based on reproducing kernel Hilbert spaces and the recently introduced kernel sum-of-squares framework. First, we establish representer theorems to make our problem tractable in practice, and derive dual formulations which are essential for scalability to larger datasets. Second, the intensity of the penalty is chosen using a novel data-driven method which automatically identifies the symmetric nature of the noise. We show that consenting to some asymmetry can let the learned prediction bands better adapt to small sample regimes or biased predictive models."}
{"id": "2601.22273", "categories": ["hep-lat", "hep-ph", "nucl-th"], "pdf": "https://arxiv.org/pdf/2601.22273", "abs": "https://arxiv.org/abs/2601.22273", "authors": ["William Detmold", "Anthony V. Grebe", "Daniel C. Hackett", "Marc Illa", "Robert J. Perry", "Phiala E. Shanahan", "Michael L. Wagman"], "title": "Excited-state uncertainties in lattice-QCD calculations of hadron masses and scattering phase shifts", "comment": null, "summary": "Lattice QCD has historically produced energy results interpretable as either estimates relying on implicit assumptions about asymptotic behavior or one-sided upper bounds. New Lanczos methods providing two-sided bounds with less-restrictive assumptions are introduced and quantified in a high-statistics calculation with unphysical quark masses. Two-sided bounds without spectral assumptions provide sub-percent constraints on the nucleon mass. Other bounds, which assume all states in a given energy window are resolved, provide meaningful two-sided constraints on nucleon-nucleon scattering phase shifts."}
{"id": "2601.22974", "categories": ["cs.ET", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.22974", "abs": "https://arxiv.org/abs/2601.22974", "authors": ["XiaoJie Zhang", "JianHan Wu", "Xiaoyang Qu", "Jianzong Wang"], "title": "MiTa: A Hierarchical Multi-Agent Collaboration Framework with Memory-integrated and Task Allocation", "comment": "Accepted to 2026 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP 2026)", "summary": "Recent advances in large language models (LLMs) have substantially accelerated the development of embodied agents. LLM-based multi-agent systems mitigate the inefficiency of single agents in complex tasks. However, they still suffer from issues such as memory inconsistency and agent behavioral conflicts. To address these challenges, we propose MiTa, a hierarchical memory-integrated task allocative framework to enhance collaborative efficiency. MiTa organizes agents into a manager-member hierarchy, where the manager incorporates additional allocation and summary modules that enable (1) global task allocation and (2) episodic memory integration. The allocation module enables the manager to allocate tasks from a global perspective, thereby avoiding potential inter-agent conflicts. The summary module, triggered by task progress updates, performs episodic memory integration by condensing recent collaboration history into a concise summary that preserves long-horizon context. By combining task allocation with episodic memory, MiTa attains a clearer understanding of the task and facilitates globally consistent task distribution. Experimental results confirm that MiTa achieves superior efficiency and adaptability in complex multi-agent cooperation over strong baseline methods."}
{"id": "2601.22389", "categories": ["physics.soc-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22389", "abs": "https://arxiv.org/abs/2601.22389", "authors": ["Bruce Stephenson", "Robin Macomber"], "title": "Convergent Discovery of Critical Phenomena Mathematics Across Disciplines: A Cross-Domain Analysis", "comment": "17 pages, no figures, plain-language summary in Appendix B", "summary": "Techniques for detecting critical phenomena -- phase transitions where correlation length diverges and small perturbations have large effects -- have been developed across at least eight fields of application over nine decades. We document this convergence pattern. The physicist's correlation length $ξ$, the cardiologist's DFA scaling exponent $α$, the financial analyst's Hurst exponent $H$, and the machine learning engineer's spectral radius $χ$ all measure correlation decay rate, detecting the same critical signatures under different notation. Citation analysis reveals minimal cross-domain awareness during the formative period (1987--2010): researchers in biomedicine, finance, machine learning, power systems, and traffic flow developed equivalent techniques independently, each with distinct notation and terminology. We present Metatron Dynamics, a framework derived from distributed systems engineering, as a candidate ninth independent discovery -- strengthening the convergence pattern while acknowledging that as authors of both the framework and this analysis, external validation would strengthen this claim. Correspondence testing on the 2D Ising model confirms that measures from multiple frameworks correctly identify the critical regime at $T_c = 2.269$. We argue that repeated independent discovery establishes criticality mathematics as fundamental public knowledge, with implications for cross-disciplinary education and research accessibility. Because these findings affect fields beyond mathematics and physics, we include a plain-language summary in Appendix B for non-specialist readers."}
{"id": "2601.22700", "categories": ["nlin.AO"], "pdf": "https://arxiv.org/pdf/2601.22700", "abs": "https://arxiv.org/abs/2601.22700", "authors": ["Tuhin Mahanty", "Ayushi Saxena", "Sangeeta Rani Ujjwal"], "title": "Slow driving induced multistability and remote synchronization in chaotic Chua's circuit", "comment": "14 pages, 19 figures", "summary": "We study the response of Chua's circuit driven by a chaotic signal of variable time-scale. We observe that when the frequency of the drive is significantly lower than that of the response and the driving strength is above a threshold, the Chua's circuit exhibits multiple stable attractors. The features of the attractors change as the driving strength ε increases, for instance the attractors are double-scroll at low ε and are single-scroll when ε is high. We also investigate generalized synchronization(GS) between the drive and the response systems by employing the auxiliary system approach. When the drive is much slower than the response, we observe different scenarios of remote synchronization(RS) between response and auxiliary units. In addition to complete synchrony between response and auxiliary systems indicating GS between drive and response, we notice that the response and auxiliary units can be lag synchronized and can also have correlated trajectories indicating novel forms of RS. The slow drive can induce multistability between these RS states which disappears as the frequency of drive increases and become equivalent to the response Chua's ciruit."}
{"id": "2601.22235", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22235", "abs": "https://arxiv.org/abs/2601.22235", "authors": ["Gianluca Peri", "Lorenzo Buffoni", "Giacomo Chiti", "Duccio Fanelli", "Raffaele Marino", "Andrea Nocentini", "Pier Paolo Panti"], "title": "Smart Walkers in Discrete Space", "comment": null, "summary": "We study the statistical properties of trainable agents moving in discrete space. After introducing the mathematical framework, we first analyze the dynamics of two completely random walkers, mutually competing in a chaser-target interaction scheme. The statistics of the encounters is analytically obtained and the predictions tested versus numerical simulations. We then move forward to extend the baseline case to agents capable of learning and adapting to an external reward signal, using reinforcement learning. Smart walkers morph the statistics of the encounter, to maximize their cumulated reward, as confirmed by combined numerical and analytical insights. More interestingly, configuration entropy proves a reliable proxy to gauge the acquired ability of the agents to cope with the assigned task when no other information about them (i.e. reward signal, policy, etc) is present. We further test the proposed measure of learned skills by operating the Stockfish chess engine against a quasi-random untrained opponent. The obtained conclusions corroborate our claim."}
{"id": "2601.22560", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22560", "abs": "https://arxiv.org/abs/2601.22560", "authors": ["Zhiqi Sun", "Xiang Xu", "Yiwen Lin"], "title": "Inverse acoustic scattering for random obstacles with multi-frequency data", "comment": "The data and code used in this study are available from the corresponding author upon reasonable request", "summary": "We study an inverse random obstacle scattering problems in $\\mathbb{R}^2$ where the scatterer is formulated by a Gaussian process defined on the angular parameter domain. Equipped with a modified covariance function which is mathematically well-defined and physically consistent, the Gaussian process admits a parameterization via Karhunen--Loève (KL) expansion. Based on observed multi-frequency data, we develop a two-stage inversion method: the first stage reconstructs the baseline shape of the random scatterer and the second stage estimates the statistical characteristics of the boundary fluctuations, including KL eigenvalues and covariance hyperparameters. We further provide theoretical justifications for the modeling and inversion pipeline, covering well-definedness of the Gaussian-process model, convergence for the two-stage procedure and a brief discussion on uniqueness. Numerical experiments demonstrate stable recovery of both geometric and statistical information for obstacles with simple and more complex shapes."}
{"id": "2601.22717", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22717", "abs": "https://arxiv.org/abs/2601.22717", "authors": ["Laura Fuentes-Vicente", "Mathieu Even", "Gaelle Dormion", "Julie Josse", "Antoine Chambaz"], "title": "Policy learning under constraint: Maximizing a primary outcome while controlling an adverse event", "comment": null, "summary": "A medical policy aims to support decision-making by mapping patient characteristics to individualized treatment recommendations. Standard approaches typically optimize a single outcome criterion. For example, recommending treatment according to the sign of the Conditional Average Treatment Effect (CATE) maximizes the policy \"value\" by exploiting treatment effect heterogeneity. This point of view shifts policy learning towards the challenge of learning a reliable CATE estimator. However, in multi-outcome settings, such strategies ignore the risk of adverse events, despite their relevance. PLUC (Policy Learning Under Constraint) addresses this challenges by learning an estimator of the CATE that yields smoothed policies controlling the probability of an adverse event in observational settings. Inspired by insights from EP-learning, PLUC involves the optimization of strongly convex Lagrangian criteria over a convex hull of functions. Its alternating procedure iteratively applies the Frank-Wolfe algorithm to minimize the current criterion, then performs a targeting step that updates the criterion so that its evaluations at previously visited landmarks become targeted estimators of the corresponding theoretical quantities. An R package PLUC-R provides a practical implementation. We illustrate PLUC's performance through a series of numerical experiments."}
{"id": "2601.22258", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22258", "abs": "https://arxiv.org/abs/2601.22258", "authors": ["Dušan Popov"], "title": "Some properties of coherent states with singular complex matrix argument", "comment": "27 pages, No figures", "summary": "In the paper our aim was to study the properties of a new version of coherent states whose argument is a linear combination of two special singular square 2 x 2 matrix, having a single nonzero element, equal to 1, and two labeling complex variables as developing coefficients. We have shown that this new version of coherent states satisfies all the conditions imposed on coherent states, both of pure, as well as the mixed (thermal) states characterized by the density operator. As applications, we examined the connection between these coherent states and the notions of qubits and von Neuman entropy."}
{"id": "2601.22880", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22880", "abs": "https://arxiv.org/abs/2601.22880", "authors": ["Tanay Raghunandan Srinivasa", "Vivek Deulkar", "Aviruch Bhatia", "Vishal Garg"], "title": "Reinforcement Learning-Based Co-Design and Operation of Chiller and Thermal Energy Storage for Cost-Optimal HVAC Systems", "comment": "11 pages, 3 figures", "summary": "We study the joint operation and sizing of cooling infrastructure for commercial HVAC systems using reinforcement learning, with the objective of minimizing life-cycle cost over a 30-year horizon. The cooling system consists of a fixed-capacity electric chiller and a thermal energy storage (TES) unit, jointly operated to meet stochastic hourly cooling demands under time-varying electricity prices. The life-cycle cost accounts for both capital expenditure and discounted operating cost, including electricity consumption and maintenance. A key challenge arises from the strong asymmetry in capital costs: increasing chiller capacity by one unit is far more expensive than an equivalent increase in TES capacity. As a result, identifying the right combination of chiller and TES sizes, while ensuring zero loss-of-cooling-load under optimal operation, is a non-trivial co-design problem. To address this, we formulate the chiller operation problem for a fixed infrastructure configuration as a finite-horizon Markov Decision Process (MDP), in which the control action is the chiller part-load ratio (PLR). The MDP is solved using a Deep Q Network (DQN) with a constrained action space. The learned DQN RL policy minimizes electricity cost over historical traces of cooling demand and electricity prices. For each candidate chiller-TES sizing configuration, the trained policy is evaluated. We then restrict attention to configurations that fully satisfy the cooling demand and perform a life-cycle cost minimization over this feasible set to identify the cost-optimal infrastructure design. Using this approach, we determine the optimal chiller and thermal energy storage capacities to be 700 and 1500, respectively."}
{"id": "2601.22370", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22370", "abs": "https://arxiv.org/abs/2601.22370", "authors": ["Nicholas Di", "Eric C. Chi", "Samy Wu Fung"], "title": "Operator Splitting with Hamilton-Jacobi-based Proximals", "comment": "27 pages, 5 Figures. arXiv admin note: substantial text overlap with arXiv:2509.07914", "summary": "Operator splitting algorithms are a cornerstone of modern first-order optimization, decomposing complex problems into simpler subproblems solved via proximal operators. However, most functions lack closed-form proximal operators, which has long restricted these methods to a narrow set of problems. Hamilton-Jacobi-based proximal operator (HJ-Prox) is a recent derivative-free Monte Carlo technique based on Hamilton-Jacobi PDE theory, that approximates proximal operators numerically. In this work, we introduce a unified framework for operator splitting via HJ-Prox, which allows for deployment of operator splitting even when functions are not proximable. We prove that replacing exact proximal steps with HJ-Prox in algorithms such as proximal point, proximal gradient descent, Douglas-Rachford splitting, Davis-Yin splitting, and primal-dual hybrid gradient preserves convergence guarantees under mild assumptions. Numerical experiments demonstrate HJ-Prox is competitive and effective on a wide variety of statistical learning tasks."}
{"id": "2601.22945", "categories": ["math.ST", "cs.CR", "econ.TH"], "pdf": "https://arxiv.org/pdf/2601.22945", "abs": "https://arxiv.org/abs/2601.22945", "authors": ["Joshua J Bon", "James Bailie", "Judith Rousseau", "Christian P Robert"], "title": "Persuasive Privacy", "comment": "17 pages", "summary": "We propose a novel framework for measuring privacy from a Bayesian game-theoretic perspective. This framework enables the creation of new, purpose-driven privacy definitions that are rigorously justified, while also allowing for the assessment of existing privacy guarantees through game theory. We show that pure and probabilistic differential privacy are special cases of our framework, and provide new interpretations of the post-processing inequality in this setting. Further, we demonstrate that privacy guarantees can be established for deterministic algorithms, which are overlooked by current privacy standards."}
{"id": "2601.23150", "categories": ["quant-ph", "cond-mat.str-el", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.23150", "abs": "https://arxiv.org/abs/2601.23150", "authors": ["J. M. Alcaine-Cuervo", "S. Pradhan", "E. Rico", "Z. Shi", "C. M. Wilson"], "title": "Compact U(1) Lattice Gauge Theory in Superconducting Circuits with Infinite-Dimensional Local Hilbert Spaces", "comment": "21 pages, 12 figures", "summary": "We propose a superconducting-circuit architecture that realizes a compact U(1) lattice gauge theory using the intrinsic infinite-dimensional Hilbert space of phase and charge variables. The gauge and matter fields are encoded directly in the degrees of freedom of the rotor variables associated with the circuit nodes, and Gauss's law emerges exactly from the conservation of local charge, without auxiliary stabilizers, penalty terms, or Hilbert-space truncation. A minimal gauge-matter coupling arises microscopically from Josephson nonlinearities, whereas the magnetic plaquette interaction is generated perturbatively via virtual matter excitations. Numerical diagonalization confirms the emergence of compact electrodynamics and coherent vortex excitations, underscoring the need for large local Hilbert spaces in the continuum regime. The required circuit parameters are within the current experimental capabilities. Our results establish superconducting circuits as a scalable, continuous-variable platform for analog quantum simulation of non-perturbative gauge dynamics."}
{"id": "2601.22459", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.22459", "abs": "https://arxiv.org/abs/2601.22459", "authors": ["Joan Hernàndez Tey", "Emanuele Cozzo"], "title": "Correlation-Based Diagnostics of Social Contagion Dynamics in Multiplex Networks", "comment": null, "summary": "Multiplex contagion dynamics display localization phenomena in which spreading activity concentrates on a subset of layers, as well as delocalized regimes where layers behave collectively. We investigate how these regimes are encoded in temporal correlations of node activity. By deriving a closed-form mean-field expression for node autocorrelations in a contact-based social contagion multiplex model and validating it through simulations, we show that lag-one autocorrelations act as sensitive indicators of both activation and localization transitions. Our results establish temporal correlations as lightweight, structure-agnostic probes of multiplex spreading dynamics, particularly valuable in partially observable systems."}
{"id": "2601.22840", "categories": ["cond-mat.stat-mech", "nlin.AO", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2601.22840", "abs": "https://arxiv.org/abs/2601.22840", "authors": ["Xin Wu", "Mingcheng Yang"], "title": "Synchronization and phase transition of two-dimensional self-rotating clock models", "comment": "7 pages, 6 figures", "summary": "We explore possible synchronization in two-dimensional (2D) locally coupled discrete-state oscillators under thermal fluctuations, using the self-rotating $q$-state clock model as a prototype. Large-scale Monte Carlo simulations reveal that for $q \\ge q_c$ (with $q_c = 5$), the system undergoes two-step Berezinskii-Kosterlitz-Thouless (BKT) transitions: first from a disordered phase to a critical synchronized phase, and then to a spatiotemporal pattern phase. The latter includes oscillatory droplet states that survive in finite systems and a thermodynamically stable spiral wave state. Notably, the synchronized phase features algebraically decaying spatial correlations, alongside divergent coherence time, thus realizing a continuous time crystal; while it vanishes when $q < q_c$. Mean-field theory supports the existence of the synchronized phase, but predicts a lower critical value $q_c^{MF} = 4$."}
{"id": "2601.22375", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22375", "abs": "https://arxiv.org/abs/2601.22375", "authors": ["Bruno Bertini"], "title": "Non-Equilibrium Quantum Many-Body Physics with Quantum Circuits", "comment": "49 pages, 6 figures", "summary": "These are the notes for the 4.5-hour course with the same title that I delivered in August 2025 at the Les Houches summer school ``Exact Solvability and Quantum Information''. In these notes I pedagogically introduce the setting of brickwork quantum circuits and show that it provides a useful framework to study non-equilibrium quantum many-body dynamics in the presence of local interactions. I first show that brickwork quantum circuits evolve quantum correlations in a way that is fundamentally similar to local Hamiltonians, and then present examples of brickwork quantum circuits where, surprisingly, one can compute exactly several relevant dynamical and spectral properties in the presence of non-trivial interactions."}
{"id": "2601.22280", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.22280", "abs": "https://arxiv.org/abs/2601.22280", "authors": ["Mayia A. Vranas", "Alejandro Ruiz", "Vikram Nagarajan", "Erik Lamb", "Gerald D. Morris", "Zahir Islam", "Christie Nelson", "Benjamin A. Frandsen", "James G. Analytis", "Alex Frano"], "title": "Anisotropic Kitaev Spin Glass in Li$_{2}$Ru$_{x}$Ir$_{1-x}$O$_{3}$", "comment": "10 pages, 6 figures", "summary": "Kitaev iridates have been proposed as candidates for realizing an elusive quantum spin liquid (QSL) state, in which strong spin-orbit coupling and bond-directional exchange generate a highly frustrated and entangled ground state. However, all physical systems proposed to host this ground state, including Li$_2$IrO$_3$, Na$_2$IrO$_3$, and RuCl$_3$, develop magnetic order at low temperatures due to competing interactions. Nonetheless, theoretical modeling of experimental data has shown that Kitaev interactions are still present, motivating the application of perturbations such as pressure, magnetic field, and chemical doping to drive the system into the QSL phase. Here we study $β$-Li$_{2}$Ru$_{x}$Ir$_{1-x}$O$_{3}$ with dilute levels of Ru, $x \\lesssim 10\\%$. Through a combination of magnetometry, resonant elastic X-ray scattering, ac-heat capacity, and muon spin relaxation/resonance, we show that weak magnetic disorder suppresses long-range antiferromagnetic order and stabilizes an anisotropic spin glass that retains key signatures of Kitaev exchange. This Kitaev spin glass shows pronounced directional anisotropy in its magnetic susceptibility and thermoremenant magnetization. These results demonstrate that dilute magnetic disorder can access an anisotropic Kitaev spin glass: a proximate phase that freezes the Kitaev frustration landscape. This could provide a new window into the degeneracy, anisotropy, and competing interactions underlying the Kitaev QSL."}
{"id": "2601.22587", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22587", "abs": "https://arxiv.org/abs/2601.22587", "authors": ["Rekha Khot", "Bishnu P. Lamichhane", "Ricardo Ruiz-Baier"], "title": "An ultra-weak three-field finite element formulation for the biharmonic and extended Fisher--Kolmogorov equations", "comment": null, "summary": "This paper discusses a so-called ultra-weak three-field formulation of the biharmonic problem where the solution, its gradient, and an additional Lagrange multiplier are the three unknowns. We establish the well-posedness of the problem using the abstract theory for saddle-point problems, and develop a conforming finite element scheme based on Raviart--Thomas discretisations of the two auxiliary variables. The well-posedness of the discrete formulation and the corresponding a priori error estimate are proved using a discrete inf-sup condition. We further extend the analysis to the time-dependent semilinear equation, namely extended Fisher--Kolmogorov equation. We present a few numerical examples to demonstrate the performance of our approach."}
{"id": "2601.22782", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22782", "abs": "https://arxiv.org/abs/2601.22782", "authors": ["Qishuo Yin", "Dylan S. Small"], "title": "Optimal Sample Splitting for Observational Studies", "comment": null, "summary": "In observational studies of treatment effects, estimates may be biased by unmeasured confounders, which can potentially affect the validity of the results. Understanding sensitivity to such biases helps assess how unmeasured confounding impacts credibility. The design of an observational study strongly influences its sensitivity to bias. Previous work has shown that the sensitivity to bias can be reduced by dividing a dataset into a planning sample and a larger analysis sample, where the planning sample guides design decisions. But the choice of what fraction of the data to put in the planning sample vs. the analysis sample was ad hoc. Here, we develop an approach to find the optimal fraction using plasmode datasets. We show that our method works well in high-dimensional outcome spaces. We apply our method to study the effects of exposure to second-hand smoke in children. The OptimalSampling R package implementing our method is available at GitHub."}
{"id": "2601.22283", "categories": ["quant-ph", "hep-ex", "physics.ins-det"], "pdf": "https://arxiv.org/pdf/2601.22283", "abs": "https://arxiv.org/abs/2601.22283", "authors": ["Giacomo Marocco", "David C. Moore", "Daniel Carney"], "title": "Three-dimensional squeezing of optically levitated nanospheres", "comment": "5 + 3 pages, 4 figures", "summary": "We propose a protocol to measure impulses beyond the standard quantum limit. The protocol reduces noise in all three spatial dimensions and consists of squeezing a mechanical system's state via a series of jumps in the frequency of the harmonic potential. We quantify how decoherence in a realistic system of an optically levitated, dielectric nanoparticle limits the ultimate sensitivity. We predict that $\\sim$10 dB of squeezing is achievable with current technology, enabling quantum-enhanced detection of weak impulses."}
{"id": "2601.23108", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.23108", "abs": "https://arxiv.org/abs/2601.23108", "authors": ["Finn Vehlhaber", "Mauro Salazar"], "title": "Energy Management Strategies for Electric Aircraft Charging Leveraging Active Landside Vehicle-to-Grid", "comment": null, "summary": "The deployment of medium-range battery electric aircraft is a promising pathway to improve the environmental footprint of air mobility. Yet such a deployment would be accompanied by significant electric power requirements at airports due to aircraft charging. Given the growing prevalence of electric vehicles and their bi-directional charging capabilities--so-called vehicle-to-grid (V2G)--we study energy buffer capabilities of parked electric vehicles to alleviate pressure on grid connections. To this end, we present energy management strategies for airports providing cost-optimal apron and landside V2G charge scheduling. Specifically, we first formulate the optimal energy management problem of joint aircraft charging and landside V2G coordination as a linear program, whereby we use partial differential equations to model the aggregated charging dynamics of the electric vehicle fleet. Second, we consider a shuttle flight network with a single hub of a large Dutch airline, real-world grid prices, and synthetic parking garage occupancy data to test our framework. Our results show that V2G at even a single airport can indeed reduce energy costs to charge the aircraft fleet: Compared to a baseline scenario without V2G, the proposed concept yields cost savings of up to 32%, depending on the schedule and amount of participating vehicles, and has other potential beneficial effects on the local power grid, e.g., the reduction of potential power peaks."}
{"id": "2601.22405", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22405", "abs": "https://arxiv.org/abs/2601.22405", "authors": ["Neilabh Banzal", "Jorge Cortés", "Sonia Martínez"], "title": "Visibility in Polygonal Environments with Holes: Finding Best Spots for Hiding and Surveillance", "comment": null, "summary": "Visibility plays an important role for decision making in cluttered, uncertain environments. This paper considers the problem of identifying optimal hiding spots for an agent against line-of-sight detection by an adversary whose location is unknown. We consider environments modeled as polygons with holes. We develop a set of mathematical tools for reasoning about visibility as a function of position and rely on non-smooth analysis to formally characterize the regularity properties of various visibility-based metrics. These metrics are non-smooth and non-convex, so off-the-shelf optimization algorithms can only guarantee convergence to Clarke critical points. To address this, the proposed Normalized Descent algorithm leverages the structure of non-smooth points in visibility problems and introduces randomness to escape saddle points. Our technical analysis allows for the non-monotonic decrease in the visibility metric and strengthens the algorithm guarantees, ensuring convergence to local minima with high probability. Simulations on two hide-and-seek scenarios showcase the effectiveness of the proposed approach."}
{"id": "2601.23124", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.23124", "abs": "https://arxiv.org/abs/2601.23124", "authors": ["Angel Reyero-Lobo", "Bertrand Thirion", "Pierre Neuvial"], "title": "Semi-knockoffs: a model-agnostic conditional independence testing method with finite-sample guarantees", "comment": null, "summary": "Conditional independence testing (CIT) is essential for reliable scientific discovery. It prevents spurious findings and enables controlled feature selection. Recent CIT methods have used machine learning (ML) models as surrogates of the underlying distribution. However, model-agnostic approaches require a train-test split, which reduces statistical power. We introduce Semi-knockoffs, a CIT method that can accommodate any pre-trained model, avoids this split, and provides valid p-values and false discovery rate (FDR) control for high-dimensional settings. Unlike methods that rely on the model-$X$ assumption (known input distribution), Semi-knockoffs only require conditional expectations for continuous variables. This makes the procedure less restrictive and more practical for machine learning integration. To ensure validity when estimating these expectations, we present two new theoretical results of independent interest: (i) stability for regularized models trained with a null feature and (ii) the double-robustness property."}
{"id": "2601.23061", "categories": ["physics.soc-ph", "physics.app-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.23061", "abs": "https://arxiv.org/abs/2601.23061", "authors": ["Francesca Santucci", "Giulio Cimini", "Tiziano Squartini"], "title": "Missing links prediction: comparing machine learning with physics-rooted approaches", "comment": "19 pages, 6 figures, 3 appendix figures", "summary": "An active research line within the broader field of network science is the one concerning link prediction. Close in scope to network reconstruction, link prediction targets specific connections with the aim of uncovering the missing ones, as well as predicting those most likely to emerge in the future, from the available information. In this paper, we consider two families of methods, i.e. those rooted in statistical physics and those based upon machine learning: the members of the first family identify missing links as the most probable non-observed ones, the probability coefficients being determined by solving maximum-entropy benchmarks over the accessible network structure; the members of the second family, instead, associate the presence of single edges to explanatory node-specific variables. Running likelihood-based models such as the Configuration Model, or one of its many fitness-based variants, in parallel with the Gradient Boosting Decision Tree algorithm reveals that the former's accuracy is comparable to (and sometimes slightly higher than) the latter's. Such a result confirms that white-box algorithms are viable competitors to the currently available black-box ones, being computationally faster and more interpretable than the latter."}
{"id": "2601.22874", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "nlin.AO", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.22874", "abs": "https://arxiv.org/abs/2601.22874", "authors": ["Alessandro Pignedoli", "Atreya Majumdar", "Karin Everschor-Sitte"], "title": "Leveraging Interactions for Efficient Swarm-Based Brownian Computing", "comment": "9 pages, 3 figures", "summary": "Drawing inspiration from swarm intelligence, we show that short-range attractive interactions between thermally driven Brownian quasiparticles enable energy-efficient optimization. As quasiparticles can be generated directly within a material, the swarm size can be adjusted with minimal energy overhead. Using an optimization task defined by a spatially varying temperature landscape, we quantitatively show that interacting swarms reliably identify global optima and significantly outperform non-interacting searchers within a well-defined regime of interaction strength and swarm size. This improvement arises from emergent cooperative behavior, where local interactions guide the swarm toward high-quality solutions without central coordination. To link our physical model to experimental realizations, we coarse-grain the quasiparticle dynamics onto a sensor lattice and generate trajectories emulating particle-tracking measurements. We further show that the interacting swarm adapts robustly to landscapes that evolve over time. These findings establish interacting Brownian quasiparticles as a physical platform for scalable and energy-efficient unconventional computing."}
{"id": "2601.22635", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22635", "abs": "https://arxiv.org/abs/2601.22635", "authors": ["Claudio Guarcello", "Alexander A. Dubkov", "Davide Valenti", "Bernardo Spagnolo"], "title": "Noise-Assisted Metastability: From Lévy Flights to Memristors, Quantum Escape, and Josephson-based Axion Searches", "comment": "23 pages, 11 figures", "summary": "Many-body and complex systems, both classical and quantum, often exhibit slow, nonlinear relaxation toward stationary states due to the presence of metastable configurations and environmental fluctuations. Nonlinear relaxation in a wide variety of natural systems proceeds through metastable states, which arise in condensed-matter physics as well as in fields ranging from cosmology and biology to high-energy physics. Moreover, noise-induced phenomena play a central role in shaping the dynamics of such systems far from equilibrium. This review develops a unifying perspective centered on noise-assisted stabilization and the statistical properties of metastable dynamics. We first discuss escape processes driven by Lévy flights in smooth metastable potentials, emphasizing the emergence of nonmonotonic residence-time behavior. We then connect these concepts to stochastic resistive switching in memristive devices, where noise-induced effects can enhance stability and reproducibility. We further examine driven dissipative quantum bistability, showing how the interplay between external driving and system-environment coupling reshapes escape pathways and lifetimes. Finally, we outline how switching-time statistics in current-biased Josephson junctions can provide an experimentally accessible strategy for axion detection, based on an axion-induced resonant-activation signature."}
{"id": "2601.22343", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.22343", "abs": "https://arxiv.org/abs/2601.22343", "authors": ["P. T. Bolokhova", "A. V. Syromyatnikov"], "title": "Field-induced transitions from incommensurate to commensurate phases in helical antiferromagnets", "comment": "12 pages, 2 figures", "summary": "Heisenberg antiferromagnet with an easy-plane anisotropy is discussed in which a magnetic spiral is induced by Dzyaloshinskii-Moriya interaction and/or frustration of the exchange coupling. The distortion of the spiral by small in-plane magnetic field is described analytically. It is found that the field can gradually change the vector of the magnetic structure ${\\bf k}_0$ and can produce transitions between phases with incommensurate and commensurate magnetic orderings when ${\\bf k}_0$ is close to ${\\bf g}/n$, where ${\\bf g}$ is a reciprocal lattice vector and $n$ is integer. Analytical expressions for critical fields are derived for $n=2$, 3, and 4. Application of the theory to the triangular-lattice compound $\\rm RbFe(MoO_4)_2$ is discussed alongside its potential applicability to other materials. As a by-product of the main consideration, model parameters are found which describe more accurately the full set of available experimental data suggested before for $\\rm RbFe(MoO_4)_2$."}
{"id": "2601.22605", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.22605", "abs": "https://arxiv.org/abs/2601.22605", "authors": ["Falai Chen", "Buyang Li", "Jiajie Li", "Rong Tang"], "title": "An inertial minimal-deformation-rate framework for shape optimization", "comment": "26 pages, 12 figures", "summary": "We propose a robust numerical framework for PDE-constrained shape optimization and Willmore-driven surface hole filling. To address two central challenges -- slow progress in flat energy landscapes, which can trigger premature stagnation at suboptimal configurations, and mesh deterioration during geometric evolution -- we couple a second-order inertial flow with a minimal-deformation-rate (MDR) mesh motion strategy. This coupling accelerates convergence while preserving mesh quality and thus avoids remeshing. To further enhance robustness for non-smooth or non-convex initial geometries, we incorporate surface-diffusion regularization within the Barrett-Garcke-N\"urnberg (BGN) framework. Moreover, we extend the inertial MDR methodology to Willmore-type surface hole filling, enabling high-order smooth reconstructions even from incompatible initial data. Numerical experiments demonstrate markedly faster convergence to lower original objective values, together with consistently superior mesh preservation throughout the evolution."}
{"id": "2601.22884", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.22884", "abs": "https://arxiv.org/abs/2601.22884", "authors": ["Ana Arribas-Gil", "Sara López-Pintado"], "title": "Depth-based estimation for multivariate functional data with phase variability", "comment": "34 pages, 11 figures, 6 tables", "summary": "In the context of multivariate functional data with individual phase variation, we develop a robust depth-based approach to estimate the main pattern function when cross-component time warping is also present. In particular, we consider the latent deformation model (Carroll and Müller, 2023) in which the different components of a multivariate functional variable are also time-distorted versions of a common template function. Rather than focusing on a particular functional depth measure, we discuss the necessary conditions on a depth function to be able to provide a consistent estimation of the central pattern, considering different model assumptions. We evaluate the method performance and its robustness against atypical observations and violations of the model assumptions through simulations, and illustrate its use on two real data sets."}
{"id": "2601.22286", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.22286", "abs": "https://arxiv.org/abs/2601.22286", "authors": ["Han Zheng", "Chia-Tung Chu", "Senrui Chen", "Argyris Giannisis Manes", "Su-un Lee", "Sisi Zhou", "Liang Jiang"], "title": "Efficient learning of logical noise from syndrome data", "comment": "13 + 42 pages, 5 figures", "summary": "Characterizing errors in quantum circuits is essential for device calibration, yet detecting rare error events requires a large number of samples. This challenge is particularly severe in calibrating fault-tolerant, error-corrected circuits, where logical error probabilities are suppressed to higher order relative to physical noise and are therefore difficult to calibrate through direct logical measurements. Recently, Wagner et al. [PRL 130, 200601 (2023)] showed that, for phenomenological Pauli noise models, the logical channel can instead be inferred from syndrome measurement data generated during error correction. Here, we extend this framework to realistic circuit-level noise models. From a unified code-theoretic perspective and spacetime code formalism, we derive necessary and sufficient conditions for learning the logical channel from syndrome data alone and explicitly characterize the learnable degrees of freedom of circuit-level Pauli faults. Using Fourier analysis and compressed sensing, we develop efficient estimators with provable guarantees on sample complexity and computational cost. We further present an end-to-end protocol and demonstrate its performance on several syndrome-extraction circuits, achieving orders-of-magnitude sample-complexity savings over direct logical benchmarking. Our results establish syndrome-based learning as a practical approach to characterizing the logical channel in fault-tolerant quantum devices."}
{"id": "2601.23160", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.23160", "abs": "https://arxiv.org/abs/2601.23160", "authors": ["Marko Nonhoff", "Mohammad Taher Al Torshan", "Matthias A. Müller"], "title": "Robust Control of Constrained Linear Systems using Online Convex Optimization and a Reference Governor", "comment": "Presented at 2024 IEEE 63rd Conference on Decision and Control (CDC)", "summary": "This article develops a control method for linear time-invariant systems subject to time-varying and a priori unknown cost functions, that satisfies state and input constraints, and is robust to exogenous disturbances. To this end, we combine the online convex optimization framework with a reference governor and a constraint tightening approach. The proposed framework guarantees recursive feasibility and robust constraint satisfaction. Its closed-loop performance is studied in terms of its dynamic regret, which is bounded linearly by the variation of the cost functions and the magnitude of the disturbances. The proposed method is illustrated by a numerical case study of a tracking control problem."}
{"id": "2601.22429", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22429", "abs": "https://arxiv.org/abs/2601.22429", "authors": ["Weijia Chen", "Jingtao Shi"], "title": "Leader-Follower Linear-Quadratic Stochastic Graphon Games", "comment": "27 pages", "summary": "This paper investigates leader-follower linear-quadratic stochastic graphon games, which consist of a single leader and a continuum of followers. The state equations of the followers interact through graphon coupling terms, with their diffusion coefficients depending on the state, the graphon aggregation term, and the control variables. The diffusion term of the leader's state equation depends on its state and control variables. Within this framework, a hierarchical decision-making structure is established: for any strategy adopted by the leader, the followers compete to attain a Nash equilibrium, while the leader optimizes its own cost functional by anticipating the followers' equilibrium response. This work develops a rigorous mathematical model for the game, proves the existence and uniqueness of solutions to the system's state equations under admissible control sets, and constructs a Stackelberg-Nash equilibrium for the continuum follower game. By employing the continuity method, we establish the existence, uniqueness, and stability of solutions to the associated forward-backward stochastic differential equation with a graphon aggregation term."}
{"id": "2601.23077", "categories": ["physics.soc-ph", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2601.23077", "abs": "https://arxiv.org/abs/2601.23077", "authors": ["Jose de Jesus Bernal-Alvarado", "David Delepine"], "title": "A Universal Convolution-Based Pre-processor to Correct the Prevalence-Incidence Gap in SIR, SEIR, and SIRS Modeling", "comment": "7 paginas, 4 figuras", "summary": "Traditional compartmental models, including SIR, SEIR, and SIRS frameworks, remain the analytical standard for epidemic forecasting. However, real-world data validation consistently reveals significant predictive failures, such as peak underestimations of up to 50%. This research identifies a persistent fundamental methodological error: the calibration of prevalence-based (stock) models using raw daily incidence (flow) data without proper transformation. We propose an integrated protocol utilizing an exponentially weighted convolution to reconstruct active cases from reported incidence: $I(t) \\approx \\frac{1}{p} \\int_{0}^{t} NDC(τ) e^{-γ(t-τ)} dτ$. This transformation accounts for the recovery rate $γ$ and the ascertainment rate $p$. We demonstrate that increasing structural complexity, such as adding latency (SEIR) or waning immunity (SIRS), fails to resolve the incidence-prevalence gap. Simulation results show that without the proposed universal pre-processor, these advanced models inherit the systematic biases of misaligned data types, leading to significant errors in estimating latent periods and the \"heavy tail\" of endemicity. The proposed convolution transformation must serve as a universal prerequisite for any compartmental framework, bridging the gap between clinical reporting and mechanistic modeling."}
{"id": "2601.22733", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22733", "abs": "https://arxiv.org/abs/2601.22733", "authors": ["Horst-Holger Boltz", "Thomas Ihle"], "title": "Spectral insights into active matter: Exceptional Points and the Mathieu equation", "comment": "13 pages, 4 figures", "summary": "We show that recent numerical findings of universal scaling relations in systems of noisy, aligning self-propelled particles by Kürsten [Kürsten, arXiv:2402.18711v2 [cond-mat.soft] (2025)] can robustly be explained by perturbation theory and known results for the Mathieu equation with purely imaginary parameter. In particular, we highlight the significance of a cascade of exceptional points that leads to non-trivial fractional scaling exponents in the singular-perturbation limit of high activity. Crucially, these features are rooted in the Fokker-Planck operator corresponding to free self-propulsion. This can be viewed as a dynamical phase transition in the dynamics of noisy active matter."}
{"id": "2601.22463", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.22463", "abs": "https://arxiv.org/abs/2601.22463", "authors": ["Tatsuya Kaneko", "Ryota Mizuno", "Shu Kamiyama", "Hideo Miyamoto", "Masayuki Ochi"], "title": "Electronic band structure, phonon dispersion, and magnetic triple-q state in GdGaI", "comment": "12 pages, 13 figures", "summary": "We theoretically investigate the physical properties of the magnetic van der Waals material GdGaI. Using first-principles calculations, we compute the phonon dispersion of GdGaI and show no imaginary phonons, suggesting that phonon-driven phase transitions are unlikely to occur in GdGaI. Our band calculation reveals that the electronic bands near the Fermi energy are composed of Gd 5d and Ga 4p orbitals. We construct a tight-binding model that incorporates the Gd 5d and Ga 4p orbitals to investigate the magnetic structure. We introduce Kondo coupling between electrons in Gd 5d orbitals and localized spins in Gd 4f orbitals and present the modified band structure when localized spins form a magnetic order characterized by three q vectors that connect the valence and conduction bands. We discuss the origin of the spin order based on the Ruderman-Kittel-Kasuya-Yosida mechanism and suggest that Coulomb interactions acting on electrons near the Fermi level can contribute to the ordering of localized spins."}
{"id": "2601.22687", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22687", "abs": "https://arxiv.org/abs/2601.22687", "authors": ["Yuki Yonekura", "Daiki Iwade", "Shun Sato", "Takayasu Matsuo"], "title": "A Mathematical Analysis of a Smooth-Convex-Concave Splitting Scheme for the Swift--Hohenberg Equation", "comment": null, "summary": "The Swift--Hohenberg equation is a widely studied fourth-order model, originally proposed to describe hydrodynamic fluctuations. It admits an energy-dissipation law and, under suitable assumptions, bounded solutions. Many structure-preserving numerical schemes have been proposed to retain such properties; however, existing approaches are often fully implicit and therefore computationally expensive. We introduce a simple design principle for constructing dissipation-preserving finite difference schemes and apply it to the Swift--Hohenberg equation in three spatial dimensions. Our analysis relies on discrete inequalities for the underlying energy, assuming a Lipschitz continuous gradient and either convexity or $μ$-strong convexity of the relevant terms. The resulting method is linearly implicit, yet it preserves the original energy-dissipation law, guarantees unique solvability, ensures boundedness of numerical solutions, and admits an a priori error estimate, provided that the time step is sufficiently small. To the best of our knowledge, this is the first linearly implicit finite difference scheme for the Swift--Hohenberg equation for which all of these properties are established."}
{"id": "2601.22971", "categories": ["stat.ME", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2601.22971", "abs": "https://arxiv.org/abs/2601.22971", "authors": ["Julian Wäsche", "Romina Ludwig", "Irmela Jeremias", "Christiane Fuchs"], "title": "Dynamic modelling and evaluation of preclinical trials in acute leukaemia", "comment": null, "summary": "Dynamic models are widely used to mathematically describe biological phenomena that evolve over time. One important area of application is leukaemia research, where leukaemia cells are genetically modified in preclinical studies to explore new therapeutic targets for reducing leukaemic burden. In advanced experiments, these studies are often conducted in mice and generate time-resolved data, the analysis of which may reveal growth-inhibiting effects of the investigated gene modifications. However, the experimental data is often times evaluated using statistical tests which compare measurements from only two different time points. This approach does not only reduce the time series to two instances but also neglects biological knowledge about cell mechanisms. Such knowledge, translated into mathematical models, expands the power to investigate and understand effects of modifications on underlying mechanisms based on experimental data. We utilise two population growth models -- an exponential and a logistic growth model -- to capture cell dynamics over the whole experimental time horizon and to consider all measurement times jointly. This approach enables us to derive modification effects from estimated model parameters. We demonstrate that the exponential growth model recognises simulated scenarios more reliably than the other candidate model and than a statistical test. Moreover, we apply the population growth models to evaluate the efficacy of candidate gene knockouts in patient-derived xenograft (PDX) models of acute leukaemia."}
{"id": "2601.22291", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22291", "abs": "https://arxiv.org/abs/2601.22291", "authors": ["Suchitra Krishnaswamy", "Dhrithi Maria", "Laura Ares", "Lorenzo M. Procopio", "Tim J. Bartley", "Jan Sperling"], "title": "Local-oscillator-agnostic squeezing detection", "comment": null, "summary": "We address the problem of measuring nonclassicality in continuous-variable bosonic systems without having access to a known reference signal. To this end, we construct broader classes of criteria for nonclassicality which allow us to investigate quantum phenomena regardless of the quantumness of selected subsystems. Such witnesses are based on the notion of partial normal ordering. This approach is applied to balanced homodyne detection using arbitrary, potentially nonclassical local oscillator states, yet only revealing the probed signal's quantumness. Our framework is compared to standard techniques, and the robustness and advanced sensitivity of our approach is shown. Therefore, a widely applicable framework, well-suited for applications in quantum metrology and quantum information, is derived to assess the quantum features of a photonic system when a well-defined coherent laser as a reference state is not available in the physical domain under study."}
{"id": "2601.22294", "categories": ["math.OC", "eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22294", "abs": "https://arxiv.org/abs/2601.22294", "authors": ["Serhii Kryhin", "Tatiana Mouzykantskii", "Vivishek Sudhir"], "title": "Forecasting in the presence of scale-free noise", "comment": "6 pages, 1 figure, 8 sections of Supplementary Information", "summary": "The extraction of signals from noise is a common problem in all areas of science and engineering. A particularly useful version is that of forecasting: determining a causal filter that estimates a future value of a hidden process from past observations. Current techniques for deriving the filter require that the noise be well described by rational power spectra. However, scale-free noises, whose spectra scale as a non-integer power of frequency, are ubiquitous in practice. We establish a method, together with performance guarantees, that solves the forecasting problem in the presence of scale-free noise. Via the duality between estimation and control, our technique can be used to design control for distributed systems. These results will have wide-ranging applications in neuroscience, finance, fluid dynamics, and quantum measurements."}
{"id": "2601.22431", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22431", "abs": "https://arxiv.org/abs/2601.22431", "authors": ["Vicente Bosca", "Robert Ghrist"], "title": "Selective Adaptation of Beliefs and Communication on Cellular Sheaves", "comment": "34 pages, 7 figures", "summary": "We extend opinion dynamics on discourse sheaves to incorporate \"directional stubbornness\": agents may hold fixed positions in specified directions of their opinion stalk while remaining flexible in others. This converts the equilibrium problem from harmonic extension to a forced sheaf equation: the free-opinion component satisfies a sheaf Poisson equation with forcing induced by the clamped directions.\n  We develop a parallel theory for \"selective learning\" of expression policies. When only a designated subset of incidence maps may adapt, the resulting gradient flow is sheaf diffusion on an auxiliary structure sheaf whose global sections correspond to sheaf structures making a fixed opinion profile publicly consistent.\n  For joint evolution of beliefs and expressions, we give conditions (and regularized variants) guaranteeing convergence to nondegenerate equilibria, excluding spurious agreement via vanishing opinions or trivialized communication maps. Finally, we derive stagnation bounds in terms of the rate ratio between opinion updating and structural adaptation, quantifying when rapid rhetorical accommodation masks nearly unchanged beliefs, and conversely when flexible beliefs conform to rigid communication norms."}
{"id": "2601.22840", "categories": ["cond-mat.stat-mech", "nlin.AO", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2601.22840", "abs": "https://arxiv.org/abs/2601.22840", "authors": ["Xin Wu", "Mingcheng Yang"], "title": "Synchronization and phase transition of two-dimensional self-rotating clock models", "comment": "7 pages, 6 figures", "summary": "We explore possible synchronization in two-dimensional (2D) locally coupled discrete-state oscillators under thermal fluctuations, using the self-rotating $q$-state clock model as a prototype. Large-scale Monte Carlo simulations reveal that for $q \\ge q_c$ (with $q_c = 5$), the system undergoes two-step Berezinskii-Kosterlitz-Thouless (BKT) transitions: first from a disordered phase to a critical synchronized phase, and then to a spatiotemporal pattern phase. The latter includes oscillatory droplet states that survive in finite systems and a thermodynamically stable spiral wave state. Notably, the synchronized phase features algebraically decaying spatial correlations, alongside divergent coherence time, thus realizing a continuous time crystal; while it vanishes when $q < q_c$. Mean-field theory supports the existence of the synchronized phase, but predicts a lower critical value $q_c^{MF} = 4$."}
{"id": "2601.22559", "categories": ["cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.22559", "abs": "https://arxiv.org/abs/2601.22559", "authors": ["Siu A. Chin"], "title": "Understanding the sign problem from an exact Path Integral Monte Carlo model of interacting harmonic fermions", "comment": "40 pages with 14 figures", "summary": "This work shows that the recently discovered operator contraction identity for solving the discreet Path Integral of the harmonic oscillator can be applied equally to fermions in any dimension. This then yields an exactly solvable model for studying the sign problem where the Path Integral Monte Carlo energy at any time step for any number of fermions is known analytically, or can be computed numerically. It is found that repulsive/attractive pairwise interaction shifts the sign problem to larger/smaller imaginary time, but does not make it more severe than the non-interacting case. More surprisingly, for closed-shell number of fermions, the sign problem goes away at large imaginary time. Fourth-order and newly found variable-bead algorithms are used to compute ground state energies of quantum dots with up to 110 electrons and compared to results obtained by modern neural networks."}
{"id": "2601.22762", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22762", "abs": "https://arxiv.org/abs/2601.22762", "authors": ["Maksym Kyselov", "Sergiy G. Solodky"], "title": "Numerical Differentiation of Functions of Two Variables Using Chebyshev Polynomials", "comment": "14 pages", "summary": "We investigate the problem of numerical differentiation of bivariate functions from weighted Wiener classes using Chebyshev polynomial expansions. We develop and analyze a new version of the truncation method based on Chebyshev polynomials and the idea of hyperbolic cross to reconstruct partial derivatives of arbitrary order. The method exploits the approximation properties of Chebyshev polynomials and their natural connection to weighted spaces through the Chebyshev weight function. We derive a choice rule for the truncation parameter as a function of the noise level, smoothness parameters of the function class, and the order of differentiation. This approach allows us to establish explicit error estimates in both weighted integral norms and uniform metric."}
{"id": "2601.22999", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.22999", "abs": "https://arxiv.org/abs/2601.22999", "authors": ["Nicolas Bianco", "Lorenzo Cappello"], "title": "Computationally efficient segmentation for non-stationary time series with oscillatory patterns", "comment": null, "summary": "We propose a novel approach for change-point detection and parameter learning in multivariate non-stationary time series exhibiting oscillatory behaviour. We approximate the process through a piecewise function defined by a sum of sinusoidal functions with unknown frequencies and amplitudes plus noise. The inference for this model is non-trivial. However, discretising the parameter space allows us to recast this complex estimation problem into a more tractable linear model, where the covariates are Fourier basis functions. Then, any change-point detection algorithms for segmentation can be used. The advantage of our proposal is that it bypasses the need for trans-dimensional Markov chain Monte Carlo algorithms used by state-of-the-art methods. Through simulations, we demonstrate that our method is significantly faster than existing approaches while maintaining comparable numerical accuracy. We also provide high probability bounds on the change-point localization error. We apply our methodology to climate and EEG sleep data."}
{"id": "2601.22363", "categories": ["quant-ph", "cond-mat.str-el", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.22363", "abs": "https://arxiv.org/abs/2601.22363", "authors": ["Meng-Yuan Li"], "title": "Quantum bootstrap product codes", "comment": null, "summary": "Product constructions constitute a powerful method for generating quantum CSS codes, yielding celebrated examples such as toric codes and asymptotically good low-density parity check (LDPC) codes. Since a CSS code is fully described by a chain complex, existing product formalisms are predominantly homological, defined via the tensor product of the underlying chain complexes of input codes, thereby establishing a natural connection between quantum codes and topology. In this Letter, we introduce the \\textit{quantum bootstrap product} (QBP), an approach that extends beyond this standard homological paradigm. Specifically, a QBP code is determined by solving a consistency condition termed the ``bootstrap equation''. We find that the QBP paradigm unifies a wide range of important codes, including general hypergraph product (HGP) codes of arbitrary dimensions and fracton codes typically represented by the X-cube code. Crucially, the solutions to the bootstrap equation yield chain complexes where the chain groups and associated boundary maps consist of multiple components. We term such structures \\textit{fork complexes}. This structure elucidates the underlying topological structures of fracton codes, akin to foliated fracton order theories. Beyond conceptual insights, we demonstrate that the QBP paradigm can generate self-correcting quantum codes from input codes with constant energy barriers and surpass the code-rate upper bounds inherent to HGP codes. Our work thus substantially extends the scope of quantum product codes and provides a versatile framework for designing fault-tolerant quantum memories."}
{"id": "2601.22611", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22611", "abs": "https://arxiv.org/abs/2601.22611", "authors": ["Manika Bag", "Sheetal Dharmatti", "Subrata Majumdar", "Debanjana Mitra"], "title": "Local controllability of the Cahn-Hilliard-Burgers' equation around certain steady states", "comment": null, "summary": "In this article we study the local controllability of the one-dimensional Cahn-Hilliard-Navier-Stokes equation, that is Cahn-Hilliard-Burgers' equation, around a certain steady state using a localized interior control acting only in the concentration equation. To do it, we first linearize the nonlinear equation around the steady state. The linearized system turns out to be a system coupled between second order and fourth order parabolic equations and the control acts in the fourth order parabolic equation. The null controllability of the linearized system is obtained by a duality argument proving an observability inequality. To prove the observability inequality, a new Carleman inequality for the coupled system is derived. Next, using the source term method, it is shown that the null controllability of the linearized system with non-homogeneous terms persists provided the non-homogeneous terms satisfy certain estimates in a suitable weighted space. Finally, using a Banach fixed point theorem in a suitable weighted space, the local controllability of the nonlinear system is obtained."}
{"id": "2601.22874", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "nlin.AO", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.22874", "abs": "https://arxiv.org/abs/2601.22874", "authors": ["Alessandro Pignedoli", "Atreya Majumdar", "Karin Everschor-Sitte"], "title": "Leveraging Interactions for Efficient Swarm-Based Brownian Computing", "comment": "9 pages, 3 figures", "summary": "Drawing inspiration from swarm intelligence, we show that short-range attractive interactions between thermally driven Brownian quasiparticles enable energy-efficient optimization. As quasiparticles can be generated directly within a material, the swarm size can be adjusted with minimal energy overhead. Using an optimization task defined by a spatially varying temperature landscape, we quantitatively show that interacting swarms reliably identify global optima and significantly outperform non-interacting searchers within a well-defined regime of interaction strength and swarm size. This improvement arises from emergent cooperative behavior, where local interactions guide the swarm toward high-quality solutions without central coordination. To link our physical model to experimental realizations, we coarse-grain the quasiparticle dynamics onto a sensor lattice and generate trajectories emulating particle-tracking measurements. We further show that the interacting swarm adapts robustly to landscapes that evolve over time. These findings establish interacting Brownian quasiparticles as a physical platform for scalable and energy-efficient unconventional computing."}
{"id": "2601.22566", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.22566", "abs": "https://arxiv.org/abs/2601.22566", "authors": ["Kosuke Fujiwara", "Takahiro Morimoto"], "title": "Interaction induced topological magnon in electron-magnon coupled systems", "comment": "13 pages, 8 figures", "summary": "We theoretically study the emergence of topological magnons in electron-magnon coupled systems. The magnon dispersion in a ferromagnet usually possesses an effective time reversal symmetry in the absence of Dzyaloshinskii-Moriya (DM) interaction, preventing the appearance of topological magnons. When a spin system is coupled to itinerant electrons, we find that the magnon band structure of the spin system experiences time-reversal symmetry breaking with the electron-magnon interaction via the exchange coupling, where topological magnons arise without requiring strong DM. Specifically, we consider a heterostructure consisting of a ferromagnetic insulator and a transition metal dichalcogenide (TMD) monolayer and investigate topological gap opening in magnon bands. Our findings reveal that even trivial ferromagnets can host topological magnons via coupling to itinerant electronic systems."}
{"id": "2601.22825", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22825", "abs": "https://arxiv.org/abs/2601.22825", "authors": ["Dinh Dũng", "Van Kien Nguyen", "Duong Thanh Pham", "Christoph Schwab"], "title": "Approximation of PDE solution manifolds: Sparse-grid interpolation and quadrature", "comment": "27 pages", "summary": "We study fully-discrete approximations and quadratures of infinite-variate functions in abstract Bochner spaces associated with a Hilbert space $X$ and an infinite-tensor-product Jacobi measure. For target infinite-variate functions taking values in $X$ which admit absolutely convergent Jacobi generalized polynomial chaos expansions, with suitable weighted summability conditions for the coefficient sequences, we generalize and improve prior results on construction of sequences of finite sparse-grid tensor-product polynomial interpolation approximations and quadratures, based on the univariate Chebyshev points. For a generic stable discretization of $X$ in terms of a dense sequence $(V_m)_{m \\in \\mathbb{N}_0}$ of finite-dimensional subspaces, we obtain fully-discrete, linear approximations in terms of so-called sparse-grid tensor-product projectors, with convergence rates of approximations as well as of sparse-grid tensor-product quadratures of the target functions.\n  We verify the abstract assumptions in two fundamental application settings: first, a linear elliptic diffusion equation with affine-parametric coefficients and second, abstract holomorphic maps between separable Hilbert spaces with affine-parametric input data encoding. For these settings, as in [37,20], cancellation of anti-symmetric terms in ultra-spherical Jacobi generalized polynomial chaos expansion coefficients implies crucially improved convergence rates of sparse-grid tensor-product quadrature with respect to the infinite-tensor-product Jacobi weight, free from the ``curse-of-dimension\".\n  Largely self-contained proofs of all results are developed. Approximation convergence rate results in the present setting which are based on construction of neural network surrogates, for unbounded parameter ranges with Gaussian measures, will be developed in extensions of the present work."}
{"id": "2601.23021", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.23021", "abs": "https://arxiv.org/abs/2601.23021", "authors": ["Nicole Cizauskas", "Foteini Strimenopoulou", "Svetlana S. Cherlin", "James M. S. Wason"], "title": "Differences in Performance of Bayesian Dynamic Borrowing and Synthetic Control Methods: A Case Study of Pediatric Atopic Dermatitis", "comment": "13 pages, 1 table, 2 figures", "summary": "Bayesian dynamic borrowing (BDB) and synthetic control methods (SCM) are both used in clinical trial design when recruitment, retention, or allocation is a challenge. The performance of these approaches has not previously been directly compared due to differences in application, product, and measurement metrics. This study aims to conduct a comparison of power and type 1 error rates of BDB (using meta-analytic predictive prior (MAP)) and SCM using a case study of Pediatric Atopic Dermatitis. Six historical randomised control trials were selected for use in both the creation of the MAP prior and synthetic control arm. The R library RBesT was used to create a MAP prior and the R library Synthpop was used to create a synthetic control arm for the SCM. Power and type 1 error rate were used as comparison metrics. BDB produced a power of 0.580 and a type 1 error rate of 0.026. SCM produced a power of 0.641 and a type 1 error rate of 0.027. In this case study, the SCM model produced a higher power than the BDB method with a similar type 1 error rate. However, the decision to use SCM or BDB should come from the specific needs of the potential trial, since their power and type 1 error rate may differ on a case-by-case basis."}
{"id": "2601.22372", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22372", "abs": "https://arxiv.org/abs/2601.22372", "authors": ["Xuan Du Trinh", "Meghana Sistla", "Nengkun Yu", "Thomas Reps"], "title": "Manjushri: A Tool for Equivalence Checking of Quantum Circuits", "comment": null, "summary": "Verifying whether two quantum circuits are equivalent is a central challenge in the compilation and optimization of quantum programs. We introduce \\textsc{Manjushri}, a new automated framework for scalable quantum-circuit equivalence checking. \\textsc{Manjushri} uses local projections as discriminative circuit fingerprints, implemented with weighted binary decision diagrams (WBDDs), yielding a compact and efficient symbolic representation of quantum behavior. We present an extensive experimental evaluation that, for random 1D Clifford+$T$ circuits, explores the trade-off between \\textsc{Manjushri} and \\textsc{ECMC}, a tool for equivalence checking based on a much different approach. \\textsc{Manjushri} is much faster up to depth 30 (with the crossover point varying from 39--49, depending on the number of qubits and whether the input circuits are equivalent or inequivalent): when inputs are equivalent, \\textsc{Manjushri} is about 10$\\times$ faster (or more); when inputs are inequivalent, \\textsc{Manjushri} is about 8$\\times$ faster (or more). For both kinds of equivalence-checking outcomes, \\textsc{ECMC}'s success rate out to depth 50 is impressive on 32- and 64-qubit circuits: on such circuits, \\textsc{ECMC} is almost uniformly successful. However, \\textsc{ECMC} struggled on 128-qubit circuits for some depths. \\textsc{Manjushri} is almost uniformly successful out to about depth 38, before tailing off to about 75\\% at depth 50 (falling to 0\\% at depth 48 for 128-qubit circuits that are equivalent). These results establish that \\textsc{Manjushri} is a practical and scalable solution for large-scale quantum-circuit verification, and would be the preferred choice unless clients need to check equivalence of circuits of depth $>$38."}
{"id": "2601.22682", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22682", "abs": "https://arxiv.org/abs/2601.22682", "authors": ["Yaoshuai Ma", "Xiao Wang", "Wei Yao", "Jin Zhang"], "title": "SUN-DSBO: A Structured Unified Framework for Nonconvex Decentralized Stochastic Bilevel Optimization", "comment": null, "summary": "Decentralized stochastic bilevel optimization (DSBO) is a powerful tool for various machine learning tasks, including decentralized meta-learning and hyperparameter tuning. Existing DSBO methods primarily address problems with strongly convex lower-level objective functions. However, nonconvex objective functions are increasingly prevalent in modern deep learning. In this work, we introduce SUN-DSBO, a Structured Unified framework for Nonconvex DSBO, in which both the upper- and lower-level objective functions may be nonconvex. Notably, SUN-DSBO offers the flexibility to incorporate decentralized stochastic gradient descent or various techniques for mitigating data heterogeneity, such as gradient tracking (GT). We demonstrate that SUN-DSBO-GT, an adaptation of the GT technique within our framework, achieves a linear speedup with respect to the number of agents. This is accomplished without relying on restrictive assumptions, such as gradient boundedness or any specific assumptions regarding gradient heterogeneity. Numerical experiments validate the effectiveness of our method."}
{"id": "2601.23234", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.23234", "abs": "https://arxiv.org/abs/2601.23234", "authors": ["Riccardo Travaglino", "Federico Rottoli", "Pasquale Calabrese"], "title": "Entanglement Hamiltonians in dissipative free fermions and the time-dependent GGE", "comment": "20 pages+ appendices, 4 figures", "summary": "We investigate the dynamics of Entanglement Hamiltonians (EHs) in dissipative free-fermionic systems using a recent operator-based formulation of the quasiparticle picture. Focusing on gain and loss dissipation, we study the post-quench evolution and derive explicit expressions for the EH at the ballistic scale. In the long-time and weak-dissipation regime, the EH is shown to take the form of a time-dependent Generalized Gibbs Ensemble (t-GGE), with a structure that is universal across different initial states of the quench protocol. Within this framework, the emergence of the t-GGE is fully accounted for by the quasiparticle picture, and we argue that this description remains valid whenever the Lindbladian admits an appropriate coarse-grained representation."}
{"id": "2601.22909", "categories": ["cond-mat.str-el", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22909", "abs": "https://arxiv.org/abs/2601.22909", "authors": ["Mark Potts", "Roderich Moessner", "S. A. Parameswaran"], "title": "N-state Potts ices as generalizations of classical and quantum spin ice", "comment": "16 pages, 12 figures", "summary": "Classical and quantum spin ice models are amongst the most popular settings for the study of spin liquid physics. $N-$state Potts ice models have been constructed that generalize spin ice, hosting multiple emergent $\\text{U}(1)$ gauge fields and excitations charged under non-trivial combinations of these fields. We present a general treatment of classical $N-$state Potts ices relating their properties to the $\\mathfrak{su}(N)$ Lie algebras, and demonstrate how the properties of charged excitations in the classical model can be related to this symmetry group. We also introduce quantum generalizations of the Potts Ice models, and demonstrate how charge flavor changing interactions unique to $N>2$ models dominate their low energy physics. We further show how symmetries inherited from the $\\mathfrak{su}(N)$ can lead to flux vacuum frustration, greatly modifying the dynamical properties of charged excitations."}
{"id": "2601.22854", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22854", "abs": "https://arxiv.org/abs/2601.22854", "authors": ["Cedric Riethmüller", "Erlend Storvik"], "title": "On the convergence and efficiency of splitting schemes for the Cahn-Hilliard-Biot model", "comment": null, "summary": "In this paper, we present a novel solution strategy for the Cahn-Hilliard-Biot model, a three-way coupled system that features the interplay of solid phase separation, fluid dynamics, and elastic deformations in porous media. It is a phase-field model that combines the Cahn-Hilliard regularized interface equation and Biot's equations of poroelasticity. Solving the system poses significant challenges due to its coupled, nonlinear, and non-convex nature. The main goal of this work is to provide a consistent and efficient solution strategy. With this in mind, we introduce a semi-implicit time discretization such that the resulting discrete system is equivalent to a convex minimization problem. Then, using abstract theory for convex problems, we prove the convergence of an alternating minimization method to the time-discrete system. The solution strategy is relatively flexible in terms of spatial discretization, although we require standard inverse inequalities for the guaranteed convergence of the alternating minimization method. Finally, we perform some numerical experiments that show the promise of the proposed solution strategy, both in terms of efficiency and robustness."}
{"id": "2601.23173", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.23173", "abs": "https://arxiv.org/abs/2601.23173", "authors": ["Chris Sherlock", "Andrew Golightly", "Anthony Lee"], "title": "Robust, partially alive particle Metropolis-Hastings via the Frankenfilter", "comment": null, "summary": "When a hidden Markov model permits the conditional likelihood of an observation given the hidden process to be zero, all particle simulations from one observation time to the next could produce zeros. If so, the filtering distribution cannot be estimated and the estimated parameter likelihood is zero. The alive particle filter addresses this by simulating a random number of particles for each inter-observation interval, stopping after a target number of non-zero conditional likelihoods. For outlying observations or poor parameter values, a non-zero result can be extremely unlikely, and computational costs prohibitive. We introduce the Frankenfilter, a principled, partially alive particle filter that targets a user-defined amount of success whilst fixing lower and upper bounds on the number of simulations. The Frankenfilter produces unbiased estimators of the likelihood, suitable for pseudo-marginal Metropolis--Hastings (PMMH). We demonstrate that PMMH with the Frankenfilter is more robust to outliers and mis-specified initial parameter values than PMMH using standard particle filters, and is typically at least 2-3 times more efficient. We also provide advice for choosing the amount of success. In the case of n exact observations, this is particularly simple: target n successes."}
{"id": "2601.22400", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22400", "abs": "https://arxiv.org/abs/2601.22400", "authors": ["Elad Hazan", "Annie Marsden"], "title": "Spectral Filtering for Learning Quantum Dynamics", "comment": null, "summary": "Learning high-dimensional quantum systems is a fundamental challenge that notoriously suffers from the curse of dimensionality. We formulate the task of predicting quantum evolution in the linear response regime as a specific instance of learning a Complex-Valued Linear Dynamical System (CLDS) with sector-bounded eigenvalues -- a setting that also encompasses modern Structured State Space Models (SSMs). While traditional system identification attempts to reconstruct full system matrices (incurring exponential cost in the Hilbert dimension), we propose Quantum Spectral Filtering, a method that shifts the goal to improper dynamic learning. Leveraging the optimal concentration properties of the Slepian basis, we prove that the learnability of such systems is governed strictly by an effective quantum dimension $k^*$, determined by the spectral bandwidth and memory horizon. This result establishes that complex-valued LDSs can be learned with sample and computational complexity independent of the ambient state dimension, provided their spectrum is bounded."}
{"id": "2601.22753", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.22753", "abs": "https://arxiv.org/abs/2601.22753", "authors": ["Gaëtan Serré", "Pierre Germain", "Samuel Gruffaz", "Argyris Kalogeratos"], "title": "Enhancing Exploration in Global Optimization by Noise Injection in the Probability Measures Space", "comment": null, "summary": "McKean-Vlasov (MKV) systems provide a unifying framework for recent state-of-the-art particlebased methods for global optimization. While individual particles follow stochastic trajectories, the probability law evolves deterministically in the mean-field limit, potentially limiting exploration in multimodal landscapes. We introduce two principled approaches to inject noise directly into the probability law dynamics: a perturbative method based on conditional MKV theory, and a geometric approach leveraging tangent space structure. While these approaches are of independent interest, the aim of this work is to apply them to global optimization. Our framework applies generically to any method that can be formulated as a MKV system. Extensive experiments on multimodal objective functions demonstrate that both our noise injection strategies enhance consistently the exploration and convergence across different configurations of dynamics, such as Langevin, Consensus-Based Optimization, and Stein Boltzmann Sampling, providing a versatile toolkit for global optimization."}
{"id": "2601.22224", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.22224", "abs": "https://arxiv.org/abs/2601.22224", "authors": ["Jia-Nan Yang", "Lata Kh Joshi", "Filiberto Ares", "Yihang Han", "Pengfei Zhang", "Pasquale Calabrese"], "title": "Probing Entanglement and Symmetries in Random States Using a Superconducting Quantum Processor", "comment": null, "summary": "Quantum many-body systems display an extraordinary degree of complexity, yet many of their features are universal: they depend not on microscopic details, but on a few fundamental physical aspects such as symmetries. A central challenge is to distill these universal characteristics from model-specific ones. Random quantum states sampled from a uniform distribution, the Haar measure, provide a powerful framework for capturing this typicality. Here, we experimentally study the entanglement and symmetries of random many-body quantum states generated by evolving simple product states under ergodic Floquet models. We find excellent agreement with the predictions from the Haar-random state ensemble. First, we measure the Rényi-2 entanglement entropy as a function of the subsystem size, observing the Page curve. Second, we probe the subsystem symmetries using entanglement asymmetry. Finally, we measure the moments of partially transposed reduced density matrices obtained by tracing out part of the system in the generated ensembles, thereby revealing distinct entanglement phases. Our results offer an experimental perspective on the typical entanglement and symmetries of many-body quantum systems."}
{"id": "2601.22924", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.22924", "abs": "https://arxiv.org/abs/2601.22924", "authors": ["Zhengpeng Yuan", "Muwei Wu", "Dao-Xin Yao", "Han-Qing Wu"], "title": "Spiral Phase and Phase Diagram of the $S$=1/2 XXZ Model on the Shastry-Sutherland Lattice", "comment": "11 pages, 7 figures", "summary": "We investigate the ground-state phase diagram of the $S$=1/2 XXZ model on the two-dimensional Shastry-Sutherland lattice using exact diagonalization (ED), density-matrix renormalization group (DMRG), and cluster mean-field theory (CMFT) with DMRG as a solver. In the isotropic case ($Δ=1$), CMFT results reveal an intermediate empty plaquette (EP) phase that has a lower energy than the full plaquette (FP) phase. However, due to mean-field artifacts, CMFT alone is not suitable for accurately determining phase boundaries. Therefore, we combined three methods to map out the reliable phase diagram. Our calculations show that the EP phase narrows as $Δ$ deviates from unity and eventually vanishes. More importantly, we identify a spiral phase at small $Δ$, which has not been reported in previous studies. This phase is clearly captured by DMRG simulations on long cylindrical geometries. The competition between the EP, spiral, and $xy$-AFM phases near their boundaries provides a plausible explanation for the emergent spin-liquid-like behavior in RE$_2$Be$_2$GeO$_2$, while shedding new light on the role of XXZ anisotropy in the Shastry-Sutherland XXZ model."}
{"id": "2601.22860", "categories": ["math.NA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.22860", "abs": "https://arxiv.org/abs/2601.22860", "authors": ["Chanwook Park", "Brian Kim", "Jiachen Guo", "Wing Kam Liu"], "title": "Bayesian Interpolating Neural Network (B-INN): a scalable and reliable Bayesian model for large-scale physical systems", "comment": "8 pages, 6 figures, ICML conference full paper submitted", "summary": "Neural networks and machine learning models for uncertainty quantification suffer from limited scalability and poor reliability compared to their deterministic counterparts. In industry-scale active learning settings, where generating a single high-fidelity simulation may require days or weeks of computation and produce data volumes on the order of gigabytes, they quickly become impractical. This paper proposes a scalable and reliable Bayesian surrogate model, termed the Bayesian Interpolating Neural Network (B-INN). The B-INN combines high-order interpolation theory with tensor decomposition and alternating direction algorithm to enable effective dimensionality reduction without compromising predictive accuracy. We theoretically show that the function space of a B-INN is a subset of that of Gaussian processes, while its Bayesian inference exhibits linear complexity, $\\mathcal{O}(N)$, with respect to the number of training samples. Numerical experiments demonstrate that B-INNs can be from 20 times to 10,000 times faster with a robust uncertainty estimation compared to Bayesian neural networks and Gaussian processes. These capabilities make B-INN a practical foundation for uncertainty-driven active learning in large-scale industrial simulations, where computational efficiency and robust uncertainty calibration are paramount."}
{"id": "2601.22602", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22602", "abs": "https://arxiv.org/abs/2601.22602", "authors": ["Zhigang Bao", "Kha Man Cheong", "Yuji Li", "Jiaxin Qiu"], "title": "A spectral approach for online covariance change point detection", "comment": null, "summary": "Change point detection in covariance structures is a fundamental and crucial problem for sequential data. Under the high-dimensional setting, most of the existing research has focused on identifying change points in historical data. However, there is a significant lack of studies on the practically relevant online change point problem, which means promptly detecting change points as they occur. In this paper, applying the limiting theory of linear spectral statistics for random matrices, we propose a class of spectrum based CUSUM-type statistic. We first construct a martingale from the difference of linear spectral statistics of sequential sample Fisher matrices, which converges to a Brownian motion. Our CUSUM-type statistic is then defined as the maximum of a variant of this process. Finally, we develop our detection procedure based on the invariance principle. Simulation results show that our detection method is highly sensitive to the occurrence of change point and is able to identify it shortly after they arise, outperforming the existing approaches."}
{"id": "2601.22471", "categories": ["quant-ph", "cs.CC", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.22471", "abs": "https://arxiv.org/abs/2601.22471", "authors": ["Archishna Bhattacharyya", "Arthur Mehta", "Yuming Zhao"], "title": "On the undecidability of quantum channel capacities", "comment": "24 pages, 1 figure", "summary": "An important distinction in our understanding of capacities of classical versus quantum channels is marked by the following question: is there an algorithm which can compute (or even efficiently compute) the capacity? While there is overwhelming evidence suggesting that quantum channel capacities may be uncomputable, a formal proof of any such statement is elusive. We initiate the study of the hardness of computing quantum channel capacities. We show that, for a general quantum channel, it is QMA-hard to compute its quantum capacity, and that the maximal-entanglement-assisted zero-error one-shot classical capacity is uncomputable."}
{"id": "2601.22819", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22819", "abs": "https://arxiv.org/abs/2601.22819", "authors": ["Yaxing Ma", "Lijuan Wang", "Huaiqiang Yu"], "title": "Rapid stabilizability of delayed infinite-dimensional control systems", "comment": "28 Pages", "summary": "In this paper, the rapid stabilizability of linear infinite-dimensional control system with constant-valued delay is studied. Under assumptions that the state operator generates an immediately compact semigroup and the coefficient of the delay term is constant, we mainly prove the following two results: (i) the delay does not affect rapid stabilizability of the control system; (ii) from the perspective of observation-feedback, it is not necessary to use historical information to stabilize the control system when the system is rapidly stabilizable. Some applications are given."}
{"id": "2601.22247", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22247", "abs": "https://arxiv.org/abs/2601.22247", "authors": ["David Vaknin"], "title": "The Photonic Foundation of Temperature: Mechanisms of Thermal Equilibrium and Entropy Production", "comment": null, "summary": "I examine the physical foundations of temperature and thermal equilibrium by identifying photons as the fundamental agents that establish and maintain the characteristic energy scale $E_c = k_B T$ in ordinary matter. While classical thermodynamics successfully describes equilibrium phenomenologically, the realization of thermal distributions requires concrete microscopic mechanisms provided by quantum electrodynamics. We derive the Boltzmann distribution from a minimal differential scaling postulate and show that sustaining thermal equilibrium demands continuous photon exchange with average energy $\\langle hν\\rangle = 2.701\\,E_c$, quantifying the energetic throughput necessary to counter radiative losses. Entropy production is shown to arise naturally from inelastic photon scattering that converts high-energy photons into many lower-energy quanta, thereby increasing accessible microstates and driving irreversible evolution toward equilibrium. We establish physical criteria distinguishing genuine thermal equilibrium from purely formal temperature assignments and demonstrate that the classical notion of an infinite thermal reservoir emerges as an effective idealization within a hierarchy of dynamically maintained photon baths. This photonic framework complements phenomenological thermodynamics by providing its microscopic foundation and clarifies the physical meaning of temperature as an emergent collective property of photon-mediated energy exchange."}
{"id": "2601.23033", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.23033", "abs": "https://arxiv.org/abs/2601.23033", "authors": ["Takeshi Matsumura", "Mitsuru Tsukagoshi", "Shota Nakamura", "Shigeo Ohara"], "title": "Conical Magnetic Structure and Atomic Displacements in Chiral Helimagnet Yb(Ni,Cu)$_3$Al$_9$ in Magnetic Fields along the Helical $c$ Axis", "comment": "8 pages, 10 figures, Accepted for publication in J. Phys. Soc. Jpn", "summary": "We investigated the conical magnetic state of a uniaxial chiral helimagnet Yb(Ni$_{1-x}$Cu$_x$)$_3$Al$_9$ induced in magnetic fields applied along the $c$ axis, which coincides with the helical axis at zero field. Using resonant X-ray diffraction, we clearly observed the disappearance of magnetic satellite peaks, corresponding to the transition from the conical to the field-induced ferromagnetic state. The critical fields were determined to be 4 T for $x=0$ and 7 T for $x= 0.05$, which were hardly discernible in the magnetization curves. We also found that atomic displacements with the same propagation vector emerge simultaneously with the onset of the conical order. The transition temperature $T_{\\text{N}}$ and the critical fields for $H \\parallel c$ ($H_{\\text{c}}^{z}$) and $H\\perp c$ ($H_{\\text{c}}^{x}$) are discussed on the basis of a mean-field calculation for a simple $q=1$ model of the magnetic structure. We propose that $T_{\\text{N}}$ and $H_{\\text{c}}^{z}$ primarily reflect the dominant intralayer exchange interactions within the honeycomb Yb-layer, whereas $H_{\\text{c}}^{x}$ is governed by the much weaker interlayer coupling."}
{"id": "2601.22867", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22867", "abs": "https://arxiv.org/abs/2601.22867", "authors": ["Peter Oehme"], "title": "Randomized Methods for Kernelized DMD", "comment": "9 pages, 5 figures", "summary": "Dynamic Mode Decomposition (DMD) is a data-driven method related to Koopman operator theory that extracts information about dominant dynamics from data snapshots. In this paper we examine techniques to accelerate the application of DMD to large-scale data sets with an eye on randomized techniques. Randomized techniques exploit low-rank matrix approximations at a much smaller computational cost, therefore permitting the use of increased data set sizes. In particular, we propose the application of the RPCholesky algorithm in the setting of kernelized DMD (KDMD). This algorithm relies on adaptive randomized sampling to approximate positive semidefinite kernel matrices and provides better stability guarantees than previously implemented randomized methods for KDMD. Differences between existing competitive randomized techniques and our proposed implementation are discussed with a focus on numerical stability and tradeoff between exploration and exploitation of information obtained from data. The efficacy of this new combination of algorithms is demonstrated on well-established benchmark problems from DMD literature increasing in problem dimension."}
{"id": "2601.22479", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22479", "abs": "https://arxiv.org/abs/2601.22479", "authors": ["Muzzamal I. Shaukat", "Charles A. Wallace", "Anatoly A. Svidzinsky", "Marlan O. Scully"], "title": "Dicke States for Accelerated Two Two-Level Atoms", "comment": "5pages, 3 figures", "summary": "We explore the formation of Dicke states. A system consisting of two two-level atoms located in the right Rindler wedge, has investigated to determine the conditions under which the superradiant or subradiant state can be formed. The dynamics of N two-level atoms forming symmetric state has also been analyzed and showed that the probability to excite any one atom of a collection of N atoms is related to the probability of exciting a single atom. We derive the analytical expression for the joint excitation probability which demonstrates the the interference effect. These findings provide new insights into the behavior of quantum systems in non-inertial frames and contribute to the broader understanding of relativistic quantum information theory."}
{"id": "2601.22850", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22850", "abs": "https://arxiv.org/abs/2601.22850", "authors": ["Glaydston C. Bento", "Boris S. Mordukhovich", "Tiago S. Mota", "Antoine Soubeyran"], "title": "Convergence Rates for the Alternating Minimization Algorithm in Structured Nonsmooth and Nonconvex Optimization", "comment": "19 pages", "summary": "This paper is devoted to developing the alternating minimization algorithm for problems of structured nonconvex optimization proposed by Attouch, Bolté, Redont, and Soubeyran in 2010. Our main result provides significant improvements of the convergence rate of the algorithm, especially under the low exponent Polyak-Łojasiewicz-Kurdyka condition when we establish either finite termination of this algorithm or its superlinear convergence rate instead of the previously known linear convergence. We also investigate the PLK exponent calculus and discuss applications to noncooperative games and behavioral science."}
{"id": "2601.22389", "categories": ["physics.soc-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22389", "abs": "https://arxiv.org/abs/2601.22389", "authors": ["Bruce Stephenson", "Robin Macomber"], "title": "Convergent Discovery of Critical Phenomena Mathematics Across Disciplines: A Cross-Domain Analysis", "comment": "17 pages, no figures, plain-language summary in Appendix B", "summary": "Techniques for detecting critical phenomena -- phase transitions where correlation length diverges and small perturbations have large effects -- have been developed across at least eight fields of application over nine decades. We document this convergence pattern. The physicist's correlation length $ξ$, the cardiologist's DFA scaling exponent $α$, the financial analyst's Hurst exponent $H$, and the machine learning engineer's spectral radius $χ$ all measure correlation decay rate, detecting the same critical signatures under different notation. Citation analysis reveals minimal cross-domain awareness during the formative period (1987--2010): researchers in biomedicine, finance, machine learning, power systems, and traffic flow developed equivalent techniques independently, each with distinct notation and terminology. We present Metatron Dynamics, a framework derived from distributed systems engineering, as a candidate ninth independent discovery -- strengthening the convergence pattern while acknowledging that as authors of both the framework and this analysis, external validation would strengthen this claim. Correspondence testing on the 2D Ising model confirms that measures from multiple frameworks correctly identify the critical regime at $T_c = 2.269$. We argue that repeated independent discovery establishes criticality mathematics as fundamental public knowledge, with implications for cross-disciplinary education and research accessibility. Because these findings affect fields beyond mathematics and physics, we include a plain-language summary in Appendix B for non-specialist readers."}
{"id": "2601.23136", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.23136", "abs": "https://arxiv.org/abs/2601.23136", "authors": ["Giacomo Mazza"], "title": "Magnetic field control of the excitonic transition in Ta$_2$NiSe$_5$", "comment": "5 pages, 5 figures", "summary": "The formation of excitonic insulator phases in quantum materials is often masked by structural distortions caused by the coupling between electronic and phononic order parameters. Here we show that the candidate material Ta$_2$NiSe$_5$ is characterized by a metastable excitonic insulating phase that is decoupled from the lattice, and that can be stabilized for sufficiently high applied magnetic fields. By considering the interplay between the excitonic and structural instabilities, we predict a magnetic field induced transition from the low-temperature structurally distorted semiconducting phase to an undistorted excitonic insulator phase with ground state loop currents. Before the transition, the existence of a latent excitonic phase can be detected by the magnetic field softening of the phonon mode associated with the structural distortion. These results highlight an unbiased route towards the disentanglement of the coupled excitonic-structural transition in Ta$_2$NiSe$_5$, and uncover a general mechanism for magnetic field control of competing phases in quantum materials."}
{"id": "2601.22942", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.22942", "abs": "https://arxiv.org/abs/2601.22942", "authors": ["Ling Guo", "Mingxin Qin", "Changtao Sheng", "Hao Wu", "Fanhai Zeng"], "title": "FNWoS: Fractional Neural Walk-on-Spheres Methods for High-Dimensional PDEs Driven by $α$-stable Lévy Process on Irregular Domains", "comment": null, "summary": "In this paper, we develop a highly parallel and derivative-free fractional neural walk-on-spheres method (FNWoS) for solving high-dimensional fractional Poisson equations on irregular domains. We first propose a simplified fractional walk-on-spheres (FWoS) scheme that replaces the high-dimensional normalized weight integral with a constant weight and adopts a correspondingly simpler sampling density, substantially reducing per-trajectory cost. To mitigate the slow convergence of standard Monte Carlo sampling, FNWoS is then proposed via integrating this simplified FWoS estimator, derived from the Feynman-Kac representation, with a neural network surrogate. By amortizing sampling effort over the entire domain during training, FNWoS achieves more accurate evaluation at arbitrary query points with dramatically fewer trajectories than classical FWoS. To further enhance efficiency in regimes where the fractional order $α$ is close to 2 and trajectories become excessively long, we introduce a truncated path strategy with a prescribed maximum step count. Building on this, we propose a buffered supervision mechanism that caches training pairs and progressively refines their Monte Carlo targets during training, removing the need to precompute a highly accurate training set and yielding the buffered fractional neural walk-on-spheres method (BFNWoS). Extensive numerical experiments, including tests on irregular domains and problems with dimensions up to $1000$, demonstrate the accuracy, scalability, and computational efficiency of the proposed methods."}
{"id": "2601.22489", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.22489", "abs": "https://arxiv.org/abs/2601.22489", "authors": ["Mohammad Rowshan"], "title": "Structural Conditions for Native CCZ Magic-State Fountains in qLDPC Codes", "comment": "7 pages, 3 figures, 2 lemmas, 1 theorem", "summary": "Quantum low-density parity-check (qLDPC) codes promise constant-rate, linear-distance families with bounded-weight checks, and recent work has realized transversal or constant-depth non-Clifford gates on various (often non-LDPC) codes. However, no explicit \\emph{qubit} qLDPC family is known that simultaneously has constant rate, linear distance, bounded stabilizer weight, and a native \\emph{magic-state fountain} that prepares many non-Clifford resource states in constant depth.\n  We take a structural approach and identify coding-theoretic conditions under which a CSS qLDPC family necessarily supports a constant-depth $\\CCZ$ magic-state fountain. The key ingredients are: (i) an algebraic notion of \\emph{magic-friendly triples} of $X$-type logical operators, defined by pairwise orthogonality and a triple-overlap form controlling diagonal $\\CCZ$ phases, and (ii) a 3-uniform hypergraph model of physical $\\CCZ$ circuits combined with a packing lemma that turns large collections of such triples with bounded overlaps into bounded-degree hypergraphs.\n  Our main theorem shows that if a CSS code family on $n$ qubits admits $Ω(n^{1+γ})$ magic-friendly triples whose supports have bounded per-qubit participation, then there exists a constant-depth circuit of physical $\\CCZ$ gates implementing $Ω(n^γ)$ logical $\\CCZ$ gates in parallel while preserving distance up to a constant factor. For asymptotically good qLDPC families such as quantum Tanner codes, this reduces the existence of a native $\\CCZ$ magic-state fountain to a concrete combinatorial problem about counting and distributing magic-friendly triples in the logical $X$ space."}
{"id": "2601.22897", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22897", "abs": "https://arxiv.org/abs/2601.22897", "authors": ["Mathias Dus"], "title": "Grassmannian Geometry and Global Convergence of Variable Projection for Neural Networks", "comment": null, "summary": "Training deep neural networks and Physics-Informed Neural Networks (PINNs) often leads to ill-conditioned and stiff optimization problems. A key structural feature of these models is that they are linear in the output-layer parameters and nonlinear in the hiddenlayer parameters, yielding a separable nonlinear least-squares formulation. In this work, we study the classical variable projection (VarPro) method for such problems in the context of deep neural networks. We provide a geometric formulation on the Grassmannian and analyze the structure of critical points and convergence properties of the reduced problem. When the feature map is parametrized by a neural network, we show that these properties persist except in rank-deficient regimes, which we address via a regularized Grassmannian framework. Numerical experiments for regression and PINNs, including an efficient solver for the heat equation, illustrate the practical effectiveness of the approach."}
{"id": "2601.22734", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22734", "abs": "https://arxiv.org/abs/2601.22734", "authors": ["Yuri Yu. Tarasevich"], "title": "Electrical conductivity of a random nanowire network: comparison of two-dimensional and quasi-three-dimensional models", "comment": "4 pages, 3 figures", "summary": "It is shown that the widely used two-dimensional model of random networks of metallic nanowires or carbon nanotubes significantly overestimates the number of contacts between elements compared to real systems, which, within the mean-field approach, leads to overestimated estimates of electrical conductivity, especially when the contact resistances between conductors make the main contribution to the electrical conductivity of the system. In the case of a two-dimensional model, the electrical conductivity of the system depends quadratically on the number density of conductors, whereas in the case of a three-dimensional model this dependence is linear."}
{"id": "2601.22363", "categories": ["quant-ph", "cond-mat.str-el", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.22363", "abs": "https://arxiv.org/abs/2601.22363", "authors": ["Meng-Yuan Li"], "title": "Quantum bootstrap product codes", "comment": null, "summary": "Product constructions constitute a powerful method for generating quantum CSS codes, yielding celebrated examples such as toric codes and asymptotically good low-density parity check (LDPC) codes. Since a CSS code is fully described by a chain complex, existing product formalisms are predominantly homological, defined via the tensor product of the underlying chain complexes of input codes, thereby establishing a natural connection between quantum codes and topology. In this Letter, we introduce the \\textit{quantum bootstrap product} (QBP), an approach that extends beyond this standard homological paradigm. Specifically, a QBP code is determined by solving a consistency condition termed the ``bootstrap equation''. We find that the QBP paradigm unifies a wide range of important codes, including general hypergraph product (HGP) codes of arbitrary dimensions and fracton codes typically represented by the X-cube code. Crucially, the solutions to the bootstrap equation yield chain complexes where the chain groups and associated boundary maps consist of multiple components. We term such structures \\textit{fork complexes}. This structure elucidates the underlying topological structures of fracton codes, akin to foliated fracton order theories. Beyond conceptual insights, we demonstrate that the QBP paradigm can generate self-correcting quantum codes from input codes with constant energy barriers and surpass the code-rate upper bounds inherent to HGP codes. Our work thus substantially extends the scope of quantum product codes and provides a versatile framework for designing fault-tolerant quantum memories."}
{"id": "2601.23185", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.23185", "abs": "https://arxiv.org/abs/2601.23185", "authors": ["Markus Bachmayr", "Wolfgang Dahmen", "Chenguang Duan", "Mathias Oster"], "title": "Preconditioning and Numerical Stability in Neural Network Training for Parametric PDEs", "comment": null, "summary": "In the context of training neural network-based approximations of solutions of parameter-dependent PDEs, we investigate the effect of preconditioning via well-conditioned frame representations of operators and demonstrate a significant improvement on the performance of standard training methods. We also observe that standard representations of preconditioned matrices are insufficient for obtaining numerical stability and propose a generally applicable form of stable representations that enables computations with single- and half-precision floating point numbers without loss of precision."}
{"id": "2601.22503", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22503", "abs": "https://arxiv.org/abs/2601.22503", "authors": ["Guantian Hu", "Wenxuan Zhang", "Zhihua Chen", "Liuzhu Zhong", "Jingchao Zhao", "Chilong Liu", "Zixing Liu", "Yue Xu", "Yongchang Lin", "Yougui Ri", "Guixu Xie", "Mingze Liu", "Haolan Yuan", "Yuxuan Zhou", "Yu Zhang", "Chang-Kang Hu", "Song Liu", "Dian Tan", "Dapeng Yu"], "title": "Quantum-Enhanced Sensing Enabled by Scrambling-Induced Genuine Multipartite Entanglement", "comment": null, "summary": "Quantum sensing leverages quantum resources to surpass the standard quantum limit, yet many existing protocols rely on the preparation of complex entangled states and Hamiltonian engineering, posing challenges for universality and scalability. Here, we report an experimental realization of a universal protocol, known as Butterfly Metrology, proposed in [arXiv:2411.12794], demonstrating a scrambling-based approach for quantum-enhanced sensing on a superconducting quantum processor. By exploiting many-body information scrambling, we observe quantum-enhanced sensitivity to an encoded phase beyond the standard quantum limit, with a scaling consistent with a factor-of-two of the Heisenberg limit for system sizes of up to 10 qubits. Importantly, we experimentally establish a connection between the enhanced sensitivity and the dynamics of the out-of-time-order correlator (OTOC), and show that the buildup of scrambling-induced genuine multipartite entanglement underlies the observed sensitivity enhancement. Our results demonstrate a scalable and practical approach for quantum-enhanced sensing in interacting many-body quantum systems."}
{"id": "2601.23034", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.23034", "abs": "https://arxiv.org/abs/2601.23034", "authors": ["Yungi Jeong", "Takumi Otsuka"], "title": "Breaking the Stochasticity Barrier: An Adaptive Variance-Reduced Method for Variational Inequalities", "comment": null, "summary": "Stochastic non-convex non-concave optimization, formally characterized as Stochastic Variational Inequalities (SVIs), presents unique challenges due to rotational dynamics and the absence of a global merit function. While adaptive step-size methods (like Armijo line-search) have revolutionized convex minimization, their application to this setting is hindered by the Stochasticity Barrier: the noise in gradient estimation masks the true operator curvature, triggering erroneously large steps that destabilize convergence. In this work, we propose VR-SDA-A (Variance-Reduced Stochastic Descent-Ascent with Armijo), a novel algorithm that integrates recursive momentum (STORM) with a rigorous Same-Batch Curvature Verification mechanism. We introduce a theoretical framework based on a Lyapunov potential tracking the Operator Norm, proving that VR- SDA-A achieves an oracle complexity of O(epsilon -3) for finding an epsilon-stationary point in general Lipschitz continuous operators. This matches the optimal rate for non-convex minimization while uniquely enabling automated step-size adaptation in the saddle-point setting. We validate our approach on canonical rotational benchmarks and non-convex robust regression tasks, demonstrating that our method effectively suppresses limit cycles and accelerates convergence with reduced dependence on manual learning rate scheduling."}
{"id": "2601.22909", "categories": ["cond-mat.str-el", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.22909", "abs": "https://arxiv.org/abs/2601.22909", "authors": ["Mark Potts", "Roderich Moessner", "S. A. Parameswaran"], "title": "N-state Potts ices as generalizations of classical and quantum spin ice", "comment": "16 pages, 12 figures", "summary": "Classical and quantum spin ice models are amongst the most popular settings for the study of spin liquid physics. $N-$state Potts ice models have been constructed that generalize spin ice, hosting multiple emergent $\\text{U}(1)$ gauge fields and excitations charged under non-trivial combinations of these fields. We present a general treatment of classical $N-$state Potts ices relating their properties to the $\\mathfrak{su}(N)$ Lie algebras, and demonstrate how the properties of charged excitations in the classical model can be related to this symmetry group. We also introduce quantum generalizations of the Potts Ice models, and demonstrate how charge flavor changing interactions unique to $N>2$ models dominate their low energy physics. We further show how symmetries inherited from the $\\mathfrak{su}(N)$ can lead to flux vacuum frustration, greatly modifying the dynamical properties of charged excitations."}
{"id": "2601.23150", "categories": ["quant-ph", "cond-mat.str-el", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.23150", "abs": "https://arxiv.org/abs/2601.23150", "authors": ["J. M. Alcaine-Cuervo", "S. Pradhan", "E. Rico", "Z. Shi", "C. M. Wilson"], "title": "Compact U(1) Lattice Gauge Theory in Superconducting Circuits with Infinite-Dimensional Local Hilbert Spaces", "comment": "21 pages, 12 figures", "summary": "We propose a superconducting-circuit architecture that realizes a compact U(1) lattice gauge theory using the intrinsic infinite-dimensional Hilbert space of phase and charge variables. The gauge and matter fields are encoded directly in the degrees of freedom of the rotor variables associated with the circuit nodes, and Gauss's law emerges exactly from the conservation of local charge, without auxiliary stabilizers, penalty terms, or Hilbert-space truncation. A minimal gauge-matter coupling arises microscopically from Josephson nonlinearities, whereas the magnetic plaquette interaction is generated perturbatively via virtual matter excitations. Numerical diagonalization confirms the emergence of compact electrodynamics and coherent vortex excitations, underscoring the need for large local Hilbert spaces in the continuum regime. The required circuit parameters are within the current experimental capabilities. Our results establish superconducting circuits as a scalable, continuous-variable platform for analog quantum simulation of non-perturbative gauge dynamics."}
{"id": "2601.23237", "categories": ["math.NA", "cs.MS"], "pdf": "https://arxiv.org/pdf/2601.23237", "abs": "https://arxiv.org/abs/2601.23237", "authors": ["Simon Dirckx"], "title": "Applications of QR-based Vector-Valued Rational Approximation", "comment": null, "summary": "Several applications of the QR-AAA algorithm, a greedy scheme for vector-valued rational approximation, are presented. The focus is on demonstrating the flexibility and practical effectiveness of QR-AAA in a variety of computational settings, including Stokes flow computation, multivariate rational approximation, function extension, the development of novel quadrature methods and near-field approximation in the boundary element method."}
{"id": "2601.22553", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22553", "abs": "https://arxiv.org/abs/2601.22553", "authors": ["Andrey R. Kolovsky"], "title": "Analysis of self-thermalization dynamics in the Bose-Hubbard model by using the pseudoclassical approach", "comment": "7 pages, 6 figures", "summary": "We analyze the self-thermalization dynamics of the $M$-site Bose-Hubbard model in terms of the single-particle density matrix that is calculated by using the pseudoclassical approach. It is shown that a weak inter-particle interaction, which suffices to convert the integrable system of non-interacting bosons into a chaotic system, has a negligible effect on the thermal density matrix given by the Bose-Einstein distribution. This opens the door for equilibration where the two coupled Bose-Hubbard systems, which are initially in different thermal states, relax to the same thermal state. When we couple these two subsystems by using a lattice of the length $L\\ll M$, we numerically calculate the quasi-stationary current of Bose particles across the lattice and show that its magnitude is consistent with the solution of the master equation for the boundary driven $L$-site Bose-Hubbard model."}
{"id": "2601.23035", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.23035", "abs": "https://arxiv.org/abs/2601.23035", "authors": ["Samir Adly", "Vinh Thanh Ho", "Huu Nhan Nguyen"], "title": "Accelerated Inertial Gradient Algorithms with Vanishing Tikhonov Regularization", "comment": null, "summary": "In this paper, we study an explicit Tikhonov-regularized inertial gradient algorithm for smooth convex minimization with Lipschitz continuous gradient. The method is derived via an explicit time discretization of a damped inertial system with vanishing Tikhonov regularization. Under appropriate control of the decay rate of the Tikhonov term, we establish accelerated convergence of the objective values to the minimum together with strong convergence of the iterates to the minimum-norm minimizer. In particular, for polynomial schedules $\\varepsilon_k = k^{-p}$ with $0<p<2$, we prove strong convergence to the minimum-norm solution while preserving fast objective decay. In the critical case $p=2$, we still obtain fast rates for the objective values, while our analysis does not guarantee strong convergence to the minimum-norm minimizer. Furthermore, we provide a thorough theoretical analysis for several choices of Tikhonov schedules. Numerical experiments on synthetic, benchmark, and real datasets illustrate the practical performance of the proposed algorithm."}
{"id": "2601.23241", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.23241", "abs": "https://arxiv.org/abs/2601.23241", "authors": ["Damien Barbier"], "title": "When low-loss paths make a binary neuron trainable: detecting algorithmic transitions with the connected ensemble", "comment": null, "summary": "We study the connected ensemble, a statistical-mechanics framework that characterizes the formation of low-loss paths in rugged landscapes. First introduced in a previous paper, this ensemble allows one to identify when a network can be trained on a simple task and which minima should be targeted during training. We apply this new framework to the symmetric binary perceptron model (SBP), and study how its typical {connected} minima behave. We show that {connected} minima exist only above a critical threshold $κ_{\\rm connected}$, or equivalently below a critical constraint density $α_{\\rm connected}$. This defines a parameter range in which training the network is easy, as local algorithms can efficiently access this connected manifold. We also highlight that these minima become increasingly robust and closer to one another as the task on which the network is trained becomes more difficult."}
{"id": "2601.23244", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.23244", "abs": "https://arxiv.org/abs/2601.23244", "authors": ["Hailiang Liu", "Laura Zinnel"], "title": "A Primal-Dual Level Set Method for Computing Geodesic Distances", "comment": "27 pages, 10 figures", "summary": "The numerical computation of shortest paths or geodesics on surfaces, along with the associated geodesic distance, has a wide range of applications. Compared to Euclidean distance computation, these tasks are more complex due to the influence of surface geometry on the behavior of shortest paths. This paper introduces a primal-dual level set method for computing geodesic distances. A key insight is that the underlying surface can be implicitly represented as a zero level set, allowing us to formulate a constraint minimization problem. We employ the primal-dual methodology, along with regularization and acceleration techniques, to develop our algorithm. This approach is robust, efficient, and easy to implement. We establish a convergence result for the high-resolution PDE system, and numerical evidence suggests that the method converges to a geodesic in the limit of refinement."}
{"id": "2601.22562", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22562", "abs": "https://arxiv.org/abs/2601.22562", "authors": ["Qian Sun", "Yuedong Sun", "Yu Hu", "Yihan Ma", "Runqi Han", "Nan Jiang"], "title": "Towards Sample Efficient Entanglement Classification for 3 and 4 Qubit Systems: A Tailored CNN-BiLSTM Approach", "comment": null, "summary": "Accurate classification of multipartite entanglement in high-dimensional quantum systems is crucial for advancing quantum communication and information processing. However, conventional methods are resource-intensive, and even many machine-learning-based approaches necessitate large training datasets, creating a significant experimental bottleneck for data acquisition. To address this challenge, we propose a hybrid neural network architecture integrating Convolutional and Bidirectional Long Short-Term Memory networks (CNN-BiLSTM). This design leverages CNNs for local feature extraction and BiLSTMs for sequential dependency modeling, enabling robust feature learning from minimal training data. We investigate two fusion paradigms: Architecture 1 (flattening-based) and Architecture 2 (dimensionality-transforming). When trained on only 100 samples, Architecture 2 maintains classification accuracies exceeding 90% for both 3-qubit and 4-qubit systems, demonstrating rapid loss convergence within tens of epochs. Under full-data conditions (400 000 samples), both architectures achieve accuracies above 99.97%. Comparative benchmarks reveal that our CNN-BiLSTM models, especially Architecture 2, consistently outperform standalone CNNs, BiLSTMs, and MLPs in low-data regimes, albeit with increased training time. These results demonstrates that the tailored CNN-BiLSTM fusion significantly alleviates experimental data acquisition burden, offering a practical pathway toward scalable entanglement verification in complex quantum systems."}
{"id": "2601.23036", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.23036", "abs": "https://arxiv.org/abs/2601.23036", "authors": ["Federico Cannerozzi"], "title": "Stationary Mean-Field singular control of an Ornstein-Uhlenbeck process", "comment": "22 pages, 3 figures", "summary": "Motivated by continuous-time optimal inventory management, we study a class of stationary mean-field control problems with singular controls. The dynamics are modeled by a mean-reverting Ornstein-Uhlenbeck process, and the performance criterion is given by a quadratic long-time average expected cost functional. The mean-field dependence is through the stationary mean of the controlled process itself, which enters the ergodic cost functional. We characterize the solution to the stationary mean-field control problem in terms of the equilibria of an associated stationary mean-field game, showing that solutions of the control problem are in bijection with the equilibria of this mean-field game. Finally, we solve the stationary mean-field game explicitly, thereby providing a solution to the original stationary mean-field control problem."}
{"id": "2601.23269", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.23269", "abs": "https://arxiv.org/abs/2601.23269", "authors": ["Ismael Ben-Yelun", "Mohammed El Fallaki Idrissi", "Jad Mounayer", "Sebastian Rodriguez", "Francisco Chinesta"], "title": "Rank Reduction AutoEncoders for Mechanical Design: Advancing Novel and Efficient Data-Driven Topology Optimization", "comment": null, "summary": "This work presents a data-driven framework for fast forward and inverse analysis in topology optimization (TO) by combining Rank Reduction Autoencoders (RRAEs) with neural latent-space mappings. The methodology targets the efficient approximation of the relationship between optimized geometries and their corresponding mechanical responses or Quantity of Interest (QoI), with a particular focus on compliance-minimized linear elastic structures. High-dimensional TO results are first compressed using RRAEs, which encode the data into a low-rank approximation via Singular Value Decomposition (SVD), obtained in this sense the most important features that approximate the data. Separate RRAE models are trained for geometry and for different types of QoIs, including scalar metrics, one-dimensional stress fields, and full two-dimensional von Mises stress distributions. The resulting low-dimensional latent coefficients of the latent space are then related through multilayer perceptrons to address both direct problems -- predicting structural responses from geometry -- and inverse problems -- recovering geometries from prescribed performance targets. The proposed approach is demonstrated on a benchmark TO problem based on a half MBB beam, using datasets generated via density-based Solid Isotropic Material with Penalization (SIMP) optimization. Numerical results show that the framework enables accurate and computationally efficient surrogate models, with increasing robustness and fidelity as richer QoIs are considered. The methodology also provides a foundation for generative mechanical design by enabling the synthesis of new geometries and responses through latent-space exploration."}
{"id": "2601.22568", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22568", "abs": "https://arxiv.org/abs/2601.22568", "authors": ["Chen-Ming Bai", "Yu Luo"], "title": "Two-parameter bipartite entanglement measure", "comment": "28 pages, 6 figures", "summary": "Entanglement concurrence is an important bipartite entanglement measure that has found wide applications in quantum technologies. In this work, inspired by unified entropy, we introduce a two-parameter family of entanglement measures, referred to as the unified $(q,s)$-concurrence. Both the standard entanglement concurrence and the recently proposed $q$-concurrence emerge as special cases within this family. By combining the positive partial transposition and realignment criteria, we derive an analytical lower bound for this measure for arbitrary bipartite mixed states, revealing a connection to strong separability criteria. Explicit expressions are obtained for the unified $(q,s)$-concurrence in the cases of isotropic and Werner states under the constraint $q>1$ and $qs\\geq 1$. Furthermore, we explore the monogamy properties of the unified $(q,s)$-concurrence for $q\\geq 2$, $0\\leq s\\leq 1$ and $1\\leq qs\\leq 3$, in qubit systems. In addition, we derive an entanglement polygon inequality for the unified $(q,s)$-concurrence with $q\\geq 1$ and $qs\\geq 1$, which manifests the relationship among all the marginal entanglements in any multipartite qudit system."}
{"id": "2601.23120", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.23120", "abs": "https://arxiv.org/abs/2601.23120", "authors": ["Bohan Zhang", "Xiaojun Zhang"], "title": "A General Tikhonov Regularized Second-Order Dynamical System for Convex-Concave Bilinear Saddle Point Problems", "comment": null, "summary": "In this paper, we propose a general Tikhonov regularized second-order dynamical system with viscous damping, time scaling and extrapolation coefficients for the convex-concave bilinear saddle point problem. By the Lyapunov function approach, we show that the convergence properties of the proposed dynamical system depend on the choice of the Tikhonov regularization parameter. Specifically, when the Tikhonov regularization parameter tends to zero rapidly, the convergence rate of the primal-dual gap along the generated trajectory is O(1 over t squared times beta(t)); when the Tikhonov regularization parameter tends to zero slowly, the convergence rate of the primal-dual gap is o(1 over beta(t)). We also prove the strong convergence property of the trajectory generated by the Tikhonov regularized dynamical system to the minimum-norm solution of the convex-concave bilinear saddle point problem, and derive several integral estimates. In addition, the effectiveness of the proposed dynamical system is verified through a series of numerical experiments."}
{"id": "2601.22200", "categories": ["q-fin.ST", "cs.LG", "cs.MS", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22200", "abs": "https://arxiv.org/abs/2601.22200", "authors": ["Luis Ontaneda Mijares", "Nick Firoozye"], "title": "Adaptive Benign Overfitting (ABO): Overparameterized RLS for Online Learning in Non-stationary Time-series", "comment": "32 pages, 3 figures, 10 tables", "summary": "Overparameterized models have recently challenged conventional learning theory by exhibiting improved generalization beyond the interpolation limit, a phenomenon known as benign overfitting. This work introduces Adaptive Benign Overfitting (ABO), extending the recursive least-squares (RLS) framework to this regime through a numerically stable formulation based on orthogonal-triangular updates. A QR-based exponentially weighted RLS (QR-EWRLS) algorithm is introduced, combining random Fourier feature mappings with forgetting-factor regularization to enable online adaptation under non-stationary conditions. The orthogonal decomposition prevents the numerical divergence associated with covariance-form RLS while retaining adaptability to evolving data distributions. Experiments on nonlinear synthetic time series confirm that the proposed approach maintains bounded residuals and stable condition numbers while reproducing the double-descent behavior characteristic of overparameterized models. Applications to forecasting foreign exchange and electricity demand show that ABO is highly accurate (comparable to baseline kernel methods) while achieving speed improvements of between 20 and 40 percent. The results provide a unified view linking adaptive filtering, kernel approximation, and benign overfitting within a stable online learning framework."}
{"id": "2601.22583", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22583", "abs": "https://arxiv.org/abs/2601.22583", "authors": ["Chen-Ming Bai", "Yu Luo"], "title": "Multipartite entanglement measures based on the thermodynamic framework", "comment": "12 pages, 5 figures", "summary": "In this work, we introduce a unified method to characterize and measure multipartite entanglement using the framework of thermodynamics. A family of the new entanglement measures is proposed: \\textit{ergotropic-gap concentratable entanglement}. Furthermore, we establish that ergotropic-gap concentratable entanglement constitutes a well-defined entanglement measure within a specific parameter regime, satisfying key properties including continuity, majorization monotonicity and monogamy. We demonstrate the utility of this measure by showing it effectively distinguishes between multi-qubit Greenberger-Horne-Zeilinger states and W states. It also proves effective in detecting entanglement in specific classes of four-partite star quantum network states."}
{"id": "2601.23187", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.23187", "abs": "https://arxiv.org/abs/2601.23187", "authors": ["Hanqing Jin", "Yanzhao Yang"], "title": "General Optimal Stopping without Time Consistency", "comment": "23 pages", "summary": "In this paper, we propose a new framework for solving a general dynamic optimal stopping problem without time consistency. A sophisticated solution is proposed and is well-defined for any time setting with general flows of objectives. A backward iteration is proposed to find the solution. The iteration works with an additional condition, which holds in interesting cases including the time inconsistency arising from non-exponential discounting. Even if the iteration does not work, the equilibrium solution can still be studied by a forward definition."}
{"id": "2601.22640", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2601.22640", "abs": "https://arxiv.org/abs/2601.22640", "authors": ["Qihang Ye", "Qihang Ye", "Bing Miao", "Lei Ying"], "title": "Unconventional Distance Scaling of Casimir-Polder Force between Atomic Arrays", "comment": "Submitted to Physical Review Letters", "summary": "Conventionally, dispersion forces mediated by quantum vacuum fluctuations are known to exhibit universal distance scalings, with retardation typically leading to a faster decay of the interaction. Here, we show that this expectation fails for intrinsically discrete systems. Using the microscopic scattering approach, we study the Casimir-Polder interaction between two atomic arrays, and uncover an unconventional distance scaling in which the force crosses over from a faster decay at short separations to a slower decay in the retarded regime. This behavior originates from the discrete lattice structure and can be consistently understood within the scattering picture. Extending our analysis to Rydberg atomic arrays, we predict an even stronger deviation from conventional scaling and propose an experimentally feasible scheme for direct measurement. Our results provide a new platform for exploring dispersion forces beyond the continuum limit."}
{"id": "2601.23249", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.23249", "abs": "https://arxiv.org/abs/2601.23249", "authors": ["Hongyu Cheng", "Amitabh Basu"], "title": "Theoretical Challenges in Learning for Branch-and-Cut", "comment": null, "summary": "Machine learning is increasingly used to guide branch-and-cut (B&C) for mixed-integer linear programming by learning score-based policies for selecting branching variables and cutting planes. Many approaches train on local signals from lookahead heuristics such as strong branching, and linear programming (LP) bound improvement for cut selection. Training and evaluation of the learned models often focus on local score accuracy. We show that such local score-based methods can lead to search trees exponentially larger than optimal tree sizes, by identifying two sources of this gap. The first is that these widely used expert signals can be misaligned with overall tree size. LP bound improvement can select a root cut set that yields an exponentially larger strong branching tree than selecting cuts by a simple proxy score, and strong branching itself can be exponentially suboptimal (Dey et al., 2024). The second is that small discrepancies can be amplified by the branch-and-bound recursion. An arbitrarily small perturbation of the right-hand sides in a root cut set can change the minimum tree size from a single node to exponentially many. For branching, arbitrarily small score discrepancies, and differences only in tie-breaking, can produce trees of exponentially different sizes, and even a small number of decision differences along a trajectory can incur exponential growth. These results show that branch-and-cut policies trained and learned using local expert scores do not guarantee small trees, thus motivating the study of data-driven methods that produce policies better aligned with tree size rather than only accuracy on expert scores."}
{"id": "2601.22697", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.22697", "abs": "https://arxiv.org/abs/2601.22697", "authors": ["Yong Zhang"], "title": "A complex-linear reformulation of Hamilton--Jacobi theory and the emergence of quantum structure", "comment": "9+5 pages, 3 figures, 1 table", "summary": "Classical mechanics admits multiple equivalent formulations, from Newton's equations to the variational Lagrange-Hamilton framework and the scalar Hamilton-Jacobi (HJ) theory. In the HJ formulation, classical ensembles evolve through the continuity equation for a real density $ρ= R^{2}$ coupled to Hamilton's principal function $S$. Here we develop a complementary formulation, the Hamilton-Jacobi-Schrödinger (HJS) theory, by embedding the pair $(R,S)$ into a single complex field. Starting from a completely general complex ansatz $ψ= f(R,S) e^{i g(R,S)}$, and imposing two minimal structural requirements, we obtain a unique map $ψ= R e^{iS/κ}$ together with a linear HJS equation whose $|κ| \\to 0$ limit reproduces the HJ formulation exactly. Remarkably, when $\\mathrm{Re}(κ)\\neq 0$, essential features of quantum mechanics, including superposition, operator algebra, commutators, the Heisenberg uncertainty principle, Born's rule, and unitary evolution, arise naturally as consistency conditions. HJS thus provides a unified mathematical viewpoint in which classical and quantum dynamics appear as different limits of a single underlying structure."}
{"id": "2601.22349", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.22349", "abs": "https://arxiv.org/abs/2601.22349", "authors": ["Andreas Habring", "Martin Zach"], "title": "Forward-KL Convergence of Time-Inhomogeneous Langevin Diffusions", "comment": null, "summary": "Many practical samplers rely on time-dependent drifts -- often induced by annealing or tempering schedules -- to improve exploration and stability. This motivates a unified non-asymptotic analysis of the corresponding Langevin diffusions and their discretizations. We provide a convergence analysis that includes non-asymptotic bounds for the continuous-time diffusion and its Euler--Maruyama discretization in the forward-Kullback--Leibler divergence under a single set of abstract conditions on the time-dependent drift. The results apply to many practically-relevant annealing schemes, including geometric tempering and annealed Langevin sampling. In addition, we provide numerical experiments comparing the annealing schemes covered by our theory in low- and high-dimensional settings."}
{"id": "2601.22785", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22785", "abs": "https://arxiv.org/abs/2601.22785", "authors": ["Raam Uzdin"], "title": "Orders of magnitude runtime reduction in quantum error mitigation", "comment": null, "summary": "Quantum error mitigation (QEM) infers noiseless expectation values by combining outcomes from intentionally modified, noisy variants of a target quantum circuit. Unlike quantum error correction, QEM requires no additional hardware resources and is therefore routinely employed in experiments on contemporary quantum processors. A central limitation of QEM is its substantial sampling overhead, which necessitates long execution times where device noise may drift, potentially compromising the reliability of standard mitigation protocols. QEM strategies based on agnostic noise amplification (ANA) are intrinsically resilient to such noise variations, but their sampling cost remains a major practical bottleneck. Here we introduce a mitigation framework that combines virtual noise scaling with a layered mitigation architecture, yielding orders of magnitude reduction in runtime overhead compared to conventional zero-noise extrapolation post-processing. The proposed approach is compatible with dynamic circuits and can be seamlessly integrated with error detection and quantum error correction schemes. In addition, it naturally extends to ANA-based mitigation of mid-circuit measurements and preparation errors. We validate our post-processing approach by applying it to previously reported experimental data, where we observe a substantial improvement in mitigation efficiency and accuracy."}
{"id": "2601.22605", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.22605", "abs": "https://arxiv.org/abs/2601.22605", "authors": ["Falai Chen", "Buyang Li", "Jiajie Li", "Rong Tang"], "title": "An inertial minimal-deformation-rate framework for shape optimization", "comment": "26 pages, 12 figures", "summary": "We propose a robust numerical framework for PDE-constrained shape optimization and Willmore-driven surface hole filling. To address two central challenges -- slow progress in flat energy landscapes, which can trigger premature stagnation at suboptimal configurations, and mesh deterioration during geometric evolution -- we couple a second-order inertial flow with a minimal-deformation-rate (MDR) mesh motion strategy. This coupling accelerates convergence while preserving mesh quality and thus avoids remeshing. To further enhance robustness for non-smooth or non-convex initial geometries, we incorporate surface-diffusion regularization within the Barrett-Garcke-N\"urnberg (BGN) framework. Moreover, we extend the inertial MDR methodology to Willmore-type surface hole filling, enabling high-order smooth reconstructions even from incompatible initial data. Numerical experiments demonstrate markedly faster convergence to lower original objective values, together with consistently superior mesh preservation throughout the evolution."}
{"id": "2601.22798", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.22798", "abs": "https://arxiv.org/abs/2601.22798", "authors": ["G. Pooseh"], "title": "Scattering of Squeezed Light by a Dielectric Slab", "comment": "24 pages, 7 figures", "summary": "We develop a quantum theory for the scattering of squeezed coherent light by a dissipative dielectric slab. Using the Green-function quantization approach, we derive the transformation of the field quadratures and show how dispersion, absorption, and multiple reflections distort the incident squeezing. We find that the slab can selectively attenuate or amplify quadrature noise depending on the slab parameters and provide expressions for the output power spectra."}
{"id": "2601.23160", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.23160", "abs": "https://arxiv.org/abs/2601.23160", "authors": ["Marko Nonhoff", "Mohammad Taher Al Torshan", "Matthias A. Müller"], "title": "Robust Control of Constrained Linear Systems using Online Convex Optimization and a Reference Governor", "comment": "Presented at 2024 IEEE 63rd Conference on Decision and Control (CDC)", "summary": "This article develops a control method for linear time-invariant systems subject to time-varying and a priori unknown cost functions, that satisfies state and input constraints, and is robust to exogenous disturbances. To this end, we combine the online convex optimization framework with a reference governor and a constraint tightening approach. The proposed framework guarantees recursive feasibility and robust constraint satisfaction. Its closed-loop performance is studied in terms of its dynamic regret, which is bounded linearly by the variation of the cost functions and the magnitude of the disturbances. The proposed method is illustrated by a numerical case study of a tracking control problem."}
{"id": "2601.22821", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22821", "abs": "https://arxiv.org/abs/2601.22821", "authors": ["Alex Elliott", "Takao Aoki", "Scott Parkins"], "title": "Steady-State Emission of Quantum-Correlated Light in the Telecom Band from a Single Atom", "comment": null, "summary": "We propose and investigate a scheme for the steady-state emission of quantum-correlated, telecom-band light from a single multilevel atom. By appropriately tuning the frequency of a pair of lasers, a two-photon transition is continually driven to an atomic excited state that emits photons at the desired wavelength. We show that resonantly coupling a cavity mode to the telecom transition can enhance the rate of emission while retaining the antibunched counting statistics that are characteristic of atomic light sources. We also explore coupling a second, independent cavity mode to the atom, which increases the telecom emission rate and introduces quantum correlations between the cavity modes. A model for the hyperfine structure of a single cesium atom is then described and numerically integrated to demonstrate the viability of implementing the scheme with a modern cavity QED system."}
{"id": "2601.23244", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.23244", "abs": "https://arxiv.org/abs/2601.23244", "authors": ["Hailiang Liu", "Laura Zinnel"], "title": "A Primal-Dual Level Set Method for Computing Geodesic Distances", "comment": "27 pages, 10 figures", "summary": "The numerical computation of shortest paths or geodesics on surfaces, along with the associated geodesic distance, has a wide range of applications. Compared to Euclidean distance computation, these tasks are more complex due to the influence of surface geometry on the behavior of shortest paths. This paper introduces a primal-dual level set method for computing geodesic distances. A key insight is that the underlying surface can be implicitly represented as a zero level set, allowing us to formulate a constraint minimization problem. We employ the primal-dual methodology, along with regularization and acceleration techniques, to develop our algorithm. This approach is robust, efficient, and easy to implement. We establish a convergence result for the high-resolution PDE system, and numerical evidence suggests that the method converges to a geodesic in the limit of refinement."}
{"id": "2601.22833", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22833", "abs": "https://arxiv.org/abs/2601.22833", "authors": ["Emilio Santos"], "title": "Are Bell's conditions for local realism general enough?", "comment": "12 pages, no figures", "summary": "Bell conditions for local realism are critically revisited. In particular for optical experiments I criticize Bell's proposed response of detectors to signals as extremely idealized. More physical conditions are proposed, whence a realistic local model of an optical experiment is possible which violates the Clauser-Horne (Bell) inequality. The possibility rests on the existence of a coincidence-time loophole in the experiments."}
{"id": "2601.22863", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22863", "abs": "https://arxiv.org/abs/2601.22863", "authors": ["Walter F. Wreszinski"], "title": "Dynamics of states of infinite quantum systems as a cornerstone of the second law of thermodynamics", "comment": "31 pages, one figure", "summary": "We improve on our version of the second law of thermodynamics as a deterministic theorem for quantum spin systems in two basic aspects. The first concerns the general statement of the second law: spontaneous changes in an adiabatically closed system will always be in the direction of increasing mean entropy, which rises to a maximal value. Two specific examples concern the transition from pure to mixed states in two different universality classes of dynamics in one dimension, one being the exponential model, the other the Dyson model, the dynamics of the latter exhibiting strong graphical evidence of quantum chaos, as a consequence of the results of Albert and Kiessling on the Cloitre function."}
{"id": "2601.22939", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22939", "abs": "https://arxiv.org/abs/2601.22939", "authors": ["Dominic J. Williamson"], "title": "Fast magic state preparation by gauging higher-form transversal gates in parallel", "comment": "16 pages, 5 figures", "summary": "Magic states are a foundational resource for universal quantum computation. To survive in a realistic noisy environment, magic states must be prepared fault-tolerantly and protected by a quantum error-correcting code. The recent discovery of highly efficient quantum low-density parity-check codes, together with efficient logic gates, lays the groundwork for low-overhead fault-tolerant quantum computation. This motivates the search for fast and parallel protocols for logical magic state preparation to enable universal quantum computation. Here, we introduce a fast code surgery procedure that performs a fault-tolerant measurement of many transversal logic gates in parallel. This is achieved by performing a generalized gauging measurement on a quantum code that supports a higher-form transversal gate. The time overhead of our procedure is constant, and the qubit overhead is linear. The procedure inherits fault-tolerance properties from the base code and the structure of the higher-form transversal gate. When applied to codes that support higher-form Clifford gates our procedure achieves fast and fault-tolerant preparation of many magic states in parallel. This motivates the search for good quantum low-density parity-check codes that support higher-form Clifford gates."}
{"id": "2601.23028", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.23028", "abs": "https://arxiv.org/abs/2601.23028", "authors": ["Chen-You Su", "Kaiyi Wu", "Lucas M. Cohen", "Saleha Fatema", "Navin B. Lingaraju", "Hsuan-Hao Lu", "Andrew M. Weiner", "Joseph M. Lukens", "Jason D. McKinney"], "title": "High-resolution tunable frequency beamsplitter enabled by an integrated silicon pulse shaper", "comment": "15 pages, 7 figures", "summary": "We demonstrate high-fidelity, tunable, and ultrafine-resolution on-chip frequency beamsplitters using a quantum frequency processor based on an integrated pulse shaper with six spectral channels. Near-ideal Hadamard gate performance is achieved, with fidelity F > 0.9995 and modified success probability P > 0.9621 maintained across frequency spacings from 2-5 GHz and down to as few as four spectral pulse shaper channels. The system's support of frequency spacings as narrow as 2 GHz significantly surpasses prior bulk demonstrations and enables arbitrary splitting ratios via spectral phase or modulation index control. These results establish a scalable and resource-efficient platform for integrated frequency-bin quantum photonics, opening new directions in quantum information processing, including densely parallel single-qubit operations and multidimensional gate implementations."}
{"id": "2601.23043", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.23043", "abs": "https://arxiv.org/abs/2601.23043", "authors": ["Sudha", "B. N. Karthik", "K. S. Akhilesh", "A. R. Usha Devi"], "title": "Dicke superposition probes for noise-resilient Heisenberg and super-Heisenberg Metrology", "comment": "14 pages, 17 figures", "summary": "Phase sensing with entangled multiqubit states in the presence of noise is a central theme of modern quantum metrology. The present work investigates Dicke state superposition probes for quantum phase sensing under parameter encoding generated by one- and two-body interaction Hamiltonians. A class of N-qubit Dicke superposition states that exhibit near-Heisenberg scaling, of the quantum Fisher information, while maintaining significantly enhanced robustness to dephasing noise compared to GHZ, W-superposition, and balanced Dicke states, under unitary encodings generated by one-body interaction Hamiltonians are identified. For two-body interactions, Dicke superposition probes optimizing the quantum Fisher information are identified, and their performance under phase-damping, amplitude-damping, and global depolarizing noise is explored. Within this family, certain Dicke superpositions are found to combine super-Heisenberg scaling with improved resilience to phase damping relative to Fisher information optimal probes. These results establish tailored near-optimal Dicke-state superposition probes as versatile and noise-resilient resources for Heisenberg and super-Heisenberg quantum phase sensing governed by one- and two-body interactions."}
{"id": "2601.23044", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.23044", "abs": "https://arxiv.org/abs/2601.23044", "authors": ["Chaehyeon Lim", "Hyungchul Park", "Beomjoon Chae", "Jeonghun Kwak", "Soo-Yeon Lee", "Namkyoo Park", "Sunkyu Yu"], "title": "Scalable Memory Sharing in Photonic Quantum Memristors for Reservoir Computing", "comment": null, "summary": "Although photons are robust, room-temperature carriers well suited to quantum machine learning, the absence of photon-photon interactions hinder the realization of memory functionalities that are critical for capturing long-range context. Recently, measurement-based implementations of photonic quantum memristors (PQMRs) have enabled tunable non-Markovian responses. However, their memory remains confined to local elements, in contrast to biological or artificial networks where memory is shared across the system. Here, we propose a scalable PQMR network that enables measurement-based memory sharing. Each memristive node updates its internal state using the history of its own and neighbouring quantum states, thereby realizing distributed memory. By modelling each node as a photonic quantum memtransistor, we demonstrate pronounced enhancements in both classical and quantum hysteresis at the device level, as well as enhanced network-level quantum hysteresis. Implemented as a quantum reservoir, the architecture achieves improved Fashion-MNIST classification accuracy and confidence via increased data separability. Our approach paves the way toward high-capacity quantum machine learning using memristive devices compatible with linear-optical quantum computing."}
{"id": "2601.23084", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.23084", "abs": "https://arxiv.org/abs/2601.23084", "authors": ["Saarisha Govender", "Ilya Sinayskiy"], "title": "Margin-Based Generalisation Bounds for Quantum Kernel Methods under Local Depolarising Noise", "comment": "30 pages, 13 figures", "summary": "Generalisation refers to the ability of a machine learning (ML) model to successfully apply patterns learned from training data to new, unseen data. Quantum devices in the current Noisy Intermediate-Scale Quantum (NISQ) era are inherently affected by noise, which degrades generalisation performance. In this work, we derive upper and lower margin-based generalisation bounds for Quantum Kernel-Assisted Support Vector Machines (QSVMs) under local depolarising noise. These theoretical bounds characterise noise-induced margin decay and are validated via numerical simulations across multiple datasets, as well as experiments on real quantum hardware. We further justify the focus on margin-based measures by empirically establishing margins as a reliable indicator of generalisation performance for QSVMs. Additionally, we motivate the study of local depolarising noise by presenting empirical evidence demonstrating that the commonly used global depolarising noise model is overly optimistic and fails to accurately capture the degradation of generalisation performance observed in the NISQ era."}
{"id": "2601.23109", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.23109", "abs": "https://arxiv.org/abs/2601.23109", "authors": ["Junyu Zhou", "Yuhao Liu", "Ethan Decker", "Justin Kalloor", "Mathias Weiden", "Kean Chen", "Costin Iancu", "Gushu Li"], "title": "TopoLS: Lattice Surgery Compilation via Topological Program Transformations", "comment": null, "summary": "Fault-tolerant quantum computing with surface codes can be achieved by compiling logical circuits into lattice-surgery instructions. To minimize space-time volume, we present TopoLS, a topological compiler that combines ZX-diagram optimizations with Monte Carlo tree search guided by different operation placements and topology-aware circuit partitioning. Our approach enables scalable exploration of lattice surgery structures and consistently reduces resource overhead. Evaluations of various benchmark algorithms across multiple architectures show that TopoLS achieves an average 33% reduction in space-time volume over prior heuristic-based compilers, while maintaining linear compilation time scaling. Compared to the SAT-solver-based compiler, which provides optimal results only for small circuits before becoming intractable, TopoLS offers an effective and scalable solution for lattice-surgery compilation."}
{"id": "2601.23116", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.23116", "abs": "https://arxiv.org/abs/2601.23116", "authors": ["Shampa Mondal", "Soumajit Das", "Preeti Parashar", "Tamal Guha"], "title": "Free encoding capacity: A universal unit for quantum resources", "comment": "4.5 pages + 4.5 pages, 4 Figs. Comments are welcome", "summary": "A perfect d-dimensional quantum channel can convey log d-bits of classical information by encoding messages in d-orthogonal quantum states. Alternatively, for every quantum state at the senders end, there exist d-encoding operations which produce d-orthogonal quantum states. Transmitting which via a d-level perfect quantum channel it is possible to communicate log d-bits of classical information. But what if the set of encoding operations is restricted only within a physically constrained class? Here, we consider such a class of encoding operations to be the set of free operations for any quantum resource theory and show that the constrained capacity - namely, the free encoding capacity (FEC) emerged as a unit of the corresponding quantum resource. Moreover, we show that for the pointed resource theories - a resource theory admitting only a single free state - FEC becomes a faithful resource measure also. We also discuss the implications of FEC in the question of resource-theoretic state transformations and the possibility of extending its faithfulness for general quantum resource theories."}
{"id": "2601.23150", "categories": ["quant-ph", "cond-mat.str-el", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.23150", "abs": "https://arxiv.org/abs/2601.23150", "authors": ["J. M. Alcaine-Cuervo", "S. Pradhan", "E. Rico", "Z. Shi", "C. M. Wilson"], "title": "Compact U(1) Lattice Gauge Theory in Superconducting Circuits with Infinite-Dimensional Local Hilbert Spaces", "comment": "21 pages, 12 figures", "summary": "We propose a superconducting-circuit architecture that realizes a compact U(1) lattice gauge theory using the intrinsic infinite-dimensional Hilbert space of phase and charge variables. The gauge and matter fields are encoded directly in the degrees of freedom of the rotor variables associated with the circuit nodes, and Gauss's law emerges exactly from the conservation of local charge, without auxiliary stabilizers, penalty terms, or Hilbert-space truncation. A minimal gauge-matter coupling arises microscopically from Josephson nonlinearities, whereas the magnetic plaquette interaction is generated perturbatively via virtual matter excitations. Numerical diagonalization confirms the emergence of compact electrodynamics and coherent vortex excitations, underscoring the need for large local Hilbert spaces in the continuum regime. The required circuit parameters are within the current experimental capabilities. Our results establish superconducting circuits as a scalable, continuous-variable platform for analog quantum simulation of non-perturbative gauge dynamics."}
{"id": "2601.23243", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.23243", "abs": "https://arxiv.org/abs/2601.23243", "authors": ["Lisa T. Weinbrenner", "Albert Rico", "Kenneth Goodenough", "Xiao-Dong Yu", "Otfried Gühne"], "title": "Complete Hierarchies for the Geometric Measure of Entanglement", "comment": "16 pages, 6 figures", "summary": "In quantum physics, multiparticle systems are described by quantum states acting on tensor products of Hilbert spaces. This product structure leads to the distinction between product states and entangled states; moreover, one can quantify entanglement by considering the distance of a quantum state to the set of product states. The underlying optimization problem occurs frequently in physics and beyond, for instance in the computation of the injective tensor norm in multilinear algebra. Here, we introduce a method to determine the maximal overlap of a pure multiparticle quantum state with product states based on considering several copies of the pure state. This leads to three types of hierarchical approximations to the problem, all of which we prove to converge to the actual value. Besides allowing for the computation of the geometric measure of entanglement, our results can be used to tackle optimizations over stochastic local transformations, to find entanglement witnesses for weakly entangled bipartite states, and to design strong separability tests for mixed multiparticle states. Finally, our approach sheds light on the complexity of separability tests."}
{"id": "2601.23263", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.23263", "abs": "https://arxiv.org/abs/2601.23263", "authors": ["Martin Houde", "Franz Roeder", "Christine Silberhorn", "Benjamin Brecht", "Nicolás Quesada"], "title": "High-gain effects in broadband continuous-wave parametric down conversion sources and measurements with undetected photons", "comment": "19 pages, 16 figures, 3 appendices", "summary": "We study theoretically how high-gain effects affect the measurement outcome of visible signal spectra in undetected photon measurement schemes. We consider two interferometric configurations: firstly, the SU(1,1) interferometer where the idler incurs loss and additional dispersion in between two identical, lossless, squeezers; secondly, the induced coherence interferometer where the idler incurs loss and additional dispersion in between two identical, lossless, squeezers and where the second squeezer is seeded by the idler and a vacuum ancilla mode. Furthermore, we consider a distributed loss configuration where the idler incurs loss as it propagates in the nonlinear medium. Motivated by experimental evidence and due to the fact that broadband sources are ideal for these measurement schemes, we use the dispersive data of a third-order dispersion engineered integrated waveguide parametric down conversion (PDC) source presented in New Journal of Physics 26, 123025 (2024) to model the PDC spectra in the three configurations. For each configuration we consider the case of idler-only (i) absorption, (ii) additional dispersion, and (iii) the combined effects. We obtain results which outline the strength and weaknesses of the different configurations at different operation points."}
{"id": "2601.23277", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.23277", "abs": "https://arxiv.org/abs/2601.23277", "authors": ["Nirjhar Sarkar", "Ronan Gourgues", "Yueh-Chun Wu", "Chengyun Hua", "Katyayani Seal", "Andreas Fognini", "Steven Randolph", "Eugene Dumitrescu", "Gabor B. Halasz", "Benjamin Lawrie"], "title": "Understanding multiscale disorder in superconducting nanowire single photon detectors", "comment": null, "summary": "Superconducting nanowire single-photon detectors are central to applications across quantum information science. Yet, their performance is limited by the effects of disorder and electrodynamic inhomogeneities that are not well understood. By combining DC transport, dark-count measurements, and bias-dependent microwave transmission spectroscopy in the presence of controlled nanoscale disorder introduced through helium-ion irradiation, we distinguish local instability-driven processes from intrinsic superconducting depairing and kinetic inductance nonlinearities. This approach enables systematic tuning of kinetic inductance, depairing currents, microwave dissipation, and mode structure within a single device. Bias- and temperature-dependent resonance shifts quantify disorder-induced modifications of the superconducting density of states through the nonlinear kinetic inductance, while the emergence of multiple resonant modes reveals the formation of electrodynamically distinct superconducting regions. Comparing depairing under current, field, and temperature isolates the dominant microwave loss mechanisms, separating vortex, quasiparticle, and two-level-system contributions, thus providing a robust multifunctional foundation for disorder engineering of superconducting nanowire detectors and resonators."}
{"id": "2601.23283", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.23283", "abs": "https://arxiv.org/abs/2601.23283", "authors": ["Wenjie Gong", "Bingtian Ye", "Daniel Mark", "Soonwon Choi"], "title": "Robust multiparameter estimation using quantum scrambling", "comment": "8 + 47 pages; 3 + 7 figures", "summary": "We propose and analyze a versatile and efficient multiparameter quantum sensing protocol, which simultaneously estimates many non-commuting and time-dependent signals that are coherently or incoherently coupled to sensing particles. Even in the presence of control imperfections and readout errors, our approach can detect exponentially many parameters in the system size while maintaining the optimal scaling of sensitivity. To accomplish this, scrambling dynamics are leveraged to map distinct signals to unique patterns of bitstring measurements, which distinguishes a large number of signals without significant sensitivity loss. Based on this principle, we develop a computationally efficient protocol utilizing random global Clifford unitaries and evaluate its performance both analytically and numerically. Our protocol naturally extends to scrambling dynamics generated by random local Clifford circuits, local random unitary circuits (RUCs), and ergodic Hamiltonian evolution--commonly realized in near-term quantum hardware--and opens the door to applications ranging from precise noise benchmarking of quantum dynamics to learning time-dependent Hamiltonians."}
{"id": "2601.22188", "categories": ["physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22188", "abs": "https://arxiv.org/abs/2601.22188", "authors": ["Jonathon Sendall"], "title": "The Beta-Bound: Drift constraints for Gated Quantum Probabilities", "comment": "18 pages", "summary": "Quantum mechanics provides extraordinarily accurate probabilistic predictions, yet the framework remains silent on what distinguishes quantum systems from definite measurement outcomes. This paper develops a measurement-theoretic framework for projective gating. The central object is the $β$-bound, an inequality that controls how much probability assignments can drift when gating and measurement fail to commute. For a density operator $ρ$, projector $F$, and effect $E$, with gate-passage probability $s = {\\rm Tr}(ρF)$ and commutator norm $\\varepsilon = \\|[F, E]\\|$, the symmetric partial-gating drift satisfies $|Δp_F(E)| \\leq 2 \\sqrt{(1 - s)/s} \\cdot \\varepsilon$. The constant 2 is sharp. We introduce two diagnostic quantities: the coherence witness $W(ρ, F) = \\|F ρ(I - F)\\|_1$, measuring cross-boundary coherence, and the record fidelity gap $Δ_T(ρ_F, R)$, measuring expectation-value change under symmetrisation. Three experimental vignettes demonstrate falsifiability: Hong--Ou--Mandel interferometry, atomic energy-basis dephasing, and decoherence-induced classicality. The framework is operational and interpretation-neutral, compatible with Everettian, Bohmian, QBist, and collapse approaches. It provides quantitative structure that any interpretation must accommodate, along with a template for experimental tests."}
{"id": "2601.22375", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22375", "abs": "https://arxiv.org/abs/2601.22375", "authors": ["Bruno Bertini"], "title": "Non-Equilibrium Quantum Many-Body Physics with Quantum Circuits", "comment": "49 pages, 6 figures", "summary": "These are the notes for the 4.5-hour course with the same title that I delivered in August 2025 at the Les Houches summer school ``Exact Solvability and Quantum Information''. In these notes I pedagogically introduce the setting of brickwork quantum circuits and show that it provides a useful framework to study non-equilibrium quantum many-body dynamics in the presence of local interactions. I first show that brickwork quantum circuits evolve quantum correlations in a way that is fundamentally similar to local Hamiltonians, and then present examples of brickwork quantum circuits where, surprisingly, one can compute exactly several relevant dynamical and spectral properties in the presence of non-trivial interactions."}
{"id": "2601.23234", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.23234", "abs": "https://arxiv.org/abs/2601.23234", "authors": ["Riccardo Travaglino", "Federico Rottoli", "Pasquale Calabrese"], "title": "Entanglement Hamiltonians in dissipative free fermions and the time-dependent GGE", "comment": "20 pages+ appendices, 4 figures", "summary": "We investigate the dynamics of Entanglement Hamiltonians (EHs) in dissipative free-fermionic systems using a recent operator-based formulation of the quasiparticle picture. Focusing on gain and loss dissipation, we study the post-quench evolution and derive explicit expressions for the EH at the ballistic scale. In the long-time and weak-dissipation regime, the EH is shown to take the form of a time-dependent Generalized Gibbs Ensemble (t-GGE), with a structure that is universal across different initial states of the quench protocol. Within this framework, the emergence of the t-GGE is fully accounted for by the quasiparticle picture, and we argue that this description remains valid whenever the Lindbladian admits an appropriate coarse-grained representation."}
