<div id=toc></div>

# Table of Contents

- [stat.ME](#stat.ME) [Total: 8]
- [physics.soc-ph](#physics.soc-ph) [Total: 2]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 4]
- [eess.SY](#eess.SY) [Total: 5]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 4]
- [cs.ET](#cs.ET) [Total: 2]
- [math.ST](#math.ST) [Total: 5]
- [quant-ph](#quant-ph) [Total: 32]
- [nlin.CD](#nlin.CD) [Total: 1]
- [physics.hist-ph](#physics.hist-ph) [Total: 2]
- [physics.comp-ph](#physics.comp-ph) [Total: 2]
- [cs.CE](#cs.CE) [Total: 3]
- [q-fin.RM](#q-fin.RM) [Total: 2]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 3]
- [math.OC](#math.OC) [Total: 5]
- [q-fin.ST](#q-fin.ST) [Total: 1]
- [physics.geo-ph](#physics.geo-ph) [Total: 3]
- [math.NA](#math.NA) [Total: 8]


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [1] [Multi-Resolution Analysis of Variable Selection for Road Safety in St. Louis and Its Neighboring Area](https://arxiv.org/abs/2601.00147)
*Debjoy Thakur,Soumendra N. Lahiri*

Main category: stat.ME

TL;DR: 本文提出了一种多分辨率视角下的空间点过程数据变量选择方法，能够有效在局部水平上选择预测因子，并识别不同区域中犯罪或事故发生的相关因素。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于圣路易斯及其周边地区的犯罪与事故发生情况，传统的变量选择方法难以捕捉局部特征，因此需要一种能够在局部层面进行精确变量选择的方法。

Method: 采用多分辨率分析框架，结合惩罚函数法（如Lasso、Adaptive Lasso和SCAD），在空间点过程强度函数估计中实现变量选择，并识别在特定分辨率下影响预测因子选择的关键点。

Result: 通过模拟研究验证了该方法在局部水平变量选择中的准确性，能够有效识别不同区域内相关的预测因子。

Conclusion: 所提出的多分辨率方法不仅提升了变量选择的效率，还提供了空间局部解释能力，适用于城市公共安全等实际问题的分析。

Abstract: Generally, Lasso, Adaptive Lasso, and SCAD are standard approaches in variable selection in the presence of a large number of predictors. In recent years, during intensity function estimation for spatial point processes with a diverging number of predictors, many researchers have considered these penalized methods. But we have discussed a multi-resolution perspective for the variable selection method for spatial point process data. Its advantage is twofold: it not only efficiently selects the predictors but also provides the idea of which points are liable for selecting a predictor at a specific resolution. Actually, our research is motivated by the crime and accident occurrences in St. Louis and its neighborhoods. It is more relevant to select predictors at the local level, and thus we get the idea of which set of predictors is relevant for the occurrences of crime or accident in which parts of St. Louis. We describe the simulation results to justify the accuracy of local-level variable selection during intensity function estimation.

</details>


### [2] [Unmixing highly mixed grain size distribution data via maximum volume constrained end member analysis](https://arxiv.org/abs/2601.00154)
*Qianqian Qi,Zhongming Chen,Peter G. M. van der Heijden*

Main category: stat.ME

TL;DR: 提出最大体积约束的端元分析（MVC-EMA），可有效识别高度混合数据集中的真实端元。


<details>
  <summary>Details</summary>
Motivation: 传统端元分析在处理高度混合的粒径分布数据时，难以分离出真实的端元成分。

Method: 通过引入最大体积约束和唯一性定理，结合二次规划算法实现MVC-EMA。

Result: 实验结果表明，MVC-EMA能更有效地从高度混合数据中提取真实端元。

Conclusion: MVC-EMA在解析复杂沉积物来源与沉积过程方面具有优越性能。

Abstract: End member analysis (EMA) unmixes grain size distribution (GSD) data into a mixture of end members (EMs), thus helping understand sediment provenance and depositional regimes and processes. In highly mixed data sets, however, many EMA algorithms find EMs which are still a mixture of true EMs. To overcome this, we propose maximum volume constrained EMA (MVC-EMA), which finds EMs as different as possible. We provide a uniqueness theorem and a quadratic programming algorithm for MVC-EMA. Experimental results show that MVC-EMA can effectively find true EMs in highly mixed data sets.

</details>


### [3] [An exact unbiased semi-parametric L2 quasi-likelihood framework, complete in the presence of ties](https://arxiv.org/abs/2601.00188)
*Landon Hurley*

Main category: stat.ME

TL;DR: 提出了一种基于ℓ₂范数的拟似然框架，利用Kemeny度量空间和Whitney嵌入实现对离散和连续变量的无偏最小方差协方差估计，并扩展至多协变量Wilcoxon秩和检验，解决了有限样本下存在线性满射映射时的精确无偏识别问题。


<details>
  <summary>Details</summary>
Motivation: 传统最大似然估计需要预设误差分布以保证无偏性，而在实际应用中协方差矩阵估计需满足特定结构与正则性；现有方法在处理多协变量Wilcoxon检验及弱工具变量等问题时缺乏对有限样本无偏性的保障。

Method: 构建基于ℓ₂范数的拟似然框架，通过所有样本对之间的二项比较，在Kemeny度量空间中利用Whitney嵌入实现Hájek投影下的无偏线性回归估计，进而得到协方差矩阵的无偏最小方差估计，并推广至非参数形式的一般线性模型。

Result: 实现了对离散与连续随机变量在有限样本下的精确无偏、最小方差协方差估计；成功扩展Wilcoxon秩和检验以处理多个协变量并保持无偏识别，同时可应对未知异质性和弱推断工具问题。

Conclusion: 该方法提供了一种一致且非参数化的协方差估计与回归分析框架，在不依赖先验分布假设下仍能保证统计无偏性与有效性，拓展了经典线性模型的应用边界。

Abstract: Maximum likelihood style estimators possesses a number of ideal characteristics, but require prior identification of the distribution of errors to ensure exact unbiasedness. Independent of the focus of the primary statistical analysis, the estimation of a covariance matrix \(S^{P \times P}\approx Σ^{P \times P}\) must possess a specific structure and regularity constraints. The need to estimate a linear Gaussian covariance models appear in various applications as a formal precondition for scientific investigation and predictive analytics. In this work, we construct an \(\ell_{2}\)-norm based quasi-likelihood framework, identified by binomial comparisons between all pairs \(X_{n},Y_{n}, \forall {n}\). Our work here focuses upon the quasi-likelihood basis for estimation of an exactly unbiased linear regression Hájek projection, within which the Kemeny metric space is operationalised via Whitney embedding to obtain exact unbiased minimum variance multivariate covariance estimators upon both discrete and continuous random variables (i.e., exact unbiased identification in the presence of ties upon finite samples). While the covariance estimator is inherently useful, expansion of the Wilcoxon rank-sum testing framework to handle multiple covariates with exact unbiasedness upon finite samples is a currently unresolved research problem, as it maintains identification in the presence of linear surjective mappings onto common points: this model space, by definition, expands our likelihood framework into a consistent non-parametric form of the standard general linear model, which we extend to address both unknown heterogeneity and the problem of weak inferential instruments.

</details>


### [4] [Identification and Estimation under Multiple Versions of Treatment: Mixture-of-Experts Approach](https://arxiv.org/abs/2601.00287)
*Kohei Yoshikawa,Shuichi Kawano*

Main category: stat.ME

TL;DR: 本文提出了一种将专家混合模型引入因果推断的新方法，用于估计未观测到的潜在治疗版本的因果效应，从而在违反SUTVA假设的情况下实现版本特异性因果效应的无偏识别与估计。


<details>
  <summary>Details</summary>
Motivation: 现有因果推断方法通常依赖于SUTVA假设，即不存在多种治疗版本，但在实际观察性研究中，治疗可能存在多个未观测的版本，忽略这些版本会导致因果效应估计偏差。目前尚缺乏能有效识别和估计版本特异性因果效应的框架，因此需要发展新的方法以深入理解复杂治疗的作用机制。

Method: 本文将专家混合模型（Mixture-of-Experts）引入因果推断，构建了一个能够处理潜在治疗版本的因果推断框架。该方法通过建模潜在版本的分布，结合观测数据，实现对未观测版本下因果效应的显式估计，即使版本本身不可见也能进行推断。

Result: 通过数值实验验证了所提方法的有效性，结果表明该方法能够准确估计不同潜在版本的因果效应，优于忽略版本差异的传统方法，具有更强的鲁棒性和解释力。

Conclusion: 本文提出的基于专家混合模型的因果推断框架能够有效应对SUTVA假设中多重治疗版本的问题，实现了对潜在版本特异性因果效应的无偏估计，为理解和分析复杂治疗机制提供了新的工具。

Abstract: The Stable Unit Treatment Value Assumption (SUTVA) includes the condition that there are no multiple versions of treatment in causal inference. Though we could not control the implementation of treatment in observational studies, multiple versions may exist in the treatment. It has been pointed out that ignoring such multiple versions of treatment can lead to biased estimates of causal effects, but a causal inference framework that explicitly deals with the unbiased identification and estimation of version-specific causal effects has not been fully developed yet. Thus, obtaining a deeper understanding for mechanisms of the complex treatments is difficult. In this paper, we introduce the Mixture-of-Experts framework into causal inference and develop a methodology for estimating the causal effects of latent versions. This approach enables explicit estimation of version-specific causal effects even if the versions are not observed. Numerical experiments demonstrate the effectiveness of the proposed method.

</details>


### [5] [Asymptotic distribution of a robust wavelet-based NKK periodogram](https://arxiv.org/abs/2601.00310)
*Manganaw N'Daam,Tchilabalo Abozou Kpanzou,Edoh Katchekpele*

Main category: stat.ME

TL;DR: 本文研究了基于小波的NKK周期图在固定分辨率下通过最小绝对偏差谐波回归构造的渐近分布，建立了适用于具有重尾创新的长记忆时间序列谱分析的稳健小波周期图的理论基础。


<details>
  <summary>Details</summary>
Motivation: 为了对具有长程依赖性和重尾误差的时间序列进行更稳健的频谱分析，需要建立基于LAD和小波方法的周期图的理论支持。

Method: 采用小波表示时间序列，结合最小绝对偏差（LAD）谐波回归构造NKK周期图，并分析其在长记忆性下的概率结构和渐近分布。

Result: 在适当正则条件下，NKK周期图依分布收敛于一个非标准极限，该极限为高斯随机向量的二次型，其协方差结构依赖于过程的记忆特性和所选小波滤波器。

Conclusion: 该结果为使用鲁棒小波周期图进行长记忆、重尾时间序列的谱分析提供了严格的理论基础。

Abstract: This paper investigates the asymptotic distribution of a wavelet-based NKK periodogram constructed from least absolute deviations (LAD) harmonic regression at a fixed resolution level. Using a wavelet representation of the underlying time series, we analyze the probabilistic structure of the resulting periodogram under long-range dependence. It is shown that, under suitable regularity conditions, the NKK periodogram converges in distribution to a nonstandard limit characterized as a quadratic form in a Gaussian random vector, whose covariance structure depends on the memory properties of the process and on the chosen wavelet filters. This result establishes a rigorous theoretical foundation for the use of robust wavelet-based periodograms in the spectral analysis of long-memory time series with heavy-tailed inovations.

</details>


### [6] [Continuous monitoring of delayed outcomes in basket trials](https://arxiv.org/abs/2601.00499)
*Marcio A. Diniz,Hulya Kocyigit,Erin Moshier,Madhu Mazumdar,Deukwoo Kwon*

Main category: stat.ME

TL;DR: 本文提出了一种适用于篮式临床试验的连续监测方法，通过贝叶斯经验模型和多重插补技术应对延迟结果带来的挑战，能够在降低计算成本的同时提高早期识别无效篮子的效率。


<details>
  <summary>Details</summary>
Motivation: 篮式临床试验需要在存在延迟结局（如免疫治疗）的情况下进行多次中期分析，但现有贝叶斯设计计算成本高且难以处理缺失数据，因此需要一种高效且实用的方法。

Method: 基于Fujiwara等人提出的低计算成本贝叶斯经验方法，并扩展Cai等人的思路，采用多重插补法处理中期分析中的延迟结果，在模拟研究中比较了四种不同缺失数据处理策略的表现。

Result: 模拟结果显示，最优的缺失数据处理方式取决于具体试验特征；在入组缓慢时缺失较少，简单方法即可胜任；而多重插补在多篮子、多药物并行测试时能带来更大的样本量节约。

Conclusion: 所提出的方法在保持低计算成本的同时有效应对延迟结局问题，支持连续监测以提升篮式试验的决策效率，具有良好的实际应用前景。

Abstract: Precision medicine has led to a paradigm shift allowing the development of targeted drugs that are agnostic to the tumor location. In this context, basket trials aim to identify which tumor types - or baskets - would benefit from the targeted therapy among patients with the same molecular marker or mutation. We propose the implementation of continuous monitoring for basket trials to increase the likelihood of early identification of non-promising baskets. Although the current Bayesian trial designs available in the literature can incorporate more than one interim analysis, most of them have high computational cost, and none of them handle delayed outcomes that are expected for targeted treatments such as immunotherapies. We leverage the Bayesian empirical approach proposed by Fujiwara et al., which has low computational cost. We also extend ideas of Cai et al to address the practical challenge of performing interim analysis with delayed outcomes using multiple imputation. Operating characteristics of four different strategies to handle delayed outcomes in basket trials are compared in an extensive simulation study with the benchmark strategy where trial accrual is put on hold until complete data is observed to make a decision. The optimal handling of missing data at interim analyses is trial-dependent. With slow accrual, missingness is minimal even with continuous monitoring, favoring simpler approaches over computationally intensive methods. Although individual sample-size savings are small, multiple imputation becomes more appealing when sample size savings scale with the number of baskets and agents tested.

</details>


### [7] [ballmapper: Applying Topological Data Analysis Ball Mapper in Stata](https://arxiv.org/abs/2601.00508)
*Simon Rudkin,Wanling Rudkin*

Main category: stat.ME

TL;DR: 本文介绍了拓扑数据分析中的球映射器（TDABM）方法及其在Stata中的实现，强调其无需降维即可可视化多变量数据的优势。


<details>
  <summary>Details</summary>
Motivation: 为了在不丢失信息的情况下对多变量数据进行可视化，避免传统降维带来的信息损失。

Method: 使用等大小球覆盖多维点云，通过调整球半径参数生成拓扑图，并利用颜色编码展示额外变量或模型残差。

Result: 实现了对多维数据结构的完整保留，并可通过图形化方式呈现多种附加信息，在多个学科领域得到应用。

Conclusion: TDABM是一种有效的无模型多变量数据可视化工具，结合Stata的ballmapper包可方便地应用于实际研究。

Abstract: Topological Data Analysis Ball Mapper (TDABM) offers a model-free visualization of multivariate data which does not necessitate the information loss associated with dimensionality reduction. TDABM Dlotko (2019) produces a cover of a multidimensional point cloud using equal size balls, the radius of the ball is the only parameter. A TDABM visualization retains the full structure of the data. The graphs produced by TDABM can convey coloration according to further variables, model residuals, or variables within the multivariate data. An expanding literature makes use of the power of TDABM across Finance, Economics, Geography, Medicine and Chemistry amongst others. We provide an introduction to TDABM and the \texttt{ballmapper} package for Stata.

</details>


### [8] [Variable Importance in Generalized Linear Models -- A Unifying View Using Shapley Values](https://arxiv.org/abs/2601.00773)
*Sinan Acemoglu,Christian Kleiber,Jörg Urban*

Main category: stat.ME

TL;DR: 本文提出了一种基于Kullback-Leibler散度的伪R²（KL R²），用于统一和扩展线性与非线性模型中的变量重要性分析，适用于广义线性模型，并通过公共健康和保险数据示例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于在非线性回归中缺乏普遍接受的拟合优度度量，现有方法难以一致地解释变量重要性，因此需要一种具有良好性质的拟合优度指标以支持Shapley值在各类模型中的应用。

Method: 提出使用基于Kullback-Leibler散度的伪R²作为拟合优度度量，并利用Shapley值分解该度量以评估变量的重要性，从而实现对线性和非线性模型中变量重要性的统一分析。

Result: KL R²在广义线性模型中具有简洁的形式，能够满足变量重要性解释所需的理想属性，并成功应用于公共健康和保险领域的实际数据示例中。

Conclusion: 基于Kullback-Leibler散度的伪R²为回归分析中的变量重要性提供了可解释且统一的框架，拓展了Shapley值在非线性模型中的适用性。

Abstract: Variable importance in regression analyses is of considerable interest in a variety of fields. There is no unique method for assessing variable importance. However, a substantial share of the available literature employs Shapley values, either explicitly or implicitly, to decompose a suitable goodness-of-fit measure, in the linear regression model typically the classical $R^2$. Beyond linear regression, there is no generally accepted goodness-of-fit measure, only a variety of pseudo-$R^2$s. We formulate and discuss the desirable properties of goodness-of-fit measures that enable Shapley values to be interpreted in terms of relative, and even absolute, importance. We suggest to use a pseudo-$R^2$ based on the Kullback-Leibler divergence, the Kullback-Leibler $R^2$, which has a convenient form for generalized linear models and permits to unify and extend previous work on variable importance for linear and nonlinear models. Several examples are presented, using data from public health and insurance.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [9] [Improved estimators of causal emergence for large systems](https://arxiv.org/abs/2601.00013)
*Madalina I. Sas,Fernando E. Rosas,Hardik Rajpal,Daniel Bor,Henrik J. Jensen,Pedro A. M. Mediano*

Main category: physics.soc-ph

TL;DR: 提出了一种改进的信息论方法来量化复杂系统中的涌现现象，通过迭代校正重复计算项，有效提高了对大规模系统中涌现行为的检测精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有检测涌现的方法存在重复计算共享组件贡献的问题，限制了其在大型系统中的应用能力。

Method: 引入了一族改进的信息论涌现度量方法，通过迭代方式校正重复计算项，并提供计算负荷与敏感性之间的可控权衡。

Result: 新方法在模拟数据和真实 flocking 行为数据中均成功检测到涌现现象，表现出更高的准确性和适用性。

Conclusion: 该方法计算高效、灵活，能更准确地估计复杂系统中的涌现，适用于大规模系统的研究。

Abstract: A central challenge in the study of complex systems is the quantification of emergence -- understood as the ability of the system to exhibit collective behaviours that cannot be traced down to the individual components. While recent work has proposed practical measures to detect emergence, these approaches tend to double-count the contribution of shared components, which substantially hinders their capability to effectively study large systems. In this work, we introduce a family of improved information-theoretic measures of emergence that iteratively correct for double-counted terms. Our approach is computationally efficient and provides a controllable trade-off between computational load and sensitivity, leading to more accurate and versatile estimates of emergence. The benefits of the proposed approach are demonstrated by successfully detecting emergence in both simulated and real-world data related to flocking behaviour.

</details>


### [10] [The dynamics of cultural systems](https://arxiv.org/abs/2601.00440)
*Fredrik Jansson*

Main category: physics.soc-ph

TL;DR: 本文提出文化是一个由信念、实践和人工制品组成的动态系统，其演化受到认知、社会和物质结构的共同影响。个体通过追求一致性的信息处理机制进行文化学习与创造，形成高级特征（如规范、认知工具），进而构建出自我强化的知识生态和社会极化现象。大型语言模型和推荐算法作为文化产物，反过来通过自动化过滤和重组信息，深刻影响文化的未来演化路径。


<details>
  <summary>Details</summary>
Motivation: 理解文化如何作为一个复杂动态系统演化，并探讨现代技术（如LLM和推荐算法）在其中的作用。

Method: 采用理论建模方式，将文化学习与创造力视为追求一致性的信息处理过程，分析高阶特征作为元过滤器的作用及其在文化系统中的自组织机制。

Result: 揭示了文化系统中路径依赖、吸引子状态和突变性转变的成因；阐明了回声室、认知封闭群体和制度如何从个体层面的信息过滤行为中涌现；并指出人工智能技术正成为新的文化过滤力量。

Conclusion: 文化不仅是静态特质的集合，而是一个受历史依赖和结构约束的动态适应系统，当前的技术系统已成为塑造文化演化的关键参与者。

Abstract: Culture is not just traits but a dynamic system of interdependent beliefs, practices and artefacts embedded in cognitive, social and material structures. Culture evolves as these entities interact, generating path dependence, attractor states and tension, with long-term stability punctuated by rapid systemic transformations. Cultural learning and creativity is modelled as coherence-seeking information processing: individuals filter, transform and recombine input in light of prior acquisitions and dissonance reduction, thereby creating increasingly structured worldviews. Higher-order traits such as goals, skills, norms and cognitive gadgets act as emergent metafilters that regulate subsequent selection by defining what counts as coherent. Together, these filtering processes self-organise into epistemic niches, echo chambers, polarised groups and institutions that channel information flows and constrain future evolution. In this view, LLMs and recommender algorithms are products of cultural embeddings that now act back on cultural systems by automated filtering and recombination of information, reshaping future dynamics of cultural systems.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [11] [Probing the magnetic ground state and magnetoelastic coupling in double perovskite ruthenate: Ca2ScRuO6](https://arxiv.org/abs/2601.00085)
*Asha Ann Abraham,Anjali Kumari,Md Aktar Hossain,Sanjoy Kr Mahatha,Saikat Das,A. K. Bera,Soham Manni*

Main category: cond-mat.str-el

TL;DR: 本研究揭示了双钙钛矿钌酸盐Ca2ScRuO6中一种不寻常的磁基态，其中长程有序的反铁磁性与小磁簇共存，导致高温下呈现类亚铁磁的磁化行为。


<details>
  <summary>Details</summary>
Motivation: 探索4d3双钙钛矿钌酸盐系列中尚未充分研究的Ca2ScRuO6的磁基态，理解其复杂磁行为的起源。

Method: 结合X射线吸收光谱、中子粉末衍射、体磁化率测量和对称性分析，研究材料的电子结构、磁结构及晶格效应。

Result: 发现Ca2ScRuO6具有混合价态Ru5+/Ru4+和Ru/Sc位点交换，低温下存在弱Type I反铁磁序（磁矩1.1μB/Ru），同时在约40 K以上表现出类亚铁磁行为，且存在磁致伸缩耦合。

Conclusion: Ca2ScRuO6呈现出由反位无序诱导的新型磁基态，为研究无序环境下长程磁序提供了独特平台。

Abstract: Ruthenates, materials with a single magnetic Ruthenium (Ru) atom, often display an exotic array of ground states ranging from superconductivity to altermagnetism. In this work, we investigated the magnetic ground state of a least explored member of the 4d3 double perovskite ruthenate series A2ScRuO6 (A = Ca, Sr, Ba): Ca2ScRuO6. Interestingly, temperature-dependent bulk susceptibility curve shows ferrimagnetic-like behaviour above the magnetic ordering at around 40 K, which were corroborated by the identification of the mixed valence states, Ru5+ and Ru4+ via X-ray absorption spectroscopy. Structural analysis further revealed atomic-site exchange between the Ru and Sc sites, which results in the Ru mixed valence states. Neutron powder diffraction measurements detected the presence of magnetic Bragg peaks at a low temperature near 4 K and a moderate magnetoelastic coupling near the ordering temperature of 40 K. However, the corresponding symmetry analysis shows a weak Type I antiferromagnetic ground state with a reduced magnetic moment of 1.1μB/Ru atom. Our findings establish an unusual magnetic ground state in the Mott insulating Ca2ScRuO6, where a long range ordered antiferromagnet coexists with small magnetic clusters, which manifests a ferrimagnetic-like high temperature inverse magnetic susceptibility. This system presents a unique platform to study long-range magnetic order in the presence of antisite disorder.

</details>


### [12] [Spin-density wave of ferrimagnetic building blocks masking the ferromagnetic quantum-critical point in NbFe2](https://arxiv.org/abs/2601.00101)
*T. Poulis,G. Mani,J. Sturt,W. J. Duncan,H. Thoma,V. Hutanu,B. Ouladdiaf,I. Kibalin,M. H. Lemee,P. Manuel,A. Neubauer,C. Pfleiderer,F. M. Grosche,P. G. Niklowitz*

Main category: cond-mat.str-el

TL;DR: 在金属磁体NbFe2中，通过调节Fe浓度揭示了纵向自旋密度波掩盖铁磁量子临界点的现象，该自旋密度波具有非公度调制和铁磁片层结构，表现出与铁磁母相的局部相似性。


<details>
  <summary>Details</summary>
Motivation: 探索NbFe2中调制磁序如何掩盖铁磁量子临界点，并揭示其微观机制。

Method: 使用球形中子极化谱学和高强度单晶中子衍射技术对磁结构进行精修。

Result: 发现首个由纵向自旋密度波掩盖铁磁量子临界点的案例，该自旋密度波具有长波长非公度调制，由反平行铁磁片层构成的亚铁磁基元组成。

Conclusion: 自旋密度波在介观尺度上抵消磁化强度，但保留局部铁磁特征，表明其起源于潜在的铁磁量子临界性，具有非常规性质。

Abstract: In the metallic magnet NbFe2, the low temperature threshold of ferromagnetism can be investigated by varying the Fe concentration within a narrow homogeneity range. NbFe2 is one of a number of compounds where modulated order is found to mask the ferromagnetic quantum critical point. However, here we report the rare case where the masking modulated magnetic order has been fully refined. Spherical neutron polarimetry and high-intensity single-crystal neutron diffraction reveal the first case of a longitudinal spin-density wave masking the ferromagnetic quantum critical point. The spin-density wave is characterised by a large-wavelength incommensurate modulation of its low average moment. It is formed from ferrimagnetic building blocks with antiparallel ferromagnetic sheets. The existence of ferromagnetic sheets and cancellation of the magnetisation only over mesoscopic length scales show local similarity between the spin-density wave and the ferromagnetic parent phase and indicate the spin-density wave's unconventional nature as emerging from underlying ferromagnetic quantum criticality.

</details>


### [13] [Topological physics in quantum critical systems](https://arxiv.org/abs/2601.00184)
*Xue-Jia Yu,Limei Xu,Hai-Qing Lin*

Main category: cond-mat.str-el

TL;DR: 本文综述了无能隙量子临界系统中拓扑性质的最新进展，挑战了传统认为拓扑性质依赖于体能隙的观点，拓展了对量子相变分类的理解。


<details>
  <summary>Details</summary>
Motivation: 传统拓扑理论依赖体能隙，但在无能隙的量子临界系统中拓扑是否仍存在尚不明确，需拓展拓扑概念以重新理解相变和临界现象。

Method: 通过回顾无能隙对称保护拓扑态的研究进展，分析量子临界点和临界相中的拓扑性质，并推广至非相互作用与相互作用系统。

Result: 证明拓扑可存在于无能隙系统中，可用于区分同一普适类下的不同量子相变，拓扑在分类临界现象中起关键作用。

Conclusion: 拓扑不仅限于有能隙系统，其在量子临界系统中的推广丰富了现代凝聚态物理对相变和临界现象的理解。

Abstract: Topology forms a cornerstone in modern condensed matter and statistical physics, offering a new framework to classify the phases and phase transitions beyond the traditional Landau paradigm. However, it is widely believed that topological properties are destroyed when the bulk energy gap closes, making it highly nontrivial to consider topology in gapless quantum critical systems. To address these challenges, recent advancements have sought to generalize the notion of topology to systems without a bulk energy gap, including quantum critical points and critical phases, collectively referred to as gapless symmetry-protected topological states. Extending topology to gapless quantum critical systems challenges the traditional belief in condensed matter physics that topological edge states are typically tied to the presence of a bulk energy gap. Furthermore, it suggests that topology plays a crucial role in classifying quantum phase transitions even if they belong to the same universality class, fundamentally enriching the textbook understanding of phase transitions. Given its importance, here we give a pedagogical review of the current progress of topological physics in quantum critical systems. We introduce the topological properties of quantum critical points and generalize them to stable critical phases, both for noninteracting and interacting systems. Additionally, we discuss further generalizations and future directions, including higher dimensions, nonequilibrium phase transitions, and realizations in modern experiments.

</details>


### [14] [About the origin of the magnetic ground state of Tb$_{2}$Ir$_{2}$O$_{7}$](https://arxiv.org/abs/2601.00749)
*Y. Alexanian,E. Lhotel,J. Robert,S. Petit,E. Lefrançois,P. Lejay,A. Hadj-Azzem,F. Damay,J. Ollivier,B. Fåk,R. Ballou,S. De Brion,V. Simonet*

Main category: cond-mat.str-el

TL;DR: 研究了Tb$_{2}$Ir$_{2}$O$_{7}$中稀土离子磁矩垂直于其局域易轴有序的奇特磁态，结合中子衍射、非弹性中子散射和比热测量，揭示了该磁态在1.5 K下完全形成，并表征了其激发谱。


<details>
  <summary>Details</summary>
Motivation: 探索磁性稀土焦绿石铱氧化物中由于稀土与铱亚晶格间复杂相互作用导致的非常规物态，特别是Tb$^{3+}$磁矩违背局域易轴取向的异常有序行为。

Method: 采用中子衍射、非弹性中子散射（至稀释温度）和比热测量手段，并结合在Ir分子场作用下的Tb$^{3+}$离子双线性相互作用模型进行理论计算。

Result: 发现Tb$^{3+}$的某一磁矩分量垂直于其局域Ising各向异性轴有序，该磁态在1.5 K完全建立；实验测定了宽能量范围内的激发谱；理论表明双线性相互作用可捕捉部分实验特征，但需补充其他机制才能完全解释观测结果。

Conclusion: Tb$_{2}$Ir$_{2}$O$_{7}$中的奇特磁有序源于Ir子晶格产生的分子场对Tb$^{3+}$离子相互作用的调制，但现有双线性模型不足以完全描述该体系，暗示存在更复杂的相互作用机制。

Abstract: Magnetic-rare-earth pyrochlore iridates exhibit a rich variety of unconventional phases, driven by the complex interactions within and between the rare-earth and the iridium sublattices. In this study, we investigate the peculiar magnetic state of Tb$_{2}$Ir$_{2}$O$_{7}$, where a component of the Tb$^{3+}$ moment orders perpendicular to its local Ising anisotropy axis. By means of neutron diffraction and inelastic neutron scattering down to dilution temperatures, complemented by specific heat measurements, we show that this intriguing magnetic state is fully established at 1.5 K and we characterize its excitation spectrum across a broad range of energies. Our calculations reveal that bilinear interactions between Tb$^{3+}$ ions subjected to the Ir molecular field capture several key features of the experiments, but need to be supplemented to fully reproduce the observed behavior.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [15] [Next Generation Intelligent Low-Altitude Economy Deployments: The O-RAN Perspective](https://arxiv.org/abs/2601.00257)
*Aly Sabri Abdalla,Vuk Marojevic*

Main category: eess.SY

TL;DR: 本文提出了一种基于O-RAN的低空经济（LAE）框架，利用开放接口和智能控制器实现AI优化的实时任务协同，并通过语义感知rApp与强化学习xApp验证了其在复杂环境中的轨迹规划能力。


<details>
  <summary>Details</summary>
Motivation: 针对低空经济应用中在复杂、信号受限环境中缺乏实时、弹性及上下文感知的空中节点协同问题，亟需融合人工智能的解决方案。

Method: 设计并实现了一个O-RAN使能的LAE框架，集成解耦RAN架构、开放接口与RAN智能控制器（RIC），开发语义感知rApp作为地形解释器，指导强化学习驱动的xApp进行实时轨迹规划。

Result: 验证了该架构在UAV集群实时路径规划中的可行性与性能，展示了语义引导下强化学习在复杂地形中的有效性，并调研了可用于LAE研究的UAV测试平台。

Conclusion: O-RAN与AI的深度融合可显著提升LAE任务的智能化与可靠性，为未来标准制定和关键技术研究提供了方向。

Abstract: Despite the growing interest in low-altitude economy (LAE) applications, including UAV-based logistics and emergency response, fundamental challenges remain in orchestrating such missions over complex, signal-constrained environments. These include the absence of real-time, resilient, and context-aware orchestration of aerial nodes with limited integration of artificial intelligence (AI) specialized for LAE missions. This paper introduces an open radio access network (O-RAN)-enabled LAE framework that leverages seamless coordination between the disaggregated RAN architecture, open interfaces, and RAN intelligent controllers (RICs) to facilitate closed-loop, AI-optimized, and mission-critical LAE operations. We evaluate the feasibility and performance of the proposed architecture via a semantic-aware rApp that acts as a terrain interpreter, offering semantic guidance to a reinforcement learning-enabled xApp, which performs real-time trajectory planning for LAE swarm nodes. We survey the capabilities of UAV testbeds that can be leveraged for LAE research, and present critical research challenges and standardization needs.

</details>


### [16] [Impact Assessment of Heterogeneous Grid Support Functions in Smart Inverter Deployments](https://arxiv.org/abs/2601.00289)
*S. Gokul Krishnan,Mohd. Asim Aftab,Nabil Mohammed,Shehab Ahmed,Charalambos Konstantinou*

Main category: eess.SY

TL;DR: 本文研究了在高比例分布式能源接入背景下，不同智能逆变器控制模式之间的动态交互影响，采用实时仿真平台对多种控制策略在不同类型馈线中的表现进行了评估。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源（如光伏系统）在低压配电网中的渗透率不断提高，智能逆变器的无协调控制可能导致系统稳定性问题；然而，不同控制模式下逆变器组之间的系统级交互影响尚未被充分研究。

Method: 通过Opal-RT实时仿真平台对CIRGE低压配电网进行建模，评估恒定功率因数（CPF）、Volt-VAR和Volt-Watt三种控制模式在阻性和感性馈线中的动态交互行为。

Result: 揭示了不同控制模式在不同馈线类型下的相互作用特性，为协调控制策略的设计提供了实证依据。

Conclusion: 异构智能逆变器组之间存在显著的动态交互，可能影响电压调节和系统稳定性，因此需要更高级的协调控制机制以提升整体电网性能。

Abstract: The decarbonization of the energy sector has led to a significant high penetration of distributed energy resources (DERs), particularly photovoltaic (PV) systems, in low-voltage (LV) distribution networks. To maintain grid stability, recent standards (e.g., IEEE 1547-2018) mandate DERs to provide grid-support functionalities through smart inverters (SIs), which typically operate autonomously based on local measurements. However, as DER penetration increases, uncoordinated control modes of SIs can lead to adverse interactions, compromising system efficiency, voltage regulation, and overall stability. While previous studies have demonstrated the benefits of coordinated inverter control and optimal dispatch strategies, the system-wide impacts of heterogeneous SI groups operating under different control modes remain largely unexamined. This paper addresses this gap by assessing the dynamic interactions among multiple SI groups with varying control strategies, namely: Constant Power Factor (CPF), Volt-VAR, and Volt-Watt modes. Furthermore, the analysis covers both resistive and inductive feeder types. The validation is performed using a real-time setup. The CIRGE low-voltage (LV) distribution network is simulated in the Opal-RT platform as the test network, enabling realistic and high-fidelity evaluation of SI control interactions under practical grid conditions.

</details>


### [17] [Probability-Aware Parking Selection](https://arxiv.org/abs/2601.00521)
*Cameron Hickert,Sirui Li,Zhengbing He,Cathy Wu*

Main category: eess.SY

TL;DR: 本文提出了一种概率感知的停车选择方法，通过动态规划框架优化驾驶员前往停车位的决策，考虑了停车场可用性的动态变化，并利用真实数据验证了该方法在减少搜索时间方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有导航系统常忽略寻找停车位的时间，导致出行时间估计不准确，影响用户体验、交通拥堵和排放。因此需要一种更精确的停车引导策略。

Method: 提出了一个基于停车场级别停车可用性概率信息的自适应动态规划框架，进行停车选择决策，并通过闭式分析判断何时应锁定特定停车场或探索其他选项。

Result: 实验表明，随着观测频率增加，平均绝对误差从7%降至2%以下；基于数据的模拟显示，相比无概率感知的基线策略，该方法最多可节省66%的时间，但仍比直接导航至目的地的估计耗时最多高出123%。

Conclusion: 所提出的概率感知停车选择模型能有效提升停车导航的准确性与效率，尤其在高频率观测下表现优异，为低成本、高可靠性的智能停车系统提供了可行方案。

Abstract: Current parking navigation systems often underestimate total travel time by failing to account for the time spent searching for a parking space, which significantly affects user experience, mode choice, congestion, and emissions. To address this issue, this paper introduces the probability-aware parking selection problem, which aims to direct drivers to the best parking location rather than straight to their destination. An adaptable dynamic programming framework is proposed for decision-making based on probabilistic information about parking availability at the parking lot level. Closed-form analysis determines when it is optimal to target a specific parking lot or explore alternatives, as well as the expected time cost. Sensitivity analysis and three illustrative cases are examined, demonstrating the model's ability to account for the dynamic nature of parking availability. Acknowledging the financial costs of permanent sensing infrastructure, the paper provides analytical and empirical assessments of errors incurred when leveraging stochastic observations to estimate parking availability. Experiments with real-world data from the US city of Seattle indicate this approach's viability, with mean absolute error decreasing from 7% to below 2% as observation frequency grows. In data-based simulations, probability-aware strategies demonstrate time savings up to 66% relative to probability-unaware baselines, yet still take up to 123% longer than direct-to-destination estimates.

</details>


### [18] [Optimal Transport-Based Decentralized Multi-Agent Distribution Matching](https://arxiv.org/abs/2601.00548)
*Kooktae Lee*

Main category: eess.SY

TL;DR: 提出了一种去中心化的多智能体系统分布匹配控制框架，利用最优传输理论实现期望的终端空间分布，具有可扩展性和分布式运行能力。


<details>
  <summary>Details</summary>
Motivation: 为了在多智能体系统中实现期望的终端空间分布，避免求解全局最优传输问题的高计算复杂度和对全局信息的依赖。

Method: 将分布匹配目标转化为每个智能体基于局部信息的决策过程，引入序列权重更新规则构建局部传输计划，并采用基于记忆的校正机制应对通信限制。

Result: 仿真结果表明该框架能有效实现分布匹配，且在间歇性和范围受限通信下仍保持可靠运行。

Conclusion: 所提方法在无需全局信息的情况下实现了多智能体系统的可扩展、去中心化分布控制，具备理论收敛保证和良好的实际性能。

Abstract: This paper presents a decentralized control framework for distribution matching in multi-agent systems (MAS), where agents collectively achieve a prescribed terminal spatial distribution. The problem is formulated using optimal transport (Wasserstein distance), which provides a principled measure of distributional discrepancy and serves as the basis for the control design. To avoid solving the global optimal transport problem directly, the distribution-matching objective is reformulated into a tractable per-agent decision process, enabling each agent to identify its desired terminal locations using only locally available information. A sequential weight-update rule is introduced to construct feasible local transport plans, and a memory-based correction mechanism is incorporated to maintain reliable operation under intermittent and range-limited communication. Convergence guarantees are established, showing cycle-wise improvement of a surrogate transport cost under both linear and nonlinear agent dynamics. Simulation results demonstrate that the proposed framework achieves effective and scalable distribution matching while operating fully in a decentralized manner.

</details>


### [19] [A formal theory on problem space as a semantic world model in systems engineering](https://arxiv.org/abs/2601.00755)
*Mayuranath SureshKumar,Hanumanthrao Kannan*

Main category: eess.SY

TL;DR: 本文提出了一种形式化的系统工程问题空间模型，通过构建先于需求和解决方案的语义世界模型，明确区分问题域与解决方案，提升问题表述的严谨性与可追溯性。


<details>
  <summary>Details</summary>
Motivation: 当前系统工程实践中，问题空间缺乏严格的理论表征，导致对运行环境、交互方式和上下文条件的基本假设隐含或过早嵌入架构中，影响问题理解的清晰度。

Method: 通过引入语义世界模型，定义问题空间中的理论结构，并建立相应的公理、定理和推论，形成具有边界语义和交互可追溯性的形式化框架。

Result: 实现了问题空间规范的无歧义边界语义、上下文依赖的交互可追溯性，以及对利益相关者目标满足的充分性验证，支持独立于方案设计的严谨推理。

Conclusion: 该理论为系统工程提供了清晰的问题域与解决方案之间的分界，有助于在设计前正确框定问题，提升实践中的推理质量与沟通效率。

Abstract: Classic problem-space theory models problem solving as a navigation through a structured space of states, operators, goals, and constraints. Systems Engineering (SE) employs analogous constructs (functional analysis, operational analysis, scenarios, trade studies), yet still lacks a rigorous systems-theoretic representation of the problem space itself. In current practice, reasoning often proceeds directly from stakeholder goals to prescriptive artifacts. This makes foundational assumptions about the operational environment, admissible interactions, and contextual conditions implicit or prematurely embedded in architectures or requirements. This paper addresses that gap by formalizing the problem space as an explicit semantic world model containing theoretical constructs that are defined prior to requirements and solution commitments. These constructs along with the developed axioms, theorems and corollary establish a rigorous criterion for unambiguous boundary semantics, context-dependent interaction traceability to successful stakeholder goal satisfaction, and sufficiency of problem-space specification over which disciplined reasoning can occur independent of solution design. It offers a clear distinction between what is true of the problem domain and what is chosen as a solution. The paper concludes by discussing the significance of the theory on practitioners and provides a dialogue-based hypothetical case study between a stakeholder and an engineer, demonstrating how the theory guides problem framing before designing any prescriptive artifacts.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [20] [Combining multiple interface set path ensembles with MBAR reweighting](https://arxiv.org/abs/2601.00458)
*Rik S. Breebaart,Peter G. Bolhuis*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种结合不同集体变量下过渡界面采样模拟来计算重加权路径集合的方法，基于MBAR方法应用于完整轨迹，显著提高了统计性能。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地计算复杂系统的反应路径和动力学性质，需要有效整合多组基于不同集体变量的模拟数据。

Method: 将多状态Bennett接受比（MBAR）方法扩展到整个轨迹，对在不同集体变量条件下进行的过渡界面采样（TIS）模拟进行加权组合。

Result: 在简单的2D势能模型和复杂的主客体系统上的测试表明，与直接合并相比，该方法显著提升了统计精度和采样效率。

Conclusion: 该方法为多维集体变量下的路径采样提供了有效的统计整合框架，有助于提升复杂化学过程动力学模拟的可靠性。

Abstract: We introduce a method to compute the reweighted path ensemble by combining transition interface sampling simulations conditioned on different collective variables. The approach is based on the Multistate Bennett Acceptance Ratio (MBAR) methodology applied to entire trajectories. Illustrating the technique with simple 2D potential models and a more complex host-guest system, we show that the statistics can significantly improve compared to a straightforward combination.

</details>


### [21] [Thermalization in a closed quantum system from randomized dynamics](https://arxiv.org/abs/2601.00056)
*Nikolay V. Gnezdilov,Andrei I. Pavlov*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种在无热浴的闭合有限量子系统中通过随机幺正演化平均实现热化的方法，能够计算符合正则系综预测的热力学观测量。


<details>
  <summary>Details</summary>
Motivation: 研究量子多体系统中统计力学的涌现问题，特别是在没有外部热浴的情况下如何实现热化。

Method: 通过对少数体系统的随机幺正演化进行经典平均，推导出自旋关联函数，并将温度作为系统总能量的全局约束。

Result: 得到了与正则系综预测一致的温度依赖性有限关联长度的自旋关联函数。

Conclusion: 建立了一种无需热浴即可在闭合有限系统中计算热力学观测量的新方法，可用于量子计算机上的热态制备。

Abstract: The emergence of statistical mechanics from quantum dynamics is a central problem in quantum many-body physics. Deriving observables aligned with the prediction of the canonical ensemble for a quantum system relies on the presence of a bath provided either as an external environment or as a larger part of a closed system. We demonstrate that thermal (canonical) observables for a whole closed quantum system of finite size can arise in the absence of a bath. These thermal observables stem from classical averaging over randomized unitary evolutions for a few-body system. The temperature in the canonical ensemble appears as a global constraint on the total energy of the system, determined by the choice of the initial state. From averaging randomized evolutions, we derive spin-spin correlation functions for a finite spin chain and show that they exhibit a temperature-dependent finite correlation length, in agreement with the prediction of the canonical ensemble. This establishes a method for computing thermal observables in a closed, finite-size system from real-time propagation without a bath. An implementation of this thermalization approach on a quantum computer can be utilized for thermal state preparation.

</details>


### [22] [Bridging Commutant and Polynomial Methods for Hilbert Space Fragmentation](https://arxiv.org/abs/2601.00294)
*Bo-Ting Chen,Yu-Ping Wang,Biao Lian*

Main category: cond-mat.stat-mech

TL;DR: 本文建立了识别希尔伯特空间碎片化（HSF）的两种不同方法——对易代数（CA）方法与整数特征多项式因式分解（ICPF）方法之间的联系。作者证明了一个定理：对于具有有理数矩阵表示的哈密顿量，若其对易代数的中心的所有特征值为有理数，则ICPF方法得到的HSF至少与CA方法一样精细。该条件适用于大多数已知的HSF模型，文中验证了定理的有效性，并讨论了两种方法结果不同的代表性模型，有助于推动HSF统一定义的研究。


<details>
  <summary>Details</summary>
Motivation: 由于不同方法（如CA和ICPF）可能识别出不同的希尔伯特空间碎片化结构，缺乏统一标准，因此需要建立这些方法之间的理论联系以促进对HSF的统一理解。

Method: 针对具有有理数矩阵表示的哈密顿量，通过分析对易代数（CA）的中心及其特征值性质，严格证明了在特定条件下ICPF方法所得的碎片化结构等于或比CA方法更精细，并通过典型模型进行验证。

Result: 证明了当哈密顿量的对易代数中心所有特征值为有理数时，ICPF方法识别的HSF至少与CA方法一样精细；验证了该条件在多数已知HSF模型中成立，并识别出导致两种方法结果不同的反例模型。

Conclusion: 该研究揭示了CA与ICPF两种HSF识别方法之间的内在联系，为未来建立统一的HSF定义提供了理论基础和方向指引。

Abstract: A quantum model exhibits Hilbert space fragmentation (HSF) if its Hilbert space decomposes into exponentially many dynamically disconnected subspaces, known as Krylov subspaces. A model may however have different HSFs depending on the method for identifying them. Here we establish a connection between two vastly distinct methods recently proposed for identifying HSF: the commutant algebra (CA) method and integer characteristic polynomial factorization (ICPF) method. For a Hamiltonian consisting of operators admitting rational number matrix representations, we prove a theorem that, if its center of commutant algebra have all eigenvalues being rational, the HSF from the ICPF method must be equal to or finer than that from the CA method. We show that this condition is satisfied by most known models exhibiting HSF, for which we demonstrate the validity of our theorem. We further discuss representative models for which ICPF and CA methods yield different HSFs. Our results may facilitate the exploration of a unified definition of HSF.

</details>


### [23] [Constructive Cavity Method](https://arxiv.org/abs/2601.00410)
*Simone Franchini*

Main category: cond-mat.stat-mech

TL;DR: 本文通过假设状态是独立随机能量模型的乘积，从空腔法获得的增量自由能中推导出Sherrington-Kirkpatrick模型自由能的Parisi公式的函数形式。


<details>
  <summary>Details</summary>
Motivation: 寻找Sherrington-Kirkpatrick模型自由能的理论基础，并验证Parisi公式的来源。

Method: 使用空腔法计算增量自由能，并假设系统状态为独立随机能量模型的乘积。

Result: 成功从增量自由能得到Parisi公式中的函数形式。

Conclusion: Parisi公式中的函数可以通过空腔法和特定假设自然导出，增强了对该模型自由能结构的理解。

Abstract: We show that the functional appearing in the celebrated Parisi formula for the free energy of the Sherrington-Kirkpatrick model can be found from the incremental free energy obtained by Cavity Method if one assumes that the state is a product of independent Random Energy models.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [24] [On the Error Floor Evaluation of NOMA-Irregular Repetition Slotted ALOHA](https://arxiv.org/abs/2601.00317)
*Estefanía Recayte*

Main category: cs.ET

TL;DR: 本文提出了一种针对基于非正交多址（NOMA）的不规则重复时隙ALOHA（IRSA）方案在误差平台区的丢包率的紧致解析近似方法，适用于物联网场景，并通过蒙特卡洛仿真验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 为了在物联网场景中更准确地评估NOMA-IRSA系统的性能，特别是在误差地板区域的丢包率，需建立一种简单且精确的分析模型。

Method: 通过设计度分布和离散功率分配，结合接收端的连续干扰消除（SIC），推导出有限长度 regime 下的丢包率表达式，并利用蒙特卡洛仿真进行验证。

Result: 所提出的丢包率表达式在不同信道负载下均表现出与仿真结果的高度匹配，包括超出低负载区域的情况。

Conclusion: 该分析方法简单且紧致，能够有效预测NOMA-IRSA在误差地板区的丢包性能，具有较强的实用性和扩展性。

Abstract: In this work, we provide a simple yet tight analytical approximation of the packet loss rate in the error floor region for a non-orthogonal multiple access (NOMA)-based irregular repetition slotted ALOHA (IRSA) scheme. Considering an Internet of Things (IoT) scenario, users randomly select both the number of replicas based on a designed degree distribution and the transmission power from predetermined levels, while successive interference cancellation (SIC) is performed at the receiver. Our derived packet loss rate expression in the finite length regime is promptly evaluated. Its accuracy is validated through Monte-Carlo simulations, demonstrating a strong match across channel loads, including those beyond the low load regime

</details>


### [25] [Two-Step Interference Cancellation for Energy Saving in Irregular Repetition Slotted ALOHA](https://arxiv.org/abs/2601.00343)
*Estefanía Recayte,Leonardo Badia,Andrea Munari*

Main category: cs.ET

TL;DR: 提出了一种改进的IRSA方案，通过中间解码和节点提前终止传输来减少能量消耗，在低负载下实现了33%的节能而不影响吞吐量。


<details>
  <summary>Details</summary>
Motivation: 在低负载情况下避免不必要的冗余传输以降低能量消耗。

Method: 修改IRSA协议，引入中间解码机制，并在节点成功解码后提前终止其后续传输；同时建立了适用于短帧长和低负载场景的能量消耗与成功概率模型。

Result: 该方法在约10%的负载下可节省33%的能量，且不影响吞吐量，仿真结果验证了分析模型的有效性。

Conclusion: 所提出的机制能有效减少IRSA的能量消耗，同时保持相对于传统ALOHA的性能优势，特别适用于低负载场景。

Abstract: We evaluate a modification of irregular repetition slotted ALOHA (IRSA) involving intermediate decoding and early transmission termination by some nodes, upon their decoding success. This is meant to avoid unnecessary transmissions, thereby reducing energy consumption. We expect this to be particularly useful at low loads, where most transmissions can be avoided as they do not often result in a collision and are therefore redundant. To validate this proposal, we observe that most of the literature related to IRSA considers an asymptotic heavily loaded regime; thus, we also present a model of energy consumption and success probability for frames of limited length and low offered loads. Thanks to our analysis, also confirmed by simulation, we are able to show that the proposed technique is able to reduce IRSA energy consumption by minimizing transmissions, while preserving performance gains over standard ALOHA. For example, we are able to get a 33% energy saving at offered loads around 10% without affecting throughput.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [26] [Characterizing Finite-Dimensional Posterior Marginals in High-Dimensional GLMs via Leave-One-Out](https://arxiv.org/abs/2601.00091)
*Manuel Sáenz,Pragya Sur*

Main category: math.ST

TL;DR: 研究了高维广义线性模型在比例渐近情形下的贝叶斯后验分布，发现后验分布的有限维边缘收敛于先验的高斯倾斜形式，且先验的影响在极限下仍然存在；后验均值在均方误差上可优于最大似然估计。


<details>
  <summary>Details</summary>
Motivation: 在高维比例渐近环境下，传统贝叶斯后验收缩性质可能失效，需重新理解后验分布的行为及其对推断的影响。

Method: 通过引入留一法策略分析后验分布的有限维边缘，研究其在高维GLM中的极限行为。

Result: 证明后验不收缩，但有限维边缘收敛于依赖真实信号坐标的高斯倾斜先验；后验均值在均方误差上可优于MLE，结果不受信号稀疏性影响。

Conclusion: 在高维比例渐近下，贝叶斯后验的边缘分布保留先验结构，且后验均值具有优于MLE的推断性能，表明先验在高维推断中持续发挥作用。

Abstract: We investigate Bayes posterior distributions in high-dimensional generalized linear models (GLMs) under the proportional asymptotics regime, where the number of features and samples diverge at a comparable rate. Specifically, we characterize the limiting behavior of finite-dimensional marginals of the posterior. We establish that the posterior does not contract in this setting. Yet, the finite-dimensional posterior marginals converge to Gaussian tilts of the prior, where the mean of the Gaussian depends on the true signal coordinates of interest. Notably, the effect of the prior survives even in the limit of large samples and dimensions. We further characterize the behavior of the posterior mean and demonstrate that the posterior mean can strictly outperform the maximum likelihood estimate in mean-squared error in natural examples. Importantly, our results hold regardless of the sparsity level of the underlying signal. On the technical front, we introduce leave-one-out strategies for studying these marginals that may be of independent interest for analyzing low-dimensional functionals of high-dimensional signals in other Bayesian inference problems.

</details>


### [27] [Geometric extremal graphical models and coefficients of extremal dependence on block graphs](https://arxiv.org/abs/2601.00239)
*Ioannis Papastathopoulos,Jennifer Wadsworth*

Main category: math.ST

TL;DR: 本文提出了几何极值图模型，通过轻尾边缘中适当缩放随机向量的极限集的规范函数定义，并在块图上研究了极值依赖系数的传播特性，特别关注条件极值理论框架下的系数，为高维复杂极值依赖结构的建模提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和建模高维数据中的复杂极值依赖结构，尤其是在变量不同时达到极端值的情况下，现有方法存在局限性。

Method: 利用轻尾边缘中缩放随机向量的极限集的规范函数来定义几何极值图模型，并在块图结构下分析极值依赖系数的传播规律，结合条件极值理论进行理论推导。

Result: 证明了块图中多种极值依赖系数沿图传播的理论结果，明确了在变量联合极端行为和非同步极端行为下的依赖关系特征。

Conclusion: 几何极值图模型为高维极端事件的复杂依赖结构建模提供了理论基础和可行路径，拓展了极值统计建模的应用范围。

Abstract: We introduce the concept of geometric extremal graphical models, which are defined through the gauge function of the limit set obtained from suitably scaled random vectors in light-tailed margins. For block graphs, we prove results relating to the propagation of various extremal dependence coefficients along the graph. A particular focus is placed on coefficients that link to the framework of conditional extreme value theory, which are especially interesting when variables do not all attain their most extreme values simultaneously. We also consider results related to the case when variables do exhibit joint extreme behaviour. Through the recent translation of the geometric approach for multivariate extremes to a statistical modelling framework, geometric extremal graphical models, and results relating to them, pave the way for an approach to modelling of high dimensional extremes with complex extremal dependence structures.

</details>


### [28] [Sparse Tucker Decomposition and Graph Regularization for High-Dimensional Time Series Forecasting](https://arxiv.org/abs/2601.00377)
*Sijia Xia,Michael K. Ng,Xiongjun Zhang*

Main category: math.ST

TL;DR: 本文提出了一种结合图正则化的稀疏Tucker分解方法，用于高维向量自回归时间序列建模，有效降低参数数量并提升估计精度，理论误差界更优且算法具有全局收敛性。


<details>
  <summary>Details</summary>
Motivation: 为解决高维向量自回归模型中参数过多的问题，现有方法采用低秩矩阵或Tucker分解，但难以充分捕捉变量间的重要交互关系且估计精度有限。

Method: 将时间序列转移矩阵堆叠成三阶张量，采用稀疏Tucker分解提取关键交互结构，并引入图正则化约束响应、预测和时间因子矩阵的局部一致性，设计近端交替线性化最小化算法求解。

Result: 建立了非渐近误差界，证明其低于现有方法；算法在合成与真实数据上均表现出更优性能；所提正则化策略提升了参数估计准确性。

Conclusion: 所提出的稀疏Tucker分解结合图正则化的方法在理论和实验上均优于现有方法，能更有效地建模高维时间序列，具有良好的收敛性和应用前景。

Abstract: Existing methods of vector autoregressive model for multivariate time series analysis make use of low-rank matrix approximation or Tucker decomposition to reduce the dimension of the over-parameterization issue. In this paper, we propose a sparse Tucker decomposition method with graph regularization for high-dimensional vector autoregressive time series. By stacking the time-series transition matrices into a third-order tensor, the sparse Tucker decomposition is employed to characterize important interactions within the transition third-order tensor and reduce the number of parameters. Moreover, the graph regularization is employed to measure the local consistency of the response, predictor and temporal factor matrices in the vector autoregressive model.The two proposed regularization techniques can be shown to more accurate parameters estimation. A non-asymptotic error bound of the estimator of the proposed method is established, which is lower than those of the existing matrix or tensor based methods. A proximal alternating linearized minimization algorithm is designed to solve the resulting model and its global convergence is established under very mild conditions. Extensive numerical experiments on synthetic data and real-world datasets are carried out to verify the superior performance of the proposed method over existing state-of-the-art methods.

</details>


### [29] [Counterfactual Spaces](https://arxiv.org/abs/2601.00507)
*Junhyung Park,Fanny Yang,Thomas Icard*

Main category: math.ST

TL;DR: 本文提出了反事实概率空间和反事实因果空间两个框架，用以数学化处理反事实的随机性，将反事实与干预视为正交概念，并通过共享信息刻画不同世界之间的关系，相较于现有框架能更广泛地处理各类反事实问题。


<details>
  <summary>Details</summary>
Motivation: 现有反事实理论多依赖于因果模型中的干预概念，限制了对更广泛反事实情形的数学表达与分析，因此需要一种不依赖干预的、更普适的反事实理论框架。

Method: 通过构建反事实概率空间和反事实因果空间，分别作为概率空间和因果空间的扩展形式，其基础可测空间为各世界特有可测空间的乘积，并利用概率测度和因果核编码世界间的共享信息，从而实现对反事实的数学公理化。

Result: 建立了不依赖干预的反事实理论框架，揭示了反事实与干预是正交的概念，并能处理比现有方法更广泛的反事实情形，其中世界间信息共享的极端情况对应于独立性和同步性。

Conclusion: 反事实空间提供了一种更基础且更具包容性的数学框架，可用于更广泛地研究反事实的结构与随机性，为因果推理提供了新的理论基础。

Abstract: We mathematically axiomatise the stochastics of counterfactuals, by introducing two related frameworks, called counterfactual probability spaces and counterfactual causal spaces, which we collectively term counterfactual spaces. They are, respectively, probability and causal spaces whose underlying measurable spaces are products of world-specific measurable spaces. In contrast to more familiar accounts of counterfactuals founded on causal models, we do not view interventions as a necessary component of a theory of counterfactuals. As an alternative to Pearl's celebrated ladder of causation, we view counterfactuals and interventions are orthogonal concepts, respectively mathematised in counterfactual probability spaces and causal spaces. The two concepts are then combined to form counterfactual causal spaces. At the heart of our theory is the notion of shared information between the worlds, encoded completely within the probability measure and causal kernels, and whose extremes are characterised by independence and synchronisation of worlds. Compared to existing frameworks, counterfactual spaces enable the mathematical treatment of a strictly broader spectrum of counterfactuals.

</details>


### [30] [Asymptotic Distribution-Free Tests for Ultra-high Dimensional Parametric Regressions via Projected Empirical Processes and $p$-value Combination](https://arxiv.org/abs/2601.00541)
*Falong Tan,Shan Tang,Lixing Zhu*

Main category: math.ST

TL;DR: 本文提出了一种基于投影经验过程和p值组合的新型方法，用于检验超高维稀疏参数回归模型的拟合优度，克服了传统方法在高维下因维度灾难和依赖渐近线性与正态性假设而失效的问题。


<details>
  <summary>Details</summary>
Motivation: 在超高维设置中，传统经验过程检验由于维度灾难以及对参数估计量渐近线性和正态性的依赖而失效，因此需要一种更稳健且适用于高维情形的新检验方法。

Method: 扩展经典鞅变换至超高维情形，构建基于鞅变换后投影残差标记经验过程的Cramer-von Mises型检验，并结合多个投影方向的p值（如Cauchy组合）进行聚合；进一步提出融合经验过程检验与局部平滑检验的混合检验方法。

Result: 所提出的投影检验在几乎所有球面上的投影下具有一致性且渐近分布自由，结合p值组合后的检验具有更强鲁棒性和功率，混合检验能同时有效检测低频和高频替代假设。

Conclusion: 该方法在超高维稀疏回归模型中实现了有效的拟合优度检验，兼具理论保证与实际功效，显著优于传统方法。

Abstract: This paper develops a novel methodology for testing the goodness-of-fit of sparse parametric regression models based on projected empirical processes and p-value combination, where the covariate dimension may substantially exceed the sample size. In such ultra-high dimensional settings, traditional empirical process-based tests often fail due to the curse of dimensionality or their reliance on the asymptotic linearity and normality of parameter estimators--properties that may not hold under ultra-high dimensional scenarios. To overcome these challenges, we first extend the classic martingale transformation to ultra-high dimensional settings under mild conditions and construct a Cramer-von Mises type test based on a martingale-transformed, projected residual-marked empirical process for any projection on the unit sphere. The martingale transformation renders this projected test asymptotically distribution-free and enables us to derive its limiting distribution using only standard convergence rates of parameter estimators. While the projected test is consistent for almost all projections on the unit sphere under mild conditions, it may still suffer from power loss for specific projections. Therefore, we further employ powerful p-value combination procedures, such as the Cauchy combination, to aggregate p-values across multiple projections, thereby enhancing overall robustness. Furthermore, recognizing that empirical process-based tests excel at detecting low-frequency signals while local smoothing tests are generally superior for high-frequency alternatives, we propose a novel hybrid test that aggregates both approaches using Cauchy combination. The resulting hybrid test is powerful against both low-frequency and high-frequency alternatives. $\cdots$

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [31] [On the measurement problem in quantum mechanics: a simple proposal](https://arxiv.org/abs/2601.00010)
*Luigi E. Picasso*

Main category: quant-ph

TL;DR: 本文探讨了量子力学解释中的一些问题，特别是与著名悖论和测量过程相关的问题，并提出通过引入‘物理实验室假设’来提供新的视角，取代波函数坍缩假设。


<details>
  <summary>Details</summary>
Motivation: 解决量子力学解释中的悖论和测量问题，尤其是波函数坍缩的合理性。

Method: 引入‘物理实验室假设’，仅将对应于实际测量仪器的自伴算符视为可观测量。

Result: 该假设为理解量子测量提供了新视角，能够替代传统的波函数坍缩假设。

Conclusion: 通过限制可观测量的定义，可以更合理地解释量子现象，避免传统解释中的悖论。

Abstract: Some of the problems connected with the interpretation of quantum mechanics are enumerated, in particular those related to some well known paradoxes and, above all, to the measurement process. We then show how the so called "Physics Laboratory Assumption" introduced in [1], which considers as "observables'' only the self-adjoint operators corresponding to existing measuring instruments, can propose a new perspective on the aforementioned problems and can replace the wavefunction collapse postulate.
  [1] Luigi E. Picasso, "On the Concept of State in Quantum Mechanics: Another Way to Decoherence?'' Int. J. Theor. Phys. 62 (2), (2023)

</details>


### [32] [Classical vs quantum dynamics and the onset of chaos in a macrospin system](https://arxiv.org/abs/2601.00062)
*Haowei Fan,Vladimir Fal'ko,Xiao Li*

Main category: quant-ph

TL;DR: 研究了在热力学极限和有限尺寸下具有各向异性长程相互作用和集体耗散的周期驱动宏观自旋系统的量子与经典动力学，发现最大李雅普诺夫指数和密度矩阵局域性是判断二者一致性的关键指标。


<details>
  <summary>Details</summary>
Motivation: 探索周期驱动开放量子系统在热力学极限下的非平衡动力学行为，并比较量子与经典动力学之间的对应关系。

Method: 采用林德布拉德主方程描述系统，在热力学极限下使用平均场近似得到经典运动方程，通过最大李雅普诺夫指数、分岔图和傅里叶谱分析动力学相；在有限尺寸下进行Dicke基中的量子模拟。

Result: 识别出混沌、准周期和周期相，观察到典型的倍周期分岔和吸引子区域的分形边界；量子与经典动力学在Lyapunov时间尺度内一致，且密度矩阵非零元高度局域时才收敛；混沌 regime 中量子演化混合并扩散探索希尔伯特空间，表现为量子混沌。

Conclusion: 最大李雅普诺夫指数的符号和密度矩阵的局域性是判断量子与经典动力学一致性的关键；不一致性并不意味着本质差异，反而揭示了量子混沌的特征。

Abstract: We study a periodically driven macrospin system with anisotropic long-range interactions and collective dissipation, described by a Lindblad master equation. In the thermodynamic limit ($N\to\infty$), a mean-field treatment yields classical equations of motion, whose dynamics are characterized via the maximal Lyapunov exponent (MLE). Focusing on the thermodynamic limit, we map out chaotic, quasiperiodic, and periodic phases via bifurcation diagrams, MLEs, and Fourier spectra of evolved observables, identifying classic period-doubling bifurcations and fractal boundaries in the regions of attractors. Finite-size quantum simulations in the Dicke basis reveal that while both quantum and classical systems exhibit diverse dynamical phases, finite-size effects suppress some behaviors present in the thermodynamic limit. The sign of $λ_{\mathrm{max}}$ serves as a key indicator of convergence between quantum and classical dynamics, which agree over timescales up to the Lyapunov time. Analysis of the density matrix shows that convergence occurs only when its nonzero elements are sharply localized. However, the nonconvergence does not imply a fundamental difference between quantum and classical dynamics: in chaotic regimes, although the evolution orbits of quantum and classical systems show significant differences, quantum evolution becomes mixed and diffusively explores the Hilbert space, signaling quantum chaos, which can be confirmed by the delocalized nature of the density matrix.

</details>


### [33] [Pauli stabilizer formalism for topological quantum field theories and generalized statistics](https://arxiv.org/abs/2601.00064)
*Yitao Feng,Hanyu Xue,Ryohei Kobayashi,Po-Shen Hsin,Yu-An Chen*

Main category: quant-ph

TL;DR: 本文构建了新的晶格规范理论作为泡利稳定子模型，实现了多种时空维度下的拓扑量子场论，并系统研究了扩展激发的广义统计性质。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在晶格上表述拓扑序以及从微观哈密顿量中提取拓扑激发特性的挑战。

Method: 通过构造基于泡利稳定子的晶格规范模型，发展晶格描述方法，并设计可计算的幺正过程来探测广义统计行为。

Result: 实现了(4+1)维铁环面码及其铁磁环统计，覆盖所有(4+1)维扭曲2-形式规范理论，并推广到高维的铁膜与铁体统计模型。

Conclusion: 提出了一套普适的基于泡利算子的框架，可用于定义和探测任意维度下扩展激发的非平凡广义统计特性。

Abstract: Topological quantum field theory (TQFT) provides a unifying framework for describing topological phases of matter and for constructing quantum error-correcting codes, playing a central role across high-energy physics, condensed matter, and quantum information. A central challenge is to formulate topological order on the lattice and to extract the properties of topological excitations from microscopic Hamiltonians. In this work, we construct new classes of lattice gauge theories as Pauli stabilizer models, realizing a wide range of TQFTs in general spacetime dimensions. We develop a lattice description of the resulting extended excitations and systematically determine their generalized statistics.
  Our main example is the $(4+1)$D \emph{fermionic-loop toric code}, obtained by condensing the $e^2 m^2$-loop in the $(4+1)$D $\mathbb{Z}_4$ toric code. We show that the loop excitation exhibits fermionic loop statistics: the 24-step loop-flipping process yields a phase of $-1$. Our Pauli stabilizer models realize all twisted 2-form gauge theories in $(4+1)$D, the higher-form Dijkgraaf-Witten TQFT classified by $H^{5}(B^{2}G, U(1))$. % Beyond $(4+1)$D, the fermionic-loop toric codes form a family of $\mathbb{Z}_2$ topological orders in arbitrary dimensions featuring fermionic loop excitations, realized as explicit Pauli stabilizer codes using $\mathbb{Z}_4$ qudits. % Finally, we develop a Pauli-based framework that defines generalized statistics for extended excitations in any dimension, yielding computable lattice unitary processes to detect nontrivial generalized statistics. For example, we propose anyonic membrane statistics in $(6+1)$D, as well as fermionic membrane and volume statistics in arbitrary dimensions. We construct new families of $\mathbb{Z}_2$ topological orders: the \emph{fermionic-membrane toric code} and the \emph{fermionic-volume toric code}.

</details>


### [34] [Detection Efficiency Bounds in (Semi-)Device-Independent Scenarios](https://arxiv.org/abs/2601.00077)
*Tailan S. Sarubi,Santiago Zamora,Moisés Alves,Vinícius F. Alves,Gandhi Viswanathan,Rafael Chaves*

Main category: quant-ph

TL;DR: 本文综述了检测效率在多种设备无关和半设备无关场景中验证非经典性的重要作用，重点讨论了检测漏洞问题及其在不同因果结构中的影响。


<details>
  <summary>Details</summary>
Motivation: 由于不完美的探测器可能导致经典隐变量模型模拟量子关联，从而掩盖真实的非经典性，因此需要系统研究检测效率在各类非经典性验证场景中的作用与要求。

Method: 通过回顾贝尔场景中CHSH不等式的效率阈值等典型例子，并扩展到仪器变量、制备-测量和双局域性等多种因果结构，分析不同场景下的效率需求变化。

Result: 发现不同场景对检测效率的要求各异：例如二元仪器变量场景与贝尔场景有相同的效率界限；制备-测量场景中低效率会影响量子维度认证并威胁QKD安全性；而双局域性场景可通过多独立源显著降低效率要求。

Conclusion: 检测效率是实现可靠非经典性验证的关键因素，在不同实验架构下其阈值要求可被优化，为未来 loophole-free 实验设计提供了指导。

Abstract: This article provides a comprehensive review of the critical role of detection efficiency in demonstrating non-classicality across various device-independent and semi-device-independent scenarios. The central focus is the detection loophole, a challenge in which imperfect detectors can allow classical hidden variable models to mimic quantum correlations, thus masking genuine non-classicality. As a review, the article revisits the paradigmatic Bell scenario, detailing the efficiency requirements for the CHSH inequality, such as the 2/3 threshold for symmetric efficiencies, and traces the historical trajectory toward the first loophole-free tests. The analysis extends to other causal structures to explore how efficiency requirements are affected in different contexts. These include the instrumental scenario, which for binary variables has recently been shown to follow the same inefficiency bounds as the bipartite dichotomic Bell scenario; the prepare-and-measure scenario, where inefficiencies impact the certification of a quantum system's dimension and create security breaches in protocols such as Quantum Key Distribution (QKD); and the bilocality scenario, which exemplifies how employing multiple independent sources can significantly relax the required efficiencies to certify non-classical correlations.

</details>


### [35] [Double-Pumped Kerr Parametric Amplifier Beyond the Gain-Bandwidth Limit](https://arxiv.org/abs/2601.00078)
*Nicolas Zapata,Najmeh Etehadi Abari,Mitchell Field,Patrick Winkel,Simon Geisert,Soeren Ihssen,Anja Metelmann,Ioan M. Pop*

Main category: quant-ph

TL;DR: 提出了一种无需接近不稳定性点的双驱动参量放大方法，在颗粒铝二聚体中实现了宽带、高增益且接近量子极限的放大。


<details>
  <summary>Details</summary>
Motivation: 传统超导参量放大器需工作在不稳定性附近，导致增益增加时瞬时带宽下降，限制了性能。

Method: 采用两个同时驱动的相位保持增益和频率转换机制，在具有克尔非线性的颗粒铝二聚体中实现参量放大。

Result: 在20 dB增益下实现了六倍带宽提升，增益-带宽关系突破传统限制，最高达25 dB，且噪声接近量子极限。

Conclusion: 该方法打破了传统增益-带宽权衡，为微波量子器件读出提供了更优的放大方案。

Abstract: Superconducting standing$-$wave parametric amplifiers are crucial for the readout of microwave quantum devices. Despite significant improvements in recent years, the need to operate near an instability point imposes a fundamental constraint: the instantaneous bandwidth decreases with increasing amplifier gain. Here we show that it is possible to obtain parametric amplification without instability by using two simultaneous drives that activate phase-preserving gain and frequency conversion. Realized in a granular aluminum dimer with Kerr nonlinearity, our method demonstrates a sixfold bandwidth increase at 20 dB gain, surpasses the conventional gain$-$bandwidth scaling up to 25 dB, and remains near the quantum limit.

</details>


### [36] [A compellingly simple proof of the speed of sound for interacting bosons](https://arxiv.org/abs/2601.00111)
*J. Eisert*

Main category: quant-ph

TL;DR: 本文证明了广义Bose-Hubbard模型中粒子传播的速度上限，表明在适当局部扰动下，粒子数传播具有有限声速。


<details>
  <summary>Details</summary>
Motivation: 探讨相互作用玻色系统中信息与粒子传播是否存在有限声速这一长期开放问题。

Method: 通过几行简洁但非显而易见的推导，为定义在一般晶格上的广义Bose-Hubbard模型建立了粒子传播的简单界限。

Result: 证明了在适当局部扰动的定态下，粒子数传播具有有限声速。

Conclusion: 相互作用玻色系统在粒子传播中也遵循因果律，支持有限群速度的存在。

Abstract: On physical grounds, one expects locally interacting quantum many-body systems to feature a finite group velocity. This intuition is rigorously underpinned by Lieb-Robinson bounds that state that locally interacting Hamiltonians with finite-dimensional constituents on suitably regular lattices always exhibit such a finite group velocity. This also implies that causality is always respected by the dynamics of quantum lattice models. It had been a long-standing open question whether interacting bosonic systems also feature finite speeds of sound in information and particle propagation, which was only recently resolved. This work proves a strikingly simple such bound for particle propagation - shown in literally a few elementary, yet not straightforward, lines - for generalized Bose-Hubbard models defined on general lattices, proving that appropriately locally perturbed stationary states feature a finite speed of sound in particle numbers.

</details>


### [37] [(PhD Thesis) The Information Locally Stored in Quantum Fields: From Entanglement to Gravity](https://arxiv.org/abs/2601.00128)
*T. Rick Perche*

Main category: quant-ph

TL;DR: 本文是作者在滑铁卢大学通过的博士论文更新版，旨在向更广泛的读者介绍局部量子场论及其相关研究方向，涵盖局部探测、纠缠、相互作用近似和时空几何信息等主题，并希望为学生提供研究指导。


<details>
  <summary>Details</summary>
Motivation: 为了让更广泛的受众了解作者博士论文中的研究成果，并为有志于相关领域研究的学生提供入门指导和合作机会。

Method: 论文分为五个章节，依次介绍局部量子场论基础、局域探测器、量子场中的纠缠及其探测方法、量子场相互作用的直接相互作用近似条件，以及量子场中蕴含的时空几何信息。

Result: 系统梳理了局部量子场论中的多个关键研究方向，提供了理论框架和研究路径，有助于后续研究者开展相关工作。

Conclusion: 该论文不仅总结了作者的研究成果，也为未来在局部量子场论及相关领域的研究提供了清晰的导引和合作契机。

Abstract: This is an updated version of my PhD thesis, defended at the University of Waterloo on the 2nd of April 2025, uploaded to the ArXiv with the goal of reaching a wider audience. The thesis is divided into 5 chapters, respectively containing (I) a brief introduction to local quantum field theory (QFT), (II) a description of local probes in QFT, (III) a discussion of entanglement in QFT and how to probe it, (IV) a description of the regimes where QFT interactions can be approximated by direct interactions, and (V) a discussion the information about the geometry of spacetime contained in quantum fields. The partial goal of this thesis is to serve as a guide for students aiming to tackle these different research programs. If the reader is interested in pursuing one or more research projects detailed here, they are encouraged to contact me for collaboration in these topics.

</details>


### [38] [Towards a temperature-insensitive composite diamond clock](https://arxiv.org/abs/2601.00157)
*Sean Lourette,Andrey Jarmola,Jabir Chathanathil,Victor M. Acosta,A. Glen Birdwell,Peter Blümler,Dmitry Budker,Sebastián C. Carrasco,Tony G. Ivanov,Shimon Kolkowitz,Vladimir S. Malinovsky*

Main category: quant-ph

TL;DR: 提出了一种基于金刚石氮空位中心电子与核自旋跃迁的复合频率参考方法，通过结合电子零场分裂和核四极分裂实现温度补偿，显著提升了频率稳定度。


<details>
  <summary>Details</summary>
Motivation: NV中心虽有潜力用于固态频率标准，但其电子零场分裂对温度敏感，限制了其作为稳定时钟的应用。需解决温度依赖性问题。

Method: 设计八相位脉冲序列，交替测量电子分裂D和核四极分裂Q，在高密度NV系综中实现温度补偿的复合频率参考，并抑制脉冲误差。

Result: 在室温下与铷原子钟对比，复合钟的分数不稳定度在200秒平均时间下低于5×10⁻⁹，在2×10⁵秒下低于1×10⁻⁸，相较仅用D频率提升4至200倍；温度不再是主要不稳定性来源。

Conclusion: 金刚石中电子与核自旋跃迁的协同利用为热稳定的固态频率计量提供了可行路径，推动紧凑型多功能量子传感器和时钟的发展。

Abstract: Frequency references based on solid state spins promise simplicity, compactness, robustness, multifunctionality, ease of integration, and high densities of emitters. Nitrogen-vacancy (NV) centers in diamond are a natural candidate, but the electronic zero-field splitting exhibits a large fractional temperature dependence, which has precluded its use as a stable clock transition. Here we show that this limitation can be overcome by forming a composite frequency reference that combines measurements of the electronic splitting D with the nuclear quadrupole splitting of the $^{14}$N nuclear spin intrinsic to the NV center. We further benchmark this composite approach against alternative strategies for mitigating temperature sensitivity. By implementing a specially designed pulse sequence with an eight-phase control scheme that suppresses pulse imperfections, we interleave measurements of D and Q in a high-density NV ensemble and demonstrate a temperature-compensated composite frequency reference. The stability of this composite diamond clock is characterized over a 10-day period at room temperature through a comparison to a Rb vapor-cell clock, yielding a fractional instability below $5 \times 10^{-9}$ for an averaging time of $τ= 200$ s and below $1 \times 10^{-8}$ at $τ= 2 \times 10^5$ s, corresponding to measured improvements by a factor of 4 and 200, respectively, over a clock based purely on the single frequency D for the same periods. By characterizing the residual sensitivity to magnetic fields, optical power, and radio-frequency drive amplitudes, we find that temperature is no longer the dominant source of instability. These results establish complementary electron- and nuclear-spin transitions in diamond as a viable route to thermally robust frequency metrology, providing a pathway toward compact, multifunctional solid-state clocks and quantum sensors.

</details>


### [39] [Reversing Heat Flow by Coherence in a Multipartite Quantum System](https://arxiv.org/abs/2601.00198)
*Keyi Huang,Qi Zhang,Xiangjing Liu,Ruiqing Li,Xinyue Long,Hongfeng Liu,Xiangyu Wang,Yu-ang Fan,Yuxuan Zheng,Yufang Feng,Yu Zhou,Jack Ng,Xinfang Nie,Zhong-Xiao Man,Dawei Lu*

Main category: quant-ph

TL;DR: 实验展示了多部分自旋系统中的内部量子相干性可以在无初始环境关联的情况下逆转热流，且热流方向和大小由相干项的强度和相位决定。


<details>
  <summary>Details</summary>
Motivation: 探索量子相干性在热流调控中的作用，挑战经典热力学第二定律的预期。

Method: 基于级联相互作用的碰撞模型进行实验验证。

Result: 证实了量子相干性的强度和相位可决定能量传递的方向和幅度。

Conclusion: 利用局部量子特性可以精确控制热流，为量子热力学调控提供了新途径。

Abstract: The second law of thermodynamics dictates that heat flows spontaneously from a high-temperature entity to a lower-temperature one. Yet, recent advances have demonstrated that quantum correlations between a system and its thermal environment can induce a reversal of heat flow, challenging classical thermodynamic expectations. Here, we experimentally demonstrate that internal quantum coherence in a multipartite spin system can also reverse heat flow, without relying on initial correlations with the environment. Under the collision model with cascade interaction, we verify that both the strength and the phase of the coherence term determine the direction and magnitude of energy transfer. These results enable precise control of heat flow using only local quantum properties.

</details>


### [40] [DC-MBQC: A Distributed Compilation Framework for Measurement-Based Quantum Computing](https://arxiv.org/abs/2601.00214)
*Yecheng Xue,Rui Yang,Zhiding Liang,Tongyang Li*

Main category: quant-ph

TL;DR: 本文提出了首个面向测量型量子计算（MBQC）的分布式量子编译框架DC-MBQC，解决了任务分配与跨量子处理器通信两大挑战，并在光子量子系统中显著提升了执行效率与光子寿命需求。


<details>
  <summary>Details</summary>
Motivation: 测量型量子计算（MBQC）作为一种与电路模型不同的通用量子计算模型，在光子平台上具有优势，但其分布式实现研究较少。本文旨在填补这一空白，推动分布式量子计算在MBQC中的应用。

Method: 提出DC-MBQC框架：1）设计自适应图划分算法以在保持图态结构的同时平衡各量子处理单元（QPU）负载；2）引入层调度问题并给出求解算法；3）针对光子损耗问题优化执行时间和所需光子寿命。

Result: 实验结果表明，在8个全连接QPU上，所需光子寿命减少7.46倍，运行速度提升6.82倍。

Conclusion: DC-MBQC有效支持了MBQC模型下的分布式量子计算，显著降低了光子系统中的资源需求，验证了分布式架构在光子量子计算中的潜力。

Abstract: Distributed quantum computing (DQC) is a promising technique for scaling up quantum systems. While significant progress has been made in DQC for quantum circuit models, there exists much less research on DQC for measurement-based quantum computing (MBQC), which is a universal quantum computing model that is essentially different from the circuit model and particularly well-suited to photonic quantum platforms. In this paper, we propose DC-MBQC, the first distributed quantum compilation framework tailored for MBQC. We identify and address two key challenges in enabling DQC for MBQC. First, for task allocation among quantum processing units (QPUs), we develop an adaptive graph partitioning algorithm that preserves the structure of the graph state while balancing the workload across QPUs. Second, for inter-QPU communication, we introduce the layer scheduling problem and propose an algorithm to solve it. Regrading realistic hardware requirements, we optimize the execution time of running quantum programs and the corresponding required photon lifetime to avoid fatal failures caused by photon loss. Our experiments demonstrate a $7.46\times$ improvement on required photon lifetime and $6.82\times$ speedup with 8 fully-connected QPUs, which further confirm the advantage of distributed quantum computing in photonic systems. The source code is publicly available at https://github.com/qfcwj/DC-MBQC.

</details>


### [41] [Efficient implementation of single particle Hamiltonians in exponentially reduced qubit space](https://arxiv.org/abs/2601.00247)
*Martin Plesch,Martin Friák,Ijaz Ahamed Mohammad*

Main category: quant-ph

TL;DR: 提出一种对数量子比特编码方法，将具有N个物理位点的系统映射到仅⌈log₂N⌉个量子比特上，显著降低变分算法在空间、时间和采样上的资源开销。


<details>
  <summary>Details</summary>
Motivation: 针对当前和近期量子硬件在量子比特数量、电路深度和重复测量成本方面的限制，尤其是在模拟固体系统哈密顿量时面临的挑战，需要开发更高效的量子资源利用方案。

Method: 引入一种对数量子比特编码，保持与物理模型的清晰对应；在压缩的量子寄存器中构建相容的变分电路，并采用受格雷码启发的测量策略，使全局测量设置数量随系统规模对数增长。

Result: 提出了一个综合量子资源消耗的体积效率度量指标，表明变分循环中的总时空采样体积可从N²降至(logN)³，实现了指数级的硬件资源节约。

Conclusion: 该方法使得在更小的量子设备上高效模拟大规模固体系统哈密顿量成为可能，显著扩展了近期变分量子算法的应用范围。

Abstract: Current and near-term quantum hardware is constrained by limited qubit counts, circuit depth, and the high cost of repeated measurements. We address these challenges for solid state Hamiltonians by introducing a logarithmic-qubit encoding that maps a system with $N$ physical sites onto only $\lceil \log_2 N \rceil$ qubits while maintaining a clear correspondence with the underlying physical model. Within this reduced register, we construct a compatible variational circuit and a Gray-code-inspired measurement strategy whose number of global settings grows only logarithmically with system size. To quantify the overall hardware load, we introduce a volumetric efficiency metric that combines the number of qubit, circuit depth, and the number of measurement settings into a single measure, expressing the overall computation costs. Using this metric, we show that the total space-time-sampling volume required in a variational loop can be reduced dramatically from $N^2$ to $(logN)^3$ for hardware efficient ansatz, allowing an exponential reduction in time and size of the quantum hardware. These results demonstrate that large, structured solid-state Hamiltonians can be simulated on substantially smaller quantum registers with controlled sampling overhead and manageable circuit complexity, extending the reach of variational quantum algorithms on near-term devices.

</details>


### [42] [First appearance of quasiprobability negativity in quantum many-body dynamics](https://arxiv.org/abs/2601.00259)
*Rohit Kumar Shukla,Amikam Levy*

Main category: quant-ph

TL;DR: 引入了首次负性（FTN）作为衡量相互作用量子系统中非经典行为出现的动态指标，并在Ising链中展示了其对不同物理条件的敏感响应。


<details>
  <summary>Details</summary>
Motivation: 探索多体系统中量子动力学的非经典特征，特别是准概率分布负性的动态出现。

Method: 基于Margenau-Hill准概率定义首次负性（FTN），并在Ising链模型中结合数值模拟与量子速度极限理论进行分析。

Result: FTN能清晰区分相互作用主导和场主导的区域，受温度影响并反映非可积性破缺；揭示了测量不相容性在晶格中的时空传播结构，并与量子速度极限有良好对应。

Conclusion: FTN是一种实用且实验上可实现的探针，可用于探测实时量子相干性和语境性，适用于当前具备连续弱/强测量能力的实验平台。

Abstract: Quasiprobability distributions capture aspects of quantum dynamics that have no classical counterpart, yet the dynamical emergence of their negativity in many-body systems remains largely unexplored. We introduce the \emph{first-time negativity} (FTN) of the Margenau-Hill quasiprobability as a dynamical indicator of when local measurement sequences in an interacting quantum system begin to exhibit genuinely nonclassical behavior. Using the Ising chain, we show that FTN discriminates clearly between interaction-dominated and field-dominated regimes, is systematically reshaped by temperature, and responds sensitively to the breaking of integrability. When measurements are performed on different sites, FTN reveals a characteristic spatio-temporal structure that reflects the finite-time spreading of operator incompatibility across the lattice. We further compare the numerical onset of negativity with a recently proposed quantum speed limit (QSL) for quasiprobabilities, which provides a geometric benchmark for the observed dynamics. Our results identify FTN as a practical and experimentally accessible probe of real-time quantum coherence and contextuality, directly suited to current platforms capable of sequential weak and strong measurements.

</details>


### [43] [Nature is stingy: Universality of Scrooge ensembles in quantum many-body systems](https://arxiv.org/abs/2601.00266)
*Wai-Keong Mok,Tobias Haug,Wen Wei Ho,John Preskill*

Main category: quant-ph

TL;DR: 本文研究了量子模拟器中投影系综的普适性行为，提出并论证了Scrooge系综在深热化中的核心作用，建立了描述受限系统下量子热化的统一理论框架。


<details>
  <summary>Details</summary>
Motivation: 在存在有限温度或守恒律等物理约束下，传统基于Haar随机系综的热化理论不再适用，需要建立更一般的深热化描述框架。

Method: 引入Scrooge k-设计来刻画受约束下的最大熵纯态分布，并通过解析推导与多体系统的数值模拟相结合，分析三种不同物理机制下Scrooge设计的涌现条件。

Result: 发现了三种可导致Scrooge k-设计出现的物理机制：长时间混沌酉演化、互补子系统测量诱导局部Scrooge设计，以及在高度混乱基底下测量产生的局域Scrooge系综；数值结果表明相干性、纠缠、非稳定性和信息 scrambling 是其关键资源。

Conclusion: 深热化普遍由Scrooge系综支配，本文为受限量子多体系统中最大熵、信息节约型随机性的涌现提供了统一的理论基础。

Abstract: Recent advances in quantum simulators allow direct experimental access to the ensemble of pure states generated by measuring part of an isolated quantum many-body system. These projected ensembles encode fine-grained information beyond thermal expectation values and provide a new window into quantum thermalization. In chaotic dynamics, projected ensembles exhibit universal statistics, a phenomenon known as deep thermalization. While infinite-temperature systems generate Haar-random ensembles, realistic physical constraints such as finite temperature or conservation laws require a more general framework. It has been proposed that deep thermalization is governed in general by the emergence of Scrooge ensembles, maximally entropic distributions of pure states consistent with the underlying constraints. Here we provide rigorous arguments supporting this proposal. To characterize this universal behavior, we invoke Scrooge $k$-designs, which approximate Scrooge ensembles, and identify three physically distinct mechanisms for their emergence. First, global Scrooge designs can arise from long-time chaotic unitary dynamics alone, without the need for measurements. Second, if the global state is highly scrambled, a local Scrooge design is induced when the complementary subsystem is measured. Third, a local Scrooge ensemble arises from an arbitrary entangled state when the complementary system is measured in a highly scrambled basis. Numerical simulations across a range of many-body systems identify coherence, entanglement, non-stabilizerness, and information scrambling as essential resources for the emergence of Scrooge-like behavior. Taken together, our results establish a unified theoretical framework for the emergence of maximally entropic, information-stingy randomness in quantum many-body systems.

</details>


### [44] [When Does Quantum Differential Privacy Compose?](https://arxiv.org/abs/2601.00337)
*Daniel Alabi,Theshani Nuradha*

Main category: quant-ph

TL;DR: 本文研究了量子差分隐私（QDP）中的组合性问题，指出经典组合定理在量子场景下不直接适用，并提出了在特定条件下恢复良好组合保证的框架。


<details>
  <summary>Details</summary>
Motivation: 量子差分隐私缺乏类似经典的组合定理，难以为复杂算法提供端到端的隐私保证，因此需要澄清量子设置下组合性的可能性与限制。

Method: 通过分析POVM-based近似QDP中经典组合性的失效情况，提出在张量积通道和乘积邻近输入下的量子矩会计方法，基于算子值隐私损失和矩阵矩生成函数构建Rényi型发散度量。

Result: 证明了即使单独完全私有的量子信道在联合实现时也可能丧失隐私；但在张量积结构下，控制矩可导出对测量Rényi散度的界，从而获得类似经典高级组合的隐私保证。

Conclusion: 量子差分隐私的组合性需要对信道、输入和测量施加结构性假设，本文提供了理解哪些经典概念可推广至量子场景的原则性框架。

Abstract: Composition is a cornerstone of classical differential privacy, enabling strong end-to-end guarantees for complex algorithms through composition theorems (e.g., basic and advanced). In the quantum setting, however, privacy is defined operationally against arbitrary measurements, and classical composition arguments based on scalar privacy-loss random variables no longer apply. As a result, it has remained unclear when meaningful composition guarantees can be obtained for quantum differential privacy (QDP).
  In this work, we clarify both the limitations and possibilities of composition in the quantum setting. We first show that classical-style composition fails in full generality for POVM-based approximate QDP: even quantum channels that are individually perfectly private can completely lose privacy when combined through correlated joint implementations. We then identify a setting in which clean composition guarantees can be restored. For tensor-product channels acting on product neighboring inputs, we introduce a quantum moments accountant based on an operator-valued notion of privacy loss and a matrix moment-generating function. Although the resulting Rényi-type divergence does not satisfy a data-processing inequality, we prove that controlling its moments suffices to bound measured Rényi divergence, yielding operational privacy guarantees against arbitrary measurements. This leads to advanced-composition-style bounds with the same leading-order behavior as in the classical theory.
  Our results demonstrate that meaningful composition theorems for quantum differential privacy require carefully articulated structural assumptions on channels, inputs, and adversarial measurements, and provide a principled framework for understanding which classical ideas do and do not extend to the quantum setting.

</details>


### [45] [Chaos and thermalization in Clifford-Floquet dynamics](https://arxiv.org/abs/2601.00511)
*Anton Kapustin,Daniil Radamovich*

Main category: quant-ph

TL;DR: 研究了平移不变Clifford量子元胞自动机在d维无限量子比特系统上的周期性幺正动力学的遍历性质，发现若系统无周期性，多数初态将热化至无限温度态，特别适用于短程纠缠且接近平衡态的初态，并指出弱热化与强热化的区别。


<details>
  <summary>Details</summary>
Motivation: 探讨非周期性量子元胞自动机下无限量子系统是否会在长时间演化后达到热平衡态，特别是无限温度态。

Method: 通过分析平移不变Clifford量子元胞自动机的弗洛凯动力学，研究其对无限d维量子比特系统的长期演化行为，结合遍历理论和状态收敛分析。

Result: 证明了在无周期性条件下，许多类初态（包括纯态和混合态）会热化至无限温度态，尤其适用于短程纠缠且接近平衡的初态，并揭示了弱热化与强热化的不同表现。

Conclusion: 大多数非周期性Clifford量子元胞自动机会导致系统热化，支持热化假设，但需区分热化的不同类型。

Abstract: We study the ergodic properties of a unitary Floquet dynamics arising from the repeated application of a translationally-invariant Clifford Quantum Cellular Automata to an infinite system of qubits in d dimensions. One expects that if the QCA does not exhibit any periodicity, a generic initial state of qubits will thermalize, that is, approach the infinite-temperature state. We show that this is true for many classes of states, both pure and mixed. In particular, this is true for all initial states that are short-range entangled and close to the equilibrium state. We also point out a subtle distinction between weak and strong thermalization.

</details>


### [46] [Probabilistic Entanglement Distillation and Cost under Approximately Nonentangling and Dually Nonentangling Instruments](https://arxiv.org/abs/2601.00383)
*Xian Shi*

Main category: quant-ph

TL;DR: 本论文研究了在近似非纠缠和对偶非纠缠量子操作下的概率性纠缠蒸馏与纠缠代价，利用后选择量子假设检验框架，建立了纠缠蒸馏误差指数与可分态假设检验之间的解析关系，并给出了误差指数的解析表达式及纠缠代价的界限。


<details>
  <summary>Details</summary>
Motivation: 在一般资源理论中，概率性变换的局限性已有所进展，但针对近似（对偶）非纠缠操作下概率性纠缠蒸馏的误差指数仍缺乏解析公式，本文旨在填补这一空白。

Method: 基于后选择量子假设检验框架，将概率性纠缠蒸馏与针对可分态集合的假设检验建立直接联系，并分析在近似非纠缠（ANE）和近似对偶非纠缠（ADNE）操作下的误差指数与纠缠成本。

Result: 推导出在ANE操作下纠缠蒸馏误差指数的解析表达式；将其与受限于可分测量的后选择假设检验相关联；建立了概率性纠缠稀释下ANE与ADNE操作之间的纠缠代价关系，并给出了非纠缠操作下的纠缠代价上界。

Conclusion: 本文成功地将概率性纠缠蒸馏问题转化为后选择假设检验问题，提供了误差指数的完整解析刻画，深化了对纠缠在有限次操作下转化行为的理解，并为一般量子资源理论中的概率性转换提供了新工具。

Abstract: Entanglement distillation and entanglement cost are fundamental tasks in quantum entanglement theory. This work studies both in the probabilistic setting and focuses on the asymptotic error exponent of probabilistic entanglement distillation when the operational model is $δ$-approximately nonentangling(ANE) and $δ$-approximately dually nonentangling(ADNE) quantum instruments. While recent progress has clarified limitations of probabilistic transformations in general resource theories, an analytic formula for the error exponent of probabilistic entanglement distillation under approximately (dually) nonentangling operations has remained unavailable.
  Building on the framework of postselected quantum hypothesis testing, we establish a direct connection between probabilistic distillation and postselected hypothesis testing against the set of separable states. In particular, we derive an analytical characterization of the distillation error exponent under ANE. Besides, we relate the exponent to postselected hypothesis testing with measurements restricted to be separable. We further investigate probabilistic entanglement dilution and establish a relation between probabilistic entanglement costs under approximately nonentangling and approximately dually nonentangling instruments, together with a bound on the probabilistic entanglement cost under nonentangling instruments

</details>


### [47] [Exponentially Accelerated Sampling of Pauli Strings for Nonstabilizerness](https://arxiv.org/abs/2601.00761)
*Zhenyu Xiao,Shinsei Ryu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum magic, quantified by nonstabilizerness, measures departures from stabilizer structure and underlies potential quantum speedups. We introduce an efficient classical algorithm that exactly computes stabilizer Rényi entropies and stabilizer nullity for generic many-body wavefunctions of $N$ qubits. The method combines the fast Walsh-Hadamard transform with an exact partition of Pauli operators. It achieves an exponential speedup over direct approaches, reducing the average cost per sampled Pauli string from $O(2^N)$ to $O(N)$. Building on this framework, we further develop a Monte-Carlo estimator for stabilizer Rényi entropies together with a Clifford-based variance-reduction scheme that suppresses sampling fluctuations. We benchmark the accuracy and efficiency on ensembles of random magic states, and apply the method to random Clifford circuits with doped $T$ gates, comparing different doping architectures. Our approach applies to arbitrary quantum states and provides quantitative access to magic resources both encoded in highly entangled states and generated by long-time nonequilibrium dynamics.

</details>


### [48] [The Maximal Entanglement Limit in Statistical and High Energy Physics](https://arxiv.org/abs/2601.00405)
*Dmitri E. Kharzeev*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: These lectures advocate the idea that quantum entanglement provides a unifying foundation for both statistical physics and high-energy interactions. I argue that, at sufficiently long times or high energies, most quantum systems approach a Maximal Entanglement Limit (MEL) in which phases of quantum states become unobservable, reduced density matrices acquire a thermal form, and probabilistic descriptions emerge without invoking ergodicity or classical randomness. Within this framework, the emergence of probabilistic parton model, thermalization in the break-up of confining strings and in high-energy collisions, and the universal small $x$ behavior of structure functions arise as direct consequences of entanglement and geometry of high-dimensional Hilbert space.

</details>


### [49] [Chip scale superconducting quantum gravimeter based on a SQUID transmon mechanical resonator](https://arxiv.org/abs/2601.00425)
*Salman Sajad Wani,Mughees Ahmed Khan,Abrar Ahmed Naqash,Saif Al-Kuwari*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Precise gravitational measurements are vital for geophysics and inertial navigation, but current platforms struggle to combine absolute accuracy with high-bandwidth tracking. We address this challenge with a chip-scale superconducting gravimeter that couples a flux-tunable transmon qubit to a high-$Q$ mechanical resonator. We embed the mechanical element inside the qubit's SQUID loop. This allows us to exploit the Josephson potential's nonlinearity, creating a motion-dependent inductance that maps gravitational displacement onto the qubit's geometric phase. Using a stroboscopic measurement protocol, we suppress mechanical decoherence at revival times. This yields a predicted sensitivity of $10^2\,\mathrm{nGal}/\sqrt{\mathrm{Hz}}$, approaching the performance of atomic sensors but with kilohertz-rate sampling. With electrical {in situ} tunability and SI traceability via microwave spectroscopy, this architecture offers a practical route to high-speed, quantum-limited on-chip gravimetry.

</details>


### [50] [Multistep quantum master equation theory for response functions in four wave mixing electronic spectroscopy of multichromophoric macromolecules](https://arxiv.org/abs/2601.00431)
*Seogjoo J. Jang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work provides an alternative derivation of third order response functions in four wave mixing spectroscopy of multichromophoric macromolecular systems considering only single exciton states. For the case of harmonic oscillator bath linearly and diagonally coupled to exciton states, closed form expressions showing all the explicit time dependences are derived. These expressions can provide more solid physical basis for understanding 2-dimensional electronic spectroscopy signals. For more general cases of system-bath coupling, the quantum master equation (QME) approach is employed for the derivation of multistep time evolution equations for Green function-like operators. Solution of these equations is feasible at the level of 2nd order non-Markovian QME, and the new approach can account for inter-exciton coupling, dephasing, relaxation, and non-Markovian effects in a consistent manner.

</details>


### [51] [Prediction of a measurable sign change in the Casimir force using a magnetic fluid](https://arxiv.org/abs/2601.00483)
*Long Ma,Larissa Inácio,Dai-Nam Le,Lilia M. Woods,Mathias Boström*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We demonstrate quantum levitation controlled by Casimir forces acting between a polystyrene surface and a Teflon-coated metallic substrate immersed in a mixture of Toluene and magnetite particles. This system experiences repulsion-attraction transitions in the Casimir interaction for distances where the effect is measurable. This Casimir trapping can be controlled by clever choices of metallic and ferrofluid materials, which are directly linked to the emergence of the trapping effect. Thermal and quantum contributions are investigated in detail, showing how the optical and magnetic properties of the ferrofluid and other materials affect the magnitude of the trapping and its distance range of observability.

</details>


### [52] [A Geometrical Design Tool for Building Cost-Effective Layout-Aware n-Bit Quantum Gates Using the Bloch Sphere Approach](https://arxiv.org/abs/2601.00484)
*Ali Al-Bayaty,Marek Perkowski*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The conventional design technique of any n-bit quantum gate is mainly achieved using unitary matrices multiplication, where n >= 2 and 1 <= m <= n-1 for m target qubits and n-m control qubits. These matrices represent quantum rotations by an n-bit quantum gate. For a quantum designer, such a conventional technique requires extensive computational time and effort, which may generate an n-bit quantum gate with a too high quantum cost. The Bloch sphere is only utilized as a visualization tool to verify the conventional design correctness for quantum rotations by a quantum gate. In contrast, this paper introduces a new concept of using the Bloch sphere as a "geometrical design tool" to build cost-effective n-bit quantum gates with lower quantum costs. This concept is termed the "Bloch sphere approach (BSA)". In BSA, a cost-effective n-bit quantum gate is built without using any unitary matrices multiplication. Instead, the quantum rotations for such a gate are visually selected using the geometrical planar intersections of the Bloch sphere. The BSA can efficiently map m targets among n-m controls for an n-bit quantum gate, to satisfy the limited layout connectivity for the physical neighboring qubits of a quantum computer. Experimentally, n-bit quantum gates built using the BSA always have lower quantum costs than those for such gates built using the conventional quantum design techniques.

</details>


### [53] [Non-Hermitian Band Topology and Edge States in Atomic Lattices](https://arxiv.org/abs/2601.00487)
*Wenxuan Xie,John C Schotland*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the band structure and topological phases of one- and two-dimensional bipartite atomic lattices mediated by long-range dissipative radiative coupling. By deriving an effective non-Hermitian Hamiltonian for the single-excitation sector, we demonstrate that the low-energy dynamics of the system are governed by a Dirac equation with a complex Fermi velocity. We analyze the associated topological invariants for both the SSH and honeycomb models, utilizing synthetic gauge fields to break time-reversal symmetry in the latter. Finally, we explicitly verify the non-Hermitian bulk-edge correspondence by deriving analytical solutions for edge states localized at domain boundaries.

</details>


### [54] [Casimir interactions and drift currents](https://arxiv.org/abs/2601.00489)
*Modi Ke,Dai-Nam Le,Lilia M. Woods*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the fluctuation-induced Casimir interactions between two parallel graphene sheets carrying steady-state drift currents. The graphene properties are modeled based on the shifted Fermi disk model to capture the non-equilibrium optical response of the system. We find that the drift current introduces a repulsive correction to the perpendicular to the layers Casimir interaction, thereby reducing the overall attractive force. Although the correction is repulsive, it does not overcome the underlying attraction between the layers. It also generates a lateral force that opposes the carrier flow direction. Both contributions are studied in terms of distance and drift velocity functionalities showing pathways for Casimir force control.

</details>


### [55] [Photonic Reservoir Engineering via 2D $Λ$-Type Atomic Arrays in Waveguide QED](https://arxiv.org/abs/2601.00622)
*Thi Phuong Anh Nguyen,Le Phuong Hoang,Xuan Binh Cao*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Electromagnetically induced transparency (EIT) in $Λ$-type atomic systems underpins quantum technologies such as high-fidelity memory and nonlinear optics, but conventional setups face intrinsic limitations. Standard geometries of one-dimensional atomic chains coupled to waveguides allow only a single bright superradiant channel, while subradiant modes remain weakly accessible, limiting control over collective radiative behavior and dark-state pathways. This leads to unwanted inelastic processes, degrading memory fidelity and reducing nonlinear photon generation efficiency. Here, we propose two two-dimensional (2D) atomic lattice geometries coupled to a photonic crystal waveguide, namely Zigzag and Orthogonal structures. In the Zigzag model, engineered collective super- and subradiant modes produce a flattened EIT window, broadening the transmission bandwidth and suppressing unwanted scattering to enhance quantum memory fidelity. In the Orthogonal model, four-wave mixing (FWM) intensity is amplified by up to six orders of magnitude relative to a conventional one-dimensional $Λ$-type EIT chain with identical $Γ_{1D}$, $Ω_c$, and probe intensity, with localized idler photons forming well-defined spectral modes. These results demonstrate a versatile route to engineer structured photonic reservoirs for on-demand photon generation, high-fidelity quantum storage, and enhanced nonlinear optical processes.

</details>


### [56] [Experimental exclusion of a generalized Károlyházy gravity-induced decoherence model](https://arxiv.org/abs/2601.00651)
*Nicola Bortolotti,Kristian Piscicchia,Matthias Laubenstein,Simone Manti,Antonino Marcianò,Federico Nola,Catalina Curceanu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We report new experimental constraints on the generalized version of the gravity-induced decoherence model originally proposed by Károlyházy. Using data collected by the VIP Collaboration at the INFN Gran Sasso National Laboratory with a high-purity germanium detector, we derive an improved lower bound on the spatial correlation length $R_K$ characterizing metric fluctuations in the model. We obtain a bound $R_K > 4.64$ m (95\% C.L.), which exceeds by more than an order of magnitude the previous experimental limit. When combined with the theoretical upper bound $R_K <1.98$ m derived from macroscopic localization requirements, our result excludes the generalized Károlyházy model. The same conclusion applies to an associated non-Markovian formulation of the Continuous Spontaneous Localization (CSL) model. Our findings significantly tighten experimental constraints on gravity-related decoherence scenarios and demonstrate the sensitivity of underground low-background experiments to foundational modifications of quantum mechanics.

</details>


### [57] [Ultracold Quantum Gravimeters: An Introduction for Geophysicists](https://arxiv.org/abs/2601.00676)
*Ivaldevingles Rodrigues De Souza Junior,Andrea Trombettoni,Carla Braitenberg*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper aims at providing an accessible introduction to ultracold quantum gravimeters tailored for geophysicists. We do not focus here on geophysical applications, as these are already well known to geophysicists, but rather provide a pedagogical exposition of the quantum-mechanical concepts needed to understand the operation of quantum gravimeters. We present a review of gravimeters based on two- and three-level atomic systems, focusing on the fundamental mechanisms of atomic interferometry. The functioning of Mach-Zehnder interferometers is discussed through the action of $π/2$ and $π$ pulses, showing how the resulting phase shift encodes gravitational acceleration. The effect of noise is briefly discussed.

</details>


### [58] [Effects of Donor-Acceptor Quantum Coherence and Non-Markovian Bath on the Distance Dependence of Resonance Energy Transfer](https://arxiv.org/abs/2601.00708)
*Seogjoo J. Jang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Accurate information on the distance dependence of resonance energy transfer (RET) is crucial for its utilization as a spectroscopic ruler \re{of} nanometer scale distances. In this regard, understanding the effects of donor-acceptor quantum coherence and non-Markovian bath, which become significant at short distances, has significant implications. The present work investigates this issue theoretically by comparing results from a theory of coherent RET (CRET) with a nonequilibrium version of Förster's RET (FRET) theory, both accounting for non-Markovian bath effects. Even for a model where the donor-acceptor electronic coupling is of transition dipole interaction form, it is shown that the RET rate in general deviates from the inverse sixth power distance dependence as opposed to the prediction of the original FRET. It is shown that the donor-acceptor quantum coherence makes the \re{distance} dependence steeper than the sixth power although detailed manner of enhancement is sensitive to specific values of parameters. On the other hand, the non-Markovian bath effects make the \re{distance} dependence more moderate than the sixth power for both CRET and nonueqilibrium FRET because finite time scale of the bath causes the rate to be smaller than the prediction of original FRET. While these effects are \re{demonstrated clearly} in the population dynamics at sub-picosecond time scales, their contributions to the conventional RET efficiency are relatively minor. This indicates that the actual detection of such effects through conventional RET efficiency measurement requires either high precision or utilization of a donor with fast spontaneous decay rate of excitation.

</details>


### [59] [Quantum Approaches to the Minimum Edge Multiway Cut Problem](https://arxiv.org/abs/2601.00720)
*Ali Abbassi,Yann Dujardin,Eric Gourdin,Philippe Lacomme,Caroline Prodhon*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the minimum edge multiway cut problem, a fundamental task in evaluating the resilience of telecommunication networks. This study benchmarks the problem across three quantum computing paradigms: quantum annealing on a D-Wave quantum processing unit, photonic variational quantum circuits simulated on Quandela s Perceval platform, and IBM s gate-based Quantum Approximate Optimization Algorithm (QAOA). We assess the comparative feasibility of these approaches for early-stage quantum optimization, highlighting trade-offs in circuit constraints, encoding overhead, and scalability. Our findings suggest that quantum annealing currently offers the most scalable performance for this class of problems, while photonic and gate-based approaches remain limited by hardware and simulation depth. These results provide actionable insights for designing quantum workflows targeting combinatorial optimization in telecom security and resilience analysis.

</details>


### [60] [Geometric Complexity of Quantum Channels via Unitary Dilations](https://arxiv.org/abs/2601.00735)
*Alberto Acevedo,Antonio Falcó*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Nielsen's geometric approach to quantum circuit complexity provides a Riemannian framework for quantifying the cost of implementing unitary (closed--system) dynamics. For open dynamics, however, the reduced evolution is described by quantum channels and admits many inequivalent Stinespring realizations, so any meaningful complexity notion must specify which microscopic resources are counted as accessible and which transformations are regarded as gauge. We introduce and analyze a geometric complexity functional for families of quantum channels based on unitary dilations. We distinguish an implementation-dependent complexity, defined relative to explicit dilation data, from an intrinsic channel complexity obtained by minimizing over a physically motivated class of admissible dilations (e.g. bounded environment dimension, energy or norm constraints, and penalty structures). The functional has a subtractive form: it compares the geometric cost of the total unitary realization with a canonical surrogate term that removes purely environmental contributions. We justify this subtraction from concise postulates, including closed-system consistency, environment-only neutrality, and invariance under dilation gauge transformations that leave the channel unchanged. This leads to a companion quantity, noise complexity, quantifying the loss of geometric complexity relative to a prescribed ideal closed evolution. We establish a coherence-based lower bound for unitary geometric complexity, derive structural properties such as linear time scaling under time-homogeneous dilations, and obtain dissipator--controlled bounds in the Markovian (GKSL/Lindblad) regime under a standard dilation construction. Finally, we illustrate the framework on canonical benchmark noise models, including dephasing, amplitude damping, and depolarizing (Pauli) channels.

</details>


### [61] [Training-Free Certified Bounds for Quantum Regression: A Scalable Framework](https://arxiv.org/abs/2601.00745)
*Demerson N. Gonçalves,Tharso D. Fernandes,Pedro H. G. Lugao,João T. Dias*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a training-free, certified error bound for quantum regression derived directly from Pauli expectation values. Generalizing the heuristic of minimum accuracy from classification to regression, we evaluate axis-aligned predictors within the Pauli feature space. We formally prove that the optimal axis-aligned predictor constitutes a rigorous upper bound on the minimum training Mean Squared Error (MSE) attainable by any linear or kernel-based regressor defined on the same quantum feature map. Since computing this exact bound requires an intractable scan of the full Pauli basis, we introduce a Monte Carlo framework to efficiently estimate it using a tractable subset of measurement axes. We further provide non-asymptotic statistical guarantees to certify performance within a practical measurement budget. This method enables rapid comparison of quantum feature maps and early diagnosis of expressivity, allowing for the informed selection of architectures before deploying higher-complexity models.

</details>


### [62] [On orthoposets of numerical events in quantum logic](https://arxiv.org/abs/2601.00772)
*Dietmar Dorninger,Helmut Länger*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Let S be a set of states of a physical system and p(s) the probability of the occurrence of an event when the system is in state s in S. Such a function p from S to [0,1] is known as a numerical event or more accurately an S-probability. A set P of numerical events including the constant functions 0 and 1 and 1-p with every p in P becomes a poset when ordered by the order of real functions and can serve as a general setting for quantum logics. We call such a poset P a general set of events (GSE). The thoroughly investigated algebras of S-probabilities (including Hilbert logics), concrete logics and Boolean algebras can all be represented within this setting. In this paper we study various classes of GSEs, in particular those that are orthoposets and their interrelations and connections to known logics. Moreover, we characterize GSEs as posets by means of states and discuss the situation for GSEs to be lattices.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [63] [A Topological Framework for Atmospheric River Interaction Using Framed Braids](https://arxiv.org/abs/2601.00354)
*Ioannis Diamantis*

Main category: nlin.CD

TL;DR: 提出基于编织态（braid）和带框编织态（framed braidoids）的拓扑框架，用于分析大气河（AR）纤维束的几何交互与水汽输送演化，揭示传统方法难以捕捉的结构重组与水汽增强现象。


<details>
  <summary>Details</summary>
Motivation: 现有大气河诊断方法多孤立分析单个纤维，忽略了同一天气系统中多个纤维频繁共存与相互作用的现象，缺乏对多纤维交互结构的系统描述。

Method: 将大气河纤维表示为时间序列下的编织 strands，通过其交叉形成braid words；引入基于水汽通量的‘ framing ’来刻画每条纤维内部强度变化，构建滑动时间窗内的braid与framed braid表示，并应用于再分析数据中的大气河轨迹。

Result: 在北太平洋强相互作用的多纤维大气河事件中，该方法成功识别出由纤维交叉引起的结构重组以及水汽增强过程，这些特征无法仅从中心轨迹几何或IVT强度单独看出。

Conclusion: 基于编织态的拓扑框架为理解大气水分输送中的多纤维相互作用提供了新的结构视角，可作为传统诊断方法的有效补充。

Abstract: Atmospheric Rivers (ARs) are filamentary moisture pathways responsible for a large fraction of extreme precipitation and often occur as interacting filament bundles within the same synoptic regime. Existing diagnostics typically analyze ARs in isolation, despite the frequent coexistence and interaction of multiple filaments. We introduce a topological framework for AR analysis based on framed braids and framed braidoids, which encodes both the geometric interaction of AR centroids and the internal evolution of moisture transport.
  In this approach, AR filaments are represented as strands whose time-ordered crossings form braid words, while moisture-based framing captures internal intensification or weakening along each filament. Applying this framework to reanalysis-derived Atmospheric River track data, we construct braid and framed braid representations over sliding time windows and analyze a strongly interacting multi-filament AR episode in the North Pacific. The results show that braid-based indicators capture structural reorganizations and moisture intensification episodes that are not apparent from centroid geometry or IVT magnitude alone, offering a complementary structural perspective on atmospheric moisture transport.

</details>


<div id='physics.hist-ph'></div>

# physics.hist-ph [[Back]](#toc)

### [64] [From Grounding to Stabilisation: Adequacy as a Criterion for Scientific Explanation](https://arxiv.org/abs/2601.00168)
*Jonathon Sendall*

Main category: physics.hist-ph

TL;DR: 本文提出了一种基于过程的科学解释框架，将“奠基”重新理解为“稳定化”，通过保持关系不变性来判断解释的充分性，解决了传统基础主义的无限倒退问题，并在量子、热力学和相对论领域具有统一的解释力。


<details>
  <summary>Details</summary>
Motivation: 传统奠基理论无法有效处理模型更新、扰动和理论变迁下的解释 adequacy 问题，缺乏动态适应性标准。

Method: 引入稳定化概念，形式化为模式 C → P(I)，即在可接受变换下保持特定关系不变性，以此作为解释充分性的判据，并发展出依赖于装置的适切性协议。

Result: 成功应用于理论变迁、量子测量、数学有效性及涌现与还原等议题，揭示过程本身具有本体论上的解释优先性，如黑洞事件视界所示；并使该框架成为可在多个物理领域检验的研究纲领。

Conclusion: 以稳定化替代终极奠基，既能避免无限回归，又能维持温和的科学实在论，为跨层级和跨理论的科学解释提供统一且可操作的基础。

Abstract: This paper develops a process-based account of scientific explanation that reconceives grounding in terms of stabilisation. Grounding theories capture hierarchical dependence but lack criteria for when explanations remain adequate under model updates, perturbations, and theory change. Stabilisation is formally defined by a schema \(C \to P(I)\), where explanatory relations are sufficient when they preserve specified relational invariants under admissible transformations. This replaces the search for ultimate foundations with operational adequacy tests indexed to measurable invariance, resolving infinite regress worries while preserving a modest scientific realism. Applications show unifying power: theory change becomes an empirical question about structural continuity; quantum measurement becomes apparatus-dependent pattern selection; the effectiveness of mathematics reflects convergence on transformation-invariant descriptions; and emergence versus reduction reduces to stability of cross-level mappings. The black hole event horizon illustrates how ontologically identical states can diverge in admissible evolution, revealing process as explanatorily fundamental. Companion work develops apparatus-dependent adequacy protocols, including pointer-basis rotation and coupling-spectra methods, turning the framework into a falsifiable research programme across quantum, thermodynamic, and relativistic domains.

</details>


### [65] [The Physics of Causation](https://arxiv.org/abs/2601.00515)
*Leroy Cronin,Sara I. Walker*

Main category: physics.hist-ph

TL;DR: 本文提出了基于组装理论（AT）的物质因果性新概念，通过组装指数和复制数量来量化进化与选择中的因果关系，并定义了生命及其衍生形式的选择阈值。


<details>
  <summary>Details</summary>
Motivation: 为了解释和测量生命现象，引入一种与基本物理相容的、新的物质因果性概念，弥补传统干预式因果理论的不足。

Method: 利用组装指数（最小构建步骤数）和对象的复制数量作为指标，在组装空间中建立因果性和偶然性的标准化度量方法，并提出选择阈值以区分生命与非生命结构。

Result: 高组装指数且具有多个复制的对象表明存在持续的生成机制，环境因此形成记忆并锁定因果链；该框架可明确划分生命的边界，并为包含新颖性、偶然性和开放性的物理理论提供基础。

Conclusion: 组装理论为理解生命、智能和技术形态提供了新的物理基础，其中决定论是在演化过程中涌现的，而非先验存在。

Abstract: Assembly theory (AT) introduces a concept of causation as a material property, constitutive of a metrology of evolution and selection. The physical scale for causation is quantified with the assembly index, defined as the minimum number of steps necessary for a distinguishable object to exist, where steps are assembled recursively. Observing countable copies of high assembly index objects indicates that a mechanism to produce them is persistent, such that the object's environment builds a memory that traps causation within a contingent chain. Copy number and assembly index underlie the standardized metrology for detecting causation (assembly index), and evidence of contingency (copy number). Together, these allow the precise definition of a selective threshold in assembly space, understood as the set of all causal possibilities. This threshold demarcates life (and its derivative agential, intelligent and technological forms) as structures with persistent copies beyond the threshold. In introducing a fundamental concept of material causation to explain and measure life, AT represents a departure from prior theories of causation, such as interventional ones, which have so far proven incompatible with fundamental physics. We discuss how AT's concept of causation provides the foundation for a theory of physics where novelty, contingency and the potential for open-endedness are fundamental, and determinism is emergent along assembled lineages.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [66] [Materials Informatics: Emergence To Autonomous Discovery In The Age Of AI](https://arxiv.org/abs/2601.00742)
*Turab Lookman,YuJie Liu,Zhibin Gao*

Main category: physics.comp-ph

TL;DR: 本文探讨了材料信息学从物理和信息理论基础到人工智能推动的演变过程，强调其作为一个不断发展的生态系统，涵盖贝叶斯优化、强化学习和Transformer等关键技术，并展望AI在材料科学中作为协作研究伙伴的未来角色。


<details>
  <summary>Details</summary>
Motivation: 旨在梳理材料信息学的发展脉络，理解其从传统方法向AI驱动的自主发现转变的内在驱动力。

Method: 通过回顾领域发展历程，分析关键技术和方法（如贝叶斯优化、强化学习、Transformer、主动学习和RAG）在逆向设计和自驱动实验室中的应用。

Result: 揭示了材料信息学正从工具集转变为生态系统，大型语言模型的集成面临不确定性量化等挑战，AI正逐步成为科研合作伙伴。

Conclusion: 材料信息学正在迈向‘人类退出回路’的自主发现新时代，AI将作为协作研究伙伴推动材料科学的自动化发展。

Abstract: This perspective explores the evolution of materials informatics, from its foundational roots in physics and information theory to its maturation through artificial intelligence (AI). We trace the field's trajectory from early milestones to the transformative impact of the Materials Genome Initiative and the recent advent of large language models (LLMs). Rather than a mere toolkit, we present materials informatics as an evolving ecosystem, reviewing key methodologies such as Bayesian Optimization, Reinforcement Learning, and Transformers that drive inverse design and autonomous self-driving laboratories. We specifically address the practical challenges of LLM integration, comparing specialist versus generalist models and discussing solutions for uncertainty quantification. Looking forward, we assess the transition of AI from a predictive tool to a collaborative research partner. By leveraging active learning and retrieval-augmented generation (RAG), the field is moving toward a new era of autonomous materials science, increasingly characterized by "human-out-of-the-loop" discovery processes.

</details>


### [67] [Kinetic Turing Instability and Emergent Spectral Scaling in Chiral Active Turbulence](https://arxiv.org/abs/2508.21012)
*Magnus F Ivarsen*

Main category: physics.comp-ph

TL;DR: 该研究通过模拟具有Kuramoto相互作用的极性手性活性个体，揭示了系统从混沌到活性湍流的转变由动力学图灵不稳定性主导，并表现出量子化的环相电流和相干聚类。推导出的连续动力学理论表明，局部相位锁定与个体运动性的竞争决定了临界结构波数，进而导致具有稳定幂律谱密度的活性湍流态，提示其普适性。结果连接了离散的 chimera 态与连续流体湍流，表明活性湍流的统计标度律可源于基本的动力学不稳定机制。


<details>
  <summary>Details</summary>
Motivation: 理解生物活性群体中从无序混沌自发形成有序结构的自组织机制，尤其是如何从微观相互作用导出宏观湍流现象及其普适性规律。

Method: 采用数值模拟极性手性活性个体集合，引入局域Kuramoto相互作用；推导系统的连续动力学理论，分析相位动力学与运动性之间的竞争，并识别导致不稳定的机理。

Result: 发现系统从混沌到活性湍流的转变由动力学图灵不稳定性控制，出现量子化环相电流和相干聚类；谱密度呈现稳健的幂律行为；确定了由相位锁定与运动性竞争选择的临界波数。

Conclusion: 活性湍流的统计标度律可源自基本的动能不稳定性，而非仅依赖于流体连续性假设；研究架起了离散chimera态与连续湍流之间的桥梁，为活性物质中的自组织提供了统一解释框架。

Abstract: The spontaneous emergence of coherent structures from chaotic backgrounds is a hallmark of active biological swarms. We investigate this self-organization by simulating an ensemble of polar chiral active agents that couple locally via a Kuramoto interaction. We demonstrate that the system's transition from chaos to active turbulence is characterized by quantized loop phase currents and coherent clustering, and that this transition is strictly governed by a kinetic Turing instability. By deriving the continuum kinetic theory for the model, we identify that the competition between local phase-locking and active agent motility selects a critical structural wavenumber. The instability then drives the system into a state of developed, active turbulence that exhibits stable, robust power-laws in spectral density, suggestive of universality and consistent with observations from a broad range of turbulent phenomena. Our results bridge the gap between discrete chimera states and continuous fluid turbulence, suggesting that the statistical scaling laws of active turbulence can arise from fundamental kinetic instability criteria.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [68] [Coupled thermo-chemo-mechanical phase field-based modelling of hydrogen-assisted cracking in girth welds](https://arxiv.org/abs/2601.00471)
*L. Castro,Y. Navidtehrani. C. Betegón,E. Martínez-Pañeda*

Main category: cs.CE

TL;DR: 提出了一种新的计算框架，用于预测氢气输送管道焊缝的结构完整性，结合了热-力焊接过程模型和考虑塑性及氢陷阱的相场断裂模型，应用于X80管线钢环焊缝分析，揭示了残余应力、氢传输与断裂之间的相互作用，并评估了多种焊接缺陷对结构完整性的影响。


<details>
  <summary>Details</summary>
Motivation: 由于现有天然气管道可能被用于氢气输送，而焊接缺陷在当前标准下被视为安全，但在氢环境下可能带来严重风险，因此需要评估这些缺陷对焊缝结构完整性的影响。

Method: 结合热-力学焊接过程模型与考虑多类型陷阱、固定和演化陷阱密度的变形-扩散-断裂相场模型，区分母材、热影响区和焊缝金属三个区域，进行虚拟断裂实验并评估不同工况下的临界失效压力。

Result: 模型成功捕捉了残余应力、陷阱生成、氢传输与断裂之间的耦合效应；虚拟实验与实验室结果吻合良好；发现焊缝微观结构和常见焊接缺陷在含氢环境中显著降低结构安全性。

Conclusion: 现有天然气管道中的焊接缺陷在转为氢气输送时可能构成重大安全隐患，必须重新评估其结构完整性，该计算框架为氢能源基础设施的安全评估提供了有效工具。

Abstract: A new computational framework is presented to predict the structural integrity of welds in hydrogen transmission pipelines. The framework combines: (i) a thermo-mechanical weld process model, and (ii) a coupled deformation-diffusion-fracture phase field-based model that accounts for plasticity and hydrogen trapping, considering multiple trap types, with stationary and evolving trap densities. This enables capturing, for the first time, the interplay between residual stresses, trap creation, hydrogen transport, and fracture. The computational framework is particularised and applied to the study of weld integrity in X80 pipeline steel. The focus is on girth welds, as they are more complex due to their multi-pass nature. The weld process model enables identifying the dimensions and characteristics of the three weld regions: base metal, heat-affected zone, and weld metal, and these are treated distinctively. This is followed by virtual fracture experiments, which reveal a very good agreement with laboratory studies. Then, weld pipeline integrity is assessed, estimating critical failure pressures for a wide range of scenarios. Of particular interest is to assess the structural integrity implications of welding defects present in existing natural gas pipelines under consideration for hydrogen transport: pores, lack of penetration, imperfections, lack of fusion, root contraction, and undercutting. The results obtained in hydrogen-containing environments reveal an important role of the weld microstructure and the detrimental effect of weld defects that are likely to be present in existing natural gas pipelines, as they are considered safe in gas pipeline standards.

</details>


### [69] [Effect of Electric Charge on Biotherapeutic Transport, Binding and Absorption: A Computational Study](https://arxiv.org/abs/2601.00505)
*Mario de Lucio,Pavlos P. Vlachos,Hector Gomez*

Main category: cs.CE

TL;DR: 本研究开发了一种基于Nernst-Planck方程和多孔介质流动理论的新型数学计算模型，用于研究单克隆抗体（mAbs）在皮下组织中与带电物质的复杂相互作用及其传输动力学。


<details>
  <summary>Details</summary>
Motivation: 探讨电荷对单克隆抗体在皮下注射中药物输送和吸收动力学的影响。

Method: 采用Nernst-Planck方程和多孔介质流动理论建立数学模型，模拟不同电学性质的mAbs在皮下组织中的短时传输和长时结合与吸收过程，并分析缓冲液pH、体重指数、注射深度和制剂浓度等因素的影响。

Result: 模型成功再现了mAbs在皮下组织中的传输行为，并与文献中的实验数据具有良好一致性，揭示了电荷效应在药物分布中的重要作用。

Conclusion: 电荷特性显著影响mAbs的皮下药物传输与吸收，所提出的模型为优化生物药剂的给药策略提供了理论支持。

Abstract: This study explores the effects of electric charge on the dynamics of drug transport and absorption in subcutaneous injections of monoclonal antibodies (mAbs). We develop a novel mathematical and computational model, based on the Nernst-Planck equations and porous media flow theory, to investigate the complex interactions between mAbs and charged species in subcutaneous tissue. The model enables us to study short-term transport dynamics and long-term binding and absorption for two mAbs with different electric properties. We examine the influence of buffer pH, body mass index, injection depth, and formulation concentration on drug distribution and compare our numerical results with experimental data from the literature.

</details>


### [70] [Toward Efficient FSI Modeling in Patient-Specific Arteries: SPH Simulation of Blood Flow in Thin Deformable Vessels](https://arxiv.org/abs/2601.00546)
*Chenxi Zhao,Dong Wu,Weiyi Kong,Oskar J. Haidn,Xiangyu Hu*

Main category: cs.CE

TL;DR: 提出了一种基于简化维度壳模型的SPH方法，用于高效模拟薄壁可变形动脉中的流固耦合问题，在保证流体动力学精度的同时显著降低计算成本，并验证了其在患者特异性血管几何中的适用性。


<details>
  <summary>Details</summary>
Motivation: 传统基于全维体积建模的SPH方法在模拟薄壁动脉时需要极细的粒子间距以确保固体力学收敛，导致流体域分辨率冗余，计算成本高。

Method: 提出一种高效的简化维度壳基SPH方法来模拟薄壁可变形动脉，并进行流固耦合（FSI）模拟以捕捉血流动力学和血管壁力学行为。

Result: 所提出的壳模型在流体动力学方面表现出与体积模型相当的精度，同时在固体力学中实现更快的收敛和更低的计算成本；在颈动脉和主动脉等患者特异性几何中展示了良好的鲁棒性、效率和生理相关性。

Conclusion: 该方法有效解决了传统SPH在薄壁结构模拟中的计算冗余问题，强调了FSI建模相对于刚性壁假设的必要性，适用于真实心血管系统的高效精准模拟。

Abstract: Accurate simulation of blood flow in deformable vessels is critical in cardiovascular research for understanding disease progression and informing clinical decision-making. However, due to the thin-walled nature of arteries, traditional smoothed particle hydrodynamics (SPH) approaches based on full-dimensional volume modeling often require extremely fine particle spacing to ensure numerical convergence for the solid mechanics. This, in turn, leads to redundant resolution in the fluid domain to maintain sufficient kernel support near the fluid-solid interface in fluid-structure interaction (FSI) simulations. To address this limitation, we propose an efficient reduced-dimensional shell-based SPH method for modeling thin-walled deformable arteries, and conduct FSI for capturing hemodynamics and arterial wall mechanics. Through a series of validation cases, the proposed shell model demonstrates comparable accuracy in fluid dynamics to the volume model, while achieving faster convergence in solid mechanics and reduced computational cost. We further investigate the influence of wall compliance on flow transitions and key hemodynamic indices, highlighting the necessity of FSI modeling over rigid-wall assumptions. Finally, the method is applied to two patient-specific vascular geometries, i.e. the carotid artery and the aorta, which demonstrates its robustness, efficiency and physiological relevance in realistic cardiovascular simulations.

</details>


<div id='q-fin.RM'></div>

# q-fin.RM [[Back]](#toc)

### [71] [Option Pricing beyond Black-Scholes Model:Quantum Mechanics Approach](https://arxiv.org/abs/2601.00293)
*Pengpeng Li,Shi-Dong Liang*

Main category: q-fin.RM

TL;DR: 提出基于市场力驱动的期权定价模型，推广了Black-Scholes模型，能够考虑意外市场行为并提供风险溢价分析。


<details>
  <summary>Details</summary>
Motivation: 为改进传统Black-Scholes模型无法反映意外市场行为的局限性，引入类比于量子谐振子的随机动力学方法，构建更灵活的期权定价框架。

Method: 利用随机动力学与量子谐振子之间的类比，建立市场力驱动模型，并通过引入不同形式的市场力来修正期权定价公式。

Result: 得到了可纳入多种非预期市场行为影响的期权定价新方案，并揭示了在突发市场力出现时可能存在风险溢价。

Conclusion: 该模型不仅为预测隐藏市场力量时提供了新的定价工具，也解释了市场突变下的风险补偿机制，具有实际应用价值。

Abstract: Based on the analog between the stochastic dynamics and quantum harmonic oscillator, we propose a market force driving model to generalize the Black-Scholes model in finance market. We give new schemes of option pricing, in which we can take various unexpected market behaviors into account to modify the option pricing. As examples, we present several market forces to analyze their effects on the option pricing. These results provide us two practical applications. One is to be used as a new scheme of option pricing when we can predict some hidden market forces or behaviors emerging. The other implies the existence of some risk premium when some unexpected forces emerge.

</details>


### [72] [Multimodal Insights into Credit Risk Modelling: Integrating Climate and Text Data for Default Prediction](https://arxiv.org/abs/2601.00478)
*Zongxiao Wu,Ran Liu,Jiang Dai,Dan Luo*

Main category: q-fin.RM

TL;DR: 本研究提出了一种多模态框架，整合结构化信用变量、气候面板数据和非结构化文本叙述，用于小微企业信用风险评估。通过LSTM、GRU和Transformer模型分析多源数据的交互作用，发现融合多模态数据可显著提升违约预测性能，其中气候与文本模态优于仅使用结构化数据的模型。SHAP解释性分析表明，降雨导致的内涝是影响违约预测的最关键物理气候风险因素。研究验证了多模态AI方法在信用风险决策中的潜力，并推动环境与文本信息在预测分析中的融合。


<details>
  <summary>Details</summary>
Motivation: 小微企业常因财务历史有限而难以通过传统结构化数据进行有效信用评估，亟需融合新型数据源以提升预测准确性。同时，气候变化带来的物理风险日益影响企业偿债能力，但现有模型对此关注不足。因此，有必要构建能够整合结构化、环境与非结构化文本等多模态信息的信用风险评估框架。

Method: 提出一个多模态学习架构，集成结构化信用变量、气候面板数据和非结构化文本叙述。采用LSTM、GRU和Transformer模型分别处理不同模态数据并捕捉其动态交互。通过SHAP值进行特征重要性分析，量化各变量（尤其是气候因子）对违约预测的影响程度。

Result: 实证结果显示，基于气候或文本数据的单模态模型已优于仅使用结构化数据的模型；而多模态融合模型在信用违约预测上表现最佳，显著提升预测性能。SHAP分析揭示物理气候风险，特别是由降雨引发的积水问题，是影响违约预测的最重要外部因素之一。

Conclusion: 多模态AI方法能有效提升小微企业信用风险评估的准确性和鲁棒性，尤其在融合气候与文本信息后表现出更强的预测能力。该框架不仅为金融机构提供更全面的风险管理工具，也推动了环境风险与非结构化数据在金融决策中的系统性应用。

Abstract: Credit risk assessment increasingly relies on diverse sources of information beyond traditional structured financial data, particularly for micro and small enterprises (mSEs) with limited financial histories. This study proposes a multimodal framework that integrates structured credit variables, climate panel data, and unstructured textual narratives within a unified learning architecture. Specifically, we use long short-term memory (LSTM), the gated recurrent unit (GRU), and transformer models to analyse the interplay between these data modalities. The empirical results demonstrate that unimodal models based on climate or text data outperform those relying solely on structured data, while the integration of multiple data modalities yields significant improvements in credit default prediction. Using SHAP-based explainability methods, we find that physical climate risks play an important role in default prediction, with water-logging by rain emerging as the most influential factor. Overall, this study demonstrates the potential of multimodal approaches in AI-enabled decision-making, which provides robust tools for credit risk assessment while contributing to the broader integration of environmental and textual insights into predictive analytics.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [73] [Anderson localisation in spatially structured random graphs](https://arxiv.org/abs/2601.00220)
*Bibek Saha,Sthitadhi Roy*

Main category: cond-mat.dis-nn

TL;DR: 研究了在具有长程距离依赖跳跃的高维图上的安德森局域化，通过引入一类模型揭示了跳跃范围与无序强度之间的竞争导致的局域化相变，并发现存在从扩展态到局域态的直接转变，且无多重分形相介入。


<details>
  <summary>Details</summary>
Motivation: 探索高维图中长程跳跃对安德森局域化的影响，填补短程与全连接模型之间的理论空白。

Method: 结合数值精确对角化和解析重正化微扰理论，分析不同跳跃范围和无序强度下的局域化相图。

Result: 增加跳跃范围会使局域化转变移向更强的无序；超过临界范围后，即使在极强无序下局域相也消失；未发现多重分形相，表现为类似Kosterlitz-Thouless的双参数标度转变。

Conclusion: 安德森局域化在长程跳跃模型中表现出新的相变行为，支持高维图上安德森转变的普适性观点。

Abstract: We study Anderson localisation on high-dimensional graphs with spatial structure induced by long-ranged but distance-dependent hopping. To this end, we introduce a class of models that interpolate between the short-range Anderson model on a random regular graph and fully connected models with statistically uniform hopping, by embedding a random regular graph into a complete graph and allowing hopping amplitudes to decay exponentially with graph distance. The competition between the exponentially growing number of neighbours with graph distance and the exponentially decaying hopping amplitude positions our models effectively as power-law hopping generalisation of the Anderson model on random regular graphs. Using a combination of numerical exact diagonalisation and analytical renormalised perturbation theory, we establish the resulting localisation phase diagram emerging from the interplay of the lengthscale associated to the hopping range and the onsite disorder strength. We find that increasing the hopping range shifts the localisation transition to stronger disorder, and that beyond a critical range the localised phase ceases to exist even at arbitrarily strong disorder. Our results indicate a direct Anderson transition between delocalised and localised phases, with no evidence for an intervening multifractal phase, for both deterministic and random hopping models. A scaling analysis based on inverse participation ratios reveals behaviour consistent with a Kosterlitz-Thouless-like transition with two-parameter scaling, in line with Anderson transitions on high-dimensional graphs. We also observe distinct critical behaviour in average and typical correlation functions, reflecting the different scaling properties of generalised inverse participation ratios.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [74] [Full grid solution for multi-asset options pricing with tensor networks](https://arxiv.org/abs/2601.00009)
*Lucas Arenstein,Michael Kastoryano*

Main category: q-fin.CP

TL;DR: 本文提出使用量化张量列车（QTT）方法解决高维Black-Scholes偏微分方程，有效缓解了维度灾难，使得在个人计算机上求解多资产期权定价问题成为可能。


<details>
  <summary>Details</summary>
Motivation: 传统的全网格求解器在处理多资产期权定价时受限于维度灾难，而蒙特卡洛方法虽然常用但存在局限性，因此需要一种更高效的数值方法来解决高维Black-Scholes PDE。

Method: 构建了算子、 payoff 和边界条件的量化张量列车（QTT）表示，并开发了两种求解器：一种用于欧式和美式期权的时间步进算法，另一种用于欧式期权的时空算法。

Result: 实现了三到五维相关联的一篮子期权和最大-最小期权的全网格价格和希腊值的高精度计算，且QTT的秩在资产数量d上多项式增长，在网格大小上拟对数增长。

Conclusion: QTT方法将d资产Black-Scholes PDE转化为可在个人电脑上处理的高维问题，显著提升了多资产期权定价的可行性和效率，未来可通过算法优化和更多计算资源扩展至10-15个标的资产。

Abstract: Pricing multi-asset options via the Black-Scholes PDE is limited by the curse of dimensionality: classical full-grid solvers scale exponentially in the number of underlyings and are effectively restricted to three assets. Practitioners typically rely on Monte Carlo methods for computing complex instrument involving multiple correlated underlyings. We show that quantized tensor trains (QTT) turn the d-asset Black-Scholes PDE into a tractable high-dimensional problem on a personal computer. We construct QTT representations of the operator, payoffs, and boundary conditions with ranks that scale polynomially in d and polylogarithmically in the grid size, and build two solvers: a time-stepping algorithm for European and American options and a space-time algorithm for European options. We compute full-grid prices and Greeks for correlated basket and max-min options in three to five dimensions with high accuracy. The methods introduced can comfortably be pushed to full-grid solutions on 10-15 underlyings, with further algorithmic optimization and more compute power.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [75] [Stratosphere Model Verification with Manufactured Geometry](https://arxiv.org/abs/2601.00206)
*Johannes Lawen,George Salman,Akshita Bhardwaj*

Main category: physics.ao-ph

TL;DR: 提出了一种在地理位势/气压坐标系下的平流层动力核心的精确解法，通过将对流层顶视为移动边界来自然响应对流层变化，并结合ALE方法保持物理量守恒。


<details>
  <summary>Details</summary>
Motivation: 避免使用再分析数据‘ nudging’约束平流层环流，改进传统固定对流层顶假设带来的不一致性。

Method: 将对流层顶作为随时间演变的几何边界，采用任意拉格朗日-欧拉（ALE）更新与保守重映射方法，在保持混合σ-p结构的同时实现平流层域的动态调整。

Result: 该方法能自然适应对流层变异性，维持正层厚和示踪物单调性，并具备良好的数学性质（如适定性、能量守恒和波动传播特性）。

Conclusion: 所提方案为平流层-对流层耦合模拟提供了一个更物理一致且数值稳健的动力框架，适用于高精度大气模式开发。

Abstract: We propose an exact solution for a stratosphere dynamical core formulated in geopotential/pressure coordinates with a time-evolving lower boundary supplied by the troposphere. Rather than constraining the stratospheric circulation via specified dynamics (``nudging'') to a reanalysis, we treat the tropopause as a moving geometric boundary. The stratospheric domain thus expands, contracts, and undulates in response to tropospheric variability while preserving familiar hybrid $σ$--$p$ structure and pressure-gradient calculations. The approach integrates naturally with arbitrary Lagrangian--Eulerian (ALE) updates and conservative remap to maintain positive layer thickness and tracer monotonicity. We outline the formulation, highlight analytical properties (well-posedness, energetics, wave propagation), and sketch a verification/validation path based on modified standard test cases and reanalysis-driven experiments.

</details>


### [76] [Bayesian optimization for re-analysis and calibration of extreme sea state events simulated with a spectral third-generation wave model](https://arxiv.org/abs/2601.00628)
*Cédric Goeury,Thierry Fouquet,Maria Teles,Michel Benoit*

Main category: physics.ao-ph

TL;DR: 本研究提出了一种基于贝叶斯优化（BO）的新型校准框架，利用树结构Parzen估计器（TPE）对ANEMOC-3海浪模型中的关键耗散参数进行高效优化，显著提升了极端海况事件的后报精度。


<details>
  <summary>Details</summary>
Motivation: 数值波浪模型在物理参数化和输入数据方面存在不确定性，限制了其对极端海态事件的可靠模拟，影响沿海工程、风险评估和气候研究。因此需要一种高效的模型校准方法来减少模型输出与观测之间的差异。

Method: 采用基于贝叶斯优化（BO）的框架，结合树结构Parzen估计器（TPE），对ANEMOC-3后报波浪模型中的底部摩擦耗散、水深致破碎及强逆流引起的波浪耗散等不确定汇项参数进行联合优化，并同时优化连续参数与离散模型结构。

Result: 在校准期（包含法国大西洋沿岸多个强风暴事件的一个月时段）内，校准后的模型相较于默认配置显著改善了与浮标观测数据的一致性，表现出更低的偏差、均方根误差（RMSE）和离散指数。

Conclusion: 贝叶斯优化能有效自动化并提升波浪模型的校准过程，具备可扩展性和灵活性，适用于广泛的地球物理建模问题，未来可拓展至多目标优化、不确定性量化及融合更多观测数据。

Abstract: Accurate hindcasting of extreme sea state events is essential for coastal engineering, risk assessment, and climate studies. However, the reliability of numerical wave models remains limited by uncertainties in physical parameterizations and model inputs. This study presents a novel calibration framework based on Bayesian Optimization (BO), leveraging the Tree structured Parzen Estimator (TPE) to efficiently estimate uncertain sink term parameters, specifically bottom friction dissipation, depth induced breaking, and wave dissipation from strong opposing currents, in the ANEMOC-3 hindcast wave model. The proposed method enables joint optimization of continuous parameters and discrete model structures, significantly reducing discrepancies between model outputs and observations. Applied to a one month period encompassing multiple intense storm events along the French Atlantic coast, the calibrated model demonstrates improved agreement with buoy measurements, achieving lower bias, RMSE, and scatter index relative to the default sea$-$state solver configuration. The results highlight the potential of BO to automate and enhance wave model calibration, offering a scalable and flexible approach applicable to a wide range of geophysical modeling problems. Future extensions include multi-objective optimization, uncertainty quantification, and integration of additional observational datasets.

</details>


### [77] [Turbulence is ineffective in causing raindrop growth in polluted clouds](https://arxiv.org/abs/2601.00637)
*K. Shri Vignesh,Ambedkar Sanket Sukdeo,P. V. Sruthibhai,Aishwarya Singh,Srikrishna Sahu,Swetaprovo Chaudhari,Amit K. Patra,T. Narayana Rao,Rama Govindarajan,Sachin S. Gunthe,R. I. Sujith*

Main category: physics.ao-ph

TL;DR: 实验室研究表明，湍流仅在液滴具有足够宽的尺寸分布时才影响碰撞与合并，这对云微物理建模具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 解决气溶胶-云相互作用中湍流对液滴增长作用不明确的问题，减少气候评估中的不确定性。

Method: 通过受控的实验室实验研究湍流对不同尺寸分布液滴的碰撞与合并的影响。

Result: 发现湍流并不总是增强液滴的碰撞与合并，其影响取决于液滴尺寸分布的宽度。

Conclusion: 需要改进参数化方案以准确模拟云微物理过程，特别是在考虑湍流效应时。

Abstract: Aerosol-cloud interactions represent the largest uncertainty in climate-change assessment, and while cloud turbulence is considered crucial for droplet growth, its precise role remains unclear. Our laboratory-controlled studies show that turbulence does not always enhance collision and coalescence; instead, its influence emerges only when droplets have a sufficiently broad size distribution. The dissipative-scale droplet behaviour underscores the importance of improved parameterisations to accurately model cloud microphysics.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [78] [Designing Information Delays in Supply Chains](https://arxiv.org/abs/2601.00265)
*Prem Talwai,Rene Caldentey,Avi Giloni,Clifford Hurvich,David Simchi-Levi,Yichen Zhang*

Main category: math.OC

TL;DR: 本文研究了在缺乏显式信息共享机制的情况下，分散式两级供应链中的下游零售商如何通过订单流结构向上游供应商隐式传递需求信息。


<details>
  <summary>Details</summary>
Motivation: 现有研究未充分探讨信息延迟对供应链隐式信息共享的影响，本文旨在填补这一空白。

Method: 引入信息延迟概念，并将最优隐式信息共享与零售商订单传递函数的群延迟联系起来；利用Hardy空间分解构建可逆ARMA策略族以逼近理论最优滤波器。

Result: 纯延迟严格次优，而分数延迟机制可通过重塑订单自相关性提升供应商预测能力并降低系统库存成本；提出了ARMA策略复杂度对供应链成本的影响规律，并分析了在供应商记忆受限情况下的策略复杂度适配问题。

Conclusion: 分数延迟机制优于纯延迟，政策复杂度需根据供应商预测窗口进行权衡，过高复杂度可能适得其反。

Abstract: This paper studies how a downstream retailer in a decentralized two-tier supply chain can implicitly transmit demand information to an upstream supplier through the structure of its order stream in the absence of an explicit information-sharing mechanism. We distinguish our work from prior work by introducing the notion of information delay and by linking optimal implicit information sharing to the group delay of the retailer's ordering transfer function. We show that pure delay is strictly suboptimal, while fractional-delay mechanisms can reshape the order autocorrelation to improve supplier forecastability and reduce system-wide inventory costs. Using Hardy-space factorization, we develop a tractable family of invertible ARMA policies that approximates the theoretically optimal (but non-rational) limiting filter derived by Caldentey et al. (2025) and preserves its informational delay properties. This construction yields sharp guidance on how policy complexity, as measured by the degrees of the ARMA policies, impacts supply chain costs. We further extend the analysis to memory-constrained suppliers and characterize how the complexity of the retailer's policy should scale with the supplier's finite forecasting window, highlighting when, perhaps counterintuitively, increasing policy complexity can become counterproductive.

</details>


### [79] [The true detection probability versus the subjective detection probability of a uniformly optimal search plan](https://arxiv.org/abs/2601.00350)
*Liang Hong*

Main category: math.OC

TL;DR: 本文研究了均匀最优搜索方案中真实检测概率与主观概率之间的差异，并通过实例表明该方案在真实检测概率下未必最优，同时探讨了基于复合先验的搜索方案性能及收敛性。


<details>
  <summary>Details</summary>
Motivation: 探讨均匀最优搜索方案在真实检测概率下的有效性及其与主观概率的差异。

Method: 通过构造示例、理论分析和比较不同先验下的复合搜索方案进行研究。

Result: 发现均匀最优搜索方案在真实检测概率下可能非最优；基于复合先验的方案可能劣于基于不同先验的复合方案；问题存在不可解性；且其真实检测概率随搜索时间趋于无穷而收敛到1。

Conclusion: 均匀最优搜索方案的表现依赖于实际检测环境，不能仅依赖主观概率评估其性能，需结合真实概率进行综合判断。

Abstract: This article investigates the difference between the true detection probability and the subjective probability of a uniformly optimal search plan. Its main contributions are multi-fold. First, it provides a set of examples to show that, in terms of the true detection probability, the uniformly optimal search plan may or may not be optimal. Secondly, it establishes that the true detection probability of the uniformly optimal search plan based on a composite prior can be less than that of the composite uniformly search plan based on different priors. Next, it argues that an open problem is unsolvable. Finally, it shows that the true detection probability of the uniformly optimal search plan converges to one as the search time approaches infinity.

</details>


### [80] [Completely Positive Reformulations of Polynomial Optimization Problems with Linear Inequality Constraints](https://arxiv.org/abs/2601.00375)
*Haibin Chen,Hong Yan,Guanglu Zhou*

Main category: math.OC

TL;DR: 本文提出了一类具有线性不等式约束的多项式优化问题的新完全正定张量锥重构方法，通过提升至对称秩一张量的凸优化框架，给出了可重构为完全正定规划的一般刻画，并构造了对偶问题，在 mild 条件下证明了强对偶性和严格可行性。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地求解具有线性不等式约束的多项式优化问题，探索基于完全正定张量锥的新型凸化方法。

Method: 将原问题提升至由对称秩一张量构成的高维空间，建立新的凸优化框架，并利用完全正定张量锥进行重构，进而推导其对偶问题。

Result: 得到了一类多项式优化问题可表示为完全正定张量锥规划的充分条件，成功构建了对应的对偶问题，并在 mild 假设下证明了对偶严格可行和强对偶成立。

Conclusion: 所提出的重构方法为求解带线性不等式约束的多项式优化问题提供了新的理论基础和工具，拓展了完全正定优化的应用范围。

Abstract: Polynomial optimization encompasses a broad class of problems in which both the objective function and constraints are polynomial functions of the decision variables. In recent years, a substantial body of research has focused on reformulating polynomial optimization problems (POPs) as conic programs over the cone of completely positive tensors (CPTs). In this article, we propose several new completely positive reformulations for a class of POPs with linear inequality constraints. Our approach begins by lifting these problems into a novel convex optimization framework, wherein the variables are represented as combinations of symmetric rank-one tensors. Based on this lifted formulation, we present a general characterization of POPs with linear inequality constraints that can be reformulated as conic programs over the CPT cone. Additionally, we construct the dual formulations of the resulting completely positive programs. Under mild assumptions, we prove that these dual problems are strictly feasible and strong duality holds.

</details>


### [81] [Safe Adaptive Feedback Control via Barrier States](https://arxiv.org/abs/2601.00476)
*Trivikram Satharasi,Tochukwu E. Ogri,Muzaffar Qureshi,Kyle Volle,Rushikesh Kamalapurkar*

Main category: math.OC

TL;DR: 提出了一种基于自适应动态规划（ADP）与屏障状态增强相结合的安全反馈控制框架，用于处理具有参数不确定性的非线性控制仿射系统，通过优化显式惩罚屏障状态的值函数来保证安全性，并结合并发学习估计器实现参数辨识与闭环稳定。


<details>
  <summary>Details</summary>
Motivation: 针对存在参数不确定性的非线性系统，传统方法难以同时保证控制性能与安全性，因此需要一种能将安全约束嵌入优化结构中的自适应控制策略。

Method: 采用带有屏障状态增强的自适应动态规划（ADP），构建包含安全惩罚项的值函数，并在Bellman方程中嵌入安全机制；结合模型基础强化学习与并发学习估计器进行参数在线辨识，利用屏障状态Lyapunov函数分析系统稳定性与安全性。

Result: 实现了对未知参数的无需持续激励条件的统一收敛估计，确保了闭环系统的稳定性与控制不变性，数值仿真验证了该方法在最优避障问题中的有效性。

Conclusion: 所提方法能够有效处理参数不确定性下的非线性系统安全控制问题，通过将安全性嵌入ADP结构并结合并发学习，实现了性能与安全的协同优化。

Abstract: This paper presents a safe feedback control framework for nonlinear control-affine systems with parametric uncertainty by leveraging adaptive dynamic programming (ADP) with barrier-state augmentation. The developed ADP-based controller enforces control invariance by optimizing a value function that explicitly penalizes the barrier state, thereby embedding safety directly into the Bellman structure. The near-optimal control policy computed using model-based reinforcement learning is combined with a concurrent learning estimator to identify the unknown parameters and guarantee uniform convergence without requiring persistency of excitation. Using a barrier-state Lyapunov function, we establish boundedness of the barrier dynamics and prove closed-loop stability and safety. Numerical simulations on an optimal obstacle-avoidance problem validate the effectiveness of the developed approach.

</details>


### [82] [Variational inference via Gaussian interacting particles in the Bures-Wasserstein geometry](https://arxiv.org/abs/2601.00632)
*Giacomo Borghi,José A. Carrillo*

Main category: math.OC

TL;DR: 提出了一种基于高斯粒子交互系统的零阶优化算法，用于在高斯概率测度空间中求解优化问题，结合共识优化机制与新型线性化Bures-Wasserstein参数化方法，在非对数凹目标下表现出优于梯度法的性能。


<details>
  <summary>Details</summary>
Motivation: 受变分推断方法启发，需要在高斯概率测度空间中进行高效优化，尤其是在传统梯度方法难以处理的非对数凹目标情况下。

Method: 基于线性化Bures-Wasserstein（LBW）空间构建高斯粒子系统，通过共识优化（CBO）机制实现粒子间的自组织，并采用零阶、随机探索的方式进行优化。

Result: 建立了系统动力学的良好适定性和收敛性理论，并通过变分推断任务上的数值实验验证了算法在鲁棒性和性能上优于基于梯度的方法。

Conclusion: 该算法为高斯测度空间中的优化提供了一个有效的无梯度框架，特别适用于复杂、非对数凹的目标函数。

Abstract: Motivated by variational inference methods, we propose a zeroth-order algorithm for solving optimization problems in the space of Gaussian probability measures. The algorithm is based on an interacting system of Gaussian particles that stochastically explore the search space and self-organize around global minima via a consensus-based optimization (CBO) mechanism. Its construction relies on the Linearized Bures-Wasserstein (LBW) space, a novel parametrization of Gaussian measures we introduce for efficient computations. LBW is inspired by linearized optimal transport and preserves key geometric features while enabling computational tractability. We establish well-posedness and study the convergence properties of the particle dynamics via a mean-field approximation. Numerical experiments on variational inference tasks demonstrate the algorithm's robustness and superior performance with respect to gradient-based method in presence of non log-concave targets.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [83] [Ultimate Forward Rate Prediction and its Application to Bond Yield Forecasting: A Machine Learning Perspective](https://arxiv.org/abs/2601.00011)
*Jiawei Du,Yi Hong*

Main category: q-fin.ST

TL;DR: 本研究利用中国国债和宏观经济数据，采用改进的de Kort-Vellekoop方法估计终极远期利率（UFR），并构建基于UFR的债券收益率预测模型，结合线性和非线性机器学习方法，发现非线性模型在引入物价指数类变量后预测效果更优。


<details>
  <summary>Details</summary>
Motivation: 准确预测长期债券收益率对保险、养老金等长期财务规划至关重要，而传统模型在估计终极远期利率（UFR）时易出现异常波动，且较少系统结合宏观经济变量进行建模，因此有必要提出更稳健的UFR估计方法并提升长期收益率预测精度。

Method: 采用de Kort-Vellekoop类型方法估计UFR，并提出一种最优拐点参数确定技术以减少波动；使用线性与非线性机器学习模型（如随机森林、支持向量机等）预测UFR和超长期债券收益率，输入变量包括历史收益率与宏观经济指标（如CPI、PPI等）。

Result: 非线性机器学习模型在UFR和长期债券收益率预测中表现优于线性模型；引入宏观经济变量，尤其是价格指数类变量，显著提升了预测准确性；所提出的UFR-based预测模型在不同期限债券中均表现出更优的预测性能。

Conclusion: 通过优化UFR估计方法并结合宏观经济变量，非线性机器学习模型能更有效地预测长期债券收益率，所构建的UFR-based模型为长期利率预测提供了更具实践价值的工具。

Abstract: This study focuses on forecasting the ultimate forward rate (UFR) and developing a UFRbased bond yield prediction model using data from Chinese treasury bonds and macroeconomic variables spanning from December 2009 to December 2024. The de Kort-Vellekooptype methodology is applied to estimate the UFR, incorporating the optimal turning parameter determination technique proposed in this study, which helps mitigate anomalous fluctuations. In addition, both linear and nonlinear machine learning techniques are employed to forecast the UFR and ultra-long-term bond yields. The results indicate that nonlinear machine learning models outperform their linear counterparts in forecasting accuracy. Incorporating macroeconomic variables, particularly price index-related variables, significantly improves the accuracy of predictions. Finally, a novel UFR-based bond yield forecasting model is developed, demonstrating superior performance across different bond maturities.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [84] [Mapping Supraglacial Water as a Window into Surge Hydrology: Linking Surface Water, Drainage Efficiency, and Surge Dynamics on Negribreen, Svalbard](https://arxiv.org/abs/2601.00137)
*Rachel Middleton,Ute Herzfeld,Thomas Trantow*

Main category: physics.geo-ph

TL;DR: 本研究分析了斯瓦尔巴群岛的Negribreen冰川系统在持续涌动期间的动力学特征，重点探讨地表水作为冰川动力过程指示器和涌动演化驱动因素的作用。通过多源遥感数据融合，识别出涌动的三个阶段，并揭示了地表水与冰川运动之间的动态关系。


<details>
  <summary>Details</summary>
Motivation: 理解北极冰川涌动过程中地表水的动态作用及其对冰川动力学的影响，有助于提升对冰川不稳定性机制的认识，并为未来冰川变化预测提供依据。

Method: 结合Maxar WorldView影像、ICESat-2测高数据和Sentinel-1合成孔径雷达数据，采用数据融合方法构建地表水分布图、水量时间序列、表面流速变化和冰面粗糙度空间分布，分析不同涌动阶段的地表水文特征。

Result: 识别出冰川涌动的三个阶段：初始加速期、成熟期和恢复静止期；发现初始加速期地表与基底水文连通性突然增强，成熟期出现充水裂隙并与压缩力区和变形区一致，且地表池塘快速排水；地表水动态可作为涌动活动的指示因子和驱动因素。

Conclusion: 地表水不仅是冰川涌动过程的重要指示器，还可能通过影响基底滑移和应力分布参与驱动涌动演化，研究结果增强了对北极冰川涌动机制的理解。

Abstract: We analyze the dynamics of Negribreen Glacier System, a polythermal glacier in Svalbard, during its ongoing surge and investigate the role of supraglacial (surface) water as both an indicator of ice-dynamic processes and a driver of surge evolution. We identify three distinct surge phases: the initial acceleration phase, mature phase, and return to quiescence. Comparing the quiescent supraglacial hydrological state to each of the surge phases, we observe a sudden increase in hydrological connectivity between the glacier surface and base during initial acceleration, followed by a gradual return to quiescent water extent. In the mature surge phase, emergent water-filled crevasses coincide with regions of compressive forcing and extensive deformation, follow local accelerations, and preceded smaller, secondary accelerations. Additionaly, rapid drainage of surface ponds is observed in the mature surge. A data-fusion approach, using Maxar WorldView(c) imagery, ICESat-2 altimetry, and Sentinel-1 Synthetic Aperture Radar, is taken to create a time series of supraglacial water maps, water volumes, surface velocity changes, and spatial ice surface roughness. These observations provide a qualitative (process understanding) and quantitative (water time series) basis for supraglacial water sources as a driver and indicator of surge activity for Arctic glaciers.

</details>


### [85] [Artificial intelligence and downscaling global climate model future projections](https://arxiv.org/abs/2601.00629)
*Rasmus E. Benestad*

Main category: physics.geo-ph

TL;DR: 本文对人工智能和深度机器学习在气候模式降尺度中的应用进行了批判性评述，指出当前研究存在忽视传统统计方法、评估策略不当及对科学进展描述不完整的问题，可能导致AI/ML优于传统方法的误导性结论。


<details>
  <summary>Details</summary>
Motivation: 近年来越来越多的研究将AI/ML应用于气候模型降尺度，但部分研究忽略了传统统计与数学方法的成功经验，且评估方式不够严谨，因此有必要基于已有科学原则进行反思与澄清。

Method: 通过回顾已有文献，结合过去的经验和公认的科学原则，对当前AI/ML在气候降尺度中的应用进行批判性分析，特别关注评估方法和对科学进展的表述是否充分。

Result: 发现许多近期研究存在对传统统计方法成就的忽视、评估策略不当以及对现有技术水平描述不完整的问题，导致可能高估AI/ML方法的性能。

Conclusion: AI/ML在气候降尺度中虽有潜力，但其优势不应被夸大；未来研究应更全面地比较不同方法，并采用更严谨的评估标准，以确保科学进步的真实性。

Abstract: A critical review of artificial intelligence and deep machine learning (AI/ML) applied to downscaling of global climate model simulations provides some words of caution, based on past experiences and well-established principles. Recent papers tend to ignore more subtle successes with statistics and mathematical based downscaling, and there are examples of inappropriate evaluation strategies and incomplete accounts of the scientific progress when it comes to climate downscaling. An incomplete description state-of-the-art and a dogmatic approach to evaluation may give a deceiving impression that AI/ML is superior to more statistics and mathematics based methods.

</details>


### [86] [Carbon mineralization in CO2-seawater-basalt systems: Reactive transport dynamics and vesicular pore architecture controls](https://arxiv.org/abs/2601.00710)
*Mohammad Nooraiepour,Mohammad Masoudi,Helge Hellevang*

Main category: physics.geo-ph

TL;DR: 该研究通过实验和多尺度成像揭示了玄武岩中碳酸盐矿物化的动力学机制，发现沉淀过程受成核控制且具有随机性，流动路径易因微小沉淀物堵塞而导致渗透率严重下降。


<details>
  <summary>Details</summary>
Motivation: 理解玄武岩中CO2矿化过程中反应传输和沉淀模式的基本控制机制，以实现快速、永久的碳封存。

Method: 结合80°C下使用CO2酸化海水的流动实验、地球化学模拟和多尺度孔隙成像，分析玄武岩玻璃中的矿物化动态。

Result: 碳酸盐沉淀受成核控制且具随机性；降低流速至0.005 mL/min才可见沉淀；发现钙碳酸盐和蒙脱石相；连接孔隙度显著低于总孔隙度；微CT显示玄武岩孔隙协调数低（模态=2），易形成串行流路径，导致轻微沉淀即可引发严重渗透率损失；海水降低矿化效率。

Conclusion: 需要采用概率性反应传输模型和更真实的孔隙拓扑结构来模拟玄武岩中的碳矿化过程，这与传统CCS方法有本质不同。

Abstract: Carbon mineralization in basaltic rocks may offer rapid, permanent \ce{CO2} storage, yet fundamental controls on reactive transport and precipitation patterns remain poorly understood. This study integrates flow-through experiments at 80\degree C using \ce{CO2}-acidified seawater with geochemical simulation and multi-scale pore imaging to elucidate mineralization dynamics in basaltic glass. Results reveal that carbonate precipitation is nucleation-controlled and stochastic rather than growth-controlled and deterministic, with isolated accumulations forming randomly despite continuous supersaturation. Residence time exerts primary control: reducing flow rate from 0.05 to 0.005\,mL/min proved necessary for visible precipitation. Post-experiment analyses identified calcium carbonate and smectite phases. Multi-scale characterization of three basalt facies revealed that connected porosity fractions (1.3--32\%) differ significantly from total porosity (18--42\%), demonstrating that network topology controls permeability. Micro-CT analysis revealed that pore coordination numbers in basalts (modal = 2) were notably lower than those in reservoir sandstones, creating serial flow paths that are vulnerable to catastrophic permeability loss from modest precipitation. Precipitation-induced clogging scenarios were proposed, where distributed small precipitates cause more severe permeability degradation than large accumulations. The use of seawater complicates geochemistry and reduces mineralization efficiency compared to freshwater. Findings emphasize the need for probabilistic reactive transport modeling frameworks and realistic pore topologies, which are fundamentally different from conventional CCS operations.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [87] [Finite element exterior calculus for time-dependent Hamiltonian partial differential equations](https://arxiv.org/abs/2601.00103)
*Ari Stern,Enrico Zampa*

Main category: math.NA

TL;DR: 本文提出了一类用于哈密顿偏微分方程的结构保持数值方法，结合有限元外微积分（FEEC）进行空间半离散化和辛积分器进行时间离散化，满足时空局部多辛守恒律。


<details>
  <summary>Details</summary>
Motivation: 受常微分方程中辛积分法成功的启发，寻求对哈密顿偏微分方程具有类似结构保持特性的数值方法。

Method: 将有限元外微积分（FEEC）用于空间半离散化，并结合辛积分器进行时间离散化，特别关注共形FEEC方法和混合间断Galerkin（HDG）方法。

Result: 所构造的方法满足时空局部多辛守恒律，比基于全局函数空间的方法能更精细地反映哈密顿结构。

Conclusion: 该方法成功推广了哈密顿常微分方程的辛守恒性质到偏微分方程，并在半线性Hodge波动方程上验证了有效性。

Abstract: The success of symplectic integrators for Hamiltonian ODEs has led to a decades-long program of research seeking analogously structure-preserving numerical methods for Hamiltonian PDEs. In this paper, we construct a large class of such methods by combining finite element exterior calculus (FEEC) for spatial semidiscretization with symplectic integrators for time discretization. The resulting methods satisfy a local multisymplectic conservation law in space and time, which generalizes the symplectic conservation law of Hamiltonian ODEs, and which carries finer information about Hamiltonian structure than other approaches based on global function spaces. We give particular attention to conforming FEEC methods and hybridizable discontinuous Galerkin (HDG) methods. The theory and methods are illustrated by application to the semilinear Hodge wave equation.

</details>


### [88] [Affine Invariant Langevin Dynamics for rare-event sampling](https://arxiv.org/abs/2601.00107)
*Deepyaman Chakraborty,Ruben Harris,Rupert Klein,Guillermo Olicón-Méndez,Sebastian Reich,Claudia Schillings*

Main category: math.NA

TL;DR: 提出了一种基于仿射不变Langevin动力学（ALDI）的框架，用于高效估计非线性动力系统中的罕见事件，通过将罕见事件转化为贝叶斯反问题并采用光滑逼近处理不可导性，在多个基准测试中表现出良好性能。


<details>
  <summary>Details</summary>
Motivation: 为了高效估计非线性动力系统中难以捕捉的罕见事件，需克服传统方法在高维、各向异性及复杂几何结构下的采样困难。

Method: 将罕见事件建模为具有非光滑极限状态函数的贝叶斯反问题，引入保持失效集的光滑近似，并利用仿射不变的ALDI粒子系统对后验分布进行采样，支持无梯度计算。

Result: 在多个基准问题（包括代数、鞍型不稳定和点涡模型）上验证了方法的有效性，ALDI能有效聚集于近临界集，提供准确的重要性采样建议分布，且计算鲁棒、适应性强。

Conclusion: ALDI框架是一种有前景的工具，适用于具有强几何各向异性和不稳定性态系统的罕见事件估计。

Abstract: We introduce an affine invariant Langevin dynamics (ALDI) framework for the efficient estimation of rare events in nonlinear dynamical systems. Rare events are formulated as Bayesian inverse problems through a nonsmooth limit-state function whose zero level set characterises the event of interest. To overcome the nondifferentiability of this function, we propose a smooth approximation that preserves the failure set and yields a posterior distribution satisfying the small-noise limit. The resulting potential is sampled by ALDI, a (derivative-free) interacting particle system whose affine invariance allows it to adapt to the local anisotropy of the posterior.
  We demonstrate the performance of the method across a hierarchy of benchmarks, namely two low-dimensional examples (an algebraic problem with convex geometry and a dynamical problem of saddle-type instability) and a point-vortex model for atmospheric blockings. In all cases, ALDI concentrates near the relevant near-critical sets and provides accurate proposal distributions for self-normalised importance sampling. The framework is computationally robust, potentially gradient-free, and well-suited for complex forward models with strong geometric anisotropy. These results highlight ALDI as a promising tool for rare-event estimation in unstable regimes of dynamical systems.

</details>


### [89] [Fast Ewald Summation with Prolates for Charged Systems in the NPT Ensemble](https://arxiv.org/abs/2601.00161)
*Jiuyang Liang,Libin Lu,Shidong Jiang*

Main category: math.NA

TL;DR: 提出了一种基于长球面波函数的NPT扩展Ewald求和方法（ESP），实现了周期带电系统在等温-等压系综下的高效、高精度压力计算，具有良好的可扩展性和较低的通信开销。


<details>
  <summary>Details</summary>
Motivation: 在分子动力学模拟中，现有网格Ewald方法在压力计算上存在精度与计算成本之间的权衡，缺乏热力学一致且高效的压力评估方法。

Method: 采用长球面波函数作为分裂和扩展核，构建了适用于各向同性、半各向同性、各向异性和全柔性晶胞的统一压力张量公式，并通过单一前向FFT实现长程压力计算。

Result: 在LAMMPS和GROMACS中实现了该方法，在体相水、离子液体和跨膜体系中验证了力和压力的准确性；在多达3000个CPU核心上的基准测试显示其在相同精度下具有更强的扩展性和更低的通信成本。

Conclusion: ESP方法在保持谱精度的同时显著减少了傅里叶网格大小和通信开销，特别适用于NPT系综下的大规模分子动力学模拟。

Abstract: We present an NPT extension of Ewald summation with prolates (ESP), a spectrally accurate and scalable particle-mesh method for molecular dynamics simulations of periodic, charged systems. Building on the recently introduced ESP framework, this work focuses on rigorous and thermodynamically consistent pressure/stress evaluation in the isothermal--isobaric ensemble. ESP employs prolate spheroidal wave functions as both splitting and spreading kernels, reducing the Fourier grid size needed to reach a prescribed pressure accuracy compared with current widely used mesh-Ewald methods based on Gaussian splitting and B-spline spreading. We derive a unified pressure-tensor formulation applicable to isotropic, semi-isotropic, anisotropic, and fully flexible cells, and show that the long-range pressure can be evaluated with a single forward FFT followed by diagonal scaling, whereas force evaluation requires both forward and inverse transforms. We provide production implementations in LAMMPS and GROMACS and validate pressure and force accuracy on bulk water, LiTFSI ionic liquids, and a transmembrane system. Benchmarks on up to $3\times 10^3$ CPU cores demonstrate strong scaling and reduced communication cost at matched accuracy, particularly for NPT pressure evaluation.

</details>


### [90] [Temporal Two-Grid Compact Difference Scheme for Benjamin-Bona-Mahony-Burgers Equation](https://arxiv.org/abs/2601.00193)
*Lisen Ding,Xiangyi Peng,Dongling Wang*

Main category: math.NA

TL;DR: 提出了一种时间双网格紧致差分（TTCD）格式求解具有初边值条件的Benjamin-Bona-Mahony-Burgers（BBMB）方程，通过粗细时间网格结合插值与线性化策略，在保证精度的同时降低了计算成本，并严格证明了其守恒性、可解性、收敛性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了在保持高精度的同时降低求解BBMB方程的计算代价，设计一种高效的数值方法。

Method: 采用时间双网格紧致差分（TTCD）方法：首先在粗时间网格（步长τ_c）上求解非线性系统，再通过线性Lagrange插值得到细时间网格（步长τ_f）上的粗略近似，最后在细网格上求解线性化格式获得修正解；结合能量法进行理论分析。

Result: TTCD格式在最大范数下达到O(τ_c² + τ_f² + h⁴)的收敛阶，具有守恒性、唯一可解性、稳定性和二阶时间收敛性；数值实验验证了方法的有效性与可行性。

Conclusion: 所提出的TTCD方法在显著减少计算量的同时保持高精度，是一种求解BBMB方程高效且可靠的数值方法。

Abstract: This paper proposes a temporal two-grid compact difference (TTCD) scheme for solving the Benjamin-Bona-Mahony-Burgers (BBMB) equation with initial and periodic boundary conditions. The method consists of three main steps: first, solving a nonlinear system on a coarse time grid of size $τ_c$; then obtaining a coarse approximation on the fine time grid of size $τ_f$ via linear Lagrange interpolation; and finally solving a linearized scheme on the fine grid to obtain the corrected solution. The TTCD scheme reduces computational cost without sacrificing accuracy. Moreover, using the energy method, we rigorously prove the conservation property, unique solvability, convergence, and stability of the proposed scheme. It is shown that the method achieves convergence of order $\mathcal{O}(τ_c^2 + τ_f^2 + h^4)$ in the maximum norm, where $h$ is space step size. Finally, some numerical experiments are provided to demonstrate the effectiveness and feasibility of the proposed strategy.

</details>


### [91] [Spectral Schur analysis of structured moment matrices for quadratic histopolation](https://arxiv.org/abs/2601.00301)
*Allal Guessab,Federico Nudo*

Main category: math.NA

TL;DR: 本文研究了来自单纯形网格上加权二次histopolation的参数依赖结构化矩矩阵，提出了兼容面密度和正交分解方法，通过减少Schur补特征分析局部矩系统的可逆性，并优化全局重构系统的稳定性和条件数。


<details>
  <summary>Details</summary>
Motivation: 为了改善单纯形网格上加权二次histopolation中结构化矩矩阵的稳定性与条件数，研究参数依赖的结构特性及其对系统性能的影响。

Method: 构造兼容面密度和二次多项式空间的正交分解，识别出描述丰富性和适定性的简化Schur补，并从矩阵角度提出谱准则以优化基的选择和系统条件数。

Result: 确定了简化Schur补与低维对称正定算子最小特征值平方根的一致性，提出了小特征值优化问题并验证了三维实验中的稳定性、条件数和收敛行为。

Conclusion: 该方法提供了局部矩系统可逆性的简单谱判据，有效提升了全局重构系统的稳定性和数值性能。

Abstract: In this paper we study parameter-dependent structured moment matrices with a canonical block form arising from weighted quadratic histopolation on simplicial meshes. For a strictly positive density on a simplex, we construct compatible face densities and an orthogonal decomposition of the quadratic polynomial space into face and interior components, which induces a natural face-interior block structure. A reduced Schur complement is identified that fully characterizes enrichment and well-posedness and provides a sharp spectral stability result. We show that this quantity coincides with the square root of the smallest eigenvalue of a low-dimensional symmetric positive definite operator. This matrix-based viewpoint yields simple spectral criteria for the invertibility of local moment systems and motivates spectrally preferable choices of face and interior bases with improved conditioning. Using the resulting degrees of freedom together with density and scaling parameters as design variables, we formulate a small eigenvalue optimization problem aimed at improving stability and reducing the condition number of the global reconstruction system. Three-dimensional experiments on uniform and quasi-uniform simplicial meshes illustrate the predicted stability, conditioning, and convergence behaviour of the enriched quadratic reconstruction.

</details>


### [92] [A weak Galerkin least squares finite element method for linear convection equations in non-divergence form](https://arxiv.org/abs/2601.00399)
*Chunmei Wang,Shangyou Zhang*

Main category: math.NA

TL;DR: 本文提出了一种用于非散度形式一阶线性对流方程的弱伽辽金最小二乘（WG--LS）有限元方法，该方法使用不连续有限元函数，无需对流矢量或反应系数的强制性假设，适用于一般多边形和多面体网格，并在适当的能量范数下建立了最优误差估计。


<details>
  <summary>Details</summary>
Motivation: 为了解决非散度形式的一阶线性对流方程，现有的方法可能需要较强的假设条件或仅限于特定类型的网格，因此需要一种更灵活且不需要强制性假设的新方法。

Method: 采用不连续有限元函数构建弱伽辽金最小二乘有限元方法，此方法导致对称正定线性系统，适用于一般多边形和多面体网格。

Result: 在系数的最小正则性假设下，针对合适的能量范数建立了WG--LS近似的最优阶误差估计，并通过数值实验验证了理论收敛结果以及所提方法的准确性和效率。

Conclusion: 提出的弱伽辽金最小二乘有限元方法对于解决非散度形式的一阶线性对流方程是有效的，它不仅放宽了对系数的要求，而且能够在广泛的网格类型上实现最优收敛率。

Abstract: This article develops a weak Galerkin least-squares (WG--LS) finite element method for first-order linear convection equations in non-divergence form. The method is formulated using discontinuous finite element functions and does not require any coercivity assumption on the convection vector or reaction coefficient. The resulting discrete problem leads to a symmetric and positive definite linear system and is applicable to general polygonal and polyhedral meshes. Under minimal regularity assumptions on the coefficients, optimal-order error estimates are established for the WG--LS approximation in a suitable energy norm. Numerical experiments are presented to confirm the theoretical convergence results and to demonstrate the accuracy and efficiency of the proposed method.

</details>


### [93] [Guaranteed stability bounds for second-order PDE problems satisfying a Garding inequality](https://arxiv.org/abs/2601.00404)
*T. Chaumont-Frelet*

Main category: math.NA

TL;DR: 提出一种数值算法，用于判断满足Garding不等式的二阶线性偏微分方程问题是否适定，并提供弱形式下inf-sup常数的下界估计，结合有限元离散与通量重构误差估计，证明该下界在足够精细离散下仅比最优常数小约两倍。


<details>
  <summary>Details</summary>
Motivation: 为了判断二阶线性PDE问题在满足Garding不等式条件下的适定性，并为后验误差估计提供可靠的inf-sup常数下界。

Method: 基于Lagrange有限元离散和通量重构技术的后验误差估计，求解两个离散的奇异值问题来计算inf-sup常数的数值下界。

Result: 在足够丰富的有限元离散条件下，所提出的数值下界仅比最优inf-sup常数小约两倍。

Conclusion: 该算法能有效估计PDE问题的适定性和inf-sup常数，具有应用于可靠后验误差估计的潜力。

Abstract: We propose an algorithm to numerically determined whether a second-order linear PDE problem satisfying a Garding inequality is well-posed. This algorithm further provides a lower bound to the inf-sup constant of the weak formulation, which may in turn be used for a posteriori error estimation purposes. Our numerical lower bound is based on two discrete singular value problems involving a Lagrange finite element discretization coupled with an a posteriori error estimator based on flux reconstruction techniques. We show that if the finite element discretization is sufficiently rich, our lower bound underestimates the optimal constant only by a factor roughly equal to two.

</details>


### [94] [A Unified Trace-Optimization Framework for Multidimensionality Reduction](https://arxiv.org/abs/2601.00729)
*Mohamed El Guide,Alaa El Ichi,Khalide Jbilou,Lothar Reichel,Hessah Alqahtani*

Main category: math.NA

TL;DR: 本文综述了多种多维降维方法，包括MPCA、MONPP、MLLE和MLE，基于迹优化框架统一表述，并比较了其理论基础、假设、计算效率及适用性，为实际应用中选择合适方法提供了指导。


<details>
  <summary>Details</summary>
Motivation: 为了系统地理解和比较多维主成分分析、正交邻域保持投影、局部线性嵌入和拉普拉斯特征映射等多维降维方法，建立一个统一的理论框架并提供方法选择指南。

Method: 采用基于迹优化的统一框架表达各降维方法，形式化为最大化或最小化问题，并提出线性方法及其核化扩展以处理非线性关系。

Result: 实现了MPCA、MONPP、MLLE和MLE在统一框架下的公式化表达，展示了核扩展方法在捕捉高维数据非线性关系上的能力，并对各方法的理论特性与计算效率进行了比较分析。

Conclusion: 不同多维降维方法各有优劣，选择应基于具体应用需求；所提出的统一框架有助于理解方法间的联系，并为非线性场景提供有效的核扩展方案。

Abstract: This paper presents a comprehensive overview of several multidimensional reduction methods focusing on Multidimensional Principal Component Analysis (MPCA), Multilinear Orthogonal Neighborhood Preserving Projection (MONPP), Multidimensional Locally Linear Embedding (MLLE), and Multidimensional Laplacian Eigenmaps (MLE). These techniques are formulated within a unified framework based on trace optimization, where the dimensionality reduction problem is expressed as maximization or minimization problems. In addition to the linear MPCA and MONPP approaches, kernel-based extensions of these methods also are presented. The latter methods make it possible to capture nonlinear relations between high-dimensional data. A comparative analysis highlights the theoretical foundations, assumptions, and computational efficiency of each method, as well as their practical applicability. The study provides insights and guidelines for selecting an appropriate dimensionality reduction technique suited to the application at hand.

</details>
