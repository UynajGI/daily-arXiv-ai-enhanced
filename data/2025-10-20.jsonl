{"id": "2510.15043", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.15043", "abs": "https://arxiv.org/abs/2510.15043", "authors": ["Mathias Dufresne-Piché", "Siva Nadarajah"], "title": "Linearly Stable Generalizations of ESFR Schemes", "comment": "31 pages, 29 figures", "summary": "The energy stable flux reconstruction (ESFR) method encompasses an infinite\nfamily of high-order, linearly stable schemes and thus provides a flex- ible\nand efficient framework for achieving high levels of accuracy on unstruc- tured\ngrids. One remarkable property of ESFR schemes is their ability to be expressed\nequivalently as linearly filtered discontinuous Galerkin (FDG) schemes. In this\nstudy, we introduce Sobolev Stable discontinuous Galerkin (SSDG) schemes, a new\nconservative and linearly stable generalization of ESFR schemes via the FDG\nframework. Additionally, we review existing generalizations of the ESFR method\nand consider their relationship with the FDG framework. The linear properties\nof SSDG schemes are studied via Von Neumann analysis and compared to those of\nthe existing extended ESFR (EESFR) method. It is found that while SSDG and\nEESFR schemes exhibit fundamentally different dispersive and dissipative\nbehaviors, they can achieve a similar increase in CFL limit and exhibit a\nsimilar spectral order of accuracy. Moreover, it is seen that the range of\nscheme parameters over which SSDG schemes can be used to increase the explicit\ntime-stepping limit is much larger than for EESFR schemes. Finally, it is\nobserved that the order of accuracy of EESFR schemes under h-refinement is\ngenerally p + 1 while that of SSDG schemes is p."}
{"id": "2510.15034", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.15034", "abs": "https://arxiv.org/abs/2510.15034", "authors": ["Lucas Z. Brito", "J. B. Marston"], "title": "Reconstructing Spin Hamiltonians of 2D Gutzwiller-Projected Wavefunctions", "comment": "12 pages, 7 figures, 1 table", "summary": "We apply the correlation matrix Hamiltonian reconstruction technique to the\ntwo-dimensional Gutzwiller-projected Fermi sea and {\\pi}-flux states on\nfinite-sized square and triangular lattices. Our results indicate no spin\nHamiltonian with simple local interaction terms stabilizes such states for\nfinite system sizes. We develop a quantitative assessment of the importance of\nlocal interactions to the stabilization of these liquid states. Lastly, we\nsystematically assess arguments for the origin of local terms driving a\nGutzwiller-projected ground state."}
{"id": "2510.15093", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15093", "abs": "https://arxiv.org/abs/2510.15093", "authors": ["Yue Zhao", "Huan Lei"], "title": "Fast spectral separation method for kinetic equation with anisotropic non-stationary collision operator retaining micro-model fidelity", "comment": null, "summary": "We present a generalized, data-driven collisional operator for one-component\nplasmas, learned from molecular dynamics simulations, to extend the collisional\nkinetic model beyond the weakly coupled regime. The proposed operator features\nan anisotropic, non-stationary collision kernel that accounts for particle\ncorrelations typically neglected in classical Landau formulations. To enable\nefficient numerical evaluation, we develop a fast spectral separation method\nthat represents the kernel as a low-rank tensor product of univariate basis\nfunctions. This formulation admits an $O(N \\log N)$ algorithm via fast Fourier\ntransforms and preserves key physical properties, including discrete\nconservation laws and the H-theorem, through a structure-preserving central\ndifference discretization. Numerical experiments demonstrate that the proposed\nmodel accurately captures plasma dynamics in the moderately coupled regime\nbeyond the standard Landau model while maintaining high computational\nefficiency and structure-preserving properties."}
{"id": "2510.15080", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2510.15080", "abs": "https://arxiv.org/abs/2510.15080", "authors": ["Xiangyu Luo", "Ludovica Zullo", "Sahaj Patel", "Dongjin Oh", "Qian Song", "Asish K. Kundu", "Anil Rajapitamahuni", "Elio Vescovo", "Natalia Olszowska", "Rafal Kurleto", "Dawid Wutke", "Giorgio Sangiovanni", "Riccardo Comin"], "title": "Robust Orbital-Selective Flat Bands in Transition-Metal Oxychlorides", "comment": null, "summary": "Flat electronic bands, which amplify electron correlations by quenching\nkinetic energy, provide an ideal foundation for exotic quantum phases. However,\nprevailing strategies -- including geometrically frustrated lattices, moire\nsuperlattices and heavy-fermion physics -- suffer from inherent trade-offs\namong robustness, tunability and orbital selectivity, limiting their broad\napplicability. Here, we unveil an intrinsic orbital-selective flat-band\nmechanism in the van der Waals materials NbOCl2 and TaOCl2, directly observed\nby angle-resolved photoemission spectroscopy (ARPES) and understood through\ndensity functional theory (DFT) and Wannier analysis. Crucially, we\nexperimentally demonstrate that this momentum-independent flat band exhibits\nremarkable robustness, surviving from the bulk crystal down to the few-layer\nlimit at room temperature. Our theoretical analysis traces its origin to the\nhybridization between Nb-dz2 orbital chains and the Lieb-like dx2-y2\nsublattice, which is further reinforced by Peierls dimerization. Our findings\nnot only establish transition-metal oxychlorides as a robust and tunable\nplatform for flat-band-driven correlated phases under ambient conditions, but\nalso uncover a new orbital-selective design principle for realizing flat bands\nin quantum materials."}
{"id": "2510.15097", "categories": ["math.NA", "cs.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.15097", "abs": "https://arxiv.org/abs/2510.15097", "authors": ["Kazufumi Ito", "Tiancheng Xue"], "title": "Reduced order method based Anderson-type acceleration method for nonlinear least square problems and large scale ill-posed problems", "comment": null, "summary": "In this paper we discuss the Anderson's type acceleration method for\nnumerical optimizations. Most mathematical modeling problems can be formulated\nas constrained optimization. The necessary optimality condition is written as a\nfixed point problem in a Banach space. Anderson's acceleration method improves\nthe convergence of the standard fixed point iteration by minimizing the total\nsum of residuals and updating solutions through an optimal linear combination\nof a sequence of iterates. Thus, it is a form of iterative method of retard\nwhich uses the history of solutions as a reduced order element method (ROM).\nThe weights are determined optimally by the least squares problem based on the\ntotal residual. We analyze Anderson's method and the reduced order method (ROM)\nfor nonlinear least squares problems of minimizing |F(x)| squared. That is, the\nsolution is approximated by a linear combination of sequentially generated\nsolutions, and then we minimize the equation error on the linear manifold\nspanned by the iterates. We use the reduced order Gauss Newton method to solve\nthe least squares problem for |F(x)| squared on the linear solution manifold.\nFor the linear equation case it is similar to Anderson's method. Anderson's\nmethod approximates the solution to the nonlinear ROM. We consider variable\nstep size gradient and quasi Newton methods and the variable fixed point\niteration to generate the solution basis, then combine these with ROM\nacceleration. It converges very rapidly if the condition number of matrix A is\nnot large. The variable iterate with ROM acceleration is nearly optimal, and\nROM also regularizes and stabilizes the convergence. We also consider a\nrandomly overlapped Kaczmarz type method and develop an acceleration approach\nfor large scale ill posed linear systems. Finally, we analyze the convergence\nof the ROM to the operator equation."}
{"id": "2510.15111", "categories": ["cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2510.15111", "abs": "https://arxiv.org/abs/2510.15111", "authors": ["Yunchao Zhang", "T. Senthil"], "title": "Unusual critical points between atomic insulating phases", "comment": "27 pages, 10 figures", "summary": "We study a class of quantum phase transitions between featureless bosonic\natomic insulators in $(2+1)$ dimensions, where each phase exhibits neither\ntopological order nor protected edge modes. Despite their lack of topology,\nthese insulators may be ``obstructed'' in the sense that their Wannier centers\nare not pinned to the physical atomic sites. These insulators represent\ndistinct phases, as no symmetry-preserving adiabatic path connects them.\nSurprisingly, we find that the critical point between these insulators can host\na conformally invariant state described by quantum electrodynamics in $(2+1)$\ndimensions (QED$_3$). The emergent electrodynamics at the critical point can be\nstabilized if the embedding of the microscopic lattice symmetries suppresses\nthe proliferation of monopoles, suggesting that even transitions between\ntrivial phases can harbor rich and unexpected physics. We analyze the mechanism\nbehind this phenomenon, discuss its stability against perturbations, and\nexplore the embedding of lattice symmetries into the continuum through anomaly\nmatching. In all the models we analyze, we confirm that the QED$_3$ is indeed\nemergeable, in the sense that it is realizable from a local lattice\nHamiltonian."}
{"id": "2510.15274", "categories": ["math.NA", "cs.NA", "65M06, 65M15, 65M55"], "pdf": "https://arxiv.org/pdf/2510.15274", "abs": "https://arxiv.org/abs/2510.15274", "authors": ["Xiangyi Peng", "Lisen Ding", "Wenlin Qiu"], "title": "An Efficient Space-Time Two-Grid Compact Difference Scheme for the Two-Dimensional Viscous Burgers' Equation", "comment": null, "summary": "This work proposes an efficient space-time two-grid compact difference\n(ST-TGCD) scheme for solving the two-dimensional (2D) viscous Burgers' equation\nsubject to initial and periodic boundary conditions. The proposed approach\ncombines a compact finite difference discretization with a two-grid strategy to\nachieve high computational efficiency without sacrificing accuracy. In the\ncoarse-grid stage, a fixed-point iteration is employed to handle the nonlinear\nsystem, while in the fine-grid stage, linear temporal and cubic spatial\nLagrange interpolations are used to construct initial approximations. The final\nfine-grid solution is refined through a carefully designed linearized\ncorrection scheme. Rigorous analysis establishes unconditional convergence of\nthe method, demonstrating second-order accuracy in time and fourth-order\naccuracy in space. Numerical experiments verify the theoretical results and\nshow that the ST-TGCD scheme reduces CPU time by more than 70\\% compared with\nthe traditional nonlinear compact difference (NCD) method, while maintaining\ncomparable accuracy. These findings confirm the proposed scheme as a highly\nefficient alternative to conventional nonlinear approaches."}
{"id": "2510.15158", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.15158", "abs": "https://arxiv.org/abs/2510.15158", "authors": ["Kazuki Okigami", "Satoru Hayami"], "title": "Four-Spin Interactions as a Route to Multiple-Q Topological Magnetic Order", "comment": "14 pages, 9 figures", "summary": "We investigate the role of four-spin interactions in stabilizing exotic\nmultiple-$Q$ topological spin textures and demonstrate their ability to realize\na skyrmion crystal. While such higher-order interactions are known to be\nimportant, their intricate nature makes systematic model construction\nsignificantly challenging. To address this issue, we develop a theoretical\nframework that connects microscopic real-space four-spin couplings to their\neffective interactions in momentum space, providing a clear route to engineer\ntarget magnetic phases. Applying this framework to a frustrated Heisenberg\nmodel with designed four-spin interactions, we identify the stabilization of\nthe zero-field skyrmion crystal with a topological number of two via simulated\nannealing. Furthermore, our momentum-space analysis reveals the intrinsic\nmechanism by which the well-known ring-exchange interaction also favors the\nskyrmion crystal. Our findings not only present a concrete model for a\nhigher-order skyrmion crystal but also offer a general methodology for\nunderstanding and designing a wide range of complex multiple-$Q$ magnetic\norders driven by multi-spin interactions."}
{"id": "2510.15035", "categories": ["cond-mat.stat-mech", "cond-mat.other", "cond-mat.quant-gas", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.15035", "abs": "https://arxiv.org/abs/2510.15035", "authors": ["Mrinal Kanti Sarkar", "Saranyo Moitra", "Rajdeep Sensarma"], "title": "Entanglement Entropy from Correlation Functions of Scalar Fields in and out of Equilibrium", "comment": "11 + 8 pages, 4 + 1 Figures", "summary": "We show that odd order R\\'enyi entropies $S^{(2q+1)}$ of a system of\ninteracting scalar fields can be calculated as the free energy of $2q+1$\nreplicas of the system with additional quadratic inter-replica couplings in the\nsubsystem at the time of measurement of the entropy. These couplings replace\nboundary field matching conditions. This formalism works both in and out of\nthermal equilibrium, for closed as well as open quantum systems, and provides a\ngeneral dictionary between measurable correlation functions and entanglement\nentropy. $S^{(2q+1)}$ can be analytically continued to calculate the von\nNeumann entropy $S^{\\mathrm{vN}}$. We provide an exact formula relating\n$S^{(2q+1)}$ and $S^{\\mathrm{vN}}$ with correlation functions in a\nnon-interacting theory. For interacting theories, we provide rules for\nconstructing all possible Feynman diagrams for $S^{(2q+1)}$. We show that the\nboundary matching conditions cannot be completely eliminated while calculating\nR\\'enyi entropies of even order due to presence of zero modes in replica space."}
{"id": "2510.15187", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2510.15187", "abs": "https://arxiv.org/abs/2510.15187", "authors": ["Cameron Cianci", "Luchang Jin", "Joshua Swaim"], "title": "Using lattice chiral effective theory to study pi-pi scattering", "comment": null, "summary": "We use lattice field theory to study the finite-volume energy spectrum of the\n$\\pi\\pi$ system in $SU(2)$ chiral effective field theory (ChEFT) at leading\norder in the chiral expansion. We compare our results with the finite volume\nspectrum obtained from lattice QCD (Blum et al., Phys. Rev. D 107(9):094512,\n2023, arXiv:2301.09286 [hep-lat]). Our calculation and the lattice QCD\ncalculation are both performed with the physical pion mass and the same\nphysical volume. However, we find significant differences between the two\ncalculations in the isospin $I=0$ channel. In particular, there is a nearly\nstable $\\sigma$ resonance in our lattice ChEFT calculation, which is absent in\nthe lattice QCD calculation. This likely indicates that ChEFT does not converge\nwell with a naive lattice regularization."}
{"id": "2505.05572", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2505.05572", "abs": "https://arxiv.org/abs/2505.05572", "authors": ["Isaías Vallejo-Fabila", "Adway Kumar Das", "Sayan Choudhury", "Lea F. Santos"], "title": "Proposal for many-body quantum chaos detection with single-site measurements", "comment": "8 pages, 6 figures", "summary": "We demonstrate that the long-time dynamics of an observable associated with a\nsingle lattice site is sufficient to determine whether a many-body quantum\nsystem exhibits level statistics characteristic of random matrix theory, a\nwidely used diagnostic of quantum chaos. In particular, we focus on the partial\nsurvival probability and spin autocorrelation function at a single site, both\nevolved under a disordered spin-1/2 chain, which is a setup realizable in\ncurrent experimental platforms. Given the precision and timescales currently\nachievable, our results indicate that the detection of many-body quantum chaos\nis feasible, but constrained to small system sizes."}
{"id": "2510.15045", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15045", "abs": "https://arxiv.org/abs/2510.15045", "authors": ["Ziqing Zhu"], "title": "Q-EnergyDEX: A Zero-Trust Distributed Energy Trading Framework Driven by Quantum Key Distribution and Blockchain", "comment": null, "summary": "The rapid decentralization and digitalization of local electricity markets\nhave introduced new cyber-physical vulnerabilities, including key leakage, data\ntampering, and identity spoofing. Existing blockchain-based solutions provide\ntransparency and traceability but still depend on classical cryptographic\nprimitives that are vulnerable to quantum attacks. To address these challenges,\nthis paper proposes Q-EnergyDEX, a zero-trust distributed energy trading\nframework driven by quantum key distribution and blockchain. The framework\nintegrates physical-layer quantum randomness with market-level operations,\nproviding an end-to-end quantum-secured infrastructure. A cloud-based Quantum\nKey Management Service continuously generates verifiable entropy and regulates\nkey generation through a rate-adaptive algorithm to sustain high-quality\nrandomness. A symmetric authentication protocol (Q-SAH) establishes secure and\nlow-latency sessions, while the quantum-aided consensus mechanism (PoR-Lite)\nachieves probabilistic ledger finality within a few seconds. Furthermore, a\nStackelberg-constrained bilateral auction couples market clearing with entropy\navailability, ensuring both economic efficiency and cryptographic security.\nSimulation results show that Q-EnergyDEX maintains robust key stability and\nnear-optimal social welfare, demonstrating its feasibility for large-scale\ndecentralized energy markets."}
{"id": "2510.15113", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2510.15113", "abs": "https://arxiv.org/abs/2510.15113", "authors": ["Anutam Srinivasan", "Aaron Nielsen"], "title": "Extending Temporal Disturbance Estimations For Magnetic Anomaly Navigation and Mapping", "comment": null, "summary": "Slow-moving vehicles relying on crustal magnetic anomaly navigation (MagNav)\nor vehicles revisiting the same location in a short time - such as those used\nfor surveys in magnetic anomaly mapping - require fixed ground stations within\n100 km of the vehicle's trajectory to measure and remove the geomagnetic\ndisturbance field from magnetic readings. This approach is impractical due to\nthe limited network of fixed-ground magnetometer stations, making long-range\n(several hundred kilometers long) aeromagnetic surveys for anomaly map-making\ninfeasible. To address these challenges, we developed the Extended Reference\nStation Model (ERSM). ERSM applies a longitudinal correction and regression\nmodel to an extended reference ground magnetometer station (ERS) to produce an\nestimate of the local temporal disturbance field. ERSM is regression\nmodel-agnostic, so we implemented a linear regression, a k-nearest neighbors\n(kNN) regression, and a neural-network regression model to assess performance\nbenefits. Our results show typical performance below 10nT root mean square\nerror and median performance below 5nT for typical use with the kNN and\nneural-net model for farther distances and below 5nT performance using the\nlinear regression model on stations with proximity. We also consider how\nspace-weather events, water-body separation, and proximity to polar regions\naffect the model performance based on ERS selection."}
{"id": "2510.15000", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15000", "abs": "https://arxiv.org/abs/2510.15000", "authors": ["Yixin Fang", "Man Jin"], "title": "Estimand framework and intercurrent events handling for clinical trials with time-to-event outcomes", "comment": null, "summary": "The ICH E9(R1) guideline presents a framework of estimand for clinical\ntrials, proposes five strategies for handling intercurrent events (ICEs), and\nprovides a comprehensive discussion and many real-life clinical examples for\nquantitative outcomes and categorical outcomes. However, in ICH E9(R1) the\ndiscussion is lacking for time-to-event (TTE) outcomes. In this paper, we\ndiscuss how to define estimands and how to handle ICEs for clinical trials with\nTTE outcomes. Specifically, we discuss six ICE handling strategies, including\nthose five strategies proposed by ICH E9(R1) and a new strategy, the\ncompeting-risk strategy. Compared with ICH E9(R1), the novelty of this paper is\nthree-fold: (1) the estimands are defined in terms of potential outcomes, (2)\nthe methods can utilize time-dependent covariates straightforwardly, and (3)\nthe efficient estimators are discussed accordingly."}
{"id": "2510.15045", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15045", "abs": "https://arxiv.org/abs/2510.15045", "authors": ["Ziqing Zhu"], "title": "Q-EnergyDEX: A Zero-Trust Distributed Energy Trading Framework Driven by Quantum Key Distribution and Blockchain", "comment": null, "summary": "The rapid decentralization and digitalization of local electricity markets\nhave introduced new cyber-physical vulnerabilities, including key leakage, data\ntampering, and identity spoofing. Existing blockchain-based solutions provide\ntransparency and traceability but still depend on classical cryptographic\nprimitives that are vulnerable to quantum attacks. To address these challenges,\nthis paper proposes Q-EnergyDEX, a zero-trust distributed energy trading\nframework driven by quantum key distribution and blockchain. The framework\nintegrates physical-layer quantum randomness with market-level operations,\nproviding an end-to-end quantum-secured infrastructure. A cloud-based Quantum\nKey Management Service continuously generates verifiable entropy and regulates\nkey generation through a rate-adaptive algorithm to sustain high-quality\nrandomness. A symmetric authentication protocol (Q-SAH) establishes secure and\nlow-latency sessions, while the quantum-aided consensus mechanism (PoR-Lite)\nachieves probabilistic ledger finality within a few seconds. Furthermore, a\nStackelberg-constrained bilateral auction couples market clearing with entropy\navailability, ensuring both economic efficiency and cryptographic security.\nSimulation results show that Q-EnergyDEX maintains robust key stability and\nnear-optimal social welfare, demonstrating its feasibility for large-scale\ndecentralized energy markets."}
{"id": "2510.15691", "categories": ["q-fin.CP", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15691", "abs": "https://arxiv.org/abs/2510.15691", "authors": ["Tian Guo", "Emmanuel Hauptmann"], "title": "Exploring the Synergy of Quantitative Factors and Newsflow Representations from Large Language Models for Stock Return Prediction", "comment": null, "summary": "In quantitative investing, return prediction supports various tasks,\nincluding stock selection, portfolio optimization, and risk management.\nQuantitative factors, such as valuation, quality, and growth, capture various\ncharacteristics of stocks. Unstructured financial data, like news and\ntranscripts, has attracted growing attention, driven by recent advances in\nlarge language models (LLMs). This paper examines effective methods for\nleveraging multimodal factors and newsflow in return prediction and stock\nselection. First, we introduce a fusion learning framework to learn a unified\nrepresentation from factors and newsflow representations generated by an LLM.\nWithin this framework, we compare three representative methods: representation\ncombination, representation summation, and attentive representations. Next,\nbuilding on empirical observations from fusion learning, we explore the mixture\nmodel that adaptively combines predictions made by single modalities and their\nfusion. To mitigate the training instability observed in the mixture model, we\nintroduce a decoupled training approach with theoretical insights. Finally, our\nexperiments on real investment universes yield several insights into effective\nmultimodal modeling of factors and news for stock return prediction."}
{"id": "2510.15790", "categories": ["math.ST", "cs.DS", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.15790", "abs": "https://arxiv.org/abs/2510.15790", "authors": ["Chirag Pabbaraju", "Gregory Valiant", "Rishi Verma"], "title": "A Simple Geometric Proof of the Optimality of the Sequential Probability Ratio Test for Symmetric Bernoulli Hypotheses", "comment": "20 pages", "summary": "This paper revisits the classical problem of determining the bias of a\nweighted coin, where the bias is known to be either $p = 1/2 + \\varepsilon$ or\n$p = 1/2 - \\varepsilon$, while minimizing the expected number of coin tosses\nand the error probability. The optimal strategy for this problem is given by\nWald's Sequential Probability Ratio Test (SPRT), which compares the\nlog-likelihood ratio against fixed thresholds to determine a stopping time.\nClassical proofs of this result typically rely on analytical, continuous, and\nnon-constructive arguments. In this paper, we present a discrete,\nself-contained proof of the optimality of the SPRT for this problem. We model\nthe problem as a biased random walk on the two-dimensional (heads, tails)\ninteger lattice, and model strategies as marked stopping times on this lattice.\nOur proof takes a straightforward greedy approach, showing how any arbitrary\nstrategy may be transformed into the optimal, parallel-line \"difference policy\"\ncorresponding to the SPRT, via a sequence of local perturbations that improve a\nBayes risk objective."}
{"id": "2510.15166", "categories": ["math.OC", "cs.SY", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.15166", "abs": "https://arxiv.org/abs/2510.15166", "authors": ["Masih Haseli", "Igor Mezić", "Jorge Cortés"], "title": "Two Roads to Koopman Operator Theory for Control: Infinite Input Sequences and Operator Families", "comment": null, "summary": "The Koopman operator, originally defined for dynamical systems without input,\nhas inspired many applications in control. Yet, the theoretical foundations\nunderpinning this progress in control remain underdeveloped. This paper\ninvestigates the theoretical structure and connections between two extensions\nof Koopman theory to control: (i) Koopman operator via infinite input sequences\nand (ii) the Koopman control family. Although these frameworks encode system\ninformation in fundamentally different ways, we show that under certain\nconditions on the function spaces they operate on, they are equivalent. The\nequivalence is both in terms of the actions of the Koopman-based formulations\nin each framework as well as the function values on the system trajectories.\nOur analysis provides constructive tools to translate between the frameworks,\noffering a unified perspective for Koopman methods in control."}
{"id": "2510.15291", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.15291", "abs": "https://arxiv.org/abs/2510.15291", "authors": ["Luke P. Filippini", "Adrianne L. Jenner", "Elliot J. Carr"], "title": "Random walk models of anisotropic diffusion on rectangular and hexagonal lattices", "comment": "30 pages, 11 figures, 1 table, submitted", "summary": "The diffusive transport of particles in anisotropic media is a fundamental\nphenomenon in computational, medical and biological disciplines. While\ndeterministic models (partial differential equations) of such processes are\nwell established, their inability to capture inherent randomness, and the\nassumption of a large number of particles, hinders their applicability. To\naddress these issues, we present several equivalent (discrete-space\ndiscrete-time) random walk models of diffusion described by a\nspatially-invariant tensor on a two-dimensional domain with no-flux boundary\nconditions. Our approach involves discretising the deterministic model in space\nand time to give a homogeneous Markov chain governing particle movement between\n(spatial) lattice sites over time. The spatial discretisation is carried out\nusing a vertex-centred element-based finite volume method on rectangular and\nhexagonal lattices, and a forward Euler discretisation in time yields a\nnearest-neighbour random walk model with simple analytical expressions for the\ntransition probabilities. For each lattice configuration, analysis of these\nexpressions yields constraints on the time step duration, spatial steps and\ndiffusion tensor to ensure the probabilities are between zero and one. We find\nthat model implementation on a rectangular lattice can be achieved with a\nconstraint on the diffusion tensor, whereas a hexagonal lattice overcomes this\nlimitation (no restrictions on the diffusion tensor). Overall, the results\ndemonstrate good visual and quantitative (mean-squared error) agreement between\nthe deterministic model and random walk simulations for several test cases. All\nresults are obtained using MATLAB code available on GitHub\n(https://github.com/lukefilippini/Filippini2025)."}
{"id": "2510.15281", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.15281", "abs": "https://arxiv.org/abs/2510.15281", "authors": ["Qingkai Kong", "Avigyan Chatterjee", "Chengping Chai", "Alex Dzubay", "Kayla A. Kroll", "Josh C. Stachnik", "Scott Fertig", "Jeffrey Liefer", "Paul Friberg"], "title": "Evaluating Multi-station Phase Picking Algorithm Phase Neural Operator (PhaseNO) on Local Seismic Networks", "comment": null, "summary": "Reliable automatic phase picking is important for many seismic applications.\nWith the development of machine learning approaches, many algorithms are\nproposed, evaluated and applied to different areas. Many of these algorithms\nare single station based, while recent proposed methods start to combine\nsurrounding stations into consideration in the problem of phase picking. Among\nthese algorithms, the Phase Neural Operator (PhaseNO) shows promising results\non regional datasets comparing to existing algorithms. But there are many use\ncases for the local seismic networks in our community, therefore in this paper\nwe evaluate the performance of PhaseNO on 4 different local datasets and\ncompared the results to PhaseNet and EQTransformer. We used both individual\nphase picking metrics as well as association metrics to illustrate the\nperformance of PhaseNO. With manually reviewing the newly detected events, we\nfind the PhaseNO model outperformed the single station-based approaches in the\nlocal-scale use cases due to its consideration of coherent signals from\nmultiple stations. We also explored PhaseNO's behaviors when only using one\nstation, as well as gradually increase the number of stations in the seismic\nnetwork to understand it better. Overall, using the off-the-shelf machine\nlearning based phase pickers, PhaseNO demonstrated its good performance on\nlocal-scale seismic networks."}
{"id": "2510.15351", "categories": ["math.NA", "cs.NA", "65Y20, 65N12, 49N15"], "pdf": "https://arxiv.org/pdf/2510.15351", "abs": "https://arxiv.org/abs/2510.15351", "authors": ["Long Chen", "Ruchi Guo", "Jingrong Wei", "Jun Zou"], "title": "A Novel Preconditioning Framework for Solving Nonlinear PDEs based on Fenchel-Rockafellar Duality and Transformed Primal-Dual Techniques", "comment": null, "summary": "A DualTPD method is proposed for solving nonlinear partial differential\nequations. The method is characterized by three main features. First,\ndecoupling via Fenchel--Rockafellar duality is achieved, so that nonlinear\nterms are discretized by discontinuous finite element spaces, yielding\nblock-diagonal mass matrices and closed-form updates. Second, improved\nconvergence is obtained by applying transformed primal--dual (TPD) dynamics to\nthe nonlinear saddle-point system, which yields strongly monotone behavior.\nThird, efficient preconditioners are designed for the elliptic-type Schur\ncomplement arising from the separated differential operators, and multigrid\nsolvers are applied effectively. Extensive numerical experiments on elliptic\n$p$-Laplacian and nonlinear $H(\\curl)$ problems are presented, showing\nsignificant efficiency gains with global, mesh-independent convergence."}
{"id": "2510.15163", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.15163", "abs": "https://arxiv.org/abs/2510.15163", "authors": ["Anna I. Tóth"], "title": "Three Types of Non-Fermi-Liquid Fixed Point for a Triplet Quantum Impurity in a Cubic Metal", "comment": "14 pages, 3 figures", "summary": "In cubic metals, a local, magnetic moment with a triplet ground state coupled\nto $\\Gamma_8$ conduction electrons can give rise to various non-Fermi liquid\n(NFL) quantum critical behaviors. To date, only those exchange couplings have\nbeen studied that are spherically symmetric already in the high-temperature,\nlocal moment regime. Namely, only the effects of potential scattering, spin\nexchange and quadrupolar exchange couplings were considered, and two types of\nNFL fixed points have been identified. However, in cubic symmetry, six\nindependent exchange couplings can be present in the Hamiltonian: in addition\nto the spherically symmetric potential scattering and spin exchange, there is a\nspherical symmetry breaking, dipolar exchange interaction, and three spherical\nsymmetry breaking, quadrupolar terms. While all of them flow to fixed points\nwhere rotational invariance is recovered, we found that one of the quadrupolar\ncouplings flows to a so far unidentified NFL fixed point. We derive the cubic\nsymmetry allowed exchanged couplings, solve them with the numerical\nrenormalization group, and present three types of NFL excitation, one of which\nis novel, at least in the context of a quantum impurity with a triplet ground\nstate."}
{"id": "2510.15124", "categories": ["cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.15124", "abs": "https://arxiv.org/abs/2510.15124", "authors": ["Alexandros Vasilopoulos", "Michail Akritidis", "Nikolaos G. Fytas", "Martin Weigel"], "title": "Cluster percolation and dynamical scaling in the Baxter--Wu model", "comment": "10 pages, 7 figures, 1 table, REVTeX4.2", "summary": "We investigate the percolation behavior of Fortuin-Kasteleyn--type clusters\nin the spin-$1/2$ Baxter--Wu model with three-spin interactions on a triangular\nlattice. The considered clusters are constructed by randomly freezing one of\nthe three sublattices, resulting in effective pairwise interactions among the\nremaining spins. Using Monte Carlo simulations combined with a finite-size\nscaling analysis, we determine the percolation temperature of these stochastic\nclusters and show that it coincides with the exact thermal critical point of\nthe model. The critical exponents derived from cluster observables are\nconsistent with those of the underlying thermal phase transition. Finally, we\nanalyze the dynamical scaling of the multi-cluster and single-cluster\nalgorithms resulting from the cluster construction, highlighting their\nefficiency and scaling behavior with system size."}
{"id": "2510.15500", "categories": ["hep-lat", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.15500", "abs": "https://arxiv.org/abs/2510.15500", "authors": ["Johann Ostmeyer", "Carsten Urbach"], "title": "The Truncated Hankel Correlator Method", "comment": "17 + 3 pages, 13 figures, 3 algorithms", "summary": "We introduce a new method to approximate Euclidean correlation functions by\nexponential sums. The Truncated Hankel Correlator (THC) method builds a Hankel\nmatrix from the full correlator data available and truncates the eigenspectrum\nof said Hankel matrix. It proceeds by applying the Prony generalised eigenvalue\nmethod to the thus obtained low-rank approximation. A large number of algebraic\ncorrelator analysis methods including (block) Prony (and equivalently (block)\nLanczos) and the generalised eigenvalue problem (GEVP) can be reproduced as\nsub-optimal special cases of the THC method. Weights, for instance inverse\nsquare errors, can be included in the analysis, so that the result has a close\nto optimal $\\chi^2$-value. This makes the THC method very similar in spirit to\na closed form solution to multi-state fits, naturally including the case of\nmatrix-valued correlators. We show that, in general, finding approximations\nbetter than those provided by the THC method is exponentially hard in the\nnumber of exponentials. Moreover, the THC method is robust against noise and\nrequires comparably little human oversight. Finally, when applied to symmetric\ndata, the obtained energy spectrum is guaranteed to be symmetric up to machine\nprecision."}
{"id": "2510.15764", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2510.15764", "abs": "https://arxiv.org/abs/2510.15764", "authors": ["Victor Delapalme", "Leticia F. Cugliandolo", "Grégory Schehr", "Marco Tarzia", "Davide Venturelli"], "title": "The Wishart--Rosenzweig--Porter random matrix ensemble", "comment": "31+13 pages, 8 figures", "summary": "In recent years the Rosenzweig--Porter (RP) ensemble, obtained by adding a\ndiagonal matrix with independent and identically distributed elements to a\nGaussian random matrix, has been widely used as a minimal model for the\nemergence of fractal eigenstates in complex many-body systems. A key open\nquestion concerns the robustness of its phase diagram when the assumption of\nindependent and uncorrelated entries is relaxed -- an assumption that\nsimplifies its analysis, but is generally violated in realistic quantum\nsystems. In this work, we take a first step in this direction by considering a\ndeformed Wishart (rather than Gaussian) random matrix, which we dub the\n``Wishart--RP'' ensemble. Using perturbation theory, as well as the cavity and\nreplica methods and the Dyson Brownian motion approach, we characterize its\nphase diagram and localization properties. Remarkably, we show that the level\ncompressibility, which quantifies spectral correlations in the fractal phase,\ncoincides with that of the Gaussian RP model, thereby extending the\nuniversality conjectured in [SciPost Phys. 14, 110 (2023)] beyond the fully\nuncorrelated setting. We confirm our results with numerical tests."}
{"id": "2510.15071", "categories": ["eess.SY", "cs.SY", "math.DG"], "pdf": "https://arxiv.org/pdf/2510.15071", "abs": "https://arxiv.org/abs/2510.15071", "authors": ["Ahmed Ali", "Chiara Gabellieri", "Antonio Franchi"], "title": "Exploring a New Design Paradigm for Omnidirectional MAVs for Minimal Actuation and Internal Force Elimination: Theoretical Framework and Control", "comment": null, "summary": "This paper presents a novel concept for achieving omnidirectionality in a\nmultirotor aerial vehicle (MAV) that uses only 6 inputs and ensures no internal\nforces at the equilibria. The concept integrates a single actively-tilting\npropeller along with 3 pendulum-like links, each carrying a propeller,\nconnected by passive universal joints to the main body. We show that this\ndesign ensures omnidirectionality while minimizing the internal forces and\nwithout resorting to overactuation (i.e., more than 6 inputs). A detailed\ndynamic model of the multi-link MAV is first developed. Afterwards, the\nanalysis identifies the equilibrium configurations and illustrates that a\nforced equilibrium exists for every pose of the MAV's main platform. In order\nto render this equilibrium asymptotically stable for the closed-loop system, a\ngeometric nonlinear controller is constructed using dynamic feedback\nlinearization and backstepping techniques with the main platform configuration\nerror being the left-trivialized error on SE(3). The stability of the\nclosed-loop system is then investigated by employing standard Lyapunov\narguments on the zero dynamics. We conclude by providing numerical simulations\nvalidating the proposed approach. They demonstrate the MAV capability to\nperform decoupled attitude and translational motions under non-zero initial\nconditions, parametric uncertainty, and actuators noise."}
{"id": "2510.15205", "categories": ["cs.CE", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2510.15205", "abs": "https://arxiv.org/abs/2510.15205", "authors": ["Shaw Dalen"], "title": "Toward Black Scholes for Prediction Markets: A Unified Kernel and Market Maker's Handbook", "comment": null, "summary": "Prediction markets, such as Polymarket, aggregate dispersed information into\ntradable probabilities, but they still lack a unifying stochastic kernel\ncomparable to the one options gained from Black-Scholes. As these markets scale\nwith institutional participation, exchange integrations, and higher volumes\naround elections and macro prints, market makers face belief volatility, jump,\nand cross-event risks without standardized tools for quoting or hedging. We\npropose such a foundation: a logit jump-diffusion with risk-neutral drift that\ntreats the traded probability p_t as a Q-martingale and exposes belief\nvolatility, jump intensity, and dependence as quotable risk factors. On top, we\nbuild a calibration pipeline that filters microstructure noise, separates\ndiffusion from jumps using expectation-maximization, enforces the risk-neutral\ndrift, and yields a stable belief-volatility surface. We then define a coherent\nderivative layer (variance, correlation, corridor, and first-passage\ninstruments) analogous to volatility and correlation products in option\nmarkets. In controlled experiments on synthetic risk-neutral paths and real\nevent data, the model reduces short-horizon belief-variance forecast error\nrelative to diffusion-only and probability-space baselines, supporting both\ncausal calibration and economic interpretability. Conceptually, the logit\njump-diffusion kernel supplies an implied-volatility analogue for prediction\nmarkets: a tractable, tradable language for quoting, hedging, and transferring\nbelief risk across venues such as Polymarket."}
{"id": "2510.15003", "categories": ["stat.ME", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.15003", "abs": "https://arxiv.org/abs/2510.15003", "authors": ["Mingao Yuan"], "title": "Asymptotic distribution of the global clustering coefficient in a random annulus graph", "comment": null, "summary": "The global clustering coefficient is an effective measure for analyzing and\ncomparing the structures of complex networks. The random annulus graph is a\nmodified version of the well-known Erd\\H{o}s-R\\'{e}nyi random graph. It has\nbeen recently proposed in modeling network communities. This paper investigates\nthe asymptotic distribution of the global clustering coefficient in a random\nannulus graph. It is demonstrated that the standardized global clustering\ncoefficient converges in law to the standard normal distribution. The result is\nestablished using the asymptotic theory of degenerate U-statistics with a\nsample-size dependent kernel. As far as we know, this method is different from\nestablished approaches for deriving asymptotic distributions of network\nstatistics. Moreover, we get the explicit expression of the limit of the global\nclustering coefficient."}
{"id": "2510.15071", "categories": ["eess.SY", "cs.SY", "math.DG"], "pdf": "https://arxiv.org/pdf/2510.15071", "abs": "https://arxiv.org/abs/2510.15071", "authors": ["Ahmed Ali", "Chiara Gabellieri", "Antonio Franchi"], "title": "Exploring a New Design Paradigm for Omnidirectional MAVs for Minimal Actuation and Internal Force Elimination: Theoretical Framework and Control", "comment": null, "summary": "This paper presents a novel concept for achieving omnidirectionality in a\nmultirotor aerial vehicle (MAV) that uses only 6 inputs and ensures no internal\nforces at the equilibria. The concept integrates a single actively-tilting\npropeller along with 3 pendulum-like links, each carrying a propeller,\nconnected by passive universal joints to the main body. We show that this\ndesign ensures omnidirectionality while minimizing the internal forces and\nwithout resorting to overactuation (i.e., more than 6 inputs). A detailed\ndynamic model of the multi-link MAV is first developed. Afterwards, the\nanalysis identifies the equilibrium configurations and illustrates that a\nforced equilibrium exists for every pose of the MAV's main platform. In order\nto render this equilibrium asymptotically stable for the closed-loop system, a\ngeometric nonlinear controller is constructed using dynamic feedback\nlinearization and backstepping techniques with the main platform configuration\nerror being the left-trivialized error on SE(3). The stability of the\nclosed-loop system is then investigated by employing standard Lyapunov\narguments on the zero dynamics. We conclude by providing numerical simulations\nvalidating the proposed approach. They demonstrate the MAV capability to\nperform decoupled attitude and translational motions under non-zero initial\nconditions, parametric uncertainty, and actuators noise."}
{"id": "2510.15205", "categories": ["cs.CE", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2510.15205", "abs": "https://arxiv.org/abs/2510.15205", "authors": ["Shaw Dalen"], "title": "Toward Black Scholes for Prediction Markets: A Unified Kernel and Market Maker's Handbook", "comment": null, "summary": "Prediction markets, such as Polymarket, aggregate dispersed information into\ntradable probabilities, but they still lack a unifying stochastic kernel\ncomparable to the one options gained from Black-Scholes. As these markets scale\nwith institutional participation, exchange integrations, and higher volumes\naround elections and macro prints, market makers face belief volatility, jump,\nand cross-event risks without standardized tools for quoting or hedging. We\npropose such a foundation: a logit jump-diffusion with risk-neutral drift that\ntreats the traded probability p_t as a Q-martingale and exposes belief\nvolatility, jump intensity, and dependence as quotable risk factors. On top, we\nbuild a calibration pipeline that filters microstructure noise, separates\ndiffusion from jumps using expectation-maximization, enforces the risk-neutral\ndrift, and yields a stable belief-volatility surface. We then define a coherent\nderivative layer (variance, correlation, corridor, and first-passage\ninstruments) analogous to volatility and correlation products in option\nmarkets. In controlled experiments on synthetic risk-neutral paths and real\nevent data, the model reduces short-horizon belief-variance forecast error\nrelative to diffusion-only and probability-space baselines, supporting both\ncausal calibration and economic interpretability. Conceptually, the logit\njump-diffusion kernel supplies an implied-volatility analogue for prediction\nmarkets: a tractable, tradable language for quoting, hedging, and transferring\nbelief risk across venues such as Polymarket."}
{"id": "2510.15003", "categories": ["stat.ME", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.15003", "abs": "https://arxiv.org/abs/2510.15003", "authors": ["Mingao Yuan"], "title": "Asymptotic distribution of the global clustering coefficient in a random annulus graph", "comment": null, "summary": "The global clustering coefficient is an effective measure for analyzing and\ncomparing the structures of complex networks. The random annulus graph is a\nmodified version of the well-known Erd\\H{o}s-R\\'{e}nyi random graph. It has\nbeen recently proposed in modeling network communities. This paper investigates\nthe asymptotic distribution of the global clustering coefficient in a random\nannulus graph. It is demonstrated that the standardized global clustering\ncoefficient converges in law to the standard normal distribution. The result is\nestablished using the asymptotic theory of degenerate U-statistics with a\nsample-size dependent kernel. As far as we know, this method is different from\nestablished approaches for deriving asymptotic distributions of network\nstatistics. Moreover, we get the explicit expression of the limit of the global\nclustering coefficient."}
{"id": "2510.15197", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.15197", "abs": "https://arxiv.org/abs/2510.15197", "authors": ["Novel Kumar Dey", "Yan Wu"], "title": "Decentralized Disturbance Rejection Control of Triangularly Coupled Loop Thermosyphon System", "comment": null, "summary": "In this paper, we investigate the stability of a triangularly coupled triple\nloop thermosyphon system with momentum and heat exchange at the coupling point\nas well as the existence of disturbances. The controller consists of a single,\nlocal state feedback. From the stability analysis, we obtain explicit bounds on\nthe feedback gains, which depend on the Rayleigh numbers and the momentum\ncoupling parameter, but independent of the thermal coupling parameter. The\nexistence of the stability bounds allows us to design decentralized adaptive\ncontrollers to automatically search for the feasible gains when the system\nparameters are unknown. In the case of existing disturbances in the system, we\napproximate the disturbances via an extended state observer for the purpose of\ndisturbance rejection. Numerical results are given to demonstrate the\nperformance of the proposed decentralized disturbance rejection controller\ndesign."}
{"id": "2510.15293", "categories": ["physics.comp-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.15293", "abs": "https://arxiv.org/abs/2510.15293", "authors": ["Zhexian Li", "Felipe de Barros", "Ketan Savla"], "title": "Constrained bilinear optimal control of reactive evolution equations", "comment": "38 pages, 7 figures", "summary": "We consider constrained bilinear optimal control of second-order linear\nevolution partial differential equations (PDEs) with a reaction term on the\nhalf line, where control arises as a time-dependent reaction coefficient and\nconstraints are imposed on the state and control variables. These PDEs\nrepresent a wide range of physical phenomena in fluid flow, heat, and mass\ntransfer. Existing computational methods for this type of control problems only\nconsider constraints on control variables. In this paper, we propose a novel\noptimize-then-discretize framework for computing constrained bilinear optimal\ncontrol with both state and control constraints. Unlike existing methods that\nderive optimality conditions directly from the PDE constraint, this framework\nfirst replaces the PDE constraint with an equivalent integral representation of\nthe PDE solution. The integral representation, derived from the unified\ntransform method, does not involve differential operators, and thus explicit\nexpressions for necessary conditions of optimality can be derived using the\nKarush-Kuhn-Tucker conditions for infinite-dimensional optimization.\nDiscretizing the optimality conditions results in a system of\nfinite-dimensional smooth nonlinear equations, which can be efficiently solved\nusing existing solvers without the need for specialized algorithms. This is in\ncontrast with discretize-then-optimize methods that discretize the PDE first\nand then solve the optimality conditions of the approximated finite-dimensional\nproblem. Computational results for two applications, namely nuclear reactivity\ncontrol and water quality treatment in a reactor, are presented to illustrate\nthe effectiveness of the proposed framework."}
{"id": "2510.15443", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.15443", "abs": "https://arxiv.org/abs/2510.15443", "authors": ["Changda Zheng", "Renshu Yang", "Chenxi Ding", "Songlin He", "Bo Wang", "Yongzhong Yuan"], "title": "Experimental and numerical study on the influence of extra-depth on cut blasting post-blast damage", "comment": null, "summary": "Cutting is a key factor affecting the speed of blasting excavation. With the\ncontinuous advancement of deep-hole blasting technology, determining the\noptimal extra-depth of the cut relative to the non-cut blast hole is of\nparamount importance. By combining model experiments and numerical simulations,\nthis study systematically investigates the effect of extra-depth on post-blast\ndamage morphology, damage width, depth, area, and fractal damage. Furthermore,\nnumerical simulations were employed to validate the experimental results from\nthe perspectives of damage evolution and peak pressure at monitoring points.\nThe main findings are as follows: The extra-depth of the cut has a significant\nnonlinear effect on the blasting outcome. As the extra-depth increases,\nblasting damage initially increases but decreases beyond a critical depth due\nto marginal effects, leading to the appearance of residual blast hole features.\nUnder experimental conditions, when the extra-depth was 15 mm, the damage\ndepth, width, and area reached their maximum values of 43.5 mm, 109.9 mm, and\n6055.2 mm, respectively, indicating optimal blasting performance. The fractal\ndamage of the specimen also exhibited a significant trend of initially\nincreasing and then decreasing. The maximum fractal damage, obtained by\nderiving the fitting curve, was 0.75, corresponding to an extra-depth of 13.7\nmm. The numerical simulation results are in good agreement with the\nexperimental findings, showing a significant downward shift in the peak\npressure points in the damage zone with increasing extra-depth. In summary, an\nappropriate extra-depth can achieve optimal borehole utilization, while an\nexcessive extra-depth can lead to residual blast hole formation at the bottom\nof the cut, reducing effectiveness. This study provides theoretical guidance\nfor optimizing the design parameters of extra-depth in deep-hole blasting."}
{"id": "2510.15474", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.15474", "abs": "https://arxiv.org/abs/2510.15474", "authors": ["Ruoke Meng", "Geert Smet", "Dieter Van den Bleeken", "Aaron Van Poecke", "Hossein Tabari", "Peter Hellinckx", "Piet Termonia", "Joris Van den Bergh"], "title": "Evaluating the Prediction of Wind Power Ramping Events in the Belgian Offshore Zone", "comment": "22 pages, 14 figures, submit to Journal of Meteorological\n  Applications", "summary": "Evaluations are presented for the prediction of wind power ramping events in\nthe Belgian Offshore Zone. Two models from the Royal Meteorological Institute\nof Belgium are verified: the operational ALARO-4km and its version with Wind\nFarm Parameterization (WFP). Power predictions are produced using power curves\nand machine learning (ML). As standard metrics such as MAE are insufficient for\nevaluating ramps, the proposed framework incorporates time and power buffers,\nenabling a flexible assessment that tolerates minor errors. Results indicate\nthat WFP models enhance ramping prediction skill, while ML provides more\nbalanced forecasts by reducing both misses and false alarms. A Ramp Alignment\nScore is also introduced to quantify temporal errors by forecast lead time,\nconfirming that WFP models yield smaller average timing errors. Moreover, the\nframework reveals that severe precipitation is a strong indicator of large,\npredictable ramps, whereas lighter precipitation is associated with greater\nforecast errors."}
{"id": "2510.15656", "categories": ["nlin.AO", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.15656", "abs": "https://arxiv.org/abs/2510.15656", "authors": ["Frank Schweitzer", "Georges Andres", "Adrien Baut", "Giona Casiraghi", "Christoph Gote", "Ramona Roller"], "title": "Active matter synchronization and synergetics", "comment": null, "summary": "We study the collective behavior in a stochastic agent-based model of active\nmatter. Provided a critical take-up of energy, agents produce two types of\ngoods $x$, $y$ that follow a generalized Lotka-Volterra dynamics. For isolated\nagents, production would either reach a fixed point or diverge. Coupling\nagents' production via a mean field of $x$, however, can lead to synchronized\noscillations if agents cooperate in the production of $x$. The production of\n$y$ supports the emergence of the synchronized dynamics by suppressing\nfluctuations and mitigating competition between agents, this way stabilizing\nthe production of $x$. We find that in the synchronized state different groups\nof agents coexist, each following their own limit cycle. The Kuramoto order\nparameter is large within groups, and small across groups. The collective state\nis stable against shocks from agents temporarily switching between cooperation\nand competition. The model dynamics illustrates the principles of synergetics,\ni.e., the spontaneous emergence of order given a critical energy supply and\ncooperative interactions."}
{"id": "2510.15475", "categories": ["math.NA", "cs.NA", "65L04, 65L06, 65L20"], "pdf": "https://arxiv.org/pdf/2510.15475", "abs": "https://arxiv.org/abs/2510.15475", "authors": ["Mathieu Benninghoff", "Gilles Vilmart"], "title": "Second order explicit stabilized multirate method for stiff differential equations with error control", "comment": null, "summary": "Explicit stabilized methods are highly efficient time integrators for large\nand stiff systems of ordinary differential equations especially when applied to\nsemi-discrete parabolic problems. However, when local spatial mesh refinement\nis introduced, their efficiency decreases, since the stiffness is driven by\nonly the smallest mesh element. A natural approach is to split the system into\nfast stiff and slower mildly stiff components. In this context, [A. Abdulle,\nM.J. Grote and G. Rosilho de Souza 2022] proposed the order one multirate\nexplicit stabilized method (mRKC). We extend their approach to second order and\nintroduce the new multirate ROCK2 method (mROCK2), which achieves high\nprecision and allows a step-size strategy with error control. Numerical methods\nincluding the heat equation with local spatial mesh refinements confirm the\naccuracy and efficiency of the scheme."}
{"id": "2510.15224", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.15224", "abs": "https://arxiv.org/abs/2510.15224", "authors": ["E. S. Ma", "Z. Song"], "title": "Dynamic destruction of magnetic order in a quantum Ising chain with oscillating transverse field", "comment": null, "summary": "We study the dynamic response of magnetic domain walls in low-lying excited\nstates of an Ising chain to an oscillating transverse field. Based on the exact\ninstantaneous eigenstates, we find that when the frequency of the external\nfield is in off-resonant regions, the domain wall exhibits Bloch oscillation,\nmaintaining the magnetic order. However, the magnetic order is destroyed when\nthe field is at resonant frequency. Numerical simulations of the dynamics of\nmagnetization and entanglement entropy for initial states with single and\ndouble domain walls accord with the predictions. These findings reveal the\nnontrivial effect of a monochromatic electromagnetic field on quantum spin\ndynamics."}
{"id": "2510.15228", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.15228", "abs": "https://arxiv.org/abs/2510.15228", "authors": ["Andreas Dechant"], "title": "Finite-frequency fluctuation-response inequality", "comment": "21 pages, 4 figures", "summary": "We derive an inequality relating the finite-frequency linear response and\nfluctuations of an observable in a physical system. The relation holds for\narbitrary observables and perturbations in general Markovian dynamics,\nincluding over- and underdamped Langevin systems and jump processes, both in\nand out of equilibrium. As a consequence, we obtain a universal upper bound on\nthe broad-band signal-to-noise ratio of noisy dynamics, which only depends on\nthe damping constant and temperature. We further show that the inequality\nreduces to an equality for appropriately chosen observables or perturbations in\nlinear systems, both overdamped and underdamped and both in and out of\nequilibrium."}
{"id": "2510.15150", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.15150", "abs": "https://arxiv.org/abs/2510.15150", "authors": ["Tina Gao", "Shimiao Li", "Lawrence Pileggi"], "title": "Sparsity-exploiting Gaussian Process for Robust Transient Learning of Power System Dynamics", "comment": "This manuscript has been submitted to PESGM2026", "summary": "Advances in leveraging Gaussian processes (GP) have enabled learning and\ninferring dynamic grid behavior from scarce PMU measurements. However, real\nmeasurements can be corrupted by various random and targeted threats, leading\nto inaccurate and meaningless results. This paper develops robust transient\nlearning to overcome this challenge by exploiting the sparse corruption\npatterns in the data flow. Specifically, we integrate sparse optimization with\nmethod of moments (MoM) to make learning robust to a sparse distribution of\ndata corruptions; then, we optimize sparse weights to identify corrupted meter\nlocations. To improve inference speed on large-scale systems, we further adopt\nK-medoid clustering of locations to develop dimension reduction (DR) and\naggregate representation (AR) heuristics. Experimental results demonstrate\nrobustness against random large errors, targeted false data injections, and\nlocal PMU clock drifts. On a 1354-bus system, inference turns out to be 18x\nfaster using DR and 400x faster when further combined with AR heuristics."}
{"id": "2510.15612", "categories": ["cs.CE", "cs.CR", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2510.15612", "abs": "https://arxiv.org/abs/2510.15612", "authors": ["Nahid Rahman", "Joseph Al-Chami", "Jeremy Clark"], "title": "SoK: Market Microstructure for Decentralized Prediction Markets (DePMs)", "comment": null, "summary": "Decentralized prediction markets (DePMs) allow open participation in\nevent-based wagering without fully relying on centralized intermediaries. We\nreview the history of DePMs which date back to 2011 and includes hundreds of\nproposals. Perhaps surprising, modern DePMs like Polymarket deviate materially\nfrom earlier designs like Truthcoin and Augur v1. We use our review to present\na modular workflow comprising seven stages: underlying infrastructure, market\ntopic, share structure and pricing, trading, market resolution, settlement, and\narchiving. For each module, we enumerate the design variants, analyzing\ntrade-offs around decentralization, expressiveness, and manipulation\nresistance. We also identify open problems for researchers interested in this\necosystem."}
{"id": "2510.15203", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.15203", "abs": "https://arxiv.org/abs/2510.15203", "authors": ["Mauricio Tejo", "Cristian Meza", "Fernando Marmolejo-Ramos"], "title": "Conditional GLMMs for reaction times in choice tasks", "comment": null, "summary": "This study connects two methods for modeling reaction times (RTs) in choice\ntasks: (1) the first-hitting time of a simple diffusion model with a single\nbarrier, representing the cognitive process leading to a response, and (2)\nGeneralized Linear Mixed Models (GLMMs). We achieve this by analyzing RT\ndistributions conditioned on each response alternative. Because certain\ndiffusion model variants yield Inverse Gaussian (IG) and Gamma distributions\nfor first-hitting times, we can justify using these distributions in RT models.\nConversely, employing IG and Gamma distributions within GLMMs allows us to\ninfer the underlying cognitive processes. We demonstrate this concept through\nsimulations and apply it to previously published real-world data. Finally, we\ndiscuss the scope and potential extensions of our approach."}
{"id": "2510.15150", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.15150", "abs": "https://arxiv.org/abs/2510.15150", "authors": ["Tina Gao", "Shimiao Li", "Lawrence Pileggi"], "title": "Sparsity-exploiting Gaussian Process for Robust Transient Learning of Power System Dynamics", "comment": "This manuscript has been submitted to PESGM2026", "summary": "Advances in leveraging Gaussian processes (GP) have enabled learning and\ninferring dynamic grid behavior from scarce PMU measurements. However, real\nmeasurements can be corrupted by various random and targeted threats, leading\nto inaccurate and meaningless results. This paper develops robust transient\nlearning to overcome this challenge by exploiting the sparse corruption\npatterns in the data flow. Specifically, we integrate sparse optimization with\nmethod of moments (MoM) to make learning robust to a sparse distribution of\ndata corruptions; then, we optimize sparse weights to identify corrupted meter\nlocations. To improve inference speed on large-scale systems, we further adopt\nK-medoid clustering of locations to develop dimension reduction (DR) and\naggregate representation (AR) heuristics. Experimental results demonstrate\nrobustness against random large errors, targeted false data injections, and\nlocal PMU clock drifts. On a 1354-bus system, inference turns out to be 18x\nfaster using DR and 400x faster when further combined with AR heuristics."}
{"id": "2510.15632", "categories": ["stat.ME", "math.ST", "stat.AP", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.15632", "abs": "https://arxiv.org/abs/2510.15632", "authors": ["Max Welz"], "title": "Robust Estimation of Polyserial Correlation", "comment": "64 pages (30 main text), 16 figures and 5 tables in total", "summary": "The association between a continuous and an ordinal variable is commonly\nmodeled through the polyserial correlation model. However, this model, which is\nbased on a partially-latent normality assumption, may be misspecified in\npractice, due to, for example (but not limited to), outliers or careless\nresponses. We demonstrate that the typically used maximum likelihood (ML)\nestimator is highly susceptible to such misspecification: One single\nobservation not generated by partially-latent normality can suffice to produce\narbitrarily poor estimates. As a remedy, we propose a novel estimator of the\npolyserial correlation model designed to be robust against the adverse effects\nof observations discrepant to that model. The estimator achieves robustness by\nimplicitly downweighting such observations; the ensuing weights constitute a\nuseful tool for pinpointing potential sources of model misspecification. We\nshow that the proposed estimator generalizes ML and is consistent as well as\nasymptotically Gaussian. As price for robustness, some efficiency must be\nsacrificed, but substantial robustness can be gained while maintaining more\nthan 98% of ML efficiency. We demonstrate our estimator's robustness and\npractical usefulness in simulation experiments and an empirical application in\npersonality psychology where our estimator helps identify outliers. Finally,\nthe proposed methodology is implemented in free open-source software."}
{"id": "2510.15251", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15251", "abs": "https://arxiv.org/abs/2510.15251", "authors": ["Yingrui Zhuang", "Lin Cheng", "Ning Qi", "Mads R. Almassalkhi", "Feng Liu"], "title": "An Iterative Problem-Driven Scenario Reduction Framework for Stochastic Optimization with Conditional Value-at-Risk", "comment": null, "summary": "Scenario reduction (SR) alleviates the computational complexity of\nscenario-based stochastic optimization with conditional value-at-risk\n(SBSO-CVaR) by identifying representative scenarios to depict the underlying\nuncertainty and tail risks. Existing distribution-driven SR methods emphasize\nstatistical similarity but often exclude extreme scenarios, leading to weak\ntail-risk awareness and insufficient problem-specific representativeness.\nInstead, this paper proposes an iterative problem-driven scenario reduction\nframework. Specifically, we integrate the SBSO-CVaR problem structure into SR\nprocess and project the original scenario set from the distribution space onto\nthe problem space. Subsequently, to minimize the SR optimality gap with\nacceptable computation complexity, we propose a tractable iterative\nproblem-driven scenario reduction (IPDSR) method that selects representative\nscenarios that best approximate the optimality distribution of the original\nscenario set while preserving tail risks. Furthermore, the iteration process is\nrendered as a mixed-integer program to enable scenario partitioning and\nrepresentative scenarios selection. And ex-post problem-driven evaluation\nindices are proposed to evaluate the SR performance. Numerical experiments show\nIPDSR significantly outperforms existing SR methods by achieving an optimality\ngap of less than 1% within an acceptable computation time."}
{"id": "2510.15424", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.15424", "abs": "https://arxiv.org/abs/2510.15424", "authors": ["Amir Mohammad Mirzaei"], "title": "Towards In-Situ Failure Assessment: Deep Learning on DIC Results for Laminated Composites", "comment": null, "summary": "Predicting fracture load in laminated composites with stress raisers is\nchallenging due to complex failure mechanisms such as delamination, fibre\nbreakage, and matrix cracking, which are heavily influenced by fibre\norientation, layup sequence, and notch geometry. This study aims to address\nthis by developing a novel deep learning framework that leverages solely\nexperimental strain field data from Digital Image Correlation (DIC) for\naccurate, in-situ predictions--bypassing the need for finite element\nsimulations or empirical calibrations. Two complementary architectures are\nexplored: a multi-layer perceptron (MLP) that processes numerical values of\nmaximum principal strain from a targeted rectangular region ahead of the notch,\nenhanced by advanced feature selection (mutual information, Lasso, and SHAP) to\nfocus on critical data points; and a convolutional neural network (CNN) trained\non full-field strain images, bolstered by data augmentation to handle\nvariability and prevent overfitting. Validated across 116 quasi-static tests\nencompassing 31 distinct configurations--including six layups (quasi-isotropic\nto highly anisotropic) with four off-axis angles for open-hole specimens, and\none cross-ply layup with four off-axis and four on-axis notch orientations for\nU-notched specimens--the MLP and CNN achieve coefficients of determination\n(R^2) of 0.86 and 0.82, respectively. This framework captures a broad spectrum\nof damage modes and responses, from brittle fibre-dominated fracture to ductile\ndelamination-driven failure, and due to its computational efficiency and\nreliance only on DIC measurements, the approach enables practical in-situ\nfracture load estimation."}
{"id": "2510.15779", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.15779", "abs": "https://arxiv.org/abs/2510.15779", "authors": ["P. Shahsavari", "J. Dettmer", "M. J. Unsworth", "A. Schaeffer"], "title": "Multiphysics inversion with variable complexity of receiver-function, surface-wave dispersion and magnetotelluric data reduces uncertainty for lithosphere structure", "comment": null, "summary": "We present a probabilistic multiphysics inversion based on Bayesian inference\nwith trans-dimensional models. We jointly consider magnetotelluric, receiver\nfunction, and Rayleigh-wave dispersion data to infer one-dimensional\nlithospheric structure in the vicinity of Athabasca, Canada. The location is on\nthe North American Craton with a cover of sediments from the Western Canada\nSedimentary Basin. The trans-dimensional model uses layer nodes that include\nparameters that are activated or deactivated based on data information.\nFurthermore, the number of nodes is based on data information. Hence, the\nparameterization uncertainty is included in the uncertainty estimates.\nFurthermore, the layer nodes permit trans-dimensional decoupling such that some\ndiscontinuities may be represented by only some of the parameters. In\nprobabilistic multiphysics inversion, it is important that the various data\ntypes are weighed objectively. Here, the weights are the data covariance\nmatrices of the various data types. We apply empirical estimation of data\ncovariance matrices and employ hierarchical scaling parameters to reduce the\ndependence on some assumptions required by the empirical approach. Hence, we\naccount for noise variances and covariances, which is crucial for successful\nprobabilistic multiphysics inversion. The parameter estimates and data\ncovariance matrices are obtained with the reversible-jump Markov chain Monte\nCarlo algorithm with parallel tempering to enhance the efficiency. Since\ncovariance matrix estimation changes data weights, the estimation process is\ncarried out while samples are not recorded for inference. The results at the\nAthabasca site fit the data and produce plausible data covariance matrices for\nthe data weights."}
{"id": "2510.15707", "categories": ["eess.SY", "cs.SY", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.15707", "abs": "https://arxiv.org/abs/2510.15707", "authors": ["Martín de Frutos", "Laura Botero-Bolívar", "Esteban Ferrer"], "title": "Mitigating Underwater Noise from Offshore Wind Turbines via Individual Pitch Control", "comment": null, "summary": "This paper proposes a pitch control strategy to mitigate the underwater\nacoustic footprint of offshore wind turbines, a measure that will soon become\nnecessary to minimize impacts on marine life, which rely on sound for\ncommunication, navigation, and survival. First, we quantify the underwater\nacoustic signature of blade-generated aerodynamic noise from three reference\nturbines, the NREL 5 MW, DTU 10 MW, and IEA 22 MW, using coupling blade element\nmomentum and coupled air-water acoustic propagation modeling. Second, we\npropose and implement an open-loop individual pitch control (IPC) strategy that\nmodulates the pitch of the blade at the blade passing frequency to attenuate\nthe overall sound pressure level (OSPL) and the amplitude modulation (AM) of\nthe transmitted noise. Third, we benchmark IPC performance against conventional\npitch schemes. The results indicate that up to 5 dB reductions in OSPL and a\ndecrease in AM depth 20% can be achieved with a pitch variation of\n$\\Delta\\theta\\approx 5^\\circ$, with small losses (5-10%) in energy capture.\nThese findings highlight a previously underappreciated noise pathway and\ndemonstrate that targeted blade-pitch modulation can mitigate its impact."}
{"id": "2510.15053", "categories": ["physics.soc-ph", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2510.15053", "abs": "https://arxiv.org/abs/2510.15053", "authors": ["Guido Caldarelli", "Oriol Artime", "Giulia Fischetti", "Stefano Guarino", "Andrzej Nowak", "Fabio Saracco", "Petter Holme", "Manlio de Domenico"], "title": "The Physics of News, Rumors, and Opinions", "comment": "67 pages, 9 figures", "summary": "The boundaries between physical and social networks have narrowed with the\nadvent of the Internet and its pervasive platforms. This has given rise to a\ncomplex adaptive information ecosystem where individuals and machines compete\nfor attention, leading to emergent collective phenomena. The flow of\ninformation in this ecosystem is often non-trivial and involves complex user\nstrategies from the forging or strategic amplification of manipulative content\nto large-scale coordinated behavior that trigger misinformation cascades,\necho-chamber reinforcement, and opinion polarization. We argue that statistical\nphysics provides a suitable and necessary framework for analyzing the unfolding\nof these complex dynamics on socio-technological systems. This review\nsystematically covers the foundational and applied aspects of this framework.\nThe review is structured to first establish the theoretical foundation for\nanalyzing these complex systems, examining both structural models of complex\nnetworks and physical models of social dynamics (e.g., epidemic and spin\nmodels). We then ground these concepts by describing the modern media ecosystem\nwhere these dynamics currently unfold, including a comparative analysis of\nplatforms and the challenge of information disorders. The central sections\nproceed to apply this framework to two central phenomena: first, by analyzing\nthe collective dynamics of information spreading, with a dedicated focus on the\nmodels, the main empirical insights, and the unique traits characterizing\nmisinformation; and second, by reviewing current models of opinion dynamics,\nspanning discrete, continuous, and coevolutionary approaches. In summary, we\nreview both empirical findings based on massive data analytics and theoretical\nadvances, highlighting the valuable insights obtained from physics-based\nefforts to investigate these phenomena of high societal impact."}
{"id": "2510.15481", "categories": ["math.NA", "cs.NA", "65J10, 65M15"], "pdf": "https://arxiv.org/pdf/2510.15481", "abs": "https://arxiv.org/abs/2510.15481", "authors": ["Carlos Arranz-Simón", "Begoña Cano", "César Palencia"], "title": "Rational methods for abstract linear initial boundary value problems without order reduction", "comment": "21 pages, 2 figures", "summary": "Given an $A$-stable rational approximation to $e^z$ of order $p$, numerical\nprocedures are suggested to time integrate abstract, well-posed IBVPs, with\ntime-dependent source term $f$ and boundary value $g$. These procedures exhibit\nthe optimal order $p$ and can be implemented by using just one single\nevaluation of $f$ and $g$ per step, i.e., no evaluations of the derivatives of\ndata are needed, and are of practical use at least for $p\\le 6$. The full\ndiscretization is also studied and the theoretical results are corroborated by\nnumerical experiments."}
{"id": "2510.15322", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2510.15322", "abs": "https://arxiv.org/abs/2510.15322", "authors": ["Makoto Shimizu", "Youichi Yanase"], "title": "Magnetic fluctuations and anisotropy in UTe2: a multi-orbital study based on GGA+U and RPA", "comment": null, "summary": "Pressure-induced changes in the magnetic and superconducting properties of a\nspin-triplet superconductor candidate UTe2 have attracted considerable\ninterest, underscoring the need for microscopic theoretical insight. In this\npaper, we investigate magnetic fluctuations and their anisotropy at ambient\npressure and under pressure using density functional theory (DFT) combined with\nthe random phase approximation (RPA). For each pressure, we perform DFT+U\ncalculations for several values of the Coulomb interaction U, construct a\n72-orbital periodic Anderson model, and calculate magnetic susceptibilities\nwith use of the RPA. For U = 2 eV, the Fermi surfaces have a\nquasi-two-dimensional shape, antiferromagnetic fluctuations develop with the\nwave vector along the a* axis, and the magnetic anisotropy follows $\\chi^b >\n\\chi^a > \\chi^c$. The antiferromagnetic fluctuations are suppressed under\npressure because of a reduced density of states at the Fermi level, while the\nmagnetic anisotropy is weakened. In contrast, for U = 1 eV, where Fermi\nsurfaces are more three-dimensional, antiferromagnetic fluctuations with Q2 =\n0.22 b* appear, accompanied by anisotropy $\\chi^a > \\chi^c > \\chi^b$,\nconsistent with experiments. Under pressure, antiferromagnetic fluctuations\naround Q2 are enhanced, the magnetic wave vector tilts slightly toward the a*\ndirection due to Fermi-surface distortion, and the magnetic anisotropy is\nsuppressed. These results demonstrate that the pressure evolution of magnetism\nin UTe2 is governed by the momentum-space distribution of U-5f states and the\ndensity of states at the Fermi level, providing a microscopic basis for\nunderstanding the magnetic and superconducting properties of UTe2."}
{"id": "2510.15410", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.15410", "abs": "https://arxiv.org/abs/2510.15410", "authors": ["Federico Corberi", "Eugenio Lippiello", "Paolo Politi", "Luca Smaldone"], "title": "Coarsening kinetics in spin systems with long-range interactions: from voter to Ising", "comment": "24 pages, 9 figures", "summary": "In this paper, we start reviewing the main features of the one-dimensional\nIsing model with long-range interactions, where the spin-spin coupling decays\nas a power law, $J(r) \\propto r^{-\\alpha}$. We then discuss the key properties\nof the one-dimensional voter model, in which two agents (spins) at distance $r$\ninteract with a power-law probability with the same form of $J(r)$. The two\nmodels are compared, and the so-called $p$-voter model is presented, which\nprovides a framework to interpolate between them. Specifically, the $p$-voter\nmodel reduces to the voter model for $p = 1$ and $p = 2$, while for $p \\ge 3$\nit falls into the universality class of the Ising model."}
{"id": "2510.15152", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15152", "abs": "https://arxiv.org/abs/2510.15152", "authors": ["Wenxin Zhang", "Yueying Li", "Ciamac C. Moallemi", "Tianyi Peng"], "title": "Tail-Optimized Caching for LLM Inference", "comment": null, "summary": "Prompt caching is critical for reducing latency and cost in LLM inference:\nOpenAI and Anthropic report up to 50-90% cost savings through prompt reuse.\nDespite its widespread success, little is known about what constitutes an\noptimal prompt caching policy, particularly when optimizing tail latency, a\nmetric of central importance to practitioners. The widely used Least Recently\nUsed (LRU) policy can perform arbitrarily poor on this metric, as it is\noblivious to the heterogeneity of conversation lengths. To address this gap, we\npropose Tail-Optimized LRU, a simple two-line modification that reallocates KV\ncache capacity to prioritize high-latency conversations by evicting cache\nentries that are unlikely to affect future turns. Though the implementation is\nsimple, we prove its optimality under a natural stochastic model of\nconversation dynamics, providing the first theoretical justification for LRU in\nthis setting, a result that may be of independent interest to the caching\ncommunity. Experimentally, on real conversation data WildChat, Tail-Optimized\nLRU achieves up to 27.5% reduction in P90 tail Time to First Token latency and\n23.9% in P95 tail latency compared to LRU, along with up to 38.9% decrease in\nSLO violations of 200ms. We believe this provides a practical and theoretically\ngrounded option for practitioners seeking to optimize tail latency in\nreal-world LLM deployments."}
{"id": "2510.15272", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.15272", "abs": "https://arxiv.org/abs/2510.15272", "authors": ["Atsushi Senda", "Yuki Takatsu", "Ryokan Ikebe", "Hiroshi Suginaka", "Koji Morishita", "Akira Endo"], "title": "Bayesian Sequential Modeling of Time-to-Urination for Dynamic ED Triage", "comment": null, "summary": "Triage tools in routine emergency care are largely static, failing to exploit\nsimple behavioral cues clinicians notice in real time. Here, we developed a\nBayesian, sequentially updating framework that integrates incoming cues to\nproduce calibrated, time-consistent risk. Using a prospective single-center\ncohort of ambulance arrivals in Japan (February-August 2025; n=2,221), we\nevaluated time to first urination (TTU) as a proof-of-concept bedside cue for\npredicting hospital admission. Population-level fit to the cumulative admission\ncurve was excellent (integrated squared error 0.002; RMSE 0.003;\nKolmogorov-Smirnov 0.008; coverage 0.98). At the patient level, performance\nimproved markedly with age/sex adjustment (AUC[t] 0.70 vs. 0.50 unadjusted),\nwith lower Brier scores and positive calibration slopes. Platt recalibration\nrefined probability scaling without altering discrimination, and decision-curve\nanalysis showed small, favorable net benefit at common thresholds. This\nframework is readily extensible to multimodal inputs and external validation\nand is designed to complement, not replace, existing triage systems."}
{"id": "2510.15152", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15152", "abs": "https://arxiv.org/abs/2510.15152", "authors": ["Wenxin Zhang", "Yueying Li", "Ciamac C. Moallemi", "Tianyi Peng"], "title": "Tail-Optimized Caching for LLM Inference", "comment": null, "summary": "Prompt caching is critical for reducing latency and cost in LLM inference:\nOpenAI and Anthropic report up to 50-90% cost savings through prompt reuse.\nDespite its widespread success, little is known about what constitutes an\noptimal prompt caching policy, particularly when optimizing tail latency, a\nmetric of central importance to practitioners. The widely used Least Recently\nUsed (LRU) policy can perform arbitrarily poor on this metric, as it is\noblivious to the heterogeneity of conversation lengths. To address this gap, we\npropose Tail-Optimized LRU, a simple two-line modification that reallocates KV\ncache capacity to prioritize high-latency conversations by evicting cache\nentries that are unlikely to affect future turns. Though the implementation is\nsimple, we prove its optimality under a natural stochastic model of\nconversation dynamics, providing the first theoretical justification for LRU in\nthis setting, a result that may be of independent interest to the caching\ncommunity. Experimentally, on real conversation data WildChat, Tail-Optimized\nLRU achieves up to 27.5% reduction in P90 tail Time to First Token latency and\n23.9% in P95 tail latency compared to LRU, along with up to 38.9% decrease in\nSLO violations of 200ms. We believe this provides a practical and theoretically\ngrounded option for practitioners seeking to optimize tail latency in\nreal-world LLM deployments."}
{"id": "2510.15257", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.15257", "abs": "https://arxiv.org/abs/2510.15257", "authors": ["Amir Ali Farzin", "Yuen-Man Pun", "Philipp Braun", "Tyler Summers", "Iman Shames"], "title": "Minimisation of Submodular Functions Using Gaussian Zeroth-Order Random Oracles", "comment": null, "summary": "We consider the minimisation problem of submodular functions and investigate\nthe application of a zeroth-order method to this problem. The method is based\non exploiting a Gaussian smoothing random oracle to estimate the smoothed\nfunction gradient. We prove the convergence of the algorithm to a global\n$\\epsilon$-approximate solution in the offline case and show that the algorithm\nis Hannan-consistent in the online case with respect to static regret.\nMoreover, we show that the algorithm achieves $O(\\sqrt{NP_N^\\ast})$ dynamic\nregret, where $N$ is the number of iterations and $P_N^\\ast$ is the path\nlength. The complexity analysis and hyperparameter selection are presented for\nall the cases. The theoretical results are illustrated via numerical examples."}
{"id": "2510.15852", "categories": ["physics.comp-ph", "65N75"], "pdf": "https://arxiv.org/pdf/2510.15852", "abs": "https://arxiv.org/abs/2510.15852", "authors": ["Maximilian Cederholm", "Siyao Wang", "Haochun Wang", "Ruichen Xu", "Yuefan Deng"], "title": "Boundary-Informed Method of Lines for Physics Informed Neural Networks", "comment": "To appear in the SIAM Undergraduate Research Online proceedings,\n  March 2026", "summary": "We propose a hybrid solver that fuses the dimensionality-reduction strengths\nof the Method of Lines (MOL) with the flexibility of Physics-Informed Neural\nNetworks (PINNs). Instead of approximating spatial derivatives with fixed\nfinite-difference stencils - whose truncation errors force extremely fine\nmeshes - our method trains a neural network to represent the initial spatial\nprofile and then employs automatic differentiation to obtain spectrally\naccurate gradients at arbitrary nodes. These high-fidelity derivatives define\nthe right-hand side of the MOL-generated ordinary-differential system, and time\nintegration is replaced with a secondary temporal PINN while spatial accuracy\nis retained without mesh refinement. The resulting \"boundary-informed MOL-PINN\"\nmatches or surpasses conventional MOL in accuracy using an order of magnitude\nfewer collocation points, thereby shrinking memory footprints, lessening\ndependence on large data sets, and increasing complexity robustness. Because it\nrelies only on automatic differentiation and standard optimizers, the framework\nextends naturally to linear and nonlinear PDEs in any spatial dimension."}
{"id": "2510.15574", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.15574", "abs": "https://arxiv.org/abs/2510.15574", "authors": ["Gouranga Mallik"], "title": "A Hybrid High-Order Finite Element Method for a Nonlocal Nonlinear Problem of Kirchhoff Type", "comment": null, "summary": "In this article, we design and analyze a hybrid high-order (HHO) finite\nelement approximation for the solution of a nonlocal nonlinear problem of\nKirchhoff type. The HHO method involves arbitrary-order polynomial\napproximations on structured and unstructured polytopal meshes. We establish\nthe existence of a unique discrete solution to the nonlocal nonlinear discrete\nproblem. We derive an optimal-order error estimate in the discrete energy norm.\nThe discrete system is solved using Newton's iterations on the sparse matrix\nsystem. We perform numerical tests to substantiate the theoretical results."}
{"id": "2510.15766", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.15766", "abs": "https://arxiv.org/abs/2510.15766", "authors": ["Meng-Yuan Li", "Peng Ye"], "title": "Subdimensional entanglement entropy: from virtual response to mixed-state holography", "comment": null, "summary": "Entanglement entropy (EE) serves as a key diagnostic of quantum phases and\nphase transitions through bipartitions of the full system. However, recent\nstudies on various topological phases of matter show that EE from bipartitions\nalone cannot effectively distinguish geometric from topological contributions.\nMotivated by this limitation, we introduce the \\textit{subdimensional\nentanglement entropy} (SEE), defined for lower-dimensional\n\\textit{subdimensional entanglement subsystems} (SESs), as a response theory\ncharacterizing many-body systems via \\textit{virtual} deformations of SES\ngeometry and topology. Analytical calculations for cluster states, discrete\nAbelian gauge theories, and fracton orders reveal distinct subleading SEE terms\nthat sharply differentiate geometric and topological responses. Viewing the\nreduced density matrix on an SES as a mixed state, we establish a\ncorrespondence between stabilizers and mixed-state symmetries, identifying\n\\textit{strong} and \\textit{weak} classes. For SESs with nontrivial SEE, weak\nsymmetries act as \\textit{transparent patch operators} of the strong ones,\nforming robust \\textit{transparent composite symmetries} (TCSs) that remain\ninvariant under finite-depth quantum circuits and yield \\textit{strong-to-weak\nspontaneous symmetry breaking} (SW-SSB). By bridging entanglement, mixed-state\nand categorical symmetries, holographic principles of topological order, and\ngeometric-topological responses, SEE provides a unified framework that invites\nfurther theoretical and numerical exploration of correlated quantum matter."}
{"id": "2510.15713", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.15713", "abs": "https://arxiv.org/abs/2510.15713", "authors": ["Simon M. Fröhlich", "Tobias Sparmann", "Maarten A. Brems", "Jan Rothörl", "Fabian Kammerbauer", "Klaus Raab", "Sachin Krishnia", "Mathias Kläui", "Peter Virnau"], "title": "Real-Time Modeling of Skyrmion Dynamics in Arbitrary 2D Spatially Dependent Pinning Potential Landscapes", "comment": "31 pages, 6 figures", "summary": "Non-flat energy landscapes leading to localized pinning of skyrmions pose an\ninherent and unavoidable challenge for studies of fundamental 2D spin structure\ndynamics as well as applications. Accounting for pinning is a key requirement\nfor predictive modeling of skyrmion systems, as it impacts the systems'\ndynamics and introduces randomizing effects. In this article, we use\nmagneto-optical Kerr microscopy to image skyrmions in a magnetic thin film\nsystem in real time and analyze their hopping dynamics within the non-flat\nenergy landscape. To achieve a fully quantitative model, we utilize skyrmion\ndiffusion and dwell times at pinning sites to extrapolate the pinning energy\nlandscape into regions that cannot be sampled on reasonable experimental time\nscales. For evaluation with a coarse-grained Thiele model, we perform long-time\nmeasurements of skyrmion diffusion and then develop a two-step procedure to\ndetermine simulation parameters by comparing them to experimentally accessible\nbehavior. This provides a direct conversion between simulation and experimental\nunits, which is the missing key step that has previously prevented quantitative\nquasiparticle modeling. We demonstrate the predictive power of our approach by\nmeasuring the experimentally unexplored density dependence of skyrmion\ndiffusion and show that it is in excellent agreement with simulation\npredictions. Our technique thus enables quantitative skyrmion simulations on\nexperimental time and length scales, allowing for predictive in-silico\nprototyping of skyrmion devices."}
{"id": "2510.15190", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15190", "abs": "https://arxiv.org/abs/2510.15190", "authors": ["Oumaima Barhoumi", "Ghazal Farhani", "Taufiq Rahman", "Mohamed H. Zaki", "Sofiène Tahar"], "title": "A Comparative Study of Oscillatory Perturbations in Car-Following Models", "comment": null, "summary": "As connected and autonomous vehicles become more widespread, platooning has\nemerged as a key strategy to improve road capacity, reduce fuel consumption,\nand enhance traffic flow. However, the benefits of platoons strongly depend on\ntheir ability to maintain stability. Instability can lead to unsafe spacing and\nincreased energy usage. In this work, we study platoon instability and analyze\nthe root cause of its occurrence, as well as its impacts on the following\nvehicle. To achieve this, we propose a comparative study between different\ncar-following models such as the Intelligent Driver Model (IDM), the Optimal\nVelocity Model (OVM), the General Motors Model (GMM), and the Cooperative\nAdaptive Cruise Control (CACC). In our approach, we introduce a disruption in\nthe model by varying the velocity of the leading vehicle to visualize the\nbehavior of the following vehicles. To evaluate the dynamic response of each\nmodel, we introduce controlled perturbations in the velocity of the leading\nvehicle, specifically, sinusoidal oscillations and discrete velocity changes.\nThe resulting vehicle trajectories and variations in inter-vehicle spacing are\nanalyzed to assess the robustness of each model to disturbance propagation. The\nfindings offer insight into model sensitivity, stability characteristics, and\nimplications for designing resilient platooning control strategies."}
{"id": "2510.15381", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.15381", "abs": "https://arxiv.org/abs/2510.15381", "authors": ["Christian H. Weiß", "Philipp Adämmer"], "title": "Nonparametric Testing of Spatial Dependence in 2D and 3D Random Fields", "comment": null, "summary": "We propose a flexible and robust nonparametric framework for testing spatial\ndependence in two- and three-dimensional random fields. Our approach involves\nconverting spatial data into one-dimensional time series using space-filling\nHilbert curves. We then apply ordinal pattern-based tests for serial dependence\nto this series. Because Hilbert curves preserve spatial locality, spatial\ndependence in the original field manifests as serial dependence in the\ntransformed sequence. The approach is easy to implement, accommodates arbitrary\ngrid sizes through generalized Hilbert (``gilbert'') curves, and naturally\nextends beyond three dimensions. This provides a practical and general\nalternative to existing methods based on spatial ordinal patterns, which are\ntypically limited to two-dimensional settings."}
{"id": "2510.15190", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15190", "abs": "https://arxiv.org/abs/2510.15190", "authors": ["Oumaima Barhoumi", "Ghazal Farhani", "Taufiq Rahman", "Mohamed H. Zaki", "Sofiène Tahar"], "title": "A Comparative Study of Oscillatory Perturbations in Car-Following Models", "comment": null, "summary": "As connected and autonomous vehicles become more widespread, platooning has\nemerged as a key strategy to improve road capacity, reduce fuel consumption,\nand enhance traffic flow. However, the benefits of platoons strongly depend on\ntheir ability to maintain stability. Instability can lead to unsafe spacing and\nincreased energy usage. In this work, we study platoon instability and analyze\nthe root cause of its occurrence, as well as its impacts on the following\nvehicle. To achieve this, we propose a comparative study between different\ncar-following models such as the Intelligent Driver Model (IDM), the Optimal\nVelocity Model (OVM), the General Motors Model (GMM), and the Cooperative\nAdaptive Cruise Control (CACC). In our approach, we introduce a disruption in\nthe model by varying the velocity of the leading vehicle to visualize the\nbehavior of the following vehicles. To evaluate the dynamic response of each\nmodel, we introduce controlled perturbations in the velocity of the leading\nvehicle, specifically, sinusoidal oscillations and discrete velocity changes.\nThe resulting vehicle trajectories and variations in inter-vehicle spacing are\nanalyzed to assess the robustness of each model to disturbance propagation. The\nfindings offer insight into model sensitivity, stability characteristics, and\nimplications for designing resilient platooning control strategies."}
{"id": "2510.15305", "categories": ["math.OC", "cs.NA", "math.NA", "49Q12, 65K10"], "pdf": "https://arxiv.org/pdf/2510.15305", "abs": "https://arxiv.org/abs/2510.15305", "authors": ["Zhuo Chen", "Xinjian Xu", "Shihui Ying", "Tieyong Zeng"], "title": "Riemannian Bilevel Optimization with Gradient Aggregation", "comment": "Submitted to the Journal of Optimization Theory and Applications\n  (JOTA), under review. 25 pages, 4 figures", "summary": "Bilevel optimization (BLO) offers a principled framework for hierarchical\ndecision-making and has been widely applied in machine learning tasks such as\nhyperparameter optimization and meta-learning. While existing BLO methods are\nmostly developed in Euclidean spaces, many real-world problems involve\nstructural constraints. In this paper, we propose a Riemannian bilevel\noptimization (RBLO) algorithm that incorporates a bilevel descent aggregation\n(BDA) scheme to jointly coordinate upper- and lower-level updates. Concretely,\nfirst we abstract the constraints in the BLO to a manifold structure and then\ntransform the constrained BLO be a unconstrained RBLO problem. Second, to\naddress limitations of existing RBLO methods, particularly the restrictive\nassumptions required for convergence, we reformulate the bilevel problem using\nsmooth manifold mappings and provide a convergence analysis under the\nconditions of geodesic convexity and Lipschitz smoothness. Finally, we recall\nthe multi-view hypergraph spectral clustering task, and evaluate the proposed\napproach on 3sources data sets. The numerical results validate the superior\nperformance over Euclidean and manifold-based baselines."}
{"id": "2510.15093", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15093", "abs": "https://arxiv.org/abs/2510.15093", "authors": ["Yue Zhao", "Huan Lei"], "title": "Fast spectral separation method for kinetic equation with anisotropic non-stationary collision operator retaining micro-model fidelity", "comment": null, "summary": "We present a generalized, data-driven collisional operator for one-component\nplasmas, learned from molecular dynamics simulations, to extend the collisional\nkinetic model beyond the weakly coupled regime. The proposed operator features\nan anisotropic, non-stationary collision kernel that accounts for particle\ncorrelations typically neglected in classical Landau formulations. To enable\nefficient numerical evaluation, we develop a fast spectral separation method\nthat represents the kernel as a low-rank tensor product of univariate basis\nfunctions. This formulation admits an $O(N \\log N)$ algorithm via fast Fourier\ntransforms and preserves key physical properties, including discrete\nconservation laws and the H-theorem, through a structure-preserving central\ndifference discretization. Numerical experiments demonstrate that the proposed\nmodel accurately captures plasma dynamics in the moderately coupled regime\nbeyond the standard Landau model while maintaining high computational\nefficiency and structure-preserving properties."}
{"id": "2510.15603", "categories": ["math.NA", "cs.NA", "math.OC", "35Q91, 49J20, 49LXX, 82C31, 65C35"], "pdf": "https://arxiv.org/pdf/2510.15603", "abs": "https://arxiv.org/abs/2510.15603", "authors": ["Elisabetta Carlini", "Luca Saluzzi"], "title": "High order Tensor-Train-Based Schemes for High-Dimensional Mean Field Games", "comment": null, "summary": "We introduce a fully discrete scheme to solve a class of high-dimensional\nMean Field Games systems. Our approach couples semi-Lagrangian (SL) time\ndiscretizations with Tensor-Train (TT) decompositions to tame the curse of\ndimensionality. By reformulating the classical Hamilton-Jacobi-Bellman and\nFokker-Planck equations as a sequence of advection-diffusion-reaction\nsubproblems within a smoothed policy iteration, we construct both first and\nsecond order in time SL schemes. The TT format and appropriate quadrature rules\nreduce storage and computational cost from exponential to polynomial in the\ndimension. Numerical experiments demonstrate that our TT-accelerated SL methods\nachieve their theoretical convergence rates, exhibit modest growth in memory\nusage and runtime with dimension, and significantly outperform grid-based SL in\naccuracy per CPU second."}
{"id": "2510.15853", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.15853", "abs": "https://arxiv.org/abs/2510.15853", "authors": ["David Porlles", "Wei Chen"], "title": "Quantum geometry of common semiconductors", "comment": "7 pages, 3 figures", "summary": "The quantum geometric properties of typical diamond-type (C, Si, Ge) and\nzincblende-type (GaAs, InP, etc) semiconductors are investigated by means of\nthe $sp^{3}s^{\\ast}$ tight-binding model, which allows to calculate the quantum\nmetric of the valence band states throughout the entire Brillouin zone. The\nglobal maximum of the metric is at the $\\Gamma$ point, but other differential\ngeometric properties like Ricci scalar, Ricci tensor, and Einstein tensor are\nfound to vary significantly in the momentum space, indicating a highly\ndistorted momentum space manifold. The momentum integration of the quantum\nmetric further yields the gauge-invariant part of the spread of valence band\nWannier function, whose value agrees well with that experimentally extracted\nfrom an optical sum rule of the dielectric function. Furthermore, the\ndependence of these geometric properties on the energy gap offers a way to\nquantify the quantum criticality of these common semiconductors."}
{"id": "2510.15764", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2510.15764", "abs": "https://arxiv.org/abs/2510.15764", "authors": ["Victor Delapalme", "Leticia F. Cugliandolo", "Grégory Schehr", "Marco Tarzia", "Davide Venturelli"], "title": "The Wishart--Rosenzweig--Porter random matrix ensemble", "comment": "31+13 pages, 8 figures", "summary": "In recent years the Rosenzweig--Porter (RP) ensemble, obtained by adding a\ndiagonal matrix with independent and identically distributed elements to a\nGaussian random matrix, has been widely used as a minimal model for the\nemergence of fractal eigenstates in complex many-body systems. A key open\nquestion concerns the robustness of its phase diagram when the assumption of\nindependent and uncorrelated entries is relaxed -- an assumption that\nsimplifies its analysis, but is generally violated in realistic quantum\nsystems. In this work, we take a first step in this direction by considering a\ndeformed Wishart (rather than Gaussian) random matrix, which we dub the\n``Wishart--RP'' ensemble. Using perturbation theory, as well as the cavity and\nreplica methods and the Dyson Brownian motion approach, we characterize its\nphase diagram and localization properties. Remarkably, we show that the level\ncompressibility, which quantifies spectral correlations in the fractal phase,\ncoincides with that of the Gaussian RP model, thereby extending the\nuniversality conjectured in [SciPost Phys. 14, 110 (2023)] beyond the fully\nuncorrelated setting. We confirm our results with numerical tests."}
{"id": "2510.15239", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15239", "abs": "https://arxiv.org/abs/2510.15239", "authors": ["Ziqing Zhu"], "title": "Quantum-Key-Distribution Authenticated Aggregation and Settlement for Virtual Power Plants", "comment": null, "summary": "The proliferation of distributed energy resources (DERs) and demand-side\nflexibility has made virtual power plants (VPPs) central to modern grid\noperation. Yet their end-to-end business pipeline, covering bidding, dispatch,\nmetering, settlement, and archival, forms a tightly coupled\ncyber-physical-economic system where secure and timely communication is\ncritical. Under the combined stress of sophisticated cyberattacks and extreme\nweather shocks, conventional cryptography offers limited long-term protection.\nQuantum key distribution (QKD), with information-theoretic guarantees, is\nviewed as a gold standard for securing critical infrastructures. However,\nlimited key generation rates, routing capacity, and system overhead render key\nallocation a pressing challenge: scarce quantum keys must be scheduled across\nheterogeneous processes to minimize residual risk while maintaining latency\nguarantees. This paper introduces a quantum-authenticated aggregation and\nsettlement framework for VPPs. We first develop a system-threat model that\nconnects QKD key generation and routing with business-layer security\nstrategies, authentication strength, refresh frequency, and delay constraints.\nBuilding on this, we formulate a key-budgeted risk minimization problem that\njointly accounts for economic risk, service-level violations, and key-budget\nfeasibility, and reveal a threshold property linking marginal security value to\nshadow prices. Case studies on a representative VPP system demonstrate that the\nproposed approach significantly reduces residual risk and SLA violations,\nenhances key efficiency and robustness, and aligns observed dynamics with the\ntheoretical shadow price mechanism."}
{"id": "2510.15618", "categories": ["stat.ME", "stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2510.15618", "abs": "https://arxiv.org/abs/2510.15618", "authors": ["Abdul-Nasah Soale", "Adewale Lukman"], "title": "Adaptive Influence Diagnostics in High-Dimensional Regression", "comment": null, "summary": "An adaptive Cook's distance (ACD) for diagnosing influential observations in\nhigh-dimensional single-index models with multicollinearity and outlier\ncontamination is proposed. ACD is a model-free technique built on sparse local\nlinear gradients to temper leverage effects. In simulations spanning low- and\nhigh-dimensional design settings with strong correlation, ACD based on LASSO\n(ACD-LASSO) and SCAD (ACD-SCAD) penalties reduced masking and swamping relative\nto classical Cook's distance and local influence as well as the DF-Model and\nCase-Weight adjusted solution for LASSO. Trimming points flagged by ACD\nstabilizes variable selection while preserving core signals. Applications to\ntwo datasets--the 1960 US cities pollution study and a high-dimensional\nriboflavin genomics experiment show consistent gains in selection stability and\ninterpretability."}
{"id": "2510.15239", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15239", "abs": "https://arxiv.org/abs/2510.15239", "authors": ["Ziqing Zhu"], "title": "Quantum-Key-Distribution Authenticated Aggregation and Settlement for Virtual Power Plants", "comment": null, "summary": "The proliferation of distributed energy resources (DERs) and demand-side\nflexibility has made virtual power plants (VPPs) central to modern grid\noperation. Yet their end-to-end business pipeline, covering bidding, dispatch,\nmetering, settlement, and archival, forms a tightly coupled\ncyber-physical-economic system where secure and timely communication is\ncritical. Under the combined stress of sophisticated cyberattacks and extreme\nweather shocks, conventional cryptography offers limited long-term protection.\nQuantum key distribution (QKD), with information-theoretic guarantees, is\nviewed as a gold standard for securing critical infrastructures. However,\nlimited key generation rates, routing capacity, and system overhead render key\nallocation a pressing challenge: scarce quantum keys must be scheduled across\nheterogeneous processes to minimize residual risk while maintaining latency\nguarantees. This paper introduces a quantum-authenticated aggregation and\nsettlement framework for VPPs. We first develop a system-threat model that\nconnects QKD key generation and routing with business-layer security\nstrategies, authentication strength, refresh frequency, and delay constraints.\nBuilding on this, we formulate a key-budgeted risk minimization problem that\njointly accounts for economic risk, service-level violations, and key-budget\nfeasibility, and reveal a threshold property linking marginal security value to\nshadow prices. Case studies on a representative VPP system demonstrate that the\nproposed approach significantly reduces residual risk and SLA violations,\nenhances key efficiency and robustness, and aligns observed dynamics with the\ntheoretical shadow price mechanism."}
{"id": "2510.15401", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.15401", "abs": "https://arxiv.org/abs/2510.15401", "authors": ["Michael Herty", "Yizhou Zhou"], "title": "Turnpike property for hierarchical optimal control problems: from particle systems to hydrodynamic equations", "comment": null, "summary": "This work is concerned with a hierarchical framework of optimal control\nproblems connecting interacting particle systems, the mean field limit\nequations, and associated hydrodynamic models. By assuming the existence of\nsolutions, we establish the exponential turnpike property for each level of the\nhierarchy, showing that optimal trajectories remain close to the associated\nsteady states over long time horizons. The results demonstrate that the\nexponential turnpike behavior persists consistently across scales, providing a\nunified connection between microscopic, kinetic, and macroscopic optimal\ncontrol frameworks."}
{"id": "2510.15124", "categories": ["cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.15124", "abs": "https://arxiv.org/abs/2510.15124", "authors": ["Alexandros Vasilopoulos", "Michail Akritidis", "Nikolaos G. Fytas", "Martin Weigel"], "title": "Cluster percolation and dynamical scaling in the Baxter--Wu model", "comment": "10 pages, 7 figures, 1 table, REVTeX4.2", "summary": "We investigate the percolation behavior of Fortuin-Kasteleyn--type clusters\nin the spin-$1/2$ Baxter--Wu model with three-spin interactions on a triangular\nlattice. The considered clusters are constructed by randomly freezing one of\nthe three sublattices, resulting in effective pairwise interactions among the\nremaining spins. Using Monte Carlo simulations combined with a finite-size\nscaling analysis, we determine the percolation temperature of these stochastic\nclusters and show that it coincides with the exact thermal critical point of\nthe model. The critical exponents derived from cluster observables are\nconsistent with those of the underlying thermal phase transition. Finally, we\nanalyze the dynamical scaling of the multi-cluster and single-cluster\nalgorithms resulting from the cluster construction, highlighting their\nefficiency and scaling behavior with system size."}
{"id": "2510.15604", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.15604", "abs": "https://arxiv.org/abs/2510.15604", "authors": ["Chen Zhang", "Patrick Henning", "Mahima Yadav", "Wenbin Chen"], "title": "Convergence analysis of Sobolev Gradient flows for the rotating Gross-Pitaevskii energy functional", "comment": null, "summary": "This paper studies the numerical approximation of the ground state of\nrotating Bose--Einstein condensates, formulated as the minimization of the\nGross--Pitaevskii energy functional under a mass conservation constraint. To\nsolve this problem, we consider three Sobolev gradient flow schemes: the\n$H_0^1$ scheme, the $a_0$ scheme, and the $a_u$ scheme. Convergence of these\nschemes in the non-rotating case was established by Chen et al., and the\nrotating $a_u$ scheme was analyzed in Henning et al. In this work, we prove the\nglobal convergence of the $H_0^1$ and $a_0$ schemes in the rotating case, and\nestablish local linear convergence for all three schemes near the ground state.\nNumerical experiments confirm our theoretical findings."}
{"id": "2510.15500", "categories": ["hep-lat", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.15500", "abs": "https://arxiv.org/abs/2510.15500", "authors": ["Johann Ostmeyer", "Carsten Urbach"], "title": "The Truncated Hankel Correlator Method", "comment": "17 + 3 pages, 13 figures, 3 algorithms", "summary": "We introduce a new method to approximate Euclidean correlation functions by\nexponential sums. The Truncated Hankel Correlator (THC) method builds a Hankel\nmatrix from the full correlator data available and truncates the eigenspectrum\nof said Hankel matrix. It proceeds by applying the Prony generalised eigenvalue\nmethod to the thus obtained low-rank approximation. A large number of algebraic\ncorrelator analysis methods including (block) Prony (and equivalently (block)\nLanczos) and the generalised eigenvalue problem (GEVP) can be reproduced as\nsub-optimal special cases of the THC method. Weights, for instance inverse\nsquare errors, can be included in the analysis, so that the result has a close\nto optimal $\\chi^2$-value. This makes the THC method very similar in spirit to\na closed form solution to multi-state fits, naturally including the case of\nmatrix-valued correlators. We show that, in general, finding approximations\nbetter than those provided by the THC method is exponentially hard in the\nnumber of exponentials. Moreover, the THC method is robust against noise and\nrequires comparably little human oversight. Finally, when applied to symmetric\ndata, the obtained energy spectrum is guaranteed to be symmetric up to machine\nprecision."}
{"id": "2510.15656", "categories": ["nlin.AO", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.15656", "abs": "https://arxiv.org/abs/2510.15656", "authors": ["Frank Schweitzer", "Georges Andres", "Adrien Baut", "Giona Casiraghi", "Christoph Gote", "Ramona Roller"], "title": "Active matter synchronization and synergetics", "comment": null, "summary": "We study the collective behavior in a stochastic agent-based model of active\nmatter. Provided a critical take-up of energy, agents produce two types of\ngoods $x$, $y$ that follow a generalized Lotka-Volterra dynamics. For isolated\nagents, production would either reach a fixed point or diverge. Coupling\nagents' production via a mean field of $x$, however, can lead to synchronized\noscillations if agents cooperate in the production of $x$. The production of\n$y$ supports the emergence of the synchronized dynamics by suppressing\nfluctuations and mitigating competition between agents, this way stabilizing\nthe production of $x$. We find that in the synchronized state different groups\nof agents coexist, each following their own limit cycle. The Kuramoto order\nparameter is large within groups, and small across groups. The collective state\nis stable against shocks from agents temporarily switching between cooperation\nand competition. The model dynamics illustrates the principles of synergetics,\ni.e., the spontaneous emergence of order given a critical energy supply and\ncooperative interactions."}
{"id": "2510.15248", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15248", "abs": "https://arxiv.org/abs/2510.15248", "authors": ["Ziqing Zhu"], "title": "Techno-Economic Feasibility Analysis of Quantum Key Distribution for Power-System Communications", "comment": null, "summary": "The accelerating digitalization and decentralization of modern power systems\nexpose critical communication infrastructures to escalating cyber risks,\nparticularly under emerging quantum computing threats. This paper presents an\nintegrated techno-economic framework to evaluate the feasibility of Quantum Key\nDistribution (QKD) for secure power-system communications. A stochastic system\nmodel is developed to jointly capture time-varying key demand, QKD supply under\noptical-loss constraints, station-side buffering, and post-quantum cryptography\n(PQC) fallback mechanisms. Analytical conditions are derived for service-level\nassurance, including buffer stability, outage probability, and availability\nbounds. Building on this, two quantitative metrics, including the Levelized\nCost of Security (LCoSec) and Cost of Incremental Security (CIS), are\nformulated to unify capital, operational, and risk-related expenditures within\na discounted net-present-value framework. Using IEEE 118-bus, 123-node, and\n39-bus test systems, we conduct discrete-event simulations comparing PQC-only,\nQKD-only, and Hybrid architectures across multiple topologies and service\nprofiles. Results show that Hybrid architectures dominated by QKD significantly\nreduce key-outage probability and SLA shortfalls, achieving near-unit\navailability for real-time and confidentiality-critical services. Economic\nanalyses reveal clear breakeven zones where QKD-enhanced deployments become\ncost-effective, primarily in metropolitan and distribution-level networks under\nmoderate optical loss and buffer sizing. The proposed framework provides a\nreproducible, risk-aware decision tool for guiding large-scale, economically\njustified QKD adoption in future resilient power-system infrastructures."}
{"id": "2510.15632", "categories": ["stat.ME", "math.ST", "stat.AP", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.15632", "abs": "https://arxiv.org/abs/2510.15632", "authors": ["Max Welz"], "title": "Robust Estimation of Polyserial Correlation", "comment": "64 pages (30 main text), 16 figures and 5 tables in total", "summary": "The association between a continuous and an ordinal variable is commonly\nmodeled through the polyserial correlation model. However, this model, which is\nbased on a partially-latent normality assumption, may be misspecified in\npractice, due to, for example (but not limited to), outliers or careless\nresponses. We demonstrate that the typically used maximum likelihood (ML)\nestimator is highly susceptible to such misspecification: One single\nobservation not generated by partially-latent normality can suffice to produce\narbitrarily poor estimates. As a remedy, we propose a novel estimator of the\npolyserial correlation model designed to be robust against the adverse effects\nof observations discrepant to that model. The estimator achieves robustness by\nimplicitly downweighting such observations; the ensuing weights constitute a\nuseful tool for pinpointing potential sources of model misspecification. We\nshow that the proposed estimator generalizes ML and is consistent as well as\nasymptotically Gaussian. As price for robustness, some efficiency must be\nsacrificed, but substantial robustness can be gained while maintaining more\nthan 98% of ML efficiency. We demonstrate our estimator's robustness and\npractical usefulness in simulation experiments and an empirical application in\npersonality psychology where our estimator helps identify outliers. Finally,\nthe proposed methodology is implemented in free open-source software."}
{"id": "2510.15248", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15248", "abs": "https://arxiv.org/abs/2510.15248", "authors": ["Ziqing Zhu"], "title": "Techno-Economic Feasibility Analysis of Quantum Key Distribution for Power-System Communications", "comment": null, "summary": "The accelerating digitalization and decentralization of modern power systems\nexpose critical communication infrastructures to escalating cyber risks,\nparticularly under emerging quantum computing threats. This paper presents an\nintegrated techno-economic framework to evaluate the feasibility of Quantum Key\nDistribution (QKD) for secure power-system communications. A stochastic system\nmodel is developed to jointly capture time-varying key demand, QKD supply under\noptical-loss constraints, station-side buffering, and post-quantum cryptography\n(PQC) fallback mechanisms. Analytical conditions are derived for service-level\nassurance, including buffer stability, outage probability, and availability\nbounds. Building on this, two quantitative metrics, including the Levelized\nCost of Security (LCoSec) and Cost of Incremental Security (CIS), are\nformulated to unify capital, operational, and risk-related expenditures within\na discounted net-present-value framework. Using IEEE 118-bus, 123-node, and\n39-bus test systems, we conduct discrete-event simulations comparing PQC-only,\nQKD-only, and Hybrid architectures across multiple topologies and service\nprofiles. Results show that Hybrid architectures dominated by QKD significantly\nreduce key-outage probability and SLA shortfalls, achieving near-unit\navailability for real-time and confidentiality-critical services. Economic\nanalyses reveal clear breakeven zones where QKD-enhanced deployments become\ncost-effective, primarily in metropolitan and distribution-level networks under\nmoderate optical loss and buffer sizing. The proposed framework provides a\nreproducible, risk-aware decision tool for guiding large-scale, economically\njustified QKD adoption in future resilient power-system infrastructures."}
{"id": "2510.15435", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.15435", "abs": "https://arxiv.org/abs/2510.15435", "authors": ["Luo Long", "Coralia Cartis", "Paz Fink Shustin"], "title": "Nonlinear Dimensionality Reduction Techniques for Bayesian Optimization", "comment": "34 pages including appendixes, 8 figures. Keywords: global\n  optimisation, dimensionality reduction techniques, Bayesian methods,\n  Variational Autoencoders", "summary": "Bayesian optimisation (BO) is a standard approach for sample-efficient global\noptimisation of expensive black-box functions, yet its scalability to high\ndimensions remains challenging. Here, we investigate nonlinear dimensionality\nreduction techniques that reduce the problem to a sequence of low-dimensional\nLatent-Space BO (LSBO). While early LSBO methods used (linear) random\nprojections (Wang et al., 2013), building on Grosnit et al. (2021), we employ\nVariational Autoencoders (VAEs) for LSBO, focusing on deep metric loss for\nstructured latent manifolds and VAE retraining to adapt the encoder-decoder to\nnewly sampled regions. We propose some changes in their implementation,\noriginally designed for tasks such as molecule generation, and reformulate the\nalgorithm for broader optimisation purposes. We then couple LSBO with\nSequential Domain Reduction (SDR) directly in the latent space (SDR-LSBO),\nyielding an algorithm that narrows the latent search domains as evidence\naccumulates. Implemented in a GPU-accelerated BoTorch stack with Matern-5/2\nGaussian process surrogates, our numerical results show improved optimisation\nquality across benchmark tasks and that structured latent manifolds improve BO\nperformance. Additionally, we compare random embeddings and VAEs as two\nmechanisms for dimensionality reduction, showing that the latter outperforms\nthe former. To the best of our knowledge, this is the first study to combine\nSDR with VAE-based LSBO, and our analysis clarifies design choices for metric\nshaping and retraining that are critical for scalable latent space BO. For\nreproducibility, our source code is available at\nhttps://github.com/L-Lok/Nonlinear-Dimensionality-Reduction-Techniques-for-Bayesian-Optimization.git."}
{"id": "2510.15664", "categories": ["stat.ME", "cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.15664", "abs": "https://arxiv.org/abs/2510.15664", "authors": ["Lucas Amoudruz", "Sergey Litvinov", "Costas Papadimitriou", "Petros Koumoutsakos"], "title": "Bayesian Inference for PDE-based Inverse Problems using the Optimization of a Discrete Loss", "comment": null, "summary": "Inverse problems are crucial for many applications in science, engineering\nand medicine that involve data assimilation, design, and imaging. Their\nsolution infers the parameters or latent states of a complex system from noisy\ndata and partially observable processes. When measurements are an incomplete or\nindirect view of the system, additional knowledge is required to accurately\nsolve the inverse problem. Adopting a physical model of the system in the form\nof partial differential equations (PDEs) is a potent method to close this gap.\nIn particular, the method of optimizing a discrete loss (ODIL) has shown great\npotential in terms of robustness and computational cost. In this work, we\nintroduce B-ODIL, a Bayesian extension of ODIL, that integrates the PDE loss of\nODIL as prior knowledge and combines it with a likelihood describing the data.\nB-ODIL employs a Bayesian formulation of PDE-based inverse problems to infer\nsolutions with quantified uncertainties. We demonstrate the capabilities of\nB-ODIL in a series of synthetic benchmarks involving PDEs in one, two, and\nthree dimensions. We showcase the application of B-ODIL in estimating tumor\nconcentration and its uncertainty in a patient's brain from MRI scans using a\nthree-dimensional tumor growth model."}
{"id": "2510.15606", "categories": ["math.NA", "cs.NA", "65M12, 35J05"], "pdf": "https://arxiv.org/pdf/2510.15606", "abs": "https://arxiv.org/abs/2510.15606", "authors": ["Olof Runborg", "Elliot Backman"], "title": "Convergence of the Waveholtz Iteration on $\\mathbb{R}^d$", "comment": "26 pages", "summary": "In this paper we analyse the Waveholtz method, a time-domain iterative method\nfor solving the Helmholtz iteration, in the constant-coefficient case in all of\n$\\mathbb{R}^d$. We show that the difference between a Waveholtz iterate and the\noutgoing Helmholtz solution satisfies a Helmholtz equation with a particular\nkind of forcing. For this forcing, we prove a frequency-explicit estimate in\nweighted Sobolev norms, that shows a decrease of the differences as\n$1/\\sqrt{n}$ in terms of the iteration number $n$. This guarantees the\nconvergence of the real parts of the Waveholtz iterates to the real part of the\noutgoing solution of the Helmholtz equation."}
{"id": "2510.15766", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.15766", "abs": "https://arxiv.org/abs/2510.15766", "authors": ["Meng-Yuan Li", "Peng Ye"], "title": "Subdimensional entanglement entropy: from virtual response to mixed-state holography", "comment": null, "summary": "Entanglement entropy (EE) serves as a key diagnostic of quantum phases and\nphase transitions through bipartitions of the full system. However, recent\nstudies on various topological phases of matter show that EE from bipartitions\nalone cannot effectively distinguish geometric from topological contributions.\nMotivated by this limitation, we introduce the \\textit{subdimensional\nentanglement entropy} (SEE), defined for lower-dimensional\n\\textit{subdimensional entanglement subsystems} (SESs), as a response theory\ncharacterizing many-body systems via \\textit{virtual} deformations of SES\ngeometry and topology. Analytical calculations for cluster states, discrete\nAbelian gauge theories, and fracton orders reveal distinct subleading SEE terms\nthat sharply differentiate geometric and topological responses. Viewing the\nreduced density matrix on an SES as a mixed state, we establish a\ncorrespondence between stabilizers and mixed-state symmetries, identifying\n\\textit{strong} and \\textit{weak} classes. For SESs with nontrivial SEE, weak\nsymmetries act as \\textit{transparent patch operators} of the strong ones,\nforming robust \\textit{transparent composite symmetries} (TCSs) that remain\ninvariant under finite-depth quantum circuits and yield \\textit{strong-to-weak\nspontaneous symmetry breaking} (SW-SSB). By bridging entanglement, mixed-state\nand categorical symmetries, holographic principles of topological order, and\ngeometric-topological responses, SEE provides a unified framework that invites\nfurther theoretical and numerical exploration of correlated quantum matter."}
{"id": "2510.15250", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15250", "abs": "https://arxiv.org/abs/2510.15250", "authors": ["Mostafaali Ayubirad", "Zeng Qiu", "Hao Wang", "Chris Weinkauf", "Michiel Van Nieuwstadt", "Hamid R. Ossareh"], "title": "Comprehensive Dynamic Modeling and Constraint-Aware Air Supply Control for Localized Water Management in Automotive Polymer Electrolyte Membrane Fuel Cells", "comment": "This is a manuscript submitted to Applied Energy", "summary": "In this paper, a predictive constraint-aware control scheme is formulated\nwithin the Command Governor (CG) framework for localized hydration management\nof a proton exchange membrane (PEM) fuel cell system. First, a comprehensive\nnonlinear dynamic model of the fuel cell system is presented which includes a\npseudo 2-dimensional (P2D) model of the stack, reactant supply and cooling\nsubsystems. The model captures the couplings among the various subsystems and\nserves as the basis for designing output feedback controllers to track the\noptimal set-points of the air supply and cooling systems for power\noptimization. The closed-loop nonlinear model is then used to analyze the\ndynamic behavior of membrane hydration near the anode inlet, the driest region\nof the membrane in a counter-flow configuration, under various operating\nconditions. A reduced-order linearized model is then derived to approximate\nhydration behavior with sufficient fidelity for constraint enforcement. This\nmodel is used within the CG framework to adjust the air supply set-points when\nnecessary to prevent membrane dry-out. The effectiveness of the proposed\napproach in maintaining local membrane hydration while closely tracking the\nrequested net power is demonstrated through realistic drive-cycle simulations."}
{"id": "2510.15664", "categories": ["stat.ME", "cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.15664", "abs": "https://arxiv.org/abs/2510.15664", "authors": ["Lucas Amoudruz", "Sergey Litvinov", "Costas Papadimitriou", "Petros Koumoutsakos"], "title": "Bayesian Inference for PDE-based Inverse Problems using the Optimization of a Discrete Loss", "comment": null, "summary": "Inverse problems are crucial for many applications in science, engineering\nand medicine that involve data assimilation, design, and imaging. Their\nsolution infers the parameters or latent states of a complex system from noisy\ndata and partially observable processes. When measurements are an incomplete or\nindirect view of the system, additional knowledge is required to accurately\nsolve the inverse problem. Adopting a physical model of the system in the form\nof partial differential equations (PDEs) is a potent method to close this gap.\nIn particular, the method of optimizing a discrete loss (ODIL) has shown great\npotential in terms of robustness and computational cost. In this work, we\nintroduce B-ODIL, a Bayesian extension of ODIL, that integrates the PDE loss of\nODIL as prior knowledge and combines it with a likelihood describing the data.\nB-ODIL employs a Bayesian formulation of PDE-based inverse problems to infer\nsolutions with quantified uncertainties. We demonstrate the capabilities of\nB-ODIL in a series of synthetic benchmarks involving PDEs in one, two, and\nthree dimensions. We showcase the application of B-ODIL in estimating tumor\nconcentration and its uncertainty in a patient's brain from MRI scans using a\nthree-dimensional tumor growth model."}
{"id": "2510.15250", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15250", "abs": "https://arxiv.org/abs/2510.15250", "authors": ["Mostafaali Ayubirad", "Zeng Qiu", "Hao Wang", "Chris Weinkauf", "Michiel Van Nieuwstadt", "Hamid R. Ossareh"], "title": "Comprehensive Dynamic Modeling and Constraint-Aware Air Supply Control for Localized Water Management in Automotive Polymer Electrolyte Membrane Fuel Cells", "comment": "This is a manuscript submitted to Applied Energy", "summary": "In this paper, a predictive constraint-aware control scheme is formulated\nwithin the Command Governor (CG) framework for localized hydration management\nof a proton exchange membrane (PEM) fuel cell system. First, a comprehensive\nnonlinear dynamic model of the fuel cell system is presented which includes a\npseudo 2-dimensional (P2D) model of the stack, reactant supply and cooling\nsubsystems. The model captures the couplings among the various subsystems and\nserves as the basis for designing output feedback controllers to track the\noptimal set-points of the air supply and cooling systems for power\noptimization. The closed-loop nonlinear model is then used to analyze the\ndynamic behavior of membrane hydration near the anode inlet, the driest region\nof the membrane in a counter-flow configuration, under various operating\nconditions. A reduced-order linearized model is then derived to approximate\nhydration behavior with sufficient fidelity for constraint enforcement. This\nmodel is used within the CG framework to adjust the air supply set-points when\nnecessary to prevent membrane dry-out. The effectiveness of the proposed\napproach in maintaining local membrane hydration while closely tracking the\nrequested net power is demonstrated through realistic drive-cycle simulations."}
{"id": "2510.15610", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15610", "abs": "https://arxiv.org/abs/2510.15610", "authors": ["El Mahdi Chayti", "Taha El Bakkali El Kadi", "Omar Saadi", "Martin Jaggi"], "title": "Stochastic Optimization with Random Search", "comment": null, "summary": "We revisit random search for stochastic optimization, where only noisy\nfunction evaluations are available. We show that the method works under weaker\nsmoothness assumptions than previously considered, and that stronger\nassumptions enable improved guarantees. In the finite-sum setting, we design a\nvariance-reduced variant that leverages multiple samples to accelerate\nconvergence. Our analysis relies on a simple translation invariance property,\nwhich provides a principled way to balance noise and reduce variance."}
{"id": "2510.15819", "categories": ["math.NA", "cs.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.15819", "abs": "https://arxiv.org/abs/2510.15819", "authors": ["Rihui Lan", "Jorge Reyes"], "title": "Longer time accuracy for the Ladyzhenskya model with the EMAC formulation", "comment": null, "summary": "In this paper, we incorporate the EMAC formulation into the Ladyzhenskaya\nmodel (LM), a large eddy simulation (LES) of incompressible flows. The EMAC\nformulation, which conserves energy, linear momentum, and angular momentum even\nwith weak enforcement of incompressibility, has been shown to provide tangible\nbenefits over the popular skew-symmetric for direct numerical simulation and\nregularized models of the Navier Stokes equations (NSE). The combination of\nEMAC with the LM addresses the known over-dissipation issues associated with\nthe classical Smagorinsky model (SM). We develop a finite element\ndiscretization for the EMAC-LM system and analyze its stability and derive\nnumerical error estimates, showing improved long-time behavior compared to the\nstandard LM approach, particularly due to EMAC's favorable Gronwall constant\nindependent of the Reynolds number. Benchmark simulations demonstrate that the\nEMAC-LM model yields more accurate flow structures, especially at high Reynolds\nnumbers."}
{"id": "2510.15285", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15285", "abs": "https://arxiv.org/abs/2510.15285", "authors": ["Saeid Bayat", "Jerry Zuo", "Jing Sun"], "title": "Modeling and Dynamic Simulation of a Hybrid Wind-Wave System on a Hexagonal Semi-Submersible Platform", "comment": "28 pages, 17 figures", "summary": "Offshore renewable energy systems offer promising solutions for sustainable\npower generation, yet most existing platforms harvest either wind or wave\nenergy in isolation. This study presents a hybrid floating offshore platform\nthat integrates a wind turbine with three oscillating surge wave energy\nconverters (WECs) into a hexagonal semi-submersible structure. In this\nconfiguration, the flaps are integrated with the platform geometry to provide\nboth energy extraction and hydrodynamic stability. A modeling and simulation\nframework was developed using WEC-Sim and benchmarked against the NREL 5 MW\nsemisubmersible reference. Metacentric height analysis confirmed hydrostatic\nstability across a range of prescribed flap angles. Sensitivity analysis of\ntwelve geometric variables identified flap dimensions and tower length as\ndominant drivers of stability, energy capture, and tower stress. Time-domain\nsimulations revealed dependence on wave incidence angle, with variations in\nflap power sharing, capture width ratio (CWR), and platform response. The\nfeasibility of using flap sweeps to modulate pitch motion was also\ndemonstrated. Annual energy production (AEP) estimates based on site-specific\ndata indicate 16.86 GWh from wind and 3.65 GWh from wave energy, with WECs\ncontributing about 18% of the total. These results highlight the potential of\nintegrated wind-wave platforms and point toward future studies on structural\nmodeling and advanced control."}
{"id": "2510.15670", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.15670", "abs": "https://arxiv.org/abs/2510.15670", "authors": ["Paolo Giudici", "Rosa C. Rosciano", "Johanna Schrader", "Delf-Magnus Kummerfeld"], "title": "A Multiclass ROC Curve", "comment": null, "summary": "This paper introduces a novel methodology for constructing multiclass ROC\ncurves using the multidimensional Gini index. The proposed methodology\nleverages the established relationship between the Gini coefficient and the ROC\nCurve and extends it to multiclass settings through the multidimensional Gini\nindex. The framework is validated by means of two comprehensive case studies in\nhealth care and finance. The paper provides a theoretically grounded solution\nto multiclass performance evaluation, particularly valuable for imbalanced\ndatasets, for which a prudential assessment should take precedence over class\nfrequency considerations."}
{"id": "2510.15285", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15285", "abs": "https://arxiv.org/abs/2510.15285", "authors": ["Saeid Bayat", "Jerry Zuo", "Jing Sun"], "title": "Modeling and Dynamic Simulation of a Hybrid Wind-Wave System on a Hexagonal Semi-Submersible Platform", "comment": "28 pages, 17 figures", "summary": "Offshore renewable energy systems offer promising solutions for sustainable\npower generation, yet most existing platforms harvest either wind or wave\nenergy in isolation. This study presents a hybrid floating offshore platform\nthat integrates a wind turbine with three oscillating surge wave energy\nconverters (WECs) into a hexagonal semi-submersible structure. In this\nconfiguration, the flaps are integrated with the platform geometry to provide\nboth energy extraction and hydrodynamic stability. A modeling and simulation\nframework was developed using WEC-Sim and benchmarked against the NREL 5 MW\nsemisubmersible reference. Metacentric height analysis confirmed hydrostatic\nstability across a range of prescribed flap angles. Sensitivity analysis of\ntwelve geometric variables identified flap dimensions and tower length as\ndominant drivers of stability, energy capture, and tower stress. Time-domain\nsimulations revealed dependence on wave incidence angle, with variations in\nflap power sharing, capture width ratio (CWR), and platform response. The\nfeasibility of using flap sweeps to modulate pitch motion was also\ndemonstrated. Annual energy production (AEP) estimates based on site-specific\ndata indicate 16.86 GWh from wind and 3.65 GWh from wave energy, with WECs\ncontributing about 18% of the total. These results highlight the potential of\nintegrated wind-wave platforms and point toward future studies on structural\nmodeling and advanced control."}
{"id": "2510.15696", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.15696", "abs": "https://arxiv.org/abs/2510.15696", "authors": ["Carlos Gamboa", "Alexandre Street", "Davi Valladão", "Bernardo Pagnocelli"], "title": "Two-Stage Data-Driven Contextual Robust Optimization: An End-to-End Learning Approach for Online Energy Applications", "comment": null, "summary": "Traditional end-to-end contextual robust optimization models are trained for\nspecific contextual data, requiring complete retraining whenever new contextual\ninformation arrives. This limitation hampers their use in online\ndecision-making problems such as energy scheduling, where multiperiod\noptimization must be solved every few minutes. In this paper, we propose a\nnovel Data-Driven Contextual Uncertainty Set, which gives rise to a new\nEnd-to-End Data-Driven Contextual Robust Optimization model. For\nright-hand-side uncertainty, we introduce a reformulation scheme that enables\nthe development of a variant of the Column-and-Constraint Generation (CCG)\nalgorithm. This new CCG method explicitly considers the contextual vector\nwithin the cut expressions, allowing previously generated cuts to remain valid\nfor new contexts, thereby significantly accelerating convergence in online\napplications. Numerical experiments on energy and reserve scheduling problems,\nbased on classical test cases and large-scale networks (with more than 10,000\nnodes), demonstrate that the proposed method reduces computation times and\noperational costs while capturing context-dependent risk structures. The\nproposed framework (model and method), therefore, offers a unified, scalable,\nand prescriptive approach to robust decision-making under uncertainty,\neffectively bridging data-driven learning and optimization."}
{"id": "2510.15854", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.15854", "abs": "https://arxiv.org/abs/2510.15854", "authors": ["Xiaofeng Cai", "Linghui Kong", "Dmitri Kuzmin", "Li Shan"], "title": "Asymptotic-preserving conservative semi-Lagrangian discontinuous Galerkin schemes for the Vlasov-Poisson system in the quasi-neutral limit", "comment": null, "summary": "We discretize the Vlasov-Poisson system using conservative semi-Lagrangian\n(CSL) discontinuous Galerkin (DG) schemes that are asymptotic preserving (AP)\nin the quasi-neutral limit. The proposed method (CSLDG) relies on two key\ningredients: the CSLDG discretization and a reformulated Poisson equation\n(RPE). The use of the CSL formulation ensures local mass conservation and\ncircumvents the Courant-Friedrichs-Lewy condition, while the DG method provides\nhigh-order accuracy for capturing fine-scale phase space structures of the\ndistribution function. The RPE is derived by the Poisson equation coupled with\nmoments of the Vlasov equation. The synergy between the CSLDG and RPE\ncomponents makes it possible to obtain reliable numerical solutions, even when\nthe spatial and temporal resolution might not fully resolve the Debye length.\nWe rigorously prove that the proposed method is asymptotically stable,\nconsistent and satisfies AP properties. Moreover, its efficiency is maintained\nacross non-quasi-neutral and quasi-neutral regimes. These properties of our\napproach are essential for accurate and robust numerical simulation of complex\nelectrostatic plasmas. Several numerical experiments verify the accuracy,\nstability and efficiency of the proposed CSLDG schemes."}
{"id": "2510.15365", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15365", "abs": "https://arxiv.org/abs/2510.15365", "authors": ["Maonan Wang", "Yirong Chen", "Yuxin Cai", "Aoyu Pang", "Yuejiao Xie", "Zian Ma", "Chengcheng Xu", "Kemou Jiang", "Ding Wang", "Laurent Roullet", "Chung Shue Chen", "Zhiyong Cui", "Yuheng Kan", "Michael Lepech", "Man-On Pun"], "title": "TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making", "comment": "9 pages, 4 figures", "summary": "Air-ground collaborative intelligence is becoming a key approach for\nnext-generation urban intelligent transportation management, where aerial and\nground systems work together on perception, communication, and decision-making.\nHowever, the lack of a unified multi-modal simulation environment has limited\nprogress in studying cross-domain perception, coordination under communication\nconstraints, and joint decision optimization. To address this gap, we present\nTranSimHub, a unified simulation platform for air-ground collaborative\nintelligence. TranSimHub offers synchronized multi-view rendering across RGB,\ndepth, and semantic segmentation modalities, ensuring consistent perception\nbetween aerial and ground viewpoints. It also supports information exchange\nbetween the two domains and includes a causal scene editor that enables\ncontrollable scenario creation and counterfactual analysis under diverse\nconditions such as different weather, emergency events, and dynamic obstacles.\nWe release TranSimHub as an open-source platform that supports end-to-end\nresearch on perception, fusion, and control across realistic air and ground\ntraffic scenes. Our code is available at\nhttps://github.com/Traffic-Alpha/TranSimHub."}
{"id": "2510.15365", "categories": ["eess.SY", "cs.LG", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15365", "abs": "https://arxiv.org/abs/2510.15365", "authors": ["Maonan Wang", "Yirong Chen", "Yuxin Cai", "Aoyu Pang", "Yuejiao Xie", "Zian Ma", "Chengcheng Xu", "Kemou Jiang", "Ding Wang", "Laurent Roullet", "Chung Shue Chen", "Zhiyong Cui", "Yuheng Kan", "Michael Lepech", "Man-On Pun"], "title": "TranSimHub:A Unified Air-Ground Simulation Platform for Multi-Modal Perception and Decision-Making", "comment": "9 pages, 4 figures", "summary": "Air-ground collaborative intelligence is becoming a key approach for\nnext-generation urban intelligent transportation management, where aerial and\nground systems work together on perception, communication, and decision-making.\nHowever, the lack of a unified multi-modal simulation environment has limited\nprogress in studying cross-domain perception, coordination under communication\nconstraints, and joint decision optimization. To address this gap, we present\nTranSimHub, a unified simulation platform for air-ground collaborative\nintelligence. TranSimHub offers synchronized multi-view rendering across RGB,\ndepth, and semantic segmentation modalities, ensuring consistent perception\nbetween aerial and ground viewpoints. It also supports information exchange\nbetween the two domains and includes a causal scene editor that enables\ncontrollable scenario creation and counterfactual analysis under diverse\nconditions such as different weather, emergency events, and dynamic obstacles.\nWe release TranSimHub as an open-source platform that supports end-to-end\nresearch on perception, fusion, and control across realistic air and ground\ntraffic scenes. Our code is available at\nhttps://github.com/Traffic-Alpha/TranSimHub."}
{"id": "2510.15714", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.15714", "abs": "https://arxiv.org/abs/2510.15714", "authors": ["El Mahdi Chayti", "Martin Jaggi"], "title": "A Split-Client Approach to Second-Order Optimization", "comment": null, "summary": "Second-order methods promise faster convergence but are rarely used in\npractice because Hessian computations and decompositions are far more expensive\nthan gradients. We propose a \\emph{split-client} framework where gradients and\ncurvature are computed asynchronously by separate clients. This abstraction\ncaptures realistic delays and inexact Hessian updates while avoiding the manual\ntuning required by Lazy Hessian methods. Focusing on cubic regularization, we\nshow that our approach retains strong convergence guarantees and achieves a\nprovable wall-clock speedup of order $\\sqrt{\\tau}$, where $\\tau$ is the\nrelative time needed to compute and decompose the Hessian compared to a\ngradient step. Since $\\tau$ can be orders of magnitude larger than one in\nhigh-dimensional problems, this improvement is practically significant.\nExperiments on synthetic and real datasets confirm the theory: asynchronous\ncurvature consistently outperforms vanilla and Lazy Hessian baselines, while\nmaintaining second-order accuracy."}
{"id": "2510.15257", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.15257", "abs": "https://arxiv.org/abs/2510.15257", "authors": ["Amir Ali Farzin", "Yuen-Man Pun", "Philipp Braun", "Tyler Summers", "Iman Shames"], "title": "Minimisation of Submodular Functions Using Gaussian Zeroth-Order Random Oracles", "comment": null, "summary": "We consider the minimisation problem of submodular functions and investigate\nthe application of a zeroth-order method to this problem. The method is based\non exploiting a Gaussian smoothing random oracle to estimate the smoothed\nfunction gradient. We prove the convergence of the algorithm to a global\n$\\epsilon$-approximate solution in the offline case and show that the algorithm\nis Hannan-consistent in the online case with respect to static regret.\nMoreover, we show that the algorithm achieves $O(\\sqrt{NP_N^\\ast})$ dynamic\nregret, where $N$ is the number of iterations and $P_N^\\ast$ is the path\nlength. The complexity analysis and hyperparameter selection are presented for\nall the cases. The theoretical results are illustrated via numerical examples."}
{"id": "2510.15519", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15519", "abs": "https://arxiv.org/abs/2510.15519", "authors": ["Yushu Qin", "Marcos L. L. Sartori", "Shengyu Duan", "Emre Ozer", "Rishad Shafik", "Alex Yakovlev"], "title": "A Tsetlin Machine Image Classification Accelerator on a Flexible Substrate", "comment": "accepted by International Symposium on the Tsetlin Machine (ISTM)\n  2025", "summary": "This paper introduces the first implementation of digital Tsetlin Machines\n(TMs) on flexible integrated circuit (FlexIC) using Pragmatic's 600nm\nIGZO-based FlexIC technology. TMs, known for their energy efficiency,\ninterpretability, and suitability for edge computing, have previously been\nlimited by the rigidity of conventional silicon-based chips. We develop two TM\ninference models as FlexICs: one achieving 98.5% accuracy using 6800 NAND2\nequivalent logic gates with an area of 8X8 mm2, and a second more compact\nversion achieving slightly lower prediction accuracy of 93% but using only 1420\nNAND2 equivalent gates with an area of 4X4 mm2, both of which are\ncustom-designed for an 8X8-pixel handwritten digit recognition dataset. The\npaper demonstrates the feasibility of deploying flexible TM inference engines\ninto wearable healthcare and edge computing applications."}
{"id": "2510.15519", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15519", "abs": "https://arxiv.org/abs/2510.15519", "authors": ["Yushu Qin", "Marcos L. L. Sartori", "Shengyu Duan", "Emre Ozer", "Rishad Shafik", "Alex Yakovlev"], "title": "A Tsetlin Machine Image Classification Accelerator on a Flexible Substrate", "comment": "accepted by International Symposium on the Tsetlin Machine (ISTM)\n  2025", "summary": "This paper introduces the first implementation of digital Tsetlin Machines\n(TMs) on flexible integrated circuit (FlexIC) using Pragmatic's 600nm\nIGZO-based FlexIC technology. TMs, known for their energy efficiency,\ninterpretability, and suitability for edge computing, have previously been\nlimited by the rigidity of conventional silicon-based chips. We develop two TM\ninference models as FlexICs: one achieving 98.5% accuracy using 6800 NAND2\nequivalent logic gates with an area of 8X8 mm2, and a second more compact\nversion achieving slightly lower prediction accuracy of 93% but using only 1420\nNAND2 equivalent gates with an area of 4X4 mm2, both of which are\ncustom-designed for an 8X8-pixel handwritten digit recognition dataset. The\npaper demonstrates the feasibility of deploying flexible TM inference engines\ninto wearable healthcare and edge computing applications."}
{"id": "2510.15734", "categories": ["math.OC", "cs.NA", "math.NA", "49K10, 65K05, 65Y20, 68Q25, 90C05, 90C30, 90C51"], "pdf": "https://arxiv.org/pdf/2510.15734", "abs": "https://arxiv.org/abs/2510.15734", "authors": ["Stephen J. Wright"], "title": "Optimization in Theory and Practice", "comment": null, "summary": "Algorithms for continuous optimization problems have a rich history of design\nand innovation over the past several decades, in which mathematical analysis of\ntheir convergence and complexity properties plays a central role. Besides their\ntheoretical properties, optimization algorithms are interesting also for their\npractical usefulness as computational tools for solving real-world problems.\nThere are often gaps between the practical performance of an algorithm and what\ncan be proved about it. These two facets of the field -- the theoretical and\nthe practical -- interact in fascinating ways, each driving innovation in the\nother. This work focuses on the development of algorithms in two areas --\nlinear programming and unconstrained minimization of smooth functions --\noutlining major algorithm classes in each area along with their theoretical\nproperties and practical performance, and highlighting how advances in theory\nand practice have influenced each other in these areas. In discussing theory,\nwe focus mainly on non-asymptotic complexity, which are upper bounds on the\namount of computation required by a given algorithm to find an approximate\nsolution of problems in a given class."}
{"id": "2510.15305", "categories": ["math.OC", "cs.NA", "math.NA", "49Q12, 65K10"], "pdf": "https://arxiv.org/pdf/2510.15305", "abs": "https://arxiv.org/abs/2510.15305", "authors": ["Zhuo Chen", "Xinjian Xu", "Shihui Ying", "Tieyong Zeng"], "title": "Riemannian Bilevel Optimization with Gradient Aggregation", "comment": "Submitted to the Journal of Optimization Theory and Applications\n  (JOTA), under review. 25 pages, 4 figures", "summary": "Bilevel optimization (BLO) offers a principled framework for hierarchical\ndecision-making and has been widely applied in machine learning tasks such as\nhyperparameter optimization and meta-learning. While existing BLO methods are\nmostly developed in Euclidean spaces, many real-world problems involve\nstructural constraints. In this paper, we propose a Riemannian bilevel\noptimization (RBLO) algorithm that incorporates a bilevel descent aggregation\n(BDA) scheme to jointly coordinate upper- and lower-level updates. Concretely,\nfirst we abstract the constraints in the BLO to a manifold structure and then\ntransform the constrained BLO be a unconstrained RBLO problem. Second, to\naddress limitations of existing RBLO methods, particularly the restrictive\nassumptions required for convergence, we reformulate the bilevel problem using\nsmooth manifold mappings and provide a convergence analysis under the\nconditions of geodesic convexity and Lipschitz smoothness. Finally, we recall\nthe multi-view hypergraph spectral clustering task, and evaluate the proposed\napproach on 3sources data sets. The numerical results validate the superior\nperformance over Euclidean and manifold-based baselines."}
{"id": "2510.15573", "categories": ["eess.SY", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15573", "abs": "https://arxiv.org/abs/2510.15573", "authors": ["Jianguo Chen", "Zhengqin Liu", "Jinlong Lei", "Peng Yi", "Yiguang Hong", "Hong Chen"], "title": "Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic", "comment": null, "summary": "With the practical implementation of connected and autonomous vehicles\n(CAVs), the traffic system is expected to remain a mix of CAVs and human-driven\nvehicles (HVs) for the foreseeable future. To enhance safety and traffic\nefficiency, the trajectory planning strategies of CAVs must account for the\ninfluence of HVs, necessitating accurate HV trajectory prediction. Current\nresearch often assumes that human drivers have perfect knowledge of all\nvehicles' objectives, an unrealistic premise. This paper bridges the gap by\nleveraging hypergame theory to account for cognitive and perception limitations\nin HVs. We model human bounded rationality without assuming them to be merely\npassive followers and propose a hierarchical cognition modeling framework that\ncaptures cognitive relationships among vehicles. We further analyze the\ncognitive stability of the system, proving that the strategy profile where all\nvehicles adopt cognitively equilibrium strategies constitutes a hyper Nash\nequilibrium when CAVs accurately learn HV parameters. To achieve this, we\ndevelop an inverse learning algorithm for distributed intention interpretation\nvia vehicle-to-everything (V2X) communication, which extends the framework to\nboth offline and online scenarios. Additionally, we introduce a distributed\ntrajectory prediction and planning approach for CAVs, leveraging the learned\nparameters in real time. Simulations in highway lane-changing scenarios\ndemonstrate the proposed method's accuracy in parameter learning, robustness to\nnoisy trajectory observations, and safety in HV trajectory prediction. The\nresults validate the effectiveness of our method in both offline and online\nimplementations."}
{"id": "2510.15573", "categories": ["eess.SY", "cs.MA", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15573", "abs": "https://arxiv.org/abs/2510.15573", "authors": ["Jianguo Chen", "Zhengqin Liu", "Jinlong Lei", "Peng Yi", "Yiguang Hong", "Hong Chen"], "title": "Hypergame-based Cognition Modeling and Intention Interpretation for Human-Driven Vehicles in Connected Mixed Traffic", "comment": null, "summary": "With the practical implementation of connected and autonomous vehicles\n(CAVs), the traffic system is expected to remain a mix of CAVs and human-driven\nvehicles (HVs) for the foreseeable future. To enhance safety and traffic\nefficiency, the trajectory planning strategies of CAVs must account for the\ninfluence of HVs, necessitating accurate HV trajectory prediction. Current\nresearch often assumes that human drivers have perfect knowledge of all\nvehicles' objectives, an unrealistic premise. This paper bridges the gap by\nleveraging hypergame theory to account for cognitive and perception limitations\nin HVs. We model human bounded rationality without assuming them to be merely\npassive followers and propose a hierarchical cognition modeling framework that\ncaptures cognitive relationships among vehicles. We further analyze the\ncognitive stability of the system, proving that the strategy profile where all\nvehicles adopt cognitively equilibrium strategies constitutes a hyper Nash\nequilibrium when CAVs accurately learn HV parameters. To achieve this, we\ndevelop an inverse learning algorithm for distributed intention interpretation\nvia vehicle-to-everything (V2X) communication, which extends the framework to\nboth offline and online scenarios. Additionally, we introduce a distributed\ntrajectory prediction and planning approach for CAVs, leveraging the learned\nparameters in real time. Simulations in highway lane-changing scenarios\ndemonstrate the proposed method's accuracy in parameter learning, robustness to\nnoisy trajectory observations, and safety in HV trajectory prediction. The\nresults validate the effectiveness of our method in both offline and online\nimplementations."}
{"id": "2510.15753", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.15753", "abs": "https://arxiv.org/abs/2510.15753", "authors": ["Ignacio Repiso", "Salvador Pineda", "Juan Miguel Morales"], "title": "Interior-Point vs. Spatial Branching Approaches for Solving the AC Optimal Power Flow Problem", "comment": null, "summary": "The AC Optimal Power Flow (AC-OPF) problem is a non-convex, NP-hard\noptimization task essential for secure and economic power system operation. Two\nprominent solution strategies are interior-point methods, valued for\ncomputational efficiency, and spatial branching techniques, which provide\nglobal optimality guarantees at higher computational cost. In this work, we\nalso explore data-boosted variants that leverage historical operating data to\nenhance performance by guiding initialization in interior-point methods or\nconstraining the search region in spatial branching. We conduct a comprehensive\nempirical comparison across networks of varying sizes and under both standard\nbenchmark conditions and modified configurations designed to induce local\noptima. Our results show that data-boosted strategies can improve convergence\nand reduce computation times for both approaches. Spatial branching, however,\nremains computationally demanding, requiring further development for practical\napplication. In contrast, modern interior-point solvers exhibit remarkable\nrobustness, often converging to the global optimum even in challenging\ninstances with multiple local solutions."}
{"id": "2510.15435", "categories": ["math.OC", "cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.15435", "abs": "https://arxiv.org/abs/2510.15435", "authors": ["Luo Long", "Coralia Cartis", "Paz Fink Shustin"], "title": "Nonlinear Dimensionality Reduction Techniques for Bayesian Optimization", "comment": "34 pages including appendixes, 8 figures. Keywords: global\n  optimisation, dimensionality reduction techniques, Bayesian methods,\n  Variational Autoencoders", "summary": "Bayesian optimisation (BO) is a standard approach for sample-efficient global\noptimisation of expensive black-box functions, yet its scalability to high\ndimensions remains challenging. Here, we investigate nonlinear dimensionality\nreduction techniques that reduce the problem to a sequence of low-dimensional\nLatent-Space BO (LSBO). While early LSBO methods used (linear) random\nprojections (Wang et al., 2013), building on Grosnit et al. (2021), we employ\nVariational Autoencoders (VAEs) for LSBO, focusing on deep metric loss for\nstructured latent manifolds and VAE retraining to adapt the encoder-decoder to\nnewly sampled regions. We propose some changes in their implementation,\noriginally designed for tasks such as molecule generation, and reformulate the\nalgorithm for broader optimisation purposes. We then couple LSBO with\nSequential Domain Reduction (SDR) directly in the latent space (SDR-LSBO),\nyielding an algorithm that narrows the latent search domains as evidence\naccumulates. Implemented in a GPU-accelerated BoTorch stack with Matern-5/2\nGaussian process surrogates, our numerical results show improved optimisation\nquality across benchmark tasks and that structured latent manifolds improve BO\nperformance. Additionally, we compare random embeddings and VAEs as two\nmechanisms for dimensionality reduction, showing that the latter outperforms\nthe former. To the best of our knowledge, this is the first study to combine\nSDR with VAE-based LSBO, and our analysis clarifies design choices for metric\nshaping and retraining that are critical for scalable latent space BO. For\nreproducibility, our source code is available at\nhttps://github.com/L-Lok/Nonlinear-Dimensionality-Reduction-Techniques-for-Bayesian-Optimization.git."}
{"id": "2510.15598", "categories": ["eess.SY", "cs.SY", "93B07, 93C05, 15A66"], "pdf": "https://arxiv.org/pdf/2510.15598", "abs": "https://arxiv.org/abs/2510.15598", "authors": ["Michael Sebek"], "title": "Observer Design over Hypercomplex Quaternions", "comment": "Accepted for presentation at the 24th European Control Conference\n  (ECC 2026), Reykjavik, Iceland. This work was co-funded by the European Union\n  under the project ROBOPROX (reg. no. CZ.02.01.01/00/22 008/0004590)", "summary": "We develop observer design over hypercomplex quaternions in a\ncharacteristic-polynomial-free framework. Using the standard right-module\nconvention, we derive a right observable companion form and its companion\npolynomial that encodes error dynamics via right-eigenvalue similarity classes.\nThe design mirrors the real/complex case - coefficient updates in companion\ncoordinates, followed by a similarity back - yet avoids determinants,\ncharacteristic/minimal polynomials, and Cayley-Hamilton identities that do not\ntransfer to quaternions. We also give an Ackermann-type construction for the\nimportant case of closed-loop companion polynomials with real coefficients,\nensuring similarity-equivariant evaluation. The results yield simple recipes\nfor full-order observers directly over quaternions, clarify the role of right\nspectra and their similarity classes, and pinpoint when classical one-shot\nformulas remain valid. Numerical examples illustrate the method and advantages\nover vectorized or complex-adjoint surrogates."}
{"id": "2510.15598", "categories": ["eess.SY", "cs.SY", "93B07, 93C05, 15A66"], "pdf": "https://arxiv.org/pdf/2510.15598", "abs": "https://arxiv.org/abs/2510.15598", "authors": ["Michael Sebek"], "title": "Observer Design over Hypercomplex Quaternions", "comment": "Accepted for presentation at the 24th European Control Conference\n  (ECC 2026), Reykjavik, Iceland. This work was co-funded by the European Union\n  under the project ROBOPROX (reg. no. CZ.02.01.01/00/22 008/0004590)", "summary": "We develop observer design over hypercomplex quaternions in a\ncharacteristic-polynomial-free framework. Using the standard right-module\nconvention, we derive a right observable companion form and its companion\npolynomial that encodes error dynamics via right-eigenvalue similarity classes.\nThe design mirrors the real/complex case - coefficient updates in companion\ncoordinates, followed by a similarity back - yet avoids determinants,\ncharacteristic/minimal polynomials, and Cayley-Hamilton identities that do not\ntransfer to quaternions. We also give an Ackermann-type construction for the\nimportant case of closed-loop companion polynomials with real coefficients,\nensuring similarity-equivariant evaluation. The results yield simple recipes\nfor full-order observers directly over quaternions, clarify the role of right\nspectra and their similarity classes, and pinpoint when classical one-shot\nformulas remain valid. Numerical examples illustrate the method and advantages\nover vectorized or complex-adjoint surrogates."}
{"id": "2510.15861", "categories": ["math.OC", "90C11, 90C15, 90C26"], "pdf": "https://arxiv.org/pdf/2510.15861", "abs": "https://arxiv.org/abs/2510.15861", "authors": ["Danial Davarnia", "Hamed Rahimian"], "title": "A Unifying Convexification Framework for Chance-Constrained Programs via Bilinear Extended Formulations over a Simplex", "comment": null, "summary": "Chance-constrained programming is a widely used framework for decision-making\nunder uncertainty, yet its mixed-integer reformulations involve nonconvex\nmixing sets with a knapsack constraint, leading to weak relaxations and\ncomputational challenges. Most existing approaches for strengthening the\nrelaxations of these sets rely primarily on extensions of a specific class of\nvalid inequalities, limiting both convex hull coverage and the discovery of\nfundamentally new structures. In this paper, we develop a novel convexification\nframework that reformulates chance-constrained sets as bilinear sets over a\nsimplex in a lifted space and employs a step-by-step aggregation procedure to\nderive facet-defining inequalities in the original space of variables. Our\napproach generalizes and unifies established families of valid inequalities in\nthe literature while introducing new ones that capture substantially larger\nportions of the convex hull. Main contributions include: (i) the development of\na new aggregation-based convexification technique for bilinear sets over a\nsimplex in a lower-dimensional space; (ii) the introduction of a novel bilinear\nreformulation of mixing sets with a knapsack constraint -- arising from\nsingle-row relaxations of chance constraints -- over a simplex, which enables\nthe systematic derivation of strong inequalities in the original variable\nspace; and (iii) the characterization of facet-defining inequalities within a\nunified framework that contains both existing and new families. Preliminary\ncomputational experiments demonstrate that our inequalities describe over 90\\%\nof the facet-defining inequalities of the convex hull of benchmark instances,\nsignificantly strengthening existing relaxations and advancing the polyhedral\nunderstanding of chance-constrained programs."}
{"id": "2510.15734", "categories": ["math.OC", "cs.NA", "math.NA", "49K10, 65K05, 65Y20, 68Q25, 90C05, 90C30, 90C51"], "pdf": "https://arxiv.org/pdf/2510.15734", "abs": "https://arxiv.org/abs/2510.15734", "authors": ["Stephen J. Wright"], "title": "Optimization in Theory and Practice", "comment": null, "summary": "Algorithms for continuous optimization problems have a rich history of design\nand innovation over the past several decades, in which mathematical analysis of\ntheir convergence and complexity properties plays a central role. Besides their\ntheoretical properties, optimization algorithms are interesting also for their\npractical usefulness as computational tools for solving real-world problems.\nThere are often gaps between the practical performance of an algorithm and what\ncan be proved about it. These two facets of the field -- the theoretical and\nthe practical -- interact in fascinating ways, each driving innovation in the\nother. This work focuses on the development of algorithms in two areas --\nlinear programming and unconstrained minimization of smooth functions --\noutlining major algorithm classes in each area along with their theoretical\nproperties and practical performance, and highlighting how advances in theory\nand practice have influenced each other in these areas. In discussing theory,\nwe focus mainly on non-asymptotic complexity, which are upper bounds on the\namount of computation required by a given algorithm to find an approximate\nsolution of problems in a given class."}
{"id": "2510.15613", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15613", "abs": "https://arxiv.org/abs/2510.15613", "authors": ["Clément Moureau", "Thomas Stegen", "Mevludin Glavic", "Bertrand Cornélusse"], "title": "A Predictive Flexibility Aggregation Method for Low Voltage Distribution System Control", "comment": "8 pages, 6 figures", "summary": "This paper presents a predictive control strategy to manage low-voltage\ndistribution systems. The proposed approach relies on an aggregate of the\nflexibility at the residential unit level into a three-dimensional chart that\nrepresents the injected active and reactive power, and the flexibility cost.\nFirst, this method solves a multiparametric optimization problem offline at the\nresidential unit level to aggregate the flexibility of the assets. Then, a\nsemi-explicit model predictive control problem is solved to account for\nforecasts. By combining the results of these problems with measurements, the\nmethod generates the desired flexibility chart. The proposed approach is\ncompatible with realtime control requirements, as heavy computations are\nperformed offline locally, making it naturally parallelizable. By linking\nrealtime flexibility assessment with energy scheduling, our approach enables\nefficient, low-cost, and privacy-preserving management of low-voltage\ndistribution systems. We validate this method on a low-voltage network of 5\nbuses by comparing it with an ideal technique."}
{"id": "2510.15613", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15613", "abs": "https://arxiv.org/abs/2510.15613", "authors": ["Clément Moureau", "Thomas Stegen", "Mevludin Glavic", "Bertrand Cornélusse"], "title": "A Predictive Flexibility Aggregation Method for Low Voltage Distribution System Control", "comment": "8 pages, 6 figures", "summary": "This paper presents a predictive control strategy to manage low-voltage\ndistribution systems. The proposed approach relies on an aggregate of the\nflexibility at the residential unit level into a three-dimensional chart that\nrepresents the injected active and reactive power, and the flexibility cost.\nFirst, this method solves a multiparametric optimization problem offline at the\nresidential unit level to aggregate the flexibility of the assets. Then, a\nsemi-explicit model predictive control problem is solved to account for\nforecasts. By combining the results of these problems with measurements, the\nmethod generates the desired flexibility chart. The proposed approach is\ncompatible with realtime control requirements, as heavy computations are\nperformed offline locally, making it naturally parallelizable. By linking\nrealtime flexibility assessment with energy scheduling, our approach enables\nefficient, low-cost, and privacy-preserving management of low-voltage\ndistribution systems. We validate this method on a low-voltage network of 5\nbuses by comparing it with an ideal technique."}
{"id": "2510.15097", "categories": ["math.NA", "cs.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.15097", "abs": "https://arxiv.org/abs/2510.15097", "authors": ["Kazufumi Ito", "Tiancheng Xue"], "title": "Reduced order method based Anderson-type acceleration method for nonlinear least square problems and large scale ill-posed problems", "comment": null, "summary": "In this paper we discuss the Anderson's type acceleration method for\nnumerical optimizations. Most mathematical modeling problems can be formulated\nas constrained optimization. The necessary optimality condition is written as a\nfixed point problem in a Banach space. Anderson's acceleration method improves\nthe convergence of the standard fixed point iteration by minimizing the total\nsum of residuals and updating solutions through an optimal linear combination\nof a sequence of iterates. Thus, it is a form of iterative method of retard\nwhich uses the history of solutions as a reduced order element method (ROM).\nThe weights are determined optimally by the least squares problem based on the\ntotal residual. We analyze Anderson's method and the reduced order method (ROM)\nfor nonlinear least squares problems of minimizing |F(x)| squared. That is, the\nsolution is approximated by a linear combination of sequentially generated\nsolutions, and then we minimize the equation error on the linear manifold\nspanned by the iterates. We use the reduced order Gauss Newton method to solve\nthe least squares problem for |F(x)| squared on the linear solution manifold.\nFor the linear equation case it is similar to Anderson's method. Anderson's\nmethod approximates the solution to the nonlinear ROM. We consider variable\nstep size gradient and quasi Newton methods and the variable fixed point\niteration to generate the solution basis, then combine these with ROM\nacceleration. It converges very rapidly if the condition number of matrix A is\nnot large. The variable iterate with ROM acceleration is nearly optimal, and\nROM also regularizes and stabilizes the convergence. We also consider a\nrandomly overlapped Kaczmarz type method and develop an acceleration approach\nfor large scale ill posed linear systems. Finally, we analyze the convergence\nof the ROM to the operator equation."}
{"id": "2510.15695", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15695", "abs": "https://arxiv.org/abs/2510.15695", "authors": ["Sheng Wang", "Muhammad Maladoh Bah"], "title": "Cross-border offshore hydrogen trade and carbon mitigation for Europe's net zero transition", "comment": null, "summary": "European countries are ambitious in both the net-zero transition and offshore\nenergy resource development. The Irish and UK governments announced their\ncommitments to offshore wind capacities - 37 and 125 GW, respectively, in 2050,\nmore than two times higher than their projected power demands. While other\ncontinental countries, such as Germany, are calling for cleaner fuel resources.\nExporting surplus offshore green hydrogen and bridging supply and demand could\nbe pivotal in carbon emission mitigation for Europe. Yet, the potentials of\nthese Island countries, are usually underestimated. This paper developed a\nbottom-up method to investigate the role of offshore hydrogen from Ireland and\nthe UK in the decarbonisation of the entire Europe. We evaluate the future\nhydrogen/ammonia trading and the contributions of each country in carbon\nemission mitigation, considering their relative cost-competitiveness in\noffshore hydrogen production, domestic hourly power and gas system operation,\nand international shipping costs. Results indicate that the offshore green\nhydrogen could reduce 175.16 Mt/year of carbon dioxide emissions in Europe. The\nUK will be the largest hydrogen supplier from 2030 to 2040, while surpassed by\nIreland in 2050, with 161 TWh of hydrogen exports to France and Spain. The\noffshore green hydrogen can contribute to 175.16 Mt of annual carbon dioxide\nemission reductions in total. This general flow of hydrogen from the West to\nthe East not only facilitates Europe's net-zero progress, but also reshapes the\nenergy supply structure and helps to ensure energy security across the European\ncontinent."}
{"id": "2510.15695", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15695", "abs": "https://arxiv.org/abs/2510.15695", "authors": ["Sheng Wang", "Muhammad Maladoh Bah"], "title": "Cross-border offshore hydrogen trade and carbon mitigation for Europe's net zero transition", "comment": null, "summary": "European countries are ambitious in both the net-zero transition and offshore\nenergy resource development. The Irish and UK governments announced their\ncommitments to offshore wind capacities - 37 and 125 GW, respectively, in 2050,\nmore than two times higher than their projected power demands. While other\ncontinental countries, such as Germany, are calling for cleaner fuel resources.\nExporting surplus offshore green hydrogen and bridging supply and demand could\nbe pivotal in carbon emission mitigation for Europe. Yet, the potentials of\nthese Island countries, are usually underestimated. This paper developed a\nbottom-up method to investigate the role of offshore hydrogen from Ireland and\nthe UK in the decarbonisation of the entire Europe. We evaluate the future\nhydrogen/ammonia trading and the contributions of each country in carbon\nemission mitigation, considering their relative cost-competitiveness in\noffshore hydrogen production, domestic hourly power and gas system operation,\nand international shipping costs. Results indicate that the offshore green\nhydrogen could reduce 175.16 Mt/year of carbon dioxide emissions in Europe. The\nUK will be the largest hydrogen supplier from 2030 to 2040, while surpassed by\nIreland in 2050, with 161 TWh of hydrogen exports to France and Spain. The\noffshore green hydrogen can contribute to 175.16 Mt of annual carbon dioxide\nemission reductions in total. This general flow of hydrogen from the West to\nthe East not only facilitates Europe's net-zero progress, but also reshapes the\nenergy supply structure and helps to ensure energy security across the European\ncontinent."}
{"id": "2510.15293", "categories": ["physics.comp-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.15293", "abs": "https://arxiv.org/abs/2510.15293", "authors": ["Zhexian Li", "Felipe de Barros", "Ketan Savla"], "title": "Constrained bilinear optimal control of reactive evolution equations", "comment": "38 pages, 7 figures", "summary": "We consider constrained bilinear optimal control of second-order linear\nevolution partial differential equations (PDEs) with a reaction term on the\nhalf line, where control arises as a time-dependent reaction coefficient and\nconstraints are imposed on the state and control variables. These PDEs\nrepresent a wide range of physical phenomena in fluid flow, heat, and mass\ntransfer. Existing computational methods for this type of control problems only\nconsider constraints on control variables. In this paper, we propose a novel\noptimize-then-discretize framework for computing constrained bilinear optimal\ncontrol with both state and control constraints. Unlike existing methods that\nderive optimality conditions directly from the PDE constraint, this framework\nfirst replaces the PDE constraint with an equivalent integral representation of\nthe PDE solution. The integral representation, derived from the unified\ntransform method, does not involve differential operators, and thus explicit\nexpressions for necessary conditions of optimality can be derived using the\nKarush-Kuhn-Tucker conditions for infinite-dimensional optimization.\nDiscretizing the optimality conditions results in a system of\nfinite-dimensional smooth nonlinear equations, which can be efficiently solved\nusing existing solvers without the need for specialized algorithms. This is in\ncontrast with discretize-then-optimize methods that discretize the PDE first\nand then solve the optimality conditions of the approximated finite-dimensional\nproblem. Computational results for two applications, namely nuclear reactivity\ncontrol and water quality treatment in a reactor, are presented to illustrate\nthe effectiveness of the proposed framework."}
{"id": "2510.15707", "categories": ["eess.SY", "cs.SY", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.15707", "abs": "https://arxiv.org/abs/2510.15707", "authors": ["Martín de Frutos", "Laura Botero-Bolívar", "Esteban Ferrer"], "title": "Mitigating Underwater Noise from Offshore Wind Turbines via Individual Pitch Control", "comment": null, "summary": "This paper proposes a pitch control strategy to mitigate the underwater\nacoustic footprint of offshore wind turbines, a measure that will soon become\nnecessary to minimize impacts on marine life, which rely on sound for\ncommunication, navigation, and survival. First, we quantify the underwater\nacoustic signature of blade-generated aerodynamic noise from three reference\nturbines, the NREL 5 MW, DTU 10 MW, and IEA 22 MW, using coupling blade element\nmomentum and coupled air-water acoustic propagation modeling. Second, we\npropose and implement an open-loop individual pitch control (IPC) strategy that\nmodulates the pitch of the blade at the blade passing frequency to attenuate\nthe overall sound pressure level (OSPL) and the amplitude modulation (AM) of\nthe transmitted noise. Third, we benchmark IPC performance against conventional\npitch schemes. The results indicate that up to 5 dB reductions in OSPL and a\ndecrease in AM depth 20% can be achieved with a pitch variation of\n$\\Delta\\theta\\approx 5^\\circ$, with small losses (5-10%) in energy capture.\nThese findings highlight a previously underappreciated noise pathway and\ndemonstrate that targeted blade-pitch modulation can mitigate its impact."}
{"id": "2510.15707", "categories": ["eess.SY", "cs.SY", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.15707", "abs": "https://arxiv.org/abs/2510.15707", "authors": ["Martín de Frutos", "Laura Botero-Bolívar", "Esteban Ferrer"], "title": "Mitigating Underwater Noise from Offshore Wind Turbines via Individual Pitch Control", "comment": null, "summary": "This paper proposes a pitch control strategy to mitigate the underwater\nacoustic footprint of offshore wind turbines, a measure that will soon become\nnecessary to minimize impacts on marine life, which rely on sound for\ncommunication, navigation, and survival. First, we quantify the underwater\nacoustic signature of blade-generated aerodynamic noise from three reference\nturbines, the NREL 5 MW, DTU 10 MW, and IEA 22 MW, using coupling blade element\nmomentum and coupled air-water acoustic propagation modeling. Second, we\npropose and implement an open-loop individual pitch control (IPC) strategy that\nmodulates the pitch of the blade at the blade passing frequency to attenuate\nthe overall sound pressure level (OSPL) and the amplitude modulation (AM) of\nthe transmitted noise. Third, we benchmark IPC performance against conventional\npitch schemes. The results indicate that up to 5 dB reductions in OSPL and a\ndecrease in AM depth 20% can be achieved with a pitch variation of\n$\\Delta\\theta\\approx 5^\\circ$, with small losses (5-10%) in energy capture.\nThese findings highlight a previously underappreciated noise pathway and\ndemonstrate that targeted blade-pitch modulation can mitigate its impact."}
{"id": "2510.15603", "categories": ["math.NA", "cs.NA", "math.OC", "35Q91, 49J20, 49LXX, 82C31, 65C35"], "pdf": "https://arxiv.org/pdf/2510.15603", "abs": "https://arxiv.org/abs/2510.15603", "authors": ["Elisabetta Carlini", "Luca Saluzzi"], "title": "High order Tensor-Train-Based Schemes for High-Dimensional Mean Field Games", "comment": null, "summary": "We introduce a fully discrete scheme to solve a class of high-dimensional\nMean Field Games systems. Our approach couples semi-Lagrangian (SL) time\ndiscretizations with Tensor-Train (TT) decompositions to tame the curse of\ndimensionality. By reformulating the classical Hamilton-Jacobi-Bellman and\nFokker-Planck equations as a sequence of advection-diffusion-reaction\nsubproblems within a smoothed policy iteration, we construct both first and\nsecond order in time SL schemes. The TT format and appropriate quadrature rules\nreduce storage and computational cost from exponential to polynomial in the\ndimension. Numerical experiments demonstrate that our TT-accelerated SL methods\nachieve their theoretical convergence rates, exhibit modest growth in memory\nusage and runtime with dimension, and significantly outperform grid-based SL in\naccuracy per CPU second."}
{"id": "2510.15708", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15708", "abs": "https://arxiv.org/abs/2510.15708", "authors": ["Thomas Bernard", "François Grondin", "Jean-Michel Lavoie"], "title": "Sugar Shack 4.0: Practical Demonstration of an IIoT-Based Event-Driven Automation System", "comment": "10 pages, 15 figures", "summary": "This paper presents a practical alternative to\nprogrammable-logic-controller-centric automation by implementing an\nevent-driven architecture built with industrial Internet of Things tools. A\nlayered design on a local edge server (i) abstracts actuators, (ii) enforces\nmutual exclusion of shared physical resources through an interlock with\npriority queueing, (iii) composes deterministic singular operations, and (iv)\norchestrates complete workflows as state machines in Node-RED, with\ncommunication over MQTT. The device layer uses low-cost ESP32-based gateways to\ninterface sensors and actuators, while all automation logic is offloaded to the\nserver side. As part of a larger project involving the first\nscientifically-documented integration of Industry 4.0 technologies in a maple\nsyrup boiling center, this work demonstrates the deployment of the proposed\nsystem as a case-study. Evaluation over an entire production season shows\nmedian message time of flight around one tenth of a second, command\nissuance-to-motion latencies of about two to three seconds, and command\ncompletion near six seconds dominated by actuator mechanics; operation runtimes\nspan tens of seconds to minutes. These results indicate that network and\norchestration overheads are negligible relative to process dynamics, enabling\nmodular, distributed control without compromising determinism or fault\nisolation. The approach reduces material and integration effort, supports\nportable containerized deployment, and naturally enables an edge/cloud split in\nwhich persistence and analytics are offloaded while automation remains at the\nedge."}
{"id": "2510.15708", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15708", "abs": "https://arxiv.org/abs/2510.15708", "authors": ["Thomas Bernard", "François Grondin", "Jean-Michel Lavoie"], "title": "Sugar Shack 4.0: Practical Demonstration of an IIoT-Based Event-Driven Automation System", "comment": "10 pages, 15 figures", "summary": "This paper presents a practical alternative to\nprogrammable-logic-controller-centric automation by implementing an\nevent-driven architecture built with industrial Internet of Things tools. A\nlayered design on a local edge server (i) abstracts actuators, (ii) enforces\nmutual exclusion of shared physical resources through an interlock with\npriority queueing, (iii) composes deterministic singular operations, and (iv)\norchestrates complete workflows as state machines in Node-RED, with\ncommunication over MQTT. The device layer uses low-cost ESP32-based gateways to\ninterface sensors and actuators, while all automation logic is offloaded to the\nserver side. As part of a larger project involving the first\nscientifically-documented integration of Industry 4.0 technologies in a maple\nsyrup boiling center, this work demonstrates the deployment of the proposed\nsystem as a case-study. Evaluation over an entire production season shows\nmedian message time of flight around one tenth of a second, command\nissuance-to-motion latencies of about two to three seconds, and command\ncompletion near six seconds dominated by actuator mechanics; operation runtimes\nspan tens of seconds to minutes. These results indicate that network and\norchestration overheads are negligible relative to process dynamics, enabling\nmodular, distributed control without compromising determinism or fault\nisolation. The approach reduces material and integration effort, supports\nportable containerized deployment, and naturally enables an edge/cloud split in\nwhich persistence and analytics are offloaded while automation remains at the\nedge."}
{"id": "2510.15740", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15740", "abs": "https://arxiv.org/abs/2510.15740", "authors": ["Geon Roh", "Jip Kim"], "title": "Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty", "comment": null, "summary": "Dynamic line rating (DLR) enables greater utilization of existing\ntransmission lines by leveraging real-time weather data. However, the elevated\ntemperature operation (ETO) of conductors under DLR is often overlooked,\ndespite its long-term impact on conductor health. This paper addresses this\nissue by 1) quantifying depreciation costs associated with ETO and 2) proposing\na Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs\nin operational decisions. The CHA-UC incorporates a robust linear approximation\nof conductor temperature and integration of expected depreciation costs due to\nhourly ETO into the objective function. Case studies on the Texas 123-bus\nbackbone test system using NOAA weather data demonstrate that the proposed\nCHA-UC model reduces the total cost by 0.8% and renewable curtailment by\n84%compared to static line rating (SLR), while conventional DLR operation\nwithout risk consideration resulted in higher costs due to excessive ETO.\nFurther analysis of the commitment decisions and the line temperature\nstatistics confirms that the CHA-UC achieves safer line flows by shifting\ngenerator commitments. Finally, we examine the emergent correlation between\nwind generation and DLR forecast errors, and show that CHA-UC adaptively\nmanages this effect by relaxing flows for risk-hedging conditions while\ntightening flows for risk-amplifying ones."}
{"id": "2510.15740", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15740", "abs": "https://arxiv.org/abs/2510.15740", "authors": ["Geon Roh", "Jip Kim"], "title": "Integrating Conductor Health into Dynamic Line Rating and Unit Commitment under Uncertainty", "comment": null, "summary": "Dynamic line rating (DLR) enables greater utilization of existing\ntransmission lines by leveraging real-time weather data. However, the elevated\ntemperature operation (ETO) of conductors under DLR is often overlooked,\ndespite its long-term impact on conductor health. This paper addresses this\nissue by 1) quantifying depreciation costs associated with ETO and 2) proposing\na Conductor Health-Aware Unit Commitment (CHA-UC) that internalizes these costs\nin operational decisions. The CHA-UC incorporates a robust linear approximation\nof conductor temperature and integration of expected depreciation costs due to\nhourly ETO into the objective function. Case studies on the Texas 123-bus\nbackbone test system using NOAA weather data demonstrate that the proposed\nCHA-UC model reduces the total cost by 0.8% and renewable curtailment by\n84%compared to static line rating (SLR), while conventional DLR operation\nwithout risk consideration resulted in higher costs due to excessive ETO.\nFurther analysis of the commitment decisions and the line temperature\nstatistics confirms that the CHA-UC achieves safer line flows by shifting\ngenerator commitments. Finally, we examine the emergent correlation between\nwind generation and DLR forecast errors, and show that CHA-UC adaptively\nmanages this effect by relaxing flows for risk-hedging conditions while\ntightening flows for risk-amplifying ones."}
{"id": "2510.15797", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15797", "abs": "https://arxiv.org/abs/2510.15797", "authors": ["Laszlo Gacsi", "Adam K. Kiss", "Tamas G. Molnar"], "title": "Braking within Barriers: Constructive Safety-Critical Control for Input-Constrained Vehicles via the Backup Set Method", "comment": "Submitted to the IEEE Transactions on Automation Science and\n  Engineering. 14 pages, 10 figures", "summary": "This paper presents a safety-critical control framework to maintain bounded\nlateral motions for vehicles braking on asymmetric surfaces. We synthesize a\nbrake controller that assists drivers and guarantees safety against excessive\nlateral motions (i.e., prevents the vehicle from spinning out) while minimizing\nthe stopping distance. We address this safety-critical control problem in the\npresence of input constraints, since braking forces are limited by the\navailable friction on the road. We use backup control barrier functions for\nsafe control design. As this approach requires the construction of a backup set\nand a backup controller, we propose a novel, systematic method to creating\nvalid backup set-backup controller pairs based on feedback linearization and\ncontinuous-time Lyapunov equations. We use simple examples to demonstrate our\nproposed safety-critical control method. Finally, we implement our approach on\na four-wheel vehicle model for braking on asymmetric surfaces and present\nsimulation results."}
{"id": "2510.15797", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15797", "abs": "https://arxiv.org/abs/2510.15797", "authors": ["Laszlo Gacsi", "Adam K. Kiss", "Tamas G. Molnar"], "title": "Braking within Barriers: Constructive Safety-Critical Control for Input-Constrained Vehicles via the Backup Set Method", "comment": "Submitted to the IEEE Transactions on Automation Science and\n  Engineering. 14 pages, 10 figures", "summary": "This paper presents a safety-critical control framework to maintain bounded\nlateral motions for vehicles braking on asymmetric surfaces. We synthesize a\nbrake controller that assists drivers and guarantees safety against excessive\nlateral motions (i.e., prevents the vehicle from spinning out) while minimizing\nthe stopping distance. We address this safety-critical control problem in the\npresence of input constraints, since braking forces are limited by the\navailable friction on the road. We use backup control barrier functions for\nsafe control design. As this approach requires the construction of a backup set\nand a backup controller, we propose a novel, systematic method to creating\nvalid backup set-backup controller pairs based on feedback linearization and\ncontinuous-time Lyapunov equations. We use simple examples to demonstrate our\nproposed safety-critical control method. Finally, we implement our approach on\na four-wheel vehicle model for braking on asymmetric surfaces and present\nsimulation results."}
{"id": "2510.15847", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15847", "abs": "https://arxiv.org/abs/2510.15847", "authors": ["Panos C. Papageorgiou", "Anastasios E. Giannopoulos", "Sotirios T. Spantideas"], "title": "Bio-inspired Microgrid Management based on Brain's Sensorimotor Gating", "comment": null, "summary": "Microgrids are emerging as key enablers of resilient, sustainable, and\nintelligent power systems, but they continue to face challenges in dynamic\ndisturbance handling, protection coordination, and uncertainty. Recent efforts\nhave explored Brain Emotional Learning (BEL) controllers as bio-inspired\nsolutions for microgrid control. Building on this growing trajectory, this\narticle introduces a new paradigm for Neuro-Microgrids, inspired by the brain's\nsensorimotor gating mechanisms, specifically the Prepulse Inhibition (PPI) and\nPrepulse Facilitation (PPF). Sensorimotor gating offers a biological model for\nselectively suppressing or amplifying responses depending on contextual\nrelevance. By mapping these principles onto the hierarchical control\narchitecture of microgrids, we propose a Sensorimotor Gating-Inspired\nNeuro-Microgrid (SG-NMG) framework. In this architecture, PPI-like control\ndecisions correspond to protective damping in primary and secondary management\nof microgrids, whereas PPF-like decisions correspond to adaptive amplification\nof corrective control actions. The framework is presented through analytical\nworkflow design, neuro-circuitry analogies, and integration with machine\nlearning methods. Finally, open challenges and research directions are\noutlined, including the mathematical modeling of gating, digital twin\nvalidation, and cross-disciplinary collaboration between neuroscience and\nindustrial power systems. The resulting paradigm highlights sensorimotor gating\nas a promising framework for designing self-protective, adaptive, and resilient\nmicrogrids."}
{"id": "2510.15847", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.15847", "abs": "https://arxiv.org/abs/2510.15847", "authors": ["Panos C. Papageorgiou", "Anastasios E. Giannopoulos", "Sotirios T. Spantideas"], "title": "Bio-inspired Microgrid Management based on Brain's Sensorimotor Gating", "comment": null, "summary": "Microgrids are emerging as key enablers of resilient, sustainable, and\nintelligent power systems, but they continue to face challenges in dynamic\ndisturbance handling, protection coordination, and uncertainty. Recent efforts\nhave explored Brain Emotional Learning (BEL) controllers as bio-inspired\nsolutions for microgrid control. Building on this growing trajectory, this\narticle introduces a new paradigm for Neuro-Microgrids, inspired by the brain's\nsensorimotor gating mechanisms, specifically the Prepulse Inhibition (PPI) and\nPrepulse Facilitation (PPF). Sensorimotor gating offers a biological model for\nselectively suppressing or amplifying responses depending on contextual\nrelevance. By mapping these principles onto the hierarchical control\narchitecture of microgrids, we propose a Sensorimotor Gating-Inspired\nNeuro-Microgrid (SG-NMG) framework. In this architecture, PPI-like control\ndecisions correspond to protective damping in primary and secondary management\nof microgrids, whereas PPF-like decisions correspond to adaptive amplification\nof corrective control actions. The framework is presented through analytical\nworkflow design, neuro-circuitry analogies, and integration with machine\nlearning methods. Finally, open challenges and research directions are\noutlined, including the mathematical modeling of gating, digital twin\nvalidation, and cross-disciplinary collaboration between neuroscience and\nindustrial power systems. The resulting paradigm highlights sensorimotor gating\nas a promising framework for designing self-protective, adaptive, and resilient\nmicrogrids."}
{"id": "2510.15166", "categories": ["math.OC", "cs.SY", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.15166", "abs": "https://arxiv.org/abs/2510.15166", "authors": ["Masih Haseli", "Igor Mezić", "Jorge Cortés"], "title": "Two Roads to Koopman Operator Theory for Control: Infinite Input Sequences and Operator Families", "comment": null, "summary": "The Koopman operator, originally defined for dynamical systems without input,\nhas inspired many applications in control. Yet, the theoretical foundations\nunderpinning this progress in control remain underdeveloped. This paper\ninvestigates the theoretical structure and connections between two extensions\nof Koopman theory to control: (i) Koopman operator via infinite input sequences\nand (ii) the Koopman control family. Although these frameworks encode system\ninformation in fundamentally different ways, we show that under certain\nconditions on the function spaces they operate on, they are equivalent. The\nequivalence is both in terms of the actions of the Koopman-based formulations\nin each framework as well as the function values on the system trajectories.\nOur analysis provides constructive tools to translate between the frameworks,\noffering a unified perspective for Koopman methods in control."}
{"id": "2510.15166", "categories": ["math.OC", "cs.SY", "eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.15166", "abs": "https://arxiv.org/abs/2510.15166", "authors": ["Masih Haseli", "Igor Mezić", "Jorge Cortés"], "title": "Two Roads to Koopman Operator Theory for Control: Infinite Input Sequences and Operator Families", "comment": null, "summary": "The Koopman operator, originally defined for dynamical systems without input,\nhas inspired many applications in control. Yet, the theoretical foundations\nunderpinning this progress in control remain underdeveloped. This paper\ninvestigates the theoretical structure and connections between two extensions\nof Koopman theory to control: (i) Koopman operator via infinite input sequences\nand (ii) the Koopman control family. Although these frameworks encode system\ninformation in fundamentally different ways, we show that under certain\nconditions on the function spaces they operate on, they are equivalent. The\nequivalence is both in terms of the actions of the Koopman-based formulations\nin each framework as well as the function values on the system trajectories.\nOur analysis provides constructive tools to translate between the frameworks,\noffering a unified perspective for Koopman methods in control."}
{"id": "2510.15251", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15251", "abs": "https://arxiv.org/abs/2510.15251", "authors": ["Yingrui Zhuang", "Lin Cheng", "Ning Qi", "Mads R. Almassalkhi", "Feng Liu"], "title": "An Iterative Problem-Driven Scenario Reduction Framework for Stochastic Optimization with Conditional Value-at-Risk", "comment": null, "summary": "Scenario reduction (SR) alleviates the computational complexity of\nscenario-based stochastic optimization with conditional value-at-risk\n(SBSO-CVaR) by identifying representative scenarios to depict the underlying\nuncertainty and tail risks. Existing distribution-driven SR methods emphasize\nstatistical similarity but often exclude extreme scenarios, leading to weak\ntail-risk awareness and insufficient problem-specific representativeness.\nInstead, this paper proposes an iterative problem-driven scenario reduction\nframework. Specifically, we integrate the SBSO-CVaR problem structure into SR\nprocess and project the original scenario set from the distribution space onto\nthe problem space. Subsequently, to minimize the SR optimality gap with\nacceptable computation complexity, we propose a tractable iterative\nproblem-driven scenario reduction (IPDSR) method that selects representative\nscenarios that best approximate the optimality distribution of the original\nscenario set while preserving tail risks. Furthermore, the iteration process is\nrendered as a mixed-integer program to enable scenario partitioning and\nrepresentative scenarios selection. And ex-post problem-driven evaluation\nindices are proposed to evaluate the SR performance. Numerical experiments show\nIPDSR significantly outperforms existing SR methods by achieving an optimality\ngap of less than 1% within an acceptable computation time."}
{"id": "2510.15251", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.15251", "abs": "https://arxiv.org/abs/2510.15251", "authors": ["Yingrui Zhuang", "Lin Cheng", "Ning Qi", "Mads R. Almassalkhi", "Feng Liu"], "title": "An Iterative Problem-Driven Scenario Reduction Framework for Stochastic Optimization with Conditional Value-at-Risk", "comment": null, "summary": "Scenario reduction (SR) alleviates the computational complexity of\nscenario-based stochastic optimization with conditional value-at-risk\n(SBSO-CVaR) by identifying representative scenarios to depict the underlying\nuncertainty and tail risks. Existing distribution-driven SR methods emphasize\nstatistical similarity but often exclude extreme scenarios, leading to weak\ntail-risk awareness and insufficient problem-specific representativeness.\nInstead, this paper proposes an iterative problem-driven scenario reduction\nframework. Specifically, we integrate the SBSO-CVaR problem structure into SR\nprocess and project the original scenario set from the distribution space onto\nthe problem space. Subsequently, to minimize the SR optimality gap with\nacceptable computation complexity, we propose a tractable iterative\nproblem-driven scenario reduction (IPDSR) method that selects representative\nscenarios that best approximate the optimality distribution of the original\nscenario set while preserving tail risks. Furthermore, the iteration process is\nrendered as a mixed-integer program to enable scenario partitioning and\nrepresentative scenarios selection. And ex-post problem-driven evaluation\nindices are proposed to evaluate the SR performance. Numerical experiments show\nIPDSR significantly outperforms existing SR methods by achieving an optimality\ngap of less than 1% within an acceptable computation time."}
