<div id=toc></div>

# Table of Contents

- [math.ST](#math.ST) [Total: 2]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [cs.CE](#cs.CE) [Total: 3]
- [cs.SI](#cs.SI) [Total: 2]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 10]
- [eess.SY](#eess.SY) [Total: 12]
- [hep-lat](#hep-lat) [Total: 3]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [quant-ph](#quant-ph) [Total: 52]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 3]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [nlin.CD](#nlin.CD) [Total: 2]
- [math.OC](#math.OC) [Total: 7]
- [physics.hist-ph](#physics.hist-ph) [Total: 1]
- [stat.ME](#stat.ME) [Total: 12]
- [math.NA](#math.NA) [Total: 11]


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [1] [Support Recovery and $\ell_2$-Error Bound for Sparse Regression with Quadratic Measurements via Weakly-Convex-Concave Regularization](https://arxiv.org/abs/2602.17466)
*Jun Fan,Jingyu Yang,Xinyu Zhang,Liqun Wang*

Main category: math.ST

TL;DR: 本文研究了高维二次测量模型中弱凸-凹正则化估计器的有限样本性质，提出了一种基于弱凸-凹惩罚最小二乘的方法，并建立了局部极小值的支持恢复和ℓ2误差界。


<details>
  <summary>Details</summary>
Motivation: 在相位恢复、电力系统状态估计和无标签距离几何等问题中，从二次测量中恢复未知信号具有广泛应用，但高维情形下的统计推断仍具挑战性。

Method: 采用弱凸-凹惩罚最小二乘方法，结合两种近端梯度算法求解优化问题，其中近端步长根据正则化函数选择闭式解或加权ℓ1近似。

Result: 建立了局部极小值的支持恢复和ℓ2误差界，数值实验验证了所提方法的有效性。

Conclusion: 该方法在高维二次测量模型中具有良好的有限样本性能，能够有效实现信号恢复。

Abstract: The recovery of unknown signals from quadratic measurements finds extensive applications in fields such as phase retrieval, power system state estimation, and unlabeled distance geometry. This paper investigates the finite sample properties of weakly convex--concave regularized estimators in high-dimensional quadratic measurements models. By employing a weakly convex--concave penalized least squares approach, we establish support recovery and $\ell_2$-error bounds for the local minimizer. To solve the corresponding optimization problem, we adopt two proximal gradient strategies, where the proximal step is computed either in closed form or via a weighted $\ell_1$ approximation, depending on the regularization function. Numerical examples demonstrate the efficacy of the proposed method.

</details>


### [2] [Asymptotically Optimal Sequential Testing with Markovian Data](https://arxiv.org/abs/2602.17587)
*Alhad Sethi,Kavali Sofia Sagar,Shubhada Agrawal,Debabrota Basu,P. N. Karthik*

Main category: math.ST

TL;DR: 本文研究了由遍历性马尔可夫链生成数据的单边和α-正确序贯假设检验，提出了在备择假设下任意有效序贯检验停止时间的紧致非渐近实例依赖下界，并设计了一个在α趋近于0时达到该下界的最优检验方法。


<details>
  <summary>Details</summary>
Motivation: 现有的序贯假设检验下界多为渐近结果或在此设定下被证明是次优的，本文旨在建立更精确、更紧致的非渐近下界，并考虑马尔可夫链的平稳分布与转移结构对检验性能的影响。

Method: 通过分析遍历性马尔可夫链的平稳分布和转移结构，推导出在备择假设下任意有效序贯检验期望停止时间的非渐近实例依赖下界，并提出一种新的序贯检验方法，证明其在α→0时渐近达到该下界。

Result: 建立了首个同时融合平稳分布与转移结构信息的紧致非渐近下界，且所提出的检验方法在理论上达到了这一下界；并通过MCMC模型误设检测和马尔可夫决策过程中的结构性质检验验证了框架的有效性。

Conclusion: 本文为具有马尔可夫依赖结构的数据提供了最优序贯检验的精确刻画，所提出的下界和检验方法在理论和应用上均优于现有方法。

Abstract: We study one-sided and $α$-correct sequential hypothesis testing for data generated by an ergodic Markov chain. The null hypothesis is that the unknown transition matrix belongs to a prescribed set $P$ of stochastic matrices, and the alternative corresponds to a disjoint set $Q$. We establish a tight non-asymptotic instance-dependent lower bound on the expected stopping time of any valid sequential test under the alternative. Our novel analysis improves the existing lower bounds, which are either asymptotic or provably sub-optimal in this setting. Our lower bound incorporates both the stationary distribution and the transition structure induced by the unknown Markov chain. We further propose an optimal test whose expected stopping time matches this lower bound asymptotically as $α\to 0$. We illustrate the usefulness of our framework through applications to sequential detection of model misspecification in Markov Chain Monte Carlo and to testing structural properties, such as the linearity of transition dynamics, in Markov decision processes. Our findings yield a sharp and general characterization of optimal sequential testing procedures under Markovian dependence.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [3] [Weak 21st-century AMOC response to Greenland meltwater in a strongly eddying ocean model](https://arxiv.org/abs/2602.17235)
*Oliver Mehling,Henk A. Dijkstra*

Main category: physics.ao-ph

TL;DR: 首次在高分辨率海洋模型中量化了格陵兰融水对大西洋经向翻转环流（AMOC）的影响，发现其导致的AMOC减弱较小且与分辨率无关，而背景海洋状态起主导作用。


<details>
  <summary>Details</summary>
Motivation: 大多数气候模型忽略了格陵兰冰盖融水增加和中尺度海洋涡旋的影响，导致对未来AMOC变化预测存在高度不确定性，本文旨在评估格陵兰融水在高分辨率模型中对AMOC的影响。

Method: 使用强涡旋、1/10°水平分辨率的海洋模型，在SSP5-8.5强迫下，首次模拟并量化21世纪末前格陵兰融水对AMOC的影响，并比较高低分辨率下的响应差异。

Result: 格陵兰融水导致的AMOC额外减弱为0.6 ± 0.2 Sv，相对于仅由变暖引起的减弱较小；该效应在高、低分辨率模型中相似；相同融水量在当前气候条件下会导致更强的AMOC减弱；AMOC对融水响应的分辨率无关性和状态依赖性均受大尺度控制机制影响。

Conclusion: 背景海洋状态比模型分辨率更重要，决定了格陵兰融水对AMOC的影响程度。

Abstract: Climate models project that the Atlantic Meridional Overturning Circulation (AMOC) will weaken in the 21st century, but the magnitude is highly uncertain. Some of this uncertainty is structural, as most climate models neglect increasing meltwater from the Greenland ice sheet and do not explicitly capture mesoscale ocean eddies. Here, we quantify the impact of Greenland meltwater on the AMOC until 2100 under SSP5-8.5 forcing for the first time in a strongly eddying (1/10° horizontal resolution) ocean model. The meltwater-induced additional AMOC weakening is small (0.6 $\pm$ 0.2 Sv) compared to the weakening due to warming alone, and similar at high and low resolution. The same meltwater would cause a stronger AMOC weakening under present-day climate conditions. We link both resolution-independence and state-dependence to large-scale controls of the AMOC. Our results demonstrate that the background ocean state is more important than resolution in determining how Greenland meltwater affects the AMOC.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [4] [BEMEval-Doc2Schema: Benchmarking Large Language Models for Structured Data Extraction in Building Energy Modeling](https://arxiv.org/abs/2602.16926)
*Yiyuan Jia,Xiaoqin Fu,Liang Zhang*

Main category: cs.CE

TL;DR: BEMEval-Doc2Schema是首个面向建筑能源建模任务的基准框架，通过引入键值重叠率（KVOR）指标评估大语言模型在结构化数据提取中的表现，结果表明Gemini 2.5优于GPT-5，且少样本提示可提升性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏公开的任务特定数据集和标准化性能指标，基础模型在建筑能源建模中的系统性评估面临挑战，因此需要建立统一的评测框架。

Method: 提出BEMEval基准框架及其首个任务BEMEval-Doc2Schema，设计KVOR指标衡量LLM生成结构输出与真实模式的一致性，并在三个数据集上对GPT-5和Gemini 2.5进行零样本和少样本评估。

Result: Gemini 2.5在所有设置下均优于GPT-5，少样本提示能提高两者的准确性；EPC模式因结构更简单，得分显著高于HPXML。

Conclusion: BEMEval-Doc2Schema通过整合 curated 数据集、可复现指标和跨模型比较，建立了首个社区驱动的LLM for BEM评测基准，为AI辅助BEM研究奠定基础。

Abstract: Recent advances in foundation models, including large language models (LLMs), have created new opportunities to automate building energy modeling (BEM). However, systematic evaluation has remained challenging due to the absence of publicly available, task-specific datasets and standardized performance metrics. We present BEMEval, a benchmark framework designed to assess foundation models' performance across BEM tasks. The first benchmark in this suite, BEMEval-Doc2Schema, focuses on structured data extraction from building documentation, a foundational step toward automated BEM processes. BEMEval-Doc2Schema introduces the Key-Value Overlap Rate (KVOR), a metric that quantifies the alignment between LLM-generated structured outputs and ground-truth schema references. Using this framework, we evaluate two leading models (GPT-5 and Gemini 2.5) under zero-shot and few-shot prompting strategies across three datasets: HERS L100, NREL iUnit, and NIST NZERTF. Results show that Gemini 2.5 consistently outperforms GPT-5, and that few-shot prompts improve accuracy for both models. Performance also varies by schema: the EPC schema yields significantly higher KVOR scores than HPXML, reflecting its simpler and reduced hierarchical depth. By combining curated datasets, reproducible metrics, and cross-model comparisons, BEMEval-Doc2Schema establishes the first community-driven benchmark for evaluating LLMs in performing building energy modeling tasks, laying the groundwork for future research on AI-assisted BEM workflows.

</details>


### [5] [The Kinematics and Dynamics Theories of a Total Lagrangian Finite Element Analysis Framework for Finite Deformation Multibody Dynamics](https://arxiv.org/abs/2602.17002)
*Zhenhao Zhou,Ganesh Arivoli,Dan Negrut*

Main category: cs.CE

TL;DR: 提出了一种基于总拉格朗日有限元法（TL-FEA）的可变形体动力学建模方法，用于模拟受运动学约束、接触和摩擦作用下的大位移、大变形和大旋转问题。


<details>
  <summary>Details</summary>
Motivation: 为解决包含复杂相互作用与大变形的多体系统动力学仿真难题，需要一种能够处理非线性变形和多种约束的有效有限元框架。

Method: 采用总拉格朗日描述框架，推导了ANCF梁、壳和四面体单元的控制方程，并引入超弹性材料模型（如St. Venant-Kirchhoff和Mooney-Rivlin）及一致切线刚度矩阵；同时提出系统性的运动学约束分类与施加方法，并结合有限应变Kelvin-Voigt阻尼模型提升数值稳定性。

Result: 实现了对受约束、接触和摩擦作用下大变形可变形体系统的高效稳定动力学仿真，支持多种单元类型与非线性材料行为。

Conclusion: 该方法为多体系统中复杂变形与相互作用的联合仿真提供了统一且稳定的有限元解决方案，具有良好的扩展性和工程应用潜力。

Abstract: This work presents a Total Lagrangian finite element formulation for deformable body dynamics. We employ the TL-FEA framework to simulate the time evolution of collections of bodies whose motion is constrained by kinematic constraints and which mutually interact through contact and friction. These bodies experience large displacements, large deformations, and large rotations. A systematic approach is proposed for classifying and posing kinematic constraints acting between the bodies present in the system. We derive the governing equations for ANCF beam, ANCF shell, and tetrahedral elements, and present hyperelastic material models including St. Venant-Kirchhoff and Mooney-Rivlin formulations with their corresponding internal force contributions and consistent tangent stiffness matrices. A finite-strain Kelvin-Voigt viscous damping model is incorporated in the TL-FEA formulation for numerical stability.

</details>


### [6] [A variational multi-phase model for elastoplastic materials with microstructure evolution](https://arxiv.org/abs/2602.17492)
*Sarah Dinkelacker-Steinhoff,Klaus Hackl*

Main category: cs.CE

TL;DR: 提出了一种基于变分原理和线性运动硬化理论的弹塑性材料模型，用于描述相变过程中的微观结构演化。


<details>
  <summary>Details</summary>
Motivation: 为了描述弹塑性材料在相变过程中微观结构的连续演化，需结合能量耗散与相变动力学建立统一模型。

Method: 采用无穷小应变理论和变分原理，结合耗散距离与概率矩阵描述瞬时相变，并用Young测度表示新生相的体积分数，实现时间连续的微结构演化模拟。

Result: 通过有限元法实现二维基准测试，验证了该模型在模拟微结构演化方面的有效性。

Conclusion: 所提出的模型能够有效描述弹塑性材料在相变过程中的微观结构演化，为相关材料设计与分析提供了理论基础。

Abstract: A general model is formulated for elasto-plastic materials undergoing linear kinematic hardening to describe microstructure evolution associated with phase transformations. Using infinitesimal strain theory, the model is based on variational principles for inelastic materials.
  In our work we combine the so-called dissipation distance, which describes an immediate phase transition in time via an underlying probability matrix. In addition, the volume fractions of the newly emerging phases are represented by Young measures to obtain a time continuous microstructure evolution. The model is verified employing a two-dimensional benchmark test implemented by the Finite Element Method (FEM).

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [7] [Simplify to Amplify: Achieving Information-Theoretic Bounds with Fewer Steps in Spectral Community Detection](https://arxiv.org/abs/2602.17104)
*Sie Hendrata Dharmawan,Peter Chin*

Main category: cs.SI

TL;DR: 提出了一种简化的谱算法用于两社区随机块模型中的社区检测，在保持常数边密度假设下，通过直接利用邻接矩阵的谱性质，取得了接近信息论极限的误差界。


<details>
  <summary>Details</summary>
Motivation: 现有社区检测算法通常依赖复杂的预处理步骤，增加了计算开销；本文旨在通过简化算法流程，在降低复杂性的同时提升理论性能和实际效果。

Method: 提出一种简化的谱算法，省去非必要的预处理步骤，直接分析 adjacency matrix 的谱特性，特别利用第二特征值的性质进行社区划分。

Result: 理论上证明了该算法具有比现有方法更紧的误差界，实验验证也表明其在保持高效计算的同时显著提升了检测精度。

Conclusion: 算法简化不仅能提高计算效率，还能增强谱方法在社区检测中的性能，挑战了‘复杂即优’的传统认知。

Abstract: We propose a streamlined spectral algorithm for community detection in the two-community stochastic block model (SBM) under constant edge density assumptions. By reducing algorithmic complexity through the elimination of non-essential preprocessing steps, our method directly leverages the spectral properties of the adjacency matrix. We demonstrate that our algorithm exploits specific characteristics of the second eigenvalue to achieve improved error bounds that approach information-theoretic limits, representing a significant improvement over existing methods. Theoretical analysis establishes that our error rates are tighter than previously reported bounds in the literature. Comprehensive experimental validation confirms our theoretical findings and demonstrates the practical effectiveness of the simplified approach. Our results suggest that algorithmic simplification, rather than increasing complexity, can lead to both computational efficiency and enhanced performance in spectral community detection.

</details>


### [8] [NTLRAG: Narrative Topic Labels derived with Retrieval Augmented Generation](https://arxiv.org/abs/2602.17216)
*Lisa Grobelscheg,Ema Kahr,Mark Strembeck*

Main category: cs.SI

TL;DR: 本文提出了一种基于检索增强生成（NTLRAG）的叙事性主题标签生成框架，用于提升主题建模中标签的可解释性和可用性。


<details>
  <summary>Details</summary>
Motivation: 传统主题模型生成的关键词列表缺乏语义上下文，难以准确表达核心主题，用户难以理解。

Method: 提出NTLRAG框架，结合检索增强生成（RAG）技术与多种检索策略及思维链元素，为标准主题模型输出生成、验证和优化叙事性主题标签。

Result: 在超过670万条社交媒体消息和三个真实数据集上进行评估，并通过16名参与者的用户研究表明，叙事性标签在可解释性和可用性上优于传统关键词列表。

Conclusion: NTLRAG能有效生成语义精确、人类可读的叙事主题标签，显著提升主题模型结果的理解性与实用性。

Abstract: Topic modeling has evolved as an important means to identify evident or hidden topics within large collections of text documents. Topic modeling approaches are often used for analyzing and making sense of social media discussions consisting of millions of short text messages. However, assigning meaningful topic labels to document clusters remains challenging, as users are commonly presented with unstructured keyword lists that may not accurately capture the respective core topic. In this paper, we introduce Narrative Topic Labels derived with Retrieval Augmented Generation (NTLRAG), a scalable and extensible framework that generates semantically precise and human-interpretable narrative topic labels. Our narrative topic labels provide a context-rich, intuitive concept to describe topic model output. In particular, NTLRAG uses retrieval augmented generation (RAG) techniques and considers multiple retrieval strategies as well as chain-of-thought elements to provide high-quality output. NTLRAG can be combined with any standard topic model to generate, validate, and refine narratives which then serve as narrative topic labels. We evaluated NTLRAG with a user study and three real-world datasets consisting of more than 6.7 million social media messages that have been sent by more than 2.7 million users. The user study involved 16 human evaluators who found that our narrative topic labels offer superior interpretability and usability as compared to traditional keyword lists. An implementation of NTLRAG is publicly available for download.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [9] [Singular three-point density correlations in two-dimensional Fermi liquids](https://arxiv.org/abs/2602.16774)
*Pok Man Tam,Charles L. Kane*

Main category: cond-mat.str-el

TL;DR: 本文研究了二维相互作用费米液体中等时三点密度关联的奇异性，发现其在动量空间中表现为|q₁×q₂|形式，并在长波长共线极限下清晰定义。对于无相互作用费米气体，该奇异性系数由费米海的量子化欧拉特征数给出，并导致实空间中对共线构型的长程关联。文章进一步证明，这种奇异性在相互作用费米液体中仍然存在，并用朗道参数表达了其系数的重整化，讨论了对量子气体实验的影响。


<details>
  <summary>Details</summary>
Motivation: 理解二维费米液体中多体相互作用下的非平庸关联特性，特别是高阶密度关联函数中的普适奇异性行为，是凝聚态物理的重要问题。本文旨在揭示一种在等时三点密度关联中普遍存在的奇异性，并探索其在无相互作用与相互作用情况下的拓扑与动力学起源。

Method: 通过解析计算动量空间中的三点密度关联函数，分析其在长波长共线极限下的渐进行为；利用费米海的几何性质（如欧拉特征数）解释无相互作用情形下的系数量化现象；结合费米液体理论，使用Landau参数描述相互作用对奇异性系数的重整化效应。

Result: 发现了二维费米液体中三点密度关联函数中形如|q₁×q₂|的普适奇异性；明确了该奇异性在长波长共线极限下被良好定义；证明了无相互作用情况下奇异性系数等于费米海的量子化欧拉特征数；推导出相互作用下该系数通过Landau参数发生重整化，适用于有无自旋的情况。

Conclusion: 二维费米液体中的三点密度关联展现出由几何与拓扑决定的普适奇异性，该奇异性在相互作用下依然稳健，且其强度可通过朗道费米液体理论进行系统修正，为实验探测费米液体中的高阶关联提供了理论依据。

Abstract: We characterize a singularity in the equal-time three-point density correlations that is generic to two-dimensional interacting Fermi liquids. In momentum space where the three-point correlation is determined by two wavevectors $\mathbf{q}_1$ and $\mathbf{q}_2$, the singularity takes the form $|\mathbf{q}_1\times\mathbf{q}_2|$. We explain how this singularity is sharply defined in a long-wavelength collinear limit. For a non-interacting Fermi gas, the coefficient of this singularity is given by the quantized Euler characteristic of the Fermi sea, and it implies a long-range real space correlation favoring collinear configurations. We show that this singularity persists in interacting Fermi liquids, and express the renormalization of the coefficient of singularity in terms of Landau parameters, for both spinless and spinful Fermi liquids. Implications for quantum gas experiments are discussed.

</details>


### [10] [Magnetoelectric Raman Force on Shear Phonons in a Frustrated van der Waals Bilayer Magnet](https://arxiv.org/abs/2602.16785)
*Wolfram Brenig*

Main category: cond-mat.str-el

TL;DR: 本文研究了在受挫量子磁体中通过入射电场激光的二阶响应产生相干声子的可能性，扩展了传统固体泵浦-探测光谱中的概念。


<details>
  <summary>Details</summary>
Motivation: 将相干声子生成机制从传统固体推广到受挫量子磁体系统，探索新的磁电耦合效应。

Method: 分析受挫磁电双层自旋系统中剪切声子的拉曼力，采用线性自旋波理论处理磁振子激发，并基于磁弹性能推导声子-磁振子散射。

Result: 发现拉曼力对应的三阶混合响应函数具有强各向异性和对磁振子寿命的高度敏感性。

Conclusion: 受挫量子磁体中可通过光场诱导的磁电耦合实现相干声子调控，为超快磁电控制提供了新途径。

Abstract: We show that the concept of coherent phonon generation by second order response to incident electric laser fields, which is a hallmark of pump-probe spectroscopy on conventional solids, can be expanded to include frustrated quantum magnets. For that purpose, we analyze the Raman force on the shear phonons of a frustrated magnetoelectric bilayer spin system. The bilayer is a stacked triangular magnet, motivated by recently emerging type-II van der Waals multiferroic transition metal dihalides and comprises a spin system which allows for incommensurate spiral order. The magnon excitations are treated by linear spin wave theory. In the spiral state, a finite electric polarization is obtained from the spin-current interaction which induces a coupling of the magnons to the electric field. Scattering of the bilayer shear phonons from the magnons is derived from a magnetoelastic energy. In this scenario, a mixed three-point response function for the Raman force is evaluated. We find it to be strongly anisotropic and very sensitive to the magnon lifetime.

</details>


### [11] [Ground State of BaFe2S3 from Lattice and Spin Dynamics](https://arxiv.org/abs/2602.16899)
*Y. Oubaid,S. Deng,NS. Dhami,M. Verseils,D. Bounoua,A. Forget,D. Colson,P. Foury-Leylekian,M. B. Lepetit,V. Balédent*

Main category: cond-mat.str-el

TL;DR: 本研究通过结合偏振同步辐射红外光谱、杂化泛函密度泛函理论计算和非弹性中子散射，揭示了准一维阶梯化合物BaFe₂S₃中晶格对称性、声子与磁性的相互作用。发现低温下晶体对称性低于先前认为的P1空间群，多个红外活性声子模式在结构相变温度（TS ≈ 125–130 K）和奈尔温度（TN ≈ 95 K）表现出显著异常。第一性原理计算表明，在TS处受影响的模式主要涉及调制磁交换路径的位移。中子散射显示，低于TN时磁序是三维长程静态的，而在TN与TS之间存在三维短程动态磁关联，且在TS以上消失。这表明结构相变与磁涨落的出现相关，而非静态磁序，揭示了短程动态磁关联足以驱动静态结构不稳定性，突显了铁基超导体中磁弹耦合在非巡游电子体系中的核心作用。


<details>
  <summary>Details</summary>
Motivation: 探究准一维铁基阶梯化合物BaFe₂S₃中晶格结构、磁性和声子之间的耦合机制，特别是结构相变是否由磁性涨落驱动，以拓展对铁基超导材料中磁弹耦合机制的理解，尤其是在强关联（Mott）体系中的表现。

Method: 结合偏振同步辐射红外光谱、杂化泛函密度泛函理论计算和非弹性中子散射三种手段：红外光谱用于探测声子模式随温度的异常行为；第一性原理计算分析晶格动力学及原子位移对磁交换路径的影响；中子散射测定磁序的维度、范围和动态特性。

Result: 发现BaFe₂S₃在低温下具有比以往认为更低的晶格对称性（P1空间群）；多个红外声子模式在TS和TN处出现明显异常；计算显示TS处的原子位移直接影响磁交换路径；中子散射证实低于TN为三维长程静态磁序，TN至TS间为三维短程动态磁关联，高于TS则完全消失；结构相变与磁涨落起始同步，而非静态磁序建立之时。

Conclusion: 短程、动态的磁关联足以驱动静态的结构不稳定性，提出一种类似于铁砷化物体系但存在于准一维Mott绝缘体中的磁驱动结构相变机制，强调磁弹耦合在非巡游电子铁基超导体系中的普遍重要性。

Abstract: We investigate the interplay between lattice symmetry, phonons, and magnetism in the quasi-one-dimensional ladder compound BaFe$_2$S$_3$ by combining polarized synchrotron infrared spectroscopy, hybrid-functional density functional theory calculations, and inelastic neutron scattering. Lattice-dynamics analysis reveals that the crystal symmetry is lower than previously proposed and is consistent with a $P1$ space group at low temperature. Several infrared-active phonon modes exhibit pronounced anomalies at both the structural transition temperature $T_S \approx 125$--$130$~K and the Néel temperature $T_N \approx 95$~K. First-principles calculations show that the modes affected at $T_S$ predominantly involve displacements that modulate magnetic exchange pathways. Neutron scattering demonstrates that below $T_N$ the magnetic order is three-dimensional, long-ranged, and static. Between $T_N$ and $T_S$, the system displays three-dimensional short-range dynamic magnetic correlations, which disappear above $T_S$. The structural transition thus coincides with the onset of magnetic fluctuations rather than with static magnetic order. Our results indicate that short-range, dynamical magnetic correlations are sufficient to drive a static structural instability, providing a magnetically driven mechanism reminiscent of the iron-pnictide 122 family, yet realized here in a quasi-one-dimensional Mott system. These findings highlight the central role of magnetoelastic coupling in iron-based superconductors beyond the itinerant regime.

</details>


### [12] [Phase transitions in coupled Ising chains and SO($N$)-symmetric spin chains](https://arxiv.org/abs/2602.17029)
*Yohei Fuji,Sylvain Capponi,Lukas Devos,Philippe Lecheminant*

Main category: cond-mat.str-el

TL;DR: 研究了(1+1)维场论中N个Ising共形场理论在竞争相关扰动下的量子相变性质，发现N=2和N=3时相变为连续，分别属于Ising和四态Potts普适类，而N≥4时变为一级相变，并将结果应用于具有SO(N)对称性的具体晶格模型。


<details>
  <summary>Details</summary>
Motivation: 探讨在竞争相互作用下，多副本Ising共形场理论中的量子相变行为，并检验SPT相之间相变临界性的猜想。

Method: 结合微扰重正化群分析和大规模矩阵乘积态模拟，系统研究相变性质随N的变化。

Result: N=2和N=3时相变连续，分别对应Ising和四态Potts普适类；N≥4时为一级相变。结果适用于SO(N)对称性自旋梯等具体模型。

Conclusion: 随着副本数N增加，量子相变从连续转变为一级，修正了关于SPT相变临界性的近期猜想。

Abstract: We investigate the nature of quantum phase transitions in a (1+1)-dimensional field theory composed of $N$ copies of the Ising conformal field theory interacting via competing relevant perturbations. The field theory governs the competition between a mass term and an interaction involving the product of $N$ order-parameter fields, which is realized, e.g. in coupled Ising chains, two-leg spin ladders, and SO($N$)-symmetric spin chains. By combining a perturbative renormalization group analysis and large-scale matrix-product state simulations, we systematically determine the nature of the phase transition as a function of $N$. For $N=2$ and $N=3$, we confirm that the transition is continuous, belonging to the Ising and four-state Potts universality classes, respectively. In contrast, for $N \ge 4$, our results provide compelling evidence that the transition becomes first order. We further apply these findings to specific lattice models with SO($N$) symmetry, including spin-$1/2$ and spin-$1$ two-leg ladders, that realize a direct transition between an SO($N$) symmetry-protected topological phase and a trivial phase. Our results refine a recent conjecture regarding the criticality of transitions between SPT phases.

</details>


### [13] [Ghost Embedding Bridging Chemistry and One-Body Theories](https://arxiv.org/abs/2602.17164)
*Carlos Mejuto-Zaera,Michele Fabrizio*

Main category: cond-mat.str-el

TL;DR: 提出了一种将强关联体系与准粒子有效单体图像联系起来的严格框架，并通过计算策略重新解释了Woodward-Hoffmann规则。


<details>
  <summary>Details</summary>
Motivation: 传统基于非相互作用轨道的现象学规则难以适用于强关联体系，需要建立能桥接强关联多体系统与可解释单体图像的新框架。

Method: 发展了一个严格的理论框架，结合鬼影Gutzwiller Ansatz的嵌入近似方法，实现对准粒子图像的有效构建和高效计算。

Result: 成功将Woodward-Hoffmann规则推广到强关联模型‘反应’中，验证了该准粒子描述在典型场景下的有效性与准确性。

Conclusion: 该工作为强关联体系建立了可解释的现象学规则基础，有望推动化学反应和材料设计新规则的发展。

Abstract: Phenomenological rules play a central role in the design of chemical reactions and materials with targeted properties. Typically, these are formulated heuristically in terms of non-interacting orbitals and bands, yet show remarkable accuracy in predicting the complex behavior of intrinsically interacting many-body systems. While their non-interacting formulation makes them easy to interpret, it potentially hinders the development of new rules for systems governed by strong correlation, such as transition metal-based materials. In this work, we present a rigorous framework that allows bridging between fully interacting, even strongly correlated, systems and an effective one-body picture in terms of quasiparticles. Further, we present a computational strategy to efficiently and accurately access the main components of such a description: the embedding approximation of the ghost Gutzwiller Ansatz. We illustrate the capabilities of this quasiparticle formulation on the Woodward-Hoffmann rules, and apply their reformulated version to toy ``reactions'' which exemplify the main scenarios covered by them.

</details>


### [14] [High-temperature $η$-pairing superconductivity in the photodoped Hubbard model](https://arxiv.org/abs/2602.17238)
*Lei Geng,Aaram J. Kim,Philipp Werner*

Main category: cond-mat.str-el

TL;DR: 研究了光掺杂Mott绝缘Hubbard模型中出现的超导性，利用稳态动力学平均场理论和高阶强耦合微扰求解器，获得了光诱导η配对超导的非平衡相图，并发现了具有高有效临界温度的超导态。


<details>
  <summary>Details</summary>
Motivation: 探索非平衡强关联体系中可控高温超导的新途径，区别于传统的s波或d波超导机制。

Method: 采用实频率轴上的稳态动力学平均场理论，并结合高阶强耦合微扰求解器进行计算。

Result: 得到了光诱导η配对超导的非平衡相图，发现显著的超导能隙及其在动量分辨谱函数和光学电导中的谱学特征。

Conclusion: 揭示了在非平衡条件下实现高有效临界温度超导的可能性，为调控强关联体系中的超导性提供了新思路。

Abstract: We investigate superconductivity emerging in the photodoped Mott insulating Hubbard model using steady-state dynamical mean-field theory implemented on the real-frequency axis. By employing high-order strong-coupling impurity solvers, we obtain the nonequilibrium phase diagram for photoinduced $η$-pairing superconductivity with a remarkably high effective critical temperature. We further identify a superconducting gap in the momentum-resolved spectral function and optical conductivity, providing spectroscopic signatures accessible to experiments. Our results highlight a route to a controllable form of high-temperature superconductivity in nonequilibrium strongly correlated systems, fundamentally distinct from the equilibrium $s$-wave pairing state in the attractive Hubbard model or cuprate-like $d$-wave superconductors.

</details>


### [15] [Orbital current signature using neutron diffraction](https://arxiv.org/abs/2602.17311)
*Dalila Bounoua,William Liège,Yvan Sidis,Philippe Bourges*

Main category: cond-mat.str-el

TL;DR: 本文综述了在多种关联电子材料中通过极化中子衍射观测到的轨道环流特征，并比较了局域磁矩与微观电流两种描述中子磁散射截面的方法及其差异。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示关联电子材料中轨道环流的存在及其对磁性的影响，推动对高温超导等量子现象的理解。

Method: 利用极化中子衍射技术探测材料中的轨道磁矩，并提出基于微观电流的中子磁散射截面新描述方法，分析其与传统点状局域磁矩模型的异同。

Result: 在高温铜氧化物超导体、铱酸盐、铜氧化物自旋梯和kagome钒酸盐超导体中均观察到环流电流信号；提出了描述磁结构因子的新方法，并揭示了两种理论框架之间的定量差异。

Conclusion: 轨道环流是多种量子材料中的普遍现象，采用微观电流图像能更准确地解释中子散射实验结果，为理解非常规超导机制提供了新视角。

Abstract: We review the hallmarks of orbital loop currents in various correlated electron materials and how they have been evidenced using polarized neutron diffraction. Over the last 20 years, loop current signatures have been observed in high temperature copper oxide superconductors, iridates, copper oxides spin ladders and recently kagome vanadate superconductors. Such currents induce orbital magnetic moments within the unit cell of these quantum materials that can be detected through their interaction with the neutron spin. In addition to the usual description of orbital moments using point-like local magnetic moments, we here show an alternative description of the neutron magnetic cross-section involving the microscopic currents running between different atomic orbitals. We discuss the corresponding magnetic structure factors and the resulting quantitative differences between both approaches.

</details>


### [16] [Hybrid Monte Carlo for Fractional Quantum Hall States](https://arxiv.org/abs/2602.17564)
*Ting-Tung Wang,Ha Quang Trung,Qianhui Xu,Min Long,Bo Yang,Zi Yang Meng*

Main category: cond-mat.str-el

TL;DR: 提出了一种高效的混合蒙特卡洛方法，用于计算 Laughlin 和 Moore-Read 波函数下的分数量子霍尔系统的物理可观测量，显著提升了模拟速度和系统规模，并获得了高质量的拓扑位移和非阿贝尔编织矩阵结果。


<details>
  <summary>Details</summary>
Motivation: 为了更高效地采样分数量子霍尔系统的波函数并克服传统蒙特卡洛方法的低效问题，特别是针对大系统和复杂几何结构的模拟需求。

Method: 开发了结合全局更新和双球面投影的混合蒙特卡洛方法，在球面几何上实现了高效采样，突破了传统Metropolis方法的限制。

Result: 成功模拟了电子数超过1000的系统，精确计算了盘几何下的拓扑位移和球面上Moore-Read准空穴的非阿贝尔编织矩阵，结果质量优于以往研究。

Conclusion: 该方法显著提升了FQH系统波函数模拟的效率与规模，为研究理想陈绝缘带中的FQH态稳定性及量子退相干影响提供了有力工具。

Abstract: We develop a hybrid Monte Carlo method to efficiently compute the physical observables from the samplings of the Laughlin and the Moore-Read wave functions of fractional quantum Hall (FQH) systems. With the advancements in methodology, including global updates and double stereographic projection on spherical geometry, our hybrid Monte Carlo simulation is significantly faster than the widely used Metropolis Monte Carlo scheme. As a result, we can readily simulate systems with electron numbers $N > 1000$ on both disk and sphere geometries. We apply this method to investigating the topological shift obtained from the edge dipole moment, computed from the density of the wave function on the disk. We also numerically computed the non-Abelian braiding matrices for different braiding schemes of the Moore-Read quasiholes on the sphere. Results with much better quality compared with previous works have been achieved. With the thermodynamic limit results obtained at ease, we also discuss the future usage of our method to clarify the questions on the instability of fractional quantum Hall states in an ideal Chern band setting or under quantum decoherence.

</details>


### [17] [Planckian bound on the local equilibration time](https://arxiv.org/abs/2602.17638)
*Marvin Qi,Alexey Milekhin,Luca Delacrétaz*

Main category: cond-mat.str-el

TL;DR: 提出了一个关于量子多体系统局部平衡时间的普朗克时间下限的严格理论证明，适用于广泛的系统类型。


<details>
  <summary>Details</summary>
Motivation: 探索量子多体系统中局部平衡时间的基本极限，验证其是否受普朗克时间的约束。

Method: 通过分析实时时热关联函数的解析性质，定义平衡时间为流体力学行为出现的时间尺度，并在调控后的热两点函数中建立严格的下限。

Result: 建立了局部平衡时间的严格下界 τ_eq ≥ αℏ/T，其中无量纲系数α仅依赖于维度和流体力学或扩散行为的类型，与微观机制无关。

Conclusion: 该下界普遍适用于具有或不具有准粒子描述的局域量子多体系统，包括存在非弹性散射的情况，支持普朗克时间作为基本时间尺度的猜想。

Abstract: The local equilibration time $τ_{\rm eq}$ of quantum many-body systems is conjectured to be bounded below by the Planckian time $\hbar /T$. We formalize this conjecture by defining $τ_{\rm eq}$ as the time scale at which a hydrodynamic description emerges for conserved densities. Drawing on analytic properties of real time thermal correlators, we establish a rigorous lower bound $τ_{\rm eq} \geq α\hbar /T$ on the onset of hydrodynamic behavior in a `regulated' thermal two-point function. The dimensionless coefficient $α$ depends only on dimensionality and the type of hydrodynamic or diffusive behavior that emerges, and is independent of the thermalization mechanism or other microscopic details. This bound applies universally to local quantum many-body systems, with or without a quasiparticle description, including in the presence of inelastic scattering.

</details>


### [18] [Anisotropic marginal Fermi liquid for Coulomb interacting generalized Weyl fermions](https://arxiv.org/abs/2602.17666)
*Gabriel Malavé,Rodrigo Soto-Garrido,Bitan Roy,Vladimir Juričić*

Main category: cond-mat.str-el

TL;DR: 该论文研究了具有整数单极电荷n>1的三维广义外尔半金属中长程库仑相互作用的影响，发现当n≥2时存在一个由相互作用主导的扩展标度区域，表现出各向异性的动态库仑屏蔽、有限的费米子反常维度以及准粒子残差的幂律抑制，形成中间能量下的各向异性边缘非费米液体行为；而当n=1时系统保持各向同性的边缘外尔液体特性。


<details>
  <summary>Details</summary>
Motivation: 由于准粒子色散中的幂律各向异性导致态密度增强，使得在三维广义外尔半金属中长程库仑相互作用效应被放大，因此需要系统研究这种条件下电子关联效应如何改变低能物理行为。

Method: 采用基于大-N展开的威尔逊重整化群方法，并结合由Ward-Takahashi恒等式确定的规范一致截断方案，对不同单极电荷n的系统进行分析。

Result: 当n≥2时，出现各向异性的动态库仑屏蔽、有限的费米子反常维度和准粒子权重的幂律压制，形成中间能量尺度下的各向异性边缘非费米液体；有效精细结构常数最终趋于零但仅以对数速度缓慢流动，导致边缘费米液体表现为缓慢耦合控制下的宽交叉现象；而n=1时系统保持各向同性特征。

Conclusion: 三维广义外尔半金属中，高单极电荷（n≥2）会引发显著的各向异性相互作用效应，导致新的边缘非费米液体相，可通过比热、压缩率、方向依赖的光学电导及角分辨光电子能谱实验验证。

Abstract: Owing to the power-law anisotropy in the quasiparticle dispersion, yielding an enhanced density of states, the effects of long range Coulomb interaction get amplified in three-dimensional generalized Weyl semimetals, characterized by integer monopole charge $n>1$ of the underlying Weyl nodes. Using a Wilsonian renormalization group approach controlled by a large-$N$ expansion with $N$ as the number of Weyl fermion flavors and a gauge-consistent regularization fixed by the Ward-Takahashi identity, we uncover for $n\ge 2$ an extended interaction-dominated scaling regime with intrinsically anisotropic dynamic Coulomb screening, a finite fermionic anomalous dimension, and a power-law suppression of the quasiparticle residue, yielding an \emph{anisotropic} marginal non-Fermi liquid at intermediate energies. Ultimately, the effective fine structure constant flows to zero, albeit only logarithmically slowly, so the marginal Fermi liquid phenomenology emerges as a broad crossover, controlled by a slowly running coupling. By contrast, for $n=1$ the system retains an isotropic marginal Weyl-liquid character. These predictions can be tested via scaling in thermodynamics (specific heat and compressibility), direction-dependent optical conductivity, and by anisotropic broadening of the single-particle spectral function in angle-resolved photoemission spectroscopy.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [19] [Low-Thrust Trajectory Optimization for Cubesat Lunar Mission: HORYU-VI](https://arxiv.org/abs/2602.16831)
*Omer Burak Iskender,Keck Voon Ling,Mengu Cho,Sangkyun Kim,Necmi Cihan Orger*

Main category: eess.SY

TL;DR: 本文提出了一种用于立方星HORYU-VI的低推力轨迹优化策略，通过三阶段任务设计实现近圆形月球轨道捕获，包括飞越前减速、月球引力捕获和轨道圆化，结合冲量初解与有限燃烧优化，并在高精度动力学模型下验证了在450天内以710 m/s总ΔV完成任务的可行性。


<details>
  <summary>Details</summary>
Motivation: HORYU-VI立方星作为NASA阿耳忒弥斯计划的次级载荷被释放至月球飞越轨道后，具有逃逸地月系统的能量，需通过低推力推进系统实现可控月球捕获与稳定科学轨道建立，但受限于小卫星平台的推进能力与复杂多体动力环境，传统方法难以适用，因此需要高效且可行的轨迹优化策略。

Method: 将任务分解为三个阶段：(1) 飞越前减速以避免日心逃逸；(2) 利用月球引力捕获；(3) 轨道圆化至科学轨道。每个阶段首先计算冲量燃烧解作为初始猜测，再采用序列二次规划（SQP）进行有限燃烧优化。动力学模型包含地-月-日-木引力相互作用及高精度月球重力场，并使用NASA的GMAT工具独立验证所有轨迹。

Result: HORYU-VI可在200天内实现月球捕获，280天时建立稳定科学轨道，并在450天内螺旋下降至近圆形100公里高度轨道，总ΔV消耗为710 m/s，处于电推进系统能力范围内。所有轨迹经GMAT验证，表明该策略在真实动力学环境下具备可行性与鲁棒性。

Conclusion: 所提出的分阶段低推力轨迹优化方法能够有效支持CubeSat在复杂多体引力环境中实现精确月球捕获与轨道调整，为小型航天器深空探测任务提供了可行的技术路径，尤其适用于资源受限的次级载荷任务。

Abstract: This paper presents a low-thrust trajectory optimization strategy to achieve a near-circular lunar orbit for a CubeSat injected into a lunar flyby trajectory. The 12U CubeSat HORYU-VI is equipped with four Hall-effect thrusters and designed as a secondary payload on NASA's Space Launch System under the Artemis program. Upon release, the spacecraft gains sufficient energy to escape the Earth-Moon system after a lunar flyby. The proposed trajectory is decomposed into three phases: (1) pre-flyby deceleration to avoid heliocentric escape, (2) lunar gravitational capture, and (3) orbit circularization to the science orbit. For each phase, an impulsive-burn solution is first computed as an initial guess, which is then refined through finite-burn optimization using Sequential Quadratic Programming (SQP). The dynamical model incorporates Earth-Moon-Sun-Jupiter gravitational interactions and a high-fidelity lunar gravity field. All trajectories are independently verified with NASA's General Mission Analysis Tool (GMAT). Results demonstrate that HORYU-VI achieves lunar capture within 200 days, establishes a stable science orbit at 280 days, and can spiral down to a near-circular 100 km orbit by 450 days, using a total Delta-V of 710 m/s, well within the capability of the electric propulsion system.

</details>


### [20] [Beyond Average-Channel-Based Rate Approximations: UAV Trajectory and Scheduling Optimization With Expected Rate Consideration](https://arxiv.org/abs/2602.17019)
*Gitae Park,Kisong Lee*

Main category: eess.SY

TL;DR: 本文研究了在满足最小期望频谱效率约束下，无人机辅助无线通信系统中轨迹、用户调度和时隙持续时间的联合优化问题，提出了一种基于数值积分的保守近似方法，并通过优化算法实现了更短的任务完成时间。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常用信道增益的均值来近似期望频谱效率，导致因Jensen不等式而高估真实性能；为此，本文旨在提出一种更准确且可优化的期望频谱效率建模方法。

Method: 采用基于数值积分的方法对信道分布进行积分以逼近期望频谱效率，通过离散累积分布函数构建有限和表示，并利用惩罚型块坐标下降框架交替优化用户调度、无人机轨迹和自适应时隙长度。

Result: 所提方法能够严格满足最小期望频谱效率约束，在仿真中相比传统基于平均信道的方法显著缩短了任务完成时间，并避免了不可行或过于保守的解。

Conclusion: 本文提出的基于积分的保守近似与联合优化框架在处理随机信道环境下的无人机通信系统设计中具有优越性能，兼顾了可行性与效率。

Abstract: This paper investigates the joint optimization of trajectory, user scheduling, and time-slot duration in unmanned aerial vehicle (UAV)-assisted wireless communication systems under minimum expected spectral efficiency (SE) constraints. Unlike most existing studies that approximate the expected SE by substituting the random channel gain with its mean value, thereby evaluating the SE at the average channel realization and overestimating the true expected SE due to Jensen's inequality, we approximate the expected SE by numerically integrating the SE over the channel distributions. Specifically, instead of relying on average-channel-based approximations, we develop a conservative yet tractable quadrature-based approximation by discretizing the associated cumulative distribution functions. The resulting finite-sum representation explicitly accounts for the probabilistic LoS structure and channel fading effects, while remaining tractable for optimization. Leveraging this lower bound, we formulate a mission completion time minimization problem subject to minimum expected-SE requirements for all ground nodes. The resulting problem is a mixed-integer nonconvex optimization, which is tackled via a penalty-based block coordinate descent framework. The proposed algorithm alternately optimizes the scheduling decisions and the UAV trajectory along with adaptive time-slot durations, and maintains feasibility with respect to the original expected-SE constraints by leveraging successive convex approximation and quadratic transform techniques. Simulation results demonstrate that the proposed method strictly satisfies the minimum expected-SE constraints and achieves a significantly shorter mission completion time than conventional average-channel-based approaches, which are shown to yield infeasible or overly conservative solutions.

</details>


### [21] [Decoupled Internal Energy Regulation and Inertial Response Provision for Grid-Forming Multilevel-Converter-Based E-STATCOMs](https://arxiv.org/abs/2602.17055)
*Ki-Hyun Kim,Yeongung Kim,Shenghui Cui,Jae-Jung Jung*

Main category: eess.SY

TL;DR: 本文提出了一种新的控制策略，通过将双星型多电平变换器（DS-MC）的总内部能量调节分配给交流侧有功功率路径，而将直流侧储能功率专门用于频率支持，从而解耦内部能量管理与惯性响应提供。该方法减少了不必要的储能循环，并可根据储能可用性灵活运行为STATCOM或E-STATCOM。


<details>
  <summary>Details</summary>
Motivation: 随着电力系统中可再生能源比例增加，短时功率不平衡更加频繁，在低惯量条件下可能导致显著的电压和频率波动。现有DS-MC型E-STATCOM的直流侧功率调节方式会将损耗补偿耦合到储能路径，导致储能频繁充放电并限制系统运行灵活性。因此需要一种更优的控制策略以解决此问题。

Method: 提出一种新型控制策略，将DS-MC的总内部能量调节任务由交流侧有功功率路径承担，直流侧储能仅用于快速频率支撑；通过仿真和实验室小规模实验验证所提方案的有效性。

Result: 所提策略成功实现了内部能量管理与惯性响应的解耦，减少了储能系统的不必要循环，提升了热管理和维护性，并支持在有无储能时灵活切换为E-STATCOM或STATCOM模式。仿真与实验证明了该方法的有效性。

Conclusion: 该控制策略有效解决了传统DS-MC E-STATCOM中储能路径过度使用的缺陷，提高了系统灵活性和可持续运行能力，适用于高比例可再生能源接入下的低惯量电网。

Abstract: As power systems accommodate higher shares of renewable generation, short-term power imbalances become more frequent and can manifest as pronounced voltage and frequency excursions under low-inertia conditions. E-STATCOMs (STATCOMs equipped with energy storage) offer a practical means to provide both voltage support and fast frequency assistance under grid-forming control. Among candidate implementations, double-star multilevel-converter (DS-MC)-based E-STATCOMs enable centralized energy-storage integration at the dc link, which improves thermal management and maintainability. Nevertheless, conventional dc-side power-based internal-energy regulation in DS-MCs can undesirably couple loss compensation to the energy-storage path, accelerating storage cycling and constraining operation when the storage is unavailable. This paper introduces a control strategy that assigns DS-MC total internal-energy regulation to the ac-side active-power path, while reserving dc-side storage power solely for frequency support. By decoupling internal-energy management from inertial-response provision, the proposed scheme enables flexible operation as either a STATCOM or an E-STATCOM according to storage availability and mitigates unnecessary storage cycling. The proposed strategy is verified through offline simulations and laboratory-scale experiments.

</details>


### [22] [Validation of KESTREL EMT for Industrial Capacitor Switching Transient Studies](https://arxiv.org/abs/2602.17118)
*Shankar Ramharack,Rajiv Sahadeo*

Main category: eess.SY

TL;DR: 本文验证了开源电磁暂态求解器KESTREL EMT在工业电容投切瞬态分析中的有效性，展示了其与现有标准一致的仿真精度。


<details>
  <summary>Details</summary>
Motivation: 商用EMT仿真平台成本高昂，限制了小型机构和学术单位的应用，尤其是在发展中国家。因此，需要一个免费、开放且可靠的替代方案。

Method: 通过三个逐步深入的案例研究（电容器投入、开关谐振及VFD与电容器组的相互作用），结合适当的电路建模技术，将KESTREL EMT的仿真结果与理论分析和IEEE基准进行对比验证。

Result: KESTREL EMT在三种工况下均表现出与解析预测和IEEE标准一致的电磁暂态响应，证明其具备可靠的仿真能力。

Conclusion: KESTREL EMT是一个经过验证、可复现且完全开源的工具，可用于开展工业级电磁暂态研究，为资源受限机构提供了可行解决方案。

Abstract: Electromagnetic transient (EMT) simulation is essential for analyzing sub-cycle switching phenomena in industrial power systems; however, commercial EMT platforms present significant cost barriers for smaller utilities, consultancies, and academic institutions, particularly in developing regions. This paper validates KESTREL EMT, a free and open-source electromagnetic transient solver with Python integration, through three progressive case studies involving industrial capacitor switching transients. This work investigates energization, switching resonance and VFD interactions with capacitor banks. The results demonstrate that KESTREL, when supported by appropriate circuit modeling techniques, produces EMT responses consistent with analytical predictions and established IEEE benchmarks. This work establishes a validated and reproducible methodology for conducting industrial EMT studies using freely available, open-source tools.

</details>


### [23] [Distributionally Robust Scheduling of Electrified Heating Under Heat Demand Forecast Uncertainty](https://arxiv.org/abs/2602.17239)
*Alessandro Quattrociocchi,Manisha Talukdar,Pere Izquierdo Gómez,Tomislav Dragicevic*

Main category: eess.SY

TL;DR: 提出了一种分布鲁棒机会约束优化框架，用于电锅炉日前调度，通过有限预测误差样本减少需求违规并降低运行成本。


<details>
  <summary>Details</summary>
Motivation: 现有调度方法假设预测不确定性可通过历史误差充分刻画，但实际中累积不确定性导致不平衡价格风险增加，需更优方法应对热需求与电价的双重不确定性。

Method: 采用分布鲁棒机会约束优化模型，基于有限残差预测样本构建模糊集，并通过可调风险参数从历史误差数据中校准模糊集，推导出问题的凸重构形式。

Result: 相比确定性调度，热需求约束违规减少40%；相比固定分布的机会约束模型，违规再降10%；引入实时反弹成本的二阶段项可使日运行成本最高降低34%。

Conclusion: 所提方法在有限数据下有效提升调度鲁棒性，显著降低需求违规和运营成本，为电力市场中大型电加热系统的灵活调度提供了实用解决方案。

Abstract: Electrified heating systems with thermal storage, such as electric boilers and heat pumps, represent a major source of demand-side flexibility. Under current electricity market designs, balance responsible parties (BRPs) operating such assets are required to submit binding day-ahead electricity consumption schedules, and they typically do it based on forecasts of heat demand and electricity prices. Common scheduling approaches implicitly assume that forecast uncertainty can be well characterized using historical forecast errors. In practice, however, the cumulative effect of uncertainty creates significant exposure to imbalance-price risk when the committed schedule cannot be followed. To address this, we propose a distributionally robust chance-constrained optimization framework for the day-ahead scheduling of a multi-MW electric boiler using only limited residual forecast samples. We derive a tractable convex reformulation of the problem and calibrate the ambiguity set directly from historical forecast-error data through an a priori tunable risk parameter. Numerical results show that enforcing performance guarantees on the heat-demand balance constraint reduces demand violations by 40% compared to a deterministic forecast-based scheduler and up to 10% relative to a nominal chance-constrained model with a fixed error distribution. Further, we show that modeling the real-time rebound cost of demand violations as a second-stage term can reduce the overall daily operating cost by up to 34% by hedging against highly volatile day-ahead electricity prices.

</details>


### [24] [On the Value of Base Station Motion Knowledge for Goal-Oriented Remote Monitoring with Energy-Harvesting Sensors](https://arxiv.org/abs/2602.17247)
*Sehani Siriwardana,Jean Michel de Souza Sant'Ana,Richard Demo Souza,Abolfazl Zakeri,Onel Luis Alcaraz López*

Main category: eess.SY

TL;DR: 本文研究了利用能量收集传感器对不可观测的马尔可夫源进行面向目标的远程监控，考虑接收端（如低轨卫星或无人机）移动性带来的时变信道特性。问题被建模为部分可观测马尔可夫决策过程（POMDP），并通过转化为信念状态MDP求解最优采样与传输策略。仿真结果表明，结合接收端移动性和信道状态信息可显著降低平均失真（10%-42%）。


<details>
  <summary>Details</summary>
Motivation: 传统远程监控系统通常假设基站静止，忽略了移动接收端（如LEO卫星、UAV）引起的时变信道影响。这种忽略可能导致性能下降。因此，需要构建一个考虑接收端移动性的新型监控框架，以提升能量受限系统下的估计精度和通信效率。

Method: 将远程监控问题建模为部分可观测马尔可夫决策过程（POMDP），其中系统状态包括源状态、信道状态和传感器能量状态；通过引入信念状态将其转化为完全可观测的MDP，并采用相对值迭代算法求解最优采样与传输策略；同时考虑最大似然（ML）和最小均值失真（MMD）两种估计方法。

Result: 数值结果表明，相比忽略信道变化的基线策略，所提方法在不同能量到达率和移动模式下可将平均失真降低10%至42%；验证了利用接收端移动性信息和动态信道建模对提升远程估计性能的重要作用。

Conclusion: 考虑接收端移动性和信道状态变化的远程监控框架能显著提升估计性能；通过POMDP建模与信念空间优化，实现了在能量约束下更高效的采样与传输决策，为面向目标的通信系统设计提供了新思路。

Abstract: This paper investigates goal-oriented remote monitoring of an unobservable Markov source using energy-harvesting sensors that communicate with a mobile receiver, such as a Low Earth Orbit (LEO) satellite or Unmanned Aerial Vehicle (UAV). Unlike conventional systems that assume stationary base stations, the proposed framework explicitly accounts for receiver mobility, which induces time-varying channel characteristics modeled as a finite-state Markov process. The remote monitoring problem is formulated as a partially observable Markov decision process (POMDP), which is transformed into a tractable belief-state MDP and solved using relative value iteration to obtain optimal sampling and transmission policies. Two estimation strategies are considered: Maximum Likelihood (ML) and Minimum Mean Distortion (MMD). Numerical results demonstrate that incorporating receiver mobility and channel state information into the optimization reduces the average distortion by 10% to 42% compared to baseline policies and constant-channel assumptions, highlighting the importance of base station motion knowledge for effective goal-oriented communication.

</details>


### [25] [Herd Behavior in Decentralized Balancing Models: A Case Study in Belgium](https://arxiv.org/abs/2602.17352)
*Max Bruninx,Seyed Soroush Karimi Madahi,Timothy Verstraeten,Jan Decuyper,Chris Develder,Jan Helsen*

Main category: eess.SY

TL;DR: 该研究通过模拟比利时2023年市场数据，分析了去中心化平衡模型中BRP参与隐性平衡的影响，发现初期可降低平衡成本，但当隐性调节容量过大时可能导致 overshoot，反而增加系统负担。


<details>
  <summary>Details</summary>
Motivation: 探讨去中心化平衡模式下BRP参与隐性平衡对电网平衡成本及系统稳定性的影响，评估高容量灵活资源接入下的潜在风险。

Method: 构建分钟级价格信号的市场模拟器，模拟具有不同风险偏好的电池资产在当前及两种新型价格机制下的隐性响应行为。

Result: 随着参与容量增加，初期能显著降低平衡成本，但总容量过高时易出现过度响应（overshoot），导致需更多显性干预；尽管TSO成本可能上升，BRP仍能从中获益。

Conclusion: 隐性平衡虽有助于降低初始平衡成本并促进灵活资源参与，但在大规模部署时需防范过度响应风险，应结合合理的激励机制设计以维持系统稳定。

Abstract: In a decentralized balancing model, Balance Responsible Parties (BRPs) are encouraged by the Transmission System Operator (TSO) to deviate from their schedule to help the system restore balance, also referred to as implicit balancing. This could reduce balancing costs for the grid operator and lower the entry barrier for flexible assets compared to explicit balancing services. However, these implicit reactions may overshoot when their total capacity is high, potentially requiring more explicit activations. This study analyses the effect of increased participation in the decentralized balancing model in Belgium. To this end, we develop a market simulator that produces price signals on minute-level and simulate the implicit reactions for battery assets with different risk profiles. Besides the current price formula, we also study two potential candidates for the near-term presented by the TSO. A simulation study is conducted using Belgian market data for the year 2023. The findings indicate that, while having a significant positive effect on the balancing costs at first, the risk of overshoots can outweigh the potential benefits when the total capacity of the implicit reactions becomes too large. Furthermore, even when the balancing costs start to increase for the TSO, BRPs were still found to benefit from implicit balancing.

</details>


### [26] [Robust Model Predictive Control for Linear Systems with Interval Matrix Model Uncertainty](https://arxiv.org/abs/2602.17379)
*Renato Quartullo,Andrea Garulli,Mirko Leomanni*

Main category: eess.SY

TL;DR: 提出了一种基于矩阵zonotope的区间矩阵不确定性建模方法，用于线性离散时间系统的鲁棒模型预测控制，具有离线计算边界、在线计算量小、保证递归可行性和稳定性的优点。


<details>
  <summary>Details</summary>
Motivation: 为了降低现有鲁棒MPC方法在处理多参数不确定性时的高计算负担，同时保持良好的控制性能和可行性。

Method: 利用矩阵zonotope对不确定系统脉冲响应的每一项进行集合论过近似，结合区间矩阵结构，在离线阶段计算所有相关边界，并采用变 horizon MPC 形式以确保递归可行性和鲁棒渐近稳定性。

Result: 数值仿真表明，该方法在保持与当前最有效方法相当的可行性区域的同时，显著降低了计算负担，能够应用于具有多个不确定参数的高维系统。

Conclusion: 所提方法在保证控制性能和稳定性的同时，大幅减少了在线计算量，适用于复杂高维不确定系统的实时鲁棒控制。

Abstract: This paper proposes a novel robust Model Predictive Control (MPC) scheme for linear discrete-time systems affected by model uncertainty described by interval matrices.
  The key feature of the proposed method is a bound on the uncertainty propagation along the prediction horizon which exploits a set-theoretic over-approximation of each term of the uncertain system impulse response.
  Such an approximation is based on matrix zonotopes and leverages the interval matrix structure of the uncertainty model.
  Its main advantage is that all the relevant bounds are computed offline, thus making the online computational load independent of the number of uncertain parameters.
  A variable-horizon MPC formulation is adopted to guarantee recursive feasibility and to ensure robust asymptotic stability of the closed-loop system.
  Numerical simulations demonstrate that the proposed approach is able to match the feasibility regions of the most effective state-of-the-art methods, while significantly reducing the computational burden, thereby enabling the treatment of nontrivial dimensional systems with multiple uncertain parameters.

</details>


### [27] [Bluetooth Phased-array Aided Inertial Navigation Using Factor Graphs: Experimental Verification](https://arxiv.org/abs/2602.17407)
*Glen Hjelmerud Mørkbak Sørensen,Torleiv H. Bryne,Kristoffer Gryte,Tor Arne Johansen*

Main category: eess.SY

TL;DR: 本文探讨了使用商用蓝牙相控阵系统在GNSS信号缺失场景下进行辅助惯性导航的鲁棒估计策略，通过多旋翼无人机飞行实验数据评估了不同传感器融合方案的性能。


<details>
  <summary>Details</summary>
Motivation: 由于GNSS信号在某些场景（如仓库物流、无人机降落）中不可用，需要低成本且可行的替代导航方案，因此研究基于商用蓝牙相控阵的辅助惯性导航系统。

Method: 采用因子图优化框架，结合蓝牙角度测量以及距离或气压计数据，对多种鲁棒估计策略进行比较，并利用实际多旋翼无人机飞行实验数据进行验证。

Result: 实验结果表明，在失去GNSS信号的情况下，融合蓝牙角度测量与其他传感器信息能够提升导航性能，但测量噪声较大且有效范围较短仍是挑战。

Conclusion: 基于商用蓝牙相控阵的系统为GNSS拒止环境下的导航提供了低成本解决方案，尽管存在噪声和距离限制，但通过鲁棒估计方法可在实际应用中实现有效导航。

Abstract: Phased-array Bluetooth systems have emerged as a low-cost alternative for performing aided inertial navigation in GNSS-denied use cases such as warehouse logistics, drone landings, and autonomous docking. Basing a navigation system off of commercial-off-the-shelf components may reduce the barrier of entry for phased-array radio navigation systems, albeit at the cost of significantly noisier measurements and relatively short feasible range. In this paper, we compare robust estimation strategies for a factor graph optimisation-based estimator using experimental data collected from multirotor drone flight. We evaluate performance in loss-of-GNSS scenarios when aided by Bluetooth angular measurements, as well as range or barometric pressure.

</details>


### [28] [Multi-Agent Temporal Logic Planning via Penalty Functions and Block-Coordinate Optimization](https://arxiv.org/abs/2602.17434)
*Eleftherios E. Vlahakis,Arash Bahari Kordabad,Lars Lindemann,Pantelis Sopasakis,Sadegh Soudjani,Dimos V. Dimarogonas*

Main category: eess.SY

TL;DR: 提出了一种基于惩罚函数的无约束优化方法，结合块坐标梯度下降（BCGD）解决多智能体STL规划中的可扩展性问题，并通过双层优化框架保证任务可行性。


<details>
  <summary>Details</summary>
Motivation: 多智能体STL规划因高维度和协作任务导致计算复杂，难以实现可扩展且具有满意度保证的合成。

Method: 将STL规划建模为带多智能体约束的优化问题，引入基于平滑STL语义的二次惩罚函数进行无约束松弛，并采用块坐标梯度下降（BCGD）分块求解；通过双层优化结构，在外层逐步增大惩罚系数以提升任务鲁棒性。

Result: 该方法在多个复杂的多机器人规划场景中验证了其可扩展性和高效性，能够有效收敛到惩罚后问题的稳定点。

Conclusion: 所提框架通过BCGD与双层优化策略，实现了对高维多智能体STL规划问题的高效求解，兼顾了计算可扩展性与任务可行性。

Abstract: Multi-agent planning under Signal Temporal Logic (STL) is often hindered by collaborative tasks that lead to computational challenges due to the inherent high-dimensionality of the problem, preventing scalable synthesis with satisfaction guarantees. To address this, we formulate STL planning as an optimization program under arbitrary multi-agent constraints and introduce a penalty-based unconstrained relaxation that can be efficiently solved via a Block-Coordinate Gradient Descent (BCGD) method, where each block corresponds to a single agent's decision variables, thereby mitigating complexity. By utilizing a quadratic penalty function defined via smooth STL semantics, we show that BCGD iterations converge to a stationary point of the penalized problem under standard regularity assumptions. To enforce feasibility, the BCGD solver is embedded within a two-layer optimization scheme: inner BCGD updates are performed for a fixed penalty parameter, which is then increased in an outer loop to progressively improve multi-agent STL robustness. The proposed framework enables scalable computations and is validated through various complex multi-robot planning scenarios.

</details>


### [29] [Dodging the Moose: Experimental Insights in Real-Life Automated Collision Avoidance](https://arxiv.org/abs/2602.17512)
*Leila Gharavi,Simone Baldi,Yuki Hosomi,Tona Sato,Bart De Schutter,Binh-Minh Nguyen,Hiroshi Fujimoto*

Main category: eess.SY

TL;DR: 本文提出了一种结合模型预测控制（MPC）与类人前馈规划器的实时避障策略，用于自动驾驶车辆在“驼鹿测试”类紧急场景中的运动规划，并通过实车实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于传统非线性MPC在紧急避障场景中存在计算量大、初始猜测敏感、实时性差的问题，难以满足突发静态障碍物情况下的实时响应需求。

Method: 采用MPC进行常规运动规划，同时设计基于最大转向操作的类人前馈规划器，在MPC不可行或求解失败时提供备用轨迹；并在FPEV2-Kanon电动平台上进行多速度与多紧急程度下的实车实验。

Result: 所提方法在多种工况下均能实现有效避障，尤其在MPC失效时前馈规划器可及时介入，显著提升系统可靠性与实时性。

Conclusion: 结合MPC与类人前馈规划的混合策略能够有效解决紧急避障中的实时性问题，为自动驾驶在高危场景下的安全决策提供了可行方案。

Abstract: The sudden appearance of a static obstacle on the road, i.e. the moose test, is a well-known emergency scenario in collision avoidance for automated driving. Model Predictive Control (MPC) has long been employed for planning and control of automated vehicles in the state of the art. However, real-time implementation of automated collision avoidance in emergency scenarios such as the moose test remains unaddressed due to the high computational demand of MPC for evasive action in such hazardous scenarios. This paper offers new insights into real-time collision avoidance via the experimental imple- mentation of MPC for motion planning after a sudden and unexpected appearance of a static obstacle. As the state-of-the-art nonlinear MPC shows limited capability to provide an acceptable solution in real-time, we propose a human-like feed-forward planner to assist when the MPC optimization problem is either infeasible or unable to find a suitable solution due to the poor quality of its initial guess. We introduce the concept of maximum steering maneuver to design the feed-forward planner and mimic a human-like reaction after detecting the static obstacle on the road. Real-life experiments are conducted across various speeds and level of emergency using FPEV2-Kanon electric vehicle. Moreover, we demonstrate the effectiveness of our planning strategy via comparison with the state-of- the-art MPC motion planner.

</details>


### [30] [Method to Compute Pointing Displacement, Smear, and Jitter Covariances for Optical Payloads](https://arxiv.org/abs/2602.17621)
*Peter Seiler,Mark E. Pittelkau,Felix Biertümpfel*

Main category: eess.SY

TL;DR: 本文提出了一种评估光学载荷在图像位移、拖影和抖动存在下的指向和图像运动性能的方法，通过求解李雅普诺夫微分方程计算协方差，并引入统计图像运动调制传递函数来验证性能要求。


<details>
  <summary>Details</summary>
Motivation: 为了更全面地评估光学载荷在复杂动态环境下的成像性能，扩展已有方法以同时考虑位移、拖影和抖动的影响。

Method: 假设图像曝光期间的运动为平稳随机过程，通过求解李雅普诺夫微分方程得到位移、拖影和抖动的协方差，进而参数化统计图像运动调制传递函数（MTF）。

Result: 成功推导出包含拖影和位移效应的协方差计算方法，得到了可用于验证指向和图像运动MTF要求的统计模型，并展示了数值示例。

Conclusion: 该方法扩展了先前的技术，能够更完整地评估图像质量影响因素，且在特定情况下比原有方法更高效。

Abstract: This paper presents a method to assess the pointing and image motion performance of optical payloads in the presence of image displacement (shift), smear, and jitter. The method assumes the motion is a stationary random process over an image exposure interval. Displacement, smear, and jitter covariances are computed from the solution to a Lyapunov differential equation. These covariances parameterize statistical image motion modulation transfer functions (MTFs), and they can be used to verify pointing and image motion MTF requirements. The method in the present paper extends a previous method to include smear, as well as displacement, and hence jitter. The approach in the present paper also leads, as a special case, to a more efficient method to compute the displacement covariance than the previous method. Numerical examples illustrate the proposed method.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [31] [Evidence of current-enhanced excited states in lattice QCD three-point functions](https://arxiv.org/abs/2602.17195)
*Lorenzo Barca*

Main category: hep-lat

TL;DR: 本文提出了一种基于介子主导思想并通过变分法实现的通用机制，用于识别由插入电流和运动学选择所增强的激发态，从而帮助控制格点QCD中强子结构观测量计算中的激发态污染。


<details>
  <summary>Details</summary>
Motivation: 激发态污染是格点QCD精确计算强子结构观测量时的主要系统误差来源之一，亟需有效方法加以识别和控制。

Method: 基于介子主导的思想，结合变分法，并通过手征微扰理论的预测和数值证据，在不同强子通道（特别是核子体系）中分析激发态的增强机制。

Result: 成功识别出特定插入电流和运动学条件下被增强的激发态，提供了对激发态效应的深入理解。

Conclusion: 该机制为抑制格点QCD中三点半径计算的激发态污染提供了概念上的洞见和实践指导。

Abstract: Excited-state contamination remains one of the leading sources of systematic uncertainty in the precise determination of hadron structure observables from lattice QCD. In this work, I present a general mechanism, motivated by meson dominance and implemented through the variational method, that identifies which excited states are enhanced by the choice of inserted current and kinematics. The argument is supported by numerical evidence and predictions from chiral perturbation theory across different hadronic channels, in particular in the nucleon sector, and provides both conceptual insight and practical guidance for controlling excited-state effects in hadron three-point function analyses.

</details>


### [32] [Three-body study of the $T_{cc}(3875)^+$ from lattice QCD](https://arxiv.org/abs/2602.17204)
*Herzallah Alharazin,André Baião Raposo,John Bulava,Sebastian Dawid,Jeremy R. Green,Colin Morningstar,Fernando Romero-López,Miguel Salg,Stephen R. Sharpe,Andres Stump*

Main category: hep-lat

TL;DR: 本文通过三体方法对双粲四夸克态$T_{cc}^+$(3875)进行了首次格点研究，分析了$DDπ$系统在$I=0$、$C=2$区域的性质，并利用CLS组合X252和X253提取有限体积能量，初步给出了两体子通道结果及三体谱的探索性分析。


<details>
  <summary>Details</summary>
Motivation: 为了理解双粲四夸克态$T_{cc}^+$的结构和性质，特别是其在$DDπ$系统中作为极点的表现，开展首次格点QCD研究。

Method: 采用三体方法研究$I=0, C=2$下的$DDπ$系统，结合两体$DD^*$和三体$DDπ$效应，并处理由单π交换引起的左支割线；使用两个CLS组态（X252, X253，$M_π\approx 280$ MeV），并构建包含二强子、三强子和四夸克算符的算符集以提取有限体积能谱。

Result: 获得了$I=1$ $DD$ 和 $I=1/2$ $Dπ$ 两体子系统的振幅初步结果，并基于简单的三粒子K矩阵$\mathcal{K}_{\text{df}, 3}$选择进行了三体谱的探索性确定，实现了与格点能谱的首次比较。

Conclusion: 该三体格点框架能够有效描述$T_{cc}^+$在$DDπ$耦合道中的行为，为未来精确提取共振参数奠定了基础。

Abstract: We discuss an ongoing first lattice study of the doubly-charmed tetraquark $T_{cc}^+$(3875) via a three-body approach. We investigate the $DDπ$ system in the $I=0$, $C=2$ sector, where the $T_{cc}^+$ appears as a pole in the $J^P = 1^+$ $DDπ$ elastic scattering amplitude. The approach automatically incorporates two-body $DD^*$ and three-body $DDπ$ effects and treats left-hand cuts due to single $π$ exchanges. Two CLS ensembles, X252 and X253, with pion mass $M_π\approx 280$ MeV, are used, and an operator set comprised of two- and three-hadron and tetraquark operators is employed to extract finite-volume energies. Additional inputs are required for the three-body finite-volume analysis, in the form of amplitudes for the $I=1$ $DD$ and $I=1/2$ $Dπ$ two-body subsystems. We present preliminary results for these subchannels and perform exploratory three-body spectra determinations for simple choices of the three-particle K-matrix $\mathcal{K}_{\text{df}, 3}$, allowing a first comparison to the lattice spectrum.

</details>


### [33] [Quarkonium in non-zero isospin chemical potential environment at $T \simeq 0$](https://arxiv.org/abs/2602.17232)
*Seyong Kim,Bastian B. Brandt,Gergely Endrődi*

Main category: hep-lat

TL;DR: 研究了在接近零温度下同位旋不对称性对QCD中夸克偶素态的影响，使用格点非相对论QCD方法计算了底夸克关联函数，并分析了不同同位旋化学势下的Upsilon质量变化。


<details>
  <summary>Details</summary>
Motivation: 探索同位旋不对称性如何影响夸克偶素态的性质，特别是在低温度条件下的行为。

Method: 采用N_f = 2 + 1味动态交错夸克生成的规范场系综，结合包含同位旋化学势效应的格点非相对论QCD形式，计算底夸克关联函数并构造S波和P波夸克偶素态关联函数。

Result: 初步结果表明，在μ_I a = 0.106时，Upsilon质量比真空中更重；而在低于此值时，同位旋不对称性对Upsilon质量的影响是非单调的。

Conclusion: 同位旋化学势对Upsilon质量有显著影响，且其效应在不同范围内表现出非单调特性。

Abstract: We study how the isospin asymmetry affects quarkonium states in QCD at near zero temperature. Using lattice Non-Relativistic QCD formalism, we calculate bottom quark correlators in the gauge field ensembles generated with $N_f = 2 + 1$ flavors of dynamical staggered quarks whose dynamics include the isospin chemical potential effect and then construct $S-$ and $P-$ wave quarkonium state correlators. From these quarkonium correlators, we consider the ratios of quarkonium correlators at non-zero isospin chemical potential to that at $μ_I a = 0.000$. Here, the gauge field ensemble with $μ_I a = 0.000, 0.048, 0.053, 0.059, 0.066, 0.080, 0.092$ and $0.106$ on a $32^3 \times 48$ lattice with non-zero isospin current strength $λa = 0.0010, 0.0018,$ and $0.0036$, where $m_π= 135$ MeV and $a = 0.1535$ fm from \cite{Brandt:2022hwy}, are used. Preliminary results suggest that for $μ_I a = 0.106$, the Upsilon mass gets heavier than the Upsilon mass in the vacuum and that below $μ_I a = 0.106$ the isospin asymmetry effect on the Upsilon mass is not monotonic.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [34] [Distillation and Interpretability of Ensemble Forecasts of ENSO Phase using Entropic Learning](https://arxiv.org/abs/2602.16857)
*Michael Groom,Davide Bassetti,Illia Horenko,Terence J. O'Kane*

Main category: physics.comp-ph

TL;DR: 提出了一种针对eSPA模型集成的蒸馏框架，用于提前24个月预测ENSO相位，同时保持高预测性能并提升可解释性。


<details>
  <summary>Details</summary>
Motivation: eSPA集成模型虽预测性能优越，但难以解释，因此需要一种方法在不损失性能的前提下提高模型的可解释性和诊断能力。

Method: 通过聚合仅在正确预测中表现良好的集成成员结构，将复杂集成压缩为一组简洁的‘蒸馏’模型，并对不同预测提前期构建单个可诊断模型。

Result: 蒸馏后的模型保持了原始集成的预测性能，揭示了ENSO的时空动态特征，识别出跨春季可预报性障碍时输入空间复杂性达到峰值，并通过空间重要性图谱定位关键预测信息区域。

Conclusion: 该蒸馏框架在不影响预测能力的同时，显著提升了模型的可解释性，支持对ENSO长期可预测性的深入诊断分析，可辅助实时数据驱动的业务化预测。

Abstract: This paper introduces a distillation framework for an ensemble of entropy-optimal Sparse Probabilistic Approximation (eSPA) models, trained exclusively on satellite-era observational and reanalysis data to predict ENSO phase up to 24 months in advance. While eSPA ensembles yield state-of-the-art forecast skill, they are harder to interpret than individual eSPA models. We show how to compress the ensemble into a compact set of "distilled" models by aggregating the structure of only those ensemble members that make correct predictions. This process yields a single, diagnostically tractable model for each forecast lead time that preserves forecast performance while also enabling diagnostics that are impractical to implement on the full ensemble.
  An analysis of the regime persistence of the distilled model "superclusters", as well as cross-lead clustering consistency, shows that the discretised system accurately captures the spatiotemporal dynamics of ENSO. By considering the effective dimension of the feature importance vectors, the complexity of the input space required for correct ENSO phase prediction is shown to peak when forecasts must cross the boreal spring predictability barrier. Spatial importance maps derived from the feature importance vectors are introduced to identify where predictive information resides in each field and are shown to include known physical precursors at certain lead times. Case studies of key events are also presented, showing how fields reconstructed from distilled model centroids trace the evolution from extratropical and inter-basin precursors to the mature ENSO state. Overall, the distillation framework enables a rigorous investigation of long-range ENSO predictability that complements real-time data-driven operational forecasts.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [35] [A Generalization of the Parametric Amplifier with Dunkl Derivative: Spectral and Statistical Properties](https://arxiv.org/abs/2602.16743)
*D. Ojeda Guillén,R. D. Mota,J. C. Vega*

Main category: quant-ph

TL;DR: 研究了Dunkl形式下的参量放大器哈密顿量，引入Dunkl产生和湮灭算符，并利用su(1,1)李代数求解谱问题，得到精确的能谱和本征函数。分析了Dunkl压缩态的统计性质，发现压缩真空的Mandel参数与Dunkl形变无关，而关联函数依赖于Dunkl参数μ，影响光子聚束效应。当Dunkl形变参数趋于零时，结果退化为标准参量放大器情形。


<details>
  <summary>Details</summary>
Motivation: 探索Dunkl形式下参量放大器系统的代数结构和精确可解性，并研究其量子态的统计特性。

Method: 引入Dunkl产生和湮灭算符，构造su(1,1)李代数，采用su(1,1)倾斜变换和广义Bogoliubov变换两种代数方法求解谱问题，基于Dunkl数相干态获得能谱和本征函数，并计算Mandel Q参数和二阶关联函数分析统计性质。

Result: 精确求解了Dunkl参量放大器的能谱和本征函数；发现压缩真空中Mandel参数不依赖Dunkl形变，而g^(2)(0)函数依赖于Dunkl参数μ，从而调控光子聚束效应；在形变参数为零时恢复标准参量放大器结果。

Conclusion: Dunkl形变不改变压缩真空的Mandel参数，但通过Dunkl参数μ调节二阶关联和光子统计行为，表明该模型可调且包含标准情况作为特例。

Abstract: We study the parametric amplifier Hamiltonian within the framework of the Dunkl formalism. We introduce the Dunkl creation and annihilation operators and show that their quadratic combinations generate an $su(1,1)$ Lie algebra. The spectral problem is solved exactly using two algebraic methods: the $su(1,1)$ tilting transformation and the generalized Bogoliubov transformation. The exact energy spectrum and the corresponding eigenfunctions are obtained in terms of the Dunkl number coherent states. Furthermore, we compute the Mandel $Q$ parameter and the second-order correlation function $g^{(2)}(0)$ to analyze the statistical properties of the Dunkl squeezed states. We show that, for the squeezed vacuum, the Mandel parameter remains independent of the Dunkl deformation, whereas the correlation function exhibits an explicit dependence on the Dunkl parameter $μ$, which modifies the photon bunching effects. Finally, we show that our results reduce to the standard parametric amplifier case in the limit of vanishing Dunkl deformation parameter.

</details>


### [36] [Finite-Temperature Dynamical Phase Diagram of the $2+1$D Quantum Ising Model](https://arxiv.org/abs/2602.16772)
*Lucas Katschke,Roland C. Farrell,Umberto Borla,Lode Pollet,Jad C. Halimeh*

Main category: quant-ph

TL;DR: 提出了一种基于量子蒙特卡罗的高效方法，用于绘制有限温度下量子多体系统的动力学相图，避免了直接模拟酉时间演化的困难，并预测了2+1维量子伊辛模型中的非平凡淬火行为。


<details>
  <summary>Details</summary>
Motivation: 建立远离平衡态的量子多体普适性框架需要绘制有限温度下的动力学相图，但因非平衡动力学中体积律纠缠难以表示而极具挑战。

Method: 利用能量守恒和遍历系统自热化特性，通过平衡态量子蒙特卡罗方法计算淬火后长时间可观测量，从而确定动力学相图。

Result: 成功绘制了2+1维量子伊辛模型的动力学相图，发现有序相中存在冷却效应，并识别出从顺磁到铁磁相变的初始温度区间。

Conclusion: 该方法无需显式模拟酉演化即可研究动力学性质，适用于其他晶格和相互作用体系，并提出了可在当前量子硬件上实现的实验验证方案。

Abstract: Mapping finite-temperature dynamical phase diagrams of quantum many-body models is a necessary step towards establishing a framework of far-from-equilibrium quantum many-body universality. However, this is quite difficult due, in part, to the severe challenges in representing the volume-law entanglement that is generated under nonequilibrium dynamics at finite temperatures. Here, we address these challenges with an efficient equilibrium quantum Monte Carlo (QMC) framework for computing the finite-temperature dynamical phase diagram. Our method uses energy conservation and the self-thermalizing properties of ergodic quantum systems to determine observables at late times after a quantum quench. We use this technique to chart the dynamical phase diagram of the $2+1$D quantum Ising model generated by quenches of the transverse field in initial thermal states. Our approach allows us to track the evolution of dynamical phases as a function of both the initial temperature and transverse field. Surprisingly, we identify quenches in the ordered phase that cool the system as well as an interval of initial temperatures where it is possible to quench from the paramagnetic (PM) to ferromagnetic (FM) phases. Our method gives access to dynamical properties without explicitly simulating unitary time evolution, and is immediately applicable to other lattice geometries and interacting many-body systems. Finally, we propose a quantum simulation experiment on state-of-the-art digital quantum hardware to directly probe the predicted dynamical phases and their real-time formation.

</details>


### [37] [Controlling energy spectra and skin effect via boundary conditions in non-Hermitian lattices](https://arxiv.org/abs/2602.16780)
*S Rahul,Pasquale Marra*

Main category: quant-ph

TL;DR: 研究了在广义边界条件下Hatano-Nelson模型的非厄米特性，发现通过调节边界跃迁幅度可精确控制体边效应和能谱性质。


<details>
  <summary>Details</summary>
Motivation: 探索广义边界条件对非厄米系统中体边效应和例外点的影响，理解边界调控在非厄米物理中的作用。

Method: 利用相似变换分析具有复数边界跃迁幅度的Hatano-Nelson模型，确定实能谱、体边效应及例外点出现的条件。

Result: 发现了边界跃迁参数可精确调控体边效应和能谱从实到复的转变，并识别出例外点的存在。

Conclusion: 非厄米系统的谱性质和本征态局域化行为对边界条件高度敏感，可通过设计边界实现量子晶格模型的定向调控，有望应用于量子器件设计。

Abstract: Non-Hermitian systems exhibit unique spectral properties, including the non-Hermitian skin effect and exceptional points, often influenced by boundary conditions. The modulation of these phenomena by generalized boundary conditions remains unexplored and not understood. Here, we analyze the Hatano-Nelson model with generalized boundary conditions induced by complex hopping amplitudes at the boundary. Using similarity transformations, we determine the conditions yielding real energy spectra and skin effect, and identify the emergence of exceptional points where spectra transition from real to complex. We demonstrate that tuning the boundary hopping amplitudes precisely controls the non-Hermitian skin effect, i.e., the localization of eigenmodes at the lattice edges. These findings reveal the sensitivity of spectral and localization properties to boundary conditions, providing a framework for engineering quantum lattice models with tailored spectral and localization features, with potential applications in quantum devices.

</details>


### [38] [Retrieving the Baby: Reichenbach's Principle, Bell Locality, and Selection Bias](https://arxiv.org/abs/2602.16985)
*Huw Price*

Main category: quant-ph

TL;DR: 本文重新审视了贝尔在推导因子化原则时的步骤，指出其忽略了选择偏差这一重要因素。作者认为，量子力学中EPR-Bell关联可能并非违反直观意义上的定域性，而是由于选择偏差导致的相关性，这类相关性不受因果发现中的常见原因原则（PCC）约束。


<details>
  <summary>Details</summary>
Motivation: 贝尔本人对其从直观定域性推导出数学上因子化条件的过程持怀疑态度。本文旨在识别并恢复被忽略的关键因素——选择偏差，以澄清对量子非定域性的误解。

Method: 基于赖欣巴哈的共同原因原则（PCC），分析EPR-Bell相关性是否属于PCC的例外情况，并将其与已知由选择偏差引起的相关性进行类比。

Result: 发现EPR-Bell相关性可被视为选择偏差的产物，类似于统计学中的碰撞偏差（collider bias），因而不违背直观的定域性概念。

Conclusion: 因子化条件的失效不一定意味着物理上的非定域性；它可能是建模过程中未恰当处理选择偏差的结果，这对量子基础、统计学和因果建模均有重要启示。

Abstract: In his late piece 'La nouvelle cuisine' (Bell 1990), John Bell describes the steps from an intuitive, informal principle of locality to a mathematical rule called Factorizability. This rule stipulates that when possible past causes are held fixed, the joint probabilities of outcomes of spacelike separated measurements, conditional on measurement settings, be the product of the local conditional probabilities individually. Bell shows that Factorizability conflicts with predictions of QM, predictions since confirmed in many experiments. However, Bell warns his readers that the steps leading to Factorizability should 'be viewed with the utmost suspicion'. He says that 'it is precisely in cleaning up intuitive ideas for mathematics that one is likely to throw the baby out with the bathwater' (1990, 239). Bell's suspicions were well-founded, for he himself misses an important baby. Here we retrieve and identify it: it is selection bias. We explain how failure of Factorizability may be regarded as a selection artefact, requiring no violation of locality in the intuitive, conceptual sense with which Bell begins his analysis. The argument begins with a central principle of causal discovery, Reichenbach's Principle of Common Cause (PCC). It is well known that correlations due to selection bias are not subject to PCC. Several writers have proposed that EPR-Bell correlations are also an exception to PCC, but it has not been noticed that they fall under this well-known exclusion. The point is relevant not only to the status of Bell nonlocality, but also for statistics and causal modeling. For these fields, the news is that selection effects play a ubiquitous role in quantum phenomena, in a form akin to collider bias.

</details>


### [39] [Entropic Barriers and the Kinetic Suppression of Topological Defects](https://arxiv.org/abs/2602.16777)
*Yi-Lin Tsao,Zhu-Xi Luo*

Main category: quant-ph

TL;DR: 本文提出了一种基于熵保护的机制，通过将量子系统与具有维度$M$的介观辅助储层耦合，抑制拓扑缺陷的成核，从而在有限温度下增强量子相的稳定性。该机制在伊辛链和二维拓扑系统中展现出三段式关联长度行为，并可显著提升有限尺寸系统中的量子记忆性能，适用于里德堡原子阵列实验实现。


<details>
  <summary>Details</summary>
Motivation: 传统基于能隙的保护机制在热涨落超过能隙时失效，而许多量子相在有限温度下因拓扑缺陷的增殖而失稳。因此需要一种新的、不依赖能隙的保护机制来稳定量子相。

Method: 引入与维度为$M$的介观辅助储层耦合的熵保护机制，通过产生随温度升高的有效自由能垒来抑制拓扑缺陷的成核和运动；理论分析其在伊辛链和二维拓扑系统（如熵托里克码和BKT相变）中的表现，并提出基于双物种里德堡原子阵列的实验实现方案。

Result: 发现关联长度随温度呈现三段行为（线性增长、熵控平台、最终崩溃）；在二维有限系统中显著增强拓扑序的稳定性；实现逻辑错误的双重参数抑制，提升相干时间；提出了可在实验上实现的熵托里克码方案。

Conclusion: 熵保护提供了一种被动且可扩展的方法，在实验相关条件下稳定量子相，尤其适用于当前量子存储和量子模拟实验中的有限尺寸系统。

Abstract: Many quantum phases, from topological orders to superfluids, are destabilized at finite temperature by the proliferation and motion of topological defects such as anyons or vortices. Conventional protection mechanisms rely on energetic gaps and fail once thermal fluctuations exceed the gap scale. Here we examine a complementary mechanism of entropic protection, in which defect nucleation is suppressed by coupling to mesoscopic auxiliary reservoirs of dimension $M$, generating an effective free-energy barrier that increases with temperature. In the Ising chain, this produces a characteristic three-regime evolution of the correlation length as a function of temperature - linear growth, entropy-controlled plateau, and eventual breakdown - indicating a general modification of defect behavior. Focusing on two spatial dimensions, where true finite-temperature topological order is forbidden in the thermodynamic limit, we show that entropic protection can nevertheless strongly enhance stabilization at finite system size, the regime directly relevant for quantum memory and experiments. Owing to the topological character of the defects, creation and transport are independently suppressed, yielding a double parametric reduction of logical errors in the entropic toric code and enhanced coherence when the framework is extended to Berezinskii-Kosterlitz-Thouless transitions. Entropic barriers thus provide a passive and scalable route to stabilizing quantum phases in experimentally relevant regimes. We propose an experimental setup for entropic toric code using dual species Rydberg arrays with dressing.

</details>


### [40] [Dissipation as a Resource: Synchronization, Coherence Recovery, and Chaos Control](https://arxiv.org/abs/2602.16817)
*Debabrata Mondal,Lea F. Santos,S. Sinha*

Main category: quant-ph

TL;DR: 该论文提出并验证了耗散可作为资源而非障碍，用于调控多组分量子系统的动力学行为，在玻色-约瑟夫森结中实现了同步锁相、瞬态混沌与稳态混沌等不同动力学相，并发现耗散能调节混沌寿命并恢复量子相干性。


<details>
  <summary>Details</summary>
Motivation: 传统上耗散被视为导致退相干和不可逆性的不利因素，本文旨在探索耗散在量子系统中可能发挥的积极作用，特别是其在塑造复杂动力学行为和调控量子相干性方面的潜力。

Method: 基于一个可实验实现的双组分玻色-约瑟夫森结模型，结合理论分析与数值模拟，研究在不同相互作用强度和实验可调参数下，耗散如何诱导出多种动力学相，包括同步振荡、瞬态混沌和稳态混沌。

Result: 发现弱相互作用下系统即使存在耗散仍能保持长寿命的同步相干振荡；强相互作用引发耗散相变进入自囚禁 regime 并伴随混沌动力学；耗散可调控混沌持续时间并在长时间恢复相干性；引入势阱倾斜可将瞬态混沌转变为稳态混沌；传统谱诊断方法无法区分两种混沌态，表明其主要反映短时不稳定性。

Conclusion: 耗散可作为一种强大工具，用于工程化设计量子系统的动力学相、恢复量子相干性，并控制混沌行为和信息 scrambling 的持续时间。

Abstract: Dissipation is commonly regarded as an obstacle to quantum control, as it induces decoherence and irreversibility. Here we demonstrate that dissipation can instead be exploited as a resource to reshape the dynamics of interacting quantum systems. Using an experimentally realizable Bose-Josephson junction containing two bosonic species, we demonstrate that dissipation enables distinct dynamical behaviors: synchronized phase-locked oscillations, transient chaos with long-time coherence recovery, and steady-state chaos. The emergence of each behavior is determined by experimentally tunable parameters. At weak interactions, the two components synchronize despite dissipation, exhibiting long-lived coherent oscillations reminiscent of a boundary time crystal. Stronger interactions induce a dissipative phase transition into a self-trapped regime accompanied by chaotic dynamics. Remarkably, dissipation regulates the lifetime of chaos and enables the recovery of coherence at long times. By introducing a controlled tilt between the wells, transient chaos can be converted into persistent steady-state chaos. We further show that standard spectral diagnostics fail to distinguish between the two chaotic regimes, revealing that spectral statistics primarily reflect short-time instability. These results establish dissipation as a powerful tool for engineering dynamical phases, restoring quantum coherence, and controlling the duration of chaotic behavior and information scrambling.

</details>


### [41] [Quantum Circuits as a Dynamical Resource to Learn Nonequilibrium Long-Range Order](https://arxiv.org/abs/2602.16788)
*Fabian Ballar Trigueros,Markus Heyl*

Main category: quant-ph

TL;DR: 该研究利用变分量子电路生成了一维系统中具有长程有序的非平衡态，突破了平衡态统计系综（如Mermin-Wagner定理）的限制，并展现出接近GHZ态的优异计量性能且对局域测量鲁棒。


<details>
  <summary>Details</summary>
Motivation: 探索在平衡态下无法实现的量子物态，特别是低维系统中受Mermin-Wagner定理限制的长程有序态。

Method: 构建变分量子电路来学习并生成具有对称性破缺和对称性保护拓扑性质的非平衡量子态。

Result: 成功生成了在有限能量密度下一维系统中的长程有序态，这些态在平衡态下通常是无特征的；所学态具有类GHZ态的高量子Fisher信息，且对局域测量保持鲁棒性。

Conclusion: 相干量子动力学是一种强大的资源，可用于工程化超越平衡系综约束的非平衡物相，拓展了量子序的动力学范畴。

Abstract: Equilibrium statistical ensembles impose stringent constraints on phases of quantum matter. For example, the Mermin-Wagner theorem prohibits long-range order in low-dimensional systems beyond the ground state. Here, we show that quantum circuits can learn states of matter with long-range order that are inaccessible in equilibrium. We construct variational quantum circuits that generate symmetry-broken and symmetry-protected topological states with long-range order in one-dimensional systems at finite energy density, where equilibrium states are typically featureless. Importantly, the learned states can exhibit unconventional features with enhanced metrological properties such as a quantum Fisher information close to a GHZ state, but robust against local measurements. Our work establishes coherent quantum dynamics as a powerful resource for engineering nonequilibrium phases of matter, opening a path toward a broader dynamical scope of quantum order beyond the constraints of equilibrium ensembles.

</details>


### [42] [When Does Quantum Annealing Outperform Classical Methods? A Gradient Variance Framework](https://arxiv.org/abs/2602.16875)
*Vishwajeet Ohal,Pierre Boulanger*

Main category: quant-ph

TL;DR: 本文提出了一种针对量子退火与经典方法选择的决策框架，依据问题的梯度方差、能量景观特征、问题规模和应用需求来推荐使用纯量子、经典或混合方法。


<details>
  <summary>Details</summary>
Motivation: 为帮助实践者在量子退火和经典优化方法之间做出合理选择，解决因问题特征不同导致的算法性能差异问题。

Method: 基于实验结果，提出一个决策框架，根据QUBO问题的梯度方差、能量景观结构、问题规模、硬件限制和时间开销等因素进行分类推荐。

Result: 高梯度方差（>0.3）和复杂能量景观适合量子退火；低梯度方差（<0.2）和平滑景观适合经典方法；超出纯量子能力但结构有利的问题推荐使用可验证分解质量的混合方法。

Conclusion: 该决策框架为不同问题特征下的优化算法选择提供了实用指导，有助于提升求解效率与质量。

Abstract: Based on our experimental findings, we propose the following decision framework for practitioners. Quantum annealing is recommended when the problem formulation QUBO exhibits a high gradient variance (greater than 0.3) and the energy landscape contains numerous thin barriers characterized by sharp peaks and narrow valleys. Additionally, quantum approaches are particularly suitable when classical methods are observed to get trapped in local minima, the problem size is manageable given hardware constraints (less than 5000 variables for pure quantum annealing), and the time overhead of approximately 10 seconds is acceptable for the application.
  In contrast, classical methods are recommended when the gradient variance is low (less than 0.2), indicating smooth landscapes where quantum tunneling provides little advantage. Classical approaches are also preferable when the problem size is small and classical solvers can provide nearly instantaneous results, when solution quality requirements are modest and local optima suffice, or when hardware access or cost is a limiting factor.
  For problems that exceed pure quantum capacity but possess a favorable landscape structure, hybrid approaches combining quantum and classical techniques are recommended. Such hybrid methods are particularly effective when decomposition quality can be verified and both solution quality and scalability are important considerations.

</details>


### [43] [Les Houches lectures on random quantum circuits and monitored quantum dynamics](https://arxiv.org/abs/2602.17258)
*Romain Vasseur*

Main category: quant-ph

TL;DR: 本文基于作者在Les Houches 2025暑期学校上的讲座，探讨了将统计力学的思想应用于理想和受监测的随机量子电路中量子信息动力学的研究，尽管单个实现的精确描述通常是难以处理的。


<details>
  <summary>Details</summary>
Motivation: 由于理想和受监测的随机量子电路中个体实现的精确描述通常不可行，因此需要采用统计力学的方法来理解量子信息的动力学行为。

Method: 应用统计力学的哲学框架，对随机量子电路中的量子信息动力学进行理论分析。

Result: 提供了一种有效的方法来研究复杂量子系统中信息演化的方式，即使无法精确描述每个具体实现。

Conclusion: 统计力学的思想为研究难以精确求解的随机量子电路中的信息动力学提供了有力工具。

Abstract: These lecture notes are based on lectures given by the author at the Les Houches 2025 summer school on "Exact Solvability and Quantum Information". The central theme of these notes is to apply the philosophy of statistical mechanics to study the dynamics of quantum information in ideal and monitored random quantum circuits -- for which an exact description of individual realizations is expected to be generically intractable.

</details>


### [44] [In situ calibration of microwave attenuation and gain using a cryogenic on-chip attenuator](https://arxiv.org/abs/2602.16889)
*Thomas Descamps,Linus Andersson,Vittorio Buccheri,Simon Sundelin,Mohammed Ali Aamir,Simone Gasparinetti*

Main category: quant-ph

TL;DR: 提出了一种紧凑型自校准低温噪声源，用于原位精确标定微波衰减和放大链噪声，适用于超导量子电路。


<details>
  <summary>Details</summary>
Motivation: 准确的原位校准微波衰减和放大链噪声对超导量子电路至关重要，但传统方法依赖于对衰减器温度的精确测量，难以实现高精度。

Method: 基于片上铬衰减器开发了一种可电阻加热并集成到同轴微波线路中的紧凑型自校准低温噪声源；通过比较焦耳热和微波加热产生的约翰逊-奈奎斯特噪声来确定输入线衰减和放大链增益，无需知道衰减器实际温度。

Result: 器件具有毫秒级响应时间，对制冷机基板几乎无额外加热；在4-8 GHz频段内成功测定了低温放大链的增益和附加噪声。

Conclusion: 该方法为表征近量子极限参量放大器（用于超导量子比特读出）提供了一种简单而精确的方案，具备良好的实用性和集成性。

Abstract: Accurate in situ calibration of microwave attenuation and amplification-chain noise is essential for superconducting quantum circuits. We demonstrate a compact, self-calibrating cryogenic noise source based on an on-chip chromium attenuator that can be resistively heated with nanowatt-level power and directly integrated into a coaxial microwave line at the mixing-chamber stage. By comparing Johnson-Nyquist noise generated by Joule and microwave heating, measured through the amplification chain, the attenuation of the input line, and hence the gain of the chain, is determined without requiring knowledge of the attenuator temperature. The device exhibits millisecond-scale response times and negligible heating of the cryostat base plate. Using this approach, we determine the gain and added noise of a cryogenic amplification chain over the 4-8 GHz band. Our results provide a simple and accurate method to characterize near-quantum-limited parametric amplifiers used in superconducting-qubit readout.

</details>


### [45] [Optimal speed-up of multi-step Pontus-Mpemba protocols](https://arxiv.org/abs/2602.17296)
*Marco Peluso,Reinhold Egger,Andrea Nava*

Main category: quant-ph

TL;DR: 研究了开放量子系统中的多步Pontus-Mpemba效应，在时间非齐次Lindblad主方程下，发现连续协议中存在由时变耗散率引起的有效动力学捷径和非马尔可夫行为。


<details>
  <summary>Details</summary>
Motivation: 探索包含制备时间的Pontus-Mpemba效应在量子系统中的表现，特别是在非平衡跃迁后的动力学行为。

Method: 基于时间非齐次Lindblad主方程，分析多步及连续Pontus-Mpemba协议下的开放量子系统动力学。

Result: 发现在准静态与突变淬火之间存在动力学生成的捷径，且时变耗散率可引发非马尔可夫行为。

Conclusion: 开放量子系统中可通过时变耗散实现高效冷却路径，并揭示超越马尔可夫框架的丰富动力学机制。

Abstract: The classical Mpemba effect is the counterintuitive phenomenon where hotter water freezes faster than colder water due to the breakdown of Newton's law of cooling after a sudden temperature quench. The genuine nonequilibrium post-quench dynamics allows the system to evolve along effective shortcuts absent in the quasi-static regime. When the time needed for preparing the (classical or quantum) system in the hotter initial state is included, we encounter so-called Pontus-Mpemba effects. We here investigate multi-step Pontus-Mpemba protocols for open quantum systems whose dynamics is governed by time-inhomogeneous Lindblad master equations. In the limit of infinitely many steps, one arrives at continuous Pontus-Mpemba protocols. We study the crossover between the quasi-static and the sudden-quench regime, showing the presence of dynamically generated shortcuts achieved for time-dependent dissipation rates. Time-dependent rates can also cause non-Markovian behavior, highlighting the existence of rich dynamical regimes accessible beyond the Markovian framework.

</details>


### [46] [From superradiance to collective EIT in three-level ensembles](https://arxiv.org/abs/2602.16892)
*Hugo Sanchez,Luis F. A. da Silva,Mickel A. Ponte,Miled H. Y. Moussa,Norton G. de Almeida*

Main category: quant-ph

TL;DR: 该论文研究了三能级系综在Dicke极限下的集体动力学，揭示了超辐射发射与电磁感应透明（EIT）之间的统一联系。通过提出一种代表性原子主方程，成功描述了瞬态超辐射和稳态EIT响应，并发现集体相互作用对慢光延迟的根本限制。


<details>
  <summary>Details</summary>
Motivation: 探索超辐射与EIT这两种看似不同的量子现象之间是否存在深层关联，并理解在有限尺寸和集体效应下它们的动力学行为。

Method: 推导出一种代表性原子主方程，能够准确再现超辐射和EIT两种机制，且与对称子空间的精确动力学一致，包含集体反馈和N依赖的展宽效应。

Result: 发现瞬态超辐射峰强遵循I_max ~ N^2标度律，具有普适的有限尺寸修正；在稳态EIT中，集体展宽虽增强吸收却反常地提高群速度，导致v_g ∝ N^2；表明协同效应从根本上限制了密介质中的慢光延迟。

Conclusion: 超辐射与EIT可在同一框架下统一描述，集体相互作用不仅影响光学响应，还对量子存储和精密测量等应用中的慢光性能设定了基本极限。

Abstract: We investigate the collective dynamics of a three-level ensemble under the Dicke limit, revealing a unified connection between superradiant emission and electromagnetically induced transparency (EIT). Our results show that the transient superradiant burst exhibits the expected peak intensity scaling $I_{\max}\!\sim\! N^2$, with a universal finite-size correction $|ξ(N)-2|\!\sim\! 1/\ln N$ that governs the apparent scaling exponent in realistic ensembles. In the stationary regime, collective broadening modifies the EIT response: although it typically enhances absorption, it counterintuitively increases the group velocity, leading to a relative scaling $v_g\!\propto\! N^2$, even while $v_g\!\ll\! c$. This effect suggests that cooperative interactions fundamentally limit the achievable slow-light delay in dense media. To achieve these results, we derive a representative-atom master equation that quantitatively reproduces both the superradiant and EIT regimes, in excellent agreement with the exact symmetric-subspace dynamics and correctly incorporating collective feedback and $N$-dependent broadening. This unified framework bridges transient superradiant emission and steady-state quantum interference, with direct implications for slow light, quantum memories, and precision metrology.

</details>


### [47] [Free Quantum Computing](https://arxiv.org/abs/2602.16927)
*Jacques Carette,Chris Heunen,Robin Kaarsgaard,Neil J. Ross,Amr Sabry*

Main category: quant-ph

TL;DR: 本文提出了一种基于离散公理化和范畴论模型的量子计算新框架，通过从可逆经典计算出发并引入特定平方根操作来刻画量子优势，为量子计算提供了更清晰的理论基础，并支持自动化验证与优化。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解量子计算与经典计算之间的关系，需要一种仅包含实现量子计算所必需物理原理的自由模型，从而揭示量子优势的本质。

Method: 采用离散方程替代传统的连续假设，构建基于范畴论的自由模型，该模型以可逆经典计算为基础，并通过引入具有良好性质的平方根操作来体现量子特性。

Result: 提出了一个等价于标准线性代数模型但更具结构化的量子计算模型，能够连接多种硬件平台，支持组合优化和暴力搜索进行量子算法优化，并可作为支持自动验证的量子编程语言。

Conclusion: 该工作为量子计算提供了一个简洁、离散且可形式化推理的新范式，有助于深化对量子与经典计算关系的理解，并推动量子程序的自动化分析与优化。

Abstract: Quantum computing improves substantially on known classical algorithms for various important problems, but the nature of the relationship between quantum and classical computing is not yet fully understood. This relationship can be clarified by free models, that add to classical computing just enough physical principles to represent quantum computing and no more. Here we develop an axiomatisation of quantum computing that replaces the standard continuous postulates with a small number of discrete equations, as well as a free model that replaces the standard linear-algebraic model with a category-theoretical one. The axioms and model are based on reversible classical computing, isolate quantum advantage in the ability to take certain well-behaved square roots, and link to various quantum computing hardware platforms. This approach allows combinatorial optimisation, including brute force computer search, to optimise quantum computations. The free model may be interpreted as a programming language for quantum computers, that has the same expressivity and computational universality as the standard model, but additionally allows automated verification and reasoning.

</details>


### [48] [The Hidden Nature of Non-Markovianity](https://arxiv.org/abs/2602.17631)
*Jihong Cai,Advith Govindarajan,Marius Junge*

Main category: quant-ph

TL;DR: 本文探讨了马尔可夫和非马尔可夫开放量子系统演化轨迹的比较，发现单个轨迹下非马尔可夫性不可见。


<details>
  <summary>Details</summary>
Motivation: 研究非马尔可夫演化是否在特定条件下优于马尔可夫演化，并揭示其在量子态制备中的作用。

Method: 通过分析时间依赖林德布拉德算符描述的马尔可夫与非马尔可夫演化轨迹，比较它们的动力学行为。

Result: 在温和假设下，每个轨迹都可以由一族时间依赖林德布拉德算符生成，因此在仅考虑单个轨迹时，非马尔可夫性是不可区分的。

Conclusion: 单独观察轨迹无法识别非马尔可夫性，这对利用非马尔可夫性增强量子技术提出了挑战。

Abstract: The theory of open quantum systems served as a tool to prepare entanglement at the beginning stage of quantum technology and more recently provides an important tool for state preparation. Dynamics given by time dependent Lindbladians are Markovian and lead to decoherence, decay of correlation and convergence to equilibrium. In contrast Non-Markovian evolutions can outperform their Markovian counterparts by enhancing memory. In this letter we compare the trajectories of Markovian and Non-Markovian evolutions starting from a fixed initial value. It turns out that under mild assumptions every trajectory can be obtained from a family of time dependent Lindbladians. Hence Non-Markovianity is invisible if single trajectories are concerned.

</details>


### [49] [A Study of Entanglement and Ansatz Expressivity for the Transverse-Field Ising Model using Variational Quantum Eigensolver](https://arxiv.org/abs/2602.17662)
*Ashutosh P. Tripathi,Nilmani Mathur,Vikram Tripathi*

Main category: quant-ph

TL;DR: 研究了变分量子本征求解器（VQE）在不同纠缠和简并情况下的本征态制备性能，使用横场伊辛模型在多种维度和边界条件下进行测试，并比较了多种试探波函数的表现。


<details>
  <summary>Details</summary>
Motivation: VQE在NISQ时代具有重要意义，但在处理强纠缠和简并系统时面临本征态制备困难的问题，需要评估其在不同模型和试探波函数下的可靠性与有效性。

Method: 采用一维、二维和三维周期边界条件的横场伊辛模型，最大达27个量子比特，结合Qiskit的EfficientSU2、物理启发的HVA及对称性破缺HVA等多种试探波函数，通过能量方差、纠缠熵、自旋关联和磁化强度等指标进行性能评估。

Result: 不同试探波函数在能量精度、纠缠生成和物理量预测方面表现各异，HVA类方法在物理一致性上更优，而硬件高效型ansatz在优化效率上有优势但可能偏离真实物理态。

Conclusion: 试探波函数的选择显著影响VQE在复杂多体系统中的表现，需结合物理先验知识与硬件限制来设计更可靠的量子算法。

Abstract: The Variational Quantum Eigensolver (VQE) is a leading hybrid quantum-classical algorithm for simulating many-body systems in the NISQ era. Its effectiveness, however, depends on the faithful preparation of eigenstates, which becomes challenging in degenerate and strongly entangled regimes. We study this problem using the transverse-field Ising model (TFIM) with periodic boundary conditions in one, two, and three dimensions, considering systems of up to 27 qubits. We employ different ansatzes: the hardware-efficient EfficientSU2 from Qiskit, the physics-inspired Hamiltonian Variational Ansatz (HVA) and HVA with symmetry breaking, and benchmark their performance using energy variance, entanglement entropy, spin correlations, and magnetization.

</details>


### [50] [Adaptive Aborting Schemes for Quantum Error Correction Decoding](https://arxiv.org/abs/2602.16929)
*Sanidhay Bhambay,Prakash Murali,Neil Walton,Thirupathaiah Vasantam*

Main category: quant-ph

TL;DR: 本文提出了一种自适应中止模块（AdAbort），用于量子纠错控制中，通过实时分析初始综合征数据提前终止高风险的测量过程，从而减少解码开销并降低逻辑错误率。与传统的固定深度解码和另一种自适应方法OSLA相比，AdAbort在表面码和颜色码下均表现出更高的解码效率，且随着码距增大优势更明显。


<details>
  <summary>Details</summary>
Motivation: 当前的量子纠错控制器在所有综合征测量完成前无法判断实验是否失败，导致不必要的测量增加了解码负担和系统延迟。为提升效率，需要一种能根据早期综合征信息动态调整测量轮数的机制。

Method: 提出了两种自适应中止方案：AdAbort 和 One-Step Lookahead (OSLA)，并与固定的非自适应方案（FD）进行对比。基于电路级去极化噪声模型，对不同码距下的表面码和颜色码进行数值模拟，评估各方案在解码效率和逻辑错误率方面的表现。

Result: AdAbort 在表面码和颜色码上均显著优于 OSLA 和 FD 方案；当码距从5增至15时，AdAbort 的效率提升在表面码中达5%至35%，在颜色码中达7%至60%。

Conclusion: 自适应中止策略（尤其是AdAbort）能有效提升量子纠错系统的解码效率并降低资源消耗，是迈向大规模、资源密集型量子计算架构的重要一步。

Abstract: Quantum error correction (QEC) is essential for realizing fault-tolerant quantum computation. Current QEC controllers execute all scheduled syndrome (parity-bit) measurement rounds before decoding, even when early syndrome data indicates that the run will result in an error. The resulting excess measurements increase the decoder's workload and system latency. To address this, we introduce an adaptive abort module that simultaneously reduces decoder overhead and suppresses logical error rates in surface codes and color codes under an existing QEC controller. The key idea is that initial syndrome information allows the controller to terminate risky shots early before additional resources are spent. An effective scheme balances the cost of further measurement against the restart cost and thus increases decoder efficiency.
  Adaptive abort schemes dynamically adjust the number of syndrome measurement rounds per shot using real-time syndrome information. We consider three schemes: fixed-depth (FD) decoding (the standard non-adaptive approach used in current state-of-the-art QEC controllers), and two adaptive schemes, AdAbort and One-Step Lookahead (OSLA) decoding. For surface and color codes under a realistic circuit-level depolarizing noise model, AdAbort substantially outperforms both OSLA and FD, yielding higher decoder efficiency across a broad range of code distances. Numerically, as the code distance increases from 5 to 15, AdAbort yields an improvement that increases from 5% to 35% for surface codes and from 7% to 60% for color codes.
  To our knowledge, these are the first adaptive abort schemes considered for QEC. Our results highlight the potential importance of abort rules for increasing efficiency as we scale to large, resource-intensive quantum architectures.

</details>


### [51] [Fault-tolerant interfaces for quantum LDPC codes](https://arxiv.org/abs/2602.16948)
*Matthias Christandl,Omar Fawzi,Ashutosh Goswami*

Main category: quant-ph

TL;DR: 本文提出了一种具有恒定空间开销的容错量子态制备方法，通过构建可降低量子低密度奇偶校验码保护级别的容错接口，克服了误差累积和开销瓶颈。


<details>
  <summary>Details</summary>
Motivation: 在含噪声的量子计算机上制备量子态会受到门噪声影响，传统容错方案需要对数多项式级空间开销，限制了大规模应用，因此需要更高效的方法。

Method: 设计了针对具有量子输入输出电路的容错方案，构造了可降低LDPC码保护级别的容错接口，并通过逐步降低编码级别同时增加并行解码块数来实现任意程度的保护级别转换。

Result: 实现了常数级别的空间开销，优于以往的polylogarithmic开销方案，并有效避免了误差堆积问题。

Conclusion: 该工作推进了容错量子计算的效率边界，为多区块编码下的低开销量子信息处理提供了新工具。

Abstract: The preparation of a quantum state using a noisy quantum computer (gate noise strength $δ$), will necessarily affect an O($δ$)-fraction of the qubits, no matter which protocol is used. Here, we show that fault-tolerant quantum state preparation can be achieved with constant space overhead improving on previous constructions requiring polylogarithmic overhead.
  To achieve this, we add to the toolbox of fault-tolerant schemes for circuits with quantum input and output. More specifically, we construct fault-tolerant interfaces that decrease the level of protection for quantum low-density parity-check (LDPC) codes. When information is encoded in multiple code blocks, our interfaces have constant space overhead.
  In our decoder construction that change the level of protection by an arbitrary amount, we circumvent bottlenecks to error pileup and overhead by gradual lowering of the level of encoding at the same time as we increase the number of blocks on which decoding is carried out simultaneously.

</details>


### [52] [Weak-Value Amplification for Longitudinal Phase Measurements Approaching the Shot-Noise Limit Characterized by Allan Variance](https://arxiv.org/abs/2602.17035)
*Jing-Hui Huang,Xiang-Yun Hu*

Main category: quant-ph

TL;DR: 该论文通过Allan方差分析，验证了弱值放大（WVA）在纵向相位测量中可实现接近散粒噪声极限的高精度，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 旨在定量评估弱值放大（WVA）在光学精密测量中的实际噪声性能，尤其是在存在技术噪声和探测器饱和的情况下是否优于传统测量方法。

Method: 基于双缝干涉实验，采用Allan方差分析对WVA的噪声特性进行量化，并考察其与探测光子数的关系。

Result: 实现了attosecond量级的时间延迟测量，在短平均时间下比先前工作降低了两个数量级的方差；实验确认Allan方差噪声底限随探测光子数的倒数1/Nr变化，达到散粒噪声极限。

Conclusion: WVA在固定探测光子数和探测器饱和条件下可超越传统测量，具备近最优的噪声性能，为高精度光学计量（如引力波探测）提供了新的基准。

Abstract: We report a quantitative evaluation of weak-value amplification (WVA) for longitudinal phase measurements using Allan variance analysis. Building on a recent double-slit interferometry experiment with real weak values [Phys. Rev. Lett. 134, 080802 (2025)], our Allan variance analysis demonstrates measurement of a few attosecond time delay approaching the shot noise limit at short averaging intervals of $T$ = $0.01-0.1$ s, representing two orders of magnitude variance reduction compared to the $T=300$ s operating point in prior implementations. We demonstrate that the Allan-variance noise floor scales with the inverse of the detected photon number $1/N_r$, confirming shot-noise-limited operation with WVA. Furthermore, this $1/N_r$ scaling experimentally validates that WVA can outperform conventional measurement under fixed detected photon number and detector saturation, in the presence of technical noise, as theoretically predicted [Phys. Rev. Lett. 118, 070802 (2017)]. Our results provide rigorous, quantitative evidence of the near-optimal noise performance achievable with WVA, establishing a new benchmark for precision optical metrology. This advancement is particularly relevant to applications such as gravitational-wave detection, where signals predominantly occupy the high-frequency regime ($>10$ Hz).

</details>


### [53] [Quantum-Channel Matrix Optimization for Holevo Bound Enhancement](https://arxiv.org/abs/2602.17065)
*Hong Niu,Chau Yuen,Alexei Ashikhmin,Lajos Hanzo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum communication holds the potential to revolutionize information transmission by enabling secure data exchange that exceeds the limits of classical systems. One of the key performance metrics in quantum information theory, namely the Holevo bound, quantifies the amount of classical information that can be transmitted reliably over a quantum channel. However, computing and optimizing the Holevo bound remains a challenging task due to its dependence on both the quantum input ensemble and the quantum channel. In order to maximize the Holevo bound, we propose a unified projected gradient ascent algorithm to optimize the quantum channel given a fixed input ensemble. We provide a detailed complexity analysis for the proposed algorithm. Simulation results demonstrate that the proposed quantum channel optimization yields higher Holevo bounds than input ensemble optimization.

</details>


### [54] [Mesoscopic Spin Coherence in a Disordered Dark Electron Spin Ensemble](https://arxiv.org/abs/2602.17074)
*Taewoong Yoon,Sangwon Oh,Junghyun Lee,Hyunyong Choi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Harnessing dipolar spin environments as controllable quantum resources is a central challenge in solid-state quantum technologies. Here, we report the observation of a coherent mesoscopic spin state in a disordered ensemble of substitutional nitrogen (P1) centers in diamond. An iterative Hartmann-Hahn protocol transfers polarization from dense nitrogen-vacancy (NV) centers to a P1 ensemble, yielding a 740-fold enhancement over room-temperature thermal equilibrium as revealed by differential readout. The resulting mesoscopic P1 spin ensemble exhibits collective Rabi oscillations and long-lived spin-lock and Hahn-echo coherences. We identify a crossover in the saturation polarization arising from the competition between coherent driving and local disorder, providing a quantitative measure of the system's intrinsic disorder. These results establish a foundation for utilizing dark electron spin ensembles as robust resources for quantum sensing and quantum many-body simulation.

</details>


### [55] [Boosting the Performance of a Lipkin-Meshkov-Glick Quantum Battery via Symmetry-Breaking Quenches and Bosonic Baths](https://arxiv.org/abs/2602.17121)
*Le Bin Ho,Duc Tuan Hoang,Tran Duong Anh-Tai,Thomas Busch,Thomás Fogarty*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We explore the operation of quantum batteries in the Lipkin-Meshkov-Glick (LMG) model, when they are charged either through a sudden quench in the magnetic field strength or by coupling them to a bosonic oscillator bath. Through initializing the battery in either the symmetric or broken symmetry phases of the LMG model we analyze how the different spectral properties can affect the performance of both the charging and discharging of the battery. In particular, we show that by quenching the magnetic field strength from the symmetric phase to the broken phase, we can achieve a significant enhancement in stored energy, as well as stable and efficient ergotropy extraction. Similar observations can be made when introducing weak coupling between the battery with the bosonic bath, while the amount of stored work and ergotropy saturate at strong coupling. These findings emphasize the importance of the magnetic field dynamics and environmental coupling in optimizing charging performance, which could lead to practical applications in quantum energy storage.

</details>


### [56] [Phonon-enhanced strain sensitivity of quantum dots in two-dimensional semiconductors](https://arxiv.org/abs/2602.17212)
*Sumitra Shit,Yunus Waheed,Jithin Thoppil Surendran,Indrajeet Dhananjay Prasad,Kenji Watanabe,Takashi Taniguchi,Santosh Kumar*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Two-dimensional semiconductors have attracted considerable interest for integration into emerging quantum photonic networks. Strain engineering of monolayer transition-metal dichalcogenides (ML-TMDs) enables the tuning of light-matter interactions and associated optoelectronic properties, and generates new functionalities, including the formation of quantum dots (QDs). Here, we combine spatially resolved micro-photoluminescence ($μ$-PL) spectroscopy from cryogenic (4$\text{-}$94 K) to room temperature with micro-Raman spectroscopy at room temperature to investigate the strain-dependent emission energies of thousands of individual QDs in ML-WS$_2$ and ML-WSe$_2$, integrated across multiple heterostructures and a piezoelectric device. Compared with delocalized excitons, QDs in both materials exhibit enhanced strain sensitivities of their emission energies $-$ approximately fourfold in WS$_2$ and twofold in WSe$_2$ $-$ leading to pronounced broadening of the ensemble emission linewidth. Temperature-dependent $μ$-PL spectroscopy combined with dynamic strain tuning experiments further reveal that the enhanced strain sensitivity of individual QDs originates from strengthened interactions with low-energy phonons induced by quantum confinement. Our results demonstrate a versatile strain-engineering approach with potential for spectral matching across solid-state, atomic, and hybrid quantum photonic networks, and provide new insights into phonon-QD interactions in two-dimensional semiconductors.

</details>


### [57] [Extending quantum theory with AI-assisted deterministic game theory](https://arxiv.org/abs/2602.17213)
*Florian Pauschitz,Ben Moseley,Ghislain Fourny*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present an AI-assisted framework for predicting individual runs of complex quantum experiments, including contextuality and causality (adaptive measurements), within our long-term programme of discovering a local hidden-variable theory that extends quantum theory. In order to circumvent impossibility theorems, we replace the assumption of free choice (measurement independence and parameter independence) with a weaker, compatibilistic version called contingent free choice.
  Our framework is based on interpreting complex quantum experiments as a Chess-like game between observers and the universe, which is seen as an economic agent minimizing action. The game structures corresponding to generic experiments such as fixed-causal-order process matrices or causal contextuality scenarios, together with a deterministic non-Nashian resolution algorithm that abandons unilateral deviation assumptions (free choice) and assumes Perfect Prediction instead, were described in previous work.
  In this new research, we learn the reward functions of the game, which contain a hidden variable, using neural networks. The cost function is the Kullback-Leibler divergence between the frequency histograms obtained through many deterministic runs of the game and the predictions of the extended Born rule.
  Using our framework on the specific case of the EPR 2-2-2 experiment acts as a proof-of-concept and a toy local-realist hidden-variable model that non-Nashian quantum theory is a promising avenue towards a local hidden-variable theory. Our framework constitutes a solid foundation, which can be further expanded in order to fully discover a complete quantum theory.

</details>


### [58] [Quantum key distribution over a metropolitan network using an integrated photonics based prototype](https://arxiv.org/abs/2602.17227)
*Maria Ana Pereira,Giulio Gualandi,Rebecka Sax,Alberto Boaron,Raphaël Houlmann,Roberto Osellame,Rob Thew,Hugo Zbinden*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: An industrial-scale adoption of Quantum Key Distribution (QKD) requires the development of practical, stable, resilient and cost-effective hardware that can be manufactured at large scales. In this work we present a high-speed (1.25GHz), field-deployable QKD prototype based on integrated photonics, that is consolidated into standard 19-inch rack compatible units. Through integrated photonics, the system prioritizes autonomous long-term stability in metropolitan settings. The architecture is further simplified by removing the need for chromatic dispersion compensation over metropolitan distances (below 100km). We demonstrate continuous key exchange over more than 4 km of metropolitan optical fiber, where the prototype maintained stable, uninterrupted operation across a measurement spanning more than 12 day-night cycles without manual intervention.

</details>


### [59] [Near-single-domain superconducting aluminum films on GaAs(111)A with exceptional crystalline quality for scalable quantum circuits](https://arxiv.org/abs/2602.17249)
*Hsien-Wen Wan,Yi-Ting Cheng,Chao-Kai Cheng,Jui-Min Chia,Chien-Ting Wu,Sheng-Shiuan Yeh,Chia-Hung Hsu,Jueinai Kwo,Minghwei Hong*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We have reproducibly grown near-single-domain superconducting aluminum (Al) films on GaAs(111)A wafers using molecular beam epitaxy. Synchrotron X-ray diffraction revealed twin-domain ratios of 0.00005 and 0.0003 for 19.4-nm- and 9.6-nm-thick films, respectively-the lowest reported for Al on any substrate and long considered unattainable for practical device platforms. Azimuthal scans across off-normal Al{$11\bar{1}$} reflections exhibit narrow full width at half maximum (FWHM) values down to $0.55^\circ$, unmatched by epi-Al grown by any other method. Normal scans showed a well-defined (111) orientation with pronounced Pendellösung fringes, and $θ$-rocking-curve FWHM values down to $0.018^\circ$; the former indicates abrupt film-substrate and oxide-film interfaces. Electron backscatter diffraction mapping confirms macroscopic in-plane uniformity and the absence of $Σ$3 twin domains. Atomic force microscopy and scanning transmission electron microscopy confirmed atomically smooth surfaces and abrupt heterointerfaces. The films exhibit critical temperatures approaching bulk values, establishing a materials platform for scalable, high-coherence superconducting qubits.

</details>


### [60] [Quantum Scrambling Born Machine](https://arxiv.org/abs/2602.17281)
*Marcin Płodzień*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum generative modeling, where the Born rule naturally defines probability distributions through measurement of parameterized quantum states, is a promising near-term application of quantum computing. We propose a Quantum Scrambling Born Machine in which a fixed entangling unitary -- acting as a scrambling reservoir -- provides multi-qubit entanglement, while only single-qubit rotations are optimized. We consider three entangling unitaries -- a Haar random unitary and two physically realizable approximations, a finite-depth brickwork random circuit and analog time evolution under nearest-neighbor spin-chain Hamiltonians -- and show that, for the benchmark distributions and system sizes considered, once the entangler produces near-Haar-typical entanglement the model learns the target distribution with weak sensitivity to the scrambler's microscopic origin. Finally, promoting the Hamiltonian couplings to trainable parameters casts the generative task as a variational Hamiltonian problem, with performance competitive with representative classical generative models at matched parameter count.

</details>


### [61] [A rigorous hybridization of variational quantum eigensolver and classical neural network](https://arxiv.org/abs/2602.17295)
*Minwoo Kim,Kyoung Keun Park,Kyungmin Lee,Jeongho Bang,Taehyun Kim*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Neural post-processing has been proposed as a lightweight route to enhance variational quantum eigensolvers by learning how to reweight measurement outcomes. In this work, we identify three general desiderata for such data-driven neural post-processing -- (i) self-contained training without prior knowledge, (ii) polynomial resources, and (iii) variational consistency -- and show that current approaches, such as diagonal non-unitary post-processing (DNP), cannot satisfy these requirements simultaneously. The obstruction is intrinsic: with finite sampling, normalization becomes a statistical bottleneck, and support mismatch between numerator and denominator estimators can render the empirical objective ill-conditioned and even sub-variational. Moreover, to reproduce the ground state with constant-depth ansatzes or with linear-depth circuits forming unitary 2-designs, the required reweighting range (and hence the sampling cost) grows exponentially with the number of qubits. Motivated by this no-go result, we develop a normalization-free alternative, the unitary variational quantum-neural hybrid eigensolver (U-VQNHE). U-VQNHE retains the practical appeal of a learnable diagonal post-processing layer while guaranteeing variational safety, and numerical experiments on transverse-field Ising models demonstrate improved accuracy and robustness over both VQE and DNP-based variants.

</details>


### [62] [Two-dimensional quantum lattice gas algorithm for anisotropic Burger-like equations](https://arxiv.org/abs/2602.17303)
*Niccoló Fonio,Pierre Sagaut,Giuseppe Di Molfetta*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Building on hybrid quantum lattice gas algorithm, we revisit the possibilities of this quantum lattice model. By deriving a correction to the predicted viscosity, we provide analytical and numerical results that refine original formulation. We introduce a minimal 2D generalization of the algorithm, which allows to simulate anisotropic Burgerlike equations while retaining only two lattice velocities. This approach opens a promising route toward embedding momentum conservation and advancing toward NavierStokes dynamics in 2D, going beyond Frisch, Hasslacher and Pomeau (FHP) with a quantum native model.

</details>


### [63] [Near-perfect quantum teleportation between continuous and discrete encodings](https://arxiv.org/abs/2602.17306)
*Ravi Kamal Pandey,Shraddha Singh,Dhiraj Yadav,Devendra Kumar Mishra*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum teleportation between polarized single-photon and phase-opposite coherent states is studied using a hybrid entangled resource and entangled coherent states. The polarized single-photon qubit represents a discrete-variable (DV) quantum system, whereas the phase-opposite coherent-state qubit constitutes a continuous-variable (CV) system. While teleportation from CV to DV can be achieved with near-unit success probability, the reverse process is usually limited to a maximum success probability of $1/2$. We demonstrate that, by employing cross-Kerr nonlinearity together with passive linear optical components such as polarizing beam splitters, beam splitters, and phase shifters, almost perfect teleportation from DV to CV encodings can also be achieved.

</details>


### [64] [Dissipative charging of tight-binding quantum batteries](https://arxiv.org/abs/2602.17326)
*Mingdi Xu,Yiming Liu,Yefeng Song,Xiang-Ping Jiang,Lei Pan*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate autonomous dissipative charging mechanisms for lattice quantum batteries within the framework of open quantum systems. Focusing on engineered Markovian dissipation, we show that appropriately designed Lindblad jump operators can drive tight-binding systems into highly excited band-edge states, resulting in steady states with large ergotropy. We illustrate this mechanism in a one-dimensional tight-binding chain and in a two-dimensional graphene lattice. We find that disorder enhances the charging power, indicating that dissipation-assisted localization effects can be beneficial for energy storage. Moreover, the dissipative charging process remains robust against additional local dephasing noise. Our results establish bond dissipation as an effective and physically transparent mechanism for charging lattice quantum batteries in realistic open-system settings.

</details>


### [65] [Detecting nonequilibrium phase transitions via continuous monitoring of space-time trajectories and autoencoder-based clustering](https://arxiv.org/abs/2602.17341)
*Erik Fitzner,Francesco Carnazza,Federico Carollo,Igor Lesanovsky*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The characterization of collective behavior and nonequilibrium phase transitions in quantum systems is typically rooted in the analysis of suitable system observables, so-called order parameters. These observables might not be known a priori, but they may in principle be identified through analyzing the quantum state of the system. Experimentally, this can be particularly demanding as estimating quantum states and expectation values of quantum observables requires a large number of projective measurements. However, open quantum systems can be probed in situ by monitoring their output, e.g. via heterodyne-detection or photon-counting experiments, which provide space-time resolved information about their dynamics. Building on this, we present a machine-learning approach to detect nonequilibrium phase transitions from the measurement time-records of continuously-monitored quantum systems. We benchmark our method using the quantum contact process, a model featuring an absorbing-state phase transition, which constitutes a particularly challenging test case for the quantum simulation of nonequilibrium processes.

</details>


### [66] [Superiority of Krylov shadow tomography in estimating quantum Fisher information: From bounds to exactness](https://arxiv.org/abs/2602.17361)
*Yuan-Hao Wang,Da-Jian Zhang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Estimating the quantum Fisher information (QFI) is a crucial yet challenging task with widespread applications across quantum science and technologies. The recently proposed Krylov shadow tomography (KST) opens a new avenue for this task by introducing a series of Krylov bounds on the QFI. In this work, we address the practical applicability of the KST, unveiling that the Krylov bounds of low orders already enable efficient and accurate estimation of the QFI. We show that the Krylov bounds converge to the QFI exponentially fast with increasing order and can surpass the state-of-the-art polynomial lower bounds known to date. Moreover, we show that certain low-order Krylov bound can already match the QFI exactly for low-rank states prevalent in practical settings. Such exact match is beyond the reach of polynomial lower bounds proposed previously. These theoretical findings, solidified by extensive numerical simulations, demonstrate practical advantages over existing polynomial approaches, holding promise for fully unlocking the effectiveness of QFI-based applications.

</details>


### [67] [Experimental certification of ensembles of high-dimensional quantum states with independent quantum devices](https://arxiv.org/abs/2602.17409)
*Yong-Nan Sun,Meng-Yun Ma,Qi-Ping Su,Zhe Sun,Chui-Ping Yang,Franco Nori*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: When increasing the dimensionality of quantum systems, high-dimensional quantum state certification becomes important in quantum information science and technology. However, how to certify ensembles of high-dimensional quantum states in a black-box scenario remains a challenging task. In this work, we report an experimental test of certifying ensembles of high-dimensional quantum states based on prepare-and-measure experiments with \textit{independent devices}, where the state preparation device and the measurement device have no shared randomness. In our experiment, the prepared quantum states are high-dimensional orbital angular momentum states of single photons, and both the preparation fidelity and the measurement fidelity are about 99.0$\%$ for the six-dimensional quantum states. We also measure the crosstalk matrices and calculate the similarity parameter for up to ten dimensions. We not only experimentally certify the ensemble of high-dimensional quantum states in a semi-device-independent manner, but also experimentally investigate the effect of atmospheric turbulent noise on high-dimensional quantum state certification. Our experimental results clearly show that the certification of high-dimensional quantum states can still be achieved even under the influence of atmospheric turbulent noise. Our findings have potential implications in quantum certification and quantum random number generation.

</details>


### [68] [Organic molecules as single-photon sources](https://arxiv.org/abs/2602.17428)
*Alexey Shkarin,Stephan Götzinger*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The development of single-photon sources has been nothing but rapid in recent years, with quantum emitter-based systems showing especially impressive progress. In this article, we give an overview of the developments in single-photon sources based on single molecules. We will introduce polycyclic hydrocarbons as the most commonly used emitter systems for the realization of an organic solid-state single-photon source. At cryogenic temperatures this special class of fluorescent molecules demonstrates remarkable optical properties such as negligible dephasing, indefinite photostability, and high photon rates, which make them attractive as fundamental building blocks in emerging quantum technologies. To better understand the general properties and limitations of these molecules, we discuss sample preparation, light collection strategies and relevant emitter parameters such as absorption and emission spectra, lifetime, and dephasing. We will also give an overview of light extraction strategies as a crucial part of a single-photon source. Finally, we conclude with a look into the future, displaying current challenges and possible solutions.

</details>


### [69] [Tight any-shot quantum decoupling](https://arxiv.org/abs/2602.17430)
*Mario Berta,Hao-Chung Cheng,Yongsheng Yao*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum information decoupling is a fundamental primitive in quantum information theory, underlying various applications in quantum physics. We prove a novel one-shot decoupling theorem formulated in terms of quantum relative entropy distance, with the decoupling error bounded by two sandwiched Rényi conditional entropies. In the asymptotic i.i.d. setting of standard information decoupling via partial trace, we show that this bound is ensemble-tight in quantum relative entropy distance and thereby yields a characterization of the associated decoupling error exponent in the low-cost-rate regime.
  Leveraging this framework, we derive several operational applications formulated in terms of purified distance: (i) a single-letter expression for the exact error exponent of quantum state merging in terms of Petz-Rényi conditional entropies, and (ii) regularized expressions for the achievable error exponent of entanglement distillation and quantum channel coding in terms of Petz-Rényi coherent informations. We further prove that these achievable bounds are tight for maximally correlated states and generalized dephasing channels, respectively, for the high distillation-rate/coding-rate regimes.

</details>


### [70] [Fault-tolerant preparation of arbitrary logical states in the cat code](https://arxiv.org/abs/2602.17438)
*Zi-Jie Chen,Weizhou Cai,Liang-Xu Xie,Qing-Xuan Jie,Xu-Bo Zou,Guang-Can Guo,Luyan Sun,Chang-Ling Zou*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Preparing high-fidelity logical states is a central challenge in fault-tolerant quantum computing, yet existing approaches struggle to balance control complexity against resource overhead. Here, we present a complete framework for the fault-tolerant preparation of arbitrary logical states encoded in the four-legged cat code. This framework is engineered to suppress the dominant incoherent errors, including excitation decay and dephasing in both the bosonic mode and the ancilla via error detection. Numerical simulations with experimentally realistic parameters on a 3D superconducting cavity platform yield logical infidelities on the order of $10^{-4}$. A scaling analysis confirms that the logical error rate grows nearly quadratically with the physical error rate, confirming that all first-order errors are fully suppressed. Our protocol is compatible with current hardware and is scalable to multiple bosonic modes, providing a resource-efficient foundation for magic state preparation and higher-level concatenated quantum error correction.

</details>


### [71] [Global bifurcations and basin geometry of the nonlinear non-Hermitian skin effect](https://arxiv.org/abs/2602.17439)
*Heng Lin,Yunyao Qi,Gui-Lu Long*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study a continuum Hatano--Nelson model with a saturating nonlinear nonreciprocity and analyze its stationary states via the associated phase-space flow. We uncover a global scenario controlled by a subcritical Hopf bifurcation and a saddle-node of limit cycles, which together generate a finite coexistence window. In this window, skin modes and extended states are both stable at a fixed energy $E$, separated by a nonlinear basin separatrix in phase space rather than a spectral (mobility-edge) mechanism in a linear system. An averaged amplitude equation yields closed-form predictions for the limit-cycle branches and the SNLC threshold. Building on the basin geometry, we introduce a basin-fraction order parameter that exhibits a first-order-like jump at SNLC. Intriguing physical phenomena in the coexistence window are also revealed, such as separatrix-induced long-lived spatial transients and hysteresis. Overall, our findings highlight that, beyond linear spectral concepts, global attractor-basin geometry provides a powerful and complementary lens for understanding stationary states in nonlinear non-Hermitian systems.

</details>


### [72] [A Programmable Linear Optical Quantum Reservoir with Measurement Feedback for Time Series Analysis](https://arxiv.org/abs/2602.17440)
*Çağın Ekici*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Feedback-driven quantum reservoir computing has so far been studied primarily in gate-based architectures, motivating alternative scalable, hardware-friendly physical platforms. Here we investigate a linear-optical quantum reservoir architecture for time-series processing based on multiphoton interference in a reconfigurable interferometer network equipped with threshold detectors and measurement-conditioned feedback. The reservoir state is constructed from coarse-grained coincidence features, and the feedback updates only a structured, budgeted subset of programmable phases, enabling recurrence without training internal weights. By sweeping the feedback strength, we identify three dynamical regimes and find that memory performance peaks near the stability boundary. We quantify temporal processing via linear memory capacity and validate nonlinear forecasting on benchmarks, namely Mackey-Glass series, NARMA$-n$ and non-integrable Ising dynamics. The proposed architecture is compatible with current photonic technology and lowers the experimental barrier to feedback-driven QRC for time-series analysis with competitive accuracy.

</details>


### [73] [Single-Photon Motion in a Two-Dimensional Plane: Confinement and Boundary Escape](https://arxiv.org/abs/2602.17461)
*Hui-hui Miao*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates the motion of a single photon in a two-dimensional plane under closed and open boundary conditions. We employ two methods to construct the Hilbert space: Method A, based on the standard second-quantization formalism, and Method B, based on a non-standard approach. By eliminating redundant quantum states, we obtain a reduced Hilbert space with significantly lower dimensionality, thereby improving the efficiency of numerical simulations. In a closed system, the two methods are equivalent, and their unitary evolution results are identical. The probability distribution diffuses outward from the center and exhibits a significant rebound after reaching the boundary. In an open system, Method B, by incorporating more dissipation channels, provides a more accurate description of the photon escape process at the boundary. The probability curves obtained from the two methods completely overlap before reaching the boundary. After the boundary is reached, a slight difference appears, but this difference does not amplify with evolution and tends to converge in the later stage. Method B yields a slightly higher dissipative-state probability, indicating that the photon escapes faster. Visualization of the two-dimensional probability distribution shows that the three scenarios (closed system, open system with Method A, and open system with Method B) exhibit identical probability distributions before reaching the boundary. After the boundary is reached, the open systems exhibit significant probability loss, which increases rapidly with evolution. The probability distribution patterns of the two open systems are highly similar, exhibiting synchronized evolution.

</details>


### [74] [Modelling quantum measurements without superposition](https://arxiv.org/abs/2602.17462)
*Gabriele Cobucci,Alexander Bernal,Roope Uola,Armin Tavakoli*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Superposition is the core feature that sets quantum theory apart from classical physics. Here, we investigate whether sets of quantum measurements can be modelled by using only devices that are operationally classical, in the sense that they have no superposition properties. This leads us to propose classical measurement models, which we show to be stronger than commutative measurements but weaker than joint measurability. We determine both the exact depolarisation noise rate and the measurement loss rate at which the all projective measurements in $d$-dimensional quantum theory admit a classical model. For finite sets of quantum measurements we develop methods both for constructing classical models and for falsifying the existence of such model via prepare-and-measure setups. Furthermore, we show that this concept also has operational implications. For that, we consider whether quantum measurements with classical side-information can be implemented in sequence without causing a disturbance and we show that classical models imply an affirmative answer. Our work sheds light on superposition as a resource for quantum measurement devices.

</details>


### [75] [Pauli Correlation Encoding for Budget-Contraint Optimization](https://arxiv.org/abs/2602.17479)
*Jacobo Padín Martínez,Vicente P. Soloviev,Alejandro Borrallo Rentero,Antón Rodríguez Otero,Raquel Alfonso Rodríguez,Michal Krompiec*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum optimization has gained increasing attention as advances in quantum hardware enable the exploration of problem instances approaching real-world scale. Among existing approaches, variational quantum algorithms and quantum annealing dominate current research; however, both typically rely on one-hot encodings that severely limit scalability. Pauli Correlation Encoding (PCE) was recently introduced as an alternative paradigm that reduces qubit requirements by embedding problem variables into Pauli correlations. Despite its promise, PCE has not yet been studied in the context of constrained optimization. In this work, we extend the PCE framework to constrained combinatorial optimization problems and evaluate its performance across multiple problem sizes. Our results show that the standard PCE formulation struggles to reliably enforce constraints, which motivates the introduction of the Iterative-$α$ PCE. This iterative strategy significantly improves solution quality, achieving consistent constraint satisfaction while yielding better cut sizes across a wide range of instances. These findings highlight both the limitations of current PCE formulations for constrained problems and the effectiveness of iterative strategies for advancing quantum optimization in the NISQ era.

</details>


### [76] [Phase transitions in quasi-Hermitian quantum models at exceptional points of order four](https://arxiv.org/abs/2602.17491)
*Miloslav Znojil*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum phase transition is interpreted as an evolution, at the end of which a parameter-dependent Hamiltonian $H(g)$ loses its observability. In the language of mathematics, such a quantum catastrophe occurs at an exceptional point of order $N$ (EPN). Although the Hamiltonian $H(g)$ itself becomes unphysical in the limit of $g \to g^{EPN}$, it is shown that it can play the role of an unperturbed operator in a perturbation-approximation analysis of the vicinity of the EPN singularity. Such an analysis is elementary at $N\leq 3$ and numerical at $N\geq 5$, so we pick up $N=4$. We demonstrate that the specific EP4 degeneracy becomes accessible via a unitary evolution process realizable inside a parametric domain ${\cal D}_{\rm physical}$, the boundaries of which are determined non-numerically. Possible relevance of such a mathematical result in the context of non-Hermitian photonics is emphasized.

</details>


### [77] [Efficiency of classical simulations of a noisy Grover algorithm](https://arxiv.org/abs/2602.17569)
*Raphaël Menu,Johannes Schachenmayer*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze the modification of entanglement dynamics in the Grover algorithm when the qubits are subjected to single-qubit amplitude-damping or phase-flip noise. We compare quantum trajectories with full density-matrix simulations, analyzing the dynamics of averaged trajectory entanglement (TE) and operator entanglement (OE), in the respective state representation. Although not a genuine entanglement measure, both TE and OE are connected to the efficiency of matrix product state simulations and thus of fundamental interest. As in many quantum algorithms, at the end of the Grover circuit entanglement decreases as the system converges towards the target product state. While we find that this is well captured in the OE dynamics, quantum trajectories rarely follow paths of reducing entanglement. Optimized unraveling schemes can lower TE slightly, however we show that deep in the circuit OE is generally smaller than TE. This implies that matrix product density operator (MPDO) simulations of quantum circuits can in general be more efficient than quantum trajectories. In addition, we investigate the noise-rate scaling of success probabilities for both amplitude-damping and phase-flip noise in Grover's algorithm.

</details>


### [78] [Subluminal and superluminal velocities of free-space photons](https://arxiv.org/abs/2602.17576)
*Konstantin Y. Bliokh*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider rectilinear free-space propagation of electromagnetic wavepackets using electromagnetic field theory, scalar wavepacket propagation, and quantum-mechanical formalism. We demonstrate that spatially localized wavepackets are inherently characterized by a subluminal group velocity and a superluminal phase velocity, whose product equals $c^2$. These velocities are also known as the 'energy' and 'momentum' velocities, introduced by K. Milton and J. Schwinger. We illustrate general conclusions by explicit calculations for Gaussian beams and wavepackets, and also highlight subtleties of the quantum-mechanical description based on the 'photon wavefunction'.

</details>


### [79] [States that grow linearly in time, exceptional points, and zero norm states in the simple harmonic oscillator](https://arxiv.org/abs/2602.17589)
*Philip D. Mannheim*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The simple harmonic oscillator has a well-known normalizable, positive energy, bound state spectrum. We show that degenerate with each such positive energy eigenvalue there is a non-normalizable positive energy eigenstate whose eigenfunction is orthogonal to that of the standard energy eigenfunction. This class of states is not built on the vacuum that $a$ annihilates, but is instead built on the vacuum that $a^{\dagger} a$ annihilates. These non-normalizable but nonetheless stationary energy eigenstates are accompanied by yet another set of non-normalizable states, states whose wave functions however are not stationary but instead grow linearly in time. With these states not being energy eigenstates, the eigenbasis of the Hamiltonian is incomplete; with the full Hilbert space containing states that are not energy eigenstates. Thus each energy eigenvalue of the harmonic oscillator is an exceptional point at which the Hamiltonian becomes of non-diagonalizable, and thus manifestly non-Hermitian, Jordan-block form. Such non-Hermitian structures occur for Hamiltonians that have an antilinear $PT$ symmetry. As is characteristic of such systems, one can construct a probability conserving inner product that despite the linear in time growth is nonetheless time independent, and not only that, it leads to states with zero norm. In addition, as is again characteristic of $PT$ symmetry, these non-normalizable states can be made normalizable by a continuation into a so-called Stokes wedge domain in the complex plane. In this domain one has a completely consistent quantum theory, one that lives alongside the standard normalizable energy eigenspectrum sector. This thus not quite so simple harmonic oscillator provides an explicit realization of our general contention that antilinearity is more basic to quantum theory than Hermiticity.

</details>


### [80] [Quantum Advantage for Sensing Properties of Classical Fields](https://arxiv.org/abs/2602.17591)
*Jordan Cotler,Daine L. Danielson,Ishaan Kannan*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Modern precision experiments often probe unknown classical fields with bosonic sensors in quantum-noise-limited regimes where vacuum fluctuations limit conventional readout. We introduce Quantum Signal Learning (QSL), a sensing framework that extends metrology to a broader property-learning setting, and propose a quantum-enhanced protocol that simultaneously estimates many properties of a classical signal with shot noise suppressed below the vacuum level. Our scheme requires only two-mode squeezing, passive optics, and static homodyne measurements, and enables post-hoc classical estimation of many properties from the same experimental dataset. We prove that our protocol enables a quantum speedup for common classical sensing tasks, including measuring electromagnetic correlations, real-time feedback control of interferometric cavities, and Fourier-domain matched filtering. To establish these separations, we introduce an optimal-transport conditioning method, and show both worst-case exponential separations from all entanglement-free strategies and practical speedups over homodyne and heterodyne baselines. We further show that when squeezing is treated as a resource, a protocol with squeezed light can sense a structured classical background exponentially faster than any coherent classical probe.

</details>


### [81] [Phase-sensitive representation of Majorana stabilizer states](https://arxiv.org/abs/2602.17604)
*Tomislav Begušić,Garnet Kin-Lic Chan*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Stabilizer states hold a special place in quantum information science due to their connection with quantum error correction and quantum circuit simulation. In the context of classical simulations of many-body physics, they are an example of states that can be both highly entangled and efficiently represented and transformed under Clifford operators. Recently, Clifford operators have been discussed in the context of fermionic quantum computation through their extension, the Majorana Clifford group. Here, we document the phase-sensitive form of the corresponding Majorana stabilizer states, as well as the algorithms for computing their amplitudes, their inner products, and update rules for transforming Majorana stabilizer states under Majorana Clifford gates.

</details>


### [82] [Scalable, self-verifying variational quantum eigensolver using adiabatic warm starts](https://arxiv.org/abs/2602.17612)
*Bojan Žunkovič,Marco Ballarin,Lewis Wright,Michael Lubasch*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study an adiabatic variant of the variational quantum eigensolver (VQE) in which VQE is performed iteratively for a sequence of Hamiltonians along an adiabatic path. We derive the conditions under which gradient-based optimization successfully prepares the adiabatic ground states. These conditions show that the barren plateau problem and local optima can be avoided. Additionally, we propose using energy-standard-deviation measurements at runtime to certify eigenstate accuracy and verify convergence to the global optimum.

</details>


### [83] [A Shadow Enhanced Greedy Quantum Eigensolver](https://arxiv.org/abs/2602.17615)
*Jona Erle,Balint Koczor*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: While ground-state preparation is expected to be a primary application of quantum computers, it is also an essential subroutine for many fault-tolerant algorithms. In early fault-tolerant regimes, logical measurements remain costly, motivating adaptive, shot-frugal state-preparation strategies that efficiently utilize each measurement. We introduce the Shadow Enhanced Greedy Quantum Eigensolver (SEGQE) as a greedy, shadow-assisted framework for measurement-efficient ground-state preparation. SEGQE uses classical shadows to evaluate, in parallel and entirely in classical post-processing, the energy reduction induced by large collections of local candidate gates, greedily selecting at each step the gate with the largest estimated energy decrease. We derive rigorous worst-case per-iteration sample-complexity bounds for SEGQE, exhibiting logarithmic dependence on the number of candidate gates. Numerical benchmarks on finite transverse-field Ising models and ensembles of random local Hamiltonians demonstrate convergence in a number of iterations that scales approximately linearly with system size, while maintaining high-fidelity ground-state approximations and competitive energy estimates. Together, our empirical scaling laws and rigorous per-iteration guarantees establish SEGQE as a measurement-efficient state-preparation primitive well suited to early fault-tolerant quantum computing architectures.

</details>


### [84] [Pseudo-deterministic Quantum Algorithms](https://arxiv.org/abs/2602.17647)
*Hugo Aaronson,Tom Gur,Jiawei Li*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We initiate a systematic study of pseudo-deterministic quantum algorithms. These are quantum algorithms that, for any input, output a canonical solution with high probability. Focusing on the query complexity model, our main contributions include the following complexity separations, which require new lower bound techniques specifically tailored to pseudo-determinism:
  - We exhibit a problem, Avoid One Encrypted String (AOES), whose classical randomized query complexity is $O(1)$ but is maximally hard for pseudo-deterministic quantum algorithms ($Ω(N)$ query complexity).
  - We exhibit a problem, Quantum-Locked Estimation (QL-Estimation), for which pseudo-deterministic quantum algorithms admit an exponential speed-up over classical pseudo-deterministic algorithms ($O(\log(N))$ vs. $Θ(\sqrt{N})$), while the randomized query complexity is $O(1)$.
  Complementing these separations, we show that for any total problem $R$, pseudo-deterministic quantum algorithms admit at most a quintic advantage over deterministic algorithms, i.e., $D(R) = \tilde O(psQ(R)^5)$.
  On the algorithmic side, we identify a class of quantum search problems that can be made pseudo-deterministic with small overhead, including Grover search, element distinctness, triangle finding, $k$-sum, and graph collision.

</details>


### [85] [Approaching the Limit in Multiparameter AC Magnetometry with Quantum Control](https://arxiv.org/abs/2602.17648)
*Takuya Isogawa,Zhiyao Hu,Ayumi Kanamoto,Nutdech Phadetsuwannukun,Shilin Wang,Shunsuke Nishimura,Boning Li,Liang Jiang,Zain H. Saleem,Guoqing Wang,Haidong Yuan,Paola Cappellaro*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Simultaneously estimating multiple parameters at the ultimate limit is a central challenge in quantum metrology, often hindered by inherent incompatibilities in optimal estimation strategies. At its most extreme, this incompatibility culminates in a fundamental impossibility when the quantum Fisher information matrix (QFIM) becomes singular, rendering joint estimation unattainable. This is the case for a canonical problem: estimating the amplitude and frequency of an AC magnetic field, where the generators are parallel to each other. Here, we introduce a quantum control protocol that resolves this singularity. Our control protocol strategically engineers the sensor's time evolution so the generators for the two parameters become orthogonal. It not only removes the singularity but also restores the optimal scaling of precision with interrogation time for both parameters simultaneously. We experimentally validate this protocol using a nitrogen-vacancy center in diamond at room temperature, demonstrating the concurrent achievement of the optimal scaling for both parameters under realistic conditions.

</details>


### [86] [Benchmarking quantum phase-space methods for near-resonant light propagation](https://arxiv.org/abs/2602.17660)
*Mojdeh S. Najafabadi,Joel F. Corney,Luis Sanchez Soto,Gerd Leuchs*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the dynamics of light interacting with a near-resonant atomic medium using the truncated Wigner and positive P phase-space representations. The atomic degrees of freedom are described using the Jordan-Schwinger mapping. The dynamics is first analyzed under unitary evolution and subsequently in the presence of an optical reservoir. While both approaches capture the main features of the light-matter dynamics, we find that the truncated Wigner approximation exhibits noticeable deviations for stronger interaction strengths and when reservoir-induced noise becomes significant.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [87] [Spectral boundaries of deterministic matrices deformed by rotationally invariant random non-Hermitian ensembles](https://arxiv.org/abs/2602.16878)
*Pierre Bousseyroux,Marc Potters*

Main category: cond-mat.dis-nn

TL;DR: 本文研究了在大N极限下，形如A+B的随机矩阵的谱边界问题，其中A是确定性矩阵，B是旋转不变的随机矩阵。结果表明，其复特征值分布满足依赖于B的R1和R2变换的简单边界方程。


<details>
  <summary>Details</summary>
Motivation: 探索在大N极限下，复杂矩阵问题如何从难以处理的有限N表达式转化为简单且优雅的渐近解。

Method: 考虑形式为A + B的矩阵，其中A是确定性的N×N矩阵（不一定是厄米特矩阵），B是旋转不变的随机矩阵，并分析其在大N极限下的复特征值分布。

Result: 在大N极限下，A + B的复特征值分布满足仅依赖于B的R1和R2变换的简单边界方程。

Conclusion: 许多复杂的矩阵问题在大N极限下可以简化为非常简洁的渐近解，这展示了随机矩阵理论中的一个奇迹。

Abstract: One of the great miracles of random matrix theory is that, in the $N \to \infty$ limit, many otherwise intractable matrix problems with horrendously complicated finite-$N$ expressions admit remarkably simple and elegant asymptotic solutions. In this paper, we illustrate this phenomenon in the context of spectral boundaries (or spectral edges) for deformed random matrices. Specifically, we consider matrices of the form $\mathbf{A} + \mathbf{B}$, where $\mathbf{A}$ is a deterministic $N\times N$ matrix (not necessarily Hermitian) and $\mathbf{B}$ is a rotationally invariant random matrix. In the large-$N$ limit, we show that the complex eigenvalue distribution of $\mathbf{A} + \mathbf{B}$ satisfies remarkably simple boundary equations that depend on the $\mathcal{R}_1$ and $\mathcal{R}_2$ transforms of $\mathbf{B}$. We illustrate our results on several explicit random matrix ensembles and support them with numerical simulations.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [88] [Quantifying non-Markovianity in magnetization dynamics via entropy production rates](https://arxiv.org/abs/2602.17384)
*Felix Hartmann,Finja Tietjen,R. Matthias Geilhufe,Janet Anders*

Main category: cond-mat.stat-mech

TL;DR: 该论文研究了磁化动力学中惯性和开放系统LLG方程的非马尔可夫性，发现其表现出暂时负熵产生率，并在不同条件下展现出最高的非马尔可夫性程度。


<details>
  <summary>Details</summary>
Motivation: 在皮秒时间尺度下，标准LLG方程不足以解释实验现象，需引入惯性和开放系统修正，进而探究其对熵产生和非马尔可夫性的影响。

Method: 通过解析推导和数值模拟方法，分析标准、惯性及开放系统LLG方程的熵产生率，并采用已有度量方式量化非马尔可夫性。

Result: 标准LLG方程熵产生率为正，而惯性和开放系统LLG方程出现暂时负熵产生率，显示非马尔可夫性；其中开放系统LLG方程的非马尔可夫性最强。

Conclusion: 开放系统的LLG方程在描述超快磁化动力学时必须考虑非马尔可夫效应，这对理解纳米磁性系统的超快动力学具有重要意义。

Abstract: Magnetization dynamics is commonly described by the stochastic Landau-Lifshitz-Gilbert (LLG) equation. On picosecond timescales, inertial and open-system extensions of the LLG equation are necessary to interpret recent experiments. We show analytically and numerically that the standard LLG equation exhibits strictly positive entropy production rates, while inertial and open-system LLG dynamics display temporarily negative entropy production rates indicating non-Markovianity. Here we quantify the degree of non-Markovianity using established measures. Our numerical calculations show that the open-system LLG equation consistently exhibits the highest magnitude of non-Markovianity for different initial conditions and magnetic field orientations.

</details>


### [89] [A covariant fermionic path integral for scalar Langevin processes with multiplicative white noise](https://arxiv.org/abs/2602.17398)
*Daniel G. Barci,Leticia F. Cugliandolo,Zochil González Arenas*

Main category: cond-mat.stat-mech

TL;DR: 本文重新研究了具有乘性白噪声的过阻尼标量朗之万过程的费米子路径积分表示，重点分析生成泛函在非线性变量变换下的协变性，并提出了一种直接在连续时间下构建该表示的方法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在非线性变量变换下路径积分表示的协变性问题，并克服离散化方案带来的复杂性。

Method: 通过分析辅助变量（包括对易和反对易变量）的变换规律，确保生成泛函的协变性，并整合辅助变量以导出Onsager-Machlup形式。

Result: 成功导出了与高阶离散化方案一致的Onsager-Machlup公式，且新方法直接在连续时间中表述，避免了离散化带来的问题。

Conclusion: 所提出的方法为处理乘性噪声系统提供了一个协变且连续时间的路径积分框架，有助于更准确地描述随机动力学。

Abstract: We revisit the construction of the fermionic path-integral representation of overdamped scalar Langevin processes with multiplicative white noise, focusing on the covariance of the generating functional under non-linear changes of variables. We identify the transformations of the auxiliary (commuting and anticommuting) variables that ensure covariance under such transformations. The subtleties induced by the non-differentiable trajectories of the stochastic dynamics are encoded in the fermionic statistics. Upon integrating out the auxiliary variables, we derive the Onsager-Machlup formulation, which agrees with the one recently obtained using a higher-order discretization scheme. In contrast to the latter, the construction proposed here is formulated directly in continuous time.

</details>


### [90] [Matrix-product operator dualities in integrable lattice models](https://arxiv.org/abs/2602.17436)
*Yuan Miao,Andras Molnar,Nick G. Jones*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了矩阵积算子（MPO）在可积格点模型中的作用，特别是其作为对偶性变换时如何改变局部杨-巴克斯特可积结构，并以XXZ自旋链的两种MPO为例进行了说明。


<details>
  <summary>Details</summary>
Motivation: 探讨MPO在可积系统中作为对偶变换时对杨-巴克斯特结构的影响，统一理解可逆与非可逆MPO下的可积性保持机制。

Method: 分析MPO作用下R矩阵的变换行为，证明一类MPO使原YB R矩阵满足修正代数，从而导出对偶模型的局域可积结构。

Result: 发现检查R矩阵在MPO对偶下具有简单变换规律；证明广泛类别的MPO导致修正的Yang-Baxter代数，维持对偶模型的转移矩阵对易性；并通过簇纠缠算子和Kramers-Wannier对偶两个案例加以验证。

Conclusion: MPO对偶保持并修正局域可积结构，为理解对偶模型中的可积性提供了统一框架，且对具有精确MPO逆的算子得出若干独立有意义的结果。

Abstract: Matrix-product operators (MPOs) appear throughout the study of integrable lattice models, notably as the transfer matrices. They can also be used as transformations to construct dualities between such models, both invertible (including unitary) and non-invertible (including discrete gauging). We analyse how the local Yang--Baxter integrable structures are modified under such dualities. We see that the $\check{R}$-matrix, that appears in the baxterization approach to integrability, transforms in a simple manner. We further show for a broad class of MPOs that the usual Yang--Baxter $R$-matrix satisfies a modified algebra, previously identified in the unitary case, that gives a local integrable structure underlying the commuting transfer matrices of the dual model. We illustrate these results with two case studies, analysing an invertible unitary MPO and a non-invertible MPO both applied to the canonical XXZ spin chain. The former is the cluster entangler, arising in the study of symmetry-protected topological phases, while the latter is the Kramers--Wannier duality. We show several results for MPOs with exact MPO inverses that are of independent interest.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [91] [Data-driven sequential analysis of tipping in high-dimensional complex systems](https://arxiv.org/abs/2602.17094)
*Tomomasa Hirose,Yohei Sawada*

Main category: physics.geo-ph

TL;DR: 提出了一种名为DA-HASC的序列诊断框架，用于从部分且含噪声的高维系统观测中检测非线性动力系统中的突变（tipping）现象。


<details>
  <summary>Details</summary>
Motivation: 在高维、非线性动力系统中，突变常伴随吸引子几何结构的变化，但如何从有限、含噪声的观测中有效识别这些变化仍具挑战性。

Method: 结合数据同化（data assimilation）重建高维系统状态，并利用流形学习量化吸引子的结构复杂性；通过滑动时间窗分析局部吸引子结构复杂性的时序变化，使用图拉普拉斯和冯·诺依曼熵度量结构信息。

Result: 在合成和真实数据集上验证了DA-HASC的有效性，证明其能在高维性和系统知识不完整条件下检测到突变，并展示了其对不同突变机制的响应特性。

Conclusion: DA-HASC为从噪声和低维观测中识别高维非线性系统的突变提供了有效工具，具有较强的鲁棒性和适用性。

Abstract: Abrupt transitions ("tipping") in nonlinear dynamical systems are often accompanied by changes in the geometry of the attracting set, but quantifying such changes from partial and noisy observations in high-dimensional systems remains challenging. We address this problem with a sequential diagnostic framework, Data Assimilation-High dimensional Attractor's Structural Complexity (DA-HASC). First, this method reconstructs system's high-dimensional state using data assimilation from limited and noisy observations. Second, we quantify a structural complexity of the high-dimensional system dynamics from the reconstructed state by manifold learning. Third, we capture underlying changes in the system by splitting the reconstructed timeseries into sliding windows and analyzing the changes in the temporally local attractor's structural complexity. The structural information is provided as graph Laplacian and measured by Von Neumann entropy in this framework. We evaluate DA-HASC on both synthetic and real-world datasets and demonstrate that it can detect tipping under high-dimensionality and imperfect system knowledge. We further discuss how this framework behaves across different tipping mechanisms.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [92] [Design of low-energy transfers in cislunar space using sequences of lobe dynamics](https://arxiv.org/abs/2602.17444)
*Naoki Hiraiwa,Mai Bando,Yuzuru Sato,Shinji Hokamoto*

Main category: nlin.CD

TL;DR: 提出了一种基于lobe动力学和图框架的系统性设计低能耗转移轨道的新方法，并在地月系统中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了更高效地设计低能耗转移轨道，利用CR3BP中的动力学结构分析相空间输运问题。

Method: 结合多个lobe动力学构建图模型以探索转移路径，并通过多段打靶法将结果推广到四体问题中。

Result: 成功构造了地球-月球系统中的最优低能耗转移轨迹，并在bicircular四体模型中实现了优化转换。

Conclusion: 所提方法能有效降低燃料消耗，为复杂多体环境下轨道设计提供了新思路。

Abstract: Dynamical structures in the circular restricted three-body problem (CR3BP) are fundamental for designing low-energy transfers, as they aid in analyzing phase space transport and designing desirable trajectories. This study focuses on lobe dynamics to exploit local chaotic transport around celestial bodies, and proposes a new method for systematically designing low-energy transfers by combining multiple lobe dynamics. A graph-based framework is constructed to explore possible transfer paths between departure and arrival orbits, reducing the complexity of the combinatorial optimization problem for designing fuel-efficient transfers. Based on this graph, low-energy transfer trajectories are constructed by connecting chaotic orbits within lobes. The resulting optimal trajectory in the Earth--Moon CR3BP is then converted into an optimal transfer in the bicircular restricted four-body problem using multiple shooting. The obtained transfer is compared with existing optimal solutions to demonstrate the effectiveness of the proposed method.

</details>


### [93] [A Phase Description of Mutually Coupled Chaotic Oscillators](https://arxiv.org/abs/2602.17519)
*Haruma Furukawa,Takashi Imai,Toshio Aoyagi*

Main category: nlin.CD

TL;DR: 本文扩展了混沌振荡器的相位描述方法，通过在庞加莱截面上定义相位并对其动力学进行平均，推导出相位差的闭合方程，验证了数据驱动的耦合函数在缺乏极限环的情况下仍具有明确的动力学意义。


<details>
  <summary>Details</summary>
Motivation: 由于强混沌节律可能被误认为噪声极限环，而传统方法在无极限环情况下仍会给出看似合理的耦合函数，因此需要一种更普适的相位描述方法来处理混沌振荡器。

Method: 通过在庞加莱截面上定义相位，并对返回映射的不变测度进行平均，推导出相位差的闭合方程，并通过数值模拟验证理论结果与时间序列数据推断出的函数一致性。

Result: 推导出的理论函数与从时间序列数据中推断出的函数高度一致，表明相位描述方法可合理应用于混沌振荡器。

Conclusion: 研究证明了相位描述方法可推广至混沌振荡器，且数据驱动的耦合函数即使在无极限环的情况下仍具有清晰的动力学含义。

Abstract: The synchronization of rhythms is ubiquitous in both natural and engineered systems, and the demand for data-driven analysis is growing. When rhythms arise from limit cycles, phase reduction theory shows that their dynamics are universally modeled as coupled phase oscillators under weak coupling. This simple representation enables direct inference of inter-rhythm coupling functions from measured time-series data. However, strongly rhythmic chaos can masquerade as noisy limit cycles. In such cases, standard estimators still return plausible coupling functions even though a phase-oscillator model lacks a priori justification. We therefore extend the phase description to the chaotic oscillators. Specifically, we derive a closed equation for the phase difference by defining the phase on a Poincaré section and averaging the phase dynamics over invariant measures of the induced return maps. Numerically, the derived theoretical functions are in close agreement with those inferred from time-series data. Consequently, our results justify the applicability of phase description to coupled chaotic oscillators and show that data-driven coupling functions retain clear dynamical meaning in the absence of limit cycles.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [94] [Entropy Regularization as Robustness under Bayesian Drift Uncertainty](https://arxiv.org/abs/2602.16862)
*Andy Au*

Main category: math.OC

TL;DR: 研究了在贝叶斯漂移不确定性下的熵正则化均值-方差投资组合优化，发现高斯策略在信息不完全下仍最优，价值函数在财富上呈二次型，且信念相关系数有闭式解。熵正则化仅影响策略方差而不影响信息增益，并提供基于信念的鲁棒性。特别地，当均值位置最激进时，最优策略方差随后验确信度增加而增大，导致更大的动作随机化。


<details>
  <summary>Details</summary>
Motivation: 在不确定市场漂移的情况下，传统均值-方差投资组合优化可能表现不佳。引入熵正则化和贝叶斯方法旨在提升策略的鲁棒性和适应性。

Method: 采用熵正则化框架结合贝叶斯更新处理漂移不确定性，分析高斯策略在部分信息条件下的最优性，并推导价值函数及策略参数的闭式解。

Result: 证明了高斯策略在信息不完全下仍为最优；价值函数为财富的二次函数；策略的均值部分与确定性贝叶斯Markowitz反馈一致，熵正则化仅影响方差部分；策略方差不影响信息增益，但提供信念依赖的鲁棒性；最优方差随后验确信度 |m_t| 增大而增加。

Conclusion: 熵正则化在均值-方差优化中主要调节策略的探索行为，其对方差的影响独立于信息获取，且能根据投资者对均值估计的信心动态调整风险暴露，从而实现更稳健的投资决策。

Abstract: We study entropy-regularized mean-variance portfolio optimization under Bayesian drift uncertainty. Gaussian policies remain optimal under partial information, the value function is quadratic in wealth, and belief-dependent coefficients admit closed-form solutions. The mean control is identical to deterministic Bayesian Markowitz feedback; entropy regularization affects only the policy variance. Additionally, this variance does not affect information gain, and instead provides belief-dependent robustness. Notably, optimal policy variance increases with posterior conviction $|m_t|$, forcing greater action randomization when mean position is most aggressive.

</details>


### [95] [Dynamics of Nesterov's Accelerated Gradient Descent in Quadratic Games](https://arxiv.org/abs/2602.16982)
*Jay Paek*

Main category: math.OC

TL;DR: 研究了Nesterov加速梯度下降（NAGD）在N人二次博弈中寻找纳什均衡的行为，发现其在非对称伪梯度矩阵下的稳定性条件，并揭示动量机制在非势博弈中可能破坏收敛性。


<details>
  <summary>Details</summary>
Motivation: 分析连续时间NAGD动力学在博弈中的行为，特别是在优化中有效但在博弈中尚未被研究的非对称伪梯度情况下的表现。

Method: 通过建立伪梯度矩阵G的谱特征进行稳定性分析，比较复特征值对一阶梯度与NAGD动态的影响。

Result: 证明NAGD稳定的充要条件是G的所有特征值位于非负实数域且G可对角化；具有正实部的复特征值会导致NAGD指数级不稳定。

Conclusion: NAGD中用于加速优化的动量机制在非势博弈中可能导致不稳定，因此需谨慎选择算法。

Abstract: We analyze Nesterov's accelerated gradient descent (NAGD) for Nash equilibrium seeking in $N$-player quadratic games. While the continuous-time NAGD dynamics, specifically the Su-Boyd-Candès ODE, are well understood for convex optimization, their behavior with non-symmetric pseudo-gradient matrices arising in games has not been previously studied. We establish sharp spectral characterizations: stability holds if and only if all eigenvalues of the pseudo-gradient matrix $G$ lie in $\mathbb{R}_{\geq 0}$, with the convergence direction additionally requiring diagonalizability of $G$. Remarkably, complex eigenvalues with positive real parts, which ensure stability for first-order gradient dynamics, induce exponential instability in NAGD. This reveals that the momentum mechanism enabling $O(1/t^2)$ convergence in optimization can be detrimental for equilibrium seeking in non-potential games, providing theoretical guidance for algorithm selection.

</details>


### [96] [Formalization of Two Fixed-Point Algorithms in Hilbert Spaces](https://arxiv.org/abs/2602.17064)
*Yifan Bai,Yantao Li,Jian Yu,Jingwei Liang*

Main category: math.OC

TL;DR: 本文在Lean4定理证明器中形式化了Krasnosel'skiĭ--Mann迭代和Halpern迭代在实希尔伯特空间中的收敛性，构建了非扩张算子、Fejér单调序列等相关理论的基础库，为凸分析和不动点迭代的形式化验证提供了可复用的组件。


<details>
  <summary>Details</summary>
Motivation: 为了支持在交互式定理证明环境中对不动点算法进行机器验证的收敛性分析，需要在类型依赖理论的基础上形式化实希尔伯特空间中的相关数学理论。

Method: 基于Lean4和类型依赖理论，形式化弱收敛、拓扑性质、非扩张算子以及Fejér单调序列等概念，并以此为基础验证Krasnosel'skiĭ--Mann迭代和Halpern迭代的收敛性。

Result: 成功在Lean4中实现了两种不动点迭代算法的收敛性证明，并构建了一套可用于后续研究的可重用形式化组件。

Conclusion: 该工作为实希尔伯特空间中的不动点迭代和凸分析理论提供了可靠且可扩展的形式化基础，有助于推动数学理论的机器验证发展。

Abstract: Iterative algorithms are fundamental tools for approximating fixed-points of nonexpansive operators in real Hilbert spaces. Among them, Krasnosel'skiĭ--Mann iteration and Halpern iteration are two widely used schemes. In this work, we formalize the convergence of these two fixed-point algorithms in the interactive theorem prover Lean4 based on type dependent theory. To this end, weak convergence and topological properties in the infinite-dimensional real Hilbert space are formalized. Definition and properties of nonexpansive operators are also provided. As a useful tool in convex analysis, we then formalize the Fejér monotone sequence. Building on these foundations, we verify the convergence of both the iteration schemes. Our formalization provides reusable components for machine-checked convergence analysis of fixed-point iterations and theories of convex analysis in real Hilbert spaces. Our code is available at https://github.com/TTony2019/fixed-point-iterations-in-lean.

</details>


### [97] [Adjoint-based gradient methods for inverse design in a multiple fragmentation model](https://arxiv.org/abs/2602.17138)
*Arijit Das*

Main category: math.OC

TL;DR: 研究了线性多重破碎方程的逆设计问题，提出了一种基于最优控制和有限体积法的重构初始尺寸分布的方法。


<details>
  <summary>Details</summary>
Motivation: 旨在通过给定的破碎规律和最终时刻的期望尺寸分布，重建未知的初始尺寸分布。

Method: 将逆设计问题建模为受破碎动力学约束的最优控制问题，推导连续伴随方程，并提出基于梯度的迭代重构方法；采用有限体积法（包括加权格式）进行数值求解。

Result: 证明了解的存在性、唯一性和连续依赖性；开发了前向与伴随方程的数值格式，并在具有解析解的线性和非线性破碎率基准问题上验证了方法的准确性与效率。

Conclusion: 所提方法能有效重构初始分布，加权有限体积法提升了质量守恒性和计算精度，适用于多种破碎核函数。

Abstract: We study an inverse design problem for the linear multiple fragmentation equation arising in particle dynamics. Our objective is to reconstruct an unknown initial size distribution that evolves, under a prescribed fragmentation law, into a desired size distribution at a specified final time. We first establish the existence of global mass-conserving solutions for a broad class of fragmentation kernels with unbounded rates, and subsequently prove the continuous dependence and uniqueness of these solutions under additional assumptions on the fragmentation kernels. We then formulate the inverse design problem as an optimal control problem constrained by the fragmentation dynamics and prove the existence of the optimal control problem. Also derive the corresponding continuous adjoint equation and propose a gradient-type iterative reconstruction method. For the numerical implementation, we develop finite volume schemes for both the forward and adjoint equations, including a weighted finite volume scheme designed to enhance mass conservation and accuracy. Two benchmark problems, involving linear and nonlinear fragmentation rates with known analytical solutions, are used to assess the accuracy and efficiency of the proposed approach and to compare the performance of the two discretizations in both forward simulations and inverse reconstructions.

</details>


### [98] [Stackelberg Dynamic Location Planning under Cumulative Demand](https://arxiv.org/abs/2602.17392)
*Warley Almeida Silva,Margarida Carvalho,Sanjay Dominik Jena*

Main category: math.OC

TL;DR: 本文研究了一种结合累积需求和市场竞争的新型竞争性设施选址问题，提出了双层混合整数规划模型，证明了乐观变体的复杂性，并开发了高效的分支切割算法。研究表明，垄断假设会导致平均利润下降一半，而合作相较于竞争可带来6%的额外联合利润。


<details>
  <summary>Details</summary>
Motivation: 现有动态设施选址问题多基于垄断假设，忽视了市场竞争对需求的影响，尤其当未满足的需求会累积到下一期时，该假设会严重影响规划效果。因此需要考虑竞争环境下设施选址与需求之间的动态关系。

Method: 提出两种问题变体的双层混合整数规划模型，证明其中乐观变体属于$Σ^{p}_{2}$-hard，并设计具有紧致值函数割的分支切割算法，显著优于通用双层求解器。

Result: 所提算法性能优越；忽略竞争的垄断假设导致平均利润下降50%；合作相比竞争可提升6%的联合利润；实例特征和双寡头建模选择对选址策略有重要影响。

Conclusion: 在存在市场竞争对手且需求具有累积性的场景中，必须考虑竞争互动以制定稳健的设施选址决策；合作可带来更高整体收益，研究结果为企业提供了关于建模选择和运营策略的重要管理启示。

Abstract: Dynamic facility location problems predominantly suppose a monopoly over the service or product provided. Nonetheless, this premise can be a severe oversimplification in the presence of market competitors, as customers may prefer facilities installed by one of them. The monopolistic assumption can particularly worsen planning performance when demand depends on prior location decisions of the market participants, namely, when unmet demand from one period carries over to the next. Such a demand behaviour creates an intrinsic relationship between customer demand and location decisions of all market participants, and requires the decision-maker to anticipate the competitor's response. This work studies a novel competitive facility location problem that combines cumulative demand and market competition to devise high-quality solutions. We propose bilevel mixed-integer programming formulations for two variants of our problem, prove that the optimistic variant is $Σ^{p}_{2}$-hard, and develop branch-and-cut algorithms with tightened value-function cuts that significantly outperform general-purpose bilevel solvers. Our results quantify the severe cost of planning under a monopolistic assumption (profit drops by half on average) and the gains from cooperation over competition (6% more joint profit), while drawing managerial guidelines on how instance attributes and duopolistic modelling choices shape robust location schedules.

</details>


### [99] [Optimization Problems with Difference of Tangentially Convex Functions under Uncertainty](https://arxiv.org/abs/2602.17405)
*Feryal Mashkoorzadeh,Nooshin Movahedian*

Main category: math.OC

TL;DR: 本文研究了一类具有数据不确定性的非光滑非凸优化问题，提出基于切向次微分的广义约束规范，并建立了DTC函数优化问题的最优性条件。


<details>
  <summary>Details</summary>
Motivation: 针对具有数据不确定性的非光滑非凸优化问题，现有方法在处理DTC结构和切向凸性时存在理论空白，需发展新的次微分计算法则和最优性条件。

Method: 通过建立最大函数的Fréchet和极限次微分与组成函数切向次微分之间的关系，发展了一系列非光滑微积分规则，并利用切向次微分框架下的广义约束规范推导最优性条件。

Result: 获得了关于DTC函数优化问题的有效次微分计算法则和最优性条件，并通过多个示例验证了理论结果的有效性。

Conclusion: 所提出的方法为处理一类具有不确定性的非光滑非凸鲁棒优化问题提供了新的理论工具，拓展了切向凸分析在DTC优化中的应用。

Abstract: This paper investigates a specific class of nonsmooth nonconvex optimization problems in the face of data uncertainty, namely, robust optimization problems, where the given objective function can be expressed as a difference of two tangentially convex (DTC) functions. More precisely, we develop a range of nonsmooth calculus rules to establish relationships between Frechet and limiting subdifferentials for a particular maximum function and the tangential subdifferential of its constituent functions. Subsequently, we derive optimality conditions for problems involving DTC functions, employing generalized constraint qualifications within the framework of the tangential subdifferential concept. Several illustrative examples are presented to demonstrate the obtained results.

</details>


### [100] [Optimal control of stochastic Volterra integral equations with completely monotone kernels and stochastic differential equations on Hilbert spaces with unbounded control and diffusion operators](https://arxiv.org/abs/2602.17578)
*Gabriele Bolli,Filippo de Feo*

Main category: math.OC

TL;DR: 本文研究了一类具有完全单调核的随机Volterra积分方程（SVIEs）的最优控制问题，通过近期的马尔可夫提升方法将其转化为Hilbert空间上的随机微分方程（SDEs）控制问题，并提出Γ-平滑性，建立了HJB方程解的存在唯一性、验证定理及最优反馈控制。


<details>
  <summary>Details</summary>
Motivation: 由于粗糙波动率在数学金融中的应用，具有完全单调核的SVIEs最优控制问题日益重要，但传统动态规划方法面临严重数学困难，尚无系统理论，因此需要发展新的分析框架。

Method: 利用最新的马尔可夫化方法将原问题转化为Hilbert空间上的抽象SDE最优控制问题，研究相应的Ornstein-Uhlenbeck半群在控制方向上的正则性，提出Γ-平滑性概念，并以此建立HJB方程的适定性与最优反馈控制构造。

Result: 证明了该类问题对应的HJB方程存在唯一的温和解，建立了验证定理，构造了最优反馈控制策略，并首次将这些结果应用于具有完全单调核的SVIEs最优控制问题。

Conclusion: 本文为一类无限维抽象SDE及具有完全单调核的SVIEs的最优控制问题提供了完整的动态规划解决方案，是该领域首个取得此类成果的研究。

Abstract: The dynamic programming approach is one of the most powerful ones in optimal control. However, when dealing with optimal control problems of stochastic Volterra integral equations (SVIEs) with completely monotone kernels, deep mathematical difficulties arise and it is still not understood. These very classical problems have applications in most fields and have now become even more popular due to their applications in mathematical finance under rough volatility. In this article, we consider a class of optimal control problems of SVIEs with completely monotone kernels. Via a recent Markovian lift \cite{FGW2024}, the problem can be reformulated as an optimal control problem of stochastic differential equations (SDEs) on suitable Hilbert spaces, which due to the roughness of the kernel, presents a generator of an analytic semigroup and unbounded control and diffusion operators.
  This analysis leads us to study a general class of optimal control problems of abstract SDEs on Hilbert spaces with unbounded control and diffusion operators. This class includes optimal control problems of SVIEs with completely monotone kernels, but it is also motivated by other models. We analyze the regularity of the associated Ornstein-Uhlenbeck transition semigroup. We prove that the semigroup exhibits a new smoothing property in control directions through a general observation operator $Γ$, which we call $Γ$-smoothing. This allows us to establish existence and uniqueness of mild solutions of the Hamilton-Jacobi-Bellman equation, establish a verification theorem, and construct optimal feedback controls. We apply these results to optimal control problems of SVIEs with completely monotone kernels. To the best of our knowledge these are the first results of this kind for this abstract class of infinite dimensional problems and for the optimal control of SVIEs with completely monotone kernels.

</details>


<div id='physics.hist-ph'></div>

# physics.hist-ph [[Back]](#toc)

### [101] [The Causal Second Law](https://arxiv.org/abs/2602.17150)
*Balazs Gyenis*

Main category: physics.hist-ph

TL;DR: 本文提出了一种“因果第二定律”，即在满足特定假设的特殊科学中，因果规律具有相关的熵概念，且从强健原因到其结果的因果熵不会减少，该结论与热力学第二定律类似。


<details>
  <summary>Details</summary>
Motivation: 旨在为特殊科学中的因果规律建立一个类似于物理中熵增原理的普遍性原则，并回应相关哲学质疑，如可逆性反驳和时间箭头问题。

Method: 通过分析特殊科学的基本假设，结合物理学中的熵概念，形式化定义因果熵，并证明因果第二定律；同时探讨其与统计力学、随附性和开放系统观点的关系。

Result: 证明了因果第二定律成立，给出了因果熵增加的充分条件，表明该定律不依赖于形而上学预设，也不蕴含因果时间箭头，且无需诉诸热力学即可支持特殊科学中时间箭头的存在。

Conclusion: 因果第二定律为理解特殊科学中的非对称因果关系提供了新的理论框架，具有哲学与科学上的兼容性与解释力。

Abstract: I argue that if a special science satisfies certain key assumptions that are familiar from physicalist accounts of the special sciences and from physics, then its causal regularities have an associated notion of entropy, and that this causal entropy cannot decrease from a robust cause to its effect. Due to its analogy with the second laws of thermodynamics and statistical physics, I call the latter conclusion the causal second law. In this paper, I clarify the key assumptions, prove the causal second law, give sufficient conditions for causal entropy increase, relate the causal second law to statistical mechanics and thermodynamics, and argue that the reversibility objection does not threaten it. In addition, I claim that the causal second law is compatible with a non-metaphysical understanding of supervenience and the open systems view, argue that it does not imply a causal time arrow, reflect on relaxing the robustness condition, question whether it is necessary to invoke thermodynamics to show that special sciences' time arrows exist, and discuss a transition-relative-frequency-based, special-science-internal characterization of causal regularities.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [102] [First versus full or first versus last: U-statistic change-point tests under fixed and local alternatives](https://arxiv.org/abs/2602.16789)
*Herold Dehling,Daniel Vogel,Martin Wendler*

Main category: stat.ME

TL;DR: 本文比较了CUSUM型变点检验中的两种方法（first-vs-full与first-vs-last），在大样本下两者渐近等价，但在小样本和固定备择假设下表现不同。研究提出了一个简单准则来判断哪种方法更具检验力，并以Gini均差、样本方差和Kendall's tau为例进行了详细分析。


<details>
  <summary>Details</summary>
Motivation: 由于在变点检测中使用U统计量的两种常见方法在小样本和实际应用中可能存在显著差异，本文旨在系统比较这两种方法的性能，明确其适用场景。

Method: 通过渐近理论分析两种U统计量构造的CUSUM型检验在零假设、局部备择和固定备择下的行为，并推导出判断检验力高低的简单判据，结合模拟和实际数据验证结果。

Result: 在大样本下两种方法渐近等价；在小样本和固定备择下存在差异；对于Gini均差检测尺度变化，first-vs-full方法在尺度由小变大时始终具有更高检验力，且该结论不依赖于总体分布或变点位置。

Conclusion: 研究明确了两种U统计量变点检验方法的适用条件，提出了选择更优方法的实用准则，尤其指出在检测尺度增大时应优先使用first-vs-full方法。

Abstract: The use of U-statistics in the change-point context has received considerable attention in the literature. We compare two approaches of constructing CUSUM-type change-point tests, which we call the first-vs-full and first-vs-last approach. Both have been pursued by different authors. The question naturally arises if the two tests substantially differ and, if so, which of them is better in which data situation. In large samples, both tests are similar: they are asymptotically equivalent under the null hypothesis and under sequences of local alternatives. In small samples, there may be quite noticeable differences, which is in line with a different asymptotic behavior under fixed alternatives. We derive a simple criterion for deciding which test is more powerful. We examine the examples Gini's mean difference, the sample variance, and Kendall's tau in detail. Particularly, when testing for changes in scale by Gini's mean difference, we show that the first-vs-full approach has a higher power if and only if the scale changes from a smaller to a larger value -- regardless of the population distribution or the location of the change. The asymptotic derivations are under weak dependence. The results are illustrated by numerical simulations and data examples.

</details>


### [103] [A statistical perspective on transformers for small longitudinal cohort data](https://arxiv.org/abs/2602.16914)
*Kiana Farhadyar,Maren Hackenberg,Kira Ahrens,Charlotte Schenk,Bianca Kollmann,Oliver Tüscher,Klaus Lieb,Michael M. Plichta,Andreas Reif,Raffael Kalisch,Martin Wolkewitz,Moritz Hess,Harald Binder*

Main category: stat.ME

TL;DR: 提出了一种简化的transformer架构，适用于小样本纵向队列数据，通过引入基于核的注意力机制和时间衰减，有效捕捉个体动态中的复杂依赖关系。


<details>
  <summary>Details</summary>
Motivation: 传统transformer在处理小样本纵向数据时因参数过多而受限，本文旨在设计一种适合小数据集但仍能捕捉复杂时间依赖的模型。

Method: 从自回归模型出发，将注意力机制建模为带时间衰减的核函数操作，并通过多头注意力积累不同个体特征的证据，支持排列检验以识别上下文模式。

Result: 模拟研究表明该方法能在个体和时间点较少的情况下恢复上下文依赖；应用于心理韧性研究数据时，成功识别出压力与心理健康间的动态时序模式。

Conclusion: 经过适当调整的transformer不仅可在小数据场景下实现良好预测性能，还能揭示复杂的上下文依赖结构，具有在医学和社会科学等小样本领域应用的潜力。

Abstract: Modeling of longitudinal cohort data typically involves complex temporal dependencies between multiple variables. There, the transformer architecture, which has been highly successful in language and vision applications, allows us to account for the fact that the most recently observed time points in an individual's history may not always be the most important for the immediate future. This is achieved by assigning attention weights to observations of an individual based on a transformation of their values. One reason why these ideas have not yet been fully leveraged for longitudinal cohort data is that typically, large datasets are required. Therefore, we present a simplified transformer architecture that retains the core attention mechanism while reducing the number of parameters to be estimated, to be more suitable for small datasets with few time points. Guided by a statistical perspective on transformers, we use an autoregressive model as a starting point and incorporate attention as a kernel-based operation with temporal decay, where aggregation of multiple transformer heads, i.e. different candidate weighting schemes, is expressed as accumulating evidence on different types of underlying characteristics of individuals. This also enables a permutation-based statistical testing procedure for identifying contextual patterns. In a simulation study, the approach is shown to recover contextual dependencies even with a small number of individuals and time points. In an application to data from a resilience study, we identify temporal patterns in the dynamics of stress and mental health. This indicates that properly adapted transformers can not only achieve competitive predictive performance, but also uncover complex context dependencies in small data settings.

</details>


### [104] [Modeling Multivariate Missingness with Tree Graphs and Conjugate Odds](https://arxiv.org/abs/2602.16992)
*Daniel Suen,Yen-Chi Chen*

Main category: stat.ME

TL;DR: 本文提出了一种在树图假设和共轭优势族下的MNAR建模范式，实现了对缺失数据的优雅建模与简单插补。


<details>
  <summary>Details</summary>
Motivation: 针对不可随机缺失（MNAR）数据中的树图结构，扩展模式图的研究，寻求能保持数据分布族的参数模型。

Method: 引入共轭优势族的概念，在树图假设下建立完整数据分布模型，并为观测数据和缺失数据分别构建共轭模型和简单插补模型，同时研究图选择、敏感性分析和统计推断。

Result: 在共轭优势族和树图假设下，实现了对观测数据的共轭建模和对缺失数据的简单插补，通过模拟和真实数据验证了方法的有效性。

Conclusion: 所提方法在特定MNAR假设下提供了对缺失数据建模的简洁且有效的框架，具有良好的可解释性和应用潜力。

Abstract: In this paper, we analyze a specific class of missing not at random (MNAR) assumptions called tree graphs, extending upon the work of pattern graphs. We build off previous work by introducing the idea of a conjugate odds family in which certain parametric models on the selection odds can preserve the data distribution family across all missing data patterns. Under a conjugate odds family and a tree graph assumption, we are able to model the full data distribution elegantly in the sense that for the observed data, we obtain a model that is conjugate from the complete-data, and for the missing entries, we create a simple imputation model. In addition, we investigate the problem of graph selection, sensitivity analysis, and statistical inference. Using both simulations and real data, we illustrate the applicability of our method.

</details>


### [105] [Reframing Population-Adjusted Indirect Comparisons as a Transportability Problem: An Estimand-Based Perspective and Implications for Health Technology Assessment](https://arxiv.org/abs/2602.17041)
*Conor Chandler,Jack Ishak*

Main category: stat.ME

TL;DR: 本文从估计量的角度探讨了人群调整间接比较（PAICs）在健康技术评估中的可转移性问题，指出即使调整了观察到的人群差异，效应估计的可转移性仍依赖于效应修饰、可折叠性和效应尺度的选择。


<details>
  <summary>Details</summary>
Motivation: 在缺乏头对头随机对照试验的情况下，PAICs被广泛用于综合不同人群的研究证据，但其结果是否能推广到决策相关人群尚不明确。

Method: 通过区分条件与边际治疗效应估计量，结合实例分析效应修饰、可折叠性及效应尺度对可转移性的影响，并探讨PAIC方法识别效应的来源人群及其向其他人群外推所需的假设。

Result: 发现常用非可折叠指标（如风险比、比值比）的边际效应通常具有人群依赖性，而在线性预测尺度上的可折叠和条件效应更易于转移；且多数PAIC方法识别的是对照组人群的效应，外推至其他人群需额外假设。

Conclusion: 在将PAIC得出的治疗效应应用于目标人群时，必须谨慎评估其可转移性是否成立，明确所需假设，避免误将特定人群结果视为普遍适用，以支持HTA中更透明和合理地使用间接证据。

Abstract: Population-adjusted indirect comparisons (PAICs) are widely used to synthesize evidence when randomized controlled trials enroll different patient populations and head-to-head comparisons are unavailable. Although PAICs adjust for observed population differences across trials, adjustment alone does not ensure transportability of estimated effects to decision-relevant populations for health technology assessment (HTA). We examine and formalize transportability in PAICs from an estimand-based perspective. We distinguish conditional and marginal treatment effect estimands and show how transportability depends on effect modification, collapsibility, and alignment between the scale of effect modification and the effect measure. Using illustrative examples, we demonstrate that even when effect modifiers are shared across treatments, marginal effects are generally population-dependent for commonly used non-collapsible measures, including hazard ratios and odds ratios. Conversely, collapsible and conditional effects defined on the linear predictor scale exhibit more favorable transportability properties. We further show that pairwise PAIC approaches typically identify effects defined in the comparator population and that applying these estimates to other populations entails an additional, often implicit, transport step requiring further assumptions. This has direct implications for HTA, where PAIC-derived effects are routinely applied within cost-effectiveness and decision models defined for different target populations. Our results clarify when applying PAIC-derived treatment effects to desired target populations is justified, when doing so requires additional assumptions, and when results should instead be interpreted as population-specific rather than decision-relevant, supporting more transparent and principled use of indirect evidence in HTA and related decision-making contexts.

</details>


### [106] [Generative modeling for the bootstrap](https://arxiv.org/abs/2602.17052)
*Leon Tran,Ting Ye,Peng Ding,Fang Han*

Main category: stat.ME

TL;DR: 本文提出了一种基于生成模型的现代自举推断方法，能够在正则和非正则估计量下提供统计上有效的置信区间，克服了传统自举方法在高维和复杂情形下的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于传统自举方法（如Efron自举）在高维或估计量缺乏根-n一致性时失效，本文旨在提出一种更稳健、适用范围更广的自举推断框架。

Method: 利用生成模型从观测样本中模拟合成数据，构建基于生成模型的自举方法，并通过理论分析证明其在多种估计环境下的一致性和有效性。

Result: 该方法能够提供同时适用于正则与非正则估计量的统计有效置信区间，在存在维度灾难或估计量非标准极限分布的情况下仍保持有效性。

Conclusion: 基于生成模型的自举方法是平滑自举的现代扩展，具有坚实的理论基础，扩展了自举方法在复杂统计问题中的应用范围。

Abstract: Generative modeling builds on and substantially advances the classical idea of simulating synthetic data from observed samples. This paper shows that this principle is not only natural but also theoretically well-founded for bootstrap inference: it yields statistically valid confidence intervals that apply simultaneously to both regular and irregular estimators, including settings in which Efron's bootstrap fails. In this sense, the generative modeling-based bootstrap can be viewed as a modern version of the smoothed bootstrap: it could mitigate the curse of dimensionality and remain effective in challenging regimes where estimators may lack root-$n$ consistency or a Gaussian limit.

</details>


### [107] [General sample size analysis for probabilities of causation: a delta method approach](https://arxiv.org/abs/2602.17070)
*Tianyuan Cheng,Ruirui Mao,Judea Pearl,Ang Li*

Main category: stat.ME

TL;DR: 本文提出了一种基于delta方法的通用样本量计算框架，用于估计因果概率（PoCs）边界估计所需的实验和观察样本量。


<details>
  <summary>Details</summary>
Motivation: 因果概率（如必要性和充分性概率）在决策中具有重要作用，但通常无法精确识别，现有研究缺乏对实现特定误差范围所需样本量的分析。

Method: 采用delta方法构建样本量计算框架，适用于PoCs边界可表示为实验与观察概率线性组合的极小或极大值的情形。

Result: 通过模拟研究表明，所提出的样本量计算方法能够稳定地估计因果概率的边界。

Conclusion: 该框架为结合实验与观察数据估计因果概率提供了有效的样本量设计工具。

Abstract: Probabilities of causation (PoCs), such as the probability of necessity and sufficiency (PNS), are important tools for decision making but are generally not point identifiable. Existing work has derived bounds for these quantities using combinations of experimental and observational data. However, there is very limited research on sample size analysis, namely, how many experimental and observational samples are required to achieve a desired margin of error. In this paper, we propose a general sample size framework based on the delta method. Our approach applies to settings in which the target bounds of PoCs can be expressed as finite minima or maxima of linear combinations of experimental and observational probabilities. Through simulation studies, we demonstrate that the proposed sample size calculations lead to stable estimation of these bounds.

</details>


### [108] [Dynamic likelihood hazard rate estimation](https://arxiv.org/abs/2602.17161)
*Nils Lid Hjort*

Main category: stat.ME

TL;DR: 本文提出了一种半参数方法来估计生存分析中的风险率函数，结合了参数和非参数方法的优点，通过动态局部似然方法在给定的参数类中拟合局部最优成员，从而实现非参数参数平滑。该方法在性能上通常优于纯非参数方法，并且在模型合适时不会明显劣于参数方法。


<details>
  <summary>Details</summary>
Motivation: 现有的风险率估计方法要么过于有偏（参数法），要么过于多变（非参数法），因此需要一种能够结合两者优势的方法以提高估计精度和稳定性。

Method: 采用动态局部似然方法，在给定的参数类中对每个时间点s进行局部拟合，得到依赖于时间的风险率参数估计，实现参数内的非参数平滑。

Result: 研究表明，动态似然估计在多数情况下优于纯非参数方法，且当基础模型适当时，其性能接近参数方法，损失较小。同时讨论了估计的偏差、方差特性及局部平滑参数的选择方法。

Conclusion: 所提出的半参数动态局部似然方法能有效平衡偏差与方差，在实际应用中具有良好的适应性和优越性，是一种改进的风险率估计方法。

Abstract: The best known methods for estimating hazard rate functions in survival analysis models are either purely parametric or purely nonparametric. The parametric ones are sometimes too biased while the nonparametric ones are sometimes too variable. In the present paper a certain semiparametric approach to hazard rate estimation, proposed in Hjort (1991), is developed further, aiming to combine parametric and nonparametric features. It uses a dynamic local likelihood approach to fit the locally most suitable member in a given parametric class of hazard rates, and amounts to a version of nonparametric parameter smoothing within the parametric class. Thus the parametric hazard rate estimate at time $s$ inserts a parameter estimate that also depends on $s$. We study bias and variance properties of the resulting estimator and methods for choosing the local smoothing parameter. It is shown that dynamic likelihood estimation often leads to better performance than the purely nonparametric methods, while also having capacity for not losing much to the parametric methods in cases where the model being smoothed is adequate.

</details>


### [109] [Selection and Collider Restriction Bias Due to Predictor Availability in Prognostic Models](https://arxiv.org/abs/2602.17255)
*Marc Delord*

Main category: stat.ME

TL;DR: 本文探讨了由于预测因子可用性导致的预后模型中可能的选择和碰撞限制偏倚。


<details>
  <summary>Details</summary>
Motivation: 研究预后模型中因预测因子缺失或不可用而引发的选择偏倚和碰撞偏倚问题。

Method: 通过方法学分析，讨论预测因子可用性对模型偏差的影响。

Result: 揭示了在构建预后模型时，预测因子的可得性可能导致选择性和碰撞限制性偏倚。

Conclusion: 在开发和解释预后模型时，必须考虑预测因子的获取机制，以避免潜在的偏倚。

Abstract: This methodological note investigates and discuss possible selection and collider restriction bias due to predictor availability in prognostic models.

</details>


### [110] [Parametric or nonparametric: the FIC approach for stationary time series](https://arxiv.org/abs/2602.17261)
*Gudmund Hermansen,Nils Lid Hjort,Martin Jullum*

Main category: stat.ME

TL;DR: 本文提出了一种新的聚焦信息准则（FIC）版本，用于直接比较参数化和非参数化时间序列模型在估计特定关注参数时的表现，通过比较模型估计量的均方误差来实现，并进一步发展了加权平均形式AFIC以优化模型选择。


<details>
  <summary>Details</summary>
Motivation: 缩小平稳时间序列过程中参数化与非参数化建模之间的差距，受聚焦推断和模型选择技术进展的启发。

Method: 发展了一种新的聚焦信息准则（FIC），通过比较不同模型对预设关注参数（如指定滞后的协方差或相关性、达到阈值的概率等）估计量的均方误差来进行模型评估，并提出了AFIC进行加权平均以选择最优模型。

Result: 得到了针对协方差、相关性或阈值概率等参数的FIC公式，并通过AFIC实现了对一系列相关性估计的最佳模型选择策略。

Conclusion: 新提出的FIC和AFIC方法能够有效比较和选择适用于特定推断目标的时间序列模型，提升了参数与非参数方法间的整合能力。

Abstract: We seek to narrow the gap between parametric and nonparametric modelling of stationary time series processes. The approach is inspired by recent advances in focused inference and model selection techniques. The paper generalises and extends recent work by developing a new version of the focused information criterion (FIC), directly comparing the performance of parametric time series models with a nonparametric alternative. For a pre-specified focused parameter, for which scrutiny is considered valuable, this is achieved by comparing the mean squared error of the model-based estimators of this quantity. In particular, this yields FIC formulae for covariances or correlations at specified lags, for the probability of reaching a threshold, etc. Suitable weighted average versions, the AFIC, also lead to model selection strategies for finding the best model for the purpose of estimating e.g.~a sequence of correlations.

</details>


### [111] [Estimating Zero-inflated Negative Binomial GAMLSS via a Balanced Gradient Boosting Approach with an Application to Antenatal Care Data from Nigeria](https://arxiv.org/abs/2602.17272)
*Alexandra Daub,Elisabeth Bergherr*

Main category: stat.ME

TL;DR: 本文研究了在广义加性位置尺度形状模型（GAMLSS）中使用收缩最优步长的提升算法，以改善变量选择和预测性能，尤其适用于复杂响应变量分布和多种基学习器。通过模拟研究和实际应用表明，该方法能实现更平衡的正则化并提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 提升GAMLSS模型类在处理复杂模型时存在参数更新不平衡和计算时间长的问题，需要改进以更好地分析社会经济因素对尼日利亚产前护理就诊次数分布的影响。

Method: 将带有收缩最优步长的提升方法扩展到超越简单线性模型的基学习器，并应用于更复杂的响应变量分布，通过模拟研究和实际数据分析验证其效果。

Result: 收缩最优步长能够实现更平衡的模型正则化，提升计算效率，尤其在存在惩罚拟合大小的基学习器时表现更优。

Conclusion: 收缩最优步长的引入有效解决了GAMLSS提升算法中的更新不平衡和计算耗时问题，增强了其在复杂建模场景下的适用性和性能。

Abstract: Statistical boosting algorithms are renowned for their intrinsic variable selection and enhanced predictive performance compared to classical statistical methods, making them especially useful for complex models such as generalized additive models for location scale and shape (GAMLSS). Boosting this model class can suffer from imbalanced updates across the distribution parameters as well as long computation times. Shrunk optimal step lengths have been shown to address these issues. To examine the influence of socio-economic factors on the distribution of the number of antenatal care visits in Nigeria, we generalize boosting of GAMLSS with shrunk optimal step lengths to base-learners beyond simple linear models and to a more complex response variable distribution. In an extensive simulation study and in the application we demonstrate that shrunk optimal step lengths yield a more balanced regularization of the overall model and enhance computational efficiency across diverse settings, in particular in the presence of base-learners penalizing the size of the fit.

</details>


### [112] [An extension to reversible jump Markov chain Monte Carlo for change point problems with heterogeneous temporal dynamics](https://arxiv.org/abs/2602.17503)
*Emily Gribbin,Benjamin Davis,Daniel Rolfe,Hannah Mitchell*

Main category: stat.ME

TL;DR: 本文提出了一种扩展的RJMCMC方法（CRJMCMC），用于检测具有异质性时间动态的时间序列中的变点，特别适用于单分子定位显微镜中的光漂白步长分析，能更准确地识别闪烁和暗态等短暂事件。


<details>
  <summary>Details</summary>
Motivation: 在单分子定位显微技术中，荧光分子的异质性光物理行为（如闪烁和可逆暗态）会干扰光漂白步分析，影响对蛋白质寡聚结构的解析，现有方法常需大量过滤或校准且难以准确处理这些短暂状态。

Method: 提出一种基于RJMCMC的复合变点对移动算法（CRJMCMC），用于分析FLImP一维积分强度轨迹，以估计每帧活跃荧光分子数量，能够更好地捕捉短寿命事件。

Result: 在模拟和实验数据上验证表明，CRJMCMC在不同信噪比（低至0.001）和高荧光分子数（高达17个）条件下均表现出更高的准确性与鲁棒性，尤其适用于EGFR寡聚体研究中的低计数情况。

Conclusion: CRJMCMC方法显著提升了光漂白步分析的精度和适用范围，不仅适用于单分子成像，还可推广至脑电图状态分割、工业故障检测和金融波动率分析等其他时间序列变点检测任务。

Abstract: Detecting brief changes in time-series data remains a major challenge in fields where short-lived states carry meaning. In single-molecule localisation microscopy, this problem is particularly acute as fluorescent molecules used to tag protein oligomers display heterogenous photophysical behaviour that can complicate photobleach step analysis; a key step in resolving nanoscale protein organisation. Existing methods often require extensive filtering or prior calibration, and can fail to accurately account for blinking or reversible dark states that may contaminate downstream analysis. In this paper, an extension to RJMCMC is proposed for change point detection with heterogeneous temporal dynamics. This approach is applied to the problem of estimating per-frame active fluorophore counts from one-dimensional integrated intensity traces derived from Fluorescence Localisation Imaging with Photobleaching (FLImP), where compound change point pair moves are introduced to better account for short-lived events known as blinking and dark states. The approach is validated using simulated and experimental data, demonstrating improved accuracy and robustness when compared with current photobleach step analysis methods and with the existing analysis approach for FLImP data. This Compound RJMCMC (CRJMCMC) algorithm performs reliably across a wide range of fluorophore counts and signal-to-noise conditions, with signal-to-noise ratio (SNR) down to 0.001 and counts as high as seventeen fluorophores, while also effectively estimating low counts observed when studying EGFR oligomerisation. Beyond single molecule imaging, this work has applications for a variety of time series change point detection problems with heterogeneous state persistence. For example, electrocorticography brain-state segmentation, fault detection in industrial process monitoring and realised volatility in financial time series.

</details>


### [113] [BMW: Bayesian Model-Assisted Adaptive Phase II Clinical Trial Design for Win Ratio Statistic](https://arxiv.org/abs/2602.17592)
*Di Zhu,Yong Zang*

Main category: stat.ME

TL;DR: 提出了一种基于贝叶斯模型辅助的自适应设计（BMW），用于随机II期临床试验，利用胜率统计量进行疗效评估，并实现灵活的中期监测和早期终止决策，同时控制I类错误和族系错误率。


<details>
  <summary>Details</summary>
Motivation: 现有贝叶斯自适应设计不能直接应用于胜率（WR）统计量，因为WR是基于成对比较的汇总统计量，缺乏明确的数据生成机制。

Method: 提出BMW设计，利用WR检验统计量在中期和最终分析中的联合渐近分布计算后验概率，无需指定潜在结果分布，并结合图形检验方法联合评估有效性和毒性。

Result: 模拟研究表明，BMW设计能有效控制I类错误和FWER，具有与传统方法相当的检验效能，并显著降低期望样本量。

Conclusion: BMW设计为基于胜率的临床试验提供了一种灵活、高效的贝叶斯自适应解决方案，便于实际应用。

Abstract: The win ratio (WR) statistic is increasingly used to evaluate treatment effects based on prioritized composite endpoints, yet existing Bayesian adaptive designs are not directly applicable because the WR is a summary statistic derived from pairwise comparisons and does not correspond to a unique data-generating mechanism. We propose a Bayesian model-assisted adaptive design for randomized phase II clinical trials based on the WR statistic, referred to as the BMW design. The proposed design uses the joint asymptotic distribution of WR test statistics across interim and final analyses to compute posterior probabilities without specifying the underlying outcome distribution. The BMW design allows flexible interim monitoring with early stopping for futility or superiority and is extended to jointly evaluate efficacy and toxicity using a graphical testing procedure that controls the family-wise error rate (FWER). Simulation studies demonstrate that the BMW design maintains valid type I error and FWER control, achieves power comparable to conventional methods, and substantially reduces expected sample size. An R Shiny application is provided to facilitate practical implementation.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [114] [An entropy-stable oscillation-eliminating dgsem for the euler equations on curvilinear meshes](https://arxiv.org/abs/2602.16732)
*Jielin Yang,Guosheng Fu*

Main category: math.NA

TL;DR: 提出了一种在一般曲线网格上满足熵稳定性的高阶数值方法，用于二维可压缩欧拉方程，结合了OEDG方法以有效抑制非物理振荡。


<details>
  <summary>Details</summary>
Motivation: 为了在复杂几何下保持高精度和稳定性，同时有效控制激波附近的非物理振荡，需要发展适用于一般曲线网格的熵稳定高阶方法。

Method: 基于满足求和分部（SBP）性质的节点间断Galerkin谱元法（DGSEM），引入熵稳定数值通量，并结合改进的OEDG方法，通过投影算子扩展到曲线网格。

Result: 方法实现了全局离散熵不等式，保持守恒性和熵稳定性，有效抑制振荡，并在多种复杂算例中验证了其精度与鲁棒性。

Conclusion: 所提方法在 Cartesian 和曲线网格上均表现出良好的准确性、稳定性和对强间断的适应能力，是一种高效且系统可推广的高阶熵稳定格式。

Abstract: We develop an entropy-stable high-order numerical method for the two-dimensional compressible Euler equations on general curvilinear meshes. The proposed approach is based on a nodal discontinuous Galerkin spectral element method (DGSEM) that satisfies the summation-by-parts (SBP) property. At the semidiscrete level, entropy stability is established through the SBP structure and the discrete metric identities associated with curvilinear coordinate mappings. By incorporating entropy-stable numerical fluxes at element interfaces, a global discrete entropy inequality is obtained. To further control nonphysical oscillations near strong discontinuities, the entropy-stable DG formulation is combined with a modified oscillation-eliminating discontinuous Galerkin (OEDG) method, which was originally proposed in [59]. We observe that the zero-order damping coefficient in the original OEDG method naturally serves as an effective shock indicator, which enables localization of the oscillation control mechanism and significantly reduces computational cost. Moreover, while the original OEDG formulation relies on local orthogonal modal bases and is primarily restricted to simplicial meshes, we reformulate the OE procedure using projection operators, allowing for a systematic extension to general curvilinear meshes. The resulting method preserves conservation and entropy stability while effectively suppressing spurious oscillations. A series of challenging numerical experiments is presented to demonstrate the accuracy, robustness, and effectiveness of the proposed entropy-stable OEDG method on both Cartesian and curvilinear meshes.

</details>


### [115] [Fast, High-Accuracy, Randomized Nullspace Computations for Tall Matrices](https://arxiv.org/abs/2602.16797)
*Ethan N. Epperly,Taejun Park,Yuji Nakatsukasa*

Main category: math.NA

TL;DR: 本文提出了一种名为RLOBPCG的高效算法，用于计算大型长矩阵对应最小奇异值的少量奇异三元组。该方法结合了随机预处理技术和LOBPCG特征求解器，通过小规模sketch构建高质量预条件子，并在Gram矩阵上运行LOBPCG以优化奇异向量。在标准子空间嵌入假设和适度奇异值间隙条件下，证明了RLOBPCG对最小奇异向量具有几何收敛性。数值实验表明，该算法在高达百万行的矩阵上接近最优精度，速度比经典LOBPCG和Lanczos方法快达12倍，并在其他迭代方法失效时仍保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 计算大型长矩阵的最小奇异值及其对应奇异向量在许多科学计算和数据科学问题中至关重要，但传统迭代方法如LOBPCG和Lanczos在收敛性和效率方面存在挑战，尤其当矩阵规模巨大或谱间隙较小时。因此，需要一种更高效且鲁棒的方法来解决此类问题。

Method: RLOBPCG方法结合了sketch-and-precondition技术中的随机预条件子与LOBPCG特征求解器：首先利用小规模sketch构造高质量预条件子，然后将LOBPCG应用于Gram矩阵以精炼奇异向量。算法依赖于子空间嵌入性质和适度的前两个最小奇异值之间的间隙假设。

Result: 理论分析证明RLOBPCG在适当条件下对最小奇异向量具有几何收敛速率；数值实验显示其在高达10^6行的矩阵上可达到近最优精度，相比传统LOBPCG和Lanczos方法有最高12倍的加速效果，并在其他迭代方法无法收敛的情况下依然保持稳定收敛。

Conclusion: RLOBPCG是一种高效、鲁棒的算法，适用于大规模矩阵最小奇异三元组的计算，在收敛速度和数值稳定性方面显著优于现有迭代方法，具备广泛的应用前景。

Abstract: In this paper, we develop RLOBPCG, an efficient method for computing a small number of singular triplets corresponding to the smallest singular values of large, tall matrices. The algorithm combines randomized preconditioner from the sketch-and-precondition techniques with the LOBPCG eigensolver: a small sketch is used to construct a high-quality preconditioner, and LOBPCG is run on the Gram matrix to refine the singular vector. Under the standard subspace embedding assumption and a modest singular value gap between the two smallest singular values, we prove that RLOBPCG converges geometrically to the minimum singular vector. In numerical experiments, RLOBPCG achieves near-optimal accuracy on matrices with up to $10^6$ rows, outperforming classical LOBPCG and Lanczos methods by a speedup of up to $12\times$ and maintaining robustness when other iterative methods fail to converge.

</details>


### [116] [Domain Decomposition for Mean Curvature Flow of Surface Polygonal Meshes](https://arxiv.org/abs/2602.16874)
*Lenka Ptackova,Michal Outrata*

Main category: math.NA

TL;DR: 本文研究了使用域分解方法优化表面网格的平均曲率流，通过将初始网格分解为子网格并并行处理，提高了计算效率，并分析了其对形状质量和纹理变形的影响。


<details>
  <summary>Details</summary>
Motivation: 为了提高平均曲率流在处理任意简单多边形面片的表面网格时的计算效率，探索域分解方法的应用潜力。

Method: 测试了传统的有重叠和无重叠域分解方法，提出了优化Schwarz方法的自适应Robin传输条件，并将初始网格分解为两个子网格以并行求解较小的边界值问题。

Result: 实现了更高效的平滑处理，能够从形状质量和纹理变形的角度分析结果，验证了并行处理的可行性与优势。

Conclusion: 域分解方法结合优化的传输条件可以有效提升平均曲率流的计算效率，同时保持良好的形状与纹理特性。

Abstract: We examine the use of domain decomposition for potentially more efficient mean curvature flow of surface meshes, whose faces are arbitrary simple polygons. We first test traditional domain decomposition methods with and without overlap of deconstructed domains. And we present adapted Robin transmission conditions of optimized Schwarz method. We then analyze the resulting smoothing from the point of view of shape quality and texture deformation. By decomposing the initial mesh into two sub-meshes, we solve two smaller boundary value problems instead of one big problem, and we can process these two tasks almost entirely in parallel.

</details>


### [117] [ARCANE: Scalable high-degree cubature formulae for simulating SDEs without Monte Carlo error](https://arxiv.org/abs/2602.17151)
*Peter Koepernik,Thomas Coxon,James Foster*

Main category: math.NA

TL;DR: 提出ARCANE算法，可高效自动构建任意高阶的cubature公式，显著优于传统蒙特卡洛方法。


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡洛方法估计随机微分方程解的性质需要大量样本，而现有cubature公式构造困难且阶数过低（仅D≤7），限制了其应用。

Method: 提出ARCANE算法，通过系统化数值优化方法自动构造高阶cubature公式，匹配布朗运动的signature矩至任意指定阶数D。

Result: ARCANE在数秒内复现了当前最优结果（D=7），并在数小时内达到D=19；在多个SDE和误差指标下，相同路径数下误差比蒙特卡洛低数个数量级。

Conclusion: ARCANE实现了高阶cubature公式的高效构造，显著提升了对SDE解的估计精度，具有广泛的应用潜力。

Abstract: Monte Carlo sampling is the standard approach for estimating properties of solutions to stochastic differential equations (SDEs), but accurate estimates require huge sample sizes. Lyons and Victoir (2004) proposed replacing independently sampled Brownian driving paths with "cubature formulae", deterministic weighted sets of paths that match Brownian "signature moments" up to some degree $D$. They prove that cubature formulae exist for arbitrary $D$, but explicit constructions are difficult and have only reached $D=7$, too small for practical use. We present ARCANE, an algorithm that efficiently and automatically constructs cubature formulae of arbitrary degree. It reproduces the state of the art in seconds and reaches $\boldsymbol{D=19}$ within hours on modest hardware. In simulations across multiple different SDEs and error metrics, our cubature formulae robustly achieve an error orders of magnitude smaller than Monte Carlo with the same number of paths.

</details>


### [118] [Invertibility of the Fourier Diffraction Relation in Raster Scan Diffraction Tomography](https://arxiv.org/abs/2602.17344)
*Peter Elbau,Noemi Naujoks*

Main category: math.NA

TL;DR: 本文研究了在使用聚焦光束而非平面波的衍射层析成像中，如何从测量数据中唯一恢复散射势的傅里叶系数，并指出在二维情况下部分系数无法唯一确定，而在高维情况下通常可以完全恢复。


<details>
  <summary>Details</summary>
Motivation: 由于实际成像系统多采用聚焦光束扫描物体，传统的基于平面波的傅里叶衍射定理不再直接适用，需分析新条件下散射势的可恢复性。

Method: 通过分析聚焦光束照射下的傅里叶衍射关系，研究不同维度下散射势傅里叶系数与测量数据之间的对应关系，判断其唯一可恢复性。

Result: 在高于二维的情况下，散射势的大多数傅里叶系数可被唯一确定；但在二维情况下，仅有部分傅里叶系数可唯一恢复，其余部分存在非唯一性。

Conclusion: 聚焦光束衍射层析中，空间维度对散射势的唯一恢复性有显著影响，二维情形存在固有的信息缺失问题，需借助额外约束或先验进行重建。

Abstract: Diffraction tomography aims to recover an object's scattering potential from measured wave fields. In the classical setting, the object is illuminated by plane waves from many directions, and the Fourier diffraction theorem gives a direct relation between the Fourier transform of the scattering potential of the object and the Fourier transformed measurements.
  In many practical imaging systems, however, focused beams are used instead of plane waves. These beams are then translated across the object to bring different regions of interest into focus. The Fourier diffraction relation adapted to this setting differs in one crucial point from the plane-wave case: while certain Fourier coefficients of the measurements still directly correspond to individual Fourier coefficients of the scattering potential, others are given by linear combinations of two Fourier coefficients of the scattering potential.
  This article investigates which Fourier coefficients of the scattering potential can be uniquely recovered from these relations. We show that in dimensions higher than two, all coefficients appearing in the equations are typically uniquely determined. In two dimensions, however, only part of the Fourier coverage is uniquely recoverable, while on the remaining subset, distinct coefficients can produce identical data.

</details>


### [119] [Analysis of an exponential integrator for stochastic PDEs driven by Riesz noise](https://arxiv.org/abs/2602.17348)
*Charles-Edouard Bréhier,David Cohen,Lluís Quer-Sardanyons,Johan Ulander*

Main category: math.NA

TL;DR: 提出并研究了一种用于由高斯噪声驱动的抛物型随机偏微分方程的显式指数积分器，证明了强误差界，并通过数值实验验证了收敛性结果。


<details>
  <summary>Details</summary>
Motivation: 为了有效求解由具有空间相关性的高斯噪声驱动的抛物型SPDEs，并分析收敛性与Riesz核指数的关系。

Method: 采用显式指数积分方法，结合对Riesz核空间相关结构的分析，在给定系数条件下推导强误差估计。

Result: 得到了强误差界的理论结果，揭示了收敛速率依赖于Riesz核指数的规律，并在1维和2维空间中通过数值实验验证了理论结论。

Conclusion: 该显式指数积分器适用于多维抛物型SPDEs，且其收敛性能明确依赖于噪声的空间相关结构。

Abstract: We present and study an explicit exponential integrator for parabolic SPDEs in any dimension driven by a Gaussian noise which is white in time and with spatial correlation given by a Riesz kernel. Under assumptions on the coefficients of the SPDE, we prove strong error bounds and exhibit how the rate of convergence depends on the exponent in the Riesz kernel. Finally, numerical experiments in spatial dimensions $1$ and $2$ are provided in order to confirm our convergence results.

</details>


### [120] [Raster Scan Diffraction Tomography](https://arxiv.org/abs/2602.17351)
*Peter Elbau,Noemi Naujoks,Otmar Scherzer*

Main category: math.NA

TL;DR: 本文扩展了衍射层析成像理论，通过引入赫格洛茨波模型将聚焦光束纳入理论框架，并推导出新的傅里叶衍射关系，用于分析不同扫描几何对重建结果的影响。


<details>
  <summary>Details</summary>
Motivation: 传统衍射层析成像假设单色平面波照明，无法反映医学超声等实际成像系统中使用聚焦光束扫描的情况，因此需要扩展理论以适应实际应用。

Method: 将入射场建模为赫格洛茨波，推导出新的傅里叶衍射关系，并在此基础上分析不同扫描几何对层析重建的影响。

Result: 建立了适用于聚焦扫描系统的衍射层析新理论框架，获得了描述扫描数据与频域信息之间关系的新傅里叶衍射关系。

Conclusion: 所提出的方法成功将聚焦光束和扫描机制纳入衍射层析理论体系，为基于扫描数据的定量成像提供了理论基础，并可指导实际成像系统的设计。

Abstract: Diffraction tomography is a widely used inverse scattering technique for quantitative imaging of weakly scattering media. In its conventional formulation, diffraction tomography assumes monochromatic plane wave illumination. This assumption, however, represents a simplification that often fails to reflect practical imaging systems such as medical ultrasound, where focused beams are used to scan a region of interest of the human body. Such measurement setups, combining focused illumination with scanning, have not yet been incorporated into the diffraction tomography framework. To bridge this gap, we extend diffraction tomography by modeling incident fields as Herglotz waves, thereby incorporating focused beams into the theory. Within this setting, we derive a new Fourier diffraction relation, which forms the basis for quantitative tomographic reconstruction from scanning data. Using this result, we systematically analyze how different scan geometries influence the reconstruction.

</details>


### [121] [Application and Evaluation of the Common Circles Method](https://arxiv.org/abs/2602.17353)
*Michael Quellmalz,Mia Kvåle Løvmo,Simon Moser,Franziska Strasser,Monika Ritsch-Marte*

Main category: math.NA

TL;DR: 本文探讨了在光学衍射层析成像中应用常见的圆方法来估计亚毫米级生物组织样本的运动，提出了一种结合时间一致性约束的实际实现方法，实验证明该方法在运动检测上比完全优化方法更高效。


<details>
  <summary>Details</summary>
Motivation: 在使用声学力场无接触固定样本时，需要从捕获的图像中估计其运动，因此需要一种有效的方法来确定样本的旋转运动。

Method: 采用常见的圆方法识别傅里叶空间中Ewald球面的交点以确定旋转运动，并引入时间一致性约束以提高重建稳定性。

Result: 在模拟和真实数据上的实验结果表明，常见圆方法在计算效率上优于完全优化方法，能够稳定地进行运动检测。

Conclusion: 常见圆方法是一种在光学衍射层析成像中高效且稳定的样本运动估计方法，特别适用于无接触固定样本的情况。

Abstract: We investigate the application of the common circle method for estimating sample motion in optical diffraction tomography (ODT) of sub-millimeter sized biological tissue. When samples are confined via contact-free acoustical force fields, their motion must be estimated from the captured images. The common circle method identifies intersections of Ewald spheres in Fourier space to determine rotational motion. This paper presents a practical implementation, incorporating temporal consistency constraints to achieve stable reconstructions. Our results on both simulated and real-world data demonstrate that the common circle method provides a computationally efficient alternative to full optimization methods for motion detection.

</details>


### [122] [Functional Analysis and Parallel Domain Decomposition for the TV-Stokes Model](https://arxiv.org/abs/2602.17494)
*Andreas Langer,Marc Runft,Talal Rahman,Xue-Cheng Tai,Bin Wu*

Main category: math.NA

TL;DR: 本文为TV-Stokes图像去噪模型建立了严格的数学分析框架，揭示了原模型的不一致性并提出改进，同时首次提出了可并行化的区域分解算法，适用于大规模图像处理。


<details>
  <summary>Details</summary>
Motivation: TV-Stokes模型在实践中有效，但其数学结构和并行化潜力尚未被深入探索，存在理论不一致性和计算效率瓶颈。

Method: 在适当的无穷维函数空间中建立TV-Stokes两步模型的变分公式，推导其对偶形式，并分析系统的兼容性与数学一致性；基于对偶形式设计重叠型Schwarz区域分解方法，实现并行计算。

Result: 发现了原始TV-Stokes模型中的解析不一致性，并提出了修正模型；证明了无散子空间正交投影在连续和离散设置下的存在性与一致性；实现了首个可并行的TV-Stokes区域分解算法，数值实验验证了其正确性和并行重建能力。

Conclusion: 本文为TV-Stokes模型提供了坚实的理论基础，解决了原有模型的数学缺陷，并通过可并行的区域分解方法显著提升了其在大规模图像处理中的适用性。

Abstract: The TV-Stokes model is a two-step variational method for image denoising that combines the estimation of a divergence-free tangent field with total variation regularization in the first step and then uses that to reconstruct the image in the second step. Although effective in practice, its mathematical structure and potential for parallelization have remained unexplored. In this work, we establish a rigorous functional-analytic foundation for the TV-Stokes model. We formulate both steps in appropriate infinite-dimensional function spaces, derive their dual formulations, and analyze the compatibility and mathematical consistency of the coupled system. In particular, we identify analytical inconsistencies in the original formulation and demonstrate how an alternative model resolves them. We also examine the orthogonal projection onto the divergence-free subspace, proving its existence in a continuous setting and establishing consistency with its discrete counterpart.
  Building on this theoretical framework, we develop the first domain decomposition method for TV-Stokes by applying overlapping Schwarz-type iterations to the duals of both steps. Although the divergence-free constraint gives rise to a global projection operator in the continuous model, we show that it becomes locally computable in the discrete setting. This insight enables a fully parallelizable algorithm suitable for large-scale image processing in memory-constrained environments. Numerical experiments demonstrate the correctness of the domain decomposition approach and its usability in parallel image reconstruction.

</details>


### [123] [High Order semi-implicit Rosenbrock type and Multistep methods for evolutionary partial differential equations with higher order derivatives](https://arxiv.org/abs/2602.17507)
*Boscarino Sebastiano,Giuseppe Izzo*

Main category: math.NA

TL;DR: 本文提出了一种半隐式（SI）策略，结合Rosenbrock型和IMEX线性多步法，用于求解含高阶空间导数的一维时间依赖偏微分方程。该方法无需牛顿迭代，避免了显式方法中的严格时间步长限制，并与有限差分法结合实现空间离散化，数值实验表明方案稳定且达到预期精度阶数。


<details>
  <summary>Details</summary>
Motivation: 为了解决显式方法在求解高阶偏微分方程时面临的时间步长受限于稳定性条件（如Δt = O(Δx^k)）的问题，并简化非线性求解过程，本文旨在发展一种高效、稳定的半隐式数值方法。

Method: 采用半隐式（SI）策略，嵌入Rosenbrock型和IMEX线性多步框架中，结合有限差分法进行空间离散化，构造无需牛顿迭代的线性隐式格式，并设计最高至四阶精度的数值方法。

Result: 所提出的半隐式格式在处理耗散、色散和双调和型方程时表现出良好的稳定性，数值实验验证了其能达到预期的收敛阶（最高四阶），且不受限于显式方法的时间步长约束。

Conclusion: 该半隐式策略为求解含高阶空间导数的1D时间依赖PDE提供了一种灵活、高效且稳定的数值方法，兼具高阶精度与计算简便性，适用于多种物理模型。

Abstract: The aim of this work is to apply a semi-implicit (SI) strategy within a Rosenbrock-type and IMEX linear multistep (LM) framework to a sequence of 1D time-dependent partial differential equations (PDEs) with high order spatial derivatives. This strategy provides great flexibility to treat these equations, and allows the construction of simple lienarly implicit schemes without any Newton iteration. Furthermore, the SI schemes so designed do not require the severe time-step restrictions typically encountered when using explicit methods for stability, i.e., $Δt = \mathcal{O}(Δx^k)$ for the $k$-th order PDEs with $k\ge 2$. For space discrertization, this strategy is combined with finite difference schemes. We provide example of methods up to order $p = 4$, and we illustrate the effectiveness of the schemes with appllications to dissipative, dispersive, and biharmonic-type equations. Numerical experiments show that the proposed schemes are stable and achieve the expected orders of accuracy.

</details>


### [124] [Computing the action of a matrix exponential on an interval via the $\star$-product approach](https://arxiv.org/abs/2602.17516)
*Stefano Pozza,Shazma Zahid*

Main category: math.NA

TL;DR: 提出了一种基于正交多项式展开和⋆-代数表示的新方法，用于高效计算矩阵指数作用于向量在时间区间内的解。


<details>
  <summary>Details</summary>
Motivation: 传统方法在计算矩阵指数作用于向量时效率较低，尤其在需要多时间点求解时缺乏统一高效的框架。

Method: 将解在给定时间区间内展开为双变量分布的正交多项式级数，并利用⋆-代数中的新表示形式导出Stein型矩阵方程，通过直接法或Krylov子空间法求解。

Result: 数值实验表明，该方法在精度和计算效率上优于现有先进方法，尤其适用于全区间时间求解场景。

Conclusion: 所提方法为矩阵指数向量计算提供了一种高效、灵活且可扩展的新框架，具有广泛的应用潜力。

Abstract: We present a new method for computing the action of the matrix exponential on a vector, $e^{At}v$. The proposed approach efficiently evaluates the solution for all $t$ within a prescribed bounded interval by expanding it into an orthogonal polynomial series. This method is derived from a new representation of the matrix exponential in the so-called $\star$-algebra, an algebra of bivariate distributions. The resulting formulation leads to a linear system equivalent to a matrix equation of Stein type, which can be solved by either direct or Krylov subspace methods. Numerical experiments demonstrate the accuracy and efficiency of the proposed approach in comparison with state-of-the-art techniques.

</details>
