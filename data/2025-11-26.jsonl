{"id": "2511.19449", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19449", "abs": "https://arxiv.org/abs/2511.19449", "authors": ["Adeline Guéret"], "title": "Power sector models featuring individual BEV profiles: Assessing the time-accuracy trade-off", "comment": null, "summary": "Electrifying passenger cars will impact future power systems. To understand the challenges and opportunities that arise, it is necessary to reflect \"sector coupling\" in the modeling space. This paper focuses on a specific modeling approach that includes dozens of individual BEV profiles rather than one aggregated BEV profile. Although including additional BEV profiles increases model complexity and runtime, it avoids losing information in the aggregation process. We investigate how many profiles are needed to ensure the accuracy of the results and the extent to which fewer profiles can be traded for runtime efficiency gains. We also examine whether selecting specific profiles influences optimal results. We demonstrate that including too few profiles may result in distorted optimal solutions. However, beyond a certain threshold, adding more profiles does not significantly enhance the robustness of the results. More generally, for fleets of 5 to 20 million BEVs, we derive a rule of thumb consisting in including enough profiles such that each profile represents 200,000 to 250,000 vehicles, ensuring accurate results without excessive runtime."}
{"id": "2511.19451", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19451", "abs": "https://arxiv.org/abs/2511.19451", "authors": ["Apurva Patil", "Alfredo Duarte", "Fabrizio Bisetti", "Takashi Tanaka"], "title": "Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control", "comment": "arXiv admin note: substantial text overlap with arXiv:2504.17154", "summary": "The paper addresses a continuous-time continuous-space chance-constrained stochastic optimal control (SOC) problem where the probability of failure to satisfy given state constraints is explicitly bounded. We leverage the notion of exit time from continuous-time stochastic calculus to formulate a chance-constrained SOC problem. Without any conservative approximation, the chance constraint is transformed into an expectation of an indicator function which can be incorporated into the cost function by considering a dual formulation. We then express the dual function in terms of the solution to a Hamilton-Jacobi-Bellman partial differential equation parameterized by the dual variable. Under a certain assumption on the system dynamics and cost function, it is shown that a strong duality holds between the primal chance-constrained problem and its dual. The Path integral approach is utilized to numerically solve the dual problem via gradient ascent using open-loop samples of system trajectories. We present simulation studies on chance-constrained motion planning for spatial navigation of mobile robots and the solution of the path integral approach is compared with that of the finite difference method."}
{"id": "2511.19452", "categories": ["eess.SY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.19452", "abs": "https://arxiv.org/abs/2511.19452", "authors": ["Yi Zhang", "Yushen Long", "Liping Huang", "Yicheng Zhang", "Sheng Zhang", "Yifang Yin"], "title": "A Data-Driven Model Predictive Control Framework for Multi-Aircraft TMA Routing Under Travel Time Uncertainty", "comment": "This is the complete 8-page version of accepted workshop paper for Artificial Intelligence for Air Transportation (AI4AT) @ AAAI 2026", "summary": "This paper presents a closed-loop framework for conflict-free routing and scheduling of multi-aircraft in Terminal Manoeuvring Areas (TMA), aimed at reducing congestion and enhancing landing efficiency. Leveraging data-driven arrival inputs (either historical or predicted), we formulate a mixed-integer optimization model for real-time control, incorporating an extended TMA network spanning a 50-nautical-mile radius around Changi Airport. The model enforces safety separation, speed adjustments, and holding time constraints while maximizing runway throughput. A rolling-horizon Model Predictive Control (MPC) strategy enables closed-loop integration with a traffic simulator, dynamically updating commands based on real-time system states and predictions. Computational efficiency is validated across diverse traffic scenarios, demonstrating a 7-fold reduction in computation time during peak congestion compared to onetime optimization, using Singapore ADS-B dataset. Monte Carlo simulations under travel time disturbances further confirm the framework's robustness. Results highlight the approach's operational resilience and computational scalability, offering actionable decision support for Air Traffic Controller Officers (ATCOs) through real-time optimization and adaptive replanning."}
{"id": "2511.19454", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19454", "abs": "https://arxiv.org/abs/2511.19454", "authors": ["Xiubin Chen"], "title": "A K-means Inspired Solution Framework for Large-Scale Multi-Traveling Salesman Problems", "comment": null, "summary": "The Multi-Traveling Salesman Problem (MTSP) is a commonly used mathematical model for multi-agent task allocation. However, as the number of agents and task targets increases, existing optimization-based methods often incur prohibitive computational costs, posing significant challenges to large-scale coordination in unmanned systems. To address this issue, this paper proposes a K-means-inspired task allocation framework that reformulates the MTSP as a spatially constrained classification process. By leveraging spatial coherence, the proposed method enables fast estimation of path costs and efficient task grouping, thereby fundamentally reducing overall computational complexity. Extensive simulation results demonstrate that the framework can maintain high solution quality even in extremely large-scale scenarios-for instance, in tasks involving 1000 agents and 5000 targets. The findings indicate that this \"cluster-then-route\" decomposition strategy offers an efficient and reliable solution for large-scale multi-agent task allocation."}
{"id": "2511.19717", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19717", "abs": "https://arxiv.org/abs/2511.19717", "authors": ["Vikram Ramavarapu", "João Alfredo Cardoso Lamy", "Mohammad Dindoost", "David A. Bader"], "title": "Large Scale Community-Aware Network Generation", "comment": "22 pages, 10 figures, code made available at https://github.com/illinois-or-research-analytics/reccs", "summary": "Community detection, or network clustering, is used to identify latent community structure in networks. Due to the scarcity of labeled ground truth in real-world networks, evaluating these algorithms poses significant challenges. To address this, researchers use synthetic network generators that produce networks with ground-truth community labels. RECCS is one such algorithm that takes a network and its clustering as input and generates a synthetic network through a modular pipeline. Each generated ground truth cluster preserves key characteristics of the corresponding input cluster, including connectivity, minimum degree, and degree sequence distribution. The output consists of a synthetically generated network, and disjoint ground truth cluster labels for all nodes. In this paper, we present two enhanced versions: RECCS+ and RECCS++. RECCS+ maintains algorithmic fidelity to the original RECCS while introducing parallelization through an orchestrator that coordinates algorithmic components across multiple processes and employs multithreading. RECCS++ builds upon this foundation with additional algorithmic optimizations to achieve further speedup. Our experimental results demonstrate that RECCS+ and RECCS++ achieve speedups of up to 49x and 139x respectively on our benchmark datasets, with RECCS++'s additional performance gains involving a modest accuracy tradeoff. With this newfound performance, RECCS++ can now scale to networks with over 100 million nodes and nearly 2 billion edges."}
{"id": "2511.19789", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2511.19789", "abs": "https://arxiv.org/abs/2511.19789", "authors": ["Ilya Kudrov", "Vitaly Bornyakov", "Vladimir Goy"], "title": "Studying properties of the SU(2) QCD by lattice field theory methods", "comment": "9 pages, 3 figures", "summary": "We present new results on properties of $SU(2)$ QCD in lattice regularization. Our main goal is to find the transition line confinement - deconfinement in $μ- T$ plane. We compute the Polyakov loop and the string tension to determine this line."}
{"id": "2511.19459", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.19459", "abs": "https://arxiv.org/abs/2511.19459", "authors": ["Sota Takagi", "Miki Saijo", "Takumi Ohashi"], "title": "Constructing a Unified Model of Community Formation in Community-Supported Agriculture: Insights from Consumer and Producer Pathways in Japan", "comment": "47 pages, 3 figures", "summary": "Community Supported Agriculture (CSA) has been recognized globally as a promising framework that embeds agriculture within social relations, yet its diffusion remains limited in contexts such as Japan. Existing studies have largely focused on either consumer or producer participation in isolation, offering fragmented insights and leaving unexplored how their reciprocal processes jointly shape CSA communities. This study addresses this gap by integrating the trajectories of both groups into a comprehensive account of CSA community formation. Drawing on semi-structured interviews with ten CSA producers and ten consumers, we employed the Modified Grounded Theory Approach (M-GTA) to inductively theorize processes of participation and practice. The analysis showed that producers advance CSA through internal adjustments and sense-making to cope with uncertainties, while consumers are guided by life events, practical skills, and prior purchasing experiences toward participation. Synthesizing these insights, we propose a six-phase model of CSA community formation, dispersed interest, awareness, interest formation, motivation, practice, and co-creative continuation, that demonstrates how producers, consumers, and intermediaries interact across stages. The model highlights the pivotal role of key players in sustaining engagement and provides a new perspective for institutionalizing CSA as a durable component of sustainable food systems."}
{"id": "2511.19494", "categories": ["quant-ph", "math.GR"], "pdf": "https://arxiv.org/pdf/2511.19494", "abs": "https://arxiv.org/abs/2511.19494", "authors": ["Ziyuan Dong", "Xiang Fan", "Tengxun Zhong", "Daowen Qiu"], "title": "Probabilistic Bounds on the Number of Elements to Generate Finite Nilpotent Groups and Their Applications", "comment": null, "summary": "This work establishes a new probabilistic bound on the number of elements to generate finite nilpotent groups. Let $\\varphi_k(G)$ denote the probability that $k$ random elements generate a finite nilpotent group $G$. For any $0 < ε< 1$, we prove that $\\varphi_k(G) \\ge 1 - ε$ if $k \\ge \\operatorname{rank}(G) + \\lceil \\log_2(2/ε) \\rceil$ (a bound based on the group rank) or if $k \\ge \\operatorname{len}(G) + \\lceil \\log_2(1/ε) \\rceil$ (a bound based on the group chain length). Moreover, these bounds are shown to be nearly tight. Both bounds sharpen the previously known requirement of $k \\ge \\lceil \\log_2 |G| + \\log_2(1/ε) \\rceil + 2$. Our results provide a foundational tool for analyzing probabilistic algorithms, enabling a better estimation of the iteration count for the finite Abelian hidden subgroup problem (AHSP) standard quantum algorithm and a reduction in the circuit repetitions required by Regev's factoring algorithm."}
{"id": "2511.19540", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.19540", "abs": "https://arxiv.org/abs/2511.19540", "authors": ["Christian Döding", "Patrick Henning"], "title": "The Ginzburg-Landau equations: Vortex states and numerical multiscale approximations", "comment": null, "summary": "In this review article, we provide an overview of recent advances in the numerical approximation of minimizers of the Ginzburg-Landau energy in multiscale spaces. Such minimizers represent the most stable states of type-II superconductors and, for large material parameters $κ$, capture the formation of lattices of quantized vortices. As the vortex cores shrink with increasing $κ$, while their number grows, it is essential to understand how $κ$ should couple to the mesh size in order to correctly resolve the vortex patterns in numerical simulations. We summarize and discuss recent developments based on LOD (Localized Orthogonal Decomposition) multiscale methods and review the corresponding error estimates that explicitly reflect the $κ$-dependence and the observed superconvergence. In addition, we include several minor refinements and extensions of existing results by incorporating techniques from recent contributions to the field. Finally, numerical experiments are presented to illustrate and support the theoretical findings."}
{"id": "2511.19637", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.19637", "abs": "https://arxiv.org/abs/2511.19637", "authors": ["Max Nilsson", "Anton Åkerman", "Pontus Giselsson"], "title": "Extending Douglas-Rachford Splitting for Convex Optimization", "comment": null, "summary": "The Douglas-Rachford splitting method is a classical and widely used algorithm for solving monotone inclusions involving the sum of two maximally monotone operators. It was recently shown to be the unique frugal, no-lifting resolvent-splitting method that is unconditionally convergent in the general two-operator setting. In this work, we show that this uniqueness does not hold in the convex optimization case: when the operators are subdifferentials of proper, closed, convex functions, a strictly larger class of frugal, no-lifting resolvent-splitting methods is unconditionally convergent. We provide a complete characterization of all such methods in the convex optimization setting and prove that this characterization is sharp: unconditional convergence holds exactly on the identified parameter regions. These results immediately yield new families of convergent ADMM-type and Chambolle-Pock-type methods obtained through their Douglas-Rachford reformulations."}
{"id": "2511.19905", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.19905", "abs": "https://arxiv.org/abs/2511.19905", "authors": ["Fangyi Chen", "Shu Ge", "Jian Qian", "Christopher Harshaw"], "title": "Sigmoid-FTRL: Design-Based Adaptive Neyman Allocation for AIPW Estimators", "comment": null, "summary": "We consider the problem of Adaptive Neyman Allocation for the class of AIPW estimators in a design-based setting, where potential outcomes and covariates are deterministic. As each subject arrives, an adaptive procedure must select both a treatment assignment probability and a linear predictor to be used in the AIPW estimator. Our goal is to construct an adaptive procedure that minimizes the Neyman Regret, which is the difference between the variance of the adaptive procedure and an oracle variance which uses the optimal non-adaptive choice of assignment probability and linear predictors. While previous work has drawn insightful connections between Neyman Regret and online convex optimization for the Horvitz--Thompson estimator, one of the central challenges for AIPW estimator is that the underlying optimization is non-convex. In this paper, we propose Sigmoid-FTRL, an adaptive experimental design which addresses the non-convexity via simultaneous minimization of two convex regrets. We prove that under standard regularity conditions, the Neyman Regret of Sigmoid-FTRL converges at a $T^{-1/2} R^2$ rate, where $T$ is the number of subjects in the experiment and $R$ is the maximum norm of covariate vectors. Moreover, we show that no adaptive design can improve upon the $T^{-1/2}$ rate under our regularity conditions. Finally, we establish a central limit theorem and a consistently conservative variance estimator which facilitate the construction of asymptotically valid Wald-type confidence intervals."}
{"id": "2511.19916", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.19916", "abs": "https://arxiv.org/abs/2511.19916", "authors": ["Thonn Homsnit", "Kensuke Kageyama", "Tomohisa Kojima"], "title": "Investigation of PINN Stability and Robustness for the Euler-Bernoulli Beam Problem", "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) encounter significant training difficulties when applied to doubly-clamped beam problems, and the underlying causes are not fully understood. This study investigates the PINN loss landscape to identify the failure mechanisms of two primary formulations: the high-order strong formulation and the energy-based formulation. The results demonstrate that the Strong Formulation suffers from landscape ill-conditioning driven by the boundary conditions (BCs), leading to convergence issues in the doubly-clamped case. Conversely, while the energy-based formulation requires only lower-order derivatives, its loss functional can become indefinite, causing optimization difficulties near saddle points. Based on strain field benchmarks against Finite Element Method (FEM), it is found that the strong formulation, combined with a BC handling method and the L-BFGS optimizer, yields the best performance across three classical boundary condition cases. These findings clarify distinct, formulation-dependent failure modes, offering a diagnostic foundation for developing robust physics-based surrogate models for complex beam systems."}
{"id": "2511.19443", "categories": ["cond-mat.stat-mech", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.19443", "abs": "https://arxiv.org/abs/2511.19443", "authors": ["Rana Imran Mushtaq", "Chunyang Wang", "Shi Zhi", "Zengxuan Zhao", "J M Nyasulu"], "title": "A matrix form solution of the multi-dimensional generalized Langevin equation in the quadratic potential", "comment": null, "summary": "In this research paper, we present an exact matrix form analytical solution of the multi-dimensional generalized Langevin equation with quadratic potentials. Our investigation provides detailed expressions for the two-dimensional probability distribution and extends the understanding of the dynamics governed by harmonic potentials. By utilizing the inverse Laplace transformation, we offer a precise method to solve these equations, corroborated by specific examples. This study contributes to the fundamental understanding of stochastic processes in multi-dimensional systems with harmonic potentials and clarifies the limitations of our approach. While the findings are specific to quadratic potentials, they provide a robust framework for exploring related phenomena within this context."}
{"id": "2511.19677", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.19677", "abs": "https://arxiv.org/abs/2511.19677", "authors": ["Benjamin Stockton", "Michele Santacatterina", "Soutrik Mandal", "Charles M. Cleland", "Erinn M. Hade", "Nicholas Illenberger", "Sharon Meropol", "Andrea B. Troxel", "Eva Petkova", "Chang Yu", "Thaddeus Tarpey"], "title": "Clarifying identification and estimation of treatment effects in the Sequential Parallel Comparison Design", "comment": null, "summary": "Sequential parallel comparison design (SPCD) clinical trials aim to adjust active treatment effect estimates for placebo response to minimize the impact of placebo responders on the estimates. This is potentially accomplished using a two stage design by measuring treatment effects among all participants during the first stage, then classifying some placebo arm participants as placebo non-responders who will be re-randomized in the second stage. In this paper, we use causal inference tools to clarify under what assumptions treatment effects can be identified in SPCD trials and what effects the conventional estimators target at each stage of the SPCD trial. We further illustrate the highly influential impact of placebo response misclassification on the second stage estimate. We conclude that the conventional SPCD estimators do not target meaningful treatment effects."}
{"id": "2511.19791", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.19791", "abs": "https://arxiv.org/abs/2511.19791", "authors": ["Sen Zhang", "Lingjun Xiong", "Yipie Liu", "Brian L. Mark", "Lei Yang", "Zebo Yang", "Weiwen Jiang"], "title": "An End-to-End Distributed Quantum Circuit Simulator", "comment": null, "summary": "Quantum computing has made substantial progress in recent years; however, its scalability remains constrained on a monolithic quantum processing unit (QPU). Distributed quantum computing (DQC) offers a pathway by coordinating multiple QPUs to execute large-scale circuits. Yet, DQC still faces practical barriers, as its realization depends on advances in hardware-level components such as quantum transducers and high-fidelity entanglement-distribution modules. While these technologies continue to improve, mature DQC platforms remain unavailable. In the meantime, researchers need to assess the benefits of DQC and evaluate emerging DQC designs, but the software ecosystem lacks a circuit-level simulator that models heterogeneous backends, noisy connections, and distributed execution. To fill this gap, this paper proposes SimDisQ, the first end-to-end circuit-level DQC simulator, composed of a set of novel DQC-oriented automated simulation toolkits and communication noise models that can interoperate with existing toolkits in mainstream quantum software ecosystems. Leveraging circuit-level simulation capabilities, SimDisQ enables quantitative exploration of architectural design trade-offs, communication fidelity constraints, and new circuit optimization challenges introduced by DQC, providing a foundation for future research in this promising direction. Benchmarking experiments using SimDisQ respond to a couple of open questions in the community; for example, noisy simulation of superconducting and trapped-ion qubits, with a reasonable entanglement- distribution fidelity, reveal that heterogeneous QPUs can indeed yield higher execution fidelity."}
{"id": "2511.19821", "categories": ["physics.comp-ph", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2511.19821", "abs": "https://arxiv.org/abs/2511.19821", "authors": ["Aashish K Gupta", "Christopher Ness", "Sina Haeri"], "title": "Effect of cohesion on the gravity-driven evacuation of metal powder through Triply-Periodic Minimal Surface structures", "comment": null, "summary": "Evacuating the powder trapped inside the complex cavities of Triply Periodic Minimal Surface (TPMS) structures remains a major challenge in metal-powder-based additive manufacturing. The Discrete Element Method offers valuable insights into this evacuation process, enabling the design of effective de-powdering strategies. In this study, we simulate gravity-driven evacuation of trapped powders from inside unit cells of various TPMS structures. We systematically investigate the role of cohesive energy density in shaping the discharge profile. Overall, we conclude that the Schwarz-P and Gyroid topologies enable the most efficient powder evacuation, remaining resilient to cohesion-induced flow hindrance. Furthermore, for the two unit cells, we analyse detailed kinematics and interpret the results in relation to particle overlaps and contact force distributions."}
{"id": "2511.19522", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19522", "abs": "https://arxiv.org/abs/2511.19522", "authors": ["Jinming Gao", "Yijing Wang", "Wentao Zhang", "Rui Zhao", "Yang Shi", "Zhiqiang Zuo"], "title": "Active Secure Neighbor Selection in Multi-Agent Systems with Byzantine Attacks", "comment": null, "summary": "This paper investigates the problem of resilient control for multi-agent systems in the presence of Byzantine adversaries via an active secure neighbor selection framework. A pre-discriminative graph is first constructed to characterize the admissible set of candidate neighbors for each agent. Based on this graph, a dynamic in-neighbor selection strategy is proposed, wherein each agent actively selects a subset of its pre-discriminative neighbors. The number of selected neighbors is adjustable, allowing for a trade-off between communication overhead and robustness, with the minimal case requiring only a single in-neighbor. The proposed strategy facilitates the reconstruction of a directed spanning tree among normal agents following the detection and isolation of Byzantine agents. It achieves resilient consensus without imposing any assumptions on the initial connectivity among normal agents. Moreover, the approach significantly reduces communication burden while maintaining resilience to adversarial behavior. A numerical example is provided to illustrate the effectiveness of the proposed method."}
{"id": "2511.20600", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2511.20600", "abs": "https://arxiv.org/abs/2511.20600", "authors": ["En-Hung Chao"], "title": "Long-distance contributions to kaon decays on the lattice", "comment": "Proceedings for the 17th International Conference on Heavy Quarks and Leptons (HQL2025), 15-19 September, 2025, Peking University, Beijing, China", "summary": "In the past decades, significant improvements have been made on standard-model predictions on kaon decays using lattice quantum chromodynamics. In these proceedings, I review selected works on long-distance contributions to kaon decays and developments on QED corrections to those."}
{"id": "2511.19507", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.19507", "abs": "https://arxiv.org/abs/2511.19507", "authors": ["M. Mavin De Silva", "Callie Clark", "Tadachika Nakayama", "Takahiro Yabe"], "title": "Causal spillover effects of electric vehicle charging station placement on local businesses: a staggered adoption study", "comment": null, "summary": "Understanding the economic impacts of the placement of electric vehicle charging stations (EVCSs) is crucial for planning infrastructure systems that benefit the broader community. Theoretical models have been used to predict human behavior during charging events, however, these models have often neglected the complexity of trip patterns, and have underestimated the real-world impacts of such infrastructure on the local economy. In this paper, we design a quasi-experiment using mobile phone GPS location and EVCS deployment history data to analyze the causal impact of EVCS placement on visitation patterns to businesses. More specifically, we leverage the staggered placement of EVCSs in New York City and California Bay Area to match treated and control businesses that share similar characteristics including the business sector, location, and pre-treatment visitation count. By comparing three alternative matching strategies, we show that staggered adoption avoids selecting controls from non-treated clusters, and yields greater spatial overlap in dense urban areas. We find that EVCS installations significantly increase customer traffic, with effects concentrated in recreational venues in New York City and routine destinations such as groceries, pharmacies, and cafes in California Bay Area. Our results suggest that the economic spillovers of EVCSs vary across urban contexts and highlight the effectiveness of leveraging the staggered nature of adoption timings for evaluating infrastructure impacts in heterogeneous urban environments."}
{"id": "2511.19501", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19501", "abs": "https://arxiv.org/abs/2511.19501", "authors": ["András Czégel", "Dávid Sipos", "Boglárka G. -Tóth"], "title": "A Quantum-Classical Hybrid Branch & Bound Algorithm", "comment": null, "summary": "We propose a complete quantum-classical hybrid branch-and-bound algorithm (QCBB) to solve binary linear programs with equality constraints. That includes bound calculation, convergence metrics and optimality guarantee to the quantum optimization based algorithm, which makes our method directly comparable to classical methods. Key aspects of the proposed algorithm are (i) encapsulation of the quantum optimization method, (ii) utilization of noisy samples for problem reduction, (iii) classical approximation based bound calculation, (iv) branch and bound traits like gap-based stopping criterion and monotonic increase in solution quality, (v) integrated composition of many different solutions that can be improved individually. We show numerical results on set partitioning problem instances and provide many details about the characteristics of the different steps of the algorithm."}
{"id": "2511.19679", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.19679", "abs": "https://arxiv.org/abs/2511.19679", "authors": ["Megala Anandan", "Mária Lukáčová-Medvid'ová"], "title": "Provably fully discrete energy-stable and asymptotic-preserving scheme for barotropic Euler equations", "comment": null, "summary": "We develop structure-preserving finite volume schemes for the barotropic Euler equations in the low Mach number regime. Our primary focus lies in ensuring both the asymptotic-preserving (AP) property and the discrete entropy stability. We construct an implicit-explicit (IMEX) method with suitable acoustic/advection splitting including implicit numerical diffusion that is independent of the Mach number. We prove the positivity of density, the entropy stability, and the asymptotic consistency of the fully discrete numerical method rigorously. Numerical experiments for benchmark problems validate the structure-preserving properties of the proposed method."}
{"id": "2511.19666", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.19666", "abs": "https://arxiv.org/abs/2511.19666", "authors": ["Nikky Avila", "Hank He", "Reza Rastegar", "Jamie Tolan", "Tobias Tiecke", "Brian White"], "title": "Catalyzing System-level Decarbonization: An Analysis of Carbon Matching As An Accounting Framework", "comment": "18 pages, 6 figures", "summary": "Carbon matching aims to improve corporate carbon accounting by tracking emissions rather than energy consumption and production. We present a mathematical derivation of carbon matching using marginal emission rates, where the unit of matching is tons of carbon emitted. We present analysis and open source notebooks showing how marginal emissions can be calculated on simulated electric bus networks. Importantly, we prove mathematically that distinct emissions rates can be assigned to all aspects of the electric grid - including transmission, storage, generation, and consumption - completely allocating electric grid emissions. We show that carbon matching is an accurate carbon accounting framework that can inspire ambitious and impactful action. This research fills a gap by blending carbon accounting expertise and power systems modeling to consider the effectiveness of alternative methodologies for allocating electric system emissions."}
{"id": "2511.19989", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.19989", "abs": "https://arxiv.org/abs/2511.19989", "authors": ["Fengcheng Liu"], "title": "On the Square Root of Wishart Matrices: Exact Distributions and Asymptotic Gaussian Behavior", "comment": "19 pages, 4 figures", "summary": "Random matrix theory has become a cornerstone in modern statistics and data science, providing fundamental tools for understanding high-dimensional covariance structures. Within this framework, the Wishart matrix plays a central role in multivariate analysis and related applications. This paper investigates both the exact and asymptotic distributions of the square root of a standard Wishart matrix. We first derive the exact distribution of the square root matrix. Then, by leveraging the Bartlett decomposition, we establish the joint asymptotic normality of the upper-triangular entries of the square root matrix. The resulting limiting distribution resembles that of a scaled Gaussian Wigner ensemble. Additionally, we quantify the rate of convergence using the 1-Wasserstein distance. To validate our theoretical findings, we conduct extensive Monte Carlo simulations, which demonstrate rapid convergence even with relatively low degrees of freedom. These results offer refined insights into the asymptotic behavior of random matrix functionals."}
{"id": "2511.20187", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.20187", "abs": "https://arxiv.org/abs/2511.20187", "authors": ["Matteo Rosellini", "Filippo Fruzza", "Alessandro Mariotti", "Maria Vittoria Salvetti", "Lorenzo Tamellini"], "title": "A Surrogate-Informed Framework for Sparse Grid Interpolation", "comment": null, "summary": "Approximating complex, high-dimensional, and computationally expensive functions is a central problem in science and engineering. Standard sparse grids offer a powerful solution by mitigating the curse of dimensionality compared to full tensor grids. However, they treat all regions of the domain isotropically, which may not be efficient for functions with localized or anisotropic behavior. This work presents a surrogate-informed framework for constructing sparse grid interpolants, which is guided by an error indicator that serves as a zero-cost estimate for the hierarchical surplus. This indicator is calculated for all candidate points, defined as those in the next-level grid $w+1$ not already present in the base grid $w$. It quantifies the local approximation error by measuring the relative difference between the predictions of two consecutive interpolants of level $w$ and $w-1$. The candidates are then ranked by this metric to select the most impactful points for refinement up to a given budget or following another criterion, as, e.g., a given threshold in the error indicator. The final higher-order model is then constructed using a surrogate-informed approach: the objective function is evaluated only at the selected high-priority points, while for the remaining nodes of the $w+1$ grid, we assign the values predicted by the initial $w$-level surrogate. This strategy significantly reduces the required number of expensive evaluations, yielding a final model that closely approximates the accuracy of a fully-resolved $w+1$ grid at a fraction of the computational cost. The accuracy and efficiency of the proposed surrogate-informed refinement criterion is demonstrated for several analytic function and for a real engineering problem, i.e., the analysis of sensitivity to geometrical parameters of numerically predicted flashback phenomenon in hydrogen-fueled perforated burners."}
{"id": "2511.19915", "categories": ["cond-mat.stat-mech", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2511.19915", "abs": "https://arxiv.org/abs/2511.19915", "authors": ["Justin Bennett"], "title": "A Single--Index Theory of Optimal Branching: Murray Laws, Gilbert Networks, and Young--Herring Junctions", "comment": "53 pages. Conceptual and mathematical development of a single-index (chi) framework unifying Murray laws, Gilbert-type concave network costs, and Young-Herring junction balances. Builds on the EPIC formulation introduced in arXiv:2511.04022", "summary": "Murray-type flux-radius laws, Gilbert-type concave transport costs, and Young-Herring triple-junction angle balances are usually treated as separate theories. This work shows that, within a natural class of quadratic, scale-free ledgers for branched networks, all three are different faces of a single structure controlled by one dimensionless index chi. Each edge carries a flux Q, an effective radius r, and a per-length ledger P(Q,r) encoding transport dissipation and structural burden. Under locality, evenness in Q, linear-response (quadratic) dependence, and an exact homogeneity ansatz in (Q,r), any admissible ledger reduces in the scale-free regime to the two-term form P(Q,r) = a Q^2 r^{-p} + b r^m. Local optimality then implies simultaneously: (i) a flux-radius power law with generalized Murray closures at degree-3 nodes; (ii) a Young-Herring-type vector balance with radius weights r^m and a fixed symmetric Y-junction angle; and (iii) an effective flux-only cost of Gilbert/branched-transport type with exponent beta. The exponents alpha and beta, the symmetric angle, and the split between transport and structural cost are all set by chi = m/(m+p) = beta/2. A rigidity theorem shows conversely that any quadratic ledger that yields power-law optimal radii and power-law flux-only cost on an open scaling cone must belong to this two-term family and obey the same Murray-Gilbert-Young dictionary. Examples for Poiseuille, diffusive, and geophysical trees illustrate how chi can be inferred from geometry and used as a falsifiable order parameter for scale-free branching architectures."}
{"id": "2511.19735", "categories": ["stat.ME", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19735", "abs": "https://arxiv.org/abs/2511.19735", "authors": ["Shu Yang", "Margaret Gamalo", "Haoda Fu"], "title": "Integrating RCTs, RWD, AI/ML and Statistics: Next-Generation Evidence Synthesis", "comment": null, "summary": "Randomized controlled trials (RCTs) have been the cornerstone of clinical evidence; however, their cost, duration, and restrictive eligibility criteria limit power and external validity. Studies using real-world data (RWD), historically considered less reliable for establishing causality, are now recognized to be important for generating real-world evidence (RWE). In parallel, artificial intelligence and machine learning (AI/ML) are being increasingly used throughout the drug development process, providing scalability and flexibility but also presenting challenges in interpretability and rigor that traditional statistics do not face. This Perspective argues that the future of evidence generation will not depend on RCTs versus RWD, or statistics versus AI/ML, but on their principled integration. To this end, a causal roadmap is needed to clarify inferential goals, make assumptions explicit, and ensure transparency about tradeoffs. We highlight key objectives of integrative evidence synthesis, including transporting RCT results to broader populations, embedding AI-assisted analyses within RCTs, designing hybrid controlled trials, and extending short-term RCTs with long-term RWD. We also outline future directions in privacy-preserving analytics, uncertainty quantification, and small-sample methods. By uniting statistical rigor with AI/ML innovation, integrative approaches can produce robust, transparent, and policy-relevant evidence, making them a key component of modern regulatory science."}
{"id": "2511.20237", "categories": ["eess.SY", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20237", "abs": "https://arxiv.org/abs/2511.20237", "authors": ["Zeynab Kaseb", "Matthias Moller", "Lindsay Spoor", "Jerry J. Guo", "Yu Xiang", "Peter Palensky", "Pedro P. Vergara"], "title": "Quantum-Enhanced Reinforcement Learning for Accelerating Newton-Raphson Convergence with Ising Machines: A Case Study for Power Flow Analysis", "comment": "10 pages, 9 figures, 4 tables", "summary": "The Newton-Raphson (NR) method is widely used for solving power flow (PF) equations due to its quadratic convergence. However, its performance deteriorates under poor initialization or extreme operating scenarios, e.g., high levels of renewable energy penetration. Traditional NR initialization strategies often fail to address these challenges, resulting in slow convergence or even divergence. We propose the use of reinforcement learning (RL) to optimize the initialization of NR, and introduce a novel quantum-enhanced RL environment update mechanism to mitigate the significant computational cost of evaluating power system states over a combinatorially large action space at each RL timestep by formulating the voltage adjustment task as a quadratic unconstrained binary optimization problem. Specifically, quantum/digital annealers are integrated into the RL environment update to evaluate state transitions using a problem Hamiltonian designed for PF. Results demonstrate significant improvements in convergence speed, a reduction in NR iteration counts, and enhanced robustness under different operating conditions."}
{"id": "2511.20092", "categories": ["physics.comp-ph", "physics.ao-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.20092", "abs": "https://arxiv.org/abs/2511.20092", "authors": ["Andreas Alexandris-Galanopoulos", "George Papadakis"], "title": "An ALE approach to reduce spurious numerical mixing through variational minimizers: application to internal waves", "comment": null, "summary": "Spurious numerical mixing is a frequent phenomenon in ocean models. In the present paper, we present an efficient and robust methodology that defines the vertical grid motion so that this mixing is reduced. This motion is defined through the solution of an optimization problem that -using the ideas of the calculus of variations- results in an elliptic equation. This framework is generally applicable to any ocean model that uses an ALE vertical coordinate and can be tuned to fit the modeler's specific needs based on the guidelines presented herein. The method is applied to the nonhydrostatic solver presented by the authors in [Alexandris-Galanopoulos et al., 2024] and its applicability in fully nonlinear internal waves is investigated for the demanding test cases of wave breaking and overturning. These numerical benchmarks show the ability of the method to reduce spurious mixing, while attaining the physical relevancy of the results."}
{"id": "2511.19567", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.19567", "abs": "https://arxiv.org/abs/2511.19567", "authors": ["M. V. Milovanović"], "title": "Pair density wave in the fractional quantum Hall effect at even denominator", "comment": null, "summary": "The fractional quantum Hall effect (FQHE) at filling 5/2, which is usually understood as a $p$-wave paired state of underlying quasiparticles - composite fermions, transforms into a nematic phase under pressure \\cite{csathy0, csathy}. A pair density wave (PDW) may be a precursor, underlying state for this behaviour, and such state(s) were proposed that maintain the weak-pairing feature of the uniform paired state \\cite{frad}. Based on considerations in the weak-coupling regime of a microscopic description of the pairing phase (to mimic the phase as it gives way to a nematic phase in the experiments), we argue that the ensuing and relevant PDW state has a strong-pairing character. Furthermore, due to the existence of a single collective mode associated with the order parameter in the uniform paired phase, in the weak-coupling regime, the $p$-wave paired state, in general (for example, in the superconducting state of electrons), may be prone to a PDW instability."}
{"id": "2511.19539", "categories": ["physics.ao-ph", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.19539", "abs": "https://arxiv.org/abs/2511.19539", "authors": ["Can Lei", "Hayat Rajani", "Nuno Gracias", "Rafael Garcia", "Huigang Wang"], "title": "PhysDNet: Physics-Guided Decomposition Network of Side-Scan Sonar Imagery", "comment": "This work was previously submitted in error as arXiv:2509.11255v2", "summary": "Side-scan sonar (SSS) imagery is widely used for seafloor mapping and underwater remote sensing, yet the measured intensity is strongly influenced by seabed reflectivity, terrain elevation, and acoustic path loss. This entanglement makes the imagery highly view-dependent and reduces the robustness of downstream analysis. In this letter, we present PhysDNet, a physics-guided multi-branch network that decouples SSS images into three interpretable fields: seabed reflectivity, terrain elevation, and propagation loss. By embedding the Lambertian reflection model, PhysDNet reconstructs sonar intensity from these components, enabling self-supervised training without ground-truth annotations. Experiments show that the decomposed representations preserve stable geological structures, capture physically consistent illumination and attenuation, and produce reliable shadow maps. These findings demonstrate that physics-guided decomposition provides a stable and interpretable domain for SSS analysis, improving both physical consistency and downstream tasks such as registration and shadow interpretation."}
{"id": "2511.19731", "categories": ["nlin.CD", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2511.19731", "abs": "https://arxiv.org/abs/2511.19731", "authors": ["J. V. M. Silveira", "H. C. Costa", "G. S. Spezzatto", "T. L. Prado", "S. R. Lopes"], "title": "Classifying Complex Dynamical and Stochastic Systems via Physics-Based Recurrence Features", "comment": "17 pages, 7 figures", "summary": "In this study, we employ the recently developed recurrence microstate probabilities as features to improve accuracy of several well-established machine learning (ML) algorithms. These algorithms are applied to classify discrete and continuous dynamical systems, as well as colored noise. We demonstrate that the dynamical characteristics quantified by this method are effectively captured in the recurrence microstate space, a space defined solely by the recurrence properties of the signal. This space change reduces dimensions, which also reduces the necessary time to perform calculations and obtain relevant information about the underlying system. Here, we also demonstrate that a few optimal machine learning (ML) algorithms are particularly effective for classification when combined with recurrence microstates. Furthermore, these new machine learning vectors significantly reduce memory usage and computational complexity, outperforming the direct analysis of raw data."}
{"id": "2511.19860", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19860", "abs": "https://arxiv.org/abs/2511.19860", "authors": ["Ali Tozar"], "title": "Universal Critical Scaling and Phase Diagram of the Non-Hermitian Skin Effect under Disorder", "comment": "8 pages, 4 figures", "summary": "Standard scaling theory dictates that disorder leads to immediate localization in one-dimensional Hermitian systems. We demonstrate that non-Hermitian topology fundamentally alters this paradigm, protecting transport up to a substantial critical disorder strength. By employing a numerically stable log-space transfer matrix approach up to thermodynamic scales (N=1000), we identify a sharp phase transition from the topological skin phase to the Anderson localized phase. Finite-size scaling analysis reveals that this transition belongs to a unique universality class with critical exponents ν\\approx1.50 and β\\approx0.65. Furthermore, we map the global phase diagram, confirming that the critical disorder scales as W_c\\propto\\sqrtγ, consistent with localization suppression by an imaginary vector potential. Our results establish the rigorous limits of non-Hermitian topological protection in imperfect media."}
{"id": "2511.19683", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19683", "abs": "https://arxiv.org/abs/2511.19683", "authors": ["Eugene Lavretsky"], "title": "State Feedback Controllers with Operational Constraints", "comment": "33 pages, 13 figures. These are the original detailed design notes where my recent CBF-related papers came from", "summary": "In this paper, a state feedback control design with min/max operational limiting constraints is developed for multi-input-multi-output linear time invariant systems. Specifically, servo-tracking control problems with input and output constraints are considered. For static servo-controllers, the output design limits are imposed component-wise on the system selected output, which is of the same dimension as the control input. For dynamic servo-controllers, operational constraints are applied to the system inputs and outputs. The proposed control solution also includes an anti-windup protection logic for dynamic servo-controllers with integral action. The developed method is based on the Nagumo Theorem for forward invariance, the Comparison Lemma for inclusion of input/output inequality constraints, and on the min-norm optimal controllers for synthesis. The derived design is similar and directly related to the method of Control Barrier Functions. Simulation trade studies are presented to illustrate benefits of the proposed control methodology for aerial flight critical systems."}
{"id": "2511.19564", "categories": ["physics.soc-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2511.19564", "abs": "https://arxiv.org/abs/2511.19564", "authors": ["Ayona Biswas", "Arindam Mandal", "Aditya Bandopadhyay", "Sourav Mitra", "Sandeep Saha"], "title": "Techno economic feasibility study of solar ORC in India", "comment": null, "summary": "Solar energy has enormous potential because there is a worldwide need to meet energy demands. Depleting non-renewable energy resources, increasing carbon emissions, and other environmental effects concern the scientific community to develop an alternative approach to electricity production. In this article, we present the study of a solar-powered Organic Rankine cycle considering Indian climatic conditions. Initially, we scrutinized seven working fluids and assessed their performance in the ORC at an evaporator pressure range of 9-30 bar and a mass flow rate range of 0.2 kg/s to 4.5 kg/s. For a fixed sink temperature of 298 K, we evaluate the system using four different power ratings of 2, 20, 50, and 100 kW based on four different source temperatures of 423 K, 403 K, 383 K, and 363 K. We estimate the system cost for each working fluid in each scenario separately. Our findings suggest that R 1233zd(E) is the optimum performing working fluid based on cost, cost-effectiveness, and environmental friendliness. We also notice that the estimated system scale cost is very competitive and could be a great alternative to the technologies already on the Indian market."}
{"id": "2511.19551", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19551", "abs": "https://arxiv.org/abs/2511.19551", "authors": ["Mikhail Zubarev"], "title": "SPARTA: $χ^2$-calibrated, risk-controlled exploration-exploitation for variational quantum algorithms", "comment": null, "summary": "Variational quantum algorithms face a fundamental trainability crisis: barren plateaus render optimization exponentially difficult as system size grows. While recent Lie algebraic theory precisely characterizes when and why these plateaus occur, no practical optimization method exists with finite-sample guarantees for navigating them. We present the sequential plateau-adaptive regime-testing algorithm (SPARTA), the first measurement-frugal scheduler that provides explicit, anytime-valid risk control for quantum optimization. Our approach integrates three components with rigorous statistical foundations: (i) a $χ^2$-calibrated sequential test that distinguishes barren plateaus from informative regions using likelihood-ratio supermartingales; (ii) a probabilistic trust-region exploration strategy with one-sided acceptance to prevent false improvements under shot noise; and (iii) a theoretically-optimal exploitation phase that achieves the best attainable convergence rate. We prove geometric bounds on plateau exit times, linear convergence in informative basins, and show how Lie-algebraic variance proxies enhance test power without compromising statistical calibration."}
{"id": "2511.19716", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19716", "abs": "https://arxiv.org/abs/2511.19716", "authors": ["Mitchell Scott", "Tianshi Xu", "Ziyuan Tang", "Alexandra Pichette-Emmons", "Qiang Ye", "Yousef Saad", "Yuanzhe Xi"], "title": "Designing Preconditioners for SGD: Local Conditioning, Noise Floors, and Basin Stability", "comment": "31 pages, 11 Figures", "summary": "Stochastic Gradient Descent (SGD) often slows in the late stage of training due to anisotropic curvature and gradient noise. We analyze preconditioned SGD in the geometry induced by a symmetric positive definite matrix $\\mathbf{M}$, deriving bounds in which both the convergence rate and the stochastic noise floor are governed by $\\mathbf{M}$-dependent quantities: the rate through an effective condition number in the $\\mathbf{M}$-metric, and the floor through the product of that condition number and the preconditioned noise level. For nonconvex objectives, we establish a preconditioner-dependent basin-stability guarantee: when smoothness and basin size are measured in the $\\mathbf{M}$-norm, the probability that the iterates remain in a well-behaved local region admits an explicit lower bound. This perspective is particularly relevant in Scientific Machine Learning (SciML), where achieving small training loss under stochastic updates is closely tied to physical fidelity, numerical stability, and constraint satisfaction. The framework applies to both diagonal/adaptive and curvature-aware preconditioners and yields a simple design principle: choose $\\mathbf{M}$ to improve local conditioning while attenuating noise. Experiments on a quadratic diagnostic and three SciML benchmarks validate the predicted rate-floor behavior."}
{"id": "2511.19675", "categories": ["math.OC", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19675", "abs": "https://arxiv.org/abs/2511.19675", "authors": ["Jiarui Wang", "Mahyar Fazlyab"], "title": "Anytime-Feasible First-Order Optimization via Safe Sequential QCQP", "comment": null, "summary": "This paper presents the Safe Sequential Quadratically Constrained Quadratic Programming (SS-QCQP) algorithm, a first-order method for smooth inequality-constrained nonconvex optimization that guarantees feasibility at every iteration. The method is derived from a continuous-time dynamical system whose vector field is obtained by solving a convex QCQP that enforces monotonic descent of the objective and forward invariance of the feasible set. The resulting continuous-time dynamics achieve an $O(1/t)$ convergence rate to first-order stationary points under standard constraint qualification conditions. We then propose a safeguarded Euler discretization with adaptive step-size selection that preserves this convergence rate while maintaining both descent and feasibility in discrete time. To enhance scalability, we develop an active-set variant (SS-QCQP-AS) that selectively enforces constraints near the boundary, substantially reducing computational cost without compromising theoretical guarantees. Numerical experiments on a multi-agent nonlinear optimal control problem demonstrate that SS-QCQP and SS-QCQP-AS maintain feasibility, exhibit the predicted convergence behavior, and deliver solution quality comparable to second-order solvers such as SQP and IPOPT."}
{"id": "2511.20061", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.20061", "abs": "https://arxiv.org/abs/2511.20061", "authors": ["Sampurna Kundu", "Jayant Jha", "Subir Kumar Bhandari"], "title": "An Efficient Adaptive Sequential Procedure for Simple Hypotheses with Expression for Finite Number of Applications of Less Effective Treatment", "comment": null, "summary": "We propose an adaptive sequential framework for testing two simple hypotheses that analytically ensures finite exposure to the less effective treatment. Our proposed procedure employs a likelihood ratio-driven adaptive allocation rule, dynamically concentrating sampling effort on the superior population while preserving asymptotic efficiency (in terms of average sample number) comparable to the Sequential Probability Ratio Test (SPRT). The foremost contribution of this work is the derivation of an explicit closed-form expression for the expected number of applications to the inferior treatment. This approach achieves a balanced method between statistical precision and ethical responsibility, aligning inferential reliability with patient safety. Extensive simulation studies substantiate the theoretical results, confirming stability in allocation and consistently high probability of correct selection (PCS) across different settings. In addition, we demonstrate how the adaptive procedure markedly reduces inferior allocations compared with the classical SPRT, highlighting its practical advantage in ethically sensitive sequential testing scenarios. The proposed design thus offers an ethically efficient and computationally tractable framework for adaptive sequential decision-making."}
{"id": "2511.20163", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.20163", "abs": "https://arxiv.org/abs/2511.20163", "authors": ["Gesualdo Delfino"], "title": "On the nature of the spin glass transition", "comment": null, "summary": "We recently showed that the two-dimensional Ising spin glass allows for a line of renormalization group fixed points. We observe that this exact result corresponds to enhancement to a one-generator continuous internal symmetry. This finally explains why no finite temperature transition to a spin glass phase is observed in two dimensions. In more than two dimensions, instead, the continuous symmetry can be broken spontaneously and yields a spin glass order parameter which, for fixed temperature and disorder strength, takes continuous values in an interval. Such a feature is shared by the order parameter of the known mean field solution of the model with infinite-range interactions, which corresponds to infinitely many dimensions."}
{"id": "2511.19761", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.19761", "abs": "https://arxiv.org/abs/2511.19761", "authors": ["Michael Hellstern", "Ali Shojaie"], "title": "Order Selection in Vector Autoregression by Mean Square Information Criterion", "comment": "28 pages, 11 figures, 3 tables", "summary": "Vector autoregressive (VAR) processes are ubiquitously used in economics, finance, and biology. Order selection is an essential step in fitting VAR models. While many order selection methods exist, all come with weaknesses. Order selection by minimizing AIC is a popular approach but is known to consistently overestimate the true order for processes of small dimension. On the other hand, methods based on BIC or the Hannan-Quinn (HQ) criteria are shown to require large sample sizes in order to accurately estimate the order for larger-dimensional processes. We propose the mean square information criterion (MIC) based on the observation that the expected squared error loss is flat once the fitted order reaches or exceeds the true order. MIC is shown to consistently estimate the order of the process under relatively mild conditions. Our simulation results show that MIC offers better performance relative to AIC, BIC, and HQ under misspecification. This advantage is corroborated when forecasting COVID-19 outcomes in New York City. Order selection by MIC is implemented in the micvar R package available on CRAN."}
{"id": "2511.20161", "categories": ["physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20161", "abs": "https://arxiv.org/abs/2511.20161", "authors": ["Maksim Radionov", "Daria Popova-Gorelova"], "title": "Attosecond momentum-resolved resonant inelastic x-ray scattering for imaging coupled electron-hole dynamics", "comment": null, "summary": "Improving our understanding of electron dynamics is essential for advancing energy transfer, optoelectronics, light harvesting systems and quantum computing. Recent developments in attosecond x-ray sources provide the fundamental possibility of observing these dynamics with atomic-scale resolution. However, connecting a time-resolved signal to dynamics is challenging due to the broad bandwidth of an attosecond probe pulse. This makes exploring the capabilities of different attosecond imaging techniques crucial. Here, we propose attosecond momentum-resolved resonant inelastic x-ray scattering as a prominent technique for tracking ultrafast dynamics. We demonstrate that the scattering signal contains an information about the instantaneous distribution of charge density across the scattering atoms. To illustrate this, we consider scattering from an $α$-sexithiophene molecule, in which coupled electron-hole dynamics are excited."}
{"id": "2511.19589", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19589", "abs": "https://arxiv.org/abs/2511.19589", "authors": ["Zhi-Qiang Gao", "Chunxiao Liu", "Joel E. Moore"], "title": "Topological BF Theory construction of twisted dihedral quantum double phases from spontaneous symmetry breaking", "comment": "4.5+10 pages, 2+3 figures", "summary": "Nonabelian topological orders host exotic anyons central to quantum computing, yet established realizations rely on case-by-case constructions that are often conceptually involved. In this work, we present a systematic construction of nonabelian dihedral quantum double phases based on a continuous $O(2)$ gauge field. We first formulate a topological $S[O(2)\\times O(2)]$ BF theory, and by identifying the Wilson loops and twist operators of this theory with anyons, we show that our topological BF theory reproduces the complete anyon data, and can incorporate all Dijkgraaf--Witten twists. Building on this correspondence, we present a microscopic model with $O(2)$ lattice gauge field coupled to Ising and rotor matter whose Higgsing yields the desired dihedral quantum double phase. A perturbative renormalization group analysis further indicates a direct transition from this phase to a $U(1)$ Coulomb or chiral topological phase at a stable multicritical point with emergent $O(3)$ symmetry. Our proposal offers an alternative route to nonabelian topological order with promising prospects in synthetic gauge field platforms."}
{"id": "2511.19638", "categories": ["physics.ao-ph", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.19638", "abs": "https://arxiv.org/abs/2511.19638", "authors": ["Haokun Zhou"], "title": "Concept drift of simple forecast models as a diagnostic of low-frequency, regime-dependent atmospheric reorganisation", "comment": null, "summary": "Data-driven weather prediction models implicitly assume that the statistical relationship between predictors and targets is stationary. Under anthropogenic climate change, this assumption is violated, yet the structure of the resulting concept drift remains poorly understood. Here we introduce concept drift of simple forecast models as a diagnostic of atmospheric reorganisation. Using ERA5 reanalysis, we quantify drift in spatially explicit linear models of daily mean sea-level pressure and 2\\,m temperature. Models are trained on the 1950s and 2000s and evaluated on 2020 tp 2024; their performance difference defines a local, interpretable drift metric. By decomposing errors by frequency band, circulation regime and region, and by mapping drift globally, we show that drift is dominated by low-frequency variability and is strongly regime-dependent. Over the North Atlantic-European sector, low-frequency drift peaks in positive NAO despite a stable large-scale NAO pattern, while Western European summer temperature drift is tightly linked to changes in land-atmosphere coupling rather than mean warming alone. In winter, extreme high-pressure frequencies increase mainly in neutral and negative NAO, whereas structural drift is concentrated in positive NAO and Alpine hotspots. Benchmarking against variance-based diagnostics shows that drift aligns much more with changes in temporal persistence than with changes in volatility or extremes. These findings demonstrate that concept drift can serve as a physically meaningful diagnostic of evolving predictability, revealing aspects of atmospheric reorganisation that are invisible to standard deviation and storm-track metrics."}
{"id": "2511.19938", "categories": ["physics.ao-ph", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2511.19938", "abs": "https://arxiv.org/abs/2511.19938", "authors": ["Himanshu Yadav", "Gisela D. Charó", "Davide Faranda"], "title": "Topological Structure of the Cyclonic-Anticyclonic Interactions", "comment": null, "summary": "We investigate the large-scale structure and temporal evolution of cyclonic and anticyclonic systems in the North Atlantic using persistent homology applied to daily sea-level pressure anomalies from the ERA5 reanalysis (1950-2022). By interpreting the pressure field as a cubical complex and computing its sublevel- and superlevel-set filtrations, we identify degree-1 topological features corresponding respectively to anticyclones surrounded by low pressure and cyclones surrounded by high pressure. We quantify their intensity through total persistence and track their evolution over time using optimal matchings and Wasserstein distances between consecutive persistence diagrams. The method captures coherent, long-lived structures without requiring feature-tracking heuristics and reveals robust seasonal patterns: both cyclonic and anticyclonic 1-holes exhibit strong winter maxima and summer minima in total persistence, lifetime, and frequency. Cyclonic features are more persistent, more numerous, and longer-lived than their anticyclonic counterparts, consistent with the climatological dominance of the Icelandic Low in winter and the weaker, more transient nature of anticyclonic highs. Long trajectories correspond to known large-scale structures such as winter cyclonic deepening and blocking episodes. These results demonstrate that persistent homology provides an objective, filtering-free characterization of pressure-field organization and offers a topological framework to analyze the dynamics and variability of mid-latitude circulation."}
{"id": "2511.20287", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2511.20287", "abs": "https://arxiv.org/abs/2511.20287", "authors": ["Anton V. Hlushchenko", "Mykhailo I. Bratchenko", "Aleksei V. Chechkin"], "title": "Stochastic Dynamics of Skyrmions on a Racetrack: Impact of Equilibrium and Nonequilibrium Noise", "comment": "13 pages, 3 figures", "summary": "Current-driven motion of domain walls and skyrmions is central to the operation of non-volatile magnetic memory devices. Racetrack memory requires current densities high enough to generate velocities above 50 m/s, but such conditions also enhance spin-current noise. We develop a theoretical framework based on the stochastic Thiele equation to analyze the effects of equilibrium (thermal) and nonequilibrium (spin-current) fluctuations on skyrmion dynamics. From this approach, we derive diffusion coefficients and mean-squared displacements that quantify stochastic motion under both noise sources. Micromagnetic simulations and analytical results demonstrate that spin-current noise dominates skyrmion dynamics in typical racetrack structures up to room temperature. We further address the first-passage-time problem, obtaining the mean first-passage time and its standard deviation along and across the racetrack. These results quantify how random displacements affect skyrmion propagation and detection, providing insights into error sources in high-speed racetrack memory devices."}
{"id": "2511.19715", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19715", "abs": "https://arxiv.org/abs/2511.19715", "authors": ["Theodor Hagström", "Lars Herre"], "title": "Understanding Risk and Revenue in the Nordic 15-minute mFRR market: An EV Aggregation Study", "comment": null, "summary": "Decarbonisation, decentralisation, and intermittency are driving the development of flexibility markets towards shorter market time units (MTU). Shorter MTUs and shorter gate closures lower the entrance barriers of demand side aggregators that face significant uncertainty on longer time scales. We study the business case for aggregated EV fleets participating in the Nordic 15-minute mFRR Energy Activation Market (EAM). Motivated by increasing system granularity and rapid EV uptake, we represent fleet flexibility as a virtual battery with time-varying power and energy envelopes and formulate a risk-aware stochastic optimisation that co-ordinates day-ahead scheduling with quarter-hour mFRR bidding. Using synthetic residential charging cohorts and observed day-ahead prices on two stylised days, we compare an independent day-ahead baseline to a co-optimised strategy under conservative availability and a CVaR-augmented objective. Across both price cases, co-optimisation increases expected profit and lowers downside risk: the model buys less energy day-ahead and shifts procurement toward mFRR down while flattening the charging plan to retain eligibility for mFRR up. Profit decomposition shows that the uplift is driven by higher mFRR down revenues and reduced reliance on unwinding day-ahead positions. We discuss operational implications for bidding and outline two extensions: rolling 45-minute re-optimisation and a V2G framework."}
{"id": "2511.20475", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.20475", "abs": "https://arxiv.org/abs/2511.20475", "authors": ["Fabrizio Battistelli", "Francesca Farruggia"], "title": "Public opinion between rearmament and crisis of the nuclear taboo", "comment": "16 pages, 3 figures", "summary": "This article examines the changing relationship between the public and nuclear weapons in a context of increasing international insecurity. It discusses the erosion of the nuclear taboo, understood as a normative aversion to nuclear use. Standard surveys capture abstract and rational opinions, while experimental surveys place respondents in simulated strategic scenarios designed to evoke more emotional responses. The divergence between their results is explained by the fact that they measure two different objects: rational opinions and emotional attitudes. A nationally representative survey conducted in Italy in 2025 shows that 81 percent of respondents consider nuclear weapons fundamentally different from conventional weapons and always wrong to use. Among opponents, a distinction is drawn between deontologists and consequentialists. The article concludes by highlighting the importance of integrating affective and cognitive dimensions in the study of public opinion, as a contribution to countering the normalization of nuclear weapons in political discourse."}
{"id": "2511.19583", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19583", "abs": "https://arxiv.org/abs/2511.19583", "authors": ["Josef Soucek", "Michael Petrov", "Michal Gulka", "Emilie Bourgeois", "Milos Nesladek"], "title": "Modelling and experimental verification of photoelectrical response of NV diamond spin centres", "comment": null, "summary": "We report on a mathematical model of the photoelectric response of NV colour centres in diamond, that can be employed for sensing and quantum science information applications. Although the model applies to NV centre in diamond, it can be applied with small modifications to other semiconducting solid state qubits. In our model, we include the drift and collection of charge carriers as well as the presence of other defects via generation and recombination dynamics. Though the photoluminescence readout and the associated dynamics of the NV defect has been extensively studied experimentally and theoretically, so far, there has been no precise model for photocurrent readout, including these effects. In our description, we use a multilevel-level system including mS=0, mS=+-1 ground and excited states, singlet state and the NV0 neutral state. Also, the presence of substitutional nitrogen (NS), which for example determines the spin coherence via the paramagnetic spin bath, is discussed together with presence of acceptor defects. We model the time-dependent occupation of all electronic sublevels and also consider the electronic charge transport from the Boltzmann transport equation, leading to information about the charge state transitions and recombination dynamics. ODMR and PDMR response as well as their quantum efficiencies, are calculated. On this basis, we determine an optimal parameter space for qubit operations, including the highest spin contrast and especially relate those to NS presence. The model is confirmed experimentally and can become a useful tool for optimisation of the performance of NV qubit photoelectric readout."}
{"id": "2511.19724", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.19724", "abs": "https://arxiv.org/abs/2511.19724", "authors": ["Sabia Asghar", "Qiyao Peng", "Fred Vermolen", "Kees Vuik"], "title": "On the Inversion of Polynomials of Discrete Laplace Matrices", "comment": "22 pages, 5 figures", "summary": "The efficient inversion of matrix polynomials is a critical challenge in computational mathematics. We design a procedure to determine the inverse of matrices polynomial of multidimensional Laplace matrices. The method is based on eigenvector and eigenvalue expansions. The method is consistent with previous expressions of the inverse discretized Laplacian in one spatial dimension \\citep{Vermolen_2022}. Several examples are given."}
{"id": "2511.19701", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.19701", "abs": "https://arxiv.org/abs/2511.19701", "authors": ["Paulin Aubert", "Etienne Chevalier", "Vathana Ly Vath"], "title": "Optimal dividend and capital injection under self-exciting claims", "comment": null, "summary": "In this paper, we study an optimal dividend and capital-injection problem in a Cramér--Lundberg model where claim arrivals follow a Hawkes process, capturing clustering effects often observed in insurance portfolios. We establish key analytical properties of the value function and characterise the optimal capital-injection strategy through an explicit threshold. We also show that the value function is the unique viscosity solution of the associated HJB variational inequality. For numerical purposes, we first compute a benchmark solution via a monotone finite-difference scheme with Howard's policy iteration. We then develop a reinforcement learning approach based on policy-gradient and actor-critic methods. The learned strategies closely match the PDE benchmark and remain stable across initial conditions. The results highlight the relevance of policy-gradient techniques for dividend optimisation under self-exciting claim dynamics and point toward scalable methods for higher-dimensional extensions."}
{"id": "2511.20594", "categories": ["math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20594", "abs": "https://arxiv.org/abs/2511.20594", "authors": ["Shitao Fan", "Ilsang Ohn", "David Dunson", "Lizhen Lin"], "title": "Variational bagging: a robust approach for Bayesian uncertainty quantification", "comment": "44 pages, 14 figures", "summary": "Variational Bayes methods are popular due to their computational efficiency and adaptability to diverse applications. In specifying the variational family, mean-field classes are commonly used, which enables efficient algorithms such as coordinate ascent variational inference (CAVI) but fails to capture parameter dependence and typically underestimates uncertainty. In this work, we introduce a variational bagging approach that integrates a bagging procedure with variational Bayes, resulting in a bagged variational posterior for improved inference. We establish strong theoretical guarantees, including posterior contraction rates for general models and a Bernstein-von Mises (BVM) type theorem that ensures valid uncertainty quantification. Notably, our results show that even when using a mean-field variational family, our approach can recover off-diagonal elements of the limiting covariance structure and provide proper uncertainty quantification. In addition, variational bagging is robust to model misspecification, with covariance structures matching those of the target covariance. We illustrate our variational bagging method in numerical studies through applications to parametric models, finite mixture models, deep neural networks, and variational autoencoders (VAEs)."}
{"id": "2511.19589", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19589", "abs": "https://arxiv.org/abs/2511.19589", "authors": ["Zhi-Qiang Gao", "Chunxiao Liu", "Joel E. Moore"], "title": "Topological BF Theory construction of twisted dihedral quantum double phases from spontaneous symmetry breaking", "comment": "4.5+10 pages, 2+3 figures", "summary": "Nonabelian topological orders host exotic anyons central to quantum computing, yet established realizations rely on case-by-case constructions that are often conceptually involved. In this work, we present a systematic construction of nonabelian dihedral quantum double phases based on a continuous $O(2)$ gauge field. We first formulate a topological $S[O(2)\\times O(2)]$ BF theory, and by identifying the Wilson loops and twist operators of this theory with anyons, we show that our topological BF theory reproduces the complete anyon data, and can incorporate all Dijkgraaf--Witten twists. Building on this correspondence, we present a microscopic model with $O(2)$ lattice gauge field coupled to Ising and rotor matter whose Higgsing yields the desired dihedral quantum double phase. A perturbative renormalization group analysis further indicates a direct transition from this phase to a $U(1)$ Coulomb or chiral topological phase at a stable multicritical point with emergent $O(3)$ symmetry. Our proposal offers an alternative route to nonabelian topological order with promising prospects in synthetic gauge field platforms."}
{"id": "2511.19771", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.19771", "abs": "https://arxiv.org/abs/2511.19771", "authors": ["Wenjie Lan", "Jerome P. Reiter"], "title": "Differentially Private Computation of the Gini Index for Income Inequality", "comment": null, "summary": "The Gini index is a widely reported measure of income inequality. In some settings, the underlying data used to compute the Gini index are confidential. The organization charged with reporting the Gini index may be concerned that its release could leak information about the underlying data. We present an approach for bounding this information leakage by releasing a differentially private version of the Gini index. In doing so, we analyze how adding, deleting, or altering a single observation in any specific dataset can affect the computation of the Gini index; this is known as the local sensitivity. We then derive a smooth upper bound on the local sensitivity. Using this bound, we define a mechanism that adds noise to the Gini index, thereby satisfying differential privacy. Using simulated and genuine income data, we show that the mechanism can reduce the errors from noise injection substantially relative to differentially private algorithms that rely on the global sensitivity, that is, the maximum of the local sensitivities over all possible datasets. We characterize settings where using smooth sensitivity can provide highly accurate estimates, as well as settings where the noise variance is simply too large to provide reliably useful results. We also present a Bayesian post-processing step that provides interval estimates about the value of the Gini index computed with the confidential data."}
{"id": "2511.19879", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19879", "abs": "https://arxiv.org/abs/2511.19879", "authors": ["Jackson C. Glass", "Gia-Wei Chern"], "title": "Learning Degenerate Manifolds of Frustrated Magnets with Boltzmann Machines", "comment": "12 pages, 10 figures", "summary": "We show that Restricted Boltzmann Machines (RBMs) provide a flexible generative framework for modeling spin configurations in disordered yet strongly correlated phases of frustrated magnets. As a benchmark, we first demonstrate that an RBM can learn the zero-temperature ground-state manifold of the one-dimensional ANNNI model at its multiphase point, accurately reproducing its characteristic oscillatory and exponentially decaying correlations. We then apply RBMs to kagome spin ice and show that they successfully learn the local ice rules and short-range correlations of the extensively degenerate ice-I manifold. Correlation functions computed from RBM-generated configurations closely match those from direct Monte Carlo simulations. For the partially ordered ice-II phase -- featuring long-range charge order and broken time-reversal symmetry -- accurate modeling requires RBMs with uniform-sign bias fields, mirroring the underlying symmetry breaking. These results highlight the utility of RBMs as generative models for learning constrained and highly frustrated magnetic states."}
{"id": "2511.19738", "categories": ["physics.ao-ph", "astro-ph.EP", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.19738", "abs": "https://arxiv.org/abs/2511.19738", "authors": ["Mahsa Jahangiri", "Afrooz Jouzdani", "Hamid Reza Khalesifard"], "title": "Investigating impacts of dust events on atmospheric surface temperature in Southwest Asia using AERONET data, satellite recordings, and atmospheric models", "comment": null, "summary": "Dust layers have already been reported to have negative impacts on the radiation budget of the atmosphere. But the questions are: How does the atmospheric surface temperature change during a dust outbreak, and what is its temporal correlation with variations of the dust outbreak strength? We investigated these at selected AERONET sites, including Bahrain, IASBS, Karachi, KAUST Campus, Kuwait University, Lahore, Mezaira, Solar Village, in Southwest Asia, and Dushanbe in Central Asia, using available data from 1998 to 2024. The aerosol optical depth at 870 nm and the temperature recorded at each site are taken as measures of dust outbreak strength and atmospheric surface temperature, respectively. The Hybrid Single-Particle Lagrangian Integrated Trajectory (HYSPLIT) model and the aerosol optical depths recorded by the Moderate Resolution Imaging Spectroradiometers (MODIS) on board the Aqua and Terra satellites are used to specify the sources of the dust outbreaks. Our investigations show that in most cases, the temperature decreases during a dust outbreak, but in a considerable number of cases, the temperature rises. Temperature changes are mostly less than 5 °C. We found that a dust outbreak may affect the temperature even up to two days after its highest intensity time. This effect is more profound at sites far from large dust sources, such as IASBS in northwest Iran. For sites that are located on either a dust source or very close to it, the temperature and dust optical depth vary almost synchronously."}
{"id": "2511.20163", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.20163", "abs": "https://arxiv.org/abs/2511.20163", "authors": ["Gesualdo Delfino"], "title": "On the nature of the spin glass transition", "comment": null, "summary": "We recently showed that the two-dimensional Ising spin glass allows for a line of renormalization group fixed points. We observe that this exact result corresponds to enhancement to a one-generator continuous internal symmetry. This finally explains why no finite temperature transition to a spin glass phase is observed in two dimensions. In more than two dimensions, instead, the continuous symmetry can be broken spontaneously and yields a spin glass order parameter which, for fixed temperature and disorder strength, takes continuous values in an interval. Such a feature is shared by the order parameter of the known mean field solution of the model with infinite-range interactions, which corresponds to infinitely many dimensions."}
{"id": "2511.19770", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19770", "abs": "https://arxiv.org/abs/2511.19770", "authors": ["Peter Iwer Hoedt Karstensen", "Roberto Galeazzi"], "title": "Multi-Hypotheses Ego-Tracking for Resilient Navigation", "comment": null, "summary": "Autonomous robots relying on radio frequency (RF)-based localization such as global navigation satellite system (GNSS), ultra-wide band (UWB), and 5G integrated sensing and communication (ISAC) are vul- nerable to spoofing and sensor manipulation. This paper presents a resilient navigation architecture that combines multi-hypothesis estimation with a Poisson binomial windowed-count detector for anomaly identi- fication and isolation. A state machine coordinates transitions between operation, diagnosis, and mitigation, enabling adaptive response to adversarial conditions. When attacks are detected, trajectory re-planning based on differential flatness allows information-gathering maneuvers minimizing performance loss. Case studies demonstrate effective detection of biased sensors, maintenance of state estimation, and recovery of nominal operation under persistent spoofing attacks"}
{"id": "2511.19585", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.19585", "abs": "https://arxiv.org/abs/2511.19585", "authors": ["Jesus Fuentes", "Cynthia Keeler", "William Munizzi", "Jason Pollack"], "title": "Monogamy of Mutual Information in Graph States", "comment": "61 pages, 13 figures, 18 tables, 1 computational package, 1 data set", "summary": "The monogamy of mutual information (MMI) is a quantum entropy inequality that enforces the non-positivity of tripartite information. We investigate the failure of MMI in graph states as a forbidden-subgraph phenomenon, conjecturing that every MMI-violating graph state is local-Clifford equivalent to one whose graph contains a four-star subgraph. We construct a family of star-like graphs whose states fail a specific class of MMI instances, and extend this analysis to general star topologies. Deriving adjacency matrix constraints that fix the MMI evaluation for these instances and interpreting them physically, we prove the forbidden-subgraph conjecture for this family of graphs. Finally, through an exhaustive search over graph representatives for all $8$-qubit stabilizer entropy vectors, we establish that MMI failure is not reducible to the cases within our scope."}
{"id": "2511.20103", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.20103", "abs": "https://arxiv.org/abs/2511.20103", "authors": ["Eric T. Chung", "Patrick Ciarlet", "Xingguang Jin", "Changqing Ye"], "title": "Multiscale Methods for wave propagation in materials with sign-changing coefficients", "comment": null, "summary": "From a mathematical perspective, the extraordinary properties of metamaterials are often reflected in the coefficients of the governing partial differential equations (PDEs). These coefficients may fall outside the assumptions of classical theory, particularly when the effective dielectric permittivity and/or magnetic permeability are negative. This situation can transform a coercive operator into a non-coercive one, potentially leading to ill-posedness. In this paper, we utilize the Constraint Energy Minimizing Generalized Multiscale Finite Element Method (CEM-GMsFEM), specifically designed for time-harmonic electromagnetic wave problems, where the construction of auxiliary spaces in the original CEM-GMsFEM is tailored to accommodate the sign-changing setting. Based on the framework of \\texttt{T}-coercivity theory and resolution conditions, we establish the inf-sup stability and provide an a priori error estimate for the proposed method. The numerical results demonstrate the effectiveness and robustness of our approach in handling such sophisticated coefficient profiles."}
{"id": "2511.19708", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19708", "abs": "https://arxiv.org/abs/2511.19708", "authors": ["Chenyang Qiu", "Yangyang Qian", "Zongli Lin", "Yacov A. Shamash"], "title": "An Accelerated Distributed Algorithm with Equality and Inequality Coupling Constraints", "comment": null, "summary": "This paper studies distributed convex optimization with both affine equality and nonlinear inequality couplings through the duality analysis. We first formulate the dual of the coupling-constraint problem and reformulate it as a consensus optimization problem over a connected network. To efficiently solve this dual problem and hence the primal problem, we design an accelerated linearized algorithm that, at each round, a look-ahead linearization of the separable objective is combined with a quadratic penalty on the Laplacian constraint, a proximal step, and an aggregation of iterations. On the theory side, we prove non-ergodic rates for both the primal optimality error and the feasibility error. On the other hand, numerical experiments show a faster decrease of optimality error and feasibility residual than augmented-Lagrangian tracking and distributed subgradient baselines under the same communication budget."}
{"id": "2511.19960", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.19960", "abs": "https://arxiv.org/abs/2511.19960", "authors": ["Deepra Ghosh", "Sanat K. Sarkar"], "title": "Dependence-Aware False Discovery Rate Control in Two-Sided Gaussian Mean Testing", "comment": null, "summary": "This paper develops a general framework for controlling the false discovery rate (FDR) in multiple testing of Gaussian means against two-sided alternatives. The widely used Benjamini-Hochberg (BH) procedure provides exact FDR control under independence or conservative control under specific one-sided dependence structures, but its validity for correlated two-sided tests has remained an open question. We introduce the notion of positive left-tail dependence under the null (PLTDN), extending classical dependence assumptions to two-sided settings, and show that it ensures valid FDR control for BH-type procedures. Building on this framework, we propose a family of generalized shifted BH (GSBH) methods that incorporate correlation information through simple p-value adjustments. Simulation results demonstrate reliable FDR control and improved power across a range of dependence structures, while an application to an HIV gene expression dataset illustrates the practical effectiveness of the proposed approach."}
{"id": "2511.19597", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.19597", "abs": "https://arxiv.org/abs/2511.19597", "authors": ["Tsung-Cheng Lu", "Yu-Jie Liu", "Sarang Gopalakrishnan", "Yizhi You"], "title": "Holographic duality between bulk topological order and boundary mixed-state order", "comment": "27 pages, 19 figures", "summary": "We introduce a holographic framework for analyzing the steady states of repeated quantum channels with strong symmetries. Using channel-state duality, we show that the steady state of a $d$-dimensional quantum channel is holographically mapped to the boundary reduced density matrix of a $(d+1)$-dimensional wavefunction generated by a sequential unitary circuit. From this perspective, strong-to-weak spontaneous symmetry breaking (SWSSB) in the steady state arises from the anyon condensation on the boundary of a topological order in one higher dimension. The conditional mutual information (CMI) associated with SWSSB is then inherited from the bulk topological entanglement entropy. We make this duality explicit using isometric tensor network states (isoTNS) by identifying the channel's time evolution with the transfer matrix of a higher-dimensional isoTNS. Built on isoTNS, we further construct continuously tunable quantum channels that exhibit distinct mixed-state phases and transitions in the steady states."}
{"id": "2511.19796", "categories": ["stat.ME", "econ.EM", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.19796", "abs": "https://arxiv.org/abs/2511.19796", "authors": ["Stevenson Bolivar", "Rong Chen", "Yuefeng Han"], "title": "Threshold Tensor Factor Model in CP Form", "comment": null, "summary": "This paper proposes a new Threshold Tensor Factor Model in Canonical Polyadic (CP) form for tensor time series. By integrating a thresholding autoregressive structure for the latent factor process into the tensor factor model in CP form, the model captures regime-switching dynamics in the latent factor processes while retaining the parsimony and interpretability of low-rank tensor representations. We develop estimation procedures for the model and establish the theoretical properties of the resulting estimators. Numerical experiments and a real-data application illustrate the practical performance and usefulness of the proposed framework."}
{"id": "2511.20060", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.20060", "abs": "https://arxiv.org/abs/2511.20060", "authors": ["Kazuki Okigami", "Satoru Hayami"], "title": "Finite-temperature stability of skyrmion crystals in frustrated magnets: Role of sixfold anisotropy and uniform spin mode in momentum space", "comment": "6 pages, 7 figures", "summary": "We study the finite-temperature stability of skyrmion crystals in frustrated magnets by analyzing the momentum-space exchange interaction of a classical Heisenberg model on a triangular lattice. Our analysis identifies two key momentum-space features that play a crucial role in stabilizing the skyrmion crystal phase. The first is the sixfold anisotropy in the momentum-space exchange interaction, which acts as a locking potential favoring triple-$Q$ skyrmion crystals. Monte Carlo simulations reveal that a larger anisotropy tends to enhance the stability region of the skyrmion crystal in the temperature--magnetic-field phase diagram. The second factor is the momentum-space energy related to the uniform spin mode, which correlates with the emergence of the skyrmion crystal phase at finite temperatures. These results provide a further understanding of the stabilization mechanism of the skyrmion crystal phase in frustrated magnets and will be useful for the design of skyrmion-hosting materials."}
{"id": "2511.19876", "categories": ["physics.ao-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.19876", "abs": "https://arxiv.org/abs/2511.19876", "authors": ["Heng Quan", "Yi Zhang", "Guy Dagan", "Stephan Fueglistaler"], "title": "Periodic extreme rainfall in a warmer climate due to stronger convectively-coupled waves", "comment": null, "summary": "Tropical regions may experience periodic extreme precipitation and suffer from associated periodic deluges in a warmer climate. Recent studies conducted small-domain (around 100 km x 100 km) atmospheric model simulations and found that precipitation transitions from a steady state to a periodic oscillation state in a hothouse climate when the sea surface temperature reaches 320-325 K. Here we conduct global-scale atmospheric model simulations with different complexity, and we find that tropical precipitation in convective regions already transitions to a O(10 day) periodic oscillation state with a O(100 mm/day) amplitude at 305-310 K. This temperature is substantially lower than previously reported, and within reach in a century under a high carbon emission scenario. We attribute the onset of the periodic extreme precipitation to the intensification of convectively-coupled waves, which occurs at temperatures much lower than the radiative mechanism responsible for the transition around 320-325 K identified before."}
{"id": "2511.19884", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19884", "abs": "https://arxiv.org/abs/2511.19884", "authors": ["Mobina Nankali", "Michael W. Levin"], "title": "An Exact Solution Algorithm for the Bi-Level Optimization Problem of Electric Vehicles Charging Station Placement", "comment": null, "summary": "This work addresses electric vehicle (EV) charging station placement through a bi-level optimization model, where the upper-level planner maximizes net revenue by selecting station locations under budget constraints, while EV users at the lower level choose routes and charging stations to minimize travel and charging costs. To account for range anxiety, we construct a battery-expanded network and apply a shortest path algorithm with Frank-Wolfe traffic assignment. Our primary contribution is developing the first exact solution algorithm for large scale EV charging station placement problems. We propose a Branch-and-Price-and-Cut algorithm enhanced with value function cuts and column generation. While existing research relies on heuristic methods that provide no optimality guarantees or exact algorithms that require prohibitively long runtimes, our exact algorithm delivers globally optimal solutions with mathematical certainty under a reasonable runtime. Computational experiments on the Eastern Massachusetts network (74 nodes, 248 links), the Anaheim network (416 nodes, 914 links), and the Barcelona network (110 zones, 1,020 nodes, and 2,512 links) demonstrate exceptional performance. Our algorithm terminates within minutes rather than hours, while achieving optimality gaps below 1% across all instances. This result represents a computational speedup of over two orders of magnitude compared to existing methods. The algorithm successfully handles problems with over 300,000 feasible combinations, which transform EV charging infrastructure planning from a computationally prohibitive problem into a tractable optimization task suitable for practical decision making problem for real world networks."}
{"id": "2511.19597", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.19597", "abs": "https://arxiv.org/abs/2511.19597", "authors": ["Tsung-Cheng Lu", "Yu-Jie Liu", "Sarang Gopalakrishnan", "Yizhi You"], "title": "Holographic duality between bulk topological order and boundary mixed-state order", "comment": "27 pages, 19 figures", "summary": "We introduce a holographic framework for analyzing the steady states of repeated quantum channels with strong symmetries. Using channel-state duality, we show that the steady state of a $d$-dimensional quantum channel is holographically mapped to the boundary reduced density matrix of a $(d+1)$-dimensional wavefunction generated by a sequential unitary circuit. From this perspective, strong-to-weak spontaneous symmetry breaking (SWSSB) in the steady state arises from the anyon condensation on the boundary of a topological order in one higher dimension. The conditional mutual information (CMI) associated with SWSSB is then inherited from the bulk topological entanglement entropy. We make this duality explicit using isometric tensor network states (isoTNS) by identifying the channel's time evolution with the transfer matrix of a higher-dimensional isoTNS. Built on isoTNS, we further construct continuously tunable quantum channels that exhibit distinct mixed-state phases and transitions in the steady states."}
{"id": "2511.20142", "categories": ["math.NA", "cs.DC"], "pdf": "https://arxiv.org/pdf/2511.20142", "abs": "https://arxiv.org/abs/2511.20142", "authors": ["Alexandre Epalle", "Isabelle Ramière", "Guillaume Latu", "Frédéric Lebon"], "title": "Parallel simulation and adaptive mesh refinement for 3D elastostatic contact mechanics problems between deformable bodies", "comment": null, "summary": "Parallel implementation of numerical adaptive mesh refinement (AMR)strategies for solving 3D elastostatic contact mechanics problems is an essential step toward complex simulations that exceed current performance levels. This paper introduces a scalable, robust, and efficient algorithm to deal with 2D and 3D elastostatics contact problems between deformable bodies in a finite element framework. The proposed solution combines a treatment of the contact problem by a node-to-node pairing algorithm with a penalization technique and a non-conforming h-adaptive refinement of quadrilateral/hexahedral meshes based on an estimate-mark-refine approach in a parallel framework. One of the special features of our parallel strategy is that contact paired nodes are hosted by the same MPI tasks, which reduces the number of exchanges between processes for building the contact operator. The mesh partitioning introduced in this paper respects this rule and is based on an equidistribution of elements over processes, without any other constraints. In order to preserve the domain curvature while hierarchical mesh refinement, super-parametric elements are used. This functionality enables the contact zone to be well detected during the AMR process, even for an initial coarse mesh and low-order discretization schemes. The efficiency of our contact-AMR-HPC strategy is assessed on 2D and 3D Hertzian contact problems. Different AMR detection criteria are considered. Various convergence analyses are conducted. Parallel performances up to 1024 cores are illustrated. Furthermore, memory footprint and preconditionners performance are analyzed."}
{"id": "2511.19714", "categories": ["math.OC", "cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19714", "abs": "https://arxiv.org/abs/2511.19714", "authors": ["Chenyang Qiu", "Zongli Lin"], "title": "Non-Ergodic Convergence Algorithms for Distributed Consensus and Coupling-Constrained Optimization", "comment": null, "summary": "We study distributed convex optimization with two ubiquitous forms of coupling: consensus constraints and global affine equalities. We first design a linearized method of multipliers for the consensus optimization problem. Without smoothness or strong convexity, we establish non-ergodic sublinear rates of order O(1/\\sqrt{k}) for both the objective optimality and the consensus violation. Leveraging duality, we then show that the economic dispatch problem admits a dual consensus formulation, and that applying the same algorithm to the dual economic dispatch yields non-ergodic O(1/\\sqrt{k}) decay for the error of the summation of the cost over the network and the equality-constraint residual under convexity and Slater's condition. Numerical results on the IEEE 118-bus system demonstrate faster reduction of both objective error and feasibility error relative to the state-of-the-art baselines, while the dual variables reach network-wide consensus."}
{"id": "2511.19662", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19662", "abs": "https://arxiv.org/abs/2511.19662", "authors": ["Eric R. Bittner"], "title": "Entropy Flow and Exceptional-Point Structure in Two-Mode Squeezed-Bath Dynamics", "comment": "12 pages, 5 figures. Comments welcome", "summary": "Squeezed reservoirs provide a powerful means of engineering nonclassical noise and controlling irreversible dynamics in open quantum systems. Here we develop a comprehensive analysis of two coupled harmonic oscillators driven by independent squeezed baths, focusing on the emergence of coherence-driven entropy flow and the structure of exceptional points (EPs) in the corresponding Lindblad dynamics. Working entirely within the Gaussian formalism, we derive closed-form evolution equations for the covariance matrix and show that squeezing induces entropy generation only at *second order* in the anomalous correlations, a nonlinear mechanism absent in thermal environments. This entropy flow is accompanied by a rich non-Hermitian structure: by scanning the squeezing parameters we uncover a characteristic \"exceptional-point fan\" in the (M1, M2) plane, which separates a narrow PT-unbroken region of oscillatory dynamics from broad PT-broken sectors in which one normal mode becomes purely overdamped. This geometric organization of EPs reveals that PT symmetry survives only when the two reservoirs squeeze opposite quadratures, and is generically broken for in-phase squeezing. Our analysis establishes squeezed reservoirs as a natural setting where information-bearing noise drives irreversible behavior through coherent pathways, and lays the groundwork for experimentally accessible probes of entropy flow and critical mode behavior in more complex open systems."}
{"id": "2511.19960", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.19960", "abs": "https://arxiv.org/abs/2511.19960", "authors": ["Deepra Ghosh", "Sanat K. Sarkar"], "title": "Dependence-Aware False Discovery Rate Control in Two-Sided Gaussian Mean Testing", "comment": null, "summary": "This paper develops a general framework for controlling the false discovery rate (FDR) in multiple testing of Gaussian means against two-sided alternatives. The widely used Benjamini-Hochberg (BH) procedure provides exact FDR control under independence or conservative control under specific one-sided dependence structures, but its validity for correlated two-sided tests has remained an open question. We introduce the notion of positive left-tail dependence under the null (PLTDN), extending classical dependence assumptions to two-sided settings, and show that it ensures valid FDR control for BH-type procedures. Building on this framework, we propose a family of generalized shifted BH (GSBH) methods that incorporate correlation information through simple p-value adjustments. Simulation results demonstrate reliable FDR control and improved power across a range of dependence structures, while an application to an HIV gene expression dataset illustrates the practical effectiveness of the proposed approach."}
{"id": "2511.20261", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20261", "abs": "https://arxiv.org/abs/2511.20261", "authors": ["Xiang Li", "Xiangjian Qian", "Mingpu Qin"], "title": "Disentangling Kitaev Quantum Spin Liquid", "comment": null, "summary": "In this work, we investigate the Kitaev honeycomb model employing the recently developed Clifford Circuits Augmented Matrix Product States (CAMPS) method. While the model in the gapped phase is known to reduce to the toric code model - whose ground state is entirely constructible from Clifford circuits - we demonstrate that the very different gapless quantum spin liquid (QSL) phase can also be significantly disentangled with Clifford circuits. Specifically, CAMPS simulations reveal that approximately two-thirds of the entanglement entropy in the isotropic point arises from Clifford-circuit contributions, enabling dramatically more efficient computations compared to conventional matrix product state (MPS) methods. Crucially, this finding implies that the Kitaev QSL state retains significant Clifford-simulatable structure, even in the gapless phase with non-abelian anyon excitations when time reversal symmetry is broken. This property not only enhances classical simulation efficiency significantly but also suggests substantial resource reduction for preparing such states on quantum devices. As an application, we leverage CAMPS to study the Kitaev-Heisenberg model and determine the most accurate phase boundary between the anti-ferromagnetic phase and the Kitaev QSL phase in the model. Our results highlight how Clifford circuits can effectively disentangle the intricate entanglement of Kitaev QSLs, opening avenues for efficiently simulating related and similar strongly correlated models."}
{"id": "2511.19938", "categories": ["physics.ao-ph", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2511.19938", "abs": "https://arxiv.org/abs/2511.19938", "authors": ["Himanshu Yadav", "Gisela D. Charó", "Davide Faranda"], "title": "Topological Structure of the Cyclonic-Anticyclonic Interactions", "comment": null, "summary": "We investigate the large-scale structure and temporal evolution of cyclonic and anticyclonic systems in the North Atlantic using persistent homology applied to daily sea-level pressure anomalies from the ERA5 reanalysis (1950-2022). By interpreting the pressure field as a cubical complex and computing its sublevel- and superlevel-set filtrations, we identify degree-1 topological features corresponding respectively to anticyclones surrounded by low pressure and cyclones surrounded by high pressure. We quantify their intensity through total persistence and track their evolution over time using optimal matchings and Wasserstein distances between consecutive persistence diagrams. The method captures coherent, long-lived structures without requiring feature-tracking heuristics and reveals robust seasonal patterns: both cyclonic and anticyclonic 1-holes exhibit strong winter maxima and summer minima in total persistence, lifetime, and frequency. Cyclonic features are more persistent, more numerous, and longer-lived than their anticyclonic counterparts, consistent with the climatological dominance of the Icelandic Low in winter and the weaker, more transient nature of anticyclonic highs. Long trajectories correspond to known large-scale structures such as winter cyclonic deepening and blocking episodes. These results demonstrate that persistent homology provides an objective, filtering-free characterization of pressure-field organization and offers a topological framework to analyze the dynamics and variability of mid-latitude circulation."}
{"id": "2511.19449", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19449", "abs": "https://arxiv.org/abs/2511.19449", "authors": ["Adeline Guéret"], "title": "Power sector models featuring individual BEV profiles: Assessing the time-accuracy trade-off", "comment": null, "summary": "Electrifying passenger cars will impact future power systems. To understand the challenges and opportunities that arise, it is necessary to reflect \"sector coupling\" in the modeling space. This paper focuses on a specific modeling approach that includes dozens of individual BEV profiles rather than one aggregated BEV profile. Although including additional BEV profiles increases model complexity and runtime, it avoids losing information in the aggregation process. We investigate how many profiles are needed to ensure the accuracy of the results and the extent to which fewer profiles can be traded for runtime efficiency gains. We also examine whether selecting specific profiles influences optimal results. We demonstrate that including too few profiles may result in distorted optimal solutions. However, beyond a certain threshold, adding more profiles does not significantly enhance the robustness of the results. More generally, for fleets of 5 to 20 million BEVs, we derive a rule of thumb consisting in including enough profiles such that each profile represents 200,000 to 250,000 vehicles, ensuring accurate results without excessive runtime."}
{"id": "2511.19961", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19961", "abs": "https://arxiv.org/abs/2511.19961", "authors": ["Zhenyu Tao", "Wei Xu", "Xiaohu You"], "title": "Toward Trustworthy Digital Twins in Agentic AI-based Wireless Network Optimization: Challenges, Solutions, and Opportunities", "comment": null, "summary": "Optimizing modern wireless networks is exceptionally challenging due to their high dynamism and complexity. While the agentic artificial intelligence (AI) powered by reinforcement learning (RL) offers a promising solution, its practical application is limited by prohibitive exploration costs and potential risks in the real world. The emerging digital twin (DT) technology provides a safe and controlled virtual environment for agentic AI training, but its effectiveness critically depends on the DT's fidelity. Policies trained in a low-fidelity DT that does not accurately represent the physical network may experience severe performance degradation upon real-world deployment. In this article, we introduce a unified DT evaluation framework to ensure trustworthy DTs in agentic AI-based network optimization. This evaluation framework shifts from conventional isolated physical accuracy metrics, such as wireless channel and user trajectory similarities, to a more holistic, task-centric DT assessment. We demonstrate it as an effective guideline for design, selection, and lifecycle management of wireless network DTs. A comprehensive case study on a real-world wireless network testbed shows how this evaluation framework is used to pre-filter candidate DTs, leading to a significant reduction in training and testing costs without sacrificing deployment performance. Finally, potential research opportunities are discussed."}
{"id": "2511.19598", "categories": ["quant-ph", "hep-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.19598", "abs": "https://arxiv.org/abs/2511.19598", "authors": ["Steven Abel", "Iwo Wasek", "Simon Williams"], "title": "Berry's phase on photonic quantum computers", "comment": "16 pages, 10 figures", "summary": "We formulate a continuous-variable quantum computing (CVQC) algorithm to study Berry's phase on photonic quantum computers. We demonstrate that CVQC allows the simulation of charged particles with orbital angular momentum under the influence of an adiabatically changing $\\vec{B}$ field. Although formulated entirely in the CVQC setting, our construction uses only passive linear-optical operations (beam splitters and phase shifts), which act identically in single-photon photonic architectures. This enables experimental realisation on the Quandella Ascella platform, where we observe the Berry's phase phenomenon with interferometric measurement. We also generalise the framework to more rapid non-adiabatic evolution. By concatenating Aharonov-Anandan cycles for opposing magnetic fields we demonstrate that one can engineer a circuit in which dynamical phases and leading non-geometric errors cancel by symmetry, leaving the intrinsically robust geometric phase contribution."}
{"id": "2511.20181", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.20181", "abs": "https://arxiv.org/abs/2511.20181", "authors": ["David Lee", "Kieran Ricardo", "Tamara Tambyah"], "title": "High order tracer variance stable transport with low order energy conserving dynamics for the thermal shallow water equations", "comment": null, "summary": "A high order discontinuous Galerkin method for the material transport of thermodynamic tracers is coupled to a low order mixed finite element solver in the context of the thermal shallow water equations. The coupling preserves the energy conserving structure of the low order dynamics solver, while the high order material transport scheme is provably tracer variance conserving, or damping with the inclusion of upwinding. The two methods are coupled via the multigrid hierarchy of the low order dynamics solver, with the basis functions of the high order transport being collocated at the Gauss-Legendre quadrature points with the low order dynamics on the finest scale multigrid mesh.\n  Standard test cases are presented to verify the consistency and conservation properties of the method. While the overall scheme is limited by the formal order of accuracy of the low order dynamics, the use of high order, tracer variance conserving transport is shown to preserve richer turbulent solutions without compromising model stability compared to a purely low order method."}
{"id": "2511.19723", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19723", "abs": "https://arxiv.org/abs/2511.19723", "authors": ["Chenyang Qiu", "Zongli Lin"], "title": "A Distributed Gradient-based Algorithm for Optimization Problems with Coupled Equality Constraints", "comment": "11 pages, 3 figures, submitted to Automatica", "summary": "This paper studies a class of distributed optimization problems with coupled equality constraints in networked systems. Many existing distributed algorithms rely on solving local subproblems via the $\\operatorname{argmin}$ operator in each iteration. Such approaches become computationally burdensome or intractable when local cost functions are complex. To address this challenge, we propose a novel distributed gradient-based algorithm that avoids solving a local optimization problem at each iteration by leveraging first-order approximations and projection onto local feasible sets. The algorithm operates in a fully distributed manner, requiring only local communication without exchanging gradients or primal variables. We rigorously establish sublinear convergence for general convex cost functions and linear convergence under strong convexity and smoothness conditions. Numerical simulation on the IEEE 118-bus system demonstrates the superior computational efficiency and scalability of the proposed method compared to several state-of-the-art distributed optimization algorithms."}
{"id": "2511.19700", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19700", "abs": "https://arxiv.org/abs/2511.19700", "authors": ["Josef Richter", "Masudul Haque", "Lucas Sá"], "title": "Localization and Delocalization of Quantum Trajectories in the Liouvillian Spectrum", "comment": "10 pages, 6 figures", "summary": "We develop an approach for understanding the dynamics of open quantum systems by analyzing individual quantum trajectories in the eigenbasis of the Liouvillian superoperator. From trajectory-eigenstate overlaps, we construct a quasiprobability distribution that characterizes the degree of localization of the trajectories in the Liouvillian eigenbasis. Contrary to the common wisdom that late-time dynamics are governed solely by the steady state and the slowest-decaying modes, we show that trajectories can remain well spread over transient eigenstates deep within the bulk of the Liouvillian spectrum even at late times. We demonstrate this explicitly using numerical simulations of interacting spin chains and bosonic systems. Moreover, we find that the delocalization of the trajectory strongly correlates with the purity of the trajectory-averaged steady state, establishing a further link between the trajectory and ensemble pictures of open quantum dynamics."}
{"id": "2511.20021", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.20021", "abs": "https://arxiv.org/abs/2511.20021", "authors": ["Sjoerd Hermes", "Joost van Heerwaarden", "Fred van Eeuwijk", "Pariya Behrouzi"], "title": "Hierarchical Causal Structure Learning", "comment": null, "summary": "Traditional statistical approaches primarily aim to model associations between variables, but many scientific and practical questions require causal methods instead. These approaches rely on assumptions about an underlying structure, often represented by a directed acyclic graph (DAG). When all variables are measured at the same level, causal structures can be learned using existing techniques. However, no suitable methods exist when data are organized hierarchically or across multiple levels. This paper addresses such cases, where both unit-level and group-level variables are present. These multi-level structures frequently arise in fields such as agriculture, where plants (units) grow within different environments (groups). Building on nonlinear structural causal models, or additive noise models, we propose a method that accommodates unobserved confounders as well as group-specific causal functions. The approach is implemented in the R package HSCM, available at https://CRAN.R-project.org/package=HSCM."}
{"id": "2511.20046", "categories": ["physics.ao-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.20046", "abs": "https://arxiv.org/abs/2511.20046", "authors": ["Hao Fu"], "title": "The modulation of vortex growth by periodic convective activity", "comment": null, "summary": "An important process in tropical cyclone formation is the development of a deep, warm core, which corresponds to the growth of a barotropic cyclone. Persistent convective activity is known to be crucial for the growth of barotropic vorticity. However, it remains unclear whether the fluctuating component of convective activity, such as that caused by the diurnal cycle and inertial-gravity waves, also accelerates the vortex development. To investigate this problem, numerical simulations are performed in an axisymmetric model with the Boussinesq approximation on the f-plane. Convection is parameterized with a bulk-plume mass-flux scheme. To represent a mesoscale convective system modulated by the diurnal cycle, periodic convective mass flux is imposed in a local region. The convection induces periodic diabatic heating and convective momentum transfer in the vertical direction (CMT). The CMT is an irreversible effect that breaks the quadrature phase relation between vertical velocity and vertical vorticity, producing a residual barotropic vorticity in each cycle. The barotropic vorticity consists of a barotropic cyclonic core and an anticyclonic shell. The cyclonic core is produced by the vertical advection and stretching of vertical vorticity. The anticyclonic shell is produced by the radial advection and tilting of radial vorticity. The analytical solution reproduces the formation and growth of the core-shell vorticity structure. This research reveals a potential acceleration effect of periodic convective activity on tropical cyclone genesis."}
{"id": "2511.19451", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19451", "abs": "https://arxiv.org/abs/2511.19451", "authors": ["Apurva Patil", "Alfredo Duarte", "Fabrizio Bisetti", "Takashi Tanaka"], "title": "Strong Duality and Dual Ascent Approach to Continuous-Time Chance-Constrained Stochastic Optimal Control", "comment": "arXiv admin note: substantial text overlap with arXiv:2504.17154", "summary": "The paper addresses a continuous-time continuous-space chance-constrained stochastic optimal control (SOC) problem where the probability of failure to satisfy given state constraints is explicitly bounded. We leverage the notion of exit time from continuous-time stochastic calculus to formulate a chance-constrained SOC problem. Without any conservative approximation, the chance constraint is transformed into an expectation of an indicator function which can be incorporated into the cost function by considering a dual formulation. We then express the dual function in terms of the solution to a Hamilton-Jacobi-Bellman partial differential equation parameterized by the dual variable. Under a certain assumption on the system dynamics and cost function, it is shown that a strong duality holds between the primal chance-constrained problem and its dual. The Path integral approach is utilized to numerically solve the dual problem via gradient ascent using open-loop samples of system trajectories. We present simulation studies on chance-constrained motion planning for spatial navigation of mobile robots and the solution of the path integral approach is compared with that of the finite difference method."}
{"id": "2511.20043", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20043", "abs": "https://arxiv.org/abs/2511.20043", "authors": ["Youzhe Yang", "Hafiz Majid Hussain", "Juha Haakana", "Pedro Nardelli"], "title": "Assessing the Technical and Environmental Impacts of Energy Management Systems in Smart Ports", "comment": null, "summary": "A vital strategy for ports to mitigate the environmental impact of the maritime industry, while complying with frameworks such as the European Green Deal and the Sustainable Development Goals (SDGs), entails the systematic implementation of comprehensive energy management solutions. This paper provides a baseline evaluation of the energy management systems (EMSs) implementation and their impact on energy consumption, carbon emissions, and operational costs in smart ports. Initially, we provide a systematic review of the literature focusing on case studies from prominent ports, including Hamburg, Genoa, Jurong, and Shanghai Yangshan Phase IV. The analysis emphasises key aspects such as energy efficiency, reductions in emissions, and the minimization of operational costs. Subsequently, we formulate an optimisation model to simulate load dispatch, carbon emission reduction, and transport scheduling. Results indicate that EMS deployment reduces annual energy consumption and carbon emissions significantly by approximately 7%-8% and 11%-12% respectively, while achieving substantial cost savings of 30%. The study also identifies critical challenges, including system integration, data quality issues, cybersecurity risks, and the need for standardization. These findings provide valuable insights for port authorities and policymakers, supporting the transition toward more sustainable and efficient port operations."}
{"id": "2511.19612", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.19612", "abs": "https://arxiv.org/abs/2511.19612", "authors": ["Ruihua Fan", "Yantao Wu", "Yimu Bao", "Zhehao Dai"], "title": "No-go theorems for sequential preparation of two-dimensional chiral states via channel-state correspondence", "comment": "19 pages + 6 pages appendices, 6 figures", "summary": "We investigate whether sequential unitary circuits can prepare two-dimensional chiral states, using a correspondence between sequentially prepared states, isometric tensor network states, and one-dimensional quantum channel circuits. We establish two no-go theorems, one for Gaussian fermion systems and one for generic interacting systems. In Gaussian fermion systems, the correspondence relates the defining features of chiral wave functions in their entanglement spectrum to the algebraic decaying correlations in the steady state of channel dynamics. We establish the no-go theorem by proving that local channel dynamics with translational invariance cannot support such correlations. As a direct implication, two-dimensional Gaussian fermion isometric tensor network states cannot support algebraically decaying correlations in all directions or represent a chiral state. In generic interacting systems, we establish a no-go theorem by showing that the state prepared by sequential circuits cannot host the tripartite entanglement of a chiral state due to the constraints from causality."}
{"id": "2511.20208", "categories": ["math.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.20208", "abs": "https://arxiv.org/abs/2511.20208", "authors": ["Ben S. Ashby", "Gabriel R. Barrenechea", "Alex Lukyanov", "Tristan Pryer", "Alex Trenam"], "title": "A finite element method for a non-Newtonian dilute polymer fluid", "comment": "28 pages, 13 figures", "summary": "We study the discretisation of a uniaxial (rank-one) reduction of the Oldroyd-B model for dilute polymer solutions, in which the conformation tensor is represented as $\\sig = \\vec b \\otimes \\vec b$. Building on structural analogies with MHD, we formulate a finite element framework compatible with the de Rham complex, so that the discrete velocity is exactly divergence-free. The spatial discretisation combines an interior-penalty treatment of viscosity with upwind transport to control stress layers and we prove inf-sup conditions on the mixed pairs. For time-stepping, we design an IMEX scheme that is linear at each step and show well-posedness of the fully discrete problem together with a discrete energy law mirroring the continuum dissipation. Numerical experiments on canonical benchmarks (lid-driven cavity, pipe-with-cavity and $4{:}1$ planar contraction) demonstrate accuracy and robustness for moderate-to-high Weissenberg numbers, capturing sharp stress gradients and corner singularities while retaining the efficiency gains of the uniaxial model. The results indicate that de Rham-compatible discretisations coupled with energy-stable IMEX time integration provide a reliable pathway for viscoelastic computations at elevated elasticity."}
{"id": "2511.19754", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.19754", "abs": "https://arxiv.org/abs/2511.19754", "authors": ["Qimeng Yu", "Simge Küçükyavuz"], "title": "Convexification of classes of mixed-integer sets with L$^\\natural$-convexity", "comment": null, "summary": "L$^\\natural$ (natural)-convex functions encompass a large class of nonlinear functions over general integer domains and arise in a wide range of real-world applications. We explore the minimization of L$^\\natural$-convex functions, of multiple L$^\\natural$-convex functions with common variables, and of a mixed-integer extension of L$^\\natural$-convex functions -- functions defined over a mixed-integer domain with properties that resemble L$^\\natural$-convexity. For each of these families of minimization problems, we propose valid linear inequalities and provide convex hull descriptions for the corresponding epigraphs. For all classes of proposed inequalities, we discuss their facet conditions, develop exact separation methods, and analyze the complexity of the separation problem. We discover hidden L$^\\natural$-convexity in well-known mixed-integer structures in the integer programming literature, namely the (general integer) mixing set and the continuous mixing set. We show that our findings subsume the existing polyhedral results for these sets and establish new results for the multi-capacity variant of the continuous mixing set."}
{"id": "2511.19860", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19860", "abs": "https://arxiv.org/abs/2511.19860", "authors": ["Ali Tozar"], "title": "Universal Critical Scaling and Phase Diagram of the Non-Hermitian Skin Effect under Disorder", "comment": "8 pages, 4 figures", "summary": "Standard scaling theory dictates that disorder leads to immediate localization in one-dimensional Hermitian systems. We demonstrate that non-Hermitian topology fundamentally alters this paradigm, protecting transport up to a substantial critical disorder strength. By employing a numerically stable log-space transfer matrix approach up to thermodynamic scales (N=1000), we identify a sharp phase transition from the topological skin phase to the Anderson localized phase. Finite-size scaling analysis reveals that this transition belongs to a unique universality class with critical exponents ν\\approx1.50 and β\\approx0.65. Furthermore, we map the global phase diagram, confirming that the critical disorder scales as W_c\\propto\\sqrtγ, consistent with localization suppression by an imaginary vector potential. Our results establish the rigorous limits of non-Hermitian topological protection in imperfect media."}
{"id": "2511.20052", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.20052", "abs": "https://arxiv.org/abs/2511.20052", "authors": ["Hans-Peter Piepho", "Emlyn Williams"], "title": "Rectangular augmented row-column designs generated from contractions", "comment": null, "summary": "Row-column designs play an important role in applications where two orthogonal sources of error need to be controlled for by blocking. Field or greenhouse experiments, in which experimental units are arranged as a rectangular array of experimental units are a prominent example. In plant breeding, the amount of seed available for the treatments to be tested may be so limited that only one experimental unit per treatment can be accommodated. In such settings, augmented designs become an interesting option, where a small set of treatments, for which sufficient seed is available, are replicated across the rectangular layout so that row and column effects, as well as the error variance can be estimated. Here, we consider the use of an auxiliary design, also known as a contraction, to generate an augmented row-column design. We make use of the fact that the efficiency factors of the contraction and the associated augmented design are closely interlinked. A major advantage of this approach is that an efficient contraction can be found by computer search at much higher computational speed than is required for direct search for an efficient augmented design. Two examples are used to illustrate the proposed method."}
{"id": "2511.20089", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.20089", "abs": "https://arxiv.org/abs/2511.20089", "authors": ["Oleg S. Ugolnikov", "Ilya S. Yankovsky", "Nikolay N. Pertsev", "Vladimir I. Perminov", "Maxim V. Klimenko", "Ekaterina N. Tipikina", "Alexey V. Popov", "Andrey M. Tatarnikov", "Sergey G. Zheltoukhov", "Sergey A. Potanin", "Egor O. Ugolnikov", "Olga Yu. Golubeva", "Andrey L. Kotikov", "Alexey S. Sushkov", "Egor A. Volkov"], "title": "Noctilucent Clouds Modulated by Strong 5-day Planetary Wave in 2025: Amplitudes, Phases and Altitudes Based on Ground-Based Observations and Satellite Temperature Data", "comment": "12 pages, 7 figures", "summary": "During the summer season of 2025, noctilucent clouds (NLC) were observed at the latitudes 55-60N from the late May until the late August. A distinct 5-day periodicity in their occurrence emerged following the summer solstice. Analysis of EOS Aura/MLS satellite data revealed that this effect was driven by a westward 5-day planetary wave, the amplitude of which was twice that of any previous northern summer since the start of the EOS Aura measurements in 2005. This study details the evolution of this exceptional planetary wave throughout the summer. Furthermore, NLC altitudes were determined via triangulation and colorimetry and were compared with MLS temperature profiles, enabling the determination of a mean positive phase lag for NLC occurrence relative to the temperature minimum."}
{"id": "2511.19452", "categories": ["eess.SY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.19452", "abs": "https://arxiv.org/abs/2511.19452", "authors": ["Yi Zhang", "Yushen Long", "Liping Huang", "Yicheng Zhang", "Sheng Zhang", "Yifang Yin"], "title": "A Data-Driven Model Predictive Control Framework for Multi-Aircraft TMA Routing Under Travel Time Uncertainty", "comment": "This is the complete 8-page version of accepted workshop paper for Artificial Intelligence for Air Transportation (AI4AT) @ AAAI 2026", "summary": "This paper presents a closed-loop framework for conflict-free routing and scheduling of multi-aircraft in Terminal Manoeuvring Areas (TMA), aimed at reducing congestion and enhancing landing efficiency. Leveraging data-driven arrival inputs (either historical or predicted), we formulate a mixed-integer optimization model for real-time control, incorporating an extended TMA network spanning a 50-nautical-mile radius around Changi Airport. The model enforces safety separation, speed adjustments, and holding time constraints while maximizing runway throughput. A rolling-horizon Model Predictive Control (MPC) strategy enables closed-loop integration with a traffic simulator, dynamically updating commands based on real-time system states and predictions. Computational efficiency is validated across diverse traffic scenarios, demonstrating a 7-fold reduction in computation time during peak congestion compared to onetime optimization, using Singapore ADS-B dataset. Monte Carlo simulations under travel time disturbances further confirm the framework's robustness. Results highlight the approach's operational resilience and computational scalability, offering actionable decision support for Air Traffic Controller Officers (ATCOs) through real-time optimization and adaptive replanning."}
{"id": "2511.20237", "categories": ["eess.SY", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20237", "abs": "https://arxiv.org/abs/2511.20237", "authors": ["Zeynab Kaseb", "Matthias Moller", "Lindsay Spoor", "Jerry J. Guo", "Yu Xiang", "Peter Palensky", "Pedro P. Vergara"], "title": "Quantum-Enhanced Reinforcement Learning for Accelerating Newton-Raphson Convergence with Ising Machines: A Case Study for Power Flow Analysis", "comment": "10 pages, 9 figures, 4 tables", "summary": "The Newton-Raphson (NR) method is widely used for solving power flow (PF) equations due to its quadratic convergence. However, its performance deteriorates under poor initialization or extreme operating scenarios, e.g., high levels of renewable energy penetration. Traditional NR initialization strategies often fail to address these challenges, resulting in slow convergence or even divergence. We propose the use of reinforcement learning (RL) to optimize the initialization of NR, and introduce a novel quantum-enhanced RL environment update mechanism to mitigate the significant computational cost of evaluating power system states over a combinatorially large action space at each RL timestep by formulating the voltage adjustment task as a quadratic unconstrained binary optimization problem. Specifically, quantum/digital annealers are integrated into the RL environment update to evaluate state transitions using a problem Hamiltonian designed for PF. Results demonstrate significant improvements in convergence speed, a reduction in NR iteration counts, and enhanced robustness under different operating conditions."}
{"id": "2511.19613", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19613", "abs": "https://arxiv.org/abs/2511.19613", "authors": ["Damian Rovara", "Lukas Burgholzer", "Robert Wille"], "title": "Quantum Hardware-Efficient Selection of Auxiliary Variables for QUBO Formulations", "comment": "7 pages, 8 figures, published at Design, Automation and Test in Europe Conference (DATE) 2026", "summary": "The Quantum Approximate Optimization Algorithm (QAOA) requires considered optimization problems to be translated into a compatible format. A popular transformation step in this pipeline involves the quadratization of higher-order binary optimization problems, translating them into Quadratic Unconstrained Binary Optimization (QUBO) formulations through the introduction of auxiliary variables. Conventional algorithms for the selection of auxiliary variables often aim to minimize the total number of required variables without taking the constraints of the underlying quantum computer-in particular, the connectivity of its qubits-into consideration. This quickly results in interaction graphs that are incompatible with the target device, resulting in a substantial compilation overhead even with highly optimized compilers. To address this issue, this work presents a novel approach for the selection of auxiliary variables tailored for architectures with limited connectivity. By specifically constructing an interaction graph with a regular structure and a limited maximal degree of vertices, we find a way to construct QAOA circuits that can be mapped efficiently to a variety of architectures. We show that, compared to circuits constructed from a QUBO formulation using conventional auxiliary selection methods, the proposed approach reduces the circuit depth by almost 40%. An implementation of all proposed methods is publicly available at https://github.com/munich-quantum-toolkit/problemsolver."}
{"id": "2511.20240", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.20240", "abs": "https://arxiv.org/abs/2511.20240", "authors": ["Chun Song", "Minfu Feng"], "title": "Enriched Galerkin Method for Navier-Stokes Equations", "comment": null, "summary": "This paper presents an enriched Galerkin (EG) finite element method for the incompressible Navier--Stokes equations. The method augments continuous piecewise linear velocity spaces with elementwise bubble functions, yielding a locally conservative velocity approximation while retaining the efficiency of low-order continuous elements. The viscous term is discretized using a symmetric interior penalty formulation, and the divergence constraint is imposed through a stable pressure space. To enhance the robustness of the velocity approximation with respect to the pressure, a reconstruction operator is introduced in the convective and coupling terms, resulting in a pressure-robust scheme whose accuracy does not deteriorate for small viscosities. Both Picard and Newton linearizations are formulated in a fully discrete manner, and the corresponding linear systems are assembled efficiently at each iteration. Optimal a~priori error estimates are established for the velocity in the mesh-dependent energy norm and for the pressure in the $L^2$ norm. Two representative numerical experiments are presented: a smooth manufactured solution and the lid-driven cavity flow. The numerical results confirm the theoretical convergence rates, demonstrating first-order convergence of the velocity in the energy norm, second-order convergence in the $L^2$ norm, and first-order convergence of the pressure. The proposed EG scheme accurately captures characteristic flow structures, illustrating its effectiveness and robustness for incompressible flow simulation."}
{"id": "2511.19766", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.19766", "abs": "https://arxiv.org/abs/2511.19766", "authors": ["Bixing Qiao"], "title": "Heterogeneous Mean Field Games and Local Well-posedness", "comment": null, "summary": "Motivated by the recent interests in asymmetric mean field games, this paper provides a general framework of Heterogeneous Mean Field Game (HMFG) that subsumes different formulations of graphon mean field games. The key feature of the HMFG is that the players interact with the population through the density ensemble. In this case, the HMFG system becomes an infinite-dimensional Forward-Backward SDE (FBSDE) system. We show that the FBSDE is locally well-posed, thus the HMFG has a unique equilibrium. In addition, we show that the equilibrium of HMFG is a good approximate equilibrium of the corresponding N-Player Game. Lastly, we derive the Itô formula of infinite-dimensional measure flow and use it to obtain the master equation for HMFG as a decoupling field of the infinite-dimensional FBSDE system."}
{"id": "2511.19879", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19879", "abs": "https://arxiv.org/abs/2511.19879", "authors": ["Jackson C. Glass", "Gia-Wei Chern"], "title": "Learning Degenerate Manifolds of Frustrated Magnets with Boltzmann Machines", "comment": "12 pages, 10 figures", "summary": "We show that Restricted Boltzmann Machines (RBMs) provide a flexible generative framework for modeling spin configurations in disordered yet strongly correlated phases of frustrated magnets. As a benchmark, we first demonstrate that an RBM can learn the zero-temperature ground-state manifold of the one-dimensional ANNNI model at its multiphase point, accurately reproducing its characteristic oscillatory and exponentially decaying correlations. We then apply RBMs to kagome spin ice and show that they successfully learn the local ice rules and short-range correlations of the extensively degenerate ice-I manifold. Correlation functions computed from RBM-generated configurations closely match those from direct Monte Carlo simulations. For the partially ordered ice-II phase -- featuring long-range charge order and broken time-reversal symmetry -- accurate modeling requires RBMs with uniform-sign bias fields, mirroring the underlying symmetry breaking. These results highlight the utility of RBMs as generative models for learning constrained and highly frustrated magnetic states."}
{"id": "2511.20191", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.20191", "abs": "https://arxiv.org/abs/2511.20191", "authors": ["Camilo Cárdenas-Hurtado", "Yunxiao Chen", "Irini Moustaki"], "title": "A Generalized Additive Partial-Mastery Cognitive Diagnosis Model", "comment": "28 pages, 5 figures. Includes online appendix", "summary": "Cognitive diagnosis models (CDMs) are restricted latent class models widely used for measuring attributes of interest in diagnostic assessments in education, psychology, biomedical sciences, and related fields. Partial-mastery CDMs (PM-CDMs) are an important extension of CDMs. They model individuals' status for each attribute to be continuous for measuring the partial mastery level, which relaxes the restrictive discrete-attribute assumption of classical CDMs. As a result, PM-CDMs often yield better fits for real-world data and refined measurement of the substantive attributes of interest. However, these models inherit some strong parametric assumptions from the traditional CDMs about the item response functions and, thus, still suffer from a significant risk of model misspecification. This paper proposes a generalized additive PM-CDM (GaPM-CDM) that substantially relaxes the parametric assumptions of PM-CDMs. This proposal leverages model parsimony and interpretability by modeling each item response function as a mixture of nonparametric monotone functions of attributes. A method for the estimation of GaPM-CDM is developed, which combines the marginal maximum likelihood estimator with a sieve approximation of the nonparametric functions. The new model is applicable under both confirmatory and exploratory settings, depending on whether prior knowledge is available about the relationship between observed variables and attributes. The proposed method is applied to two measurement problems from educational testing and healthcare research, respectively, and further evaluated and compared with PM-CDMs through extensive simulation studies."}
{"id": "2511.19597", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.19597", "abs": "https://arxiv.org/abs/2511.19597", "authors": ["Tsung-Cheng Lu", "Yu-Jie Liu", "Sarang Gopalakrishnan", "Yizhi You"], "title": "Holographic duality between bulk topological order and boundary mixed-state order", "comment": "27 pages, 19 figures", "summary": "We introduce a holographic framework for analyzing the steady states of repeated quantum channels with strong symmetries. Using channel-state duality, we show that the steady state of a $d$-dimensional quantum channel is holographically mapped to the boundary reduced density matrix of a $(d+1)$-dimensional wavefunction generated by a sequential unitary circuit. From this perspective, strong-to-weak spontaneous symmetry breaking (SWSSB) in the steady state arises from the anyon condensation on the boundary of a topological order in one higher dimension. The conditional mutual information (CMI) associated with SWSSB is then inherited from the bulk topological entanglement entropy. We make this duality explicit using isometric tensor network states (isoTNS) by identifying the channel's time evolution with the transfer matrix of a higher-dimensional isoTNS. Built on isoTNS, we further construct continuously tunable quantum channels that exhibit distinct mixed-state phases and transitions in the steady states."}
{"id": "2511.20092", "categories": ["physics.comp-ph", "physics.ao-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.20092", "abs": "https://arxiv.org/abs/2511.20092", "authors": ["Andreas Alexandris-Galanopoulos", "George Papadakis"], "title": "An ALE approach to reduce spurious numerical mixing through variational minimizers: application to internal waves", "comment": null, "summary": "Spurious numerical mixing is a frequent phenomenon in ocean models. In the present paper, we present an efficient and robust methodology that defines the vertical grid motion so that this mixing is reduced. This motion is defined through the solution of an optimization problem that -using the ideas of the calculus of variations- results in an elliptic equation. This framework is generally applicable to any ocean model that uses an ALE vertical coordinate and can be tuned to fit the modeler's specific needs based on the guidelines presented herein. The method is applied to the nonhydrostatic solver presented by the authors in [Alexandris-Galanopoulos et al., 2024] and its applicability in fully nonlinear internal waves is investigated for the demanding test cases of wave breaking and overturning. These numerical benchmarks show the ability of the method to reduce spurious mixing, while attaining the physical relevancy of the results."}
{"id": "2511.19454", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19454", "abs": "https://arxiv.org/abs/2511.19454", "authors": ["Xiubin Chen"], "title": "A K-means Inspired Solution Framework for Large-Scale Multi-Traveling Salesman Problems", "comment": null, "summary": "The Multi-Traveling Salesman Problem (MTSP) is a commonly used mathematical model for multi-agent task allocation. However, as the number of agents and task targets increases, existing optimization-based methods often incur prohibitive computational costs, posing significant challenges to large-scale coordination in unmanned systems. To address this issue, this paper proposes a K-means-inspired task allocation framework that reformulates the MTSP as a spatially constrained classification process. By leveraging spatial coherence, the proposed method enables fast estimation of path costs and efficient task grouping, thereby fundamentally reducing overall computational complexity. Extensive simulation results demonstrate that the framework can maintain high solution quality even in extremely large-scale scenarios-for instance, in tasks involving 1000 agents and 5000 targets. The findings indicate that this \"cluster-then-route\" decomposition strategy offers an efficient and reliable solution for large-scale multi-agent task allocation."}
{"id": "2511.20239", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20239", "abs": "https://arxiv.org/abs/2511.20239", "authors": ["Jan Krejčí", "Oliver Kost", "Yuxuan Xia", "Lennart Svensson", "Ondřej Straka"], "title": "Occlusion-Aware Multi-Object Tracking via Expected Probability of Detection", "comment": "Submitted to IEEE Transactions on Aerospace and Electronic Systems (TAES)", "summary": "This paper addresses multi-object systems, where objects may occlude one another relative to the sensor. The standard point-object model for detection-based sensors is enhanced so that the probability of detection considers the presence of all objects. A principled tracking method is derived, assigning each object an expected probability of detection, where the expectation is taken over the reduced Palm density, which means conditionally on the object's existence. The assigned probability thus considers the object's visibility relative to the sensor, under the presence of other objects. Unlike existing methods, the proposed method systematically accounts for uncertainties related to all objects in a clear and manageable way. The method is demonstrated through a visual tracking application using the multi-Bernoulli mixture (MBM) filter with marks."}
{"id": "2511.19631", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19631", "abs": "https://arxiv.org/abs/2511.19631", "authors": ["Emanuele Tumbiolo", "Lorenzo Maccone", "Chiara Macchiavello", "Matteo G. A. Paris", "Giacomo Guarnieri"], "title": "Shake before use: universal enhancement of quantum thermometry by unitary", "comment": "12 pages, 3 figures", "summary": "Quantum thermometry aims at determining temperature with ultimate precision in the quantum regime. Standard equilibrium approaches, limited by the Quantum Fisher Information given by static energy fluctuations, lose sensitivity outside a fixed temperature window. Non-equilibrium strategies have therefore been recently proposed to overcome these limits, but their advantages are typically model-dependent or tailored for a specific purpose. This Letter establishes a general, model-independent result showing that any temperature-dependent unitary driving applied to a thermalized probe enhances its quantum Fisher information with respect to its equilibrium value. Such information gain is expressed analytically through a positive semi-definite kernel of information currents that quantify the flow of statistical distinguishability. Our results are benchmarked on a driven spin-$1/2$ thermometer, furthermore showing that resonant modulations remarkably restore the quadratic-in-time scaling of the Fisher information and allow to shift the sensitivity peak across arbitrary temperature ranges. Our findings identify external unitary control as a universal resource for precision metrology and pave the way for future implementations in quantum sensing."}
{"id": "2511.20361", "categories": ["math.NA", "cs.LG", "math.AP"], "pdf": "https://arxiv.org/pdf/2511.20361", "abs": "https://arxiv.org/abs/2511.20361", "authors": ["Maarten V. de Hoop", "Nikola B. Kovachki", "Matti Lassas", "Nicholas H. Nelsen"], "title": "Extension and neural operator approximation of the electrical impedance tomography inverse map", "comment": "80 pages (49 main text, 20 appendix, and 11 references pages), 14 figures, 2 tables", "summary": "This paper considers the problem of noise-robust neural operator approximation for the solution map of Calderón's inverse conductivity problem. In this continuum model of electrical impedance tomography (EIT), the boundary measurements are realized as a noisy perturbation of the Neumann-to-Dirichlet map's integral kernel. The theoretical analysis proceeds by extending the domain of the inversion operator to a Hilbert space of kernel functions. The resulting extension shares the same stability properties as the original inverse map from kernels to conductivities, but is now amenable to neural operator approximation. Numerical experiments demonstrate that Fourier neural operators excel at reconstructing infinite-dimensional piecewise constant and lognormal conductivities in noisy setups both within and beyond the theory's assumptions. The methodology developed in this paper for EIT exemplifies a broader strategy for addressing nonlinear inverse problems with a noise-aware operator learning framework."}
{"id": "2511.19981", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.19981", "abs": "https://arxiv.org/abs/2511.19981", "authors": ["Senhan Yao", "Longxu Zhang"], "title": "On the Fundamental Limit of Stochastic Gradient Identification Algorithm Under Non-Persistent Excitation", "comment": null, "summary": "Stochastic gradient methods are of fundamental importance in system identification and machine learning, enabling online parameter estimation for large-scale and data-streaming processes. The stochastic gradient algorithm stands as a classical identification method that has been extensively studied for decades. Under non-persistent excitation, the best known convergence result requires the condition number of the Fisher information matrix to satisfy $κ(\\sum_{i=1}^n \\varphi_i \\varphi_i^\\top) = O((\\log r_n)^α)$, where $r_n = 1 + \\sum_{i=1}^n \\|\\varphi_i\\|^2$, with strong consistency guaranteed for $α\\leq 1/3$ but known to fail for $α> 1$. This paper establishes that strong consistency in fact holds for the entire range $0 \\leq α< 1$, achieved through a novel algebraic framework that yields substantially sharper matrix norm bounds. Our result nearly resolves the four-decade-old conjecture of Chen and Guo (1986), bridging the theoretical gap from $α\\leq 1/3$ to nearly the entire feasible range."}
{"id": "2511.20308", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.20308", "abs": "https://arxiv.org/abs/2511.20308", "authors": ["Marian Grendar"], "title": "Wilcoxon-Mann-Whitney Test of No Group Discrimination", "comment": "6 pages", "summary": "The traditional WMW null hypothesis $H_0: F = G$ is erroneously too broad. WMW actually tests narrower $H_0: AUC = 0.5$. Asymptotic distribution of the standardized $U$ statistic (i.e., the empirical AUC) under the correct $H_0$ is derived along with finite sample bias corrections. The traditional alternative hypothesis of stochastic dominance is too narrow. WMW is consistent against $H_1: AUC \\neq 0.5$, as established by Van Dantzig in 1951."}
{"id": "2511.19612", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.19612", "abs": "https://arxiv.org/abs/2511.19612", "authors": ["Ruihua Fan", "Yantao Wu", "Yimu Bao", "Zhehao Dai"], "title": "No-go theorems for sequential preparation of two-dimensional chiral states via channel-state correspondence", "comment": "19 pages + 6 pages appendices, 6 figures", "summary": "We investigate whether sequential unitary circuits can prepare two-dimensional chiral states, using a correspondence between sequentially prepared states, isometric tensor network states, and one-dimensional quantum channel circuits. We establish two no-go theorems, one for Gaussian fermion systems and one for generic interacting systems. In Gaussian fermion systems, the correspondence relates the defining features of chiral wave functions in their entanglement spectrum to the algebraic decaying correlations in the steady state of channel dynamics. We establish the no-go theorem by proving that local channel dynamics with translational invariance cannot support such correlations. As a direct implication, two-dimensional Gaussian fermion isometric tensor network states cannot support algebraically decaying correlations in all directions or represent a chiral state. In generic interacting systems, we establish a no-go theorem by showing that the state prepared by sequential circuits cannot host the tripartite entanglement of a chiral state due to the constraints from causality."}
{"id": "2511.19522", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19522", "abs": "https://arxiv.org/abs/2511.19522", "authors": ["Jinming Gao", "Yijing Wang", "Wentao Zhang", "Rui Zhao", "Yang Shi", "Zhiqiang Zuo"], "title": "Active Secure Neighbor Selection in Multi-Agent Systems with Byzantine Attacks", "comment": null, "summary": "This paper investigates the problem of resilient control for multi-agent systems in the presence of Byzantine adversaries via an active secure neighbor selection framework. A pre-discriminative graph is first constructed to characterize the admissible set of candidate neighbors for each agent. Based on this graph, a dynamic in-neighbor selection strategy is proposed, wherein each agent actively selects a subset of its pre-discriminative neighbors. The number of selected neighbors is adjustable, allowing for a trade-off between communication overhead and robustness, with the minimal case requiring only a single in-neighbor. The proposed strategy facilitates the reconstruction of a directed spanning tree among normal agents following the detection and isolation of Byzantine agents. It achieves resilient consensus without imposing any assumptions on the initial connectivity among normal agents. Moreover, the approach significantly reduces communication burden while maintaining resilience to adversarial behavior. A numerical example is provided to illustrate the effectiveness of the proposed method."}
{"id": "2511.20276", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20276", "abs": "https://arxiv.org/abs/2511.20276", "authors": ["Lianzhe Hu", "Yu Wang", "Bikash Pal"], "title": "LLM-Driven Transient Stability Assessment: From Automated Simulation to Neural Architecture Design", "comment": null, "summary": "This paper presents an LLM-driven, end-to-end workflow that addresses the lack of automation and intelligence in power system transient stability assessment (TSA). The proposed agentic framework integrates large language models (LLMs) with a professional simulator (ANDES) to automatically generate and filter disturbance scenarios from natural language, and employs an LLM-driven Neural Network Design (LLM-NND) pipeline to autonomously design and optimize TSA models through performance-guided, closed-loop feedback. On the IEEE 39-bus system, the LLM-NND models achieve 93.71% test accuracy on four-class TSA with only 4.78M parameters, while maintaining real-time inference latency (less than 0.95 ms per sample). Compared with a manually designed DenseNet (25.9M parameters, 80.05% accuracy), the proposed approach jointly improves accuracy and efficiency. Ablation studies confirm that the synergy among domain-grounded retrieval, reasoning augmentation, and feedback mechanisms is essential for robust automation. The results demonstrate that LLM agents can reliably accelerate TSA research from scenario generation and data acquisition to model design and interpretation, offering a scalable paradigm that is readily extensible to other power system tasks such as optimal power flow, fault analysis, and market operations."}
{"id": "2511.19659", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19659", "abs": "https://arxiv.org/abs/2511.19659", "authors": ["Peter Brearley", "Philipp Pfeffer"], "title": "High-Order Splitting of Non-Unitary Operators on Quantum Computers", "comment": null, "summary": "We present a high-order splitting method for simulating non-unitary dynamics by sequential real- and imaginary-time Hamiltonian evolutions. Complex-coefficient splitting methods with positive real parts are chosen for stable integration in a quantum circuit, avoiding the unstable, norm-amplifying negative steps that arise from real-coefficient splitting at high orders. The method is most beneficial for dynamics that naturally separate into unitary and dissipative components, with broad applications across science and engineering. These systems frequently admit compact spectral representations of the split operators, which we demonstrate by deriving efficient quantum circuits for simulating the damped-wave equation with up to sixth-order accuracy in time. A single sixth-order step in three dimensions on 35 trillion cells requires 1,562 CNOT gates, which can be executed within the coherence time of modern quantum processors."}
{"id": "2511.20432", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.20432", "abs": "https://arxiv.org/abs/2511.20432", "authors": ["Yang Yang", "Ye Ji", "Matthias Möller", "Can Ayas"], "title": "Efficient thermal simulation in metal additive manufacturing via semi-analytical isogeometric analysis", "comment": "39 pages, 17 figures", "summary": "Thermal modeling of Laser Powder Bed Fusion (LPBF) is challenging due to steep, rapidly moving thermal gradients induced by the laser, which are difficult to resolve accurately with conventional Finite Element Methods. Highly refined, dynamically adaptive spatial discretization is typically required, leading to prohibitive computational costs. Semi-analytical approaches mitigate this by decomposing the temperature field into an analytical point-source solution and a complementary numerical field that enforces boundary conditions. However, state-of-the-art implementations either necessitate extensive mesh refinement near boundaries or rely on restrictive image source techniques, limiting their efficiency and applicability to complex geometries. This study presents a novel reformulation of the semi-analytical framework using Isogeometric Analysis. The laser heat input is captured by the analytical point-source solution, while the complementary correction field, which imposes boundary conditions, is solved using a spline-based IGA discretization. The governing heat equation for the correction field is cast in a weak form, discretized with NURBS basis functions, and advanced in time using an implicit $θ$-scheme. This approach leverages IGA's key advantages: exact geometry representation, higher-order continuity, and superior accuracy per degree of freedom. These features unlock efficient thermal modeling of realistic parts with complex contours. Our strategy eliminates the need for scan-wise remeshing and robustly handles intricate geometric features like sharp corners and varying cross-sections. Numerical examples demonstrate that the proposed semi-analytical IGA method delivers accurate temperature predictions and achieves substantial computational efficiency gains compared to standard FEM, establishing it as a powerful new tool for high-fidelity thermal simulation in LPBF."}
{"id": "2511.20029", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.20029", "abs": "https://arxiv.org/abs/2511.20029", "authors": ["I. Baragaña", "F. Puerta", "I. Zaballa"], "title": "A Local Parametrization of the State-Feedback Matrices in the Pole Assignment Problem", "comment": "43 pages, submitted to IET Control Theory and Applications", "summary": "Given a controllable system $(F,G)$, a local parametrization is obtained for the set of feedback gain matrices $K$ such that the state matrix, $F+GK$, of the closed loop system is in a prescribed similarity class. It is shown that this set can be endowed with the structure of a differentiable manifold whose dimension is also computed. Then a local parametrization and a local system of coordinates is provided using a diffeomorphism between this set of state feedback matrices and the orbit space of a set of truncated observability matrices via de action of a Lie group."}
{"id": "2511.20318", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.20318", "abs": "https://arxiv.org/abs/2511.20318", "authors": ["Shanshan Luo", "Peng Wu", "Zhi Geng"], "title": "Pseudo-strata learning via maximizing misclassification reward", "comment": null, "summary": "Online advertising aims to increase user engagement and maximize revenue, but users respond heterogeneously to ad exposure. Some users purchase only when exposed to ads, while others purchase regardless of exposure, and still others never purchase. This heterogeneity can be characterized by latent response types, commonly referred to as principal strata, defined by users' joint potential outcomes under exposure and non-exposure. However, users' true strata are unobserved, making direct analysis infeasible. In this article, instead of learning the true strata, we propose a novel approach that learns users' pseudo-strata by leveraging information from an outcome (revenue) observed after the response (purchase). We construct pseudo-strata to classify users and introduce misclassification rewards to quantify the expected revenue gain of pseudo-strata-based policies relative to true strata. Within a Bayesian classification framework, we learn the pseudo-strata by optimizing the expected revenue. To implement these procedures, we introduce identification assumptions and estimation methods, and establish their large-sample properties. Simulation studies show that the proposed method achieves more accurate strata classification and substantially higher revenue than baselines. We further illustrate the method using a large-scale industrial dataset from the Criteo Predictive Search Platform."}
{"id": "2511.20388", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.20388", "abs": "https://arxiv.org/abs/2511.20388", "authors": ["Joseph Vovrosh", "Tiago Mendes-Santos", "Hadriel Mamann", "Kemal Bidzhiev", "Fergus Hayes", "Bruno Ximenez", "Lucas Béguin", "Constantin Dalyac", "Alexandre Dauphin"], "title": "Resource assessment of classical and quantum hardware for post-quench dynamics", "comment": "10 (+5) pages, 6 (+3) figures", "summary": "We estimate the run-time and energy consumption of simulating non-equilibrium dynamics on neutral atom quantum computers in analog mode, directly comparing their performance to state-of-the-art classical methods, namely Matrix Product States and Neural Quantum States. By collecting both experimental data from a quantum processing unit (QPU) in analog mode and numerical benchmarks, we enable accurate predictions of run-time and energy consumption for large-scale simulations on both QPUs and classical systems through fitting of theoretical scaling laws. Our analysis shows that neutral atom devices are already operating in a competitive regime, achieving comparable or superior performance to classical approaches while consuming significantly less energy. These results demonstrate the potential of analog neutral atom quantum computing for energy-efficient simulation and highlight a viable path toward sustainable computational strategies."}
{"id": "2511.19683", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19683", "abs": "https://arxiv.org/abs/2511.19683", "authors": ["Eugene Lavretsky"], "title": "State Feedback Controllers with Operational Constraints", "comment": "33 pages, 13 figures. These are the original detailed design notes where my recent CBF-related papers came from", "summary": "In this paper, a state feedback control design with min/max operational limiting constraints is developed for multi-input-multi-output linear time invariant systems. Specifically, servo-tracking control problems with input and output constraints are considered. For static servo-controllers, the output design limits are imposed component-wise on the system selected output, which is of the same dimension as the control input. For dynamic servo-controllers, operational constraints are applied to the system inputs and outputs. The proposed control solution also includes an anti-windup protection logic for dynamic servo-controllers with integral action. The developed method is based on the Nagumo Theorem for forward invariance, the Comparison Lemma for inclusion of input/output inequality constraints, and on the min-norm optimal controllers for synthesis. The derived design is similar and directly related to the method of Control Barrier Functions. Simulation trade studies are presented to illustrate benefits of the proposed control methodology for aerial flight critical systems."}
{"id": "2511.20294", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20294", "abs": "https://arxiv.org/abs/2511.20294", "authors": ["Dnyandeep Mandaokar", "Bernhard Rinner"], "title": "SAFE-IMM: Robust and Lightweight Radar-Based Object Tracking on Mobile Platforms", "comment": null, "summary": "Tracking maneuvering targets requires estimators that are both responsive and robust. Interacting Multiple Model (IMM) filters are a standard tracking approach, but fusing models via Gaussian mixtures can lag during maneuvers. Recent winnertakes-all (WTA) approaches react quickly but may produce discontinuities. We propose SAFE-IMM, a lightweight IMM variant for tracking on mobile and resource-limited platforms with a safe covariance-aware gate that permits WTA only when the implied jump from the mixture to the winner is provably bounded. In simulations and on nuScenes front-radar data, SAFE-IMM achieves high accuracy at real-time rates, reducing ID switches while maintaining competitive performance. The method is simple to integrate, numerically stable, and clutter-robust, offering a practical balance between responsiveness and smoothness."}
{"id": "2511.19662", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19662", "abs": "https://arxiv.org/abs/2511.19662", "authors": ["Eric R. Bittner"], "title": "Entropy Flow and Exceptional-Point Structure in Two-Mode Squeezed-Bath Dynamics", "comment": "12 pages, 5 figures. Comments welcome", "summary": "Squeezed reservoirs provide a powerful means of engineering nonclassical noise and controlling irreversible dynamics in open quantum systems. Here we develop a comprehensive analysis of two coupled harmonic oscillators driven by independent squeezed baths, focusing on the emergence of coherence-driven entropy flow and the structure of exceptional points (EPs) in the corresponding Lindblad dynamics. Working entirely within the Gaussian formalism, we derive closed-form evolution equations for the covariance matrix and show that squeezing induces entropy generation only at *second order* in the anomalous correlations, a nonlinear mechanism absent in thermal environments. This entropy flow is accompanied by a rich non-Hermitian structure: by scanning the squeezing parameters we uncover a characteristic \"exceptional-point fan\" in the (M1, M2) plane, which separates a narrow PT-unbroken region of oscillatory dynamics from broad PT-broken sectors in which one normal mode becomes purely overdamped. This geometric organization of EPs reveals that PT symmetry survives only when the two reservoirs squeeze opposite quadratures, and is generically broken for in-phase squeezing. Our analysis establishes squeezed reservoirs as a natural setting where information-bearing noise drives irreversible behavior through coherent pathways, and lays the groundwork for experimentally accessible probes of entropy flow and critical mode behavior in more complex open systems."}
{"id": "2511.20529", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.20529", "abs": "https://arxiv.org/abs/2511.20529", "authors": ["Daniel Bach", "Andrés M. Rueda-Ramírez", "Eric Sonnendrücker", "David C. Del Rey Fernández", "Gregor J. Gassner"], "title": "SBP-FDEC: Summation-by-Parts Finite Difference Exterior Calculus", "comment": "38 pages, 21 figures", "summary": "We demonstrate that we can carry over the strategy of Finite Element Exterior Calculus (FEEC) to Summation-by-Parts (SBP) Finite Difference (FD) methods to achieve divergence- and curl-free discretizations. This is not obvious at first sight, as for SBP-FD no basis functions are known, but only values and derivatives at points. The key is a remarkable analytic relationship that enables us to construct compatible operators using integral and nodal degrees of free- dom. Pre-existing SBP-FD matrix operators can then be used to obtain nodal values from the integral degrees of freedom to derive a scheme with the desired properties."}
{"id": "2511.20037", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.20037", "abs": "https://arxiv.org/abs/2511.20037", "authors": ["Guillaume O. Berger"], "title": "On the differentiability of the value function of switched linear systems under arbitrary and controlled switching", "comment": null, "summary": "This paper studies the differentiability of the value function of switched linear systems under arbitrary switching and controlled switching, referred to as worst-case and optimal value functions respectively. First, we show that the value functions are Lipschitz continuous, when the cost function is Lipschitz continuous. Then, as the central contribution of this work, we show with examples that each of these functions can be non-differentiable on dense subsets of the state space, even if the cost function is smooth and Lipschitz continuous. This has implications for optimal control and reinforcement learning since it implies that the exact computation of these value functions requires templates involving functions that are non-differentiable on dense subsets."}
{"id": "2511.20412", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.20412", "abs": "https://arxiv.org/abs/2511.20412", "authors": ["Neng Wang", "Eric V. Slud", "Tianzhou Ma"], "title": "A novel multi-exposure-to-multi-mediator mediation model for imaging genetic study of brain disorders", "comment": null, "summary": "Common psychiatric and brain disorders are highly heritable and affected by a number of genetic risk factors, yet the mechanism by which these genetic factors contribute to the disorders through alterations in brain structure and function remain poorly understood. Contemporary imaging genetic studies integrate genetic and neuroimaging data to investigate how genetic variation contributes to brain disorders via intermediate neuroimaging endophenotypes. However, the large number of potential exposures (genes) and mediators (neuroimaging features) pose new challenges to the traditional mediation analysis. In this paper, we propose a novel multi-exposure-to-multi-mediator mediation model that integrates genetic, neuroimaging and phenotypic data to investigate the \"geneneuroimaging-brain disorder\" mediation pathway. Our method jointly reduces the dimensions of exposures and mediators into low-dimensional aggregators where the mediation effect is maximized. We further introduce sparsity into the loadings to improve the interpretability. To target the bi-convex optimization problem, we implement an efficient alternating direction method of multipliers algorithm with block coordinate updates. We provide theoretical guarantees for the convergence of our algorithm and establish the asymptotic properties of the resulting estimators. Through extensive simulations, we demonstrate that our method outperforms other competing methods in recovering true loadings and true mediation proportions across a wide range of signal strengths, noise levels, and correlation structures. We further illustrate the utility of the method through a mediation analysis that integrates genetic, brain functional connectivity and smoking behavior data from UK Biobank, and identifies critical genes that impact nicotine dependence via changing the functional connectivity in specific brain regions."}
{"id": "2511.19715", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19715", "abs": "https://arxiv.org/abs/2511.19715", "authors": ["Theodor Hagström", "Lars Herre"], "title": "Understanding Risk and Revenue in the Nordic 15-minute mFRR market: An EV Aggregation Study", "comment": null, "summary": "Decarbonisation, decentralisation, and intermittency are driving the development of flexibility markets towards shorter market time units (MTU). Shorter MTUs and shorter gate closures lower the entrance barriers of demand side aggregators that face significant uncertainty on longer time scales. We study the business case for aggregated EV fleets participating in the Nordic 15-minute mFRR Energy Activation Market (EAM). Motivated by increasing system granularity and rapid EV uptake, we represent fleet flexibility as a virtual battery with time-varying power and energy envelopes and formulate a risk-aware stochastic optimisation that co-ordinates day-ahead scheduling with quarter-hour mFRR bidding. Using synthetic residential charging cohorts and observed day-ahead prices on two stylised days, we compare an independent day-ahead baseline to a co-optimised strategy under conservative availability and a CVaR-augmented objective. Across both price cases, co-optimisation increases expected profit and lowers downside risk: the model buys less energy day-ahead and shifts procurement toward mFRR down while flattening the charging plan to retain eligibility for mFRR up. Profit decomposition shows that the uplift is driven by higher mFRR down revenues and reduced reliance on unwinding day-ahead positions. We discuss operational implications for bidding and outline two extensions: rolling 45-minute re-optimisation and a V2G framework."}
{"id": "2511.20383", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20383", "abs": "https://arxiv.org/abs/2511.20383", "authors": ["Viet-Anh Le", "Andreas A. Malikopoulos"], "title": "Accelerating Time-Optimal Trajectory Planning for Connected and Automated Vehicles with Graph Neural Networks", "comment": "submitted to IFAC WC 2026", "summary": "In this paper, we present a learning-based framework that accelerates time- and energy-optimal trajectory planning for connected and automated vehicles (CAVs) using graph neural networks (GNNs). We formulate the multi-agent coordination problem encountered in traffic scenarios as a cooperative trajectory planning problem that minimizes travel time, subject to motion primitives derived from energy-optimal solutions. The effectiveness of this framework can be further improved through replanning at each time step, enabling the system to incorporate newly observed information. To achieve real-time execution of such a multi-agent replanning scheme, we employ a GNN architecture to learn the solutions of the time-optimal trajectory planning problem from offline-generated data. The trained model produces online predictions that serve as warm-start solutions for numerical optimization, thereby enabling rapid computation of minimal exit times and the associated feasible trajectories. This learning-augmented approach substantially reduces computation time while ensuring that all state, input, and safety constraints are satisfied."}
{"id": "2511.19668", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.19668", "abs": "https://arxiv.org/abs/2511.19668", "authors": ["Henry C. Hammer", "Hassan A. Bukhari", "Yogendra Limdu", "Brett M. Wasick", "Christopher Rouleau", "Michael E. Flatté", "Durga Paudyal", "Denis R. Candido", "Ravitej Uppu"], "title": "Quantum Coherence of Rare-Earth Ions in Heterogeneous Photonic Interfaces", "comment": "19 pages, 5 figures", "summary": "Harnessing rare-earth ions in oxides for quantum networks requires integration with bright emitters in III-V semiconductors, but local disorder and interfacial noise limit their optical coherence. Here, we investigate the microscopic origins of the ensemble spectrum in Er$^{3+}$:TiO$_2$ epitaxial thin films on GaAs and GaSb substrates. Ab initio calculations combined with noise-Hamiltonian modeling and Monte Carlo simulations quantify the effects of interfacial and bulk spin noise and local strain on erbium crystal-field energies and inhomogeneous linewidths. Photoluminescence excitation spectroscopy reveals that Er$^{3+}$ ions positioned at increasing distances from the III-V/oxide interface produce a systematic blue shift of the $Y_1\\rightarrow Z_1$ transition, consistent with strain relaxation predicted by theory. Thermal annealing produces a compensating redshift and linewidth narrowing, isolating the roles of oxygen-vacancy and gallium-diffusion noise. These results provide microscopic insight into disorder-driven decoherence, offering pathways for precise control of hybrid quantum systems for scalable quantum technologies."}
{"id": "2511.20126", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.20126", "abs": "https://arxiv.org/abs/2511.20126", "authors": ["Max Nendel", "Ariel Neufeld", "Kyunghyun Park", "Alessandro Sgarabottolo"], "title": "Scaling limits of multi-period distributionally robust optimization problems", "comment": null, "summary": "We examine the scaling limit of multi-period distributionally robust optimization (DRO) problems via a semigroup approach. Each period involves a worst-case maximization over distributions in a Wasserstein ball around the transition probability of a reference process with radius proportional to the length of the period, and the multi-period DRO problem arises through its sequential composition. We show that the scaling limit of the multi-period DRO, as the length of each period tends to zero, is a strongly continuous monotone semigroup on $\\mathrm{C_b}$. Furthermore, we show that its infinitesimal generator is equal to the generator associated with the non-robust scaling limit plus an additional perturbation term induced by the Wasserstein uncertainty. As an application, we show that when the reference process follows an Itô process, the viscosity solution of the associated nonlinear PDE coincides with the value of continuous-time robust optimization problems under parametric uncertainty."}
{"id": "2511.20466", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.20466", "abs": "https://arxiv.org/abs/2511.20466", "authors": ["Alexis Boulin", "Erik Haufs"], "title": "Extrapolating into the Extremes with Minimum Distance Estimation", "comment": null, "summary": "Understanding complex dependencies and extrapolating beyond observations are key challenges in modeling environmental space-time extremes. To address this, we introduce a simplifying approach that projects a wide range of multivariate exceedance problems onto a univariate peaks-over-threshold problem. In this framework, an estimator is computed by minimizing the $L_2$-distance between the empirical distribution function of the data and the theoretical distribution of the model. Asymptotic properties of this estimator are derived and validated in a simulation study. We evaluated our estimator in the EVA (2025) conference Data Challenge as part of Team Bochum's submission. The challenge provided precipitation data from four runs of LENS2, an ensemble of long-term weather simulations, on a $5 \\times 5$ grid of locations centered at the grid point closest to Asheville, NC. Our estimator achieved a top-three rank in two of six competitive categories and won the overall preliminary challenge against ten competing teams."}
{"id": "2511.19770", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19770", "abs": "https://arxiv.org/abs/2511.19770", "authors": ["Peter Iwer Hoedt Karstensen", "Roberto Galeazzi"], "title": "Multi-Hypotheses Ego-Tracking for Resilient Navigation", "comment": null, "summary": "Autonomous robots relying on radio frequency (RF)-based localization such as global navigation satellite system (GNSS), ultra-wide band (UWB), and 5G integrated sensing and communication (ISAC) are vul- nerable to spoofing and sensor manipulation. This paper presents a resilient navigation architecture that combines multi-hypothesis estimation with a Poisson binomial windowed-count detector for anomaly identi- fication and isolation. A state machine coordinates transitions between operation, diagnosis, and mitigation, enabling adaptive response to adversarial conditions. When attacks are detected, trajectory re-planning based on differential flatness allows information-gathering maneuvers minimizing performance loss. Case studies demonstrate effective detection of biased sensors, maintenance of state estimation, and recovery of nominal operation under persistent spoofing attacks"}
{"id": "2511.20443", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20443", "abs": "https://arxiv.org/abs/2511.20443", "authors": ["Amy K. Strong", "Samuel Akinwande", "Leila Bridgeman"], "title": "Adaptive Meshing for CPA Lyapunov Function Synthesis", "comment": null, "summary": "Continuous piecewise affine (CPA) Lyapunov function synthesis is one method to perform Lyapunov stability analysis for nonlinear systems. This method first generates a mesh over the region of interest in the system's state space and then solves a linear program (LP), which enforces constraints on each vertex of the mesh, to synthesize a Lyapunov function. Finer meshes broaden the class of Lyapunov function candidates, but CPA function synthesis is more computationally expensive for finer meshes -- particularly so in higher dimensional systems. This paper explores methods to mesh the region of interest more efficiently so that a Lyapunov function can be synthesized using less computational effort. Three methods are explored -- adaptive meshing, meshing using knowledge of the system model, and a combination of the two. Numerical examples for two and three dimensional nonlinear dynamical systems are used to compare the efficacy of the three methods."}
{"id": "2511.19687", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2511.19687", "abs": "https://arxiv.org/abs/2511.19687", "authors": ["Zhenlin Wu", "Tim Duka", "Mariano Isaza-Monsalve", "Miriam Kautzky", "Vojtěch Švarc", "Andrea Turci", "René Nardi", "Marcin Gronowski", "Michał Tomza", "Brandon J. Furey", "Philipp Schindler"], "title": "Infrared absorption spectroscopy of a single polyatomic molecular ion", "comment": null, "summary": "Absorption spectroscopy is a fundamental tool for probing molecular structure. However, performing absorption spectroscopy on individual molecules is challenging due to the low signal-to-noise ratio. Here, we report on a nondestructive absorption spectroscopy on a mid-infrared vibrational transition in a single molecular ion that is co-trapped with an atomic ion. The absorption of a single photon is detected via the momentum transfer from the absorbed photon onto the molecule. This recoil signal is amplified using a non-classical state of motion of the two-ion crystal and subsequently read out via the atomic ion. We characterize the recoil detection method and use it to investigate the interaction between femtosecond laser pulses and the O-H stretching vibration in individual CaOH+ molecular ions. Furthermore, we present the single-photon absorption spectrum obtained for the vibrational transition. This method represents a milestone towards quantum non-demolition measurements of complex polyatomic molecules, providing high-fidelity methods for preparation and measurement of the quantum state of a wide range of molecular species."}
{"id": "2511.20178", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.20178", "abs": "https://arxiv.org/abs/2511.20178", "authors": ["Panchajanya Sanyal", "Srujan Teja Thomdapu", "Ketan Rajawat"], "title": "Stochastic Sequential Quadratic Programming for Optimization with Functional Constraints", "comment": "17 pages, 4 figures. Submitted to IEEE Transactions on Signal Processing", "summary": "Stochastic convex optimization problems with nonlinear functional constraints are ubiquitous in machine learning applications, including multi-task learning, structured prediction, and multi-view learning. The presence of nonlinear functional constraints renders the traditional projected stochastic gradient descent and related projection-based methods inefficient, and motivates the use of first-order methods. However, existing first-order methods, including primal and primal-dual algorithms, typically rely on a bounded (sub-)gradient assumption, which may be too restrictive in many settings.\n  We propose a stochastic sequential quadratic programming (SSQP) algorithm that works entirely in the primal domain, avoids projecting onto the feasible region, obviates the need for bounded gradients, and achieves state-of-the-art oracle complexity under standard smoothness and convexity assumptions. A faster version, namely SSQP-Skip, is also proposed where the quadratic subproblems can be skipped in most iterations. Finally, we develop an accelerated variance-reduced version of SSQP (VARAS), whose oracle complexity bounds match those for solving unconstrained finite-sum convex optimization problems. The superior performance of the proposed algorithms is demonstrated via numerical experiments on real datasets."}
{"id": "2511.19905", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.19905", "abs": "https://arxiv.org/abs/2511.19905", "authors": ["Fangyi Chen", "Shu Ge", "Jian Qian", "Christopher Harshaw"], "title": "Sigmoid-FTRL: Design-Based Adaptive Neyman Allocation for AIPW Estimators", "comment": null, "summary": "We consider the problem of Adaptive Neyman Allocation for the class of AIPW estimators in a design-based setting, where potential outcomes and covariates are deterministic. As each subject arrives, an adaptive procedure must select both a treatment assignment probability and a linear predictor to be used in the AIPW estimator. Our goal is to construct an adaptive procedure that minimizes the Neyman Regret, which is the difference between the variance of the adaptive procedure and an oracle variance which uses the optimal non-adaptive choice of assignment probability and linear predictors. While previous work has drawn insightful connections between Neyman Regret and online convex optimization for the Horvitz--Thompson estimator, one of the central challenges for AIPW estimator is that the underlying optimization is non-convex. In this paper, we propose Sigmoid-FTRL, an adaptive experimental design which addresses the non-convexity via simultaneous minimization of two convex regrets. We prove that under standard regularity conditions, the Neyman Regret of Sigmoid-FTRL converges at a $T^{-1/2} R^2$ rate, where $T$ is the number of subjects in the experiment and $R$ is the maximum norm of covariate vectors. Moreover, we show that no adaptive design can improve upon the $T^{-1/2}$ rate under our regularity conditions. Finally, we establish a central limit theorem and a consistently conservative variance estimator which facilitate the construction of asymptotically valid Wald-type confidence intervals."}
{"id": "2511.19884", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19884", "abs": "https://arxiv.org/abs/2511.19884", "authors": ["Mobina Nankali", "Michael W. Levin"], "title": "An Exact Solution Algorithm for the Bi-Level Optimization Problem of Electric Vehicles Charging Station Placement", "comment": null, "summary": "This work addresses electric vehicle (EV) charging station placement through a bi-level optimization model, where the upper-level planner maximizes net revenue by selecting station locations under budget constraints, while EV users at the lower level choose routes and charging stations to minimize travel and charging costs. To account for range anxiety, we construct a battery-expanded network and apply a shortest path algorithm with Frank-Wolfe traffic assignment. Our primary contribution is developing the first exact solution algorithm for large scale EV charging station placement problems. We propose a Branch-and-Price-and-Cut algorithm enhanced with value function cuts and column generation. While existing research relies on heuristic methods that provide no optimality guarantees or exact algorithms that require prohibitively long runtimes, our exact algorithm delivers globally optimal solutions with mathematical certainty under a reasonable runtime. Computational experiments on the Eastern Massachusetts network (74 nodes, 248 links), the Anaheim network (416 nodes, 914 links), and the Barcelona network (110 zones, 1,020 nodes, and 2,512 links) demonstrate exceptional performance. Our algorithm terminates within minutes rather than hours, while achieving optimality gaps below 1% across all instances. This result represents a computational speedup of over two orders of magnitude compared to existing methods. The algorithm successfully handles problems with over 300,000 feasible combinations, which transform EV charging infrastructure planning from a computationally prohibitive problem into a tractable optimization task suitable for practical decision making problem for real world networks."}
{"id": "2511.20463", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20463", "abs": "https://arxiv.org/abs/2511.20463", "authors": ["Amy K. Strong", "Ali Kashani", "Claus Danielson", "Leila Bridgeman"], "title": "Learning Control Barrier Functions with Deterministic Safety Guarantees", "comment": null, "summary": "Barrier functions (BFs) characterize safe sets of dynamical systems, where hard constraints are never violated as the system evolves over time. Computing a valid safe set and BF for a nonlinear (and potentially unmodeled), non-autonomous dynamical system is a difficult task. This work explores the design of BFs using data to obtain safe sets with deterministic assurances of control invariance. We leverage ReLU neural networks (NNs) to create continuous piecewise affine (CPA) BFs with deterministic safety guarantees for Lipschitz continuous, discrete-time dynamical system using sampled one-step trajectories. The CPA structure admits a novel classifier term to create a relaxed \\ac{bf} condition and construction via a data driven constrained optimization. We use iterative convex overbounding (ICO) to solve this nonconvex optimization problem through a series of convex optimization steps. We then demonstrate our method's efficacy on two-dimensional autonomous and non-autonomous dynamical systems."}
{"id": "2511.19697", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19697", "abs": "https://arxiv.org/abs/2511.19697", "authors": ["Amir Hossein Houshmand Almani", "Ali Mortezapour", "Alireza Nourmandipour"], "title": "Synergistic Effects of Detuning and Auxiliary Qubits on Quantum Synchronization", "comment": "10 pages, 7 figures", "summary": "We investigate how detuning and auxiliary qubits collaboratively enhance quantum synchronization in a dissipative multi-qubit system that is coupled to a structured reservoir. Our findings indicate that while detuning is ineffective in Markovian environments, it emerges as a powerful control parameter in the non-Markovian regime, where environmental memory facilitates long-lived phase coherence. It is shown that adding more auxiliary qubits amplifies this effect by strengthening the collective coupling and enhancing memory, resulting in robust phase locking within the system. Analysis using the Husimi Q-function, synchronization measures, and Arnold tongue structures reveals a detuning-induced enhancement of phase locking, which significantly improves stability compared to the resonance case. These results establish a cooperative control strategy where detuning actively engineers phases, while auxiliary qubits provide the necessary memory for sustained synchronization."}
{"id": "2511.20207", "categories": ["math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20207", "abs": "https://arxiv.org/abs/2511.20207", "authors": ["Haotian Wu"], "title": "Adaptive SGD with Line-Search and Polyak Stepsizes: Nonconvex Convergence and Accelerated Rates", "comment": null, "summary": "We extend the convergence analysis of AdaSLS and AdaSPS in [Jiang and Stich, 2024] to the nonconvex setting, presenting a unified convergence analysis of stochastic gradient descent with adaptive Armijo line-search (AdaSLS) and Polyak stepsize (AdaSPS) for nonconvex optimization. Our contributions include: (1) an $\\mathcal{O}(1/\\sqrt{T})$ convergence rate for general nonconvex smooth functions, (2) an $\\mathcal{O}(1/T)$ rate under quasar-convexity and interpolation, and (3) an $\\mathcal{O}(1/T)$ rate under the strong growth condition for general nonconvex functions."}
{"id": "2511.20061", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.20061", "abs": "https://arxiv.org/abs/2511.20061", "authors": ["Sampurna Kundu", "Jayant Jha", "Subir Kumar Bhandari"], "title": "An Efficient Adaptive Sequential Procedure for Simple Hypotheses with Expression for Finite Number of Applications of Less Effective Treatment", "comment": null, "summary": "We propose an adaptive sequential framework for testing two simple hypotheses that analytically ensures finite exposure to the less effective treatment. Our proposed procedure employs a likelihood ratio-driven adaptive allocation rule, dynamically concentrating sampling effort on the superior population while preserving asymptotic efficiency (in terms of average sample number) comparable to the Sequential Probability Ratio Test (SPRT). The foremost contribution of this work is the derivation of an explicit closed-form expression for the expected number of applications to the inferior treatment. This approach achieves a balanced method between statistical precision and ethical responsibility, aligning inferential reliability with patient safety. Extensive simulation studies substantiate the theoretical results, confirming stability in allocation and consistently high probability of correct selection (PCS) across different settings. In addition, we demonstrate how the adaptive procedure markedly reduces inferior allocations compared with the classical SPRT, highlighting its practical advantage in ethically sensitive sequential testing scenarios. The proposed design thus offers an ethically efficient and computationally tractable framework for adaptive sequential decision-making."}
{"id": "2511.19961", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19961", "abs": "https://arxiv.org/abs/2511.19961", "authors": ["Zhenyu Tao", "Wei Xu", "Xiaohu You"], "title": "Toward Trustworthy Digital Twins in Agentic AI-based Wireless Network Optimization: Challenges, Solutions, and Opportunities", "comment": null, "summary": "Optimizing modern wireless networks is exceptionally challenging due to their high dynamism and complexity. While the agentic artificial intelligence (AI) powered by reinforcement learning (RL) offers a promising solution, its practical application is limited by prohibitive exploration costs and potential risks in the real world. The emerging digital twin (DT) technology provides a safe and controlled virtual environment for agentic AI training, but its effectiveness critically depends on the DT's fidelity. Policies trained in a low-fidelity DT that does not accurately represent the physical network may experience severe performance degradation upon real-world deployment. In this article, we introduce a unified DT evaluation framework to ensure trustworthy DTs in agentic AI-based network optimization. This evaluation framework shifts from conventional isolated physical accuracy metrics, such as wireless channel and user trajectory similarities, to a more holistic, task-centric DT assessment. We demonstrate it as an effective guideline for design, selection, and lifecycle management of wireless network DTs. A comprehensive case study on a real-world wireless network testbed shows how this evaluation framework is used to pre-filter candidate DTs, leading to a significant reduction in training and testing costs without sacrificing deployment performance. Finally, potential research opportunities are discussed."}
{"id": "2511.20508", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20508", "abs": "https://arxiv.org/abs/2511.20508", "authors": ["Elise Zhang", "François Mirallès", "Stéphane Dellacherie", "Di Wu", "Benoit Boulet"], "title": "Causal Feature Selection for Weather-Driven Residential Load Forecasting", "comment": "5 pages, 3 figures, 3 tables", "summary": "Weather is a dominant external driver of residential electricity demand, but adding many meteorological covariates can inflate model complexity and may even impair accuracy. Selecting appropriate exogenous features is non-trivial and calls for a principled selection framework, given the direct operational implications for day-to-day planning and reliability. This work investigates whether causal feature selection can retain the most informative weather drivers while improving parsimony and robustness for short-term load forecasting. We present a case study on Southern Ontario with two open-source datasets: (i) IESO hourly electricity consumption by Forward Sortation Areas; (ii) ERA5 weather reanalysis data. We compare different feature selection regimes (no feature selection, non-causal selection, PCMCI-causal selection) on city-level forecasting with three different time series forecasting models: GRU, TCN, PatchTST. In the feature analysis, non-causal selection prioritizes radiation and moisture variables that show correlational dependence, whereas PCMCI-causal selection emphasizes more direct thermal drivers and prunes the indirect covariates. We detail the evaluation pipeline and report diagnostics on prediction accuracy and extreme-weather robustness, positioning causal feature selection as a practical complement to modern forecasters when integrating weather into residential load forecasting."}
{"id": "2511.19700", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.19700", "abs": "https://arxiv.org/abs/2511.19700", "authors": ["Josef Richter", "Masudul Haque", "Lucas Sá"], "title": "Localization and Delocalization of Quantum Trajectories in the Liouvillian Spectrum", "comment": "10 pages, 6 figures", "summary": "We develop an approach for understanding the dynamics of open quantum systems by analyzing individual quantum trajectories in the eigenbasis of the Liouvillian superoperator. From trajectory-eigenstate overlaps, we construct a quasiprobability distribution that characterizes the degree of localization of the trajectories in the Liouvillian eigenbasis. Contrary to the common wisdom that late-time dynamics are governed solely by the steady state and the slowest-decaying modes, we show that trajectories can remain well spread over transient eigenstates deep within the bulk of the Liouvillian spectrum even at late times. We demonstrate this explicitly using numerical simulations of interacting spin chains and bosonic systems. Moreover, we find that the delocalization of the trajectory strongly correlates with the purity of the trajectory-averaged steady state, establishing a further link between the trajectory and ensemble pictures of open quantum dynamics."}
{"id": "2511.20209", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.20209", "abs": "https://arxiv.org/abs/2511.20209", "authors": ["Jan Quan", "Alexander Bodard", "Konstantinos Oikonomidis", "Panagiotis Patrinos"], "title": "Scaled relative graphs for pairs of operators beyond classical monotonicity", "comment": null, "summary": "We introduce a generalization of the scaled relative graph (SRG) to pairs of operators, enabling the visualization of their relative incremental properties. This novel SRG framework provides the geometric counterpart for the study of nonlinear resolvents based on paired monotonicity conditions. We demonstrate that these conditions apply to linear operators composed with monotone mappings, a class that notably includes NPN transistors, allowing us to compute the response of multivalued, nonsmooth and highly nonmonotone electrical circuits."}
{"id": "2511.20043", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20043", "abs": "https://arxiv.org/abs/2511.20043", "authors": ["Youzhe Yang", "Hafiz Majid Hussain", "Juha Haakana", "Pedro Nardelli"], "title": "Assessing the Technical and Environmental Impacts of Energy Management Systems in Smart Ports", "comment": null, "summary": "A vital strategy for ports to mitigate the environmental impact of the maritime industry, while complying with frameworks such as the European Green Deal and the Sustainable Development Goals (SDGs), entails the systematic implementation of comprehensive energy management solutions. This paper provides a baseline evaluation of the energy management systems (EMSs) implementation and their impact on energy consumption, carbon emissions, and operational costs in smart ports. Initially, we provide a systematic review of the literature focusing on case studies from prominent ports, including Hamburg, Genoa, Jurong, and Shanghai Yangshan Phase IV. The analysis emphasises key aspects such as energy efficiency, reductions in emissions, and the minimization of operational costs. Subsequently, we formulate an optimisation model to simulate load dispatch, carbon emission reduction, and transport scheduling. Results indicate that EMS deployment reduces annual energy consumption and carbon emissions significantly by approximately 7%-8% and 11%-12% respectively, while achieving substantial cost savings of 30%. The study also identifies critical challenges, including system integration, data quality issues, cybersecurity risks, and the need for standardization. These findings provide valuable insights for port authorities and policymakers, supporting the transition toward more sustainable and efficient port operations."}
{"id": "2511.20552", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20552", "abs": "https://arxiv.org/abs/2511.20552", "authors": ["Haoyu Wang", "Andrea Alfonsi", "Roberto Ponciroli", "Richard Vilim"], "title": "From Features to States: Data-Driven Selection of Measured State Variables via RFE-DMDc", "comment": null, "summary": "The behavior of a dynamical system under a given set of inputs can be captured by tracking the response of an optimal subset of process variables (\\textit{state variables}). For many engineering systems, however, first-principles, model-based identification is impractical, motivating data-driven approaches for Digital Twins used in control and diagnostics. In this paper, we present RFE-DMDc, a supervised, data-driven workflow that uses Recursive Feature Elimination (RFE) to select a minimal, physically meaningful set of variables to monitor and then derives a linear state-space model via Dynamic Mode Decomposition with Control (DMDc). The workflow includes a cross-subsystem selection step that mitigates feature \\textit{overshadowing} in multi-component systems. To corroborate the results, we implement a GA-DMDc baseline that jointly optimizes the state set and model fit under a common accuracy cost on states and outputs. Across a truth-known RLC benchmark and a realistic Integrated Energy System (IES) with multiple thermally coupled components and thousands of candidate variables, RFE-DMDc consistently recovers compact state sets (\\(\\approx 10\\) variables) that achieve test errors comparable to GA-DMDc while requiring an order of magnitude less computational time. The selected variables retain clear physical interpretation across subsystems, and the resulting models demonstrate competitive predictive accuracy, computational efficiency, and robustness to overfitting."}
{"id": "2511.19732", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19732", "abs": "https://arxiv.org/abs/2511.19732", "authors": ["Sowmitra Das"], "title": "Measurement-Assisted Clifford Synthesis", "comment": null, "summary": "In this letter, we introduce a method to synthesize an $n$-qubit Clifford unitary $C$ from the stabilizer tableau of its inverse $C†$, using ancilla qubits and measurements. The procedure uses ancillary $|+\\rangle$ states, controlled-Paulis, $X$-basis measurements and single-qubit Pauli corrections on the data qubits (based on the measurement results). This introduces a new normal form for Clifford synthesis, with the number of two-qubit gates required exactly equal to the weight of the stabilizer tableau, and a depth linear in $n$."}
{"id": "2511.20370", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.20370", "abs": "https://arxiv.org/abs/2511.20370", "authors": ["Konstantinos Oikonomidis", "Alexander Bodard", "Jan Quan", "Panagiotis Patrinos"], "title": "Nonlinearly preconditioned gradient flows", "comment": null, "summary": "We study a continuous-time dynamical system which arises as the limit of a broad class of nonlinearly preconditioned gradient methods. Under mild assumptions, we establish existence of global solutions and derive Lyapunov-based convergence guarantees. For convex costs, we prove a sublinear decay in a geometry induced by some reference function, and under a generalized gradient-dominance condition we obtain exponential convergence. We further uncover a duality connection with mirror descent, and use it to establish that the flow of interest solves an infinite-horizon optimal-control problem of which the value function is the Bregman divergence generated by the cost. These results clarify the structure and optimization behavior of nonlinearly preconditioned gradient flows and connect them to known continuous-time models in non-Euclidean optimization."}
{"id": "2511.20237", "categories": ["eess.SY", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.20237", "abs": "https://arxiv.org/abs/2511.20237", "authors": ["Zeynab Kaseb", "Matthias Moller", "Lindsay Spoor", "Jerry J. Guo", "Yu Xiang", "Peter Palensky", "Pedro P. Vergara"], "title": "Quantum-Enhanced Reinforcement Learning for Accelerating Newton-Raphson Convergence with Ising Machines: A Case Study for Power Flow Analysis", "comment": "10 pages, 9 figures, 4 tables", "summary": "The Newton-Raphson (NR) method is widely used for solving power flow (PF) equations due to its quadratic convergence. However, its performance deteriorates under poor initialization or extreme operating scenarios, e.g., high levels of renewable energy penetration. Traditional NR initialization strategies often fail to address these challenges, resulting in slow convergence or even divergence. We propose the use of reinforcement learning (RL) to optimize the initialization of NR, and introduce a novel quantum-enhanced RL environment update mechanism to mitigate the significant computational cost of evaluating power system states over a combinatorially large action space at each RL timestep by formulating the voltage adjustment task as a quadratic unconstrained binary optimization problem. Specifically, quantum/digital annealers are integrated into the RL environment update to evaluate state transitions using a problem Hamiltonian designed for PF. Results demonstrate significant improvements in convergence speed, a reduction in NR iteration counts, and enhanced robustness under different operating conditions."}
{"id": "2511.20603", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20603", "abs": "https://arxiv.org/abs/2511.20603", "authors": ["Winfrey Paul Sagayam Dennis"], "title": "Exploring Urban Air Mobility Adoption Potential in San Francisco Bay Area Region A Systems of Systems Level Case Study on Passenger Waiting Times and Travel Efficiency", "comment": null, "summary": "Urban Air mobility has gained momentum with recent advancements in the electric vertical take-off and landing (eVTOL) vehicles, offering faster point-to-point air taxi services that could help relieve traffic congestion in chronically overburdened cities. The research assesses the feasibility and systems-of-systems level adoption potential of UAM operations in the San Francisco Bay Area by comparing passenger departure, waiting, travel, and arrival times across key regional nodes, including San Francisco, Oakland, San Jose, and Palo Alto airports, with conventional ground transportation. A multi-agent simulation was developed in MATLAB to evaluate the fleet operations and to model demand arrival using a Poisson process under stochastic passenger flows and turnaround constraints. Results indicate that utilizing UAM during peak demand could reduce total travel times up to eighty percent across the region. The findings of this paper highlight the critical operational factors for fleet schedule optimization. Especially how the fleet size, passengers' request volumes, and turnaround time directly influence waiting time, operating cost, and overall user acceptance."}
{"id": "2511.19855", "categories": ["quant-ph", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.19855", "abs": "https://arxiv.org/abs/2511.19855", "authors": ["Brani Vidakovic"], "title": "Quantum Framework for Wavelet Shrinkage", "comment": "25 pages, 9 figures", "summary": "This paper develops a unified framework for quantum wavelet shrinkage, extending classical denoising ideas into the quantum domain. Shrinkage is interpreted as a completely positive trace-preserving process, so attenuation of coefficients is carried out through controlled decoherence rather than nonlinear thresholding. Phase damping and ancilla-driven constructions realize this behavior coherently and show that statistical adaptivity and quantum unitarity can be combined within a single circuit model. The same physical mechanisms that reduce quantum coherence, such as dephasing and amplitude damping, are repurposed as programmable resources for noise suppression. Practical demonstrations implemented with Qiskit illustrate how circuits and channels emulate coefficientwise attenuation, and all examples are provided as Jupyter notebooks in the companion GitHub repository. Encoding schemes for amplitude, phase, and hybrid representations are examined in relation to transform coherence and measurement feasibility, and realizations suited to current noisy intermediate-scale quantum devices are discussed. The work provides a conceptual and experimental link between wavelet-based statistical inference and quantum information processing, and shows how engineered decoherence can act as an operational surrogate for classical shrinkage."}
{"id": "2511.20411", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20411", "abs": "https://arxiv.org/abs/2511.20411", "authors": ["Wouter J. A. van Weerelt", "Lantian Zhang", "Silun Zhang", "Nicola Bastianello"], "title": "Self-Identifying Internal Model-Based Online Optimization", "comment": null, "summary": "In this paper, we propose a novel online optimization algorithm built by combining ideas from control theory and system identification. The foundation of our algorithm is a control-based design that makes use of the internal model of the online problem. Since such prior knowledge of this internal model might not be available in practice, we incorporate an identification routine that learns this model on the fly. The algorithm is designed starting from quadratic online problems but can be applied to general problems. For quadratic cases, we characterize the asymptotic convergence to the optimal solution trajectory. We compare the proposed algorithm with existing approaches, and demonstrate how the identification routine ensures its adaptability to changes in the underlying internal model. Numerical results also indicate strong performance beyond the quadratic setting."}
{"id": "2511.20239", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20239", "abs": "https://arxiv.org/abs/2511.20239", "authors": ["Jan Krejčí", "Oliver Kost", "Yuxuan Xia", "Lennart Svensson", "Ondřej Straka"], "title": "Occlusion-Aware Multi-Object Tracking via Expected Probability of Detection", "comment": "Submitted to IEEE Transactions on Aerospace and Electronic Systems (TAES)", "summary": "This paper addresses multi-object systems, where objects may occlude one another relative to the sensor. The standard point-object model for detection-based sensors is enhanced so that the probability of detection considers the presence of all objects. A principled tracking method is derived, assigning each object an expected probability of detection, where the expectation is taken over the reduced Palm density, which means conditionally on the object's existence. The assigned probability thus considers the object's visibility relative to the sensor, under the presence of other objects. Unlike existing methods, the proposed method systematically accounts for uncertainties related to all objects in a clear and manageable way. The method is demonstrated through a visual tracking application using the multi-Bernoulli mixture (MBM) filter with marks."}
{"id": "2511.19675", "categories": ["math.OC", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19675", "abs": "https://arxiv.org/abs/2511.19675", "authors": ["Jiarui Wang", "Mahyar Fazlyab"], "title": "Anytime-Feasible First-Order Optimization via Safe Sequential QCQP", "comment": null, "summary": "This paper presents the Safe Sequential Quadratically Constrained Quadratic Programming (SS-QCQP) algorithm, a first-order method for smooth inequality-constrained nonconvex optimization that guarantees feasibility at every iteration. The method is derived from a continuous-time dynamical system whose vector field is obtained by solving a convex QCQP that enforces monotonic descent of the objective and forward invariance of the feasible set. The resulting continuous-time dynamics achieve an $O(1/t)$ convergence rate to first-order stationary points under standard constraint qualification conditions. We then propose a safeguarded Euler discretization with adaptive step-size selection that preserves this convergence rate while maintaining both descent and feasibility in discrete time. To enhance scalability, we develop an active-set variant (SS-QCQP-AS) that selectively enforces constraints near the boundary, substantially reducing computational cost without compromising theoretical guarantees. Numerical experiments on a multi-agent nonlinear optimal control problem demonstrate that SS-QCQP and SS-QCQP-AS maintain feasibility, exhibit the predicted convergence behavior, and deliver solution quality comparable to second-order solvers such as SQP and IPOPT."}
{"id": "2511.19977", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19977", "abs": "https://arxiv.org/abs/2511.19977", "authors": ["Syed Affan Aslam", "Areej Ilyas", "Jibran Rashid"], "title": "Suboptimality of Parity for Distilling Correlations with Nontrivial Marginals", "comment": null, "summary": "We prove that the PARITY protocol is optimal for a general class of non-adaptive distillation protocols of all $n$ player nonlocal boxes (NLBs) based on XOR games. The conditional distributions generated by these NLBs are assumed to have trivial local marginals. We also show that already for $n=2$, PARITY is no longer optimal if the local marginals are non-trivial. The OR protocol is shown to perform better and in the process also slightly extend the known correlations that collapse communication complexity. This emphasizes again the need to understand the local properties of nonlocal systems in order to obtain a better characterization of the global behavior. We conclude by showing an equivalence between adaptive distillation protocols that use identical NLBs and PARITY protocol using nonidentical NLBs."}
{"id": "2511.20413", "categories": ["math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.20413", "abs": "https://arxiv.org/abs/2511.20413", "authors": ["Zhuojun Xie", "Adam Abdin", "Yiping Fang"], "title": "PAC-Bayes Meets Online Contextual Optimization", "comment": null, "summary": "The predict-then-optimize paradigm bridges online learning and contextual optimization in dynamic environments. Previous works have investigated the sequential updating of predictors using feedback from downstream decisions to minimize regret in the full-information settings. However, existing approaches are predominantly frequentist, rely heavily on gradient-based strategies, and employ deterministic predictors that could yield high variance in practice despite their asymptotic guarantees. This work introduces, to the best of our knowledge, the first Bayesian online contextual optimization framework. Grounded in PAC-Bayes theory and general Bayesian updating principles, our framework achieves $\\mathcal{O}(\\sqrt{T})$ regret for bounded and mixable losses via a Gibbs posterior, eliminates the dependence on gradients through sequential Monte Carlo samplers, and thereby accommodates nondifferentiable problems. Theoretical developments and numerical experiments substantiate our claims."}
{"id": "2511.20276", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20276", "abs": "https://arxiv.org/abs/2511.20276", "authors": ["Lianzhe Hu", "Yu Wang", "Bikash Pal"], "title": "LLM-Driven Transient Stability Assessment: From Automated Simulation to Neural Architecture Design", "comment": null, "summary": "This paper presents an LLM-driven, end-to-end workflow that addresses the lack of automation and intelligence in power system transient stability assessment (TSA). The proposed agentic framework integrates large language models (LLMs) with a professional simulator (ANDES) to automatically generate and filter disturbance scenarios from natural language, and employs an LLM-driven Neural Network Design (LLM-NND) pipeline to autonomously design and optimize TSA models through performance-guided, closed-loop feedback. On the IEEE 39-bus system, the LLM-NND models achieve 93.71% test accuracy on four-class TSA with only 4.78M parameters, while maintaining real-time inference latency (less than 0.95 ms per sample). Compared with a manually designed DenseNet (25.9M parameters, 80.05% accuracy), the proposed approach jointly improves accuracy and efficiency. Ablation studies confirm that the synergy among domain-grounded retrieval, reasoning augmentation, and feedback mechanisms is essential for robust automation. The results demonstrate that LLM agents can reliably accelerate TSA research from scenario generation and data acquisition to model design and interpretation, offering a scalable paradigm that is readily extensible to other power system tasks such as optimal power flow, fault analysis, and market operations."}
{"id": "2511.19708", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19708", "abs": "https://arxiv.org/abs/2511.19708", "authors": ["Chenyang Qiu", "Yangyang Qian", "Zongli Lin", "Yacov A. Shamash"], "title": "An Accelerated Distributed Algorithm with Equality and Inequality Coupling Constraints", "comment": null, "summary": "This paper studies distributed convex optimization with both affine equality and nonlinear inequality couplings through the duality analysis. We first formulate the dual of the coupling-constraint problem and reformulate it as a consensus optimization problem over a connected network. To efficiently solve this dual problem and hence the primal problem, we design an accelerated linearized algorithm that, at each round, a look-ahead linearization of the separable objective is combined with a quadratic penalty on the Laplacian constraint, a proximal step, and an aggregation of iterations. On the theory side, we prove non-ergodic rates for both the primal optimality error and the feasibility error. On the other hand, numerical experiments show a faster decrease of optimality error and feasibility residual than augmented-Lagrangian tracking and distributed subgradient baselines under the same communication budget."}
{"id": "2511.19983", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19983", "abs": "https://arxiv.org/abs/2511.19983", "authors": ["Pei Zeng", "Guo Zheng", "Qian Xu", "Liang Jiang"], "title": "Error-structure-tailored early fault-tolerant quantum computing", "comment": "35 pages, 22 figures. Comments are welcome", "summary": "Fault tolerance is widely regarded as indispensable for achieving scalable and reliable quantum computing. However, the spacetime overhead required for fault-tolerant quantum computating remains prohibitively large. A critical challenge arises in many quantum algorithms with Clifford + $\\varphi$ compiling, where logical rotation gates $R_{Z_L}(\\varphi)$ serve as essential components. The Eastin-Knill theorem prevents their transversal implementation in quantum error correction codes and necessitating resource-intensive workarounds through T-gate compilation combined with magic state distillation and injection. In this work, we consider error-structure-tailored fault tolerance, where fault-tolerance conditions are analyzed by combining perturbative analysis of realistic dissipative noise processes with the structural properties of stabilizer codes. Based on this framework, we design 1-fault-tolerant continuous-angle rotation gates in stabilizer codes, implemented via dispersive-coupling Hamiltonians. Our approach could circumvent the need for T-gate compilation and distillation, offering a hardware-efficient solution that maintains simplicity, minimizes physical footprint, and requires only nearest-neighbor interactions. Integrating with recent small-angle-state preparation techniques, we can suppress the gate error to $91|\\varphi| p^2$ for small rotation angle (where p denotes the physical error rate). For current achievable hardware parameters ($p=10^{-3}$), this enables reliable execution of over $10^7$ small-angle rotations when $|\\varphi|\\approx 10^{-3}$, meeting the requirements of many near-term quantum applications. Compared to the 15-to-1 magic state distillation and magic state cultivation approaches, our method reduces spacetime resource costs by factors of 1337.5 and 43.6, respectively, for a Heisenberg Hamiltonian simulation task under realistic hardware assumptions."}
{"id": "2511.20294", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20294", "abs": "https://arxiv.org/abs/2511.20294", "authors": ["Dnyandeep Mandaokar", "Bernhard Rinner"], "title": "SAFE-IMM: Robust and Lightweight Radar-Based Object Tracking on Mobile Platforms", "comment": null, "summary": "Tracking maneuvering targets requires estimators that are both responsive and robust. Interacting Multiple Model (IMM) filters are a standard tracking approach, but fusing models via Gaussian mixtures can lag during maneuvers. Recent winnertakes-all (WTA) approaches react quickly but may produce discontinuities. We propose SAFE-IMM, a lightweight IMM variant for tracking on mobile and resource-limited platforms with a safe covariance-aware gate that permits WTA only when the implied jump from the mixture to the winner is provably bounded. In simulations and on nuScenes front-radar data, SAFE-IMM achieves high accuracy at real-time rates, reducing ID switches while maintaining competitive performance. The method is simple to integrate, numerically stable, and clutter-robust, offering a practical balance between responsiveness and smoothness."}
{"id": "2511.19714", "categories": ["math.OC", "cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19714", "abs": "https://arxiv.org/abs/2511.19714", "authors": ["Chenyang Qiu", "Zongli Lin"], "title": "Non-Ergodic Convergence Algorithms for Distributed Consensus and Coupling-Constrained Optimization", "comment": null, "summary": "We study distributed convex optimization with two ubiquitous forms of coupling: consensus constraints and global affine equalities. We first design a linearized method of multipliers for the consensus optimization problem. Without smoothness or strong convexity, we establish non-ergodic sublinear rates of order O(1/\\sqrt{k}) for both the objective optimality and the consensus violation. Leveraging duality, we then show that the economic dispatch problem admits a dual consensus formulation, and that applying the same algorithm to the dual economic dispatch yields non-ergodic O(1/\\sqrt{k}) decay for the error of the summation of the cost over the network and the equality-constraint residual under convexity and Slater's condition. Numerical results on the IEEE 118-bus system demonstrate faster reduction of both objective error and feasibility error relative to the state-of-the-art baselines, while the dual variables reach network-wide consensus."}
{"id": "2511.20014", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20014", "abs": "https://arxiv.org/abs/2511.20014", "authors": ["Reiji Okada", "Francesco Buscemi"], "title": "Virtual phase-covariant quantum broadcasting for qubits", "comment": "10 pages. Comments welcome", "summary": "Virtual maps allow the simulation of quantum operations by combining physical processes with classical post-processing. Recent work on virtual unitary covariant broadcasting has shown, however, that such maps remain impractical for observable estimation tasks due to poor sample efficiency. Here we investigate whether relaxing the symmetry requirements can improve operational performance, focusing on virtual phase-covariant quantum broadcasting for qubits. We show that imposing phase-covariance, flip covariance, permutation invariance, and classical consistency fully determines the structure of the broadcasting map. Within this family, we identify the unique map that minimizes the simulation cost, and we prove that both the simulation cost and the distance to the closest CPTP map are strictly smaller than in the unitary covariant setting. We also demonstrate that the closest physical map is the optimal phase-covariant cloning channel, mirroring the relation between unitary covariant broadcasting and universal cloning. Despite these improvements, the resulting virtual broadcasting map remains sample-inefficient and is therefore still operationally impractical."}
{"id": "2511.20383", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20383", "abs": "https://arxiv.org/abs/2511.20383", "authors": ["Viet-Anh Le", "Andreas A. Malikopoulos"], "title": "Accelerating Time-Optimal Trajectory Planning for Connected and Automated Vehicles with Graph Neural Networks", "comment": "submitted to IFAC WC 2026", "summary": "In this paper, we present a learning-based framework that accelerates time- and energy-optimal trajectory planning for connected and automated vehicles (CAVs) using graph neural networks (GNNs). We formulate the multi-agent coordination problem encountered in traffic scenarios as a cooperative trajectory planning problem that minimizes travel time, subject to motion primitives derived from energy-optimal solutions. The effectiveness of this framework can be further improved through replanning at each time step, enabling the system to incorporate newly observed information. To achieve real-time execution of such a multi-agent replanning scheme, we employ a GNN architecture to learn the solutions of the time-optimal trajectory planning problem from offline-generated data. The trained model produces online predictions that serve as warm-start solutions for numerical optimization, thereby enabling rapid computation of minimal exit times and the associated feasible trajectories. This learning-augmented approach substantially reduces computation time while ensuring that all state, input, and safety constraints are satisfied."}
{"id": "2511.19723", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19723", "abs": "https://arxiv.org/abs/2511.19723", "authors": ["Chenyang Qiu", "Zongli Lin"], "title": "A Distributed Gradient-based Algorithm for Optimization Problems with Coupled Equality Constraints", "comment": "11 pages, 3 figures, submitted to Automatica", "summary": "This paper studies a class of distributed optimization problems with coupled equality constraints in networked systems. Many existing distributed algorithms rely on solving local subproblems via the $\\operatorname{argmin}$ operator in each iteration. Such approaches become computationally burdensome or intractable when local cost functions are complex. To address this challenge, we propose a novel distributed gradient-based algorithm that avoids solving a local optimization problem at each iteration by leveraging first-order approximations and projection onto local feasible sets. The algorithm operates in a fully distributed manner, requiring only local communication without exchanging gradients or primal variables. We rigorously establish sublinear convergence for general convex cost functions and linear convergence under strong convexity and smoothness conditions. Numerical simulation on the IEEE 118-bus system demonstrates the superior computational efficiency and scalability of the proposed method compared to several state-of-the-art distributed optimization algorithms."}
{"id": "2511.20016", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20016", "abs": "https://arxiv.org/abs/2511.20016", "authors": ["Fumin Wang"], "title": "Kernelized Decoded Quantum Interferometry", "comment": null, "summary": "Decoded Quantum Interferometry (DQI) promises superpolynomial speedups for structured optimization; however, its practical realization is often hindered by significant sensitivity to hardware noise and spectral dispersion. To bridge this gap, we introduce \\textbf{Kernelized Decoded Quantum Interferometry (k-DQI)}, a unified framework that integrates spectral engineering directly into the quantum circuit architecture. By inserting a unitary kernel prior to the interference step, k-DQI actively reshapes the problem's energy landscape, concentrating the solution mass into a ``decoder-friendly'' low-frequency head. We formalize this advantage through a novel robustness metric, the noise-weighted head mass $Σ_K$, and prove a \\textbf{Monotonic Improvement Theorem}, which establishes that maximizing $Σ_K$ guarantees higher decoding success rates under local depolarizing noise. We substantiate these theoretical gains in Optimal Polynomial Interpolation (OPI) and LDPC-like problems, demonstrating that kernel tuning functions as a ``spectral lens'' to recover signal otherwise lost to isotropic noise. Crucially, we provide explicit, efficient circuit realizations using Chirp and Linear Canonical Transform (LCT) kernels that achieve significant boosts in effective signal-to-noise ratio with negligible depth overhead ($\\tilde{O}(n)$ to $\\tilde{O}(n^2)$). Collectively, these results reframe DQI from a static algorithm into a tunable, noise-aware protocol suited for near-term error-corrected environments."}
{"id": "2511.20443", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20443", "abs": "https://arxiv.org/abs/2511.20443", "authors": ["Amy K. Strong", "Samuel Akinwande", "Leila Bridgeman"], "title": "Adaptive Meshing for CPA Lyapunov Function Synthesis", "comment": null, "summary": "Continuous piecewise affine (CPA) Lyapunov function synthesis is one method to perform Lyapunov stability analysis for nonlinear systems. This method first generates a mesh over the region of interest in the system's state space and then solves a linear program (LP), which enforces constraints on each vertex of the mesh, to synthesize a Lyapunov function. Finer meshes broaden the class of Lyapunov function candidates, but CPA function synthesis is more computationally expensive for finer meshes -- particularly so in higher dimensional systems. This paper explores methods to mesh the region of interest more efficiently so that a Lyapunov function can be synthesized using less computational effort. Three methods are explored -- adaptive meshing, meshing using knowledge of the system model, and a combination of the two. Numerical examples for two and three dimensional nonlinear dynamical systems are used to compare the efficacy of the three methods."}
{"id": "2511.20411", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20411", "abs": "https://arxiv.org/abs/2511.20411", "authors": ["Wouter J. A. van Weerelt", "Lantian Zhang", "Silun Zhang", "Nicola Bastianello"], "title": "Self-Identifying Internal Model-Based Online Optimization", "comment": null, "summary": "In this paper, we propose a novel online optimization algorithm built by combining ideas from control theory and system identification. The foundation of our algorithm is a control-based design that makes use of the internal model of the online problem. Since such prior knowledge of this internal model might not be available in practice, we incorporate an identification routine that learns this model on the fly. The algorithm is designed starting from quadratic online problems but can be applied to general problems. For quadratic cases, we characterize the asymptotic convergence to the optimal solution trajectory. We compare the proposed algorithm with existing approaches, and demonstrate how the identification routine ensures its adaptability to changes in the underlying internal model. Numerical results also indicate strong performance beyond the quadratic setting."}
{"id": "2511.20017", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20017", "abs": "https://arxiv.org/abs/2511.20017", "authors": ["Xinchi Huang", "Hirofumi Nishi", "Yoshifumi Kawada", "Tomofumi Zushi", "Yu-ichiro Matsushita"], "title": "Real and Fourier space readout methods: Comparison of complexity and applications to CFD problems", "comment": "41 pages including the appendices", "summary": "Quantum computing is a promising technology that accelerates the partial differential equations solver for practical problems. The reconstruction of solutions (i.e., the readout of quantum states) remains a crucial problem, although numerous efficient quantum algorithms have been proposed. In this paper, we propose and compare several efficient readout methods in the real and the Fourier space. The Fourier space readout (FSR) and the proposed approximate real space readout (ARSR) methods are currently the most efficient and practical ones for the purpose of reconstructing continuous real-valued functions. In contrast, the quantum amplitude estimation (QAE) based methods (especially in the Fourier space) are favorable for mid-term/far-term quantum devices. Besides, we apply the methods for benchmark solutions in computational fluid dynamics (CFD) and demonstrate great improvements compared to the conventional sampling method for large grid numbers. Equipped with efficient readout methods, we further show that a 2D Burgers' equation can be solved efficiently without using the expensive strategy of linearization. It suggests the potential quantum advantages for some practical applications on mid-term quantum devices."}
{"id": "2511.20463", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20463", "abs": "https://arxiv.org/abs/2511.20463", "authors": ["Amy K. Strong", "Ali Kashani", "Claus Danielson", "Leila Bridgeman"], "title": "Learning Control Barrier Functions with Deterministic Safety Guarantees", "comment": null, "summary": "Barrier functions (BFs) characterize safe sets of dynamical systems, where hard constraints are never violated as the system evolves over time. Computing a valid safe set and BF for a nonlinear (and potentially unmodeled), non-autonomous dynamical system is a difficult task. This work explores the design of BFs using data to obtain safe sets with deterministic assurances of control invariance. We leverage ReLU neural networks (NNs) to create continuous piecewise affine (CPA) BFs with deterministic safety guarantees for Lipschitz continuous, discrete-time dynamical system using sampled one-step trajectories. The CPA structure admits a novel classifier term to create a relaxed \\ac{bf} condition and construction via a data driven constrained optimization. We use iterative convex overbounding (ICO) to solve this nonconvex optimization problem through a series of convex optimization steps. We then demonstrate our method's efficacy on two-dimensional autonomous and non-autonomous dynamical systems."}
{"id": "2511.20026", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20026", "abs": "https://arxiv.org/abs/2511.20026", "authors": ["Ya-Tang Yu", "Hsin-Lien Lee", "Ting Hsu", "Guin-Dar Lin", "Yin-Cheng Chen", "H. H. Jen"], "title": "An Adaptable Route to Fast Coherent State Transport via Bang-Bang-Bang Protocols", "comment": null, "summary": "Fast coherent state transport is essential to quantum computation and quantum information processing. While an adiabatic transport of atomic qubits guarantees a high fidelity of the state preparation, it requires a long timescale that defies efficient quantum operations. Here, we propose an adaptable and fast bang-bang-bang (BBB) protocol, utilizing a combination of forwardand backward-moving trap potentials, to expedite the coherent state transport. This protocol approaches the quantum speed limit under a harmonic trap potential, surpassing the performance by the forward-moving-only potential protocols. We further showcase the advantage of applying squeezed coherent state evolution under a deeper potential followed by a weaker one, where a design of symmetric squeezing potential transports promotes an even shorter timescale for genuine state preparation. Our protocols outperform conventional forward-moving-only methods, providing new insights and opportunities for rapid state transport and preparation, ultimately advancing the capabilities of quantum control and quantum operations."}
{"id": "2511.20508", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20508", "abs": "https://arxiv.org/abs/2511.20508", "authors": ["Elise Zhang", "François Mirallès", "Stéphane Dellacherie", "Di Wu", "Benoit Boulet"], "title": "Causal Feature Selection for Weather-Driven Residential Load Forecasting", "comment": "5 pages, 3 figures, 3 tables", "summary": "Weather is a dominant external driver of residential electricity demand, but adding many meteorological covariates can inflate model complexity and may even impair accuracy. Selecting appropriate exogenous features is non-trivial and calls for a principled selection framework, given the direct operational implications for day-to-day planning and reliability. This work investigates whether causal feature selection can retain the most informative weather drivers while improving parsimony and robustness for short-term load forecasting. We present a case study on Southern Ontario with two open-source datasets: (i) IESO hourly electricity consumption by Forward Sortation Areas; (ii) ERA5 weather reanalysis data. We compare different feature selection regimes (no feature selection, non-causal selection, PCMCI-causal selection) on city-level forecasting with three different time series forecasting models: GRU, TCN, PatchTST. In the feature analysis, non-causal selection prioritizes radiation and moisture variables that show correlational dependence, whereas PCMCI-causal selection emphasizes more direct thermal drivers and prunes the indirect covariates. We detail the evaluation pipeline and report diagnostics on prediction accuracy and extreme-weather robustness, positioning causal feature selection as a practical complement to modern forecasters when integrating weather into residential load forecasting."}
{"id": "2511.20031", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.20031", "abs": "https://arxiv.org/abs/2511.20031", "authors": ["Yuexun Huang", "Delaney Smith", "Pei Zeng", "Debayan Bandyopadhyay", "Junyu Liu", "Rana X Adhikari", "Liang Jiang"], "title": "A Comprehensive Characterization of the Vacuum Beam Guide and Its Applications", "comment": null, "summary": "The proposed vacuum beam guide (VBG) represents an innovation in the field of quantum channel technology, guaranteeing an ultra-low level of attenuation and a broad transmission linewidth, which offers an unprecedented quantum capacity exceeding Tera-qubits per second on a continental scale. However, its stability in terms of interferometry remains unexamined. To address this gap, we have developed a comprehensive error model that captures the intrinsic phase noise power spectral density associated with VBG, thereby revealing the advantages of VBG for interferometry over existing techniques. This model facilitates a comprehensive characterization of VBG as a photonic quantum channel, thereby facilitating a detailed investigation of its potential. Our theoretical analysis demonstrates the feasibility of VBG and its expected performance in a wide range of quantum applications."}
{"id": "2511.20552", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20552", "abs": "https://arxiv.org/abs/2511.20552", "authors": ["Haoyu Wang", "Andrea Alfonsi", "Roberto Ponciroli", "Richard Vilim"], "title": "From Features to States: Data-Driven Selection of Measured State Variables via RFE-DMDc", "comment": null, "summary": "The behavior of a dynamical system under a given set of inputs can be captured by tracking the response of an optimal subset of process variables (\\textit{state variables}). For many engineering systems, however, first-principles, model-based identification is impractical, motivating data-driven approaches for Digital Twins used in control and diagnostics. In this paper, we present RFE-DMDc, a supervised, data-driven workflow that uses Recursive Feature Elimination (RFE) to select a minimal, physically meaningful set of variables to monitor and then derives a linear state-space model via Dynamic Mode Decomposition with Control (DMDc). The workflow includes a cross-subsystem selection step that mitigates feature \\textit{overshadowing} in multi-component systems. To corroborate the results, we implement a GA-DMDc baseline that jointly optimizes the state set and model fit under a common accuracy cost on states and outputs. Across a truth-known RLC benchmark and a realistic Integrated Energy System (IES) with multiple thermally coupled components and thousands of candidate variables, RFE-DMDc consistently recovers compact state sets (\\(\\approx 10\\) variables) that achieve test errors comparable to GA-DMDc while requiring an order of magnitude less computational time. The selected variables retain clear physical interpretation across subsystems, and the resulting models demonstrate competitive predictive accuracy, computational efficiency, and robustness to overfitting."}
{"id": "2511.20097", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20097", "abs": "https://arxiv.org/abs/2511.20097", "authors": ["Babak Mohammadian"], "title": "Superconducting Parametric Amplifiers: Resonator Design and Role in Qubit Readout", "comment": null, "summary": "Superconducting parametric amplifiers (SPAs) are critical components for ultralow-noise qubit readout in quantum computing, addressing the critical challenge of amplifying weak quantum signals without introducing noise that degrades coherence and computational fidelity. Unlike classical amplifiers, SPAs can achieve or closely approach quantum-limited performance, specifically the Standard Quantum Limit (SQL) of half a photon of added noise for phase-preserving amplification. The core principle of SPAs relies on parametric amplification, where energy is transferred from a strong pump tone to a weak input signal through non-dissipative nonlinear mixing processes. This is enabled by intrinsic nonlinearities in superconducting materials, primarily kinetic inductance in thin films (e.g., NbTiN, Al) and, more significantly, the Josephson effect in Josephson junctions. These nonlinear elements facilitate frequency mixing (three-wave or four-wave mixing) and can operate in phase-preserving or phase-sensitive amplification modes, with the latter allowing for noise squeezing below the SQL. This chapter emphasizes the significant role of resonator design in determining critical SPA performance metrics such as gain, bandwidth, and noise characteristics. It details both lumped-element (LC) and distributed-element (coplanar waveguide, CPW) resonators, discussing their unique properties, suitability for different frequency ranges, and the importance of achieving high-quality factors (Q) for efficient energy storage and minimal loss. A practical design and simulation of a meandered quarterwavelength CPW resonator coupled to a feed line is presented, illustrating how precise control over geometric parameters optimizes resonant frequency, coupling strength, and quality factor for high-fidelity qubit state discrimination."}
{"id": "2511.20603", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20603", "abs": "https://arxiv.org/abs/2511.20603", "authors": ["Winfrey Paul Sagayam Dennis"], "title": "Exploring Urban Air Mobility Adoption Potential in San Francisco Bay Area Region A Systems of Systems Level Case Study on Passenger Waiting Times and Travel Efficiency", "comment": null, "summary": "Urban Air mobility has gained momentum with recent advancements in the electric vertical take-off and landing (eVTOL) vehicles, offering faster point-to-point air taxi services that could help relieve traffic congestion in chronically overburdened cities. The research assesses the feasibility and systems-of-systems level adoption potential of UAM operations in the San Francisco Bay Area by comparing passenger departure, waiting, travel, and arrival times across key regional nodes, including San Francisco, Oakland, San Jose, and Palo Alto airports, with conventional ground transportation. A multi-agent simulation was developed in MATLAB to evaluate the fleet operations and to model demand arrival using a Poisson process under stochastic passenger flows and turnaround constraints. Results indicate that utilizing UAM during peak demand could reduce total travel times up to eighty percent across the region. The findings of this paper highlight the critical operational factors for fleet schedule optimization. Especially how the fleet size, passengers' request volumes, and turnaround time directly influence waiting time, operating cost, and overall user acceptance."}
{"id": "2511.20115", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.20115", "abs": "https://arxiv.org/abs/2511.20115", "authors": ["Johannes Kerber", "Helmut Ritsch", "Laurin Ostermann"], "title": "The Cumulants Expansion Approach: The Good, The Bad and The Ugly", "comment": "9 pages, 10 figures and 3 tables", "summary": "The configuration space, i.e. the Hilbert space, of compound quantum systems grows exponentially with the number of its subsystems: its dimensionality is given by the product of the dimensions of its constituents. Therefore a full quantum treatment is rarely possible analytically and can be carried out numerically for fairly small systems only. Fortunately, in order to obtain interesting physics, approximations often very well suffice. One of these approximations is given by the cumulants expansion, where expectation values of products of operators are approximated by products of expectation values of said operators, neglecting higher-order correlations. The lowest order of this approximation is widely known as the mean field approximation and used routinely throughout quantum physics. Despite its ubiquitous presence, a general criterion for applicability and convergence properties of higher order cumulants expansions remains to be found. In this paper, we discuss two problems in quantum electrodynamics and quantum information, namely the collective radiative dissipation of a dipole-dipole interacting chain of atoms and the factorization of a bi-prime by annealing in an adiabatic quantum simulator. In the first case we find smooth, convergence behavior, where the approximation performs increasingly better with higher orders, while in the latter going beyond mean field turns out useless and, even for small system sizes, we are puzzled by numerically challenging and partly non-physical solutions."}
{"id": "2511.19675", "categories": ["math.OC", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19675", "abs": "https://arxiv.org/abs/2511.19675", "authors": ["Jiarui Wang", "Mahyar Fazlyab"], "title": "Anytime-Feasible First-Order Optimization via Safe Sequential QCQP", "comment": null, "summary": "This paper presents the Safe Sequential Quadratically Constrained Quadratic Programming (SS-QCQP) algorithm, a first-order method for smooth inequality-constrained nonconvex optimization that guarantees feasibility at every iteration. The method is derived from a continuous-time dynamical system whose vector field is obtained by solving a convex QCQP that enforces monotonic descent of the objective and forward invariance of the feasible set. The resulting continuous-time dynamics achieve an $O(1/t)$ convergence rate to first-order stationary points under standard constraint qualification conditions. We then propose a safeguarded Euler discretization with adaptive step-size selection that preserves this convergence rate while maintaining both descent and feasibility in discrete time. To enhance scalability, we develop an active-set variant (SS-QCQP-AS) that selectively enforces constraints near the boundary, substantially reducing computational cost without compromising theoretical guarantees. Numerical experiments on a multi-agent nonlinear optimal control problem demonstrate that SS-QCQP and SS-QCQP-AS maintain feasibility, exhibit the predicted convergence behavior, and deliver solution quality comparable to second-order solvers such as SQP and IPOPT."}
{"id": "2511.20133", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.20133", "abs": "https://arxiv.org/abs/2511.20133", "authors": ["A. R. Mukhamedyanov", "E. S. Andrianov", "A. A. Zyablovsky"], "title": "All-Optical Brillouin Random number Generator", "comment": null, "summary": "We propose a model of binary random number generator (RNG) based on a Brillouin optomechanical system. The device uses a hard excitation mode in a Brillouin optomechanical system, where thermal noise induces spontaneous transitions between two stable states in the hard excitation mode. We demonstrate the existence of an amplitude criterion for observing these transitions and show that the probability distribution of their occurrence in the non-generating and generating states can be precisely controlled by the amplitude of an external pump wave. At the same time, the use of a low-intensity seed wave allows for the control of the transition times between states. We demonstrate that the proposed random number generator successfully passes the standard tests NIST SP 800-22. The obtained result opens a way for development of an all-optical integrated True RNG, generating a sequence of random bits with equal probability."}
{"id": "2511.19708", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19708", "abs": "https://arxiv.org/abs/2511.19708", "authors": ["Chenyang Qiu", "Yangyang Qian", "Zongli Lin", "Yacov A. Shamash"], "title": "An Accelerated Distributed Algorithm with Equality and Inequality Coupling Constraints", "comment": null, "summary": "This paper studies distributed convex optimization with both affine equality and nonlinear inequality couplings through the duality analysis. We first formulate the dual of the coupling-constraint problem and reformulate it as a consensus optimization problem over a connected network. To efficiently solve this dual problem and hence the primal problem, we design an accelerated linearized algorithm that, at each round, a look-ahead linearization of the separable objective is combined with a quadratic penalty on the Laplacian constraint, a proximal step, and an aggregation of iterations. On the theory side, we prove non-ergodic rates for both the primal optimality error and the feasibility error. On the other hand, numerical experiments show a faster decrease of optimality error and feasibility residual than augmented-Lagrangian tracking and distributed subgradient baselines under the same communication budget."}
{"id": "2511.20140", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20140", "abs": "https://arxiv.org/abs/2511.20140", "authors": ["Anagha Gayathri", "Aryan Bhardwaj", "Nilesh Sharma", "Tarun Goel", "Y. V. Subba Rao", "Anil Prabhakar"], "title": "Plug-n-Play Three Pulse Twin Field QKD", "comment": "7 pages, 8 figures", "summary": "We present the experimental implementation of a three-time-bin phase-encoded Twin-Field Quantum Key Distribution (TF-QKD) protocol using a Sagnac-based star-topology plug-and-play architecture. The proposed encoding method leverages the relative phases of three consecutive time bins to encode two bits per signal. The Sagnac loop configuration enables self-compensation for both phase and polarisation drifts, eliminating the need for active stabilisation. However, field deployments are subject to rapid phase fluctuations caused by external vibrations, which can degrade interference visibility. We used the first time bin for real-time phase-fluctuation monitoring. Although this monitoring reduces the effective key generation rate, the system achieved a secure key rate of approximately 1.5e-5 bits per pulse, with a corresponding visibility of up to 87% over a 50 km asymmetric optical fibre channel. These results demonstrate the practicality, stability, and scalability of the proposed three-time-bin TF-QKD protocol for real-world quantum communication networks."}
{"id": "2511.19714", "categories": ["math.OC", "cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19714", "abs": "https://arxiv.org/abs/2511.19714", "authors": ["Chenyang Qiu", "Zongli Lin"], "title": "Non-Ergodic Convergence Algorithms for Distributed Consensus and Coupling-Constrained Optimization", "comment": null, "summary": "We study distributed convex optimization with two ubiquitous forms of coupling: consensus constraints and global affine equalities. We first design a linearized method of multipliers for the consensus optimization problem. Without smoothness or strong convexity, we establish non-ergodic sublinear rates of order O(1/\\sqrt{k}) for both the objective optimality and the consensus violation. Leveraging duality, we then show that the economic dispatch problem admits a dual consensus formulation, and that applying the same algorithm to the dual economic dispatch yields non-ergodic O(1/\\sqrt{k}) decay for the error of the summation of the cost over the network and the equality-constraint residual under convexity and Slater's condition. Numerical results on the IEEE 118-bus system demonstrate faster reduction of both objective error and feasibility error relative to the state-of-the-art baselines, while the dual variables reach network-wide consensus."}
{"id": "2511.20212", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20212", "abs": "https://arxiv.org/abs/2511.20212", "authors": ["Jingheng Wang", "Shengminjie Chen", "Xiaoming Sun", "Jialin Zhang"], "title": "A Unified Complexity-Algorithm Account of Constant-Round QAOA Expectation Computation", "comment": null, "summary": "The Quantum Approximate Optimization Algorithm (QAOA) is widely studied for combinatorial optimization and has achieved significant advances both in theoretical guarantees and practical performance, yet for general combinatorial optimization problems the expected performance and classical simulability of fixed-round QAOA remain unclear. Focusing on Max-Cut, we first show that for general graphs and any fixed round $p\\ge2$, exactly evaluating the expectation of fixed-round QAOA at prescribed angles is $\\mathrm{NP}$-hard, and that approximating this expectation within additive error $2^{-O(n)}$ in the number $n$ of vertices is already $\\mathrm{NP}$-hard. To evaluate the expected performance of QAOA, we propose a dynamic programming algorithm leveraging tree decomposition. As a byproduct, when the $p$-local treewidth grows at most logarithmically with the number of vertices, this yields a polynomial-time \\emph{exact} evaluation algorithm in the graph size $n$. Beyond Max-Cut, we extend the framework to general Binary Unconstrained Combinatorial Optimization (BUCO). Finally, we provide reproducible evaluations for rounds up to $p=3$ on representative structured families, including the generalized Petersen graph $GP(15,2)$, double-layer triangular 2-lifts, and the truncated icosahedron graph $C_{60}$, and report cut ratios while benchmarking against locality-matched classical baselines."}
{"id": "2511.19723", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19723", "abs": "https://arxiv.org/abs/2511.19723", "authors": ["Chenyang Qiu", "Zongli Lin"], "title": "A Distributed Gradient-based Algorithm for Optimization Problems with Coupled Equality Constraints", "comment": "11 pages, 3 figures, submitted to Automatica", "summary": "This paper studies a class of distributed optimization problems with coupled equality constraints in networked systems. Many existing distributed algorithms rely on solving local subproblems via the $\\operatorname{argmin}$ operator in each iteration. Such approaches become computationally burdensome or intractable when local cost functions are complex. To address this challenge, we propose a novel distributed gradient-based algorithm that avoids solving a local optimization problem at each iteration by leveraging first-order approximations and projection onto local feasible sets. The algorithm operates in a fully distributed manner, requiring only local communication without exchanging gradients or primal variables. We rigorously establish sublinear convergence for general convex cost functions and linear convergence under strong convexity and smoothness conditions. Numerical simulation on the IEEE 118-bus system demonstrates the superior computational efficiency and scalability of the proposed method compared to several state-of-the-art distributed optimization algorithms."}
{"id": "2511.20281", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20281", "abs": "https://arxiv.org/abs/2511.20281", "authors": ["Jiaxi Kuang", "Kensei Torii", "Francesco Buscemi"], "title": "Quantum measurement retrodiction and entropic uncertainty relations", "comment": null, "summary": "We study quantum measurement retrodiction using the principle of minimum change. For quantum-to-classical measurement channels, we show that all standard quantum divergences select the same retrodictive update, yielding a unique and divergence-independent quantum Bayesian inverse for any POVM and prior state. Using this update, we construct a symmetric joint distribution for pairs of POVMs and introduce the mutual retrodictability, for which we also derive a general upper bound that depends only on the prior state and holds for all measurements. This structure leads to two retrodictive entropic uncertainty relations, expressed directly in terms of the prior state and the POVMs, but valid independently of the retrodictive framework and fully compatible with the conventional operational interpretation of entropic uncertainty relations. Finally, we benchmark these relations numerically and find that they provide consistently tighter bounds than existing entropic uncertainty relations over broad classes of measurements and states."}
{"id": "2511.20411", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.20411", "abs": "https://arxiv.org/abs/2511.20411", "authors": ["Wouter J. A. van Weerelt", "Lantian Zhang", "Silun Zhang", "Nicola Bastianello"], "title": "Self-Identifying Internal Model-Based Online Optimization", "comment": null, "summary": "In this paper, we propose a novel online optimization algorithm built by combining ideas from control theory and system identification. The foundation of our algorithm is a control-based design that makes use of the internal model of the online problem. Since such prior knowledge of this internal model might not be available in practice, we incorporate an identification routine that learns this model on the fly. The algorithm is designed starting from quadratic online problems but can be applied to general problems. For quadratic cases, we characterize the asymptotic convergence to the optimal solution trajectory. We compare the proposed algorithm with existing approaches, and demonstrate how the identification routine ensures its adaptability to changes in the underlying internal model. Numerical results also indicate strong performance beyond the quadratic setting."}
{"id": "2511.20304", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20304", "abs": "https://arxiv.org/abs/2511.20304", "authors": ["Hongfeng Liu", "Zizhao Han", "Xinfang Nie", "Zhenhuan Liu", "Dawei Lu"], "title": "Realizing Universal Non-Markovian Noise Suppression", "comment": "20 pages, 17 figures, comments are welcome", "summary": "Non-Markovian noise, arising from environmental memory effects, is the most general and challenging form of noise in quantum computing, and is typically difficult to characterize and suppress. Here, we analyze and experimentally demonstrate a non-Markovian noise suppression scheme inspired by quantum purification protocols. We theoretically prove that, even without noise calibration and assumptions on specific noise models, the scheme can exponentially reduce non-Markovian error rates with respect to the ancillary system size. We implement the protocol using nuclear spins, demonstrating that non-Markovian noise can be suppressed for both unitary operations and non-unitary channels. The observed fidelities and process tomography show close agreement with theoretical predictions, confirming the practicality and effectiveness of the scheme."}
{"id": "2511.20355", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20355", "abs": "https://arxiv.org/abs/2511.20355", "authors": ["Minh T. P. Nguyen", "Mackenzie H. Shaw"], "title": "Fault-Tolerant Non-Clifford GKP Gates using Polynomial Phase Gates and On-Demand Noise Biasing", "comment": "43 pages, 8 figures", "summary": "The Gottesman-Kitaev-Preskill (GKP) error correcting code uses a bosonic mode to encode a logical qubit, and has the attractive property that its logical Clifford gates can be implemented using Gaussian unitary gates. In contrast, a direct unitary implementation of the ${T}$ gate using the cubic phase gate has been shown to have logical error floor unless the GKP codestate has a biased noise profile [1]. In this work, we propose a method for on-demand noise biasing based on a standard GKP error correction circuit. This on-demand biasing circuit can be used to bias the GKP codestate before a $T$ gate and return it to a non-biased state afterwards. With the on-demand biasing circuit, we prove that the logical error rate of the $T$ gate can be made arbitrarily small as the quality of the GKP codestates increases. We complement our proof with a numerical investigation of the cubic phase gate subject to a phenomenological noise model, showing that the ${T}$ gate can achieve average gate fidelities above $99\\%$ with 12 dB of GKP squeezing without the use of postselection. Moreover, we develop a formalism for finding optimal unitary representations of logical diagonal gates in higher levels of the Clifford hierarchy that is based on a framework of ``polynomial phase stabilizers'' whose exponents are polynomial functions of one of the quadrature operators. This formalism naturally extends to multi-qubit logical gates and even to number-phase bosonic codes, providing a powerful algebraic tool for analyzing non-Clifford gates in bosonic quantum codes.\n  [1] J. Hastrup, M. V. Larsen, J. S. Neergaard-Nielsen, N. C. Menicucci, and U. L. Andersen, Phys. Rev. A 103, 032409 (2021)"}
{"id": "2511.20357", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20357", "abs": "https://arxiv.org/abs/2511.20357", "authors": ["Aryan Pratap Srivastava", "Moulik Deviprasad Ketkar", "Kuldeep Kumar Shrivastava", "Abhishek Maurya", "Biswanath Bhoi", "Rajeev Singh"], "title": "Proximity driven photon-tunneling in chiral quantum hybrid systems", "comment": null, "summary": "We investigate photon tunneling in a pair of coupled inverted circular split-ring microwave resonators with four discrete chiral orientations. By varying the spacing between the resonators, we observe strong modulation of the transmission spectra, including mode splitting, interference effects, and the formation of dark states. Measurements on fabricated devices show clear signatures of hybridization that depend on both chirality and proximity, and these results are consistent with full-wave electromagnetic simulations. To describe the observed behavior, we develop a circuit quantum electrodynamics model that captures the dependence of the coupling strength on geometry and the reversal of its sign. Although the experimental excitation is classical, the system reproduces features expected from two quantized harmonic oscillators, providing a classical analogue of a chiral quantum hybrid platform. The ability to control photon tunneling through structural design and excitation parameters suggests potential applications in reconfigurable photonic devices, quantum communication, chiral sensing, and polarization-selective signal processing."}
{"id": "2511.20371", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20371", "abs": "https://arxiv.org/abs/2511.20371", "authors": ["Arnab Mukherjee", "Soham Sen", "Sunandan Gangopadhyay"], "title": "Quantum coherence measures in entangled atomic systems", "comment": "10 Pages LATEX, comments are welcome. OTM", "summary": "In this study, we investigate the effect of the Lorentz transformation on the measures of quantum coherence in an entangled atomic system. Here, we consider the effect of this relativistic boosts on two-particle entangled generalized Gaussian wave packets in two scenarios. In the first scenario, we consider that the relativistic boost affects the one particle and other remains unaffected while in the second scenario, we consider that both the particles are affected by the effect of the relativistic boost. The coherence of the wave function as measured by the boosted observer is studied as a function of the boost parameter and the width of the Gaussian wave packets. Using various formulations of coherence, it is shown that in general the coherence decays with increase in the width of the Gaussian wave packet, higher values of boost parameter, and the number of particles on which boost is applied."}
{"id": "2511.20388", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.20388", "abs": "https://arxiv.org/abs/2511.20388", "authors": ["Joseph Vovrosh", "Tiago Mendes-Santos", "Hadriel Mamann", "Kemal Bidzhiev", "Fergus Hayes", "Bruno Ximenez", "Lucas Béguin", "Constantin Dalyac", "Alexandre Dauphin"], "title": "Resource assessment of classical and quantum hardware for post-quench dynamics", "comment": "10 (+5) pages, 6 (+3) figures", "summary": "We estimate the run-time and energy consumption of simulating non-equilibrium dynamics on neutral atom quantum computers in analog mode, directly comparing their performance to state-of-the-art classical methods, namely Matrix Product States and Neural Quantum States. By collecting both experimental data from a quantum processing unit (QPU) in analog mode and numerical benchmarks, we enable accurate predictions of run-time and energy consumption for large-scale simulations on both QPUs and classical systems through fitting of theoretical scaling laws. Our analysis shows that neutral atom devices are already operating in a competitive regime, achieving comparable or superior performance to classical approaches while consuming significantly less energy. These results demonstrate the potential of analog neutral atom quantum computing for energy-efficient simulation and highlight a viable path toward sustainable computational strategies."}
{"id": "2511.20404", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20404", "abs": "https://arxiv.org/abs/2511.20404", "authors": ["Aritra Ghosh", "Adam Miranowicz", "Miloslav Znojil"], "title": "Twin Hamiltonians, three types of the Dyson maps, and the probabilistic interpretation problem in quasi-Hermitian quantum mechanics", "comment": "19 pp., written in honor of our friend, professor Jean-Pierre Gazeau, on the occasion of his 80th birthday", "summary": "In quasi-Hermitian quantum mechanics (QHQM) of unitary systems, an optimal, calculation-friendly form of Hamiltonian is generally non-Hermitian, $H \\neq H^\\dagger$. This makes its physical interpretation ambiguous. Without altering $H$, this ambiguity is resolved by specifying a nontrivial inner-product metric $Θ$ in Hilbert space. Here, we focus on an alternative strategy: transforming $H$ into a Hermitian form via the Dyson map $Ω: H \\to \\mathfrak{h}$. This construction of the Hermitian isospectral twin $\\mathfrak{h}$ of $H$ does not only restore the conventional correspondence principle between quantum and classical physics, but it also provides a framework for the exhaustive classification of all admissible probabilistic interpretations of quantum systems in QHQM framework."}
{"id": "2511.20628", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20628", "abs": "https://arxiv.org/abs/2511.20628", "authors": ["Maxwell Tang", "Garrett Hinkley", "Kenneth Goodenough", "Stefan Krastanov", "Guus Avis"], "title": "Routing in Non-Isotonic Quantum Networks", "comment": "21 pages, 14 figures", "summary": "Optimal routing in quantum-repeater networks requires finding the best path that connects a pair of end nodes. Most previous work on routing in quantum networks assumes utility functions that are isotonic, meaning that the ordering of two paths does not change when extending both with the same edge. However, we show that utility functions that take into account both the rate and quality of the entanglement generation (e.g., the secret-key rate) are often non-isotonic. This makes pathfinding difficult as classical algorithms such as Dijkstra's become unsuitable, with the state of the art for quantum networks being an exhaustive search over all possible paths. In this work we present improved algorithms. First, we present two best-first-search algorithms that use destination-aware merit functions for faster convergence. One of these provably finds the best path, while the other uses heuristics to achieve an effectively sublinear scaling of the query count in the network size while in practice always finding a close-to-optimal path. Second, we present metaheuristic algorithms (simulated annealing and a genetic algorithm) that enable tuning a tradeoff between path quality and computational overhead. While we focus on swap-ASAP quantum repeaters for concreteness, our algorithms are readily generalized to different repeater schemes and models."}
{"id": "2511.19589", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.19589", "abs": "https://arxiv.org/abs/2511.19589", "authors": ["Zhi-Qiang Gao", "Chunxiao Liu", "Joel E. Moore"], "title": "Topological BF Theory construction of twisted dihedral quantum double phases from spontaneous symmetry breaking", "comment": "4.5+10 pages, 2+3 figures", "summary": "Nonabelian topological orders host exotic anyons central to quantum computing, yet established realizations rely on case-by-case constructions that are often conceptually involved. In this work, we present a systematic construction of nonabelian dihedral quantum double phases based on a continuous $O(2)$ gauge field. We first formulate a topological $S[O(2)\\times O(2)]$ BF theory, and by identifying the Wilson loops and twist operators of this theory with anyons, we show that our topological BF theory reproduces the complete anyon data, and can incorporate all Dijkgraaf--Witten twists. Building on this correspondence, we present a microscopic model with $O(2)$ lattice gauge field coupled to Ising and rotor matter whose Higgsing yields the desired dihedral quantum double phase. A perturbative renormalization group analysis further indicates a direct transition from this phase to a $U(1)$ Coulomb or chiral topological phase at a stable multicritical point with emergent $O(3)$ symmetry. Our proposal offers an alternative route to nonabelian topological order with promising prospects in synthetic gauge field platforms."}
{"id": "2511.20161", "categories": ["physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20161", "abs": "https://arxiv.org/abs/2511.20161", "authors": ["Maksim Radionov", "Daria Popova-Gorelova"], "title": "Attosecond momentum-resolved resonant inelastic x-ray scattering for imaging coupled electron-hole dynamics", "comment": null, "summary": "Improving our understanding of electron dynamics is essential for advancing energy transfer, optoelectronics, light harvesting systems and quantum computing. Recent developments in attosecond x-ray sources provide the fundamental possibility of observing these dynamics with atomic-scale resolution. However, connecting a time-resolved signal to dynamics is challenging due to the broad bandwidth of an attosecond probe pulse. This makes exploring the capabilities of different attosecond imaging techniques crucial. Here, we propose attosecond momentum-resolved resonant inelastic x-ray scattering as a prominent technique for tracking ultrafast dynamics. We demonstrate that the scattering signal contains an information about the instantaneous distribution of charge density across the scattering atoms. To illustrate this, we consider scattering from an $α$-sexithiophene molecule, in which coupled electron-hole dynamics are excited."}
{"id": "2511.20261", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.20261", "abs": "https://arxiv.org/abs/2511.20261", "authors": ["Xiang Li", "Xiangjian Qian", "Mingpu Qin"], "title": "Disentangling Kitaev Quantum Spin Liquid", "comment": null, "summary": "In this work, we investigate the Kitaev honeycomb model employing the recently developed Clifford Circuits Augmented Matrix Product States (CAMPS) method. While the model in the gapped phase is known to reduce to the toric code model - whose ground state is entirely constructible from Clifford circuits - we demonstrate that the very different gapless quantum spin liquid (QSL) phase can also be significantly disentangled with Clifford circuits. Specifically, CAMPS simulations reveal that approximately two-thirds of the entanglement entropy in the isotropic point arises from Clifford-circuit contributions, enabling dramatically more efficient computations compared to conventional matrix product state (MPS) methods. Crucially, this finding implies that the Kitaev QSL state retains significant Clifford-simulatable structure, even in the gapless phase with non-abelian anyon excitations when time reversal symmetry is broken. This property not only enhances classical simulation efficiency significantly but also suggests substantial resource reduction for preparing such states on quantum devices. As an application, we leverage CAMPS to study the Kitaev-Heisenberg model and determine the most accurate phase boundary between the anti-ferromagnetic phase and the Kitaev QSL phase in the model. Our results highlight how Clifford circuits can effectively disentangle the intricate entanglement of Kitaev QSLs, opening avenues for efficiently simulating related and similar strongly correlated models."}
