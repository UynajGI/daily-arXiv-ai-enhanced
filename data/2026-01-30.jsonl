{"id": "2601.20926", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20926", "abs": "https://arxiv.org/abs/2601.20926", "authors": ["Hyunsoo Ha", "David A. Huse", "Rhine Samajdar"], "title": "Quench spectroscopy of amplitude modes in a one-dimensional critical phase", "comment": "7+16 pages, 3+5 figures", "summary": "We investigate the emergence of an amplitude (Higgs-like) mode in the gapless phase of the $(1+1)$D XXZ spin chain. Unlike conventional settings where amplitude modes arise from spontaneous symmetry breaking, here, we identify a symmetry-preserving underdamped excitation on top of a Luttinger-liquid ground state. Using nonequilibrium quench spectroscopy, we demonstrate that this mode manifests as oscillations of U(1)-symmetric observables following a sudden quench. By combining numerical simulations with Bethe-ansatz analyses, we trace its microscopic origin to specific families of string excitations. We further discuss experimental pathways to detect this mode in easy-plane quantum magnets and programmable quantum simulators. Our results showcase the utility of quantum quenches as a powerful tool to probe collective excitations, beyond the scope of linear response."}
{"id": "2601.20935", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.20935", "abs": "https://arxiv.org/abs/2601.20935", "authors": ["Ruizhi Liu", "Pok Man Tam", "Ho Tat Lam", "Liujun Zou"], "title": "When does a lattice higher-form symmetry flow to a topological higher-form symmetry at low energies?", "comment": "Main: 14 pages, 6 figures. Supplement: 3 appendices", "summary": "We study the lattice version of higher-form symmetries on tensor-product Hilbert spaces. Interestingly, at low energies, these symmetries may not flow to the topological higher-form symmetries familiar from relativistic quantum field theories, but instead to non-topological higher-form symmetries. We present concrete lattice models exhibiting this phenomenon. One particular model is an $\\mathbb{R}$ generalization of the Kitaev honeycomb model featuring an $\\mathbb{R}$ lattice 1-form symmetry. We show that its low-energy effective field theory is a gapless, non-relativistic theory with a non-topological $\\mathbb{R}$ 1-form symmetry. In both the lattice model and the effective field theory, we demonstrate that the non-topological $\\mathbb{R}$ 1-form symmetry is not robust against local perturbations. In contrast, we also study various modifications of the toric code and their low-energy effective field theories to demonstrate that the compact $\\mathbb{Z}_2$ lattice 1-form symmetry does become topological at low energies unless the Hamiltonian is fine-tuned. Along the way, we clarify the rules for constructing low-energy effective field theories in the presence of multiple superselection sectors. Finally, we argue on general grounds that non-compact higher-form symmetries (such as $\\mathbb{R}$ and $\\mathbb{Z}$ 1-form symmetries) in lattice systems generically remain non-topological at low energies, whereas compact higher-form symmetries (such as $\\mathbb{Z}_{n}$ and $U(1)$ 1-form symmetries) generically become topological."}
{"id": "2601.20945", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.20945", "abs": "https://arxiv.org/abs/2601.20945", "authors": ["Wenjie Ji", "Ryan A. Lanzetta", "Zheng Zhou", "Chong Wang"], "title": "Self-dual Higgs transitions: Toric code and beyond", "comment": "5+4 pages", "summary": "The toric code, when deformed in a way that preserves the self-duality $\\mathbb{Z}_2$ symmetry exchanging the electric and magnetic excitations, admits a transition to a topologically trivial state that spontaneously breaks the $\\mathbb{Z}_2$ symmetry. Numerically, this transition was found to be continuous, which makes it particularly enigmatic given the longstanding absence of a continuum field-theoretic description. In this work we propose such a continuum field theory for the transition dubbed the $SO(4)_{2,-2}$ Chern-Simons-Higgs (CSH) theory. We show that our field theory provides a natural \"mean-field\" understanding of the phase diagram. Moreover, it can be generalized to an entire series of theories, namely the $SO(4)_{k,-k}$ CSH theories, labeled by an integer $k$. For each $k>2$, the theory describes an analogous transition involving different non-Abelian topological orders, such as the double Fibonacci order ($k=3$) and the $S_3$ quantum double ($k=4$). For $k=1$, we conjecture that the corresponding CSH transition is in fact infrared-dual to the $3d$ Ising transition, in close analogy with the particle-vortex duality of a complex scalar."}
{"id": "2601.20963", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.20963", "abs": "https://arxiv.org/abs/2601.20963", "authors": ["Seongjun Park", "Sung-Min Park", "Yun-Tak Oh", "Hyun-Yong Lee", "Eun-Gook Moon"], "title": "Spin-orbit-induced Instability and Finite-Temperature Stabilization of a Triangular-lattice Supersolid", "comment": "8 pages, 5 figures", "summary": "Geometrically frustrated triangular-lattice magnets provide fertile ground for realizing intriguing quantum phases such as spin supersolids. A common expectation is that spin-orbit coupling (SOC), which breaks continuous spin rotational symmetry, destabilizes these phases by gapping their low-energy modes. Revisiting this assumption, we map out the SOC-field phase diagram of a frustrated triangular-lattice magnet using spin-wave theory and infinite density-matrix renormalization group (iDMRG) simulations. We find that while infinitesimally weak SOC indeed drives a zero-temperature instability of the supersolid by opening a gap, certain supersolid states remain thermodynamically stable at non-zero temperatures. This reveals a previously unrecognized mechanism in which thermal fluctuations counteract SOC to stabilize supersolidity. The resulting finite-temperature supersolids retain key responses, including a giant magnetocaloric effect, highlighting their potential relevance to real materials. At larger SOC, the system transitions into distinct magnetic orders, including a skyrmion lattice, completing a unified phase diagram."}
{"id": "2601.21392", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.21392", "abs": "https://arxiv.org/abs/2601.21392", "authors": ["Chunpeng Du", "Zongyang Li", "Yali Zhang", "Yikang Lu", "Attila Szolnoki"], "title": "Shaping the learning signal in a combined Q-learning rule to improve structured cooperation", "comment": "11 pages, 7 figures", "summary": "Q-learning provides a standard reinforcement learning framework for studying cooperation by specifying how agents update action values from repeated local interactions outcomes. Although previous work has shown that reputation can promote cooperation in such systems, most models introduce reputation by modifying payoffs, encoding it directly in the state or changing partner selection, which makes it difficult to isolate the role of the learning signal itself. Here, we construct the reinforcement signal as a weighted combination of reputation and game payoffs, leaving the game and network structure unchanged. We find that increasing the weight on reputation generally promotes cooperation by consolidating clusters, but this effect is conditional on the learning dynamics. Specifically, this promoting effect vanishes in two regimes: when the learning rate is extremely small, which prevents effective information propagation and when the discount factor approaches one, as distant future expectations obscure the immediate reputational advantage. Outside these limiting cases, the efficacy of reputation in promoting cooperation is attenuated by higher learning rates but amplified by larger discount factors. These results advance the understanding of cooperative dynamics by demonstrating that cooperation can be stabilized through the reputational shaping of learning signals alone, providing critical insights into the interplay between social information and individual learning parameters."}
{"id": "2601.21117", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.21117", "abs": "https://arxiv.org/abs/2601.21117", "authors": ["Daniel Köglmayr", "Miralem Spahic", "Andrew Flynn", "Christoph Räth"], "title": "Two-shot learning of multiple strange attractors", "comment": null, "summary": "The brain combines short- and long-term memory to process, store, and recall multiple different pieces of information. Inspired by this and recent results on multifunctional and parameter-aware learning, we extend a new machine learning technique that combines short- and long-term memory units, specifically, a system consisting of a next-generation reservoir computer (NGRC) and extremely randomized trees (ERT), to process, store, and recall multiple different strange attractors. We train the combined NGRC+ERT system using a two-shot learning approach which significantly improves performance by filtering out unnecessary features, thereby avoiding extensive hyperparameter optimization. We first show that an NGRC+ERT system achieves highly accurate reconstruction of the short- and long-term dynamics of both the Lorenz and Halvorsen chaotic attractors when using an exponential filtering scheme. We validate these finding by training the NGRC+ERT system to reconstruct different pairs of attractors and also a greater number of attractors. We focus on the task of training a single NGRC+ERT system to reconstruct 16 different attractors and show that sufficient index-based separation in feature space suppresses unwanted switching dynamics, thus stabilizing long-term memory recall. Finally, we identify that defects in short-term memory processing can provoke failure modes in long-term memory recall resulting in confabulation."}
{"id": "2601.20931", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall", "cond-mat.quant-gas", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.20931", "abs": "https://arxiv.org/abs/2601.20931", "authors": ["Pasquale Marra"], "title": "Hidden localization transitions in generalized Aubry-André models", "comment": "7 pages, 2 figures", "summary": "Anderson localization is a phase transition between a metallic phase, where wavefunctions are extended and delocalized in space, and an insulating phase, where wavefunctions are completely localized. These transitions are driven by uncorrelated disorder or quasiperiodic disorder, e.g., in the case of the Aubry-André model. Here, I consider a family of Hamiltonians that generalizes the Aubry-André model obtained when position and momentum operators are replaced by an arbitrary couple of canonically conjugate operators. In these models, a hidden localization transition occurs between metallic/insulating phases with wavefunctions delocalized/localized with respect to one of the two canonically conjugate operators. If the canonically conjugate operators coincide with a linear combination of position and momentum, the phase transition is signaled by a zero in the normalized participation ratio in the usual position space. Surprisingly, I found that at the phase transition, this model Hamiltonian coincides with the lattice Hamiltonian of a massless Dirac fermion in a curved spacetime background, indicating an unexpected relation between many-body localization and analog gravity."}
{"id": "2601.21019", "categories": ["math.ST", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21019", "abs": "https://arxiv.org/abs/2601.21019", "authors": ["Markus Holzleitner", "Sergiy Pereverzyev", "Sergei V. Pereverzyev", "Vaibhav Silmana", "S. Sivananthan"], "title": "Towards regularized learning from functional data with covariate shift", "comment": "38 pages", "summary": "This paper investigates a general regularization framework for unsupervised domain adaptation in vector-valued regression under the covariate shift assumption, utilizing vector-valued reproducing kernel Hilbert spaces (vRKHS). Covariate shift occurs when the input distributions of the training and test data differ, introducing significant challenges for reliable learning. By restricting the hypothesis space, we develop a practical operator learning algorithm capable of handling functional outputs. We establish optimal convergence rates for the proposed framework under a general source condition, providing a theoretical foundation for regularized learning in this setting. We also propose an aggregation-based approach that forms a linear combination of estimators corresponding to different regularization parameters and different kernels. The proposed approach addresses the challenge of selecting appropriate tuning parameters, which is crucial for constructing a good estimator, and we provide a theoretical justification for its effectiveness. Furthermore, we illustrate the proposed method on a real-world face image dataset, demonstrating robustness and effectiveness in mitigating distributional discrepancies under covariate shift."}
{"id": "2601.21039", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21039", "abs": "https://arxiv.org/abs/2601.21039", "authors": ["Jingguan Liu", "Cong Chen", "Xiaomeng Ai", "Jiakun Fang", "Jinsong Wang", "Jinyu Wen"], "title": "Mean-Field Learning for Storage Aggregation", "comment": "14 pages, 6 figures", "summary": "Distributed energy storage devices can be pooled and coordinated by aggregators to participate in power system operations and market clearings. This requires representing a massive device population as a single, tractable surrogate that is computationally efficient, accurate, and compatible with market participation requirements. However, surrogate identification is challenging due to heterogeneity, nonconvexity, and high dimensionality of storage devices. To address these challenges, this paper develops a mean-field learning framework for storage aggregation. We interpret aggregation as the average behavior of a large storage population and show that, as the population grows, aggregate performance converges to a unique, convex mean-field limit, enabling tractable population-level modeling. This convexity further yields a price-responsive characterization of aggregate storage behavior and allows us to bound the mean-field approximation error. Leveraging these results, we construct a convex surrogate model that approximates the aggregate behavior of large storage populations and can be embedded directly into power system operations and market clearing. Surrogate parameter identification is formulated as an optimization problem using historical market price-response data, and we adopt a gradient-based algorithm for efficient learning procedure. Case studies validate the theoretical findings and demonstrate the effectiveness of the proposed framework in approximation accuracy, data efficiency, and profit outcomes."}
{"id": "2601.21024", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.21024", "abs": "https://arxiv.org/abs/2601.21024", "authors": ["L. Stödter", "C. Kastner", "H. O. Jeschke", "M. Reehuis", "K. Beauvois", "B. Ouladdiaf", "E. Chan", "F. Yokaichiya", "F. Bert", "T. J. Hicken", "J. A. Krieger", "H. Luetkens", "J. L. Allen", "R. Feyerherm", "M. Tovar", "D. Menzel", "A. U. B. Wolter", "B. Büchner", "K. C. Rule", "F. J. Litterst", "U. K. Rößler", "S. Süllow"], "title": "Competing Ordering Modes in the Distorted Quantum Kagome Material Clinoatacamite Cu$_2$Cl(OH)$_3$", "comment": null, "summary": "We have studied the magnetic properties of clinoatacamite Cu$_2$Cl(OH)$_3$, the parent compound of the quantum spin liquid candidate herbertsmithite and a longstanding puzzle among frustrated quantum magnets. As we reveal using density-functional theory, clinoatacamite belongs to the class of distorted kagome antiferromagnets with the kagome plane being embedded into a low-symmetry crystal structure. By means of thermodynamic measurements, muon spin rotation/relaxation as well as neutron diffraction on single crystals, we find a complex sequence of phases/regions below 18.1 K in zero magnetic field. We propose this complexity in multicritical clinoatacamite to arise from the competition of antiferromagnetic ordering modes from the underconstrained manifold of modes, which can lead to a metamagnetic texture in zero magnetic field."}
{"id": "2601.21724", "categories": ["physics.soc-ph", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.21724", "abs": "https://arxiv.org/abs/2601.21724", "authors": ["Simon Woodruff"], "title": "A costing framework for fusion power plants", "comment": null, "summary": "This paper summarizes and consolidates fusion power-plant costing work performed in support of ARPA-E from 2017 through 2024, and documents the evolution of the associated analysis framework from early capital-cost-focused studies to a standards-aligned, auditable costing capability. Early efforts applied ARIES-style cost-scaling relations to generate Nth-of-a-kind (NOAK) estimates and were calibrated through a pilot study with Bechtel and Decysive Systems to benchmark balance-of-plant (BOP) costs and validate plant-level reasonableness from an engineering, procurement, and construction (EPC) perspective. Subsequent work, informed by Lucid Catalyst studies of nuclear cost drivers, expanded the methodology to treat indirect costs explicitly and to evaluate cost-reduction pathways for non-fusion-island systems through design-for-cost practices, modularization, centralized manufacturing, and learning. As ARPA-E's fusion portfolio expanded, these methods were applied across BETHE and GAMOW concepts (and select ALPHA revisits), including enhanced treatment of tritium handling and plant integration supported by Princeton/PPPL expertise. In 2023 the capability was refactored to align with the IAEA-GEN-IV EMWG-EPRI code-of-accounts lineage, while key ARIES-derived scaling relations were replaced by bottom-up subsystem models for dominant fusion cost drivers (e.g., magnets, lasers, power supplies, and power-core components) coupled to physics-informed power balances and engineering-constrained radial builds. These developments were implemented in the spreadsheet-based Fusion Economics code (FECONs) and released as an open-source Python framework (pyFECONs), providing a transparent mapping from subsystem estimates to standardized accounts and a consistent computation of LCOE."}
{"id": "2601.21510", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.21510", "abs": "https://arxiv.org/abs/2601.21510", "authors": ["David Valle", "Alexandre Wagemakers", "Miguel A. F. Sanjuán"], "title": "From Basins to safe sets: a machine learning perspective on chaotic dynamics", "comment": "Chaos control, machine learning, neural networks, basins of attraction, transient chaos", "summary": "The study of chaos has long relied on computationally intensive methods to quantify unpredictability and design control strategies. Recent advances in machine learning, from convolutional neural networks to transformer architectures, provide new ways to analyze complex phase space structures and enable real time action in chaotic dynamics. In this perspective article, we highlight how data driven approaches can accelerate classical tasks such as estimating basin characterization metrics, or partial control of transient chaos, while opening new possibilities for scalable and robust interventions in chaotic systems. In recent studies, convolutional networks have reproduced classical basin metrics with negligible bias and low computational cost, while transformer based surrogates have computed accurate safety functions within seconds, bypassing the recursive procedures required by traditional methods. We discuss current opportunities, remaining challenges, and future directions at the intersection of nonlinear dynamics and artificial intelligence."}
{"id": "2507.08533", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "nlin.CD", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2507.08533", "abs": "https://arxiv.org/abs/2507.08533", "authors": ["Shu Zhou", "K. Y. Michael Wong", "Juntao Wang", "David Shui Wing Hui", "Daniel Ebler", "Jie Sun"], "title": "Phase analysis of Ising machines and their implications on optimization", "comment": "5 pages, 4 figures", "summary": "Ising machines, which are dynamical systems designed to operate in a parallel and iterative manner, have emerged as a new paradigm for solving combinatorial optimization problems. Despite computational advantages, the quality of solutions depends heavily on the form of dynamics and tuning of parameters, which are in general set heuristically due to the lack of systematic insights. Here, we focus on optimal Ising machine design by analyzing phase diagrams of spin distributions in the Sherrington-Kirkpatrick model. We find that that the ground state can be achieved in the phase where the spin distribution becomes binary, and optimal solutions are produced where the binary phase and gapless phase coexist. Our analysis shows that such coexistence phase region can be expanded by carefully placing a digitization operation, giving rise to a family of superior Ising machines, as illustrated by the proposed algorithm digCIM."}
{"id": "2601.21131", "categories": ["math.ST", "cs.IT", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21131", "abs": "https://arxiv.org/abs/2601.21131", "authors": ["Qiyang Han"], "title": "Thompson sampling: Precise arm-pull dynamics and adaptive inference", "comment": null, "summary": "Adaptive sampling schemes are well known to create complex dependence that may invalidate conventional inference methods. A recent line of work shows that this need not be the case for UCB-type algorithms in multi-armed bandits. A central emerging theme is a `stability' property with asymptotically deterministic arm-pull counts in these algorithms, making inference as easy as in the i.i.d. setting.\n  In this paper, we study the precise arm-pull dynamics in another canonical class of Thompson-sampling type algorithms. We show that the phenomenology is qualitatively different: the arm-pull count is asymptotically deterministic if and only if the arm is suboptimal or is the unique optimal arm; otherwise it converges in distribution to the unique invariant law of an SDE. This dichotomy uncovers a unifying principle behind many existing (in)stability results: an arm is stable if and only if its interaction with statistical noise is asymptotically negligible.\n  As an application, we show that normalized arm means obey the same dichotomy, with Gaussian limits for stable arms and a semi-universal, non-Gaussian limit for unstable arms. This not only enables the construction of confidence intervals for the unknown mean rewards despite non-normality, but also reveals the potential of developing tractable inference procedures beyond the stable regime.\n  The proofs rely on two new approaches. For suboptimal arms, we develop an `inverse process' approach that characterizes the inverse of the arm-pull count process via a Stieltjes integral. For optimal arms, we adopt a reparametrization of the arm-pull and noise processes that reduces the singularity in the natural SDE to proving the uniqueness of the invariant law of another SDE. We prove the latter by a set of analytic tools, including the parabolic Hörmander condition and the Stroock-Varadhan support theorem."}
{"id": "2601.21046", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21046", "abs": "https://arxiv.org/abs/2601.21046", "authors": ["Jason Lu", "Tejas Santanam", "Hongzhao Guan", "Connor Riley", "Meen-Sung Kim", "Anthony Trasatti", "Neda Masoud", "Pascal Van Hentenryck"], "title": "The Impact of Shared Autonomous Vehicles in Microtransit Systems: A Case Study in Atlanta", "comment": null, "summary": "Microtransit systems represent an enhancement to solve the first- and last-mile problem, integrating traditional rail and bus networks with on-demand shuttles into a flexible, integrated system. This type of demand responsive transport provides greater accessibility and higher quality levels of service compared to conventional fixed-route transit services. Advances in technology offer further opportunities to enhance microtransit performance. In particular, shared autonomous vehicles (SAVs) have the potential to transform the mobility landscape by enabling more sustainable operations, enhanced user convenience, and greater system reliability. This paper investigates the integration of SAVs in microtransit systems, advancing the technological capabilities of on-demand shuttles. A shuttle dispatching optimization model is enhanced to accommodate for driver behavior and SAV functionalities. A model predictive control approach is proposed that dynamically rebalances on-demand shuttles towards areas of higher demand without relying on vast historical data. Scenario-driven experiments are conducted using data from the MARTA Reach microtransit pilot. The results demonstrate that SAVs can elevate both service quality and user experience compared to traditional on-demand shuttles in microtransit systems."}
{"id": "2601.21178", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2601.21178", "abs": "https://arxiv.org/abs/2601.21178", "authors": ["Ryan Bignell", "Gert Aarts", "Chris Allton", "Benjamin Jäger", "Seyong Kim", "Jon-Ivar Skullerud", "Antonio Smecca"], "title": "$U(1)_A$ symmetry restoration at finite temperature with mesonic correlators", "comment": "10 pages, 4 figures, 1 table. Proceedings of the 42nd International Symposium on Lattice Field Theory (Lattice 2025), TIFR Mumbai, India, 2025", "summary": "The $U(1)_A$ symmetry of the massless QCD Lagrangian is explicitly broken in the quantised theory by the anomaly. It may be effectively restored at some finite temperature, which would have important consequences for the order of the chiral transition and the QCD phase diagram. It has been argued in the literature that one way to probe the effective restoration of $U(1)_A$ is to check for the degeneracy of pseudoscalar and flavour non-singlet scalar correlators. In this work, we consider a new method of examining this degeneracy based upon hadron correlation functions on the anisotropic FASTSUM ensembles. The anisotropic nature and our newest Generation 3 ensembles aid in a determination of the effective restoration of the $U(1)_A$ symmetry which we find to be $T_{U(1)_A} \\sim 320$ MeV, well above the chiral transition temperature, which is $T_{\\rm pc} \\sim 180$ MeV for our choice of Wilson-Clover fermions."}
{"id": "2601.21632", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.21632", "abs": "https://arxiv.org/abs/2601.21632", "authors": ["Shaina Raza", "Iuliia Eyriay", "Ahmed Y. Radwan", "Nate Lesperance", "Deval Pandya", "Sedef Akinli Kocak", "Graham W. Taylor"], "title": "Sustainable Open-Source AI Requires Tracking the Cumulative Footprint of Derivatives", "comment": null, "summary": "Open-source AI is scaling rapidly, and model hubs now host millions of artifacts. Each foundation model can spawn large numbers of fine-tunes, adapters, quantizations, merges, and forks. We take the position that compute efficiency alone is insufficient for sustainability in open-source AI: lower per-run costs can accelerate experimentation and deployment, increasing aggregate environmental footprint unless impacts are measurable and comparable across derivative lineages. However, the energy use, water consumption, and emissions of these derivative lineages are rarely measured or disclosed in a consistent, comparable manner, leaving ecosystem-level impact largely invisible. We argue that sustainable open-source AI requires coordination infrastructure that tracks impacts across model lineages, not only base models. We propose Data and Impact Accounting (DIA), a lightweight, non-restrictive transparency layer that (i) standardizes carbon and water reporting metadata, (ii) integrates low-friction measurement into common training and inference pipelines, and (iii) aggregates reports through public dashboards to summarize cumulative impacts across releases and derivatives. DIA makes derivative costs visible and supports ecosystem-level accountability while preserving openness. https://vectorinstitute.github.io/ai-impact-accounting/"}
{"id": "2601.21004", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.21004", "abs": "https://arxiv.org/abs/2601.21004", "authors": ["Cyril Voyant"], "title": "A Tolerance-Based Framework for Spatio-Temporal Forecast Validation Using the gamma-Index", "comment": "9 pages, 3 figures", "summary": "Classical field forecast evaluation relies mainly on local scores such as RMSE or MAE. These metrics severely over-penalize small spatial or temporal displacements of coherent structures, a limitation known as the double-penalty issue and common to many forecasting domains. The present paper introduces a tolerance-based framework built on the three-dimensional gamma index, initially designed for medical dose verification, as a unified acceptance criterion for gridded forecasts. The method embeds explicit margins in space (DTA), time (TTA), and intensity (IDT), and evaluates whether predictions agree with observations within predefined physical bounds rather than through pixel-wise differences only. A synthetic illustration is first used to show why conventional metrics can misrepresent usable forecasts. The approach is then applied to satellite-derived SSI fields to demonstrate operational behaviour on a real dataset. Results confirm that the gamma criterion preserves structural consistency under minor positional noise while isolating physically significant discrepancies. The formulation is generic and can be implemented for any gridded variable provided meaningful tolerances are defined, offering a pragmatic complement to existing spatial verification tools in general forecasting workflows."}
{"id": "2601.22119", "categories": ["q-fin.CP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.22119", "abs": "https://arxiv.org/abs/2601.22119", "authors": ["Han Yang", "Dong Hao", "Zhuohan Wang", "Qi Shi", "Xingtong Li"], "title": "Alpha Discovery via Grammar-Guided Learning and Search", "comment": "24 pages, 10 figures", "summary": "Automatically discovering formulaic alpha factors is a central problem in quantitative finance. Existing methods often ignore syntactic and semantic constraints, relying on exhaustive search over unstructured and unbounded spaces. We present AlphaCFG, a grammar-based framework for defining and discovering alpha factors that are syntactically valid, financially interpretable, and computationally efficient. AlphaCFG uses an alpha-oriented context-free grammar to define a tree-structured, size-controlled search space, and formulates alpha discovery as a tree-structured linguistic Markov decision process, which is then solved using a grammar-aware Monte Carlo Tree Search guided by syntax-sensitive value and policy networks. Experiments on Chinese and U.S. stock market datasets show that AlphaCFG outperforms state-of-the-art baselines in both search efficiency and trading profitability. Beyond trading strategies, AlphaCFG serves as a general framework for symbolic factor discovery and refinement across quantitative finance, including asset pricing and portfolio construction."}
{"id": "2601.21299", "categories": ["cs.CE", "eess.SP", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.21299", "abs": "https://arxiv.org/abs/2601.21299", "authors": ["Tingyu Zhao", "István A. Kovács"], "title": "Collective Noise Filtering in Complex Networks", "comment": null, "summary": "Complex networks are powerful representations of complex systems across scales and domains, and the field is experiencing unprecedented growth in data availability. However, real-world network data often suffer from noise, biases, and missing data in the edge weights, which undermine the reliability of downstream network analyses. Standard noise filtering approaches, whether treating individual edges one-by-one or assuming a uniform global noise level, are suboptimal, because in reality both signal and noise can be heterogeneous and correlated across multiple edges. As a solution, we introduce the Network Wiener Filter, a principled method for collective edge-level noise filtering that leverages both network topology and noise characteristics, to reduce error in the observed edge weights and to infer missing edge weights. We demonstrate the broad practical efficacy of the Network Wiener Filter in two distinct settings, the genetic interaction network of the yeast S. cerevisiae and the Enron Corpus email network, noting compelling evidence of successful noise suppression in both applications. With the Network Wiener Filter, we advocate for a shift toward error-aware network science, one that embraces data imperfection as an inherent feature and learns to navigate it effectively."}
{"id": "2601.21030", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.21030", "abs": "https://arxiv.org/abs/2601.21030", "authors": ["Rafael T. Winkler", "Larissa Boie", "Yunpei Deng", "Matteo Savoini", "Serhane Zerdane", "Abhishek Nag", "Sabina Gurung", "Davide Soranzio", "Tim Suter", "Vladimir Ovuka", "Janine Zemp", "Elsa Abreu", "Simone Biasco", "Roman Mankowsky", "Edwin J. Divall", "Alexander R. Oggenfuss", "Mathias Sander", "Christopher Arrell", "Danylo Babich", "Henrik T. Lemke", "Urs Staub", "Jure Demsar", "Steven L. Johnson"], "title": "Ultrafast Decoherence of Charge Density Waves in K$_{0.3}$MoO$_{3}$", "comment": "14 pages, 6 figures, 1 table", "summary": "Recent works have suggested that transient suppression of a charge density wave (CDW) by an ultra-short excitation can lead to an inversion of the CDW phase. We experimentally investigate the dynamics of the CDW in K$_{0.3}$MoO$_{3}$ by time resolved x-ray diffraction after excitation with optical pulses. Our results indicate a transient inversion of the CDW phase close to the surface that evolves into a highly disordered state in less than one picosecond. Numerical simulations solving the Ginzburg-Landau equation including disorder from strong pinning defects reproduce our main observations. Our findings highlight the critical role of disorder in schemes for coherent control in condensed matter systems."}
{"id": "2601.21743", "categories": ["physics.soc-ph", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2601.21743", "abs": "https://arxiv.org/abs/2601.21743", "authors": ["Fabio Mazza", "Gabriele Ricci", "Francesca Colaiori", "Stefano Guarino", "Sandro Meloni", "Fabio Saracco"], "title": "Impact of behavioral heterogeneity on epidemic outcome and its mapping into effective network topologies", "comment": "13 pages, 7 figures", "summary": "Human behavior plays a critical role in shaping epidemic trajectories. During health crises, people respond in diverse ways in terms of self-protection and adherence to recommended measures, largely reflecting differences in how individuals assess risk. This behavioral variability induces effective heterogeneity into key epidemic parameters, such as infectivity and susceptibility. We introduce a minimal extension of the susceptible-infected-removed~(SIR) model, denoted HeSIR, that captures these effects through a simple bimodal scheme, where individuals may have higher or lower transmission--related traits. We derive a closed-form expression for the epidemic threshold in terms of the model parameters, and the network's degree distribution and homophily, defined as the tendency of like--risk individuals to preferentially interact. We identify a resurgence regime just beyond the classical threshold, where the number of infected individuals may initially decline before surging into large-scale transmission. Through simulations on homogeneous and heterogeneous network topologies we corroborate the analytical results and highlight how variations in susceptibility and infectivity influence the epidemic dynamics. We further show that, under suitable assumptions, the HeSIR model maps onto a standard SIR process on an appropriately modified contact network, providing a unified interpretation in terms of structural connectivity. Our findings quantify the effect of heterogeneous behavioral responses, especially in the presence of homophily, and caution against underestimating epidemic potential in fragmented populations, which may undermine timely containment efforts. The results also extend to heterogeneity arising from biological or other non-behavioral sources."}
{"id": "2601.21720", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.21720", "abs": "https://arxiv.org/abs/2601.21720", "authors": ["Federico J. Gonzalez"], "title": "Integrating prior knowledge in equation discovery: Interpretable symmetry-informed neural networks and symbolic regression via characteristic curves", "comment": null, "summary": "Data-driven equation discovery aims to reconstruct governing equations directly from empirical observations. A fundamental challenge in this domain is the ill-posed nature of the inverse problem, where multiple distinct mathematical models may yield similar errors, thus complicating model selection and failing to guarantee a unique representation of the underlying mechanisms. This issue can be addressed by incorporating inductive biases to constrain the search space and discard the undesirable models. The characteristic curves-based (CCs) framework offers a modular approach ideally suited to this aim. This approach is based on the specification of structural families that possess provable identifiability properties. Crucially, this framework enables practitioners to embed domain expertise directly into the learning process and facilitates the integration of diverse post-processing tools. In this work, we build upon the recent neural network implementation of this formalism (NN-CC), which benefits from the universal approximation capabilities of NNs. Specifically, we extend NN-CC by introducing two inductive biases: (i) symmetry constraints and (ii) post-processing with symbolic regression. Using a chaotic Duffing oscillator and a discontinuous stick-slip model under varying Gaussian noise levels, we show how these extensions systematically improve the discovery process. We also analyze the integration of sparse and symbolic regression (using SINDy and PySR) into the CC-based formalism. These extensions (SINDy-CC and SR-CC) consistently show improvements as prior information is incorporated. By enabling the integration of prior or hypothesized knowledge into the learning and post-processing stages, the CC-based formalism emerges as a promising candidate to address identifiability issues in purely data-driven methods, advancing the goal of interpretable and reliable system identification."}
{"id": "2601.21134", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21134", "abs": "https://arxiv.org/abs/2601.21134", "authors": ["Tobias Swann", "Adam Nahum"], "title": "Continuum mechanics of entanglement in noisy interacting fermion chains", "comment": "24 pages, 10 figures", "summary": "We develop an effective continuum description for information scrambling in a chain of randomly interacting Majorana fermions. The approach is based on the semiclassical treatment of the path integral for an effective spin chain that describes \"two-replica\" observables such as the entanglement purity and the OTOC. This formalism gives exact results for the entanglement membrane and for operator spreading in the limit of weak interactions. In this limit there is a large crossover lengthscale between free and interacting behavior, and this large lengthscale allows for a continuum limit and a controlled saddle-point calculation. The formalism is also somewhat different from that known from random unitary circuits. The entanglement membrane emerges as a kind of bound state of two travelling waves, and shows an interesting unbinding phenomenon as the velocity of the entanglement membrane approaches the butterfly velocity."}
{"id": "2601.21818", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.21818", "abs": "https://arxiv.org/abs/2601.21818", "authors": ["Cecilie Olesen Recke", "Sarah Lumpp", "Nataliia Kushnerchuk", "Janike Oldekop", "Jiayi Li", "Jane Ivy Coons", "Elina Robeva"], "title": "Identifiability in Graphical Discrete Lyapunov Models", "comment": "29 pages, 18 pages of appendix", "summary": "In this paper, we study discrete Lyapunov models, which consist of steady-state distributions of first-order vector autoregressive models. The parameter matrix of such a model encodes a directed graph whose vertices correspond to the components of the random vector. This combinatorial framework naturally allows for cycles in the graph structure. We focus on the fundamental problem of identifying the entries of the parameter matrix. In contrast to the classical setting, we assume non-Gaussian error terms, which allows us to use the higher-order cumulants of the model. In this setup, we show generic identifiability for directed acyclic graphs with self-loops at each vertex and show how to express the parameters as a rational function of the cumulants. Furthermore, we establish local identifiability for all directed graphs containing self loops at each vertex and no isolated vertices. Finally, we provide first results on the defining equations of the models, showing model equivalence for certain graphs and paving the way towards structure learning."}
{"id": "2601.21176", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21176", "abs": "https://arxiv.org/abs/2601.21176", "authors": ["Ruixing Ren", "Junhui Zhao", "Xiaoke Sun", "Shanjin Ni"], "title": "Towards Governance of Localized VANET: An Adjustable Degree Distribution Model", "comment": "This paper is 10 pages long, including 8 figures. It presents original research on VANET governance with an adjustable degree distribution model and has been submitted to IEEE Transactions on Information Forensics and Security", "summary": "Vehicular Ad-hoc Networks (VANETs) serve as a critical enabler for intelligent transportation systems. However, their practical deployment faces a core governance dilemma: the network topology requires a dynamic trade-off between robustness against targeted attacks and ensuring low-latency information transmission. Most existing models generate fixed degree distributions, lacking the ability to adapt autonomously to the demands of diverse traffic scenarios. To address this challenge, this paper innovatively proposes a schedulable degree distribution model for localized VANETs. The core of this model lies in introducing a hybrid connection mechanism. When establishing connections, newly joining nodes do not follow a single rule but instead collaboratively perform random attachment and preferential attachment. Through theoretical derivation and simulation validation, this study demonstrates that by adjusting the cooperative weighting between these two mechanisms, the overall network degree distribution can achieve a continuous and controllable transition between a uniform distribution and a power-law distribution. The former effectively disperses attack risks and enhances robustness, while the latter facilitates the formation of hub nodes, shortening transmission paths to reduce latency. Experimental results based on the real-world road network of Beijing indicate that this model can precisely regulate node connection heterogeneity, attack resistance, and average transmission path length through the reshaping of the underlying topology. This provides a forward-looking and practical governance paradigm for constructing next-generation VANETs capable of dynamically adapting to complex environments."}
{"id": "2601.21846", "categories": ["cs.ET", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.21846", "abs": "https://arxiv.org/abs/2601.21846", "authors": ["Konstantinos Varsos", "Adamantia Stamou", "George D. Stamoulis", "Vasillios A. Siris"], "title": "Optimal Energy-Aware Service Management in Future Networks with a Gamified Incentives Mechanism", "comment": null, "summary": "As energy demands surge across ICT infrastructures, service providers must engage users in sustainable practices while maintaining the Quality of Experience (QoE) at acceptable levels. In this paper, we introduce such an approach, leveraging gamified incentives and a model for user's acceptance on incentives, thus encouraging energy-efficient behaviors such as adaptive bitrate streaming. Each user is characterized by an environmental sensitivity factor and a private incentive threshold, shaping probabilistic responses to energy-saving offers. A serious-game mechanism based on positive behavioral reinforcement and rewards of the users, due to their inclusion in top-K and bottom-M rankings, fosters peer comparison and competition, thus transforming passive acceptance into active engagement. Moreover, within a Stackelberg game formulation, the video streaming service provider--acting as the strategic leader--optimizes both incentive levels and game parameters to achieve network-wide energy and traffic reductions, while adhering to budgetary constraints. This structured approach empowers providers with proactive, application-level control over energy consumption, offering them measurable benefits such as reduced high-bitrate traffic and increased participation in energy-saving behaviors, while also considering user satisfaction. The results of our simulations show that indeed gamification boosts significantly user participation and energy savings provided that the incentive and game parameters are chosen optimally."}
{"id": "2601.21890", "categories": ["physics.ao-ph", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.21890", "abs": "https://arxiv.org/abs/2601.21890", "authors": ["Laura Mack", "Norbert Pirk"], "title": "Reddy: An open-source toolbox for analyzing eddy-covariance measurements in heterogeneous environments", "comment": null, "summary": "Land-atmosphere exchange processes are determined by turbulent fluxes, which can be derived from eddy-covariance measurements. This method was established to quantify ecosystem-scale vertical atmosphere-vegetation exchange processes, but is also used to validate atmospheric turbulence theories with the ultimate aim to improve the representation of turbulence in numerical models. While the focus has long been on turbulence over idealized, homogeneous and flat surfaces, recent scientific developments are shifting towards investigating turbulent exchange processes in complex heterogeneous environments under non-idealized conditions, which pose particular challenges, e.g. advective fluxes between different surface types or non-stationarity of nighttime turbulence. This requires to rethink standard post-processing routines for determining turbulent fluxes from the high-frequency sonic and gas analyzer measurements. Here, we introduce the open-source R-package 'Reddy', which provides modular-built functions for post-processing, analysis and visualization of eddy-covariance measurements, including investigating spectra, coherent structures, anisotropy, flux footprints and surface energy balance closure. The 'Reddy' package is accompanied by a detailed documentation and a set of jupyter notebooks introducing new users hands-on to eddy-covariance data analysis. We showcase 'Reddy' based on measurements from three different sites in Norway: A case study during strong stratification over alpine tundra, for determining suitable averaging times during ice-cover transition at a boreal lake, and for fitting flux-variance relations for a permafrost peatland. 'Reddy' serves as extension of previously developed software packages, paving the way towards holistic turbulence data analysis in heterogeneous real-world environments."}
{"id": "2601.20978", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.20978", "abs": "https://arxiv.org/abs/2601.20978", "authors": ["Omid Khosravi", "Mehdi Tatari"], "title": "Solution of Advection Equation with Discontinuous Initial and Boundary Conditions via Physics-Informed Neural Networks", "comment": null, "summary": "In this paper, we investigate several techniques for modeling the one-dimensional advection equation for a specific class of problems with discontinuous initial and boundary conditions using physics-informed neural networks (PINNs). To mitigate the spectral bias phenomenon, we employ a Fourier feature mapping layer as the input representation, adopt a two-stage training strategy in which the Fourier feature parameters and the neural network weights are optimized sequentially, and incorporate adaptive loss weighting. To further enhance the approximation accuracy, a median filter is applied to the spatial data, and the predicted solution is constrained through a bounded linear mapping. Moreover, for certain nonlinear problems, we introduce a modified loss function inspired by the upwind numerical scheme to alleviate the excessive smoothing of discontinuous solutions typically observed in neural network approximations."}
{"id": "2601.21039", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21039", "abs": "https://arxiv.org/abs/2601.21039", "authors": ["Jingguan Liu", "Cong Chen", "Xiaomeng Ai", "Jiakun Fang", "Jinsong Wang", "Jinyu Wen"], "title": "Mean-Field Learning for Storage Aggregation", "comment": "14 pages, 6 figures", "summary": "Distributed energy storage devices can be pooled and coordinated by aggregators to participate in power system operations and market clearings. This requires representing a massive device population as a single, tractable surrogate that is computationally efficient, accurate, and compatible with market participation requirements. However, surrogate identification is challenging due to heterogeneity, nonconvexity, and high dimensionality of storage devices. To address these challenges, this paper develops a mean-field learning framework for storage aggregation. We interpret aggregation as the average behavior of a large storage population and show that, as the population grows, aggregate performance converges to a unique, convex mean-field limit, enabling tractable population-level modeling. This convexity further yields a price-responsive characterization of aggregate storage behavior and allows us to bound the mean-field approximation error. Leveraging these results, we construct a convex surrogate model that approximates the aggregate behavior of large storage populations and can be embedded directly into power system operations and market clearing. Surrogate parameter identification is formulated as an optimization problem using historical market price-response data, and we adopt a gradient-based algorithm for efficient learning procedure. Case studies validate the theoretical findings and demonstrate the effectiveness of the proposed framework in approximation accuracy, data efficiency, and profit outcomes."}
{"id": "2601.21047", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2601.21047", "abs": "https://arxiv.org/abs/2601.21047", "authors": ["Shubham Kukreja", "Dawson M. Willerton", "Sung-Sik Lee"], "title": "Classification of non-Fermi liquids and universal superconducting fluctuations", "comment": "123 pages, 70 figures", "summary": "In quantum critical metals, a plethora of different non-Fermi liquids arises depending on the nature of critical fluctuations coupled to Fermi surfaces. In this paper, we classify non-Fermi liquids that arise from q=0 critical fluctuations and characterize their universal superconducting fluctuations. The essential tool is the projective fixed points, which generalizes the notion of fixed points to fixed trajectories that take into account the incessant running of the Fermi momentum under the renormalization group flow. Based on the topology of bundles of projective fixed points, non-Fermi liquids are first grouped into seven superuniversality classes. Each superuniversality class includes multiple universality classes, which are further classified by the universal pairing interactions and emergent symmetries. Despite the pairing interaction generated by critical fluctuations, some non-Fermi liquids remain stable down to zero temperature due to the incoherence of excitations and the lack of scale invariance caused by Fermi momentum. Depending on the strength and span of the universal pairing interaction in momentum space, the emergent symmetry of non-Fermi liquids may or may not be lower than that of Fermi liquids. In non-Fermi liquids that become superconductors at low temperatures, the universal data of the parent metal determine the lower bound for the superconducting transition temperature and the associated pairing symmetry. In superuniversality classes that contain non-Fermi liquids prone to non-s-wave superconducting instabilities, the critical angular momentum above which pairing instability becomes inevitable is sensitive to the Fermi momentum, and the associated superconducting transition temperature oscillates as a function of the density. We use physical examples, as well as a toy model, to elucidate the universal low-energy physics of all superuniversality classes."}
{"id": "2601.21783", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.21783", "abs": "https://arxiv.org/abs/2601.21783", "authors": ["Bo Yang"], "title": "Measuring node similarity using minimum cycles in networks", "comment": null, "summary": "Cycles are ubiquitous in various networks such as social, biological, and technological systems, where they play a significant functional and dynamical role. This paper proposes a node similarity measure based on minimal simple cycles, referred to as cycle similarity. Specifically, the metric quantifies the similarity between two nodes by considering the minimal cycles that connect them through their neighboring nodes, with an upper bound imposed on the cycle size to ensure computational feasibility. We then systematically examine the effectiveness and applicability of this similarity measure through two fundamental tasks: link prediction and community detection. To address the scarcity of cycles in link prediction, an edge-addition correction strategy is introduced, whereby the existence of a candidate edge is hypothetically assumed before computing node similarity. Experimental results demonstrate that this correction leads to improved performance on datasets including karate, INT, PPI, and Grid. In hierarchical community detection using cycle similarity, we find that the significance of cyclic structures (reflected by Z-scores), the presence of pendant nodes with degree one, and the existence of cut vertices are the primary factors influencing the algorithm's performance."}
{"id": "2507.08533", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "nlin.CD", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2507.08533", "abs": "https://arxiv.org/abs/2507.08533", "authors": ["Shu Zhou", "K. Y. Michael Wong", "Juntao Wang", "David Shui Wing Hui", "Daniel Ebler", "Jie Sun"], "title": "Phase analysis of Ising machines and their implications on optimization", "comment": "5 pages, 4 figures", "summary": "Ising machines, which are dynamical systems designed to operate in a parallel and iterative manner, have emerged as a new paradigm for solving combinatorial optimization problems. Despite computational advantages, the quality of solutions depends heavily on the form of dynamics and tuning of parameters, which are in general set heuristically due to the lack of systematic insights. Here, we focus on optimal Ising machine design by analyzing phase diagrams of spin distributions in the Sherrington-Kirkpatrick model. We find that that the ground state can be achieved in the phase where the spin distribution becomes binary, and optimal solutions are produced where the binary phase and gapless phase coexist. Our analysis shows that such coexistence phase region can be expanded by carefully placing a digitization operation, giving rise to a family of superior Ising machines, as illustrated by the proposed algorithm digCIM."}
{"id": "2601.21931", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.21931", "abs": "https://arxiv.org/abs/2601.21931", "authors": ["Karel Devriendt", "Ignacio Echave-Sustaeta Rodríguez", "Frank Röttger"], "title": "Extremal conditional independence for Hüsler-Reiss distributions via modular functions", "comment": "16 pages, 3 figures", "summary": "We study extremal conditional independence for Hüsler-Reiss distributions, which is a parametric subclass of multivariate Pareto distributions. As the main contribution, we introduce two set functions, i.e.~functions which assign a value to the distribution and each of its marginals, and show that extremal conditional independence statements can be characterized by modularity relations for these functions. For the first function, we make use of the close connection between Hüsler-Reiss and Gaussian models to introduce a multiinformation-inspired measure $m^{\\text{HR}}$ for Hüsler-Reiss distributions. For the second function, we consider an invariant $σ^2$ that is naturally associated to the Hüsler-Reiss parameterization and establish the second modularity criterion under additional positivity constraints. Together, these results provide new tools for describing extremal dependence structures in high-dimensional extreme value statistics. In addition, we study the geometry of a bounded subset of Hüsler-Reiss parameters and its relation with the Gaussian elliptope."}
{"id": "2601.21230", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.21230", "abs": "https://arxiv.org/abs/2601.21230", "authors": ["Hengde Zhang", "Yunxiao Ren", "Zhisheng Duan", "Zhiyong Sun", "Guanrong Chen"], "title": "Deep Koopman Iterative Learning and Stability-Guaranteed Control for Unknown Nonlinear Time-Varying Systems", "comment": null, "summary": "This paper proposes a Koopman-based framework for modeling, prediction, and control of unknown nonlinear time-varying systems. We present a novel Koopman-based learning method for predicting the state of unknown nonlinear time-varying systems, upon which a robust controller is designed to ensure that the resulting closed-loop system is input-to-state stable with respect to the Koopman approximation error. The error of the lifted system model learned through the Koopman-based method increases over time due to the time-varying nature of the nonlinear time-varying system. To address this issue, an online iterative update scheme is incorporated into the learning process to update the lifted system model, aligning it more precisely with the time-varying nonlinear system by integrating the updated data and discarding the outdated data. A necessary condition for the feasibility of the proposed iterative learning method is derived. In order to reduce unnecessary system updates while ensuring the prediction accuracy of the lifted system, the update mechanism is enhanced to determine whether to update the lifted system and meanwhile to reduce updates that deteriorate the fitting performance. Furthermore, based on the online-updated lifted system, a controller is designed to ensure the closed-loop controlled system be input-to-state stable with respect to the Koopman approximation error. Numerical simulations on the Duffing oscillator, the serial manipulator, and the synthetic biological network system are presented to demonstrate the effectiveness of the proposed method for the approximation and control of unknown nonlinear time-varying systems. The results show that the proposed approach outperforms existing methods in terms of approximation accuracy and computational efficiency, even under significant system variations."}
{"id": "2601.21903", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.21903", "abs": "https://arxiv.org/abs/2601.21903", "authors": ["Konstantinos Varsos", "Adamantia Stamou", "George D. Stamoulis", "Vasillios A. Siris"], "title": "User Acceptance Model for Smart Incentives in Sustainable Video Streaming towards 6G", "comment": null, "summary": "The rapid growth of 5G video streaming is intensifying energy consumption across access, core, and data-center networks, underscoring the critical need for energy and carbon-efficient solutions. While reducing streaming bitrates improves energy efficiency, its success hinges on user acceptance--particularly when lower bitrates may be perceived as reduced quality of experience (QoE). Therefore, there is a need to develop transparent, user-centric incentive models that balance sustainability with perceived value. We propose a user-acceptance model that combines diverse environmental awareness, personalized responsiveness to incentives, and varying levels of altruism into a unified probabilistic framework. The model incorporates dynamic, individualized incentives that adapt over time. We further enhance the framework by incorporating (i) social well-being as a motivator for altruistic choices, (ii) provider-driven education strategies that gradually adjust user acceptance thresholds, and (iii) data-driven learning of user traits from historical offer--response interactions. Extensive synthetic-data experiments reveal the trade-offs between provider cost and network flexibility, showing that personalized incentives and gradual behavioral adaptation can advance sustainability targets without compromising stakeholder requirements."}
{"id": "2601.21913", "categories": ["physics.ao-ph", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21913", "abs": "https://arxiv.org/abs/2601.21913", "authors": ["Cassidy All", "Kevin Ho", "Maya Magnuski", "Christopher Nicolaides", "Louisa B. Ebby", "Mohammad Farazmand"], "title": "Rapid estimation of global sea surface temperatures from sparse streaming in situ observations", "comment": null, "summary": "Reconstructing high-resolution sea surface temperatures (SST) from staggered SST measurements is essential for weather forecasting and climate projections. However, when SST measurements are sparse, the resulting inferred SST fields are rather inaccurate. Here, we demonstrate the ability of Sparse Discrete Empirical Interpolation Method (S-DEIM) to reconstruct the high-resolution SST field from sparse in situ observations, without using a model. The S-DEIM estimate consists of two terms, one computed from instantaneous in situ observations using empirical interpolation, and the other learned from the historical time series of observations using recurrent neural networks (RNNs). We train the RNNs using the National Oceanic and Atmospheric Administration's weekly high-resolution SST dataset spanning the years 1989-2021 which constitutes the training data. Subsequently, we examine the performance of S-DEIM on the test data, comprising January 2022 to January 2023. For this test data, S-DEIM infers the high-resolution SST from 100 in situ observations, constituting only 0.2% of the high-resolution spatial grid. We show that the resulting S-DEIM reconstructions are about 40% more accurate than earlier empirical interpolation methods, such as DEIM and Q-DEIM. Furthermore, 91% of S-DEIM estimates fall within $\\pm 1^\\circ$C of the true SST. We also demonstrate that S-DEIM is robust with respect to sensor placement: even when the sensors are distributed randomly, S-DEIM reconstruction error deteriorates only by 1-2%. S-DEIM is also computationally efficient. Training the RNN, which is performed only once offline, takes approximately one minute. Once trained, the S-DEIM reconstructions are computed in less than a second. As such, S-DEIM can be used for rapid SST reconstruction from sparse streaming observational data in real time."}
{"id": "2601.21018", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21018", "abs": "https://arxiv.org/abs/2601.21018", "authors": ["Barbara Kaltenbacher", "William Rundell"], "title": "Identification of space-dependent coefficients in two competing terms of a nonlinear subdiffusion equation", "comment": null, "summary": "We consider a (sub)diffusion equation with a nonlinearity of the form $pf(u)-qu$, where $p$ and $q$ are space dependent functions. Prominent examples are the Fisher-KPP, the Frank-Kamenetskii-Zeldovich and the Allen-Cahn equations. We devise a fixed point scheme for reconstructing the spatially varying coefficients from interior observations a) at final time under two different excitations b) at two different time instances under a single excitation. Convergence of the scheme as well as local uniqueness of these coefficients is proven. Numerical experiments illustrate the performance of the reconstruction scheme."}
{"id": "2601.21046", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21046", "abs": "https://arxiv.org/abs/2601.21046", "authors": ["Jason Lu", "Tejas Santanam", "Hongzhao Guan", "Connor Riley", "Meen-Sung Kim", "Anthony Trasatti", "Neda Masoud", "Pascal Van Hentenryck"], "title": "The Impact of Shared Autonomous Vehicles in Microtransit Systems: A Case Study in Atlanta", "comment": null, "summary": "Microtransit systems represent an enhancement to solve the first- and last-mile problem, integrating traditional rail and bus networks with on-demand shuttles into a flexible, integrated system. This type of demand responsive transport provides greater accessibility and higher quality levels of service compared to conventional fixed-route transit services. Advances in technology offer further opportunities to enhance microtransit performance. In particular, shared autonomous vehicles (SAVs) have the potential to transform the mobility landscape by enabling more sustainable operations, enhanced user convenience, and greater system reliability. This paper investigates the integration of SAVs in microtransit systems, advancing the technological capabilities of on-demand shuttles. A shuttle dispatching optimization model is enhanced to accommodate for driver behavior and SAV functionalities. A model predictive control approach is proposed that dynamically rebalances on-demand shuttles towards areas of higher demand without relying on vast historical data. Scenario-driven experiments are conducted using data from the MARTA Reach microtransit pilot. The results demonstrate that SAVs can elevate both service quality and user experience compared to traditional on-demand shuttles in microtransit systems."}
{"id": "2601.20986", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.20986", "abs": "https://arxiv.org/abs/2601.20986", "authors": ["Valerio La Gatta", "Marco Postiglione", "Jeremy Gilbert", "Daniel W. Linna", "Morgan Manella Greenfield", "Aaron Shaw", "V. S. Subrahmanian"], "title": "SMART: A Social Movement Analysis & Reasoning Tool with Case Studies on #MeToo and #BlackLivesMatter", "comment": "Accepted at 2026 ACM The Web Conference (WWW 2026)", "summary": "Social movements supporting the UN's Sustainable Development Goals (SDGs) play a vital role in improving human lives. If journalists were aware of the relationship between social movements and external events, they could provide more precise, time-sensitive reporting about movement issues and SDGs. Our SMART system achieves this goal by collecting data from multiple sources, extracting emotions on various themes, and then using a transformer-based forecasting engine (DEEP) to predict quantity and intensity of emotions in future posts. This paper demonstrates SMART's Retrospective capabilities required by journalists via case studies analyzing social media discussions of the #MeToo and #BlackLivesMatter before and after the 2024 U.S. election. We create a novel 1-year dataset which we will release upon publication. It contains over 2.7M Reddit posts and over 1M news articles. We show that SMART enables early detection of discourse shifts around key political events, providing journalists with actionable insights to inform editorial planning. SMART was developed through multiple interactions with a panel of over 20 journalists from a variety of news organizations over a 2-year period, including an author of this paper."}
{"id": "2601.21447", "categories": ["q-fin.ST"], "pdf": "https://arxiv.org/pdf/2601.21447", "abs": "https://arxiv.org/abs/2601.21447", "authors": ["Demetrio Lacava", "Edoardo Otranto"], "title": "Trade uncertainty impact on stock-bond correlations: Insights from conditional correlation models", "comment": "24 pages, 9 tables, 4 figures", "summary": "This paper investigates the impact of Trade Policy Uncertainty (TPU) on stock-bond correlation dynamics in the United States. Using daily data on major U.S. stock indices and the 10-year Treasury bond from 2015 to 2025, we estimate correlation within a two-step GARCH-based framework, relying on multivariate specifications, including Constant Conditional Correlation (CCC), Smooth Transition Conditional Correlation (STCC), and Dynamic Conditional Correlation (DCC) models. We extend these frameworks by incorporating TPU index and a presidential dummy to capture effects of trade uncertainty and government cycles. The findings show that constant correlation models are strongly rejected in favor of time-varying specifications. Both STCC and DCC models confirm TPU's central role in driving correlation dynamics, with significant differences across political regimes. DCC models augmented with TPU and political effects deliver the best in-sample fit and strongest forecasting performance, as measured by statistical and economic loss functions."}
{"id": "2601.21088", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.21088", "abs": "https://arxiv.org/abs/2601.21088", "authors": ["Thomas Blommel", "M. Rey Lambert", "Michael A. Kurniawan", "Annabelle Canestraight", "Vojtech Vlcek"], "title": "Influence of Markovianity and self-consistency on time-resolved spectral functions of driven quantum systems", "comment": null, "summary": "We present a systematic comparison of the real-time Dyson expansion (RTDE) with established non-equilibrium Green's function approaches for simulating driven, interacting quantum systems. Focusing on density matrix dynamics, time-off-diagonal Green's functions, and time-resolved photoemission spectra, we benchmark RTDE against fully self-consistent Kadanoff-Baym equation (KBE) calculations, the generalized Kadanoff-Baym ansatz (GKBA), and exact diagonalization for small systems using second order many-body perturbation theory. Using a driven two-band Hubbard model, we show that mean-field single particle density matrix trajectories provide a reliable baseline for RTDE across a broad range of interaction strengths and excited-carrier populations. Further, RTDE accurately captures correlation effects in the Green's functions, including long-lived oscillations and revivals that are strongly suppressed by the overdamping inherent to self-consistent KBE schemes. As a consequence, RTDE resolves rich non-equilibrium spectral structure in time-resolved photoemission, such as interaction- and population-dependent quasiparticle splittings and bandgap renormalization, which are largely washed out in self-consistent approaches, yet are present in the exact solutions. Our results demonstrate that RTDE bridges the gap between mean-field propagation and full two-time KBE simulations, retaining favorable linear scaling while capturing essential dynamical correlations relevant for ultrafast spectroscopy."}
{"id": "2601.22021", "categories": ["physics.soc-ph", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.22021", "abs": "https://arxiv.org/abs/2601.22021", "authors": ["Yu Chen", "Genjiu Xu", "Sinan Feng", "Chaoqian Wang"], "title": "Post-Disaster Resource Redistribution and Cooperation Evolution Based on Two-Layer Network Evolutionary Games", "comment": "11 pages, 14 figures, accepted for publication in Chaos", "summary": "In the aftermath of large-scale disasters, the scarcity of resources and the paralysis of infrastructure raise severe challenges to effective post-disaster recovery. Efficient coordination between shelters and victims plays a crucial role in building community resilience, yet the evolution of two-layer behavioral feedback between these two groups through network coupling remains insufficiently understood. Here, this study develops a two-layer network to capture the cross-layer coupling between shelters and victims. The upper layer uses a post-disaster emergency resource redistribution model within the framework of the public goods game, while the lower layer adopts a cooperative evolutionary game to describe internal victim interactions. Monte Carlo simulations on scale-free networks reveal threshold effects of incentives: moderate public goods enhancement and subsidies promote cooperation, whereas excessive incentives induce free-riding. In contrast, credible and well-executed punishment effectively suppresses defection. Targeted punishment of highly connected shelters significantly enhances cooperation under resource constraints. A comparative analysis using a network generated from the actual coordinates of Beijing shelters confirms the model's generality and practical applicability. The findings highlight the importance of calibrated incentives, enforceable sanctions, and structural targeting in fostering robust cooperation across organizational and individual levels in post-disaster environments."}
{"id": "2601.21515", "categories": ["cond-mat.stat-mech", "hep-th", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.21515", "abs": "https://arxiv.org/abs/2601.21515", "authors": ["L. Ts. Adzhemyan", "M. V. Kompaniets", "A. V. Trenogin"], "title": "Six-loop renormalization group analysis of the $φ^4 + φ^6$ model", "comment": "10 pages", "summary": "We investigate the $λ\\ph^4+g\\ph^6$ model using the renormalization group method and the $\\ep$ expansion. This model is used in a situation where the coefficients $λ$, $g$ and the coefficient $τ$ of the term $τ\\ph^2$ depend on two parameters $T$ and $P$, and there is a point ($T_c,P_c$) at which $τ$ and $λ$ are zero. This point is named the tricritical point. The description of a system depends on a trajectory that leads to the tricritical point on the plane ($T,P$). In the trajectories, when $λ$ goes to zero fast enough, the description is defined by the $\\ph^6$ interaction and then the $\\ph^4$ term can be considered as a composite operator. In this case, the logarithmic dimension is $d=3$, and the $\\ep$ expansion is carried out in the dimension $d=3-2\\ep$. The main exponents of the \\textit{tricritical} model have been calculated in the third order of the $\\ep$ expansion. Taking into account the $\\ph^4$ interaction, we were able to calculate the value of the parameter that determines the required decrease rate in $λ$ to implement the tricritical behavior. The tricritical dimensions of the composite operators $\\ph^k$ for $k=1, 2, 4, 6$ have been computed. The resulting values are compared to those known from a conformal field theory and non-perturbative renormalization group."}
{"id": "2601.22005", "categories": ["quant-ph", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22005", "abs": "https://arxiv.org/abs/2601.22005", "authors": ["Jian Yao", "Pengtao Li", "Xiaohui Chen", "Quntao Zhuang"], "title": "Hierarchy of discriminative power and complexity in learning quantum ensembles", "comment": null, "summary": "Distance metrics are central to machine learning, yet distances between ensembles of quantum states remain poorly understood due to fundamental quantum measurement constraints. We introduce a hierarchy of integral probability metrics, termed MMD-$k$, which generalizes the maximum mean discrepancy to quantum ensembles and exhibit a strict trade-off between discriminative power and statistical efficiency as the moment order $k$ increases. For pure-state ensembles of size $N$, estimating MMD-$k$ using experimentally feasible SWAP-test-based estimators requires $Θ(N^{2-2/k})$ samples for constant $k$, and $Θ(N^3)$ samples to achieve full discriminative power at $k = N$. In contrast, the quantum Wasserstein distance attains full discriminative power with $Θ(N^2 \\log N)$ samples. These results provide principled guidance for the design of loss functions in quantum machine learning, which we illustrate in the training quantum denoising diffusion probabilistic models."}
{"id": "2601.21300", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21300", "abs": "https://arxiv.org/abs/2601.21300", "authors": ["Kushal Pratap Singh", "Manvi Bengani", "Darshit Mittal", "Twinkle Tripathy"], "title": "Distributed Circumnavigation Using Bearing Based Control with Limited Target Information", "comment": "6 pages, 17 figures", "summary": "In this paper, we address the problem of circumnavigation of a stationary target by a heterogeneous group comprising of $\\textbf{n}$ autonomous agents, having unicycle kinematics. The agents are assumed to have constant linear speeds, we control only the angular speeds. Assuming limited sensing capabilities of the agents, in the proposed framework, only a subset of agents, termed as \\textit{leaders}, know the target location. The rest, termed as \\textit{followers}, do not. We propose a distributed guidance law which drives all the agents towards the desired objective; global asymptotic stability (GAS) is ensured by using Zubov's theorem. The efficacy of the approach is demonstrated through both numerical simulations and hardware experiments on the TurtleBots utilising OptiTrack motion capture system."}
{"id": "2601.21080", "categories": ["math.NA", "cs.LG", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.21080", "abs": "https://arxiv.org/abs/2601.21080", "authors": ["Lizuo Liu", "Lu Zhang", "Anne Gelb"], "title": "Parametric Hyperbolic Conservation Laws: A Unified Framework for Conservation, Entropy Stability, and Hyperbolicity", "comment": "arXiv admin note: text overlap with arXiv:2507.01795", "summary": "We propose a parametric hyperbolic conservation law (SymCLaw) for learning hyperbolic systems directly from data while ensuring conservation, entropy stability, and hyperbolicity by design. Unlike existing approaches that typically enforce only conservation or rely on prior knowledge of the governing equations, our method parameterizes the flux functions in a form that guarantees real eigenvalues and complete eigenvectors of the flux Jacobian, thereby preserving hyperbolicity. At the same time, we embed entropy-stable design principles by jointly learning a convex entropy function and its associated flux potential, ensuring entropy dissipation and the selection of physically admissible weak solutions. A corresponding entropy-stable numerical flux scheme provides compatibility with standard discretizations, allowing seamless integration into classical solvers. Numerical experiments on benchmark problems, including Burgers, shallow water, Euler, and KPP equations, demonstrate that SymCLaw generalizes to unseen initial conditions, maintains stability under noisy training data, and achieves accurate long-time predictions, highlighting its potential as a principled foundation for data-driven modeling of hyperbolic conservation laws."}
{"id": "2601.21176", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21176", "abs": "https://arxiv.org/abs/2601.21176", "authors": ["Ruixing Ren", "Junhui Zhao", "Xiaoke Sun", "Shanjin Ni"], "title": "Towards Governance of Localized VANET: An Adjustable Degree Distribution Model", "comment": "This paper is 10 pages long, including 8 figures. It presents original research on VANET governance with an adjustable degree distribution model and has been submitted to IEEE Transactions on Information Forensics and Security", "summary": "Vehicular Ad-hoc Networks (VANETs) serve as a critical enabler for intelligent transportation systems. However, their practical deployment faces a core governance dilemma: the network topology requires a dynamic trade-off between robustness against targeted attacks and ensuring low-latency information transmission. Most existing models generate fixed degree distributions, lacking the ability to adapt autonomously to the demands of diverse traffic scenarios. To address this challenge, this paper innovatively proposes a schedulable degree distribution model for localized VANETs. The core of this model lies in introducing a hybrid connection mechanism. When establishing connections, newly joining nodes do not follow a single rule but instead collaboratively perform random attachment and preferential attachment. Through theoretical derivation and simulation validation, this study demonstrates that by adjusting the cooperative weighting between these two mechanisms, the overall network degree distribution can achieve a continuous and controllable transition between a uniform distribution and a power-law distribution. The former effectively disperses attack risks and enhances robustness, while the latter facilitates the formation of hub nodes, shortening transmission paths to reduce latency. Experimental results based on the real-world road network of Beijing indicate that this model can precisely regulate node connection heterogeneity, attack resistance, and average transmission path length through the reshaping of the underlying topology. This provides a forward-looking and practical governance paradigm for constructing next-generation VANETs capable of dynamically adapting to complex environments."}
{"id": "2601.21540", "categories": ["cs.SI", "cs.MA", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.21540", "abs": "https://arxiv.org/abs/2601.21540", "authors": ["Iris Yazici", "Mert Kayaalp", "Stefan Taga", "Ali H. Sayed"], "title": "Opinion Consensus Formation Among Networked Large Language Models", "comment": "Accepted at ICASSP 2026", "summary": "Can classical consensus models predict the group behavior of large language models (LLMs)? We examine multi-round interactions among LLM agents through the DeGroot framework, where agents exchange text-based messages over diverse communication graphs. To track opinion evolution, we map each message to an opinion score via sentiment analysis. We find that agents typically reach consensus and the disagreement between the agents decays exponentially. However, the limiting opinion departs from DeGroot's network-centrality-weighted forecast. The consensus between LLM agents turns out to be largely insensitive to initial conditions and instead depends strongly on the discussion subject and inherent biases. Nevertheless, transient dynamics align with classical graph theory and the convergence rate of opinions is closely related to the second-largest eigenvalue of the graph's combination matrix. Together, these findings can be useful for LLM-driven social-network simulations and the design of resource-efficient multi-agent LLM applications."}
{"id": "2601.21036", "categories": ["stat.ME", "econ.EM", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21036", "abs": "https://arxiv.org/abs/2601.21036", "authors": ["Chonghuan Wang"], "title": "Experimental Design for Matching", "comment": null, "summary": "Matching mechanisms play a central role in operations management across diverse fields including education, healthcare, and online platforms. However, experimentally comparing a new matching algorithm against a status quo presents some fundamental challenges due to matching interference, where assigning a unit in one matching may preclude its assignment in the other. In this work, we take a design-based perspective to study the design of randomized experiments to compare two predetermined matching plans on a finite population, without imposing outcome or behavioral models. We introduce the notation of a disagreement set, which captures the difference between the two matching plans, and show that it admits a unique decomposition into disjoint alternating paths and cycles with useful structural properties. Based on these properties, we propose the Alternating Path Randomized Design, which sequentially randomizes along these paths and cycles to effectively manage interference. Within a minimax framework, we optimize the conditional randomization probability and show that, for long paths, the optimal choice converges to $\\sqrt{2}-1$, minimizing worst-case variance. We establish the unbiasedness of the Horvitz-Thompson estimator and derive a finite-population Central Limit Theorem that accommodates complex and unstable path and cycle structures as the population grows. Furthermore, we extend the design to many-to-one matchings, where capacity constraints fundamentally alter the structure of the disagreement set. Using graph-theoretic tools, including finding augmenting paths and Euler-tour decomposition on an auxiliary unbalanced directed graph, we construct feasible alternating path and cycle decompositions that allow the design and inference results to carry over."}
{"id": "2601.21161", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.21161", "abs": "https://arxiv.org/abs/2601.21161", "authors": ["Shijie Li", "Hong Liang", "Songze Chen", "Chuang Zhang"], "title": "Semi-implicit Lax-Wendroff kinetic scheme for hydrodynamic phonon transport", "comment": "9 pages, 4 figures, 46 references", "summary": "A semi-implicit Lax-Wendroff kinetic scheme is developed for hydrodynamic phonon transport in solid materials based on the Boltzmann transport equation under the double relaxation time approximation, in which both the normal and resistive scattering processes are accounted. The trapezoidal and midpoint rules are adopted for the temporal integration of the scattering and migration terms under the framework of finite volume method, respectively. Instead of direct numerical interpolation, the kinetic equation is solved again when reconstructing the interfacial flux, in order to realize the coupling of phonon migration and scattering within a numerical time step. Specifically, the finite difference scheme is introduced and the second-order upwind or central schemes are used for the reconstruction of the interfacial distribution function and its spatial gradient. Consequently, the cell size and time step of the present method could be larger than the phonon mean free path and relaxation time in the limit of small Knudsen numbers. Numerical tests demonstrate that the present method can accurately capture multi-scale thermal conduction phenomena within different normal or resistive scattering rates."}
{"id": "2601.21098", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.21098", "abs": "https://arxiv.org/abs/2601.21098", "authors": ["Mohamed M. Elsayed", "Taras I. Lakoba", "Valeri N. Kotov"], "title": "Interacting type-II semi-Dirac quasiparticles", "comment": "5 pages, 6 figures", "summary": "Type-II semi-Dirac fermions in two dimensions have been proposed to describe topologically nontrivial low energy excitations in titanium/vanadium oxide heterostructures. These quasiparticles appear at the merger of three Dirac cones, resulting in a non-zero Berry phase. We find, by employing Hartree-Fock, renormalization group and RPA techniques, that the spectrum is very sensitive to long-range electron-electron interactions and can undergo a profound transformation. Specifically the quasiparticle spectrum evolves, driven by interactions, from anisotropic Dirac dispersion at the lowest energies, towards the characteristic type-II semi-Dirac boomerang shape as the energy increases. The corresponding density of states varies between linear and power one third ($ρ(\\varepsilon) \\sim |\\varepsilon| \\rightarrow |\\varepsilon|^{1/3}$). The crossover scale is controlled by the interaction strength $α= e^2/(\\hbar v)$, and the specifics of the effective interacting Hamiltonian. Our results imply that various physical characteristics exhibit critical behavior with continuously varying 'critical exponents'; for example Landau levels in a magnetic field vary with the energy scale: $|\\varepsilon_n(B)|\\sim (nB)^{1/2} \\rightarrow (nB)^{3/4}, n=0,1,2,...$, and similarly for other observables."}
{"id": "2601.22099", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.22099", "abs": "https://arxiv.org/abs/2601.22099", "authors": ["Sandro M. Reia", "Henrique F. de Arruda", "Shiyang Ruan", "Taylor Anderson", "Hamdi Kavak", "Dieter Pfoser"], "title": "Towards Universal Urban Patterns-of-Life Simulation", "comment": null, "summary": "Understanding urban mobility requires models that capture how people interact with and navigate the built environment. We present a scalable, generalizable agent-based framework in which daily schedules emerge from the interplay between mandatory (e.g., work, school) and flexible (e.g., errands, food, leisure) activities, driven by evolving individual needs. The results of our model are validated against empirical patterns from the 2017 U.S. National Household Travel Survey, including activity distributions, origin-destination flows, and trip-chain length distributions. We introduce a normalized similarity metric to quantify agreement between simulated and empirical patterns. Most cities achieve scores above 0.80, demonstrating strong alignment without the need for city-specific calibration. The model scales efficiently to over 20 million agents, enabling full-population simulations of large metropolitan areas. This combination of universality and scalability enables scenario analysis for infrastructure stress testing, disaster recovery, innovation diffusion, and disease spread in urban systems."}
{"id": "2601.21671", "categories": ["cond-mat.stat-mech", "nlin.CD", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2601.21671", "abs": "https://arxiv.org/abs/2601.21671", "authors": ["Divya D. Joshi", "Trupti R. Sharma", "Prashant M. Gade"], "title": "Pattern Formation in Excitable Neuronal Maps", "comment": "9 pages, 6 figures, 30 subfigures", "summary": "Coupled excitable systems can generate a variety of patterns. In this work, we investigate coupled Chialvo maps in two dimensions under two types of nearest-neighbor couplings. One coupling produces ringlike patterns, while the other produces spirals. The rings expand with increasing coupling, whereas spirals evolve into turbulence and dissipate at stronger coupling. To quantify these patterns, we introduce an analogue of the discriminant of the velocity gradient tensor and examine the persistence of its sign. For ring-type patterns, the persistence decays more slowly than exponentially, often following a power law or stretched exponential. When spiral structures remain intact, persistence saturates asymptotically and can exhibit superposed periodic oscillations, suggesting complex exponents at early times. These behaviors highlight deep connections with the underlying dynamics."}
{"id": "2601.21371", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21371", "abs": "https://arxiv.org/abs/2601.21371", "authors": ["Sifat Chowdhury", "Yihsu Chen", "Yu Zhang"], "title": "Resilient Grid Hardening against Multiple Hazards: An Adaptive Two-Stage Stochastic Optimization Approach", "comment": null, "summary": "The growing prevalence of extreme weather events driven by climate change poses significant challenges to power system resilience. Infrastructure damage and prolonged power outages highlight the urgent need for effective grid-hardening strategies. While some measures provide long-term protection against specific hazards, they can become counterproductive under conflicting threats. In this work, we develop an adaptive two-stage stochastic optimization framework to support dynamic decision-making for hardening critical grid components under multiple hazard exposures. Unlike traditional approaches, our model adapts to evolving climate conditions, enabling more resilient investment strategies. Furthermore, we integrate long-term (undergrounding) and short-term (vegetation management) hardening actions to jointly minimize total system costs. Extensive simulation results validate the effectiveness of the proposed framework in reducing outage and repair costs while enhancing the adaptability and robustness of grid infrastructure planning."}
{"id": "2601.21241", "categories": ["math.NA", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.21241", "abs": "https://arxiv.org/abs/2601.21241", "authors": ["Simone Chiocchetti", "Giovanni Russo"], "title": "An efficient implicit scheme for the multimaterial Euler equations in Lagrangian coordinates", "comment": null, "summary": "Stratified fluids composed of a sequence of alternate layers show interesting macroscopic properties, which may be quite different from those of the individual constituent fluids. On a macroscopic scale, such systems can be considered a sort of fluid metamaterial. In many cases each fluid layer can be described by Euler equations following the stiffened gas equation of state. The computation of detailed numerical solutions of such stratified material poses several challenges, first and foremost the issue of artificial smearing of material parameters across interface boundaries. Lagrangian schemes completely eliminate this issue, but at the cost of rather stringent time step restrictions. In this work we introduce an implicit numerical method for the multimaterial Euler equations in Lagrangian coordinates. The implicit discretization is aimed at bypassing the prohibitive time step restrictions present in flows with stratified media, where one of the materials is particularly dense, or rigid (or both). This is the case for flows of water-air mixtures, air-granular media, or similar high density ratio systems. We will present the novel discretisation approach, which makes extensive use of the remarkable structure of the governing equations in Lagrangian coordinates to find the solution by means of a single implicit discrete wave equation for the pressure field, yielding a symmetric positive definite structure and thus a particularly efficient algorithm. Additionally, we will introduce simple filtering strategies for counteracting the emergence of pressure or density oscillations typically encountered in multimaterial flows, and will present results concerning the robustness, accuracy, and performance of the proposed method, including applications to stratified media with high density and stiffness ratios."}
{"id": "2601.21230", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.21230", "abs": "https://arxiv.org/abs/2601.21230", "authors": ["Hengde Zhang", "Yunxiao Ren", "Zhisheng Duan", "Zhiyong Sun", "Guanrong Chen"], "title": "Deep Koopman Iterative Learning and Stability-Guaranteed Control for Unknown Nonlinear Time-Varying Systems", "comment": null, "summary": "This paper proposes a Koopman-based framework for modeling, prediction, and control of unknown nonlinear time-varying systems. We present a novel Koopman-based learning method for predicting the state of unknown nonlinear time-varying systems, upon which a robust controller is designed to ensure that the resulting closed-loop system is input-to-state stable with respect to the Koopman approximation error. The error of the lifted system model learned through the Koopman-based method increases over time due to the time-varying nature of the nonlinear time-varying system. To address this issue, an online iterative update scheme is incorporated into the learning process to update the lifted system model, aligning it more precisely with the time-varying nonlinear system by integrating the updated data and discarding the outdated data. A necessary condition for the feasibility of the proposed iterative learning method is derived. In order to reduce unnecessary system updates while ensuring the prediction accuracy of the lifted system, the update mechanism is enhanced to determine whether to update the lifted system and meanwhile to reduce updates that deteriorate the fitting performance. Furthermore, based on the online-updated lifted system, a controller is designed to ensure the closed-loop controlled system be input-to-state stable with respect to the Koopman approximation error. Numerical simulations on the Duffing oscillator, the serial manipulator, and the synthetic biological network system are presented to demonstrate the effectiveness of the proposed method for the approximation and control of unknown nonlinear time-varying systems. The results show that the proposed approach outperforms existing methods in terms of approximation accuracy and computational efficiency, even under significant system variations."}
{"id": "2601.21152", "categories": ["quant-ph", "cs.SI", "math.CO", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.21152", "abs": "https://arxiv.org/abs/2601.21152", "authors": ["Md Samsur Rahaman", "Supriyo Dutta"], "title": "Community detection in network using Szegedy quantum walk", "comment": "Comments are welcome!", "summary": "In a network, the vertices with similar characteristics construct communities. The vertices in a community are well-connected. Detecting the communities in a network is a challenging and important problem in the theory of complex networks. One approach to solve this problem uses the classical random walks on the graphs. In quantum computing, quantum walks are the quantum mechanical counterparts of classical random walks. In this article, we employ a variant of Szegedy's quantum walk to develop a procedure for discovering the communities in networks. The limiting probability distribution of quantum walks assists us in determining the inclusion of a vertex in a community. We apply our procedure of community detection on a number of graphs and social networks, such as the relaxed caveman graph, $l$-partition graph, Karate club graph, dolphin's social network, etc."}
{"id": "2601.21106", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.21106", "abs": "https://arxiv.org/abs/2601.21106", "authors": ["Annesh Pal", "Aguirre Mimoun", "Rodolphe Thiébaut", "Boris P. Hejblum"], "title": "Adaptive Dirichlet Process mixture model with unknown concentration parameter and variance: Scaling high dimensional clustering via collapsed variational inference", "comment": "19 pages with 7 figures and 1 table", "summary": "We propose a novel method that performs adaptive clustering with DPMM using collapsed VI, while incorporating weakly-informative priors for DP concentration parameter alpha and base distribution G0. We illustrate the importance of G0 covariance structure and prior choice by considering different parameterisations of the data covariance matrix. On high-dimensional Gaussian simulations, our model demonstrates substantially faster convergence than a state-of-the-art MCMC splice sampler. We further evaluate performances on Negative Binomial simulations and conduct sensitivity analyses to assess robustness on realistic data conditions. Application to a publicly available leukemia transcriptomic data set comprising 72 samples and 2,194 gene expression successfully recovers every known sub-type, all while identifying additional gene expression-based sub-clusters with meaningful biological interpretation."}
{"id": "2601.21881", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.21881", "abs": "https://arxiv.org/abs/2601.21881", "authors": ["Jingruo Peng", "Shuze Zhu"], "title": "Acquiring Human-Like Mechanics Intuition from Scarce Observations via Deep Reinforcement Learning", "comment": null, "summary": "Humans can infer accurate mechanical outcomes from only a few observations, a capability known as mechanics intuition. The mechanisms behind such data-efficient learning remain unclear. Here, we propose a reinforcement learning framework in which an agent encodes continuous physical observation parameters into its state and is trained via episodic switching across closely related observations. With merely two or three observations, the agent acquires robust mechanics intuition that generalizes accurately over wide parameter ranges, substantially beyond the training data, as demonstrated on the brachistochrone and a large-deformation elastic plate. We explain this generalization through a unified theoretical view: it emerges when the learned value function enforces Bellman consistency across neighboring task parameters, rendering the Bellman residual stationary with respect to physical variations. This induces a smooth policy that captures a low-dimensional solution manifold underlying the continuum of tasks. Our work establishes episodic switching as a principled route to artificial mechanics intuition and offers a theoretical link to similar generalization abilities in biological learners."}
{"id": "2601.21134", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21134", "abs": "https://arxiv.org/abs/2601.21134", "authors": ["Tobias Swann", "Adam Nahum"], "title": "Continuum mechanics of entanglement in noisy interacting fermion chains", "comment": "24 pages, 10 figures", "summary": "We develop an effective continuum description for information scrambling in a chain of randomly interacting Majorana fermions. The approach is based on the semiclassical treatment of the path integral for an effective spin chain that describes \"two-replica\" observables such as the entanglement purity and the OTOC. This formalism gives exact results for the entanglement membrane and for operator spreading in the limit of weak interactions. In this limit there is a large crossover lengthscale between free and interacting behavior, and this large lengthscale allows for a continuum limit and a controlled saddle-point calculation. The formalism is also somewhat different from that known from random unitary circuits. The entanglement membrane emerges as a kind of bound state of two travelling waves, and shows an interesting unbinding phenomenon as the velocity of the entanglement membrane approaches the butterfly velocity."}
{"id": "2601.21625", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21625", "abs": "https://arxiv.org/abs/2601.21625", "authors": ["Tsubasa Oishi", "Takuma Saito", "Hiromi Ebisu"], "title": "Non-invertible translation from Lieb-Schultz-Mattis anomaly", "comment": "36 pages, 4 figures", "summary": "Symmetry provides powerful non-perturbative constraints in quantum many-body systems. A prominent example is the Lieb-Schultz-Mattis (LSM) anomaly -- a mixed 't Hooft anomaly between internal and translational symmetries that forbids a trivial symmetric gapped phase. In this work, we investigate lattice translation operators in systems with an LSM anomaly. We construct explicit lattice models in two and three spatial dimensions and show that, after gauging the full internal symmetry, translation becomes non-invertible and fuses into defects of the internal symmetry. The result is supported by the anomaly-inflow in view of topological field theory. Our work extends earlier one-dimensional observations to a unified higher-dimensional framework and clarifies their origin in mixed anomalies and higher-group structures, highlighting a coherent interplay between internal and crystalline symmetries."}
{"id": "2601.21152", "categories": ["quant-ph", "cs.SI", "math.CO", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.21152", "abs": "https://arxiv.org/abs/2601.21152", "authors": ["Md Samsur Rahaman", "Supriyo Dutta"], "title": "Community detection in network using Szegedy quantum walk", "comment": "Comments are welcome!", "summary": "In a network, the vertices with similar characteristics construct communities. The vertices in a community are well-connected. Detecting the communities in a network is a challenging and important problem in the theory of complex networks. One approach to solve this problem uses the classical random walks on the graphs. In quantum computing, quantum walks are the quantum mechanical counterparts of classical random walks. In this article, we employ a variant of Szegedy's quantum walk to develop a procedure for discovering the communities in networks. The limiting probability distribution of quantum walks assists us in determining the inclusion of a vertex in a community. We apply our procedure of community detection on a number of graphs and social networks, such as the relaxed caveman graph, $l$-partition graph, Karate club graph, dolphin's social network, etc."}
{"id": "2601.21390", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21390", "abs": "https://arxiv.org/abs/2601.21390", "authors": ["B. da Costa Paulo", "N. Aginako", "J. Ugartemendia", "I. Landa del Barrio", "M. Quartulli", "H. Camblong"], "title": "Surrogate model of a HVAC system for PV self-consumption maximisation", "comment": null, "summary": "In the last few years, energy efficiency has become a challenge. Not only mitigating environmental impact but reducing energy waste can lead to financial advantages. Buildings play an important role in this: they are among the biggest consumers. So, finding manners to reduce energy consumption is a way to minimise energy waste, and a technique for that is creating Demand Response (DR) strategies. This paper proposes a novel way to decrease computational effort of simulating the behaviour of a building using surrogate models based on active learning. Before going straight to the problem of a building, which is complex and computationally costly, the paper proposes the approach of active learning to a smaller problem: with reduced simulations, regress the curve of voltage versus current of a thermo-resistor. Then, the paper implements a surrogate model of energy consumption of a building. The goal is to be able to learn the consumption pattern based on a limited number of simulations. The result given by the surrogate can be used to set the reference temperature, maximising the PV self-consumption, and reducing energy usage from the grid. Thanks to the surrogate, the total time spent to map all possible consumption scenarios is reduced around 7 times."}
{"id": "2601.21368", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21368", "abs": "https://arxiv.org/abs/2601.21368", "authors": ["Peng Yang", "Zhimin Zhang"], "title": "Natural superconvergence points for splines", "comment": "27 pages, 3 figures, 3 tables", "summary": "This paper develops a unified theory of natural superconvergence points for polynomial spline approximations to second-order elliptic problems. Beginning with the one-dimensional case, we establish that when a point $x_0$ is a local symmetric center of the partition, the numerical error $(u-u_h)^{(s)}(x_0)$ exhibits superconvergence whenever the polynomial degree $k$ and the derivative order $s$ share the same parity. In particular, for the smoothest spline (B-spline) solution, the abundance of superconvergence points allows us to construct asymptotic expansion of the error within the element that fully characterize all superconvergence points, for both function values and derivatives. The theoretical framework is then extended to higher-dimensional settings on simplicial and tensor-product meshes, and the essential conclusions are preserved, with one-dimensional derivatives generalized to mixed derivatives. Numerical experiments demonstrate that superconvergence persists even in extremely localized symmetric regions, revealing that superconvergence points are both readily attainable and follow systematic distribution patterns."}
{"id": "2601.21300", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21300", "abs": "https://arxiv.org/abs/2601.21300", "authors": ["Kushal Pratap Singh", "Manvi Bengani", "Darshit Mittal", "Twinkle Tripathy"], "title": "Distributed Circumnavigation Using Bearing Based Control with Limited Target Information", "comment": "6 pages, 17 figures", "summary": "In this paper, we address the problem of circumnavigation of a stationary target by a heterogeneous group comprising of $\\textbf{n}$ autonomous agents, having unicycle kinematics. The agents are assumed to have constant linear speeds, we control only the angular speeds. Assuming limited sensing capabilities of the agents, in the proposed framework, only a subset of agents, termed as \\textit{leaders}, know the target location. The rest, termed as \\textit{followers}, do not. We propose a distributed guidance law which drives all the agents towards the desired objective; global asymptotic stability (GAS) is ensured by using Zubov's theorem. The efficacy of the approach is demonstrated through both numerical simulations and hardware experiments on the TurtleBots utilising OptiTrack motion capture system."}
{"id": "2601.21493", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.21493", "abs": "https://arxiv.org/abs/2601.21493", "authors": ["Silvia Dallari", "Laura Anderlucci", "Nicola Grandi", "Angela Montanari"], "title": "A Poisson Factor Mixture Model for the Analysis of Linguistic Competence in Italian University Students' Writing", "comment": null, "summary": "Public debate on the alleged decline of language skills among younger generations often focuses on university students, the most highly educated segment of the population. Rather than addressing the ill posed question of linguistic decline, this paper examines how formal written Italian is currently used by university students and whether systematic patterns of competence and heterogeneity can be identified. The analysis is based on data from the UniversITA project, which collected formal texts written by a large and nationally representative sample of Italian university students. Texts were annotated for linguistically motivated features covering orthography, lexicon, syntax, morphosyntax, coherence, register, and sentence structure, yielding low frequency multivariate count data. To analyse these data, we propose a novel model-based clustering approach based on a Poisson factor mixture model that accounts for dependence among linguistic features and unobserved population heterogeneity. The results identify two correlated dimensions of writing competence, interpretable as communicative competence and linguistic grammatical competence. When educational and socio demographic information is incorporated, distinct student profiles emerge that are associated with field of study and educational background. These findings provide quantitative evidence on contemporary writing and offer insights relevant for language education and higher education policy."}
{"id": "2507.08533", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "nlin.CD", "physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2507.08533", "abs": "https://arxiv.org/abs/2507.08533", "authors": ["Shu Zhou", "K. Y. Michael Wong", "Juntao Wang", "David Shui Wing Hui", "Daniel Ebler", "Jie Sun"], "title": "Phase analysis of Ising machines and their implications on optimization", "comment": "5 pages, 4 figures", "summary": "Ising machines, which are dynamical systems designed to operate in a parallel and iterative manner, have emerged as a new paradigm for solving combinatorial optimization problems. Despite computational advantages, the quality of solutions depends heavily on the form of dynamics and tuning of parameters, which are in general set heuristically due to the lack of systematic insights. Here, we focus on optimal Ising machine design by analyzing phase diagrams of spin distributions in the Sherrington-Kirkpatrick model. We find that that the ground state can be achieved in the phase where the spin distribution becomes binary, and optimal solutions are produced where the binary phase and gapless phase coexist. Our analysis shows that such coexistence phase region can be expanded by carefully placing a digitization operation, giving rise to a family of superior Ising machines, as illustrated by the proposed algorithm digCIM."}
{"id": "2601.21399", "categories": ["cond-mat.stat-mech", "math-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.21399", "abs": "https://arxiv.org/abs/2601.21399", "authors": ["Mingzhong Lu", "Yufeng Song", "Qiyuan Shi", "Ming Li", "Youjin Deng"], "title": "High-precision Dynamic Monte Carlo Study of Rigidity Percolation", "comment": null, "summary": "Rigidity percolation provides an important basis for understanding the onset of mechanical stability in disordered materials. While most studies on the triangular lattice have focused on static properties at fixed bond~(site) occupation probabilities, the dynamics of the rigidity transition remain less explored. In this work, we formulate a dynamic pebble game algorithm that monitors how rigid clusters emerge and evolve as bonds are added sequentially to an empty lattice, with computational efficiency comparable to the standard static pebble game. We uncover a previously overlooked temporal self-similarity exhibited in multiple quantities, including the cluster size changes and merged cluster sizes during bond addition, as well as the number of simultaneously merging clusters. We identify large-scale cascade events in which a single bond addition triggers the merger of an extensive number of clusters that scales with system size with inverse correlation-length exponent. Using an event-based ensemble approach, we obtain high-precision estimates of the critical point $p_c = 0.660\\,277\\,8(10)$, the inverse correlation-length exponent $1/ν= 0.850(3)$, and the fractal dimension $d_f = 1.850(2)$, representing substantial improvements over existing values."}
{"id": "2601.20970", "categories": ["math.OC", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20970", "abs": "https://arxiv.org/abs/2601.20970", "authors": ["Gabriel Ponte", "Marcia Fampa", "Jon Lee"], "title": "The augmented NLP bound for maximum-entropy remote sampling", "comment": null, "summary": "The maximum-entropy remote sampling problem (MERSP) is to select a subset of s random variables from a set of n random variables, so as to maximize the information concerning a set of target random variables that are not directly observable. We assume throughout that the set of all of these random variables follows a joint Gaussian distribution, and that we have the covariance matrix available. Finally, we measure information using Shannon's differential entropy.\n  The main approach for exact solution of moderate-sized instances of MERSP has been branch-and-bound, and so previous work concentrated on upper bounds. Prior to our work, there were two upper-bounding methods for MERSP: the so-called NLP bound and the spectral bound, both introduced 25 years ago. We are able now to establish domination results between these two upper bounds. We propose an ``augmented NLP bound'' based on a subtle convex relaxation. We provide theoretical guarantees, giving sufficient conditions under which the augmented NLP bound strictly dominates the ordinary NLP bound. In addition, the augmented NLP formulation allows us to derive upper bounds for rank-deficient covariance matrices when they satisfy a technical condition. This is in contrast to the earlier work on the ordinary NLP bound that worked with only positive definite covariance matrices. Finally, we introduce a novel and very effective diagonal-scaling technique for MERSP, employing a positive vector of parameters. Numerical experiments on benchmark instances demonstrate the effectiveness of our approaches in advancing the state of the art for calculating upper bounds on MERSP."}
{"id": "2601.22053", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.22053", "abs": "https://arxiv.org/abs/2601.22053", "authors": ["Sankha Subhra Bakshi", "Gia-Wei Chern"], "title": "Emergent Spatial Textures from Interaction Quenches in the Hubbard Model", "comment": "9 pages, 5+4 Figures", "summary": "Interaction quenches in strongly correlated electron systems provide a powerful route to probe nonequilibrium many-body dynamics. For the Hubbard model, nonequilibrium dynamical mean-field theory has revealed coherent post-quench oscillations, dynamical crossovers, and long-lived transient regimes. However, these studies are largely restricted to spatially homogeneous dynamics and therefore neglect the role of spatial structure formation during ultrafast evolution. Here we investigate interaction quenches in the half-filled Hubbard model using a real-space time-dependent Gutzwiller framework. We show that homogeneous nonequilibrium dynamics is generically unstable: even arbitrarily weak spatial fluctuations grow dynamically and drive the system toward intrinsically inhomogeneous states. Depending on the interaction strength, the post-quench evolution exhibits spatial differentiation, nucleation, and slow coarsening of Mott-like domains. Our results establish spatial self-organization as a generic feature of far-from-equilibrium correlated matter and reveal a fundamental limitation of spatially homogeneous nonequilibrium theories."}
{"id": "2601.21562", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21562", "abs": "https://arxiv.org/abs/2601.21562", "authors": ["Xiang Zhu", "Xiuqiang He", "Hongyang Qing", "Hua Geng"], "title": "Decentralized Analysis Approach for Oscillation Damping in Grid-Forming and Grid-Following Heterogeneous Power Systems", "comment": null, "summary": "This letter proposes a decentralized local gain condition (LGC) to guarantee oscillation damping in inverter-based resource (IBR)-dominated power systems. The LGC constrains the dynamic gain between each IBR and the network at its point of connection. By satisfying the LGC locally, the closed-loop poles are confined to a desired region, thereby yielding system-wide oscillation damping without requiring global information. Notably, the LGC is agnostic to different IBR dynamics, well-suited for systems with heterogeneous IBRs, and flexible to various damping requirements. Moreover, a low-complexity algorithm is proposed to parameterize LGC, providing scalable and damping-constrained parameter tuning guidance for IBRs."}
{"id": "2601.21388", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21388", "abs": "https://arxiv.org/abs/2601.21388", "authors": ["Mingyi Wang", "Dongling Wang"], "title": "Higher-Order Finite Difference Methods for the Tempered Fractional Laplacian", "comment": null, "summary": "This paper presents a general framework of high-order finite difference (HFD) schemes for the tempered fractional Laplacian (TFL) based on new generating functions obtained from the discrete symbols. Specifically, for sufficiently smooth functions, the resulting discretizations achieve high-order convergence with orders $p=4, 6, 8$. The discrete operators lead to Toeplitz stiffness matrices, allowing efficient matrix-vector multiplications via fast algorithms. Building on these approximations, HFD methods are formulated for solving TFL equations, and their stability and convergence are rigorously analyzed. Numerical simulations confirm the effectiveness of the proposed methods, showing excellent agreement with the theoretical predictions."}
{"id": "2601.21371", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21371", "abs": "https://arxiv.org/abs/2601.21371", "authors": ["Sifat Chowdhury", "Yihsu Chen", "Yu Zhang"], "title": "Resilient Grid Hardening against Multiple Hazards: An Adaptive Two-Stage Stochastic Optimization Approach", "comment": null, "summary": "The growing prevalence of extreme weather events driven by climate change poses significant challenges to power system resilience. Infrastructure damage and prolonged power outages highlight the urgent need for effective grid-hardening strategies. While some measures provide long-term protection against specific hazards, they can become counterproductive under conflicting threats. In this work, we develop an adaptive two-stage stochastic optimization framework to support dynamic decision-making for hardening critical grid components under multiple hazard exposures. Unlike traditional approaches, our model adapts to evolving climate conditions, enabling more resilient investment strategies. Furthermore, we integrate long-term (undergrounding) and short-term (vegetation management) hardening actions to jointly minimize total system costs. Extensive simulation results validate the effectiveness of the proposed framework in reducing outage and repair costs while enhancing the adaptability and robustness of grid infrastructure planning."}
{"id": "2601.21532", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.21532", "abs": "https://arxiv.org/abs/2601.21532", "authors": ["Edoardo Otranto"], "title": "A Matrix-Variate Log-Normal Model for Covariance Matrices", "comment": null, "summary": "We propose a modeling framework for time-varying covariance matrices based on the assumption that the logarithm of a realized covariance matrix follows a matrix-variate oNrmal distribution. By operating in the space of symmetric matrices, the approach guarantees positive definiteness without imposing parameter constraints beyond stationarity. The conditional mean of the logarithmic covariance matrix is specified through a BEKK-type structure that can be rewritten as a diagonal vector representation, yielding a parsimonious specification that mitigates the curse of dimensionality. Estimation is performed by maximum likelihood exploiting properties of matrix-variate Normal distributions and expressing the scale parameter matrix as a function of the location matrix. The covariance matrix is recovered via the matrix exponential. Since this transformation induces an upward bias, an approximate, time-specific bias correction based on a second-order Taylor expansion is proposed. The framework is flexible and applicable to a wide class of problems involving symmetric positive definite matrices."}
{"id": "2601.21399", "categories": ["cond-mat.stat-mech", "math-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.21399", "abs": "https://arxiv.org/abs/2601.21399", "authors": ["Mingzhong Lu", "Yufeng Song", "Qiyuan Shi", "Ming Li", "Youjin Deng"], "title": "High-precision Dynamic Monte Carlo Study of Rigidity Percolation", "comment": null, "summary": "Rigidity percolation provides an important basis for understanding the onset of mechanical stability in disordered materials. While most studies on the triangular lattice have focused on static properties at fixed bond~(site) occupation probabilities, the dynamics of the rigidity transition remain less explored. In this work, we formulate a dynamic pebble game algorithm that monitors how rigid clusters emerge and evolve as bonds are added sequentially to an empty lattice, with computational efficiency comparable to the standard static pebble game. We uncover a previously overlooked temporal self-similarity exhibited in multiple quantities, including the cluster size changes and merged cluster sizes during bond addition, as well as the number of simultaneously merging clusters. We identify large-scale cascade events in which a single bond addition triggers the merger of an extensive number of clusters that scales with system size with inverse correlation-length exponent. Using an event-based ensemble approach, we obtain high-precision estimates of the critical point $p_c = 0.660\\,277\\,8(10)$, the inverse correlation-length exponent $1/ν= 0.850(3)$, and the fractal dimension $d_f = 1.850(2)$, representing substantial improvements over existing values."}
{"id": "2601.21502", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "hep-th", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.21502", "abs": "https://arxiv.org/abs/2601.21502", "authors": ["Yiteng Zhang", "Li-Ping Yang", "Hong-Hao Tu", "Yueshui Zhang"], "title": "Finite-size corrections to the crosscap overlap in the two-dimensional Ising model", "comment": "6 pages, 3 figures", "summary": "We analyze the finite-size corrections to the crosscap overlap in the two-dimensional classical Ising model along its self-dual critical line. Using a fermionic formulation, we express the lattice crosscap overlap in terms of Bogoliubov angles and develop a contour-integral approach by analytically continuing the lattice momentum to the complex plane. This leads to a remarkably simple expression for the crosscap overlap, which demonstrates that the finite-size corrections decay exponentially with system size. We further derive an exact analytical formula for the corresponding decay constant and show that it is determined by the complex singularity structure of the Bogoliubov angle."}
{"id": "2601.20973", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.20973", "abs": "https://arxiv.org/abs/2601.20973", "authors": ["Asaf Cohen", "Ruolan He", "Yuqiong Wang"], "title": "Thompson Sampling Algorithm for Stochastic Games", "comment": null, "summary": "We study a stochastic differential game with $N$ competitive players in a linear-quadratic framework with ergodic cost, where $d$-dimensional diffusion processes govern the state dynamics with an unknown common drift (matrix). Assuming a Gaussian prior on the drift, we use filtering techniques to update its posterior estimates. Based on these estimates, we propose a Thompson-sampling-based algorithm with dynamic episode lengths to approximate strategies. We show that the Bayesian regret for each player has an error bound of order $O(\\sqrt{T\\log(T)})$, where $T$ is the time-horizon, independent of the number of players. This implies that average regret per unit time goes to zero. Finally, we prove that the algorithm results in a Nash equilibrium."}
{"id": "2601.22078", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.22078", "abs": "https://arxiv.org/abs/2601.22078", "authors": ["Krzysztof P. Wójcik", "Michał P. Kwasigroch"], "title": "Inverted anisotropy of the partially screened magnetic impurity", "comment": "6 pages, 3 figures", "summary": "We investigate a single magnetic impurity in the presence of strong spin-orbit coupling and single-ion anisotropy. We show that at sufficiently strong coupling there exists a finite temperature window, before the moment is completely screened, where the magnetic anisotropy of the system flips: the hard-axis becomes the easy-axis or vice versa. We derive this rigorously for a single impurity using numerical renormalization group calculations as well as Nozieres' strong-coupling limit and discuss its relevance to heavy-fermion compounds which order magnetically along the hard-direction. We show that the coexistence of Curie-like response and Kondo fluctuations is stabilized along the initially hard direction leading to the anisotropy switch."}
{"id": "2601.21622", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21622", "abs": "https://arxiv.org/abs/2601.21622", "authors": ["Junhao He", "Feiran You", "Hongyang Du"], "title": "StarSD: One-for-Many Speculative Decoding", "comment": null, "summary": "Speculative decoding accelerates autoregressive generation by separating token proposal from verification, but most existing approaches are designed for single-node execution and do not scale well to multi-accelerator clusters used for serving modern Large Language Models (LLMs). We present StarSD, a one-for-many speculative decoding framework that uses a single draft model to serve multiple target models across distributed nodes via a star topology. StarSD decouples drafting and verification, enabling effective sharing of draft computation, and preventing distributed accelerators from remaining idle under bursty workloads. We provide a system-level analysis that characterizes when and why a single draft model can remain fully utilized by multiple verifiers, yielding predictable latency and utilization gains. Extensive experiments in real-world distributed inference settings demonstrate that StarSD simplifies deployment and supports flexible resource allocation across heterogeneous accelerators, while maintaining output quality. These results indicate that StarSD is a practical and scalable framework for bringing speculative decoding to modern cloud and edge inference infrastructures."}
{"id": "2601.21428", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21428", "abs": "https://arxiv.org/abs/2601.21428", "authors": ["Yoshihito Kazashi", "Fabio Nobile", "Fabio Zoccolan"], "title": "Numerical Methods for Dynamical Low-Rank Approximations of Stochastic Differential Equations -- Part I: Time discretization", "comment": "49 pages, 67 figures", "summary": "In this work (Part I), we study three time-discretization procedures of the Dynamical Low-Rank Approximation (DLRA) of high-dimensional stochastic differential equations (SDEs). Specifically, we consider the Dynamically Orthogonal (DO) method for DLRA proposed and analyzed in arXiv:2308.11581v4, which consists of a linear combination of products between deterministic orthonormal modes and stochastic modes, both time-dependent. The first strategy we consider for numerical time-integration is very standard, consisting in a forward discretization in time of both deterministic and stochastic components. Its convergence is proven subject to a time-step restriction dependent on the smallest singular value of the Gram matrix associated to the stochastic modes. Under the same condition on the time-step, this smallest singular value is shown to be always positive, provided that the SDE under study is driven by a non-degenerate noise. The second and the third algorithms, on the other hand, are staggered ones, in which we alternately update the deterministic and the stochastic modes in half steps. These approaches are shown to be more stable than the first one and allow us to obtain convergence results without the aforementioned restriction on the time-step. Computational experiments support theoretical results. In this work we do not consider the discretization in probability, which will be the topic of Part II."}
{"id": "2601.21390", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21390", "abs": "https://arxiv.org/abs/2601.21390", "authors": ["B. da Costa Paulo", "N. Aginako", "J. Ugartemendia", "I. Landa del Barrio", "M. Quartulli", "H. Camblong"], "title": "Surrogate model of a HVAC system for PV self-consumption maximisation", "comment": null, "summary": "In the last few years, energy efficiency has become a challenge. Not only mitigating environmental impact but reducing energy waste can lead to financial advantages. Buildings play an important role in this: they are among the biggest consumers. So, finding manners to reduce energy consumption is a way to minimise energy waste, and a technique for that is creating Demand Response (DR) strategies. This paper proposes a novel way to decrease computational effort of simulating the behaviour of a building using surrogate models based on active learning. Before going straight to the problem of a building, which is complex and computationally costly, the paper proposes the approach of active learning to a smaller problem: with reduced simulations, regress the curve of voltage versus current of a thermo-resistor. Then, the paper implements a surrogate model of energy consumption of a building. The goal is to be able to learn the consumption pattern based on a limited number of simulations. The result given by the surrogate can be used to set the reference temperature, maximising the PV self-consumption, and reducing energy usage from the grid. Thanks to the surrogate, the total time spent to map all possible consumption scenarios is reduced around 7 times."}
{"id": "2601.21696", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21696", "abs": "https://arxiv.org/abs/2601.21696", "authors": ["Alexandre Chaussard", "Anna Bonnet", "Sylvain Le Corff"], "title": "Independent Component Discovery in Temporal Count Data", "comment": "8 pages, 6 figures, Appendix provided", "summary": "Advances in data collection are producing growing volumes of temporal count observations, making adapted modeling increasingly necessary. In this work, we introduce a generative framework for independent component analysis of temporal count data, combining regime-adaptive dynamics with Poisson log-normal emissions. The model identifies disentangled components with regime-dependent contributions, enabling representation learning and perturbations analysis. Notably, we establish the identifiability of the model, supporting principled interpretation. To learn the parameters, we propose an efficient amortized variational inference procedure. Experiments on simulated data evaluate recovery of the mixing function and latent sources across diverse settings, while an in vivo longitudinal gut microbiome study reveals microbial co-variation patterns and regime shifts consistent with clinical perturbations."}
{"id": "2601.21668", "categories": ["math.NA", "physics.comp-ph", "physics.flu-dyn", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2601.21668", "abs": "https://arxiv.org/abs/2601.21668", "authors": ["Philipp Krah", "Zetao Lin", "R. -Paul Wilhelm", "Fabio Bacchini", "Jean-Christophe Nave", "Virginie Grandgirard", "Kai Schneider"], "title": "A Hybrid semi-Lagrangian Flow Mapping Approach for Vlasov Systems: Combining Iterative and Compositional Flow Maps", "comment": "Preprint", "summary": "We propose a hybrid semi-Lagrangian scheme for the Vlasov--Poisson equation that combines the Numerical Flow Iteration (NuFI) method with the Characteristic Mapping Method (CMM). Both approaches exploit the semi-group property of the underlying diffeomorphic flow, enabling the reconstruction of solutions through flow maps that trace characteristics back to their initial positions. NuFI builds this flow map iteratively, preserving symplectic structure and conserving invariants, but its computational cost scales quadratically with time. Its advantage lies in a compact, low-dimensional representation depending only on the electric field. In contrast, CMM achieves low computational costs when remapping by composing the global flow map from explicitly stored submaps. The proposed hybrid method merges these strengths: NuFi is employed for accurate and conservative local time stepping, while CMM efficiently propagates the solution through submap composition. This approach reduces storage requirements, maintains accuracy, and improves structural properties. Numerical experiments demonstrate the effectiveness of the scheme and highlight the trade-offs between memory usage and computational cost. We benchmark against a semi-Lagrangian predictor-corrector scheme used in modern gyrokinetic codes, evaluating accuracy and conservation properties."}
{"id": "2601.21515", "categories": ["cond-mat.stat-mech", "hep-th", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.21515", "abs": "https://arxiv.org/abs/2601.21515", "authors": ["L. Ts. Adzhemyan", "M. V. Kompaniets", "A. V. Trenogin"], "title": "Six-loop renormalization group analysis of the $φ^4 + φ^6$ model", "comment": "10 pages", "summary": "We investigate the $λ\\ph^4+g\\ph^6$ model using the renormalization group method and the $\\ep$ expansion. This model is used in a situation where the coefficients $λ$, $g$ and the coefficient $τ$ of the term $τ\\ph^2$ depend on two parameters $T$ and $P$, and there is a point ($T_c,P_c$) at which $τ$ and $λ$ are zero. This point is named the tricritical point. The description of a system depends on a trajectory that leads to the tricritical point on the plane ($T,P$). In the trajectories, when $λ$ goes to zero fast enough, the description is defined by the $\\ph^6$ interaction and then the $\\ph^4$ term can be considered as a composite operator. In this case, the logarithmic dimension is $d=3$, and the $\\ep$ expansion is carried out in the dimension $d=3-2\\ep$. The main exponents of the \\textit{tricritical} model have been calculated in the third order of the $\\ep$ expansion. Taking into account the $\\ph^4$ interaction, we were able to calculate the value of the parameter that determines the required decrease rate in $λ$ to implement the tricritical behavior. The tricritical dimensions of the composite operators $\\ph^k$ for $k=1, 2, 4, 6$ have been computed. The resulting values are compared to those known from a conformal field theory and non-perturbative renormalization group."}
{"id": "2601.20977", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.20977", "abs": "https://arxiv.org/abs/2601.20977", "authors": ["Paulo Michel F. Yamagishi", "Marcia Fampa", "Jon Lee"], "title": "The dual-path fixing strategy and its application to the set-covering problem", "comment": null, "summary": "We introduce the dual-path fixing strategy to exploit dual algorithms for solving relaxations of mixed-integer nonlinear-optimization problems. Such dual algorithms are naturally applied in the context of branch-and-bound, and eventual impact on the success of branch-and-bound is our strong motivation. Our fixing strategy aims to be more powerful than the common strategy of fixing variables based on a single dual-feasible solution (e.g., standard reduced-cost fixing for mixed-integer linear optimization), but to be much faster than ``strong fixing'', essentially requiring no more time than that of the dual algorithm that we exploit. We have successfully tested our ideas on mixed-integer linear-optimization set-covering instances from the literature, in the context of the dual-simplex method applied to the continuous relaxations."}
{"id": "2601.20871", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20871", "abs": "https://arxiv.org/abs/2601.20871", "authors": ["Rylan Malarchick"], "title": "End-to-End Fidelity Analysis of Quantum Circuit Optimization: From Gate-Level Transformations to Pulse-Level Control", "comment": null, "summary": "We present a comprehensive analysis of quantum circuit fidelity across the full compilation stack, from high-level gate optimization through pulse-level control. Using a modular integration framework connecting a C++ circuit optimizer with Lindblad-based pulse simulation, we systematically evaluate the fidelity impact of four optimization passes: gate cancellation, commutation, rotation merging, and identity elimination, on IQM Garnet hardware parameters. Our simulation campaign spanning 371 circuit runs reveals that gate cancellation provides the most significant improvement (68\\% of circuits improved, 14,024 gates eliminated), while pulse duration exhibits the strongest negative correlation with process fidelity ($r = -0.74$, $R^2 = 0.55$). We validate these findings through hardware execution on the IQM Resonance Garnet 20-qubit processor, demonstrating 70\\% gate reduction on QFT circuits with 100\\% job success rate (8 executions). Our open-source framework enables reproducible benchmarking of quantum compilation pipelines."}
{"id": "2601.20938", "categories": ["quant-ph", "cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2601.20938", "abs": "https://arxiv.org/abs/2601.20938", "authors": ["Hao Chen", "Wucheng Zhang", "Manas Kulkarni", "Abhinav Prem"], "title": "Non-Equilibrium Phase Transition in a Boundary-Driven Dissipative Fermionic Chain", "comment": "7+5 pages, 5+3 figures", "summary": "We demonstrate that a boundary-localized periodic (Floquet) drive can induce nontrivial long-range correlations in a non-interacting fermionic chain which is additionally subject to boundary dissipation. Surprisingly, we find that this phenomenon occurs even when the corresponding isolated bulk is in a trivial gapped phase with exponentially decaying correlations. We argue that this boundary-drive induced non-equilibrium transition (as witnessed through the correlation matrix) is driven by a resonance mechanism whereby the drive frequency bridges bulk energy gaps, allowing boundary-injected particles and holes to propagate and mediate long-range correlations into the bulk. We also numerically establish that when the drive bridges a particle-hole gap, the induced long-range order scales as a power law with the bulk pairing potential ($χ\\sim γ^2$). Our results highlight the potential of localized coherent driving for generating macroscopic order in open quantum systems."}
{"id": "2601.21651", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21651", "abs": "https://arxiv.org/abs/2601.21651", "authors": ["Savvas Panagi", "Chrysovalantis Spanias", "Petros Aristidou"], "title": "A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps", "comment": null, "summary": "The growing electrification of transportation and heating through Electric Vehicles (EVs) and Heat Pumps (HPs) introduces both flexibility and complexity to Active Distribution Networks (ADNs). These resources provide substantial operational flexibility but also create tightly coupled thermal-electrical dynamics that challenge conventional network management. This paper proposes a unified co-optimization framework that integrates a calibrated 3R2C grey-box building thermal model into a network-constrained Optimal Power Flow (OPF). The framework jointly optimizes EVs, HPs, and photovoltaic systems while explicitly enforcing thermal comfort, Distributed Energy Resource (DER) limits, and full power flow physics. To maintain computational tractability, Second-Order Cone Programming (SOCP) relaxations are evaluated on a realistic low-voltage feeder. The analysis shows that, despite network heterogeneity violating some theoretical exactness conditions, the relaxation remains exact in practice. Comparative assessments of convex DistFlow, bus injection, and branch flow formulations reveal that convex DistFlow achieves sub-second runtimes and near-optimal performance even at high DER penetration levels. Simulations confirm the effectiveness of coordinated scheduling, yielding reductions of 41% in transformer aging, 54% in losses, and complete elimination of voltage violations, demonstrating the value of integrated thermal-electrical coordination in future smart grids."}
{"id": "2601.21635", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21635", "abs": "https://arxiv.org/abs/2601.21635", "authors": ["Giovanni Taraschi", "Maicon Ribeiro Correa"], "title": "Numerical analysis of a locking-free primal hybrid method for linear elasticity with $H(\\mathrm{div})$-conforming stress recovery", "comment": null, "summary": "In this work, we study a primal hybrid finite element method for the approximation of linear elasticity problems, posed in terms of displacement, an auxiliary pressure field, and a Lagrange multiplier related to the traction. We develop a general analysis for the existence and uniqueness of the solution for the discrete problem, which is applied to the construction of stable approximation spaces on triangular and quadrilateral meshes. The use of these spaces lead to optimal convergence orders, resulting in a locking-free method capable of providing robust approximations for nearly incompressible problems. Finally, we propose a strategy for recovering the stress field from the hybrid solution by solving element-wise sub-problems. The resulting stress approximation is $H(\\mathrm{div})$-conforming, locally equilibrated, weakly symmetric, and robust to locking."}
{"id": "2601.21562", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21562", "abs": "https://arxiv.org/abs/2601.21562", "authors": ["Xiang Zhu", "Xiuqiang He", "Hongyang Qing", "Hua Geng"], "title": "Decentralized Analysis Approach for Oscillation Damping in Grid-Forming and Grid-Following Heterogeneous Power Systems", "comment": null, "summary": "This letter proposes a decentralized local gain condition (LGC) to guarantee oscillation damping in inverter-based resource (IBR)-dominated power systems. The LGC constrains the dynamic gain between each IBR and the network at its point of connection. By satisfying the LGC locally, the closed-loop poles are confined to a desired region, thereby yielding system-wide oscillation damping without requiring global information. Notably, the LGC is agnostic to different IBR dynamics, well-suited for systems with heterogeneous IBRs, and flexible to various damping requirements. Moreover, a low-complexity algorithm is proposed to parameterize LGC, providing scalable and damping-constrained parameter tuning guidance for IBRs."}
{"id": "2601.21732", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.21732", "abs": "https://arxiv.org/abs/2601.21732", "authors": ["Xiaoyu Hu", "Zhenhua Lin"], "title": "Neural Wasserstein Two-Sample Tests", "comment": "49 pages, 3 figures", "summary": "The two-sample homogeneity testing problem is fundamental in statistics and becomes particularly challenging in high dimensions, where classical tests can suffer substantial power loss. We develop a learning-assisted procedure based on the projection 1-Wasserstein distance, which we call the neural Wasserstein test. The method is motivated by the observation that there often exists a low-dimensional projection under which the two high-dimensional distributions differ. In practice, we learn the projection directions via manifold optimization and a witness function using deep neural networks. To adapt to unknown projection dimensions and sparsity levels, we aggregate a collection of candidate statistics through a max-type construction, avoiding explicit tuning while potentially improving power. We establish the validity and consistency of the proposed test and prove a Berry--Esseen type bound for the Gaussian approximation. In particular, under the null hypothesis, the aggregated statistic converges to the absolute maximum of a standard Gaussian vector, yielding an asymptotically pivotal (distribution-free) calibration that bypasses resampling. Simulation studies and a real-data example demonstrate the strong finite-sample performance of the proposed method."}
{"id": "2601.21591", "categories": ["cond-mat.stat-mech", "cond-mat.soft", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.21591", "abs": "https://arxiv.org/abs/2601.21591", "authors": ["Katie L. Y. Zhou", "Anna T. Bui", "Stephen J. Cox"], "title": "The roles of bulk and surface thermodynamics in the selective adsorption of a confined azeotropic mixture", "comment": "Main: 14 pages, 5 figures. SI: 5 pages, 4 figures", "summary": "Fluid mixtures that exhibit an azeotrope cannot be purified by simple bulk distillation. Consequently, there is strong motivation to understand the behavior of azeotropic mixtures under confinement. We address this problem using a machine-learning-enhanced classical density functional theory applied to a binary Lennard-Jones mixture that exhibits azeotropic phase behavior. As proof-of-principle of a \"train once, learn many\" strategy, our approach combines a neural functional trained on a single-component repulsive reference system with a mean-field treatment of attractive interactions, derived within the framework of hyperdensity functional theory (hyper-DFT). The theory faithfully describes capillary condensation and results from grand canonical Monte Carlo simulations. Moreover, by taking advantage of a known accurate equation of state, the theory we present well-describes bulk thermodynamics by construction. Exploiting the computational efficiency of hyper-DFT, we systematically evaluate adsorption selectivity across a wide range of compositions, pressures, temperatures, and wall-fluid affinities. In cases where the wall-fluid interaction is the same for both species, we find that the pore becomes completely unselective at the bulk azeotropic composition. Strikingly, this unselective point persists far from liquid-vapor coexistence, including in the supercritical regime. Analysis of the bulk equation of state across a wide range of thermodynamic state points shows that the azeotropic composition coincides with equal partial molar volumes and an extremum in the isothermal compressibility. A complementary thermodynamic analysis demonstrates that unselective adsorption corresponds to an aneotrope (a point of zero relative adsorption) and an extremum in the interfacial free energy. We also find that the two interfaces of the slit pore behave independently down to remarkably small slits."}
{"id": "2601.21166", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21166", "abs": "https://arxiv.org/abs/2601.21166", "authors": ["Taha El Bakkali", "Rayane Bouftini", "Qiuyi Zhang", "Omar Saadi"], "title": "Noisy Pairwise-Comparison Random Search for Smooth Nonconvex Optimization", "comment": null, "summary": "We consider minimizing high-dimensional smooth nonconvex objectives using only noisy pairwise comparisons. Unlike classical zeroth-order methods limited by the ambient dimension $d$, we propose Noisy-Comparison Random Search (NCRS), a direct-search method that exploits random line search to adapt to the intrinsic dimension $k \\le d$. We establish novel non-convex convergence guarantees for approximate stationarity: under a uniform-margin oracle, NCRS attains $ε$-stationarity with complexity $\\mathcal{O}(k/(p^{2}ε^{2}))$, explicitly replacing ambient dependence with the intrinsic dimension. Furthermore, we introduce a general tie-aware noise model where comparison quality degrades near ties; for this setting, we prove that a majority-vote variant of NCRS achieves $ε$-stationarity with complexity $\\mathcal{O}(k^{2}/ε^{4})$."}
{"id": "2601.20872", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20872", "abs": "https://arxiv.org/abs/2601.20872", "authors": ["Shiang-Yi Han", "Ciann-Dong Yang"], "title": "An Ontological Interpretation of Photon Wave-Particle Duality via Complex-Space Trajectories", "comment": null, "summary": "Wave particle duality remains a central interpretational challenge in quantum theory. In this work, we develop a trajectory-based description of photon dynamics formulated in an extended complex space within the relativistic quantum Hamilton Jacobi framework. In this approach, photon motion is represented by complex trajectories whose real projections describe propagation, while imaginary components encode oscillatory structure. We show that momentum eigenstates correspond to straight line trajectories with uniform propagation at the speed of light, whereas superposition states lead to nontrivial quantum potentials and oscillatory motion in the complex plane. Extending the analysis to complex two dimensional space reveals richer dynamical behavior, including propagating wave like trajectories and standing wave like patterns in real projections. Energy momentum consistency is verified through an internal coherence analysis based on projected standing wave wavelengths. Rather than introducing new dynamical laws or additional physical dimensions, the complex space is employed as an interpretational framework that renders wave like and particle like aspects as complementary projections of a single underlying motion. The results suggest a unified geometric perspective on wave particle duality, while remaining fully compatible with standard quantum mechanics."}
{"id": "2601.20956", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.20956", "abs": "https://arxiv.org/abs/2601.20956", "authors": ["Chiu Fan Bowen Lo", "Anasuya Lyons", "Dan Gresh", "Michael Mills", "Peter E. Siegfried", "Maxwell D. Urmey", "Nathanan Tantivasadakarn", "Henrik Dreyer", "Ashvin Vishwanath", "Ruben Verresen", "Mohsin Iqbal"], "title": "Universal Topological Gates from Braiding and Fusing Anyons on Quantum Hardware", "comment": "main text: 7+ε pages and 7 figures; total: 50 pages and 25 figures", "summary": "Topological quantum computation encodes quantum information in the internal fusion space of non-Abelian anyonic quasiparticles, whose braiding implements logical gates. This goes beyond Abelian topological order (TO) such as the toric code, as its anyons lack internal structure. However, the simplest non-Abelian generalizations of the toric code do not support universality via braiding alone. Here we demonstrate that such minimally non-Abelian TOs can be made universal by treating anyon fusion as a computational primitive. We prepare a 54-qubit TO wavefunction associated with the smallest non-Abelian group, $S_3$, on Quantinuum's H2 quantum processor. This phase of matter exhibits cyclic anyon fusion rules, known to underpin universality, which we evidence by trapping a single non-Abelian anyon on the torus. We encode logical qutrits in the nonlocal fusion space of non-Abelian fluxes and, by combining an entangling braiding operation with anyon charge measurements, realize a universal topological gate set and read-out, which we further demonstrate by topologically preparing a magic state. This work establishes $S_3$ TO as simple enough to be prepared efficiently, yet rich enough to enable universal topological quantum computation."}
{"id": "2601.21679", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21679", "abs": "https://arxiv.org/abs/2601.21679", "authors": ["Yuansheng Lian", "Ke Zhang", "Yaming Guo", "Shen Li", "Meng Li"], "title": "BAP-SRL: Bayesian Adaptive Priority Safe Reinforcement Learning for Vehicle Motion Planning at Mixed Traffic Intersections", "comment": null, "summary": "Navigating urban intersections, especially when interacting with heterogeneous traffic participants, presents a formidable challenge for autonomous vehicles (AVs). In such environments, safety risks arise simultaneously from multiple sources, each carrying distinct priority levels and sensitivities that necessitate differential protection preferences. While safe reinforcement learning (RL) offers a robust paradigm for constrained decision-making, existing methods typically model safety as a single constraint or employ static, heuristic weighting schemes for multiple constraints. These approaches often fail to address the dynamic nature of multi-source risks, leading to gradient cancellation that hampers learning, and suboptimal trade-offs in critical dilemma zones. To address this, we propose a Bayesian adaptive priority safe reinforcement learning (BAP-SRL) based motion planning framework. Unlike heuristic weighting schemes, BAP formulates constraint prioritization as a probabilistic inference task. By modeling historical optimization difficulty as a Bayesian prior and instantaneous risk evidence as a likelihood, BAP dynamically gates gradient updates using a Bayesian inference mechanism on latent constraint criticality. Extensive experiments demonstrate that our approach outperforms state-of-the-art baselines in handling interactions with stochastic, heterogeneous agents, achieving lower collision rates and smoother conflict resolution."}
{"id": "2601.21668", "categories": ["math.NA", "physics.comp-ph", "physics.flu-dyn", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2601.21668", "abs": "https://arxiv.org/abs/2601.21668", "authors": ["Philipp Krah", "Zetao Lin", "R. -Paul Wilhelm", "Fabio Bacchini", "Jean-Christophe Nave", "Virginie Grandgirard", "Kai Schneider"], "title": "A Hybrid semi-Lagrangian Flow Mapping Approach for Vlasov Systems: Combining Iterative and Compositional Flow Maps", "comment": "Preprint", "summary": "We propose a hybrid semi-Lagrangian scheme for the Vlasov--Poisson equation that combines the Numerical Flow Iteration (NuFI) method with the Characteristic Mapping Method (CMM). Both approaches exploit the semi-group property of the underlying diffeomorphic flow, enabling the reconstruction of solutions through flow maps that trace characteristics back to their initial positions. NuFI builds this flow map iteratively, preserving symplectic structure and conserving invariants, but its computational cost scales quadratically with time. Its advantage lies in a compact, low-dimensional representation depending only on the electric field. In contrast, CMM achieves low computational costs when remapping by composing the global flow map from explicitly stored submaps. The proposed hybrid method merges these strengths: NuFi is employed for accurate and conservative local time stepping, while CMM efficiently propagates the solution through submap composition. This approach reduces storage requirements, maintains accuracy, and improves structural properties. Numerical experiments demonstrate the effectiveness of the scheme and highlight the trade-offs between memory usage and computational cost. We benchmark against a semi-Lagrangian predictor-corrector scheme used in modern gyrokinetic codes, evaluating accuracy and conservation properties."}
{"id": "2601.21622", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21622", "abs": "https://arxiv.org/abs/2601.21622", "authors": ["Junhao He", "Feiran You", "Hongyang Du"], "title": "StarSD: One-for-Many Speculative Decoding", "comment": null, "summary": "Speculative decoding accelerates autoregressive generation by separating token proposal from verification, but most existing approaches are designed for single-node execution and do not scale well to multi-accelerator clusters used for serving modern Large Language Models (LLMs). We present StarSD, a one-for-many speculative decoding framework that uses a single draft model to serve multiple target models across distributed nodes via a star topology. StarSD decouples drafting and verification, enabling effective sharing of draft computation, and preventing distributed accelerators from remaining idle under bursty workloads. We provide a system-level analysis that characterizes when and why a single draft model can remain fully utilized by multiple verifiers, yielding predictable latency and utilization gains. Extensive experiments in real-world distributed inference settings demonstrate that StarSD simplifies deployment and supports flexible resource allocation across heterogeneous accelerators, while maintaining output quality. These results indicate that StarSD is a practical and scalable framework for bringing speculative decoding to modern cloud and edge inference infrastructures."}
{"id": "2601.21752", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.21752", "abs": "https://arxiv.org/abs/2601.21752", "authors": ["Nina Moutonnet", "Joshua Corneck", "Felipe Tobar", "Danilo Mandic"], "title": "Synthesizing Epileptic Seizures: Gaussian Processes for EEG Generation", "comment": null, "summary": "Reliable seizure detection from electroencephalography (EEG) time series is a high-priority clinical goal, yet the acquisition cost and scarcity of labeled EEG data limit the performance of machine learning methods. This challenge is exacerbated by the long-range, high-dimensional, and non-stationary nature of epileptic EEG recordings, which makes realistic data generation particularly difficult. In this work, we revisit Gaussian processes as a principled and interpretable foundation for modeling EEG dynamics, and propose a novel hierarchical framework, \\textit{GP-EEG}, for generating synthetic epileptic EEG recordings. At its core, our approach decomposes EEG signals into temporal segments modeled via Gaussian process regression, and integrates a domain-adaptation variational autoencoder. We validate the proposed method on two real-world, open-source epileptic EEG datasets. The synthetic EEG recordings generated by our model match real-world epileptic EEG both quantitatively and qualitatively, and can be used to augment training sets."}
{"id": "2601.21671", "categories": ["cond-mat.stat-mech", "nlin.CD", "nlin.PS"], "pdf": "https://arxiv.org/pdf/2601.21671", "abs": "https://arxiv.org/abs/2601.21671", "authors": ["Divya D. Joshi", "Trupti R. Sharma", "Prashant M. Gade"], "title": "Pattern Formation in Excitable Neuronal Maps", "comment": "9 pages, 6 figures, 30 subfigures", "summary": "Coupled excitable systems can generate a variety of patterns. In this work, we investigate coupled Chialvo maps in two dimensions under two types of nearest-neighbor couplings. One coupling produces ringlike patterns, while the other produces spirals. The rings expand with increasing coupling, whereas spirals evolve into turbulence and dissipate at stronger coupling. To quantify these patterns, we introduce an analogue of the discriminant of the velocity gradient tensor and examine the persistence of its sign. For ring-type patterns, the persistence decays more slowly than exponentially, often following a power law or stretched exponential. When spiral structures remain intact, persistence saturates asymptotically and can exhibit superposed periodic oscillations, suggesting complex exponents at early times. These behaviors highlight deep connections with the underlying dynamics."}
{"id": "2601.21243", "categories": ["math.OC", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21243", "abs": "https://arxiv.org/abs/2601.21243", "authors": ["Amir Ali Farzin", "Yuen-Man Pun", "Philipp Braun", "Tyler Summers", "Iman Shames"], "title": "Solving the Offline and Online Min-Max Problem of Non-smooth Submodular-Concave Functions: A Zeroth-Order Approach", "comment": null, "summary": "We consider max-min and min-max problems with objective functions that are possibly non-smooth, submodular with respect to the minimiser and concave with respect to the maximiser. We investigate the performance of a zeroth-order method applied to this problem. The method is based on the subgradient of the Lovász extension of the objective function with respect to the minimiser and based on Gaussian smoothing to estimate the smoothed function gradient with respect to the maximiser. In expectation sense, we prove the convergence of the algorithm to an $ε$-saddle point in the offline case. Moreover, we show that, in the expectation sense, in the online setting, the algorithm achieves $O(\\sqrt{N\\bar{P}_N})$ online duality gap, where $N$ is the number of iterations and $\\bar{P}_N$ is the path length of the sequence of optimal decisions. The complexity analysis and hyperparameter selection are presented for all the cases. The theoretical results are illustrated via numerical examples."}
{"id": "2601.20873", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20873", "abs": "https://arxiv.org/abs/2601.20873", "authors": ["P. J. Rijken", "Th. A. Rijken"], "title": "Novel method for evaluating the eigenvalues of the Heun differential equation with an application to the Breit equation", "comment": null, "summary": "Eigenvalues of the Breit equation, in which only the static Coulomb potential is considered, have been found. Over the past decades several authors have analyzed the Breit equation to obtain numerically or by approximation an estimation of the energy levels. Various approaches have been used and no determination of the energy levels currently exists that is directly based on the second order Heun differential equation derived.\n  The aim of this work is to provide a method of calculation that can be used to numerically calculate the energy levels for various spin states to high accuracy.\n  From the Breit equation, we derive the corresponding second-order Heun differential equation and continued fraction from which the eigenvalues can be determined very accurately. Next, we present a novel method based on the Green function method, which leads to a semi-infinite determinant from which we are able to obtain the numerical values of the eigenvalues by direct calculation.\n  Using suitable numerical methods for the direct calculation of the continued fraction and the semi-infinite determinant, we show that both methods are consistent within 25 digits of accuracy. We show that the correct energy levels for the Dirac equation follow from our results by a suitable mapping of the variables.\n  The results are in total agreement with earlier calculations found in the literature and extend this by several digits of additional accuracy. The condition on the determinant giving the energy levels provides a rich structure that is promising in extending the results of this work."}
{"id": "2601.21134", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21134", "abs": "https://arxiv.org/abs/2601.21134", "authors": ["Tobias Swann", "Adam Nahum"], "title": "Continuum mechanics of entanglement in noisy interacting fermion chains", "comment": "24 pages, 10 figures", "summary": "We develop an effective continuum description for information scrambling in a chain of randomly interacting Majorana fermions. The approach is based on the semiclassical treatment of the path integral for an effective spin chain that describes \"two-replica\" observables such as the entanglement purity and the OTOC. This formalism gives exact results for the entanglement membrane and for operator spreading in the limit of weak interactions. In this limit there is a large crossover lengthscale between free and interacting behavior, and this large lengthscale allows for a continuum limit and a controlled saddle-point calculation. The formalism is also somewhat different from that known from random unitary circuits. The entanglement membrane emerges as a kind of bound state of two travelling waves, and shows an interesting unbinding phenomenon as the velocity of the entanglement membrane approaches the butterfly velocity."}
{"id": "2601.21753", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21753", "abs": "https://arxiv.org/abs/2601.21753", "authors": ["Italo Napolitano", "Mario di Bernardo"], "title": "Optimal Transport for Time-Varying Multi-Agent Coverage Control", "comment": "Keywords: Optimal Transport; Multi-Agent Systems; Coverage Control; Wasserstein Distance; Time-Varying Density; Autonomous Systems; Distributed Control", "summary": "Coverage control algorithms have traditionally focused on static target densities, where agents are deployed to optimally cover a fixed spatial distribution. However, many applications involve time-varying densities, including environmental monitoring, surveillance, and adaptive sensor deployment. Although time-varying coverage strategies have been studied within Voronoi-based frameworks, recent works have reformulated static coverage control as a semi-discrete optimal transport problem. Extending this optimal transport perspective to time-varying scenarios has remained an open challenge. This paper presents a rigorous optimal transport formulation for time-varying coverage control, in which agents minimize the instantaneous Wasserstein distance to a continuously evolving target density. The proposed solution relies on a coupled system of differential equations governing agent positions and the dual variables that define Laguerre regions. In one-dimensional domains, the resulting system admits a closed-form analytical solution, offering both computational benefits and theoretical insight into the structure of optimal time-varying coverage. Numerical simulations demonstrate improved tracking performance compared to quasi-static and Voronoi-based methods, validating the proposed framework."}
{"id": "2601.21707", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21707", "abs": "https://arxiv.org/abs/2601.21707", "authors": ["Tamás Dózsa", "Andrea Angino", "Zoltán Szabó", "József Bokor", "Matthias Voigt"], "title": "Adaptive Kernel Methods", "comment": "Submitted to IEEE Transactions on Neural Networks and Learning Systems for review", "summary": "Kernel methods approximate nonlinear maps in a data-driven manner by projecting the target map onto a finite-dimensional Hilbert space called the solution space. Traditionally, this space is a subspace of a fixed ambient reproducing kernel Hilbert space (RKHS), determined solely by the chosen kernel and the dataset, whose elements identify the basis elements. Consequently, the projection operator underlying the kernel method depends on the loss function, the dataset, and the choice of ambient RKHS. In this study, we consider kernel methods whose solution spaces also depend on learnable parameters that are independent of the dataset. The resulting methods can be viewed as variable projection operators that depend on the loss function, the dataset, and the new learnable parameters instead of a fixed RKHS. This work has two main contributions. First, we propose an efficient approximation of kernels associated with infinite-dimensional RKHSs, commonly used to reduce the solution-space dimension for large datasets. Second, we construct fixed-dimensional, parameter-dependent solution spaces that enable highly efficient kernel models suitable for large-scale problems without the need to approximate kernels of infinite-dimensional RKHSs. Our novel family of adaptive kernel methods generalizes earlier approaches, including Random Fourier Features, and we demonstrate their effectiveness through several numerical experiments."}
{"id": "2601.21651", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21651", "abs": "https://arxiv.org/abs/2601.21651", "authors": ["Savvas Panagi", "Chrysovalantis Spanias", "Petros Aristidou"], "title": "A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps", "comment": null, "summary": "The growing electrification of transportation and heating through Electric Vehicles (EVs) and Heat Pumps (HPs) introduces both flexibility and complexity to Active Distribution Networks (ADNs). These resources provide substantial operational flexibility but also create tightly coupled thermal-electrical dynamics that challenge conventional network management. This paper proposes a unified co-optimization framework that integrates a calibrated 3R2C grey-box building thermal model into a network-constrained Optimal Power Flow (OPF). The framework jointly optimizes EVs, HPs, and photovoltaic systems while explicitly enforcing thermal comfort, Distributed Energy Resource (DER) limits, and full power flow physics. To maintain computational tractability, Second-Order Cone Programming (SOCP) relaxations are evaluated on a realistic low-voltage feeder. The analysis shows that, despite network heterogeneity violating some theoretical exactness conditions, the relaxation remains exact in practice. Comparative assessments of convex DistFlow, bus injection, and branch flow formulations reveal that convex DistFlow achieves sub-second runtimes and near-optimal performance even at high DER penetration levels. Simulations confirm the effectiveness of coordinated scheduling, yielding reductions of 41% in transformer aging, 54% in losses, and complete elimination of voltage violations, demonstrating the value of integrated thermal-electrical coordination in future smart grids."}
{"id": "2601.22103", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22103", "abs": "https://arxiv.org/abs/2601.22103", "authors": ["Greg Kreider"], "title": "A Spacing Estimator", "comment": "40 pages, 3 figures", "summary": "The distribution of the spacing, or the difference between consecutive order statistics, is known only for uniform and exponential random variates. We add here logistic and Gumbel variates, and present an estimator for distributions with a known inverse cumulative density function. We show the estimator is accurate to the limit of numerical simulations for points near the middle of the order statistics, but degrades by up to 20% in the tails."}
{"id": "2512.20215", "categories": ["quant-ph", "cond-mat.stat-mech", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.20215", "abs": "https://arxiv.org/abs/2512.20215", "authors": ["Thomas Barthel"], "title": "Tree tensor network states represent low-energy states faithfully", "comment": "9 pages, 2 figures", "summary": "Extending corresponding results for matrix product states [Verstraete and Cirac, PRB 73, 094423 (2006); Schuch et al. PRL 100, 030504 (2008)], it is shown how the approximation error of tree tensor network states (TTNS) can be bounded using Schmidt spectra or Rényi entanglement entropies of the target quantum state. Conversely, one obtains bounds on TTNS bond dimensions needed to achieve a specific approximation accuracy. For tree lattices, the result implies that efficient TTNS approximations exist if $α<1$ Rényi entanglement entropies for single-branch cuts obey an area law, as in ground and low-energy states of certain gapped systems."}
{"id": "2601.21333", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21333", "abs": "https://arxiv.org/abs/2601.21333", "authors": ["Pinxi Gong", "Lexiao Lai", "Jianhao Ma"], "title": "Certifying optimality in nonconvex robust PCA", "comment": null, "summary": "Robust principal component analysis seeks to recover a low-rank matrix from fully observed data with sparse corruptions. A scalable approach fits a low-rank factorization by minimizing the sum of entrywise absolute residuals, leading to a nonsmooth and nonconvex objective. Under standard incoherence conditions and a random model for the corruption support, we study factorizations of the ground-truth rank-$r$ matrix with both factors of rank $r$. With high probability, every such factorization is a Clarke critical point. We also characterize the local geometry: when the factorization rank equals $r$, these solutions are sharp local minima; when it exceeds $r$, they are strict saddle points."}
{"id": "2601.20877", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20877", "abs": "https://arxiv.org/abs/2601.20877", "authors": ["Sathish Krishna Anumula", "Harinatha Reddy Chennam", "Ranganath Nagesh Taware", "Balakumar Ravindranath Kunthu"], "title": "AI Optimized Routing and Resource Allocation for Quantum Enabled Non Terrestrial Industrial Networks", "comment": "9 Pages 7 Figures", "summary": "The industrial transformation of Industry 4 and 5 results in cyber physical production systems that require secure resilient and energy efficient connectivity over integrated terrestrial and nonterrestrial networks NTNs Since its operation over fiber spans over 5G or 6G infrastructures to Low Earth Orbit LEO satellites quantum communication techniques enabled by Quantum Key Distribution QKD together with entanglement assisted links have the potential for high assurance security as well as synchronization But quantum channels are extremely vulnerable to any kind of impairment be it environmental or physicalsuch as effects induced by atmospheric turbulence pointing errors Doppler shifts satellite motion restricted optical power and limited quantum memory All these factors make for a tightly coupled routing and resource allocation problem that unfortunately cannot be addressed at scale by existing approaches to network control."}
{"id": "2601.21502", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "hep-th", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.21502", "abs": "https://arxiv.org/abs/2601.21502", "authors": ["Yiteng Zhang", "Li-Ping Yang", "Hong-Hao Tu", "Yueshui Zhang"], "title": "Finite-size corrections to the crosscap overlap in the two-dimensional Ising model", "comment": "6 pages, 3 figures", "summary": "We analyze the finite-size corrections to the crosscap overlap in the two-dimensional classical Ising model along its self-dual critical line. Using a fermionic formulation, we express the lattice crosscap overlap in terms of Bogoliubov angles and develop a contour-integral approach by analytically continuing the lattice momentum to the complex plane. This leads to a remarkably simple expression for the crosscap overlap, which demonstrates that the finite-size corrections decay exponentially with system size. We further derive an exact analytical formula for the corresponding decay constant and show that it is determined by the complex singularity structure of the Bogoliubov angle."}
{"id": "2601.22052", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22052", "abs": "https://arxiv.org/abs/2601.22052", "authors": ["Sten Elling Tingstad Jacobsen", "Attila Lischka", "Balázs Kulcsár", "Anders Lindman"], "title": "Learning to Dial-a-Ride: A Deep Graph Reinforcement Learning Approach to the Electric Dial-a-Ride Problem", "comment": null, "summary": "Urban mobility systems are transitioning toward electric, on-demand services, creating operational challenges for fleet management under energy and service-quality constraints. The Electric Dial-a-Ride Problem (E-DARP) extends the classical dial-a-ride problem by incorporating limited battery capacity and nonlinear charging dynamics, increasing computational complexity and limiting the scalability of exact methods for real-time use. This paper proposes a deep reinforcement learning approach based on a graph neural network encoder and an attention-driven route construction policy. By operating directly on edge attributes such as travel time and energy consumption, the method captures non-Euclidean, asymmetric, and energy-dependent routing costs in real road networks. The learned policy jointly optimizes routing, charging, and service quality without relying on Euclidean assumptions or handcrafted heuristics. The approach is evaluated on two case studies using ride-sharing data from San Francisco. On benchmark instances, the method achieves solutions within 0.4% of best-known results while reducing computation times by orders of magnitude. A second case study considers large-scale instances with up to 250 request pairs, realistic energy models, and nonlinear charging. On these instances, the learned policy outperforms Adaptive Large Neighborhood Search (ALNS) by 9.5% in solution quality while achieving 100% service completion, with sub-second inference times compared to hours for the metaheuristic. Finally, sensitivity analyses quantify the impact of battery capacity, fleet size, ride-sharing capacity, and reward weights, while robustness experiments show that deterministically trained policies generalize effectively under stochastic conditions."}
{"id": "2601.21736", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21736", "abs": "https://arxiv.org/abs/2601.21736", "authors": ["Michael Hinze", "Christian Kahle", "Michael Stahl"], "title": "A reduced basis method for parabolic PDEs based on a space-time least squares formulation", "comment": null, "summary": "In this work, we present a POD-greedy reduced basis method for parabolic partial differential equations (PDEs), based on the least squares space-time formulation proposed in [Hinze, Kahle, Stahl, A least-squares space-time approach for parabolic equations, 2023, arXiv:2305.03402] that assumes only minimal regularity. We extend this approach to the parameter-dependent case. The corresponding variational formulation then is based on a parameter-dependent, symmetric, uniformly coercive, and continuous bilinear form. We apply the reduced basis method to this formulation, following the well-developed techniques for parameterized coercive problems, as seen e.g. in reduced basis methods for parameterized elliptic PDEs. We present an offline-online decomposition and provide certification with absolute and relative error bounds. The performance of the method is demonstrated using selected numerical examples."}
{"id": "2601.21679", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21679", "abs": "https://arxiv.org/abs/2601.21679", "authors": ["Yuansheng Lian", "Ke Zhang", "Yaming Guo", "Shen Li", "Meng Li"], "title": "BAP-SRL: Bayesian Adaptive Priority Safe Reinforcement Learning for Vehicle Motion Planning at Mixed Traffic Intersections", "comment": null, "summary": "Navigating urban intersections, especially when interacting with heterogeneous traffic participants, presents a formidable challenge for autonomous vehicles (AVs). In such environments, safety risks arise simultaneously from multiple sources, each carrying distinct priority levels and sensitivities that necessitate differential protection preferences. While safe reinforcement learning (RL) offers a robust paradigm for constrained decision-making, existing methods typically model safety as a single constraint or employ static, heuristic weighting schemes for multiple constraints. These approaches often fail to address the dynamic nature of multi-source risks, leading to gradient cancellation that hampers learning, and suboptimal trade-offs in critical dilemma zones. To address this, we propose a Bayesian adaptive priority safe reinforcement learning (BAP-SRL) based motion planning framework. Unlike heuristic weighting schemes, BAP formulates constraint prioritization as a probabilistic inference task. By modeling historical optimization difficulty as a Bayesian prior and instantaneous risk evidence as a likelihood, BAP dynamically gates gradient updates using a Bayesian inference mechanism on latent constraint criticality. Extensive experiments demonstrate that our approach outperforms state-of-the-art baselines in handling interactions with stochastic, heterogeneous agents, achieving lower collision rates and smoother conflict resolution."}
{"id": "2601.22106", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22106", "abs": "https://arxiv.org/abs/2601.22106", "authors": ["Harry T. Bond", "Bertrand Gauthier", "Kirstin Strokorb"], "title": "Information-geometry-driven graph sequential growth", "comment": "23 pages, 10 figures", "summary": "We investigate the properties of a class of regularisation-free approaches for Gaussian graphical inference based on the information-geometry-driven sequential growth of initially edgeless graphs. Relating the growth of a graph to a coordinate descent process, we characterise the fully-corrective descents corresponding to information-optimal growths, and propose numerically efficient strategies for their approximation. We demonstrate the ability of the proposed procedures to reliably extract sparse graphical models while limiting the number of false detections, and illustrate how activation ranks can provide insight into the informational relevance of edge sets. The considered approaches are tuning-parameter-free and have complexities akin to coordinate descents."}
{"id": "2601.20925", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.20925", "abs": "https://arxiv.org/abs/2601.20925", "authors": ["Ankit W. Shrestha", "Budhaditya Bhattacharjee", "Adolfo del Campo"], "title": "Double-Bracket Master Equations: Phase-Space Representation and Classical Limit", "comment": "18 pages, 7 figures", "summary": "We investigate the classical limit of quantum master equations featuring double-bracket dissipators. Specifically, we consider dissipators defined by double commutators, which describe dephasing dynamics, as well as dissipators involving double anticommutators, associated with fluctuating anti-Hermitian Hamiltonians. The classical limit is obtained by formulating the open quantum dynamics in phase space using the Wigner function and Moyal products, followed by a systematic $\\hbar$-expansion. We begin with the well-known model of energy dephasing, associated with energy diffusion. We then turn to master equations containing a double anticommutator with the system Hamiltonian, recently derived in the context of noisy non-Hermitian systems. For both classes of double-bracket equations, we provide a gradient-flow representation of the dynamics. We analyze the classical limit of the resulting evolutions for harmonic and driven anharmonic quantum oscillators, considering both classical and nonclassical initial states. The dynamics is characterized through the evolution of several observables as well as the Wigner logarithmic negativity. We conclude by extending our analysis to generalized master equations involving higher-order nested brackets, which provide a time-continuous description of spectral filtering techniques commonly used in the numerical analysis of quantum systems."}
{"id": "2601.21355", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21355", "abs": "https://arxiv.org/abs/2601.21355", "authors": ["Rongxing Du", "Hoi-To Wai"], "title": "Decentralized Learning with Dynamically Refined Edge Weights: A Data-Dependent Framework", "comment": "4 pages(without appendix)", "summary": "This paper aims to accelerate decentralized optimization by strategically designing the edge weights used in the agent-to-agent message exchanges. We propose a Dynamic Directed Decentralized Gradient (D3GD) framework and show that the proposed data-dependent framework is a practical alternative to the classical directed DGD (Di-DGD) algorithm for learning on directed graphs. To obtain a strategy for edge weights refinement, we derive a design function inspired by the cost-to-go function in a new convergence analysis for Di-DGD. This results in a data-dependent dynamical design for the edge weights. A fully decentralized version of D3GD is developed such that each agent refines its communication strategy using only neighbor's information. Numerical experiments show that D3GD accelerates convergence towards stationary solution by 30-40\\% over Di-DGD, and learns edge weights that adapt to data similarity."}
{"id": "2601.20887", "categories": ["quant-ph", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.20887", "abs": "https://arxiv.org/abs/2601.20887", "authors": ["Takeru Goto", "Masayuki Ohzeki"], "title": "Micro-mobility dispatch optimization via quantum annealing incorporating historical data", "comment": "15 pages, 7 figures, 1 table", "summary": "This paper proposes a novel dispatch formulation for micro-mobility vehicles using a Quantum Annealer (QA). In recent years, QA has gained increasing attention as a high-performance solver for combinatorial optimization problems. Meanwhile, micro-mobility services have been rapidly developed as a promising means of realizing efficient and sustainable urban transportation. In this study, the dispatch problem for such micro-mobility services is formulated as a Quadratic Unconstrained Binary Optimization (QUBO) problem, enabling efficient solving through QA. Furthermore, the proposed formulation incorporates historical usage data to enhance operational efficiency. Specifically, customer arrival frequencies and destination distributions are modeled into the QUBO formulation through a Bayesian approach, which guides the allocation of vacant vehicles to designated stations for waiting and charging. Simulation experiments are conducted to evaluate the effectiveness of the proposed method, with comparisons to conventional formulations such as the vehicle routing problem. Additionally, the performance of QA is compared with that of classical solvers to reveal its potential advantages for the proposed dispatch formulation. The effect of reverse annealing on improving solution quality is also investigated."}
{"id": "2601.22087", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22087", "abs": "https://arxiv.org/abs/2601.22087", "authors": ["Qian Zhang", "Feng Zhao", "Gord Stephen", "Chanan Singh", "Le Xie"], "title": "A Gradient-Based Capacity Accreditation Framework in Resource Adequacy: Formulation, Computation, and Practical Implications", "comment": null, "summary": "Probabilistic resource adequacy assessment is a cornerstone of modern capacity accreditation. This paper develops a gradient-based framework, in which capacity accreditation is interpreted as the directional derivative of a probabilistic resource adequacy metric with respect to resource capacity, that unifies two widely used accreditation approaches: Effective Load Carrying Capability (ELCC) and Marginal Reliability Impact (MRI). Under mild regularity conditions, we show that marginal ELCC and MRI yield equivalent accreditation factors, while their numerical implementations exhibit markedly different computational characteristics. Building on this framework, we demonstrate how infinitesimal perturbation analysis enables up to a $1000\\times$ speedup in gradient estimation for capacity accreditation, and we implement gradient-informed search algorithms that significantly accelerate ELCC computations relative to standard bisection methods. Large-scale Monte Carlo experiments show that MRI achieves substantial runtime reductions compared to ELCC and exhibits greater robustness to perturbation step-size selection. These results provide practical guidance for implementing efficient and scalable capacity accreditation in large-scale power systems."}
{"id": "2601.21764", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.21764", "abs": "https://arxiv.org/abs/2601.21764", "authors": ["Olivier Bokanowski", "Carlos Esteve-Yagüe", "Richard Tsai"], "title": "Solving Hamilton-Jacobi equations by minimizing residuals of monotone discretizations", "comment": "29 pages, 5 figures", "summary": "We derive sufficient conditions under which residual minimization yields well-posed discrete solutions for nonlinear equations defined by monotone finite--difference discretizations. Our analysis is motivated by the challenge of solving fully nonlinear Hamilton--Jacobi (HJ) equations in high dimensions by means of a Neural Network, which is trained by minimizing residuals arising from monotone discretizations of the Hamiltonian. While classical theory ensures that consistency and monotonicity imply convergence to the viscosity solution, treating these discrete systems as optimization problems introduces new analytical hurdles: solvability and the uniqueness of local minima do not follow from monotonicity alone.\n  By establishing the well--posedness of these optimization--based solvers, our framework enables the adaptation of Level Set Methods to high--dimensional settings, unlocking new capabilities in applications such as high--dimensional segmentation and interface tracking. Finally, we observe that these arguments extend almost directly to degenerate elliptic or parabolic PDEs on graphs equipped with monotone graph Laplacians."}
{"id": "2601.21753", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21753", "abs": "https://arxiv.org/abs/2601.21753", "authors": ["Italo Napolitano", "Mario di Bernardo"], "title": "Optimal Transport for Time-Varying Multi-Agent Coverage Control", "comment": "Keywords: Optimal Transport; Multi-Agent Systems; Coverage Control; Wasserstein Distance; Time-Varying Density; Autonomous Systems; Distributed Control", "summary": "Coverage control algorithms have traditionally focused on static target densities, where agents are deployed to optimally cover a fixed spatial distribution. However, many applications involve time-varying densities, including environmental monitoring, surveillance, and adaptive sensor deployment. Although time-varying coverage strategies have been studied within Voronoi-based frameworks, recent works have reformulated static coverage control as a semi-discrete optimal transport problem. Extending this optimal transport perspective to time-varying scenarios has remained an open challenge. This paper presents a rigorous optimal transport formulation for time-varying coverage control, in which agents minimize the instantaneous Wasserstein distance to a continuously evolving target density. The proposed solution relies on a coupled system of differential equations governing agent positions and the dual variables that define Laguerre regions. In one-dimensional domains, the resulting system admits a closed-form analytical solution, offering both computational benefits and theoretical insight into the structure of optimal time-varying coverage. Numerical simulations demonstrate improved tracking performance compared to quasi-static and Voronoi-based methods, validating the proposed framework."}
{"id": "2601.22116", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22116", "abs": "https://arxiv.org/abs/2601.22116", "authors": ["Greg Kreider"], "title": "Interval Spacing", "comment": "19 pages, 5 figures", "summary": "We define interval spacing as the difference in the order statistics of data over a gap of some width. We derive its density, expected value, and variance for uniform, exponential, and logistic variates. We show that interval spacing is equivalent to running a rectangular low-pass filter over the spacing, which simplifies the expressions for the expected values and introduces correlations between overlapping intervals."}
{"id": "2601.20926", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20926", "abs": "https://arxiv.org/abs/2601.20926", "authors": ["Hyunsoo Ha", "David A. Huse", "Rhine Samajdar"], "title": "Quench spectroscopy of amplitude modes in a one-dimensional critical phase", "comment": "7+16 pages, 3+5 figures", "summary": "We investigate the emergence of an amplitude (Higgs-like) mode in the gapless phase of the $(1+1)$D XXZ spin chain. Unlike conventional settings where amplitude modes arise from spontaneous symmetry breaking, here, we identify a symmetry-preserving underdamped excitation on top of a Luttinger-liquid ground state. Using nonequilibrium quench spectroscopy, we demonstrate that this mode manifests as oscillations of U(1)-symmetric observables following a sudden quench. By combining numerical simulations with Bethe-ansatz analyses, we trace its microscopic origin to specific families of string excitations. We further discuss experimental pathways to detect this mode in easy-plane quantum magnets and programmable quantum simulators. Our results showcase the utility of quantum quenches as a powerful tool to probe collective excitations, beyond the scope of linear response."}
{"id": "2601.21487", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.21487", "abs": "https://arxiv.org/abs/2601.21487", "authors": ["Kaiwei Yang", "Lexiao Lai"], "title": "Manifold constrained steepest descent", "comment": "23 pages, 7 figures, and 5 tables", "summary": "Norm-constrained linear minimization oracle (LMO)-based optimizers such as spectral gradient descent and Muon are attractive in large-scale learning, but extending them to manifold-constrained problems is nontrivial and often leads to nested-loop schemes that solve tangent-space subproblems iteratively. We propose \\emph{Manifold Constrained Steepest Descent} (MCSD), a single-loop framework for optimization over manifolds that selects a norm-induced steepest-descent direction via an LMO applied to the Riemannian gradient, and then returns to the manifold via projection. Under standard smoothness assumptions, we establish convergence guarantees for MCSD and a stochastic momentum variant. We further introduce \\emph{SPEL}, the spectral-norm specialization of MCSD on the Stiefel manifold, which admits scalable implementations via fast matrix sign computations. Experiments on PCA, orthogonality-constrained CNNs, and manifold-constrained LLM adapter tuning demonstrate improved stability and competitive performance relative to standard Riemannian baselines and existing manifold-aware LMO methods."}
{"id": "2601.20922", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20922", "abs": "https://arxiv.org/abs/2601.20922", "authors": ["L. L. Sanchez-Soto", "A. B. Klimov", "A. Z. Goldberg", "G. Leuchs"], "title": "The quantum sky of Majorana stars", "comment": "Comments welcome!", "summary": "Majorana stars, the $2S$ spin coherent states that are orthogonal to a spin-$S$ state, offer an elegant method to visualize quantum states. This representation offers deep insights into the structure, symmetries, and entanglement properties of quantum states, bridging abstract algebraic formulations with intuitive geometrical intuition. In this paper, we briefly survey the development and applications of the Majorana constellation, exploring its relevance in modern areas of quantum information."}
{"id": "2601.22096", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22096", "abs": "https://arxiv.org/abs/2601.22096", "authors": ["Qian Zhang", "Feng Zhao", "Tongxin Zheng", "Le Xie"], "title": "Reformulating Energy Storage Capacity Accreditation Problem with Marginal Reliability Impact", "comment": null, "summary": "To enhance the efficiency of capacity markets, many electricity markets in the U.S. are adopting or planning to implement marginal capacity accreditation reforms. This paper provides new insights into energy storage capacity accreditation using Marginal Reliability Impact (MRI). We reformulate the commonly used reliability-based storage dispatch model as an optimization problem, enabling direct calculation of the MRI from the Lagrange multipliers, rather than using brute-force perturbation analysis. The analysis demonstrates that the EUE is a piecewise linear function and the storage MRI retains a non-negative property across various system scenarios. We further explore the influence of qualified capacity (QC), storage dispatch rules, and other key factors on storage accreditation, providing practical insights for system operators. Additionally, comparisons of storage capacity accreditation under different reliability criteria offer valuable guidance for policymakers in setting future standards. Numerical results from a modified California system validate our findings and highlight several important phenomena associated with the MRI-based accreditation scheme."}
{"id": "2601.21799", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.21799", "abs": "https://arxiv.org/abs/2601.21799", "authors": ["Daniel Kressner", "Peter Oehme"], "title": "A novel Krylov subspace method for approximating Fréchet derivatives of large-scale matrix functions", "comment": "15 pages, 13 figures, 2 tables", "summary": "We present a novel Krylov subspace method for approximating $L_f(A, E) \\vc{b}$, the matrix-vector product of the Fréchet derivative $L_f(A, E)$ of a large-scale matrix function $f(A)$ in direction $E$, a task that arises naturally in the sensitivity analysis of quantities involving matrix functions, such as centrality measures for networks. It also arises in the context of gradient-based methods for optimization problems that feature matrix functions, e.g., when fitting an evolution equation to an observed solution trajectory. In principle, the well-known identity \\[\n  f\\left( \\begin{bmatrix}\n  A & E \\\\ 0 & A\n  \\end{bmatrix} \\right) \\begin{bmatrix}\n  0 \\\\ \\vc{b}\n  \\end{bmatrix} = \\begin{bmatrix}\n  L_f(A, E) \\vc{b} \\\\ f(A) \\vc{b}\n  \\end{bmatrix}, \\] allows one to directly apply any standard Krylov subspace method, such as the Arnoldi algorithm, to address this task. However, this comes with the major disadvantage that the involved block triangular matrix has unfavorable spectral properties, which impede the convergence analysis and, to a certain extent, also the observed convergence. To avoid these difficulties, we propose a novel modification of the Arnoldi algorithm that aims at better preserving the block triangular structure. In turn, this allows one to bound the convergence of the modified method by the best polynomial approximation of the derivative $f^\\prime$ on the numerical range of $A$. Several numerical experiments illustrate our findings."}
{"id": "2601.22052", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22052", "abs": "https://arxiv.org/abs/2601.22052", "authors": ["Sten Elling Tingstad Jacobsen", "Attila Lischka", "Balázs Kulcsár", "Anders Lindman"], "title": "Learning to Dial-a-Ride: A Deep Graph Reinforcement Learning Approach to the Electric Dial-a-Ride Problem", "comment": null, "summary": "Urban mobility systems are transitioning toward electric, on-demand services, creating operational challenges for fleet management under energy and service-quality constraints. The Electric Dial-a-Ride Problem (E-DARP) extends the classical dial-a-ride problem by incorporating limited battery capacity and nonlinear charging dynamics, increasing computational complexity and limiting the scalability of exact methods for real-time use. This paper proposes a deep reinforcement learning approach based on a graph neural network encoder and an attention-driven route construction policy. By operating directly on edge attributes such as travel time and energy consumption, the method captures non-Euclidean, asymmetric, and energy-dependent routing costs in real road networks. The learned policy jointly optimizes routing, charging, and service quality without relying on Euclidean assumptions or handcrafted heuristics. The approach is evaluated on two case studies using ride-sharing data from San Francisco. On benchmark instances, the method achieves solutions within 0.4% of best-known results while reducing computation times by orders of magnitude. A second case study considers large-scale instances with up to 250 request pairs, realistic energy models, and nonlinear charging. On these instances, the learned policy outperforms Adaptive Large Neighborhood Search (ALNS) by 9.5% in solution quality while achieving 100% service completion, with sub-second inference times compared to hours for the metaheuristic. Finally, sensitivity analyses quantify the impact of battery capacity, fleet size, ride-sharing capacity, and reward weights, while robustness experiments show that deterministically trained policies generalize effectively under stochastic conditions."}
{"id": "2601.22147", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.22147", "abs": "https://arxiv.org/abs/2601.22147", "authors": ["Melissa Lynne Martin", "Juliette Brook", "Sage Rush", "Theodore D. Satterthwaite", "Ian J. Barnett"], "title": "Variance component score test for multivariate change point detection with applications to mobile health", "comment": "15 pages, 5 figures", "summary": "Multivariate change point detection is the process of identifying distributional shifts in time-ordered data across multiple features. This task is particularly challenging when the number of features is large relative to the number of observations. This problem is often present in mobile health, where behavioral changes in at-risk patients must be detected in real time in order to prompt timely interventions. We propose a variance component score test (VC*) for detecting changes in feature means and/or variances using only pre-change point data to estimate distributional parameters. Through simulation studies, we show that VC* has higher power than existing methods. Moreover, we demonstrate that reducing bias by using only pre-change point days to estimate parameters outweighs the increased estimator variances in most scenarios. Lastly, we apply VC* and competing methods to passively collected smartphone data in adolescents and young adults with affective instability."}
{"id": "2601.20945", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.20945", "abs": "https://arxiv.org/abs/2601.20945", "authors": ["Wenjie Ji", "Ryan A. Lanzetta", "Zheng Zhou", "Chong Wang"], "title": "Self-dual Higgs transitions: Toric code and beyond", "comment": "5+4 pages", "summary": "The toric code, when deformed in a way that preserves the self-duality $\\mathbb{Z}_2$ symmetry exchanging the electric and magnetic excitations, admits a transition to a topologically trivial state that spontaneously breaks the $\\mathbb{Z}_2$ symmetry. Numerically, this transition was found to be continuous, which makes it particularly enigmatic given the longstanding absence of a continuum field-theoretic description. In this work we propose such a continuum field theory for the transition dubbed the $SO(4)_{2,-2}$ Chern-Simons-Higgs (CSH) theory. We show that our field theory provides a natural \"mean-field\" understanding of the phase diagram. Moreover, it can be generalized to an entire series of theories, namely the $SO(4)_{k,-k}$ CSH theories, labeled by an integer $k$. For each $k>2$, the theory describes an analogous transition involving different non-Abelian topological orders, such as the double Fibonacci order ($k=3$) and the $S_3$ quantum double ($k=4$). For $k=1$, we conjecture that the corresponding CSH transition is in fact infrared-dual to the $3d$ Ising transition, in close analogy with the particle-vortex duality of a complex scalar."}
{"id": "2601.21606", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21606", "abs": "https://arxiv.org/abs/2601.21606", "authors": ["Amine Othmane", "Philipp Schmitz", "Karl Worthmann", "Kathrin Flaßkamp"], "title": "A data-based image representation for continuous-time LTI systems", "comment": null, "summary": "We derive a numerically stable method to obtain an image representation of an unknown linear system only from data, leveraging a continuous-time version of Willems et al.'s fundamental lemma. We propose a data-based representation that, unlike previous approaches, avoids solving differential-algebraic equations and uses derivatives approximated by algebraic differentiators. Our image-based formulation significantly reduces the complexity of the data-driven representation by eliminating redundant degrees of freedom and thus reducing the number of unknown quantities to be identified. Simulation results confirm the effectiveness of the proposed approach, even in the presence of severe measurement disturbances."}
{"id": "2601.20925", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.20925", "abs": "https://arxiv.org/abs/2601.20925", "authors": ["Ankit W. Shrestha", "Budhaditya Bhattacharjee", "Adolfo del Campo"], "title": "Double-Bracket Master Equations: Phase-Space Representation and Classical Limit", "comment": "18 pages, 7 figures", "summary": "We investigate the classical limit of quantum master equations featuring double-bracket dissipators. Specifically, we consider dissipators defined by double commutators, which describe dephasing dynamics, as well as dissipators involving double anticommutators, associated with fluctuating anti-Hermitian Hamiltonians. The classical limit is obtained by formulating the open quantum dynamics in phase space using the Wigner function and Moyal products, followed by a systematic $\\hbar$-expansion. We begin with the well-known model of energy dephasing, associated with energy diffusion. We then turn to master equations containing a double anticommutator with the system Hamiltonian, recently derived in the context of noisy non-Hermitian systems. For both classes of double-bracket equations, we provide a gradient-flow representation of the dynamics. We analyze the classical limit of the resulting evolutions for harmonic and driven anharmonic quantum oscillators, considering both classical and nonclassical initial states. The dynamics is characterized through the evolution of several observables as well as the Wigner logarithmic negativity. We conclude by extending our analysis to generalized master equations involving higher-order nested brackets, which provide a time-continuous description of spectral filtering techniques commonly used in the numerical analysis of quantum systems."}
{"id": "2601.22120", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22120", "abs": "https://arxiv.org/abs/2601.22120", "authors": ["Qian Zhang", "Le Xie", "Long Zhao", "Congcong Wang"], "title": "Comparative Assessment of Look-Ahead Economic Dispatch and Ramp Products for Grid Flexibility", "comment": null, "summary": "High renewable penetration increases the frequency and magnitude of net-load ramps, stressing real-time flexibility. Two commonly deployed remedies are look-ahead economic dispatch (LAED) and ramp products (RPs), yet their operational equivalence under the industry-standard rolling-window dispatch implementation is not well understood. This paper develops linear optimization models for multi-interval LAED and RP-based co-optimization, and proves that an enhanced RP formulation can match LAED's dispatch feasible region at a single time step when additional intertemporal deliverability constraints are enforced. We then show that this equivalence does not generally persist under rolling-window operation because LAED and RP formulations optimize different intertemporal objectives, leading to divergent end-of-window states. Using different test systems under stressed ramping conditions and multiple load levels, we show LAED achieves similar or lower load shedding than RP implementations with the same look-ahead horizon, with the most pronounced differences under high-load, ramp-limited conditions. The study highlights the limitations of current ramp product implementations and suggests enhancements, such as introducing more mid-duration RPs."}
{"id": "2601.21874", "categories": ["math.NA", "math.OC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21874", "abs": "https://arxiv.org/abs/2601.21874", "authors": ["Bin Gao", "Renfeng Peng", "Ya-xiang Yuan"], "title": "Quotient geometry of tensor ring decomposition", "comment": "22 pages, 8 figures, 1 table", "summary": "Differential geometries derived from tensor decompositions have been extensively studied and provided the foundations for a variety of efficient numerical methods. Despite the practical success of the tensor ring (TR) decomposition, its intrinsic geometry remains less understood, primarily due to the underlying ring structure and the resulting nontrivial gauge invariance. We establish the quotient geometry of TR decomposition by imposing full-rank conditions on all unfolding matrices of the core tensors and capturing the gauge invariance. Additionally, the results can be extended to the uniform TR decomposition, where all core tensors are identical. Numerical experiments validate the developed geometries via tensor ring completion tasks."}
{"id": "2601.22087", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22087", "abs": "https://arxiv.org/abs/2601.22087", "authors": ["Qian Zhang", "Feng Zhao", "Gord Stephen", "Chanan Singh", "Le Xie"], "title": "A Gradient-Based Capacity Accreditation Framework in Resource Adequacy: Formulation, Computation, and Practical Implications", "comment": null, "summary": "Probabilistic resource adequacy assessment is a cornerstone of modern capacity accreditation. This paper develops a gradient-based framework, in which capacity accreditation is interpreted as the directional derivative of a probabilistic resource adequacy metric with respect to resource capacity, that unifies two widely used accreditation approaches: Effective Load Carrying Capability (ELCC) and Marginal Reliability Impact (MRI). Under mild regularity conditions, we show that marginal ELCC and MRI yield equivalent accreditation factors, while their numerical implementations exhibit markedly different computational characteristics. Building on this framework, we demonstrate how infinitesimal perturbation analysis enables up to a $1000\\times$ speedup in gradient estimation for capacity accreditation, and we implement gradient-informed search algorithms that significantly accelerate ELCC computations relative to standard bisection methods. Large-scale Monte Carlo experiments show that MRI achieves substantial runtime reductions compared to ELCC and exhibits greater robustness to perturbation step-size selection. These results provide practical guidance for implementing efficient and scalable capacity accreditation in large-scale power systems."}
{"id": "2601.21890", "categories": ["physics.ao-ph", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.21890", "abs": "https://arxiv.org/abs/2601.21890", "authors": ["Laura Mack", "Norbert Pirk"], "title": "Reddy: An open-source toolbox for analyzing eddy-covariance measurements in heterogeneous environments", "comment": null, "summary": "Land-atmosphere exchange processes are determined by turbulent fluxes, which can be derived from eddy-covariance measurements. This method was established to quantify ecosystem-scale vertical atmosphere-vegetation exchange processes, but is also used to validate atmospheric turbulence theories with the ultimate aim to improve the representation of turbulence in numerical models. While the focus has long been on turbulence over idealized, homogeneous and flat surfaces, recent scientific developments are shifting towards investigating turbulent exchange processes in complex heterogeneous environments under non-idealized conditions, which pose particular challenges, e.g. advective fluxes between different surface types or non-stationarity of nighttime turbulence. This requires to rethink standard post-processing routines for determining turbulent fluxes from the high-frequency sonic and gas analyzer measurements. Here, we introduce the open-source R-package 'Reddy', which provides modular-built functions for post-processing, analysis and visualization of eddy-covariance measurements, including investigating spectra, coherent structures, anisotropy, flux footprints and surface energy balance closure. The 'Reddy' package is accompanied by a detailed documentation and a set of jupyter notebooks introducing new users hands-on to eddy-covariance data analysis. We showcase 'Reddy' based on measurements from three different sites in Norway: A case study during strong stratification over alpine tundra, for determining suitable averaging times during ice-cover transition at a boreal lake, and for fitting flux-variance relations for a permafrost peatland. 'Reddy' serves as extension of previously developed software packages, paving the way towards holistic turbulence data analysis in heterogeneous real-world environments."}
{"id": "2601.21065", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.21065", "abs": "https://arxiv.org/abs/2601.21065", "authors": ["Jonathan Jeffrey", "Lucien Gandarias", "Monika Schleier-Smith", "Brian Swingle"], "title": "Building Holographic Entanglement by Measurement", "comment": "5 pages + references + supplement, 4 figures in main text", "summary": "We propose a framework for preparing quantum states with a holographic entanglement structure, in the sense that the entanglement entropies are governed by minimal surfaces in a chosen bulk geometry. We refer to such entropies as holographic because they obey a relation between entropies and bulk minimal surfaces, known as the Ryu-Takayanagi formula, that is a key feature of holographic models of quantum gravity. Typically in such models, the bulk geometry is determined by solving Einstein's equations. Here, we simply choose a bulk geometry, then discretize the geometry into a coupling graph comprising bulk and boundary nodes. Evolving under this graph of interactions and measuring the bulk nodes leaves behind the desired pure state on the boundary. We numerically demonstrate that the resulting entanglement properties approximately reproduce the predictions of the Ryu-Takayanagi formula in the chosen bulk geometry. We consider graphs associated with hyperbolic disk and wormhole geometries, but the approach is general. The minimal ingredients in our proposal involve only Gaussian operations and measurements and are readily implementable in photonic and cold-atom platforms."}
{"id": "2601.21705", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21705", "abs": "https://arxiv.org/abs/2601.21705", "authors": ["Andi Bodnariu", "Nils Engler", "Neofytos Rodosthenous"], "title": "Outrunning the Omega Clock: A Singular Control Problem for Dividend Optimisation with Ruin and Time-in-Distress Default", "comment": null, "summary": "This paper extends the classical dividend problem by incorporating a novel, path-dependent mechanism of firm default. In the traditional framework, ruin occurs when the surplus process first reaches zero. In contrast, default in our model may also arise when the surplus spends an excessive amount of time below a distress threshold, even without ever hitting zero. This occupation-time-based default criterion captures financial distress more realistically, as prolonged periods of low liquidity or capitalisation may trigger regulatory intervention or operational failure. The resulting optimisation problem is formulated as a new singular stochastic control problem with discontinuous state-dependent discounting and killing. We provide a complete analytical solution via a bespoke sequential guess-and-verify method and identify three distinct classes of optimal dividend strategies corresponding to different parameter regimes of the dual-ruin structure. Notably, for certain distress thresholds, the optimal policy features disconnected action and inaction regions. We further show that, unlike in the classical dividend problem, higher effective discounting induced by occupation time below a distress level can lead to delayed, rather than earlier, dividend payments."}
{"id": "2601.20927", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20927", "abs": "https://arxiv.org/abs/2601.20927", "authors": ["Jin Ming Koh", "Anqi Gong", "Andrei C. Diaconu", "Daniel Bochen Tan", "Alexandra A. Geim", "Michael J. Gullans", "Norman Y. Yao", "Mikhail D. Lukin", "Shayan Majidy"], "title": "Entangling logical qubits without physical operations", "comment": "12 pages in the main text (6 figures, 2 tables); 69 pages total (18 figures, 8 tables)", "summary": "Fault-tolerant logical entangling gates are essential for scalable quantum computing, but are limited by the error rates and overheads of physical two-qubit gates and measurements. To address this limitation, we introduce phantom codes-quantum error-correcting codes that realize entangling gates between all logical qubits in a code block purely through relabelling of physical qubits during compilation, yielding perfect fidelity with no spatial or temporal overhead. We present a systematic study of such codes. First, we identify phantom codes using complementary numerical and analytical approaches. We exhaustively enumerate all $2.71 \\times 10^{10}$ inequivalent CSS codes up to $n=14$ and identify additional instances up to $n=21$ via SAT-based methods. We then construct higher-distance phantom-code families using quantum Reed-Muller codes and the binarization of qudit codes. Across all identified codes, we characterize other supported fault-tolerant logical Clifford and non-Clifford operations. Second, through end-to-end noisy simulations with state preparation, full QEC cycles, and realistic physical error rates, we demonstrate scalable advantages of phantom codes over the surface code across multiple tasks. We observe a one-to-two order-of-magnitude reduction in logical infidelity at comparable qubit overhead for GHZ-state preparation and Trotterized many-body simulation tasks, given a modest preselection acceptance rate. Our work establishes phantom codes as a viable architectural route to fault-tolerant quantum computation with scalable benefits for workloads with dense local entangling structure, and introduces general tools for systematically exploring the broader landscape of quantum error-correcting codes."}
{"id": "2601.21036", "categories": ["stat.ME", "econ.EM", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21036", "abs": "https://arxiv.org/abs/2601.21036", "authors": ["Chonghuan Wang"], "title": "Experimental Design for Matching", "comment": null, "summary": "Matching mechanisms play a central role in operations management across diverse fields including education, healthcare, and online platforms. However, experimentally comparing a new matching algorithm against a status quo presents some fundamental challenges due to matching interference, where assigning a unit in one matching may preclude its assignment in the other. In this work, we take a design-based perspective to study the design of randomized experiments to compare two predetermined matching plans on a finite population, without imposing outcome or behavioral models. We introduce the notation of a disagreement set, which captures the difference between the two matching plans, and show that it admits a unique decomposition into disjoint alternating paths and cycles with useful structural properties. Based on these properties, we propose the Alternating Path Randomized Design, which sequentially randomizes along these paths and cycles to effectively manage interference. Within a minimax framework, we optimize the conditional randomization probability and show that, for long paths, the optimal choice converges to $\\sqrt{2}-1$, minimizing worst-case variance. We establish the unbiasedness of the Horvitz-Thompson estimator and derive a finite-population Central Limit Theorem that accommodates complex and unstable path and cycle structures as the population grows. Furthermore, we extend the design to many-to-one matchings, where capacity constraints fundamentally alter the structure of the disagreement set. Using graph-theoretic tools, including finding augmenting paths and Euler-tour decomposition on an auxiliary unbalanced directed graph, we construct feasible alternating path and cycle decompositions that allow the design and inference results to carry over."}
{"id": "2601.21019", "categories": ["math.ST", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21019", "abs": "https://arxiv.org/abs/2601.21019", "authors": ["Markus Holzleitner", "Sergiy Pereverzyev", "Sergei V. Pereverzyev", "Vaibhav Silmana", "S. Sivananthan"], "title": "Towards regularized learning from functional data with covariate shift", "comment": "38 pages", "summary": "This paper investigates a general regularization framework for unsupervised domain adaptation in vector-valued regression under the covariate shift assumption, utilizing vector-valued reproducing kernel Hilbert spaces (vRKHS). Covariate shift occurs when the input distributions of the training and test data differ, introducing significant challenges for reliable learning. By restricting the hypothesis space, we develop a practical operator learning algorithm capable of handling functional outputs. We establish optimal convergence rates for the proposed framework under a general source condition, providing a theoretical foundation for regularized learning in this setting. We also propose an aggregation-based approach that forms a linear combination of estimators corresponding to different regularization parameters and different kernels. The proposed approach addresses the challenge of selecting appropriate tuning parameters, which is crucial for constructing a good estimator, and we provide a theoretical justification for its effectiveness. Furthermore, we illustrate the proposed method on a real-world face image dataset, demonstrating robustness and effectiveness in mitigating distributional discrepancies under covariate shift."}
{"id": "2601.22096", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22096", "abs": "https://arxiv.org/abs/2601.22096", "authors": ["Qian Zhang", "Feng Zhao", "Tongxin Zheng", "Le Xie"], "title": "Reformulating Energy Storage Capacity Accreditation Problem with Marginal Reliability Impact", "comment": null, "summary": "To enhance the efficiency of capacity markets, many electricity markets in the U.S. are adopting or planning to implement marginal capacity accreditation reforms. This paper provides new insights into energy storage capacity accreditation using Marginal Reliability Impact (MRI). We reformulate the commonly used reliability-based storage dispatch model as an optimization problem, enabling direct calculation of the MRI from the Lagrange multipliers, rather than using brute-force perturbation analysis. The analysis demonstrates that the EUE is a piecewise linear function and the storage MRI retains a non-negative property across various system scenarios. We further explore the influence of qualified capacity (QC), storage dispatch rules, and other key factors on storage accreditation, providing practical insights for system operators. Additionally, comparisons of storage capacity accreditation under different reliability criteria offer valuable guidance for policymakers in setting future standards. Numerical results from a modified California system validate our findings and highlight several important phenomena associated with the MRI-based accreditation scheme."}
{"id": "2601.21710", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21710", "abs": "https://arxiv.org/abs/2601.21710", "authors": ["Yuan Zhang", "Yutong Han", "Yuanqing Xia", "Aming Li"], "title": "On Diagonalizable Systems with Random Structure", "comment": null, "summary": "Diagonalizability plays an important role in the analysis and design of multivariable systems. A structured matrix is called structurally diagonalizable if almost all of its numerical realizations, obtained by assigning real values to its free entries, are diagonalizable. Structural diagonalizability is useful for the verification and optimization of various structural system properties. In this paper, we study the asymptotic probability distribution of structural diagonalizability for structured systems whose system matrices are represented by directed Erdős-Rényi random graphs. Leveraging a recently established graph-theoretic characterization of structural diagonalizability, we analyze the distribution of structurally diagonalizable graphs under different edge-density regimes. For dense graphs, we prove that the system is almost always structurally diagonalizable. For graphs of medium density, we derive tight upper and lower bounds on the asymptotic probability of structural diagonalizability. For extremely sparse graphs, we show that this probability approaches 0. The theoretical results are validated through extensive numerical simulations with varying numbers of vertices and connection probabilities."}
{"id": "2601.20938", "categories": ["quant-ph", "cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2601.20938", "abs": "https://arxiv.org/abs/2601.20938", "authors": ["Hao Chen", "Wucheng Zhang", "Manas Kulkarni", "Abhinav Prem"], "title": "Non-Equilibrium Phase Transition in a Boundary-Driven Dissipative Fermionic Chain", "comment": "7+5 pages, 5+3 figures", "summary": "We demonstrate that a boundary-localized periodic (Floquet) drive can induce nontrivial long-range correlations in a non-interacting fermionic chain which is additionally subject to boundary dissipation. Surprisingly, we find that this phenomenon occurs even when the corresponding isolated bulk is in a trivial gapped phase with exponentially decaying correlations. We argue that this boundary-drive induced non-equilibrium transition (as witnessed through the correlation matrix) is driven by a resonance mechanism whereby the drive frequency bridges bulk energy gaps, allowing boundary-injected particles and holes to propagate and mediate long-range correlations into the bulk. We also numerically establish that when the drive bridges a particle-hole gap, the induced long-range order scales as a power law with the bulk pairing potential ($χ\\sim γ^2$). Our results highlight the potential of localized coherent driving for generating macroscopic order in open quantum systems."}
{"id": "2601.22080", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22080", "abs": "https://arxiv.org/abs/2601.22080", "authors": ["Shuaicheng Tong", "Michael A. Boateng", "Mathieu Tanneau", "Pascal Van Hentenryck"], "title": "Volt/VAR Optimization in Transmission Networks with Discrete-Control Devices", "comment": null, "summary": "Voltage (Volt) and reactive-power (VAR) control in transmission networks is critical for reliability and increasingly needs fast, implementable decisions. This paper presents a transmission Volt/VAR Optimization (VVO) framework that co-optimizes discrete control of on-load tap-changing transformers (OLTCs) and capacitor banks (CBs) with AC power flow (ACPF) physics to improve voltage stability and minimize VAR generation. The framework follows a relax-round-resolve pipeline: a continuous relaxation proposes targets, a rounding step selects feasible discrete settings, and a final solve enforces AC power flow physics. Extensive experiments on IEEE, PEGASE, and RTE systems show consistent improvements in voltage and VAR quality metrics with modest generator redispatch while preserving economic operation and achieving compatible runtimes with real-time transmission operations."}
{"id": "2601.21243", "categories": ["math.OC", "cs.LG", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21243", "abs": "https://arxiv.org/abs/2601.21243", "authors": ["Amir Ali Farzin", "Yuen-Man Pun", "Philipp Braun", "Tyler Summers", "Iman Shames"], "title": "Solving the Offline and Online Min-Max Problem of Non-smooth Submodular-Concave Functions: A Zeroth-Order Approach", "comment": null, "summary": "We consider max-min and min-max problems with objective functions that are possibly non-smooth, submodular with respect to the minimiser and concave with respect to the maximiser. We investigate the performance of a zeroth-order method applied to this problem. The method is based on the subgradient of the Lovász extension of the objective function with respect to the minimiser and based on Gaussian smoothing to estimate the smoothed function gradient with respect to the maximiser. In expectation sense, we prove the convergence of the algorithm to an $ε$-saddle point in the offline case. Moreover, we show that, in the expectation sense, in the online setting, the algorithm achieves $O(\\sqrt{N\\bar{P}_N})$ online duality gap, where $N$ is the number of iterations and $\\bar{P}_N$ is the path length of the sequence of optimal decisions. The complexity analysis and hyperparameter selection are presented for all the cases. The theoretical results are illustrated via numerical examples."}
{"id": "2601.22120", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22120", "abs": "https://arxiv.org/abs/2601.22120", "authors": ["Qian Zhang", "Le Xie", "Long Zhao", "Congcong Wang"], "title": "Comparative Assessment of Look-Ahead Economic Dispatch and Ramp Products for Grid Flexibility", "comment": null, "summary": "High renewable penetration increases the frequency and magnitude of net-load ramps, stressing real-time flexibility. Two commonly deployed remedies are look-ahead economic dispatch (LAED) and ramp products (RPs), yet their operational equivalence under the industry-standard rolling-window dispatch implementation is not well understood. This paper develops linear optimization models for multi-interval LAED and RP-based co-optimization, and proves that an enhanced RP formulation can match LAED's dispatch feasible region at a single time step when additional intertemporal deliverability constraints are enforced. We then show that this equivalence does not generally persist under rolling-window operation because LAED and RP formulations optimize different intertemporal objectives, leading to divergent end-of-window states. Using different test systems under stressed ramping conditions and multiple load levels, we show LAED achieves similar or lower load shedding than RP implementations with the same look-ahead horizon, with the most pronounced differences under high-load, ramp-limited conditions. The study highlights the limitations of current ramp product implementations and suggests enhancements, such as introducing more mid-duration RPs."}
{"id": "2601.21748", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21748", "abs": "https://arxiv.org/abs/2601.21748", "authors": ["Lin Li", "Jiongmin Yong"], "title": "Stochastic Optimal Linear Quadratic Controls with A Recursive Cost Functional", "comment": "27 pages", "summary": "This paper is concerned with a stochastic linear quadratic (LQ, for short) control problem with a recursive cost functional. It involves BSDEs in $L^1$ whose well-posedness is a subtle issue. A suitable framework has been adopted so that the corresponding LQ problem is correctly formulated. Open-loop and closed-loop solvability of such an LQ problem have been investigated and characterized by the solvability of an FBSDE and that of Riccati differential equation."}
{"id": "2601.20949", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20949", "abs": "https://arxiv.org/abs/2601.20949", "authors": ["Ryan Rizaldy", "Tian Zhou", "Run Zhou", "Anupam Mazumdar"], "title": "Spatial superposition for a two-dimensional matter-wave interferometer in an inverted harmonic potential with gyroscopic rotational stability", "comment": "27 pages, 8 figures", "summary": "This study presents a mathematical model of the spatial and rotational motion of a nanodiamond in an inverted harmonic potential to create a macroscopic quantum spatial superposition. The model is based on the Stern-Gerlach Interferometer (SGI) scheme, which utilises linear and quadratic magnetic fields to generate a harmonic potential (linear magnetic field) and a non-linear potential (non-linear/quadratic magnetic field). By incorporating two-dimensional dynamics into the model, we provide a more realistic and accurate depiction of nanoparticle dynamics in linear and inverted harmonic potentials and explore the interaction between motion in a two-dimensional plane. Importantly, we derive the equations of motion for the rotational degrees of freedom, i.e. libration, precession, and rotation. The results show that adding a magnetic-field bias term to the magnetic-field profile in the linear stage affects the classical equations of motion but does not affect the width of the wave packet. Moreover, the libration mode always forms a harmonic potential at each stage because the applied initial angular velocity is dominated by the nanoparticle's defect axis, making it more stable in the presence of the trap frequency in the orthogonal direction along the axis that enables the creation of a macroscopic quantum superposition."}
{"id": "2601.21913", "categories": ["physics.ao-ph", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.21913", "abs": "https://arxiv.org/abs/2601.21913", "authors": ["Cassidy All", "Kevin Ho", "Maya Magnuski", "Christopher Nicolaides", "Louisa B. Ebby", "Mohammad Farazmand"], "title": "Rapid estimation of global sea surface temperatures from sparse streaming in situ observations", "comment": null, "summary": "Reconstructing high-resolution sea surface temperatures (SST) from staggered SST measurements is essential for weather forecasting and climate projections. However, when SST measurements are sparse, the resulting inferred SST fields are rather inaccurate. Here, we demonstrate the ability of Sparse Discrete Empirical Interpolation Method (S-DEIM) to reconstruct the high-resolution SST field from sparse in situ observations, without using a model. The S-DEIM estimate consists of two terms, one computed from instantaneous in situ observations using empirical interpolation, and the other learned from the historical time series of observations using recurrent neural networks (RNNs). We train the RNNs using the National Oceanic and Atmospheric Administration's weekly high-resolution SST dataset spanning the years 1989-2021 which constitutes the training data. Subsequently, we examine the performance of S-DEIM on the test data, comprising January 2022 to January 2023. For this test data, S-DEIM infers the high-resolution SST from 100 in situ observations, constituting only 0.2% of the high-resolution spatial grid. We show that the resulting S-DEIM reconstructions are about 40% more accurate than earlier empirical interpolation methods, such as DEIM and Q-DEIM. Furthermore, 91% of S-DEIM estimates fall within $\\pm 1^\\circ$C of the true SST. We also demonstrate that S-DEIM is robust with respect to sensor placement: even when the sensors are distributed randomly, S-DEIM reconstruction error deteriorates only by 1-2%. S-DEIM is also computationally efficient. Training the RNN, which is performed only once offline, takes approximately one minute. Once trained, the S-DEIM reconstructions are computed in less than a second. As such, S-DEIM can be used for rapid SST reconstruction from sparse streaming observational data in real time."}
{"id": "2601.21036", "categories": ["stat.ME", "econ.EM", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.21036", "abs": "https://arxiv.org/abs/2601.21036", "authors": ["Chonghuan Wang"], "title": "Experimental Design for Matching", "comment": null, "summary": "Matching mechanisms play a central role in operations management across diverse fields including education, healthcare, and online platforms. However, experimentally comparing a new matching algorithm against a status quo presents some fundamental challenges due to matching interference, where assigning a unit in one matching may preclude its assignment in the other. In this work, we take a design-based perspective to study the design of randomized experiments to compare two predetermined matching plans on a finite population, without imposing outcome or behavioral models. We introduce the notation of a disagreement set, which captures the difference between the two matching plans, and show that it admits a unique decomposition into disjoint alternating paths and cycles with useful structural properties. Based on these properties, we propose the Alternating Path Randomized Design, which sequentially randomizes along these paths and cycles to effectively manage interference. Within a minimax framework, we optimize the conditional randomization probability and show that, for long paths, the optimal choice converges to $\\sqrt{2}-1$, minimizing worst-case variance. We establish the unbiasedness of the Horvitz-Thompson estimator and derive a finite-population Central Limit Theorem that accommodates complex and unstable path and cycle structures as the population grows. Furthermore, we extend the design to many-to-one matchings, where capacity constraints fundamentally alter the structure of the disagreement set. Using graph-theoretic tools, including finding augmenting paths and Euler-tour decomposition on an auxiliary unbalanced directed graph, we construct feasible alternating path and cycle decompositions that allow the design and inference results to carry over."}
{"id": "2601.21836", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21836", "abs": "https://arxiv.org/abs/2601.21836", "authors": ["Marco Rando", "Samuel Vaiter"], "title": "ZOBA: An Efficient Single-loop Zeroth-order Bilevel Optimization Algorithm", "comment": "79 pages, 5 figures, 5 tables", "summary": "Bilevel optimization problems consist of minimizing a value function whose evaluation depends on the solution of an inner optimization problem. These problems are typically tackled using first-order methods that require computing the gradient of the value function ({\\it the hypergradient}). In several practical settings, however, first-order information is unavailable ({\\it zeroth-order setting}), rendering these methods inapplicable. Finite-difference methods provide an alternative by approximating hypergradients using function evaluations along a set of directions. Nevertheless, such surrogates are notoriously expensive, and existing finite-difference bilevel methods rely on two-loop algorithms that are poorly parallelizable. In this work, we propose ZOBA, the first finite-difference single-loop algorithm for bilevel optimization. Our method leverages finite-difference hypergradient approximations based on delayed information to eliminate the need for nested loops. We analyze the proposed algorithm and establish convergence rates in the non-convex setting, achieving a complexity of $\\mathcal{O}(p(d + p)^2\\varepsilon^{-2})$, where $p$ and $d$ denote the dimension of inner and outer spaces respectively, which is better than prior approaches based on Hessian approximation. We further introduce and analyze HF-ZOBA, a Hessian-free variant that yields additional complexity improvements. Finally, we corroborate our findings with numerical experiments on synthetic functions and a real-world black-box task in adversarial machine learning. Our results show that our methods achieve accuracy comparable to state-of-the-art techniques while requiring less computation time."}
{"id": "2601.20950", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.20950", "abs": "https://arxiv.org/abs/2601.20950", "authors": ["Simon Tonner", "Viet T. Tran", "Richard Kueng"], "title": "Parametric Quantum State Tomography with HyperRBMs", "comment": null, "summary": "Quantum state tomography (QST) is essential for validating quantum devices but suffers from exponential scaling in system size. Neural-network quantum states, such as Restricted Boltzmann Machines (RBMs), can efficiently parameterize individual many-body quantum states and have been successfully used for QST. However, existing approaches are point-wise and require retraining at every parameter value in a phase diagram. We introduce a parametric QST framework based on a hypernetwork that conditions an RBM on Hamiltonian control parameters, enabling a single model to represent an entire family of quantum ground states. Applied to the transverse-field Ising model, our HyperRBM achieves high-fidelity reconstructions from local Pauli measurements on 1D and 2D lattices across both phases and through the critical region. Crucially, the model accurately reproduces the fidelity susceptibility and identifies the quantum phase transition without prior knowledge of the critical point. These results demonstrate that hypernetwork-modulated neural quantum states provide an efficient and scalable route to tomographic reconstruction across full phase diagrams."}
{"id": "2601.21917", "categories": ["math.OC", "cs.CC", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21917", "abs": "https://arxiv.org/abs/2601.21917", "authors": ["Amir Ali Ahmadi", "Georgina Hall"], "title": "On Approximate Computation of Critical Points", "comment": null, "summary": "We show that computing even very coarse approximations of critical points is intractable for simple classes of nonconvex functions. More concretely, we prove that if there exists a polynomial-time algorithm that takes as input a polynomial in $n$ variables of constant degree (as low as three) and outputs a point whose gradient has Euclidean norm at most $2^n$ whenever the polynomial has a critical point, then P=NP. The algorithm is permitted to return an arbitrary point when no critical point exists. We also prove hardness results for approximate computation of critical points under additional structural assumptions, including settings in which existence and uniqueness of a critical point are guaranteed, the function is lower bounded, and approximation is measured in terms of distance to a critical point. Overall, our results stand in contrast to the commonly-held belief that, in nonconvex optimization, approximate computation of critical points is a tractable task."}
{"id": "2601.22080", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22080", "abs": "https://arxiv.org/abs/2601.22080", "authors": ["Shuaicheng Tong", "Michael A. Boateng", "Mathieu Tanneau", "Pascal Van Hentenryck"], "title": "Volt/VAR Optimization in Transmission Networks with Discrete-Control Devices", "comment": null, "summary": "Voltage (Volt) and reactive-power (VAR) control in transmission networks is critical for reliability and increasingly needs fast, implementable decisions. This paper presents a transmission Volt/VAR Optimization (VVO) framework that co-optimizes discrete control of on-load tap-changing transformers (OLTCs) and capacitor banks (CBs) with AC power flow (ACPF) physics to improve voltage stability and minimize VAR generation. The framework follows a relax-round-resolve pipeline: a continuous relaxation proposes targets, a rounding step selects feasible discrete settings, and a final solve enforces AC power flow physics. Extensive experiments on IEEE, PEGASE, and RTE systems show consistent improvements in voltage and VAR quality metrics with modest generator redispatch while preserving economic operation and achieving compatible runtimes with real-time transmission operations."}
{"id": "2601.21858", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.21858", "abs": "https://arxiv.org/abs/2601.21858", "authors": ["Jie Liu", "Hailun Zhang", "Jiheng Zhang"], "title": "When to Match: A Cost-Balancing Principle for Dynamic Markets", "comment": null, "summary": "Matching platforms, from ridesharing to food delivery to competitive gaming, face a fundamental operational dilemma: match agents immediately to minimize waiting costs, or delay to exploit the efficiency gains of thicker markets. Yet computing optimal policies is generally intractable, sophisticated algorithms often rely on restrictive distributional assumptions, and common heuristics lack worst-case performance guarantees. We formulate a versatile framework for multi-sided matching with general state-dependent cost structures and non-stationary arrival dynamics. Central to our approach is a cost-balancing principle: match when accumulated waiting cost reaches a calibrated proportion of instantaneous matching cost. This equilibrium condition emerges from fluid-limit analysis and motivates a simple, adaptive Cost-Balancing (CB) algorithm requiring no distributional assumptions. We prove that CB achieves a competitive ratio of $(1+\\sqrtΓ)$ under adversarial arrivals, where $Γ$ quantifies economies of scale, guaranteeing cost within a constant factor of the offline optimum. In contrast, standard greedy and threshold policies can incur unbounded costs in adversarial scenarios. We further establish a universal lower bound of $(\\sqrt{5}+1)/2$ (the golden ratio), quantifying the fundamental price of uncertainty in online matching. Experiments on game matchmaking and real-world food delivery data demonstrate practical effectiveness, with CB consistently outperforming industry-standard heuristics."}
{"id": "2601.20952", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20952", "abs": "https://arxiv.org/abs/2601.20952", "authors": ["Yu-Xin Wang", "Flavio Salvati", "David R. M. Arvidsson Shukur", "William F. Braasch", "Kater Murch", "Nicole Yunger Halpern"], "title": "Quantum metrology enhanced by effective time reversal", "comment": "11 pages, including 1 table and 4 figures", "summary": "Quantum metrology involves the application of quantum resources to enhance measurements. Several communities have developed quantum-metrology strategies that leverage effective time reversals. These strategies, we posit, form four classes. First, echo metrology begins with a preparatory unitary and ends with that unitary's time-reverse. The protocol amplifies the visibility of a small parameter to be sensed. Similarly, weak-value amplification enhances a weak coupling's detectability. The technique exhibits counterintuitive properties captured by a retrocausal model. Using the third strategy, one simulates closed timelike curves, worldlines that loop back on themselves in time. The fourth strategy involves indefinite causal order, which characterises channels applied in a superposition of orderings. We review these four strategies, which we unify under the heading of time-reverse metrology. We also outline opportunities for this toolkit in quantum metrology; quantum information science; quantum foundations; atomic, molecular, and optical physics; and solid-state physics."}
{"id": "2601.21860", "categories": ["math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21860", "abs": "https://arxiv.org/abs/2601.21860", "authors": ["Nicole Tianjiao Yang"], "title": "Pathwise Learning of Stochastic Dynamical Systems with Partial Observations", "comment": null, "summary": "The reconstruction and inference of stochastic dynamical systems from data is a fundamental task in inverse problems and statistical learning. While surrogate modeling advances computational methods to approximate these dynamics, standard approaches typically require high-fidelity training data. In many practical settings, the data are indirectly observed through noisy and nonlinear measurement. The challenge lies not only in approximating the coefficients of the SDEs, but in simultaneously inferring the posterior updates given the observations. In this work, we present a neural path estimation approach to solve stochastic dynamical systems based on variational inference. We first derive a stochastic control problem that solve filtering posterior path measure corresponding to a pathwise Zakai equation. We then construct a generative model that maps the prior path measure to posterior measure through the controlled diffusion and the associated Randon-Nykodym derivative. Through an amortization of sample paths of the observation process, the control is learned by an embedding of the noisy observation paths. Thus, we learn the unknown prior SDE and the control can recover the conditional path measure given the observation sample paths and we learn an associated SDE which induces the same path measure. In the end, we perform experiments on nonlinear dynamical systems, demonstrating the model's ability to learn multimodal, chaotic, or high dimensional systems."}
{"id": "2601.20956", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.20956", "abs": "https://arxiv.org/abs/2601.20956", "authors": ["Chiu Fan Bowen Lo", "Anasuya Lyons", "Dan Gresh", "Michael Mills", "Peter E. Siegfried", "Maxwell D. Urmey", "Nathanan Tantivasadakarn", "Henrik Dreyer", "Ashvin Vishwanath", "Ruben Verresen", "Mohsin Iqbal"], "title": "Universal Topological Gates from Braiding and Fusing Anyons on Quantum Hardware", "comment": "main text: 7+ε pages and 7 figures; total: 50 pages and 25 figures", "summary": "Topological quantum computation encodes quantum information in the internal fusion space of non-Abelian anyonic quasiparticles, whose braiding implements logical gates. This goes beyond Abelian topological order (TO) such as the toric code, as its anyons lack internal structure. However, the simplest non-Abelian generalizations of the toric code do not support universality via braiding alone. Here we demonstrate that such minimally non-Abelian TOs can be made universal by treating anyon fusion as a computational primitive. We prepare a 54-qubit TO wavefunction associated with the smallest non-Abelian group, $S_3$, on Quantinuum's H2 quantum processor. This phase of matter exhibits cyclic anyon fusion rules, known to underpin universality, which we evidence by trapping a single non-Abelian anyon on the torus. We encode logical qutrits in the nonlocal fusion space of non-Abelian fluxes and, by combining an entangling braiding operation with anyon charge measurements, realize a universal topological gate set and read-out, which we further demonstrate by topologically preparing a magic state. This work establishes $S_3$ TO as simple enough to be prepared efficiently, yet rich enough to enable universal topological quantum computation."}
{"id": "2601.21917", "categories": ["math.OC", "cs.CC", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.21917", "abs": "https://arxiv.org/abs/2601.21917", "authors": ["Amir Ali Ahmadi", "Georgina Hall"], "title": "On Approximate Computation of Critical Points", "comment": null, "summary": "We show that computing even very coarse approximations of critical points is intractable for simple classes of nonconvex functions. More concretely, we prove that if there exists a polynomial-time algorithm that takes as input a polynomial in $n$ variables of constant degree (as low as three) and outputs a point whose gradient has Euclidean norm at most $2^n$ whenever the polynomial has a critical point, then P=NP. The algorithm is permitted to return an arbitrary point when no critical point exists. We also prove hardness results for approximate computation of critical points under additional structural assumptions, including settings in which existence and uniqueness of a critical point are guaranteed, the function is lower bounded, and approximation is measured in terms of distance to a critical point. Overall, our results stand in contrast to the commonly-held belief that, in nonconvex optimization, approximate computation of critical points is a tractable task."}
{"id": "2601.20991", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20991", "abs": "https://arxiv.org/abs/2601.20991", "authors": ["E. Pascoe", "A. Catalan", "J. Sharkansky", "M. Beck"], "title": "Active polarization stabilization of fields in an optical fiber for protective measurements", "comment": "13 pages, 6 figures, 2 tables", "summary": "We have performed Zeno protective measurements of quantum polarization states by coupling the polarization to a temporal pointer (arrival time) in a birefringent optical fiber. It is necessary to actively stabilize the polarization, and we do this by using the signal photon counts themselves as the error signal in a feedback loop. We compare these measurements to a stabilization scheme using a classical reference beam as the error signal. The method using photon counts has higher signal levels and significantly reduced background. These improvements allow us to increase the number of Zeno stages in our measurements from 9 to 13, with a corresponding decrease in the measurement uncertainty."}
{"id": "2601.21990", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.21990", "abs": "https://arxiv.org/abs/2601.21990", "authors": ["Nicolas Blin", "Stefano Gualandi", "Christopher Maes", "Andrea Lodi", "Bartolomeo Stellato"], "title": "Batched First-Order Methods for Parallel LP Solving in MIP", "comment": "15 pages, 4 figures, 4 tables", "summary": "We present a batched first-order method for solving multiple linear programs in parallel on GPUs. Our approach extends the primal-dual hybrid gradient algorithm to efficiently solve batches of related linear programming problems that arise in mixed-integer programming techniques such as strong branching and bound tightening. By leveraging matrix-matrix operations instead of repeated matrix-vector operations, we obtain significant computational advantages on GPU architectures. We demonstrate the effectiveness of our approach on various case studies and identify the problem sizes where first-order methods outperform traditional simplex-based solvers depending on the computational environment one can use. This is a significant step for the design and development of integer programming algorithms tightly exploiting GPU capabilities where we argue that some specific operations should be allocated to GPUs and performed in full instead of using light-weight heuristic approaches on CPUs."}
{"id": "2601.21062", "categories": ["quant-ph", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2601.21062", "abs": "https://arxiv.org/abs/2601.21062", "authors": ["Kristian Knakkergaard Nielsen", "Lukas Wangler", "David Castells-Graells", "J. Ignacio Cirac", "Ana Asenjo-Garcia", "Daniel Malz", "Cosimo C. Rusconi"], "title": "Polaron-Polaritons in Subwavelength Arrays of Trapped Atoms", "comment": "33 pages (18 main text + 15 appendices) + 12 figures (8 in main + 4 in appendices)", "summary": "Subwavelength arrays of atoms trapped in optical lattices or tweezers are inherently susceptible to deformations: Optomechanical forces produce lattice distortions, which, in turn, modify the optical response of the array. We show that this coupling hybridizes collective atomic excitations (polaritons) with phonons, forming polaron-polaritons -- the fundamental quasiparticles governing light-matter interactions in arrays of trapped atoms. Using analytical polaron theory and numerical simulations, we show that: (1) phonons can strongly enhance the decay of subradiant states, but also enable their efficient excitation; (2) transport of dark excitations remains remarkably robust even at low trap frequencies, except when a polariton can resonantly scatter phonons; and (3) motion reduces the reflectivity of a two-dimensional atomic mirror, however, we identify mechanisms that mitigate this degradation and restore reflectivity above 99% in some cases. Our findings lay the foundation for analyzing motional effects in key applications and suggest new ways to harness them in state-of-the-art experiments."}
{"id": "2601.22038", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22038", "abs": "https://arxiv.org/abs/2601.22038", "authors": ["Vitalii Aksenov", "Martin Eigel", "Mathias Oster"], "title": "Anderson Mixing in Bures Wasserstein Space of Gaussian Measures", "comment": null, "summary": "Various statistical tasks, including sampling or computing Wasserstein barycenters, can be reformulated as fixed-point problems for operators on probability distributions.\n  Accelerating standard fixed-point iteration schemes provides a promising novel approach to the design of efficient numerical methods for these problems.\n  The Wasserstein geometry on the space of probability measures, although not precisely Riemannian, allows us to define various useful Riemannian notions, such as tangent spaces, exponential maps and parallel transport, motivating the adaptation of Riemannian numerical methods.\n  We demonstrate this by developing and implementing the Riemannian Anderson Mixing (RAM) method for Gaussian distributions.\n  The method reuses the history of the residuals and improves the iteration complexity, and we argue that the additional costs, compared to Picard method, are negligible.\n  We show that certain open balls in the Bures-Wasserstein manifold satisfy the requirements for convergence of RAM.\n  The numerical experiments show a significant acceleration compared to a Picard iteration, and performance on par with Riemannian Gradient Descent and Conjugate Gradient methods."}
{"id": "2601.21065", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.21065", "abs": "https://arxiv.org/abs/2601.21065", "authors": ["Jonathan Jeffrey", "Lucien Gandarias", "Monika Schleier-Smith", "Brian Swingle"], "title": "Building Holographic Entanglement by Measurement", "comment": "5 pages + references + supplement, 4 figures in main text", "summary": "We propose a framework for preparing quantum states with a holographic entanglement structure, in the sense that the entanglement entropies are governed by minimal surfaces in a chosen bulk geometry. We refer to such entropies as holographic because they obey a relation between entropies and bulk minimal surfaces, known as the Ryu-Takayanagi formula, that is a key feature of holographic models of quantum gravity. Typically in such models, the bulk geometry is determined by solving Einstein's equations. Here, we simply choose a bulk geometry, then discretize the geometry into a coupling graph comprising bulk and boundary nodes. Evolving under this graph of interactions and measuring the bulk nodes leaves behind the desired pure state on the boundary. We numerically demonstrate that the resulting entanglement properties approximately reproduce the predictions of the Ryu-Takayanagi formula in the chosen bulk geometry. We consider graphs associated with hyperbolic disk and wormhole geometries, but the approach is general. The minimal ingredients in our proposal involve only Gaussian operations and measurements and are readily implementable in photonic and cold-atom platforms."}
{"id": "2601.22080", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.22080", "abs": "https://arxiv.org/abs/2601.22080", "authors": ["Shuaicheng Tong", "Michael A. Boateng", "Mathieu Tanneau", "Pascal Van Hentenryck"], "title": "Volt/VAR Optimization in Transmission Networks with Discrete-Control Devices", "comment": null, "summary": "Voltage (Volt) and reactive-power (VAR) control in transmission networks is critical for reliability and increasingly needs fast, implementable decisions. This paper presents a transmission Volt/VAR Optimization (VVO) framework that co-optimizes discrete control of on-load tap-changing transformers (OLTCs) and capacitor banks (CBs) with AC power flow (ACPF) physics to improve voltage stability and minimize VAR generation. The framework follows a relax-round-resolve pipeline: a continuous relaxation proposes targets, a rounding step selects feasible discrete settings, and a final solve enforces AC power flow physics. Extensive experiments on IEEE, PEGASE, and RTE systems show consistent improvements in voltage and VAR quality metrics with modest generator redispatch while preserving economic operation and achieving compatible runtimes with real-time transmission operations."}
{"id": "2601.21075", "categories": ["quant-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2601.21075", "abs": "https://arxiv.org/abs/2601.21075", "authors": ["Gustavo de Oliveira", "Thiago Henrique Moreira", "Lucas Chibebe Céleri"], "title": "Dynamical Casimir effect under the action of gravitational waves", "comment": "Comments are welcome!", "summary": "Several nontrivial phenomena emerge when a quantum field is subjected to dynamical perturbations, with prominent examples including the Hawking and Unruh effects, as well as the dynamical Casimir effect. In this work, we compute the number of particles produced via the dynamical Casimir effect in an ideal cavity, where one of the mirrors is allowed to move under the influence of a gravitational wave. Assuming an oscillatory mirror motion and a plane gravitational wave, we identify the resonance conditions that lead to an exponential increase in the number of created particles through parametric amplification."}
{"id": "2601.22126", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.22126", "abs": "https://arxiv.org/abs/2601.22126", "authors": ["David Huckleberry Gutman", "George Lobo"], "title": "An Invitation to Higher-Order Riemannian Optimization: Optimal and Implementable Methods", "comment": null, "summary": "This paper presents the first optimal-rate $p$-th order methods with $p\\geq 1$ for finding first and second-order stationary points of non-convex smooth objective functions over Riemannian manifolds. In contrast to the geodesically convex setting, we definitively establish that the optimal oracle complexity of non-convex optimization over manifolds matches that over Euclidean space. In parallel with the complexity analysis, we introduce a general framework for systematically studying higher-order regularity on Riemannian manifolds that characterizes its joint dependence on the objective function and the chosen retraction. To the best of our knowledge, this framework constitutes the first known application in optimization of pullback connections and the Sasaki metric to the study of retraction-based pullbacks of the objective function. We provide clean derivative bounds based on a new covariant Faà di Bruno formula derived within our framework. For $p=3$, our methods are fully implementable via a new Krylov-based framework for minimizing quartically regularized cubic polynomials. This is the first Krylov method for this class of polynomials and may be of independent interest beyond Riemannian optimization."}
{"id": "2601.21119", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.21119", "abs": "https://arxiv.org/abs/2601.21119", "authors": ["M. Kamba", "S. Otabe", "K. Funo", "T. Sagawa", "K. Aikawa"], "title": "A levitated nano-accelerometer sensitized by quantum quench", "comment": "11 pages, 7 figures", "summary": "We realize a nanoscale accelerometer exploiting the nonequilibrium dynamics of a nanoparticle near the quantum ground state. We explore the dynamics after quenching the trapping potential and find that rapid quenching provides an instance at which the sensitivity is enhanced due to the minimized uncertainty in the position. With rapid quenching, the observed sensitivity is in good agreement with a numerical simulation based on the quantum Langevin equation and approaches to the limit given by the quantum Fisher information. Our results open up a pathway to quantum inertial sensing sensitized by exploiting quench dynamics."}
{"id": "2601.21230", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.21230", "abs": "https://arxiv.org/abs/2601.21230", "authors": ["Hengde Zhang", "Yunxiao Ren", "Zhisheng Duan", "Zhiyong Sun", "Guanrong Chen"], "title": "Deep Koopman Iterative Learning and Stability-Guaranteed Control for Unknown Nonlinear Time-Varying Systems", "comment": null, "summary": "This paper proposes a Koopman-based framework for modeling, prediction, and control of unknown nonlinear time-varying systems. We present a novel Koopman-based learning method for predicting the state of unknown nonlinear time-varying systems, upon which a robust controller is designed to ensure that the resulting closed-loop system is input-to-state stable with respect to the Koopman approximation error. The error of the lifted system model learned through the Koopman-based method increases over time due to the time-varying nature of the nonlinear time-varying system. To address this issue, an online iterative update scheme is incorporated into the learning process to update the lifted system model, aligning it more precisely with the time-varying nonlinear system by integrating the updated data and discarding the outdated data. A necessary condition for the feasibility of the proposed iterative learning method is derived. In order to reduce unnecessary system updates while ensuring the prediction accuracy of the lifted system, the update mechanism is enhanced to determine whether to update the lifted system and meanwhile to reduce updates that deteriorate the fitting performance. Furthermore, based on the online-updated lifted system, a controller is designed to ensure the closed-loop controlled system be input-to-state stable with respect to the Koopman approximation error. Numerical simulations on the Duffing oscillator, the serial manipulator, and the synthetic biological network system are presented to demonstrate the effectiveness of the proposed method for the approximation and control of unknown nonlinear time-varying systems. The results show that the proposed approach outperforms existing methods in terms of approximation accuracy and computational efficiency, even under significant system variations."}
{"id": "2601.21139", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21139", "abs": "https://arxiv.org/abs/2601.21139", "authors": ["Sinan Bugu"], "title": "Hidden-Field Coordination Reveals Payoff-Free Quantum Correlation Structure in Decentralized Coordination", "comment": null, "summary": "We study decentralized multi-agent coordination where agents must correlate actions against an unobserved field and cannot communicate. To isolate correlation geometry from payoff optimization, we introduce the Hidden-Field Coordination (HFC) model, which enforces identical information access and no-signaling constraints across strategies. Using information-theoretic diagnostics, we compare classical shared-randomness baselines with an entanglement-mediated strategy based on multipartite W states and a strictly local Spontaneous Leader Election rule. Within the restricted symmetric shared-latent baseline studied here, increasing total correlation is achieved primarily by driving actions toward alignment (copying), which also increases pairwise coincidence (collisions). By contrast, the quantum strategy realizes a collision-suppressing coordination regime: it preserves global dependence while reducing pairwise coincidence below the independent (product) baseline induced by the common marginal distribution. This produces a geometric separation in the joint-action distribution. Classical baselines concentrate probability near the diagonal of action equality, whereas the entanglement-mediated mapping occupies an offset-diagonal region associated with relational roles. Accordingly, the entanglement signature in this setting is not higher correlation magnitude; total-correlation differentials can be negative relative to the classical copying optimum. Instead, it reflects a change in dependence geometry that supports robust anti-coordination."}
{"id": "2601.21764", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.21764", "abs": "https://arxiv.org/abs/2601.21764", "authors": ["Olivier Bokanowski", "Carlos Esteve-Yagüe", "Richard Tsai"], "title": "Solving Hamilton-Jacobi equations by minimizing residuals of monotone discretizations", "comment": "29 pages, 5 figures", "summary": "We derive sufficient conditions under which residual minimization yields well-posed discrete solutions for nonlinear equations defined by monotone finite--difference discretizations. Our analysis is motivated by the challenge of solving fully nonlinear Hamilton--Jacobi (HJ) equations in high dimensions by means of a Neural Network, which is trained by minimizing residuals arising from monotone discretizations of the Hamiltonian. While classical theory ensures that consistency and monotonicity imply convergence to the viscosity solution, treating these discrete systems as optimization problems introduces new analytical hurdles: solvability and the uniqueness of local minima do not follow from monotonicity alone.\n  By establishing the well--posedness of these optimization--based solvers, our framework enables the adaptation of Level Set Methods to high--dimensional settings, unlocking new capabilities in applications such as high--dimensional segmentation and interface tracking. Finally, we observe that these arguments extend almost directly to degenerate elliptic or parabolic PDEs on graphs equipped with monotone graph Laplacians."}
{"id": "2601.21140", "categories": ["quant-ph", "cs.CC", "cs.DS", "math.CO"], "pdf": "https://arxiv.org/pdf/2601.21140", "abs": "https://arxiv.org/abs/2601.21140", "authors": ["Ryan L. Mann", "Gabriel Waite"], "title": "Efficient Algorithms for Weakly-Interacting Quantum Spin Systems", "comment": "6 pages, 0 figures", "summary": "We establish efficient algorithms for weakly-interacting quantum spin systems at arbitrary temperature. In particular, we obtain a fully polynomial-time approximation scheme for the partition function and an efficient approximate sampling scheme for the thermal distribution over a classical spin space. Our approach is based on the cluster expansion method and a standard reduction from approximate sampling to approximate counting."}
{"id": "2601.21874", "categories": ["math.NA", "math.OC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21874", "abs": "https://arxiv.org/abs/2601.21874", "authors": ["Bin Gao", "Renfeng Peng", "Ya-xiang Yuan"], "title": "Quotient geometry of tensor ring decomposition", "comment": "22 pages, 8 figures, 1 table", "summary": "Differential geometries derived from tensor decompositions have been extensively studied and provided the foundations for a variety of efficient numerical methods. Despite the practical success of the tensor ring (TR) decomposition, its intrinsic geometry remains less understood, primarily due to the underlying ring structure and the resulting nontrivial gauge invariance. We establish the quotient geometry of TR decomposition by imposing full-rank conditions on all unfolding matrices of the core tensors and capturing the gauge invariance. Additionally, the results can be extended to the uniform TR decomposition, where all core tensors are identical. Numerical experiments validate the developed geometries via tensor ring completion tasks."}
{"id": "2601.21152", "categories": ["quant-ph", "cs.SI", "math.CO", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.21152", "abs": "https://arxiv.org/abs/2601.21152", "authors": ["Md Samsur Rahaman", "Supriyo Dutta"], "title": "Community detection in network using Szegedy quantum walk", "comment": "Comments are welcome!", "summary": "In a network, the vertices with similar characteristics construct communities. The vertices in a community are well-connected. Detecting the communities in a network is a challenging and important problem in the theory of complex networks. One approach to solve this problem uses the classical random walks on the graphs. In quantum computing, quantum walks are the quantum mechanical counterparts of classical random walks. In this article, we employ a variant of Szegedy's quantum walk to develop a procedure for discovering the communities in networks. The limiting probability distribution of quantum walks assists us in determining the inclusion of a vertex in a community. We apply our procedure of community detection on a number of graphs and social networks, such as the relaxed caveman graph, $l$-partition graph, Karate club graph, dolphin's social network, etc."}
{"id": "2601.21240", "categories": ["quant-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2601.21240", "abs": "https://arxiv.org/abs/2601.21240", "authors": ["Shu-Min Wu", "Xiao-Ying Jiang", "Xiang-Yue Yu", "Zhihong Liu", "Xiao-Li Huang"], "title": "Reflecting boundary induced modulation of tripartite coherence harvesting", "comment": "20 pages, 7 figures", "summary": "We study the extraction of quantum coherence by three static Unruh-DeWitt (UDW) detectors that interact locally with a massless scalar vacuum field in the vicinity of an infinite perfectly reflecting boundary. Depending on the setup, the detectors are positioned either parallel or orthogonal to the boundary, with their energy gaps chosen to satisfy the hierarchy $Ω_C\\geq Ω_B\\geq Ω_A$. Our analysis reveals that decreasing the detector-boundary separation leads to a monotonic degradation of quantum coherence, whereas the same boundary effect can simultaneously preserve and even amplify the harvested quantum entanglement. Moreover, when the detectors possess distinct energy gaps, coherence extraction is further inhibited; strikingly, such non-identical configurations substantially enhance the efficiency of entanglement harvesting and markedly extend the range of detector separations over which non-negligible entanglement can be generated. Nevertheless, the harvesting of nonlocal quantum coherence is achievable over a significantly broader range of detector separations than that of quantum entanglement. Despite exhibiting similar overall behavior, orthogonal detector configurations outperform parallel ones in coherence harvesting, highlighting the quantitative influence of detector geometry. Overall, our study reveals a hierarchical distinction between quantum coherence and entanglement as operational resources in structured vacuum fields: quantum coherence is not only more readily accessible across space but also more robust than entanglement, whereas entanglement exhibits richer features and can be selectively activated and enhanced through boundary effects and detector non-uniformity."}
{"id": "2601.21250", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.21250", "abs": "https://arxiv.org/abs/2601.21250", "authors": ["Yang Xue", "Ze-Shan He", "Hao-Shu Tian", "Qin-Qin Wang", "Bin-Tong Yin", "Jun Zhong", "Xiao-Ye Xu", "Chuan-Feng Li", "Guang-Can Guo"], "title": "3D imaging of the biphoton spatiotemporal wave packet", "comment": null, "summary": "Photons are among the most important carriers of quantum information owing to their rich degrees of freedom (DoFs), including various spatiotemporal structures. The ability to characterize these DoFs, as well as the hidden correlations among them, directly determines whether they can be exploited for quantum tasks. While various methods have been developed for measuring the spatiotemporal structure of classical light fields, owing to the technical challenges posed by weak photon flux, there have so far been no reports of observing such structures in their quantum counterparts, except for a few studies limited to correlations within individual DoFs. Here, we propose and experimentally demonstrate a self-referenced, high-efficiency, and all-optical method, termed 3D imaging of photonic wave packets, for comprehensive characterization of the spatiotemporal structure of a quantum light field, i.e., the biphoton spatiotemporal wave packet. Benefiting from this developed method, we successfully observe the spatial-spatial, spectral-spectral, and spatiotemporal correlations of biphotons generated via spontaneous parametric down-conversion, revealing rich local and nonlocal spatiotemporal structure in quantum light fields. This method will further advance the understanding of the dynamics in nonlinear quantum optics and expand the potential of photons for applications in quantum communication and quantum computing."}
{"id": "2601.21254", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21254", "abs": "https://arxiv.org/abs/2601.21254", "authors": ["Daniel Eyles", "Emmanuel Lassalle", "Adam Stokes", "Ramón Paniagua-Domínguez", "Ahsan Nazir"], "title": "Sampling methods to describe superradiance in large ensembles of quantum emitters", "comment": "18 pages, 14 figures", "summary": "Superradiance is a quantum phenomenon in which coherence between emitters results in enhanced and directional radiative emission. Many quantum optical phenomena can be characterized by the two-time quantum correlation function $g^{(2)}(t,τ)$, which describes the photon statistics of emitted radiation. However, the critical task of determining $g^{(2)}(t,τ)$ becomes intractable for large emitter ensembles due to the exponential scaling of the Hilbert space dimension with the number of emitters. Here, we analyse and benchmark two approximate numerical sampling methods applicable to emitter arrays embedded within electromagnetic environments, which generally provide upper and lower bounds for $g^{(2)}(t,0)$. We also introduce corrections to these methods (termed offset corrections) that significantly improve the quality of the predictions. The optimal choice of method depends on the total number of emitters, such that taken together, the two approaches provide accurate descriptions across a broad range of important regimes. This work therefore provides new theoretical tools for studying the well-known yet complex phenomenon of superradiance in large ensembles of quantum emitters."}
{"id": "2601.21263", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21263", "abs": "https://arxiv.org/abs/2601.21263", "authors": ["Xinyin Zhang", "Yongguan Ke", "Zhengzhi Peng", "Zuorui Chen", "Wenjie Liu", "Li Zhang", "Chaohong Lee"], "title": "Localization and scattering of a photon in quasiperiodic qubit arrays", "comment": null, "summary": "We study the localization and scattering of a single photon in a waveguide coupled to qubit arrays with quasiperiodic spacings. As the quasiperiodic strength increases, localized subradiant states with extremely long lifetime appear around the resonant frequency and form a continuum band. In stark contrast to the fully disordered waveguide QED where all states are localized, we analytically find that the fraction of localized states is up to $(3-\\sqrt{5})/2$ when the modulation frequency is $(1+\\sqrt{5})/2$. The localized and delocalized states can be related to excitation in flat and curved inverse energy bands under the approximation of large-period modulation. When the quasiperiodic strength is weak, an extended subradiant state can support the transmission of a photon. However, as the quasiperiodic strength increases, localized subradiant states can completely block the transmission of a single photon in resonance with the subradiant states, and enhance the overall reflection. At a fixed quasiperiodic strength, we also find mobility edge in transmission spectrum, below and above which the transmission is either turned on and off as system size increases. Our work give new insights into the localization in non-Hermitian systems."}
{"id": "2601.21265", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21265", "abs": "https://arxiv.org/abs/2601.21265", "authors": ["Shang-Jen Su", "Shi-Yuan Wang", "Matthieu R. Bloch"], "title": "A Quantum-Memory-Free Quantum Secure Direct Communication Protocol Based on Privacy Amplification of Coded Sequences", "comment": null, "summary": "We develop an information-theoretic analysis of Quantum-Memory-Free (QMF) Quantum Secure Direct Communication (QSDC) under collective attacks as an alternative to the conventional Quantum Key Distribution (QKD) protocol with one-time pads. Our main contributions are: 1) a QMF-QSDC protocol that only relies on universal hashing of coded sequences without wiretap coding; 2) a set of privacy amplification theorems for extracting secrecy from coded classical sequences against quantum side-information. These tools open the way to the design of robust QMF-QSDC protocols."}
{"id": "2601.21313", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.21313", "abs": "https://arxiv.org/abs/2601.21313", "authors": ["Yiran Tian"], "title": "Dispersive Microwave Sensing for Quantum Computing with Floating Electrons", "comment": "Dissertation", "summary": "In this dissertation, resonator-based readout techniques were developed for floating electrons as qubits on cryogenic substrates, using two platforms: electrons on liquid helium and electrons on solid neon. In addition, a cryogenic microwave source was developed to enable low-noise measurement for qubit readout."}
{"id": "2601.21318", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21318", "abs": "https://arxiv.org/abs/2601.21318", "authors": ["Zirui Zhu", "Xiangyang Li"], "title": "QCL-IDS: Quantum Continual Learning for Intrusion Detection with Fidelity-Anchored Stability and Generative Replay", "comment": "11 pages", "summary": "Continual intrusion detection must absorb newly emerging attack stages while retaining legacy detection capability under strict operational constraints, including bounded compute and qubit budgets and privacy rules that preclude long-term storage of raw telemetry. We propose QCL-IDS, a quantum-centric continual-learning framework that co-designs stability and privacy-governed rehearsal for NISQ-era pipelines. Its core component, Q-FISH (Quantum Fisher Anchors), enforces retention using a compact anchor coreset through (i) sensitivity-weighted parameter constraints and (ii) a fidelity-based functional anchoring term that directly limits decision drift on representative historical traffic. To regain plasticity without retaining sensitive flows, QCL-IDS further introduces privacy-preserved quantum generative replay (QGR) via frozen, task-conditioned generator snapshots that synthesize bounded rehearsal samples. Across a three-stage attack stream on UNSW-NB15 and CICIDS2017, QCL-IDS consistently attains the best retention-adaptation trade-off: the gradient-anchor configuration achieves mean Attack-F1 = 0.941 with forgetting = 0.005 on UNSW-NB15 and mean Attack-F1 = 0.944 with forgetting = 0.004 on CICIDS2017, versus 0.800/0.138 and 0.803/0.128 for sequential fine-tuning, respectively."}
{"id": "2601.21332", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21332", "abs": "https://arxiv.org/abs/2601.21332", "authors": ["F. Iwase"], "title": "Robust Floquet Topological Phases and Anomalous $π$-Modes in Quasiperiodic Quantum Walks", "comment": "4 pages, 3 figures", "summary": "We uncover the global topological phase diagram of one-dimensional discrete-time quantum walks driven by Fibonacci-modulated coin parameters. Utilizing the mean chiral displacement (MCD) as dynamical probe, we identify robust topological phases defined by a strictly quantized winding number $ν=-1$ and exponentially localized edge states. Crucially, we discover that these topological edge modes emerges not only at zero energy but also at the quasienergy zone boundary $E=π$, exhibiting identical localization robustness despite the fractal nature of the bulk spectrum. These results demonstrate that Floquet topological protection remains intact amidst quasiperiodic disorder, offering a concrete route to observing exotic non-equilibrium phases in photonic experiments."}
{"id": "2601.21385", "categories": ["quant-ph", "physics.acc-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.21385", "abs": "https://arxiv.org/abs/2601.21385", "authors": ["Jakob M. Grzesik", "Aviv Karnieli", "Charles Roques-Carmes", "Dylan S. Black", "Trung Kiên Lê", "Olav Solgaard", "Shanhui Fan", "Jelena Vučković"], "title": "A general framework for interactions between electron beams and quantum optical systems", "comment": "8 pages, 3 figures", "summary": "We provide a theoretical framework to describe the dynamics of a free-electron beam interacting with quantized bound systems in arbitrary electromagnetic environments. This expands the quantum optics toolbox to incorporate free-electron beams for applications in highly tunable quantum control, imaging, and spectroscopy at the nanoscale. The framework recovers previously studied results and shows that electromagnetic environments can amplify the intrinsically weak coupling between a free-electron and a bound electron to reach previously inaccessible interaction regimes. We leverage this enhanced coupling for experimentally feasible protocols in coherent qubit control and towards the nondestructive readout and projective control of the electron beam's quantum-number statistics. Our framework is broadly applicable to microwave-frequency qubits, optical nanophotonics, cavity quantum electrodynamics, and emerging platforms at the interface of electron microscopy and quantum information."}
{"id": "2601.21398", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21398", "abs": "https://arxiv.org/abs/2601.21398", "authors": ["Meng-Long Song", "Zan Cao", "Xue-Ke Song", "Liu Ye", "Dong Wang"], "title": "Quantum steering probes energy transfer in quantum batteries", "comment": "9 pages, 7 figures, comments are welcomed. Accepted by Physical Review A", "summary": "This study investigates the role of EPR steering in characterizing the energy dynamics of quantum batteries (QBs) within \\textcolor{black}{a charging system that features shared reservoirs. After optimizing parameter configurations to achieve high-energy systems, we observe across a variety of charging scenarios with low-dissipation regimes that steering serves as a vital resource: it is initially stored until the system reaches energy equilibrium, and then subsequently utilized to sustain the enhancement of energy storage. Furthermore, steering acts as a witness to battery population balance and a consumable that enhances extractable work. Additionally, we discuss the contribution of the steering potential to energy upon high-dissipation charging in details. These findings establish a novel indicator for monitoring QB energy variations, which will be beneficial to achieve the high-performance quantum batteries."}
{"id": "2601.21435", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21435", "abs": "https://arxiv.org/abs/2601.21435", "authors": ["Han-Chuan Kou", "Zhi-Han Zhang", "Xin-Hui Wu", "Yan Zhou", "Gang Chen", "Peng Li"], "title": "Optimized adiabatic-impulse protocol preserving Kibble-Zurek scaling with attenuated anti-Kibble-Zurek behavior", "comment": null, "summary": "We propose an optimized adiabatic-impulse (OAI) protocol that achieves much shorter evolution time while preserving the Kibble-Zurek scaling. Near the critical regime, the control field is linearly ramped across the quantum critical point at a rate characterized by a quench time $τ_Q$. Away from the critical regime, the evolution is designed to follow the threshold of adiabatic breakdown, which we characterize by an adiabatic coefficient $ζ\\proptoτ_Q^α$. As a consequence, the total evolution time exhibits a sublinear power-law dependence on $τ_Q$, and the conventional linear quench protocol is recovered in the limit $α\\rightarrow\\infty$. We apply the OAI protocol to the transverse Ising chain and numerically determine the minimum value of $ζ$. We further investigate the nonequilibrium dynamics in the presence of a noisy field that can induce anti-Kibble-Zurek behavior, leading to more defects for slower ramps. Within the OAI protocol, the optimal quench time that minimizes defects obeys an altered universal power-law scaling with the noise strength. Finally, we generalize the OAI protocol to incorporate nonlinear Kibble-Zurek scaling."}
{"id": "2601.21472", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21472", "abs": "https://arxiv.org/abs/2601.21472", "authors": ["Xiao Xiao", "Dominik Hangleiter", "Dolev Bluvstein", "Mikhail D. Lukin", "Michael J. Gullans"], "title": "In-situ benchmarking of fault-tolerant quantum circuits. I. Clifford circuits", "comment": "53 pages, 19 figures", "summary": "Benchmarking physical devices and verifying logical algorithms are important tasks for scalable fault-tolerant quantum computing. Numerous protocols exist for benchmarking devices before running actual algorithms. In this work, we show that both physical and logical errors of fault-tolerant circuits can even be characterized in-situ using syndrome data. To achieve this, we map general fault-tolerant Clifford circuits to subsystem codes using the spacetime code formalism and develop a scheme for estimating Pauli noise in Clifford circuits using syndrome data. We give necessary and sufficient conditions for the learnability of physical and logical noise from given syndrome data, and show that we can accurately predict logical fidelities from the same data. Importantly, our approach requires only a polynomial sample size, even when the logical error rate is exponentially suppressed by the code distance, and thus gives an exponential advantage against methods that use only logical data such as direct fidelity estimation. We demonstrate the practical applicability of our methods in various scenarios using synthetic data as well as the experimental data from a recent demonstration of fault-tolerant circuits by Bluvstein et al. [Nature 626, 7997 (2024)]. Our methods provide an efficient, in-situ way of characterizing a fault-tolerant quantum computer to help gate calibration, improve decoding accuracy, and verify logical circuits."}
{"id": "2601.21499", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21499", "abs": "https://arxiv.org/abs/2601.21499", "authors": ["Raphael Wörnle", "Jonathan Körber", "Timo Steidl", "Georgy V. Astakhov", "Durga B. R. Dasari", "Florian Kaiser", "Vadim Vorobyov", "Jörg Wrachtrup"], "title": "RF-free driving of nuclear spins with color centers in silicon carbide", "comment": null, "summary": "Color centers that enable nuclear-spin control without RF fields offer a powerful route towards simplified and scalable quantum devices. Such capabilities are especially valuable for quantum sensing and computing platforms that already find applications in biology, materials science, and geophysics. A key challenge is the coherent manipulation of nearby nuclear spins, which serve as quantum memories and auxiliary qubits but conventionally require additional high-power RF fields which increase the experimental complexity and overall power consumption. Finding systems where both electron and nuclear spins can be controlled using a single MW source is therefore highly desirable. Here, using a modified divacancy center in silicon carbide, we show that coherent control of a coupled nuclear spin is possible without any RF fields. Instead, MW pulses driving the electron spin also manipulate the nuclear spin through hyperfineenhanced effects, activated by a precisely tilted external magnetic field. We demonstrate high-fidelity nuclear-spin control, achieving 89% two-qubit tomography fidelity and nearly T1-limited nuclear coherence times. This approach offers a simplified and scalable route for future quantum applications."}
{"id": "2601.21507", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21507", "abs": "https://arxiv.org/abs/2601.21507", "authors": ["Ivan Amelio", "Quentin Ficheux", "Nathan Goldman"], "title": "Quantum Simulation with Fluxonium Qutrit Arrays", "comment": null, "summary": "Fluxonium superconducting circuits were originally proposed to realize highly coherent qubits. In this work, we explore how these circuits can be used to implement and harness qutrits, by tuning their energy levels and matrix elements via an external flux bias. In particular, we investigate the distinctive features of arrays of fluxonium qutrits, and their potential for the quantum simulation of exotic quantum matter. We identify four different operational regimes, classified according to the plasmon-like versus fluxon-like nature of the qutrit excitations. Highly tunable on-site interactions are complemented by correlated single-particle hopping, pair hopping and non-local interactions, which naturally emerge and have different weights in the four regimes. Dispersive corrections and decoherence are also analyzed. We investigate the rich ground-state phase diagram of qutrit arrays and propose practical dynamical experiments to probe the different regimes. Altogether, fluxonium qutrit arrays emerge as a versatile and experimentally accessible platform to explore strongly correlated bosonic matter beyond the Bose-Hubbard paradigm, and with a potential toward simulating lattice gauge theories and non-Abelian topological states."}
{"id": "2601.21528", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21528", "abs": "https://arxiv.org/abs/2601.21528", "authors": ["Masroor H. S. Bukhari"], "title": "High-Coherence and High-frequency Quantum Computing: The Design of a High-Frequency, High-Coherence and Scalable Quantum Computing Architecture", "comment": "25 pages, 9 figures", "summary": "High-coherence, fault-tolerant and scalable quantum computing architectures with unprecedented long coherence times, faster gates, low losses and low bit-flip errors may be one of the only ways forward to achieve the true quantum advantage. In this context, high-frequency high-coherence (HCQC) qubits with new high-performance topologies could be a significant step towards efficient and high-fidelity quantum computing by facilitating compact size, higher scalability and higher than conventional operating temperatures. Although transmon type qubits are designed and manufactured routinely in the range of a few Giga-Hertz, normally from 4 to 6 GHz (and, at times, up to around 10GHz), achieving higher-frequency operation has challenges and entails special design and manufacturing considerations. This report presents the proposal and preliminary design of an 8-qubit transmon (with possible upgrade to up to 72 qubits on a chip) architecture working beyond an operation frequency of 10GHz, as well as presents a new connection topology. The current design spans a range of around 11 to 13.5 GHz (with a possible full range of 9-12GHz at the moment), with a central optimal operating frequency of 12.0 GHz, with the aim to possibly achieve a stable, compact and low-charge-noise operation, as lowest as possible as per the existing fabrication techniques. The aim is to achieve average relaxation times of up to 1.9ms with average quality factors of up to 2.75 x 10^7 after trials, while exploiting the new advances in superconducting junction manufacturing using tantalum and niobium/aluminum/aluminum oxide tri-layer structures on high-resistivity silicon substrates (carried out elsewhere by other groups and referred in this report)."}
{"id": "2601.21544", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21544", "abs": "https://arxiv.org/abs/2601.21544", "authors": ["Igor Khanonkin", "Amir Sivan", "Le Liu", "Johannes Eberle", "Kenji Watanabe", "Takashi Taniguchi", "Gadi Eisenstein", "Meir Orenstein"], "title": "Cooperative Emission from Quantum Emitters in Hexagonal Boron Nitride Layers", "comment": null, "summary": "Collective light emission from many-body quantum systems is a cornerstone of quantum optics, yet its implementation in solid-state platforms operating under ambient conditions remains highly challenging. Large-bandgap van der Waals materials such as hexagonal boron nitride (hBN) host stable room-temperature single-photon emitters with narrow linewidths across a broad spectral range. However, cooperative radiative effects in this system have not been previously explored. Here we demonstrate collective emission from quantum-emitter ensembles in hBN layers when the emitters are nearly indistinguishable and positioned within a sub-wavelength proximity. Using confocal microscopy and a Hanbury Brown-Twiss (HBT) configuration, we identify both isolated emitters and ensembles activated by localized electron-beam irradiation. Time-resolved photoluminescence measurements reveal a superlinear intensity enhancement and a pronounced acceleration of the radiative decay in tightly confined ensembles, with lifetimes approaching the temporal resolution of our experimental system (about 500 ps), compared to approximately 1.85 ns for single emitters or large, spatially extended ensembles. Complementary second-order photon-correlation measurements exhibit sub-Poissonian antidip consistent with emission from a few indistinguishable emitters. The simultaneous observation of lifetime shortening and enhanced emission provides direct evidence of cooperative emission at room temperature, achieved without optical cavities or cryogenic cooling. These results establish optically active defect ensembles in hBN as a scalable solid-state platform for engineered collective quantum optics in two-dimensional materials, opening avenues toward ultrabright superradiant light sources and nonclassical photonic states for quantum technologies."}
{"id": "2601.21555", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21555", "abs": "https://arxiv.org/abs/2601.21555", "authors": ["Sebastian Ulbricht", "Andrés Darío Bermúdez Manjarres", "Marcel Reginatto"], "title": "Entanglement of quantum systems via a classical mediator in hybrid van Hove theory", "comment": null, "summary": "It is a matter of ongoing discussion whether quantum states can become entangled while only interacting via a classical mediator. This lively debate is deeply interwoven with the question of whether entanglement studies can prove the quantum nature of gravity. However, the answer to this fundamental question depends crucially on which hybrid quantum-classical theory is used. In this letter, we demonstrate that entanglement by a classical mediator is possible within the framework of hybrid van Hove theory, showing that existing no-go theorems on that matter do not universally apply to hybrid theories in general. After briefly recapitulating the key features of the hybrid van Hove theory, we show this using the example of two quantum spins coupled by a classical harmonic oscillator. By deriving the spin density matrix for this scenario and comparing it to its equivalent for a pure quantum system, we show that entanglement between the two spins is generated in both cases. Conclusively, this is illustrated by presenting the purity and concurrence of the spin-spin system as a decisive measure for entanglement. Our results further imply that quantum entanglement studies cannot rule out consistent quantum theories featuring classical gravity."}
{"id": "2601.21616", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21616", "abs": "https://arxiv.org/abs/2601.21616", "authors": ["Jiasheng Mai", "Qiyu Liu", "Xiaowei Deng", "Yanyan Cai", "Zhongchu Ni", "Libo Zhang", "Ling Hu", "Pan Zheng", "Song Liu", "Yuan Xu", "Dapeng Yu"], "title": "A biased-erasure cavity qubit with hardware-efficient quantum error detection", "comment": "Main text: 10 pages, 4 figures; Supplementary material: 14 pages, 9 figures, 2 tables", "summary": "Erasure qubits are beneficial for quantum error correction due to their relaxed threshold requirements. While dual-rail erasure qubits have been demonstrated with a strong error hierarchy in circuit quantum electrodynamics, biased-erasure qubits -- where erasures originate predominantly from one logical basis state -- offer further advantages. Here, we realize a hardware-efficient biased-erasure qubit encoded in the vacuum and two-photon Fock states of a single microwave cavity. The qubit exhibits an erasure bias ratio of over 265. By using a transmon ancilla for logical measurements and mid-circuit erasure detections, we achieve logical state assignment errors below 1% and convert over 99.3% leakage errors into detected erasures. After postselection against erasures, we achieve effective logical relaxation and dephasing rates of $(6.2~\\mathrm{ms})^{-1}$ and $(3.1~\\mathrm{ms})^{-1}$, respectively, which exceed the erasure error rate by factors of 31 and 15, establishing a strong error hierarchy within the logical subspace. These postselected error rates indicate a coherence gain of about 6.0 beyond the break-even point set by the best physical qubit encoded in the two lowest Fock states in the cavity. Moreover, randomized benchmarking with interleaved erasure detections reveals a residual logical gate error of 0.29%. This work establishes a compact and hardware-efficient platform for biased-erasure qubits, promising concatenations into outer-level stabilizer codes toward fault-tolerant quantum computation."}
{"id": "2601.21629", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.21629", "abs": "https://arxiv.org/abs/2601.21629", "authors": ["Daniel Mills", "Ifan Williams", "Jacob Swain", "Gabriel Matos", "Enrico Rinaldi", "Alexander Koziell-Pipe"], "title": "Reinforcement Learning for Adaptive Composition of Quantum Circuit Optimisation Passes", "comment": "14 pages, 7 figures", "summary": "Many quantum software development kits provide a suite of circuit optimisation passes. These passes have been highly optimised and tested in isolation. However, the order in which they are applied is left to the user, or else defined in general-purpose default pass sequences. While general-purpose sequences miss opportunities for optimisation which are particular to individual circuits, designing pass sequences bespoke to particular circuits requires exceptional knowledge about quantum circuit design and optimisation. Here we propose and demonstrate training a reinforcement learning agent to compose optimisation-pass sequences. In particular the agent's action space consists of passes for two-qubit gate count reduction used in default PyTKET pass sequences. For the circuits in our diverse test set, the (mean, median) fraction of two-qubit gates removed by the agent is $(57.7\\%, \\ 56.7 \\%)$, compared to $(41.8 \\%, \\ 50.0 \\%)$ for the next best default pass sequence."}
{"id": "2601.21715", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21715", "abs": "https://arxiv.org/abs/2601.21715", "authors": ["Nirupam Basak", "Ankith Mohan", "Andrew Tanggara", "Tobias Haug", "Goutam Paul", "Kishor Bharti"], "title": "Hierarchical quantum decoders", "comment": null, "summary": "Decoders are a critical component of fault-tolerant quantum computing. They must identify errors based on syndrome measurements to correct quantum states. While finding the optimal correction is NP-hard and thus extremely difficult, approximate decoders with faster runtime often rely on uncontrolled heuristics. In this work, we propose a family of hierarchical quantum decoders with a tunable trade-off between speed and accuracy while retaining guarantees of optimality. We use the Lasserre Sum-of-Squares (SOS) hierarchy from optimization theory to relax the decoding problem. This approach creates a sequence of Semidefinite Programs (SDPs). Lower levels of the hierarchy are faster but approximate, while higher levels are slower but more accurate. We demonstrate that even low levels of this hierarchy significantly outperform standard Linear Programming relaxations. Our results on rotated surface codes and honeycomb color codes show that the SOS decoder approaches the performance of exact decoding. We find that Levels 2 and 3 of our hierarchy perform nearly as well as the exact solver. We analyze the convergence using rank-loop criteria and compare the method against other relaxation schemes. This work bridges the gap between fast heuristics and rigorous optimal decoding."}
{"id": "2601.21746", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21746", "abs": "https://arxiv.org/abs/2601.21746", "authors": ["Akitada Sakurai", "Aoi Hayashi", "William John Munro", "Kae Nemoto"], "title": "Quantum Random Features: A Spectral Framework for Quantum Machine Learning", "comment": "1o pages, 4 figures", "summary": "Quantum machine learning (QML) models often require deep, parameterized circuits to capture complex frequency components, limiting their scalability and near-term implementation. We introduce \\textit{Quantum Random Features} (QRF) and \\textit{Quantum Dynamical Random Features} (QDRF), lightweight quantum reservoir models inspired by classical random Fourier features (RFF) that generate high-dimensional spectral representations without variational optimization. Using $Z$-rotation encoding combined with random permutations or Hamiltonian dynamics, these models achieve $N_f$-dimensional feature maps at preprocessing cost $O(\\log(N_f))$. Spectral analysis shows that QRF and QDRF reproduce the behavior of RFF, while simulations on Fashion-MNIST reach up to 89.3\\% accuracy-matching or surpassing classical baselines with scalable qubit requirements. By linking spectral theory with experimentally feasible quantum dynamics, this work provides a compact and hardware-compatible route to scalable quantum learning."}
{"id": "2601.21801", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21801", "abs": "https://arxiv.org/abs/2601.21801", "authors": ["Jing Yang", "Satoya Imai", "Luca Pezzè"], "title": "A geometric criterion for optimal measurements in multiparameter quantum metrology", "comment": "5+2+7 pages, 1 figure", "summary": "Determining when the multiparameter quantum Cramér--Rao bound (QCRB) is saturable with experimentally relevant single-copy measurements is a central open problem in quantum metrology. Here we establish an equivalence between QCRB saturation and the simultaneous hollowization of a set of traceless operators associated with the estimation model, i.e., the existence of complete (generally nonorthogonal) bases in which all corresponding diagonal matrix elements vanish. This formulation yields a geometric characterization: optimal rank-one measurement vectors are confined to a subspace orthogonal to a state-determined Hermitian span. This provides a direct criterion to construct optimal Positive Operator-Valued Measures(POVMs). We then identify conditions under which the partial commutativity condition proposed in [Phys. Rev. A 100, 032104(2019)] becomes necessary and sufficient for the saturation of the QCRB, demonstrate that this condition is not always sufficient, and prove the counter-intuitive uselessness of informationally-complete POVMs."}
{"id": "2601.21806", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.21806", "abs": "https://arxiv.org/abs/2601.21806", "authors": ["Walter F. Wreszinski"], "title": "Schroedinger's principle eliminates the EPR-locality paradox", "comment": "8 pages", "summary": "We introduce a principle, implicitly contained in Schroedinger's paper (Schr35), which allows a proof of the non-existence of the EPR-locality paradox in the Copenhagen interpretation of quantum mechanics. The paradox is shown to be well-posed already in the simplest example of an entangled state of two spins one-half, independently of the (well-taken) objections by Araki and Yanase that the measurement of spin is not a local measurement. We assume that any measurement results in the collapse of the wave-packet."}
{"id": "2601.21838", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21838", "abs": "https://arxiv.org/abs/2601.21838", "authors": ["Weizhou Cai", "Zi-Jie Chen", "Ming Li", "Qing-Xuan Jie", "Xu-Bo Zou", "Guang-Can Guo", "Luyan Sun", "Chang-Ling Zou"], "title": "Error-detectable Universal Control for High-Gain Bosonic Quantum Error Correction", "comment": "6 pages, 4 figures", "summary": "Protecting quantum information through quantum error correction (QEC) is a cornerstone of future fault-tolerant quantum computation. However, current QEC-protected logical qubits have only achieved coherence times about twice those of their best physical constituents. Here, we show that the primary barrier to higher QEC gains is ancilla-induced operational errors rather than intrinsic cavity coherence. To overcome this bottleneck, we introduce error-detectable universal control of bosonic modes, wherein ancilla relaxation events are detected and the corresponding trajectories discarded, thereby suppressing operational errors on logical qubits. For binomial codes, we demonstrate universal gates with fidelities exceeding $99.6\\%$ and QEC gains of $8.33\\times$ beyond break-even. Our results establish that gains beyond $10\\times$ are achievable with state-of-the-art devices, establishing a path toward fault-tolerant bosonic quantum computing."}
{"id": "2601.21863", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21863", "abs": "https://arxiv.org/abs/2601.21863", "authors": ["Jelena Mackeprang", "Jonas Helsen"], "title": "A Bravyi-König theorem for Floquet codes generated by locally conjugate instantaneous stabiliser groups", "comment": null, "summary": "The Bravyi-König (BK) theorem is an important no-go theorem for the dynamics of topological stabiliser quantum error correcting codes. It states that any logical operation on a $D$-dimensional topological stabiliser code that can be implemented by a short-depth circuit acts on the codespace as an element of the $D$-th level of the Clifford hierarchy. In recent years, a new type of quantum error correcting codes based on Pauli stabilisers, dubbed Floquet codes, has been introduced. In Floquet codes, syndrome measurements are arranged such that they dynamically generate a codespace at each time step. Here, we show that the BK theorem holds for a definition of Floquet codes based on locally conjugate stabiliser groups. Moreover, we introduce and define a class of generalised unitaries in Floquet codes that need not preserve the codespace at each time step, but that combined with the measurements constitute a valid logical operation. We derive a canonical form of these generalised unitaries and show that the BK theorem holds for them too."}
{"id": "2601.21869", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.21869", "abs": "https://arxiv.org/abs/2601.21869", "authors": ["Yu-Chen Shen", "Matthieu R. Bloch"], "title": "Entanglement-Assisted Bosonic MAC: Achievable Rates and Covert Communication", "comment": "35 pages. Full technical version; includes detailed proofs for all main results", "summary": "We consider the problem of covert communication over the entanglement-assisted (EA) bosonic multiple access channel (MAC). We derive a closed-form achievable rate region for the general EA bosonic MAC using high-order phase-shift keying (PSK) modulation. Specifically, we demonstrate that in the low-photon regime the capacity region collapses into a rectangle, asymptotically matching the point-to-point capacity as multi-user interference vanishes. We also characterize an achievable covert throughput region, showing that entanglement assistance enables an aggregate throughput scaling of \\(O(\\sqrt{n} \\log n)\\) covert bits with the block length $n$ for both senders, surpassing the square-root law as in the point-to-point case. Our analysis reveals that the joint covertness constraint imposes a linear trade-off between the senders throughput."}
{"id": "2601.21880", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.21880", "abs": "https://arxiv.org/abs/2601.21880", "authors": ["Aidan G. McConnell", "Nils Dessmann", "Wojciech Adamczyk", "Benedict N. Murdin", "Lorenzo Amato", "Nikolay V. Abrosimov", "Sergey G. Pavlov", "Gabriel Aeppli", "Guy Matmon"], "title": "Rapid high-temperature initialisation and readout of spins in silicon with 10 THz photons", "comment": null, "summary": "Each cycle of a quantum computation requires a quantum state initialisation. For semiconductor-based quantum platforms, initialisation is typically performed via slow microwave processes and usually requires cooling to temperatures where only the lowest quantum level is occupied. In silicon, boron atoms are the most common impurities. They bind holes in orbitals including an effective spin-3/2 ground state as well as excited states analogous to the Rydberg series for hydrogen. Here we show that initialisation temperature demands may be relaxed and speeds increased over a thousand-fold by importing, from atomic physics, the procedure of optical pumping via excited orbital states to preferentially occupy a target ground state spin. Spin relaxation within the orbital ground state of unstrained silicon is too fast to measure for conventional pulsed microwave technology, except at temperatures below 2 K, implying a need not only for fast state preparation but also fast state readout. Circularly polarised ~10 THz photon pulses from a free electron laser meet both needs at temperatures above 3 K: a 9 ps pulse enhances the population of one spin eigenstate for the \"1s\"-like ground state orbital, and the second interrogates this imbalance in spin population. Using parameters given by our data, we calculate that it should be possible to initialise 99% of spins for boron in strained silicon within 250 ps at 3 K. The speedup of both state preparation and measurement gained for THz rather than microwave photons should be explored for the many other solid state quantum systems hosting THz excitations potentially useful as intermediate states."}
{"id": "2601.21923", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21923", "abs": "https://arxiv.org/abs/2601.21923", "authors": ["Elisabeth Wybo", "Jami Rönkkö", "Olli Hirviniemi", "Jernej Rudi Finžgar", "Martin Leib"], "title": "A scalable quantum-enhanced greedy algorithm for maximum independent set problems", "comment": "12 pages, 5 figures", "summary": "We investigate a hybrid quantum-classical algorithm for solving the Maximum Independent Set (MIS) problem on regular graphs, combining the Quantum Approximate Optimization Algorithm (QAOA) with a minimal degree classical greedy algorithm. The method leverages pre-computed QAOA angles, derived from depth-$p$ QAOA circuits on regular trees, to compute local expectation values and inform sequential greedy decisions that progressively build an independent set. This hybrid approach maintains shallow quantum circuit and avoids instance-specific parameter training, making it well-suited for implementation on current quantum hardware: we have implemented the algorithm on a 20 qubit IQM superconducting device to find independent sets in graphs with thousands of nodes. We perform tensor network simulations to evaluate the performance of the algorithm beyond the reach of current quantum hardware and compare to established classical heuristics. Our results show that even at low depth ($p=4$), the quantum-enhanced greedy method significantly outperforms purely classical greedy baselines as well as more sophisticated approximation algorithms. The modular structure of the algorithm and relatively low quantum resource requirements make it a compelling candidate for scalable, hybrid optimization in the NISQ era and beyond."}
{"id": "2601.21930", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21930", "abs": "https://arxiv.org/abs/2601.21930", "authors": ["Guillaume Théret", "Dominique Sugny", "Camille L. Latune"], "title": "Entropy production versus memory effects in two-level open quantum systems", "comment": "7+10 pages, 5+6 figures", "summary": "We compare several definitions of entropy production rate introduced in the literature from a large variety of situations and motivations, and then analyze their relations with memory effects. Considering a relevant experimental example of a qubit interacting with a single bosonic mode playing the role of a finite bath, we show that all definitions of entropy production coincide at weak coupling. In the strong coupling regime, significant discrepancies emerge between the different entropy production rates, although some similarities in the overall behaviour remain. However, surprisingly, two of these definitions -- one based on local quantities of the system and the other on non-local quantities -- coincide exactly, even in the case of strong coupling. Finally, a high degree of correspondence is observed when memory effects characterized by P-divisibility are compared with the sign of all entropy production rates in the case of weak coupling. Such correspondence degrades at strong coupling, leading us to extend the concept of entropy production to the dynamical map. We show a perfect equivalence between the sign of this enlarged concept of entropy production and P-divisibility, both numerically and analytically, in the case of phase-covariant master equations."}
{"id": "2601.22005", "categories": ["quant-ph", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.22005", "abs": "https://arxiv.org/abs/2601.22005", "authors": ["Jian Yao", "Pengtao Li", "Xiaohui Chen", "Quntao Zhuang"], "title": "Hierarchy of discriminative power and complexity in learning quantum ensembles", "comment": null, "summary": "Distance metrics are central to machine learning, yet distances between ensembles of quantum states remain poorly understood due to fundamental quantum measurement constraints. We introduce a hierarchy of integral probability metrics, termed MMD-$k$, which generalizes the maximum mean discrepancy to quantum ensembles and exhibit a strict trade-off between discriminative power and statistical efficiency as the moment order $k$ increases. For pure-state ensembles of size $N$, estimating MMD-$k$ using experimentally feasible SWAP-test-based estimators requires $Θ(N^{2-2/k})$ samples for constant $k$, and $Θ(N^3)$ samples to achieve full discriminative power at $k = N$. In contrast, the quantum Wasserstein distance attains full discriminative power with $Θ(N^2 \\log N)$ samples. These results provide principled guidance for the design of loss functions in quantum machine learning, which we illustrate in the training quantum denoising diffusion probabilistic models."}
{"id": "2601.22006", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22006", "abs": "https://arxiv.org/abs/2601.22006", "authors": ["Vasily Bokov", "Lisa Kohl", "Sebastian Schmitt", "Vedran Dunjko"], "title": "Machine learning with minimal use of quantum computers: Provable advantages in Learning Under Quantum Privileged Information (LUQPI)", "comment": "30 pages, 5 figures", "summary": "Quantum machine learning (QML) is often listed as a promising candidate for useful applications of quantum computers, in part due to numerous proofs of possible quantum advantages. A central question is how small a role quantum computers can play while still enabling provable learning advantages over classical methods. We study an especially restricted setting in which a quantum computer is used only as a feature extractor: it acts independently on individual data points, without access to labels or global dataset information, is available only to augment the training set, and is not available at deployment. Training and deployment are therefore carried out by fully classical learners on a dataset augmented with quantum-generated features. We formalize this model by adapting the classical framework of Learning Under Privileged Information (LUPI) to the quantum case, which we call Learning Under Quantum Privileged Information (LUQPI). Within this framework, we show that even such minimally involved quantum feature extraction, available only during training, can yield exponential quantum-classical separations for suitable concept classes and data distributions under reasonable computational assumptions. We further situate LUQPI within a taxonomy of related quantum and classical learning settings and show how standard classical machinery, most notably the SVM+ algorithm, can exploit quantum-augmented data. Finally, we present numerical experiments in a physically motivated many-body setting, where privileged quantum features are expectation values of observables on ground states, and observe consistent performance gains for LUQPI-style models over strong classical baselines."}
{"id": "2601.22011", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2601.22011", "abs": "https://arxiv.org/abs/2601.22011", "authors": ["M. Reefaz Rahman", "Karsten Schnier", "Ryan Goldsmith", "Benjamin J. Lawrie", "Joseph M. Lukens", "Seongsin M. Kim", "Patrick Kung"], "title": "Photonic Links for Spin-Based Quantum Sensors", "comment": null, "summary": "A growing variety of optically accessible spin qubits have emerged in recent years as key components for quantum sensors, qubits, and quantum memories. However, the scalability of conventional spin-based quantum architectures remains limited by direct microwave delivery, which introduces thermal noise, electromagnetic cross-talk, and design constraints for cryogenic, high-field, and distributed systems. In this work, we present a unified framework for RF-over-fiber (RFoF) control of optically accessible spins through RFoF optically detected magnetic resonance (ODMR) spectroscopy of nitrogen-vacancy (NV) centers in diamond. The RFoF platform relies on an electro-optically modulated telecom-band laser that transmits microwave signals over fiber and a high-speed photodiode that recovers the RF waveform to drive NV center spin transitions. We obtain an RFoF efficiency of 1.81\\% at 2.90~GHz, corresponding to $P_{\\mathrm{RF,out}}=-0.7$~dBm. The RFoF architecture provides a path toward low-noise, thermally isolated, and cryo-compatible ODMR systems bridging conventional spin-based quantum sensing protocols with emerging distributed quantum technologies."}
{"id": "2601.22064", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.22064", "abs": "https://arxiv.org/abs/2601.22064", "authors": ["Pedro Linck Maciel", "Nadja Kolb Bernardes"], "title": "Thermodynamics of linear open quantum walks", "comment": null, "summary": "Open quantum systems interact with their environment, leading to nonunitary dynamics. We investigate the thermodynamics of linear Open Quantum Walks (OQWs), a class of quantum walks whose dynamics is entirely driven by the environment. We define an equilibrium temperature, identify a population inversion near a finite critical value of a control parameter, analyze the thermalization process, and develop the statistical mechanics needed to describe the thermodynamical properties of linear OQWs. We also study nonequilibrium thermodynamics by analyzing the time evolution of entropy, energy, and temperature, while providing analytical tools to understand the system's evolution as it converges to the thermalized state. We examine the validity of the second and third laws of thermodynamics in this setting. Finally, we employ these developments to shed light on dissipative quantum computation within the OQW framework."}
{"id": "2601.22091", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.22091", "abs": "https://arxiv.org/abs/2601.22091", "authors": ["Juan Naranjo", "Thi Ha Kyaw", "Gaurav Saxena", "Kevin Ferreira", "Jack S. Baker"], "title": "Designing quantum technologies with a quantum computer", "comment": "13 pages, 6 figures, 2 tables", "summary": "Interacting spin systems in solids underpin a wide range of quantum technologies, from quantum sensors and single-photon sources to spin-defect-based quantum registers and processors. We develop a quantum-computer-aided framework for simulating such devices using a general electron spin resonance Hamiltonian incorporating zero-field splitting, the Zeeman effect, hyperfine interactions, dipole-dipole spin-spin terms, and electron-phonon decoherence. Within this model, we combine Gray-encoded qudit-to-qubit mappings, qubit-wise commuting aggregation, and a multi-reference selected quantum Krylov fast-forwarding (sQKFF) hybrid algorithm to access long-time dynamics while remaining compatible with NISQ and early fault-tolerant hardware constraints. Numerical simulations demonstrate the computation of autocorrelation functions up to $\\sim100$ ns, together with microwave absorption spectra and the $\\ell_1$-norm of coherence, achieving 18-30$\\%$ reductions in gate counts and circuit depth for Trotterized time-evolution circuits compared to unoptimized implementations. Using the nitrogen vacancy center in diamond as a testbed, we benchmark the framework against classical simulations and identify the reference-state selection in sQKFF as the primary factor governing accuracy at fixed hardware cost. This methodology provides a flexible blueprint for using quantum computers to design, compare, and optimize solid-state spin-qubit technologies under experimentally realistic conditions."}
{"id": "2601.20926", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.20926", "abs": "https://arxiv.org/abs/2601.20926", "authors": ["Hyunsoo Ha", "David A. Huse", "Rhine Samajdar"], "title": "Quench spectroscopy of amplitude modes in a one-dimensional critical phase", "comment": "7+16 pages, 3+5 figures", "summary": "We investigate the emergence of an amplitude (Higgs-like) mode in the gapless phase of the $(1+1)$D XXZ spin chain. Unlike conventional settings where amplitude modes arise from spontaneous symmetry breaking, here, we identify a symmetry-preserving underdamped excitation on top of a Luttinger-liquid ground state. Using nonequilibrium quench spectroscopy, we demonstrate that this mode manifests as oscillations of U(1)-symmetric observables following a sudden quench. By combining numerical simulations with Bethe-ansatz analyses, we trace its microscopic origin to specific families of string excitations. We further discuss experimental pathways to detect this mode in easy-plane quantum magnets and programmable quantum simulators. Our results showcase the utility of quantum quenches as a powerful tool to probe collective excitations, beyond the scope of linear response."}
{"id": "2601.21134", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21134", "abs": "https://arxiv.org/abs/2601.21134", "authors": ["Tobias Swann", "Adam Nahum"], "title": "Continuum mechanics of entanglement in noisy interacting fermion chains", "comment": "24 pages, 10 figures", "summary": "We develop an effective continuum description for information scrambling in a chain of randomly interacting Majorana fermions. The approach is based on the semiclassical treatment of the path integral for an effective spin chain that describes \"two-replica\" observables such as the entanglement purity and the OTOC. This formalism gives exact results for the entanglement membrane and for operator spreading in the limit of weak interactions. In this limit there is a large crossover lengthscale between free and interacting behavior, and this large lengthscale allows for a continuum limit and a controlled saddle-point calculation. The formalism is also somewhat different from that known from random unitary circuits. The entanglement membrane emerges as a kind of bound state of two travelling waves, and shows an interesting unbinding phenomenon as the velocity of the entanglement membrane approaches the butterfly velocity."}
{"id": "2601.21625", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21625", "abs": "https://arxiv.org/abs/2601.21625", "authors": ["Tsubasa Oishi", "Takuma Saito", "Hiromi Ebisu"], "title": "Non-invertible translation from Lieb-Schultz-Mattis anomaly", "comment": "36 pages, 4 figures", "summary": "Symmetry provides powerful non-perturbative constraints in quantum many-body systems. A prominent example is the Lieb-Schultz-Mattis (LSM) anomaly -- a mixed 't Hooft anomaly between internal and translational symmetries that forbids a trivial symmetric gapped phase. In this work, we investigate lattice translation operators in systems with an LSM anomaly. We construct explicit lattice models in two and three spatial dimensions and show that, after gauging the full internal symmetry, translation becomes non-invertible and fuses into defects of the internal symmetry. The result is supported by the anomaly-inflow in view of topological field theory. Our work extends earlier one-dimensional observations to a unified higher-dimensional framework and clarifies their origin in mixed anomalies and higher-group structures, highlighting a coherent interplay between internal and crystalline symmetries."}
{"id": "2601.21874", "categories": ["math.NA", "math.OC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.21874", "abs": "https://arxiv.org/abs/2601.21874", "authors": ["Bin Gao", "Renfeng Peng", "Ya-xiang Yuan"], "title": "Quotient geometry of tensor ring decomposition", "comment": "22 pages, 8 figures, 1 table", "summary": "Differential geometries derived from tensor decompositions have been extensively studied and provided the foundations for a variety of efficient numerical methods. Despite the practical success of the tensor ring (TR) decomposition, its intrinsic geometry remains less understood, primarily due to the underlying ring structure and the resulting nontrivial gauge invariance. We establish the quotient geometry of TR decomposition by imposing full-rank conditions on all unfolding matrices of the core tensors and capturing the gauge invariance. Additionally, the results can be extended to the uniform TR decomposition, where all core tensors are identical. Numerical experiments validate the developed geometries via tensor ring completion tasks."}
