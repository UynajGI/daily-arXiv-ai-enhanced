<div id=toc></div>

# Table of Contents

- [q-fin.CP](#q-fin.CP) [Total: 1]
- [stat.ME](#stat.ME) [Total: 17]
- [hep-lat](#hep-lat) [Total: 2]
- [cs.ET](#cs.ET) [Total: 2]
- [physics.geo-ph](#physics.geo-ph) [Total: 2]
- [q-fin.ST](#q-fin.ST) [Total: 7]
- [cs.CE](#cs.CE) [Total: 6]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 6]
- [math.ST](#math.ST) [Total: 12]
- [cs.SI](#cs.SI) [Total: 2]
- [eess.SY](#eess.SY) [Total: 14]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 7]
- [math.OC](#math.OC) [Total: 26]
- [physics.ao-ph](#physics.ao-ph) [Total: 3]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [nlin.CD](#nlin.CD) [Total: 1]
- [math.NA](#math.NA) [Total: 27]
- [physics.soc-ph](#physics.soc-ph) [Total: 4]


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [1] [FinFlowRL: An Imitation-Reinforcement Learning Framework for Adaptive Stochastic Control in Finance](https://arxiv.org/abs/2510.15883)
*Yang Li,Zhi Chen*

Main category: q-fin.CP

TL;DR: FinFlowRL是一种新的金融随机最优控制框架，通过预训练自适应元策略并结合噪声空间的强化学习微调，克服传统方法在非平稳市场中的局限性，显著提升多变市场环境下的控制性能。


<details>
  <summary>Details</summary>
Motivation: 传统随机控制方法依赖简化假设，在真实、非平稳金融市场中表现不佳，难以适应复杂多变的市场环境。

Method: 提出FinFlowRL框架，首先从多个专家策略中预训练一个自适应元策略，然后在噪声空间中通过强化学习进行微调；采用动作分块机制生成动作序列，以应对市场的非马尔可夫特性。

Result: FinFlowRL在多种市场条件下均优于单独优化的专家策略，表现出更强的适应性和控制效果。

Conclusion: FinFlowRL通过结合元学习与强化学习，并引入动作序列建模，有效提升了金融随机控制在复杂环境中的性能，具有较强的现实应用潜力。

Abstract: Traditional stochastic control methods in finance struggle in real world
markets due to their reliance on simplifying assumptions and stylized
frameworks. Such methods typically perform well in specific, well defined
environments but yield suboptimal results in changed, non stationary ones. We
introduce FinFlowRL, a novel framework for financial optimal stochastic
control. The framework pretrains an adaptive meta policy learning from multiple
expert strategies, then finetunes through reinforcement learning in the noise
space to optimize the generative process. By employing action chunking
generating action sequences rather than single decisions, it addresses the non
Markovian nature of markets. FinFlowRL consistently outperforms individually
optimized experts across diverse market conditions.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [2] [Extending Prediction-Powered Inference through Conformal Prediction](https://arxiv.org/abs/2510.16166)
*Daniel Csillag,Pedro Dall'Antonia,Claudio José Struchiner,Guilherme Tegoni Goedert*

Main category: stat.ME

TL;DR: 本文通过将预测驱动推断与共形预测相结合，提出了一种新的方法，能够在保证有效性的同时自然地实现额外的保障，如隐私性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的预测驱动推断方法在面对隐私、鲁棒性或连续分布偏移等强属性要求时，难以通用化，需逐案处理。本文旨在提出一种更通用且具备多重保障的推断方法。

Method: 通过使用校准的共形集合预测器进行数据填补，将预测驱动推断与共形预测结合，从而在均值推断、Z/M估计、e值及基于e值的方法中实现有效推断。

Result: 所提方法不仅实现了有效推断，还自然具备隐私保护和时间序列数据处理能力，且首次实现了离线运行的e值预测驱动方法。

Conclusion: 该方法为预测驱动推断提供了统一框架，能同时满足多种强属性需求，扩展了其在复杂实际场景中的适用性。

Abstract: Prediction-powered inference is a recent methodology for the safe use of
black-box ML models to impute missing data, strengthening inference of
statistical parameters. However, many applications require strong properties
besides valid inference, such as privacy, robustness or validity under
continuous distribution shifts; deriving prediction-powered methods with such
guarantees is generally an arduous process, and has to be done case by case. In
this paper, we resolve this issue by connecting prediction-powered inference
with conformal prediction: by performing imputation through a calibrated
conformal set-predictor, we attain validity while achieving additional
guarantees in a natural manner. We instantiate our procedure for the inference
of means, Z- and M-estimation, as well as e-values and e-value-based
procedures. Furthermore, in the case of e-values, ours is the first general
prediction-powered procedure that operates off-line. We demonstrate these
advantages by applying our method on private and time-series data. Both tasks
are nontrivial within the standard prediction-powered framework but become
natural under our method.

</details>


### [3] [Heterogeneity-Aware Federated Causal Inference Leveraging Effect-Measure Transportability](https://arxiv.org/abs/2510.16317)
*Siqi Cao,Shu Yang*

Main category: stat.ME

TL;DR: 本文提出了一种用于多源数据下因果估计的联邦学习框架，通过半参数有效估计器和自适应权重选择方法，在保护隐私的同时提升估计效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单一数据源下的平均处理效应，而跨多个数据源的更广泛因果度量仍缺乏有效方法，尤其是在数据可迁移性假设不完全成立的情况下。

Method: 推导并比较了在两种可迁移性假设下的半参数有效估计器，提出了Post-Federated Weighting Selection (PFWS) 框架，该框架分两步自适应识别兼容的数据站点，并整合机器学习算法估计干扰函数。

Result: 模拟和真实数据分析表明，PFWS框架在不同可迁移性场景下均优于仅使用目标站点的分析方法，显著提高了方差效率，同时保持了渐近有效性与名义覆盖概率。

Conclusion: PFWS框架为多中心联邦因果推断提供了一种高效、稳健且实用的解决方案，平衡了效率与模型假设之间的权衡。

Abstract: Federated learning of causal estimands offers a powerful strategy to improve
estimation efficiency by leveraging data from multiple study sites while
preserving privacy. Existing literature has primarily focused on the average
treatment effect using single data source, whereas our work addresses a broader
class of causal measures across multiple sources. We derive and compare
semiparametrically efficient estimators under two transportability assumptions,
which impose different restrictions on the data likelihood and illustrate the
efficiency-robustness tradeoff. This estimator also permits the incorporation
of flexible machine learning algorithms for nuisance functions while
maintaining parametric convergence rates and nominal coverage. To further
handle scenarios where some source sites violate transportability, we propose a
Post-Federated Weighting Selection (PFWS) framework, which is a two-step
procedure that adaptively identifies compatible sites and achieves the
semiparametric efficiency bound asymptotically. This framework mitigates the
efficiency loss of weighting methods and the instability and computational
burden of direct site selection in finite samples. Through extensive
simulations and real-data analysis, we demonstrate that our PFWS framework
achieves superior variance efficiency compared with the target-only analyses
across diverse transportability scenarios.

</details>


### [4] [Spatial Scalar-on-Function Quantile Regression Model](https://arxiv.org/abs/2510.16429)
*Muge Mutis,Ufuk Beyaztas,Filiz Karaman,Han Lin Shang*

Main category: stat.ME

TL;DR: 本文提出了一种新的空间标量-函数分位数回归模型，能够考虑空间依赖性和异质性条件分布，通过空间滞后响应纳入空间自相关，并利用工具变量方法解决空间滞后项引起的内生性问题，在模拟和实际环境数据中表现出优越的预测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统标量-函数回归模型难以处理空间依赖性和条件分布的异质性，尤其是在存在异常值和强空间相关性的场景下，因此需要发展能同时处理空间效应和分位数特征的新型模型。

Method: 提出一种包含空间滞后响应的空间标量-函数分位数回归模型，采用两种基于工具变量的稳健估计方法解决内生性问题，并在温和的正则条件下证明估计量的√n一致性与渐近正态性。

Result: 蒙特卡洛模拟显示所提估计量在强空间依赖和异常值污染下优于现有均值基和稳健方法；应用于意大利伦巴第地区的臭氧轨迹预测PM2.5浓度时，表现出更高的预测精度、鲁棒性和可解释性。

Conclusion: 所提出的模型有效整合了功能预测变量、空间依赖性和分位数回归，提供了对条件分布的全面刻画，具有良好的理论性质和实际应用价值，相关方法已实现于R包ssofqrm中。

Abstract: This paper introduces a novel spatial scalar-on-function quantile regression
model that extends classical scalar-on-function models to account for spatial
dependence and heterogeneous conditional distributions. The proposed model
incorporates spatial autocorrelation through a spatially lagged response and
characterizes the entire conditional distribution of a scalar outcome given a
functional predictor. To address the endogeneity induced by the spatial lag
term, we develop two robust estimation procedures based on instrumental
variable strategies. $\sqrt{n}$-consistency and asymptotic normality of the
proposed estimators are established under mild regularity conditions. We
demonstrate through extensive Monte Carlo simulations that the proposed
estimators outperform existing mean-based and robust alternatives, particularly
in settings with strong spatial dependence and outlier contamination. We apply
our method to high-resolution environmental data from the Lombardy region in
Italy, using daily ozone trajectories to predict daily mean particulate matter
with a diameter of less than 2.5 micrometers concentrations. The empirical
results confirm the superiority of our approach in predictive accuracy,
robustness, and interpretability across various quantile levels. Our method has
been implemented in the \texttt{ssofqrm} R package.

</details>


### [5] [Rank-based concordance for zero-inflated data: New representations, estimators, and sharp bounds](https://arxiv.org/abs/2510.16504)
*Jasper Arends,Guanjie Lyu,Mhamed Mesfioui,Elisa Perrone,Julien Trufin*

Main category: stat.ME

TL;DR: 本文提出了一种针对零膨胀连续分布的Gini's gamma和Spearman's footrule的新公式，修正了文献中关于零膨胀数据的Spearman's rho表达式，并建立了这些测度的最佳上下界，通过模拟和保险、天气预报的实际应用展示了零膨胀对依赖性估计的影响。


<details>
  <summary>Details</summary>
Motivation: 传统的一致性度量方法在处理包含大量零值（零膨胀）的数据时表现不佳，尤其是在保险、气象预测和生物医学等领域常见的混合离散-连续数据中。因此，需要开发适用于此类数据的一致性度量方法。

Method: 提出了适应于零膨胀连续分布的Gini's gamma和Spearman's footrule的新形式，结合绝对秩差进行建模，并修正了已有文献中Spearman's rho的错误表达式，同时推导出这些度量在零膨胀情况下的理论上下界。

Result: 建立了适用于零膨胀数据的一致性度量及其理论边界，仿真和实际案例（保险与天气预报）表明新方法能更准确地估计依赖关系，且优于传统方法。

Conclusion: 适当调整的零膨胀一致性度量能有效提升对含有大量零值数据的依赖结构估计精度，具有良好的实用性和解释力。

Abstract: Quantifying concordance between two random variables is crucial in
applications. Traditional estimation techniques for commonly used concordance
measures, such as Gini's gamma or Spearman's rho, often fail when data contain
ties. This is particularly problematic for zero-inflated data, characterized by
a combination of discrete mass in zero and a continuous component, which
frequently appear in insurance, weather forecasting, and biomedical
applications. This study provides a new formulation of Gini's gamma and
Spearman's footrule, two rank-based concordance measures that incorporate
absolute rank differences, tailored to zero-inflated continuous distributions.
Along the way, we correct an expression of Spearman's rho for zero-inflated
data previously presented in the literature. The best-possible upper and lower
bounds for these measures in zero-inflated continuous settings are established,
making the estimators useful and interpretable in practice. We pair our
theoretical results with simulations and two real-life applications in
insurance and weather forecasting, respectively. Our results illustrate the
impact of zero inflation on dependence estimation, emphasizing the benefits of
appropriately adjusted zero-inflated measures.

</details>


### [6] [Sensitivity Analysis to Unobserved Confounders: A Comparative Review to Estimate Confounding Strength in Sensitivity Models](https://arxiv.org/abs/2510.16560)
*Jean-Baptiste Baitairian,Bernard Sebastien,Rana Jreich,Sandrine Katsahian,Agathe Guilloux*

Main category: stat.ME

TL;DR: 本文综述了针对逆概率加权（IPW）估计量的边际敏感性模型，重点探讨了如何估计或下界化“混杂强度”这一敏感性参数，并提出了避免结果解释中常见误区的方法，以促进该方法在实际中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于观察性研究中忽略性假设常常不现实，存在未观测的混杂因素，导致因果推断困难，因此需要对IPW估计量进行敏感性分析以放宽该假设。

Method: 介绍边际敏感性模型及其在二元和连续处理效应中的应用，回顾不同估计或下界化敏感性参数（即“混杂强度”）的策略，并讨论如何选择合适的方法。

Result: 总结了现有文献中用于推导处理效应边界的方法，强调了敏感性参数设定的挑战及其对结果解释的影响。

Conclusion: 合理估计或下界化“混杂强度”参数并正确解释敏感性分析结果，有助于克服当前障碍，推动边际敏感性模型在实践中的更广泛应用。

Abstract: Causal inference is only valid when its underlying assumptions are satisfied,
one of the most central being the ignorability assumption (also known as
unconfoundedness or exogeneity). In practice, however, this assumption is often
unrealistic in observational studies, as some confounding variables may remain
unobserved. To address this limitation, sensitivity models for Inverse
Probability Weighting (IPW) estimators, known as Marginal Sensitivity Models,
have been introduced, allowing for a controlled relaxation of ignorability.
Over the past decades, a substantial body of literature has emerged around
these models, aiming to derive sharp and robust bounds for both binary and
continuous treatment effects. A key element of these approaches is the
specification of a sensitivity parameter, sometimes referred to as the
"confounding strength", which quantifies the extent of deviation from
ignorability. Yet, determining an appropriate value for this parameter is
challenging, and the final interpretation of sensitivity analyses can be
unclear. We believe these difficulties represent major obstacles to the
adoption of such methods in practice. In this review, after introducing
sensitivity analyses for IPW estimators, we focus on different strategies to
estimate or lower bound the confounding strength, select the most suitable
approach, and avoid common pitfalls in the interpretation of results.

</details>


### [7] [Identification and estimation of causal mechanisms in cluster-randomized trials with post-treatment confounding using Bayesian nonparametrics](https://arxiv.org/abs/2510.16673)
*Yuki Ohnishi,Michael J. Daniels,Lei Yang,Fan Li*

Main category: stat.ME

TL;DR: 提出了一种贝叶斯非参数框架，用于在存在干扰和事后混杂因素的情况下进行整群随机试验中的因果中介分析。


<details>
  <summary>Details</summary>
Motivation: 在整群随机试验中，因果中介分析因干扰、事后混杂和层次协变量调整等问题而复杂化，需要更稳健的方法来识别和估计因果效应。

Method: 开发了一个基于多元高斯copula的贝叶斯非参数框架，引入嵌套的公共原子增强型狄利克雷过程（CA-EDP）先验，结合公共原子模型（CAM）和增强型狄利克雷过程（EDP），实现跨群信息共享、异质性建模与稳健协变量调整。

Result: 该方法在模拟研究中表现出良好性能，提供了对残余事后混杂的内建敏感性分析，并通过真实整群随机试验的再分析验证了其有效性。

Conclusion: 所提出的框架能够有效处理整群随机试验中复杂的因果中介问题，具有理论支持和实际应用价值。

Abstract: Causal mediation analysis in cluster-randomized trials (CRTs) is essential
for explaining how cluster-level interventions affect individual outcomes, yet
it is complicated by interference, post-treatment confounding, and hierarchical
covariate adjustment. We develop a Bayesian nonparametric framework that
simultaneously accommodates interference and a post-treatment confounder that
precedes the mediator. Identification is achieved through a multivariate
Gaussian copula that replaces cross-world independence with a single dependence
parameter, yielding a built-in sensitivity analysis to residual post-treatment
confounding. For estimation, we introduce a nested common atoms enriched
Dirichlet process (CA-EDP) prior that integrates the Common Atoms Model (CAM)
to share information across clusters while capturing between- and
within-cluster heterogeneity, and an Enriched Dirichlet Process (EDP) structure
delivering robust covariate adjustment without impacting the outcome model. We
provide formal theoretical support for our prior by deriving the model's key
distributional properties, including its partially exchangeable partition
structure, and by establishing convergence guarantees for the practical
truncation-based posterior inference strategy. We demonstrate the performance
of the proposed methods in simulations and provide further illustration through
a reanalysis of a completed CRT.

</details>


### [8] [Correlation of divergency: c-delta. Being different in a similar way or not](https://arxiv.org/abs/2510.16717)
*Johan F. Hoorn*

Main category: stat.ME

TL;DR: 本文提出了一种新的统计指标c-delta，用于量化两组数值内部差异模式的相似性，不同于传统的相关系数，c-delta关注的是组内差异模式的匹配程度。


<details>
  <summary>Details</summary>
Motivation: 为了衡量两组数据在内部变异模式上的相似性，而传统相关系数无法有效捕捉这种结构化差异。

Method: 计算每组中每个值与其他值的发散程度，然后比较两组之间的发散模式，并通过组内平均均方根发散进行归一化以实现尺度不变性。

Result: c-delta提供了一种可应用于量子物理、遗传学、生态学、心理测量等多个领域的新型相似性度量方法，特别适用于基准测试和聚类验证。

Conclusion: c-delta为分析数据内部变异性提供了新视角，尽管其取值无界且对异常值敏感，但仍是一种有力的补充性统计工具。

Abstract: This paper introduces the correlation-of-divergency coefficient, c-delta, a
custom statistical measure designed to quantify the similarity of internal
divergence patterns between two groups of values. Unlike conventional
correlation coefficients such as Pearson or Spearman, which assess the
association between paired values, c-delta evaluates whether the way values
differ within one group is mirrored in another. The method involves
calculating, for each value, its divergence from all other values in its group,
and then comparing these patterns across the two groups (e.g., human vs machine
intelligence). The coefficient is normalised by the average root mean square
divergence within each group, ensuring scale invariance. Potential applications
of c-delta span quantum physics, where it can compare the spread of measurement
outcomes between quantum systems, as well as fields such as genetics, ecology,
psychometrics, manufacturing, machine learning, and social network analysis.
The measure is particularly useful for benchmarking, clustering validation, and
assessing the similarity of variability structures. While c-delta is not
bounded between -1 and 1 and may be sensitive to outliers (but so is PMCC), it
offers a new perspective for analysing internal variability and divergence. The
article discusses the mathematical formulation, potential adaptations for
complex data, and the interpretative considerations relevant to this
alternative approach.

</details>


### [9] [Causal inference for calibrated scaling interventions on time-to-event processes](https://arxiv.org/abs/2510.16798)
*Helene Charlotte Wiese Rytgaard,Mark van der Laan*

Main category: stat.ME

TL;DR: 本文提出了一种在连续时间事件历史设置中通过乘法缩放中间事件过程强度来进行随机干预的方法，定义了由标量参数α索引的因果估计量族，并引入校准干预以实现特定目标，提出了基于目标最大似然估计的估计方法。


<details>
  <summary>Details</summary>
Motivation: 在生存和纵向研究中，传统的确定性或静态干预常难以定义，因此需要一种更灵活且统计上合理的方法来进行因果干预分析。

Method: 通过将干预建模为事件强度的乘法缩放，构建由参数α索引的因果估计量族，引入校准干预以达到预设目标，并使用目标最大似然估计（TMLE）进行参数估计。

Result: 提出了适用于时间至事件处理或中介变量的广泛因果问题的框架，导出了非参数模型下各类目标参数的有效影响曲线，并证明其具有双重稳健性。

Conclusion: 该方法为生存和纵向数据分析提供了实用且统计严谨的干预分析工具，是传统干预方法的灵活替代方案，并可作为间接/直接效应分解的实用类比。

Abstract: This work studies stochastic interventions in continuous-time event-history
settings formulated as multiplicative scalings of the observed intensity
governing an intermediate event process. This gives rise to a family of causal
estimands indexed by a scalar parameter {\alpha}, which changes the event rate
while preserving the temporal and covariate structure of the data-generating
process. We introduce calibrated interventions, where \(\alpha\) is chosen to
achieve a pre-specified goal, such as a desired level of cumulative risk of the
intermediate event, and define corresponding composite target parameters
capturing the resulting effects on the outcome process. Our proposal enables
practical yet statistically principled intervention analysis in survival and
longitudinal settings, which offers a flexible alternative to deterministic or
static interventions that are often ill-defined. The framework applies broadly
to causal questions involving time-to-event treatments or mediators, and offers
a pragmatic analogue to indirect/direct effect decompositions. We present the
efficient influence curves for various versions of target parameters under a
nonparametric statistical model, discuss their double robustness properties,
and propose an estimation procedure based on targeted maximum likelihood
estimation (TMLE). The proposed estimands are illustrated through examples of
event-history scenarios addressing distinct causal questions.

</details>


### [10] [Causal Variance Decompositions for Measuring Health Inequalities](https://arxiv.org/abs/2510.16975)
*Lin Yu,Zhihui Liu,Kathy Han,Olli Saarela*

Main category: stat.ME

TL;DR: 本文提出了一种新的八路因果方差分解方法，用于在多值暴露情况下分解医疗服务质量差异的来源，特别是在医院绩效评估中，以量化不同社会人口群体间医疗服务差异的原因。


<details>
  <summary>Details</summary>
Motivation: 现有因果推断方法多局限于两两比较，难以全面解释医院绩效差异的来源，尤其是在涉及多个医院和多个社会人口群体时。因此，需要一种能分解多值暴露下结果方差的方法，以识别不平等的成因。

Method: 提出八路因果方差分解框架，将观察到的医疗服务质量变异分解为医院主效应、群体主效应、群体对医院效应的修饰作用、医院准入/选择、病例组合协变量效应及残差方差等八个部分，并构建了基于参数和非参数模型的估计方法。

Result: 通过模拟研究验证了所提估计量的性质，并利用SEER数据库中的癌症治疗数据进行了实证分析，展示了方法在真实场景中的应用效果。

Conclusion: 该八路分解方法能有效识别和量化医院绩效差异的多种因果来源，有助于更深入理解医疗不平等的机制，为政策制定提供依据。

Abstract: Recent causal inference literature has introduced causal effect
decompositions to quantify sources of observed inequalities or disparities in
outcomes but usually limiting this to pairwise comparisons. In the context of
hospital profiling, comparison of hospital performance may reveal inequalities
in healthcare delivery between sociodemographic groups, which may be explained
by access/selection or actual effect modification. We consider the case of
polytomous exposures in hospital profiling where the comparison is often to the
system wide average performance, and decompose the observed variance in care
delivery as the quantity of interest. For this, we formulate a new eight-way
causal variance decomposition where we attribute the observed variation to
components describing the main effects of hospital and group membership,
modification of the hospital effect by group membership, hospital
access/selection, effect of case-mix covariates and residual variance. We
discuss the causal interpretation of the components, formulate parametric and
nonparametric model based estimators and study the properties of these
estimators through simulation. Finally, we illustrate our method by an example
of cancer care delivery using data from the SEER database.

</details>


### [11] [Functional principal component analysis for functional data with detection limits](https://arxiv.org/abs/2510.16992)
*Haiyan Liu,Jeanine Houwing-Duistermaat*

Main category: stat.ME

TL;DR: 本文提出了一种考虑检测限导致的非随机缺失数据机制的功能性主成分分析方法，相较于传统方法能更准确地估计主成分和得分。


<details>
  <summary>Details</summary>
Motivation: 由于检测限导致的数据缺失属于非随机缺失（MNAR），传统FPCA方法通过填补检测限值忽略该机制，导致估计偏差，因此需要更合理的方法来处理此类问题。

Method: 基于Liu和Houwing-Duistermaat（2022, 2023）提出的均值和协方差函数估计方法，扩展了FPCA以适应受检测限影响的功能性数据，并推导了估计量的渐近性质，通过模拟研究评估性能。

Result: 模拟结果显示新方法在估计功能主成分和得分方面优于标准方法，且在纵向生物标志物数据分析中表现更优。

Conclusion: 所提出的方法能有效处理检测限导致的MNAR数据，提高了功能数据分析的可靠性。

Abstract: When measurements fall below or above a detection threshold, the resulting
data are missing not at random (MNAR), posing challenges for statistical
analysis. For example, in longitudinal biomarker studies, observations may be
subject to detection limits. Functional principal component analysis (FPCA) is
commonly used method for dimension reduction of dense and sparse data measured
along a continuum, but standard approaches typically ignore MNAR mechanisms by
imputing detection limit values, leading to biased estimates of principal
components and scores.
  Building on recent work by Liu and Houwing-Duistermaat (2022, 2023), who
proposed estimators for the mean and covariance functions under detection
limits, we extend FPCA to accommodate functional data affected by such limits.
We derive the asymptotic properties of the resulting estimators and assess
their performance through simulations, comparing them to standard methods.
Finally, we illustrate our approach using longitudinal biomarker data subject
to detection limits.
  Our method yields more accurate estimates of functional principal components
and scores, enhancing the reliability of functional data analysis in the
presence of detection limits.

</details>


### [12] [Variable Selection with Broken Adaptive Ridge Regression for Interval-Censored Competing Risks Data](https://arxiv.org/abs/2510.17084)
*Fatemeh Mahmoudi,Chenxi Li,Kaida Cai,Xuewen Lu*

Main category: stat.ME

TL;DR: 本文提出了一种基于断裂自适应岭（BAR）惩罚的变量选择方法，用于处理区间删失下的竞争风险数据，适用于半参数变换回归模型，能够同时选择重要风险因素并估计其对各事件的影响。


<details>
  <summary>Details</summary>
Motivation: 在医学研究和临床试验中，竞争风险数据普遍存在，传统方法难以有效处理区间删失情况下的变量选择问题，因此需要发展一种能够在复杂设置下进行稀疏变量选择并保持良好统计性质的方法。

Method: 采用断裂自适应岭（BAR）惩罚方法，在一类广泛的半参数变换回归模型（包括比例和非比例风险模型）框架下，对区间删失的竞争风险数据进行变量选择和参数估计。

Result: 理论分析表明该方法具有oracle性质，模拟研究表明其在变量选择和估计精度方面表现良好，并在真实HIV队列数据中得到应用验证。

Conclusion: 所提出的方法能有效处理区间删失竞争风险数据中的变量选择问题，具有良好的理论支持和实际应用价值，适用于多类半参数模型。

Abstract: Competing risks data refer to situations where the occurrence of one event
pre- cludes the possibility of other events happening, resulting in multiple
mutually exclusive events. This data type is commonly encountered in medical
research and clinical trials, exploring the interplay between different events
and informing decision-making in fields such as healthcare and epidemiology. We
develop a penal- ized variable selection procedure to handle such complex data
in an interval-censored setting. We consider a broad class of semiparametric
transformation regression mod- els, including popular models such as
proportional and non-proportional hazards models. To promote sparsity and
select variables specific to each event, we employ the broken adaptive ridge
(BAR) penalty. This approach allows us to simultane- ously select important
risk factors and estimate their effects for each event under investigation. We
establish the oracle property of the BAR procedure and evaluate its performance
through simulation studies. The proposed method is applied to a real-life HIV
cohort dataset, further validating its applicability in practice.

</details>


### [13] [Discovering Causal Relationships using Proxy Variables under Unmeasured Confounding](https://arxiv.org/abs/2510.17167)
*Yong Wu,Yanwei Fu,Shouyan Wang,Yizhou Wang,Xinwei Sun*

Main category: stat.ME

TL;DR: 提出一种新的非参数方法，利用负控制结果（NCO）在存在未观测混杂因素的情况下检验因果假设，适用于离散和连续变量，并通过核方法提高效率；在NCO无法识别时引入负控制暴露（NCE）恢复可识别性。


<details>
  <summary>Details</summary>
Motivation: 由于未观测混杂因素的存在，从观测数据中推断变量间的因果关系具有挑战性，现有方法受限于离散变量设置或强假设，缺乏通用性和稳健性。

Method: 基于新提出的积分方程，利用单个负控制结果（NCO），在完备性和温和正则条件下实现因果效应识别；提出核基检验方法，并在NCO不可识别时结合负控制暴露（NCE）进行补充。

Result: 理论推导了检验的渐近水平和功效性质，模拟和真实数据（ICU和世界价值观调查）实验表明该方法在多种设置下有效，优于现有方法。

Conclusion: 该方法为在未观测混杂下进行因果推断提供了一个通用、非参数且高效的框架，扩展了负控制方法的适用范围。

Abstract: Inferring causal relationships between variable pairs in the observational
study is crucial but challenging, due to the presence of unmeasured
confounding. While previous methods employed the negative controls to adjust
for the confounding bias, they were either restricted to the discrete setting
(i.e., all variables are discrete) or relied on strong assumptions for
identification. To address these problems, we develop a general nonparametric
approach that accommodates both discrete and continuous settings for testing
causal hypothesis under unmeasured confounders. By using only a single negative
control outcome (NCO), we establish a new identification result based on a
newly proposed integral equation that links the outcome and NCO, requiring only
the completeness and mild regularity conditions. We then propose a kernel-based
testing procedure that is more efficient than existing moment-restriction
methods. We derive the asymptotic level and power properties for our tests.
Furthermore, we examine cases where our procedure using only NCO fails to
achieve identification, and introduce a new procedure that incorporates a
negative control exposure (NCE) to restore identifiability. We demonstrate the
effectiveness of our approach through extensive simulations and real-world data
from the Intensive Care Data and World Values Survey.

</details>


### [14] [On Misspecified Error Distributions in Bayesian Functional Clustering: Consequences and Remedies](https://arxiv.org/abs/2510.17215)
*Fumiya Iwashige,Tomoya Wakayama,Shonosuke Sugasawa,Shintaro Hashimoto*

Main category: stat.ME

TL;DR: 本文提出通过引入高斯过程建模误差相关性，解决非参数贝叶斯方法在函数型数据中过度估计聚类数的问题，并提供可扩展近似与合理的超参数选择方法。


<details>
  <summary>Details</summary>
Motivation: 非参数贝叶斯方法虽灵活，但常因忽略误差结构的相关性而在函数型数据中高估聚类数量。

Method: 通过高斯过程建模观测点间的误差相关性，提出改进的贝叶斯函数模型及其可扩展近似方法，并结合高维聚类理论分析误差误设的影响。

Result: 理论和数值实验表明，正确建模误差依赖关系后，即使使用简单的狄利克雷过程聚类也能显著改善聚类结果，避免过估簇数。

Conclusion: 误差结构的正确建模对非参数贝叶斯聚类至关重要，忽略相关性是导致过估簇数的根本原因之一。

Abstract: Nonparametric Bayesian approaches provide a flexible framework for clustering
without pre-specifying the number of groups, yet they are well known to
overestimate the number of clusters, especially for functional data. We show
that a fundamental cause of this phenomenon lies in misspecification of the
error structure: errors are conventionally assumed to be independent across
observed points in Bayesian functional models. Through high-dimensional
clustering theory, we demonstrate that ignoring the underlying correlation
leads to excess clusters regardless of the flexibility of prior distributions.
Guided by this theory, we propose incorporating the underlying correlation
structures via Gaussian processes and also present its scalable approximation
with principled hyperparameter selection. Numerical experiments illustrate that
even simple clustering based on Dirichlet processes performs well once error
dependence is properly modeled.

</details>


### [15] [Bridging the gap between experimental burden and statistical power for quantiles equivalence testing](https://arxiv.org/abs/2510.17514)
*Jun Wu,Stéphane Guerrier,Si Gou,Yogeshvar N. Kalia,Luca Insolia*

Main category: stat.ME

TL;DR: 本文提出了一种新的有限样本调整方法α-qTOST，用于在双总体间检验多个分位数的等效性，相较于传统的qTOST方法，在保持名义检验水平的同时具有更高的统计功效，尤其适用于异方差和小样本不平衡情况下的极端分位数检验，并通过HIV药物开发和实验可重复性两个案例验证了其优势。


<details>
  <summary>Details</summary>
Motivation: 传统基于均值的方法在评估不同人群或实验条件下药物反应分布（尤其是极端分位数）的等效性时存在不足，且现有qTOST方法在异质高斯样本中过于保守，因此需要一种更高效、适用于多分位数联合检验的方法。

Method: 提出α-qTOST方法，对现有qTOST进行有限样本调整以提升检验功效，并扩展框架以实现多个分位数的同步等效性检验，结合理论证明与大规模模拟研究验证其性能。

Result: α-qTOST在保持名义检验水准的同时显著提高了统计功效，尤其在异方差、小样本和不平衡设计下对极端分位数的检验表现优越，并通过两个实际案例展示了其应用价值。

Conclusion: α-qTOST是一种优于传统qTOST的分位数等效性检验方法，适用于临床桥接研究等场景中对多个分位数（特别是极端分位数）的等效性评估，具有良好的理论支持和实际应用前景。

Abstract: Testing the equivalence of multiple quantiles between two populations is
important in many scientific applications, such as clinical trials, where
conventional mean-based methods may be inadequate. This is particularly
relevant in bridging studies that compare drug responses across different
experimental conditions or patient populations. These studies often aim to
assess whether a proposed dose for a target population achieves pharmacokinetic
levels comparable to those of a reference population where efficacy and safety
have been established. The focus is on extreme quantiles which directly inform
both efficacy and safety assessments. When analyzing heterogeneous Gaussian
samples, where a single quantile of interest is estimated, the existing Two
One-Sided Tests method for quantile equivalence testing (qTOST) tends to be
overly conservative. To mitigate this behavior, we introduce $\alpha$-qTOST, a
finite-sample adjustment that achieves uniformly higher power compared to qTOST
while maintaining the test size at the nominal level. Moreover, we extend the
quantile equivalence framework to simultaneously assess equivalence across
multiple quantiles. Through theoretical guarantees and an extensive simulation
study, we demonstrate that $\alpha$-qTOST offers substantial improvements,
especially when testing extreme quantiles under heteroskedasticity and with
small, unbalanced sample sizes. We illustrate these advantages through two case
studies, one in HIV drug development, where a bridging clinical trial examines
exposure distributions between male and female populations with unbalanced
sample sizes, and another in assessing the reproducibility of an identical
experimental protocol performed by different operators for generating
biodistribution profiles of topically administered and locally acting products.

</details>


### [16] [Defining Utility as a Measure of Preference Under Uncertainty in Phase I-II Oncology Dose Finding Trials](https://arxiv.org/abs/2510.17550)
*Andrew Hall,Duncan Wilson,Stuart Barber,Sarah R Brown*

Main category: stat.ME

TL;DR: 本文提出了一种基于参考依赖决策理论的贝叶斯剂量寻找方法（R2DT），通过结合疗效和毒性并引入参考点来反映临床决策中的风险态度变化，模拟结果显示该方法在接近疗效和毒性阈值的情况下更优地识别最佳剂量。


<details>
  <summary>Details</summary>
Motivation: 传统的剂量寻找方法难以充分反映临床决策中对收益和损失的风险态度差异，因此需要一种更贴近真实临床判断的灵活效用函数框架。

Method: 采用贝叶斯决策理论，构建基于冯·诺依曼-摩根斯坦效用理论的新效用函数，引入参考点以区分收益与损失的风险态度，提出Reference Dependent Decision Theoretic dose finding（R2DT）方法，并通过模拟研究评估其性能。

Result: 模拟研究表明R2DT在候选剂量接近最低可接受疗效和最高可接受毒性阈值时，能更有效地识别最优剂量，具有良好的操作特性。

Conclusion: R2DT框架通过灵活的效用函数更好地捕捉临床医生的信念，能够提高找到最优剂量的概率，展示了在剂量寻找试验中的应用潜力，值得在更广泛的场景中进一步评估。

Abstract: The main objective of dose finding trials is to find an optimal dose amongst
a candidate set for further research. The trial design in oncology proceeds in
stages with a decision as to how to treat the next group of patients made at
every stage until a final sample size is reached or the trial stopped early.
  This work applies a Bayesian decision-theoretic approach to the problem,
proposing a new utility function based on both efficacy and toxicity and
grounded in von Neumann-Morgenstern (VNM) utility theory. Our proposed
framework seeks to better capture real clinical judgements by allowing
attitudes to risk to vary when the judgements are of gains or losses, which are
defined with respect to an intermediate outcome known as a reference point. We
call this method Reference Dependent Decision Theoretic dose finding (R2DT).
  A simulation study demonstrates that the framework can perform well and
produce good operating characteristics. The simulation results demonstrate that
R2DT is better at detecting the optimal dose in scenarios where candidate doses
are around minimum acceptable efficacy and maximum acceptable toxicity
thresholds.
  The proposed framework shows that a flexible utility function, which better
captures clinician beliefs, can lead to trials with good operating
characteristics, including a high probability of finding the optimal dose. Our
work demonstrates proof-of-concept for this framework, which should be
evaluated in a broader range of settings.

</details>


### [17] [The modified odd Burr XII-G family of distributions: Properties and Applications](https://arxiv.org/abs/2510.17567)
*Alexsandro A. Ferreira,Gauss M. Cordeiro*

Main category: stat.ME

TL;DR: 提出了一种改进的奇 Burr XII-G 分布族，能够包含双峰和浴盆形状，并基于指数-G 类推导其性质。该族中建立了回归模型，通过最大似然法估计参数，并通过模拟验证其一致性。通过三个真实数据集展示了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了扩展现有分布族的灵活性，能够更好地拟合具有双峰或浴盆形状的复杂数据模式。

Method: 基于指数-G类构建改进的奇 Burr XII-G 分布族，提出相应的回归模型，并采用最大似然法进行参数估计。

Result: 模拟研究表明参数估计具有一致性，三个实际数据应用证明了该模型在拟合真实数据方面的优越性和实用性。

Conclusion: 改进的奇 Burr XII-G 族及其回归模型为复杂数据形态提供了有效的建模工具，具有良好的理论性质和应用前景。

Abstract: The modified odd Burr XII-G family is developed, capable of incorporating
bimodal and bathtub shapes in its baseline distributions, with properties
derived from the exponentiated-G class. A regression model is developed within
this family. The parameters are estimated by maximum likelihood, and
simulations are performed to verify their consistency. The usefulness of the
proposals is demonstrated by means of three real data sets.

</details>


### [18] [Relaxing the Assumption of Strongly Non-Informative Linkage Error in Secondary Regression Analysis of Linked Files](https://arxiv.org/abs/2510.17553)
*Priyanjali Bukke,Martin Slawski*

Main category: stat.ME

TL;DR: 本文提出了一种针对多源记录链接数据中回归分析的扩展框架，通过放松强非信息性链接假设，改进了在仅有链接数据且链接过程信息有限情况下的推断有效性。


<details>
  <summary>Details</summary>
Motivation: 由于多源数据链接过程中存在链接错误（如错误链接或遗漏链接），传统的回归分析可能产生偏差，因此需要一种能够考虑链接误差并适用于二次分析的统计框架。

Method: 基于先前提出的双组分混合模型框架，本文扩展了其假设，放松了链接过程与分析中使用的协变量无关的强非信息性链接假设，并通过模拟研究和案例研究验证方法的有效性。

Result: 模拟和案例研究表明，所提出的扩展方法在处理非信息性链接假设不成立的情况时，能够更准确地进行回归分析，提升后链接推断的准确性。

Conclusion: 该扩展框架提高了在实际应用场景中对链接数据进行回归分析的鲁棒性和适用性，尤其适用于链接机制信息有限的二次数据分析。

Abstract: Data analysis of files that are a result of linking records from multiple
sources are often affected by linkage errors. Records may be linked
incorrectly, or their links may be missed. In consequence, it is essential that
such errors are taken into account to ensure valid post-linkage inference.
Here, we propose an extension to a general framework for regression with linked
covariates and responses based on a two-component mixture model, which was
developed in prior work. This framework addresses the challenging case of
secondary analysis in which only the linked data is available and information
about the record linkage process is limited. The extension considered herein
relaxes the assumption of strongly non-informative linkage in the framework
according to which linkage does not depend on the covariates used in the
analysis, which may be limiting in practice. The effectiveness of the proposed
extension is investigated by simulations and a case study.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [19] [Electromagnetic form factors and structure of the $T_{bb}$ tetraquark from lattice QCD](https://arxiv.org/abs/2510.17549)
*Ivan Vujmilovic,Sara Collins,Luka Leskovec,Sasa Prelovsek*

Main category: hep-lat

TL;DR: 本文首次通过格点QCD计算了具有$I(J^P) = 0(1^+)$量子数的奇特四夸克态$T_{bb}\ (bb \bar u \bar d)$的电磁形状因子，揭示了其内部结构特征，包括电荷分布和磁偶极矩。研究结果支持$T_{bb}$是由一个紧致的自旋为1的重双夸克$[bb]$和一个自旋为0的轻反双夸克$[\bar u \bar d]$组成的束缚态。此外，$T_{bb}$的电荷半径显著小于$B$和$B^*$介子电荷半径之和。计算基于包含$N_f = 2+1$味动力学夸克、格距约为0.064 fm、π介子质量约为290 MeV的一个CLS组态系综完成。


<details>
  <summary>Details</summary>
Motivation: 理解奇特四夸克态$T_{bb}$的内部结构及其是否为由重双夸克和轻反双夸克组成的紧致束缚态。

Method: 采用格点QCD方法，在单个CLS组态系综上计算$T_{bb}$的电磁形状因子，并分别提取轻夸克和重夸克的电荷分布与磁偶极矩；同时计算了$B$和$B^*$介子的电磁形状因子用于对比。

Result: 发现$T_{bb}$的电荷半径明显小于$B$和$B^*$介子电荷半径之和；形状因子分析支持其为包含自旋1的$[bb]$色反三重态和自旋0的$[\bar u \bar d]$色三重态的紧致结构。

Conclusion: $T_{bb}$很可能是由紧致重双夸克和轻反双夸克构成的束缚态，具有较小的电荷半径，表明其内部结构紧凑，不同于松散的分子态。

Abstract: We present the first lattice QCD determination of the electromagnetic form
factors of the exotic tetraquark $T_{bb} \ (bb \bar u \bar d)$ with quantum
numbers $I( J^P ) = 0( 1^+ )$. The extracted form factors encode information
about its internal structure, including the charge distribution and the
magnetic dipole moments, determined separately for the light and heavy quarks.
Our results provide evidence in favor of it being a bound state consisting of a
compact heavy diquark $[bb]$ in a color-antitriplet with spin one, and a light
antidiquark $[\bar u \bar d]$ in a color-triplet with spin zero. The charge
radius of $T_{bb}$ is found to be significantly smaller than the combined
charge radii of $B$ and $B^*$ mesons. These two comprise the lowest-lying
threshold $BB^*$ in the channel we are considering, and their electric charge
form factors are also determined. The computations were performed on a single
CLS ensemble with $N_f = 2+1$ dynamical quarks and a lattice spacing of
approximately $a \approx0.064 \ \mathrm{fm}$ at the pion mass $m_\pi \approx
290 \ \mathrm{MeV}$.

</details>


### [20] [First Self-Renormalized Gluon PDF of Nucleon from Large-Momentum Effective Theory in the Continuum Limit](https://arxiv.org/abs/2510.17758)
*Alex NieMiera,William Good,Huey-Wen Lin,Fei Yao*

Main category: hep-lat

TL;DR: 本文首次在大动量有效理论（LaMET）框架下，通过混合方案结合自重正化方法，在连续极限中利用格点QCD确定了核子的胶子部分子分布函数（PDF）。研究使用高统计量计算，并在多个格点间距和特定参数下验证了结果的一致性，最终的胶子PDF与部分全球拟合结果相符，尤其偏好x>0.6区域胶子密度接近零的分析。


<details>
  <summary>Details</summary>
Motivation: 为了精确确定核子内部胶子的部分子分布函数（PDF），填补此前缺乏直接从第一性原理出发的格点QCD计算的空白，特别是在大动量有效理论（LaMET）框架下的应用。

Method: 采用大动量有效理论（LaMET）框架内的混合方案并结合自重正化方法，进行高统计量的格点QCD计算；在不同格点间距（a ≈ 0.15, 0.12, 0.09 fm）、pion质量约为310 MeV及Nf=2+1+1夸克味条件下，施加梯度流平滑处理（TW = 3a²），外推至连续极限。

Result: 实现了稳定的自重正化过程；重正化后的胶子矩阵元和PDF在不同格点间距下表现一致，其中a≈0.09 fm的结果在统计上与连续极限相容；最终得到的LaMET胶子PDF与某些全球拟合结果合理吻合，尤其支持x≳0.6区域胶子密度接近零的情况。

Conclusion: 该研究成功地在LaMET框架下通过格点QCD计算获得了核子胶子PDF的可靠结果，验证了自重正化方法的稳定性，并为高能物理中核子结构的理解提供了重要的第一性原理支持。

Abstract: We present the first lattice-QCD determination of the nucleon gluon parton
distribution function (PDF) within the large-momentum effective theory (LaMET)
framework, employing the hybrid scheme with self renormalization, in the
continuum limit. High statistics calculations with boost momentum $P_z \approx
2.0$-$2.2$~GeV are performed at lattice spacings of $a \approx \{ 0.15, 0.12,
0.09 \}$~fm, a pion mass of $M_\pi \approx 310$~MeV, with $N_f=2+1+1$ quark
flavors. We apply gradient flow smearing with $\mathcal{T}_\text{W} = 3a^2$,
finding that self-renormalization remains stable. The renormalized gluon matrix
elements and PDFs show consistent behavior across lattice spacings, with the $a
\approx 0.09$~fm results statistically compatible with the continuum limit. Our
final LaMET gluon PDF compares reasonably with select global-fit
determinations, specifically preferring analyses which have near-zero gluonic
density in the $x \gtrsim 0.6$ region.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [21] [Quantum Approximate Optimization Algorithm for MIMO with Quantized b-bit Beamforming](https://arxiv.org/abs/2510.15935)
*Nikos A Mitsiou,Ioannis Krikidis,George K Karagiannidis*

Main category: cs.ET

TL;DR: 本文首次将量子近似优化算法（QAOA）应用于6G通信中的低比特量化波束成形问题，建立了相位移与量子门之间的理论联系，并提出了一种warm-start QAOA方法以提升计算效率，数值结果表明该方法优于经典优化基准。


<details>
  <summary>Details</summary>
Motivation: 为解决传统全数字MIMO系统硬件复杂度和功耗高的问题，采用低比特量化相移器的MIMO架构虽具成本优势，但带来了预编码和后编码设计中的NP难组合优化问题，亟需高效求解方法。

Method: 利用量子近似优化算法（QAOA）结合交替优化方法，将量化波束成形问题映射为适合QAOA求解的哈密顿量，并提出warm-start策略以加速收敛。

Result: 成功建立了量化波束成形中相位移与量子旋转门之间的理论对应关系，推导了b比特情况下的哈密顿量，warm-start QAOA在数值仿真中表现出优于经典方法的波束成形增益。

Conclusion: QAOA为低比特MIMO系统的组合优化问题提供了有效解决方案，所提出的理论映射和哈密顿量分析具有跨领域应用潜力，如集成感知与通信、量子机器学习等。

Abstract: Multiple-input multiple-output (MIMO) is critical for 6G communication,
offering improved spectral efficiency and reliability. However, conventional
fully digital designs face significant challenges due to high hardware
complexity and power consumption. Low-bit MIMO architectures, such as those
employing b-bit quantized phase shifters, provide a cost-effective alternative
but introduce NP-hard combinatorial problems in the pre- and post-coding
design. This paper explores the use of the Quantum Approximate Optimization
Algorithm (QAOA) and alternating optimization to address the problem of b-bit
quantized phase shifters both at the transmitter and the receiver. We
demonstrate that the structure of this quantized beamforming problem aligns
naturally with hybrid-classical methods like QAOA, as the phase shifts used in
beamforming can be directly mapped to rotation gates in a quantum circuit.
Notably, this paper is the first to show that theoretical connection. Then, the
Hamiltonian derivation analysis for the b-bit case is presented, which could
have applications in different fields, such as integrated sensing and
communication, and emerging quantum algorithms such as quantum machine
learning. In addition, a warm-start QAOA approach is studied which improves
computational efficiency. Numerical results highlight the effectiveness of the
proposed methods in achieving an improved quantized beamforming gain over their
classical optimization benchmarks from the literature.

</details>


### [22] [Navigate in Demanding Missions: Integrating Human Intelligence and Brain-Inspired Intelligence](https://arxiv.org/abs/2510.17530)
*Xu He,Xiaolin Meng,Youdong Zhang,Lingfei Mo,Wenxuan Yin*

Main category: cs.ET

TL;DR: 本文探讨了神经科学、类脑智能（BII）和类脑导航（BIN）之间的相互作用，提出将神经形态赋能的脑机接口（BCI）融入BIN系统，以提升无人系统在复杂任务（如深空探索）中的可靠导航能力，并强调类脑人工智能意识可扩展人类智能，而BCI可作为机器失效时的安全保障。


<details>
  <summary>Details</summary>
Motivation: 当前BCI与BIN领域缺乏协同合作，限制了无人系统在极端环境下的自主导航能力，亟需融合神经科学与类脑技术以提升系统鲁棒性和智能化水平。

Method: 通过综述分析神经科学、BII与BIN的交叉关系，提出将神经形态计算支持的BCI集成到BIN框架中，构建人机协同增强的智能导航架构。

Result: 该方法有望显著提升无人系统在复杂环境中的导航可靠性，支持深空探索等高挑战任务，同时具备诊断空间认知障碍的潜力，并促进人机智能互补与安全协同。

Conclusion: 整合神经形态BCI与BIN是实现高可信智能导航的关键路径，不仅能增强机器智能的适应性与安全性，还为理解人类空间认知提供了新工具，但需审慎应对伦理与安全风险。

Abstract: This perspective analyzes the intricate interplay among neuroscience,
Brain-Inspired Intelligence (BII), and Brain-Inspired Navigation (BIN),
revealing a current lack of cooperative relationship between Brain-Computer
Interfaces (BCIs) and BIN fields. We advocate for the integration of
neuromorphic-empowered BCI into BIN, thereby bolstering the unmanned systems'
reliable navigation in demanding missions, such as deep space exploration, etc.
We highlight that machine intelligence, reinforced by brain-inspired artificial
consciousness, can extend human intelligence, with human intelligence mediated
by neuromorphic-enabled BCI acting as a safeguard in case machine intelligence
failures. This study also discusses the potentials of the proposed approach to
enhance unmanned systems' capabilities and facilitate the diagnostics of
spatial cognition disorders, while considering associated ethical and security
concerns.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [23] [Thermal Acoustical and Mechanical Characterization of Rock under in-situ conditions](https://arxiv.org/abs/2510.17353)
*Nima Haghighat,Hem B. Motra,Amir S. Sattari,Frank Wuttke*

Main category: physics.geo-ph

TL;DR: 本研究利用多冲头立方压机在控制的原位条件下进行稳态热导率测量，同时记录P波和S波速度，揭示了压力和温度对砂岩热导率的耦合影响。


<details>
  <summary>Details</summary>
Motivation: 目前关于压力和温度共同作用下岩石热导率的数据有限，因此需要一种能够在原位条件下精确测量热导率并监测微观结构变化的方法。

Method: 采用改进的多冲头立方压机系统，在不同温度和围压条件下对两种砂岩样品进行稳态热导率测量，并同步测量三个正交方向的P波和S波速度，以实时监控微结构演化。

Result: 实验结果显示，围压增加通过闭合微裂隙和改善颗粒接触提高了热导率；同时降低了热导率随温度升高而下降的速率。在12 MPa围压下，热导率每50°C平均下降约5.9%，而在100 MPa下仅下降约4.2%；此外，每增加10 MPa围压，热导率平均提高约1.4%。

Conclusion: 该方法可靠且能有效揭示压力与温度对岩石热导率的耦合作用，为地球深部热传输建模提供了重要实验依据。

Abstract: Data on the coupled influence of pressure and temperature on rock thermal
conductivity remain limited. This study adapts a multi-anvil cubic press to
enable steady-state thermal conductivity measurements under controlled in-situ
conditions. The setup concurrently records P- and S-wave velocities along three
orthogonal directions, providing unique real-time constraints on
micro-structural evolution. Beyond the expected temperature dependence,
preliminary tests on two sandstones reveal a twofold pressure effect:
increasing confining pressure enhances thermal conductivity through microcrack
closure and better grain contacts, while simultaneously reducing the rate at
which conductivity decreases with temperature. Initial results align closely
with published datasets, supporting the reliability of the developed
methodology. Quantitatively, the thermal conductivity of the studied sandstones
was found to decrease by an average of approximately 5.9% per 50 {\deg}C at the
lowest confinement (12 MPa), compared with about 4.2% per 50 {\deg}C at the
highest confinement (100 MPa). In addition, an average increase of roughly 1.4%
per 10 MPa of applied confining pressure was observed for both samples.

</details>


### [24] [Water saturation in texturally porous carbonate rocks: Shock thermodynamics and dampening of the shock](https://arxiv.org/abs/2510.17446)
*Juulia-Gabrielle Moreau,Argo Jõeleht,Anna Losiak,Meng-Hua Zhu,Jüri Plado*

Main category: physics.geo-ph

TL;DR: 本研究通过中尺度数值模拟，探讨了不同孔隙结构和含水饱和度的碳酸盐岩在冲击过程中的热力学特性，发现含水会降低冲击温度，孔隙取向和连通性显著影响温度分布和岩石变形。


<details>
  <summary>Details</summary>
Motivation: 研究沉积岩（尤其是碳酸盐岩）在冲击事件中的热力学行为，考虑孔隙结构和含水率的影响，以更准确地理解冲击坑形成过程及冲击效应的分布。

Method: 采用中尺度数值模拟方法，分析具有不同孔隙形态（孤立孔隙、粒间孔隙、拉长孔隙）和含水饱和度的碳酸盐岩在冲击下的热力学响应。

Result: 含水饱和显著降低冲击温度；拉长孔隙的取向在50-90°范围内影响温度分布和岩石变形；粒间孔隙因冲击波复杂相互作用导致颗粒周围出现温度分区。

Conclusion: 孔隙结构特征和含水状态对碳酸盐岩的冲击热力学行为有重要影响，需在冲击建模中予以充分考虑，特别是孔隙取向和连通性对冲击效应空间分布的调控作用。

Abstract: Sedimentary rocks often form the upper layers or the entire target rocks in
impact events. Thermodynamic properties of sedimentary rocks related to
porosity and water saturation affect the process of impact crater formation.
The heterogeneous distribution of sedimentary facies can complicate the
development and distribution of shock effects, especially in numerical
modeling. This work focuses on the shock thermodynamic properties of carbonate
rocks with differing porosity textures (e.g., isolated pores, interstitial
porosity, elongated pores) and water saturation levels. Using mesoscale
numerical modeling, we found that water saturation reduces shock temperatures
compared to those in dry, porous carbonate rocks. The orientation of elongated
pores and porosity lineations influences the shock temperature distribution and
rock deformation at angles of 50-90{\deg} to the shock front. Additionally, due
to complex shock wave interactions, interstitial porosity is key in creating
temperature zonations around larger grains.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [25] [A three-step machine learning approach to predict market bubbles with financial news](https://arxiv.org/abs/2510.16636)
*Abraham Atsiwo*

Main category: q-fin.ST

TL;DR: 提出了一种结合金融新闻情感和宏观经济指标的三步机器学习框架，用于预测标普500股市泡沫。


<details>
  <summary>Details</summary>
Motivation: 传统计量经济学方法在预测股市泡沫方面存在局限，因此需要结合文本和定量数据以提高预测准确性。

Method: 第一步使用右尾单位根检验识别标普500指数中的泡沫期；第二步利用自然语言处理技术从大规模金融新闻中提取情感特征；第三步采用集成学习方法，基于情感和宏观经济指标预测泡沫。

Result: 通过k折交叉验证评估模型性能，并优于基准机器学习算法，显著提高了预测准确性和鲁棒性。

Conclusion: 该三步集成方法能有效预测股市泡沫，为投资者、监管机构和政策制定者提供有价值的早期预警。

Abstract: This study presents a three-step machine learning framework to predict
bubbles in the S&P 500 stock market by combining financial news sentiment with
macroeconomic indicators. Building on traditional econometric approaches, the
proposed approach predicts bubble formation by integrating textual and
quantitative data sources. In the first step, bubble periods in the S&P 500
index are identified using a right-tailed unit root test, a widely recognized
real-time bubble detection method. The second step extracts sentiment features
from large-scale financial news articles using natural language processing
(NLP) techniques, which capture investors' expectations and behavioral
patterns. In the final step, ensemble learning methods are applied to predict
bubble occurrences based on high sentiment-based and macroeconomic predictors.
Model performance is evaluated through k-fold cross-validation and compared
against benchmark machine learning algorithms. Empirical results indicate that
the proposed three-step ensemble approach significantly improves predictive
accuracy and robustness, providing valuable early warning insights for
investors, regulators, and policymakers in mitigating systemic financial risks.

</details>


### [26] [Quantum and Classical Machine Learning in Decentralized Finance: Comparative Evidence from Multi-Asset Backtesting of Automated Market Makers](https://arxiv.org/abs/2510.15903)
*Chi-Sheng Chen,Aidan Hung-Wen Tsai*

Main category: q-fin.ST

TL;DR: 本研究通过在10个模型和多种加密货币资产上的回测，比较了量子机器学习（QML）与经典机器学习（CML）在自动做市商（AMM）和去中心化金融（DeFi）交易策略中的表现。结果显示，混合量子-经典模型整体表现最优，平均收益率为11.2%，平均夏普比率为1.42；经典机器学习模型平均收益率为9.8%，夏普比率为1.47。其中，QASA Sequence混合模型表现最佳，收益率达13.99%，夏普比率为1.76，显示出量子-经典混合方法在DeFi交易中的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索量子机器学习在去中心化金融交易策略中的实际有效性，并与经典方法进行系统性比较，以评估其潜在优势。

Method: 在多个加密货币资产上对10种模型（包括经典模型、纯量子模型、混合模型和Transformer模型）进行广泛回测，评估其在AMM和DeFi交易策略中的表现。

Result: 混合量子-经典模型取得最优整体表现，平均收益率11.2%，平均夏普比率1.42；经典模型为9.8%和1.47；QASA Sequence模型表现最佳，收益率13.99%，夏普比率1.76。

Conclusion: 量子-经典混合模型在AMM和DeFi交易策略中展现出优于纯经典和纯量子模型的潜力，特别是在收益和风险调整回报方面表现突出。

Abstract: This study presents a comprehensive empirical comparison between quantum
machine learning (QML) and classical machine learning (CML) approaches in
Automated Market Makers (AMM) and Decentralized Finance (DeFi) trading
strategies through extensive backtesting on 10 models across multiple
cryptocurrency assets. Our analysis encompasses classical ML models (Random
Forest, Gradient Boosting, Logistic Regression), pure quantum models (VQE
Classifier, QNN, QSVM), hybrid quantum-classical models (QASA Hybrid, QASA
Sequence, QuantumRWKV), and transformer models. The results demonstrate that
hybrid quantum models achieve superior overall performance with 11.2\% average
return and 1.42 average Sharpe ratio, while classical ML models show 9.8\%
average return and 1.47 average Sharpe ratio. The QASA Sequence hybrid model
achieves the highest individual return of 13.99\% with the best Sharpe ratio of
1.76, demonstrating the potential of quantum-classical hybrid approaches in AMM
and DeFi trading strategies.

</details>


### [27] [Investor Sentiment and Market Movements: A Granger Causality Perspective](https://arxiv.org/abs/2510.15915)
*Tamoghna Mukherjee*

Main category: q-fin.ST

TL;DR: 本研究探讨了投资者情绪与股票价格之间的关系，利用格兰杰因果关系检验分析收盘价指数与情感评分的关系，发现情绪变化对股价变动具有预测作用。


<details>
  <summary>Details</summary>
Motivation: 理解投资者情绪如何影响股市走势，并验证情绪变化是否能提前预示股价变动。

Method: 采用格兰杰因果关系推断方法，分析情感评分与股票收盘价指数之间的时间序列关系。

Result: 假设检验结果显示，投资者情绪变化在统计上能够显著地预测股价变化，存在正向响应关系。

Conclusion: 投资者情绪是影响股票价格的重要因素之一，情绪的变动可作为股价变动的领先指标。

Abstract: The stock market is heavily influenced by investor sentiment, which can drive
buying or selling behavior. Sentiment analysis helps in gauging the overall
sentiment of market participants towards a particular stock or the market as a
whole. Positive sentiment often leads to increased buying activity and vice
versa. Granger causality can be applied to ascertain whether changes in
sentiment precede changes in stock prices.The study is focused on this aspect
and tries to understand the relationship between close price index and
sentiment score with the help of Granger causality inference. The study finds a
positive response through hypothesis testing.

</details>


### [28] [Comparing LLMs for Sentiment Analysis in Financial Market News](https://arxiv.org/abs/2510.15929)
*Lucas Eduardo Pereira Teles,Carlos M. S. Figueiredo*

Main category: q-fin.ST

TL;DR: 本文比较了大语言模型与传统方法在金融新闻情感分析中的表现，发现大语言模型在大多数情况下优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 分析大语言模型在金融领域自然语言处理任务中的性能差异。

Method: 通过对比大语言模型与经典方法在情感分析任务中的表现进行评估。

Result: 大语言模型在绝大多数情况下优于经典模型。

Conclusion: 大语言模型在金融新闻情感分析中具有显著优势，优于传统方法。

Abstract: This article presents a comparative study of large language models (LLMs) in
the task of sentiment analysis of financial market news. This work aims to
analyze the performance difference of these models in this important natural
language processing task within the context of finance. LLM models are compared
with classical approaches, allowing for the quantification of the benefits of
each tested model or approach. Results show that large language models
outperform classical models in the vast majority of cases.

</details>


### [29] [Dynamic Factor Analysis of Price Movements in the Philippine Stock Exchange](https://arxiv.org/abs/2510.15938)
*Brian Godwin Lim,Dominic Dayta,Benedict Ryan Tiu,Renzo Roel Tan,Len Patrick Dominic Garces,Kazushi Ikeda*

Main category: q-fin.ST

TL;DR: 本研究利用动态因子模型分析菲律宾股票市场的价格动态，通过卡尔曼滤波和最大似然估计提取共同因子，并验证其作为实时市场指标的潜力，结果表明该模型能有效降低预测误差并提供对市场机制的新见解。


<details>
  <summary>Details</summary>
Motivation: 为了更深入理解股票市场的复杂动态，尤其是在新兴市场如菲律宾股市中，传统模型解释力有限，因此需要一个兼具可解释性和预测能力的模型框架。

Method: 采用动态因子模型，结合卡尔曼滤波和最大似然估计方法，从股价数据中提取因子载荷与共同因子，并将结果与资本资产定价模型进行对比；同时应用于菲律宾GDP增长率的现时预测。

Result: 一因子模型提取出类似于综合指数的系统性市场因子，两因子模型则分离出市场趋势和波动率因子；在GDP增长现时预测中，模型使样本外预测误差降低了超过34%。

Conclusion: 动态因子模型不仅有助于解释股票市场价格变动的内在机制，还可作为有效的实时经济指标工具，具有较强的实证价值和应用前景。

Abstract: The intricate dynamics of stock markets have led to extensive research on
models that are able to effectively explain their inherent complexities. This
study leverages the econometrics literature to explore the dynamic factor model
as an interpretable model with sufficient predictive capabilities for capturing
essential market phenomena. Although the model has been extensively applied for
predictive purposes, this study focuses on analyzing the extracted loadings and
common factors as an alternative framework for understanding stock price
dynamics. The results reveal novel insights into traditional market theories
when applied to the Philippine Stock Exchange using the Kalman method and
maximum likelihood estimation, with subsequent validation against the capital
asset pricing model. Notably, a one-factor model extracts a common factor
representing systematic or market dynamics similar to the composite index,
whereas a two-factor model extracts common factors representing market trends
and volatility. Furthermore, an application of the model for nowcasting the
growth rates of the Philippine gross domestic product highlights the potential
of the extracted common factors as viable real-time market indicators, yielding
over a 34% decrease in the out-of-sample prediction error. Overall, the results
underscore the value of dynamic factor analysis in gaining a deeper
understanding of market price movement dynamics.

</details>


### [30] [Institutional Differences, Crisis Shocks, and Volatility Structure: A By-Window EGARCH/TGARCH Analysis of ASEAN Stock Markets](https://arxiv.org/abs/2510.16010)
*Junlin Yang*

Main category: q-fin.ST

TL;DR: 本研究通过EGARCH和TGARCH模型，分析2010至2024年印尼、马来西亚和菲律宾股市在多个外部危机期间的波动性动态，发现危机加剧了波动持续性和非对称性，而制度成熟度影响市场恢复速度。


<details>
  <summary>Details</summary>
Motivation: 现有研究多聚焦单一市场或静态时期，缺乏将制度差异与多危机动态结合的统一分析框架。本文旨在填补这一空白，探讨制度因素如何调节新兴亚洲股市在不同危机中的波动特征。

Method: 采用EGARCH(1,1)和TGARCH(1,1)模型，基于滚动窗口方法，对印尼、马来西亚和菲律宾的日度股指收益率进行分析，并将样本划分为2013年缩减恐慌、2020-2021年新冠疫情、2022-2023年加息周期及平静期。

Result: 三个市场均表现出显著的波动持续性、非对称效应和厚尾特征；危机期间这些特征增强，危机后逐渐回归；马来西亚因制度较成熟，波动放大较小且恢复较快，而菲律宾因市场结构薄弱，波动持续更久。

Conclusion: 外部危机会普遍加剧股市波动结构，但制度稳健性决定了市场恢复的速度，表明加强透明度、宏观审慎沟通和流动性支持有助于降低全球冲击下的波动持续性。

Abstract: This study examines how institutional differences and external crises shape
volatility dynamics in emerging Asian stock markets. Using daily stock index
returns for Indonesia, Malaysia, and the Philippines from 2010 to 2024, we
estimate EGARCH(1,1) and TGARCH(1,1) models in a by-window design. The sample
is split into the 2013 Taper Tantrum, the 2020-2021 COVID-19 period, the
2022-2023 rate-hike cycle, and tranquil phases. Prior work typically studies a
single market or a static period; to our knowledge no study unifies
institutional comparison with multi-crisis dynamics within one GARCH framework.
We address this gap and show that all three markets display strong volatility
persistence and fat-tailed returns. During crises both persistence and
asymmetry increase, while tail thickness rises, implying more frequent extreme
moves. After crises, parameters revert toward pre-shock levels. Cross-country
evidence indicates a buffering role of institutional maturity: Malaysias
stronger regulatory and information systems dampen amplification and speed
recovery, whereas the Philippines thinner market structure prolongs
instability. We conclude that crises amplify volatility structures, while
institutional robustness governs recovery speed. The results provide policy
guidance on transparency, macroprudential communication, and liquidity support
to reduce volatility persistence during global shocks.

</details>


### [31] [Sentiment and Volatility in Financial Markets: A Review of BERT and GARCH Applications during Geopolitical Crises](https://arxiv.org/abs/2510.16503)
*Domenica Mino,Cillian Williamson*

Main category: q-fin.ST

TL;DR: 本研究结合人工智能与计量经济学方法，分析了2024年1月至7月期间美国主流平台关于俄乌战争的新闻情绪对股市波动性的影响，发现负面新闻情绪显著增加标普500指数的市场波动。


<details>
  <summary>Details</summary>
Motivation: 探讨地缘政治事件中的新闻情绪如何影响金融市场波动性，以提升危机时期的金融风险评估能力。

Method: 使用针对金融语言微调的BERT模型提取新闻情绪得分，并结合基于学生t分布的GARCH模型分析其对市场波动的影响。

Result: 发现负面新闻情绪与市场稳定性呈显著负相关，即悲观报道会加剧标普500指数的波动性。

Conclusion: 人工智能与自然语言处理技术可有效整合于计量经济模型中，用于实时监测和预测地缘政治危机下的市场动态，为金融风险管理提供有力工具。

Abstract: Artificial intelligence techniques have increasingly been applied to
understand the complex relationship between public sentiment and financial
market behaviour. This study explores the relationship between the sentiment of
news related to the Russia-Ukraine war and the volatility of the stock market.
A comprehensive dataset of news articles from major US platforms, published
between January 1 and July 17, 2024, was analysed using a fine-tuned
Bidirectional Encoder Representations from Transformers (BERT) model adapted
for financial language. We extracted sentiment scores and applied a Generalised
Autoregressive Conditional Heteroscedasticity (GARCH) model, enhanced with a
Student-t distribution to capture the heavy-tailed nature of financial returns
data. The results reveal a statistically significant negative relationship
between negative news sentiment and market stability, suggesting that
pessimistic war coverage is associated with increased volatility in the S&P 500
index. This research demonstrates how artificial intelligence and natural
language processing can be integrated with econometric modelling to assess
real-time market dynamics, offering valuable tools for financial risk analysis
during geopolitical crises.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [32] [Population-Based Search Method Using Uncertainty-related Pareto Front for Robust Multi-objective Optimization](https://arxiv.org/abs/2510.16386)
*Lihong Xu,Wenxiang Jiang*

Main category: cs.CE

TL;DR: 提出一种新的不确定性相关帕累托前沿（UPF）框架，平衡鲁棒性与收敛性，并在此基础上设计了RMOEA-UPF算法，实验证明其在多目标优化问题中具有优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统鲁棒多目标优化方法通常优先考虑收敛性而忽视鲁棒性，且单点评估效率低，难以应对噪声环境下的真实最优解需求。

Method: 提出不确定性相关帕累托前沿（UPF）框架，将鲁棒性与收敛性置于同等地位，并基于该框架设计基于种群搜索的RMOEA-UPF算法，在进化过程中直接优化UPF。

Result: 在九个基准问题和一个实际应用中验证了RMOEA-UPF的有效性，实验结果 consistently 表现优异，优于现有方法。

Conclusion: UPF框架为处理不确定环境下的多目标优化提供了更通用、可靠的解决方案，RMOEA-UPF是一种高效且具竞争力的鲁棒多目标优化算法。

Abstract: Traditional robust multi-objective optimization methods typically prioritize
convergence while treating robustness as a secondary consideration. This
approach can yield solutions that are not genuinely robust optimal under
noise-affected scenarios. Furthermore, compared to population-based search
methods, determining the robust optimal solution by evaluating the robustness
of a single convergence-optimal solution is also inefficient. To address these
two limitations,we propose a novel Uncertainty-related Pareto Front (UPF)
framework that balances robustness and convergence as equal priorities. Unlike
traditional Pareto Front, the UPF explicitly accounts for decision variable
with noise perturbation by quantifying their effects on both convergence
guarantees and robustness preservation equally within a theoretically grounded
and general framework. Building upon UPF, we propose RMOEA-UPF--a
population-based search robust multi-objective optimization algorithm. This
method enables efficient search optimization by calculating and optimizing the
UPF during the evolutionary process.Experiments on nine benchmark problems and
a real-world application demonstrate that RMOEA-UPF consistently delivers
high-quality results. Our method's consistent top-ranking performance indicates
a more general and reliable approach for solving complex, uncertain
multi-objective optimization problems. Code is available at:
https://github.com/WenxiangJiang-me/RMOEA-UPF.

</details>


### [33] [Chem-R: Learning to Reason as a Chemist](https://arxiv.org/abs/2510.16880)
*Weida Wang,Benteng Chen,Di Zhang,Wanhao Liu,Shuchen Pu,Ben Gao,Jin Zeng,Lei Bai,Wanli Ouyang,Xiaoyong Wei,Tianshu Yu,Tianfan Fu,Shuzhou Sun,Jiatong Li,Zifu Wang,Yuqiang Li,Shufei Zhang*

Main category: cs.CE

TL;DR: Chem-R是一种可泛化的化学推理模型，通过三阶段训练框架提升大语言模型在化学任务中的表现，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型缺乏核心化学知识，推理不可靠，在多样化化学任务中表现不佳。

Method: 提出Chem-R模型，采用三阶段训练框架：化学基础训练、化学推理协议蒸馏、多任务组相对策略优化。

Result: 在分子级和反应级任务上均达到最先进水平，相比Gemini-2.5-Pro和DeepSeek-R1最高提升46%（分子任务）和66%（反应任务）。

Conclusion: Chem-R具有强大的泛化能力、可解释性，有望成为下一代AI驱动化学发现的基础模型。

Abstract: Although large language models (LLMs) have significant potential to advance
chemical discovery, current LLMs lack core chemical knowledge, produce
unreliable reasoning trajectories, and exhibit suboptimal performance across
diverse chemical tasks. To address these challenges, we propose Chem-R, a
generalizable Chemical Reasoning model designed to emulate the deliberative
processes of chemists. Chem-R is trained through a three-phase framework that
progressively builds advanced reasoning capabilities, including: 1) Chemical
Foundation Training, which establishes core chemical knowledge. 2) Chemical
Reasoning Protocol Distillation, incorporating structured, expert-like
reasoning traces to guide systematic and reliable problem solving. 3)
Multi-task Group Relative Policy Optimization that optimizes the model for
balanced performance across diverse molecular- and reaction-level tasks. This
structured pipeline enables Chem-R to achieve state-of-the-art performance on
comprehensive benchmarks, surpassing leading large language models, including
Gemini-2.5-Pro and DeepSeek-R1, by up to 46% on molecular tasks and 66% on
reaction tasks. Meanwhile, Chem-R also consistently outperforms the existing
chemical foundation models across both molecular and reaction level tasks.
These results highlight Chem-R's robust generalization, interpretability, and
potential as a foundation for next-generation AI-driven chemical discovery.

</details>


### [34] [Trading with the Devil: Risk and Return in Foundation Model Strategies](https://arxiv.org/abs/2510.17165)
*Jinrui Zhang*

Main category: cs.CE

TL;DR: 本文提出了一种扩展的资本资产定价模型（CAPM），用于分离基于基础模型的交易策略中的系统性风险和特有风险，通过将不确定性分解为认知不确定性和偶然不确定性，利用蒙特卡洛dropout等方法量化风险，从而更清晰地评估基于基础模型的金融策略的风险收益特征。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练的基础模型在时间序列任务中展现出潜力，但其对交易策略风险特征的影响尚不明确，导致从业者难以投入大量资金。因此，需要一种方法来清晰区分和量化不同来源的风险。

Method: 提出扩展CAPM模型，结合不确定性解耦概念，将系统性风险对应于认知不确定性（来自预训练模型），特有风险对应于偶然不确定性（来自定制微调）。在“偶然性坍缩假设”下，使用蒙特卡洛dropout等方法估计认知风险。

Result: 实验表明，分离这两种风险有助于深入理解基于基础模型的交易策略的性能极限、模型随时间的退化情况以及可能的优化路径。

Conclusion: 该方法揭示了在竞争性金融市场中部署大规模预训练模型的潜力与陷阱，为风险透明化提供了可行框架。

Abstract: Foundation models - already transformative in domains such as natural
language processing - are now starting to emerge for time-series tasks in
finance. While these pretrained architectures promise versatile predictive
signals, little is known about how they shape the risk profiles of the trading
strategies built atop them, leaving practitioners reluctant to commit serious
capital. In this paper, we propose an extension to the Capital Asset Pricing
Model (CAPM) that disentangles the systematic risk introduced by a shared
foundation model - potentially capable of generating alpha if the underlying
model is genuinely predictive - from the idiosyncratic risk attributable to
custom fine-tuning, which typically accrues no systematic premium. To enable a
practical estimation of these separate risks, we align this decomposition with
the concepts of uncertainty disentanglement, casting systematic risk as
epistemic uncertainty (rooted in the pretrained model) and idiosyncratic risk
as aleatory uncertainty (introduced during custom adaptations). Under the
Aleatory Collapse Assumption, we illustrate how Monte Carlo dropout - among
other methods in the uncertainty-quantization toolkit - can directly measure
the epistemic risk, thereby mapping trading strategies to a more transparent
risk-return plane. Our experiments show that isolating these distinct risk
factors yields deeper insights into the performance limits of
foundation-model-based strategies, their model degradation over time, and
potential avenues for targeted refinements. Taken together, our results
highlight both the promise and the pitfalls of deploying large pretrained
models in competitive financial markets.

</details>


### [35] [StrengthLawExtractor: A Fiji plugin for 3D morphological feature extraction from X-ray micro-CT data](https://arxiv.org/abs/2510.17279)
*Qinyi Tian,Laura E. Dalton*

Main category: cs.CE

TL;DR: 提出了一种基于微CT和形态学测量的非破坏性方法，用于预测多孔材料的力学行为，并开发了Fiji插件以自动化提取关键微结构参数。


<details>
  <summary>Details</summary>
Motivation: 由于材料有限或条件不可重复，破坏性测试常不可行，因此需要非破坏性方法来关联多孔材料的微观结构几何与其力学性能。

Method: 利用微CT获取多孔材料的三维结构，结合最新的形态学理论，通过开发Fiji插件自动提取孔隙率、表面积、平均曲率和欧拉特征四个形态学参数。

Result: 该插件可集成到Fiji平台，实现可重复、易用的分析，并成功将提取的参数用于本构模型和机器学习，实现应力-应变行为预测和微观结构逆向设计。

Conclusion: 该方法支持非破坏性评估，加速材料筛选，并推动成像与预测建模在多孔介质研究中的融合。

Abstract: Non-destructive methods are essential for linking the microstructural
geometry of porous materials to their mechanical behavior, as destructive
testing is often infeasible due to limited material availability or
irreproducible conditions. Micro-computed tomography (micro-CT) provides high
resolution three dimensional reconstructions of porous microstructures,
enabling direct quantification of geometric descriptors. Recent advances in
morphometric theory have demonstrated that four independent morphometric
measures (porosity, surface area, mean curvature, and Euler characteristic) are
required to capture the relationship between microstructure and strength,
thereby forming the basis of generalized strength laws. To facilitate practical
application of this framework, a Fiji plugin was developed to extract the four
morphometric measures (porosity, surface area, mean curvature, Euler
characteristic) from micro-CT datasets automatically. The plugin integrates
within the Fiji platform to provide reproducible, accessible, and user friendly
analysis. The application of the tool demonstrates that the extracted
descriptors can be readily incorporated into constitutive models and machine
learning workflows, enabling the forward prediction of stress-strain behavior
as well as the inverse design of microstructures. This approach supports
non-destructive evaluation, accelerates materials selection, and advances the
integration of imaging with predictive modeling in porous media research.

</details>


### [36] [Modelling complexity in system safety: generalizing the D2T2 methodology](https://arxiv.org/abs/2510.17351)
*Silvia Tolo,John Andrews*

Main category: cs.CE

TL;DR: 本文提出了一种动态和依赖树理论的广义框架，旨在克服传统故障树和事件树分析在捕捉复杂系统动态行为和依赖关系方面的局限性，同时保持传统方法的计算可行性和易用性。


<details>
  <summary>Details</summary>
Motivation: 传统故障树和事件树分析难以充分描述复杂系统的动态行为和多层次依赖关系，且依赖保守假设导致分析结果的保守程度不可控，可能影响安全性和市场竞争力。

Method: 通过将传统故障树和事件树的组合失效分析特性与更灵活的建模方法相结合，推广动态和依赖树理论，实现对各类依赖关系的系统性集成建模。

Result: 所提出的方法能够在同一建模框架下考虑任意类型和位置的依赖关系，同时保持传统安全分析的熟悉性和有效性。

Conclusion: 该广义动态和依赖树理论为传统安全分析方法提供了增强能力，能够在不牺牲计算可行性的前提下，更真实地反映复杂系统的依赖结构和动态行为。

Abstract: Although Fault Tree and Event Tree analysis are still today the standard
approach to system safety analysis for many engineering sectors, these
techniques lack the capabilities of fully capturing the realistic, dynamic
behaviour of complex systems, which results in a dense network of dependencies
at any level, i.e. between components, trains of components or subsystems.
While these limitations are well recognised across both industry and academia,
the shortage of alternative tools able to tackle such challenges while
retaining the computational feasibility of the analysis keeps fuelling the
long-lived success of Fault Tree and Event Tree modelling. Analysts and
regulators often rely on the use of conservative assumptions to mitigate the
effect of oversimplifications associated with the use of such techniques.
However, this results in the analysis output to be characterised by an unknown
level of conservatism, with potential consequences on market competitiveness
(i.e., over-conservatism) or safety (i.e., under-conservatism). This study
proposes a generalization of the Dynamic and Dependent Tree Theory, which
offers theoretical tools for the systematic integration of dependency modelling
within the traditional Fault and Event Tree analysis framework. This is
achieved by marrying the traditional combinatorial nature of failure analysis,
formalised by the Fault and Event Tree language, with more flexible modelling
solutions, which provide the flexibility required to capture complex system
features. The main advantage of the proposed approach in comparison to existent
solutions is the ability to take into account, under the same modelling
framework, any type of dependency regardless of its nature and location, while
retaining the familiarity and effectiveness of traditional safety modelling.

</details>


### [37] [Volumetric Non-Invasive Cardiac Mapping for Accessible Global Arrhythmia Characterization](https://arxiv.org/abs/2510.17539)
*Jorge Vicente-Puig,Judit Chamorro-Servent,Ernesto Zacur,Inés Llorente-Lipe,Marta Martínez,Jorge Sanchez,Jana Reventós,Ivo Roca-Luque,Lluis Mont,Felipe Atienza,Andreu M. Climent,Maria S. Guillem,Ismael Hernández-Romero*

Main category: cs.CE

TL;DR: 本文提出了一种无需影像的三维心电图成像（volumetric ECGI）方法，通过格林函数求解逆源问题，实现全心肌体积激活映射，显著提高了心律失常起源定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统ECGI仅限于心外膜重建，难以检测深层心肌的心律失常，本文旨在突破这一局限，实现三维全心肌电活动重建。

Method: 采用基于格林函数的体积分形式求解逆源问题，结合体表电位进行三维心脏电活动重建，并在模拟早搏、多种患者病例及公开心梗数据集上验证性能。

Result: 与仅表面方法相比，该方法使估计与真实起源之间的测地误差减少了59.3%，在患者案例中激活模式与临床诊断一致，能更准确地定位复杂解剖区域中的心律失常起源。

Conclusion: 无需影像的三维ECGI技术克服了传统表面限制性方法的核心缺陷，提供了一种可及、无创的三维激活映射手段，有助于提升术前规划、消融靶点引导及心脏再同步治疗的优化。

Abstract: Cardiac arrhythmias are a major cause of morbidity and mortality increasing
the risk of stroke, heart failure, and sudden cardiac death. Imageless
electrocardiographic imaging (ECGI) provides a non invasive alternative to
electrical mapping from body surface potentials, but conventional ECGI is
confined to epicardial reconstructions and can miss arrhythmias originating in
deeper myocardium. We address this by reconstructing three dimensional cardiac
activity with a volumetric formulation that solves an inverse source problem
via Green's functions, enabling full volume activation mapping and improved
localization in anatomically complex regions. We evaluate the approach on
simulated premature ventricular beats and on four challenging patient cases, a
right ventricular outflow tract premature ventricular contraction, a left
bundle branch block, a ventricular tachycardia, and Wolff Parkinson White, and
additionally assess performance on an open source myocardial infarction
dataset. Results show that volumetric ECGI recovers 3D activation and sharpens
arrhythmia origin localization, achieving a 59.3% reduction in geodesic error
between estimated and simulated origins relative to surface only methods; in
patient cases, activation patterns align with clinical diagnoses. Overall,
imageless volumetric ECGI offers accessible, non invasive 3D activation mapping
that overcomes a core limitation of surface restricted techniques and may
improve preprocedural planning, ablation target guidance, and selection or
optimization of cardiac resynchronization therapy.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [38] [A unified framework for divergences, free energies, and Fokker-Planck equations](https://arxiv.org/abs/2510.16690)
*Anna L. F. Lucchi,Jean H. Y. Passos,Max Jauregui,Renio S. Mendes*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一种统一的理论框架，将散度、广义自由能、广义福克-普朗克方程和H定理联系起来，揭示了势能与稳态解之间在不同形式下的对偶关系。


<details>
  <summary>Details</summary>
Motivation: 为了理解和描述偏离标准统计力学预测的系统，需要一个能够统一处理广义热力学量和动力学方程的理论框架。

Method: 通过引入包含势能项的自由能泛函或以散度作为自由能量，构建相应的广义福克-普朗克方程，并结合H定理分析其演化特性。

Result: 建立了自由能形式与动力学方程结构之间的对应关系：当自由能显含势能时，稳态解直接由其决定；若以散度为自由能，则需额外设定稳态解与势能的关系才能恢复势能解释。

Conclusion: 该形式体系具有高度灵活性，适用于势能未知或非必要的复杂系统，为非标准统计力学提供了统一的描述方法。

Abstract: Many efforts have been made to explore systems that show significant
deviations from predictions related to the standard statistical mechanics. The
present work introduces a unified formalism that connects divergences,
generalized free energies, generalized Fokker-Planck equations, and H-theorem.
This framework is applied here in a range of scenarios, illustrating both
established and novel results. In many cases, the approach begins with a free
energy functional that explicitly includes a potential energy term, leading to
a direct relation between this energy and the stationary solution. Conversely,
when a divergence is used as free energy, the associated Fokker-Planck-like
equation lacks any explicit dependence on the potential energy, depending
instead on the stationary solution. To restore a potential-based
interpretation, an additional relation between the stationary solution and the
potential energy must be imposed. This duality underlines the flexibility of
the formalism and its capacity to adapt to systems where the potential energy
is unknown or unnecessary.

</details>


### [39] [Automatic Refinement of Force Fields Based on Phase Diagrams](https://arxiv.org/abs/2510.16778)
*Bin Jin,Bin Han,Wei Feng,Kuang Yu,Shenzhen Xu*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种基于自动微分和相图优化目标的力场 refinement 策略，通过气液共存相图验证，实现了高效准确的相变研究力场自动化开发。


<details>
  <summary>Details</summary>
Motivation: 精确表征相变需要充分的构型采样，传统分子力场在复杂相互作用下难以兼顾计算效率与物理可解释性，亟需高效的力场优化方法。

Method: 采用增强采样技术，设计可微损失函数，以相图为自上而下的优化目标，结合自动微分实现力场参数的精细化调整。

Result: 优化后的力场在两个模型体系中生成的气液相图与目标高度吻合。

Conclusion: 该方法为相变研究提供了一个有效的自动化力场开发框架。

Abstract: Exact characterization of phase transitions requires sufficient
configurational sampling, necessitating efficient and accurate potential energy
surfaces. Molecular force fields with computational efficiency and physical
interpretability are desirable but challenging to refine for complex
interactions. To address this, we propose a force field refinement strategy
with phase diagrams as top-down optimization targets based on automatic
differentiation. Using gas-liquid co-existence as a paradigm, we employ an
enhanced sampling technique and design a differentiable loss function to
evaluate force fields' depiction of phase diagrams. The refined force fields
produce gas-liquid phase diagrams matching well with targets for two modeling
systems, which confirms our approach as an effective automated force field
development framework for phase transition studies.

</details>


### [40] [A conjecture on the lower bound of the length-scale critical exponent $ν$ at continuous phase transitions](https://arxiv.org/abs/2510.17637)
*Andrea Pelissetto,Ettore Vicari*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一个关于连续相变中长度尺度指数ν的下限猜想，该猜想适用于d维Landau-Ginzburg-Wilson Φ^4理论，并得到了格点模型、二维极小共形场论及现有数值和解析结果的支持。


<details>
  <summary>Details</summary>
Motivation: 探讨重正化群理论中与连续相变兼容的临界指数的允许值，特别是长度尺度指数ν的下界问题。

Method: 通过分析序参量维度Δ_φ和能量算符维度Δ_ε之间的关系，提出不等式Δ_ε - 2Δ_φ ≥ 0，并结合格点模型论证、共形场论精确关系以及已有理论与数值结果进行验证。

Result: 提出了Δ_ε - 2Δ_φ ≥ 0这一不等式，导出了1/ν ≤ 2−η 和 γ = (2−η)ν ≥ 1；在幺正性要求η≥0的前提下，得出ν ≥ 1/2，比传统的ν > 1/d更严格。

Conclusion: 所提出的不等式在多种理论框架和已知结果中均成立，为LGW Φ^4理论中的连续相变提供了新的普适性约束。

Abstract: A fundamental issue in the renormalization-group (RG) theory of critical
phenomena concerns the allowed values of critical exponents that are consistent
with the continuous nature of a phase transition. Here we conjecture a lower
bound for the length-scale exponent $\nu$ that should hold at continuous
transitions associated with $d$-dimensional Landau-Ginzburg-Wilson (LGW)
$\Phi^4$ theories with a multicomponent scalar field $\varphi_i$ (including
some extensions with fermionic and gauge fields). If
$\Delta_\varphi=(d-2+\eta)/2$ is the dimension of the order parameter --
$\varphi_i$ in LGW models -- and $\Delta_\varepsilon=d-1/\nu$ is the RG
dimension of the energy operator $\varepsilon$, which can be identified with
$[\sum_i \varphi_i^2]$ (the squared field with a proper subtraction of the
mixing with the identity), we conjecture the inequality $\Delta_\varepsilon - 2
\Delta_\varphi\ge 0$, which implies $1/\nu \le 2-\eta$ and $\gamma =
(2-\eta)\nu\ge 1$. These inequalities are supported by general arguments for
lattice models, exact relations for two-dimensional minimal conformal field
theories, and are consistent with all known (numerical, perturbative, and
exact) results for LGW $\Phi^4$ theories. In particular, since unitarity
requires $\eta\ge 0$, the above inequality implies $\nu\ge 1/2$ for unitary
theories. This lower bound is more restrictive than the bound $\nu > 1/d$,
which is derived by noting that $\nu=1/d$ is the expected behavior at
first-order transitions.

</details>


### [41] [The first positive position of a lattice random walk](https://arxiv.org/abs/2510.17329)
*Claude Godrèche,Jean-Marc Luck*

Main category: cond-mat.stat-mech

TL;DR: 本文对一维对称有限范围格点随机游走中，从原点出发的随机游走者首次到达的正位置分布进行了详细且自包含的分析。


<details>
  <summary>Details</summary>
Motivation: 研究一维随机游走中的极值和记录问题需要理解首次到达正位置的分布，这是该领域的一个核心问题。

Method: 采用解析方法，针对步长取自有限整数集上的对称有限范围格点随机游走进行研究。

Result: 得到了该类随机游走首次到达正位置分布的详细分析结果。

Conclusion: 为理解对称有限范围格点随机游走的极端值统计提供了理论基础。

Abstract: The distribution of the first positive position reached by a random walker
starting at the origin is central to the analysis of extremes and records in
one-dimensional random walks. In this work, we present a detailed and
self-contained analytical study of this distribution for symmetric finite-range
lattice walks, whose steps are drawn from a distribution supported on finitely
many integers.

</details>


### [42] [Breakdown of hydrodynamics in a one-dimensional cold gas](https://arxiv.org/abs/2510.17428)
*Taras Holovatch,Yuri Kozitsky,Krzysztof Pilorz,Yurij Holovatch*

Main category: cond-mat.stat-mech

TL;DR: 研究了质量交替分布的粒子在弹性碰撞下的动力学行为，发现特定质量比下系统呈现不同的演化模式：某些情况下出现流体动力学行为，而在其他特定质量比下则表现为弹道运动且无溅射现象。


<details>
  <summary>Details</summary>
Motivation: 探索非均匀质量分布粒子系统在初始驱动下的集体动力学行为，特别是不同质量比对系统宏观演化的影响。

Method: 通过解析和数值方法研究一维半轴上交替质量粒子的弹性碰撞动力学，分析不同质量比和初始条件下的系统演化。

Result: 1. 当质量比m/μ取特定值时，系统呈现流体动力学行为：爆震前沿以t^δ（δ<1）运动，反冲粒子进入负半轴，溅射部分以弹道方式运动并最终吸收全部能量；2. 发现一组特殊质量比M_i，此时无溅射、最多三个粒子同时运动、爆震前沿为弹道运动；3. 在随机初始位置下，即使m/μ=M_i，系统仍呈现流体动力学行为。

Conclusion: 质量比和初始排列共同决定系统的宏观动力学行为，特定有序排列可导致非典型的局域化动力学，而无序初始条件恢复流体行为。

Abstract: The following model is studied analytically and numerically: point particles
with masses $m,\mu,m, \dots$ ($m\geq\mu$) are distributed over the positive
half-axis. Their dynamics is initiated by giving a positive velocity to the
particle located at the origin; in its course the particles undergo elastic
collisions. We show that, for certain values of $m/\mu$, starting from the
initial state where the particles are equidistant the system evolves in a
hydrodynamic way: (i) the rightmost particle (blast front) moves as
$t^{\delta}$ with $\delta < 1$; (ii) recoiled particles behind the front enter
the negative half-axis; (iii) the splatter -- the particles with locations
$x\leq 0$ -- moves in the ballistic way and eventually takes over the whole
energy of the system. These results agree with those obtained in S. Chakraborti
et al, SciPost Phys. 2022, 13, 074, for $m/\mu=2$ and random initial particle
positions. At the same time, we explicitly found the collection of positive
numbers $\{\mathcal{M}_i, i \in \mathbf{N} \}$ such that, for $m/\mu =
\mathcal{M}_i$, $i\leq 700$, the following holds: (a) the splatter is absent;
(b) the number of simultaneously moving particles is at most three; (c) the
blast front moves in the ballistic way. However, if, similarly as in S.
Chakraborti et al, the particle positions are sampled from a uniformly
distributed ensemble, for $m/\mu = \mathcal{M}_i$ the system evolves in a
hydrodynamic way.

</details>


### [43] [deGennes-Suzuki-Kubo Quantum Ising Mean Field Dynamics: Applications to Quantum Hysteresis, Heat Engines and Annealing](https://arxiv.org/abs/2510.17668)
*Soumyaditya Das,Soumyajyoti Biswas,Muktish Acharyya,Bikas K. Chakrabarti*

Main category: cond-mat.stat-mech

TL;DR: 本文回顾了合作相互作用的量子多体系统平均场动力学的早期发展，重点是伪自旋（Ising类）系统的映射。从BCS超导模型出发，通过平均场方法将其简化为横向场中的XY或Ising模型，并得到了基态能隙的温度依赖性结果。进一步引入de Gennes提出的经典合作分量与量子分量分解，结合Suzuki-Kubo动力学，构建了量子Ising系统的动力学扩展理论。该理论被应用于量子滞后、量子热机以及Sherrington-Kirkpatrick自旋玻璃的量子退火，表现出高效计算性能和理论一致性，验证了该平均场方法在研究量子凝聚态系统动力学中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了理解合作相互作用的量子多体系统中的集体行为，特别是超导和自旋系统的相变与动力学过程，需要发展有效的平均场理论框架。早期的BCS理论和Landau理论提供了静态描述，但缺乏对非平衡和动力学现象的刻画，因此有必要扩展平均场理论至动力学领域。

Method: 采用伪自旋映射将BCS超导哈密顿量转化为横向场中的XY/Ising模型；利用de Gennes提出的平均场分解方法，将平均场分为经典的纵向合作分量和量子横向分量；分别应用Suzuki-Kubo平均场动力学处理两个分量，构建完整的动力学理论框架。

Result: 成功推导出温度依赖的能隙行为，符合Landau的超流唯象理论；实现了对量子Ising磁体中滞后现象、量子热机性能及自旋玻璃量子退火过程的理论描述；在量子退火中实现了快速收敛至接近最优基态能量的计算结果。

Conclusion: de Gennes-Suzuki-Kubo平均场方程为研究量子凝聚态系统的多种动力学特性提供了一个有效且实用的理论工具，尤其在处理非平衡、周期驱动和优化问题中展现出强大能力。

Abstract: We briefly review the early development of the mean-field dynamics for
cooperatively interacting quantum many-body systems, mapped to pseudo-spin
(Ising-like) systems. We start with (Anderson, 1958) pseudo-spin mapping of the
BCS (1957) Hamiltonian of superconductivity, reducing it to a mean-field
Hamiltonian of XY (or effectively Ising) model in a transverse field. Then we
get the mean-field estimate for the equilibrium gap in the ground state energy
at different temperatures (gap disappearing at the transition temperature),
which fits Landau's (1949) phenomenological theory of superfluidity. We then
present in detail a general dynamical extension of the mean-field theory of
quantum Ising systems (in a transverse field), following de Gennes' (1963)
decomposition of the mean field into orthogonal classical cooperative
(longitudinal) component and the quantum (transverse) component, with each of
the components following Suzuki-Kubo (1968) mean-field dynamics. Next we
discuss its applications to quantum hysteresis in Ising magnets (in presence of
oscillating transverse field), to quantum heat engines (employing transverse
Ising model as working fluid), and to the quantum annealing of the
Sherrington-Kirkpatrick (1975) spin glass by tuning down (to zero) the
transverse field which provided us a very fast computational algorithm leading
to ground state energy values converging to the best known analytic estimate
for the model. Finally, we summarize the main results obtained and conclude
about the effectiveness of the de Gennes-Suzuki-Kubo mean-field equations for
the study of various dynamical aspects of quantum condensed matter systems.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [44] [Sharp comparisons between sliced and standard $1$-Wasserstein distances](https://arxiv.org/abs/2510.16465)
*Guillaume Carlier,Alessio Figalli,Quentin Mérigot,Yi Wang*

Main category: math.ST

TL;DR: 本文研究了切片1-Wasserstein距离与1-Wasserstein距离之间的定量估计，证明了估计中的指数是精确的，并将分析推广到投影到k维平面的情况。


<details>
  <summary>Details</summary>
Motivation: 基于切片Wasserstein距离在高维中计算效率高的实际应用，探讨其理论基础。

Method: 通过构造具体例子证明估计的指数的锐性，并对投影到k维平面的情况进行一般性分析。

Result: 得到了切片1-Wasserstein距离与1-Wasserstein距离之间的定量估计，并验证了估计的指数的锐性。

Conclusion: 切片Wasserstein距离在理论上具有良好的性质，且其估计在特定条件下是精确的。

Abstract: Sliced Wasserstein distances are widely used in practice as a computationally
efficient alternative to Wasserstein distances in high dimensions. In this
paper, motivated by theoretical foundations of this alternative, we prove
quantitative estimates between the sliced $1$-Wasserstein distance and the
$1$-Wasserstein distance. We construct a concrete example to demonstrate the
exponents in the estimate is sharp. We also provide a general analysis for the
case where slicing involves projections onto $k$-planes and not just lines.

</details>


### [45] [Spectral Thresholds in Correlated Spiked Models and Fundamental Limits of Partial Least Squares](https://arxiv.org/abs/2510.17561)
*Pierre Mergny,Lenka Zdeborová*

Main category: math.ST

TL;DR: 本文对部分对齐信号的高维数据通道下的尖峰交叉协方差模型进行了严格的随机矩阵理论分析，揭示了PLS方法在不同信噪比和相关性条件下的信号恢复能力极限，并指出了其与贝叶斯最优估计器之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 由于多模态学习的需求，Partial Least Squares (PLS) 虽被广泛使用但理论基础尚不完善，因此需要对其在高维数据下的信号恢复性能进行严格的理论分析。

Method: 采用随机矩阵理论分析尖峰交叉协方差模型，研究样本交叉协方差矩阵的最大奇异值的相变行为（BBP型相变），并确定信息成分出现的精确阈值。

Result: 发现PLS在某些信噪比和相关性条件下无法恢复信号，即使理论上信号是可检测的；首次给出了PLS在该设定下的尖锐渐近性能描述，并揭示了其与贝叶斯最优估计器之间的根本性能差距。

Conclusion: 研究阐明了PLS在高维多模态学习中的理论局限性，为设计更可靠的多模态推断方法提供了理论指导。

Abstract: We provide a rigorous random matrix theory analysis of spiked
cross-covariance models where the signals across two high-dimensional data
channels are partially aligned. These models are motivated by multi-modal
learning and form the standard generative setting underlying Partial Least
Squares (PLS), a widely used yet theoretically underdeveloped method. We show
that the leading singular values of the sample cross-covariance matrix undergo
a Baik-Ben Arous-Peche (BBP)-type phase transition, and we characterize the
precise thresholds for the emergence of informative components. Our results
yield the first sharp asymptotic description of the signal recovery
capabilities of PLS in this setting, revealing a fundamental performance gap
between PLS and the Bayes-optimal estimator. In particular, we identify the SNR
and correlation regimes where PLS fails to recover any signal, despite
detectability being possible in principle. These findings clarify the
theoretical limits of PLS and provide guidance for the design of reliable
multi-modal inference methods in high dimensions.

</details>


### [46] [Estimating location parameters of several exponential distributions with ordered restriction under Linex loss function](https://arxiv.org/abs/2510.16527)
*Shrajal Bajpai,Lakshmi Kanta Patra,Suchandan Kayal*

Main category: math.ST

TL;DR: 本文研究了在不对称Linex损失函数下，具有有序限制的多个指数分布位置参数的分量估计问题，考虑了尺度参数已知、相等和不等三种情况，提出了改进的估计量，并通过蒙特卡洛模拟验证了其风险值的显著改善。


<details>
  <summary>Details</summary>
Motivation: 由于两参数指数分布在生存分析、可靠性工程等领域的重要应用，且位置参数代表故障前的最小保证时间，因此在有序约束下对多个指数分布的位置参数进行有效估计具有实际意义。

Method: 在三种不同尺度参数假设下，建立了一般性的不可容许性结果，并证明了最佳仿射同变估计的不可容许性；构造了显式形式的改进估计量，并利用蒙特卡洛模拟比较各估计量的风险表现。

Result: 得到了位置参数在有序限制下的改进估计量，证明了传统估计方法的不可容许性，且数值结果显示新估计量在风险值上有显著提升。

Conclusion: 提出的改进估计量在多种情况下均优于传统估计方法，尤其在不对称损失下表现更优，且该方法可推广至II型删失、逐步删失和记录值等重要寿命试验模型。

Abstract: Some improved estimators of the location parameters of several exponential
distributions with ordered restriction are derived and compared numerically
using Monte Carlo simulations. Note that the two-parameter exponential
distribution is very useful in different areas like survival analysis,
reliability engineering and biomedical research, where products have a
guaranteed failure-free operating time before failures begin to occur. In the
present manuscript, we address the component-wise estimation of location
parameters of $k~(\ge 2)$ exponential distributions under an asymmetric Linex
loss function. The location parameter represents a minimum guaranteed period
before failure. At first, we consider the estimation of the location parameters
with ordered scale parameters. Next, we address the estimation of ordered
location parameters. For this, we take three different cases into account as
follows: $(i)$ scale parameters are known, $(ii)$ scale parameters are unknown
but equal, $(iii)$ scale parameters are unknown and unequal. In these cases, we
establish general inadmissibility results. Further, using the general result,
the inadmissibility of the best affine equivariant estimator is proved. The
improved estimators are written in explicit forms. Additionally, we show that
the results for several important life-testing schemes namely $(i)$ Type-II
censoring, $(ii)$ progressive type-II censoring and $(iii)$ record value data
can be obtained using i.i.d sample.Finally, for each case, the Monte Carlo
simulation technique is used to compare the performance of the proposed
estimators based on their risk values. The numerical results reveal a
significant improvement of the proposed estimators.

</details>


### [47] [On Robust hypothesis testing with respect to Hellinger distance](https://arxiv.org/abs/2510.16750)
*Eeshan Modak*

Main category: math.ST

TL;DR: 研究在样本可能不来自任一假设分布情况下的假设检验问题，提出测试对Hellinger距离的鲁棒性，并量化了真实分布需接近假设分布的程度，同时针对复合检验问题提出了新的检验方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统假设检验在模型误设时表现不佳的问题，确保检验方法在样本分布偏离原假设时仍能有效识别更接近的真实分布。

Method: 基于Hellinger距离分析分布间的接近程度，提出一种新的检验方法，并与广义似然比检验进行比较，适用于每个假设为围绕固定分布的Hellinger球的复合检验场景。

Result: 量化了真实分布需接近某一假设分布以保证检验有效的阈值条件，并提出了一种可替代广义似然比检验的新方法，在复合假设下具有良好的性能。

Conclusion: 所提出的检验方法在面对分布误设时具有鲁棒性，能够在合理条件下识别出更接近真实数据的假设，扩展了传统假设检验的应用范围。

Abstract: We study the hypothesis testing problem where the observed samples need not
come from either of the specified hypotheses (distributions). In such a
situation, we would like our test to be robust to this misspecification and
output the distribution closer in Hellinger distance. If the underlying
distribution is close to being equidistant from the hypotheses, then this would
not be possible. Our main result is quantifying how close the underlying
distribution has to be to either of the hypotheses. We also study the composite
testing problem, where each hypothesis is a Hellinger ball around a fixed
distribution. A generalized likelihood ratio test is known to work for this
problem. We give an alternate test for the same.

</details>


### [48] [Batch learning equals online learning in Bayesian supervised learning](https://arxiv.org/abs/2510.16892)
*Hông Vân Lê*

Main category: math.ST

TL;DR: 本文利用概率形态的范畴性质，证明了在条件独立数据下的贝叶斯监督学习模型中，Lê提出的序列贝叶斯反演与批量贝叶斯反演一致，并给出了后验预测分布的递归公式。文章还将Orbanz的结果推广到更一般的情形，并讨论了基于DDP先验的贝叶斯学习模型的后验计算。


<details>
  <summary>Details</summary>
Motivation: 旨在统一序列与批量贝叶斯反演的理论框架，并推广现有概率测度构造方法，以支持更广泛的贝叶斯监督学习模型分析与应用。

Method: 采用范畴论中概率形态的数学性质，结合投影系统构造概率测度，重新审视并扩展MacEachern的依赖狄利克雷过程（DDP），应用于高斯过程回归等模型。

Result: 证明了序列与批量贝叶斯反演的一致性；提出了后验预测分布的递归计算公式；将Orbanz关于单点集的结果推广到任意集合X与Polish空间Y的情形；给出了DDP先验下后验分布的计算方法。

Conclusion: 序列贝叶斯反演在条件独立数据下等价于批量反演，且可通过范畴论工具统一处理；所提出的递归公式和测度构造方法为贝叶斯非参数模型提供了更广泛的理论基础和计算支持。

Abstract: Using categorical properties of probabilistic morphisms, we prove that
sequential Bayesian inversions in Bayesian supervised learning models for
conditionally independent (possibly not identically distributed) data, proposed
by L\^e in \cite{Le2025}, coincide with batch Bayesian inversions. Based on
this result, we provide a recursive formula for posterior predictive
distributions in Bayesian supervised learning. We illustrate our results with
Gaussian process regressions. For Polish spaces $\mathcal{Y}$ and arbitrary
sets $\mathcal{X}$, we define probability measures on $\mathcal{P}
(\mathcal{Y})^{\mathcal X}$, using a projective system generated by
$\mathcal{Y}$ and $\mathcal{X}$. This is a generalization of a result by Orbanz
\cite{Orbanz2011} for the case $\mathcal{X}$ consisting of one point. We
revisit MacEacher's Dependent Dirichlet Processes (DDP) taking values on the
space $\mathcal{P} (\mathcal{Y})$ of all probability measures on a measurable
subset $\mathcal{Y}$ in $\mathbf{R}^n$, considered by Barrientos-Jara-Quintana
\cite{BJQ2012}. We indicate how to compute posterior distributions and
posterior predictive distributions of Bayesian supervised learning models with
DDP priors.

</details>


### [49] [Robust extrapolation problem for stochastic sequences with stationary increments](https://arxiv.org/abs/2510.16900)
*Maksym Luz,Mykhailo Moklyachuk*

Main category: math.ST

TL;DR: 本文研究了在时间点m=-1,-2,...观测到的具有平稳n阶增量的随机序列ξ(k)的未知值所依赖的泛函Aξ和ANξ的最优估计问题。当序列的谱密度已知时，推导出最优线性估计的均方误差和谱特性的计算公式；当谱密度未知但给定一组可接受的谱密度时，提出了最不利谱密度和最小最大（稳健）谱特性的确定公式。


<details>
  <summary>Details</summary>
Motivation: 解决具有平稳n阶增量的随机序列未知值的泛函最优估计问题，尤其是在谱密度已知或仅知其可接受集合的情况下。

Method: 基于在m=-1,-2,...处对序列ξ(m)的观察，利用谱密度信息推导最优线性估计的均方误差和谱特性，并针对未知谱密度情况提出最不利谱密度和最小最大估计方法。

Result: 得出了谱密度已知时最优线性估计的均方误差和谱特性的计算公式，以及谱密度未知时最不利谱密度和最小最大估计的确定公式。

Conclusion: 本文提供了针对不同谱密度信息条件下随机序列泛函最优估计的有效方法，增强了估计的鲁棒性。

Abstract: The problem of optimal estimation of functionals $A\xi
=\sum\nolimits_{k=0}^{\infty }{}a(k)\xi (k)$ and ${{A}_{N}}\xi
=\sum\nolimits_{k=0}^{N}{}a(k)\xi (k)$ which depend on the unknown values of
stochastic sequence $\xi (k)$ with stationary $n$th increments is considered.
Estimates are based on observations of the sequence $\xi (m)$ at points of time
$m=-1,-2,\ldots$. Formulas for calculating the value of the mean square error
and the spectral characteristic of the optimal linear estimates of the
functionals are derived in the case where spectral density of the sequence is
exactly known. Formulas that determine the least favorable spectral densities
and minimax (robust) spectral characteristic of the optimal linear estimates of
the functionals are proposed in the case where the spectral density of the
sequence is not known but a set of admissible spectral densities is given.

</details>


### [50] [On Minimax Estimation Problems for Periodically Correlated Stochastic Processes](https://arxiv.org/abs/2510.16906)
*Iryna Dubovets'ka,Mykhailo Moklyachuk*

Main category: math.ST

TL;DR: 本文研究了基于周期相关随机过程及其噪声观测的线性泛函的均方最优估计问题，给出了在谱确定和谱不确定条件下的最优线性估计的谱特征和均方误差计算公式，并提出了在给定允许谱密度集下的最不利谱密度和最小最大鲁棒估计。


<details>
  <summary>Details</summary>
Motivation: 解决周期相关随机过程中未知值的线性泛函在存在噪声情况下的最优估计问题，尤其是在谱信息不完全确定时的鲁棒估计需求。

Method: 在谱确定和谱不确定两种条件下，利用观测数据和噪声信息，推导最优线性估计的谱特征和均方误差公式，并应用最小最大准则确定最不利谱密度和鲁棒估计特性。

Result: 提出了计算最优线性估计的谱特征和均方误差的公式，并得出了在不同允许谱密度集合下的最不利谱密度及相应的最小最大鲁棒估计特性。

Conclusion: 该研究为周期相关随机过程的线性泛函提供了有效的均方最优估计方法，并在谱不确定性下实现了鲁棒估计，具有理论和应用价值。

Abstract: The aim of this article is to overview the problem of mean square optimal
estimation of linear functionals which depend on unknown values of periodically
correlated stochastic process. Estimates are based on observations of this
process and noise. These problems are investigated under conditions of spectral
certainty and spectral uncertainty. Formulas for calculating the main
characteristics (spectral characteristic, mean square error) of the optimal
linear estimates of the functionals are proposed. The least favorable spectral
densities and the minimax-robust spectral characteristics of optimal estimates
of the functionals are presented for given sets of admissible spectral
densities.

</details>


### [51] [Filtering Problem for Functionals of Stationary Processes with Missing Observations](https://arxiv.org/abs/2510.16908)
*Mykhailo Moklyachuk,Maria Sidei*

Main category: math.ST

TL;DR: 本文研究了在观测到受噪声干扰的平稳随机过程时，如何对依赖于未知过程值的线性泛函进行均方最优线性估计的问题。在谱密度精确已知的情况下，给出了最优估计的均方误差和谱特征计算公式；当谱密度不确定时，采用极小化极大（鲁棒）估计方法，并针对某些特定的可接受谱密度集合，提出了最不利谱密度和极小化极大谱特征的计算公式。


<details>
  <summary>Details</summary>
Motivation: 由于实际中常无法精确获知随机过程的谱密度，且观测常受噪声和数据缺失影响，本文旨在建立在谱不确定性下对随机过程线性泛函进行鲁棒估计的理论框架。

Method: 在谱确定性条件下使用传统最优滤波方法推导估计误差和谱特征；在谱不确定性条件下应用极小化极大估计理论，通过确定最不利谱密度来获得鲁棒估计器。

Result: 得到了谱确定情形下最优线性估计的显式计算公式；在多种可接受谱密度集合下，推导出了最不利谱密度和对应的极小化极大估计的谱特征。

Conclusion: 所提出的极小化极大估计方法能够在谱密度不完全已知的情况下提供鲁棒的线性估计，适用于存在观测缺失和噪声干扰的实际场景。

Abstract: The problem of the mean-square optimal linear estimation of the functional
$A\xi=\ \int\limits_{R^s}a(t)\xi(-t)dt,$ which depends on the unknown values of
stochastic stationary process $\xi(t)$ from observations of the process
$\xi(t)+\eta(t)$ at points $t\in\mathbb{R} ^{-} \backslash S $,
$S=\bigcup\limits_{l=1}^{s}[-M_{l}-N_{l}, \, \ldots, \, -M_{l} ],$
$R^s=[0,\infty) \backslash S^{+},$ $S^{+}=\bigcup\limits_{l=1}^{s}[ M_{l}, \,
\ldots, \, M_{l}+N_{l}]$ is considered. Formulas for calculating the
mean-square error and the spectral characteristic of the optimal linear
estimate of the functional are proposed under the condition of spectral
certainty, where spectral densities of the processes $\xi(t)$ and $\eta(t)$ are
exactly known. The minimax (robust) method of estimation is applied in the case
where spectral densities are not known exactly, but sets of admissible spectral
densities are given. Formulas that determine the least favorable spectral
densities and the minimax spectral characteristics are proposed for some
special sets of admissible spectral densities.

</details>


### [52] [A Unified Approach to Statistical Estimation Under Nonlinear Observations: Tensor Estimation and Matrix Factorization](https://arxiv.org/abs/2510.16965)
*Junren Chen,Lijun Ding,Dong Xia,Ming Yuan*

Main category: math.ST

TL;DR: 本文提出了一种统一的方法，通过构建数据梯度并建立受限近似可逆性条件（RAIC），为多种非线性观测模型下的参数估计问题提供了线性收敛保证，并在高斯设计下实现了多个张量和矩阵估计问题的最优统计结果。


<details>
  <summary>Details</summary>
Motivation: 针对非线性观测下位于锥形空间中的参数估计问题，现有方法缺乏统一的分析框架和最优收敛保证，因此需要发展一种通用且高效的分析工具。

Method: 首先从数据构造梯度，然后提出受限近似可逆性条件（RAIC）来衡量梯度与理想下降方向的对齐程度，并结合投影梯度下降、黎曼梯度下降和因子化梯度下降算法进行理论分析。

Result: 在高斯设计下，所提RAIC条件为单指数模型、广义线性模型、含噪相位恢复和一比特压缩感知等典型问题提供了 sharp 的分析结果，并首次实现了张量单指数模型、张量逻辑回归、局部含噪张量相位恢复和一比特张量感知的最小最大最优且计算高效的算法。

Conclusion: RAIC为多种非线性统计估计问题提供了统一的收敛性分析框架，所提出的算法在理论和实践上均达到最优性能，拓展了高维统计推断的适用范围。

Abstract: We consider the estimation of some parameter $\mathbf{x}$ living in a cone
from the nonlinear observations of the form
$\{y_i=f_i(\langle\mathbf{a}_i,\mathbf{x}\rangle)\}_{i=1}^m$. We develop a
unified approach that first constructs a gradient from the data and then
establishes the restricted approximate invertibility condition (RAIC), a
condition that quantifies how well the gradient aligns with the ideal descent
step. We show that RAIC yields linear convergence guarantees for the standard
projected gradient descent algorithm, a Riemannian gradient descent algorithm
for low Tucker-rank tensor estimation, and a factorized gradient descent
algorithm for asymmetric low-rank matrix estimation. Under Gaussian designs, we
establish sharp RAIC for the canonical statistical estimation problems of
single index models, generalized linear models, noisy phase retrieval, and
one-bit compressed sensing. Combining the convergence guarantees and the RAIC,
we obtain a set of optimal statistical estimation results, including, to our
knowledge, the first minimax-optimal and computationally efficient algorithms
for tensor single index models, tensor logistic regression, (local) noisy
tensor phase retrieval, and one-bit tensor sensing. Moreover, several other
results are new or match the best known guarantees. We also provide simulations
and a real-data experiment to illustrate the theoretical results.

</details>


### [53] [Composite Lp-quantile regression, near quantile regression and the oracle model selection theory](https://arxiv.org/abs/2510.17325)
*Fuming Lin*

Main category: math.ST

TL;DR: 本文提出了一种高维Lp分位数回归的新方法（CLpQR），在误差方差无限的情况下优于传统方法，具有高效率，并提出了近分位数回归及其渐近正态性，同时开发了高效的统一算法用于拟合高维Lp分位数回归。


<details>
  <summary>Details</summary>
Motivation: 为了克服绝对损失函数不可导和平方损失函数对误差方差有限的要求，研究仅需低阶矩条件的高维Lp分位数回归方法。

Method: 提出了复合Lp分位数回归（CLpQR）和近分位数回归方法，结合循环坐标下降和增广近端梯度算法开发了高效的统一算法。

Result: CLpQR在某些p值下比CQR更优，具有高效率；近分位数回归在p趋近于1且样本量趋于无穷时具有渐近正态性；所提算法是拟合分位数回归的有利替代方案。

Conclusion: Lp分位数回归在高维情况下表现优异，所提方法在效率和适用性上优于现有方法，且新算法为实际应用提供了高效工具。

Abstract: In this paper, we consider high-dimensional Lp-quantile regression which only
requires a low order moment of the error and is also a natural generalization
of the above methods and Lp-regression as well. The loss function of
Lp-quantile regression circumvents the non-differentiability of the absolute
loss function and the difficulty of the squares loss function requiring the
finiteness of error's variance and thus promises excellent properties of
Lp-quantile regression. Specifically, we first develop a new method called
composite Lp-quantile regression(CLpQR). We study the oracle model selection
theory based on CLpQR (call the estimator CLpQR-oracle) and show in some cases
of p CLpQR-oracle behaves better than CQR-oracle (based on composite quantile
regression) when error's variance is infinite. Moreover, CLpQR has high
efficiency and can be sometimes arbitrarily more efficient than both CQR and
the least squares regression. Second, we propose another new regression
method,i.e. near quantile regression and prove the asymptotic normality of the
estimator when p converges to 1 and the sample size infinity simultaneously. As
its applications, a new thought of smoothing quantile objective functions and a
new estimation are provided for the asymptotic covariance matrix of quantile
regression. Third, we develop a unified efficient algorithm for fitting
high-dimensional Lp-quantile regression by combining the cyclic coordinate
descent and an augmented proximal gradient algorithm. Remarkably, the algorithm
turns out to be a favourable alternative of the commonly used liner programming
and interior point algorithm when fitting quantile regression.

</details>


### [54] [A robust and scalable framework for high-dimensional volatility estimation](https://arxiv.org/abs/2510.17578)
*Kejun Chen,Yuchang Lin,Qianqian Zhu*

Main category: math.ST

TL;DR: 本文提出了一种针对BEKK-ARCH类高维波动率模型的鲁棒且计算高效的估计框架，采用数据截断和正则化最小二乘法，在重尾分布下实现高效优化，并建立了误差界和最优收敛率。


<details>
  <summary>Details</summary>
Motivation: 为了解决高维波动率模型在重尾分布下的估计难题，提升计算效率与鲁棒性。

Method: 利用BEKK-ARCH模型的等价VAR表示，结合数据截断和正则化最小二乘法进行估计，并提出稳健BIC和岭型估计器用于模型选择。

Result: 建立了非渐近误差界和最小最大最优收敛率，模拟研究和实证应用表明该方法在计算速度和预测精度上优于现有方法。

Conclusion: 所提出的框架在高维、重尾环境下具有良好的理论性质和实际表现，显著提升了波动率建模的效率与准确性。

Abstract: This paper introduces a robust and computationally efficient estimation
framework for high-dimensional volatility models in the BEKK-ARCH class. The
proposed approach employs data truncation to ensure robustness against
heavy-tailed distributions and utilizes a regularized least squares method for
efficient optimization in high-dimensional settings. This is achieved by
leveraging an equivalent VAR representation of the BEKK-ARCH model.
Non-asymptotic error bounds are established for the resulting estimators under
heavy-tailed regime, and the minimax optimal convergence rate is derived.
Moreover, a robust BIC and a Ridge-type estimator are introduced for selecting
the model order and the number of BEKK components, respectively, with their
selection consistency established under heavy-tailed settings. Simulation
studies demonstrate the finite-sample performance of the proposed method, and
two empirical applications illustrate its practical utility. The results show
that the new framework outperforms existing alternatives in both computational
speed and forecasting accuracy.

</details>


### [55] [Wild regenerative block bootstrap for Harris recurrent Markov chains](https://arxiv.org/abs/2510.17648)
*Kyuseong Choi,Gabriella Ciolek*

Main category: math.ST

TL;DR: 本文研究了在非Donsker情形下，对周期性Harris递归Markov链的加性泛函上确界的高斯和Bootstrap逼近，并利用Nummelin分裂技术建立了非渐近高斯逼近误差和有限样本下的Gaussian multiplier bootstrap方法，应用于扩散过程不变密度的一致置信带构造。


<details>
  <summary>Details</summary>
Motivation: 为了在函数类依赖样本量、经验过程可能无弱极限的非Donsker设定下，仍能对Markov链的加性泛函上确界进行有效的统计推断。

Method: 采用Nummelin分裂技术将Markov链分解为独立或一阶相依的随机块，结合高维向量求和的逼近理论，建立非渐近高斯逼近和Gaussian multiplier bootstrap方法。

Result: 得到了与高维独立或一阶相依向量相当的逼近速率；提出了具有有限样本保证的Bootstrap推断方法；成功应用于扩散过程不变密度的一致置信带构建。

Conclusion: Nummelin分裂技术为处理强a周期Markov链的非渐近推断提供了有效工具，所提Bootstrap方法在复杂依赖结构下具有良好的理论保证和应用前景。

Abstract: We consider Gaussian and bootstrap approximations for the supremum of
additive functionals of aperiodic Harris recurrent Markov chains. The supremum
is taken over a function class that may depend on the sample size, which allows
for non-Donsker settings; that is, the empirical process need not have a weak
limit in the space of bounded functions. We first establish a non-asymptotic
Gaussian approximation error, which holds at rates comparable to those for sums
of high-dimensional independent or one-dependent vectors. Key to our derivation
is the Nummelin splitting technique, which enables us to decompose the chain
into either independent or one-dependent random blocks. Additionally, building
upon the Nummelin splitting, we propose a Gaussian multiplier bootstrap for
practical inference and establish its finite-sample guarantees in the strongly
aperiodic case. Finally, we apply our bootstrap to construct a uniform
confidence band for an invariant density within a certain class of diffusion
processes.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [56] [Proactive and Fair Epidemic Resource Allocation Through an Integrated Supply Chain Framework: Insights from a COVID-19 Study](https://arxiv.org/abs/2510.16969)
*Kimiya Jozani,Nihal A. Sageer,Hode Eldardiry,Sait Tunc,Esra Buyuktahtakin Toy*

Main category: cs.SI

TL;DR: 提出了一种结合流行病学动态与多尺度疫苗供应链的新型优化框架，通过公平性和区域脆弱性建模，在美国COVID-19数据中验证可减少200万感染和3万死亡。


<details>
  <summary>Details</summary>
Motivation: 现有模型通常将疫情预测与物流规划分离，难以实现适应性强、区域响应及时的干预措施，因此需要集成化模型以支持跨空间尺度的协同决策。

Method: 构建了一个联合建模疫情传播与疫苗供应链的框架，包含时空变化的有效感染率；采用基于Gini的多目标模型和基于背包问题的区域脆弱性模型，并设计了受Benders分解启发的两种可扩展启发式算法。

Result: 在美国COVID-19数据上验证显示，六个月内可避免超过200万例感染和3万例死亡，显著提升弱势地区的疫苗可及性；引入SARIMA预测方法用于数据有限情况下的模型验证。

Conclusion: 将公平性、流行病动态与疫苗物流整合的框架优于传统短视政策，长期来看优先保护脆弱人群能提高整体效率和公共健康水平，为决策者提供可扩展且实用的工具。

Abstract: Timely and effective decision-making is critical during epidemics to reduce
preventable infections and deaths. This demands integrated models that jointly
capture disease dynamics, vaccine distribution, regional disparities, and
behavioral responses. However, most existing approaches decouple epidemic
forecasting from logistics planning, hindering adaptive and regionally
responsive interventions. We propose a novel epidemiological-optimization
framework that jointly models epidemic progression and a multiscale vaccine
supply chain. The model incorporates spatio-temporally varying effective
infection rates to reflect regional policy and behavioral dynamics. It supports
coordinated, data-driven decision-making across spatial scales through two
formulations: a multi-objective Gini-based model and a knapsack-based model
that leverages regional vulnerability indicators for tractability and improved
mitigation. To address computational complexity, we design two scalable
heuristic decomposition algorithms inspired by the Benders decomposition. The
model is validated using COVID-19 data in the U.S.. We introduce SARIMA-based
forecasting as a novel approach for validating epidemic-optimization models
under data limitations. The results show that our approach can prevent more
than 2 million infections and 30,000 deaths in just six months while
significantly improving the accessibility of vaccines in underserved regions.
Our framework demonstrates that integrating fairness and epidemic dynamics with
vaccine logistics leads to superior outcomes compared to traditional myopic
policies. Fairness improves overall efficiency in the long term by prioritizing
the most vulnerable populations, leading to better long-term public health
outcomes. The model offers policymakers a scalable and operationally relevant
tool to strengthen preparedness and ensure a more effective and equitable
response to epidemics.

</details>


### [57] [HyperSearch: Prediction of New Hyperedges through Unconstrained yet Efficient Search](https://arxiv.org/abs/2510.17153)
*Hyunjin Choo,Fanchen Bu,Hyunjin Hwang,Young-Gyu Yoon,Kijung Shin*

Main category: cs.SI

TL;DR: 本文提出了HyperSearch，一种基于搜索的超边预测算法，通过引入经验驱动的评分函数和高效的搜索机制，在真实世界超图数据上实现了比现有方法更高的预测准确率。


<details>
  <summary>Details</summary>
Motivation: 由于超边候选空间巨大，传统的穷举搜索不可行，现有方法依赖启发式采样或未经验证的结构假设，限制了预测性能，因此需要一种高效且准确的超边预测方法。

Method: 提出HyperSearch算法，包含两个核心组件：一是基于真实超图观测数据构建的经验评分函数；二是利用反单调性上界对非反单调的评分函数进行剪枝，从而实现高效搜索。

Result: 在五个领域共10个真实世界超图上的实验表明，HyperSearch在预测新超边方面 consistently 优于现有最先进基线方法。

Conclusion: HyperSearch通过理论保证的剪枝策略和经验驱动的评分函数，有效解决了超边预测中的计算挑战，在广泛的真实数据上表现出优越性能。

Abstract: Higher-order interactions (HOIs) in complex systems, such as scientific
collaborations, multi-protein complexes, and multi-user communications, are
commonly modeled as hypergraphs, where each hyperedge (i.e., a subset of nodes)
represents an HOI among the nodes. Given a hypergraph, hyperedge prediction
aims to identify hyperedges that are either missing or likely to form in the
future, and it has broad applications, including recommending interest-based
social groups, predicting collaborations, and uncovering functional complexes
in biological systems. However, the vast search space of hyperedge candidates
(i.e., all possible subsets of nodes) poses a significant computational
challenge, making naive exhaustive search infeasible. As a result, existing
approaches rely on either heuristic sampling to obtain constrained candidate
sets or ungrounded assumptions on hypergraph structure to select promising
hyperedges.
  In this work, we propose HyperSearch, a search-based algorithm for hyperedge
prediction that efficiently evaluates unconstrained candidate sets, by
incorporating two key components: (1) an empirically grounded scoring function
derived from observations in real-world hypergraphs and (2) an efficient search
mechanism, where we derive and use an anti-monotonic upper bound of the
original scoring function (which is not antimonotonic) to prune the search
space. This pruning comes with theoretical guarantees, ensuring that discarded
candidates are never better than the kept ones w.r.t. the original scoring
function. In extensive experiments on 10 real-world hypergraphs across five
domains, HyperSearch consistently outperforms state-of-the-art baselines,
achieving higher accuracy in predicting new (i.e., not in the training set)
hyperedges.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [58] [A Motivational Driver Steering Model: Task Difficulty Homeostasis From Control Theory Perspective](https://arxiv.org/abs/2510.16247)
*H. Mozaffari,A. Nahvi*

Main category: eess.SY

TL;DR: 本文提出了一种结合心理学理论与控制理论的驾驶员避碰行为模型，通过任务难度稳态理论与李雅普诺夫稳定性方法的融合，实现了对驾驶员转向行为的准确建模，并在多种速度下通过模拟实验验证了其有效性，平均误差仅为7%。


<details>
  <summary>Details</summary>
Motivation: 现有的计算驾驶员模型大多仅基于控制理论，缺乏心理学基础，难以真实反映人类驾驶行为。本文旨在建立一个更通用且符合心理机制的驾驶员避碰模型，以提升交通安全。

Method: 结合心理学中的“任务难度稳态理论”和控制理论中的“李雅普诺夫稳定性方法”，构建了一个统一的驾驶员转向行为模型，并通过驾驶模拟器实验和多速度场景下的仿真进行验证。

Result: 模型在20 km/h到170 km/h的不同速度下均表现出良好的避碰性能，仿真结果与人类驾驶行为高度一致，平均误差为7%。

Conclusion: 该融合心理学与控制理论的模型能够准确模拟人类驾驶员的避碰转向行为，具有较高的心理合理性和应用潜力，有助于提升智能驾驶系统的真实性与安全性。

Abstract: A general and psychologically plausible collision avoidance driver model can
improve transportation safety significantly. Most computational driver models
found in the literature have used control theory methods only, and they are not
established based on psychological theories. In this paper, a unified approach
is presented based on concepts taken from psychology and control theory. The
"task difficulty homeostasis theory", a prominent motivational theory, is
combined with the "Lyapunov stability method" in control theory to present a
general and psychologically plausible model. This approach is used to model
driver steering behavior for collision avoidance. The performance of this model
is measured by simulation of two collision avoidance scenarios at a wide range
of speeds from 20 km/h to 170 km/h. The model is validated by experiments on a
driving simulator. The results demonstrate that the model follows human
behavior accurately with a mean error of 7 percent.

</details>


### [59] [Supervisory Control of Hybrid Power Plants Using Online Feedback Optimization: Designs and Validations with a Hybrid Co-Simulation Engine](https://arxiv.org/abs/2510.16352)
*Sayak Mukherjee,Himanshu Sharma,Wenceslao Shaw Cortez,Genevieve Starke,Michael Sinner,Brooke J. Stanislawski,Zachary Tully,Paul Fleming,Sonja Glavaski*

Main category: eess.SY

TL;DR: 本文提出了一种基于反馈优化的混合电厂监督控制器设计方法，通过在线调整风能、太阳能和储能系统的有功功率参考值，实现对电网功率需求的响应，并在存在天气不确定性的情况下保持鲁棒控制性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对混合电厂中可再生能源出力的不确定性，并在无需精确模型的情况下实现对电网功率需求的实时响应，需要一种不依赖详细系统模型的控制策略。

Method: 采用基于梯度信息的反馈优化方法，在线更新控制输入，利用成本函数和输出对控制指令的梯度来调整风能、太阳能和储能系统的有功功率输出。同时构建了面向控制的组件模型，并将控制器集成到Hercules混合电厂协同仿真平台中进行验证。

Result: 所提出的监督反馈优化控制器能够在不确定天气条件下有效协调混合电厂各组成部分，满足电网调度的功率需求，并在更真实的仿真环境中验证了其有效性。

Conclusion: 反馈优化是一种适用于混合可再生能源电厂的有效监督控制方法，具有不依赖精确模型、适应性强和鲁棒性好的优点，具备在实际系统中应用的潜力。

Abstract: This research investigates designing a supervisory feedback controller for a
hybrid power plant that coordinates the wind, solar, and battery energy storage
plants to meet the desired power demands. We have explored an online feedback
control design that does not require detailed knowledge about the models, known
as feedback optimization. The control inputs are updated using the gradient
information of the cost and the outputs with respect to the input control
commands. This enables us to adjust the active power references of wind, solar,
and storage plants to meet the power generation requirements set by grid
operators. The methodology also ensures robust control performance in the
presence of uncertainties in the weather. In this paper, we focus on describing
the supervisory feedback optimization formulation and control-oriented modeling
for individual renewable and storage components of the hybrid power plant. The
proposed supervisory control has been integrated with the hybrid plant
co-simulation engine, Hercules, demonstrating its effectiveness in more
realistic simulation scenarios.

</details>


### [60] [Real-time Measurement-based Optimization for Distribution System Operation Considering Battery Voltage and Thermal Constraints](https://arxiv.org/abs/2510.16408)
*Sen Zhan,Lingkang Jin,Haoyang Zhang,Nikolaos G. Paterakis*

Main category: eess.SY

TL;DR: 本文提出了一种基于实时测量数据的电池储能运行控制方案，利用李雅普诺夫优化实现无需预测、计算复杂度低的实时控制，有效保障配电系统的安全运行。


<details>
  <summary>Details</summary>
Motivation: 由于分布式能源的大量接入，配电网的安全运行面临挑战。传统措施如发电限电会导致能量损失，而电池储能的灵活性提供了一种更经济的解决方案。然而，不准确的电网模型、负荷数据缺失、非线性关系和储能复杂的动态特性使得储能运行建模困难。

Method: 提出一种数据驱动的电池储能控制方法，基于实时测量数据构建线性和凸二次运行约束，并采用李雅普诺夫优化方法解耦多时段储能运行问题，实现无需预测的实时控制。

Result: 通过非线性配电网和电池储能仿真器进行数值实验，验证了该方法在保障系统安全运行、满足电压和电池热约束方面的有效性。

Conclusion: 所提数据驱动的实时控制策略能够有效应对配电网中电池储能运行的多重挑战，具有较低的计算复杂度和良好的实用性。

Abstract: The secure operation of power distribution systems is challenged by the
growing integration of distributed energy resources. Leveraging the flexibility
of battery storage offers a cost-effective alternative to measures like
generation curtailment, which results in energy losses. However, developing an
effective operational model for battery storage is hindered by inaccurate grid
models, unavailability of load data, nonlinear relationship between power
injections and network states, intertemporal constraints, and complex
electrochemical and thermal dynamics. To address these challenges, this paper
proposes a data-driven operational control scheme for battery storage in
distribution systems. Linear and convex quadratic operational constraints are
constructed based on real-time distribution system and battery storage
measurements. Lyapunov optimization decouples multi-period battery operation,
enabling a real-time, forecast-free control strategy with low computational
complexity. Numerical studies using nonlinear distribution system and battery
storage simulators validate the effectiveness of the approach in ensuring
secure distribution system operation and satisfaction of voltage and thermal
constraints of battery storage.

</details>


### [61] [Stabilization of Nonlinear Systems with State-Dependent Representation: From Model-Based to Direct Data-Driven Control](https://arxiv.org/abs/2510.16451)
*Lidong Li,Rui Huang,Lin Zhao*

Main category: eess.SY

TL;DR: 本文提出了一种基于状态依赖参数变化模型的新框架，用于稳定非线性系统，并通过数据驱动方法在无需显式建模的情况下实现稳定性、鲁棒性和安全性保证。


<details>
  <summary>Details</summary>
Motivation: 为了在存在输入饱和和噪声数据的情况下，对非线性系统提供严格的稳定性与鲁棒性保证，避免传统模型辨识的复杂性。

Method: 将非线性动态重构成状态依赖参数变化模型，利用线性矩阵不等式（LMI）离线设计控制器；在数据驱动场景下，结合Petersen引理推导出依赖数据的LMI以保证兼容系统的稳定性。

Result: 所提方法能够估计吸引域，保证局部指数稳定性和抗扰鲁棒性，并通过数值与物理实验验证了从有限数据直接获得的端到端稳定性与安全性。

Conclusion: 该框架成功实现了无需显式模型辨识的非线性系统控制，为基于数据的控制系统设计提供了具有理论保证的有效途径。

Abstract: This paper presents a novel framework for stabilizing nonlinear systems
represented in state-dependent form. We first reformulate the nonlinear
dynamics as a state-dependent parameter-varying model and synthesize a
stabilizing controller offline via tractable linear matrix inequalities (LMIs).
The resulting controller guarantees local exponential stability, maintains
robustness against disturbances, and provides an estimate of the region of
attraction under input saturation. We then extend the formulation to the direct
data-driven setting, where a known library of basis functions represents the
dynamics with unknown coefficients consistent with noisy experimental data. By
leveraging Petersen's lemma, we derive data-dependent LMIs that ensure
stability and robustness for all systems compatible with the data. Numerical
and physical experimental results validate that our approach achieves rigorous
end-to-end guarantees on stability, robustness, and safety directly from finite
data without explicit model identification.

</details>


### [62] [SMP-RCR: A Sparse Multipoint Moment Matching Method for RC Reduction](https://arxiv.org/abs/2510.16550)
*Siyuan Yin,Yuncheng Xu,Lin Liu,Fan Yang,Xuan Zeng,Chengtao An,Yangfeng Su*

Main category: eess.SY

TL;DR: 本文提出了一种用于多端口RC电路的稀疏多点矩匹配模型降阶方法，兼具高精度和高效率，在高频点的精度比SIP方法提高两个数量级以上，且速度比TurboMOR快两倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有高阶矩匹配方法在端口数较多时生成的降阶系统过于稠密，影响效率；而基于高斯消元的SIP等方法高阶矩匹配不足，精度有限。因此需要一种兼顾精度与效率的新型MOR方法。

Method: 提出一种稀疏多点矩匹配方法，并引入稀疏控制和 deflate 技术优化算法效率；同时对多频点高阶矩匹配特性进行了系统的理论分析。

Result: 数值实验表明，与SIP相比，新方法在不显著增加线性元件的情况下，高频点精度提升超过两个数量级；与TurboMOR相比，在保持相同精度的同时，速度提升两倍以上。

Conclusion: 所提出的稀疏多点矩匹配方法在精度和效率之间实现了良好平衡，适用于大规模多端口RC电路的高效模型降阶。

Abstract: In post--layout circuit simulation, efficient model order reduction (MOR) for
many--port resistor--capacitor (RC) circuits remains a crucial issue. The
current mainstream MOR methods for such circuits include high--order moment
matching methods and elimination methods. High-order moment matching
methods--characterized by high accuracy, such as PRIMA and TurboMOR--tend to
generate large dense reduced-order systems when the number of ports is large,
which impairs the efficiency of MOR. Another common type of MOR method for
many--port circuits is based on Gaussian elimination, with the SIP method as a
representative. The main limitation of this method lies in the inadequate
matching of high--order moments. In this paper, we propose a sparse multipoint
moment matching method and present comprehensive theoretical analysis results
regarding the multi--frequency high--order moment matching property. Meanwhile,
to enhance the algorithm's efficiency, sparse control and deflation techniques
are introduced to further optimize the algorithm. Numerical experiments
demonstrated that, compared to SIP, the accuracy is improved by more than two
orders of magnitude at high frequency points without adding many extra linear
components. Compared to TurboMOR methods, our method achieves a speed
improvement of more than twice while maintaining the same level of precision.

</details>


### [63] [Linear State Estimation in Presence of Bounded Uncertainties: A Comparative Analysis](https://arxiv.org/abs/2510.16693)
*Ayan Das,Anushka Sharma,Anamitra Pal*

Main category: eess.SY

TL;DR: 本文研究了在数据和模型存在有界不确定性的情况下，电力系统线性状态估计的三种算法：基于区间算术、凸优化和广义线性分式规划。实验表明前两种方法快速且结果可靠，第三种存在可扩展性问题，不适合线性状态估计。


<details>
  <summary>Details</summary>
Motivation: 由于电力系统中线路参数的实际值可能与数据库中的值不同，模型扰动会影响状态估计的准确性，因此需要研究在模型和数据均存在不确定性时的鲁棒估计方法。

Method: 提出了三种处理有界不确定性的方法：区间算术法、凸优化法和广义线性分式规划法，并在多个IEEE测试系统上进行验证与比较。

Result: 区间算术和凸优化方法计算速度快、结果符合预期，而广义线性分式规划方法存在可扩展性问题，不适用于线性状态估计。

Conclusion: 在考虑模型和数据不确定性时，基于区间算术和凸优化的方法更适合于电力系统线性状态估计，具有良好的实用性和效率。

Abstract: A variety of algorithms have been proposed to address the power system state
estimation problem in the presence of uncertainties in the data. However, less
emphasis has been given to handling perturbations in the model. In the context
of linear state estimation (LSE), which is the focus of this paper,
perturbations in the model come from variations in the line parameters. Since
the actual values of the line parameters can be different from the values
stored in a power utility's database, we investigate three approaches in this
paper to estimate the states in the presence of bounded uncertainties in the
data and the model. The first approach is based on interval arithmetic, the
second is based on convex optimization, and the third is based on generalized
linear fractional programming. The three algorithms are applied to multiple
IEEE test systems and compared in terms of their speed and accuracy. The
results indicate that the first two algorithms are extremely fast and give
expected results, while the third suffers from scalability issues and is
unsuitable for LSE.

</details>


### [64] [A Control-Theoretic Approach to Dynamic Payment Routing for Success Rate Optimization](https://arxiv.org/abs/2510.16735)
*Aniket Agrawal,Harsharanga Patil*

Main category: eess.SY

TL;DR: 本文提出了一种基于控制理论的动态支付路由框架，通过反馈机制和自适应决策提升交易成功率。


<details>
  <summary>Details</summary>
Motivation: 为了提高支付系统的交易成功率和运行韧性，解决传统规则路由在动态环境中的局限性。

Method: 将路由系统建模为闭环反馈控制器，结合控制理论、强化学习与多臂赌博机优化，实现基于性能偏差的动态调整。

Result: 在生产环境中实现了最高1.15%的成功率提升，优于传统基于规则的路由方法。

Conclusion: 该混合框架有效融合了控制理论与自适应决策，实现了稳定、可靠的自调节支付路由。

Abstract: This paper introduces a control-theoretic framework for dynamic payment
routing, implemented within JUSPAY's Payment Orchestrator to maximize
transaction success rate. The routing system is modeled as a closed-loop
feedback controller continuously sensing gateway performance, computing
corrective actions, and dynamically routes transactions across gateway to
ensure operational resilience. The system leverages concepts from control
theory, reinforcement learning, and multi-armed bandit optimization to achieve
both short-term responsiveness and long-term stability. Rather than relying on
explicit PID regulation, the framework applies generalized feedback-based
adaptation, ensuring that corrective actions remain proportional to observed
performance deviations and the computed gateway score gradually converges
toward the success rate. This hybrid approach unifies control theory and
adaptive decision systems, enabling self-regulating transaction routing that
dampens instability, and improves reliability. Live production results show an
improvement of up to 1.15% in success rate over traditional rule-based routing,
demonstrating the effectiveness of feedback-based control in payment systems.

</details>


### [65] [Safe Payload Transfer with Ship-Mounted Cranes: A Robust Model Predictive Control Approach](https://arxiv.org/abs/2510.16953)
*Ersin Das,William A. Welch,Patrick Spieler,Keenan Albee,Aurelio Noca,Jeffrey Edlund,Jonathan Becktor,Thomas Touma,Jessica Todd,Sriramya Bhamidipati,Stella Kombo,Maira Saboia,Anna Sabel,Grace Lim,Rohan Thakker,Amir Rahmani,Joel W. Burdick*

Main category: eess.SY

TL;DR: 提出了一种基于鲁棒零阶控制屏障函数（R-ZOCBF）的安全模型预测控制框架，用于船舶起重机在复杂海况下的安全实时控制，通过实验验证了其在扰动环境下的有效性。


<details>
  <summary>Details</summary>
Motivation: 船舶起重机在恶劣海况下受到显著外部扰动，传统控制方法难以兼顾安全性与操作性能，需开发更鲁棒的安全控制策略。

Method: 采用非线性模型预测控制（MPC），结合鲁棒零阶控制屏障函数（R-ZOCBF）和时变边界框实现安全约束与避障，并引入基于优化的在线鲁棒参数自适应机制以降低保守性。

Result: 在5自由度起重机原型上实验验证，所提方法能在显著基座扰动下实现安全、准确的负载转移，并有效避免碰撞。

Conclusion: 该框架有效提升了船舶起重机在动态扰动环境中的安全性与操作性能，且方法可推广至机器人辅助装配等其他安全关键任务。

Abstract: Ensuring safe real-time control of ship-mounted cranes in unstructured
transportation environments requires handling multiple safety constraints while
maintaining effective payload transfer performance. Unlike traditional crane
systems, ship-mounted cranes are consistently subjected to significant external
disturbances affecting underactuated crane dynamics due to the ship's dynamic
motion response to harsh sea conditions, which can lead to robustness issues.
To tackle these challenges, we propose a robust and safe model predictive
control (MPC) framework and demonstrate it on a 5-DOF crane system, where a
Stewart platform simulates the external disturbances that ocean surface motions
would have on the supporting ship. The crane payload transfer operation must
avoid obstacles and accurately place the payload within a designated target
area. We use a robust zero-order control barrier function (R-ZOCBF)-based
safety constraint in the nonlinear MPC to ensure safe payload positioning,
while time-varying bounding boxes are utilized for collision avoidance. We
introduce a new optimization-based online robustness parameter adaptation
scheme to reduce the conservativeness of R-ZOCBFs. Experimental trials on a
crane prototype demonstrate the overall performance of our safe control
approach under significant perturbing motions of the crane base. While our
focus is on crane-facilitated transfer, the methods more generally apply to
safe robotically-assisted parts mating and parts insertion.

</details>


### [66] [Semantic Intelligence: A Bio-Inspired Cognitive Framework for Embodied Agents](https://arxiv.org/abs/2510.17129)
*Wenbing Tang,Meilin Zhu,Fenghua Wu,Yang Liu*

Main category: eess.SY

TL;DR: 本文提出了一种语义智能驱动的具身智能体框架（SIDE），通过结合分层语义认知架构和语义驱动的决策过程，提升智能体在非结构化真实环境中的语义理解与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有具身智能体在非结构化真实环境中表现受限，主要由于缺乏足够的语义智能来理解和推理复杂任务。因此，需要构建具备更强语义认知能力的智能体框架。

Method: 提出SIDE框架，融合受生物认知机制启发的分层语义认知架构与语义驱动决策机制，模拟人类和动物整合与处理感官信息的方式，实现对物理环境的情境自适应推理与交互。

Result: 该框架增强了智能体在复杂环境中的语义理解与任务推理能力，为开发更智能、更通用的具身智能体提供了可行路径。

Conclusion: SIDE框架通过引入生物启发的语义认知结构，有效提升了具身智能体的语义智能水平，是迈向更高级智能体的重要一步。

Abstract: Recent advancements in Large Language Models (LLMs) have greatly enhanced
natural language understanding and content generation. However, these models
primarily operate in disembodied digital environments and lack interaction with
the physical world. To address this limitation, Embodied Artificial
Intelligence (EAI) has emerged, focusing on agents that can perceive and
interact with their surroundings. Despite progress, current embodied agents
face challenges in unstructured real-world environments due to insufficient
semantic intelligence, which is critical for understanding and reasoning about
complex tasks. This paper introduces the Semantic Intelligence-Driven Embodied
(SIDE) agent framework, which integrates a hierarchical semantic cognition
architecture with a semantic-driven decision-making process. This enables
agents to reason about and interact with the physical world in a contextually
adaptive manner. The framework is inspired by biological cognitive mechanisms
and utilizes bio-inspired principles to design a semantic cognitive
architecture that mimics how humans and animals integrate and process sensory
information. We present this framework as a step toward developing more
intelligent and versatile embodied agents.

</details>


### [67] [Enhanced Ground-Satellite Direct Access via Onboard Rydberg Atomic Quantum Receivers](https://arxiv.org/abs/2510.17290)
*Qihao Peng,Tierui Gong,Zihang Song,Qu Luo,Zihuai Lin,Pei Xiao,Chau Yuen*

Main category: eess.SY

TL;DR: 本文提出了一种用于6G星地链路的里德堡原子量子接收机（RAQR），该微型前端通过原子电磁诱导透明效应将射频信号转换为光信号，具备高灵敏度和高频率选择性，可有效应对传统射频前端在链路预算、载荷限制和干扰方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 为解决6G星地链路中严重路径损耗、严苛的尺寸-重量-功率限制以及频谱拥塞等问题，亟需新型高性能、小型化的接收前端技术。

Method: 提出基于里德堡原子电磁诱导透明效应的量子接收机（RAQR），采用混合原子-电子设计，并建立相应的信号模型，实现射频到光信号的转换。

Result: RAQR在灵敏度、频率选择性、数据速率、覆盖范围和感知精度方面均优于传统射频接收机，且满足卫星系统的空间与功耗约束。

Conclusion: RAQR为下一代卫星通信提供了有前景的前端解决方案，未来需研究其集成策略、分布式卫星架构及关键科学问题以推动实际应用。

Abstract: Ground-satellite links for 6G networks face critical challenges, including
severe path loss, tight size-weight-power limits, and congested spectrum, all
of which significantly hinder the performance of traditional radio frequency
(RF) front ends. This article introduces the Rydberg Atomic Quantum Receiver
(RAQR) for onboard satellite systems, a millimeter-scale front end that
converts radio fields to optical signals through atomic electromagnetically
induced transparency. RAQR's high sensitivity and high frequency selectivity
address link budget, payload, and interference challenges while fitting within
space constraints. A hybrid atomic-electronic design and supporting signal
model demonstrate enhanced data rate, coverage, and sensing accuracy relative
to conventional RF receivers. The article concludes with integration
strategies, distributed-satellite concepts, and open research problems for
bringing RAQR-enabled satellite payloads into service.

</details>


### [68] [Comparison and performance analysis of dynamic encrypted control approaches](https://arxiv.org/abs/2510.17333)
*Sebastian Schlor,Frank Allgöwer*

Main category: eess.SY

TL;DR: 本文回顾了动态加密控制的最新方法，并对其稳定性与性能进行了分析，同时通过基准系统上的数值性能比较进行了补充。


<details>
  <summary>Details</summary>
Motivation: 解决动态控制器加密过程中因编码噪声和溢出问题带来的挑战，确保系统在保证隐私的同时稳定运行。

Method: 回顾并分析了包括自举、控制器状态周期性重置、整数重构和FIR控制器在内的多种动态加密控制方法，并进行了稳定性与性能评估。

Result: 提供了各种动态加密控制方法在稳定性、性能和适用性方面的系统性评估，并通过数值实验进行了验证。

Conclusion: 不同动态加密控制方法各有优劣，需根据具体应用场景权衡选择；本文为实际部署提供了理论支持和实践指导。

Abstract: Encrypted controllers using homomorphic encryption have proven to guarantee
the privacy of measurement and control signals, as well as system and
controller parameters, while regulating the system as intended. However,
encrypting dynamic controllers has remained a challenge due to growing noise
and overflow issues in the encoding. In this paper, we review recent approaches
to dynamic encrypted control, such as bootstrapping, periodic resets of the
controller state, integer reformulations, and FIR controllers, and equip them
with a stability and performance analysis to evaluate their suitability. We
complement the analysis with a numerical performance comparison on a benchmark
system.

</details>


### [69] [Accelerating Adaptive Systems via Normalized Parameter Estimation Laws](https://arxiv.org/abs/2510.17371)
*Mohammad Boveiri,Mohammad Khosravi,Peyman Mohajerin Esfahan*

Main category: eess.SY

TL;DR: 本文提出了一类新的参数估计律——归一化参数估计律，可加速系统状态收敛至原点，并保证系统状态的r次根平方范数的有限可积性，具有更强的收敛性能和适用性。


<details>
  <summary>Details</summary>
Motivation: 为了提升自适应系统中参数估计的收敛速度，克服传统李雅普诺夫方法仅能保证平方范数可积的局限，本文提出归一化参数估计律，通过增强对长时间慢衰减信号的惩罚，促进更快收敛。

Method: 设计归一化参数估计律，使其保证系统状态的\(\|x(t)\|_2^{2/r}\)在\(\mathcal{L}_1\)空间中可积（\(r \geq 1\)），并通过引入动量构造高阶估计律；该方法不依赖时变增益、高增益或持续激励条件，适用于存在匹配与不匹配不确定性的系统，且兼容任何基于控制李雅普诺夫函数（CLF）的确定性等价控制器。

Result: 理论分析表明所提方法在广泛系统中可实现更高的收敛性能；数值实验验证了其在加速状态收敛、提升瞬态性能方面的有效性，尤其在大\(r\)值下表现出更强的稀疏促进特性。

Conclusion: 归一化参数估计律为自适应控制提供了一种无需高增益或持续激励、通用且高效的参数估计新框架，显著提升了系统状态的收敛速度和性能。

Abstract: In this paper, we propose a new class of parameter estimation laws for
adaptive systems, called \emph{normalized parameter estimation laws}. A key
feature of these estimation laws is that they accelerate the convergence of the
system state, $\mathit{x(t)}$, to the origin. We quantify this improvement by
showing that our estimation laws guarantee finite integrability of the
$\mathit{r}$-th root of the squared norm of the system state, i.e., \(
\mathit{\|x(t)\|}_2^{2/\mathit{r}} \in \mathcal{L}_1, \) where $\mathit{r} \geq
1$ is a pre-specified parameter that, for a broad class of systems, can be
chosen arbitrarily large. In contrast, standard Lyapunov-based estimation laws
only guarantee integrability of $\mathit{\|x(t)\|}_2^2$ (i.e., $\mathit{r} =
1$). We motivate our method by showing that, for large values of $r$, this
guarantee serves as a sparsity-promoting mechanism in the time domain, meaning
that it penalizes prolonged signal duration and slow decay, thereby promoting
faster convergence of $\mathit{x(t)}$. The proposed estimation laws do not rely
on time-varying or high adaptation gains and do not require persistent
excitation. Moreover, they can be applied to systems with matched and unmatched
uncertainties, regardless of their dynamic structure, as long as a control
Lyapunov function (CLF) exists. Finally, they are compatible with any CLF-based
certainty equivalence controllers. We further develop higher-order extensions
of our estimation laws by incorporating momentum into the estimation dynamics.
We illustrate the performance improvements achieved with the proposed scheme
through various numerical experiments.

</details>


### [70] [Artificial magnetic conductor backed dual-mode sectoral cylindrical DRA for off-body biomedical telemetry](https://arxiv.org/abs/2510.17619)
*Nayab Gogosh,Sohail Khalid,Bilal Tariq Malik,Slawomir Koziel*

Main category: eess.SY

TL;DR: 本研究提出了一种用于生物医学遥测的双模扇形介质谐振天线（CDRA），通过EH110和TE210模式操作克服了传统CDRA带宽窄和尺寸大的问题，结合人工磁导体（AMC）降低比吸收率（SAR），实现了7.9 dBi的峰值增益和1.24 W/kg的SAR，适用于可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 传统CDRA因带宽有限和体积较大，难以应用于可穿戴生物医学设备，因此需要一种小型化、宽带且低SAR的天线设计。

Method: 采用扇形CDRA结构并引入完美电导边界，将尺寸缩小四倍；利用EH110和TE210双模操作拓宽带宽；在天线背面集成人工磁导体（AMC）以抑制表面波并降低SAR。

Result: 天线工作在5.2–5.9 GHz频段，带宽达0.7 GHz，实测峰值增益为7.9 dBi，在人体手臂模型上的SAR值为1.24 W/kg，满足安全标准。

Conclusion: 所提出的双模扇形CDRA结合AMC结构在保持高性能的同时实现了小型化和低SAR，适合用于可穿戴生物医学遥测系统。

Abstract: This research investigates the potential of a sectoral Cylindrical Dielectric
Resonator Antenna (CDRA) for biomedical telemetry. CDRAs are known for their
low loss, ruggedness, and stability, but their limited bandwidth and size make
them unsuitable for wearable devices. The research addresses these limitations
by proposing a dual mode antenna that operates in EH110 and TE210 modes. The
sectoral CDRA is a quarter segment with Perfect Electric Conductor boundaries,
reducing its size by a factor of four. Mathematical derivations of the field
components for both modes are derived to support the design. To minimize
specific absorption rate (SAR), an Artificial Magnetic Conductor (AMC) surface
is applied to the antennas backside, enhancing compatibility with the
transverse electric modes. The antenna achieves a bandwidth of 0.7 GHz (5.2-5.9
GHz), suitable for biomedical applications, with a measured peak gain of 7.9
dBi and a SAR of 1.24 W/kg when applied to a human arm.

</details>


### [71] [Data-driven Communication and Control Design for Distributed Frequency Regulation with Black-box Inverters](https://arxiv.org/abs/2510.17769)
*Michael Nestor,Jiaxin Wang,Ning Zhang,Fei Teng*

Main category: eess.SY

TL;DR: 本文提出了一种基于分布式数据驱动的二次频率控制方法，利用逆变器间的对等通信实现无需中央控制的协同控制，并通过通信拓扑设计框架在通信需求与控制性能之间实现权衡，验证了在IEEE 39节点系统上的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着基于逆变器的资源越来越多地接入电网，传统频率控制方法面临挑战，尤其是缺乏透明模型和集中控制依赖的问题，因此需要一种兼顾动态行为与通信能力的新型二次频率控制方法。

Method: 提出一种分布式数据驱动控制方法，设计基于对等通信的通信拓扑结构，并构建与通信拓扑一致的控制器，在闭环系统中保证稳定性。

Result: 在IEEE 39节点系统上的案例研究表明，该方法能有效实现频率调节，并展示了通信开销与控制性能之间的权衡关系。

Conclusion: 所提出的框架能够通过合理的通信拓扑设计，在不依赖中央控制器的情况下实现高效、稳定的二次频率控制，为未来高比例逆变器接入电网提供了可行解决方案。

Abstract: The increasing penetration of inverter-based resources into the power grid,
with often only black-box models available, challenges long-standing frequency
control methods. Most recent works take a decentralized approach without online
device coordination via communication. This paper considers both dynamic
behavior and communication within secondary frequency control on an
intermediate timescale. We develop a distributed data-driven approach that
utilizes peer-to-peer communication between inverters to avoid the need for a
central control center. To enable a trade off between communication network
requirements and control performance, we present a framework to guide
communication topology design for secondary frequency regulation. Following
design of the inter-agent information exchange scheme, we design a controller
that is structured according to the communication topology with a closed-loop
stability guarantee. Case studies on the IEEE 39-bus system validate the
framework and illustrate the trade-off between communication requirements and
control performance that is enabled by our approach.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [72] [Optimal transport by a Lagrangian dynamics of population distribution](https://arxiv.org/abs/2510.17193)
*Babak Benam,Abolfazl Ramezanpour*

Main category: cond-mat.dis-nn

TL;DR: 本研究提出了一种基于拉格朗日动力学模型的人类移动性分析方法，利用局部人口函数作为坐标变量，通过梯度下降算法优化参数，有效捕捉了合成与实证移动数据的动力学特征。


<details>
  <summary>Details</summary>
Motivation: 人类移动性对城市功能至关重要，理解其在不同尺度下的动态行为有助于揭示城市系统的自适应与自组织机制。因此，需要建立一个可解释且能生成人类移动模式的动力学模型。

Method: 构建以局部人口函数为坐标变量的拉格朗日动力学模型，引入高效的梯度下降算法来最小化局部误差函数，从而估计最优拉格朗日参数，并使用合成与真实移动数据验证模型性能。

Result: 即使采用包含耗散项的二次拉格朗日函数，也能有效拟合移动数据；惯性和耗散效应具有相近的重要性，而交互作用和随机性会显著改变模型参数。

Conclusion: 该模型为人类移动性提供了可解释且具备生成能力的框架，在移动预测等方面具有潜在应用价值。

Abstract: Human mobility, enabled by diverse transportation modes, is fundamental to
urban functionality. Studying these movements across scales-from microscopic to
macroscopic-yields valuable insights into urban dynamics. Local adaptation and
(self-)organization in such systems are expected to result in dynamical
behaviors that are represented by stationary trajectories of an appropriate
effective action. In this study we develop a Lagrangian dynamical model for
movement processes, using local population functions as the coordinate
variables. An efficient gradient descent algorithm is introduced to estimate
the optimal Lagrangian parameters minimizing a local error function of the
dynamical process. We show that even a quadratic Lagrangian, incorporating
dissipation, effectively captures the dynamics of synthetic and empirical
movement data. The inferred models reveal that inertia and dissipation are of
comparable importance, while interactions and randomness in the movements
induce significant qualitative changes in model parameters. Our results provide
an interpretable and generative model for human mobility, with potential
applications in movement prediction.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [73] [Finite temperature magnetic interactions from first principles](https://arxiv.org/abs/2510.16143)
*Ravi Kaushik,Ryota Ono,Sergey Artyukhin*

Main category: cond-mat.str-el

TL;DR: 提出了一种从第一性原理计算有限温度下磁交换相互作用的方法，仅需两次超胞计算，揭示了键角和带隙变化是影响交换作用的主要因素。


<details>
  <summary>Details</summary>
Motivation: 缺乏高效的第一性原理方法来计算有限温度下磁交换相互作用，而室温磁性对应用至关重要。

Method: 基于密度泛函理论，通过两次超胞计算，结合金属-配体杂化、 Hubbard 排斥、带隙、原子间距和键角等因素，计算有限温度下的磁交换相互作用。

Result: 键角和带隙的变化是影响磁交换的主要机制；在NiO中，180度键角导致交换作用随温度升高而降低；在Cr₂O₃中，偏离180度的键角使交换作用在室温下增加10%。

Conclusion: 该方法高效且准确，可用于研究温度依赖的磁交换机制，有助于理解并设计室温磁性材料。

Abstract: Density functional theory has demonstrated remarkable predictive power in
calculating magnetic properties at zero temperature. At finite temperatures,
thermally excited phonons may affect magnetism. Efficient ab-initio methods to
calculate the temperature dependence of magnetic exchange interactions are
still lacking despite the importance of room temperature magnetism for
applications. Exchange is controlled by an interplay between metal-ligand
hybridization, Hubbard repulsion, band gap, interatomic distances and bond
angles, all of which change with temperature. Here we present a method to
calculate the exchange interactions at finite temperatures from first
principles using only two supercell calculations and quantify these mechanisms.
Changes in bond angles and the band gap are identified as a primary factors. In
NiO with 180-degree bonds exchange decreases with temperature, while in
Cr$_2$O$_3$ with the bond angles away from 180 degrees the exchange increases
by 10% at room temperature.

</details>


### [74] [Cavity-induced coherent magnetization and polaritons in altermagnets](https://arxiv.org/abs/2510.16248)
*Mohsen Yarmohammadi,Libor Šmejkal,James K. Freericks*

Main category: cond-mat.str-el

TL;DR: 通过将二维d波反铁磁材料置于驱动光学腔中，可诱导出有限且可调的磁化，实现对反铁磁材料的腔控磁化，适用于自旋电子学应用。


<details>
  <summary>Details</summary>
Motivation: 探索如何在无净磁化的反铁磁材料中实现可控磁化，拓展其在自旋电子学中的应用潜力。

Method: 利用相干光子驱动与电子亚晶格选择性耦合，结合平均场Lindblad分析研究稳态下的自旋不平衡和极化激元特征。

Result: 实现了在d波反铁磁材料中诱导出可调谐的有限磁化，发现二次耦合占主导地位，并在强耦合 regime 下观察到明显的极化激元信号。

Conclusion: 光学腔可以有效控制反铁磁材料的磁化状态，为自旋电子学器件提供了新的调控手段。

Abstract: Altermagnets feature antiparallel spin sublattices with $d$-, $g$-, or
$i$-wave spin order, yielding nonrelativistic spin splitting without net
magnetization. We show that embedding a two-dimensional $d$-wave altermagnet in
a driven optical cavity induces a finite, tunable magnetization. Coherent
photon driving couples selectively to electronic sublattices, and the resulting
altermagnets' symmetry-broken spin texture yields a pronounced steady-state
spin imbalance -- coherent magnetization -- absent in conventional
antiferromagnets for the same lattice configuration. A mean-field Lindblad
analysis reveals the dominance of quadratic over linear couplings. In the
strong-coupling regime, distinct polariton signatures emerge in the steady
state of induced magnetization. This work demonstrates cavity control of
altermagnets for spintronic applications.

</details>


### [75] [Photoinduced melting dynamics and collective mode in a correlated charge-order system](https://arxiv.org/abs/2510.16855)
*Yasuhiro Tanaka,Hitoshi Seo*

Main category: cond-mat.str-el

TL;DR: 研究了光诱导下电荷序融化过程中的瞬态谱函数，发现泵浦光频率对瞬态谱特性有显著影响，共振时出现隙内权重并导致电荷序失稳，与高能激发导致的能隙收缩机制不同。


<details>
  <summary>Details</summary>
Motivation: 揭示不同初始激发下相关电子系统中电荷序融化的动力学过程。

Method: 采用一维相互作用无自旋费米子模型，引入脉冲激光，结合哈特里-福克近似和精确对角化方法求解含时薛定谔方程。

Result: 发现当泵浦光频率与集体相位模共振时，瞬态谱出现明显的隙内权重，随激光强度增加导致电荷隙坍塌；而当泵浦光频率高于电荷隙时，主要引发带间激发导致能隙收缩。

Conclusion: 光诱导电荷序失稳的机制强烈依赖于泵浦光频率，共振激发通过隙内模式触发显著响应，不同于高能激发的机制。

Abstract: We theoretically investigate the transient spectral function during the
photoinduced melting of charge order in a correlated electron system, to
unravel the dynamical processes triggered by different initial excitations. We
employ a one-dimensional interacting spinless fermion model introducing a
pulsed laser light, and perform a comparative study by the Hartree-Fock
approximation and by the exact diagonalization method to numerically solve the
time-dependent Schr\"odinger equation. We find characteristic behavior in the
transient spectral function, whose features strongly depend on the pump light
frequency $\omega_p$. When $\omega_p$ is resonant with the collective phase
mode of frequency $\Omega_c\simeq \Delta_{\rm CO}/2$, where $\Delta_{\rm CO}$
is the charge gap, the transient spectral function exhibits a photoinduced
in-gap weight which triggers large responses. With increasing the laser
intensity, the development of in-gap weight directly turns into the collapse of
the gap. This charge-order destabilization process is in sharp contrast to the
case of $\omega_p>\Delta_{\rm CO}$, where the photoirradiation induces
interband electron-hole excitations giving rise to a shrinkage of the gap. The
impact of quantum fluctuations and spatial inhomogeneity on the photoinduced
dynamics is also discussed.

</details>


### [76] [Temperature Dependence of the Momentum-Resolved Static Spin Susceptibility in a Mott-Proximate Cuprate Model](https://arxiv.org/abs/2510.16884)
*Keishichiro Tanaka*

Main category: cond-mat.str-el

TL;DR: 本文研究了高温超导铜氧化物模型中静态自旋 susceptibility 在 $(\pi, \pi)$ 和 $(\pi, 0)$ 处的温度依赖性，发现其起始温度与超导临界温度 $T_c$ 相关，并揭示了反节点伪能隙对低能自旋响应和粒子-空穴激发的抑制作用，从而有利于 $d$-波配对。


<details>
  <summary>Details</summary>
Motivation: 理解高温超导体中自旋响应与超导机制之间的关系，特别是伪能隙在调控低能激发和促进 $d$-波配对中的作用。

Method: 基于接近Mott绝缘态且具有反节点伪能隙的铜氧化物模型，计算并分析不同电子填充下的静态自旋 susceptibility 随温度的变化。

Result: 静态自旋 susceptibility 的 onset 温度与 $T_c$ 具有相似尺度并随之变化；当化学势接近反节点van Hove区域时，$(\pi, 0)$ 处的 susceptibility 显著增强；超导出现伴随着反节点低能自旋响应和粒子-空穴激发的抑制。

Conclusion: 伪能隙通过抑制反节点附近的低频粒子-空穴相空间，减少对 $d$-波配对的去相干效应，从而在高温超导中起到关键调控作用。

Abstract: This paper presents the temperature dependence of the static spin
susceptibility at $\mathbf{q} = (\pi, \pi)$ and $\mathbf{q} = (\pi, 0)$ in a
Mott-proximate cuprate model with an antinodal pseudogap -- a model system for
high-temperature superconducting (HTSC) cuprates.
  The results show the susceptibility onset temperature tracks the critical
temperature ($T_c$) of HTSCs with a comparable scale across the electron
filling factor. Also, as the electron filling decreases and the chemical
potential approaches the antinodal van Hove region, the susceptibility at
$\mathbf{q}=(\pi,0)$ -- the axial particle-hole response -- grows markedly.
  The emergence of cuprate superconductivity correlates with a suppression of
low-energy antinodal spin response and associated particle-hole excitations,
which would otherwise dephase $d$-wave pairing, commonly attributed to spin
fluctuations. In this context, the pseudogap partially suppresses antinodal
spectral weight near $\omega = 0$, thereby reducing the low-$\omega$
particle-hole phase space.

</details>


### [77] [Magnon edge states of skyrmion crystal in non-uniform magnetic field](https://arxiv.org/abs/2510.16970)
*V. E. Timofeev,D. N. Aristov*

Main category: cond-mat.str-el

TL;DR: 在具有Dzyaloshinskii-Moriya相互作用的薄铁磁薄膜中，磁斯格明子晶格是较宽外磁场范围内的基态。随着磁场增加，斯格明子晶格的磁子谱可能发生拓扑转变，非均匀磁场可在斯格明子晶格界面处诱导出局域化的边缘态。本文通过半经典量子化和球极投影方法，结合能带结构计算与扩展狄拉克方程的有效模型，研究了这些边缘态的性质，发现其手性和局域化程度由磁场分布调控，局域长度可短至几个斯格明子间距。


<details>
  <summary>Details</summary>
Motivation: 探索斯格明子晶体中磁子边缘态的形成机制及其调控方式，为拓扑磁子学和低能耗信息器件提供理论基础。

Method: 采用半经典量子化和球极投影方法，结合完整的能带结构计算与基于扩展狄拉克方程的有效模型，分析斯格明子晶格中的边缘态。

Result: 揭示了外磁场调控下斯格明子晶格中磁子边缘态的手性与局域化特性，局域长度可小至数个斯格明子间距。

Conclusion: 磁场分布可有效调控斯格明子晶格中磁子边缘态的性质，为实现拓扑保护的磁子输运提供了可行路径。

Abstract: A regular lattice of magnetic skyrmions is the ground state of thin
ferromagnetic films with Dzyaloshinskii-Moriya interaction in a relatively wide
range of external magnetic fields. It was previously theoretically shown that
upon the increase of magnetic field a topological transition in the magnon
spectrum of such skyrmion crystal (SkX) may occur. Non-uniform magnetic field
may lead to localized magnon states emerging at the interface between two
half-planes of SkX. Using semiclassical quantization and the stereographic
projection approach, we study such appearing edge states both in a full band
structure calculation and in simplified effective model. The latter effective
model described by extended Dirac equation is applicable to two relevant magnon
bands near $\Gamma$ point. We show that both the chirality of emerging edge
states and the degree of its localization at the interface is controlled by
magnetic field profile. We demonstrate that the localization length may be as
small as a few inter-skyrmion distances.

</details>


### [78] [High-Field Torque Magnetometry on the Kagome Antiferromagnet Karpenkoite](https://arxiv.org/abs/2510.17050)
*Hibiki Kunisawa,Ryuya Watanabe,Jun-ichi Yamaura,Yoshimitsu Kohama,Toshihiro Nomura*

Main category: cond-mat.str-el

TL;DR: 在karpenkoite单晶中通过扭矩磁强计研究其作为kagome反铁磁模型候选材料的性质，发现在高达45 T的磁场下未观测到相变，而是出现持续的自旋重取向，可能由主导的Dzyaloshinskii-Moriya相互作用引起。


<details>
  <summary>Details</summary>
Motivation: 研究karpenkoite作为kagome反铁磁体模型候选材料的磁场响应行为，探索其是否存在场致相变及自旋结构演化机制。

Method: 采用扭矩磁强计技术对单晶样品在高达45 T的磁场下进行测量，分别针对B||c和B||a方向。

Result: 在B||c和B||a方向均未检测到场致相变，但观察到扭矩信号显示自旋持续重取向直至饱和，表明可能存在显著的Dzyaloshinskii-Moriya相互作用。

Conclusion: karpenkoite在强磁场下表现出连续的自旋重取向而非相变，其行为可能由Dzyaloshinskii-Moriya相互作用主导，支持其作为kagome反铁磁体系的研究价值。

Abstract: We report torque magnetometry results on single crystals of karpenkoite
Co3(V2O7)(OH)2 2H2O, a model candidate for the kagome antiferromagnet. No
field-induced phase transition is detected up to 45 T for B||c and B||a.
Instead, the torque reveals a continuous spin reorientation toward saturation,
most likely governed by a dominant Dzyaloshinskii-Moriya interaction.

</details>


### [79] [Mott vs Kondo: Influence of Various Density Functional Based Methods on the Ce Isostructural Phase Transition Mechanism](https://arxiv.org/abs/2510.17755)
*Brenden W. Hamilton,Alexander R. Muñoz,Travis E. Jones,Benjamin T. Nebgen*

Main category: cond-mat.str-el

TL;DR: 本文研究了铈的γ到α相变过程中的f电子局域化变化，通过不同密度泛函方法（GGA、MetaGGA和杂化泛函）在零开尔文下对等静压压缩进行广泛比较，评估这些方法在再现实验结果方面的表现，并探讨相变机制与Mott/Kondo理论之争的关系。


<details>
  <summary>Details</summary>
Motivation: 铈的γ到α相变涉及f电子局域化、磁序变化和体积坍塌，传统第一性原理方法难以准确描述这些物理现象。本文旨在系统评估多种密度泛函方法在捕捉该相变关键物理特征方面的能力。

Method: 采用三种理论层级和不同类型泛函（GGA、MetaGGA、杂化泛函）的密度泛函理论方法，对零温下沿相变边界的等静压压缩过程进行广泛计算与比较。

Result: 识别出能较好再现实验结果的计算方法，并基于这些方法深入分析预测的相变机制，特别是在Mott与Kondo物理图像之间的区分能力。

Conclusion: 不同泛函对相变驱动机制的描述存在显著差异，研究揭示了各方法在处理f电子局域化和关联效应方面的假设与局限，为理解铈相变的主导动力学提供了新视角。

Abstract: The cerium iso-structural phase transition (gamma to alpha) is dominated by
f-electron localization changes that results in a magnetic ordering change and
a volume collapse. Generally, these physics are difficult to capture with ab
initio and first principles methods. However, previous works have shown various
methods to be successful in predicting at least some of the physics of the
gamma to alpha phase transition. Therefore, here, we perform a broad survey of
density functional based methods across three levels of theory and types of
functions (GGA, MetaGGA, and Hybrid functionals) and compare the results,
focusing on hydrostatic compression across the phase boundary at zero Kelvin.
For the methods that best reproduce experimental results, we directly probe the
predicted mechanisms and frame the results in the Mott/Kondo debate, assessing
how the underlying methods and assumptions of different functionals can assess
the physical drivers in the phase transition, providing insight into the
governing dynamics of this unique phase transition.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [80] [Fitting an Escalier to a Curve](https://arxiv.org/abs/2510.16148)
*Sebastien Bossu,Andrew Papanicolaou,Nour El Hatto*

Main category: math.OC

TL;DR: 本文研究了在L^2空间中用多阶跃函数拟合曲线的问题，提出了一种两阶段优化方法，并证明了在正则条件下收敛速度为线性，同时设计了可恢复全局最优拟合的简单算法。


<details>
  <summary>Details</summary>
Motivation: 为了在L^2 Hilbert空间中更有效地拟合阶梯函数，解决传统方法在确定阶跃位置时的优化难题。

Method: 采用两阶段优化方法：首先固定阶跃位置，转化为闭式解的经典线性最小二乘问题；然后允许阶跃位置变化，通过递归求解一阶条件。

Result: 在满足正则条件下，当阶跃数n趋于无穷时，收敛速度为线性；基于扫描搜索的数值实验显示该算法在速度和精度方面表现良好。

Conclusion: 所提出的两阶段优化方法能有效拟合多阶跃函数，具备理论收敛性保证和良好的数值性能，适用于全局最优拟合的求解。

Abstract: We analyze the problem of fitting a fonction en escalier or multi-step
function to a curve in L^2 Hilbert space. We propose a two-stage optimization
approach whereby the step positions are initially fixed, corresponding to a
classic linear least-squares problem with closed-form solution, and then are
allowed to vary, leading to first-order conditions that can be solved
recursively. We find that, subject to regularity conditions, the speed of
convergence is linear as the number of steps $n$ goes to infinity, and we
develop a simple algorithm to recover the global optimum fit. Our numerical
results based on a sweep search implementation show promising performance in
terms of speed and accuracy.

</details>


### [81] [Agent-Based Optimal Control for Image Processing](https://arxiv.org/abs/2510.16154)
*Alessio Oliviero,Simone Cacace,Giuseppe Visconti*

Main category: math.OC

TL;DR: 本文提出了一种基于多智能体系统的图像处理方法，通过最优控制框架实现颜色量化和图像分割，结合全变分与图像保真度的平衡，并采用 primal-dual 分裂和乘子法求解，CUDA 并行实验验证了方法在高维数据上的有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在探索多智能体系统在经典图像处理任务中的应用潜力，提供一种新颖的基于动力学控制的图像分割方法。

Method: 将图像处理任务建模为最优控制问题，通过调节颜色场的总变分和对原始图像的保真度，利用 primal-dual 分裂和乘子法求解多智能体系统的演化动力学。

Result: 数值实验表明该方法能有效实现图像的颜色聚类与分割，且在 CUDA 并行环境下表现出良好的计算效率和扩展性。

Conclusion: 所提出的方法为图像处理提供了一种新的基于多智能体控制的视角，具有处理高维数据的潜力，适用于复杂图像分析任务。

Abstract: We investigate the use of multi-agent systems to solve classical image
processing tasks, such as colour quantization and segmentation. We frame the
task as an optimal control problem, where the objective is to steer the
multi-agent dynamics to obtain colour clusters that segment the image. To do
so, we balance the total variation of the colour field and fidelity to the
original image. The solution is obtained resorting to primal-dual splitting and
the method of multipliers. Numerical experiments, implemented in parallel with
CUDA, demonstrate the efficacy of the approach and its potential for
high-dimensional data.

</details>


### [82] [Conformal Prediction in The Loop: A Feedback-Based Uncertainty Model for Trajectory Optimization](https://arxiv.org/abs/2510.16376)
*Han Wang,Chao Ning*

Main category: math.OC

TL;DR: 本文提出了一种基于反馈的共形预测（Fb-CP）框架，用于带联合风险约束的收缩时域轨迹优化，通过利用已实现轨迹动态调整预测区域，在保证覆盖性的同时提升轨迹性能。


<details>
  <summary>Details</summary>
Motivation: 现有共形预测方法在决策过程中缺乏反馈机制，无法利用实际执行轨迹的信息来优化预测，限制了其在不确定环境下的轨迹优化性能。

Method: 提出Fb-CP框架，通过构建基于共形预测的后验风险计算方法，利用已实现轨迹调整后验可允许风险，并将其分配至未来时段以更新预测区域，实现预测与决策的闭环反馈；同时设计了面向决策的迭代风险分配算法，并扩展至处理分布偏移场景。

Result: 所提方法在保证预测区域覆盖性的同时，实现了轨迹性能的在线提升，实验表明其在基准测试中优于现有方法，且具备处理分布偏移的能力。

Conclusion: Fb-CP框架通过引入反馈机制，实现了共形预测与决策过程的协同优化，在理论和实验上均验证了其在安全性、性能提升和适应性方面的优势。

Abstract: Conformal Prediction (CP) is a powerful statistical machine learning tool to
construct uncertainty sets with coverage guarantees, which has fueled its
extensive adoption in generating prediction regions for decision-making tasks,
e.g., Trajectory Optimization (TO) in uncertain environments. However, existing
methods predominantly employ a sequential scheme, where decisions rely
unidirectionally on the prediction regions, and consequently the information
from decision-making fails to be fed back to instruct CP. In this paper, we
propose a novel Feedback-Based CP (Fb-CP) framework for shrinking-horizon TO
with a joint risk constraint over the entire mission time. Specifically, a
CP-based posterior risk calculation method is developed by fully leveraging the
realized trajectories to adjust the posterior allowable risk, which is then
allocated to future times to update prediction regions. In this way, the
information in the realized trajectories is continuously fed back to the CP,
enabling attractive feedback-based adjustments of the prediction regions and a
provable online improvement in trajectory performance. Furthermore, we
theoretically prove that such adjustments consistently maintain the coverage
guarantees of the prediction regions, thereby ensuring provable safety.
Additionally, we develop a decision-focused iterative risk allocation algorithm
with theoretical convergence analysis for allocating the posterior allowable
risk which closely aligns with Fb-CP. Furthermore, we extend the proposed
method to handle distribution shift. The effectiveness and superiority of the
proposed method are demonstrated through benchmark experiments.

</details>


### [83] [A Simple First-Order Algorithm for Full-Rank Equality Constrained Optimization](https://arxiv.org/abs/2510.16390)
*Serge Gratton,Philippe L. Toint*

Main category: math.OC

TL;DR: 提出了一种简单的自适应一阶算法，用于求解带有非线性等式约束的优化问题，无需目标函数评估，具有与无约束问题最优速率匹配的全局收敛性。


<details>
  <summary>Details</summary>
Motivation: 解决带确定性非线性等式约束的非线性优化问题，尤其在目标函数不可靠或含噪声时，避免使用传统的罚函数或滤波方法。

Method: 算法自适应选择切平面步（基于AdaGrad）或减小不可行性的步，不依赖目标函数值，仅利用约束和梯度信息进行优化。

Result: 理论分析表明算法具有O(1/sqrt{k})的全局收敛速率，数值实验显示其性能接近无约束一阶方法，且在梯度含噪情况下表现出强鲁棒性。

Conclusion: 该算法为约束优化提供了一种简单、高效且抗噪的一阶方法，适用于目标函数难以准确评估的实际场景。

Abstract: A very simple first-order algorithm is proposed for solving nonlinear
optimization problems with deterministic nonlinear equality constraints. This
algorithm adaptively selects steps in the plane tangent to the constraints or
steps that reduce infeasibility, without using a merit function or filter. The
tangent steps are based on the AdaGrad method for unconstrained minimization.
The objective function is never evaluated by the algorithm, making it suitable
for noisy problems. Its worst-case evaluation complexity is analyzed, yielding
a global convergence rate in O(1/sqrt{k}), which matches the best known rate of
first-order methods for unconstrained problems. Numerical experiments are
presented suggesting that the performance of the algorithm is comparable to
that of first-order methods for unconstrained problems, and that its
reliability is remarkably stable in the presence of noise on the gradient.

</details>


### [84] [Charnes--Cooper transformation and fractional optimization with SOS-convex polynomials](https://arxiv.org/abs/2510.16400)
*Chengmiao Yang,Liguo Jiao,Jae Hyoung Lee*

Main category: math.OC

TL;DR: 本文提出了一种基于Charnes-Cooper变换的无参数方法，用于求解一类具有SOS-凸多项式的分式规划问题，并在一定条件下建立了解的存在性、强对偶性和解提取的理论结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决一类具有SOS-convex多项式的分式规划问题，现有方法可能依赖参数或缺乏理论保证，因此需要一种无参数且具有严格理论支持的求解方案。

Method: 采用基于Charnes-Cooper变换的参数-free方法，结合凸优化理论，在满足特定条件下分析解的存在性、强对偶性及解的提取方法。

Result: 建立了分式规划问题解的存在性定理、强对偶性定理和解提取方法，并通过一个示例验证了所提方法的有效性和理论结果。

Conclusion: 所提出的无参数方法在适当条件下能够有效求解一类SOS-convex分式规划问题，且具有坚实的理论基础和应用潜力。

Abstract: This paper proposes a parameter-free scheme that is based on the
Charnes--Cooper transformation for solving a class of fractional programs with
SOS-convex polynomials. Under certain conditions, we establish theorems of
solution existence,strong duality and solution extraction. An illustrative
example is designed to show the obtained results.

</details>


### [85] [Frank-Wolfe Algorithms for (L0, L1)-smooth functions](https://arxiv.org/abs/2510.16468)
*A. A. Vyguzov,F. S. Stonyakin*

Main category: math.OC

TL;DR: 提出了一种新的(L0, L1)-Frank-Wolfe算法，用于优化具有(L0, L1)-光滑目标的问题，并设计了自适应版本以动态调整光滑参数，理论和实验均表明其优于经典Frank-Wolfe方法。


<details>
  <summary>Details</summary>
Motivation: 为了提升经典Frank-Wolfe方法在(L0, L1)-光滑目标优化问题中的收敛速度和稳定性。

Method: 提出了(L0, L1)-Frank-Wolfe算法及其自适应变体，通过理论分析证明其收敛性，并通过数值实验验证性能。

Result: 新算法在理论上具有更优的收敛速率，自适应版本进一步提升了性能和稳定性，实验结果验证了其优越性。

Conclusion: 所提出的(L0, L1)-Frank-Wolfe算法及其自适应版本在理论和实践中均优于现有Frank-Wolfe方法。

Abstract: We propose a new version of the Frank-Wolfe method, called the (L0,
L1)-Frank-Wolfe algorithm, developed for optimization problems with (L0,
L1)-smooth objectives. We establish that this algorithm achieves superior
theoretical convergence rates compared to the classical Frank-Wolfe method. In
addition, we introduce a novel adaptive procedure, termed the Adaptive (L0,
L1)-Frank-Wolfe algorithm, which dynamically adjusts the smoothness parameters
to further improve performance and stability. Comprehensive numerical
experiments confirm the theoretical results and demonstrate the clear practical
advantages of both proposed algorithms over existing Frank-Wolfe variants.

</details>


### [86] [On the convergence rate of the boosted Difference-of-Convex Algorithm (DCA)](https://arxiv.org/abs/2510.16569)
*Hadi Abbaszadehpeivasti,Etienne de Klerk,Adrien Taylor*

Main category: math.OC

TL;DR: 本文研究了无约束差分凸算法（DCA）及其增强版本在最坏情况下的性能，利用半定规划性能估计方法证明了在某些DC分解下，增强DCA优于传统DCA。


<details>
  <summary>Details</summary>
Motivation: 尽管已有数值研究表明增强DCA优于传统DCA，但尚缺乏理论解释。本文旨在从理论上分析增强DCA为何在最坏情况下表现更优。

Method: 采用半定规划（SDP）性能估计方法，对带有和不带有增强步骤的DCA进行最坏情况性能分析。

Result: 证明了对于特定类别的DC分解，增强DCA在最坏情况下的性能严格优于传统DCA。

Conclusion: 增强DCA在理论上有更优的最坏情况性能，为其实证优势提供了首个理论依据。

Abstract: The difference-of-convex algorithm (DCA) is a well-established nonlinear
programming technique that solves successive convex optimization problems.
These sub-problems are obtained from the difference-of-convex~(DC)
decompositions of the objective and constraint functions. We investigate the
worst-case performance of the unconstrained DCA, with and without boosting,
where boosting simply performs an additional step in the direction generated by
the usual DCA method. We show that, for certain classes of DC decompositions,
the boosted DCA is provably better in the worst-case than the usual DCA. While
several numerical studies have reported that boosted DCA outperforms classical
DCA, a theoretical explanation for this behavior has, to the best of our
knowledge, not been given until now. Our proof technique relies on semidefinite
programming (SDP) performance estimation.

</details>


### [87] [A class of singular control problems with tipping points](https://arxiv.org/abs/2510.16599)
*Jean-Paul Décamps,Fabien Gensbittel,Thomas Mariotti,Stéphane Villeneuve*

Main category: math.OC

TL;DR: 本文研究了一个性能准则依赖于随机水平首次到达时间的奇异随机控制问题，并建立了该问题与扩散过程及其运行最小值相关的奇异控制问题之间的联系，提出了验证定理并应用于资源开采问题的显式求解。


<details>
  <summary>Details</summary>
Motivation: 研究系统在跨越临界点后发生突变的情况下的最优控制策略，特别是在资源开采等实际应用中如何应对不可逆变化。

Method: 通过建立原问题与带有扩散过程及其运行最小值的奇异控制问题之间的联系，使用动态规划和验证定理的方法进行分析。

Result: 证明了验证定理的有效性，并成功应用于一个具体的资源开采模型，得到了显式解。

Conclusion: 该方法能够有效处理涉及非停时随机水平的奇异控制问题，为存在临界点的动态系统提供了可行的优化框架。

Abstract: Tipping points define situations where a system experiences sudden and
irreversible changes and are generally associated with a random level of the
system below which the changes materialize. In this paper, we study a singular
stochastic control problem in which the performance criterion depends on the
hitting time of a random level that is not a stopping time for the reference
filtration. We establish a connection between the value of the problem and the
value of a singular control problem involving a diffusion and its running
minimum. We prove a verification theorem and apply our results to explicitly
solve a resource extraction problem where the random evolution of the resource
changes when it crosses a tipping point.

</details>


### [88] [Adversarial Reinforcement Learning for Robust Control of Fixed-Wing Aircraft under Model Uncertainty](https://arxiv.org/abs/2510.16650)
*Dennis J. Marquis,Blake Wilhelm,Devaprakash Muniraj,Mazen Farhood*

Main category: math.OC

TL;DR: 本文提出了一种基于强化学习的固定翼小型无人机路径跟踪控制器，采用鲁棒对抗强化学习框架训练，通过引入气动模型系数的有界扰动提升控制器在不确定环境下的鲁棒性，并在高保真六自由度仿真中验证了其优于传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高固定翼小型无人机在气动模型不确定性下的路径跟踪鲁棒性，克服传统方法对精确模型依赖性强、适应能力差的问题。

Method: 采用鲁棒对抗强化学习（RARL）框架，其中智能体为无人机路径跟踪控制器，对手则对气动模型系数施加速率受限的扰动，以模拟各种不确定气动条件，从而在训练中增强控制器的鲁棒性。

Result: 实验结果表明，经过对抗训练的控制器相比基于随机模型不确定性的训练方法具有更强的鲁棒性，在多种不确定气动条件下均表现出更优的路径跟踪精度；同时优于切换不确定初始条件控制器。

Conclusion: 该方法有效提升了固定翼小型无人机在气动模型不确定性下的路径跟踪性能，验证了对抗训练在飞行控制中的潜力，适用于高保真仿真环境下的复杂飞行任务。

Abstract: This paper presents a reinforcement learning-based path-following controller
for a fixed-wing small uncrewed aircraft system (sUAS) that is robust to
uncertainties in the aerodynamic model of the sUAS. The controller is trained
using the Robust Adversarial Reinforcement Learning framework, where an
adversary perturbs the environment (aerodynamic model) to expose the agent
(sUAS) to demanding scenarios. In our formulation, the adversary introduces
rate-bounded perturbations to the aerodynamic model coefficients. We
demonstrate that adversarial training improves robustness compared to
controllers trained using stochastic model uncertainty. The learned controller
is also benchmarked against a switched uncertain initial condition controller.
The effectiveness of the approach is validated through high-fidelity
simulations using a realistic six-degree-of-freedom fixed-wing aircraft model,
showing accurate and robust path-following performance under a variety of
uncertain aerodynamic conditions.

</details>


### [89] [Bregman Stochastic Proximal Point Algorithm with Variance Reduction](https://arxiv.org/abs/2510.16655)
*Cheik Traoré,Peter Ochs*

Main category: math.OC

TL;DR: 本文提出了针对Bregman随机近端点算法（BSPPA）的方差缩减技术，结合了非欧几里得几何下的优化优势与方差缩减方法，提升了算法的稳定性和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 随机近端点算法（SPPA）虽然在步长设置上比SGD更鲁棒，但由于需要逐渐减小的步长而导致收敛速度下降。此外，许多问题在非欧几里得几何下使用Bregman距离可更高效求解。因此，将方差缩减技术引入Bregman空间中的SPPA具有重要意义。

Method: 本文提出了适用于Bregman随机近端点算法（BSPPA）的方差缩减方法，具体包括类SAGA和类SVRG的技术，并在统一框架下推广至Bregman SGD。

Result: 理论与数值实验结果表明，所提方法相比标准BSPPA在固定和衰减步长下均表现出更好的稳定性与更快的收敛速率。

Conclusion: 通过结合方差缩减技术和Bregman距离结构，BSPPA的性能得到显著提升，且该框架可统一涵盖Bregman SGD的相关变体。

Abstract: Stochastic algorithms, especially stochastic gradient descent (SGD), have
proven to be the go-to methods in data science and machine learning. In recent
years, the stochastic proximal point algorithm (SPPA) emerged, and it was shown
to be more robust than SGD with respect to stepsize settings. However, SPPA
still suffers from a decreased convergence rate due to the need for vanishing
stepsizes, which is resolved by using variance reduction methods. In the
deterministic setting, there are many problems that can be solved more
efficiently when viewing them in a non-Euclidean geometry using Bregman
distances. This paper combines these two worlds and proposes variance reduction
techniques for the Bregman stochastic proximal point algorithm (BSPPA). As
special cases, we obtain SAGA- and SVRG-like variance reduction techniques for
BSPPA. Our theoretical and numerical results demonstrate improved stability and
convergence rates compared to the vanilla BSPPA with constant and vanishing
stepsizes, respectively. Our analysis, also, allow to recover the same variance
reduction techniques for Bregman SGD in a unified way.

</details>


### [90] [HNAG++: A Super-Fast Accelerated Gradient Method for Strongly Convex Optimization](https://arxiv.org/abs/2510.16680)
*Long Chen,Zeyi Xu*

Main category: math.OC

TL;DR: 本文提出了两种用于最小化具有大条件数κ的强凸函数的方法HNAG+和HNAG++。HNAG+实现了信息论最优的全局线性收敛速率1 - 2/√κ，而HNAG++在Hessian满足Hölder连续的函数上达到了更快的渐近线性速率1 - 2√(2/κ)，是目前已知最快的全局收敛一阶方法。数值实验表明HNAG++在多个线性和非线性问题上优于现有加速梯度方法。


<details>
  <summary>Details</summary>
Motivation: 针对条件数较大的强凸函数优化问题，现有加速梯度方法的收敛速率仍有提升空间，尤其是在Hessian结构具有特定正则性时缺乏更优的全局收敛算法。

Method: 提出了HNAG+和HNAG++两种新算法，基于动量加速梯度方法，并针对Hessian的Hölder连续性进行优化设计，理论分析其全局收敛性和收敛速率。

Result: HNAG+达到最优的1 - 2/√κ收敛速率；HNAG++在Hölder连续Hessian条件下实现1 - 2√(2/κ)的渐近线性收敛速率，为当前最快；实验验证其在多种问题上优于现有方法。

Conclusion: HNAG+和HNAG++在理论收敛速率和实际性能上均优于现有方法，尤其是HNAG++在特定正则性条件下实现了当前最快的全局收敛速率，推动了一阶优化方法的性能边界。

Abstract: We introduce and analyze two methods, HNAG+ and HNAG++, for minimizing
strongly convex functions with large condition number kappa. For HNAG+, we
prove a global linear convergence rate of 1 - 2/sqrt(kappa), achieving the
information-theoretic optimal rate. For HNAG++, we establish a global
asymptotic linear rate of 1 - 2*sqrt(2/kappa) for functions with H\"older
continuous Hessians, representing the fastest known rate among globally
convergent first-order methods. Extensive numerical experiments on linear and
nonlinear problems show that HNAG++ consistently outperforms existing
accelerated gradient methods.

</details>


### [91] [Local integral input-to-state stability for non-autonomous infinite-dimensional systems](https://arxiv.org/abs/2510.16725)
*Yongchun Bi,Panyu Deng,Jun Zheng,Guchuan Zhu*

Main category: math.OC

TL;DR: 本文研究了具有时变系数和超线性项的非线性微分方程的比较原理，并发展了无穷维非自治非线性系统的积分输入-状态稳定性（iISS）的李雅普诺夫分析工具。


<details>
  <summary>Details</summary>
Motivation: 由于非线性项的超线性增长给iISS分析带来困难，因此需要建立适用于广泛时变系数系统的比较原理和相应的李雅普诺夫方法。

Method: 首先建立适用于多种时变系数常微分方程的比较原理，然后在Banach空间框架下证明局部iISS的李雅普诺夫定理，并在Hilbert空间中构造局部iISS李雅普诺夫泛函，结合插值不等式处理超线性项。

Result: 提出了局部iISS的李雅普诺夫定理，给出了LiISS-LF存在的充分条件，并构造了两类系统的LiISS-LF；通过两个示例（有限维系统和多维抛物方程）验证了方法的有效性，并通过数值实验确认了结果。

Conclusion: 所提出的比较原理和李雅普诺夫方法为具有时变系数和超线性非线性的无穷维非自治系统提供了有效的iISS分析框架。

Abstract: In this paper, we prove comparison principles for nonlinear differential
equations with time-varying coefficients and develop Lyapunov analytical tools
for the integral input-to-state stability (iISS) analysis of nonlinear
non-autonomous infinite-dimensional systems, which involve nonlinearities
satisfying a superlinear growth, {bringing} difficulties to the iISS
{analysis.} Specifically, our approach starts by establishing several forms of
comparison principles for a wide range of ordinary differential equations
having time-varying coefficients and superlinear terms, paving the way to
conduct iISS assessment for general nonlinear non-autonomous
infinite-dimensional systems within the Lyapunov stability framework. Then, by
using the comparison principles, we prove a local {iISS} {(LiISS)} Lyapunov
theorem for the nonlinear non-autonomous infinite-dimensional systems in the
framework of Banach spaces. {Furthermore,} we provide sufficient conditions of
the existence of a local iISS Lyapunonv functional (LiISS-LF) and construct
LiISS-LFs for the systems in the framework of Hilbert spaces. Finally, we
preset two examples to illustrate the proposed {Lyapunov} method for the LiISS
analysis: one is to show how to obtain the LiISS of a nonlinear
finite-dimensional system with time-varying coefficients and superlinear terms
under linear state feedback control law while another one is to show how to
employ the interpolation inequalities to handle superliner terms and establish
the LiISS-LF for a class of multi-dimensional parabolic equations with
space-time-varying coefficients. To demonstrate the validity of the results,
numerical experiments are also conducted to verify the LiISS of these two
classes of systems.

</details>


### [92] [Method of Monotone Structural Evolution for control and state constrained optimal and control problems](https://arxiv.org/abs/2510.16768)
*Maciej Szymkat,Adam Korytowski*

Main category: math.OC

TL;DR: 提出了一种用于具有控制和状态约束问题的最优控制计算方法，通过调整控制结构（节点和弧的生成与减少）来重新定义决策空间，而不改变当前控制。


<details>
  <summary>Details</summary>
Motivation: 解决带有控制和状态约束的最优控制问题，提升计算效率与可行性。

Method: 采用一系列控制结构的调整，包括节点和弧的生成与减少，以重新定义决策空间。

Result: 方法在多个示例中得到验证，展示了其有效性。

Conclusion: 该方法能够在不改变当前控制的情况下优化决策空间，适用于复杂约束下的最优控制计算。

Abstract: A method of optimal control computation is proposed for problems with control
and state constraints. It uses a sequence of control structure adjustments in
the form of generations and reductions of nodes and arcs, which do not change
the current control but redefine the decision space. Several examples are
given.

</details>


### [93] [The Augmented Lagrangian Methods: Overview and Recent Advances](https://arxiv.org/abs/2510.16827)
*Kangkang Deng,Rui Wang,Zhenyuan Zhu,Junyu Zhang,Zaiwen Wen*

Main category: math.OC

TL;DR: 本文综述了增广拉格朗日方法（ALM）在大规模约束优化中的统一构建与应用，涵盖非线性规划及凸与非凸复合优化问题，讨论了其理论基础、收敛性、复杂度分析及实际应用。


<details>
  <summary>Details</summary>
Motivation: 由于现代科学、工程和工业计算中常涉及大量变量和约束的复杂系统，亟需高效可靠的优化方法，因此需要对增广拉格朗日方法进行系统性梳理与拓展。

Method: 基于Hestenes-Powell-Rockafellar增广拉格朗日函数，构建适用于多种优化问题的统一框架，并分析ALM在凸与非凸情形下的理论性质，结合近端算子处理非光滑问题，探讨其变体及子问题求解算法。

Result: 总结了ALM在处理非凸约束、保证一阶和二阶梯度收敛、非光滑凸问题的局部线性收敛性以及整数规划等方面的最新进展，提供了不同领域中的有效算法实现和应用实例。

Conclusion: ALM是一种强大且灵活的优化框架，具备良好的理论支持和广泛的应用前景，其多种变体可有效提升收敛性和计算效率，但也存在对问题结构敏感、子问题求解成本高等局限性。

Abstract: Large-scale constrained optimization is pivotal in modern scientific,
engineering, and industrial computation, often involving complex systems with
numerous variables and constraints. This paper provides a unified and
comprehensive perspective on constructing augmented Lagrangian functions (based
on Hestenes-Powell-Rockafellar augmented Lagrangian) for various optimization
problems, including nonlinear programming and convex and nonconvex composite
programming. We present the augmented Lagrangian method (ALM), covering its
theoretical foundations in both convex and nonconvex cases, and discuss several
successful examples and applications. Recent advancements have extended ALM's
capabilities to handle nonconvex constraints and ensure global convergence to
first and second-order stationary points. For nonsmooth convex problems, ALM
utilizes proximal operations, preserving desirable properties such as locally
linear convergence rates. Furthermore, recent progress has refined the
complexity analysis for ALM and tackled challenging integer programming
instances. This review aims to offer a thorough understanding of ALM's benefits
and limitations, exploring different ALM variants designed to enhance
convergence and computational performance. We also illustrate effective
algorithms for ALM subproblems across different types of optimization problems
and highlight practical implementations in several fields.

</details>


### [94] [Solving nonconvex optimization problems via a second order dynamical system with unbounded damping](https://arxiv.org/abs/2510.16864)
*Szilárd Csaba László*

Main category: math.OC

TL;DR: 本文研究了一个与光滑非凸函数最小化问题相关的二阶变系数动力系统，证明了在目标函数的正则化满足Kurdyka-Łojasiewicz性质时，系统轨迹收敛到目标函数的临界点，并给出了基于Łojasiewicz指数的收敛速率。所考虑的无界阻尼显著提升了已有文献中的收敛速率，实现了从线性到超线性的改进。


<details>
  <summary>Details</summary>
Motivation: 为了改进非凸优化问题中动力系统方法的收敛速率，研究引入变系数和无界阻尼机制，以克服现有方法收敛速度慢的问题。

Method: 采用二阶动力系统建模，结合变量系数和无界阻尼项，利用目标函数正则化后的Kurdyka-Łojasiewicz性质分析轨迹的收敛性，并通过Łojasiewicz指数推导收敛速率。

Result: 证明了轨迹收敛到临界点，并获得了基于Łojasiewicz指数的超线性收敛速率，优于文献中已知的线性速率。

Conclusion: 所提出的变系数二阶动力系统在无界阻尼作用下，能有效提升非凸优化问题的收敛速度，实现了超线性收敛，显著优于现有结果。

Abstract: In this paper we study a second order dynamical system with variable
coefficients in connection to the minimization problem of a smooth nonconvex
function. The convergence of the trajectories generated by the dynamical system
to a critical point of the objective function is assured, provided a
regularization of the objective function satisfies the Kurdyka-{\L}ojasiewicz
property. We also provide convergence rates for the trajectories generated by
the dynamical system, formulated in terms of the {\L}ojasiewicz exponent, and
we show that the unbounded damping considered in our dynamical system
significantly improves the convergence rates known so far in the literature,
that is, instead of linear rates we obtain superlinear rates.

</details>


### [95] [Distributionally Robust Nash Equilibria via Variational Inequalities](https://arxiv.org/abs/2510.17024)
*Zeinab Alizadeh,Azadeh Farsi,Afrooz Jalilzadeh*

Main category: math.OC

TL;DR: 本文研究了分布鲁棒纳什均衡（DRNE）问题，将其重新表述为变分不等式（VI）问题，并提出了一种具有收敛性保证的梯度下降-上升算法，有效应对高维和非光滑目标带来的计算挑战。


<details>
  <summary>Details</summary>
Motivation: DRNE在不确定环境下具有重要意义，但其计算复杂，尤其是在高维和非光滑情况下缺乏有效的求解方法。

Method: 将DRNE问题转化为变分不等式（VI）问题，并设计了一种梯度下降-上升类型的算法。

Result: 提出了一个统一的分析框架，并开发了具有收敛性保证的算法，能够有效处理高维和非光滑的DRNE问题。

Conclusion: 该方法为求解分布鲁棒纳什均衡提供了一个有效且理论可靠的途径，适用于广泛的应用场景。

Abstract: Nash Equilibrium and its robust counterpart, Distributionally Robust Nash
Equilibrium (DRNE), are fundamental problems in game theory with applications
in economics, engineering, and machine learning. This paper addresses the
problem of DRNE, where multiple players engage in a noncooperative game under
uncertainty. Each player aims to minimize their objective against the
worst-case distribution within an ambiguity set, resulting in a minimax
structure. We reformulate the DRNE problem as a Variational Inequality (VI)
problem, providing a unified framework for analysis and algorithm development.
We propose a gradient descent-ascent type algorithm with convergence guarantee
that effectively addresses the computational challenges of high-dimensional and
nonsmooth objectives.

</details>


### [96] [Optimal Trajectories for Optimal Transport in Nonuniform Environments](https://arxiv.org/abs/2510.17170)
*Luca Dieci,Daniyar Omarov*

Main category: math.OC

TL;DR: 本文提出了一种在非均匀环境中求解离散最优传输问题的方法，通过建立并求解欧拉-拉格朗日方程来构造代价矩阵，并给出了解的最优性充分条件，同时设计了新算法并通过数值实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决非均匀环境下的离散最优传输问题，其中传统方法难以准确构建代价矩阵，需考虑两点间最优路径的影响。

Method: 通过建立和求解与最优路径相关的欧拉-拉格朗日方程来构造代价矩阵，并提出新的求解算法。

Result: 提供了可验证的最优性充分条件，并展示了所提算法在多个数值例子中的有效性。

Conclusion: 所提出的方法能够有效处理非均匀环境中的离散最优传输问题，理论结果支持算法的正确性，数值实验表明其良好性能。

Abstract: In this work, we solve a discrete optimal transport problem in a nonuniform
environment. The key challenge is to form the cost matrix, which requires
finding the optimal path between two points, and for this task we formulate and
solve the associated Euler-Lagrange equations. A main theoretical result of
ours is to provide verifiable sufficient conditions of optimality of the
solution of the Euler-Lagrange equation. We propose new algorithms to solve the
problem, and illustrate our results and performance of the algorithms on
several numerical examples.

</details>


### [97] [Periodic limit for non-autonomous Lagrangian systems and applications to a Kuramoto type model](https://arxiv.org/abs/2510.17242)
*Veronica Danesi,Cristian Mendico,Xuan Tao,Kaizhi Wang*

Main category: math.OC

TL;DR: 本文研究了非自治拉格朗日系统的渐近性质，假设相关的Tonelli拉格朗日函数收敛到一个时间周期函数。通过构造适当的Lax-Oleinik半群，证明其收敛到方程的周期解，并应用于Kuramoto型模型，证明了由哈密顿-雅可比方程周期解梯度构成的不变环面的存在性。


<details>
  <summary>Details</summary>
Motivation: 研究非自治系统在长时间下的渐进行为，特别是在拉格朗日函数趋于周期性时的动力学特性。

Method: 通过构造Lax-Oleinik半群并分析其收敛性，结合Hausdorff距离研究梯度图的收敛性质。

Result: 证明了Lax-Oleinik半群收敛到周期解，且其梯度图在Hausdorff距离下收敛到极限周期函数的梯度图；并将结果应用于Kuramoto型模型，得到不变环面的存在性。

Conclusion: 非自治Tonelli拉格朗日系统在长时间下趋于周期行为，其渐近动力学可由周期解及其梯度结构刻画。

Abstract: This paper explores the asymptotic properties of non-autonomous Lagrangian
systems, assuming that the associated Tonelli Lagrangian converges to a
time-periodic function. Specifically, given a continuous initial condition, we
provide a suitable construction of a Lax-Oleinik semigroup such that it
converges toward a periodic solution of the equation. Moreover, the graph of
its gradient converges as time tends to infinity to the graph of the gradient
of the periodic limit function with respect to the Hausdorff distance. Finally,
we apply this result to a Kuramoto-type model, proving the existence of an
invariant torus given by the graph of the gradient of the limiting periodic
solution of the Hamilton-Jacobi equation.

</details>


### [98] [A polynomial-based QCQP solver for encrypted optimization](https://arxiv.org/abs/2510.17294)
*Sebastian Schlor,Andrea Iannelli,Junsoo Kim,Hyungbo Shim,Frank Allgöwer*

Main category: math.OC

TL;DR: 提出了一种仅使用加法和乘法求解二次约束二次优化问题的新方法，适用于同态加密下的私有数据优化。


<details>
  <summary>Details</summary>
Motivation: 为了在保护数据隐私的前提下解决约束优化问题，利用同态加密兼容的运算（加法和乘法）设计优化算法。

Method: 引入一系列次数递增的多项式罚函数，将其加入原目标函数形成无约束问题序列，采用梯度下降法迭代求解，并保证迭代点始终位于可行域内。

Result: 证明了迭代序列收敛到原问题的最优解，且可行域在迭代过程中保持正不变性；方法在加密环境下比较两个数大小的问题中得到验证。

Conclusion: 该方法能够在不暴露私有数据的情况下求解一类约束优化问题，具备在同态加密环境下实现的潜力。

Abstract: In this paper, we present a novel method for solving a class of quadratically
constrained quadratic optimization problems using only additions and
multiplications. This approach enables solving constrained optimization
problems on private data since the operations involved are compatible with the
capabilities of homomorphic encryption schemes. To solve the constrained
optimization problem, a sequence of polynomial penalty functions of increasing
degree is introduced, which are sufficiently steep at the boundary of the
feasible set. Adding the penalty function to the original cost function creates
a sequence of unconstrained optimization problems whose minimizer always lies
in the admissible set and converges to the minimizer of the constrained
problem. A gradient descent method is used to generate a sequence of iterates
associated with these problems. For the algorithm, it is shown that the iterate
converges to a minimizer of the original problem, and the feasible set is
positively invariant under the iteration. Finally, the method is demonstrated
on an illustrative cryptographic problem, finding the smaller value of two
numbers, and the encrypted implementability is discussed.

</details>


### [99] [Assessing the Quality of a Set of Basis Functions for Inverse Optimal Control via Projection onto Global Minimizers](https://arxiv.org/abs/2510.17339)
*Filip Bečanović,Jared Miller,Vincent Bonnet,Kosta Jovanović,Samer Mohammed*

Main category: math.OC

TL;DR: 本文提出了一种新的逆优化方法，通过测量测试点与由基函数凸组合生成的全局最优解集之间的距离，来评估基函数对测试点的表达质量，并探讨了该最优解集在有约束和无约束情况下的性质。


<details>
  <summary>Details</summary>
Motivation: 传统逆优化方法假设真实代价函数是已知凸基函数的凸组合，且基函数与测试数据一致，但这一假设在许多实际场景中难以成立。本文旨在解决基函数可能不具表达能力的问题，提出一种量化基函数适用性的新度量方法。

Method: 引入测试点到全局最优解集的距离作为基函数表达质量的度量；在无约束和有约束条件下分析最优解集的性质；在凸二次情形下，采用双层梯度下降法和增强线性矩阵不等式分别计算最小距离的上下界；并扩展至最大可表示基函数、非凸基函数及多项式优化技术。

Result: 提出了衡量基函数有效性的新框架，能够识别不合适的基函数集合；给出了凸二次情况下的最小距离上下界计算方法；扩展了该框架以处理更广泛的函数类型。

Conclusion: 该方法为逆优化中的基函数选择提供了理论依据和实用工具，增强了在未知数据生成机制下的鲁棒性和适用性。

Abstract: Inverse optimization (Inverse optimal control) is the task of imputing a cost
function such that given test points (trajectories) are (nearly) optimal with
respect to the discovered cost. Prior methods in inverse optimization assume
that the true cost is a convex combination of a set of convex basis functions
and that this basis is consistent with the test points. However, the
consistency assumption is not always justified, as in many applications the
principles by which the data is generated are not well understood. This work
proposes using the distance between a test point and the set of global optima
generated by the convex combinations of the convex basis functions as a
measurement for the expressive quality of the basis with respect to the test
point. A large minimal distance invalidates the set of basis functions. The
concept of a set of global optima is introduced and its properties are explored
in unconstrained and constrained settings. Upper and lower bounds for the
minimum distance in the convex quadratic setting are implemented by bi-level
gradient descent and an enriched linear matrix inequality respectively.
Extensions to this framework include max-representable basis functions,
nonconvex basis functions (local minima), and applying polynomial optimization
techniques.

</details>


### [100] [A Finite-Difference Trust-Region Method for Convexly Constrained Smooth Optimization](https://arxiv.org/abs/2510.17366)
*Dânâ Davar,Geovani Nunes Grapiglia*

Main category: math.OC

TL;DR: 提出了一种基于有限差分梯度近似的无导数信赖域方法，用于求解带凸约束的光滑优化问题，并在不同函数类型下建立了复杂度界，数值实验表明该方法在无约束和边界约束问题上均具有较高效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决光滑优化问题中无法获取导数信息的情况，同时处理凸约束，提出一种无需计算近似平稳性度量的无导数信赖域方法。

Method: 采用有限差分近似梯度构造信赖域子问题，结合信任域框架进行迭代求解，不依赖精确梯度信息，适用于非凸、凸及满足Polyak-Lojasiewicz条件的目标函数。

Result: 对于非凸问题，达到近似平稳点的函数评估复杂度为O(n(L/σε)^{-2})；凸情况下降至O(n(L/σε)^{-1})；PL条件下进一步提升至O(n log((L/σε)^{-1}))，实验显示其优于现有无导数求解器。

Conclusion: 该无导数信赖域方法在理论复杂度和实际性能上均表现良好，适用于多种光滑优化问题，尤其在缺乏梯度信息时具有优势。

Abstract: We propose a derivative-free trust-region method based on finite-difference
gradient approximations for smooth optimization problems with convex
constraints. The proposed method does not require computing an approximate
stationarity measure. For nonconvex problems, we establish a worst-case
complexity bound of
$\mathcal{O}\!\left(n\left(\tfrac{L}{\sigma}\epsilon\right)^{-2}\right)$
function evaluations for the method to reach an
$\left(\tfrac{L}{\sigma}\epsilon\right)$-approximate stationary point, where
$n$ is the number of variables, $L$ is the Lipschitz constant of the gradient,
and $\sigma$ is a user-defined estimate of $L$. If the objective function is
convex, the complexity to reduce the functional residual below
$(L/\sigma)\epsilon$ is shown to be of
$\mathcal{O}\!\left(n\left(\tfrac{L}{\sigma}\epsilon\right)^{-1}\right)$
function evaluations, while for Polyak-Lojasiewicz functions on unconstrained
domains, the bound further improves to
$\mathcal{O}\left(n\log\left(\left(\frac{L}{\sigma}\epsilon\right)^{-1}\right)\right)$.
Numerical experiments on benchmark problems and a model-fitting application
demonstrate the method's efficiency relative to state-of-the-art
derivative-free solvers for both unconstrained and bound-constrained problems.

</details>


### [101] [A condensing approach for linear-quadratic optimization with geometric constraints](https://arxiv.org/abs/2510.17465)
*Alberto De Marchi*

Main category: math.OC

TL;DR: 本文提出了一种结合增广拉格朗日框架和结构利用型子问题重构的方法，用于求解带有逻辑条件和基数约束的凸二次成本与多面体约束优化问题，通过提出的压缩技术显著提升了计算性能。


<details>
  <summary>Details</summary>
Motivation: 为了处理包含逻辑条件、基数约束以及部分非凸约束的更广泛优化问题，同时保持计算可行性。

Method: 结合增广拉格朗日框架与求解器无关的结构利用型子问题重构方法，并采用压缩技术以提高计算效率。

Result: 该方法在保持收敛性的同时，显著提升了求解此类优化问题的计算性能。

Conclusion: 所提出的方法有效应对了复杂约束下的优化问题，在实际应用中具有良好的计算效率和广泛适用性。

Abstract: Optimization problems with convex quadratic cost and polyhedral constraints
are ubiquitous in signal processing, automatic control and decision-making. We
consider here an enlarged problem class that allows to encode logical
conditions and cardinality constraints, among others. In particular, we cover
also situations where parts of the constraints are nonconvex and possibly
complicated, but it is practical to compute projections onto this nonconvex
set. Our approach combines the augmented Lagrangian framework with a
solver-agnostic structure-exploiting subproblem reformulation. While
convergence guarantees follow from the former, the proposed condensing
technique leads to significant improvements in computational performance.

</details>


### [102] [Towards Optimal Control and Algorithmic Structure of Decompression Schedules](https://arxiv.org/abs/2510.17551)
*Benjamin Marsh*

Main category: math.OC

TL;DR: 本文将减压计划形式化为一个最优控制问题，考虑了气体可行性窗口、仿射上限和凸惩罚，并证明了在混合气体可行性窗口下的存在性和Bang-Bang结构。


<details>
  <summary>Details</summary>
Motivation: 为了更精确地规划潜水减压过程，确保安全并优化减压时间，研究者试图将减压计划建模为一个包含多种约束条件的最优控制问题。

Method: 采用最优控制理论，结合气体可行性窗口（如ppO₂和END）、仿射天花板以及归一化过饱和度中的凸惩罚项来构建模型。通过动态规划(DP)和标签设置算法提供解决方案，并推导出在线价值函数的Lipschitz正则性。

Result: 证明了在温和的惰性分数单调性假设下，存在最优解且具有单调无再下降结构及Bang-Bang上升特性；给出了带有先验误差界的伪多项式DP和标签设置算法；揭示了有效前沿是连续但通常非凸的。

Conclusion: 该研究提供了首个在混合气体可行性窗口条件下关于存在性和Bang-Bang结构的形式化证明，为潜水减压计划提供了坚实的理论基础。

Abstract: We formalise decompression planning as an optimal control problem with gas
feasibility windows (ppO$_2$, END), affine ceilings, and convex penalties in
normalised oversaturation. We prove existence, a monotone no re-descent
structure and bang-bang ascents under a mild monotonicity assumption on inert
fraction, and establish dwell time KKT conditions. We give pseudo-polynomial DP
and label-setting algorithms with a priori error bounds, derive Lipschitz
regularity of the online value function, and discuss multi-species extensions.
The efficient frontier is continuous and generally nonconvex. We provide the
first formal existence and bang-bang structure proof under mixed gas
feasibility windows.

</details>


### [103] [An Inexact General Descent Method with Applications in Differential Equation-Constrained Optimization](https://arxiv.org/abs/2510.17581)
*Humberto Gimenes Macedo,Luís Felipe Bueno*

Main category: math.OC

TL;DR: 提出了一种非精确通用下降框架，用于在梯度近似情况下实现全局收敛，适用于微分方程约束优化问题。


<details>
  <summary>Details</summary>
Motivation: 在许多应用中，梯度计算本质上是近似的，尤其是在微分方程约束优化中，离散伴随梯度依赖迭代求解器，因此需要在非精确一阶信息下仍能可靠工作的优化方法。

Method: 提出了一个非精确通用下降框架，在固定和递减步长两种情况下建立全局收敛理论；采用自适应精度的梯度近似，并实现了非精确梯度下降和类BFGS方法。

Result: 在二阶常微分方程反问题和二维拉普拉斯反问题上的实验表明，与固定高精度容差相比，自适应非精确梯度显著减少了优化时间，结合曲率信息进一步提高了效率。

Conclusion: 所提出的非精确下降框架在理论和实践中均有效，自适应梯度精度策略能显著提升优化效率，尤其适用于依赖迭代求解的微分方程约束优化问题。

Abstract: In many applications, gradient evaluations are inherently approximate,
motivating the development of optimization methods that remain reliable under
inexact first-order information. A common strategy in this context is adaptive
evaluation, whereby coarse gradients are used in early iterations and refined
near a minimizer. This is particularly relevant in differential
equation-constrained optimization (DECO), where discrete adjoint gradients
depend on iterative solvers. Motivated by DECO applications, we propose an
inexact general descent framework and establish its global convergence theory
under two step-size regimes. For bounded step sizes, the analysis assumes that
the error tolerance in the computed gradient is proportional to its norm,
whereas for diminishing step sizes, the tolerance sequence is required to be
summable. The framework is implemented through inexact gradient descent and an
inexact BFGS-like method, whose performance is demonstrated on a second-order
ODE inverse problem and a two-dimensional Laplace inverse problem using
discrete adjoint gradients with adaptive accuracy. Across these examples,
adaptive inexact gradients consistently reduced optimization time relative to
fixed tight tolerances, while incorporating curvature information further
improved overall efficiency.

</details>


### [104] [A brief note on approximate optimization of submodular functions](https://arxiv.org/abs/2510.17610)
*Alen Alexanderian*

Main category: math.OC

TL;DR: 本文简要讨论了用于近似最大化单调子模函数的贪心方法及其两种更高效的变体。


<details>
  <summary>Details</summary>
Motivation: 为了提高在最大化单调子模函数问题中的效率和性能，研究贪心方法的改进版本。

Method: 分析贪心方法及其两种更高效的变体。

Result: 提出了两种比传统贪心方法更高效的变体，用于近似最大化单调子模函数。

Conclusion: 这些变体在保持近似质量的同时提升了计算效率。

Abstract: We briefly discuss the greedy method and a couple of its more efficient
variants for approximately maximizing monotone submodular functions.

</details>


### [105] [Counterfactual Explanations for Integer Optimization Problems](https://arxiv.org/abs/2510.17624)
*Felix Engelhardt,Jannis Kurtz,Ş. İlker Birbil,Ted Ralphs*

Main category: math.OC

TL;DR: 本文研究了针对一般整数优化问题的反事实解释（CE），证明了构建CE的一般问题是Σ₂^p-完全的，并提出了几种可解特殊情况的算法，实验表明所提方法能在数小时内找到包含最多40个物品的小规模实例的最优CE。


<details>
  <summary>Details</summary>
Motivation: 反事实解释（CE）能通过识别输入参数的特定变化来解释模型决策，但在一般整数优化问题中的研究较少，本文旨在填补这一空白。

Method: 首先证明构建CE问题的复杂性，然后针对可处理的特殊情况（如可变目标参数、单个可变约束、可变右端项等）设计求解算法，并在经典背包问题实例上进行评估。

Result: 研究表明，即使对于仅含一个可变约束的二元整数规划，构建CE的问题也是Σ₂^p-完全的；所提出的算法能够在小规模实例（最多40个项目）上在几小时内找到最优CE。

Conclusion: 本文系统地分析了整数优化中反事实解释的理论复杂性，并为若干特殊情形提供了有效的求解方法，推动了CE在优化模型中的应用。

Abstract: Counterfactual explanations (CEs) offer a human-understandable way to explain
decisions by identifying specific changes to the input parameters of a base or
present model that would lead to a desired change in the outcome. For
optimization models, CEs have primarily been studied in limited contexts and
little research has been done on CEs for general integer optimization problems.
In this work, we address this gap. We first show that the general problem of
constructing a CE is $\Sigma_2^p$-complete even for binary integer programs
with just a single mutable constraint. Second, we propose solution algorithms
for several of the most tractable special cases: (i) mutable objective
parameters, (ii) a single mutable constraint, (iii) mutable right-hand-side,
and (iv) all input parameters can be modified. We evaluate our approach using
classical knapsack problem instances, focusing on cases with mutable constraint
parameters. Our results show that our methods are capable of finding optimal
CEs for small instances involving up to 40 items within a few hours.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [106] [Asymptotically well-balanced geostrophic reconstruction finite volumes numerical schemes for the 2D rotating NLSWE in spherical coordinates](https://arxiv.org/abs/2510.16002)
*Alejandro González del Pino,Manuel Jesús Castro Díaz,Jorge Macías Sánchez*

Main category: physics.ao-ph

TL;DR: 本文开发了用于球坐标下二维旋转浅水方程的二阶和三阶有限体积数值格式，旨在保持地转平衡，以提高对由大气压力扰动引发的海啸等长波事件的模拟和预测能力。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地模拟和预测由大气压力扰动引起的海洋长波事件（如气象海啸），需要发展能够在低罗斯贝数下保持地转平衡的高精度数值模型。

Method: 采用二阶和三阶有限体积法求解球坐标系下的二维旋转浅水方程，并设计格式以在罗斯贝数趋于零时保持地转平衡。

Result: 在多种解析和真实案例中的数值结果表明，长时间保持地转平衡对模拟精度至关重要，所提方法能有效维持该平衡。

Conclusion: 所发展的高阶有限体积格式能够有效保持地转平衡，适用于大尺度大气和海洋动力系统的可靠预测，特别是气象海啸等长波现象的模拟。

Abstract: The dynamics of large-scale geophysical fluids is primarily governed by the
balance between the Coriolis force and the pressure gradient.
  This phenomenon, known as geostrophic equilibrium, is the basis for the
geostrophic model, which has proven to be extremely useful for understanding
and forecasting large-scale atmospheric and oceanic dynamics.
  In the present work, we develop second- and third-order finite-volume
numerical schemes applied to the 2D rotating shallow-water equations in
spherical coordinates. These schemes are designed to preserve the geostrophic
equilibrium in the limit as the Rossby number tends to zero.
  The final goal is to design reliable and efficient forecasting models for
simulating meteotsunamis, long-wave events generated in the ocean by
atmospheric pressure disturbances. These disturbances produce long waves of
small amplitude that gradually amplify as they approach the coast.
  The numerical results for various analytical and real-world test cases
underscore the importance of maintaining geostrophic equilibrium over time.

</details>


### [107] [A Storm-Centric 250 m NEXRAD Level-II Dataset for High-Resolution ML Nowcasting](https://arxiv.org/abs/2510.16031)
*Andy Shi*

Main category: physics.ao-ph

TL;DR: 本文介绍了Storm250-L2，一个高分辨率、风暴中心的雷达数据集，用于改进强对流天气的临近预报。


<details>
  <summary>Details</summary>
Motivation: 现有公共雷达数据集分辨率较粗（1-2 km），平滑了影响极端天气预测的关键细尺度结构，限制了机器学习模型的发展。

Method: 基于NEXRAD Level-II和GridRad-Severe数据，围绕GridRad-Severe的风暴轨迹裁剪出固定高分辨率（250 m）窗口，保留原始极坐标几何结构，并提供时间一致的单仰角扫描和伪组合反射率序列。

Result: 构建了一个包含美国本土数千个风暴事件的数据集，以HDF5张量格式存储，附带丰富的上下文元数据和可复现的清单。

Conclusion: Storm250-L2为机器学习驱动的极端天气临近预报提供了更高保真度的数据支持，有助于提升对强对流风暴短期演化的建模能力。

Abstract: Machine learning-based precipitation nowcasting relies on high-fidelity radar
reflectivity sequences to model the short-term evolution of convective storms.
However, the development of models capable of predicting extreme weather has
been constrained by the coarse resolution (1-2 km) of existing public radar
datasets, such as SEVIR, HKO-7, and GridRad-Severe, which smooth the fine-scale
structures essential for accurate forecasting. To address this gap, we
introduce Storm250-L2, a storm-centric radar dataset derived from NEXRAD
Level-II and GridRad-Severe data. We algorithmically crop a fixed,
high-resolution (250 m) window around GridRad-Severe storm tracks, preserve the
native polar geometry, and provide temporally consistent sequences of both
per-tilt sweeps and a pseudo-composite reflectivity product. The dataset
comprises thousands of storm events across the continental United States,
packaged in HDF5 tensors with rich context metadata and reproducible manifests.

</details>


### [108] [A purely analytical and physical wind turbine wake model accounting for atmospheric stratification](https://arxiv.org/abs/2510.17236)
*Emeline Noël,Erwan Jézéquel,Pierre-Antoine Joulin*

Main category: physics.ao-ph

TL;DR: 提出了一种完全基于大气湍流与风机动力学物理相互作用的解析型尾流模型，无需经验假设或可调参数，仅依赖于来流湍流强度和湍流积分时间尺度进行预测，在多种大气稳定条件下均表现出与大涡模拟高度一致的结果，且对积分时间尺度不敏感，具有强鲁棒性，相较超高斯模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有尾流模型多依赖经验假设或可调参数，难以普适且缺乏物理基础，尤其在不同大气稳定条件下表现不稳定，因此需要一种完全基于物理机制、无需校准的尾流模型。

Method: 基于大气湍流与风机动力学之间的物理相互作用，推导出纯解析的尾流模型，输入仅为可测量的来流湍流强度和湍流积分时间尺度，并通过Meso-NH模拟下的大涡模拟（LES）对IEA 15MW和NREL 5MW风机在稳定、中性和不稳定大气条件下的数据进行系统验证。

Result: 模型在不同大气稳定条件下均与大涡模拟结果高度一致，表现出优异的预测性能，尤其在中性和不稳定层结下优于超高斯模型，且对湍流积分时间尺度的敏感性较弱，具备良好的鲁棒性。

Conclusion: 通过引入更丰富的来流物理信息，可以实现高精度、无需校准的尾流建模，该模型为风电场运行中的尾流预测提供了物理基础坚实、适用性强的新方法。

Abstract: A purely analytical wake model for wind turbines is derived, anchored
exclusively in physical interactions between atmospheric turbulence and turbine
dynamics, and thus inherently accounting for atmospheric stratification. Unlike
empirical models relying on assumed wake deficit shapes or tunable
coefficients, this model predicts the wake deficit solely from measurable
properties of the inflow, namely, turbulence intensity and the turbulence
integral time scale. Systematic validation against Large Eddy Simulations (LES)
for both IEA 15MW and NREL 5MW turbines, simulated in Meso-NH under stable,
neutral, and unstable conditions, demonstrates excellent agreement across
atmospheric regimes. Importantly, the model requires these specific turbulence
statistics as input but shows only weak sensitivity to the integral time scale,
ensuring robustness even with moderate uncertainties in inflow
characterisation. Comparative analysis with the state-of-the-art Super-Gaussian
analytical model highlights superior performance of the present approach,
particularly for unstable and neutral stratification. These results show that
the predictive accuracy gained by incorporating richer inflow physics justifies
the need for more comprehensive atmospheric inputs, providing a clear pathway
for physically grounded, calibration-free wake modeling in operational wind
energy contexts.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [109] [Design of Magnetic Lattices with Quantum Optimization Algorithms](https://arxiv.org/abs/2510.16349)
*Zekeriya Ender Eğer,Waris Khan,Priyabrata Maharana,Kandula Eswara Sai Kumar,Udbhav Sharma,Abhishek Chopra,Rut Lineswala,Pınar Acar*

Main category: physics.comp-ph

TL;DR: 本文通过最小化系统的自由能来研究铁磁材料中磁自旋分布的识别问题，采用Ising模型计算自由能，并使用BQP量子优化算法解决大规模自旋状态优化问题。


<details>
  <summary>Details</summary>
Motivation: 为了准确识别铁磁材料中的磁自旋分布，尤其是在大尺度系统中传统方法难以处理的情况下，探索高效求解方法。

Method: 构建不同大小的磁性晶格，利用考虑自旋间相互作用和外加磁场影响的Ising模型计算自由能，将问题转化为优化问题，并采用BQP量子优化算法求解。

Result: BQP算法的结果在小晶格上通过遗传算法验证有效，并成功应用于50×50的大规模晶格系统，展示了其在处理高维、计算复杂问题上的优势。

Conclusion: BQP量子优化算法能够有效解决大规模磁自旋分布识别问题，在传统方法不可行的情况下仍具可行性与优越性。

Abstract: This article investigates the identification of magnetic spin distributions
in ferromagnetic materials by minimizing the system's free energy. Magnetic
lattices of varying sizes are constructed, and the free energy is computed
using an Ising model that accounts for spin-to-spin neighbor interactions and
the influence of an external magnetic field. The problem reduces to determining
the state of each spin, either up or down, leading to an optimization problem
with $2^{n \times n}$ design variables for an $n \times n$ lattice. To address
the high-dimensional and computationally intractable nature of this problem,
particularly for large domains, we employ a quantum optimization algorithm,
BQP. The BQP results are first validated against solutions obtained using a
genetic algorithm for smaller lattices. Finally, the approach is extended to
large-scale systems, including $50 \times 50$ lattices, where conventional
methods become impractical.

</details>


### [110] [Extended phase-space symplectic integration for electron dynamics](https://arxiv.org/abs/2510.16542)
*Francois Mauger,Cristel Chandre*

Main category: physics.comp-ph

TL;DR: 本文研究了扩展相空间辛积分在两类电子动力学模拟中的应用，包括等离子体物理中的带电粒子动力学和含无限自由度的Kohn-Sham含时密度泛函理论。提出了高阶辛分裂算子方法的数值积分方案和稳定性条件，并识别出一种计算成本低的精度评估指标。


<details>
  <summary>Details</summary>
Motivation: 为了提高对具有有限和无限自由度的经典与量子哈密顿系统进行高效、高精度数值模拟的能力，研究扩展相空间辛积分方法的应用。

Method: 采用高阶辛分裂算子方法，对两类电子动力学系统进行扩展相空间的辛积分，并分析其稳定性条件和精度评估指标。

Result: 成功将扩展相空间辛积分方法应用于两类电子动力学问题，提出了有效的数值积分方案，并发现了一种可低成本实时评估模拟精度的度量方法。

Conclusion: 该工作为广泛应用于经典与量子哈密顿系统的辛分裂算子积分方法奠定了基础，适用于有限和无限自由度系统。

Abstract: We investigate the use of extended phase-space symplectic integration [M.
Tao, Phys. Rev. E 94, 043303 (2016)] for simulating two different classes of
electron dynamics. The first one, with one and a half degrees of freedom, comes
from plasma physics and describes the classical dynamics of a charged particle
in a strong, constant, and uniform magnetic field perturbed by a turbulent
electrostatic potential. The second one, with an infinite number of degrees of
freedom, comes from physical chemistry and corresponds to Kohn-Sham
time-dependent density-functional theory. For both we lay out the extension
procedure and stability condition for numerical integration of the dynamics
using high-order symplectic split-operator schemes. We also identify a
computationally inexpensive metric that can be used for on-the-fly estimation
of the accuracy of simulations. Our work paves the way for broad application of
symplectic split-operator integration of classical and quantum Hamiltonian
systems with finite and infinite number of degrees of freedom.

</details>


### [111] [Scalable cell filter nudged elastic band (CFNEB) for large-scale transition-path calculations](https://arxiv.org/abs/2510.16721)
*Qiuhan Jia,Jiuyang Shi,Jian Sun*

Main category: physics.comp-ph

TL;DR: 提出了一种可扩展的细胞滤波nudged elastic band（CFNEB）框架，用于高效计算包含多达10^5个原子的系统中的过渡路径，结合变形基细胞滤波方案和自适应图像插入删除策略，并在ASE环境和GPU加速版本中实现，展示了在大尺度固态系统中探索真实过渡机制的实用性。


<details>
  <summary>Details</summary>
Motivation: 传统NEB方法在处理大规模系统时计算成本过高，难以研究大超胞中的成核型转变，因此需要一种可扩展且高效的方法来克服这一限制。

Method: 开发了CFNEB方法，结合基于变形的细胞滤波方案（将晶格矢量作为广义坐标并消除虚假旋转自由度）与自适应图像插入和删除策略，动态优化反应路径；并在ASE环境及GPU加速的GPUMD引擎中实现。

Result: 实现了每秒约10^6原子·步的计算吞吐量，成功应用于Ti3O5的层间相变和石墨到金刚石的成核转变，发现当模拟胞足够大时，系统会自发对称破缺，转向成核机制。

Conclusion: CFNEB为研究大尺度固态系统中的真实相变机制提供了一条实用且高效的路径，显著提升了过渡态搜索的可扩展性和计算效率。

Abstract: The nudged elastic band (NEB) method is one of the most widely used
techniques for determining minimum-energy reaction pathways and activation
barriers between known initial and final states. However, conventional
implementations face steep computational scaling with system size, which makes
nucleation-type transitions in realistically large supercells practically
inaccessible. In this work, we develop a scalable cell-filter nudged elastic
band (CFNEB) framework that enables efficient transition-path calculations in
systems containing up to $10^5$ atoms. The method combines a deformation-based
cell filtering scheme, which treats lattice vectors as generalized coordinates
while removing spurious rotational degrees of freedom, with an adaptive image
insertion and deletion strategy that dynamically refines the reaction path. We
implement CFNEB both within the ASE environment and in a fully GPU-accelerated
version using the Graphics Processing Units Molecular Dynamics (GPUMD) engine,
achieving throughput on the order of $10^6$ atom$\cdot$steps per second on
consumer GPUs. We demonstrate the method on two representative systems: the
layer-by-layer $\beta$-$\lambda$ transition in $Ti_3O_5$ and the
nucleation-driven graphite-to-diamond transformation. These examples illustrate
that CFNEB not only reproduces known concerted pathways but also captures
spontaneous symmetry breaking toward nucleated mechanisms when the simulation
cell is sufficiently large. Our results establish CFNEB as a practical route to
exploring realistic transition mechanisms in large-scale solid-state systems.

</details>


### [112] [Large-scale stochastic propagation method beyond the sequential approach](https://arxiv.org/abs/2510.17432)
*Zhichang Fu,Yunhai Li,Weiqing Zhou,Shengjun Yuan*

Main category: physics.comp-ph

TL;DR: 提出了一种新的并发策略的O(N)随机传播方法，消除了传统方法中中间态的顺序计算，显著提升了计算效率，在十亿原子规模的紧束缚模型中实现了近一个数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统O(N)随机传播方法中因顺序计算中间态导致的时间步长限制和计算效率低的问题，提高大规模第一性原理计算的性能。

Method: 引入一种并发策略，减少信息冗余，在状态、矩和能量三种实现方式下进行时间演化，同时遵循奈奎斯特-香农采样定理以保持精度。

Result: 在包含十亿原子的紧束缚模型中系统性基准测试显示，新方法相比传统方法实现了最高一个数量级的加速，能够快速计算多种电子、光学和输运性质。

Conclusion: 所提出的并发O(N)随机传播方法突破了传统时间传播算法的性能瓶颈，为改进包括大规模随机密度泛函理论在内的其他时间传播算法提供了重要思路。

Abstract: The $O(N)$ stochastic propagation method, which relies on the numerical
solution of the time-dependent Schr\"odinger equation using random initial
states, is widely used in large-scale first-principles calculations. In this
work, we eliminate the conventional sequential computation of intermediate
states by introducing a concurrent strategy that minimizes information
redundancy. The new method, in its state-, moment-, and energy-based
implementations, not only surpasses the time step constraint of sequential
propagation but also maintains precision within the framework of the
Nyquist-Shannon sampling theorem. Systematic benchmarking on one billion atoms
within the tight-binding model demonstrates that our new concurrent method
achieves up to an order-of-magnitude speedup, enabling the rapid computation of
a wide range of electronic, optical, and transport properties. This performance
breakthrough offers valuable insights for enhancing other time-propagation
algorithms, including those employed in large-scale stochastic density
functional theory.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [113] [The subtlety of the outermost stellarator magnetic surface](https://arxiv.org/abs/2510.16999)
*Alkesh Punjabi,Allen H. Boozer*

Main category: nlin.CD

TL;DR: 该论文通过解析模型研究了仿星器中磁场线行为，特别是最外层磁面的概念。研究发现，在特定磁通量范围内存在准封闭区域，而超出该范围后磁场线迅速撞击壁面，影响等离子体约束和偏滤器设计。


<details>
  <summary>Details</summary>
Motivation: 探讨仿星器中磁场结构的复杂性，尤其是最外层磁面的定义及其对等离子体约束的影响。

Method: 采用解析模型分析仿星器中的磁场线行为，研究不同磁通量区域内的磁场线轨迹和穿行次数。

Result: 发现最外层完美约束面的磁通量为0.86倍总磁通量；在1.02倍磁通量内存在四条通量管导致磁场线逃逸；超过1.02倍时85%的磁场线在单周期内撞击壁面；此外还发现了新的通量管对。

Conclusion: 在1.02倍磁通量以内的区域可能存在有效的约束表面，而外部区域由于快速粒子损失可能对偏滤器研究不具实际意义。

Abstract: An analytic model of the magnetic field line behavior in a stellarator is
used to study the subtlety of the concept of an outermost magnetic surface. The
analytic model that we use has a central region of nested magnetic surfaces.
The outermost perfectly confining surface has a toroidal flux of 0.86 of the
toroidal flux of the outermost confining surface. The field lines in the
annulus between these surfaces strike a distant wall, but they make tens of
thousands of transits through a period of the stellarator before doing so. The
number of transits is so large that this region can probably be viewed as
having confining surfaces. Between the outermost confining surface and a
surface at 1.02 times the toroidal flux field lines go to the walls in four
flux tubes: two with inward flux and two with outward flux. One of the
inward-outward pairs of flux tubes are adjoining and the other pair is
separated. When the toroidal flux is greater than 1.02 of that of the outermost
confining surface approximately 85% of the field lines strike the wall before
transiting a single period. The loss of plasma from this region is so fast
compared to cross-field plasma diffusion that they are probably irrelevant to
the study of divertors. In addition to the two inward-outward flux tube pairs
that escape from the region inside 1.02 times the flux of the confining region,
the outer region has two new inward-outward of flux-tube pairs; one adjoining
and one separated.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [114] [Is simplicity still possible for a more accurate approximation to the perimeter of the ellipse? or, Using the exponential function to further improve the second Ramanujan's approximation](https://arxiv.org/abs/2510.16191)
*Salvador E. Ayala-Raggi,Manuel Rendón-Marín*

Main category: math.NA

TL;DR: 本文提出了一种改进的椭圆周长闭式近似公式，通过在拉马努金第二公式基础上引入两个指数项的二项式修正，实现了在b/a∈[0.0001,1]范围内最大相对误差仅为0.57 ppm的高精度逼近，且公式简洁，仅含四个常数，显著优于坎特雷尔等现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于椭圆周长无法用初等函数精确表示，长期以来依赖近似公式，但现有方法在精度与简洁性之间难以兼顾，本文旨在提出一个兼具高精度与简单形式的闭式近似公式。

Method: 在拉马努金第二公式的基础上，构造一个由两个指数项组成的二项式修正因子，将其作为分母进行调整，从而提升近似精度，同时保持表达式的紧凑性。

Result: 所提方法在b/a∈[0.0001,1]范围内最大相对误差约为0.57 ppm，在圆形和退化扁椭圆极限情况下接近精确解，相比坎特雷尔方法误差降低25倍。

Conclusion: 该公式是目前文献中最为简洁且精确的单行闭式椭圆周长近似之一，实现了精度与计算简便性的优异平衡。

Abstract: The perimeter of an ellipse has no exact closed-form expression in terms of
elementary functions, and numerous approximations have been proposed since the
eighteenth century. Classical formulas by Fagnano, Euler, and Ramanujan, as
well as modern refinements such as Cantrell and Koshy methods, aim to reduce
the approximation error while maintaining computational simplicity. In this
paper, we introduce a new closed-form expression that enhances Ramanujan second
formula by dividing it by 1 minus a binomial of two exponential terms resulting
in a very stable approximation in a range of b/a between 1 and 1/10000, or even
up to a smaller ratio. The resulting approximation remains compact, requiring
only four constants, and achieving a remarkable tradeoff between simplicity and
accuracy. Across the full eccentricity range of b/a in [0.0001,1], our method
attains a maximum relative error of approximately 0.57 ppm with respect to the
exact perimeter computed via elliptic integral. Our formula is quasi-exact at
the extremes, for the circle b/a=1 and for the degenerate flat ellipse b/a=0.
Compared with Cantrell approximation, the proposed method reduces the maximum
relative error by a factor of 25 while preserving a short and elegant
expression. This makes it one of the simplest yet most accurate closed-form and
single-line approximations to the ellipse perimeter currently available in the
literature.

</details>


### [115] [Applications of AAA rational approximation](https://arxiv.org/abs/2510.16237)
*Yuji Nakatsukasa,Lloyd N. Trefethen*

Main category: math.NA

TL;DR: 本文使用AAA算法来展示有理函数在数值分析中的广泛应用。


<details>
  <summary>Details</summary>
Motivation: 为了展示有理函数在数值分析中的多种应用，采用AAA有理逼近算法作为工具。

Method: 采用AAA（Adaptive Antoulas-Anderson）算法进行有理函数逼近，应用于多个数值分析问题。

Result: 展示了AAA算法在不同数值分析任务中的有效性，突出了有理函数的灵活性和实用性。

Conclusion: AAA算法是有理逼近的有力工具，能够广泛应用于数值分析的多个领域。

Abstract: The AAA algorithm for rational approximation is employed to illustrate
applications of rational functions all across numerical analysis.

</details>


### [116] [Iterative solvers for partial differential equations with dissipative structure: Operator preconditioning and optimal control](https://arxiv.org/abs/2510.16399)
*Volker Mehrmann,Manuel Schaller,Martin Stoll*

Main category: math.NA

TL;DR: 本文研究了由(port-)Hamiltonian偏微分方程离散化产生的非对称矩阵或算子的大规模问题的迭代求解方法，提出利用对称部分作为预处理子，结合Krylov子空间方法（如GMRES）来提高求解效率，并证明该方法在椭圆型和抛物型PDE中具有与网格尺寸无关的条件数，最后通过大规模数值实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决由(port-)Hamiltonian PDE离散化带来的非对称线性系统的高效求解问题，特别是提升Krylov子空间方法的收敛速度。

Method: 采用对称部分\(\mathcal{H}\)或其近似作为预处理子，结合GMRES等Krylov子空间方法；对于最优控制问题，使用定制的Krylov方法结合压缩策略和约束预处理子；预处理子的高效实现包括不完全Cholesky分解和代数多重网格法。

Result: 理论分析表明，在\(\mathcal{H}^{-1}\mathcal{S}\)有界的情况下，使用对称部分预处理可使条件数与网格尺寸无关；数值实验验证了该方法在扩散、流体动力学和弹性等问题中的有效性。

Conclusion: 利用对称部分作为预处理子能显著改善非对称系统的求解性能，尤其适用于一类由物理结构驱动的PDE问题，且在多种大规模实际问题中表现出良好的收敛性和计算效率。

Abstract: This work considers the iterative solution of large-scale problems subject to
non-symmetric matrices or operators arising in discretizations of
(port-)Hamiltonian partial differential equations. We consider problems
governed by an operator $\mathcal{A}=\mathcal{H}+\mathcal{S}$ with symmetric
part $\mathcal{H}$ that is positive (semi-)definite and skew-symmetric part
$\mathcal{S}$. Prior work has shown that the structure and sparsity of the
associated linear system enables Krylov subspace solvers such as the
generalized minimal residual method (GMRES) or short recurrence variants such
as Widlund's or Rapoport's method using the symmetric part $\mathcal{H}$, or an
approximation of it, as preconditioner. In this work, we analyze the resulting
condition numbers, which are crucial for fast convergence of these methods, for
various partial differential equations (PDEs) arising in diffusion phenomena,
fluid dynamics, and elasticity. We show that preconditioning with the symmetric
part leads to a condition number uniform in the mesh size in case of elliptic
and parabolic PDEs where $\mathcal{H}^{-1}\mathcal{S}$ is a bounded operator.
Further, we employ the tailored Krylov subspace methods in optimal control by
means of a condensing approach and a constraint preconditioner for the
optimality system. We illustrate the results by various large-scale numerical
examples and discuss efficient evaluations of the preconditioner, such as
incomplete Cholesky factorization or the algebraic multigrid method.

</details>


### [117] [Applications of optimal error bounds for some generalized two-step iterative processes in Banach spaces](https://arxiv.org/abs/2510.16403)
*Tan-Phuc Nguyen,Thai-Hung Nguyen,Tien-Khai Nguyen,Cong-Duy-Nguyen Nguyen,Trung-Hieu Huynh*

Main category: math.NA

TL;DR: 本文继续研究更一般迭代过程的最优误差界，并在此基础上得到收敛性结果及收敛速率。


<details>
  <summary>Details</summary>
Motivation: 为了推广已有迭代过程的收敛性分析，研究更广泛的迭代过程的最优误差界。

Method: 通过分析参数序列的充分条件，确定多种广义迭代过程的最优误差界，并比较不同迭代过程的收敛性能。

Result: 获得了更一般迭代过程的收敛性结果，并确定了其在特定条件下的收敛速率。

Conclusion: 最优误差界方法可有效用于分析多种迭代过程的收敛性与收敛速度，具有较强的推广性。

Abstract: In a recent paper~\cite{paper2}, we proposed the concept of optimal error
bounds for an iterative process, which allows us to obtain the convergence
result of the iterative sequence to the common fixed point of the nonexpansive
mappings in Banach spaces. Moreover, we also achieve the comparison results
between different iterative processes via optimal error bounds. In this paper,
we continue to determine optimal error bounds for more general iterative
processes which were studied by many authors, such as in~\cite{DungHieu} and
references therein. From there, the convergence results are obtained and the
convergence rates of these iterative processes are determined under some
sufficient conditions on sequences of parameters.

</details>


### [118] [Parameter-related strong convergence rate and polynomial stability of a Euler's type method for time-changed stochastic differential equations](https://arxiv.org/abs/2510.16405)
*Ruchun Zuo*

Main category: math.NA

TL;DR: 提出了一种具有等距步长的欧拉型方法，用于求解由乘性噪声驱动的一类时间变化随机微分方程，并获得了与时间变化过程参数相关的强收敛速率。该方法的收敛性结果显著不同于使用随机步长方法的现有结果，且研究了数值方法在均方意义下的多项式稳定性，与原方程的渐近行为一致。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地数值求解由乘性噪声驱动的时间变化随机微分方程，并准确刻画其收敛行为与稳定性，提出采用等距步长的欧拉型方法，以克服现有随机步长方法的局限性。

Method: 采用具有固定等距步长的欧拉型数值方法，对时间变化的随机微分方程进行离散化求解，并分析其强收敛性与均方意义下的多项式稳定性。

Result: 得到了与时间变化过程参数相关的强收敛速率，表明该方法的收敛性优于或不同于现有随机步长方法；同时证明了数值解在均方意义下具有多项式稳定性，与原方程的渐近性质一致。

Conclusion: 所提出的等距步长欧拉型方法适用于一类时间变化的随机微分方程，不仅具有良好的强收敛性，还能保持原系统的稳定性特征，为相关模型的数值模拟提供了有效工具。

Abstract: A Euler's type method with the equidistant step size is proposed for a class
of time-changed stochastic differential equations driven by the multiplicative
noise and the strong convergence rate that is related to the parameter of the
time changing process is obtained. Such a observation of the convergence rate
is significantly different from those existing results that employ methods with
the random step size. The polynomial stability in the mean square sense of the
numerical method is also studied, which is in line with the asymptotic behavior
of the underlying equation.

</details>


### [119] [Determining the space dependent coefficients in space-time fractional diffusion equations via Krylov preconditioning](https://arxiv.org/abs/2510.16425)
*Asim Ilyas,Muhammad Faisal Khan,Rosita L. Sormani,Giacomo Tento,Stefano Serra-Capizzano*

Main category: math.NA

TL;DR: 本文研究了一类含变系数的时间-空间分数阶扩散方程的源项反演问题，通过拟边界值法正则化处理以缓解问题的不适定性，并采用有限差分法进行数值逼近，构造基于GLT理论的预处理子以提高求解效率。


<details>
  <summary>Details</summary>
Motivation: 分数阶扩散方程在描述异常扩散现象中具有重要作用，但源项反演问题通常具有不适定性，且数值求解面临计算效率挑战，因此需要发展有效的正则化方法和高效的数值求解策略。

Method: 采用拟边界值法对反问题进行正则化处理，利用有限差分法离散方程，形成大规模二阶块线性系统；结合广义局部Toeplitz（GLT）理论对矩阵序列进行谱分析，并据此构造有效的预处理子以加速迭代求解。

Result: 实现了对源项的稳定重构，数值实验验证了所提方法的有效性和鲁棒性，基于GLT理论构造的预处理子显著提升了线性系统的求解效率。

Conclusion: 结合正则化方法与基于GLT理论的预处理技术，能够有效求解含变系数的时间-空间分数阶扩散方程的源项反演问题，为相关反问题的数值求解提供了可行框架。

Abstract: We consider a time-space fractional diffusion equation with a variable
coefficient and investigate the inverse problem of reconstructing the source
term, after regularizing the problem with the quasiboundary value method to
mitigate the ill-posedness. The equation involves a Caputo fractional
derivative in the space variable and a tempered fractional derivative in the
time variable, both of order in (0, 1). A finite difference approximation leads
to a two-by-two block linear system of large dimensions. We conduct a spectral
analysis of the associated matrix sequences, employing tools from Generalized
Locally Toeplitz (GLT) theory, and construct the preconditioner guided by the
GLT analysis. Numerical experiments are reported and commented, followed by
concluding remarks.

</details>


### [120] [Dynamic-stabilization-based linear schemes for the Allen-Cahn equation with degenerate mobility: MBP and energy stability](https://arxiv.org/abs/2510.16447)
*Hongfei Fu,Dianming Hou,Zhonghua Qiao,Bingyin Zhang*

Main category: math.NA

TL;DR: 本文提出了一种用于Allen-Cahn方程的线性一阶和二阶数值格式，采用新的动态稳定方法，无条件保持最大值有界性原理（MBP）和能量稳定性，且在迁移率退化情况下仍保持能量稳定性（迁移率鲁棒性），并建立了严格的误差估计。


<details>
  <summary>Details</summary>
Motivation: 现有数值方法在处理具有退化迁移率的Allen-Cahn方程时难以同时保持最大值有界性原理和能量稳定性，本文旨在设计一种新型数值格式以克服这一局限。

Method: 提出一种新型动态稳定方法，结合线性一阶和二阶格式，并对二阶格式引入带截断预处理的预测策略，每时间步仅需求解一个线性系统。

Result: 所提格式无条件保持MBP和能量稳定性，具备迁移率鲁棒性，并建立了最大范数误差估计；数值实验验证了理论分析结果和算法性能。

Conclusion: 该方法在保持物理一致性和数值稳定性方面表现优越，尤其适用于含退化迁移率的Allen-Cahn模型模拟。

Abstract: In this paper, we investigate linear first- and second-order numerical
schemes for the Allen--Cahn equation with a general (possibly degenerate)
mobility. Compared with existing numerical methods, our schemes employ a novel
dynamic stabilization approach that guarantees unconditional preservation of
the maximum bound principle (MBP) and energy stability. A key advance is that
the discrete energy stability remains valid even in the presence of degenerate
mobility-a property we refer to as mobility robustness. Rigorous maximum-norm
error estimates are also established. In particular, for the second-order
scheme, we introduce a new prediction strategy with a cut-off preprocessing
procedure on the extrapolation solution, and only one linear system needs to be
solved per time level. Representative numerical examples are provided to
validate the theoretical findings and performance of the proposed schemes.

</details>


### [121] [Improving performance estimation of a PCM-integrated solar chimney through reduced-order based data assimilation](https://arxiv.org/abs/2510.16469)
*Diego R. Rivera,Ernesto Castillo,Felipe Galarce,Douglas R. Q. Pacheco*

Main category: math.NA

TL;DR: 本研究提出了一种基于降阶模型的数据同化框架（ROM-DA），结合混合数据填充策略，利用有限的温度测量数据重构相变材料（PCM）集成太阳能烟囱内的动态温度场，从而提高出口气流速度的估计精度。


<details>
  <summary>Details</summary>
Motivation: 由于太阳能烟囱内热-流耦合过程复杂，且相变材料引入了非线性热行为，仅依靠稀疏测点难以准确重构温度场并预测出口速度，因此需要一种高效且精确的数据驱动方法来提升系统状态估计能力。

Method: 采用正则化最小二乘法，结合高保真有限体积模拟生成的降阶模型与三种不同密度的实验数据（22、135、203个测点），并通过边界层与双三次插值混合策略填补缺失数据，将同化后的温度场输入热耦合前向求解器以改进速度预测。

Result: ROM-DA框架在稀疏数据下温度场重构相对误差低于10%，数据密集时低于3%；应用于实验数据时，出口速度均方根误差降低20%，显著优于基线模型。

Conclusion: 这是首次将ROM-DA框架应用于集成PCM的多物理场耦合太阳能烟囱，验证了其在近实时热状态估计和数字孪生开发中的潜力。

Abstract: This study evaluates a data assimilation framework based on reduced-order
modeling (ROM-DA), complemented by a hybrid data-filling strategy, to
reconstruct dynamic temperature fields in a phase-change-material (PCM)
integrated solar chimney from limited temperature measurements. The goal is to
enhance the estimation accuracy of the outlet airflow velocity. A regularized
least-squares formulation is employed to estimate temperature distributions
within an inclined solar chimney using RT-42 as the PCM. The methodology
combines (i) a reduced-order model derived from high-fidelity finite-volume
simulations of unsteady conjugate heat transfer with liquid-solid phase change
and surface radiation, and (ii) three experimental datasets with 22, 135, and
203 measurement points. Missing data are reconstructed using a hybrid filling
scheme based on boundary-layer and bicubic interpolations. The assimilated
temperature fields are integrated into the thermally coupled forward solver to
improve velocity predictions. Results show that the ROM-DA framework
reconstructs the transient temperature fields in both the air and PCM domains
with relative errors below 10 percent for sparse data and below 3 percent for
expanded datasets. When applied to experimental measurements, the approach
enhances the fidelity of temperature and velocity fields compared with the
baseline model, reducing the outlet velocity RMS error by 20 percent. This
represents the first application of a ROM-DA framework to a coupled
multiphysics solar chimney with PCM integration, demonstrating its potential
for near-real-time thermal state estimation and digital-twin development.

</details>


### [122] [Computing functions of $A^{-1}B$ where $A$ and $B$ are Hermitian matrices](https://arxiv.org/abs/2510.16473)
*Dario A. Bini,Massimiliano Fasi,Bruno Iannazzo*

Main category: math.NA

TL;DR: 研究了在A为Hermitian正定、B为Hermitian时，计算Af(A^{-1}B)的数值方法，提出结合Schur分解与矩阵平方根或Cholesky分解的算法，并通过分析和实验表明基于Cholesky分解的方法更准确高效。


<details>
  <summary>Details</summary>
Motivation: 为了更准确和高效地数值计算Af(A^{-1}B)，其中A是Hermitian正定矩阵，B是Hermitian矩阵，f是在A^{-1}B谱上定义的函数。

Method: 结合Schur分解与矩阵平方根或Cholesky分解，提出多种算法，并分析其在浮点运算中的数值行为、计算成本及性能。

Result: 基于Cholesky分解的算法在数值实验中表现出更高的准确性和计算效率，优于基于矩阵平方根的算法。

Conclusion: Cholesky分解结合Schur分解的方法在计算Af(A^{-1}B)时更具优势，推荐用于实际应用。

Abstract: We consider the numerical evaluation of the quantity $Af(A^{-1}B)$, where $A$
is Hermitian positive definite, $B$ is Hermitian, and $f$ is a function defined
on the spectrum of $A^{-1}B$. We study the conditioning of the problem, and we
introduce several algorithms that combine the Schur decomposition with either
the matrix square root or the Cholesky factorization. We study the numerical
behavior of these algorithms in floating-point arithmetic, assess their
computational costs, and compare their numerical performance. Our analysis
suggests that the algorithms based on the Cholesky factorization will be more
accurate and efficient than those based on the matrix square root. This is
confirmed by our numerical experiments.

</details>


### [123] [High-order temporal parametric finite element methods for simulating solid-state dewetting](https://arxiv.org/abs/2510.16493)
*Xiaowen Gan,Yuqian Teng,Sisheng Wang*

Main category: math.NA

TL;DR: 提出了一类用于模拟二维薄膜固态去湿的高阶时间参数有限元方法，基于尖锐界面模型，结合预测-校正策略和后向微分公式，实现了时间上的高阶精度，且保持了良好的网格质量。


<details>
  <summary>Details</summary>
Motivation: 为了更精确地模拟薄膜固态去湿过程中的表面扩散和接触点迁移，需要发展具有高时间精度且稳定的数值方法。

Method: 在Zhao等人（2021）提出的能量稳定参数有限元方法基础上，引入预测-校正策略和后向微分公式进行时间离散，构建半隐式高阶格式，并证明全离散系统的适定性。

Result: 所提出的方法实现了预期的时间精度（通过流形距离衡量），保持了长期的网格等分布性，且在演化过程中维持良好网格质量。

Conclusion: 该高阶参数有限元方法有效、稳定，适用于二维薄膜固态去湿的长期模拟。

Abstract: We propose a class of temporally high-order parametric finite element methods
for simulating solid-state dewetting of thin films in two dimensions using a
sharp-interface model. The process is governed by surface diffusion and contact
point migration, along with appropriate boundary conditions. By incorporating
the predictor-corrector strategy and the backward differentiation formula for
time discretization into the energy-stable parametric finite element method
developed by Zhao et al. (2021), we successfully construct temporally
high-order schemes. The resulting numerical scheme is semi-implicit, requiring
the solution of a linear system at each time step. The well-posedness of the
fully discretized system is established. Moreover, the method maintains the
long-term mesh equidistribution property. Extensive numerical experiments
demonstrate that our methods achieve the desired temporal accuracy, measured by
the manifold distance, while maintaining good mesh quality throughout the
evolution.

</details>


### [124] [A linear unconditionally structure-preserving L1 scheme for the time-fractional Allen-Cahn equation](https://arxiv.org/abs/2510.16496)
*Dianming Hou,Zhonghua Qiao,Tao Tang*

Main category: math.NA

TL;DR: 本文提出并分析了用于时间分数阶Allen-Cahn方程的线性、保结构时间步进格式，包括一阶和min{1+α, 2−α}阶L1离散，并结合指数和（SOE）技术实现快速计算。所提格式在一般时间网格（包括常用分级网格）上无条件保持离散最大值原理和变分能量耗散律。利用数值解的最大值原理，结合时间分数阶Gronwall不等式，建立了精确的误差估计。数值实验验证了理论结果，并展示了所提格式在自适应时间步长策略下的有效性。


<details>
  <summary>Details</summary>
Motivation: 时间分数阶Allen-Cahn方程具有最大值原理和能量耗散特性，但现有数值方法在保持这些结构特性方面存在挑战，尤其是在非均匀时间网格上。因此，需要设计既能高效计算又能严格保持这些物理特性的线性数值格式。

Method: 采用L1型时间离散方法构造一阶和高阶格式，结合线性化策略保证格式的线性性；引入指数和（SOE）近似实现快速算法；在一般时间网格（包括分级网格）上设计保结构格式，确保离散最大值原理和能量耗散律的无条件保持。

Result: 所提出的线性格式在任意时间网格上无条件保持离散最大值原理和变分能量耗散律；通过时间分数阶Gronwall不等式获得了 sharp 的误差估计；数值实验表明格式在自适应步长下具有高效率和高精度。

Conclusion: 本文提出的线性、保结构时间步进格式能有效求解时间分数阶Allen-Cahn方程，在保持关键物理特性的同时实现了高精度和计算效率，适用于复杂时间演化问题的长期模拟。

Abstract: As a variational phase-field model, the time-fractional Allen-Cahn (TFAC)
equation enjoys the maximum bound principle (MBP) and a variational energy
dissipation law. In this work, we develop and analyze linear,
structure-preserving time-stepping schemes for TFAC, including first-order and
$\min\{1+\alpha, 2-\alpha\}$-order L1 discretizations, together with fast
implementations based on the sum-of-exponentials (SOE) technique. A central
feature of the proposed linear schemes is their unconditional preservation of
both the discrete MBP and the variational energy dissipation law on general
temporal meshes, including graded meshes commonly used for these problems.
Leveraging the MBP of the numerical solutions, we establish sharp error
estimates by employing the time-fractional Gro\"nwall inequality. Finally,
numerical experiments validate the theoretical results and demonstrate the
effectiveness of the proposed schemes with an adaptive time-stepping strategy.

</details>


### [125] [Accelerated implicitization: Robust fixed-point iterations arising from an explicit scheme](https://arxiv.org/abs/2510.16535)
*Nicolas A. Barnafi,Felipe Galarce,Pablo Brubeck*

Main category: math.NA

TL;DR: 提出一种通过显式解序列求解非线性隐式时间离散问题的通用策略，结合Anderson加速改善收敛性与计算效率。


<details>
  <summary>Details</summary>
Motivation: 隐式时间离散产生的非线性问题通常计算成本高，尤其在矩阵组装昂贵或缺乏有效预条件子时。因此需要一种更高效、易实现的替代方法。

Method: 采用显式不动点迭代处理非线性问题，并引入Anderson加速技术以提升收敛速度和稳定性，适用于时间和时空耦合离散格式。

Result: 在三个非线性微分方程上验证了该方法的有效性与可扩展性，误差分析支持其理论性质，实例显示其实现简单且对参数选择敏感性适中。

Conclusion: 该方法实现简单、性能良好，特别适用于矩阵组装昂贵或难以构造高效预条件子的问题，为后续研究奠定了基础。

Abstract: This work proposes a general strategy for solving possibly nonlinear problems
arising from implicit time discretizations as a sequence of explicit solutions.
The resulting sequence may exhibit instabilities similar to those of the base
explicit scheme, which can be mitigated through Anderson acceleration. The
approach uses explicit fixed-point subiterations for nonlinear problems,
combined with Anderson acceleration to improve convergence and computational
efficiency. Its usability and scalability are verified on three nonlinear
differential equations. An error analysis is presented to establish the
expected properties of the proposed strategy for both time and space-time
formulations. Several examples illustrate the simplicity of the implementation
and reveal the influence of parameter choices. The method proves simple to
implement and performs well across a range of problems, particularly when
matrix assembly is expensive or a good preconditioner for the implicit system
is unavailable, such as in highly convective fluid flows. This work formalizes
the delay of implicit terms in time discretization, provides a concise error
analysis, and enhances the approach using Anderson acceleration. The results
are encouraging and well supported by existing theory, laying the groundwork
for further research.

</details>


### [126] [Strong error analysis and first-order convergence of Milstein-type schemes for McKean-Vlasov SDEs with superlinear coefficients](https://arxiv.org/abs/2510.16801)
*Jingtao Zhu,Yuying Zhao,Siqing Gan*

Main category: math.NA

TL;DR: 本文提出了一类统一的Milstein型离散化方法，用于处理具有超线性漂移和扩散系数的McKean-Vlasov随机微分方程，建立了在较弱正则性条件下的一阶强收敛理论，并通过数值实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 经典Milstein方法在全局Lipschitz条件下具有一阶强收敛性，但许多实际应用中的MV-SDEs具有超线性增长的系数，导致经典方法可能发散或出现粒子退化问题。因此，需要发展适用于非Lipschitz情形的数值方法。

Method: 构建了一类统一的Milstein型离散化框架，包含tamed-Milstein、tanh-Milstein和sine-Milstein方法作为特例，采用离散时间分析和二项式展开技术，在仅要求系数一阶可微的较弱条件下证明了一阶强收敛性，避免了传统的连续时间Itô方法。

Result: 在较温和的正则性假设下，所提出的方法对相应的相互作用粒子系统具有一阶强收敛性；数值实验验证了收敛行为并与理论结果一致；补充了Chen等人的工作，为其数值实验提供了严格的收敛理论支持。

Conclusion: 本文发展的Milstein型框架为处理具有超线性系数的McKean-Vlasov方程提供了有效且具理论保证的数值方法，拓展了现有理论的适用范围。

Abstract: In the study of McKean-Vlasov stochastic differential equations (MV-SDEs),
numerical approximation plays a crucial role in understanding the behavior of
interacting particle systems (IPS). Classical Milstein schemes provide strong
convergence of order one under globally Lipschitz coefficients. Nevertheless,
many MV-SDEs arising from applications possess super-linearly growing drift and
diffusion terms, where classical methods may diverge and particle corruption
can occur. In the present work, we aim to fill this gap by developing a unified
class of Milstein-type discretizations handling both super-linear drift and
diffusion coefficients. The proposed framework includes the tamed-, tanh-, and
sine-Milstein methods as special cases and establishes order-one strong
convergence for the associated interacting particle system under mild
regularity assumptions, requiring only once differentiable coefficients. In
particular, our results complement Chen et al. (Electron. J. Probab., 2025),
where a taming-based Euler scheme was only tested numerically without
theoretical guarantees, by providing a rigorous convergence theory within a
broader Milstein-type framework. The analysis relies on discrete-time arguments
and binomial-type expansions, avoiding the continuous-time It\^o approach that
is standard in the literature. Numerical experiments are presented to
illustrate the convergence behavior and support the theoretical findings.

</details>


### [127] [Sparse variational regularization with oversmoothing penalty term in the scale of sequence spaces](https://arxiv.org/abs/2510.16821)
*Robert Plato,Bernd Hofmann*

Main category: math.NA

TL;DR: 本文研究了一类从序列空间到Banach空间的线性不适定问题的正则化方法，采用特定罚函数处理确定性噪声，并在先验参数选择下给出了稳定性和收敛速度结果，特别分析了过平滑情形，利用硬阈值技术保证稀疏性。


<details>
  <summary>Details</summary>
Motivation: 解决在过平滑情况下，传统正则化方法难以处理的问题，特别是当目标解不在罚函数定义域内时，仍能保证稳定性和收敛性。

Method: 采用变分正则化方法，罚函数为ℓp范数或计数测度（ℓ0范数），结合先验参数选择策略，并引入硬阈值技术构造辅助元素以分析过平滑情形。

Result: 在满足条件稳定性估计的框架下，证明了正则化方法的稳定性与收敛速度，尤其在过平滑情况下仍可获得最优收敛率，并可通过后处理保证解的稀疏性。

Conclusion: 该方法有效处理了过平滑问题，扩展了正则化理论的适用范围，硬阈值技术不仅用于分析，还可用于获得稀疏解。

Abstract: In this work, we consider a class of linear ill-posed problems with operators
that map from the sequence space $ \ell_r $ ($r \ge 1$) into a Banach space and
in addition satisfy a conditional stability estimate in the scale of sequence
spaces $ \ell_q, \, q \ge 0 $. For the regularization of such problems in the
presence of deterministic noise, we consider variational regularization with a
penalty functional either of the form $ \mathcal{R} =\Vert \cdot \Vert_p^p $
for some $ p > 0 $ or in form of the counting measure $\mathcal{R}_0 = \Vert
\cdot \Vert_0 $. The latter case guarantees sparsity of the corresponding
regularized solutions. In this framework, we present first stability and then
convergence rates for suitable a priori parameter choices. The results cover
the oversmoothing situation, where the desired solution does not belong to the
domain of definition of the considered penalty functional. The analysis of the
oversmoothing case utilizes auxiliary elements that are defined by means of
hard thresholding. Such technique can also be used for post processing to
guarantee sparsity.

</details>


### [128] [Unconditionally Stable, Variable Step DLN Methods for the Allen-Cahn Active Fluid Model: A Divergence-free Preserving Approach](https://arxiv.org/abs/2510.16860)
*Nan Zheng,Wenlong Pei,Qingguang Guan,Wenju Zhao*

Main category: math.NA

TL;DR: 本文提出了一种用于非线性四阶Allen-Cahn相场耦合活性流体方程的无散混合有限元方法，通过引入辅助变量将高阶问题降阶，并设计了保持无散性质的全离散格式，结合变步长时间积分器和自适应步长策略，验证了方法的有效性与精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决非线性四阶Allen-Cahn相场与活性流体耦合方程的数值模拟难题，降低传统H²相容有限元空间的正则性要求，并保持模型原有的无散特性。

Method: 引入两个辅助变量w = Δu和类压力变量ξ，将原问题转化为二阶方程组，采用无散混合有限元进行空间离散，结合变步长Dahlquist-Liniger-Nevanlinna（DLN）时间积分器构建全离散格式，并基于最小耗散准则设计自适应时间步长策略。

Result: 建立了全离散格式的有界性理论，数值实验表明该方法在模拟复杂活性流体动力学时具有良好的有效性、准确性和计算效率。

Conclusion: 所提出的无散混合有限元方法结合变步长时间积分和自适应策略，能够高效准确地求解非线性四阶相场耦合活性流体方程，适用于复杂流体系统的模拟。

Abstract: This paper addresses the divergence-free mixed finite element method (FEM)
for nonlinear fourth-order Allen-Cahn phase field coupled active fluid
equations. By introducing an auxiliary variable $w = \Delta u$, the original
fourth-order problem is converted into a system of second-order equations,
thereby easing the regularity constraints imposed on standard $H^2$-comforming
finite element spaces. To further refine the formulation, an additional
auxiliary variable $\xi$, analogous to the pressure, is introduced, resulting
in a mixed finite element scheme that preserves the divergence-free condition
in $which = \Delta u$ inherited from the model. A fully discrete scheme is then
established by combining the spatial approximation by the divergence-free mixed
finite element method with the variable-step Dahlquist-Liniger-Nevanlinna (DLN)
time integrator. The boundedness of the scheme is rigorously derived under
suitable regularity assumptions. Additionally, an adaptive time-stepping
strategy based on the minimum dissipation criterion is carried out to enhance
computational efficiency. Several numerical experiments validate the
theoretical findings and demonstrate the method's effectiveness and accuracy in
simulating complex active fluid dynamics.

</details>


### [129] [HOQRI: Higher-order QR Iteration for Low Multilinear Rank Approximation of Large and Sparse Tensors](https://arxiv.org/abs/2510.16930)
*Yuchen Sun,Amit Bhat,Chunmei Wang,Kejun Huang*

Main category: math.NA

TL;DR: 提出了一种名为高阶QR迭代（HOQRI）的新算法，用于计算大型稀疏张量的低多线性秩近似（即Tucker分解），相比HOOI方法更高效且避免了中间内存爆炸问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决HOOI在处理大规模稀疏张量时存在的计算复杂度高和内存消耗大的问题，需要一种更高效的算法。

Method: 提出HOQRI算法，使用简单的正交化步骤替代HOOI中的奇异值分解，并引入新的稀疏张量运算TTMcTC以避免内存爆炸；同时基于流形优化框架保证收敛到稳定点。

Result: 在合成和真实数据上的数值实验表明，HOQRI在效率和可扩展性方面优于现有方法，能有效处理极大规模稀疏张量。

Conclusion: HOQRI是一种高效、稳定且适用于大规模稀疏张量Tucker分解的算法，具有良好的应用前景。

Abstract: We propose a new algorithm called higher-order QR iteration (HOQRI) for
computing low multilinear rank approximation (LMLRA), also known as the Tucker
decomposition, of large and sparse tensors. Compared to the celebrated
higher-order orthogonal iterations (HOOI), HOQRI relies on a simple
orthogonalization step in each iteration rather than a more sophisticated
singular value decomposition step as in HOOI. More importantly, when dealing
with extremely large and sparse data tensors, HOQRI completely eliminates the
intermediate memory explosion by defining a new sparse tensor operation called
TTMcTC (short for tensor times matrix chains times core). Furthermore,
recognizing that the orthonormal constraints form a Cartesian product of
Stiefel manifolds, we introduce the framework of manifold optimization and show
that HOQRI guarantees convergence to the set of stationary points. Numerical
experiments on synthetic and real data showcase the effectiveness of HOQRI.

</details>


### [130] [Numerical boundary control of multi-dimensional discrete-velocity kinetic models](https://arxiv.org/abs/2510.17246)
*Haitian Yang,Wen-An Yong*

Main category: math.NA

TL;DR: 本文将多维离散速度模型的理论结果推广到数值层面，通过算子分裂法和引入离散Lyapunov函数，设计了确保数值解指数衰减的控制律，并采用隐式格式处理刚性源项，验证了格式的稳定性。


<details>
  <summary>Details</summary>
Motivation: 将理论上的多维离散速度模型扩展到数值模拟，以实现对系统长期行为的准确捕捉。

Method: 采用算子分裂方法，引入合适的离散Lyapunov函数，设计数值控制律；对碰撞项使用隐式格式以处理刚性源项。

Result: 证明了所提出数值格式的稳定性，并通过二维共面模型的三个数值实验验证了理论结果。

Conclusion: 所提出的数值方法能有效保持系统能量的指数衰减特性，适用于处理具有刚性源项的多维离散速度模型。

Abstract: This paper extends our recent results on multi-dimensional discrete-velocity
models to the numerical level. By adopting an operator splitting scheme and
introducing a suitable discrete Lyapunov function, we derive numerical control
laws that ensure the corresponding numerical solutions decay exponentially in
time. To handle the stiff source term, we also use an implicit scheme for the
collision part and prove the stability of the resulting schemes. The
theoretical results are validated through three numerical simulations for the
two-dimensional coplanar model.

</details>


### [131] [Counterexamples to the conjecture of the upper bound of the derivative of a rational Bézier curve](https://arxiv.org/abs/2510.17300)
*Mao Shi*

Main category: math.NA

TL;DR: 本文提出了有理Bézier曲线一阶导数上界的反例，并进一步研究了这类曲线各阶导数的上确界。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地理解有理Bézier曲线导数的性质，揭示已有上界结论的不足。

Method: 通过构造反例来否定已有的上界结论，并分析所有阶次导数的上确界。

Result: 发现了现有上界不成立的反例，并得出了各阶导数的上确界结果。

Conclusion: 原有上界结论不正确，文中给出了更精确的关于有理Bézier曲线各阶导数上确界的分析。

Abstract: In this paper, we present counterexamples to the upper bound of the
first-order derivative of rational B\'ezier curves and further investigate the
supremum of derivatives of all orders for such curves.

</details>


### [132] [Optimal error estimates of the diffuse domain method for semilinear parabolic equations](https://arxiv.org/abs/2510.17319)
*Yuejin Xu*

Main category: math.NA

TL;DR: 本文研究了扩散域方法（DDM）在求解具有Neumann边界条件的半线性抛物方程时的收敛性，利用相场函数逼近不规则区域，并在界面厚度趋于零时证明数值解收敛于精确解，同时给出了加权L2和H1范数下的最优误差估计。


<details>
  <summary>Details</summary>
Motivation: 由于不规则区域上的偏微分方程求解困难，希望通过扩散域方法将问题转化为规则区域上的求解问题，从而简化计算并保持收敛性。

Method: 采用相场函数逼近原始不规则区域，并将原问题延拓到包含原区域的更大矩形域上，基于加权Sobolev空间理论分析收敛性和误差估计。

Result: 证明了当界面厚度参数趋于零时，数值解在加权L2和H1范数下收敛于精确解，并得到了最优误差估计，数值实验验证了理论结果。

Conclusion: 扩散域方法适用于求解不规则区域上的半线性抛物方程，在适当加权范数下具有良好的收敛性和误差控制。

Abstract: In this paper, we mainly discuss the convergence behavior of diffuse domain
method (DDM) for solving semilinear parabolic equations with Neumann boundary
condition defined in general irregular domains. We use a phasefield function to
approximate the irregular domain and when the interface thickness tends to
zero, the phasefield function will converge to indicator function of the
original domain. With this function, we can modify the problem to another one
defined on a larger rectangular domain that contains the targer physical
domain. Based on the weighted Sobolev spaces, we prove that when the interface
thickness parameter goes to zero, the numerical solution will converge to the
exact solution. Also, we derive the corresponding optimal error estimates under
the weighted L2 and H1 norms. Some numerical experiments are also carried out
to validate the theoretical results.

</details>


### [133] [ParaSLRF: A High Performance Rational Filter Method for Solving Large Scale Eigenvalue Problems](https://arxiv.org/abs/2510.17334)
*Biyi Wang,Karl Meerbergen,Raf Vandebril,Hengbin An,Zeyao Mo*

Main category: math.NA

TL;DR: 本文提出了一种名为ParaSLRF的并行实现方法，用于求解对称定广义特征值问题中位于正实轴区间内的所有特征值。该方法采用两级并行策略，并使用迭代法求解线性系统，具有良好的负载均衡和并行效率。


<details>
  <summary>Details</summary>
Motivation: 为了高效计算大规模对称定广义特征值问题中特定区间内的所有特征值，提升现有理性滤波方法的并行性能。

Method: 采用两级并行化策略：第一级将理性滤波应用到不同向量上并分配给处理器组；第二级在每组内并行求解每个线性系统。使用迭代法而非直接法求解线性系统，并通过锁定收敛特征对和提供良好的初始猜测来优化性能。

Result: 数值实验表明，ParaSLRF在有限元振动模型中表现出优于其他基于积分规则的理性滤波方法的并行效率，具有良好的强可扩展性和优秀的负载均衡。

Conclusion: ParaSLRF方法在大规模特征值问题中展现出高效的并行性能和良好的可扩展性，适用于实际工程计算。

Abstract: In \emph{Wang et al., A Shifted Laplace Rational Filter for Large-Scale
Eigenvalue Problems}, the SLRF method was proposed to compute all eigenvalues
of a symmetric definite generalized eigenvalue problem lying in an interval on
the real positive axis. The current paper discusses a parallel implementation
of this method, abbreviated as ParaSLRF. The parallelization consists of two
levels: (1) on the highest level, the application of the rational filter to the
various vectors is partitioned among groups of processors; (2) within each
group, every linear system is solved in parallel.
  In ParaSLRF, the linear systems are solved by iterative methods instead of
direct ones, in contrast to other rational filter methods, such as, PFEAST.
Because of the specific selection of poles in ParaSLRF, the computational cost
of solving the associated linear systems for each pole, is almost the same.
This intrinsically leads to a better load balance between each group of
resources, and reduces waiting times of processes.
  We show numerical experiments from finite element models of mechanical
vibrations, and show a detailed parallel performance analysis. ParaSLRF shows
the best parallel efficiency, compared to other rational filter methods based
on quadrature rules for contour integration. To further improve performance,
the converged eigenpairs are locked, and a good initial guess of iterative
linear solver is proposed. These enhancements of ParaSLRF show good two-level
strong scalability and excellent load balance in our experiments.

</details>


### [134] [A non-local model for heterogeneous material flow on conveyor belts](https://arxiv.org/abs/2510.17500)
*Paola Goatin,Simone Göttlich,Fabian Ziegler*

Main category: math.NA

TL;DR: 本文采用有限体积近似方法求解二维空间中考虑边界影响的非局部宏观材料流动模型，并将其从标量情形推广到有界域上的异质材料系统，通过Roe格式结合维度分裂证明了近似解的收敛性，数值实验表明与微观模拟结果吻合良好。


<details>
  <summary>Details</summary>
Motivation: 将非局部宏观材料流动模型扩展到包含边界的二维有界域上的异质材料系统，解决实际应用中复杂的材料流动问题。

Method: 采用有限体积法中的Roe格式结合维度分裂构造近似解，并处理通量函数中的不连续性。

Result: 证明了近似解的收敛性，且数值测试结果与微观模拟具有良好一致性。

Conclusion: 该数值方法有效适用于二维非局部宏观材料流动系统的模拟，尤其在处理边界和异质材料方面表现出良好性能。

Abstract: In this paper, a finite volume approximation scheme is used to solve a
non-local macroscopic material flow model in two space dimensions, accounting
for the presence of boundaries in the non-local terms. Based on a previous
result for the scalar case, we extend the setting to a system of heterogeneous
material on bounded domains. We prove the convergence of the approximate
solutions constructed using the Roe scheme with dimensiona splitting, where the
major challenge lies in the treatment of the discontinuity occurring in the
flux function. Numerical tests show a good agreement with microscopic
simulations.

</details>


### [135] [A general framework for Krylov ODE residuals with applications to randomized Krylov methods](https://arxiv.org/abs/2510.17538)
*Emil Krieger,Marcel Schweitzer*

Main category: math.NA

TL;DR: 本文研究了基于随机Krylov子空间方法在常微分方程指数积分中的应用，提出了一种新的后验误差估计方法，并构建了一个统一的Krylov ODE残差分析框架，提升了方法的通用性与实用性。


<details>
  <summary>Details</summary>
Motivation: 为了提高涉及非对称矩阵的线性代数任务（如求解线性系统、矩阵函数作用于向量等）的计算效率，特别是指数积分方案中矩阵函数作用的近似问题，需发展更高效的Krylov方法。

Method: 采用sketch-and-solve范式的随机Krylov子空间方法，利用微分方程的残差推导出新的后验误差估计，并构建了一个适用于多种Krylov方法（如有理Krylov、非标准内积Krylov等）的通用残差分析框架。

Result: 所提出的误差估计可靠且可用于监控收敛性；数值实验表明，sketched Krylov方法在大规模实际ODE模型中具有良好的误差估计质量和计算竞争力。

Conclusion: 随机Krylov方法结合新误差估计和统一框架，显著提升了求解大规模ODE问题的效率和可靠性，展现出在实际应用中的广泛潜力。

Abstract: Randomized Krylov subspace methods that employ the sketch-and-solve paradigm
to substantially reduce orthogonalization cost have recently shown great
promise in speeding up computations for many core linear algebra tasks (e.g.,
solving linear systems, eigenvalue problems and matrix equations, as well as
approximating the action of matrix functions on vectors) whenever a
nonsymmetric matrix is involved. An important application that requires
approximating the action of matrix functions on vectors is the implementation
of exponential integration schemes for ordinary differential equations. In this
paper, we specifically analyze randomized Krylov methods from this point of
view. In particular, we use the residual of the underlying differential
equation to derive a new, reliable a posteriori error estimate that can be used
to monitor convergence and decide when to stop the iteration. To do so, we
first develop a very general framework for Krylov ODE residuals that unifies
existing results, simplifies their derivation and allows extending the concept
to a wide variety of methods beyond randomized Arnoldi (e.g., rational Krylov
methods, Krylov methods using a non-standard inner product, ...). In addition,
we discuss certain aspects regarding the efficient implementation of sketched
Krylov methods. Numerical experiments on large-scale ODE models from real-world
applications illustrate the quality of the error estimate as well as the
general competitiveness of sketched Krylov methods for ODEs in comparison to
other Krylov-based methods.

</details>


### [136] [Numerical Error Analysis of the Poisson Equation under RHS Inaccuracies in Particle-in-Cell Simulations](https://arxiv.org/abs/2510.17580)
*Kai Zhang,Tao Xiao,Weizong Wang,Bijiao He*

Main category: math.NA

TL;DR: 该研究分析了粒子模拟中泊松方程右端项（RHS）在边界附近的误差对求解精度的影响，发现线性格式在典型RHS误差下反而比二次格式更精确，并提出了一种校准策略来恢复二次格式的精度。


<details>
  <summary>Details</summary>
Motivation: 在粒子模拟中，泊松方程在不规则边界附近的求解精度常因电荷密度采样不准确而导致右端项（RHS）误差，但这一问题尚未被深入研究。因此，本文旨在分析此类RHS误差对不同离散格式精度的影响。

Method: 采用嵌入边界有限差分法，结合一维解析推导和二维截断误差分析，并在一维、二维和三维域中进行数值实验，比较线性和二次格式在RHS误差下的表现。

Result: RHS误差会改变局部截断行为：在线性格式中降低主导误差，但在二次格式中引入零阶项，导致更大的全局误差；数值实验表明线性格式在典型RHS误差下整体精度更高；提出一种简单的RHS校准方法可恢复二次格式的精度。

Conclusion: 右端项在边界附近的采样误差显著影响泊松方程的求解精度，线性离散格式在实际PIC模拟中可能优于高阶格式，且通过校准RHS可有效提升高阶格式性能。

Abstract: Particle-in-Cell (PIC) simulations rely on accurate solutions of the
electrostatic Poisson equation, yet accuracy often deteriorates near irregular
Dirichlet boundaries on Cartesian meshes. While much research has addressed
discretization errors on the left-hand side (LHS) of the Poisson equation, the
impact of right-hand-side (RHS) inaccuracies - arising from charge density
sampling near boundaries in PIC methods - remains largely unexplored. This
study analyzes the numerical errors induced by underestimated RHS values at
near-boundary nodes when solving the Poisson equation using embedded boundary
finite difference schemes with linear and quadratic treatments. Analytical
derivations in one dimension and truncation error analyses in two dimensions
reveal that such RHS inaccuracies modify local truncation behavior differently:
they reduce the dominant truncation error in the linear scheme but introduce a
zeroth-order term in the quadratic scheme, leading to larger global errors.
Numerical experiments in one-, two-, and three-dimensional domains confirm
these findings. Contrary to expectations, the linear scheme yields superior
overall accuracy under typical PIC-induced RHS inaccuracies. A simple RHS
calibration strategy is further proposed to restore the accuracy of the
quadratic scheme. These results offer new insight into the interplay between
boundary-induced RHS errors and discretization accuracy in Poisson-type
problems.

</details>


### [137] [PDE-Free Mass-Constrained Learning of Complex Systems with Hidden States: The crowd dynamics case](https://arxiv.org/abs/2510.17657)
*Gianmaria Viola,Alessandro Della Pia,Lucia Russo,Ioannis Kevrekidis,Constantinos Siettos*

Main category: math.NA

TL;DR: 提出了一种基于流形学习的数据驱动框架，用于在不显式识别控制方程的情况下重建质量守恒复杂系统的低维降阶模型，利用延迟坐标和非线性嵌入（如扩散映射）实现高精度、长期稳定的预测。


<details>
  <summary>Details</summary>
Motivation: 许多复杂系统（如流体和人群动力学）的行为虽可由PDE描述，但缺乏显式模型；传统方法难以在不依赖先验方程的情况下构建保持物理约束（如质量守恒）的降阶模型。

Method: 结合延迟坐标和流形学习（POD与扩散映射）从数据中提取低维潜空间，学习潜空间内的预测降阶模型，并通过k-NN或POD求解预像问题将演化结果映射回高维空间，确保质量守恒。

Result: 在Hughes模型生成的合成数据上验证，扩散映射构建的非线性嵌入比POD具有更高的重构精度，生成更简洁、稳定且长期可积的降阶模型。

Conclusion: 该框架无需发现PDE即可重建其解算子，通过流形引导的映射桥接多尺度，为缺乏显式方程的质量守恒系统提供了有效的数据驱动建模范式。

Abstract: We introduce a machine learning framework for modeling the spatio-temporal
dynamics of mass-constrained complex systems with hidden states, whose behavior
can, in principle, be described by PDEs but lack explicit models. The method
extends the Equation-Free approach, enabling the data-driven reconstruction of
reduced-order models (ROMs) without needing to identify governing equations.
Using manifold learning, we obtain a latent space representation of system
evolution from data via delayed coordinates, in accordance with
Takens/Whitney's embedding theorems. Linear (Proper Orthogonal Decomposition,
POD) and nonlinear (Diffusion Maps, DMs) methods are employed to extract
low-dimensional embeddings that capture the essential dynamics. Predictive ROMs
are then learned within this latent space, and their evolution is lifted back
to the original high-dimensional space by solving a pre-image problem. We show
that both POD and k-nearest neighbor (k-NN) lifting operators preserve mass, a
key physical constraint in systems such as computational fluid dynamics and
crowd dynamics. Our framework effectively reconstructs the solution operator of
the underlying PDE without discovering the PDE itself, by leveraging a
manifold-informed objective map that bridges multiple scales. For our
illustrations, we use synthetic spatio-temporal data from the Hughes model,
which couples a continuity PDE with an Eikonal equation describing optimal path
selection in crowds. Results show that DM-based nonlinear embeddings outperform
POD in reconstruction accuracy, producing more parsimonious and stable ROMs
that remain accurate and integrable over long time horizons.

</details>


### [138] [A decoupled meshless Nyström scheme for 2D Fredholm integral equations of the second kind with smooth kernels](https://arxiv.org/abs/2510.17680)
*Bruno Degli Esposti,Alessandra Sestini*

Main category: math.NA

TL;DR: 本文提出了一种解第二类Fredholm积分方程的去耦Nyström方法，通过将求解节点与积分节点分离，并结合无矩无网格积分公式，提高了数值精度和计算效率，尤其适用于窄核函数和复杂二维区域。


<details>
  <summary>Details</summary>
Motivation: 传统Nyström方法在处理窄核函数或复杂几何域时精度和效率受限，因此需要一种更灵活、高效的方法来提升数值求解性能。

Method: 将求解节点与积分节点解耦，采用基于散乱节点的无矩无网格积分公式，并引入重构方案在积分节点上逼近求解节点的值。

Result: 新方法在光滑核函数和复杂二维域上表现出更高的精度和效率，尤其在窄核情况下优于经典Nyström方法；整体收敛阶由积分格式和重构格式中较低者决定。

Conclusion: 去耦Nyström方法显著提升了数值求解的灵活性与性能，是一种适用于复杂问题的高效积分方程求解策略。

Abstract: The Nystr\"om method for the numerical solution of Fredholm integral
equations of the second kind is generalized by decoupling the set of solution
nodes from the set of quadrature nodes. The accuracy and efficiency of the new
method is investigated for smooth kernels and complex 2D domains using recently
developed moment-free meshless quadrature formulas on scattered nodes. Compared
to the classical Nystr\"om method, our variant has a clear performance
advantage, especially for narrow kernels. The decoupled Nystr\"om method
requires the choice of a reconstruction scheme to approximate values at
quadrature nodes from values at solution nodes. We prove that, under natural
assumptions, the overall order of convergence is the minimum between that of
the quadrature scheme and of the reconstruction scheme.

</details>


### [139] [Efficient Tensor Completion Algorithms for Highly Oscillatory Operators](https://arxiv.org/abs/2510.17734)
*Navjot Singh,Edgar Solomonik,Xiaoye Sherry Li,Yang Liu*

Main category: math.NA

TL;DR: 本文提出了一种基于蝴蝶分解和张量补全的低复杂度算法，用于高效重构高振荡算子矩阵，在仅使用O(n log n)观测值的情况下实现了O(n log³n)的计算成本，并在重建精度和速度上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了高效重建离散化的高振荡算子（如地震应用中的n×n矩阵），克服传统低秩矩阵和量化张量列车补全方法在大矩阵下计算复杂度高、精度不足的问题。

Method: 通过将输入矩阵重塑为张量并结合蝴蝶分解，构建一个对数阶张量表示；在此基础上提出两种基于交替最小二乘和梯度优化的张量补全算法，并设计一种基于低秩矩阵补全的初始猜测生成策略以提升收敛效率。

Result: 在三个模拟实验中，仅使用O(n log n)观测项即实现了O(n log³n)的计算成本，相比现有方法每轮迭代提速数个数量级，且重建误差降低一个数量级，能更准确地恢复原始结构。

Conclusion: 所提出的蝴蝶格式张量补全算法结合高效的初始化策略，在处理大规模高振荡矩阵补全问题时兼具高计算效率与高精度，显著优于当前主流方法。

Abstract: This paper presents low-complexity tensor completion algorithms and their
efficient implementation to reconstruct highly oscillatory operators
discretized as $n\times n$ matrices. The underlying tensor decomposition is
based on the reshaping of the input matrix and its butterfly decomposition into
an order $\mathcal{O} (\log n)$ tensor. The reshaping of the input matrix into
a tensor allows for representation of the butterfly decomposition as a tensor
decomposition with dense tensors. This leads to efficient utilization of the
existing software infrastructure for dense and sparse tensor computations. We
propose two tensor completion algorithms in the butterfly format, using
alternating least squares and gradient-based optimization, as well as a novel
strategy that uses low-rank matrix completion to efficiently generate an
initial guess for the proposed algorithms. To demonstrate the efficiency and
applicability of our proposed algorithms, we perform three numerical
experiments using simulated oscillatory operators in seismic applications. In
these experiments, we use $\mathcal {O} (n \log n)$ observed entries in the
input matrix and demonstrate an $\mathcal{O}(n\log^3 n)$ computational cost of
the proposed algorithms, leading to a speedup of orders of magnitudes per
iteration for large matrices compared to the low-rank matrix and quantized
tensor-train completion. Moreover, the proposed butterfly completion
algorithms, equipped with the novel initial guess generation strategy, achieve
reconstruction errors that are smaller by an order of magnitude, enabling
accurate recovery of the underlying structure compared to the state-of-the-art
completion algorithms.

</details>


### [140] [Local Solvers for High-Order Patch Smoothers via p-Multigrid](https://arxiv.org/abs/2510.17785)
*Michał Wichrowski*

Main category: math.NA

TL;DR: 提出了一种基于顶点块平滑器的嵌套、矩阵无关p多重网格方法，构建了多重网格内的多重网格框架，具有高效性和对非结构化网格上不可分问题的适用性。


<details>
  <summary>Details</summary>
Motivation: 为了解决非结构化网格上高次多项式和网格细化带来的求解效率与鲁棒性问题，特别是在存在几何畸变和高对比度系数的情况下。

Method: 采用嵌套的矩阵无关p多重网格作为局部求解器，在顶点块平滑器中不精确地解决局部问题，形成多层多重网格框架。

Result: 单次局部求解迭代仅需O(p^(d+1))次操作，数值实验显示该方法对几何畸变和高对比度系数不敏感，在全局几何多重网格求解器中表现出对多项式次数p和网格细化的鲁棒性。

Conclusion: 所提出的顶点块平滑器结合p多重网格的多层级框架在处理复杂非结构化问题时兼具高效性与鲁棒性，适用于高阶有限元计算。

Abstract: I propose a vertex patch smoother where local problems are solved inexactly
by a nested, matrix-free p-multigrid, creating a multigrid-within-multigrid
framework. A single iteration of the local solver can be evaluated with
$\mathcal{O}(p^{d+1})$ operations, and the approach is applicable to
non-separable problems on unstructured meshes. Numerical experiments
demonstrate limited sensitivity to geometric distortion and high-contrast
coefficients. When used in a global geometric multigrid solver, the method
achieves robustness with respect to both polynomial degree $p$ and mesh
refinement, even on heavily distorted meshes.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [141] [Social Laser Theory as a Natural Extension of Quantum-Like Modeling](https://arxiv.org/abs/2510.16012)
*Andrei Khrennikov*

Main category: physics.soc-ph

TL;DR: 本文综述了社会激光理论（SLT），作为量子类比建模（QLM）的自然延伸，通过引入量子场论概念，将社会系统视为可吸收和发射社会能量量子的社会原子集合，提出外部信息刺激可在类似粒子数反转的条件下引发群体行为的相干性与大规模同步行动，为理解社会能量放大及集体行为相变提供了可量化的理论框架。


<details>
  <summary>Details</summary>
Motivation: 旨在扩展量子类比建模至复杂社会系统，解释集体行为中突发的、高度协调的现象（如抗议、意识形态转变），弥补微观心理过程与宏观社会现象之间的理论鸿沟。

Method: 采用量子类比建模框架，结合希尔伯特空间表示、干涉效应、非对易观测量，并引入量子场论中的概念（如激发态、辐射），构建社会原子模型，模拟社会能量的吸收、发射与相干放大过程。

Result: 提出了社会激光理论的正式模型，定义了社会能量、社会原子、群体相干性等可测量量，能够形式化描述在外部信息刺激下集体行为的相变过程，并具备对社会政治动态进行实证诊断的潜力。

Conclusion: 社会激光理论为理解当代社会中快速、大规模的集体行为转变提供了一个数学严谨且具有预测能力的新范式，成功将量子类比方法从个体认知扩展到复杂社会系统层面。

Abstract: This paper presents a comprehensive review of the Social Laser Theory (SLT)
as a natural extension of the broader framework of Quantum-Like Modeling (QLM).
While QLM applies the mathematical formalism of quantum theory . such as
Hilbert space representations, interference, and non-commutative observables -
to model context-dependent and non-classical phenomena in cognition,
decision-making, and social behavior, SLT advances this approach by integrating
concepts from quantum field theory. The theory conceptualizes social systems as
ensembles of social atoms capable of absorbing and emitting quantized units of
social energy. Under conditions analogous to population inversion in physical
lasers, external informational stimuli (e.g., media signals or mobilizing
rhetoric) can trigger coherence across the population, resulting in
large-scale, synchronized collective actions such as protests or ideological
shifts. SLT thus provides a formal framework for understanding the
amplification and coherence of social energy leading to abrupt phase-like
transitions in collective behavior. Beyond its metaphorical appeal, the theory
proposes measurable quantities and predictive parameters that may support
empirical diagnostics of sociopolitical dynamics. By bridging micro-level
psychological processes with macro-level sociological phenomena, SLT extends
QLM into the domain of complex social systems, offering a mathematically
grounded paradigm for interpreting rapid transformations in contemporary
societies.

</details>


### [142] [The Probability of Vacuum Metastability and Artificial Vacuum Decay: Expert Survey Results](https://arxiv.org/abs/2510.16043)
*Jordan Stone,Youssef Saleh,Darryl Wright,Jess Riedel*

Main category: physics.soc-ph

TL;DR: 本研究首次对20位物理学专家进行了结构化调查，探讨宇宙真空是否处于亚稳态以及先进科技是否可能引发真空衰变。结果显示，专家估计真空为亚稳态的概率平均为45.6%，若真空确实亚稳，任意先进科技诱发真空衰变的平均概率为18.8%。但专家间存在显著分歧，且普遍认为解决这些问题需超越标准模型的理论进展。


<details>
  <summary>Details</summary>
Motivation: 评估先进科技是否可能触发真空衰变，对于理解技术文明的长期发展路径和人类面临的终极生存风险具有重要意义。

Method: 通过对20位物理学专家进行结构化问卷调查，收集他们对真空亚稳态可能性及技术诱发真空衰变可能性的判断，并分析共识与分歧。

Result: 专家平均认为真空处于亚稳态的概率为45.6%，若真空亚稳，任意先进技术诱发真空衰变的平均概率为18.8%。受访者在真空是否亚稳以及是否可被人工诱导衰变上存在显著分歧，多数认为需依赖超出标准模型的新理论来解答这些问题。对于认为真空衰变理论上可能发生的专家而言，普遍认为即使拥有银河级资源的技术文明，实现人工诱导也面临巨大技术挑战。

Conclusion: 目前关于真空是否亚稳及其能否被技术诱发衰变仍存在高度不确定性，亟需发展新的物理理论以澄清这些问题；即便可能，人工诱发真空衰变在技术上极难实现。

Abstract: Vacuum decay posits that the universe's apparent vacuum is metastable and
could transition to a lower-energy state. According to current physics models,
if such a transition occurred in any location, a region of "true vacuum" would
propagate outward at near light speed, destroying the accessible universe as we
know it by deeply altering the effective physical laws. Understanding whether
advanced technology could potentially trigger such a transition has
implications for existential risk assessment and the long-term trajectory of
technological civilizations. We present results from what we believe to be the
first structured survey of physics experts (n = 20) regarding both the
theoretical possibility of vacuum decay and its potential technological
inducibility. The average responded probability that our vacuum is metastable
was 45.6%, with an average estimated 18.8% probability that arbitrarily
advanced technology could induce vacuum decay if our vacuum is metastable.
However, the survey revealed substantial disagreement among respondents on both
whether the vacuum is metastable, and, if it is, whether vacuum decay could be
artificially induced with arbitrarily advanced technology. According to
participants, resolving these questions primarily depends on developing
theories that go beyond the Standard Model of particle physics. Among
respondents who considered vacuum decay theoretically possible, it was
generally expected that artificial induction would pose significant
technological challenges even for a civilization with galactic resources.

</details>


### [143] [Non-equilibrium phase transition and cultural drift in the continuous-trait Axelrod model](https://arxiv.org/abs/2510.16267)
*Paulo R. A. Campos,Sandro M. Reia,José F. Fontanari*

Main category: physics.soc-ph

TL;DR: 提出了一种基于连续文化特征的广义Axelrod模型，通过引入相似性阈值d作为连续控制参数，研究了模型在完美与非完美复制下的相变行为和动力学特性，发现临界点处平均域密度连续消失但最大域分数出现突变，并揭示了在持续文化漂移下大社会中文化收敛难以实现。


<details>
  <summary>Details</summary>
Motivation: 标准Axelrod模型因使用离散文化特征而难以精细研究临界行为，本文旨在通过引入连续文化特征和相似性阈值，克服这一限制，以更精确地分析文化扩散模型的相变和动力学性质。

Method: 构建了一个基于连续文化特征（位于[0,1]区间）和相似性阈值d的广义Axelrod模型，结合有限尺寸缩放分析相变临界点及指数，并模拟文化漂移（复制噪声）影响下的系统演化。

Result: 在完美复制下，精确确定了临界阈值dc，平均域密度在dc处以β=1/3的指数连续消失，最大域分数却出现不连续跳跃；有限尺寸效应由ν=2主导。在非完美复制下，噪声导致在d和1-d处形成对称吸引子，但在热力学极限下这些吸引子不稳定，导致系统无法冻结，表现为持续的文化碎片化和非稳态动力学。

Conclusion: 在大规模持续演化的社会中，由于噪声诱导的吸引子在大尺度下不稳定，文化共识难以达成，系统倾向于长期保持文化分裂和动态演化状态，无法实现真正的文化收敛。

Abstract: The standard Axelrod model of cultural dissemination, based on discrete
cultural traits, exhibits a non-equilibrium phase transition but is inherently
limited by its inability to continuously probe the critical behavior. We
address this limitation by introducing a generalized Axelrod model utilizing
continuous cultural traits confined to the interval $[0,1]$, and a similarity
threshold, $d$, that serves as a continuous control parameter representing
cultural tolerance. This framework allows for a robust analysis of the model's
critical properties and its dynamics under cultural drift (copying noise). For
the perfect copying scenario, we precisely locate the critical threshold $d_c$,
which separates the disordered (fragmented) and ordered (polarized) phases.
Through Finite-Size Scaling, we find that the mean domain density vanishes
continuously at $d_c$ with the exponent $\beta = 1/3$. Simultaneously, the
largest domain fraction displays a surprising discontinuous jump at $d_c$. We
find that the finite size effects in the critical region are governed by the
exponent $\nu=2$ for both the continuous and discontinuous transitions. Under
imperfect copying, persistent noise introduces a powerful selective pressure on
the trait space, leading to the emergence of two symmetry-related attractors at
the trait values $d$ and $1-d$. However, these noise-induced attractors prove
fragile in the thermodynamic limit, becoming unstable at large lattice sizes,
which directly accounts for the observed failure of the dynamics to freeze
under sustained cultural drift. This suggests that in large, continuously
evolving societies, true cultural convergence is highly unlikely, leading
instead to sustained fragmentation and nonstationary dynamics where cultural
domains never fully stabilize.

</details>


### [144] [Mastering Uncertainty: From Understanding to Prediction](https://arxiv.org/abs/2510.16409)
*Didier Sornette*

Main category: physics.soc-ph

TL;DR: 本文重新定义不确定性为“无知”，而非随机性，强调其源于模型缺陷、制度盲区和认知偏差。通过物理与复杂系统理论，提出在转变临界点附近存在可识别的预警信号，主张以动态预见框架取代传统预测，通过适应性领导、透明沟通和系统学习应对不确定性。


<details>
  <summary>Details</summary>
Motivation: 作者旨在纠正人们对不确定性的误解，指出其主要来源并非自然本身的随机性，而是人类认知与组织结构的局限，从而推动更有效的应对策略。

Method: 结合物理学、复杂系统理论及多年实证研究，分析金融危机与工业灾难等案例，识别不确定性中的结构特征与预警信号，提出动态预见框架。

Result: 发现不确定性在系统临界点附近表现出可识别的模式，如反馈机制与早期预警信号；人类行为和组织失效是放大不确定性的主因；预测应转向诊断系统不稳定的前兆。

Conclusion: 掌握不确定性需从追求控制转向培养预见能力，构建能够直面复杂性、持续学习和适应变化的制度与领导模式。

Abstract: Uncertainty defines our age: it shapes climate, finance, technology, and
society, yet remains profoundly misunderstood. We oscillate between the
illusion of control and the paralysis of fatalism. This paper reframes
uncertainty not as randomness but as ignorance: a product of poor models,
institutional blindness, and cognitive bias. Drawing on insights from physics,
complex systems, and decades of empirical research, I show that much of what
appears unpredictable reveals structure near transitions, where feedbacks,
critical thresholds, and early-warning signals emerge. Across domains from
financial crises to industrial disasters, uncertainty is amplified less by
nature than by human behavior and organizational failure. To master it,
prediction must shift from prophecy to diagnosis, identifying precursors of
instability rather than forecasting exact outcomes. I propose a framework of
dynamic foresight grounded in adaptive leadership, transparent communication,
and systemic learning. Mastering uncertainty thus means transforming fear into
foresight and building institutions that navigate, rather than deny, the
complexity of change.

</details>
