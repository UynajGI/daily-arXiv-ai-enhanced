{"id": "2512.22316", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.22316", "abs": "https://arxiv.org/abs/2512.22316", "authors": ["Ashwin Mohan", "Radha S"], "title": "Magnetic and Transport Studies of the TbAgAl compound at high fields", "comment": "7 pages, 3 figures (with a & b)", "summary": "In order to further investigate the magnetic state of the RAgAl series, the magnetization measurements on the TbAgAl compound from this series have been extended to higher fields of 12 Tesla in the temperature range 2K-300K. The electrical resistivity in the temperature range 2-300K has been measured up to fields of 9 Tesla. The field dependence of magnetization at low temperatures suggests an antiferromagnetic state undergoing a metamagnetic transition to a ferromagnetic state above the critical field. The observation of large coercivity (unlike other compounds in the RAgAl series) and non-saturation of magnetization indicates a disordered magnetic state having both ferromagnetic and antiferromagnetic exchange interaction. The presence of competing interactions leading to a disordered state is also supported by transport measurements and is attributed presumably to the layered structure of the compound."}
{"id": "2512.22523", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.22523", "abs": "https://arxiv.org/abs/2512.22523", "authors": ["Ittai Sidilkover", "Nir Hen Levin", "Yuval Nitzav", "Shiri Gvishi", "Abigail Dishi", "Shaked Rosenstein", "Noam Ophir", "Irena Feldman", "Andrei Varykhalov", "Naaman Amer", "Amit Kanigel", "Anna Keselman", "Iliya Esin", "Hadas Soifer"], "title": "Competing Trion and Exciton Dynamics in a Quasi-One-Dimensional Correlated Semiconductor", "comment": "27 pages, 10 figures", "summary": "Strong Coulomb interactions in low-dimensional quantum materials give rise to emergent bound states such as excitons and trions, which play a central role in correlated electronic phases. In quasi-one-dimensional systems, equilibrium photoemission studies have reported signatures of trions, suggesting an unusually robust state, as opposed to conventional semiconductors where trions typically appear only as excited states stabilized by carrier doping. Here, we show that optical excitation of undoped Ta2NiS5 - a correlated quasi-one-dimensional semiconductor - generates a pronounced and long-lived trion population, demonstrating that such states can be dynamically induced even in the absence of doping. Using time- and angle-resolved photoemission spectroscopy we track the dynamics of a bright, localized in-gap state that emerges following photoexcitation and identify it as a transient trion population. We uncover an unconventional trion formation pathway and a fluence-dependent competition between trions and excitons. These findings extend ultrafast quasiparticle photoemission spectroscopy to complex bound states in bulk quantum materials, enabling the dynamical control of charged and neutral excitations."}
{"id": "2512.22528", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.22528", "abs": "https://arxiv.org/abs/2512.22528", "authors": ["Bin Shen", "Feng Du", "Rui Li", "Hang Su", "Kazunori Umeo", "Xin Lu", "Toshiro Takabatake", "Michael Smidman", "Huiqiu Yuan"], "title": "Magnetic field and pressure tuning of the heavy fermion antiferromagnet CePdIn", "comment": "9 pages, 11 figures", "summary": "Frustrated Kondo lattices are ideal platforms for studying how both the Kondo effect and quantum fluctuations compete with the magnetic exchange interactions that drive magnetic ordering. Here, we investigate the effect of tuning the heavy-fermion compound CePdIn, which crystallizes in the geometrically frustrated ZrNiAl-type structure, using applied magnetic fields and hydrostatic pressure. At ambient pressure, CePdIn exhibits two magnetic transitions, one at $T_{\\rm{N}} \\approx 1.65$ K and another at $T_{\\rm{M}} \\approx 1.15$ K, which are both suppressed by applied $c$-axis fields. Upon applying pressure in zero magnetic field, there is a non-monotonic evolution of $T_{\\rm{N}}$, which decreases to 0.8 K at 2.3 GPa, before abruptly increasing to 1.5 K at 2.6 GPa. At higher pressures, $T_{\\rm{N}}$ has a weak pressure dependence, and vanishes near 5 GPa. Together with the high-pressure phase being more robust to applied fields, these results suggest two distinct antiferromagnetic phases in CePdIn, which are separated near 2.6 GPa, and this change may be driven by the evolution of the underlying electronic structure due to enhanced Kondo hybridization under pressure."}
{"id": "2512.22576", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.22576", "abs": "https://arxiv.org/abs/2512.22576", "authors": ["Matteo Crispino", "Niklas Witt", "Stefan Enzner", "Tommaso Gorni", "Luca de' Medici", "Domenico Di Sante", "Giorgio Sangiovanni"], "title": "Tunable Electronic Correlations in 135-Kagome Metals", "comment": "12 pages, 8 figures", "summary": "Kagome metals exhibit rich correlated-electron physics, yet a systematic understanding of the degree of correlation across transition-metal species remains elusive. Using density-functional theory plus multi-orbital slave-spin mean-field theory, we investigate electronic correlations in the Ti-, V-, and Cr-based 135 compounds with Sb and Bi pnictogens. We find that the significantly stronger degree of correlation of the Cr-based materials compared to Ti and V can only be explained through the synergy of two effects: the larger electron filling of the $d$-shell and the reduced characteristic kinetic energy. We put forward that the substitution of Sb with Bi strengthens correlations in all compounds and make the prediction that the-yet-to-be-synthesized CsCr$_3$Bi$_5$ must be the most strongly correlated member of the entire family. These findings provide a quantitative, band-structure-based framework for understanding and predicting correlation strength in Kagome metals."}
{"id": "2512.22163", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22163", "abs": "https://arxiv.org/abs/2512.22163", "authors": ["Gard Olav Helle", "Tommaso Benacchio", "Anna Bomme Ousager", "Jørgen Ellegaard Andersen"], "title": "A quantum advection-diffusion solver using the quantum singular value transform", "comment": "43 pages, 8 figures", "summary": "We present a quantum algorithm for the simulation of the linear advection-diffusion equation based on block encodings of high order finite-difference operators and the quantum singular value transform. Our complexity analysis shows that the higher order methods significantly reduce the number of gates and qubits required to reach a given accuracy. The theoretical results are supported by numerical simulations of one- and two-dimensional benchmarks."}
{"id": "2512.22548", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2512.22548", "abs": "https://arxiv.org/abs/2512.22548", "authors": ["Bomont Jean-Marc", "Bretonnet Jean-Louis", "Costa Dino", "Pastore Giorgio"], "title": "Structural changes in the Lennard-Jones supercooled liquid and ideal glass: an improved integral equation for the replica method", "comment": null, "summary": "Framing the glass formation within standard statistical mechanics is an outstanding problem of condensed matter theory. To provide new insight, we investigate the structural properties of the Lennard-Jones fluid in the very-low temperature regime, by using a replicated version of the refined HMSA theory of the liquid state, combined with an appropriate split of the pair potential [Bomont and Bretonnet, J. Chem. Phys. 114, 4141 (2001)]. Our scheme allows one to reach an unprecedented low-temperature domain within both the supercooled liquid and the ideal-glass phase. Therein, a density-dependent temperature is identified, whereupon the radial distribution function experiences clear-cut structural changes, insofar as an additional peak develops in between the main and the second peaks. Such a structural feature points to a local structure of the Lennard-Jones ideal glass with an fcc-like short-range order, in the absence of any long-range order."}
{"id": "2512.22348", "categories": ["cs.SI", "cs.CY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.22348", "abs": "https://arxiv.org/abs/2512.22348", "authors": ["Aleksandar Tomašević", "Ana Vranić", "Aleksandra Alorić", "Marija Mitrović Dankulov"], "title": "Reddit Deplatforming and Toxicity Dynamics on Generalist Voat Communities", "comment": null, "summary": "Deplatforming, the permanent banning of entire communities, is a primary tool for content moderation on mainstream platforms. While prior research examines effects on banned communities or source platform health, the impact on alternative platforms that absorb displaced users remains understudied. We analyze four major Reddit ban waves (2015--2020) and their effects on generalist communities on Voat, asking how post-ban arrivals reshape community structure and through what mechanisms transformation occurs. Combining network analysis, toxicity detection, and dynamic reputation modeling, we identify two distinct regimes of migration impact: (1) Hostile Takeover (2015--2018), where post-ban arrival cohorts formed parallel social structures that bypassed existing community cores through sheer volume, and (2) Toxic Equilibrium (2018--2020), where the flattening of existing user hierarchy enabled newcomers to integrate into the now-dominant toxic community. Crucially, community transformation occurred through peripheral dynamics rather than hub capture: fewer than 5% of newcomers achieved central positions in most months, yet toxicity doubled. Migration structure also shaped outcomes: loosely organized communities dispersed into generalist spaces, while ideologically cohesive groups concentrated in dedicated enclaves. These findings suggest that receiving platforms face a narrow intervention window during the hostile takeover phase, after which toxic norms become self-sustaining."}
{"id": "2512.23640", "categories": ["q-fin.ST", "econ.TH"], "pdf": "https://arxiv.org/pdf/2512.23640", "abs": "https://arxiv.org/abs/2512.23640", "authors": ["Siqi Shao", "Arshia Ghasemi", "Hamed Farahani", "R. A. Serota"], "title": "Broken Symmetry of Stock Returns - a Modified Jones-Faddy Skew t-Distribution", "comment": "19 pages, 19 figures, 2 tables", "summary": "We argue that negative skew and positive mean of the distribution of stock returns are largely due to the broken symmetry of stochastic volatility governing gains and losses. Starting with stochastic differential equations for stock returns and for stochastic volatility we argue that the distribution of stock returns can be effectively split in two - for gains and losses - assuming difference in parameters of their respective stochastic volatilities. A modified Jones-Faddy skew t-distribution utilized here allows to reflect this in a single organic distribution which tends to meaningfully capture this asymmetry. We illustrate its application on distribution of daily S&P500 returns, including analysis of its tails."}
{"id": "2512.22144", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22144", "abs": "https://arxiv.org/abs/2512.22144", "authors": ["Xiao Zhou", "Yuze Sun", "Jie Wu", "Xiaomeng Huang"], "title": "The Complete Anatomy of the Madden-Julian Oscillation Revealed by Artificial Intelligence", "comment": null, "summary": "Accurately defining the life cycle of the Madden-Julian Oscillation (MJO), the dominant mode of intraseasonal climate variability, remains a foundational challenge due to its propagating nature. The established linear-projection method (RMM index) often conflates mathematical artifacts with physical states, while direct clustering in raw data space is confounded by a \"propagation penalty.\" Here, we introduce an \"AI-for-theory\" paradigm to objectively discover the MJO's intrinsic structure. We develop a deep learning model, PhysAnchor-MJO-AE, to learn a latent representation where vector distance corresponds to physical-feature similarity, enabling objective clustering of MJO dynamical states. Clustering these \"MJO fingerprints\" reveals the first complete, six-phase anatomical map of its life cycle. This taxonomy refines and critically completes the classical view by objectively isolating two long-hypothesized transitional phases: organizational growth over the Indian Ocean and the northward shift over the Philippine Sea. Derived from this anatomy, we construct a new physics-coherent monitoring framework that decouples location and intensity diagnostics. This framework reduces the rates of spurious propagation and convective misplacement by over an order of magnitude compared to the classical index. Our work transforms AI from a forecasting tool into a discovery microscope, establishing a reproducible template for extracting fundamental dynamical constructs from complex systems."}
{"id": "2512.22347", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22347", "abs": "https://arxiv.org/abs/2512.22347", "authors": ["Austin Cooper", "Sean Meyn"], "title": "Reinforcement Learning for Optimal Stopping in POMDPs with Application to Quickest Change Detection", "comment": "24 pages, 9 figures. To appear, IEEE Trans. Auto. Control", "summary": "The field of quickest change detection (QCD) focuses on the design and analysis of online algorithms that estimate the time at which a significant event occurs. In this paper, design and analysis are cast in a Bayesian framework, where QCD is formulated as an optimal stopping problem with partial observations. An approximately optimal detection algorithm is sought using techniques from reinforcement learning. The contributions of the paper are summarized as follows: (i) A Q-learning algorithm is proposed for the general partially observed optimal stopping problem. It is shown to converge under linear function approximation, given suitable assumptions on the basis functions. An example is provided to demonstrate that these assumptions are necessary to ensure algorithmic stability. (ii) Prior theory motivates a particular choice of features in applying Q-learning to QCD. It is shown that, in several scenarios and under ideal conditions, the resulting class of policies contains one that is approximately optimal. (iii) Numerical experiments show that Q-learning consistently produces policies that perform close to the best achievable within the chosen function class."}
{"id": "2512.22126", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.22126", "abs": "https://arxiv.org/abs/2512.22126", "authors": ["Svyatoslav Covanov", "Cedric Pradalier"], "title": "Validation methodology on real data of reversible Kalman Filter for state estimation with Manifold", "comment": null, "summary": "This work extends a previous study that introduced an algorithm for state estimation on manifolds within the framework of the Kalman filter. Its objective is to address the limitations of the earlier approach. The reversible Kalman filter was designed to provide a methodology for evaluating the accuracy of existing Kalman filter variants with arbitrary precision on synthetic data. It has favorable numerical properties on synthetic data, achieving arbitrary precision without relying on the small-velocity assumption and depending only on sensor noise. However, its application to real data encountered difficulties related to measurement noise, which was mitigated using a heuristic. In particular, the heuristic involved an event detection step switching between reversible Kalman filter and classical Kalman variant at chosen moments. In the present work, we propose a study of this detection step and propose a methodology to prove at which moment the reversible Kalman approach improves on classical multiplicative variant. In particular, we propose a metric allowing one to discriminate situations in real-world scenarios where it behaves better than classical approach."}
{"id": "2512.22126", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.22126", "abs": "https://arxiv.org/abs/2512.22126", "authors": ["Svyatoslav Covanov", "Cedric Pradalier"], "title": "Validation methodology on real data of reversible Kalman Filter for state estimation with Manifold", "comment": null, "summary": "This work extends a previous study that introduced an algorithm for state estimation on manifolds within the framework of the Kalman filter. Its objective is to address the limitations of the earlier approach. The reversible Kalman filter was designed to provide a methodology for evaluating the accuracy of existing Kalman filter variants with arbitrary precision on synthetic data. It has favorable numerical properties on synthetic data, achieving arbitrary precision without relying on the small-velocity assumption and depending only on sensor noise. However, its application to real data encountered difficulties related to measurement noise, which was mitigated using a heuristic. In particular, the heuristic involved an event detection step switching between reversible Kalman filter and classical Kalman variant at chosen moments. In the present work, we propose a study of this detection step and propose a methodology to prove at which moment the reversible Kalman approach improves on classical multiplicative variant. In particular, we propose a metric allowing one to discriminate situations in real-world scenarios where it behaves better than classical approach."}
{"id": "2512.22421", "categories": ["math.NA", "cs.LG", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.22421", "abs": "https://arxiv.org/abs/2512.22421", "authors": ["Zihan Lin", "QiZhi He"], "title": "Differentiable Inverse Modeling with Physics-Constrained Latent Diffusion for Heterogeneous Subsurface Parameter Fields", "comment": "33 pages, 16 figures", "summary": "We present a latent diffusion-based differentiable inversion method (LD-DIM) for PDE-constrained inverse problems involving high-dimensional spatially distributed coefficients. LD-DIM couples a pretrained latent diffusion prior with an end-to-end differentiable numerical solver to reconstruct unknown heterogeneous parameter fields in a low-dimensional nonlinear manifold, improving numerical conditioning and enabling stable gradient-based optimization under sparse observations. The proposed framework integrates a latent diffusion model (LDM), trained in a compact latent space, with a differentiable finite-volume discretization of the forward PDE. Sensitivities are propagated through the discretization using adjoint-based gradients combined with reverse-mode automatic differentiation. Inversion is performed directly in latent space, which implicitly suppresses ill-conditioned degrees of freedom while preserving dominant structural modes, including sharp material interfaces. The effectiveness of LD-DIM is demonstrated using a representative inverse problem for flow in porous media, where heterogeneous conductivity fields are reconstructed from spatially sparse hydraulic head measurements. Numerical experiments assess convergence behavior and reconstruction quality for both Gaussian random fields and bimaterial coefficient distributions. The results show that LD-DIM achieves consistently improved numerical stability and reconstruction accuracy of both parameter fields and corresponding PDE solutions compared with physics-informed neural networks (PINNs) and physics-embedded variational autoencoder (VAE) baselines, while maintaining sharp discontinuities and reducing sensitivity to initialization."}
{"id": "2512.22658", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "cond-mat.quant-gas", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2512.22658", "abs": "https://arxiv.org/abs/2512.22658", "authors": ["Gang v. Chen", "Congjun Wu"], "title": "Orbital homology of p and t2g orbitals in models and materials", "comment": "12 pages, 8 figures. A little review", "summary": "The nominal divide between $p$- and $d$-electron systems often obscures a deep underlying unity in condensed matter physics. This review elucidates the orbital homology between the $p$ and $t_{2g}$ orbital manifolds, establishing the correspondence that extends from minimal model Hamiltonians to the complex behaviors of real quantum materials. We demonstrate that despite their distinct atomic origins, these orbitals host nearly identical hopping physics and spin-orbit coupling, formalized through an effective ${l=1}$ angular momentum algebra for the $t_{2g}$ case. This equivalence allows one to transpose physical intuition and theoretical models developed for $p$-orbital systems directly onto the more complex $t_{2g}$ materials, and vice versa. We showcase how this paradigm provides a unified understanding of emergent phenomena, including non-trivial band topology, itinerant ferromagnetism, and unconventional superconductivity, across a wide range of platforms, from transition metal compounds, two-dimensional oxide heterostructures, and iron-based superconductors, to $p$-orbital ultracold gases. Ultimately, this $p$-$t_{2g}$ homology serves not only as a tool for interpretation but also as a robust design principle for engineering novel quantum states."}
{"id": "2512.22169", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.22169", "abs": "https://arxiv.org/abs/2512.22169", "authors": ["M. Süzen"], "title": "Wigner Cat Phases: A finely tunable system for exploring the transition to quantum chaos", "comment": "10 pages, 4 figures", "summary": "The transition to chaos for quantum dynamics is quantified via a finely tunable mixed random matrix ensemble. The {\\it mixed Gaussian Orthogonal Ensemble (mGOE)} forms a pedagogically accessible family of systems in simulating {\\it Many-Body Localization (MBL)} transitions. It can be tuned from chaotic to localized and heavy-tailed localized phases in a continuous fashion, providing an opportunity to explore new phases. We numerically study how the spectral properties of mGOE evolve during these transitions. Characterization of transition to quantum chaos is computed and analyzed via empirical spectral density, nearest-neighbor spacing, and adjacent gap ratios with statistical uncertainty quantifications that strengthens the robustness of evidence of transitions. The transition is identified as {\\it Wigner Cat Phases}, because of the shape of empirical spectral densities, which depens on the tuneable parameter. These simulated phases in mGOE appear to be an ideal tool to study {\\it Eigenstate Thermalization Hypothesis (ETH)} and its related transitions, representing a family of physical systems under different localisation and disorder strengths."}
{"id": "2512.22826", "categories": ["cond-mat.stat-mech", "physics.comp-ph", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.22826", "abs": "https://arxiv.org/abs/2512.22826", "authors": ["Aryan Tyagi", "Soumyajyoti Biswas", "Anirban Chakraborti"], "title": "Active-Absorbing Phase Transitions in the Parallel Minority Game", "comment": "6 pages, 3 figures", "summary": "The Parallel Minority Game (PMG) is a synchronous adaptive multi-agent model that exhibits active-absorbing transitions characteristic of non-equilibrium statistical systems. We perform a comprehensive numerical study of the PMG under two families of microscopic decision rules: (i) agents update their choices based on instantaneous population in their alternative choices, and (ii) threshold-based activation that activates agents movement only after overcrowding density crossing a threshold. We measure time-dependent and steady state limits of activity $A(t)$, overcrowding fraction $F(t)$ as functions of the control parameter $g=N/D$, where $N$ is the number of agents and $D$ is the total number of sites. Instantaneous rules display mean-field directed-percolation (MF-DP) scaling with $β\\approx1.00$, $δ\\approx0.5$, and $ν_{\\parallel}\\approx2.0$. Threshold rules, however, produce a distinct non-mean-field universality class with $β\\approx0.75$ and a systematic failure of MF-DP dynamical scaling. We show that thresholding acts as a relevant perturbation to DP. The results highlight how minimal cognitive features at the agent level fundamentally alter large-scale critical behaviour in socio-economic and active systems."}
{"id": "2512.23355", "categories": ["cs.SI", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.23355", "abs": "https://arxiv.org/abs/2512.23355", "authors": ["Ágnes Backhausz", "Villő Csiszár", "Balázs Csegő Kolok", "Damján Tárkányi", "András Zempléni"], "title": "A new adaptive two-layer model for opinion spread in hypergraphs: parameter sensitivity and estimation", "comment": "21 pages, 12 figures", "summary": "When opinion spread is studied, peer pressure is often modeled by interactions of more than two individuals (higher-order interactions). In our work, we introduce a two-layer random hypergraph model, in which hyperedges represent households and workplaces. Within this overlapping, adaptive structure, individuals react if their opinion is in majority in their groups. The process evolves through random steps: individuals can either change their opinion, or quit their workplace and join another one in which their opinion belongs to the majority. Based on computer simulations, our first goal is to describe the effect of the parameters responsible for the probability of changing opinion and quitting workplace on the homophily and speed of polarization. We also analyze the model as a Markov chain, and study the frequency of the absorbing states. Then, we quantitatively compare how different statistical and machine learning methods, in particular, linear regression, xgboost and a convolutional neural network perform for estimating these probabilities, based on partial information from the process, for example, the distribution of opinion configurations within households and workplaces. Among other observations, we conclude that all methods can achieve the best results under appropriate circumstances, and that the amount of information that is necessary to provide good results depends on the strength of the peer pressure effect."}
{"id": "2512.22152", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22152", "abs": "https://arxiv.org/abs/2512.22152", "authors": ["Daria Botvynko", "Pierre Haslée", "Lucile Gaultier", "Bertrand Chapron", "Clement de Boyer Montégut", "Anass El Aouni", "Julien Le Sommer", "Ronan Fablet"], "title": "Neural ocean forecasting from sparse satellite-derived observations: a case-study for SSH dynamics and altimetry data", "comment": null, "summary": "We present an end-to-end deep learning framework for short-term forecasting of global sea surface dynamics based on sparse satellite altimetry data. Building on two state-of-the-art architectures: U-Net and 4DVarNet, originally developed for image segmentation and spatiotemporal interpolation respectively, we adapt the models to forecast the sea level anomaly and sea surface currents over a 7-day horizon using sequences of sparse nadir altimeters observations. The model is trained on data from the GLORYS12 operational ocean reanalysis, with synthetic nadir sampling patterns applied to simulate realistic observational coverage. The forecasting task is formulated as a sequence-to-sequence mapping, with the input comprising partial sea level anomaly (SLA) snapshots and the target being the corresponding future full-field SLA maps. We evaluate model performance using (i) normalized root mean squared error (nRMSE), (ii) averaged effective resolution, (iii) percentage of correctly predicted velocities magnitudes and angles, and benchmark results against the operational Mercator Ocean forecast product. Results show that end-to-end neural forecasts outperform the baseline across all lead times, with particularly notable improvements in high variability regions. Our framework is developed within the OceanBench benchmarking initiative, promoting reproducibility and standardized evaluation in ocean machine learning. These results demonstrate the feasibility and potential of end-to-end neural forecasting models for operational oceanography, even in data-sparse conditions."}
{"id": "2512.22419", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22419", "abs": "https://arxiv.org/abs/2512.22419", "authors": ["Mohannad Alkhraijah", "Devon Sigler", "Daniel K. Molzahn"], "title": "A Decomposition Method for Solving Sensitivity-Based Distributed Optimal Power Flow", "comment": null, "summary": "Efficiently solving large-scale optimal power flow (OPF) problems is challenging due to the high dimensionality and interconnectivity of modern power systems. Decomposition methods offer a promising solution via partitioning large problems into smaller subproblems that can be solved in parallel, often with local information. These approaches reduce computational burden and improve flexibility by allowing agents to manage their local models. This article introduces a decomposition method that enables a distributed solution to OPF problems. The proposed method solves OPF problems with a sensitivity-based formulation using the alternating direction method of multipliers (ADMM) algorithm. We also propose a distributed method to compute system-wide sensitivities without sharing local parameters. This approach facilitates scalable optimization while satisfying global constraints and limiting data sharing. We demonstrate the effectiveness of the proposed approach using a large set of test systems and compare its performance against existing decomposition methods. The results show that the proposed method significantly outperforms the typical phase-angle formulation with a 14-times faster computation speed on average."}
{"id": "2512.22639", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22639", "abs": "https://arxiv.org/abs/2512.22639", "authors": ["Irched Chafaa", "Giacomo Bacci", "Luca Sanguinetti"], "title": "Tree Meets Transformer: A Hybrid Architecture for Scalable Power Allocation in Cell-Free Networks", "comment": null, "summary": "Power allocation remains a fundamental challenge in wireless communication networks, particularly under dynamic user loads and large-scale deployments. While Transformerbased models have demonstrated strong performance, their computational cost scales poorly with the number of users. In this work, we propose a novel hybrid Tree-Transformer architecture that achieves scalable per-user power allocation. Our model compresses user features via a binary tree into a global root representation, applies a Transformer encoder solely to this root, and decodes per-user uplink and downlink powers through a shared decoder. This design achieves logarithmic depth and linear total complexity, enabling efficient inference across large and variable user sets without retraining or architectural changes. We evaluate our model on the max-min fairness problem in cellfree massive MIMO systems and demonstrate that it achieves near-optimal performance while significantly reducing inference time compared to full-attention baselines."}
{"id": "2512.22639", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22639", "abs": "https://arxiv.org/abs/2512.22639", "authors": ["Irched Chafaa", "Giacomo Bacci", "Luca Sanguinetti"], "title": "Tree Meets Transformer: A Hybrid Architecture for Scalable Power Allocation in Cell-Free Networks", "comment": null, "summary": "Power allocation remains a fundamental challenge in wireless communication networks, particularly under dynamic user loads and large-scale deployments. While Transformerbased models have demonstrated strong performance, their computational cost scales poorly with the number of users. In this work, we propose a novel hybrid Tree-Transformer architecture that achieves scalable per-user power allocation. Our model compresses user features via a binary tree into a global root representation, applies a Transformer encoder solely to this root, and decodes per-user uplink and downlink powers through a shared decoder. This design achieves logarithmic depth and linear total complexity, enabling efficient inference across large and variable user sets without retraining or architectural changes. We evaluate our model on the max-min fairness problem in cellfree massive MIMO systems and demonstrate that it achieves near-optimal performance while significantly reducing inference time compared to full-attention baselines."}
{"id": "2512.22567", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.22567", "abs": "https://arxiv.org/abs/2512.22567", "authors": ["Francesco Romor", "Federico Pichi", "Giovanni Stabile", "Gianluigi Rozza", "Christoph Schwab"], "title": "ROM for Viscous, Incompressible Flow in Polygons -- exponential $n$-width bounds and convergence rate", "comment": null, "summary": "We demonstrate exponential convergence of Reduced Order Model (ROM) approximations for mixed boundary value problems of the stationary, incompressible Navier-Stokes equations in plane, polygonal domains $Ω$. Admissible boundary conditions comprise mixed BCs, no-slip, slip and open boundary conditions, subject to corner-weighted analytic boundary data and volume forcing. The small data hypothesis is assumed to ensure existence of a unique weak solution in the sense of Leray-Hopf. Recent results on corner-weighted, analytic regularity of velocity and pressure fields in $Ω$, imply exponential convergence rates of so-called mixed $hp$-Finite Element Methods in $H^1(Ω)^2\\times L^2(Ω)$ on sequences of geometric partitions of $Ω$, with corner-refinement. Based on these exponential convergence rate bounds, we infer exponential bounds for the Kolmogorov $n$-widths of solution sets for analytic forcing and boundary data. This implies corresponding exponential convergence rates of POD Galerkin methods that are based on truth solutions which are obtained offline from low-order, divergence stable mixed Finite Element discretizations. Numerical experiments confirm the exponential rates and the theoretical results."}
{"id": "2512.22368", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2512.22368", "abs": "https://arxiv.org/abs/2512.22368", "authors": ["Raúl A. Briceño"], "title": "Introduction to Lattice Field Theory", "comment": "14 pages, 2 figures, version to be published in the Encyclopedia of Particle Physics", "summary": "This chapter provides a pedagogical introduction to lattice quantum field theory, with strong emphasis on lattice quantum chromodynamics. The chapter reviews key foundational concepts of lattice quantum chromodynamics, as well as a broad summary of ongoing research in the field."}
{"id": "2512.22555", "categories": ["cs.CE", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.22555", "abs": "https://arxiv.org/abs/2512.22555", "authors": ["Fynn Jerome Aschmoneit", "Bastiaan Cockx"], "title": "Volume and Surface Area of two Orthogonal, Partially Intersecting Cylinders: A Generalization of the Steinmetz Solid", "comment": null, "summary": "The intersection of two orthogonal cylinders represents a classical problem in computational geometry with direct applications to engineering design, manufacturing, and numerical simulation. While analytical solutions exist for the fully intersecting case, the Steinmetz solid, partial intersections with arbitrary depth ratios require numerical methods or approximations. This work presents general integral expressions for both the intersection volume and surface area as explicit functions of the intersection depth. Accompanying these exact formulations are empirical approximation functions, which provide closed-form evaluations with relative errors below 15% across the full range of intersection depth. Validation against Quasi-Monte Carlo simulation confirms the accuracy of both the analytical and approximate solutions."}
{"id": "2512.22540", "categories": ["physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22540", "abs": "https://arxiv.org/abs/2512.22540", "authors": ["David Nolland"], "title": "Determinism and Indeterminism as Model Artefacts: Toward a Model-Invariant Ontology of Physics", "comment": "32 pages", "summary": "This paper argues that the traditional opposition between determinism and indeterminism in physics is representational rather than ontological. Deterministic--stochastic dualities are available in principle, and arise in a non-contrived way in many scientifically important models. When dynamical systems admit mathematically equivalent deterministic and stochastic formulations, their observable predictions depend only on the induced structure of correlations between preparations and measurement outcomes. I use this model-equivalence to motivate a model-invariance criterion for ontological commitment, according to which only structural features that remain stable across empirically equivalent representations, and whose physical effects are invariant under such reformulations, are candidates for realism. This yields a fallibilist form of structural realism grounded in modal robustness rather than in the specifics of any given mathematical representation. Features such as conservation laws, symmetries, and causal or metric structure satisfy this criterion and can be encoded in observable relations in mathematically intelligible ways. By contrast, the localisation of modal selection -- whether in initial conditions, stochastic outcomes, or informational collapse mechanisms -- is not invariant under empirically equivalent reformulations and is therefore best understood as a gauge choice rather than an ontological feature. The resulting framework explains how certain long-standing problems in the foundations of physics, including the measurement problem and the perceived conflict between physical determinism and free agency, arise from the reification of representational artefacts. By distinguishing model-invariant structure from modelling conventions, I offer a realist ontology for modern physics that combines empirical openness with resistance to metaphysical overreach."}
{"id": "2512.22596", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.22596", "abs": "https://arxiv.org/abs/2512.22596", "authors": ["Takuma Narizuka", "Issei Yamazaki"], "title": "Evaluating Soccer Player Movements Using the Attacker-Defender Model", "comment": "This paper is a revised version of the proceedings paper presented at MathSport International Conference 2025, pp. 124--129", "summary": "The present study investigates the attacker-defender (AD) model proposed by Brink et al. (2023), a motion model that describes the interactions between a ball carrier (attacker) and the nearest defender during ball possession. The model is based on the equations of motion for both players, incorporating resistance, goal-oriented force, and opponent-oriented force. It generates trajectories based on physically interpretable parameters. Although the AD model reproduces real dribbling trajectories well, previous studies have explored only a limited range of parameter values and relied on relatively small datasets.\n  This study aims to (1) enhance parameter optimization by solving the AD model for one player with the opponent's actual trajectory fixed, (2) validate the model's applicability to a large dataset from 306 J1-League matches, and (3) demonstrate distinct playing styles of attackers and defenders based on the full range of optimized parameters."}
{"id": "2512.22783", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2512.22783", "abs": "https://arxiv.org/abs/2512.22783", "authors": ["Chen Zhang", "Lixing Chen", "Qi-Yi Wu", "Congcong Le", "Xianxin Wu", "Hao Liu", "Bo Chen", "Ying Zhou", "Zhong-Tuo Fu", "Chun-Hui Lv", "Zi-Jie Xu", "Hai-Long Deng", "Enkang Zhang", "Yinghao Zhu", "H. Y. Liu", "Yu-Xia Duan", "Jun Zhao", "Jian-Qiao Meng"], "title": "Lattice-Entangled Density Wave Instability and Nonthermal Melting in La$_4$Ni$_3$O$_{10}$", "comment": "5 pages, 4 figures", "summary": "The recent discovery of high-temperature superconductivity in pressurized nickelates has renewed interest in the broken-symmetry states of their ambient-pressure parent phases, where a density-wave (DW) order emerges and competes with superconductivity, but its microscopic origin remains unresolved. Using ultrafast optical spectroscopy, we track quasiparticle relaxation dynamics across the DW transition at $T_{\\rm DW} \\approx$ 136 K in trilayer nickelate La$_4$Ni$_3$O$_{10}$ single crystals, revealing the opening of an energy gap of $\\sim$ 52 meV. Multiple coherent phonons, including $A_g$ modes near 3.88, 5.28, and 2.09 THz, display pronounced mode-selective anomalies across the transition, demonstrating that the DW is coupled with lattice degree of freedom stabilized through electron-phonon coupling. At higher excitation densities, the DW is nonthermally suppressed, producing a temperature-fluence phase diagram that parallels pressure-tuned behavior. These results establish the DW in La$_4$Ni$_3$O$_{10}$ as a lattice-entangled instability involving multiple phonon modes, and highlight ultrafast optical excitation as a powerful tool to manipulate competing orders in nickelates."}
{"id": "2512.22229", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.22229", "abs": "https://arxiv.org/abs/2512.22229", "authors": ["Shalender Singh", "Santosh Kumar"], "title": "Bell-Inequality Violation for Continuous, Non-Projective Measurements", "comment": "25 pages, 1 figure", "summary": "Many solid-state quantum platforms do not permit sharp, projective measurements but instead yield continuous voltage or field traces under weak, non-demolition readout. In such systems, standard Bell tests based on dichotomic projective measurements are not directly applicable, raising the question of how quantum nonlocality can be certified from continuous time-series data. Here we develop a general theoretical framework showing that Bell-CHSH inequality violation can be extracted from continuous, non-projective measurements without assuming any specific collapse model or phase distribution. We show that sufficiently long continuous measurements of a single entangled pair sample its internal phase-probability structure, enabling effective dichotomic observables to be constructed through phase-sensitive projections and coarse-graining. The resulting Bell correlator is governed by two experimentally accessible resources: intrinsic single-qubit phase spread and nonlocal phase locking between qubits. We benchmark the resulting estimator against conventional projective-measurement CHSH tests implemented via quantum-circuit simulations using Qiskit, finding quantitative agreement in the Bell-violating regime without parameter fitting. Classical deterministic correlations cannot violate the CHSH bound, whereas quantum phase-locked systems recover the nonlinear angular dependence characteristic of entanglement. Our results provide a practical route to demonstrating Bell nonlocality in platforms where measurements are inherently continuous and weak."}
{"id": "2512.22871", "categories": ["cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.22871", "abs": "https://arxiv.org/abs/2512.22871", "authors": ["Chuan-Tsung Chan", "Chan-Yi Chang", "Zhong-Tang Wu"], "title": "On the Cocycle Structure of the Boltzmann Distribution", "comment": "7 pages, no figure", "summary": "Based on a cocycle structure, we identify a new derivation of the Boltzmann distribution for finite energy-level systems from the maximal entropy principle (MEP). Our approach does not rely on the method of the Lagrange multiplier, and it provides a more transparent way to understand the dependence on the energy levels of the temperature $T = 1/β$ for the equilibrium distribution. Finally, we make two curious observations associated with our derivations."}
{"id": "2512.23400", "categories": ["cs.SI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23400", "abs": "https://arxiv.org/abs/2512.23400", "authors": ["Abd Ullah Khan", "Uman Khalid", "Muhammad Tanveer", "Trung Q. Duong", "Hyundong Shin"], "title": "Beyond-Diagonal Reconfigurable Intelligent Surfaces for 6G Networks: Principles, Challenges, and Quantum Horizons", "comment": null, "summary": "A beyond-diagonal reconfigurable intelligent surface (BD-RIS) is an innovative type of reconfigurable intelligent surface (RIS) that has recently been proposed and is considered a revolutionary advancement in wave manipulation. Unlike the mutually disconnected arrangement of elements in traditional RISs, BD-RIS creates cost-effective and simple inter-element connections, allowing for greater freedom in configuring the amplitude and phase of impinging waves. However, there are numerous underlying challenges in realizing the advantages associated with BD-RIS, prompting the research community to actively investigate cutting-edge schemes and algorithms in this direction. Particularly, the passive beamforming design for BD-RIS under specific environmental conditions has become a major focus in this research area. In this article, we provide a systematic introduction to BD-RIS, elaborating on its functional principles concerning architectural design, promising advantages, and classification. Subsequently, we present recent advances and identify a series of challenges and opportunities. Additionally, we consider a specific case study where beamforming is designed using four different algorithms, and we analyze their performance with respect to sum rate and computation cost. To augment the beamforming capabilities in 6G BD-RIS with quantum enhancement, we analyze various hybrid quantum-classical machine learning (ML) models to improve beam prediction performance, employing real-world communication Scenario 8 from the DeepSense 6G dataset. Consequently, we derive useful insights about the practical implications of BD-RIS."}
{"id": "2512.22499", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2512.22499", "abs": "https://arxiv.org/abs/2512.22499", "authors": ["Akshara Satheesh", "Rajib Chattopadhyay"], "title": "Emerging trend in the east-west Dipole Pattern in Indian Summer Monsoon Rainfall and the associated impact on Regional Dynamics", "comment": null, "summary": "Traditionally, during the monsoon season, more rainfall is received along the Western Ghats, the Northern Gangetic plains, the central belt, and northeast India. However, recently, there has been a shift in this canonical monsoon rainfall pattern on the monthly to seasonal scale. In this study, we quantify an east-west asymmetric trend in monthly to seasonal rainfall due to the increased rainfall over the northwestern part of the country. An Empirical Orthogonal Function (EOF) analysis has been performed to understand the spatial and temporal variation of the monsoon. EOF mode 3 shows such a distinct east-west dipole pattern, highlighting the existence of a modal feature representing the recent trend in the rainfall distribution. The physical nature of this mode is also established. The regression pattern of the rainfall anomalies to the Webster-Yang Index (Webster and Yang, 1992) exhibits a similar east-west pattern that further confirms the physical existence of this east-west rainfall modal dipole pattern. Since rainfall across the northwest is directly linked to the Arabian Sea and rainfall over the eastern region to the Bay of Bengal, the characteristics of these two regions are studied separately. Over the Arabian Sea, there is a significant negative trend in the Sea Level Pressure (SLP) anomalies and an increase in the specific humidity, causing greater moisture convergence. In contrast, over the Bay of Bengal, the SLP shows an increasing trend. The SST warming over the Arabian Sea is higher than that of the Bay of Bengal. Further, while investigating the zonal wind(u) at 850hPa, it shows an increasing trend along the northern branch that is more directed towards the northwestern part of the country. These factors together create dynamically favorable conditions for enhanced convection and thus receive more rainfall across the northwest compared to the northeast India."}
{"id": "2512.22512", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.22512", "abs": "https://arxiv.org/abs/2512.22512", "authors": ["Xingwu Zeng", "Can Zhang"], "title": "Small-time approximate controllability for the nonlinear complex Ginzburg-Landau equation with bilinear control", "comment": "26 pages", "summary": "In this paper, we consider the bilinear approximate controllability for the complex Ginzburg-Landau (CGL) equation with a power-type nonlinearity of any integer degree on a torus of arbitrary space dimension. Under a saturation hypothesis on the control operator, we show the small-time global controllability of the CGL equation. The proof is obtained by developing a multiplicative version of a geometric control approach, introduced by Agrachev and Sarychev in \\cite{AS05,AS06}."}
{"id": "2512.22646", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22646", "abs": "https://arxiv.org/abs/2512.22646", "authors": ["Kamil Hassan", "Henrik Sandberg"], "title": "On the Stealth of Unbounded Attacks Under Non-Negative-Kernel Feedback", "comment": "8 pages, 3 figures, submitted to IFAC World Congress 2026", "summary": "The stealth of false data injection attacks (FDIAs) against feedback sensors in linear time-varying (LTV) control systems is investigated. In that regard, the following notions of stealth are pursued: For some finite $ε> 0$, i) an FDIA is deemed $ε$-stealthy if the deviation it produces in the signal that is monitored by the anomaly detector remains $ε$-bounded for all time, and ii) the $ε$-stealthy FDIA is further classified as untraceable if the bounded deviation dissipates over time (asymptotically). For LTV systems that contain a chain of $q \\geq 1$ integrators and feedback controllers with non-negative impulse-response kernels, it is proved that polynomial (in time) FDIA signals of degree $a$ - growing unbounded over time - will remain i) $ε$-stealthy, for some finite $ε> 0$, if $a \\leq q$, and ii) untraceable, if $a < q$. These results are obtained using the theory of linear Volterra integral equations."}
{"id": "2512.22646", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22646", "abs": "https://arxiv.org/abs/2512.22646", "authors": ["Kamil Hassan", "Henrik Sandberg"], "title": "On the Stealth of Unbounded Attacks Under Non-Negative-Kernel Feedback", "comment": "8 pages, 3 figures, submitted to IFAC World Congress 2026", "summary": "The stealth of false data injection attacks (FDIAs) against feedback sensors in linear time-varying (LTV) control systems is investigated. In that regard, the following notions of stealth are pursued: For some finite $ε> 0$, i) an FDIA is deemed $ε$-stealthy if the deviation it produces in the signal that is monitored by the anomaly detector remains $ε$-bounded for all time, and ii) the $ε$-stealthy FDIA is further classified as untraceable if the bounded deviation dissipates over time (asymptotically). For LTV systems that contain a chain of $q \\geq 1$ integrators and feedback controllers with non-negative impulse-response kernels, it is proved that polynomial (in time) FDIA signals of degree $a$ - growing unbounded over time - will remain i) $ε$-stealthy, for some finite $ε> 0$, if $a \\leq q$, and ii) untraceable, if $a < q$. These results are obtained using the theory of linear Volterra integral equations."}
{"id": "2512.22708", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.22708", "abs": "https://arxiv.org/abs/2512.22708", "authors": ["A. Durán", "N. Reguera"], "title": "A high-order method for the numerical approximation of fractional nonlinear Schrödinger equations", "comment": null, "summary": "In this paper, the periodic initial-value problem for the fractional nonlinear Schrödinger (fNLS) equation is discretized in space by a Fourier spectral Galerkin method and in time by diagonally implicit, high-order Runge-Kutta schemes, based on the composition with the implicit midpoint rule (IMR). Some properties and error estimates for the semidiscretization in space and for the full discretization are proved. The convergence results and the general performance of the scheme are illustrated with several numerical experiments."}
{"id": "2512.22609", "categories": ["hep-lat", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.22609", "abs": "https://arxiv.org/abs/2512.22609", "authors": ["Tatsuhiro Misumi"], "title": "Minimal-doubling and single-Weyl Hamiltonians", "comment": "28 pages", "summary": "We develop a systematic Hamiltonian formulation of minimally doubled lattice fermions in (3+1) dimensions, derive their nodal structures (structures of zeros), and classify their symmetry patterns for both four-component Dirac and two-component Weyl constructions. Motivated by recent single-Weyl proposals based on Bogoliubov-de Gennes (BdG) representation, we argue that the corresponding single-Weyl Hamiltonians are obtained from the minimal-doubling Hamiltonians supplemented by an appropriate species-splitting mass term, and we re-examine the non-onsite symmetry protecting the physical Weyl node in terms of a Ginsparg-Wilson-type relation. We then construct a one-parameter family of deformations that preserves all the symmetries and demonstrate that, once the parameter exceeds a critical value, additional Weyl nodes emerge and the system exits the single-node regime. This indicates that in interacting theories radiative corrections can generate symmetry-allowed counterterms, so maintaining the desired single-Weyl phase generically requires \"moderate\" parameter tuning."}
{"id": "2512.23027", "categories": ["cs.CE", "cs.DC", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.23027", "abs": "https://arxiv.org/abs/2512.23027", "authors": ["Sudhi Sharma Padillath Vasudevan"], "title": "A Domain Decomposition-based Solver for Acoustic Wave propagation in Two-Dimensional Random Media", "comment": "29 pages, 55 figures. Based on the author's thesis submitted to Carleton University (2023). This research was performed while the author was at the Department of Civil and Environmental Engineering, Carleton University", "summary": "An acoustic wave propagation problem with a log normal random field approximation for wave speed is solved using a sampling-free intrusive stochastic Galerkin approach. The stochastic partial differential equation with the inputs and outputs expanded using polynomial chaos expansion (PCE) is transformed into a set of deterministic PDEs and further to a system of linear equations. Domain decomposition (DD)-based solvers are utilized to handle the overwhelming computational cost for the resulting system with increasing mesh size, time step and number of random parameters. A conjugate gradient iterative solver with a two-level Neumann-Neumann preconditioner is applied here showing their efficient scalabilities."}
{"id": "2512.22618", "categories": ["physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2512.22618", "abs": "https://arxiv.org/abs/2512.22618", "authors": ["Tim Maudlin"], "title": "Actual Physics, Observation, and Quantum Theory", "comment": "Forthcoming in How to Understand Quantum Mechanics? 100 Years of Ongoing Interpretation, Eds. J. Faye and L. Johansson, Springer. 33 pages", "summary": "Since its inception, quantum theory has been the subject of fierce interpretive controversy, which persists to this day. Disputed topics include the basic ontology and dynamics of the theory, the role (if any) of measurement, the meaning of probability, and the issue of non-locality. But there is yet another problem that has been largely ignored: how the theory makes contact with observational data. The problem is endemic to physics, and was discussed by Einstein in several places. In this essay, I discuss Einstein's general approach, how it applied to some quantum-mechanical phenomena, and why a central aspect of the solution might lead to novel and important new predictions."}
{"id": "2512.22348", "categories": ["cs.SI", "cs.CY", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.22348", "abs": "https://arxiv.org/abs/2512.22348", "authors": ["Aleksandar Tomašević", "Ana Vranić", "Aleksandra Alorić", "Marija Mitrović Dankulov"], "title": "Reddit Deplatforming and Toxicity Dynamics on Generalist Voat Communities", "comment": null, "summary": "Deplatforming, the permanent banning of entire communities, is a primary tool for content moderation on mainstream platforms. While prior research examines effects on banned communities or source platform health, the impact on alternative platforms that absorb displaced users remains understudied. We analyze four major Reddit ban waves (2015--2020) and their effects on generalist communities on Voat, asking how post-ban arrivals reshape community structure and through what mechanisms transformation occurs. Combining network analysis, toxicity detection, and dynamic reputation modeling, we identify two distinct regimes of migration impact: (1) Hostile Takeover (2015--2018), where post-ban arrival cohorts formed parallel social structures that bypassed existing community cores through sheer volume, and (2) Toxic Equilibrium (2018--2020), where the flattening of existing user hierarchy enabled newcomers to integrate into the now-dominant toxic community. Crucially, community transformation occurred through peripheral dynamics rather than hub capture: fewer than 5% of newcomers achieved central positions in most months, yet toxicity doubled. Migration structure also shaped outcomes: loosely organized communities dispersed into generalist spaces, while ideologically cohesive groups concentrated in dedicated enclaves. These findings suggest that receiving platforms face a narrow intervention window during the hostile takeover phase, after which toxic norms become self-sustaining."}
{"id": "2512.22162", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.22162", "abs": "https://arxiv.org/abs/2512.22162", "authors": ["Vladimir Vovk"], "title": "Exchangeability and randomness for infinite and finite sequences", "comment": "15 pages, 1 figure", "summary": "Randomness (in the sense of being generated in an IID fashion) and exchangeability are standard assumptions in nonparametric statistics and machine learning, and relations between them have been a popular topic of research. This note draws the reader's attention to the fact that, while for infinite sequences of observations the two assumptions are almost indistinguishable, the difference between them becomes very significant for finite sequences of a given length."}
{"id": "2512.23237", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.23237", "abs": "https://arxiv.org/abs/2512.23237", "authors": ["Yang Yu", "Lei Zhang", "Emanuel Gull", "Xiaodong Cao", "Xinyang Dong"], "title": "Multi-orbital dynamical mean-field theory with a complex-time solver", "comment": null, "summary": "We present the combination of a complex-time tensor-network impurity solver with an analytic continuation scheme based on exponential fitting as an efficient framework for single and multi-orbital dynamical mean-field calculations. By performing time-evolution along a complex-time contour, the approach balances computational cost with the difficulty of spectral recovery, offering greater flexibility than methods confined to the real or imaginary axis. By complementing the complex-time evolution with an exponential fitting scheme, we faithfully extract real-time information at negligible cost. The resulting method obtains high-resolution spectra at a significantly lower computational cost than real-time evolution, offering a promising tool for ab initio studies of strongly correlated materials."}
{"id": "2512.22232", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22232", "abs": "https://arxiv.org/abs/2512.22232", "authors": ["Deriyan Senjaya"], "title": "Non-Relativistic Quantum Particle Confined on a Cylindrical Surface under a Stark-like Potential", "comment": null, "summary": "This study explores the influence of a Stark-like perturbative potential on a quantum particle confined to a cylindrical surface (QPCS) and its implications for extra-dimensional theories. The QPCS framework is particularly relevant to Kaluza-Klein (KK) theory, which postulates extra spatial dimensions to unify electromagnetism and gravity. In KK theory, these extra dimensions are typically hidden and require high-energy conditions for detection. Motivated by the challenge of uncovering these dimensions more feasibly, this research applies a perturbative potential of the form \\hat{H}_{\\text{SL}} = βzV_{o_{z}}(θ) to a QPCS characterized by length \\textit{L} and radius R_{o}. This potential is inspired by the Stark effect in hydrogen atoms, where energy level splitting serves as an indicator of an external influence. The study demonstrates that, for a degenerate configuration (R_{o} = \\frac{L}π), the Stark-like perturbation effectively induces energy level splitting, which can be interpreted as a means of revealing hidden dimensions. The first-order energy correction in this scenario depends explicitly on the quantum numbers n_{z} and n_θ, highlighting the potential for this approach to probe extra-dimensional effects in lower-energy quantum systems."}
{"id": "2512.22890", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.22890", "abs": "https://arxiv.org/abs/2512.22890", "authors": ["Sosuke Ito", "Yoh Maekawa", "Ryuna Nagayama", "Andreas Dechant", "Kohei Yoshimura"], "title": "Geometric decomposition of information flow for overdamped Langevin systems and optimal transport in subsystems", "comment": "26 pages, 4 figures", "summary": "Information flow between subsystems is a central concept in information thermodynamics, which provides the second-law-like inequalities for subsystems. This paper discusses the geometric decomposition of information flow, which was introduced for Markov jump systems [Y Maekawa, R Nagayama, K Yoshimura and S Ito, arXiv:2509.21985 (2025)], and applies it to overdamped Langevin systems. For overdamped Langevin systems, the geometric decomposition of information flow into excess and housekeeping contributions is related to the conventional definition of the $2$-Wasserstein distance between marginal distributions in optimal transport theory. This formulation offers an optimal-transport interpretation of subsystem dynamics, and this optimal-transport formulation is simpler for overdamped Langevin systems than for general Markov jump systems. It is also possible to handle features that are specific to overdamped Langevin systems, such as representations based on the Koopman mode decomposition, as well as their relationship with the Fisher information matrix. As with the results for Markov jump systems, we generalize the second law of information thermodynamics using housekeeping and excess information flow, leading to the concept of excess and housekeeping demons. We also derive a thermodynamic uncertainty relation and an information-thermodynamic speed limit incorporating excess information flow. These results are illustrated for the Gaussian case, and we discuss the conditions under which the excess and housekeeping demons emerge."}
{"id": "2512.23622", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.23622", "abs": "https://arxiv.org/abs/2512.23622", "authors": ["Till Hoffmann", "Jukka-Pekka Onnela"], "title": "Information is localized in growing network models", "comment": "7 pages, 2 figures, 1 table", "summary": "Mechanistic network models can capture salient characteristics of empirical networks using a small set of domain-specific, interpretable mechanisms. Yet inference remains challenging because the likelihood is often intractable. We show that, for a broad class of growing network models, information about model parameters is localized in the network, i.e., the likelihood can be expressed in terms of small subgraphs. We take a Bayesian perspective to inference and develop neural density estimators (NDEs) to approximate the posterior distribution of model parameters using graph neural networks (GNNs) with limited receptive size, i.e., the GNN can only \"see\" small subgraphs. We characterize nine growing network models in terms of their localization and demonstrate that localization predictions agree with NDEs on simulated data. Even for non-localized models, NDEs can infer high-fidelity posteriors matching model-specific inference methods at a fraction of the cost. Our findings establish information localization as a fundamental property of network growth, theoretically justifying the analysis of local subgraphs embedded in larger, unobserved networks and the use of GNNs with limited receptive field for likelihood-free inference."}
{"id": "2512.22678", "categories": ["physics.ao-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.22678", "abs": "https://arxiv.org/abs/2512.22678", "authors": ["Eran Vos", "Peter Huybers", "Eli Tziperman"], "title": "Climate change alters teleconnections", "comment": "Accepted to GRL", "summary": "Internal modes of climate variability, such as El Niño and the North Atlantic Oscillation, can have strong influences upon distant weather patterns, effects that are referred to as \"teleconnections\". The extent to which anthropogenic climate change has and will continue to affect these teleconnections, however, remains uncertain. Here, we employ a covariance fingerprinting approach to demonstrate that shifts in teleconnection patterns affecting monthly temperatures between the periods 1960-1990 and 1990-2020 are attributable to anthropogenic forcing. We further apply multilinear regression to assess the regional contributions and statistical significance of changes in five key climate modes: the El Niño-Southern Oscillation, North Atlantic Oscillation, Southern Annular Mode, Indian Ocean Dipole, and the Pacific Decadal Oscillation. In many regions, observed changes exceed what would be expected from natural variability alone, further implicating an anthropogenic influence. Finally, we provide projections of how these teleconnections will alter in response to further changes in climate."}
{"id": "2512.22561", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22561", "abs": "https://arxiv.org/abs/2512.22561", "authors": ["N. Dinh", "M. A. Goberna", "D. H. Long", "M. Volle"], "title": "Robust generalized S-Procedure", "comment": "11 pages", "summary": "We introduce in this paper the so-called robust generalized S-procedure associated with a given robust optimization problem. We provide a primal characterization for the validity of this procedure as well as a dual characterization under the assumption that the decision space is locally convex. We also analyze an extension of the mentioned robust S-procedure that incorporates a right-hand side function."}
{"id": "2512.22668", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22668", "abs": "https://arxiv.org/abs/2512.22668", "authors": ["Arya Rashidinejad Meibodi", "Mahbod Gholamali Sinaki", "Khalil Alipour"], "title": "Optimal Regulation of Nonlinear Input-Affine Systems via an Integral Reinforcement Learning-Based State-Dependent Riccati Equation Approach", "comment": "Presented at the 13th RSI International Conference on Robotics and Mechatronics (ICRoM 2025), Dec. 16-18, 2025, Tehran, Iran", "summary": "The State-Dependent Riccati Equation (SDRE) technique generalizes the classical algebraic Riccati formulation to nonlinear systems by designing an input to the system that optimally(suboptimally) regulates system states toward the origin while simultaneously optimizing a quadratic performance index. In the SDRE technique, we solve the State-Dependent Riccati Equation to determine the control for regulating a nonlinear input-affine system. Since an analytic solution to SDRE is not straightforward, one method is to linearize the system at every state, solve the corresponding Algebraic Riccati Equation (ARE), and apply optimal control until the next state of the system. Completing this task with high frequency gives a result like the original SDRE technique. Both approaches require a complete model; therefore, here we propose a method that solves ARE in every state of the system using a partially model-free approach that learns optimal control in every state of the system, without explicit knowledge of the drift dynamics, based on Integral Reinforcement Learning (IRL). To show the effectiveness of our proposed approach, we apply it to the second-order nonlinear system in simulation and compare its performance with the classical SDRE method, which relies on the system's model and solves the ARE at each state. Our simulation results demonstrate that, with sufficient iterations, the IRL-based approach achieves approximately the same performance as the conventional SDRE method, demonstrating its capability as a reliable alternative for nonlinear system control that does not require an explicit environmental model. Index Terms-Algebraic Riccati Equation (ARE), Integral Reinforcement Learning (IRL), Nonlinear Input-Affine Systems, Optimal Regulation, State-Dependent Riccati Equation (SDRE)"}
{"id": "2512.22668", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22668", "abs": "https://arxiv.org/abs/2512.22668", "authors": ["Arya Rashidinejad Meibodi", "Mahbod Gholamali Sinaki", "Khalil Alipour"], "title": "Optimal Regulation of Nonlinear Input-Affine Systems via an Integral Reinforcement Learning-Based State-Dependent Riccati Equation Approach", "comment": "Presented at the 13th RSI International Conference on Robotics and Mechatronics (ICRoM 2025), Dec. 16-18, 2025, Tehran, Iran", "summary": "The State-Dependent Riccati Equation (SDRE) technique generalizes the classical algebraic Riccati formulation to nonlinear systems by designing an input to the system that optimally(suboptimally) regulates system states toward the origin while simultaneously optimizing a quadratic performance index. In the SDRE technique, we solve the State-Dependent Riccati Equation to determine the control for regulating a nonlinear input-affine system. Since an analytic solution to SDRE is not straightforward, one method is to linearize the system at every state, solve the corresponding Algebraic Riccati Equation (ARE), and apply optimal control until the next state of the system. Completing this task with high frequency gives a result like the original SDRE technique. Both approaches require a complete model; therefore, here we propose a method that solves ARE in every state of the system using a partially model-free approach that learns optimal control in every state of the system, without explicit knowledge of the drift dynamics, based on Integral Reinforcement Learning (IRL). To show the effectiveness of our proposed approach, we apply it to the second-order nonlinear system in simulation and compare its performance with the classical SDRE method, which relies on the system's model and solves the ARE at each state. Our simulation results demonstrate that, with sufficient iterations, the IRL-based approach achieves approximately the same performance as the conventional SDRE method, demonstrating its capability as a reliable alternative for nonlinear system control that does not require an explicit environmental model. Index Terms-Algebraic Riccati Equation (ARE), Integral Reinforcement Learning (IRL), Nonlinear Input-Affine Systems, Optimal Regulation, State-Dependent Riccati Equation (SDRE)"}
{"id": "2512.22831", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.22831", "abs": "https://arxiv.org/abs/2512.22831", "authors": ["Endre Süli", "Dennis Trautwein"], "title": "Convergent numerical schemes for the viscoelastic Giesekus model in two dimensions", "comment": null, "summary": "In this work, we develop a class of stable and convergent numerical methods for the approximate solution of the viscoelastic Giesekus model in two space dimensions. The model couples the incompressible Navier--Stokes equations with an evolution equation for an additional stress tensor accounting for elastic effects. This coupled evolution equation is stated here in terms of the elastic deformation gradient and models transport and nonlinear relaxation effects. In the existing literature, numerical schemes for such models often suffer from accuracy limitations and convergence problems, usually due to the lack of rigorous existence results or inherent limitations of the discretization. Therefore, our main goal is to prove the (subsequence) convergence of the proposed numerical method to a large-data global weak solution in two dimensions, without relying on cut-offs or additional regularization. This also provides an alternative proof of the recent existence result by Bulíček et al.~(Nonlinearity, 2022). Finally, we verify the practicality of the proposed method through numerical experiments, including convergence studies and typical benchmark problems."}
{"id": "2512.23417", "categories": ["hep-lat", "hep-ex", "hep-ph"], "pdf": "https://arxiv.org/pdf/2512.23417", "abs": "https://arxiv.org/abs/2512.23417", "authors": ["Navdeep Singh Dhindsa", "Debsubhra Chakraborty", "Archana Radhakrishnan", "Nilmani Mathur", "M. Padmanath"], "title": "Precisely determining the ground state mass of Spin-3/2 $Ω_{ccc}$ baryon from Lattice QCD", "comment": "10 pages, 3 figures, 2 tables, contribution to the 42nd International Symposium on Lattice Field Theory (LATTICE2025), 2-8 November 2025, Tata Institute of Fundamental Research, Mumbai, India", "summary": "We present the most precise determination to date of the ground-state masses of the triply charmed baryons with both parities, obtained by continuum extrapolation and fully addressing the systematic uncertainties. The calculations are performed on six $N_f=2+1+1$ HISQ ensembles, generated by the MILC collaboration, with two complementary setups for the valence charm action, one using the HISQ action and the other using the overlap fermion action. Our prediction for the mass of the lowest two triply charmed spin-3/2 baryons are: $M_{Ω_{ccc}} (3/2^{+}) = 4793 (5) \\left(^{+11}_{-8}\\right)$ MeV, and $M_{Ω_{ccc}} (3/2^{-}) = 5094 (12) \\left(^{+19}_{-17}\\right)$ MeV."}
{"id": "2512.22842", "categories": ["physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2512.22842", "abs": "https://arxiv.org/abs/2512.22842", "authors": ["Jan-Willem van Holten"], "title": "On Huygens' derivation of the laws of elastic collisions", "comment": "6 pages, no figures", "summary": "In this note I sketch the work of Christiaan Huygens to develop a theory of motion and its application to elastic collisions. In this theory he uses the relativity of uniform linear motion to derive the conservation of momentum and kinetic energy (at the time referred to as living force or vis viva). The conservation of living force was used subsequently by Leibniz as a basic general principle of dynamics, an alternative to that of Newton set forth in the Principia Mathematica."}
{"id": "2512.22826", "categories": ["cond-mat.stat-mech", "physics.comp-ph", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.22826", "abs": "https://arxiv.org/abs/2512.22826", "authors": ["Aryan Tyagi", "Soumyajyoti Biswas", "Anirban Chakraborti"], "title": "Active-Absorbing Phase Transitions in the Parallel Minority Game", "comment": "6 pages, 3 figures", "summary": "The Parallel Minority Game (PMG) is a synchronous adaptive multi-agent model that exhibits active-absorbing transitions characteristic of non-equilibrium statistical systems. We perform a comprehensive numerical study of the PMG under two families of microscopic decision rules: (i) agents update their choices based on instantaneous population in their alternative choices, and (ii) threshold-based activation that activates agents movement only after overcrowding density crossing a threshold. We measure time-dependent and steady state limits of activity $A(t)$, overcrowding fraction $F(t)$ as functions of the control parameter $g=N/D$, where $N$ is the number of agents and $D$ is the total number of sites. Instantaneous rules display mean-field directed-percolation (MF-DP) scaling with $β\\approx1.00$, $δ\\approx0.5$, and $ν_{\\parallel}\\approx2.0$. Threshold rules, however, produce a distinct non-mean-field universality class with $β\\approx0.75$ and a systematic failure of MF-DP dynamical scaling. We show that thresholding acts as a relevant perturbation to DP. The results highlight how minimal cognitive features at the agent level fundamentally alter large-scale critical behaviour in socio-economic and active systems."}
{"id": "2512.22403", "categories": ["math.ST", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.22403", "abs": "https://arxiv.org/abs/2512.22403", "authors": ["Chia-Yu Hsu", "Shubhanshu Shekhar"], "title": "Active Nonparametric Two-Sample Testing by Betting on Heterogeneous Data Sources", "comment": null, "summary": "We study the problem of active nonparametric sequential two-sample testing over multiple heterogeneous data sources. In each time slot, a decision-maker adaptively selects one of $K$ data sources and receives a paired sample generated from that source for testing. The goal is to decide as quickly as possible whether the pairs are generated from the same distribution or not. The gain achieved by such adaptive sampling (in terms of smaller expected stopping time or larger error exponents) has been well-characterized for parametric models via Chernoff's adaptive MLE selection rule [1]. However, analogous results are not known for the case of nonparametric problems, such as two-sample testing, where we place no restrictions on the distributions.\n  Our main contribution is a general active nonparametric testing procedure that combines an adaptive source-selecting strategy within the testing-by-betting framework of [2] that works under minimal distributional assumptions. In each time slot, our scheme proceeds by selecting a source according to a probability that mixes exploitation, favoring sources with the largest empirical distinguishability, and exploration via a vanishing greedy strategy. The (paired) observations so collected are then used to update the \"betting-wealth process\", which is a stochastic process guaranteed to be a nonnegative martingale under the null. The procedure stops and rejects the null when the wealth process exceeds an appropriate threshold; an event that is unlikely under the null. We show that our test controls the type-I error at a prespecified level-$α$ under the null, and establish its power-one property and a bound on its expected sample size under the alternative. Our results provide a precise characterization of the improvements achievable by a principled adaptive sampling strategy over its passive analog."}
{"id": "2512.22472", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.22472", "abs": "https://arxiv.org/abs/2512.22472", "authors": ["Wenhao Cui", "Jie Hu"], "title": "Random Subset Averaging", "comment": null, "summary": "We propose a new ensemble prediction method, Random Subset Averaging (RSA), tailored for settings with many covariates, particularly in the presence of strong correlations. RSA constructs candidate models via binomial random subset strategy and aggregates their predictions through a two-round weighting scheme, resulting in a structure analogous to a two-layer neural network. All tuning parameters are selected via cross-validation, requiring no prior knowledge of covariate relevance. We establish the asymptotic optimality of RSA under general conditions, allowing the first-round weights to be data-dependent, and demonstrate that RSA achieves a lower finite-sample risk bound under orthogonal design. Simulation studies demonstrate that RSA consistently delivers superior and stable predictive performance across a wide range of sample sizes, dimensional settings, sparsity levels and correlation structures, outperforming conventional model selection and ensemble learning methods. An empirical application to financial return forecasting further illustrates its practical utility."}
{"id": "2512.22855", "categories": ["physics.geo-ph", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.22855", "abs": "https://arxiv.org/abs/2512.22855", "authors": ["Alexandru Hegyi"], "title": "A Rapid GeoSAM-Based Workflow for Multi-Temporal Glacier Delineation: Case Study from Svalbard", "comment": null, "summary": "Consistent glacier boundary delineation is essential for monitoring glacier change, yet many existing approaches are difficult to scale across long time series and heterogeneous environments. In this report, we present a GeoSAM-based, semi-automatic workflow for rapid glacier delineation from Sentinel-2 surface reflectance imagery. The method combines late-summer image compositing, spectral-index-based identification of candidate ice areas, prompt-guided segmentation using GeoSAM, and physically based post-processing to derive annual glacier outlines. The workflow is demonstrated in the Ny-Alesund and Kongsfjorden region of western Svalbard across multiple years of the Sentinel-2 era. Results show that the approach produces spatially coherent and temporally consistent outlines for major glacier bodies, while most errors are associated with small features affected by water bodies, terrain shadows, or high surface variability. The reliance on derived RGB imagery makes the method flexible and transferable to other optical datasets, with improved performance expected at higher spatial resolution. Although user inspection remains necessary to filter incorrect polygons and adjust thresholds for local conditions, the workflow provides a fast and practical alternative for multi-temporal glacier mapping and ice-loss assessment."}
{"id": "2512.22839", "categories": ["nlin.AO", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.22839", "abs": "https://arxiv.org/abs/2512.22839", "authors": ["Shreeman Auromahima", "Sitangshu Bikas Santra", "Biplab Bose"], "title": "Switching Transition in a Resource Exchange Model on Graphs", "comment": null, "summary": "In this work, we investigate a simple nonequilibrium system with many interconnected, open subsystems, each exchanging a globally conserved resource with an external reserve. The system is represented by a random graph, where nodes represent the subsystems connected through edges. At each time step, a randomly selected node gains a token (i.e, a resource) from the reserve with probability (1-p) or loses a token to the reserve with probability p. When a node loses a token, its neighbors also lose a token each. This asymmetric token exchange breaks the detailed balance. We investigate the steady state behavior of our model for different types of random graphs: graphs without edges, regular graphs, Erdős-Rényi, and Barabási-Albert graphs. In all cases, the system exhibits a sharp, switch-like transition between a token-saturated state and an empty state. When the control parameter p is below a critical threshold, almost all tokens accumulate on the graph. Furthermore, in a non-regular graph, most tokens accumulate or condense on nodes of minimum degree. A slight increase in p beyond the threshold drains almost all the tokens from the graph. This switching transition results from the interplay between drift and the conservation of tokens. However, the position of the critical threshold and the behavior at the transition zone depend on graph topology."}
{"id": "2512.22381", "categories": ["cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22381", "abs": "https://arxiv.org/abs/2512.22381", "authors": ["Mohammad Zakaria Haider", "Amit Kumar Podder", "Prabin Mali", "Aranya Chakrabortty", "Sumit Paudyal", "Mohammad Ashiqur Rahman"], "title": "PHANTOM: Physics-Aware Adversarial Attacks against Federated Learning-Coordinated EV Charging Management System", "comment": null, "summary": "The rapid deployment of electric vehicle charging stations (EVCS) within distribution networks necessitates intelligent and adaptive control to maintain the grid's resilience and reliability. In this work, we propose PHANTOM, a physics-aware adversarial network that is trained and optimized through a multi-agent reinforcement learning model. PHANTOM integrates a physics-informed neural network (PINN) enabled by federated learning (FL) that functions as a digital twin of EVCS-integrated systems, ensuring physically consistent modeling of operational dynamics and constraints. Building on this digital twin, we construct a multi-agent RL environment that utilizes deep Q-networks (DQN) and soft actor-critic (SAC) methods to derive adversarial false data injection (FDI) strategies capable of bypassing conventional detection mechanisms. To examine the broader grid-level consequences, a transmission and distribution (T and D) dual simulation platform is developed, allowing us to capture cascading interactions between EVCS disturbances at the distribution level and the operations of the bulk transmission system. Results demonstrate how learned attack policies disrupt load balancing and induce voltage instabilities that propagate across T and D boundaries. These findings highlight the critical need for physics-aware cybersecurity to ensure the resilience of large-scale vehicle-grid integration."}
{"id": "2512.22563", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.22563", "abs": "https://arxiv.org/abs/2512.22563", "authors": ["Mattia Tarabolo", "Luca Dall'Asta", "Roberto Mulet"], "title": "Sparse Interactions Reshape Stability in Random Lotka-Volterra Dynamics", "comment": "6 pages, 3 figures", "summary": "Classical approaches to ecological stability rely on fully connected interaction models, yet real ecosystems are sparse and structured--a feature that qualitatively reshapes their collective dynamics. Here, we establish a thermodynamically exact stability phase diagram for generalized Lotka-Volterra dynamics on sparse random graphs, resolving how finite connectivity and interaction heterogeneity jointly govern ecosystem resilience. Using a small-coupling expansion of the dynamic cavity method, we derive an effective single-site stochastic process that is solvable via population dynamics. Our approach uncovers a topological phase transition--driven purely by the finite connectivity structure of the network--that leads to multi-stability. This instability is fundamentally distinct from the disorder-driven transitions induced by quenched randomness of the couplings. Our framework overcomes the considerable computational cost of direct simulations, offering a scalable and versatile analysis of stability, biodiversity, and alternative stable states in realistic, large-scale ecological ecosystems."}
{"id": "2512.22445", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2512.22445", "abs": "https://arxiv.org/abs/2512.22445", "authors": ["Vinesh Vijayan"], "title": "Universality classes of chaos in non Markovian dynamics", "comment": "8 pages, 3 figures", "summary": "Classical chaos theory rests on the notion of universality, whereby disparate dynamical systems share identical scaling laws. Existing universality classes, however, implicitly assume Markovian dynamics. Here, a logistic map endowed with power law memory is used to show that Feigenbaum universality breaks down when temporal correlations decay sufficiently slowly. A critical memory exponent is identified that separates perturbative and memory dominated regimes, demonstrating that long range memory acts as a relevant renormalisation operator and generates a new universality class of chaotic dynamics. The onset of chaos is accompanied by fractional scaling of Lyapunov exponents, in quantitative agreement with analytical predictions. These results establish temporal correlations as a previously unexplored axis of universality in chaotic systems, with implications for physical, biological and geophysical settings where memory effects are intrinsic."}
{"id": "2512.23254", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.23254", "abs": "https://arxiv.org/abs/2512.23254", "authors": ["Naofumi Matsuyama", "So Yokomori", "Toshihiro Nomura", "Yuto Ishii", "Hiroaki Hayashi", "Hajime Ishikawa", "Kazuki Matsui", "Hatsumi Mori", "Koichi Kindo", "Yasuhiro H. Matsuda", "Shusaku Imajo"], "title": "Fate of Pomeranchuk effect in ultrahigh magnetic fields", "comment": null, "summary": "The Pomeranchuk effect is a counterintuitive phenomenon where liquid helium-3 (3He) solidifies under specific pressures, not when cooled, but when heated. This behaviour originates from the magnetic entropy of nuclear spins, suggesting a magnetic field should influence it. However, its detailed response to magnetic fields remains elusive due to the small nuclear magneton of 3He and lack of analogous fermion systems. Here, we show that an electron system also exhibit the Pomeranchuk effect, where the Fermi liquid state solidifies in a high magnetic field, unlike conventional electron systems where a field melts an electron solid into a metal. Remarkably, the electron system displays a reentrant liquid state in ultrahigh fields. These responses are explained by changes in magnetic entropy and magnetisation, extending the underlying physics to 3He. Our findings clarify magnetic-field impact on the Pomeranchuk effect and open avenues for magnetic control of chemical interactions."}
{"id": "2512.22235", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.22235", "abs": "https://arxiv.org/abs/2512.22235", "authors": ["Shalender Singh", "Santosh Kumar"], "title": "Partial Collapse and Ensemble Invariance under Continuous Quantum Measurement", "comment": "8 pages, no figures", "summary": "Wavefunction collapse is often regarded as an unavoidable consequence of quantum measurement. Here we show that in driven-dissipative quantum systems, continuous measurement can extract information without disturbing the physical steady-state ensemble. Using the stochastic master equation formalism, we identify measurement-invariant steady states whose unconditional density matrix remains unchanged under continuous monitoring, despite the presence of measurement-induced collapse at the level of individual quantum trajectories. This separation between conditional collapse and ensemble invariance leads to a regime of partial collapse, in which measurement-induced localization is transient and continuously counteracted by dissipation and drive. We establish a necessary and sufficient condition for steady-state invariance under continuous measurement and show-that it holds over a finite range of measurement strengths. Our results clarify how information gain and measurement backaction can be dynamically decoupled in open quantum systems, with implications for continuous quantum sensing and the foundations of nonprojective measurement."}
{"id": "2512.22950", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22950", "abs": "https://arxiv.org/abs/2512.22950", "authors": ["Alexander Sturges", "Hugo Smith", "Matteo Marcuzzi"], "title": "Effective Kinetic Monte Carlo for a Quantum Epidemic Process", "comment": "38 paages (62 including Appendices and Bibliography); 25 figures (28 counting the three in the Appendices)", "summary": "Inspired by previous works on epidemic-like processes in open quantum systems, we derive an elementary quantum epidemic model that is simple enough to be studied via Quantum Jump Monte Carlo simulations at reasonably large system sizes. We show how some weak symmetries of the Lindblad equation allow us to map the dynamics onto a classical Kinetic Monte Carlo; this simplified, effective dynamics can be described via local stochastic jumps coupled with a local deterministic component. Simulations are then used to reconstruct a phase diagram which displays stationary features completely equivalent to those of completely classical epidemic processes, but richer dynamics with multiple, recurrent waves of infection."}
{"id": "2512.22710", "categories": ["physics.ao-ph", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2512.22710", "abs": "https://arxiv.org/abs/2512.22710", "authors": ["Georg A. Gottwald", "Eli Tziperman", "Alexey Fedorov"], "title": "Contrasting different noise models for representing westerly wind bursts in a recharge oscillator model of ENSO", "comment": null, "summary": "Westerly wind bursts (WWBs) have long been known to have a major impact on the development of El Niño events. In particular, they amplify these events, with stronger events associated with a higher number of WWBs. We further find indications that WWBs lead to a more monotonically increasing evolution of warming events. We consider here a noise-driven recharge oscillator model of ENSO. Commonly, WWBs are represented by a state-dependent Gaussian noise which naturally reproduces the amplification of warm events. However, we show that many properties of WWBs and their effects on sea surface temperature (SST) are not well captured by such Gaussian noise. Instead, we show that conditional additive and multiplicative (CAM) noise presents a promising alternative. In addition to recovering the sporadic nature of WWBs, CAM noise leads to an asymmetry between El Niño and La Niña events without the need for deterministic nonlinearities. Furthermore, CAM noise generates a more monotonic increase of extreme warming events with a higher frequency of WWBs accompanying the largest events. This suggests that extreme warm events are better modelled by CAM noise. To cover the full spectrum of warm events we propose a conditional noise model in which the wind stress is modelled by additive Gaussian noise for sufficiently small SSTs and by additive CAM noise once the SST exceeds a certain threshold. We show that this conditional noise model captures the observed properties of WWBs reasonably well."}
{"id": "2512.22642", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22642", "abs": "https://arxiv.org/abs/2512.22642", "authors": ["Anbang Liu", "Shaochong Lin", "Jingchuan Chen", "Peng Wu", "Zuojun Max Shen"], "title": "A Survey of Machine-Learning-Based Scheduling: From Solver-Centric to Data-Centric Paradigms", "comment": null, "summary": "Scheduling problems are a fundamental class of combinatorial optimization problems that underpin operational efficiency in manufacturing, logistics, and service systems. While operations research has traditionally developed solver-centric methods emphasizing model structure and optimality, recent advances in machine learning are reshaping scheduling into a data-centric discipline that learns from experience and adapts to dynamic environments. This paper provides a comprehensive and comparative review of this methodological transition. We first revisit classical optimization-based approaches and summarize how ML has been integrated within them to improve computational efficiency. We then review end-to-end learning approaches that generate scheduling solutions directly from data, highlighting how they shift decision-making from explicit optimization to learned inference. Adopting a systematic, method-oriented perspective, we compare these paradigms and their underlying learning algorithms in terms of principles, scalability, interpretability, and generalization. Finally, we discuss key research challenges and outline future directions along three interdependent dimensions, scalability, reliability, and universality, that together define a pathway toward adaptive, intelligent, and trustworthy scheduling systems for data-driven operations management."}
{"id": "2512.22680", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22680", "abs": "https://arxiv.org/abs/2512.22680", "authors": ["Abderaouf Bahi", "Amel Ourici", "Chaima Lagraa", "Siham Lameche", "Soundess Halimi", "Inoussa Mouiche", "Ylias Sabri", "Waseem Haider", "Mohamed Trari"], "title": "From Electrochemical Energy Storage to Next-Generation Intelligent Battery Technologies for Electric Vehicles: A Survey", "comment": "This work was supervised by leading professor in the field (Pr. Mohamed Trari, Pr. Waseem Haider, Pr. Ylias Sabri)", "summary": "This study provides a comprehensive overview of recent advances in electrochemical energy storage, including Na+ -ion, metal-ion, and metal-air batteries, alongside innovations in electrode engineering, electrolytes, and solid-electrolyte interphase control. It also explores the integration of machine learning, digital twins, large language models and predictive analytics to enable intelligent battery management systems, enhancing performance, safety, and operational longevity. Key challenges, research gaps, and future prospects are addressed, highlighting opportunities presented by hybrid chemistry, scalable manufacturing, sustainability, and AI-driven optimization. This survey aims to provide researchers, engineers, and industry profesionnals with a comprehensive understanding of next-generation battery technologies for the evolving electric vehicles sector."}
{"id": "2512.22680", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22680", "abs": "https://arxiv.org/abs/2512.22680", "authors": ["Abderaouf Bahi", "Amel Ourici", "Chaima Lagraa", "Siham Lameche", "Soundess Halimi", "Inoussa Mouiche", "Ylias Sabri", "Waseem Haider", "Mohamed Trari"], "title": "From Electrochemical Energy Storage to Next-Generation Intelligent Battery Technologies for Electric Vehicles: A Survey", "comment": "This work was supervised by leading professor in the field (Pr. Mohamed Trari, Pr. Waseem Haider, Pr. Ylias Sabri)", "summary": "This study provides a comprehensive overview of recent advances in electrochemical energy storage, including Na+ -ion, metal-ion, and metal-air batteries, alongside innovations in electrode engineering, electrolytes, and solid-electrolyte interphase control. It also explores the integration of machine learning, digital twins, large language models and predictive analytics to enable intelligent battery management systems, enhancing performance, safety, and operational longevity. Key challenges, research gaps, and future prospects are addressed, highlighting opportunities presented by hybrid chemistry, scalable manufacturing, sustainability, and AI-driven optimization. This survey aims to provide researchers, engineers, and industry profesionnals with a comprehensive understanding of next-generation battery technologies for the evolving electric vehicles sector."}
{"id": "2512.23182", "categories": ["math.NA", "math.SP"], "pdf": "https://arxiv.org/pdf/2512.23182", "abs": "https://arxiv.org/abs/2512.23182", "authors": ["Xuefeng Liu", "Michael Plum"], "title": "A Two-Stage Finite Element Approach for High-precision Guaranteed Lower Eigenvalue Bounds", "comment": "45 pages, 9 figures", "summary": "Obtaining high-precision guaranteed lower eigenvalue bounds remains difficult, even though the standard high-order conforming finite element (FEM) easily yields extremely sharp upper bounds. Recently developed rigorous approaches using such as Crouzeix--Raviart or linear conforming elements do not extend well to high-order FEM. Some non-standard FEM approaches can provide sharp eigenvalue bounds but are technically involved. This persistent gap between accurate upper bounds and equally sharp rigorous lower bounds via standard high-order conforming FEMs makes the problem technically demanding and highly competitive. In this paper, we propose a new two-stage rigorous algorithm that closes this gap by employing high-order FEM on graded meshes and producing rigorous lower eigenvalue bounds as sharp as the corresponding high-order upper bounds, as demonstrated in our numerical examples. Numerical experiments for the Laplacian and Steklov eigenvalue problems on square and dumbbell domains show the accuracy and efficiency of the method, particularly on graded or highly nonuniform meshes. These results confirm that the proposed approach provides a practical and competitive solution to the long-standing difficulty of obtaining sharp, reliable lower eigenvalue bounds."}
{"id": "2512.23462", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2512.23462", "abs": "https://arxiv.org/abs/2512.23462", "authors": ["A. Gómez Nicola", "R. Molina", "Julián A. Sánchez"], "title": "Pion scattering at finite volume within the Inverse Amplitude Method", "comment": null, "summary": "We study the effect of a finite volume for pion-pion scattering within Chiral Perturbation Theory (ChPT) and the Inverse Amplitude Method (IAM) in a $L^3$ box (rest frame). Our full ChPT calculation takes into account the discretization not only in the $s$-channel loops but also in the $t,u$- channels and tadpole contributions. Hence, not only the unitarity right-hand cut but also the left-hand one continuum contributions are calculated in the finite volume. A proper extension of the standard Veltman-Pasarino identities is needed, as well as a suitable projection on the internal space spanned by the irreducible representations (irreps) of the octahedral group, based on either a finite set of cubic harmonics or the matrices which represent the irreps properly. From the ChPT we construct the IAM in the internal space, which provides the full volume dependence of the interacting energy levels of two-pions scattering in the finite volume. Our results for various low-energy constants sets show sizable corrections with respect to previous analyses in the literature for $ m_πL \\lesssim 2$, being compatible with energy levels lattice data. We expect that our analysis and results will help to optimize the process of determination of energy levels and phase-shifts with higher accuracy."}
{"id": "2512.23105", "categories": ["physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2512.23105", "abs": "https://arxiv.org/abs/2512.23105", "authors": ["Jonathon Sendall"], "title": "Event Horizons, Spacetime Geometry, and the Limits of Integrated Consciousness", "comment": "16 pages, 1 figure", "summary": "What happens to a unified conscious field when its physical implementation straddles a black hole event horizon? This paper addresses that question for integration-based theories, including Integrated Information Theory, Global Workspace Theory, and Predictive Processing. These views share a structural commitment: unity requires a single strongly connected component (SCC) in an effective causal graph over a finite integration window $τ$. Using the standard black hole causal structure, I show that no SCC can span an event horizon. Any theory that ties unity to strong connectivity must therefore accept that a single conscious field cannot remain numerically identical and unified across such a configuration. From the perspective of the theories themselves, the outcome is bifurcation: each causally connected subsystem continues to satisfy the very structural criteria the theory declared necessary for a unified field. On any such view, the number and boundaries of unified conscious fields are therefore fixed not by the substrate alone but by the conjunction of its internal architecture with the relativistic causal structure of the spacetime it occupies, a dependency that ordinary spacetime conceals by supplying it so abundantly, but which an event horizon abruptly withdraws."}
{"id": "2512.23622", "categories": ["cs.SI", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.23622", "abs": "https://arxiv.org/abs/2512.23622", "authors": ["Till Hoffmann", "Jukka-Pekka Onnela"], "title": "Information is localized in growing network models", "comment": "7 pages, 2 figures, 1 table", "summary": "Mechanistic network models can capture salient characteristics of empirical networks using a small set of domain-specific, interpretable mechanisms. Yet inference remains challenging because the likelihood is often intractable. We show that, for a broad class of growing network models, information about model parameters is localized in the network, i.e., the likelihood can be expressed in terms of small subgraphs. We take a Bayesian perspective to inference and develop neural density estimators (NDEs) to approximate the posterior distribution of model parameters using graph neural networks (GNNs) with limited receptive size, i.e., the GNN can only \"see\" small subgraphs. We characterize nine growing network models in terms of their localization and demonstrate that localization predictions agree with NDEs on simulated data. Even for non-localized models, NDEs can infer high-fidelity posteriors matching model-specific inference methods at a fraction of the cost. Our findings establish information localization as a fundamental property of network growth, theoretically justifying the analysis of local subgraphs embedded in larger, unobserved networks and the use of GNNs with limited receptive field for likelihood-free inference."}
{"id": "2512.22412", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.22412", "abs": "https://arxiv.org/abs/2512.22412", "authors": ["Yunhong Lyu", "Bouchra R. Nasri", "Bruno N. Rémillard"], "title": "Sequential change-point detection for generalized Ornstein-Uhlenbeck processes", "comment": null, "summary": "In this article, we study sequential change-point methods for discretely observed generalized Ornstein-Uhlenbeck processes with periodic drift. Two detection methods are proposed, and their respective performance is studied through numerical experiments for several choices of parameters."}
{"id": "2512.22504", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.22504", "abs": "https://arxiv.org/abs/2512.22504", "authors": ["Joyee Ghosh"], "title": "On the Choice of Model Space Priors and Multiplicity Control in Bayesian Variable Selection: An Application to Streaming Logistic Regression", "comment": "25 pages, 8 figures", "summary": "Bayesian variable selection (BVS) depends critically on the specification of a prior distribution over the model space, particularly for controlling sparsity and multiplicity. This paper examines the practical consequences of different model space priors for BVS in logistic regression, with an emphasis on streaming data settings. We review some popular and well-known Beta--Binomial priors alongside the recently proposed matryoshka doll (MD) prior. We introduce a simple approximation to the MD prior that yields independent inclusion indicators and is convenient for scalable inference. Using BIC-based approximations to marginal likelihoods, we compare the effect of different model space priors on posterior inclusion probabilities and coefficient estimation at intermediate and final stages of the data stream via simulation studies. Overall, the results indicate that no single model space prior uniformly dominates across scenarios, and that the recently proposed MD prior provides a useful additional option that occupies an intermediate position between commonly used Beta--Binomial priors with differing degrees of sparsity."}
{"id": "2512.22421", "categories": ["math.NA", "cs.LG", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.22421", "abs": "https://arxiv.org/abs/2512.22421", "authors": ["Zihan Lin", "QiZhi He"], "title": "Differentiable Inverse Modeling with Physics-Constrained Latent Diffusion for Heterogeneous Subsurface Parameter Fields", "comment": "33 pages, 16 figures", "summary": "We present a latent diffusion-based differentiable inversion method (LD-DIM) for PDE-constrained inverse problems involving high-dimensional spatially distributed coefficients. LD-DIM couples a pretrained latent diffusion prior with an end-to-end differentiable numerical solver to reconstruct unknown heterogeneous parameter fields in a low-dimensional nonlinear manifold, improving numerical conditioning and enabling stable gradient-based optimization under sparse observations. The proposed framework integrates a latent diffusion model (LDM), trained in a compact latent space, with a differentiable finite-volume discretization of the forward PDE. Sensitivities are propagated through the discretization using adjoint-based gradients combined with reverse-mode automatic differentiation. Inversion is performed directly in latent space, which implicitly suppresses ill-conditioned degrees of freedom while preserving dominant structural modes, including sharp material interfaces. The effectiveness of LD-DIM is demonstrated using a representative inverse problem for flow in porous media, where heterogeneous conductivity fields are reconstructed from spatially sparse hydraulic head measurements. Numerical experiments assess convergence behavior and reconstruction quality for both Gaussian random fields and bimaterial coefficient distributions. The results show that LD-DIM achieves consistently improved numerical stability and reconstruction accuracy of both parameter fields and corresponding PDE solutions compared with physics-informed neural networks (PINNs) and physics-embedded variational autoencoder (VAE) baselines, while maintaining sharp discontinuities and reducing sensitivity to initialization."}
{"id": "2512.22542", "categories": ["quant-ph", "math.PR", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.22542", "abs": "https://arxiv.org/abs/2512.22542", "authors": ["Tingyu Zhao", "Balázs Maga", "Pierfrancesco Dionigi", "Gergely Ódor", "Kyle Soni", "Anastasiya Salova", "Bingjie Hao", "Miklós Abért", "István A. Kovács"], "title": "Quantum preferential attachment", "comment": null, "summary": "The quantum internet is a rapidly developing technological reality, yet, it remains unclear what kind of quantum network structures might emerge. Since indirect quantum communication is already feasible and preserves absolute security of the communication channel, a new node joining the quantum network does not need to connect directly to its desired target. Instead, in our proposed quantum preferential attachment model, it uniformly randomly connects to any node within the proximity of the target, including, but not restricted to, the target itself. This local flexibility is found to qualitatively change the global network behavior, leading to two distinct classes of complex network architectures, both of which are small-world, but neither of which is scale-free. Our numerical findings are supported by rigorous analytic results, in a framework that incorporates quantum and classical variants of preferential attachment in a unified phase diagram. Besides quantum networks, we expect that our results will have broad implications for classical scenarios where there is flexibility in establishing new connections."}
{"id": "2512.22722", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2512.22722", "abs": "https://arxiv.org/abs/2512.22722", "authors": ["Yue Zhou", "Shaan Shah", "Tamal Dey", "Yucheng Zhou", "Ashwani Kumar", "Sashank Sriram", "Siyou Guo", "Siddharth Kumar", "Ranjan Kumar Patel", "Eva Y. Andrei", "Ertugrul Cubukcu", "Shriram Ramanathan", "Duygu Kuzum"], "title": "Protonic Nickelate Device Networks for Spatiotemporal Neuromorphic Computing", "comment": null, "summary": "Computation in biological neural circuits arises from the interplay of nonlinear temporal responses and spatially distributed dynamic network interactions. Replicating this richness in hardware has remained challenging, as most neuromorphic devices emulate only isolated neuron- or synapse-like functions. In this work, we introduce an integrated neuromorphic computing platform in which both nonlinear spatiotemporal processing and programmable memory are realized within a single perovskite nickelate material system. By engineering symmetric and asymmetric hydrogenated NdNiO3 junction devices on the same wafer, we combine ultrafast, proton-mediated transient dynamics with stable multilevel resistance states. Networks of symmetric NdNiO3 junctions exhibit emergent spatial interactions mediated by proton redistribution, while each node simultaneously provides short-term temporal memory, enabling nanoseconds scale operation with an energy cost of 0.2 nJ per input. When interfaced with asymmetric output units serving as reconfigurable long-term weights, these networks allow both feature transformation and linear classification in the same material system. Leveraging these emergent interactions, the platform enables real-time pattern recognition and achieves high accuracy in spoken-digit classification and early seizure detection, outperforming temporal-only or uncoupled architectures. These results position protonic nickelates as a compact, energy-efficient, CMOS-compatible platform that integrates processing and memory for scalable intelligent hardware."}
{"id": "2512.23240", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23240", "abs": "https://arxiv.org/abs/2512.23240", "authors": ["Gabriel Hayoun", "Ilya A. Gruzberg", "Marcel Filoche"], "title": "Localization-landscape generalized Mott-Berezinskiĭ formula", "comment": null, "summary": "We introduce a conceptual reformulation of the Mott-Berezinskiĭ (MB) theory of low-frequency AC conductivity in disordered systems based on localization landscape theory. Instead of assuming uniform localization and fixed hopping distances, transport is described through an effective potential whose geometry encodes the spatial organization and energy-dependent localization of quantum states. Using the associated Agmon metric, we define a generalized Mott scale that replaces the classical hopping length with a geometric criterion set by the disorder landscape. This framework naturally incorporates strong spatial inhomogeneity and yields the AC conductivity directly from the effective potential. The standard MB result is recovered as a limiting case. Our approach extends the conceptual foundation of MB theory to arbitrary disordered media and energies approaching the mobility edge, providing a unified description of AC transport in complex quantum materials."}
{"id": "2512.23002", "categories": ["nlin.CD", "math-ph", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.23002", "abs": "https://arxiv.org/abs/2512.23002", "authors": ["Jean-Jacq du Plessis", "Malcolm Hillebrand", "Charalampos Skokos"], "title": "On the efficient numerical computation of covariant Lyapunov vectors", "comment": "10 pages, 12 figures", "summary": "Covariant Lyapunov vectors (CLVs) are useful in multiple applications, but the optimal time windows needed to accurately compute these vectors are yet unclear. To remedy this, we investigate two methods for determining when to safely terminate the forward and backward transient phases of the CLV computation algorithm by Ginelli et al.~\\cite{GinelliEtAl2007} when applied to chaotic orbits of conservative Hamiltonian systems. We perform this investigation for two prototypical Hamiltonian systems, namely the well-known Hénon-Heiles system of two degrees of freedom and a system of three nonlinearly coupled harmonic oscillators having three degrees of freedom, finding very similar results for the two methods and thus recommending the more efficient one. We find that the accuracy of two-dimesnional center subspace computations is significantly reduced when the backward evolution stages of the algorithm are performed over long time intervals. We explain this observation by examining the tangent dynamics of the center subspace wherein CLVs tend to align/anti-align, and we propose an adaptation of the algorithm that improves the accuracy of such computations over long times by preventing this alignment/anti-alignment of CLVs in the center subspace."}
{"id": "2512.23361", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23361", "abs": "https://arxiv.org/abs/2512.23361", "authors": ["Chang-Yu Shen", "Shuai Yin", "Zi-Xiang Li"], "title": "Universal Entanglement Growth along Imaginary Time in Quantum Critical Systems", "comment": "7+5 pages, 4+3 figures", "summary": "Characterizing universal entanglement features in higher-dimensional quantum matter is a central goal of quantum information science and condensed matter physics. While the subleading corner terms in two-dimensional quantum systems encapsulate essential universal information of the underlying conformal field theory, our understanding of these features remains remarkably limited compared to their one-dimensional counterparts. We address this challenge by investigating the entanglement dynamics of fermionic systems along the imaginary-time evolution. We uncover a pioneering non-equilibrium scaling law where the corner entanglement entropy grows linearly with the logarithm of imaginary time, dictated solely by the universality class of the quantum critical point. Through unbiased Quantum Monte Carlo simulations, we verify this scaling in the interacting Gross-Neveu-Yukawa model, demonstrating that universal data can be accurately recovered from the early stages of relaxation. Our findings significantly circumvent the computational bottlenecks inherent in reaching full equilibrium convergence. This work establishes a direct link between the fundamental theory of non-equilibrium critical phenomena and the high-precision determination of universal entanglement properties on both classical and quantum platforms, paving the way for probing the rich entanglement structure of quantum critical systems."}
{"id": "2512.22297", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22297", "abs": "https://arxiv.org/abs/2512.22297", "authors": ["Angelo Mamitiana Ralaikoto", "Diary Lova Ratsimbazafy", "Ravo Tokiniaina Ranaivoson", "Fanamby Sahondraniandriana", "Roland Raboanary", "Raoelina Andriambololona", "Nomenjanahary Tanjonirina Manampisoa", "Rivo Herivola Manjakamanana Ravelonjato"], "title": "Decoherence challenges in Nanoscience: A Quantum Phase Space perspective", "comment": "15 pages", "summary": "Quantum decoherence, the process by which a quantum system loses its coherence through interaction with an environment and becomes classical-like, represents both the fundamental mechanism for the quantum-to-classical transition and a major challenge to realizing scalable nanoscale quantum technologies. This work introduces a novel theoretical framework based on Quantum Phase Space (QPS) to address the dual challenge of characterizing environment-selected pointer states and modeling decoherence dynamics across different regimes. Within this framework, pointer states for particle motion are identified as the minimum-uncertainty states, those that saturate the quantum uncertainty relation, thereby constituting the closest quantum analogue to classical phase-space points. The structure of the QPS, encoded in a variance-covariance matrix, is shown to be directly shaped by environmental properties. A time-independent matrix corresponds to Markovian (memoryless) decoherence, described by constant diffusion and friction coefficients, while a time-dependent matrix captures non-Markovian dynamics, characterized by environmental memory and information backflow. This unified geometric formalism, applied to both Lindblad and Non-Markovian master equations, enables us to derive explicit relations between environmental parameters and phase-space structure, as demonstrated in a specific illustrative example. This approach has the potential to serve as a powerful tool for modeling decoherence in nanoscience and could inform new principles for designing mitigation strategies and harnessing non-Markovian effects for quantum technologies. The QPS framework may thus bridge fundamental theory and practical quantum engineering, offering a promising coherent pathway to understand, control, and exploit decoherence at the nanoscience frontier."}
{"id": "2512.23086", "categories": ["cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.23086", "abs": "https://arxiv.org/abs/2512.23086", "authors": ["Teng Liu", "Xuezhi Niu", "Mingli Zhang", "Gaoke Hu", "Yuhan Chen", "Yongwen Zhang", "Rui Shi", "Jingyuan Li", "Peng Tan", "Maoxin Liu", "Hui Li", "Xiaosong Chen"], "title": "Phase transition revealed by eigen microstate entropy", "comment": null, "summary": "We introduce the eigen microstate entropy ($S_{\\text{EM}}$), a novel metric of complexity derived from the probabilities of statistically independent eigen microstates. After establishing its scaling behavior in equilibrium systems and demonstrating its utility in critical phenomena (mean spherical, Ising, and Potts models), we apply $S_{\\text{EM}}$ to non-equilibrium complex systems. Our analysis reveals a consistent precursor signal: a significant increase in $S_{\\text{EM}}$ precedes major phase transitions. Specifically, we observe this entropy rise before biomolecular condensate formation in liquid-liquid phase separation in living cells and months ahead of El Niño events. These findings position $S_{\\text{EM}}$ as a general framework for detecting and interpreting phase transitions in non-equilibrium systems."}
{"id": "2512.23038", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2512.23038", "abs": "https://arxiv.org/abs/2512.23038", "authors": ["Sarah Packman", "Justin Finkel", "Dorian S. Abbot", "Eli Tziperman"], "title": "Using a rare event sampling technique to quantify extreme El Niño event statistics", "comment": "18 pages, 8 figures", "summary": "Extreme El Niño events, such as occurred in 1997--1998, can induce severe weather on a global scale, with significant socioeconomic impacts that motivate efforts to understand them better. However, extreme El Niño events are rare, and even in a very long direct numerical simulation (DNS) occur too infrequently for robust statistical characterization. This study seeks to generate extreme El Niño event model data at a lower cost, while preserving statistical fidelity, using a rare event sampling technique, which preferentially devotes computational resources toward extreme events by generating a large, branched ensemble of interrelated trajectories through successive targeted perturbations. We specifically use the ``trying-early adaptive multi-level splitting'' (TEAMS) algorithm, which is well-suited for El Niño's relative timescales of predictability and event duration. We apply TEAMS to the Zebiak-Cane model, an intermediate-complexity ENSO model for which it is feasible to run a long DNS (500000 years) for validation. We compare extreme El Niño event return time estimates from TEAMS to those from the long DNS to assess TEAMS' accuracy and efficiency. We find that TEAMS accurately reproduces the return time estimates of the DNS at about one fifth the computational cost. Therefore, TEAMS is an efficient approach to study rare ENSO events that can be plausibly applied to full-complexity climate models."}
{"id": "2512.22750", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22750", "abs": "https://arxiv.org/abs/2512.22750", "authors": ["Jiachen Jin", "Kangkang Deng", "Hongxia Wang"], "title": "A Single-loop Stochastic Riemannian ADMM for Nonsmooth Optimization", "comment": null, "summary": "We study a class of nonsmooth stochastic optimization problems on Riemannian manifolds. In this work, we propose MARS-ADMM, the first stochastic Riemannian alternating direction method of multipliers with provable near-optimal complexity guarantees. Our algorithm incorporates a momentum-based variance-reduced gradient estimator applied exclusively to the smooth component of the objective, together with carefully designed penalty parameter and dual stepsize updates. Unlike existing approaches that rely on computationally expensive double-loop frameworks, MARS-ADMM operates in a single-loop fashion and requires only a constant number of stochastic gradient evaluations per iteration. Under mild assumptions, we establish that MARS-ADMM achieves an iteration complexity of \\(\\tilde{\\mathcal{O}}(\\varepsilon^{-3})\\), which improves upon the previously best-known bound of \\(\\mathcal{O}(\\varepsilon^{-3.5})\\) for stochastic Riemannian operator-splitting methods. As a result, our analysis closes the theoretical complexity gap between stochastic Riemannian operator-splitting algorithms and stochastic methods for nonsmooth optimization with nonlinear constraints. Notably, the obtained complexity also matches the best-known bounds in deterministic nonsmooth Riemannian optimization, demonstrating that deterministic-level accuracy can be achieved using only constant-size stochastic samples."}
{"id": "2512.22786", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22786", "abs": "https://arxiv.org/abs/2512.22786", "authors": ["Özhan Bingöl"], "title": "A Time-Barrier Lyapunov Condition for Predefined-Time Stability", "comment": "4 pages, 0 figures", "summary": "Predefined-time stability enables convergence within a user-specified time independent of initial conditions. Existing results are predominantly based on autonomous Lyapunov inequalities, where the predefined-time is realized through integral bounds on state-dependent decay and therefore acts as an upper bound rather than a structurally enforced deadline. This paper introduces a time-barrier predefined-time stability concept in which convergence is enforced through a nonautonomous Lyapunov mechanism that intrinsically restricts the remaining available time. A sufficient Lyapunov-based condition is established, guaranteeing convergence before the predefined deadline via divergence of a time-dependent barrier. It is further shown that this mechanism cannot be reproduced by classical autonomous predefined-time stability formulations, thereby constituting a distinct stability notion. The proposed approach provides a concise and transparent means of enforcing hard convergence deadlines in nonlinear systems."}
{"id": "2512.22786", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22786", "abs": "https://arxiv.org/abs/2512.22786", "authors": ["Özhan Bingöl"], "title": "A Time-Barrier Lyapunov Condition for Predefined-Time Stability", "comment": "4 pages, 0 figures", "summary": "Predefined-time stability enables convergence within a user-specified time independent of initial conditions. Existing results are predominantly based on autonomous Lyapunov inequalities, where the predefined-time is realized through integral bounds on state-dependent decay and therefore acts as an upper bound rather than a structurally enforced deadline. This paper introduces a time-barrier predefined-time stability concept in which convergence is enforced through a nonautonomous Lyapunov mechanism that intrinsically restricts the remaining available time. A sufficient Lyapunov-based condition is established, guaranteeing convergence before the predefined deadline via divergence of a time-dependent barrier. It is further shown that this mechanism cannot be reproduced by classical autonomous predefined-time stability formulations, thereby constituting a distinct stability notion. The proposed approach provides a concise and transparent means of enforcing hard convergence deadlines in nonlinear systems."}
{"id": "2512.23238", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23238", "abs": "https://arxiv.org/abs/2512.23238", "authors": ["Tao Lin", "Yuanhui Lin", "Xu Zhang"], "title": "Frenet Immersed Finite Element Spaces on Triangular Meshes", "comment": null, "summary": "In this paper, we develop geometry-conforming immersed finite element (GC-IFE) spaces on triangular meshes for elliptic interface problems. These IFE spaces are constructed via a Frenet-Serret mapping that transforms the interface curve into a straight line, allowing the interface jump conditions to be imposed exactly. Extending the framework of [7,8] from rectangular to triangular meshes, we introduce three procedures for constructing high-degree Frenet-IFE spaces: an initial construction based on monomial bases, a generalized construction using orthogonal polynomials, and reconstruction methods aimed at improving the conditioning of the associated mass matrix. The optimal approximation capability of the proposed IFE spaces is demonstrated through numerical examples. We further incorporate these spaces into interior penalty discontinuous Galerkin methods for elliptic interface problems and observe optimal convergence rates in the $H^1$ and $L^2$ norms."}
{"id": "2512.23560", "categories": ["hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.23560", "abs": "https://arxiv.org/abs/2512.23560", "authors": ["P. V. Buividovich", "B. Hind"], "title": "Spectral reconstruction based on dimensional reduction in high-temperature gauge theories", "comment": "Main text: 4 pages RevTeX, 4 figures. Supplemental material: 14 pages, 4 figures. Simulation codes available at https://github.com/buividovich/u1_2d_LGT and https://github.com/buividovich/static_lattice_QCD", "summary": "We propose a numerical spectral reconstruction workflow for high-temperature gauge theories that incorporates elements of semi-classical real-time evolution directly into standard lattice QCD simulations via high-temperature dimensional reduction, thus counteracting the deterioration of Euclidean-time correlators at high temperatures. With a moderate numerical cost, our method allows to estimate spectral functions with parametrically better frequency resolution as compared with spectral reconstruction methods based on Euclidean-time correlators alone. The method is tested on a simple (1+1)-dimensional Abelian gauge theory with fermions, where our method precisely reproduces the full quantum spectral functions calculated using exact numerical diagonalization in the high-temperature, weak-coupling regime. We also demonstrate the feasibility of our approach by applying it to light-quark meson correlators in lattice QCD deep in the deconfinement regime."}
{"id": "2512.22965", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2512.22965", "abs": "https://arxiv.org/abs/2512.22965", "authors": ["Philippe Grangier"], "title": "Comment on \"There is No Quantum World\" by Jeffrey Bub", "comment": "5 pages, no figures. Comment on arXiv:2512.18400", "summary": "In a recent preprint [1] Jeffrey Bub presents a discussion of neo-Bohrian interpretations of quantum mechanics, and also of von Neumann's work on infinite tensor products [2]. He rightfully writes that this work provides a theoretical framework that deflates the measurement problem and justifies Bohr's insistence on the primacy of classical concepts. But then he rejects these ideas, on the basis that the infinity limit is \"never reached for any real system composed of a finite number of elementary systems\". In this note we present opposite views on two major points: first, admitting mathematical infinities in a physical theory is not a problem, if properly done; second, the critics of [3,4,5] comes with a major misunderstanding of these papers: they don't ask about \"the significance of the transition from classical to quantum mechanics\", but they start from a physical ontology where classical and quantum physics need each other from the beginning. This is because they postulate that a microscopic physical object (or degree of freedom) always appears as a quantum system, within a classical context. Here we argue why this (neo-Bohrian) position makes sense."}
{"id": "2512.22557", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.22557", "abs": "https://arxiv.org/abs/2512.22557", "authors": ["Xiaoda Xu", "Jun Xian"], "title": "Sharp Non-Asymptotic Bounds for the Star Discrepancy of Double-Infinite Random Matrices via Optimal Covering Numbers", "comment": null, "summary": "We establish sharp non-asymptotic probabilistic bounds for the star discrepancy of double-infinite random matrices -- a canonical model for sequences of random point sets in high dimensions. By integrating the recently proved \\textbf{optimal covering numbers for axis-parallel boxes} (Gnewuch, 2024) into the dyadic chaining framework, we achieve \\textbf{explicitly computable constants} that improve upon all previously known bounds.\n  For dimension $d \\ge 3$, we prove that with high probability, \\[ D_N^d \\le \\sqrt{αA_d + βB \\frac{\\ln \\log_2 N}{d}} \\sqrt{\\frac{d}{N}}, \\] where $A_d$ is given by an explicit series and satisfies $A_3 \\le 745$, a \\textbf{14\\% improvement} over the previous best constant of 868 (Fiedler et al., 2023). For $d=2$, we obtain the currently smallest known constant $A_2 \\le 915$.\n  Our analysis reveals a \\textbf{precise trade-off} between the dimensional dependence and the logarithmic factor in $N$, highlighting how optimal covering estimates directly translate to tighter discrepancy bounds. These results immediately yield improved error guarantees for \\textbf{quasi-Monte Carlo integration, uncertainty quantification, and high-dimensional sampling}, and provide a new benchmark for the probabilistic analysis of geometric discrepancy.\n  \\textbf{Keywords:} Star discrepancy, double-infinite random matrices, covering numbers, dyadic chaining, high-dimensional integration, quasi-Monte Carlo, probabilistic bounds."}
{"id": "2512.22655", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.22655", "abs": "https://arxiv.org/abs/2512.22655", "authors": ["Jiaming Liu", "Meng Li"], "title": "Bend to Mend: Toward Trustworthy Variational Bayes with Valid Uncertainty Quantification", "comment": null, "summary": "Variational Bayes (VB) is a popular and computationally efficient method to approximate the posterior distribution in Bayesian inference, especially when the exact posterior is analytically intractable and sampling-based approaches are computationally prohibitive. While VB often yields accurate point estimates, its uncertainty quantification (UQ) is known to be unreliable. For example, credible intervals derived from VB posteriors tend to exhibit undercoverage, failing to achieve nominal frequentist coverage probabilities. In this article, we address this challenge by proposing Trustworthy Variational Bayes (TVB), a method to recalibrate the UQ of broad classes of VB procedures. Our approach follows a bend-to-mend strategy: we intentionally misspecify the likelihood to correct VB's flawed UQ. In particular, we first relax VB by building on a recent fractional VB method, and then identify the optimal fraction parameter using conformal techniques such as sample splitting and bootstrapping. This yields recalibrated UQ for any given parameter of interest. On the theoretical front, we establish that the calibrated credible intervals achieve asymptotically correct frequentist coverage for a given parameter of interest; this, to the best of our knowledge, is the first such theoretical guarantee for VB. On the practical front, we introduce the \"TVB table\", which enables (1) massive parallelization and remains agnostic to the parameter of interest during its construction, and (2) efficient identification of the optimal fraction parameter for any specified parameter of interest. The proposed method is illustrated via Gaussian mixture models and Bayesian mixture linear regression models, and numerical experiments demonstrate that the TVB method outperforms standard VB and achieves normal frequentist coverage in finite samples. A real data application is also discussed."}
{"id": "2512.22678", "categories": ["physics.ao-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.22678", "abs": "https://arxiv.org/abs/2512.22678", "authors": ["Eran Vos", "Peter Huybers", "Eli Tziperman"], "title": "Climate change alters teleconnections", "comment": "Accepted to GRL", "summary": "Internal modes of climate variability, such as El Niño and the North Atlantic Oscillation, can have strong influences upon distant weather patterns, effects that are referred to as \"teleconnections\". The extent to which anthropogenic climate change has and will continue to affect these teleconnections, however, remains uncertain. Here, we employ a covariance fingerprinting approach to demonstrate that shifts in teleconnection patterns affecting monthly temperatures between the periods 1960-1990 and 1990-2020 are attributable to anthropogenic forcing. We further apply multilinear regression to assess the regional contributions and statistical significance of changes in five key climate modes: the El Niño-Southern Oscillation, North Atlantic Oscillation, Southern Annular Mode, Indian Ocean Dipole, and the Pacific Decadal Oscillation. In many regions, observed changes exceed what would be expected from natural variability alone, further implicating an anthropogenic influence. Finally, we provide projections of how these teleconnections will alter in response to further changes in climate."}
{"id": "2512.23086", "categories": ["cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.23086", "abs": "https://arxiv.org/abs/2512.23086", "authors": ["Teng Liu", "Xuezhi Niu", "Mingli Zhang", "Gaoke Hu", "Yuhan Chen", "Yongwen Zhang", "Rui Shi", "Jingyuan Li", "Peng Tan", "Maoxin Liu", "Hui Li", "Xiaosong Chen"], "title": "Phase transition revealed by eigen microstate entropy", "comment": null, "summary": "We introduce the eigen microstate entropy ($S_{\\text{EM}}$), a novel metric of complexity derived from the probabilities of statistically independent eigen microstates. After establishing its scaling behavior in equilibrium systems and demonstrating its utility in critical phenomena (mean spherical, Ising, and Potts models), we apply $S_{\\text{EM}}$ to non-equilibrium complex systems. Our analysis reveals a consistent precursor signal: a significant increase in $S_{\\text{EM}}$ precedes major phase transitions. Specifically, we observe this entropy rise before biomolecular condensate formation in liquid-liquid phase separation in living cells and months ahead of El Niño events. These findings position $S_{\\text{EM}}$ as a general framework for detecting and interpreting phase transitions in non-equilibrium systems."}
{"id": "2512.22784", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2512.22784", "abs": "https://arxiv.org/abs/2512.22784", "authors": ["Mikhail Erementchouk", "Aditya Shukla", "Pinaki Mazumder"], "title": "Relaxation-based dynamical Ising machines for discrete tomography", "comment": "21 pages; 6 figures", "summary": "Dynamical Ising machines are continuous dynamical systems that evolve from a generic initial state to a state strongly related to the ground state of the classical Ising model. We show that such a machine driven by the V${}_2$ dynamical model can solve exactly discrete tomography problems about reconstructing a binary image from the pixel sums along a discrete set of rays. In contrast to usual applications of Ising machines, targeting approximate solutions to optimization problems, the randomly initialized V${}_2$ model converges with high probability ($P_{\\mathrm{succ}} \\approx 1$) to an image precisely satisfying the tomographic data. For the problems with at most two rays intersecting at each pixel, the V${}_2$ model converges in internal machine time that depends only weakly on the image size. Our consideration is an example of how specific dynamical systems can produce exact solutions to highly non-trivial data processing tasks. Crucially, this solving capability arises from the dynamical features of the V${}_2$ model itself, in particular its equations of motion that enable non-local transitions of the discrete component of the relaxed spin beyond Hamming-neighborhood constraints, rather than from merely recasting the tomography problem in spin form."}
{"id": "2512.23639", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.23639", "abs": "https://arxiv.org/abs/2512.23639", "authors": ["Ritesh Bhola", "Kedar Damle"], "title": "Random geometry of maximum-density dimer packings of the site-diluted kagome lattice", "comment": null, "summary": "Recent work that analyzed the effect of vacancy disorder on a short-range resonating valence bond spin liquid state of kagome-lattice antiferromagnets argued that such spin liquids are stable to vacancy disorder. The argument relied crucially on a numerical study that identified the following property of the site-diluted kagome lattice: maximum-density dimer packings (maximum matchings) of any connected component of such site-diluted kagome lattices have at most one unmatched vertex that hosts a monomer. Here, we provide an inductive proof of a stronger result that implies this property: If a connected cluster of such a lattice has an odd number of vertices, its Gallai-Edmonds decomposition~\\cite{Lovas_Plummer_1986} has exactly one ${\\mathcal R}$-type region that spans the entire connected cluster and hosts a single monomer of any maximum-density dimer packing. If on the other hand it has an even number of sites, it admits perfect matchings (fully-packed dimer coverings with no monomers) and its Gallai-Edmonds decomposition consists of a single ${\\mathcal P}$-type region that spans the entire cluster. Our proof also applies to the site-diluted Archimedean star lattice, the site-diluted pyrochlore lattice (corner-sharing tetrahedra), the site-diluted hyperkagome lattice, and, more generally, to any lattice satisfying a certain local connectivity property. It does not apply to bond-diluted versions of such lattices."}
{"id": "2512.23269", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2512.23269", "abs": "https://arxiv.org/abs/2512.23269", "authors": ["Baptiste Bergeot", "Christophe Vergez"], "title": "Analytical prediction of delayed Hopf bifurcations in a simplified stochastic model of reed musical instruments", "comment": null, "summary": "This paper investigates the dynamic behavior of a simplified single reed instrument model subject to a stochastic forcing of white noise type when one of its bifurcation parameters (the dimensionless blowing pressure) increases linearly over time and crosses the Hopf bifurcation point of its trivial equilibrium position. The stochastic slow dynamics of the model is first obtained by means of the stochastic averaging method. The resulting averaged system reduces to a non-autonomous one-dimensional It{ô} stochastic differential equation governing the time evolution of the mouthpiece pressure amplitude. Under relevant approximations the latter is solved analytically treating separately cases where noise can be ignored and cases where it cannot. From that, two analytical expressions of the bifurcation parameter value for which the mouthpiece pressure amplitude gets its initial value back are deduced. These special values of the bifurcation parameter characterize the effective appearance of sound in the instrument and are called deterministic dynamic bifurcation point if the noise can be neglected and stochastic dynamic bifurcation point otherwise. Finally, for illustration and validation purposes, the analytical results are compared with direct numerical integration of the model in both deterministic and stochastic situations. In each considered case, a good agreement is observed between theoretical results and numerical simulations, which validates the proposed analysis."}
{"id": "2512.22124", "categories": ["physics.comp-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.22124", "abs": "https://arxiv.org/abs/2512.22124", "authors": ["Shriram Srinivasan", "Kaarthik Sundar"], "title": "The Solution of Potential-Driven, Steady-State Nonlinear Network Flow Equations via Graph Partitioning", "comment": "6 pages, 2 figures", "summary": "The solution of potential-driven steady-state flow in large networks is required in various engineering applications, such as transport of natural gas or water through pipeline networks. The resultant system of nonlinear equations depends on the network topology, and its solution grows more challenging as the network size increases. We present an algorithm that utilizes a given partition of a network into tractable sizes to compute a global solution for the full nonlinear system through local solution of smaller subsystems induced by the partitions. When the partitions are induced by interconnects or transfer points corresponding to networks owned by different operators, the method ensures data is shared solely at the interconnects, leaving network operators free to solve the network flow system corresponding to their own domain in any manner of their choosing. The proposed method is shown to be connected to the Schur complement and the method's viability demonstrated on some challenging test cases."}
{"id": "2512.23418", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.23418", "abs": "https://arxiv.org/abs/2512.23418", "authors": ["Matthieu Mambrini", "Nathan Goldman", "Didier Poilblanc"], "title": "Detuning the Floquet anomalous chiral spin liquid", "comment": "23 pages, 20 figures", "summary": "At high-frequency a periodically-driven quantum spin-1/2 system can emulate a chiral spin liquid (CSL) described by an effective static local chiral hamiltonian. In contrast, at low-frequency {\\it anomalous} CSL can be realized in Swap Models, in which one-way spin transport occurs at the edge although the bulk time-evolution operator over one period is trivial. In this work we explicitly construct a family of Floquet quantum spin-1/2 models on the square lattice implementing Swap Models to investigate the stability of the anomalous CSL under frequency detuning and the transition to the high-frequency regime. We have used the average-energy spectrum on finite-size torus and cylinders to unfold the Floquet quasi-energy spectrum over the whole frequency range and obtain the geometrical Berry phases. This enabled us to identify three regimes upon increasing detuning: i) a finite-size regime (with no folding of the Floquet spectrum), ii) an intermediate (narrow) regime with folding and very few resonances and iii) a regime with an increased density of resonances suggesting heating. At small detuning, edge modes are revealed by spectroscopic tools and from the diamagnetic response of the system giving access to the anomalous winding number. The analysis of all the data suggests that the anomalous CSL is not continuously connected to the high-frequency CSL. We also discuss the possible occurrence of a long-lived prethermal anomalous CSL."}
{"id": "2512.22320", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22320", "abs": "https://arxiv.org/abs/2512.22320", "authors": ["Lance H. Carter"], "title": "A Time-Symmetric Variational Formulation of Quantum Mechanics with Emergent Schrödinger Dynamics and Objective Boundary Randomness", "comment": null, "summary": "We present a time-symmetric variational formulation of nonrelativistic quantum mechanics in which Schrödinger dynamics and a Bohm-type guidance law arise as emergent Euler-Lagrange optimality conditions rather than postulates. The formulation is expressed in terms of probability density and current fields subject to a continuity constraint and two-time boundary conditions. A Fisher-information regularization term generates the quantum potential, yielding the Schrödinger equation when the optimality system is expressed in complex form. Unlike standard Bohmian mechanics, which requires an auxiliary Quantum Equilibrium Hypothesis ($P = |ψ|^2$), our primal-dual formulation satisfies the Born rule by construction. The trajectories emerge not from an external guidance wave, but as the unique hydrodynamic flow minimizing the Fisher-regularized action between two-time boundary constraints. Deterministic trajectories thus emerge only as effective, coarse-grained descriptions, with randomness entering objectively at the interface of boundary constraints."}
{"id": "2512.23127", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.23127", "abs": "https://arxiv.org/abs/2512.23127", "authors": ["Loris Di Cairano"], "title": "The Geometric Foundations of Microcanonical Thermodynamics: Entropy Flow Equation and Thermodynamic Equivalence", "comment": null, "summary": "We develop a geometric foundation of microcanonical thermodynamics in which entropy and its derivatives are determined from the geometry of phase space, rather than being introduced through an a priori ensemble postulate. Once the minimal structure needed to measure constant -- energy manifolds is made explicit, the microcanonical measure emerges as the natural hypersurface measure on each energy shell. Thermodynamics becomes the study of how these shells deform with energy: the entropy is the logarithm of a geometric area, and its derivatives satisfy a deterministic hierarchy of entropy flow equations driven by microcanonical averages of curvature invariants (built from the shape/Weingarten operator and related geometric data). Within this framework, phase transitions correspond to qualitative reorganizations of the geometry of energy manifolds, leaving systematic signatures in the derivatives of the entropy.\n  Two general structural consequences follow. First, we reveal a thermodynamic covariance: the reconstructed thermodynamics is invariant under arbitrary descriptive choices such as reparametrizations and equivalent representations of the same conserved dynamics. Second, a geometric microcanonical equivalence is found: microscopic realizations that share the same geometric content of their energy manifolds (in the sense of entering the curvature sources of the flow) necessarily yield the same microcanonical thermodynamics. We demonstrate the full practical power of the formalism by reconstructing microcanonical response and identifying criticality across paradigmatic systems, from exactly solvable mean-field models to genuinely nontrivial short-range lattice field theories and the 1D long-range XY model with $1/r^α$ interactions."}
{"id": "2512.22806", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22806", "abs": "https://arxiv.org/abs/2512.22806", "authors": ["Jorge I. Poveda", "Mahmoud Abdelgalil"], "title": "On Composite Foster Functions for a Class of Singularly Perturbed Stochastic Hybrid Inclusions", "comment": null, "summary": "We study sufficient conditions for stability and recurrence in a class of singularly perturbed stochastic hybrid dynamical systems. The systems considered combine multi-time-scale deterministic continuous-time dynamics, modeled by constrained differential inclusions, with discrete-time dynamics described by constrained difference inclusions subject to random disturbances. Under suitable regularity assumptions on the dynamics and causality of the associated solutions, we develop a family of composite nonsmooth Lagrange-Foster and Lyapunov-Foster functions that certify stability and recurrence properties by leveraging simpler functions related to the slow and fast subsystems. Stability is characterized with respect to compact sets, while recurrence is established for bounded open sets. The proposed framework is illustrated through several examples and applications, including the stability analysis of singularly perturbed switching systems with stochastic spontaneous mode transitions, feedback optimization problems with stochastically switching plants, and momentum-based feedback optimization algorithms with stochastic restarting."}
{"id": "2512.22793", "categories": ["eess.SY", "cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.22793", "abs": "https://arxiv.org/abs/2512.22793", "authors": ["Minh Bui", "Simon Monckton", "Mo Chen"], "title": "Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach", "comment": "Paper version accepted to the Journal of Guidance, Control, and Dynamics (JGCD)", "summary": "Reach-avoid (RA) games have significant applications in security and defense, particularly for unmanned aerial vehicles (UAVs). These problems are inherently challenging due to the need to consider obstacles, consider the adversarial nature of opponents, ensure optimality, and account for nonlinear dynamics. Hamilton-Jacobi (HJ) reachability analysis has emerged as a powerful tool for tackling these challenges; however, while it has been applied to games involving two spatial dimensions, directly extending this approach to three spatial dimensions is impossible due to high dimensionality. On the other hand, alternative approaches for solving RA games lack the generality to consider games with three spatial dimensions involving agents with non-trivial system dynamics. In this work, we propose a novel framework for dimensionality reduction by decomposing the problem into a horizontal RA sub-game and a vertical RA sub-game. We then solve each sub-game using HJ reachability analysis and consider second-order dynamics that account for the defender's acceleration. To reconstruct the solution to the original RA game from the sub-games, we introduce a HJ-based tracking control algorithm in each sub-game that not only guarantees capture of the attacker but also tracking of the attacker thereafter. We prove the conditions under which the capture guarantees are maintained. The effectiveness of our approach is demonstrated via numerical simulations, showing that the decomposition maintains optimality and guarantees in the original problem. Our methods are also validated in a Gazebo physics simulator, achieving successful capture of quadrotors in three spatial dimensions space for the first time to the best of our knowledge."}
{"id": "2512.22793", "categories": ["eess.SY", "cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.22793", "abs": "https://arxiv.org/abs/2512.22793", "authors": ["Minh Bui", "Simon Monckton", "Mo Chen"], "title": "Reach-Avoid Differential game with Reachability Analysis for UAVs: A decomposition approach", "comment": "Paper version accepted to the Journal of Guidance, Control, and Dynamics (JGCD)", "summary": "Reach-avoid (RA) games have significant applications in security and defense, particularly for unmanned aerial vehicles (UAVs). These problems are inherently challenging due to the need to consider obstacles, consider the adversarial nature of opponents, ensure optimality, and account for nonlinear dynamics. Hamilton-Jacobi (HJ) reachability analysis has emerged as a powerful tool for tackling these challenges; however, while it has been applied to games involving two spatial dimensions, directly extending this approach to three spatial dimensions is impossible due to high dimensionality. On the other hand, alternative approaches for solving RA games lack the generality to consider games with three spatial dimensions involving agents with non-trivial system dynamics. In this work, we propose a novel framework for dimensionality reduction by decomposing the problem into a horizontal RA sub-game and a vertical RA sub-game. We then solve each sub-game using HJ reachability analysis and consider second-order dynamics that account for the defender's acceleration. To reconstruct the solution to the original RA game from the sub-games, we introduce a HJ-based tracking control algorithm in each sub-game that not only guarantees capture of the attacker but also tracking of the attacker thereafter. We prove the conditions under which the capture guarantees are maintained. The effectiveness of our approach is demonstrated via numerical simulations, showing that the decomposition maintains optimality and guarantees in the original problem. Our methods are also validated in a Gazebo physics simulator, achieving successful capture of quadrotors in three spatial dimensions space for the first time to the best of our knowledge."}
{"id": "2512.23357", "categories": ["math.NA", "math.CV"], "pdf": "https://arxiv.org/pdf/2512.23357", "abs": "https://arxiv.org/abs/2512.23357", "authors": ["Michael S. Ackermann", "Sean Reiter", "Lloyd N. Trefethen"], "title": "$L^2$ and $L^\\infty$ rational approximation", "comment": null, "summary": "Using recently developed algorithms, we compute and compare best $L^2$ and $L^\\infty$ rational approximations of analytic functions on the unit disk. Although there is some theory for these problems going back decades, this may be the first computational study. To compute the $L^2$ best approximations, we employ a new formulation of TF-IRKA in barycentric form."}
{"id": "2512.22782", "categories": ["quant-ph", "hep-lat"], "pdf": "https://arxiv.org/pdf/2512.22782", "abs": "https://arxiv.org/abs/2512.22782", "authors": ["Henry Froland", "Dorota M. Grabowska", "Zhiyao Li"], "title": "Simulating Fully Gauge-Fixed SU(2) Hamiltonian Dynamics on Digital Quantum Computers", "comment": "27 pages, 7 figures, 4 tables", "summary": "Quantum simulations of many-body systems offer novel methods for probing the dynamics of the Standard Model and its constituent gauge theories. Extracting low-energy predictions from such simulations rely on formulating systematically-improvable representations of lattice gauge theory Hamiltonians that are efficient at all values of the gauge coupling. One such candidate representation for SU(2) is the fully gauge-fixed Hamiltonian defined in the mixed basis. This work focuses on the quantum simulation of the smallest non-trivial system: two plaquettes with open boundary conditions. A mapping of the continuous gauge field degrees of freedom to qubit-based representations is developed. It is found that as few as three qubits per plaquette is sufficient to reach per-mille level precision on predictions for observables. Two distinct algorithms for implementing time evolution in the mixed basis are developed and analyzed in terms of quantum resource estimates. One algorithm has favorable scaling in circuit depth for large numbers of qubits, while the other is more practical when qubit count is limited. The latter algorithm is used in the measurement of a real-time observable on IBM's Heron superconducting quantum processor, ibm_fez. The quantum results match classical predictions at the percent-level. This work lays out a path forward for two- and three-dimensional simulations of larger systems, as well as demonstrating the viability of mixed-basis formulations for studying the properties of SU(2) gauge theories at all values of the gauge coupling."}
{"id": "2512.22714", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.22714", "abs": "https://arxiv.org/abs/2512.22714", "authors": ["Matey Neykov"], "title": "Polynomial-Time Near-Optimal Estimation over Certain Type-2 Convex Bodies", "comment": null, "summary": "We develop polynomial-time algorithms for near-optimal minimax mean estimation under $\\ell_2$-squared loss in a Gaussian sequence model under convex constraints. The parameter space is an origin-symmetric, type-2 convex body $K \\subset \\mathbb{R}^n$, and we assume additional regularity conditions: specifically, we assume $K$ is well-balanced, i.e., there exist known radii $r, R > 0$ such that $r B_2 \\subseteq K \\subseteq R B_2$, as well as oracle access to the Minkowski gauge of $K$. Under these and some further assumptions on $K$, our procedures achieve the minimax rate up to small factors, depending poly-logarithmically on the dimension, while remaining computationally efficient.\n  We further extend our methodology to the linear regression and robust heavy-tailed settings, establishing polynomial-time near-optimal estimators when the constraint set satisfies the regularity conditions above. To the best of our knowledge, these results provide the first general framework for attaining statistically near-optimal performance under such broad geometric constraints while preserving computational tractability."}
{"id": "2512.22659", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.22659", "abs": "https://arxiv.org/abs/2512.22659", "authors": ["Nabil Awan", "Richard J. Chappell"], "title": "Ranked Set Sampling in Survival Analysis", "comment": "This manuscript is a preprint prepared for dissemination and feedback. The results are complete, and submission to a peer-reviewed statistics journal is planned", "summary": "Ranked set sampling (RSS) is a cost-efficient study design that uses inexpensive baseline ranking to select a more informative subset of individuals for full measurement. While RSS is well known to improve precision over simple random sampling (SRS) for uncensored outcomes, survival analysis under RSS has largely been limited to estimation of the Kaplan-Meier survival curve under random censoring. Consequently, many standard tools routinely used with SRS data, including log-rank and weighted log-rank tests, restricted mean survival time summaries, and window-based mean life measures, are not yet fully developed for RSS settings, particularly when ranking is imperfect and censoring is present.\n  This work develops a unified survival analysis framework for balanced RSS designs that preserves efficiency gains while providing the inferential tools expected in applied practice. We formalize Kaplan-Meier and Nelson-Aalen estimators for right-censored data under both perfect and concomitant-based imperfect ranking and establish their large-sample properties using martingale and empirical process methods adapted to the rank-wise RSS structure. Rank-aware Greenwood-type variance estimators are proposed, and efficiency relative to SRS is evaluated through simulation studies varying set size, number of cycles, censoring proportion, and ranking quality. The framework is further extended to log-rank and Fleming-Harrington weighted tests, as well as restricted and window mean life functionals with asymptotic variance formulas and two-sample comparisons. An implementation plan with real-data illustrations is provided to facilitate practical use."}
{"id": "2512.23212", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2512.23212", "abs": "https://arxiv.org/abs/2512.23212", "authors": ["Amod Holla", "Sumedh Chatterjee", "Sutanu Sen", "Anushka Mukherjee", "Fernando Garcia-Redondo", "Dwaipayan Biswas", "Francesca Iacopi", "Kaushik Roy"], "title": "LIMO: Low-Power In-Memory-Annealer and Matrix-Multiplication Primitive for Edge Computing", "comment": "26 pages, 12 figures; under review", "summary": "Combinatorial optimization (CO) underpins applications in science and engineering, ranging from logistics to electronic design automation. A classic example is the NP-complete Traveling Salesman Problem (TSP). Finding exact solutions for large-scale TSP instances remains computationally intractable; on von Neumann architectures, such solvers are constrained by the memory wall, incurring compute-memory traffic that grows with instance size. Metaheuristics, such as simulated annealing implemented on compute-in-memory (CiM) architectures, offer a way to mitigate the von Neumann bottleneck. This is accomplished by performing in-memory optimization cycles to rapidly find approximate solutions for TSP instances. Yet this approach suffers from degrading solution quality as instance size increases, owing to inefficient state-space exploration. To address this, we present LIMO, a mixed-signal computational macro that implements an in-memory annealing algorithm with reduced search-space complexity. The annealing process is aided by the stochastic switching of spin-transfer-torque magnetic-tunnel-junctions (STT-MTJs) to escape local minima. For large instances, our macro co-design is complemented by a refinement-based divide-and-conquer algorithm amenable to parallel optimization in a spatial architecture. Consequently, our system comprising several LIMO macros achieves superior solution quality and faster time-to-solution on instances up to 85,900 cities compared to prior hardware annealers. The modularity of our annealing peripherals allows the LIMO macro to be reused for other applications, such as vector-matrix multiplications (VMMs). This enables our architecture to support neural network inference. As an illustration, we show image classification and face detection with software-comparable accuracy, while achieving lower latency and energy consumption than baseline CiM architectures."}
{"id": "2512.22710", "categories": ["physics.ao-ph", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2512.22710", "abs": "https://arxiv.org/abs/2512.22710", "authors": ["Georg A. Gottwald", "Eli Tziperman", "Alexey Fedorov"], "title": "Contrasting different noise models for representing westerly wind bursts in a recharge oscillator model of ENSO", "comment": null, "summary": "Westerly wind bursts (WWBs) have long been known to have a major impact on the development of El Niño events. In particular, they amplify these events, with stronger events associated with a higher number of WWBs. We further find indications that WWBs lead to a more monotonically increasing evolution of warming events. We consider here a noise-driven recharge oscillator model of ENSO. Commonly, WWBs are represented by a state-dependent Gaussian noise which naturally reproduces the amplification of warm events. However, we show that many properties of WWBs and their effects on sea surface temperature (SST) are not well captured by such Gaussian noise. Instead, we show that conditional additive and multiplicative (CAM) noise presents a promising alternative. In addition to recovering the sporadic nature of WWBs, CAM noise leads to an asymmetry between El Niño and La Niña events without the need for deterministic nonlinearities. Furthermore, CAM noise generates a more monotonic increase of extreme warming events with a higher frequency of WWBs accompanying the largest events. This suggests that extreme warm events are better modelled by CAM noise. To cover the full spectrum of warm events we propose a conditional noise model in which the wind stress is modelled by additive Gaussian noise for sufficiently small SSTs and by additive CAM noise once the SST exceeds a certain threshold. We show that this conditional noise model captures the observed properties of WWBs reasonably well."}
{"id": "2512.22157", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.22157", "abs": "https://arxiv.org/abs/2512.22157", "authors": ["Nikolaj Maack Bielefeld"], "title": "A Radiation Exchange Factor Transformation with Proven Convergence, Non-Negativity, and Energy Conservation", "comment": null, "summary": "This paper presents a matrix-based exchange factor transformation for solving coupled mixed boundary condition radiative transfer problems on general domains. The method applies to participating media ranging from transparent to absorbing, emitting, and scattering, with boundaries ranging from absorbing to reflecting. Given a first-interaction exchange factor matrix $\\mathbf{F}$, the transformation produces an absorption matrix $\\mathbf{A}$ and a multiple reflection-scattering matrix $\\mathbf{R}$ through a Neumann series that analytically traces all reflection-scattering paths to steady state. The paper establishes rigorous conditions under which the method guarantees convergence, non-negative radiation, and exact energy conservation to machine precision. A comparison with Noble's matrix formulation of Hottel's zonal method reveals a previously unidentified discrepancy in that classical approach; the proposed transformation eliminates this discrepancy. The method is validated against the diffusion approximation in the high-extinction limit and against results of Crosbie and Schrenker for pure and partial scattering cases. The method is applicable to medium-scale general reflecting-scattering problems and scales to large problems when negligible reflection-scattering and high extinction ensure matrix sparsity."}
{"id": "2512.23608", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.23608", "abs": "https://arxiv.org/abs/2512.23608", "authors": ["Chuyi Tuo", "Ming-Rui Li", "Hong Yao"], "title": "Fractional quantum anomalous Hall and anyon density-wave halo in a minimal interacting lattice model of twisted bilayer MoTe$_2$", "comment": "13 pages, 8 figures", "summary": "The experimental discovery of fractional quantum anomalous Hall (FQAH) states in tunable moiré superlattices has sparked intense interest in exploring the interplay between topological order and symmetry breaking phases. In this paper, we present a comprehensive numerical study of this interplay through large-scale density matrix renormalization group (DMRG) simulations on a minimal two-band lattice model of twisted bilayer MoTe$_2$ at filling $ν=-2/3$. We find robust FQAH ground states and provide clear numerical evidences for anyon excitations with fractional charge and pronounced real-space density modulations, directly supporting the recently proposed anyon density-wave halo picture. We also map out the displacement field dependent phase diagram, uncovering a rich landscape of charge ordered states emerging from the FQAH, including a quantum anomalous Hall crystal (QAHC) with an integer quantized Hall conductance. We expect our work to inspire further research interest of intertwined correlated topological phases in moiré systems."}
{"id": "2512.22332", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22332", "abs": "https://arxiv.org/abs/2512.22332", "authors": ["Naw Sai"], "title": "Resonance matching of 2-$δ$ and 3-$δ$ potentials in 1D Quantum Scattering", "comment": null, "summary": "We investigate whether a 3-$δ$ system with positive coupling strengths can approximate the transmission spectrum of a 2-$δ$ resonance system with opposite-sign couplings for $k <3$. Theoretical analysis establishes exact isospectrality -- perfectly matched transmission spectrum -- is impossible for physically non-trivial configurations, while numerical experiments identify the minimal constraint set for practicability. These results establish both the practical limits and achievable accuracy of resonance matching under sign constraints, with implications for understanding spectral non-uniqueness in quantum scattering problems."}
{"id": "2512.23129", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.23129", "abs": "https://arxiv.org/abs/2512.23129", "authors": ["Zoey Zhou"], "title": "Survey on Lattice Gas Models on 2D Lattices: Critical Behavior of Closed Trajectories", "comment": "11 pages, 1 figure", "summary": "Lorentz lattice gases (LLGs) are discrete-time transport models in which a point particle moves ballistically between lattice sites and is scattered by randomly placed, quenched local scatterers such as ``rotators'' or ``mirrors.'' Despite the elementary update rules, LLGs exhibit rich dynamical regimes: typically, trajectories close quickly and the distribution of loop lengths has exponential tails, but at special concentrations of scatterers one observes critical behavior with scale-free statistics and fractal geometry. This survey focuses on the critical behavior of closed trajectories in two-dimensional LLGs, starting from the numerical study of Cao and Cohen, and its relation to percolation-hull scaling and kinetic hull-generating walks. We highlight the scaling hypothesis for loop-length distributions, the emergence of critical exponents $τ=15/7$, $d_f=7/4$, and $σ=3/7$ in several universality classes, and the appearance of alternative exponents in partially occupied models."}
{"id": "2512.22817", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.22817", "abs": "https://arxiv.org/abs/2512.22817", "authors": ["Sedi Bartz", "Heinz H. Bauschke", "Yuan Gao"], "title": "Baillon-Bruck-Reich revisited: divergent-series parameters and strong convergence in the linear case", "comment": "5 pages, 0 figures", "summary": "The Krasnoselskii-Mann iteration is an important algorithm in optimization and variational analysis for finding fixed points of nonexpansive mappings. In the general case, it produces a sequence converging \\emph{weakly} to a fixed point provided the parameter sequence satisfies a divergent-series condition.\n  In this paper, we show that \\emph{strong} convergence holds provided the underlying nonexpansive mapping is \\emph{linear}. This improves on a celebrated result by Baillon, Bruck, and Reich from 1978, where the parameter sequence was assumed to be constant as well as on recent work where the parameters were bounded away from $0$ and $1$."}
{"id": "2512.22859", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22859", "abs": "https://arxiv.org/abs/2512.22859", "authors": ["Tegenu Argaw Woldegiyorgis", "Hong Xian Li", "Fekadu Chekol Admassu", "Merkebu Gezahegne", "Abdurohman Kebede", "Tadese Abera", "Haris Ishaq", "Eninges Asmare"], "title": "Assessment of a Hybrid Energy System for Reliable and Sustainable Power Supply to Boru Meda Hospital in Ethiopia", "comment": null, "summary": "This study aims to evaluate the techno-economic feasibility of hybrid energy systems (HES) including Grid for providing reliable and sustainable power to Boru Meda Hospital, Ethiopia. HOMER pro 3.11.2 was used to design and evaluate a novel, integrated optimization and comparative assessment of diverse HRES, specif ically adjusted to the energy consumptions and available resources of the Hospital. The scenario evaluation showed that interconnecting photovoltaic (PV), biomass generator (BG), wind power (WP), diesel generator (DG), battery, and converter can effectively provide the Hospital's daily energy consumption of 11,214.66 kWh while conforming reliability and reducing emissions. The PV/BG/batt/conv configuration emerged as the most cost-effective and sustainable alternative, attaining the lowest LCOE of \\$0.339/kWh, an NPC of \\$25.7 million, and a 100% renewable energy fraction with simple pay back of 7.26 yr. As a result, the operational cost associated with the consumption of 500.00 L of diesel per month can be entirely avoided. The DG-integrated hybrids exhibit advanced techno-economic capability with significant worth, strong ROI (20\\%) and IRR (18\\%), endorsed by fast capital recovery (7.21-8.71 years). Overall, the hybrid system offers an optimal balance of cost, reliability, and sustainability, making it a promising and scalable solution for electrification of energy scare institution and areas in Ethiopia, thereby contributing to national sustainable energy development goals."}
{"id": "2512.22859", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22859", "abs": "https://arxiv.org/abs/2512.22859", "authors": ["Tegenu Argaw Woldegiyorgis", "Hong Xian Li", "Fekadu Chekol Admassu", "Merkebu Gezahegne", "Abdurohman Kebede", "Tadese Abera", "Haris Ishaq", "Eninges Asmare"], "title": "Assessment of a Hybrid Energy System for Reliable and Sustainable Power Supply to Boru Meda Hospital in Ethiopia", "comment": null, "summary": "This study aims to evaluate the techno-economic feasibility of hybrid energy systems (HES) including Grid for providing reliable and sustainable power to Boru Meda Hospital, Ethiopia. HOMER pro 3.11.2 was used to design and evaluate a novel, integrated optimization and comparative assessment of diverse HRES, specif ically adjusted to the energy consumptions and available resources of the Hospital. The scenario evaluation showed that interconnecting photovoltaic (PV), biomass generator (BG), wind power (WP), diesel generator (DG), battery, and converter can effectively provide the Hospital's daily energy consumption of 11,214.66 kWh while conforming reliability and reducing emissions. The PV/BG/batt/conv configuration emerged as the most cost-effective and sustainable alternative, attaining the lowest LCOE of \\$0.339/kWh, an NPC of \\$25.7 million, and a 100% renewable energy fraction with simple pay back of 7.26 yr. As a result, the operational cost associated with the consumption of 500.00 L of diesel per month can be entirely avoided. The DG-integrated hybrids exhibit advanced techno-economic capability with significant worth, strong ROI (20\\%) and IRR (18\\%), endorsed by fast capital recovery (7.21-8.71 years). Overall, the hybrid system offers an optimal balance of cost, reliability, and sustainability, making it a promising and scalable solution for electrification of energy scare institution and areas in Ethiopia, thereby contributing to national sustainable energy development goals."}
{"id": "2512.23362", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.23362", "abs": "https://arxiv.org/abs/2512.23362", "authors": ["Duan-Peng Ling", "Wenlong Zhang"], "title": "A Data-Driven Approach to Solving First-Kind Fredholm Integral Equations and Their Convergence Analysis", "comment": null, "summary": "We investigate the statistical recovery of solutions to first-kind Fredholm integral equations with discrete, scattered, and noisy pointwise measurements. Assuming the forward operator's range belongs to the Sobolev space of order $m$, which implies algebraic singular-value decay $s_j\\le Cj^{-m}$, we derive optimal upper bounds for the reconstruction error in the weak topology under an a priori choice of the regularization parameter. For bounded-variance noise, we establish mean-square error rates that explicitly quantify the dependence on sample size $n$, noise level $σ$, and smoothness index $m$; under sub-Gaussian noise, we strengthen these to exponential concentration bounds. The analysis yields an explicit a priori and a posteriori rule for the regularization parameter. Numerical experiments validate the theoretical results and demonstrate the efficiency of our practical parameter choice."}
{"id": "2512.22932", "categories": ["quant-ph", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.22932", "abs": "https://arxiv.org/abs/2512.22932", "authors": ["Masanori Hanada", "Shunji Matsuura", "Andreas Schafer", "Jinzhao Sun"], "title": "Gauge Symmetry in Quantum Simulation", "comment": "Supplementary material is available in the source files of this submission", "summary": "Quantum simulation of non-Abelian gauge theories requires careful handling of gauge redundancy. We address this challenge by presenting universal principles for treating gauge symmetry that apply to any quantum simulation approach, clarifying that physical states need not be represented solely by gauge singlets. Both singlet and non-singlet representations are valid, with distinct practical trade-offs, which we elucidate using analogies to BRST quantization. We demonstrate these principles within a complete quantum simulation framework based on the orbifold lattice, which enables explicit and efficient circuit constructions relevant to real-world QCD. For singlet-based approaches, we introduce a Haar-averaging projection implemented via linear combinations of unitaries, and analyze its cost and truncation errors. Beyond the singlet-approach, we show how non-singlet approaches can yield gauge-invariant observables through wave packets and string excitations. This non-singlet approach is proven to be both universal and efficient. Working in temporal gauge, we provide explicit mappings of lattice Yang-Mills dynamics to Pauli-string Hamiltonians suitable for Trotterization. Classical simulations of small systems validate convergence criteria and quantify truncation and Trotter errors, showing concrete resource estimates and scalable circuit recipes for SU($N$) gauge theories. Our framework provides both conceptual clarity and practical tools toward quantum advantage in simulating non-Abelian gauge theories."}
{"id": "2512.22866", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.22866", "abs": "https://arxiv.org/abs/2512.22866", "authors": ["Afshin Yaghoubi", "Esmaile Khorram", "Omid Naghshineh Arjmand"], "title": "A Recursive Exponential-Gamma Mixture: a New Generalized of the Lindley Distribution", "comment": null, "summary": "The Lindley distribution was first introduced by Lindley in 1958 for Bayesian computations. Over the past years, various generalizations of this distribution have been proposed by different authors. The generalized Lindley distributions sometimes have many parameters, and although they show good flexibility, their statistical form becomes complicated. In this article, we propose a new and simple distribution determined by the recursive relation of the Lindley distribution and the Gamma distribution with specific weights. Subsequently, some statistical properties of this distribution are examined, and with real numerical examples, its superiority over the Lindley generalizations is demonstrated."}
{"id": "2512.23250", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.23250", "abs": "https://arxiv.org/abs/2512.23250", "authors": ["Shaoxin Wang", "Ziyun Ma"], "title": "Robust and Well-conditioned Sparse Estimation for High-dimensional Covariance Matrices", "comment": "25 pages, 2 figures", "summary": "Estimating covariance matrices with high-dimensional complex data presents significant challenges, particularly concerning positive definiteness, sparsity, and numerical stability. Existing robust sparse estimators often fail to guarantee positive definiteness in finite samples, while subsequent positive-definite correction can degrade sparsity and lack explicit control over the condition number. To address these limitations, we propose a novel robust and well-conditioned sparse covariance matrix estimator. Our key innovation is the direct incorporation of a condition number constraint within a robust adaptive thresholding framework. This constraint simultaneously ensures positive definiteness, enforces a controllable level of numerical stability, and preserves the desired sparse structure without resorting to post-hoc modifications that compromise sparsity. We formulate the estimation as a convex optimization problem and develop an efficient alternating direction algorithm with guaranteed convergence. Theoretically, we establish that the proposed estimator achieves the minimax optimal convergence rate under the Frobenius norm. Comprehensive simulations and real-data applications demonstrate that our method consistently produces positive definite, well-conditioned, and sparse estimates, and achieves comparable or superior numerical stability to eigenvalue-bound methods while requiring less tuning parameters."}
{"id": "2512.23383", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2512.23383", "abs": "https://arxiv.org/abs/2512.23383", "authors": ["Hakan Yildiz", "Axel Küpper"], "title": "interID - An Ecosystem-agnostic Verifier Application for Self-sovereign Identity", "comment": null, "summary": "Self-Sovereign Identity is a transformative paradigm in digital identity management, empowering individuals with full control over their credentials. However, the coexistence of diverse SSI ecosystems, such as the European Digital Identity and the European Blockchain Services Infrastructure, poses significant challenges for cross-ecosystem interoperability due to technological and trust framework differences. This paper introduces \\textit{interID}, a modular credential verification application that addresses this fragmentation by orchestrating ecosystem-specific verifier services. Our key contributions include: (1) an ecosystem-agnostic orchestration layer that interfaces with multiple SSI verification services, (2) a unified API that abstracts underlying protocol complexities for service providers, and (3) a practical implementation that bridges three major SSI ecosystems: Hyperledger Indy/Aries, EBSI, and EUDI. Evaluation results demonstrate that interID successfully verifies credentials across all tested wallets with minimal performance overhead, while maintaining a flexible architecture that can be extended to accept credentials from additional SSI ecosystems. This work offers both a technical solution and architectural pattern for achieving interoperability in SSI verifier implementations."}
{"id": "2512.22397", "categories": ["physics.comp-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22397", "abs": "https://arxiv.org/abs/2512.22397", "authors": ["Behzad Parvaresh", "Rahmat K. Adesunkanmi", "Adel Alaeddini"], "title": "Integrating Wide and Deep Neural Networks with Squeeze-and-Excitation Blocks for Multi-Target Property Prediction in Additively Manufactured Fiber Reinforced Composites", "comment": "This manuscript has been submitted to an Elsevier journal for possible publication", "summary": "Continuous fiber-reinforced composite manufactured by additive manufacturing (CFRC-AM) offers opportunities for printing lightweight materials with high specific strength. However, their performance is sensitive to the interaction of process and material parameters, making exhaustive experimental testing impractical. In this study, we introduce a data-efficient, multi-input, multi-target learning approach that integrates Latin Hypercube Sampling (LHS)-guided experimentation with a squeeze-and-excitation wide and deep neural network (SE-WDNN) to jointly predict multiple mechanical and manufacturing properties of CFRC-AMs based on different manufacturing parameters. We printed and tested 155 specimens selected from a design space of 4,320 combinations using a Markforged Mark Two 3D printer. The processed data formed the input-output set for our proposed model. We compared the results with those from commonly used machine learning models, including feedforward neural networks, Kolmogorov-Arnold networks, XGBoost, CatBoost, and random forests. Our model achieved the lowest overall test error (MAPE = 12.33%) and showed statistically significant improvements over the baseline wide and deep neural network for several target variables (paired t-tests, p <= 0.05). SHapley Additive exPlanations (SHAP) analysis revealed that reinforcement strategy was the major influence on mechanical performance. Overall, this study demonstrates that the integration of LHS and SE-WDNN enables interpretable and sample-efficient multi-target predictions, guiding parameter selection in CFRC-AM with a balance between mechanical behavior and manufacturing metrics."}
{"id": "2512.23655", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.23655", "abs": "https://arxiv.org/abs/2512.23655", "authors": ["R. J. Spieker", "B. Krohnke", "D. Zhai", "A. Lopez Benet", "M. Spaić", "X. He", "C. Y. Tan", "Z. W. Anderson", "F. Ye", "H. Cao", "M. J. Krogstad", "R. Osborn", "D. Pelc", "M. Greven"], "title": "Evidence for rare-region physics in the structural and electronic degrees of freedom of the nickelate La$_{2-x}$Sr$_x$NiO$_4$", "comment": "20 pages, 10 figures, supplementary material included", "summary": "We present a diffuse neutron and x-ray scattering study of structural, spin- and charge-density-wave fluctuations in the electrical insulator La$_{2-x}$Sr$_x$NiO$_4$. This lamellar nickelate is an isostructural analogue of the high-temperature cuprate superconductor La$_{2-x}$Sr$_x$CuO$_4$, for which recent experiments uncovered evidence for unusual structural and superconducting fluctuations indicative of rare-region physics due to inherent inhomogeneity unrelated to common point disorder effects. We find closely analogous nanoscale orthorhombic fluctuation behavior in La$_{2-x}$Sr$_x$NiO$_4$, including exponential scaling of the diffuse scattering intensity and power-law scaling of the characteristic length with relative temperature. Moreover, our neutron and x-ray scattering data reveal similar behavior for short-range magnetic and charge fluctuations above the respective ordering temperatures. These observations indicate that rare-region effects are a generic feature of perovskite-related structures and lead to universal fluctuations of both structural and electronic degrees of freedom over extended temperature ranges."}
{"id": "2512.22352", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.22352", "abs": "https://arxiv.org/abs/2512.22352", "authors": ["Anna-Maria Alexandrova", "Jesus Valdiviezo"], "title": "Casimir Arc Plate Geometry: Computational Analysis of Thickness Constraints for Gold and Silver Nanomembranes in MEMS Applications", "comment": "19 pages, 4 figures, 3 tables", "summary": "A theoretical analysis of the Casimir interaction between an arc and plate is conducted, which remains unexplored despite its relevance to Micro-Electro-Mechanical Systems (MEMS) fabrication. The configuration consists of a rigid finite plate and a flexible curved nanomembrane, with radius 100 micrometers, initially concave toward the rigid plate. The maximum thickness is evaluated for which the nanomembrane undergoes a change in curvature: from concave to convex with respect to the plate, due to the Casimir interaction. The Casimir energy for a curved surface is derived using the Proximity Force Approximation (PFA) with next-to-leading-order (NTLO) corrections. Kirchhoff-Love theory for a thin isotropic plate of constant thickness is used to estimate the bending energy. Material-dependent effects on the Casimir interaction are evaluated by comparing Au and Ag plates. The maximum thickness is derived where U_Casimir > U_bending for distances in the range of 0.1-1 micrometers. Results show curvature reversal occurs for nanomembranes with nanoscale thicknesses at the studied distances. Silver nanomembranes tolerate greater thickness than gold nanomembranes due to material-dependent properties. Comparison between NTLO-corrected PFA and perturbative PFA confirms the accuracy of the NTLO approach. The Casimir arc-to-plate geometry in MEMS enables Casimir-based actuation, enhances devices reliability, and prevents stiction. These findings provide thickness constraints for MEMS design and performance, accounting for the Casimir force."}
{"id": "2512.23349", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.23349", "abs": "https://arxiv.org/abs/2512.23349", "authors": ["L. Delzescaux", "D. Mouhanna"], "title": "Renormalization group approach to graphene bilayers", "comment": "25 pages, 10 figures", "summary": "We investigate the effects of thermal fluctuations in graphene bilayers by means of a nonperturbative renormalization group (NPRG) approach, following the pioneering work of Mauri et al. [Phys. Rev. B 102, 165421 (2020)] based on a self-consistent screening approximation (SCSA). We consider a model of two continuum polymerized membranes, separated by a distance $\\ell$, in their flat phase, coupled by interlayer shear, compression/dilatation and elastic terms. Within a controlled truncation of the effective average action, we retain only the contributions that generate a pronounced crossover of the effective bending rigidity along the renormalization group flow between two regimes: at high running scale $k$, the rigidity is dominated by the in-plane elastic properties, with $κ_{\\mathrm{eff}}\\sim \\ell^{2}(λ+2μ)/2$, whereas at low $k$ it is controlled by the bending rigidity of two independent monolayers, $κ_{\\mathrm{eff}}\\sim 2κ$. This crossover is reminiscent of that observed by Mauri et al. as a function of the wavevector scale $q$, but here it is obtained within a renormalization group framework. This has several advantages. First, although approximations are performed, the NPRG approach allows one, in principle, to take into account all nonlinearities present in the elastic theory, in contrast to the SCSA treatment which requires, already at the formal level, significant simplifications. Second, it demonstrates that the bilayer problem can be treated as a straightforward extension of the monolayer case, with flow equations that keep the same structure and differ only by bilayer-specific adjustments. Third, unlike the SCSA, the NPRG framework admits a controlled, systematically improvable, hierarchy of approximations."}
{"id": "2512.22909", "categories": ["math.OC", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.22909", "abs": "https://arxiv.org/abs/2512.22909", "authors": ["Zhaosong Lu", "Sanyou Mei"], "title": "A first-order method for nonconvex-strongly-concave constrained minimax optimization", "comment": "Accepted by Optimization Methods and Software", "summary": "In this paper we study a nonconvex-strongly-concave constrained minimax problem. Specifically, we propose a first-order augmented Lagrangian method for solving it, whose subproblems are nonconvex-strongly-concave unconstrained minimax problems and suitably solved by a first-order method developed in this paper that leverages the strong concavity structure. Under suitable assumptions, the proposed method achieves an \\emph{operation complexity} of $O(\\varepsilon^{-3.5}\\log\\varepsilon^{-1})$, measured in terms of its fundamental operations, for finding an $\\varepsilon$-KKT solution of the constrained minimax problem, which improves the previous best-known operation complexity by a factor of $\\varepsilon^{-0.5}$."}
{"id": "2512.22901", "categories": ["eess.SY", "cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.22901", "abs": "https://arxiv.org/abs/2512.22901", "authors": ["Si-Yu Xiao", "Xin-Di Zhao", "Xiang-Zhan Wang", "Tian-Hao Mao", "Ying-Kai Liao", "Xing-Yu Liao", "Yu-Qiao Chen", "Jun-Jie Wang", "Shuang Liu", "Tu-Pei Chen", "Yang Liu"], "title": "A Neural Network-Based Real-time Casing Collar Recognition System for Downhole Instruments", "comment": null, "summary": "Accurate downhole positioning is critical in oil and gas operations but is often compromised by signal degradation in traditional surface-based Casing Collar Locator (CCL) monitoring. To address this, we present an in-situ, real-time collar recognition system using embedded neural network. We introduce lightweight \"Collar Recognition Nets\" (CRNs) optimized for resource-constrained ARM Cortex-M7 microprocessors. By leveraging temporal and depthwise separable convolutions, our most compact model reduces computational complexity to just 8,208 MACs while maintaining an F1 score of 0.972. Hardware validation confirms an average inference latency of 343.2 μs, demonstrating that robust, autonomous signal processing is feasible within the severe power and space limitations of downhole instrumentation."}
{"id": "2512.22901", "categories": ["eess.SY", "cs.AI", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.22901", "abs": "https://arxiv.org/abs/2512.22901", "authors": ["Si-Yu Xiao", "Xin-Di Zhao", "Xiang-Zhan Wang", "Tian-Hao Mao", "Ying-Kai Liao", "Xing-Yu Liao", "Yu-Qiao Chen", "Jun-Jie Wang", "Shuang Liu", "Tu-Pei Chen", "Yang Liu"], "title": "A Neural Network-Based Real-time Casing Collar Recognition System for Downhole Instruments", "comment": null, "summary": "Accurate downhole positioning is critical in oil and gas operations but is often compromised by signal degradation in traditional surface-based Casing Collar Locator (CCL) monitoring. To address this, we present an in-situ, real-time collar recognition system using embedded neural network. We introduce lightweight \"Collar Recognition Nets\" (CRNs) optimized for resource-constrained ARM Cortex-M7 microprocessors. By leveraging temporal and depthwise separable convolutions, our most compact model reduces computational complexity to just 8,208 MACs while maintaining an F1 score of 0.972. Hardware validation confirms an average inference latency of 343.2 μs, demonstrating that robust, autonomous signal processing is feasible within the severe power and space limitations of downhole instrumentation."}
{"id": "2512.23363", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23363", "abs": "https://arxiv.org/abs/2512.23363", "authors": ["Tommaso Taddei", "Xuejun Xu", "Lei Zhang"], "title": "High-order implicit Runge-Kutta time integrators for component-based model reduction of FSI problems", "comment": null, "summary": "We propose a model order reduction framework for incompressible fluid-structure interaction (FSI) problems based on high-order implicit Runge-Kutta (IRK) methods. We consider separate reduced spaces for fluid velocity, fluid pressure and solid displacement; we enrich the velocity space with supremizer modes to ensure the inf-sup stability of the fluid subproblem; we consider bubble-port decomposition of fluid velocity and solid displacement to satisfy the kinematic conditions at the fluid structure interface. We resort to Galerkin projection to define the semi-discrete reduced-order model and we consider a Radau-IIA IRK method for time integration: the resulting algebraic system is solved using static condensation of the interface degrees of freedom. The reduced-order model preserves a semi-discrete energy balance inherited from the full-order model, and avoids the need for additional interface enrichment. Numerical experiments demonstrate that the proposed combination of high-order IRK schemes with bubble-port decoupling of velocity and displacement degrees of freedom yields stable and accurate reduced-order model for long-time integration of strongly-coupled parametric FSI problems."}
{"id": "2512.23047", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.23047", "abs": "https://arxiv.org/abs/2512.23047", "authors": ["Sayantan Banerjee"], "title": "Bayesian Effective Dimension: A Mutual Information Perspective", "comment": null, "summary": "High-dimensional Bayesian procedures often exhibit behavior that is effectively low dimensional, even when the ambient parameter space is large or infinite-dimensional. This phenomenon underlies the success of shrinkage priors, regularization, and approximate Bayesian methods, yet it is typically described only informally through notions such as sparsity, intrinsic dimension, or degrees of freedom. In this paper we introduce the \\emph{Bayesian effective dimension}, a model- and prior-dependent quantity defined through the mutual information between parameters and data. This notion quantifies the expected information gain from prior to posterior and provides a coordinate-free measure of how many directions in parameter space are statistically learnable at a given sample size. In regular parametric models the effective dimension coincides with the usual parameter dimension, while in high-dimensional, ill-posed, or strongly regularized settings it can be substantially smaller. We develop basic properties of the effective dimension and present explicit calculations for Gaussian location models and linear models with general design, revealing close connections with spectral complexity and effective rank. These examples illustrate how shrinkage and regularization mechanisms directly control the growth of effective dimension. The framework offers a unifying perspective on dimension reduction in Bayesian inference and provides insight into uncertainty quantification and the behavior of approximate posterior distributions."}
{"id": "2512.23251", "categories": ["stat.ME", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2512.23251", "abs": "https://arxiv.org/abs/2512.23251", "authors": ["Wang Yinbu", "Xu Yong"], "title": "A Wide-Sense Stationarity Test Based on the Geometric Structure of Covariance", "comment": null, "summary": "This paper presents a test for wide-sense stationarity (WSS) based on the geometry of the covariance function. We estimate local patches of the covariance surface and then check whether the directional derivative in the $(1,1,0)$ direction is zero on each patch. The method only requires the covariance function to be locally smooth and does not assume stationarity in advance. It can be applied to general stochastic dynamical systems and provides a time-resolved view. We apply the test method to an SDOF system and to a stochastic Duffing oscillator. These examples show that the method is numerically stable and can detect departures from WSS in practice."}
{"id": "2512.22670", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.22670", "abs": "https://arxiv.org/abs/2512.22670", "authors": ["Gourav Yadav", "Shakti S. Gupta", "Roger A. Sauer"], "title": "A survey of interlayer interaction models for graphene and other 2D materials", "comment": "48 pages, 25 figures", "summary": "This work presents a survey of mechanical models describing van der Waals interactions between 2D materials, encompassing both continuous elastomer-like materials and discrete (crystalline) 2D materials such as graphene. These interactions give rise to a range of physical phenomena, including contact instabilities, Moiré patterns, surface reconstructions, and superlubricity. The underlying contact forces follow from the variation of an interfacial interaction potential. The presentation first discusses normal contact models, and then tangential contact models. Both atomistic and continuum approaches are considered. In addition, the influence of external loading and changes in length scale on the ground state configuration and frictional contact behavior are analyzed. A particular emphasis is placed on discussing strategies that reduce computational cost in multiscale modeling."}
{"id": "2512.23678", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.23678", "abs": "https://arxiv.org/abs/2512.23678", "authors": ["Igor Ermakov", "Oleg Lychkovskiy"], "title": "Symbolic recursion method for strongly correlated fermions in two and three dimensions", "comment": null, "summary": "We present a symbolic implementation of recursion method for the dynamics of strongly correlated fermions on one-, two- and three-dimensional lattices. Focusing on two paradigmatic models, interacting spinless fermions and the Hubbard model, we first directly confirm that the universal operator growth hypothesis holds for interacting fermionic systems, manifested by the linear growth of Lanczos coefficients. Equipped with symbolically computed Lanczos coefficients and knowledge of their asymptotics, we are able to compute infinite-temperature autocorrelation functions up to times long enough for thermalization to occur. In turn, the knowledge of autocorrelation functions unlocks transport properties. We compute with high precision the charge diffusion constant over a broad range of interaction strengths, $V$. Surprisingly, we observe that these results are well described by a simple functional dependence $\\sim 1/V^2$ universally valid both for small and large $V$. All results are obtained directly in the thermodynamic limit. Our results highlight the promise of symbolic computational paradigm where the most costly step is performed once and outputs symbolic results that can further be used multiple times to easily compute physical quantities for specific values of model parameters."}
{"id": "2512.22380", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22380", "abs": "https://arxiv.org/abs/2512.22380", "authors": ["Pavel Stránský", "Pavel Cejnar"], "title": "Creating multicomponent Schrödinger cat states in a coupled qubit-oscillator system", "comment": "6 pages of the main text, 10 pages of the supplemental material, includes a video file as an additional supplemental material", "summary": "We present a method for preparing various exotic modifications of Schrödinger cat states by coupling a semiclassical oscillator to a system of qubits. Varying the number of qubits and parameters of the quantum quench performed in the coupled system, we bring the oscillator into a~highly non-classical state composed of an arbitrary number of partly coherent wavepackets in tunable proportions and motion relations. The method can be implemented with the aid of current experimental techniques and may find applications in quantum information and sensing protocols."}
{"id": "2512.23625", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.23625", "abs": "https://arxiv.org/abs/2512.23625", "authors": ["Rameez Farooq Shah", "Syed Rashid Ahmad"], "title": "Universal Aging Dynamics and Scaling Laws in Three-Dimensional Driven Granular Gases", "comment": null, "summary": "We establish universal scaling laws and quantify aging in three-dimensional uniformly heated hard sphere granular gases through large-scale event-driven molecular dynamics ($N=500{,}000$). We report three primary quantitative discoveries: (i) The characteristic energy decay time exhibits a universal inverse scaling $τ_0 \\propto ε^{-1.03 \\pm 0.02}$ with the dissipation parameter $ε= 1 - e^2$. (ii) The steady-state temperature follows a precise power-law $T_{\\mathrm{steady}} \\propto ε^{-1.51 \\pm 0.03}$, reflecting the non-linear balance between thermostat heating and collisional dissipation. (iii) The velocity autocorrelation function $\\bar{A}(τ_w, τ)$ demonstrates pronounced aging, with decay rates $λ$ following a power-law slowing down $λ(τ_w) \\propto τ_w^{-0.82 \\pm 0.05}$. These results establish the first 3D quantitative benchmarks for aging in driven dissipative gases, where near-Gaussian statistics persist despite extreme structural clustering."}
{"id": "2512.22961", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22961", "abs": "https://arxiv.org/abs/2512.22961", "authors": ["Mathieu Laurière", "Mehdi Talbi"], "title": "Deep Learning for the Multiple Optimal Stopping Problem", "comment": null, "summary": "This paper presents a novel deep learning framework for solving multiple optimal stopping problems in high dimensions. While deep learning has recently shown promise for single stopping problems, the multiple exercise case involves complex recursive dependencies that remain challenging. We address this by combining the Dynamic Programming Principle with neural network approximation of the value function. Unlike policy-search methods, our algorithm explicitly learns the value surface. We first consider the discrete-time problem and analyze neural network training error. We then turn to continuous problems and analyze the additional error due to the discretization of the underlying stochastic processes. Numerical experiments on high-dimensional American basket options and nonlinear utility maximization demonstrate that our method provides an efficient and scalable method for the multiple optimal stopping problem."}
{"id": "2512.22914", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22914", "abs": "https://arxiv.org/abs/2512.22914", "authors": ["Liping Guo", "Jimin Wang", "Yanlong Zhao", "Ji-Feng Zhang"], "title": "Distributed Fusion Estimation with Protecting Exogenous Inputs", "comment": null, "summary": "In the context of distributed fusion estimation, directly transmitting local estimates to the fusion center may cause a privacy leakage concerning exogenous inputs. Thus, it is crucial to protect exogenous inputs against full eavesdropping while achieving distributed fusion estimation. To address this issue, a noise injection strategy is provided by injecting mutually independent noises into the local estimates transmitted to the fusion center. To determine the covariance matrices of the injected noises, a constrained minimization problem is constructed by minimizing the sum of mean square errors of the local estimates while ensuring (ε, δ)-differential privacy. Suffering from the non-convexity of the minimization problem, an approach of relaxation is proposed, which efficiently solves the minimization problem without sacrificing differential privacy level. Then, a differentially private distributed fusion estimation algorithm based on the covariance intersection approach is developed. Further, by introducing a feedback mechanism, the fusion estimation accuracy is enhanced on the premise of the same (ε, δ)-differential privacy. Finally, an illustrative example is provided to demonstrate the effectiveness of the proposed algorithms, and the trade-off between differential privacy level and fusion estimation accuracy."}
{"id": "2512.22914", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22914", "abs": "https://arxiv.org/abs/2512.22914", "authors": ["Liping Guo", "Jimin Wang", "Yanlong Zhao", "Ji-Feng Zhang"], "title": "Distributed Fusion Estimation with Protecting Exogenous Inputs", "comment": null, "summary": "In the context of distributed fusion estimation, directly transmitting local estimates to the fusion center may cause a privacy leakage concerning exogenous inputs. Thus, it is crucial to protect exogenous inputs against full eavesdropping while achieving distributed fusion estimation. To address this issue, a noise injection strategy is provided by injecting mutually independent noises into the local estimates transmitted to the fusion center. To determine the covariance matrices of the injected noises, a constrained minimization problem is constructed by minimizing the sum of mean square errors of the local estimates while ensuring (ε, δ)-differential privacy. Suffering from the non-convexity of the minimization problem, an approach of relaxation is proposed, which efficiently solves the minimization problem without sacrificing differential privacy level. Then, a differentially private distributed fusion estimation algorithm based on the covariance intersection approach is developed. Further, by introducing a feedback mechanism, the fusion estimation accuracy is enhanced on the premise of the same (ε, δ)-differential privacy. Finally, an illustrative example is provided to demonstrate the effectiveness of the proposed algorithms, and the trade-off between differential privacy level and fusion estimation accuracy."}
{"id": "2512.23476", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23476", "abs": "https://arxiv.org/abs/2512.23476", "authors": ["Laura Weidensager"], "title": "Sensitivity Analysis on the Sphere and a Spherical ANOVA Decomposition", "comment": null, "summary": "We establish sensitivity analysis on the sphere. We present formulas that allow us to decompose a function $f\\colon \\mathbb S^d\\rightarrow \\mathbb R$ into a sum of terms $f_{\\boldsymbol u,\\boldsymbol ξ}$. The index $\\boldsymbol u$ is a subset of $\\{1,2,\\ldots,d+1\\}$, where each term $f_{\\boldsymbol u,\\boldsymbol ξ}$ depends only on the variables with indices in $\\boldsymbol u$. In contrast to the classical analysis of variance (ANOVA) decomposition, we additionally use the decomposition of a function into functions with different parity, which adds the additional parameter $\\boldsymbol ξ$. The natural geometry on the sphere naturally leads to the dependencies between the input variables. Using certain orthogonal basis functions for the function approximation, we are able to model high-dimensional functions with low-dimensional variable interactions."}
{"id": "2512.23069", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.23069", "abs": "https://arxiv.org/abs/2512.23069", "authors": ["Eyar Azar", "Michael J. Feldman", "Boaz Nadler"], "title": "Robustness of OLS to sample removals: Theoretical analysis and implications", "comment": null, "summary": "For learned models to be trustworthy, it is essential to verify their robustness to perturbations in the training data. Classical approaches involve uncertainty quantification via confidence intervals and bootstrap methods. In contrast, recent work proposes a more stringent form of robustness: stability to the removal of any subset of $k$ samples from the training set. In this paper, we present a theoretical study of this criterion for ordinary least squares (OLS). Our contributions are as follows: (1) Given $n$ i.i.d. training samples from a general misspecified model, we prove that with high probability, OLS is robust to the removal of any $k \\ll n $ samples. (2) For data of dimension $p$, OLS can withstand up to ${k\\ll \\sqrt{np}/\\log n}$ sample removals while remaining robust and achieving the same error rate as OLS applied to the full dataset. Conversely, if $k$ is proportional to $n$, OLS is provably non-robust. (3) We revisit prior analyses that found several econometric datasets to be highly non-robust to sample removals. While this appears to contradict our results in (1), we demonstrate that the sensitivity is due to either heavy-tailed responses or correlated samples. Empirically, this sensitivity is considerably attenuated by classical robust methods, such as linear regression with a Huber loss."}
{"id": "2512.23395", "categories": ["stat.ME", "math.PR", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.23395", "abs": "https://arxiv.org/abs/2512.23395", "authors": ["David Bolin", "Peter Braunsteins", "Sebastian Engelke", "Raphaël Huser"], "title": "Intrinsic Whittle--Matérn fields and sparse spatial extremes", "comment": null, "summary": "Intrinsic Gaussian fields are used in many areas of statistics as models for spatial or spatio-temporal dependence, or as priors for latent variables. However, there are two major gaps in the literature: first, the number and flexibility of existing intrinsic models are very limited; second, theory, fast inference, and software are currently underdeveloped for intrinsic fields. We tackle these challenges by introducing the new flexible class of intrinsic Whittle--Matérn Gaussian random fields obtained as the solution to a stochastic partial differential equation (SPDE). Exploiting sparsity resulting from finite-element approximations, we develop fast estimation and simulation methods for these models. We demonstrate the benefits of this intrinsic SPDE approach for the important task of kriging under extrapolation settings. Leveraging the connection of intrinsic fields to spatial extreme value processes, we translate our theory to an SPDE approach for Brown--Resnick processes for sparse modeling of spatial extreme events. This new paradigm paves the way for efficient inference in unprecedented dimensions. To demonstrate the wide applicability of our new methodology, we apply it in two very different areas: a longitudinal study of renal function data, and the modeling of marine heat waves using high-resolution sea surface temperature data."}
{"id": "2512.22920", "categories": ["physics.comp-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.22920", "abs": "https://arxiv.org/abs/2512.22920", "authors": ["Christos Mystilidis", "Christos Tserkezis", "Guy A. E. Vandenbosch", "N. Asger Mortensen", "Xuezhi Zheng"], "title": "Overcoming Computational Bottlenecks in Quantum Hydrodynamics: A Volume-Based Integral Formalism", "comment": null, "summary": "Mesoscopic models of the optical response of metals have emerged as fundamental building blocks in quantum plasmonics, in principle overcoming the computational bottlenecks of ab initio techniques by implementing aspects of the atomistic description of the metal in otherwise classical calculations. Nonetheless, even these approaches are eventually hindered by demanding computations due to sophisticated material response. Here, this issue is addressed for the advanced Self-Consistent Hydrodynamic Drude Model (SC-HDM), which captures both nonlocal electron dynamics and electron spill-out, through a Volume Integral Equation (VIE) method. Adopting an IE-based method shifts perspective from the commonly employed Differential Equation (DE)-based ones, demonstrating significant computational efficiency. The VIE approach is a valuable methodological scaffold: It addresses SC-HDM and simpler models, but can also be adapted to more advanced ones. For spherical nanoparticles (NPs), using the inherent symmetries, similar performance for three increasingly complicated material models is achieved, breaking the taboo that increased sophistication in material response requires taxing simulations. Mesoscopic material-response functions can be readily extracted from the VIE implementation, thus circumventing the need for lengthy microscopic calculations. This method opens a new way of modeling quantum hydrodynamic NPs and will serve as essential benchmarking tool for recipes addressing more complicated geometries."}
{"id": "2512.23706", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23706", "abs": "https://arxiv.org/abs/2512.23706", "authors": ["Saranesh Prembabu", "Shu-Heng Shao", "Ruben Verresen"], "title": "Non-Invertible Interfaces Between Symmetry-Enriched Critical Phases", "comment": "11 pages, 7 figures + 4 page appendix", "summary": "Gapless quantum phases can become distinct when internal symmetries are enforced, in analogy with gapped symmetry-protected topological (SPT) phases. However, this distinction does not always lead to protected edge modes, raising the question of how the bulk-boundary correspondence is generalized to gapless cases. We propose that the spatial interface between gapless phases -- rather than their boundaries -- provides a more robust fingerprint. We show that whenever two 1+1d conformal field theories (CFTs) differ in symmetry charge assignments of local operators or twisted sectors, any symmetry-preserving spatial interface between the theories must flow to a non-invertible defect. We illustrate this general result for different versions of the Ising CFT with $\\mathbb{Z}_2 \\times \\mathbb{Z}_2^T$ symmetry, obtaining a complete classification of allowed conformal interfaces. When the Ising CFTs differ by nonlocal operator charges, the interface hosts 0+1d symmetry-breaking phases with finite-size splittings scaling as $1/L^3$, as well as continuous phase transitions between them. For general gapless phases differing by an SPT entangler, the interfaces between them can be mapped to conformal defects with a certain defect 't Hooft anomaly. This classification also gives implications for higher-dimensional examples, including symmetry-enriched variants of the 2+1d Ising CFT. Our results establish a physical indicator for symmetry-enriched criticality through symmetry-protected interfaces, giving a new handle on the interplay between topology and gapless phases."}
{"id": "2512.22395", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22395", "abs": "https://arxiv.org/abs/2512.22395", "authors": ["Brendan J. Mahoney", "Craig S. Lent"], "title": "The Lieb-Robinson correlation function for long disordered transverse-field Ising chains", "comment": "13 pages, 15 figures", "summary": "The transverse-field Ising model is useful for studying interacting qubit arrays. The Lieb--Robinson correlation function can be used to characterize the propagation of quantum information in Ising chains. Considerable work has been done to establish bounds on this correlation function in various circumstances. To actually calculate the value of the correlation function directly typically requires a state space which grows exponentially with system size, and so is intractable for all but relatively small systems. We employ a recently-developed method that enables direct calculation of the value of the Lieb--Robinson correlation function and which scales linearly with system size. This enables the computation for systems with many hundreds of qubits, revealing the propagation of quantum information down the chain. We extend this technique to the problem of Ising chains with randomly disordered coupling strengths. Increasing disorder causes localization of the quantum correlations and halts propagation of quantum information."}
{"id": "2512.23641", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.23641", "abs": "https://arxiv.org/abs/2512.23641", "authors": ["Urna Basu", "Satya N. Majumdar", "Alberto Rosso"], "title": "Ergodicity Breaking in Active Run-and-Tumble Particles in a Double-Well Potential", "comment": "8 pages, 4 figures", "summary": "We investigate the dynamics of a run-and-tumble particle in a double-well potential and demonstrate that, in stark contrast to Brownian particles, active dynamics can lead to strong ergodicity breaking. When the barrier height exceeds a critical threshold, the long-time position distribution depends crucially on the initial condition: if the particle starts within the basin of attraction of one well, it remains trapped there, while if it begins between the two basins, it can reach either well with a finite probability, which we compute exactly via hitting probabilities. Below the critical barrier height, ergodicity is restored and the system converges to a unique stationary distribution, which we derive analytically. Using this result, we also estimate the characteristic barrier crossing time and show that it violates Kramer's-Arrhenius law, and displays a divergence near the critical height following a Vogel-Fulcher-Tammann-like form with an anomalous exponent $1/2$."}
{"id": "2512.22986", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22986", "abs": "https://arxiv.org/abs/2512.22986", "authors": ["Siyi Wang", "Zifan Wang", "Karl H. Johansson"], "title": "Risk-Averse Learning with Varying Risk Levels", "comment": null, "summary": "In safety-critical decision-making, the environment may evolve over time, and the learner adjusts its risk level accordingly. This work investigates risk-averse online optimization in dynamic environments with varying risk levels, employing Conditional Value-at-Risk (CVaR) as the risk measure. To capture the dynamics of the environment and risk levels, we employ the function variation metric and introduce a novel risk-level variation metric. Two information settings are considered: a first-order scenario, where the learner observes both function values and their gradients; and a zeroth-order scenario, where only function evaluations are available. For both cases, we develop risk-averse learning algorithms with a limited sampling budget and analyze their dynamic regret bounds in terms of function variation, risk-level variation, and the total number of samples. The regret analysis demonstrates the adaptability of the algorithms in non-stationary and risk-sensitive settings. Finally, numerical experiments are presented to demonstrate the efficacy of the methods."}
{"id": "2512.22922", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22922", "abs": "https://arxiv.org/abs/2512.22922", "authors": ["Anton A. Stoorvogel", "Ali Saberi", "Zhenwei Liu", "Tayaba Yeasmin"], "title": "Weak state synchronization of homogeneous multi-agent systems with adaptive protocols", "comment": "This paper was submitted to 2026 CCDC at Dec. 25, 2025. Different from the submitted version, this version includes all simulation results", "summary": "In this paper, we study scale-free weak synchronization for multi-agent systems (MAS). In other words, we design a protocol for the agents without using any knowledge about the network. We do not\n  even require knowledge about the connectivity of the network. Each protocol contains an adaptive parameter to tune the protocol automatically to the demands of the network."}
{"id": "2512.22922", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22922", "abs": "https://arxiv.org/abs/2512.22922", "authors": ["Anton A. Stoorvogel", "Ali Saberi", "Zhenwei Liu", "Tayaba Yeasmin"], "title": "Weak state synchronization of homogeneous multi-agent systems with adaptive protocols", "comment": "This paper was submitted to 2026 CCDC at Dec. 25, 2025. Different from the submitted version, this version includes all simulation results", "summary": "In this paper, we study scale-free weak synchronization for multi-agent systems (MAS). In other words, we design a protocol for the agents without using any knowledge about the network. We do not\n  even require knowledge about the connectivity of the network. Each protocol contains an adaptive parameter to tune the protocol automatically to the demands of the network."}
{"id": "2512.23540", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23540", "abs": "https://arxiv.org/abs/2512.23540", "authors": ["Mehdi Hamzehnejad", "Abbas Salemi"], "title": "Error Estimates for Gauss--Christoffel Quadrature under Reduced Regularity Conditions", "comment": "14 pages, 3 tables", "summary": "Gauss--Christoffel quadrature is a fundamental method for numerical integration, and its convergence analysis is closely related to the decay of Chebyshev expansion coefficients. Classical estimates, including those due to Trefethen, are based on weighted bounded variation assumptions involving the singular weight $(1-x^{2})^{-1/2}$, which may be too restrictive for functions with limited regularity at the endpoints.\n  In this paper, we establish a new error bound for Gauss--Christoffel quadrature under weakened regularity assumptions. The analysis relies on a new identity for higher-order derivatives of Chebyshev polynomials. As a consequence, we obtain an improved decay estimate for Chebyshev coefficients, where the classical weighted condition \\[ V_{r}=\\int_{-1}^{1}\\frac{|f^{(r+1)}(x)|}{\\sqrt{1-x^{2}}}\\,dx \\] is replaced by the weaker condition \\[ U_{r}=\\int_{-1}^{1}|f^{(r+1)}(x)|\\,dx. \\]\n  This result leads to a corresponding error estimate for the Gauss--Christoffel quadrature rule, which is less restrictive than previous bounds. The approach is also extended to the Gauss--Gegenbauer case. Numerical experiments are provided to illustrate the theoretical results."}
{"id": "2512.23308", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.23308", "abs": "https://arxiv.org/abs/2512.23308", "authors": ["Jyotishka Datta", "Nicholas G. Polson", "Vadim Sokolov", "Daniel Zantedeschi"], "title": "Conformal Prediction = Bayes?", "comment": null, "summary": "Conformal prediction (CP) is widely presented as distribution-free predictive inference with finite-sample marginal coverage under exchangeability. We argue that CP is best understood as a rank-calibrated descendant of the Fisher-Dempster-Hill fiducial/direct-probability tradition rather than as Bayesian conditioning in disguise.\n  We establish four separations from coherent countably additive predictive semantics. First, canonical conformal constructions violate conditional extensionality: prediction sets can depend on the marginal design P(X) even when P(Y|X) is fixed. Second, any finitely additive sequential extension preserving rank calibration is nonconglomerable, implying countable Dutch-book vulnerabilities. Third, rank-calibrated updates cannot be realized as regular conditionals of any countably additive exchangeable law on Y^infty. Fourth, formalizing both paradigms as families of one-step predictive kernels, conformal and Bayesian kernels coincide only on a Baire-meagre subset of the space of predictive laws.\n  We further show that rank- and proxy-based reductions are generically Blackwell-deficient relative to full-data experiments, yielding positive Le Cam deficiency for suitable losses. Extending the analysis to prediction-powered inference (PPI) yields an analogous message: bias-corrected, proxy-rectified estimators can be valid as confidence devices while failing to define transportable belief states across stages, shifts, or adaptive selection. Together, the results sharpen a general limitation of wrappers: finite-sample calibration guarantees do not by themselves supply composable semantics for sequential updating or downstream decision-making."}
{"id": "2512.23444", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.23444", "abs": "https://arxiv.org/abs/2512.23444", "authors": ["Zina-Sabrina Duma", "Otto Lamminpää", "Jouni Susiluoto", "Heikki Haario", "Ting Zheng", "Tuomas Sihvonen", "Amy Braverman", "Philip A. Townsend", "Satu-Pia Reinikainen"], "title": "Uncertainty calibration for latent-variable regression models", "comment": null, "summary": "Uncertainty quantification is essential for scientific analysis, as it allows for the evaluation and interpretation of variability and reliability in complex systems and datasets. In their original form, multivariate statistical regression models (partial least-squares regression, PLS, principal component regression, PCR) along with their kernelized versions (kernel partial least-squares regression, K-PLS, kernel principal component regression, K-PCR), do not incorporate uncertainty quantification as part of their output. In this study, we propose a method inspired by conformal inference to estimate and calibrate the uncertainty of multivariate statistical models. The result of this method is a point prediction accompanied by prediction intervals that depend on the input data. We tested the proposed method on both traditional and kernelized versions of PLS and PCR. The method is demonstrated using synthetic data, as well as laboratory near-infrared (NIR) and airborne hyperspectral regression models for estimating functional plant traits. The model was able to successfully identify the uncertain regions in the simulated data and match the magnitude of the uncertainty. In real-case scenarios, the optimised model was not overconfident nor underconfident when estimating from test data: for example, for a 95% prediction interval, 95% of the true observations were inside the prediction interval."}
{"id": "2512.23010", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.23010", "abs": "https://arxiv.org/abs/2512.23010", "authors": ["Guanghen Liu", "Songge Yang", "Yu Zhong"], "title": "Masgent: An AI-assisted Materials Simulation Agent", "comment": "43 pages, 13 figures", "summary": "Density functional theory (DFT) and machine learning potentials (MLPs) are essential for predicting and understanding materials properties, yet preparing, executing, and analyzing these simulations typically requires extensive scripting, multi-step procedures, and significant high-performance computing (HPC) expertise. These challenges hinder reproducibility and slow down discovery. Here, we introduce Masgent, an AI-assisted materials simulation agent that unifies structure manipulation, automated VASP input generation, DFT workflow construction and analysis, fast MLP-based simulations, and lightweight machine learning (ML) utilities within a single platform. Powered by large language models (LLMs), Masgent enables researchers to perform complex simulation tasks through natural-language interaction, eliminating most manual scripting and reducing setup time from hours to seconds. By standardizing protocols and integrating advanced simulation and data-driven tools, Masgent democratizes access to state-of-the-art computational methodologies, accelerating hypothesis testing, pre-screening, and exploratory research for both new and experienced practitioners."}
{"id": "2512.22609", "categories": ["hep-lat", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.22609", "abs": "https://arxiv.org/abs/2512.22609", "authors": ["Tatsuhiro Misumi"], "title": "Minimal-doubling and single-Weyl Hamiltonians", "comment": "28 pages", "summary": "We develop a systematic Hamiltonian formulation of minimally doubled lattice fermions in (3+1) dimensions, derive their nodal structures (structures of zeros), and classify their symmetry patterns for both four-component Dirac and two-component Weyl constructions. Motivated by recent single-Weyl proposals based on Bogoliubov-de Gennes (BdG) representation, we argue that the corresponding single-Weyl Hamiltonians are obtained from the minimal-doubling Hamiltonians supplemented by an appropriate species-splitting mass term, and we re-examine the non-onsite symmetry protecting the physical Weyl node in terms of a Ginsparg-Wilson-type relation. We then construct a one-parameter family of deformations that preserves all the symmetries and demonstrate that, once the parameter exceeds a critical value, additional Weyl nodes emerge and the system exits the single-node regime. This indicates that in interacting theories radiative corrections can generate symmetry-allowed counterterms, so maintaining the desired single-Weyl phase generically requires \"moderate\" parameter tuning."}
{"id": "2512.22434", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22434", "abs": "https://arxiv.org/abs/2512.22434", "authors": ["Taihei Kuroiwa", "Daiki Yamazaki", "Keita Takahashi", "Kodai Shiba", "Chih-Chieh Chen", "Tomah Sogabe"], "title": "Quantum-Circuit Framework for Two-Stage Stochastic Programming via QAOA Integrated with a Quantum Generative Neural Network", "comment": "50 pages, 7 figures, 3 tables", "summary": "Two-stage stochastic programming often discretizes uncertainty into scenarios, but scenario enumeration makes expected recourse evaluation scale at least linearly in the scenario count. We propose qGAN-QAOA, a unified quantum-circuit workflow in which a pre-trained quantum generative adversarial network encodes the scenario distribution and QAOA optimizes first-stage decisions by minimizing the full two-stage objective, including expected recourse cost. With the qGAN parameters fixed after training, we evaluate the objective as the expectation value of a problem Hamiltonian and optimize only the QAOA variational parameters. We interpret non-anticipativity as a condition on measurement outcome statistics and prove that the first-stage measurement marginal is independent of the scenario. For uniformly discretized uncertainty, the diagonal operator encoding the uncertainty admits a sparse Pauli-Z expansion via the Walsh--Hadamard transform, yielding polylogarithmic scaling of gate count and circuit depth with the number of scenarios. Numerical experiments on the stochastic unit commitment problem (UCP) with photovoltaic (PV) uncertainty compare the expected cost of the proposed method with classical expected-value and two-stage stochastic programming baselines, demonstrating the effectiveness of qGAN-QAOA as a two-stage decision model."}
{"id": "2512.22169", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.22169", "abs": "https://arxiv.org/abs/2512.22169", "authors": ["M. Süzen"], "title": "Wigner Cat Phases: A finely tunable system for exploring the transition to quantum chaos", "comment": "10 pages, 4 figures", "summary": "The transition to chaos for quantum dynamics is quantified via a finely tunable mixed random matrix ensemble. The {\\it mixed Gaussian Orthogonal Ensemble (mGOE)} forms a pedagogically accessible family of systems in simulating {\\it Many-Body Localization (MBL)} transitions. It can be tuned from chaotic to localized and heavy-tailed localized phases in a continuous fashion, providing an opportunity to explore new phases. We numerically study how the spectral properties of mGOE evolve during these transitions. Characterization of transition to quantum chaos is computed and analyzed via empirical spectral density, nearest-neighbor spacing, and adjacent gap ratios with statistical uncertainty quantifications that strengthens the robustness of evidence of transitions. The transition is identified as {\\it Wigner Cat Phases}, because of the shape of empirical spectral densities, which depens on the tuneable parameter. These simulated phases in mGOE appear to be an ideal tool to study {\\it Eigenstate Thermalization Hypothesis (ETH)} and its related transitions, representing a family of physical systems under different localisation and disorder strengths."}
{"id": "2512.23115", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23115", "abs": "https://arxiv.org/abs/2512.23115", "authors": ["Eilon Solan", "Avraham Tabbach", "Chang Zhao"], "title": "The Design of Optimal Dependency and Rewards", "comment": null, "summary": "We analyze a two-period principal-agent model in which the principal faces a budget constraint, and the agent's private costs of performing tasks across the two periods may be correlated. We examine the optimal design of the reward scheme and the cost correlation structure. Our findings reveal that when the budget is low, the optimal reward scheme employs \\textit{sufficient performance targeting}, rewarding the agent's first performance. Conversely, when the principal's budget is high, the focus shifts to \\textit{sustained performance targeting}, compensating the agent's second performance. Introducing a negative cost correlation proves particularly beneficial in both scenarios: it increases the likelihood of the agent performing at least once under low budgets and balances the agent's total costs to facilitate consistent performance under high budgets. However, the optimal cost correlation structure can be more elaborate, especially for intermediate budget levels. Our results offer valuable insights for real-world applications, such as research funding allocation."}
{"id": "2512.22968", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22968", "abs": "https://arxiv.org/abs/2512.22968", "authors": ["Carlos Arturo Saldarriaga-Cortes", "Carlos Adrian Correa-Florez", "Maximiliano Bueno-Lopez", "Maria Victoria Gasca-Segura"], "title": "A Bezier Curve Based Approach to the Convexification of the AC Optimal Power Flow Problem", "comment": "10 pages, 7 figures", "summary": "The Alternating Current Optimal Power Flow (ACOPF) problem remains one of the most fundamental yet computationally challenging tasks in power systems operation and planning due to its nonconvex, nonlinear, and multimodal nature. This paper proposes a convex reformulation of the AC power flow problem by introducing auxiliary variables to isolate nonlinear terms, applying logarithmic transformations to exploit product-sum properties, and approximating with Bezier curves using a novel convexifying butterfly shaped function. This model is intended for assessing and operating weak power systems that face challenges with reactive power supply and overall network robustness. Its formulation closely mirrors the AC formulation, particularly regarding active and reactive power dispatch and network voltage levels.\n  The proposed model achieves convergence on large test systems (e.g., IEEE 118 bus) in seconds and is validated against exact AC solutions. This convex formulation stands out not only for its mathematical transparency and intuitive structure but also for its ease of validation and implementation, making it an accessible and reliable tool for researchers and system operators for energy planning.\n  The numerical analysis conducted on the IEEE 118 bus system yielded average percentage errors in the state variables specifically, the magnitudes and angles of nodal voltages of just 0.0008 percentage and 0.014 degree, respectively, when compared with the precise AC formulation. These results underscore the high accuracy and reliability of the proposed methodology."}
{"id": "2512.22968", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22968", "abs": "https://arxiv.org/abs/2512.22968", "authors": ["Carlos Arturo Saldarriaga-Cortes", "Carlos Adrian Correa-Florez", "Maximiliano Bueno-Lopez", "Maria Victoria Gasca-Segura"], "title": "A Bezier Curve Based Approach to the Convexification of the AC Optimal Power Flow Problem", "comment": "10 pages, 7 figures", "summary": "The Alternating Current Optimal Power Flow (ACOPF) problem remains one of the most fundamental yet computationally challenging tasks in power systems operation and planning due to its nonconvex, nonlinear, and multimodal nature. This paper proposes a convex reformulation of the AC power flow problem by introducing auxiliary variables to isolate nonlinear terms, applying logarithmic transformations to exploit product-sum properties, and approximating with Bezier curves using a novel convexifying butterfly shaped function. This model is intended for assessing and operating weak power systems that face challenges with reactive power supply and overall network robustness. Its formulation closely mirrors the AC formulation, particularly regarding active and reactive power dispatch and network voltage levels.\n  The proposed model achieves convergence on large test systems (e.g., IEEE 118 bus) in seconds and is validated against exact AC solutions. This convex formulation stands out not only for its mathematical transparency and intuitive structure but also for its ease of validation and implementation, making it an accessible and reliable tool for researchers and system operators for energy planning.\n  The numerical analysis conducted on the IEEE 118 bus system yielded average percentage errors in the state variables specifically, the magnitudes and angles of nodal voltages of just 0.0008 percentage and 0.014 degree, respectively, when compared with the precise AC formulation. These results underscore the high accuracy and reliability of the proposed methodology."}
{"id": "2512.23580", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23580", "abs": "https://arxiv.org/abs/2512.23580", "authors": ["Zhirui Tang", "Julian Koellermeier", "Emil Løvbak", "Giovanni Samaey"], "title": "Analysis of kinetic-diffusion Monte Carlo simulation and source term estimation scheme in nuclear fusion applications", "comment": "Section 5.6 of this article builds upon the numerical results presented in arXiv:2509.11883 and these articles contain some textual overlap", "summary": "In plasma edge simulations, the behavior of neutral particles is often described by a Boltzmann--BGK equation. Solving this kinetic equation and estimating the moments of its solution are essential tasks, typically carried out using Monte Carlo (MC) methods. However, for large-sized reactors, like ITER and DEMO, high collision rates lead to a substantial computational cost. To accelerate the calculation, an asymptotic-preserving kinetic-diffusion Monte Carlo (KDMC) simulation method (Mortier et al., SIAM J. Sci. Comput., 2022) and a corresponding fluid estimation technique (Mortier et al., Contrib. Plasma Phys., 2022) have recently been proposed. In this work, we present a comprehensive analysis of the convergence of KDMC combined with the associated fluid estimation. The analysis consists of proving theoretical upper bounds for both KDMC and the fluid estimation, and numerical verifications of these bounds. In addition, we compare the analyzed algorithm with a purely fluid-based method using the fully kinetic MC method as a reference. The algorithm consistently achieves lower error than the fluid-based method, and even one order of magnitude lower in a fusion-relevant test case. Moreover, the algorithm exhibits a significant speedup compared to the reference kinetic MC method. Overall, our analysis confirms the effectiveness of KDMC with the associated fluid estimation in nuclear fusion applications."}
{"id": "2512.23425", "categories": ["math.ST", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23425", "abs": "https://arxiv.org/abs/2512.23425", "authors": ["William Kengne", "Modou Wade"], "title": "A general framework for deep learning", "comment": null, "summary": "This paper develops a general approach for deep learning for a setting that includes nonparametric regression and classification. We perform a framework from data that fulfills a generalized Bernstein-type inequality, including independent, $φ$-mixing, strongly mixing and $\\mathcal{C}$-mixing observations. Two estimators are proposed: a non-penalized deep neural network estimator (NPDNN) and a sparse-penalized deep neural network estimator (SPDNN). For each of these estimators, bounds of the expected excess risk on the class of Hölder smooth functions and composition Hölder functions are established. Applications to independent data, as well as to $φ$-mixing, strongly mixing, $\\mathcal{C}$-mixing processes are considered. For each of these examples, the upper bounds of the expected excess risk of the proposed NPDNN and SPDNN predictors are derived. It is shown that both the NPDNN and SPDNN estimators are minimax optimal (up to a logarithmic factor) in many classical settings."}
{"id": "2512.23467", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.23467", "abs": "https://arxiv.org/abs/2512.23467", "authors": ["Hajime Ogawa", "Shonosuke Sugasawa"], "title": "Propensity Patchwork Kriging for Scalable Inference on Heterogeneous Treatment Effects", "comment": "24 pages (main) + 11 pages (supplement)", "summary": "Gaussian process-based models are attractive for estimating heterogeneous treatment effects (HTE), but their computational cost limits scalability in causal inference settings. In this work, we address this challenge by extending Patchwork Kriging into the causal inference framework. Our proposed method partitions the data according to the estimated propensity score and applies Patchwork Kriging to enforce continuity of HTE estimates across adjacent regions. By imposing continuity constraints only along the propensity score dimension, rather than the full covariate space, the proposed approach substantially reduces computational cost while avoiding discontinuities inherent in simple local approximations. The resulting method can be interpreted as a smoothing extension of stratification and provides an efficient approach to HTE estimation. The proposed method is demonstrated through simulation studies and a real data application."}
{"id": "2512.23057", "categories": ["physics.comp-ph", "astro-ph.HE", "gr-qc"], "pdf": "https://arxiv.org/pdf/2512.23057", "abs": "https://arxiv.org/abs/2512.23057", "authors": ["Corwin Cheung", "Marcos Johnson-Noya", "Michael Xiang", "Dominic Chang", "Alfredo Guevara"], "title": "Reconstructing Relativistic Magnetohydrodynamics with Physics-Informed Neural Networks", "comment": "7 pages with figures. Code available on github.com/aguevara22/RMHD-NN", "summary": "We construct the first physics-informed neural-network (PINN) surrogates for relativistic magnetohydrodynamics (RMHD) using a hybrid PDE and data-driven workflow. Instead of training for the conservative form of the equations, we work with Jacobians or PDE characteristics directly in terms of primitive variables. We further add to the trainable system the divergence-free condition, without the need of cleaning modes. Using a novel MUON optimizer implementation, we show that a baseline PINN trained on early-time snapshots can extrapolate RMHD dynamics in one and two spatial dimensions, and that posterior residual-guided networks can systematically reduce PDE violations."}
{"id": "2512.22510", "categories": ["quant-ph", "math-ph", "nlin.SI"], "pdf": "https://arxiv.org/pdf/2512.22510", "abs": "https://arxiv.org/abs/2512.22510", "authors": ["Aritra Ghosh", "Bijan Bagchi", "A. Ghose-Choudhury", "Partha Guha", "Miloslav Znojil"], "title": "Quasi-harmonic spectra from branched Hamiltonians", "comment": null, "summary": "We revisit the canonical quantization to assess the spectrum of the modified Emden equation $\\ddot{x} + kx\\dot{x} + ω^2 x + \\frac{k^2}{9}x^3 = 0$, which is an isochronous case of the Liénard-Kukles equation. While its classical isochronicity and canonical quantization, leading to polynomial solutions with an exactly-equispaced spectrum have been discussed earlier, including in the recent paper [Int. J. Theor. Phys. 64, 212 (2025)], the present study focuses on the quantization of its branched Hamiltonians. For small $k$, we show numerically that the resulting energy spectrum is no longer perfectly harmonic but only approximately equispaced, exhibiting quasi-harmonic behavior characterized by deviations from uniform spacing. Our numerical results are precisely validated by analytical calculations based on perturbation theory."}
{"id": "2512.22643", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-ex"], "pdf": "https://arxiv.org/pdf/2512.22643", "abs": "https://arxiv.org/abs/2512.22643", "authors": ["Haruki Emori", "Hiroyasu Tajima"], "title": "Measuring out-of-time-order correlators on a quantum computer based on an irreversibility-susceptibility method", "comment": "13 pages and 6 figures", "summary": "The out-of-time-ordered correlator (OTOC) is a powerful tool for probing quantum information scrambling, a fundamental process by which local information spreads irreversibly throughout a quantum many-body system. Experimentally measuring the OTOC, however, is notoriously challenging due to the need for time-reversed evolution. Here, we present an experimental evaluation of the OTOC on a quantum computer, using three distinct protocols to address this challenge: the rewinding time method (RTM), the weak-measurement method (WMM), and the irreversibility-susceptibility method (ISM). Our experiments investigate the quantum dynamics of an XXZ spin-1/2 chain prepared in a thermal Gibbs state. As a key contribution, we provide the first experimental demonstration of the ISM, using the numerical emulator of the trapped-ion quantum computer, reimei. We also conduct a detailed comparative analysis of all three methods, revealing method-dependent behaviors in the measured OTOC. This work not only validates these protocols as practical tools for exploring quantum chaos on near-term hardware but also offers crucial insights into their respective advantages and limitations, providing a practical framework for future experimental investigations."}
{"id": "2512.23134", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23134", "abs": "https://arxiv.org/abs/2512.23134", "authors": ["Lang Yu", "Nanjing Huang"], "title": "Difference-of-Convex Elastic Net for Compressed Sensing", "comment": null, "summary": "This work proposes a novel and unified sparse recovery framework, termed the difference of convex Elastic Net (DCEN). This framework effectively balances strong sparsity promotion with solution stability, and is particularly suitable for high-dimensional variable selection involving highly correlated features. Built upon a difference-of-convex (DC) structure, DCEN employs two continuously tunable parameters to unify classical and state-of-the-art models--including Lasso, Elastic Net, Ridge, and $\\ell_1-α\\ell_2$--as special cases. Theoretically, sufficient conditions for exact and stable recovery are established under the restricted isometry property (RIP), and a closed-form expression of the DCEN regularization proximal operator is derived. Moreover, two efficient optimization algorithms are developed based on the DC algorithm (DCA) and the alternating direction method of multipliers (ADMM). Within the Kurdyka-Lojasiewicz (KL) framework, the global convergence of DCA and its linear convergence rate are rigorously established. Furthermore, DCEN is extended to image reconstruction by incorporating total variation (TV) regularization, yielding the DCEN-TV model, which is efficiently solved via the Split Bregman method. Numerical experiments demonstrate that DCEN consistently outperforms state-of-the-art methods in sparse signal recovery, high-dimensional variable selection under strong collinearity, and Magnetic Resonance Imaging (MRI) image reconstruction, achieving superior recovery accuracy and robustness."}
{"id": "2512.23081", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23081", "abs": "https://arxiv.org/abs/2512.23081", "authors": ["Taha Saeed Khan"], "title": "Global Frequency Reference Tracking as an Oscillation Suppression Mechanism in VSM Primary Control: A Coupled-Oscillator Study", "comment": null, "summary": "Synchronization in power systems is traditionally achieved through physical network coupling, whereby inverter-based resources (IBRs) and synchronous machines converge to a common frequency via oscillatory swing dynamics. In conventional operation, secondary control acts on a slow time scale and is typically engaged only after the primary dynamics have largely settled. As a result, in the absence of an explicit global reference, disturbances can induce prolonged transients and large phase excursions. This work considers a setting in which the total active power balance is known and maintained at all times, and proposes a control architecture for virtual synchronous machine (VSM) based inverters in which all units track a broadcast global frequency reference. Under this assumption, synchronization is transformed from a mutual oscillator locking problem into a reference tracking problem. Using a second order swing network model, we show that embedding a simple proportional integral (PI) frequency controller can significantly improves transient behavior. A washout mechanism ensures that the additional control action vanishes in steady state, thereby preserving network determined power sharing. Simulations on a three oscillator network demonstrate reduced frequency overshoot, elimination of underdamped oscillations, and lower angular stress compared to conventional open loop synchronization, highlighting the effectiveness of a global frequency reference as a coordination mechanism for grid-forming inverter networks."}
{"id": "2512.23081", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23081", "abs": "https://arxiv.org/abs/2512.23081", "authors": ["Taha Saeed Khan"], "title": "Global Frequency Reference Tracking as an Oscillation Suppression Mechanism in VSM Primary Control: A Coupled-Oscillator Study", "comment": null, "summary": "Synchronization in power systems is traditionally achieved through physical network coupling, whereby inverter-based resources (IBRs) and synchronous machines converge to a common frequency via oscillatory swing dynamics. In conventional operation, secondary control acts on a slow time scale and is typically engaged only after the primary dynamics have largely settled. As a result, in the absence of an explicit global reference, disturbances can induce prolonged transients and large phase excursions. This work considers a setting in which the total active power balance is known and maintained at all times, and proposes a control architecture for virtual synchronous machine (VSM) based inverters in which all units track a broadcast global frequency reference. Under this assumption, synchronization is transformed from a mutual oscillator locking problem into a reference tracking problem. Using a second order swing network model, we show that embedding a simple proportional integral (PI) frequency controller can significantly improves transient behavior. A washout mechanism ensures that the additional control action vanishes in steady state, thereby preserving network determined power sharing. Simulations on a three oscillator network demonstrate reduced frequency overshoot, elimination of underdamped oscillations, and lower angular stress compared to conventional open loop synchronization, highlighting the effectiveness of a global frequency reference as a coordination mechanism for grid-forming inverter networks."}
{"id": "2512.23621", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23621", "abs": "https://arxiv.org/abs/2512.23621", "authors": ["Luxuan Yang", "Fei Lu", "Ting Gao", "Wei Wei", "Jinqiao Duan"], "title": "Learning Lévy density via adaptive RKHS regression with bi-level optimization", "comment": null, "summary": "We propose a nonparametric method to learn the Lévy density from probability density data governed by a nonlocal Fokker-Planck equation. We recast the problem as identifying the kernel in a nonlocal integral operator from discrete data, which leads to an ill-posed inverse problem. To regularize it, we construct an adaptive reproducing kernel Hilbert space (RKHS) whose kernel is built directly from the data. Under standard source and spectral decay conditions, we show that the reconstruction error decays in the mesh size at a near optimal rate. Importantly, we develop a generalized singular value decomposition (GSVD)-based bilevel optimization algorithm to choose the regularization parameter, leading to efficient and robust computation of the regularized estimator. Numerical experiments for several Lévy densities, drift fields and data types (PDE-based densities and sample ensemble-based KDE reconstructions) demonstrate that our bilevel RKHS method outperforms classical L-curve and generalized cross-validation strategies and that the adaptive RKHS norm is more accurate and robust than $L^2_ρ$- and $\\ell^2$-based regularization."}
{"id": "2512.23395", "categories": ["stat.ME", "math.PR", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.23395", "abs": "https://arxiv.org/abs/2512.23395", "authors": ["David Bolin", "Peter Braunsteins", "Sebastian Engelke", "Raphaël Huser"], "title": "Intrinsic Whittle--Matérn fields and sparse spatial extremes", "comment": null, "summary": "Intrinsic Gaussian fields are used in many areas of statistics as models for spatial or spatio-temporal dependence, or as priors for latent variables. However, there are two major gaps in the literature: first, the number and flexibility of existing intrinsic models are very limited; second, theory, fast inference, and software are currently underdeveloped for intrinsic fields. We tackle these challenges by introducing the new flexible class of intrinsic Whittle--Matérn Gaussian random fields obtained as the solution to a stochastic partial differential equation (SPDE). Exploiting sparsity resulting from finite-element approximations, we develop fast estimation and simulation methods for these models. We demonstrate the benefits of this intrinsic SPDE approach for the important task of kriging under extrapolation settings. Leveraging the connection of intrinsic fields to spatial extreme value processes, we translate our theory to an SPDE approach for Brown--Resnick processes for sparse modeling of spatial extreme events. This new paradigm paves the way for efficient inference in unprecedented dimensions. To demonstrate the wide applicability of our new methodology, we apply it in two very different areas: a longitudinal study of renal function data, and the modeling of marine heat waves using high-resolution sea surface temperature data."}
{"id": "2512.23474", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23474", "abs": "https://arxiv.org/abs/2512.23474", "authors": ["Junyu Chen", "Pratik Nag", "Huixia Judy-Wang", "Ying Sun"], "title": "Deep classifier kriging for probabilistic spatial prediction of air quality index", "comment": null, "summary": "Accurate spatial interpolation of the air quality index (AQI), computed from concentrations of multiple air pollutants, is essential for regulatory decision-making, yet AQI fields are inherently non-Gaussian and often exhibit complex nonlinear spatial structure. Classical spatial prediction methods such as kriging are linear and rely on Gaussian assumptions, which limits their ability to capture these features and to provide reliable predictive distributions. In this study, we propose \\textit{deep classifier kriging} (DCK), a flexible, distribution-free deep learning framework for estimating full predictive distribution functions for univariate and bivariate spatial processes, together with a \\textit{data fusion} mechanism that enables modeling of non-collocated bivariate processes and integration of heterogeneous air pollution data sources. Through extensive simulation experiments, we show that DCK consistently outperforms conventional approaches in predictive accuracy and uncertainty quantification. We further apply DCK to probabilistic spatial prediction of AQI by fusing sparse but high-quality station observations with spatially continuous yet biased auxiliary model outputs, yielding spatially resolved predictive distributions that support downstream tasks such as exceedance and extreme-event probability estimation for regulatory risk assessment and policy formulation."}
{"id": "2512.23061", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.23061", "abs": "https://arxiv.org/abs/2512.23061", "authors": ["Itay Hen"], "title": "Exponential divided differences via Chebyshev polynomials", "comment": "21 pages, 5 figures", "summary": "Exponential divided differences arise in numerical linear algebra, matrix-function evaluation, and quantum Monte Carlo simulations, where they serve as kernel weights for time evolution and observable estimation. Efficient and numerically stable evaluation of high-order exponential divided differences for dynamically evolving node sets remains a significant computational challenge. We present a Chebyshev-polynomial-based algorithm that addresses this problem by combining the Chebyshev-Bessel expansion of the exponential function with a direct recurrence for Chebyshev divided differences. The method achieves a computational cost of ${\\cal O}(qN)$, where $q$ is the divided-difference order and $N$ is the Chebyshev truncation length. We show that $N$ scales linearly with the spectral width through the decay of modified Bessel coefficients, while the dependence on $q$ enters only through structural polynomial constraints. We further develop an incremental update scheme for dynamic node sets that enables the insertion or removal of a single node in ${\\cal O}(N)$ time when the affine mapping interval is held fixed. A full \\texttt{C++} reference implementation of the algorithms described in this work is publicly available."}
{"id": "2512.22514", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22514", "abs": "https://arxiv.org/abs/2512.22514", "authors": ["Yu Lu", "Hao-Fan Wang", "Meng Su", "Zhi-Xi Wang", "Shao-Ming Fei"], "title": "Enhanced separability criteria based on symmetric measurements", "comment": "13 pages, 4 figures", "summary": "We present separability criteria based on local symmetric measurements. These experimental plausible criteria are shown to be more efficient in detecting entanglement than the current counterparts by detailed examples. Furthermore, we generalize the separability criteria from bipartite to arbitrary multipartite systems. These criteria establish a richer connection between the quantum entanglement and the probabilities of local measurement outcomes."}
{"id": "2512.22839", "categories": ["nlin.AO", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.22839", "abs": "https://arxiv.org/abs/2512.22839", "authors": ["Shreeman Auromahima", "Sitangshu Bikas Santra", "Biplab Bose"], "title": "Switching Transition in a Resource Exchange Model on Graphs", "comment": null, "summary": "In this work, we investigate a simple nonequilibrium system with many interconnected, open subsystems, each exchanging a globally conserved resource with an external reserve. The system is represented by a random graph, where nodes represent the subsystems connected through edges. At each time step, a randomly selected node gains a token (i.e, a resource) from the reserve with probability (1-p) or loses a token to the reserve with probability p. When a node loses a token, its neighbors also lose a token each. This asymmetric token exchange breaks the detailed balance. We investigate the steady state behavior of our model for different types of random graphs: graphs without edges, regular graphs, Erdős-Rényi, and Barabási-Albert graphs. In all cases, the system exhibits a sharp, switch-like transition between a token-saturated state and an empty state. When the control parameter p is below a critical threshold, almost all tokens accumulate on the graph. Furthermore, in a non-regular graph, most tokens accumulate or condense on nodes of minimum degree. A slight increase in p beyond the threshold drains almost all the tokens from the graph. This switching transition results from the interplay between drift and the conservation of tokens. However, the position of the critical threshold and the behavior at the transition zone depend on graph topology."}
{"id": "2512.23150", "categories": ["math.OC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23150", "abs": "https://arxiv.org/abs/2512.23150", "authors": ["Vítor A. Barbosa", "Rafael A. Melo"], "title": "Constraint programming model and biased random-key genetic algorithm for the single-machine coupled task scheduling problem with exact delays to minimize the makespan", "comment": null, "summary": "We consider the strongly NP-hard single-machine coupled task scheduling problem with exact delays to minimize the makespan. In this problem, a set of jobs has to be scheduled, each composed of two tasks interspersed by an exact delay. Given that no preemption is allowed, the goal consists of minimizing the completion time of the last scheduled task. We model the problem using constraint programming (CP) and propose a biased random-key genetic algorithm (BRKGA). Our CP model applies well-established global constraints. Our BRKGA combines some successful components in the literature: an initial solution generator, periodical restarts and shakes, and a local search algorithm. Furthermore, the BRKGA's decoder is focused on efficiency rather than optimality, which accelerates the solution space exploration. Computational experiments on a benchmark set containing instances with up to 100 jobs (200 tasks) indicate that the proposed BRKGA can efficiently explore the problem solution space, providing high-quality approximate solutions within low computational times. It can also provide better solutions than the CP model under the same computational settings, i.e., three minutes of time limit and a single thread. The CP model, when offered a longer running time of 3600 seconds and multiple threads, significantly improved the results, reaching the current best-known solution for 90.56% of these instances. Finally, our experiments highlight the importance of the shake and local search components in the BRKGA, whose combination significantly improves the results of a standard BRKGA."}
{"id": "2512.23085", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23085", "abs": "https://arxiv.org/abs/2512.23085", "authors": ["Ran Hao", "Yuttana Itsarachaiyot", "Yen-Chun Chen", "M. Cenk Çavuşoğlu"], "title": "Real-Time Forward Kinematics and Jacobians for Control of an MRI-Guided Magnetically Actuated Robotic Catheter", "comment": null, "summary": "This paper presents a forward kinematics and analytical Jacobian computation approach for real-time control of a novel magnetic resonance imaging (MRI)-actuated robotic catheter. The MRI-actuated robotic catheter is modeled as a series of rigid and flexible segments and actuated by magnetic torques generated on a set of current-carrying microcoils embedded on the catheter body by the magnetic field of the MRI scanner. First, a real-time forward kinematic modeling approach of the robotic catheter employing the static Cosserat-rod theory is presented. Second, the analytical calculation approach of the forward kinematic Jacobians of the proposed forward kinematic model is presented. The accuracy, reproducibility, and computational efficiency of the proposed methods are evaluated using a robotic catheter prototype with a single coil set, where catheter tip trajectories collected by a catadioptric stereo camera tracking system are validated using the desired tip trajectories. Experimental results demonstrate that the proposed method can successfully control the catheter in an open loop to perform complex trajectories with real-time computational efficiency, paving the way for accurate closed-loop control with real-time MR-imaging feedback."}
{"id": "2512.23085", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23085", "abs": "https://arxiv.org/abs/2512.23085", "authors": ["Ran Hao", "Yuttana Itsarachaiyot", "Yen-Chun Chen", "M. Cenk Çavuşoğlu"], "title": "Real-Time Forward Kinematics and Jacobians for Control of an MRI-Guided Magnetically Actuated Robotic Catheter", "comment": null, "summary": "This paper presents a forward kinematics and analytical Jacobian computation approach for real-time control of a novel magnetic resonance imaging (MRI)-actuated robotic catheter. The MRI-actuated robotic catheter is modeled as a series of rigid and flexible segments and actuated by magnetic torques generated on a set of current-carrying microcoils embedded on the catheter body by the magnetic field of the MRI scanner. First, a real-time forward kinematic modeling approach of the robotic catheter employing the static Cosserat-rod theory is presented. Second, the analytical calculation approach of the forward kinematic Jacobians of the proposed forward kinematic model is presented. The accuracy, reproducibility, and computational efficiency of the proposed methods are evaluated using a robotic catheter prototype with a single coil set, where catheter tip trajectories collected by a catadioptric stereo camera tracking system are validated using the desired tip trajectories. Experimental results demonstrate that the proposed method can successfully control the catheter in an open loop to perform complex trajectories with real-time computational efficiency, paving the way for accurate closed-loop control with real-time MR-imaging feedback."}
{"id": "2512.23643", "categories": ["math.NA", "cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23643", "abs": "https://arxiv.org/abs/2512.23643", "authors": ["Konstantin Yakovlev", "Nikita Puchkin"], "title": "Simultaneous Approximation of the Score Function and Its Derivatives by Deep Neural Networks", "comment": "38 pages", "summary": "We present a theory for simultaneous approximation of the score function and its derivatives, enabling the handling of data distributions with low-dimensional structure and unbounded support. Our approximation error bounds match those in the literature while relying on assumptions that relax the usual bounded support requirement. Crucially, our bounds are free from the curse of dimensionality. Moreover, we establish approximation guarantees for derivatives of any prescribed order, extending beyond the commonly considered first-order setting."}
{"id": "2512.23643", "categories": ["math.NA", "cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23643", "abs": "https://arxiv.org/abs/2512.23643", "authors": ["Konstantin Yakovlev", "Nikita Puchkin"], "title": "Simultaneous Approximation of the Score Function and Its Derivatives by Deep Neural Networks", "comment": "38 pages", "summary": "We present a theory for simultaneous approximation of the score function and its derivatives, enabling the handling of data distributions with low-dimensional structure and unbounded support. Our approximation error bounds match those in the literature while relying on assumptions that relax the usual bounded support requirement. Crucially, our bounds are free from the curse of dimensionality. Moreover, we establish approximation guarantees for derivatives of any prescribed order, extending beyond the commonly considered first-order setting."}
{"id": "2512.23567", "categories": ["stat.ME", "econ.EM"], "pdf": "https://arxiv.org/pdf/2512.23567", "abs": "https://arxiv.org/abs/2512.23567", "authors": ["Liyuan Cui", "Guanhao Feng", "Yuefeng Han", "Jiayan Li"], "title": "Panel Coupled Matrix-Tensor Clustering Model with Applications to Asset Pricing", "comment": null, "summary": "We tackle the challenge of estimating grouping structures and factor loadings in asset pricing models, where traditional regressions struggle due to sparse data and high noise. Existing approaches, such as those using fused penalties and multi-task learning, often enforce coefficient homogeneity across cross-sectional units, reducing flexibility. Clustering methods (e.g., spectral clustering, Lloyd's algorithm) achieve consistent recovery under specific conditions but typically rely on a single data source. To address these limitations, we introduce the Panel Coupled Matrix-Tensor Clustering (PMTC) model, which simultaneously leverages a characteristics tensor and a return matrix to identify latent asset groups. By integrating these data sources, we develop computationally efficient tensor clustering algorithms that enhance both clustering accuracy and factor loading estimation. Simulations demonstrate that our methods outperform single-source alternatives in clustering accuracy and coefficient estimation, particularly under moderate signal-to-noise conditions. Empirical application to U.S. equities demonstrates the practical value of PMTC, yielding higher out-of-sample total $R^2$ and economically interpretable variation in factor exposures."}
{"id": "2512.23358", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.23358", "abs": "https://arxiv.org/abs/2512.23358", "authors": ["Louis Libat", "Can Selçuk", "Eric Chénier", "Vincent Le Chenadec"], "title": "A space-time extension of a conservative two-fluid cut-cell diffusion method for moving geometries", "comment": "25 pages, 11 figures", "summary": "We present a space-time extension of a conservative Cartesian cut-cell finite-volume method for two-phase diffusion in prescribed-motion geometries. The formulation follows a two-fluid approach: one scalar field is solved in each phase with discontinuous material properties, coupled by sharp interface conditions enforcing flux continuity and jump laws. To handle moving boundaries on a fixed Cartesian grid, the discrete balance is written over phase-restricted space-time control volumes, whose geometric moments (swept volumes and apertures) are used as weights in the finite-volume operators. This construction naturally accounts for the creation and destruction of cut cells (fresh/dead-cell events) and yields strict discrete conservation. The resulting scheme retains the algebraic structure of the static cut-cell formulation while incorporating motion through local geometric weights and interface coupling operators. A series of verification and validation tests in two and three dimensions demonstrate super-linear accuracy in space, robust behavior under repeated topology changes and conservation across strong coefficient jumps and moving interfaces. The proposed space-time cut-cell framework provides a conservative building block for multiphase transport in evolving geometries and a foundation for future free-boundary extensions such as Stefan-type phase change."}
{"id": "2512.22521", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.22521", "abs": "https://arxiv.org/abs/2512.22521", "authors": ["Jinpeng Liu", "Yuanhong Teng", "Yu Chen", "Yixuan Wang", "Chihang Luo", "Jun Yin", "Hao Li", "Lixing You", "Ya Wang", "Qi Zhang", "Fazhan Shi"], "title": "Quantum Noise Spectroscopy of Nanoscale Charge Defects in Silicon Carbide at Room Temperature", "comment": "8 pages, 4 figures", "summary": "The nanoscale charge environment critically influences semiconductor physics and device performance. While conventional bulk characterization techniques provide volume-averaged defect properties, they lack the spatial resolution to resolve nanoscale charge heterogeneity and identify microscopic noise sources. Here, we utilize single PL5 centers in 4H-SiC as room-temperature broadband quantum sensors to fill in the gap. We report the first real-time, nanoscale observation of singlecharge tunneling dynamics in a commercial semiconductor at room temperature, by monitoring the random telegraph noise using optically detected magnetic resonance (ODMR). This capability enables an electrical noise imaging technique, showing distinct noise variations across different wafer substrates. By employing dynamical decoupling, we extend noise spectroscopy from near-DC to MHz frequencies, uncovering significant noise spectral density correlations across frequency bands. Finally, we probe MHz-GHz noise and identify its origin via T1 relaxation spectroscopy, obtaining the first nanoscale electron paramagnetic resonance (EPR) spectroscopic fingerprint of charge defects in SiC. These techniques open avenues for characterizing noise environments in semiconductor devices, providing critical insights for optimizing SiC fabrication processes, defect control, and advancing quantum technologies."}
{"id": "2512.22888", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.22888", "abs": "https://arxiv.org/abs/2512.22888", "authors": ["Giovanni Canossa", "Lode Pollet", "Miguel A. Martin-Delgado", "Hao Song", "Ke Liu"], "title": "Optimal Threshold for Fracton Codes and Nearly Saturated Code Capacity in Three Dimensions", "comment": "12 pages, 5 figures, 2 tables", "summary": "Fracton codes have been intensively studied as novel topological states of matter, yet their fault-tolerant properties remain largely unexplored. Here, we investigate the optimal thresholds of self-dual fracton codes, in particular the checkerboard code, against stochastic Pauli noise. By utilizing a statistical-mechanical mapping combined with large-scale parallel tempering Monte Carlo simulations, we calculate the optimal code capacity of the checkerboard code to be $p_{th} \\simeq 0.108(2)$. This value is the highest among known three-dimensional codes and nearly saturates the theoretical limit for topological codes. Our results further validate the generalized entropy relation for two mutually dual models, $H(p_{th}) + H(\\tilde{p}_{th}) \\approx 1$, and extend its applicability beyond standard topological codes. This verification indicates the Haah's code also possesses a code capacity near the theoretical limit $p_{th} \\approx 0.11$. These findings highlight fracton codes as highly resilient quantum memory and demonstrate the utility of duality techniques in analyzing intricate quantum error-correcting codes."}
{"id": "2512.23166", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23166", "abs": "https://arxiv.org/abs/2512.23166", "authors": ["Frank E. Curtis", "Xiaoyi Qu", "Daniel P. Robinson"], "title": "A Proximal-Gradient Method for Solving Regularized Optimization Problems with General Constraints", "comment": "1 figure", "summary": "We propose, analyze, and test a proximal-gradient method for solving regularized optimization problems with general constraints. The method employs a decomposition strategy to compute trial steps and uses a merit function to determine step acceptance or rejection. Under various assumptions, we establish a worst-case iteration complexity result, prove that limit points are first-order KKT points, and show that manifold identification and active-set identification properties hold. Preliminary numerical experiments on a subset of the CUTEst test problems and sparse canonical correlation analysis problems demonstrate the promising performance of our approach."}
{"id": "2512.23158", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.23158", "abs": "https://arxiv.org/abs/2512.23158", "authors": ["Kooktae Lee", "Julian Martinez"], "title": "Breaking Symmetry-Induced Degeneracy in Multi-Agent Ergodic Coverage via Stochastic Spectral Control", "comment": null, "summary": "Multi-agent ergodic coverage via Spectral Multiscale Coverage (SMC) provides a principled framework for driving a team of agents so that their collective time-averaged trajectories match a prescribed spatial distribution. While classical SMC has demonstrated empirical success, it can suffer from gradient cancellation, particularly when agents are initialized near symmetry points of the target distribution, leading to undesirable behaviors such as stalling or motion constrained along symmetry axes. In this work, we rigorously characterize the initial conditions and symmetry-induced invariant manifolds that give rise to such directional degeneracy in first-order agent dynamics. To address this, we introduce a stochastic perturbation combined with a contraction term and prove that the resulting dynamics ensure almost-sure escape from zero-gradient manifolds while maintaining mean-square boundedness of agent trajectories. Simulations on symmetric multi-modal reference distributions demonstrate that the proposed stochastic SMC effectively mitigates transient stalling and axis-constrained motion, while ensuring that all agent trajectories remain bounded within the domain."}
{"id": "2512.23158", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.23158", "abs": "https://arxiv.org/abs/2512.23158", "authors": ["Kooktae Lee", "Julian Martinez"], "title": "Breaking Symmetry-Induced Degeneracy in Multi-Agent Ergodic Coverage via Stochastic Spectral Control", "comment": null, "summary": "Multi-agent ergodic coverage via Spectral Multiscale Coverage (SMC) provides a principled framework for driving a team of agents so that their collective time-averaged trajectories match a prescribed spatial distribution. While classical SMC has demonstrated empirical success, it can suffer from gradient cancellation, particularly when agents are initialized near symmetry points of the target distribution, leading to undesirable behaviors such as stalling or motion constrained along symmetry axes. In this work, we rigorously characterize the initial conditions and symmetry-induced invariant manifolds that give rise to such directional degeneracy in first-order agent dynamics. To address this, we introduce a stochastic perturbation combined with a contraction term and prove that the resulting dynamics ensure almost-sure escape from zero-gradient manifolds while maintaining mean-square boundedness of agent trajectories. Simulations on symmetric multi-modal reference distributions demonstrate that the proposed stochastic SMC effectively mitigates transient stalling and axis-constrained motion, while ensuring that all agent trajectories remain bounded within the domain."}
{"id": "2512.23648", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23648", "abs": "https://arxiv.org/abs/2512.23648", "authors": ["Simone Minniti", "Jens Visbech", "Claes Eskilsson", "Nicola Parolini", "Allan Peter Engsig-Karup"], "title": "A High-Order Spectral Element Solver for Steady-State Free Surface Flows", "comment": "23 pages, 17 figures", "summary": "We present a spectral element solver for the steady incompressible Navier-Stokes equations subject to a free surface. Utilizing the kinematic behaviour of the free surface boundary, an iterative pseudo-time procedure is proposed to determine the a priori unknown free surface profile. The numerical model is implemented in the open-source finite element framework Firedrake, which enables the use of a high-order polynomial basis on unstructured meshes through weak formulations. Additionally, the curvature of the free surface and submerged bodies is incorporated through curvilinear elements obtained via transfinite linear blending, which conserves the high-order convergent properties of the overall scheme. The model is applied to several benchmark cases in two spatial dimensions. Initially, it addresses fixed-domain problems, including the lid-driven cavity flow and flows around bodies such as a cylinder and a NACA airfoil. Subsequently, with the presence of a free surface, it is extended to determine the flow around a bathymetry bump and a submerged NACA airfoil. The results confirm the high-order accuracy of the model through convergence studies and demonstrate a substantial speed-up over low-order numerical schemes."}
{"id": "2512.23571", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.23571", "abs": "https://arxiv.org/abs/2512.23571", "authors": ["Fendler Julie", "Guihenneuc Chantal", "Ancelet Sophie"], "title": "Considering parallel tempering and comparing post-treatment procedures in Bayesian Profile Regression Models for a survival outcome and correlated exposures", "comment": null, "summary": "Bayesian profile regression mixture models (BPRM) allow to assess a health risk in a multi-exposed population. These mixture models cluster individuals according to their exposure profile and their health risk. However, their results, based on Monte-Carlo Markov Chain (MCMC) algorithms, turned out to be unstable in different application cases. We suppose two reasons for this instability. The MCMC algorithm can be trapped in local modes of the posterior distribution and the choice of post-treatment procedures used on the output of the MCMC algorithm leads to different clustering structures. In this work, we propose improvements of the MCMC algorithms proposed in previous works in order to avoid the local modes of the posterior distribution while reducing the computation time. We also carry out a simulation study to compare the performances of the MCMC algorithms and different post-processing in order to provide guidelines on their use. An application in radiation epidemiology is considered."}
{"id": "2512.23396", "categories": ["physics.comp-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23396", "abs": "https://arxiv.org/abs/2512.23396", "authors": ["Nilufer K. Bulut"], "title": "PINNs for Electromagnetic Wave Propagation", "comment": null, "summary": "Physics-Informed Neural Networks (PINNs) are a methodology that aims to solve physical systems by directly embedding PDE constraints into the neural network training process. In electromagnetism, where well-established methodologies such as FDTD and FEM already exist, new methodologies are expected to provide clear advantages to be accepted. Despite their mesh-free nature and applicability to inverse problems, PINNs can exhibit deficiencies in terms of accuracy and energy metrics when compared to FDTD solutions. This study demonstrates hybrid training strategies can bring PINNs closer to FDTD-level accuracy and energy consistency.\n  This study presents a hybrid methodology addressing common challenges in wave propagation scenarios. The causality collapse problem in time-dependent PINN training is addressed via time marching and causality-aware weighting. In order to mitigate the discontinuities that are introduced by time marching, a two-stage interface continuity loss is applied. In order to suppress loss accumulation, which is manifested as cumulative energy drift in electromagnetic waves, a local Poynting-based regularizer has been developed.\n  In the developed PINN model, high field accuracy is achieved with an average 0.09\\% $NRMSE$ and 1.01\\% $L^2$ error over time. Energy conservation is achieved on the PINN side with only a 0.024\\% relative energy mismatch in the 2D PEC cavity scenario. Training is performed without labeled field data, using only physics-based residual losses; FDTD is used solely for post-training evaluation. The results demonstrate that PINNs can achieve competitive results with FDTD in canonical electromagnetic examples and are a viable alternative."}
{"id": "2512.22532", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.22532", "abs": "https://arxiv.org/abs/2512.22532", "authors": ["Shalender Singh", "Santosh Kumar"], "title": "Operational entanglement of collective quantum modes at room temperature", "comment": "19 pages, 4 figures", "summary": "Quantum entanglement is commonly assumed to be fragile at ambient temperature and over macroscopic distances, where thermal noise and dissipation are expected to rapidly suppress nonclassical correlations. Here we show that this intuition fails for collective quantum modes whose dynamics is governed by reduced open-system channels rather than by microscopic thermal equilibrium. For two spatially separated collective modes, we derive an exact entanglement boundary based on the positivity of the partial transpose, valid in the symmetric resonant limit. From this result we obtain an explicit minimum collective fluctuation amplitude, expressed entirely in measurable noise, bandwidth, dissipation, and distance-dependent coupling parameters, required to sustain steady-state entanglement at finite temperature. We further show that large collective occupation suppresses but does not eliminate quantum phase diffusion, so the steady state remains phase symmetric and does not collapse to a classical mean-field despite macroscopic signal amplitudes. Stochastic simulations of the reduced open-system dynamics, together with matched classical correlated-noise null models analyzed through an identical pipeline, confirm that entanglement witnesses are violated only in the quantum regime. Our results establish a minimal, platform-independent framework connecting collective-mode dynamics, noise injection, distance, and operational certification of macroscopic entanglement."}
{"id": "2512.22942", "categories": ["quant-ph", "cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.22942", "abs": "https://arxiv.org/abs/2512.22942", "authors": ["Anwesha Chakraborty", "Lucas Hackl", "Mario Kieburg"], "title": "Random matrix prediction of average entanglement entropy in non-Abelian symmetry sectors", "comment": "22 pages, 4 figures, 2 tables", "summary": "We study the average bipartite entanglement entropy of Haar-random pure states in quantum many-body systems with global $\\mathrm{SU}(2)$ symmetry, constrained to fixed total spin $J$ and magnetization $J_z = 0$. Focusing on spin-$\\tfrac12$ lattices and subsystem fractions $f < \\frac{1}{2}$, we derive a asymptotic expression for the average entanglement entropy up to constant order in the system volume $V$. In addition to the expected leading volume law term, we prove the existence of a $\\frac{1}{2}\\log V$ finite-size correction resulting from the scaling of the Clebsch-Gordon coefficients and compute explicitly the $O(1)$ contribution reflecting angular-momentum coupling within magnetization blocks. Our analysis uses features of random matrix ensembles and provides a fully analytical treatment for arbitrary spin densities, thereby extending Page type results to non-Abelian sectors and clarifying how $\\mathrm{SU}(2)$ symmetry shapes average entanglement."}
{"id": "2512.23178", "categories": ["math.OC", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23178", "abs": "https://arxiv.org/abs/2512.23178", "authors": ["Zijian Liu"], "title": "Clipped Gradient Methods for Nonsmooth Convex Optimization under Heavy-Tailed Noise: A Refined Analysis", "comment": "Part of this work is in submission", "summary": "Optimization under heavy-tailed noise has become popular recently, since it better fits many modern machine learning tasks, as captured by empirical observations. Concretely, instead of a finite second moment on gradient noise, a bounded ${\\frak p}$-th moment where ${\\frak p}\\in(1,2]$ has been recognized to be more realistic (say being upper bounded by $σ_{\\frak l}^{\\frak p}$ for some $σ_{\\frak l}\\ge0$). A simple yet effective operation, gradient clipping, is known to handle this new challenge successfully. Specifically, Clipped Stochastic Gradient Descent (Clipped SGD) guarantees a high-probability rate ${\\cal O}(σ_{\\frak l}\\ln(1/δ)T^{1/{\\frak p}-1})$ (resp. ${\\cal O}(σ_{\\frak l}^2\\ln^2(1/δ)T^{2/{\\frak p}-2})$) for nonsmooth convex (resp. strongly convex) problems, where $δ\\in(0,1]$ is the failure probability and $T\\in\\mathbb{N}$ is the time horizon. In this work, we provide a refined analysis for Clipped SGD and offer two faster rates, ${\\cal O}(σ_{\\frak l}d_{\\rm eff}^{-1/2{\\frak p}}\\ln^{1-1/{\\frak p}}(1/δ)T^{1/{\\frak p}-1})$ and ${\\cal O}(σ_{\\frak l}^2d_{\\rm eff}^{-1/{\\frak p}}\\ln^{2-2/{\\frak p}}(1/δ)T^{2/{\\frak p}-2})$, than the aforementioned best results, where $d_{\\rm eff}\\ge1$ is a quantity we call the $\\textit{generalized effective dimension}$. Our analysis improves upon the existing approach on two sides: better utilization of Freedman's inequality and finer bounds for clipping error under heavy-tailed noise. In addition, we extend the refined analysis to convergence in expectation and obtain new rates that break the known lower bounds. Lastly, to complement the study, we establish new lower bounds for both high-probability and in-expectation convergence. Notably, the in-expectation lower bounds match our new upper bounds, indicating the optimality of our refined analysis for convergence in expectation."}
{"id": "2512.23170", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23170", "abs": "https://arxiv.org/abs/2512.23170", "authors": ["Mingxue Yan", "Xuewen Zhang", "Kaixiang Zhang", "Zhaojian Li", "Xunyuan Yin"], "title": "Learning-based data-enabled economic predictive control with convex optimization for nonlinear systems", "comment": "18 pages,7 figures,9 tables", "summary": "In this article, we propose a data-enabled economic predictive control method for a class of nonlinear systems, which aims to optimize the economic operational performance while handling hard constraints on the system outputs. Two lifting functions are constructed via training neural networks, which generate mapped input and mapped output in a higher-dimensional space, where the nonlinear economic cost function can be approximated using a quadratic function of the mapped variables. The data-enabled predictive control framework is extended to address nonlinear dynamics by using the mapped input and the mapped output that belong to a virtual linear representation, which serves as an approximation of the original nonlinear system. Additionally, we reconstruct the system output variables from the mapped output, on which hard output constraints are imposed. The online control problem is formulated as a convex optimization problem, despite the nonlinearity of the system dynamics and the original economic cost function. Theoretical analysis is presented to justify the suitability of the proposed method for nonlinear systems. We evaluate the proposed method through two large-scale industrial case studies: (i) a biological water treatment process, and (ii) a solvent-based shipboard post-combustion carbon capture process. These studies demonstrate its effectiveness and advantages."}
{"id": "2512.23170", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23170", "abs": "https://arxiv.org/abs/2512.23170", "authors": ["Mingxue Yan", "Xuewen Zhang", "Kaixiang Zhang", "Zhaojian Li", "Xunyuan Yin"], "title": "Learning-based data-enabled economic predictive control with convex optimization for nonlinear systems", "comment": "18 pages,7 figures,9 tables", "summary": "In this article, we propose a data-enabled economic predictive control method for a class of nonlinear systems, which aims to optimize the economic operational performance while handling hard constraints on the system outputs. Two lifting functions are constructed via training neural networks, which generate mapped input and mapped output in a higher-dimensional space, where the nonlinear economic cost function can be approximated using a quadratic function of the mapped variables. The data-enabled predictive control framework is extended to address nonlinear dynamics by using the mapped input and the mapped output that belong to a virtual linear representation, which serves as an approximation of the original nonlinear system. Additionally, we reconstruct the system output variables from the mapped output, on which hard output constraints are imposed. The online control problem is formulated as a convex optimization problem, despite the nonlinearity of the system dynamics and the original economic cost function. Theoretical analysis is presented to justify the suitability of the proposed method for nonlinear systems. We evaluate the proposed method through two large-scale industrial case studies: (i) a biological water treatment process, and (ii) a solvent-based shipboard post-combustion carbon capture process. These studies demonstrate its effectiveness and advantages."}
{"id": "2512.22909", "categories": ["math.OC", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.22909", "abs": "https://arxiv.org/abs/2512.22909", "authors": ["Zhaosong Lu", "Sanyou Mei"], "title": "A first-order method for nonconvex-strongly-concave constrained minimax optimization", "comment": "Accepted by Optimization Methods and Software", "summary": "In this paper we study a nonconvex-strongly-concave constrained minimax problem. Specifically, we propose a first-order augmented Lagrangian method for solving it, whose subproblems are nonconvex-strongly-concave unconstrained minimax problems and suitably solved by a first-order method developed in this paper that leverages the strong concavity structure. Under suitable assumptions, the proposed method achieves an \\emph{operation complexity} of $O(\\varepsilon^{-3.5}\\log\\varepsilon^{-1})$, measured in terms of its fundamental operations, for finding an $\\varepsilon$-KKT solution of the constrained minimax problem, which improves the previous best-known operation complexity by a factor of $\\varepsilon^{-0.5}$."}
{"id": "2512.23581", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.23581", "abs": "https://arxiv.org/abs/2512.23581", "authors": ["Courtney Kyger", "James Fernandez", "John A. Grunenwald", "James Braun", "Annie Booth"], "title": "Profile Bayesian Optimization for Expensive Computer Experiments", "comment": null, "summary": "We propose a novel Bayesian optimization (BO) procedure aimed at identifying the ``profile optima'' of a deterministic black-box computer simulation that has a single control parameter and multiple nuisance parameters. The profile optima capture the optimal response values as a function of the control parameter. Our objective is to identify them across the entire plausible range of the control parameter. Classic BO, which targets a single optimum over all parameters, does not explore the entire control parameter range. Instead, we develop a novel two-stage acquisition scheme to balance exploration across the control parameter and exploitation of the profile optima, leveraging deep and shallow Gaussian process surrogates to facilitate uncertainty quantification. We are motivated by a computer simulation of a diffuser in a rotating detonation combustion engine, which returns the energy lost through diffusion as a function of various design parameters. We aim to identify the lowest possible energy loss as a function of the diffuser's length; understanding this relationship will enable well-informed design choices. Our ``profile Bayesian optimization'' procedure outperforms traditional BO and profile optimization methods on a variety of benchmarks and proves effective in our motivating application."}
{"id": "2512.23591", "categories": ["physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23591", "abs": "https://arxiv.org/abs/2512.23591", "authors": ["Pablo Yanes-Thomas", "Rocío Jáuregui-Renaud Santiago F. Caballero-Benítez", "Daniel Sahagún Sánchez", "Alejandro Kunold"], "title": "MultiAtomLiouvilleEquationGenerator: A Mathematica package for Liouville superoperators and master equations of multilevel atomic systems", "comment": "55 pages, 3 figures", "summary": "MulAtoLEG (Multi-Atom Liouville Equation Generator) is an open-source Mathematica package for generating Liouville superoperators and Liouville equations, specialized for multilevel atomic systems comprising an arbitrary number of atoms. This scheme is based on an extension to multilevel atomic systems, originally developed by Lehmberg [R. H. Lehmberg, Phys. Rev. A 2, 883 (1970)] as an adjoint master equation for ensembles of two-level emitters and later reformulated by Genes [M. Reitz, C. Sommer and C. Genes, PRX Quantum 3, 010201 (2022)] as a master equation. The package facilitates the generation of equations for complex transition configurations in alkali atoms. Although primarily designed for atomic systems, it can also generate the master and adjoint master equations for general Hamiltonians and Lindbladians. In addition, it includes functionalities to construct the differential equations in the dressed-state basis, where, in many cases, the non-unitary evolution operator can be determined explicitly. To maximize computational efficiency, the package leverages Mathematica's vectorization and sparse linear algebra capabilities. Since MulAtoLEG produces exact equations without approximations, the feasible system size is naturally limited by the available computational resources."}
{"id": "2512.22541", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22541", "abs": "https://arxiv.org/abs/2512.22541", "authors": ["Tengtao Guo", "Yuxuan Zhou", "Jiahui Feng", "Xinyu Zhao", "Yan Xia"], "title": "Entanglement protection induced by mixed noise", "comment": "9 pages, 6 figures", "summary": "Contrary to the conventional view that noise is detrimental, we show that mixed noise can protect entanglement in a two-atom-cavity system. Specifically, the leakage of the cavity and the stochastic atom-cavity couplings are modeled as two types of noises. From the analytical derivation of the dynamical equations, the mechanism of the entanglement protection is revealed as the high-frequency(HF) noise in the atom-cavity couplings could suppress the decoherence caused by the cavity leakage, thus protect the entanglement. We investigate the entanglement protection induced by mixed noise constructed from diverse noise types, including the Ornstein-Uhlenbeck noise, flicker noise, and telegraph noise. Numerical simulations demonstrate that entanglement protection depends critically on the proportion of HF components in the power spectral density of the mixed noise. Our work establishes that enhanced HF components are essential for effective noise-assisted entanglement protection, offering key insights for noise engineering in practical open quantum systems."}
{"id": "2512.23361", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23361", "abs": "https://arxiv.org/abs/2512.23361", "authors": ["Chang-Yu Shen", "Shuai Yin", "Zi-Xiang Li"], "title": "Universal Entanglement Growth along Imaginary Time in Quantum Critical Systems", "comment": "7+5 pages, 4+3 figures", "summary": "Characterizing universal entanglement features in higher-dimensional quantum matter is a central goal of quantum information science and condensed matter physics. While the subleading corner terms in two-dimensional quantum systems encapsulate essential universal information of the underlying conformal field theory, our understanding of these features remains remarkably limited compared to their one-dimensional counterparts. We address this challenge by investigating the entanglement dynamics of fermionic systems along the imaginary-time evolution. We uncover a pioneering non-equilibrium scaling law where the corner entanglement entropy grows linearly with the logarithm of imaginary time, dictated solely by the universality class of the quantum critical point. Through unbiased Quantum Monte Carlo simulations, we verify this scaling in the interacting Gross-Neveu-Yukawa model, demonstrating that universal data can be accurately recovered from the early stages of relaxation. Our findings significantly circumvent the computational bottlenecks inherent in reaching full equilibrium convergence. This work establishes a direct link between the fundamental theory of non-equilibrium critical phenomena and the high-precision determination of universal entanglement properties on both classical and quantum platforms, paving the way for probing the rich entanglement structure of quantum critical systems."}
{"id": "2512.23188", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23188", "abs": "https://arxiv.org/abs/2512.23188", "authors": ["Huaning Liu", "Junke Yang", "Soren L. Larsen", "Pamela P. Martinez", "Gokce Dayanikli"], "title": "Incorporating Authority Perception, Economic Status, and Behavioral Response in Infectious Disease Control", "comment": null, "summary": "We introduce a multi-population mean field game framework to examine how economic status and authority perception shape vaccination and social distancing decisions under different epidemic control policies. We carried out a survey to inform our model and stratify the population into six groups based on income and perception of authority, capturing behavioral heterogeneity. Individuals adjust their socialization and vaccination levels to optimize objectives such as minimizing treatment costs, complying with social-distancing guidelines if they are authority-followers, or reducing losses from decreased social interactions if they are authority-indifferents, alongside economic costs. Public health authorities influence behavior through social-distancing guidelines and vaccination costs. We characterize the Nash equilibrium via a forward-backward differential equation system, provide its mathematical analysis, and develop a numerical algorithm to solve it. Our findings reveal a trade-off between social-distancing and vaccination decisions. Under stricter guidelines that target both susceptible and infected individuals, followers reduce both socialization and vaccination levels, while indifferents increase socialization due to followers' preventative measures. Adaptive guidelines targeting infected individuals effectively reduce infections and narrow the gap between low- and high-income groups, even when susceptible individuals socialize more and vaccinate less. Lower vaccination costs incentivize vaccination among low-income groups, but their impact on disease spread is smaller than when they are coupled with social-distancing guidelines. Trust-building emerges as a critical factor in epidemic mitigation, underscoring the importance of data-informed, game-theoretical models that aim to understand complex human responses to mitigation policies."}
{"id": "2512.23186", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23186", "abs": "https://arxiv.org/abs/2512.23186", "authors": ["Yanbo Li", "Jinsong Li", "Zongjue Liu", "Riming Xu"], "title": "Multi-objective control strategy of Electro-Mechanical Transmission Based on Driving Pattern Division", "comment": "25pages 10figures", "summary": "Based on the driving requirement and power balance of heavy-duty vehicle equipped with Electro-Mechanical Transmission (EMT), optimization goals under different driving patterns are put forward. The optimization objectives are changed into a comprehensive optimization target based on the method of weighting, which is calculated by using analytic hierarchy process (AHP) under different working conditions. According to theory of Dynamic Programming (DP), a multi-object control strategy of DP under different driving patterns is proposed. This strategy is verified by simulation and contrasted with rule strategy, the results show that comprehensive performance is significantly enhanced, and the fuel economy is highly improved especially."}
{"id": "2512.23186", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23186", "abs": "https://arxiv.org/abs/2512.23186", "authors": ["Yanbo Li", "Jinsong Li", "Zongjue Liu", "Riming Xu"], "title": "Multi-objective control strategy of Electro-Mechanical Transmission Based on Driving Pattern Division", "comment": "25pages 10figures", "summary": "Based on the driving requirement and power balance of heavy-duty vehicle equipped with Electro-Mechanical Transmission (EMT), optimization goals under different driving patterns are put forward. The optimization objectives are changed into a comprehensive optimization target based on the method of weighting, which is calculated by using analytic hierarchy process (AHP) under different working conditions. According to theory of Dynamic Programming (DP), a multi-object control strategy of DP under different driving patterns is proposed. This strategy is verified by simulation and contrasted with rule strategy, the results show that comprehensive performance is significantly enhanced, and the fuel economy is highly improved especially."}
{"id": "2512.23027", "categories": ["cs.CE", "cs.DC", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.23027", "abs": "https://arxiv.org/abs/2512.23027", "authors": ["Sudhi Sharma Padillath Vasudevan"], "title": "A Domain Decomposition-based Solver for Acoustic Wave propagation in Two-Dimensional Random Media", "comment": "29 pages, 55 figures. Based on the author's thesis submitted to Carleton University (2023). This research was performed while the author was at the Department of Civil and Environmental Engineering, Carleton University", "summary": "An acoustic wave propagation problem with a log normal random field approximation for wave speed is solved using a sampling-free intrusive stochastic Galerkin approach. The stochastic partial differential equation with the inputs and outputs expanded using polynomial chaos expansion (PCE) is transformed into a set of deterministic PDEs and further to a system of linear equations. Domain decomposition (DD)-based solvers are utilized to handle the overwhelming computational cost for the resulting system with increasing mesh size, time step and number of random parameters. A conjugate gradient iterative solver with a two-level Neumann-Neumann preconditioner is applied here showing their efficient scalabilities."}
{"id": "2512.23627", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.23627", "abs": "https://arxiv.org/abs/2512.23627", "authors": ["Nithisha Suryadevara", "Vivek Reddy Srigiri"], "title": "Joint Modeling of Longitudinal and Survival Data: A Bayesian Approach for Predicting Disease Progression", "comment": "Preprint. Simulation study and application to a real-world clinical dataset", "summary": "Joint modeling of longitudinal and survival data has become increasingly important in medical research, particularly for understanding disease progression in chronic conditions where both repeated biomarker measurements and time-to-event outcomes are available. Traditional two-stage methods, which analyze longitudinal and survival components separately, often result in biased estimates and suboptimal predictions due to failure to account for their interdependence.\n  In this study, we propose a Bayesian hierarchical joint modeling framework with an emphasis on predictive evaluation and clinical interpretability. The model simultaneously characterizes the longitudinal trajectory of a biomarker and the associated survival outcome through shared random effects, capturing the intrinsic association between disease dynamics and event risk. The Bayesian formulation allows flexible incorporation of prior information, accommodates irregular measurement times and missing data, and provides full posterior distributions for uncertainty quantification via credible intervals.\n  We evaluate the proposed framework using both simulated data designed to mimic realistic patient trajectories and a real-world clinical dataset involving patients with chronic liver disease. Results demonstrate that the Bayesian joint model consistently outperforms conventional two-stage approaches in terms of parameter estimation accuracy and predictive performance, as measured by time-dependent area under the curve and Brier scores. The proposed approach provides a robust and interpretable tool for dynamic, patient-specific prognosis, supporting clinical decision-making in personalized medicine."}
{"id": "2512.22555", "categories": ["cs.CE", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.22555", "abs": "https://arxiv.org/abs/2512.22555", "authors": ["Fynn Jerome Aschmoneit", "Bastiaan Cockx"], "title": "Volume and Surface Area of two Orthogonal, Partially Intersecting Cylinders: A Generalization of the Steinmetz Solid", "comment": null, "summary": "The intersection of two orthogonal cylinders represents a classical problem in computational geometry with direct applications to engineering design, manufacturing, and numerical simulation. While analytical solutions exist for the fully intersecting case, the Steinmetz solid, partial intersections with arbitrary depth ratios require numerical methods or approximations. This work presents general integral expressions for both the intersection volume and surface area as explicit functions of the intersection depth. Accompanying these exact formulations are empirical approximation functions, which provide closed-form evaluations with relative errors below 15% across the full range of intersection depth. Validation against Quasi-Monte Carlo simulation confirms the accuracy of both the analytical and approximate solutions."}
{"id": "2512.22542", "categories": ["quant-ph", "math.PR", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.22542", "abs": "https://arxiv.org/abs/2512.22542", "authors": ["Tingyu Zhao", "Balázs Maga", "Pierfrancesco Dionigi", "Gergely Ódor", "Kyle Soni", "Anastasiya Salova", "Bingjie Hao", "Miklós Abért", "István A. Kovács"], "title": "Quantum preferential attachment", "comment": null, "summary": "The quantum internet is a rapidly developing technological reality, yet, it remains unclear what kind of quantum network structures might emerge. Since indirect quantum communication is already feasible and preserves absolute security of the communication channel, a new node joining the quantum network does not need to connect directly to its desired target. Instead, in our proposed quantum preferential attachment model, it uniformly randomly connects to any node within the proximity of the target, including, but not restricted to, the target itself. This local flexibility is found to qualitatively change the global network behavior, leading to two distinct classes of complex network architectures, both of which are small-world, but neither of which is scale-free. Our numerical findings are supported by rigorous analytic results, in a framework that incorporates quantum and classical variants of preferential attachment in a unified phase diagram. Besides quantum networks, we expect that our results will have broad implications for classical scenarios where there is flexibility in establishing new connections."}
{"id": "2512.23706", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23706", "abs": "https://arxiv.org/abs/2512.23706", "authors": ["Saranesh Prembabu", "Shu-Heng Shao", "Ruben Verresen"], "title": "Non-Invertible Interfaces Between Symmetry-Enriched Critical Phases", "comment": "11 pages, 7 figures + 4 page appendix", "summary": "Gapless quantum phases can become distinct when internal symmetries are enforced, in analogy with gapped symmetry-protected topological (SPT) phases. However, this distinction does not always lead to protected edge modes, raising the question of how the bulk-boundary correspondence is generalized to gapless cases. We propose that the spatial interface between gapless phases -- rather than their boundaries -- provides a more robust fingerprint. We show that whenever two 1+1d conformal field theories (CFTs) differ in symmetry charge assignments of local operators or twisted sectors, any symmetry-preserving spatial interface between the theories must flow to a non-invertible defect. We illustrate this general result for different versions of the Ising CFT with $\\mathbb{Z}_2 \\times \\mathbb{Z}_2^T$ symmetry, obtaining a complete classification of allowed conformal interfaces. When the Ising CFTs differ by nonlocal operator charges, the interface hosts 0+1d symmetry-breaking phases with finite-size splittings scaling as $1/L^3$, as well as continuous phase transitions between them. For general gapless phases differing by an SPT entangler, the interfaces between them can be mapped to conformal defects with a certain defect 't Hooft anomaly. This classification also gives implications for higher-dimensional examples, including symmetry-enriched variants of the 2+1d Ising CFT. Our results establish a physical indicator for symmetry-enriched criticality through symmetry-protected interfaces, giving a new handle on the interplay between topology and gapless phases."}
{"id": "2512.23203", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23203", "abs": "https://arxiv.org/abs/2512.23203", "authors": ["Shuo Shi", "Juan Zhang"], "title": "Output feedback stabilization of linear port-Hamiltonian descriptor systems", "comment": "20 pages", "summary": "This paper presents a structure-preserving method for the stabilization of linear port-Hamiltonian (pH) descriptor systems via output feedback. The stabilization problem is NP-hard for general descriptor systems. Existing approaches often rely on explicit knowledge of the structure-defining matrix $Q$, which is difficult to determine in practice. When $Q$ is unknown, we derive necessary and sufficient conditions under which proportional output feedback ensures that the closed-loop system is regular, impulse-free, asymptotically stable, and retains the port-Hamiltonian structure. These conditions also allow any positive definite matrix to serve as the feedback matrix. The framework is further extended to proportional and derivative output feedback, enabling the assignment of a desired dynamical order. The proposed method thus generalizes existing stabilization results from the special case $Q = I$ to systems with an unknown $Q$, offering a systematic method to structure-preserving stabilization of pH descriptor systems."}
{"id": "2512.23189", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23189", "abs": "https://arxiv.org/abs/2512.23189", "authors": ["Zelin Zang", "Yuhang Song", "Bingo Wing-Kuen Ling", "Aili Wang", "Fuji Yang"], "title": "The Dawn of Agentic EDA: A Survey of Autonomous Digital Chip Design", "comment": null, "summary": "This survey provides a comprehensive overview of the integration of Generative AI and Agentic AI within the field of Digital Electronic Design Automation (EDA). The paper first reviews the paradigmatic evolution from traditional Computer-Aided Design (CAD) to AI-assisted EDA (AI4EDA), and finally to the emerging AI-Native and Agentic design paradigms. We detail the application of these paradigms across the digital chip design flow, including the construction of agentic cognitive architectures based on multimodal foundation models, frontend RTL code generation and intelligent verification, and backend physical design featuring algorithmic innovations and tool orchestration. We validate these methodologies through integrated case studies, demonstrating practical viability from microarchitecture definition to GDSII. Special emphasis is placed on the potential for cross-stage feedback loops where agents utilize backend PPA metrics to autonomously refine frontend logic. Furthermore, this survey delves into the dual-faceted impact on security, covering novel adversarial risks, automated vulnerability repair, and privacy-preserving infrastructure. Finally, the paper critically summarizes current challenges related to hallucinations, data scarcity, and black-box tools, and outlines future trends towards L4 autonomous chip design. Ultimately, this work aims to define the emerging field of Agentic EDA and provide a strategic roadmap for the transition from AI-assisted tools to fully autonomous design engineers."}
{"id": "2512.23189", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23189", "abs": "https://arxiv.org/abs/2512.23189", "authors": ["Zelin Zang", "Yuhang Song", "Bingo Wing-Kuen Ling", "Aili Wang", "Fuji Yang"], "title": "The Dawn of Agentic EDA: A Survey of Autonomous Digital Chip Design", "comment": null, "summary": "This survey provides a comprehensive overview of the integration of Generative AI and Agentic AI within the field of Digital Electronic Design Automation (EDA). The paper first reviews the paradigmatic evolution from traditional Computer-Aided Design (CAD) to AI-assisted EDA (AI4EDA), and finally to the emerging AI-Native and Agentic design paradigms. We detail the application of these paradigms across the digital chip design flow, including the construction of agentic cognitive architectures based on multimodal foundation models, frontend RTL code generation and intelligent verification, and backend physical design featuring algorithmic innovations and tool orchestration. We validate these methodologies through integrated case studies, demonstrating practical viability from microarchitecture definition to GDSII. Special emphasis is placed on the potential for cross-stage feedback loops where agents utilize backend PPA metrics to autonomously refine frontend logic. Furthermore, this survey delves into the dual-faceted impact on security, covering novel adversarial risks, automated vulnerability repair, and privacy-preserving infrastructure. Finally, the paper critically summarizes current challenges related to hallucinations, data scarcity, and black-box tools, and outlines future trends towards L4 autonomous chip design. Ultimately, this work aims to define the emerging field of Agentic EDA and provide a strategic roadmap for the transition from AI-assisted tools to fully autonomous design engineers."}
{"id": "2512.23358", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.23358", "abs": "https://arxiv.org/abs/2512.23358", "authors": ["Louis Libat", "Can Selçuk", "Eric Chénier", "Vincent Le Chenadec"], "title": "A space-time extension of a conservative two-fluid cut-cell diffusion method for moving geometries", "comment": "25 pages, 11 figures", "summary": "We present a space-time extension of a conservative Cartesian cut-cell finite-volume method for two-phase diffusion in prescribed-motion geometries. The formulation follows a two-fluid approach: one scalar field is solved in each phase with discontinuous material properties, coupled by sharp interface conditions enforcing flux continuity and jump laws. To handle moving boundaries on a fixed Cartesian grid, the discrete balance is written over phase-restricted space-time control volumes, whose geometric moments (swept volumes and apertures) are used as weights in the finite-volume operators. This construction naturally accounts for the creation and destruction of cut cells (fresh/dead-cell events) and yields strict discrete conservation. The resulting scheme retains the algebraic structure of the static cut-cell formulation while incorporating motion through local geometric weights and interface coupling operators. A series of verification and validation tests in two and three dimensions demonstrate super-linear accuracy in space, robust behavior under repeated topology changes and conservation across strong coefficient jumps and moving interfaces. The proposed space-time cut-cell framework provides a conservative building block for multiphase transport in evolving geometries and a foundation for future free-boundary extensions such as Stefan-type phase change."}
{"id": "2512.22162", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.22162", "abs": "https://arxiv.org/abs/2512.22162", "authors": ["Vladimir Vovk"], "title": "Exchangeability and randomness for infinite and finite sequences", "comment": "15 pages, 1 figure", "summary": "Randomness (in the sense of being generated in an IID fashion) and exchangeability are standard assumptions in nonparametric statistics and machine learning, and relations between them have been a popular topic of research. This note draws the reader's attention to the fact that, while for infinite sequences of observations the two assumptions are almost indistinguishable, the difference between them becomes very significant for finite sequences of a given length."}
{"id": "2512.22572", "categories": ["quant-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.22572", "abs": "https://arxiv.org/abs/2512.22572", "authors": ["Luca Ion", "Adam Smith"], "title": "Variational quantum eigensolver for chemical molecules", "comment": null, "summary": "Solving interacting multi-particle systems is a central challenge in quantum chemistry and condensed matter physics. In this work, we investigate the computation of ground states and ground-state energies for the He-H+ and H2O molecules using quantum computing techniques. We employ the variational quantum eigensolver (VQE), implemented both on a quantum computer simulator and on an IBM quantum device. The resulting energies are benchmarked against exact ground-state energies obtained via classical methods. Simulations of the H2O molecule were performed on Nottingham's High Performance Computing (HPC) facilities."}
{"id": "2512.22558", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22558", "abs": "https://arxiv.org/abs/2512.22558", "authors": ["Ben Wang", "Minghao Mi", "Huangqiuchen Wang", "Qian Xie", "Lijian Zhang"], "title": "Experimental Joint Estimation of Phase and Phase Diffusion via Deterministic Bell Measurements", "comment": null, "summary": "Accurate phase estimation plays a pivotal role in quantum metrology, yet its precision is significantly affected by noise, particularly phase-diffusive noise caused by phase drift. To address this challenge, the joint estimation of phase and phase diffusion has emerged as an effective approach, transforming the problem into a multi-parameter estimation task. However, the incompatibility between optimal measurements for different parameters prevents single-copy measurements from reaching the fundamental precision limits defined by the quantum Cramer-Rao bound. Meanwhile, collective measurements performed on multiple identical copies can mitigate this incompatibility and thus enhance the precision of joint parameter estimation. This work experimentally demonstrates joint phase and phase-diffusion estimation using deterministic Bell measurements on a two-qubit system. A linear optical network is employed to implement both parameter encoding and deterministic Bell measurements, achieving improved estimation precision compared to any separable measurement strategy. This work proposes a new framework for phase estimation under phase-diffusive noise and underscores the substantial advantages of collective measurements in multi-parameter quantum metrology."}
{"id": "2512.23317", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23317", "abs": "https://arxiv.org/abs/2512.23317", "authors": ["Kansei Ushiyama", "Shun Sato", "Takayasu Matsuo"], "title": "Essential Convergence Rates of Continuous-Time Models for Optimization Methods", "comment": null, "summary": "Designing and analyzing optimization methods via continuous-time models expressed as ordinary differential equations (ODEs) is a promising approach for its intuitiveness and simplicity. A key concern, however, is that the convergence rates of such models can be arbitrarily modified by time rescaling, rendering the task of seeking ODEs with ``fast'' convergence meaningless. To eliminate this ambiguity of the rates, we introduce the notion of the essential convergence rate. We justify this notion by proving that, under appropriate assumptions on discretization, no method obtained by discretizing an ODE can achieve a faster rate than its essential convergence rate."}
{"id": "2512.23205", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23205", "abs": "https://arxiv.org/abs/2512.23205", "authors": ["Hamid Varmazyari", "Masoud H. Nazari"], "title": "A Learning-Driven Stochastic Hybrid System Framework for Detecting Unobservable Contingencies in Power Systems", "comment": null, "summary": "This paper presents a new learning based Stochastic Hybrid System (LSHS) framework designed for the detection and classification of contingencies in modern power systems. Unlike conventional monitoring schemes, the proposed approach is capable of identifying unobservable events that remain hidden from standard sensing infrastructures, such as undetected protection system malfunctions. The framework operates by analyzing deviations in system outputs and behaviors, which are then categorized into three groups: physical, control, and measurement contingencies based on their impact on the SHS model. The SHS model integrates both system dynamics and observer-driven state estimation error dynamics. Within this architecture, machine learning classifiers are employed to achieve rapid and accurate categorization of contingencies. The effectiveness of the method is demonstrated through simulations on the IEEE 5-bus and 30-bus systems, where results indicate substantial improvements in both detection speed and accuracy compared with existing approaches."}
{"id": "2512.23205", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23205", "abs": "https://arxiv.org/abs/2512.23205", "authors": ["Hamid Varmazyari", "Masoud H. Nazari"], "title": "A Learning-Driven Stochastic Hybrid System Framework for Detecting Unobservable Contingencies in Power Systems", "comment": null, "summary": "This paper presents a new learning based Stochastic Hybrid System (LSHS) framework designed for the detection and classification of contingencies in modern power systems. Unlike conventional monitoring schemes, the proposed approach is capable of identifying unobservable events that remain hidden from standard sensing infrastructures, such as undetected protection system malfunctions. The framework operates by analyzing deviations in system outputs and behaviors, which are then categorized into three groups: physical, control, and measurement contingencies based on their impact on the SHS model. The SHS model integrates both system dynamics and observer-driven state estimation error dynamics. Within this architecture, machine learning classifiers are employed to achieve rapid and accurate categorization of contingencies. The effectiveness of the method is demonstrated through simulations on the IEEE 5-bus and 30-bus systems, where results indicate substantial improvements in both detection speed and accuracy compared with existing approaches."}
{"id": "2512.22714", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.22714", "abs": "https://arxiv.org/abs/2512.22714", "authors": ["Matey Neykov"], "title": "Polynomial-Time Near-Optimal Estimation over Certain Type-2 Convex Bodies", "comment": null, "summary": "We develop polynomial-time algorithms for near-optimal minimax mean estimation under $\\ell_2$-squared loss in a Gaussian sequence model under convex constraints. The parameter space is an origin-symmetric, type-2 convex body $K \\subset \\mathbb{R}^n$, and we assume additional regularity conditions: specifically, we assume $K$ is well-balanced, i.e., there exist known radii $r, R > 0$ such that $r B_2 \\subseteq K \\subseteq R B_2$, as well as oracle access to the Minkowski gauge of $K$. Under these and some further assumptions on $K$, our procedures achieve the minimax rate up to small factors, depending poly-logarithmically on the dimension, while remaining computationally efficient.\n  We further extend our methodology to the linear regression and robust heavy-tailed settings, establishing polynomial-time near-optimal estimators when the constraint set satisfies the regularity conditions above. To the best of our knowledge, these results provide the first general framework for attaining statistically near-optimal performance under such broad geometric constraints while preserving computational tractability."}
{"id": "2512.22826", "categories": ["cond-mat.stat-mech", "physics.comp-ph", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.22826", "abs": "https://arxiv.org/abs/2512.22826", "authors": ["Aryan Tyagi", "Soumyajyoti Biswas", "Anirban Chakraborti"], "title": "Active-Absorbing Phase Transitions in the Parallel Minority Game", "comment": "6 pages, 3 figures", "summary": "The Parallel Minority Game (PMG) is a synchronous adaptive multi-agent model that exhibits active-absorbing transitions characteristic of non-equilibrium statistical systems. We perform a comprehensive numerical study of the PMG under two families of microscopic decision rules: (i) agents update their choices based on instantaneous population in their alternative choices, and (ii) threshold-based activation that activates agents movement only after overcrowding density crossing a threshold. We measure time-dependent and steady state limits of activity $A(t)$, overcrowding fraction $F(t)$ as functions of the control parameter $g=N/D$, where $N$ is the number of agents and $D$ is the total number of sites. Instantaneous rules display mean-field directed-percolation (MF-DP) scaling with $β\\approx1.00$, $δ\\approx0.5$, and $ν_{\\parallel}\\approx2.0$. Threshold rules, however, produce a distinct non-mean-field universality class with $β\\approx0.75$ and a systematic failure of MF-DP dynamical scaling. We show that thresholding acts as a relevant perturbation to DP. The results highlight how minimal cognitive features at the agent level fundamentally alter large-scale critical behaviour in socio-economic and active systems."}
{"id": "2512.22559", "categories": ["quant-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.22559", "abs": "https://arxiv.org/abs/2512.22559", "authors": ["Jiahua Yang", "Zhen Lu", "Yue Yang"], "title": "Modeling Noise in Quantum Computing of Scalar Convection", "comment": null, "summary": "Quantum computing holds potential for accelerating the simulation of fluid dynamics. However, hardware noise in the noisy intermediate-scale quantum era significantly distorts simulation accuracy. Although error magnitudes are frequently quantified, the specific physical effects of quantum noise on flow simulation results remain largely uncharacterized. We investigate the influence of gate noise on the quantum simulation of one-dimensional scalar convection. By employing a quantum spectral algorithm where ideal time advancement affects only Fourier phases, we isolate and analyze noise-induced artifacts in spectral magnitudes. We derive a theoretical transition matrix based on Hamming distances between computational basis states to predict spectral decay, and then validate this model against density-matrix simulations and experiments on a superconducting quantum processor. Furthermore, using data-driven sparse regression, we demonstrate that quantum noise manifests in the effective partial differential equation primarily as artificial diffusion and nonlinear source terms. These findings suggest that quantum errors can be modeled as deterministic physical terms rather than purely stochastic perturbations."}
{"id": "2512.23339", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.23339", "abs": "https://arxiv.org/abs/2512.23339", "authors": ["Subrata Majumdar", "Debanjit Mondal"], "title": "Small-time global controllability of a class of bilinear fourth-order parabolic equations", "comment": "29 pages, Comments are welcome!", "summary": "In this work, we investigate the small-time global controllability properties of a class of fourth-order nonlinear parabolic equations driven by a bilinear control posed on the one-dimensional torus. The controls depend only on time and act through a prescribed family of spatial profiles. Our first result establishes the small-time global approximate controllability of the system using three scalar controls, between states that share the same sign. This property is obtained by adapting the geometric control approach to the fourth-order setting, using a finite family of frequency-localized controls. We then study the small-time global exact controllability to non-zero constant states for the concerned system. This second result is achieved by analyzing the null controllability of an appropriate linearized fourth-order system and by deducing the controllability of the nonlinear bilinear model through a fixed-point argument together with the small-time global approximate control property."}
{"id": "2512.23284", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.23284", "abs": "https://arxiv.org/abs/2512.23284", "authors": ["Mahdi Kchaou", "Francesco Contino", "Diederik Coppitters"], "title": "Revealing design archetypes and flexibility in e-molecule import pathways using Modeling to Generate Alternatives and interpretable machine learning", "comment": null, "summary": "Given the central role of green e-molecule imports in the European energy transition, many studies optimize import pathways and identify a single cost-optimal solution. However, cost optimality is fragile, as real-world implementation depends on regulatory, spatial, and stakeholder constraints that are difficult to represent in optimization models and can render cost-optimal designs infeasible. To address this limitation, we generate a diverse set of near-cost-optimal alternatives within an acceptable cost margin using Modeling to Generate Alternatives, accounting for unmodeled uncertainties. Interpretable machine learning is then applied to extract insights from the resulting solution space. The approach is applied to hydrogen import pathways considering hydrogen, ammonia, methane, and methanol as carriers. Results reveal a broad near-optimal space with great flexibility: solar, wind, and storage are not strictly required to remain within 10% of the cost optimum. Wind constraints favor solar-storage methanol pathways, while limited storage favors wind-based ammonia or methane pathways."}
{"id": "2512.23284", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.23284", "abs": "https://arxiv.org/abs/2512.23284", "authors": ["Mahdi Kchaou", "Francesco Contino", "Diederik Coppitters"], "title": "Revealing design archetypes and flexibility in e-molecule import pathways using Modeling to Generate Alternatives and interpretable machine learning", "comment": null, "summary": "Given the central role of green e-molecule imports in the European energy transition, many studies optimize import pathways and identify a single cost-optimal solution. However, cost optimality is fragile, as real-world implementation depends on regulatory, spatial, and stakeholder constraints that are difficult to represent in optimization models and can render cost-optimal designs infeasible. To address this limitation, we generate a diverse set of near-cost-optimal alternatives within an acceptable cost margin using Modeling to Generate Alternatives, accounting for unmodeled uncertainties. Interpretable machine learning is then applied to extract insights from the resulting solution space. The approach is applied to hydrogen import pathways considering hydrogen, ammonia, methane, and methanol as carriers. Results reveal a broad near-optimal space with great flexibility: solar, wind, and storage are not strictly required to remain within 10% of the cost optimum. Wind constraints favor solar-storage methanol pathways, while limited storage favors wind-based ammonia or methane pathways."}
{"id": "2512.23308", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2512.23308", "abs": "https://arxiv.org/abs/2512.23308", "authors": ["Jyotishka Datta", "Nicholas G. Polson", "Vadim Sokolov", "Daniel Zantedeschi"], "title": "Conformal Prediction = Bayes?", "comment": null, "summary": "Conformal prediction (CP) is widely presented as distribution-free predictive inference with finite-sample marginal coverage under exchangeability. We argue that CP is best understood as a rank-calibrated descendant of the Fisher-Dempster-Hill fiducial/direct-probability tradition rather than as Bayesian conditioning in disguise.\n  We establish four separations from coherent countably additive predictive semantics. First, canonical conformal constructions violate conditional extensionality: prediction sets can depend on the marginal design P(X) even when P(Y|X) is fixed. Second, any finitely additive sequential extension preserving rank calibration is nonconglomerable, implying countable Dutch-book vulnerabilities. Third, rank-calibrated updates cannot be realized as regular conditionals of any countably additive exchangeable law on Y^infty. Fourth, formalizing both paradigms as families of one-step predictive kernels, conformal and Bayesian kernels coincide only on a Baire-meagre subset of the space of predictive laws.\n  We further show that rank- and proxy-based reductions are generically Blackwell-deficient relative to full-data experiments, yielding positive Le Cam deficiency for suitable losses. Extending the analysis to prediction-powered inference (PPI) yields an analogous message: bias-corrected, proxy-rectified estimators can be valid as confidence devices while failing to define transportable belief states across stages, shifts, or adaptive selection. Together, the results sharpen a general limitation of wrappers: finite-sample calibration guarantees do not by themselves supply composable semantics for sequential updating or downstream decision-making."}
{"id": "2512.22572", "categories": ["quant-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.22572", "abs": "https://arxiv.org/abs/2512.22572", "authors": ["Luca Ion", "Adam Smith"], "title": "Variational quantum eigensolver for chemical molecules", "comment": null, "summary": "Solving interacting multi-particle systems is a central challenge in quantum chemistry and condensed matter physics. In this work, we investigate the computation of ground states and ground-state energies for the He-H+ and H2O molecules using quantum computing techniques. We employ the variational quantum eigensolver (VQE), implemented both on a quantum computer simulator and on an IBM quantum device. The resulting energies are benchmarked against exact ground-state energies obtained via classical methods. Simulations of the H2O molecule were performed on Nottingham's High Performance Computing (HPC) facilities."}
{"id": "2512.23527", "categories": ["math.OC", "cs.DM", "cs.IT", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.23527", "abs": "https://arxiv.org/abs/2512.23527", "authors": ["Barbara Fiedorowicz", "Amitabh Basu"], "title": "Identifying faulty edges in resistive electrical networks", "comment": null, "summary": "Given a resistive electrical network, we would like to determine whether all the resistances (edges) in the network are working, and if not, identify which edge (or edges) are faulty. To make this determination, we are allowed to measure the effective resistance between certain pairs of nodes (which can be done by measuring the amount of current when one unit of voltage difference is applied at the chosen pair of nodes). The goal is to determine which edge, if any, is not working in the network using the smallest number of measurements. We prove rigorous upper and lower bounds on this optimal number of measurements for different classes of graphs. These bounds are tight for several of these classes showing that our measurement strategies are optimal."}
{"id": "2512.23294", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23294", "abs": "https://arxiv.org/abs/2512.23294", "authors": ["Haixiao Gao", "Mengying Sun", "Ruichen Zhang", "Yanhan Wang", "Xiaodong Xu", "Nan Ma", "Dusit Niyato", "Ping Zhang"], "title": "Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications", "comment": null, "summary": "Semantic communications (SemCom), as one of the key technologies for 6G, is shifting networks from bit transmission to semantic information exchange. On this basis, introducing agentic artificial intelligence (AI) with perception, memory, reasoning, and action capabilities provides a practicable path to intelligent communications. This paper provides a systematic exposition of how agentic AI empowers SemCom from the perspectives of research foundations, system architecture, and application scenarios. We first provide a comprehensive review of existing studies by agent types, covering embedded agents, large language model (LLM)/large vision model (LVM) agents, and reinforcement learning (RL) agents. Additionally, we propose a unified agentic AI-enhanced SemCom framework covering the application layer, the semantic layer, and the cloud-edge collaboration layer, forming a closed loop from intent to encoding to transmission to decoding to action to evaluation. We also present several typical scenarios, including multi-vehicle collaborative perception, multi-robot cooperative rescue, and agentic operations for intellicise (intelligent and concise) networks. Furthermore, we introduce an agentic knowledge base (KB)-based joint source-channel coding case study, AKB-JSCC, where the source KB and channel KB are built by LLM/LVM agents and RL agents, respectively. Experimental results show that AKB-JSCC achieves higher information reconstruction quality under different channel conditions. Finally, we discuss future evolution and research directions, providing a reference for portable, verifiable, and controllable research and deployment of agentic SemCom."}
{"id": "2512.23294", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23294", "abs": "https://arxiv.org/abs/2512.23294", "authors": ["Haixiao Gao", "Mengying Sun", "Ruichen Zhang", "Yanhan Wang", "Xiaodong Xu", "Nan Ma", "Dusit Niyato", "Ping Zhang"], "title": "Agentic AI-Enhanced Semantic Communications: Foundations, Architecture, and Applications", "comment": null, "summary": "Semantic communications (SemCom), as one of the key technologies for 6G, is shifting networks from bit transmission to semantic information exchange. On this basis, introducing agentic artificial intelligence (AI) with perception, memory, reasoning, and action capabilities provides a practicable path to intelligent communications. This paper provides a systematic exposition of how agentic AI empowers SemCom from the perspectives of research foundations, system architecture, and application scenarios. We first provide a comprehensive review of existing studies by agent types, covering embedded agents, large language model (LLM)/large vision model (LVM) agents, and reinforcement learning (RL) agents. Additionally, we propose a unified agentic AI-enhanced SemCom framework covering the application layer, the semantic layer, and the cloud-edge collaboration layer, forming a closed loop from intent to encoding to transmission to decoding to action to evaluation. We also present several typical scenarios, including multi-vehicle collaborative perception, multi-robot cooperative rescue, and agentic operations for intellicise (intelligent and concise) networks. Furthermore, we introduce an agentic knowledge base (KB)-based joint source-channel coding case study, AKB-JSCC, where the source KB and channel KB are built by LLM/LVM agents and RL agents, respectively. Experimental results show that AKB-JSCC achieves higher information reconstruction quality under different channel conditions. Finally, we discuss future evolution and research directions, providing a reference for portable, verifiable, and controllable research and deployment of agentic SemCom."}
{"id": "2512.22591", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22591", "abs": "https://arxiv.org/abs/2512.22591", "authors": ["A. S. Naumchik", "Roman K. Goncharov", "Alexei D. Kiselev"], "title": "Asymmetry effects in homodyne and heterodyne measurements: Positive operator-valued measures and asymptotic security of Gaussian continuous variable quantum key distribution", "comment": "21 pages, 14 figures", "summary": "We use the Gaussian approximation describing photocount statistics for both the homodyne and the double homodyne (heterodyne) measurements to study asymmetry effects arising from imbalance of the beam splitters and variations in quantum efficiencies of the photodetectors. After computing the $Q$ symbols of the positive operator-valued measures (POVMs) of noisy measurements that take into account the asymmetry effects, the operator representations for the POVMs are obtained in the form that assumes applying the additive noise quantum channel to the POVMs of noiseless (ideal) measurements. For double homodyne detection, it was found that the noiseless measurements should generally be expressed in terms of the projectors onto squeezed-states and the corresponding squeezed-state operator representation of POVM along with the measurement noise channel depend on the squeezing parameter that lies in the interval dictated by the condition for the excess noise covariance matrix to be positive semi-definite. The analytical results are used to perform analysis of the asymptotic security of the Gaussian-modulated continuous variable quantum key distribution (CV-QKD) protocol in the untrusted-noise scenario where the measurement noise is assumed to be accessible to an adversary. The inherent non-uniqueness of the operator representation for the double-homodyne POVM manifests itself in the squeezing dependent Holevo information that needs to be additionally optimized. For both types of the measurements, the mutual information, the Holevo information and the asymptotic secret fraction are sensitive to asymmetry effects leading to degraded performance of the protocol."}
{"id": "2512.23695", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.23695", "abs": "https://arxiv.org/abs/2512.23695", "authors": ["Egor Makarenkov"], "title": "A dimension reduction procedure for the selection of Two-spring lattice-spring topologies with minimal fabrication cost and required weighted force-resistance performance", "comment": "8 pages, 5 figures", "summary": "Starting from a problem in elastoplasticity, we consider an optimization problem $C(c_1,c_2)=c_1+c_2\\to \\min$ under constraints $F_R^k(c_1,c_2)=a\\cdot F^k(c_1,c_2)+b\\cdot R^k(c_1,c_2)\\ge 1$ and $F^k(c_1,c_2)\\ge 1$, where both $F^k$ and $R^k$ non-linear, $a,b$ are constants, and $i\\in\\{1,2\\}$ is an index. For each $(a,b)$ we determine which of the two values of $i\\in\\{1,2\\}$ leads to the smaller minimum of the optimization problem. This way we obtain an interesting curve bounding the region where $k=1$ outperforms $k=2$."}
{"id": "2512.23420", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23420", "abs": "https://arxiv.org/abs/2512.23420", "authors": ["Antika Yadav", "Prasad Vilas Chanekar"], "title": "Control Co-design of systems with parabolic partial differential equation dynamics", "comment": null, "summary": "In this paper we study the control co-design (CCD) synthesis problem for a class of systems with parabolic partial differential equation (PDE) dynamics. We formulate CCD problem and finally derive an approximate CCD problem with matrix algebraic constraint. We then solve this approximate problem with gradient-based method and prove that the optimal solution also stabilizes the PDE system. We justify approach through numerical examples."}
{"id": "2512.23420", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23420", "abs": "https://arxiv.org/abs/2512.23420", "authors": ["Antika Yadav", "Prasad Vilas Chanekar"], "title": "Control Co-design of systems with parabolic partial differential equation dynamics", "comment": null, "summary": "In this paper we study the control co-design (CCD) synthesis problem for a class of systems with parabolic partial differential equation (PDE) dynamics. We formulate CCD problem and finally derive an approximate CCD problem with matrix algebraic constraint. We then solve this approximate problem with gradient-based method and prove that the optimal solution also stabilizes the PDE system. We justify approach through numerical examples."}
{"id": "2512.22634", "categories": ["quant-ph", "physics.ed-ph"], "pdf": "https://arxiv.org/pdf/2512.22634", "abs": "https://arxiv.org/abs/2512.22634", "authors": ["Sandy H. S. Herho", "Siti N. Kaban", "Rusmawan Suwarman", "Iwan P. Anwar", "Nurjanna J. Trilaksono"], "title": "1d-qt-ideal-solver: 1D Idealized Quantum Tunneling Solver with Absorbing Boundaries", "comment": "13 pages, 4 figures", "summary": "We present 1d-qt-ideal-solver, an open-source Python library for simulating one-dimensional quantum tunneling dynamics under idealized coherent conditions. The solver implements the split-operator method with second-order Trotter-Suzuki factorization, utilizing FFT-based spectral differentiation for the kinetic operator and complex absorbing potentials to eliminate boundary reflections. Numba just-in-time compilation achieves performance comparable to compiled languages while maintaining code accessibility. We validate the implementation through two canonical test cases: rectangular barriers modeling field emission through oxide layers and Gaussian barriers approximating scanning tunneling microscopy interactions. Both simulations achieve exceptional numerical fidelity with machine-precision energy conservation over femtosecond-scale propagation. Comparative analysis employing information-theoretic measures and nonparametric hypothesis tests reveals that rectangular barriers exhibit moderately higher transmission coefficients than Gaussian barriers in the over-barrier regime, though Jensen-Shannon divergence analysis indicates modest practical differences between geometries. Phase space analysis confirms complete decoherence when averaged over spatial-temporal domains. The library name reflects its scope: idealized signifies deliberate exclusion of dissipation, environmental coupling, and many-body interactions, limiting applicability to qualitative insights and pedagogical purposes rather than quantitative experimental predictions. Distributed under the MIT License, the library provides a deployable tool for teaching quantum mechanics and preliminary exploration of tunneling dynamics."}
{"id": "2512.22124", "categories": ["physics.comp-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.22124", "abs": "https://arxiv.org/abs/2512.22124", "authors": ["Shriram Srinivasan", "Kaarthik Sundar"], "title": "The Solution of Potential-Driven, Steady-State Nonlinear Network Flow Equations via Graph Partitioning", "comment": "6 pages, 2 figures", "summary": "The solution of potential-driven steady-state flow in large networks is required in various engineering applications, such as transport of natural gas or water through pipeline networks. The resultant system of nonlinear equations depends on the network topology, and its solution grows more challenging as the network size increases. We present an algorithm that utilizes a given partition of a network into tractable sizes to compute a global solution for the full nonlinear system through local solution of smaller subsystems induced by the partitions. When the partitions are induced by interconnects or transfer points corresponding to networks owned by different operators, the method ensures data is shared solely at the interconnects, leaving network operators free to solve the network flow system corresponding to their own domain in any manner of their choosing. The proposed method is shown to be connected to the Schur complement and the method's viability demonstrated on some challenging test cases."}
{"id": "2512.23636", "categories": ["eess.SY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.23636", "abs": "https://arxiv.org/abs/2512.23636", "authors": ["Alberto Bemporad"], "title": "NashOpt - A Python Library for Computing Generalized Nash Equilibria", "comment": "23 pages, 6 figures", "summary": "NashOpt is an open-source Python library for computing and designing generalized Nash equilibria (GNEs) in noncooperative games with shared constraints and real-valued decision variables. The library exploits the joint Karush-Kuhn-Tucker (KKT) conditions of all players to handle both general nonlinear GNEs and linear-quadratic games, including their variational versions. Nonlinear games are solved via nonlinear least-squares formulations, relying on JAX for automatic differentiation. Linear-quadratic GNEs are reformulated as mixed-integer linear programs, enabling efficient computation of multiple equilibria. The framework also supports inverse-game and Stackelberg game-design problems. The capabilities of NashOpt are demonstrated through several examples, including noncooperative game-theoretic control problems of linear quadratic regulation and model predictive control. The library is available at https://github.com/bemporad/nashopt"}
{"id": "2512.23636", "categories": ["eess.SY", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.23636", "abs": "https://arxiv.org/abs/2512.23636", "authors": ["Alberto Bemporad"], "title": "NashOpt - A Python Library for Computing Generalized Nash Equilibria", "comment": "23 pages, 6 figures", "summary": "NashOpt is an open-source Python library for computing and designing generalized Nash equilibria (GNEs) in noncooperative games with shared constraints and real-valued decision variables. The library exploits the joint Karush-Kuhn-Tucker (KKT) conditions of all players to handle both general nonlinear GNEs and linear-quadratic games, including their variational versions. Nonlinear games are solved via nonlinear least-squares formulations, relying on JAX for automatic differentiation. Linear-quadratic GNEs are reformulated as mixed-integer linear programs, enabling efficient computation of multiple equilibria. The framework also supports inverse-game and Stackelberg game-design problems. The capabilities of NashOpt are demonstrated through several examples, including noncooperative game-theoretic control problems of linear quadratic regulation and model predictive control. The library is available at https://github.com/bemporad/nashopt"}
{"id": "2512.22636", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22636", "abs": "https://arxiv.org/abs/2512.22636", "authors": ["Mara Vizzuso", "Gianluca Passarelli", "Giovanni Cantele", "Procolo Lucignano", "Xi Chen", "Koushik Paul"], "title": "Nonadiabatic Self-Healing of Trotter Errors in Digitized Counterdiabatic Dynamics", "comment": null, "summary": "Trotter errors in digitized quantum dynamics arise from approximating time-ordered evolution under noncommuting Hamiltonian terms with a product formula. In the adiabatic regime, such errors are known to exhibit long-time self-healing [Phys. Rev. Lett. \\textbf{131}, 060602 (2023)], where discretization effects are effectively suppressed. Here we show that self-healing persists at finite evolution times once nonadiabatic errors induced by finite-speed ramps are compensated. Using counterdiabatic driving to cancel diabatic transitions and isolate discretization effects, we study both noninteracting and interacting spin models and characterize the finite-time scaling with the Trotter steps and the total evolution time. In the instantaneous eigenbasis of the driven Hamiltonian, the leading digital error maps to an effective harmonic perturbation whose dominant Fourier component yields an analytic upper bound on the finite-time Trotter error and reveals the phase-cancellation mechanism underlying self-healing. Our results establish finite-time self-healing as a generic feature of digitized counterdiabatic protocols, clarify its mechanism beyond the long-time adiabatic limit, and provide practical guidance for high-fidelity state preparation on gate-based quantum processors."}
{"id": "2512.22126", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.22126", "abs": "https://arxiv.org/abs/2512.22126", "authors": ["Svyatoslav Covanov", "Cedric Pradalier"], "title": "Validation methodology on real data of reversible Kalman Filter for state estimation with Manifold", "comment": null, "summary": "This work extends a previous study that introduced an algorithm for state estimation on manifolds within the framework of the Kalman filter. Its objective is to address the limitations of the earlier approach. The reversible Kalman filter was designed to provide a methodology for evaluating the accuracy of existing Kalman filter variants with arbitrary precision on synthetic data. It has favorable numerical properties on synthetic data, achieving arbitrary precision without relying on the small-velocity assumption and depending only on sensor noise. However, its application to real data encountered difficulties related to measurement noise, which was mitigated using a heuristic. In particular, the heuristic involved an event detection step switching between reversible Kalman filter and classical Kalman variant at chosen moments. In the present work, we propose a study of this detection step and propose a methodology to prove at which moment the reversible Kalman approach improves on classical multiplicative variant. In particular, we propose a metric allowing one to discriminate situations in real-world scenarios where it behaves better than classical approach."}
{"id": "2512.23658", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23658", "abs": "https://arxiv.org/abs/2512.23658", "authors": ["Masoud H. Nazaria", "Hamid Varmazyari", "Antar Kumar Biswas", "Umit Cali", "Hollis Belnap", "Masood Parvania"], "title": "A Review of Community-Centric Power Systems Resilience Assessment and Enhancement Strategies", "comment": "This paper is under review at an Elsevier journal. Revisions may be made in response to peer review", "summary": "This paper presents a comprehensive review of resilience metrics, covering both engineering-based measures, such as fragility-curve modeling, and data-driven approaches, including triangular and trapezoidal representations. Next, the paper examines the interdependencies between power systems resilience and community resilience, addressing socioeconomic and behavioral dimensions, infrastructure interconnections, and the emerging role of resilience hubs. The review then synthesizes state-of-the-art strategies for enhancing power system resilience, including network hardening, resource allocation, optimal scheduling, and reconfiguration techniques. Special emphasis is placed on the integration of Artificial Intelligence (AI) methods and the techno-legal dimensions of resilient power systems and communities. In particular, the paper contrasts the regulatory landscapes of the European Union and the United States, highlighting key similarities and distinctions. By analyzing methodologies for mitigating the impacts of high-impact, low-probability (HILP) events, the review identifies critical research gaps and outlines promising directions for future investigation."}
{"id": "2512.23658", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23658", "abs": "https://arxiv.org/abs/2512.23658", "authors": ["Masoud H. Nazaria", "Hamid Varmazyari", "Antar Kumar Biswas", "Umit Cali", "Hollis Belnap", "Masood Parvania"], "title": "A Review of Community-Centric Power Systems Resilience Assessment and Enhancement Strategies", "comment": "This paper is under review at an Elsevier journal. Revisions may be made in response to peer review", "summary": "This paper presents a comprehensive review of resilience metrics, covering both engineering-based measures, such as fragility-curve modeling, and data-driven approaches, including triangular and trapezoidal representations. Next, the paper examines the interdependencies between power systems resilience and community resilience, addressing socioeconomic and behavioral dimensions, infrastructure interconnections, and the emerging role of resilience hubs. The review then synthesizes state-of-the-art strategies for enhancing power system resilience, including network hardening, resource allocation, optimal scheduling, and reconfiguration techniques. Special emphasis is placed on the integration of Artificial Intelligence (AI) methods and the techno-legal dimensions of resilient power systems and communities. In particular, the paper contrasts the regulatory landscapes of the European Union and the United States, highlighting key similarities and distinctions. By analyzing methodologies for mitigating the impacts of high-impact, low-probability (HILP) events, the review identifies critical research gaps and outlines promising directions for future investigation."}
{"id": "2512.22643", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-ex"], "pdf": "https://arxiv.org/pdf/2512.22643", "abs": "https://arxiv.org/abs/2512.22643", "authors": ["Haruki Emori", "Hiroyasu Tajima"], "title": "Measuring out-of-time-order correlators on a quantum computer based on an irreversibility-susceptibility method", "comment": "13 pages and 6 figures", "summary": "The out-of-time-ordered correlator (OTOC) is a powerful tool for probing quantum information scrambling, a fundamental process by which local information spreads irreversibly throughout a quantum many-body system. Experimentally measuring the OTOC, however, is notoriously challenging due to the need for time-reversed evolution. Here, we present an experimental evaluation of the OTOC on a quantum computer, using three distinct protocols to address this challenge: the rewinding time method (RTM), the weak-measurement method (WMM), and the irreversibility-susceptibility method (ISM). Our experiments investigate the quantum dynamics of an XXZ spin-1/2 chain prepared in a thermal Gibbs state. As a key contribution, we provide the first experimental demonstration of the ISM, using the numerical emulator of the trapped-ion quantum computer, reimei. We also conduct a detailed comparative analysis of all three methods, revealing method-dependent behaviors in the measured OTOC. This work not only validates these protocols as practical tools for exploring quantum chaos on near-term hardware but also offers crucial insights into their respective advantages and limitations, providing a practical framework for future experimental investigations."}
{"id": "2512.22863", "categories": ["quant-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.22863", "abs": "https://arxiv.org/abs/2512.22863", "authors": ["Jianting Yang"], "title": "A Counterexample to the Optimality Conjecture in Convex Quantum Channel Optimization", "comment": null, "summary": "This paper presents a counterexample to the optimality conjecture in convex quantum channel optimization proposed by Coutts et al. The conjecture posits that for nuclear norm minimization problems in quantum channel optimization, the dual certificate of an optimal solution can be uniquely determined via the spectral calculus of the Choi matrix. By constructing a counterexample in 2-dimensional Hilbert spaces, we disprove this conjecture."}
{"id": "2512.22419", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22419", "abs": "https://arxiv.org/abs/2512.22419", "authors": ["Mohannad Alkhraijah", "Devon Sigler", "Daniel K. Molzahn"], "title": "A Decomposition Method for Solving Sensitivity-Based Distributed Optimal Power Flow", "comment": null, "summary": "Efficiently solving large-scale optimal power flow (OPF) problems is challenging due to the high dimensionality and interconnectivity of modern power systems. Decomposition methods offer a promising solution via partitioning large problems into smaller subproblems that can be solved in parallel, often with local information. These approaches reduce computational burden and improve flexibility by allowing agents to manage their local models. This article introduces a decomposition method that enables a distributed solution to OPF problems. The proposed method solves OPF problems with a sensitivity-based formulation using the alternating direction method of multipliers (ADMM) algorithm. We also propose a distributed method to compute system-wide sensitivities without sharing local parameters. This approach facilitates scalable optimization while satisfying global constraints and limiting data sharing. We demonstrate the effectiveness of the proposed approach using a large set of test systems and compare its performance against existing decomposition methods. The results show that the proposed method significantly outperforms the typical phase-angle formulation with a 14-times faster computation speed on average."}
{"id": "2512.22419", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.22419", "abs": "https://arxiv.org/abs/2512.22419", "authors": ["Mohannad Alkhraijah", "Devon Sigler", "Daniel K. Molzahn"], "title": "A Decomposition Method for Solving Sensitivity-Based Distributed Optimal Power Flow", "comment": null, "summary": "Efficiently solving large-scale optimal power flow (OPF) problems is challenging due to the high dimensionality and interconnectivity of modern power systems. Decomposition methods offer a promising solution via partitioning large problems into smaller subproblems that can be solved in parallel, often with local information. These approaches reduce computational burden and improve flexibility by allowing agents to manage their local models. This article introduces a decomposition method that enables a distributed solution to OPF problems. The proposed method solves OPF problems with a sensitivity-based formulation using the alternating direction method of multipliers (ADMM) algorithm. We also propose a distributed method to compute system-wide sensitivities without sharing local parameters. This approach facilitates scalable optimization while satisfying global constraints and limiting data sharing. We demonstrate the effectiveness of the proposed approach using a large set of test systems and compare its performance against existing decomposition methods. The results show that the proposed method significantly outperforms the typical phase-angle formulation with a 14-times faster computation speed on average."}
{"id": "2512.22665", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22665", "abs": "https://arxiv.org/abs/2512.22665", "authors": ["Arnaud Rémi", "François Damanet", "Christophe Geuzaine"], "title": "Variational quantum algorithm for solving Helmholtz problems with high order finite elements", "comment": "7 pages, 4 figures", "summary": "Discretizing Helmholtz problems via finite elements yields linear systems whose efficient solution remains a major challenge for classical computation. In this paper, we investigate how variational quantum algorithms could address this challenge. We first show that, for regular meshes, a block encoding of the operators $A$ and $A^\\dagger A$ arising from the high-order finite element discretisation of Helmholtz problems can be designed, resulting in a quantum circuit of depth $\\mathcal{O}(p^3\\mathrm{poly}\\log(Np))$ with $N$ the number of elements and $p$ the order of the finite elements. Then we apply our algorithm to a one-dimensional Helmholtz problem with Dirichlet and Neumann boundary conditions for various wavenumbers."}
{"id": "2512.22998", "categories": ["quant-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.22998", "abs": "https://arxiv.org/abs/2512.22998", "authors": ["Dionisis Stefanatos", "Ioannis Thanopulos", "Emmanuel Paspalakis"], "title": "Fast chiral resolution with optimal control", "comment": null, "summary": "In this work, we formulate the problem of achieving in minimum-time perfect chiral resolution with bounded control fields, as an optimal control problem on two non-interacting spins-$1/2$. We assume the same control bound for the two Raman fields (pump and Stokes) and a different bound for the field connecting directly the two lower-energy states. Using control theory, we show that the optimal fields can only take the boundary values or be zero, the latter corresponding to singular control. Subsequently, using numerical optimal control and intuitive arguments, we identify some three-stage symmetric optimal pulse-sequences, for relatively larger values of the ratio between the two control bounds, and analytically calculate the corresponding pulse timings as functions of this ratio. For smaller values of the bounds ratio, numerical optimal control indicates that the optimal pulse-sequence loses its symmetry and the number of stages increases in general. In all cases, the analytical or numerical optimal protocol achieves a faster perfect chiral resolution than other pulsed protocols, mainly because of the simultaneous action of the control fields. The present work is expected to be useful in the wide spectrum of applications across the natural sciences where enantiomer separation is a crucial task."}
{"id": "2512.22739", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22739", "abs": "https://arxiv.org/abs/2512.22739", "authors": ["Ella P. Walsh", "Sepehr Ahmadi", "Alexander J. Healey", "David A. Simpson", "Liam T. Hall"], "title": "A method for robust spin relaxometry in the presence of imperfect state preparation", "comment": "13 pages, 3 figures in manuscript, 7 supplementary figures in appendix, submitted to PR Applied on 19 December 2025", "summary": "Spin relaxometry based on quantum spin systems has developed as a valuable tool in medical and condensed matter systems, offering the advantage of operating without the need for external DC or RF fields. Spin relaxometry with nitrogen-vacancy (NV) centers has been applied to paramagnetic sensing using both single crystal diamond and nanodiamond materials. However, these methods often suffer from artifacts and systematic uncertainties, particularly due to imperfect spin state preparation, leading to artificially fast T$_1$ relaxation times. Current analysis techniques fail to adequately account for these issues, limiting the precision of parameter estimation. In this work, we introduce a minimal fitting procedure that enables more robust parameter estimation in the presence of imperfect spin polarization. Our model improves upon existing approaches by offering more accurate fits and provides a framework for efficiently parallelizing single-spin dynamics studies."}
{"id": "2512.23284", "categories": ["eess.SY", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.23284", "abs": "https://arxiv.org/abs/2512.23284", "authors": ["Mahdi Kchaou", "Francesco Contino", "Diederik Coppitters"], "title": "Revealing design archetypes and flexibility in e-molecule import pathways using Modeling to Generate Alternatives and interpretable machine learning", "comment": null, "summary": "Given the central role of green e-molecule imports in the European energy transition, many studies optimize import pathways and identify a single cost-optimal solution. However, cost optimality is fragile, as real-world implementation depends on regulatory, spatial, and stakeholder constraints that are difficult to represent in optimization models and can render cost-optimal designs infeasible. To address this limitation, we generate a diverse set of near-cost-optimal alternatives within an acceptable cost margin using Modeling to Generate Alternatives, accounting for unmodeled uncertainties. Interpretable machine learning is then applied to extract insights from the resulting solution space. The approach is applied to hydrogen import pathways considering hydrogen, ammonia, methane, and methanol as carriers. Results reveal a broad near-optimal space with great flexibility: solar, wind, and storage are not strictly required to remain within 10% of the cost optimum. Wind constraints favor solar-storage methanol pathways, while limited storage favors wind-based ammonia or methane pathways."}
{"id": "2512.22767", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22767", "abs": "https://arxiv.org/abs/2512.22767", "authors": ["Daniel C. Cole", "Vikas Buchemmavari", "Mark Saffman"], "title": "An asymmetric and fast Rydberg gate protocol for long range entanglement", "comment": "6 figures", "summary": "We analyze a new Rydberg gate design based on the original $π-2π-π$ protocol [Jaksch, et. al. Phys. Rev. Lett. {\\bf 85}, 2208 (2000)] that is modified to enable high fidelity operation without requiring a strong Rydberg interaction. The gate retains the $π-2π-π$ structure with an additional detuning added to the $2π$ pulse on the target qubit. The protocol reaches within a factor of 2.39 (1.68) of the fundamental fidelity limit set by Rydberg lifetime for equal (asymmetric) Rabi frequencies on the control and target qubits. We generalize the gate protocol to arbitrary controlled phases. We design optimal target-qubit phase waveforms to generalize the gate across a range of interaction strengths and we find that, within this family of gates, the constant-phase protocol is time-optimal for a fixed laser Rabi frequency and tunable interaction strength. Robust control methods are used to design gates that are robust against variations in Rydberg Rabi frequency or interaction strength."}
{"id": "2512.22782", "categories": ["quant-ph", "hep-lat"], "pdf": "https://arxiv.org/pdf/2512.22782", "abs": "https://arxiv.org/abs/2512.22782", "authors": ["Henry Froland", "Dorota M. Grabowska", "Zhiyao Li"], "title": "Simulating Fully Gauge-Fixed SU(2) Hamiltonian Dynamics on Digital Quantum Computers", "comment": "27 pages, 7 figures, 4 tables", "summary": "Quantum simulations of many-body systems offer novel methods for probing the dynamics of the Standard Model and its constituent gauge theories. Extracting low-energy predictions from such simulations rely on formulating systematically-improvable representations of lattice gauge theory Hamiltonians that are efficient at all values of the gauge coupling. One such candidate representation for SU(2) is the fully gauge-fixed Hamiltonian defined in the mixed basis. This work focuses on the quantum simulation of the smallest non-trivial system: two plaquettes with open boundary conditions. A mapping of the continuous gauge field degrees of freedom to qubit-based representations is developed. It is found that as few as three qubits per plaquette is sufficient to reach per-mille level precision on predictions for observables. Two distinct algorithms for implementing time evolution in the mixed basis are developed and analyzed in terms of quantum resource estimates. One algorithm has favorable scaling in circuit depth for large numbers of qubits, while the other is more practical when qubit count is limited. The latter algorithm is used in the measurement of a real-time observable on IBM's Heron superconducting quantum processor, ibm_fez. The quantum results match classical predictions at the percent-level. This work lays out a path forward for two- and three-dimensional simulations of larger systems, as well as demonstrating the viability of mixed-basis formulations for studying the properties of SU(2) gauge theories at all values of the gauge coupling."}
{"id": "2512.22856", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22856", "abs": "https://arxiv.org/abs/2512.22856", "authors": ["Matthaus Zering", "Jolyon Joyce", "Tal Gurfinkel", "Jingbo Wang"], "title": "Benchmarking Lie-Algebraic Pretraining and Non-Variational QWOA for the MaxCut Problem", "comment": null, "summary": "The Quantum Approximate Optimization Algorithm (QAOA) is a leading candidate for achieving quantum advantage in combinatorial optimization on Near-Term Intermediate-Scale Quantum (NISQ) devices. However, random initialization of the variational parameters typically leads to vanishing gradients, rendering standard variational optimization ineffective. This paper provides a comparative performance analysis of two distinct strategies designed to improve trainability: Lie algebraic pretraining framework that uses Lie-algebraic classical simulation to find near-optimal initializations, and non-variational QWOA (NV-QWOA) that targets a restrict parameter subspace covered by 3 hyperparameters. We benchmark both methods on the unweighted Maxcut problem using a circuit depth of $p = 256$ across 200 Erdős-Rényi and 200 3-regular graphs, each with 16 vertices. Both approaches significantly improve upon the standard randomly initialized QWOA. NV-QWOA attains a mean approximation ratio of 98.9\\% in just 60 iterations, while the Lie-algebraic pretrained QWOA improves to 77.71\\% after 500 iterations. That optimization proceeds more quickly for NV-QWOA is not surprising given its significantly smaller parameter space, however, that an algorithm with so few tunable parameters reliably finds near-optimal solutions is remarkable. These findings suggest that the structured parameterization of NV-QWOA offers a more robust training approach than pretraining on lower-dimensional auxiliary problems. Future work is needed to confirm scaling to larger problem sizes and to asses generalization to other problem classes."}
{"id": "2512.22863", "categories": ["quant-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.22863", "abs": "https://arxiv.org/abs/2512.22863", "authors": ["Jianting Yang"], "title": "A Counterexample to the Optimality Conjecture in Convex Quantum Channel Optimization", "comment": null, "summary": "This paper presents a counterexample to the optimality conjecture in convex quantum channel optimization proposed by Coutts et al. The conjecture posits that for nuclear norm minimization problems in quantum channel optimization, the dual certificate of an optimal solution can be uniquely determined via the spectral calculus of the Choi matrix. By constructing a counterexample in 2-dimensional Hilbert spaces, we disprove this conjecture."}
{"id": "2512.22869", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22869", "abs": "https://arxiv.org/abs/2512.22869", "authors": ["Roey Shafran", "Ron Ziv", "Mordechai Segev"], "title": "Any DOF All at Once: Single Photon State Tomography in a Single Measurement Setup", "comment": "25 pages, 5 figures, submitted to Optica Quantum", "summary": "Photonic quantum technologies utilize various degrees of freedom (DOFs) of light, such as polarization, frequency, and spatial modes, to encode quantum information. In the effort of further improving channel capacity and increasing the complexity of available quantum operations, high-dimensional and hyperentangled states are now gaining interest. Efficiently measuring these high dimensional states is challenging due to the large number of measurements required for reconstructing the full density matrix via quantum state tomography (QST), and the fact that each measurement requires some modification in the experimental setup. Here, we propose a framework for reconstructing the density matrix of a single-photon hyperentangled across multiple DOFs using a single intensity-measurement obtainable from traditional cameras, and discuss extensions for multiphoton hyperentangled states. Our method hinges on the spatial DOF of the photon and uses it to encode information from other DOFs. We numerically demonstrate this method for single-photon OAM-spin and OAM-frequency entangled states using an ideal coupler and a multimode fiber, to perform the spatial information mixing and encoding. This technique simplifies the experimental setup and reduces acquisition time compared to traditional QST based methods. Moreover, it allows recovery of DOFs that conventional cameras cannot detect, such as polarization, thus eliminating the need for projection measurements."}
{"id": "2512.22879", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22879", "abs": "https://arxiv.org/abs/2512.22879", "authors": ["Alexei Grinbaum"], "title": "Agency under indefinite causality: operational eternalism in higher-order quantum theory", "comment": "25 pages, 2 original figures and 7 figures to review previous research", "summary": "After two decades of research on indefinite causality, a philosophical lesson emerges: the tension between operational quantum theory and dynamical spacetime physics is unbridgeable if one believes both types of theories to be fundamental. We interpret this tension through operational eternalism, a stance analogous to the block-universe view but applied to information rather than geometry. Inputs and outputs are primary givens, while agents are secondary constructs arising from specific groupings of data. Agency is perspectival: from Alice's perspective Bob may not qualify as an observer, and vice versa. These results redefine the observer in the operational approach as a tool to avoid non-causality. They also provide a criterion for Wigner's friends as a class of causally compatible agents."}
{"id": "2512.22888", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.22888", "abs": "https://arxiv.org/abs/2512.22888", "authors": ["Giovanni Canossa", "Lode Pollet", "Miguel A. Martin-Delgado", "Hao Song", "Ke Liu"], "title": "Optimal Threshold for Fracton Codes and Nearly Saturated Code Capacity in Three Dimensions", "comment": "12 pages, 5 figures, 2 tables", "summary": "Fracton codes have been intensively studied as novel topological states of matter, yet their fault-tolerant properties remain largely unexplored. Here, we investigate the optimal thresholds of self-dual fracton codes, in particular the checkerboard code, against stochastic Pauli noise. By utilizing a statistical-mechanical mapping combined with large-scale parallel tempering Monte Carlo simulations, we calculate the optimal code capacity of the checkerboard code to be $p_{th} \\simeq 0.108(2)$. This value is the highest among known three-dimensional codes and nearly saturates the theoretical limit for topological codes. Our results further validate the generalized entropy relation for two mutually dual models, $H(p_{th}) + H(\\tilde{p}_{th}) \\approx 1$, and extend its applicability beyond standard topological codes. This verification indicates the Haah's code also possesses a code capacity near the theoretical limit $p_{th} \\approx 0.11$. These findings highlight fracton codes as highly resilient quantum memory and demonstrate the utility of duality techniques in analyzing intricate quantum error-correcting codes."}
{"id": "2512.22908", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22908", "abs": "https://arxiv.org/abs/2512.22908", "authors": ["Debkanta Ghosh", "Tanoy Kanti Konar", "Amit Kumar Pal", "Aditi Sen De"], "title": "Quantum batteries with K-regular graph generators: A no-go for quantum advantage", "comment": "11 pages, 6 figures", "summary": "Regular graphs find broad applications ranging from quantum communication to quantum computation. Motivated by this, we investigate the design of a quantum battery based on a K-regular graph, where K denotes the number of edges incident on each vertex. We prove that a 0-regular graph battery exhibits extractable work that scales linearly with the system-size when charged using a K-regular graph. This linear scaling is shown to persist even when the charging is implemented via a collective K-regular charger with power-law decaying interactions. While no superlinear scaling is observed, the work output is found to improve systematically with increasing regularity K. Furthermore, by introducing the notion of the fraction of extractable work when only subsystems are accessible, we identify this fraction to be independent of system-size if the battery is prepared in the down-polarized product state. This independence breaks down when the battery is oriented along the x- and y-directions of the Bloch sphere."}
{"id": "2512.22912", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.22912", "abs": "https://arxiv.org/abs/2512.22912", "authors": ["Xuanchao Zhang", "Yang-Cheng Ye", "Panpan Zhang", "Xiangmei Duan", "R. J. Dwayne Miller", "Fulu Zheng", "Ajay Jha", "Hong-Guang Duan"], "title": "Controlling Nonadiabatic Transitions Through Engineered Ultrafast Laser Fields at Conical Intersections", "comment": null, "summary": "In this paper, we investigate coherent control of nonadiabatic dynamics at a conical intersection (CI) using engineered ultrafast laser pulses. Within a model vibronic system, we tailor pulse chirp and temporal profile and compute the resulting wave-packet population and coherence dynamics using projections along the reaction coordinate. This approach allows us to resolve the detailed evolution of wave-packets as they traverse the degeneracy region with strong nonadiabatic coupling. By systematically varying pulse parameters, we demonstrate that both chirp and pulse duration modulate vibrational coherence and alter branching between competing pathways, leading to controlled changes in quantum yield. Our results elucidate the dynamical mechanisms underlying pulse-shaped control near conical intersections and establish a general framework for manipulating ultrafast nonadiabatic processes."}
{"id": "2512.22932", "categories": ["quant-ph", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.22932", "abs": "https://arxiv.org/abs/2512.22932", "authors": ["Masanori Hanada", "Shunji Matsuura", "Andreas Schafer", "Jinzhao Sun"], "title": "Gauge Symmetry in Quantum Simulation", "comment": "Supplementary material is available in the source files of this submission", "summary": "Quantum simulation of non-Abelian gauge theories requires careful handling of gauge redundancy. We address this challenge by presenting universal principles for treating gauge symmetry that apply to any quantum simulation approach, clarifying that physical states need not be represented solely by gauge singlets. Both singlet and non-singlet representations are valid, with distinct practical trade-offs, which we elucidate using analogies to BRST quantization. We demonstrate these principles within a complete quantum simulation framework based on the orbifold lattice, which enables explicit and efficient circuit constructions relevant to real-world QCD. For singlet-based approaches, we introduce a Haar-averaging projection implemented via linear combinations of unitaries, and analyze its cost and truncation errors. Beyond the singlet-approach, we show how non-singlet approaches can yield gauge-invariant observables through wave packets and string excitations. This non-singlet approach is proven to be both universal and efficient. Working in temporal gauge, we provide explicit mappings of lattice Yang-Mills dynamics to Pauli-string Hamiltonians suitable for Trotterization. Classical simulations of small systems validate convergence criteria and quantify truncation and Trotter errors, showing concrete resource estimates and scalable circuit recipes for SU($N$) gauge theories. Our framework provides both conceptual clarity and practical tools toward quantum advantage in simulating non-Abelian gauge theories."}
{"id": "2512.22937", "categories": ["quant-ph", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.22937", "abs": "https://arxiv.org/abs/2512.22937", "authors": ["Amar Abane", "Junxiao Shi", "Van Sy Mai", "Abderrahim Amlou", "Abdella Battou"], "title": "Multiverse: A Simulator for Evaluating Entanglement Routing in Quantum Networks", "comment": null, "summary": "We present MQNS, a discrete-event simulator for rapid evaluation of entanglement routing under dynamic, heterogeneous configurations. MQNS supports runtime-configurable purification, swapping, memory management, and routing, within a unified qubit lifecycle and integrated link-architecture models. A modular, minimal design keeps MQNS architecture-agnostic, enabling fair, reproducible comparisons across paradigms and facilitating future emulation."}
{"id": "2512.22942", "categories": ["quant-ph", "cond-mat.stat-mech", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.22942", "abs": "https://arxiv.org/abs/2512.22942", "authors": ["Anwesha Chakraborty", "Lucas Hackl", "Mario Kieburg"], "title": "Random matrix prediction of average entanglement entropy in non-Abelian symmetry sectors", "comment": "22 pages, 4 figures, 2 tables", "summary": "We study the average bipartite entanglement entropy of Haar-random pure states in quantum many-body systems with global $\\mathrm{SU}(2)$ symmetry, constrained to fixed total spin $J$ and magnetization $J_z = 0$. Focusing on spin-$\\tfrac12$ lattices and subsystem fractions $f < \\frac{1}{2}$, we derive a asymptotic expression for the average entanglement entropy up to constant order in the system volume $V$. In addition to the expected leading volume law term, we prove the existence of a $\\frac{1}{2}\\log V$ finite-size correction resulting from the scaling of the Clebsch-Gordon coefficients and compute explicitly the $O(1)$ contribution reflecting angular-momentum coupling within magnetization blocks. Our analysis uses features of random matrix ensembles and provides a fully analytical treatment for arbitrary spin densities, thereby extending Page type results to non-Abelian sectors and clarifying how $\\mathrm{SU}(2)$ symmetry shapes average entanglement."}
{"id": "2512.22959", "categories": ["quant-ph", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.22959", "abs": "https://arxiv.org/abs/2512.22959", "authors": ["Ziyuan Dong", "Xiang Fan", "Tengxun Zhong", "Daowen Qiu"], "title": "Revisiting finite Abelian hidden subgroup problem and its distributed exact quantum algorithm", "comment": null, "summary": "We revisit the finite Abelian hidden subgroup problem (AHSP) from a mathematical perspective and make the following contributions. First, by employing amplitude amplification, we present an exact quantum algorithm for the finite AHSP, our algorithm is more concise than the previous exact algorithm and applies to any finite Abelian group. Second, utilizing the Chinese Remainder Theorem, we propose a distributed exact quantum algorithm for finite AHSP, which requires fewer qudits, lower quantum query complexity, and no quantum communication. We further show that our distributed approach can be extended to certain classes of non-Abelian groups. Finally, we develop a parallel exact classical algorithm for finite AHSP with reduced query complexity; even without parallel execution, the total number of queries across all nodes does not exceed that of the original centralized algorithm under mild conditions."}
{"id": "2512.22965", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2512.22965", "abs": "https://arxiv.org/abs/2512.22965", "authors": ["Philippe Grangier"], "title": "Comment on \"There is No Quantum World\" by Jeffrey Bub", "comment": "5 pages, no figures. Comment on arXiv:2512.18400", "summary": "In a recent preprint [1] Jeffrey Bub presents a discussion of neo-Bohrian interpretations of quantum mechanics, and also of von Neumann's work on infinite tensor products [2]. He rightfully writes that this work provides a theoretical framework that deflates the measurement problem and justifies Bohr's insistence on the primacy of classical concepts. But then he rejects these ideas, on the basis that the infinity limit is \"never reached for any real system composed of a finite number of elementary systems\". In this note we present opposite views on two major points: first, admitting mathematical infinities in a physical theory is not a problem, if properly done; second, the critics of [3,4,5] comes with a major misunderstanding of these papers: they don't ask about \"the significance of the transition from classical to quantum mechanics\", but they start from a physical ontology where classical and quantum physics need each other from the beginning. This is because they postulate that a microscopic physical object (or degree of freedom) always appears as a quantum system, within a classical context. Here we argue why this (neo-Bohrian) position makes sense."}
{"id": "2512.22998", "categories": ["quant-ph", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.22998", "abs": "https://arxiv.org/abs/2512.22998", "authors": ["Dionisis Stefanatos", "Ioannis Thanopulos", "Emmanuel Paspalakis"], "title": "Fast chiral resolution with optimal control", "comment": null, "summary": "In this work, we formulate the problem of achieving in minimum-time perfect chiral resolution with bounded control fields, as an optimal control problem on two non-interacting spins-$1/2$. We assume the same control bound for the two Raman fields (pump and Stokes) and a different bound for the field connecting directly the two lower-energy states. Using control theory, we show that the optimal fields can only take the boundary values or be zero, the latter corresponding to singular control. Subsequently, using numerical optimal control and intuitive arguments, we identify some three-stage symmetric optimal pulse-sequences, for relatively larger values of the ratio between the two control bounds, and analytically calculate the corresponding pulse timings as functions of this ratio. For smaller values of the bounds ratio, numerical optimal control indicates that the optimal pulse-sequence loses its symmetry and the number of stages increases in general. In all cases, the analytical or numerical optimal protocol achieves a faster perfect chiral resolution than other pulsed protocols, mainly because of the simultaneous action of the control fields. The present work is expected to be useful in the wide spectrum of applications across the natural sciences where enantiomer separation is a crucial task."}
{"id": "2512.23005", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.23005", "abs": "https://arxiv.org/abs/2512.23005", "authors": ["Rafaĺ Bistroń", "Márton Mestyán", "Balázs Pozsgay", "Karol Życzkowski"], "title": "Graph restricted tensors: building blocks for holographic networks", "comment": "15 pages", "summary": "We analyze few-body quantum states with particular correlation properties imposed by the requirement of maximal bipartite entanglement for selected partitions of the system into two complementary parts. A novel framework to treat this problem by encoding these constraints in a graph is advocated; the resulting objects are called ``graph-restricted tensors''. This framework encompasses several examples previously treated in the literature, such as 1-uniform multipartite states, quantum states related to dual unitary operators and absolutely maximally entangled states (AME) corresponding to 2-unitary matrices. Original examples of presented graph-restricted tensors are motivated by tensor network models for the holographic principle. In concrete cases we find exact analytic solutions, demonstrating thereby that there exists a vast landscape of non-stabilizer tensors useful for the lattice models of holography."}
{"id": "2512.23009", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23009", "abs": "https://arxiv.org/abs/2512.23009", "authors": ["Rudraksh Sharma"], "title": "Symmetry-Preserving Variational Quantum Simulation of the Heisenberg Spin Chain on Noisy Quantum Hardware", "comment": null, "summary": "Variational quantum algorithms are among the most promising approaches for simulating interacting quantum many-body systems on noisy intermediate-scale quantum (NISQ) devices. However, the practical success of variational quantum eigensolvers (VQE) critically depends on the structure of the chosen variational ansatz. In this work, we investigate the ground-state properties of the one-dimensional antiferromagnetic Heisenberg spin-1/2 chain using both generic hardware-efficient ansatz and physics-informed, symmetry-preserving variational circuits. We benchmark variational results against exact diagonalization and noiseless simulations, and subsequently validate the approach on real IQM Garnet quantum hardware. Our results demonstrate that incorporating physical symmetries into the circuit design leads to significantly improved energy estimates, enhanced robustness against hardware noise, and clearer convergence behavior when compared to hardware-efficient ansatz under identical resource constraints. These findings highlight the importance of problem specific ansatz construction for reliable quantum simulations in the NISQ era."}
{"id": "2512.23013", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23013", "abs": "https://arxiv.org/abs/2512.23013", "authors": ["Simone Cepollaro", "Gianluca Cuffaro", "Matthew B. Weiss", "Stefano Cusumano", "Alioscia Hamma", "Seth Lloyd"], "title": "Stabilizer Entropy of Subspaces", "comment": "40 pages, 15 figures", "summary": "We consider the costs and benefits of embedding the states of one quantum system within those of another. Such embeddings are ubiquitous, e.g., in error correcting codes and in symmetry-constrained systems. In particular we investigate the impact of embeddings in terms of the resource theory of nonstabilizerness (also known as magic) quantified via the stabilizer entropy (SE). We analytically and numerically study the stabilizer entropy gap or magic gap: the average gap between the SE of a quantum state realized within a subspace of a larger system and the SE of the quantum state considered on its own. We find that while the stabilizer entropy gap is typically positive, requiring the injection of magic, both zero and negative magic gaps are achievable. This suggests that certain choices of embedding subspace provide strong resource advantages over others. We provide formulas for the average nonstabilizerness of a subspace given its corresponding projector and sufficient conditions for realizing zero or negative gaps: in particular, certain classes of stabilizer codes provide paradigmatic examples of the latter. Through numerical optimization, we find subspaces which achieve both minimal and maximal average SE for a variety of dimensions, and compute the magic gap for specific error-correcting codes and symmetry-induced subspaces. Our results suggest that a judicious choice of embedding can lead to greater efficiency in both classical and quantum simulations."}
{"id": "2512.23026", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23026", "abs": "https://arxiv.org/abs/2512.23026", "authors": ["Evgeniy O. Kiktenko", "Elizaveta V. Krendeleva", "Aleksey K. Fedorov"], "title": "Applying Grover-mixer Quantum Alternating Ansatz Algorithm to Higher-order Quadratic Unconstrained Optimization Problems", "comment": "13 pages, 6 figures", "summary": "The Quantum Approximate Optimization Algorithm (QAOA) is among leading candidates for achieving quantum advantage on near-term processors. While typically implemented with a transverse-field mixer (XM-QAOA), the Grover-mixer variant (GM-QAOA) offers a compelling alternative due to its global search capabilities. This work investigates the application of GM-QAOA to Higher-Order Unconstrained Binary Optimization (HUBO) problems, also known as Polynomial Unconstrained Binary Optimization (PUBO), which constitute a generalized class of combinatorial optimization tasks characterized by intrinsically multi-variable interactions. We present a comprehensive numerical study demonstrating that GM-QAOA, unlike XM-QAOA, exhibits monotonic performance improvement with circuit depth and achieves superior results for HUBO problems. An important component of our approach is an analytical framework for modeling GM-QAOA dynamics, which enables a classical approximation of the optimal parameters and helps reduce the optimization overhead. Our resource-efficient parameterized GM-QAOA nearly matches the performance of the fully optimized algorithm while being far less demanding, establishing it as a highly effective approach for complex optimization tasks. These findings highlight GM-QAOA's potential and provide a practical pathway for its implementation on current quantum hardware."}
{"id": "2512.23037", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23037", "abs": "https://arxiv.org/abs/2512.23037", "authors": ["Riling Li", "Keli Zheng", "Yiming Zhang", "Huazhe Lou", "Shenggang Ying", "Ke Liu", "Xiaoming Sun"], "title": "SOFT: a high-performance simulator for universal fault-tolerant quantum circuits", "comment": null, "summary": "Circuit simulation tools are critical for developing and assessing quantum-error-correcting and fault-tolerant strategies. In this work, we present SOFT, a high-performance SimulatOr for universal Fault-Tolerant quantum circuits. Integrating the generalized stabilizer formalism and highly optimized GPU parallelization, SOFT enables the simulation of noisy quantum circuits containing non-Clifford gates at a scale not accessible with existing tools. To provide a concrete demonstration, we simulate the state-of-the-art magic state cultivation (MSC) protocol at code distance $d=5$, involving 42 qubits, 72 $T$ / $T^\\dagger$ gates, and mid-circuit measurements. Using only modest GPU resources, SOFT performs over 200 billion shots and achieves the first ground-truth simulation of the cultivation protocol at a non-trivial scale. This endeavor not only certifies the MSC's effectiveness for generating high-fidelity logical $T$-states, but also reveals a large discrepancy between the actual logical error rate and the previously reported values. Our work demonstrates the importance of reliable simulation tools for fault-tolerant architecture design, advancing the field from simulating quantum memory to simulating a universal quantum computer."}
{"id": "2512.23050", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23050", "abs": "https://arxiv.org/abs/2512.23050", "authors": ["Gianluca Cuffaro", "Matthew B. Weiss"], "title": "Clifford entropy", "comment": "20 pages, 2 figures", "summary": "We introduce the Clifford entropy, a measure of how close an arbitrary unitary is to a Clifford unitary, which generalizes the stabilizer entropy for states. We show that this quantity vanishes if and only if a unitary is Clifford, is invariant under composition with Clifford unitaries, and is subadditive under tensor products. Rewriting the Clifford entropy in terms of the stabilizer entropy of the corresponding Choi state allows us to derive an upper bound: that this bound is not tight follows from considering the properties of symmetric informationally complete sets. Nevertheless we are able to numerically estimate the maximum in low dimensions, comparing it to the average over all unitaries, which we derive analytically. Finally, harnessing a concentration of measure result, we show that as the dimension grows large, with probability approaching unity, the ratio between the Clifford entropy of a Haar random unitary and that of a fixed magic gate gives a lower bound on the depth of a doped Clifford circuit which realizes the former in terms of the latter. In fact, numerical evidence suggests that this result holds reliably even in low dimensions. We conclude with several directions for future research."}
{"id": "2512.23111", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23111", "abs": "https://arxiv.org/abs/2512.23111", "authors": ["Chuen Hei Chan", "Charu Jain", "Ezra Kissel", "Wenji Wu", "Edwin Barnes", "Sophia E. Economou", "Inder Monga"], "title": "Theoretical Analysis and Simulations of Memory-based and All-photonic Quantum Repeaters and Networks", "comment": "24+12 pages, 28 figures", "summary": "Developing and deploying advanced Quantum Repeater (QR) technologies will be necessary to scale quantum networks to longer distances. Depending on the error mitigation mechanisms adopted to suppress loss and errors, QRs are typically classified into memory-based or all-photonic QRs; and each type of QR may be best suited for a specific type of underlying quantum technology, a particular scale of quantum networks, or a specific regime of operational parameters. We perform theoretical analysis and simulations of quantum repeaters and networks to investigate the relative performance and resource requirements of different quantum network paradigms. Our results will help guide the optimization of quantum hardware and components and shed light on the role of a robust control plane. We present our research findings on theoretical analysis and simulations of memory-based first-generation trapped-ion quantum repeaters and networks, and all-photonic entanglement-based quantum repeaters and networks. We study the relative performance in terms of entanglement generation rate and fidelity, as well as the resource requirements of these two different quantum network paradigms."}
{"id": "2512.23119", "categories": ["quant-ph", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2512.23119", "abs": "https://arxiv.org/abs/2512.23119", "authors": ["Achintya Paradkar", "Paul Nicaise", "Karim Dakroury", "Fabian Resare", "Christian Dejaco", "Lukas Deeg", "Gerhard Kirchmair", "Witlef Wieczorek"], "title": "Efficient flip-chip and on-chip-based modulation of flux-tunable superconducting resonators", "comment": "7+20 pages, 5+8 figures", "summary": "We demonstrate the efficient modulation of flux-tunable superconducting resonators (FTRs) using flip-chip or on-chip-based input coils. The FTRs we use are aluminum-based quarter-wave coplanar waveguide resonators terminated with 100um or 200um-wide square loop dc superconducting quantum interference devices (SQUIDs) employing 1um-sized Josephson junctions. We employ SQUIDs with a geometric loop inductance of up to 0.7nH to increase the flux transfer efficiency. The geometric inductance of the SQUID results in a non-zero screening parameter $β_L$, whose branch switching effect is mitigated by using asymmetric junctions. We achieve flux modulation of the FTRs by more than one GHz and flux responsivities of up to tens of GHz/$Φ_0$ with uA-scale on-chip currents. We compare flip-chip with on-chip input-coil-based flux modulation, where the former is realized through galvanically connected and closely spaced chips, while the latter is achieved through superconducting air-bridge connections. We achieve a flux-transfer efficiency from the input coil to the SQUID loop of up to 20%. Our work paves the way for efficient low current flux modulation of FTRs and sensitive measurement of flux signals."}
{"id": "2512.23156", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2512.23156", "abs": "https://arxiv.org/abs/2512.23156", "authors": ["Ivan Gonoskov", "Christian Hünecke", "Stefanie Gräfe"], "title": "Emergence of nonclassical radiation in strongly laser-driven quantum systems", "comment": null, "summary": "Nonclassical light sources are central to emerging quantum technologies, yet current platforms offer limited tunability and typically operate at low photon numbers. In parallel, strong-field physics provides widely tunable, bright coherent radiation through high-order harmonic generation (HHG), but its quantum optical character has remained largely unexplained. While recent experiments have revealed signatures of entanglement, squeezing, and quantum-state modification in both the driving and generated fields, a unified theoretical framework capable of identifying the origin and controllability of these effects has been missing. Here we introduce a fully quantum, analytically tractable theory of intense light-matter interaction that rigorously captures the emergence of nonclassicality in HHG. Our approach employs a parametric factorization of the coupled electron-field system into a driven electronic state and a dynamically perturbed quantum optical field, derived directly from the time-dependent Schrödinger equation without requiring conditioning, homodyne detection, or mode-selection techniques. We show how quantum correlations, squeezing, and Wigner-function negativity arise intrinsically from the interaction dynamics, and we identify the precise conditions under which specific nonclassical features are amplified or suppressed. The theory enables predictive design of bright, high-photon-number quantum states at tunable frequencies, and we demonstrate its utility by outlining realistic conditions for generating bright nonclassical ultraviolet light. Our results establish a comprehensive foundation for strong-field quantum optics and open new avenues toward tabletop quantum light sources for sensing, communication, and photonic quantum information processing."}
{"id": "2512.23168", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23168", "abs": "https://arxiv.org/abs/2512.23168", "authors": ["Xingjian He", "Aoqian Shi", "Jianjun Liu", "Jiangbin Gong"], "title": "Quantum Metrology via Adiabatic Control of Topological Edge States", "comment": "14 pages, 4 figures. Comments are welcome!", "summary": "Criticality-based quantum sensing exploits hypersensitive response to system parameters near phase transition points. This work uncovers two metrological advantages offered by topological phase transitions when the probe is prepared as topological edge states. Firstly, the order of topological band touching is found to determine how the metrology sensitivity scales with the system size. Engineering a topological phase transition with higher-order band touching is hence advocated, with the associated quantum Fisher information scaling as $ \\mathcal{F}_Q \\sim L^{2p}$, with $L$ the lattice size in one dimension, and $p$ the order of band touching. Secondly, with a topological lattice accommodating degenerate edge modes (such as multiple zero modes), preparing an $N$-particle entangled state at the edge and then adiabatically tuning the system to the phase transition point grows quantum entanglement to macroscopic sizes, yielding $\\mathcal{F}_Q \\sim N^2 L^{2p}$. This work hence paves a possible topological phase transition-based route to harness entanglement, large lattice size, and high-order band touching for quantum metrology."}
{"id": "2512.23183", "categories": ["quant-ph", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.23183", "abs": "https://arxiv.org/abs/2512.23183", "authors": ["Shiwen An", "Jiayi Wang", "Konstantinos Slavakis"], "title": "LogosQ: A High-Performance and Type-Safe Quantum Computing Library in Rust", "comment": "https://github.com/zazabap/LogosQ https://github.com/zazabap/LogosQBenchmarks https://crates.io/crates/logosq https://logosqbook.vercel.app/", "summary": "Developing robust and high performance quantum software is challenging due to the dynamic nature of existing Python-based frameworks, which often suffer from runtime errors and scalability bottlenecks. In this work, we present LogosQ, a high performance backend agnostic quantum computing library implemented in Rust that enforces correctness through compile time type safety. Unlike existing tools, LogosQ leverages Rust static analysis to eliminate entire classes of runtime errors, particularly in parameter-shift rule gradient computations for variational algorithms. We introduce novel optimization techniques, including direct state-vector manipulation, adaptive parallel processing, and an FFT optimized Quantum Fourier Transform, which collectively deliver speedups of up to 900 times for state preparation (QFT) and 2 to 5 times for variational workloads over Python frameworks (PennyLane, Qiskit), 6 to 22 times over Julia implementations (Yao), and competitive performance with Q sharp. Beyond performance, we validate numerical stability through variational quantum eigensolver (VQE) experiments on molecular hydrogen and XYZ Heisenberg models, achieving chemical accuracy even in edge cases where other libraries fail. By combining the safety of systems programming with advanced circuit optimization, LogosQ establishes a new standard for reliable and efficient quantum simulation."}
{"id": "2512.23248", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.23248", "abs": "https://arxiv.org/abs/2512.23248", "authors": ["Jing-Yi-Ran Jin", "Shuang-Quan Ma", "Qing Ai"], "title": "Quantum Phase Transitions in Coherent Ising Machines: XY Model for Demonstration", "comment": "7 pages, 3 figures", "summary": "Quantum phase transitions (QPTs) in coherent Ising machines (CIMs) are studied via a spectral mapping between the one-dimensional XY spin model and a network of degenerate optical parametric oscillators (DOPOs). This exact correspondence reveals that the DOPO network faithfully reproduces the quantum critical behavior of the XY model across its anisotropic, isotropic, and transverse-field Ising regimes. The ground-state energy density and its derivatives are analyzed to reveal second-order QPTs characterized by singularities in magnetic susceptibility at critical points. These results show that CIMs do not only serve as powerful platforms for solving combinatorial optimization problems but also provide a versatile optical simulator for studying universal quantum critical phenomena, bridging quantum-spin models and photonic quantum systems."}
{"id": "2512.23299", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23299", "abs": "https://arxiv.org/abs/2512.23299", "authors": ["Ole Steuernagel", "Ray-Kuang Lee"], "title": "Towards a Faithful Quantumness Certification Functional for One-Dimensional Continuous-Variable Systems", "comment": "5 pages, one figure", "summary": "If the phase space-based Sudarshan-Glauber distribution, $P_ρ$, has negative values the quantum state, $ρ$, it describes is nonclassical. Due to $P$'s singular behavior this simple criterion is impractical to use. Recent work [Bohmann and Agudelo, Phys. Rev. Lett. 124, 133601 (2020)] presented a general, sensitive, and noise-tolerant certification functional, $ξ_{P}$, for the detection of non-classical behavior of quantum states $P_ρ$. There, it was shown that when this functional takes on negative values somewhere in phase space, $ξ_{P}(x,p) < 0$, this is \\emph{sufficient} to certify the nonclassicality of a state. Here we give examples where this certification fails. We investigate states which are known to be nonclassical but the certification functions is positive $ξ(x,p) \\geq 0$ everywhere in phase space. We generalize $ξ$ giving it an appealing form which allows for improved certification. This way we generate the best family of certification functions available so far. Yet, they also fail for very weakly nonclassical states, in other words, the question how to faithfully certify quantumness remains an open question."}
{"id": "2512.23323", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23323", "abs": "https://arxiv.org/abs/2512.23323", "authors": ["S. B. Korolev", "A. A. Silin"], "title": "Generation of Squeezed Fock States by Particle-Number Measurements on Multimode Gaussian States", "comment": null, "summary": "We investigate the generation of squeezed Fock states (SFSs) via particle-number measurements in the modes of multimode Gaussian states. We identify a universal class of $N$-mode Gaussian states for which measuring $N-1$ modes results in the generation of SFSs. The key feature of these states is that the generated SFSs depend only on the total number of detected particles and are independent of their distribution among the detectors. Based on the general form of the wave functions of multimode Gaussian states, we propose a universal scheme for SFS generation. For this scheme, we evaluate the probability of SFS generation and analyze the robustness of the process against imperfections in particle-number-resolving detectors. In addition, we compare the universal scheme with a nonuniversal scheme, in which the generation of SFSs depends on a specific distribution of particle numbers across the detectors. We demonstrate that the universal scheme provides a higher probability of SFS generation, at the cost of increased experimental resources."}
{"id": "2512.23325", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23325", "abs": "https://arxiv.org/abs/2512.23325", "authors": ["Partha Ghose"], "title": "The Quantum Rashomon Effect as a Failure of Gluing", "comment": "5 pages, no figures", "summary": "Recently Szangolies has argued (in the setting of extended Wigner's-friend scenarios) that quantum theory permits ``Rashomon'' situations: multiple internally coherent accounts of events that cannot be combined into a single, consistent global narrative. This note explains why the Rashomon phenomenon can be understood as a \\emph{failure of gluing}: local descriptions over different contexts exist, but they do not admit a single global ``all-perspectives-at-once'' description. This is the same mathematical obstruction that underlies modern sheaf-theoretic treatments of contextuality. I then indicate why the same perspective is useful in parts of the social sciences (quantum-like modelling of cognition, judgment, and decision-making), where ``context effects'' can likewise be interpreted as the absence of a single joint probability space."}
{"id": "2512.23388", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23388", "abs": "https://arxiv.org/abs/2512.23388", "authors": ["W. K. Yam", "M. Renger", "S. Gandorfer", "R. Gross", "K. G. Fedorov"], "title": "Practical quantum teleportation with finite-energy codebooks", "comment": "14 pages, 8 figures", "summary": "Quantum communication exploits non-classical correlations to achieve efficient and unconditionally secure exchange of information. In particular, the quantum teleportation protocol allows for a deterministic and secure transfer of unknown quantum states by using pre-shared quantum entanglement and classical feedforward communication. Quantum teleportation in the microwave regime provides an important tool for high-fidelity remote quantum operations, enabling distributed quantum computing with superconducting circuits and potentially facilitating short-range, open-air microwave quantum communication. In this context, we consider practical application scenarios for the microwave analog quantum teleportation protocol based on continuous-variable states. We theoretically analyze the effect of feedforward losses and noise on teleportation fidelities of coherent states and show that these imperfections can be fully corrected by an appropriate feedforward gain. Furthermore, we consider quantum teleportation with finite-size codebooks and derive modified no-cloning thresholds as a function of the codebook configuration. Finally, we analyze the security of quantum teleportation under public channel attacks and demonstrate that the corresponding secure fidelity thresholds may drastically differ from the conventional no-cloning values. Our results contribute to the general development of quantum communication protocols and, in particular, illustrate the feasibility of using quantum teleportation in realistic microwave networks for robust and unconditionally secure communication."}
{"id": "2512.23469", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23469", "abs": "https://arxiv.org/abs/2512.23469", "authors": ["M. Haider Akbar", "Özgür E. Müstecaplıoğlu"], "title": "Anisotropic Quantum Annealing vs Trit Annealing", "comment": "8 pages; Comments are welcome", "summary": "Quantum annealing offers a promising strategy for solving complex optimization problems by encoding the solution into the ground state of a problem Hamiltonian. While most implementations rely on spin-$1/2$ systems, we explore the performance of quantum annealing on a spin-$1$ system where the problem Hamiltonian includes a single ion anisotropy term of the form $D\\sum (S^z)^2$. Our results reveal that for a suitable range of the anisotropy strength $D$, the spin-$1$ annealer reaches the ground state with higher fidelity. We attribute this performance to the presence of the intermediate spin level and the tunable anisotropy, which together enable the algorithm to traverse the energy landscape through smaller, incremental steps instead of a single large spin flip. This mechanism effectively lowers barriers in the configuration space and stabilizes the evolution. These findings suggest that higher spin annealers offer intrinsic advantages for robust and flexible quantum optimization, especially for problems naturally formulated with ternary decision variables."}
{"id": "2512.23484", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.23484", "abs": "https://arxiv.org/abs/2512.23484", "authors": ["Ido Fridman", "Shemuel Sternklar", "Eliran Talker"], "title": "Cavity-Free $Δ$-Type Coherent Population Trapping for Microwave Sensing", "comment": "19 pages, 9 figures", "summary": "We investigated experimentally and theoretically a cavity-free microwave field that couples the two ground states of a Λ-type atomic system, thereby forming a closed Δ configuration. In this regime, the absence of cavity-imposed phase matching leads to a strong sensitivity of the ground-state coherence to the microwave field parameters. We observe that the coherent population trapping (CPT) resonance exhibits a pronounced dependence on the microwave power and detuning, resulting in measurable changes in resonance contrast, linewidth, and center frequency. To explain these effects, we develop a numerical density-matrix model in which the ground-state coherence explicitly incorporates the microwave coupling strength, capturing the essential physics of this no-phase-matching Δ system. The excellent agreement between theory and experiment establishes a simple and robust framework for microwave control of cavity-free Δ-type atomic systems, with direct implications for compact atomic clocks and quantum-enhanced quantum sensing platforms."}
{"id": "2512.23517", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.23517", "abs": "https://arxiv.org/abs/2512.23517", "authors": ["L. Saba", "C. D. Fosco"], "title": "Van der Waals interaction at short and long distances: a pedagogical path from stationary to time-dependent perturbation theory", "comment": "17 pages, 2 figures, LaTeX", "summary": "The van der Waals interaction between neutral atoms is typically studied using stationary perturbation theory for the short-distance (London) limit, while long-distance (Casimir-Polder) results are usually derived via semiclassical, time-dependent approaches. In this pedagogical article, we demonstrate that reformulating stationary perturbation theory calculations in terms of time-ordered correlation functions significantly simplifies the mathematical treatment. This reformulation is particularly advantageous for higher-order calculations required in the long-distance regime, where retardation effects become important. Our approach provides a unified framework that connects both limiting cases while offering a clear conceptual picture suitable for advanced quantum mechanics courses."}
{"id": "2512.23550", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23550", "abs": "https://arxiv.org/abs/2512.23550", "authors": ["Carlos Cardoso-Isidoro", "Enrique J. Galvez"], "title": "Clauser-Horne-Shimony-Holt Bell-inequality Violability with the Full Poincaré-Bloch Sphere", "comment": null, "summary": "Linearly polarized projections are the tacit means for performing Clauser-Horne-Shimony-Holt (CHSH) Bell-inequality tests using polarization-entangled photon pairs. The inequality is valid for all states on the Poincaré-Bloch sphere, but few laboratory studies have investigated violations with the full sphere. In this article, we explore the experimental verifications of the predicted violations of the CHSH inequality with Bell and non-Bell states with same and different linear and elliptically polarized basis states for each photon. We find that Bell states violate CHSH when using the same basis for both photons, regardless of their ellipticity, whereas they show no violations for photon projections in different bases. We found non-Bell maximally-entangled states for which the converse is true."}
{"id": "2512.23586", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23586", "abs": "https://arxiv.org/abs/2512.23586", "authors": ["Marcin Markiewicz", "Łukasz Pawela", "Zbigniew Puchała"], "title": "Averaging of quantum channels via channel-state duality", "comment": "11 pages. Comments welcome", "summary": "Twirling, uniform averaging over symmetry actions, is a standard tool for reducing the description of quantum states and channels to symmetry-invariant data. We develop a framework for averaging quantum channels based on channel-state duality that converts pre- and post-processing averages into a group twirl acting directly on the Choi operator. For arbitrary unitary representations on the input and output spaces, the twirled channel is obtained as an explicit projection onto the commutant of the induced representation on $\\mathcal H_{\\rm out}\\otimes \\mathcal H_{\\rm in}$. In the collective setting, where the commutant is the walled Brauer algebra, we introduce a partial-transpose reduction that maps channel twirling to an ordinary Schur-Weyl twirl of the partially transposed Choi operator, enabling formulas in terms of permutation operators. We further extend the construction beyond compact symmetries to reductive non-unitary groups via Cartan decomposition, yielding a weighted sum of invariant-sector projections with weights determined by the Abelian component. Finally, we provide two finite realizations of channel averaging. The first one is a ``dual'' averaging protocol as a convex mixture of unitary-$1$-design channels on invariant sectors. The second one is a notion of channel $t$-designs induced by weighted group $t$-designs for $t=t_{\\rm in}+t_{\\rm out}$."}
{"id": "2512.23599", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23599", "abs": "https://arxiv.org/abs/2512.23599", "authors": ["Hippolyte Dourdent", "Kyrylo Simonov", "Andreas Leitherer", "Emanuel-Cristian Boghiu", "Ravi Kunjwal", "Saronath Halder", "Remigiusz Augusiak", "Antonio Acín"], "title": "Paradox-free classical non-causality and unambiguous non-locality without entanglement are equivalent", "comment": "14 + 13 pages, 4 figures", "summary": "Closed timelike curves (CTCs) challenge our conception of causality by allowing information to loop back into its own past. Any consistent description of such scenarios must avoid time-travel paradoxes while respecting the no-new-physics principle, which requires that the set of operations available within any local spacetime region remain unchanged, irrespective of whether CTCs exist elsewhere. Within an information-theoretic framework, this leads to process functions: deterministic classical communication structures that remain logically consistent under arbitrary local operations, yet can exhibit correlations incompatible with any definite causal order - a phenomenon known as non-causality. In this work, we provide the first complete recursive characterization of process functions and of (non-)causal process functions. We use it to establish a correspondence between process functions and unambiguous complete product bases, i.e., product bases in which every local state belongs to a unique local basis. This equivalence implies that non-causality of process functions is exactly mirrored by quantum nonlocality without entanglement (QNLWE) - the impossibility of perfectly distinguishing separable states using local operations and causal classical communication - for such bases. Our results generalize previous special cases to arbitrary local dimensions and any number of parties, enable systematic constructions of non-causal process functions and unambiguous QNLWE bases, and reveal an unexpected connection between certain non-signaling inequalities and causal inequalities."}
{"id": "2512.23606", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23606", "abs": "https://arxiv.org/abs/2512.23606", "authors": ["Z. M. McIntyre", "Ji Zou", "Jelena Klinovaja", "Daniel Loss"], "title": "Heisenberg-limited metrology from the quantum-quench dynamics of an anisotropic ferromagnet", "comment": null, "summary": "The emerging field of quantum magnonics seeks to understand and harness the quantum properties of magnons -- quantized collective spin excitations in magnets. Squeezed magnon states arise naturally as the equilibrium ground states of anisotropic ferromagnets and antiferromagnets, representing an important class of nonclassical magnon states. In this work, we show how a qubit-conditioned quantum quench of an anisotropic ferromagnet can be used for Heisenberg-limited parameter estimation based on measurements of the qubit only. In the presence of ground-state squeezing, the protocol yields information about the eigenmode frequency of the coupled magnon-qubit system, whereas no information is gained in the absence of such squeezing. The protocol therefore leverages genuine quantum correlations in the form of magnonic squeezing while simultaneously relying on the equilibrium character of this squeezing -- a feature distinctive to magnetic systems."}
{"id": "2512.23607", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.23607", "abs": "https://arxiv.org/abs/2512.23607", "authors": ["Jakub Szefer"], "title": "Research Directions in Quantum Computer Cybersecurity", "comment": "5 pages", "summary": "This document presents a concise overview of the contemporary research directions in quantum computer cybersecurity. The aim of this document is not to be a survey, but rather a succinct summary of the major research directions in quantum computer cybersecurity at the end of the first half of the current decade. The document has been inspired by the presentations and discussions held at the 3$^{rd}$ Quantum Computer Cybersecurity Symposium, but goes beyond the contents of the symposium and aims to summarize at the high level the last five years of quantum computer cybersecurity work in academia. It is hoped that the document can provide researchers as well as government and industry leaders an overview of the current landscape of security threats and defenses against emergent quantum computing technologies. The document also includes a discussion of the current trends in cybersecurity research on quantum computers, and the perceived research gaps that should be filled with future funding and through academic and industry~research."}
{"id": "2512.23642", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.23642", "abs": "https://arxiv.org/abs/2512.23642", "authors": ["Nayan Sharma", "Ajay Tripathi"], "title": "Gauge-Invariant Phase Mapping to Intensity Lobes of Structured Light via Closed-Loop Atomic Dark States", "comment": null, "summary": "We present an analytical model showing how the gauge-invariant loop phase in a three-level closed-loop atomic system imprints as bright-dark lobes in Laguerre Gaussian probe beam intensity patterns. In the weak probe limit, the output intensity in such systems include Beer-Lambert absorption, a scattering term and loop phase dependent interference term with optical depth controlling visibility. These systems enable mapping of arbitrary phases via interference rotation and offer a platform to measure Berry phase. Berry phase emerge as a geometric holonomy acquired by the dark states during adiabatic traversal of LG phase defined in a toroidal parameter space. Manifesting as fringe shifts which are absent in open systems, experimental realization using cold atoms or solid state platforms appears feasible, positioning structured light in closed-loop systems as ideal testbeds for geometric phases in quantum optics."}
{"id": "2512.23702", "categories": ["quant-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2512.23702", "abs": "https://arxiv.org/abs/2512.23702", "authors": ["Michał Eckstein", "Tomasz Miller", "Ryszard Horodecki", "Ravishankar Ramanathan", "Paweł Horodecki"], "title": "The operational no-signalling constraints and their implications", "comment": "Comments are welcome!", "summary": "The study of quantum correlations within relativistic spacetimes, and the consequences of relativistic causality on information processing using such correlations, has gained much attention in recent years. In this paper, we establish a unified framework in the form of operational no-signalling constraints to study both nonlocal and temporal correlations within general relativistic spacetimes. We explore several intriguing consequences arising from our framework. Firstly, we show that the violation of the operational no-signalling constraints in Minkowski spacetime implies either a logical paradox or an operational infringement of Poincaré symmetry. We thereby examine and subvert recent claims in [Phys. Rev. Lett. 129, 110401 (2022)] on the possibility of witnessing operationally detectable causal loops in Minkowski spacetime. Secondly, we explore the possibility of jamming of nonlocal correlations, controverting a recent claim in [Nat. Comm. 16, 269 (2025)] that a physical mechanism for jamming would necessarily lead to superluminal signalling. Finally, we show that in black hole spacetimes certain nonlocal correlations under and across the event horizon can be jammed by any agent without spoiling the operational no-signalling constraints."}
{"id": "2512.23708", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.23708", "abs": "https://arxiv.org/abs/2512.23708", "authors": ["Milosz Matraszek", "Wojciech J. Jankowski", "Jan Behrends"], "title": "Quantum Geometric Bounds in Non-Hermitian Systems", "comment": "6+10 pages, 2 figures", "summary": "We identify quantum geometric bounds for observables in non-Hermitian systems. We find unique bounds on non-Hermitian quantum geometric tensors, generalized two-point response correlators, conductivity tensors, and optical weights. We showcase these findings in topological systems with non-Hermitian Chern numbers. We demonstrate that the non-Hermitian geometric constraints on response functions naturally arise in open quantum systems governed by out-of-equilibrium Lindbladian dynamics. Our findings are relevant to experimental observables and responses under the realistic setups that fall beyond the idealized closed-system descriptions."}
{"id": "2512.22540", "categories": ["physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22540", "abs": "https://arxiv.org/abs/2512.22540", "authors": ["David Nolland"], "title": "Determinism and Indeterminism as Model Artefacts: Toward a Model-Invariant Ontology of Physics", "comment": "32 pages", "summary": "This paper argues that the traditional opposition between determinism and indeterminism in physics is representational rather than ontological. Deterministic--stochastic dualities are available in principle, and arise in a non-contrived way in many scientifically important models. When dynamical systems admit mathematically equivalent deterministic and stochastic formulations, their observable predictions depend only on the induced structure of correlations between preparations and measurement outcomes. I use this model-equivalence to motivate a model-invariance criterion for ontological commitment, according to which only structural features that remain stable across empirically equivalent representations, and whose physical effects are invariant under such reformulations, are candidates for realism. This yields a fallibilist form of structural realism grounded in modal robustness rather than in the specifics of any given mathematical representation. Features such as conservation laws, symmetries, and causal or metric structure satisfy this criterion and can be encoded in observable relations in mathematically intelligible ways. By contrast, the localisation of modal selection -- whether in initial conditions, stochastic outcomes, or informational collapse mechanisms -- is not invariant under empirically equivalent reformulations and is therefore best understood as a gauge choice rather than an ontological feature. The resulting framework explains how certain long-standing problems in the foundations of physics, including the measurement problem and the perceived conflict between physical determinism and free agency, arise from the reification of representational artefacts. By distinguishing model-invariant structure from modelling conventions, I offer a realist ontology for modern physics that combines empirical openness with resistance to metaphysical overreach."}
{"id": "2512.22950", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22950", "abs": "https://arxiv.org/abs/2512.22950", "authors": ["Alexander Sturges", "Hugo Smith", "Matteo Marcuzzi"], "title": "Effective Kinetic Monte Carlo for a Quantum Epidemic Process", "comment": "38 paages (62 including Appendices and Bibliography); 25 figures (28 counting the three in the Appendices)", "summary": "Inspired by previous works on epidemic-like processes in open quantum systems, we derive an elementary quantum epidemic model that is simple enough to be studied via Quantum Jump Monte Carlo simulations at reasonably large system sizes. We show how some weak symmetries of the Lindblad equation allow us to map the dynamics onto a classical Kinetic Monte Carlo; this simplified, effective dynamics can be described via local stochastic jumps coupled with a local deterministic component. Simulations are then used to reconstruct a phase diagram which displays stationary features completely equivalent to those of completely classical epidemic processes, but richer dynamics with multiple, recurrent waves of infection."}
{"id": "2512.23240", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23240", "abs": "https://arxiv.org/abs/2512.23240", "authors": ["Gabriel Hayoun", "Ilya A. Gruzberg", "Marcel Filoche"], "title": "Localization-landscape generalized Mott-Berezinskiĭ formula", "comment": null, "summary": "We introduce a conceptual reformulation of the Mott-Berezinskiĭ (MB) theory of low-frequency AC conductivity in disordered systems based on localization landscape theory. Instead of assuming uniform localization and fixed hopping distances, transport is described through an effective potential whose geometry encodes the spatial organization and energy-dependent localization of quantum states. Using the associated Agmon metric, we define a generalized Mott scale that replaces the classical hopping length with a geometric criterion set by the disorder landscape. This framework naturally incorporates strong spatial inhomogeneity and yields the AC conductivity directly from the effective potential. The standard MB result is recovered as a limiting case. Our approach extends the conceptual foundation of MB theory to arbitrary disordered media and energies approaching the mobility edge, providing a unified description of AC transport in complex quantum materials."}
{"id": "2512.23361", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23361", "abs": "https://arxiv.org/abs/2512.23361", "authors": ["Chang-Yu Shen", "Shuai Yin", "Zi-Xiang Li"], "title": "Universal Entanglement Growth along Imaginary Time in Quantum Critical Systems", "comment": "7+5 pages, 4+3 figures", "summary": "Characterizing universal entanglement features in higher-dimensional quantum matter is a central goal of quantum information science and condensed matter physics. While the subleading corner terms in two-dimensional quantum systems encapsulate essential universal information of the underlying conformal field theory, our understanding of these features remains remarkably limited compared to their one-dimensional counterparts. We address this challenge by investigating the entanglement dynamics of fermionic systems along the imaginary-time evolution. We uncover a pioneering non-equilibrium scaling law where the corner entanglement entropy grows linearly with the logarithm of imaginary time, dictated solely by the universality class of the quantum critical point. Through unbiased Quantum Monte Carlo simulations, we verify this scaling in the interacting Gross-Neveu-Yukawa model, demonstrating that universal data can be accurately recovered from the early stages of relaxation. Our findings significantly circumvent the computational bottlenecks inherent in reaching full equilibrium convergence. This work establishes a direct link between the fundamental theory of non-equilibrium critical phenomena and the high-precision determination of universal entanglement properties on both classical and quantum platforms, paving the way for probing the rich entanglement structure of quantum critical systems."}
{"id": "2512.23591", "categories": ["physics.comp-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23591", "abs": "https://arxiv.org/abs/2512.23591", "authors": ["Pablo Yanes-Thomas", "Rocío Jáuregui-Renaud Santiago F. Caballero-Benítez", "Daniel Sahagún Sánchez", "Alejandro Kunold"], "title": "MultiAtomLiouvilleEquationGenerator: A Mathematica package for Liouville superoperators and master equations of multilevel atomic systems", "comment": "55 pages, 3 figures", "summary": "MulAtoLEG (Multi-Atom Liouville Equation Generator) is an open-source Mathematica package for generating Liouville superoperators and Liouville equations, specialized for multilevel atomic systems comprising an arbitrary number of atoms. This scheme is based on an extension to multilevel atomic systems, originally developed by Lehmberg [R. H. Lehmberg, Phys. Rev. A 2, 883 (1970)] as an adjoint master equation for ensembles of two-level emitters and later reformulated by Genes [M. Reitz, C. Sommer and C. Genes, PRX Quantum 3, 010201 (2022)] as a master equation. The package facilitates the generation of equations for complex transition configurations in alkali atoms. Although primarily designed for atomic systems, it can also generate the master and adjoint master equations for general Hamiltonians and Lindbladians. In addition, it includes functionalities to construct the differential equations in the dressed-state basis, where, in many cases, the non-unitary evolution operator can be determined explicitly. To maximize computational efficiency, the package leverages Mathematica's vectorization and sparse linear algebra capabilities. Since MulAtoLEG produces exact equations without approximations, the feasible system size is naturally limited by the available computational resources."}
{"id": "2512.23706", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23706", "abs": "https://arxiv.org/abs/2512.23706", "authors": ["Saranesh Prembabu", "Shu-Heng Shao", "Ruben Verresen"], "title": "Non-Invertible Interfaces Between Symmetry-Enriched Critical Phases", "comment": "11 pages, 7 figures + 4 page appendix", "summary": "Gapless quantum phases can become distinct when internal symmetries are enforced, in analogy with gapped symmetry-protected topological (SPT) phases. However, this distinction does not always lead to protected edge modes, raising the question of how the bulk-boundary correspondence is generalized to gapless cases. We propose that the spatial interface between gapless phases -- rather than their boundaries -- provides a more robust fingerprint. We show that whenever two 1+1d conformal field theories (CFTs) differ in symmetry charge assignments of local operators or twisted sectors, any symmetry-preserving spatial interface between the theories must flow to a non-invertible defect. We illustrate this general result for different versions of the Ising CFT with $\\mathbb{Z}_2 \\times \\mathbb{Z}_2^T$ symmetry, obtaining a complete classification of allowed conformal interfaces. When the Ising CFTs differ by nonlocal operator charges, the interface hosts 0+1d symmetry-breaking phases with finite-size splittings scaling as $1/L^3$, as well as continuous phase transitions between them. For general gapless phases differing by an SPT entangler, the interfaces between them can be mapped to conformal defects with a certain defect 't Hooft anomaly. This classification also gives implications for higher-dimensional examples, including symmetry-enriched variants of the 2+1d Ising CFT. Our results establish a physical indicator for symmetry-enriched criticality through symmetry-protected interfaces, giving a new handle on the interplay between topology and gapless phases."}
