<div id=toc></div>

# Table of Contents

- [cond-mat.str-el](#cond-mat.str-el) [Total: 8]
- [hep-lat](#hep-lat) [Total: 2]
- [math.NA](#math.NA) [Total: 12]
- [math.ST](#math.ST) [Total: 5]
- [nlin.CD](#nlin.CD) [Total: 2]
- [physics.soc-ph](#physics.soc-ph) [Total: 3]
- [physics.hist-ph](#physics.hist-ph) [Total: 1]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [stat.ME](#stat.ME) [Total: 10]
- [eess.SY](#eess.SY) [Total: 7]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 4]
- [math.OC](#math.OC) [Total: 15]
- [cs.CE](#cs.CE) [Total: 2]
- [physics.ao-ph](#physics.ao-ph) [Total: 5]
- [physics.comp-ph](#physics.comp-ph) [Total: 4]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [1] [$\mathbb{Z}_2$ lattice gauge theories: fermionic gauging, transmutation, and Kramers-Wannier dualities](https://arxiv.org/abs/2510.20893)
*Lei Su*

Main category: cond-mat.str-el

TL;DR: 本文通过引入Majorana费米子推广了$\mathbb{Z}_2$对称性的规范方法，建立了玻色和费米格点系统的对偶对应关系，并构造了可解释为Majorana稳定子码的$\mathbb{Z}_2$规范理论。


<details>
  <summary>Details</summary>
Motivation: 旨在统一玻色与费米系统中的对偶性，拓展$\mathbb{Z}_2$规范理论在量子计算和模拟中的应用。

Method: 采用费米子规范方法，结合Jordan-Wigner变换和线性深度局域酉电路，实现玻色与费米系统的对偶映射。

Result: 证明了费米子宇称规范后的$\mathbb{Z}_2$规范理论与传统含非局域项的$\mathbb{Z}_2$规范理论的酉等价性，并建立了其与折叠Ising链的等价关系。

Conclusion: 提供了一个统一的框架来理解高维$\mathbb{Z}_2$格点规范理论中的玻色-费米对偶性，为量子信息处理带来了新视角。

Abstract: We generalize the gauging of $\mathbb{Z}_2$ symmetries by inserting Majorana
fermions, establishing parallel duality correspondences for bosonic and
fermionic lattice systems. Using this fermionic gauging, we construct fermionic
analogs of $\mathbb{Z}_2$ gauge theories dual to the transverse-field Ising
model, interpretable as Majorana stabilizer codes. We demonstrate a unitary
equivalence between the $\mathbb{Z}_2$ gauge theory obtained by gauging the
fermion parity of a free fermionic system and the conventional $\mathbb{Z}_2$
gauge theory with potentially nonlocal terms on the square lattice with
toroidal geometry. This equivalence is implemented by a linear-depth local
unitary circuit, connecting the bosonic and fermionic toric codes through a
direction-dependent anyonic transmutation. The gauge theory obtained by gauging
fermion parity is further shown to be equivalent to a folded Ising chain
obtained via the Jordan--Wigner transformation. We clarify the distinction
between the recently proposed Kramers--Wannier dualities and those obtained by
gauging the $\mathbb{Z}_2$ symmetry along a space-covering path. Our results
extend naturally to higher-dimensional $\mathbb{Z}_2$ lattice gauge theories,
providing a unified framework for bosonic and fermionic dualities and offering
new insights for quantum computation and simulation.

</details>


### [2] [A Universal Chern Model on Arbitrary Triangulations](https://arxiv.org/abs/2510.20862)
*Nigel Higson,Emil Prodan*

Main category: cond-mat.str-el

TL;DR: 提出基于三角剖分的紧束缚哈密顿量模型，具有拓扑谱隙和非平凡陈数，并通过数值模拟验证，实现了真实物体表面的拓扑边缘态，设计了可实现该模型的超材料。


<details>
  <summary>Details</summary>
Motivation: 探索闭合可定向曲面上离散拓扑模型的构建，利用单纯复形的边界和庞加莱对偶映射引入新的紧束缚哈密顿量，以实现稳定的拓扑性质。

Method: 在三角剖分的顶点、边和面构成的格点上构建两个基于边界算子和庞加莱对偶的紧束缚哈密顿量，通过数值模拟分析其能谱特性及拓扑不变量。

Result: 模型在三角剖分无限细化极限下展现出清晰的拓扑谱隙和非平凡陈数，支持拓扑边缘态，并设计出可复现该动力学行为的超材料。

Conclusion: 所提出的模型为在真实物体表面实现拓扑边缘态提供了理论基础和实验路径，推动了拓扑超材料向实际应用的发展。

Abstract: Given a triangulation of a closed orientable surface, we consider the lattice
with sites at the vertices, edges and facets of the triangulation. Borrowing
from mathematics literature, we introduce on this lattice a pair of
tight-binding Hamiltonians derived from the boundary and Poincar\'e duality
maps of finite simplicial manifolds. These Hamiltonians have been proved to
have clean topological spectral gaps carrying non-trivial Chern numbers in the
limit of infinite refinement of the triangulation. We confirm this via
numerical simulations, and demonstrate how these models enable topological edge
modes at the surfaces of real-world objects. Furthermore, we describe a
metamaterial whose dynamics reproduces that of the proposed model, thus
bringing the topological metamaterials closer to real-world applications.

</details>


### [3] [The generic Mott transition in the sine-Gordon model through an embedded worm algorithm](https://arxiv.org/abs/2510.20901)
*Oscar Bouverot-Dupuis,Laura Foini,Alberto Rosso*

Main category: cond-mat.str-el

TL;DR: 本文提出了一种名为SmoWo的新型蒙特卡洛算法，通过结合蠕虫更新和事件链蒙特卡洛移动，实现了在正弦-戈登模型不同拓扑扇区之间的平滑过渡，从而克服了传统局域蒙特卡洛方法在模拟一维量子系统Mott转变时的局限性。该方法显著加速了模拟过程，使大规模系统的模拟成为可能，精确揭示了正弦-戈登模型的相变行为和临界特性。


<details>
  <summary>Details</summary>
Motivation: 由于正弦-戈登模型的构型空间分为不同的拓扑扇区，传统的局域蒙特卡洛方法只能处理极小的系统尺寸，限制了对Mott转变的精确研究。因此，需要开发一种能跨越拓扑障碍的高效算法。

Method: 引入了平滑蠕虫（SmoWo）蒙特卡洛算法，该方法将蠕虫更新与事件链蒙特卡洛移动相结合，扩展了构型空间，实现了拓扑扇区间的平滑过渡，并通过理论证明和性能测试验证了其有效性。

Result: SmoWo算法显著提升了模拟效率，能够处理更大的系统尺寸，从而获得了正弦-戈登模型在不同相态和临界行为方面的精确图像。

Conclusion: SmoWo算法有效克服了传统蒙特卡洛方法在拓扑障碍下的局限性，为研究一维量子系统中的Mott转变提供了强大工具，拓展了对强关联系统临界现象的理解。

Abstract: The generic Mott transition in one-dimensional quantum systems can be
described by the sine-Gordon model with a tilt via bosonization. Because the
configuration space of the sine-Gordon model separates into distinct
topological sectors, standard local Monte Carlo schemes are limited to very
small system sizes. To overcome this limitation, we introduce the smooth worm
(SmoWo) Monte Carlo algorithm which enlarges the configuration space to allow
smooth transitions between topological sectors. The method combines worm
updates with event-chain Monte Carlo moves. We explicitly prove its validity
and quantify its performance. Thanks to the substantial acceleration achieved
by the SmoWo algorithm, we are able to simulate large system sizes, providing a
precise picture of the different phases and critical behaviour of the
sine-Gordon model.

</details>


### [4] [Photoinduced Metal-to-Insulator Transitions in 2D Moiré Devices](https://arxiv.org/abs/2510.21005)
*Yiliu Li,Esteban Rojas-Gatjens,Yinjie Guo,Birui Yang,Dihao Sun,Luke Holtzman,Juseung Oh,Katayun Barmak,Cory R. Dean,James C. Hone,Nathaniel Gabor,Eric A. Arsenault,Xiaoyang Zhu*

Main category: cond-mat.str-el

TL;DR: 本文展示了通过光热电子空穴注入在门控掺杂的WS2/WSe2和WSe2/WSe2莫尔器件中实现超快金属到绝缘体的转变，所形成的关联绝缘态具有微秒级以上的寿命，为范德华异质结构中关联电子态的超快调控提供了有效机制。


<details>
  <summary>Details</summary>
Motivation: 探索非平衡状态下亚稳态相的控制方法，特别是实现无初始序的逆向光诱导金属-绝缘体转变。

Method: 利用石墨栅极的光热电子空穴注入，在门控掺杂的WS2/WSe2和WSe2/WSe2莫尔器件中诱导超快金属到绝缘体的转变。

Result: 实现了超快金属到绝缘体的转变，生成了寿命超过微秒的亚稳关联绝缘态。

Conclusion: 该研究为范德华异质结构中关联电子相的超快调控提供了一种有效的机制。

Abstract: Photoexcitation has been utilized to control quantum matter and to uncover
metastable phases far from equilibrium. Among demonstrations to date, the most
common is the photo-induced transition from correlated insulators to metallic
states; however, the reverse process without initial orders has not been
observed. Here, we show ultrafast metal-to-insulator transition in gate-doped
WS2/WSe2 and WSe2/WSe2 moir\'e devices using photo-thermionic hole injection
from graphite gates. The resulting correlated insulators are metastable, with
lifetimes exceeding microseconds. These findings establish an effective
mechanism for the ultrafast control of correlated electronic phases in van der
Waals heterostructures.

</details>


### [5] [Ultrafast Charge-Doping via Photo-Thermionic Injection in van der Waals Devices](https://arxiv.org/abs/2510.21008)
*Yiliu Li,Esteban Rojas-Gatjens,Yinjie Guo,Birui Yang,Dihao Sun,Luke Holtzman,Juseung Oh,Katayun Barmak,Cory R. Dean,James C. Hone,Nathaniel Gabor,Eric A. Arsenault,Xiaoyang Zhu*

Main category: cond-mat.str-el

TL;DR: 本文研究了双栅扭曲WSe2双层结构中的超快光掺杂机制，通过瞬态反射实验揭示了石墨栅极的光电热发射导致空穴注入，并展示了通过调节激发能量、光强和栅极偏压可选择性控制注入空穴。


<details>
  <summary>Details</summary>
Motivation: 探索二维材料范德华异质结构在飞秒激光激发下的非平衡动力学行为，尤其是莫尔界面的动力学响应及层自由度带来的额外器件功能。

Method: 采用时间分辨瞬态反射实验，在双栅扭曲WSe2双层结构中研究光学激发效应，结合少层石墨栅极和氮化硼间隔层，分析光电热发射引起的光掺杂过程。

Result: 发现了来自石墨栅极的光电热发射导致的超快光掺杂机制；观察到相关绝缘体光学信号的门电压移动、微秒量级的电荷扩散和脉冲累积效应，以及可能由瞬态相关绝缘体形成引起的光致吸收。

Conclusion: 实现了对莫尔双层系统中光诱导空穴注入的有效调控，为空穴掺杂动态调控及新型光电器件设计提供了新途径。

Abstract: Van der Waals (vdW) heterostructures of two-dimensional (2D) materials have
become a rich playground for the exploration of correlated quantum phases, and
recent studies have begun to probe their non-equilibrium dynamics under
femtosecond laser excitation. In a time-resolved experiment, optical excitation
of the multilayer structure can lead not only to rich dynamic responses from
the target layers, such as moir\'e interfaces, but also to additional device
functionality from the layer degree of freedom. Here, we investigate optical
excitation in a prototypical moir\'e device of dual-gated twisted WSe2
bilayers, with few-layer graphite gates and hexagonal boron nitride (hBN)
spacers. We establish an ultrafast photodoping mechanism in the moir\'e bilayer
from photo-thermionic emission of the graphite gates. Using transient
reflectance experiments, we reveal photo-induced hole injection evidenced by:
(i) a shift of gate voltages at which optical signatures of correlated
insulators are observed, (ii) a persistent optical signature indicative of
charge diffusion at microsecond timescales and local charge buildup from
pulse-to-pulse accumulation, and (iii) photoinduced absorption due likely to
transient formation of correlated insulators. We further demonstrate that the
injected holes can be selectively controlled by tuning the excitation energy,
fluence, and gate bias.

</details>


### [6] [Paramagnetic electron-nuclear spin entanglement in HoCo2Zn20](https://arxiv.org/abs/2510.21158)
*Takafumi Kitazawa,Yasuyuki Shimura,Takahiro Onimaru,Shun Tsuchida,Katsunori Kubo,Yoshinori Haga,Hironori Sakai,Yoshifumi Tokiwa,Shinsaku Kambe,Yo Tokunaga*

Main category: cond-mat.str-el

TL;DR: 研究了Ho基立方化合物HoCo2Zn20中电子-核自旋纠缠的顺磁基态，通过磁化和比热数据分析确定了晶体场参数、交换常数和超精细耦合常数，发现基态为由f电子自旋与核自旋纠缠形成的准六重态，并可能转变为电子-核耦合的十重态。


<details>
  <summary>Details</summary>
Motivation: 准确理解含活性核自旋的稀土化合物在低温下的物理性质，需明确其电子-核能级结构。

Method: 通过分析磁化率和比热数据，确定晶体场参数、磁交换常数及超精细耦合常数。

Result: Gamma5晶体场基态因超精细相互作用在0 T下分裂出1.3 K的能量宽度，真实顺磁基态是由f电子有效自旋S=1与165Ho核自旋I=7/2纠缠形成的准六重态，并可根据晶体场参数转变为十重态。

Conclusion: 电子-核自旋纠缠显著影响HoCo2Zn20的基态结构，精确识别电子-核能级方案对理解此类稀土化合物的低温性质至关重要。

Abstract: We investigated electron-nuclear spin entanglement in the paramagnetic ground
state of the Ho-based cubic compound HoCo2Zn20. From analyses of magnetization
and specific heat data, we determined the cubic crystalline electric field
(CEF) parameters, the magnetic exchange constant, and the hyperfine coupling
constant between the 4f magnetic moment and the 165Ho nuclear spin. Our results
show that the Gamma5 CEF ground state is split by the hyperfine coupling, with
an energy width of 1.3 K at 0 T, and that the true paramagnetic ground state is
a quasi-sextet arising primarily from entanglement between the f-electron
effective spin S = 1 and the 165Ho nuclear spin I = 7/2. We further demonstrate
that, depending on the CEF parameters, the paramagnetic ground state can switch
to an electron-nuclear coupled dectet. These findings underscore the importance
of accurately identifying the electron-nuclear level scheme for understanding
the low-temperature properties of rare-earth compounds containing spin-active
nuclei.

</details>


### [7] [Altermagnetism in an interacting model of Kagome materials](https://arxiv.org/abs/2510.21291)
*Alejandro Blanco Peces,Jaime Merino*

Main category: cond-mat.str-el

TL;DR: 在没有自旋轨道耦合或明确空间对称性破缺的情况下，Kagome Hubbard模型在Dirac填充时表现出由库仑相互作用驱动的交替磁性（altermagnetism），并展现出可用于中子散射实验探测的特征磁振子分裂。


<details>
  <summary>Details</summary>
Motivation: 探索Kagome晶格Hubbard模型中由电子相互作用驱动的新奇磁性态，特别是在无自旋轨道耦合情况下的交替磁性。

Method: 理论分析Kagome Hubbard模型在Dirac填充下的电子结构和磁性，扩展至具有更大单胞的晶格（如Lieb-Kagome晶格），并研究其磁振子谱特征。

Result: 发现了一种绝缘型交替磁态，表现出特征性的磁振子分裂，该现象可被中子散射实验检测，并适用于其他扩展晶格结构。

Conclusion: 库仑相互作用足以在Kagome Hubbard模型中诱导出交替磁性，为理解关联Kagome材料中的磁性提供了新视角。

Abstract: The Hubbard model on the Kagome lattice is a widely used interacting model
for describing the electronic properties of various transition metal-based
Kagome materials. We find altermagnetism driven by Coulomb interaction in the
Kagome Hubbard model at Dirac filling with no spin-orbit coupling nor explicit
spatial symmetry breaking present. We show how this insulating altermagnet is
relevant to other lattices with larger unit cells such as the Lieb-Kagome
lattice. The ALM found displays a characteristic magnon splitting which can be
detected in inelastic neutron scattering experiments on interacting Kagome
materials.

</details>


### [8] [Direct observation of the crystal electric-field splitting under magnetic field and uncovering field-induced magnetic phase transition in triangular rare-earth magnet CsErSe$_2$](https://arxiv.org/abs/2510.21616)
*Hope Whitelock,Allen O. Scheie,Marissa McMaster,Ian A. Leahy,Li Xing,Mykhaylo Ozerov,Dmitry Smirnov,Eun Sang Choi,C. dela Cruz,M. O. Ajeesh,Eliana S. Krakovsky,Daniel Rehn,Jie Xing,Athena S. Sefat,Minhyea Lee*

Main category: cond-mat.str-el

TL;DR: 本研究通过光学光谱直接测量了三角绝缘磁体CsErSe$_2$在磁场下的晶体场能级分裂，提取了晶体场参数和交换能，揭示了外场诱导的能级交叉与磁化跃变现象，为理解稀土磁体中的磁相互作用及磁阻挫提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 理解稀土磁体中由晶体场物理引起的各向异性单离子性质是研究磁相互作用的关键步骤，但在低对称性位点上实验确定这些参数极具挑战。

Method: 利用光学光谱技术在磁场下直接测量晶体场能级分裂，并结合低温交流磁化率测量，提取晶体场参数和交换能。

Result: 观察到随磁场增加出现多个能级交叉并伴随本征态切换，特别是在基态发生的交叉导致磁化率出现阶跃式增长。

Conclusion: 精确确定的晶体场哈密顿量参数有助于揭示外场诱导的集体磁现象的丰富物理内涵，并可能为实现磁阻挫提供新路径。

Abstract: An indispensable step toward understanding magnetic interaction in rare-earth
magnets is the determination of spatially anisotropic single-ion properties
resulting from the crystal electric field (CEF) physics. The CEF Hamiltonian
exhibits a discrete energy spectrum governed by a set of independent parameters
that reflect the site symmetry of the magnetic ion. However, experimentally
determining these parameters for magnetic ions at low-symmetry sites has been
proven highly challenging. In this study, we directly measured the CEF level
splitting under magnetic fields (B) using optical spectroscopy and extracted
both CEF parameters and the exchange energies of a triangular insulating magnet
CsErSe$_2$ as a model system. With increasing field, we find many CEF levels
undergo level-crossing, which accompanies switching of the eigenstate.
Particularly, such a crossing occurring at the ground state results in a
step-like increase in magnetization that we captured with the low-temperature
AC magnetic susceptibility measurements. Our work demonstrates that the
accurately determined CEF Hamiltonian parameters enable uncovering the rich
physics of field-induced collective magnetic phenomena, and potentially lead to
a new route to magnetic frustration.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [9] [Gaussian Processes for Inferring Parton Distributions](https://arxiv.org/abs/2510.21041)
*Yamil Cahuana Medrano,Hervé Dutrieux,Joseph Karpie,Kostas Orginos,Savvas Zafeiropoulos*

Main category: hep-lat

TL;DR: 本文提出了一种基于高斯过程回归（GPR）的贝叶斯框架，用于从格点QCD矩阵元中重构部分子分布函数（PDF），该方法具有非参数化、系统性强、不确定性可控和模型偏差小的优点。


<details>
  <summary>Details</summary>
Motivation: 由于从实验或格点QCD数据中提取部分子分布函数（PDF）是一个病态的逆问题，正则化对系统误差和结果可靠性有显著影响，因此需要一种能灵活处理不确定性和约束的系统性方法。

Method: 采用基于高斯过程回归（GPR）的贝叶斯框架，研究多种核函数、均值函数和超参数处理方式，并利用KL散度量化数据带来的信息增益，通过合成数据测试验证方法的一致性和鲁棒性。

Result: 合成数据测试表明该方法具有一致性和鲁棒性，能够提供可控的不确定性估计并减少模型偏差。

Conclusion: GPR被确立为一种系统且非参数化的PDF重构方法，在格点QCD分析中具有优越的不确定性控制和较低的模型依赖性。

Abstract: The extraction of parton distribution functions (PDFs) from experimental or
lattice QCD data is an ill-posed inverse problem, where regularization strongly
impacts both systematic uncertainties and the reliability of the results. We
study a framework based on Gaussian Process Regression (GPR) to reconstruct
PDFs from lattice QCD matrix elements. Within a Bayesian framework, Gaussian
processes serve as flexible priors that encode uncertainties, correlations, and
constraints without imposing rigid functional forms. We investigate a wide
range of kernel choices, mean functions, and hyperparameter treatments. We
quantify information gained from the data using the Kullback Leibler
divergence. Synthetic data tests demonstrate the consistency and robustness of
the method. Our study establishes GPR as a systematic and non-parametric
approach to PDF reconstruction, offering controlled uncertainty estimates and
reduced model bias in lattice QCD analyses.

</details>


### [10] [Composite objects in quantum (super)gravity](https://arxiv.org/abs/2510.21248)
*Axel Maas,Simon Plätzer,Felix Pressler*

Main category: hep-lat

TL;DR: 本文探讨了自束缚引力子（geon）作为暗物质候选者或原初黑洞形成的可能性，利用因果动力学三角剖分方法进行数值研究，并扩展到超引力情景，暗示超对称性在低能尺度下可能不可观测。


<details>
  <summary>Details</summary>
Motivation: 探索geon作为暗物质候选者或原初黑洞的可能性，并结合量子引力理论的发展对其进行研究。

Method: 采用因果动力学三角剖分这一非微扰的量子引力方法进行数值模拟，并基于复合算符的解析方法研究geon的性质，同时扩展至超引力框架。

Result: 数值结果显示出geon行为对宇宙学时间的有趣依赖性及其他意外特征；在超引力情景下，发现可能解释为何低能（对撞机）尺度下超对称性不可观测的线索。

Conclusion: geon是量子引力中值得进一步研究的对象，可能为暗物质和原初黑洞提供解释，同时超引力扩展为超对称性破缺机制提供了新视角。

Abstract: It has been a long entertained idea that self-bound gravitons, so-called
geons, could be a dark matter candidate or form (primordial) black holes. The
development of viable candidates for quantum gravity allows now to investigate
these ideas. Analytic methods show that the description of geons needs to be
based on composite operators made out of the graviton field. We present results
from a numerical investigation into this idea using causal dynamical
triangulations, an ab-initio non-perturbative definition of quantum gravity
based on general relativity, and accessible in lattice-gauge-theory-like
simulations. Our results suggest an interesting dependence on cosmological time
and other unexpected features. Finally, we extend the analytic part of the
setting to a supergravity scenario. This provides hints which, if confirmed,
could explain why supersymmetry may in a realistic universe in principle not be
observable at low (collider) energy scales.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [11] [Efficient optimization-based invariant-domain-preserving limiters in solving gas dynamics equations](https://arxiv.org/abs/2510.21080)
*Chen Liu,Dionysis Milesis,Chi-Wang Shu,Xiangxiong Zhang*

Main category: math.NA

TL;DR: 提出了一种基于优化的限制器方法，通过有效的分裂算法在高阶数值格式中保持气体动力学中的不变域，适用于间断Galerkin方法，并通过基准测试验证了其鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 为了在高阶数值模拟中保持气体动力学方程的物理合理性，需确保数值解始终位于不变域内，传统方法存在效率或精度不足的问题。

Method: 采用基于优化的限制器方法，结合Douglas-Rachford分裂和Davis-Yin分裂算法，显式地高效实现向不变域集合的投影，并应用于高阶间断Galerkin格式。

Result: 所提方法能够构造高阶精度、全局守恒且保持不变域的数值格式，在多个高难度基准测试中验证了ℓ¹和ℓ²范数最小化限制器的鲁棒性和良好性能。

Conclusion: 该优化框架可广泛应用于各类高阶数值方法，有效保证压缩流模拟的稳定性与物理一致性。

Abstract: We introduce effective splitting methods for implementing optimization-based
limiters to enforce the invariant domain in gas dynamics in high order accurate
numerical schemes. The key ingredients include an easy and efficient explicit
formulation of the projection onto the invariant domain set, and also proper
applications of the classical Douglas-Rachford splitting and its more recent
extension Davis-Yin splitting. Such an optimization-based approach can be
applied to many numerical schemes to construct high order accurate, globally
conservative, and invariant-domain-preserving schemes for compressible flow
equations. As a demonstration, we apply it to high order discontinuous Galerkin
schemes and test it on demanding benchmarks to validate the robustness and
performance of both $\ell^1$-norm minimization limiter and $\ell^2$-norm
minimization limiter.

</details>


### [12] [On the recent advances of spectral analysis for systems arising from fully-implicit RK methods](https://arxiv.org/abs/2510.21241)
*Michal Outrata*

Main category: math.NA

TL;DR: 本文研究了全隐式Runge-Kutta方法在求解线性时变偏微分方程中产生的矩阵的两类谱分析结果，证明了不同方法和表述下结果的等价性，并统一了两种研究方向。


<details>
  <summary>Details</summary>
Motivation: 不同表述和工具导致谱分析结果不一致，需要验证其等价性并统一理论框架。

Method: 通过理论分析和数学推导，比较并证明不同方法下谱分析结果的等价性。

Result: 证明了不同形式和工具得到的谱分析结果是等价的，且所采用的方法在本质上是统一的。

Conclusion: 全隐式Runge-Kutta方法中不同谱分析路径的结果具有一致性，理论框架可以统一。

Abstract: This work deals with two groups of spectral analysis results for matrices
arising in fully implicit Runge-Kutta methods used for linear time-dependent
partial differential equations. These were applied for different formulations
of the same problem and used different tools to arrive at results that do not
immediately coincide. We show the equivalence of the results as well as the
equivalence of the approaches, unifying the two directions.

</details>


### [13] [Ergodic Estimates of One-Step Numerical Approximations for Superlinear SODEs](https://arxiv.org/abs/2510.21279)
*Xin Liu,Zhihui Liu*

Main category: math.NA

TL;DR: 本文首次建立了具有超线性系数和乘性噪声的一类随机常微分方程数值近似在平均误差下的一阶收敛率。


<details>
  <summary>Details</summary>
Motivation: 针对具有超线性系数和乘性噪声的SODEs，现有数值方法的收敛性分析尚不充分，特别是关于不变测度的逼近误差缺乏精确估计。

Method: 利用基于生成元的Stein方法，推导出单步数值格式的误差表示公式，并在适当的耗散性和光滑性条件下进行分析。

Result: 证明了精确不变测度π与数值不变测度π_τ之间的误差为O(τ)，且该阶数是最优的。该结果适用于截断欧拉法、投影欧拉法和向后欧拉法等多种近期研究的格式。

Conclusion: 本文提供了一个统一且精确的误差分析框架，确立了一类重要SODEs数值解在不变测度逼近上的一阶收敛率。

Abstract: This paper establishes the first-order convergence rate for the ergodic error
of numerical approximations to a class of stochastic ODEs (SODEs) with
superlinear coefficients and multiplicative noise. By leveraging the generator
approach to the Stein method, we derive a general error representation formula
for one-step numerical schemes. Under suitable dissipativity and smoothness
conditions, we prove that the error between the accurate invariant measure
$\pi$ and the numerical invariant measure $\pi_\tau$ is of order
$\mathscr{O}(\tau)$, which is sharp. Our framework applies to several recently
studied schemes, including the tamed Euler, projected Euler, and backward Euler
methods.

</details>


### [14] [Multiscale Spectral Generalized Finite Element Methods for Discontinuous Galerkin Schemes](https://arxiv.org/abs/2510.21289)
*Christian Alber,Lukas Holbach*

Main category: math.NA

TL;DR: 提出了一种用于间断Galerkin离散的多尺度谱广义有限元方法（MS-GFEM），通过在重叠子域上构建局部近似并利用最优谱粗空间进行修正，结合单位分解实现全局解的组装，证明了对二阶椭圆问题具有近似指数衰减的误差估计。


<details>
  <summary>Details</summary>
Motivation: 为了提高间断Galerkin方法在处理多尺度问题时的计算效率和精度，设计一种具有快速收敛性的多尺度方法。

Method: 在重叠子域上构造局部近似，将其分解为局部源解和来自广义特征问题所得最优谱粗空间的修正项，再通过单位分解加权得到全局解。

Result: 对于采用加权对称内罚间断Galerkin格式离散的二阶椭圆问题，证明了逼近误差具有近似指数衰减的收敛性。

Conclusion: 所提出的MS-GFEM方法在理论上具有极高的收敛效率，适用于高精度求解多尺度椭圆问题。

Abstract: We propose a multiscale spectral generalized finite element method (MS-GFEM)
for discontinuous Galerkin (DG) discretizations. The method builds local
approximations on overlapping subdomains as the sum of a local source solution
and a correction from an optimal spectral coarse space, which is obtained from
a generalized eigenproblem. The global solution is then assembled via a
partition of unity. We prove nearly exponential decay of the approximation
error for second-order elliptic problems discretized with a weighted symmetric
interior-penalty DG scheme.

</details>


### [15] [A Variational Framework for the Algorithmic Complexity of PDE Solutions](https://arxiv.org/abs/2510.21290)
*Juan Esteban Suarez Cardona,Holger Boche,Gitta Kutyniok*

Main category: math.NA

TL;DR: 本文提出了一种基于最小二乘变分形式和梯度流的新框架，用于从优化角度研究偏微分方程（PDE）解的可计算性与复杂性，揭示了PDE结构特性与其解的计算复杂性之间的联系。


<details>
  <summary>Details</summary>
Motivation: 由于大多数实际应用中的偏微分方程无法解析求解，且数值方法受限于现有计算模型的理论极限，因此需要研究PDE解的图灵可计算性及其计算复杂性，以区分哪些方程原则上可算法求解，哪些包含不可判定或不可计算行为。

Method: 采用最小二乘变分形式及其对应的梯度流构建新框架，通过离散梯度流逼近PDE解算子，并将PDE的强制性、椭圆性和凸性等结构属性与解的内在复杂性关联起来。

Result: 该框架能够刻画两类情形：一类是存在多项式时间有效数值求解器的PDE，另一类是输入数据具有多项式时间复杂性但解本身呈超多项式增长的复杂性爆炸情形。

Conclusion: 该方法为分析PDE解的可计算性和复杂性提供了新的优化视角，有助于理解不同PDE在算法求解上的根本差异。

Abstract: Partial Differential Equations (PDEs) are fundamental tools for modeling
physical phenomena, yet most PDEs of practical interest cannot be solved
analytically and require numerical approximations. The feasibility of such
numerical methods, however, is ultimately constrained by the limitations of
existing computation models. Since digital computers constitute the primary
physical realizations of numerical computation, and Turing machines define
their theoretical limits, the question of Turing computability of PDE solutions
arises as a problem of fundamental theoretical significance. The Turing
computability of PDE solutions provides a rigorous framework to distinguish
equations that are, in principle, algorithmically solvable from those that
inherently encode undecidable or non-computable behavior. Once computability is
established, complexity theory extends the analysis by quantifying the
computational resources required to approximate the corresponding PDE
solutions. In this work, we present a novel framework based on least-squares
variational formulations and their associated gradient flows to study the
computability and complexity of PDE solutions from an optimization perspective.
Our approach enables the approximation of PDE solution operators via discrete
gradient flows, linking structural properties of the PDE, such as coercivity,
ellipticity, and convexity, to the inherent complexity of their solutions. This
framework characterizes both regimes where PDEs admit effective numerical
solvers in polynomial-time and those exhibiting complexity blowup, where the
input data possess polynomial-time complexity, yet the solution itself scales
super-polynomially.

</details>


### [16] [A numerical method for the fractional Zakharov-Kuznetsov equation](https://arxiv.org/abs/2510.21355)
*Mukul Dwivedi,Andreas Rupp*

Main category: math.NA

TL;DR: 本文提出了一种全离散傅里叶谱Galerkin方法求解定义在二维周期域上的分数阶Zakharov-Kuznetsov（fZK）方程，该方程通过α∈[1,2]阶的分数拉普拉斯算子引入非局部色散。所提方法在空间上保持质量、动量和能量的离散守恒，并证明了解的存在唯一性及一致收敛性，具有谱精度或指数收敛性，结合高效的积分因子Runge-Kutta时间离散化，数值实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地模拟包含非局部色散效应的物理现象，将经典的ZK方程推广至分数阶情形，并发展高效且保持守恒律的数值方法求解分数阶ZK方程。

Method: 采用傅里叶谱Galerkin法进行空间离散，构造保持质量、动量和能量守恒的半离散格式；利用紧性论证证明解的存在唯一性和收敛性；设计基于积分因子的Runge-Kutta方法处理刚性分数阶项，实现全离散格式。

Result: 证明了半离散格式解的存在唯一性及其对真实解的一致收敛性；获得了H^r_per空间中初始数据下的谱收敛阶O(N^{-r})，以及解析解下的指数收敛性；提出了高效的全离散格式并给出了误差分析。

Conclusion: 所提出的全离散傅里叶谱Galerkin方法能有效求解分数阶ZK方程，具有高精度、守恒性和稳定性，适用于不同分数阶情形，数值结果验证了理论分析的正确性。

Abstract: This paper develops a fully discrete Fourier spectral Galerkin (FSG) method
for the fractional Zakharov-Kuznetsov (fZK) equation posed on a two-dimensional
periodic domain. The equation generalizes the classical ZK model to incorporate
nonlocal dispersion through a fractional Laplacian of order $\alpha \in [1,2]$.
We first propose a semi-discrete FSG scheme in space that preserves the
discrete analogs of mass, momentum, and energy. The existence and uniqueness of
semi-discrete solutions are established. Using compactness arguments, we prove
the uniform convergence of the semi-discrete approximations to the unique
solution of the fZK equation for the periodic initial data in
$H^{1+\alpha}_{\mathrm{per}}(\Omega)$. The method achieves spectral convergence
of order $\mathcal{O}(N^{-r})$ for initial data in $H^r_{\mathrm{per}}$ with $r
\geq \alpha+1$, and exponential convergence for analytic solutions utilizing a
modified projection. An efficient integrating-factor Runge-Kutta time
discretization is designed to handle the stiff fractional term, and an error
analysis is presented. Numerical experiments validate the theoretical results
and demonstrate the method's effectiveness across various fractional orders.

</details>


### [17] [Exponential integrators for parabolic problems with non-homogeneous boundary conditions](https://arxiv.org/abs/2510.21381)
*Carlos Arranz-Simón,Alexander Ostermann*

Main category: math.NA

TL;DR: 本文扩展了指数Runge-Kutta方法在非齐次边界条件下的应用，提出了一种基于边界数据光滑延拓的修正策略，恢复并提高了收敛阶数，理论与数值实验验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的指数Runge-Kutta方法通常假设边界条件是齐次的，但在实际问题中常遇到非齐次边界条件，导致收敛阶降低，因此需要发展适用于非齐次情况的方法。

Method: 通过将非齐次边界条件问题转化为具有修正源项的齐次问题，采用基于边界数据光滑延拓的修正策略，并结合标准的指数积分器进行求解。

Result: 对于线性问题，证明了修正后的格式可恢复预期收敛阶，并可通过适当求积规则达到更高阶精度（如s阶段高斯配置法可达2s阶）；对于半线性问题，保持了满足刚性阶条件的指数Runge-Kutta方法所保证的收敛阶。数值实验验证了理论结果。

Conclusion: 所提出的修正策略有效解决了非齐次边界条件下指数Runge-Kutta方法的阶数下降问题，拓展了其适用范围并提升了精度。

Abstract: Exponential Runge-Kutta methods are a well-established tool for the numerical
integration of parabolic evolution equations. However, these schemes are
typically developed under the assumption of homogeneous boundary conditions. In
this paper, we extend classical convergence results to the case of
non-homogeneous boundary conditions. Since non-homogeneous boundary conditions
typically cause order reduction, we introduce a correction strategy based on
smooth extensions of the boundary data. This results in a reformulation as a
homogeneous problem with modified source term, to which standard exponential
integrators can be applied. For linear problems, we prove that the corrected
schemes recover the expected convergence order, and hat higher orders can be
attained with suitable quadrature rules, reaching order $2s$ for s-stage Gauss
collocation methods. For semilinear problems, our approach preserves the
convergence orders guaranteed by exponential Runge-Kutta methods satisfying the
corresponding stiff order conditions. Numerical experiments validate the
theoretical findings.

</details>


### [18] [Matrix- and tensor-oriented numerical schemes for the evolutionary space-fractional complex Ginzburg--Landau equation](https://arxiv.org/abs/2510.21394)
*Marco Caliari,Fabio Cassini*

Main category: math.NA

TL;DR: 提出了一种基于矩阵和张量的数值方法，用于求解多维时空分数阶复Ginzburg-Landau方程，通过高效计算特殊矩阵函数并利用张量结构，在2D和3D实验中显著优于现有方法，速度提升达一到两个数量级，并有效利用单个GPU加速计算。


<details>
  <summary>Details</summary>
Motivation: 为了高效求解多维时空分数阶复Ginzburg-Landau方程，克服传统方法在高维问题中的计算瓶颈，提升数值模拟的效率和可扩展性。

Method: 采用空间半离散化将原问题转化为常微分方程组，使用刚性稳定的积分格式进行时间推进，并通过利用问题的张量结构，高效直接地计算矩阵函数（如逆、指数和φ-函数），结合高性能BLAS和可并行的逐点操作实现加速。

Result: 在2D和3D数值实验中，所提方法在线性隐式和指数型格式下均表现出高可靠性，相比现有方法实现了10到100倍的速度提升，并验证了单个GPU在消费级和专业级硬件上均可显著加速计算。

Conclusion: 该方法充分利用张量结构和现代硬件加速能力，为求解高维分数阶复Ginzburg-Landau方程提供了高效、可扩展的数值解决方案，具有显著的计算优势。

Abstract: In this manuscript, we propose matrix- and tensor-oriented methods for the
numerical solution of the multidimensional evolutionary space-fractional
complex Ginzburg--Landau equation. After a suitable spatial semidiscretization,
the resulting system of ordinary differential equations is time integrated with
stiff-resistant schemes. The needed actions of special matrix functions (e.g.,
inverse, exponential, and the so-called $\varphi$-functions) are efficiently
computed in a direct way by exploiting the underlying tensor structure of the
task and taking advantage of high performance BLAS and parallelizable pointwise
operations. Several numerical experiments in 2D and 3D, where we apply the
proposed technique in the context of linearly-implicit and exponential-type
schemes, show the reliability and superiority of the approach against the
state-of-the-art, allowing to obtain speedups which range from one to two
orders of magnitude. Finally, we demonstrate that in our context a single GPU
can be effectively exploited to boost the computations both on consumer- and
professional-level hardware.

</details>


### [19] [Macro-element Refinement schemes for THB-Splines: Applications to Bézier Projection and Structure-Preserving Discretizations](https://arxiv.org/abs/2510.21429)
*Kevin Dijkstra,Carlotta Giannelli,Deepesh Toshniwal*

Main category: math.NA

TL;DR: 本文提出了一种基于截断分层B样条（THB-splines）的等几何分析自适应细化策略，通过宏单元细化方法（q-boxes）在保持关键数学性质的同时简化了实现过程，适用于L²稳定投影和结构保持离散化，并通过理论证明和数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在自适应细化过程中保持THB样条的关键数学性质（如局部线性无关性和离散de Rham复形的精确性），同时避免复杂的网格修改，提升算法实现的简便性和适用性。

Method: 提出基于宏单元的细化方法，根据应用需求选择q-块大小：在Bézier投影中使用p-块，在结构保持离散化中使用(p+1)-块，从而保证所需数学性质的满足。

Result: 理论证明和数值实验表明，该方法能有效实现最优收敛，支持自适应近似和不可压缩Navier-Stokes方程的模拟，且无需额外的网格修改。

Conclusion: 所提出的自适应细化策略在保持重要数学结构的同时简化了实现，为THB样条在等几何分析中的高效自适应应用提供了通用且可靠的框架。

Abstract: This paper introduces a novel adaptive refinement strategy for Isogeometric
Analysis (IGA) using Truncated Hierarchical B-splines (THB-splines). The
proposed strategy enhances locally-refined meshes for specific applications,
simplifying implementation. We focus on two key applications: an $L^2$-stable
local projector for THB-splines via B\'ezier projection [Dijkstra and Toshniwal
(2023)], and structure-preserving discretizations using THB-splines [Evans et
al. (2020), Shepherd and Toshniwal (2024)]. Previous methods required mesh
modifications to retain crucial properties like local linear independence and
the exactness of discrete de Rham complexes. Our approach introduces a
macro-element-based refinement technique, refining $\vec{q} =
q_1\times\cdots\times q_n$ blocks of elements, termed $\vec{q}$-boxes, where
the block size $\vec{q}$ is determined by the spline degree and application.
For the B\'ezier projection, we refine $\vec{p}$-boxes (i.e., $\vec{q} =
\vec{p}$), ensuring THB-splines are locally linearly independent in these
boxes, which enables a straightforward extension of the B\'ezier projection
algorithm, greatly improving upon Dijkstra and Toshniwal (2023). For
structure-preserving discretizations, we refine $(\vec{p+1})$-boxes (i.e.,
$\vec{q} = \vec{p}+\vec{1}$), demonstrating that this choice meets the
sufficient conditions for ensuring the exactness of the THB-spline de Rham
complex, as outlined by Shepherd and Toshniwal (2024), in any dimension. This
critical aspect allows for adaptive simulations without additional mesh
modifications. The effectiveness of our framework is supported by theoretical
proofs and numerical experiments, including optimal convergence for adaptive
approximation and simulations of the incompressible Navier-Stokes equations.

</details>


### [20] [The temporal domain derivative in inverse acoustic obstacle scattering](https://arxiv.org/abs/2510.21471)
*Marvin Knöller,Jörg Nick*

Main category: math.NA

TL;DR: 本文研究了时域声散射问题中的域导数，提出了一种基于卷积求积的时间半离散化方法，并结合高斯-牛顿法实现了对未知散射体边界的高效重建。


<details>
  <summary>Details</summary>
Motivation: 为了从时域测量数据中高效重建声软散射体的边界，需要精确刻画散射算子关于散射体形状变化的Frechét导数，即域导数。

Method: 通过分析时间依赖的波动方程解的非线性算子，定义其Frechét导数为域导数；采用卷积求积法对域导数对应的散射问题进行时间半离散化，并在高斯-牛顿法中使用离散域导数实现边界重构。

Result: 证明了在入射波具有足够时间正则性的条件下，该时间半离散化方法是稳定且收敛的；数值实验表明该方法在二维声波方程中能有效重建散射体边界。

Conclusion: 所提出的基于域导数和卷积求积的方法为时域声散射问题的形状反演提供了稳定、收敛且高效的数值求解途径。

Abstract: This work describes and analyzes the domain derivative for a time-dependent
acoustic scattering problem. We study the nonlinear operator that maps a
sound-soft scattering object to the solution of the time-dependent wave
equation evaluated at a finite number of points away from the obstacle. The
Fr\'echet derivative of this operator with respect to variations of the
scatterer coincides with point evaluations of the temporal domain derivative.
The latter is the solution to another time-dependent scattering problem, for
which a well-posedness result is shown under sufficient temporal regularity of
the incoming wave. Applying convolution quadrature to this scattering problem
gives a stable and provably convergent semi-discretization in time, provided
that the incoming wave is sufficient regular. Using the discrete domain
derivative in a Gauss--Newton method, we describe an efficient algorithm to
reconstruct the boundary of an unknown scattering object from time domain
measurements in a few points away from the boundary. Numerical examples for the
acoustic wave equation in two dimensions demonstrate the performance of the
method.

</details>


### [21] [Error Estimates for Sparse Tensor Products of B-spline Approximation Spaces](https://arxiv.org/abs/2510.21517)
*Clément Guillet*

Main category: math.NA

TL;DR: 本文提出并分析了基于一般几何域的B样条逼近空间，通过参数域映射构造稀疏网格张量积空间，并证明了两种构造方法的数学等价性，同时推导了误差估计和逆不等式，表明在适当正则性假设下，该方法能以更少自由度达到与标准张量积空间相同的逼近阶。


<details>
  <summary>Details</summary>
Motivation: 为了在复杂几何域上高效构造高精度逼近空间，减少自由度数量，提升计算效率。

Method: 采用最大光滑B样条构建单变量逼近空间和几何映射，通过稀疏网格组合技术或层次子空间分解构造逼近空间，并进行理论分析。

Result: 证明了两种稀疏网格构造方法的数学等价性，获得了逼近误差估计和逆不等式，显示在满足正则性条件下可用更少自由度达到相同逼近阶，但在非张量积域上需更强的解正则性假设。

Conclusion: 所提出的稀疏网格B样条逼近空间在处理一般几何域时具有良好的逼近性能和自由度优势，但收敛性依赖于解的各向同性正则性条件。

Abstract: This work introduces and analyzes B-spline approximation spaces defined on
general geometric domains obtained through a mapping from a parameter domain.
These spaces are constructed as sparse-grid tensor products of univariate
spaces in the parameter domain and are mapped to the physical domain via a
geometric parametrization. Both the univariate approximation spaces and the
geometric mapping are built using maximally smooth B-splines. We construct two
such spaces, employing either the sparse-grid combination technique or the
hierarchical subspace decomposition of sparse-grid tensor products, and we
prove their mathematical equivalence. Furthermore, we derive approximation
error estimates and inverse inequalities that highlight the advantages of
sparse-grid tensor products. Specifically, under suitable regularity
assumptions on the solution, these spaces achieve the same approximation order
as standard tensor product spaces while using significantly fewer degrees of
freedom. Additionally, our estimates indicate that, in the case of
non-tensor-product domains, stronger regularity assumptions on the solution --
particularly concerning isotropic (non-mixed) derivatives -- are required to
achieve optimal convergence rates compared to sparse-grid methods defined on
tensor-product domains.

</details>


### [22] [A Stabilized Trace FEM for Surface Cahn--Hilliard Equations: Analysis and Simulations](https://arxiv.org/abs/2510.21662)
*Deepika Garg,Maxim Olshanskii*

Main category: math.NA

TL;DR: 本文提出了一种用于求解曲面上Cahn-Hilliard方程的计算方法，结合了稳定化迹有限元法和隐-显式时间离散格式，并证明了其数值稳定性和最优误差估计。


<details>
  <summary>Details</summary>
Motivation: 为了有效求解定义在曲面上的Cahn-Hilliard方程，需要发展适用于复杂几何形状的高效且稳定的数值方法。

Method: 采用稳定化迹有限元法进行空间离散，结合隐-显式时间离散方案；利用固定背景网格和水平集函数隐式表示曲面，属于非适配有限元方法。

Result: 证明了离散问题满足能量耗散律，建立了最优阶误差估计，并通过多个二维闭合曲面上的数值实验验证了理论结果和方法的鲁棒性与收敛性。

Conclusion: 所提出的方法在理论和数值上均表现出良好的稳定性、收敛性和鲁棒性，适用于求解曲面上的Cahn-Hilliard方程。

Abstract: This paper addresses the analysis and numerical assessment of a computational
method for solving the Cahn--Hilliard equation defined on a surface. The
proposed approach combines the stabilized trace finite element method for
spatial discretization with an implicit--explicit scheme for temporal
discretization. The method belongs to a class of unfitted finite element
methods that use a fixed background mesh and a level-set function for implicit
surface representation. We establish the numerical stability of the discrete
problem by showing a suitable energy dissipation law for it. We further derive
optimal-order error estimates assuming simplicial background meshes and finite
element spaces of order $m \geq 1$. The effectiveness of the method is
demonstrated through numerical experiments on several two-dimensional closed
surfaces, confirming the theoretical results and illustrating the robustness
and convergence properties of the scheme.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [23] [A Geometric Analysis of PCA](https://arxiv.org/abs/2510.20978)
*Ayoub El Hanchi,Murat Erdogdu,Chris Maddison*

Main category: math.ST

TL;DR: 本文研究了主成分分析（PCA）的过量风险与数据分布特性的关系，建立了PCA估计主子空间误差的中心极限定理，并推导了重构损失下过量风险的渐近分布，同时给出了非渐近上界，证明了负块瑞利商在特定条件下具有广义自协调性。


<details>
  <summary>Details</summary>
Motivation: 明确数据分布的何种特性决定了主成分分析的过量风险，从而更深入理解PCA的统计性能。

Method: 通过建立主子空间估计误差的中心极限定理，推导重构损失下的渐近分布，结合非渐近上界分析，并利用广义自协调性理论在Grassmann流形上进行理论证明。

Result: 得到了PCA过量风险的渐近分布和非渐近上界，并证明了负块瑞利商在最大旋转小于π/4的测地线上具有广义自协调性。

Conclusion: 数据分布通过影响主子空间的估计精度来决定PCA的过量风险，本文提供了精确的理论刻画。

Abstract: What property of the data distribution determines the excess risk of
principal component analysis? In this paper, we provide a precise answer to
this question. We establish a central limit theorem for the error of the
principal subspace estimated by PCA, and derive the asymptotic distribution of
its excess risk under the reconstruction loss. We obtain a non-asymptotic upper
bound on the excess risk of PCA that recovers, in the large sample limit, our
asymptotic characterization. Underlying our contributions is the following
result: we prove that the negative block Rayleigh quotient, defined on the
Grassmannian, is generalized self-concordant along geodesics emanating from its
minimizer of maximum rotation less than $\pi/4$.

</details>


### [24] [Limiting Spectral Distribution of High-dimensional Multivariate Kendall-$τ$](https://arxiv.org/abs/2510.21077)
*Ruoyu Wu*

Main category: math.ST

TL;DR: 本文研究了多元Kendall-τ统计量$K_n$的经验谱分布（ESD）的极限性质，证明了$\frac{1}{2}pK_n$的ESD几乎必然收敛于参数为$\frac{1}{2}$的Mar\u{c}enko--Pastur分布，并通过Stieltjes变换技术将结果推广到独立成分模型，推导出极限谱分布的不动点方程，理论结果通过模拟研究得到验证。


<details>
  <summary>Details</summary>
Motivation: 多元Kendall-τ统计量在稳健统计分析中具有重要作用，但其经验谱分布的极限性质尚未充分研究，本文旨在填补这一理论空白。

Method: 利用Stieltjes变换技术分析经验谱分布的极限行为，并将其扩展到独立成分模型，推导出刻画极限谱分布的不动点方程。

Result: 证明了$\frac{1}{2}pK_n$的ESD几乎必然收敛于参数为$\frac{1}{2}$的Mar\u{c}enko--Pastur分布，并在独立成分模型下得到了极限谱分布的不动点刻画。

Conclusion: 多元Kendall-τ统计量的谱分布具有与样本协方差矩阵类似的极限行为，本文结果为其在高维数据中的理论应用提供了基础。

Abstract: The multivariate Kendall-$\tau$ statistic, denoted by $K_n$, plays a
significant role in robust statistical analysis. This paper establishes the
limiting properties of the empirical spectral distribution (ESD) of $K_n$. We
demonstrate that the ESD of $\frac{1}{2}pK_n$ converges almost surely to the
Mar\v{c}enko--Pastur law with variance parameter $\frac{1}{2}$, analogous to
the classical result for sample covariance matrices.
  Using Stieltjes transform techniques, we extend these results to the
independent component model, deriving a fixed-point equation that characterizes
the limiting spectral distribution of $\frac{1}{2}tr\Sigma K_n$. The
theoretical findings are validated through comprehensive simulation studies.

</details>


### [25] [Kriging measure-valued data with sparse observations: application to nuclear safety studies](https://arxiv.org/abs/2510.21277)
*Florian Gossard,François Bachoc,Jean Baccou,Thibaut Le Gouic,Jacques Liandrat,Tony Glantz*

Main category: math.ST

TL;DR: 提出了一种基于Wasserstein空间的Kriging插值方法，结合交叉验证技术用于概率测度的插值，适用于稀疏数据，并在核安全实际问题中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 在空间统计框架下解决概率测度插值问题，特别是在数据稀疏时传统半变异函数估计不准确的问题。

Method: 利用一维Wasserstein距离的分位数函数表示，在Wasserstein空间中构建Kriging方法，并引入针对分位数函数的虚拟交叉验证变体以提高估计精度。

Result: 在控制的玩具问题和核安全实际应用中验证了该方法的有效性，显示其在稀疏数据下具有良好的插值性能。

Conclusion: 所提出的方法能有效提升概率测度插值的准确性，尤其适用于稀疏数据场景，具有实际应用价值。

Abstract: This work addresses the interpolation of probability measures within a
spatial statistics framework. We develop a Kriging approach in the Wasserstein
space, leveraging the quantile function representation of the one-dimensional
Wasserstein distance. To mitigate the inaccuracies in semivariogram estimation
that arise from sparse datasets, we combine this formulation with
cross-validation techniques. In particular, we introduce a variant of the
virtual cross-validation formulas tailored to quantile functions. The
effectiveness of the proposed method is demonstrated on a controlled toy
problem as well as on a real-world application from nuclear safety.

</details>


### [26] [Conditional Forecasts and Proper Scoring Rules for Reliable and Accurate Performative Predictions](https://arxiv.org/abs/2510.21335)
*Philip Boeken,Onno Zoeter,Joris M. Mooij*

Main category: math.ST

TL;DR: 本文研究了可执行预测（performative predictions）中的预测偏差问题，提出通过协变量分离和改进评分规则来实现正确预测，并解决了Perdomo等人（2020）提出的预测不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 可执行预测会改变其试图预测的结果，导致传统预测方法失效，因此需要新的理论框架来保证预测的正确性和可评估性。

Method: 通过引入将预测与结果分离的协变量，使目标分布对预测不变，并提出修正的评分规则；在决策理论框架下分析可执行稳定预测的可行性。

Result: 证明了经典适当评分规则在可执行环境下无法激励正确预测，提出了两种解决方案：一是使用分离性预测实现激励相容，二是使用对预测与目标变量分布间差异的无偏估计进行评分。

Conclusion: 本文揭示了传统预测评估的根本局限，并为可执行环境下的可靠预测提供了新工具，实现了可执行稳定的参数估计。

Abstract: Performative predictions are forecasts which influence the outcomes they aim
to predict, undermining the existence of correct forecasts and standard methods
of elicitation and estimation. We show that conditioning forecasts on
covariates that separate them from the outcome renders the target distribution
forecast-invariant, guaranteeing well-posedness of the forecasting problem.
However, even under this condition, classical proper scoring rules fail to
elicit correct forecasts. We prove a general impossibility result and identify
two solutions: (i) in decision-theoretic settings, elicitation of correct and
incentive-compatible forecasts is possible if forecasts are separating; (ii)
scoring with unbiased estimates of the divergence between the forecast and the
induced distribution of the target variable yields correct forecasts. Applying
these insights to parameter estimation, conditional forecasts and proper
scoring rules enable performatively stable estimation of performatively correct
parameters, resolving the issues raised by Perdomo et al. (2020). Our results
expose fundamental limits of classical forecast evaluation and offer new tools
for reliable and accurate forecasting in performative settings.

</details>


### [27] [Sparse estimation for the drift of high-dimensional Ornstein--Uhlenbeck processes with i.i.d. paths](https://arxiv.org/abs/2510.21505)
*Shogo Nakakita*

Main category: math.ST

TL;DR: 研究了高维非平稳Ornstein-Uhlenbeck过程漂移参数的稀疏正则化最大似然估计，证明了Lasso和Slope估计器可以达到最小最大最优收敛速率，并通过数值实验展示了稀疏估计方法的性能。


<details>
  <summary>Details</summary>
Motivation: 针对高维非平稳Ornstein-Uhlenbeck过程，在重复测量独立同分布路径的情况下，估计其漂移参数具有挑战性，尤其是当参数具有稀疏性时，需要有效的稀疏正则化方法来提高估计精度和效率。

Method: 采用Lasso和Slope两种稀疏正则化方法进行最大似然估计，并理论分析其在高维非平稳Ornstein-Uhlenbeck模型中的收敛性质。

Result: 证明了Lasso和Slope估计器能够达到最小最大最优的收敛速率，并通过数值实验验证了这些稀疏估计方法的有效性和性能。

Conclusion: Lasso和Slope方法在高维非平稳Ornstein-Uhlenbeck过程的参数估计中表现优异，能够实现理论上的最优收敛速率，适用于稀疏结构的漂移参数估计。

Abstract: We study sparsity-regularized maximum likelihood estimation for the drift
parameter of high-dimensional non-stationary Ornstein--Uhlenbeck processes
given repeated measurements of i.i.d. paths. In particular, we show that Lasso
and Slope estimators can achieve the minimax optimal rate of convergence. We
exhibit numerical experiments for sparse estimation methods and show their
performance.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [28] [A Probability Space at Inception of Stochastic Process](https://arxiv.org/abs/2510.20824)
*Liteng Yang,Yuliang Liu,Jing Liu,Hongxuan Li,Wei Chen*

Main category: nlin.CD

TL;DR: 本文探讨了湍流理论中的新进展，研究了确定性过程如何在热力学状态变化下转变为随机过程，并通过统计框架分析共振中的非耗散动力学，提出了带有负概率区域的准周期概率密度函数。


<details>
  <summary>Details</summary>
Motivation: 理解确定性过程向随机过程转变的机制，特别是在共振条件下非耗散运动的产生及其统计描述。

Method: 基于牛顿力学框架，结合符号测度理论、符号概率空间和随机过程理论，对流体流动、固体振动和热传导等系统中的共振现象进行统计分析。

Result: 发现耗散状态的振荡载荷激发系统，产生具有负概率区域的准周期概率密度函数；随机速度的矢量特性导致概率密度函数在正负轴上略有不对称的分裂；确定性过程可视为概率为1的情况，且动态分形落在概率密度函数上。

Conclusion: 建立了共振非耗散动力学的概率密度函数框架，为现代统计学提供了新的数学工具和解析表达式，推动了对湍流等复杂系统的理解。

Abstract: Recently, progress has been made in the theory of turbulence, which provides
a framework on how a deterministic process changes to a stochastic one owing to
the change in thermodynamic states. It is well known that, in the framework of
Newtonian mechanics, motions are dissipative; however, when subjected to
periodic motion, a system can produce nondissipative motions intermittently and
subject to resonance. It is in resonance that turbulence occurs in fluid flow,
solid vibration, thermal transport, etc. In this, the findings from these
physical systems are analyzed in the framework of statistics with their own
probability space to establish their compliance to the stochastic process. In
particular, a systematic alignment of the inception of the stochastic process
with the signed measure theory, signed probability space, and stochastic
process was investigated. It was found that the oscillatory load from the
dissipative state excited the system and resulted in a quasi-periodic
probability density function with the negative probability regimes. In
addition, the vectorial nature of the random velocity splits the probability
density function along both the positive and negative axes with slight
asymmetricity. By assuming that a deterministic process has a probability of 1,
we can express the inception of a stochastic process, and the subsequent
benefit is that a dynamic fractal falls on the probability density function.
Moreover, we leave some questions of inconsistency between the physical system
and the measurement theory for future investigation. We believe that the
establishment of the probability density function of resonance nondissipative
dynamics in contemporary statistics should make many mathematical tools
available and the analytical formulas for the random velocity and probability
density function can provide a convenient platform for the development of
statistics.

</details>


### [29] [A Deep Learning Framework for Identifying Weakly Chaotic, Strongly Chaotic, Resonant and Non-resonant Orbits in the Generalized Kicked Rotator](https://arxiv.org/abs/2510.21318)
*Jian Zu,Zhiguo Xu,Jingyue Hao*

Main category: nlin.CD

TL;DR: 本文提出了一种基于深度学习的框架，用于识别广义 kicked rotator 系统中的轨道类型，特别是弱混沌轨道。通过结合加权Birkhoff平均、李雅普诺夫指数和关联维度，提出新算法生成四类轨道数据集，并利用2D-CNN实现高精度分类。


<details>
  <summary>Details</summary>
Motivation: 识别混沌动力系统中的轨道类型，特别是常规与混沌行为共存区域中的弱混沌轨道，是研究中的难点。传统方法难以有效区分这种中间状态，因此需要更有效的识别方法。

Method: 首先提出一种融合加权Birkhoff平均、李雅普诺夫指数和关联维度的新算法，用于识别并分类轨道为弱混沌、强混沌、共振和非共振规则轨道；然后构建2D-CNN模型，利用相空间的二维结构信息进行轨道分类。

Result: 所提出的算法成功生成了可用于深度学习的高质量轨道分类数据集；2D-CNN模型在轨道分类任务中表现出高准确率，验证了利用相空间结构信息的有效性。

Conclusion: 这是首次使用深度学习方法识别弱混沌轨道的研究，所提框架不仅在广义kicked rotator系统中有效，还可推广至其他复杂动力系统。

Abstract: Identifying the types of orbits is an important topic in the study of chaotic
dynamical systems. Beyond the well-known distinctly chaotic and regular
motions, we focus on dynamics occurring in regions where regular and chaotic
motions coexist and intertwine, which potentially indicating weakly chaotic
orbits. This intermediate regime lies between strongly chaotic dynamics,
characterized by exponential sensitivity and completely non-chaotic, purely
regular behavior. In this paper, we introduce a deep learning framework to
identify the types of orbits in the generalized kicked rotator system, which is
challenging to study due to its complex and mixed chaotic behaviors. Our deep
learning framework can be divided into two steps. First, we propose a novel
algorithm that integrates the weighted Birkhoff average, the Lyapunov exponent,
and the correlation dimension to identify weakly chaotic orbits. The algorithm
categorizes orbits into four types: weakly chaotic, strongly chaotic, and
regular orbits (which are further subdivided into resonant and non-resonant
orbits), thereby creating a valuable dataset required for deep learning models.
Second, we demonstrate that a well-trained 2D-CNN achieves high performance in
accurately classifying orbits, largely because it effectively leverages the 2D
structural information of the phase space relation. To our knowledge, this is
the first paper to identify weakly chaotic orbits using deep learning methods.
The method can be easily extend to other models.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [30] [The geography of novel and atypical research](https://arxiv.org/abs/2510.20827)
*Qing Ke,Tianxing Pan,Jin Mao*

Main category: physics.soc-ph

TL;DR: 本文研究了全球创造性科学生产的地理分布，通过新颖性和非典型性指标分析各国在创造性科研方面的表现。研究发现，尽管科学生产日益全球化，但不同国家在产生创造性成果方面仍存在显著差异。中国不仅成为科学产出大国，还在多个领域特别是材料科学和化学中显著领先于其他国， disproportionately produces novel and atypical research.


<details>
  <summary>Details</summary>
Motivation: 探讨在全球化背景下，地理位置和国家政策等因素如何影响创造性科学研究的分布，理解不同国家在科学创新中的角色演变。

Method: 采用Uzzi et al. (2013)提出的新颖性和非典型性指标，量化各国在创造性科学产出中的代表性，并基于时间趋势对国家进行聚类分析。

Result: 发现发达国家之间在产生新颖科学方面存在持续差异；识别出一个新兴国家群体；中国近年来不仅科研产出量大，且在新颖性和非典型性研究上表现突出，尤其在材料科学和化学等领域。

Conclusion: 科学创新具有地理集中性，中国的崛起不仅是数量上的领先，更体现在高质量、创新型研究的快速增长，显示出其在全球科研格局中的领导潜力。

Abstract: The production of knowledge has become increasingly a global endeavor. Yet,
location related factors, such as local working environment and national policy
designs, may continue to affect what kind of science is being pursued. Here we
examine the geography of the production of creative science by country, through
the lens of novelty and atypicality proposed in Uzzi et al. (2013). We quantify
a country's representativeness in novel and atypical science, finding
persistent differences in propensity to generate creative works, even among
developed countries that are large producers in science. We further cluster
countries based on how their tendency to publish novel science changes over
time, identifying one group of emerging countries. Our analyses point out the
recent emergence of China not only as a large producer in science but also as a
leader that disproportionately produces more novel and atypical research.
Discipline specific analysis indicates that China's over-production of atypical
science is limited to a few disciplines, especially its most prolific ones like
materials science and chemistry.

</details>


### [31] [Urban Planning in 3D with a Two-tier LUTI model](https://arxiv.org/abs/2510.20992)
*Flora Roumpani,Joel Dearden,Alan Wilson*

Main category: physics.soc-ph

TL;DR: 该论文提出了一种双层Lowry模型，将人口和就业的动态模拟直接引入规划过程，通过连接区域建模与邻里设计，支持规划者探索不同规划情景的演化。


<details>
  <summary>Details</summary>
Motivation: 旨在弥合区域预测与地方空间设计之间的差距，提升城市规划的动态性和多尺度整合能力。

Method: 采用双层Lowry模型，上层捕捉区域层面的人口、就业和服务流动，下层将其分配到细粒度区域（如街区或地块），并在CityEngine中实现交互式可视化与评估。

Result: 在英国南约克郡的案例研究中，成功将区域预测转化为局部设计响应，实现了量化建模与三维空间规划的衔接。

Conclusion: 该框架有效支持了多尺度城市规划决策，增强了动态模拟与实际空间设计之间的联动。

Abstract: The two-tier Lowry model brings dynamic simulations of population and
employment directly into the planning process. By linking regional modelling
with neighbourhood design, the framework enables planners to explore how
alternative planning scenarios may evolve over time. The upper tier captures
regional flows of people, jobs, and services, while the lower tier allocates
these to fine-grain zones such as neighbourhoods or parcels. Implemented in
CityEngine, the approach allows interactive visualisation and evaluation of
multi-scale scenarios. A case study in South Yorkshire (UK) illustrates how
regional forecasts can be translated into local design responses, connecting
quantitative modelling with 3D spatial planning.

</details>


### [32] [The dynamics of discovery and the Heaps-Zipf relationship](https://arxiv.org/abs/2510.21481)
*Célestin Zimmerlin,Thomas Louail,Manuel Moussallam,Marc Barthelemy*

Main category: physics.soc-ph

TL;DR: 本文研究了在序列跟踪过程中类型-标记增长（type-token growth）如何受到时间相关性的影响，指出传统的Zipf-Heaps框架在忽略序列时间结构时存在局限性，并通过一个单参数模型成功复现了多种类型-标记增长轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统上Heaps定律常通过Zipf分布的随机采样解释，但该方法假设时间独立性，而现实系统中序列具有强烈的时间相关性，因此需要探究时间结构对类型-标记曲线的实际影响。

Method: 分析真实系统（如音乐聆听和网页浏览）中的序列数据，提出一个极简的单参数模型，用以模拟不同类型-标记增长轨迹，并考察其与频率分布和时间结构的关系。

Result: 发现领域特定的时间相关性会导致类型-标记曲线显著偏离Zipf-Heaps框架，类型-标记增长不仅取决于类型频率分布，还强烈依赖于序列的时间结构；所提出的模型能复现包括极值情况在内的多种增长行为。

Conclusion: 类型-标记增长不能仅由频率分布解释，时间结构是一个关键且常被忽视的因素，需在应用标度律分析人类行为时予以考虑。

Abstract: When following a sequence - such as reading a text or tracking a user's
activity - one can measure how the "dictionary" of distinct elements (types)
grows with the number of observations (tokens). When this growth follows a
power law, it is referred to as Heaps' law, a regularity often associated with
Zipf's law and frequently used to characterize human innovation and discovery
processes. While random sampling from a Zipf-like distribution can reproduce
Heaps' law, this connection relies on the assumption of temporal independence -
an assumption often violated in real-world systems although frequently found in
the literature. Here, we investigate how temporal correlations in token
sequences affect the type-token curve. In systems like music listening and web
browsing, domain-specific correlations in token ordering lead to systematic
deviations from the Zipf-Heaps framework, effectively decoupling the type-token
plot from the rank-frequency distribution. Using a minimal one-parameter model,
we reproduce a wide variety of type-token trajectories, including the extremal
cases that bound all possible behaviors compatible with a given frequency
distribution. Our results demonstrate that type-token growth reflects not only
the empirical distribution of type frequencies, but also the temporal structure
of the sequence - a factor often overlooked in empirical applications of
scaling laws to characterize human behavior.

</details>


<div id='physics.hist-ph'></div>

# physics.hist-ph [[Back]](#toc)

### [33] [Philip Warren Anderson](https://arxiv.org/abs/2510.20865)
*Premala Chandra,Piers Coleman,Clare C. Yu*

Main category: physics.hist-ph

TL;DR: Philip Warren Anderson是一位杰出的理论物理学家，其研究深刻影响了凝聚态物理和粒子物理，提出了诸如安德森局域化、共振价键理论和安德森-希格斯机制等重要概念，并倡导‘多即不同’的涌现思想。


<details>
  <summary>Details</summary>
Motivation: Anderson致力于理解复杂系统中的集体行为和基本对称性破缺，探索从微观粒子到宏观现象之间的联系。

Method: 他通过理论建模与数学分析，结合实验合作，研究无序系统、磁性、超导性和基本粒子中的对称性破缺机制。

Result: 取得了包括局域化理论、超导中的安德森定理、Kondo问题解决、自旋玻璃理论以及对标准模型有影响的安德森-希格斯机制等一系列重要成果。

Conclusion: Anderson的工作不仅奠定了现代凝聚态物理的基础，也深刻影响了粒子物理和复杂系统科学的发展方向。

Abstract: Philip Warren Anderson was a pioneering theoretical physicist whose work
fundamentally shaped our understanding of complex systems. Anderson received
the Nobel Prize in Physics in 1977 for his groundbreaking research on
localization and magnetism, yet he did so much more. His work on magnetism
included antiferromagnetism, superexchange, the Kondo problem and local
magnetic moments in metals. Anderson pointed out the importance of disorder
through his work on localization, non-crystalline solids and spin glasses. In
superconductivity, he is known for the dirty superconductor theorem, showing
the gauge-invariance of the BCS theory, his study of flux creep, and for his
collaboration with experimentalists to realize the Josephson effect. Anderson's
resonating valence bond theory may yet play an important role in high
temperature superconductivity. Anderson was also fascinated by broken symmetry,
and he laid the theoretical groundwork for what is now known as the
Anderson-Higgs mechanism, showing how gauge bosons can acquire mass - an
insight that played a foundational role in the Standard Model of particle
physics. In his seminal "More is Different" paper, Anderson argued that the
collective emergent phenomena that arise in complex interacting systems cannot
be deduced from their fundamental parts. Anderson's legacy endures not only
through the lasting impact of his scientific work but also through his
influence on generations of physicists who continue to explore the rich
landscape of collective behavior in nature.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [34] [The geometry and dynamics of annealed optimization in the coherent Ising machine with hidden and planted solutions](https://arxiv.org/abs/2510.21109)
*Federico Ghimenti,Adithya Sriram,Atsushi Yamamura,Hideo Mabuchi,Surya Ganguli*

Main category: cond-mat.dis-nn

TL;DR: 本文研究了相干伊辛机（CIM）在求解大规模组合优化问题中的优化动力学行为，结合多种理论方法分析能量景观演化过程中全局与局部极小值的几何特性，揭示了CIM如何避开大量未对齐的高能局部极小值并趋近对齐的低能全局极小值，最终实现对隐藏解的有效恢复。


<details>
  <summary>Details</summary>
Motivation: 理解CIM在复杂能量景观中的优化机制，特别是其如何在存在大量局部极小值的情况下找到接近隐藏解的全局最优解。

Method: 结合复制方法、随机矩阵理论、Kac-Rice方法和动力平均场理论，分析Sherrington-Kirkpatrick自旋玻璃模型和Wishart植入系综的能量景观演化、临界点分布及Hessian特征谱。

Result: 发现低能全局极小值具有软模，优化动力学可利用此特性下降；尽管存在指数级未对齐的高能局部极小值，CIM仍能避开它们趋近对齐的全局极小值；进一步退火会使全局极小值变刚性，终止优化增益；并在Wishart系综中描述了隐藏解可恢复性的相变。

Conclusion: 高维能量景观的几何特性与优化动力学密切相关，CIM能有效利用软模和景观演化避开陷阱，实现对隐藏解的高效搜索。

Abstract: The coherent Ising machine (CIM) is a nonconventional hardware architecture
for finding approximate solutions to large-scale combinatorial optimization
problems.It operates by annealing a laser gain parameter to adiabatically
deform a high-dimensional energy landscape over a set of soft spins, going from
a simple convex landscape to the more complex optimization landscape of
interest. We address how the evolving energy landscapes guides the optimization
dynamics against problems with hidden planted solutions. We study the
Sherrington-Kirkpatrick spin-glass with ferromagnetic couplings that favor a
hidden configuration by combining the replica method, random matrix theory, the
Kac-Rice method and dynamical mean field theory. We characterize energy,
number, location, and Hessian eigenspectra of global minima, local minima, and
critical points as the landscape evolves. We find that low energy global minima
develop soft-modes which the optimization dynamics can exploit to descend the
energy landscape. Even when these global minima are aligned to the hidden
configuration, there can be exponentially many higher energy local minima that
are all unaligned with the hidden solution. Nevertheless, the annealed
optimization dynamics can evade this cloud of unaligned high energy local
minima and descend near to aligned lower energy global minima. Eventually, as
the landscape is further annealed, these global minima become rigid,
terminating any further optimization gains from annealing. We further consider
a second optimization problem, the Wishart planted ensemble, which contains a
hidden planted solution in a landscape with tunable ruggedness. We describe CIM
phase transitions between recoverability and non-recoverability of the hidden
solution. Overall, we find intriguing relations between high-dimensional
geometry and dynamics in analog machines for combinatorial optimization.

</details>


### [35] [Markov Inequality as a Tool for Linear-Scaling Estimation of Local Observables](https://arxiv.org/abs/2510.21688)
*H. P. Veiga,D. R. Pinheiro,J. P. Santos Pires,J. M. Viana Parente Lopes*

Main category: cond-mat.dis-nn

TL;DR: 提出了一种线性标度的随机方法，用于在紧束缚模型中计算任意正定局域谱算符的实空间映射，适用于强空间涨落情形，并可扩展至非对角观测量。


<details>
  <summary>Details</summary>
Motivation: 为克服传统方法在强空间涨落下缺乏自平均性导致的精度问题，发展一种高效且鲁棒的随机方法来计算局域谱算符的实空间分布。

Method: 采用正定估计量结合马尔可夫不等式，对每个格点的采样误差进行严格界定，并通过局域酉变换将方法推广到非对角观测量，如局域电流。

Result: 在二维无序π-通量模型中实现了局域态密度（LDoS）和稳态电流图的高效计算，验证了方法的有效性与精确性。

Conclusion: 该方法具有线性计算标度，适用于大规模晶格中无序驱动的介观现象模拟，并有望加速实空间自洽平均场计算。

Abstract: We introduce a linear-scaling stochastic method to compute real-space maps of
any positive local spectral operator in a tight-binding model. By employing
positive-definite estimators, the sampling error at each site can be rigorously
bounded relative to the mean via the Markov inequality, overcoming the lack of
self-averaging and enabling accurate estimates even under strong spatial
fluctuations. The approach extends to non-diagonal observables, such as local
currents, through local unitary transformations and its effectiveness is
showcased by benchmark calculations in the disordered two-dimensional (2D)
$\pi$-flux model, where the LDoS and steady-state current maps are computed.
This method will enable simulations of disorder-driven mesoscopic phenomena in
realistically large lattices and accelerate real-space self-consistent
mean-field calculations.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [36] [Handling Missing Responses under Cluster Dependence with Applications to Language Model Evaluation](https://arxiv.org/abs/2510.20928)
*Zhenghao Zeng,David Arbour,Avi Feller,Ishita Dasgupta,Atanu R Sinha,Edward H. Kennedy*

Main category: stat.ME

TL;DR: 本文研究了在人类标注存在缺失和聚类依赖情况下，双稳健估计量在生成式AI模型评估中的应用，提出了考虑聚类依赖的新理论性质，并通过模拟和真实数据验证了其重要性。


<details>
  <summary>Details</summary>
Motivation: 由于人类标注常存在缺失和聚类依赖问题，传统的评估方法可能导致偏差和错误的不确定性估计，因此需要一种能同时处理这两个问题的可靠推断方法。

Method: 采用双稳健估计量，并建立其在聚类依赖结构下的新理论性质，通过模拟实验和真实对话质量数据集进行验证。

Result: 理论和实证结果表明，在缺失响应问题中考虑聚类依赖对于实现有效的统计推断至关重要，忽略该结构可能导致标准误估计偏差。

Conclusion: 在存在缺失标注和聚类依赖的人类-AI交互评估中，应使用考虑聚类结构的双稳健估计方法，以确保无偏估计和正确的统计推断。

Abstract: Human annotations play a crucial role in evaluating the performance of GenAI
models. Two common challenges in practice, however, are missing annotations
(the response variable of interest) and cluster dependence among human-AI
interactions (e.g., questions asked by the same user may be highly correlated).
Reliable inference must address both these issues to achieve unbiased
estimation and appropriately quantify uncertainty when estimating average
scores from human annotations. In this paper, we analyze the doubly robust
estimator, a widely used method in missing data analysis and causal inference,
applied to this setting and establish novel theoretical properties under
cluster dependence. We further illustrate our findings through simulations and
a real-world conversation quality dataset. Our theoretical and empirical
results underscore the importance of incorporating cluster dependence in
missing response problems to perform valid statistical inference.

</details>


### [37] [Bayesian analysis of flexible Heckman selection models using Hamiltonian Monte Carlo](https://arxiv.org/abs/2510.20942)
*Heeju Lim,Victor E. Lachos,Victor H. Lachos*

Main category: stat.ME

TL;DR: 本文提出了一种基于贝叶斯方法的Heckman选择模型，采用尺度混合正态分布（如t分布和污染正态分布）替代传统的正态误差假设，以应对实际数据中的厚尾问题，并利用Stan的NUTS采样器进行后验推断，通过模拟研究和真实数据应用验证了方法的有效性，相关算法已实现于R包HeckmanStan中。


<details>
  <summary>Details</summary>
Motivation: 传统Heckman选择模型依赖误差项服从二元正态分布的假设，但现实数据常呈现厚尾特征，导致估计偏差。因此，需要更稳健的模型来处理非正态误差问题。

Method: 采用贝叶斯框架，将Heckman模型中的正态分布假设替换为尺度混合正态分布（如Student's-t和污染正态分布），并使用Stan的No-U-Turn采样器（NUTS）进行后验抽样。

Result: 模拟研究表明，基于Student's-t和污染正态分布的Heckman模型在厚尾数据下表现优于传统正态假设模型；在医疗支出和劳动供给数据上的实证分析也验证了该方法的适用性和稳健性。

Conclusion: 所提出的基于尺度混合正态分布的贝叶斯Heckman模型能更有效地处理样本选择偏差与非正态误差问题，提高了估计的稳健性，且可通过HeckmanStan R包方便实现。

Abstract: The Heckman selection model is widely used in econometric analysis and other
social sciences to address sample selection bias in data modeling. A common
assumption in Heckman selection models is that the error terms follow an
independent bivariate normal distribution. However, real-world data often
deviates from this assumption, exhibiting heavy-tailed behavior, which can lead
to inconsistent estimates if not properly addressed. In this paper, we propose
a Bayesian analysis of Heckman selection models that replace the Gaussian
assumption with well-known members of the class of scale mixture of normal
distributions, such as the Student's-t and contaminated normal distributions.
For these complex structures, Stan's default No-U-Turn sampler is utilized to
obtain posterior simulations. Through extensive simulation studies, we compare
the performance of the Heckman selection models with normal, Student's-t and
contaminated normal distributions. We also demonstrate the broad applicability
of this methodology by applying it to medical care and labor supply data. The
proposed algorithms are implemented in the R package HeckmanStan.

</details>


### [38] [Autocorrelation Test under Frequent Mean Shifts](https://arxiv.org/abs/2510.21047)
*Ziyang Liu,Ning Hao,Yue Selena Niu,Han Xiao,Hongxu Ding*

Main category: stat.ME

TL;DR: 提出了一种新的抗偏移的Portmanteau（SIP）检验方法，用于在频繁均值变化下可靠检测时间序列中的自相关性。


<details>
  <summary>Details</summary>
Motivation: 传统自相关检验方法依赖于平稳性假设，难以处理复杂均值结构（如频繁变化的分段常数均值），因此需要一种对均值偏移鲁棒的新方法。

Method: 提出了一种新的推断框架——Shift-Immune Portmanteau (SIP) 检验，能够在存在频繁均值变化的情况下检测时间序列中的自相关性。

Result: SIP检验在存在频繁均值偏移的情况下仍能有效检测自相关性，表现出良好的鲁棒性，并成功应用于纳米孔测序数据。

Conclusion: SIP检验为非平稳时间序列中的自相关分析提供了一种可靠且鲁棒的方法，尤其适用于均值结构复杂的应用场景。

Abstract: Testing for the presence of autocorrelation is a fundamental problem in time
series analysis. Classical methods such as the Box-Pierce test rely on the
assumption of stationarity, necessitating the removal of non-stationary
components such as trends or shifts in the mean prior to application. However,
this is not always practical, particularly when the mean structure is complex,
such as being piecewise constant with frequent shifts. In this work, we propose
a new inferential framework for autocorrelation in time series data under
frequent mean shifts. In particular, we introduce a Shift-Immune Portmanteau
(SIP) test that reliably tests for autocorrelation and is robust against mean
shifts. We illustrate an application of our method to nanopore sequencing data.

</details>


### [39] [Sensitivity Analysis when Generalizing Causal Effects from Multiple Studies to a Target Population: Motivation from the ECHO Program](https://arxiv.org/abs/2510.21116)
*Bolun Liu,Trang Quynh Nguyen,Elizabeth A. Stuart,Bryan Lau,Amii M. Kress,Michael R. Elliott,Kyle R. Busse,Ellen C. Caniglia,Yajnaseni Chakraborti,Amy J. Elliott,James E. Gern,Alison E. Hipwell,Catherine J. Karr,Kaja Z. LeWinn,Li Luo,Hans-Georg Müller,Sunni L. Mumford,Ruby H. N. Nguyen,Emily Oken,Janet L. Peacock,Enrique F. Schisterman,Arjun Sondhi,Rosalind J. Wright,Yidong Zhou,Elizabeth L. Ogburn*

Main category: stat.ME

TL;DR: 本文提出了一种敏感性分析框架，用于评估因果效应估计在存在未观测效应修饰因子时的稳健性，并适用于多种可推广性场景。


<details>
  <summary>Details</summary>
Motivation: 未观测的效应修饰因子可能导致在将因果效应估计推广到目标人群时产生偏差，因此需要一种稳健的分析方法来评估这种偏差的影响。

Method: 扩展了敏感性分析框架，适应多种可推广性情景，包括多个随机试验、观察性研究或其组合，并通过假设检验检测可推广性假设的违反情况。

Result: 模拟结果显示所提出的检验方法在真实世界样本量下具有高统计功效，并成功应用于ECHO研究中二手烟暴露对出生体重影响的广义效应估计分析。

Conclusion: 该框架具有良好的解释性，不依赖于对未知参数的分布或函数形式假设，能够有效评估多研究场景下的因果效应推广性。

Abstract: Unobserved effect modifiers can induce bias when generalizing causal effect
estimates to target populations. In this work, we extend a sensitivity analysis
framework assessing the robustness of study results to unobserved effect
modification that adapts to various generalizability scenarios, including
multiple (conditionally) randomized trials, observational studies, or
combinations thereof. This framework is interpretable and does not rely on
distributional or functional assumptions about unknown parameters. We
demonstrate how to leverage the multi-study setting to detect violation of the
generalizability assumption through hypothesis testing, showing with
simulations that the proposed test achieves high power under real-world sample
sizes. Finally, we apply our sensitivity analysis framework to analyze the
generalized effect estimate of secondhand smoke exposure on birth weight using
cohort sites from the Environmental influences on Child Health Outcomes (ECHO)
study.

</details>


### [40] [Leveraging semantic similarity for experimentation with AI-generated treatments](https://arxiv.org/abs/2510.21119)
*Lei Shi,David Arbour,Raghavendra Addanki,Ritwik Sinha,Avi Feller*

Main category: stat.ME

TL;DR: 提出双核表示学习方法，用于捕捉高维处理的潜在结构，并通过交替最小化算法高效学习表示，适用于在线实验中的自适应设计。


<details>
  <summary>Details</summary>
Motivation: 解决在结合人类和模型生成内容的数字实验中，如何表示高维处理而不丢失语义意义或导致分析不可行的问题。

Method: 提出双核表示学习，通过基于核的处理和用户协变量表示的内积建模因果效应，并使用交替最小化算法进行学习。

Result: 开发了具有收敛保证的算法，在低秩因子模型下能有效从数据中学习表示，并通过数值实验验证了其在自适应在线实验设计中的有效性。

Conclusion: 该方法能够有效捕捉高维、语义丰富的处理变量的结构，支持生成有意义的变体并实现在线实验中的自适应分配。

Abstract: Large Language Models (LLMs) enable a new form of digital experimentation
where treatments combine human and model-generated content in increasingly
sophisticated ways. The main methodological challenge in this setting is
representing these high-dimensional treatments without losing their semantic
meaning or rendering analysis intractable. Here, we address this problem by
focusing on learning low-dimensional representations that capture the
underlying structure of such treatments. These representations enable
downstream applications such as guiding generative models to produce meaningful
treatment variants and facilitating adaptive assignment in online experiments.
We propose double kernel representation learning, which models the causal
effect through the inner product of kernel-based representations of treatments
and user covariates. We develop an alternating-minimization algorithm that
learns these representations efficiently from data and provides convergence
guarantees under a low-rank factor model. As an application of this framework,
we introduce an adaptive design strategy for online experimentation and
demonstrate the method's effectiveness through numerical experiments.

</details>


### [41] [Expectation-propagation for Bayesian empirical likelihood inference](https://arxiv.org/abs/2510.21174)
*Kenyon Ng,Weichang Yu,Howard D. Bondell*

Main category: stat.ME

TL;DR: 本文提出了一种基于期望传播的变分方法来近似贝叶斯经验似然后验，解决了传统贝叶斯推断中模型误设和计算复杂度高的问题，在计算成本和准确性之间实现了更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统的贝叶斯推断依赖于参数化模型，当模型设定错误时会导致收敛速度慢和后验校准不可靠。贝叶斯经验似然提供了一种无需明确分布假设的半参数替代方法，但其计算成本高且在小样本下存在后验支持非凸等问题。因此，需要一种更高效且准确的近似方法。

Method: 提出一种基于期望传播（expectation-propagation）的变分推断方法，用于近似贝叶斯经验似然的后验分布。该方法避免了为每个似然评估求解约束优化问题，并不引入伪观测等调整手段，保持目标后验不变。

Result: 实验表明，该方法在成本-精度权衡上优于现有的哈密尔顿蒙特卡洛和变分贝叶斯方法；理论上证明了该近似与贝叶斯经验似然后验在渐近意义下等价。

Conclusion: 所提出的期望传播变分方法在保持理论一致性的同时显著提升了贝叶斯经验似然的计算效率，是一种有效且可靠的后验近似方案。

Abstract: Bayesian inference typically relies on specifying a parametric model that
approximates the data-generating process. However, misspecified models can
yield poor convergence rates and unreliable posterior calibration. Bayesian
empirical likelihood offers a semi-parametric alternative by replacing the
parametric likelihood with a profile empirical likelihood defined through
moment constraints, thereby avoiding explicit distributional assumptions.
Despite these advantages, Bayesian empirical likelihood faces substantial
computational challenges, including the need to solve a constrained
optimization problem for each likelihood evaluation and difficulties with
non-convex posterior support, particularly in small-sample settings. This paper
introduces a variational approach based on expectation-propagation to
approximate the Bayesian empirical-likelihood posterior, balancing
computational cost and accuracy without altering the target posterior via
adjustments such as pseudo-observations. Empirically, we show that our approach
can achieve a superior cost-accuracy trade-off relative to existing methods,
including Hamiltonian Monte Carlo and variational Bayes. Theoretically, we show
that the approximation and the Bayesian empirical-likelihood posterior are
asymptotically equivalent.

</details>


### [42] [Forecast reconciliation with non-linear constraints](https://arxiv.org/abs/2510.21249)
*Daniele Girolimetto,Anastasios Panagiotelis,Tommaso Di Fonzo,Han Li*

Main category: stat.ME

TL;DR: 本文提出了非线性约束协调（NLCR）方法，用于调整不符合非线性约束的时间序列预测结果，并在人口统计学和经济学数据上显著提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法多关注线性约束，而实际中许多变量（如死亡率、失业率）受非线性约束影响，如何有效处理此类问题尚属开放课题。

Method: 提出非线性约束协调（NLCR）算法，通过将预测结果投影到非线性曲面上，以解决非线性约束下的预测协调问题；该过程被建模为一个约束优化问题。

Result: 推导了保证NLCR提升预测精度的充分条件，并在两个真实数据集（人口与经济）上验证了其相较于基准方法显著提升了预测准确性。

Conclusion: NLCR为非线性约束时间序列预测提供了有效解决方案，在理论和实证层面均证明了其优越性，拓展了预测协调方法的应用范围。

Abstract: Methods for forecasting time series adhering to linear constraints have seen
notable development in recent years, especially with the advent of forecast
reconciliation. This paper extends forecast reconciliation to the open question
of non-linearly constrained time series. Non-linear constraints can emerge with
variables that are formed as ratios such as mortality rates and unemployment
rates. On the methodological side, Non-linearly Constrained Reconciliation
(NLCR) is proposed. This algorithm adjusts forecasts that fail to meet
non-linear constraints, in a way that ensures the new forecasts meet the
constraints. The NLCR method is a projection onto a non-linear surface,
formulated as a constrained optimisation problem. On the theoretical side,
optimisation methods are again used, this time to derive sufficient conditions
for when the NLCR methodology is guaranteed to improve forecast accuracy.
Finally on the empirical side, NLCR is applied to two datasets from demography
and economics and shown to significantly improve forecast accuracy relative to
relevant benchmarks.

</details>


### [43] [A Comparison for Non-Specialists of Workflow Steps and Similarity of Factor Rankings for Several Global Sensitivity Analysis Methods](https://arxiv.org/abs/2510.21579)
*Ken Newman,Shaini Naha,Leah Jackson-Blake,Cairistiona Topp,Miriam Glendell,Adam Butler*

Main category: stat.ME

TL;DR: 本文研究了多种全局敏感性分析（GSA）方法在不同复杂度模拟器上的应用，比较了方法间的因子排序一致性、输出解释性及实施难点，发现Sobol指数和回归树表现良好。


<details>
  <summary>Details</summary>
Motivation: 帮助非GSA专家在众多GSA方法中做出选择，解决方法在工作流程、结果解释和因子排序一致性方面的挑战。

Method: 应用广泛和较少使用的GSA方法于三个不同复杂度的模拟器，使用Kendall's W评估因子排序的相似性，并分析各方法在实现和解释上的优劣。

Result: 各GSA方法在因子排序上具有较高一致性；参数范围设定对实施至关重要；Sobol一阶和总敏感性指数易于解释且信息丰富；回归树有助于理解输入变量间的交互作用。

Conclusion: Sobol指数和回归树是推荐用于GSA的方法，同时明确参数范围对所有GSA方法的成功应用至关重要。

Abstract: Global sensitivity analysis (GSA) is a recommended step in the use of
computer simulation models. GSA quantifies the relative importance of model
inputs on outputs (Factor Ranking), identifies inputs that could be fixed, thus
simplifying model calibration (Factor Fixing), and pinpointing areas for future
data collection (Factor Prioritization). Given the wide variety of GSA methods,
choosing between methods can be challenging for non-GSA experts. Issues include
workflow steps and complexity, interpretation of GSA outputs, and the degree of
similarity between methods in Factor Ranking. We conducted a study of both
widely and less commonly used GSA methods applied to three simulators of
differing complexity. All methods share common issues around implementation
with specification of parameter ranges particularly critical. Similarities in
Factor Rankings were generally high based on Kendall's W. Sobol' first order
and total sensitivity indices were easy to interpret and informative with
regression trees providing additional insight into interactions.

</details>


### [44] [MECfda: An R Package for Bias Correction Due to Measurement Error in Functional and Scalar Covariates in Scalar-on-Function Regression Models](https://arxiv.org/abs/2510.21661)
*Heyang Ji,Carmen Tekwe*

Main category: stat.ME

TL;DR: MECfda是一个R包，用于拟合多种函数型回归模型，并在校正函数协变量测量误差的情况下提供无偏估计，适用于处理噪声功能数据的功能数据分析。


<details>
  <summary>Details</summary>
Motivation: 由于设备采集的物理活动或睡眠数据虽客观但存在测量误差，需要一种能够校正此类误差并进行稳健推断的工具。

Method: 开发了MECfda R包，统一支持标量对函数回归、广义标量对函数回归和分位数函数回归模型，并引入偏差校正方法以处理带有测量误差的函数协变量。

Result: MECfda实现了对带噪声功能数据的准确建模与无偏估计，提升了功能数据分析在实际应用中的可靠性。

Conclusion: MECfda通过整合多种回归模型和误差校正方法，为存在测量误差的功能性数据提供了有效的分析工具。

Abstract: Functional data analysis (FDA) deals with high-resolution data recorded over
a continuum, such as time, space or frequency. Device-based assessments of
physical activity or sleep are objective yet still prone to measurement error.
We present MECfda, an R package that (i) fits scalar-on-function, generalized
scalar-on-function, and functional quantile regression models, and (ii)
provides bias-corrected estimation when functional covariates are measured with
error. By unifying these tools under a consistent syntax, MECfda enables robust
inference for FDA applications that involve noisy functional data.

</details>


### [45] [Optimal weighted tests for replication studies and the two-trials rule](https://arxiv.org/abs/2510.21708)
*David S. Robertson,Thomas Jaki*

Main category: stat.ME

TL;DR: 本文提出了一种基于原始研究结果的最优加权Bonferroni方法，用于分析重复性研究，以最大化试验的析取功效，并证明该方法能显著提高重复研究的功效且对效应量变化具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了提高重复性研究的统计功效并确保多重假设检验中的家族错误率控制，需要一种更有效的分析方法。

Method: 采用基于原始研究结果设定权重的最优加权Bonferroni方法，优化目标为最大化析取功效（即至少拒绝一个非零假设的能力）。

Result: 所提出的方法能够显著提高重复研究的析取功效，并且对两研究间效应量的变化具有较强的鲁棒性。

Conclusion: 使用基于原始研究结果的最优加权Bonferroni程序可有效提升重复研究的统计功效，是一种可靠且高效的多重假设检验控制方法。

Abstract: Replication studies for scientific research are an important part of ensuring
the reliability and integrity of experimental findings. In the context of
clinical trials, the concept of replication has been formalised by the
'two-trials' rule, where two pivotal studies are required to show positive
results before a drug can be approved. In experiments testing multiple
hypotheses simultaneously, control of the overall familywise error rate (FWER)
is additionally required in many contexts. The well-known Bonferroni procedure
controls the FWER, and a natural extension is to introduce weights into this
procedure to reflect the a-priori importance of hypotheses or to maximise some
measure of the overall power of the experiment. In this paper, we consider
analysing a replication study using an optimal weighted Bonferroni procedure,
with the weights based on the results of the original study that is being
replicated and the optimality criterion being to maximise the disjunctive power
of the trial (the power to reject at least one non-null hypothesis). We show
that using the proposed procedure can lead to a substantial increase in the
disjunctive power of the replication study, and is robust to changes in the
effect sizes between the two studies.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [46] [Safety Monitor for Off-Road Planning with Uncertainty Bounded Bekker Costs](https://arxiv.org/abs/2510.21006)
*Akshay Naik,Ramavarapu S. Sreenivas,William R. Norris,Albert E. Patterson,Ahmet Soylemezoglu,Dustin Nottage*

Main category: eess.SY

TL;DR: 本文提出了一种用于非铺装路面自动驾驶的安全监控方法，通过结合Bekker成本模型与不确定性边界，在运行时评估车辆行驶风险，并在必要时触发安全降级策略以确保不超出沉陷和翻车的安全限值。


<details>
  <summary>Details</summary>
Motivation: 在土壤强度不确定的情况下，保障非铺装路面自动驾驶的可靠性和安全性，防止因地形估计不准导致的沉陷或翻车事故。

Method: 采用基于Bekker模型的置信上限遍历成本方法，结合轻量级压力-沉陷模型，在线识别并预测最大沉陷与侧倾裕度；监控器实时检查规划动作，超出风险阈值时切换至预认证的降级模式（如减速、避让松软地面或停车）。

Result: 仿真结果显示该方法在不同土壤条件下能有效降低违规概率，控制干预频率，并保持路径效率；台架静态加载测试提供了初步实验验证。

Conclusion: 该安全监控框架可嵌入车载系统，解耦了规划器的效率目标与运行时安全约束，支持基于车辆设计参数和实时土壤信息动态设定速度、曲率和停车策略，具有工程实用性。

Abstract: Reliable off-road autonomy requires operational constraints so that behavior
stays predictable and safe when soil strength is uncertain. This paper presents
a runtime assurance safety monitor that collaborates with any planner and uses
a Bekker-based cost model with bounded uncertainty. The monitor builds an upper
confidence traversal cost from a lightweight pressure sinkage model identified
in field tests and checks each planned motion against two limits: maximum
sinkage and rollover margin. If the risk of crossing either limit is too high,
the monitor switches to a certified fallback that reduces vehicle speed,
increases standoff from soft ground, or stops on firmer soil. This separation
lets the planner focus on efficiency while the monitor keeps the vehicle within
clear safety limits on board. Wheel geometry, wheel load estimate, and a soil
raster serve as inputs, which tie safety directly to vehicle design and let the
monitor set clear limits on speed, curvature, and stopping at run time. The
method carries uncertainty analytically into the upper confidence cost and
applies simple intervention rules. Tuning of the sinkage limit, rollover
margin, and risk window trades efficiency for caution while keeping the monitor
light enough for embedded processors. Results from a simulation environment
spanning loam to sand include intervention rates, violation probability, and
path efficiency relative to the nominal plan, and a benchtop static loading
check provides initial empirical validation.

</details>


### [47] [The Role of Information Incompleteness in Defending Against Stealth Attacks](https://arxiv.org/abs/2510.21227)
*Ke Sun,Jingyi Yan,Zhenglin Li,Shaorong Xie*

Main category: eess.SY

TL;DR: 本文研究了在数据注入攻击中，系统信息不完整性对攻击隐蔽性和破坏性的权衡影响，提出了通过增强信息不完整性来削弱攻击效果的防御策略，并设计了优化方法与启发式算法进行验证。


<details>
  <summary>Details</summary>
Motivation: 由于数据注入攻击的效果高度依赖于攻击者获取的系统信息完整性，因此提升信息不完整性可作为一种关键防御手段，以降低攻击的隐蔽性与破坏性。

Method: 通过信息论方法分析不完全导纳信息对攻击隐蔽性和破坏性的双重影响，建立两种不同运行模式的充分条件，并提出最大不完整性策略及相应的优化算法，在缩减可行域后使用启发式算法求解近似最优解。

Result: 理论分析得出了信息不完整性能有效削弱攻击性能的条件，仿真结果表明所提策略能显著降低攻击的隐蔽性，同时控制其破坏性。

Conclusion: 增强系统信息的不完整性是一种有效的防御机制，可在特定条件下同时优化攻击的隐蔽性与破坏性之间的权衡，为电力系统安全提供了新的防护思路。

Abstract: The effectiveness of Data Injections Attacks (DIAs) critically depends on the
completeness of the system information accessible to adversaries. This
relationship positions information incompleteness enhancement as a vital
defense strategy for degrading DIA performance. In this paper, we focus on the
information-theoretic stealth attacks, where the attacker encounters a
fundamental tradeoff between the attack stealthiness and destructiveness.
Specifically, we systematically characterize how incomplete admittance
information impacts the dual objectives. In particular, we establish sufficient
conditions for two distinct operational regimes: (i) stealthiness intensifies
while destructive potential diminishes and (ii) destructiveness increases while
stealth capability weakens. For scenarios beyond these regimes, we propose a
maximal incompleteness strategy to optimally degrade stealth capability. To
solve the associated optimization problem, the feasible region is reduced
without excluding the optimal solution, and a heuristic algorithm is then
introduced to effectively identify the near-optimal solutions within the
reduced region. Numerical simulations are conducted on IEEE test systems to
validate the findings.

</details>


### [48] [The PhasorArray Toolbox for Harmonic Analysis and Control Design](https://arxiv.org/abs/2510.21294)
*Maxime Grosso,Pierre Riedinger,Jamal Daafouz*

Main category: eess.SY

TL;DR: 本文介绍了一个名为PhasorArray Toolbox的MATLAB工具包，旨在简化谐波分析与控制方法的使用，具备面向对象架构和高级功能。


<details>
  <summary>Details</summary>
Motivation: 为了使谐波分析和控制方法更加实用和用户友好，开发该工具箱以降低复杂周期系统建模与分析的门槛。

Method: 采用面向对象架构，重载加法、乘法、卷积等运算符，并支持自动Toeplitz矩阵构造，集成YALMIP以实现基于线性矩阵不等式（LMI）的高级控制与分析。

Result: 实现了谐波Sylvester、Lyapunov和Riccati方程求解器，并提供了直观、高效的周期矩阵操作方式。

Conclusion: PhasorArray Toolbox为谐波域内的系统分析与控制设计提供了一个强大且易于使用的平台。

Abstract: We present a MATLAB package called the Pha-sorArray Toolbox that has been
developed to make harmonic analysis and control methods both practical and
user-friendly. The toolbox adopts an object-oriented architecture that enables
intuitive manipulation of periodic matrices through overloaded operators for
addition, multiplication, convolution, and automatic Toeplitz construction. Its
advanced features include harmonic Sylvester, Lyapunov and Riccati equations
solvers, and seamless integration with YALMIP, thereby facilitating advanced
control and analysis techniques based on Linear Matrix Inequalities (LMIs) in
the harmonic framework.

</details>


### [49] [Data-driven Koopman MPC using Mixed Stochastic-Deterministic Tubes](https://arxiv.org/abs/2510.21308)
*Zhengang Zhong,Ehecatl Antonio del Rio-Chanona,Panagiotis Petsagkourakis*

Main category: eess.SY

TL;DR: 本文提出了一种基于Koopman算子和分布鲁棒优化（DRO）框架的数据驱动随机模型预测控制（MPC）方法，用于处理具有加性扰动的离散时间非线性系统。通过将系统提升到线性空间并构造混合随机-确定性管，确保系统在满足约束下的稳定调节，并通过数值仿真验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 针对非线性系统在存在建模误差和扰动时难以实现高效、鲁棒控制的问题，本文旨在提出一种结合数据驱动与鲁棒优化的新型MPC设计方法。

Method: 利用Koopman算子将非线性动态系统提升为线性系统，采用有限维近似；结合分布鲁棒优化（DRO）构建随机管，使用超立方体包络构建确定性管，形成混合管以同时处理建模误差和加性扰动。

Result: 提出了混合随机-确定性管的构造方法，并给出了两种管的有限样本误差界；通过数值仿真验证了该方法在约束满足和系统调节方面的有效性。

Conclusion: 所提出的数据驱动DRO-MPC方法能够有效处理非线性系统的建模误差与扰动，在保证约束的同时实现良好控制性能，具有较强的鲁棒性和应用潜力。

Abstract: This paper presents a novel data-driven stochastic MPC design for
discrete-time nonlinear systems with additive disturbances by leveraging the
Koopman operator and a distributionally robust optimization (DRO) framework. By
lifting the dynamical system into a linear space, we achieve a
finite-dimensional approximation of the Koopman operator. We explicitly account
for the modeling approximation and additive disturbance error by a mixed
stochastic-deterministic tube for the lifted linear model. This ensures the
regulation of the original nonlinear system while complying with the
prespecified constraints. Stochastic and deterministic tubes are constructed
using a DRO and a hyper-cube hull, respectively. We provide finite sample error
bounds for both types of tubes. The effectiveness of the proposed approach is
demonstrated through numerical simulations.

</details>


### [50] [Predictive control barrier functions for piecewise affine systems with non-smooth constraints](https://arxiv.org/abs/2510.21321)
*Kanghui He,Anil Alan,Shengling Shi,Ton van den Boom,Bart De Schutter*

Main category: eess.SY

TL;DR: 本文提出了一种基于广义Clarke导数的预测安全滤波器设计方法，用于解决非光滑、非仿射系统在复杂约束下的安全控制问题，并通过显式近似降低计算负担。


<details>
  <summary>Details</summary>
Motivation: 针对非光滑系统和非仿射系统的安全控制中传统控制屏障函数（CBF）方法存在的梯度未定义和计算复杂问题，亟需一种能处理不连续性和非线性约束的安全控制框架。

Method: 采用分段仿射系统建模，结合预测安全滤波器（PSF），引入集值广义Clarke导数来定义CBF约束，并提出显式的PSF近似方法以提升实时计算效率。

Result: 理论证明了在所有广义Clarke导数元素上施加CBF约束可保证系统安全性，数值实验验证了所提方法的有效性和计算优势。

Conclusion: 该方法有效扩展了CBF在非光滑、非仿射系统中的应用范围，兼顾安全性与实时性，为复杂系统的安全控制提供了可行解决方案。

Abstract: Obtaining control barrier functions (CBFs) with large safe sets for complex
nonlinear systems and constraints is a challenging task. Predictive CBFs
address this issue by using an online finite-horizon optimal control problem
that implicitly defines a large safe set. The optimal control problem, also
known as the predictive safety filter (PSF), involves predicting the system's
flow under a given backup control policy. However, for non-smooth systems and
constraints, some key elements, such as CBF gradients and the sensitivity of
the flow, are not well-defined, making the current methods inadequate for
ensuring safety. Additionally, for control-non-affine systems, the PSF is
generally nonlinear and non-convex, posing challenges for real-time
computation. This paper considers piecewise affine systems, which are usually
control-non-affine, under nonlinear state and polyhedral input constraints. We
solve the safety issue by incorporating set-valued generalized Clarke
derivatives in the PSF design. We show that enforcing CBF constraints across
all elements of the generalized Clarke derivatives suffices to guarantee
safety. Moreover, to lighten the computational overhead, we propose an explicit
approximation of the PSF. The resulting control methods are demonstrated
through numerical examples.

</details>


### [51] [System-Theoretic Analysis of Dynamic Generalized Nash Equilibrium Problems -- Turnpikes and Dissipativity](https://arxiv.org/abs/2510.21556)
*Sophie Hall,Florian Dörfler,Timm Faulwasser*

Main category: eess.SY

TL;DR: 本文从系统理论的角度研究了广义纳什均衡（GNE）的开环轨迹性质，揭示了严格耗散性与GNE解中“中枢现象”之间的关系，并提出了确保GNE轨迹收敛到稳态的线性终端惩罚设计方法。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和分析多智能体系统中耦合成本、动态和约束下的战略互动，需要从系统理论角度深入研究广义纳什均衡的动态特性。

Method: 通过严格耗散性理论分析GNE轨迹的中枢现象，建立从中枢现象到严格耗散性的逆向结果，并利用博弈值函数对存储函数的局部几何结构进行刻画，设计线性终端惩罚以保证收敛性。

Result: 证明了严格耗散性导致GNE解中的中枢现象，并实现了从中枢现象反推严格耗散性的 converse 结果；给出了稳态GNE为最优运行点的条件，并设计了确保轨迹收敛到稳态的线性终端惩罚。

Conclusion: 严格耗散性是理解GNE动态行为的关键，所提出的系统理论框架为未来类似最优控制中的GNE分析奠定了基础。

Abstract: Generalized Nash equilibria are used in multi-agent control applications to
model strategic interactions between agents that are coupled in the cost,
dynamics, and constraints. We study the properties of open-loop GNE
trajectories from a system-theoretic perspective. We show how strict
dissipativity generates the turnpike phenomenon in GNE solutions. Moreover, we
establish a converse turnpike result, i.e., the implication from turnpike to
strict dissipativity. We derive conditions under which the steady-state GNE is
the optimal operating point and, using a game value function, we give a local
characterization of the geometry of storage functions. Finally, we design
linear terminal penalties that ensure GNE open-loop trajectories converge to
and remain at the steady-state GNE. These connections provide the foundation
for future system-theoretic analysis of GNEs similar to those existing in
optimal control.

</details>


### [52] [Rate-cost tradeoffs in continuous-time control with a biomolecular application](https://arxiv.org/abs/2510.21612)
*Yorie Nakahira,Fangzhou Xiao,Victoria Kostina,John C. Doyle*

Main category: eess.SY

TL;DR: 本文研究了广义Ornstein-Uhlenbeck过程在速率受限下的控制问题，推导了实现目标控制成本所需的数据率下限，并讨论了其在生物分子系统控制中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了理解在通信速率受限的情况下如何有效控制具有乘性和加性控制作用的广义Ornstein-Uhlenbeck过程，并将其应用于生物分子系统的调控。

Method: 通过信息论方法推导数据率下限，并分析加性高斯白噪声信道下的控制性能。

Result: 得到了实现期望控制成本所需的数据率下限，且在通过加性高斯白信道进行控制时可达到该下限。

Conclusion: 该结果为通过化学反应控制生物分子系统提供了理论基础，特别是在减少分子浓度波动方面具有实际意义。

Abstract: This paper focuses on rate-limited control of the generalized
Ornstein-Uhlenbeck process where the control action can be either
multiplicative or additive, and the noise variance can depend on the control
action. We derive a lower bound on the data rate necessary to achieve the
desired control cost. The lower bound is attained with equality if the control
is performed via an additive white Gaussian channel. The system model
approximates the dynamics of a discrete-state molecular birth-death process,
and the result has direct implications on the control of a biomolecular system
via chemical reactions, where the multiplicative control corresponds to the
degradation rate, the additive control corresponds to the production rate, and
the control objective is to decrease the fluctuations of the controlled
molecular species around their desired concentration levels.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [53] [Tensor Renormalization-Group study of the surface critical behavior of a frustrated two-layer Ising model](https://arxiv.org/abs/2510.21269)
*Christophe Chatelain*

Main category: cond-mat.stat-mech

TL;DR: 研究了通过受挫自旋-自旋相互作用耦合的二维伊辛模型双层系统的表面临界行为，发现其表面磁标度维数的二重简并被解除，并满足一种简单的对偶关系。


<details>
  <summary>Details</summary>
Motivation: 探索受挫双层伊辛模型的表面临界行为，特别是其与Ashkin-Teller模型的异同。

Method: 使用张量重整化群方法，扩展了适用于有边界系统的键权张量重整化群算法进行数值研究。

Result: 发现F2LIM中表面磁标度维数的二重简并被解除，且两个不同的标度维数满足对偶关系x_1^s = 1/(4x_2^s)，这是由于单个伊辛副本在自旋反转下的Z2对称性破缺所致。

Conclusion: 受挫双层伊辛模型的表面临界行为表现出新的标度特性，揭示了对称性破缺在表面临界现象中的重要作用。

Abstract: Two replicas of a 2D Ising model are coupled by frustrated spin-spin
interactions. It is known that this inter-layer coupling is marginal and that
the bulk critical behavior belongs to the Ashkin-Teller (AT) universality
class, as the $J_1$-$J_2$ Ising model. In this work, the surface critical
behavior is studied numerically by Tensor Renormalization-Group calculations.
The Bond-Weight Tensor Renormalization Group algorithm is extended to tackle
systems with boundaries. It is observed that the two-fold degeneracy of the
surface magnetic scaling dimension of the AT model is lifted in the frustrated
two-layer Ising model (F2LIM). The splitting is explained by the breaking of
the ${\mathbb Z}_2$-symmetry under spin reversal of a single Ising replica in
the F2LIM. The two distinct surface magnetic scaling dimensions $x_1^s$ and
$x_2^s$ of the F2LIM satisfies a simple duality relation $x_1^s=1/4x_2^s$.

</details>


### [54] [Faradaic and capacitive charging of an electrolyte-filled pore in response to a small applied potential](https://arxiv.org/abs/2510.21336)
*Timur Aslyamov,Massimiliano Esposito,Mathijs Janssen*

Main category: cond-mat.stat-mech

TL;DR: 研究了电化学器件中法拉第反应与双电层形成的耦合过程，通过渐近近似求解耦合的Poisson-Nernst-Planck和Frumkin-Butler-Volmer方程，提出了早期时间的扩展法拉第传输线模型，并在长时间极限下给出了零电荷电位的新表达式，可用于实验测量法拉第对零电荷电位的贡献。


<details>
  <summary>Details</summary>
Motivation: 理解电化学器件中法拉第反应与双电层充电的耦合机制，并揭示接近平衡电位时系统的动态行为。

Method: 采用小参数渐近近似方法，求解耦合的Poisson-Nernst-Planck方程和Frumkin-Butler-Volmer方程，基于孔隙的低反 aspect ratio 进行简化分析。

Result: 早期阶段得到包含电压源和法拉第电阻的扩展传输线模型；长时间下发现非平凡的零电荷电位表达式：Ψ_pzc = Ψ_eq[1 - Ẑ(0)/R_F]，其中Ẑ(0)为系统零频阻抗。

Conclusion: 该模型为实验上分离并测量法拉第效应对零电荷电位的贡献提供了新途径。

Abstract: Electrochemical devices often charge both through Faradaic reactions and
electric double layer formation. Here, we study these coupled processes in a
model system of a long electrolyte-filled pore subject to a small
suddenly-applied potential, close to the equilibrium potential $\Psi^\text{eq}$
at which there is no net Faradaic charge transfer. Specifically, we solve the
coupled Poisson-Nernst-Planck and Frumkin-Butler-Volmer equations by asymptotic
approximations, using the pore's small inverse aspect ratio as the small
parameter. In the early-time limit, the reaction-diffusion equations yield an
extended Faradaic transmission line model that includes a voltage source,
$\Psi_\text{eq}$, biasing the Faradaic reactions, captured by the resistance
$R_F$. In the long-time limit, the model exhibits a nontrivial potential of
zero charge, $\Psi_\text{pzc} = \Psi_\text{eq}[1 - \hat{Z}(0)/R_F]$, where
$\hat{Z}(0)$ is the experimentally accessible zero-frequency impedance of the
system. This expression provides a new means to experimentally measure the
Faradaic contribution to $\Psi_\text{pzc}$.

</details>


### [55] [Koopman Mode Decomposition of Thermodynamic Dissipation in Nonlinear Langevin Dynamics](https://arxiv.org/abs/2510.21340)
*Daiki Sekizawa,Sosuke Ito,Masafumi Oizumi*

Main category: cond-mat.stat-mech

TL;DR: 本文利用Koopman模态分解方法，将非线性动力学系统中的振荡模式与热力学耗散联系起来，揭示了各振荡模式的耗散与其频率平方和强度成正比，为理解噪声环境下非线性振荡系统的耗散机制提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 非线性振荡在远离平衡的复杂系统中普遍存在，但其振荡特性（如频率、幅度）如何影响热力学耗散尚不明确，尤其是在非线性动力学和噪声干扰下，缺乏有效的分析工具。

Method: 采用Koopman模态分解方法，将非线性动力学转化为函数空间中的线性演化，从而将过阻尼非线性Langevin动力学中的非保守力引起的热力学耗散分解为各振荡模式的贡献。

Result: 发现每个振荡模式的耗散与其频率的平方和强度成正比；在FitzHugh-Nagumo模型中验证了该框架的有效性，揭示了随机共振最优噪声强度下耗散由宽频谱支持，而非最优条件下则由特定频率主导。

Conclusion: 该工作提供了一种将非线性振荡特征与热力学耗散关联起来的通用方法，增强了从非平衡热力学角度理解复杂振荡现象的能力。

Abstract: Nonlinear oscillations are commonly observed in complex systems far from
equilibrium, such as living organisms. These oscillations are essential for
sustaining vital processes, like neuronal firing, circadian rhythms, and
heartbeats. In such systems, thermodynamic dissipation is necessary to maintain
oscillations against noise. However, due to their nonlinear dynamics, it has
been challenging to determine how the characteristics of oscillations, such as
frequency, amplitude, and coherent patterns across elements, influence
dissipation. To resolve this issue, we employ Koopman mode decomposition, which
recasts nonlinear dynamics as a linear evolution in a function space. This
linearization allows the dynamics to be decomposed into temporal oscillatory
modes coherent across elements, with the Koopman eigenvalues determining their
frequencies. Using this method, we decompose thermodynamic dissipation caused
by nonconservative forces into contributions from oscillatory modes in
overdamped nonlinear Langevin dynamics. We show that the dissipation from each
mode is proportional to its frequency squared and its intensity, providing an
interpretable, mode-by-mode picture. In the noisy FitzHugh--Nagumo model, we
demonstrate the effectiveness of this framework in quantifying the impact of
oscillatory modes on dissipation during nonlinear phenomena like stochastic
resonance and bifurcation. For instance, our analysis of stochastic resonance
reveals that the greatest dissipation at the optimal noise intensity is
supported by a broad spectrum of frequencies, whereas at non-optimal noise
levels, dissipation is dominated by specific frequency modes. Our work offers a
general approach to connecting oscillations to dissipation in noisy
environments and improves our understanding of diverse oscillation phenomena
from a nonequilibrium thermodynamic perspective.

</details>


### [56] [Beyond Poisson: First-Passage Asymptotics of Renewal Shot Noise](https://arxiv.org/abs/2510.21670)
*Julien Brémont*

Main category: cond-mat.stat-mech

TL;DR: 本文突破了非泊松到达统计下更新脉冲噪声首达时间分析的长期障碍，提出了适用于一般到达统计和指数标记的首达时间均值的普适渐近公式，揭示了短时间间隔分布行为对阈值穿越的加速效应，并证明在高阈值下首达时间分布趋于指数分布。


<details>
  <summary>Details</summary>
Motivation: 由于在神经元放电、基因表达等实际应用中普遍存在非泊松到达统计，而首达时间的解析结果长期局限于泊松情况，因此需要建立适用于更广泛非马尔可夫系统的理论框架。

Method: 通过发展一种新的关于噪声矩的精确解法，推导出具有通用到达统计和指数标记的更新脉冲噪声模型的首达时间均值的闭式渐近表达式，并结合数值模拟验证全分布的指数收敛性。

Result: 得到了首达时间均值的普适渐近公式，发现短时间间隔分布行为会引入从拉伸指数到代数形式的普适标度修正，显著加速阈值穿越过程；同时表明在大阈值极限下，首达时间分布趋于指数分布，均值足以完全刻画其渐近行为。

Conclusion: 本文建立了分析具松弛机制的非马尔可夫系统中极端事件的通用框架，为处理广泛存在于物理、生物和金融中的非泊松首达问题提供了基础性工具。

Abstract: The first-passage time (FPT) of a stochastic signal to a threshold is a
fundamental observable across physics, biology, and finance. While renewal shot
noise is a canonical model for such signals, analytical results for its FPT
have remained confined to the Poisson (Markovian) case, despite the prevalence
of non-Poisson arrival statistics in applications from neuronal spiking to gene
expression. We break this long-standing barrier by deriving the first universal
asymptotic formula for the mean FPT $\langle T_b \rangle$ to reach level $b$
for renewal shot noise with general arrival statistics and exponential marks.
Our central result is a closed-form expression that reveals precisely how
general inter-arrival statistics impact the naive Arrhenius law. We show that
the short-time behavior of the interarrival distribution dictates universal
scaling corrections, ranging from stretched-exponential to algebraic, that can
dramatically accelerate threshold crossing. Furthermore, we argue and confirm
numerically that the full FPT distribution becomes exponential at large
thresholds, implying that $\langle T_b \rangle$ provides a complete asymptotic
characterization. Our work, enabled by a novel exact solution for the moments
of the noise, establishes a general framework for analyzing extreme events in
non-Markovian systems with relaxation.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [57] [A Convex Optimization Approach to the Discrete Hanging Chain Problem](https://arxiv.org/abs/2510.20917)
*Russell Gabrys,Stefan Sremac*

Main category: math.OC

TL;DR: 本文研究了经典悬链问题的离散版本，推广到每节链具有任意质量和长度的情况，并表明其形状可通过求解凸优化问题获得。在链节对称时，问题可进一步简化为求解一个非线性方程。


<details>
  <summary>Details</summary>
Motivation: 将经典连续悬链问题离散化并推广到非均匀链节，以更贴近实际物理系统。

Method: 通过建立离散模型，将悬链形状问题转化为凸优化问题，并利用最优性条件进行简化。

Result: 证明离散悬链形状可通过凸优化求解；在对称条件下，问题可归约为单个非线性方程。

Conclusion: 离散悬链问题可有效建模为优化问题，对称情况下存在进一步简化的解析途径。

Abstract: In this paper we investigate the discrete version of the classical hanging
chain problem. We generalize the problem, by allowing for arbitrary mass and
length of each link. We show that the shape of the chain can be obtained by
solving a convex optimization problem. Then we use optimality conditions to
show that the problem can be further reduced to solving a single non-linear
equation, when the links of the chain have symmetric mass and length.

</details>


### [58] [MOCVXPY: a CVXPY extension for multiobjective optimization](https://arxiv.org/abs/2510.21010)
*Ludovic Salomon,Daniel Dörfler,Andreas Löhne*

Main category: math.OC

TL;DR: MOCVXPY是一个基于CVXPY的开源Python库，用于凸向量优化，支持直观的代数语言描述问题，并应用于金融和能源领域的实际案例。


<details>
  <summary>Details</summary>
Motivation: 为凸向量优化问题提供一个易于使用、贴近数学表达的开源工具，扩展CVXPY在多目标优化中的应用。

Method: 基于CVXPY构建，采用代数建模语言描述凸向量优化问题，并集成求解算法处理多目标优化。

Result: 实现了MOCVXPY库，提供了示例和两个真实应用（金融与能源），并公开发布于GitHub。

Conclusion: MOCVXPY有效支持凸向量优化问题的建模与求解，具有良好的可读性和实用性，适用于多领域多目标优化需求。

Abstract: MOCVXPY is an open-source Python library for convex vector optimization. It
is built on top of CVXPY, a domain-specific language for single-objective
convex optimization. MOCVXPY enables practitioners to describe their convex
vector optimization problem in an intuitive algebraic language, that closely
follows the mathematical formulation. This work presents the main features of
MOCVXPY, explains some background of the algorithms it employs to solve the
optimization problems, and illustrates its functionality through examples and
two real-world applications in finance and energy. MOCVXPY is available at
https://github.com/salomonl/mocvxpy under the Apache 2.0 licence, with some
documentation and examples.

</details>


### [59] [Iso-Riemannian Optimization on Learned Data Manifolds](https://arxiv.org/abs/2510.21033)
*Willem Diepeveen,Melanie Weber*

Main category: math.OC

TL;DR: 本文提出了一种基于iso-Riemannian几何的优化框架，用于在学习到的数据流形上进行优化，解决了传统Riemannian优化中测地线速度不恒定和凸性假设失效的问题，通过引入新的单调性和Lipschitz连续性概念，设计了具有收敛性分析的iso-Riemannian下降算法，并在合成和真实数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在高维数据中普遍存在内在低维结构，但如何在学习到的流形上有效进行优化仍具挑战，特别是传统Riemannian方法在实际使用的pullback结构下存在测地线非恒速和凸性假设失效的问题。

Method: 提出iso-Riemannian几何框架，定义适配该几何的新单调性和Lipschitz连续性概念，并设计相应的iso-Riemannian下降算法，提供详细的收敛性分析。

Result: 算法在合成和真实数据（如MNIST）上表现出色，能够生成可解释的中心点、改进聚类效果，并高效求解逆问题，即使在高维情况下也有效。

Conclusion: iso-Riemannian几何能够克服学习流形映射中的固有失真，为在学习流形上的优化提供了可靠且有效的理论与算法基础。

Abstract: High-dimensional data that exhibit an intrinsic low-dimensional structure are
ubiquitous in machine learning and data science. While various approaches allow
for learning the corresponding data manifold from finite samples, performing
downstream tasks such as optimization directly on these learned manifolds
presents a significant challenge. This work introduces a principled framework
for optimization on learned data manifolds using iso-Riemannian geometry. Our
approach addresses key limitations of classical Riemannian optimization in this
setting, specifically, that the Levi-Civita connection fails to yield
constant-speed geodesics, and that geodesic convexity assumptions break down
under the learned pullback constructions commonly used in practice. To overcome
these challenges, we propose new notions of monotonicity and Lipschitz
continuity tailored to the iso-Riemannian setting and propose iso-Riemannian
descent algorithms for which we provide a detailed convergence analysis. We
demonstrate the practical effectiveness of those algorithms on both synthetic
and real datasets, including MNIST under a learned pullback structure. Our
approach yields interpretable barycentres, improved clustering, and provably
efficient solutions to inverse problems, even in high-dimensional settings.
These results establish that optimization under iso-Riemannian geometry can
overcome distortions inherent to learned manifold mappings.

</details>


### [60] [Reliability-Aware Control of Distributed Energy Resources using Multi-Source Data Models](https://arxiv.org/abs/2510.21062)
*Gejia Zhang,Robert Mieth*

Main category: math.OC

TL;DR: 本文提出了一种基于多源数据的模型，将天气和系统状态信息映射到组件故障率，并结合集成树模型与优化方法，实现配电系统可靠性感知的动态控制，提升了系统可靠性并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 由于数据缺乏和配电系统故障事件稀少，现有模型难以准确反映运行决策和环境条件对系统故障风险的影响，因此需要建立更有效的故障风险映射模型。

Method: 提出一个多源数据模型，结合两种基于集成树的模型来处理特征共线性，识别关键特征并降维，进而估计组件故障率；将估计结果嵌入顺序非凸优化过程中，动态更新运行控制决策。

Result: 通过数值实验验证了该可靠性感知控制方法在提升系统可靠性和降低成本方面的有效性，并分析了所提估计模型的性能特性。

Conclusion: 所提出的多源数据驱动方法能够有效支持配电系统中基于控制的可靠性提升，为避免昂贵的物理升级提供了可行替代方案。

Abstract: Distributed energy resources offer a control-based option to improve
distribution system reliability by ensuring system states that positively
impact component failure rates. This option is an attractive complement to
otherwise costly and lengthy physical infrastructure upgrades. However,
required models that adequately map operational decisions and environmental
conditions to system failure risk are lacking because of data unavailability
and the fact that distribution system failures remain rare events. This paper
addresses this gap and proposes a multi-source data model that consistently
maps comprehensive weather and system state information to component failure
rates. To manage collinearity in the available features, we propose two
ensemble tree-based models that systematically identify the most influential
features and reduce the dataset's dimensionality based on each feature's impact
on failure rate estimates. These estimates are embedded within a sequential,
non-convex optimization procedure, that dynamically updates operational control
decisions. We perform a numerical experiment to demonstrate the cost and
reliability benefits that can be achieved through this reliability-aware
control approach and to analyze the properties of each proposed estimation
model.

</details>


### [61] [Complexity of Bilevel Linear Programming with a Single Upper-Level Variable](https://arxiv.org/abs/2510.21126)
*Nagisa Sugishita,Margarida Carvalho*

Main category: math.OC

TL;DR: 本文研究了双层线性规划（bilevel LP）的计算复杂性，证明即使上层问题只有一个变量、无约束且变量有界，其决策问题仍为NP-完全，表明仅限制上层问题的变量或约束数无法保证易解性；但作者同时提出了一种可在多项式时间内求解此类问题局部最优解的算法，并展示了背包问题和旅行商问题等组合优化问题可转化为此类双层LP。


<details>
  <summary>Details</summary>
Motivation: 已有研究指出，当固定下层变量数或约束数时，双层线性规划可变得易解，但对上层问题施加限制是否能带来类似效果尚不清楚。本文旨在填补这一空白，探究仅限制上层问题复杂性时双层LP的可解性。

Method: 通过构造特定的双层线性规划实例，证明即使上层仅有一个变量、无显式约束且变量有界，其决策问题仍为NP-完全；同时设计了一个多项式时间算法用于求解此类问题的局部最优解，并将多个经典组合优化问题转化为该形式的双层LP。

Result: 1. 双层LP的决策问题在仅有单个上层变量、无上层约束且变量有界的情况下仍为NP-完全；2. 提出了一种可在多项式时间内找到局部最优解的算法；3. 展示了背包问题和旅行商问题等可被表达为该受限形式的双层LP。

Conclusion: 仅限制上层问题的变量数或约束数不足以使双层线性规划变得易解，其决策问题仍保持NP-完全性；然而，存在多项式时间算法可求得局部最优解，且该模型具有表达多种组合优化问题的能力。

Abstract: Bilevel linear programming (LP) is one of the simplest classes of bilevel
optimization problems, yet it is known to be NP-hard in general. Specifically,
determining whether the optimal objective value of a bilevel LP is at least as
good as a given threshold, a standard decision version of the problem, is
NP-complete. However, this decision problem becomes tractable when either the
number of lower-level variables or the number of lower-level constraints is
fixed, which prompts the question: What if restrictions are placed on the
upper-level problem? In this paper, we address this gap by showing that the
decision version of bilevel LP remains NP-complete even when there is only a
single upper-level variable, no upper-level constraints (apart from the
constraint enforcing optimality of the lower-level decision) and all variables
are bounded between 0 and 1. This result implies that fixing the number of
variables or constraints in the upper-level problem alone does not lead to
tractability in general. On the positive side, we show that there is a
polynomial-time algorithm that finds a local optimal solution of such a
rational bilevel LP instance. We also demonstrate that many combinatorial
optimization problems, such as the knapsack problem and the traveling salesman
problem, can be written as such a bilevel LP instance.

</details>


### [62] [Linear-Quadratic Non-zero Sum Differential Game with Asymmetric Delayed Information](https://arxiv.org/abs/2510.21152)
*Yuxin Ye,Jingtao Shi*

Main category: math.OC

TL;DR: 本文研究了一类具有非对称延迟信息的线性-二次非零和微分博弈。通过随机最大值原理和离散化方法，建立了在非对称延迟信息结构下的状态估计反馈纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 解决具有非对称时间延迟信息的微分博弈问题，提升在信息延迟情况下的决策优化能力。

Method: 利用随机最大值原理导出随机哈密顿系统，并结合离散化方法和向后迭代技术分析前向与后向过程的关系。

Result: 建立了延迟前向-后向随机微分方程模型，获得了非对称延迟信息下的状态估计反馈纳什均衡。

Conclusion: 所提出的方法有效解决了非对称延迟信息下的微分博弈问题，为相关领域的控制与博弈分析提供了理论支持。

Abstract: This paper is concerned with a linear-quadratic non-zero sum differential
game with asymmetric delayed information. To be specific, two players exist
time delays simultaneously which are different, leading the dynamical system
being an asymmetric information structure. By virtue of stochastic maximum
principle, the stochastic Hamiltonian system is given which is a delayed
forward-backward stochastic differential equation. Utilizing discretisation
approach and backward iteration technique, we establish the relationship
between forward and backward processes under asymmetric delayed information
structure and obtain the state-estimate feedback Nash equilibrium of our
problem.

</details>


### [63] [Near Optimality of Discrete-Time Approximations for Controlled McKean-Vlasov Diffusions and Interacting Particle Systems](https://arxiv.org/abs/2510.21208)
*Somnath Pradhan,Serdar Yuksel*

Main category: math.OC

TL;DR: 本文研究了McKean-Vlasov型随机最优控制问题，提出了离散时间与多粒子系统的逼近方法，证明了最优松弛控制的存在性、离散策略的近似最优性，并展示了在集中式与分布式控制结构下，当粒子数趋于无穷且时间步长趋于零时，控制策略的渐近最优性。


<details>
  <summary>Details</summary>
Motivation: McKean-Vlasov控制问题在多智能体系统和平均场博弈中具有重要应用，但其连续时间下的求解困难，因此需要有效的离散化和粒子系统逼近方法。

Method: 通过引入松弛控制空间的弱拓扑结构证明存在性；分析控制策略下成本函数的连续性；利用离散时间逼近和N-粒子相互作用系统，结合集中式与分布式信息结构进行近似分析。

Result: 证明了最优松弛控制的存在性；离散时间值函数收敛到连续时间情形；最优离散策略在连续问题中近似最优并给出收敛速率；McKean-Vlasov离散策略在N粒子系统中具有渐近最优性。

Conclusion: 该文为McKean-Vlasov最优控制问题提供了系统的离散时间和粒子逼近框架，支持数值求解，并验证了近似策略在多智能体系统中的有效性。

Abstract: We study stochastic optimal control problems for (possibly degenerate)
McKean-Vlasov controlled diffusions and obtain discrete-time as well as finite
interacting particle approximations. (i) Under mild assumptions, we first prove
the existence of optimal relaxed controls by endowing the space of relaxed
policies with a compact weak topology. (ii) Establishing continuity of the cost
in control policy, we establish near-optimality of piecewise-constant strict
policies, show that the discrete-time value functions (finite-horizon and
discounted infinite-horizon) converge to their continuous-time counterparts as
the timestep converges to zero, and that optimal discrete-time policies are
near-optimal for the original continuous-time problem, where rates of
convergence are also obtained. (iii) We then extend these approximation and
near-optimality results to $N$-particle interacting systems under centralized
or decentralized mean-field sharing information structure, proving that the
discrete-time McKean-Vlasov policy is asymptotically optimal as $N\to \infty$
and the time step goes to zero. We thus develop an approximation of
McKean-Vlasov optimal control problems via discrete-time McKean-Vlasov control
problems (and associated numerical methods such as finite model approximation),
and also show the near optimality of such approximate policy solutions for the
$N$-agent interacting models under centralized and decentralized control.

</details>


### [64] [Time-varying Gaussian Process Bandit Optimization with Experts: no-regret in logarithmically-many side queries](https://arxiv.org/abs/2510.21274)
*Eliabelle Mauduit,Eloïse Berthier,Andrea Simonetto*

Main category: math.OC

TL;DR: 提出了一种基于异方差高斯过程回归和稀疏推断的时变贝叶斯优化方法，通过少量专家查询实现无遗憾优化。


<details>
  <summary>Details</summary>
Motivation: 在时变环境中，传统贝叶斯优化难以实现无遗憾性能，需探索如何利用少量额外信息来恢复优化效率。

Method: 采用置信上界高斯过程算法，引入不确定性注入机制，并结合稀疏推断扩展至异方差回归，定期用专家查询更新过时观测。

Result: 在仅需每步对数级额外查询的条件下，实现了时变环境下的无遗憾贝叶斯优化。

Conclusion: 少量外部专家信息足以抵消时间漂移影响，确保时变环境下高效优化。

Abstract: We study a time-varying Bayesian optimization problem with bandit feedback,
where the reward function belongs to a Reproducing Kernel Hilbert Space (RKHS).
We approach the problem via an upper-confidence bound Gaussian Process
algorithm, which has been proven to yield no-regret in the stationary case.
  The time-varying case is more challenging and no-regret results are out of
reach in general in the standard setting. As such, we instead tackle the
question of how many additional observations asked to an expert are required to
regain a no-regret property. To do so, we formulate the presence of past
observation via an uncertainty injection procedure, and we reframe the problem
as a heteroscedastic Gaussian Process regression. In addition, to achieve a
no-regret result, we discard long outdated observations and replace them with
updated (possibly very noisy) ones obtained by asking queries to an external
expert. By leveraging and extending sparse inference to the heteroscedastic
case, we are able to secure a no-regret result in a challenging time-varying
setting with only logarithmically-many side queries per time step. Our method
demonstrates that minimal additional information suffices to counteract
temporal drift, ensuring efficient optimization despite time variation.

</details>


### [65] [Binno: A 1st-order method for Bi-level Nonconvex Nonsmooth Optimization for Matrix Factorizations](https://arxiv.org/abs/2510.21390)
*Laura Selicato,Flavia Esposito,Andersen Ang*

Main category: math.OC

TL;DR: 本文提出了一种用于非凸、非光滑双层优化的新方法Binno，该方法结合了近端构造与精心设计的下降条件，并在稀疏低秩分解任务中表现出优于标准方法的性能。


<details>
  <summary>Details</summary>
Motivation: 针对非凸、非光滑双层优化问题缺乏有效且具有理论保证的一阶算法，本文旨在设计一种能够确保双层目标函数同步下降的实用算法。

Method: 提出Binno算法，采用分块近端梯度更新分别处理上下层问题，通过校准的块对角凸组合生成新迭代点，并利用线搜索选择组合权重以实现双层目标的同时下降，结合变分分析证明下降方向的存在性。

Result: 理论分析表明Binno能有效产生下降方向并满足收敛条件；在合成矩阵和真实交通视频数据集上的实验显示，相比标准方法，Binno获得了更低的重构误差和更高的峰值信噪比。

Conclusion: Binno为非凸非光滑双层优化提供了一个有效且具理论支持的求解框架，在稀疏低秩分解等应用中展现出优越性能。

Abstract: In this work, we develop a method for nonconvex, nonsmooth bi-level
optimization and we introduce Binno, a first order method that leverages
proximal constructions together with carefully designed descent conditions and
variational analysis. Within this framework, Binno provably enforces a descent
property for the overall objective surrogate associated with the bi-level
problem. Each iteration performs blockwise proximal-gradient updates for the
upper and the lower problems separately and then forms a calibrated,
block-diagonal convex combination of the two tentative iterates. A linesearch
selects the combination weights to enforce simultaneous descent of both
level-wise objectives, and we establish conditions guaranteeing the existence
of such weights together with descent directions induced by the associated
proximal-gradient maps. We also apply Binno in the context of sparse low-rank
factorization, where the upper level uses elementwise $\ell_1$ penalties and
the lower level uses nuclear norms, coupled via a Frobenius data term. We test
Binno on synthetic matrix and a real traffic-video dataset, attaining lower
relative reconstruction error and higher peak signal-to-noise ratio than some
standard methods.

</details>


### [66] [Optimal policies for environmental assets under spatial heterogeneity and global awareness](https://arxiv.org/abs/2510.21397)
*Emmanuelle Augeraud-Véron,Daria Ghilli,Fausto Gozzi,Marta Leocata*

Main category: math.OC

TL;DR: 本文提出并研究了一个地理背景下环境资产管理的随机模型，其中各地当局在非合作情况下最大化自身福利。模型考虑了局部与全局环境资产对福利的影响，并通过N人博弈和平均场博弈分析了非合作与合作情形下的均衡解，同时提出了使分散决策达到社会最优的庇古税。


<details>
  <summary>Details</summary>
Motivation: 研究在非合作环境下，地方当局如何基于局部与全局环境资产进行决策，以及这种决策如何影响整体环境管理效率。

Method: 采用随机博弈模型，分析N人博弈中的开环与闭环纳什均衡，并研究其向平均场博弈的收敛性；同时求解社会规划者视角下的合作最优解，并设计庇古税以协调个体与社会最优。

Result: 得到了N人博弈中开环和闭环纳什均衡的显式解；证明了当参与者数量趋于无穷时，博弈收敛到唯一的平均场博弈均衡；求出了社会规划者的最优解及使分散决策与社会最优一致的庇古税。

Conclusion: 非合作决策导致次优结果，而通过适当的庇古税可引导地方当局行为与社会整体利益一致，为环境政策设计提供了理论支持。

Abstract: The aim of this paper is to formulate and study a stochastic model for the
management of environmental assets in a geographical context where in each
place the local authorities take their policy decisions maximizing their own
welfare, hence not cooperating each other. A key feature of our model is that
the welfare depends not only on the local environmental asset, but also on the
global one, making the problem much more interesting but technically much more
complex to study, since strategic interaction among players arise.
  We study the problem first from the $N$-players game perspective and find
open and closed loop Nash equilibria in explicit form. We also study the
convergence of the $N$-players game (when $n\to +\infty$) to a suitable Mean
Field Game whose unique equilibrium is exactly the limit of both the open and
closed loop Nash equilibria found above, hence supporting their meaning for the
game. Then we solve explicitly the problem from the cooperative perspective of
the social planner and compare its solution to the equilibria of the
$N$-players game. Moreover we find the Pigouvian tax which aligns the
decentralized closed loop equilibrium to the social optimum.

</details>


### [67] [Robust Regret Control with Uncertainty-Dependent Baseline](https://arxiv.org/abs/2510.21415)
*Jietian Liu,Peter Seiler*

Main category: math.OC

TL;DR: 本文提出了一种鲁棒后悔控制框架，通过自适应性能基准来应对系统不确定性，将鲁棒加性后悔控制问题转化为改进系统的鲁棒H∞性能问题，并利用线性近似将其简化为标准的μ综合问题。


<details>
  <summary>Details</summary>
Motivation: 为了在系统存在不确定性的情况下提升控制性能，提出一种能够自适应调整性能基准的鲁棒后悔控制方法，以更有效地衡量控制器的实际表现。

Method: 将系统建模为具有实参数不确定性的离散时间线性时不变系统，以具有完全扰动和系统实现信息的最优非因果控制器作为性能基准，并通过H∞性能条件和线性近似方法将问题转化为μ综合问题。

Result: 证明了控制器实现鲁棒加性后悔的充要条件是满足改进系统上的鲁棒H∞性能条件，并通过数值例子验证了该方法的有效性。

Conclusion: 所提出的框架成功地将鲁棒后悔控制问题与鲁棒H∞控制联系起来，借助线性近似可将其转化为标准μ综合问题，具备实际求解可行性。

Abstract: This paper proposes a robust regret control framework in which the
performance baseline adapts to the realization of system uncertainty. The plant
is modeled as a discrete-time, uncertain linear time-invariant system with
real-parametric uncertainty. The performance baseline is the optimal non-causal
controller constructed with full knowledge of the disturbance and the specific
realization of the uncertain plant. We show that a controller achieves robust
additive regret relative to this baseline if and only if it satisfies a
related, robust $H_\infty$ performance condition on a modified plant. One
technical issue is that the modified plant can, in general, have a complicated
nonlinear dependence on the uncertainty. We use a linear approximation step so
that the robust additive regret condition can be recast as a standard
$\mu$-synthesis problem. A numerical example is used to demonstrate the
proposed approach.

</details>


### [68] [Finite-Time Analysis of Stochastic Nonconvex Nonsmooth Optimization on the Riemannian Manifolds](https://arxiv.org/abs/2510.21468)
*Emre Sahinoglu,Youbang Sun,Shahin Shahrampour*

Main category: math.OC

TL;DR: 本文提出了适用于流形约束下非光滑非凸随机优化的RO2NC算法，并建立了其有限时间收敛性分析，首次在黎曼流形上实现了与欧氏空间最优复杂度相匹配的样本复杂度。


<details>
  <summary>Details</summary>
Motivation: 针对流形约束下的非光滑非凸随机优化问题，缺乏有效的有限时间分析方法，本文旨在填补这一理论空白。

Method: 引入适用于流形情形的Goldstein平稳性概念，提出RO2NC算法及其零阶版本ZO-RO2NC，并分析其在寻找(δ,ε)-平稳点时的样本复杂度。

Result: RO2NC和ZO-RO2NC算法均达到O(ε⁻³δ⁻¹)的样本复杂度，这是流形上完全非光滑非凸优化首个有限时间收敛保证，且复杂度与欧氏情形最优结果一致。

Conclusion: 本文为流形上的非光滑非凸随机优化提供了理论基础和高效算法，理论与实验结果一致，验证了算法的有效性。

Abstract: This work addresses the finite-time analysis of nonsmooth nonconvex
stochastic optimization under Riemannian manifold constraints. We adapt the
notion of Goldstein stationarity to the Riemannian setting as a performance
metric for nonsmooth optimization on manifolds. We then propose a Riemannian
Online to NonConvex (RO2NC) algorithm, for which we establish the sample
complexity of $O(\epsilon^{-3}\delta^{-1})$ in finding
$(\delta,\epsilon)$-stationary points. This result is the first-ever
finite-time guarantee for fully nonsmooth, nonconvex optimization on manifolds
and matches the optimal complexity in the Euclidean setting. When gradient
information is unavailable, we develop a zeroth order version of RO2NC
algorithm (ZO-RO2NC), for which we establish the same sample complexity. The
numerical results support the theory and demonstrate the practical
effectiveness of the algorithms.

</details>


### [69] [A Practical Adaptive Subgame Perfect Gradient Method](https://arxiv.org/abs/2510.21617)
*Alan Luner,Benjamin Grimmer*

Main category: math.OC

TL;DR: 提出了一种基于子博弈完美性的自适应梯度方法（ASPGM），用于光滑凸优化，具有无需线搜索、无参数、自适应等优点，并具备强理论保证。


<details>
  <summary>Details</summary>
Motivation: 为了在光滑凸优化中实现更优的性能并获得动态强化的极小极大最优性，同时避免传统方法对参数调整和线搜索的依赖。

Method: 采用子博弈完美概念设计新的梯度算法ASPGM，结合动量更新机制与有限历史一阶信息的记忆体进行动态优化，并引入自动调节条件、重启和预处理技术实现自适应性。

Result: ASPGM在多种光滑凸问题上表现与L-BFGS等先进方法相当，且具备非渐近性的强理论保证，提供解质量的证书，支持简单的停止和重启准则。

Conclusion: ASPGM是一种高效、自适应且具有坚实理论基础的梯度优化方法，在性能和理论保证方面均表现出优势。

Abstract: We present a performant gradient method for smooth convex optimization,
drawing inspiration from several recent advances in the field. Our algorithm,
the Adaptive Subgame Perfect Gradient Method (ASPGM) is based on the notion of
subgame perfection, attaining a dynamic strengthening of minimax optimality. At
each iteration, ASPGM makes a momentum-type update, optimized dynamically based
on a (limited) memory/bundle of past first-order information. ASPGM is
linesearch-free, parameter-free, and adaptive due to its use of recently
developed auto-conditioning, restarting, and preconditioning ideas. We show
that ASPGM is competitive with state-of-the-art L-BFGS methods on a wide range
of smooth convex problems. Unlike quasi-Newton methods, however, our core
algorithm underlying ASPGM has strong, subgame perfect, non-asymptotic
guarantees, providing certificates of solution quality, resulting in simple
stopping criteria and restarting conditions.

</details>


### [70] [Goal-based portfolio selection with fixed transaction costs](https://arxiv.org/abs/2510.21650)
*Erhan Bayraktar,Bingyan Han,Jingjie Zhang*

Main category: math.OC

TL;DR: 研究了在存在交易成本的情况下，投资者如何选择投资组合以实现多个具有特定截止日期和目标金额的财务目标。


<details>
  <summary>Details</summary>
Motivation: 解决多目标、有交易成本约束下的投资组合选择问题，填补摩擦市场中目标驱动投资策略的研究空白。

Method: 采用随机Perron方法，证明价值函数是拟变分不等式系统的唯一粘性解。

Result: 建立了最优交易策略和目标融资方案的存在性，数值结果揭示了复杂的最优交易区域，且最优投资策略与无摩擦情况下的V型策略显著不同。

Conclusion: 该模型有效刻画了现实市场中多目标投资决策的复杂性，为考虑交易成本的目标驱动投资提供了理论支持和数值验证。

Abstract: We study a goal-based portfolio selection problem in which an investor aims
to meet multiple financial goals, each with a specific deadline and target
amount. Trading the stock incurs a strictly positive transaction cost. Using
the stochastic Perron's method, we show that the value function is the unique
viscosity solution to a system of quasi-variational inequalities. The existence
of an optimal trading strategy and goal funding scheme is established.
Numerical results reveal complex optimal trading regions and show that the
optimal investment strategy differs substantially from the V-shaped strategy
observed in the frictionless case.

</details>


### [71] [Advanced Cutting-Plane Algorithms for ACOPF](https://arxiv.org/abs/2510.21698)
*Daniel Bienstock,Matias Villagra*

Main category: math.OC

TL;DR: 提出了一种基于线性切割平面的ACOPF问题SDP松弛的稳定且可扩展的方法，能够快速热启动并计算大规模多周期松弛的紧致准确边界。


<details>
  <summary>Details</summary>
Motivation: 为了克服非线性凸求解器在大规模多周期ACOPF问题中计算能力的局限性，需要一种更稳定和可扩展的SDP松弛方法。

Method: 采用基于线性切割平面的 disciplined 方法，利用其线性特性实现热启动，并逐步逼近SDP松弛解。

Result: 初步实验表明，该方法在PGLIB实例上相较于最先进的方法能够提供有竞争力的边界，且适用于更大规模的问题。

Conclusion: 该方法在稳定性、可扩展性和计算效率方面优于现有非线性方法，具有应用于大规模电力系统优化的潜力。

Abstract: We propose a disciplined, numerically stable, and scalable approach to SDP
relaxations of the ACOPF problem based on linear cutting-planes. Our method can
be warm-started and, owing to its linear nature, enables the computation of
tight and accurate bounds for large-scale multi-period relaxations -- well
beyond what nonlinear convex solvers can achieve. Preliminary experiments show
promising results when benchmarked against state-of-the-art bounds on PGLIB
instances.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [72] [Integrated physics-informed learning and resonance process signature for the prediction of fatigue crack growth for laser-fused alloys](https://arxiv.org/abs/2510.21018)
*Panayiotis Kousoulas,Rahul Sharma,Y. B. Guo*

Main category: cs.CE

TL;DR: 本研究提出了一种非量纲化的物理信息机器学习（PIML）模型，用于预测激光熔融SS-316L材料的疲劳裂纹扩展，结合疲劳定律与小数据，实现可解释且准确的预测。


<details>
  <summary>Details</summary>
Motivation: 激光熔融金属部件因随机几何缺陷导致疲劳行为分散，传统统计模型难以处理此类散射，现有数据驱动方法缺乏可解释性，因此需要一种兼具准确性与可解释性的预测方法。

Method: 提出一种融合疲劳定律（如Paris定律）和共振过程特征数据的非量纲化物理信息机器学习（PIML）模型，利用小样本数据进行训练，无需实验裂纹扩展数据。

Result: 模型成功学习到与文献数据相似的Paris定律参数，并能准确预测裂纹扩展速率和裂纹尺寸。

Conclusion: 该PIML模型在小数据条件下实现了对激光熔融材料裂纹扩展的可解释、合理且准确的预测，为增材制造部件的疲劳寿命评估提供了新方法。

Abstract: Fatigue behaviors of metal components by laser fusion suffer from scattering
due to random geometrical defects (e.g., porosity, lack of fusion). Monitoring
fatigue crack initiation and growth is critical, especially for laser-fused
components with significant inherent fatigue scattering. Conventional
statistics-based curve-fitting fatigue models have difficulty incorporating
significant scattering in their fatigue life due to the random geometrical
defects. A scattering-informed predictive method is needed for laser-fused
materials' crack size and growth. Current data-driven machine learning could
circumvent the issue of deterministic modeling, but results in a black-box
function that lacks interpretability. To address these challenges, this study
explores a novel nondimensionalized physics-informed machine learning (PIML)
model to predict fatigue crack growth of laser-fused SS-316L by integrating
fatigue laws and constraints with small data to ensure a realistic and
interpretable prediction. Resonance process signature data were leveraged with
Paris's law to train the PIML model without experimental crack growth data. The
results show that Paris's law constants can be learned with good similarity to
comparable data from the literature, and the crack growth rate can be predicted
to compute crack sizes.

</details>


### [73] [Linked Cell Traversal Algorithms for Three-Body Interactions in Molecular Dynamics](https://arxiv.org/abs/2510.21230)
*Jose Alfonso Pinzon Escobar,Markus Mühlhäußer,Hans-Joachim Bungartz,Philipp Neumann*

Main category: cs.CE

TL;DR: 本文提出了一种用于分子动力学中三体相互作用并行计算的算法，扩展了传统成对相互作用的遍历方法，并结合截断条件进行验证和性能测试。


<details>
  <summary>Details</summary>
Motivation: 为了高效计算跨三个单元存储分子间的三体相互作用，弥补现有成对相互作用遍历方法在多体作用中的不足。

Method: 建立了一个基于链式单元的三体相互作用通用计算框架，设计了相应的遍历算法，并结合常用的截断条件优化计算负载。

Result: 通过Lennard-Jones流体的案例验证了方法在均匀与非均匀场景下的有效性，并测得了良好的节点级强可扩展性和分子更新性能。

Conclusion: 所提出的框架能有效支持三体相互作用的并行计算，结合截断策略显著提升了计算效率，具备良好的可扩展性。

Abstract: In this work, algorithms for the parallel computation of three-body
interactions in molecular dynamics are developed. While traversals for the
computation of pair interactions are readily available in the literature, here,
such traversals are extended to allow for the computation between molecules
stored across three cells. A general framework for the computation of
three-body interactions in linked cells is described, and then used to
implement the corresponding traversals. In addition, our analysis is combined
with the commonly used cutoff conditions, because they influence the total
workload of the computation of interactions. The combinations between
traversals and truncation conditions are validated using the well-known
Lennard-Jones fluid. Validation case studies are taken from the literature and
configured into homogeneous and inhomogeneous scenarios. Finally, strong
scalability and performance in terms of molecule updates are measured at
node-level.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [74] [Space waste: An update of the anthropogenic matter injection into Earth atmosphere](https://arxiv.org/abs/2510.21328)
*Leonard Schulz,Karl-Heinz Glassmeier,Moritz Herberhold,Adam Mitchell,Daniel M. Murphy,John M. C. Plane,Ferdinand Plaschke*

Main category: physics.ao-ph

TL;DR: 本研究更新了2015至2025年太空废弃物进入地球大气层的元素注入估算，发现自2020年起其质量显著上升，多种用于航天器的金属元素已超过自然陨石输入量，可能对大气环境造成长期负面影响。


<details>
  <summary>Details</summary>
Motivation: 随着大型卫星星座的快速部署，越来越多的人造物体在寿命结束后重返大气层，烧蚀后向高层大气注入大量金属元素。此前研究已指出此类人为输入可能超过自然 meteoric 输入，但需进一步更新和验证。本文旨在评估近年实际注入情况并预测未来趋势，以揭示潜在大气风险。

Method: 基于Schulz & Glassmeier (2021)的方法，更新2015–2025年的卫星与火箭残骸再入数据，计算43种元素的年均注入通量，并与自然陨石输入进行详细对比；同时结合Murphy等(2023)对平流层气溶胶中残留物的观测数据进行验证。

Result: 自2020年起，太空废弃物的质量输入显著增加；到2024年，有24种元素的注入量超过自然陨石输入（2015年为18种），其中包括具有催化活性的过渡金属；模型估算与平流层气溶胶观测数据高度一致；原预测的未来情景可能在2025年前实现。

Conclusion: 人造空间废弃物正成为高层大气金属元素的主要来源，可能引发臭氧损耗、辐射效应和云形成变化等长期环境风险，亟需加强对这些元素在大气中的积累、化学行为及其环境影响的研究。

Abstract: Large satellite constellations are one of the main reasons for an increasing
amount of mass being brought into low Earth orbit in recent years. After end of
life, the satellites, as well as rocket stages, reenter Earth's atmosphere.
This space waste burns up and thus injects a substantial amount of its matter
into the mesosphere and lower thermosphere. A first comprehensive analysis of
the anthropogenic injection and a comparison to the natural injection by
meteoroids was presented by Schulz & Glassmeier (2021). They found significant
and even the dominant injection of several metal elements regularly used in
spacecraft compared to the natural injection. The first observations of space
waste remnants in stratospheric aerosol particles (Murphy et al., 2023)
confirmed several of these estimates, but also revealed differences and new
insights. The current study presents an update to the space waste injection
estimates of Schulz & Glassmeier (2021), assessing the years from 2015 to 2025
but also considering future mass influx scenarios. 43 elements are considered
and thus a much more detailed comparison to the meteoric injection is possible.
Comparison of estimated elemental fluxes to stratospheric aerosol data shows
excellent agreement. From 2020 onward, a strong rise in space waste mass influx
to the atmosphere can be seen. Future scenarios discussed by Schulz &
Glassmeier (2021) may already be reached by the end of 2025. In 2024, 24
elements were dominating the meteoric injection compared to 18 in 2015. Several
of them are transition metals, which are known for their catalytic activity.
This indicates a substantial risk of long-term adverse effects on the
atmosphere such as ozone depletion, radiative effects and changes in cloud
formation, if no action is taken. Research is urgently needed into the
atmospheric accumulation, chemistry, and general atmospheric effects of
specific elements.

</details>


### [75] [Navigating Through Turbulence: Blueprint for the Next Generation of Weather-Climate Scientists](https://arxiv.org/abs/2510.21123)
*Gan Zhang,Zhuo Wang,Kevin A Reed,Lucas M Harris*

Main category: physics.ao-ph

TL;DR: 本文探讨了气象与气候科学领域在技术进步推动下面临的职业变迁与机遇，强调高分辨率模拟和人工智能带来的新科学前沿，并提出教育和职业发展路径的适应性变革。


<details>
  <summary>Details</summary>
Motivation: 应对气候变化研究领域人才流失和职业不确定性，同时利用新技术带来的机遇。

Method: 通过分析当前科研与就业环境的变化，结合新兴技术趋势，提出对未来人才培养和职业发展的建议。

Result: 识别出高分辨率模拟和人工智能等新兴科学前沿，提出了适应新生态系统的教育和职业发展路径。

Conclusion: 新的扩展生态系统为学生和早期职业专业人士提供了巨大机遇，需通过改革教育和培训来充分把握这些机遇。

Abstract: The field of weather and climate science is at a pivotal moment, defined by
the dual forces of unprecedented technological advancement. While a shifting
research and employment landscape has created career uncertainty, leading to a
significant migration of talent toward the private sector, it has
simultaneously spurred an expansion of the ecosystem through the emergence of
new computational tools and the growing role of industry innovators and
stakeholders. This perspective paper argues that this new, expanded ecosystem
presents extraordinary opportunities for students and early-career
professionals. We outline the emerging scientific frontiers powered by
high-resolution simulations and artificial intelligence, suggest a practical
path for navigating a more fluid career landscape, and propose how education
and training must evolve to equip the next generation for success.

</details>


### [76] [Light scattering by random convex polyhedron in geometric optics approximation](https://arxiv.org/abs/2510.21201)
*Quan Mu*

Main category: physics.ao-ph

TL;DR: 提出了一种基于凸包构造算法的冰晶几何模型，用于研究卷云粒子的光散射特性，并在几何光学近似下计算了随机取向大晶体的散射矩阵，适用于任意凸多面体，具有广泛的适用性。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地模拟卷云中冰晶粒子的光散射特性，提出一种通用且灵活的几何模型，以支持大气辐射传输模拟和遥感数据解释。

Method: 基于凸包构造算法构建冰晶的几何模型，在几何光学近似下计算随机取向的大冰晶（任意凸多面体）的完整偏振散射矩阵，不考虑衍射和吸收效应。

Result: 在统一计算框架下，计算了三种不同几何形状冰晶的散射矩阵；对于经典的六角柱模型，计算结果与其他研究者的结果总体一致。

Conclusion: 所提出的冰晶模型和散射矩阵计算框架适用于各种凸多面体，在地球及行星大气的辐射传输模拟和遥感数据解释中具有广泛应用前景。

Abstract: Based on the convex hull construction algorithm, a new geometrical model of
ice crystals is proposed to investigate the scattering properties of cirrus
clouds particles. Light scattering matrices involving complete polarization
information are calculated in geometric optics approximation for randomly
oriented large crystals with random and given convex polyhedron shape. The
proposed model construction method and computational scheme of light scattering
matrix works for any convex polyhedron within the scope of geometrical optics.
To illustrate the broad applicability of the proposed ice crystal model,
scattering matrices for three ice crystal examples with different geometrical
shapes are calculated under a unified computational framework. Diffraction and
absorption are not considered in this work. The calculated results for the
classical hexagonal column model show overall agreement with those reported by
other authors. The crystal model and scattering matrix computational framework
developed in this study are applicable to radiative transfer simulations and
remote sensing data interpretation in terrestrial and planetary atmospheres.

</details>


### [77] [Characterizing global tropical cyclone events of 2024](https://arxiv.org/abs/2510.21507)
*Lingke Jiang,G. Brooke Anderson,Yanran Li,Xiao Wu,Victoria D. Lynch,Robbie M. Parks*

Main category: physics.ao-ph

TL;DR: 2024年热带气旋影响了全球约5.5%的人口，其中飓风级风力影响约0.8%，研究通过1980-2024年的历史数据提供了社会人口特征分析，以支持防灾韧性与恢复工作。


<details>
  <summary>Details</summary>
Motivation: 为了全面评估热带气旋的年度影响，需结合社会人口特征进行分析，从而为防灾减灾和恢复提供依据。

Method: 基于1980-2024年的历史数据，分析2024年受热带气旋和飓风级风力影响区域的社会人口特征。

Result: 2024年约有4.29亿人受到热带气旋级风力影响，5967万人受到飓风级风力影响，分别占全球人口的5.5%和0.8%。

Conclusion: 热带气旋对全球大量人口构成持续威胁，结合长期社会人口数据分析有助于优化应对策略和资源分配。

Abstract: Full impact assessment of tropical cyclones each year requires a
comprehensive sociodemographic analysis. We evaluated sociodemographic
characteristics of tropical cyclone-impacted regions during the 2024 calendar
year in recent historical context of 1980-2024. In 2024, tropical cyclone-force
wind affected an estimated 429,902,820 people (5.5% of global population), and
hurricane-force wind an estimated 59,672,600 people (0.8%). Our findings
provide a global context for tropical cyclones to better guide resilience and
recovery efforts.

</details>


### [78] [Direct test for critical slowing down before Dansgaard-Oeschger events via the volcanic climate response](https://arxiv.org/abs/2510.21539)
*Johannes Lohmann*

Main category: physics.ao-ph

TL;DR: 该研究通过分析末次冰期多格拉斯-奥施格事件（DO事件）前的气候恢复情况，检验了统计性早期预警信号（EWS）预测气候临界点的有效性。研究利用数百次火山喷发后的冰芯数据，发现接近DO增温事件时气候恢复无明显变化，未显示临界慢化（CSD）；但在接近DO降温事件时，部分关键指标显示响应增强、恢复变慢，表现出CSD迹象。尽管多数指标在增温和降温前均显示出统计性EWS，但增温信号较弱。总体上EWS与CSD趋势一致，但二者在具体指标上的不一致表明需谨慎解读单一变量的EWS。


<details>
  <summary>Details</summary>
Motivation: 验证统计性早期预警信号（EWS）是否能可靠预测未来气候系统 tipping point，特别是基于过去 abrupt 气候变化（如DO事件）中是否存在临界慢化（CSD）进行直接检验。

Method: 通过分析末次冰期期间数百次大型火山喷发后的气候响应，利用八个冰芯代用指标，平均构建出稳定的外部扰动，直接检测接近DO事件时气候系统的恢复能力是否变慢（即CSD）。同时对比统计性EWS（如波动幅度和相关性增加）的存在情况。

Result: 接近DO增温事件时，气候对火山喷发的响应保持稳定，未发现CSD；但在接近DO降温事件时，部分关键代用指标显示气候响应更强、恢复更慢，表现出CSD迹象。几乎所有代用指标都显示出统计性EWS，但增温前的EWS信号较弱。EWS与CSD整体趋势一致，但在具体指标上存在不一致。

Conclusion: 统计性早期预警信号（EWS）与直接检测到的临界慢化（CSD）在趋势上具有一致性，尤其在DO降温事件前更明显，但两者在具体代用指标上的不匹配表明，单独依赖某一变量的EWS需谨慎，应结合多种方法综合判断气候 tipping point。

Abstract: It is tested whether past abrupt climate changes support the validity of
statistical early-warning signals (EWS) as predictor of future climate tipping
points. EWS are expected increases in amplitude and correlation of fluctuations
driven by noise. This is a symptom of critical slowing down (CSD), where a
system's recovery from an external perturbation becomes slower as a tipping
point (represented by a bifurcation) is approached. EWS are a simple, indirect
measure of CSD, but subject to assumptions on the noise process and measurement
stationarity that are hard to verify. In this work the existence of CSD before
the Dansgaard-Oeschger (DO) events of the last glacial period is directly
tested by inferring the climate's recovery from large volcanic eruptions. By
averaging over hundreds of eruptions, a well-defined, stationary perturbation
is constructed and the average climate response is measured by eight ice core
proxies. As the abrupt DO warming transitions are approached, the climate
response to eruptions remains the same, indicating no CSD. For the abrupt DO
cooling transitions, however, some key proxies show evidence of larger climate
response and slower recovery as the transitions are approached. By comparison,
almost all proxies show statistical EWS before cooling and warming transitions,
but with only weak confidence for the warming transitions. There is thus
qualitative agreement of CSD and EWS, in that the evidence for bifurcation
precursors is larger for the cooling transitions. However, the discrepancy that
many proxies show EWS but no direct CSD (and vice versa) highlights that
statistical EWS in individual observables need to be interpreted with care.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [79] [Interpolative separable density fitting on adaptive real space grids](https://arxiv.org/abs/2510.20826)
*Hai Zhu,Chia-Nan Yeh,Miguel A. Morales,Leslie Greengard,Shidong Jiang,Jason Kaye*

Main category: physics.comp-ph

TL;DR: 本文推广了插值可分离密度拟合（ISDF）方法，结合自适应实空间网格用于高度局域化的单粒子基函数，并通过高效的双重空间多层核分裂法求解泊松方程，实现了对电子排斥积分张量的高效压缩。


<details>
  <summary>Details</summary>
Motivation: 为了提高对高度局域化基函数的电子排斥积分（ERI）张量压缩效率，克服传统均匀网格方法在处理紧致基组时的局限性。

Method: 采用自适应的双重空间多层核分裂方法生成满足误差容限的高阶精确自适应网格，并基于单粒子基函数构造能解析电子对密度的网格，从而实现ISDF辅助基函数的高效计算与ERI张量压缩。

Result: 证明了可用于解析单粒子基函数的自适应网格稍作扩展即可用于解析电子对密度；在全电子基组下，ISDF对高度局域化基函数的压缩效率与平滑基函数相当，且显著优于均匀网格方法。

Conclusion: 该方法为任意光滑基函数下的可扩展多体电子结构模拟提供了新途径，使大规模核心能级激发等现象的模拟成为可能。

Abstract: We generalize the interpolative separable density fitting (ISDF) method, used
for compressing the four-index electron repulsion integral (ERI) tensor, to
incorporate adaptive real space grids for potentially highly localized
single-particle basis functions. To do so, we employ a fast adaptive algorithm,
the recently-introduced dual-space multilevel kernel-splitting method, to solve
the Poisson equation for the ISDF auxiliary basis functions. The adaptive grids
are generated using a high-order accurate, black-box procedure that satisfies a
user-specified error tolerance. Our algorithm relies on the observation, which
we prove, that an adaptive grid resolving the pair densities appearing in the
ERI tensor can be straightforwardly constructed from one that resolves the
single-particle basis functions, with the number of required grid points
differing only by a constant factor. We find that the ISDF compression
efficiency for the ERI tensor with highly localized basis sets is comparable to
that for smoother basis sets compatible with uniform grids. To demonstrate the
performance of our procedure, we consider several molecular systems with
all-electron basis sets which are intractable using uniform grid-based methods.
Our work establishes a pathway for scalable many-body electronic structure
simulations with arbitrary smooth basis functions, making simulations of
phenomena like core-level excitations feasible on a large scale.

</details>


### [80] [Phase-Field/Discontinuity Capturing operator for direct van der Waals simulation (DVS)](https://arxiv.org/abs/2510.21065)
*Tianyi Hu,Thomas J. R. Hughes,Guglielmo Scovazzi,Hector Gomez*

Main category: physics.comp-ph

TL;DR: 提出了一种新的相场/间断捕获（PF/DC）算子，用于解决传统间断捕获算子在直接范德华模拟中可能导致非物理波结构和违反自由能耗散律的问题，新方法在体相流体和界面区域均表现出稳定性和高精度，并在三维钝体空化流模拟中显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统间断捕获算子在处理具有负压-密度导数区域的直接范德华模拟时可能违反自由能耗散律并产生非物理波结构，因此需要一种更稳健的数值方法。

Method: 提出了相场/间断捕获（PF/DC）算子，结合相场方法与间断捕获技术，确保在界面区域的热力学一致性和数值稳定性。

Result: PF/DC算子在体相流体和界面区域均实现了稳定且精确的解，并在三维钝体空化流模拟中与实验数据高度吻合，明显优于传统DC算子的结果。

Conclusion: PF/DC算子有效解决了传统DC算子在非平衡相变模拟中的局限性，具备良好的物理一致性和工程应用前景。

Abstract: Discontinuity capturing (DC) operators are commonly employed to numerically
solve problems involving sharp gradients in the solution. Despite their
success, the application of DC operators to the direct van der Waals simulation
(DVS) remains challenging. The DVS framework models non-equilibrium phase
transitions by admitting interfacial regions in which the derivative of
pressure with respect to density is negative. In these regions, we demonstrate
that classical DC operators may violate the free energy dissipation law and
produce unphysical wave structures. To address this limitation, we propose the
phase-field/discontinuity capturing (PF/DC) operator. Numerical results show
that PF/DC yields stable and accurate solutions in both bulk fluids and
interfacial regions. Finally, we apply the proposed method to simulate
cavitating flow over a three-dimensional bluff body, obtaining excellent
agreement with experimental data and significant improvements over results
produced using classical DC operators.

</details>


### [81] [Fast adaptive discontinuous basis sets for electronic structure](https://arxiv.org/abs/2510.21213)
*Yulong Pan,Michael Lindsey*

Main category: physics.comp-ph

TL;DR: 提出了一种基于间断Galerkin（DG）框架的自适应基组构造方法，用于电子结构计算，兼具灵活性、数值稳定性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统基组在精度和计算效率之间难以平衡，缺乏系统性改进能力，且难以实现自适应优化。因此需要一种能够灵活组合不同类型基函数、保持良好数值性质并支持高效算法的新框架。

Method: 采用间断Galerkin方法，允许基函数在单元边界处不连续，结合原子中心基和多项式基；设计专用数值积分策略计算积分项，并引入多重网格预条件Poisson求解器加速HF和DFT计算中的本征求解过程。

Result: 数值实验表明，该方法在较小基组下即可达到化学精度，优于常规GTO基组；具有结构稀疏性，可扩展性好，尤其在体系尺寸增大时表现更优。

Conclusion: 该DG框架为电子结构理论提供了一条灵活、可系统改进且具结构自适应性的基组构建路径，具有良好的应用前景。

Abstract: We develop a discontinuous Galerkin (DG) framework for automatically
constructing adaptive basis sets for electronic structure calculations. By
allowing basis functions to be discontinuous across element interfaces, our
approach supports flexible combinations of atom-centered and polynomial basis
sets, maintains favorable numerical conditioning, and induces structured
sparsity of the one- and two-electron integrals, which we compute using
specialised numerical integration strategies. We also introduce
multigrid-preconditioned Poisson solvers that enable fast algorithms for both
Hartree-Fock (HF) and density functional theory (DFT) calculations within our
DG basis sets. Moreover, these basis sets naturally support adaptive multigrid
preconditioning for the linear eigensolvers employed within the self-consistent
field iteration for HF and DFT. Numerical experiments for HF and DFT
demonstrate that our approach achieves chemical accuracy with modest basis
sizes that compare favorably to the sizes of ordinary GTO basis sets achieving
similar accuracy, while offering additional structured sparsity and improved
computational scalability in the size-extensive limit. The framework thus
provides a flexible route toward the construction of systematically improvable
and structured adaptive basis sets for electronic structure theory.

</details>


### [82] [Reduced Floating-Point Precision Implicit Monte Carlo](https://arxiv.org/abs/2510.21683)
*Simon Butson,Mathew Cleveland,Alex Long,Todd Palmer*

Main category: physics.comp-ph

TL;DR: 本文提出了一种使用降低浮点精度的隐式蒙特卡洛方法来精确求解热辐射输运问题的算法，并通过算术操作和缩放方法提高计算精度，比较了半精度和双精度在多个基准问题上的结果。


<details>
  <summary>Details</summary>
Motivation: 为了在保证计算精度的同时降低计算资源消耗，探索在热辐射输运问题中使用降低浮点精度的可行性。

Method: 采用降低精度的隐式蒙特卡洛方法，结合算术操作和缩放技术来提升计算准确性。

Result: 半精度和双精度实现的结果在多个热辐射基准问题上进行了比较，验证了降低精度方法的有效性和精度提升技术的作用。

Conclusion: 通过适当的精度优化技术，可以在减少计算开销的同时保持热辐射输运问题求解的高精度。

Abstract: This work demonstrates algorithms to accurately compute solutions to thermal
radiation transport problems using a reduced floating-point precision
implementation of the Implicit Monte Carlo method. Several techniques falling
into the categories of arithmetic manipulations and scaling methods are
evaluated for their ability to improve the accuracy of reduced-precision
computations. The results for half- and double-precision implementations of
various thermal radiation benchmark problems are compared.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [83] [Cold-Diffusion Driven Downward Continuation of Gravity Data](https://arxiv.org/abs/2510.21191)
*Adarsh Jain,Pawan Bharadwaj,Chandra Sekhar Seelamantula*

Main category: physics.geo-ph

TL;DR: 本文提出了一种基于冷扩散模型和指数核的框架，利用U-Net解决重力数据向下延拓这一病态反卷积问题，相较于传统方法在抗噪性和性能上表现更优，且接近拥有真实标签的Oracle Tikhonov方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决重力数据向下延拓中传统正则化方法对参数敏感以及U-Net对相关噪声敏感的问题，需要一种更鲁棒、无需手动调参的去卷积方法。

Method: 基于冷扩散模型设计指数核，利用该核的特性训练U-Net，使其能够同时处理不同程度模糊的反卷积问题，从而提升模型鲁棒性与泛化能力。

Result: 所提框架在定量指标上优于传统的U-Net方法，性能接近拥有真实标签信息的Oracle Tikhonov正则化方法，且对相关噪声具有更强的鲁棒性。

Conclusion: 基于冷扩散模型与指数核的U-Net框架能有效解决向下延拓中的多尺度去卷积问题，是一种稳定、高效且接近理想性能的重力数据处理新方法。

Abstract: Gravity data can be better interpreted after enhancing high-frequency
information via downward continuation. Downward continuation is an ill-posed
deconvolution problem. It has been tackled using regularization techniques,
which are sensitive to the choice of regularization parameters. More recently,
convolutional neural networks such as the U-Net have been trained using
synthetic data to potentially learn prior information and perform deconvolution
without the need to adjust the regularization parameters. Our experiments
reveal that the U-Net is highly sensitive to correlated noise, which is
ubiquitously present in geophysical field data. In this paper, we develop a
framework based on the $\textbf{cold-diffusion model}$ using the exponential
kernel associated with downward continuation. The exponential form of the
kernel allows us to train the U-Net to tackle multiple concurrent deconvolution
problems with varying levels of blur. This allows our framework to be more
robust and quantitatively outperform traditional U-Net-based approaches. The
performances also closely matches that of $\textbf{oracle}$ Tikhonov
reconstruction technique, which has access to the ground truth.

</details>
