{"id": "2511.21715", "categories": ["physics.hist-ph", "cond-mat.stat-mech", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21715", "abs": "https://arxiv.org/abs/2511.21715", "authors": ["Robert W. Batterman", "James F. Woodward"], "title": "DNNs, Dataset Statistics, and Correlation Functions", "comment": "37 pages, 12 figures", "summary": "This paper argues that dataset structure is important in image recognition tasks (among other tasks). Specifically, we focus on the nature and genesis of correlational structure in the actual datasets upon which DNNs are trained. We argue that DNNs are implementing a widespread methodology in condensed matter physics and materials science that focuses on mesoscale correlation structures that live between fundamental atomic/molecular scales and continuum scales. Specifically, we argue that DNNs that are successful in image classification must be discovering high order correlation functions. It is well-known that DNNs successfully generalize in apparent contravention of standard statistical learning theory. We consider the implications of our discussion for this puzzle."}
{"id": "2511.22547", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2511.22547", "abs": "https://arxiv.org/abs/2511.22547", "authors": ["Jin-Xin Tan", "Zhi-Chao Gong", "Jun Hua", "Xiangdong Ji", "Xiangyu Jiang", "Hang Liu", "Andreas Schäfer", "Yushan Su", "Han-Zhang Wang", "Wei Wang", "Yi-Bo Yang", "Jun Zeng", "Jian-Hui Zhang", "Jia-Lu Zhang", "Qi-An Zhang"], "title": "Lattice QCD Determination of the Collins-Soper Kernel in the Continuum and Physical Mass Limits", "comment": "43 pages, 41 figures, 3 tables", "summary": "The Collins-Soper (CS) kernel governs the rapidity evolution of transverse-momentum-dependent (TMD) parton distributions, a cornerstone for QCD factorization and linking nucleon structure data across scales. Its nonperturbative behavior at large transverse separations ($b_{\\perp}$) remains weakly constrained due to phenomenological model dependencies. We present a first-principles determination of the CS kernel at the continuum limit and physical pion mass from lattice QCD in the large-momentum effective theory framework. Using (2+1)-flavor configurations (lattice spacings $a =(0.052-0.105$) fm, and pion mass $m_π \\approx (136, 230, 300, 320)$ MeV), we simulating the nonlocal equal-time correlation function and extract the quasi-TMD wave functions. Taking into account systematic improvements including hypercubic smearing, nonperturbative renormalization, and a $b_{\\perp}$-unexpanded matching kernel, we obtain the CS kernel at the continuum, chiral, and infinite-momentum limits. Our results are determined up to $b_{\\perp} \\sim 1$ fm, with controllable uncertainties, and agree with perturbative QCD at small $b_{\\perp}$ and global TMD phenomenological extractions. We conduct a global analysis integrated with phenomenological fits and demonstrate the impact of our results on such fits. This work yields the most precise nonperturbative constraint on the CS kernel's long-distance behavior from Lattice QCD, which not only bridges Lattice QCD, perturbation theory, and nucleon structure experiments for TMD studies, but also boosts the utility of our constraint for future global TMD analyses."}
{"id": "2511.21806", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.21806", "abs": "https://arxiv.org/abs/2511.21806", "authors": ["Robin Schäfer", "Paul L. Ebert", "Noah Hassan", "Johannes Reuther", "David J. Luitz", "Alexander Wietek"], "title": "Thermodynamics of the Heisenberg antiferromagnet on the maple-leaf lattice", "comment": null, "summary": "We study the Heisenberg antiferromagnet on the maple-leaf lattice using several numerical approaches, focusing on the numerical linked-cluster expansion (NLCE), which exhibits an unconventional convergence extending to low and even zero temperatures. We evaluate thermodynamic properties as well as spin-spin correlations through the equal-time structure factor. Within NLCE the specific heat capacity reveals a two-peak structure at $T_1 \\approx 0.479\\,J$ and $T_2 \\approx 0.131\\,J$, reminiscent of the corresponding result for the triangular lattice. At intermediate temperatures, the spin-spin structure factor develops features that reflect the absence of reflection symmetry in the lattice. The zero-temperature convergence of NLCE enables reliable estimates of the ground-state energy and points to a short-range correlated paramagnetic ground state composed of resonating hexagonal motifs. The NLCE results are benchmarked against Pseudo-Majorana Functional Renormalization Group, finite-temperature Lanczos, and classical Monte Carlo simulations."}
{"id": "2511.22185", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.22185", "abs": "https://arxiv.org/abs/2511.22185", "authors": ["Ruize Gao", "Feng Xiao", "Jinpu Li", "Shaoze Cui"], "title": "Textual semantics and machine learning methods for data product pricing", "comment": null, "summary": "Reasonable pricing of data products enables data trading platforms to maximize revenue and foster the growth of the data trading market. The textual semantics of data products are vital for pricing and contain significant value that remains largely underexplored. Therefore, to investigate how textual features influence data product pricing, we employ five prevalent text representation techniques to encode the descriptive text of data products. And then, we employ six machine learning methods to predict data product prices, including linear regression, neural networks, decision trees, support vector machines, random forests, and XGBoost. Our empirical design consists of two tasks: a regression task that predicts the continuous price of data products, and a classification task that discretizes price into ordered categories. Furthermore, we conduct feature importance analysis by the mRMR feature selection method and SHAP-based interpretability techniques. Based on empirical data from the AWA Data Exchange, we find that for predicting continuous prices, Word2Vec text representations capturing semantic similarity yield superior performance. In contrast, for price-tier classification tasks, simpler representations that do not rely on semantic similarity, such as Bag-of-Words and TF-IDF, perform better. SHAP analysis reveals that semantic features related to healthcare and demographics tend to increase prices, whereas those associated with weather and environmental topics are linked to lower prices. This analytical framework significantly enhances the interpretability of pricing models."}
{"id": "2511.21713", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.21713", "abs": "https://arxiv.org/abs/2511.21713", "authors": ["Mauricio Guerrero-Montero", "Michal Bosy", "Christopher D. Cooper"], "title": "A Self-Adjusting FEM-BEM Coupling Scheme for the Nonlinear Poisson-Boltzmann Equation", "comment": null, "summary": "The Poisson-Boltzmann equation is widely used to model molecular electrostatics; however, it is usually solved in linearised form because the sinh nonlinearity is challenging, limiting its applicability in highly charged systems such as nucleic acids. This work presents a solution method for the nonlinear Poisson-Boltzmann equation based on a coupled finite/boundary element scheme that automatically finds an optimal relaxation parameter, ensuring fast and reliable convergence of the nonlinear solver without user intervention. We validated our solver against APBS for a spherical cavity, and used RNA-based structures to perform a thorough study of the different algorithmic choices, and to test our implementation. We found that the best alternative to solve the Poisson-Boltzmann equation was using a Newton-Raphson method where the nonlinearity was gradually introduced with a cubic approximation in the first iteration. Newton-Raphson was also the best method to find the optimal relaxation factor, reducing the number of iterations by 40%. Including other optimisation techniques, we were able to obtain a 1.37x speed-up with respect to the best hand-picked relaxation factor for 1HC8 (molecule with highest charge in our tests), avoiding any trial-and-error process to find the relaxation factor."}
{"id": "2511.22694", "categories": ["math.ST", "math.SP"], "pdf": "https://arxiv.org/pdf/2511.22694", "abs": "https://arxiv.org/abs/2511.22694", "authors": ["Yann Chaubet", "Vincent Divol"], "title": "Minimax spectral estimation of weighted Laplace operators", "comment": null, "summary": "Given $n$ i.i.d. observations, we study the problem of estimating the spectrum of weighted Laplace operators of the form $Δ_f=Δ+ α\\nabla \\log f\\cdot \\nabla$, where $f$ is a positive probability density on a known compact $d$-dimensional manifold without boundary and $α\\in \\mathbb{R}$ is a hyperparameter. These operators arise as continuum limits of graph Laplacian matrices and provide valuable geometric information on the underlying data distribution. We establish the exact minimax rates of estimation for this problem, by exhibiting two different rates of convergence for eigenfunctions and eigenvalues. When $f$ belongs to a Hölder-Zygmund class $\\mathscr{C}^s$ of regularity $s\\geqslant 2$, the eigenfunctions can be estimated with respect to the $\\mathrm{L}^q$-norm ($q\\geqslant 1$) via plug-in methods at the minimax rate $n^{-\\frac{s+1}{2s+d}}$ for $d\\geqslant 3$ (with different rates for $d\\leqslant 2$). Moreover, eigenvalues can be estimated at the minimax rate $n^{-\\frac{4s}{4s+d}}+n^{-\\frac 12}$. In the regime $s>\\frac d4$, we further show that asymptotically efficient estimators exist.\n  We also present a general framework for estimating nonlinear functionals over Hölder-Zygmund spaces, with potential applications to a broad class of statistical problems."}
{"id": "2511.21871", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.21871", "abs": "https://arxiv.org/abs/2511.21871", "authors": ["Yingke Li", "Yifan Lin", "Enlu Zhou", "Fumin Zhang"], "title": "Bayesian Risk-averse Model Predictive Control with Consistency and Stability Guarantees", "comment": null, "summary": "Model Predictive Control (MPC) is a powerful framework for constrained control, but its performance and safety can be severely degraded when the prediction model is learned online and thus remains uncertain. In this work, we develop a Bayesian risk-averse MPC framework for stochastic, discrete-time, nonlinear systems that provides theoretical guarantees on the consistency of Bayesian learning and closed-loop stability. First, we study Bayesian learning under the conditionally independent state transitions induced by feedback control and establish explicit conditions for Bayesian consistency on an infinitely countable parameter space. Second, we introduce a general notion of risk-averse asymptotic stability (RAAS), defined via comparison function classes and independent of any specific coherent risk measure or convergence rate, and we derive a risk-averse Lyapunov stability theorem together with MPC-specific stability conditions. Third, building on these foundations, we design a practical Bayesian risk-averse MPC scheme that separates epistemic (parametric) and aleatoric (disturbance) uncertainty: additive disturbances are treated in a risk-neutral fashion, while parametric uncertainty is managed via dynamically shrinking ambiguity sets constructed from Bayesian credible intervals, approximated online using particle filtering. To enable real-time implementation, we propose both an optimal and a sub-optimal receding-horizon control policy, the latter obtained by warm-starting from the previous solution, and prove that asymptotic RAAS is recovered as the Bayesian estimator becomes consistent."}
{"id": "2511.22020", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.22020", "abs": "https://arxiv.org/abs/2511.22020", "authors": ["Shreyas Sadugol", "Giuseppe Luca Celardo", "Fausto Borgonovi", "Lev Kaplan"], "title": "Shaping Causality: Emergence of Nonlocal Light Cones in Long-Range Quantum Systems", "comment": "Includes Supplementary Material", "summary": "While for non-relativistic short-range interactions, the spread of information is local, remaining confined in an effective light cone, long-range interactions can generate either nonlocal (faster-than-ballistic) or local (ballistic) spread of correlations depending on the initial conditions. This makes long-range interactions a rich platform for controlling the spread of information. Here, we derive an effective Hamiltonian analytically and identify the specific interaction term that drives nonlocality in a wide class of long-range spin chains. This allows us to understand the conditions for the emergence of local behavior in the presence of nonlocal interactions and to identify a regime where the causal space-time landscape can be precisely designed. Indeed, we show that for large long-range interaction strength or large system size, initial conditions can be chosen in a way that allows a local perturbation to generate nonlocal signals at programmable distant positions, which then propagate within effective light cones. The possibility of engineering the emergence of nonlocal Lieb-Robinson-like light cones allows one to shape the causal landscape of long-range interacting systems, with direct applications to quantum information processing devices, quantum memories, error correction, and information transport in programmable quantum simulators."}
{"id": "2511.21796", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.21796", "abs": "https://arxiv.org/abs/2511.21796", "authors": ["Shah Zayed Riam", "Zhenlin Pei", "Kyle Mooney", "Chenyun Pan", "Na Gong", "Jinhui Wang"], "title": "Sneak Path Current Modeling in Memristor Crossbar Arrays for Analog In-Memory Computing", "comment": null, "summary": "Memristor crossbar arrays have emerged as a key component for next-generation non-volatile memories, artificial neural networks, and analog in-memory computing (IMC) systems. By minimizing data transfer between the processor and memory, they offer substantial energy savings. However, a major design challenge in memristor crossbar arrays is the presence of sneak path currents, which degrade electrical performance, reduce noise margins, and limit reliable operations. This work presents a closed-form analytical framework based on IMEC A14 (1.4 nm) Technology for accurately estimating sneak path currents in memristor crossbar arrays. The proposed model captures the interdependence of key design parameters in memristor crossbar arrays, including array size, ON/OFF ratio of memristors, read voltage, and interconnect conditions, through mathematically derived relationships. It supports various practical configurations, such as different data patterns and connection strategies, enabling rapid and comprehensive sneak path current modeling. The sensitivity analysis includes how design parameters influence sneak path current and noise margin loss, underscoring the trade-offs involved in scaling crossbar arrays. Validation through SPICE simulations shows that the model achieves an error of less than 10.9% while being up to 4784 times faster than full circuit simulations. This analytical framework offers a powerful tool for quantitative assessment and pre-design/real-time optimization of memristor-based analog in-memory computing (IMC) architectures."}
{"id": "2511.21719", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.21719", "abs": "https://arxiv.org/abs/2511.21719", "authors": ["Marina Andrade", "Manuel Alberto M. Ferreira"], "title": "The Problem of Civil and Criminal Identification -- Bayesian Networks Approach", "comment": "11 pages and 2 figures", "summary": "DNA evidence use in problems of civil and criminal identification is becoming greater. The necessity of evaluating the weight of that evidence may be accomplished using one of the most known powerful tools: the Bayesian networks. In the current paper this will be illustrated through the presentation of a civil identification problem and of a criminal identification problem."}
{"id": "2511.21792", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.21792", "abs": "https://arxiv.org/abs/2511.21792", "authors": ["Yanmo Weng", "Avantika Gori"], "title": "Climatological benchmarking of AI-generated tropical cyclones", "comment": null, "summary": "This study presents a comprehensive climatological benchmarking of tropical cyclones (TCs) generated by AI-based global weather prediction models. Using all TC events from the North Atlantic and Western Pacific basins between 2020 and 2025, we assess the ability of two AI models (Pangu-Weather and Aurora) to reproduce observed TC track density, climatology of storm characteristics, and physical consistency with TC theory. By comparing AI-simulated TCs with ERA5 reanalysis, we benchmark the distributions of intensity, size, forward speed, and evaluate the model's ability to credibly simulate extratropical transition. Results show that both Pangu and Aurora perform well in reproducing storm track density, forward speed distribution, and outer size distribution. Aurora shows an improved performance in simulating storm intensity compared to Pangu, with less bias in the distribution of minimum central pressure and maximum wind speed. However, both models overestimate the distribution of storm inner size (radius of maximum winds), especially for extreme events. AI models capture the relative frequency and temporal evolution of extratropical transition patterns with reasonable accuracy. The AI-simulated TCs are also less likely to conform to gradient wind balance compared to ERA5, indicating that the AI TCs may not be physically realistic in many cases. This benchmarking identifies systematic biases that can guide future corrections and support extended applications of AI models for TC hazard and risk assessment. Our work establishes a foundation for future studies using AI weather models in the context of TC climatological and hazard research."}
{"id": "2511.22678", "categories": ["hep-lat", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.22678", "abs": "https://arxiv.org/abs/2511.22678", "authors": ["Anna Hasenfratz", "Oliver Witzel"], "title": "Symmetric Mass Generation", "comment": "7 pages, 4 figures, Proceedings of The European Physical Society Conference on High Energy Physics (EPS-HEP2025), 7-11 July 2025, Marseille, France", "summary": "In recent years tantalizing signs for a novel phase have been reported that is chirally symmetric but nevertheless exhibits massive bound states. The necessary condition for such a phase, referred to as Symmetric Mass Generation (SMG), is the cancellation of all (continuous and discrete) 't~Hooft anomalies. In 3+1 dimensions this occurs in systems containing a multiple of 16 massless Weyl fermions. SMG was originally discovered in lower dimensional condensed matter systems. We present results investigating four dimensional field theories with gauge group SU(3). Our findings suggest that SU(3) with $N_f=8$ fundamental fermions exhibits an SMG phase not only on the lattice but also in the infinite cutoff continuum limit. If confirmed, SMG could provide a new UV completion of the standard model and give rise to new scenarios for beyond standard model physics."}
{"id": "2511.21815", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.21815", "abs": "https://arxiv.org/abs/2511.21815", "authors": ["Ramanjit Sohal", "Ruben Verresen"], "title": "Obstruction to Ergodicity from Locality and $U(1)$ Higher Symmetries on the Lattice", "comment": "5+3 pages", "summary": "We argue that the presence of \\emph{any} exact $U(1)$ higher-form symmetry, under mild assumptions, presents a fundamental obstruction to ergodicity under unitary dynamics in lattice systems with local interactions and finite on-site Hilbert space dimension. Focusing on the two-dimensional case, we show that such systems necessarily exhibit Hilbert space fragmentation and explicitly construct Krylov sectors whose number scales exponentially with system size. While these sectors cannot be distinguished by symmetry quantum numbers, we identify the emergent integrals of motion which characterize them. Our symmetry-based approach is insensitive to details of the Hamiltonian and the lattice, providing a systematic explanation for ergodicity-breaking in a range of systems, including quantum link models."}
{"id": "2511.23016", "categories": ["cs.CE", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.23016", "abs": "https://arxiv.org/abs/2511.23016", "authors": ["Moritz Hütten"], "title": "Maritime Activities Observed Through Open-Access Positioning Data: Moving and Stationary Vessels in the Baltic Sea", "comment": "29 pages, 15 figures, and 9 tables, matching the version published in Geomatics. Accompanying research data are available at http://dx.doi.org/10.6084/m9.figshare.29062715", "summary": "Understanding past and present maritime activity patterns is critical for navigation safety, environmental assessment, and commercial operations. An increasing number of services now openly provide positioning data from the Automatic Identification System (AIS) via ground-based receivers. We show that coastal vessel activity can be reconstructed from open access data with high accuracy, even with limited data quality and incomplete receiver coverage. For three months of open AIS data in the Baltic Sea from August to October 2024, we present (i) cleansing and reconstruction methods to improve the data quality, and (ii) a journey model that converts AIS message data into vessel counts, traffic estimates, and spatially resolved vessel density at a resolution of $\\sim$400 m. Vessel counts are provided, along with their uncertainties, for both moving and stationary activity. Vessel density maps also enable the identification of port locations, and we infer the most crowded and busiest coastal areas in the Baltic Sea. We find that on average, $\\gtrsim$4000 vessels simultaneously operate in the Baltic Sea, and more than 300 vessels enter or leave the area each day. Our results agree within 20\\% with previous studies relying on proprietary data."}
{"id": "2511.21839", "categories": ["physics.comp-ph", "physics.acc-ph", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2511.21839", "abs": "https://arxiv.org/abs/2511.21839", "authors": ["Ji Qianga", "Yue Hao", "Allen Qiang", "Jinyu Wan"], "title": "A multi-language auto-differentiation module and its application to a parallel particle-in-cell code on distributed computers", "comment": null, "summary": "The auto differentiable simulation is a type of simulation that outputs of the simulation include not only the simulation result itself, but also their derivatives with respect to various input parameters. It provides an efficient method to study sensitivity of the simulation results with respect to the input parameters. Furthermore, it can be used in gradient based optimization methods for rapidly optimizing design parameters. In this paper, we present the development of a fast and transparent auto-differentiation module/class designed for easy integration into numerous simulation codes. As an application, this auto-differentiation module is integrated into a parallel particle-in-cell code with message passing interface (MPI) on distributed memory computers."}
{"id": "2511.22816", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22816", "abs": "https://arxiv.org/abs/2511.22816", "authors": ["Miodrag M. Lovric"], "title": "What the Jeffreys-Lindley Paradox Really Is: Correcting a Persistent Misconception", "comment": "21 pages, 1 figure, 1 table. Submitted to Statistica Sinica", "summary": "The Jeffreys-Lindley paradox stands as the most profound divergence between frequentist and Bayesian approaches to hypothesis testing. Yet despite more than six decades of discussion, this paradox remains frequently misunderstood--even in the pages of leading statistical journals. In a 1993 paper published in Statistica Sinica, Robert characterized the Jeffreys-Lindley paradox as \"the fact that a point null hypothesis will always be accepted when the variance of a conjugate prior goes to infinity.\" This characterization, however, describes a different phenomenon entirely-what we term Bartlett's Anomaly-rather than the Jeffreys-Lindley paradox as originally formulated. The paradox, as presented by Lindley (1957), concerns what happens as sample size increases without bound while holding the significance level fixed, not what happens as prior variance diverges. This distinction is not merely terminological: the two phenomena have different mathematical structures, different implications, and require different solutions. The present paper aims to clarify this confusion, demonstrating through Lindley's own equations that he was concerned exclusively with sample size asymptotics. We show that even Jeffreys himself underestimated the practical frequency of the paradox. Finally, we argue that the only genuine resolution lies in abandoning point null hypotheses in favor of interval nulls, a paradigm shift that eliminates the paradox and restores harmony between Bayesian and frequentist inference. Submitted to Statistica Sinica."}
{"id": "2511.21917", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.21917", "abs": "https://arxiv.org/abs/2511.21917", "authors": ["Luwei Bai", "Yang Zeng", "Baoyu Zhou"], "title": "Generalization of Silver Stepsize Schedule to Stochastic Optimization", "comment": "29 pages, 5 figures", "summary": "This work introduces a two-step stepsize schedule for stochastic gradient methods minimizing smooth strongly convex functions. We consider the setting where only stochastic gradient approximations, which are unbiased, of bounded variance, and supported on a finite set, are accessible. When the variance bound is relatively smaller than a ratio of the initial optimality gap, the proposed stepsize schedule achieves better convergence performance compared to the well-regarded constant stepsize α = 2/(M+m), where m and M denote the strong convexity and gradient-Lipschitz parameters, respectively. Our stepsize schedule can be viewed as a generalization of the well-known two-step silver stepsize schedule in [J. M. Altschuler and P. A. Parrilo, Journal of the ACM, 72(2):1-38, 2025] from deterministic setting to stochastic optimization."}
{"id": "2511.22079", "categories": ["cond-mat.stat-mech", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.22079", "abs": "https://arxiv.org/abs/2511.22079", "authors": ["Mario A. Ciampini", "Jakob Rieser", "Nikolai Kiesel", "Andreas Dechant"], "title": "Entropy production and non-Gaussianity of fast processes at weak damping", "comment": "17 pages, 7 figures", "summary": "We present a method of estimating the rate of entropy production in underdamped dynamics by decomposing it into contributions originating in different non-equilibrium effects. Specifically, a non-zero average velocity, a non-thermal width of the velocity distribution, correlations between position and velocity and non-Gaussian velocity statistics represent different ways in which the system can be out of equilibrium and each give rise to a positive contribution to the overall entropy production rate. We demonstrate that each contribution can be separately estimated from experimental trajectory data of levitated nano-particles subject to non-linear forces. We find that the majority of the entropy production rate can be attributed to the first three contributions which can be estimated from the first and second moments of the position and velocity and therefore result in a useful \\enquote{Gaussian} estimate for the entropy production rate."}
{"id": "2511.22408", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.22408", "abs": "https://arxiv.org/abs/2511.22408", "authors": ["Yizhi He", "Sayed Amir Hoseini", "Mahbub Hassan"], "title": "Quantifying Geometry Effects on Low-Cost Intelligent Reflecting Surfaces", "comment": "6 pages, 11 figures", "summary": "Intelligent Reflecting Surfaces (IRS) promise low-power coverage extension, yet practical deployments must curb hardware complexity and control overhead. This paper quantifies the performance impact of two cost-saving measures, column-wise element grouping and 1-bit (binary) phase quantization, relative to the ideal fully-controlled, continuous-phase baseline. A single-input single-output link is simulated at 26 GHz (mmWave) across three deployment geometries that vary the relative heights of access point, IRS and user equipment. Results show that switching from continuous to binary phase control reduces median SNR gain by approximately 4 dB, while adopting column-wise grouping introduces a similar penalty; combining both constraints incurs approximately 8 dB loss under height-offset deployments. When all nodes share the same height, the degradation from column-wise control becomes negligible, indicating deployment geometry can offset control-granularity limits. Despite the losses, a 32 x 32 column-wise binary IRS still delivers double-digit SNR gains over the no-IRS baseline in most positions, confirming its viability for cost-constrained scenarios. The study provides quantitative guidelines on when simplified IRS architectures can meet link-budget targets and where full element-wise control remains justified."}
{"id": "2511.21782", "categories": ["physics.soc-ph", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.21782", "abs": "https://arxiv.org/abs/2511.21782", "authors": ["Fong Yew Leong", "Jaeyoung Kwak", "Zhengwei Ge", "Chin Chun Ooi", "Siew-Wai Fong", "Matthew Zirui Tay", "Hua Qian", "Chang Wei Kang", "Wentong Cai", "Hongying Li"], "title": "CompARE: A Computational framework for Airborne Respiratory disease Evaluation integrating flow physics and human behavior", "comment": null, "summary": "The risk of indoor airborne transmission among co-located individuals is generally non-uniform, which remains a critical challenge for public health modelling. Thus, we present CompARE, an integrated risk assessment framework for indoor airborne disease transmission that reveals a striking bimodal distribution of infection risk driven by airflow dynamics and human behavior. Combining computational fluid dynamics (CFD), machine learning (ML), and agent-based modeling (ABM), our model captures the complex interplay between aerosol transport, human mobility, and environmental context. Based on a prototypical childcare center, our approach quantifies how incorporation of ABM can unveil significantly different infection risk profiles across agents, with more than two-fold change in risk of infection between the individuals with the lowest and highest risks in more than 90% of cases, despite all individuals being in the same overall environment. We found that infection risk distributions can exhibit not only a striking bimodal pattern in certain activities but also exponential decay and fat-tailed behavior in others. Specifically, we identify low-risk modes arising from source containment, as well as high-risk tails from prolonged close contact. Our approach enables near-real-time scenario analysis and provides policy-relevant quantitative insights into how ventilation design, spatial layout, and social distancing policies can mitigate transmission risk. These findings challenge simple distance-based heuristics and support the design of targeted, evidence-based interventions in high-occupancy indoor settings."}
{"id": "2511.21856", "categories": ["physics.ao-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.21856", "abs": "https://arxiv.org/abs/2511.21856", "authors": ["Md Meftahul Ferdaus", "Nathan Alton Cooper", "Austin B. Schmidt", "Pujan Pokhrel", "Elias Ioup", "Mahdi Abdelguerfi", "Julian Simeonov"], "title": "A Comprehensive Review of Phase-Averaged and Phase-Resolving Wave Models for Coastal Modeling Applications", "comment": "Paper submitted to Elsevier", "summary": "Predicting ocean wave behavior is challenging due to the difficulty in choosing suitable numerical models among many with varying capabilities. This review examines the development and performance of numerical wave models in coastal engineering and oceanography, focusing on the difference between phase-averaged spectral models and phase-resolving models. We evaluate the formulation, governing equations, and methods of widely used third-generation phase-averaged spectral models (SWAN, WAVEWATCH III, MIKE 21 SW, TOMAWAC, and WAM) alongside advanced phase-resolving models (FUNWAVE, SWASH, COULWAVE, and NHWAVE) that employ Boussinesq-type equations and non-hydrostatic formulations. The review begins with early parameterized models and progresses to contemporary third-generation models, which solve the wave action conservation equation with few spectral constraints. A comparison of the models' efficiency, accuracy in nearshore conditions, ability to resolve nonlinear wave-wave interaction, simulate wave breaking, diffraction, and wave-current interactions is provided. Applications in operational forecasting, extreme event simulation, coastal structure design, and assessing climate change impacts are discussed. The validation of these models and the statistical metrics and intercomparison studies used are addressed. A discussion of the limitations in computational scalability, physics parameterization, and model coupling is provided, along with emerging trends in high-resolution modeling and hybrid models. This review guides researchers in evaluating which models to use in coastal and oceanographic research."}
{"id": "2511.21858", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.21858", "abs": "https://arxiv.org/abs/2511.21858", "authors": ["Stefan Güttel", "Shuai Shao"], "title": "Concentrated real-pole uniform-in-time approximation of the matrix exponential", "comment": null, "summary": "We propose an asympotically optimal choice of shared concentrated real poles of a family of rational approximants of time-dependent exponential functions $\\exp(-tz)$ for $z \\geq 0$ and $t$ in a positive time interval $T$. Our result extends a classical result by J.-E.Andersson [J.Approx.Theory, 32(2):85--95, 1981] on the asymptotic best rational approximation of $\\exp(-z)$ with real poles. Numerical experiments demonstrate the near-optimality of our choice for various time ranges and for both small and large approximation degrees. An application of the uniform-in-time rational approximation using our proposed concentrated real poles to a linear constant-coefficient initial-value problem is also discussed."}
{"id": "2511.21849", "categories": ["cs.SI", "cond-mat.stat-mech", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.21849", "abs": "https://arxiv.org/abs/2511.21849", "authors": ["Majid Saberi", "Samin Aref"], "title": "Evaluating Global Measures of Network Centralization: Axiomatic and Numerical Assessments", "comment": "Peer-reviewed author copy", "summary": "Network centralization, driven by hub nodes, impacts communication efficiency, structural integration, and dynamic processes such as diffusion and synchronization. Although numerous centralization measures exist, a major challenge lies in determining measures that are both theoretically sound and empirically reliable across different network contexts. To resolve this challenge, we normalize 11 measures of network centralization and assess them systematically using an axiomatic framework and numerical simulations. Our axiomatic assessment tests each measure against the six postulates of centralization, ensuring consistency with minimal theoretical requirements. In addition, our numerical assessment examines the behavior of normalized centralization measures over different random graphs. Our results indicate major differences among the measures, despite their common aim of quantifying centralization. Together, our assessments point to the relative suitability of three measures: normalized betweenness centralization, normalized closeness centralization, and normalized degree centralization. Applying these three measures to real-world networks from diverse domains reveals meaningful variation in the organization of the networks with respect to hubs. Normalized betweenness centralization highlights path-based dominance; normalized closeness centralization reflects accessibility and efficiency of reach; and normalized degree centralization captures degree-based hub concentration. When used jointly, the three measures demonstrate the required sensitivity to varying levels of centralization and provide complementary aspects of network centralization that no single measure can offer alone. Our dual evaluation framework clarifies conceptual differences among existing measures and offers practical guidance for selecting reliable centralization metrics."}
{"id": "2511.23398", "categories": ["quant-ph", "cond-mat.stat-mech", "math-ph", "nlin.CG"], "pdf": "https://arxiv.org/pdf/2511.23398", "abs": "https://arxiv.org/abs/2511.23398", "authors": ["Lorenzo Siro Trezzini", "Andrea Pizzamiglio", "Alessandro Bisio", "Paolo Perinotti"], "title": "Renormalisation of Fermionic Cellular Automata", "comment": "16 + 12 pages, 4 figures", "summary": "We present an exact renormalisation scheme for fermionic cellular automata on hypercubic lattices. By grouping neighbouring cells into tiles and selecting subspaces within them, multiple evolution steps on the original system correspond to a single step of an effective automaton acting on the subspaces. We derive a necessary and sufficient condition for renormalisability and fully characterise the renormalisation flow for two-cell tiles and two time steps of nearest-neighbour fermionic automata on a chain of spinless modes, identifying all fixed points."}
{"id": "2511.22878", "categories": ["hep-lat", "hep-ph", "nucl-th"], "pdf": "https://arxiv.org/pdf/2511.22878", "abs": "https://arxiv.org/abs/2511.22878", "authors": ["Etsuko Itou", "Kei Iida", "Kotaro Murakami", "Daiki Suenaga"], "title": "Speed of sound exceeding the conformal bound in dense QCD-like theories", "comment": "5pages, Proceedings of the 29th International Nuclear Physics Conference (INPC2025), Deajon, Korea, May 25-30, 2025", "summary": "We investigated the phase structure and the equation of state (EoS) for dense two-color QCD at low temperatures using the lattice Monte Carlo simulations. A rich phase structure below the pseudo-critical temperature $T_c$ as a function of quark chemical potential has been revealed. In a high-density regime, we can see a superfluid phase, where the diquark condensate takes a non-zero expectation value. We have newly found that the speed of sound exceeds the conformal bound, which is the value of the relativistic free theory. This talk is based on Refs.~\\cite{Iida:2022hyy, Iida:2024irv, Itou:2025vcy}."}
{"id": "2511.22002", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2511.22002", "abs": "https://arxiv.org/abs/2511.22002", "authors": ["Muxian Xu", "Siyu Cheng", "Andrea Capa Salinas", "Ganesh Pokharel", "Alexander LaFleur", "Hong Li", "Hengxin Tan", "Brenden R. Ortiz", "Qinwen Deng", "Binghai Yan", "Ziqiang Wang", "Stephen D. Wilson", "Ilija Zeljkovic"], "title": "Pervasive electronic nematicity as the parent state of kagome superconductors", "comment": null, "summary": "Kagome superconductors $A$V$_3$Sb$_5$ ($A$ = Cs, K, Rb) have developed into an exciting playground for realizing and exploring exotic solid state phenomena. Abundant experimental evidence suggests that electronic structure breaks rotational symmetry of the lattice, but whether this may be a simple consequence of the symmetry of the underlying 2 $\\times$ 2 charge density wave phase or an entirely different mechanism remains intensely debated. We use spectroscopic imaging scanning tunneling microscopy to explore the phase diagram of the prototypical kagome superconductor CsV$_3$Sb$_5$ as a function of doping. We intentionally suppress the charge density wave phase with chemical substitutions selectively introduced at two distinct lattice sites, and investigate the resulting system. We discover that rotational symmetry breaking of the electronic structure -- now present in short-range nanoscale regions -- persists in all samples, in a wide doping range long after all charge density waves have been suppressed. As such, our experiments uncover ubiquitous electronic nematicity across the $A$V$_3$Sb$_5$ phase diagram, unrelated to the 2 $\\times$ 2 charge density wave. This further points towards electronic nematicity as the intrinsic nature of the parent state of kagome superconductors, under which other exotic low-temperature phenomena subsequently emerge."}
{"id": "2511.23064", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.23064", "abs": "https://arxiv.org/abs/2511.23064", "authors": ["Jonas Heinzmann", "Francesco Vicentini", "Pietro Carrara", "Laura De Lorenzis"], "title": "Iterative convergence in phase-field brittle fracture computations: exact line search is all you need", "comment": null, "summary": "Variational phase-field models of brittle fracture pose a local constrained minimization problem of a non-convex energy functional. In the discrete setting, the problem is most often solved by alternate minimization, exploiting the separate convexity of the energy with respect to the two unknowns. This approach is theoretically guaranteed to converge, provided each of the individual subproblems is solved successfully. However, strong non-linearities of the energy functional may lead to failure of iterative convergence within one or both subproblems. In this paper, we propose an exact line search algorithm based on bisection, which (under certain conditions) guarantees global convergence of Newton's method for each subproblem and consequently the successful determination of critical points of the energy through the alternate minimization scheme. Through several benchmark tests computed with various strain energy decompositions and two strategies for the enforcement of the irreversibility constraint in two and three dimensions, we demonstrate the robustness of the approach and assess its efficiency in comparison with other commonly used line search algorithms."}
{"id": "2511.22088", "categories": ["physics.comp-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.22088", "abs": "https://arxiv.org/abs/2511.22088", "authors": ["Jing-yi Shi", "Jia-qi Song", "Peng-cheng Ji", "Zi-qing Zhao", "Yuan-jin Yu", "Ming-fei Li", "Ling-an Wu"], "title": "Single-pixel imaging via data-driven and deep image prior dual networks", "comment": null, "summary": "Single-pixel imaging(SPI),especially when integrated with deep neural networks like deep image prior networks (DIP-Net) or data-driven networks (DD-Net), has gained considerable attention for its capability to generate high-quality reconstructed images, even in the presence of sub-sampling conditions. However, DIP-Net often requires thousands of iterations to achieve high-quality image reconstruction, and DD-Net performs optimally only when the target closely resembles the features present in its training set. To overcome these limitations, we propose a dual-network iterative optimization (SPI-DNIO) framework that combines the strengths of both DD-Net and DIP-Net. It has been demonstrated that this approach can recover high-quality images with fewer iteration steps. Furthermore, to address the challenge of SPI inputs having less effective information at low sampling rates, we have designed a residual block enriched with gradient information, which can convey details to deeper layers, thereby enhancing the deep network's learning capabilities. We have applied these techniques to both indoor experiments with active lighting and outdoor long-range experiments with passive lighting. Our experimental results confirm the exceptional reconstruction capabilities and generalization performance of the SPI-DNIO framework."}
{"id": "2511.23008", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.23008", "abs": "https://arxiv.org/abs/2511.23008", "authors": ["Alessia Caponera", "Vinicius Ferreira", "Emilio Porcu"], "title": "Functional Gaussian Fields on Hyperspheres with their Equivalent Gaussian Measures", "comment": null, "summary": "We develop a general framework for isotropic functional Gaussian fields on the $d$-dimensional sphere $\\mathbb{S}^{d}$, where the field takes values in a separable Hilbert space $\\mathcal{H}$. We establish an operator-valued extension of Schoenberg's theorem and show that the covariance structure of such fields admits a representation through a sequence of trace-class $d$-Schoenberg operators, yielding an explicit spectral decomposition of the covariance operator on $L^{2}(\\mathbb{S}^{d};\\mathcal{H})$. We derive a functional version of the Feldman-H'ajek criterion and prove that equivalence of the Gaussian measures induced by two Hilbert-valued spherical fields is determined by a Hilbert summability condition involving Schoenberg functional sequences, extending classical results for scalar and vector fields to the infinite-dimensional setting. We further show how equivalence of all scalar projections is contained within, and dominated by, the functional criterion. The theory is illustrated through two models: (i) a multiquadratic bivariate family on $\\mathbb{S}^{d}$, where the equivalence region has a closed-form description in terms of cross-correlation and geodesic decay parameters, and (ii) an infinite-dimensional Legendre-Mat'ern construction, where operator-valued spectra yield identifiability conditions on smoothness and scale. These examples show how operator-valued Schoenberg coefficients govern both geometry and measure-theoretic behavior of functional spherical fields. Overall, the results provide a unified spectral framework for Gaussian measures on $L^{2}(\\mathbb{S}^{d};\\mathcal{H})$, bridging harmonic analysis, operator theory, and stochastic geometry on manifolds, and offering tools for functional data analysis, spatial statistics, and kernel methods on spherical domains."}
{"id": "2511.21980", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.21980", "abs": "https://arxiv.org/abs/2511.21980", "authors": ["Maalvladédon Ganet Somé", "Edward Korveh"], "title": "A stochastic maximum principle for singular mean-field regime-switching optimal control", "comment": "23 pages", "summary": "In this paper, we investigate a mean-field singular stochastic optimal control problem for systems governed by mean-field regime-switching singular stochastic differential equations. The state process is assumed to depend on both a regular and a singular control, and the coefficient associated with the singular component is allowed to be regime dependent. We derive both necessary and sufficient singular stochastic maximum principles. Because the regular control domain is not assumed to be convex, we employ the spike variation technique and obtain the necessary maximum principle by introducing a second-order adjoint process. As an application, we use the main theoretical results to analyse an inter-bank borrowing and lending model with transaction costs."}
{"id": "2511.22216", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.22216", "abs": "https://arxiv.org/abs/2511.22216", "authors": ["Yu. D. Panov"], "title": "Exact solution for one-dimensional spin models with Markov property", "comment": "10 pages, 12 references; will be published in Bulletin of the Russian Academy of Sciences: Physics, Volume 89, supplement issue 3, 2025", "summary": "For one-dimensional spin and pseudospin models that allow mapping to a Markov chain, the free energy of the system at a finite temperature can be expressed in terms of bond concentrations. Minimizing the free energy function makes it possible to obtain an exact solution of a statistical model. A dilute Ising chain with interacting impurities is considered as an example."}
{"id": "2511.21783", "categories": ["physics.soc-ph", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.21783", "abs": "https://arxiv.org/abs/2511.21783", "authors": ["Xuan Qiu"], "title": "NetworkGames: Simulating Cooperation in Network Games with Personality-driven LLM Agents", "comment": null, "summary": "The advent of Large Language Models (LLMs) presents a novel opportunity to build high-fidelity agent-based models for simulating complex social systems. However, the behavior of these LLM-based agents in game-theoretic network games remains surprisingly unexplored. In this work, we introduce \"NetworkGames,\" a novel simulation framework designed to investigate how network topology and agent personality jointly shape the evolution of cooperation in network games. We instantiate a population of LLM agents, each endowed with a distinct personality from the MBTI taxonomy, and situate them in various network structures (e.g., small-world and scale-free). Through extensive simulations of the Iterated Prisoner's Dilemma, we first establish a baseline dyadic interaction matrix, revealing nuanced cooperative preferences between all 16 personality pairs. We then demonstrate that macro-level cooperative outcomes are not predictable from dyadic interactions alone; they are co-determined by the network's connectivity and the spatial distribution of personalities. For instance, we find that small-world networks are detrimental to cooperation, while strategically placing pro-social personalities in hub positions within scale-free networks can significantly promote cooperative behavior. Our findings offer significant implications for designing healthier online social environments and forecasting collective behavior. We open-source our framework to foster further research in network game simulations."}
{"id": "2511.22610", "categories": ["physics.ao-ph", "physics.flu-dyn", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2511.22610", "abs": "https://arxiv.org/abs/2511.22610", "authors": ["Claudia Fanelli", "Tiany Li", "Luca Biferale", "Bruno Buongiorno Nardelli", "Daniele Ciani", "Andrea Pisano", "Michele Buzzicotti"], "title": "Super-resolution of satellite-derived SST data via Generative Adversarial Networks", "comment": null, "summary": "In this work, we address the super-resolution problem of satellite-derived sea surface temperature (SST) using deep generative models. Although standard gap-filling techniques are effective in producing spatially complete datasets, they inherently smooth out fine-scale features that may be critical for a better understanding of the ocean dynamics. We investigate the use of deep learning models as Autoencoders (AEs) and generative models as Conditional-Generative Adversarial Networks (C-GANs), to reconstruct small-scale structures lost during interpolation. Our supervised -- model free -- training is based on SST observations of the Mediterranean Sea, with a focus on learning the conditional distribution of high-resolution fields given their low-resolution counterparts. We apply a tiling and merging strategy to deal with limited observational coverage and to ensure spatial continuity. Quantitative evaluations based on mean squared error metrics, spectral analysis, and gradient statistics show that while the AE reduces reconstruction error, it fails to recover high-frequency variability. In contrast, the C-GAN effectively restores the statistical properties of the true SST field at the cost of increasing the pointwise discrepancy with the ground truth observation. Our results highlight the potential of deep generative models to enhance the physical and statistical realism of gap-filled satellite data in oceanographic applications."}
{"id": "2511.21996", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.21996", "abs": "https://arxiv.org/abs/2511.21996", "authors": ["Jin Zhang", "Xiaowei Liu"], "title": "Pressure-robust optimally convergent H(div) finite element method without the commuting diagram property for the steady Oseen equations", "comment": null, "summary": "This work develops a convergence theory for H(div)-conforming finite element methods applied to the steady Oseen problem, focusing on cases where the exact finite element complex holds while the commuting diagram property may fail. The proposed method incorporates vorticity stabilization to ensure optimal-order convergence of the velocity error, especially for convection-dominated cases. As a crucial component of the analysis, exact de Rham and finite element complexes provide a framework whose utility includes establishing velocity error estimates independent of the discrete inf-sup constant. As a representative example, Stenberg finite elements demonstrate the framework's validity and offer several computational advantages: pressure robustness, fewer degrees of freedom than classical RT or BDM elements due to vertex continuity, and convergence without requiring the commuting diagram property. Moreover, the proposed methodology is applicable to a class of finite element pairs that violate the commuting diagram property, thereby offering new possibilities for efficient discretizations of incompressible fluid problems, particularly in high Reynolds number regimes."}
{"id": "2511.22082", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.22082", "abs": "https://arxiv.org/abs/2511.22082", "authors": ["Ali Sahandi", "Mahsa Pahlavan Yousefkhani", "Mehrshad Eisaei", "Hossein Momeni", "Ramin Mousa"], "title": "WET -- Weighted Ensemble Transformer for Identifying Psychiatric Stressors Related to Suicide X (formerly Twitter)", "comment": null, "summary": "Suicide remains one of the leading causes of death worldwide, particularly among young people, and psychological stressors are consistently identified as proximal drivers of suicidal ideation and behavior. In recent years, social media platforms such as X have become critical environments where individuals openly disclose emotional distress and conditions associated with suicidality, creating new opportunities for early detection and intervention. Existing approaches, however, predominantly rely on raw textual content and often neglect auxiliary emotional and contextual signals embedded in user metadata. To address this limitation, we propose a Weighted Ensemble Transformer (WET), a dual branch deep learning architecture designed to identify psychiatric stressors associated with suicide in X posts. Our model integrates semantic representations extracted through Transformer encoders with an engineered feature vector capturing sentiment, subjectivity, polarity, and user engagement characteristics. We collected, filtered, and annotated 125,754 English tweets for suicide-related psychological stressors and evaluated the proposed model under two configurations. Extensive comparative experiments against traditional machine learning methods, advanced recurrent networks, and transformer baselines demonstrate that WET achieves state-of-the-art performance, reaching 0.9901 accuracy in binary classification. These findings show that hybridizing deep semantic signals with auxiliary emotional and behavioral features substantially improves suicidality detection accuracy."}
{"id": "2511.22067", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.22067", "abs": "https://arxiv.org/abs/2511.22067", "authors": ["Xu-Yan Jia", "Wen Huang", "D. N. Sheng", "Shou-Shu Gong"], "title": "Emergent Fermi-liquid-like phase by melting a holon Wigner crystal in a doped Mott insulator on the kagome lattice", "comment": "9 pages, 9 figures", "summary": "The doped quantum spin liquid on the kagome lattice provides a fascinating platform to explore exotic quantum states, such as the reported holon Wigner crystal at low doping. By extending the doping range to $δ= 0.027$ - $0.36$, we study the kagome-lattice $t$-$J$ model using the state-of-the-art density matrix renormalization group calculation. On the $L_y=3$ cylinder ($L_y$ is the number of unit cells along the circumference direction), we establish a quantum phase diagram with increasing doping level. In addition to the charge density wave (CDW) states at lower doping, we find an emergent Fermi-liquid-like phase by melting the holon Wigner crystal at $δ\\approx 0.15$, which is characterized by suppression of charge density oscillation and power-law decay of various correlation functions. On the wider $L_y = 4$ cylinder, the bond-dimension extrapolated correlation functions also support such a Fermi-liquid-like state, suggesting its stability with increasing system size. In a narrow doping range near $δ= 1/3$ on the $L_y = 3$ cylinder, we find a state with an exponential decay of single-particle correlation but the other correlation functions preserving the features in the Fermi-liquid-like phase, which may be a precursor of a superconducting state. Nevertheless, this peculiar state near $δ= 1/3$ disappears on the $L_y = 4$ cylinder, implying a possible lattice size dependence. Our results reveal a quantum melting from a holon Wigner crystal to a Fermi-liquid-like state with increasing hole density, and suggest a doping regime to explore superconductivity for future study."}
{"id": "2511.23364", "categories": ["cs.CE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.23364", "abs": "https://arxiv.org/abs/2511.23364", "authors": ["Koutarou Tamura"], "title": "Predicting Startup-VC Fund Matches with Structural Embeddings and Temporal Investment Data", "comment": null, "summary": "This study proposes a method for predicting startup inclusion, estimating the probability that a venture capital fund will invest in a given startup. Unlike general recommendation systems, which typically rank multiple candidates, our approach formulates the problem as a binary classification task tailored to each fund-startup pair. Each startup is represented by integrating textual, numerical, and structural features, with Node2Vec capturing network context and multihead attention enabling feature fusion. Fund investment histories are encoded as LSTM based sequences of past investees.\n  Experiments on Japanese startup data demonstrate that the proposed method achieves higher accuracy than a static baseline. The results indicate that incorporating structural features and modeling temporal investment dynamics are effective in capturing fund-startup compatibility."}
{"id": "2511.22510", "categories": ["physics.comp-ph", "cond-mat.soft", "cond-mat.stat-mech", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.22510", "abs": "https://arxiv.org/abs/2511.22510", "authors": ["Martin Kjøllesdal Johnsrud", "Navdeep Rana"], "title": "Efficient Pseudo-spectral Algorithms for Statistical Field Theories", "comment": null, "summary": "We present stochastic variants of the exponential time differencing schemes for stiff stochastic differential equations. We derive three explicit schemes that offer better stability compared to Euler-Maruyama and Milstein's method, and achieve strong convergence up to order O(h) in the time step h. We combine these schemes with a pseudo-spectral approach to outline efficient algorithms for simulating stochastic field theories with additive noise. To illustrate the effectiveness of this approach, we study several systems in and out of equilibrium, including Model A, Model B, the Kardar-Parisi-Zhang equation, and the Complex Ginzburg-Landau equation. We outline procedures for computing physical observables such as the critical exponents, correlation functions, and dynamic linear response, and provide our implementation as open source code."}
{"id": "2511.23094", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.23094", "abs": "https://arxiv.org/abs/2511.23094", "authors": ["Jens-Peter Kreiss", "Panagiotis Maouris", "Efstathios Paparoditis"], "title": "Detecting Periodicity of a General Stationary Time Series via AR(2)-Model Fitting", "comment": null, "summary": "Estimating the periodicity of a stationary time series via fitting a second order stationary autoregressive (AR(2)) model has been initiated by the seminal paper of Yule(1927).. We investigate properties of this procedure when applied to a general stationary processes possessing a spectral density with a dominant peak at some frequency $λ_0\\in(0,π)$. We show that if the peak of the spectral density is sharp enough (in a way to be specified) then the AR(2) model, which best (in mean square sense) approximates the underlying process, correctly identifies the frequency $λ_0$. To investigate consistency properties of the AR(2) based estimator of $λ_0$, a near to pole framework is adopted. Triangular arrays of stationary stochastic processes are considered that possess a spectral density the peak of which at $λ_0$ becomes more pronounced as the sample size $n$ of the observed time series increases to infinity. It is shown in this set up, that the AR(2) based estimator achieves a rate of convergence which is larger than the parametric $n^{-1/2}$ rate and which can be arbitrarily close to $ n^{-2/3}$, the best rate that can be achieved by this estimator."}
{"id": "2511.22011", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22011", "abs": "https://arxiv.org/abs/2511.22011", "authors": ["Lei Yang", "Jingjing Hu", "Tianxiang Liu"], "title": "A nonmonotone extrapolated proximal gradient-subgradient algorithm beyond global Lipschitz gradient continuity", "comment": "38 pages, comments welcome", "summary": "With the advancement of modern applications, an increasing number of composite optimization problems arise whose smooth component does not possess a globally Lipschitz continuous gradient. This setting prevents the direct use of the proximal gradient (PG) method and its variants, and has motivated a growing body of research on new PG-type methods and their convergence theory, in particular, global convergence analysis without imposing any explicit or implicit boundedness assumptions on the iterates. Until recently, the first complete analysis of this kind has been established for the PG method and its specific nonmonotone variants, which has since stimulated further exploration along this research direction. In this paper, we consider a general composite optimization model beyond the global Lipschitz gradient continuity setting. We propose a novel problem-parameter-free algorithm that incorporates a carefully designed nonmonotone line search to handle the non-global Lipschitz gradient continuity, together with an extrapolation step to achieve potential acceleration. Despite the added technical challenges introduced by combining extrapolation with nonmonotone line search, we establish a refined convergence analysis for the proposed algorithm under the Kurdyka-Ł ojasiewicz property, without requiring any boundedness assumptions on the iterates. This work thus further advances the theoretical understanding of PG-type methods in the non-global Lipschitz gradient continuity setting. Finally, we conduct numerical experiments to illustrate the effectiveness of our algorithm and highlight the advantages of integrating extrapolation with a nonmonotone line search."}
{"id": "2511.22282", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2511.22282", "abs": "https://arxiv.org/abs/2511.22282", "authors": ["Fabian H. Kreten", "Ludger Santen", "Reza Shaebani"], "title": "Inferring Tree Structure with Hidden Traps from First Passage Times", "comment": "15 pages, 9 figures", "summary": "Tracking the movement of tracer particles has long been a strategy for uncovering complex structures. Here, we study discrete-time random walks on finite Cayley trees to infer key parameters such as tree depth and geometric bias toward the root or leaves. By analyzing first passage properties, we show that the first two first-passage-time factorial moments (FPTFMs) uniquely determine the tree structure. However, if the random walker experiences waiting phases -- due to sticky branch walls or presence of traps -- this identification becomes nontrivial. We demonstrate that the generating function of the first passage time (FPT) distribution decomposes into contributions from the waiting time distribution and the random walk without waiting, leading to a nonlinear system of equations relating the factorial moments of the waiting time distribution and the FPTFMs of random walks with and without waiting. For geometrically distributed waiting times, additional moment measurements do not suffice, but unique determination of the structure is achieved by varying initial conditions or fitting the Fourier transform of the FPT distribution to measured data. The latter method remains effective also for power-law waiting time distributions, where higher-order FPTFMs are undefined. These results provide a framework for reconstructing tree-like networks from FPT data, with applications in biological transport and spatial networks."}
{"id": "2511.22234", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.22234", "abs": "https://arxiv.org/abs/2511.22234", "authors": ["Chunpeng Du", "Fei Fang", "Alfonso de Miguel-Arribas", "Yikang Lu", "Yanan Wang", "Xin Pan", "Yamir Moreno"], "title": "Edge-based reputation promotes cooperation in simplicial complexes", "comment": "14 pages, 6 figures", "summary": "Understanding how cooperation emerges and persists is a central challenge in the evolutionary dynamics of social and biological systems. Most prior studies have examined cooperation through pairwise interactions, yet real-world interactions often involve groups and higher-order structures. Reputation is a key mechanism for guiding strategic behavior in such contexts, but its role in higher-order networks remains underexplored. In this study, we introduce an edge-based reputation mechanism, incorporating both direct and indirect reputation, to investigate the evolution of cooperation in simplicial complexes. Our results show that coupling reputation mechanisms with higher-order network structures strongly promotes cooperation, with direct reputation exerting a stronger influence than indirect reputation. Moreover, we reveal a nonlinear interplay between network topology and reputation mechanisms, highlighting how multi-level structures shape collective outcomes. These findings provide a novel theoretical framework for understanding cooperation in complex social systems."}
{"id": "2511.22970", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.22970", "abs": "https://arxiv.org/abs/2511.22970", "authors": ["Francesco Immorlano", "Elijah Tavares", "Felix Draxler", "Padhraic Smyth", "Pierre Gentine", "Stephan Mandt"], "title": "Technical Report: Towards Unified Diffusion Models for Multi-Model Climate Emulation at Scale", "comment": null, "summary": "Large ensembles of climate projections are essential for characterizing uncertainty in future climate and extreme weather events, yet computational constraints of numerical climate models limit ensemble sizes to a small number of realizations per model. We present a unified conditional diffusion model that dramatically reduces this computational barrier by learning shared distributional patterns across multiple Coupled Model Intercomparison Project phase 6 models and emission scenarios. Rather than training separate emulators for each model-scenario combination, our approach captures the common statistical structures underlying nine CMIP6 models, generating daily temperature maps with a global coverage for historical and future periods. This unified framework enables: (i) efficient probabilistic sampling for comprehensive uncertainty quantification across models and scenarios; (ii) rapid generation of large ensembles that would be computationally intractable with traditional climate models; (iii) variance-reduced treatment effect analysis via fixed-seed generation that disentangles forced climate responses from internal variability. Evaluations on held-out models demonstrate reliable generalization to unseen future climates, enabling rapid exploration of different emission pathways."}
{"id": "2511.22000", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22000", "abs": "https://arxiv.org/abs/2511.22000", "authors": ["Michele Aldé", "Michael Feischl", "Dirk Praetorius"], "title": "BDF2-type integrator for Landau-Lifshitz-Gilbert equation in micromagnetics, part I: unconditional weak convergence to weak solutions", "comment": "34 pages, 29 figures", "summary": "We consider the Landau-Lifshitz-Gilbert equation (LLG) that models time-dependent micromagnetic phenomena. We propose a full discretization that employs first-order finite elements in space and a BDF2-type two-step method in time. In each time step, only one linear system of equations has to be solved. We employ linear interpolation in time to reconstruct the discrete space-time magnetization. We prove that the integrator is unconditionally stable and thus guarantees that a subsequence of the reconstructed magnetization converges weakly in $H^1$ towards a weak solution of LLG in the space-time domain. Numerical experiments verify that the proposed integrator is indeed first-order in space and second-order in time."}
{"id": "2511.22493", "categories": ["cs.SI", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22493", "abs": "https://arxiv.org/abs/2511.22493", "authors": ["Zida Liu", "Jun Gao", "Zhang Ji", "Li Zhao"], "title": "HW-GNN: Homophily-Aware Gaussian-Window Constrained Graph Spectral Network for Social Network Bot Detection", "comment": null, "summary": "Social bots are increasingly polluting online platforms by spreading misinformation and engaging in coordinated manipulation, posing severe threats to cybersecurity. Graph Neural Networks (GNNs) have become mainstream for social bot detection due to their ability to integrate structural and attribute features, with spectral-based approaches demonstrating particular efficacy due to discriminative patterns in the spectral domain. However, current spectral GNN methods face two limitations: (1) their broad-spectrum fitting mechanisms degrade the focus on bot-specific spectral features, and (2) certain domain knowledge valuable for bot detection, e.g., low homophily correlates with high-frequency features, has not been fully incorporated into existing methods.\n  To address these challenges, we propose HW-GNN, a novel homophily-aware graph spectral network with Gaussian window constraints. Our framework introduces two key innovations: (i) a Gaussian-window constrained spectral network that employs learnable Gaussian windows to highlight bot-related spectral features, and (ii) a homophily-aware adaptation mechanism that injects domain knowledge between homophily ratios and frequency features into the Gaussian window optimization process. Through extensive experimentation on multiple benchmark datasets, we demonstrate that HW-GNN achieves state-of-the-art bot detection performance, outperforming existing methods with an average improvement of 4.3% in F1-score, while exhibiting strong plug-in compatibility with existing spectral GNNs."}
{"id": "2511.21836", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.21836", "abs": "https://arxiv.org/abs/2511.21836", "authors": ["Gellért Perényi", "Matias Janvin", "Mats J. Stensrud"], "title": "A simple and powerful test of vaccine waning", "comment": null, "summary": "Determining whether vaccine efficacy wanes is important for individual and public decision making. Yet, quantification of waning is a subtle task. The classical approaches cannot be interpreted as measures of declining efficacy unless we impose unreasonable assumptions. Recently, formal causal estimands designed to quantify vaccine waning have been proposed. These estimands can be bounded under weaker assumptions, but the bounds are often too wide to make claims about the presence of vaccine waning. We propose an alternative approach: a formal test to determine whether a treatment effect is constant over time. This test not only gives a considerable power gain compared to existing approaches but is also valid under plausible assumptions that are expected to hold in vaccine trials. We illustrate the increase in power through real and simulated examples, using three different approaches to compute the test statistics. Two of these approaches are based solely on summary data, accessible from existing clinical trials. Beyond our test, we also give new results that bound the waning effect. We use our methods to reanalyze data from a randomized controlled trial of the BNT162b2 COVID-19 vaccine. While prior analysis did not establish waning, our test rejects the null hypothesis of no waning."}
{"id": "2511.22204", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.22204", "abs": "https://arxiv.org/abs/2511.22204", "authors": ["Jia-Heng Ji", "Zhi-Yan Shao", "Yu-Bo Liu", "Fan Yang"], "title": "Néel Ordered Magnetic Phases in Bipartite Quasicrystals", "comment": "4 pages, 4 figures, with supplementary materials", "summary": "Magnetism is a fundamental research area in which the recently proposed altermagnetism (AM) has become an emergent frontier. Very recently, the quasicrystal (QC) was proposed as a possible platform to realize AM. However, the existence of AM in QCs still lacks vigorous evidence. In this work, we adopt the sign-problem-free projector quantum Monte Carlo (PQMC) algorithm to investigate the magnetic phases in the half-filled Hubbard models in various 2D bipartite QCs, and always obtain Néel ordered states. While the Néel states in bipartite crystals are usually antiferromagnetism (AFM), we find it common that those in bipartite QCs can also be AM or ferromagnetism (FM). Based on symmetry analysis, combined with our comprehensive PQMC results, we propose a general criterion for determining the magnetism classes of the Néel states in a bipartite QC: According to whether the two sublattices are related by the inversion, the other point-group operation, or no operation about the unique symmetry center in the QC, the corresponding Néel state is AFM, AM or FM, respectively. For example, our results yield AM for the two $D_4$-symmetric Thue-Morse QCs and FM for the $D_5$-symmetric Penrose QC at half-filling. Our results provide a solid foundation for experimental investigations and potential applications of different classes of magnetism in QCs."}
{"id": "2511.22875", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.22875", "abs": "https://arxiv.org/abs/2511.22875", "authors": ["Marc M Nasser", "Frédéric Poitevin", "Kevin M Dalton"], "title": "Robust Indexing for Challenging Serial X-ray Diffraction Patterns", "comment": null, "summary": "Serial crystallography experiments routinely produce thousands of diffraction patterns from crystals in random orientations. To turn this stream of images into a usable dataset, each pattern must be indexed before integration and merging can proceed. In practice, diffraction patterns may contain only a small number of reliable peaks, be contaminated by background or spuriously detected reflections, or arise from crystals with highly skewed unit cells. These factors make indexing unstable in the small-N regime. We introduce a robust indexing algorithm tailored to this setting. We formulate indexing as a symmetry-aware lattice decoding problem and design a loss that explicitly incorporates lattice symmetries while trimming outlier peaks that are inconsistent with any plausible orientation. We combine this objective with a reciprocal-space basis reparameterization that stabilizes decoding for skewed or poorly conditioned lattices, and we develop a dedicated small-N objective mode that couples refined peak scoring with a method to recover orientations from very few reflections. The resulting method is memory-efficient and suitable for robust indexing. We evaluate our approach on three protein datasets from the Coherent X-ray Imaging Data Bank collected at XFEL facilities, using identical preprocessing and unit-cell information across methods. Across all datasets, our algorithm matches or outperforms established indexers such as XGANDALF and TORO, with particularly large gains for patterns with few indexed peaks and for crystals with skewed unit cells. While slower, our method is extremely memory-efficient, and its structure allows high-parallelism on CPUs or larger batch sizes on GPUs. These results show that exploiting lattice structure, symmetry, and small-N-aware search yields substantial improvements in indexing robustness."}
{"id": "2511.23144", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.23144", "abs": "https://arxiv.org/abs/2511.23144", "authors": ["Riko Kelter", "Samuel Pawel"], "title": "The Bayesian optimal two-stage design for clinical phase II trials based on Bayes factors", "comment": "39 pages, 6 figures", "summary": "Sequential trial design is an important statistical approach to increase the efficiency of clinical trials. Bayesian sequential trial design relies primarily on conducting a Monte Carlo simulation under the hypotheses of interest and investigating the resulting design characteristics via Monte Carlo estimates. This approach has several drawbacks, namely that replicating the calibration of a Bayesian design requires repeating a possibly complex Monte Carlo simulation. Furthermore, Monte Carlo standard errors are required to judge the reliability of the simulation. All of this is due to a lack of closed-form or numerical approaches to calibrate a Bayesian design which uses Bayes factors. In this paper, we propose the Bayesian optimal two-stage design for clinical phase II trials based on Bayes factors. The optimal two-stage Bayes factor design is a sequential clinical trial design that is built on the idea of trinomial tree branching, a method we propose to correct the resulting design characteristics for introducing a single interim analysis. We build upon this idea to invent a calibration algorithm which yields the optimal Bayesian design that minimizes the expected sample size under the null hypothesis. Examples show that our design recovers Simon's two-stage optimal design as a special case, improves upon non-sequential Bayesian design based on Bayes factors, and can be calibrated quickly, as it makes use only of standard numerical techniques instead of time-consuming Monte Carlo simulations. Furthermore, the design allows to ensure a minimum probability on compelling evidence in favour of the null hypothesis, which is not possible with other designs. As the idea of trinomial tree branching is neither dependent on the endpoint, nor on the use of Bayes factors, the design can therefore be generalized to other settings, too."}
{"id": "2511.22123", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22123", "abs": "https://arxiv.org/abs/2511.22123", "authors": ["Adam Waterman", "Martin Guay"], "title": "Model Predictive Path Planning in Navier-Stokes Flow with POD-Based Reduced-Order Models", "comment": null, "summary": "We present a framework for optimal trajectory generation in flow-driven systems governed by the Navier-Stokes equations, combining a Proper Orthogonal Decomposition (POD) reduced0order model (ROM) with Model Predictive Control (MPC). The approach (i) approximates the velocity field from data via snapshot POD and orthogonal projection, (ii) derives a Galerkin-projected dynamical model in reduced coordinates, and (iii) employs MPC to plan control inputs that steer an agent through the predicted flow while satisfying state and actuation constraints. By leveraging reduced-order modeling, the method enables real-time control in high-dimensional flow environments. Simulations demonstrate accurate flow-field reconstruction and efficient trajectory generation within realistic wind environments."}
{"id": "2511.22431", "categories": ["cond-mat.stat-mech", "physics.class-ph"], "pdf": "https://arxiv.org/pdf/2511.22431", "abs": "https://arxiv.org/abs/2511.22431", "authors": ["Tingzhang Shi", "Chentong Qi", "H. T. Quan"], "title": "Exact four-vector work distribution and covariant Jarzynski's equality for a relativistic particle in an expanding piston", "comment": "16 pages, 11 figures", "summary": "We investigate the non-equilibrium four-vector work in an expanding relativistic piston. By deriving the exact work distribution in this pedagogical model, we verify the covariant form of Jarzynski's equality. We find that the joint distribution of four-vector work $(W^0, W^1)$ concentrates on the origin and some curves in the $(W^0, W^1)$ space, rather than being smoothly distributed. In the non-relativistic limit, our model consistently recovers the non-relativistic dynamics. We further demonstrate that the momentum component of four-vector work remains significant in both the Lorentz-relativistic and Galilean-relativistic frameworks. In addition, we introduce a novel geometrical technique for analyzing the dynamics of relativistic collision processes, which can be straightforwardly extended to three-dimensional piston models."}
{"id": "2511.22839", "categories": ["physics.soc-ph", "econ.GN", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22839", "abs": "https://arxiv.org/abs/2511.22839", "authors": ["Ruike Lyu", "Anna Li", "Jianxiao Wang", "Hongxi Luo", "Yan Shen", "Hongye Guo", "Ershun Du", "Chongqing Kang", "Jesse Jenkins"], "title": "Can industrial overcapacity enable seasonal flexibility in electricity use? A case study of aluminum smelting in China", "comment": "Submitted to Nature Energy", "summary": "In many countries, declining demand in energy-intensive industries (EIIs) such as cement, steel, and aluminum is leading to industrial overcapacity. Although overcapacity is traditionally seen as problematic, it could unlock EIIs' flexibility in electricity use. Using China's aluminum smelting sector as a case, we evaluate the system-level cost-benefit of retaining EII overcapacity for flexible electricity use in decarbonized systems. We find that overcapacity enables smelters to adopt a seasonal operation paradigm, ceasing production during winter load peaks driven by heating electrification and renewable seasonality. In a 2050-net-zero scenario, this paradigm reduces China's electricity-system investment and operating costs by 15-72 billion CNY per year (8-34% of the industry's product value), enough to offset the costs of maintaining overcapacity and product storage. Seasonal operation also cuts workforce fluctuations across aluminum smelting and thermal-power sectors by up to 62%, potentially mitigating socio-economic disruptions from industrial restructuring and the energy transition."}
{"id": "2511.23043", "categories": ["physics.ao-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.23043", "abs": "https://arxiv.org/abs/2511.23043", "authors": ["Even Marius Nordhagen", "Håvard Homleid Haugen", "Aram Farhad Shafiq Salihi", "Magnus Sikora Ingstad", "Thomas Nils Nipen", "Ivar Ambjørn Seierstad", "Inger-Lise Frogner", "Mariana Clare", "Simon Lang", "Matthew Chantry", "Peter Dueben", "Jørn Kristiansen"], "title": "High-Resolution Probabilistic Data-Driven Weather Modeling with a Stretched-Grid", "comment": "14 pages, 8 figures", "summary": "We present a probabilistic data-driven weather model capable of providing an ensemble of high spatial resolution realizations of 87 variables at arbitrary forecast length and ensemble size. The model uses a stretched grid, dedicating 2.5 km resolution to a region of interest, and 31 km resolution elsewhere. Based on a stochastic encoder-decoder architecture, the model is trained using a loss function based on the Continuous Ranked Probability Score (CRPS) evaluated point-wise in real and spectral space. The spectral loss components is shown to be necessary to create fields that are spatially coherent. The model is compared to high-resolution operational numerical weather prediction forecasts from the MetCoOp Ensemble Prediction System (MEPS), showing competitive forecasts when evaluated against observations from surface weather stations. The model produced fields that are more spatially coherent than mean squared error based models and CRPS based models without the spectral component in the loss."}
{"id": "2511.22206", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22206", "abs": "https://arxiv.org/abs/2511.22206", "authors": ["Martin Campos Pinto", "Frederik Schnack"], "title": "Broken-FEEC on multipatch domains with local refinements", "comment": null, "summary": "This article introduces a novel approach for broken-FEEC (Finite Element Exterior Calculus), extending its application to locally refined spline spaces with non-matching interfaces. Traditional broken-FEEC allows for discontinuous discretizations at patch interfaces, preserving the de Rham structure and offering computational benefits. However, local refinements often lead to numerical artifacts. Our solution involves developing moment-preserving discrete conforming projection operators. These operators are explicit, localized, and metric-independent, ensuring $H^1$ and $H(\\text{curl})$ continuity across non-matching interfaces while preserving high-order polynomial moments. This results in broken-FEEC de Rham sequences with accurate strong and weak derivatives, leading to energy-preserving Maxwell solvers that are explicit and virtually free of spurious modes. Numerical simulations confirm the efficacy of our method in eliminating spurious waves."}
{"id": "2511.23247", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.23247", "abs": "https://arxiv.org/abs/2511.23247", "authors": ["Randa Boukabene", "Fatima Benbouzid Si Tayeb"], "title": "Community Detection in Multilayer Networks: Challenges, Opportunities and Applications", "comment": "9 pages, 2 figures, conference", "summary": "Community detection is a fascinating and rapidly evolving field, but when it comes to analyzing networks with multiple types of interactions, referred to as multilayer networks, there is still a lot of untapped potential. Despite the wide array of methods developed to identify community structures in such networks, this area remains underexplored, leaving plenty of room for innovation. A systematic review of recent advancements is essential to understand where the field stands and where it is headed. While significant strides have been made across various disciplines, many questions remain unanswered, and new opportunities are waiting to be uncovered. In this paper, we explore the different types of multilayer networks, community detection techniques, and how they are applied in real world scenarios. We also dive into the key challenges researchers face and suggest potential directions for future work, aiming to refine community detection techniques and boost their effectiveness in multilayer networks."}
{"id": "2511.21973", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.21973", "abs": "https://arxiv.org/abs/2511.21973", "authors": ["Siyu Heng", "Yuan Huang", "Hyunseung Kang"], "title": "A Non-Bipartite Matching Framework for Difference-in-Differences with General Treatment Types", "comment": "This working manuscript reports preliminary results from our ongoing research on this topic. Additional simulation studies, data applications, methodological developments, and detailed results are still in progress and will be incorporated in future versions. This document is therefore not a final version of our work", "summary": "Difference-in-differences (DID) is one of the most widely used causal inference frameworks in observational studies. However, most existing DID methods are designed for binary treatments and cannot be readily applied to non-binary treatment settings. Although recent work has begun to extend DID to non-binary (e.g., continuous) treatments, these approaches typically require strong additional assumptions, including parametric outcome models or the presence of idealized comparison units with (nearly) static treatment levels over time (commonly called ``stayers'' or ``quasi-stayers''). In this technical note, we introduce a new non-bipartite matching framework for DID that naturally accommodates general treatment types (e.g., binary, ordinal, or continuous). Our framework makes three main contributions. First, we develop an optimal non-bipartite matching design for DID that jointly balances baseline covariates across comparable units (reducing bias) and maximizes contrasts in treatment trajectories over time (improving efficiency). Second, we establish a post-matching randomization condition, the design-based counterpart to the traditional parallel-trends assumption, which enables valid design-based inference. Third, we introduce the sample average DID ratio, a finite-population-valid and fully nonparametric causal estimand applicable to arbitrary treatment types. Our design-based approach that preserves the full treatment-dose information, avoids parametric assumptions, does not rely on the existence of stayers or quasi-stayers, and operates entirely within a finite-population framework, without appealing to hypothetical super-populations or outcome distributions."}
{"id": "2511.21846", "categories": ["eess.SY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21846", "abs": "https://arxiv.org/abs/2511.21846", "authors": ["Amit Jena", "Na Li", "Le Xie"], "title": "LILAD: Learning In-context Lyapunov-stable Adaptive Dynamics Models", "comment": "This article has been accepted for AAAI-26 (The 40th Annual AAAI Conference on Artificial Intelligence)", "summary": "System identification in control theory aims to approximate dynamical systems from trajectory data. While neural networks have demonstrated strong predictive accuracy, they often fail to preserve critical physical properties such as stability and typically assume stationary dynamics, limiting their applicability under distribution shifts. Existing approaches generally address either stability or adaptability in isolation, lacking a unified framework that ensures both. We propose LILAD (Learning In-Context Lyapunov-stable Adaptive Dynamics), a novel framework for system identification that jointly guarantees adaptability and stability. LILAD simultaneously learns a dynamics model and a Lyapunov function through in-context learning (ICL), explicitly accounting for parametric uncertainty. Trained across a diverse set of tasks, LILAD produces a stability-aware, adaptive dynamics model alongside an adaptive Lyapunov certificate. At test time, both components adapt to a new system instance using a short trajectory prompt, which enables fast generalization. To rigorously ensure stability, LILAD also computes a state-dependent attenuator that enforces a sufficient decrease condition on the Lyapunov function for any state in the new system instance. This mechanism extends stability guarantees even under out-of-distribution and out-of-task scenarios. We evaluate LILAD on benchmark autonomous systems and demonstrate that it outperforms adaptive, robust, and non-adaptive baselines in predictive accuracy."}
{"id": "2511.21846", "categories": ["eess.SY", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21846", "abs": "https://arxiv.org/abs/2511.21846", "authors": ["Amit Jena", "Na Li", "Le Xie"], "title": "LILAD: Learning In-context Lyapunov-stable Adaptive Dynamics Models", "comment": "This article has been accepted for AAAI-26 (The 40th Annual AAAI Conference on Artificial Intelligence)", "summary": "System identification in control theory aims to approximate dynamical systems from trajectory data. While neural networks have demonstrated strong predictive accuracy, they often fail to preserve critical physical properties such as stability and typically assume stationary dynamics, limiting their applicability under distribution shifts. Existing approaches generally address either stability or adaptability in isolation, lacking a unified framework that ensures both. We propose LILAD (Learning In-Context Lyapunov-stable Adaptive Dynamics), a novel framework for system identification that jointly guarantees adaptability and stability. LILAD simultaneously learns a dynamics model and a Lyapunov function through in-context learning (ICL), explicitly accounting for parametric uncertainty. Trained across a diverse set of tasks, LILAD produces a stability-aware, adaptive dynamics model alongside an adaptive Lyapunov certificate. At test time, both components adapt to a new system instance using a short trajectory prompt, which enables fast generalization. To rigorously ensure stability, LILAD also computes a state-dependent attenuator that enforces a sufficient decrease condition on the Lyapunov function for any state in the new system instance. This mechanism extends stability guarantees even under out-of-distribution and out-of-task scenarios. We evaluate LILAD on benchmark autonomous systems and demonstrate that it outperforms adaptive, robust, and non-adaptive baselines in predictive accuracy."}
{"id": "2511.22106", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2511.22106", "abs": "https://arxiv.org/abs/2511.22106", "authors": ["Yuma Matsumoto", "Taro Yaoyama", "Sangwon Lee", "Asako Iwaki", "Tatsuya Itoi"], "title": "Waveform-Based Probabilistic Seismic Hazard Analysis Using Ground-Motion Generative Models", "comment": null, "summary": "In probabilistic seismic hazard analysis (PSHA), the exceedance probability of a ground-motion intensity measure (IM) is typically evaluated. However, in recent years, dynamic response analyses using ground-motion time histories as input have been increasingly common in seismic design and risk assessment, and thus there is a growing demand for representing seismic hazard in terms of ground-motion waveforms. In this study, we propose a novel PSHA framework, referred to as waveform-based PSHA, that enables the direct evaluation of the probability distribution of ground-motion waveforms by introducing ground-motion models (GMMs) based on deep generative models (ground-motion generative models; GMGMs) into the PSHA framework. In waveform-based PSHA, seismic hazard is represented, in a Monte Carlo sense, as a set of ground-motion waveforms. We propose the formulation of such a PSHA framework as well as an algorithm for performing the required Monte Carlo simulations. Three different GMGMs based on generative adversarial networks (GANs) are constructed. After verifying the performance of each GMGM, hazard evaluations using the proposed method are conducted for two numerical examples: one assuming a hypothetical area source and the other assuming an actual site and source faults in Japan. We demonstrate that seismic hazard can be represented as a set of ground-motion waveforms, and that the IM-based hazard obtained from these waveforms is consistent with the results of conventional PSHA using GMMs. Finally, nonlinear dynamic response analyses of a building model are performed using the evaluated seismic hazard as input, and it is shown that exceedance probabilities of engineering demand parameters (EDPs) as well as hazard disaggregation with respect to EDPs can be carried out in a straightforward manner within the proposed framework."}
{"id": "2511.22008", "categories": ["cond-mat.dis-nn", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.22008", "abs": "https://arxiv.org/abs/2511.22008", "authors": ["I. Komis", "E. T. Kokkinakis", "K. G. Makris", "E. N. Economou"], "title": "Evolving disorder in non-Hermitian lattices", "comment": "10 pages, 9 figures", "summary": "The impact of disorder on wave transport has been extensively studied in Hermitian systems, where static randomness gives rise to Anderson localization. In non-Hermitian lattices, static disorder can lead to peculiar transport features, including jumpy wave evolution. By contrast, much less is known about how transport is modified when the on-site disorder evolves during propagation. Here we address this problem by investigating two pertinent non-Hermitian lattice models with disorder altered at regular intervals, characterized by a finite disorder period. In lattices with symmetric couplings and complex on-site disorder, short disorder periods suppress localization and give rise to diffusion-like spreading, while longer periods allow the emergence of jumps. In Hatano-Nelson lattices with real on-site disorder, the non-Hermitian skin effect asymptotically dominates regardless of the disorder strength, while the disorder period reshapes the drift velocity and modulates its competition with Anderson localization. These results establish evolving disorder as a novel way of tuning non-Hermitian transport."}
{"id": "2511.22517", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.22517", "abs": "https://arxiv.org/abs/2511.22517", "authors": ["O. Benton", "Y. Skourski", "D. Gorbunov", "A. Miyata", "S. Chattopadhyay", "J. Wosnitza", "M. Ciomaga Hatnean", "G. Balakrishnan", "S. Zherlitsyn", "O. A. Petrenko"], "title": "Large out-of-equilibrium magnetocaloric effect in rare-earth zirconate pyrochlores", "comment": "14 pages, 18 figures", "summary": "We explore the magnetic properties of Nd$_2$Zr$_2$O$_7$ and Pr$_2$Zr$_2$O$_7$ single crystals subjected to pulsed magnetic fields up to 60 T using magnetization and magnetocaloric-effect (MCE) measurements, with initial temperatures ranging from 2 to 31K. The MCE data exhibit pronounced and unconventional hysteresis loops, in which the sample temperature increases during both the up-sweep and down-sweep of the field. In Nd$_2$Zr$_2$O$_7$, the MCE further displays a striking plateau as a function of time, followed by a rapid temperature rise that begins at the maximum applied field, across pulses with differing peak-field strengths. Our magnetization measurements reveal an inferred temperature of the magnetic subsystem that differs significantly from the directly measured sample temperature and exhibits opposite hysteresis: the temperature is higher on the up-sweep than the down-sweep, unlike the direct measurements. These observations indicate a breakdown of thermal equilibrium between magnetic and lattice degrees of freedom on the timescale of the pulse ($\\sim 10^{-1}$s). We interpret the results using a phenomenological model involving two thermally coupled subsystems - the magnetic ions and phonons, and a thermal reservoir, which accounts well for the behavior of Pr$_2$Zr$_2$O$_7$. However, it fails to reproduce the plateau seen in Nd$_2$Zr$_2$O$_7$. Agreement with Nd$_2$Zr$_2$O$_7$ data is improved substantially if we allow the thermal coupling between the magnetic and the lattice subsystems to depend on the product $\\frac{HdH}{dt}$. Our results reveal anomalously slow heat transfer between magnetic and lattice subsystems and point toward a novel mechanism for dynamically controlling the heat flow in Nd$_2$Zr$_2$O$_7$ via the rate of magnetic field variation."}
{"id": "2511.22951", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.22951", "abs": "https://arxiv.org/abs/2511.22951", "authors": ["I. S. Galtsov", "R. V. Muratov", "G. V. Vyskvarko", "S. A. Murzov", "S. A. Dyachkov", "P. R. Levashov"], "title": "MDcraft -- a modern molecular dynamics simulation package with machine learning potentials support", "comment": "29 pages, 13 figures", "summary": "Molecular dynamics is widely used to study various phenomena, such as diffusion, shock wave propagation, and plasma dynamics. A wide range of software packages supports the expanding scope of molecular dynamics applications. However, the quality of simulations depends on force field approximations, ranging from simple models to direct quantum solutions. Recently, machine learning approaches for constructing accurate interatomic potentials have received significant attention. In MDcraft, we integrate these advances into a scalable, physically accurate framework. MDcraft is a comprehensive, modern molecular dynamics platform. It offers a high-level Python API with a user-friendly, script-based interface. The core simulation algorithms are implemented in C++ to ensure robustness and computational efficiency. MDcraft is built for high-performance computing on modern clusters and supports dynamic domain decomposition and load balancing via the Message Passing Interface (MPI) for scalable parallelization. Additionally, MDcraft leverages multithreading within nodes through standard C++ parallelism, enabling efficient use of heterogeneous architectures. We demonstrate the code's capabilities through several examples, including the shock response in aluminum, the shock Hugoniot in argon, and the cold curve of copper."}
{"id": "2511.22218", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22218", "abs": "https://arxiv.org/abs/2511.22218", "authors": ["Md Ashiqur Rahman", "Mustofa Tanbir Kuhel", "Clara Novoa"], "title": "A Two-Stage Stochastic Optimization Framework for Environmentally Sensitive Oil Spill Response Resource Allocation in the Arctic", "comment": "18 pages, 11 figures, 5 tables, 1 algorithm", "summary": "The risk of oil spills in the Alaskan Arctic has become an urgent environmental and logistical concern as maritime traffic increases under climate driven sea ice retreat. Traditional deterministic response planning models fail to represent key uncertainties, including variable spill magnitudes, changing environmental sensitivity, and infrastructure limitations. This study develops a two-stage stochastic mixed integer linear programming framework that jointly optimizes the location of oil spill response stations and the allocation of heterogeneous resources across multiple probabilistic spill scenarios. The model integrates a weighted objective that combines spill volume, environmental sensitivity index (ESI), response time, and costs for station setup, deployment, and inter station transfer. Separate importance weights for coverage and cost, together with internal ecological weights, allow decision makers to balance ecological protection and operational efficiency. Data was compiled from Alaska Department of Environmental Conservation spill records and National Oceanic and Atmospheric Administration ESI layers and are converted into model ready scenarios through harmonization and sampling. The model is solved with the Gurobi optimizer, and sensitivity analysis is performed over 324 combinations of importance and ecological weights. Results show about a 35.45% percent improvement in response effectiveness over deterministic methods, as confirmed by the value of the stochastic solution, and reveal clear tradeoffs between cost and ecological coverage. The framework provides a data driven decision support tool for Arctic emergency planners that simultaneously accounts for uncertainty, environmental sensitivity, and realistic logistical constraints."}
{"id": "2511.22477", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.22477", "abs": "https://arxiv.org/abs/2511.22477", "authors": ["Xia-Ze Xu", "Tong-Yu Lin", "Guang-Ming Zhang"], "title": "Equivalence of residual entropy of hexagonal and cubic ices from tensor network methods", "comment": "10 pages, 6 figures, two tables", "summary": "The long-standing question of whether the residual entropy of hexagonal ice ($S_h$) equals that of cubic ice ($S_c$) remains unresolved despite decades of research on ice-type models. While analytical studies have established the inequality $S_h \\geq S_c$, numerical investigations suggest that the two values are very close. In this work, we revisit this problem using high-precision tensor-network methods. In Monte Carlo approaches the residual entropy cannot be directly obtained by sampling the ground-state degeneracy space, however, the tensor-network framework enables an explicit encoding of the \"ice rule'' into local tensors, and then the residual entropy is transformed into finding the largest eigenvalue of a transfer operator in the form of a projected entangled-pair operator, which allows high-accuracy numerical evaluation. Meanwhile, we propose a new perspective based on analyzing the normality of the transfer operator, and demonstrate that if the operator is normal, the equality $S_h = S_c$ follows directly. Then the variational tensor network methods are employed to numerically verify this normality. Finally both residual entropies are directly computed by using our recently developed split corner transfer matrix renormalization group algorithm, providing a rigorous evidence supporting the equality between $S_h$ and $S_c$."}
{"id": "2511.23061", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.23061", "abs": "https://arxiv.org/abs/2511.23061", "authors": ["Angelika Abramiuk-Szurlej"], "title": "The impact of anticonformity on the diffusion of innovation -- insights from the q-voter model", "comment": "7 pages, 2 figures", "summary": "Anticonformity, behaving in deliberate opposition to the group of influence, has long been recognized as a distinct social response, differing both from conformity and from independence. While often treated as a source of noise or contrarianism, anticonformity can play a constructive role in social dynamics by counterbalancing majority pressure and influencing collective outcomes. Recently, it was shown in laboratory experiments that evaluation may induce strategic anticonformity when rewards are anticipated. Moreover, using agent-based modeling, it has been demonstrated that anticonformity can depolarize highly polarized social groups and prevent social hysteresis. These findings encouraged us to extend the q-voter model with asymmetric independence, an agent-based model of the diffusion of innovation, by introducing anticonformity, so that agents can act independently, follow the group, or oppose it. Using a mean-field approximation (MFA), we investigate how these behavioral tendencies influence the diffusion of innovation. Our results show that anticonformists can accelerate early adoption and enable successful diffusion even in cases where diffusion would otherwise fail. The model exhibits two stable adoption levels separated by an unstable branch, giving rise to hysteresis and a critical mass effect. We also demonstrate that increasing independence lowers the threshold of anticonformity needed for widespread adoption. These results highlight how anticonformist behavior can facilitate innovation diffusion, with practical implications for decision-makers and policy design."}
{"id": "2511.23448", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.23448", "abs": "https://arxiv.org/abs/2511.23448", "authors": ["Laura A. Mansfield", "Hannah M. Christensen"], "title": "Epistemic and Aleatoric Uncertainty Quantification in Weather and Climate Models", "comment": null, "summary": "Representing and quantifying uncertainty in physical parameterisations is a central challenge in weather and climate modelling, and approaches are often developed separately for different timescales. Here, we introduce a unified framework for analysing uncertainty in parameterisations across weather and climate regimes. Using the Lorenz 1996 system as a testbed for simplified chaotic dynamics, we quantify uncertainties in a subgrid-scale parameterisation using a Bayesian Neural Network (BNN). This allows us to disentangle aleatoric uncertainty, arising from internal variability in the training data, and epistemic uncertainties, arising from poorly constrained parameters during training. At runtime, we sample uncertainties in line with stochastic approaches in weather models and perturbed-parameter methods in climate models. On weather timescales, aleatoric uncertainty dominates, underscoring the value of stochastic parameterisations. On longer, climate timescales and under changing forcings, accounting for both types of uncertainty is necessary for well-calibrated ensembles, with epistemic uncertainty widening the range of explored climate states, and aleatoric uncertainty promoting transitions between them. Constraining parameter uncertainty with short simulations reduces epistemic uncertainty and improves long-term model behaviour under perturbed forcings. This framework links concepts from machine learning with traditional uncertainty quantification in Earth system modelling, offering a pathway toward seamless treatment of uncertainty in weather and climate prediction."}
{"id": "2511.22219", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22219", "abs": "https://arxiv.org/abs/2511.22219", "authors": ["Paola F. Antonietti", "Silvia Bertoluzza", "Fabio Credali"], "title": "The Reduced Basis Multigrid scheme for the Virtual Element Method", "comment": "8 pages, 1 figure, 2 tables, 2 algorithms", "summary": "We present a non-nested W-cycle multigrid scheme for the lowest order Virtual Element Method on polygonal meshes. To avoid the implicit definition of the Virtual Element space, which poses several issues in the computation of intergrid operators that underpin multigrid methods, the proposed scheme uses a fully-conforming auxiliary space constructed by cheaply computing the virtual basis functions via the reduced basis method."}
{"id": "2511.22745", "categories": ["math.OC", "cs.DC", "cs.SI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.22745", "abs": "https://arxiv.org/abs/2511.22745", "authors": ["Anqi Dong", "Amirhossein Taghvaei", "Tryphon T. Georgiou"], "title": "A lasso-alternative to Dijkstra's algorithm for identifying short paths in networks", "comment": "25 pages, 7 figures", "summary": "We revisit the problem of finding the shortest path between two selected vertices of a graph and formulate this as an $\\ell_1$-regularized regression -- Least Absolute Shrinkage and Selection Operator (lasso). We draw connections between a numerical implementation of this lasso-formulation, using the so-called LARS algorithm, and a more established algorithm known as the bi-directional Dijkstra. Appealing features of our formulation include the applicability of the Alternating Direction of Multiplier Method (ADMM) to the problem to identify short paths, and a relatively efficient update to topological changes."}
{"id": "2511.21992", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.21992", "abs": "https://arxiv.org/abs/2511.21992", "authors": ["Zhe Chen", "Xinran Li", "Michael O. Harhay", "Bo Zhang"], "title": "Design-based nested instrumental variable analysis", "comment": null, "summary": "Two binary instrumental variables (IVs) are nested if individuals who comply under one binary IV also comply under the other. This situation often arises when the two IVs represent different intensities of encouragement or discouragement to take the treatment--one stronger than the other. In a nested IV structure, treatment effects can be identified for two latent subgroups: always-compliers and switchers. Always-compliers are individuals who comply even under the weaker IV, while switchers are those who do not comply under the weaker IV but do under the stronger IV. We introduce a novel pair-of-pairs nested IV design, where each matched stratum consists of four units organized in two pairs. Under this design, we develop design-based inference for estimating the always-complier sample average treatment effect (ACO-SATE) and switcher sample average treatment effect (SW-SATE). In a nested IV analysis, IV assignment is randomized within each IV pair; however, whether a study unit receives the weaker or stronger IV may not be randomized. To address this complication, we then propose a novel partly biased randomization scheme and study design-based inference under this new scheme. Using extensive simulation studies, we demonstrate the validity of the proposed method and assess its power under different scenarios. Applying the nested IV framework, we estimated that 52.2% (95% CI: 50.4%-53.9%) of participants enrolled at the Henry Ford Health System in the Prostate, Lung, Colorectal, and Ovarian Cancer Screening Trial were always-compliers, while 26.7% (95% CI: 24.5%-28.9%) were switchers. Among always-compliers, flexible sigmoidoscopy was associated with a trend toward a decreased colorectal cancer rate. No effect was detected among switchers. This offers a richer interpretation of why no increase in the intention-to-treat effect was observed after 1997, even though the compliance rate rose."}
{"id": "2511.21855", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21855", "abs": "https://arxiv.org/abs/2511.21855", "authors": ["Reihaneh Jahedan", "Satya Peddada", "Mark Jennings", "Sunil Katragadda", "James Allison", "Nenad Miljkovic"], "title": "Automated Enumeration of Reconfigurable Architectures for Thermal Management Systems in Battery Electric Vehicles", "comment": null, "summary": "As the automotive industry moves towards vehicle electrification, designing and optimizing thermal management systems (TMSs) for Battery Electric Vehicles (BEVs) has become a critical focus in recent years. The dependence of battery performance on operating temperature, the lack of waste combustion heat, and the significant effect of TMS energy consumption on driving range make the design of BEV TMSs highly complicated compared to conventional vehicles. Although prior research has focused on optimizing the configuration of thermal systems for varying ambient conditions, a holistic approach to studying the full potential of reconfigurable TMS architectures has not yet been fully explored. The complex design landscape of multi-mode reconfigurable systems is difficult to navigate. Relying solely on expert intuition and creativity to identify new architectures both restricts progress and leaves significant performance improvements unrealized. In this study, using graph modelling of TMS architectures, we propose a systematic method to automatically enumerate and simulate reconfigurable architectures for a TMS, given the desired operating modes, along with a framework to conduct transient performance analysis and optimization-based trade-off studies among system performance, energy consumption, and complexity. We explored more than 150 operating mode sequences, retaining 39 unique architectures for further evaluation. MATLAB Simscape models of these architectures were automatically created and their performance evaluated. The multi-objective optimization results provide decision support for selecting the best architecture based on user priorities."}
{"id": "2511.21855", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21855", "abs": "https://arxiv.org/abs/2511.21855", "authors": ["Reihaneh Jahedan", "Satya Peddada", "Mark Jennings", "Sunil Katragadda", "James Allison", "Nenad Miljkovic"], "title": "Automated Enumeration of Reconfigurable Architectures for Thermal Management Systems in Battery Electric Vehicles", "comment": null, "summary": "As the automotive industry moves towards vehicle electrification, designing and optimizing thermal management systems (TMSs) for Battery Electric Vehicles (BEVs) has become a critical focus in recent years. The dependence of battery performance on operating temperature, the lack of waste combustion heat, and the significant effect of TMS energy consumption on driving range make the design of BEV TMSs highly complicated compared to conventional vehicles. Although prior research has focused on optimizing the configuration of thermal systems for varying ambient conditions, a holistic approach to studying the full potential of reconfigurable TMS architectures has not yet been fully explored. The complex design landscape of multi-mode reconfigurable systems is difficult to navigate. Relying solely on expert intuition and creativity to identify new architectures both restricts progress and leaves significant performance improvements unrealized. In this study, using graph modelling of TMS architectures, we propose a systematic method to automatically enumerate and simulate reconfigurable architectures for a TMS, given the desired operating modes, along with a framework to conduct transient performance analysis and optimization-based trade-off studies among system performance, energy consumption, and complexity. We explored more than 150 operating mode sequences, retaining 39 unique architectures for further evaluation. MATLAB Simscape models of these architectures were automatically created and their performance evaluated. The multi-objective optimization results provide decision support for selecting the best architecture based on user priorities."}
{"id": "2511.22720", "categories": ["physics.geo-ph", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.22720", "abs": "https://arxiv.org/abs/2511.22720", "authors": ["Rafat Qubaja", "Murray Moinester", "Joel Kronfeld"], "title": "Disentangling the soil and atmospheric stress on carbon sequestration in a Mediterranean pine forest", "comment": "23 pages, 8 figures, 1 table, drylands forestation, organic and inorganic carbon sequestration,fossil water irrigation", "summary": "Sequestration of atmospheric CO$_2$ in a Mediterranean semi-arid Aleppo Pine Forest (Pinus halepensis) close to the border of the semi-arid timberline was characterized and quantified under field conditions. Measurements of organic and inorganic CO$_2$ sequestration with gas exchange and stock counting approaches were made in both rainfed control (approximately 12$\\%$ average annual soil moisture) and summer irrigated plots (approximately 24$\\%$ annual average soil moisture), providing the opportunity to separate the effects of atmospheric water demand from soil water stress on the atmospheric CO$_2$ sequestration responses. Measurements yield an organic carbon sequestration (OCS) rate of approximately 550 g CO$_2$ m$^{-2}$ yr$^{-1}$, two-thirds in soil and one-third in biomass. In addition, measurements yield an inorganic carbon sequestration (ICS) rate of approximately 216 g CO$_2$ m$^{-2}$ yr$^{-1}$; via calcite (CaCO$_3$) precipitation in the soil due to root exhalation of CO$_2$ (60$\\%$) and microbial activity (40$\\%$). The drip irrigated plot showed approximately 3 times higher organic CO$_2$ sequestration than the control plot. The organic sequestration is divided equally between the soil and the biomass. For the irrigated plot, the inorganic CO$_2$ was approximately 1.8 times higher than that of the control plot. However, for inorganic CO$_2$ sequestration, the soil moisture would need to be maintained lower than that of the study plot to preclude dissolving precipitated calcite. For many drylands, irrigation could be achieved by using fossil water reserves. These measured values demonstrate the relatively high potential carbon sequestration in Mediterranean drylands forests under irrigated and non-irrigated conditions."}
{"id": "2511.22506", "categories": ["quant-ph", "cond-mat.dis-nn", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.22506", "abs": "https://arxiv.org/abs/2511.22506", "authors": ["Youenn Le Gal", "Marco Schirò"], "title": "Replica Field Theory of Quantum Jumps Monitoring: Application to the Ising Chain", "comment": "40 pages, 1 figure, 4 tables", "summary": "In this work we derive the replica field theory for monitored quantum many-body systems evolving under the quantum jumps protocol, corresponding to a non-Hermitian evolution interspersed with random quantum jumps whose distribution is state-dependent. We show that the density matrix of $R$ replicas evolves according to a master equation where the non-Hermitian term is replica-diagonal while coupling among replicas are due to quantum jumps. We write down the associated Keldysh action and study its behavior for the specific case of the Ising Chain with monitoring of particle density and tunable anisotropy, interpolating between free fermions with strong U(1) symmetry and the Ising chain with Z$_2$ symmetry. We derive the effective field theory in terms of slowly varying fields and obtain the replica-diagonal saddle point, which we show to describe the average state. We then go beyond saddle point and derive the effective field theory describing the replica off-diagonal sector, which takes the form of a Non-Linear Sigma Model. The symmetry class is either DIII or D, depending on the parameters of the Ising chain, except at a special symmetric point, where we recover the results for free fermions. We discuss the implications of these findings for the entangling phase observed numerically for the monitored Ising chain."}
{"id": "2511.22647", "categories": ["cond-mat.str-el", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.22647", "abs": "https://arxiv.org/abs/2511.22647", "authors": ["Dong-Yu Bao", "Gong Cheng", "Hong-Hao Song", "Zheng-Cheng Gu"], "title": "Tensor complex renormalization with generalized symmetry and topological bootstrap", "comment": "27 pages, 28 figures", "summary": "Recent progress in generalized symmetry and topological holography has shown that, in conformal field theory (CFT), topological data from one dimensional higher can play a key role in determining local dynamics. Based on this insight, a fixed-point (FP) tensor complex (TC) for CFT has recently been constructed. In this work, we develop a TC renormalization (TCR) algorithm adapted to this CFT-based structure, forming a renormalization-group (RG) framework with generalized symmetry. We show that the full FP tensor can emerge from the RG flow starting with only the three-point function of the primary fields. Remarkably, even when starting solely from topological data, the RG process can still reconstruct the full FP tensor--a method we call as topological bootstrap. This approach deepens the connection between the topological and dynamical aspects of CFT and suggests pathways toward a fully algebraic description of gapless quantum states, with potential extensions to higher dimensions."}
{"id": "2511.23102", "categories": ["physics.comp-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.23102", "abs": "https://arxiv.org/abs/2511.23102", "authors": ["Guoqiang Lei", "Zhihua Wang", "Lijing Zhou", "D. Exposito", "Xuerui Mao"], "title": "Discontinuity-aware physics-informed neural networks for phase-field method in three-phase flows", "comment": null, "summary": "Physics-informed neural networks (PINNs) have proved to be a promising method for modeling multiphase flows. However, due to the gradient-direction conflict during the optimization of the coupled strongly nonlinear Allen-Cahn, Cahn-Hilliard, and Navier-Stokes equations, phase-field-based PINNs have not been extended to three-phase flows with phase change. Furthermore, the interface thickness is known to be artificially magnified, whether in numerical or artificial intelligence-based simulations, reducing accuracy. To mitigate these limitations, this study presents a discontinuity-aware physics-informed neural network (DPINN) that solves an energy-stable phase-field model for three-phase flows. It incorporates a discontinuity-aware residual-adaptive architecture to mitigate spectral bias and to automatically detect and model sharp interfaces, and a learnable local artificial-viscosity term to stabilize the algorithm near steep gradients. During optimization, adaptive time-marching and loss-balancing strategies are introduced to reduce long-term error accumulation and to mitigate gradient conflicts in multi-objective training, respectively. In numerical experiments on the two-phase reversed single-vortex and bubble-rising problems, the proposed method accurately resolves sharp interfacial dynamics that conventional PINNs fail to converge. It also extends to a three-phase droplet-icing case with viscosity and density ratios exceeding 7 and 3 orders of magnitude, accurately capturing the phase-change dynamics and the formation of the pointy tip."}
{"id": "2511.22251", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22251", "abs": "https://arxiv.org/abs/2511.22251", "authors": ["Christopher Hojny", "Cédric Roy"], "title": "A Framework for Handling and Exploiting Symmetry in Benders' Decomposition", "comment": "20 pages, 2 figures", "summary": "Benders' decomposition (BD) is a framework for solving optimization problems by removing some variables and modeling their contribution to the original problem via so-called Benders cuts. While many advanced optimization techniques can be applied in a BD framework, one central technique has not been applied systematically in BD: symmetry handling. The main reason for this is that Benders cuts are not known explicitly but only generated via a separation oracle.\n  In this work, we close this gap by developing a theory of symmetry detection within the BD framework. To this end, we introduce a tailored family of graphs that capture the symmetry information of both the Benders master problem and the Benders oracles. Once symmetries of these graphs are known, which can be found by established techniques, classical symmetry handling approaches become available to accelerate BD. We complement these approaches by devising techniques for the separation and aggregation of symmetric Benders cuts by means of tailored separation routines and extended formulations. Both substantially reduce the number of executions of the separation oracles. In a numerical study, we show the effect of both symmetry handling and cut aggregation for bin packing and scheduling problems."}
{"id": "2511.22583", "categories": ["cond-mat.stat-mech", "gr-qc", "hep-ph", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.22583", "abs": "https://arxiv.org/abs/2511.22583", "authors": ["Fumika Suzuki", "Wojciech H. Zurek"], "title": "Deconstructing symmetry breaking dynamics", "comment": "13 pages, 8 figures, see arXiv:2412.15568 for the preliminary version", "summary": "The Kibble-Zurek mechanism (KZM) successfully predicts the density of topological defects deposited by the phase transitions, but it is not clear why. Its key conjecture is that, near the critical point of the second-order phase transition, critical slowing down will result in a period when the system is too sluggish to follow the potential that is changing faster than its reaction time. The correlation length at the freeze-out instant $\\hat t$ when the order parameter catches up with the post-transition broken symmetry configuration is then decisive, determining when the mosaic of broken symmetry domains locks in topological defects. To understand why the KZM works so well we analyze Landau-Ginzburg model and show why temporal evolution of the order parameter plays such a key role. The analytical solutions we obtain suggest novel, hitherto unexplored, experimentally accessible observables that can shed light on symmetry breaking dynamics while testing the conjecture on which the KZM is based."}
{"id": "2511.23069", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.23069", "abs": "https://arxiv.org/abs/2511.23069", "authors": ["Rohit Sahasrabuddhe", "Renaud Lambiotte"], "title": "Quantifying the Spatial and Demographic Scales of Segregation", "comment": null, "summary": "Cities around the world exhibit residential segregation along ethnic, religious, socioeconomic, and other social divides. As high-resolution demographic and spatial data become widely available, decomposable measures have become essential tools for understanding the multi-scale structure of segregation. In this paper, we introduce a framework that quantifies how much segregation is expressed at different spatial and demographic scales. Extending existing spatial decompositions, our approach also measures the internal segregation of broad demographic groups, enabling a joint assessment of geographic and demographic structure. We illustrate the usefulness of this framework with a case study of ethnic residential segregation in England and Wales. Our methods provide a flexible, general tool for identifying the scales at which segregation operates and for guiding multi-scale models of urban systems."}
{"id": "2511.23458", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.23458", "abs": "https://arxiv.org/abs/2511.23458", "authors": ["Charles W. Powell"], "title": "A retrospective on the 2025 Atlantic hurricane season", "comment": null, "summary": "The 2025 Atlantic hurricane season saw above average activity overall, with extended quiet periods separated by three distinct clusters of activity. The broad-scale conditions were often unfavourable for cyclogenesis and common drivers of activity such as La Nina were not present. However, short-term variability, including periods of weak shear and episodic equatorial wave driving, led to the clusters of activity. When storms were able to overcome the unfavourable conditions, above-average SSTs provided the energy for intensification, leading to the formation of five hurricanes, of which three (Erin, Humberto, and Melissa) reached category five."}
{"id": "2511.22304", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22304", "abs": "https://arxiv.org/abs/2511.22304", "authors": ["Domenico Caparello", "Lorenzo Pareschi", "Thomas Rey"], "title": "High-Order Asymptotic-Preserving IMEX schemes for an ES-BGK model for Gas Mixtures", "comment": "27 pages, 8 figures", "summary": "In this work we construct a high-order Asymptotic-Preserving (AP) Implicit-Explicit (IMEX) scheme for the ES-BGK model for gas mixtures introduced in [Brull, Commun. Math. Sci., 2015]. The time discretization is based on the IMEX strategy proposed in [Filbet, Jin, J. Sci. Comput., 2011] for the single-species BGK model and is here extended to the multi-species ES-BGK setting. The resulting method is fully explicit, uniformly stable with respect to the Knudsen number and, in the fluid regime, it reduces to a consistent and high-order accurate solver for the limiting macroscopic equations of the mixture. The IMEX structure removes the stiffness associated with the relaxation term so that the time step is constrained only by a hyperbolic CFL condition. The full solver couples a high-order space and velocity discretization that includes third-order time integration, a CWENO3 finite-volume reconstruction in space, exact conservation of macroscopic moments in the discrete velocity space, and a multithreaded implementation. The proposed approach can handle an arbitrary number of species. Its accuracy and robustness are demonstrated on a set of multidimensional kinetic tests for gas mixtures, where the AP property and the correct asymptotics are numerically verified across different regimes."}
{"id": "2511.23061", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.23061", "abs": "https://arxiv.org/abs/2511.23061", "authors": ["Angelika Abramiuk-Szurlej"], "title": "The impact of anticonformity on the diffusion of innovation -- insights from the q-voter model", "comment": "7 pages, 2 figures", "summary": "Anticonformity, behaving in deliberate opposition to the group of influence, has long been recognized as a distinct social response, differing both from conformity and from independence. While often treated as a source of noise or contrarianism, anticonformity can play a constructive role in social dynamics by counterbalancing majority pressure and influencing collective outcomes. Recently, it was shown in laboratory experiments that evaluation may induce strategic anticonformity when rewards are anticipated. Moreover, using agent-based modeling, it has been demonstrated that anticonformity can depolarize highly polarized social groups and prevent social hysteresis. These findings encouraged us to extend the q-voter model with asymmetric independence, an agent-based model of the diffusion of innovation, by introducing anticonformity, so that agents can act independently, follow the group, or oppose it. Using a mean-field approximation (MFA), we investigate how these behavioral tendencies influence the diffusion of innovation. Our results show that anticonformists can accelerate early adoption and enable successful diffusion even in cases where diffusion would otherwise fail. The model exhibits two stable adoption levels separated by an unstable branch, giving rise to hysteresis and a critical mass effect. We also demonstrate that increasing independence lowers the threshold of anticonformity needed for widespread adoption. These results highlight how anticonformist behavior can facilitate innovation diffusion, with practical implications for decision-makers and policy design."}
{"id": "2511.22049", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22049", "abs": "https://arxiv.org/abs/2511.22049", "authors": ["Joshua Richland", "Tuomo Kiiskinen", "William Wang", "Sophia Lu", "Balasubramanian Narasimhan", "Manuel Rivas", "Robert Tibshirani"], "title": "Univariate-Guided Sparse Regression for Biobank-Scale High-Dimensional -omics Data", "comment": null, "summary": "We present a scalable framework for computing polygenic risk scores (PRS) in high-dimensional genomic settings using the recently introduced Univariate-Guided Sparse Regression (uniLasso). UniLasso is a two-stage penalized regression procedure that leverages univariate coefficients and magnitudes to stabilize feature selection and enhance interpretability. Building on its theoretical and empirical advantages, we adapt uniLasso for application to the UK Biobank, a population-based repository comprising over one million genetic variants measured on hundreds of thousands of individuals from the United Kingdom. We further extend the framework to incorporate external summary statistics to increase predictive accuracy. Our results demonstrate that the adapted uniLasso attains predictive performance comparable to standard Lasso while selecting substantially fewer variants, yielding sparser and more interpretable models. Moreover, it exhibits superior performance in estimating PRS relative to its competitors, such as PRS-CS. Integrating external scores further improves prediction while maintaining sparsity."}
{"id": "2511.21906", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21906", "abs": "https://arxiv.org/abs/2511.21906", "authors": ["Ying Wang", "Yanlong Zhao", "Ji-Feng Zhang", "Karl Henrik Johansson"], "title": "Quantized Distributed Estimation with Event-triggered Communication and Packet Loss", "comment": "6 page,4 figures, accepted by 64rd IEEE Conference on Decision and Control", "summary": "This paper focuses on the problem of quantized distributed estimation with event-triggered communication and packet loss, aiming to reduce the number of transmitted bits. The main challenge lies in the inability to differentiate between an untriggered event and a packet loss occurrence. This paper proposes an event-triggered distributed estimation algorithm with quantized communication and quantized measurement, in which it introduces a one-bit information reconstruction method to deal with packet loss. The almost sure convergence and convergence rate of the proposed algorithm are established.Besides, it is demonstrated that the global average communication bit-rate decreases to zero over time. Moreover, the trade-off between communication rate and convergence rate is revealed, providing guidance for designing the communication rate required to achieve the algorithm's convergence rate. A numerical example is supplied to validate the findings."}
{"id": "2511.21906", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21906", "abs": "https://arxiv.org/abs/2511.21906", "authors": ["Ying Wang", "Yanlong Zhao", "Ji-Feng Zhang", "Karl Henrik Johansson"], "title": "Quantized Distributed Estimation with Event-triggered Communication and Packet Loss", "comment": "6 page,4 figures, accepted by 64rd IEEE Conference on Decision and Control", "summary": "This paper focuses on the problem of quantized distributed estimation with event-triggered communication and packet loss, aiming to reduce the number of transmitted bits. The main challenge lies in the inability to differentiate between an untriggered event and a packet loss occurrence. This paper proposes an event-triggered distributed estimation algorithm with quantized communication and quantized measurement, in which it introduces a one-bit information reconstruction method to deal with packet loss. The almost sure convergence and convergence rate of the proposed algorithm are established.Besides, it is demonstrated that the global average communication bit-rate decreases to zero over time. Moreover, the trade-off between communication rate and convergence rate is revealed, providing guidance for designing the communication rate required to achieve the algorithm's convergence rate. A numerical example is supplied to validate the findings."}
{"id": "2511.22971", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2511.22971", "abs": "https://arxiv.org/abs/2511.22971", "authors": ["Ali Tozar"], "title": "Robust Universality of Non-Hermitian Anderson Transitions: From Dyson Singularity to Model-Independent Scaling", "comment": "8pages 7figures", "summary": "We investigate the universality of Anderson localization transitions in one-dimensional non-Hermitian systems exhibiting the skin effect. By developing a numerically stable Log-Space Non-Hermitian Scaling (LNS) method, we overcome the severe floating-point overflow issues associated with the exponential growth of transmittance (T ~ exp(2 gamma L)), enabling precision finite-size scaling analysis up to system sizes of L = 1200. We probe the critical behavior across three distinct disorder landscapes: uniform diagonal, binary diagonal, and off-diagonal (random hopping) disorder. While the uniform model exhibits a standard mobility edge, the off-diagonal model reveals a Dyson-like singularity at the band center (E = 0), where the system resists localization even at strong disorder due to sublattice symmetry protection. However, upon symmetry breaking (E != 0), we demonstrate that all considered models, regardless of the disorder distribution (continuous vs. discrete) or Hamiltonian structure (site vs. bond randomness), belong to the same robust universality class. The critical exponents are determined as nu = 1.50 +/- 0.00 and beta ~ 0.65 through unambiguous data collapse, establishing a model-independent description of non-Hermitian localization transitions."}
{"id": "2511.22669", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.22669", "abs": "https://arxiv.org/abs/2511.22669", "authors": ["Emilio Cortés Estay", "Naushad A. Kamar", "Philippe Corboz"], "title": "Accurate computation of the energy variance and $\\langle\\langle \\mathcal{L}^\\dagger \\mathcal{L} \\rangle\\rangle$ using iPEPS", "comment": "9 pages, 7 figures", "summary": "Infinite projected entangled-pair states (iPEPS) provide a powerful tensor network ansatz for two-dimensional quantum many-body systems in the thermodynamic limit. In this paper we introduce an approach to accurately compute the energy variance of an iPEPS, enabling systematic extrapolations of the ground-state energy to the exact zero-variance limit. It is based on the contraction of a large cell of tensors using the corner transfer matrix renormalization group (CTRMG) method, to evaluate the correlator between pairs of local Hamiltonian terms. We show that the accuracy of this approach is substantially higher than that of previous methods, and we demonstrate the usefulness of variance extrapolation for the Heisenberg model, for a free fermionic model, and for the Shastry-Sutherland model. Finally, we apply the approach to compute $\\langle \\langle \\mathcal{L}^\\dagger \\mathcal{L} \\rangle \\rangle$ for an open quantum system described by the Liouvillian $\\mathcal{L}$, in order to assess the quality of the steady-state solution and to locate first-order phase transitions, using the dissipative quantum Ising model as an example."}
{"id": "2511.22202", "categories": ["quant-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.22202", "abs": "https://arxiv.org/abs/2511.22202", "authors": ["Hossein Abedi", "Mohammadsadegh Khazali", "Klaus Mølmer"], "title": "Optimal Control for Rydberg multi-qubit operations", "comment": null, "summary": "Quantum computing algorithms can be decomposed into a universal set of elementary one- and two-qubit gates. Different physical implementations of quantum computing, however, employ interactions that permit direct conditional dynamics on multiple qubits in a single step. In this work, we leverage quantum optimal control techniques to design single continuous laser pulses that implement multi-qubit controlled-phase, -NOT and -swap (Fredkin) gates on Rydberg atom quantum processors. The identification of robust multi-qubit operations leads to reduced operation time and less decoherence, and the control field provides continuous protection of the atoms from environmental noise. Notably, we find that the controlled-swap (Fredkin) gate, implemented using this approach achieves 99.74\\% fidelity while accounting for imperfections such as spontaneous emission, laser fluctuations, and Doppler dephasing."}
{"id": "2511.22331", "categories": ["math.OC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.22331", "abs": "https://arxiv.org/abs/2511.22331", "authors": ["Lesi Chen", "Jingzhao Zhang"], "title": "On the Condition Number Dependency in Bilevel Optimization", "comment": null, "summary": "Bilevel optimization minimizes an objective function, defined by an upper-level problem whose feasible region is the solution of a lower-level problem. We study the oracle complexity of finding an $ε$-stationary point with first-order methods when the upper-level problem is nonconvex and the lower-level problem is strongly convex. Recent works (Ji et al., ICML 2021; Arbel and Mairal, ICLR 2022; Chen el al., JMLR 2025) achieve a $\\tilde{\\mathcal{O}}(κ^4 ε^{-2})$ upper bound that is near-optimal in $ε$. However, the optimal dependency on the condition number $κ$ is unknown. In this work, we establish a new $Ω(κ^2 ε^{-2})$ lower bound and $\\tilde{\\mathcal{O}}(κ^{7/2} ε^{-2})$ upper bound for this problem, establishing the first provable gap between bilevel problems and minimax problems in this setup. Our lower bounds can be extended to various settings, including high-order smooth functions, stochastic oracles, and convex hyper-objectives: (1) For second-order and arbitrarily smooth problems, we show $Ω(κ_y^{13/4} ε^{-12/7})$ and $Ω(κ^{17/10} ε^{-8/5})$ lower bounds, respectively. (2) For convex-strongly-convex problems, we improve the previously best lower bound (Ji and Liang, JMLR 2022) from $Ω(κ/\\sqrtε)$ to $Ω(κ^{5/4} / \\sqrtε)$. (3) For smooth stochastic problems, we show an $Ω(κ^4 ε^{-4})$ lower bound."}
{"id": "2511.22622", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.22622", "abs": "https://arxiv.org/abs/2511.22622", "authors": ["Alexander Valov", "Baruch Meerson"], "title": "Anomalous scaling and phase transition in large deviations of dynamical observables of stationary Gaussian processes", "comment": "15 pages, 7 figures", "summary": "We study large deviations, over a long time window $T \\to \\infty$, of the dynamical observables $A_n = \\int_{0}^{T} x^n(t) dt$, $n=3,4,\\dots$, where $x(t)$ is a centered stationary Gaussian process in continuous time. We show that, for short-correlated processes the probability density of $A_n$ exhibits an anomalous scaling $P(A_n,T) \\sim \\exp[-T^μ f_n(ΔA_n T^{-ν})]$ at $T\\to \\infty$ while keeping $ΔA_n T^{-ν}$ constant. Here $ΔA_n$ is the deviation of $A_n$ from its ensemble average. The anomalous exponents $μ$ and $ν$ depend on $n$ and are smaller than $1$, whereas the rate function $f_n(z)$ exhibits a first-order dynamical phase transition (DPT) which resembles condensation transitions observed in many systems. The same type of anomaly and DPT, with the same $μ$ and $ν$, was previously uncovered for the Ornstein-Uhlenbeck process - the only stationary Gaussian process which is also Markovian. We also uncover an anomalous behavior and a similar DPT in the long-correlated Gaussian processes. However, the anomalous exponents $μ$ and $ν$ are determined in this case not only by $n$ but also by the power-law long-time decay $\\sim |t|^{-α}$ of the covariance. The different anomalous scaling behavior is a consequence of a faster-than-linear scaling with $T$ of the variance of $A_n$. Finally, for sufficiently long-ranged correlations, $α<2/n$, the DPT disappears, giving way to a smooth crossover between the regions of typical, Gaussian fluctuations and large deviations. The basic mechanism behind the DPT is the existence of strongly localized optimal paths of the process conditioned on very large $A_n$ and coexistence between the localized and delocalized paths of the conditioned process. Our theoretical predictions are corroborated by replica-exchange Wang-Landau simulations where we could probe probability densities down to $10^{-200}$."}
{"id": "2511.23339", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.23339", "abs": "https://arxiv.org/abs/2511.23339", "authors": ["Veronika Brooks", "Joshua Fragoso García", "Lin Zheng", "Viktor Paul Müller", "Christoph Nolden", "Dominik Möst", "Martin Wietschel"], "title": "Who will import hydrogen in 2050? Global assessment with China and US case studies", "comment": "42 pages, 9 figures, 4 tables", "summary": "This study assesses the global hydrogen import potential in 2050 by looking at the renewable hydrogen production potential in prospective import-oriented countries. Renewable energy potentials calculated with a GIS based model and 2050 primary energy consumption projections are used to identify candidate importers by comparing it with expected demand. Two approaches are applied: (1) a meta-analysis of literature on hydrogen production potential and demand for the identified countries, and (2) detailed regional analyses for the United States and China. The results suggest limited prospects for a fully global hydrogen market, although certain countries, such as Germany, Italy, and the Netherlands, are likely to remain net importers. By contrast, many Asian countries have enough renewable resources to decarbonise their energy systems. China and the United States may follow divergent pathways: while the United States is well placed to meet its overall demand, using its own resources, it can still benefit from regional connections with neighbouring countries. China is facing strong demand in its eastern regions, so it may source cost-effective renewable hydrogen from foreign countries instead of relying solely on domestic production. Overall, the findings suggest that hydrogen trade will likely remain regionally concentrated, shaped by the interplay of renewable resource distribution, energy demand, other available hydrogen production pathways, and infrastructure constraints."}
{"id": "2511.23460", "categories": ["physics.ao-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2511.23460", "abs": "https://arxiv.org/abs/2511.23460", "authors": ["Nihar Paul", "Amala Mahadevan"], "title": "Effect of near-inertial pumping on subduction at an ocean front", "comment": "38 pages, 1 Table, 12 Figures, 11 SI Figures, Text S1 to S3, SI Movies S1 to S2, and Table S1", "summary": "The interactions between near-inertial waves (NIWs) and submesoscale currents in the surface ocean are challenging to deconvolve due to their overlapping temporal and spatial scales. The frequency of NIW is modulated by the relative vorticity, $ζ$, of submesoscale currents, which varies between positive and negative $ζ$ of $O(f)$ on spatial scales of 1 -- 10~$km$, particularly across fronts where the horizontal buoyancy gradient, $\\nabla_H b$, is intensified. The effective NIW frequency $f_{\\small{eff}} = f + ζ/2$ can therefore also vary by $O(f)$ on these scales, causing the waves to be out of phase. This generates periodic convergence and divergence in the surface layer, particularly at fronts. The resulting vertical motion, known as inertial pumping, is traditionally considered to be reversible. However, the strong vertical shear of the horizontal velocity at fronts, $v_z \\sim |\\nabla_H b|/f$, implies that not all of the water that is pumped downward will return. We examine the effect of this asymmetry on the vertical transport of tracers with an ambient vertical gradient, analogous to biogeochemical tracers, such as oxygen and dissolved organic carbon. Using numerical simulations of an unstable front forced by NIW, we demonstrate that inertial pumping can lead to net vertical transport of tracers. Spectral analysis of the vertical tracer flux -- given by the covariance between tracer anomaly and vertical velocity -- reveals that the interaction of strong NIW with submesoscale currents enhances the vertical exchange at the front on both the sub-inertial and inertial time scales."}
{"id": "2511.22422", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22422", "abs": "https://arxiv.org/abs/2511.22422", "authors": ["Ayoub Lailoune", "Valerio Loi", "Stefano Serra-Capizzano"], "title": "Weyl distributions, spectral properties, and circulant approximation results for quaternion block multilevel Toeplitz matrix sequences", "comment": null, "summary": "The present work contains a comprehensive treatment of Weyl eigenvalue and singular value distributions for single-axis quaternion block multilevel Toeplitz matrix sequences generated by $s\\times t$ quaternion matrix-valued, $d$-variate, Lebesgue integrable generating functions. Furthermore, in view of concrete applications, we are interested in preconditioning and matrix approximation results. To this end, a crucial step is the extension of the notion of an approximating class of sequences (a.c.s.) to the case of matrix sequences with quaternion entries, since it allows us to decompose the difference between a matrix and its preconditioner into low-norm plus (relatively) low-rank terms. As a specific example, we consider classes of quaternion block multilevel circulant matrix sequences as an a.c.s. for quaternion block multilevel Toeplitz matrix sequences. These approximation results lay the foundations for fast preconditioning methods when dealing with large quaternion linear systems stemming from modern applications. We conclude our study with numerical experiments and directions for future research."}
{"id": "2511.23364", "categories": ["cs.CE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.23364", "abs": "https://arxiv.org/abs/2511.23364", "authors": ["Koutarou Tamura"], "title": "Predicting Startup-VC Fund Matches with Structural Embeddings and Temporal Investment Data", "comment": null, "summary": "This study proposes a method for predicting startup inclusion, estimating the probability that a venture capital fund will invest in a given startup. Unlike general recommendation systems, which typically rank multiple candidates, our approach formulates the problem as a binary classification task tailored to each fund-startup pair. Each startup is represented by integrating textual, numerical, and structural features, with Node2Vec capturing network context and multihead attention enabling feature fusion. Fund investment histories are encoded as LSTM based sequences of past investees.\n  Experiments on Japanese startup data demonstrate that the proposed method achieves higher accuracy than a static baseline. The results indicate that incorporating structural features and modeling temporal investment dynamics are effective in capturing fund-startup compatibility."}
{"id": "2511.22152", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22152", "abs": "https://arxiv.org/abs/2511.22152", "authors": ["Miodrag M. Lovric"], "title": "The Bayes Factor Reversal Paradox", "comment": "8 pages, 1 figure, 1 table, supplementary material. Submitted to Biometrika", "summary": "In 1957, Lindley published \"A statistical paradox\" in Biometrika, revealing a fundamental conflict between frequentist and Bayesian inference as sample size approaches infinity. We present a new paradox of a different kind: a conflict within Bayesian inference itself. In the normal model with known variance, we prove that for any two-sided statistically significant result at the 0.05 level there exist prior variances such that the Bayes factor indicates evidence for the alternative with one choice while indicating evidence for the null with another. Thus, the same data, testing the same hypothesis, can yield opposite conclusions depending solely on prior choice. This answers Robert's 2016 call to investigate the impact of the prior scale on Bayes factors and formalises his concern that this choice involves arbitrariness to a high degree. Unlike the Jeffreys-Lindley paradox, which requires sample size approaching infinity, the paradox we identify occurs with realistic sample sizes."}
{"id": "2511.21953", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21953", "abs": "https://arxiv.org/abs/2511.21953", "authors": ["Yuezhu Xu", "Mohamed Serry", "Jun Liu", "S. Sivaranjani"], "title": "Learning Neural Network Safe Tracking Controllers from Backward Reachable Sets", "comment": null, "summary": "The design of tracking controllers that closely follow a reference trajectory while ensuring safety and robustness against disturbances is a challenging problem in the control of autonomous systems. In this work, we propose a neural network-based safe tracking control framework for nonlinear discrete-time systems with reach-avoid specifications in the presence of disturbances. Our approach begins with generation of a nominal trajectory using standard trajectory synthesis approaches, followed by construction of safe zonotopic backward reachable sets along the nominal trajectory. The states lying within the backward reachable sets are guaranteed to satisfy safe reachability specifications. Then, our key insight is to leverage the computed backward reachable sets to inform the architecture and training of a neural network-based tracking controller such that the neural network drives the system's states through these backward reachable sets, thereby improving the likelihood of safe reachability. We perform formal verification with conformal prediction to achieve statistical safety guarantees on the performance of the learned neural controller. The performance of our approach is illustrated through a numerical example on the discrete-time Dubin's car model."}
{"id": "2511.21953", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.21953", "abs": "https://arxiv.org/abs/2511.21953", "authors": ["Yuezhu Xu", "Mohamed Serry", "Jun Liu", "S. Sivaranjani"], "title": "Learning Neural Network Safe Tracking Controllers from Backward Reachable Sets", "comment": null, "summary": "The design of tracking controllers that closely follow a reference trajectory while ensuring safety and robustness against disturbances is a challenging problem in the control of autonomous systems. In this work, we propose a neural network-based safe tracking control framework for nonlinear discrete-time systems with reach-avoid specifications in the presence of disturbances. Our approach begins with generation of a nominal trajectory using standard trajectory synthesis approaches, followed by construction of safe zonotopic backward reachable sets along the nominal trajectory. The states lying within the backward reachable sets are guaranteed to satisfy safe reachability specifications. Then, our key insight is to leverage the computed backward reachable sets to inform the architecture and training of a neural network-based tracking controller such that the neural network drives the system's states through these backward reachable sets, thereby improving the likelihood of safe reachability. We perform formal verification with conformal prediction to achieve statistical safety guarantees on the performance of the learned neural controller. The performance of our approach is illustrated through a numerical example on the discrete-time Dubin's car model."}
{"id": "2511.23060", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.23060", "abs": "https://arxiv.org/abs/2511.23060", "authors": ["Yan V. Fyodorov", "Bertrand Lacroix-A-Chez-Toine", "Pierre Le Doussal"], "title": "Ground state energy fluctuations of pinned elastic manifolds", "comment": "39 pages, 3 figures", "summary": "We describe the atypical fluctuations of the ground state energy of the random elastic manifold, a disordered model defined on a lattice of linear size $L$ with internal dimension $0\\leq d<4$ embedded in a medium of dimension $N\\gg 1$. The ground-state energy results from a competition between confinement, elasticity and disorder. We obtain an exact description of the large deviation rate function with speed $NL^d$ and its different phases, corresponding to different patterns of replica symmetry breaking (RSB). Our results show that the ground-state energy satisfies a central limit theorem and we obtain an explicit expression for the rescaled variance. In the (massless) limit of zero confinement, this variance vanishes for short-range disorder and the ground-state energy displays super-concentration. From our results on the large deviation function, we characterise explicitly the left tail of the distribution of the typical fluctuations of the ground state energy. It displays an exponential tail for a one step RSB pattern while for a full RSB pattern it decays super-exponentially with a non trivial exponent $ξ$ that we compute explicitly."}
{"id": "2511.22714", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.22714", "abs": "https://arxiv.org/abs/2511.22714", "authors": ["Maxime Lucas", "Arnaud Ralko", "Andreas Honecker", "Guy Trambly de Laissardière"], "title": "Tetrahedral Core in a Sea of Competing Magnetic Phases in Graphene", "comment": null, "summary": "We reveal the emergence of a robust tetrahedral magnetic ground state in monolayer graphene doped to the van Hove singularity (vHS). This noncoplanar, gapped spin configuration -- featuring four orthogonal moments -- has been previously identified as a candidate instability. Here, not only do we confirm its stability across all finite interactions using fully self-consistent, real-space-resolved calculations, but we also go beyond earlier work by charting the full surrounding phase diagram. In doing so, we unravel a cascade of symmetry-broken magnetic states -- pseudo-tetrahedral, planar, collinear, and modulated textures -- which we classify using spin structure factors and vector order parameters. These results stem from unrestricted Hartree-Fock simulations on large supercells with dense k-point sampling, enabling us to resolve interaction-driven magnetic and charge inhomogeneities. Our findings connect directly with recent ARPES and doping experiments near the vHS in graphene, and establish the tetrahedral state as the central correlated instability in this regime, offering predictive insight into emergent magnetism in correlated Dirac materials."}
{"id": "2511.22332", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.atom-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.22332", "abs": "https://arxiv.org/abs/2511.22332", "authors": ["Rosa Lucia Capurso", "Giuseppe Calajó", "Simone Montangero", "Saverio Pascazio", "Francesco V. Pepe", "Maria Maffei", "Giuseppe Magnifico", "Paolo Facchi"], "title": "Superradiant decay in non-Markovian Waveguide Quantum Electrodynamics", "comment": "16 pages, 8 figures", "summary": "An array of initially excited emitters coupled to a one-dimensional waveguide exhibits superradiant decay under the Born-Markov approximation, manifested as a coherent burst of photons in the output field. In this work, we employ tensor-network methods to investigate its non-Markovian dynamics induced by finite time delays in photon exchange among the emitters. We find that the superradiant burst breaks into a structured train of correlated photons, each intensity peak corresponding to a specific photon number. We quantify the emitter-photon and emitter-emitter entanglement generated during this process and show that the latter emerges in the long-time limit, as part of the excitation becomes trapped within the emitters' singlet subspace. We finally consider the decay of the system's most radiant state, the symmetric Dicke state, and show that time delay can lead to decay rates exceeding those predicted by the Markovian approximation."}
{"id": "2511.22428", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22428", "abs": "https://arxiv.org/abs/2511.22428", "authors": ["Alain Bensoussan", "Ziyu Huang", "Sheung Chi Phillip Yam"], "title": "A Variational Approach to Mean Field Type Control", "comment": null, "summary": "Variational methods have been used to study stochastic control for long, see Bensoussan (1982) and Bensoussan-Lions (1978) for the early works. More precisely, variational approaches apply to the study of Bellman equation as a parabolic quasi-linear equation, when the nonlinearity affects only the gradient of the solution, and the second order derivative term is linear and not degenerate. This corresponds to a stochastic control problem, where the state equation is a diffusion process. The primary objective of this article is to extend this approach to mean field control theory, as an alternative to the current approach, which considers a coupled system of Hamilton-Jacobi (HJ) and Fokker-Planck (FP) equations, since the introduction of the theory by Lasry-Lions (2007). The main novelty lies in that the equation studied here is the HJB equation, neither the HJ-FP system nor the master equation; and our results also provide another perspective for probabilistic approaches; see Chassagneux-Crisan-Delarue (2022), Bensoussan-Wong-Yam-Yuan (2024), Bensoussan-Tai-Yam (2025) and Bensoussan-Huang-Tang-Yam (2025) for instance. Within the scope of the PDE methods, the advantage of this article is to solve a larger class of mean field control problems, with moderate regularity; and this kind of variational methods fairly require few conditions on the regularity of the coefficients."}
{"id": "2511.22710", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.22710", "abs": "https://arxiv.org/abs/2511.22710", "authors": ["Stéphane Ouvry", "Alexios P. Polychronakos"], "title": "Inclusion Statistics", "comment": "14 pages, 2 figures", "summary": "We present a historical review of anyon and exclusion statistics, introduced in the 1980s and 1990s respectively, and then turn to developments in the recently introduced inclusion statistics. In contrast to exclusion statistics, where particles tend to be more exclusive than usual fermions, inclusion statistics particles tend to be more gregarious than usual bosons and manifest an enhanced propensity to form condensates. Inclusion and exclusion statistics are related through a duality transformation, generalizing the well-known Bose-Fermi duality. We conclude with a review of the Calogero model realization of exclusion statistics and its extension to inclusion statistics."}
{"id": "2511.23371", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.23371", "abs": "https://arxiv.org/abs/2511.23371", "authors": ["Alberto Aleta", "Andreia Sofia Teixeira", "Guilherme Ferraz de Arruda", "Andrea Baronchelli", "Alain Barrat", "János Kertész", "Albert Díaz-Guilera", "Oriol Artime", "Michele Starnini", "Giovanni Petri", "Márton Karsai", "Siddharth Patwardhan", "Alessandro Vespignani", "Yamir Moreno", "Santo Fortunato"], "title": "Multilayer network science: theory, methods, and applications", "comment": null, "summary": "Multilayer network science has emerged as a central framework for analysing interconnected and interdependent complex systems. Its relevance has grown substantially with the increasing availability of rich, heterogeneous data, which makes it possible to uncover and exploit the inherently multilayered organisation of many real-world networks. In this review, we summarise recent developments in the field. On the theoretical and methodological front, we outline core concepts and survey advances in community detection, dynamical processes, temporal networks, higher-order interactions, and machine-learning-based approaches. On the application side, we discuss progress across diverse domains, including interdependent infrastructures, spreading dynamics, computational social science, economic and financial systems, ecological and climate networks, science-of-science studies, network medicine, and network neuroscience. We conclude with a forward-looking perspective, emphasizing the need for standardized datasets and software, deeper integration of temporal and higher-order structures, and a transition toward genuinely predictive models of complex systems."}
{"id": "2511.22720", "categories": ["physics.geo-ph", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.22720", "abs": "https://arxiv.org/abs/2511.22720", "authors": ["Rafat Qubaja", "Murray Moinester", "Joel Kronfeld"], "title": "Disentangling the soil and atmospheric stress on carbon sequestration in a Mediterranean pine forest", "comment": "23 pages, 8 figures, 1 table, drylands forestation, organic and inorganic carbon sequestration,fossil water irrigation", "summary": "Sequestration of atmospheric CO$_2$ in a Mediterranean semi-arid Aleppo Pine Forest (Pinus halepensis) close to the border of the semi-arid timberline was characterized and quantified under field conditions. Measurements of organic and inorganic CO$_2$ sequestration with gas exchange and stock counting approaches were made in both rainfed control (approximately 12$\\%$ average annual soil moisture) and summer irrigated plots (approximately 24$\\%$ annual average soil moisture), providing the opportunity to separate the effects of atmospheric water demand from soil water stress on the atmospheric CO$_2$ sequestration responses. Measurements yield an organic carbon sequestration (OCS) rate of approximately 550 g CO$_2$ m$^{-2}$ yr$^{-1}$, two-thirds in soil and one-third in biomass. In addition, measurements yield an inorganic carbon sequestration (ICS) rate of approximately 216 g CO$_2$ m$^{-2}$ yr$^{-1}$; via calcite (CaCO$_3$) precipitation in the soil due to root exhalation of CO$_2$ (60$\\%$) and microbial activity (40$\\%$). The drip irrigated plot showed approximately 3 times higher organic CO$_2$ sequestration than the control plot. The organic sequestration is divided equally between the soil and the biomass. For the irrigated plot, the inorganic CO$_2$ was approximately 1.8 times higher than that of the control plot. However, for inorganic CO$_2$ sequestration, the soil moisture would need to be maintained lower than that of the study plot to preclude dissolving precipitated calcite. For many drylands, irrigation could be achieved by using fossil water reserves. These measured values demonstrate the relatively high potential carbon sequestration in Mediterranean drylands forests under irrigated and non-irrigated conditions."}
{"id": "2511.22424", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22424", "abs": "https://arxiv.org/abs/2511.22424", "authors": ["Shu Xu", "Liqun Cao"], "title": "Parabolic hysteresis problems revisited: Finite element error analysis and convergent Newton-type solvers", "comment": null, "summary": "Numerical investigations of partial differential equations with hysteresis have largely focused on simulations, leaving numerical error analysis unexplored and relying mainly on derivative-free nonlinear solvers. This work establishes rigorous finite element error estimates for the backward Euler fully discrete scheme applied to semilinear and quasilinear parabolic equations involving continuous hysteresis operators. To efficiently handle the inherent nonsmoothness of the resulting nonlinear algebraic systems, we develop a damped smoothing Newton solver under a general condition on the smoothing approximation, ensuring global convergence together with local Q-quadratic convergence. Numerical experiments confirm the theoretical convergence rates for semilinear problems, while showing higher-than-predicted orders for quasilinear ones. The robustness and efficiency of the proposed solver are further demonstrated in comparison with existing methods."}
{"id": "2511.22223", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22223", "abs": "https://arxiv.org/abs/2511.22223", "authors": ["Keunbaik Lee", "Eun Jin Jang", "Dipak Dey"], "title": "Overall marginalized models for longitudinal zero-inflated count data", "comment": "29 pages", "summary": "To analyze longitudinal zero-inflated count data, we extend existing models by introducing marginalized zero-inflated Poisson (MZIP) models with random effects, which explicitly capture the marginal effect of covariates and address limitations of previous methods. These models provide a clearer interpretation of the overall mean effect of covariates on zero-inflated count data. To further accommodate overdispersion, we develop marginalized zero-inflated negative binomial (MZINB) models. Both models incorporate subject-specific heterogeneity through a flexible random effects covariance structure. Simulation studies are conducted to evaluate the performance of the MZIP and MZINB models, comparing their inference under both homogeneous and heterogeneous random effects. Finally, we illustrate the applicability of the proposed models through an analysis of systemic lupus erythematosus data."}
{"id": "2511.21962", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21962", "abs": "https://arxiv.org/abs/2511.21962", "authors": ["Ingyu Jang", "Leila J. Bridgeman"], "title": "Communication-Aware Dissipative Control for Networks of Heterogeneous Nonlinear Agents", "comment": "Under review for IFAC 2026. 8 pages, 4 figures, 1 table", "summary": "Communication-aware control is essential to reduce costs and complexity in large-scale networks. However, it is challenging to simultaneously determine a sparse communication topology and achieve high performance and robustness. This work achieves all three objectives through dissipativity-based, sparsity-promoting controller synthesis. The approach identifies an optimal sparse structure using either weighted l1 penalties or alternating direction methods of multipliers (ADMM) with a cardinality term, and iteratively solves a convexified version of the NP hard structured optimal control problem. The proposed methods are demonstrated on heterogeneous networks with uncertain and unstable agents."}
{"id": "2511.21962", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21962", "abs": "https://arxiv.org/abs/2511.21962", "authors": ["Ingyu Jang", "Leila J. Bridgeman"], "title": "Communication-Aware Dissipative Control for Networks of Heterogeneous Nonlinear Agents", "comment": "Under review for IFAC 2026. 8 pages, 4 figures, 1 table", "summary": "Communication-aware control is essential to reduce costs and complexity in large-scale networks. However, it is challenging to simultaneously determine a sparse communication topology and achieve high performance and robustness. This work achieves all three objectives through dissipativity-based, sparsity-promoting controller synthesis. The approach identifies an optimal sparse structure using either weighted l1 penalties or alternating direction methods of multipliers (ADMM) with a cardinality term, and iteratively solves a convexified version of the NP hard structured optimal control problem. The proposed methods are demonstrated on heterogeneous networks with uncertain and unstable agents."}
{"id": "2511.22740", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2511.22740", "abs": "https://arxiv.org/abs/2511.22740", "authors": ["Gaurav Harsha", "Selina Dirnbök", "Emanuel Gull", "Vojtěch Vlček", "Dominika Zgid"], "title": "Discovering topological phases in gray-Tin", "comment": "8 pages, 3 figures; SI has 3 pages, 3 figures", "summary": "Non-trivial topological phases often emerge in narrow-gap semiconductors with a delicate blend of spin-orbit coupling and electron correlation. The diamond-lattice allotrope of Sn ($α$-Sn) exemplifies this behavior, hosting multiple topological phases that can be tuned by small distortions in the lattice. Despite rapid experimental progress, theoretical descriptions of $α$-Sn lack predictive power and rely mainly on tight-binding models and density functional theory with uncontrolled approximations. We employ first-principles fully self-consistent, relativistic GW (scGW) to overcome these limitations. The scGW recovers the experimentally observed zero-gap semiconductor and the strain-induced topological insulator and Dirac semimetal phases, while also predicting new trivial and topological insulators and a Dirac semimetal phase, further demonstrating the versatility of $α$-Sn for band engineering. Additionally, we propose a robust diagnostic of topological behavior based on a combined analysis of band and orbital-occupation dispersions, tailored for correlated methods where standard mean-field-based topological invariants fall short. Our findings pave the way for studying a broad class of topological materials using accurate first-principles methods beyond density functional theory."}
{"id": "2511.22927", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.22927", "abs": "https://arxiv.org/abs/2511.22927", "authors": ["Zhiyi Li", "Pengcheng Hou", "Bao-Zong Wang", "Youjin Deng", "Kun Chen"], "title": "Two-Electron Correlations in the Metallic Electron Gas", "comment": "14 pages, 8 figures", "summary": "We present high-precision ab initio calculations of the four-point vertex function for the three-dimensional uniform electron gas using variational diagrammatic Monte Carlo. From these results, we extract Landau parameters that demonstrate a density-driven crossover from underscreening to overscreening. Guided by our numerical data, we propose a charge-based Kukkonen--Overhauser effective interaction within the local-density approximation, supplemented by a small s-wave correction (sKO$^+$), which accurately captures the electron--electron scattering amplitude. Using our numerically determined scattering amplitude, together with the sKO$^+$ ansatz, we compute the electron-electron contribution to the thermal resistivity, demonstrating excellent agreement with experimental measurements in simple metals."}
{"id": "2511.22579", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22579", "abs": "https://arxiv.org/abs/2511.22579", "authors": ["Ziliang Wang", "Han Zhang", "Axel Ringh"], "title": "Consistent inverse optimal control for discrete-time nonlinear stochastic systems", "comment": null, "summary": "Inverse Optimal Control (IOC) seeks to recover an unknown cost from expert demonstrations, and it provides a systematic way of modeling experts' decision mechanisms while considering the prior information of the cost functions. Nevertheless, existing IOC methods have consistency issue with the estimator under noisy and nonlinear settings. In this paper, we consider a discrete-time nonlinear system with process noise, and it is controlled by an optimal policy that minimizes the expectation of a discounted cumulative cost function across an infinite time-horizon. In particular, the cost function takes the form of a linear combination of a priori known feature functions. In this setting, we first adopt Lasserre's reformulation of the forward problem with occupancy measure. Next, we propose the infinite dimensional IOC algorithm and further approximate it with Lagrange interpolating polynomials, which results in a convex, finite-dimensional sum-of-squares optimization. Moreover, the estimator is shown to be asymptotically and statistically consistent. Finally, we validate the theoretical results and illustrate the performance of our method with numerical experiments. In addition, the robustness and generalizability performance of the proposed IOC algorithm are also illustrated."}
{"id": "2511.22966", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.22966", "abs": "https://arxiv.org/abs/2511.22966", "authors": ["Adithya A. Vasista", "Anushka Agrawal", "Tanay Nag"], "title": "Generation of concurrence in a generalized central spin model with a three-spin interacting environment", "comment": "12 pages, 10 figures", "summary": "We consider the three-spin Ising model to study the effect of three-spin interacting term on bi-partitie entanglement between adjacent spins. The three-dominated disordered region has tri-partite entanglement causing a vanishingly small concurrence, while it acquires maximum value around the critical points. Considering the above model as an environment, we construct a generalized central spin model where two central spins, initially in an unentangled pure state, are coupled locally to two distinct sites of the environmental spin chain. We study the generation of mixed state entanglement between the central spins when the transverse field of the environment is kept fixed, and suddenly quenched, referring to equilibrium and non-equilibrium dynamics of the central spins, respectively. For the critical environment in the equilibrium, the concurrence shows a dip-revival structure governed by quasi-particle movement. In the non-equilibrium study, we find an initial growth of concurrence followed by a two-stage fall for the inter-phase quench which is governed by dynamic decoherence channels. The central spins are maximally entangled for a quench in the vicinity of a multicritical point, which arises due to three-spin interaction only. The concurrence becomes long-lived for an intra-phase quench, and this sustainability depends on the strength of the three-spin interaction. Therefore, the three-spin interaction indeed helps in generating bi-partite entanglement in the central spins."}
{"id": "2511.22628", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22628", "abs": "https://arxiv.org/abs/2511.22628", "authors": ["D P Hewett"], "title": "Piecewise polynomial approximation on non-Lipschitz domains", "comment": null, "summary": "We prove best approximation error estimates for discontinuous piecewise polynomial approximation in fractional Sobolev spaces on non-Lipschitz meshes of non-Lipschitz domains. In particular, the boundary of the domain, and the boundaries of the mesh elements, can be fractal."}
{"id": "2511.22274", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22274", "abs": "https://arxiv.org/abs/2511.22274", "authors": ["Chenxiao Dai", "Feiyu Jiang", "Dong Li", "Xiaofeng Shao"], "title": "Diagnostic Checking for Wasserstein Autoregression", "comment": null, "summary": "Wasserstein autoregression provides a robust framework for modeling serial dependence among probability distributions, with wide-ranging applications in economics, finance, and climate science. In this paper, we develop portmanteau-type diagnostic tests for assessing the adequacy of Wasserstein autoregressive models. By defining autocorrelation functions for model errors and residuals in the Wasserstein space, we construct two related tests: one analogous to the classical McLeod type test, and the other based on the sample-splitting approach of Davis and Fernandes(2025). We establish that, under mild regularity conditions, the corresponding test statistics converge in distribution to chi-square limits. Simulation studies and empirical applications demonstrate that the proposed tests effectively detect model mis-specification, offering a principled and reliable diagnostic tool for distributional time series analysis."}
{"id": "2511.22034", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.22034", "abs": "https://arxiv.org/abs/2511.22034", "authors": ["Batin Kurt", "Umut Orguner"], "title": "Performance of the Kalman Filter and Smoother for Benchmark Studies", "comment": null, "summary": "We propose analytical mean square error (MSE) expressions for the Kalman filter (KF) and the Kalman smoother (KS) for benchmark studies, where the true system dynamics are unknown or unavailable to the estimator. In such cases, as in benchmark evaluations for target tracking, the analysis relies on deterministic state trajectories. This setting introduces a model mismatch between the estimator and the system, causing the covariance estimates to no longer reflect the actual estimation errors. To enable accurate performance prediction for fixed state trajectories without relying on computationally intensive Monte Carlo simulations, we derive recursive MSE expressions with linear time complexity. The proposed framework also accounts for measurement model mismatch and provides an efficient tool for performance evaluation in benchmark studies with long trajectories. Simulation results confirm the accuracy and computational efficiency of the proposed method."}
{"id": "2511.22034", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.22034", "abs": "https://arxiv.org/abs/2511.22034", "authors": ["Batin Kurt", "Umut Orguner"], "title": "Performance of the Kalman Filter and Smoother for Benchmark Studies", "comment": null, "summary": "We propose analytical mean square error (MSE) expressions for the Kalman filter (KF) and the Kalman smoother (KS) for benchmark studies, where the true system dynamics are unknown or unavailable to the estimator. In such cases, as in benchmark evaluations for target tracking, the analysis relies on deterministic state trajectories. This setting introduces a model mismatch between the estimator and the system, causing the covariance estimates to no longer reflect the actual estimation errors. To enable accurate performance prediction for fixed state trajectories without relying on computationally intensive Monte Carlo simulations, we derive recursive MSE expressions with linear time complexity. The proposed framework also accounts for measurement model mismatch and provides an efficient tool for performance evaluation in benchmark studies with long trajectories. Simulation results confirm the accuracy and computational efficiency of the proposed method."}
{"id": "2511.22775", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.22775", "abs": "https://arxiv.org/abs/2511.22775", "authors": ["J. Khatua", "Kwang-Yong Choi"], "title": "Frustration and chirality in three-dimensional trillium lattices: Insights and Perspectives", "comment": null, "summary": "Condensed matter physics continues to seek new frustrated quantum materials that not only deepen our understanding of fundamental physical phenomena but also hold promise for transformative technologies. In this review article, we highlight the unique features of chiral spin topology and review the topological phenomena recently identified in trillium lattice compounds. Based on the unique spin states realized in these systems, we explore the potential for realizing various theoretically proposed chiral quantum phases. We examine representative materials including the magnetic insulating compound K2Ni2(SO4)3 and and the intermetallic EuPtSi discussing both experimental findings and theoretical predictions, while outlining several key questions. Finally, we offer a perspective on promising research directions aimed at uncovering novel emergent behavior in chiral trillium lattice-based materials."}
{"id": "2511.23095", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.23095", "abs": "https://arxiv.org/abs/2511.23095", "authors": ["Ashley Melvin", "J. C. Mandal"], "title": "A Path-Conservative Method for a Weakly Compressible Two-Phase Model with Surface Tension", "comment": null, "summary": "When extended to two-phase flows, weakly compressible models lead to a non-conservative system, which precludes its treatment using standard finite volume techniques. In this paper, a novel HLLC-type path-conservative scheme is formulated for the weakly compressible two-phase model. Furthermore, capillary effects are included in the proposed path-conservative scheme, eliminating the need to discretize surface tension terms separately. The first-order path-conservative formulation is combined with a local solution reconstruction technique to obtain high-order spatial accuracy. The solver is tested on several benchmark two-phase flow problems to demonstrate its efficacy."}
{"id": "2511.22613", "categories": ["math.OC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.22613", "abs": "https://arxiv.org/abs/2511.22613", "authors": ["Yan Yang", "Bin Gao", "Ya-xiang Yuan"], "title": "Variational analysis of determinantal varieties", "comment": "71 pages, 6 figures, 2 tables", "summary": "Determinantal varieties -- the sets of bounded-rank matrices or tensors -- have attracted growing interest in low-rank optimization. The tangent cone to low-rank sets is widely studied and underpins a range of geometric methods. The second-order geometry, which encodes curvature information, is more intricate. In this work, we develop a unified framework to derive explicit formulas for both first- and second-order tangent sets to various low-rank sets, including low-rank matrices, tensors, symmetric matrices, and positive semidefinite matrices. The framework also accommodates the intersection of a low-rank set and another set satisfying mild assumptions, thereby yielding a tangent intersection rule. Through the lens of tangent sets, we establish a necessary and sufficient condition under which a nonsmooth problem and its smooth parameterization share equivalent second-order stationary points. Moreover, we exploit tangent sets to characterize optimality conditions for low-rank optimization and prove that verifying second-order optimality is NP-hard. In a separate line of analysis, we investigate variational geometry of the graph of the normal cone to matrix varieties, deriving the explicit Bouligand tangent cone, Fréchet and Mordukhovich normal cones to the graph. These results are further applied to develop optimality conditions for low-rank bilevel programs."}
{"id": "2511.22971", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2511.22971", "abs": "https://arxiv.org/abs/2511.22971", "authors": ["Ali Tozar"], "title": "Robust Universality of Non-Hermitian Anderson Transitions: From Dyson Singularity to Model-Independent Scaling", "comment": "8pages 7figures", "summary": "We investigate the universality of Anderson localization transitions in one-dimensional non-Hermitian systems exhibiting the skin effect. By developing a numerically stable Log-Space Non-Hermitian Scaling (LNS) method, we overcome the severe floating-point overflow issues associated with the exponential growth of transmittance (T ~ exp(2 gamma L)), enabling precision finite-size scaling analysis up to system sizes of L = 1200. We probe the critical behavior across three distinct disorder landscapes: uniform diagonal, binary diagonal, and off-diagonal (random hopping) disorder. While the uniform model exhibits a standard mobility edge, the off-diagonal model reveals a Dyson-like singularity at the band center (E = 0), where the system resists localization even at strong disorder due to sublattice symmetry protection. However, upon symmetry breaking (E != 0), we demonstrate that all considered models, regardless of the disorder distribution (continuous vs. discrete) or Hamiltonian structure (site vs. bond randomness), belong to the same robust universality class. The critical exponents are determined as nu = 1.50 +/- 0.00 and beta ~ 0.65 through unambiguous data collapse, establishing a model-independent description of non-Hermitian localization transitions."}
{"id": "2511.22650", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22650", "abs": "https://arxiv.org/abs/2511.22650", "authors": ["Stanislav Budzinskiy", "Vladimir Kazeev", "Maxim Olshanskii"], "title": "Low-rank cross approximation of function-valued tensors for reduced-order modeling of parametric PDEs", "comment": null, "summary": "The paper considers function-valued tensors, viewed as multidimensional arrays with entries in an abstract Hilbert space. Despite the absence of the algebraic structure of a field, the geometric inner-product structure suffices to introduce the Tucker rank, higher-order SVD, and Tucker-cross decomposition for function-valued tensors. An adaptive cross-approximation algorithm is developed to compute low-rank approximations of such tensors. The framework is motivated by, and applied to, model order reduction of the parameter-to-solution map for a parametric PDE. The resulting reduced-order model can be interpreted as an encoder-decoder scheme with a nonlinear encoder and a multilinear decoder. The performance of the proposed non-intrusive approximation method is demonstrated in numerical examples for two nonlinear parametric PDE systems."}
{"id": "2511.22414", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22414", "abs": "https://arxiv.org/abs/2511.22414", "authors": ["Camille Frévent"], "title": "Investigating new, signature-based, spatial autoregressive models for functional covariates", "comment": null, "summary": "We developed two new alternatives to signature-based, spatial autoregressive models. In a simulation study, we found that the new models performed at least as well as existing approaches but presented shorter computation times. We then used the new models to analyze the premature mortality rate and the mortality rate for people aged 65 and over."}
{"id": "2511.22091", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22091", "abs": "https://arxiv.org/abs/2511.22091", "authors": ["Ji-Hong Li"], "title": "CBF Based Quadratic Program for Trajectory Tracking of Underatuated Marine Vessels", "comment": null, "summary": "By introducing two polar coordinates transformations, the marine vessel's original two-input-three-output second-order tracking model can be reduced to a two-input-two-output feedback form. However, the resulting system does not confirm to the strict-feedback structure, leading to potential singularity when designing the stabilizing function for the virtual input in the recursive controller design. Moreover, the polar coordinate transformation itself inherently introduces singularities. To address these singularity issues, this paper employs a control barrier function (CBF) based approach and formulates the trajectory tracking problem as a quadratic program (QP) solved via a QP optimizer. Numerical simulations are carried out to demonstrate the effectiveness of the proposed method."}
{"id": "2511.22091", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22091", "abs": "https://arxiv.org/abs/2511.22091", "authors": ["Ji-Hong Li"], "title": "CBF Based Quadratic Program for Trajectory Tracking of Underatuated Marine Vessels", "comment": null, "summary": "By introducing two polar coordinates transformations, the marine vessel's original two-input-three-output second-order tracking model can be reduced to a two-input-two-output feedback form. However, the resulting system does not confirm to the strict-feedback structure, leading to potential singularity when designing the stabilizing function for the virtual input in the recursive controller design. Moreover, the polar coordinate transformation itself inherently introduces singularities. To address these singularity issues, this paper employs a control barrier function (CBF) based approach and formulates the trajectory tracking problem as a quadratic program (QP) solved via a QP optimizer. Numerical simulations are carried out to demonstrate the effectiveness of the proposed method."}
{"id": "2511.22801", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.22801", "abs": "https://arxiv.org/abs/2511.22801", "authors": ["Yasuyuki Kato", "Takeshi Hayashida", "Koei Matsumoto", "Tsuyoshi Kimura", "Yukitoshi Motome"], "title": "Electric-field-induced magnetic toroidal moment and nonlinear magnetoelectric effect in antiferromagnetic olivines", "comment": "10 pages, 8 figures", "summary": "Beyond conventional electric and magnetic monopoles, electric and magnetic toroidal monopoles, which are rank-0 multipoles distinguished by opposite parities under spatial inversion and time reversal, can exist in nature. The recent observation of electric-field-induced directional dichroism in antiferromagnetic olivine Co$_2$SiO$_4$ has provided the first concrete example of a magnetic toroidal monopole; however, its microscopic origin remains elusive. Here, we propose a minimal spin model that incorporates magnetoelectric coupling via the $d$-$p$ hybridization mechanism and analyze it within the mean-field approximation. The model qualitatively reproduces the experimentally observed temperature dependence of the dielectric constant and its pronounced sensitivity to the direction of the applied electric field. Furthermore, it elucidates the temperature evolution of the magnetic toroidal monopole and the strong electric-field-direction dependence of the magnetic toroidal moment. Our calculations also predict a second-order nonlinear magnetoelectric response, consistent with the symmetry classification of Co$_2$SiO$_4$ as an altermagnet. Additionally, we demonstrate that the same framework is applicable to other antiferromagnetic olivines with analogous magnetic order, indicating the robustness and generality of the toroidal-type magnetoelectric response in this material family."}
{"id": "2511.22745", "categories": ["math.OC", "cs.DC", "cs.SI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2511.22745", "abs": "https://arxiv.org/abs/2511.22745", "authors": ["Anqi Dong", "Amirhossein Taghvaei", "Tryphon T. Georgiou"], "title": "A lasso-alternative to Dijkstra's algorithm for identifying short paths in networks", "comment": "25 pages, 7 figures", "summary": "We revisit the problem of finding the shortest path between two selected vertices of a graph and formulate this as an $\\ell_1$-regularized regression -- Least Absolute Shrinkage and Selection Operator (lasso). We draw connections between a numerical implementation of this lasso-formulation, using the so-called LARS algorithm, and a more established algorithm known as the bi-directional Dijkstra. Appealing features of our formulation include the applicability of the Alternating Direction of Multiplier Method (ADMM) to the problem to identify short paths, and a relatively efficient update to topological changes."}
{"id": "2511.23060", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.23060", "abs": "https://arxiv.org/abs/2511.23060", "authors": ["Yan V. Fyodorov", "Bertrand Lacroix-A-Chez-Toine", "Pierre Le Doussal"], "title": "Ground state energy fluctuations of pinned elastic manifolds", "comment": "39 pages, 3 figures", "summary": "We describe the atypical fluctuations of the ground state energy of the random elastic manifold, a disordered model defined on a lattice of linear size $L$ with internal dimension $0\\leq d<4$ embedded in a medium of dimension $N\\gg 1$. The ground-state energy results from a competition between confinement, elasticity and disorder. We obtain an exact description of the large deviation rate function with speed $NL^d$ and its different phases, corresponding to different patterns of replica symmetry breaking (RSB). Our results show that the ground-state energy satisfies a central limit theorem and we obtain an explicit expression for the rescaled variance. In the (massless) limit of zero confinement, this variance vanishes for short-range disorder and the ground-state energy displays super-concentration. From our results on the large deviation function, we characterise explicitly the left tail of the distribution of the typical fluctuations of the ground state energy. It displays an exponential tail for a one step RSB pattern while for a full RSB pattern it decays super-exponentially with a non trivial exponent $ξ$ that we compute explicitly."}
{"id": "2511.22684", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22684", "abs": "https://arxiv.org/abs/2511.22684", "authors": ["Moritz Hauck", "Alexei Lozinski"], "title": "A High-Order Localized Orthogonal Decomposition Method for Heterogeneous Stokes Problems", "comment": "33 pages, 5 figures", "summary": "In this paper, we propose a high-order extension of the multiscale method introduced by the authors in [SIAM J. Numer. Anal., 63(4) (2025), pp. 1617--1641] for heterogeneous Stokes problems, while also providing several other improvements, including a better localization strategy and a more precise pressure reconstruction. The proposed method is based on the Localized Orthogonal Decomposition methodology and achieves optimal convergence orders under minimal structural assumptions on the coefficients. A key feature of our approach is the careful design of so-called quantities of interest, defining functionals of the solution whose values the multiscale approximation aims to reproduce exactly. Their selection is particularly delicate in the context of Stokes problems due to potential conflicts arising from the divergence-free constraint. We prove the exponential decay of the problem-adapted basis functions, justifying their localized computation in practical implementations. A rigorous a priori error analysis proves high-order convergence for both velocity and pressure, if the basis supports grow logarithmically with the desired accuracy. Numerical experiments confirm the theoretical findings."}
{"id": "2511.22432", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22432", "abs": "https://arxiv.org/abs/2511.22432", "authors": ["Camille Frévent"], "title": "A signature-based spatial scan statistic for functional data", "comment": null, "summary": "We have developed a new signature-based spatial scan statistic for functional data (SigFSS). This scan statistic can be applied to both univariate and multivariate functional data. In a simulation study, SigFSS almost always performed better than the literature approaches and yielded more precise clusters in geographic terms. Lastly, we used SigFSS to search for spatial clusters of abnormally high or abnormally low mortality rates in mainland France."}
{"id": "2511.22137", "categories": ["eess.SY", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2511.22137", "abs": "https://arxiv.org/abs/2511.22137", "authors": ["Arindom Chakraborty", "Mehedi Hasan", "Amzad Hossain", "Meratun Junnut Anee"], "title": "Smart Traffic Systems: A Comprehensive Review of Recent Advancements, Technologies, and Challenges", "comment": "31 Pages, 8 Figures, 5 Tables", "summary": "With an ever-growing urban population, the need for transportation is increasing at an alarming rate. Thus, the massive increase in the number of vehicles is creating traffic congestion which creates various environmental, societal, and economic problems. To tackle traffic-related issues, several Smart Traffic Systems (STS) have been proposed and implemented. As a result, a comprehensive review of STS has become necessary. The main objective of this paper is to provide an overview and a thorough review of the existing STSs in terms of various technological approaches, traffic detection technologies using different sensors, various networking/communication tools, and their pros and cons. The paper also provides information on major STS services. In addition, challenges related to modern STS are identified. Therefore, the taxonomy of STSs provided in this paper will aid researchers, urban planners, and policymakers to recognize and install the best-suited STSs for their settings."}
{"id": "2511.22137", "categories": ["eess.SY", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2511.22137", "abs": "https://arxiv.org/abs/2511.22137", "authors": ["Arindom Chakraborty", "Mehedi Hasan", "Amzad Hossain", "Meratun Junnut Anee"], "title": "Smart Traffic Systems: A Comprehensive Review of Recent Advancements, Technologies, and Challenges", "comment": "31 Pages, 8 Figures, 5 Tables", "summary": "With an ever-growing urban population, the need for transportation is increasing at an alarming rate. Thus, the massive increase in the number of vehicles is creating traffic congestion which creates various environmental, societal, and economic problems. To tackle traffic-related issues, several Smart Traffic Systems (STS) have been proposed and implemented. As a result, a comprehensive review of STS has become necessary. The main objective of this paper is to provide an overview and a thorough review of the existing STSs in terms of various technological approaches, traffic detection technologies using different sensors, various networking/communication tools, and their pros and cons. The paper also provides information on major STS services. In addition, challenges related to modern STS are identified. Therefore, the taxonomy of STSs provided in this paper will aid researchers, urban planners, and policymakers to recognize and install the best-suited STSs for their settings."}
{"id": "2511.22909", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2511.22909", "abs": "https://arxiv.org/abs/2511.22909", "authors": ["Kohei Yamagami", "Yuichi Yokoyama", "Yuta Sumiya", "Hayaru Shouno", "Tetsuro Nakamura", "Masaichiro Mizumaki"], "title": "Development of ultra-high efficiency soft X-ray angle-resolved photoemission spectroscopy equipped with deep prior-based denoising method", "comment": "8 pages, 5 figures, 1 table", "summary": "Soft X-ray angle resolved photoemission spectroscopy (SX-ARPES) is one of the most powerful spectroscopic techniques to visualize the three-dimensional bulk electronic structure in reciprocal lattice space. Compared with ARPES employing low-energy photon sources, the time burden imposed by a lower photoelectron yield, stemming from the photoionization cross-section, has been a persistent technical challenge. To address this challenge, we have developed a noise removal system by using the deep prior-based method and integrated it into the micro focused SX-ARPES (μSX-ARPES) system at BL25SU in SPring-8. Our implemented system effectively eliminates the grid and spike noise typically present in ARPES data acquired using the voltage Fixed-mode, within about 30 seconds. We demonstrate, through the μSX-ARPES measurements on a single crystal of CeRu2Si2, that data with sufficient statistical accuracy can be obtained in approximately 40 seconds. In addition, we present the potential of high signal-to-noise ratio ARPES measurement, achieving an energy resolution of 51.6 meV at an excitation energy of 708 eV in μSX-ARPES measurements on polycrystalline gold. Our developed system successfully reduces the time burden in SX-ARPES and paves the way for advancements in lower photoelectron yield measurements, such as those requiring higher energy resolution and three-dimensional nonequilibrium measurements."}
{"id": "2511.22753", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22753", "abs": "https://arxiv.org/abs/2511.22753", "authors": ["Anders Rantzer"], "title": "On Minimax Optimal Dual Control for Fully Actuated Systems", "comment": "5 pages", "summary": "A multi-variable adaptive controller is derived as the explicit solution to a minimax dynamic game. The minimizing player selects the control action as a function of past state measurements and inputs. The maximizing player selects disturbances and model parameters for the underlying linear time-invariant dynamics. This leads to a Bellman equation that can be solved explicitly for the case with unitary B-matrix known up to a sign and no input penalty. The minimizing policy is a dual controller that optimizes the tradeoff between exploration and exploitation."}
{"id": "2511.23197", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.23197", "abs": "https://arxiv.org/abs/2511.23197", "authors": ["Miguel Hoyuelos"], "title": "A thermodynamic framework for the thermal conductivity of dense fluids", "comment": null, "summary": "A thermodynamic framework that predicts the thermal conductivity $λ$ of simple fluids beyond the dilute-gas limit is introduced. By generalizing the transition-rate approach of particles on a lattice to conserved quantities in continuous space, an expression for the ratio $λ/λ_{\\rm id}$, with $λ_{\\rm id}$ the dilute-gas-limit value, is derived; it depends solely on equilibrium thermodynamic properties and is therefore directly computable from any equation of state. The resulting formula quantitatively reproduces molecular-dynamics data for hard spheres throughout almost the entire fluid range, and captures the behavior of Lennard-Jones fluids in the supercritical region where thermodynamic fluctuations remain moderate. Comparison with experimental data for argon, reported by other authors, also shows very good agreement. These results provide evidence that transport coefficients of dense fluids can be expressed as their dilute-gas values multiplied by a universal thermodynamic factor."}
{"id": "2511.22790", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.22790", "abs": "https://arxiv.org/abs/2511.22790", "authors": ["Liang Li", "Jun Zhu", "Shanqin Chen", "Yong-Tao Zhang"], "title": "A fifth-order absolutely convergent fixed-point fast sweeping hybrid alternative WENO scheme for steady state of hyperbolic conservation laws", "comment": "29 pages", "summary": "In this paper, we extend the previous work on absolutely convergent fixed-point fast sweeping WENO methods by Li et al. (J. Comput. Phys. 443: 110516, 2021) and design a fifth-order hybrid fast sweeping scheme for solving steady state problems of hyperbolic conservation laws. Unlike many other fast sweeping methods, the explicit property of fixed-point fast sweeping methods provides flexibility to apply the alternative weighted essentially non-oscillatory (AWENO) scheme with unequal-sized substencils as the local solver, which facilitates the usage of arbitrary monotone numerical fluxes. Furthermore, a novel hybrid technique is designed in the local solver to combine the nonlinear AWENO interpolation with the linear scheme for an additional improvement in efficiency of the high-order fast sweeping iterations. Numerical examples show that the developed fixed-point fast sweeping hybrid AWENO method with unequal-sized substencils can achieve absolute convergence (i.e., the residue of the fast sweeping iterations converges to machine zero / round off errors) more easily than the original AWENO method with equal-sized substencils, and is more efficient than the popular third-order total variation diminishing (TVD) Runge-Kutta time-marching approach to converge to steady state solutions."}
{"id": "2511.22500", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22500", "abs": "https://arxiv.org/abs/2511.22500", "authors": ["Yacine Mohamed Idir", "Olivier Orfila", "Patrice Chatellier", "Vincent Judalet"], "title": "Improving Spatio-temporal Gaussian Process Modeling with Vecchia Approximation: A Low-Cost Sensor-Driven Approach to Urban Environmental Monitoring", "comment": null, "summary": "This paper explores Vecchia likelihood approximation for modeling physical phenomena sensed by mobile and fixed low-cost sensors in urban environments. A three-level hierarchical model is proposed to simultaneously accounts for the physical process of interest and measurement errors inherent in low-cost sensors. Several innovative configurations of Vecchia's approximation are investigated, including variations in ordering strategies, distance definitions, and sensor-specific conditioning. These configurations are evaluated for approximating the likelihood of a spatio-temporal Gaussian process, using simulated data based on real mobile sensor trajectories across Nantes, France. Our findings highlight the effectiveness of the min-max distance algorithm for ordering, reaffirming existing literature. Additionally, we demonstrate the utility of a random ordering approach that doesn't require prior definition of a spatio-temporal distance. These two ordering configurations achieved, on average, 102\\% better results in log Kullback-Leibler divergence compared with four other ordering schemes studied. Results are supplemented with Asymptotic Relative Efficiency analysis, offering practical recommendations for optimizing parameter estimation. The proposed model and preferred Vecchia configuration are applied to real-world air quality data collected using mobile and fixed low-cost sensors. This application underscores the model's practical value for pollution mapping and prediction in environmental monitoring. This study advances the use of Vecchia's approximation for addressing computational challenges of Gaussian models in large-scale spatio-temporal datasets from environmental monitoring with low-cost sensor networks."}
{"id": "2511.22160", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22160", "abs": "https://arxiv.org/abs/2511.22160", "authors": ["Dongdong Li", "Jiuxiang Dong"], "title": "Output-Feedback Stabilizing Policy Iteration for Convergence Assurance of Unknown Discrete-Time Systems with Unmeasurable States", "comment": null, "summary": "This note proposes a data-driven output-feedback stabilizing policy iteration for unknown linear discrete-time systems with unmeasurable states. Existing policy iteration methods for optimal control must start from a stabilizing control policy, which is particularly challenging to obtain for unknown systems, especially when states are unavailable. In such cases, it is more difficult to guarantee stability and convergence performance. To address this problem, an output-feedback stabilizing policy iteration framework is developed to learn closed-loop stabilizing control policies while ensuring convergence performance. Specifically, cumulative scalar parameters are introduced to compress the original system to a stable scale. Then, by integrating modified policy iteration with parameter update rules, the system is gradually amplified/restored to the original system while preserving stability such that the stabilizing control policy is obtained. The entire process is driven solely by input-output data. Moreover, a stability analysis is provided for output-feedback. The proposed approach is validated by simulations."}
{"id": "2511.22160", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22160", "abs": "https://arxiv.org/abs/2511.22160", "authors": ["Dongdong Li", "Jiuxiang Dong"], "title": "Output-Feedback Stabilizing Policy Iteration for Convergence Assurance of Unknown Discrete-Time Systems with Unmeasurable States", "comment": null, "summary": "This note proposes a data-driven output-feedback stabilizing policy iteration for unknown linear discrete-time systems with unmeasurable states. Existing policy iteration methods for optimal control must start from a stabilizing control policy, which is particularly challenging to obtain for unknown systems, especially when states are unavailable. In such cases, it is more difficult to guarantee stability and convergence performance. To address this problem, an output-feedback stabilizing policy iteration framework is developed to learn closed-loop stabilizing control policies while ensuring convergence performance. Specifically, cumulative scalar parameters are introduced to compress the original system to a stable scale. Then, by integrating modified policy iteration with parameter update rules, the system is gradually amplified/restored to the original system while preserving stability such that the stabilizing control policy is obtained. The entire process is driven solely by input-output data. Moreover, a stability analysis is provided for output-feedback. The proposed approach is validated by simulations."}
{"id": "2511.22927", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.22927", "abs": "https://arxiv.org/abs/2511.22927", "authors": ["Zhiyi Li", "Pengcheng Hou", "Bao-Zong Wang", "Youjin Deng", "Kun Chen"], "title": "Two-Electron Correlations in the Metallic Electron Gas", "comment": "14 pages, 8 figures", "summary": "We present high-precision ab initio calculations of the four-point vertex function for the three-dimensional uniform electron gas using variational diagrammatic Monte Carlo. From these results, we extract Landau parameters that demonstrate a density-driven crossover from underscreening to overscreening. Guided by our numerical data, we propose a charge-based Kukkonen--Overhauser effective interaction within the local-density approximation, supplemented by a small s-wave correction (sKO$^+$), which accurately captures the electron--electron scattering amplitude. Using our numerically determined scattering amplitude, together with the sKO$^+$ ansatz, we compute the electron-electron contribution to the thermal resistivity, demonstrating excellent agreement with experimental measurements in simple metals."}
{"id": "2511.22758", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22758", "abs": "https://arxiv.org/abs/2511.22758", "authors": ["Anders Rantzer"], "title": "Minimax Optimal Adaptive Control for Systems on Cones", "comment": "3 pages, preprint for the 2025 IEEE Conference on Decision and Control", "summary": "The theory of optimal control on positive cones has recently identified several new problem classes where the Bellman equation can be solved explicitly, in analogy with classical linear quadratic control. In this paper, the idea is extended to minimax adaptive control, yielding exact solutions to instances of the Bellman equation for dual control. In particular, this allows for optimization of the fundamental tradeoff between exploration and exploitation."}
{"id": "2511.23217", "categories": ["cond-mat.stat-mech", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.23217", "abs": "https://arxiv.org/abs/2511.23217", "authors": ["Elisa Vallini", "Laura Foini", "Silvia Pappalardi"], "title": "Refinements of the Eigenstate Thermalization Hypothesis under Local Rotational Invariance via Free Probability", "comment": "30 pages", "summary": "The Eigenstate Thermalization Hypothesis (ETH) was developed as a framework for understanding how the principles of statistical mechanics emerge in the long-time limit of isolated quantum many-body systems. Since then, ETH has shifted the attention towards the study of matrix elements of physical observables in the energy eigenbasis. In this work, we revisit recent developments leading to the formulation of full ETH, a generalization of the original ETH ansatz that accounts for multi-point correlation functions. Using tools from free probability, we explore the implications of local rotational invariance, a property that emerges from the statistical invariance of observables under random basis transformations induced by small perturbations of the Hamiltonian. This approach allows us to make quantitative predictions and derive an analytical characterization of subleading corrections to matrix-element correlations, thereby refining the ETH ansatz. Moreover, our analysis links the statistical properties of matrix elements under random basis changes to the empirical averages over energy windows that are usually considered when dealing with a single instance of the ensemble. We validate our analytical predictions through comparison with numerical simulations in non-integrable Floquet systems."}
{"id": "2511.23015", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.23015", "abs": "https://arxiv.org/abs/2511.23015", "authors": ["Michael Dumbser", "Andrea Thomann", "Maurizio Tavelli", "Walter Boscheri"], "title": "A structure-preserving semi-implicit four-split scheme for continuum mechanics", "comment": null, "summary": "We introduce a novel structure-preserving vertex-staggered semi-implicit four-split discretization of a unified first order hyperbolic formulation of continuum mechanics that is able to describe at the same time fluid and solid materials within the same mathematical model. The governing PDE system goes back to pioneering work of Godunov, Romenski, Peshkov and collaborators. Previous structure-preserving discretizations of this system allowed to respect the curl-free properties of the distortion field and the specific thermal impulse in the absence of source terms and were consistent with the low Mach number limit with respect to the adiabatic sound speed. However, the evolution of the thermal impulse and the distortion field were still discretized explicitly, thus requiring a rather severe CFL stability restriction on the time step based on the shear sound speed and the finite, but potentially large, speed of heat waves. Instead, the new four-split semi-implicit scheme presented in this paper has a material time step restriction only. For this purpose, the governing PDE system is split into four subsystems: i) a convective subsystem, which is the only one that is treated explicitly; ii) a heat subsystem, iii) a subsystem containing momentum, distortion field and specific thermal impulse; iv) a pressure subsystem. The three subsystems ii)-iv) are all discretized implicitly, hence a rather mild CFL restriction based on the velocity of the continuum is imposed. The method is asymptotically consistent with the low Mach number limit and the stiff relaxation limits. Moreover, it maintains an exactly curl-free distortion field and thermal impulse in the case of linear source terms or in their absence. The scheme is benchmarked against classical test cases verifying its theoretical properties."}
{"id": "2511.22518", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22518", "abs": "https://arxiv.org/abs/2511.22518", "authors": ["Xin Lu", "Wanjia Fu", "Hongzi Li", "Haoyang Yu", "Honghao Zhang", "Ke Zhu", "Hanzhong Liu"], "title": "Design-based theory for causal inference", "comment": "in Chinese language", "summary": "Causal inference, as a major research area in statistics and data science, plays a central role across diverse fields such as medicine, economics, education, and the social sciences. Design-based causal inference begins with randomized experiments and emphasizes conducting statistical inference by leveraging the known randomization mechanism, thereby enabling identification and estimation of causal effects under weak model dependence. Grounded in the seminal works of Fisher and Neyman, this paradigm has evolved to include various design strategies, such as stratified randomization and rerandomization, and analytical methods including Fisher randomization tests, Neyman-style asymptotic inference, and regression adjustment. In recent years, with the emergence of complex settings involving high-dimensional data, individual noncompliance, and network interference, design-based causal inference has witnessed remarkable theoretical and methodological advances. This paper provides a systematic review of recent progress in this field, focusing on covariate-balanced randomization designs, design-based statistical inference methods, and their extensions to high-dimensional, noncompliance, and network interference scenarios. It concludes with a comprehensive perspective on future directions for the theoretical development and practical applications of causal inference."}
{"id": "2511.22179", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22179", "abs": "https://arxiv.org/abs/2511.22179", "authors": ["Bo Li", "Xicong Pang", "Guangrui Wei", "Haiwang Zhong", "Grant Ruan", "Zhengmao Li", "Edris Pouresmaeil"], "title": "An Equality Set Projection Approach for TSO-DSO Coordination Dispatch", "comment": null, "summary": "Coordinated optimization dispatch (COD) of transmission system operator (TSO) and distribution system operator (DSO) can effectively ensure system security and efficiency under high-penetration distributed energy resource (DER) integration. Researches of large-scale COD problem can be categorized into iterative approaches that allow DSO to dispatch independently, and non-iterative methods based on projections of feasible regions (FR). However, the iterative methods suffer from low computational convergence and efficiency, while non-iterative methods struggle to solve equivalent projections with high-dimensional FR. To address these issues, this paper proposes a TSO-DSO coordinated dispatch approach based on an accelerated non-iterative Equality Set Projection (ESP) algorithm. First, ESP algorithm is employed to overcome the bottleneck of high-dimensional FR construction. Second, an regularization-based accelerated method is proposed to reduce computational burden when degeneracy occurs. Accelerated ESP algorithm constructs projection of FR via adjacent facet searching. Therefore, it is less sensitive to the increase of vertices and could efficiently construct the projection of high-dimensional FR. Case studies on a polyhedron dataset, IEEE 33-Bus System and T118D10 TSO-DSO system demonstrate the effectiveness and computational efficiency of the proposed COD approach."}
{"id": "2511.22179", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22179", "abs": "https://arxiv.org/abs/2511.22179", "authors": ["Bo Li", "Xicong Pang", "Guangrui Wei", "Haiwang Zhong", "Grant Ruan", "Zhengmao Li", "Edris Pouresmaeil"], "title": "An Equality Set Projection Approach for TSO-DSO Coordination Dispatch", "comment": null, "summary": "Coordinated optimization dispatch (COD) of transmission system operator (TSO) and distribution system operator (DSO) can effectively ensure system security and efficiency under high-penetration distributed energy resource (DER) integration. Researches of large-scale COD problem can be categorized into iterative approaches that allow DSO to dispatch independently, and non-iterative methods based on projections of feasible regions (FR). However, the iterative methods suffer from low computational convergence and efficiency, while non-iterative methods struggle to solve equivalent projections with high-dimensional FR. To address these issues, this paper proposes a TSO-DSO coordinated dispatch approach based on an accelerated non-iterative Equality Set Projection (ESP) algorithm. First, ESP algorithm is employed to overcome the bottleneck of high-dimensional FR construction. Second, an regularization-based accelerated method is proposed to reduce computational burden when degeneracy occurs. Accelerated ESP algorithm constructs projection of FR via adjacent facet searching. Therefore, it is less sensitive to the increase of vertices and could efficiently construct the projection of high-dimensional FR. Case studies on a polyhedron dataset, IEEE 33-Bus System and T118D10 TSO-DSO system demonstrate the effectiveness and computational efficiency of the proposed COD approach."}
{"id": "2511.23084", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2511.23084", "abs": "https://arxiv.org/abs/2511.23084", "authors": ["Yuval Nitzav", "Abigail Dishi", "Himanshu Lohani", "Ittai Sidilkover", "Noam Ophir", "Roni Anna Gofman", "Avior Almoalem", "Ilay Mangel", "Nitzan Ragoler", "Francois Bertran", "Jaime Sánchez-Barriga", "Dmitry Marchenko", "Andrei Varykhalov", "Nicholas Clark Plumb", "Irena Feldman", "Hadas Soifer", "Anna Keselman", "Amit Kanigel"], "title": "Trion gas on the surface of a failed excitonic insulator", "comment": null, "summary": "Trions, three-body bound states composed of an exciton and an additional charge, are typically fragile and require external excitation to form. Here, we report the spontaneous emergence of a stable trion gas at the surface of the layered semiconductor Ta2NiS5, revealed through angle-resolved photoemission spectroscopy. We observe a sharp, highly localized in-gap feature that cannot be explained by conventional band-theory. Instead, we argue that it arises from the formation of negative trions, stabilized by surface-induced band bending and the material's quasi-one-dimensional geometry. Unlike excitons, these trions form without optical pumping and persist at equilibrium, marking a rare example of an interaction-driven surface state in a nominally conventional semiconductor. Our findings establish Ta2NiS5 as a unique platform for exploring many-body physics at surfaces and open new avenues for studying and controlling collective excitations in low-dimensional systems."}
{"id": "2511.22807", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22807", "abs": "https://arxiv.org/abs/2511.22807", "authors": ["Nguyen Hong Duc", "Vu Trung Hieu"], "title": "Deciding lower-boundedness of polynomials", "comment": "19 pages", "summary": "This paper addresses the problem of deciding the lower-boundedness of an arbitrary real polynomial p in n variables."}
{"id": "2511.21715", "categories": ["physics.hist-ph", "cond-mat.stat-mech", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.21715", "abs": "https://arxiv.org/abs/2511.21715", "authors": ["Robert W. Batterman", "James F. Woodward"], "title": "DNNs, Dataset Statistics, and Correlation Functions", "comment": "37 pages, 12 figures", "summary": "This paper argues that dataset structure is important in image recognition tasks (among other tasks). Specifically, we focus on the nature and genesis of correlational structure in the actual datasets upon which DNNs are trained. We argue that DNNs are implementing a widespread methodology in condensed matter physics and materials science that focuses on mesoscale correlation structures that live between fundamental atomic/molecular scales and continuum scales. Specifically, we argue that DNNs that are successful in image classification must be discovering high order correlation functions. It is well-known that DNNs successfully generalize in apparent contravention of standard statistical learning theory. We consider the implications of our discussion for this puzzle."}
{"id": "2511.23037", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.23037", "abs": "https://arxiv.org/abs/2511.23037", "authors": ["Yuanhong Chen", "Federico Pichi", "Zhen Gao", "Gianluigi Rozza"], "title": "Time Extrapolation with Graph Convolutional Autoencoder and Tensor Train Decomposition", "comment": null, "summary": "Graph autoencoders have gained attention in nonlinear reduced-order modeling of parameterized partial differential equations defined on unstructured grids. Despite they provide a geometrically consistent way of treating complex domains, applying such architectures to parameterized dynamical systems for temporal prediction beyond the training data, i.e. the extrapolation regime, is still a challenging task due to the simultaneous need of temporal causality and generalizability in the parametric space. In this work, we explore the integration of graph convolutional autoencoders (GCAs) with tensor train (TT) decomposition and Operator Inference (OpInf) to develop a time-consistent reduced-order model. In particular, high-fidelity snapshots are represented as a combination of parametric, spatial, and temporal cores via TT decomposition, while OpInf is used to learn the evolution of the latter. Moreover, we enhance the generalization performance by developing a multi-fidelity two-stages approach in the framework of Deep Operator Networks (DeepONet), treating the spatial and temporal cores as the trunk networks, and the parametric core as the branch network. Numerical results, including heat-conduction, advection-diffusion and vortex-shedding phenomena, demonstrate great performance in effectively learning the dynamic in the extrapolation regime for complex geometries, also in comparison with state-of-the-art approaches e.g. MeshGraphNets."}
{"id": "2511.22535", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22535", "abs": "https://arxiv.org/abs/2511.22535", "authors": ["Joris Mulder", "Robbie C. M. van Aert"], "title": "Bayes Factor Hypothesis Testing in Meta-Analyses: Practical Advantages and Methodological Considerations", "comment": "63 pages, 10 figures", "summary": "Bayesian hypothesis testing via Bayes factors offers a principled alternative to classical p-value methods in meta-analysis, particularly suited to its cumulative and sequential nature. Unlike p-values, Bayes factors allow for quantifying support both for and against the existence of an effect, facilitate ongoing evidence monitoring, and maintain coherent long-run behavior as additional studies are incorporated. Recent theoretical developments further show how Bayes factors can flexibly control Type I error rates through connections to e-value theory. Despite these advantages, their use remains limited in the meta-analytic literature. This paper provides a critical overview of their theoretical properties, methodological considerations, such as prior sensitivity, and practical advantages for evidence synthesis. Two illustrative applications are provided: one on statistical learning in individuals with language impairments, and another on seroma incidence following post-operative exercise in breast cancer patients. New tools supporting these methods are available in the open-source R package BFpack."}
{"id": "2511.22244", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22244", "abs": "https://arxiv.org/abs/2511.22244", "authors": ["Maoyuan Ma", "Wangyi Guo", "Lei Yang", "Zhanbo Xu", "Xiaohong Guan"], "title": "Joint Scheduling of Workload Demand and Energy Supply in Low-carbon Data Centers with Decision-Dependent Uncertainty Set", "comment": null, "summary": "This paper addresses the joint scheduling problem of stochastic workloads and a hydrogen-enabled distributed energy system in a low-carbon Internet data centers (IDC). Although such workloads can be shifted over temporal and spatial horizons, it poses challenges when they cannot be accurately predicted, resulting in significant efficiency degradation and high operational cost of the energy system. The problem becomes even more difficult when the workload shifting decisions would influence their randomness, which is natural for the IDC workloads. To tackle these issues, we propose a workload classification model based on the decision-dependent uncertainty set, where the spatiotemporal elasticity of different types of random workloads are clearly identified and the decision dependencies are explicitly described as linear constraints. Thus, a mixed integer program is then established for the optimal scheduling of both workload demand and energy supply. To enhance system resilience against high volatility scenarios, a rolling horizon algorithm is developed to ensure nonanticipativity and full-scenario feasibility. Numerical tests demonstrate that the proposed method exhibits effective workload scheduling decisions with dramatic energy operational cost reductions compared to the benchmarks under most of the uncertain scenarios."}
{"id": "2511.22244", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22244", "abs": "https://arxiv.org/abs/2511.22244", "authors": ["Maoyuan Ma", "Wangyi Guo", "Lei Yang", "Zhanbo Xu", "Xiaohong Guan"], "title": "Joint Scheduling of Workload Demand and Energy Supply in Low-carbon Data Centers with Decision-Dependent Uncertainty Set", "comment": null, "summary": "This paper addresses the joint scheduling problem of stochastic workloads and a hydrogen-enabled distributed energy system in a low-carbon Internet data centers (IDC). Although such workloads can be shifted over temporal and spatial horizons, it poses challenges when they cannot be accurately predicted, resulting in significant efficiency degradation and high operational cost of the energy system. The problem becomes even more difficult when the workload shifting decisions would influence their randomness, which is natural for the IDC workloads. To tackle these issues, we propose a workload classification model based on the decision-dependent uncertainty set, where the spatiotemporal elasticity of different types of random workloads are clearly identified and the decision dependencies are explicitly described as linear constraints. Thus, a mixed integer program is then established for the optimal scheduling of both workload demand and energy supply. To enhance system resilience against high volatility scenarios, a rolling horizon algorithm is developed to ensure nonanticipativity and full-scenario feasibility. Numerical tests demonstrate that the proposed method exhibits effective workload scheduling decisions with dramatic energy operational cost reductions compared to the benchmarks under most of the uncertain scenarios."}
{"id": "2511.23181", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.23181", "abs": "https://arxiv.org/abs/2511.23181", "authors": ["Yihan Wu", "Mario Caserta", "Tommaso Chiarotti", "Nicola Marzari"], "title": "Electronic Structure and Dynamical Correlations in Antiferromagnetic BiFeO$_3$", "comment": null, "summary": "We study the electronic structure and dynamical correlations in antiferromagnetic BiFeO$_3$, a prototypical room-temperature multiferroic, using a variety of static and dynamical first-principles methods. Conventional static Hubbard corrections (DFT+$U$, DFT+$U$+$V$) incorrectly predict a deep-valence Fe $3d$ peak (around $-7\\,\\text{eV}$) in antiferromagnetic BiFeO$_3$, in contradiction with hard-X-ray photoemission. We resolve this failure by using a recent generalization of DFT+$U$ to include a frequency-dependent screening -- DFT+$U(ω)$ -- or using a dynamical Hubbard functional (dynH). The screened Coulomb interaction $U(ω)$, computed with spin-polarized RPA and projected onto maximally localized Fe $3d$ Wannier orbitals, is expressed as a sum-over-poles, yielding a self-energy that augments the Kohn--Sham Hamiltonian. This DFT+$U(ω)$ approach predicts a fundamental band gap of $1.53\\,\\text{eV}$, consistent with experiments, and completely eliminates the unphysical deep-valence peak. The resulting simulated HAXPES spectrum reproduces the experimental lineshape with an accuracy matching or exceeding that of far more demanding DFT+DMFT calculations. Our work demonstrates the critical nature of dynamical screening in complex oxides and establishes DFT+$U(ω)$ as a predictive, computationally efficient method for correlated materials."}
{"id": "2511.22838", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22838", "abs": "https://arxiv.org/abs/2511.22838", "authors": ["Pierre Bonami", "Sanjeeb Dash", "Anton Derkach", "Andrea Lodi"], "title": "Cutting Planes for Binarized Integer Programs", "comment": "14 pages, 7 tables", "summary": "We consider integer programming problems with bounded general-integer variables belonging to the general class of network flow problems. For those, we computationally investigate the effect on mixed-integer linear programming (MIP) solvers of the different ways of producing extended formulations that replace a bounded general integer variable by a linear combination of a set of auxiliary binary variables linked by additional linear constraints. We show that MILP solvers perform very differently depending on which extended formulations is used and we interpret that different performance through the lens of cutting planes generation. Finally, we discuss a simple family of mixed-integer rounding inequalities that especially benefit from the reformulation, and we show its benefit within different MIP solvers. This provides methodological and practical guidelines for the use of those extended formulations in MIP and, to the best of our knowledge, this is the first extensive computational analysis of the topic."}
{"id": "2511.21815", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.21815", "abs": "https://arxiv.org/abs/2511.21815", "authors": ["Ramanjit Sohal", "Ruben Verresen"], "title": "Obstruction to Ergodicity from Locality and $U(1)$ Higher Symmetries on the Lattice", "comment": "5+3 pages", "summary": "We argue that the presence of \\emph{any} exact $U(1)$ higher-form symmetry, under mild assumptions, presents a fundamental obstruction to ergodicity under unitary dynamics in lattice systems with local interactions and finite on-site Hilbert space dimension. Focusing on the two-dimensional case, we show that such systems necessarily exhibit Hilbert space fragmentation and explicitly construct Krylov sectors whose number scales exponentially with system size. While these sectors cannot be distinguished by symmetry quantum numbers, we identify the emergent integrals of motion which characterize them. Our symmetry-based approach is insensitive to details of the Hamiltonian and the lattice, providing a systematic explanation for ergodicity-breaking in a range of systems, including quantum link models."}
{"id": "2511.23095", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.23095", "abs": "https://arxiv.org/abs/2511.23095", "authors": ["Ashley Melvin", "J. C. Mandal"], "title": "A Path-Conservative Method for a Weakly Compressible Two-Phase Model with Surface Tension", "comment": null, "summary": "When extended to two-phase flows, weakly compressible models lead to a non-conservative system, which precludes its treatment using standard finite volume techniques. In this paper, a novel HLLC-type path-conservative scheme is formulated for the weakly compressible two-phase model. Furthermore, capillary effects are included in the proposed path-conservative scheme, eliminating the need to discretize surface tension terms separately. The first-order path-conservative formulation is combined with a local solution reconstruction technique to obtain high-order spatial accuracy. The solver is tested on several benchmark two-phase flow problems to demonstrate its efficacy."}
{"id": "2511.22538", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22538", "abs": "https://arxiv.org/abs/2511.22538", "authors": ["Hyotae Kim", "Athanasios Kottas"], "title": "Bayesian Nonparametric Marked Hawkes Processes for Earthquake Modeling", "comment": null, "summary": "The Hawkes process is a versatile stochastic model for point patterns that exhibit self-excitation, that is, the property that an event occurrence increases the rate of occurrence for some period of time in the future. We present a Bayesian nonparametric modeling approach for temporal marked Hawkes processes. Our focus is on point process modeling of earthquake occurrences, where the mark variable is given by earthquake magnitude. We develop a nonparametric prior model for the marked Hawkes process excitation function, using a representation with basis components for the time lag and the mark, and basis weights defined through a gamma process prior. We elaborate the model with a nonparametric prior for time-dependent background intensity functions, thus enabling a fully nonparametric approach to modeling the ground process intensity of marked Hawkes processes. The model construction balances computationally tractable inference with flexible forms for marked Hawkes process functionals, including mark-dependent offspring densities. The posterior simulation method provides full inference, without any approximations to the Hawkes process likelihood. In the context of the application, the modeling approach enables estimation of aftershock densities that vary with the magnitude of the main shock, thus significantly expanding the inferential scope of existing self-exciting point process models for earthquake occurrences. We investigate different aspects of the methodology through study of model properties, and with inference results based on synthetic marked point patterns. The practical utility of modeling magnitude-dependent aftershock dynamics is demonstrated with analysis of earthquakes that occurred in Japan from 1885 through 1980."}
{"id": "2511.22368", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22368", "abs": "https://arxiv.org/abs/2511.22368", "authors": ["Ali Azarbahram", "Shenyu Liu", "Gian Paolo Incremona"], "title": "Distributed Koopman Operator Learning for Perception and Safe Navigation", "comment": null, "summary": "This paper presents a unified and scalable framework for predictive and safe autonomous navigation in dynamic transportation environments by integrating model predictive control (MPC) with distributed Koopman operator learning. High-dimensional sensory data are employed to model and forecast the motion of surrounding dynamic obstacles. A consensus-based distributed Koopman learning algorithm enables multiple computational agents or sensing units to collaboratively estimate the Koopman operator without centralized data aggregation, thereby supporting large-scale and communication-efficient learning across a networked system. The learned operator predicts future spatial densities of obstacles, which are subsequently represented through Gaussian mixture models. Their confidence ellipses are approximated by convex polytopes and embedded as linear constraints in the MPC formulation to guarantee safe and collision-free navigation. The proposed approach not only ensures obstacle avoidance but also scales efficiently with the number of sensing or computational nodes, aligning with cooperative perception principles in intelligent transportation system (ITS) applications. Theoretical convergence guarantees and predictive constraint formulations are established, and extensive simulations demonstrate reliable, safe, and computationally efficient navigation performance in complex environments."}
{"id": "2511.22368", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22368", "abs": "https://arxiv.org/abs/2511.22368", "authors": ["Ali Azarbahram", "Shenyu Liu", "Gian Paolo Incremona"], "title": "Distributed Koopman Operator Learning for Perception and Safe Navigation", "comment": null, "summary": "This paper presents a unified and scalable framework for predictive and safe autonomous navigation in dynamic transportation environments by integrating model predictive control (MPC) with distributed Koopman operator learning. High-dimensional sensory data are employed to model and forecast the motion of surrounding dynamic obstacles. A consensus-based distributed Koopman learning algorithm enables multiple computational agents or sensing units to collaboratively estimate the Koopman operator without centralized data aggregation, thereby supporting large-scale and communication-efficient learning across a networked system. The learned operator predicts future spatial densities of obstacles, which are subsequently represented through Gaussian mixture models. Their confidence ellipses are approximated by convex polytopes and embedded as linear constraints in the MPC formulation to guarantee safe and collision-free navigation. The proposed approach not only ensures obstacle avoidance but also scales efficiently with the number of sensing or computational nodes, aligning with cooperative perception principles in intelligent transportation system (ITS) applications. Theoretical convergence guarantees and predictive constraint formulations are established, and extensive simulations demonstrate reliable, safe, and computationally efficient navigation performance in complex environments."}
{"id": "2511.22678", "categories": ["hep-lat", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.22678", "abs": "https://arxiv.org/abs/2511.22678", "authors": ["Anna Hasenfratz", "Oliver Witzel"], "title": "Symmetric Mass Generation", "comment": "7 pages, 4 figures, Proceedings of The European Physical Society Conference on High Energy Physics (EPS-HEP2025), 7-11 July 2025, Marseille, France", "summary": "In recent years tantalizing signs for a novel phase have been reported that is chirally symmetric but nevertheless exhibits massive bound states. The necessary condition for such a phase, referred to as Symmetric Mass Generation (SMG), is the cancellation of all (continuous and discrete) 't~Hooft anomalies. In 3+1 dimensions this occurs in systems containing a multiple of 16 massless Weyl fermions. SMG was originally discovered in lower dimensional condensed matter systems. We present results investigating four dimensional field theories with gauge group SU(3). Our findings suggest that SU(3) with $N_f=8$ fundamental fermions exhibits an SMG phase not only on the lattice but also in the infinite cutoff continuum limit. If confirmed, SMG could provide a new UV completion of the standard model and give rise to new scenarios for beyond standard model physics."}
{"id": "2511.22916", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.22916", "abs": "https://arxiv.org/abs/2511.22916", "authors": ["Nachuan Xiao", "Shiwei Wang", "Tianyun Tang", "Kim-Chuan Toh"], "title": "A Quadratically Convergent Alternating Projection Method for Nonconvex Sets", "comment": "25 pages", "summary": "In this paper, we consider the feasibility problem, which aims to find a feasible point for the constraint set $\\{x \\in \\mathbb{R}^n: c(x) = 0\\}$ over a possibly non-regular subset $\\mathcal{X} \\subset \\mathbb{R}^n$. Under the constraint nondegeneracy condition, we propose a modified alternating projection method. In our proposed method, based on the concept of projective mapping for $\\mathcal{X}$, we alternate a Newton step for finding an inexact solution within the limiting tangent cone of $\\mathcal{X}$ and a projection to $\\mathcal{X}$. Under mild conditions, we prove the local quadratic convergence of our proposed method. Preliminary numerical experiments demonstrate the high efficiency of our proposed alternating projection method."}
{"id": "2511.21849", "categories": ["cs.SI", "cond-mat.stat-mech", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.21849", "abs": "https://arxiv.org/abs/2511.21849", "authors": ["Majid Saberi", "Samin Aref"], "title": "Evaluating Global Measures of Network Centralization: Axiomatic and Numerical Assessments", "comment": "Peer-reviewed author copy", "summary": "Network centralization, driven by hub nodes, impacts communication efficiency, structural integration, and dynamic processes such as diffusion and synchronization. Although numerous centralization measures exist, a major challenge lies in determining measures that are both theoretically sound and empirically reliable across different network contexts. To resolve this challenge, we normalize 11 measures of network centralization and assess them systematically using an axiomatic framework and numerical simulations. Our axiomatic assessment tests each measure against the six postulates of centralization, ensuring consistency with minimal theoretical requirements. In addition, our numerical assessment examines the behavior of normalized centralization measures over different random graphs. Our results indicate major differences among the measures, despite their common aim of quantifying centralization. Together, our assessments point to the relative suitability of three measures: normalized betweenness centralization, normalized closeness centralization, and normalized degree centralization. Applying these three measures to real-world networks from diverse domains reveals meaningful variation in the organization of the networks with respect to hubs. Normalized betweenness centralization highlights path-based dominance; normalized closeness centralization reflects accessibility and efficiency of reach; and normalized degree centralization captures degree-based hub concentration. When used jointly, the three measures demonstrate the required sensitivity to varying levels of centralization and provide complementary aspects of network centralization that no single measure can offer alone. Our dual evaluation framework clarifies conceptual differences among existing measures and offers practical guidance for selecting reliable centralization metrics."}
{"id": "2511.23153", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.23153", "abs": "https://arxiv.org/abs/2511.23153", "authors": ["Julian Koellermeier", "Michael Redle", "Manuel Torrilhon"], "title": "Moment Approximations to Magnetic Rotating Shallow Flows", "comment": null, "summary": "Originally introduced to describe a transition region in stars, the magnetic rotating shallow water (MRSW) model is now used in many solar physics and geophysical applications. Derived from the 3-D incompressible magnetohydrodynamic system, the shallow nature of these applications motivates depth-averaging of both the velocities and magnetic fields. This is advantageous in terms of computational efficiency -- but at the loss of vertical information, thus limiting the predictive power of the MRSW model. To overcome this problem, we employ higher-order vertical moments, but now in the context of conductive fluids. In doing so, the new approximation maintains non-constant vertical profiles of both the horizontal magnetic fields and horizontal velocities, while still remaining in the simplified 2-D framework corresponding to depth integration. In this work, we extend the derivation of the shallow water moment equations to derive the MRSW moment system of arbitrary order; i.e., we represent the vertical profiles of the velocities -- and now additionally the magnetic fields -- by arbitrary-order polynomial expansions, and close the new expanded 2-D system with evolution equations for these polynomial coefficients, found via Galerkin projection. Through numerical experiments for MRSW moment systems up to third-order, we demonstrate that these moment approximations reduce model error without significantly sacrificing computational efficiency."}
{"id": "2511.22544", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22544", "abs": "https://arxiv.org/abs/2511.22544", "authors": ["Yacine Mohamed Idir", "Olivier Orfila", "Vincent Judalet", "Benoit Sagot", "Patrice Chatellier"], "title": "Mapping Urban Air Quality from Mobile Sensors Using Spatio-Temporal Geostatistics", "comment": null, "summary": "With the advancement of technology and the arrival of miniaturized environmental sensors that offer greater performance, the idea of building mobile network sensing for air quality has quickly emerged to increase our knowledge of air pollution in urban environments. However, with these new techniques, the difficulty of building mathematical models capable of aggregating all these data sources in order to provide precise mapping of air quality arises. In this context, we explore the spatio-temporal geostatistics methods as a solution for such a problem and evaluate three different methods: Simple Kriging (SK) in residuals, Ordinary Kriging (OK), and Kriging with External Drift (KED). On average, geostatistical models showed 26.57% improvement in the Root Mean Squared Error (RMSE) compared to the standard Inverse Distance Weighting (IDW) technique in interpolating scenarios (27.94% for KED, 26.05% for OK, and 25.71% for SK). The results showed less significant scores in extrapolating scenarios (a 12.22% decrease in the RMSE for geostatisical models compared to IDW). We conclude that univariable geostatistics is suitable for interpolating this type of data but is less appropriate for an extrapolation of non-sampled places since it does not create any information."}
{"id": "2511.22502", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22502", "abs": "https://arxiv.org/abs/2511.22502", "authors": ["Pablo Krupa", "Hasna El Hasnaouy", "Mario Zanon", "Alberto Bemporad"], "title": "Learning the MPC objective function from human preferences", "comment": "(6 pages, 6 figures)", "summary": "In Model Predictive Control (MPC), the objective function plays a central role in determining the closed-loop behavior of the system, and must therefore be designed to achieve the desired closed-loop performance. However, in real-world scenarios, its design is often challenging, as it requires balancing complex trade-offs and accurately capturing a performance criterion that may not be easily quantifiable in terms of an objective function. This paper explores preference-based learning as a data-driven approach to constructing an objective function from human preferences over trajectory pairs. We formulate the learning problem as a machine learning classification task to learn a surrogate model that estimates the likelihood of a trajectory being preferred over another. The approach provides a surrogate model that can directly be used as an MPC objective function. Numerical results show that we can learn objective functions that provide closed-loop trajectories that align with the expressed human preferences."}
{"id": "2511.22502", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22502", "abs": "https://arxiv.org/abs/2511.22502", "authors": ["Pablo Krupa", "Hasna El Hasnaouy", "Mario Zanon", "Alberto Bemporad"], "title": "Learning the MPC objective function from human preferences", "comment": "(6 pages, 6 figures)", "summary": "In Model Predictive Control (MPC), the objective function plays a central role in determining the closed-loop behavior of the system, and must therefore be designed to achieve the desired closed-loop performance. However, in real-world scenarios, its design is often challenging, as it requires balancing complex trade-offs and accurately capturing a performance criterion that may not be easily quantifiable in terms of an objective function. This paper explores preference-based learning as a data-driven approach to constructing an objective function from human preferences over trajectory pairs. We formulate the learning problem as a machine learning classification task to learn a surrogate model that estimates the likelihood of a trajectory being preferred over another. The approach provides a surrogate model that can directly be used as an MPC objective function. Numerical results show that we can learn objective functions that provide closed-loop trajectories that align with the expressed human preferences."}
{"id": "2511.23100", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.23100", "abs": "https://arxiv.org/abs/2511.23100", "authors": ["Gennaro Auricchio", "Adelaide Emma Bernardelli", "Paolo Giudici", "Giuseppe Toscani"], "title": "On Rank Graduation Metrics for High Dimensional Ordinal Data", "comment": null, "summary": "Evaluating the reliability of machine learning classifications remains a fundamental challenge in Artificial Intelligence (AI), particularly when the target variable is multidimensional. Classification variables can be expressed by means of a categorical scale which, at best, is ordinal. Because ordinal data lack a natural metric structure in their underlying space, most conventional distance measures aimed at assessing the accuracy of machine learning classifications cannot be directly or meaningfully applied. In this paper, we develop a mathematical framework for comparing ordinal data based on a family of Rank Graduation $(\\mathrm{RGX}_p)$ \\emph{metrics}. We demonstrate that these metrics can quantify the proportion of variability of the response explained by the predictions, in a similar manner as the predictive $R^2$ for continuous response variables. After establishing theoretical connections between the $\\mathrm{RGX}_p$ family and other prominent metrics in AI, we conduct extensive experiments across diverse datasets and learning tasks to evaluate their empirical performance. The results underscore the versatility, interpretability, and robustness of the $\\mathrm{RGX}_p$ metrics as a principled foundation for developing trustworthy and SAFE AI systems."}
{"id": "2511.22349", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.22349", "abs": "https://arxiv.org/abs/2511.22349", "authors": ["Ankita Mazumdar", "Akash Mitra", "Shashi C. L. Srivastava"], "title": "Sunburst quantum Ising battery under periodic delta-kick charging", "comment": null, "summary": "Most quantum batteries studied so far with notable exception of Sachdev-Ye-Kitaev (SYK) batteries are based on integrable models, where superlinear scaling of charging power and hence a quantum advantage can be achieved, but at the cost of unstable stored energy due to integrability. Here, by considering the sunburst quantum Ising battery driven by periodic delta-kicks, we show that in the quantum chaotic regime a quantum advantage is achieved for number of batteries $n_b\\leq 4$, together with excellent stability of energy storage. In the integrable regime optimal energy storage and extraction are possible irrespective of the initial state of the charger. Finally, we show that the observed advantage does not originate from multipartite entanglement within the battery subsystem and is therefore classical in nature."}
{"id": "2511.23266", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.23266", "abs": "https://arxiv.org/abs/2511.23266", "authors": ["Boris D. Andrews", "Patrick E. Farrell"], "title": "Conservative and dissipative discretisations of multi-conservative ODEs and GENERIC systems", "comment": "24 pages, 11 figures", "summary": "Partial differential equations (PDEs) describing thermodynamically isolated systems typically possess conserved quantities (like mass, momentum, and energy) and dissipated quantities (like entropy). Preserving these conservation and dissipation laws on discretisation in time can yield vastly better approximations for the same computational effort, compared to schemes that are not structure-preserving. In this work we present two novel contributions: (i) an arbitrary-order time discretisation for general conservative ordinary differential equations that conserves all known invariants and (ii) an energy-conserving and entropy-dissipating scheme for both ordinary and partial differential equations written in the GENERIC format, a superset of Poisson and gradient-descent systems. In both cases the underlying strategy is the same: the systematic introduction of auxiliary variables, allowing for the replication at the discrete level of the proofs of conservation or dissipation. We illustrate the advantages of our approximations with numerical examples of the Kepler and Kovalevskaya problems, a combustion engine model, and the Benjamin-Bona-Mahony equation."}
{"id": "2511.22618", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22618", "abs": "https://arxiv.org/abs/2511.22618", "authors": ["Leonardo Scandurra", "Pavlos Alexias", "Eugene de Villiers"], "title": "A Framework for Initial Transient Detection and Statistical Assessment of Convergence in CFD Simulations", "comment": null, "summary": "Time series data often contain initial transient periods before reaching a stable state, posing challenges in analysis and interpretation. In this paper, we propose a novel approach to detect and estimate the end of the initial transient in time series data. Our method leverages the reversal mean standard error (RMSE) as a metric for assessing the stability of the data. Additionally, we employ fractional filtering techniques to enhance the detection accuracy by filtering out noise and capturing essential features of the underlying dynamics.\n  Combining with autocorrelation-corrected confidence intervals we provide a robust framework to automate transient detection and convergence assessment. The method ensures statistical rigor by accounting for autocorrelation effects, validated through simulations with varying time steps. Results demonstrate independence from numerical parameters (e.g., time step size, under-relaxation factors), offering a reliable tool for steady-state analysis. The framework is lightweight, generalizable, and mitigates inflated false positives in autocorrelated datasets."}
{"id": "2511.22528", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22528", "abs": "https://arxiv.org/abs/2511.22528", "authors": ["Edward Moroshko", "Weizhe Qin", "Desen Kirli", "Mohammed Qais", "Sotirios Tsaftaris", "Aristides Kiprakis"], "title": "A model predictive control framework with customer-priority tiers for virtual power plant resilience during extreme weather: A UK heatwave case study", "comment": null, "summary": "Due to changes in frequency and intensity of extreme weather events, such as heatwaves and storms, power systems around the globe are having to deal with increased imbalance between demand and supply and additional risk of loss of supply, calling for advanced control strategies that strengthen system resilience. This paper develops a Model Predictive Control (MPC) framework for coordination of Virtual Power Plants (VPPs) that manages photovoltaic (PV) systems, batteries, and loads before, during, and after extreme weather events. A multi-objective mixed-integer quadratically constrained program is solved to enforce customer-priority tiers, serving critical loads first, while minimizing operating cost and PV curtailment under network and device constraints. Simulations on the IEEE 33-bus distribution network with real UK heatwave data show that, under realistic forecast errors and modeling uncertainties, MPC improves resilience by 11-20% relative to traditional full-horizon optimization. These results indicate the practical viability of receding-horizon coordination for resilient, low-carbon VPP operation during extreme weather."}
{"id": "2511.22528", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22528", "abs": "https://arxiv.org/abs/2511.22528", "authors": ["Edward Moroshko", "Weizhe Qin", "Desen Kirli", "Mohammed Qais", "Sotirios Tsaftaris", "Aristides Kiprakis"], "title": "A model predictive control framework with customer-priority tiers for virtual power plant resilience during extreme weather: A UK heatwave case study", "comment": null, "summary": "Due to changes in frequency and intensity of extreme weather events, such as heatwaves and storms, power systems around the globe are having to deal with increased imbalance between demand and supply and additional risk of loss of supply, calling for advanced control strategies that strengthen system resilience. This paper develops a Model Predictive Control (MPC) framework for coordination of Virtual Power Plants (VPPs) that manages photovoltaic (PV) systems, batteries, and loads before, during, and after extreme weather events. A multi-objective mixed-integer quadratically constrained program is solved to enforce customer-priority tiers, serving critical loads first, while minimizing operating cost and PV curtailment under network and device constraints. Simulations on the IEEE 33-bus distribution network with real UK heatwave data show that, under realistic forecast errors and modeling uncertainties, MPC improves resilience by 11-20% relative to traditional full-horizon optimization. These results indicate the practical viability of receding-horizon coordination for resilient, low-carbon VPP operation during extreme weather."}
{"id": "2511.23175", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.23175", "abs": "https://arxiv.org/abs/2511.23175", "authors": ["Ashish Chandra", "Mohit Tawarmalani"], "title": "Minimizing risk measures with applications in network traffic engineering", "comment": null, "summary": "This paper presents a novel two-stage optimization framework designed to model integrated quantile functions, which leads to the formulation of a bilinear optimization problem (P). A specific instance of this framework offers a new approach to minimizing the Value-at-risk (Var) and the Conditional Value-at-risk (CVar), thus providing a broader perspective on risk assessment and optimization. We investigate various convexification techniques to under- and over-estimate the optimal value of (P), resulting in new and tighter lower- and upper-convex estimators for the Var minimization problems. Furthermore, we explore the properties and implications of the bilinear optimization problem (P) in connection to the integrated quantile functions. Finally, to illustrate the practical applications of our approach, we present computational comparisons in the context of real-life network traffic engineering problems, demonstrating the effectiveness of our proposed framework."}
{"id": "2511.22510", "categories": ["physics.comp-ph", "cond-mat.soft", "cond-mat.stat-mech", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.22510", "abs": "https://arxiv.org/abs/2511.22510", "authors": ["Martin Kjøllesdal Johnsrud", "Navdeep Rana"], "title": "Efficient Pseudo-spectral Algorithms for Statistical Field Theories", "comment": null, "summary": "We present stochastic variants of the exponential time differencing schemes for stiff stochastic differential equations. We derive three explicit schemes that offer better stability compared to Euler-Maruyama and Milstein's method, and achieve strong convergence up to order O(h) in the time step h. We combine these schemes with a pseudo-spectral approach to outline efficient algorithms for simulating stochastic field theories with additive noise. To illustrate the effectiveness of this approach, we study several systems in and out of equilibrium, including Model A, Model B, the Kardar-Parisi-Zhang equation, and the Complex Ginzburg-Landau equation. We outline procedures for computing physical observables such as the critical exponents, correlation functions, and dynamic linear response, and provide our implementation as open source code."}
{"id": "2511.23409", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.23409", "abs": "https://arxiv.org/abs/2511.23409", "authors": ["Naseem Abbas", "Vittorio Colao", "Davide Macri", "William Spataro"], "title": "A Multi-Phase Dual-PINN Framework: Soft Boundary-Interior Specialization via Distance-Weighted Priors", "comment": null, "summary": "Physics-informed neural networks (PINNs) often struggle with multi-scale PDEs featuring sharp gradients and nontrivial boundary conditions, as the physics residual and boundary enforcement compete during optimization. We present a dual-network framework that decomposes the solution as $u = u_{\\text{D}} + u_{\\text{B}}$, where $u_{\\text{D}}$ (domain network) captures interior dynamics and $u_{\\text{B}}$ (boundary network) handles near-boundary corrections. Both networks share a unified physics residual while being softly specialized via distance-weighted priors ($w_{\\text{bd}} = \\exp(-d/τ)$) that are cosine-annealed during training. Boundary conditions are enforced through an augmented Lagrangian method, eliminating manual penalty tuning. Training proceeds in two phases: Phase~1 uses uniform collocation to establish network roles and stabilize boundary satisfaction; Phase~2 employs focused sampling (e.g. ring sampling near $\\partialΩ$) with annealed role weights to efficiently resolve localized features. We evaluate our model on four benchmarks, including the 1D Fokker-Planck equation, the Laplace equation, the Poisson equation, and the 1D wave equation. Across Laplace and Poisson benchmarks, our method reduces error by $36-90\\%$, improves boundary satisfaction by $21-88\\%$, and decreases MAE by $2.2-9.3\\times$ relative to a single-network PINN. Ablations isolate contributions of (i)~soft boundary-interior specialization, (ii)~annealed role regularization, and (iii)~the two-phase curriculum. The method is simple to implement, adds minimal computational overhead, and broadly applies to PDEs with sharp solutions and complex boundary data."}
{"id": "2511.22762", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22762", "abs": "https://arxiv.org/abs/2511.22762", "authors": ["Yuchen Hu", "Xiaoyi Wang", "Long Feng"], "title": "High dimensional Mean Test for Temporal Dependent Data", "comment": null, "summary": "This paper proposes a novel test method for high-dimensional mean testing regard for the temporal dependent data. Comparison to existing methods, we establish the asymptotic normality of the test statistic without relying on restrictive assumptions, such as Gaussian distribution or M-dependence. Importantly, our theoretical framework holds potential for extension to other high-dimensional problems involving temporal dependent data. Additionally, our method offers significantly reduced computational complexity, making it more practical for large-scale applications. Simulation studies further demonstrate the computational advantages and performance improvements of our test."}
{"id": "2511.22721", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22721", "abs": "https://arxiv.org/abs/2511.22721", "authors": ["Yukta Pareek", "Khadija Omar Said", "Satadru Dey", "Ashish Ranjan Kumar"], "title": "A Cyber-Physical Systems Framework for Tracking Post Thermal-Runaway Temperature and Smoke Dynamics in Underground Mines", "comment": null, "summary": "Underground mining operations are actively exploring the use of large-format lithium-ion batteries (LIBs) to power their equipment. LIBs have high energy density, long cycle life, and favorable safety record. They also have low noise, heat, and emission footprints. This fosters a conducive workplace environment for underground mining personnel. However, many occurrences of LIB failure have resulted in dangerous situations in underground mines. The combustion products, including toxic emissions, can rapidly travel throughout the mine using the ventilation network. Therefore, it is critical to monitor the temperature and smoke concentration underground at all times to ensure the safety of the miners. High-fidelity models can be developed for specific scenarios of LIB failure, but are computationally prohibitive for large underground mine volumes, complex geometries, and long duration combustion events. To mitigate computation-related issues associated with high-fidelity models, we developed cyber-physical systems (CPS) models to examine temperature and smoke dynamics. The mine supervisory control center, acting as the cyber framework, operates in conjunction with the physical underground mine. The CPS models, trained on high-fidelity computational fluid dynamics (CFD) model data sets, present an exceptional estimate of the evolution of temperature and smoke concentration in the underground mine tunnel. Once implemented, the research results can help mine operators make informed decisions during emergencies."}
{"id": "2511.22721", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22721", "abs": "https://arxiv.org/abs/2511.22721", "authors": ["Yukta Pareek", "Khadija Omar Said", "Satadru Dey", "Ashish Ranjan Kumar"], "title": "A Cyber-Physical Systems Framework for Tracking Post Thermal-Runaway Temperature and Smoke Dynamics in Underground Mines", "comment": null, "summary": "Underground mining operations are actively exploring the use of large-format lithium-ion batteries (LIBs) to power their equipment. LIBs have high energy density, long cycle life, and favorable safety record. They also have low noise, heat, and emission footprints. This fosters a conducive workplace environment for underground mining personnel. However, many occurrences of LIB failure have resulted in dangerous situations in underground mines. The combustion products, including toxic emissions, can rapidly travel throughout the mine using the ventilation network. Therefore, it is critical to monitor the temperature and smoke concentration underground at all times to ensure the safety of the miners. High-fidelity models can be developed for specific scenarios of LIB failure, but are computationally prohibitive for large underground mine volumes, complex geometries, and long duration combustion events. To mitigate computation-related issues associated with high-fidelity models, we developed cyber-physical systems (CPS) models to examine temperature and smoke dynamics. The mine supervisory control center, acting as the cyber framework, operates in conjunction with the physical underground mine. The CPS models, trained on high-fidelity computational fluid dynamics (CFD) model data sets, present an exceptional estimate of the evolution of temperature and smoke concentration in the underground mine tunnel. Once implemented, the research results can help mine operators make informed decisions during emergencies."}
{"id": "2511.23268", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.23268", "abs": "https://arxiv.org/abs/2511.23268", "authors": ["El Mehdi Achour", "Umberto L. Hryniewicz", "Michael Westdickenberg"], "title": "Avoidance of non-strict saddle points by blow-up", "comment": null, "summary": "It is an old idea to use gradient flows or time-discretized variants thereof as methods for solving minimization problems. In some applications, for example in machine learning contexts, it is important to know that for generic initial data, gradient flow trajectories do not get stuck at saddle points. There are classical results concerned with the nondegenerate situation. But if the Hessian of the objective function has a nontrivial kernel at the critical point, then these results are inconclusive. In this paper, we show how relevant information can be extracted by ``blowing up'' the objective function around the non-strict saddle point, i.e., by a suitable nonlinear rescaling that makes the higher order geometry visible. Then the center-stable manifold theorem of dynamical system theory can be applied."}
{"id": "2511.22654", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.22654", "abs": "https://arxiv.org/abs/2511.22654", "authors": ["Keisuke Fujii"], "title": "Out-of-Time-Order Correlator Spectroscopy", "comment": "10 pages, 2 figures", "summary": "Out-of-time-order correlators (OTOCs) are central probes of quantum scrambling, and their generalizations have recently become key primitives for both benchmarking quantum advantage and learning the structure of Hamiltonians. Yet their behavior has lacked a unified algorithmic interpretation. We show that higher-order OTOCs naturally fit within the framework of quantum signal processing (QSP): each $\\mathrm{OTOC}^{(k)}$ measures the $2k$-th Fourier component of the phase distribution associated with the singular values of a spatially resolved truncated propagator. This explains the contrasting sensitivities of time-ordered correlators (TOCs) and higher-order OTOCs to causal-cone structure and to chaotic, integrable, or localized dynamics. Based on this understanding, we further generalize higher-order OTOCs by polynomial transformation of the singular values of the spatially resolved truncated propagator. The resultant signal allows us to construct frequency-selective filters, which we call \\emph{OTOC spectroscopy}. This extends conventional OTOCs into a mode-resolved tool for probing scrambling and spectral structure of quantum many-body dynamics."}
{"id": "2511.23412", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.23412", "abs": "https://arxiv.org/abs/2511.23412", "authors": ["Francesco Patrizi"], "title": "LR B-spline perspective for RM B-splines: construction and effortless refinements", "comment": "19 pages, 8 figures", "summary": "Reachable Minimally supported (RM) B-splines have been recently introduced as a novel B-spline--like basis. They feature local linear independence and admit a fast de Boor--like evaluation algorithm. These properties make them particularly attractive for applications in isogeometric analysis. In this note, we show that automatic mesh refinement procedures can be readily established by observing that RM B-splines are a special case of Locally Refined (LR) B-splines."}
{"id": "2511.22833", "categories": ["stat.ME", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.22833", "abs": "https://arxiv.org/abs/2511.22833", "authors": ["Angus Lewis", "Antonio Parrella", "John Maclean", "Andrew J. Black"], "title": "Gaussian approximations for fast Bayesian inference of partially observed branching processes with applications to epidemiology", "comment": null, "summary": "We consider the problem of inference for the states and parameters of a continuous-time multitype branching process from partially observed time series data. Exact inference for this class of models, typically using sequential Monte Carlo, can be computationally challenging when the populations that are being modelled grow exponentially or the time series is long. Instead, we derive a Gaussian approximation for the transition function of the process that leads to a Kalman filtering algorithm that runs in a time independent of the population sizes. We also develop a hybrid approach for when populations are smaller and the approximation is less applicable. We investigate the performance of our approximation and algorithms to both a simple and a complex epidemic model, finding good adherence to the true posterior distributions in both cases with large computational speed-ups in most cases. We also apply our method to a COVID-19 dataset with time dependent parameters where exact methods are intractable due to the population sizes involved."}
{"id": "2511.22728", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22728", "abs": "https://arxiv.org/abs/2511.22728", "authors": ["Yue Huang", "Dixant B. Sapkota", "Manish K. Singh"], "title": "Optimal Singular Perturbation-based Model Reduction for Heterogeneous Power Systems", "comment": null, "summary": "Power systems are globally experiencing an unprecedented growth in size and complexity due to the advent of nonconventional generation and consumption technologies. To navigate computational complexity, power system dynamic models are often reduced using techniques based on singular perturbation. However, several technical assumptions enabling traditional approaches are being challenged due to the heterogeneous, and often black-box, nature of modern power system component models. This work proposes two singular perturbation approaches that aim to optimally identify fast states that shall be reduced, without prior knowledge about the physical meaning of system states. After presenting a timescale-agnostic formulation for singular perturbation, the first approach uses greedy optimization to sequentially select states to be reduced. The second approach relies on a nonlinear optimization routine allowing state transformations while obtaining an optimally reduced model. Numerical studies on a test system featuring synchronous machines, inverters, and line dynamics demonstrate the generalizability and accuracy of the developed approaches."}
{"id": "2511.22728", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22728", "abs": "https://arxiv.org/abs/2511.22728", "authors": ["Yue Huang", "Dixant B. Sapkota", "Manish K. Singh"], "title": "Optimal Singular Perturbation-based Model Reduction for Heterogeneous Power Systems", "comment": null, "summary": "Power systems are globally experiencing an unprecedented growth in size and complexity due to the advent of nonconventional generation and consumption technologies. To navigate computational complexity, power system dynamic models are often reduced using techniques based on singular perturbation. However, several technical assumptions enabling traditional approaches are being challenged due to the heterogeneous, and often black-box, nature of modern power system component models. This work proposes two singular perturbation approaches that aim to optimally identify fast states that shall be reduced, without prior knowledge about the physical meaning of system states. After presenting a timescale-agnostic formulation for singular perturbation, the first approach uses greedy optimization to sequentially select states to be reduced. The second approach relies on a nonlinear optimization routine allowing state transformations while obtaining an optimally reduced model. Numerical studies on a test system featuring synchronous machines, inverters, and line dynamics demonstrate the generalizability and accuracy of the developed approaches."}
{"id": "2511.23336", "categories": ["math.OC", "math.AP", "math.FA"], "pdf": "https://arxiv.org/pdf/2511.23336", "abs": "https://arxiv.org/abs/2511.23336", "authors": ["Marco Roschkowski", "Hannes Gernandt"], "title": "Two energy methods for distributed port-Hamiltonian systems and their application to stability analysis", "comment": null, "summary": "We develop two local energy methods for distributed parameter port-Hamiltonian (pH) systems on one-dimensional spatial domains. The methods are applied to derive a characterization of exponential stability directly in terms of the energy passing through the boundary over a given time horizon. The resulting condition is verified for a network of vibrating strings where existing sufficient conditions cannot be applied. Moreover, we use a local energy method to study the short-time behavior of pH systems with boundary damping which was recently studied in the context of hypocoercivity."}
{"id": "2511.23398", "categories": ["quant-ph", "cond-mat.stat-mech", "math-ph", "nlin.CG"], "pdf": "https://arxiv.org/pdf/2511.23398", "abs": "https://arxiv.org/abs/2511.23398", "authors": ["Lorenzo Siro Trezzini", "Andrea Pizzamiglio", "Alessandro Bisio", "Paolo Perinotti"], "title": "Renormalisation of Fermionic Cellular Automata", "comment": "16 + 12 pages, 4 figures", "summary": "We present an exact renormalisation scheme for fermionic cellular automata on hypercubic lattices. By grouping neighbouring cells into tiles and selecting subspaces within them, multiple evolution steps on the original system correspond to a single step of an effective automaton acting on the subspaces. We derive a necessary and sufficient condition for renormalisability and fully characterise the renormalisation flow for two-cell tiles and two time steps of nearest-neighbour fermionic automata on a chain of spinless modes, identifying all fixed points."}
{"id": "2511.21856", "categories": ["physics.ao-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.21856", "abs": "https://arxiv.org/abs/2511.21856", "authors": ["Md Meftahul Ferdaus", "Nathan Alton Cooper", "Austin B. Schmidt", "Pujan Pokhrel", "Elias Ioup", "Mahdi Abdelguerfi", "Julian Simeonov"], "title": "A Comprehensive Review of Phase-Averaged and Phase-Resolving Wave Models for Coastal Modeling Applications", "comment": "Paper submitted to Elsevier", "summary": "Predicting ocean wave behavior is challenging due to the difficulty in choosing suitable numerical models among many with varying capabilities. This review examines the development and performance of numerical wave models in coastal engineering and oceanography, focusing on the difference between phase-averaged spectral models and phase-resolving models. We evaluate the formulation, governing equations, and methods of widely used third-generation phase-averaged spectral models (SWAN, WAVEWATCH III, MIKE 21 SW, TOMAWAC, and WAM) alongside advanced phase-resolving models (FUNWAVE, SWASH, COULWAVE, and NHWAVE) that employ Boussinesq-type equations and non-hydrostatic formulations. The review begins with early parameterized models and progresses to contemporary third-generation models, which solve the wave action conservation equation with few spectral constraints. A comparison of the models' efficiency, accuracy in nearshore conditions, ability to resolve nonlinear wave-wave interaction, simulate wave breaking, diffraction, and wave-current interactions is provided. Applications in operational forecasting, extreme event simulation, coastal structure design, and assessing climate change impacts are discussed. The validation of these models and the statistical metrics and intercomparison studies used are addressed. A discussion of the limitations in computational scalability, physics parameterization, and model coupling is provided, along with emerging trends in high-resolution modeling and hybrid models. This review guides researchers in evaluating which models to use in coastal and oceanographic research."}
{"id": "2511.22868", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22868", "abs": "https://arxiv.org/abs/2511.22868", "authors": ["Yue Ma", "Oksana A. Chkrebtii", "Stephen R. Niezgoda"], "title": "Constrained Gaussian Random Fields with Continuous Linear Boundary Restrictions for Physics-informed Modeling of States", "comment": null, "summary": "Boundary constraints in physical, environmental and engineering models restrict smooth states such as temperature to follow known physical laws at the edges of their spatio-temporal domain. Examples include fixed-state or fixed-derivative (insulated) boundary conditions, and constraints that relate the state and the derivatives, such as in models of heat transfer. Despite their flexibility as prior models over system states, Gaussian random fields do not in general enable exact enforcement of such constraints. This work develops a new general framework for constructing linearly boundary-constrained Gaussian random fields from unconstrained Gaussian random fields over multi-dimensional, convex domains. This new class of models provides flexible priors for modeling smooth states with known physical mechanisms acting at the domain boundaries. Simulation studies illustrate how such physics-informed probability models yield improved predictive performance and more realistic uncertainty quantification in applications including probabilistic numerics, data-driven discovery of dynamical systems, and boundary-constrained state estimation, as compared to unconstrained alternatives."}
{"id": "2511.22810", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.22810", "abs": "https://arxiv.org/abs/2511.22810", "authors": ["Dongjae Lee", "Dimos V. Dimarogonas", "H. Jin Kim"], "title": "Switching control of underactuated multi-channel systems with input constraints for cooperative manipulation", "comment": "14 pages", "summary": "This work presents an event-triggered switching control framework for a class of nonlinear underactuated multi-channel systems with input constraints. These systems are inspired by cooperative manipulation tasks involving underactuation, where multiple underactuated agents collaboratively push or pull an object to a target pose. Unlike existing approaches for multi-channel systems, our method addresses underactuation and the potential loss of controllability by additionally addressing channel assignment of agents. To simultaneously account for channel assignment, input constraints, and stabilization, we formulate the control problem as a Mixed Integer Linear Programming and derive sufficient conditions for its feasibility. To improve real-time computation efficiency, we introduce an event-triggered control scheme that maintains stability even between switching events through a quadratic programming-based stabilizing controller. We theoretically establish the semi-global exponential stability of the proposed method and the asymptotic stability of its extension to nonprehensile cooperative manipulation under noninstantaneous switching. The proposed framework is further validated through numerical simulations on 2D and 3D free-flyer systems and multi-robot nonprehensile pushing tasks."}
{"id": "2511.22810", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.22810", "abs": "https://arxiv.org/abs/2511.22810", "authors": ["Dongjae Lee", "Dimos V. Dimarogonas", "H. Jin Kim"], "title": "Switching control of underactuated multi-channel systems with input constraints for cooperative manipulation", "comment": "14 pages", "summary": "This work presents an event-triggered switching control framework for a class of nonlinear underactuated multi-channel systems with input constraints. These systems are inspired by cooperative manipulation tasks involving underactuation, where multiple underactuated agents collaboratively push or pull an object to a target pose. Unlike existing approaches for multi-channel systems, our method addresses underactuation and the potential loss of controllability by additionally addressing channel assignment of agents. To simultaneously account for channel assignment, input constraints, and stabilization, we formulate the control problem as a Mixed Integer Linear Programming and derive sufficient conditions for its feasibility. To improve real-time computation efficiency, we introduce an event-triggered control scheme that maintains stability even between switching events through a quadratic programming-based stabilizing controller. We theoretically establish the semi-global exponential stability of the proposed method and the asymptotic stability of its extension to nonprehensile cooperative manipulation under noninstantaneous switching. The proposed framework is further validated through numerical simulations on 2D and 3D free-flyer systems and multi-robot nonprehensile pushing tasks."}
{"id": "2511.21962", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.21962", "abs": "https://arxiv.org/abs/2511.21962", "authors": ["Ingyu Jang", "Leila J. Bridgeman"], "title": "Communication-Aware Dissipative Control for Networks of Heterogeneous Nonlinear Agents", "comment": "Under review for IFAC 2026. 8 pages, 4 figures, 1 table", "summary": "Communication-aware control is essential to reduce costs and complexity in large-scale networks. However, it is challenging to simultaneously determine a sparse communication topology and achieve high performance and robustness. This work achieves all three objectives through dissipativity-based, sparsity-promoting controller synthesis. The approach identifies an optimal sparse structure using either weighted l1 penalties or alternating direction methods of multipliers (ADMM) with a cardinality term, and iteratively solves a convexified version of the NP hard structured optimal control problem. The proposed methods are demonstrated on heterogeneous networks with uncertain and unstable agents."}
{"id": "2511.22510", "categories": ["physics.comp-ph", "cond-mat.soft", "cond-mat.stat-mech", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.22510", "abs": "https://arxiv.org/abs/2511.22510", "authors": ["Martin Kjøllesdal Johnsrud", "Navdeep Rana"], "title": "Efficient Pseudo-spectral Algorithms for Statistical Field Theories", "comment": null, "summary": "We present stochastic variants of the exponential time differencing schemes for stiff stochastic differential equations. We derive three explicit schemes that offer better stability compared to Euler-Maruyama and Milstein's method, and achieve strong convergence up to order O(h) in the time step h. We combine these schemes with a pseudo-spectral approach to outline efficient algorithms for simulating stochastic field theories with additive noise. To illustrate the effectiveness of this approach, we study several systems in and out of equilibrium, including Model A, Model B, the Kardar-Parisi-Zhang equation, and the Complex Ginzburg-Landau equation. We outline procedures for computing physical observables such as the critical exponents, correlation functions, and dynamic linear response, and provide our implementation as open source code."}
{"id": "2511.23010", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23010", "abs": "https://arxiv.org/abs/2511.23010", "authors": ["Shoji Toyota", "Yuto Miyatake"], "title": "Joint Bayesian Inference of Parameter and Discretization Error Uncertainties in ODE Models", "comment": "31 pages, submitted for a publication", "summary": "We address the problem of Bayesian inference for parameters in ordinary differential equation (ODE) models based on observational data. Conventional approaches in this setting typically rely on numerical solvers such as the Euler or Runge-Kutta methods. However, these methods generally do not account for the discretization error induced by discretizing the ODE model. We propose a Bayesian inference framework for ODE models that explicitly quantifies discretization errors. Our method models discretization error as a random variable and performs Bayesian inference on both ODE parameters and variances of the randomized discretization errors, referred to as the discretization error variance. A key idea of our approach is the introduction of a Markov prior on the temporal evolution of the discretization error variances, enabling the inference problem to be formulated as a state-space model. Furthermore, we propose a specific form of the Markov prior that arises naturally from standard discretization error analysis. This prior depends on the step size in the numerical solver, and we discuss its asymptotic property in the limit as the step size approaches zero. Numerical experiments illustrate that the proposed method can simultaneously quantify uncertainties in both the ODE parameters and the discretization errors, and can produce posterior distributions over the parameters with broader support by accounting for discretization error."}
{"id": "2511.22836", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22836", "abs": "https://arxiv.org/abs/2511.22836", "authors": ["Yibo Ding", "Wenzhuo Shi", "Mengzhao Duan", "Yuhong Zhao", "Jiaqi Ruan", "Jian Zhao", "Zhao Xu"], "title": "Power System Robust State Estimation As a Layer: A Novel End-to-end Learning Approach", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Serving as an essential prerequisite for modern power system operation, robust state estimation (RSE) could effectively resist noises and outliers in measurements. The emerging neural network (NN) based end-to-end (E2E) learning framework enables real-time application of RSE but cannot strictly enforce the physical constraints involved, potentially yielding solutions that are statistically accurate yet physically inconsistent. To bridge this gap, this work proposes a novel E2E learning based RSE framework, where the RSE problem is innovatively constructed as an explicit differentiable layer of NN for the first time, ensuring physics alignments with rigors. Also, the measurement weights are treated as learnable parameters of NN to enhance estimation robustness. A hybrid loss function is formulated to pursue accurate and physically consistent solutions. To realize the proposed NN structure, the original non-convex RSE problem is specially relaxed. Extensive numerical simulations have been carried out to demonstrate that the proposed framework can significantly improve the SE performance while fulfilling physical consistency on six testing systems, in comparisons to the classical E2E learning based approach and the physics-informed neural network (PINN) approach."}
{"id": "2511.22836", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22836", "abs": "https://arxiv.org/abs/2511.22836", "authors": ["Yibo Ding", "Wenzhuo Shi", "Mengzhao Duan", "Yuhong Zhao", "Jiaqi Ruan", "Jian Zhao", "Zhao Xu"], "title": "Power System Robust State Estimation As a Layer: A Novel End-to-end Learning Approach", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Serving as an essential prerequisite for modern power system operation, robust state estimation (RSE) could effectively resist noises and outliers in measurements. The emerging neural network (NN) based end-to-end (E2E) learning framework enables real-time application of RSE but cannot strictly enforce the physical constraints involved, potentially yielding solutions that are statistically accurate yet physically inconsistent. To bridge this gap, this work proposes a novel E2E learning based RSE framework, where the RSE problem is innovatively constructed as an explicit differentiable layer of NN for the first time, ensuring physics alignments with rigors. Also, the measurement weights are treated as learnable parameters of NN to enhance estimation robustness. A hybrid loss function is formulated to pursue accurate and physically consistent solutions. To realize the proposed NN structure, the original non-convex RSE problem is specially relaxed. Extensive numerical simulations have been carried out to demonstrate that the proposed framework can significantly improve the SE performance while fulfilling physical consistency on six testing systems, in comparisons to the classical E2E learning based approach and the physics-informed neural network (PINN) approach."}
{"id": "2511.23022", "categories": ["eess.SY", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.23022", "abs": "https://arxiv.org/abs/2511.23022", "authors": ["Shubham Sawarkar", "Pushpak Jagtap"], "title": "Control Barrier Function for Unknown Systems: An Approximation-free Approach", "comment": null, "summary": "We study the prescribed-time reach-avoid (PT-RA) control problem for nonlinear systems with unknown dynamics operating in environments with moving obstacles. Unlike robust or learning based Control Barrier Function (CBF) methods, the proposed framework requires neither online model learning nor uncertainty bound estimation. A CBF-based Quadratic Program (CBF-QP) is solved on a simple virtual system to generate a safe reference satisfying PT-RA conditions with respect to time-varying, tightened obstacle and goal sets. The true system is confined to a Virtual Confinement Zone (VCZ) around this reference using an approximation-free feedback law. This construction guarantees real-time safety and prescribed-time target reachability under unknown dynamics and dynamic constraints without explicit model identification or offline precomputation. Simulation results illustrate reliable dynamic obstacle avoidance and timely convergence to the target set."}
{"id": "2511.23085", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23085", "abs": "https://arxiv.org/abs/2511.23085", "authors": ["Yongseok Hur", "Joonhyuk Jung", "Juhee Lee"], "title": "A General Bayesian Nonparametric Approach for Estimating Population-Level and Conditional Causal Effects", "comment": "Short headings : Causal Logistic Stick-Breaking Process / 26 pages / 11 figures", "summary": "We propose a Bayesian nonparametric (BNP) approach to causal inference using observational data consisting of outcome, treatment, and a set of confounders. The conditional distribution of the outcome given treatment and confounders is modeled flexibly using a dependent nonparametric mixture model, in which both the atoms and the weights vary with the confounders. The proposed BNP model is well suited for causal inference problems, as it does not rely on parametric assumptions about how the conditional distribution depends on the confounders. In particular, the model effectively adjusts for confounding and improves the modeling of treatment effect heterogeneity, leading to more accurate estimation of both the average treatment effect (ATE) and heterogeneous treatment effects (HTE). Posterior inference under the proposed model is computationally efficient due to the use of data augmentation. Extensive evaluations demonstrate that the proposed model offers competitive or superior performance compared to a wide range of recent methods spanning various statistical approaches, including Bayesian additive regression tree (BART) models, which are well known for their strong empirical performance. More importantly, the model provides fully probabilistic inference on quantities of interest that other methods cannot easily provide, using their posterior distributions."}
{"id": "2511.22893", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22893", "abs": "https://arxiv.org/abs/2511.22893", "authors": ["Sebastián Espinel-Ríos"], "title": "Switching-time bioprocess control with pulse-width-modulated optogenetics", "comment": "Submitted conference paper", "summary": "Biotechnology can benefit from dynamic control to improve production efficiency. In this context, optogenetics enables modulation of gene expression using light as an external input, allowing fine-tuning of protein levels to unlock dynamic metabolic control and regulation of cell growth. Optogenetic systems can be actuated by light intensity. However, relying solely on intensity-driven control (i.e., signal amplitude) may fail to properly tune optogenetic bioprocesses when the dose-response relationship (i.e., light intensity versus gene-expression strength) is steep. In these cases, tunability is effectively constrained to either fully active or fully repressed gene expression, with little intermediate regulation. Pulse-width modulation, a concept widely used in electronics, can alleviate this issue by alternating between fully ON and OFF light intensity within forcing periods, thereby smoothing the average response and enhancing process controllability. Naturally, optimizing pulse-width-modulated optogenetics entails a switching-time optimal control problem with a binary input over many forcing periods. While this can be formulated as a mixed-integer program on a refined time grid, the number of decision variables can grow rapidly with increasing time-grid resolution and number of forcing periods, compromising tractability. Here, we propose an alternative solution based on reinforcement learning. We parametrize control actions via the duty cycle, a continuous variable that encodes the ON-to-OFF switching time within each forcing period, thereby respecting the intrinsic binary nature of the light intensity."}
{"id": "2511.22893", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.22893", "abs": "https://arxiv.org/abs/2511.22893", "authors": ["Sebastián Espinel-Ríos"], "title": "Switching-time bioprocess control with pulse-width-modulated optogenetics", "comment": "Submitted conference paper", "summary": "Biotechnology can benefit from dynamic control to improve production efficiency. In this context, optogenetics enables modulation of gene expression using light as an external input, allowing fine-tuning of protein levels to unlock dynamic metabolic control and regulation of cell growth. Optogenetic systems can be actuated by light intensity. However, relying solely on intensity-driven control (i.e., signal amplitude) may fail to properly tune optogenetic bioprocesses when the dose-response relationship (i.e., light intensity versus gene-expression strength) is steep. In these cases, tunability is effectively constrained to either fully active or fully repressed gene expression, with little intermediate regulation. Pulse-width modulation, a concept widely used in electronics, can alleviate this issue by alternating between fully ON and OFF light intensity within forcing periods, thereby smoothing the average response and enhancing process controllability. Naturally, optimizing pulse-width-modulated optogenetics entails a switching-time optimal control problem with a binary input over many forcing periods. While this can be formulated as a mixed-integer program on a refined time grid, the number of decision variables can grow rapidly with increasing time-grid resolution and number of forcing periods, compromising tractability. Here, we propose an alternative solution based on reinforcement learning. We parametrize control actions via the duty cycle, a continuous variable that encodes the ON-to-OFF switching time within each forcing period, thereby respecting the intrinsic binary nature of the light intensity."}
{"id": "2511.23086", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23086", "abs": "https://arxiv.org/abs/2511.23086", "authors": ["Srijan Chattopadhyay", "Siddhaarth Sarkar", "Arun Kumar Kuchibhotla"], "title": "Inference for quantile-parametrized families via CDF confidence bands", "comment": "29 pages total: 5 pages appendix, 3 pages references, 21 pages main content. 14 figures", "summary": "Quantile-based distribution families are an important subclass of parametric families, capable of exhibiting a wide range of behaviors using very few parameters. These parametric models present significant challenges for classical methods, since the CDF and density do not have a closed-form expression. Furthermore, approximate maximum likelihood estimation and related procedures may yield non-$\\sqrt{n}$ and non-normal asymptotics over regions of the parameter space, making bootstrap and resampling techniques unreliable. We develop a novel inference framework that constructs confidence sets by inverting distribution-free confidence bands for the empirical CDF through the known quantile function. Our proposed inference procedure provides a principled and assumption-lean alternative in this setting, requiring no distributional assumptions beyond the parametric model specification and avoiding the computational and theoretical difficulties associated with likelihood-based methods for these complex parametric families. We demonstrate our framework on Tukey Lambda and generalized Lambda distributions, evaluate its performance through simulation studies, and illustrate its practical utility with an application to both a small-sample dataset (Twin Study) and a large-sample dataset (Spanish household incomes)."}
{"id": "2511.22919", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22919", "abs": "https://arxiv.org/abs/2511.22919", "authors": ["Kai-Yuan Guo", "Yan-Wu Wang", "Xiao-Kang Liu", "Zhi-Wei Liu"], "title": "Fast Distributed Algorithm for Aggregative Games in Malicious Environment", "comment": null, "summary": "This paper addresses the distributed Nash Equilibrium seeking problem for aggregative games, where legitimate players' decisions are affected by potential malicious players. To describe players' behavior, we introduce a novel heterogeneous trustworthiness probabilistic framework by employing stochastic trust observations. To mitigate the waste of communication and gradient computation, we utilize a compressible unbalanced network information matrix and a multi-round communication mechanism to develop a fast Nash equilibrium seeking algorithm for aggregative games with unbalanced directed networks. By integrating the multi-round communication mechanism and a trustworthiness broadcast mechanism, we embed our fast convergence algorithm into the heterogeneous trustworthiness probabilistic framework, yielding a resilient fast Nash equilibrium seeking algorithm. Theoretical analysis confirms the convergence of the algorithm. Comparative simulations verify the accuracy of our fast convergence algorithm, and validation simulations verify the resilience of the algorithm."}
{"id": "2511.22919", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22919", "abs": "https://arxiv.org/abs/2511.22919", "authors": ["Kai-Yuan Guo", "Yan-Wu Wang", "Xiao-Kang Liu", "Zhi-Wei Liu"], "title": "Fast Distributed Algorithm for Aggregative Games in Malicious Environment", "comment": null, "summary": "This paper addresses the distributed Nash Equilibrium seeking problem for aggregative games, where legitimate players' decisions are affected by potential malicious players. To describe players' behavior, we introduce a novel heterogeneous trustworthiness probabilistic framework by employing stochastic trust observations. To mitigate the waste of communication and gradient computation, we utilize a compressible unbalanced network information matrix and a multi-round communication mechanism to develop a fast Nash equilibrium seeking algorithm for aggregative games with unbalanced directed networks. By integrating the multi-round communication mechanism and a trustworthiness broadcast mechanism, we embed our fast convergence algorithm into the heterogeneous trustworthiness probabilistic framework, yielding a resilient fast Nash equilibrium seeking algorithm. Theoretical analysis confirms the convergence of the algorithm. Comparative simulations verify the accuracy of our fast convergence algorithm, and validation simulations verify the resilience of the algorithm."}
{"id": "2511.23118", "categories": ["stat.ME", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.23118", "abs": "https://arxiv.org/abs/2511.23118", "authors": ["Stefaniya Kozhevnikova", "Denis Yukhnenko", "Giulio Scola", "Seena Fazel"], "title": "Machine learning for violence prediction: a systematic review and critical appraisal", "comment": null, "summary": "Purpose To conduct a systematic review of machine learning models for predicting violent behaviour by synthesising and appraising their validity, usefulness, and performance.\n  Methods We systematically searched nine bibliographic databases and Google Scholar up to September 2025 for development and/or validation studies on machine learning methods for predicting all forms of violent behaviour. We synthesised the results by summarising discrimination and calibration performance statistics and evaluated study quality by examining risk of bias and clinical utility.\n  Results We identified 38 studies reporting the development and validation of 40 models. Most studies reported Area Under the Curve (AUC) as the discrimination statistic with a range of 0.68-0.99. Only eight studies reported calibration performance, and three studies reported external validation. 31 studies had a high risk of bias, mainly in the analysis domain, and three studies had low risk of bias. The overall clinical utility of violence prediction models is poor, as indicated by risks of overfitting due to small samples, lack of transparent reporting, and low generalisability.\n  Conclusion Although black box machine learning models currently have limited applicability in clinical settings, they may show promise for identifying high-risk individuals. We recommend five key considerations for violence prediction modelling: (i) ensuring methodological quality (e.g. following guidelines) and interdisciplinary collaborations; (ii) using black box algorithms only for highly complex data; (iii) incorporating dynamic predictions to allow for risk monitoring; (iv) developing more trustworthy algorithms using explainable methods; and (v) applying causal machine learning approaches where appropriate."}
{"id": "2511.22952", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22952", "abs": "https://arxiv.org/abs/2511.22952", "authors": ["Jiachen Li", "Shihao Li"], "title": "RDS-DeePC: Robust Data Selection for Data-Enabled Predictive Control via Sensitivity Score", "comment": null, "summary": "Data-Enabled Predictive Control (DeePC) offers a powerful model-free approach to predictive control, but faces two fundamental challenges: computational complexity scaling cubically with dataset size, and severe performance degradation from corrupted data. This paper introduces Robust Data Selection DeePC (RDS-DeePC), which addresses both challenges through influence function analysis. We derive a sensitivity score quantifying each trajectory segment's leverage on the optimization solution, proving that high-sensitivity segments correspond to outliers while low-sensitivity segments represent consistent data. By selecting low-sensitivity segments, RDS-DeePC achieves computational efficiency and automatic outlier filtering without requiring data quality labels. For nonlinear systems, we extend the framework through a two-stage online selection approach accelerated by the LiSSA algorithm."}
{"id": "2511.22952", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22952", "abs": "https://arxiv.org/abs/2511.22952", "authors": ["Jiachen Li", "Shihao Li"], "title": "RDS-DeePC: Robust Data Selection for Data-Enabled Predictive Control via Sensitivity Score", "comment": null, "summary": "Data-Enabled Predictive Control (DeePC) offers a powerful model-free approach to predictive control, but faces two fundamental challenges: computational complexity scaling cubically with dataset size, and severe performance degradation from corrupted data. This paper introduces Robust Data Selection DeePC (RDS-DeePC), which addresses both challenges through influence function analysis. We derive a sensitivity score quantifying each trajectory segment's leverage on the optimization solution, proving that high-sensitivity segments correspond to outliers while low-sensitivity segments represent consistent data. By selecting low-sensitivity segments, RDS-DeePC achieves computational efficiency and automatic outlier filtering without requiring data quality labels. For nonlinear systems, we extend the framework through a two-stage online selection approach accelerated by the LiSSA algorithm."}
{"id": "2511.23137", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23137", "abs": "https://arxiv.org/abs/2511.23137", "authors": ["Natalie Neumeyer", "Leonie Selk"], "title": "Goodness-of-fit testing for the error distribution in functional linear models", "comment": "This article is part of a Festschrift in honor of Marie Hušková (title of the Festschrift: Asymptotic and Methodological Statistics)", "summary": "We consider the error distribution in functional linear models with scalar response and functional covariate. Different asymptotic expansions of the empirical distribution function and the empirical characteristic function based on estimated residuals under different model assumptions are discussed. The results are applied for simple and composite goodness-of-fit testing for the error distribution, in particular testing for normal distribution."}
{"id": "2511.22954", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22954", "abs": "https://arxiv.org/abs/2511.22954", "authors": ["Jiachen Li", "Shihao Li"], "title": "Adaptive Trajectory Bundle Method for Roll-to-Roll Manufacturing Systems", "comment": null, "summary": "Roll-to-roll (R2R) manufacturing demands precise tension and velocity control under strict operational constraints. Model predictive control requires gradient computation, while sampling-based methods such as MPPI struggle with hard constraint satisfaction. This paper presents an adaptive trajectory bundle method that achieves rigorous constraint handling through derivative-free sequential convex programming. The approach approximates nonlinear dynamics and costs via interpolated sample bundles, with adaptive trust regions and penalty parameters ensuring robust convergence without manual tuning. Simulations on a six-zone R2R system demonstrate tracking accuracy comparable to gradient-based MPC with superior constraint satisfaction over sampling-based alternatives."}
{"id": "2511.22954", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22954", "abs": "https://arxiv.org/abs/2511.22954", "authors": ["Jiachen Li", "Shihao Li"], "title": "Adaptive Trajectory Bundle Method for Roll-to-Roll Manufacturing Systems", "comment": null, "summary": "Roll-to-roll (R2R) manufacturing demands precise tension and velocity control under strict operational constraints. Model predictive control requires gradient computation, while sampling-based methods such as MPPI struggle with hard constraint satisfaction. This paper presents an adaptive trajectory bundle method that achieves rigorous constraint handling through derivative-free sequential convex programming. The approach approximates nonlinear dynamics and costs via interpolated sample bundles, with adaptive trust regions and penalty parameters ensuring robust convergence without manual tuning. Simulations on a six-zone R2R system demonstrate tracking accuracy comparable to gradient-based MPC with superior constraint satisfaction over sampling-based alternatives."}
{"id": "2511.23144", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.23144", "abs": "https://arxiv.org/abs/2511.23144", "authors": ["Riko Kelter", "Samuel Pawel"], "title": "The Bayesian optimal two-stage design for clinical phase II trials based on Bayes factors", "comment": "39 pages, 6 figures", "summary": "Sequential trial design is an important statistical approach to increase the efficiency of clinical trials. Bayesian sequential trial design relies primarily on conducting a Monte Carlo simulation under the hypotheses of interest and investigating the resulting design characteristics via Monte Carlo estimates. This approach has several drawbacks, namely that replicating the calibration of a Bayesian design requires repeating a possibly complex Monte Carlo simulation. Furthermore, Monte Carlo standard errors are required to judge the reliability of the simulation. All of this is due to a lack of closed-form or numerical approaches to calibrate a Bayesian design which uses Bayes factors. In this paper, we propose the Bayesian optimal two-stage design for clinical phase II trials based on Bayes factors. The optimal two-stage Bayes factor design is a sequential clinical trial design that is built on the idea of trinomial tree branching, a method we propose to correct the resulting design characteristics for introducing a single interim analysis. We build upon this idea to invent a calibration algorithm which yields the optimal Bayesian design that minimizes the expected sample size under the null hypothesis. Examples show that our design recovers Simon's two-stage optimal design as a special case, improves upon non-sequential Bayesian design based on Bayes factors, and can be calibrated quickly, as it makes use only of standard numerical techniques instead of time-consuming Monte Carlo simulations. Furthermore, the design allows to ensure a minimum probability on compelling evidence in favour of the null hypothesis, which is not possible with other designs. As the idea of trinomial tree branching is neither dependent on the endpoint, nor on the use of Bayes factors, the design can therefore be generalized to other settings, too."}
{"id": "2511.22957", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22957", "abs": "https://arxiv.org/abs/2511.22957", "authors": ["Ferran Bohigas-Daranas", "Oriol Gomis-Bellmunt", "Eduardo Prieto-Araujo"], "title": "Open-source implementation of distribution network reconfiguration methods: Analysis and comparison", "comment": null, "summary": "This paper presents a critical and practical approach to the evolution of distribution network reconfiguration algorithms, tracing their development from foundational heuristic methods introduced in 1975 to contemporary state-of-the-art techniques. The article systematically reviews seven different methodologies, including classical heuristic algorithms (Merlin, Baran, and others), advanced meta-heuristic methodologies (particle swarm optimization (PSO) and genetic algorithms), and purely mathematical approaches (MILP-based), analyzing their theoretical foundations, implementation strategies, computational complexity, and performance metrics based on extensive literature review and our own empirical testing. Each methodology is assessed through standardized test systems, considering multiple objectives such as power loss minimization and voltage profile improvement. The comparative analysis reveals the strengths and limitations of each approach under various network conditions and operational constraints. Furthermore, this work provides significant value to the research community by offering an open-source repository containing documented implementations of all reviewed algorithms. This resource facilitates accessibility for newcomers to the field, promotes reproducible research, and accelerates the development of next-generation distribution network optimization solutions. The repository includes comprehensive documentation, test cases, and performance benchmarks."}
{"id": "2511.22957", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22957", "abs": "https://arxiv.org/abs/2511.22957", "authors": ["Ferran Bohigas-Daranas", "Oriol Gomis-Bellmunt", "Eduardo Prieto-Araujo"], "title": "Open-source implementation of distribution network reconfiguration methods: Analysis and comparison", "comment": null, "summary": "This paper presents a critical and practical approach to the evolution of distribution network reconfiguration algorithms, tracing their development from foundational heuristic methods introduced in 1975 to contemporary state-of-the-art techniques. The article systematically reviews seven different methodologies, including classical heuristic algorithms (Merlin, Baran, and others), advanced meta-heuristic methodologies (particle swarm optimization (PSO) and genetic algorithms), and purely mathematical approaches (MILP-based), analyzing their theoretical foundations, implementation strategies, computational complexity, and performance metrics based on extensive literature review and our own empirical testing. Each methodology is assessed through standardized test systems, considering multiple objectives such as power loss minimization and voltage profile improvement. The comparative analysis reveals the strengths and limitations of each approach under various network conditions and operational constraints. Furthermore, this work provides significant value to the research community by offering an open-source repository containing documented implementations of all reviewed algorithms. This resource facilitates accessibility for newcomers to the field, promotes reproducible research, and accelerates the development of next-generation distribution network optimization solutions. The repository includes comprehensive documentation, test cases, and performance benchmarks."}
{"id": "2511.23208", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23208", "abs": "https://arxiv.org/abs/2511.23208", "authors": ["Suehyun Kim", "Kwonsang Lee"], "title": "A Design-Based Matching Framework for Staggered Adoption with Time-Varying Confounding", "comment": "26 pages, 3 figures", "summary": "Causal inference in longitudinal datasets has long been challenging due to dynamic treatment adoption and confounding by time-varying covariates. Prior work either fails to account for heterogeneity across treatment adoption cohorts and treatment timings or relies on modeling assumptions. In this paper, we develop a novel design-based framework for inference on group- and time-specific treatment effects in panel data with staggered treatment adoption. We establish identification results for causal effects under this structure and introduce corresponding estimators, together with a block bootstrap procedure for estimating the covariance matrix and testing the homogeneity of group-time treatment effects. To implement the framework in practice, we propose the Reverse-Time Nested Matching algorithm, which constructs matched strata by pairing units from different adoption cohorts in a way that ensures comparability of covariate histories at each treatment time. Applying the algorithm to the Netflix-IPTV dataset, we find that while Netflix subscription does not significantly affect total IPTV viewing time, it does negatively affect VoD usage. We also provide statistical evidence that the causal effects of Netflix subscription may vary even within the same treatment cohort or across the same outcome and event times."}
{"id": "2511.22975", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22975", "abs": "https://arxiv.org/abs/2511.22975", "authors": ["Jiachen Li", "Shihao Li", "Christopher Martin", "Zijun Chen", "Dongmei Chen", "Wei Li"], "title": "An LLM-Assisted Multi-Agent Control Framework for Roll-to-Roll Manufacturing Systems", "comment": null, "summary": "Roll-to-roll manufacturing requires precise tension and velocity control to ensure product quality, yet controller commissioning and adaptation remain time-intensive processes dependent on expert knowledge. This paper presents an LLM-assisted multi-agent framework that automates control system design and adaptation for R2R systems while maintaining safety. The framework operates through five phases: system identification from operational data, automated controller selection and tuning, sim-to-real adaptation with safety verification, continuous monitoring with diagnostic capabilities, and periodic model refinement. Experimental validation on a R2R system demonstrates successful tension regulation and velocity tracking under significant model uncertainty, with the framework achieving performance convergence through iterative adaptation. The approach reduces manual tuning effort while providing transparent diagnostic information for maintenance planning, offering a practical pathway for integrating AI-assisted automation in manufacturing control systems."}
{"id": "2511.22975", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22975", "abs": "https://arxiv.org/abs/2511.22975", "authors": ["Jiachen Li", "Shihao Li", "Christopher Martin", "Zijun Chen", "Dongmei Chen", "Wei Li"], "title": "An LLM-Assisted Multi-Agent Control Framework for Roll-to-Roll Manufacturing Systems", "comment": null, "summary": "Roll-to-roll manufacturing requires precise tension and velocity control to ensure product quality, yet controller commissioning and adaptation remain time-intensive processes dependent on expert knowledge. This paper presents an LLM-assisted multi-agent framework that automates control system design and adaptation for R2R systems while maintaining safety. The framework operates through five phases: system identification from operational data, automated controller selection and tuning, sim-to-real adaptation with safety verification, continuous monitoring with diagnostic capabilities, and periodic model refinement. Experimental validation on a R2R system demonstrates successful tension regulation and velocity tracking under significant model uncertainty, with the framework achieving performance convergence through iterative adaptation. The approach reduces manual tuning effort while providing transparent diagnostic information for maintenance planning, offering a practical pathway for integrating AI-assisted automation in manufacturing control systems."}
{"id": "2511.23216", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23216", "abs": "https://arxiv.org/abs/2511.23216", "authors": ["Nikola Sekulovski", "František Bartoš", "Don van den Bergh", "Giuseppe Arena", "Henrik R. Godmann", "Vipasha Goyal", "Julius M. Pfadt", "Maarten Marsman", "Adrian E. Raftery"], "title": "Comparing Variable Selection and Model Averaging Methods for Logistic Regression", "comment": null, "summary": "Model uncertainty is a central challenge in statistical models for binary outcomes such as logistic regression, arising when it is unclear which predictors should be included in the model. Many methods have been proposed to address this issue for logistic regression, but their relative performance under realistic conditions remains poorly understood. We therefore conducted a preregistered, simulation-based comparison of 28 established methods for variable selection and inference under model uncertainty, using 11 empirical datasets spanning a range of sample sizes and numbers of predictors, in cases both with and without separation. We found that Bayesian model averaging methods based on g-priors, particularly with g = max(n, p^2), show the strongest overall performance when separation is absent. When separation occurs, penalized likelihood approaches, especially the LASSO, provide the most stable results, while Bayesian model averaging with the local empirical Bayes (EB-local) prior is competitive in both situations. These findings offer practical guidance for applied researchers on how to effectively address model uncertainty in logistic regression in modern empirical and machine learning research."}
{"id": "2511.22986", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22986", "abs": "https://arxiv.org/abs/2511.22986", "authors": ["Dennis Zanutto", "Christos Michalopoulos", "Lydia Tsiami", "André Artelt", "Jasmin Brandt", "Demetrios Eliades", "Stelios Vrachimis", "Stefano Alvisi", "Valentina Marsili", "Filippo Mazzoni", "Panagiotis Smartzis", "Barbara Hammer", "Phoebe Koundouri", "Marios Polycarpou", "Dragan Savić"], "title": "The Battle of the Water Futures", "comment": null, "summary": "The highly anticipated 'Battle of the Water Networks' is back with a new challenge for the water community. This competition will be hosted at the 4th International Joint Conference on Water Distribution Systems Analysis and Computing and Control in the Water Industry (WDSA/CCWI 2026), taking place in Paphos, Cyprus, from May 18-21, 2026. This competition embodies the core mission of Water-Futures and the theme for WDSA/CCWI 2026: \"Designing the next generation of urban water (and wastewater) systems.\"\n  The objective is to design and operate a water distribution system over a long-term horizon under deep uncertainty, with interventions applied in stages. For the first time, this challenge features a staged-design approach, unobservable and unknown uncertainties, and incorporates elements of policymaking and artificial intelligence. The solutions will be assessed using a transparent and inspectable open-source evaluation framework."}
{"id": "2511.22986", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22986", "abs": "https://arxiv.org/abs/2511.22986", "authors": ["Dennis Zanutto", "Christos Michalopoulos", "Lydia Tsiami", "André Artelt", "Jasmin Brandt", "Demetrios Eliades", "Stelios Vrachimis", "Stefano Alvisi", "Valentina Marsili", "Filippo Mazzoni", "Panagiotis Smartzis", "Barbara Hammer", "Phoebe Koundouri", "Marios Polycarpou", "Dragan Savić"], "title": "The Battle of the Water Futures", "comment": null, "summary": "The highly anticipated 'Battle of the Water Networks' is back with a new challenge for the water community. This competition will be hosted at the 4th International Joint Conference on Water Distribution Systems Analysis and Computing and Control in the Water Industry (WDSA/CCWI 2026), taking place in Paphos, Cyprus, from May 18-21, 2026. This competition embodies the core mission of Water-Futures and the theme for WDSA/CCWI 2026: \"Designing the next generation of urban water (and wastewater) systems.\"\n  The objective is to design and operate a water distribution system over a long-term horizon under deep uncertainty, with interventions applied in stages. For the first time, this challenge features a staged-design approach, unobservable and unknown uncertainties, and incorporates elements of policymaking and artificial intelligence. The solutions will be assessed using a transparent and inspectable open-source evaluation framework."}
{"id": "2511.23275", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23275", "abs": "https://arxiv.org/abs/2511.23275", "authors": ["William Laplante", "Matias Altamirano", "Jeremias Knoblauch", "Andrew Duncan", "François-Xavier Briol"], "title": "Conjugate Generalised Bayesian Inference for Discrete Doubly Intractable Problems", "comment": null, "summary": "Doubly intractable problems occur when both the likelihood and the posterior are available only in unnormalised form, with computationally intractable normalisation constants. Bayesian inference then typically requires direct approximation of the posterior through specialised and typically expensive MCMC methods. In this paper, we provide a computationally efficient alternative in the form of a novel generalised Bayesian posterior that allows for conjugate inference within the class of exponential family models for discrete data. We derive theoretical guarantees to characterise the asymptotic behaviour of the generalised posterior, supporting its use for inference. The method is evaluated on a range of challenging intractable exponential family models, including the Conway-Maxwell-Poisson graphical model of multivariate count data, autoregressive discrete time series models, and Markov random fields such as the Ising and Potts models. The computational gains are significant; in our experiments, the method is between 10 and 6000 times faster than state-of-the-art Bayesian computational methods."}
{"id": "2511.22993", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22993", "abs": "https://arxiv.org/abs/2511.22993", "authors": ["Cesare Donati", "Fabrizio Dabbene", "Constantino Lagoa", "Carlo Novara", "Yoshio Ebihara"], "title": "Identification of contractive Lur'e-type systems via kernel-based Lipschitz design", "comment": null, "summary": "This paper addresses the problem of identifying contractive Lur'e-type systems. Specifically, it proposes an identification framework that integrates linear prior knowledge with a kernel representation of the nonlinear feedback while systematically enforcing contractivity via Lipschitz constant design. The resulting algorithms provide models that are accurate in prediction, interpretable, and faithful to the contractive nature of the true system. Numerical experiments demonstrate that enforcing contractivity significantly improves parameter estimation and yields models that are both accurate and physically meaningful."}
{"id": "2511.22993", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22993", "abs": "https://arxiv.org/abs/2511.22993", "authors": ["Cesare Donati", "Fabrizio Dabbene", "Constantino Lagoa", "Carlo Novara", "Yoshio Ebihara"], "title": "Identification of contractive Lur'e-type systems via kernel-based Lipschitz design", "comment": null, "summary": "This paper addresses the problem of identifying contractive Lur'e-type systems. Specifically, it proposes an identification framework that integrates linear prior knowledge with a kernel representation of the nonlinear feedback while systematically enforcing contractivity via Lipschitz constant design. The resulting algorithms provide models that are accurate in prediction, interpretable, and faithful to the contractive nature of the true system. Numerical experiments demonstrate that enforcing contractivity significantly improves parameter estimation and yields models that are both accurate and physically meaningful."}
{"id": "2511.23419", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23419", "abs": "https://arxiv.org/abs/2511.23419", "authors": ["Shifeng Sun", "Xueqi Wang", "Zhuoran Hou", "Elizabeth L. Turner"], "title": "Getting it right: Methods for risk ratios and risk differences cluster randomized trials with a small number of clusters", "comment": null, "summary": "Most cluster randomized trials (CRTs) randomize fewer than 30-40 clusters in total. When performing inference for such ``small'' CRTs, it is important to use methods that appropriately account for the small sample size. When the generalized estimating equations (GEE) approach is used for analysis of ``small'' CRTs, the robust variance estimator from GEE is biased downward and therefore bias-corrected standard errors should be used. Moreover, in order to avoid inflated Type I error, an appropriate bias-corrected standard error should be paired with the t- rather than Z-statistic when making inference about a single-parameter intervention effect. Although several bias-correction methods (including Kauermann and Carroll (KC), Mancl and DeRouen (MD), Morel, Bokossa, and Neerchal (MBN), and the average of KC and MD (AVG)) have been evaluated for inference for odds ratios, their finite-sample behavior in ``small'' CRTs with few clusters has not been thoroughly investigated for risk ratios and risk differences. The current article aims to fill the gap by including analysis via binomial, Poisson and Gaussian models and for a broad spectrum of scenarios. Analysis is via binomial and Poisson models (using log and identity link for risk and differences measures, respectively). We additionally explore the use of Gaussian models with identity link for risk differences and adopt the \"modified\" approach for analysis with misspecified Poisson and Gaussian models. We consider a broad spectrum of scenarios including for rare outcomes, small cluster sizes, high intracluster correlations (ICCs), and high coefficients of variation (CVs) of cluster size."}
{"id": "2511.23014", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23014", "abs": "https://arxiv.org/abs/2511.23014", "authors": ["Suraj Kumar", "Aditya Rallapalli", "Nivriti Priyadarshini", "Bharat Kumar GVP", "Ravi Kumar L"], "title": "Closed-Loop Control Law for Low Thrust Orbit Transfer with Guaranteed Stability", "comment": "6 pages, 5 figures, 3 tables -- Accepted for publication in Indian Control Conference 2025", "summary": "Electric propulsion is used to maximize payload capacity in communication satellites. These orbit raising maneuvers span several months and hundreds of revolutions, making trajectory design a complex challenge. The literature typically addresses this problem using feedback laws, with Q-law being one of the most prominent approaches. However, Q-law suffers from closed-loop stability issues, limiting its suitability for real-time on-board implementation. In this work, we focus on closed-loop orbit raising rather than offline trajectory planning and address the stability limitations of the Q-law through a Lyapunov based control design. A Lyapunov-guided modification of the classical Q-law is proposed to ensure closed-loop stability and enable real-time implementation. The effectiveness of the proposed method is demonstrated through closed-loop orbit transfers across various scenarios, including co-planar transfers, equatorial to polar orbit transfers, and geostationary transfer orbit (GTO) to geostationary earth orbit (GEO) transfers."}
{"id": "2511.23014", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23014", "abs": "https://arxiv.org/abs/2511.23014", "authors": ["Suraj Kumar", "Aditya Rallapalli", "Nivriti Priyadarshini", "Bharat Kumar GVP", "Ravi Kumar L"], "title": "Closed-Loop Control Law for Low Thrust Orbit Transfer with Guaranteed Stability", "comment": "6 pages, 5 figures, 3 tables -- Accepted for publication in Indian Control Conference 2025", "summary": "Electric propulsion is used to maximize payload capacity in communication satellites. These orbit raising maneuvers span several months and hundreds of revolutions, making trajectory design a complex challenge. The literature typically addresses this problem using feedback laws, with Q-law being one of the most prominent approaches. However, Q-law suffers from closed-loop stability issues, limiting its suitability for real-time on-board implementation. In this work, we focus on closed-loop orbit raising rather than offline trajectory planning and address the stability limitations of the Q-law through a Lyapunov based control design. A Lyapunov-guided modification of the classical Q-law is proposed to ensure closed-loop stability and enable real-time implementation. The effectiveness of the proposed method is demonstrated through closed-loop orbit transfers across various scenarios, including co-planar transfers, equatorial to polar orbit transfers, and geostationary transfer orbit (GTO) to geostationary earth orbit (GEO) transfers."}
{"id": "2511.23433", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23433", "abs": "https://arxiv.org/abs/2511.23433", "authors": ["Maria Alejandra Valdez Cabrera", "Amy D Willis", "Armeen Taeb"], "title": "Consensus Tree Estimation with False Discovery Rate Control via Partially Ordered Sets", "comment": null, "summary": "Connected acyclic graphs (trees) are data objects that hierarchically organize categories. Collections of trees arise in a diverse variety of fields, including evolutionary biology, public health, machine learning, social sciences and anatomy. Summarizing a collection of trees by a single representative is challenging, in part due to the dimension of both the sample and parameter space. We frame consensus tree estimation as a structured feature-selection problem, where leaves and edges are the features. We introduce a partial order on leaf-labeled trees, use it to define true and false discoveries for a candidate summary tree, and develop an estimation algorithm that controls the false discovery rate at a nominal level for a broad class of non-parametric generative models. Furthermore, using the partial order structure, we assess the stability of each feature in a selected tree. Importantly, our method accommodates unequal leaf sets and non-binary trees, allowing the estimator to reflect uncertainty by collapsing poorly supported structure instead of forcing full resolution. We apply the method to study the archaeal origin of eukaryotic cells and to quantify uncertainty in deep branching orders. While consensus tree construction has historically been viewed as an estimation task, reframing it as feature selection over a partially ordered set allows us to obtain the first estimator with finite-sample and model-free guarantees. More generally, our approach provides a foundation for integrating tools from multiple testing into tree estimation."}
{"id": "2511.23022", "categories": ["eess.SY", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.23022", "abs": "https://arxiv.org/abs/2511.23022", "authors": ["Shubham Sawarkar", "Pushpak Jagtap"], "title": "Control Barrier Function for Unknown Systems: An Approximation-free Approach", "comment": null, "summary": "We study the prescribed-time reach-avoid (PT-RA) control problem for nonlinear systems with unknown dynamics operating in environments with moving obstacles. Unlike robust or learning based Control Barrier Function (CBF) methods, the proposed framework requires neither online model learning nor uncertainty bound estimation. A CBF-based Quadratic Program (CBF-QP) is solved on a simple virtual system to generate a safe reference satisfying PT-RA conditions with respect to time-varying, tightened obstacle and goal sets. The true system is confined to a Virtual Confinement Zone (VCZ) around this reference using an approximation-free feedback law. This construction guarantees real-time safety and prescribed-time target reachability under unknown dynamics and dynamic constraints without explicit model identification or offline precomputation. Simulation results illustrate reliable dynamic obstacle avoidance and timely convergence to the target set."}
{"id": "2511.23022", "categories": ["eess.SY", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.23022", "abs": "https://arxiv.org/abs/2511.23022", "authors": ["Shubham Sawarkar", "Pushpak Jagtap"], "title": "Control Barrier Function for Unknown Systems: An Approximation-free Approach", "comment": null, "summary": "We study the prescribed-time reach-avoid (PT-RA) control problem for nonlinear systems with unknown dynamics operating in environments with moving obstacles. Unlike robust or learning based Control Barrier Function (CBF) methods, the proposed framework requires neither online model learning nor uncertainty bound estimation. A CBF-based Quadratic Program (CBF-QP) is solved on a simple virtual system to generate a safe reference satisfying PT-RA conditions with respect to time-varying, tightened obstacle and goal sets. The true system is confined to a Virtual Confinement Zone (VCZ) around this reference using an approximation-free feedback law. This construction guarantees real-time safety and prescribed-time target reachability under unknown dynamics and dynamic constraints without explicit model identification or offline precomputation. Simulation results illustrate reliable dynamic obstacle avoidance and timely convergence to the target set."}
{"id": "2511.23466", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.23466", "abs": "https://arxiv.org/abs/2511.23466", "authors": ["Danielle Paulson", "Souhardya Sengupta", "Lucas Janson"], "title": "The $L$-test: Increasing the Linear Model $F$-test's Power Under Sparsity Without Sacrificing Validity", "comment": null, "summary": "We introduce a new procedure for testing the significance of a set of regression coefficients in a Gaussian linear model with $n \\geq d$. Our method, the $L$-test, provides the same statistical validity guarantee as the classical $F$-test, while attaining higher power when the nuisance coefficients are sparse. Although the $L$-test requires Monte Carlo sampling, each sample's runtime is dominated by simple matrix-vector multiplications so that the overall test remains computationally efficient. Furthermore, we provide a Monte-Carlo-free variant that can be used for particularly large-scale multiple testing applications. We give intuition for the power of our approach, validate its advantages through extensive simulations, and illustrate its practical utility in both single- and multiple-testing contexts with an application to an HIV drug resistance dataset. In the concluding remarks, we also discuss how our methodology can be applied to a more general class of parametric models that admit asymptotically Gaussian estimators."}
{"id": "2511.23023", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23023", "abs": "https://arxiv.org/abs/2511.23023", "authors": ["Yushan Li", "Jiabao He", "Dimos V. Dimarogonas"], "title": "Resistant Topology Inference in Consensus Networks: A Feedback-Based Design", "comment": "Accepted by 2025 IEEE Conference on Decision and Control", "summary": "Consensus networks are widely deployed in numerous civil and industrial applications. However, the process of reaching a common consensus among nodes can unintentionally reveal the network's topology to external observers by appropriate inference techniques. This paper investigates a feedback-based resistant inference design to prevent the topology from being inferred using data, while preserving the original consensus convergence. First, we characterize the conditions to preserve the original consensus, and introduce the ''accurate inference'' notion, which accounts for both the uniqueness of the solution to topology inference (solvability) and the deviation from the original topology (accuracy). Then, we employ invariant subspace analysis to characterize the solvability. Even when unique inference remains possible, we provide necessary and sufficient conditions for the feedback design to induce inaccurate inference, and give a Laplacian structure based distributed design. Simulations validate the effectiveness of the method."}
{"id": "2511.23023", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23023", "abs": "https://arxiv.org/abs/2511.23023", "authors": ["Yushan Li", "Jiabao He", "Dimos V. Dimarogonas"], "title": "Resistant Topology Inference in Consensus Networks: A Feedback-Based Design", "comment": "Accepted by 2025 IEEE Conference on Decision and Control", "summary": "Consensus networks are widely deployed in numerous civil and industrial applications. However, the process of reaching a common consensus among nodes can unintentionally reveal the network's topology to external observers by appropriate inference techniques. This paper investigates a feedback-based resistant inference design to prevent the topology from being inferred using data, while preserving the original consensus convergence. First, we characterize the conditions to preserve the original consensus, and introduce the ''accurate inference'' notion, which accounts for both the uniqueness of the solution to topology inference (solvability) and the deviation from the original topology (accuracy). Then, we employ invariant subspace analysis to characterize the solvability. Even when unique inference remains possible, we provide necessary and sufficient conditions for the feedback design to induce inaccurate inference, and give a Laplacian structure based distributed design. Simulations validate the effectiveness of the method."}
{"id": "2511.22816", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2511.22816", "abs": "https://arxiv.org/abs/2511.22816", "authors": ["Miodrag M. Lovric"], "title": "What the Jeffreys-Lindley Paradox Really Is: Correcting a Persistent Misconception", "comment": "21 pages, 1 figure, 1 table. Submitted to Statistica Sinica", "summary": "The Jeffreys-Lindley paradox stands as the most profound divergence between frequentist and Bayesian approaches to hypothesis testing. Yet despite more than six decades of discussion, this paradox remains frequently misunderstood--even in the pages of leading statistical journals. In a 1993 paper published in Statistica Sinica, Robert characterized the Jeffreys-Lindley paradox as \"the fact that a point null hypothesis will always be accepted when the variance of a conjugate prior goes to infinity.\" This characterization, however, describes a different phenomenon entirely-what we term Bartlett's Anomaly-rather than the Jeffreys-Lindley paradox as originally formulated. The paradox, as presented by Lindley (1957), concerns what happens as sample size increases without bound while holding the significance level fixed, not what happens as prior variance diverges. This distinction is not merely terminological: the two phenomena have different mathematical structures, different implications, and require different solutions. The present paper aims to clarify this confusion, demonstrating through Lindley's own equations that he was concerned exclusively with sample size asymptotics. We show that even Jeffreys himself underestimated the practical frequency of the paradox. Finally, we argue that the only genuine resolution lies in abandoning point null hypotheses in favor of interval nulls, a paradigm shift that eliminates the paradox and restores harmony between Bayesian and frequentist inference. Submitted to Statistica Sinica."}
{"id": "2511.23046", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23046", "abs": "https://arxiv.org/abs/2511.23046", "authors": ["Ignasi Ventura Nadal", "Mohammad Kazem Bakhshizadeh", "Petros Aristidou", "Nicolae Darii", "Rahul Nellikkath", "Spyros Chatzivasileiadis"], "title": "Scalable Physics-Informed Neural Networks for Accelerating Electromagnetic Transient Stability Assessment", "comment": null, "summary": "This paper puts forward a framework to accelerate Electromagnetic Transient (EMT) simulations by replacing individual components with trained Physics-Informed Neural Networks (PINNs). EMT simulations are considered the cornerstone of transient stability assessment of power systems with high shares of Inverter-Based Resources (IBRs), and, although accurate, they are notorious for their slow simulation speed. Taking a deeper dive into the EMT simulation algorithms, this paper identifies the most computationally expensive components of the simulation and replaces them with fast and accurate PINNs. The proposed novel PINN formulation enables a modular and scalable integration into the simulation algorithm. Using a type-4 wind turbine EMT model, we demonstrate a 4--6x simulation speedup by capturing the Phase-Locked Loop (PLL) with a PINN. We validate all our results with PSCAD software."}
{"id": "2511.23046", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23046", "abs": "https://arxiv.org/abs/2511.23046", "authors": ["Ignasi Ventura Nadal", "Mohammad Kazem Bakhshizadeh", "Petros Aristidou", "Nicolae Darii", "Rahul Nellikkath", "Spyros Chatzivasileiadis"], "title": "Scalable Physics-Informed Neural Networks for Accelerating Electromagnetic Transient Stability Assessment", "comment": null, "summary": "This paper puts forward a framework to accelerate Electromagnetic Transient (EMT) simulations by replacing individual components with trained Physics-Informed Neural Networks (PINNs). EMT simulations are considered the cornerstone of transient stability assessment of power systems with high shares of Inverter-Based Resources (IBRs), and, although accurate, they are notorious for their slow simulation speed. Taking a deeper dive into the EMT simulation algorithms, this paper identifies the most computationally expensive components of the simulation and replaces them with fast and accurate PINNs. The proposed novel PINN formulation enables a modular and scalable integration into the simulation algorithm. Using a type-4 wind turbine EMT model, we demonstrate a 4--6x simulation speedup by capturing the Phase-Locked Loop (PLL) with a PINN. We validate all our results with PSCAD software."}
{"id": "2511.23062", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23062", "abs": "https://arxiv.org/abs/2511.23062", "authors": ["Serhiy Kapustyan", "Pranav Tetey", "Thomas Grube", "Jochen Linssen"], "title": "Development of a Load Profile Generator for Non-road Mobile Machinery", "comment": "24 Pages, 11 Figures", "summary": "This research presents a Load Profile Generator model for non-road mobile machinery, which depicts the most common operational profiles that reflect real-world conditions. This technological bottom-up model enables users to parameterize specific machines for simulation and observe their power demand at the actuator interfaces. The application of the Load Profile Generator covers different non-road mobile machinery categories, such as construction, agriculture, industrial and forestry. In this study, the Load Profile Generator was used to demonstrate common operations of material handler and forest forwarder, which have been validated against real-world data to match the results. The usage of Load Profile Generator aids engineers in evaluation machines performance by developing operation strategies. It opens doors to further systems analysis as it can serve as an interface for energy demand calculations. The model's results are accurate enough to provide a sufficient understanding of a wide range of non-road mobile machinery load profiles as well as insights about alternative fuel and power supply concepts helping in optimising the system simulation."}
{"id": "2511.23062", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23062", "abs": "https://arxiv.org/abs/2511.23062", "authors": ["Serhiy Kapustyan", "Pranav Tetey", "Thomas Grube", "Jochen Linssen"], "title": "Development of a Load Profile Generator for Non-road Mobile Machinery", "comment": "24 Pages, 11 Figures", "summary": "This research presents a Load Profile Generator model for non-road mobile machinery, which depicts the most common operational profiles that reflect real-world conditions. This technological bottom-up model enables users to parameterize specific machines for simulation and observe their power demand at the actuator interfaces. The application of the Load Profile Generator covers different non-road mobile machinery categories, such as construction, agriculture, industrial and forestry. In this study, the Load Profile Generator was used to demonstrate common operations of material handler and forest forwarder, which have been validated against real-world data to match the results. The usage of Load Profile Generator aids engineers in evaluation machines performance by developing operation strategies. It opens doors to further systems analysis as it can serve as an interface for energy demand calculations. The model's results are accurate enough to provide a sufficient understanding of a wide range of non-road mobile machinery load profiles as well as insights about alternative fuel and power supply concepts helping in optimising the system simulation."}
{"id": "2511.23138", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23138", "abs": "https://arxiv.org/abs/2511.23138", "authors": ["Songyan Li", "Hongchang Li", "Haiyue Jiang", "Yudong Zhang", "Wenjie Chen", "Xu Yang"], "title": "Targeted-Subharmonic-Eliminating Pulse Density Modulation for Wireless Power Transfer Systems", "comment": null, "summary": "This letter proposes a targeted-subharmonic-eliminating pulse density modulation (PDM) method for series-series (SS) compensated wireless power transfer (WPT) systems. The subharmonic frequency components which excite current abnormal oscillations in PDM controlled WPT systems are eliminated through a specially designed noise transfer function (NTF). The proposed method is simple to implement in both primary and secondary sides of WPT systems and exhibits a certain tolerance to deviations caused by inaccurate coupling coefficient identification in NTF design. Experimental results demonstrated the effectiveness and robustness of the proposed method in suppressing current abnormal oscillations and reducing the fluctuations in current amplitudes."}
{"id": "2511.23138", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23138", "abs": "https://arxiv.org/abs/2511.23138", "authors": ["Songyan Li", "Hongchang Li", "Haiyue Jiang", "Yudong Zhang", "Wenjie Chen", "Xu Yang"], "title": "Targeted-Subharmonic-Eliminating Pulse Density Modulation for Wireless Power Transfer Systems", "comment": null, "summary": "This letter proposes a targeted-subharmonic-eliminating pulse density modulation (PDM) method for series-series (SS) compensated wireless power transfer (WPT) systems. The subharmonic frequency components which excite current abnormal oscillations in PDM controlled WPT systems are eliminated through a specially designed noise transfer function (NTF). The proposed method is simple to implement in both primary and secondary sides of WPT systems and exhibits a certain tolerance to deviations caused by inaccurate coupling coefficient identification in NTF design. Experimental results demonstrated the effectiveness and robustness of the proposed method in suppressing current abnormal oscillations and reducing the fluctuations in current amplitudes."}
{"id": "2511.23322", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23322", "abs": "https://arxiv.org/abs/2511.23322", "authors": ["Jianqiang Ding", "Shankar A. Deka"], "title": "Data-driven Reachability Verification with Probabilistic Guarantees under Koopman Spectral Uncertainty", "comment": "This work has been submitted to the IFAC for possible publication", "summary": "Providing rigorous reachability guarantees for unknown complex systems is a crucial and challenging task. In this paper, we present a novel data-driven framework that addresses this challenge by leveraging Koopman operator theory. Instead of operating in the state space, the proposed method encodes model uncertainty from finite data directly into Koopman spectral representation with quantifiable error bounds. Leveraging this spectral information, we systematically determine time intervals within which trajectories from the initial set are guaranteed, with a prescribed probability, to reach the target set. This enables the rigorous reachability verification without explicit computation of reachable sets, thereby offering a significant advantage in scalability and applicability. We finally validate the effectiveness of the proposed framework through case studies on representative dynamical systems."}
{"id": "2511.23322", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23322", "abs": "https://arxiv.org/abs/2511.23322", "authors": ["Jianqiang Ding", "Shankar A. Deka"], "title": "Data-driven Reachability Verification with Probabilistic Guarantees under Koopman Spectral Uncertainty", "comment": "This work has been submitted to the IFAC for possible publication", "summary": "Providing rigorous reachability guarantees for unknown complex systems is a crucial and challenging task. In this paper, we present a novel data-driven framework that addresses this challenge by leveraging Koopman operator theory. Instead of operating in the state space, the proposed method encodes model uncertainty from finite data directly into Koopman spectral representation with quantifiable error bounds. Leveraging this spectral information, we systematically determine time intervals within which trajectories from the initial set are guaranteed, with a prescribed probability, to reach the target set. This enables the rigorous reachability verification without explicit computation of reachable sets, thereby offering a significant advantage in scalability and applicability. We finally validate the effectiveness of the proposed framework through case studies on representative dynamical systems."}
{"id": "2511.23326", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23326", "abs": "https://arxiv.org/abs/2511.23326", "authors": ["Ahmad Adnan Qidan", "Taisir El-Gorashi", "Majid Safari", "Harald Haas", "Richard V. Penty", "Ian H. White", "Jaafar M. H. Elmirghani"], "title": "Dynamic Power Allocation For NOMA-Based Transmission in 6G Optical Wireless Networks", "comment": null, "summary": "OWC has been considered as a key enabling technology to unlock unprecedented speeds of communication, supporting high demands of data traffic. In this paper, infrared lasers are used as optical transmitters operating in an indoor environment under eye safety regulations due to their high modulation speed. To provide efficient multiple access service, NOMA-based transmission is implemented to multiplex messages intended to multiple users in the power domain and maximize the spectral efficiency of our laser-based OWC network. In particular, a BIA outer precoder is designed to coordinate the transmission among multiple APs and determine the precoding matrices for groups of users potential formed according to NOMA principles. For effective use of NOMA, an optimization problem is formulated to maximize the sum rate of the network through forming optimum groups under certain joint conditions, efficient power allocation, high quality of service for each weak and strong users, and high overall system performance. Such optimization problems are defined as max-min fractional programs difficult to solve in practice. Therefore, a dynamic application for NOMA is introduced using two algorithms. First, a RF-aided dynamic algorithm is designed to form multiple groups, where users exchange binary variables among them through an RF system to establish distance-based weight edges, which are used as a metric for the grouping process. Second, a dynamic power allocation is proposed to determine the optimum power allocated to each group, while the users belonging to a certain group receive their traffic demands regardless of their classification as weak or strong. The results show the convergence of the proposed dynamic application to the optimum solution, and its high performance in terms of sum rate, fairness, and energy efficiency compared to counterpart schemes."}
{"id": "2511.23326", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23326", "abs": "https://arxiv.org/abs/2511.23326", "authors": ["Ahmad Adnan Qidan", "Taisir El-Gorashi", "Majid Safari", "Harald Haas", "Richard V. Penty", "Ian H. White", "Jaafar M. H. Elmirghani"], "title": "Dynamic Power Allocation For NOMA-Based Transmission in 6G Optical Wireless Networks", "comment": null, "summary": "OWC has been considered as a key enabling technology to unlock unprecedented speeds of communication, supporting high demands of data traffic. In this paper, infrared lasers are used as optical transmitters operating in an indoor environment under eye safety regulations due to their high modulation speed. To provide efficient multiple access service, NOMA-based transmission is implemented to multiplex messages intended to multiple users in the power domain and maximize the spectral efficiency of our laser-based OWC network. In particular, a BIA outer precoder is designed to coordinate the transmission among multiple APs and determine the precoding matrices for groups of users potential formed according to NOMA principles. For effective use of NOMA, an optimization problem is formulated to maximize the sum rate of the network through forming optimum groups under certain joint conditions, efficient power allocation, high quality of service for each weak and strong users, and high overall system performance. Such optimization problems are defined as max-min fractional programs difficult to solve in practice. Therefore, a dynamic application for NOMA is introduced using two algorithms. First, a RF-aided dynamic algorithm is designed to form multiple groups, where users exchange binary variables among them through an RF system to establish distance-based weight edges, which are used as a metric for the grouping process. Second, a dynamic power allocation is proposed to determine the optimum power allocated to each group, while the users belonging to a certain group receive their traffic demands regardless of their classification as weak or strong. The results show the convergence of the proposed dynamic application to the optimum solution, and its high performance in terms of sum rate, fairness, and energy efficiency compared to counterpart schemes."}
{"id": "2511.23385", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23385", "abs": "https://arxiv.org/abs/2511.23385", "authors": ["Yang Guo", "Jaime A. Moreno", "Stefan Streif"], "title": "Strong nonlinear detectability and moving horizon estimation for nonlinear systems with unknown inputs", "comment": "18 pages,3 figures", "summary": "This paper considers state estimation for general nonlinear discrete-time systems subject to measurement noise and possibly unbounded unknown inputs. To approach this problem, we first propose the concept of strong nonlinear detectability. This condition is sufficient and necessary for the existence of unknown input state estimators (UISEs), which reconstruct states from noisy sampled measurements and yield bounded estimation error even for unbounded unknown inputs. Based on the proposed detectability notion, a UISE is designed via a moving horizon estimation strategy using a full-order model as well as past and current measurements. Next, we tighten this detectability notion to design a two-stage MHE-based UISE, which is computationally more efficient than the MHE-based UISE using full-order models. In a simulation example with a plant growth process, both variants of MHE-based UISEs are compared with a conventional MHE to illustrate the merits of the developed methods."}
{"id": "2511.23385", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23385", "abs": "https://arxiv.org/abs/2511.23385", "authors": ["Yang Guo", "Jaime A. Moreno", "Stefan Streif"], "title": "Strong nonlinear detectability and moving horizon estimation for nonlinear systems with unknown inputs", "comment": "18 pages,3 figures", "summary": "This paper considers state estimation for general nonlinear discrete-time systems subject to measurement noise and possibly unbounded unknown inputs. To approach this problem, we first propose the concept of strong nonlinear detectability. This condition is sufficient and necessary for the existence of unknown input state estimators (UISEs), which reconstruct states from noisy sampled measurements and yield bounded estimation error even for unbounded unknown inputs. Based on the proposed detectability notion, a UISE is designed via a moving horizon estimation strategy using a full-order model as well as past and current measurements. Next, we tighten this detectability notion to design a two-stage MHE-based UISE, which is computationally more efficient than the MHE-based UISE using full-order models. In a simulation example with a plant growth process, both variants of MHE-based UISEs are compared with a conventional MHE to illustrate the merits of the developed methods."}
{"id": "2511.23474", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23474", "abs": "https://arxiv.org/abs/2511.23474", "authors": ["Michael Tang", "Miroslav Krstic", "Jorge Poveda"], "title": "A Lyapunov-Based Small-Gain Theorem for Fixed-Time Stability", "comment": null, "summary": "This paper introduces a novel Lyapunov-based small-gain methodology for establishing fixed-time stability (FxTS) guarantees in interconnected dynamical systems. Specifically, we consider interconnections in which each subsystem admits an individual fixed-time input-to-state stability (ISS) Lyapunov function that certifies FxT-ISS. We then show that if a nonlinear small-gain condition is satisfied, then the entire interconnected system is FxTS. Our results are analogous to existing Lyapunov-based small-gain theorems developed for asymptotic and finite-time stability, thereby filling an important gap in the stability analysis of interconnected dynamical systems. The proposed theoretical tools are further illustrated through analytical and numerical examples, including an application to fixed-time feedback optimization of dynamical systems without time-scale separation between the plant and the controller."}
{"id": "2511.23474", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.23474", "abs": "https://arxiv.org/abs/2511.23474", "authors": ["Michael Tang", "Miroslav Krstic", "Jorge Poveda"], "title": "A Lyapunov-Based Small-Gain Theorem for Fixed-Time Stability", "comment": null, "summary": "This paper introduces a novel Lyapunov-based small-gain methodology for establishing fixed-time stability (FxTS) guarantees in interconnected dynamical systems. Specifically, we consider interconnections in which each subsystem admits an individual fixed-time input-to-state stability (ISS) Lyapunov function that certifies FxT-ISS. We then show that if a nonlinear small-gain condition is satisfied, then the entire interconnected system is FxTS. Our results are analogous to existing Lyapunov-based small-gain theorems developed for asymptotic and finite-time stability, thereby filling an important gap in the stability analysis of interconnected dynamical systems. The proposed theoretical tools are further illustrated through analytical and numerical examples, including an application to fixed-time feedback optimization of dynamical systems without time-scale separation between the plant and the controller."}
{"id": "2511.22123", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22123", "abs": "https://arxiv.org/abs/2511.22123", "authors": ["Adam Waterman", "Martin Guay"], "title": "Model Predictive Path Planning in Navier-Stokes Flow with POD-Based Reduced-Order Models", "comment": null, "summary": "We present a framework for optimal trajectory generation in flow-driven systems governed by the Navier-Stokes equations, combining a Proper Orthogonal Decomposition (POD) reduced0order model (ROM) with Model Predictive Control (MPC). The approach (i) approximates the velocity field from data via snapshot POD and orthogonal projection, (ii) derives a Galerkin-projected dynamical model in reduced coordinates, and (iii) employs MPC to plan control inputs that steer an agent through the predicted flow while satisfying state and actuation constraints. By leveraging reduced-order modeling, the method enables real-time control in high-dimensional flow environments. Simulations demonstrate accurate flow-field reconstruction and efficient trajectory generation within realistic wind environments."}
{"id": "2511.22123", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22123", "abs": "https://arxiv.org/abs/2511.22123", "authors": ["Adam Waterman", "Martin Guay"], "title": "Model Predictive Path Planning in Navier-Stokes Flow with POD-Based Reduced-Order Models", "comment": null, "summary": "We present a framework for optimal trajectory generation in flow-driven systems governed by the Navier-Stokes equations, combining a Proper Orthogonal Decomposition (POD) reduced0order model (ROM) with Model Predictive Control (MPC). The approach (i) approximates the velocity field from data via snapshot POD and orthogonal projection, (ii) derives a Galerkin-projected dynamical model in reduced coordinates, and (iii) employs MPC to plan control inputs that steer an agent through the predicted flow while satisfying state and actuation constraints. By leveraging reduced-order modeling, the method enables real-time control in high-dimensional flow environments. Simulations demonstrate accurate flow-field reconstruction and efficient trajectory generation within realistic wind environments."}
{"id": "2511.22839", "categories": ["physics.soc-ph", "econ.GN", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22839", "abs": "https://arxiv.org/abs/2511.22839", "authors": ["Ruike Lyu", "Anna Li", "Jianxiao Wang", "Hongxi Luo", "Yan Shen", "Hongye Guo", "Ershun Du", "Chongqing Kang", "Jesse Jenkins"], "title": "Can industrial overcapacity enable seasonal flexibility in electricity use? A case study of aluminum smelting in China", "comment": "Submitted to Nature Energy", "summary": "In many countries, declining demand in energy-intensive industries (EIIs) such as cement, steel, and aluminum is leading to industrial overcapacity. Although overcapacity is traditionally seen as problematic, it could unlock EIIs' flexibility in electricity use. Using China's aluminum smelting sector as a case, we evaluate the system-level cost-benefit of retaining EII overcapacity for flexible electricity use in decarbonized systems. We find that overcapacity enables smelters to adopt a seasonal operation paradigm, ceasing production during winter load peaks driven by heating electrification and renewable seasonality. In a 2050-net-zero scenario, this paradigm reduces China's electricity-system investment and operating costs by 15-72 billion CNY per year (8-34% of the industry's product value), enough to offset the costs of maintaining overcapacity and product storage. Seasonal operation also cuts workforce fluctuations across aluminum smelting and thermal-power sectors by up to 62%, potentially mitigating socio-economic disruptions from industrial restructuring and the energy transition."}
{"id": "2511.22839", "categories": ["physics.soc-ph", "econ.GN", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.22839", "abs": "https://arxiv.org/abs/2511.22839", "authors": ["Ruike Lyu", "Anna Li", "Jianxiao Wang", "Hongxi Luo", "Yan Shen", "Hongye Guo", "Ershun Du", "Chongqing Kang", "Jesse Jenkins"], "title": "Can industrial overcapacity enable seasonal flexibility in electricity use? A case study of aluminum smelting in China", "comment": "Submitted to Nature Energy", "summary": "In many countries, declining demand in energy-intensive industries (EIIs) such as cement, steel, and aluminum is leading to industrial overcapacity. Although overcapacity is traditionally seen as problematic, it could unlock EIIs' flexibility in electricity use. Using China's aluminum smelting sector as a case, we evaluate the system-level cost-benefit of retaining EII overcapacity for flexible electricity use in decarbonized systems. We find that overcapacity enables smelters to adopt a seasonal operation paradigm, ceasing production during winter load peaks driven by heating electrification and renewable seasonality. In a 2050-net-zero scenario, this paradigm reduces China's electricity-system investment and operating costs by 15-72 billion CNY per year (8-34% of the industry's product value), enough to offset the costs of maintaining overcapacity and product storage. Seasonal operation also cuts workforce fluctuations across aluminum smelting and thermal-power sectors by up to 62%, potentially mitigating socio-economic disruptions from industrial restructuring and the energy transition."}
