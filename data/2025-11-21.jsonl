{"id": "2511.15783", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15783", "abs": "https://arxiv.org/abs/2511.15783", "authors": ["Po-Shen Hsin", "Ryohei Kobayashi"], "title": "Automorphism in Gauge Theories: Higher Symmetries and Transversal Non-Clifford Logical Gates", "comment": "22 pages, 6 figures", "summary": "Gauge theories are important descriptions for many physical phenomena and systems in quantum computation. Automorphism of gauge group naturally gives global symmetries of gauge theories. In this work we study such symmetries in gauge theories induced by automorphisms of the gauge group, when the gauge theories have nontrivial topological actions in different spacetime dimensions. We discover the automorphism symmetry can be extended, become a higher group symmetry, and/or become a non-invertible symmetry. We illustrate the discussion with various models in field theory and on the lattice. In particular, we use automorphism symmetry to construct new transversal non-Clifford logical gates in topological quantum codes. In particular, we show that 2+1d $\\mathbb{Z}_N$ qudit Clifford stabilizer models can implement non-Clifford transversal logical gate in the 4th level $\\mathbb{Z}_N$ qudit Clifford hierarchy for $N\\geq 3$, extending the generalized Bravyi-König bound proposed in the companion paper [arXiv:2511.02900] for qubits."}
{"id": "2511.15811", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.15811", "abs": "https://arxiv.org/abs/2511.15811", "authors": ["Alexander Schwenke", "Wolfram Brenig"], "title": "Magnetostriction in the $J$-$K$-$Γ$ model: Application of the numerical linked cluster expansion", "comment": "10 pages, 5 figures", "summary": "We apply the numerical linked cluster expansion (NLCE) to study thermodynamic properties of the proximate Kitaev magnet $α$-RuCl$_3$ on the honeycomb lattice in the presence of a magnetic field. Using the extended spin-1/2 $J$-$K$-$Γ$ model and based on documented exchange and magnetoelastic coupling parameters, we present results for the internal energy, the specific heat, and the magnetization. Moreover, the linear magnetostriction coefficient perpendicular to the plane is calculated, which is sensitive to changes of the in-plane spin-spin correlations. We find the magnetostriction to display a dip-like feature, in line with the temperature dependent and field-driven suppression of magnetic order in $α$-RuCl$_3$. Our results are consistent with previous findings, establishing NLCE also as a tool to study magnetoelastic features of quantum magnets."}
{"id": "2511.16359", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.16359", "abs": "https://arxiv.org/abs/2511.16359", "authors": ["V. E. Timofeev", "D. A. Bedyaev", "D. N. Aristov"], "title": "Topological transition in spectrum of skyrmion crystal with uniaxial anisotropy", "comment": "6 pages, 5 figures", "summary": "The band structure of elementary excitations of skyrmion crystal in thin ferromagnetic film with Dzyaloshinskii-Moriya interaction and uniaxial magnetic anisotropy under external magnetic field is studied. In the absence of anisotropy there is a topological transition in the spectrum of skyrmion crystal: the gap between breathing and counter-clock-wise modes closes, which is accompanied by changes of Berry curvature sign of these bands. In this work we demonstrate that such topological transition exists in some range of the uniaxial anisotropy values. We present a phase diagram showing that the value of the field of topological transition is higher in the easy-plane domain and lower in the easy-axis domain of anisotropy."}
{"id": "2511.16429", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.16429", "abs": "https://arxiv.org/abs/2511.16429", "authors": ["Arnaud Ralko", "Jaime Merino"], "title": "Order-by-disorder from Schwinger bosons in a frustrated honeycomb ferromagnet", "comment": null, "summary": "The cobalt-based honeycomb magnet BaCo$_2$(AsO$_4$)$_2$ (BCAO) has recently emerged as a promising platform for studying frustrated magnetism beyond conventional paradigms. Neutron-scattering experiments and first-principles calculations have revealed an unexpected double-zigzag (dZZ) magnetically ordered ground state, whose microscopic origin remains under active debate. Here, we investigate the emergence of such dZZ phase in a ferro-antiferromagnetic $J_1$-$J_3$ Heisenberg model on the honeycomb lattice, using a generalized Schwinger boson mean-field theory ($g$-SBMFT) that treats ferromagnetic and antiferromagnetic interactions on equal footing. Based on $g$-SBMFT and exact-diagonalization (ED) techniques, we find that the dZZ is selected by an order-by-disorder mechanism in a narrow $J_3/|J_1|$ range, in agreement with recent density-matrix renormalization-group calculations. The magnetic excitation spectra within the dZZ phase displays a distinctive smearing out in momentum space due to quantum fluctuations which may be probed through inelastic neutron-scattering experiments."}
{"id": "2511.15873", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.15873", "abs": "https://arxiv.org/abs/2511.15873", "authors": ["Shannon Kelley", "Aleksandr M. Kazachkov", "Ted Ralphs"], "title": "Parametric Disjunctive Cuts for Sequences of Mixed Integer Linear Optimization Problems", "comment": null, "summary": "Many applications require solving sequences of related mixed-integer linear programs. We introduce a class of parametric disjunctive inequalities (PDIs), obtained by reusing the disjunctive proofs of optimality from prior solves to construct cuts valid for perturbed instances. We describe several methods of generating such cuts that navigate the tradeoff between computational expense and strength. We provide sufficient conditions under which PDIs support the disjunctive hull and a tightening step that guarantees support when needed. On perturbed instances from MIPLIB 2017, augmenting branch-and-cut with PDIs substantially improves performance, reducing total solve times on the majority of challenging cases."}
{"id": "2511.15960", "categories": ["q-fin.CP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15960", "abs": "https://arxiv.org/abs/2511.15960", "authors": ["Gabriel M. Arantes", "Richard F. Pinto", "Bruno L. Dalmazo", "Eduardo N. Borges", "Giancarlo Lucca", "Viviane L. D. de Mattos", "Fabian C. Cardoso", "Rafael A. Berri"], "title": "Machine Learning vs. Randomness: Challenges in Predicting Binary Options Movements", "comment": "Accepted for publication at the 26th International Conference on Intelligent Data Engineering and Automated Learning (IDEAL 2025)", "summary": "Binary options trading is often marketed as a field where predictive models can generate consistent profits. However, the inherent randomness and stochastic nature of binary options make price movements highly unpredictable, posing significant challenges for any forecasting approach. This study demonstrates that machine learning algorithms struggle to outperform a simple baseline in predicting binary options movements. Using a dataset of EUR/USD currency pairs from 2021 to 2023, we tested multiple models, including Random Forest, Logistic Regression, Gradient Boosting, and k-Nearest Neighbors (kNN), both before and after hyperparameter optimization. Furthermore, several neural network architectures, including Multi-Layer Perceptrons (MLP) and a Long Short-Term Memory (LSTM) network, were evaluated under different training conditions. Despite these exhaustive efforts, none of the models surpassed the ZeroR baseline accuracy, highlighting the inherent randomness of binary options. These findings reinforce the notion that binary options lack predictable patterns, making them unsuitable for machine learning-based forecasting."}
{"id": "2511.15711", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.15711", "abs": "https://arxiv.org/abs/2511.15711", "authors": ["Atena Khoshkonesh", "Mohsen Mohammadagha", "Navid Ebrahimi"], "title": "Integrated 4D/5D Digital-Twin Framework for Cost Estimation and Probabilistic Schedule Control: A Texas Mid-Rise Case Study", "comment": null, "summary": "Persistent cost and schedule overruns in U.S. building projects expose limitations of conventional, document-based estimating and deterministic Critical Path Method (CPM) scheduling, which remain inflexible under uncertainty and lag dynamic field conditions. This study presents an integrated 4D/5D digital-twin framework unifying Building Information Modeling (BIM), natural language processing (NLP), reality capture, computer vision, Bayesian risk modeling, and deep reinforcement learning (DRL) for construction cost and schedule control. The system automates project-control functions by: (a) mapping contract documents to standardized cost items using transformer-based NLP (0.883 weighted F1 score); (b) aligning photogrammetry and LiDAR data with BIM to compute earned value; (c) deriving real-time activity completion from site imagery (0.891 micro accuracy); (d) updating probabilistic CPM forecasts via Bayesian inference and Monte Carlo simulation; (e) using DRL for adaptive resource allocation (75% adoption rate); and (f) providing 4D/5D decision sandbox for predictive analysis. A Texas mid-rise case study demonstrates localized cost adjustment using RSMeans City Cost Index and Bureau of Labor Statistics wage data. Results show 43% reduction in estimating labor, 6% overtime reduction (91 hours), and project completion matching P50 probabilistic forecast of 128 days, confirming improved estimation accuracy and responsiveness."}
{"id": "2511.15739", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15739", "abs": "https://arxiv.org/abs/2511.15739", "authors": ["Floyd M. Creevey", "Lloyd C. L. Hollenberg"], "title": "Genetically Engineered Quantum Circuits for Financial Market Indicators", "comment": null, "summary": "Quantum computing holds immense potential for transforming financial analysis and decision-making. Realising this potential necessitates the efficient encoding and processing of financial data on quantum computers. In this study, we propose using the GASP (Genetic Algorithm for State Preparation) framework to optimise the encoding of stock price data into quantum states and show it can enhance both the fidelity and efficiency of the encoding process. We demonstrate the efficacy of our approach by encoding stock price data onto both a simulated and real quantum computer to calculate the Singular Value Decomposition (SVD) entropy. Our results show improvements in fidelity and the potential for more precise financial analysis. This research provides insights into the applicability of GASP for the efficient encoding of real-world data, specifically stock price data, which is crucial for quantum advantage on noisy intermediate-scale quantum (NISQ) era quantum computers."}
{"id": "2511.15726", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.15726", "abs": "https://arxiv.org/abs/2511.15726", "authors": ["Shalini Jangra", "Zaid Almahmoud", "Suparna De", "Gareth Tyson", "Ehsan Ul Haq", "Nishanth Sastry"], "title": "Understanding the Complexities of Responsibly Sharing NSFW Content Online", "comment": "13 Pages, 7 Figures", "summary": "Reddit is in the minority of mainstream social platforms that permit posting content that may be considered to be at the edge of what is permissible, including so-called Not Safe For Work (NSFW) content. However, NSFW is becoming more common on mainstream platforms, with X now allowing such material. We examine the top 15 NSFW-restricted subreddits by size to explore the complexities of responsibly sharing adult content, aiming to balance ethical and legal considerations with monetization opportunities. We find that users often use NSFW subreddits as a social springboard, redirecting readers to private or specialized adult social platforms such as Telegram, Kik or OnlyFans for further interactions. They also directly negotiate image \"trades\" through credit cards or payment platforms such as PayPal, Bitcoin or Venmo. Disturbingly, we also find linguistic cues linked to non-consensual content sharing. To help platforms moderate such behavior, we trained a RoBERTa-based classification model, which outperforms GPT-4 and traditional classifiers such as logistic regression and random forest in identifying non-consensual content sharing, demonstrating superior performance in this specific task. The source code and trained model weights are publicly available at https://github.com/socsys/15NSFW Subreddits."}
{"id": "2511.15832", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.15832", "abs": "https://arxiv.org/abs/2511.15832", "authors": ["Kadja Flore Gali", "Hamed Fahandezh Sadi", "Jesse C. Anderson", "Payton Beeler", "Aaron Wang", "David Richter", "Raymond A Shaw", "Fan Yang", "Will Cantrell", "Laura Fierce"], "title": "Cloud droplet size distribution and optical properties only weakly linked to aerosol size", "comment": null, "summary": "Changes in aerosol concentrations can modify cloud brightness, producing a strong but poorly constrained influence on Earth's energy balance. Because cloud reflectivity depends on the size distribution of cloud droplets, and aerosol size strongly governs activation into droplets, one might expect cloud properties to be sensitive to aerosol size distributions. Here we show, through a combination of cloud chamber experiments and high-resolution simulations, that cloud microphysical and optical properties are often insensitive to aerosol size. Detectable impacts on cloud optical properties occur only under weak convective forcing and high aerosol concentrations. These results indicate that, in most conditions, cloud reflectivity can be predicted from aerosol number alone without detailed knowledge of aerosol size distributions, providing new constraints on how aerosol perturbations affect climate."}
{"id": "2511.15934", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.15934", "abs": "https://arxiv.org/abs/2511.15934", "authors": ["Danny Smyl"], "title": "Implicit and explicit treatments of model error in numerical simulation", "comment": null, "summary": "Numerical simulations of physical systems invariably suffer from model errors stemming from unmodeled physics, idealizations, and discretization. This article provides a review of techniques developed in the past two decades to approximate and account for these model errors, both implicitly and explicitly. Beginning from fundamental definitions of model-form versus numerical error, we frame model error in inverse problems, data assimilation, and predictive modeling contexts. We then survey major approaches: the Bayesian approximation error framework for implicit error quantification, embedded internal error models for structural uncertainty, probabilistic numerical methods for discretization uncertainty, model discrepancy modeling in Bayesian calibration and its recent extensions, machine-learning-based discrepancy correction, multi-fidelity and hybrid modeling strategies, as well as residual-based, variational, and adjoint-driven error estimators. Throughout, we emphasize conceptual underpinnings of implicit versus explicit error treatment and highlight how these methods improve predictive performance and uncertainty quantification in practical applications ranging from engineering design to Earth-system science. Each section provides an overview of key developments with an extensive list of references to facilitate further reading. The review is written for practitioners of large-scale computational physics and engineering simulation, emphasizing how these methods can be incorporated into PDE solvers, inverse problem workflows, and data assimilation systems."}
{"id": "2511.15889", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.15889", "abs": "https://arxiv.org/abs/2511.15889", "authors": ["Daniele Ravasio", "Bestem Abdulaziz", "Marcello Farina", "Andrea Ballarino"], "title": "Development of a velocity form for a class of RNNs, with application to offset-free nonlinear MPC design", "comment": "14 pages, 3 figures, under review", "summary": "This paper addresses the offset-free tracking problem for nonlinear systems described by a class of recurrent neural networks (RNNs). To compensate for constant disturbances and guarantee offset-free tracking in the presence of model-plant mismatches, we propose a novel reformulation of the RNN model in velocity form. Conditions based on linear matrix inequalities are then derived for the design of a nonlinear state observer and a nonlinear state-feedback controller, ensuring global or regional closed-loop stability of the origin of the velocity form dynamics. Moreover, to handle input and output constraints, a theoretically sound offset-free nonlinear model predictive control algorithm is developed. The algorithm exploits the velocity form model as the prediction model and the static controller as an auxiliary law for the definition of the terminal ingredients. Simulations on a pH-neutralisation process benchmark demonstrate the effectiveness of the proposed approach."}
{"id": "2511.16557", "categories": ["cs.ET", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16557", "abs": "https://arxiv.org/abs/2511.16557", "authors": ["Asmita S. Thool", "Sourodeep Roy", "Prahalad Kanti Barman", "Kartick Biswas", "Pavan Nukala", "Abhishek Misra", "Saptarshi Das", "and Bhaswar Chakrabarti"], "title": "Interfacial and bulk switching MoS2 memristors for an all-2D reservoir computing framework", "comment": null, "summary": "In this study, we design a reservoir computing (RC) network by exploiting short- and long-term memory dynamics in Au/Ti/MoS$_2$/Au memristive devices. The temporal dynamics is engineered by controlling the thickness of the Chemical Vapor Deposited (CVD) MoS$_2$ films. Devices with a monolayer (1L)-MoS$_2$ film exhibit volatile (short-term memory) switching dynamics. We also report non-volatile resistance switching with excellent uniformity and analog behavior in conductance tuning for the multilayer (ML) MoS$_2$ memristive devices. We correlate this performance with trap-assisted space-charge limited conduction (SCLC) mechanism, leading to a bulk-limited resistance switching behavior. Four-bit reservoir states are generated using volatile memristors. The readout layer is implemented with an array of nonvolatile synapses. This small RC network achieves 89.56\\% precision in a spoken-digit recognition task and is also used to analyze a nonlinear time series equation."}
{"id": "2511.15841", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.15841", "abs": "https://arxiv.org/abs/2511.15841", "authors": ["Yizhe Ding", "Runze Li", "Lingzhou Xue"], "title": "New Empirical Process Tools and Their Applications to Robust Deep ReLU Networks and Phase Transitions for Nonparametric Regression", "comment": null, "summary": "This paper introduces new empirical process tools for analyzing a broad class of statistical learning models under heavy-tailed noise and complex function classes. Our primary contribution is the derivation of two Dudley-type maximal inequalities for expected empirical processes that remove restrictive assumptions such as light tails and uniform boundedness of the function class. These inequalities enlarge the scope of empirical process theory available for statistical learning and nonparametric estimation. Exploiting the new bounds, we establish robustness guarantees for deep ReLU network estimators in Huber and quantile regression. In particular, we prove a unified non-asymptotic sub-Gaussian concentration bound that remains valid even under infinite-variance noise and provide a comprehensive analysis of non-asymptotic robustness for deep Huber estimators across all noise regimes. For deep quantile regression, we provide the first non-asymptotic sub-Gaussian bounds without requiring moment assumptions. As an additional application, our framework yields estimation error bounds for nonparametric least-squares estimators that simultaneously accommodate infinite-variance noise, non-Donsker function classes, and approximation error. Moreover, unlike prior approaches based on specialized multiplier processes, our framework extends to broader empirical risk minimization problems, including the nonparametric generalized linear models and the ``set-structured'' models."}
{"id": "2511.15845", "categories": ["cond-mat.stat-mech", "cond-mat.soft", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2511.15845", "abs": "https://arxiv.org/abs/2511.15845", "authors": ["Shaon Mandal Chakraborty", "Bibhut Sahoo", "Rituparno Mandal", "Peter Sollich"], "title": "Effects of Non-reciprocity on Coupled Kuramoto Oscillators", "comment": "10 pages, 8 figures", "summary": "All the fundamental interactions (such as gravity or electromagnetic interactions) are reciprocal in nature. However, in the macroscopic world, in particular outside equilibrium, non-reciprocal or non-mutual interactions are quite ubiquitous. Understanding the impact of such non-reciprocal interactions has drawn a significant amount of interest in physics and other fields of sciences in recent years. We explore a non-reciprocal version of coupled oscillators (known as the Kuramoto model) with the aim of understanding the role of non-reciprocity, particularly in relation to chimera states, where oscillators spontaneously break into mutually synchronous and asynchronous groups. Our findings suggest that non-reciprocity not only alters the state diagram of the chimera state significantly but can also lead to new dynamical states, such as traveling chimera, run-and-chase and coexistence phases."}
{"id": "2511.15889", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.15889", "abs": "https://arxiv.org/abs/2511.15889", "authors": ["Daniele Ravasio", "Bestem Abdulaziz", "Marcello Farina", "Andrea Ballarino"], "title": "Development of a velocity form for a class of RNNs, with application to offset-free nonlinear MPC design", "comment": "14 pages, 3 figures, under review", "summary": "This paper addresses the offset-free tracking problem for nonlinear systems described by a class of recurrent neural networks (RNNs). To compensate for constant disturbances and guarantee offset-free tracking in the presence of model-plant mismatches, we propose a novel reformulation of the RNN model in velocity form. Conditions based on linear matrix inequalities are then derived for the design of a nonlinear state observer and a nonlinear state-feedback controller, ensuring global or regional closed-loop stability of the origin of the velocity form dynamics. Moreover, to handle input and output constraints, a theoretically sound offset-free nonlinear model predictive control algorithm is developed. The algorithm exploits the velocity form model as the prediction model and the static controller as an auxiliary law for the definition of the terminal ingredients. Simulations on a pH-neutralisation process benchmark demonstrate the effectiveness of the proposed approach."}
{"id": "2511.16446", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.16446", "abs": "https://arxiv.org/abs/2511.16446", "authors": ["Yun Chen", "Haojie Shen", "Wei Su", "Rui Wang"], "title": "Multi-scale competition in the Majorana-Kondo system", "comment": "11 pages, 4 figures", "summary": "A side-coupled Majorana zero mode in Kondo systems realizes a simple yet nontrivial hybridization that profoundly alters the low-energy physics, making such setups promising candidates for detecting Majorana zero modes. Recently, we demonstrated that the low-energy behavior of this system can be captured by a spin-charge-entangled screening process with an \\(A\\otimes N\\) boundary condition. Here, we investigate the evolution of both the screening cloud and the boundary condition in the presence of competing terms that could break either the spin-charge-entangled \\({\\rm SU}_{\\bf L}(2)\\) rotation symmetry or the topological degeneracy. We introduce a temperature-dependent spatial integral of the screening cloud, which can be obtained from the numerical renormalization group. This quantity serves as a proper observable that unambiguously captures the properties of the screening process across temperatures. A clear crossover from conventional Kondo spin screening to spin-charge-entangled screening is observed. Taking into account the overlap between Majorana zero modes, the \\(A\\otimes N\\) boundary condition reduces to a normal one, yet the spin-charge-entangled screening is protected by the \\({\\rm SU}_{\\bf L}(2)\\) symmetry. On the other hand, perturbation that breaks the \\({\\rm SU}_{\\bf L}(2)\\) symmetry can destroy the screening singlet, while leaving the low-temperature \\(A\\otimes N\\) boundary condition intact."}
{"id": "2511.16007", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.16007", "abs": "https://arxiv.org/abs/2511.16007", "authors": ["Wang Zhong-bao", "Zhang Zhong-cheng"], "title": "Single-loop variance reduction methods in Bregman setups for finite-sum structured variational inequalities", "comment": null, "summary": "In this paper, we address variational inequalities (VI) with a finite sum structure by proposing a novel single-loop variance-reduced algorithm that incorporates the Bregman distance. Under the monotone setting, we establish the almost sure convergence of the proposed algorithm and prove that it achieves the optimal complexity of $\\mathcal{O}\\left(\\frac{\\sqrt{M}}{\\varepsilon }\\right)$ for finding an $\\varepsilon$-gap. Furthermore, under the non-monotone setting, we derive a complexity of $\\mathcal{O}\\left(\\frac{1}{\\varepsilon^2 }\\right)$ of the algorithm. Our proposed method yields complexity results that either match or improve the state-of-the-art complexity bounds reported in existing literature. Notably, this work is the first to rigorously establish the linear convergence rate of the algorithm for solving finite-sum variational inequalities in Bregman setups. Finally, we report two numerical experiments to validate the effectiveness and practical performance of our method."}
{"id": "2511.15870", "categories": ["cs.CE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15870", "abs": "https://arxiv.org/abs/2511.15870", "authors": ["Qiming Guo", "Bishal Khatri", "Wenbo Sun", "Jinwen Tang", "Hua Zhang", "Wenlu Wang"], "title": "AquaSentinel: Next-Generation AI System Integrating Sensor Networks for Urban Underground Water Pipeline Anomaly Detection via Collaborative MoE-LLM Agent Architecture", "comment": "7 pages, 1 figure, 2 tables, Accepted to the 40th AAAI Conference on Artificial Intelligence (AAAI 2026), IAAI Deployed Applications Track", "summary": "Underground pipeline leaks and infiltrations pose significant threats to water security and environmental safety. Traditional manual inspection methods provide limited coverage and delayed response, often missing critical anomalies. This paper proposes AquaSentinel, a novel physics-informed AI system for real-time anomaly detection in urban underground water pipeline networks. We introduce four key innovations: (1) strategic sparse sensor deployment at high-centrality nodes combined with physics-based state augmentation to achieve network-wide observability from minimal infrastructure; (2) the RTCA (Real-Time Cumulative Anomaly) detection algorithm, which employs dual-threshold monitoring with adaptive statistics to distinguish transient fluctuations from genuine anomalies; (3) a Mixture of Experts (MoE) ensemble of spatiotemporal graph neural networks that provides robust predictions by dynamically weighting model contributions; (4) causal flow-based leak localization that traces anomalies upstream to identify source nodes and affected pipe segments. Our system strategically deploys sensors at critical network junctions and leverages physics-based modeling to propagate measurements to unmonitored nodes, creating virtual sensors that enhance data availability across the entire network. Experimental evaluation using 110 leak scenarios demonstrates that AquaSentinel achieves 100% detection accuracy. This work advances pipeline monitoring by demonstrating that physics-informed sparse sensing can match the performance of dense deployments at a fraction of the cost, providing a practical solution for aging urban infrastructure."}
{"id": "2511.15802", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15802", "abs": "https://arxiv.org/abs/2511.15802", "authors": ["C. Weeks", "P. Strange", "P. Drmota", "J. Quintanilla"], "title": "Quantum-Assisted Graph Domination Games", "comment": "14 pages (including appendix), 5 figures, 4 tables (including appendix)", "summary": "We study quantum advantage in the 1-step graph domination game on cycle graphs numerically, analytically and through the use of Noisy intermediate scale quantum (NISQ) processors. We find explicit strategies that realise the recently found upper bounds for small graphs and generalise them to larger cycles. We demonstrate that NISQ computers realise the predicted quantum advantages with high accuracy."}
{"id": "2511.15774", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.15774", "abs": "https://arxiv.org/abs/2511.15774", "authors": ["S M Mehedi Zaman", "Kiran Garimella"], "title": "Disagreement is Disappearing on U.S. Cable Debate Shows", "comment": "Accepted at the International AAAI Conference on Web and Social Media (ICWSM 2026)", "summary": "Prime-time cable news programs are a highly influential part of the American media landscape, with top-rated opinion shows attracting millions of politically attentive viewers each night. In an era of intense political polarization, a critical question is whether these widely-watched \"debate\" shows foster genuine discussion or have devolved into partisan echo chambers that deepen societal divides. While these programs claim to air competing viewpoints, no large-scale evidence exists to quantify how often hosts and guests actually disagree. Measuring these exchanges is a significant challenge, as live broadcasts contain overlapping speakers, sarcasm, and billions of words of text. To address this gap, we construct the first speaker-resolved map of agreement and disagreement across U.S. cable opinion programming. Our study assembles over 21,000 episodes from 24 flagship shows on Fox News, MSNBC, and CNN from 2010-2024, segmenting them into host-guest turns and labeling 2.13 million turn-pairs using a high-fidelity large-language-model classifier. We present three findings: (1) the proportion of disagreement/debate on prime time shows a consistent downward trend, dropping by roughly one-third between 2017 and 2024; (2) on-air challenge is partisan and asymmetric--conservatives seldom face push-back on Fox, liberals seldom on MSNBC, with CNN declining toward the midpoint; and (3) polarizing issues such as abortion, gun rights, and immigration attract the least disagreement. The work contributes a public corpus, an open-source stance pipeline, and the first longitudinal evidence that televised \"debate\" is retreating from genuine discussion. By transforming into platforms for partisan affirmation, these shows erode the cross-cutting cleavages essential for a pluralistic society, thereby intensifying affective polarization."}
{"id": "2511.16441", "categories": ["physics.comp-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2511.16441", "abs": "https://arxiv.org/abs/2511.16441", "authors": ["Jianing Zhang", "Rumei Liu"], "title": "A physics-inspired momentum-based gradient method", "comment": null, "summary": "In this work, a nonlinear momentum method is introduced to improve the convergence performance of momentum-based gradient optimization algorithms. The method is motivated by the dynamics of non-Newtonian mechanical systems, where conventional momentum schemes can be interpreted as a dynamical model with quadratic kinetic energy and linear damping. Based on this analogy, a generalized optimization dynamics is constructed by extending the kinetic energy formulation and incorporating a nonlinear damping term. An anharmonic kinetic energy function can be employed to represent the inertial effect of accumulated gradient information during the iterations, while the nonlinear damping mechanism enables a more flexible control of the momentum contribution along the convergence trajectory. Numerical experiments indicate that the method exhibits faster convergence and higher robustness compared to classical momentum algorithms. Moreover, its strong performance on nonconvex objectives makes it particularly suitable for inverse photonic design problems. The results suggest that dynamical systems from physics can provide a view towards the development of efficient optimization methods."}
{"id": "2511.15925", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.15925", "abs": "https://arxiv.org/abs/2511.15925", "authors": ["Yashar Mousavi", "Mahsa Tavasoli", "Ibrahim Beklan Kucukdemiral", "Umit Cali", "Abdolhossein Sarrafzadeh", "Ali Karimoddini", "Afef Fekih"], "title": "Cyber-Resilient Data-Driven Event-Triggered Secure Control for Autonomous Vehicles Under False Data Injection Attacks", "comment": "14 pages, 8 figures", "summary": "This paper proposes a cyber-resilient secure control framework for autonomous vehicles (AVs) subject to false data injection (FDI) threats as actuator attacks. The framework integrates data-driven modeling, event-triggered communication, and fractional-order sliding mode control (FSMC) to enhance the resilience against adversarial interventions. A dynamic model decomposition (DMD)-based methodology is employed to extract the lateral dynamics from real-world data, eliminating the reliance on conventional mechanistic modeling. To optimize communication efficiency, an event-triggered transmission scheme is designed to reduce the redundant transmissions while ensuring system stability. Furthermore, an extended state observer (ESO) is developed for real-time estimation and mitigation of actuator attack effects. Theoretical stability analysis, conducted using Lyapunov methods and linear matrix inequality (LMI) formulations, guarantees exponential error convergence. Extensive simulations validate the proposed event-triggered secure control framework, demonstrating substantial improvements in attack mitigation, communication efficiency, and lateral tracking performance. The results show that the framework effectively counteracts actuator attacks while optimizing communication-resource utilization, making it highly suitable for safety-critical AV applications."}
{"id": "2511.16389", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.16389", "abs": "https://arxiv.org/abs/2511.16389", "authors": ["Melanie Birke", "Tim Greger"], "title": "Bias Reduction for nonparametric Estimators applied to functional Data Analysis", "comment": null, "summary": "Compared to nonparametric estimators in the multivariate setting, kernel estimators for functional data models have a larger order of bias. This is problematic for constructing confidence regions or statistical tests since the bias might not be negligible. It stems from the fact that one sided kernels are used where already the first moment of the kernel is different from 0. It cannot be cured by assuming the existence of higher order derivatives. In the following, we propose bias corrected estimators based on the idea in \\cite{Cheng2018} which still have an appealing structure, but have a bias of smaller order as in multiple regression settings while the variance is of the same order of magnitude as before. In addition we show asymptotic normality of such estimators and derive uniform rates. The performance of the estimator in finite samples is in addition checked in a simulation study."}
{"id": "2511.15901", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.15901", "abs": "https://arxiv.org/abs/2511.15901", "authors": ["Mário J. de Oliveira"], "title": "Boltzmann-Kolmogorov equation", "comment": null, "summary": "We investigate the properties of a Kolmogorov equation governing the time evolution of the probability distribution defined in phase space. Energy is strictly conserved along a trajectory in phase space, meaning the equation is appropriate to describe an isolated system, and the stationary state is the Gibbs microcanonical distribution. The equation predicts the increase in entropy in agreement with thermodynamics, and in contrast with the Liouville equation, which conserves entropy. Using an approximation in which the distribution is a product of one-particle distributions, we derive the Boltzmann equation of kinetic theory. We also consider a Kolmogorov equation to describe an open system in contact with the external environment. In this case the equation describes not only the situation in which the system is found in thermodynamic equilibrium with a Gibbs canonical distribution in the stationary state, but also the nonequilibrium steady state with a continuous production of entropy."}
{"id": "2511.15925", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.15925", "abs": "https://arxiv.org/abs/2511.15925", "authors": ["Yashar Mousavi", "Mahsa Tavasoli", "Ibrahim Beklan Kucukdemiral", "Umit Cali", "Abdolhossein Sarrafzadeh", "Ali Karimoddini", "Afef Fekih"], "title": "Cyber-Resilient Data-Driven Event-Triggered Secure Control for Autonomous Vehicles Under False Data Injection Attacks", "comment": "14 pages, 8 figures", "summary": "This paper proposes a cyber-resilient secure control framework for autonomous vehicles (AVs) subject to false data injection (FDI) threats as actuator attacks. The framework integrates data-driven modeling, event-triggered communication, and fractional-order sliding mode control (FSMC) to enhance the resilience against adversarial interventions. A dynamic model decomposition (DMD)-based methodology is employed to extract the lateral dynamics from real-world data, eliminating the reliance on conventional mechanistic modeling. To optimize communication efficiency, an event-triggered transmission scheme is designed to reduce the redundant transmissions while ensuring system stability. Furthermore, an extended state observer (ESO) is developed for real-time estimation and mitigation of actuator attack effects. Theoretical stability analysis, conducted using Lyapunov methods and linear matrix inequality (LMI) formulations, guarantees exponential error convergence. Extensive simulations validate the proposed event-triggered secure control framework, demonstrating substantial improvements in attack mitigation, communication efficiency, and lateral tracking performance. The results show that the framework effectively counteracts actuator attacks while optimizing communication-resource utilization, making it highly suitable for safety-critical AV applications."}
{"id": "2511.16252", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2511.16252", "abs": "https://arxiv.org/abs/2511.16252", "authors": ["Tommaso Trabocchi", "Raffaella Burioni", "Lucilla de Arcangelis", "Duccio Fanelli"], "title": "Generalized Wilson-Cowan model with short term synaptic plasticity", "comment": null, "summary": "A generalized version of the Wilson-Cowan (WC) model is proposed which accounts for the evolution of the synaptic resources. Adiabatic elimination of the fast variables is performed to yield a simplified framework for the coupled interaction between active excitatory and inhibitory neurons. The latter model is shown to smoothly converge to the benchmark WC model, when the appropriate limit is performed. Different dynamical regimes are identified for the reduced model and commented upon with reference to the original formulation of the generalized dynamics. This includes identifying limit cycle oscillations for population of available resources."}
{"id": "2511.16496", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.16496", "abs": "https://arxiv.org/abs/2511.16496", "authors": ["Rintaro Masaoka"], "title": "$c=-2$ conformal field theory in quadratic band touching", "comment": null, "summary": "Quadratic band touching in fermionic systems defines a universality class distinct from that of linear Dirac points, yet its characterization as a quantum critical point remains incomplete. In this work, I show that a $(d+1)$-dimensional free-fermion model with quadratic band touching exhibits spatial conformal invariance, and that its equal-time ground-state correlation functions are exactly captured by the $d$-dimensional symplectic fermion theory. I establish this correspondence by constructing explicit mappings between physical fermionic operators and the fields of the symplectic fermion theory. I further explore the implications of this correspondence in two spatial dimensions, where the symplectic fermion theory is a logarithmic conformal field theory with central charge $c=-2$. In the corresponding $(2+1)$-dimensional systems, I identify anyonic excitations originating from the underlying symplectic fermion theory, even though the Hamiltonian is gapless. Transporting these excitations along non-contractible loops generates transitions among topologically degenerate ground states, in close analogy with those in topologically ordered phases. Moreover, the action of a $2π$ rotation on these excitations is represented by a Jordan block, reflecting the logarithmic character of the associated conformal field theory."}
{"id": "2511.16008", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.16008", "abs": "https://arxiv.org/abs/2511.16008", "authors": ["Masashi Wakaiki"], "title": "Data informativity for stabilization of discrete-time infinite-dimensional systems", "comment": "19 pages", "summary": "This paper develops a data-driven framework for stabilization of discrete-time infinite-dimensional systems. We investigate informativity for stabilization, defined as the existence of a feedback gain that stabilizes all systems compatible with the available input-state data. Assuming that infinite-length data are Bessel sequences, we first establish a sufficient condition for data informativity in the noise-free case. We next show that this sufficient condition is also necessary under a mild data assumption when the input space is one-dimensional. Furthermore, if the state sequence forms a frame, then the sufficient condition can be extended to the case of noisy data. Finally, when the unstable part of the true system is known to be finite-dimensional, we derive a necessary and sufficient condition for data informativity of finite-length data."}
{"id": "2511.15970", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2511.15970", "abs": "https://arxiv.org/abs/2511.15970", "authors": ["Junhao Wei", "Yanzhao Gu", "Ran Zhang", "Yanxiao Li", "Wenxuan Zhu", "Yapeng Wang", "Xu Yang", "Ngai Cheong"], "title": "An Enhanced Whale Optimization Algorithm with Log-Normal Distribution for Optimizing Coverage of Wireless Sensor Networks", "comment": null, "summary": "Wireless Sensor Networks (WSNs) are essential for monitoring and communication in complex environments, where coverage optimization directly affects performance and energy efficiency. However, traditional algorithms such as the Whale Optimization Algorithm (WOA) often suffer from limited exploration and premature convergence. To overcome these issues, this paper proposes an enhanced WOA which is called GLNWOA. GLNWOA integrates a log-normal distribution model into WOA to improve convergence dynamics and search diversity. GLNWOA employs a Good Nodes Set initialization for uniform population distribution, a Leader Cognitive Guidance Mechanism for efficient information sharing, and an Enhanced Spiral Updating Strategy to balance global exploration and local exploitation. Tests on benchmark functions verify its superior convergence accuracy and robustness. In WSN coverage optimization, deploying 25 nodes in a 60 m $\\times$ 60 m area achieved a 99.0013\\% coverage rate, outperforming AROA, WOA, HHO, ROA, and WOABAT by up to 15.5\\%. These results demonstrate that GLNWOA offers fast convergence, high stability, and excellent optimization capability for intelligent network deployment."}
{"id": "2511.15805", "categories": ["quant-ph", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2511.15805", "abs": "https://arxiv.org/abs/2511.15805", "authors": ["Jieqiu Shao", "Diego A. R. Dalvit", "Lukasz Cincio", "Bharath Hebbe Madhusudhana"], "title": "Engineering multi-mode bosonic squeezed states using Monte-Carlo optimization", "comment": "13 pages, 5 figures", "summary": "Bosonic systems, such as photons and ultracold atoms, have played a central role in demonstrating quantum-enhanced sensing. Quantum entanglement, through squeezed and GHZ states, enables sensing beyond classical limits. However, such a quantum advantage has so far been confined to two-mode bosonic systems, as analogous multi-mode squeezed states are non-trivial to prepare. Here, we develop a Monte-Carlo based optimization technique which can be used to efficiently engineer a Hamiltonian control-sequence for multi-mode bosonic systems to prepare multi-mode squeezed states. Specifically, we consider a Bose-Einstein condensate in an optical lattice, relevant for applications in gravimetry and gradiometry, and demonstrate that metrologically useful squeezed states can be generated using the Bose-Hubbard Hamiltonian which includes on-site atomic interactions, tunable via Feshbach resonances. By analyzing the distribution (density) of the quantum Fisher information (QFI) over the Hilbert space, we identify a characteristic \\textit{intermediate scaling} of the QFI: $\\mathcal{O}(N^2 L+L^2 N)$, which lies between the standard quantum limit (SQL) and the Heisenberg limit (HL) for $N$ atoms in $L$ modes. We show that in general, within the Hilbert space there is a finite, $\\mathcal{O}(1)$ measure subset of Hilbert space with an intermediate QFI scaling. Therefore, one can find a Hamiltonian control sequence using a Monte Carlo optimization over random control sequences, that produces a state with intermediate scaling of the QFI. We assume an experimentally accessible range of the control parameters in the Hamiltonian resources and show that the intermediate scaling can be readily achieved. Our results indicate that the HL can be approached in quantum gravimetry using realistic experimental parameters for systems with $L=\\mathcal{O}(1)$ and $N\\gg L$."}
{"id": "2511.16068", "categories": ["cs.SI", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.16068", "abs": "https://arxiv.org/abs/2511.16068", "authors": ["Jilong Shi", "Qiuyan Yan", "Xiaobin Rui", "Zhixiao Wang"], "title": "Time-Critical Adversarial Influence Blocking Maximization", "comment": null, "summary": "Adversarial Influence Blocking Maximization (AIBM) aims to select a set of positive seed nodes that propagate synchronously with the known negative seed nodes on the graph to counteract their negative influence. Currently, most AIBM studies are based on the classical Independent Cascade (IC) model, which omits the time factor and thus hinders their applications to time-critical scenarios like political campaigns or public emergencies. More importantly, existing AIBM studies have not investigated in-depth the submodularity of the objective function, resulting in their failure to provide a theoretical lower bound for the problem. To address these challenges, firstly, this paper proposes the Time-Critical Independent Cascade (TC-IC) model, which incorporates time constraints into the classical IC model. Secondly, the Time-Critical Adversarial Influence Blocking Maximization (TC-AIBM) is established to better handle time-critical scenarios. A detailed formulation of the problem is then presented, along with a theoretical proof of its submodularity under three different tie-breaking rules. Finally, a Bidirectional Influence Sampling (BIS) algorithm is proposed to solve the TC-AIBM problem. The submodularity of the objective function guarantees that the BIS can provide an approximation guarantee of\n  to the optimal solution. Comprehensive experiments on four real-world datasets demonstrated that the proposed BIS algorithm exhibits excellent stability with various negative seeds, time constraints, and tie-breaking rules, outperforming state-of-the-art baselines. In addition, BIS improves efficiency by up to three orders of magnitude compared to the Greedy algorithm."}
{"id": "2511.16614", "categories": ["physics.comp-ph", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2511.16614", "abs": "https://arxiv.org/abs/2511.16614", "authors": ["A. Albert", "S. Alves", "M. André", "M. Ardid", "S. Ardid", "J. -J. Aubert", "J. Aublin", "B. Baret", "S. Basa", "Y. Becherini", "B. Belhorma", "F. Benfenati", "V. Bertin", "S. Biagi", "J. Boumaaza", "M. Bouta", "M. C. Bouwhuis", "H. Brânzaş", "R. Bruijn", "J. Brunner", "J. Busto", "B. Caiffi", "D. Calvo", "S. Campion", "A. Capone", "F. Carenini", "J. Carr", "V. Carretero", "T. Cartraud", "S. Celli", "L. Cerisy", "M. Chabab", "R. Cherkaoui El Moursli", "T. Chiarusi", "M. Circella", "J. A. B. Coelho", "A. Coleiro", "R. Coniglione", "P. Coyle", "A. Creusot", "A. F. Díaz", "B. De Martino", "C. Distefano", "I. Di Palma", "C. Donzaud", "D. Dornic", "D. Drouhin", "T. Eberl", "A. Eddymaoui", "T. van Eeden", "D. van Eijk", "S. El Hedri", "N. El Khayati", "A. Enzenhöfer", "P. Fermani", "G. Ferrara", "F. Filippini", "L. Fusco", "S. Gagliardini", "J. García-Méndez", "C. Gatius Oliver", "P. Gay", "N. Geißelbrecht", "H. Glotin", "R. Gozzini", "R. Gracia Ruiz", "K. Graf", "C. Guidi", "L. Haegel", "H. van Haren", "A. J. Heijboer", "Y. Hello", "L. Hennig", "J. J. Hernández-Rey", "J. Hößl", "F. Huang", "G. Illuminati", "B. Jisse-Jung", "M. de Jong", "P. de Jong", "M. Kadler", "O. Kalekin", "U. Katz", "A. Kouchner", "I. Kreykenbohm", "V. Kulikovskiy", "R. Lahmann", "M. Lamoureux", "A. Lazo", "D. Lefèvre", "E. Leonora", "G. Levi", "S. Le Stum", "S. Loucatos", "J. Manczak", "M. Marcelin", "A. Margiotta", "A. Marinelli", "J. A. Martínez-Mora", "P. Migliozzi", "A. Moussa", "R. Muller", "S. Navas", "E. Nezri", "B. Ó Fearraigh", "E. Oukacha", "A. M. Păun", "G. E. Păvălaş", "S. Peña-Martínez", "M. Perrin-Terrin", "P. Piattelli", "C. Poiré", "V. Popa", "T. Pradier", "N. Randazzo", "D. Real", "G. Riccobene", "A. Romanov", "A. Sánchez Losa", "A. Saina", "F. Salesa Greus", "D. F. E. Samtleben", "M. Sanguineti", "P. Sapienza", "F. Schüssler", "J. Seneca", "M. Spurio", "Th. Stolarczyk", "M. Taiuti", "Y. Tayalati", "B. Vallage", "G. Vannoye", "V. Van Elewyck", "S. Viola", "D. Vivolo", "J. Wilms", "S. Zavatarelli", "A. Zegarelli", "J. D. Zornoza", "J. Zúñiga"], "title": "Deep Learning Framework for Enhanced Neutrino Reconstruction of Single-line Events in the ANTARES Telescope", "comment": null, "summary": "We present the $N$-fit algorithm designed to improve the reconstruction of neutrino events detected by a single line of the ANTARES underwater telescope, usually associated with low energy neutrino events ($\\sim$ 100 GeV). $N$-Fit is a neural network model that relies on deep learning and combines several advanced techniques in machine learning --deep convolutional layers, mixture density output layers, and transfer learning. This framework divides the reconstruction process into two dedicated branches for each neutrino event topology --tracks and showers-- composed of sub-models for spatial estimation --direction and position-- and energy inference, which later on are combined for event classification. Regarding the direction of single-line events, the $N$-Fit algorithm significantly refines the estimation of the zenithal angle, and delivers reliable azimuthal angle predictions that were previously unattainable with traditional $χ^2$-fit methods. Improving on energy estimation of single-line events is a tall order; $N$-Fit benefits from transfer learning to efficiently integrate key characteristics, such as the estimation of the closest distance from the event to the detector. $N$-Fit also takes advantage from transfer learning in event topology classification by freezing convolutional layers of the pretrained branches. Tests on Monte Carlo simulations and data demonstrate a significant reduction in mean and median absolute errors across all reconstructed parameters. The improvements achieved by $N$-Fit highlight its potential for advancing multimessenger astrophysics and enhancing our ability to probe fundamental physics beyond the Standard Model using single-line events from ANTARES data."}
{"id": "2511.15952", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.15952", "abs": "https://arxiv.org/abs/2511.15952", "authors": ["Chengyu Li", "Saleh Faghfoorian", "Ivan Ruchkin"], "title": "What Does It Take to Get Guarantees? Systematizing Assumptions in Cyber-Physical Systems", "comment": null, "summary": "Formal guarantees for cyber-physical systems (CPS) rely on diverse assumptions. If satisfied, these assumptions enable the transfer of abstract guarantees into real-world assurances about the deployed CPS. Although assumptions are central to assured CPS, there is little systematic knowledge about what assumptions are made, what guarantees they support, and what it would take to specify them precisely. To fill this gap, we present a survey of assumptions and guarantees in the control, verification, and runtime assurance areas of CPS literature. From 104 papers over a 10-year span (2014-2024), we extracted 423 assumptions and 321 guarantees using grounded-theory coding. We also annotated the assumptions with 21 tags indicating elementary language features needed for specifications. Our analysis highlighted prevalent trends and gaps in CPS assumptions, particularly related to initialization, sensing, perception, neural components, and uncertainty. Our observations culminated in a call to action on reporting and testing CPS assumptions."}
{"id": "2511.15769", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.15769", "abs": "https://arxiv.org/abs/2511.15769", "authors": ["Jared N. Lakhani"], "title": "Models with Accelerated Failure Conditionals", "comment": "26 pages, 3 figures, 7 tables", "summary": "Arnold and Arvanitis (2020) introduced a novel bivariate conditionally specified distribution, a distribution in which dependence between two random variables is established by defining the distribution of one variable conditional on the other. This novel conditioning regime was achieved through the use of survival functions, and the approach was termed the accelerated failure conditionals model. In their work, the conditioning framework was constructed using the exponential distribution. Although further generalization was proposed, challenges emerged in deriving the necessary and sufficient conditions for valid joint survival functions. The present study achieves such generalization, extending the conditioning framework to encompass distributional families whose marginal densities may exhibit unimodality and skewness, moving beyond distributional families whose marginal densities are non-increasing. The resulting models are fully specified through closed-form expressions for their moments, with simulations implemented using either a copula-based procedure or the Metropolis-Hastings algorithm. Empirical applications to two datasets, each featuring variables which are unimodal and skewed, demonstrate that the models with flexible, non-monotonic marginal densities yield a superior fit relative to those models with marginal densities restricted to monotonically decaying forms."}
{"id": "2511.16234", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.16234", "abs": "https://arxiv.org/abs/2511.16234", "authors": ["Annika Vonhusen", "Sören Schweers", "Artem Ryabov", "Philipp Maass"], "title": "Nonequilibrium phase transition in single-file transport at high crowding", "comment": "6 pages, 4 figures", "summary": "Driven particle transport in crowded and confining environments is fundamental to diverse phenomena across physics, chemistry, and biology. A main objective in studying such systems is to identify novel emergent states and phases of collective dynamics. Here, we report on a nonequilibrium phase transition occurring in periodic structures at high particle densities. This transition separates a weak-current phase of thermally activated transport from a high-current phase of solitary wave propagation. It is reflected also in a change of universality classes characterizing correlations of particle current fluctuations. Our findings demonstrate that sudden changes to high current states can occur when increasing particle densities beyond critical values."}
{"id": "2511.15952", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.15952", "abs": "https://arxiv.org/abs/2511.15952", "authors": ["Chengyu Li", "Saleh Faghfoorian", "Ivan Ruchkin"], "title": "What Does It Take to Get Guarantees? Systematizing Assumptions in Cyber-Physical Systems", "comment": null, "summary": "Formal guarantees for cyber-physical systems (CPS) rely on diverse assumptions. If satisfied, these assumptions enable the transfer of abstract guarantees into real-world assurances about the deployed CPS. Although assumptions are central to assured CPS, there is little systematic knowledge about what assumptions are made, what guarantees they support, and what it would take to specify them precisely. To fill this gap, we present a survey of assumptions and guarantees in the control, verification, and runtime assurance areas of CPS literature. From 104 papers over a 10-year span (2014-2024), we extracted 423 assumptions and 321 guarantees using grounded-theory coding. We also annotated the assumptions with 21 tags indicating elementary language features needed for specifications. Our analysis highlighted prevalent trends and gaps in CPS assumptions, particularly related to initialization, sensing, perception, neural components, and uncertainty. Our observations culminated in a call to action on reporting and testing CPS assumptions."}
{"id": "2511.15769", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.15769", "abs": "https://arxiv.org/abs/2511.15769", "authors": ["Jared N. Lakhani"], "title": "Models with Accelerated Failure Conditionals", "comment": "26 pages, 3 figures, 7 tables", "summary": "Arnold and Arvanitis (2020) introduced a novel bivariate conditionally specified distribution, a distribution in which dependence between two random variables is established by defining the distribution of one variable conditional on the other. This novel conditioning regime was achieved through the use of survival functions, and the approach was termed the accelerated failure conditionals model. In their work, the conditioning framework was constructed using the exponential distribution. Although further generalization was proposed, challenges emerged in deriving the necessary and sufficient conditions for valid joint survival functions. The present study achieves such generalization, extending the conditioning framework to encompass distributional families whose marginal densities may exhibit unimodality and skewness, moving beyond distributional families whose marginal densities are non-increasing. The resulting models are fully specified through closed-form expressions for their moments, with simulations implemented using either a copula-based procedure or the Metropolis-Hastings algorithm. Empirical applications to two datasets, each featuring variables which are unimodal and skewed, demonstrate that the models with flexible, non-monotonic marginal densities yield a superior fit relative to those models with marginal densities restricted to monotonically decaying forms."}
{"id": "2511.16033", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.16033", "abs": "https://arxiv.org/abs/2511.16033", "authors": ["Xuelian Wen", "Qiuqi Li", "Juan Zhang"], "title": "Data-driven Model Reduction for Parameter-Dependent Matrix Equations via Operator Inference", "comment": "20 pages, 11 figures, focusing on data-driven model reduction for parametric matrix equations", "summary": "This work develops a non-intrusive, data-driven surrogate modeling framework based on Operator Inference (OpInf) for rapidly solving parameter-dependent matrix equations in many-query settings. Motivated by the requirements of the OpInf methodology, we reformulate the matrix equations into a structured representation that explicitly shows the parameter dependence in polynomial form. This reformulation is crucial for efficient model reduction. This approach constructs reduced-order models via regression on solution snapshots, bypassing the need for expensive full-order operators and thus overcoming the primary bottlenecks of intrusive methods in high-dimensional contexts. Numerical experiments confirm their accuracy and computational efficiency, demonstrating that our work is a scalable and practical solution for parameter-dependent matrix equations."}
{"id": "2511.15724", "categories": ["physics.soc-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15724", "abs": "https://arxiv.org/abs/2511.15724", "authors": ["Misao Fukuda"], "title": "Comparison of Mathematical Models for Subscription Services Using Optimization Problems and Quantum Information Theory -Feasibility of Implementing Optimization Problem Algorithms on Quantum Computers-", "comment": null, "summary": "The purpose of this research is to explore whether it is possible to construct a design theory for subscription services for intangible goods from a time discounting perspective, based on quantum information theory, which is the foundational theory for quantum computers and similar technologies. To this end, we propose a mathematical model of subscription services using optimization problems based on optimal growth theory from standard economics, and with reference to microeconomics, we define utility as a value function of customer satisfaction derived from quantum mutual information, an entropy measure in quantum information theory, by considering time discounting. We propose the quantification of customer satisfaction and the formulation of consumer surplus. In the mathematical model of subscription services, the existence of a minimum value in the time-discounted customer satisfaction value function under budget constraints, and the realization of a mathematical expression for consumer surplus, could be explained by the laws of behavioral economics. This yielded new insights into the design of individually customized customer experiences, enhanced the feasibility of constructing economic models based on quantum information theory and the mathematical design of customer experiences, raised the possibility that mathematical models using quantum information theory can achieve greater economic welfare than standard economics, and increased the feasibility of implementing optimization problem algorithms on quantum computers."}
{"id": "2511.16603", "categories": ["cond-mat.str-el", "cond-mat.other", "cond-mat.quant-gas", "cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.16603", "abs": "https://arxiv.org/abs/2511.16603", "authors": ["Aleksey Alekseev", "Konrad Jerzy Kapcia"], "title": "Charge-Ordered States and the Phase Diagram of the Extended Hubbard Model on the Bethe lattice", "comment": "12 pages, 5 figures, 65 references; RevTeX class, double-column formatting", "summary": "We study the extended Hubbard model (EHM) with both onsite Hubbard interaction and the intersite density-density interaction between nearest-neighbors using the standard Hartree mean-field approximation (MFA) on the Bethe lattice. We found that, at the ground state, the system can be in a charge-ordered insulating (COI), a charge-order metallic (COM) or a non-charge-ordered (NO) state. Moreover, the finite-temperature phase diagrams are presented. Several observables like a charge-order parameter, a spectral function, and particularly at finite temperatures, a charge carrier concentration (to visualize the degree of metallicity) are analyzed. The results show that increasing onsite repulsion suppresses charge order and change the properties of the system from insulating to metallic. Worth noting, that a number of phenomena can be found within the MFA, where their analysis is much simpler than in more advanced approaches. The method used for the EHM on the Bethe lattice also allows for a series of analytical derivations and simplification to see general geometry-independent features and analytical results, avoiding the numerical inaccuracies and other issues that appear with a purely numerical solution."}
{"id": "2511.16127", "categories": ["math.OC", "math.AP", "math.DG"], "pdf": "https://arxiv.org/pdf/2511.16127", "abs": "https://arxiv.org/abs/2511.16127", "authors": ["Livia Betz"], "title": "A novel way of computing the shape derivative for a class of non-smooth PDEs and its impact on deriving necessary conditions for locally optimal shapes", "comment": "34 pages , 3 figures", "summary": "We derive necessary conditions for locally optimal shapes of a design problem governed by a non-smooth PDE. The main particularity of the state system is the lack of differentiability of the nonlinearity. We work in the framework of the functional variational approach (FVA), which has the capacity to transfer geometric optimization problems into optimal control problems, the set of admissible shapes being parametrized by a large class of continuous mappings. In the FVA setting, we introduce a sensitivity analysis technique that is novel even for smooth PDEs. We emphasize that we do not resort to extensions on the hold-all domain or any kind of approximation of the original PDE. The computation of the directional derivative of the state w.r.t. functional variations results in a new way of computing the shape derivative. The presented approach allows us to handle in the objective pointwise observation and derivatives of the state on an observation set as well as distributed observation terms. In addition, we introduce the concept of locally optimal shapes and we put into evidence its connection to locally minimizers of the corresponding control problem. With directional differentiability results for the control-to-state map at our disposal, we can then state necessary conditions for locally optimal shapes in general non-smooth settings."}
{"id": "2511.16628", "categories": ["cs.CE", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.16628", "abs": "https://arxiv.org/abs/2511.16628", "authors": ["Tammam Bakeer", "Max Herbers", "Steffen Marx"], "title": "Sensor Informativeness, Identifiability, and Uncertainty in Bayesian Inverse Problems for Structural Health Monitoring", "comment": null, "summary": "In Structural Health Monitoring (SHM), the recovery of distributed mechanical parameters from sparse data is often ill-posed, raising critical questions about identifiability and the reliability of inferred states. While deterministic regularization methods such as Tikhonov stabilise the inversion, they provide little insight into the spatial limits of resolution or the inherent uncertainty of the solution. This paper presents a Bayesian inverse framework that rigorously quantifies these limits, using the identification of distributed flexural rigidity from rotation (tilt) influence lines as a primary case study. Fisher information is employed as a diagnostic metric to quantify sensor informativeness, revealing how specific sensor layouts and load paths constrain the recoverable spatial features of the parameter field.\n  The methodology is applied to the full-scale openLAB research bridge (TU Dresden) using data from controlled vehicle passages. Beyond estimating the flexural rigidity profile, the Bayesian formulation produces credible intervals that expose regions of practical non-identifiability, which deterministic methods may obscure. The results demonstrate that while the measurement data carry high information content for the target parameters, their utility is spatially heterogeneous and strictly bounded by the experiment design. The proposed framework unifies identification with uncertainty quantification, providing a rigorous basis for optimising sensor placement and interpreting the credibility of SHM diagnostics."}
{"id": "2511.15806", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15806", "abs": "https://arxiv.org/abs/2511.15806", "authors": ["Angelos Pelecanos", "Jack Spilecki", "Ewin Tang", "John Wright"], "title": "Mixed state tomography reduces to pure state tomography", "comment": "46 pages", "summary": "A longstanding belief in quantum tomography is that estimating a mixed state is far harder than estimating a pure state. This is borne out in the mathematics, where mixed state algorithms have always required more sophisticated techniques to design and analyze than pure state algorithms. We present a new approach to tomography demonstrating that, contrary to this belief, state-of-the-art mixed state tomography follows easily and naturally from pure state algorithms.\n  We analyze the following strategy: given $n$ copies of an unknown state $ρ$, convert them into copies of a purification $|ρ\\rangle$; run a pure state tomography algorithm to produce an estimate of $|ρ\\rangle$; and output the resulting estimate of $ρ$. The purification subroutine was recently discovered via the \"acorn trick\" of Tang, Wright, and Zhandry. With this strategy, we obtain the first tomography algorithm which is sample-optimal in all parameters. For a rank-$r$ $d$-dimensional state, it uses $n = O((rd + \\log(1/δ))/\\varepsilon)$ samples to output an estimate which is $\\varepsilon$-close in fidelity with probability at least $1-δ$. This algorithm also uses poly$(n)$ gates, making it the first gate-efficient tomography algorithm which is sample-optimal even in terms of the dimension $d$ alone. Moreover, with this method we recover essentially all results on mixed state tomography, including its applications to tomography with limited entanglement, classical shadows, and quantum metrology. Our proofs are simple, closing the gap in conceptual difficulty between mixed and pure tomography. Our results also clarify the role of entangled measurement in mixed state tomography: the only step of the algorithm which requires entanglement across copies is the purification step, suggesting that, for tomography, the reason entanglement is useful is for consistent purification."}
{"id": "2511.16598", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.16598", "abs": "https://arxiv.org/abs/2511.16598", "authors": ["Hyunuk Kim"], "title": "Disparity-in-Differences: Extracting Hierarchical Backbones of Weighted Directed Networks", "comment": null, "summary": "Networks are useful representations for complex systems. Especially, heterogeneous and asymmetrical relations commonly found in complex systems can be converted to weighted directed edges between nodes. The disparity filter (Serrano et al., 2009) has successfully extracted backbones, sets of important edges, from empirical networks but is not designed to incorporate node-node dependency that may encode hierarchical relations. This paper proposes an extended disparity filter named \"disparity-in-differences\" that assigns a synthetic relation between two nodes if one depends relatively more on the other where the extent of asymmetric dependence is measured by the disparity between a normalized edge weight difference and an expected edge weight difference. For evaluation, the proposed method is applied to a journal citation network, a U.S. airport network, the Enron email network, and a world trade network. Compared to the disparity filter, the proposed approach better captures hierarchical relations that align well with journal quality ratings, airport hub categories by size, levels of management, and a core-periphery structure of countries, respectively."}
{"id": "2511.16603", "categories": ["cond-mat.str-el", "cond-mat.other", "cond-mat.quant-gas", "cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.16603", "abs": "https://arxiv.org/abs/2511.16603", "authors": ["Aleksey Alekseev", "Konrad Jerzy Kapcia"], "title": "Charge-Ordered States and the Phase Diagram of the Extended Hubbard Model on the Bethe lattice", "comment": "12 pages, 5 figures, 65 references; RevTeX class, double-column formatting", "summary": "We study the extended Hubbard model (EHM) with both onsite Hubbard interaction and the intersite density-density interaction between nearest-neighbors using the standard Hartree mean-field approximation (MFA) on the Bethe lattice. We found that, at the ground state, the system can be in a charge-ordered insulating (COI), a charge-order metallic (COM) or a non-charge-ordered (NO) state. Moreover, the finite-temperature phase diagrams are presented. Several observables like a charge-order parameter, a spectral function, and particularly at finite temperatures, a charge carrier concentration (to visualize the degree of metallicity) are analyzed. The results show that increasing onsite repulsion suppresses charge order and change the properties of the system from insulating to metallic. Worth noting, that a number of phenomena can be found within the MFA, where their analysis is much simpler than in more advanced approaches. The method used for the EHM on the Bethe lattice also allows for a series of analytical derivations and simplification to see general geometry-independent features and analytical results, avoiding the numerical inaccuracies and other issues that appear with a purely numerical solution."}
{"id": "2511.16019", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16019", "abs": "https://arxiv.org/abs/2511.16019", "authors": ["Mengyun Xu", "Jie Fang", "Eui-Jin Kim", "Tony Z. Qiu", "Prateek Bansal"], "title": "Physics Informed Multi-task Joint Generative Learning for Arterial Vehicle Trajectory Reconstruction Considering Lane Changing Behavior", "comment": "29 pages, 14 figures, 2 tables. Submitted to Transportation Research Part C: Emerging Technologies. Preprint version", "summary": "Reconstructing complete traffic flow time-space diagrams from vehicle trajectories offer a comprehensive view on traffic dynamics at arterial intersections. However, obtaining full trajectories across networks is costly, and accurately inferring lane-changing (LC) and car-following behaviors in multi-lane environments remains challenging. This study proposes a generative framework for arterial vehicle trajectory reconstruction that jointly models lane-changing and car-following behaviors through physics-informed multi-task joint learning. The framework consists of a Lane-Change Generative Adversarial Network (LC-GAN) and a Trajectory-GAN. The LC-GAN models stochastic LC behavior from historical trajectories while considering physical conditions of arterial intersections, such as signal control, geometric configuration, and interactions with surrounding vehicles. The Trajectory-GAN then incorporates LC information from the LC-GAN with initial trajectories generated from physics-based car-following models, refining them in a data-driven manner to adapt to dynamic traffic conditions. The proposed framework is designed to reconstruct complete trajectories from only a small subset of connected vehicle (CV) trajectories; for example, even a single observed trajectory per lane, by incorporating partial trajectory information into the generative process. A multi-task joint learning facilitates synergistic interaction between the LC-GAN and Trajectory-GAN, allowing each component to serves as both auxiliary supervision and a physical condition for the other. Validation using two real-world trajectory datasets demonstrates that the framework outperforms conventional benchmark models in reconstructing complete time-space diagrams for multi-lane arterial intersections. This research advances the integration of trajectory-based sensing from CVs with physics-informed deep learning."}
{"id": "2511.15896", "categories": ["stat.ME", "math.ST", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.15896", "abs": "https://arxiv.org/abs/2511.15896", "authors": ["Ying Jin", "José Zubizarreta"], "title": "Cross-Balancing for Data-Informed Design and Efficient Analysis of Observational Studies", "comment": null, "summary": "Causal inference starts with a simple idea: compare groups that differ by treatment, not much else. Traditionally, similar groups are constructed using only observed covariates; however, it remains a long-standing challenge to incorporate available outcome data into the study design while preserving valid inference. In this paper, we study the general problem of covariate adjustment, effect estimation, and statistical inference when balancing features are constructed or selected with the aid of outcome information from the data. We propose cross-balancing, a method that uses sample splitting to separate the error in feature construction from the error in weight estimation. Our framework addresses two cases: one where the features are learned functions and one where they are selected from a potentially high-dimensional dictionary. In both cases, we establish mild and general conditions under which cross-balancing produces consistent, asymptotically normal, and efficient estimators. In the learned-function case, cross-balancing achieves finite-sample bias reduction relative to plug-in-type estimators, and is multiply robust when the learned features converge at slow rates. In the variable-selection case, cross-balancing only requires a product condition on how well the selected variables approximate true functions. We illustrate cross-balancing in extensive simulations and an observational study, showing that careful use of outcome information can substantially improve both estimation and inference while maintaining interpretability."}
{"id": "2511.16286", "categories": ["cond-mat.stat-mech", "cond-mat.other", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2511.16286", "abs": "https://arxiv.org/abs/2511.16286", "authors": ["Nico Hahn", "Lars Öhrström", "R. Matthias Geilhufe"], "title": "Collective Buckling in Metal-Organic Framework Materials", "comment": null, "summary": "We develop a framework to describe collective buckling in metal-organic frameworks (MOFs). Starting from the microscopic structure of a single organic linker, we define a buckling coordinate governed by an effective double-well potential. Coupling between linkers arises from dipole-dipole interactions, leading to a lattice Hamiltonian. We analyze the transition between ordered and disordered phases within a mean-field approximation and determine the critical temperature. As an example for our theory, we discuss the collective buckling instability for the prototypical cubic framework MOF-5 under different values of uniaxial strain. Our approach enables a quantitative description of collective buckling in framework materials."}
{"id": "2511.16019", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16019", "abs": "https://arxiv.org/abs/2511.16019", "authors": ["Mengyun Xu", "Jie Fang", "Eui-Jin Kim", "Tony Z. Qiu", "Prateek Bansal"], "title": "Physics Informed Multi-task Joint Generative Learning for Arterial Vehicle Trajectory Reconstruction Considering Lane Changing Behavior", "comment": "29 pages, 14 figures, 2 tables. Submitted to Transportation Research Part C: Emerging Technologies. Preprint version", "summary": "Reconstructing complete traffic flow time-space diagrams from vehicle trajectories offer a comprehensive view on traffic dynamics at arterial intersections. However, obtaining full trajectories across networks is costly, and accurately inferring lane-changing (LC) and car-following behaviors in multi-lane environments remains challenging. This study proposes a generative framework for arterial vehicle trajectory reconstruction that jointly models lane-changing and car-following behaviors through physics-informed multi-task joint learning. The framework consists of a Lane-Change Generative Adversarial Network (LC-GAN) and a Trajectory-GAN. The LC-GAN models stochastic LC behavior from historical trajectories while considering physical conditions of arterial intersections, such as signal control, geometric configuration, and interactions with surrounding vehicles. The Trajectory-GAN then incorporates LC information from the LC-GAN with initial trajectories generated from physics-based car-following models, refining them in a data-driven manner to adapt to dynamic traffic conditions. The proposed framework is designed to reconstruct complete trajectories from only a small subset of connected vehicle (CV) trajectories; for example, even a single observed trajectory per lane, by incorporating partial trajectory information into the generative process. A multi-task joint learning facilitates synergistic interaction between the LC-GAN and Trajectory-GAN, allowing each component to serves as both auxiliary supervision and a physical condition for the other. Validation using two real-world trajectory datasets demonstrates that the framework outperforms conventional benchmark models in reconstructing complete time-space diagrams for multi-lane arterial intersections. This research advances the integration of trajectory-based sensing from CVs with physics-informed deep learning."}
{"id": "2511.15813", "categories": ["stat.ME", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.15813", "abs": "https://arxiv.org/abs/2511.15813", "authors": ["Aleix Alcacer", "Rafael Benitez", "Vicente J. Bolos", "Irene Epifanio"], "title": "Multidimensional scaling of two-mode three-way asymmetric dissimilarities: finding archetypal profiles and clustering", "comment": null, "summary": "Multidimensional scaling visualizes dissimilarities among objects and reduces data dimensionality. While many methods address symmetric proximity data, asymmetric and especially three-way proximity data (capturing relationships across multiple occasions) remain underexplored. Recent developments, such as the h-plot, enable the analysis of asymmetric and non-reflexive relationships by embedding dissimilarities in a Euclidean space, allowing further techniques like archetypoid analysis to identify representative extreme profiles. However, no existing methods extract archetypal profiles from three-way asymmetric proximity data. This work extends the h-plot methodology to three-way proximity data under both symmetric and asymmetric, conditional and unconditional frameworks. The proposed approach offers several advantages: intuitive interpretability through a unified Euclidean representation; an explicit, eigenvector-based analytical solution free from local minima; scale invariance under linear transformations; computational efficiency for large matrices; and a straightforward goodness-of-fit evaluation. Furthermore, it enables the identification of archetypal profiles and clustering structures for three-way asymmetric proximities. Its performance is compared with existing models for multidimensional scaling and clustering, and illustrated through a financial application. All data and code are provided to facilitate reproducibility."}
{"id": "2511.16070", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.16070", "abs": "https://arxiv.org/abs/2511.16070", "authors": ["Fang Feng", "Yuanyi Sun", "Yue Yu"], "title": "Optimal error analysis of an interior penalty virtual element method for fourth-order singular perturbation problems", "comment": null, "summary": "In recent studies \\cite{ZZ24, FY24}, the Interior Penalty Virtual Element Method (IPVEM) has been developed for solving a fourth-order singular perturbation problem, with uniform convergence established in the lowest-order case concerning the perturbation parameter. However, the resulting uniform convergence rate is only of half-order, which is suboptimal. In this work, we demonstrate that the proposed IPVEM in fact achieves optimal and uniform error estimates, even in the presence of boundary layers. The theoretical results are substantiated through extensive numerical experiments, which confirm the validity of the error estimates and highlight the method's effectiveness for singularly perturbed problems."}
{"id": "2511.16497", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2511.16497", "abs": "https://arxiv.org/abs/2511.16497", "authors": ["Aleix Bassolas", "Piero Birello", "Julian Vicens"], "title": "An analytical and experimental study of the energy transition discourse on YouTube", "comment": "36 pages, 27 Figures, 1 Table", "summary": "Energy production and management face significant political, economic, and environmental challenges, yet the rise in information consumption through social media undermines the availability of reliable knowledge to the general public. This study examines the ideas discussed in the energy transition content on YouTube, assesses the most effective methods of communicating knowledge and information to the general public, and identifies the most engaged audiences. We examine videos related to the subject, analysing the themes discussed, the language used, and the emotions conveyed on YouTube, linking language formality to user engagement. To test the relationship experimentally, we uploaded original content to YouTube through two mirror channels containing the same material but using different levels of language formality. Our results indicate that conversational content reaches a broader audience, but retention rates are higher on the academic channel beyond the initial video segments. Interest in the topic varies by viewer profile, with younger individuals and women showing greater engagement regardless of language style."}
{"id": "2511.15939", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2511.15939", "abs": "https://arxiv.org/abs/2511.15939", "authors": ["Gerardo Aquino", "Mauro Bologna"], "title": "Noise-induced resonant acceleration of a charge in an intermittent magnetic field: an exact solution for ergodic and non-ergodic fluctuations", "comment": "13 pages, 6 figures", "summary": "We study the diffusion of a charged particle in a magnetic field subject to stochastic dichotomous fluctuations.The associated induced electric field gives rise to nontrivial dynamical regimes.In particular, when the mean magnetic field vanishes, the particle remains confined within a finite radius, regardless of the fluctuation statistics. For a non-zero mean field, we show, using a density approach for Poissonian fluctuations, that the particle undergoes an exponential regime of accelerated diffusion. Crucially and more generally, adopting a trajectory-based formalism, we derive an exact analytical solution valid for arbitrary waiting-time distributions, including non-Poissonian and non-ergodic cases.Even rare, abrupt field reversals are shown to trigger exponential acceleration of the particle's diffusion.We demonstrate that this behaviour stems from noise exciting resonance bands present for periodic fluctuations, and we propose noise-induced resonant acceleration as a robust and efficient charge acceleration mechanism, potentially more effective than Fermi's classic model for cosmic-ray acceleration."}
{"id": "2511.16634", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16634", "abs": "https://arxiv.org/abs/2511.16634", "authors": ["Mina Tarakemeh", "Shenglong Xu"], "title": "Non-Abelian operator size distribution in charge-conserving many-body systems", "comment": "7+8 pages, 4 figures", "summary": "We show that operator dynamics in U(1) symmetric systems are constrained by two independent conserved charges and construct a non-Abelian operator size basis that respects both, enabling a symmetry-resolved characterization of operator growth. The non-Abelian operator size depends on the operator's nonlocal structure and is organized by an SU(2) algebra. Operators associated with large total angular momentum are relatively simple, while those with small angular momentum are more complex. Operator growth is thus characterized by a reduction in angular momentum and can be probed using out-of-time-ordered correlators. Using the charge-conserving Brownian Sachdev-Ye-Kitaev model, we derive an exact classical master equation that governs the size distribution, the distribution of an operator expanded in this basis, for arbitrary system sizes. The resulting dynamics reveal that the size distribution follows a chi-squared form, with the two conserved charges jointly determining the overall time scale and the shape of the distribution. In particular, single-particle operators retain a divergent peak at large angular momentum throughout the time evolution."}
{"id": "2511.16195", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16195", "abs": "https://arxiv.org/abs/2511.16195", "authors": ["Jörn Tebbe", "Andreas Besginow", "Markus Lange-Hegermann"], "title": "Physics-informed Gaussian Processes as Linear Model Predictive Controller with Constraint Satisfaction", "comment": null, "summary": "Model Predictive Control evolved as the state of the art paradigm for safety critical control tasks. Control-as-Inference approaches thereof model the constrained optimization problem as a probabilistic inference problem. The constraints have to be implemented into the inference model. A recently introduced physics-informed Gaussian Process method uses Control-as-Inference with a Gaussian likelihood for state constraint modeling, but lacks guarantees of open-loop constraint satisfaction. We mitigate the lack of guarantees via an additional sampling step using Hamiltonian Monte Carlo sampling in order to obtain safe rollouts of the open-loop dynamics which are then used to obtain an approximation of the truncated normal distribution which has full probability mass in the safe area. We provide formal guarantees of constraint satisfaction while maintaining the ODE structure of the Gaussian Process on a discretized grid. Moreover, we show that we are able to perform optimization of a quadratic cost function by closed form Gaussian Process computations only and introduce the Matérn kernel into the inference model."}
{"id": "2511.15880", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15880", "abs": "https://arxiv.org/abs/2511.15880", "authors": ["Lorenzo Braccini", "Debarshi Das", "Ben Zindorf", "Stephen D. Hogan", "John J. L. Morton", "Sougato Bose"], "title": "Nonclassicality of a Macroscopic Qubit-Ensemble via Parity Measurement Induced Disturbance", "comment": "24 pages, 7 figures; Any feedback is welcome", "summary": "We propose an experimental scheme to test the nonclassicality of a macroscopic ensemble of qubits, through the violation of the classical notion of macrorealism (MR) via the fundamental measurement-induced disturbance of quantum systems. An electromagnetic resonator is used to probe the parity of the qubit-ensemble. The action of sequential measurements allows the nonclassicality of whole ensemble to manifest itself, in the ideal case, irrespective of its size. This enables to probe the macroscopic limits of quantum mechanics as the qubit-ensemble is, effectively, a single large spin of many $\\hbar$ units. Even as $\\hbar \\rightarrow 0$ in comparison to the total angular momentum of the ensemble, a constant amount of violation of MR is found in the noiseless case. However, environmental decoherence and inhomogeneity of qubit-electromagnetic field couplings precipitate the quantum-to-classical transition. This implies that Bohr's correspondence principle is not fundamental, but a consequence of practical limitations. We outline an implementation with a variety of qubits (superconducting qubits, spins in semiconductors, and Rydberg atoms) coupled to a coplanar waveguide resonator, and - via the corresponding noise analysis - find that violation of MR is detectable up to $100$ qubits via current technology."}
{"id": "2511.16066", "categories": ["eess.SY", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.16066", "abs": "https://arxiv.org/abs/2511.16066", "authors": ["Shreyan Banerjee", "Aasifa Rounak", "Vikram Pakrashi"], "title": "Bellman Memory Units: A neuromorphic framework for synaptic reinforcement learning with an evolving network topology", "comment": "11 pages, submitted to IEEE Transactions on Automatic Control", "summary": "Application of neuromorphic edge devices for control is limited by the constraints on gradient-free online learning and scalability of the hardware across control problems. This paper introduces a synaptic Q-learning algorithm for the control of the classical Cartpole, where the Bellman equations are incorporated at the synaptic level. This formulation enables the iterative evolution of the network topology, represented as a directed graph, throughout the training process. This is followed by a similar approach called neuromorphic Bellman Memory Units (BMU(s)), which are implemented with the Neural Engineering Framework on Intel's Loihi neuromorphic chip. Topology evolution, in conjunction with mixed-signal computation, leverages the optimization of the number of neurons and synapses that could be used to design spike-based reinforcement learning accelerators. The proposed architecture can potentially reduce resource utilization on board, aiding the manufacturing of compact application-specific neuromorphic ICs. Moreover, the on-chip learning introduced in this work and implemented on a neuromorphic chip can enable adaptation to unseen control scenarios."}
{"id": "2511.15904", "categories": ["stat.ME", "econ.EM", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.15904", "abs": "https://arxiv.org/abs/2511.15904", "authors": ["Gözde Sert", "Abhishek Chakrabortty", "Anirban Bhattacharya"], "title": "Bayesian Semiparametric Causal Inference: Targeted Doubly Robust Estimation of Treatment Effects", "comment": "48 pages (including supplement)", "summary": "We propose a semiparametric Bayesian methodology for estimating the average treatment effect (ATE) within the potential outcomes framework using observational data with high-dimensional nuisance parameters. Our method introduces a Bayesian debiasing procedure that corrects for bias arising from nuisance estimation and employs a targeted modeling strategy based on summary statistics rather than the full data. These summary statistics are identified in a debiased manner, enabling the estimation of nuisance bias via weighted observables and facilitating hierarchical learning of the ATE. By combining debiasing with sample splitting, our approach separates nuisance estimation from inference on the target parameter, reducing sensitivity to nuisance model specification. We establish that, under mild conditions, the marginal posterior for the ATE satisfies a Bernstein-von Mises theorem when both nuisance models are correctly specified and remains consistent and robust when only one is correct, achieving Bayesian double robustness. This ensures asymptotic efficiency and frequentist validity. Extensive simulations confirm the theoretical results, demonstrating accurate point estimation and credible intervals with nominal coverage, even in high-dimensional settings. The proposed framework can also be extended to other causal estimands, and its key principles offer a general foundation for advancing Bayesian semiparametric inference more broadly."}
{"id": "2511.16362", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.16362", "abs": "https://arxiv.org/abs/2511.16362", "authors": ["Félix Benoist", "Pablo Sartori"], "title": "Resolving Speed and Encoding Bottlenecks in Fast Heteromeric Self-Assembly", "comment": "Main: 10 pages, 6 figures. SI: 9 pages, 8 figures", "summary": "The cytoplasm is a heterogeneous mixture containing many types of proteins that self-assemble into a wide variety of complexes. The accuracy and speed of cytoplasmic self-assembly is astonishing because it involves the correct identification of components shared among different structures, despite pervasive thermal fluctuations. Typical toy models of self-assembly are based on the specificity of binding energies among components and neglect kinetic effects. However, kinetics plays a key role in biological self-assembly, often catalyzed by a plethora of assembly factors. Building on this observation, we extend a previous heteropolymer growth model to describe the retrieval of two-dimensional structures. We find that the self-assembly of structures in this model is subject to strong speed and encoding bottlenecks. Moreover, we show that these bottlenecks can be suppressed by increasing the connectivity of a small fraction of components. This mechanism of kinetically controlling a small number of critical binding events provides a simple explanation for the timely assembly of large protein, and suggests a unifying principle for the role of assembly factors."}
{"id": "2511.16066", "categories": ["eess.SY", "cs.NE"], "pdf": "https://arxiv.org/pdf/2511.16066", "abs": "https://arxiv.org/abs/2511.16066", "authors": ["Shreyan Banerjee", "Aasifa Rounak", "Vikram Pakrashi"], "title": "Bellman Memory Units: A neuromorphic framework for synaptic reinforcement learning with an evolving network topology", "comment": "11 pages, submitted to IEEE Transactions on Automatic Control", "summary": "Application of neuromorphic edge devices for control is limited by the constraints on gradient-free online learning and scalability of the hardware across control problems. This paper introduces a synaptic Q-learning algorithm for the control of the classical Cartpole, where the Bellman equations are incorporated at the synaptic level. This formulation enables the iterative evolution of the network topology, represented as a directed graph, throughout the training process. This is followed by a similar approach called neuromorphic Bellman Memory Units (BMU(s)), which are implemented with the Neural Engineering Framework on Intel's Loihi neuromorphic chip. Topology evolution, in conjunction with mixed-signal computation, leverages the optimization of the number of neurons and synapses that could be used to design spike-based reinforcement learning accelerators. The proposed architecture can potentially reduce resource utilization on board, aiding the manufacturing of compact application-specific neuromorphic ICs. Moreover, the on-chip learning introduced in this work and implemented on a neuromorphic chip can enable adaptation to unseen control scenarios."}
{"id": "2511.15866", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.15866", "abs": "https://arxiv.org/abs/2511.15866", "authors": ["Chenyin Gao", "Han Chen", "Anru R. Zhang", "Shu Yang"], "title": "Causal Inference on Sequential Treatments via Tensor Completion", "comment": null, "summary": "Marginal Structural Models (MSMs) are popular for causal inference of sequential treatments in longitudinal observational studies, which however are sensitive to model misspecification. To achieve flexible modeling, we envision the potential outcomes to form a three-dimensional tensor indexed by subject, time, and treatment regime and propose a tensorized history-restricted MSM (HRMSM). The semi-parametric tensor factor model allows us to leverage the underlying low-rank structure of the potential outcomes tensor and exploit the pre-treatment covariate information to recover the counterfactual outcomes. We incorporate the inverse probability of treatment weighting in the loss function for tensor completion to adjust for time-varying confounding. Theoretically, a non-asymptotic upper bound on the Frobenius norm error for the proposed estimator is provided. Empirically, simulation studies show that the proposed tensor completion approach outperforms the parametric HRMSM and existing matrix/tensor completion methods. Finally, we illustrate the practical utility of the proposed approach to study the effect of ventilation on organ dysfunction from the Medical Information Mart for Intensive Care database."}
{"id": "2511.16171", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.16171", "abs": "https://arxiv.org/abs/2511.16171", "authors": ["Lan Wang", "Qiao Zhu", "Bangti Jin", "Ye Zhang"], "title": "Shallow neural network yields regularization for ill-posed inverse problems", "comment": "21 pages, 27 figures", "summary": "In this paper, we establish universal approximation theorems for neural networks applied to general nonlinear ill-posed operator equations. In addition to the approximation error, the measurement error is also taken into account in our error estimation. We introduce the expanding neural network method as a novel iterative regularization scheme and prove its regularization properties under different a priori assumptions about the exact solutions. Within this framework, the number of neurons serves as both the regularization parameter and iteration number. We demonstrate that for data with high noise levels, a small network architecture is sufficient to obtain a stable solution, whereas a larger architecture may compromise stability due to overfitting. Furthermore, under standard assumptions in regularization theory, we derive convergence rate results for neural networks in the context of variational regularization. Several numerical examples are presented to illustrate the robustness of the proposed neural network-based algorithms."}
{"id": "2511.16598", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.16598", "abs": "https://arxiv.org/abs/2511.16598", "authors": ["Hyunuk Kim"], "title": "Disparity-in-Differences: Extracting Hierarchical Backbones of Weighted Directed Networks", "comment": null, "summary": "Networks are useful representations for complex systems. Especially, heterogeneous and asymmetrical relations commonly found in complex systems can be converted to weighted directed edges between nodes. The disparity filter (Serrano et al., 2009) has successfully extracted backbones, sets of important edges, from empirical networks but is not designed to incorporate node-node dependency that may encode hierarchical relations. This paper proposes an extended disparity filter named \"disparity-in-differences\" that assigns a synthetic relation between two nodes if one depends relatively more on the other where the extent of asymmetric dependence is measured by the disparity between a normalized edge weight difference and an expected edge weight difference. For evaluation, the proposed method is applied to a journal citation network, a U.S. airport network, the Enron email network, and a world trade network. Compared to the disparity filter, the proposed approach better captures hierarchical relations that align well with journal quality ratings, airport hub categories by size, levels of management, and a core-periphery structure of countries, respectively."}
{"id": "2511.16252", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2511.16252", "abs": "https://arxiv.org/abs/2511.16252", "authors": ["Tommaso Trabocchi", "Raffaella Burioni", "Lucilla de Arcangelis", "Duccio Fanelli"], "title": "Generalized Wilson-Cowan model with short term synaptic plasticity", "comment": null, "summary": "A generalized version of the Wilson-Cowan (WC) model is proposed which accounts for the evolution of the synaptic resources. Adiabatic elimination of the fast variables is performed to yield a simplified framework for the coupled interaction between active excitatory and inhibitory neurons. The latter model is shown to smoothly converge to the benchmark WC model, when the appropriate limit is performed. Different dynamical regimes are identified for the reduced model and commented upon with reference to the original formulation of the generalized dynamics. This includes identifying limit cycle oscillations for population of available resources."}
{"id": "2511.16641", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2511.16641", "abs": "https://arxiv.org/abs/2511.16641", "authors": ["Run Hou", "Andriy H. Nevidomskyy"], "title": "Stabilizing Fractional Chern States in Twisted MoTe2: Multi-band Correlations via Non-perturbative Renormalization Group", "comment": null, "summary": "The observation of fraction quantum Hall states in twisted MoTe2 has sparked a lof of interest in this phenomenon. Most theoretical works to date rely on the brute-force exact diagonalization which is limited to the one partially occupied band. In this work, we present strong evidence that the effect of higher lying bands cannot be ignored due to strong interband interactions. To tackle these effects, we introduce a non-perturbative driven similarity renormalization group (DSRG) method, originally developed for problems in quantum chemistry. We apply this methodology to twisted MoTe2 at fractional hole fillings of ν = 1/3 and 2/3 across a spectrum of twist angles. Our results show that at ν = 1/3, the many-body excitation energy gaps are substantially reduced compared to the one-band treatment. For ν = 2/3, we find that the dynamic correlations stemming from interband interactions stabilize fractional Chern insulating phases at larger twist angles, consistent with the experimental findings. By examining the correlated orbitals and their single-particle topological features, we demonstrate that this stabilization at higher twist angles arises predominantly from the dynamic correlations, rather than conditions on the single-particle quantum geometric tensor."}
{"id": "2511.16211", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.16211", "abs": "https://arxiv.org/abs/2511.16211", "authors": ["Guillaume Carlier", "Hugo Malamut", "Maxime Sylvestre"], "title": "Weak optimal transport with moment constraints: constraintqualification, dual attainment and entropic regularization", "comment": "37 pages, 2 figures", "summary": "We consider weak optimal problems (possibly entropically penalized) incorporating both soft and hard (including the case of the martingale condition) moment constraints. Even in the special case of the martingale optimal transport problem, existence of Lagrange multipliers corresponding to the martingale constraint is notoriously hard (and may fail unless some specific additional assumptions are made). We identify a condition of qualification of the hard moment constraints (which in the martingale case is implied by well-known conditions in the literature) under which general dual attainment results are established. We also analyze the convergence of entropically regularized schemes combined with penalization of the moment constraint and illustrate our theoretical findings by numerically solving in dimension one, the Brenier-Strassen problem of Gozlan and Juillet and a family of problems which interpolates between monotone transport and left-curtain martingale coupling of Beiglböck and Juillet."}
{"id": "2511.15881", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15881", "abs": "https://arxiv.org/abs/2511.15881", "authors": ["Ben Zindorf", "Lorenzo Braccini", "Debarshi Das", "Sougato Bose"], "title": "How \"Quantum\" is your Quantum Computer? Macrorealism-based Benchmarking via Mid-Circuit Parity Measurements", "comment": "12 pages, 4 figures; Any feedback is welcome", "summary": "To perform meaningful computations, Quantum Computers (QCs) must scale to macroscopic levels - i.e., to a large number of qubits - an objective pursued by most quantum companies. How to efficiently test their quantumness at these scales? We show that the violation of Macrorealism (MR), being the fact that classical systems possess definite properties that can be measured without disturbances, provide a fruitful avenue to this aim. The No Disturbance Condition (NDC) - the equality used here to test MR - can be violated by two consecutive parity measurements on $N$ qubits and found to be independent of $N$ under ideal conditions. However, realistic noisy QCs show a quantum-to-classical transition as $N$ increases, giving a foundationally-motivated scalable benchmarking metric. Two methods are formulated to implement this metric: one that involves a mid-circuit measurement, probing the irreversible collapse of the wavefunction, in contrast to the reversible entanglement generated in the other. Both methods are designed to be clumsiness-loophole free: the unwanted classical disturbances are negligible within statistical error. Violation of MR is detected on a IBM QC up to $N = 38$ qubits, increasing $N$ by one order of magnitude over best known results of MR. Two QCs are benchmarked using the proposed NDC metric, showing a three-fold improvement in their quantumness from one generation to the next."}
{"id": "2511.16093", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16093", "abs": "https://arxiv.org/abs/2511.16093", "authors": ["Xinyuan Liao", "Shaowei Chen", "Shuai Zhao"], "title": "Parallelizable Complex Neural Dynamics Models for PMSM Temperature Estimation with Hardware Acceleration", "comment": null, "summary": "Accurate and efficient thermal dynamics models of permanent magnet synchronous motors are vital to efficient thermal management strategies. Physics-informed methods combine model-based and data-driven methods, offering greater flexibility than model-based methods and superior explainability compared to data-driven methods. Nonetheless, there are still challenges in balancing real-time performance, estimation accuracy, and explainability. This paper presents a hardware-efficient complex neural dynamics model achieved through the linear decoupling, diagonalization, and reparameterization of the state-space model, introducing a novel paradigm for the physics-informed method that offers high explainability and accuracy in electric motor temperature estimation tasks. We validate this physics-informed method on an NVIDIA A800 GPU using the JAX machine learning framework, parallel prefix sum algorithm, and Compute Unified Device Architecture (CUDA) platform. We demonstrate its superior estimation accuracy and parallelizable hardware acceleration capabilities through experimental evaluation on a real electric motor."}
{"id": "2511.16029", "categories": ["stat.ME", "econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.16029", "abs": "https://arxiv.org/abs/2511.16029", "authors": ["Gregor Steiner", "Jeremie Houssineau", "Mark F. J. Steel"], "title": "Possibilistic Instrumental Variable Regression", "comment": null, "summary": "Instrumental variable regression is a common approach for causal inference in the presence of unobserved confounding. However, identifying valid instruments is often difficult in practice. In this paper, we propose a novel method based on possibility theory that performs posterior inference on the treatment effect, conditional on a user-specified set of potential violations of the exogeneity assumption. Our method can provide informative results even when only a single, potentially invalid, instrument is available, offering a natural and principled framework for sensitivity analysis. Simulation experiments and a real-data application indicate strong performance of the proposed approach."}
{"id": "2511.16443", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2511.16443", "abs": "https://arxiv.org/abs/2511.16443", "authors": ["Tuuli Sillanpää", "Sanni Nousiainen", "Lasse Laurson"], "title": "Height distribution of elastic interfaces in quenched random media", "comment": "9 pages, 6 figures", "summary": "Elastic interfaces in quenched random media driven by external forces exhibit a continuous depinning phase transition between pinned and moving phases at a critical external force. Recent work [Phys. Rev. Lett. 129, 175701 (2022)] has shown that the distribution of local interface heights at depinning displays negative skewness. Here, by considering local, long-range and fully-coupled (mean-field) elasticity, we expand on this result by demonstrating the robustness of the negative skewness at depinning when approaching the thermodynamic limit and considering different values of the spring stiffness controlling the avalanche cutoff. Additionally, we investigate the evolution of the height distribution as the external force is ramped up from zero, approaching the critical force from below. Starting from a symmetric height distribution at zero force, the distribution initially develops positive skewness increasing with the external force, followed by a steep drop to the negative value characteristic of the critical point as the depinning transition is reached."}
{"id": "2511.16093", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16093", "abs": "https://arxiv.org/abs/2511.16093", "authors": ["Xinyuan Liao", "Shaowei Chen", "Shuai Zhao"], "title": "Parallelizable Complex Neural Dynamics Models for PMSM Temperature Estimation with Hardware Acceleration", "comment": null, "summary": "Accurate and efficient thermal dynamics models of permanent magnet synchronous motors are vital to efficient thermal management strategies. Physics-informed methods combine model-based and data-driven methods, offering greater flexibility than model-based methods and superior explainability compared to data-driven methods. Nonetheless, there are still challenges in balancing real-time performance, estimation accuracy, and explainability. This paper presents a hardware-efficient complex neural dynamics model achieved through the linear decoupling, diagonalization, and reparameterization of the state-space model, introducing a novel paradigm for the physics-informed method that offers high explainability and accuracy in electric motor temperature estimation tasks. We validate this physics-informed method on an NVIDIA A800 GPU using the JAX machine learning framework, parallel prefix sum algorithm, and Compute Unified Device Architecture (CUDA) platform. We demonstrate its superior estimation accuracy and parallelizable hardware acceleration capabilities through experimental evaluation on a real electric motor."}
{"id": "2511.15882", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.15882", "abs": "https://arxiv.org/abs/2511.15882", "authors": ["Sida Chen", "Jessica K. Barrett", "Marco Palma", "Jianxin Pan", "Brian D. M. Tom"], "title": "Bayesian semiparametric modelling of biomarker variability in joint models", "comment": null, "summary": "There is growing interest in the role of within-individual variability (WIV) in biomarker trajectories for assessing disease risk and progression. A trajectory-based definition that has attracted recent attention characterises WIV as the curvature-based roughness of the latent biomarker trajectory (TB-WIV). To rigorously evaluate the association between TB-WIV and clinical outcomes and to perform dynamic risk prediction, joint models for longitudinal and time-to-event data (JM) are necessary. However, specifying the longitudinal trajectory is critical in this framework and poses methodological challenges. In this work, we investigate three Bayesian semiparametric approaches for longitudinal modelling and TB-WIV estimation within the JM framework to improve stability and accuracy over existing approaches. Two key methods are newly introduced: one based on Bayesian penalised splines (P-splines) and another on functional principal component analysis (FPCA). Using extensive simulation studies, we compare their performance under two important TB-WIV definitions against established approaches. Our results demonstrate overall inferential and predictive advantages of the proposed P-spline and FPCA-based approaches while also providing insights that guide method choice and interpretation of inference results. The proposed approaches are applied to data from the UK Cystic Fibrosis Registry, where, for the first time, we identify a significant positive association between lung function TB-WIV and mortality risk in patients with cystic fibrosis and demonstrate improved predictive performance for survival."}
{"id": "2511.16180", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.16180", "abs": "https://arxiv.org/abs/2511.16180", "authors": ["Rémi Abgrall", "Yongle Liu"], "title": "Robust PAMPA Scheme in the DG Formulation on Unstructured Triangular Meshes: bound preservation, oscillation elimination, and boundary conditions", "comment": null, "summary": "We propose an improved version of the PAMPA algorithm where the solution is sought as globally continuous. The scheme is locally conservative, and there is no mass matrix to invert. This method had been developed in a series of papers, see e.g \\cite{Abgrall2024a} and the references therein. In \\cite{Abgrall2025d}, we had shown the connection between PAMPA and the discontinuous Galerkin method, for the linear hyperbolic problem. Taking advantage of this reinterpretation, we use it to define a family of methods, show how to implement the boundary conditions in a rigorous manner. In addition, we propose a method that complements the bound preserving method developed in \\cite{Abgrall2025d} in the sense that it is non oscillatory. A truncation error analysis is provided, it shows that the scheme should be third order accurate for smooth solutions. This is confirmed by numerical experiments. Several numerical examples are presented to show that the scheme is indeed bound preserving and non oscillatory on a wide range on numerical benchmarks."}
{"id": "2511.16393", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.16393", "abs": "https://arxiv.org/abs/2511.16393", "authors": ["Zhao-Fan Cai", "Yang Li", "Yu-Ran Zhang", "Tao Liu"], "title": "Arbitrary Control of Non-Hermitian Skin Modes via Disorder and Electric Field", "comment": "8 pages, 3 figures,", "summary": "The non-Hermitian skin effect (NHSE), characterized by the accumulation of a macroscopic number of bulk states at system boundaries, is a hallmark of non-Hermitian physics. However, effective control of skin-mode localization in higher-dimensional systems remains challenging. Here, we propose a versatile approach to manipulate the localization of skin modes in a two-dimensional nonreciprocal lattice by combining disorder and a static electric field. While the electric field alone suppresses the NHSE in a clean system, the introduction of disorder induces transverse wave-packet transport perpendicular to the field. When the nonreciprocal hopping direction is misaligned with the electric field, the hopping component perpendicular to the field guides the wave-packet propagation and leads to boundary localization. By tuning the relative orientations of the electric field and the nonreciprocal hopping, arbitrary control over the boundary localization position can be achieved. Our results demonstrate a robust and tunable mechanism for engineering boundary accumulation and directed transport in non-Hermitian systems, offering new opportunities for applications in classical platforms and quantum materials."}
{"id": "2511.16667", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.16667", "abs": "https://arxiv.org/abs/2511.16667", "authors": ["Christopher A. Leong", "Bitan Roy"], "title": "Strained hyperbolic Dirac fermions: Zero modes, flat bands, and competing orders", "comment": "19 Pages, 11 Figures, and 1 Table (For full Abstract see manuscript)", "summary": "Starting from the nearest-neighbor tight-binding model on {10,3} and {14,3} hyperbolic lattices that, for a uniform hopping amplitude, gives rise to emergent Dirac fermions on a curved space with a constant negative curvature, displaying a vanishing density of states, we propose spatially modulated hopping pattern therein that preserve the underlying 5- and 7-fold rotational symmetries, respectively, and effectively couples fermions to time-reversal symmetric axial magnetic fields. Such strain-induced axial fields produce a flat band near zero-energy, triggering nucleation of a charge density-wave, featuring a staggered pattern of fermionic density between two sublattices, and the Haldane phase fostering intra-sublattice circulating currents with a net zero magnetic flux for weak nearest- and next-nearest-neighbor Coulomb repulsions, respectively. Sufficiently weak on-site Hubbard repulsion destabilizes such flat bands toward the formation of a magnetic phase that simultaneously supports antiferromagnetic and ferromagnetic orders in the whole system. While the magnetization in the bulk and boundary cancel each other, the Neél order is of the same sign everywhere, thereby yielding a global antiferromagnet. Throughout, we draw parallels between these findings and the well-studied qualitatively similar results on a 3-fold rotational symmetric strained honeycomb lattice, thereby unifying the phenomenon of axial magnetic catalysis for Dirac fermions, encompassing the ones living on the Euclidean plane. Finally, we show that with a specific class of non-Hermiticity, manifesting via an imbalance in the hopping amplitudes between two sublattices in the opposite directions, magnitudes of all these orders can be boosted substantially when all the eigenvalues in the noninteracting systems are real, staging a non-Hermitian amplification of axial magnetic catalysis."}
{"id": "2511.16251", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.16251", "abs": "https://arxiv.org/abs/2511.16251", "authors": ["Ludovic Sacchelli", "Alessandro Scagliotti"], "title": "A case study in ensemble optimal control for Bayesian input design", "comment": null, "summary": "We discuss the problem of input design for uncertainty reduction in a parameter estimation procedure. Assuming a linear continuous-time control system with noisy measurements, we formulate an objective of variance reduction in a Bayesian Gaussian setting as an optimal control problem and analyze it from a geometric control perspective. The resulting cost functional depends on the unknown parameter, we compare the optimal control approach with a non-standard alternative inspired by ensemble control, where the cost is averaged over the prior distribution after computation, rather than before. This requires the statement of a generalized Pontryagin's maximum principle adapted to Gaussian distributions."}
{"id": "2511.15910", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15910", "abs": "https://arxiv.org/abs/2511.15910", "authors": ["Sahil Khan", "Abhinav Anand", "Kenneth R. Brown", "Jonathan M. Baker"], "title": "Cyclone: Designing Efficient and Highly Parallel QCCD Architectural Codesigns for Fault Tolerant Quantum Memory", "comment": "Accepted into HPCA 2026", "summary": "Modular trapped-ion quantum computing hardware, known as QCCDs require shuttling operations in order to maintain effective all-to-all connectivity. Each module or trap can perform only one operation at a time, resulting in low intra-trap parallelism, but there is no restriction on operations happening on independent traps, enabling high inter-trap parallelism. Unlike their superconducting counterparts, the design space for QCCDs is relatively flexible and can be explored beyond current grid designs. In particular, current grid-based architectures significantly limit the performance of many promising, high-rate codes such as HGP codes and BB codes, suffering from numerous trap to trap ``roadblocks\", forcing serialization and destroying the inherent parallelism of these codes.. Many of these codes are highly parallelizable, meaning that with appropriate hardware layouts and matching software schedules, execution latency can be reduced. Faster execution, in turn, reduces error accumulation from decoherence and heating, ultimately improving code performance when mapped to realistic hardware. To address this, we propose Cyclone, a circular software-hardware codesign that departs from traditional 2D grids in favor of a flexible ring topology, where ancilla qubits move in lockstep. Cyclone eliminates roadblocks, bounds total movement, and enables high levels of parallelism, resulting in up to ~4$\\times$ speedup in execution times. With HGP codes, Cyclone achieves up to a 2$\\times$ order of magnitude improvement in logical error rate, and with BB codes, this improvement reaches up to a 3$\\times$ in order of magnitude.Spatially, Cyclone reduces the number of required traps and ancilla qubits by $2\\times$.The overall spacetime improvement over a standard grid is up to $\\sim 20 \\times$, demonstrating Cyclone as a scalable and efficient alternative to conventional 2D QCCD architectures."}
{"id": "2511.16235", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16235", "abs": "https://arxiv.org/abs/2511.16235", "authors": ["Robin Wroblowski", "Rodolphe Sepulchre"], "title": "Describing Functions and Phase Response Curves of Excitable Systems", "comment": "7 pages, 6 figures, submitted to European Control Conference 2026", "summary": "The describing function (DF) and phase response curve (PRC) are classical tools for the analysis of feedback oscillations and rhythmic behaviors, widely used across control engineering, biology, and neuroscience. These tools are known to have limitations in networks of relaxation oscillators and excitable systems. For this reason, the paper proposes a novel approach tailored to excitable systems. Our analysis focuses on the discrete-event operator mapping input trains of events to output trains of events. The methodology is illustrated on the excitability model of Hodgkin-Huxley. The proposed framework provides a basis for designing and analyzing central pattern generators in networks of excitable neurons, with direct relevance to neuromorphic control and neurophysiology."}
{"id": "2511.16102", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.16102", "abs": "https://arxiv.org/abs/2511.16102", "authors": ["Bankitdor M Nongrum", "Adarsha Kumar Jena"], "title": "Estimation of the Coefficient of Variation of Weibull Distribution under Type-I Progressively Interval Censoring: A Simulation-based Approach", "comment": null, "summary": "Measures of relative variability, such as the Pearson's coefficient of variation (CV$_p$), give much insight into the spread of lifetime distributions, like the Weibull distribution. The estimation of the Weibull CV$_p$ in modern statistics has traditionally been prioritized only when complete data is available. In this article, we estimate the Weibull CV$_p$ and its second-order alternative, denoted as CV$_k$, under type-I progressively interval censoring, which is a typical scenario in survival analysis and reliability theory. Point estimates are obtained using the methods of maximum likelihood, least squares, and the Bayesian approach with MCMC simulation. A nonlinear least squares method is proposed for estimating the CV$_p$ and CV$_k$. We also perform interval estimation of the CV$_p$ and CV$_k$ using the asymptotic confidence intervals, bootstrap intervals through the least squares estimates, and the highest posterior density intervals. A comprehensive Monte Carlo simulation study is carried out to understand and compare the performance of the estimators. The proposed least squares and the Bayesian methods produce better point estimates for the CV$_p$. The highest posterior density intervals outperform other interval estimates in many cases. The methodologies are also applied to a real dataset to demonstrate the performance of the estimators."}
{"id": "2511.16457", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "cond-mat.quant-gas", "physics.data-an", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16457", "abs": "https://arxiv.org/abs/2511.16457", "authors": ["Yoshiaki Horiike", "Yuki Kawaguchi"], "title": "Distinguishing thermal versus quantum annealing using probability-flux signatures across interaction networks", "comment": null, "summary": "Simulated annealing provides a heuristic solution to combinatorial optimization problems. The cost function of a problem is mapped to the energy function of a physical many-body system, and, using thermal or quantum fluctuations, the system explores the state space to find the ground state, which may correspond to the optimal solution of the problem. Studies have highlighted both the similarities and differences between thermal and quantum fluctuations. Nevertheless, fundamental understanding of thermal and quantum annealing remains incomplete, making it difficult to design problem instances that fairly compare the two methods. Here, we investigate the many-body dynamics of thermal and quantum annealing by examining all possible interaction networks of $\\pm J$ Ising spin systems up to seven spins. Our comprehensive investigation reveals that differences between thermal and quantum annealing emerge for particular interaction networks, indicating that the structure of the energy landscape distinguishes the two dynamics. We identify the microscopic origin of these differences through probability fluxes in state space, finding that the two dynamics are broadly similar but that quantum tunnelling produces qualitative differences. Our results provide insight into how thermal and quantum fluctuations navigate a system toward the ground state in simulated annealing, and are experimentally verifiable in atomic, molecular, and optical systems. Furthermore, these insights may improve mappings of optimization problems to Ising spin systems, yielding more accurate solutions in faster simulated annealing and thus benefiting real-world applications in industry. Our comprehensive survey of interaction networks and visualization of probability flux can help to understand, predict, and control quantum advantage in quantum annealing."}
{"id": "2511.16235", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16235", "abs": "https://arxiv.org/abs/2511.16235", "authors": ["Robin Wroblowski", "Rodolphe Sepulchre"], "title": "Describing Functions and Phase Response Curves of Excitable Systems", "comment": "7 pages, 6 figures, submitted to European Control Conference 2026", "summary": "The describing function (DF) and phase response curve (PRC) are classical tools for the analysis of feedback oscillations and rhythmic behaviors, widely used across control engineering, biology, and neuroscience. These tools are known to have limitations in networks of relaxation oscillators and excitable systems. For this reason, the paper proposes a novel approach tailored to excitable systems. Our analysis focuses on the discrete-event operator mapping input trains of events to output trains of events. The methodology is illustrated on the excitability model of Hodgkin-Huxley. The proposed framework provides a basis for designing and analyzing central pattern generators in networks of excitable neurons, with direct relevance to neuromorphic control and neurophysiology."}
{"id": "2511.15896", "categories": ["stat.ME", "math.ST", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.15896", "abs": "https://arxiv.org/abs/2511.15896", "authors": ["Ying Jin", "José Zubizarreta"], "title": "Cross-Balancing for Data-Informed Design and Efficient Analysis of Observational Studies", "comment": null, "summary": "Causal inference starts with a simple idea: compare groups that differ by treatment, not much else. Traditionally, similar groups are constructed using only observed covariates; however, it remains a long-standing challenge to incorporate available outcome data into the study design while preserving valid inference. In this paper, we study the general problem of covariate adjustment, effect estimation, and statistical inference when balancing features are constructed or selected with the aid of outcome information from the data. We propose cross-balancing, a method that uses sample splitting to separate the error in feature construction from the error in weight estimation. Our framework addresses two cases: one where the features are learned functions and one where they are selected from a potentially high-dimensional dictionary. In both cases, we establish mild and general conditions under which cross-balancing produces consistent, asymptotically normal, and efficient estimators. In the learned-function case, cross-balancing achieves finite-sample bias reduction relative to plug-in-type estimators, and is multiply robust when the learned features converge at slow rates. In the variable-selection case, cross-balancing only requires a product condition on how well the selected variables approximate true functions. We illustrate cross-balancing in extensive simulations and an observational study, showing that careful use of outcome information can substantially improve both estimation and inference while maintaining interpretability."}
{"id": "2511.16238", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.16238", "abs": "https://arxiv.org/abs/2511.16238", "authors": ["Arshyn Altybay", "Niyaz Tokmagambetov", "Gulzat Nalzhupbayeva"], "title": "Numerical identification of the time-dependent coefficient in the heat equation with fractional Laplacian", "comment": null, "summary": "We address the inverse problem of identifying a time-dependent source coefficient in a one-dimensional heat equation with a fractional Laplacian subject to Dirichlet boundary conditions and an integral nonlocal data. An a priori estimate is established to ensure the uniqueness and stability of the solution. A fully implicit Crank-Nicolson (CN) finite-difference scheme is proposed and rigorously analysed for stability and convergence. An efficient noise-stable computation algorithm is developed and verified through numerical experiments, demonstrating accuracy and robustness under noisy data."}
{"id": "2511.16460", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16460", "abs": "https://arxiv.org/abs/2511.16460", "authors": ["Margaux Vrech", "Jan Major", "Dominique Delande", "Marcel Filoche", "Nicolas Cherroret"], "title": "From percolation transition to Anderson localization in one-dimensional speckle potentials", "comment": null, "summary": "Classical particles in random potentials typically experience a percolation phase transition, being trapped in clusters of mean size $χ$ that diverges algebraically at a percolation threshold. In contrast, quantum transport in random potentials is controlled by the Anderson localization length, which shows no distinct feature at this classical critical point. Here, we present a comprehensive theoretical analysis of the semi-classical crossover between these two regimes by studying particle propagation in a one-dimensional, red speckle potential, which hosts a percolation transition at its upper bound. As the system deviates from the classical limit, we find that the algebraic divergence of $χ$ continuously connects to a smooth yet non-analytic increase of the localization length. We characterize this behavior both numerically and theoretically using a semi-classical approach. In this crossover regime, the correlated and non-Gaussian nature of the speckle potential becomes essential, causing the standard DMPK description for uncorrelated disorder to break down. Instead, we predict the emergence of a bimodal transmission distribution, a behavior normally absent in one dimension, which we capture within our semi-classical analysis. Deep in the quantum regime, the DMPK framework is recovered and the universal features of Anderson localization reappear."}
{"id": "2511.16473", "categories": ["quant-ph", "cond-mat.str-el", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.16473", "abs": "https://arxiv.org/abs/2511.16473", "authors": ["Martín Zapata", "Federico Finkel", "Artemio González-López"], "title": "Local fermion density in inhomogeneous free-fermion chains: a discrete WKB approach", "comment": "35 pages, 14 figures, supplementary material linked", "summary": "We introduce a novel analytical approach for studying free-fermion (XX) chains with smoothly varying, site-dependent hoppings and magnetic fields. Building on a discrete WKB-like approximation applied directly to the recurrence relation for the single-particle eigenfunctions, we derive a closed-form expression for the local fermion density profile as a function of the Fermi energy, which is valid for arbitrary fillings, hopping amplitudes and magnetic fields. This formula reproduces the depletion and saturation effects observed in previous studies of inhomogeneous free-fermion chains, and provides a theoretical framework to understand entanglement entropy suppression in these models. We demonstrate the accuracy of our asymptotic formula in several chains with different hopping and magnetic field profiles. Our findings are thus the first step towards an analytical treatment of entanglement in free-fermion chains beyond the reach of conventional field-theoretic techniques."}
{"id": "2511.16336", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.16336", "abs": "https://arxiv.org/abs/2511.16336", "authors": ["G. C. Bento", "J. X. Cruz Neto", "J. O. Lopes", "B. S. Mordukhovich", "P. R. Silva Filho"], "title": "Regularized Multiobjective Optimization with Directionally Lipschitzian Data", "comment": "15 pages", "summary": "The paper is devoted to the study of regularized versions of multiobjective optimization problems described by directionally Lipschitzian functions. Such regularizations appear in proximal-type algorithms of multiobjective optimization, various models of machine learning, medical physics, etc. We investigate and illustrate several useful properties of directionally Lipschitzian functions, which distinguish them from locally Lipschitzian ones. By using advanced tools of variational analysis and generalized differentiation revolving around the limiting/Mordukhovich subdifferential, we derive necessary conditions for Pareto optimality in regularized multiobjective problems."}
{"id": "2511.15911", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15911", "abs": "https://arxiv.org/abs/2511.15911", "authors": ["Gabriel M. Arantes", "Vinícius Salem", "Danilo Cius", "Bárbara Amaral"], "title": "k-Uniform complete hypergraph states stabilizers in terms of local operators", "comment": "9 pages, 1 figure", "summary": "In this work, we present a novel method to express the stabilizer of a k-uniform complete hypergraph state as a linear combination of local operators. Quantum hypergraph states generalize graph states and exhibit properties that are not shared by their graph counterparts, most notably, their stabilizers are intrinsically nonlocal, as hyperedges can involve arbitrary subsets of vertices. Our formulation provides an explicit description of the stabilizers for k-uniform complete hypergraphs and may offer new insights for exploring these states within the stabilizer formalism. In particular, this approach could facilitate the construction of new Bell inequalities or find applications in quantum error correction."}
{"id": "2511.16253", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16253", "abs": "https://arxiv.org/abs/2511.16253", "authors": ["Abbas Tariverdi"], "title": "Robust Self-Triggered Control Approaches Optimizing Sensors Utilization with Asynchronous Measurements", "comment": "This research was conducted in 2017--2018. The literature review has not been updated and may not reflect subsequent or concurrent developments in the field", "summary": "Most control systems run on digital hardware with limited communication resources. This work develops self-triggered control for linear systems where sensors update independently (asynchronous measurements). The controller computes an optimal horizon at each sampling instant, selecting which sensor to read over the next several time steps to maximize inter-sample intervals while maintaining stability.\n  Two implementations address computational complexity. The online version solves an optimization problem at each update for theoretical optimality. The offline version precomputes optimal horizons using conic partitioning, reducing online computation to a lookup. Both guarantee exponential stability for unperturbed systems and global uniform ultimate boundedness for systems with bounded disturbances. Simulations demonstrate 59-74\\% reductions in sensor utilization compared to periodic sampling. The framework enables resource-efficient control in networked systems with communication constraints."}
{"id": "2511.16568", "categories": ["math.OC", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.16568", "abs": "https://arxiv.org/abs/2511.16568", "authors": ["Lai Tian", "Johannes O. Royset"], "title": "Failure of uniform laws of large numbers for subdifferentials and beyond", "comment": "14 pages, 2 figures", "summary": "We provide counterexamples showing that uniform laws of large numbers do not hold for subdifferentials under natural assumptions. Our results apply to random Lipschitz functions and random convex functions with a finite number of smooth pieces. Consequently, they resolve the questions posed by Shapiro and Xu [J. Math. Anal. Appl., 325(2), 2007] in the negative and highlight the obstacles nonsmoothness poses to uniform results."}
{"id": "2511.16509", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16509", "abs": "https://arxiv.org/abs/2511.16509", "authors": ["J. Sirker"], "title": "Comment on: \"Scaling and Universality at Noisy Quench Dynamical Quantum Phase Transitions\"", "comment": "Comment on arXiv:2506.14355", "summary": "In Ref. Ansari et al., dynamical quantum phase transitions (DQPTs) -- non-analyticities in the Loschmidt return rate at critical times -- are investigated in the presence of noise for a two-band model. The authors report that DQPTs persist even after averaging over the noise and they use their results to derive dynamical phase diagrams. In this comment we rigorously prove that in any two-dimensional Hilbert space the Loschmidt echo of two density matrices can only become zero if and only if both density matrices are pure. As a consequence, the existence of DQPTs in the considered scenario is strictly ruled out for non-zero noise because the considered averaging leads to a mixed state. We also investigate alternative natural ways to average over noise realizations and show that in all of them DQPTs are smoothed out."}
{"id": "2511.16253", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16253", "abs": "https://arxiv.org/abs/2511.16253", "authors": ["Abbas Tariverdi"], "title": "Robust Self-Triggered Control Approaches Optimizing Sensors Utilization with Asynchronous Measurements", "comment": "This research was conducted in 2017--2018. The literature review has not been updated and may not reflect subsequent or concurrent developments in the field", "summary": "Most control systems run on digital hardware with limited communication resources. This work develops self-triggered control for linear systems where sensors update independently (asynchronous measurements). The controller computes an optimal horizon at each sampling instant, selecting which sensor to read over the next several time steps to maximize inter-sample intervals while maintaining stability.\n  Two implementations address computational complexity. The online version solves an optimization problem at each update for theoretical optimality. The offline version precomputes optimal horizons using conic partitioning, reducing online computation to a lookup. Both guarantee exponential stability for unperturbed systems and global uniform ultimate boundedness for systems with bounded disturbances. Simulations demonstrate 59-74\\% reductions in sensor utilization compared to periodic sampling. The framework enables resource-efficient control in networked systems with communication constraints."}
{"id": "2511.15904", "categories": ["stat.ME", "econ.EM", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.15904", "abs": "https://arxiv.org/abs/2511.15904", "authors": ["Gözde Sert", "Abhishek Chakrabortty", "Anirban Bhattacharya"], "title": "Bayesian Semiparametric Causal Inference: Targeted Doubly Robust Estimation of Treatment Effects", "comment": "48 pages (including supplement)", "summary": "We propose a semiparametric Bayesian methodology for estimating the average treatment effect (ATE) within the potential outcomes framework using observational data with high-dimensional nuisance parameters. Our method introduces a Bayesian debiasing procedure that corrects for bias arising from nuisance estimation and employs a targeted modeling strategy based on summary statistics rather than the full data. These summary statistics are identified in a debiased manner, enabling the estimation of nuisance bias via weighted observables and facilitating hierarchical learning of the ATE. By combining debiasing with sample splitting, our approach separates nuisance estimation from inference on the target parameter, reducing sensitivity to nuisance model specification. We establish that, under mild conditions, the marginal posterior for the ATE satisfies a Bernstein-von Mises theorem when both nuisance models are correctly specified and remains consistent and robust when only one is correct, achieving Bayesian double robustness. This ensures asymptotic efficiency and frequentist validity. Extensive simulations confirm the theoretical results, demonstrating accurate point estimation and credible intervals with nominal coverage, even in high-dimensional settings. The proposed framework can also be extended to other causal estimands, and its key principles offer a general foundation for advancing Bayesian semiparametric inference more broadly."}
{"id": "2511.16149", "categories": ["quant-ph", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.16149", "abs": "https://arxiv.org/abs/2511.16149", "authors": ["Ariel Neufeld", "Philipp Schmocker", "Viet Khoa Tran"], "title": "Approximation rates of quantum neural networks for periodic functions via Jackson's inequality", "comment": null, "summary": "Quantum neural networks (QNNs) are an analog of classical neural networks in the world of quantum computing, which are represented by a unitary matrix with trainable parameters. Inspired by the universal approximation property of classical neural networks, ensuring that every continuous function can be arbitrarily well approximated uniformly on a compact set of a Euclidean space, some recent works have established analogous results for QNNs, ranging from single-qubit to multi-qubit QNNs, and even hybrid classical-quantum models. In this paper, we study the approximation capabilities of QNNs for periodic functions with respect to the supremum norm. We use the Jackson inequality to approximate a given function by implementing its approximating trigonometric polynomial via a suitable QNN. In particular, we see that by restricting to the class of periodic functions, one can achieve a quadratic reduction of the number of parameters, producing better approximation results than in the literature. Moreover, the smoother the function, the fewer parameters are needed to construct a QNN to approximate the function."}
{"id": "2511.16443", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2511.16443", "abs": "https://arxiv.org/abs/2511.16443", "authors": ["Tuuli Sillanpää", "Sanni Nousiainen", "Lasse Laurson"], "title": "Height distribution of elastic interfaces in quenched random media", "comment": "9 pages, 6 figures", "summary": "Elastic interfaces in quenched random media driven by external forces exhibit a continuous depinning phase transition between pinned and moving phases at a critical external force. Recent work [Phys. Rev. Lett. 129, 175701 (2022)] has shown that the distribution of local interface heights at depinning displays negative skewness. Here, by considering local, long-range and fully-coupled (mean-field) elasticity, we expand on this result by demonstrating the robustness of the negative skewness at depinning when approaching the thermodynamic limit and considering different values of the spring stiffness controlling the avalanche cutoff. Additionally, we investigate the evolution of the height distribution as the external force is ramped up from zero, approaching the critical force from below. Starting from a symmetric height distribution at zero force, the distribution initially develops positive skewness increasing with the external force, followed by a steep drop to the negative value characteristic of the critical point as the depinning transition is reached."}
{"id": "2511.16509", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16509", "abs": "https://arxiv.org/abs/2511.16509", "authors": ["J. Sirker"], "title": "Comment on: \"Scaling and Universality at Noisy Quench Dynamical Quantum Phase Transitions\"", "comment": "Comment on arXiv:2506.14355", "summary": "In Ref. Ansari et al., dynamical quantum phase transitions (DQPTs) -- non-analyticities in the Loschmidt return rate at critical times -- are investigated in the presence of noise for a two-band model. The authors report that DQPTs persist even after averaging over the noise and they use their results to derive dynamical phase diagrams. In this comment we rigorously prove that in any two-dimensional Hilbert space the Loschmidt echo of two density matrices can only become zero if and only if both density matrices are pure. As a consequence, the existence of DQPTs in the considered scenario is strictly ruled out for non-zero noise because the considered averaging leads to a mixed state. We also investigate alternative natural ways to average over noise realizations and show that in all of them DQPTs are smoothed out."}
{"id": "2511.16358", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.16358", "abs": "https://arxiv.org/abs/2511.16358", "authors": ["Ziyi Gan", "Chunfeng Cui"], "title": "iFCTN: Folding-Free Fully-Connected Tensor Network Decomposition for Tensor Completion", "comment": null, "summary": "The fully-connected tensor network (FCTN) decomposition has recently exhibited strong modeling capabilities by connecting every pair of tensor factors, thereby capturing rich cross-mode correlations and maintaining invariance under mode transpositions. However, this advantage comes with an inherent limitation: updating the factors typically requires reconstructing auxiliary sub-networks, which entails extensive and cumbersome (un)folding. In this study, we propose intra-block FCTN (iFCTN) decomposition, a novel (un)folding-free variant of FCTN decomposition that streamlines computation. We parameterize each FCTN factor through Khatri-Rao products, which significantly reduces the complexity of reconstructing intermediate sub-networks and yields subproblems with well-structured coefficient matrices. Furthermore, we deploy the proposed iFCTN decomposition on the representative task of tensor completion and design an efficient proximal alternating minimization algorithm while retaining convergence guarantees. Extensive experiments demonstrate that iFCTN outperforms or matches state-of-the-art methods with comparable computational cost."}
{"id": "2511.15919", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.15919", "abs": "https://arxiv.org/abs/2511.15919", "authors": ["Einar Gabbassov"], "title": "Reversing Quantum Noise: Quantum Reverse Diffusion for Pauli Channels", "comment": null, "summary": "The ensemble-averaged dynamics of open quantum systems are typically irreversible. We show that this irreversibility need not hold at the level of individually monitored quantum trajectories. Our main results are quantum reverse diffusion stochastic differential equations, along with corresponding stochastic master equations. These equations describe the exact and approximate reverse diffusion dynamics for continuously monitored Pauli channels, including time-dependent depolarizing noise. Our results bridge the gap between highly nonlinear classical reverse diffusion, prominent in generative modelling, and linear quantum mechanics. Consequently, this establishes a theoretical framework for diffusion-driven quantum gates, quantum tomography via forward-reverse cycles, and potential paradigms for quantum error correction based on reverse diffusion."}
{"id": "2511.16279", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16279", "abs": "https://arxiv.org/abs/2511.16279", "authors": ["Ziyue Li", "Guanglun Zhang", "Grant Ruan", "Haiwang Zhong", "Chongqing Kang"], "title": "Spatially Dependent Sampling of Component Failures for Power System Preventive Control Against Hurricane", "comment": null, "summary": "Preventive control is a crucial strategy for power system operation against impending natural hazards, and its effectiveness fundamentally relies on the realism of scenario generation. While most existing studies employ sequential Monte Carlo simulation and assume independent sampling of component failures, this oversimplification neglects the spatial correlations induced by meteorological factors such as hurricanes. In this paper, we identify and address the gap in modeling spatial dependence among component failures under extreme weather. We analyze how the mean, variance, and correlation structure of weather intensity random variables influence the correlation of component failures. To fill this gap, we propose a spatially dependent sampling method that enables joint sampling of multiple component failures by generating correlated meteorological intensity random variables. Comparative studies show that our approach captures long-tailed scenarios and reveals more extreme events than conventional methods. Furthermore, we evaluate the impact of scenario selection on preventive control performance. Our key findings are: (1) Strong spatial correlations in uncertain weather intensity consistently lead to interdependent component failures, regardless of mean value level; (2) The proposed method uncovers more high-severity scenarios that are missed by independent sampling; (3) Preventive control requires balancing load curtailment and over-generation costs under different scenario severities; (4) Ignoring failure correlations results in underestimating risk from high-severity events, undermining the robustness of preventive control strategies."}
{"id": "2511.16510", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.16510", "abs": "https://arxiv.org/abs/2511.16510", "authors": ["Andrea Pelissetto", "Davide Rossini", "Ettore Vicari"], "title": "Out-of-equilibrium spinodal-like scaling behaviors at the thermal first-order transitions of three-dimensional q-state Potts models", "comment": "9 pages", "summary": "We study the out-of-equilibrium spinodal-like dynamics of three-dimensional $q$-state Potts systems driven across their thermal first-order transition in the thermodynamic limit, by a relaxational (heat-bath) dynamics. During the evolution, the inverse temperature $β$ increases linearly with time, as $δβ(t)\\equiv β(t)- β_{\\rm fo} \\sim t/t_s$, where $β_{\\rm fo}$ is the inverse temperature at the transition point, $t$ is the time and $t_s$ is a time scale. The dynamics starts at $t_i< 0$ from an ensemble of disordered configurations equilibrated at inverse temperature $β(t_i)<β_{\\rm fo}$ and ends at positive values of $t$, when the system is ordered (this is analogous to a standard Kibble-Zurek protocol). The time-dependent energy density shows an out-of-equilibrium scaling behavior in the large-$t_s$ limit, in terms of the scaling variable $t(\\ln t)^κ/t_s$. The corresponding exponent turns out to be consistent with $κ=3/2$ (with a good accuracy), which is the value obtained by assuming that the initial nucleation of ordered regions provides the relevant mechanism for the passage from one phase to the other. The scaling behavior implies a spinodal-like phenomenon close to the transition point: the passage from the disordered to the ordered phase, composed of large ordered regions of different color, occurs at $δβ(t)=δβ_*>0$, where $δβ_*$ decreases as $1/(\\ln t_s)^{3/2}$ in the large-$t_s$ limit."}
{"id": "2511.16279", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16279", "abs": "https://arxiv.org/abs/2511.16279", "authors": ["Ziyue Li", "Guanglun Zhang", "Grant Ruan", "Haiwang Zhong", "Chongqing Kang"], "title": "Spatially Dependent Sampling of Component Failures for Power System Preventive Control Against Hurricane", "comment": null, "summary": "Preventive control is a crucial strategy for power system operation against impending natural hazards, and its effectiveness fundamentally relies on the realism of scenario generation. While most existing studies employ sequential Monte Carlo simulation and assume independent sampling of component failures, this oversimplification neglects the spatial correlations induced by meteorological factors such as hurricanes. In this paper, we identify and address the gap in modeling spatial dependence among component failures under extreme weather. We analyze how the mean, variance, and correlation structure of weather intensity random variables influence the correlation of component failures. To fill this gap, we propose a spatially dependent sampling method that enables joint sampling of multiple component failures by generating correlated meteorological intensity random variables. Comparative studies show that our approach captures long-tailed scenarios and reveals more extreme events than conventional methods. Furthermore, we evaluate the impact of scenario selection on preventive control performance. Our key findings are: (1) Strong spatial correlations in uncertain weather intensity consistently lead to interdependent component failures, regardless of mean value level; (2) The proposed method uncovers more high-severity scenarios that are missed by independent sampling; (3) Preventive control requires balancing load curtailment and over-generation costs under different scenario severities; (4) Ignoring failure correlations results in underestimating risk from high-severity events, undermining the robustness of preventive control strategies."}
{"id": "2511.15917", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.15917", "abs": "https://arxiv.org/abs/2511.15917", "authors": ["Austin E Schumacher", "Jon Wakefield"], "title": "Small Area Estimation Methods for Multivariate Health and Demographic Outcomes using Complex Survey Data", "comment": "23 pages, 9 figures, 3 tables", "summary": "Improving health in the most disadvantaged populations requires reliable estimates of health and demographic indicators to inform policy and interventions. Low- and middle-income countries with the largest burden of disease and disability tend to have the least comprehensive data, relying primarily on household surveys. Subnational estimates are increasingly used to inform targeted interventions and health policies. Producing reliable estimates from these data at fine geographical scales requires statistical modeling, and small area estimation models are commonly used in this context. Although most current methods model univariate outcomes, improved estimates may be attained by borrowing strength across related outcomes via multivariate modeling. In this paper, we develop classes of area- and unit-level multivariate shared component models using complex survey data. This framework jointly models multiple outcomes to improve accuracy of estimates compared to separately fitting univariate models. We conduct simulation studies to validate the methodology and use the proposed approach on survey data from Kenya in 2014; first, to jointly model height-for-age and weight-for-age in children, and second, to model three categories of contraceptive use in women. These models produce improved estimates compared to univariate and naive multivariate modeling approaches."}
{"id": "2511.16420", "categories": ["math.OC", "cs.DC", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.16420", "abs": "https://arxiv.org/abs/2511.16420", "authors": ["Shaked Regev", "Eve Tsybina", "Slaven Peles"], "title": "A Fast Relax-and-Round Approach to Unit Commitment for Data Center Own Generation", "comment": "Limited to 5 pages and this format for IEEE PESGM conference", "summary": "The rapid growth of data centers increasingly requires data center operators to \"bring own generation\" to complement the available utility power plants to supply all or part of data center load. This practice sharply increases the number of generators on the bulk power system and shifts operational focus toward fuel costs rather than traditional startup and runtime constraints. Conventional mixed-integer unit commitment formulations are not well suited for systems with thousands of flexible, fast-cycling units. We propose a unit commitment formulation that relaxes binary commitment decisions by allowing generators to be fractionally on, enabling the use of algorithms for continuous solvers. We then use a rounding approach to get a feasible unit commitment. For a 276-unit system, solution time decreases from 10 hours to less than a second, with minor accuracy degradation. Our approach scales with no issues to tens of thousands of generators, which allows solving problems on the scale of the major North America interconnections. The bulk of computation is parallel and GPU compatible, enabling further acceleration in future work."}
{"id": "2511.16457", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "cond-mat.quant-gas", "physics.data-an", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16457", "abs": "https://arxiv.org/abs/2511.16457", "authors": ["Yoshiaki Horiike", "Yuki Kawaguchi"], "title": "Distinguishing thermal versus quantum annealing using probability-flux signatures across interaction networks", "comment": null, "summary": "Simulated annealing provides a heuristic solution to combinatorial optimization problems. The cost function of a problem is mapped to the energy function of a physical many-body system, and, using thermal or quantum fluctuations, the system explores the state space to find the ground state, which may correspond to the optimal solution of the problem. Studies have highlighted both the similarities and differences between thermal and quantum fluctuations. Nevertheless, fundamental understanding of thermal and quantum annealing remains incomplete, making it difficult to design problem instances that fairly compare the two methods. Here, we investigate the many-body dynamics of thermal and quantum annealing by examining all possible interaction networks of $\\pm J$ Ising spin systems up to seven spins. Our comprehensive investigation reveals that differences between thermal and quantum annealing emerge for particular interaction networks, indicating that the structure of the energy landscape distinguishes the two dynamics. We identify the microscopic origin of these differences through probability fluxes in state space, finding that the two dynamics are broadly similar but that quantum tunnelling produces qualitative differences. Our results provide insight into how thermal and quantum fluctuations navigate a system toward the ground state in simulated annealing, and are experimentally verifiable in atomic, molecular, and optical systems. Furthermore, these insights may improve mappings of optimization problems to Ising spin systems, yielding more accurate solutions in faster simulated annealing and thus benefiting real-world applications in industry. Our comprehensive survey of interaction networks and visualization of probability flux can help to understand, predict, and control quantum advantage in quantum annealing."}
{"id": "2511.16360", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.16360", "abs": "https://arxiv.org/abs/2511.16360", "authors": ["Nizar Bousselmi", "Zhicheng Deng", "Jie Lu", "Francois Glineur", "Julien M. Hendrickx"], "title": "On the Convex Interpolation for Linear Operators", "comment": null, "summary": "The worst-case performance of an optimization method on a problem class can be analyzed using a finite description of the problem class, known as interpolation conditions. In this work, we study interpolation conditions for linear operators given scalar products between discrete inputs and outputs. First, we show that if only convex constraints on the scalar products of inputs and outputs are allowed,it is only possible to characterize classes of linear operators or symmetric linear operator whose all singular values or eigenvalues belong to some subset of R. Then, we propose new interpolation conditions for linear operators with minimal and maximal singular values and linear operators whose eigenvalues or singular values belong to unions of subsets. Finally, we illustrate the new interpolation conditions through the analysis of the Gradient and Chambolle-Pock methods. It allows to obtain new numerical worst-case guarantees on these methods."}
{"id": "2511.15931", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.15931", "abs": "https://arxiv.org/abs/2511.15931", "authors": ["Yifan Song", "Nabiha Hasan", "Susumu Takahashi"], "title": "Generation of spin-squeezed states using dipole-coupled spins", "comment": "12 pages, 16 figures", "summary": "Spins in solids and molecules are promising for applications of quantum sensing technology. The sensitivity of the quantum sensing depends on how precisely spin observables can be determined in the measurement, and is intrinsically limited by the uncertainties of the observables. The use of a spin-squeezed state in a quantum sensor can reduce the uncertainty below the standard quantum limit when combined with an appropriate measurement procedure. Here, we discuss the simulation study of the generation of a squeezed state in an interacting spin system. We show that a spin system coupled by the magnetic dipole interaction can create a squeezed state. Model systems to realize the spin squeezing experimentally are also discussed. In addition, we find that a squeezed state is a type of entangled state. The present work paves the way to realize a squeezed state using a spin system to build a quantum sensor network with improved sensitivity, and to use it for the detection of quantum entanglement."}
{"id": "2511.16399", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16399", "abs": "https://arxiv.org/abs/2511.16399", "authors": ["Siddhesh Pimpale"], "title": "A Comprehensive Study on Cyber Attack Vectors in EV Traction Power Electronics", "comment": "15 pages, 3 Figures", "summary": "Electric vehicles (EVs) have drastically changed the auto industry and developed a new era of technologies where power electronics play the leading role in traction management, energy conversion and vehicle control processes. Nevertheless, this is a digital transformation, and the cyber-attack surface area has increased considerably, to the point that EV traction power electronics are becoming vulnerable to various cybersecurity risks. This paper is able to provide its expertise on possible cyber-attack vectors which can attack important parts of the traction, powertrain, including things like inverters, motor controllers, and communicated systems within the embedded bits. Using the (STRIDE) threat modeling framework, the research outlines and groups the vulnerabilities of the architecture and runs some attack simulations, such as the Denial of Service (DoS), spoofing, firmware manipulation, and data injection. The experiments prove the fact that a slight interruption in the control signal, the sensed data may lead to the severe working implications, such as unstable sensor values of the torque, abnormal voltage shifts, and entire system freezes. These results highlight the high priority on the need of injective embedded intrusion preventive mechanisms and secure design of firmware in EV powertrain electronics. In this paper, the author makes his contribution to the general body of knowledge that underpins the links existing between cyber security practices and the peculiar needs of automotive power electronics."}
{"id": "2511.15971", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.15971", "abs": "https://arxiv.org/abs/2511.15971", "authors": ["Donny Dwiputra", "Mir Faizal", "Francesco Marino", "Freddy P. Zen"], "title": "Universal work statistics in quenched gapless quantum systems", "comment": "14 pages, 1 figure", "summary": "We study the universality of work statistics performed during a quench in gapless quantum systems. We show that the cumulants of work scale separately in the fast and slow quench regimes, following a power law analogous to the universal scaling in the Kibble-Zurek mechanism for topological defect formation in phase transition. As an example, we analyze the nonequilibrium dynamics of a quenched Heisenberg XXZ chain at its critical gapless state using the bosonization picture, resulting in a Tomonaga-Luttinger liquid. The analytical scaling is in agreement with the exact numerical calculation for the fast and slow quench regimes. In finite systems, the characteristic function display an oscillatory pattern which disappears in the thermodynamic limit. This study is particularly useful for understanding the thermodynamics of adiabatic quantum computation."}
{"id": "2511.16399", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16399", "abs": "https://arxiv.org/abs/2511.16399", "authors": ["Siddhesh Pimpale"], "title": "A Comprehensive Study on Cyber Attack Vectors in EV Traction Power Electronics", "comment": "15 pages, 3 Figures", "summary": "Electric vehicles (EVs) have drastically changed the auto industry and developed a new era of technologies where power electronics play the leading role in traction management, energy conversion and vehicle control processes. Nevertheless, this is a digital transformation, and the cyber-attack surface area has increased considerably, to the point that EV traction power electronics are becoming vulnerable to various cybersecurity risks. This paper is able to provide its expertise on possible cyber-attack vectors which can attack important parts of the traction, powertrain, including things like inverters, motor controllers, and communicated systems within the embedded bits. Using the (STRIDE) threat modeling framework, the research outlines and groups the vulnerabilities of the architecture and runs some attack simulations, such as the Denial of Service (DoS), spoofing, firmware manipulation, and data injection. The experiments prove the fact that a slight interruption in the control signal, the sensed data may lead to the severe working implications, such as unstable sensor values of the torque, abnormal voltage shifts, and entire system freezes. These results highlight the high priority on the need of injective embedded intrusion preventive mechanisms and secure design of firmware in EV powertrain electronics. In this paper, the author makes his contribution to the general body of knowledge that underpins the links existing between cyber security practices and the peculiar needs of automotive power electronics."}
{"id": "2511.15918", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.15918", "abs": "https://arxiv.org/abs/2511.15918", "authors": ["Indrila Ganguly", "Ying Huang"], "title": "Sequential Testing for Assessing the Incremental Value of Biomarkers Under Biorepository Specimen Constraints with Robustness to Model Misspecification", "comment": "33 pages including Supplementary Material, 3 figures", "summary": "In cancer biomarker development, a key objective is to evaluate whether a new biomarker, when combined with an established one, improves early cancer detection compared to using the established biomarker alone. Incremental value is often quantified by changes at specific points on the ROC curve, such as an increase in sensitivity at a fixed specificity, which is especially relevant in early cancer detection. Our research is motivated by the Early Detection Research Network (EDRN) biorepository studies, which aim to validate multiple cancer biomarkers across laboratories using specimens obtained from a centralized biorepository, under the constraint of limited specimen availability. To address this challenge, we propose a two-stage group sequential hypothesis testing framework for assessing incremental effects, allowing early stopping for futility or efficacy to conserve valuable samples. Our asymptotic results are derived under a logistic working model and remain valid even under model misspecification, ensuring robustness and broad applicability. We further integrate a rotating group membership design to facilitate validation of multiple candidate biomarkers across laboratories. Through extensive simulations, we demonstrate valid type I error control and efficient utilization of specimens. Finally, we apply our method to data from a multicenter EDRN pancreatic cancer reference set study and show how the proposed approach identifies promising candidate biomarkers that provide incremental performance when combined with CA19-9, while enabling efficient evaluation of a large number of such candidates."}
{"id": "2511.16420", "categories": ["math.OC", "cs.DC", "math.NA"], "pdf": "https://arxiv.org/pdf/2511.16420", "abs": "https://arxiv.org/abs/2511.16420", "authors": ["Shaked Regev", "Eve Tsybina", "Slaven Peles"], "title": "A Fast Relax-and-Round Approach to Unit Commitment for Data Center Own Generation", "comment": "Limited to 5 pages and this format for IEEE PESGM conference", "summary": "The rapid growth of data centers increasingly requires data center operators to \"bring own generation\" to complement the available utility power plants to supply all or part of data center load. This practice sharply increases the number of generators on the bulk power system and shifts operational focus toward fuel costs rather than traditional startup and runtime constraints. Conventional mixed-integer unit commitment formulations are not well suited for systems with thousands of flexible, fast-cycling units. We propose a unit commitment formulation that relaxes binary commitment decisions by allowing generators to be fractionally on, enabling the use of algorithms for continuous solvers. We then use a rounding approach to get a feasible unit commitment. For a 276-unit system, solution time decreases from 10 hours to less than a second, with minor accuracy degradation. Our approach scales with no issues to tens of thousands of generators, which allows solving problems on the scale of the major North America interconnections. The bulk of computation is parallel and GPU compatible, enabling further acceleration in future work."}
{"id": "2511.15954", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.15954", "abs": "https://arxiv.org/abs/2511.15954", "authors": ["Daniel McNulty"], "title": "A Graph-Theoretic Approach to Quantum Measurement Incompatibility", "comment": "24 pages, 7 figures", "summary": "Measurement incompatibility--the impossibility of jointly measuring certain quantum observables--is a fundamental resource for quantum information processing. We develop a graph-theoretic framework for quantifying this resource for large families of binary measurements, including Pauli observables on multi-qubit systems and $k$-body Majorana observables on $n$-mode fermionic systems. To each set of observables we associate an anti-commutativity graph, whose vertices represent observables and whose edges indicate pairs that anti-commute. In this representation, the incompatibility robustness--the minimal amount of classical noise required to render the set jointly measurable--becomes a graph invariant. We derive general bounds on this invariant in terms of the Lovász number, clique number, and fractional chromatic number, and show that the Lovász number yields the correct asymptotic scaling for $k$-body Majorana observables. For line graphs $L(G)$, which naturally arise in the characterisation of exactly solvable spin models, we obtain spectral bounds on the robustness expressed through the energy and skew-energy of the underlying graph $G$. These bounds become tight for highly symmetric graphs, leading to closed formulas for several graph families. Finally, we identify structural conditions under which the robustness is determined by a simple function of the graph's maximum degree and the number of vertices and edges, and show that such extremal cases occur only when combinatorial structures such as Hadamard, conference or weighing matrices exist."}
{"id": "2511.16413", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16413", "abs": "https://arxiv.org/abs/2511.16413", "authors": ["Anıl Erdinç Türetken", "Hakan Ersoy", "Aslihan Kartci"], "title": "Energy-Efficient and Actuator-Friendly Control Under Wave Disturbances: Model Reference vs. PID for Thruster Surge", "comment": null, "summary": "In this study, we compare a model reference control (MRC) strategy against conventional PID controllers (tuned via metaheuristic algorithms) for surge velocity control of a thruster-driven marine system, under combined wave disturbance and sensor noise. The goal is to evaluate not only tracking performance but also control energy usage and actuator stress. A high-order identified model of a Blue Robotics T200 thruster with a 2~kg vehicle is used, with an 8~N sinusoidal wave disturbance applied and white noise ( added to the speed measurement. Results show that the optimized MRC (MRC-R*) yields the lowest control energy and smoothest command among all controllers, while maintaining acceptable tracking. The IMC-based design performs closely. In contrast, PID controllers achieve comparable RMS tracking error but at the cost of excessive actuator activity and energy use, making them impractical in such scenarios. Future"}
{"id": "2511.16252", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2511.16252", "abs": "https://arxiv.org/abs/2511.16252", "authors": ["Tommaso Trabocchi", "Raffaella Burioni", "Lucilla de Arcangelis", "Duccio Fanelli"], "title": "Generalized Wilson-Cowan model with short term synaptic plasticity", "comment": null, "summary": "A generalized version of the Wilson-Cowan (WC) model is proposed which accounts for the evolution of the synaptic resources. Adiabatic elimination of the fast variables is performed to yield a simplified framework for the coupled interaction between active excitatory and inhibitory neurons. The latter model is shown to smoothly converge to the benchmark WC model, when the appropriate limit is performed. Different dynamical regimes are identified for the reduced model and commented upon with reference to the original formulation of the generalized dynamics. This includes identifying limit cycle oscillations for population of available resources."}
{"id": "2511.16413", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16413", "abs": "https://arxiv.org/abs/2511.16413", "authors": ["Anıl Erdinç Türetken", "Hakan Ersoy", "Aslihan Kartci"], "title": "Energy-Efficient and Actuator-Friendly Control Under Wave Disturbances: Model Reference vs. PID for Thruster Surge", "comment": null, "summary": "In this study, we compare a model reference control (MRC) strategy against conventional PID controllers (tuned via metaheuristic algorithms) for surge velocity control of a thruster-driven marine system, under combined wave disturbance and sensor noise. The goal is to evaluate not only tracking performance but also control energy usage and actuator stress. A high-order identified model of a Blue Robotics T200 thruster with a 2~kg vehicle is used, with an 8~N sinusoidal wave disturbance applied and white noise ( added to the speed measurement. Results show that the optimized MRC (MRC-R*) yields the lowest control energy and smoothest command among all controllers, while maintaining acceptable tracking. The IMC-based design performs closely. In contrast, PID controllers achieve comparable RMS tracking error but at the cost of excessive actuator activity and energy use, making them impractical in such scenarios. Future"}
{"id": "2511.15929", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.15929", "abs": "https://arxiv.org/abs/2511.15929", "authors": ["Jesus E. Vazquez", "Yanyuan Ma", "Karen Marder", "Tanya P. Garcia"], "title": "Robust Estimation under Outcome Dependent Right Censoring in Huntington Disease: Estimators for Low and High Censoring Rates", "comment": null, "summary": "Across health applications, researchers model outcomes as a function of time to an event, but the event time is right-censored for participants who exit the study or otherwise do not experience the event during follow-up. When censoring depends on the outcome-as in neurodegenerative disease studies where dropout is potentially related to disease severity-standard regression estimators produce biased estimates. We develop three consistent estimators for this outcome-dependent censoring setting: two augmented inverse probability weighted (AIPW) estimators and one maximum likelihood estimator (MLE). We establish their asymptotic properties and derive their robust sandwich variance estimators that account for nuisance parameter estimation. A key contribution is demonstrating that the choice of estimator to use depends on the censoring rate-the MLE performs best under low censoring rates, while the AIPW estimators yield lower bias and a higher nominal coverage under high censoring rates. We apply our estimators to Huntington disease data to characterize health decline leading up to mild cognitive impairment onset. The AIPW estimator with robustness matrix provided clinically-backed estimates with improved precision over inverse probability weighting, while MLE exhibited bias. Our results provide practical guidance for estimator selection based on censoring rate."}
{"id": "2511.16458", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16458", "abs": "https://arxiv.org/abs/2511.16458", "authors": ["Michele Mascherpa", "Axel Ringh", "Amirhossein Taghvaei", "Johan Karlsson"], "title": "A convex approach for Markov chain estimation from aggregate data via inverse optimal transport", "comment": "8 pages, 3 Figures. Submitted to European Control Conference 2026 (ECC26)", "summary": "We address the problem of identifying the dynamical law governing the evolution of a population of indistinguishable particles, when only aggregate distributions at successive times are observed. Assuming a Markovian evolution on a discrete state space, the task reduces to estimating the underlying transition probability matrix from distributional data. We formulate this inverse problem within the framework of entropic optimal transport, as a joint optimization over the transition matrix and the transport plans connecting successive distributions. This formulation results in a convex optimization problem, and we propose an efficient iterative algorithm based on the entropic proximal method. We illustrate the accuracy and convergence of the method in two numerical setups, considering estimation from independent snapshots and estimation from a time series of aggregate observations, respectively."}
{"id": "2511.15959", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2511.15959", "abs": "https://arxiv.org/abs/2511.15959", "authors": ["Haonan Liu", "Varun D. Vaidya", "Monica Gutierrez Galan", "Alexander K. Ratcliffe", "Amrit Poudel", "C. Ricardo Viteri"], "title": "High-Fidelity Raman Spin-Dependent Kicks in the Presence of Micromotion", "comment": "Main text has 6 pages, 4 figures; supplemental material has 15 pages, 0 figures", "summary": "We propose high-fidelity single-qubit spin-dependent kicks (SDKs) for trapped ions using nanosecond Raman pulses via amplitude modulation of a continuous-wave laser with a tunable beat frequency. We develop a general method for maintaining SDK performance in the presence of micromotion by identifying optimal choices of the RF phase and frequency that suppress unwanted backward kicks. The proposed scheme enables SDK infidelities as low as $10^{-9}$ in the absence of micromotion, and below $10^{-5}$ with micromotion. This study lays the foundation for the realization of sub-trap-period and high-fidelity two-qubit gates based on SDKs."}
{"id": "2511.16424", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16424", "abs": "https://arxiv.org/abs/2511.16424", "authors": ["Samuel Mallick", "Filippo Airaldi", "Azita Dabiri", "Bart De Schutter"], "title": "Second-Order MPC-Based Distributed Q-Learning", "comment": "6 pages, 2 figures, submitted to IFAC World Congress 2026", "summary": "The state of the art for model predictive control (MPC)-based distributed Q-learning is limited to first-order gradient updates of the MPC parameterization. In general, using secondorder information can significantly improve the speed of convergence for learning, allowing the use of higher learning rates without introducing instability. This work presents a second-order extension to MPC-based Q-learning with updates distributed across local agents, relying only on locally available information and neighbor-to-neighbor communication. In simulation the approach is demonstrated to significantly outperform first-order distributed Q-learning."}
{"id": "2511.16496", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2511.16496", "abs": "https://arxiv.org/abs/2511.16496", "authors": ["Rintaro Masaoka"], "title": "$c=-2$ conformal field theory in quadratic band touching", "comment": null, "summary": "Quadratic band touching in fermionic systems defines a universality class distinct from that of linear Dirac points, yet its characterization as a quantum critical point remains incomplete. In this work, I show that a $(d+1)$-dimensional free-fermion model with quadratic band touching exhibits spatial conformal invariance, and that its equal-time ground-state correlation functions are exactly captured by the $d$-dimensional symplectic fermion theory. I establish this correspondence by constructing explicit mappings between physical fermionic operators and the fields of the symplectic fermion theory. I further explore the implications of this correspondence in two spatial dimensions, where the symplectic fermion theory is a logarithmic conformal field theory with central charge $c=-2$. In the corresponding $(2+1)$-dimensional systems, I identify anyonic excitations originating from the underlying symplectic fermion theory, even though the Hamiltonian is gapless. Transporting these excitations along non-contractible loops generates transitions among topologically degenerate ground states, in close analogy with those in topologically ordered phases. Moreover, the action of a $2π$ rotation on these excitations is represented by a Jordan block, reflecting the logarithmic character of the associated conformal field theory."}
{"id": "2511.16424", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16424", "abs": "https://arxiv.org/abs/2511.16424", "authors": ["Samuel Mallick", "Filippo Airaldi", "Azita Dabiri", "Bart De Schutter"], "title": "Second-Order MPC-Based Distributed Q-Learning", "comment": "6 pages, 2 figures, submitted to IFAC World Congress 2026", "summary": "The state of the art for model predictive control (MPC)-based distributed Q-learning is limited to first-order gradient updates of the MPC parameterization. In general, using secondorder information can significantly improve the speed of convergence for learning, allowing the use of higher learning rates without introducing instability. This work presents a second-order extension to MPC-based Q-learning with updates distributed across local agents, relying only on locally available information and neighbor-to-neighbor communication. In simulation the approach is demonstrated to significantly outperform first-order distributed Q-learning."}
{"id": "2511.15942", "categories": ["stat.ME", "stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.15942", "abs": "https://arxiv.org/abs/2511.15942", "authors": ["Camilla Andreozzi", "Pietro Colombo", "Philipp Otto"], "title": "A Simple and Robust Multi-Fidelity Data Fusion Method for Effective Modeling of Citizen-Science Air Pollution Data", "comment": null, "summary": "We propose a robust multi-fidelity Gaussian process for integrating sparse, high-quality reference monitors with dense but noisy citizen-science sensors. The approach replaces the Gaussian log-likelihood in the high-fidelity channel with a global Huber loss applied to precision-weighted residuals, yielding bounded influence on all parameters, including the cross-fidelity coupling, while retaining the flexibility of co-kriging. We establish attenuation and unbounded influence of the Gaussian maximum likelihood estimator under low-fidelity contamination and derive explicit finite bounds for the proposed estimator that clarify how whitening and mean-shift sensitivity determine robustness. Monte Carlo experiments with controlled contamination show that the robust estimator maintains stable MAE and RMSE as anomaly magnitude and frequency increase, whereas the Gaussian MLE deteriorates rapidly. In an empirical study of PM2.5 concentrations in Hamburg, combining UBA monitors with openSenseMap data, the method consistently improves cross-validated predictive accuracy and yields coherent uncertainty maps without relying on auxiliary covariates. The framework remains computationally scalable through diagonal or low-rank whitening and is fully reproducible with publicly available code."}
{"id": "2511.16500", "categories": ["math.OC", "math.PR", "stat.CO"], "pdf": "https://arxiv.org/pdf/2511.16500", "abs": "https://arxiv.org/abs/2511.16500", "authors": ["Diego Fonseca", "Mauricio Junca"], "title": "Scenario-based Regularization: A Tractable Framework for Distributionally Robust Stochastic Optimization", "comment": null, "summary": "We propose a flexible scenario-based regularized Sample Average Approximation (SBR-SAA) framework for stochastic optimization. This work is motivated by challenges in standard Wasserstein Distributionally Robust Optimization (WDRO), where out-of-sample performance, particularly tail risk, is sensitive to the choice of the p-norm, and formulations can be computationally intractable. Our method is inspired by the asymptotic expansion of the WDRO objective and introduces a regularizer that penalizes the (sub)gradient norm of the objective at a selected set of scenarios. This framework serves a dual purpose: (i) it provides a computationally tractable alternative to WDRO by using a representative subset of the data, and (ii) it can provide targeted robustness by incorporating user-defined adverse scenarios. We establish the theoretical properties of this framework by proving its equivalence to a decision-dependent WDRO problem, from which we derive finite sample guarantees and asymptotic consistency. We demonstrate the method's efficacy in two applications: (1) a multi-product newsvendor problem, where SBR-SAA serves as a tractable alternative to NP-hard WDRO, and (2) a mean-risk portfolio optimization problem, where it successfully uses historical crisis data to improve out-of-sample performance."}
{"id": "2511.15969", "categories": ["quant-ph", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.15969", "abs": "https://arxiv.org/abs/2511.15969", "authors": ["Su Yeon Chang", "M. Cerezo"], "title": "A Primer on Quantum Machine Learning", "comment": "29+16 pages, 5 figures, 15 boxes. Chapter for Comprehensive Quantum Physics. Comments welcomed!", "summary": "Quantum machine learning (QML) is a computational paradigm that seeks to apply quantum-mechanical resources to solve learning problems. As such, the goal of this framework is to leverage quantum processors to tackle optimization, supervised, unsupervised and reinforcement learning, and generative modeling-among other tasks-more efficiently than classical models. Here we offer a high level overview of QML, focusing on settings where the quantum device is the primary learning or data generating unit. We outline the field's tensions between practicality and guarantees, access models and speedups, and classical baselines and claimed quantum advantages-flagging where evidence is strong, where it is conditional or still lacking, and where open questions remain. By shedding light on these nuances and debates, we aim to provide a friendly map of the QML landscape so that the reader can judge when-and under what assumptions-quantum approaches may offer real benefits."}
{"id": "2511.16425", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16425", "abs": "https://arxiv.org/abs/2511.16425", "authors": ["Ákos M. Bokor", "Tamás Dózsa", "Felix Biertümpfel", "Ádám Szabó"], "title": "Tube-Based Model Predictive Control with Random Fourier Features for Nonlinear Systems", "comment": "Submitted to IEEE IV 2026, The IEEE Intelligent Vehicles Symposium", "summary": "This paper presents a computationally efficient approach for robust Model Predictive Control of nonlinear systems by combining Random Fourier Features with tube-based MPC. Tube-based Model Predictive Control provides robust constraint satisfaction under bounded model uncertainties arising from approximation errors and external disturbances. The Random Fourier Features method approximates nonlinear system dynamics by solving a numerically tractable least-squares problem, thereby reducing the approximation error. We develop the integration of RFF-based residual learning with tube MPC and demonstrate its application to an autonomous vehicle path-tracking problem using a nonlinear bicycle model. Compared to the linear baseline, the proposed method reduces the tube size by approximately 50%, leading to less conservative behavior and resulting in around 70% smaller errors in the test scenario. Furthermore, the proposed method achieves real-time performance while maintaining provable robustness guarantees."}
{"id": "2511.16603", "categories": ["cond-mat.str-el", "cond-mat.other", "cond-mat.quant-gas", "cond-mat.stat-mech", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.16603", "abs": "https://arxiv.org/abs/2511.16603", "authors": ["Aleksey Alekseev", "Konrad Jerzy Kapcia"], "title": "Charge-Ordered States and the Phase Diagram of the Extended Hubbard Model on the Bethe lattice", "comment": "12 pages, 5 figures, 65 references; RevTeX class, double-column formatting", "summary": "We study the extended Hubbard model (EHM) with both onsite Hubbard interaction and the intersite density-density interaction between nearest-neighbors using the standard Hartree mean-field approximation (MFA) on the Bethe lattice. We found that, at the ground state, the system can be in a charge-ordered insulating (COI), a charge-order metallic (COM) or a non-charge-ordered (NO) state. Moreover, the finite-temperature phase diagrams are presented. Several observables like a charge-order parameter, a spectral function, and particularly at finite temperatures, a charge carrier concentration (to visualize the degree of metallicity) are analyzed. The results show that increasing onsite repulsion suppresses charge order and change the properties of the system from insulating to metallic. Worth noting, that a number of phenomena can be found within the MFA, where their analysis is much simpler than in more advanced approaches. The method used for the EHM on the Bethe lattice also allows for a series of analytical derivations and simplification to see general geometry-independent features and analytical results, avoiding the numerical inaccuracies and other issues that appear with a purely numerical solution."}
{"id": "2511.16425", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16425", "abs": "https://arxiv.org/abs/2511.16425", "authors": ["Ákos M. Bokor", "Tamás Dózsa", "Felix Biertümpfel", "Ádám Szabó"], "title": "Tube-Based Model Predictive Control with Random Fourier Features for Nonlinear Systems", "comment": "Submitted to IEEE IV 2026, The IEEE Intelligent Vehicles Symposium", "summary": "This paper presents a computationally efficient approach for robust Model Predictive Control of nonlinear systems by combining Random Fourier Features with tube-based MPC. Tube-based Model Predictive Control provides robust constraint satisfaction under bounded model uncertainties arising from approximation errors and external disturbances. The Random Fourier Features method approximates nonlinear system dynamics by solving a numerically tractable least-squares problem, thereby reducing the approximation error. We develop the integration of RFF-based residual learning with tube MPC and demonstrate its application to an autonomous vehicle path-tracking problem using a nonlinear bicycle model. Compared to the linear baseline, the proposed method reduces the tube size by approximately 50%, leading to less conservative behavior and resulting in around 70% smaller errors in the test scenario. Furthermore, the proposed method achieves real-time performance while maintaining provable robustness guarantees."}
{"id": "2511.15961", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.15961", "abs": "https://arxiv.org/abs/2511.15961", "authors": ["Kedar Karhadkar", "Jack Klys", "Daniel Ting", "Artem Vorozhtsov", "Houssam Nassif"], "title": "Evaluating Variance Estimates with Relative Efficiency", "comment": "Presented at CODE@MIT 2025", "summary": "Experimentation platforms in industry must often deal with customer trust issues. Platforms must prove the validity of their claims as well as catch issues that arise. As a central quantity estimated by experimentation platforms, the validity of confidence intervals is of particular concern. To ensure confidence intervals are reliable, we must understand and diagnose when our variance estimates are biased or noisy, or when the confidence intervals may be incorrect.\n  A common method for this is A/A testing, in which both the control and test arms receive the same treatment. One can then test if the empirical false positive rate (FPR) deviates substantially from the target FPR over many tests. However, this approach turns each A/A test into a simple binary random variable. It is an inefficient estimate of the FPR as it throws away information about the magnitude of each experiment result. We show how to empirically evaluate the effectiveness of statistics that monitor the variance estimates that partly dictate a platform's statistical reliability. We also show that statistics other than empirical FPR are more effective at detecting issues. In particular, we propose a $t^2$-statistic that is more sample efficient."}
{"id": "2511.16514", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.16514", "abs": "https://arxiv.org/abs/2511.16514", "authors": ["Tran T. A. Nghia", "Nghia V. Vo", "Khoa V. H. Vu"], "title": "Nonsmooth Newton methods with effective subspaces for polyhedral regularization", "comment": null, "summary": "We propose several new nonsmooth Newton methods for solving convex composite opti- mization problems with polyhedral regularizers, while avoiding the computation of compli- cated second-order information on these functions. Under the tilt-stability condition at the optimal solution, these methods achieve the quadratic convergence rates expected of New- ton schemes. Numerical experiments on Lasso, generalized Lasso, OSCAR-regularized least- square problems, and an image super-resolution task illustrate both the broad applicability and the accelerated convergence profile of the proposed algorithms, in comparison with first-order and several recently developed nonsmooth Newton schemes."}
{"id": "2511.15971", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.15971", "abs": "https://arxiv.org/abs/2511.15971", "authors": ["Donny Dwiputra", "Mir Faizal", "Francesco Marino", "Freddy P. Zen"], "title": "Universal work statistics in quenched gapless quantum systems", "comment": "14 pages, 1 figure", "summary": "We study the universality of work statistics performed during a quench in gapless quantum systems. We show that the cumulants of work scale separately in the fast and slow quench regimes, following a power law analogous to the universal scaling in the Kibble-Zurek mechanism for topological defect formation in phase transition. As an example, we analyze the nonequilibrium dynamics of a quenched Heisenberg XXZ chain at its critical gapless state using the bosonization picture, resulting in a Tomonaga-Luttinger liquid. The analytical scaling is in agreement with the exact numerical calculation for the fast and slow quench regimes. In finite systems, the characteristic function display an oscillatory pattern which disappears in the thermodynamic limit. This study is particularly useful for understanding the thermodynamics of adiabatic quantum computation."}
{"id": "2511.16469", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16469", "abs": "https://arxiv.org/abs/2511.16469", "authors": ["Weixuan Wang", "Alejandro I. Maass", "Dragan Nešić", "Ying Tan", "Romain Postoyan", "W. P. M. H. Heemels"], "title": "Observer Design for Singularly Perturbed Linear Networked Control Systems Subject to Measurement Noise", "comment": "9 pages, 2 figures, full version of the paper submitted to the IFAC World Congress", "summary": "This paper addresses the emulation-based observer design for linear networked control systems (NCS) operating at two time scales in the presence of measurement noise. The system is formulated as a hybrid singularly perturbed dynamical system, enabling the systematic use of singular perturbation techniques to derive explicit bounds on the maximum allowable transmission intervals (MATI) for both fast and slow communication channels. Under the resulting conditions, the proposed observer guarantees that the estimation error satisfies a global exponential derivative-input-to-state stability (DISS)-like property, where the ultimate bound scales proportionally with the magnitudes of the measurement noise and the time derivative of the control input. The effectiveness of the approach is illustrated through a numerical example."}
{"id": "2511.16469", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16469", "abs": "https://arxiv.org/abs/2511.16469", "authors": ["Weixuan Wang", "Alejandro I. Maass", "Dragan Nešić", "Ying Tan", "Romain Postoyan", "W. P. M. H. Heemels"], "title": "Observer Design for Singularly Perturbed Linear Networked Control Systems Subject to Measurement Noise", "comment": "9 pages, 2 figures, full version of the paper submitted to the IFAC World Congress", "summary": "This paper addresses the emulation-based observer design for linear networked control systems (NCS) operating at two time scales in the presence of measurement noise. The system is formulated as a hybrid singularly perturbed dynamical system, enabling the systematic use of singular perturbation techniques to derive explicit bounds on the maximum allowable transmission intervals (MATI) for both fast and slow communication channels. Under the resulting conditions, the proposed observer guarantees that the estimation error satisfies a global exponential derivative-input-to-state stability (DISS)-like property, where the ultimate bound scales proportionally with the magnitudes of the measurement noise and the time derivative of the control input. The effectiveness of the approach is illustrated through a numerical example."}
{"id": "2511.16029", "categories": ["stat.ME", "econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.16029", "abs": "https://arxiv.org/abs/2511.16029", "authors": ["Gregor Steiner", "Jeremie Houssineau", "Mark F. J. Steel"], "title": "Possibilistic Instrumental Variable Regression", "comment": null, "summary": "Instrumental variable regression is a common approach for causal inference in the presence of unobserved confounding. However, identifying valid instruments is often difficult in practice. In this paper, we propose a novel method based on possibility theory that performs posterior inference on the treatment effect, conditional on a user-specified set of potential violations of the exogeneity assumption. Our method can provide informative results even when only a single, potentially invalid, instrument is available, offering a natural and principled framework for sensitivity analysis. Simulation experiments and a real-data application indicate strong performance of the proposed approach."}
{"id": "2511.16568", "categories": ["math.OC", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.16568", "abs": "https://arxiv.org/abs/2511.16568", "authors": ["Lai Tian", "Johannes O. Royset"], "title": "Failure of uniform laws of large numbers for subdifferentials and beyond", "comment": "14 pages, 2 figures", "summary": "We provide counterexamples showing that uniform laws of large numbers do not hold for subdifferentials under natural assumptions. Our results apply to random Lipschitz functions and random convex functions with a finite number of smooth pieces. Consequently, they resolve the questions posed by Shapiro and Xu [J. Math. Anal. Appl., 325(2), 2007] in the negative and highlight the obstacles nonsmoothness poses to uniform results."}
{"id": "2511.15981", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15981", "abs": "https://arxiv.org/abs/2511.15981", "authors": ["Jingcheng Dai", "Atharva Vidwans", "Eric H. Wan", "Alexander X. Miller", "Micheline B. Soley"], "title": "Molecular resonance identification in complex absorbing potentials via integrated quantum computing and high-throughput computing", "comment": null, "summary": "Recent advancements in quantum algorithms have reached a state where we can consider how to capitalize on quantum and classical computational resources to accelerate molecular resonance state identification. Here we identify molecular resonances with a method that combines quantum computing with classical high-throughput computing (HTC). This algorithm, which we term qDRIVE (the quantum deflation resonance identification variational eigensolver) exploits the complex absorbing potential formalism to distill the problem of molecular resonance identification into a network of hybrid quantum-classical variational quantum eigensolver tasks, and harnesses HTC resources to execute these interconnected but independent tasks both asynchronously and in parallel, a strategy that minimizes wall time to completion. We show qDRIVE successfully identifies resonance energies and wavefunctions in simulated quantum processors with current and planned specifications, which bodes well for qDRIVE's ultimate application in disciplines ranging from photocatalysis to quantum control and places a spotlight on the potential offered by integrated heterogenous quantum computing/HTC approaches in computational chemistry."}
{"id": "2511.16195", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16195", "abs": "https://arxiv.org/abs/2511.16195", "authors": ["Jörn Tebbe", "Andreas Besginow", "Markus Lange-Hegermann"], "title": "Physics-informed Gaussian Processes as Linear Model Predictive Controller with Constraint Satisfaction", "comment": null, "summary": "Model Predictive Control evolved as the state of the art paradigm for safety critical control tasks. Control-as-Inference approaches thereof model the constrained optimization problem as a probabilistic inference problem. The constraints have to be implemented into the inference model. A recently introduced physics-informed Gaussian Process method uses Control-as-Inference with a Gaussian likelihood for state constraint modeling, but lacks guarantees of open-loop constraint satisfaction. We mitigate the lack of guarantees via an additional sampling step using Hamiltonian Monte Carlo sampling in order to obtain safe rollouts of the open-loop dynamics which are then used to obtain an approximation of the truncated normal distribution which has full probability mass in the safe area. We provide formal guarantees of constraint satisfaction while maintaining the ODE structure of the Gaussian Process on a discretized grid. Moreover, we show that we are able to perform optimization of a quadratic cost function by closed form Gaussian Process computations only and introduce the Matérn kernel into the inference model."}
{"id": "2511.16195", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16195", "abs": "https://arxiv.org/abs/2511.16195", "authors": ["Jörn Tebbe", "Andreas Besginow", "Markus Lange-Hegermann"], "title": "Physics-informed Gaussian Processes as Linear Model Predictive Controller with Constraint Satisfaction", "comment": null, "summary": "Model Predictive Control evolved as the state of the art paradigm for safety critical control tasks. Control-as-Inference approaches thereof model the constrained optimization problem as a probabilistic inference problem. The constraints have to be implemented into the inference model. A recently introduced physics-informed Gaussian Process method uses Control-as-Inference with a Gaussian likelihood for state constraint modeling, but lacks guarantees of open-loop constraint satisfaction. We mitigate the lack of guarantees via an additional sampling step using Hamiltonian Monte Carlo sampling in order to obtain safe rollouts of the open-loop dynamics which are then used to obtain an approximation of the truncated normal distribution which has full probability mass in the safe area. We provide formal guarantees of constraint satisfaction while maintaining the ODE structure of the Gaussian Process on a discretized grid. Moreover, we show that we are able to perform optimization of a quadratic cost function by closed form Gaussian Process computations only and introduce the Matérn kernel into the inference model."}
{"id": "2511.16040", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.16040", "abs": "https://arxiv.org/abs/2511.16040", "authors": ["Garritt L. Page", "Andrés F. Barrientos", "David B. Dahl", "David B. Dunson"], "title": "Uncertainty Quantification in Bayesian Clustering", "comment": null, "summary": "Bayesian clustering methods have the widely touted advantage of providing a probabilistic characterization of uncertainty in clustering through the posterior distribution. An amazing variety of priors and likelihoods have been proposed for clustering in a broad array of settings. There is also a rich literature on Markov chain Monte Carlo (MCMC) algorithms for sampling from posterior clustering distributions. However, there is relatively little work on summarizing the posterior uncertainty. The complexity of the partition space corresponding to different clusterings makes this problem challenging. We propose a post-processing procedure for any Bayesian clustering model with posterior samples that generates a credible set that is easy to use, fast to compute, and intuitive to interpret. We also provide new measures of clustering uncertainty and show how to compute cluster-specific parameter estimates and credible regions that accumulate a desired posterior probability without having to condition on a partition estimate or employ label-switching techniques. We illustrate our procedure through several applications."}
{"id": "2511.16616", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.16616", "abs": "https://arxiv.org/abs/2511.16616", "authors": ["Karl Kunisch", "Sérgio S. Rodrigues"], "title": "Stabilization of nonautonomous linear parabolic equations with inputs subject to time-delay", "comment": "8 figures", "summary": "The stabilization of nonautonomous parabolic equations is achieved by feedback inputs tuning a finite number of actuators, where it is assumed that the input is subject to a time delay. To overcome destabilizing effects of the time delay, the input is based on a prediction of the state at a future time. This prediction is computed depending on a state-estimate at the current time, which in turn is provided by a Luenberger observer. The observer is designed using the output of measurements performed by a finite number of sensors. The asymptotic behavior of the resulting coupled system is investigated. Numerical simulations are presented validating the theoretical findings, including tests showing the response against sensor measurement errors."}
{"id": "2511.15989", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15989", "abs": "https://arxiv.org/abs/2511.15989", "authors": ["Paul Webster", "Samuel C. Smith", "Lawrence Z. Cohen"], "title": "Explicit construction of low-overhead gadgets for gates on quantum LDPC codes", "comment": "6 pages, 1 figure", "summary": "Quantum low-density parity check (QLDPC) codes can significantly reduce the overhead of quantum computing, provided the methods for performing logical operations do not require substantial space and time resources. A popular method for performing logical operations is by measuring logical Pauli operators. We present a simple, explicit construction for fixed gadgets that can measure arbitrary logical Pauli operators on QLDPC codes when dynamically connected to the code block. We apply this construction to a family of generalised bicycle codes with distances relevant to utility-scale quantum computation ($10\\leq d \\leq 24$) and show that it reduces the space overhead by at least an order of magnitude compared to corresponding surface code architectures, without increasing the time overhead."}
{"id": "2511.16458", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16458", "abs": "https://arxiv.org/abs/2511.16458", "authors": ["Michele Mascherpa", "Axel Ringh", "Amirhossein Taghvaei", "Johan Karlsson"], "title": "A convex approach for Markov chain estimation from aggregate data via inverse optimal transport", "comment": "8 pages, 3 Figures. Submitted to European Control Conference 2026 (ECC26)", "summary": "We address the problem of identifying the dynamical law governing the evolution of a population of indistinguishable particles, when only aggregate distributions at successive times are observed. Assuming a Markovian evolution on a discrete state space, the task reduces to estimating the underlying transition probability matrix from distributional data. We formulate this inverse problem within the framework of entropic optimal transport, as a joint optimization over the transition matrix and the transport plans connecting successive distributions. This formulation results in a convex optimization problem, and we propose an efficient iterative algorithm based on the entropic proximal method. We illustrate the accuracy and convergence of the method in two numerical setups, considering estimation from independent snapshots and estimation from a time series of aggregate observations, respectively."}
{"id": "2511.16458", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.16458", "abs": "https://arxiv.org/abs/2511.16458", "authors": ["Michele Mascherpa", "Axel Ringh", "Amirhossein Taghvaei", "Johan Karlsson"], "title": "A convex approach for Markov chain estimation from aggregate data via inverse optimal transport", "comment": "8 pages, 3 Figures. Submitted to European Control Conference 2026 (ECC26)", "summary": "We address the problem of identifying the dynamical law governing the evolution of a population of indistinguishable particles, when only aggregate distributions at successive times are observed. Assuming a Markovian evolution on a discrete state space, the task reduces to estimating the underlying transition probability matrix from distributional data. We formulate this inverse problem within the framework of entropic optimal transport, as a joint optimization over the transition matrix and the transport plans connecting successive distributions. This formulation results in a convex optimization problem, and we propose an efficient iterative algorithm based on the entropic proximal method. We illustrate the accuracy and convergence of the method in two numerical setups, considering estimation from independent snapshots and estimation from a time series of aggregate observations, respectively."}
{"id": "2511.16102", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.16102", "abs": "https://arxiv.org/abs/2511.16102", "authors": ["Bankitdor M Nongrum", "Adarsha Kumar Jena"], "title": "Estimation of the Coefficient of Variation of Weibull Distribution under Type-I Progressively Interval Censoring: A Simulation-based Approach", "comment": null, "summary": "Measures of relative variability, such as the Pearson's coefficient of variation (CV$_p$), give much insight into the spread of lifetime distributions, like the Weibull distribution. The estimation of the Weibull CV$_p$ in modern statistics has traditionally been prioritized only when complete data is available. In this article, we estimate the Weibull CV$_p$ and its second-order alternative, denoted as CV$_k$, under type-I progressively interval censoring, which is a typical scenario in survival analysis and reliability theory. Point estimates are obtained using the methods of maximum likelihood, least squares, and the Bayesian approach with MCMC simulation. A nonlinear least squares method is proposed for estimating the CV$_p$ and CV$_k$. We also perform interval estimation of the CV$_p$ and CV$_k$ using the asymptotic confidence intervals, bootstrap intervals through the least squares estimates, and the highest posterior density intervals. A comprehensive Monte Carlo simulation study is carried out to understand and compare the performance of the estimators. The proposed least squares and the Bayesian methods produce better point estimates for the CV$_p$. The highest posterior density intervals outperform other interval estimates in many cases. The methodologies are also applied to a real dataset to demonstrate the performance of the estimators."}
{"id": "2511.16009", "categories": ["quant-ph", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.16009", "abs": "https://arxiv.org/abs/2511.16009", "authors": ["Joseph Jaeger"], "title": "Nonadaptive One-Way to Hiding Implies Adaptive Quantum Reprogramming", "comment": "24 pages, 12 figures", "summary": "An important proof technique in the random oracle model involves reprogramming it on hard to predict inputs and arguing that an attacker cannot detect that this occurred. In the quantum setting, a particularly challenging version of this considers adaptive reprogramming wherein the points to be reprogrammed (or the output values they should be programmed to) are dependent on choices made by the adversary. Some quantum frameworks for analyzing adaptive reprogramming were given by Unruh (CRYPTO 2014, EUROCRYPT 2015), Grilo-Hövelmanns-Hülsing-Majenz (ASIACRYPT 2021), and Pan-Zeng (PKC 2024). We show, counterintuitively, that these adaptive results follow from the \\emph{nonadaptive} one-way to hiding theorem of Ambainis-Hamburg-Unruh (CRYPTO 2019). These implications contradict beliefs (whether stated explicitly or implicitly) that some properties of the adaptive frameworks cannot be provided by the Ambainis-Hamburg-Unruh result."}
{"id": "2511.16530", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.16530", "abs": "https://arxiv.org/abs/2511.16530", "authors": ["Nicholas C. Henderson", "Nicholas Hartman"], "title": "Targeted Parameter Estimation for Robust Empirical Bayes Ranking", "comment": null, "summary": "Ordering the expected outcomes across a collection of clusters after performing a covariate adjustment commonly arises in many applied settings, such as healthcare provider evaluation. Regression parameters in such covariate adjustment models are frequently estimated by maximum likelihood or through other criteria that do not directly evaluate the quality of the rankings resulting from using a particular set of parameter estimates. In this article, we propose both a novel empirical Bayes ranking procedure and an associated estimation approach for finding the regression parameters of the covariate adjustment model. By building our ranking approach around estimating approximate percentiles of the covariate-adjusted cluster-level means, we are able to develop manageable expressions for the expected ranking squared-error loss associated with any choice of the covariate-adjustment model parameters, and we harness this to generate a novel unbiased estimator for this expected loss. Minimization of this unbiased estimator directly leads to a novel ranking procedure that is often more robust than conventional empirical Bayes ranking methods. Through a series of simulation studies, we show that our approach consistently delivers improved ranking squared-error performance relative to competing methods, such as posterior expected ranks and ranking the components of the best linear unbiased predictor. Estimating rankings using our method is illustrated with an example from a longitudinal study evaluating test scores across a large group of schools."}
{"id": "2511.16051", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16051", "abs": "https://arxiv.org/abs/2511.16051", "authors": ["Yifei Huang", "Pascal Jahan Elahi", "Kan He", "Jinchuan Hou", "Shusen Liu"], "title": "TRAM: A Transverse Relaxation Time-Aware Qubit Mapping Algorithm for NISQ Devices", "comment": null, "summary": "Noisy intermediate-scale quantum (NISQ) devices impose dual challenges on quantum circuit execution: limited qubit connectivity requires extensive SWAP-gate routing, while time-dependent decoherence progressively degrades quantum information. Existing qubit mapping algorithms optimize for hardware topology and static calibration metrics but systematically neglect transverse relaxation dynamics (T2), creating a fundamental gap between compiler decisions and evolving noise characteristics. We present TRAM (Transverse Relaxation Time-Aware Qubit Mapping), a coherence-guided compilation framework that elevates decoherence mitigation to a primary optimization objective. TRAM integrates calibration-informed community detection to construct noise-resilient qubit partitions, generates time-weighted initial mappings that anticipate coherence decay, and dynamically schedules SWAP operations to minimize cumulative error accumulation. Evaluated on Qiskit-based simulators with realistic noise models, TRAM outperforms SABRE by 3.59% in fidelity, reduces gate count by 11.49%, and shortens circuit depth by 12.28%, establishing coherence-aware optimization as essential for practical quantum compilation in the NISQ era."}
{"id": "2511.16589", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.16589", "abs": "https://arxiv.org/abs/2511.16589", "authors": ["Divan A. Burger", "Sean van der Merwe", "Emmanuel Lesaffre"], "title": "A flexible quantile mixed-effects model for censored outcomes", "comment": null, "summary": "We introduce a Bayesian quantile mixed-effects model for censored longitudinal outcomes based on the skew exponential power (SEP) error distribution. The SEP family separates tail behavior and skewness from the targeted quantile and includes the skew Laplace (SL) distribution as a special case. We derive analytic likelihood contributions for left, right, and interval censoring under the SEP model, so censored observations are handled within a single parametric framework without numerical integration in the likelihood. In simulation studies with varying censoring patterns and skewness profiles, the SEP-based quantile mixed-effects model maintains near-nominal bias and credible interval coverage for regression coefficients. In contrast, the SL-based model can exhibit bias and undercoverage when the data's skewness conflicts with the skewness implied by the target quantile. In an HIV-1 RNA viral load case study with left censoring at the assay limit, bridge-sampled marginal likelihoods and simulation-based residual diagnostics favor the SEP specification across quantiles and yield more stable estimates of treatment-specific viral load trajectories than the SL benchmark."}
{"id": "2511.16085", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16085", "abs": "https://arxiv.org/abs/2511.16085", "authors": ["Shoichi Murakami", "Shunsuke Hiraoka", "Toshiki Kobayashi", "Takashi Yamamoto", "Rikizo Ikuta"], "title": "Channel-selective frequency up-conversion for frequency-multiplexed quantum network", "comment": null, "summary": "We demonstrate channel-selective frequency up-conversion from telecom wavelengths around 1540 nm for optical fiber communication to visible wavelengths around 780 nm, based on second-order optical nonlinearity in a cavity of the converted modes. In our experiment, we selectively convert a light from any frequency mode within frequency-multiplexed telecom signals to a desired output mode, determined by the cavity resonances. Based on the experimental results of the frequency up-conversion, we derive the signal-to-noise ratio of the process at the single-photon level, and discuss its applicability to channel-selective quantum frequency conversion (CS-QFC) in the context of frequency-multiplexed quantum networks. Finally, we describe specific use cases of the CS-QFC, which show its utility as a reconfigurable switching element in frequency-multiplexed networks, particularly for selectively performing Bell-state measurements between two photons originating from different frequencies."}
{"id": "2511.16149", "categories": ["quant-ph", "cs.LG", "math.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.16149", "abs": "https://arxiv.org/abs/2511.16149", "authors": ["Ariel Neufeld", "Philipp Schmocker", "Viet Khoa Tran"], "title": "Approximation rates of quantum neural networks for periodic functions via Jackson's inequality", "comment": null, "summary": "Quantum neural networks (QNNs) are an analog of classical neural networks in the world of quantum computing, which are represented by a unitary matrix with trainable parameters. Inspired by the universal approximation property of classical neural networks, ensuring that every continuous function can be arbitrarily well approximated uniformly on a compact set of a Euclidean space, some recent works have established analogous results for QNNs, ranging from single-qubit to multi-qubit QNNs, and even hybrid classical-quantum models. In this paper, we study the approximation capabilities of QNNs for periodic functions with respect to the supremum norm. We use the Jackson inequality to approximate a given function by implementing its approximating trigonometric polynomial via a suitable QNN. In particular, we see that by restricting to the class of periodic functions, one can achieve a quadratic reduction of the number of parameters, producing better approximation results than in the literature. Moreover, the smoother the function, the fewer parameters are needed to construct a QNN to approximate the function."}
{"id": "2511.16215", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16215", "abs": "https://arxiv.org/abs/2511.16215", "authors": ["Xiaoguang Wang", "Xiao-Ming Lu", "Yunbo Zhang", "Libin Fu", "Shu Chen"], "title": "Mixed-State Berry Curvature in quantum multiparameter estimations", "comment": null, "summary": "For pure states, the quantum Berry curvature was well studied. However, the quantum curvature for mixed states has received less attention. From the concept of symmetric logarithmic derivative, we introduce a mixed-state quantum curvature and find that it plays a key role in the field of multi-parameter precision estimations. Through spectral decomposition, we derive the mixed-state Berry curvature for both the full-rank and non-full-rank density matrices. As an example, we obtain the exact expression of the Berry curvature for an arbitrary qubit state."}
{"id": "2511.16242", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16242", "abs": "https://arxiv.org/abs/2511.16242", "authors": ["F. Bemani", "A. A. Rakhubovsky", "R. Filip"], "title": "Heralded quantum non-Gaussian states in pulsed levitating optomechanics", "comment": null, "summary": "Optomechanics with levitated nanoparticles is a promising way to combine very different types of quantum non-Gaussian aspects induced by continuous dynamics in a nonlinear or time-varying potential with the ones coming from discrete quantum elements in dynamics or measurement. First, it is necessary to prepare quantum non-Gaussian states using both methods. The nonlinear and time-varying potentials have been widely analyzed for this purpose. However, feasible preparation of provably quantum non-Gaussian states in a single mechanical mode using discrete photon detection has not been proposed yet for optical levitation. We explore pulsed optomechanical interactions combined with non-linear photon detection techniques to approach mechanical Fock states and confirm their quantum non-Gaussianity. We also predict the conditions under which the optomechanical interaction can induce multiple-phonon addition processes, which are relevant for $n$-phonon quantum non-Gaussianity. The practical applicability of quantum non-Gaussian states for sensing phase-randomized displacements is shown. Besides such applications, generating quantum non-Gaussian states of levitated nanoparticles can help to study fundamental questions of quantum thermodynamics, and macroscopic quantum effects."}
{"id": "2511.16272", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16272", "abs": "https://arxiv.org/abs/2511.16272", "authors": ["Ioana Moflic", "Alexandru Paler", "Akash Kundu"], "title": "QASER: Breaking the Depth vs. Accuracy Trade-Off for Quantum Architecture Search", "comment": null, "summary": "Quantum computing faces a key challenge: balancing the need for low circuit depth (crucial for fault tolerance) with the high accuracy required for complex computations like quantum chemistry and error correction, which typically require deeper circuits. We overcome this trade-off by introducing a novel reinforcement learning approach featuring engineered reward functions, called \\textbf{QASER}, that take into account seemingly contradictory optimization goals. This reward enables the compilation of circuits with lower depth and higher accuracy, significantly outperforming state-of-the-art techniques. Benchmarks on quantum chemistry state preparation circuits demonstrate stable compilations. We achieve up to 50\\% improved accuracy, while reducing 2-qubit gate counts and depths by 20\\%. This advancement enables more efficient and reliable quantum compilation."}
{"id": "2511.16274", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.16274", "abs": "https://arxiv.org/abs/2511.16274", "authors": ["Riccardo Grazi", "Dario Ferraro", "Niccolò Traverso Ziani"], "title": "Universal features of non-analytical energy storage in quantum critical quantum batteries", "comment": "23 pages, 6 figures", "summary": "Quantum batteries are quantum mechanical systems able to store and release energy in a controlled fashion. Among them, a special role is played by quantum structures defined as networks of two-level systems. In this context, it has recently been shown that the energy stored in free fermion quantum batteries is sensitive to the quantum phase diagram of the battery itself. This sensitivity is relevant for stabilizing the stored energy and designing optimal charging protocols. In this article, we explore universal charging behaviors of free fermion quantum batteries across quantum phase transitions. We first analyze a Dirac cone-like model to extract general features. Then, we verify our findings by means of two relevant lattice models, namely the Ising chain in a transverse field and the Haldane model."}
{"id": "2511.16285", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2511.16285", "abs": "https://arxiv.org/abs/2511.16285", "authors": ["Dasom Kim", "Maxime Dherbécourt", "Sae R. Endo", "Geon Lee", "Ayush Agrawal", "Sunghwan Kim", "Wen-Hua Wu", "Aditya D. Mohite", "Minah Seo", "David Hagenmüller", "Junichiro Kono"], "title": "Symmetry-Controlled Ultrastrong Phonon-Photon Coupling in a Terahertz Cavity", "comment": null, "summary": "Optical cavities provide a powerful means to engineer light-matter hybrid states by coupling confined electromagnetic fields with matter excitations. Achieving in situ control of the coupling strength is essential for investigating how such hybridization evolves with the coupling strength. In this work, we use a symmetry-changing structural phase transition in lead halide perovskites to reversibly tune the phonon-photon coupling strength, leveraging the fact that their phonon frequencies and oscillator strengths are dictated by lattice symmetry. Terahertz time-domain spectroscopy of MAPbI3 embedded in nanoslot cavities reveals three polariton branches above the critical temperature Tc = 162.5 K, and the emergence of an additional branch below Tc, activated by a new phonon mode in the low-temperature phase. The full dispersion is accurately reproduced using a multimode Hopfield model, confirming that all normalized coupling strengths remain in the ultrastrong coupling regime. These results demonstrate symmetry-controlled tuning of ultrastrong coupling via phonon engineering in optical cavities."}
{"id": "2511.16289", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16289", "abs": "https://arxiv.org/abs/2511.16289", "authors": ["Karoliina Oksanen", "Quan Hoang", "Alexandru Paler"], "title": "Medusa: Detecting and Removing Failures for Scalable Quantum Computing", "comment": null, "summary": "Quantum circuits will experience failures that lead to computational errors. We introduce Medusa, an automated compilation method for lowering a circuit's failure rate. Medusa uses flags to predict the absence of high-weight errors. Our method can numerically upper bound the failure rate of a circuit in the presence of flags, and fine tune the fault-tolerance of the flags in order to reach this bound. We assume the flags can have an increased fault-tolerance as a result of applying surface QECs to the gates interacting with them. We use circuit level depolarizing noise to evaluate the effectiveness of these flags in revealing the absence of the high-weight stabilizers. Medusa reduces the cost of quantum-error-correction (QEC) because the underlying circuit has a lower failure rate. We benchmark our approach using structured quantum circuits representative of ripple-carry adders. In particular, our flag scheme demonstrates that for adder-like circuits, the failure rate of large-scale implementations can be lowered to fit the failure rates of smaller-scale circuits. We show numerically that a slight improvement in the local fault-tolerance of the flag-qubits can lead to a reduction in the overall failure rate of the entire quantum circuit."}
{"id": "2511.16299", "categories": ["quant-ph", "math.OA"], "pdf": "https://arxiv.org/pdf/2511.16299", "abs": "https://arxiv.org/abs/2511.16299", "authors": ["Idris Delsol", "Omar Fawzi", "Li Gao", "Mizanur Rahaman"], "title": "Emulation Capacity between Idempotent Channels", "comment": "28 pages", "summary": "We study the optimal rates of emulation (also called interconversion) between quantum channels. When the source and the target channels are idempotent, we give a single-letter expression for the zero-error emulation capacity in terms of structural properties of the range of the two channels. This expression shows that channel emulation is not reversible for general idempotent channels. Furthermore, we establish a strong converse rate that matches with the zero-error emulation capacity when the source or the target channel is either an identity or a completely dephasing channel."}
{"id": "2511.16303", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16303", "abs": "https://arxiv.org/abs/2511.16303", "authors": ["Otto Savola", "Alexandru Paler"], "title": "ATLAS: Efficient Atom Rearrangement for Defect-Free Neutral-Atom Quantum Arrays Under Transport Loss", "comment": null, "summary": "Neutral-atom quantum computers encode qubits in individually trapped atoms arranged in optical lattices. Achieving defect-free atom configurations is essential for high-fidelity quantum gates and scalable error correction, yet stochastic loading and atom loss during rearrangement hinder reliable large-scale assembly. This work presents ATLAS, an open-source atom transport algorithm that efficiently converts a randomly loaded $W \\times W$ lattice into a defect-free $L \\times L$ subarray while accounting for realistic physical constraints, including finite acceleration, transfer time, and per-move loss probability. In the planning phase, optimal batches of parallel moves are computed on a lossless virtual array; during execution, these moves are replayed under probabilistic atom loss to maximize the expected number of retained atoms. Monte Carlo simulations across lattice sizes $W=10$--$100$, loading probabilities $p_{\\mathrm{occ}}=0.5$--$0.9$, and loss rates $p_{\\mathrm{loss}}=0$--$0.05$ demonstrate fill rates above $99\\%$ within six iterations and over $90\\%$ atom retention at low loss. The algorithm achieves sublinear move scaling ($\\propto M^{0.55}$) and linear growth of required initial size with target dimension, outperforming prior methods in robustness and scalability -- offering a practical path toward larger neutral-atom quantum arrays."}
{"id": "2511.16350", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16350", "abs": "https://arxiv.org/abs/2511.16350", "authors": ["Xiaosong Ren", "Zhanping Jin", "Xiaotong Zou", "Xiaole Zhang", "Xue Feng", "Fang Liu", "Kaiyu Cui", "Yidong Huang", "Wei Zhang"], "title": "On-chip Time-bin to Path Qubit Encoding Converter via Thin Film Lithium Niobate Photonics Chip", "comment": null, "summary": "The development of quantum internet demands on-chip quantum processor nodes and interconnection between the nodes. Path-encoded photonic qubits are suitable for on-chip quantum information processors, while time-bin encoded ones are good at long-distance communication. It is necessary to develop an on-chip converter between the two encodings to satisfy the needs of the quantum internet. In this work, a quantum photonic circuit is proposed to convert time-bin-encoded photonic qubits to path-encoded ones via a thin-film lithium niobate high-speed optical switch and low-loss matched optical delay lines. The performance of the encoding converter is demonstrated by the experiment of time-bin to path encoding conversion on the fabricated sample chip. The converted path qubits have an average fidelity higher than 97%. The potential of the encoding converter on applications in quantum networks is demonstrated by the experiments of entanglement distribution and quantum key distribution. The results show that the on-chip encoding converter can serve as a foundational component in the future quantum internet, bridging the gap between quantum information transmission and on-chip processing based on photons."}
{"id": "2511.16351", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16351", "abs": "https://arxiv.org/abs/2511.16351", "authors": ["Abhishek Mandal", "Joy Ghosh", "Maruthi Manoj Brundavanam", "Shailendra K Varshney"], "title": "Tripartite Entanglement Generation in Atom-Coupled Dual Microresonators System", "comment": "9 pages, 8 figures", "summary": "In this work, we investigate the emergence and control of genuine tripartite entanglement in a hybrid cavity quantum electrodynamics architecture consisting of two linearly coupled single mode resonators, one of which interacts coherently with a two level atom. An analytical framework is developed in a weak driving regime, where the system dynamically supports a delocalized hybrid excitation shared by the two photonic modes and the atomic degree of freedom. Tripartite concurrence fill has been used to characterize and identify parameter regimes of maximal multipartite quantum correlation that can be generated in this model. Additionally, we demonstrate how dissipative rates and detuning asymmetries govern the conversion of bipartite entanglement into a genuinely tripartite state, establishing a controllable transition from localized Jaynes Cummings correlations to delocalized photonic atomic entanglement networks. These findings outline a clear route to engineering steady state multipartite quantum resources in coupled cavity QED platforms, with direct relevance to quantum networking, distributed quantum information processing, and photonic state routing in scalable quantum architectures."}
{"id": "2511.16431", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.16431", "abs": "https://arxiv.org/abs/2511.16431", "authors": ["Zhi-Jie Liu", "Hao-Nan Qiang", "Jie Zhou", "Mi Xie", "Jing-Ling Chen"], "title": "Identifying the $3$-qubit $W$ state with quantum uncertainty relation", "comment": "6 pages, 0 figure", "summary": "The $W$ state, a canonical representative of multipartite quantum entanglement, plays a crucial role in quantum information science due to its robust entanglement properties. Quantum uncertainty relations, on the other hand, are a fundamental cornerstone of quantum mechanics. This paper introduces a novel approach to Identifying tripartite $W$ states by leveraging tripartite quantum uncertainty relations. By employing a specific set of non-commuting observables, we formulate an uncertainty-based criterion for identifying $W$ states and rigorously demonstrate its generality in distinguishing them from other tripartite entangled states, such as the Greenberger-Horne-Zeilinger state. Our approach bypasses the need for complete quantum state tomography, as it requires only the verification of a set of uncertainty inequalities for efficient $W$-state identification. This work provides a new theoretical tool for identifying multipartite entangled states and underscores the significant role of quantum uncertainty relations in entanglement characterization."}
{"id": "2511.16468", "categories": ["quant-ph", "cs.CR", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.16468", "abs": "https://arxiv.org/abs/2511.16468", "authors": ["Akshit Pramod Anchan", "Ameiy Acharya", "Leki Chom Thungon"], "title": "Optimizing Quantum Key Distribution Network Performance using Graph Neural Networks", "comment": "11 pages, 4 figures, and 2 tables", "summary": "This paper proposes an optimization of Quantum Key Distribution (QKD) Networks using Graph Neural Networks (GNN) framework. Today, the development of quantum computers threatens the security systems of classical cryptography. Moreover, as QKD networks are designed for protecting secret communication, they suffer from multiple operational difficulties: adaptive to dynamic conditions, optimization for multiple parameters and effective resource utilization. In order to overcome these obstacles, we propose a GNN-based framework which can model QKD networks as dynamic graphs and extracts exploitable characteristics from these networks' structure. The graph contains not only topological information but also specific characteristics associated with quantum communication (the number of edges between nodes, etc). Experimental results demonstrate that the GNN-optimized QKD network achieves a substantial increase in total key rate (from 27.1 Kbits/s to 470 Kbits/s), a reduced average QBER (from 6.6% to 6.0%), and maintains path integrity with a slight reduction in average transmission distance (from 7.13 km to 6.42 km). Furthermore, we analyze network performance across varying scales (10 to 250 nodes), showing improved link prediction accuracy and enhanced key generation rate in medium-sized networks. This work introduces a novel operation mode for QKD networks, shifting the paradigm of network optimization through adaptive and scalable quantum communication systems that enhance security and performance."}
{"id": "2511.16473", "categories": ["quant-ph", "cond-mat.str-el", "math-ph"], "pdf": "https://arxiv.org/pdf/2511.16473", "abs": "https://arxiv.org/abs/2511.16473", "authors": ["Martín Zapata", "Federico Finkel", "Artemio González-López"], "title": "Local fermion density in inhomogeneous free-fermion chains: a discrete WKB approach", "comment": "35 pages, 14 figures, supplementary material linked", "summary": "We introduce a novel analytical approach for studying free-fermion (XX) chains with smoothly varying, site-dependent hoppings and magnetic fields. Building on a discrete WKB-like approximation applied directly to the recurrence relation for the single-particle eigenfunctions, we derive a closed-form expression for the local fermion density profile as a function of the Fermi energy, which is valid for arbitrary fillings, hopping amplitudes and magnetic fields. This formula reproduces the depletion and saturation effects observed in previous studies of inhomogeneous free-fermion chains, and provides a theoretical framework to understand entanglement entropy suppression in these models. We demonstrate the accuracy of our asymptotic formula in several chains with different hopping and magnetic field profiles. Our findings are thus the first step towards an analytical treatment of entanglement in free-fermion chains beyond the reach of conventional field-theoretic techniques."}
{"id": "2511.16526", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16526", "abs": "https://arxiv.org/abs/2511.16526", "authors": ["Agung Budiyono", "Michael Moody", "Hadyan L. Prihadi", "Rafika Rahmawati", "Sebastian Deffner"], "title": "Quantum speed limit for observables from quantum asymmetry", "comment": "9 pages, 1 figure", "summary": "Quantum asymmetry and coherence are genuinely quantum resources that are essential to realize quantum advantage in information technologies. However, all quantum processes are fundamentally constrained by quantum speed limits, which raises the question on the corresponding bounds on the rate of consumption of asymmetry and coherence. In the present work, we derive a formulation of the quantum speed limit for observables in terms of the trace-norm asymmetry of the time-dependent quantum state relative to the observable. This version of the quantum speed limit can be shown to be directly relevant in weak measurements and quantum metrology. It can be further related to quantum coherence relative to the observable, and we obtain a complementary relation for the speed of three mutually unbiased observables for a single qubit. As an application, we derive a notion of a quantum thermodynamic speed limit."}
{"id": "2511.16529", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16529", "abs": "https://arxiv.org/abs/2511.16529", "authors": ["Xuemei Gu", "Carlos Ruiz-Gonzalez", "Mario Krenn"], "title": "Analytical Fock Representation of Two-Mode Squeezing for Quantum Interference", "comment": "8 pages, 4 figures; 6 pages appendix", "summary": "Two-mode squeezing is central to entangled-photon generation and nonlinear interferometry, yet standard perturbative low-gain and Gaussian treatments obscure how photon-number amplitudes interfere, especially in multi-crystal geometries and at high gain. Here, we derive the exact analytic action of the two-mode squeezing operator on arbitrary Fock states to analyze nonlinear interferometers directly in the number basis at arbitrary squeezing strength. Within this framework, we find new physical interpretations of previously known quantum interference effects, and theoretically discover a new and unusual multi-photon interference effect in an experimental four-crystal geometry that could readily be observed in laboratories. Our work provides a compact analytic toolkit and concrete design rules for engineering multi-photon interference, with applications in quantum sensing, precision metrology, and advanced quantum state generation."}
{"id": "2511.16558", "categories": ["quant-ph", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.16558", "abs": "https://arxiv.org/abs/2511.16558", "authors": ["Konrad Anand", "Zongchen Chen", "Mary Cryan", "Graham Freifeld", "Leslie Ann Goldberg", "Heng Guo", "Xinyuan Zhang"], "title": "Simulating Gaussian boson sampling on graphs in polynomial time", "comment": "10 pages, 2 figures", "summary": "We show that a distribution related to Gaussian Boson Sampling (GBS) on graphs can be sampled classically in polynomial time. Graphical applications of GBS typically sample from this distribution, and thus quantum algorithms do not provide exponential speedup for these applications. We also show that another distribution related to Boson sampling can be sampled classically in polynomial time."}
{"id": "2511.16559", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16559", "abs": "https://arxiv.org/abs/2511.16559", "authors": ["Maureen Krumtünger", "Alissa Wilms", "Paul K. Faehrmann", "Jens Eisert", "Jakob Kottmann", "Paolo Andrea Erdman", "Sumeet Khatri"], "title": "Reinforcement learning of quantum circuit architectures for molecular potential energy curves", "comment": "16+14 pages, 21 figures. Comments welcome!", "summary": "Quantum chemistry and optimization are two of the most prominent applications of quantum computers. Variational quantum algorithms have been proposed for solving problems in these domains. However, the design of the quantum circuit ansatz remains a challenge. Of particular interest is developing a method to generate circuits for any given instance of a problem, not merely a circuit tailored to a specific instance of the problem. To this end, we present a reinforcement learning (RL) approach to learning a problem-dependent quantum circuit mapping, which outputs a circuit for the ground state of a Hamiltonian from a given family of parameterized Hamiltonians. For quantum chemistry, our RL framework takes as input a molecule and a discrete set of bond distances, and it outputs a bond-distance-dependent quantum circuit for arbitrary bond distances along the potential energy curve. The inherently non-greedy approach of our RL method contrasts with existing greedy approaches to adaptive, problem-tailored circuit constructions. We demonstrate its effectiveness for the four-qubit and six-qubit lithium hydride molecules, as well as an eight-qubit H$_4$ chain. Our learned circuits are interpretable in a physically meaningful manner, thus paving the way for applying RL to the development of novel quantum circuits for the ground states of large-scale molecular systems."}
{"id": "2511.16585", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16585", "abs": "https://arxiv.org/abs/2511.16585", "authors": ["Ed Younis"], "title": "OpenQudit: Extensible and Accelerated Numerical Quantum Compilation via a JIT-Compiled DSL", "comment": null, "summary": "High-performance numerical quantum compilers rely on classical optimization, but are limited by slow numerical evaluations and a design that makes extending them with new instructions a difficult, error-prone task for domain experts. This paper introduces OpenQudit, a compilation framework that solves these problems by allowing users to define quantum operations symbolically in the Qudit Gate Language (QGL), a mathematically natural DSL. OpenQudit's ahead-of-time compiler uses a tensor network representation and an e-graph-based pass for symbolic simplification before a runtime tensor network virtual machine (TNVM) JIT-compiles the expressions into high-performance native code. The evaluation shows that this symbolic approach is highly effective, accelerating the core instantiation task by up to $\\mathtt{\\sim}20\\times$ on common quantum circuit synthesis problems compared to state-of-the-art tools."}
{"id": "2511.16591", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2511.16591", "abs": "https://arxiv.org/abs/2511.16591", "authors": ["Gerónimo J. Caselli", "Luis O. Manuel", "Liliana Arrachea"], "title": "Lindbladian approach for many-qubit thermal machines: enhancing the performance with geometric heat pumping by entanglement", "comment": "31 pages", "summary": "We present a detailed analysis of slowly driven quantum thermal machines based on interacting qubits within the framework of the Lindblad master equation. By implementing a systematic expansion in the driving rate, we derive explicit expressions for the rate of work of the driving forces, the heat currents exchanged with the reservoirs, and the entropy production up to second order, ensuring full thermodynamic consistency in the linear-response regime. The formalism naturally separates geometric and dissipative contributions, identified by a Berry curvature and a metric in parameter space, respectively. Analytical results show that the geometric heat pumped per cycle is bounded by $k_B T N_q \\ln 2$ for $N_q$ non-interacting qubits, in direct analogy with the Landauer limit for entropy change. This bound can be surpassed when qubit interactions and asymmetric couplings to the baths are introduced. Numerical results for the interacting two-qubit system reveal a non-trivial role of the interaction between qubits and the coupling between the qubits and the baths in the behavior of the dissipated power. The approach provides a general platform for studying dissipation, pumping, and performance optimization in driven quantum devices operating as heat engines."}
{"id": "2511.16597", "categories": ["quant-ph", "cs.IT", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.16597", "abs": "https://arxiv.org/abs/2511.16597", "authors": ["Ivana Nikoloska", "Osvaldo Simeone"], "title": "Variational Quantum Integrated Sensing and Communication", "comment": "Submitted for publication", "summary": "The integration of sensing and communication functionalities within a common system is one of the main innovation drivers for next-generation networks. In this paper, we introduce a quantum integrated sensing and communication (QISAC) protocol that leverages entanglement in quantum carriers of information to enable both superdense coding and quantum sensing. The proposed approach adaptively optimizes encoding and quantum measurement via variational circuit learning, while employing classical machine learning-based decoders and estimators to process the measurement outcomes. Numerical results for qudit systems demonstrate that the proposed QISAC protocol can achieve a flexible trade-off between classical communication rate and accuracy of parameter estimation."}
{"id": "2511.16632", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16632", "abs": "https://arxiv.org/abs/2511.16632", "authors": ["Nolan J. Coble", "Min Ye", "Nicolas Delfosse"], "title": "Correction of chain losses in trapped ion quantum computers", "comment": null, "summary": "Neutral atom quantum computers and to a lesser extent trapped ions may suffer from atom loss. In this work, we investigate the impact of atom loss in long chains of trapped ions. Even though this is a relatively rare event, ion loss in long chains must be addressed because it destabilizes the entire chain resulting in the loss of all the qubits of the chain. We propose a solution to the chain loss problem based on (1) a quantum error correction code distributed over multiple long chains, (2) beacon qubits within each long chain to detect the loss of a chain, and (3) a decoder adapted to correct a combination of circuit faults and erasures after beacon qubits convert chain losses into erasures. We verify the chain loss correction capability of our scheme through circuit level simulations with a distributed $[[72,12,6]]$ BB code with beacon qubits."}
{"id": "2511.16645", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16645", "abs": "https://arxiv.org/abs/2511.16645", "authors": ["Francesco Albarelli", "Dominic Branford", "Jesús Rubio"], "title": "Measurement incompatibility in Bayesian multiparameter quantum estimation", "comment": "24 pages, 3 figures", "summary": "We present a comprehensive and pedagogical formulation of Bayesian multiparameter quantum estimation, providing explicit conditions for achieving minimum quadratic losses. Within this framework, we analyse the role of measurement incompatibility and establish its quantitative effect on attainable precision. We achieve this by deriving upper bounds based on the pretty good measurement -- a notion originally developed for hypothesis testing -- combined with the evaluation of the Nagaoka-Hayashi lower bound. In general, we prove that, as in the many-copy regime of local estimation theory, incompatibility can at most double the minimum loss relative to the idealised scenario in which individually optimal measurements are assumed jointly implementable. This result implies that, in many practical situations, the latter may provide a sufficient and computationally efficient benchmark without solving the full optimisation problem. Our results, which we illustrate through a range of applications, including discrete quantum phase imaging, phase and dephasing estimation, and qubit sensing, provide analytical and numerical tools for assessing ultimate precision limits and the role of measurement incompatibility in Bayesian multiparameter quantum metrology. We also provide an open-source package that implements all bounds discussed here, enabling practical evaluation and comparison across quantum metrological models."}
{"id": "2511.15724", "categories": ["physics.soc-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15724", "abs": "https://arxiv.org/abs/2511.15724", "authors": ["Misao Fukuda"], "title": "Comparison of Mathematical Models for Subscription Services Using Optimization Problems and Quantum Information Theory -Feasibility of Implementing Optimization Problem Algorithms on Quantum Computers-", "comment": null, "summary": "The purpose of this research is to explore whether it is possible to construct a design theory for subscription services for intangible goods from a time discounting perspective, based on quantum information theory, which is the foundational theory for quantum computers and similar technologies. To this end, we propose a mathematical model of subscription services using optimization problems based on optimal growth theory from standard economics, and with reference to microeconomics, we define utility as a value function of customer satisfaction derived from quantum mutual information, an entropy measure in quantum information theory, by considering time discounting. We propose the quantification of customer satisfaction and the formulation of consumer surplus. In the mathematical model of subscription services, the existence of a minimum value in the time-discounted customer satisfaction value function under budget constraints, and the realization of a mathematical expression for consumer surplus, could be explained by the laws of behavioral economics. This yielded new insights into the design of individually customized customer experiences, enhanced the feasibility of constructing economic models based on quantum information theory and the mathematical design of customer experiences, raised the possibility that mathematical models using quantum information theory can achieve greater economic welfare than standard economics, and increased the feasibility of implementing optimization problem algorithms on quantum computers."}
{"id": "2511.15783", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.15783", "abs": "https://arxiv.org/abs/2511.15783", "authors": ["Po-Shen Hsin", "Ryohei Kobayashi"], "title": "Automorphism in Gauge Theories: Higher Symmetries and Transversal Non-Clifford Logical Gates", "comment": "22 pages, 6 figures", "summary": "Gauge theories are important descriptions for many physical phenomena and systems in quantum computation. Automorphism of gauge group naturally gives global symmetries of gauge theories. In this work we study such symmetries in gauge theories induced by automorphisms of the gauge group, when the gauge theories have nontrivial topological actions in different spacetime dimensions. We discover the automorphism symmetry can be extended, become a higher group symmetry, and/or become a non-invertible symmetry. We illustrate the discussion with various models in field theory and on the lattice. In particular, we use automorphism symmetry to construct new transversal non-Clifford logical gates in topological quantum codes. In particular, we show that 2+1d $\\mathbb{Z}_N$ qudit Clifford stabilizer models can implement non-Clifford transversal logical gate in the 4th level $\\mathbb{Z}_N$ qudit Clifford hierarchy for $N\\geq 3$, extending the generalized Bravyi-König bound proposed in the companion paper [arXiv:2511.02900] for qubits."}
{"id": "2511.16457", "categories": ["cond-mat.stat-mech", "cond-mat.dis-nn", "cond-mat.quant-gas", "physics.data-an", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16457", "abs": "https://arxiv.org/abs/2511.16457", "authors": ["Yoshiaki Horiike", "Yuki Kawaguchi"], "title": "Distinguishing thermal versus quantum annealing using probability-flux signatures across interaction networks", "comment": null, "summary": "Simulated annealing provides a heuristic solution to combinatorial optimization problems. The cost function of a problem is mapped to the energy function of a physical many-body system, and, using thermal or quantum fluctuations, the system explores the state space to find the ground state, which may correspond to the optimal solution of the problem. Studies have highlighted both the similarities and differences between thermal and quantum fluctuations. Nevertheless, fundamental understanding of thermal and quantum annealing remains incomplete, making it difficult to design problem instances that fairly compare the two methods. Here, we investigate the many-body dynamics of thermal and quantum annealing by examining all possible interaction networks of $\\pm J$ Ising spin systems up to seven spins. Our comprehensive investigation reveals that differences between thermal and quantum annealing emerge for particular interaction networks, indicating that the structure of the energy landscape distinguishes the two dynamics. We identify the microscopic origin of these differences through probability fluxes in state space, finding that the two dynamics are broadly similar but that quantum tunnelling produces qualitative differences. Our results provide insight into how thermal and quantum fluctuations navigate a system toward the ground state in simulated annealing, and are experimentally verifiable in atomic, molecular, and optical systems. Furthermore, these insights may improve mappings of optimization problems to Ising spin systems, yielding more accurate solutions in faster simulated annealing and thus benefiting real-world applications in industry. Our comprehensive survey of interaction networks and visualization of probability flux can help to understand, predict, and control quantum advantage in quantum annealing."}
{"id": "2511.16460", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16460", "abs": "https://arxiv.org/abs/2511.16460", "authors": ["Margaux Vrech", "Jan Major", "Dominique Delande", "Marcel Filoche", "Nicolas Cherroret"], "title": "From percolation transition to Anderson localization in one-dimensional speckle potentials", "comment": null, "summary": "Classical particles in random potentials typically experience a percolation phase transition, being trapped in clusters of mean size $χ$ that diverges algebraically at a percolation threshold. In contrast, quantum transport in random potentials is controlled by the Anderson localization length, which shows no distinct feature at this classical critical point. Here, we present a comprehensive theoretical analysis of the semi-classical crossover between these two regimes by studying particle propagation in a one-dimensional, red speckle potential, which hosts a percolation transition at its upper bound. As the system deviates from the classical limit, we find that the algebraic divergence of $χ$ continuously connects to a smooth yet non-analytic increase of the localization length. We characterize this behavior both numerically and theoretically using a semi-classical approach. In this crossover regime, the correlated and non-Gaussian nature of the speckle potential becomes essential, causing the standard DMPK description for uncorrelated disorder to break down. Instead, we predict the emergence of a bimodal transmission distribution, a behavior normally absent in one dimension, which we capture within our semi-classical analysis. Deep in the quantum regime, the DMPK framework is recovered and the universal features of Anderson localization reappear."}
{"id": "2511.16509", "categories": ["cond-mat.stat-mech", "cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16509", "abs": "https://arxiv.org/abs/2511.16509", "authors": ["J. Sirker"], "title": "Comment on: \"Scaling and Universality at Noisy Quench Dynamical Quantum Phase Transitions\"", "comment": "Comment on arXiv:2506.14355", "summary": "In Ref. Ansari et al., dynamical quantum phase transitions (DQPTs) -- non-analyticities in the Loschmidt return rate at critical times -- are investigated in the presence of noise for a two-band model. The authors report that DQPTs persist even after averaging over the noise and they use their results to derive dynamical phase diagrams. In this comment we rigorously prove that in any two-dimensional Hilbert space the Loschmidt echo of two density matrices can only become zero if and only if both density matrices are pure. As a consequence, the existence of DQPTs in the considered scenario is strictly ruled out for non-zero noise because the considered averaging leads to a mixed state. We also investigate alternative natural ways to average over noise realizations and show that in all of them DQPTs are smoothed out."}
{"id": "2511.16634", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.16634", "abs": "https://arxiv.org/abs/2511.16634", "authors": ["Mina Tarakemeh", "Shenglong Xu"], "title": "Non-Abelian operator size distribution in charge-conserving many-body systems", "comment": "7+8 pages, 4 figures", "summary": "We show that operator dynamics in U(1) symmetric systems are constrained by two independent conserved charges and construct a non-Abelian operator size basis that respects both, enabling a symmetry-resolved characterization of operator growth. The non-Abelian operator size depends on the operator's nonlocal structure and is organized by an SU(2) algebra. Operators associated with large total angular momentum are relatively simple, while those with small angular momentum are more complex. Operator growth is thus characterized by a reduction in angular momentum and can be probed using out-of-time-ordered correlators. Using the charge-conserving Brownian Sachdev-Ye-Kitaev model, we derive an exact classical master equation that governs the size distribution, the distribution of an operator expanded in this basis, for arbitrary system sizes. The resulting dynamics reveal that the size distribution follows a chi-squared form, with the two conserved charges jointly determining the overall time scale and the shape of the distribution. In particular, single-particle operators retain a divergent peak at large angular momentum throughout the time evolution."}
