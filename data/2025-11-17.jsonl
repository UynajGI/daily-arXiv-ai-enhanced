{"id": "2511.10771", "categories": ["eess.SY", "cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10771", "abs": "https://arxiv.org/abs/2511.10771", "authors": ["Le Liu", "Yu Kawano", "Ming Cao"], "title": "Privacy protection under the exposure of systems' prior information", "comment": null, "summary": "For systems whose states implicate sensitive information, their privacy is of great concern. While notions like differential privacy have been successfully introduced to dynamical systems, it is still unclear how a system's privacy can be properly protected when facing the challenging yet frequently-encountered scenario where an adversary possesses prior knowledge, e.g., the steady state, of the system. This paper presents a new systematic approach to protect the privacy of a discrete-time linear time-invariant system against adversaries knowledgeable of the system's prior information. We employ a tailored \\emph{pointwise maximal leakage (PML) privacy} criterion. PML characterizes the worst-case privacy performance, which is sharply different from that of the better-known mutual-information privacy. We derive necessary and sufficient conditions for PML privacy and construct tractable design procedures. Furthermore, our analysis leads to insight into how PML privacy, differential privacy, and mutual-information privacy are related. We then revisit Kalman filters from the perspective of PML privacy and derive a lower bound on the steady-state estimation-error covariance in terms of the PML parameters. Finally, the derived results are illustrated in a case study of privacy protection for distributed sensing in smart buildings."}
{"id": "2511.10775", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10775", "abs": "https://arxiv.org/abs/2511.10775", "authors": ["Fletcher T. Chapin", "Akshay K. Rao", "Adhithyan Sakthivelu", "Carson I. Tucker", "Eres David", "Casey S. Chen", "Erin Musabandesu", "Meagan S. Mauter"], "title": "Retail electricity costs and emissions incentives are misaligned for commercial and industrial power consumers", "comment": "Main manuscript has 24 pages, 6 figures, and 1 table. Supplementary information has 10 pages, 4 figures, and 1 table", "summary": "Electrification is contributing to substantial growth in U.S. commercial and industrial loads, but the cost and Scope 2 carbon emission implications of this load growth are opaque for both power consumers and utilities. This work describes a unique spatiotemporally resolved data set of U.S. electricity costs and emissions and applies time series approximation methods to quantify the alignment of electricity cost and emission incentives for large commercial and industrial consumers. We present a comprehensive spatiotemporal dataset of U.S. price-based demand response (i.e., tariff) and incentive-based demand response (IBDR) programs, enabling direct comparison to previously published marginal emission factor (MEF), average emission factor (AEF), and day-ahead market (DAM) prices. We resolved the structural incompatibility and fragmentation of these datasets by developing time series approximations of discrete data and unifying geospatially heterogeneous datasets. Analysis of these datasets reveals significant spatial and temporal heterogeneity in cost and carbon emissions incentives for demand-side energy flexibility, underscoring the importance of site selection as a key factor influencing power costs and scope 2 emissions. Analysis also reveals broad misalignment of economic and emissions incentives under existing electricity tariff structures, meaning tariffs are incentivizing consumption of more carbon-intensive electricity, and highlighting potential barriers to electrification delivering carbon savings."}
{"id": "2511.10798", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10798", "abs": "https://arxiv.org/abs/2511.10798", "authors": ["Marcus Greiff", "Ray Zhang", "Takeru Shirasawa", "John Subosits"], "title": "Semantic Property Maps for Driving Applications", "comment": "6 pages, 3 figures, workshop paper for ICIP 2025", "summary": "We consider the problem of estimating the parameters of a vehicle dynamics model for predictive control in driving applications. Instead of solely using the instantaneous parameters estimated from the vehicle signals, we combine this with cameras and update a probabilistic map with parameter estimates and semantic information using Bayesian moment matching. Key to this approach is the map representation, which is constructed with conjugate priors to the measurement likelihoods and defined in the same path coordinates as the vehicle controller, such that the map can be externalized to provide a local representation of the parameter likelihoods that vary in space. The result is a spatial map of vehicle parameters adapted online to enhance the driving control system. We provide theoretical guarantees on the smoothness of relevant parameter likelihood statistics as a function of space, which is critical for their use in predictive control."}
{"id": "2511.10844", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10844", "abs": "https://arxiv.org/abs/2511.10844", "authors": ["Anna Franziska Frigge", "Alexander Medvedev"], "title": "Tissue Activation Calculation in Dual-lead Deep Brain Stimulation", "comment": "Submitted to European Control Conference 2026", "summary": "Deep Brain Stimulation (DBS) is a well-established neurosurgical treatment aiming at symptom alleviation in a range of neurological and psychiatric diseases. Computational models of DBS are widely used to investigate the effects of stimulation on neural tissue, to explore stimulation targets and sweetspots, and ultimately, to aid clinicians in the DBS programming by calculating the stimulation parameters. Commonly, DBS is performed bilaterally, i.e. with one lead in each brain hemisphere, where computational models are solved independently for one lead at a time. This paper treats scenarios where multiple DBS leads are implanted in close proximity to one another, resulting in interacting electrical fields and, therefore, potentially overlapping stimulation spreads. In particular, a global dual-lead model is compared to approximations derived from single-lead approaches in a cohort of twelve multiple sclerosis (MS) tremor patients. It is concluded that simple superposition of volumes of tissue activated (VTAs) underestimates activation, while superposition of electric fields or activating functions leads to overestimation. It is concluded that given close proximity of DBS leads, the VTA cannot be computed individually as stimulation fields exhibit significant and complex interaction. The approach is extended to modeling two obsessive compulsive disorder patients with medially placed leads, where similar VTA discrepancies as in the MS patient cohort are observed."}
{"id": "2511.10771", "categories": ["eess.SY", "cs.IT", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10771", "abs": "https://arxiv.org/abs/2511.10771", "authors": ["Le Liu", "Yu Kawano", "Ming Cao"], "title": "Privacy protection under the exposure of systems' prior information", "comment": null, "summary": "For systems whose states implicate sensitive information, their privacy is of great concern. While notions like differential privacy have been successfully introduced to dynamical systems, it is still unclear how a system's privacy can be properly protected when facing the challenging yet frequently-encountered scenario where an adversary possesses prior knowledge, e.g., the steady state, of the system. This paper presents a new systematic approach to protect the privacy of a discrete-time linear time-invariant system against adversaries knowledgeable of the system's prior information. We employ a tailored \\emph{pointwise maximal leakage (PML) privacy} criterion. PML characterizes the worst-case privacy performance, which is sharply different from that of the better-known mutual-information privacy. We derive necessary and sufficient conditions for PML privacy and construct tractable design procedures. Furthermore, our analysis leads to insight into how PML privacy, differential privacy, and mutual-information privacy are related. We then revisit Kalman filters from the perspective of PML privacy and derive a lower bound on the steady-state estimation-error covariance in terms of the PML parameters. Finally, the derived results are illustrated in a case study of privacy protection for distributed sensing in smart buildings."}
{"id": "2511.10926", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.10926", "abs": "https://arxiv.org/abs/2511.10926", "authors": ["Ryota Yamamoto", "Kazushi Okamoto"], "title": "Multi-team Formation System for Collaborative Crowdsourcing", "comment": null, "summary": "For complex crowdsourcing tasks that require collaboration between multiple individuals, teams should be formed by considering both worker compatibility and expertise. Furthermore, the nature of crowdsourcing dictates the budget for tasks and workers' remuneration, and excessively large team sizes may reduce collaborative performance. To address these challenges, we propose a heuristic optimization algorithm that leverages social network information to simultaneously form teams with optimized worker compatibility for multiple tasks. In our approach, historical collaboration is represented as a social network, where the edge weights correspond to explicit ratings of worker compatibility. In a simulation experiment using synthetic data, we applied Gaussian process regression to examine the relationship between eight experimental parameters and evaluation values, thereby analyzing the output of the proposed algorithm. To generate the necessary data for regression, we ran the proposed algorithm with experimental parameters that were sequentially estimated using Bayesian optimization. Our experiments revealed that the evaluation values were extremely low when the team size limit, the degree mean of the social network, and the task budget were set to low values. The results also indicate that the proposed algorithm outperformed the hill-climbing method under almost all experimental conditions. In addition, the highest evaluation values were achieved when the simulated annealing temperature decrease rate was approximately 0.9, while smoothing the objective function proved ineffective."}
{"id": "2511.10917", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.10917", "abs": "https://arxiv.org/abs/2511.10917", "authors": ["Qiuping Wang", "Lu Pan", "Ting Yan"], "title": "Moment estimation in paired comparison models with a growing number of subjects", "comment": "34 pages, 2 tables", "summary": "When the number of subjects, $n$, is large, paired comparisons are often sparse. Here, we study statistical inference in a class of paired comparison models parameterized by a set of merit parameters, under an Erdös--Rényi comparison graph, where the sparsity is measured by a probability $p_n$ tending to zero. We use the moment estimation base on the scores of subjects to infer the merit parameters. We establish a unified theoretical framework in which the uniform consistency and asymptotic normality of the moment estimator hold as the number of subjects goes to infinity. A key idea for the proof of the consistency is that we obtain the convergence rate of the Newton iterative sequence for solving the estimator. We use the Thurstone model to illustrate the unified theoretical results. Further extensions to a fixed sparse comparison graph are also provided. Numerical studies and a real data analysis illustrate our theoretical findings."}
{"id": "2511.10877", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.10877", "abs": "https://arxiv.org/abs/2511.10877", "authors": ["Veikka Piispa", "Dilshanie Prasikala", "Joonas Lahtinen", "Alexandra Koulouri", "Sampsa Pursiainen"], "title": "Tracking EEG Thalamic and Cortical Focal Brain Activity using Standardized Kalman Filtering with Kinematics Modeling", "comment": null, "summary": "Kalman filtering has proven to be effective for estimating brain activity using EEG recordings. In particular, the introduced post hoc standardization step of the algorithm, inspired by the sLORETA time-invariant method, reduces the depth bias and thus allows the estimation to appear at the correct depth from the electrode surface. In the current work, we propose first and second-order kinematic evolution models, where the state-space vector includes not only the dipolar source activity but also its velocity and acceleration. Compared to our previous study, this motion model yields smoother and more physically plausible estimates of brain activity even when the measurement noise is high, for both superficial and deep sources. In addition, we introduce a tunable power parameter that enhances the computational efficiency of the algorithm. Our simulation study, which involves thalamic and cortical activity in the somatosensory region, demonstrates that accurate estimation and tracking of both superficial and deep brain activity are feasible."}
{"id": "2511.11099", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2511.11099", "abs": "https://arxiv.org/abs/2511.11099", "authors": ["Vicenç Méndez", "Rosa Flaquer-Galmés"], "title": "Ergodic properties of occupation times in heterogeneous media", "comment": null, "summary": "We investigate the ergodic properties of Brownian motion in heterogeneous media through the statistics of occupation times. Using the Feynman-Kac formalism, we derive analytical expressions for the distributions, moments, and ergodicity breaking parameters of occupation times in two models with spatially varying diffusion coefficient: a piecewise-constant profile and a power-law profile. In the piecewise model, the half occupation time and the occupation time within an interval follow asymmetric arcsine and half-Gaussian distributions, respectively, indicating non-ergodic behavior. For the power-law case, the corresponding distributions are the Lamperti and Mittag-Leffler. In both models, we identify a transition from non-ergodic to ergodic dynamics as the exponent vary. Numerical simulations fully corroborate the analytical results, demonstrating the effectiveness of the Feynman-Kac approach for quantifying ergodicity in heterogeneous diffusion processes."}
{"id": "2511.11320", "categories": ["cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11320", "abs": "https://arxiv.org/abs/2511.11320", "authors": ["Jiaqi Lin", "Yi Jiang", "Abhronil Sengupta"], "title": "StochEP: Stochastic Equilibrium Propagation for Spiking Convergent Recurrent Neural Networks", "comment": null, "summary": "Spiking Neural Networks (SNNs) promise energy-efficient, sparse, biologically inspired computation. Training them with Backpropagation Through Time (BPTT) and surrogate gradients achieves strong performance but remains biologically implausible. Equilibrium Propagation (EP) provides a more local and biologically grounded alternative. However, existing EP frameworks, primarily based on deterministic neurons, either require complex mechanisms to handle discontinuities in spiking dynamics or fail to scale beyond simple visual tasks. Inspired by the stochastic nature of biological spiking mechanism and recent hardware trends, we propose a stochastic EP framework that integrates probabilistic spiking neurons into the EP paradigm. This formulation smoothens the optimization landscape, stabilizes training, and enables scalable learning in deep convolutional spiking convergent recurrent neural networks (CRNNs). We provide theoretical guarantees showing that the proposed stochastic EP dynamics approximate deterministic EP under mean-field theory, thereby inheriting its underlying theoretical guarantees. The proposed framework narrows the gap to both BPTT-trained SNNs and EP-trained non-spiking CRNNs in vision benchmarks while preserving locality, highlighting stochastic EP as a promising direction for neuromorphic and on-chip learning."}
{"id": "2511.11337", "categories": ["physics.comp-ph", "hep-ex"], "pdf": "https://arxiv.org/pdf/2511.11337", "abs": "https://arxiv.org/abs/2511.11337", "authors": ["Akshat Gupta", "Caterina Doglioni", "Thomas Joseph Elliott"], "title": "BOA Constrictor: A Mamba-based lossless compressor for High Energy Physics data", "comment": "10 pages and 6 figures, excluding appendix", "summary": "The petabyte-scale data generated annually by High Energy Physics (HEP) experiments like those at the Large Hadron Collider present a significant data storage challenge. Whilst traditional algorithms like LZMA and ZLIB are widely used, they often fail to exploit the deep structure inherent in scientific data. We investigate the application of modern state space models (SSMs) to this problem, which have shown promise for capturing long-range dependencies in sequences. We present the Bytewise Online Autoregressive (BOA) Constrictor, a novel, streaming-capable lossless compressor built upon the Mamba architecture. BOA combines an autoregressive Mamba model for next-byte prediction with a parallelised streaming range coder. We evaluate our method on three distinct structured datasets in HEP, demonstrating state-of-the-art compression ratios, improving upon LZMA-9 across all datasets. These improvements range from 2.21$\\times$ (vs. 1.69$\\times$) on the ATLAS dataset to a substantial 44.14$\\times$ (vs. 27.14$\\times$) on the highly-structured CMS dataset, with a modest $\\sim 4.5$MB model size. However, this gain in compression ratio comes with a trade-off in throughput; the Storage-Saving Rate ($σ_{SSR}$) of our prototype currently lags behind highly-optimised CPU-based algorithms like ZLIB. We conclude that while this Mamba-based approach is a highly promising proof-of-principle, significant future work on performance optimisation and hardware portability is required to develop it into a production-ready tool for the HEP community."}
{"id": "2511.10934", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.10934", "abs": "https://arxiv.org/abs/2511.10934", "authors": ["He-Yu Lin", "Shuai Yin", "Z. Y. Xie", "Zhong-Yi Lu"], "title": "Probing universal imaginary-time relaxation critical dynamics with infinite projected entangled pair states", "comment": "8 pages, 5 figures", "summary": "We investigate the imaginary-time relaxation critical dynamics of the two-dimensional transverse-field Ising model using infinite projected entangled pair states (iPEPS) with the full-update strategy. Simulating directly in the thermodynamic limit, we explore the relaxation process near the critical point with two types of initial states: a fully polarized state and a product state with a small magnetization. For the fully polarized state, the magnetization shows a power law scaling $M\\propto τ^{-β/(νz)}$ in the imaginary-time evolution, from which both the critical point and critical exponent can be determined with high accuracy. For the nearly paramagnetic state, the relaxation process exhibits a behavior of $M\\propto τ^θ$ with $θ=0.1958$ being the critical initial-slip exponent, which is in good agreement with that obtained from the dynamic scaling of the self-correlation in quantum Monte Carlo method. These universal features emerge well before the system converges to the ground state, demonstrating the efficiency of imaginary-time evolution for probing quantum criticality. Our results demonstrate that iPEPS can serve as a robust and scalable method for studying dynamical critical phenomena in two-dimensional quantum many-body systems."}
{"id": "2511.11150", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2511.11150", "abs": "https://arxiv.org/abs/2511.11150", "authors": ["Miguel Aguilera", "Daniele De Martino", "Ivan Garashchuk", "Dmitry Sinelshchikov"], "title": "Nonequilibrium Thermodynamics of Associative Memory Continuous-Time Recurrent Neural Networks", "comment": "7 pages, 4 figures", "summary": "Continuous-Time Recurrent Neural Networks (CTRNNs) have been widely used for their capacity to model complex temporal behaviour. However, their internal dynamics often remain difficult to interpret. In this paper, we propose a new class of CTRNNs based on Hopfield-like associative memories with asymmetric couplings. This model combines the expressive power of associative memories with a tractable mathematical formalism to characterize fluctuations in nonequilibrium dynamics. We show that this mathematical description allows us to directly compute the evolution of its macroscopic observables (the encoded features), as well as the instantaneous entropy and entropy dissipation of the system, thereby offering a bridge between dynamical systems descriptions of low-dimensional observables and the statistical mechanics of large nonequilibrium networks. Our results suggest that these nonequilibrium associative CTRNNs can serve as more interpretable models for complex sequence-encoding networks."}
{"id": "2511.10815", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.10815", "abs": "https://arxiv.org/abs/2511.10815", "authors": ["Yuyang Huang", "Dante Kalise", "Hicham Kouhkouh"], "title": "Non-Convex Global Optimization as an Optimal Stabilization Problem: Dynamical Properties", "comment": null, "summary": "We study global optimization of non-convex functions through optimal control theory. Our main result establishes that (quasi-)optimal trajectories of a discounted control problem converge globally and practically asymptotically to the set of global minimizers. Specifically, for any tolerance $η> 0$, there exist parameters $λ$ (discount rate) and $t$ (time horizon) such that trajectories remain within an $η$-neighborhood of the global minimizers after some finite time $τ$. This convergence is achieved directly, without solving ergodic Hamilton-Jacobi-Bellman equations. We prove parallel results for three problem formulations: evolutive discounted, stationary discounted, and evolutive non-discounted cases. The analysis relies on occupation measures to quantify the fraction of time trajectories spend away from the minimizer set, establishing both reachability and stability properties."}
{"id": "2511.10911", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.10911", "abs": "https://arxiv.org/abs/2511.10911", "authors": ["Baoshan Zhang", "Sean M. O'Brien", "Yuan Wu", "Laine E. Thomas"], "title": "Improving Variance and Confidence Interval Estimation in Small-Sample Propensity Score Analyses: Bootstrap vs. Asymptotic Methods", "comment": null, "summary": "Propensity score (PS) methods are widely used to estimate treatment effects in non-randomized studies. Variance is typically estimated using sandwich or bootstrap methods, which can either treat the PS as estimated or fixed. The latter is thought to be conservative. Comparisons between the sandwich and bootstrap estimators have been compared in moderate to large sample sizes, favoring the bootstrap estimator. With the growing interest in treatments for rare disease and externally controlled clinical trials, very small sample sizes are not uncommon and the asymptotic properties of sandwich estimators may not hold. Bootstrap methods that allow for PS re-estimation can also generate problems with quasi-separation in small samples. It is unclear whether it is safe to prefer sandwich estimators or to assume that treating the PS as fixed is conservative. We conducted a Monte Carlo simulation to compare the performance of bootstrap versus sandwich variance and CI estimators for average treatment effects estimated with PS methods. We systematically evaluated the impact of treating the PS as fixed versus re-estimating it. These methodological comparisons were performed using Inverse Probability of Treatment Weighting (IPTW) and Augmented Inverse Probability of Treatment Weighting (AIPW) estimators. Simulations assessed performance under various conditions, including small sample sizes and different outcome and treatment prevalences. We illustrate the differences in our motivating example, the LIMIT-JIA trial. We show that the sandwich estimators can perform quite poorly in small samples, and fixed PS methods are not necessarily conservative. A stratified bootstrap avoids quasi-separation and performs well. Differences were large enough to alter statistical conclusions in our motivating example, LIMIT-JIA."}
{"id": "2511.10761", "categories": ["cs.CE", "cs.AI", "cs.LG", "math.DG"], "pdf": "https://arxiv.org/pdf/2511.10761", "abs": "https://arxiv.org/abs/2511.10761", "authors": ["Andrin Rehmann", "Nolan Black", "Josiah Bjorgaard", "Alessandro Angioi", "Andrei Paleyes", "Niklas Heim", "Dion Häfner", "Alexander Lavin"], "title": "Surrogate-Based Differentiable Pipeline for Shape Optimization", "comment": null, "summary": "Gradient-based optimization of engineering designs is limited by non-differentiable components in the typical computer-aided engineering (CAE) workflow, which calculates performance metrics from design parameters. While gradient-based methods could provide noticeable speed-ups in high-dimensional design spaces, codes for meshing, physical simulations, and other common components are not differentiable even if the math or physics underneath them is. We propose replacing non-differentiable pipeline components with surrogate models which are inherently differentiable. Using a toy example of aerodynamic shape optimization, we demonstrate an end-to-end differentiable pipeline where a 3D U-Net full-field surrogate replaces both meshing and simulation steps by training it on the mapping between the signed distance field (SDF) of the shape and the fields of interest. This approach enables gradient-based shape optimization without the need for differentiable solvers, which can be useful in situations where adjoint methods are unavailable and/or hard to implement."}
{"id": "2511.10852", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10852", "abs": "https://arxiv.org/abs/2511.10852", "authors": ["Yi-Ping Chen", "Derick Suarez", "Ying-Kuan Tsai", "Vispi Karkaria", "Guanzhong Hu", "Zihan Chen", "Ping Guo", "Jian Cao", "Wei Chen"], "title": "Adaptive Digital Twin of Sheet Metal Forming via Proper Orthogonal Decomposition-Based Koopman Operator with Model Predictive Control", "comment": null, "summary": "Digital Twin (DT) technologies are transforming manufacturing by enabling real-time prediction, monitoring, and control of complex processes. Yet, applying DT to deformation-based metal forming remains challenging because of the strongly coupled spatial-temporal behavior and the nonlinear relationship between toolpath and material response. For instance, sheet-metal forming by the English wheel, a highly flexible but artisan-dependent process, still lacks digital counterparts that can autonomously plan and adapt forming strategies. This study presents an adaptive DT framework that integrates Proper Orthogonal Decomposition (POD) for physics-aware dimensionality reduction with a Koopman operator for representing nonlinear system in a linear lifted space for the real-time decision-making via model predictive control (MPC). To accommodate evolving process conditions or material states, an online Recursive Least Squares (RLS) algorithm is introduced to update the operator coefficients in real time, enabling continuous adaptation of the DT model as new deformation data become available. The proposed framework is experimentally demonstrated on a robotic English Wheel sheet metal forming system, where deformation fields are measured and modeled under varying toolpaths. Results show that the adaptive DT is capable of controlling the forming process to achieve the given target shape by effectively capturing non-stationary process behaviors. Beyond this case study, the proposed framework establishes a generalizable approach for interpretable, adaptive, and computationally-efficient DT of nonlinear manufacturing systems, bridging reduced-order physics representations with data-driven adaptability to support autonomous process control and optimization."}
{"id": "2511.10775", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10775", "abs": "https://arxiv.org/abs/2511.10775", "authors": ["Fletcher T. Chapin", "Akshay K. Rao", "Adhithyan Sakthivelu", "Carson I. Tucker", "Eres David", "Casey S. Chen", "Erin Musabandesu", "Meagan S. Mauter"], "title": "Retail electricity costs and emissions incentives are misaligned for commercial and industrial power consumers", "comment": "Main manuscript has 24 pages, 6 figures, and 1 table. Supplementary information has 10 pages, 4 figures, and 1 table", "summary": "Electrification is contributing to substantial growth in U.S. commercial and industrial loads, but the cost and Scope 2 carbon emission implications of this load growth are opaque for both power consumers and utilities. This work describes a unique spatiotemporally resolved data set of U.S. electricity costs and emissions and applies time series approximation methods to quantify the alignment of electricity cost and emission incentives for large commercial and industrial consumers. We present a comprehensive spatiotemporal dataset of U.S. price-based demand response (i.e., tariff) and incentive-based demand response (IBDR) programs, enabling direct comparison to previously published marginal emission factor (MEF), average emission factor (AEF), and day-ahead market (DAM) prices. We resolved the structural incompatibility and fragmentation of these datasets by developing time series approximations of discrete data and unifying geospatially heterogeneous datasets. Analysis of these datasets reveals significant spatial and temporal heterogeneity in cost and carbon emissions incentives for demand-side energy flexibility, underscoring the importance of site selection as a key factor influencing power costs and scope 2 emissions. Analysis also reveals broad misalignment of economic and emissions incentives under existing electricity tariff structures, meaning tariffs are incentivizing consumption of more carbon-intensive electricity, and highlighting potential barriers to electrification delivering carbon savings."}
{"id": "2511.10957", "categories": ["cs.SI", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.10957", "abs": "https://arxiv.org/abs/2511.10957", "authors": ["Allana Tavares Bastos", "Tiago Alves Schieber", "Renato Hadad", "Laura Carpi", "Martín Gómez Ravetti"], "title": "Structural asymmetry as a fraud signature: detecting collusion with Heron's Information Coefficient", "comment": "Source code on https://github.com/FutureLab-DCC/Heron_coefficient", "summary": "Fraud in public procurement remains a persistent challenge, especially in large, decentralized systems like Brazil's Unified Health System. We introduce Heron's Information Coefficient (HIC), a geometric measure that quantifies how subgraphs deviate from the global structure of a network. Applied to over eight years of Brazilian bidding data for medical supplies, this measure highlights collusive patterns that standard indicators may overlook. Unlike conventional robustness metrics, the Heron coefficient focuses on the interaction between active and inactive subgraphs, revealing structural shifts that may signal coordinated behavior, such as cartel formation. Synthetic experiments support these findings, demonstrating strong detection performance across varying corruption intensities and network sizes. While our results do not replace legal or economic analyses, they offer an effective complementary tool for auditors and policymakers to monitor procurement integrity more effectively. This study demonstrates that simple geometric insight can reveal hidden dynamics in real-world networks better than other Information Theoretic metrics."}
{"id": "2511.11003", "categories": ["math.ST", "econ.EM", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.11003", "abs": "https://arxiv.org/abs/2511.11003", "authors": ["Jeonghwan Lee", "Cong Ma"], "title": "Learning bounds for doubly-robust covariate shift adaptation", "comment": "49 pages, comments are welcome", "summary": "Distribution shift between the training domain and the test domain poses a key challenge for modern machine learning. An extensively studied instance is the \\emph{covariate shift}, where the marginal distribution of covariates differs across domains, while the conditional distribution of outcome remains the same. The doubly-robust (DR) estimator, recently introduced by \\cite{kato2023double}, combines the density ratio estimation with a pilot regression model and demonstrates asymptotic normality and $\\sqrt{n}$-consistency, even when the pilot estimates converge slowly. However, the prior arts has focused exclusively on deriving asymptotic results and has left open the question of non-asymptotic guarantees for the DR estimator.\n  This paper establishes the first non-asymptotic learning bounds for the DR covariate shift adaptation. Our main contributions are two-fold: (\\romannumeral 1) We establish \\emph{structure-agnostic} high-probability upper bounds on the excess target risk of the DR estimator that depend only on the $L^2$-errors of the pilot estimates and the Rademacher complexity of the model class, without assuming specific procedures to obtain the pilot estimate, and (\\romannumeral 2) under \\emph{well-specified parameterized models}, we analyze the DR covariate shift adaptation based on modern techniques for non-asymptotic analysis of MLE, whose key terms governed by the Fisher information mismatch term between the source and target distributions. Together, these findings bridge asymptotic efficiency properties and a finite-sample out-of-distribution generalization bounds, providing a comprehensive theoretical underpinnings for the DR covariate shift adaptation."}
{"id": "2511.10928", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.10928", "abs": "https://arxiv.org/abs/2511.10928", "authors": ["Kabenge Hamiss", "Mohammed M. Alshahrani", "Mujahid N. Syed"], "title": "Two Generalized Derivative-free Methods to Solve Large Scale Nonlinear Equations with Convex Constraints", "comment": "26, 6 figures", "summary": "In this work, we propose two derivative-free methods to address the problem of large-scale nonlinear equations with convex constraints. These algorithms satisfy the sufficient descent condition. The search directions can be considered generalizations of the Modified Optimal Perry conjugate gradient method and the conjugate gradient projection method or the Spectral Modified Optimal Perry conjugate gradient method and the Spectral Conjugate Gradient Projection method. The global convergence of the former does not depend on the Lipschitz continuity of G. In contrast, the latter's global convergence depends on the Lipschitz continuity of G. The numerical results show the efficiency of the algorithms."}
{"id": "2511.11333", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2511.11333", "abs": "https://arxiv.org/abs/2511.11333", "authors": ["Merlin Füllgraf", "Jochen Gemmer", "Jiaozi Wang"], "title": "Scaling of free cumulants in closed system-bath setups", "comment": "15 pages, 6 figures", "summary": "The Eigenstate Thermalization Hypothesis (ETH) has been established as a cornerstone for understanding thermalization in quantum many-body systems. Recently, there has been growing interest in the full ETH, which extends the framework of the conventional ETH and postulates a smooth function to describe the multi-point correlations among matrix elements. Within this framework, free cumulants play a central role, and most previous studies have primarily focused on closed systems. In this paper, we extend the analysis to a system-bath setup, considering both an idealized case with a random-matrix bath and a more realistic scenario where the bath is modeled as a defect Ising chain. In both cases, we uncover a universal scaling of microcanonical free cumulants of system observables with respect to the interaction strength. Furthermore we establish a connection between this scaling behavior and the thermalization dynamics of the thermal free cumulants of corresponding observables."}
{"id": "2511.11354", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.11354", "abs": "https://arxiv.org/abs/2511.11354", "authors": ["Jiong-Hang Liang", "Yunfeng Xiong"], "title": "Beyond quantum mean-field approximation: Phase-space formulation of many-body time-dependent density functional theory and efficient spectral approximations", "comment": null, "summary": "As a universal quantum mechanical approach to the dynamical many-body problem, the time-dependent density functional theory (TDDFT) might be inadequate to describe crucial observables that rely on two-body evolution behavior, like the double-excitation probability and two-body dynamic correlation. One promising remedy is to utilize the time-dependent 2-reduced density matrix (2-RDM) that directly represents two-body observables in an N-particle system, and resort to the extended TDDFT for multibody densities to break the confines of spatial local on one-body density [Phys. Rev. Lett. 26(6) (2024) 263001]. However, the usage of 2-RDM is prohibitive due to the augmented dimensionality, e.g., 4-D space for unidimensional 2-RDM. This work addresses the high-dimensional numerical challenges by using an equivalent Wigner phase-space formulation of 2-RDM and seeking efficient spectral approximations to nonlocal quantum potentials. For spatial periodic case, a pseudo-difference operator approach is derived for both the Hartree-exchange-correlation term and two-body collision operator, while the discretization via the Chebyshev spectral element method is provided for non-periodic case. A massively parallel numerical scheme, which integrates these spectral approximations with a distributed characteristics method, allows us to make the first attempt for real simulations of 2-RDM dynamics. Numerical experiments demonstrate the two-body correction to the quantum kinetic theory, and show the increase in the system's entropy induced by the two-bdoy interaction. Thus it may pave the way for an accurate description of 2-RDM dynamics and advance to a practical application of many-body TDDFT."}
{"id": "2511.10954", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2511.10954", "abs": "https://arxiv.org/abs/2511.10954", "authors": ["Daemo Kang", "Tien-Tien Yeh", "Takahiro Morimoto", "Alexander V. Balatsky"], "title": "Kapitza-Dirac interference of Higgs waves in superconductors", "comment": null, "summary": "We present a novel framework for controlling Higgs mode and vortex dynamics in superconductors using structured light. We propose a phenomenon analog of the Kapitza-Dirac effect in superconductors, where Higgs waves scatter off light-induced vortex lattices, generating interference patterns akin to matter wave diffraction. We also find that the vortices enable the linear coupling of Higgs mode to the electromagnetic field. This interplay between light-engineered Higgs excitations and emergent vortex textures opens a pathway to probe nonequilibrium superconductivity with unprecedented spatial and temporal resolution. Our results bridge quantum optics and condensed matter physics, offering new examples of quantum printing where one uses structured light to manipulate the collective modes in correlated quantum fluids."}
{"id": "2511.11098", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.11098", "abs": "https://arxiv.org/abs/2511.11098", "authors": ["Georgi Angelov", "Alberto Domínguez Corella", "Vladimir Veliov"], "title": "On the accuracy of the model predictive control method", "comment": null, "summary": "The paper investigates the accuracy of the Model Predictive Control (MPC) method for finding online approximate optimal feedback control for Bolza type problems on a fixed finite horizon. The predictions for the dynamics, the state measurements, and the solution of the auxiliary open-loop control problems that appear at every step of the MPC method may be inaccurate. The main result provides an error estimate of the MPC-generated solution compared with the optimal open-loop solution of the ``ideal'' problem, where all predictions and measurements are exact. The technique of proving the estimate involves an extension of the notion of strong metric sub-regularity of set-valued maps and utilization of a specific new metric in the control space, which makes the proof non-standard. The result is specialized for two problem classes: coercive problems, and affine problems."}
{"id": "2511.11114", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.11114", "abs": "https://arxiv.org/abs/2511.11114", "authors": ["Chiara Degan", "Bart J. A. Mertens", "Jelle Goeman", "Nadine A. Ikelaar", "Erik H. Niks", "Pietro Spitali", "Roula Tsonaka"], "title": "Multivariate longitudinal modeling of cross-sectional and lagged associations between a continuous time-varying endogenous covariate and a non-Gaussian outcome", "comment": null, "summary": "In longitudinal studies, time-varying covariates are often endogenous, meaning their values depend on both their own history and that of the outcome variable. This violates key assumptions of Generalized Linear Mixed Effects Models (GLMMs), leading to biased and inconsistent estimates. Additionally, missing data and non-concurrent measurements between covariates and outcomes further complicate analysis, especially in rare or degenerative diseases where data is limited. To address these challenges, we propose an alternative use of two well-known multivariate models, each assuming a different form of the association. One induces the association by jointly modeling the random effects, called Joint Mixed Model (JMM); the other quantifies the association using a scaling factor, called Joint Scaled Model (JSM). We extend these models to accommodate continuous endogenous covariates and a wide range of longitudinal outcome types. A limitation in both cases is that the interpretation of the association is neither straightforward nor easy to communicate to scientists. Hence, we have numerically derived an association coefficient that measures the marginal relation between the outcome and the endogenous covariate. The proposed method provides interpretable, population-level estimates of cross-sectional associations (capturing relationships between covariates and outcomes measured at the same time point) and lagged associations (quantifying how past covariate values influence future outcomes), enabling clearer clinical insights. We fitted the JMM and JSM using a flexible Bayesian estimation approach, known as Integrated Nested Laplace Approximation (INLA), to overcome computation burden problems. These models will be presented along with the results of a simulation study and a natural history study on patients with Duchenne Muscular Dystrophy."}
{"id": "2511.11150", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2511.11150", "abs": "https://arxiv.org/abs/2511.11150", "authors": ["Miguel Aguilera", "Daniele De Martino", "Ivan Garashchuk", "Dmitry Sinelshchikov"], "title": "Nonequilibrium Thermodynamics of Associative Memory Continuous-Time Recurrent Neural Networks", "comment": "7 pages, 4 figures", "summary": "Continuous-Time Recurrent Neural Networks (CTRNNs) have been widely used for their capacity to model complex temporal behaviour. However, their internal dynamics often remain difficult to interpret. In this paper, we propose a new class of CTRNNs based on Hopfield-like associative memories with asymmetric couplings. This model combines the expressive power of associative memories with a tractable mathematical formalism to characterize fluctuations in nonequilibrium dynamics. We show that this mathematical description allows us to directly compute the evolution of its macroscopic observables (the encoded features), as well as the instantaneous entropy and entropy dissipation of the system, thereby offering a bridge between dynamical systems descriptions of low-dimensional observables and the statistical mechanics of large nonequilibrium networks. Our results suggest that these nonequilibrium associative CTRNNs can serve as more interpretable models for complex sequence-encoding networks."}
{"id": "2511.10750", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2511.10750", "abs": "https://arxiv.org/abs/2511.10750", "authors": ["K. Z. Nanjo", "J. Yazbeck", "I. T. Baughman", "J. B. Rundle"], "title": "Seismic quiescence and activation prior to the 2025 M8.8 Kamchatka, Russia earthquake", "comment": "6 Figures", "summary": "The 29 July 2025 Kamchatka earthquake, of magnitude M8.8, provides a unique opportunity to investigate the preparatory processes of a great subduction event. Despite Kamchatka's high seismic activity, the long-term evolution of seismicity preceding major ruptures has been poorly documented. Identifying temporal patterns-such as multiyear quiescence and short-term activation-is essential for understanding megathrust failure processes. We applied the Epidemic-Type Aftershock Sequence (ETAS) model and change-point analysis to earthquakes with M>=5 within a 100-km radius of the 2025 mainshock epicenter, using the Advanced National Seismic System (ANSS) catalog spanning 1975-2025. This approach quantified temporal variations in the seismicity rate and detected statistically significant change points. We identified a pronounced approximately 20-year quiescent interval beginning around mid-2003, followed by an abrupt activation that commenced with the M7.4 foreshock on 20 July 2025. A similar quiescence-to-activation sequence near the eventual hypocenter was also observed for the 1997 M7.8 Kronotsky and 2006 M8.3 Simushirskoe earthquakes, which ruptured segments immediately north and south of the 2025 rupture, respectively. These results suggest that heightened seismic activity following multiyear quiescence is a recurrent feature of the Kamchatka-Kuril subduction system hosting large megathrust earthquakes."}
{"id": "2511.10835", "categories": ["nlin.AO", "cs.MA", "math.OC", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2511.10835", "abs": "https://arxiv.org/abs/2511.10835", "authors": ["Domenico Maisto", "Davide Nuzzi", "Giovanni Pezzulo"], "title": "What the flock knows that the birds do not: exploring the emergence of joint agency in multi-agent active inference", "comment": "18 pages, 3 figures, appendix", "summary": "Collective behavior pervades biological systems, from flocks of birds to neural assemblies and human societies. Yet, how such collectives acquire functional properties -- such as joint agency or knowledge -- that transcend those of their individual components remains an open question. Here, we combine active inference and information-theoretic analyses to explore how a minimal system of interacting agents can give rise to joint agency and collective knowledge. We model flocking dynamics using multiple active inference agents, each minimizing its own free energy while coupling reciprocally with its neighbors. We show that as agents self-organize, their interactions define higher-order statistical boundaries (Markov blankets) enclosing a ``flock'' that can be treated as an emergent agent with its own sensory, active, and internal states. When exposed to external perturbations (a ``predator''), the flock exhibits faster, coordinated responses than individual agents, reflecting collective sensitivity to environmental change. Crucially, analyses of synergistic information reveal that the flock encodes information about the predator's location that is not accessible to every individual bird, demonstrating implicit collective knowledge. Together, these results show how informational coupling among active inference agents can generate new levels of autonomy and inference, providing a framework for understanding the emergence of (implicit) collective knowledge and joint agency."}
{"id": "2511.11026", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.11026", "abs": "https://arxiv.org/abs/2511.11026", "authors": ["Adel Bechihi", "Aristotelis Kapnopoulos"], "title": "Region of Attraction Estimate Learning and Verification for Nonlinear Systems using Neural-Network-based Lyapunov Functions", "comment": null, "summary": "Estimating the Region of Attraction (RoA) for nonlinear dynamical systems is a fundamental problem in control theory, with direct implications for stability analysis and safe controller design. Traditional approaches rely on analytically derived Lyapunov functions, which are often conservative and challenging to construct for high-dimensional or highly nonlinear systems. In this work, we propose a data-driven framework for learning and verifying RoA estimates for nonlinear systems using neural-network-based Lyapunov functions. Our method employs a composite Lyapunov function that combines a quadratic term with a neural-network-based component, providing both structure and flexibility. We introduce a novel homogeneous loss function for training, which removes the imbalance typically caused by the two non-homogeneous Lyapunov conditions. Together, these two aspects enable efficient training of the Lyapunov candidate. To guarantee the correctness of the learned Lyapunov function, we employ a Satisfiability Modulo Theories (SMT) solver to formally verify the stability results. Lastly, we perform a deeper analysis near the origin to overcome numerical artifacts, ensuring strict asymptotic stability. We demonstrate the effectiveness of our approach on benchmark nonlinear systems, showing that it significantly reduces conservatism compared to traditional Lyapunov methods while maintaining verifiability. This framework bridges the gap between function approximation and stability certification, paving the way for scalable safety analysis in learning-based control and safety-critical applications."}
{"id": "2511.10798", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10798", "abs": "https://arxiv.org/abs/2511.10798", "authors": ["Marcus Greiff", "Ray Zhang", "Takeru Shirasawa", "John Subosits"], "title": "Semantic Property Maps for Driving Applications", "comment": "6 pages, 3 figures, workshop paper for ICIP 2025", "summary": "We consider the problem of estimating the parameters of a vehicle dynamics model for predictive control in driving applications. Instead of solely using the instantaneous parameters estimated from the vehicle signals, we combine this with cameras and update a probabilistic map with parameter estimates and semantic information using Bayesian moment matching. Key to this approach is the map representation, which is constructed with conjugate priors to the measurement likelihoods and defined in the same path coordinates as the vehicle controller, such that the map can be externalized to provide a local representation of the parameter likelihoods that vary in space. The result is a spatial map of vehicle parameters adapted online to enhance the driving control system. We provide theoretical guarantees on the smoothness of relevant parameter likelihood statistics as a function of space, which is critical for their use in predictive control."}
{"id": "2511.11053", "categories": ["cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11053", "abs": "https://arxiv.org/abs/2511.11053", "authors": ["Martina Alutto", "Sofia Bellotti", "Fabrizio Dabbene", "Chiara Ravazzi"], "title": "Modeling and Control of Sustainable Transitions through Opinion-Behavior Coupling in Heterogeneous Networks", "comment": "13 pages, 10 figures", "summary": "Understanding how sustainable behaviors spread within heterogeneous societies requires the integration of behavioral data, social influence mechanisms, and structured approaches to control. In this paper, we propose a data-driven computational framework for coupled opinion-adoption dynamics in social systems. Each node in the multilayer network represents a community characterized by a specific age group and mobility level, derived from large-scale survey data on the predisposition to adopt electric vehicles in Northern Europe. The proposed model captures three mechanisms: behavioral contagion through social and informational diffusion, abandonment driven by dissatisfaction, and feedback between opinions and adoption levels through social influence. Analyzing the equilibrium points of the coupled system allows us to derive the conditions that enable large-scale adoption. We empirically calibrate the model using data to construct synthetic populations and social similarity networks, which we use to explore targeted interventions that promote sustainable transitions. Specifically, the analysis focuses on two types of control strategies: opinion-based policies, which act on the social network layer, and policies that aim to improve experience and reduce dissatisfaction. Simulation results show that the latter ensure more stable and long-term adoption, offering concrete insights for designing effective interventions in sociotechnical transitions toward sustainability."}
{"id": "2511.11054", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.11054", "abs": "https://arxiv.org/abs/2511.11054", "authors": ["Xiang Li", "Jun S. Liu", "Qiang Sun", "Lihu Xu"], "title": "Joint robust estimation", "comment": null, "summary": "We introduce a joint robust estimation method for three parametric statistical models with heavy-tailed data: mean estimation, linear regression, and L2-penalized linear regression, where both the trend parameters and the error variance are unknown. Our approach is based on solving two coupled Catoni-type equations, one for estimating the trend parameters and the other for estimating the error variance. Notably, this joint estimation strategy cannot be obtained by minimizing a single loss function involving both the trend and variance parameters. The method offers four key advantages: (i) the length of the resulting (1 - epsilon) confidence interval scales as (log(1/epsilon))^{1/2}, matching the order achieved by classical estimators for sub-Gaussian data; (ii) it is tuning-free, eliminating the need for separate variance estimation; (iii) it allows flexible selection of Catoni-type functions tailored to the data; and (iv) it delivers strong performance for high-variance data, thanks to the explicit inclusion of the variance term in the denominators of both equations.\n  We establish the consistency and asymptotic efficiency of the proposed joint robust estimators using new analytical techniques. The coupled equations are inherently complex, which makes the theoretical analysis of their solutions challenging. To address this, we employ the Poincare-Miranda theorem to show that the solutions lie within geometric regions, such as cylinders or cones, centered around the true parameter values. This methodology is of independent interest and extends to other statistical problems."}
{"id": "2511.11016", "categories": ["math.NA", "math-ph", "math.SP"], "pdf": "https://arxiv.org/pdf/2511.11016", "abs": "https://arxiv.org/abs/2511.11016", "authors": ["Davide Pradovera", "Alessandro Borghi", "Lukas Pieronek", "Andreas Kleefeld"], "title": "Bifurcations in Interior Transmission Eigenvalues: Theory and Computation", "comment": null, "summary": "The interior transmission eigenvalue problem (ITP) plays a central role in inverse scattering theory and in the spectral analysis of inhomogeneous media. Despite its smooth dependence on the refractive index at the PDE level, the corresponding spectral map from material parameters to eigenpairs may exhibit non-smooth or bifurcating behavior. In this work, we develop a theoretical framework identifying sufficient conditions for such non-smooth spectral behavior in the ITP on general domains. We further specialize our analysis to some radially symmetric geometries, enabling a more precise characterization of bifurcations in the spectrum. Computationally, we formulate the ITP as a parametric, discrete, nonlinear eigenproblem and use a match-based adaptive contour eigensolver to accurately and efficiently track eigenvalue trajectories under parameter variation. Numerical experiments confirm the theoretical predictions and reveal novel non-smooth spectral effects."}
{"id": "2511.11150", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "nlin.CD"], "pdf": "https://arxiv.org/pdf/2511.11150", "abs": "https://arxiv.org/abs/2511.11150", "authors": ["Miguel Aguilera", "Daniele De Martino", "Ivan Garashchuk", "Dmitry Sinelshchikov"], "title": "Nonequilibrium Thermodynamics of Associative Memory Continuous-Time Recurrent Neural Networks", "comment": "7 pages, 4 figures", "summary": "Continuous-Time Recurrent Neural Networks (CTRNNs) have been widely used for their capacity to model complex temporal behaviour. However, their internal dynamics often remain difficult to interpret. In this paper, we propose a new class of CTRNNs based on Hopfield-like associative memories with asymmetric couplings. This model combines the expressive power of associative memories with a tractable mathematical formalism to characterize fluctuations in nonequilibrium dynamics. We show that this mathematical description allows us to directly compute the evolution of its macroscopic observables (the encoded features), as well as the instantaneous entropy and entropy dissipation of the system, thereby offering a bridge between dynamical systems descriptions of low-dimensional observables and the statistical mechanics of large nonequilibrium networks. Our results suggest that these nonequilibrium associative CTRNNs can serve as more interpretable models for complex sequence-encoding networks."}
{"id": "2511.11489", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.11489", "abs": "https://arxiv.org/abs/2511.11489", "authors": ["Jay Shen", "Yifeng Tang", "Andrew Ferguson"], "title": "Power law attention biases for molecular transformers", "comment": "Machine Learning and the Physical Sciences Workshop at NeurIPS 2025", "summary": "Transformers are the go-to architecture for most data modalities due to their scalability. While they have been applied extensively to molecular property prediction, they do not dominate the field as they do elsewhere. One cause may be the lack of structural biases that effectively capture the relationships between atoms. Here, we investigate attention biases as a simple and natural way to encode structure. Motivated by physical power laws, we propose a family of low-complexity attention biases $b_{ij} = p \\log|| \\mathbf{r}_i - \\mathbf{r}_j||$ which weigh attention probabilities according to interatomic distances. On the QM9 and SPICE datasets, this approach outperforms positional encodings and graph attention while remaining competitive with more complex Gaussian kernel biases. We also show that good attention biases can compensate for a complete ablation of scaled dot-product attention, suggesting a low-cost path toward interpretable molecular transformers."}
{"id": "2511.11105", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2511.11105", "abs": "https://arxiv.org/abs/2511.11105", "authors": ["Jakov Budić", "Serena Nasrallah", "D. Santos-Cottin", "A. Pulkkinen", "J. Minár", "P. Sačer", "B. Gudac", "V. Despoja", "N. Barišić", "C. C. Homes", "Ana Akrap", "Mario Novak"], "title": "Optical conductivity of layered topological semimetal TaNiTe$_5$", "comment": "Data at https://doi.org/10.5281/zenodo.17601609", "summary": "We present an infrared spectroscopy study of the layered topological semimetal TaNiTe$_5$, a material with a quasi-one-dimensional structure and strong in-plane anisotropy. Despite its structural features, infrared reflectivity and electronic transport measurements along the $a$ and $c$ crystallographic axes show metallic behavior without evidence of reduced dimensionality. Optical conductivity reveals an anisotropic but conventional metallic response with low scattering rates and a single sharp infrared-active phonon mode at $396$ cm$^{-1}$ ($49$ meV). Ab initio calculations closely match the experimental optical data and confirm a three-dimensional electronic structure. Our results demonstrate that TaNiTe$_5$ behaves as a three-dimensional anisotropic semimetal in its electronic and optical properties."}
{"id": "2511.11122", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.11122", "abs": "https://arxiv.org/abs/2511.11122", "authors": ["Yuyang Huang", "Dante Kalise", "Hicham Kouhkouh"], "title": "Non-Convex Global Optimization as an Optimal Stabilization Problem: Convergence Rates", "comment": null, "summary": "We propose a discounted infinite-horizon optimal control formulation that generates trajectories converging to the set of global minimizers of a continuous, non-convex function. The analysis provides explicit convergence rates for both the variational behavior of the value function and the pathwise convergence of the optimal trajectories. This paper is a companion to our previous work, where a more general framework was introduced; here, we focus on a specific setting in which sharper and more detailed results can be established."}
{"id": "2511.11166", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.11166", "abs": "https://arxiv.org/abs/2511.11166", "authors": ["Lasse Fischer", "Konstantinos Sechidis"], "title": "Knockoffs for low dimensions: changing the nominal level post-hoc to gain power while controlling the FDR", "comment": null, "summary": "Knockoffs are a powerful tool for controlled variable selection with false discovery rate (FDR) control. However, while they are frequently used in high-dimensional regressions, they lack power in low-dimensional and sparse signal settings. One of the main reasons is that knockoffs require a minimum number of selections, depending on the nominal FDR level. In this paper, we leverage e-values to allow the nominal level to be switched after looking at the data and applying the knockoff procedure. In this way, we can increase the nominal level in cases where the original knockoff procedure does not make any selections to potentially make discoveries. Also, in cases where the original knockoff procedure makes discoveries, we can often decrease the nominal level to increase the precision. These improvements come without any costs, meaning the results of our post-hoc knockoff procedure are always more informative than the results of the original knockoff procedure. Furthermore, we apply our technique to recently proposed derandomized knockoff procedures."}
{"id": "2511.11130", "categories": ["physics.soc-ph", "math.PR", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2511.11130", "abs": "https://arxiv.org/abs/2511.11130", "authors": ["Paolo Cermelli", "Silvia Marchese", "Laura Sacerdote", "Cristina Zucca"], "title": "Animal social networks as intersections graphs of random walks", "comment": "30 pages, 7 figures", "summary": "We study here the social network generated by the asynchronous visits, to a fixed set of sites, of mobile agents modelled as independent random walks on the plane lattice. The social network is constructed by assuming that a group of agents are associated if they have visited the same set of sites within a finite time interval. This construction is an instance of a random intersection graph, and has been used in the literature to study association networks in a number of animal species. We characterize the mathematical structure of these networks, which we view as one-mode projections of suitable bipartite graphs or, equivalently, as 2-sections of the corresponding hypergraphs. We determine analytically the probability distribution of the random bipartite graphs and hypergraphs associated to this construction, and suggest that association networks generated by the use of common resources are better described by hypergraphs rather than simple projected graphs, that miss important information regarding the actual associations among the agents."}
{"id": "2511.11131", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11131", "abs": "https://arxiv.org/abs/2511.11131", "authors": ["Farnaz Adib Yaghmaie", "Arunava Naha"], "title": "Convergence of Flow-Policy Gradient Learning for Linear Quadratic Regulator Problems", "comment": "Submitted to L4DC", "summary": "Flow $Q$-learning has recently been introduced to integrate learning from expert demonstrations into an actor-critic structure. Central to this innovation is the ``the one-step policy'' network, which is optimized through a $Q$-function that is regularized with the behavioral cloning from expert trajectories, allowing learning more expressive policies using flow-based generative models. In this paper, we studied the convergence property and stabilizablity of the one-step policy during learning for linear quadratic problems under the offline settings. Our theoretical results are based on a new formulation of the one-step policy loss based on the average expected cost, and regularized with the behavioral cloning loss. Such a formulation allows us to tap into existing strong theoretical results from the policy gradient theorem to study the convergence properties of the one-step policy. We verify our theoretical finding with simulation results on a linearized inverted pendulum."}
{"id": "2511.10844", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.10844", "abs": "https://arxiv.org/abs/2511.10844", "authors": ["Anna Franziska Frigge", "Alexander Medvedev"], "title": "Tissue Activation Calculation in Dual-lead Deep Brain Stimulation", "comment": "Submitted to European Control Conference 2026", "summary": "Deep Brain Stimulation (DBS) is a well-established neurosurgical treatment aiming at symptom alleviation in a range of neurological and psychiatric diseases. Computational models of DBS are widely used to investigate the effects of stimulation on neural tissue, to explore stimulation targets and sweetspots, and ultimately, to aid clinicians in the DBS programming by calculating the stimulation parameters. Commonly, DBS is performed bilaterally, i.e. with one lead in each brain hemisphere, where computational models are solved independently for one lead at a time. This paper treats scenarios where multiple DBS leads are implanted in close proximity to one another, resulting in interacting electrical fields and, therefore, potentially overlapping stimulation spreads. In particular, a global dual-lead model is compared to approximations derived from single-lead approaches in a cohort of twelve multiple sclerosis (MS) tremor patients. It is concluded that simple superposition of volumes of tissue activated (VTAs) underestimates activation, while superposition of electric fields or activating functions leads to overestimation. It is concluded that given close proximity of DBS leads, the VTA cannot be computed individually as stimulation fields exhibit significant and complex interaction. The approach is extended to modeling two obsessive compulsive disorder patients with medially placed leads, where similar VTA discrepancies as in the MS patient cohort are observed."}
{"id": "2511.11086", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2511.11086", "abs": "https://arxiv.org/abs/2511.11086", "authors": ["Alexander Kagan", "Peter W. MacDonald", "Elizaveta Levina", "Ji Zhu"], "title": "Latent space models for grouped multiplex networks", "comment": "44 pages, 9 figures", "summary": "Complex multilayer network datasets have become ubiquitous in various applications, including neuroscience, social sciences, economics, and genetics. Notable examples include brain connectivity networks collected across multiple patients or trade networks between countries collected across multiple goods. Existing statistical approaches to such data typically focus on modeling the structure shared by all networks; some go further by accounting for individual, layer-specific variation. However, real-world multilayer networks often exhibit additional patterns shared only within certain subsets of layers, which can represent treatment and control groups, or patients grouped by a specific trait. Identifying these group-level structures can uncover systematic differences between groups of networks and influence many downstream tasks, such as testing and low-dimensional visualization. To address this gap, we introduce the GroupMultiNeSS model, which enables the simultaneous extraction of shared, group-specific, and individual latent structures from a sample of networks on a shared node set. For this model, we establish identifiability, develop a fitting procedure using convex optimization in combination with a nuclear norm penalty, and prove a guarantee of recovery for the latent positions as long as there is sufficient separation between the shared, group-specific, and individual latent subspaces. We compare the model with MultiNeSS and other models for multiplex networks in various synthetic scenarios and observe an apparent improvement in the modeling accuracy when the group component is accounted for. Experiment with the Parkinson's disease brain connectivity dataset demonstrates the superiority of GroupMultiNeSS in highlighting node-level insights on biological differences between the treatment and control patient groups."}
{"id": "2511.11067", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.11067", "abs": "https://arxiv.org/abs/2511.11067", "authors": ["Axel Bücher", "Johan Segers", "Torben Staud"], "title": "Consistency of M-estimators for non-identically distributed data: the case of fixed-design distributional regression", "comment": "31 pages", "summary": "This paper explores strong and weak consistency of M-estimators for non-identically distributed data, extending prior work. Emphasis is given to scenarios where data is viewed as a triangular array, which encompasses distributional regression models with non-random covariates. Primitive conditions are established for specific applications, such as estimation based on minimizing empirical proper scoring rules or conditional maximum likelihood. A key motivation is addressing challenges in extreme value statistics, where parameter-dependent supports can cause criterion functions to attain the value $-\\infty$, hindering the application of existing theorems."}
{"id": "2511.11082", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.11082", "abs": "https://arxiv.org/abs/2511.11082", "authors": ["Francisco de la Hoz", "Peru Muniain"], "title": "Numerical approximation of Caputo-type advection-diffusion equations in one and multiple spatial dimensions via shifted Chebyshev polynomials", "comment": "23 pages, 3 figures", "summary": "In this paper, using a pseudospectral approach, we develop operational matrices based on the shifted Chebyshev polynomials to approximate numerically Caputo fractional derivatives and Riemann-Liouville fractional integrals. In order to make the generation of these matrices stable, we use variable precision arithmetic. Then, we apply the Caputo differentiation matrices to solve numerically Caputo-type advection-diffusion equations in one and multiple spatial dimensions, which involves transforming the discretization of the concerning equation into a Sylvester (tensor) equation. We provide complete Matlab codes, whose implementation is carefully explained. The numerical experiments involving highly oscillatory functions in time confirm the effectiveness of this approach."}
{"id": "2511.11191", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.11191", "abs": "https://arxiv.org/abs/2511.11191", "authors": ["Hélène Arvis", "Olivier Beaude", "Nicolas Gast", "Stéphane Gaubert", "Bruno Gaujal"], "title": "Integrating Aggregated Electric Vehicle Flexibilities in Unit Commitment Models using Submodular Optimization", "comment": "8 pages, 3 figures", "summary": "The Unit Commitment (UC) problem consists in controlling a large fleet of heterogeneous electricity production units in order to minimize the total production cost while satisfying consumer demand. Electric Vehicles (EVs) are used as a source of flexibility and are often aggregated for problem tractability. We develop a new approach to integrate EV flexibilities in the UC problem and exploit the generalized polymatroid structure of aggregated flexibilities of a large population of users to develop an exact optimization algorithm, combining a cutting-plane approach and submodular optimization. We show in particular that the UC can be solved exactly in a time which scales linearly, up to a logarithmic factor, in the number of EV users when each production unit is subject to convex constraints. We illustrate our approach by solving a real instance of a long-term UC problem, combining open-source data of the European grid (European Resource Adequacy Assessment project) and data originating from a survey of user behavior of the French EV fleet."}
{"id": "2511.11296", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.11296", "abs": "https://arxiv.org/abs/2511.11296", "authors": ["Shahriar Hasnat Kazi", "Niall Adams", "Edward A. K. Cohen"], "title": "Online Spectral Density Estimation", "comment": null, "summary": "This paper develops the first online algorithms for estimating the spectral density function -- a fundamental object of interest in time series analysis -- that satisfies the three core requirements of streaming inference: fixed memory, fixed computational complexity, and temporal adaptivity. Our method builds on the concept of forgetting factors, allowing the estimator to adapt to gradual or abrupt changes in the data-generating process without prior knowledge of its dynamics. We introduce a novel online forgetting-factor periodogram and show that, under stationarity, it asymptotically recovers the properties of its offline counterpart. Leveraging this, we construct an online Whittle estimator, and further develop an adaptive online spectral estimator that dynamically tunes its forgetting factor using the Whittle likelihood as a loss. Through extensive simulation studies and an application to ocean drifter velocity data, we demonstrate the method's ability to track time-varying spectral properties in real-time with strong empirical performance."}
{"id": "2511.11180", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11180", "abs": "https://arxiv.org/abs/2511.11180", "authors": ["Farideh Abdollahi", "Kourosh Malek", "Thomas Kadyk", "Nadiia Kulyk", "Christophe Gerling", "Michael H. Eikerling"], "title": "Prognostics and Health Management in Polymer Electrolyte Fuel Cells: Current Trends, Challenges, and Future Directions", "comment": "Review article", "summary": "Prognostics and Health Management is crucial for the reliability and lifetime assessment of Polymer Electrolyte Fuel Cells (PEFCs). Here, we review the current advances on this topic, focusing mainly on key degradation mechanisms and methodologies such as physics-aware, data-driven, and hybrid modeling approaches. Key open challenges are analyzed, including the need for more accurate degradation modeling, effective management of multi-stack systems, and advancements in the currently underdeveloped action phase, in which diagnostic and prognostic insights are translated into real-time system responses, such as dynamic load derating, thermal-management adjustments, or automated maintenance triggers, to prevent failures and extend PEFC life. While notable strides have been made in recent years in diagnostics and remaining useful life estimation, it remains challenging to seamlessly integrate these insights into actionable strategies. Future directions highlight the need to address data scarcity and advance interdisciplinary research. Key focus areas include sensor integration, artificial intelligence, and digital twins. Additionally material innovations play a crucial role in bridging existing gaps. This work, therefore, intends to map the further development of Prognostics and Health Management systems toward ensuring the viability of PEFCs in practical applications."}
{"id": "2511.10852", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10852", "abs": "https://arxiv.org/abs/2511.10852", "authors": ["Yi-Ping Chen", "Derick Suarez", "Ying-Kuan Tsai", "Vispi Karkaria", "Guanzhong Hu", "Zihan Chen", "Ping Guo", "Jian Cao", "Wei Chen"], "title": "Adaptive Digital Twin of Sheet Metal Forming via Proper Orthogonal Decomposition-Based Koopman Operator with Model Predictive Control", "comment": null, "summary": "Digital Twin (DT) technologies are transforming manufacturing by enabling real-time prediction, monitoring, and control of complex processes. Yet, applying DT to deformation-based metal forming remains challenging because of the strongly coupled spatial-temporal behavior and the nonlinear relationship between toolpath and material response. For instance, sheet-metal forming by the English wheel, a highly flexible but artisan-dependent process, still lacks digital counterparts that can autonomously plan and adapt forming strategies. This study presents an adaptive DT framework that integrates Proper Orthogonal Decomposition (POD) for physics-aware dimensionality reduction with a Koopman operator for representing nonlinear system in a linear lifted space for the real-time decision-making via model predictive control (MPC). To accommodate evolving process conditions or material states, an online Recursive Least Squares (RLS) algorithm is introduced to update the operator coefficients in real time, enabling continuous adaptation of the DT model as new deformation data become available. The proposed framework is experimentally demonstrated on a robotic English Wheel sheet metal forming system, where deformation fields are measured and modeled under varying toolpaths. Results show that the adaptive DT is capable of controlling the forming process to achieve the given target shape by effectively capturing non-stationary process behaviors. Beyond this case study, the proposed framework establishes a generalizable approach for interpretable, adaptive, and computationally-efficient DT of nonlinear manufacturing systems, bridging reduced-order physics representations with data-driven adaptability to support autonomous process control and optimization."}
{"id": "2511.11517", "categories": ["math.OC", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.11517", "abs": "https://arxiv.org/abs/2511.11517", "authors": ["Jitian Liu", "Nicolas Kozachuk", "Subhrajit Bhattacharya"], "title": "Distributed Optimization of Pairwise Polynomial Graph Spectral Functions via Subgraph Optimization", "comment": "22 pages, 8 figures", "summary": "We study distributed optimization of finite-degree polynomial Laplacian spectral objectives under fixed topology and a global weight budget, targeting the collective behavior of the entire spectrum rather than a few extremal eigenvalues. By re-formulating the global cost in a bilinear form, we derive local subgraph problems whose gradients approximately align with the global descent direction via an SVD-based test on the $ZC$ matrix. This leads to an iterate-and-embed scheme over disjoint 1-hop neighborhoods that preserves feasibility by construction (positivity and budget) and scales to large geometric graphs. For objectives that depend on pairwise eigenvalue differences $h(λ_i-λ_j)$, we obtain a quadratic upper bound in the degree vector, which motivates a ``warm-start'' by degree-regularization. The warm start uses randomized gossip to estimate global average degree, accelerating subsequent local descent while maintaining decentralization, and realizing $\\sim95\\%{}$ of the performance with respect to centralized optimization. We further introduce a learning-based proposer that predicts one-shot edge updates on maximal 1-hop embeddings, yielding immediate objective reductions. Together, these components form a practical, modular pipeline for spectrum-aware weight tuning that preserves constraints and applies across a broader class of whole-spectrum costs."}
{"id": "2511.11068", "categories": ["math.ST", "math.AP"], "pdf": "https://arxiv.org/pdf/2511.11068", "abs": "https://arxiv.org/abs/2511.11068", "authors": ["Pu-Zhao Kow", "Janne Nurminen", "Jesse Railo"], "title": "Bayesian inference for the fractional Calderón problem with a single measurement", "comment": "22 pages, 2 figures", "summary": "This paper investigates the consistency of a posterior distribution in the single-measurement fractional Calderón problem with additive Gaussian noise. We consider a Bayesian framework with rescaled and Gaussian sieve priors, using a collection of noisy, discrete observations taken from a suitable exterior domain. Our main result shows that the posterior distribution concentrates around the true parameter as the number of measurements increases. Furthermore, we establish tight convergence rates for the reconstruction error of the posterior mean. A central technical challenge is to obtain refined stability estimates for both the forward and inverse problems. In particular, the required forward estimates are delicate to obtain because the fractional elliptic problems do not enjoy as strong regularity theory as their classical counterparts."}
{"id": "2511.11103", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2511.11103", "abs": "https://arxiv.org/abs/2511.11103", "authors": ["Maryna Kachanovska", "Adrian Savchuk"], "title": "Asymptotic models for time-domain scattering by small particles of arbitrary shapes", "comment": null, "summary": "In this work, we investigate time-dependent wave scattering by multiple small particles of arbitrary shape. To approximate the solution of the associated boundary-value problem, we derive an asymptotic model that is valid in the limit as the particle size tends to zero. Our method relies on a boundary integral formulation, semi-discretized in space using a Galerkin approach with appropriately chosen basis functions, s.t. convergence is achieved as the particle size vanishes rather than by increasing the number of basis functions. Since the computation of the Galerkin matrix involves double integration over particles, the method can become computationally demanding when the number of obstacles is large. To address this, we also derive a simplified model and consider the Born approximation to improve computational efficiency. For the high-order models, we provide an error analysis, supported and validated by numerical experiments."}
{"id": "2511.11215", "categories": ["math.OC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.11215", "abs": "https://arxiv.org/abs/2511.11215", "authors": ["Toshiaki Yamanaka"], "title": "TSP integrality gap via 2-edge-connected multisubgraph problem under coincident IP optima", "comment": null, "summary": "Determining the integrality gap of the linear programming (LP) relaxation of the metric traveling salesman problem (TSP) remains a long-standing open problem. We introduce a transfer principle: when the integer optimum of the 2-edge-connected multisubgraph problem (2ECM) is a unique Hamiltonian cycle $T$, any $α$-approximation algorithm for 2ECM that outputs a Hamiltonian cycle yields an $α$-approximation for TSP. We further develop a cut-margin uniqueness framework that certifies $T$ as the unique integer optimum for both problems and is stable under $\\ell_\\infty$-bounded perturbations. We show that, if instances exist where the 2ECM has both a unique Hamiltonian cycle integer optimum and a half-integral LP solution, then the TSP integrality gap is at most 4/3 by the algorithm of Boyd et al. (SIAM Journal on Discrete Mathematics 36:1730--1747, 2022). Constructing such instances remains an open problem."}
{"id": "2511.11338", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.11338", "abs": "https://arxiv.org/abs/2511.11338", "authors": ["Stéphane Girard", "Cambyse Pakzad"], "title": "Extreme-PLS with missing data under weak dependence", "comment": "45 pages, 14 figures", "summary": "This paper develops a theoretical framework for Extreme Partial Least Squares (EPLS) dimension reduction in the presence of missing data and weak temporal dependence. Building upon the recent EPLS methodology for modeling extremal dependence between a response variable and high-dimensional covariates, we extend the approach to more realistic data settings where both serial correlation and missing-ness occur. Specifically, we consider a single-index inverse regression model under heavy-tailed conditions and introduce a Missing-at-Random (MAR) mechanism acting on the covariates, whose probability depends on the extremeness of the response. The asymptotic behavior of the proposed estimator is established within an alpha-mixing framework, leading to consistency results under regularly varying tails. Extensive Monte-Carlo experiments covering eleven dependence schemes (including ARMA, GARCH, and nonlinear ESTAR processes) demonstrate that the method performs robustly across a wide range of heavy-tailed and dependent scenarios, even when substantial portions of data are missing. A real-world application to environmental data further confirms the method's capacity to recover meaningful tail directions."}
{"id": "2511.11183", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11183", "abs": "https://arxiv.org/abs/2511.11183", "authors": ["Ashutosh Jindal", "Florentina Nicolau", "David Martin Diego", "Ravi Banavar"], "title": "Numerical Discretization Schemes that Preserve Flatness", "comment": "7 pages, 5 figures", "summary": "Differential flatness serves as a powerful tool for controlling continuous time nonlinear systems in problems such as motion planning and trajectory tracking. A similar notion, called difference flatness, exists for discrete-time systems. Although many control systems evolve in continuous time, control implementation is performed digitally, requiring discretization. It is well known in the literature that discretization does not necessarily preserve structural properties, and it has been established that, in general, flatness is not preserved under discretization (whether exact or approximate). In this paper, inspired by our previous work [1] and based on the notion of discretization maps, we construct numerical schemes that preserve flatness."}
{"id": "2511.11026", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.11026", "abs": "https://arxiv.org/abs/2511.11026", "authors": ["Adel Bechihi", "Aristotelis Kapnopoulos"], "title": "Region of Attraction Estimate Learning and Verification for Nonlinear Systems using Neural-Network-based Lyapunov Functions", "comment": null, "summary": "Estimating the Region of Attraction (RoA) for nonlinear dynamical systems is a fundamental problem in control theory, with direct implications for stability analysis and safe controller design. Traditional approaches rely on analytically derived Lyapunov functions, which are often conservative and challenging to construct for high-dimensional or highly nonlinear systems. In this work, we propose a data-driven framework for learning and verifying RoA estimates for nonlinear systems using neural-network-based Lyapunov functions. Our method employs a composite Lyapunov function that combines a quadratic term with a neural-network-based component, providing both structure and flexibility. We introduce a novel homogeneous loss function for training, which removes the imbalance typically caused by the two non-homogeneous Lyapunov conditions. Together, these two aspects enable efficient training of the Lyapunov candidate. To guarantee the correctness of the learned Lyapunov function, we employ a Satisfiability Modulo Theories (SMT) solver to formally verify the stability results. Lastly, we perform a deeper analysis near the origin to overcome numerical artifacts, ensuring strict asymptotic stability. We demonstrate the effectiveness of our approach on benchmark nonlinear systems, showing that it significantly reduces conservatism compared to traditional Lyapunov methods while maintaining verifiability. This framework bridges the gap between function approximation and stability certification, paving the way for scalable safety analysis in learning-based control and safety-critical applications."}
{"id": "2511.11351", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2511.11351", "abs": "https://arxiv.org/abs/2511.11351", "authors": ["Jason Beh", "Jerome Morio", "Florian Simatos"], "title": "Phase transition for conditional covariance matrices estimated by importance sampling, and implications for cross-entropy schemes in high dimension", "comment": null, "summary": "Motivated by the estimation of covariance matrices by importance sampling arising in the cross-entropy (CE) algorithm, we study a random matrix model $\\hat Σ= {\\bf X} L {\\bf X}^\\top$ with two distinct features: $\\bf X$ and $L$ are dependent, and $L$ is heavy-tailed. In the high-dimensional regime $d \\to \\infty$, we prove under suitable assumptions that a phase transition occurs in the polynomial regime $n = d^κ$, with $n$ the sample size. Namely, we prove that $\\lVert \\hat Σ- E \\hat Σ\\rVert \\Rightarrow 0$ if and only if $κ> κ_*$ for some threshold $κ_*$ determined by the behavior of the maximum likelihood ratios. Moreover, we identify general situations where $κ_* = 1/λ_1$, with $λ_1$ the smallest eigenvalue of the covariance matrix of the auxiliary distribution used to estimate $\\hat Σ$ by importance sampling. This suggests that importance sampling will work better with covariance matrices having a large smallest eigenvalue. We carry this insight into recent CE schemes proposed to estimate the probability of high-dimensional rare events. Through numerical simulations, we demonstrate that better CE schemes are also the ones with larger smallest eigenvalue, even though these algorithms were not designed to smooth the spectrum. This new spectral interpretation raises stimulating questions and opens research directions for the design of efficient high-dimensional algorithms."}
{"id": "2511.11135", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.11135", "abs": "https://arxiv.org/abs/2511.11135", "authors": ["Hussam Al Daas", "Nicholas I. M. Gould"], "title": "Extended-Krylov-subspace methods for trust-region and norm-regularization subproblems", "comment": null, "summary": "We consider an effective new method for solving trust-region and norm-regularization problems that arise as subproblems in many optimization applications. We show that the solutions to such subproblems lie on a manifold of approximately very low rank as a function of their controlling parameters (trust-region radius or regularization weight). Based on this, we build a basis for this manifold using an efficient extended-Krylov-subspace iteration that involves a single matrix factorization. The problems within the subspace using such a basis may be solved at very low cost using effective high-order root-finding methods. This then provides an alternative to common methods using multiple factorizations or standard Krylov subspaces. We provide numerical results to illustrate the effectiveness of our {\\tt TREK}/{\\tt NREK} approach."}
{"id": "2511.11350", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.11350", "abs": "https://arxiv.org/abs/2511.11350", "authors": ["Karl Kunisch", "Jesper Schröder"], "title": "Risk averse deterministic Kalman filters for uncertain dynamical systems", "comment": null, "summary": "Taking a deterministic viewpoint this work investigates extensions of the Kalman-Bucy filter for state reconstruction to systems containing parametric uncertainty in the state operator. The emphasis lies on risk averse designs reducing the probability of large reconstruction errors. In a theoretical analysis error bounds in terms of the variance of the uncertainties are derived. The article concludes with a numerical implementation of two examples allowing for a comparison of risk neutral and risk averse estimators."}
{"id": "2511.11353", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.11353", "abs": "https://arxiv.org/abs/2511.11353", "authors": ["Johan de Aguas"], "title": "Interpolated stochastic interventions based on propensity scores, target policies and treatment-specific costs", "comment": null, "summary": "We introduce families of stochastic interventions for discrete treatments that connect causal modeling to cost-sensitive decision making. The interventions arise from a cost-penalized information projection of the independent product of the organic propensity and a user-specified target, yielding closed-form Boltzmann-Gibbs couplings. The induced marginals define modified stochastic policies that interpolate smoothly, via a single tilt parameter, from the organic law or from the target distribution toward a product-of-experts limit when all destination costs are strictly positive. One of these families recovers and extends incremental propensity score interventions, retaining identification without global positivity. For inference, we derive efficient influence functions under a nonparametric model for the expected outcomes after these policies and construct one-step estimators with uniform confidence bands. In simulations, the proposed estimators improve stability and robustness to nuisance misspecification relative to plug-in baselines. The framework can operationalize graded scientific hypotheses under realistic constraints: because inputs are modular, analysts can sweep feasible policy spaces, prototype candidates, and align interventions with budgets and logistics before committing experimental resources. This could help close the loop between observational evidence and resource-aware experimental design."}
{"id": "2511.11285", "categories": ["eess.SY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11285", "abs": "https://arxiv.org/abs/2511.11285", "authors": ["Yuki Miyoshi", "Masaki Inoue", "Yusuke Fujimoto"], "title": "Language-Aided State Estimation", "comment": "7 pages, 5 figures, submitted to IFAC World Congress 2026 with Journal option (IFAC Journal of Systems and Control)", "summary": "Natural language data, such as text and speech, have become readily available through social networking services and chat platforms. By leveraging human observations expressed in natural language, this paper addresses the problem of state estimation for physical systems, in which humans act as sensing agents. To this end, we propose a Language-Aided Particle Filter (LAPF), a particle filter framework that structures human observations via natural language processing and incorporates them into the update step of the state estimation. Finally, the LAPF is applied to the water level estimation problem in an irrigation canal and its effectiveness is demonstrated."}
{"id": "2511.11131", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11131", "abs": "https://arxiv.org/abs/2511.11131", "authors": ["Farnaz Adib Yaghmaie", "Arunava Naha"], "title": "Convergence of Flow-Policy Gradient Learning for Linear Quadratic Regulator Problems", "comment": "Submitted to L4DC", "summary": "Flow $Q$-learning has recently been introduced to integrate learning from expert demonstrations into an actor-critic structure. Central to this innovation is the ``the one-step policy'' network, which is optimized through a $Q$-function that is regularized with the behavioral cloning from expert trajectories, allowing learning more expressive policies using flow-based generative models. In this paper, we studied the convergence property and stabilizablity of the one-step policy during learning for linear quadratic problems under the offline settings. Our theoretical results are based on a new formulation of the one-step policy loss based on the average expected cost, and regularized with the behavioral cloning loss. Such a formulation allows us to tap into existing strong theoretical results from the policy gradient theorem to study the convergence properties of the one-step policy. We verify our theoretical finding with simulation results on a linearized inverted pendulum."}
{"id": "2511.11530", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.11530", "abs": "https://arxiv.org/abs/2511.11530", "authors": ["Marta Pérez-Casany", "Ariel Duarte-López", "Jordi Valero"], "title": "Exploring the Zipf Distribution Through the Lens of Mixtures", "comment": "14 pages, 3 tables, 4 figures", "summary": "The Zipf distribution is a probability distribution widely used by scientists from various disciplines due to its ubiquity. Some of these areas include linguistics, physics, genetics, and sociology, among others. In this paper, it is proved that the Zipf distribution is both a mixture of geometric distributions and a mixture of zero-truncated Poisson distributions. It is also shown that it is not the zero-truncation of a mixed Poisson distribution. These results are important because they provide insights on the data generation mechanism that leads to data from a Zipf distribution. Additionally, it is proved, as a corollary, that the Zipf-Poisson Stopped Sum distribution is a particular case of a mixed Poisson distribution. The results are illustrated analyzing the 135 chapters of the novel Moby Dick."}
{"id": "2511.11137", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11137", "abs": "https://arxiv.org/abs/2511.11137", "authors": ["Samuel Auroy", "Pavlos Protopapas"], "title": "One-Shot Transfer Learning for Nonlinear PDEs with Perturbative PINNs", "comment": "Accepted at Machine Learning and the Physical Sciences Workshop, NeurIPS 2025", "summary": "We propose a framework for solving nonlinear partial differential equations (PDEs) by combining perturbation theory with one-shot transfer learning in Physics-Informed Neural Networks (PINNs). Nonlinear PDEs with polynomial terms are decomposed into a sequence of linear subproblems, which are efficiently solved using a Multi-Head PINN. Once the latent representation of the linear operator is learned, solutions to new PDE instances with varying perturbations, forcing terms, or boundary/initial conditions can be obtained in closed form without retraining.\n  We validate the method on KPP-Fisher and wave equations, achieving errors on the order of 1e-3 while adapting to new problem instances in under 0.2 seconds; comparable accuracy to classical solvers but with faster transfer. Sensitivity analyses show predictable error growth with epsilon and polynomial degree, clarifying the method's effective regime.\n  Our contributions are: (i) extending one-shot transfer learning from nonlinear ODEs to PDEs, (ii) deriving a closed-form solution for adapting to new PDE instances, and (iii) demonstrating accuracy and efficiency on canonical nonlinear PDEs. We conclude by outlining extensions to derivative-dependent nonlinearities and higher-dimensional PDEs."}
{"id": "2511.11359", "categories": ["math.OC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2511.11359", "abs": "https://arxiv.org/abs/2511.11359", "authors": ["Matthew X. Burns", "Jiaming Liang"], "title": "Linear-Space Extragradient Methods for Fast, Large-Scale Optimal Transport", "comment": "45 pages, 6 figures", "summary": "Optimal transport (OT) and its entropy-regularized form (EOT) have become increasingly prominent computational problems, with applications in machine learning and statistics. Recent years have seen a commensurate surge in first-order methods aiming to improve the complexity of large-scale (E)OT. However, there has been a consistent tradeoff: attaining state-of-the-art rates requires $\\mathcal{O}(n^2)$ storage to enable ergodic primal averaging. In this work, we demonstrate that recently proposed primal-dual extragradient methods (PDXG) can be implemented entirely in the dual with $\\mathcal{O}(n)$ storage. Additionally, we prove that regularizing the reformulated OT problem is equivalent to EOT with extensions to entropy-regularized barycenter problems, further widening the applications of the proposed method. The proposed dual-only extragradient method (DXG) is the first algorithm to achieve $\\mathcal{O}(n^2\\varepsilon^{-1})$ complexity for $\\varepsilon$-approximate OT with $\\mathcal{O}(n)$ memory. Numerical experiments demonstrate that the dual extragradient method scales favorably in non/weakly-regularized regimes compared to existing algorithms, though future work is needed to improve performance in certain problem classes."}
{"id": "2511.11355", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.11355", "abs": "https://arxiv.org/abs/2511.11355", "authors": ["Ryan Cecil", "Lucas Mentch"], "title": "Model Class Selection", "comment": null, "summary": "Classical model selection seeks to find a single model within a particular class that optimizes some pre-specified criteria, such as maximizing a likelihood or minimizing a risk. More recently, there has been an increased interest in model set selection (MSS), where the aim is to identify a (confidence) set of near-optimal models. Here, we generalize the MSS framework further by introducing the idea of model class selection (MCS). In MCS, multiple model collections are evaluated, and all collections that contain at least one optimal model are sought for identification. Under mild conditions, data splitting based approaches are shown to provide general solutions for MCS. As a direct consequence, for particular datasets we are able to investigate formally whether classes of simpler and more interpretable statistical models are able to perform on par with more complex black-box machine learning models. A variety of simulated and real-data experiments are provided."}
{"id": "2511.11304", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11304", "abs": "https://arxiv.org/abs/2511.11304", "authors": ["Katayoun Eshkofti", "Henrik Sandberg", "Mikael Nilsson", "Matthieu Barreau"], "title": "Modeling and Physics-Enhanced Fault Detection in Wastewater Pump Stations", "comment": null, "summary": "Monitoring wastewater pump stations is essential because they are critical infrastructure. However, monitoring is still often performed manually due to the lack of suitable algorithmic methods and data. This paper introduces a high-fidelity, physics-enhanced simulator of a three-pump wastewater station that captures transient hydro-mechanical dynamics at a one-second resolution. The simulator is fully parameter-driven, adaptable to other wastewater stations, and capable of generating datasets for data-driven analytics. It can also generate balanced faulty datasets when real failures are scarce or confidential. A comparison with high-frequency SCADA data from a municipal station shows strong agreement across key operational metrics. Furthermore, the paper proposes robust statistical and mathematical frameworks for fault detection and isolation, including a nested-model F-test to detect pump degradation or system faults, and a tangent residual approach to distinguish pump faults from system faults using operating-point kinematics. This framework enables what-if studies, facilitates early fault diagnosis based on flow rate and head, and provides actionable insights for condition-based maintenance in wastewater pumping infrastructure."}
{"id": "2511.11180", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11180", "abs": "https://arxiv.org/abs/2511.11180", "authors": ["Farideh Abdollahi", "Kourosh Malek", "Thomas Kadyk", "Nadiia Kulyk", "Christophe Gerling", "Michael H. Eikerling"], "title": "Prognostics and Health Management in Polymer Electrolyte Fuel Cells: Current Trends, Challenges, and Future Directions", "comment": "Review article", "summary": "Prognostics and Health Management is crucial for the reliability and lifetime assessment of Polymer Electrolyte Fuel Cells (PEFCs). Here, we review the current advances on this topic, focusing mainly on key degradation mechanisms and methodologies such as physics-aware, data-driven, and hybrid modeling approaches. Key open challenges are analyzed, including the need for more accurate degradation modeling, effective management of multi-stack systems, and advancements in the currently underdeveloped action phase, in which diagnostic and prognostic insights are translated into real-time system responses, such as dynamic load derating, thermal-management adjustments, or automated maintenance triggers, to prevent failures and extend PEFC life. While notable strides have been made in recent years in diagnostics and remaining useful life estimation, it remains challenging to seamlessly integrate these insights into actionable strategies. Future directions highlight the need to address data scarcity and advance interdisciplinary research. Key focus areas include sensor integration, artificial intelligence, and digital twins. Additionally material innovations play a crucial role in bridging existing gaps. This work, therefore, intends to map the further development of Prognostics and Health Management systems toward ensuring the viability of PEFCs in practical applications."}
{"id": "2511.11566", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2511.11566", "abs": "https://arxiv.org/abs/2511.11566", "authors": ["Robert J. Petrella"], "title": "The Maximal Variance of Unilaterally Truncated Gaussian and Chi Distributions", "comment": "51 pages, 17 figures", "summary": "This work explores the bounds of the variance of unilaterally truncated Gaussian distributions (UTGDs) and scaled chi distributions (UTSCDs) with fixed means. For any arbitrary Gaussian distribution function, $f(x;μ,σ)$, with a fixed, finite mean $M$ on the truncated domain $x \\ge a$, where $a \\in \\mathbb{R}$, it is proven that the variance is bounded: specifically, $\\sup \\mathrm{Var}(x)_{|x \\ge a}= \\sup \\mathrm{Var}(x)_{|x \\le a} =(M-a)^2$. For a fixed cutoff, $a$, the variance can be considered a function of only $M$, $a$, and the location parameter $μ$. Examples of such approximating functions, which can be used for model calibration, are developed in addition to other, related calibration methods. For UTSCDs, numerical evidence is presented indicating that for $n \\in \\mathbb{Z+}$ degrees of freedom, or dimensions, and a fixed, finite mean, the variance, $\\mathrm{Var}(R)$, over $R \\in [a,\\infty)$ reaches its maximum value $M^2(π-2)/2$ at $a=0$, $n=1$. For a fixed cutoff value, there is a local maximum in the variance as a function of $n$, and the number of dimensions resulting in the maximal variance, $n_{\\mathrm{vmx}}$, increases with cutoff value. However, for $n \\in \\mathbb{R}$, as the cutoff approaches $0$, $n_{\\mathrm{vmx}}$ approaches $-1$, while $\\mathrm{Var}(R)$ appears to grow without bound."}
{"id": "2511.11194", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.11194", "abs": "https://arxiv.org/abs/2511.11194", "authors": ["Antoniorenee Barletta", "Salvatore Cuomo", "Nadaniela Egidi", "Josephin Giacomini", "Pierluigi Maponi"], "title": "Inverse modeling of porous flow through deep neural networks: the case of coffee percolation", "comment": null, "summary": "This work addresses the inverse problem of espresso coffee extraction, in which one aims to reconstruct the brewing conditions that generate a desired chemical profile in the final beverage. Starting from a high-fidelity multiphysics percolation model, describing fluid flow, solute transport, solid, liquid reactions, and heat exchange within the coffee bed, we derive a reduced forward operator mapping controllable brewing parameters to the concentrations of the main chemical species in the cup. From a mathematical standpoint, we formalize the structural requirements for the local solvability of inverse problems, providing a minimal analytical condition for the existence of a (local) inverse map: continuous differentiability of the forward operator and a locally constant, nondegenerate Jacobian rank. Under these assumptions, the Constant Rank Theorem ensures that the image of the forward operator is a smooth embedded manifold on which well-defined local right-inverses exist.\n  Extensive experiments, including off-grid validation, show that the learned inverse map accurately reconstructs brewing temperature, grind size, and powder composition. The resulting framework combines rigorous analytical guarantees with modern data-driven methods, providing a principled and computationally efficient solution to the inverse extraction problem and enabling personalised brewing, recipe optimisation, and integration into smart coffee-machine systems."}
{"id": "2511.11383", "categories": ["math.OC", "q-fin.MF", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2511.11383", "abs": "https://arxiv.org/abs/2511.11383", "authors": ["Tim J. Boonen", "Engel John C. Dela Vega"], "title": "Optimal Dividend, Reinsurance and Capital Injection Strategies for Collaborating Business Lines: The Case of Excess-of-Loss Reinsurance", "comment": "31 pages, 12 figures", "summary": "This paper considers an insurer with two collaborating business lines that must make three critical decisions: (1) dividend payout, (2) a combination of proportional and excess-of-loss reinsurance coverage, and (3) capital injection between the lines. The reserve level of each line is modeled using a diffusion approximation, with the insurer's objective being to maximize the weighted total discounted dividends paid until the first ruin time. We obtain the value function and the optimal strategies in closed form. We then prove that the optimal dividend payout strategy for bounded dividend rates is of threshold type, while for unbounded dividend rates it is of barrier type. The optimal combination of proportional and excess-of-loss reinsurance is shown to be pure excess-of-loss reinsurance. We also show that the optimal level of risk ceded to the reinsurer decreases as the aggregate reserve level increases. The optimal capital injection strategy involves transferring reserves to prevent the ruin of one line. Finally, numerical examples are presented to illustrate these optimal strategies."}
{"id": "2511.11433", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.11433", "abs": "https://arxiv.org/abs/2511.11433", "authors": ["Giulio Grossi", "Leo Vanciu", "Veronica Ballerini", "Danielle Braun", "Falco J. Bargagli Stoffi"], "title": "Estimating the Effects of Heatwaves on Health: A Causal Inference Framework", "comment": null, "summary": "The harmful relationship between heatwaves and health has been extensively documented in medical and epidemiological literature. However, most evidence is associational and cannot be interpreted causally unless strong assumptions are made. In this paper, we first make explicit the assumptions underlying the statistical methods frequently used in the heatwave literature and demonstrate when these assumptions might break down in heatwave contexts. To address these shortcomings, we propose a causal inference framework that transparently elicits causal identification assumptions. Within this new framework, we first introduce synthetic controls (SC) for estimating heatwave effects, then propose a spatially augmented Bayesian synthetic control (SA-SC) method that accounts for spatial dependence and spillovers. Empirical Monte Carlo simulations show both methods perform well, with SA-SC reducing root mean squared error and improving posterior interval coverage under spillovers and spatial dependence. Finally, we apply the proposed methods to estimate the causal effects of heatwaves on Medicare heat-related hospitalizations among 13,753,273 beneficiaries residing in Northeastern U.S. from 2000 to 2019. This causal inference framework provides spatially coherent counterfactual outcomes and robust, interpretable, and transparent causal estimates while explicitly addressing the unexamined assumptions in existing methods that pervade the heatwave effect literature."}
{"id": "2511.11308", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.11308", "abs": "https://arxiv.org/abs/2511.11308", "authors": ["Riccardo Zuliani", "Efe C. Balta", "John Lygeros"], "title": "Policy Optimization for Unknown Systems using Differentiable Model Predictive Control", "comment": null, "summary": "Model-based policy optimization often struggles with inaccurate system dynamics models, leading to suboptimal closed-loop performance. This challenge is especially evident in Model Predictive Control (MPC) policies, which rely on the model for real-time trajectory planning and optimization. We introduce a novel policy optimization framework for MPC-based policies combining differentiable optimization with zeroth-order optimization. Our method combines model-based and model-free gradient estimation approaches, achieving faster transient performance compared to fully data-driven approaches while maintaining convergence guarantees, even under model uncertainty. We demonstrate the effectiveness of the proposed approach on a nonlinear control task involving a 12-dimensional quadcopter model."}
{"id": "2511.11183", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11183", "abs": "https://arxiv.org/abs/2511.11183", "authors": ["Ashutosh Jindal", "Florentina Nicolau", "David Martin Diego", "Ravi Banavar"], "title": "Numerical Discretization Schemes that Preserve Flatness", "comment": "7 pages, 5 figures", "summary": "Differential flatness serves as a powerful tool for controlling continuous time nonlinear systems in problems such as motion planning and trajectory tracking. A similar notion, called difference flatness, exists for discrete-time systems. Although many control systems evolve in continuous time, control implementation is performed digitally, requiring discretization. It is well known in the literature that discretization does not necessarily preserve structural properties, and it has been established that, in general, flatness is not preserved under discretization (whether exact or approximate). In this paper, inspired by our previous work [1] and based on the notion of discretization maps, we construct numerical schemes that preserve flatness."}
{"id": "2511.11338", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2511.11338", "abs": "https://arxiv.org/abs/2511.11338", "authors": ["Stéphane Girard", "Cambyse Pakzad"], "title": "Extreme-PLS with missing data under weak dependence", "comment": "45 pages, 14 figures", "summary": "This paper develops a theoretical framework for Extreme Partial Least Squares (EPLS) dimension reduction in the presence of missing data and weak temporal dependence. Building upon the recent EPLS methodology for modeling extremal dependence between a response variable and high-dimensional covariates, we extend the approach to more realistic data settings where both serial correlation and missing-ness occur. Specifically, we consider a single-index inverse regression model under heavy-tailed conditions and introduce a Missing-at-Random (MAR) mechanism acting on the covariates, whose probability depends on the extremeness of the response. The asymptotic behavior of the proposed estimator is established within an alpha-mixing framework, leading to consistency results under regularly varying tails. Extensive Monte-Carlo experiments covering eleven dependence schemes (including ARMA, GARCH, and nonlinear ESTAR processes) demonstrate that the method performs robustly across a wide range of heavy-tailed and dependent scenarios, even when substantial portions of data are missing. A real-world application to environmental data further confirms the method's capacity to recover meaningful tail directions."}
{"id": "2511.11202", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.11202", "abs": "https://arxiv.org/abs/2511.11202", "authors": ["Nadaniela Egidi", "Lauro Fioretti", "Josephin Giacomini", "Pierluigi Maponi", "Gianluca Pacini"], "title": "The RBF Collocation Method to Design a Digital Twin for Coffee Percolation", "comment": null, "summary": "Espresso coffee extraction is a complex physico-chemical process and can be modeled through a system of coupled partial differential equations. We present a numerical solution based on a meshless Collocation Method using Radial Basis Functions and Kansa's approach, which reveals to be accurate and robust in comparison to a reference numerical solution provided by a well-known simulation software."}
{"id": "2511.11384", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.11384", "abs": "https://arxiv.org/abs/2511.11384", "authors": ["Nguyen Xuan Duy Bao", "Nguyen Mau Nam"], "title": "On Characterizations of Strong Quasiconvexity", "comment": "Keywords: Quasiconvexity, Strong quasiconvexity, Gradient characterizations, Generalized monotonicity", "summary": "We revisit classical gradient characterizations of quasiconvexity and provide corrected proofs that close gaps in earlier arguments. For the differentiable case of $σ$-quasiconvexity, we establish the full equivalence between several first-order conditions, resolving a remaining implication left open in the recent literature. Our approach yields a concise, self-contained proof of a classical characterization originally stated in the 1970s and sharpens the first-order theory for strong quasiconvexity."}
{"id": "2511.11497", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2511.11497", "abs": "https://arxiv.org/abs/2511.11497", "authors": ["Filip Tronarp"], "title": "A Recursive Theory of Variational State Estimation: The Dynamic Programming Approach", "comment": null, "summary": "In this article, variational state estimation is examined from the dynamic programming perspective. This leads to two different value functional recursions depending on whether backward or forward dynamic programming is employed. The result is a theory of variational state estimation that corresponds to the classical theory of Bayesian state estimation. More specifically, in the backward method, the value functional corresponds to a likelihood that is upper bounded by the state likelihood from the Bayesian backward recursion. In the forward method, the value functional corresponds to an unnormalized density that is upper bounded by the unnormalized filtering density. Both methods can be combined to arrive at a variational two-filter formula. Additionally, it is noted that optimal variational filtering is generally of quadratic time-complexity in the sequence length. This motivates the notion of sub-optimal variational filtering, which also lower bounds the evidence but is of linear time-complexity. Another problem is the fact that the value functional recursions are generally intractable. This is briefly discussed and a simple approximation is suggested that retrieves the filter proposed by Courts et al. (2021). The methodology is examined in a jump Gauss--Markov system, where it is observed that the value functional recursions are tractable under a certain factored Markov process approximation. A simulation study demonstrates that the posterior approximation is of adequate quality."}
{"id": "2511.11417", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11417", "abs": "https://arxiv.org/abs/2511.11417", "authors": ["Alessandro Bosso", "Marco Borghesi", "Andrea Iannelli", "Bowen Yi", "Giuseppe Notarstefano"], "title": "Data-Driven Stabilization of Continuous-Time LTI Systems from Noisy Input-Output Data", "comment": null, "summary": "We present an approach to compute stabilizing controllers for continuous-time linear time-invariant systems directly from an input-output trajectory affected by process and measurement noise. The proposed output-feedback design combines (i) an observer of a non-minimal realization of the plant and (ii) a feedback law obtained from a linear matrix inequality (LMI) that depends solely on the available data. Under a suitable interval excitation condition and knowledge of a noise energy bound, the feasibility of the LMI is shown to be necessary and sufficient for stabilizing all non-minimal realizations consistent with the data. We further provide a condition for the feasibility of the LMI related to the signal-to-noise ratio, guidelines to compute the noise energy bound, and numerical simulations that illustrate the effectiveness of the approach."}
{"id": "2511.11285", "categories": ["eess.SY", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.11285", "abs": "https://arxiv.org/abs/2511.11285", "authors": ["Yuki Miyoshi", "Masaki Inoue", "Yusuke Fujimoto"], "title": "Language-Aided State Estimation", "comment": "7 pages, 5 figures, submitted to IFAC World Congress 2026 with Journal option (IFAC Journal of Systems and Control)", "summary": "Natural language data, such as text and speech, have become readily available through social networking services and chat platforms. By leveraging human observations expressed in natural language, this paper addresses the problem of state estimation for physical systems, in which humans act as sensing agents. To this end, we propose a Language-Aided Particle Filter (LAPF), a particle filter framework that structures human observations via natural language processing and incorporates them into the update step of the state estimation. Finally, the LAPF is applied to the water level estimation problem in an irrigation canal and its effectiveness is demonstrated."}
{"id": "2511.11228", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.11228", "abs": "https://arxiv.org/abs/2511.11228", "authors": ["Qiumei Huang", "Xu Wang", "Yu Zhao"], "title": "The modified Physics-Informed Hybrid Parallel Kolmogorov--Arnold and Multilayer Perceptron Architecture with domain decomposition", "comment": null, "summary": "In this work, we propose a modified Hybrid Parallel Kolmogorov--Arnold Network and Multilayer Perceptron Physics-Informed Neural Network to overcome the high-frequency and multiscale challenges inherent in Physics-Informed Neural Networks. This proposed model features a trainable weighting parameter to optimize the convex combination of outputs from the Kolmogorov--Arnold Network and the Multilayer Perceptron, thus maximizing the networks' capabilities to capture different frequency components. Furthermore, we adopt an overlapping domain decomposition technique to decompose complex problems into subproblems, which alleviates the challenge of global optimization. Benchmark results demonstrate that our method reduces training costs and improves computational efficiency compared with manual hyperparameter tuning in solving high-frequency multiscale problems."}
{"id": "2511.11455", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2511.11455", "abs": "https://arxiv.org/abs/2511.11455", "authors": ["María Josefa Cánovas", "Masao Fukushima", "Juan Parra"], "title": "Lispchitz modulus of the argmin mapping in convex quadratic optimization", "comment": "30 pages, no figures", "summary": "This paper was initially motivated by the computation of the Lipschitz modulus of the metric projection on polyhedral convex sets in the Euclidean space when both the reference point and the polyhedron where it is projected are subject to perturbations. The paper tackles the more general problem of computing the Lipschitz modulus of the argmin mapping in the framework of canonically perturbed convex quadratic problems. We point out the fact that a point-based formula (depending only on the nominal data) for such a modulus is provided. In this way, the paper extends to the current quadratic setting some results previously developed in linear programming. As an application, we provide a point-based formula for the Lipschitz modulus of the metric projection on a polyhedral convex set."}
{"id": "2511.11564", "categories": ["stat.ME", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.11564", "abs": "https://arxiv.org/abs/2511.11564", "authors": ["Albert Tan", "Mohsen Bayati", "James Nordlund", "Roman Istomin"], "title": "Estimating Total Effects in Bipartite Experiments with Spillovers and Partial Eligibility", "comment": "21 pages, 6 figures, Appeared as Oral Presentation in 2025 Conference on Digital Experimentation (CODE) at MIT", "summary": "We study randomized experiments in bipartite systems where only a subset of treatment-side units are eligible for assignment while all units continue to interact, generating interference. We formalize eligibility-constrained bipartite experiments and define estimands aligned with full deployment: the Primary Total Treatment Effect (PTTE) on eligible units and the Secondary Total Treatment Effect (STTE) on ineligible units. Under randomization within the eligible set, we give identification conditions and develop interference-aware ensemble estimators that combine exposure mappings, generalized propensity scores, and flexible machine learning. We further introduce a projection that links treatment- and outcome-level estimands; this mapping is exact under a Linear Additive Edges condition and enables estimation on the (typically much smaller) treatment side with deterministic aggregation to outcomes. In simulations with known ground truth across realistic exposure regimes, the proposed estimators recover PTTE and STTE with low bias and variance and reduce the bias that could arise when interference is ignored. Two field experiments illustrate practical relevance: our method corrects the direction of expected interference bias for a pre-specified metric in both studies and reverses the sign and significance of the primary decision metric in one case."}
{"id": "2511.11429", "categories": ["eess.SY", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.11429", "abs": "https://arxiv.org/abs/2511.11429", "authors": ["Lorenzo Ghiro", "Marco Franceschini", "Renato Lo Cigno", "Michele Segata"], "title": "Heterogeneous CACC Coexistence: Simulation, Analysis, and Modeling", "comment": null, "summary": "The design of Cooperative Adaptive Cruise Control (CACC) algorithms for vehicle platooning has been extensively investigated, leading to a wide range of approaches with different requirements and performance. Most existing studies evaluate these algorithms under the assumption of homogeneous platoons, i.e., when all platoon members adopt the same CACC. However, market competition is likely to result in vehicles from different manufacturers implementing distinct CACCs. This raises fundamental questions about whether heterogeneous vehicles can safely cooperate within a platoon and what performance can be achieved. To date, these questions have received little attention, as heterogeneous platoons are difficult to model and analyze. In this work, we introduce the concept of mixed platoons, i.e., platoons made of vehicles running heterogeneous CACCs, and we study their performance through simulation-based experiments. We consider mixtures of three well-established CACCs from the literature. In the first part of the paper, we study a single mixed platoon in isolation to understand the microscopic effects on safety: we evaluate the performance of various CACC-mixtures across speed change and emergency braking scenarios. In the second part, we examine a high-density ring-road scenario to assess macroscopic impacts on safety, comfort, and traffic throughput, especially comparing throughput results with those obtained from vehicles controlled by a standard Adaptive Cruise Control (ACC) or by human drivers. Our findings highlight that some combinations of CACCs can operate robustly and safely, while others exhibit critical limitations in safety, comfort, or efficiency. These results emphasize the need for careful system design and the development of theoretical frameworks for modeling heterogeneous platoons."}
{"id": "2511.11304", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11304", "abs": "https://arxiv.org/abs/2511.11304", "authors": ["Katayoun Eshkofti", "Henrik Sandberg", "Mikael Nilsson", "Matthieu Barreau"], "title": "Modeling and Physics-Enhanced Fault Detection in Wastewater Pump Stations", "comment": null, "summary": "Monitoring wastewater pump stations is essential because they are critical infrastructure. However, monitoring is still often performed manually due to the lack of suitable algorithmic methods and data. This paper introduces a high-fidelity, physics-enhanced simulator of a three-pump wastewater station that captures transient hydro-mechanical dynamics at a one-second resolution. The simulator is fully parameter-driven, adaptable to other wastewater stations, and capable of generating datasets for data-driven analytics. It can also generate balanced faulty datasets when real failures are scarce or confidential. A comparison with high-frequency SCADA data from a municipal station shows strong agreement across key operational metrics. Furthermore, the paper proposes robust statistical and mathematical frameworks for fault detection and isolation, including a nested-model F-test to detect pump degradation or system faults, and a tangent residual approach to distinguish pump faults from system faults using operating-point kinematics. This framework enables what-if studies, facilitates early fault diagnosis based on flow rate and head, and provides actionable insights for condition-based maintenance in wastewater pumping infrastructure."}
{"id": "2511.11246", "categories": ["math.NA", "math.DS"], "pdf": "https://arxiv.org/pdf/2511.11246", "abs": "https://arxiv.org/abs/2511.11246", "authors": ["Tin Nwe Aye", "Linus Carlsson"], "title": "Analyzing Smoothness and Dynamics in an SEIR$^{\\text{T}}$R$^{\\text{P}}$D Endemic Model with Distributed Delays", "comment": null, "summary": "This article explores the properties of an SEIR$^{\\text{T}}$R$^{\\text{P}}$D endemic model expressed through delay-differential equations with distributed delays for latency and temporary immunity. Our research delves into the variability of latent periods and immunity durations across diseases, in particular, we introduce a class of delays defined by continuous integral kernels with compact support. The main result of the paper is a kind of smoothening property which the solution function posesses under mild conditions of the system parameter functions. Also, boundedness and non-negativity is proved. Numerical simulations indicates that the continuous model can be approximated with a discrete lag endemic models. The study contributes to understanding infectious disease dynamics and provides insights into the numerical approximation of exact solution for different delay scenarios."}
{"id": "2511.11466", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.11466", "abs": "https://arxiv.org/abs/2511.11466", "authors": ["Dmitry Kovalev", "Ekaterina Borodich"], "title": "Non-Euclidean SGD for Structured Optimization: Unified Analysis and Improved Rates", "comment": null, "summary": "Recently, several instances of non-Euclidean SGD, including SignSGD, Lion, and Muon, have attracted significant interest from the optimization community due to their practical success in training deep neural networks. Consequently, a number of works have attempted to explain this success by developing theoretical convergence analyses. Unfortunately, these results cannot properly justify the superior performance of these methods, as they could not beat the convergence rate of vanilla Euclidean SGD. We resolve this important open problem by developing a new unified convergence analysis under the structured smoothness and gradient noise assumption. In particular, our results indicate that non-Euclidean SGD (i) can exploit the sparsity or low-rank structure of the upper bounds on the Hessian and gradient noise, (ii) can provably benefit from popular algorithmic tools such as extrapolation or momentum variance reduction, and (iii) can match the state-of-the-art convergence rates of adaptive and more complex optimization algorithms such as AdaGrad and Shampoo."}
{"id": "2511.11453", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11453", "abs": "https://arxiv.org/abs/2511.11453", "authors": ["Ruike Lyu", "Chuyi Li", "Kedi Zheng", "Mengshu Shi", "Hongye Guo", "Chongqing Kang"], "title": "Translation-Symmetric Market: Enabling Incentive Compatibility For DER Aggregation", "comment": "Submitted to 2026 IEEE PES General Meeting", "summary": "Virtual power plants (VPPs) are indispensable for coordinating the rapidly growing portfolios of distributed energy resources (DERs) and enabling them to deliver multiple services into higher-level electricity markets. However, the profit allocation procedures that govern VPP participants become increasingly challenging to keep incentive-compatible due to the enlarged DER market power within each VPP, compared to directly bidding into the wholesale market. In this paper, we formulate both the VPP's market participation and its internal operation and profit allocation as consistent market-clearing processes. Building on this unified view, we propose the concept of a translation-symmetric market (TSM) framework, in which market-clearing models maintain identical structural forms across all hierarchical levels. We prove that translation symmetry induces an inductive property: once incentive compatibility holds at one level, it propagates downward to the internal settlements between the VPP and its constituent DERs. TSM also preserves service prices across levels, ensuring competitive conditions and enabling transparent valuation of resource contributions. Theoretical analysis and case studies illustrate how TSM secures incentive-compatible profit allocation in aggregating DERs to provide multiple services."}
{"id": "2511.11308", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.11308", "abs": "https://arxiv.org/abs/2511.11308", "authors": ["Riccardo Zuliani", "Efe C. Balta", "John Lygeros"], "title": "Policy Optimization for Unknown Systems using Differentiable Model Predictive Control", "comment": null, "summary": "Model-based policy optimization often struggles with inaccurate system dynamics models, leading to suboptimal closed-loop performance. This challenge is especially evident in Model Predictive Control (MPC) policies, which rely on the model for real-time trajectory planning and optimization. We introduce a novel policy optimization framework for MPC-based policies combining differentiable optimization with zeroth-order optimization. Our method combines model-based and model-free gradient estimation approaches, achieving faster transient performance compared to fully data-driven approaches while maintaining convergence guarantees, even under model uncertainty. We demonstrate the effectiveness of the proposed approach on a nonlinear control task involving a 12-dimensional quadcopter model."}
{"id": "2511.11321", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.11321", "abs": "https://arxiv.org/abs/2511.11321", "authors": ["Kristina Bätz", "Frank Werner"], "title": "L^1 data fitting for Inverse Problems yields optimal rates of convergence in case of discretized white Gaussian noise", "comment": null, "summary": "It is well-known in practice, that L^1 data fitting leads to improved robustness compared to standard L^2 data fitting. However, it is unclear whether resulting algorithms will perform as well in case of regular data without outliers. In this paper, we therefore analyze generalized Tikhonov regularization with L^1 data fidelity for Inverse Problems F(u) = g in a general setting, including general measurement errors and errors in the forward operator. The derived results are then applied to the situation of discretized Gaussian white noise, and we show that the resulting error bounds allow for order-optimal rates of convergence. These findings are also investigated in numerical simulations."}
{"id": "2511.11517", "categories": ["math.OC", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.11517", "abs": "https://arxiv.org/abs/2511.11517", "authors": ["Jitian Liu", "Nicolas Kozachuk", "Subhrajit Bhattacharya"], "title": "Distributed Optimization of Pairwise Polynomial Graph Spectral Functions via Subgraph Optimization", "comment": "22 pages, 8 figures", "summary": "We study distributed optimization of finite-degree polynomial Laplacian spectral objectives under fixed topology and a global weight budget, targeting the collective behavior of the entire spectrum rather than a few extremal eigenvalues. By re-formulating the global cost in a bilinear form, we derive local subgraph problems whose gradients approximately align with the global descent direction via an SVD-based test on the $ZC$ matrix. This leads to an iterate-and-embed scheme over disjoint 1-hop neighborhoods that preserves feasibility by construction (positivity and budget) and scales to large geometric graphs. For objectives that depend on pairwise eigenvalue differences $h(λ_i-λ_j)$, we obtain a quadratic upper bound in the degree vector, which motivates a ``warm-start'' by degree-regularization. The warm start uses randomized gossip to estimate global average degree, accelerating subsequent local descent while maintaining decentralization, and realizing $\\sim95\\%{}$ of the performance with respect to centralized optimization. We further introduce a learning-based proposer that predicts one-shot edge updates on maximal 1-hop embeddings, yielding immediate objective reductions. Together, these components form a practical, modular pipeline for spectrum-aware weight tuning that preserves constraints and applies across a broader class of whole-spectrum costs."}
{"id": "2511.11567", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11567", "abs": "https://arxiv.org/abs/2511.11567", "authors": ["Allen Emmanuel Binny", "Anushri Dixit"], "title": "Who Moved My Distribution? Conformal Prediction for Interactive Multi-Agent Systems", "comment": null, "summary": "Uncertainty-aware prediction is essential for safe motion planning, especially when using learned models to forecast the behavior of surrounding agents. Conformal prediction is a statistical tool often used to produce uncertainty-aware prediction regions for machine learning models. Most existing frameworks utilizing conformal prediction-based uncertainty predictions assume that the surrounding agents are non-interactive. This is because in closed-loop, as uncertainty-aware agents change their behavior to account for prediction uncertainty, the surrounding agents respond to this change, leading to a distribution shift which we call endogenous distribution shift. To address this challenge, we introduce an iterative conformal prediction framework that systematically adapts the uncertainty-aware ego-agent controller to the endogenous distribution shift. The proposed method provides probabilistic safety guarantees while adapting to the evolving behavior of reactive, non-ego agents. We establish a model for the endogenous distribution shift and provide the conditions for the iterative conformal prediction pipeline to converge under such a distribution shift. We validate our framework in simulation for 2- and 3- agent interaction scenarios, demonstrating collision avoidance without resulting in overly conservative behavior and an overall improvement in success rates of up to 9.6% compared to other conformal prediction-based baselines."}
{"id": "2511.11417", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11417", "abs": "https://arxiv.org/abs/2511.11417", "authors": ["Alessandro Bosso", "Marco Borghesi", "Andrea Iannelli", "Bowen Yi", "Giuseppe Notarstefano"], "title": "Data-Driven Stabilization of Continuous-Time LTI Systems from Noisy Input-Output Data", "comment": null, "summary": "We present an approach to compute stabilizing controllers for continuous-time linear time-invariant systems directly from an input-output trajectory affected by process and measurement noise. The proposed output-feedback design combines (i) an observer of a non-minimal realization of the plant and (ii) a feedback law obtained from a linear matrix inequality (LMI) that depends solely on the available data. Under a suitable interval excitation condition and knowledge of a noise energy bound, the feasibility of the LMI is shown to be necessary and sufficient for stabilizing all non-minimal realizations consistent with the data. We further provide a condition for the feasibility of the LMI related to the signal-to-noise ratio, guidelines to compute the noise energy bound, and numerical simulations that illustrate the effectiveness of the approach."}
{"id": "2511.11330", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.11330", "abs": "https://arxiv.org/abs/2511.11330", "authors": ["Shuai Su", "Xiurong Yan", "Qian Zhang"], "title": "A pressure-robust and parameter-free enriched Galerkin method for the Navier-Stokes equations of rotational form", "comment": null, "summary": "In this paper, we develop a novel enriched Galerkin (EG) method for the steady incompressible Navier-Stokes equations in rotational form, which is both pressure-robust and parameter-free. The EG space employed here, originally proposed in [1], differs from traditional EG methods: it enriches the first-order continuous Galerkin (CG) space with piecewise constants along edges in two dimensions or on faces in three dimensions, rather than with elementwise polynomials. Within this framework, the gradient and divergence are modified to incorporate the edge/face enrichment, while the curl remains applied only to the CG component, an inherent feature that makes the space particularly suitable for the rotational form. The proposed EG method achieves pressure robustness through a velocity reconstruction operator. We establish existence, uniqueness under a small-data assumption, and convergence of the method, and confirm its effectiveness by numerical experiments."}
{"id": "2511.11557", "categories": ["math.OC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.11557", "abs": "https://arxiv.org/abs/2511.11557", "authors": ["Michael Z. Zgurovsky", "Pavlo O. Kasyanov", "Liliia S. Paliichuk"], "title": "Drone Swarm Energy Management", "comment": "14 pages, 4 Tables, 2 Figures", "summary": "This note presents an analytical framework for decision-making in drone swarm systems operating under uncertainty, based on the integration of Partially Observable Markov Decision Processes (POMDP) with Deep Deterministic Policy Gradient (DDPG) reinforcement learning. The proposed approach enables adaptive control and cooperative behavior of unmanned aerial vehicles (UAVs) within a cognitive AI platform, where each agent learns optimal energy management and navigation policies from dynamic environmental states. We extend the standard DDPG architecture with a belief-state representation derived from Bayesian filtering, allowing for robust decision-making in partially observable environments. In this paper, for the Gaussian case, we numerically compare the performance of policies derived from DDPG to optimal policies for discretized versions of the original continuous problem. Simulation results demonstrate that the POMDP-DDPG-based swarm control model significantly improves mission success rates and energy efficiency compared to baseline methods. The developed framework supports distributed learning and decision coordination across multiple agents, providing a foundation for scalable cognitive swarm autonomy. The outcomes of this research contribute to the advancement of energy-aware control algorithms for intelligent multi-agent systems and can be applied in security, environmental monitoring, and infrastructure inspection scenarios."}
{"id": "2511.11053", "categories": ["cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11053", "abs": "https://arxiv.org/abs/2511.11053", "authors": ["Martina Alutto", "Sofia Bellotti", "Fabrizio Dabbene", "Chiara Ravazzi"], "title": "Modeling and Control of Sustainable Transitions through Opinion-Behavior Coupling in Heterogeneous Networks", "comment": "13 pages, 10 figures", "summary": "Understanding how sustainable behaviors spread within heterogeneous societies requires the integration of behavioral data, social influence mechanisms, and structured approaches to control. In this paper, we propose a data-driven computational framework for coupled opinion-adoption dynamics in social systems. Each node in the multilayer network represents a community characterized by a specific age group and mobility level, derived from large-scale survey data on the predisposition to adopt electric vehicles in Northern Europe. The proposed model captures three mechanisms: behavioral contagion through social and informational diffusion, abandonment driven by dissatisfaction, and feedback between opinions and adoption levels through social influence. Analyzing the equilibrium points of the coupled system allows us to derive the conditions that enable large-scale adoption. We empirically calibrate the model using data to construct synthetic populations and social similarity networks, which we use to explore targeted interventions that promote sustainable transitions. Specifically, the analysis focuses on two types of control strategies: opinion-based policies, which act on the social network layer, and policies that aim to improve experience and reduce dissatisfaction. Simulation results show that the latter ensure more stable and long-term adoption, offering concrete insights for designing effective interventions in sociotechnical transitions toward sustainability."}
{"id": "2511.11429", "categories": ["eess.SY", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.11429", "abs": "https://arxiv.org/abs/2511.11429", "authors": ["Lorenzo Ghiro", "Marco Franceschini", "Renato Lo Cigno", "Michele Segata"], "title": "Heterogeneous CACC Coexistence: Simulation, Analysis, and Modeling", "comment": null, "summary": "The design of Cooperative Adaptive Cruise Control (CACC) algorithms for vehicle platooning has been extensively investigated, leading to a wide range of approaches with different requirements and performance. Most existing studies evaluate these algorithms under the assumption of homogeneous platoons, i.e., when all platoon members adopt the same CACC. However, market competition is likely to result in vehicles from different manufacturers implementing distinct CACCs. This raises fundamental questions about whether heterogeneous vehicles can safely cooperate within a platoon and what performance can be achieved. To date, these questions have received little attention, as heterogeneous platoons are difficult to model and analyze. In this work, we introduce the concept of mixed platoons, i.e., platoons made of vehicles running heterogeneous CACCs, and we study their performance through simulation-based experiments. We consider mixtures of three well-established CACCs from the literature. In the first part of the paper, we study a single mixed platoon in isolation to understand the microscopic effects on safety: we evaluate the performance of various CACC-mixtures across speed change and emergency braking scenarios. In the second part, we examine a high-density ring-road scenario to assess macroscopic impacts on safety, comfort, and traffic throughput, especially comparing throughput results with those obtained from vehicles controlled by a standard Adaptive Cruise Control (ACC) or by human drivers. Our findings highlight that some combinations of CACCs can operate robustly and safely, while others exhibit critical limitations in safety, comfort, or efficiency. These results emphasize the need for careful system design and the development of theoretical frameworks for modeling heterogeneous platoons."}
{"id": "2511.11494", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2511.11494", "abs": "https://arxiv.org/abs/2511.11494", "authors": ["Eky Febrianto", "Yiren Wang", "Burigede Liu", "Michael Ortiz", "Fehmi Cirak"], "title": "A Quantum Spectral Method for Non-Periodic Boundary Value Problems", "comment": null, "summary": "Quantum computing holds the promise of solving computational mechanics problems in polylogarithmic time, meaning computational time scales as $\\mathscr{O}((\\log N)^c)$, where $N$ is the problem size and $c$ a constant. We propose a quantum spectral method with polylogarithmic complexity for solving non-periodic boundary value problems with arbitrary Dirichlet boundary conditions. Our method extends the recently proposed approach by Liu et al. (2025), in which periodic problems are discretised using truncated Fourier series. In such spectral methods, the discretisation of boundary value problems with constant coefficients leads to a set of algebraic equations in the Fourier space. We implement the respective diagonal solution operator by first approximating it with a polynomial and then quantum encoding the polynomial. The mapping between the physical and Fourier spaces is accomplished using the quantum Fourier transform (QFT). To impose zero Dirichlet boundary conditions, we double the domain size and reflect all physical fields antisymmetrically. The respective reflection matrix defines the quantum sine transform (QST) by pre- and post-multiplying with the QFT. For non-zero Dirichlet boundary conditions, the solution is decomposed into a boundary-conforming and a homogeneous part. The homogenous part is determined by solving a problem with a suitably modified forcing vector. We illustrate the basic approach with a Dirichlet-Poisson problem and demonstrate its generality by applying it to a fractional stochastic PDE for modelling spatial random fields. We discuss the circuit implementation of the proposed approach and provide numerical evidence confirming its polylogarithmic complexity."}
{"id": "2511.10835", "categories": ["nlin.AO", "cs.MA", "math.OC", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2511.10835", "abs": "https://arxiv.org/abs/2511.10835", "authors": ["Domenico Maisto", "Davide Nuzzi", "Giovanni Pezzulo"], "title": "What the flock knows that the birds do not: exploring the emergence of joint agency in multi-agent active inference", "comment": "18 pages, 3 figures, appendix", "summary": "Collective behavior pervades biological systems, from flocks of birds to neural assemblies and human societies. Yet, how such collectives acquire functional properties -- such as joint agency or knowledge -- that transcend those of their individual components remains an open question. Here, we combine active inference and information-theoretic analyses to explore how a minimal system of interacting agents can give rise to joint agency and collective knowledge. We model flocking dynamics using multiple active inference agents, each minimizing its own free energy while coupling reciprocally with its neighbors. We show that as agents self-organize, their interactions define higher-order statistical boundaries (Markov blankets) enclosing a ``flock'' that can be treated as an emergent agent with its own sensory, active, and internal states. When exposed to external perturbations (a ``predator''), the flock exhibits faster, coordinated responses than individual agents, reflecting collective sensitivity to environmental change. Crucially, analyses of synergistic information reveal that the flock encodes information about the predator's location that is not accessible to every individual bird, demonstrating implicit collective knowledge. Together, these results show how informational coupling among active inference agents can generate new levels of autonomy and inference, providing a framework for understanding the emergence of (implicit) collective knowledge and joint agency."}
{"id": "2511.11453", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11453", "abs": "https://arxiv.org/abs/2511.11453", "authors": ["Ruike Lyu", "Chuyi Li", "Kedi Zheng", "Mengshu Shi", "Hongye Guo", "Chongqing Kang"], "title": "Translation-Symmetric Market: Enabling Incentive Compatibility For DER Aggregation", "comment": "Submitted to 2026 IEEE PES General Meeting", "summary": "Virtual power plants (VPPs) are indispensable for coordinating the rapidly growing portfolios of distributed energy resources (DERs) and enabling them to deliver multiple services into higher-level electricity markets. However, the profit allocation procedures that govern VPP participants become increasingly challenging to keep incentive-compatible due to the enlarged DER market power within each VPP, compared to directly bidding into the wholesale market. In this paper, we formulate both the VPP's market participation and its internal operation and profit allocation as consistent market-clearing processes. Building on this unified view, we propose the concept of a translation-symmetric market (TSM) framework, in which market-clearing models maintain identical structural forms across all hierarchical levels. We prove that translation symmetry induces an inductive property: once incentive compatibility holds at one level, it propagates downward to the internal settlements between the VPP and its constituent DERs. TSM also preserves service prices across levels, ensuring competitive conditions and enabling transparent valuation of resource contributions. Theoretical analysis and case studies illustrate how TSM secures incentive-compatible profit allocation in aggregating DERs to provide multiple services."}
{"id": "2511.10928", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.10928", "abs": "https://arxiv.org/abs/2511.10928", "authors": ["Kabenge Hamiss", "Mohammed M. Alshahrani", "Mujahid N. Syed"], "title": "Two Generalized Derivative-free Methods to Solve Large Scale Nonlinear Equations with Convex Constraints", "comment": "26, 6 figures", "summary": "In this work, we propose two derivative-free methods to address the problem of large-scale nonlinear equations with convex constraints. These algorithms satisfy the sufficient descent condition. The search directions can be considered generalizations of the Modified Optimal Perry conjugate gradient method and the conjugate gradient projection method or the Spectral Modified Optimal Perry conjugate gradient method and the Spectral Conjugate Gradient Projection method. The global convergence of the former does not depend on the Lipschitz continuity of G. In contrast, the latter's global convergence depends on the Lipschitz continuity of G. The numerical results show the efficiency of the algorithms."}
{"id": "2511.11567", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11567", "abs": "https://arxiv.org/abs/2511.11567", "authors": ["Allen Emmanuel Binny", "Anushri Dixit"], "title": "Who Moved My Distribution? Conformal Prediction for Interactive Multi-Agent Systems", "comment": null, "summary": "Uncertainty-aware prediction is essential for safe motion planning, especially when using learned models to forecast the behavior of surrounding agents. Conformal prediction is a statistical tool often used to produce uncertainty-aware prediction regions for machine learning models. Most existing frameworks utilizing conformal prediction-based uncertainty predictions assume that the surrounding agents are non-interactive. This is because in closed-loop, as uncertainty-aware agents change their behavior to account for prediction uncertainty, the surrounding agents respond to this change, leading to a distribution shift which we call endogenous distribution shift. To address this challenge, we introduce an iterative conformal prediction framework that systematically adapts the uncertainty-aware ego-agent controller to the endogenous distribution shift. The proposed method provides probabilistic safety guarantees while adapting to the evolving behavior of reactive, non-ego agents. We establish a model for the endogenous distribution shift and provide the conditions for the iterative conformal prediction pipeline to converge under such a distribution shift. We validate our framework in simulation for 2- and 3- agent interaction scenarios, demonstrating collision avoidance without resulting in overly conservative behavior and an overall improvement in success rates of up to 9.6% compared to other conformal prediction-based baselines."}
{"id": "2511.11135", "categories": ["math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.11135", "abs": "https://arxiv.org/abs/2511.11135", "authors": ["Hussam Al Daas", "Nicholas I. M. Gould"], "title": "Extended-Krylov-subspace methods for trust-region and norm-regularization subproblems", "comment": null, "summary": "We consider an effective new method for solving trust-region and norm-regularization problems that arise as subproblems in many optimization applications. We show that the solutions to such subproblems lie on a manifold of approximately very low rank as a function of their controlling parameters (trust-region radius or regularization weight). Based on this, we build a basis for this manifold using an efficient extended-Krylov-subspace iteration that involves a single matrix factorization. The problems within the subspace using such a basis may be solved at very low cost using effective high-order root-finding methods. This then provides an alternative to common methods using multiple factorizations or standard Krylov subspaces. We provide numerical results to illustrate the effectiveness of our {\\tt TREK}/{\\tt NREK} approach."}
{"id": "2511.11053", "categories": ["cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.11053", "abs": "https://arxiv.org/abs/2511.11053", "authors": ["Martina Alutto", "Sofia Bellotti", "Fabrizio Dabbene", "Chiara Ravazzi"], "title": "Modeling and Control of Sustainable Transitions through Opinion-Behavior Coupling in Heterogeneous Networks", "comment": "13 pages, 10 figures", "summary": "Understanding how sustainable behaviors spread within heterogeneous societies requires the integration of behavioral data, social influence mechanisms, and structured approaches to control. In this paper, we propose a data-driven computational framework for coupled opinion-adoption dynamics in social systems. Each node in the multilayer network represents a community characterized by a specific age group and mobility level, derived from large-scale survey data on the predisposition to adopt electric vehicles in Northern Europe. The proposed model captures three mechanisms: behavioral contagion through social and informational diffusion, abandonment driven by dissatisfaction, and feedback between opinions and adoption levels through social influence. Analyzing the equilibrium points of the coupled system allows us to derive the conditions that enable large-scale adoption. We empirically calibrate the model using data to construct synthetic populations and social similarity networks, which we use to explore targeted interventions that promote sustainable transitions. Specifically, the analysis focuses on two types of control strategies: opinion-based policies, which act on the social network layer, and policies that aim to improve experience and reduce dissatisfaction. Simulation results show that the latter ensure more stable and long-term adoption, offering concrete insights for designing effective interventions in sociotechnical transitions toward sustainability."}
{"id": "2511.11308", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.11308", "abs": "https://arxiv.org/abs/2511.11308", "authors": ["Riccardo Zuliani", "Efe C. Balta", "John Lygeros"], "title": "Policy Optimization for Unknown Systems using Differentiable Model Predictive Control", "comment": null, "summary": "Model-based policy optimization often struggles with inaccurate system dynamics models, leading to suboptimal closed-loop performance. This challenge is especially evident in Model Predictive Control (MPC) policies, which rely on the model for real-time trajectory planning and optimization. We introduce a novel policy optimization framework for MPC-based policies combining differentiable optimization with zeroth-order optimization. Our method combines model-based and model-free gradient estimation approaches, achieving faster transient performance compared to fully data-driven approaches while maintaining convergence guarantees, even under model uncertainty. We demonstrate the effectiveness of the proposed approach on a nonlinear control task involving a 12-dimensional quadcopter model."}
