<div id=toc></div>

# Table of Contents

- [hep-lat](#hep-lat) [Total: 1]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [physics.hist-ph](#physics.hist-ph) [Total: 1]
- [math.OC](#math.OC) [Total: 11]
- [physics.geo-ph](#physics.geo-ph) [Total: 1]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 11]
- [quant-ph](#quant-ph) [Total: 35]
- [math.NA](#math.NA) [Total: 8]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 4]
- [eess.SY](#eess.SY) [Total: 13]
- [nlin.CD](#nlin.CD) [Total: 3]
- [math.ST](#math.ST) [Total: 6]
- [physics.comp-ph](#physics.comp-ph) [Total: 3]
- [stat.ME](#stat.ME) [Total: 12]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.ET](#cs.ET) [Total: 3]


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [1] [Probing Instanton Dynamics in the Pion Vector Form Factor with Wilson Flow](https://arxiv.org/abs/2602.04409)
*Vaibhav Chahar,Piotr Korcyl*

Main category: hep-lat

TL;DR: 本文提出利用瞬子液体模型研究介子电磁形状因子这一费米子观测量，并通过Wilson flow方法从格点QCD组态中提取瞬子主导的贡献，旨在检验该模型在非微扰区域的精度。


<details>
  <summary>Details</summary>
Motivation: 为了检验瞬子液体模型在非微扰QCD区域中的精确性，需要将其预测与格点QCD模拟结果进行比较，特别是在瞬子主导的动力学区域。

Method: 采用Wilson flow方法从格点QCD组态系综中分离出瞬子的主导贡献，并研究介子电磁形状因子这一费米子观测量。

Result: 文中描述了数值计算设置并展示了一些初步结果，但尚未给出最终结论。

Conclusion: 该研究为评估瞬子液体模型在费米子观测量上的有效性提供了新途径，有待进一步分析完整数据。

Abstract: Instanton liquid model is believed to capture the main features of vacuum QCD dynamics. Recently, multiple predictions for hadron structure functions have been derived and compared with experimental measurements and lattice QCD calculations, finding a general agreement. In order to explore the precision of the instanton liquid model, one has to compare its predictions with non-perturbative simulations in a regime dominated by instanton dynamics. This has been performed for two gluon-sensitive observables: the gluon Green's function and the strong running coupling constant. In this contribution, we propose to study a fermionic observable, the pion electromagnetic form factor, for which instanton liquid model predictions have been discussed in Phys.Rev.D 109, 074029. We use the Wilson flow to single out the dominant contribution from the instantons out of a lattice QCD configuration ensemble. We describe the details of our numerical setup, and some first, preliminary results.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [2] [Scalable platform enabling reservoir computing with nanoporous oxide memristors for image recognition and time series prediction](https://arxiv.org/abs/2602.04619)
*Joshua Donald,Ben A. Johnson,Amir Mehrnejat,Alex Gabbitas,Arthur G. T. Coveney,Alexander G. Balanov,Sergey Savel'ev,Pavel Borisov*

Main category: cond-mat.dis-nn

TL;DR: 本研究利用具有随机纳米孔结构的铌氧化物薄膜忆阻器构建物理储层计算系统，成功实现了XOR运算、图像识别以及时序信号预测与重构，展示了其在处理时间信号方面的高效性与潜力。


<details>
  <summary>Details</summary>
Motivation: 受哺乳动物大脑中神经元间随机连接的启发，探索基于随机结构的物理储层计算系统，以实现高效、低功耗的时间信号处理。

Method: 制备具有内在非均匀性（随机纳米孔）的铌氧化物薄膜忆阻器，将其作为物理储层，输入三路时变电压信号，通过读出层训练电流响应信号完成计算任务。

Result: 在XOR运算、图像识别和复杂三维混沌Lorenz-63时间序列的预测与重构任务中均取得良好性能，显著优于无储层的情况。

Conclusion: 基于全氧化物的随机结构忆阻器可作为可扩展的片上储层计算器件，为高效能类脑电子学提供了新路径。

Abstract: Typical mammal brains have some form of random connectivity between neurons. Reservoir computing, a neural network approach, uses random weights within its processing layer along with built-in recurrent connections and short-term, fading memory, and is shown to be time and training efficient in processing spatiotemporal signals. Here we prepared a niobium oxide-based thin film memristor device with intrinsic structural in-homogeneity in the form of random nanopores and performed computational tasks of XOR operations, image recognition, and time series prediction and reconstruction. For the latter task we chose a complex three-dimensional chaotic Lorenz-63 time series. By applying three temporal voltage waveforms individually across the device and training the readout layer with electrical current signals from a three-output physical reservoir, we achieved satisfactory prediction and reconstruction accuracy in comparison to the case of no reservoir. This work highlights the potential for scalable, on-chip devices using all-oxide reservoir systems, paving the way for energy-efficient neuromorphic electronics dealing with time signals.

</details>


### [3] [Theory of Optimal Learning Rate Schedules and Scaling Laws for a Random Feature Model](https://arxiv.org/abs/2602.04774)
*Blake Bordelon,Francesco Mori*

Main category: cond-mat.dis-nn

TL;DR: 本文研究了深度学习中随机梯度下降（SGD）最优学习率调度的可解模型，提出了在不同训练阶段（易相和难相）下的最优学习率规律，并扩展到批量大小、动量等优化，理论预测与实验验证一致。


<details>
  <summary>Details</summary>
Motivation: 学习率的选择对深度学习训练至关重要，但通常依赖经验试错；本文旨在通过可解模型从理论上推导最优学习率调度，减少调参依赖。

Method: 基于幂律随机特征模型，使用最优控制方法数值和解析地求解SGD训练中的最优学习率调度η_T^⋆(t)，并推广到批量大小和动量的联合优化。

Result: 发现两个训练相态：易相中最佳学习率呈多项式衰减；难相中则类似warmup-stable-decay模式。同时识别出学习率与批量大小的退化最优条件，并预测了计算最优缩放律；动量优化可在难相带来加速。

Conclusion: 最优学习率调度依赖于模型与任务结构，本文提供了理论指导，表明传统恒定或幂律调度次优，所提调度更优且可迁移至不同训练周期。

Abstract: Setting the learning rate for a deep learning model is a critical part of successful training, yet choosing this hyperparameter is often done empirically with trial and error. In this work, we explore a solvable model of optimal learning rate schedules for a powerlaw random feature model trained with stochastic gradient descent (SGD). We consider the optimal schedule $η_T^\star(t)$ where $t$ is the current iterate and $T$ is the total training horizon. This schedule is computed both numerically and analytically (when possible) using optimal control methods. Our analysis reveals two regimes which we term the easy phase and hard phase. In the easy phase the optimal schedule is a polynomial decay $η_T^\star(t) \simeq T^{-ξ} (1-t/T)^δ$ where $ξ$ and $δ$ depend on the properties of the features and task. In the hard phase, the optimal schedule resembles warmup-stable-decay with constant (in $T$) initial learning rate and annealing performed over a vanishing (in $T$) fraction of training steps. We investigate joint optimization of learning rate and batch size, identifying a degenerate optimality condition. Our model also predicts the compute-optimal scaling laws (where model size and training steps are chosen optimally) in both easy and hard regimes. Going beyond SGD, we consider optimal schedules for the momentum $β(t)$, where speedups in the hard phase are possible. We compare our optimal schedule to various benchmarks in our task including (1) optimal constant learning rates $η_T(t) \sim T^{-ξ}$ (2) optimal power laws $η_T(t) \sim T^{-ξ} t^{-χ}$, finding that our schedule achieves better rates than either of these. Our theory suggests that learning rate transfer across training horizon depends on the structure of the model and task. We explore these ideas in simple experimental pretraining setups.

</details>


<div id='physics.hist-ph'></div>

# physics.hist-ph [[Back]](#toc)

### [4] [From Florence to Fermions: a historical reconstruction of the origins of Fermi's statistics one hundred years later](https://arxiv.org/abs/2602.04484)
*Roberto Casalbuoni,Daniele Dominici*

Main category: physics.hist-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Aim of this paper is to retrace the path that led the young Enrico Fermi to write his paper on the statistics of an ideal monatomic gas. This discovery originated in his interest, which he had shown since his formative years, in the absolute entropy constant and in the problems he highlighted in Sommerfeld's quantization in the case of identical particle systems. The fundamental step taken by Fermi in writing his work on statistics was to apply the Exclusion Principle, formulated for electrons in an atom and which could therefore have been a pure effect due to dynamics, to a system of non-interacting particles.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [5] [Convex duality contracts for production-grade mathematical optimization](https://arxiv.org/abs/2602.04048)
*Juan Pablo Vielma,Ross Anderson,Joey Huchette*

Main category: math.OC

TL;DR: 本文提出了一个基于简化Fenchel对偶框架的抽象原-对偶问题对，用于统一数学优化中不同求解器和问题类别的对偶解与不可行性证书的约定，提升互补松弛最优性条件的清晰度。


<details>
  <summary>Details</summary>
Motivation: 由于不同优化求解器在对偶解和不可行性证书（射线）上的约定差异较大，导致在自主生产系统中部署数学优化时缺乏统一、精确的对象契约，因此需要一个统一的理论框架来解决这一问题。

Method: 提出了一种基于简化Fenchel对偶方案的抽象原-对偶问题对，并通过该框架机械地推导出各类问题的对偶问题及其对应契约，涵盖线性与二次目标函数以及线性、锥、二次和双边线性约束等问题类型。

Result: 实现了对MathOpt当前支持的所有问题类别的对偶问题和契约的统一表达，并提升了某些问题类别下基于互补松弛的最优性条件的清晰度。

Conclusion: 该抽象框架有效统一了不同优化问题和求解器之间的对偶解和不可行性证书的语义，增强了优化结果在实际系统中的可部署性和可解释性。

Abstract: Deploying mathematical optimization in autonomous production systems requires precise contracts for objects returned by an optimization solver. Unfortunately, conventions on dual solution and infeasibility certificates (rays) vary widely across solvers and classes of problems. This paper presents the theoretical framework used by MathOpt (a domain-specific language developed and used at Google) to unify these notions. We propose an abstract primal-dual pair based on a simplified Fenchel duality scheme that allows for the mechanical derivation of dual problems and associated contracts for all classes of problems currently supported by MathOpt (including those with linear and quadratic objectives plus linear, conic, quadratic, and two-sided linear constraints). We also show how these contracts can improve clarity of complementary-slackness based optimality conditions for certain classes of problems.

</details>


### [6] [New Outer Approximation Algorithms for Nonsmooth Convex MINLP Problems](https://arxiv.org/abs/2602.04122)
*Zhou Wei,He-Yi Liu,Bo Zeng*

Main category: math.OC

TL;DR: 提出了一种用于非光滑混合整数非线性规划问题的新型外逼近算法，通过KKT条件生成有效线性割平面，并引入新参数改进割平面生成机制，理论证明算法在有限步内收敛。


<details>
  <summary>Details</summary>
Motivation: 针对非光滑混合整数非线性规划（MINLP）问题缺乏高效外逼近方法的问题，特别是传统方法依赖一阶泰勒展开、割平面松弛不足的局限，本文旨在提出一种更有效的外逼近框架。

Method: 固定整数变量求解凸非线性子问题；对于可行子问题，利用最优解处的KKT条件计算目标和约束函数的次梯度以生成有效线性割平面；对不可行子问题，求解可行性子问题并基于KKT次梯度生成排除不可行整数配置的割平面；引入一个由非线性约束定义的新参数辅助割平面生成；结合两类割平面构建等价的MILP主问题，形成新的外逼近算法。

Result: 所提算法能生成比经典外逼近方法更紧的MILP松弛；提供了超越一阶梯度泰勒展开的新型线性割平面生成机制；数值实验表明算法性能与MINLP问题内在结构密切相关；理论上证明了算法在有限次迭代后收敛。

Conclusion: 本文提出的基于KKT次梯度和新参数的外逼近算法为非光滑MINLP问题提供了一个有效且理论上收敛的求解框架，增强了割平面的紧致性与适应性，拓展了外逼近方法的应用边界。

Abstract: This paper presents a novel outer approximation algorithm for nonsmooth mixed-integer nonlinear programming (MINLP) problems. The method proceeds by fixing the integer variables and solving the resulting nonlinear convex subproblem. When the subproblem is feasible, valid linear cuts are derived by computing suitable subgradients of the objective and constraint functions at the optimal solution, utilizing KKT optimality conditions. A new parameter, defined through the nonlinear constraint functions, is introduced to facilitate the generation of these cuts. For infeasible subproblems, a feasibility problem is solved, and valid linear cuts are generated via KKT-based subgradients to exclude the infeasible integer assignment.
  By integrating both types of cuts, a mixed-integer linear programming (MILP) master problem is formulated and proven equivalent to the original MINLP. This equivalence underpins a new outer approximation algorithm, which is guaranteed to terminate after a finite number of iterations.
  Numerical experiments on smooth convex MINLP problems demonstrate that the proposed algorithm produces tighter MILP relaxations than the classical outer approximation method. Furthermore, the approach offers an alternative mechanism for generating linear cuts, extending beyond reliance solely on first-order Taylor expansions and shows that the efficiency of outer approximation algorithm is strongly dependent on the inherent structure of the MINLP problem.

</details>


### [7] [Variable Aggregation-based Perspective Reformulation for Mixed-Integer Convex Optimization with Symmetry](https://arxiv.org/abs/2602.04123)
*Junhao Wu,Shaoze Li,Cheng Lu,Zhibin Deng,Shu-Cherng Fang*

Main category: math.OC

TL;DR: 本文提出了一种将视角重构方法融入变量聚合框架的新公式，以在具有对称结构的混合整数凸优化问题中获得更紧密的连续松弛。


<details>
  <summary>Details</summary>
Motivation: 尽管已经使用变量聚合技术来缓解对称性，但其对相应连续松弛的紧致性影响尚未得到充分研究。

Method: 将视角重构方法整合到变量聚合框架中，并证明在存在对称性的情况下，可以精确刻画每组聚合变量相关联的可行区域的凸包。

Result: 所提出的重构方法能够产生更紧密的连续松弛，并为基于变量聚合的混合整数规划公式实现紧致性建立了新的理论基础。

Conclusion: 该方法有效提升了混合整数凸优化问题中对称结构处理的松弛质量，具有重要的理论与应用价值。

Abstract: This paper addresses the challenging issue of symmetry in mixed-integer convex optimization problems, which frequently arise in real-world applications such as the unit commitment problem. Although variable aggregation techniques have been employed to mitigate symmetry, their impact on tightening the corresponding continuous relaxation has not been thoroughly investigated. In this work, we propose a new formulation that integrates the perspective reformulation method into the variable aggregation framework, yielding a tighter continuous relaxation for mixed-integer convex optimization problems with symmetric structures. We prove that, in the presence of symmetry, the convex hull of the feasible region associated with each set of aggregated variables can be exactly characterized. These results demonstrate the effectiveness of the proposed reformulation and establish new theoretical foundations for achieving tightness in variable aggregation-based mixed-integer programming formulations.

</details>


### [8] [Inertial dynamical systems and accelerated algorithms with implicit Hessian-driven damping for nonconvex optimization](https://arxiv.org/abs/2602.04143)
*Zeying Gao,Xiangkai Sun,Liang He*

Main category: math.OC

TL;DR: 本文研究了具有隐式Hessian驱动阻尼的惯性动力系统，用于强拟凸优化问题，并建立了无需梯度Lipschitz连续性的指数收敛速率。通过显式时间离散化得到了加速算法，并考虑了外源扰动情形，利用Lyapunov方法证明了迭代序列的收敛速率，且通过数值实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 针对非凸优化中的一类特殊问题——强拟凸优化，设计具有快速收敛性质的动力系统及相应算法，且不依赖梯度Lipschitz连续性这一较强假设。

Method: 基于隐式Hessian驱动阻尼的惯性动力系统建模，采用显式时间离散化构造优化算法，并引入Lyapunov函数分析系统收敛性，同时考虑外源扰动的影响。

Result: 建立了该动力系统的指数收敛速率；得到了适用于强拟凸函数的惯性加速算法及其在扰动下的变体；证明了迭代序列及其函数值的收敛速率，并通过数值实验验证了算法有效性。

Conclusion: 所提出的动力系统和算法对强拟凸优化问题具有良好的收敛性能，且在无需梯度Lipschitz连续条件下仍能保证指数收敛，拓展了现有方法的适用范围。

Abstract: This paper is devoted to the investigation of inertial dynamical systems with implicit Hessian-driven damping for strongly quasiconvex optimization which is a specific class of nonconvex optimization problems. We first establish exponential convergence rate properties for this system without requiring Lipschitz continuity of the gradient on the function. Then, we obtain an inertial accelerated algorithm for minimizing strongly quasiconvex functions through natural explicit time discretization to the dynamical system. Meanwhile, we consider an exogenous additive perturbation term to this dynamical system and obtain the corresponding algorithm. By utilizing the Lyapunov method, we establish convergence rates of iterative sequences and their function values. Furthermore, we conduct numerical experiments to illustrate the theoretical results.

</details>


### [9] [Restart-Free (Accelerated) Gradient Sliding Methods for Strongly Convex Composite Optimization](https://arxiv.org/abs/2602.04161)
*Xinming Wu,Zi Xu,Huiling Zhang*

Main category: math.OC

TL;DR: 本文提出了一种无需重启的随机梯度滑动算法，用于求解一类复合优化问题，在保持最优复杂度的同时简化了算法设计。


<details>
  <summary>Details</summary>
Motivation: 重启策略虽然在强凸条件下能实现最优收敛，但增加了算法结构复杂性和实际开销，本文旨在消除这一负担。

Method: 提出一种无需重启的随机梯度滑动算法，通过精心设计的参数选择策略，避免显式重启阶段；对于可转化为双线性鞍点问题的结构化非光滑项，进一步发展了加速版本。

Result: 所提算法在光滑部分仅需O(log(1/ε))次梯度计算，非光滑部分需O(1/ε)次随机次梯度计算，达到最优复杂度；对于鞍点问题，整体迭代复杂度为O(1/√ε)，且光滑部分仍保持O(log(1/ε))的梯度计算量。

Conclusion: 本文方法在不牺牲理论性能的前提下，显著简化了算法结构，为嵌套和实际应用提供了更简洁高效的解决方案。

Abstract: In this paper, we study a class of composite optimization problems whose objective function is given by the summation of a general smooth and nonsmooth component, together with a relatively simple nonsmooth term. While restart strategies are commonly employed in first-order methods to achieve optimal convergence under strong convexity, they introduce structural complexity and practical overhead, making algorithm design and nesting cumbersome. To address this, we propose a \emph{restart-free} stochastic gradient sliding algorithm that eliminates the need for explicit restart phases when the simple nonsmooth component is strongly convex. Through a novel and carefully designed parameter selection strategy, we prove that the proposed algorithm achieves an $ε$-solution with only $\mathcal{O}(\log(\frac{1}ε))$ gradient evaluations for the smooth component and $\mathcal{O}(\frac{1}ε)$ stochastic subgradient evaluations for the nonsmooth component, matching the optimal complexity of existing multi-phase (restart-based) methods. Moreover, for the case where the nonsmooth component is structured, allowing the overall problem to be reformulated as a bilinear saddle-point problem, we develop a restart-free accelerated stochastic gradient sliding algorithm. We show that the resulting method requires only $\mathcal{O}(\log(\frac{1}ε))$ gradient computations for the smooth component while preserving an overall iteration complexity of $\mathcal{O}(\frac{1}{\sqrtε})$ for solving the corresponding saddle-point problems. Our work thus provides simpler, restart-f

</details>


### [10] [Sampled-Data Wasserstein Distributionally Robust Control of Multiplicative Systems: A Convex Relaxation with Performance Guarantees](https://arxiv.org/abs/2602.04219)
*Chung-Han Hsieh*

Main category: math.OC

TL;DR: 本文研究了具有乘性噪声和分布模糊性的采样数据随机系统的鲁棒最优控制，提出了一种基于Wasserstein模糊集的凸松弛方法，提供了可计算的性能下界和非渐近的对偶间隙估计，并应用于对数最优投资组合控制问题。


<details>
  <summary>Details</summary>
Motivation: 针对具有分布模糊性和乘性噪声的采样数据随机系统，传统凸损失最小化方法难以处理最大化凹效用时的"凹-最大"结构难题，亟需一种能够应对模型不确定性并保证系统鲁棒性能的控制框架。

Method: 采用Wasserstein模糊集建模不确定性，利用一般极小极大不等式推导出一个可处理的凸松弛形式，通过半无限约束中的极小极大交换克服凹效用导致的强对偶性缺失问题，并建立非渐近的对偶间隙上界。

Result: 得到了一个严格的概率性能下界和显式的非渐近对偶间隙估计，该间隙由阶段奖励的Lipschitz平滑性和干扰支撑直径统一控制；提出了保证状态正不变性的鲁棒可行性充要条件，并证明松弛问题的最优值为渐近平均效用率提供了几乎必然的确定性下界。

Conclusion: 所提方法为具有模型不确定性的离散时间随机控制系统提供了一个兼具理论严谨性与计算可行性的鲁棒控制框架，特别适用于如对数最优投资组合等乘性随机控制问题。

Abstract: This paper investigates the robust optimal control of sampled-data stochastic systems with multiplicative noise and distributional ambiguity. We consider a class of discrete-time optimal control problems where the controller \emph{jointly} selects a feedback policy and a sampling period to maximize the worst-case expected concave utility of the inter-sample growth factor. Modeling uncertainty via a Wasserstein ambiguity set, we confront the structural obstacle of~``concave-max'' geometry arising from maximizing a concave utility against an adversarial distribution. Unlike standard convex loss minimization, the dual reformulation here requires a minimax interchange within the semi-infinite constraints, where the utility's concavity precludes exact strong duality. To address this, we utilize a general minimax inequality to derive a tractable convex relaxation. Our approach yields a rigorous lower bound that functions as a probabilistic performance guarantee. We establish an explicit, non-asymptotic bound on the resulting duality gap, proving that the approximation error is uniformly controlled by the Lipschitz-smoothness of the stage reward and the diameter of the disturbance support. Furthermore, we introduce necessary and sufficient conditions for \emph{robust viability}, ensuring state positivity invariance across the entire ambiguity set. Finally, we bridge the gap between static optimization and dynamic performance, proving that the optimal value of the relaxation serves as a rigorous deterministic floor for the asymptotic average utility rate almost surely. The framework is illustrated on a log-optimal portfolio control problem, which serves as a canonical instance of multiplicative stochastic control.

</details>


### [11] [An Improved Boosted DC Algorithm for Nonsmooth Functions with Applications in Image Recovery](https://arxiv.org/abs/2602.04237)
*ZeYu Li,Te Qi,TieYong Zeng*

Main category: math.OC

TL;DR: 提出了一种针对非光滑非凸问题的单调改进型增强差分凸函数算法（IBDCA），在图像恢复应用中表现出优于DCA和其他先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 经典BDCA在处理非光滑DC问题时可能产生上升方向，导致无法进行单调线搜索，因此需要一种适用于非光滑情况的改进算法。

Method: 提出单调改进的IBDCA，用于一类可表示为非光滑函数与光滑函数之差的DC问题，并结合Kurdyka-Łojasiewicz性质分析其全局收敛性与收敛速率。

Result: IBDCA生成序列的任意聚点是问题的临界点，目标函数值单调递减且收敛；在KL条件下具有全局收敛性和收敛率；数值实验显示其在计算时间和迭代次数上优于DCA及其他先进方法。

Conclusion: IBDCA有效解决了非光滑DC优化中BDCA的局限性，在理论和实际应用（如图像恢复）中均表现出优越性能。

Abstract: We propose a new approach to perform the boosted difference of convex functions algorithm (BDCA) on non-smooth and non-convex problems involving the difference of convex (DC) functions. The recently proposed BDCA uses an extrapolation step from the point computed by the classical DC algorithm (DCA) via a line search procedure in a descent direction to get an additional decrease of the objective function and accelerate the convergence of DCA. However, when the first function in DC decomposition is non-smooth, the direction computed by BDCA can be ascent and a monotone line search cannot be performed. In this work, we proposed a monotone improved boosted difference of convex functions algorithm (IBDCA) for certain types of non-smooth DC programs, namely those that can be formulated as the difference of a possibly non-smooth function and a smooth one. We show that any cluster point of the sequence generated by IBDCA is a critical point of the problem under consideration and that the corresponding objective value is monotonically decreasing and convergent. We also present the global convergence and the convergent rate under the Kurdyka-Lojasiewicz property. The applications of IBDCA in image recovery show the effectiveness of our proposed method. The corresponding numerical experiments demonstrate that our IBDCA outperforms DCA and other state-of-the-art DC methods in both computational time and number of iterations.

</details>


### [12] [A Path-Complete Approach for Optimal Control of Switched Systems](https://arxiv.org/abs/2602.04310)
*Léa Ninite,Adrien Banse,Guillaume O. Berger,Raphaël M. Jungers*

Main category: math.OC

TL;DR: 提出了一种基于路径完全图的新型框架，用于构建离散时间切换系统价值函数的可计算上界，适用于具有二次代价的线性切换系统，并提供了LMI形式的凸优化公式和近似保证。


<details>
  <summary>Details</summary>
Motivation: 由于切换序列数量随时间指数增长，精确计算离散时间切换系统的价值函数不可行，因此需要发展可处理的近似方法。

Method: 利用路径完全图框架，结合多个二次函数并通过有向图编码动态规划不等式，构建凸且可靠的上界估计；对于线性系统采用LMI方法求解。

Result: 推导出基于LMI的可处理公式，提供计算复杂度界限，证明上界具有近似保证并渐近非保守，同时扩展至含仿射控制输入的控制器综合问题。

Conclusion: 该方法为具有外部切换信号的离散时间系统提供了有效、可计算的价值函数上界估计方案，并在数值示例中验证了其有效性。

Abstract: We study the problem of estimating the value function of discrete-time switched systems under arbitrary switching. Unlike the switched LQR problem, where both inputs and mode sequences are optimized, we consider the case where switching is exogenous. For such systems, the number of possible mode sequences grows exponentially with time, making the exact computation of the value function intractable. This motivates the development of tractable bounds that approximate it. We propose a novel framework, based on path-complete graphs, for constructing computable upper bounds on the value function. In this framework, multiple quadratic functions are combined through a directed graph that encodes dynamic programming inequalities, yielding convex and sound formulations. For example, for switched linear systems with quadratic cost, we derive tractable LMI-based formulations and provide computational complexity bounds. We further establish approximation guarantees for the upper bounds and show asymptotic non-conservativeness using concepts from graph theory. Finally, we extend the approach to controller synthesis for systems with affine control inputs and demonstrate its effectiveness on numerical examples.

</details>


### [13] [Lower Bounds for Frank-Wolfe on Strongly Convex Sets](https://arxiv.org/abs/2602.04378)
*Jannis Halbey,Daniel Deza,Max Zimmer,Christophe Roux,Bartolomeo Stellato,Sebastian Pokutta*

Main category: math.OC

TL;DR: 本文提出了在目标函数和约束集均为光滑且强凸的情况下，Frank-Wolfe算法的收敛下界为Ω(1/√ε)，证明了已知的O(1/√ε)上界是紧致的。


<details>
  <summary>Details</summary>
Motivation: 研究在目标函数和约束集都强凸且光滑时，Frank-Wolfe算法是否能获得比O(1/√ε)更快的统一收敛速率，而不依赖于最优解的位置。

Method: 通过分析在欧几里得单位球上最小化强凸二次函数（最优解位于边界）这一典型问题，构建最坏情况下的Frank-Wolfe轨迹，并提出新的计算方法辅助构造，进而给出解析证明。

Result: 建立了Frank-Wolfe算法在此类问题下的收敛下界Ω(1/√ε)，表明已有上界是紧致的，无法在一般情况下进一步提升收敛速率。

Conclusion: 即使在目标函数和约束集均强凸且光滑的情况下，Frank-Wolfe算法也无法实现比O(1/√ε)更优的统一收敛速率，从而回答了该领域的一个开放问题。

Abstract: We present a constructive lower bound of $Ω(1/\sqrt{\varepsilon})$ for Frank-Wolfe (FW) when both the objective and the constraint set are smooth and strongly convex, showing that the known uniform $\mathcal{O}(1/\sqrt{\varepsilon})$ guarantees in this regime are tight. It is known that under additional assumptions on the position of the optimizer, FW can converge linearly. However, it remained unclear whether strong convexity of the set can yield rates uniformly faster than $\mathcal{O}(1/\sqrt{\varepsilon})$, i.e., irrespective of the position of the optimizer. To investigate this question, we focus on a simple yet representative problem class: minimizing a strongly convex quadratic over the Euclidean unit ball, with the optimizer on the boundary. We analyze the dynamics of FW for this problem in detail and develop a novel computational approach to construct worst-case FW trajectories, which is of independent interest. Guided by these constructions, we develop an analytical proof establishing the lower bound.

</details>


### [14] [Decentralized Optimization with Mixed Affine Constraints](https://arxiv.org/abs/2602.04479)
*Demyan Yarmoshik,Nhat Trung Nguyen,Alexander Rogozin,Alexander Gasnikov*

Main category: math.OC

TL;DR: 本文提出了一种针对具有混合仿射等式约束（包含局部和全局变量）的去中心化凸优化问题的最优算法，在光滑强凸情形下达到已知的复杂度下界，其余情形下也提供近优方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习、联邦学习、多任务学习及分布式控制中出现的含混合等式约束的去中心化优化问题，现有方法在收敛速率和适应性方面存在不足。

Method: 设计适用于光滑与非光滑、强凸与一般凸目标函数的去中心化优化算法，利用对偶方法处理混合等式约束，并分析其在不同设定下的收敛性。

Result: 在光滑强凸情况下实现了最优收敛速率，匹配已知的下界；在其他情况下提供了近优的收敛速率。

Conclusion: 所提算法在多种设定下均具有理论最优或近优性能，为含混合约束的去中心化优化问题提供了统一且高效的解决方案。

Abstract: This paper considers decentralized optimization of convex functions with mixed affine equality constraints involving both local and global variables. Constraints on global variables may vary across different nodes in the network, while local variables are subject to coupled and node-specific constraints. Such problem formulations arise in machine learning applications, including federated learning and multi-task learning, as well as in resource allocation and distributed control. We analyze this problem under smooth and non-smooth assumptions, considering both strongly convex and general convex objective functions. Our main contribution is an optimal algorithm for the smooth, strongly convex regime, whose convergence rate matches established lower complexity bounds. We further provide near-optimal methods for the remaining cases.

</details>


### [15] [A GPU-accelerated Nonlinear Branch-and-Bound Framework for Sparse Linear Models](https://arxiv.org/abs/2602.04551)
*Xiang Meng,Ryan Lucas,Rahul Mazumder*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study exact sparse linear regression with an $\ell_0-\ell_2$ penalty and develop a branch-and-bound (BnB) algorithm explicitly designed for GPU execution. Starting from a perspective reformulation, we derive an interval relaxation that can be solved by ADMM with closed-form, coordinate-wise updates. We structure these updates so that the main work at each BnB node reduces to batched matrix-vector operations with a shared data matrix, enabling fine-grained parallelism across coordinates and coarse-grained parallelism across many BnB nodes on a single GPU. Feasible solutions (upper bounds) are generated by a projected gradient method on the active support, implemented in a batched fashion so that many candidate supports are updated in parallel on the GPU. We discuss practical design choices such as memory layout, batching strategies, and load balancing across nodes that are crucial for obtaining good utilization on modern GPUs. On synthetic and real high-dimensional datasets, our GPU-based approach achieves clear runtime improvements over a CPU implementation of our method, an existing specialized BnB method, and commercial MIP solvers.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [16] [Backend-agnostic Julia framework for 3D modeling and inversion of gravity data](https://arxiv.org/abs/2602.03857)
*Nimatullah,Pankaj K Mishra,Jochen Kamm,Anand Singh*

Main category: physics.geo-ph

TL;DR: 本文提出了一种基于Julia语言的高性能三维重力建模与反演框架，采用数据空间反演 formulation 以降低计算复杂度和内存需求，并支持CPU与GPU后端加速，显著提升了大规模重力反演的效率与分辨率。


<details>
  <summary>Details</summary>
Motivation: 针对重力反演中存在的计算复杂性、病态性和非唯一性等挑战，需要一种高效、可扩展且高精度的计算框架来实现大尺度、高分辨率的地下密度结构重建。

Method: 采用数据空间反演方法降低问题维度，结合深度加权敏感性与隐式模型约束；前向建模与反演算子通过后端无关的核抽象实现，支持多核CPU和NVIDIA GPU（CUDA）加速。

Result: 在包含约330万个矩形棱柱的大规模数据集上，GPU实现显著缩短了运行时间；合成模型验证表明该框架能准确重建垂直和倾斜岩墙等复杂结构；实际数据应用结果与地质先验信息高度一致。

Conclusion: 基于Julia的GPU加速框架在保持反演精度的同时大幅提升了计算效率，展示了其在大规模高分辨率地球物理反演中的潜力，为重力勘探提供了高效、可扩展的新工具。

Abstract: This paper presents a high-performance framework for three-dimensional gravity modeling and inversion implemented in Julia, addressing key challenges in geophysical modeling such as computational complexity, ill-posedness, and the non-uniqueness inherent to gravity inversion. The framework adopts a data-space inversion formulation to reduce the dimensionality of the problem, leading to significantly lower memory requirements and improved computational efficiency while maintaining inversion accuracy. Forward modeling and inversion operators are implemented within a backend-agnostic kernel abstraction, enabling execution on both multicore CPUs and GPU accelerators from a single code base. Performance analyses conducted on NVIDIA CUDA GPUs demonstrate substantial reductions in runtime relative to CPU execution, particularly for large-scale datasets involving up to approximately 3.3 million rectangular prisms, highlighting the scalability of the proposed approach. The inversion incorporates implicit model constraints through the data-space formulation and depth-weighted sensitivity, which mitigate depth-related amplitude decay and yield geologically coherent, high-resolution subsurface density models. Validation using synthetic models confirms the ability of the framework to accurately reconstruct complex subsurface structures such as vertical and dipping dykes. Application to field gravity data further demonstrates the robustness and practical utility of the GPU-accelerated framework, with the recovered models showing strong consistency with independent geological constraints and prior interpretations. Overall, this work underscores the potential of GPU-enabled computing in Julia to transform large-scale gravity inversion workflows, providing an efficient, extensible, and accurate computational solution for high-resolution geophysical studies.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [17] [Tsallis Entropy derived from the Chaitin-Kolmogorov Informational Entropy](https://arxiv.org/abs/2602.03919)
*Airton Deppman*

Main category: cond-mat.stat-mech

TL;DR: 本文通过Chaitin-Kolmogorov算法信息论严格推导出非加性的Tsallis熵，表明在字符串形成中引入非局域限制规则后，算法代价随字符串长度呈幂律增长，导致Tsallis熵主导信息增长，并影响Landauer极限下的热耗散。


<details>
  <summary>Details</summary>
Motivation: 旨在从第一性原理出发，解释非加性熵的起源及其在复杂系统中的作用机制。

Method: 基于Chaitin-Kolmogorov算法信息理论，引入非局域语法约束，分析字符串生成的算法代价，并结合数值模拟验证结果。

Result: 发现算法代价随字符串长度呈幂律增长，Tsallis熵自然出现；具有长程关联的系统的热耗散降低；不可压缩数Ω_q与参数q相关，支持复杂性的连续增长；结果与Zipf定律一致。

Conclusion: Tsallis熵可由算法信息论自然导出，适用于描述具有长程关联和复杂语法结构的系统，拓展了传统熵理论的应用范围。

Abstract: We provide a rigorous first-principle derivation of the non-additive Tsallis' entropy by employing the Chaitin-Kolmogorov algorithmic information theory. By applying non-local restrictive rules on the string formation (grammar), we show that the algorithmic cost follows a power-law of the string length, instead of the linear behaviour obtained in the classical theory. As a result, the Tsallis entropy governs the increase of information. We explore the result showing, through Landauer's limit, that the heat dissipation in systems with long-range correlations is diminished. The $Ω_q$ number, which remains incompressible, now offers the possibility of a continuous increase of complexity, measured by the parameter $q$. We show the consistency of the results by a numerical simulation, and discuss Zipf's law in light of the new findings.

</details>


### [18] [Restoring Sparsity in Potts Machines via Mean-Field Constraints](https://arxiv.org/abs/2602.04200)
*Kevin Callahan-Coray,Kyle Lee,Kyle Jiang,Kerem Y. Camsari*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一种硬件感知的多态概率数字（p-dits）原生表示方法和均场约束（MFC）混合方案，以解决伊辛机在处理约束优化问题时因密集耦合导致的可扩展性问题。该方法显著降低了图密度，并在FPGA实现中实现了比CPU求解器快几个数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 许多实际优化问题包含导致全连接或密集耦合的约束，这会破坏伊辛机等概率硬件的可扩展性和效率。因此需要一种能缓解约束引起密度问题的新方法。

Method: 1. 提出p-dits的硬件感知原生表示，避免二进制伊辛编码所需的局部密集变量内耦合；2. 提出均场约束（MFC）混合方案，用动态更新的单节点偏置替代密集的成对约束耦合；3. 通过二维Potts模型验证p-dits动力学，并在平衡图划分问题上评估MFC性能；4. 使用FPGA实现验证稀疏性的恢复带来的实际加速效果。

Result: 1. 成功复现了2D Potts模型的已知临界行为，验证了p-dits的正确性；2. MFC在解质量上与精确的全连接约束形式相当，但显著降低了图密度；3. FPGA实现相比CPU求解器实现了数个数量级的加速。

Conclusion: p-dits与MFC相结合为在概率硬件上扩展约束优化提供了一条可行路径，有效解决了由约束引起的密集耦合问题，提升了硬件效率和可扩展性。

Abstract: Ising machines and related probabilistic hardware have emerged as promising platforms for NP-hard optimization and sampling. However, many practical problems involve constraints that induce dense or all-to-all couplings, undermining scalability and hardware efficiency. We address this constraint-induced density through two complementary approaches. First, we introduce a hardware-aware native formulation for multi-state probabilistic digits (p-dits) that avoids the locally dense intra-variable couplings required by binary Ising encodings. We validate p-dit dynamics by reproducing known critical behavior of the 2D Potts model. Second, we propose mean-field constraints (MFC), a hybrid scheme that replaces dense pairwise constraint couplings with dynamically updated single-node biases. Applied to balanced graph partitioning, MFC achieves solution quality comparable to exact all-to-all constraint formulations while dramatically reducing graph density. Finally, we demonstrate the practical impact of restored sparsity by an FPGA implementation, enabling orders-of-magnitude acceleration over CPU-based solvers. Together, these results outline a pathway for scaling constrained optimization on probabilistic hardware.

</details>


### [19] [Statistical Mechanics of the Sub-Optimal Transport](https://arxiv.org/abs/2602.04308)
*Riccardo Piombo,Dario Mazzilli,Aurelio Patelli*

Main category: cond-mat.stat-mech

TL;DR: 本文发展了一种平均场理论，首次对次优传输（SOT）模型中的熵与成本竞争导致的平滑交叉行为进行了精确的解析描述，突破了传统统计力学局限于零温极限的方法。


<details>
  <summary>Details</summary>
Motivation: 现实系统常处于熵与成本最小化相竞争的中间状态，而传统统计力学多聚焦于零温极限下的最优配置，缺乏对这种中间态的解析理解。因此，需要建立能刻画次优、结构化配置的理论框架。

Method: 提出一种平均场理论，通过分析拉格朗日乘子的局部涨落，在热力学极限下将具有强度约束的完整模型简化为一个有效的单约束问题，并在中间区域求得精确解。

Result: 发现自由能在耦合参数上是解析的，表明系统经历的是平滑交叉而非相变；推导出热力学可观测量和权重分布的闭式表达式，并通过数值模拟验证了结果。

Conclusion: 该工作建立了SOT模型的首个解析理论，揭示了熵与成本竞争下系统行为的本质特征，扩展了统计力学方法至非零温、非最优的现实情境。

Abstract: Statistical mechanics is a powerful framework for analyzing optimization yielding analytical results for matching, optimal transport, and other combinatorial problems. However, these methods typically target the zero-temperature limit, where systems collapse onto optimal configurations, a.k.a. the ground states. Real-world systems often occupy intermediate regimes where entropy and cost minimization genuinely compete, producing configurations that are structured yet sub-optimal. The Sub-Optimal Transport (SOT) model captures this competition through an ensemble of weighted bipartite graphs: a coupling parameter interpolates between entropy-dominated dense configurations and cost-dominated sparse structures. This crossover has been observed numerically but lacked analytical understanding. Here we develop a mean-field theory that characterizes this transition. We show that local fluctuations in Lagrange multipliers become sub-extensive in the thermodynamic limit, reducing the full model with strength constraints to an effective single-constraint problem admitting an exact solution in some intermediate regime. The resulting free energy is analytic in the coupling parameter, confirming a smooth crossover rather than a phase transition. We derive closed-form expressions for thermodynamic observables and weight distributions, validated against numerical simulations. These results establish the first analytical description of the SOT model, extending statistical mechanics methods beyond the zero-temperature regime.

</details>


### [20] [Critical behavior of isotropic systems with strong dipole-dipole interaction from the functional renormalization group](https://arxiv.org/abs/2602.04313)
*Georgii Kalagov,Nikita Lebedev*

Main category: cond-mat.stat-mech

TL;DR: 使用函数重正化群方法研究了具有强偶极相互作用的三维磁体的临界指数，发现其接近Heisenberg O(3)普适类但属于不同的普适类。


<details>
  <summary>Details</summary>
Motivation: 确定强偶极相互作用下三维磁体的普适类及其临界行为。

Method: 在局域势近似（包含波函数重正化，LPA′）框架内应用函数重正化群（FRG）方法。

Result: 识别出由Aharony固定点控制的标度不变但不具备共形不变性的系统，得到的临界指数与Heisenberg O(3)普适类相近但不同。

Conclusion: 强偶极相互作用的三维磁体属于一个独立的普适类，其临界行为虽数值上接近O(3)类，但本质不同。

Abstract: We compute the critical exponents of three-dimensional magnets with strong dipole-dipole interactions using the functional renormalization group (FRG) within the local potential approximation including the wave function renormalization (LPA$^\prime$). The system is governed by the Aharony fixed point, which is scale-invariant but lacks conformal invariance. Our nonperturbative FRG analysis identifies this fixed point and determines its scaling behavior. The resulting critical exponents are found to be close to those of the Heisenberg $O(3)$ universality class, as computed within the same FRG/LPA$^\prime$ framework. This proximity confirms the distinct yet numerically similar nature of the two universality classes.

</details>


### [21] [Area under subdiffusive random walks](https://arxiv.org/abs/2602.04342)
*Vicenç Méndez,Rosa Flaquer-Galmés,Javier Cristín*

Main category: cond-mat.stat-mech

TL;DR: 研究了亚扩散随机游走轨迹下面积和绝对面积的统计特性，通过不同框架分析并计算了前两阶矩、遍历性破坏参数，推导出概率密度函数的普适标度，并通过蒙特卡洛模拟验证理论结果。


<details>
  <summary>Details</summary>
Motivation: 理解亚扩散过程中轨迹下面积及其绝对值的统计行为，揭示不同亚扩散模型之间的差异及其在实验中的意义。

Method: 采用多种亚扩散描述框架（如缩放布朗运动、分数布朗运动、连续时间随机游走和非均匀介质中的布朗运动），计算面积与绝对面积的前两阶矩及遍历性破坏参数，归纳其概率密度函数的普适标度律。

Result: 得到了不同模型下面积和绝对面积的统计特性，发现其概率密度函数具有普适标度形式，各模型在遍历性和涨落性质上存在差异。

Conclusion: 不同亚扩散模型对面积类观测量的统计行为有显著影响，研究结果有助于解释实验中观测到的非遍历性和功能分布特征。

Abstract: We study the statistical properties of the area and the absolute area under the trajectories of subdiffusive random walks. Using different frameworks to describe subdiffusion (as the scaled Brownian motion, fractional Brownian motion, the continuous-time random walk or the Brownian motion in heterogeneous media), we compute the first two moments, the ergodicity breaking parameter for the absolute area and infer a general scaling for the probability density functions of these functionals. We discuss the differences between the statistical properties of the area and the absolute area for the different subdiffusion models and illustrate the experimental interest of our results. Our theoretical findings are supported by Monte Carlo simulations showing an excellent agreement.

</details>


### [22] [Population dynamics simulations of large deviations for three subclasses of the Kardar-Parisi-Zhang universality class](https://arxiv.org/abs/2602.04357)
*Yuta Yanagibashi,Kazumasa A. Takeuchi*

Main category: cond-mat.stat-mech

TL;DR: 通过基于群体动力学算法的数值方法研究了TASEP模型中时间积分局部电流的大偏差行为，揭示了不同初始条件下深层负大偏差区域的意外鲁棒性，并将其归因于界面形貌中楔形结构的自发形成。


<details>
  <summary>Details</summary>
Motivation: 尽管理论研究已加深了对一维KPZ普适类在大偏差区域的理解，但相应的数值方法仍然有限，特别是针对不同初始条件下的大偏差行为尚缺乏系统研究。

Method: 采用基于群体动力学算法的方法，模拟全不对称简单排斥过程（TASEP）中三种典型初始条件（step、flat和stationary）下时间积分局部电流的大偏差。

Result: 不仅验证了step初始条件下已有理论预测，还首次刻画了flat和stationary情况下的大偏差行为，发现深层负大偏差区域在不同初始条件下表现出意外的鲁棒性，这与界面形貌中自发形成的楔形结构有关。

Conclusion: 群体动力学方法为研究KPZ普适类中的大偏差提供了一种灵活且有效的数值工具，具有推广到其他系统甚至实验研究的潜力。

Abstract: Recent theoretical studies have gradually deepened our understanding of the one-dimensional (1D) Kardar-Parisi-Zhang (KPZ) universality class even in the large deviation regime, but numerical methods for studying KPZ large deviations remain limited. Here we implement a method based on the population dynamics algorithm for studying large deviations of time-integrated local currents in the totally asymmetric simple exclusion process (TASEP), which is a pragmatic model in the 1D KPZ class. Carrying out simulations for the three representative initial conditions, namely step, flat, and stationary ones, we not only confirm theoretical predictions available for the step case, but also characterize large deviations for the flat and stationary cases which have not been investigated before. We reveal in particular an unexpected robustness of the deeply negative large deviation regime with respect to different initial conditions. We attribute this robustness to the spontaneous formation of a wedge shape in interface profile. Our population dynamics approach may serve as a versatile method for studying large deviations in the KPZ class numerically and, potentially, even experimentally.

</details>


### [23] [Probabilities of rare events in product kernel aggregation: An exact formula and phase diagram](https://arxiv.org/abs/2602.04363)
*R. Goutham,R. Rajesh,V. Subashri,Oleg Zaboronski*

Main category: cond-mat.stat-mech

TL;DR: 本文提出了一种精确计算乘积核聚集过程中粒子数罕见涨落的大偏差函数的方法，通过主方程推导出概率的积分表达式，并利用复制假设扩展到实数指数，揭示了相变中的奇异性及三临界点。


<details>
  <summary>Details</summary>
Motivation: 为了精确描述乘积核聚集过程中粒子数的罕见涨落行为，现有方法缺乏对大偏差函数的精确解析结果。

Method: 从主方程出发，推导出有限M、N、t下粒子数概率P(M,N,t)的精确积分表示，进而获得整数p的指数矩⟨p^N⟩，并通过经数值验证的复制假设将其推广至实数p≥0，最后通过Legendre-Fenchel变换得到大偏差函数的凸包络。

Result: 得到了大偏差函数的精确表达式，发现其具有奇异结构，揭示了包含连续与不连续相变分界的三临界点，并给出了小N/M极限下LDF的渐近形式。

Conclusion: 该方法成功构建了乘积核聚集的完整相图，揭示了相变的丰富结构，为理解非平衡聚集过程中的极端涨落提供了新视角。

Abstract: We present an exact method for calculating the large deviation function describing rare fluctuations in the number of particles for product-kernel aggregation. Starting from the master equation, we derive an exact integral representation for the probability $P(M,N,t)$ of observing $N$ particles at time $t$ starting from $M$ monomers for any finite $M, N, t$. From this, we obtain an exact expression for the exponential moment $\langle p^N\rangle$ for integer $p$. Employing a replica conjecture -- numerically validated by finite-$M$ scaling -- we extend this result to real $p \geq 0$. The convex envelope of the large deviation function, obtained via a Legendre-Fenchel transform of the exponential moment, shows singular behavior. The singular structure allows us to construct the full phase diagram of product-kernel aggregation, which contains a tricritical point, separating continuous and discontinuous transitions. We also compute the asymptotic form of the LDF for small $N/M$.

</details>


### [24] [Control protocols for harmonically confined run-and-tumble particles](https://arxiv.org/abs/2602.04560)
*Marco Baldovin,Alessandro Manacorda*

Main category: cond-mat.stat-mech

TL;DR: 研究了在谐波约束势中运行和翻滚的活性粒子，通过提出一种新的动力学描述方法，探讨了在给定时间内实现系统状态转换的最优控制协议，并分析了最小平均功的实现路径。


<details>
  <summary>Details</summary>
Motivation: 为了理解和控制非平衡态活性物质系统，探索在有限时间内驱动系统从初始状态到目标状态的最优控制策略。

Method: 采用一种基于无限阶常微分方程组的动力学描述方法，通过对层级结构进行适当截断来近似求解，并结合数值模拟验证；在慢速但非准静态变换条件下进行解析分析。

Result: 提出了有效的控制协议设计方法，能够在规定时间内完成状态转移；找到了实现最小平均功的最优协议，并揭示了控制活性物质系统的最优策略。

Conclusion: 该研究为活性物质系统的外部控制提供了理论框架和直观洞见，尤其适用于长时间但非准静态的操作过程。

Abstract: Run-and-tumble particles constitute one of the simplest models of self-propelled active matter, and provide an ideal playground to the understanding of out-of-equilibrium systems. We consider an idealized setup where one such particle is subject to a harmonic confining potential, and an external agent can vary in time the tumbling rate and the strength of the trap. We search for time-dependent control protocols steering the system between assigned end states, in a prescribed time interval. To this aim, we propose a description of the dynamics, alternative to the usual ones, in the form of an infinite set of ordinary differential equations. Solutions based on a suitable closure of such hierarchy, which we expect to hold true in the limit of long protocol duration, are discussed and compared with numerical simulations. We also look for the protocol completing the task with the minimal work, on average: the problem can be tackled analytically, again in the regime of slow (but not quasi-static) transformations. The solution provides insightful intuition on the optimal strategies for the control of active matter systems.

</details>


### [25] [Emergent Hawking Radiation and Quantum Sensing in a Quenched Chiral Spin Chain](https://arxiv.org/abs/2602.04593)
*Nitesh Jaiswal,S. Shankaranarayanan*

Main category: cond-mat.stat-mech

TL;DR: 研究了1D手性自旋链模型中霍金辐射的产生与探测，通过量子淬火模拟引力坍缩并引发视界相变，结合场论模式与量子传感器方法分析辐射谱特征，提出了在量子模拟平台中区分真实类比霍金辐射与环境噪声的操作方案。


<details>
  <summary>Details</summary>
Motivation: 探索在不满足Hoop猜想条件下黑洞形成后霍金辐射的出现机制及其可观测性，特别是在低维量子系统中实现类比引力效应的可行性。

Method: 将自旋链动力学映射到(1+1)维弯曲时空中的狄拉克费米子，采用局域高斯波包和耦合比特作为两种探测手段，分别从场论和量子传感角度分析辐射谱特性。

Result: 发现辐射谱偏离理想普朗克形式但保持泊松统计；弱耦合下qubit可准确响应霍金温度，强耦合下则与全局环境热化而掩盖信号。

Conclusion: 提出了一种可行的操作协议，可用于在量子模拟中识别真实的类比霍金辐射并排除环境干扰。

Abstract: We investigate the emergence and detection of Hawking radiation (HR) in a 1D chiral spin chain model, where the gravitational collapse is simulated by a sudden quantum quench that triggers a horizon-inducing phase transition. While our previous work Jaiswal [2025] established that this model mimics BH formation conditions even when the Hoop conjecture is seemingly violated, we here focus on the resulting stationary radiation spectrum and its detectability. By mapping the spin chain dynamics to a Dirac fermion in a curved (1 + 1)-dimensional spacetime, we analyze the radiation using two complementary approaches: field-theoretic modes and operational quantum sensors. First, using localized Gaussian wave packets to model realistic detectors, we find that the radiation spectrum exhibits deviations from the ideal Planckian form, analogous to frequency-dependent greybody factors, while retaining robust Poissonian statistics that signal the loss of formation-scale information. Second, we introduce a qubit coupled to the chain as a stationary Unruh-DeWitt detector. We demonstrate that the qubit functions as a faithful quantum sensor of the Hawking temperature only in the weak-coupling regime, where its population dynamics are governed solely by the bath spectral density. In the strong-coupling limit, the probe thermalizes with the global environment, obscuring the horizon-induced thermal signature. These results provide a clear operational protocol for distinguishing genuine analog HR from environmental noise in quantum simulation platforms.

</details>


### [26] [The Most Dispersed Subset of Random Points in $\mathbb{R}^d$](https://arxiv.org/abs/2602.04626)
*Fabio Deelan Cunden,Noemi Cuppone,Giovanni Gramegna,Pierpaolo Vivo*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了从N个个体中选择M个个体使得其d个特征的分散度最大化的统计特性，提出了基于顺序统计的平均场理论和无序系统中的副本方法两种互补的方法，并在各种维度和旋转对称分布下得出了最优子集的性质。


<details>
  <summary>Details</summary>
Motivation: 为了理解在多特征情况下如何选择最分散的子群体，特别是在大规模人群中，需要发展新的理论工具来解析计算最大可实现分散度的完整统计特性。

Method: 采用基于顺序统计的平均场理论和来自无序系统领域的副本方法两种互补的方法进行分析。

Result: 对于所有维度d和旋转对称分布，大群体中的最优子集由位于d维球体外的所有点组成，球体半径自洽确定；对于单个特征(d=1)，还可以处理有限N,M的情况。所得公式通过小规模实例的数值模拟和寻找近似最优解的启发式算法得到验证。

Conclusion: 提出的理论框架能够准确描述大规模人群中多特征分散度的最大化问题，且适用于不同维度和分布情况，为相关领域提供了重要的理论基础。

Abstract: Consider a population of $N$ individuals, each having $d\geq 1$ different traits, and an additive measure, called dispersion, which rewards large pairwise separations between traits. The goal is to select $M\leq N$ individuals such that their traits are as dispersed as possible. We compute analytically the full statistics (including large deviation tails) of the maximally achievable dispersion among sub-populations of size $M$ when the traits are independent and identically distributed. Two complementary approaches are developed, one based on a mean-field theory for order statistics, and the other on the replica method from the field of disordered systems. In all dimensions $d$, and for rotationally symmetric distributions, the optimal subset for large populations consists of all points lying outside a $d$-dimensional ball whose radius is determined self-consistently. For a single trait ($d=1$), the statistics of the maximal dispersion can be tackled for finite $N,M$ as well. The formulae we obtained are corroborated by numerical simulations on small instances and by heuristic algorithms that find near-optimal solutions.

</details>


### [27] [Site and bond percolation in linearly distorted triangular and square lattices](https://arxiv.org/abs/2602.04818)
*Bishnu Bhowmik,Sayantan Mitra,Robert M. Ziff,Ankur Sensharma*

Main category: cond-mat.stat-mech

TL;DR: 研究了线性畸变下三角形和正方形晶格中的位点和键渗流，发现三角晶格表现出显著的方向依赖性，而正方晶格在畸变下保持有效各向同性。


<details>
  <summary>Details</summary>
Motivation: 探讨传统晶格几何保持型畸变之外的线性畸变对渗流阈值的影响，揭示畸变诱导的各向异性对渗流行为的作用机制。

Method: 采用蒙特卡洛模拟和有限尺寸标度分析，研究不同畸变参数和连接阈值下位点与键渗流阈值的变化规律。

Result: 三角晶格中渗流阈值表现出显著方向依赖性和临界连接阈值变化，键渗流行为不能仅由平均配位数解释；正方晶格在不同畸变方向下渗流阈值相同，保持各向同性。

Conclusion: 线性畸变通过改变最近邻距离导致各向异性，显著影响三角晶格的渗流性质，而对正方晶格影响较小，有限系统模拟结果能可靠反映热力学极限下的行为。

Abstract: We investigate site and bond percolation in triangular and square lattices subjected to linear distortion. In contrast to previously studied distortion schemes that preserve lattice geometry, linear distortion dislocates regular lattice sites along a fixed direction. Nearest-neighbors of a regular lattice need to satisfy a distance-based connection criterion to remain neighbors in the linearly distorted lattice. Using extensive Monte Carlo simulations and finite-size scaling analyses, we examine how site and bond percolation thresholds vary with the distortion parameter and the connection threshold. For triangular lattices, we observe pronounced directional dependence of both site and bond percolation thresholds, as well as of the critical connection threshold. This arises from the distortion-induced anisotropic modification of nearest-neighbor separations. In particular, bond percolation exhibits nontrivial behavior that cannot be explained solely in terms of changes in the average coordination number. In contrast, square lattices remain effectively isotropic under linear distortion, resulting in identical percolation thresholds for distortions applied along different directions. Percolation thresholds in the thermodynamic limit, evaluated for a selected set of values of distortion parameter and connection threshold, confirm that the results for large finite lattices provide reliable estimates of the infinite-system behavior.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [28] [Detailed, interpretable characterization of mid-circuit measurement on a transmon qubit](https://arxiv.org/abs/2602.03938)
*Piper C. Wysocki,Luke D. Burkhart,Madeline H. Morocco,Corey I. Ostrove,Riley J. Murray,Tristan Brown,Jeffrey M. Gertler,David K. Kim,Nathan E. Miller,Bethany M. Niedzielski,Katrina M. Sliwa,Robin Blume-Kohout,Gabriel O. Samach,Mollie E. Schwartz,Kenneth M. Rudinger*

Main category: quant-ph

TL;DR: 本文提出了一种基于误差生成器形式化的方法来分析中程量子测量（MCM）中的误差机制，并在transmon量子比特上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 中程测量（MCM）是实现量子纠错的关键，但实验估计的量子仪器难以解释或与物理机制关联。需要一种可解释的误差分析框架。

Method: 将先前用于解读噪声量子门的误差生成器形式化方法扩展到MCM，使用量子仪器模型并结合门集层析进行自洽表征，进而分解出具有物理意义的基本误差项。

Result: 在transmon量子比特上成功识别并量化了包括幅度阻尼、读出误差和坍缩不完全在内的多种误差机制；发现这些误差随读出脉冲幅度变化，并通过一个仅含少数参数的简化模型即可有效描述实验观测。

Conclusion: 误差生成器框架可用于有效解析MCM中的物理误差来源，为优化量子测量和纠错协议提供了可解释、实用的工具。

Abstract: Mid-circuit measurements (MCMs) are critical components of the quantum error correction protocols expected to enable utility-scale quantum computing. MCMs can be modeled by quantum instruments (a type of quantum operation or process), which can be characterized self-consistently using gate set tomography. However, experimentally estimated quantum instruments are often hard to interpret or relate to device physics. We address this challenge by adapting the error generator formalism -- previously used to interpret noisy quantum gates by decomposing their error processes into physically meaningful sums of "elementary errors" -- to MCMs. We deploy our new analysis on a transmon qubit device to tease out and quantify error mechanisms including amplitude damping, readout error, and imperfect collapse. We examine in detail how the magnitudes of these errors vary with the readout pulse amplitude, recover the key features of dispersive readout predicted by theory, and show that these features can be modeled parsimoniously using a reduced model with just a few parameters.

</details>


### [29] [Correlation-Enabled Beatings in Two-Dimensional Electronic Spectroscopy](https://arxiv.org/abs/2602.04061)
*Sirui Chen,Dragomir Davidović*

Main category: quant-ph

TL;DR: 本文提出了一种由相关性驱动的机制，解释了二维电子光谱中长期存在的振荡现象，强调了慢速浴记忆和超快脉冲序列在维持相干性中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 为了解释标准激子开放系统模型难以说明的二维电子光谱中长寿命拍频现象。

Method: 通过理论分析和模型推导，研究慢浴记忆和超快脉冲序列对系统-浴相关性传播的影响。

Result: 发现持久拍频可由相关性驱动机制产生，该机制依赖于慢浴记忆和超快脉冲序列，能够在无场演化期间激活非对角项的布居-相干转换。

Conclusion: 长寿命拍频应被重新理解为一种协议层面的动力学效应，即在超快控制下的相关介导检索过程。

Abstract: Long-lived beatings in two-dimensional electronic spectroscopy (2DES) remain difficult to interpret within standard excitonic open-system models, which typically assume factorized initialization and predict rapid coherence decay. We show that persistent beatings can arise from a correlation-driven mechanism that requires both slow bath memory and ultrafast pulse sequences that propagate system-bath correlations across optical interactions. In this regime, the pulse sequence unitarily dresses the bath-memory contribution and activates nonsecular population-coherence transfer during field-free evolution, sustaining coherence signatures far beyond factorized or weak-memory descriptions. Rather than addressing what is oscillating (excitonic versus vibronic) or quantum-versus-classical semantics, this work reframes long-lived beatings as a protocol-level dynamical effect: correlation-mediated retrieval under ultrafast control.

</details>


### [30] [Data Verification is the Future of Quantum Computing Copilots](https://arxiv.org/abs/2602.04072)
*Junhao Song,Ziqian Bi,Xinliang Chia,William Knottenbelt,Yudong Cao*

Main category: quant-ph

TL;DR: 本文主张在量子计算和AI4Research领域，应将验证机制从事后补充提升为AI架构的基础组成部分，以应对大语言模型在生成量子程序时因统计推理导致的不可避免的错误。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型在生成量子程序时存在数学上不可避免的幻觉问题，导致生成结果不可行，因此需要优先考虑具备验证能力的架构来确保生成内容的正确性。

Method: 提出三个核心观点：使用经过验证的训练数据使模型学习精确约束；在生成过程中嵌入验证以限制输出空间；在受物理规律约束的领域中将验证作为架构基本单元。并通过早期实验对比未验证数据下LLM在电路优化中的表现。

Result: 实验显示，未经验证数据训练的LLM在电路优化任务中最高准确率仅为79%，验证机制对提升生成正确性至关重要。

Conclusion: 为实现可靠的AI驱动科研与量子编程，必须将验证内置于AI系统架构之中，而非仅作为后期过滤手段。

Abstract: Quantum program generation demands a level of precision that may not be compatible with the statistical reasoning carried out in the inference of large language models (LLMs). Hallucinations are mathematically inevitable and not addressable by scaling, which leads to infeasible solutions. We argue that architectures prioritizing verification are necessary for quantum copilots and AI automation in domains governed by constraints. Our position rests on three key points: verified training data enables models to internalize precise constraints as learned structures rather than statistical approximations; verification must constrain generation rather than filter outputs, as valid designs occupy exponentially shrinking subspaces; and domains where physical laws impose correctness criteria require verification embedded as architectural primitives. Early experiments showed LLMs without data verification could only achieve a maximum accuracy of 79% in circuit optimization. Our positions are formulated as quantum computing and AI4Research community imperatives, calling for elevating verification from afterthought to architectural foundation in AI4Research.

</details>


### [31] [Influence of Noninertial Dynamics on Static Quantum Resource Theories](https://arxiv.org/abs/2602.04199)
*Saveetha Harikrishnan,Tim Byrnes,Chandrashekar Radhakrishnan*

Main category: quant-ph

TL;DR: 研究了非惯性动力学对静态量子资源理论的影响，揭示了非惯性效应与完全正定迹保持映射之间的等价性，并分析了该映射对量子资源理论核心要素的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨在非惯性系中量子资源理论如何受到相对论效应（如Unruh效应）的影响，以扩展量子信息理论在弯曲时空或加速参考系中的适用性。

Method: 通过将非惯性效应建模为完全正定迹保持（CPTP）映射，分析其对自由态、自由操作和资源量化器这三个资源理论核心成分的影响，其中Unruh效应被等效为玻色放大信道。

Result: 建立了非惯性效应与CPTP映射之间的等价关系，明确了Unruh效应对应于玻色放大信道，并得出了关于非惯性运动下资源理论各组成部分的一般性结论。

Conclusion: 非惯性运动可通过CPTP映射有效描述，这对理解相对论环境下量子资源的演化和保护具有重要意义。

Abstract: The effect of noninertial dynamics on static quantum resource theories is investigated. To this end, we first show the equivalence between noninertial effects and a completely positive, trace-preserving (CPTP) map. In this formulation, the Unruh effect is equivalent to a bosonic amplifier channel. The effect of this map on a generic quantum resource is investigated by studying the role of the CPTP map on the three core ingredients of a resource theory, namely, the free states, the free operations and the resource quantifiers. We show several general statements can be made about these three components of a resource theory in the presence of noninertial motion.

</details>


### [32] [Constructing Compact ADAPT Unitary Coupled-Cluster Ansatz with Parameter-Based Criterion](https://arxiv.org/abs/2602.04253)
*Runhong He,Xin Hong,Qiaozhen Chai,Ji Guan,Junyuan Zhou,Arapat Ablimit,Guolong Cui,Shenggang Ying*

Main category: quant-ph

TL;DR: 提出Param-ADAPT-VQE算法，通过参数化准则选择激发算子并结合子哈密顿技术和热启动策略，有效减少冗余和测量成本，提升分子基态能量计算的效率与可扩展性。


<details>
  <summary>Details</summary>
Motivation: ADAPT-VQE在分子基态能量计算中具有良好前景，但存在激发算子冗余和测量成本过高的问题，限制了其实际可扩展性。

Method: 采用基于参数的选择准则替代传统的梯度准则来筛选激发算子，引入子哈密顿技术，并结合热启动VQE优化策略，降低电路深度和测量次数。

Result: 在典型分子体系上的数值实验表明，Param-ADAPT-VQE在计算精度、ansatz规模和测量成本方面均优于原始ADAPT-VQE。

Conclusion: Param-ADAPT-VQE显著提升了ADAPT-VQE的效率与可扩展性，保留了其框架兼容性，为量子化学中的实际应用提供了可行的改进方案。

Abstract: The adaptive derivative-assembled pseudo-trotter variational quantum eigensolver (ADAPT-VQE) is a promising hybrid quantum-classical algorithm for molecular ground state energy calculation, yet its practical scalability is hampered by redundant excitation operators and excessive measurement costs. To address these challenges, we propose Param-ADAPT-VQE, a novel improved algorithm that selects excitation operators based on a parameter-based criterion instead of the traditional gradient-based metric. This strategy effectively eludes redundant operators. We further develop a sub-Hamiltonian technique and integrate a hot-start VQE optimization strategy, achieving a significant reduction in measurement costs. Numerical experiments on typical molecular systems demonstrate that Param-ADAPT-VQE outperforms the original ADAPT-VQE in computational accuracy, ansatz size, and measurement costs. Furthermore, our scheme retains the fundamental framework of ADAPT-VQE and is thus fully compatible with its various modified versions, enabling further performance improvements in specific aspects. This work presents an efficient and scalable enhancement to ADAPT-VQE, mitigating the core obstacles that impede its practical implementation in the field of molecular quantum chemistry.

</details>


### [33] [Canonical Quantization of Cylindrical Waveguides: A Gauge-Based Approach](https://arxiv.org/abs/2602.04295)
*Alexandre Delattre,Eddy Collin*

Main category: quant-ph

TL;DR: 提出了一种基于规范场的正则量子化方法，用于分析圆柱波导中的电磁模式，统一了笛卡尔和圆柱几何下导模的处理框架，并为TM、TE等模式定义了可测量的量子算符。


<details>
  <summary>Details</summary>
Motivation: 扩展此前在笛卡尔几何中发展的规范场量子化方法至圆柱波导，以统一处理不同几何结构下的导行电磁模式，并为复杂模式（如TM、TE）提供清晰的量子描述。

Method: 引入TEM、TM和TE行波模式的两个场正交分量X、Y，构造满足Klein-Gordon型方程的一维标量广义磁通φ；通过麦克斯韦方程组导出哈密顿量，构建玻色子升降算符，并从电磁势A、V出发，在特定规范下推导广义磁通。

Result: 成功将圆柱波导中的各种模式纳入统一的量子化框架，导出了模式特有的电容与电感参数，并用电学中的电压、电流表示了正则场变量，使非平凡模式（如TM、TE）的可观测量得以明确定义。

Conclusion: 该形式体系为圆柱与笛卡尔波导提供了通用且一致的量子化方法，具有理论深度与实验应用价值，未来可推广至片上共面波导等其他结构，助力量子技术发展。

Abstract: We present a canonical quantization of electromagnetic modes in cylindrical waveguides, extending a gauge-based formalism previously developed for Cartesian geometries [1]. By introducing the two field quadratures $X,Y$ of TEM (transverse electric-magnetic), but also of TM (transverse magnetic) and TE (transverse electric) traveling modes, we identify for each a characteristic one-dimensional scalar field (a generalized flux $\varphi$) governed by a Klein-Gordon type equation. The associated Hamiltonian is derived explicitly from Maxwell's equations, allowing the construction of bosonic ladder operators. The generalized flux is directly deduced from the electromagnetic potentials $A,V$ by a proper gauge choice, generalizing Devoret's approach [2]. Our analysis unifies the treatment of cylindrical and Cartesian guided modes under a consistent and generic framework, ensuring both theoretical insight and experimental relevance. We derive mode-specific capacitance and inductance from the field profiles and express voltage and current in terms of the canonical field variables. Measurable quantities are therefore properly defined from the mode quantum operators, especially for the non-trivial TM and TE ones. The formalism shall extend in future works to any other type of waveguides, especially on-chip coplanar geometries particularly relevant to quantum technologies.

</details>


### [34] [Locally Gentle State Certification for High Dimensional Quantum Systems](https://arxiv.org/abs/2602.04550)
*Cristina Butucea,Jan Johannes,Henning Stein*

Main category: quant-ph

TL;DR: 本文研究了在量子态微扰约束下的局部温和量子态验证问题，推导出非破坏性测量的信息论代价，并揭示了信息提取与状态扰动之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 探索量子统计推断中非破坏性测量的基本极限，特别是在允许重复使用量子样本的场景下。

Method: 通过构建显式的测量算子，分析判断未知量子态是否等于参考态或与其相差ε的问题，计算其极小极大样本复杂度。

Result: 证明了α-温和性约束带来d/α²的样本量惩罚，总样本复杂度为n = Θ(d³/(ε²α²))，且惩罚项随希尔伯特空间维度d线性增长而非参数数量d²−1。

Conclusion: 结果阐明了物理测量限制与量子学习中隐私机制之间的深刻联系，表明在高维空间中实现非破坏性学习的代价低于传统私有估计预期。

Abstract: Standard approaches to quantum statistical inference rely on measurements that induce a collapse of the wave function, effectively consuming the quantum state to extract information. In this work, we investigate the fundamental limits of \emph{locally-gentle} quantum state certification, where the learning algorithm is constrained to perturb the state by at most $α$ in trace norm, thereby allowing for the reuse of samples. We analyze the hypothesis testing problem of distinguishing whether an unknown state $ρ$ is equal to a reference $ρ_0$ or $ε$-far from it. We derive the minimax sample complexity for this problem, quantifying the information-theoretic price of non-destructive measurements. Specifically, by constructing explicit measurement operators, we show that the constraint of $α$-gentleness imposes a sample size penalty of $\frac{d}{α^2}$, yielding a total sample complexity of $n = Θ(\frac{d^3}{ε^2 α^2})$. Our results clarify the trade-off between information extraction and state disturbance, and highlight deep connections between physical measurement constraints and privacy mechanisms in quantum learning. Crucially, we find that the sample size penalty incurred by enforcing $α$-gentleness scales linearly with the Hilbert-space dimension $d$ rather than the number of parameters $d^2-1$ typical for high-dimensional private estimation.

</details>


### [35] [Does the entropy of systems with larger internal entanglement grow stronger?](https://arxiv.org/abs/2602.04345)
*Daria Gaidukevich*

Main category: quant-ph

TL;DR: 研究了量子系统内部纠缠与熵增长的关系，发现平均而言内部纠缠更大的系统熵增长更强，但特定条件下可能相反，且纠缠深度对熵增长有较小贡献。


<details>
  <summary>Details</summary>
Motivation: 探讨系统内部纠缠是否会导致其与环境相互作用时熵增长更强。

Method: 使用由量子谐振子描述环境的量子比特系统作为最简单模型，通过模拟一组随机态进行统计分析。

Result: 平均来看，内部纠缠更大的系统熵增长更强，但在某些特定状态下该关系可能反转；同时发现纠缠深度对熵增长有轻微影响。

Conclusion: 系统内部纠缠程度与其熵增长之间存在统计上的正相关关系，但该关系受具体状态选择的影响，不具有绝对普适性。

Abstract: It is known that when a system interacts with its environment, the entanglement contained in the system is redistributed since parts of the system entangle with the environment. On the other hand, the entanglement of a system with its environment is closely related to the entropy of the system. However, does this imply that the entropy of systems with larger internal entanglement will grow stronger? We study the issue using the simplest model as an example: a system of qubits interacts with the environment described by the quantum harmonic oscillator. The answer to the posed question is ambiguous. However, the study of the situation on average (using the simulation of a set of random states) reveals certain patterns and we can say that the answer is affirmative. At the same time, the choice of states satisfying certain conditions in some cases can change the dependence to the opposite. Additionally, we show that the entanglement depth also makes a small contribution to entropy growth.

</details>


### [36] [Vistas of Algebraic Probability: Quantum Computation and Information](https://arxiv.org/abs/2602.04351)
*Antonio Falcó,Hermann G. Matthies*

Main category: quant-ph

TL;DR: 本文介绍了基于代数观点的概率论框架，该框架通过随机变量代数和态（期望）的线性泛函来统一描述经典与量子类现象，强调非交换性是区分二者的关键，并指出其在量子计算等领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统Kolmogorov概率框架在处理量子效应或量子类现象时存在局限，因此需要一种更广泛的代数方法以统一描述经典与量子类随机现象，并为经典概率和不确定性量化提供新视角。

Method: 采用代数概率框架，从随机变量代数和作为期望的状态（线性泛函）出发，聚焦有限维代数以避免复杂的分析细节，同时保留核心思想及其在经典极限与量子类模型中的适用性。

Result: 该代数框架能够统一容纳经典与量子类行为，揭示非交换性是产生量子类现象特征效应的关键因素，并展示了其在量子计算等计算科学领域中的潜在应用价值。

Conclusion: 代数概率方法不仅为经典和量子类现象提供了统一且清晰的基础，还为计算科学中涉及量子技术的问题带来了新的理论工具和结构洞见。

Abstract: Kolmogorov's foundation of probability takes measure spaces, $σ$-algebras, and probability measures as basic objects. It is, however, widely recognized that this classical framework is inadequate for random phenomena involving quantum effects, and more generally for \emph{quantum-like} situations. A broader formulation is provided by an algebraic viewpoint: one starts from an algebra of random variables equipped with a distinguished linear functional -- the \emph{state} -- interpreted as expectation. In this sense, the approach can also be viewed as a modern reading of ideas already implicit in early probability (e.g., the Bernoullis), while its contemporary form has been developed and used extensively in quantum physics.
  The algebraic framework accommodates both classical and quantum-like behaviours, yet it remains underused in classical probability and uncertainty quantification, where it can nevertheless open new perspectives and clarify structural features. Although the language carries a physics flavor, the subject is purely probabilistic. The key distinction between classical and quantum-like behaviour is \emph{commutativity}: its failure produces the characteristic effects of quantum-like situations. The rise of quantum computing is a prominent setting in which such behaviour may become relevant even for practitioners in computational science. Here we focus on the purely algebraic core of the approach. By restricting attention to finite-dimensional algebras, we avoid many analytical subtleties while retaining the main ideas, their classical limit, and their applicability to quantum-like models and quantum computation.

</details>


### [37] [Low resource entanglement classification from neural network interpretability](https://arxiv.org/abs/2602.04366)
*A. García-Velo,R. Puebla,Y. Ban,E. Torrontegui,M. Paraschiv*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Entanglement is a central resource in quantum information and quantum technologies, yet its characterization remains challenging due to both theoretical complexity and measurement requirements. Machine learning has emerged as a promising alternative, enabling entanglement characterization from incomplete measurement data, however model interpretability remains a challenge. In this work, we introduce a unified and interpretable framework for SLOCC entanglement classification of two- and three-qubit states, encompassing both pure and mixed states. We train dense and convolutional neural networks on Pauli-measurement outcomes, provide design guidelines for each architecture, and systematically compare their performance across types of states. To interpret the models, we compute Shapley values to quantify the contribution of each measurement, analyze measurement-importance patterns across different systems, and use these insights to guide a measurement-reduction scheme. Accuracy-versus-measurement curves and comparisons with analytical entanglement criteria demonstrate the minimal resources required for reliable classification and highlight both the capabilities and limitations of Shapley-based interpretability when using machine learning models for entanglement detection and classification.

</details>


### [38] [Limitations of an approximative phase-space description in strong-field quantum optics](https://arxiv.org/abs/2602.04370)
*Rasmus Vesterager Gothelf,Lars Bojer Madsen,Christian Saugbjerg Lange*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In recent years, strong-field processes such as high-order harmonic generation (HHG) and above-threshold ionization driven by nonclassical states of light have become an increasingly popular field of study. The theoretical modeling of these processes often applies an approximate phase-space expansion of the nonclassical driving field in terms of coherent states, which has been shown to accurately predict the harmonic spectrum. However, its accuracy for the computation of quantum optical observables like the degree of squeezing and photon statistics has not been thoroughly considered. In this work, we introduce this approximative phase-space description and discuss its accuracy, and we find that it mischaracterizes the quantum optical properties of the driving laser by making it an incoherent mixture of classical states. We further show that this error in the driving field description maps onto the light emitted from HHG, as neither sub-Poissonian photon statistics nor quadrature squeezing below vacuum fluctuations can be captured by the approximative phase-space description. Lastly, to benchmark the approximative phase-space description, we consider the quantum HHG from a one-band model, which yields an exact analytical solution. Using the approximative phase-space representation with this specific model, we find a small quantitative error in the quadrature variance of the emitted field that scales with pulse duration and emitter density. Our results show that using this approximative phase-space description can mischaracterize quantum optical observables. Attributing physical meaning to such results should therefore be accompanied by a quantitative analysis of the error.

</details>


### [39] [Squeezing Enhanced Sagnac Sensing based on SU(1,1) Quantum Interference](https://arxiv.org/abs/2602.04394)
*Michal Natan,Saar Levin,Avi Pe'er*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a simple and robust design for a squeezing-enhanced Sagnac interferometer that employs the concept of SU(1,1) interference to significantly surpass the classical sensitivity limit (shot-noise limit - SNL) in rotational sensing. By strategically placing an optical parametric amplifier (OPA) inside the Sagnac loop, light is automatically squeezed in both forward and backward directions of the loop, which enhances the detectability of a small phase. For measuring the squeezed quadrature, we explore two approaches: Direct detection of the output intensity, which is simple, but requires a high-efficiency photo-detector; and parametric homodyne with an additional OPA, which accepts practical detectors with no efficiency limitation, but is technically more complex. Our analysis demonstrates super-classical sensitivity under most realistic conditions of loss and detector inefficiency, thereby leveraging the resources of squeezing and the principles of SU(1,1) interference, while maintaining compatibility with standard Sagnac configurations.

</details>


### [40] [Qudit Twisted-Torus Codes in the Bivariate Bicycle Framework](https://arxiv.org/abs/2602.04443)
*Mourad Halla*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study finite-length qudit quantum low-density parity-check (LDPC) codes from translation-invariant CSS constructions on two-dimensional tori with twisted boundary conditions. Recent qubit work [PRX Quantum 6, 020357 (2025)] showed that, within the bivariate-bicycle viewpoint, twisting generalized toric patterns can significantly improve finite-size performance as measured by $k d^{2}/n$. Here $n$ denotes the number of physical qudits, $k$ the number of logical qudits, and $d$ the code distance. Building on this insight, we extend the search to qudit codes over finite fields. Using algebraic methods, we compute the number of logical qudits and identify compact codes with favorable rate--distance tradeoffs. Overall, for the finite sizes explored, twisted-torus qudit constructions typically achieve larger distances than their untwisted counterparts and outperform previously reported twisted qubit instances. The best new codes are tabulated.

</details>


### [41] [Review of Superconducting Qubit Devices and Their Large-Scale Integration](https://arxiv.org/abs/2602.04831)
*Hiu Yung Wong*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The superconducting qubit quantum computer is one of the most promising quantum computing architectures for large-scale integration due to its maturity and close proximity to the well-established semiconductor manufacturing infrastructure. From an education perspective, it also bridges classical microwave electronics and quantum electrodynamics. In this paper, we will review the basics of quantum computers, superconductivity, and Josephson junctions. We then introduce important technologies and concepts related to DiVincenzo's criteria, which are the necessary conditions for the superconducting qubits to work as a useful quantum computer. Firstly, we will discuss various types of superconducting qubits formed with Josephson junctions, from which we will understand the trade-off across multiple design parameters, including their noise immunity. Secondly, we will discuss different schemes to achieve entanglement gate operations, which are a major bottleneck in achieving more efficient fault-tolerant quantum computing. Thirdly, we will review readout engineering, including the implementations of the Purcell filters and quantum-limited amplifiers. Finally, we will discuss the nature and review the studies of two-level system defects, which are currently the limiting factor of qubit coherence time. DiVincenzo's criteria are only the necessary conditions for a technology to be eligible for quantum computing. To have a useful quantum computer, large-scale integration is required. We will review proposals and developments for the large-scale integration of superconducting qubit devices. By comparing with the application of electronic design automation (EDA) in semiconductors, we will also review the use of EDA in superconducting qubit quantum computer design, which is necessary for its large-scale integration.

</details>


### [42] [Influence of environment on quantum correlations in two-spin systems with dipole-dipole interactions](https://arxiv.org/abs/2602.04444)
*G. A. Bochkin,E. B. Fel'dman,E. I. Kuznetsova,E. I. Shipulya*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: An influence of environment on quantum correlations (entanglement and quantum discord) is studied in a two-spin-1/2 system with dipole-dipole interactions on the basis of Lindblad equation. We consider the simplest case when the environment causes only dephasing of system spins. The dependencies of entanglement and the quantum discord on the relaxation rate are obtained. We compare the influence of the environment on entanglement and quantum discord.

</details>


### [43] [Optimal Control Design Guided by Adam Algorithm and LSTM-Predicted Open Quantum System Dynamics](https://arxiv.org/abs/2602.04480)
*JunDong Zhong,ZhaoMing Wang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The realization of high-fidelity quantum control is crucial for quantum information processing, particularly in noisy environments where control strategies must simultaneously achieve precise manipulation and effective noise suppression. Conventional optimal control designs typically requires numerical calculations of the system dynamics. Recent studies have demonstrated that long short-term memory neural networks (LSTM-NNs) can accurately predict the time evolution of open quantum systems. Based on LSTM-NN predicted dynamics, we propose an optimal control framework for rapid and efficient optimal control design in open quantum systems. As an exemplary example, we apply our scheme to design an optimal control for the adiabatic speedup in a two-level system under a non-Markovian environment. Our optimization procedure entails two steps: driving trajectory optimization and zero-area pulse optimization. Fidelity improvement for both steps have been obtained, showing the effectiveness of the scheme. Our optimal control design scheme utilizes predicted dynamics to generate optimized controls, offering broad application potential in quantum computing, communication, and sensing.

</details>


### [44] [Squeezing-Enhanced Rotational Doppler Metrology](https://arxiv.org/abs/2602.04508)
*Javier Navarro,Mateo Casariego,Gabriel Molina-Terriza,Íñigo Luis Egusquiza,Mikel Sanz*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A rotating surface can induce a frequency shift in incident light by changing its angular momentum, a phenomenon known as the rotational Doppler effect. This effect provides a means to estimate the angular velocity of the rotating surface. In this work, we develop a continuous-variable quantum protocol for estimating the angular velocity of a rotating surface via the rotational Doppler effect. Our approach exploits squeezed and displaced Laguerre-Gaussian modes as quantum resources, which interact with a rotating metallic disc with surface roughness. The frequency shift induced by the rotational Doppler effect is then measured using a homodyne detection scheme. By analyzing the Fisher information, we demonstrate that the proposed squeezing-enhanced protocol achieves Heisenberg scaling in the ideal noiseless regime. Furthermore, we investigate the influence of noise and consider different surface models to assess their impact on the protocol's performance. While Heisenberg scaling is degraded in the presence of noise, we show that optimizing the energy allocation ratio between displacement and squeezing of the probe ensures that the quantum strategy consistently outperforms its classical counterpart.

</details>


### [45] [A simple means for deriving quantum mechanics](https://arxiv.org/abs/2602.04524)
*Eric Tesse*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A type of mechanics will be presented that possesses some distinctive properties. On the one hand, its physical description & rules of operation are readily comprehensible & intuitively clear. On the other, it fully satisfies all observable predictions of non-relativistic quantum mechanics. Within it, particles exist at points in space, follow continuous, piecewise differentiable paths, and their linear momentum is equal to their mass times their velocity along their path. Yet the probabilities for position and momentum, conditioned on the state of the particle's environment, follow the rules of quantum theory. Indeed, all observable consequences of quantum theory are satisfied; particles can be entangled, have intrinsic spin, this spin is not local to the particle, particle identity can effect probabilities, and so forth. All the rules of quantum mechanics are obeyed, and all arise in a straightforward fashion. After this is established, connections will be drawn out between this type of mechanics and other types of quantum worlds; those that obey Bohmian mechanics, stochastic mechanics, the many worlds interpretation, and physical collapse. In the final section, a relativistic version of the mechanics will be presented.

</details>


### [46] [Thermodynamic Cost of Regeneration in a Quantum Stirling Cycle](https://arxiv.org/abs/2602.04538)
*Ferdi Altintas*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the regenerative quantum Stirling heat engine cycle within the standard weak-coupling, Markovian open quantum system framework. We point out that the regeneration process is not thermodynamically free in a reduced open-system description, and we treat the required work input as an explicit regeneration cost by modifying the cycle efficiency accordingly. We consider two working substances--a single spin-$1/2$ and a pair of interacting spin-$1/2$ particles--and investigate the cycle performance by taking the regeneration cost at its minimum value set by the Carnot heat-pump limit. For comparison, we also analyze the conventional Stirling cycle without regeneration under the same conditions. The super-Carnot efficiencies reported under the cost-free regeneration assumption disappear once the regeneration cost is included: the modified efficiency stays below the Carnot bound, while still remaining higher than the efficiency of the conventional Stirling cycle. For the conventional Stirling cycle, we provide a rigorous Carnot bound using quantum relative entropy, whereas for the regenerative cycle we derive a sufficient lower bound on the regeneration cost that guarantees thermodynamic consistency. Finally, we suggest three candidate quantum regenerator models for future work.

</details>


### [47] [Effect of initial intrasystem entanglement on entropy growth in generalized Jaynes-Cummings models](https://arxiv.org/abs/2602.04543)
*Daria Gaidukevich*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate how initial intrasystem entanglement influences the entropy generated in atomic systems interacting with a photonic environment in several generalizations of the Jaynes-Cummings model with two or more subsystems. Since the initial entanglement does not uniquely determine the final entropy, we focus on ensemble-averaged behavior. We consider ensembles of initial system states including pure and mixed Haar-random states, ensembles with fixed average energy or fixed mixedness, and varying initial photon numbers in the environment. In all cases, we observe a positive correlation between the initial entanglement and the entropy growth, although the fractional contribution of the initial entanglement varies. Our results emphasize the role of intrasystem correlations as a factor contributing to entropy growth in quantum informational processes.

</details>


### [48] [Restoring Landauer's Principle for Unitarily Transformed Thermal Reservoirs](https://arxiv.org/abs/2602.04552)
*Hao Xu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Landauer's principle, a cornerstone of quantum information and thermodynamics, appears to be violated when the thermal reservoir is replaced by a squeezed thermal state (STS). We introduce a formal extension of the principle to such unitarily transformed thermal states. By defining an effective Hamiltonian, we rigorously establish a generalized Landauer inequality, which naturally reduces to the standard case for an ordinary thermal reservoir as a special instance. The framework further yields a consistent definition of entropy production and a proof of its non-negativity. We illustrate its utility by studying an arbitrarily moving Unruh-DeWitt detector coupled to a quantum field initially prepared in the STS. Using perturbation theory, we compute the entropy production explicitly, confirming its positivity. As a result of the symmetry breaking induced by the unitary transformation, it depends on both the proper time interval and the absolute spacetime position. Our work resolves the apparent violation of Landauer's principle with STSs. It also provides a robust tool for analyzing quantum thermodynamics in non-equilibrium and relativistic settings, with potential implications for quantum thermal machines and information protocols.

</details>


### [49] [Entanglement improves coordination in distributed systems](https://arxiv.org/abs/2602.04588)
*Francisco Ferreira da Silva,Stephanie Wehner*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Coordination in distributed systems is often hampered by communication latency, which degrades performance. Quantum entanglement offers fundamentally stronger correlations than classically achievable without communication. Crucially, these correlations manifest instantaneously upon measurement, irrespective of the physical distance separating the systems. We investigate the application of shared entanglement to a dual-work optimization problem in a distributed system comprising two servers. The system must process both a continuously available, preemptible baseline task and incoming customer requests arriving in pairs. System performance is characterized by the trade-off between baseline task throughput and customer waiting time. We present a rigorous analytical model demonstrating that when the baseline task throughput function is strictly convex, rewarding longer uninterrupted processing periods, entanglement-assisted routing strategies achieve Pareto-superior performance compared to optimal communication-free classical strategies. We prove this advantage through queueing-theoretic analysis, non-local game formulation, and computational certification of classical bounds. Our results identify distributed scheduling and coordination as a novel application domain for near-term entanglement-based quantum networks.

</details>


### [50] [Dicke Superradiance in Extended 2D Quantum Arrays Coupled to Metasurface Bound States in the Continuum](https://arxiv.org/abs/2602.04627)
*Daniel Eyles,Emmanuel Lassalle,Adam Stokes,Ahsan Nazir,Ramón Paniagua-Domínguez*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Dicke superradiance is a collective phenomenon where the emission from ensembles of quantum emitters is coherently enhanced beyond the sum of each emitter's independent emission. Here, we propose a platform that exploits the delocalised nature of a high-Q, non-local mode supported by a dielectric metasurface (a so-called bound-state-in-the-continuum or BIC) to induce superradiant behaviour within an extended two-dimensional array of distant quantum emitters. We show that these BIC-mediated emitter interactions can span several wavelengths, thus overcoming the traditional subwavelength separation between emitters required in free space. We further show that reaching the idealised Dicke limit is possible in this system, provided that the emitters are coupled to the BIC mode efficiently enough, as quantified through the $β$-factor. Moreover, we demonstrate its experimental viability by analysing its robustness to realistic experimental imperfections. This work puts forward optical metasurfaces supporting BICs as a physically viable platform for realising the upper limits of cooperative emission in physically extended quantum emitter arrays.

</details>


### [51] [On the emergence of classical stochasticity](https://arxiv.org/abs/2602.04633)
*Xuan Du Trinh,Ismaël Septembre,Hai-Chau Nguyen*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We examine the logical structure of the emergence of classical stochasticity for a quantum system governed by a Pauli-type master equation. It is well-known that while such equations describe the evolution of probabilities, they do not automatically justify classical reasoning based on the assumption that the system exists in a definite state at intermediate times. On the other hand, we show that this assumption is crucial for the standard calculation of stochastic times such as the persistent time and the time of first arrivals. We then consider examples of single particles, bosons, and fermions in the so-called ultradecoherence limit to illustrate how classical stochasticity may emerge from quantum mechanics.

</details>


### [52] [Pure narrowband photon-pair generation in a monolithic cavity](https://arxiv.org/abs/2602.04646)
*Xavier Barcons Planas,Helen M. Chrzanowski,Janik Wolters*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Photonic quantum technologies require efficient sources of pure single photons. Here we present a heralded SPDC single-photon source in a monolithic cavity optimized for high spectral and spatial purity. The source heralds single-photons at a wavelength of 1540 nm and a spectral bandwidth of 168 MHz with a maximum heralding efficiency of 84%, while keeping the multi-photon contamination below 3%. The cavity enhancement generates photons mainly in the central cavity mode with 96.2% spectral purity.

</details>


### [53] [Pre-optimization of quantum circuits, barren plateaus and classical simulability: tensor networks to unlock the variational quantum eigensolver](https://arxiv.org/abs/2602.04676)
*Baptiste Anselme Martin,Thomas Ayral*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Variational quantum algorithms are practical approaches to prepare ground states, but their potential for quantum advantage remains unclear. Here, we use differentiable 2D tensor networks (TN) to optimize parameterized quantum circuits that prepare the ground state of the transverse field Ising model (TFIM). Our method enables the preparation of states with high energy accuracy, even for large systems beyond 1D. We show that TN pre-optimization can mitigate the barren plateau issue by giving access to enhanced gradient zones that do not shrink exponentially with system size. We evaluate the classical simulation cost evaluating energies at these warm-starts, and identify regimes where quantum hardware offers better scaling than TN simulations.

</details>


### [54] [Quantum Advantage in Decision Trees: A Weighted Graph and $L_1$ Norm Approach](https://arxiv.org/abs/2602.04700)
*Sebastian Alberto Grillo,Bernardo Daniel Dávalos,Rodney Fabian Franco Torres,Franklin de Lima Marquezino,Edgar López Pezoa*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The analysis of the computational power of single-query quantum algorithms is important because they must extract maximal information from one oracle call, revealing fundamental limits of quantum advantage and enabling optimal, resource-efficient quantum computation. This paper proposes a formulation of single-query quantum decision trees as weighted graphs. This formulation has the advantage that it facilitates the analysis of the $L_1$ spectral norm of the algorithm output. This advantage is based on the fact that a high $L_1$ spectral norm of the output of a quantum decision tree is a necessary condition to outperform its classical counterpart. We propose heuristics for maximizing the $L_{1}$ spectral norm, show how to combine weighted graphs to generate sequences with strictly increasing norm, and present functions exhibiting exponential quantum advantage. Finally, we establish a necessary condition linking single-query quantum advantage to the asymptotic growth of measurement projector dimensions.

</details>


### [55] [Enabling large-scale digital quantum simulations with superconducting qubits](https://arxiv.org/abs/2602.04719)
*Laurin E. Fischer*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum computing promises to revolutionize several scientific and technological domains through fundamentally new ways of processing information. Among its most compelling applications is digital quantum simulation, where quantum computers are used to replicate the behavior of other quantum systems. This could enable the study of problems that are otherwise intractable on classical computers, transforming fields such as quantum chemistry, condensed matter physics, and materials science. Despite this potential, realizations of practical quantum advantage for relevant problems are hindered by imperfections of current devices. This also affects quantum hardware based on superconducting circuits which is among the most advanced and scalable platforms. The envisaged long-term solution of fault-tolerant quantum computers that correct their own errors remains out of reach mainly due to the associated qubit number overhead. As a result, the field has developed strategies that combine quantum and classical resources, exploit hardware-native operations, and employ error mitigation techniques to extract meaningful results from noisy data. This doctoral thesis contributes to this broader effort by exploring methods for advancing quantum simulation across the full computational stack, including hardware-level innovations, refined techniques for noise modeling and error mitigation, and algorithmic improvements enabled by efficient measurement processing.

</details>


### [56] [Ising-Induced Spectral Broadening Resolves the Relaxation Bottleneck in Superradiant Masers](https://arxiv.org/abs/2602.04721)
*Hongze Ding,Jiuqing Liang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The recent observation of self-induced superradiant masing [[W. Kersten et al., Nat. Phys. 22, 158 (2026)]] revealed a collective relaxation timescale significantly slower than predicted by standard coherent transport models. Here, we elucidate the microscopic origin of this ``relaxation bottleneck.'' We show that in the high-density regime relevant to the experiment, diagonal Ising interactions -- often treated as perturbative -- generate profound inhomogeneous broadening that exceeds the intrinsic single-particle dephasing. This intense diagonal disorder suppresses resonant flip-flop exchange, effectively renormalizing the density of states available for spectral diffusion. Our parameter-free analytic theory quantitatively reproduces the experimentally observed microsecond dynamics, identifying Ising-induced broadening as the governing mechanism for energy transport in dense solid-state spin ensembles.

</details>


### [57] [Resource-Efficient Digitized Adiabatic Quantum Factorization](https://arxiv.org/abs/2602.04740)
*Felip Pellicer,Juan José García-Ripoll,Alan C. Santos*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Digitized adiabatic quantum factorization is a hybrid algorithm that exploits the advantage of digitized quantum computers to implement efficient adiabatic algorithms for factorization through gate decompositions of analog evolutions. In this paper, we harness the flexibility of digitized computers to derive a digitized adiabatic algorithm able to reduce the gate-demanding costs of implementing factorization. To this end, we propose a new approach for adiabatic factorization by encoding the solution of the problem in the kernel subspace of the problem Hamiltonian, instead of using ground-state encoding considered in the standard adiabatic factorization proposed by Peng $et$ $al$. [Phys. Rev. Lett. 101, 220405 (2008)]. Our encoding enables the design of adiabatic factorization algorithms belonging to the class of Quadratic Unconstrained Binary Optimization (QUBO) methods, instead the Polinomial Unconstrained Binary Optimization (PUBO) used by standard adiabatic factorization. We illustrate the performance of our QUBO algorithm by implementing the factorization of integers $N$ up to 8 bits. The results demonstrate a substantial improvement over the PUBO formulation, both in terms of reduced circuit complexity and increased fidelity in identifying the correct solution.

</details>


### [58] [Generalized quantum theory for accessing nonlinear systems: the case of Levinson-Smith equations](https://arxiv.org/abs/2602.04747)
*Bijan Bagchi,Anindya Ghose-Choudhury*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Motivated by a recently developed generalized scheme of quantum mechanics, we touch upon connections with Levinson-Smith classes of nonlinear systems that contain as a particular case the Liénard family of differential equations. The latter, which has coefficients of odd and odd symmetry, admits a closed form solution when converted to the Abel form. Analysis of the governing condition shows that one of the nontrivial equilibrium points is stable in character. Other classes of differential equations that we encounter speak of solutions involving Jacobi elliptic functions for a certain combination of underlying parameters, while, for a different set, relevance to position-dependent mass systems is shown. In addition, an interesting off-shoot of our results is the emergence of solitonic-like solutions from the condition of the level surface in the system.

</details>


### [59] [Quantifying the Operational Cost of Multipartite Entanglement](https://arxiv.org/abs/2602.04760)
*Francois Payn,Michele Minervini,Davide Girolami*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multipartite entanglement determines the strength and range of interactions in many-body quantum systems. Yet, it is hard to evaluate it, due to the complex structures of quantum states. Here, we introduce a generic method to quantify the k <= N-partite entanglement of an N-particle system, by maximizing an arbitrary bipartite entanglement measure within subsystems of size up to k. The resulting classification of multipartite states captures their experimental cost: creating a k-partite entangled state requires at least k-1 two-particle entangling gates. Further, we analytically calculate the newly defined k-partite entanglement of formation, which generalizes an important bipartite entanglement measure, in several classes of states, including the W states of any dimension.

</details>


### [60] [Digital signatures with classical shadows on near-term quantum computers](https://arxiv.org/abs/2602.04859)
*Pradeep Niroula,Minzhao Liu,Sivaprasad Omanakuttan,David Amaro,Shouvanik Chakrabarti,Soumik Ghosh,Zichang He,Yuwei Jin,Fatih Kaleoglu,Steven Kordonowy,Rohan Kumar,Michael A. Perlin,Akshay Seshadri,Matthew Steinberg,Joseph Sullivan,Jacob Watkins,Henry Yuen,Ruslan Shaydulin*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum mechanics provides cryptographic primitives whose security is grounded in hardness assumptions independent of those underlying classical cryptography. However, existing proposals require low-noise quantum communication and long-lived quantum memory, capabilities which remain challenging to realize in practice. In this work, we introduce a quantum digital signature scheme that operates with only classical communication, using the classical shadows of states produced by random circuits as public keys. We provide theoretical and numerical evidence supporting the conjectured hardness of learning the private key (the circuit) from the public key (the shadow). A key technical ingredient enabling our scheme is an improved state-certification primitive that achieves higher noise tolerance and lower sample complexity than prior methods. We realize this certification by designing a high-rate error-detecting code tailored to our random-circuit ensemble and experimentally generating shadows for 32-qubit states using circuits with $\geq 80$ logical ($\geq 582$ physical) two-qubit gates, attaining 0.90 $\pm$ 0.01 fidelity. With increased number of measurement samples, our hardware-demonstrated primitives realize a proof-of-principle quantum digital signature, demonstrating the near-term feasibility of our scheme.

</details>


### [61] [Requirements for Teleportation in an Intercity Quantum Network](https://arxiv.org/abs/2602.04869)
*Soubhadra Maiti,Guus Avis,Sounak Kar,Stephanie Wehner*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the hardware requirements for quantum teleportation in an intercity-scale network topology consisting of two metropolitan-scale networks connected via a long-distance backbone link. Specifically, we identify the minimal improvements required beyond the state-of-the-art to achieve an end-to-end expected teleportation fidelity of $2/3$, which represents the classical limit. To this end, we formulate the hardware requirements computation as optimisation problems, where the hardware parameters representing the underlying device capabilities serve as decision variables. Assuming a simplified noise model, we derive closed-form analytical expressions for the teleportation fidelity and rate when the network is realised using heterogeneous quantum hardware, including a quantum repeater chain with a memory cut-off. Our derivations are based on events defined by the order statistics of link generation durations in both the metropolitan networks and the backbone, and the resulting expressions are validated through simulations on the NetSquid platform. The analytical expressions facilitate efficient exploration of the optimisation parameter space without resorting to computationally intensive simulations. We then apply this framework to a representative realisation in which the metropolitan nodes are based on trapped-ion processors and the backbone is composed of ensemble-based quantum memories. Our results suggest that teleportation across metropolitan distances is already achievable with state-of-the-art hardware when the data qubit is prepared after end-to-end entanglement has already been established, whereas extending teleportation to intercity scales requires additional, though plausibly achievable, improvements in hardware performance.

</details>


### [62] [Thermal State Simulation with Pauli and Majorana Propagation](https://arxiv.org/abs/2602.04878)
*Manuel S. Rudolph,Armando Angrisani,Andrew Wright,Iwo Sanderski,Ricard Puig,Zoë Holmes*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We introduce a propagation-based approach to thermal state simulation by adapting Pauli and Majorana propagation to imaginary-time evolution in the Schrödinger picture. Our key observation is that high-temperature states can be sparse in the Pauli or Majorana bases, approaching the identity at infinite temperature. By formulating imaginary-time evolution directly in these operator bases and evolving from the maximally mixed state, we access a continuum of temperatures where the state remains efficiently representable. We provide analytic guarantees for small-coefficient truncation and Pauli-weight (Majorana-length) truncation strategies by quantifying the error growth and the impact of backflow. Large-scale numerics on the 1D J1-J2 model (energies) and the triangular-lattice Hubbard model (static correlations) validate efficiency at high temperatures.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [63] [Efficient Explicit Taylor ODE Integrators with Symbolic-Numeric Computing](https://arxiv.org/abs/2602.04086)
*Songchen Tan,Oscar Smith,Christopher Rackauckas*

Main category: math.NA

TL;DR: 本文提出了一种基于Julia的泰勒级数方法新实现，结合高阶自动微分和符号-数值混合技术，实现了高效、透明且性能优于传统显式Runge-Kutta方法的常微分方程求解器。


<details>
  <summary>Details</summary>
Motivation: 随着编译器增强技术的发展，利用高阶导数计算非刚性常微分方程的泰勒级数方法展现出新潜力，但缺乏高效、低开销的实现工具。

Method: 开发了一个基于Julia的新实现，包含两个关键技术：(1) 通用高阶自动微分引擎，用于低开销的导数计算；(2) 符号-数值结合的方法，生成递归计算泰勒多项式的代码；并设计了自适应时间和阶次算法。

Result: 该软件在运行时性能上优于标准显式Runge-Kutta方法，具有用户透明的接口，并在不同动力学问题中表现出更高的效率和鲁棒性。

Conclusion: 对于支持编译器优化的代码，所提出的泰勒级数积分器比传统显式Runge-Kutta方法更高效、更稳健，适用于广泛的动力系统模拟。

Abstract: Taylor series methods show a newfound promise for the solution of non-stiff ordinary differential equations (ODEs) given the rise of new compiler-enhanced techniques for calculating high order derivatives. In this paper we detail a new Julia-based implementation that
  has two important techniques: (1) a general purpose higher-order automatic differentiation engine for derivative evaluation with low overhead; (2) a combined symbolic-numeric approach to generate code for recursively computing the Taylor polynomial of the ODE solution. We demonstrate that the resulting software's compiler-based tooling is transparent to the user, requiring no changes from interfaces required to use standard explicit Runge-Kutta methods, while achieving better run time performance. In addition, we also developed a comprehensive adaptive time and order algorithm that uses different step size and polynomial degree across the integration period, which makes this implementation more efficient and versatile in a broad range of dynamics. We show that for codes compatible with compiler transformations, these integrators are more efficient and robust than the traditionally used explicit Runge-Kutta methods.

</details>


### [64] [A frequency-domain method to inverse moving source problem with unknown radiating moment](https://arxiv.org/abs/2602.04207)
*Guanqiu Ma,Hongxia Guo,Guanghui Hu*

Main category: math.NA

TL;DR: 提出一种多频因子化方法，用于成像时间依赖源，恢复其空间支持和激发时刻。


<details>
  <summary>Details</summary>
Motivation: 旨在通过远场数据反演时间相关源的空间分布与激发时间，提升非定常源成像能力。

Method: 利用两个相反方向的远场数据构建计算准则，构造逐点定义的指示函数，实现对脉冲矩和源支撑域最窄条带的表征，并通过因子化方法实现稀疏观测下的Θ-凸支撑域重建。

Result: 实现了从稀疏观测方向的远场数据中恢复源的凸包和激发时刻，验证了方法在二维和三维情况下的有效性与可行性。

Conclusion: 该方法能有效确定时间依赖源的凸支撑域和激发时间，具有良好的数值稳定性和应用前景。

Abstract: This paper introduces a multi-frequency factorization method for imaging a time-dependent source, specifically to recover its spatial support and the associated excitation instants. Using far-field data from two opposite directions, we establish a computational criterion that characterizes both the unknown pulse moments and the narrowest strip (perpendicular to the direction) enclosing the source support. Central to our inversion scheme is the construction of indicator functions, defined pointwise over the spatial and temporal sampling variables. The proposed inversion scheme permits the recovery of the $Θ$-convex support domain from far-field data at sparse observation directions. Uniqueness in determining the convex hull of the support and the excitation instants-using all observation directions-is also established as a direct consequence of the factorization method. The effectiveness and feasibility of the approach are examined through comprehensive numerical simulations in two and three dimensions.

</details>


### [65] [Towards $C^0$ finite element methods for fourth-order elliptic equation. Part I: general boundary conditions](https://arxiv.org/abs/2602.04235)
*Xihao Zhang,Hengguang Li,Nianyu Yi,Peimeng Yin*

Main category: math.NA

TL;DR: 本文提出了一种改进的混合有限元方法，用于求解多边形区域上的双调和方程，通过分解为多个泊松方程来处理不同边界条件，确保了方法在任意多边形域和多种边界条件下的收敛性。


<details>
  <summary>Details</summary>
Motivation: 研究边界条件对C^0有限元格式设计的影响，解决传统混合方法在复杂边界条件下无法保证收敛的问题。

Method: 提出一种改进的混合变分形式，将原问题分解为依赖于最大内角和相邻边边界条件的多个泊松方程，并发展相应的C^0有限元算法。

Result: 建立了严格的误差估计，数值实验验证了方法的适定性和有效性，能够在任意多边形域和Navier、Neumann及混合边界条件下收敛到真解。

Conclusion: 该方法克服了传统两方程混合格式的局限性，为四阶椭圆方程提供了更通用且可靠的C^0有限元解决方案。

Abstract: This paper is part of a series developing $C^0$ finite element methods for fourth-order elliptic equations on polygonal domains. Here, we investigate how boundary conditions influence the design of effective $C^0$ schemes, specifically focusing on equations without lower-order terms, namely the biharmonic equation. We propose a modified mixed formulation that decomposes the problem into a system of Poisson equations, where the number of equations depends on both the largest interior angle and the boundary conditions on its two adjacent sides. In contrast to the naive mixed formulation, which involves only two Poisson problems, the proposed approach guarantees convergence to the true solution for arbitrary polygonal domains and general boundary conditions, including Navier, Neumann, and mixed boundary conditions. $C^0$ finite element algorithms are developed, rigorous error estimates are established, and numerical experiments are presented to demonstrate the well-posedness and effectiveness of the proposed method.

</details>


### [66] [Balancing Inexactness in Mixed Precision Matrix Computations](https://arxiv.org/abs/2602.04348)
*Erin Claire Carson*

Main category: math.NA

TL;DR: 探讨在存在其他不精确性的情况下，如何利用混合精度计算来提升性能而不显著降低准确性。


<details>
  <summary>Details</summary>
Motivation: 确定在代码中如何安全地利用多精度算术以提高性能。

Method: 分析不同来源的不精确性之间的相互作用，以平衡误差并选择合适的计算精度。

Result: 展示了混合精度在数值线性代数和矩阵计算中的潜力。

Conclusion: 通过平衡各种不精确性，可以在保持准确性的前提下提升计算性能。

Abstract: Support for arithmetic in multiple precisions and number formats is becoming increasingly common in emerging high-performance architectures. From a computational scientist's perspective, our goal is to determine how and where we can safely exploit mixed precision computation in our codes to improve performance. One case where the use of low precision is natural, common in computational science, is when there are already other significant sources of ``inexactness'' present, e.g., discretization error, measurement error, or algorithmic approximation error. In such instances, analyzing the interaction of these different sources of inexactness can give insight into how the precisions of various computations should be chosen in order to ``balance'' the errors, potentially improving performance without a noticeable decrease in accuracy. We present a few recent examples of this approach which demonstrate the potential for the use of mixed precision in numerical linear algebra and matrix computations.

</details>


### [67] [On the pure traction problem of linear elasticity: a regularized formulation and its robust approximation](https://arxiv.org/abs/2602.04359)
*Ahsan Kaleem,Cristian Gebhardt,Ignacio Romero*

Main category: math.NA

TL;DR: 本文提出了一种新的正则化方法来解决弹性力学中的纯牵引问题，该方法无需额外自由度即可通过有限元直接求解，并在载荷非平衡时提供收敛解。


<details>
  <summary>Details</summary>
Motivation: 纯牵引问题的解在刚体运动下不唯一，传统有限元方法需通过边界条件或全局约束处理，但存在复杂性与计算效率低的问题。

Method: 采用正则化形式重构问题，使解唯一且具最小范数；提出预测-校正有限元格式以处理离散域上载荷非平衡导致的不适定性。

Result: 正则化解收敛于原问题的最小范数解；数值算例验证了方法在典型力学问题中的有效性。

Conclusion: 所提方法简洁高效，能稳定求解纯牵引问题，适用于工程中常见纯牵引边界条件的情形。

Abstract: The pure traction problem of elasticity appears frequently in engineering applications, and its complexity stems from the fact that its solution is unique only up to (infinitesimal) rigid body motions. When finite elements are employed to approximate this problem, one solution is typically singled out by applying carefully selected boundary conditions on the discrete model or by imposing global constraints on the deformation. However, neither of these strategies is both simple and computationally efficient. In this work, we propose a new approach to solving the pure traction problem that overcomes existing limitations. Our method builds on a regularized form of the problem whose solution is shown to be unique, converges to the original solution of minimal norm, and can be approximated with finite elements in a straightforward way, without additional degrees of freedom. Additionally, we analyze the situation in which the approximation of the solution domain renders the loading of the discretized problem non-equilibrated, making the problem ill-posed. In this case, we propose a regularized predictor--corrector finite element formulation that handles the incompatibilities of the loading, providing a solution that converges to that of the original Neumann problem as the mesh size and the regularizing parameter tend to zero. Numerical examples illustrate the effectiveness of the proposed approach for representative problems in mechanics where pure traction boundary conditions appear.

</details>


### [68] [A Priori and A Posteriori Error Identities for Vectorial Problems via Convex Duality](https://arxiv.org/abs/2602.04368)
*P. A. Gazca-Orozco,A. Kaltenbach*

Main category: math.NA

TL;DR: 本文将凸对偶方法扩展到向量问题，研究不可压缩Stokes和Navier-Lamé方程，在非均匀混合边界条件下推导了误差恒等式与估计，并证明了Crouzeix-Raviart离散格式的准最优收敛性。


<details>
  <summary>Details</summary>
Motivation: 将近年来用于非线性非光滑标量问题的凸对偶与误差估计方法推广至向量情形，并处理更一般的混合边界条件与载荷。

Method: 利用Crouzeix-Raviart和Raviart-Thomas元的兼容性，结合凸对偶理论进行误差分析与通量重构。

Result: 导出了精确的误差恒等式与后验误差估计，实现了在最小正则性假设下无数据振荡项的准最优误差估计。

Conclusion: 该方法有效扩展了凸对偶在向量问题中的应用，适用于复杂边界条件，提升了非协调有限元分析的适用范围。

Abstract: Convex duality has been leveraged in recent years to derive a posteriori error estimates and identities for a wide range of non-linear and non-smooth scalar problems. By employing remarkable compatibility properties of the Crouzeix-Raviart and Raviart-Thomas elements, optimal convergence of non-conforming discretisations and flux reconstruction formulas have also been established. This paper aims to extend these results to the vectorial setting, focusing on the archetypical problems of incompressible Stokes and Navier-Lamé. Moreover, unlike most previous results, we consider inhomogeneous mixed boundary conditions and loads in the topological dual of the energy space. At the discrete level, we derive error identities and estimates that enable to prove quasi-optimal error estimates for a Crouzeix-Raviart discretisation with minimal regularity assumptions and no data oscillation terms.

</details>


### [69] [Randomized Projection Operators onto Piecewise Polynomial Spaces](https://arxiv.org/abs/2602.04490)
*Johannes Storn*

Main category: math.NA

TL;DR: 提出了基于分段多项式空间的可计算投影算子，通过采样和离散最小二乘多项式逼近实现，在L²和H⁻¹空间中具有几乎最优的逼近性质，并可用于粗糙数据的平滑处理，得到最优收敛率的有限元离散化。


<details>
  <summary>Details</summary>
Motivation: 为了处理不完整或粗糙数据，需要构造具有良好逼近性质且可计算的投影算子，以提升有限元方法的收敛性能。

Method: 通过采样和离散最小二乘法定义分段多项式空间上的投影算子，并分析其在L²和H⁻¹范数下的逼近性质。

Result: 所提出的投影算子在L²和H⁻¹空间中表现出几乎最优的逼近误差，并可作为平滑器用于有限元离散，实现最优收敛率。

Conclusion: 该方法提供了一种高效、可计算的投影策略，适用于处理不规则或低正则性数据，同时保持有限元逼近的最优收敛性。

Abstract: We introduce computable projection operators onto piecewise polynomial spaces, defined via sampling and discrete least-squares polynomial approximations. The resulting mappings exhibit (almost) optimal approximation properties in $L^2$ and $H^{-1}$. As smoothers for incomplete or rough data, they yield computable finite element discretizations with optimal convergence rates.

</details>


### [70] [Domain decomposition methods and preconditioning strategies using generalized locally Toepltiz tools: proposals, analysis, and numerical validation](https://arxiv.org/abs/2602.04603)
*Abdessadek Rifqui,Ahmed Ratnani,Stefano Serra-Capizzano*

Main category: math.NA

TL;DR: 本文利用广义局部Toeplit兹（GLT）序列理论，对加性和乘性Schwarz方法的谱性质进行了系统分析，重点研究了其收敛行为及传输算子的影响，并通过GLT符号给出了收敛因子的显式表达式，为经典和未来改进型Schwarz方法提供了统一的谱分析框架。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解经典Schwarz方法在域分解中的收敛行为，并为设计高效并行且保持良好收敛性的改进方法（如受限变体）提供理论基础。

Method: 采用广义局部Toeplitz（GLT）序列理论，分析离散化后Schwarz迭代算子序列的渐近谱分布，推导出加性和乘性Schwarz方法对应的GLT符号及其收敛因子的显式表达式。

Result: 得到了描述Schwarz方法谱分布的GLT符号，揭示了网格细化和重叠大小对收敛性的影响，建立了预测块Jacobi/Gauss-Seidel及块加性/乘性Schwarz预条件子效率的理论工具，并通过大量数值实验验证了理论结果的有效性。

Conclusion: GLT理论为分析Schwarz类方法提供了强大而统一的谱分析框架，不仅深化了对经典方法的理解，也为未来新型域分解预条件子的设计与分析奠定了基础。

Abstract: In the current work we present a spectral analysis of the additive and multiplicative Schwarz methods within the framework of domain decomposition techniques, by investigating the spectral properties of these classical Schwarz preconditioning matrix-sequences, with emphasis on their convergence behavior and on the effect of transmission operators. In particular, after a general presentation of various options, we focus on restricted variants of the Schwarz methods aimed at improving parallel efficiency, while preserving their convergence features. In order to rigorously describe and analyze the convergence behavior, we employ the theory of generalized locally Toeplitz (GLT) sequences, which provides a robust framework for studying the asymptotic spectral distribution of the discretized operators arising from Schwarz iterations. By associating each operator sequence with the appropriate GLT symbol, we derive explicit expressions for the GLT symbols of the convergence factors, for both additive and multiplicative Schwarz methods. The GLT-based spectral approach offers a unified and systematic understanding of how the spectrum evolves with mesh refinement and overlap size (in the algebraic case). Our analysis not only deepens the theoretical understanding of classical Schwarz methods, but also establishes a foundation for examining future restricted or hybrid Schwarz variants using symbolic spectral tools. These results enable the prediction of the remarkable efficiency of block Jacobi/Gauss--Seidel and block additive/multiplicative Schwarz preconditioners for GLT sequences, as further illustrated through a wide choice of numerical experiments.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [71] [Data Driven Air Entrainment Velocity Parameterization by Breaking Waves](https://arxiv.org/abs/2602.04067)
*Xiaohui Zhou,Anton S. Darmenov,Kianoosh Yousefi*

Main category: physics.ao-ph

TL;DR: 本研究利用43年WAVEWATCH III模拟数据，开发了一种基于机器学习的全球波浪破碎夹气速度（Va）参数化方法，显著改进了现有模型中对气泡介导的CO2传输和海盐气溶胶排放的估算精度。


<details>
  <summary>Details</summary>
Motivation: 波浪破碎过程对海气交换具有重要影响，但当前耦合模型中对该过程的参数化过于简化，导致在不同海况下的通量估算存在显著偏差，亟需更精确的物理表征方法。

Method: 基于WAVEWATCH III的43年波浪模拟数据，提取波前分布及能量特征，构建一个包含风速、波高、波龄、陡度、方向和水深等七个物理变量的多层感知机机器学习模型，用于预测夹气速度Va。

Result: 该模型能够高精度再现谱参考的Va，显著减少传统公式在低纬度涌浪区的高估和风暴路径区的低估问题；在全球应用中，使气泡介导的CO2传质速度和海盐气溶胶排放的误差降低一个数量级，并通过独立的HiWinGS观测数据验证了其在深水区域的稳健性。

Conclusion: 引入多物理因子的机器学习参数化方案可有效提升波浪破碎相关海气通量在气候和天气模型中的表示精度，为改进耦合大气-波浪-海洋模型提供了可行路径。

Abstract: Wave breaking injects turbulence and bubbles into the upper ocean, modulating air-sea exchange of momentum, heat, gases, and sea-spray aerosols. These fluxes depend nonlinearly on sea state but remain poorly represented in coupled atmosphere-wave-ocean models, where air-entrainment velocity is often parameterized using wind speed or significant wave height alone. We develop a global machine-learning parameterization of Va trained on a 43-year WAVEWATCH III simulation that resolves the breaker-front distribution and associated energetics. A multilayer perceptron with seven physically motivated predictors (wind speed, wave height, wave age, steepness, direction, and depth) reproduces spectral-reference Va with high skill. The model reduces longstanding biases in bulk formulas, notably overestimation in swell-dominated low latitudes and underestimation in storm tracks. Applied globally, it improves bubble-mediated CO2 transfer velocity and sea-salt aerosol emission, reducing errors by an order of magnitude. Validation against independent HiWinGS observations supports robust deep-water performance.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [72] [Primary charge-4e superconductivity from doping a featureless Mott insulator](https://arxiv.org/abs/2602.03925)
*Zhi-Qiang Gao,Yan-Qi Wang,Ya-Hui Zhang,Hui Yang*

Main category: cond-mat.str-el

TL;DR: 本文提出了一种具有SU(4)对称性的掺杂无特征Mott绝缘体作为实现原初电荷-4e超导相的自然平台，并通过构造双层Hubbard模型和DMRG模拟验证了该机制。


<details>
  <summary>Details</summary>
Motivation: 寻找在零温下实现原初电荷-4e超导的新机制，拓展非常规超导的理解。

Method: 基于微扰重正化群理论和群论分析，构建具有可调SU(4)和Sp(4)对称性的双层Hubbard模型，并使用DMRG方法研究其低能物理行为。

Result: 发现SU(4)情形下存在原初电荷-4e超导相，而Sp(4)情形下为传统的电荷-2e超导相；明确了相应的正常态性质及有限温度相图。

Conclusion: SU(4)对称性的掺杂无特征Mott绝缘体是实现原初电荷-4e超导的有效途径，为多体量子态的设计提供了新方向。

Abstract: Superconductivity is usually understood as a phase in which charge-$2e$ Cooper pairs are condensed. Charge-$4e$ superconductivity has largely been discussed as a vestigial order at finite temperature emerging from charge-$2e$ states. Primary charge-$4e$ superconducting phases at zero temperature remain scarce in both experiments and microscopic models. Here we argue that a doped featureless Mott insulator with $SU(4)$ symmetry provides a natural platform for primary charge-$4e$ superconductivity, based on perturbative renormalization group arguments and group theoretic considerations. As a concrete realization, we construct a bilayer Hubbard model with tunable onsite $SU(4)$ and $Sp(4)$ symmetries that exhibits a featureless Mott insulating phase at half filling. Its low energy physics is captured by a generalized ESD model, featuring an effective Hamiltonian that is purely kinetic within the constrained Hilbert space. Using density matrix renormalization group (DMRG) simulations, we find a primary charge-$4e$ superconducting phase in the $SU(4)$ ESD model and a conventional primary charge-$2e$ phase in the $Sp(4)$ case. We further characterize the corresponding normal states and discuss the resulting finite temperature phase diagram.

</details>


### [73] [Revealing the microscopic origin of the magnetization plateau in Na$_3$Ni$_2$BiO$_6$](https://arxiv.org/abs/2602.03936)
*Amanda A. Konieczna,P. Peter Stavropoulos,Roser Valentí*

Main category: cond-mat.str-el

TL;DR: 本文通过第一性原理计算和微观建模，揭示了Na$_3$Ni$_2$BiO$_6$中三分之一磁化平台的起源，发现该现象无需Kitaev相互作用，而是由强单离子各向异性和竞争性Heisenberg耦合共同导致。


<details>
  <summary>Details</summary>
Motivation: 解释Na$_3$Ni$_2$BiO$_6$在磁场下出现的一三分之一磁化平台的微观机制，并探讨Kitaev相互作用是否必要。

Method: 结合密度泛函理论计算与微观磁模型，提取交换参数并构建有效自旋模型，用于模拟中子散射谱和磁化曲线。

Result: 模型成功复现了零场下的zigzag磁序和中间磁场下的double-zigzag态，并表明三分之一磁化平台可由单离子各向异性及J1、J3 Heisenberg耦合解释，无需引入Kitaev项。

Conclusion: Na$_3$Ni$_2$BiO$_6$中的三分之一磁化平台主要源于强单离子各向异性和竞争性近邻Heisenberg相互作用，而非Kitaev相互作用，提供了对该材料磁行为的一致微观解释。

Abstract: Recent experimental studies of the spin-1 honeycomb antiferromagnet Na$_3$Ni$_2$BiO$_6$ have revealed a pronounced one-third magnetization plateau under applied magnetic fields, highlighting the presence of strong magnetic frustration and anisotropy in this material. Such behavior has been attributed to substantial bond-dependent Kitaev interactions in combination with single-ion anisotropy, placing Na$_3$Ni$_2$BiO$_6$ among honeycomb compounds of interest for unconventional magnetic phases. Motivated by these observations, we present a first-principles-based analysis of the magnetic interactions in Na$_3$Ni$_2$BiO$_6$. By combining density-functional calculations with microscopic modeling, we extract the relevant exchange parameters and construct an effective spin model that quantitatively reproduces both the elastic neutron-scattering spectra and the magnetization curve. The model captures the experimentally observed zero-field zigzag magnetic order, and proposes a $\textit{double-zigzag}$ state at intermediate magnetic fields, realizing the 1/3-magnetization plateau in a simpler way than suggested in previous works. Crucially, we show that the one-third magnetization plateau does not require Kitaev interactions; instead, it arises from the interplay of strong out-of-plane single-ion anisotropy and competing ferromagnetic nearest-neighbor ($J_1$) and antiferromagnetic third-neighbor ($J_3$) Heisenberg couplings. These results establish a consistent microscopic description of Na$_3$Ni$_2$BiO$_6$ and clarify the origin of its field-induced plateau phase.

</details>


### [74] [Emergent Coherence at the Edge of Magnetism: Low-Doped La2-xSrxCuO4+delta Revisited](https://arxiv.org/abs/2602.04452)
*E. Yu. Beliayev,Y. K. Mishra,I. A. Chichibaba,I. G. Mirzoiev,V. A. Horielyi,A. V. Terekhov*

Main category: cond-mat.str-el

TL;DR: 该研究通过分析La2-xSrxCuO4+delta (LSCO)体系中的输运行为，揭示了从局域化主导的绝缘态到颗粒超导再到相干金属态的连续交叉演化过程，强调了无序、介观电子不均匀性、渗流效应和非平衡效应在欠掺杂铜基超导体中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 探索掺杂Mott绝缘体中磁性、超导性和无序如何共同影响电荷输运。

Method: 通过对轻度掺杂且富氧的LSCO体系进行输运测量，分析其在不同载流子浓度下的电导特性、非线性电流-电压关系及负微分电阻等现象。

Result: 发现随着载流子浓度增加，系统经历从变程跳跃主导的强绝缘态，经颗粒和渗流超导区域，最终演化为均匀的奇异金属态；整个过程呈现连续交叉而非 abrupt 相变，并对无序、偏置电流和磁场敏感。

Conclusion: LSCO体系中的输运行为由电子屏蔽增强、区域间耦合和超导连通性的渐进发展驱动，支持基于渗流和非平衡效应的统一物理图像，为理解欠掺杂铜基超导体提供了实验基础。

Abstract: The La2-xSrxCuO4+delta (LSCO) system provides a unique experimental setting for exploring how magnetism, superconductivity, and disorder jointly shape charge transport in a doped Mott insulator. Transport measurements in lightly doped and oxygen-enriched LSCO reveal a strongly insulating normal state governed by variable-range hopping, accompanied by pronounced nonlinear current-voltage characteristics and, at low temperatures, current-induced negative differential resistance. With increasing carrier concentration, these features evolve into regimes characterized by granular and percolative superconductivity near the threshold of bulk superconductivity and, eventually, into a homogeneous strange-metal state close to optimal doping. Throughout this evolution, the transport response shows marked sensitivity to disorder, electronic inhomogeneity, and external control parameters, such as bias current and magnetic field. Rather than reflecting a sequence of sharply distinct phases, the observed transport regimes form a continuous crossover from a localization-dominated insulating state to granular superconductivity and further to a coherent metallic state. This crossover is driven primarily by the progressive enhancement of electronic screening, inter-region coupling, and superconducting connectivity, rather than by abrupt changes in the underlying microscopic scattering mechanisms. Taken together, the available transport data provide a coherent experimental basis for understanding how disorder and mesoscale electronic inhomogeneity organize charge transport and superconductivity across the LSCO phase diagram, underscoring the central role of percolation and nonequilibrium effects in underdoped cuprates.

</details>


### [75] [Boundary and Symmetry Breaking in a Deformed Toric Code](https://arxiv.org/abs/2602.04002)
*Rodrigo Corso*

Main category: cond-mat.str-el

TL;DR: 研究了一种诱导拓扑序相变的Kitaev环码变形模型，发现相变伴随高阶对称性破缺，并通过全息边界哈密顿量揭示了体系统临界性对有效中心电荷的影响。


<details>
  <summary>Details</summary>
Motivation: 探索在Kitaev环码模型中引入变形后如何引发从拓扑有序相到其他相的相变，并理解相变过程中对称性的演化。

Method: 将变形后的Kitaev环码模型置于圆柱几何上，利用体系统的全局1-形式对称性在边界上的分离特性，结合(1+1)维全息边界哈密顿量分析有效中心电荷的行为。

Result: 发现相变伴随着一种高阶对称性的破缺；通过边界哈密顿量计算得到的有效中心电荷在临界点β_c附近显著抑制，并在强耦合下恢复，表明其响应的是体系统的临界性而非拓扑序本身。

Conclusion: 该模型中的相变由高阶对称性破缺驱动，有效中心电荷的变化反映了体系统临界性的特征，而非拓扑序的存在与否。

Abstract: This work explores a deformation of the Kitaev toric code that induces a phase transition out of the topologically ordered phase. By placing the model on a cylinder, the bulk global 1-form symmetries separate into distinct boundary operators, allowing us to show that the transition is accompanied by the breaking of one higher-form symmetry. Using a holographic $(1+1)$-dimensional boundary Hamiltonian, we extract an effective central charge and find a pronounced suppression near $β_c$, followed by its restoration at strong coupling, indicating sensitivity to bulk criticality rather than topological order.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [76] [C-IDS: Solving Contextual POMDP via Information-Directed Objective](https://arxiv.org/abs/2602.03939)
*Chongyang Shi,Michael Dorothy,Jie Fu*

Main category: eess.SY

TL;DR: 提出了一种用于上下文部分可观测马尔可夫决策过程（CPOMDP）的信息导向策略合成方法，通过联合优化回报与上下文不确定性，实现了更快的上下文识别和更高的累积收益。


<details>
  <summary>Details</summary>
Motivation: 在CPOMDP中，环境由未知的潜在上下文决定，传统方法将其视为隐状态变量处理，难以高效识别上下文并实现最优策略。因此，需要一种能主动减少上下文不确定性的策略学习方法。

Method: 引入了一个信息导向目标函数，将奖励最大化与观测与潜在上下文之间的互信息结合；提出了C-IDS算法来优化该目标，并证明其目标可解释为线性信息比的拉格朗日松弛，温度参数为信息比的上界。

Result: 在连续的Light-Dark环境中验证了方法的有效性，相比标准POMDP求解器，C-IDS能更快速识别上下文并获得更高回报。

Conclusion: 所提出的信息导向策略能够有效平衡探索与利用，在未知上下文动态的环境中实现亚线性贝叶斯遗憾，并显著优于传统方法。

Abstract: We study the policy synthesis problem in contextual partially observable Markov decision processes (CPOMDPs), where the environment is governed by an unknown latent context that induces distinct POMDP dynamics. Our goal is to design a policy that simultaneously maximizes cumulative return and actively reduces uncertainty about the underlying context. We introduce an information-directed objective that augments reward maximization with mutual information between the latent context and the agent's observations. We develop the C-IDS algorithm to synthesize policies that maximize the information-directed objective. We show that the objective can be interpreted as a Lagrangian relaxation of the linear information ratio and prove that the temperature parameter is an upper bound on the information ratio. Based on this characterization, we establish a sublinear Bayesian regret bound over K episodes. We evaluate our approach on a continuous Light-Dark environment and show that it consistently outperforms standard POMDP solvers that treat the unknown context as a latent state variable, achieving faster context identification and higher returns.

</details>


### [77] [Safety-Critical Reinforcement Learning with Viability-Based Action Shielding for Hypersonic Longitudinal Flight](https://arxiv.org/abs/2602.03968)
*Hossein Rastgoftar*

Main category: eess.SY

TL;DR: 提出了一种面向非线性动力系统的安全强化学习框架，通过动作屏蔽和可达性分析确保物理约束下的安全性，并结合状态空间分区与有限状态抽象实现在线学习与安全恢复控制。


<details>
  <summary>Details</summary>
Motivation: 在具有连续状态和输入空间的非线性系统中，传统强化学习可能违反关键物理安全约束，因此需要一种能保证学习和执行过程中绝对安全的控制框架。

Method: 采用动作屏蔽（action shielding）和基于可达性的允许动作集来强制实施硬安全约束；将状态空间根据安全区域进行分区，并设计模式依赖的奖励函数以支持正常运行与恢复行为；通过状态聚合构建有限状态抽象，实现连续系统上的在线表格学习。

Result: 该方法在高超声速飞行器纵向点质量模型上得到验证，能够有效满足气动与推进耦合条件下的安全约束，并实现对安全区域的准确跟踪与越界后的恢复控制。

Conclusion: 所提出的框架能够在不依赖奖励函数的情况下保障学习过程中的安全性，同时支持连续动态系统的在线学习与安全-恢复统一控制，适用于高安全要求的复杂非线性系统。

Abstract: This paper presents a safety-critical reinforcement learning framework for nonlinear dynamical systems with continuous state and input spaces operating under explicit physical constraints. Hard safety constraints are enforced independently of the reward through action shielding and reachability-based admissible action sets, ensuring that unsafe behaviors are never intentionally selected during learning or execution. To capture nominal operation and recovery behavior within a single control architecture, the state space is partitioned into safe and unsafe regions based on membership in a safety box, and a mode-dependent reward is used to promote accurate tracking inside the safe region and recovery toward it when operating outside. To enable online tabular learning on continuous dynamics, a finite-state abstraction is constructed via state aggregation, and action selection and value updates are consistently restricted to admissible actions. The framework is demonstrated on a longitudinal point-mass hypersonic vehicle model with aerodynamic and propulsion couplings, using angle of attack and throttle as control inputs.

</details>


### [78] [Towards X-embodiment safety: A control theory perspective on transferring safety certificates across dynamical systems](https://arxiv.org/abs/2602.03987)
*Nikolaos Bousias,George Pappas*

Main category: eess.SY

TL;DR: 本文提出了一种转移控制屏障函数（tCBF）框架，用于在具有不匹配动力学的系统之间传递安全性保证，能够在不同维度和动态特性下实现安全约束的迁移，并通过四旋翼导航任务验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于复杂高维系统中直接应用控制屏障函数（CBFs）较为困难，且安全证书通常基于简化模型设计，难以直接适用于实际目标系统，因此需要一种方法将安全性从一个系统迁移到另一个具有不匹配动力学的系统。

Method: 提出转移控制屏障函数（tCBF）框架，利用仿真函数和显式裕度项，将源系统的安全约束转移到目标系统，并通过二次规划安全滤波器在目标系统上实施安全条件。该方法不要求两个系统具有相同的状态维度或动态特性。

Result: 在四旋翼导航任务中成功实现了碰撞避免的安全性迁移，所提出的tCBF框架能有效处理模型失配问题，同时对名义控制器干扰最小。

Conclusion: tCBF为异构动力学系统之间的安全约束迁移提供了一种通用机制，具有广泛的应用潜力。

Abstract: Control barrier functions (CBFs) provide a powerful tool for enforcing safety constraints in control systems, but their direct application to complex, high-dimensional dynamics is often challenging. In many settings, safety certificates are more naturally designed for simplified or alternative system models that do not exactly match the dynamics of interest. This paper addresses the problem of transferring safety guarantees between dynamical systems with mismatched dynamics. We propose a transferred control barrier function (tCBF) framework that enables safety constraints defined on one system to be systematically enforced on another system using a simulation function and an explicit margin term. The resulting transferred barrier accounts for model mismatch and induces a safety condition that can be enforced on the target system via a quadratic-program-based safety filter. The proposed approach is general and does not require the two systems to share the same state dimension or dynamics. We demonstrate the effectiveness of the framework on a quadrotor navigation task with the transferred barrier ensuring collision avoidance for the target system, while remaining minimally invasive to a nominal controller. These results highlight the potential of transferred control barrier functions as a general mechanism for enforcing safety across heterogeneous dynamical systems.

</details>


### [79] [Modular Safety Guardrails Are Necessary for Foundation-Model-Enabled Robots in the Real World](https://arxiv.org/abs/2602.04056)
*Joonkyung Kim,Wenxi Chen,Davood Soleymanzadeh,Yi Ding,Xiangbo Gao,Zhengzhong Tu,Ruqi Zhang,Fan Fei,Sushant Veer,Yiwei Lyu,Minghui Zheng,Yan Gu*

Main category: eess.SY

TL;DR: 本文探讨了基础模型（FMs）在机器人技术中的应用所带来的安全挑战，并提出了模块化安全护栏架构，以在动作、决策和以人为中心三个层面上实现全面的安全保障。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型在机器人中的应用增加，传统的物理约束已不足以确保安全，需要考虑语义推理与人类意图等更广泛的安全维度。

Method: 提出了一种包含监控与干预层的模块化安全护栏架构，并探讨了跨层协同设计的可能性，如表示对齐与保守性分配。

Result: 该方法能够在开放性、长尾分布及动态变化的任务、环境和人类期望中提供更高效、灵活且全面的安全保障。

Conclusion: 社区应进一步探索丰富的护栏模块和系统化的协同设计策略，以推动现实世界中安全的物理人工智能部署。

Abstract: The integration of foundation models (FMs) into robotics has accelerated real-world deployment, while introducing new safety challenges arising from open-ended semantic reasoning and embodied physical action. These challenges require safety notions beyond physical constraint satisfaction. In this paper, we characterize FM-enabled robot safety along three dimensions: action safety (physical feasibility and constraint compliance), decision safety (semantic and contextual appropriateness), and human-centered safety (conformance to human intent, norms, and expectations). We argue that existing approaches, including static verification, monolithic controllers, and end-to-end learned policies, are insufficient in settings where tasks, environments, and human expectations are open-ended, long-tailed, and subject to adaptation over time. To address this gap, we propose modular safety guardrails, consisting of monitoring (evaluation) and intervention layers, as an architectural foundation for comprehensive safety across the autonomy stack. Beyond modularity, we highlight possible cross-layer co-design opportunities through representation alignment and conservatism allocation to enable faster, less conservative, and more effective safety enforcement. We call on the community to explore richer guardrail modules and principled co-design strategies to advance safe real-world physical AI deployment.

</details>


### [80] [Lyapunov Constrained Soft Actor-Critic (LC-SAC) using Koopman Operator Theory for Quadrotor Trajectory Tracking](https://arxiv.org/abs/2602.04132)
*Dhruv S. Kushwaha,Zoleikha A. Biron*

Main category: eess.SY

TL;DR: 本文提出了一种基于Koopman算子理论的Lyapunov约束Soft Actor-Critic（LC-SAC）算法，通过EDMD方法构建系统线性近似并导出李雅普诺夫函数的闭式解，从而在保证非线性系统稳定性的同时实现强化学习控制，在2D四旋翼轨迹跟踪任务中验证了该方法相较于标准SAC具有更好的稳定性和训练收敛性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在安全关键系统中的应用受限于缺乏稳定性保证，传统方法存在候选李雅普诺夫函数选择困难、计算复杂度高和策略过于保守等问题，因此需要一种既能保障稳定性又能保持学习效率的新方法。

Method: 利用Koopman算子理论和扩展动态模态分解（EDMD）对非线性系统进行线性近似，并基于该近似推导出候选李雅普诺夫函数的闭式解；将该函数嵌入Soft Actor-Critic（SAC）算法中，形成Lyapunov约束的LC-SAC算法，以确保策略满足稳定性条件。

Result: 在safe-control-gym框架下的2D四旋翼轨迹跟踪环境中进行评估，结果表明LC-SAC相比标准SAC算法具有更好的训练收敛性，并且李雅普诺夫稳定性约束违反程度逐渐降低。

Conclusion: 所提出的LC-SAC算法结合EDMD与李雅普诺夫约束，能够在不牺牲学习性能的前提下为连续控制任务提供稳定性保证，为强化学习在安全关键系统中的应用提供了可行路径。

Abstract: Reinforcement Learning (RL) has achieved remarkable success in solving complex sequential decision-making problems. However, its application to safety-critical physical systems remains constrained by the lack of stability guarantees. Standard RL algorithms prioritize reward maximization, often yielding policies that may induce oscillations or unbounded state divergence. There has significant work in incorporating Lyapunov-based stability guarantees in RL algorithms with key challenges being selecting a candidate Lyapunov function, computational complexity by using excessive function approximators and conservative policies by incorporating stability criterion in the learning process. In this work we propose a novel Lyapunov-constrained Soft Actor-Critic (LC-SAC) algorithm using Koopman operator theory. We propose use of extended dynamic mode decomposition (EDMD) to produce a linear approximation of the system and use this approximation to derive a closed form solution for candidate Lyapunov function. This derived Lyapunov function is incorporated in the SAC algorithm to further provide guarantees for a policy that stabilizes the nonlinear system. The results are evaluated trajectory tracking of a 2D Quadrotor environment based on safe-control-gym. The proposed algorithm shows training convergence and decaying violations for Lyapunov stability criterion compared to baseline vanilla SAC algorithm. GitHub Repository: https://github.com/DhruvKushwaha/LC-SAC-Quadrotor-Trajectory-Tracking

</details>


### [81] [Mitigation of Structural Harmonic Instability in Virtual Admittance-Based Grid-Forming Inverters via Mimicking Skin Effect](https://arxiv.org/abs/2602.04221)
*Jaekeun Lee,Jae-Jung Jung,Shenghui Cui*

Main category: eess.SY

TL;DR: 本文提出了一种改进的虚拟导纳-电流控制（VA-CC）方案，通过引入并联虚拟电阻增强高频下的阻尼特性，解决了由滤波器与虚拟电感相互作用引起的谐波不稳定性问题，实验验证了该方法在相同电网条件下相比传统方法具有更好的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有VA-CC方案存在谐波不稳定问题，亟需从物理机制上理解其成因并提出改进措施。

Method: 识别出导致谐波不稳定性的二阶非无源传递函数项，并提出在VA结构中加入并联虚拟电阻以提升系统无源性，模拟集肤效应增强高频阻尼。

Result: 所提方法在全谐波频段增强了系统的无源性，无需改动原有的电流控制器和电压前馈控制，即可实现稳定控制。

Conclusion: 通过引入并联虚拟电阻的VA-CC改进方案能有效抑制谐波 instability，实验结果证实其在相同电网条件下显著优于传统方法。

Abstract: The virtual admittance-current controller (VA-CC) scheme is widely employed to emulate an equivalent inductance in front of the internal voltage source of grid-forming inverters. However, recent studies have reported harmonic instabilities associated with VA-CC, motivating the need for a more physically interpretable understanding of their origin. This letter identifies a delay-independent structural mechanism of harmonic instability in the VA-CC scheme, wherein the interaction between the filter and virtual inductances introduces a non-passive second-order transfer-function term exhibiting negative resistance. To address this issue, a simple yet effective modification is proposed by integrating a parallel virtual resistor into the VA structure. This reconfiguration enhances the passivity of VA-CC scheme across the harmonic range by mimicking the skin effect which augments damping in high-frequency range, without altering the wellestablished current controller or voltage feedforward control. Experimental results validate that the proposed method achieves robust harmonic stability, whereas the conventional approach fails under identical grid conditions.

</details>


### [82] [Parameter Privacy-Preserving Data Sharing: A Particle-Belief MDP Formulation](https://arxiv.org/abs/2602.04262)
*Haokun Yu,Jingyuan Zhou,Kaidi Yang*

Main category: eess.SY

TL;DR: 本文研究了在连续状态动态系统中保护敏感参数的隐私数据共享策略，提出了一种基于粒子信念MDP的方法，通过优化信息论隐私泄露与数据可用性之间的权衡，有效防止对手推断敏感参数，同时保持系统性能。


<details>
  <summary>Details</summary>
Motivation: 在动态系统中进行数据共享时，如何在保证下游估计与控制任务性能的同时，防止敏感参数被恶意推断，是一个关键挑战。本文旨在设计一种兼顾隐私与可用性的数据共享策略。

Method: 将隐私数据共享问题建模为权衡隐私泄露与效用影响的优化问题，并转化为信念马尔可夫决策过程（MDP）；采用粒子滤波近似参数后验，提出粒子信念MDP框架，并利用高斯混合模型推导互信息的闭式上界以实现高效优化。

Result: 所提方法在连续状态和动作空间中实现了信息论隐私泄露的有效量化；实验表明该方法能显著抑制对人类驾驶行为参数的推理攻击，同时维持数据可用性和系统性能。

Conclusion: 本文提出的粒子信念MDP框架为连续动态系统中的参数隐私保护提供了可扩展且高效的解决方案，能够在保障数据使用价值的同时实现强隐私保护。

Abstract: This paper investigates parameter-privacy-preserving data sharing in continuous-state dynamical systems, where a data owner designs a data-sharing policy to support downstream estimation and control while preventing adversarial inference of a sensitive parameter. This data-sharing problem is formulated as an optimization problem that trades off privacy leakage and the impact of data sharing on the data owner's utility, subject to a data-usability constraint. We show that this problem admits an equivalent belief Markov decision process (MDP) formulation, which provides a simplified representation of the optimal policy. To efficiently characterize information-theoretic privacy leakage in continuous state and action spaces, we propose a particle-belief MDP formulation that tracks the parameter posterior via sequential Monte Carlo, yielding a tractable belief-state approximation that converges asymptotically as the number of particles increases. We further derive a tractable closed-form upper bound on particle-based MI via Gaussian mixture approximations, which enables efficient optimization of the particle-belief MDP. Experiments on a mixed-autonomy platoon show that the learned continuous policy substantially impedes inference attacks on human-driving behavior parameters while maintaining data usability and system performance.

</details>


### [83] [Peak Bounds for the Estimation Error under Sensor Attacks](https://arxiv.org/abs/2602.04568)
*Axel Stafström,Daniel Arnström,Adam Miksits,David Umsonst*

Main category: eess.SY

TL;DR: 本文研究了在有界扰动和传感器攻击下线性系统的估计误差界，利用L∞系统范数分析攻击下和正常情况下的误差界，并提出一种观测器设计方法以降低受攻击时的误差界，同时讨论检测阈值调节的影响。


<details>
  <summary>Details</summary>
Motivation: 为了在存在扰动和传感器攻击的情况下保证系统估计性能，并防止攻击者在不被检测到的情况下影响系统安全。

Method: 采用诱导L∞范数（峰对峰范数）来分析估计误差界，提出一种兼顾攻击下与正常运行时误差界的观测器设计方法，并调整检测器阈值以增强安全性。

Result: 得到了一个充分条件，表明在何种情况下攻击下的估计误差界小于正常运行时的误差界；该条件与攻击策略无关，仅依赖于攻击者隐蔽意图和观测器增益；数值示例显示不当的误差界可能导致基于控制屏障函数的安全滤波器失效。

Conclusion: 通过合理设计观测器和调整检测阈值，可以在保持正常性能的同时减小攻击带来的估计误差，从而提升系统对隐蔽攻击的鲁棒性。

Abstract: This paper investigates bounds on the estimation error of a linear system affected by norm-bounded disturbances and full sensor attacks. The system is equipped with a detector that evaluates the norm of the innovation signal to detect faults, and the attacker wants to avoid detection. We utilize induced $L_\infty$ system norms, also called \emph{peak-to-peak} norms, to compare the estimation error bounds under nominal operations and under attack. This leads to a sufficient condition for when the bound on the estimation error is smaller during an attack than during nominal operation. This condition is independent of the attack strategy and depends only on the attacker's desire to remain undetected and (indirectly) the observer gain. Therefore, we investigate both an observer design method, that seeks to reduce the error bound under attack while keeping the nominal error bound low, and detector threshold tuning. As a numerical illustration, we show how a sensor attack can deactivate a robust safety filter based on control barrier functions if the attacked error bound is larger than the nominal one. We also statistically evaluate our observer design method and the effect of the detector threshold.

</details>


### [84] [Reinforcement Learning-based Home Energy Management with Heterogeneous Batteries and Stochastic EV Behaviour](https://arxiv.org/abs/2602.04578)
*Meng Yuan,Ye Wang,Xinghuo Yu,Torsten Wik,Changfu Zou*

Main category: eess.SY

TL;DR: 提出了一种基于深度强化学习的家居能源管理框架，用于在不确定性条件下联合优化能源支出和电池退化，同时满足用户舒适度和电动汽车充电需求。


<details>
  <summary>Details</summary>
Motivation: 随着光伏、电动汽车和储能系统在家庭中的广泛应用，如何在存在不确定性的情况下有效协调这些资源成为挑战，且现有研究未充分考虑不同类型电池的退化特性和用户行为的随机性。

Method: 将能量调度问题建模为约束马尔可夫决策过程（CMDP），并采用拉格朗日软演员-评论家（SAC）算法进行求解，显式考虑了固定储能和电动汽车电池的异质退化特性以及用户到达、离开时间和行驶距离的随机行为。

Result: 一年期仿真结果表明，该方法在满足室内温度和电动汽车离家时电量等物理约束的同时，消除了热振荡现象，相比两种基于规则的基线方法显著降低了累计运行成本，并将电池退化成本减少了8.44%。

Conclusion: 所提出的DRL-based框架能有效协调家庭多能源设备，在复杂不确定环境下实现经济性与设备寿命的协同优化，具有良好的实际应用潜力。

Abstract: The widespread adoption of photovoltaic (PV), electric vehicles (EVs), and stationary energy storage systems (ESS) in households increases system complexity while simultaneously offering new opportunities for energy regulation. However, effectively coordinating these resources under uncertainties remains challenging. This paper proposes a novel home energy management framework based on deep reinforcement learning (DRL) that can jointly minimise energy expenditure and battery degradation while guaranteeing occupant comfort and EV charging requirements. Distinct from existing studies, we explicitly account for the heterogeneous degradation characteristics of stationary and EV batteries in the optimisation, alongside stochastic user behaviour regarding arrival time, departure time, and driving distance. The energy scheduling problem is formulated as a constrained Markov decision process (CMDP) and solved using a Lagrangian soft actor-critic (SAC) algorithm. This approach enables the agent to learn optimal control policies that enforce physical constraints, including indoor temperature bounds and target EV state of charge upon departure, despite stochastic uncertainties. Numerical simulations over a one-year horizon demonstrate the effectiveness of the proposed framework in satisfying physical constraints while eliminating thermal oscillations and achieving significant economic benefits. Specifically, the method reduces the cumulative operating cost substantially compared to two standard rule-based baselines while simultaneously decreasing battery degradation costs by 8.44%.

</details>


### [85] [Safe Adaptive Control of Parabolic PDE-ODE Cascades](https://arxiv.org/abs/2602.04656)
*Yun Jiang,Ji Wang*

Main category: eess.SY

TL;DR: 提出了一种针对具有参数不确定性的抛物型PDE-ODE级联系统的安全自适应边界控制策略，结合自适应控制屏障函数（aCBF）与批量最小二乘辨识（BaLSI），确保系统安全性和状态收敛性。


<details>
  <summary>Details</summary>
Motivation: 针对PDE-ODE级联系统中存在PDE和ODE子系统参数不确定性的问题，现有方法难以同时保证系统安全性和状态收敛，因此需要设计一种能处理多重不确定并满足安全与时效性要求的自适应控制策略。

Method: 采用基于自适应控制屏障函数（aCBF）的框架，结合高相对阶CBF与批量最小二乘辨识（BaLSI）方法，在有限时间内实现参数的精确辨识，并设计边界控制律以确保系统输出进入安全集并在预设时间内保持安全，同时实现全状态收敛至零。

Result: 所提控制策略能够确保：若初始状态在安全集内，则系统安全性始终维持；若不在，则在预设有限时间内返回安全区，并实现所有系统状态收敛至零。数值仿真验证了该方法的有效性。

Conclusion: 本文提出的基于aCBF与BaLSI的自适应边界控制策略，有效解决了具参数不确定PDE-ODE级联系统的安全控制问题，兼具有限时间参数辨识、安全保证与状态收敛能力，具有良好的应用潜力。

Abstract: In this paper, we propose a safe adaptive boundary control strategy for a class of parabolic partial differential equation-ordinary differential equation (PDE-ODE) cascaded systems with parametric uncertainties in both the PDE and ODE subsystems. The proposed design is built upon an adaptive Control Barrier Function (aCBF) framework that incorporates high-relative-degree CBFs together with a batch least-squares identification (BaLSI)-based adaptive control that guarantees exact parameter identification in finite time. The proposed control law ensures that: (i) if the system output state initially lies within a prescribed safe set, safety is maintained for all time; otherwise, the output is driven back into the safe region within a preassigned finite time; and (ii) convergence to zero of all plant states is achieved. Numerical simulations are provided to demonstrate the effectiveness of the proposed approach.

</details>


### [86] [Dynamic Constraint Tightening for Nonlinear MPC for Autonomous Racing via Contraction Analysis](https://arxiv.org/abs/2602.04744)
*Joscha F. Bongard,Valentin L. Krieger,Boris Lohmann*

Main category: eess.SY

TL;DR: 提出了一种基于控制收缩度量（CCM）的鲁棒非线性模型预测控制框架，用于自动驾驶车辆在极限工况下的路径跟踪，具有计算高效和约束适应性强的优点。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶车辆在轮胎参数不确定和外部扰动存在时，在极限操控条件下的路径跟踪鲁棒性。

Method: 基于摄动单轨动力学模型设计非线性MPC，并利用优化后的CCM参数化同伦管以实现约束收紧。

Result: 仿真表明该方法能有效处理不确定性，在动态极限下保持约束满足，且仅比标称模型多一个状态变量，计算效率高。

Conclusion: 所提出的基于CCM的鲁棒非线性MPC方法在保证控制性能的同时提升了鲁棒性和计算效率，适用于极限工况下的自动驾驶车辆控制。

Abstract: This work develops a robust nonlinear Model Predictive Control (MPC) framework for path tracking in autonomous vehicles operating at the limits of handling utilizing a Control Contraction Metric (CCM) derived from a perturbed dynamic single track model. We first present a nonlinear MPC scheme for autonomous vehicles. Building on this nominal scheme, we assume limited uncertainty in tire parameters as well as bounded force disturbances in both lateral and longitudinal directions. By simplifying the perturbed model, we optimize a CCM for the uncertain model, which is validated through simulations at the dynamic limits of vehicle performance. This CCM is subsequently employed to parameterize a homothetic tube used for constraint tightening within the MPC formulation. The resulting robust nonlinear MPC is computationally more efficient than competing methods, as it introduces only a single additional state variable into the prediction model compared to the nominal scheme. Simulation results demonstrate that the homothetic tube expands most significantly in regions where the nominal scheme would otherwise violate constraints, illustrating its ability to capture all uncertain trajectories while avoiding unnecessary conservatism.

</details>


### [87] [Control Lyapunov Functions for Optimality in Sontag-Type Control](https://arxiv.org/abs/2602.04756)
*Joscha F. Bongard,Boris Lohmann*

Main category: eess.SY

TL;DR: 本文研究了基于控制李雅普诺夫函数（CLF）的Sontag公式在非线性系统中的应用，提出利用LQR的值函数作为CLF可优化局部和全局性能，并扩展至反馈线性化系统实现全局渐近稳定。


<details>
  <summary>Details</summary>
Motivation: 尽管已有方法可构造特定系统的CLF，但其对控制性能的影响尚不明确，本文旨在明确Sontag型控制器在使用特定CLF时的优化行为与稳定性保证。

Method: 采用LQR的值函数作为CLF，结合Sontag公式设计状态反馈控制器；对于可反馈线性化的系统，提出一种构造全局CLF的方法。

Result: 证明了所提出的控制器在局部至少具有与LQR相同的稳定域，并能最小化一个围绕设定点的二次代价函数和一个依赖CLF的代价函数；对于反馈线性化系统可实现全局渐近稳定和全局代价优化。

Conclusion: 该方法为非线性多输入系统提供了一种构造性强、易于实现的控制设计途径，在保持稳定性的同时优化了控制性能。

Abstract: Given a Control Lyapunov Function (CLF), Sontag's famous Formula provides a nonlinear state-feedback guaranteeing asymptotic stability of the setpoint. At the same time, a cost function that depends on the CLF is minimized. While there exist methods to construct CLFs for certain classes of systems, the impact on the resulting performance is unclear. This article aims to make two contributions to this problem: (1) We show that using the value function of an LQR design as CLF, the resulting Sontag-type controller minimizes a classical quadratic cost around the setpoint and a CLF-dependent cost within the domain where the CLF condition holds. We also show that the closed-loop system is stable within a local region at least as large as that generated by the LQR. (2) We show a related CLF design for feedback-linearizable systems resulting in a global CLF in a straight-forward manner; The Sontag design then guarantees global asymptotic stability while minimizing a quadratic cost at the setpoint and a CLF-dependent cost in the whole state-space. Both designs are constructive and easily applicable to nonlinear multi-input systems under mild assumptions.

</details>


### [88] [SQP-Based Cable-Tension Allocation for Multi-Drone Load Transport](https://arxiv.org/abs/2602.04801)
*Lamberto Vazquez-Soqui,Fatima Oliva-Palomo,Diego Mercado-Ravell,Pedro Castillo*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Multi-Agent Aerial Load Transport Systems (MAATS) offer greater payload capacity and fault tolerance than single-drone solutions. However, they have an underdetermined tension allocation problem that leads to uneven energy distribution, cable slack, or collisions between drones and cables. This paper presents a real-time optimization layer that improves a hierarchical load-position-attitude controller by incorporating a Sequential Quadratic Programming (SQP) algorithm. The SQP formulation minimizes the sum of squared cable tensions while imposing a cable-alignment penalty that discourages small inter-cable angles, thereby preventing tether convergence without altering the reference trajectory. We tested the method under nominal conditions by running numerical simulations of four quadrotors. Computational experiments based on numerical simulations demonstrate that the SQP routine runs in a few milliseconds on standard hardware, indicating feasibility for real-time use. A sensitivity analysis confirms that the gain of the cable-alignment penalty can be tuned online, enabling a controllable trade-off between safety margin and energy consumption with no measurable degradation of tracking performance in simulation. This framework provides a scalable path to safe and energy-balanced cooperative load transport in practical deployments.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [89] [A phenomenological description of critical slowing down at period-doubling bifurcations](https://arxiv.org/abs/2602.04091)
*Edson D. Leonel,João P. C. Ferreira,Diego F. M. Oliveira*

Main category: nlin.CD

TL;DR: 本文提出了一个描述离散动力系统中倍周期分岔相关临界慢化的现象学理论，通过局部泰勒展开推导出在临界点及附近向稳态收敛的简化描述，并验证了其在一维和二维映射中的普适性。


<details>
  <summary>Details</summary>
Motivation: 研究离散动力系统中倍周期分岔导致的临界慢化现象，探索其在不同维度系统中的普适性描述。

Method: 基于固定点和分岔参数的局部泰勒展开，建立简化模型；通过中心流形上的动力学投影，将二维系统的局部标准型约化为一维情况的普适结构，并利用Hénon和Ikeda映射进行数值验证。

Result: 在分岔点处获得三个普适临界指数，分别表征短时行为、渐近衰减及两者之间的交叉行为；在远离临界性时识别出第四个控制弛豫时间的指数；数值结果与理论预测高度一致。

Conclusion: 该现象学理论不仅适用于一维映射，还可自然推广至二维映射，揭示了不同维度下倍周期分岔的普适临界行为。

Abstract: We present a phenomenological description of the critical slowing down associated with period-doubling bifurcations in discrete dynamical systems. Starting from a local Taylor expansion around the fixed point and the bifurcation parameter, we derive a reduced description that captures the convergence towards stationary state both at and near criticality. At the bifurcation point, three universal critical exponents are obtained, characterising the short-time behaviour, the asymptotic decay, and the crossover between these regimes. Away from criticality, a fourth exponent governing the relaxation time is identified. We show this phenomenology, well established for one-dimensional maps, extends naturally to two-dimensional mappings. By projecting the dynamics onto the centre manifold, we demonstrate that the local normal form of a two-dimensional period-doubling bifurcation reduces to the same universal structure found in one dimension. The theoretical predictions are validated numerically using the Hénon and Ikeda maps, showing excellent agreement for all scaling laws and critical exponents.

</details>


### [90] [Semiclassical Structure of the Advection--Diffusion Spectrum in Mixed Phase Spaces](https://arxiv.org/abs/2602.04730)
*Christopher Amey,Bala Sundaram,Andrew C. Poje*

Main category: nlin.CD

TL;DR: 研究了二维对流-扩散算子在混合相空间流体中大佩克莱数下的谱结构，发现谱的组织受局部拉格朗日相空间几何控制，存在三种本征模式，导致有限时间动力学由多种模式竞争主导。


<details>
  <summary>Details</summary>
Motivation: 理解大佩克莱数下混合相空间中对流-扩散过程的谱特性及其动力学行为。

Method: 结合傅里叶离散化、对称性约化和Krylov-Arnoldi方法计算前百个本征对，并基于半经典类比标记本征模式。

Result: 发现了三种本征模式：与不变环面输运相关的对流模式、扩散模式以及正则区域间弱耦合产生的隧穿模式；谱间隙非均匀，存在模态竞争。

Conclusion: 在大佩克莱数下，由于不同本征模式家族共存且谱间隙不一致，有限时间内的对流-扩散动力学由多模式竞争主导而非单一模式支配。

Abstract: We examine the spectral structure of the two-dimensional advection-diffusion operator in flows with mixed phase space at very large Peclet number. Using Fourier discretization combined with symmetry reduction and Krylov-Arnoldi methods, we compute on the order of one hundred leading eigenpairs reliably in the asymptotic, weak-diffusion regime. While the principal eigenvalue is asymptotically diffusive and localized on the largest regular region, the broader spectrum exhibits a rich organization controlled by local Lagrangian phase-space geometry. In particular, exponential mixing in chaotic regions rapidly suppresses correlations, whereas algebraic mixing in integrable regions generates long-lived coherent structures that dominate the slow and intermediate parts of the spectrum. We identify three distinct classes of eigenmodes: advective modes associated with transport on invariant tori, diffusive modes and, within the duffusive branch, tunneling modes arising from weak coupling between dynamically separated regular regions. Drawing on a semiclassical analogy, we assign quantum-number-like labels to these families and predict the appearance, scaling, and ordering of their sub-spectra directly from the Hamiltonian phase-space structure. The coexistence of these families implies that no uniform control of the spectral gap exists across the full spectrum: although the slowest mode is diffusive, arbitrarily small gaps arise between competing families at higher mode numbers. As a result, finite-time advection-diffusion dynamics is generically governed by persistent modal competition rather than single-mode dominance, even at asymptotically large Peclet number.

</details>


### [91] [Correspondence between classical and quantum resonances](https://arxiv.org/abs/2602.04793)
*F. J. Arranz,F. Borondo*

Main category: nlin.CD

TL;DR: 研究了CN-Li⇋Li-CN异构化系统中经典共振的量子表现，通过能级与普朗克常数的相关图揭示了避免交叉序列及其对应的量子共振，并发展了半经典理论以获得解析表达式。


<details>
  <summary>Details</summary>
Motivation: 探索分子哈密顿非线性系统中随激发能增加出现的经典共振的量子对应现象。

Method: 使用能级与普朗克常数的相关图分析避免交叉序列，并发展半经典理论。

Result: 发现了不同系列的避免交叉，对应于量子共振；外推至ħ=0揭示了经典共振分岔能与量子共振能在半经典极限下的对应关系。

Conclusion: 经典共振的分岔能量在半经典极限下对应于量子共振的能量，证实了经典与量子共振之间的深刻联系。

Abstract: Bifurcations take place in molecular Hamiltonian nonlinear systems as the excitation energy increases, this leading to the appearance of different classical resonances. In this paper, we study the quantum manifestations of these classical resonances in the isomerizing system CN-Li$\leftrightarrows$Li-CN. By using a correlation diagram of eigenenergies versus Planck constant, we show the existence of different series of avoided crossings, leading to the corresponding series of quantum resonances, which represent the quantum manifestations of the classical resonances. Moreover, the extrapolation of these series to $\hbar=0$ unveils the correspondence between the bifurcation energy of classical resonances and the energy of the series of quantum resonances in the semiclassical limit $\hbar\to0$. Additionally, in order to obtain analytical expressions for our results, a semiclassical theory is developed.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [92] [Bayes, E-values and Testing](https://arxiv.org/abs/2602.04146)
*Nick Polson,Vadim Sokolov,Daniel Zantedeschi*

Main category: math.ST

TL;DR: 本文探讨了Kolmogorov复杂度、Shannon熵、贝叶斯因子、E值和可交换性检验之间的关系，重点是负对数边际或预测概率作为连接编码、预测和序列检验的共同证据统计量。


<details>
  <summary>Details</summary>
Motivation: 旨在揭示不同信息论工具在衡量证据强度方面的联系，并探索其在可交换性检验中的应用。

Method: 回顾相关的信息论和鞅工具，讨论通过共形e-预测进行的可交换性检验。

Result: 建立了多种统计量与证据测度之间的理论联系，为序列假设检验提供了新的视角。

Conclusion: 负对数预测概率作为一种通用证据统计量，在连接编码、预测和测试方面具有重要作用。

Abstract: This paper studies relationships between Kolmogorov complexity, Shannon entropy, Bayes factors, E-values, and exchangeability testing. The focus is on negative log marginal or predictive probabilities -- what I.J.~Good termed the ``weight of evidence'' -- as a common evidence statistic linking coding, prediction, and sequential testing. The paper reviews the relevant information-theoretic and martingale tools, and discusses exchangeability testing via conformal e-prediction.

</details>


### [93] [Phase Transition of Spectral Fluctuations in Large Gram Matrices with a Variance Profile: A Unified Framework for Sparse CLTs](https://arxiv.org/abs/2602.04302)
*Rui Wang,Guangming Pan,Dandan Jiang*

Main category: math.ST

TL;DR: 研究了具有稀疏性和给定方差分布的高维随机Gram矩阵的渐近谱行为，建立了经验谱分布的收敛性及线性谱统计量的中心极限定理，揭示了不同稀疏性 regime 下的相变现象，并应用于大规模MIMO系统的假设检验和中断概率分析。


<details>
  <summary>Details</summary>
Motivation: 受无线通信应用驱动，研究高维稀疏Gram矩阵在不同稀疏程度下的谱分布行为，以更好地理解其统计特性。

Method: 采用基于预解式技术和鞅差分方法的分析工具，研究两种渐近稀疏情形下（中等稀疏与高稀疏）的经验谱分布收敛性与线性谱统计量的中心极限定理。

Result: 证明了在两种稀疏 regime 下经验谱分布收敛到确定性极限，并发现高稀疏情形下波动由四阶矩主导且需对中心化项进行显式修正，揭示了相变现象；结果适用于高斯与非高斯情形。

Conclusion: 稀疏性水平显著影响谱统计量的渐近行为，需根据稀疏程度调整中心化方式，理论结果可有效应用于大规模MIMO系统的统计推断与性能分析。

Abstract: We study the asymptotic spectral behavior of high-dimensional random Gram matrices with sparsity and a given variance profile, motivated by applications in wireless communication. Specifically, we consider the Gram matrices $\mathbf S_n=\mathbf Y_n\mathbf Y_n^*$, where the entries of $\mathbf Y_n$ are independent, centered, heteroscedastic, and sparse through Bernoulli masking. The sparsity level is parameterized as $s=q^2/n$, with $q$ ranging from polynomial order to order $n^{1/2}$.
  We investigate two asymptotic regimes in a high-dimensional framework: a moderate-sparsity regime with fixed $s\in(0,1]$, and a high-sparsity regime where $s\to0$. In both regimes, we establish the convergence of the empirical spectral distribution of $\mathbf S_n$ to a deterministic limit, and further derive central limit theorems for linear spectral statistics using resolvent techniques and martingale difference arguments. Our analysis reveals a phase transition in the fluctuation behavior across the two regimes. In the high-sparsity regime, the asymptotic fluctuations are governed by fourth-moment effects, with sparsity-scaled contributions being suppressed. Moreover, a mismatch between the scaling of the mean and variance, of different orders in $q$, necessitates an explicit correction in the centering of the linear spectral statistic. The theory applies to both Gaussian and non-Gaussian entries, and its statistical utility is illustrated through applications to hypothesis testing and outage probability analysis in large-scale MIMO systems.

</details>


### [94] [Universality of General Spiked Tensor Models](https://arxiv.org/abs/2602.04472)
*Yanjin Xiang,Zhihua Zhang*

Main category: math.ST

TL;DR: 研究了高维下非高斯噪声的秩一尖峰张量模型，证明了其谱分布和统计极限具有与高斯情形相同的普适性。


<details>
  <summary>Details</summary>
Motivation: 扩展经典高斯框架至更广泛的非高斯噪声分布，探究尖峰张量模型在高维下的普适性行为。

Method: 采用随机矩阵理论中的预解子方法、基于有限矩假设的累积量展开以及Efron-Stein型方差界，分析块状张量收缩后的经验谱分布。

Result: 经验谱分布在几乎必然意义下收敛到与高斯情形相同的确定极限，奇异值及估计方向与真实信号方向的对齐关系可显式刻画。

Conclusion: 建立了尖峰张量模型的普适性原理，表明其高维谱行为和统计极限对非高斯噪声具有鲁棒性。

Abstract: We study the rank-one spiked tensor model in the high-dimensional regime, where the noise entries are independent and identically distributed with zero mean, unit variance, and finite fourth moment.This setting extends the classical Gaussian framework to a substantially broader class of noise distributions.Focusing on asymmetric tensors of order $d$ ($\ge 3$), we analyze the maximum likelihood estimator of the best rank-one approximation.Under a mild assumption isolating informative critical points of the associated optimization landscape, we show that the empirical spectral distribution of a suitably defined block-wise tensor contraction converges almost surely to a deterministic limit that coincides with the Gaussian case.As a consequence, the asymptotic singular value and the alignments between the estimated and true spike directions admit explicit characterizations identical to those obtained under Gaussian noise. These results establish a universality principle for spiked tensor models, demonstrating that their high-dimensional spectral behavior and statistical limits are robust to non-Gaussian noise.
  Our analysis relies on resolvent methods from random matrix theory, cumulant expansions valid under finite moment assumptions, and variance bounds based on Efron-Stein-type arguments. A key challenge in the proof is how to handle the statistical dependence between the signal term and the noise term.

</details>


### [95] [Estimation of reliability and accuracy of models of $\varphi$-sub-Gaussian process using generating functions of polynomial expansions](https://arxiv.org/abs/2602.04668)
*Oleksandr Mokliachuk*

Main category: math.ST

TL;DR: 本文扩展了φ-次高斯过程的可靠性与精度估计方法，应用于无解析生成函数的正交多项式系统（如勒让德、广义拉盖尔和盖根鲍尔多项式），推导出同时考虑截断误差和系数逼近误差的新界，为基于多项式的随机过程模型提供了实用的级数项数选择准则。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注正交级数展开中的截断误差，但在实际建模中，当系数函数无闭式表达时，还需考虑其逼近误差。这两种误差的联合影响在文献中尚未充分解决，因此需要发展更全面的误差分析框架。

Method: 基于作者前期关于φ-次高斯过程的研究成果，将方法推广至不具备解析归一化生成函数的正交多项式系统，并在L_p空间和连续函数空间中推导同时包含截断误差和系数逼近误差的新型误差界。

Result: 得到了适用于L_p(T)和C([0,T])空间的新误差上界，能够同时量化截断与系数逼近带来的误差，提出了可操作的准则用于确定实现预定可靠性与精度所需的级数项数。

Conclusion: 所提出的方法为更广泛的基于正交多项式的随机过程模型提供了兼顾多种误差源的精度与可靠性评估工具，增强了此类模型在实际应用中的可信度与实用性。

Abstract: Stochastic processes are often represented through orthonormal series expansions, a framework originating in the classical works of Loève and Karhunen and widely used for simulation and numerical approximation. While truncation error in such expansions has been extensively studied, practical models frequently involve an additional source of error arising from the approximation of coefficient functions when closed-form expressions are unavailable. The combined effect of these two errors remains insufficiently addressed in the literature. Building on the author's earlier work on reliability and accuracy estimates for $\varphi$-sub-Gaussian processes, this paper extends the methodology to orthonormal polynomial systems that do not possess normalized generating functions in analytical form, including the Legendre, generalized Laguerre, and Gegenbauer families. New bounds are derived for models in $L_p(T)$ and $C([0,T])$ that simultaneously account for truncation and coefficient approximation. The resulting criteria provide practical guidance for selecting the number of series terms required to achieve prescribed levels of reliability and accuracy across a broader class of polynomial-based stochastic process models.

</details>


### [96] [Statistical inference for the stochastic wave equation based on discrete observations](https://arxiv.org/abs/2602.04708)
*Anton Tiepner,Mathias Trabs,Eric Ziebell*

Main category: math.ST

TL;DR: 提出了一种基于离散观测的矩估计方法，用于估计由Riesz噪声驱动的随机波动方程在无界多维空间域上的波速，建立了空间、时间和时空二阶变差的中心极限定理，并证明了估计量的渐近正态性。


<details>
  <summary>Details</summary>
Motivation: 为了准确估计在复杂噪声环境下随机波动方程的波速，需要发展适用于高维无界区域且基于离散数据的有效统计推断方法。

Method: 通过建立空间、时间及时空二阶变差的中心极限定理，利用二阶增量协方差结构的闭式表达（涉及两种Fejér型核），构造矩估计方法，并分析其在不同采样频率下的渐近性质。

Result: 所提出的矩估计量在一般采样条件下具有渐近正态性，协方差结构具有明确的闭式表达，能够精确刻画空间与时间成分之间的相互作用。

Conclusion: 该方法为基于离散观测的随机波动方程参数估计提供了理论支持，尤其适用于多维无界域中的波速推断问题。

Abstract: The wave speed of a stochastic wave equation driven by Riesz noise on the unbounded multidimensional spatial domain is estimated based on discrete measurements. Central limit theorems for second-order variations of the observations in space, time, and space-time are established. Under general assumptions on the spatial and temporal sampling frequencies, the resulting method-of-moments estimators are asymptotically normally distributed. The covariance structure of the discrete increments admits a closed-form representation involving two different Fejér-type kernels, enabling a precise analysis of the interplay between spatial and temporal contributions.

</details>


### [97] [Adaptive estimation of Sobolev-type energy functionals on the sphere](https://arxiv.org/abs/2602.04823)
*Claudio Durastanti*

Main category: math.ST

TL;DR: 本文研究了单位球面上未知密度的二次Sobolev型积分泛函的估计问题，利用球面needlet框架构造无偏估计量，并通过偏差-方差分析得到尖锐的oracle风险界。在密度光滑性未知时，提出数据驱动的分辨率选择方法，所得到的自适应估计量在Sobolev类上达到最优收敛速率。


<details>
  <summary>Details</summary>
Motivation: 为了对单位球面上未知密度的全局光滑性和谱能量进行有效估计，需要发展适用于分数阶拉普拉斯-贝尔特拉米算子定义的Sobolev型泛函的非参数估计方法。

Method: 采用球面needlet框架实现函数的局部化多尺度分解，构造截断版本泛函的无偏估计量，并通过偏差-方差分析推导oracle风险界；在光滑性未知时，使用Lepski型数据驱动方法选择分辨率层次。

Result: 得到了估计量的尖锐oracle风险界，自适应估计量在Sobolev类上达到了最小最大最优收敛速率，且无需依赖非线性或稀疏性方法。

Conclusion: 基于球面needlet的自适应估计方法能够高效地估计由分数阶拉普拉斯-贝尔特拉米算子定义的Sobolev型泛函，在未知光滑性条件下仍可达到最优性能。

Abstract: We study the estimation of quadratic Sobolev-type integral functionals of an unknown density on the unit sphere. The functional is defined through fractional powers of the Laplace--Beltrami operator and provides a global measure of smoothness and spectral energy. Our approach relies on spherical needlet frames, which yield a localized multiscale decomposition while preserving tight frame properties in the natural square-integrable function space on the sphere.
  We construct unbiased estimators of suitably truncated versions of the functional and derive sharp oracle risk bounds through an explicit bias--variance analysis. When the smoothness of the density is unknown, we propose a Lepski-type data-driven selection of the resolution level. The resulting adaptive estimator achieves minimax-optimal rates over Sobolev classes, without resorting to nonlinear or sparsity-based methods.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [98] [Numerical study of loss of hyperbolicity using a cold plasma model](https://arxiv.org/abs/2602.03859)
*Evgeniy V. Chizhonkov,Olga S. Rozanova*

Main category: physics.comp-ph

TL;DR: 本文研究了一维冷等离子体方程组在考虑电子-离子碰撞情况下的解的光滑性问题，提出了一种新的欧拉变量下的隐式求解方法，克服了因碰撞系数依赖电子密度而导致系统失去双曲性所带来的计算困难，并在相对论和非相对论情况下进行了验证。


<details>
  <summary>Details</summary>
Motivation: 由于碰撞系数ν对电子密度N的依赖关系会导致系统失去双曲性，从而引发数值计算困难，因此需要发展新的数值方法来处理此类问题。

Method: 提出一种新的基于欧拉变量的隐式求解方法，适用于相对论与非相对论情形，并针对线性依赖ν(N)=ν₁+ν₀N这一临界情况进行数值实验。

Result: 该方法成功克服了系统失去双曲性带来的计算难题，在临界情况下仍能有效运行，且数值结果与现有理论完全一致。

Conclusion: 所提出的隐式方法能够有效处理具有密度依赖碰撞项的冷等离子体方程，保证了在可能失稳条件下数值解的稳定性与准确性。

Abstract: We study a one-dimensional system of cold plasma equations taking into account electron-ion collisions in both relativistic and nonrelativistic cases. It is known that for a constant collision coefficient $ν$, the solution to the Cauchy problem for such a system can lose smoothness. However, if the dependence of $ν$ on the electron density $N$ is more than linear, then the solution remains globally smooth for any initial data. However, the appearance of the dependence $ν(N)$ leads to a change in the type of the system, it loses hyperbolicity, which leads to computational problems. In this paper, we propose a new implicit solution method in Euler variables that overcomes these difficulties. It can be used in both nonrelativistic and relativistic cases and is tested for the threshold case of a linear dependence $ν(N)=ν_1+ν_0 N$, when smoothness can still be lost. The computational experiments carried out are in full agreement with the available theoretical results.

</details>


### [99] [Topology- and Geometry-Exact Coupling for Incompressible Fluids and Thin Deformables](https://arxiv.org/abs/2602.03988)
*Jonathan Panuelos,Eitan Grinspun,David Levin*

Main category: physics.comp-ph

TL;DR: 提出了一种保持拓扑结构的离散化方法，用于不可压缩流体与薄弹性结构的耦合，确保流体域连通性并实现无泄漏模拟。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理极薄结构时容易出现流体泄漏或破坏流体域连通性，难以精确施加边界条件。

Method: 基于拉格朗日流体粒子生成裁剪后的Voronoi图，并采用缝合算法保持绕过障碍物的路径连通性；在此保形网格上离散压力投影方程，实现界面处速度边界条件和压力力的精确施加。

Result: 实现了流体与薄弹性结构间的锐利双向耦合，有效防止流体穿透固体，同时允许连续流道中的自然流动，适用于复杂几何和可变形结构。

Conclusion: 该方法通过保持拓扑连通性解决了薄结构耦合中的泄漏问题，在多种场景中展示了鲁棒的双向耦合效果，无需人工密封或额外修正。

Abstract: We introduce a topology-preserving discretization for coupling incompressible fluids with thin deformable structures, achieving guaranteed leakproofness through preservation of fluid domain connectivity. Our approach leverages a stitching algorithm applied to a clipped Voronoi diagram generated from Lagrangian fluid particles, in order to maintain path connectivity around obstacles. This geometric discretization naturally conforms to arbitrarily thin structures, enabling boundary conditions to be enforced exactly at fluid-solid interfaces. By discretizing the pressure projection equations on this conforming mesh, we can enforce velocity boundary conditions at the interface for the fluid while applying pressure forces directly on the solid boundary, enabling sharp two-way coupling between phases. The resulting method prevents fluid leakage through solids while permitting flow wherever a continuous path exists through the fluid domain. We demonstrate the effectiveness of our approach on diverse scenarios including flows around thin membranes, complex geometries with narrow passages, and deformable structures immersed in liquid, showcasing robust two-way coupling without artificial sealing or leakage artifacts.

</details>


### [100] [At the Top of the Mountain, the World can Look Boltzmann-Like: Sampling Dynamics of Noisy Double-Well Systems](https://arxiv.org/abs/2602.04014)
*Abir Hasan,Nikhil Shukla*

Main category: physics.comp-ph

TL;DR: 该论文提出了一种基于双势阱系统在鞍点附近的随机动力学的普适性，利用拓扑框架揭示了不同物理系统中p-bit（概率比特）实现的统一原理，支持鲁棒的同步随机采样与概率计算。


<details>
  <summary>Details</summary>
Motivation: 寻找类似于晶体管在数字计算中的基础作用的硬件原语——p-bit，以推动概率计算的发展。

Method: 采用基于Morse理论和奇点理论的拓扑框架，将平滑偶对称双势阱势近似为标准四次规范形式，并分析噪声、偏置和势曲率在鞍点附近的短时演化行为。

Result: 发现多种双势阱系统在鞍点附近表现出由tanh型响应主导的拓扑稳健短期演化，可实现类玻尔兹曼采样，且结果不依赖于势的具体形状，仅通过有效温度缩放。数值模拟和解析推导在多个系统中验证了这一行为。

Conclusion: 为评估和设计各类物理平台（如振荡器、双稳态锁存器和磁性器件）作为p-bit用于同步概率计算提供了统一的理论基础。

Abstract: The success of the transistor as the cornerstone of digital computation motivates analogous efforts to identify an equivalent hardware primitive, the probabilistic bit or p-bit, for the emerging paradigm of probabilistic computing. Here, we uncover a fundamental ubiquity in the stochastic dynamics of double well energy systems when initialized near the barrier top. Using a topological framework grounded in Morse theory and singularity theory, we make use of the result that all smooth, even double well potentials reduce near the saddle point to a canonical quartic normal form. Within this regime, the interplay of noise, synaptic bias, and potential curvature produces a topologically robust short time evolution characterized by a tanh like response. This enables Boltzmann like sampling that is largely independent of the detailed shape of the potential, apart from its effective temperature scaling. Analytical derivations and numerical simulations across multiple representative systems corroborate this behavior. Our work provides a unifying foundation for assessing and engineering a broad class of physical platforms, including oscillators, bistable latches, and magnetic devices, as p-bits operating within a synchronous framework for stochastic sampling and probabilistic computation.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [101] [Robust Nonparametric Two-Sample Tests via Mutual Information using Extended Bregman Divergence](https://arxiv.org/abs/2602.04010)
*Arijit Pyne*

Main category: stat.ME

TL;DR: 本文提出了一种基于扩展Bregman散度的广义互信息（MI）框架，统一了S-散度和Bregman指数散度，用于构建稳健且一致的非参数双样本检验方法，并通过理论分析与实验验证其在污染数据下的优越鲁棒性和渐近功效。


<details>
  <summary>Details</summary>
Motivation: 为了统一分散的统计距离并发展更具鲁棒性的非参数检验方法，本文旨在构建一个涵盖广泛散度族的广义互信息框架。

Method: 基于扩展Bregman散度定义广义互信息，构造非参数双样本检验统计量，推导其在原假设和相邻备择假设下的渐近正态性，并通过影响函数和崩溃点分析其鲁棒性。

Result: 所提检验方法具有渐近正态性、良好的鲁棒性（尤其在污染数据下表现优于传统方法），且多类散度（如DPD、S-HD）在保持高效率的同时表现出更优性能；提出了数据驱动的调参策略。

Conclusion: 广义互信息框架为非参数两样本检验提供了统一且稳健的方法，兼具高渐近效率与强鲁棒性，具有实际应用价值。

Abstract: We introduce a generalized formulation of mutual information (MI) based on the extended Bregman divergence, a framework that subsumes the generalized S-Bregman (GSB) divergence family. The GSB divergence unifies two important classes of statistical distances, namely the S-divergence and the Bregman exponential divergence (BED), thereby encompassing several widely used subfamilies, including the power divergence (PD), density power divergence (DPD), and S-Hellinger distance (S-HD). In parametric inference, minimum divergence estimators are well known to balance robustness with high asymptotic efficiency relative to the maximum likelihood estimator. However, nonparametric tests based on such statistical distances have been relatively less explored. In this paper, we construct a class of consistent and robust nonparametric two-sample tests for the equality of two absolutely continuous distributions using the generalized MI. We establish the asymptotic normality of the proposed test statistics under the null and contiguous alternatives. The robustness properties of the generalized MI are rigorously studied through the influence function and the breakdown point, demonstrating that stability of the generalized MI translates into stability of the associated tests. Extensive simulation studies show that divergences beyond the PD family often yield superior robustness under contamination while retaining high asymptotic power. A data-driven scheme for selecting optimal tuning parameters is also proposed. Finally, the methodology is illustrated with applications to real data.

</details>


### [102] [Privacy Amplification for Synthetic data using Range Restriction](https://arxiv.org/abs/2602.04124)
*Monika Hu,Matthew R. Williams,Terrance D. Savitsky*

Main category: stat.ME

TL;DR: 提出了一类新的范围受限的形式化数据隐私标准，通过结合数据所有者对敏感数据范围的先验信念，增强了隐私保护，适用于基于风险加权伪后验机制生成合成数据的场景。


<details>
  <summary>Details</summary>
Motivation: 现有的形式化隐私标准可能在某些先验知识已知的情况下过于保守或不足，因此需要引入能结合数据所有者对敏感值范围信念的新型隐私标准，以提供更强的隐私保障。

Method: 设计了两种结合先验信念的调整方法：一是使用概率λ表示数据落在非敏感区域的可能性，仅对(1-λ)部分进行风险加权；二是利用敏感范围边界上的概率质量差P(R)来调整似然函数，提升尾部值的保护。这些调整被应用于风险加权伪后验机制（PPM），并在渐近微分隐私（aDP）框架下评估。

Result: 所提出的范围受限隐私标准能够在保留数据效用的同时，提供比传统aDP更强的隐私保护，尤其是在敏感范围外的信息已被合理假设为公开的情况下，实现了隐私与效用的更好平衡。

Conclusion: 通过引入数据所有者的信念到形式化隐私标准中，可以有效增强隐私保护并提升数据实用性，展示了将领域知识融入隐私机制设计的潜力。

Abstract: We introduce a new class of range restricted formal data privacy standards that condition on owner beliefs about sensitive data ranges. By incorporating this additional information, we can provide a stronger privacy guarantee (e.g. an amplification). The range restricted formal privacy standards protect only a subset (or ball) of data values and exclude ranges (or balls) believed to be already publicly known. The privacy standards are designed for the risk-weighted pseudo posterior (model) mechanism (PPM) used to generate synthetic data under an asymptotic Differential (aDP) privacy guarantee. The PPM downweights the likelihood contribution for each record proportionally to its disclosure risk. The PPM is adapted under inclusion of beliefs by adjusting the risk-weighted pseudo likelihood. We introduce two alternative adjustments. The first expresses data owner knowledge of the sensitive range as a probability, $λ$, that a datum value drawn from the underlying generating distribution lies outside the ball or subspace of values that are sensitive. The portion of each datum likelihood contribution deemed sensitive is then $(1-λ) \leq 1$ and is the only portion of the likelihood subject to risk down-weighting. The second adjustment encodes knowledge as the difference in probability masses $P(R) \leq 1$ between the edges of the sensitive range, $R$. We use the resulting conditional (pseudo) likelihood for a sensitive record, which boosts its worst case tail values away from 0. We compare privacy and utility properties for the PPM under the aDP and range restricted privacy standards.

</details>


### [103] [Sparse group principal component analysis via double thresholding with application to multi-cellular programs](https://arxiv.org/abs/2602.04178)
*Qi Xu,Jing Lei,Kathryn Roeder*

Main category: stat.ME

TL;DR: 提出了一种新的稀疏组主成分分析方法（SGPCA）用于估计多细胞程序（MCPs），具有高效性、可扩展性和优于现有方法的统计性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MCP估计方法计算成本高且统计功效有限，难以有效识别复杂生物过程中的多细胞协同表达模式。

Method: 提出SGPCA方法，利用MCP内在的组稀疏和个体稀疏特性，并设计基于幂迭代的双阈值算法：先通过组阈值筛选相关基因组，再通过个体阈值选择活跃细胞类型。

Result: 该算法计算复杂度为O(np)，具备线性效率；理论分析表明其具有统计一致性和更快的收敛速率；模拟实验显示其在估计准确性和信号检测功效上优于现有方法；在红斑狼疮研究中成功识别出患者与正常人之间的差异表达MCP。

Conclusion: SGPCA是一种高效、可扩展且统计性能优越的方法，适用于大规模基因组数据中多细胞程序的检测与分析。

Abstract: Multi-cellular programs (MCPs) are coordinated patterns of gene expression across interacting cell types that collectively drive complex biological processes such as tissue development and immune responses. While MCPs are typically estimated from high-dimensional gene expression data using methods like sparse principal component analysis or latent factor models, these approaches often suffer from high computational costs and limited statistical power. In this work, we propose Sparse Group Principal Component Analysis (SGPCA) to estimate MCPs by leveraging their inherent group and individual sparsity. We introduce an efficient double-thresholding algorithm based on power iteration. In each iteration, a group thresholding step first identifies relevant gene groups, followed by an individual thresholding step to select active cell types. This algorithm achieves a linear computational complexity of $O(np)$, making it highly efficient and scalable for large-scale genomic analyses. We establish theoretical guarantees for SGPCA, including statistical consistency and a convergence rate that surpasses competing methods. Through extensive simulations, we demonstrate that SGPCA achieves superior estimation accuracy and improved statistical power for signal detection. Furthermore, We apply SGPCA to a Lupus study, discovering differentially expressed MCPs distinguishing Lupus patients from normal subjects.

</details>


### [104] [Accurate and Efficient Approximation of the Null Distribution of Rao's Spacing Test](https://arxiv.org/abs/2602.04318)
*Yoshiki Kinoshita,Aya Shinozaki,Toshinari Kamakura*

Main category: stat.ME

TL;DR: 本文提出了一种通过递归计算高阶矩并结合Gram-Charlier展开来近似Rao间距检验统计量零分布的新方法，实现了任意样本量下p值的高效直接计算，显著提升了该检验的实用性和适用范围。


<details>
  <summary>Details</summary>
Motivation: Rao间距检验虽广泛用于圆形数据均匀性检验，但其零分布难以计算，导致实际应用中依赖有限样本量的临界值表，限制了方法的灵活性和通用性。

Method: 通过递归计算Rao间距检验统计量的高阶矩，并利用Gram-Charlier展开逼近其零分布，从而实现对任意样本量的p值进行高效直接计算。

Result: 所提方法在广泛样本量范围内均表现出高精度，与已发表的临界值和鞍点近似结果对比显示其准确性优异，且适用于当前表格中未包含的大样本情况。

Conclusion: 该方法克服了传统Rao间距检验依赖临界值表的局限性，显著增强了其在理论研究和实际统计分析中的可用性和实用性。

Abstract: Rao's spacing test is a widely used nonparametric method for assessing uniformity on the circle. However, its broader applicability in practical settings has been limited because the null distribution is not easily calculated. As a result, practitioners have traditionally depended on pre-tabulated critical values computed for a limited set of sample sizes, which restricts the flexibility and generality of the method. In this paper, we address this limitation by recursively computing higher-order moments of the Rao's spacing test statistic and employing the Gram-Charlier expansion to derive an accurate approximation to its null distribution. This approach allows for the efficient and direct computation of p-values for arbitrary sample sizes, thereby eliminating the dependency on existing critical value tables. Moreover, we confirm that our method remains accurate and effective even for large sample sizes that are not represented in current tables, thus overcoming a significant practical limitation. Comparative evaluations with published critical values and saddlepoint approximations demonstrate that our method achieves a high degree of accuracy across a wide range of sample sizes. These findings greatly improve the practicality and usability of Rao's spacing test in both theoretical investigations and applied statistical analyses.

</details>


### [105] [Unit Shiha Distribution and its Applications to Engineering and Medical Data](https://arxiv.org/abs/2602.04400)
*F. A. Shiha*

Main category: stat.ME

TL;DR: 本文提出了一种新的单位区间分布——单位Shiha（USh）分布，通过逆指数变换从原始Shiha分布导出，具有灵活的密度函数和多种风险率形状，适用于左右偏数据建模。


<details>
  <summary>Details</summary>
Motivation: 为了满足对能够准确建模单位区间数据的灵活统计分布日益增长的需求，本文提出了USh分布。

Method: 采用逆指数变换构造USh分布，研究其统计性质，并使用最大似然法进行参数估计，通过模拟研究和四个真实数据集验证其性能。

Result: USh分布能有效建模左偏和右偏数据，风险率函数可呈现递增、浴盆形和J形；模拟和实证分析表明其拟合效果优于其他竞争模型。

Conclusion: USh分布是一种灵活且实用的单位区间分布，在实际应用中表现出优越的拟合能力，是现有单位分布的有力补充。

Abstract: There is a growing need for flexible statistical distributions that can accurately model data defined on the unit interval. This paper introduces a new unit distribution, termed the unit Shiha (USh) distribution, which is derived from the original Shiha (Sh) distribution through an inverse exponential transformation. The probability density function of the USh distribution is sufficiently flexible to model both left- and right-skewed data, while its hazard rate function is capable of capturing various failure-rate patterns, including increasing, bathtub-shaped, and J-shaped forms. Several statistical properties of the proposed distribution are investigated, including moments and related measures, the quantile function, entropy, and stress-strength reliability. Parameter estimation is carried out using the maximum likelihood method, and its performance is evaluated through a simulation study. The practical usefulness of the USh distribution is demonstrated using four real-life data sets, and its performance is compared with several well-known competing unit distributions. The comparative results indicate that the proposed model fits the data better than the competitive models applied in this study.

</details>


### [106] [Exact Multiple Change-Point Detection Via Smallest Valid Partitioning](https://arxiv.org/abs/2602.04322)
*Vincent Runge,Anica Kostic,Alexandre Combeau,Gaetano Romano*

Main category: stat.ME

TL;DR: 提出了一种名为最小有效划分（SVP）的时间序列多变点检测方法，通过局部有效性检验和基于字典序优化的全局聚合策略，实现兼具准确性与片段有效性的分割。


<details>
  <summary>Details</summary>
Motivation: 传统最优划分方法缺乏对每个分割段有效性的显式控制，SVP旨在通过局部有效性检验确保检测到的每个变化点都具有统计意义，并提升模型的可解释性与鲁棒性。

Method: SVP首先生成满足用户指定有效性检验（如单变点检验）的候选段，然后采用基于字典序的优化准则进行聚合，优先选择更简洁的全局分割方案，从而求解一个明确的优化问题。

Result: SVP在计算复杂度上具有弹性，根据成本函数和数据设置可在O(n)到O(n³)之间变化；与标准最优划分算法相比，SVP能产生竞争性的分段结果，同时显式保证段的有效性，并可通过将稳健性编码进有效性标准来实现鲁棒变点检测。

Conclusion: SVP提供了一个灵活且理论严谨的框架，用于多变点检测，能够在不同应用场景中通过自定义有效性测试来保障分割质量，兼顾模型简洁性与统计有效性。

Abstract: We introduce smallest valid partitioning (SVP), a segmentation method for multiple change-point detection in time-series. SVP relies on a local notion of segment validity: a candidate segment is retained only if it passes a user-chosen validity test (e.g., a single change-point test). From the collection of valid segments, we propose a coherent aggregation procedure that constructs a global segmentation which is the exact solution of an optimization problem. Our main contribution is the use of a lexicographic order for the optimization problem that prioritizes parsimony. We analyze the computational complexity of the resulting procedure, which ranges from linear to cubic time depending on the chosen cost and validity functions, the data regime and the number of detected changes. Finally, we assess the quality of SVP through comparisons with standard optimal partitioning algorithms, showing that SVP yields competitive segmentations while explicitly enforcing segment validity. The flexibility of SVP makes it applicable to a broad class of problems; as an illustration, we demonstrate robust change-point detection by encoding robustness in the validity criterion.

</details>


### [107] [Distributed Convoluted Rank Regression for Non-Shareable Data under Non-Additive Losses](https://arxiv.org/abs/2602.04594)
*Wen Zhang,Liping Zhu,Songshan Yang*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study high-dimensional rank regression when data are distributed across multiple machines and the loss is a non-additive U-statistic, as in convoluted rank regression (CRR). Classical communication-efficient surrogate likelihood (CSL) methods crucially rely on the additivity of the empirical loss and therefore break down for CRR, whose global loss couples all sample pairs across machines. We propose a distributed convoluted rank regression (DCRR) framework that constructs a similar surrogate loss and demonstrate its validity under the non-additive losses. We show that this surrogate shares the same population minimizer as the full-data CRR loss and yields estimators that are statistically equivalent to centralized CRR. Building on this, we develop a two-stage sparse DCRR procedure -- an iterative $\ell_1$-penalized stage followed by a folded-concave refinement -- and establish non-asymptotic error bounds, a distributed strong oracle property, and a DHBIC-type criterion for consistent model selection. A scaling result shows that the number of machines may diverge as $M = o({N/(s^2\log p)})$ while achieving centralized oracle rates with only $O(\log N)$ communication rounds. Simulations and a large-scale real data example demonstrate substantial gains over naive divide-and-conquer, particularly under heavy-tailed errors.

</details>


### [108] [Covariate Selection for Joint Latent Space Modeling of Sparse Network Data](https://arxiv.org/abs/2602.04682)
*Emma G Crenshaw,Yuhua Zhang,Jukka-Pekka Onnela*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Network data are increasingly common in the social sciences and infectious disease epidemiology. Analyses often link network structure to node-level covariates, but existing methods falter with sparse networks and high-dimensional node features. We propose a joint latent space modeling framework for sparse networks with high-dimensional binary node covariates that performs covariate selection while accounting for uncertainty in estimated latent positions. Building on joint latent space models that couple edges and node variables through shared latent positions, we introduce a group lasso screening step and incorporate a measurement-error-aware stabilization term to mitigate bias from using estimated latent positions as predictors. We establish prediction error rates for the covariate component both when latent positions are treated as observed and when they are estimated with bounded error; under uniform control across $q$ covariates and $n$ nodes, the rate is of order $O(\log q / n)$ up to an additional term due to latent position estimation error. Our method addresses three challenges: (1) incorporating information from isolated nodes, which are common in sparse networks but often ignored; (2) selecting relevant covariates from high-dimensional spaces; and (3) accounting for uncertainty in estimated latent positions. Simulations show predictive performance remains stable as covariate sparsity grows, while naive approaches degrade. We illustrate how the method can support efficient study design using household social networks from 75 Indian villages, where an emulated pilot study screens a large covariate battery and substantially reduces required subsequent data collection without sacrificing network predictive accuracy.

</details>


### [109] [Linear Regression: Inference Based on Cluster Estimates](https://arxiv.org/abs/2602.04691)
*Subhodeep Dey,Gopal K. Basak,Samarjit Das*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This article proposes a novel estimator for regression coefficients in clustered data that explicitly accounts for within-cluster dependence. We study the asymptotic properties of the proposed estimator under both finite and infinite cluster sizes. The analysis is then extended to a standard random coefficient model, where we derive asymptotic results for the average (common) parameters and develop a Wald-type test for general linear hypotheses. We also investigate the performance of the conventional pooled ordinary least squares (POLS) estimator within the random coefficients framework and show that it can be unreliable across a wide range of empirically relevant settings. Furthermore, we introduce a new test for parameter stability at a higher (superblock; Tier 2, Tier 3,...) level, assuming that parameters are stable across clusters within that level. Extensive simulation studies demonstrate the effectiveness of the proposed tests, and an empirical application illustrates their practical relevance.

</details>


### [110] [Species Sensitivity Distribution revisited: a Bayesian nonparametric approach](https://arxiv.org/abs/2602.04788)
*Louise Alamichel,Julyan Arbel,Guillaume Kon Kam King,Igor Prünster*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a novel approach to ecological risk assessment by recasting the Species Sensitivity Distribution (SSD) method within a Bayesian nonparametric (BNP) framework. Widely mandated by environmental regulatory bodies globally, SSD has faced criticism due to its historical reliance on parametric assumptions when modeling species variability. By adopting nonparametric mixture models, we address this limitation, establishing a statistically robust foundation for SSD. Our BNP approach offers several advantages, including its efficacy in handling small datasets or censored data, which are common in ecological risk assessment, and its ability to provide principled uncertainty quantification alongside simultaneous density estimation and clustering. We utilize a specific nonparametric prior as the mixing measure, chosen for its robust clustering properties, a crucial consideration given the lack of strong prior beliefs about the number of components. Through simulation studies and analysis of real datasets, we demonstrate the superiority of our BNP-SSD over classical SSD methods. We also provide a BNP-SSD Shiny application, making our methodology available to the Ecotoxicology community. Moreover, we exploit the inherent clustering structure of the mixture model to explore patterns in species sensitivity. Our findings underscore the effectiveness of the proposed approach in improving ecological risk assessment methodologies.

</details>


### [111] [Score-Based Change-Point Detection and Region Localization for Spatio-Temporal Point Processes](https://arxiv.org/abs/2602.04798)
*Wenbin Zhou,Liyan Xie,Shixiang Zhu*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study sequential change-point detection for spatio-temporal point processes, where actionable detection requires not only identifying when a distributional change occurs but also localizing where it manifests in space. While classical quickest change detection methods provide strong guarantees on detection delay and false-alarm rates, existing approaches for point-process data predominantly focus on temporal changes and do not explicitly infer affected spatial regions. We propose a likelihood-free, score-based detection framework that jointly estimates the change time and the change region in continuous space-time without assuming parametric knowledge of the pre- or post-change dynamics. The method leverages a localized and conditionally weighted Hyvärinen score to quantify event-level deviations from nominal behavior and aggregates these scores using a spatio-temporal CUSUM-type statistic over a prescribed class of spatial regions. Operating sequentially, the procedure outputs both a stopping time and an estimated change region, enabling real-time detection with spatial interpretability. We establish theoretical guarantees on false-alarm control, detection delay, and spatial localization accuracy, and demonstrate the effectiveness of the proposed approach through simulations and real-world spatio-temporal event data.

</details>


### [112] [Marginal Likelihood Inference for Fitting Dynamical Survival Analysis Models to Epidemic Count Data](https://arxiv.org/abs/2602.04855)
*Suchismita Roy,Alexander A. Fisher,Jason Xu*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Stochastic compartmental models are prevalent tools for describing disease spread, but inference under these models is challenging for many types of surveillance data when the marginal likelihood function becomes intractable due to missing information. To address this, we develop a closed-form likelihood for discretely observed incidence count data under the dynamical survival analysis (DSA) paradigm. The method approximates the stochastic population-level hazard by a large population limit while retaining a count-valued stochastic model, and leads to survival analytic inferential strategies that are both computationally efficient and flexible to model generalizations. Through simulation, we show that parameter estimation is competitive with recent exact but computationally expensive likelihood-based methods in partially observed settings. Previous work has shown that the DSA approximation is generalizable, and we show that the inferential developments here also carry over to models featuring individual heterogeneity, such as frailty models. We consider case studies of both Ebola and COVID-19 data on variants of the model, including a network-based epidemic model and a model with distributions over susceptibility, demonstrating its flexibility and practical utility on real, partially observed datasets.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [113] [OSCAgent: Accelerating the Discovery of Organic Solar Cells with LLM Agents](https://arxiv.org/abs/2602.04510)
*Zhaolin Hu,Zhiliang Wu,Hehe Fan,Yi Yang*

Main category: cs.CE

TL;DR: 本文提出了一种名为OSCAgent的多智能体框架，用于有机太阳能电池（OSC）分子的高效发现，结合检索增强设计、分子生成和系统评估，实现了无需人工干预的持续优化流程。


<details>
  <summary>Details</summary>
Motivation: 现有分子生成方法大多局限于优化已知骨架，且未能有效利用领域化学知识，导致生成的分子不切实际，因此需要一种更高效、更符合化学常识的分子设计方法。

Method: OSCAgent包含三个协作智能体：Planner从文献和先前候选中检索知识以指导设计方向；Generator根据计划生成新的OSC受体分子；Experimenter对候选分子进行综合评估并提供反馈用于迭代优化。

Result: 实验表明，OSCAgent生成的分子化学有效且可合成，并在预测性能上优于传统方法和仅使用大语言模型的基线方法，部分候选分子的预测效率接近18%。

Conclusion: OSCAgent为OSC材料的发现提供了一个高效、自动化且知识驱动的解决方案，具有较高的应用潜力和推广价值。

Abstract: Organic solar cells (OSCs) hold great promise for sustainable energy, but discovering high-performance materials is time-consuming and costly. Existing molecular generation methods can aid the design of OSC molecules, but they are mostly confined to optimizing known backbones and lack effective use of domain-specific chemical knowledge, often leading to unrealistic candidates. In this paper, we introduce OSCAgent, a multi-agent framework for OSC molecular discovery that unifies retrieval-augmented design, molecular generation, and systematic evaluation into a continuously improving pipeline, without requiring additional human intervention. OSCAgent comprises three collaborative agents. The Planner retrieves knowledge from literature-curated molecules and prior candidates to guide design directions. The Generator proposes new OSC acceptors aligned with these plans. The Experimenter performs comprehensive evaluation of candidate molecules and provides feedback for refinement. Experiments show that OSCAgent produces chemically valid, synthetically accessible OSC molecules and achieves superior predicted performance compared to both traditional and large language model (LLM)-only baselines. Representative results demonstrate that some candidates achieve predicted efficiencies approaching 18\%. The code will be publicly available.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [114] [Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem](https://arxiv.org/abs/2602.03969)
*Shama Magnur,Mayank Kejriwal*

Main category: cs.SI

TL;DR: 该研究利用2021至2025年arXiv上的AI领域预印本数据，分析大语言模型（如ChatGPT）兴起后人工智能科研格局的变化，发现学术机构仍是主要研究力量，但学术界与产业界的合作仍低于预期水平。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型的兴起如何影响人工智能领域的科研结构，特别是出版数量、团队规模和学术-产业合作模式的变化。

Method: 通过多阶段的数据收集与增强流程，结合基于大语言模型的机构分类方法，对arXiv cs.AI类别的预印本进行分析，使用标准化合作指数（NCI）评估学术-产业合作水平。

Result: ChatGPT发布后论文产出量激增，学术机构贡献最大；但在所有主要子领域中，学术-产业合作的NCI持续低于随机混合基线，表明合作受限。

Conclusion: 生成式AI研究的高资本需求可能正在加剧学术界与产业界之间的割裂，重塑科研合作边界。

Abstract: The emergence of large language models (LLMs) represents a significant technological shift within the scientific ecosystem, particularly within the field of artificial intelligence (AI). This paper examines structural changes in the AI research landscape using a dataset of arXiv preprints (cs.AI) from 2021 through 2025. Given the rapid pace of AI development, the preprint ecosystem has become a critical barometer for real-time scientific shifts, often preceding formal peer-reviewed publication by months or years. By employing a multi-stage data collection and enrichment pipeline in conjunction with LLM-based institution classification, we analyze the evolution of publication volumes, author team sizes, and academic--industry collaboration patterns. Our results reveal an unprecedented surge in publication output following the introduction of ChatGPT, with academic institutions continuing to provide the largest volume of research. However, we observe that academic--industry collaboration is still suppressed, as measured by a Normalized Collaboration Index (NCI) that remains significantly below the random-mixing baseline across all major subfields. These findings highlight a continuing institutional divide and suggest that the capital-intensive nature of generative AI research may be reshaping the boundaries of scientific collaboration.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [115] [A Comparative Study of Digital Memristor-Based Processing-In-Memory from a Device and Reliability Perspective](https://arxiv.org/abs/2602.04035)
*Thomas Neuner,Henriette Padberg,Lior Kornblum,Eilam Yalon,Pedram Khalili Amiri,Shahar Kvatinsky*

Main category: cs.ET

TL;DR: 本文综述了基于阻变存储器（RRAM）、相变存储器（PCM）和磁阻存储器（MRAM）等新兴非易失性存储技术的存内计算（PIM）中的状态型与非状态型逻辑技术的最新进展，分析了其实验与仿真逻辑设计，探讨了可靠性挑战及器件级优化对实现可扩展、商业化PIM系统的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着数据密集型应用对传统计算系统的压力日益增大，内存墙问题愈发突出。为减少内存与处理单元之间的数据传输，存内计算（PIM）成为一种有前景的解决方案。本文旨在系统梳理基于新兴非易失性存储器的PIM逻辑技术进展，明确当前面临的挑战与优化方向。

Method: 本文采用文献综述方法，首先介绍相关的逻辑家族、忆阻器件类型及其可靠性指标；随后按逻辑家族分类，分析各类技术如何利用器件特性实现逻辑运算；并通过对比代表性器件堆叠结构与性能参数的表格，揭示其性能权衡与质量指标。

Result: 总结了基于RRAM、PCM和MRAM的状态型与非状态型PIM逻辑技术在实验与仿真中的实现情况，明确了器件可靠性（如耐久性、稳定性）是主要挑战，并指出通过器件级优化可提升PIM系统的可扩展性与商业可行性。

Conclusion: 器件层面的优化对于推动高性能、高可靠性的存内计算系统至关重要，未来需进一步开发鲁棒、可扩展的忆阻器件，以支持下一代PIM应用的发展。

Abstract: As data-intensive applications increasingly strain conventional computing systems, processing-in-memory (PIM) has emerged as a promising paradigm to alleviate the memory wall by minimizing data transfer between memory and processing units. This review presents the recent advances in both stateful and non-stateful logic techniques for PIM, focusing on emerging nonvolatile memory technologies such as resistive random-access memory (RRAM), phase-change memory (PCM), and magnetoresistive random-access memory (MRAM). Both experimentally demonstrated and simulated logic designs are critically examined, highlighting key challenges in reliability and the role of device-level optimization in enabling scalable and commercial viable PIM systems. The review begins with an overview of relevant logic families, memristive device types, and associated reliability metrics. Each logic family is then explored in terms of how it capitalizes on distinct device properties to implement logic techniques. A comparative table of representative device stacks and performance parameters illustrates trade-offs and quality indicators. Through this comprehensive analysis, the development of optimized, robust memristive devices for next-generation PIM applications is supported.

</details>


### [116] [The Dynamics of Attention across Automated and Manual Driving Modes: A Driving Simulation Study](https://arxiv.org/abs/2602.04164)
*Yuan Cai,Mustafa Demir,Farzan Sasangohar,Mohsen Zare*

Main category: cs.ET

TL;DR: 本研究通过高保真驾驶模拟和眼动追踪技术，探讨了不同驾驶模式下驾驶员对道路、后视镜、人机界面（HMI）和速度表等区域的注意力分配动态。结果显示，驾驶模式显著影响注意力分布：手动模式下注意力集中在道路，自动模式下更多关注HMI，而在切换阶段则在环境与技术元素间动态转移。研究结果可指导自适应HMI设计，提升自动驾驶中的安全性和人车交互。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆（AVs）的普及，驾驶员在模式切换时的重新参与成为关键安全问题。以往事故表明，过度依赖自动化可能导致风险，因此需深入理解驾驶员在不同驾驶模式下的注意力动态分配机制，以支持更安全的人机协同。

Method: 采用高保真驾驶模拟实验，结合眼动追踪技术，测量驾驶员在自动化、手动及过渡三种驾驶模式下对多个兴趣区（AOI）的注视持续时间、注视次数和首次注视时间，并使用广义线性混合模型（GLMM）进行分析。

Result: 驾驶员注意力分配在不同驾驶模式下存在显著差异：手动驾驶时主要关注道路；自动驾驶时对嵌入式HMI的注视时间延长；在接管和移交过程中，注意力在环境与车载技术之间动态切换。GLMM分析证实了驾驶模式对视觉注意力的显著影响。

Conclusion: 驾驶员的视觉注意力分配具有模式依赖性，研究结果为开发适应不同驾驶情境的自适应人机界面（HMI）提供了实证依据，有助于优化信息呈现时机、提升驾驶员准备状态和整体行车安全。

Abstract: This study aims to explore the dynamics of driver attention to various zones, including the road, the central mirror, the embedded Human-Machine Interface (HMI), and the speedometer, across different driving modes in AVs. The integration of autonomous vehicles (AVs) into transportation systems has introduced critical safety concerns, particularly regarding driver re-engagement during mode transitions. Past accidents underscore the risks of overreliance on automation and highlight the need to understand dynamic attention allocation to support safety in autonomous driving. A high-fidelity driving simulation was conducted. Eye-tracking technology was used to measure fixation duration, fixation count, and time to first fixation across distinct driving modes (automated, manual, and transition), which were then used to assess how drivers allocated attention to various areas of interest (AOIs). Findings show that drivers' attention varies significantly across driving modes. In manual mode, attention consistently focuses on the road, while in automated mode, prolonged fixation on the embedded HMI was observed. During the handover and takeover phases, attention shifts dynamically between environmental and technological elements. The study reveals that driver attention allocation is mode-dependent. These findings inform the design of adaptive HMIs in AVs that align with drivers' attention patterns. By presenting relevant information according to the driving context, such systems can enhance driver-vehicle interaction, support effective transitions, and improve overall safety. Systematic analysis of visual attention dynamics across driving modes is gaining prominence, as it informs adaptive HMI designs and driver readiness interventions. The GLMM findings can be directly applied to the design of adaptive HMIs or driver training programs to enhance attention and improve safety.

</details>


### [117] [Self-evolving Embodied AI](https://arxiv.org/abs/2602.04411)
*Tongtong Feng,Xin Wang,Wenwu Zhu*

Main category: cs.ET

TL;DR: 本文提出了自演化具身人工智能的新范式，旨在通过记忆自更新、任务自切换、环境自预测、具身自适应和模型自进化，实现持续适应性智能。


<details>
  <summary>Details</summary>
Motivation: 现有具身AI局限于人工设定的静态环境与固定任务，难以应对真实世界中动态开放环境与多变具身形态的挑战，因此需要提出更具自主性和适应性的新范式。

Method: 提出自演化具身AI的定义、框架、组成组件与运行机制，并系统综述各组件的前沿研究进展。

Result: 构建了支持自主演化的具身AI框架，涵盖记忆、任务、环境、具身和模型五个方面的自演化能力，并梳理了相关技术现状与应用实例。

Conclusion: 自演化具身AI能够使智能体以类人方式自主学习与交互，为通向通用人工智能提供了新方向。

Abstract: Embodied Artificial Intelligence (AI) is an intelligent system formed by agents and their environment through active perception, embodied cognition, and action interaction. Existing embodied AI remains confined to human-crafted setting, in which agents are trained on given memory and construct models for given tasks, enabling fixed embodiments to interact with relatively static environments. Such methods fail in in-the-wild setting characterized by variable embodiments and dynamic open environments. This paper introduces self-evolving embodied AI, a new paradigm in which agents operate based on their changing state and environment with memory self-updating, task self-switching, environment self-prediction, embodiment self-adaptation, and model self-evolution, aiming to achieve continually adaptive intelligence with autonomous evolution. Specifically, we present the definition, framework, components, and mechanisms of self-evolving embodied AI, systematically review state-of-the-art works for realized components, discuss practical applications, and point out future research directions. We believe that self-evolving embodied AI enables agents to autonomously learn and interact with environments in a human-like manner and provide a new perspective toward general artificial intelligence.

</details>
