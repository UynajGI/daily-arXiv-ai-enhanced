{"id": "2601.15310", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2601.15310", "abs": "https://arxiv.org/abs/2601.15310", "authors": ["Michele Caraglio"], "title": "Two-Dimensional Active Brownian Particles Crossing a Parabolic Barrier: Transition-Path Times, Survival Probability, and First-Passage Time", "comment": "12 pages, 7 gigures. arXiv admin note: substantial text overlap with arXiv:2410.07226", "summary": "We derive an analytical expression for the propagator and the transition path time distribution of a two-dimensional active Brownian particle crossing a parabolic barrier with absorbing boundary conditions at both sides. By taking those of a passive Brownian particle as basis states and dealing with the activity as a perturbation, our solution is expressed in terms of the perturbed eigenfunctions and eigenvalues of the associated Fokker-Planck equation once the latter is reduced by taking into account only the coordinate along the direction of the barrier and the self-propulsion angle. We show that transition path times are typically shortened by the self-propulsion of the particle. Our solution also allows us to obtain the survival probability and the first-passage times distribution, which display a strong dependence on the particle's activity, while the rotational diffusivity influences them to a minor extent."}
{"id": "2601.15782", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15782", "abs": "https://arxiv.org/abs/2601.15782", "authors": ["V. I. Yukalov", "E. P. Yukalova"], "title": "Mesoscopic Fluctuations in Statistical Systems", "comment": "Review, latex file, 63 pages, 2 figures", "summary": "The fluctuations are termed mesoscopic, when their typical size is essentially larger then the average distance between the nearest neighbors, while being much smaller than the overall system size. Since the features of mesoscopic fluctuations are essentially different from those of the surrounding matter, they can be interpreted as fluctuations of one phase occurring inside another host phase. In condensed matter, these fluctuations are of nanosize. They can occur in many-body systems of different nature, for instance, they are typical for condensed matter, can appear in systems of trapped atoms, and also arise in biological and social systems. A survey of the experimental evidence for the occurrence of mesoscopic fluctuations in different materials and systems is given. The main attention is paid to a general theoretical approach for describing them. Applications of the approach are also discussed."}
{"id": "2601.16029", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16029", "abs": "https://arxiv.org/abs/2601.16029", "authors": ["Éric Brunet", "Bernard Derrida"], "title": "The flux of particles in a one-dimensional Fleming-Viot process", "comment": null, "summary": "The Fleming-Viot process describes a system of $N$ particles diffusing on a graph with an absorbing site. Whenever one of the particles is absorbed, it is replaced by a new particle at the position of one of the $N-1$ remaining particles. Here we consider the case where the particles lie on the semi-infinite line with a biased diffusion towards the origin which is the absorbing site. In the large $N$ limit, the evolution of the density becomes deterministic and has a number of characteristics similar to the Fisher-KPP equation: a one-parameter family of steady state solutions, dependence of the long time asymptotics on the initial conditions, Bramson logarithmic shift, etc. One noticeable difference, however, is that in the Fleming-Viot case, the solution can be computed explicitly for arbitrary initial conditions and at an arbitrary time. By modifying the diffusion rule near the origin, one can produce a transition in the flux of absorbed particles, very similar to the pushed-pulled transition in travelling waves. Lastly, using a cut-off approximation (which is known to be correct in the theory of travelling waves), we derive a number of predictions for the leading large $N$ correction of the flux of absorbed particles."}
{"id": "2601.16086", "categories": ["cond-mat.stat-mech", "nlin.AO", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.16086", "abs": "https://arxiv.org/abs/2601.16086", "authors": ["Diego Febbe", "Duccio Fanelli", "Timoteo Carletti"], "title": "Random Walks Across Dimensions: Exploring Simplicial Complexes", "comment": null, "summary": "We introduce a novel operator to describe a random walk process on a simplicial complex. Walkers are allowed to wonder across simplices of various dimensions, bridging nodes to edges, and edges to triangles, via a nested organization that hierarchically extends to higher structures of arbitrary large, but finite, dimension. The asymptotic distribution of the walkers provides a natural ranking to gauge the relative importance of higher order simplices. Optimal search strategies in presence of stochastic teleportation are addressed and the peculiar interplay of noise with higher order structures unraveled."}
{"id": "2601.15325", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.15325", "abs": "https://arxiv.org/abs/2601.15325", "authors": ["Chaojun Li", "Hao Fang"], "title": "MLP-Enhanced Nonnegative Tensor RESCAL Decomposition for Dynamic Community Detection", "comment": "8 pages,4 figures,63 conferences", "summary": "Dynamic community detection plays a crucial role in understanding the temporal evolution of community structures in complex networks. Existing methods based on nonnegative tensor RESCAL decomposition typically require the decomposition rank to equal the number of communities, which limits model flexibility. This paper proposes an improved MLP-enhanced nonnegative tensor decomposition model (MLP-NTD) that incorporates a multilayer perceptron (MLP) after RESCAL decomposition for community mapping, thereby decoupling the decomposition rank from the number of communities. The framework optimizes model parameters through a reconstruction loss function, which preserves the ability to capture dynamic community evolution while significantly improving the accuracy and robustness of community partitioning. Experimental results on multiple real-world dynamic network datasets demonstrate that MLP-NTD outperforms state-of-the-art methods in terms of modularity, validating the effectiveness of the proposed approach."}
{"id": "2601.15377", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15377", "abs": "https://arxiv.org/abs/2601.15377", "authors": ["Laura Shou", "Jeet Shah", "Matthew Lerner-Brecher", "Amol Aggarwal", "Alexei Borodin", "Victor Galitski"], "title": "Exactly solvable topological phase transition in a quantum dimer model", "comment": "5+6 pages, 8+4 figures", "summary": "We introduce a family of generalized Rokhsar-Kivelson (RK) Hamiltonians, which are reverse-engineered to have an arbitrary edge-weighted superposition of dimer coverings as their exact ground state at the RK point. We then focus on a quantum dimer model on the triangular lattice, with doubly-periodic edge weights. For simplicity we consider a $2\\times1$ periodic model in which all weights are set to one except for a tunable horizontal edge weight labeled $α$. We analytically show that the model exhibits a continuous quantum phase transition at $α=3$, changing from a topological $\\mathbb{Z}_2$ quantum spin liquid ($α<3$) to a columnar ordered state ($α>3$). The dimer-dimer correlator decays exponentially on both sides of the transition with the correlation length $ξ\\propto1/|α-3|$ and as a power-law at criticality. The vison correlator exhibits an exponential decay in the spin liquid phase, but becomes a constant in the ordered phase. We explain the constant vison correlator in terms of loops statistics of the double-dimer model. Using finite-size scaling of the vison correlator, we extract critical exponents consistent with the 2D Ising universality class."}
{"id": "2601.15720", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2601.15720", "abs": "https://arxiv.org/abs/2601.15720", "authors": ["Shinji Ejiri", "Masanari Koiida", "Toshiki Sato"], "title": "Phase structure of lattice QCD in the heavy quark high-density region and the three-state Potts model", "comment": "10 pages, 10 figures, contribution to the 42nd International Symposium on Lattice Field Theory (Lattice 2025), 2-8 November 2025, TIFR Mumbai, India", "summary": "We discuss the nature of the QCD phase transition in the heavy quark high-density region by considering an effective theory in which Polyakov loops are dynamical variables. The Polyakov loop is an order parameter of $Z_3$ symmetry, and the fundamental properties of the phase transition are thought to be determined by the $Z_3$ symmetry broken by the phase transition. By replacing the Polyakov loop with $Z_3$ spin, we find that the effective model becomes a three-dimensional three-state Potts model ($Z_3$ spin model) with a complex external field term. We investigate the phase structure of the Potts model and discuss QCD in the heavy quark region. The critical points are determined by finite volume scaling analysis, and in the region where the sign problem is severe, the tensor renormalization group is used to investigate. As the density varies from $μ=0$ to $μ=\\infty$, we find that the phase transition is first order in the low-density region, changes to a crossover at the critical point, and then becomes first order again. This strongly suggests the existence of a first order phase transition in the high-density heavy quark region of QCD."}
{"id": "2601.15354", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15354", "abs": "https://arxiv.org/abs/2601.15354", "authors": ["Peng Chen", "Jun Jing"], "title": "Precision limit under weak-coupling with ancillary qubit", "comment": "12 pages, 6 figures", "summary": "We propose a measurement-based quantum metrology protocol in a composite model, where the probe system (a spin ensemble) is coupled to an ancillary two-level system (qubit) with a general Heisenberg XXZ interaction. With an optimized and weak probe-ancilla coupling strength and a proper duration of joint evolution, the two parallel evolution paths of the probe system induced by the unconditional measurement on qubit can transform an eigenstate of the collective angular momentum operator of spin ensemble to be a two-component state with a large distance in eigenspace. The quantum Fisher information about the phase encoded in the probe system of polarized states or their superposition, that could be relaxed to mixed states, can therefore manifest an exact or asymptotic quadratic scaling with respect to the probe size (spin number) $N$. The quadratic scaling behavior is found to be insensitive to the imperfect encoding operator and coupling strength. By virtue of the parity detection on the ancillary qubit or the probe system, the phase sensitivity can approach the Heisenberg limit. We suggest that the unconditional measurement on qubit could become an efficient resource to replace Greenberger-Horne-Zeilinger-like states and squeezing Hamiltonian for exceeding the standard quantum limit in metrology precision."}
{"id": "2601.15427", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.15427", "abs": "https://arxiv.org/abs/2601.15427", "authors": ["Alex Alberts", "Akshay Jacob Thomas", "Kamran Daryabeigi", "Ilias Bilionis"], "title": "Bayesian identification of fibrous insulation thermal conductivity towards design of spacecraft thermal protection systems", "comment": null, "summary": "The design of spacecraft thermal protection systems (TPS) requires accurate knowledge of thermal transport properties across wide ranges of temperature and pressure. For fibrous insulation, conventional measurement techniques in laboratory settings are typically limited to temperatures much lower than what is reached in atmosphere entry scenarios. Moreover, it is often the case that only temperature measurements are available, meaning that the thermal conductivity of the insulation must be indirectly inferred as an inverse problem. We propose a Bayesian framework using information field theory (IFT) to reconstruct the thermal conductivity of high-temperature fibrous insulation from sparse experimental data. Under IFT, the conductivity is represented as a Gaussian process, and the physics is enforced via a physics-informed prior over the temperature derived from the heat equation. Bayes's rule produces an infinite-dimensional posterior distribution that quantifies uncertainty about the conductivity which can be evaluated in extrapolation regimes. We apply the method to Opacified Fibrous Insulation with both synthetic and experimental data to reconstruct the thermal conductivity beyond the experimental regime. The inferred conductivities are validated against reference data and then propagated into high-fidelity digital twins of flexible TPS performance under Mars and Earth entry trajectories. The results show that IFT yields accurate predictions with quantified uncertainty, enabling robust TPS sizing in regimes inaccessible to direct measurement."}
{"id": "2601.15496", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15496", "abs": "https://arxiv.org/abs/2601.15496", "authors": ["Ali Nikkhah", "Anthony Ephremides", "Nikolaos Pappas"], "title": "Semantics in Actuation Systems: From Age of Actuation to Age of Actuated Information", "comment": "Submitted for possible Journal publication", "summary": "In this paper, we study the timeliness of actions in communication systems where actuation is constrained by control permissions or energy availability. Building on the Age of Actuation (AoA) metric, which quantifies the timeliness of actions independently of data freshness, we introduce a new metric, the \\emph{Age of Actuated Information (AoAI)}. AoAI captures the end-to-end timeliness of actions by explicitly accounting for the age of the data packet at the moment it is actuated. We analyze and characterize both AoA and AoAI in discrete-time systems with data storage capabilities under multiple actuation scenarios. The actuator requires both a data packet and an actuation opportunity, which may be provided by a controller or enabled by harvested energy. Data packets may be stored either in a single-packet buffer or an infinite-capacity queue for future actuation. For these settings, we derive closed-form expressions for the average AoA and AoAI and investigate their structural differences. While AoA and AoAI coincide in instantaneous actuation systems, they differentiate when data buffering is present. Our results reveal counterintuitive regimes in which increasing update or actuation rates degrade action timeliness for both AoA and AoAI. Moreover, as part of the analysis, we obtain a novel closed-form characterization of the steady-state distribution of a Geo/Geo/1 queue operating under the FCFS discipline, expressed solely in terms of the queue length and the age of the head-of-line packet. The proposed metrics and analytical results provide new insights into the semantics of timeliness in systems where information ultimately serves the purpose of actuation."}
{"id": "2601.15449", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.15449", "abs": "https://arxiv.org/abs/2601.15449", "authors": ["Diptanil Santra", "Guanhua Chen", "Chan Park"], "title": "Distributional Balancing for Causal Inference: A Unified Framework via Characteristic Function Distance", "comment": "35 pages", "summary": "Weighting methods are essential tools for estimating causal effects in observational studies, with the goal of balancing pre-treatment covariates across treatment groups. Traditional approaches pursue this objective indirectly, for example, via inverse propensity score weighting or by matching a finite number of covariate moments, and therefore do not guarantee balance of the full joint covariate distributions. Recently, distributional balancing methods have emerged as robust, nonparametric alternatives that directly target alignment of entire covariate distributions, but they lack a unified framework, formal theoretical guarantees, and valid inferential procedures. We introduce a unified framework for nonparametric distributional balancing based on the characteristic function distance (CFD) and show that widely used discrepancy measures, including the maximum mean discrepancy and energy distance, arise as special cases. Our theoretical analysis establishes conditions under which the resulting CFD-based weighting estimator achieves $\\sqrt{n}$-consistency. Since the standard bootstrap may fail for this estimator, we propose subsampling as a valid alternative for inference. We further extend our approach to an instrumental variable setting to address potential unmeasured confounding. Finally, we evaluate the performance of our method through simulation studies and a real-world application, where the proposed estimator performs well and exhibits results consistent with our theoretical predictions."}
{"id": "2601.15340", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall", "cs.LG", "nlin.AO", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2601.15340", "abs": "https://arxiv.org/abs/2601.15340", "authors": ["Fabiana Taglietti", "Andrea Pulici", "Maxwell Roxburgh", "Gabriele Seguini", "Ian Vidamour", "Stephan Menzel", "Edoardo Franco", "Michele Laus", "Eleni Vasilaki", "Michele Perego", "Thomas J. Hayward", "Marco Fanciulli", "Jack C. Gartside"], "title": "Learning Nonlinear Heterogeneity in Physical Kolmogorov-Arnold Networks", "comment": null, "summary": "Physical neural networks typically train linear synaptic weights while treating device nonlinearities as fixed. We show the opposite - by training the synaptic nonlinearity itself, as in Kolmogorov-Arnold Network (KAN) architectures, we yield markedly higher task performance per physical resource and improved performance-parameter scaling than conventional linear weight-based networks, demonstrating ability of KAN topologies to exploit reconfigurable nonlinear physical dynamics.\n  We experimentally realise physical KANs in silicon-on-insulator devices we term 'Synaptic Nonlinear Elements' (SYNEs), operating at room temperature, 0.1-1 microampere currents, and 2 MHz speeds with no observed degradation over 10^13 measurements and months-long timescales.\n  We demonstrate nonlinear function regression, classification, and prediction of Li-Ion battery dynamics from noisy real-world multi-sensor data. Physical KANs outperform equivalently-parameterised software multilayer perceptron networks across all tasks, with up to two orders of magnitude fewer parameters, and two orders of magnitude fewer devices than linear weight based physical networks. These results establish learned physical nonlinearity as a hardware-native computational primitive for compact and efficient learning systems, and SYNE devices as effective substrates for heterogenous nonlinear computing."}
{"id": "2601.15660", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.15660", "abs": "https://arxiv.org/abs/2601.15660", "authors": ["Akshay Sunil", "B. Deepthi", "Muhammed Rashid"], "title": "Toward Trustworthy Short-Range Forecasts with AFNO: From Skill Metrics to Conservation Checks", "comment": null, "summary": "Data driven weather models now approach traditional numerical weather prediction (NWP) skill at short to medium lead times, but their dynamical consistency during autoregressive rollout remains uncertain."}
{"id": "2601.15340", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall", "cs.LG", "nlin.AO", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2601.15340", "abs": "https://arxiv.org/abs/2601.15340", "authors": ["Fabiana Taglietti", "Andrea Pulici", "Maxwell Roxburgh", "Gabriele Seguini", "Ian Vidamour", "Stephan Menzel", "Edoardo Franco", "Michele Laus", "Eleni Vasilaki", "Michele Perego", "Thomas J. Hayward", "Marco Fanciulli", "Jack C. Gartside"], "title": "Learning Nonlinear Heterogeneity in Physical Kolmogorov-Arnold Networks", "comment": null, "summary": "Physical neural networks typically train linear synaptic weights while treating device nonlinearities as fixed. We show the opposite - by training the synaptic nonlinearity itself, as in Kolmogorov-Arnold Network (KAN) architectures, we yield markedly higher task performance per physical resource and improved performance-parameter scaling than conventional linear weight-based networks, demonstrating ability of KAN topologies to exploit reconfigurable nonlinear physical dynamics.\n  We experimentally realise physical KANs in silicon-on-insulator devices we term 'Synaptic Nonlinear Elements' (SYNEs), operating at room temperature, 0.1-1 microampere currents, and 2 MHz speeds with no observed degradation over 10^13 measurements and months-long timescales.\n  We demonstrate nonlinear function regression, classification, and prediction of Li-Ion battery dynamics from noisy real-world multi-sensor data. Physical KANs outperform equivalently-parameterised software multilayer perceptron networks across all tasks, with up to two orders of magnitude fewer parameters, and two orders of magnitude fewer devices than linear weight based physical networks. These results establish learned physical nonlinearity as a hardware-native computational primitive for compact and efficient learning systems, and SYNE devices as effective substrates for heterogenous nonlinear computing."}
{"id": "2601.15561", "categories": ["cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15561", "abs": "https://arxiv.org/abs/2601.15561", "authors": ["Naoya Onizawa", "Takahiro Hanyu"], "title": "Enhanced Convergence in p-bit Based Simulated Annealing with Partial Deactivation for Large-Scale Combinatorial Optimization Problems", "comment": "17 pages", "summary": "This article critically investigates the limitations of the simulated annealing algorithm using probabilistic bits (pSA) in solving large-scale combinatorial optimization problems. The study begins with an in-depth analysis of the pSA process, focusing on the issues resulting from unexpected oscillations among p-bits. These oscillations hinder the energy reduction of the Ising model and thus obstruct the successful execution of pSA in complex tasks. Through detailed simulations, we unravel the root cause of this energy stagnation, identifying the feedback mechanism inherent to the pSA operation as the primary contributor to these disruptive oscillations. To address this challenge, we propose two novel algorithms, time average pSA (TApSA) and stalled pSA (SpSA). These algorithms are designed based on partial deactivation of p-bits and are thoroughly tested using Python simulations on maximum cut benchmarks that are typical combinatorial optimization problems. On the 16 benchmarks from 800 to 5,000 nodes, the proposed methods improve the normalized cut value from 0.8% to 98.4% on average in comparison with the conventional pSA."}
{"id": "2601.15536", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th", "nlin.CD", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2601.15536", "abs": "https://arxiv.org/abs/2601.15536", "authors": ["Amit Vikram", "Edwin Chaparro", "Muhammad Miskeen Khan", "Andrew Lucas", "Chris Akers", "Ana Maria Rey"], "title": "Bidirectional teleportation using scrambling dynamics: a practical protocol", "comment": "9+26 pages, 4+7 figures", "summary": "We show that quantum information scrambling can enable a generic SWAP gate between collective degrees of freedom in systems without universal local control. Our protocol combines the Hayden-Preskill recovery scheme, associated with the black hole information paradox, with quantum teleportation and runs them in parallel and in opposite directions, enabling bidirectional exchange of quantum states through global interactions alone. This approach cleanly distinguishes the roles of information spreading, entanglement, and chaos for enabling both coherent state transfer and recovery. We propose an experimental realization using the Dicke model, which can be realized in cavity-QED and trapped-ion platforms, highlighting the utility of holography in designing practical quantum gates."}
{"id": "2601.15496", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15496", "abs": "https://arxiv.org/abs/2601.15496", "authors": ["Ali Nikkhah", "Anthony Ephremides", "Nikolaos Pappas"], "title": "Semantics in Actuation Systems: From Age of Actuation to Age of Actuated Information", "comment": "Submitted for possible Journal publication", "summary": "In this paper, we study the timeliness of actions in communication systems where actuation is constrained by control permissions or energy availability. Building on the Age of Actuation (AoA) metric, which quantifies the timeliness of actions independently of data freshness, we introduce a new metric, the \\emph{Age of Actuated Information (AoAI)}. AoAI captures the end-to-end timeliness of actions by explicitly accounting for the age of the data packet at the moment it is actuated. We analyze and characterize both AoA and AoAI in discrete-time systems with data storage capabilities under multiple actuation scenarios. The actuator requires both a data packet and an actuation opportunity, which may be provided by a controller or enabled by harvested energy. Data packets may be stored either in a single-packet buffer or an infinite-capacity queue for future actuation. For these settings, we derive closed-form expressions for the average AoA and AoAI and investigate their structural differences. While AoA and AoAI coincide in instantaneous actuation systems, they differentiate when data buffering is present. Our results reveal counterintuitive regimes in which increasing update or actuation rates degrade action timeliness for both AoA and AoAI. Moreover, as part of the analysis, we obtain a novel closed-form characterization of the steady-state distribution of a Geo/Geo/1 queue operating under the FCFS discipline, expressed solely in terms of the queue length and the age of the head-of-line packet. The proposed metrics and analytical results provide new insights into the semantics of timeliness in systems where information ultimately serves the purpose of actuation."}
{"id": "2601.15302", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2601.15302", "abs": "https://arxiv.org/abs/2601.15302", "authors": ["Ivan O. Kitov"], "title": "Low-magnitude seismic activity between the Kamchatka July 20 and July 29, 2025, earthquakes. Spatio-temporal evolution recovered using waveform cross-correlation", "comment": "23 pages, 5 figures", "summary": "The M8.8 Kamchatka earthquake on July 29, 2025 was one of the largest in the first quarter of the 21st century. It deserves a thorough analysis including the preparation process. A smaller M7.4 earthquake occurred on July 20 with its epicenter within the confidence ellipse for the July 29 event. The aftershock sequence of the July 20 earthquake and the evolution of seismicity within the Kamchatka Peninsula region during 10 days period before the July 29 event may provide important information on the earthquake preparation and initiation processes. The CTBTO's International Monitoring System is one of the most sensitive global seismic networks comprising high-resolution array stations with enhanced sensitivity relative to three-component stations at the same locations. The International Data Centre of the CTBTO processes IMS data automatically and interactively to create a Reviewed Event Bulletin (REB), which serves as a source of information for the International Seismological Centre. Waveform cross-correlation (WCC) allows for additional detection capabilities to the IMS data and IDC processing when repeated seismicity is analyzed. The aftershock sequence of the July 20 earthquake is recovered using the WCC-based detection and phase association techniques as applied to the IMS data in order to accurately describe the spatio-temporal evolution of seismic process just before the July 29 event. With the reduced detection threshold, smaller events are found in the zones where the REB has no located sources. This finding opens up the possibility for a more detailed study of seismic and mechanical processes before the July 29 mainshock."}
{"id": "2601.15434", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.15434", "abs": "https://arxiv.org/abs/2601.15434", "authors": ["Yunqing Li", "Zihan Dong", "Farhad Ameri", "Jianbang Zhang"], "title": "ManuRAG: Multi-modal Retrieval Augmented Generation for Manufacturing Question Answering", "comment": null, "summary": "The evolution of digital manufacturing requires intelligent Question Answering (QA) systems that can seamlessly integrate and analyze complex multi-modal data, such as text, images, formulas, and tables. Conventional Retrieval Augmented Generation (RAG) methods often fall short in handling this complexity, resulting in subpar performance. We introduce ManuRAG, an innovative multi-modal RAG framework designed for manufacturing QA, incorporating specialized techniques to improve answer accuracy, reliability, and interpretability. To benchmark performance, we evaluate ManuRAG on three datasets comprising a total of 1,515 QA pairs, corresponding to mathematical, multiple-choice, and review-based questions in manufacturing principles and practices. Experimental results show that ManuRAG consistently outperforms existing methods across all evaluated datasets. Furthermore, ManuRAG's adaptable design makes it applicable to other domains, including law, healthcare, and finance, positioning it as a versatile tool for domain-specific QA."}
{"id": "2601.15787", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.15787", "abs": "https://arxiv.org/abs/2601.15787", "authors": ["Shutong Hou", "Mourad Sini", "Haibing Wang"], "title": "Efficient Numerical Reconstruction of Wave Equation Sources via Droplet-Induced Asymptotics", "comment": null, "summary": "In this paper, we develop and numerically implement a novel approach for solving the inverse source problem of the acoustic wave equation in three dimensions. By injecting a small high-contrast droplet into the medium, we exploit the resulting wave field perturbation measured at a single external point over time. The method enables stable source reconstructions where conventional approaches fail due to ill-posedness, with potential applications in medical imaging and non-destructive testing. Key contributions include:\n  1. Implementation of a theoretically justified asymptotic expansion, from [33], using the eigensystem of the Newtonian operator, with error analysis for the spectral truncation.\n  2. Novel numerical schemes for solving the time-domain Lippmann-Schwinger equation and reconstructing the source via Riesz basis expansions and mollification-based numerical differentiations.\n  3. Reconstruction requiring only single-point measurements, overcoming traditional spatial data limitations.\n  4. 3D numerical experiments demonstrating accurate source recovery under noise (SNR of the order $1/a$), with error analysis for the droplet size (of the order $a$) and the number of spectral modes $N$."}
{"id": "2601.15398", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15398", "abs": "https://arxiv.org/abs/2601.15398", "authors": ["Heinz H. Bauschke", "Walaa M. Moursi"], "title": "Understanding FISTA's weak convergence: A step-by-step introduction to the 2025 milestone", "comment": null, "summary": "Beck and Teboulle's FISTA for finding the minimizer of the sum of two convex functions is one of the most important algorithms of the past decades. While function value convergence of the iterates was known, the actual convergence of the iterates remained elusive until October 2025 when Jang and Ryu, as well as Boţ, Fadili, and Nguyen proved weak convergence.\n  In this paper, we provide a gentle self-contained introduction to the proof of their remarkable result."}
{"id": "2601.15603", "categories": ["math.ST", "cs.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.15603", "abs": "https://arxiv.org/abs/2601.15603", "authors": ["Yi Yu", "Yubo Hou", "Yinchong Wang", "Nan Zhang", "Jianfeng Feng", "Wenlian Lu"], "title": "On the Nonasymptotic Scaling Guarantee of Hyperparameter Estimation in Inhomogeneous, Weakly-Dependent Complex Network Dynamical Systems", "comment": null, "summary": "Hierarchical Bayesian models are increasingly used in large, inhomogeneous complex network dynamical systems by modeling parameters as draws from a hyperparameter-governed distribution. However, theoretical guarantees for these estimates as the system size grows have been lacking. A critical concern is that hyperparameter estimation may diverge for larger networks, undermining the model's reliability. Formulating the system's evolution in a measure transport perspective, we propose a theoretical framework for estimating hyperparameters with mean-type observations, which are prevalent in many scientific applications. Our primary contribution is a nonasymptotic bound for the deviation of estimate of hyperparameters in inhomogeneous complex network dynamical systems with respect to network population size, which is established for a general family of optimization algorithms within a fixed observation duration. While we firstly establish a consistency result for systems with independent nodes, our main result extends this guarantee to the more challenging and realistic setting of weakly-dependent nodes. We validate our theoretical findings with numerical experiments on two representative models: a Susceptible-Infected-Susceptible model and a Spiking Neuronal Network model. In both cases, the results confirm that the estimation error decreases as the network population size increases, aligning with our theoretical guarantees. This research proposes the foundational theory to ensure that hierarchical Bayesian methods are statistically consistent for large-scale inhomogeneous systems, filling a gap in this area of theoretical research and justifying their application in practice."}
{"id": "2601.15317", "categories": ["physics.soc-ph", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.15317", "abs": "https://arxiv.org/abs/2601.15317", "authors": ["Daisuke Hirota"], "title": "The Impossibility of Cohesion Without Fragmentation", "comment": "31 pages 1 figure", "summary": "Most models in game theory and network formation implicitly assume that relations between agents are feasible whenever incentives are aligned or interaction opportunities exist. Under this premise analytical attention is directed toward equilibrium efficiency or probabilistic link formation while the possibility that a relation may be structurally infeasible is rarely examined. This paper develops a static axiomatic framework in which relation maintenance is treated as a problem of structural compatibility rather than strategic choice or stochastic realization. Agents occupy positions in an abstract space and relations are subject to minimum conditions defined over these positions. A bifurcation event such as a vote declaration or institutional assignment fixes agents positions and thereby determines which relations are compatible. We identify position dependent gain axes as the key source of structural selectivity and prove an impossibility result under any non degenerate positional constraint no bifurcation event can preserve all relations. Instead the post event network necessarily exhibits either the simultaneous emergence of fragmentation and cohesion or a degenerate trivial case in which constraints are position independent. The result is purely structural and does not rely on preferences beliefs incentives or dynamic adjustment. It establishes a fundamental limit on universally cohesive outcomes and reframes division not as a failure of design or coordination but as a logical consequence of positional constraints."}
{"id": "2601.16111", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16111", "abs": "https://arxiv.org/abs/2601.16111", "authors": ["Prashant Singh", "David A. Kessler", "Eli Barkai"], "title": "Transition in Splitting Probabilities of Quantum Walks", "comment": "5 pages + 4 figures+ 5 pages of SM", "summary": "We investigate the splitting probability of a monitored continuous-time quantum walk with two targets and show that, in stark contrast to a classical random walk, it exhibits a nonanalytic, phase-transition-like behavior controlled by the sampling time at the targets. For large systems and sampling times smaller than a critical value $τ_c = 2π/ΔE$, where $ΔE$ is the energy bandwidth, the splitting probability is universal and equal to $1/2$, independent of the initial condition and the sampling time. Above the critical sampling, a nonuniversal regime emerges in which the splitting probability deviates from $1/2$ and develops a fluctuating pattern of pronounced peaks and dips dependent on both the sampling time and the initial condition. These results follow from a nontrivial mapping of the splitting problem onto a pair of single-target detection problems enabled by the superposition principle."}
{"id": "2601.15623", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.15623", "abs": "https://arxiv.org/abs/2601.15623", "authors": ["Shiori Hironaka", "Hayato Oshimo", "Mitsuo Yoshida", "Kyoji Umemura"], "title": "Mapping Social Media User Behaviors in Reciprocity Space", "comment": null, "summary": "Social media users exhibit diverse behavioral patterns as platforms function simultaneously as information and friendship networks. We introduce a reciprocity-based framework mapping users onto two-dimensional space defined by bidirectional connection ratios. Analyzing 48,830 Twitter users and 149 million connections, we demonstrate that fragmented user types from prior studies (influencers, lurkers, brokers, and follow-back accounts) emerge naturally as regions within continuous behavioral space rather than discrete categories. User properties vary smoothly across the reciprocity dimensions, revealing clear behavioral gradients. This framework provides the first unified model encompassing the full spectrum of social media behaviors and offers interpretable metrics for influence measurement and platform design."}
{"id": "2601.15386", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.15386", "abs": "https://arxiv.org/abs/2601.15386", "authors": ["Misha Yutushui", "David F. Mross"], "title": "Theory of Next-Generation Even-Denominator States", "comment": "19 pages, 14 figures, 5 tables", "summary": "Even-denominator quantum Hall states are leading candidates for realizing non-Abelian topological orders, with the $ν=\\frac{5}{2}$ plateau in GaAs the first and most-studied example. Recent experiments in GaAs and bilayer graphene (BLG) have observed many `next-generation' even-denominator states at filling factors such as $ν=\\frac{3}{4}$, $\\frac{3}{8}$, and $\\frac{3}{10}$. We develop the theory of these states, including analyses of their bulk quasiparticles, of methods for distinguishing between pairing channels in edge transport measurements, and of their trial wavefunctions. As part of this study, we derive general relations of how flux attachment affects many universal properties of states. In particular, we prove that the topological stability of interface modes is invariant under flux attachment. We compare next-generation paired states to Bonderson-Slingerland states at the same filling factors, and demonstrate that their quasiparticles carry identical charges and obey the same exchange statistics. The next-generation and Bonderson-Slingerland states still describe distinct phases, and we find that the former are energetically favored in the lowest Landau level, while the latter are favored in the first excited level."}
{"id": "2601.15842", "categories": ["hep-lat", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15842", "abs": "https://arxiv.org/abs/2601.15842", "authors": ["Gianluca Esposito", "Simone Cepollaro", "Luigi Cappiello", "Alioscia Hamma"], "title": "Magic of discrete lattice gauge theories", "comment": null, "summary": "Simulation of quantum field theories and fundamental interactions are one of the most challenging tasks in modern particle physics. Classical computers generally fail to reproduce accurate results when it comes to strongly coupled theories such as QCD. Recent developments in quantum technologies open up the possibility of simulating such physical regimes by using quantum computers. In this paper, we study the quantum resource related to the simulability of a quantum theory, i.e. non-stabilizerness for Lattice Gauge Theory (LGT) with discrete symmetry gauge groups. We show that enforcing gauge constraints for $\\mathbb{Z}_l$ LGTs has no cost in terms of this resource and discuss the relation between non-abelianity of the gauge group with the average non-stabilizerness of the gauge invariant Hilbert space."}
{"id": "2601.15361", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15361", "abs": "https://arxiv.org/abs/2601.15361", "authors": ["Hoshitaro Ohnishi", "Hideo Mukai"], "title": "USDs: A universal stabilizer decoder framework using symmetry", "comment": null, "summary": "Quantum error correction is indispensable to achieving reliable quantum computation. When quantum information is encoded redundantly, a larger Hilbert space is constructed using multiple physical qubits, and the computation is performed within a designated subspace. When applying deep learning to the decoding of quantum error-correcting codes, a key challenge arises from the non-uniqueness between the syndrome measurements provided to the decoder and the corresponding error patterns that constitute the ground-truth labels. Building upon prior work that addressed this issue for the toric code by re-optimizing the decoder with respect to the symmetry inherent in the parity-check structure, we generalize this approach to arbitrary stabilizer codes. In our experiments, we employed multilayer perceptrons to approximate continuous functions that complement the syndrome measurements of the Color code and the Golay code. Using these models, we performed decoder re-optimization for each code. For the Color code, we achieved an improvement of approximately 0.8% in decoding accuracy at a physical error rate of 5%, while for the Golay code the accuracy increased by about 0.1%. Furthermore, from the evaluation of the geometric and algebraic structures in the continuous function approximation for each code, we showed that the design of generalized continuous functions is advantageous for learning the geometric structure inherent in the code. Our results also indicate that approximations that faithfully reproduce the code structure can have a significant impact on the effectiveness of reoptimization. This study demonstrates that the re-optimization technique previously shown to be effective for the Toric code can be generalized to address the challenge of label degeneracy that arises when applying deep learning to the decoding of stabilizer codes."}
{"id": "2601.15492", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.15492", "abs": "https://arxiv.org/abs/2601.15492", "authors": ["Thiago Reschützegger", "Sarp Aykent", "Gabriel Jacob Perin", "Bruno Henrique Nunes", "Flaviu Cipcigan", "Rodrigo Neumann Barros Ferreira", "Mathias Steiner", "Fabian L. Thiemann"], "title": "Equivariant Interatomic Potentials without Tensor Products", "comment": "24 pages, 5 figures", "summary": "Foundational machine-learned interatomic potentials have emerged as powerful tools for atomistic simulations, promising near first-principles accuracy across diverse chemical spaces at a fraction of the cost of quantum-mechanical calculations. However, the most accurate equivariant architectures rely on Clebsch-Gordan tensor products whose computational cost scales steeply with angular resolution, creating a trade-off between model expressiveness and inference speed that ultimately limits practical applications. Here we introduce Geodite, an equivariant message-passing architecture that replaces tensor products while incorporating physical priors to ensure smooth, well-behaved potential energy surfaces. Trained on the Materials Project trajectories dataset of inorganic crystals, Geodite-MP achieves accuracy competitive with leading methods on benchmarks for materials stability prediction, thermal conductivity, phonon-derived properties, and nanosecond-scale molecular dynamics, while running $3\\text{--}5\\times$ faster than models performing similarly. By combining predictive accuracy, computational efficiency, and physicality, Geodite enables faster large-scale atomistic simulations and high-throughput screening that would otherwise be computationally prohibitive."}
{"id": "2601.15622", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15622", "abs": "https://arxiv.org/abs/2601.15622", "authors": ["Sampson E. Nwachukwu"], "title": "Design, Modelling, and Control of Magnetic Ball Suspension System", "comment": "8 pages", "summary": "This paper presents the modeling, control design, and performance analysis of a Magnetic Ball Suspension System (MBSS), a nonlinear and inherently unstable electromechanical system used in various precision applications. The system's primary objective is to levitate a steel ball using electromagnetic force without physical contact, thereby eliminating frictional losses. A comprehensive state-space model was developed, capturing both the mechanical and electrical dynamics. The equilibrium points of the system were determined through feedback linearization using the Jacobian matrix. To ensure system stability, controllability and observability analyses were conducted, confirming that state feedback and observer-based control strategies could be effectively implemented. Three distinct control methods were explored: pole placement-based state feedback control, full-order observer design, and optimal state feedback control using the Linear Quadratic Regulator (LQR). Each control strategy was validated through Simulink simulations for both linearized and nonlinear models. Simulation results demonstrated that the linearized system consistently achieved desired performance with minimal oscillations, whereas the nonlinear system exhibited significant transient oscillations before stabilization. The full-order observer enhanced estimation accuracy, enabling effective control where direct state measurement was impractical. The LQR-based control offered improved robustness and minimized control effort, though its performance was comparable to standard state feedback in some cases."}
{"id": "2601.15566", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.15566", "abs": "https://arxiv.org/abs/2601.15566", "authors": ["Fan Yang", "Zhao Ren", "Wen Zhou", "Kejue Jia", "Robert Jernigan"], "title": "Model-Free Inference for Characterizing Protein Mutations through a Coevolutionary Lens", "comment": null, "summary": "Multiple sequence alignment (MSA) data play a crucial role in the study of protein mutations, with contact prediction being a notable application. Existing methods are often model-based or algorithmic and typically do not incorporate statistical inference to quantify the uncertainty of the prediction outcomes. To address this, we propose a novel framework that transforms the task of contact prediction into a statistical testing problem. Our approach is motivated by the partial correlation for continuous random variables. With one-hot encoding of MSA data, we are able to construct a partial correlation graph for multivariate categorical variables. In this framework, two connected nodes in the graph indicate that the corresponding positions on the protein form a contact. A new spectrum-based test statistic is introduced to test whether two positions are partially correlated. Moreover, the new framework enables the identification of amino acid combinations that contribute to the correlation within the identified contacts, an important but largely unexplored aspect of protein mutations. Numerical experiments demonstrate that our proposed method is valid in terms of controlling Type I errors and powerful in general. Real data applications on various protein families further validate the practical utility of our approach in coevolution and mutation analysis."}
{"id": "2601.15345", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15345", "abs": "https://arxiv.org/abs/2601.15345", "authors": ["Amanda Gatto Lamas", "Taylor L. Hughes"], "title": "Non-zero Momentum Implies Long-Range Entanglement When Translation Symmetry is Broken in 1D", "comment": "24+8 pages, 15+5 figures", "summary": "A result by Gioia and Wang [Phys Rev X 12, 031007 (2022)] showed that translationally symmetric states having nonzero momentum are necessarily long range entangled (LRE). Here, we consider the question: can a notion of momentum for non-translation symmetric states directly encode the nature of their entanglement, as it does for translation symmetric states? We show the answer is affirmative for 1D systems, while higher dimensional extensions and topologically ordered systems require further work. While Gioia and Wang's result applies to states connected via finite depth quantum circuits to a translation symmetric state, it is often impractical to find such a circuit to determine the nature of the entanglement of states that break translation symmetry. Here, instead of translation eigenstates, we focus on the many-body momentum distribution and the expectation value of the translation operator in many-body states of systems having broken translation symmetry. We show that in the continuum limit the magnitude of the expectation value of the translation operator $|<T>|$ necessarily goes to $1$ for delocalized states, a proxy for LRE states in 1D systems. This result can be seen as a momentum-space version of Resta's formula for the localization length. We investigate how accurate our results are in different lattice models with and without well-defined continuum limits. To that end, we introduce two models: a deterministic version of the random dimer model, illustrating the role of the thermodynamic and continuum limits for our result at a lattice level, and a simplified version of the Aubry-Andre model, with commensurate hopping for both momentum and position space. Finally, we use the random dimer model as a test case for the accuracy of $|<T>|$ as a localization (and thus entanglement) probe for 1D periodic lattice models without a well-defined continuum limit."}
{"id": "2601.16086", "categories": ["cond-mat.stat-mech", "nlin.AO", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.16086", "abs": "https://arxiv.org/abs/2601.16086", "authors": ["Diego Febbe", "Duccio Fanelli", "Timoteo Carletti"], "title": "Random Walks Across Dimensions: Exploring Simplicial Complexes", "comment": null, "summary": "We introduce a novel operator to describe a random walk process on a simplicial complex. Walkers are allowed to wonder across simplices of various dimensions, bridging nodes to edges, and edges to triangles, via a nested organization that hierarchically extends to higher structures of arbitrary large, but finite, dimension. The asymptotic distribution of the walkers provides a natural ranking to gauge the relative importance of higher order simplices. Optimal search strategies in presence of stochastic teleportation are addressed and the peculiar interplay of noise with higher order structures unraveled."}
{"id": "2601.16169", "categories": ["cs.ET", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.16169", "abs": "https://arxiv.org/abs/2601.16169", "authors": ["Robert Walkup", "Juha Jäykkä", "Igor Pasichnyk", "Zachary Streeter", "Kasia Świrydowicz", "Mikko Tukiainen", "Yasuko Eckert", "Luke Bertels", "Daniel Claudino", "Peter Groszkowski", "Travis S. Humble", "Constantinos Evangelinos", "Javier Robledo-Moreno", "William Kirby", "Antonio Mezzacapo", "Antonio Córcoles", "Seetharami Seelam"], "title": "Scaling Sample-Based Quantum Diagonalization on GPU-Accelerated Systems using OpenMP Offload", "comment": "12 pages", "summary": "Hybrid quantum-HPC algorithms advance research by delegating complex tasks to quantum processors and using HPC systems to orchestrate workflows and complementary computations. Sample-based quantum diagonalization (SQD) is a hybrid quantum-HPC method in which information from a molecular Hamiltonian is encoded into a quantum circuit for evaluation on a quantum computer. A set of measurements on the quantum computer yields electronic configurations that are filtered on the classical computer, which also performs diagonalization on the selected subspace and identifies configurations to be carried over to the next step in an iterative process. Diagonalization is the most demanding task for the classical computer. Previous studies used the Fugaku supercomputer and a highly scalable diagonalization code designed for CPUs. In this work, we describe our efforts to enable efficient scalable and portable diagonalization on heterogeneous systems using GPUs as the main compute engines based on the previous work.\n  GPUs provide massive on-device thread-level parallelism that is well aligned with the algorithms used for diagonalization. We focus on the computation of ground-state energies and wavefunctions using the Davidson algorithm with a selected set of electron configurations. We describe the offload strategy, code transformations, and data-movement, with examples of measurements on the Frontier supercomputer and five other GPU accelerated systems. Our measurements show that GPUs provide an outstanding performance boost of order 100x on a per-node basis. This dramatically expedites the diagonalization step-essential for extracting ground and excited state energies-bringing the classical processing time down from hours to minutes."}
{"id": "2601.15622", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15622", "abs": "https://arxiv.org/abs/2601.15622", "authors": ["Sampson E. Nwachukwu"], "title": "Design, Modelling, and Control of Magnetic Ball Suspension System", "comment": "8 pages", "summary": "This paper presents the modeling, control design, and performance analysis of a Magnetic Ball Suspension System (MBSS), a nonlinear and inherently unstable electromechanical system used in various precision applications. The system's primary objective is to levitate a steel ball using electromagnetic force without physical contact, thereby eliminating frictional losses. A comprehensive state-space model was developed, capturing both the mechanical and electrical dynamics. The equilibrium points of the system were determined through feedback linearization using the Jacobian matrix. To ensure system stability, controllability and observability analyses were conducted, confirming that state feedback and observer-based control strategies could be effectively implemented. Three distinct control methods were explored: pole placement-based state feedback control, full-order observer design, and optimal state feedback control using the Linear Quadratic Regulator (LQR). Each control strategy was validated through Simulink simulations for both linearized and nonlinear models. Simulation results demonstrated that the linearized system consistently achieved desired performance with minimal oscillations, whereas the nonlinear system exhibited significant transient oscillations before stabilization. The full-order observer enhanced estimation accuracy, enabling effective control where direct state measurement was impractical. The LQR-based control offered improved robustness and minimized control effort, though its performance was comparable to standard state feedback in some cases."}
{"id": "2601.16068", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2601.16068", "abs": "https://arxiv.org/abs/2601.16068", "authors": ["Chaohua Liang", "Xingliang Peng", "Jun Matsushima"], "title": "Physics-Informed Neural Networks for Viscoacoustic Wave Propagation: Forward Modelling, Inversion and Discretization Sensitivity", "comment": null, "summary": "Seismic wave forward and inverse modeling are fundamental tools for subsurface imaging and geological hazard assessment. Conventional grid-based numerical methods, such as finite-difference and finite-element approaches, often require dense discretization and repeated forward simulations, leading to high computational cost in inverse problems. Although deep learning has shown promise in seismic applications, its performance is commonly limited by the need for large labeled datasets and weak enforcement of physical constraints.\n  In this study, we propose a unified physics-informed neural network (PINN) framework for forward modeling and parameter inversion of viscoacoustic wave propagation. By embedding the viscoacoustic wave equation into the learning process, the proposed framework accurately reproduces wavefields, attenuation, and phase characteristics, while enabling the simultaneous inversion of velocity and attenuation parameters from temporally sparse observations.\n  Numerical experiments demonstrate that the PINN approach achieves stable and reliable accuracy compared with finite-difference solutions, while exhibiting reduced sensitivity to spatial discretization. These results highlight the potential of PINNs as a data-efficient and physically consistent alternative for high-resolution seismic modeling and inversion in attenuative media."}
{"id": "2601.15458", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.15458", "abs": "https://arxiv.org/abs/2601.15458", "authors": ["Emily G. Light", "Morgan Prior", "Noah M. Daniels", "Najib Ishaq"], "title": "MuSAlS: A Fast Multiple Sequence Alignment Approach Using Hierarchical Clustering", "comment": "As submitted to ISMB 2026", "summary": "Motivation: The multiple sequence alignment (MSA) problem has been extensively studied, with numerous approaches developed over recent years. With the rapid growth of sequence data, there is an increasing need for fast and accurate MSA tools that scale effectively to large datasets. Building on our previous work on CLAM, we are able to use exact dynamic programming (Needleman-Wunsch) while scaling to large datasets. We introduce MuSAlS (Multiple Sequence Alignment at Scale), a fast and scalable de novo MSA aligner. MuSAlS uses hierarchical clustering to construct a guide tree based on the Levenshtein distance metric, enabling efficient and accurate alignment through a bottom-up approach. Results: MuSAlS achieves competitive accuracy compared to state-of-the-art methods while significantly improving runtime performance. This makes it a valuable tool for researchers analyzing large-scale genomic and metagenomic datasets, addressing the growing demand for scalable bioinformatics solutions. Availability and Implementation: MuSAlS is implemented in the Rust programming language, and available at https://github.com/URI-ABD/clam"}
{"id": "2601.15911", "categories": ["math.NA", "math.CA"], "pdf": "https://arxiv.org/pdf/2601.15911", "abs": "https://arxiv.org/abs/2601.15911", "authors": ["Miguel A. Piñar"], "title": "A fully diagonalized spectral method on the unit ball", "comment": "This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this article is published in Numerical Algorithms, and is available online at https://doi.org/10.1007/s11075-026-02315-w", "summary": "Our main objective in this work is to show how Sobolev orthogonal polynomials emerge as a useful tool within the framework of spectral methods for boundary-value problems. The solution of a boundary-value problem for a stationary Schrödinger equation on the unit ball can be studied from a variational perspective. In this variational formulation, a Sobolev inner product naturally arises. As test functions, we consider the linear space of the polynomials satisfying the boundary conditions on the sphere, and a basis of mutually orthogonal polynomials with respect to the Sobolev inner product is provided. The basis of the proposed method is given in terms of spherical harmonics and univariate Sobolev orthogonal polynomials. The connection formula between these Sobolev orthogonal polynomials and the classical orthogonal polynomials on the ball is established. Consequently, the Sobolev Fourier coefficients of a function satisfying the boundary value problem are recursively derived. Finally, one numerical experiment is presented."}
{"id": "2601.15411", "categories": ["math.OC", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.15411", "abs": "https://arxiv.org/abs/2601.15411", "authors": ["D. Russell Luke", "Johannes-Carl Schnebel", "Mathias Staudigl", "Juan Peypouquet", "Siqi Qu"], "title": "Asymptotic behaviour of coupled random dynamical systems with multiscale aspects", "comment": null, "summary": "We examine a class of stochastic differential inclusions involving multiscale effects designed to solve a class of generalized variational inequalities. This class of problems contains constrained convex non-smooth optimization problems, constrained saddle-point problems and various equilibrium problems in economics and engineering. In order to respect constraints we adopt a penalty approach, introducing an explicit time-dependency into the evolution system. The resulting dynamics are described in terms of a non-autonomous stochastic evolution equation governed by maximally monotone operators in the drift and perturbed by a Brownian motion. We study the asymptotic behavior, as well as finite time convergence rates in terms of gap functions. The condition we use to prove convergence involves a Legendre transform of the function describing the set C, a condition first used by Attouch and Czarnecki (J. Differ. Equations, Vol. 248, Issue 6, 2010) in the context of deterministic evolution equations. We also establish a large deviations principle showing that individual trajectories exhibit exponential concentration around the solution set. Finally we show how our continuous-time approach relates to penalty-regulated algorithms of forward-backward type after performing a suitable Euler-Maruyama discretisation."}
{"id": "2601.16041", "categories": ["math.ST", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.16041", "abs": "https://arxiv.org/abs/2601.16041", "authors": ["Omar Al-Ghattas"], "title": "Risk reversal for least squares estimators under nested convex constraints", "comment": "31 pages, 5 figures", "summary": "In constrained stochastic optimization, one naturally expects that imposing a stricter feasible set does not increase the statistical risk of an estimator defined by projection onto that set. In this paper, we show that this intuition can fail even in canonical settings.\n  We study the Gaussian sequence model, a deliberately austere test best, where for a compact, convex set $Θ\\subset \\mathbb{R}^d$ one observes \\[ Y = θ^\\star + σZ, \\qquad Z \\sim N(0, I_d), \\] and seeks to estimate an unknown parameter $θ^\\star \\in Θ$. The natural estimator is the least squares estimator (LSE), which coincides with the Euclidean projection of $Y$ onto $Θ$. We construct an explicit example exhibiting \\emph{risk reversal}: for sufficiently large noise, there exist nested compact convex sets $Θ_S \\subset Θ_L$ and a parameter $θ^\\star \\in Θ_S$ such that the LSE constrained to $Θ_S$ has strictly larger risk than the LSE constrained to $Θ_L$. We further show that this phenomenon can persist at the level of worst-case risk, with the supremum risk over the smaller constraint set exceeding that over the larger one.\n  We clarify this behavior by contrasting noise regimes. In the vanishing-noise limit, the risk admits a first-order expansion governed by the statistical dimension of the tangent cone at $θ^\\star$, and tighter constraints uniformly reduce risk. In contrast, in the diverging-noise regime, the risk is determined by global geometric interactions between the constraint set and random noise directions. Here, the embedding of $Θ_S$ within $Θ_L$ can reverse the risk ordering.\n  These results reveal a previously unrecognized failure mode of projection-based estimators: in sufficiently noisy settings, tightening a constraint can paradoxically degrade statistical performance."}
{"id": "2601.15535", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.15535", "abs": "https://arxiv.org/abs/2601.15535", "authors": ["Estefanía Duque Pérez", "Lukas Jansen", "Benedikt Haeckner"], "title": "Exploring the impacts of demand scenarios, weather variability and mitigation of emissions on Morocco's hydrogen market and renewable transition pathways", "comment": null, "summary": "The global demand for green hydrogen and its derivatives is growing rapidly as a cornerstone for decarbonizing hard-to-abate sectors. Morocco, endowed with abundant solar and wind resources, ambitions to capture up to 4% of the global PtX market by 2030, positioning itself as a strategic partner for Europe's energy transition. Yet, uncertainty persists regarding European demand trajectories, infrastructure readiness, and investment risks. This study evaluates Morocco's hydrogen transition through 2035 using a sector-coupled capacity expansion model. We compare industry reallocation and hydrogen export-oriented scenarios, assessing their impacts under interannual weather variability and financial sensitivities. Both scenarios require a tripling of current renewable and electrolyzer capacities, with hydrogen demand reaching approximately up to 38 TWh by 2035. Lower financing costs (WACC) have a greater effect on system costs and competitiveness than stricter CO2 constraints or weather variability. The trade- off between domestic energy security and export competitiveness is pronounced, but both pathways are technically feasible and aligned with Morocco's strategic energy goals. These findings provide evidence-based guidance for policymakers to balance Morocco's domestic and export ambitions in the evolving hydrogen market."}
{"id": "2601.16114", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16114", "abs": "https://arxiv.org/abs/2601.16114", "authors": ["Alex V. Plyukhin"], "title": "Langevin equations with non-Gaussian thermal noise: Valid but superfluous", "comment": "10 pages", "summary": "We discuss the statistics of additive thermal (internal) noise in systems governed by the generalized Langevin equation with linear dissipation. To assess the equation's validity, it is common to assume that the system is ergodic and to verify that solutions approach correct equilibrium values at asymptotically long times. In this paper, we instead consider the consistency of the generalized Langevin equation with the Jarzynski equality at finite times and do not assume the system's ergodicity. Specifically, we consider a classical Brownian oscillator whose initial stiffness, or frequency, is perturbed by a rectangular pulse of duration $τ$. We find that the Jarzynski equality is satisfied unconditionally only up to the seventh order in $τ$; in higher orders, the Jarzynski equality holds if and only if the noise is Gaussian. These results imply that, unless it is exact, the Langevin equation can only be used to evaluate properties that are linear or quadratic in noise and its derivatives. Such properties are insensitive to the noise statistics, so the Langevin equation with linear dissipation and non-Gaussian noise (though not inconsistent by itself) is superfluous."}
{"id": "2601.15635", "categories": ["cs.SI", "physics.soc-ph", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.15635", "abs": "https://arxiv.org/abs/2601.15635", "authors": ["Theodore Y. Faust", "Arash A. Amini", "Mason A. Porter"], "title": "Community-Size Biases in Statistical Inference of Communities in Temporal Networks", "comment": "45 pages, 11 figures", "summary": "In the study of time-dependent (i.e., temporal) networks, researchers often examine the evolution of communities, which are sets of densely connected sets of nodes that are connected sparsely to other nodes. An increasingly prominent approach to studying community structure in temporal networks is statistical inference. In the present paper, we study the performance of a class of statistical-inference methods for community detection in temporal networks. We represent temporal networks as multilayer networks, with each layer encoding a time step, and we illustrate that statistical-inference models that generate community assignments via either a uniform distribution on community assignments or discrete-time Markov processes are biased against generating communities with large or small numbers of nodes. In particular, we demonstrate that statistical-inference methods that use such generative models tend to poorly identify community structure in networks with large or small communities. To rectify this issue, we introduce a novel statistical model that generates the community assignments of the nodes in given layer (i.e., at a given time) using all of the community assignments in the previous layer. We prove results that guarantee that our approach greatly mitigates the bias against large and small communities, so using our generative model is beneficial for studying community structure in networks with large or small communities. Our code is available at https://github.com/tfaust0196/TemporalCommunityComparison."}
{"id": "2601.15702", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.15702", "abs": "https://arxiv.org/abs/2601.15702", "authors": ["K. Guratinder", "T. G. Romig", "H. C. Mandujano", "C. Stock", "E. E. Rodriguez"], "title": "Spin reorientations in structurally metastable, disordered, and hexagonal Cr7Te8", "comment": "Accepted in PRB", "summary": "Vapor deposited two-dimensional Cr$_{7}$Te$_{8}$ displays unusual temperature dependent Hall effect properties, including a room temperature anomalous Hall effect, sign reversals of the Hall resistivity on cooling, and a peak in the Hall resistivity at low temperatures. The two dimensional Cr$_{7}$Te$_{8}$ heterostructures that form the basis of these measurements are hexagonal in structure. We study the magnetic and structural properties of bulk Cr$_{7}$Te$_{8}$ synthesized by quenching from 1000 $^{\\circ}$C with the goal of relating the magnetic, structural, and electronic properties. This quenched phase is metastable, hexagonal, and displays different magnetic properties from the slow-cooled and more thermodynamically stable monoclinic phase. High-resolution x-ray diffraction of the quenched hexagonal phase finds a first-order transition to a lower symmetry monoclinic phase on \\textit{heating} above $\\sim$ 550 K. Magnetic susceptibility measurements of the quenched hexagonal phase reveal ferromagnetic ordering above room temperature, along with the two distinct transitions at $\\sim$ 220~K and $\\sim$ 70~K. Through neutron diffraction studies, we find the $\\sim$ 220 K anomaly is a spin reorientation transition of the ferromagnetically aligned magnetic moments and the $\\sim70$ K feature represents a transition from a high temperature ferromagnet to a low temperature antiferromagnet. We suggest that these magnetic transitions are related to changes in the unit cell dimensions and are connected to the temperature dependent Hall resisitivity studied in two-dimensional heterostructures. This implies a link between structural, magnetic, and electronic properties in the ``pseudo\" two-dimensional chromium tellurides."}
{"id": "2601.16051", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2601.16051", "abs": "https://arxiv.org/abs/2601.16051", "authors": ["Simon Hands", "Jude Worthy"], "title": "Critical scaling in the $N=1$ Thirring Model in $(2+1)d$", "comment": "contributed talk at LATTICE 2025, Mumbai, 2-8 November 2025", "summary": "The Thirring model in 2+1$d$ with $N$ Dirac flavors can exhibit spontaneous U($2N)\\to$U($N)\\otimes$U($N$) breaking through fermion - antifermion condensation in the limit $m\\to0$. With no small parameter in play the symmetry-breaking dynamics is strongly-interacting and quantitative work requires a fermion formulation accurately capturing global symmetries. We present simulation results for $N=1$ obtained with Wilson kernel domain wall fermions on $16^3\\times L_s$, with $L_s=24,\\ldots,120$. The $L_s\\to\\infty$ extrapolation of the bilinear condensate $\\langle\\barψψ\\rangle$ as a function of coupling and bare mass is fitted to an empirical equation of state; the resulting critical exponents are significantly altered from previously obtained values, and for the first time resemble those emerging from analytic predictions based on approximate solutions to Schwinger-Dyson equations, consistent with a putative UV-stable renormalisation group fixed point. To address the non-perturbative issue of the value $N_c$ below which such a fixed point exists we present preliminary results obtained with $N=2$."}
{"id": "2601.15393", "categories": ["quant-ph", "cs.CC", "cs.CR", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.15393", "abs": "https://arxiv.org/abs/2601.15393", "authors": ["Johannes Jakob Meyer", "Jacopo Rizzo", "Asad Raza", "Lorenzo Leone", "Sofiene Jerbi", "Jens Eisert"], "title": "The computational two-way quantum capacity", "comment": "5+2 pages, comments welcome", "summary": "Quantum channel capacities are fundamental to quantum information theory. Their definition, however, does not limit the computational resources of sender and receiver. In this work, we initiate the study of computational quantum capacities. These quantify how much information can be reliably transmitted when imposing the natural requirement that en- and decoding have to be computationally efficient. We focus on the computational two-way quantum capacity and showcase that it is closely related to the computational distillable entanglement of the Choi state of the channel. This connection allows us to show a stark computational capacity separation. Under standard cryptographic assumptions, there exists a quantum channel of polynomial complexity whose computational two-way quantum capacity vanishes while its unbounded counterpart is nearly maximal. More so, we show that there exists a sharp transition in computational quantum capacity from nearly maximal to zero when the channel complexity leaves the polynomial realm. Our results demonstrate that the natural requirement of computational efficiency can radically alter the limits of quantum communication."}
{"id": "2601.15497", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.15497", "abs": "https://arxiv.org/abs/2601.15497", "authors": ["Kathleen Winona Vian Martinus", "Sushan Nakarmi", "Dawa Seo", "Nitin Pandurang Daphalapurkar"], "title": "Convolutional LSTM Surrogate for Mesoscale Hydrocode Simulations of Granular Wave Propagation", "comment": "24 page, 8 figures", "summary": "Granular materials subjected to impact loading exhibit highly heterogeneous spatiotemporal dynamics governed by wave propagation, pore collapse, and grain-scale rearrangements. Mesoscale hydrocodes resolve these processes but are computationally expensive, limiting their use in parametric studies and uncertainty quantification. In this work, we develop a convolutional Long Short-Term Memory (ConvLSTM) neural network as a spatiotemporal surrogate for mesoscale simulations of weak shock propagation in granular media. Using two-dimensional hydrocode simulations as training data, we first consider a simplified \"billiard break\" problem in which a cue ball impacts a cluster of nine circular balls, all deformable. Sequences of pressure-field images serve as input-output pairs for a sequence-to-sequence ConvLSTM, which is trained to predict future frames from a short history. We compare several architectures and show that a relatively compact encoder-decoder ConvLSTM accurately reproduces the propagation of the pressure wave and the resulting particle motion for an unseen combination of cue-ball position and impact velocity. As a proof-of-concept extension, we apply the same ConvLSTM framework to previously published mesoscale simulations of weak shock compaction in a granular ensemble. When evaluated at piston impact speeds that were completely withheld from training, the surrogate captures the position and shape of the compaction front and its dependence on impact speed, while smoothing fine pore-scale details in the highly compacted region as expected. These results demonstrate that ConvLSTM models can serve as satisfactory surrogates for spatiotemporal mesoscale simulations of granular wave propagation, enabling accelerated exploration of parameter space and laying the groundwork for physics-informed, mesoscale simulations of granular materials under shock loading."}
{"id": "2601.15626", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15626", "abs": "https://arxiv.org/abs/2601.15626", "authors": ["Lili Chen", "Winn Wing-Yiu Chow", "Stella Peng", "Bencheng Fan", "Sachitha Bandara"], "title": "Bridging Qualitative Rubrics and AI: A Binary Question Framework for Criterion-Referenced Grading in Engineering", "comment": "Proceedings of the 36th Annual Conference of the Australasian Association for Engineering Education (AAEE 2025)", "summary": "PURPOSE OR GOAL: This study investigates how GenAI can be integrated with a criterion-referenced grading framework to improve the efficiency and quality of grading for mathematical assessments in engineering. It specifically explores the challenges demonstrators face with manual, model solution-based grading and how a GenAI-supported system can be designed to reliably identify student errors, provide high-quality feedback, and support human graders. The research also examines human graders' perceptions of the effectiveness of this GenAI-assisted approach. ACTUAL OR ANTICIPATED OUTCOMES: The study found that GenAI achieved an overall grading accuracy of 92.5%, comparable to two experienced human graders. The two researchers, who also served as subject demonstrators, perceived the GenAI as a helpful second reviewer that improved accuracy by catching small errors and provided more complete feedback than they could manually. A central outcome was the significant enhancement of formative feedback. However, they noted the GenAI tool is not yet reliable enough for autonomous use, especially with unconventional solutions. CONCLUSIONS/RECOMMENDATIONS/SUMMARY: This study demonstrates that GenAI, when paired with a structured, criterion-referenced framework using binary questions, can grade engineering mathematical assessments with an accuracy comparable to human experts. Its primary contribution is a novel methodological approach that embeds the generation of high-quality, scalable formative feedback directly into the assessment workflow. Future work should investigate student perceptions of GenAI grading and feedback."}
{"id": "2601.15696", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.15696", "abs": "https://arxiv.org/abs/2601.15696", "authors": ["Kyongwon Kim", "Bing Li"], "title": "Learning Functional Graphs with Nonlinear Sufficient Dimension Reduction", "comment": null, "summary": "Functional graphical models have undergone extensive development during the recent years, leading to a variety models such as the functional Gaussian graphical model, the functional copula Gaussian graphical model, the functional Bayesian graphical model, the nonparametric functional additive graphical model, and the conditional functional graphical model. These models rely either on some parametric form of distributions on random functions, or on additive conditional independence, a criterion that is different from probabilistic conditional independence. In this paper we introduce a nonparametric functional graphical model based on functional sufficient dimension reduction. Our method not only relaxes the Gaussian or copula Gaussian assumptions, but also enhances estimation accuracy by avoiding the ``curse of dimensionality''. Moreover, it retains the probabilistic conditional independence as the criterion to determine the absence of edges. By doing simulation study and analysis of the f-MRI dataset, we demonstrate the advantages of our method."}
{"id": "2601.15799", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.15799", "abs": "https://arxiv.org/abs/2601.15799", "authors": ["Sanghoon Lee", "Tilen Cadez", "Kyoung-Min Kim"], "title": "Structural constraints on mobility edges in one-dimensional quasiperiodic systems", "comment": "7 pages, 7 figures", "summary": "Mobility edges commonly arise in one-dimensional quasiperiodic systems once exact self-duality is broken, yet their origin is typically understood only at the level of individual Hamiltonians. Here we show that mobility edge positions are not independent spectral features of individual Hamiltonians, but are structurally constrained across quasiperiodic Hamiltonians related by an isospectral duality. Using a bichromatic Aubry--André model as a minimal setting, we demonstrate that this constraint is encoded in an exact identity for Lyapunov exponents derived from the Thouless formula. As a consequence, the mobility edge positions are restricted to a reduced set of energies. In the self-dual limit, these mobility edge positions coincide at a single localization--delocalization transition. This structural constraint enforces a linear critical scaling of the physical Lyapunov spectrum near the self-dual point. Numerical results confirm a critical exponent consistent with the standard Aubry--André value of $ν= 1$, while simultaneously revealing a novel, non-universal energy-dependent prefactor."}
{"id": "2601.16004", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.16004", "abs": "https://arxiv.org/abs/2601.16004", "authors": ["Christopher Altman"], "title": "Wigner's Friend as a Circuit: Inter-Branch Communication Witness Benchmarks on Superconducting Quantum Hardware", "comment": "11 pages, 6 figures. Includes reproducibility code and archived data release", "summary": "We implement and benchmark on IBM Quantum hardware the circuit family proposed by Violaris for estimating operational inter-branch communication witnesses, defined as correlations in classical measurement records produced by compiled Wigner's-friend-style circuits. We realize a five-qubit instance of the protocol as an inter-register message-transfer pattern within a single circuit, rather than physical signaling, and evaluate its behavior under realistic device noise and compilation constraints. The circuit encodes branch-conditioned evolution of an observer subsystem whose dynamics depend on a control qubit, followed by a controlled transfer operation that probes correlations between conditional measurement contexts.\n  Executing on the ibm_fez backend with 20000 shots, we observe population-based visibility of 0.877, coherence witnesses of 0.840 and -0.811 along orthogonal axes, and a phase-sensitive magnitude of approximately 1.17. While the visibility metric is insensitive to some classes of dephasing, the coherence witnesses provide complementary sensitivity to off-diagonal noise.\n  This work does not test or discriminate among interpretations of quantum mechanics. Instead, it provides a reproducible operational constraint pipeline for evaluating detectability of non-ideal channels relative to calibrated device noise."}
{"id": "2601.15626", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15626", "abs": "https://arxiv.org/abs/2601.15626", "authors": ["Lili Chen", "Winn Wing-Yiu Chow", "Stella Peng", "Bencheng Fan", "Sachitha Bandara"], "title": "Bridging Qualitative Rubrics and AI: A Binary Question Framework for Criterion-Referenced Grading in Engineering", "comment": "Proceedings of the 36th Annual Conference of the Australasian Association for Engineering Education (AAEE 2025)", "summary": "PURPOSE OR GOAL: This study investigates how GenAI can be integrated with a criterion-referenced grading framework to improve the efficiency and quality of grading for mathematical assessments in engineering. It specifically explores the challenges demonstrators face with manual, model solution-based grading and how a GenAI-supported system can be designed to reliably identify student errors, provide high-quality feedback, and support human graders. The research also examines human graders' perceptions of the effectiveness of this GenAI-assisted approach. ACTUAL OR ANTICIPATED OUTCOMES: The study found that GenAI achieved an overall grading accuracy of 92.5%, comparable to two experienced human graders. The two researchers, who also served as subject demonstrators, perceived the GenAI as a helpful second reviewer that improved accuracy by catching small errors and provided more complete feedback than they could manually. A central outcome was the significant enhancement of formative feedback. However, they noted the GenAI tool is not yet reliable enough for autonomous use, especially with unconventional solutions. CONCLUSIONS/RECOMMENDATIONS/SUMMARY: This study demonstrates that GenAI, when paired with a structured, criterion-referenced framework using binary questions, can grade engineering mathematical assessments with an accuracy comparable to human experts. Its primary contribution is a novel methodological approach that embeds the generation of high-quality, scalable formative feedback directly into the assessment workflow. Future work should investigate student perceptions of GenAI grading and feedback."}
{"id": "2601.15716", "categories": ["cs.CE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.15716", "abs": "https://arxiv.org/abs/2601.15716", "authors": ["Xiao-Yang Liu", "Ningjie Li", "Keyi Wang", "Xiaoli Zhi", "Weiqin Tong"], "title": "zkFinGPT: Zero-Knowledge Proofs for Financial Generative Pre-trained Transformers", "comment": null, "summary": "Financial Generative Pre-trained Transformers (FinGPT) with multimodal capabilities are now being increasingly adopted in various financial applications. However, due to the intellectual property of model weights and the copyright of training corpus and benchmarking questions, verifying the legitimacy of GPT's model weights and the credibility of model outputs is a pressing challenge. In this paper, we introduce a novel zkFinGPT scheme that applies zero-knowledge proofs (ZKPs) to high-value financial use cases, enabling verification while protecting data privacy. We describe how zkFinGPT will be applied to three financial use cases. Our experiments on two existing packages reveal that zkFinGPT introduces substantial computational overhead that hinders its real-world adoption. E.g., for LLama3-8B model, it generates a commitment file of $7.97$MB using $531$ seconds, and takes $620$ seconds to prove and $2.36$ seconds to verify."}
{"id": "2601.16122", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.16122", "abs": "https://arxiv.org/abs/2601.16122", "authors": ["Jörg Schröder", "Maximilian Vorwerk"], "title": "Canonical structure of the LLG equation for exponential updates in micromagnetism", "comment": null, "summary": "In this contribution we propose an exponential update algorithm for magnetic moments appearing in the framework of micromagnetics and the Landau-Lifshitz-Gilbert (LLG) equation. This algorithm can be interpreted as the geometric integration on spheres, that a priori satisfy the unit length constraint of the normalized magnetization vector. Even though the geometric structures for this are obvious and some works already use an exponential algorithm, to the best of the authors' knowledge, there is no canonical structure of the LLG equation for the exponential update algorithm in micromagnetism. Tensor algebraic reformulations of the LLG equation allow the canonical representation of the evolution equation for the magnetization, which serves as the basis for different integrators. Based on the specific structure of the exponential of skew symmetric matrices an efficient update scheme is derived. The excellent performance of the proposed exponential update algorithm is demonstrated in representative examples."}
{"id": "2601.15499", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15499", "abs": "https://arxiv.org/abs/2601.15499", "authors": ["Oliver Bachtler"], "title": "Folklore in Multi-Objective Optimisation", "comment": null, "summary": "In this paper, we present and prove some results in multi-objective optimisation that are considered folklore. For the most part, proofs for these results exist in special cases, but they are used in more general settings since their proofs can be (largely) transferred. We do this transfer explicitly and try to state the results as generally as possible. In particular, we also aim at providing clean and complete proofs for results where the original papers are not rigorous."}
{"id": "2601.16058", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.16058", "abs": "https://arxiv.org/abs/2601.16058", "authors": ["Claudia Kirch", "Hedvika Ranošová", "Martin Wendler"], "title": "Fully Functional Weighted Testing for Abrupt and Gradual Location Changes in Functional Time Series", "comment": null, "summary": "Change point tests for abrupt changes in the mean of functional data, i.e., random elements in infinite-dimensional Hilbert spaces, are either based on dimension reduction techniques, e.g., based on principal components, or directly based on a functional CUSUM (cumulative sum) statistic. The former have often been criticized as not being fully functional and losing too much information. On the other hand, unlike the latter, they take the covariance structure of the data into account by weighting the CUSUM statistics obtained after dimension reduction with the inverse covariance matrix. In this paper, as a middle ground between these two approaches, we propose an alternative statistic that includes the covariance structure with an offset parameter to produce a scale-invariant test procedure and to increase power when the change is not aligned with the first components. We obtain the asymptotic distribution under the null hypothesis for this new test statistic, allowing for time dependence of the data. Furthermore, we introduce versions of all three test statistics for gradual change situations, which have not been previously considered for functional data, and derive their limit distribution. Further results shed light on the asymptotic power behavior for all test statistics under various ground truths for the alternatives."}
{"id": "2601.15537", "categories": ["physics.soc-ph", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.15537", "abs": "https://arxiv.org/abs/2601.15537", "authors": ["Jhordan Silveira de Borba", "Celia Anteneodo", "Sebastian Gonçalves"], "title": "Can Rising Consumption Deepen Inequality?", "comment": "19 pages, 8 figures", "summary": "The impact of rising consumption on wealth inequality remains an open question. Here we revisit and extend the Social Architecture of Capitalism agent-based model proposed by Ian Wright, which reproduces stylized facts of wealth and income distributions. In a previous study, we demonstrated that the macroscopic behavior of the model is predominantly governed by a single dimensionless parameter, the ratio between average wealth per capita and mean salary, denoted by R. The shape of the wealth distribution, the emergence of a two-class structure, and the level of inequality -- summarized by the Gini index -- were found to depend mainly on R, with inequality increasing as R increases. In the present work, we examine the robustness of this result by relaxing some simplifying assumptions of the model. We first allow transactions such as purchases, salary payments, and revenue collections to occur with different frequencies, reflecting the heterogeneous temporal dynamics of real economies. We then impose limits on the maximum fractions of wealth that agents can spend or collect at each step, constraining the amplitude of individual transactions. We find that the dependence of the inequality on R remains qualitatively robust, although the detailed distribution patterns are affected by relative frequencies and transaction limits. Finally, we analyze a further variant of the model with adaptive wages emerging endogenously from the dynamics, showing that self-organized labor-market feedback can either stabilize or amplify inequality depending on macroeconomic conditions."}
{"id": "2601.16157", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16157", "abs": "https://arxiv.org/abs/2601.16157", "authors": ["Sanjeev Kumar Verma"], "title": "A saturation bound for cumulative responses under local linear relaxation", "comment": "4 pages, no figures", "summary": "Saturation of cumulative observables is widely observed in systems with propagating or spreading signals and is commonly modeled using system-specific mechanisms such as scattering statistics, coherence functions, or phenomenological decay laws. This work shows that such saturation follows directly from linear local relaxation alone. Any linear observable accumulated over the lifetime of a relaxing signal is bounded by a scale set by the relaxation time, independent of geometry, dimensionality, or microscopic dynamics. When relaxation is mapped to space through transport or spreading, this temporal bound yields a corresponding spatial saturation scale. A closed-form expression reveals a two-regime behavior: linear growth at short times followed by saturation beyond the relaxation time. The result provides a minimal and unified explanation for cumulative saturation across transport, diffusive, and stochastic systems."}
{"id": "2601.15666", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.15666", "abs": "https://arxiv.org/abs/2601.15666", "authors": ["Uehara Keito", "Taichi Murayama"], "title": "Impression Zombies: Characteristics Analysis and Classification of New Harmful Accounts on Social Media", "comment": null, "summary": "``Impression Zombies'', a type of malicious account designed to artificially inflate engagement metrics, have recently emerged as a significant threat on X (formerly Twitter). These accounts disseminate a high volume of low-quality, irrelevant posts, which degrade the user experience. This study aims (1) to quantitatively characterize their behavioral patterns and (2) to develop a method for detecting such accounts. To address the first objective, we collected data from 9,909 accounts and compared the characteristics of Impression Zombies and general users within this dataset. We find that, Impression Zombies post more than three times the average total number of posts per day and tend to gather followers by using phrases such as ``follow back.'' Addressing the second objective, we constructed a classification model for Impression Zombies that leverages the contextual incoherence often observed between parent posts and the replies from Impression Zombies. Experimental results show that our model achieved approximately 92\\% accuracy in detecting Impression Zombies. This study provides the first quantitative insights into Impression Zombies and offers a practical framework for detecting such accounts, contributing to platform transparency and the health of social media ecosystems."}
{"id": "2601.15833", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.15833", "abs": "https://arxiv.org/abs/2601.15833", "authors": ["T. Haidamak", "G. Bastien", "P. Proschek", "A. Eliáš", "R. H. Colman", "D. Gorbunov", "S. Zherlitsyn", "A. A. Zvyagin", "G. A. Zvyagina", "J. Prokleška", "V. Sechovský", "M. Vališka"], "title": "Magnetoelastic coupling at the field-induced transition in EuAl$_{12}$O$_{19}$", "comment": null, "summary": "Magnetoelastic coupling plays a crucial role in magnetic-field-induced transitions in anisotropic ferromagnets. Ultrasonic methods are suitable for experimental investigations of these phenomena. We investigate elastic constants in EuAl$_{12}$O$_{19}$, a quasi-two-dimensional anisotropic ferromagnet, by measuring sound velocity in magnetic fields perpendicular to spontaneous magnetization. The shear modulus $C_{44}$ exhibits dramatic softening at the field-induced transition from the ferromagnetic to a paramagnetic phase with magnetic moments forced to polarize along the applied transverse field. The softening is attributed to strong magnetic fluctuations near a second-order phase transition. Theoretical calculations based on magnetization data qualitatively reproduced the observed behavior within a strain-exchange mechanism. These results demonstrate that magnetoelastic coupling in EuAl$_{12}$O$_{19}$ arises primarily from exchange striction and provide a framework for modeling similar transitions in other anisotropic ferromagnets."}
{"id": "2601.16166", "categories": ["hep-lat", "cond-mat.quant-gas", "nucl-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16166", "abs": "https://arxiv.org/abs/2601.16166", "authors": ["Jiahao Cao", "Rohan Joshi", "Yizhuo Tian", "N. S. Srivatsa", "Jad C. Halimeh"], "title": "String Breaking and Glueball Dynamics in $2+1$D Quantum Link Electrodynamics", "comment": "$21$ pages, $11$ figures, $2$ tables", "summary": "At the heart of quark confinement and hadronization, the physics of flux strings has recently become a focal point in the field of quantum simulation of high-energy physics (HEP). Despite considerable progress, a detailed understanding of the behavior of flux strings in quantum simulation-relevant lattice formulations of gauge theories has remained limited to the lowest truncations of the gauge field, which are severely limited in their ability to draw conclusions about the quantum field theory limit. Here, we employ tensor network simulations to investigate the behavior of flux strings in a quantum link formulation of $2+1$D quantum electrodynamics (QED) with a spin-$1$ representation of the gauge field. We first map out the ground-state phase diagram of this model in the presence of two spatially separated static charges, revealing distinct microscopic processes responsible for string breaking, including a two-stage breaking mechanism not possible in the spin-$\\frac{1}{2}$ formulation. Starting in different initial product state string configurations, we then explore far-from-equilibrium quench dynamics across various parameter regimes, demonstrating genuine $2+1$D real-time string breaking and glueball-like bound state formation, with the latter not possible in the spin-$\\frac{1}{2}$ formulation. In and out of equilibrium, we consider different values and placements of the static charges. Finally, we provide efficient qudit circuits for a quantum simulation experiment in which our results can be observed in state-of-the-art ion-trap setups. Our findings lay the groundwork for quantum simulations of flux strings towards the quantum field theory limit."}
{"id": "2601.15396", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.15396", "abs": "https://arxiv.org/abs/2601.15396", "authors": ["Andreas Bauer", "Seth Lloyd"], "title": "Quadratic tensors as a unification of Clifford, Gaussian, and free-fermion physics", "comment": null, "summary": "Certain families of quantum mechanical models can be described and solved efficiently on a classical computer, including qubit or qudit Clifford circuits and stabilizer codes, free-boson or free-fermion models, and certain rotor and GKP codes. We show that all of these families can be described as instances of the same algebraic structure, namely quadratic functions over abelian groups, or more generally over (super) Hopf algebras. Different kinds of degrees of freedom correspond to different \"elementary\" abelian groups or Hopf algebras: $\\mathbb{Z}_2$ for qubits, $\\mathbb{Z}_d$ for qudits, $\\mathbb{R}$ for continuous variables, both $\\mathbb{Z}$ and $\\mathbb{R}/\\mathbb{Z}$ for rotors, and a super Hopf algebra $\\mathcal F$ for fermionic modes. Objects such as states, operators, superoperators, or projection-operator valued measures, etc, are tensors. For the solvable models above, these tensors are quadratic tensors based on quadratic functions. Quadratic tensors with $n$ degrees of freedom are fully specified by only $O(n^2)$ coefficients. Tensor networks of quadratic tensors can be contracted efficiently on the level of these coefficients, using an operation reminiscent of the Schur complement. Our formalism naturally includes models with mixed degrees of freedom, such as qudits of different dimensions. We also use quadratic functions to define generalized stabilizer codes and Clifford gates for arbitrary abelian groups. Finally, we give a generalization from quadratic (or 2nd order) to $i$th order tensors, which are specified by $O(n^i)$ coefficients but cannot be contracted efficiently in general."}
{"id": "2601.08132", "categories": ["quant-ph", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.08132", "abs": "https://arxiv.org/abs/2601.08132", "authors": ["Thomas Barthel"], "title": "Cost scaling of MPS and TTNS simulations for 2D and 3D systems with area-law entanglement", "comment": "8.5 pages, 5 figures, 3 tables", "summary": "Tensor network states are an indispensable tool for the simulation of strongly correlated quantum many-body systems. In recent years, tree tensor network states (TTNS) have been successfully used for two-dimensional systems and to benchmark quantum simulation approaches for condensed matter, nuclear, and particle physics. In comparison to the more traditional approach based on matrix product states (MPS), the graph distance of physical degrees of freedom can be drastically reduced in TTNS. Surprisingly, it turns out that, for large systems in $D>1$ spatial dimensions, MPS simulations of low-energy states are nevertheless more efficient than TTNS simulations. With a focus on $D=2$ and 3, the scaling of computational costs for different boundary conditions is determined under the assumption that the system obeys an entanglement (log-)area law, implying that bond dimensions scale exponentially in the surface area of the associated subsystems."}
{"id": "2601.15816", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15816", "abs": "https://arxiv.org/abs/2601.15816", "authors": ["Shiqi Wei", "Qiqing Wang", "Kaidi Yang"], "title": "Virtual Traffic Police: Large Language Model-Augmented Traffic Signal Control for Unforeseen Incidents", "comment": null, "summary": "Adaptive traffic signal control (TSC) has demonstrated strong effectiveness in managing dynamic traffic flows. However, conventional methods often struggle when unforeseen traffic incidents occur (e.g., accidents and road maintenance), which typically require labor-intensive and inefficient manual interventions by traffic police officers. Large Language Models (LLMs) appear to be a promising solution thanks to their remarkable reasoning and generalization capabilities. Nevertheless, existing works often propose to replace existing TSC systems with LLM-based systems, which can be (i) unreliable due to the inherent hallucinations of LLMs and (ii) costly due to the need for system replacement. To address the issues of existing works, we propose a hierarchical framework that augments existing TSC systems with LLMs, whereby a virtual traffic police agent at the upper level dynamically fine-tunes selected parameters of signal controllers at the lower level in response to real-time traffic incidents. To enhance domain-specific reliability in response to unforeseen traffic incidents, we devise a self-refined traffic language retrieval system (TLRS), whereby retrieval-augmented generation is employed to draw knowledge from a tailored traffic language database that encompasses traffic conditions and controller operation principles. Moreover, we devise an LLM-based verifier to update the TLRS continuously over the reasoning process. Our results show that LLMs can serve as trustworthy virtual traffic police officers that can adapt conventional TSC methods to unforeseen traffic incidents with significantly improved operational efficiency and reliability."}
{"id": "2601.15880", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.15880", "abs": "https://arxiv.org/abs/2601.15880", "authors": ["Dennis Dobler", "Alina Schenk", "Matthias Schmid"], "title": "A two-sample pseudo-observation-based regression approach for the relative treatment effect", "comment": "22 pages, 6 figures, 6 tables", "summary": "The relative treatment effect is an effect measure for the order of two sample-specific outcome variables. It has the interpretation of a probability and also a connection to the area under the ROC curve. In the literature it has been considered for both ordinal or right-censored time-to-event outcomes. For both cases, the present paper introduces a distribution-free regression model that relates the relative treatment effect to a linear combination of covariates. To fit the model, we develop a pseudo-observation-based procedure yielding consistent and asymptotically normal coefficient estimates. In addition, we propose bootstrap-based hypothesis tests to infer the effects of the covariates on the relative treatment effect. A simulation study compares the novel method to Cox regression, demonstrating that the proposed hypothesis tests have high power and keep up with the z-test of the Cox model even in scenarios where the latter is specified correctly. The new methods are used to re-analyze data from the SUCCESS-A trial for progression-free survival of breast cancer patients."}
{"id": "2601.15944", "categories": ["physics.soc-ph", "cond-mat.dis-nn", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.15944", "abs": "https://arxiv.org/abs/2601.15944", "authors": ["Massimo Ostilli"], "title": "Partitioning networks into clusters of synchronized nodes via the message-passing algorithm: an unbiased scalable approach", "comment": "13 pages, 12 figures", "summary": "Partitioning large networks into stable clusters of synchronized nodes is a challenging task. Recent approaches based on spectral analysis can provide exact results on specific dynamics but remain unfeasible for very large networks. Moreover, within a stochastic framework, it is unclear which dynamics should be chosen to study synchronization. Here we propose an unbiased and scalable method based on the message-passing algorithm. By exploiting the collective behavior emerging across critical points of an effective Ising-like model, we identify dynamically coherent clusters of synchronized nodes and illustrate the approach on some large real-world networks. We find that, unlike continuous-time dynamics, abrupt desyncrhronization occurs even in simple graphs, without the need to invoke higher order interactions. However, when noise is included, the transition to synchronization becomes smoother and proceeds through the formation of plateaus, albeit at the cost of requiring larger coupling strengths."}
{"id": "2601.15816", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15816", "abs": "https://arxiv.org/abs/2601.15816", "authors": ["Shiqi Wei", "Qiqing Wang", "Kaidi Yang"], "title": "Virtual Traffic Police: Large Language Model-Augmented Traffic Signal Control for Unforeseen Incidents", "comment": null, "summary": "Adaptive traffic signal control (TSC) has demonstrated strong effectiveness in managing dynamic traffic flows. However, conventional methods often struggle when unforeseen traffic incidents occur (e.g., accidents and road maintenance), which typically require labor-intensive and inefficient manual interventions by traffic police officers. Large Language Models (LLMs) appear to be a promising solution thanks to their remarkable reasoning and generalization capabilities. Nevertheless, existing works often propose to replace existing TSC systems with LLM-based systems, which can be (i) unreliable due to the inherent hallucinations of LLMs and (ii) costly due to the need for system replacement. To address the issues of existing works, we propose a hierarchical framework that augments existing TSC systems with LLMs, whereby a virtual traffic police agent at the upper level dynamically fine-tunes selected parameters of signal controllers at the lower level in response to real-time traffic incidents. To enhance domain-specific reliability in response to unforeseen traffic incidents, we devise a self-refined traffic language retrieval system (TLRS), whereby retrieval-augmented generation is employed to draw knowledge from a tailored traffic language database that encompasses traffic conditions and controller operation principles. Moreover, we devise an LLM-based verifier to update the TLRS continuously over the reasoning process. Our results show that LLMs can serve as trustworthy virtual traffic police officers that can adapt conventional TSC methods to unforeseen traffic incidents with significantly improved operational efficiency and reliability."}
{"id": "2601.15763", "categories": ["cs.CE", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.15763", "abs": "https://arxiv.org/abs/2601.15763", "authors": ["Zheng Fang", "Chen Yang", "Hai-tao Yu", "Haoming Luo", "Haitao He", "Jiaqing Xie", "Zhuo Yang", "Jun Xia"], "title": "NMRGym: A Comprehensive Benchmark for Nuclear Magnetic Resonance Based Molecular Structure Elucidation", "comment": null, "summary": "Nuclear Magnetic Resonance (NMR) spectroscopy is the cornerstone of small-molecule structure elucidation. While deep learning has demonstrated significant potential in automating structure elucidation and spectral simulation, current progress is severely impeded by the reliance on synthetic datasets, which introduces significant domain shifts when applied to real-world experimental spectra. Furthermore, the lack of standardized evaluation protocols and rigorous data splitting strategies frequently leads to unfair comparisons and data leakage. To address these challenges, we introduce \\textbf{NMRGym}, the largest and most comprehensive standardized dataset and benchmark derived from high-quality experimental NMR data to date. Comprising \\textbf{269,999} unique molecules paired with high-fidelity $^1$H and $^{13}$C spectra, NMRGym bridges the critical gap between synthetic approximations and real-world diversity. We implement a strict quality control pipeline and unify data formats to ensure fair comparison. To strictly prevent data leakage, we enforce a scaffold-based split. Additionally, we provide fine-grained peak-atom level annotations to support future usage. Leveraging this resource, we establish a comprehensive evaluation suite covering diverse downstream tasks, including structure elucidation, functional group prediction from NMR, toxicity prediction from NMR, and spectral simulation, benchmarking representative state-of-the-art methodologies. Finally, we release an open-source leadboard with an automated leaderboard to foster community collaboration and standardize future research. The dataset, benchmark and leaderboard are publicly available at \\textcolor{blue}{https://AIMS-Lab-HKUSTGZ.github.io/NMRGym/}."}
{"id": "2601.16124", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.16124", "abs": "https://arxiv.org/abs/2601.16124", "authors": ["Guohui Song", "Congzhi Xia"], "title": "A hybrid reconstruction of piece-wise smooth functions from non-uniform Fourier data", "comment": null, "summary": "In this paper, we consider the problem of reconstructing piece-wise smooth functions from their non-uniform Fourier data. We first extend the filter method for uniform Fourier data to the non-uniform setting by using the techniques of admissible frames. We show that the proposed non-uniform filter method converges exponentially away from the jump discontinuities. However, the convergence rate is significantly slower near the jump discontinuities due to the Gibbs phenomenon. To overcome this issue, we combine the non-uniform filter method with a stable extrapolation method to recover the function values near the jump discontinuities. We show that the proposed hybrid method could achieve exponential accuracy uniformly on the entire domain. Numerical experiments are provided to demonstrate the performance of the proposed method."}
{"id": "2601.15531", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15531", "abs": "https://arxiv.org/abs/2601.15531", "authors": ["Felipe Atenas", "Minh N. Dao", "Matthew K. Tam"], "title": "Variable Stepsize Distributed Forward-Backward Splitting Methods as Relocated Fixed-Point Iterations", "comment": "31 pages", "summary": "We present a family of distributed forward-backward methods with variable stepsizes to find a solution of structured monotone inclusion problems. The framework is constructed by means of relocated fixed-point iterations, extending the approach introduced in arXiv:2507.07428 to conically averaged operators, thus including iteration operators for methods of forward-backward type devised by graphs. The family of methods we construct preserve the per-iteration computational cost and the convergence properties of their constant stepsize counterparts. Specifically, we show that the resulting methods generate a sequence that converges to a fixed-point of the underlying iteration operator, whose shadow sequences converge to a solution of the problem. Numerical experiments illustrate the behaviour of our framework in structured sparse optimisation problems."}
{"id": "2601.15880", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.15880", "abs": "https://arxiv.org/abs/2601.15880", "authors": ["Dennis Dobler", "Alina Schenk", "Matthias Schmid"], "title": "A two-sample pseudo-observation-based regression approach for the relative treatment effect", "comment": "22 pages, 6 figures, 6 tables", "summary": "The relative treatment effect is an effect measure for the order of two sample-specific outcome variables. It has the interpretation of a probability and also a connection to the area under the ROC curve. In the literature it has been considered for both ordinal or right-censored time-to-event outcomes. For both cases, the present paper introduces a distribution-free regression model that relates the relative treatment effect to a linear combination of covariates. To fit the model, we develop a pseudo-observation-based procedure yielding consistent and asymptotically normal coefficient estimates. In addition, we propose bootstrap-based hypothesis tests to infer the effects of the covariates on the relative treatment effect. A simulation study compares the novel method to Cox regression, demonstrating that the proposed hypothesis tests have high power and keep up with the z-test of the Cox model even in scenarios where the latter is specified correctly. The new methods are used to re-analyze data from the SUCCESS-A trial for progression-free survival of breast cancer patients."}
{"id": "2601.15944", "categories": ["physics.soc-ph", "cond-mat.dis-nn", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2601.15944", "abs": "https://arxiv.org/abs/2601.15944", "authors": ["Massimo Ostilli"], "title": "Partitioning networks into clusters of synchronized nodes via the message-passing algorithm: an unbiased scalable approach", "comment": "13 pages, 12 figures", "summary": "Partitioning large networks into stable clusters of synchronized nodes is a challenging task. Recent approaches based on spectral analysis can provide exact results on specific dynamics but remain unfeasible for very large networks. Moreover, within a stochastic framework, it is unclear which dynamics should be chosen to study synchronization. Here we propose an unbiased and scalable method based on the message-passing algorithm. By exploiting the collective behavior emerging across critical points of an effective Ising-like model, we identify dynamically coherent clusters of synchronized nodes and illustrate the approach on some large real-world networks. We find that, unlike continuous-time dynamics, abrupt desyncrhronization occurs even in simple graphs, without the need to invoke higher order interactions. However, when noise is included, the transition to synchronization becomes smoother and proceeds through the formation of plateaus, albeit at the cost of requiring larger coupling strengths."}
{"id": "2601.15377", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15377", "abs": "https://arxiv.org/abs/2601.15377", "authors": ["Laura Shou", "Jeet Shah", "Matthew Lerner-Brecher", "Amol Aggarwal", "Alexei Borodin", "Victor Galitski"], "title": "Exactly solvable topological phase transition in a quantum dimer model", "comment": "5+6 pages, 8+4 figures", "summary": "We introduce a family of generalized Rokhsar-Kivelson (RK) Hamiltonians, which are reverse-engineered to have an arbitrary edge-weighted superposition of dimer coverings as their exact ground state at the RK point. We then focus on a quantum dimer model on the triangular lattice, with doubly-periodic edge weights. For simplicity we consider a $2\\times1$ periodic model in which all weights are set to one except for a tunable horizontal edge weight labeled $α$. We analytically show that the model exhibits a continuous quantum phase transition at $α=3$, changing from a topological $\\mathbb{Z}_2$ quantum spin liquid ($α<3$) to a columnar ordered state ($α>3$). The dimer-dimer correlator decays exponentially on both sides of the transition with the correlation length $ξ\\propto1/|α-3|$ and as a power-law at criticality. The vison correlator exhibits an exponential decay in the spin liquid phase, but becomes a constant in the ordered phase. We explain the constant vison correlator in terms of loops statistics of the double-dimer model. Using finite-size scaling of the vison correlator, we extract critical exponents consistent with the 2D Ising universality class."}
{"id": "2601.15726", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.15726", "abs": "https://arxiv.org/abs/2601.15726", "authors": ["Poonam Sharma", "Suman Banerjee"], "title": "Profit Maximization for Viral Marketing in Online Social Networks using Two Phase Diffusion Approach", "comment": null, "summary": "Now-a-days, Online Social Networks (OSNs) are extensively used by different commercial houses for viral marketing. The key problem that arises in this context is to choose a limited number of highly influential users as the initial adopters of a brand such that the influence regarding the brand in the network gets maximized. Deviating from this standard setting, in this paper, we study the problem where every user of the network is associated with a selection cost and a benefit value. This benefit value can be earned from the user if (s)he is influenced by the brand. A fixed amount of budget is allocated for selecting the seed users. The goal of initial adopters is to choose a set of seed users within the budget such that the profit is maximized. We propose a two phase diffusion model for this problem where the goal is to split the diffusion process into two phases, and hence, split the budget into two halves. First, we spend the first half budget to select seed users for the first phase and observe the diffusion for a few rounds and then deploy the seed users for the second phase and successively complete the diffusion process. We prove several properties of the two phase influence function. Three solution approaches have been proposed for our problem with detailed analysis and illustrative examples. We conduct a number of experiments with three real-world social network datasets. From the experiments, we observe that the two phase diffusion approach leads to more amount of profit compared to the single-phase diffusion. In particular, for most instances, this improvement is greater than 18% and reaching as high as 40% by the proposed methodologies."}
{"id": "2601.16017", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2601.16017", "abs": "https://arxiv.org/abs/2601.16017", "authors": ["Samuel Vadnais", "Rémi Duchesne", "Kristjan Haule", "A. -M. S. Tremblay", "David Sénéchal", "Benjamin Bacq-Labreuil"], "title": "The role of the apical oxygen in cuprate high-temperature superconductors", "comment": "12 pages, 4 main figures, 3 End Matter figures, 1 supplementary figure", "summary": "Scanning tunneling microscopy measurements exploiting the natural superstructure modulation of the cuprate superconductor Bi$_2$Sr$_2$CaCu$_2$O$_{8+x}$ (Bi-2212) have revealed a possible correlation between the Cu-apical-O distance $δ_{\\mathrm{api}}$ and the superconducting order parameter $m_{\\mathrm{SC}}$, as reported recently by O'Mahony et al. (Proc. Natl. Acad. Sci. 119, e2207449119 (2022)). These observations were interpreted as evidence for a direct link between superconductivity and the charge-transfer gap, and more broadly revived the long-standing question of the role of apical oxygens in cuprate superconductivity. Using a combination of density-functional theory and cluster dynamical mean-field theory, we compute from first principles the variations of $m_{\\mathrm{SC}}$ induced solely by apical oxygen displacement in Bi$_2$Sr$_2$CuO$_{6+δ}$, Bi-2212, and HgBa$_2$CuO$_{4+δ}$. The quantitative agreement between our calculations and experiments allows us to unambiguously attribute the observed variations of $m_{\\mathrm{SC}}$ to changes in $δ_{\\mathrm{api}}$. We demonstrate, however, that these variations of $m_{\\mathrm{SC}}$ originate predominantly from changes in the effective hole-doping of the CuO$_2$ planes, with negligible effect on the charge-transfer gap. The modest magnitude of the $m_{\\mathrm{SC}}$ modulation induced by apical-oxygen displacement alone therefore warrants caution in interpreting correlations between $T_c$ and $δ_{\\mathrm{api}}$ inferred from comparisons across different cuprate compounds."}
{"id": "2601.15885", "categories": ["quant-ph", "hep-lat"], "pdf": "https://arxiv.org/pdf/2601.15885", "abs": "https://arxiv.org/abs/2601.15885", "authors": ["Chaitanya Gupta", "Anthony J. Short"], "title": "Fermion Doubling in Dirac Quantum Walks", "comment": "13 pages, 5 figures", "summary": "We consider discrete spacetime models known as quantum walks, which can be used to simulate Dirac particles. In particular we look at fermion doubling in these models, in which high momentum states yield additional low energy solutions which behave like Dirac particles. The presence of doublers carries over to the `second quantised' version of the walks represented by quantum cellular automata, which may lead to spurious solutions when introducing interactions. Moreover, we also consider pseudo-doublers, which have high energy but behave like low energy Dirac particles, and cause potential problems regarding the stability of the vacuum. To address these issues, we propose a family of quantum walks, that are free of these doublers and pseudo-doublers, but still simulate the Dirac equation in the continuum limit. However, there remain a small number of additional low energy solutions which do not directly correspond to Dirac particles. While the conventional Dirac walk always has a zero probability for the walker staying at the same point, we obtain the family of walks by allowing this probability to be non-zero."}
{"id": "2601.15439", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15439", "abs": "https://arxiv.org/abs/2601.15439", "authors": ["Wei-Yang Liu", "Hsuan-Wei Lee"], "title": "Dissipative Quantum Dynamics in Static Network with Different Topologies", "comment": "15 pages, 9 figures", "summary": "We investigate the dissipative dynamics of quantum population and coherence among different network topologies of a quantum network using a quantum spin model coupled to a thermal bosonic reservoir. Our study proceeds in two parts. First, we analyze a small network of Ising spins embedded in a large dissipative bath, modeled via the Lindblad master equation, where temperature arises naturally from system-bath coupling. This approach reveals how network topology shapes quantum dissipative dynamics, providing a basis for controlling quantum coherence through tailored network structures. Second, we propose a mean-field approach that extends the network to larger scales and captures dissipative dynamics in large-scale networks, connecting network topology to quantum coherence in complex systems and revealing the sensitivity of quantum coherence to network structure. Our results highlight how dissipative quantum dynamics depend on network topology, providing insight into the coherent dynamics of entangled states in networks. These results may be extended to dynamics in complex systems such as opinion propagation in social models, epidemiology, and various condensed-phase and biological systems."}
{"id": "2601.16014", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16014", "abs": "https://arxiv.org/abs/2601.16014", "authors": ["Eder Baron-Prada", "Adolfo Anta", "Florian Dörfler"], "title": "Stability Analysis of Power-Electronics-Dominated Grids Using Scaled Relative Graphs", "comment": "Submitted to possible publication", "summary": "This paper presents a novel approach to stability analysis for grid-connected converters utilizing Scaled Relative Graphs (SRG). Our method effectively decouples grid and converter dynamics, thereby establishing a comprehensive and efficient framework for evaluating closed-loop stability. Our analysis accommodates both linear and non-linear loads, enhancing its practical applicability. Furthermore, we demonstrate that our stability assessment remains unaffected by angular variations resulting from dq-frame transformations, significantly increasing the method's robustness and versatility. The effectiveness of our approach is validated in several simulation case studies, which illustrate its broad applicability in modern power systems."}
{"id": "2601.15896", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.15896", "abs": "https://arxiv.org/abs/2601.15896", "authors": ["Davide Benussi", "Ester Alongi", "Erika Banzato"], "title": "Leave-one-out testing for node-level differences in Gaussian graphical models", "comment": null, "summary": "We study two-sample equality testing in Gaussian graphical models. Classical likelihood ratio tests on decomposable graphs admit clique-wise factorizations, offering limited localization and unstable finite-sample behaviour. We propose node-level inference via a leave-one-out Bartlett-adjusted test on a fully connected graph. The resulting increments have standard chi-square null limits, enabling calibrated significance for single nodes and fixed-size subsets. Simulations confirm validity, and a case study shows practical utility."}
{"id": "2601.16180", "categories": ["quant-ph", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.16180", "abs": "https://arxiv.org/abs/2601.16180", "authors": ["Melody Lee", "Roland C. Farrell"], "title": "Studying energy-resolved transport with wavepacket dynamics on quantum computers", "comment": "21 pages, 11 figures, 4 tables", "summary": "Probing energy-dependent transport in quantum simulators requires preparing states with tunable energy and small energy variance. Existing approaches often study quench dynamics of simple initial states, such as computational basis states, which are far from energy eigenstates and therefore limit the achievable energy resolution. In this work, we propose using wavepackets to probe transport properties with improved energy resolution. To demonstrate the utility of this approach, we prepare and evolve wavepackets on Quantinuum's H2-2 quantum computer and identify an energy-dependent localization transition in the Anderson model on an 8x7 lattice--a finite-size mobility edge. We observe that a wavepacket initialized at low energy remains spatially localized under time evolution, while a high-energy wavepacket delocalizes, consistent with the presence of a mobility edge. Crucial to our experiments is an error mitigation strategy that infers the noiseless output bit string distribution using maximum-likelihood estimation. Compared to post-selection, this method removes systematic errors and reduces statistical uncertainty by up to a factor of 5. We extend our methods to the many-particle regime by developing a quantum algorithm for preparing quasiparticle wavepackets in a one-dimensional model of interacting fermions. This technique has modest quantum resource requirements, making wavepacket-based studies of transport in many-body systems a promising application for near-term quantum computers."}
{"id": "2601.16014", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16014", "abs": "https://arxiv.org/abs/2601.16014", "authors": ["Eder Baron-Prada", "Adolfo Anta", "Florian Dörfler"], "title": "Stability Analysis of Power-Electronics-Dominated Grids Using Scaled Relative Graphs", "comment": "Submitted to possible publication", "summary": "This paper presents a novel approach to stability analysis for grid-connected converters utilizing Scaled Relative Graphs (SRG). Our method effectively decouples grid and converter dynamics, thereby establishing a comprehensive and efficient framework for evaluating closed-loop stability. Our analysis accommodates both linear and non-linear loads, enhancing its practical applicability. Furthermore, we demonstrate that our stability assessment remains unaffected by angular variations resulting from dq-frame transformations, significantly increasing the method's robustness and versatility. The effectiveness of our approach is validated in several simulation case studies, which illustrate its broad applicability in modern power systems."}
{"id": "2601.15786", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.15786", "abs": "https://arxiv.org/abs/2601.15786", "authors": ["Zhenzhong Wang", "Yongjie Hou", "Chenggong Huang", "Yuxuan Du", "Dacheng Tao", "Min Jiang"], "title": "Endowing Molecular Language with Geometry Perception via Modality Compensation for High-Throughput Quantum Hamiltonian Prediction", "comment": null, "summary": "The quantum Hamiltonian is a fundamental property that governs a molecule's electronic structure and behavior, and its calculation and prediction are paramount in computational chemistry and materials science. Accurate prediction is highly reliant on extensive training data, including precise molecular geometries and the Hamiltonian matrices, which are expensive to acquire via either experimental or computational methods. Towards a fast yet accurate method for Hamiltonian prediction, we first introduce a geometry information-aware molecular language model to bypass the use of expensive molecular geometries by only using the readily available molecular language -- simplified molecular input line entry system (SMILES). Our method employs multimodal alignment to bridge the relationship between SMILES strings and their corresponding molecular geometries. Recognizing that the molecular language inherently lacks explicit geometric information, we propose a geometry modality compensation strategy to imbue molecular language representations with essential geometric features, thereby enabling accurate predictions using SMILES. In addition, given the high cost of acquiring Hamiltonian data, we devise a weakly supervised strategy to fine-tune the molecular language model, thus improving the data efficiency. Theoretically, we prove that the prediction generalization error without explicit molecular geometry can be bounded through our modality compensation scheme. Empirically, our method achieves superior computational efficiency, providing up to 100x speedup over conventional quantum mechanical methods while maintaining comparable prediction accuracy. We further demonstrate the practical case study of our approach in the screening of electrolyte formulations."}
{"id": "2601.15608", "categories": ["math.OC", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.15608", "abs": "https://arxiv.org/abs/2601.15608", "authors": ["Scott Powers", "Sivaramakrishnan Ramani", "Jacob Hahn", "Andrew J. Schaefer"], "title": "Lead distance under a pickoff limit in Major League Baseball: A sequential game model", "comment": "33 pages", "summary": "Major League Baseball (MLB) recently limited pitchers to three pickoff attempts, creating a cat-and-mouse game between pitcher and runner. Each failed attempt adds pressure on the pitcher to avoid using another, and the runner can intensify this pressure by extending their leadoff toward the next base. We model this dynamic as a two-player zero-sum sequential game in which the runner first chooses a lead distance, and then the pitcher chooses whether to attempt a pickoff. We establish optimality characterizations for the game and present variants of value iteration and policy iteration to solve the game. Using lead distance data, we estimate generalized linear mixed-effects models for pickoff and stolen base outcome probabilities given lead distance, context, and player skill. We compute the game-theoretic equilibria under the two-player model, as well as the optimal runner policy under a simplified one-player Markov decision process (MDP) model. In the one-player setting, our results establish an actionable rule of thumb: the Two-Foot Rule, which recommends that a runner increase their lead by two feet after each pickoff attempt."}
{"id": "2601.15996", "categories": ["math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.15996", "abs": "https://arxiv.org/abs/2601.15996", "authors": ["Mario Bravo", "Roberto Cominetti", "Jongmin Lee"], "title": "Minimax-optimal Halpern iterations for Lipschitz maps", "comment": null, "summary": "This paper investigates the minimax-optimality of Halpern fixed-point iterations for Lipschitz maps in general normed spaces. Starting from an a priori bound on the orbit of iterates, we derive non-asymptotic estimates for the fixed-point residuals. These bounds are tight, meaning that they are attained by a suitable Lipschitz map and an associated Halpern sequence. By minimizing these tight bounds we identify the minimax-optimal Halpern scheme. For contractions, the optimal iteration exhibits a transition from an initial Halpern phase to the classical Banach-Picard iteration and, as the Lipschitz constant approaches one, we recover the known convergence rate for nonexpansive maps. For expansive maps, the algorithm is purely Halpern with no Banach-Picard phase; moreover, on bounded domains, the residual estimates converge to the minimal displacement bound. Inspired by the minimax-optimal iteration, we design an adaptive scheme whose residuals are uniformly smaller than the minimax-optimal bounds, and can be significantly sharper in practice. Finally, we extend the analysis by introducing alternative bounds based on the distance to a fixed point, which allow us to handle mappings on unbounded domains; including the case of affine maps for which we also identify the minimax-optimal iteration."}
{"id": "2601.16181", "categories": ["physics.soc-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16181", "abs": "https://arxiv.org/abs/2601.16181", "authors": ["Renato Vieira dos Santos"], "title": "Engineering polarization: How contradictory stimulation systematically undermines political moderation", "comment": null, "summary": "Political moderation, a key attractor in democratic systems, proves highly fragile under realistic information conditions. We develop a stochastic model of opinion dynamics to analyze how noise and differential susceptibility reshape the political spectrum. Extending Marvel et al.'s deterministic framework, we incorporate stochastic media influence $ζ(t)$ and neuropolitically-grounded sensitivity differences ($σ_y > σ_x$). Analysis reveals the moderate population -- stable in deterministic models -- undergoes catastrophic collapse under stochastic forcing. This occurs through an effective deradicalization asymmetry ($u_{B}^{\\text{eff}} = u + σ_y^2/2 > u_{A}^{\\text{eff}}$) that drives conservatives to extinction, eliminating cross-cutting interactions that sustain moderates. The system exhibits a phase transition from multi-stable coexistence to liberal dominance, demonstrating how information flow architecture -- independent of content -- systematically dismantles the political center. Our findings reveal moderation as an emergent property highly vulnerable to stochastic perturbations in complex social systems."}
{"id": "2601.15439", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15439", "abs": "https://arxiv.org/abs/2601.15439", "authors": ["Wei-Yang Liu", "Hsuan-Wei Lee"], "title": "Dissipative Quantum Dynamics in Static Network with Different Topologies", "comment": "15 pages, 9 figures", "summary": "We investigate the dissipative dynamics of quantum population and coherence among different network topologies of a quantum network using a quantum spin model coupled to a thermal bosonic reservoir. Our study proceeds in two parts. First, we analyze a small network of Ising spins embedded in a large dissipative bath, modeled via the Lindblad master equation, where temperature arises naturally from system-bath coupling. This approach reveals how network topology shapes quantum dissipative dynamics, providing a basis for controlling quantum coherence through tailored network structures. Second, we propose a mean-field approach that extends the network to larger scales and captures dissipative dynamics in large-scale networks, connecting network topology to quantum coherence in complex systems and revealing the sensitivity of quantum coherence to network structure. Our results highlight how dissipative quantum dynamics depend on network topology, providing insight into the coherent dynamics of entangled states in networks. These results may be extended to dynamics in complex systems such as opinion propagation in social models, epidemiology, and various condensed-phase and biological systems."}
{"id": "2601.16040", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.16040", "abs": "https://arxiv.org/abs/2601.16040", "authors": ["Marie Neubrander", "Markus Reiter-Haas", "Ben Rochford", "Max Allamong", "Christopher Bail", "Sunshine Hillygus", "Alexander Volfovsky"], "title": "Can Platform Design Encourage Curiosity? Evidence from an Independent Social Media Experiment", "comment": null, "summary": "Social media platforms are often criticized for fostering antisocial behavior rather than prosocial behavior. Yet, testing interventions to encourage prosocial dispositions, such as open-mindedness, has been hindered by researchers' limited ability to manipulate platform features and isolate causal effects in commercial environments. We address this challenge through a randomized controlled trial with 2,282 U.S. adults conducted on a new research platform we developed that uses AI bots to replicate live social media dynamics while enabling controlled experimentation. Participants engaged in 15-minute discussions about energy and climate topics, with treatment groups exposed to curiosity priming either through modified on-platform social norms, interface affordances, or both. Results demonstrate that curiosity priming significantly increased question-asking behavior and textual measures of curiosity in user posts, while also reducing toxicity. Although interventions decreased generic engagement behaviors like liking and commenting, they had no significant negative impact on reported app enjoyment or time spent writing posts and replies. Leveraging experimental control over platform features, our findings suggest that platform designs prioritizing curiosity can promote prosocial behaviors among users without compromising user experience."}
{"id": "2601.16069", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.16069", "abs": "https://arxiv.org/abs/2601.16069", "authors": ["Yuhao Hong", "Shilin Hu", "Ziyue Shen", "Chao Deng", "Xiaodong Zhang", "Lei Wang", "Long Wei", "Qinghua Zhang", "Lingfei Wang", "Liang Si", "Yulin Gan", "Kai Chen", "Zhaoliang Liao"], "title": "Interface Spin-orbit Coupling Induced Room-temperature Ferromagnetic Insulator", "comment": "Accepted by Physical Review Letters", "summary": "To achieve room-temperature ferromagnetic insulators, which are crucial candidates for next-generation dissipation-free quantum and spintronic devices, remains a significant challenge. In this study, we report the epitaxial synthesis of novel room-temperature ferromagnetic insulating thin films, achieved through the precise construction of (111)-oriented 3d/5d interfaces. Our analysis indicates that, unlike conventional doping methods, the (111)-oriented SrIrO3/La2/3Sr1/3MnO3 (SIO/LSMO) interfaces exhibit markedly enhanced spin-orbit coupling (SOC). This enhanced interfacial SOC strengthens the electron-phonon coupling in LSMO, thereby shortening the electronic mean free path. As a result, the intrinsic metallicity of LSMO is suppressed, giving rise to a new FMI phase that emerges between the ferromagnetic metal and paramagnetic insulator regimes of the LSMO phase diagram. Furthermore, the temperature window of the FMI state can be tuned by precisely controlling the thickness of the LSMO layers. Our study reveals a new strategy for developing ferromagnetic insulators by engineering 3d/5d interfaces and orientations, paving a way for the development of novel dissipation-free quantum and spintronic devices."}
{"id": "2601.15446", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15446", "abs": "https://arxiv.org/abs/2601.15446", "authors": ["Lily Wang", "Andy Zeyi Liu", "Ray Li", "Aleksander Kubica", "Shouzhen Gu"], "title": "Check-weight-constrained quantum codes: Bounds and examples", "comment": "29 pages, 13 figures", "summary": "Quantum low-density parity-check (qLDPC) codes can be implemented by measuring only low-weight checks, making them compatible with noisy quantum hardware and central to the quest to build noise-resilient quantum computers. A fundamental open question is how constraints on check weight limit the achievable parameters of qLDPC codes. Here, we study stabilizer and subsystem codes with constrained check weight, combining analytical arguments with numerical optimization to establish strong upper bounds on their parameters. We show that stabilizer codes with checks of weight at most three cannot have nontrivial distance. We also prove tight tradeoffs between rate and distance for broad families of CSS stabilizer and subsystem codes with checks of weight at most four and two, respectively. Notably, our bounds are applicable to general qLDPC codes, as they rely only on check-weight constraints without assuming geometric locality or special graph connectivity. In the finite-size regime, we derive numerical upper bounds using linear programming techniques and identify explicit code constructions that approach these limits, delineating the landscape of practically relevant qLDPC codes with tens or hundreds of physical qubits."}
{"id": "2601.16061", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16061", "abs": "https://arxiv.org/abs/2601.16061", "authors": ["John Bannan", "Nazia Rahman", "Chang-Hee Won"], "title": "Dynamic Tactile Sensing System and Soft Actor Critic Reinforcement Learning for Inclusion Characterization", "comment": null, "summary": "This paper presents the Dynamic Tactile Sensing System that utilizes robotic tactile sensing in conjunction with reinforcement learning to locate and characterize embedded inclusions. A dual arm robot is integrated with an optical Tactile Imaging Sensor that utilizes the Soft Actor Critic Algorithm to acquire tactile data based on a pixel intensity reward. A Dynamic Interrogation procedure for tactile exploration is developed that enables the robot to first localize inclusion and refine their positions for precise imaging. Experimental validation conducted on Polydimethylsiloxane phantoms demonstrates that the robot using the Tactile Soft Actor Critic Model was able to achieve size estimation errors of 2.61% and 5.29% for soft and hard inclusions compared to 7.84% and 6.87% for expert human operators. Results also show that Dynamic Tactile Sensing System was able to locate embedded inclusions and autonomously determine their mechanical properties, useful in applications such as breast tumor characterization."}
{"id": "2601.15942", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.15942", "abs": "https://arxiv.org/abs/2601.15942", "authors": ["Xinyu Jia", "Iason Papaioannou", "Daniel Straub"], "title": "A Hierarchical Bayesian Framework for Model-based Prognostics", "comment": null, "summary": "In prognostics and health management (PHM) of engineered systems, maintenance decisions are ideally informed by predictions of a system's remaining useful life (RUL) based on operational data. Model-based prognostics algorithms rely on a parametric model of the system degradation process. The model parameters are learned from real-time operational data collected on the system. However, there can be valuable information in data from similar systems or components, which is not typically utilized in PHM. In this contribution, we propose a hierarchical Bayesian modeling (HBM) framework for PHM that integrates both operational data and run-to-failure data from similar systems or components. The HBM framework utilizes hyperparameter distributions learned from data of similar systems or components as priors. It enables efficient updates of predictions as more information becomes available, allowing for increasingly accurate assessments of the degradation process and its associated variability. The effectiveness of the proposed framework is demonstrated through two experimental applications involving real-world data from crack growth and lithium battery degradation. Results show significant improvements in RUL prediction accuracy and demonstrate how the framework facilitates uncertainty management through predictive distributions."}
{"id": "2601.16061", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16061", "abs": "https://arxiv.org/abs/2601.16061", "authors": ["John Bannan", "Nazia Rahman", "Chang-Hee Won"], "title": "Dynamic Tactile Sensing System and Soft Actor Critic Reinforcement Learning for Inclusion Characterization", "comment": null, "summary": "This paper presents the Dynamic Tactile Sensing System that utilizes robotic tactile sensing in conjunction with reinforcement learning to locate and characterize embedded inclusions. A dual arm robot is integrated with an optical Tactile Imaging Sensor that utilizes the Soft Actor Critic Algorithm to acquire tactile data based on a pixel intensity reward. A Dynamic Interrogation procedure for tactile exploration is developed that enables the robot to first localize inclusion and refine their positions for precise imaging. Experimental validation conducted on Polydimethylsiloxane phantoms demonstrates that the robot using the Tactile Soft Actor Critic Model was able to achieve size estimation errors of 2.61% and 5.29% for soft and hard inclusions compared to 7.84% and 6.87% for expert human operators. Results also show that Dynamic Tactile Sensing System was able to locate embedded inclusions and autonomously determine their mechanical properties, useful in applications such as breast tumor characterization."}
{"id": "2601.15684", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15684", "abs": "https://arxiv.org/abs/2601.15684", "authors": ["Xin Chen", "Chunfeng Cui", "Deren Han", "Liqun Qi"], "title": "Parallelizable Riemannian Alternating Direction Method of Multipliers for Non-convex Pose Graph Optimization", "comment": null, "summary": "Pose graph optimization (PGO) is fundamental to robot perception and navigation systems, serving as the mathematical backbone for solving simultaneous localization and mapping (SLAM). Existing solvers suffer from polynomial growth in computational complexity with graph size, hindering real-time deployment in large-scale scenarios. In this paper, by duplicating variables and introducing equality constraints, we reformulate the problem and propose a Parallelizable Riemannian Alternating Direction Method of Multipliers (PRADMM) to solve it efficiently. Compared with the state-of-the-art methods that usually exhibit polynomial time complexity growth with graph size, PRADMM enables efficient parallel computation across vertices regardless of graph size. Crucially, all subproblems admit closed-form solutions, ensuring PRADMM maintains exceptionally stable performance. Furthermore, by carefully exploiting the structures of the coefficient matrices in the constraints, we establish the global convergence of PRADMM under mild conditions, enabling larger relaxation step sizes within the interval $(0,2)$. Extensive empirical validation on two synthetic datasets and multiple real-world 3D SLAM benchmarks confirms the superior computational performance of PRADMM."}
{"id": "2601.16095", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.16095", "abs": "https://arxiv.org/abs/2601.16095", "authors": ["Eduardo García-Portugués"], "title": "On the spherical cardioid distribution and its goodness-of-fit", "comment": "53 pages, 7 figures, 2 tables", "summary": "In this paper, we study the spherical cardioid distribution, a higher-dimensional and higher-order generalization of the circular cardioid distribution. This distribution is rotationally symmetric and generates unimodal, multimodal, axial, and girdle-like densities. We show several characteristics of the spherical cardioid that make it highly tractable: simple density evaluation, closedness under convolution, explicit expressions for vectorized moments, and efficient simulation. The moments of the spherical cardioid up to a given order coincide with those of the uniform distribution on the sphere, highlighting its closeness to the latter. We derive estimators by the method of moments and maximum likelihood, their asymptotic distributions, and their asymptotic relative efficiencies. We give the machinery for a bootstrap goodness-of-fit test based on the projected-ecdf approach, including the projected distribution and closed-form expressions for test statistics. An application to modeling the orbits of long-period comets shows the usefulness of the spherical cardioid distribution in real data analyses."}
{"id": "2601.15635", "categories": ["cs.SI", "physics.soc-ph", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.15635", "abs": "https://arxiv.org/abs/2601.15635", "authors": ["Theodore Y. Faust", "Arash A. Amini", "Mason A. Porter"], "title": "Community-Size Biases in Statistical Inference of Communities in Temporal Networks", "comment": "45 pages, 11 figures", "summary": "In the study of time-dependent (i.e., temporal) networks, researchers often examine the evolution of communities, which are sets of densely connected sets of nodes that are connected sparsely to other nodes. An increasingly prominent approach to studying community structure in temporal networks is statistical inference. In the present paper, we study the performance of a class of statistical-inference methods for community detection in temporal networks. We represent temporal networks as multilayer networks, with each layer encoding a time step, and we illustrate that statistical-inference models that generate community assignments via either a uniform distribution on community assignments or discrete-time Markov processes are biased against generating communities with large or small numbers of nodes. In particular, we demonstrate that statistical-inference methods that use such generative models tend to poorly identify community structure in networks with large or small communities. To rectify this issue, we introduce a novel statistical model that generates the community assignments of the nodes in given layer (i.e., at a given time) using all of the community assignments in the previous layer. We prove results that guarantee that our approach greatly mitigates the bias against large and small communities, so using our generative model is beneficial for studying community structure in networks with large or small communities. Our code is available at https://github.com/tfaust0196/TemporalCommunityComparison."}
{"id": "2601.15536", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th", "nlin.CD", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2601.15536", "abs": "https://arxiv.org/abs/2601.15536", "authors": ["Amit Vikram", "Edwin Chaparro", "Muhammad Miskeen Khan", "Andrew Lucas", "Chris Akers", "Ana Maria Rey"], "title": "Bidirectional teleportation using scrambling dynamics: a practical protocol", "comment": "9+26 pages, 4+7 figures", "summary": "We show that quantum information scrambling can enable a generic SWAP gate between collective degrees of freedom in systems without universal local control. Our protocol combines the Hayden-Preskill recovery scheme, associated with the black hole information paradox, with quantum teleportation and runs them in parallel and in opposite directions, enabling bidirectional exchange of quantum states through global interactions alone. This approach cleanly distinguishes the roles of information spreading, entanglement, and chaos for enabling both coherent state transfer and recovery. We propose an experimental realization using the Dicke model, which can be realized in cavity-QED and trapped-ion platforms, highlighting the utility of holography in designing practical quantum gates."}
{"id": "2601.16153", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.16153", "abs": "https://arxiv.org/abs/2601.16153", "authors": ["Olivier Simard", "Michel Ferrero", "Thomas Ayral"], "title": "Charge and spin orders in the t-U-V-J model: a slave-spin-1 approach", "comment": "23 pages, 17 figures", "summary": "Strongly-correlated fermion systems on a lattice have been a subject of intense focus in the field of condensed-matter physics. These systems are notoriously difficult to solve, even with state-of-the-art numerical methods, especially in regimes of parameters where degrees of freedom compete or cooperate at similar energy and length scales. Here, we introduce a spin-1 slave-particle technique to approximately treat the t-U-V-J fermionic model at arbitrary electron dopings in an economical manner. This formalism respectively maps the original charge and spin degrees of freedom into effective pseudo-spin and pseudo-fermion sectors, which are treated using a self-consistent cluster mean-field method. We study the phase diagram of the model under various conditions and report the appearance of charge and spin stripes within this formalism. These stripes are a consequence of the cluster mean-field treatment of the pseudo-particle sectors and have not been detected in previous slave-particle studies. The results obtained agree qualitatively well with what more reliable numerical methods capture."}
{"id": "2601.15521", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15521", "abs": "https://arxiv.org/abs/2601.15521", "authors": ["Ang Li"], "title": "NWQWorkflow: The Northwest Quantum Workflow", "comment": "This whitepaper reflects the author's own perspectives on the NWQ software ecosystem and does not represent an official position of PNNL, UW, or the U.S. Department of Energy", "summary": "This whitepaper presents NWQWorkflow, an end-to-end workflow for quantum application development, compilation, error correction, benchmarking, numerical simulation, control, and execution on a prototype superconducting testbed. NWQWorkflow integrates NWQStudio (programming GUI environment), NWQASM (intermediate representation), QASMTrans (compiler), NWQEC (quantum error correction), QASMBench (benchmarking and characterization), NWQSim (HPC simulation), NWQLib (algorithm library), NWQData (data sets), NWQControl (quantum control), and NWQSC (superconducting testbed). The system enables closed-loop software-hardware co-design and reflects the past eight years of quantum computing research the author has led at PNNL (2018-2026). By releasing most software components as open source or planning their open-source availability, we aim to cultivate a collaborative quantum information science (QIS) ecosystem and support the transition toward a scalable quantum supercomputing era."}
{"id": "2601.16149", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.16149", "abs": "https://arxiv.org/abs/2601.16149", "authors": ["Zirui Niu", "Giordano Scarciotti", "Alessandro Astolfi"], "title": "Interconnection-based Model Reduction for Linear Hybrid Systems", "comment": "17 pages", "summary": "In this paper, we address the model reduction problem for linear hybrid systems via the interconnection-based technique called moment matching. We consider two classical interconnections, namely the direct and swapped interconnections, in the hybrid setting, and we present families of reduced-order models for each interconnection via a hybrid characterisation of the steady-state responses. By combining the results for each interconnection, the design of a reduced-order model that achieves moment matching simultaneously for both interconnections is studied. In addition, we show that the presented results have simplified counterparts when the jumps of the hybrid system are periodic. A numerical simulation is finally given to illustrate the results."}
{"id": "2601.16022", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.16022", "abs": "https://arxiv.org/abs/2601.16022", "authors": ["Samuel I. Watson", "Yixin Wang", "Emanuele Giorgi"], "title": "A Fast Monte Carlo Newton-Raphson Algorithm to Estimate Generalized Linear Mixed Models with Dense Covariance", "comment": null, "summary": "Estimation of Generalised linear mixed models (GLMM) including spatial Gaussian process models is often considered computationally impractical for even moderately sized datasets. In this article, we propose a fast Monte Carlo maximum likelihood (MCML) algorithm for the estimation of GLMMs. The algorithm is a stochastic Newton-Raphson method, which approximates the expected Hessian and gradient of the log-likelihood by drawing samples of the random effects. We propose a new stopping criterion for efficient termination and preventing long runs of sampling in the stationary post-convergence phase of the algorithm and discuss Monte Carlo sample size choice. We run a series of simulation comparisons of spatial statistical models alongside the popular integrated nested Laplacian approximation method and demonstrate potential for similar or improved estimator performance and reduced running times. We also consider scaling of the algorithms to large datasets and demonstrate a greater than 100-fold reduction in running times using modern GPU hardware to illustrate the feasibility of full maximum likelihood methods with big spatial datasets."}
{"id": "2601.16149", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.16149", "abs": "https://arxiv.org/abs/2601.16149", "authors": ["Zirui Niu", "Giordano Scarciotti", "Alessandro Astolfi"], "title": "Interconnection-based Model Reduction for Linear Hybrid Systems", "comment": "17 pages", "summary": "In this paper, we address the model reduction problem for linear hybrid systems via the interconnection-based technique called moment matching. We consider two classical interconnections, namely the direct and swapped interconnections, in the hybrid setting, and we present families of reduced-order models for each interconnection via a hybrid characterisation of the steady-state responses. By combining the results for each interconnection, the design of a reduced-order model that achieves moment matching simultaneously for both interconnections is studied. In addition, we show that the presented results have simplified counterparts when the jumps of the hybrid system are periodic. A numerical simulation is finally given to illustrate the results."}
{"id": "2601.15742", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15742", "abs": "https://arxiv.org/abs/2601.15742", "authors": ["Ruoyu Diao", "Yu-Hong Dai", "Liwei Zhang"], "title": "A sequential linear complementarity problem method for generalized Nash equilibrium problems", "comment": "38 pages, 5 figures", "summary": "We propose a sequential linear complementarity problem (SLCP) method for solving generalized Nash equilibrium problems (GNEPs). By introducing a novel merit function that utilizes the specific structure of GNEPs, we establish global convergence of the method. The conditions guaranteeing global convergence are analogous to those for the classical sequential quadratic programming method with exact Lagrange Hessians, making this a natural and reasonable generalization. Moreover, we provide a detailed analysis of the solvability of the mixed linear complementarity subproblems, which are formulated as affine GNEPs. Sufficient characterizations for the local superlinear convergence are also derived, highlighting the efficiency of the proposed method. Finally, numerical experiments demonstrate the practical performance and effectiveness of the SLCP method in comparison with existing approaches."}
{"id": "2601.16086", "categories": ["cond-mat.stat-mech", "nlin.AO", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.16086", "abs": "https://arxiv.org/abs/2601.16086", "authors": ["Diego Febbe", "Duccio Fanelli", "Timoteo Carletti"], "title": "Random Walks Across Dimensions: Exploring Simplicial Complexes", "comment": null, "summary": "We introduce a novel operator to describe a random walk process on a simplicial complex. Walkers are allowed to wonder across simplices of various dimensions, bridging nodes to edges, and edges to triangles, via a nested organization that hierarchically extends to higher structures of arbitrary large, but finite, dimension. The asymptotic distribution of the walkers provides a natural ranking to gauge the relative importance of higher order simplices. Optimal search strategies in presence of stochastic teleportation are addressed and the peculiar interplay of noise with higher order structures unraveled."}
{"id": "2601.15941", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15941", "abs": "https://arxiv.org/abs/2601.15941", "authors": ["Vishnu Muraleedharan Sajitha", "Matthew J. Davis", "L. A. Williamson"], "title": "Frictional work and entropy production in integrable and non-integrable spin chains", "comment": null, "summary": "The maximum work extractable from a quantum system is achieved when the system is driven adiabatically. Frictional work then quantifies the difference in work output between adiabatic and non-adiabatic driving. Here we show that frictional work in a non-integrable spin chain is well-described by the diagonal entropy production associated with the build up of quantum coherence. The relationship is characterized by an effective temperature of the final adiabatic state and holds for slow to moderate driving protocols. For fast protocols, the frictional work is instead described by the quantum relative entropy between the final non-adiabatic and adiabatic states. We compare our results to those obtained from an integrable spin chain, in which case the adiabatic state is no longer described by a single temperature. In this case, the frictional work is described by a sum of terms for each independent subspace of the spin chain, which are at different effective temperatures. We show how integrability breaking can enhance work extraction in the adiabatic limit, but degrade work extraction in sufficiently non-adiabatic regimes."}
{"id": "2601.08132", "categories": ["quant-ph", "cond-mat.str-el", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.08132", "abs": "https://arxiv.org/abs/2601.08132", "authors": ["Thomas Barthel"], "title": "Cost scaling of MPS and TTNS simulations for 2D and 3D systems with area-law entanglement", "comment": "8.5 pages, 5 figures, 3 tables", "summary": "Tensor network states are an indispensable tool for the simulation of strongly correlated quantum many-body systems. In recent years, tree tensor network states (TTNS) have been successfully used for two-dimensional systems and to benchmark quantum simulation approaches for condensed matter, nuclear, and particle physics. In comparison to the more traditional approach based on matrix product states (MPS), the graph distance of physical degrees of freedom can be drastically reduced in TTNS. Surprisingly, it turns out that, for large systems in $D>1$ spatial dimensions, MPS simulations of low-energy states are nevertheless more efficient than TTNS simulations. With a focus on $D=2$ and 3, the scaling of computational costs for different boundary conditions is determined under the assumption that the system obeys an entanglement (log-)area law, implying that bond dimensions scale exponentially in the surface area of the associated subsystems."}
{"id": "2601.15523", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15523", "abs": "https://arxiv.org/abs/2601.15523", "authors": ["Tyler Kharazi", "Ahmad M. Alkadri", "Kranthi K. Mandadapu", "K. Birgitta Whaley"], "title": "A Sublinear-Time Quantum Algorithm for High-Dimensional Reaction Rates", "comment": "57 pages, 9 figures", "summary": "The Fokker-Planck equation models rare events across sciences, but its high-dimensional nature challenges classical computers. Quantum algorithms for such non-unitary dynamics often suffer from exponential {decay in} success probability. We introduce a quantum algorithm that overcomes this for computing reaction rates. Using a sum-of-squares representation, we develop a Gaussian linear combination of Hamiltonian simulations (Gaussian-LCHS) to represent the non-unitary propagator with $O\\left(\\sqrt{t\\|H\\|\\log(1/ε)}\\right)$ queries to its block encoding. Crucially, we pair this with {a} novel technique to directly estimate matrix elements without exponential decay. For $η$ pairwise interacting particles discretized with $N$ plane waves per degree of freedom, we estimate reactive flux to error $ε$ using $\\widetilde{O}\\left((η^{5/2}\\sqrt{tβ}α_V + η^{3/2}\\sqrt{t/β}N)/ε\\right)$ quantum gates, where $α_V = \\max_{r}|V'(r)/r|$. For non-convex potentials, the {sharpest classical} worst-case analytical bounds to simulate the related overdamped Langevin {equation} scale as $O(te^{Ω(η)}/ε^4)$. This {implies} an exponential separation in particle number $η$, a quartic speedup in $ε$, and quadratic speedup in $t$. While specialized classical heuristics may outperform these bounds in practice, this demonstrates a rigorous route toward quantum advantage for high-dimensional dissipative dynamics."}
{"id": "2601.16198", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16198", "abs": "https://arxiv.org/abs/2601.16198", "authors": ["Ruoyu Lin", "Magnus Egerstedt"], "title": "Stochastic Control Barrier Functions under State Estimation: From Euclidean Space to Lie Groups", "comment": null, "summary": "Ensuring safety for autonomous systems under uncertainty remains challenging, particularly when safety of the true state is required despite the true state not being fully known. Control barrier functions (CBFs) have become widely adopted as safety filters. However, standard CBF formulations do not explicitly account for state estimation uncertainty and its propagation, especially for stochastic systems evolving on manifolds. In this paper, we propose a safety-critical control framework with a provable bound on the finite-time safety probability for stochastic systems under noisy state information. The proposed framework explicitly incorporates the uncertainty arising from both process and measurement noise, and synthesizes controllers that adapt to the level of uncertainty. The framework admits closed-form solutions in linear settings, and experimental results demonstrate its effectiveness on systems whose state spaces range from Euclidean space to Lie groups."}
{"id": "2601.16095", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.16095", "abs": "https://arxiv.org/abs/2601.16095", "authors": ["Eduardo García-Portugués"], "title": "On the spherical cardioid distribution and its goodness-of-fit", "comment": "53 pages, 7 figures, 2 tables", "summary": "In this paper, we study the spherical cardioid distribution, a higher-dimensional and higher-order generalization of the circular cardioid distribution. This distribution is rotationally symmetric and generates unimodal, multimodal, axial, and girdle-like densities. We show several characteristics of the spherical cardioid that make it highly tractable: simple density evaluation, closedness under convolution, explicit expressions for vectorized moments, and efficient simulation. The moments of the spherical cardioid up to a given order coincide with those of the uniform distribution on the sphere, highlighting its closeness to the latter. We derive estimators by the method of moments and maximum likelihood, their asymptotic distributions, and their asymptotic relative efficiencies. We give the machinery for a bootstrap goodness-of-fit test based on the projected-ecdf approach, including the projected distribution and closed-form expressions for test statistics. An application to modeling the orbits of long-period comets shows the usefulness of the spherical cardioid distribution in real data analyses."}
{"id": "2601.16198", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16198", "abs": "https://arxiv.org/abs/2601.16198", "authors": ["Ruoyu Lin", "Magnus Egerstedt"], "title": "Stochastic Control Barrier Functions under State Estimation: From Euclidean Space to Lie Groups", "comment": null, "summary": "Ensuring safety for autonomous systems under uncertainty remains challenging, particularly when safety of the true state is required despite the true state not being fully known. Control barrier functions (CBFs) have become widely adopted as safety filters. However, standard CBF formulations do not explicitly account for state estimation uncertainty and its propagation, especially for stochastic systems evolving on manifolds. In this paper, we propose a safety-critical control framework with a provable bound on the finite-time safety probability for stochastic systems under noisy state information. The proposed framework explicitly incorporates the uncertainty arising from both process and measurement noise, and synthesizes controllers that adapt to the level of uncertainty. The framework admits closed-form solutions in linear settings, and experimental results demonstrate its effectiveness on systems whose state spaces range from Euclidean space to Lie groups."}
{"id": "2601.15789", "categories": ["math.OC", "math.SP"], "pdf": "https://arxiv.org/pdf/2601.15789", "abs": "https://arxiv.org/abs/2601.15789", "authors": ["Antonio Sasaki", "Sophie Demassey", "Valentina Sessa"], "title": "Localization of complementarity eigenvalues", "comment": null, "summary": "Let A, B be symmetric n x n real matrices with B positive definite and strictly diagonally dominant. We derive two localization sets for the complementarity eigenvalues of (A, B), the tightest one assuming additionally that A is copositive. This extends He-Liu-Shen sets to the case where B is not the identity. Moreover, we compare the computable bounds obtained from these new sets with the extreme classical generalized eigenvalues."}
{"id": "2601.15972", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15972", "abs": "https://arxiv.org/abs/2601.15972", "authors": ["Takuya Hatomura"], "title": "Universal Digitized Counterdiabatic Driving", "comment": null, "summary": "Counterdiabatic driving realizes parameter displacement of an energy eigenstate of a given parametrized Hamiltonian using the adiabatic gauge potential. In this paper, we propose a universal method of digitized counterdiabatic driving, constructing the adiabatic gauge potential in a digital way with the idea of universal counterdiabatic driving. This method has three advantages over existing universal counterdiabatic driving and/or digitized counterdiabatic driving: it does not introduce any many-body and/or nonlocal interactions to an original target Hamiltonian; it can incorporate infinite nested commutators, which constitute the adiabatic gauge potential; and it gives explicit expression of rotation angles for digital implementation. We show the consistency of our method to the exact theory in an analytical way and the effectiveness of our method with the aid of numerical simulations."}
{"id": "2601.15536", "categories": ["quant-ph", "cond-mat.stat-mech", "hep-th", "nlin.CD", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2601.15536", "abs": "https://arxiv.org/abs/2601.15536", "authors": ["Amit Vikram", "Edwin Chaparro", "Muhammad Miskeen Khan", "Andrew Lucas", "Chris Akers", "Ana Maria Rey"], "title": "Bidirectional teleportation using scrambling dynamics: a practical protocol", "comment": "9+26 pages, 4+7 figures", "summary": "We show that quantum information scrambling can enable a generic SWAP gate between collective degrees of freedom in systems without universal local control. Our protocol combines the Hayden-Preskill recovery scheme, associated with the black hole information paradox, with quantum teleportation and runs them in parallel and in opposite directions, enabling bidirectional exchange of quantum states through global interactions alone. This approach cleanly distinguishes the roles of information spreading, entanglement, and chaos for enabling both coherent state transfer and recovery. We propose an experimental realization using the Dicke model, which can be realized in cavity-QED and trapped-ion platforms, highlighting the utility of holography in designing practical quantum gates."}
{"id": "2601.16003", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16003", "abs": "https://arxiv.org/abs/2601.16003", "authors": ["Yunan Wang", "Chuxiong Hu", "Zhao Jin"], "title": "Time-Optimal Switching Surfaces for Triple Integrator under Full Box Constraints", "comment": "Accepted by ACC 2026", "summary": "Time-optimal control for triple integrator under full box constraints is a fundamental problem in the field of optimal control, which has been widely applied in the industry. However, scenarios involving asymmetric constraints, non-stationary boundary conditions, and active position constraints pose significant challenges. This paper provides a complete characterization of time-optimal switching surfaces for the problem, leading to novel insights into the geometric and algebraic structure of the optimal control. The active condition of position constraints is derived, which is absent from the literature. An efficient algorithm is proposed, capable of planning time-optimal trajectories under asymmetric full constraints and arbitrary boundary states, with a 100% success rate. Computational time for each trajectory is within approximately 10μs, achieving a 5-order-of-magnitude reduction compared to optimization-based baselines."}
{"id": "2601.16196", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.16196", "abs": "https://arxiv.org/abs/2601.16196", "authors": ["Wanting Jin", "Guorong Wu", "Quefeng Li"], "title": "Inference on the Significance of Modalities in Multimodal Generalized Linear Models", "comment": null, "summary": "Despite the popular of multimodal statistical models, there lacks rigorous statistical inference tools for inferring the significance of a single modality within a multimodal model, especially in high-dimensional models. For high-dimensional multimodal generalized linear models, we propose a novel entropy-based metric, called the expected relative entropy, to quantify the information gain of one modality in addition to all other modalities in the model. We propose a deviance-based statistic to estimate the expected relative entropy, prove that it is consistent and its asymptotic distribution can be approximated by a non-central chi-squared distribution. That enables the calculation of confidence intervals and p-values to assess the significance of the expected relative entropy for a given modality. We numerically evaluate the empirical performance of our proposed inference tool by simulations and apply it to a multimodal neuroimaging dataset to demonstrate its good performance on various high-dimensional multimodal generalized linear models."}
{"id": "2601.16003", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16003", "abs": "https://arxiv.org/abs/2601.16003", "authors": ["Yunan Wang", "Chuxiong Hu", "Zhao Jin"], "title": "Time-Optimal Switching Surfaces for Triple Integrator under Full Box Constraints", "comment": "Accepted by ACC 2026", "summary": "Time-optimal control for triple integrator under full box constraints is a fundamental problem in the field of optimal control, which has been widely applied in the industry. However, scenarios involving asymmetric constraints, non-stationary boundary conditions, and active position constraints pose significant challenges. This paper provides a complete characterization of time-optimal switching surfaces for the problem, leading to novel insights into the geometric and algebraic structure of the optimal control. The active condition of position constraints is derived, which is absent from the literature. An efficient algorithm is proposed, capable of planning time-optimal trajectories under asymmetric full constraints and arbitrary boundary states, with a 100% success rate. Computational time for each trajectory is within approximately 10μs, achieving a 5-order-of-magnitude reduction compared to optimization-based baselines."}
{"id": "2601.15915", "categories": ["math.OC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15915", "abs": "https://arxiv.org/abs/2601.15915", "authors": ["Chen Xu"], "title": "Progressive Power Homotopy for Non-convex Optimization", "comment": null, "summary": "We propose a novel first-order method for non-convex optimization of the form $\\max_{\\bm{w}\\in\\mathbb{R}^d}\\mathbb{E}_{\\bm{x}\\sim\\mathcal{D}}[f_{\\bm{w}}(\\bm{x})]$, termed Progressive Power Homotopy (Prog-PowerHP). The method applies stochastic gradient ascent to a surrogate objective obtained by first performing a power transformation and then Gaussian smoothing, $F_{N,σ}(\\bmμ):=\\mathbb{E}_{\\bm{w}\\sim\\mathcal{N}(\\bmμ,σ^2I_d),\\bm{x}\\sim\\mathcal{D}}[e^{Nf_w(\\bm{x})}]$, while progressively increasing the power parameter $N$ and decreasing the smoothing scale $σ$ along the optimization trajectory. We prove that, under mild regularity conditions, Prog-PowerHP converges to a small neighborhood of the global optimum with an iteration complexity scaling nearly as $O(d^2\\varepsilon^{-2})$. Empirically, Prog-PowerHP demonstrates clear advantages in phase retrieval when the samples-to-dimension ratio approaches the information-theoretic limit, and in training two-layer neural networks in under-parameterized regimes. These results suggest that Prog-PowerHP is particularly effective for navigating cluttered non-convex landscapes where standard first-order methods struggle."}
{"id": "2601.16126", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16126", "abs": "https://arxiv.org/abs/2601.16126", "authors": ["Rishi Sundar", "Thomas Elliott"], "title": "Quantum Dimension Reduction of Hidden Markov Models", "comment": "14 pages, 6 figures", "summary": "Hidden Markov models (HMMs) are ubiquitous in time-series modelling, with applications ranging from chemical reaction modelling to speech recognition. These HMMs are often large, with high-dimensional memories. A recently-proposed application of quantum technologies is to execute quantum analogues of HMMs. Such quantum HMMs (QHMMs) are strictly more expressive than their classical counterparts, enabling the construction of more parsimonious models of stochastic processes. However, state-of-the-art techniques for QHMM compression, based on tensor networks, are only applicable for a restricted subset of HMMs, where the transitions are deterministic. In this work we introduce a pipeline by which \\emph{any} finite, ergodic HMM can be compressed in this manner, providing a route for effective quantum dimension reduction of general HMMs. We demonstrate the method on both a simple toy model, and on a speech-derived HMM trained from data, obtaining favourable memory--accuracy trade-offs compared to classical compression approaches."}
{"id": "2601.15559", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15559", "abs": "https://arxiv.org/abs/2601.15559", "authors": ["Jun-Jae Choi", "Seung-Jae Hwang", "Seoyoung Paik", "Juhwan Kim", "Jawad UI-Hassan", "Nguyen Tien Son", "Hiroshi Abe", "Takeshi Oshima", "Jaekwon Suk", "Hyeon-Ho Jeong", "Dong-Hee Kim", "Sang-Yun Lee"], "title": "Spectator-transition crosstalk in a spin-3/2 silicon vacancy qudit in silicon carbide revealed by broadband Ramsey interferometry", "comment": "28 pages, 4 figures", "summary": "Color center spins in 4H-SiC offer a rare combination of wafer-scale materials maturity with long spin coherence and chip-level photonics, making them promising building blocks for scalable quantum technologies. In particular, the silicon vacancy hosts an S=3/2 ground state, a native qudit that enables compact encodings and subspace-selective control, but also introduces spectator transitions: short, detuned pulses can coherently drive non-addressed level pairs and create crosstalk. Here we use broadband Ramsey interferometry to reveal and quantify such spectator-transition crosstalk. Experimentally, the Ramsey Fourier spectra display multiple lines beyond the addressed single-quantum transition. Analytically, we map each line to a pairwise energy difference between qudit levels of the rotating-frame Hamiltonian and assign its weight via compact amplitudes set by the prepared state and the microwave pulse parameters, predicting a deterministic six-branch structure. Numerical time-domain propagation with the experimental sampling reproduces the detuning map, and the measured peak positions coincide with the analytic branch lines without frequency fitting. Together these results provide a practical, spectator-aware framework for multilevel control in the silicon vacancy qudit. The approach offers clear guidance to suppress crosstalk or, conversely, to exploit spectator lines, for example as additional constraints for in situ pulse calibration and for phase-sensitive quantum state and process estimation."}
{"id": "2601.15635", "categories": ["cs.SI", "physics.soc-ph", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.15635", "abs": "https://arxiv.org/abs/2601.15635", "authors": ["Theodore Y. Faust", "Arash A. Amini", "Mason A. Porter"], "title": "Community-Size Biases in Statistical Inference of Communities in Temporal Networks", "comment": "45 pages, 11 figures", "summary": "In the study of time-dependent (i.e., temporal) networks, researchers often examine the evolution of communities, which are sets of densely connected sets of nodes that are connected sparsely to other nodes. An increasingly prominent approach to studying community structure in temporal networks is statistical inference. In the present paper, we study the performance of a class of statistical-inference methods for community detection in temporal networks. We represent temporal networks as multilayer networks, with each layer encoding a time step, and we illustrate that statistical-inference models that generate community assignments via either a uniform distribution on community assignments or discrete-time Markov processes are biased against generating communities with large or small numbers of nodes. In particular, we demonstrate that statistical-inference methods that use such generative models tend to poorly identify community structure in networks with large or small communities. To rectify this issue, we introduce a novel statistical model that generates the community assignments of the nodes in given layer (i.e., at a given time) using all of the community assignments in the previous layer. We prove results that guarantee that our approach greatly mitigates the bias against large and small communities, so using our generative model is beneficial for studying community structure in networks with large or small communities. Our code is available at https://github.com/tfaust0196/TemporalCommunityComparison."}
{"id": "2601.15970", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15970", "abs": "https://arxiv.org/abs/2601.15970", "authors": ["Serge Gratton", "Philippe L. Toint"], "title": "Iteration complexity of the Difference-of-Convex Algorithm for unconstrained optimization: a simple proof", "comment": null, "summary": "We propose a simple proof of the worst-case iteration complexity for the Difference of Convex functions Algorithm (DCA) for unconstrained minimization, showing that the global rate of convergence of the norm of the objective function's gradients at the iterates converge to zero like o(1/k). A small example is also provided indicating that the rate cannot be improved."}
{"id": "2601.16144", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16144", "abs": "https://arxiv.org/abs/2601.16144", "authors": ["Tetsuro Abe", "Shu Tanaka"], "title": "Fair sampling with temperature-targeted QAOA based on quantum-classical correspondence theory", "comment": "4pages, 3figures", "summary": "In combinatorial optimization problems with degenerate ground states, fair sampling of degenerate solutions is essential. However, the quantum approximate optimization algorithm (QAOA) with a standard transverse-field mixer induces biases among degenerate states as circuit depth increases. Based on quantum-classical correspondence theory, we propose SBO-QAOA, which employs a temperature-dependent Hamiltonian encoding a Gibbs distribution as its ground state. Numerical simulations show that, unlike standard QAOA, SBO-QAOA yields ground-state probabilities converging to finite-temperature values with uniform distribution among degenerate states. These fairness and temperature-targeting properties are preserved even with only four variational parameters under a linear schedule."}
{"id": "2601.15565", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.15565", "abs": "https://arxiv.org/abs/2601.15565", "authors": ["Alex Terrasson", "Lars Madsen", "Joel Grim", "Warwick Bowen"], "title": "Bright Pulsed Squeezed Light for Quantum-Enhanced Precision Microscopy", "comment": "5 pages, 3 figures", "summary": "Squeezed states of light enable enhanced measurement precision by reducing noise below the standard quantum limit. A key application of squeezed light is nonlinear microscopy, where state-of-the-art performance is limited by photodamage and quantum-limited noise. Such microscopes require bright, pulsed light for optimal operation, yet generating and detecting bright pulsed squeezing at high levels remains challenging. In this work, we present an efficient technique to generate high levels of bright picosecond pulsed squeezed light using a $χ^2$ optical parametric amplification process in a waveguide. We measure $-3.2~\\mathrm{dB}$ of bright squeezing with optical power compatible with nonlinear microscopy, as well as $-3.6~\\mathrm{dB}$ of vacuum squeezing. Corrected for losses, these squeezing levels correspond to $-15.4^{+2.7}_{-8.7}~\\mathrm{dB}$ of squeezing generated in the waveguide. The measured level of bright amplitude pulsed squeezing is to our knowledge the highest reported to date, and will contribute to the broader adoption of quantum-enhanced nonlinear microscopy in biological studies."}
{"id": "2601.16058", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.16058", "abs": "https://arxiv.org/abs/2601.16058", "authors": ["Claudia Kirch", "Hedvika Ranošová", "Martin Wendler"], "title": "Fully Functional Weighted Testing for Abrupt and Gradual Location Changes in Functional Time Series", "comment": null, "summary": "Change point tests for abrupt changes in the mean of functional data, i.e., random elements in infinite-dimensional Hilbert spaces, are either based on dimension reduction techniques, e.g., based on principal components, or directly based on a functional CUSUM (cumulative sum) statistic. The former have often been criticized as not being fully functional and losing too much information. On the other hand, unlike the latter, they take the covariance structure of the data into account by weighting the CUSUM statistics obtained after dimension reduction with the inverse covariance matrix. In this paper, as a middle ground between these two approaches, we propose an alternative statistic that includes the covariance structure with an offset parameter to produce a scale-invariant test procedure and to increase power when the change is not aligned with the first components. We obtain the asymptotic distribution under the null hypothesis for this new test statistic, allowing for time dependence of the data. Furthermore, we introduce versions of all three test statistics for gradual change situations, which have not been previously considered for functional data, and derive their limit distribution. Further results shed light on the asymptotic power behavior for all test statistics under various ground truths for the alternatives."}
{"id": "2601.15996", "categories": ["math.OC", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.15996", "abs": "https://arxiv.org/abs/2601.15996", "authors": ["Mario Bravo", "Roberto Cominetti", "Jongmin Lee"], "title": "Minimax-optimal Halpern iterations for Lipschitz maps", "comment": null, "summary": "This paper investigates the minimax-optimality of Halpern fixed-point iterations for Lipschitz maps in general normed spaces. Starting from an a priori bound on the orbit of iterates, we derive non-asymptotic estimates for the fixed-point residuals. These bounds are tight, meaning that they are attained by a suitable Lipschitz map and an associated Halpern sequence. By minimizing these tight bounds we identify the minimax-optimal Halpern scheme. For contractions, the optimal iteration exhibits a transition from an initial Halpern phase to the classical Banach-Picard iteration and, as the Lipschitz constant approaches one, we recover the known convergence rate for nonexpansive maps. For expansive maps, the algorithm is purely Halpern with no Banach-Picard phase; moreover, on bounded domains, the residual estimates converge to the minimal displacement bound. Inspired by the minimax-optimal iteration, we design an adaptive scheme whose residuals are uniformly smaller than the minimax-optimal bounds, and can be significantly sharper in practice. Finally, we extend the analysis by introducing alternative bounds based on the distance to a fixed point, which allow us to handle mappings on unbounded domains; including the case of affine maps for which we also identify the minimax-optimal iteration."}
{"id": "2601.16177", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16177", "abs": "https://arxiv.org/abs/2601.16177", "authors": ["Akihiro Hokkyo"], "title": "Stabilizer Thermal Eigenstates at Infinite Temperature", "comment": "4+3 pages, 2 figures", "summary": "Understanding how to analyze highly entangled thermal eigenstates is a central challenge in the study of quantum many-body systems. In this Letter, we introduce a stabilizer-based approach to construct analytically tractable energy eigenstates of nonintegrable many-body Hamiltonians. Focusing on zero-energy eigenstates at infinite temperature, we prove a sharp no-go theorem: stabilizer eigenstates of two-body Hamiltonians cannot satisfy $k$-body microscopic thermal equilibrium for any $k\\ge4$. We further show that this bound is tight by explicitly constructing two-body nonintegrable Hamiltonians whose stabilizer eigenstates reproduce thermal expectation values for all two-body and all three-body observables. Finally, we identify the structural origin of this limitation by characterizing the conditions under which a stabilizer state can appear as a zero-energy eigenstate of a Hamiltonian, thereby revealing a fundamental constraint imposed by the few-body nature of interactions."}
{"id": "2601.15586", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15586", "abs": "https://arxiv.org/abs/2601.15586", "authors": ["Xueting Fang", "Doudou Wang", "Kun Yuan", "Jie Deng", "Qin Luo", "Xiaochun Duan", "Minkang Zhou", "Lushuai Cao", "Zhongkun Hu"], "title": "Optimized Slice-Phase Control of Mirror Pulse in Cold-Atom Interferometry with Finite Response Time", "comment": null, "summary": "Atom interferometers require both high efficiency and robust performance in their mirror pulses under experimental inhomogeneities. In this work, we demonstrated that quantum optimal control designed mirror pulse significantly enhance interferometer performance by using novel adaptive sliced structure. Using gradient ascent pulse engineering (GRAPE), optimized mirror pulse for a Mach-Zehnder light-pulse atom interferometer was designed by discretizing the control into non-uniform phase slices. This design broadened the tolerence to experimentally relevant variations in detuning $[-Ω_0,Ω_0]$ and Rabi frequency $[0.1\\timesΩ_0,1.9\\timesΩ_0]$ ($Ω_0=2π\\times25$ kHz), while maintaining high transfer efficiency even when the response-time delays up to 1.6 $\\rm{μs}$. The optimized pulse was found to be robust to coupling inhomogeneity and velocity spread, offering a significant improvement in robustness over conventional pulse. The adaptive pulse slicing method provides a minimalist strategy that reduces experimental complexity while enhancing robustness and scalability, offering an innovative scheme for quantum optimal control in high precision atom interferometry."}
{"id": "2601.16003", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.16003", "abs": "https://arxiv.org/abs/2601.16003", "authors": ["Yunan Wang", "Chuxiong Hu", "Zhao Jin"], "title": "Time-Optimal Switching Surfaces for Triple Integrator under Full Box Constraints", "comment": "Accepted by ACC 2026", "summary": "Time-optimal control for triple integrator under full box constraints is a fundamental problem in the field of optimal control, which has been widely applied in the industry. However, scenarios involving asymmetric constraints, non-stationary boundary conditions, and active position constraints pose significant challenges. This paper provides a complete characterization of time-optimal switching surfaces for the problem, leading to novel insights into the geometric and algebraic structure of the optimal control. The active condition of position constraints is derived, which is absent from the literature. An efficient algorithm is proposed, capable of planning time-optimal trajectories under asymmetric full constraints and arbitrary boundary states, with a 100% success rate. Computational time for each trajectory is within approximately 10μs, achieving a 5-order-of-magnitude reduction compared to optimization-based baselines."}
{"id": "2601.16181", "categories": ["physics.soc-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16181", "abs": "https://arxiv.org/abs/2601.16181", "authors": ["Renato Vieira dos Santos"], "title": "Engineering polarization: How contradictory stimulation systematically undermines political moderation", "comment": null, "summary": "Political moderation, a key attractor in democratic systems, proves highly fragile under realistic information conditions. We develop a stochastic model of opinion dynamics to analyze how noise and differential susceptibility reshape the political spectrum. Extending Marvel et al.'s deterministic framework, we incorporate stochastic media influence $ζ(t)$ and neuropolitically-grounded sensitivity differences ($σ_y > σ_x$). Analysis reveals the moderate population -- stable in deterministic models -- undergoes catastrophic collapse under stochastic forcing. This occurs through an effective deradicalization asymmetry ($u_{B}^{\\text{eff}} = u + σ_y^2/2 > u_{A}^{\\text{eff}}$) that drives conservatives to extinction, eliminating cross-cutting interactions that sustain moderates. The system exhibits a phase transition from multi-stable coexistence to liberal dominance, demonstrating how information flow architecture -- independent of content -- systematically dismantles the political center. Our findings reveal moderation as an emergent property highly vulnerable to stochastic perturbations in complex social systems."}
{"id": "2601.15616", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15616", "abs": "https://arxiv.org/abs/2601.15616", "authors": ["Shu Kanno", "Kenji Sugisaki", "Rei Sakuma", "Jumpei Kato", "Hajime Nakamura", "Naoki Yamamoto"], "title": "Tensor-based phase difference estimation on time series analysis", "comment": "13 pages", "summary": "We propose a phase-difference estimation algorithm based on the tensor-network circuit compression, leveraging time-evolution data to pursue scalability and higher accuracy on a quantum phase estimation (QPE)-type algorithm. Using tensor networks, we construct circuits composed solely of nearest-neighbor gates and extract time-evolution data by four-type circuit measurements. In addition, to enhance the accuracy of time-evolution and state-preparation circuits, we propose techniques based on algorithmic error mitigation and on iterative circuit optimization combined with merging into matrix product states, respectively. Verifications using a noiseless simulator for the 8-qubit one-dimensional Hubbard model using an ancilla qubit show that the proposed algorithm achieves accuracies with 0.4--4.7\\% error from a true energy gap on an appropriate time-step size, and that accuracy improvements due to the algorithmic error mitigation are observed. We also confirm the enhancement of the overlap with matrix product states through iterative optimization. Finally, the proposed algorithm is demonstrated on IBM Heron devices with Q-CTRL error suppression for 8-, 36-, and 52-qubit models using more than 5,000 2-qubit gates. These largest-scale demonstrations for the QPE-type algorithm represent significant progress not only toward practical applications of near-term quantum computing but also toward preparation for the era of error-corrected quantum devices."}
{"id": "2601.16043", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.16043", "abs": "https://arxiv.org/abs/2601.16043", "authors": ["Nam Van Tran"], "title": "A Second-Order Dynamical System for Solving Generalized Inverse Mixed Variational Inequality problems", "comment": null, "summary": "In this paper, we study a class of generalized inverse mixed variational inequality problems (GIMVIPs). We propose a novel projection-based second-order time-varying dynamical system for solving GIMVIPs. Under the assumptions that the underlying operators are strongly monotone and Lipschitz continuous, we establish the existence and uniqueness of solution trajectories and prove their global exponential convergence to the unique solution of the GIMVIP. Furthermore, a discrete-time realization of the continuous dynamical system is developed, resulting in an inertial projection algorithm. We show that the proposed algorithm achieves linear convergence under suitable choices of parameters. Finally, numerical experiments are presented to illustrate the effectiveness and convergence behavior of the proposed method in solving GIMVIPs."}
{"id": "2601.15641", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15641", "abs": "https://arxiv.org/abs/2601.15641", "authors": ["Larry Bowden", "Qi Chu", "Bernard Cena", "Kentaro Ohno", "Bob Parney", "Deepak Sharma", "Mitsuharu Takeori"], "title": "Machine Failure Detection Based on Projected Quantum Models", "comment": "9 pages", "summary": "Detecting machine failures promptly is of utmost importance in industry for maintaining efficiency and minimizing downtime. This paper introduces a failure detection algorithm based on quantum computing and a statistical change-point detection approach. Our method leverages the potential of projected quantum feature maps to enhance the precision of anomaly detection in machine monitoring systems. We empirically validate our approach on benchmark multi-dimensional time series datasets as well as on a real-world dataset comprising IoT sensor readings from operational machines, ensuring the practical relevance of our study. The algorithm was executed on IBM's 133-qubit Heron quantum processor, demonstrating the feasibility of integrating quantum computing into industrial maintenance procedures. The presented results underscore the effectiveness of our quantum-based failure detection system, showcasing its capability to accurately identify anomalies in noisy time series data. This work not only highlights the potential of quantum computing in industrial diagnostics but also paves the way for more sophisticated quantum algorithms in the realm of predictive maintenance."}
{"id": "2601.16128", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.16128", "abs": "https://arxiv.org/abs/2601.16128", "authors": ["Lixin Shen", "Guohui Song"], "title": "Proximity Operator of the $\\ell_1$ over $\\ell_2$ Function", "comment": null, "summary": "We study the proximity operator of the nonconvex, scale-invariant ratio $h(\\vx)=\\|\\vx\\|_{1}/\\|\\vx\\|_{2}$ and show it can be computed exactly in any dimension. By expressing $\\vx=r\\vu$ and exploiting sign and permutation invariance, we reduce the proximal step to a smooth optimization of a rank-one quadratic over the nonnegative orthant of the unit sphere. We prove that every proximal point arises from a finite candidate set indexed by $k\\in\\{1,\\dots,n\\}$: the active subvector is a local, but nonglobal, minimizer on $\\mathbb{S}^{k-1}$ characterized by the roots of an explicit quartic. This yields closed-form candidates, an exact selection rule, and a necessary and sufficient existence test. Building on these characterizations, we develop practical algorithms, including an $O(n)$ implementation via prefix sums and a pruning criterion that avoids unnecessary quartic solves. The method returns all proximal points when the prox is non-unique, and in experiments it attains strictly lower objective values than approaches that guess sparsity or rely on sphere projections with limited scalability."}
{"id": "2601.15654", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.15654", "abs": "https://arxiv.org/abs/2601.15654", "authors": ["Arman", "Prasanta K. Panigrahi"], "title": "Enhancing the Size of Phase-Space States Containing Sub-Planck-Scale Structures via Non-Gaussian Operations", "comment": null, "summary": "We observe a metrological advantage in phase-space sensitivity for photon-added cat and kitten states over their original forms, due to phase-space broadening from increased amplitude via photon addition, albeit with higher energy cost. Using accessible non-classical resources, weak squeezing and displacement, we construct a squeezed state and two superposed states: the squeezed cat state and the symmetrically squeezed state. Their photon-added variants are compared with parity-matched cat and KSs using quantum Fisher information and fidelity. The QFI isocontours reveal regimes where KS exhibit high fidelity and large amplitude, enabling their preparation via Gaussian operations and photon addition. Similar regimes are identified for cat states enhanced by squeezing and photon addition, demonstrating improved metrological performance. Moreover, increased amplitude and thus larger phase-space area reduces the size of interferometric fringes, enhancing the effectiveness of quantum error correction in cat codes."}
{"id": "2601.16194", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.16194", "abs": "https://arxiv.org/abs/2601.16194", "authors": ["El Mehdi Er Raqabi", "Kevin Dalmeijer", "Pascal Van Hentenryck"], "title": "A Rolling-Space Branch-and-Price Algorithm for the Multi-Compartment Vehicle Routing Problem with Multiple Time Windows", "comment": null, "summary": "This paper investigates the multi-compartment vehicle routing problem with multiple time windows (MCVRPMTW), an extension of the classical vehicle routing problem with time windows that considers vehicles equipped with multiple compartments and customers requiring service across several delivery time windows. The problem incorporates three key compartment-related features: (i) compartment flexibility in the number of compartments, (ii) item-to-compartment compatibility, and (iii) item-to-item compatibility. The problem also accommodates practical operational requirements such as driver breaks. To solve the MCVRPMTW, we develop an exact branch-and-price (B&P) algorithm in which the pricing problem is solved using a labeling algorithm. Several acceleration strategies are introduced to limit symmetry during label extensions, improve the stability of dual solutions in column generation, and enhance the branching process. To handle large-scale instances, we propose a rolling-space B&P algorithm that integrates clustering techniques into the solution framework. Extensive computational experiments on instances inspired by a real-world industrial application demonstrate the effectiveness of the proposed approach and provide useful managerial insights for practical implementation."}
{"id": "2601.15677", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15677", "abs": "https://arxiv.org/abs/2601.15677", "authors": ["Kentaro Yamamoto", "Riku Masui", "Takahito Nakajima", "Miwako Tsuji", "Mitsuhisa Sato", "Peter Schow", "Lukas Heidemann", "Matthew Burke", "Philipp Seitz", "Oliver J. Backhouse", "Juan W. Pedersen", "John Children", "Craig Holliman", "Nathan Lysne", "Daichi Okuno", "Seyon Sivarajah", "David Muñoz Ramo", "Alex Chernoguzov", "Ross Duncan"], "title": "Quantum-HPC hybrid computation of biomolecular excited-state energies", "comment": "7 pages, 5 figures", "summary": "We develop a workflow within the ONIOM framework and demonstrate it on the hybrid computing system consisting of the supercomputer Fugaku and the Quantinuum Reimei trapped-ion quantum computer. This hybrid platform extends the layered approach for biomolecular chemical reactions to accurately treat the active site, such as a protein, and the large and often weakly correlated molecular environment. Our result marks a significant milestone in enabling scalable and accurate simulation of complex biomolecular reactions"}
{"id": "2601.16041", "categories": ["math.ST", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.16041", "abs": "https://arxiv.org/abs/2601.16041", "authors": ["Omar Al-Ghattas"], "title": "Risk reversal for least squares estimators under nested convex constraints", "comment": "31 pages, 5 figures", "summary": "In constrained stochastic optimization, one naturally expects that imposing a stricter feasible set does not increase the statistical risk of an estimator defined by projection onto that set. In this paper, we show that this intuition can fail even in canonical settings.\n  We study the Gaussian sequence model, a deliberately austere test best, where for a compact, convex set $Θ\\subset \\mathbb{R}^d$ one observes \\[ Y = θ^\\star + σZ, \\qquad Z \\sim N(0, I_d), \\] and seeks to estimate an unknown parameter $θ^\\star \\in Θ$. The natural estimator is the least squares estimator (LSE), which coincides with the Euclidean projection of $Y$ onto $Θ$. We construct an explicit example exhibiting \\emph{risk reversal}: for sufficiently large noise, there exist nested compact convex sets $Θ_S \\subset Θ_L$ and a parameter $θ^\\star \\in Θ_S$ such that the LSE constrained to $Θ_S$ has strictly larger risk than the LSE constrained to $Θ_L$. We further show that this phenomenon can persist at the level of worst-case risk, with the supremum risk over the smaller constraint set exceeding that over the larger one.\n  We clarify this behavior by contrasting noise regimes. In the vanishing-noise limit, the risk admits a first-order expansion governed by the statistical dimension of the tangent cone at $θ^\\star$, and tighter constraints uniformly reduce risk. In contrast, in the diverging-noise regime, the risk is determined by global geometric interactions between the constraint set and random noise directions. Here, the embedding of $Θ_S$ within $Θ_L$ can reverse the risk ordering.\n  These results reveal a previously unrecognized failure mode of projection-based estimators: in sufficiently noisy settings, tightening a constraint can paradoxically degrade statistical performance."}
{"id": "2601.15693", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15693", "abs": "https://arxiv.org/abs/2601.15693", "authors": ["Sahel Ashhab"], "title": "Fractional squeezing: spectra and dynamics from generalized squeezing Hamiltonian with fractional orders", "comment": "15 pages (preprint); 5 figures", "summary": "We generalize the generalized-squeezing problem to include fractional values of the squeezing order $n$. This approach allows us to determine the locations of critical points at which qualitative changes in behaviour occur and accurately predict the behaviour at these critical points, which are challenging for conventional computational methods. Based on our numerical calculations, we identify with a high degree of confidence the point at which the spectrum turns from continuous to discrete and the point at which oscillations turn from having asymptotically infinite amplitudes to finite amplitudes. Furthermore, we numerically investigate the behaviour in the large $n$ regime and provide an intuitive explanation that coincides with the numerical results."}
{"id": "2601.16149", "categories": ["eess.SY", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.16149", "abs": "https://arxiv.org/abs/2601.16149", "authors": ["Zirui Niu", "Giordano Scarciotti", "Alessandro Astolfi"], "title": "Interconnection-based Model Reduction for Linear Hybrid Systems", "comment": "17 pages", "summary": "In this paper, we address the model reduction problem for linear hybrid systems via the interconnection-based technique called moment matching. We consider two classical interconnections, namely the direct and swapped interconnections, in the hybrid setting, and we present families of reduced-order models for each interconnection via a hybrid characterisation of the steady-state responses. By combining the results for each interconnection, the design of a reduced-order model that achieves moment matching simultaneously for both interconnections is studied. In addition, we show that the presented results have simplified counterparts when the jumps of the hybrid system are periodic. A numerical simulation is finally given to illustrate the results."}
{"id": "2601.15752", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15752", "abs": "https://arxiv.org/abs/2601.15752", "authors": ["Jian-Feng Wu", "Yi Huang", "Yu-Xiang Zhang"], "title": "Unsplit Spreading: An Overlooked Signature of Long-Range Interaction", "comment": "6+5 pages, 4+8 figures", "summary": "In conventional lattice models, the dispersion relation $ω(k)$ is assumed to be a smooth function. We prove that this smoothness implies the splitting of an initially localized excitation into counter-propagating wave packets. Consequently, unsplit spreading can occur only when $ω(k)$ develops singular features, precisely what long-range interactions enable. Remarkably, this phenomenon was clearly visible in published quantum simulation experiments as early as 2014, yet it has remained unrecognized or discussed as a distinct physical effect. We show that unsplit spreading emerges in realistic open quantum systems, such as 1D and 2D subwavelength atomic arrays, where the long-lived subradiant states host effective dispersion with the required singularities. Our work establishes unsplit spreading as an experimentally accessible, smoking-gun signature of singular band structure induced by long-range physics."}
{"id": "2601.15760", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15760", "abs": "https://arxiv.org/abs/2601.15760", "authors": ["Shubham Patel", "Utkarsh Mishra"], "title": "Improving the efficiency of QAOA using efficient parameter transfer initialization and targeted-single-layer regularized optimization with minimal performance degradation", "comment": "14 pages, 13 figures, 2 tables, 2 algorithms", "summary": "Quantum approximate optimization algorithm (QAOA) have promising applications in combinatorial optimization problems (COPs). We investigated the MaxCut problem in three different families of graphs using QAOA ansats with parameter transfer initialization followed by targeted single layer optimization. For 3 regular (3R), Erdos Renyi (ER), and Barabasi Albert (BA) graphs, the parameter transfer approach achieved mean approximation ratios of 0.9443 for targeted-single layer optimization as compared to 0.9551 of full optimization. It represents 98.88 percent optimal performance, with 8.06 times computational speedup in unweighted graphs. But, in weighted graph families, optimal performance is relatively low (less than 90 percent) for higher nodes graph, suggesting parameter transfer followed by targeted-single-layer optimization is not ideal for weighted graph families, however, we find that for some weighted families (weighted 3-regular) this approach works perfectly. In 8.92 percent test cases, targeted single layer optimization outperformed the full optimization, indicating that complex parameter landscape can trap full optimization in sub-optimal local minima. To mitigate this inconsistency, ridge (L2) regularization is used to smoothen the solution landscape, which helps the optimizer to find better optimum parameters during full optimization and reduces these inconsistent test cases from 8.92 percent to 3.81 percent. This work demonstrates that efficient parameter initialization and targeted-single-layer optimization can improve the efficiency of QAOA with minimal performance degradation."}
{"id": "2601.15770", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15770", "abs": "https://arxiv.org/abs/2601.15770", "authors": ["Jue Xu", "Chu Zhao", "Xiangran Zhang", "Shuchen Zhu", "Qi Zhao"], "title": "Classical Simulation of Noiseless Quantum Dynamics without Randomness", "comment": null, "summary": "Simulating noiseless quantum dynamics classically faces a fundamental dilemma: tensor-network methods become inefficient as entanglement saturates, while Pauli-truncation approaches typically rely on noise or randomness. To close the gap, we propose the Low-weight Pauli Dynamics (LPD) algorithm that efficiently approximates local observables for short-time dynamics in the absence of noise. We prove that the truncation error admits an average-case bound without assuming randomness, provided that the state is sufficiently entangled. Counterintuitively, entanglement--usually an obstacle for classical simulation--alleviates classical simulation error. We further show that such entangled states can be generated either by tensor-network classical simulation or near-term quantum devices. Our results establish a rigorous synergy between existing classical simulation methods and provide a complementary route to quantum simulation that reduces circuit depth for long-time dynamics, thereby extending the accessible regime of quantum dynamics."}
{"id": "2601.15885", "categories": ["quant-ph", "hep-lat"], "pdf": "https://arxiv.org/pdf/2601.15885", "abs": "https://arxiv.org/abs/2601.15885", "authors": ["Chaitanya Gupta", "Anthony J. Short"], "title": "Fermion Doubling in Dirac Quantum Walks", "comment": "13 pages, 5 figures", "summary": "We consider discrete spacetime models known as quantum walks, which can be used to simulate Dirac particles. In particular we look at fermion doubling in these models, in which high momentum states yield additional low energy solutions which behave like Dirac particles. The presence of doublers carries over to the `second quantised' version of the walks represented by quantum cellular automata, which may lead to spurious solutions when introducing interactions. Moreover, we also consider pseudo-doublers, which have high energy but behave like low energy Dirac particles, and cause potential problems regarding the stability of the vacuum. To address these issues, we propose a family of quantum walks, that are free of these doublers and pseudo-doublers, but still simulate the Dirac equation in the continuum limit. However, there remain a small number of additional low energy solutions which do not directly correspond to Dirac particles. While the conventional Dirac walk always has a zero probability for the walker staying at the same point, we obtain the family of walks by allowing this probability to be non-zero."}
{"id": "2601.15902", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15902", "abs": "https://arxiv.org/abs/2601.15902", "authors": ["Prabal Dasgupta", "Debashis Gangopadhyay"], "title": "Improved cryptographic security in teleportation with q-deformed non-maximal entangled states", "comment": null, "summary": "In this work the machinery of q-deformed algebras are used to enhance cryptographic security during teleportation. We use q-deformed harmonic oscillator states to develop a novel method of teleportation. The deformed states can be expressed in terms of standard oscillator states and the expressions contain certain arbitrary functions of $q$. It is the presence of these arbitrary functions that allows an enhancement of cryptographic security. The specifics are :\n  (a) q-deformed Bell-like states are constructed which reduce to the usual Bell states when the deformation parameter $q\\rightarrow 1$. These deformed states form an orthonormal basis for q-deformed entangled bipartite states when certain arbitrary functions of $q$ satisfy a constraint.\n  (b) We discuss the generalisation of the usual teleportation protocol with non-maximally entangled states. This generalisation is then employed to construct two new protocols using q-deformed non-maximally entangled states. These states have additional parameters and these have to be shared for decryption after teleportation. Consequently, the cryptographic security is improved."}
{"id": "2601.15934", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15934", "abs": "https://arxiv.org/abs/2601.15934", "authors": ["Marcin Szyniszewski", "Aleks Kissinger", "Noah Linden", "Paul Skrzypczyk"], "title": "Automated quantum circuit optimization with randomized replacements", "comment": "7 pages, 4 figures", "summary": "Quantum circuit optimization - the process of transforming a quantum circuit into an equivalent one with reduced time and space requirements - is crucial for maximizing the utility of current and near-future quantum devices. While most automated optimization techniques focus on transforming circuits into equivalent ones that implement the same unitary, we show that substantial new opportunities for resource reduction can be achieved by (1) allowing approximate local transformations and (2) employing mixed quantum channels to approximate pure circuits. Our novel automated protocol for approximate circuit rewriting is a refined evolution of automated optimization techniques based on the ZX-calculus, where we add a greedy strategy that selectively replaces ZX-diagrams with small phase angles with stochastic mixtures of the identity and carefully chosen over-rotations, which are designed to reduce the overall gate count in expectation while staying within a strict error budget. This approach yields modest two-qubit gate count reduction in random quantum circuits, and achieves a substantial reduction in structured circuits such as the quantum Fourier transform. Fundamentally, our protocol converts experimental noise due to gate applications into deliberately engineered random noise, outperforming many other approximation methods on average. These results highlight the potential of mixed-channel approximations to enhance future quantum circuit performance, suggesting new directions for resource-aware automated quantum compilation beyond pure unitary channels."}
{"id": "2601.15941", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15941", "abs": "https://arxiv.org/abs/2601.15941", "authors": ["Vishnu Muraleedharan Sajitha", "Matthew J. Davis", "L. A. Williamson"], "title": "Frictional work and entropy production in integrable and non-integrable spin chains", "comment": null, "summary": "The maximum work extractable from a quantum system is achieved when the system is driven adiabatically. Frictional work then quantifies the difference in work output between adiabatic and non-adiabatic driving. Here we show that frictional work in a non-integrable spin chain is well-described by the diagonal entropy production associated with the build up of quantum coherence. The relationship is characterized by an effective temperature of the final adiabatic state and holds for slow to moderate driving protocols. For fast protocols, the frictional work is instead described by the quantum relative entropy between the final non-adiabatic and adiabatic states. We compare our results to those obtained from an integrable spin chain, in which case the adiabatic state is no longer described by a single temperature. In this case, the frictional work is described by a sum of terms for each independent subspace of the spin chain, which are at different effective temperatures. We show how integrability breaking can enhance work extraction in the adiabatic limit, but degrade work extraction in sufficiently non-adiabatic regimes."}
{"id": "2601.15945", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15945", "abs": "https://arxiv.org/abs/2601.15945", "authors": ["Romain Piron", "Akihito Soeda"], "title": "Renormalization Treatment of IR and UV Cutoffs in Waveguide QED and Implications to Numerical Model Simulation", "comment": "20 pages, 7 figures", "summary": "We present a non-perturbative, first-principles derivation of renormalization relations for waveguide-QED models, explicitly accounting for the infrared (IR) and ultraviolet (UV) cutoffs that are necessarily introduced in numerical simulations. By formulating the atomic dynamics in the time domain, we obtain explicit expressions linking the bare model parameters to the physically observable atomic frequency and decay rate, and verify their consistency with scattering theory. We further connect these results to standard Feynman diagrams, providing a transparent physical interpretation and ensuring the generality of the approach. Finally, we show how these renormalization relations can be used to parameterize simulations with a minimal frequency bandwidth, simultaneously preserving physical accuracy and reducing computational cost, thereby paving the way for efficient and reliable multi-photon light-matter simulations."}
{"id": "2601.15972", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15972", "abs": "https://arxiv.org/abs/2601.15972", "authors": ["Takuya Hatomura"], "title": "Universal Digitized Counterdiabatic Driving", "comment": null, "summary": "Counterdiabatic driving realizes parameter displacement of an energy eigenstate of a given parametrized Hamiltonian using the adiabatic gauge potential. In this paper, we propose a universal method of digitized counterdiabatic driving, constructing the adiabatic gauge potential in a digital way with the idea of universal counterdiabatic driving. This method has three advantages over existing universal counterdiabatic driving and/or digitized counterdiabatic driving: it does not introduce any many-body and/or nonlocal interactions to an original target Hamiltonian; it can incorporate infinite nested commutators, which constitute the adiabatic gauge potential; and it gives explicit expression of rotation angles for digital implementation. We show the consistency of our method to the exact theory in an analytical way and the effectiveness of our method with the aid of numerical simulations."}
{"id": "2601.15986", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15986", "abs": "https://arxiv.org/abs/2601.15986", "authors": ["Matheus V. Scherer", "Lea F. Santos", "Alexandre D. Ribeiro"], "title": "Semiclassical entanglement entropy for spin-field interaction", "comment": null, "summary": "We study a general bipartite quantum system consisting of a spin interacting with a bosonic field, with the initial state prepared as the product of a spin coherent state and a canonical coherent state. Our goal is to develop a semiclassical framework to describe the entanglement dynamics between these two subsystems. Using appropriate approximations, we derive a semiclassical expression for the entanglement entropy that depends exclusively on the trajectories of the underlying classical description. By analytically extending the classical phase space into the complex domain, we identify additional complex trajectories that significantly improve the accuracy of the semiclassical description. The inclusion of these complex trajectories allows us to capture the entanglement dynamics with remarkable precision, even well beyond the Ehrenfest time. The approach is illustrated with a representative example, where the role of real and complex trajectories in reproducing the quantum entanglement entropy is explicitly demonstrated."}
{"id": "2601.16002", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16002", "abs": "https://arxiv.org/abs/2601.16002", "authors": ["Xiang Zhang Chen Sun", "Fuxiang Li"], "title": "Engineering quantum Mpemba effect by Liouvillian skin effect", "comment": "7 pages, 2 figures", "summary": "We propose a new approach to engineer the quantum Mpemba effect (QME) -- wherein an initial state farther from system relaxes faster than a close one -- by the Liouvillian skin effect (LSE) in open quantum systems. Moreover, the LSE serves as an ideal platform for realizing the QME and the spatial profile of the LSE provides a straightforward pathway for the initial state preparation, thereby enabling readily accessible experimental preparation. Focusing on the quadratic Lindbladians, we consider two concrete cases to design the initial states, thereby realizing the QME. Interestingly, we uncover a new kind of QME (QME-III) that is distinct from the two typical scenarios, manifested as two reversals in the Hilbert-Schmidt distance at two different times. In particular, the LSE provides a physically more intuitive understanding of the QME."}
{"id": "2601.16004", "categories": ["quant-ph", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.16004", "abs": "https://arxiv.org/abs/2601.16004", "authors": ["Christopher Altman"], "title": "Wigner's Friend as a Circuit: Inter-Branch Communication Witness Benchmarks on Superconducting Quantum Hardware", "comment": "11 pages, 6 figures. Includes reproducibility code and archived data release", "summary": "We implement and benchmark on IBM Quantum hardware the circuit family proposed by Violaris for estimating operational inter-branch communication witnesses, defined as correlations in classical measurement records produced by compiled Wigner's-friend-style circuits. We realize a five-qubit instance of the protocol as an inter-register message-transfer pattern within a single circuit, rather than physical signaling, and evaluate its behavior under realistic device noise and compilation constraints. The circuit encodes branch-conditioned evolution of an observer subsystem whose dynamics depend on a control qubit, followed by a controlled transfer operation that probes correlations between conditional measurement contexts.\n  Executing on the ibm_fez backend with 20000 shots, we observe population-based visibility of 0.877, coherence witnesses of 0.840 and -0.811 along orthogonal axes, and a phase-sensitive magnitude of approximately 1.17. While the visibility metric is insensitive to some classes of dephasing, the coherence witnesses provide complementary sensitivity to off-diagonal noise.\n  This work does not test or discriminate among interpretations of quantum mechanics. Instead, it provides a reproducible operational constraint pipeline for evaluating detectability of non-ideal channels relative to calibrated device noise."}
{"id": "2601.16026", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16026", "abs": "https://arxiv.org/abs/2601.16026", "authors": ["Dong-Sheng Liu", "Zi-Jie Chen", "Ziyue Hua", "Yilong Zhou", "Qing-Xuan Jie", "Weizhou Cai", "Ming Li", "Luyan Sun", "Chang-Ling Zou", "Xi-Feng Ren", "Guang-Can Guo"], "title": "Echoed Random Quantum Metrology", "comment": null, "summary": "Quantum metrology typically demands the preparation of exotic quantum probe states, such as entangled or squeezed states, to surpass classical limits. However, the need for carefully calibrated system parameters and finely optimized quantum controls imposes limitations on scalability and robustness. Here, we circumvent these limitations by introducing an echoed random process that achieves sensitivity approaching the Heisenberg limit while remaining blind to the random probe state. We demonstrate that by simply driving a Kerr nonlinear mode with random pulses, the emergence of sub-Planck phase-space structures grants high sensitivity, eliminating the need for complex quantum control. The protocol is statistically robust, yielding high performance across broad driving parameter ranges while exhibiting resilience to control fluctuations and photon loss. Broadly applicable to both bosonic and qubit platforms, our work reveals a practical, hardware-efficient, scalable, and optimization-free route to quantum-enhanced metrology in high-dimensional Hilbert spaces."}
{"id": "2601.16081", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16081", "abs": "https://arxiv.org/abs/2601.16081", "authors": ["Aishwarya Majumdar", "Yuan Liu"], "title": "Robust Quantum Algorithmic Binary Decision-Making on Displacement Signals", "comment": null, "summary": "A relevant signal in the quantum domain may manifest as a displacement or a phase shift operator in the bosonic phase space. For a real parameter $β$ embedded in such a displacement operator, the task of determining if $β\\in [β_{-th}, β_{+th}]$ for real asymmetric thresholds $(β_{-th} \\ne -β_{+th})$ is a binary decision problem. We propose a framework based on generalized quantum signal processing interferometry (GQSPI) on hybrid qubit-bosonic oscillator systems that addresses this parameter detection problem by recasting the practical task of active binary hypothesis testing on quantum systems to that of a polynomial approximation. We achieve a small decision error probability $p_{err}$ on the order of $O(\\frac{1}{d}\\log{(d)})$, with $d$ as the circuit depth. We analyze the protocol when (i) $β$ is a deterministic parameter, and (ii) when $β$ is drawn randomly from a known prior distribution. The performance of the sensing protocol under dephasing noise is also shown to be robust. We further extend our protocol from two thresholds to more general multi-threshold cases as well. Overall, the proposed framework enables decision-making over arbitrary thresholds for any general displacement signal in a single or a few shots."}
{"id": "2601.16106", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16106", "abs": "https://arxiv.org/abs/2601.16106", "authors": ["Byeong-Yoon Go", "Geunhee Gwak", "Young-Do Yoon", "Sungho Lee", "Nicolas Treps", "Jiyong Park", "Young-Sik Ra"], "title": "Quantum Metrology under Coarse-Grained Measurement", "comment": null, "summary": "While quantum metrology enables measurement precision beyond classical limits, its performance is often susceptible to experimental imperfections. Most prior studies have focused on imperfections in quantum states and operations. Here, we investigate the effect of coarse graining in quantum measurement through both theoretical analysis and experimental demonstration. Using an interferometer with a squeezed vacuum and a laser input, we analyze how coarse graining in homodyne detection affects the precision of phase estimation. We evaluate the Fisher information under various coarse-graining conditions and determine, in each case, an optimal estimation strategy that saturates the Cramér-Rao bound. Remarkably, even extremely coarse-grained measurement -- with only two bins -- enables phase estimation beyond the standard quantum limit and even achieves a precision that follows the Heisenberg scaling. We experimentally demonstrate quantum-enhanced phase estimation under coarse-grained homodyne detection. To determine an optimal estimation strategy, we employ the method of moments and present calibration procedures that enable its application to general experimental settings. Using only two bins, we observe a quantum enhancement of 1.2 dB compared to the classical method using the ideal measurement, improving towards 3.8 dB as the bin number increases. These results highlight a practical pathway to achieving quantum enhancement under the presence of severe experimental imperfections."}
{"id": "2601.16116", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16116", "abs": "https://arxiv.org/abs/2601.16116", "authors": ["Hari Krishnan KB", "Vishal Varma", "T. S. Mahesh"], "title": "Experimental prime factorization via a feedback quantum control", "comment": null, "summary": "Prime factorization on quantum processors is typically implemented either via circuit-based approaches such as Shor's algorithm or through Hamiltonian optimization methods based on adiabatic, annealing, or variational techniques. While Shor's algorithm demands high-fidelity quantum gates, Hamiltonian optimization schemes, with prime factors encoded as degenerate ground states of a problem Hamiltonian, generally require substantial classical post-processing to determine control parameters. We propose an all-quantum, measurement-based feedback approach that iteratively steers a quantum system toward the target ground state, eliminating the need for classical computation of drive parameters once the problem Hamiltonian is determined and realized. As a proof of principle, we experimentally factor the biprime 551 using a three-qubit NMR quantum register and numerically analyze the robustness of the method against control field-errors. We further demonstrate scalability by numerically implementing the FALQON factorization of larger biprimes, 9,167 and 2,106,287, using 5 and 9 qubits, respectively."}
{"id": "2601.16121", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.16121", "abs": "https://arxiv.org/abs/2601.16121", "authors": ["Frank Ernesto Quintela Rodríguez"], "title": "Exceptional points in Gaussian channels: diffusion gauging and drift-governed spectrum", "comment": "12 pages, 4 figures", "summary": "McDonald and Clerk [Phys.\\ Rev.\\ Research 5, 033107 (2023)] showed that for linear open quantum systems the Liouvillian spectrum is independent of the noise strength. We first make this noise-independence principle precise in continuous time for multimode bosonic Gaussian Markov semigroups: for Hurwitz drift, a time-independent Gaussian similarity fixed by the Lyapunov equation gauges away diffusion for all times, so eigenvalues and non-diagonalizability are controlled entirely by the drift, while diffusion determines steady states and the structure of eigenoperators. We then extend the same separation to discrete time for general stable multimode bosonic Gaussian channels: for any stable Gaussian channel, we construct an explicit Gaussian similarity transformation that gauges away diffusion at the level of the channel parametrization. We illustrate the method with a single-mode squeezed-reservoir Lindbladian and with a non-Markovian family of single-mode Gaussian channels, where the exceptional-point manifolds and the associated gauging covariances can be obtained analytically."}
{"id": "2601.16123", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16123", "abs": "https://arxiv.org/abs/2601.16123", "authors": ["Samuel Stein", "Shuwen Kan", "Chenxu Liu", "Adrian Harkness", "Sean Garner", "Zefan Du", "Yufei Ding", "Ying Mao", "Ang Li"], "title": "Calibration-Conditioned FiLM Decoders for Low-Latency Decoding of Quantum Error Correction Evaluated on IBM Repetition-Code Experiments", "comment": null, "summary": "Real-time decoding of quantum error correction (QEC) is essential for enabling fault-tolerant quantum computation. A practical decoder must operate with high accuracy at low latency, while remaining robust to spatial and temporal variations in hardware noise. We introduce a hardware-conditioned neural decoder framework designed to exploit the natural separation of timescales in superconducting processors, where calibration drifts occur over hours while error correction requires microsecond-scale responses. By processing calibration data through a graph-based encoder and conditioning a lightweight convolutional backbone via feature-wise linear modulation (FiLM), we decouple the heavy processing of device statistics from the low-latency syndrome decoding.\n  We evaluate this approach using the 1D repetition code as a testbed on IBM Fez, Kingston, and Pittsburgh processors, collecting over 2.7 million experimental shots spanning distances up to d = 11. We demonstrate that a single trained model generalizes to unseen qubit chains and new calibration data acquired days later without retraining. On these unseen experiments, the FiLM-conditioned decoder achieves up to an 11.1x reduction in logical error rate relative to modified minimum-weight perfect matching. We observe that by employing a network architecture that exploits the highly asynchronous nature of system calibration and decoding, hardware-conditioned neural decoding demonstrates promising, adaptive performance with negligible latency overhead relative to unconditioned baselines."}
{"id": "2601.16126", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16126", "abs": "https://arxiv.org/abs/2601.16126", "authors": ["Rishi Sundar", "Thomas Elliott"], "title": "Quantum Dimension Reduction of Hidden Markov Models", "comment": "14 pages, 6 figures", "summary": "Hidden Markov models (HMMs) are ubiquitous in time-series modelling, with applications ranging from chemical reaction modelling to speech recognition. These HMMs are often large, with high-dimensional memories. A recently-proposed application of quantum technologies is to execute quantum analogues of HMMs. Such quantum HMMs (QHMMs) are strictly more expressive than their classical counterparts, enabling the construction of more parsimonious models of stochastic processes. However, state-of-the-art techniques for QHMM compression, based on tensor networks, are only applicable for a restricted subset of HMMs, where the transitions are deterministic. In this work we introduce a pipeline by which \\emph{any} finite, ergodic HMM can be compressed in this manner, providing a route for effective quantum dimension reduction of general HMMs. We demonstrate the method on both a simple toy model, and on a speech-derived HMM trained from data, obtaining favourable memory--accuracy trade-offs compared to classical compression approaches."}
{"id": "2601.16144", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16144", "abs": "https://arxiv.org/abs/2601.16144", "authors": ["Tetsuro Abe", "Shu Tanaka"], "title": "Fair sampling with temperature-targeted QAOA based on quantum-classical correspondence theory", "comment": "4pages, 3figures", "summary": "In combinatorial optimization problems with degenerate ground states, fair sampling of degenerate solutions is essential. However, the quantum approximate optimization algorithm (QAOA) with a standard transverse-field mixer induces biases among degenerate states as circuit depth increases. Based on quantum-classical correspondence theory, we propose SBO-QAOA, which employs a temperature-dependent Hamiltonian encoding a Gibbs distribution as its ground state. Numerical simulations show that, unlike standard QAOA, SBO-QAOA yields ground-state probabilities converging to finite-temperature values with uniform distribution among degenerate states. These fairness and temperature-targeting properties are preserved even with only four variational parameters under a linear schedule."}
{"id": "2601.16154", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16154", "abs": "https://arxiv.org/abs/2601.16154", "authors": ["Samuel Slezak", "Matteo Scandi", "Álvaro M. Alhambra", "Daniel Stilck França", "Cambyse Rouzé"], "title": "Polynomial-time thermalization and Gibbs sampling from system-bath couplings", "comment": "28 pages, 1 figure", "summary": "Many physical phenomena, including thermalization in open quantum systems and quantum Gibbs sampling, are modeled by Lindbladians approximating a system weakly coupled to a bath. Understanding the convergence speed of these Lindbladians to their steady states is crucial for bounding algorithmic runtimes and thermalization timescales. We study two such families of processes: one characterizing a repeated-interaction Gibbs sampling algorithm, and another modeling open many-body quantum thermalization. We prove that both converge in polynomial time for several non-commuting systems, including high-temperature local lattices, weakly interacting fermions, and 1D spin chains. These results demonstrate that simple dissipative quantum algorithms can prepare complex Gibbs states and that Lindblad dynamics accurately capture thermal relaxation. Our proofs rely on a novel technical result that extrapolates spectral gap lower bounds from quasi-local Lindbladians to the non-local generators governing these dynamics."}
{"id": "2601.16177", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.16177", "abs": "https://arxiv.org/abs/2601.16177", "authors": ["Akihiro Hokkyo"], "title": "Stabilizer Thermal Eigenstates at Infinite Temperature", "comment": "4+3 pages, 2 figures", "summary": "Understanding how to analyze highly entangled thermal eigenstates is a central challenge in the study of quantum many-body systems. In this Letter, we introduce a stabilizer-based approach to construct analytically tractable energy eigenstates of nonintegrable many-body Hamiltonians. Focusing on zero-energy eigenstates at infinite temperature, we prove a sharp no-go theorem: stabilizer eigenstates of two-body Hamiltonians cannot satisfy $k$-body microscopic thermal equilibrium for any $k\\ge4$. We further show that this bound is tight by explicitly constructing two-body nonintegrable Hamiltonians whose stabilizer eigenstates reproduce thermal expectation values for all two-body and all three-body observables. Finally, we identify the structural origin of this limitation by characterizing the conditions under which a stabilizer state can appear as a zero-energy eigenstate of a Hamiltonian, thereby revealing a fundamental constraint imposed by the few-body nature of interactions."}
{"id": "2601.16180", "categories": ["quant-ph", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.16180", "abs": "https://arxiv.org/abs/2601.16180", "authors": ["Melody Lee", "Roland C. Farrell"], "title": "Studying energy-resolved transport with wavepacket dynamics on quantum computers", "comment": "21 pages, 11 figures, 4 tables", "summary": "Probing energy-dependent transport in quantum simulators requires preparing states with tunable energy and small energy variance. Existing approaches often study quench dynamics of simple initial states, such as computational basis states, which are far from energy eigenstates and therefore limit the achievable energy resolution. In this work, we propose using wavepackets to probe transport properties with improved energy resolution. To demonstrate the utility of this approach, we prepare and evolve wavepackets on Quantinuum's H2-2 quantum computer and identify an energy-dependent localization transition in the Anderson model on an 8x7 lattice--a finite-size mobility edge. We observe that a wavepacket initialized at low energy remains spatially localized under time evolution, while a high-energy wavepacket delocalizes, consistent with the presence of a mobility edge. Crucial to our experiments is an error mitigation strategy that infers the noiseless output bit string distribution using maximum-likelihood estimation. Compared to post-selection, this method removes systematic errors and reduces statistical uncertainty by up to a factor of 5. We extend our methods to the many-particle regime by developing a quantum algorithm for preparing quasiparticle wavepackets in a one-dimensional model of interacting fermions. This technique has modest quantum resource requirements, making wavepacket-based studies of transport in many-body systems a promising application for near-term quantum computers."}
{"id": "2601.16189", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16189", "abs": "https://arxiv.org/abs/2601.16189", "authors": ["Xiaotian Yang", "Santiago Zamora", "Rafael Chaves", "Ulrik L. Andersen", "Jonatan Bohr Brask", "A. de Oliveira Junior"], "title": "Robust Bell Nonlocality from Gottesman-Kitaev-Preskill States", "comment": "5+11 pages, 5 figures. Comments welcome", "summary": "Bell tests based on homodyne detection are strongly constrained in continuous-variable systems. Can Gottesman-Kitaev-Preskill (GKP) encoding turn homodyne detection into a practical tool for revealing Bell nonlocality? We consider a physically motivated model in which each party performs homodyne detection and digitizes the continuous outcome via a fixed periodic binning, corresponding to logical Pauli measurements. Within this framework, we derive a bipartite no-go: CHSH cannot be violated for Bell-pair states. Moving beyond two parties, we show that finitely squeezed GKP-encoded GHZ and W states nevertheless exhibit strong multipartite nonlocality, violating multipartite Bell inequalities with homodyne-only readout. We quantify the required squeezing thresholds and robustness to loss, providing a route toward homodyne-based Bell tests in continuous-variable systems."}
{"id": "2601.15345", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15345", "abs": "https://arxiv.org/abs/2601.15345", "authors": ["Amanda Gatto Lamas", "Taylor L. Hughes"], "title": "Non-zero Momentum Implies Long-Range Entanglement When Translation Symmetry is Broken in 1D", "comment": "24+8 pages, 15+5 figures", "summary": "A result by Gioia and Wang [Phys Rev X 12, 031007 (2022)] showed that translationally symmetric states having nonzero momentum are necessarily long range entangled (LRE). Here, we consider the question: can a notion of momentum for non-translation symmetric states directly encode the nature of their entanglement, as it does for translation symmetric states? We show the answer is affirmative for 1D systems, while higher dimensional extensions and topologically ordered systems require further work. While Gioia and Wang's result applies to states connected via finite depth quantum circuits to a translation symmetric state, it is often impractical to find such a circuit to determine the nature of the entanglement of states that break translation symmetry. Here, instead of translation eigenstates, we focus on the many-body momentum distribution and the expectation value of the translation operator in many-body states of systems having broken translation symmetry. We show that in the continuum limit the magnitude of the expectation value of the translation operator $|<T>|$ necessarily goes to $1$ for delocalized states, a proxy for LRE states in 1D systems. This result can be seen as a momentum-space version of Resta's formula for the localization length. We investigate how accurate our results are in different lattice models with and without well-defined continuum limits. To that end, we introduce two models: a deterministic version of the random dimer model, illustrating the role of the thermodynamic and continuum limits for our result at a lattice level, and a simplified version of the Aubry-Andre model, with commensurate hopping for both momentum and position space. Finally, we use the random dimer model as a test case for the accuracy of $|<T>|$ as a localization (and thus entanglement) probe for 1D periodic lattice models without a well-defined continuum limit."}
{"id": "2601.15377", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15377", "abs": "https://arxiv.org/abs/2601.15377", "authors": ["Laura Shou", "Jeet Shah", "Matthew Lerner-Brecher", "Amol Aggarwal", "Alexei Borodin", "Victor Galitski"], "title": "Exactly solvable topological phase transition in a quantum dimer model", "comment": "5+6 pages, 8+4 figures", "summary": "We introduce a family of generalized Rokhsar-Kivelson (RK) Hamiltonians, which are reverse-engineered to have an arbitrary edge-weighted superposition of dimer coverings as their exact ground state at the RK point. We then focus on a quantum dimer model on the triangular lattice, with doubly-periodic edge weights. For simplicity we consider a $2\\times1$ periodic model in which all weights are set to one except for a tunable horizontal edge weight labeled $α$. We analytically show that the model exhibits a continuous quantum phase transition at $α=3$, changing from a topological $\\mathbb{Z}_2$ quantum spin liquid ($α<3$) to a columnar ordered state ($α>3$). The dimer-dimer correlator decays exponentially on both sides of the transition with the correlation length $ξ\\propto1/|α-3|$ and as a power-law at criticality. The vison correlator exhibits an exponential decay in the spin liquid phase, but becomes a constant in the ordered phase. We explain the constant vison correlator in terms of loops statistics of the double-dimer model. Using finite-size scaling of the vison correlator, we extract critical exponents consistent with the 2D Ising universality class."}
{"id": "2601.15842", "categories": ["hep-lat", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15842", "abs": "https://arxiv.org/abs/2601.15842", "authors": ["Gianluca Esposito", "Simone Cepollaro", "Luigi Cappiello", "Alioscia Hamma"], "title": "Magic of discrete lattice gauge theories", "comment": null, "summary": "Simulation of quantum field theories and fundamental interactions are one of the most challenging tasks in modern particle physics. Classical computers generally fail to reproduce accurate results when it comes to strongly coupled theories such as QCD. Recent developments in quantum technologies open up the possibility of simulating such physical regimes by using quantum computers. In this paper, we study the quantum resource related to the simulability of a quantum theory, i.e. non-stabilizerness for Lattice Gauge Theory (LGT) with discrete symmetry gauge groups. We show that enforcing gauge constraints for $\\mathbb{Z}_l$ LGTs has no cost in terms of this resource and discuss the relation between non-abelianity of the gauge group with the average non-stabilizerness of the gauge invariant Hilbert space."}
{"id": "2601.16166", "categories": ["hep-lat", "cond-mat.quant-gas", "nucl-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.16166", "abs": "https://arxiv.org/abs/2601.16166", "authors": ["Jiahao Cao", "Rohan Joshi", "Yizhuo Tian", "N. S. Srivatsa", "Jad C. Halimeh"], "title": "String Breaking and Glueball Dynamics in $2+1$D Quantum Link Electrodynamics", "comment": "$21$ pages, $11$ figures, $2$ tables", "summary": "At the heart of quark confinement and hadronization, the physics of flux strings has recently become a focal point in the field of quantum simulation of high-energy physics (HEP). Despite considerable progress, a detailed understanding of the behavior of flux strings in quantum simulation-relevant lattice formulations of gauge theories has remained limited to the lowest truncations of the gauge field, which are severely limited in their ability to draw conclusions about the quantum field theory limit. Here, we employ tensor network simulations to investigate the behavior of flux strings in a quantum link formulation of $2+1$D quantum electrodynamics (QED) with a spin-$1$ representation of the gauge field. We first map out the ground-state phase diagram of this model in the presence of two spatially separated static charges, revealing distinct microscopic processes responsible for string breaking, including a two-stage breaking mechanism not possible in the spin-$\\frac{1}{2}$ formulation. Starting in different initial product state string configurations, we then explore far-from-equilibrium quench dynamics across various parameter regimes, demonstrating genuine $2+1$D real-time string breaking and glueball-like bound state formation, with the latter not possible in the spin-$\\frac{1}{2}$ formulation. In and out of equilibrium, we consider different values and placements of the static charges. Finally, we provide efficient qudit circuits for a quantum simulation experiment in which our results can be observed in state-of-the-art ion-trap setups. Our findings lay the groundwork for quantum simulations of flux strings towards the quantum field theory limit."}
